<doc id="17417" url="https://es.wikipedia.org/wiki?curid=17417" title="Medellín">
Medellín

Medellín es un municipio colombiano, capital del departamento de Antioquia. Es la ciudad más poblada del departamento y la segunda del país. Se asienta en la parte más ancha de la región natural conocida como Valle de Aburrá, en la cordillera central de los Andes, constituyéndose como el mayor centro urbano de tal ramal andino. Se extiende a ambas orillas del río Medellín -llamado también río Aburrá-, que la atraviesa de sur a norte, y es el núcleo principal del área metropolitana del Valle de Aburrá. La ciudad tiene una población de 2 508 452 habitantes (2017), mientras que dicha cifra, incluyendo el área metropolitana, asciende a 3 821 797 personas (2016).

El 2 de marzo de 1616, el gobernador Francisco Herrera Campuzano estableció un resguardo indígena con el nombre de San Lorenzo de Aburrá, en el lugar donde hoy se ubica el barrio El Poblado. El acto fundacional comenzó el 20 de marzo de 1671 cuando el gobernador de la entonces provincia de Antioquia, Francisco Montoya y Salazar, decretó la fundación de la “villa” en el sitio Aná, con el nombre “Villa de Nuestra Señora de la Candelaria de Aná”. Cuatro años después, el 14 de octubre de 1675 se recibió su aprobación mediante la Real Cédula, fechada el 22 de noviembre de 1674, y firmada por la reina María Ana de Austria, con el nombre sancionado de “Villa de Nuestra Señora de la Candelaria de Medellín”. El 2 de noviembre de 1675, el gobernador Miguel de Aguinaga da cumplimiento a la disposición de la Real Cédula. En 1966, el Concejo de Medellín, mediante Acuerdo 17, aclaró que en 1616 se fundó un resguardo y que en 1675 lo que se fundó fue una villa. En 1975, el Acuerdo 32 volvió a reconocer la fecha de fundación de Medellín el 2 de noviembre de 1675.

En 1826 fue designada capital de Antioquia, título que ostentaba Santa Fe de Antioquia desde la época colonial. Durante el siglo XIX, Medellín se desarrolló como un centro dinámico de comercio, primero exportando oro, y posteriormente mercancías provenientes de la industrialización de la ciudad.

Como capital departamental, Medellín alberga las sedes de la Gobernación de Antioquia, la Asamblea Departamental, el Tribunal Superior del Distrito Judicial de Medellín, el Área metropolitana del Valle de Aburrá y la Fiscalía General, así como diferentes empresas públicas, instituciones y organismos del Estado colombiano. Como centro financiero, comercial e industrial es sede de empresas nacionales e internacionales en sectores como el textil, confecciones, metalmecánico, energético, financiero, salud, telecomunicaciones, construcción, automotriz, y alimentos, entre otros.

La más reciente encuesta sobre el estado global de las Ciudades Inteligentes de Indra Sistemas cataloga a Medellín como una de las mejores ciudades para vivir en América del Sur, compartiendo el primer lugar con Santiago de Chile y junto a Barcelona y Lisboa en Europa. Medellín ganó el Premio de la Ciudad Mundial Lee Kuan Yew 2016. El premio busca reconocer y celebrar los esfuerzos en fomentar la innovación en las soluciones urbanas y el desarrollo urbano sostenible.

En 2013 fue elegida como la ciudad más innovadora del mundo en el marco del concurso City of the Year, que organizan The Wall Street Journal y Citigroup; para optar este título, un jurado internacional escogió a Medellín y a otras dos ciudades como finalistas; la decisión final fue tomada por una encuesta abierta al público por Internet. Es considerada una ciudad global tipo "suficiente" por el GaWC.

En el año 75 a.C., Quintus Caecilius Metellus Pius fundó una población en Hispania a la que llamó "Metellinum", la actual Medellín de Extremadura, en la provincia de Badajoz, España. El nombre de la ciudad fue dado en 1675 en honor de Pedro Portocarrero y Luna, conde de Medellín en Extremadura y por aquel entonces presidente del Consejo de Indias, por el interés que tomó en la erección en villa del poblado de "Nuestra Señora de la Candelaria de Aná" ya que hubo una fuerte oposición por parte de la ciudad de Santa Fe de Antioquia, que por esa época era la capital de la Provincia de Antioquia, puesto que con dicha erección verían disminuida su jurisdicción y su control político sobre la provincia.

Ese mismo año, llegó, finalmente, la real cédula firmada por la reina regente, Mariana de Austria (en representación de su hijo, Carlos II, menor de edad), fechada el 22 de noviembre de 1674, en la cual concede la fundación en Villa de la "Candelaria de Aná". El 2 de noviembre de 1675 le correspondió al gobernador y capitán general de la Provincia de Antioquia, Miguel de Aguinaga y Mendigoitia, proclamar la erección de la Villa de Nuestra Señora de la Candelaria de Medellín.

Hace 1.500 años aproximadamente el Valle de Aburrá era recorrido por tribus de cazadores y recolectores. Cuando llegaron los conquistadores españoles encontraron asentada una población nativa numerosa, que opuso poca resistencia. Eran aburraes, yamesíes, peques, ebéjicos, noriscos y maníes que, se calcula, estaban allí desde el siglo V a. C. Tenían grandes cultivos de maíz y fríjol, criaban curíes y perros mudos, tejían mantas de algodón, comercializaban sal, y conocían la orfebrería. Bajo el dominio español fueron repartidos en encomiendas y desplazados de sus tierras. La deserción, el maltrato, las enfermedades y el duro trabajo intensivo en la tierra y las minas, en pocos años los diezmaron.

El valle en donde hoy se asienta Medellín fue descubierto el 24 de agosto de 1541, día de San Bartolomé, por Jerónimo Luis Tejelo, un capitán a órdenes del mariscal Jorge Robledo, quien fundó la ciudad de Santa Fe de Antioquia ese mismo año y es considerado el conquistador de Antioquia. El valle era llamado Valle de Aburrá por los indígenas que lo habitaban y fue llamado por los españoles Valle de San Bartolomé o de Los Alcázares. Los indígenas respondieron con belicosidad según algunos cronistas, resistencia que obligó a Tejelo a atrincherarse para la defensiva y a despachar un expreso al mariscal Robledo pidiéndole auxilio, con el cual vencieron fácilmente a los aborígenes. Dicha resistencia la hicieron propiamente los indígenas que habitaban el caserío de Guayabal, pues los demás que ocupaban el valle prefirieron huir o quitarse la vida.
El 2 de marzo de 1616 el licenciado Francisco de Herrera Campuzano, del Consejo del Rey, Oidor de la Real Audiencia del Nuevo Reino de Granada y Visitador General de la Provincia de Antioquia, fundó una población a la que llamó San Lorenzo de Aburrá, en donde hoy se sitúa El Poblado. El caserío, que estaba compuesto por trecientos indígenas y algunos pocos españoles, finalmente no prosperó y en 1646 fue trasladado al ángulo que forman el río Medellín (antes río Aburrá) y el arroyo Santa Elena, sitio que los indígenas llamaban Aná y los españoles Aguasal. Pocos años después se levantó la primera iglesia de tapias y tejas, consagrada a la Virgen de la Candelaria, y desde entonces la población se llamó Nuestra Señora de la Candelaria de Aná, que a los 54 años de vida contaba apenas con 700 habitantes de los 3.000 que poblaban el territorio comprendido entre el Ancón de la Valeria (hoy Caldas) hasta los potreros de Barbosa.

Desde 1670 los habitantes pidieron a la Real Audiencia la elección en villa de su población, encontrando resistencia por parte de la ciudad de Santa Fe de Antioquia. Finalmente Mariana de Austria, viuda de Felipe IV, en nombre de su hijo Carlos II, otorgó la elección en villa de la pequeña población, que ahora pasó a llamarse Villa de Nuestra Señora de la Candelaria de Medellín. Un siglo después, en 1783, se abrieron nuevas calles por orden de Francisco Silvestre y Sánchez, quien fue gobernador de la Provincia de Antioquia. En 1786, el Oidor Juan Antonio Mon y Velarde hizo numerar las casas, que eran 242 de un piso y 29 de balcón, y marcar las calles con los nombres de San Francisco, San Lorenzo, La Amargura (hoy calle Ayacucho), El Prado, entre otros. También dictó medidas sobre saneamiento, instrucción pública, mejora del comercio y sistemas administrativos; igualmente dota a la villa de agua corriente, crea colonias agrícolas y estimula la minería. Estas medidas progresistas levantan el ánimo de los habitantes y permiten entrever tiempos mejores para la población y para la provincia entera.

Ya en el siglo XIX y en plena época de la Independencia, el 21 de agosto de 1813, Juan del Corral erige en ciudad a Medellín, privilegio que hasta entonces, y en lo que respecta a la provincia, solo tenían Santa Fe de Antioquia y Rionegro. En 1826 se le nombra capital de Antioquia, contando en ese año con 6.050 habitantes.

En los primeros años del siglo XIX la ciudad experimentó un lento desarrollo debido, entre otras cosas, a las precarias vías de comunicación con el resto del país y el exterior. Desde el punto de vista intelectual, material y social se seguían conservando las características de pueblo de incipiente civilización. No fue sino hasta el periodo comprendido entre 1830 y 1850 cuando la ciudad comenzó su desarrollo paulatino. La educación dio en este periodo un salto trascendental. Durante la época colonial y aún en los inicios de la República se contaban con muy pocas escuelas y colegios, situación que cambió a partir de la mitad del siglo, siendo notable durante el gobierno de Pedro Justo Berrío.

El río Medellín carecía en aquel entonces de puentes que lo atravesaran y fue haciéndose necesaria la construcción de alguno, ya que sus aguas eran abundantes, sobre todo en invierno, y se requerían balsas para pasarlo. El puente de Colombia fue el primero dentro del territorio de la ciudad y fue levantado con auxilio nacional ofrecido por el entonces presidente Tomás Cipriano de Mosquera en 1846. El segundo puente sobre el río fue el de Guayaquil. En 1868 se decretó el traslado de la sede de la diócesis de Santa Fe de Antioquia a Medellín, lo que le permitió a ésta fortalecer las instituciones religiosas que existían en aquel entonces. La construcción de la Catedral Metropolitana marcó un hito no solo en el ámbito religioso sino también desde el punto de vista arquitectónico. Igualmente el comercio se fue fortaleciendo hasta consolidarse como actividad financiera. Fue así como en Medellín surgió el Banco de Antioquia en 1871, el Banco de Medellín en 1881, el Banco Popular en 1882 y el Banco del Comercio en 1896.

El despegue de la ciudad hacia la modernidad coincidió con un acelerado crecimiento de su población, de 20.000 habitantes en 1870 a 140.000 en 1938. La ciudad se consolidó como un centro de comercio de oro, café, finca raíz, mecánica, fundición, especulación e importación de mercancías. Esta vocación comercial se complementó al comienzo del siglo XX con una industrial (textil, gaseosas, cigarrillos, calzado, entre otras), al aprovechar la presencia de abundantes fuentes hídricas, avances en movilidad y mercados cercanos.

Al tiempo que entraron los primeros automóviles importados de Estados Unidos y de Francia, se crearon fábricas importantes, en particular empresas textileras, como la Compañía Colombiana de Tejidos Coltejer (1907), o la fábrica de Hilados y Tejidos del Hato (Fabricato), la cual empezó a funcionar en los años veinte y en menos de dos décadas se consolidaría como la segunda textilera más importante, después de Coltejer. Otras empresas importantes fueron creadas en estos años como la Compañía Colombiana de Tabaco (1919), la fábrica de Gaseosas Lux (1925) y en lo referente a la industria cafetera se destaca la fundación de Café La Bastilla en 1922.

A partir de 1910 estas industrias se convirtieron en el motor principal del crecimiento urbano, y crearon una primera generación de empresarios industriales y de obreros asalariados. La ciudad atrajo inmigrantes del campo con aspiración de trabajar en las fábricas y almacenes. También llegaron inmigrantes más prósperos, como empresarios de la minería, comerciantes, ganaderos y jóvenes de familias pudientes, con la idea de educarse.

En el "Plan Piloto de Medellín", elaborado en 1950 por los arquitectos extranjeros Paul Wiener y José Luis Sert, se recomendaba: la canalización del río, el control de los asentamientos en las laderas, el montaje de la zona industrial de Guayabal, la articulación de la ciudad en torno al río, la construcción de la zona deportiva del estadio Atanasio Girardot y del centro administrativo “La Alpujarra”. Pronto, el Plan Piloto se vio desbordado por la realidad de una población que se triplicó en 20 años, pasando de 358.189 habitantes, en 1951, a 1.071.252, en 1973. En este periodo la construcción tuvo un gran dinamismo y los campesinos, que no tenían acceso a los créditos de vivienda, empezaron a construir en las laderas. Muchas de las edificaciones antiguas del centro, y aún las de principios del siglo XX, fueron demolidas para dar paso a los edificios que fueron destinados para oficinas y vivienda, entre ellos el de Coltejer, símbolo de la ciudad. El sector textil se modernizó bastante en este periodo y se consolidó de forma definitiva la vocación industrial de la ciudad.

Por primera vez, después de tener Antioquia una economía en ascenso durante 150 años, se presentan en la década de 1970 los síntomas iniciales de lo que sería la más grande crisis económica y social en su historia. Aparecen indicadores de aumento del desempleo, y con él la criminalidad y la inseguridad general. Aunque el país en su conjunto afrontó entre 1970 y 1980 un periodo crítico en su economía, esta crisis tuvo un especial impacto en Medellín, que llegó a tener la tasa de desempleo más alta de la nación. El sector manufacturero no solo había perdido dinámica, sino que se mostraba incapaz para afrontar la situación creada con los altos índices de desempleo, la recesión económica y la imposición desde el gobierno central de un nuevo modelo de desarrollo fundamentado en las actividades financieras y de la construcción. Es entonces cuando el contrabando, primero, y luego el narcotráfico, aparecen como alternativa para miles de personas que no tenían en el mercado legal ninguna o muy poca posibilidad de encontrar empleo o de ejercer una actividad económica rentable.

El Cartel de Medellín fue creado en 1976 y contó, hasta mediados de los años 1980, de una relativa libertad y tolerancia como resultado de su directa penetración en todos los sectores de la sociedad. Con la aprobación de las medidas que permitían la extradición de colombianos a los Estados Unidos, tomadas por el presidente Belisario Betancur luego del asesinato de su ministro de Justicia, el cartel de la droga inició un gran movimiento para desestabilizar al Estado. La ciudad sufrió todo el peso de la lucha entre el narcotráfico y el gobierno central en los últimos años de la década de los ochenta y a principios de los noventa. Aparecieron el narcoterrorismo, el sicariato, las bandas delincuenciales en los barrios populares, los secuestros, y los asesinatos de jueces y políticos.

La muerte de Pablo Escobar, en 1993, supuso el fin del llamado Cartel de Medellín, pero dejó profundos conflictos sociales en la región. La guerrilla y el paramilitarismo continuaron con su activismo armado que han creado duros impactos no solo en la ciudad sino en el país como el aumento de desplazados por la violencia y el endurecimiento de las políticas de seguridad del Estado como la Operación Orión en San Javier (octubre de 2002).

Hasta 2008 en la Región Paisa, de la que Medellín hace parte, operaban por lo menos seis de las principales bandas emergentes provenientes de los restos de los grupos paramilitares que se desmovilizaron durante las conversaciones de paz con el gobierno Colombiano en el periodo 2004-2006. Entre ellas están: Autodefensas Gaitanistas de Colombia, Águilas Negras, la Oficina de Envigado, Los Urabeños, Los Rastrojos o el grupo de Los Paisas; los cuatro últimos grupos son los que están activos en el país a 2015. Estos grupos criminales concentran sus operaciones en las ciudades y pequeños pueblos a lo largo y ancho del país, tratando de controlar los flujos de drogas hacia la costa Caribe y el control de la minería ilegal. Las rutas del narcotráfico se mueven especialmente los departamentos de Córdoba y Sucre donde venden la droga a las organizaciones que cuentan con infraestructuras más grandes y pueden mover las drogas a nivel internacional.

La preocupación por detener los flujos de violencia urbana ha hecho que se presenten proyectos de inclusión social que incluyen grandes infraestructuras como los parques-bibliotecas en áreas urbanas conflictivas, los sistemas de transporte masivo como el Metro, el Metroplús, y el Tranvía y la participación del sector privado, oficial y las instituciones para unificar un proyecto de ciudad, la proliferación de eventos culturales y artísticos, la construcción de bibliotecas, parques y centros educativos y la creación y renovación del espacio público.

En palabras de "Dan Restrepo", asesor del presidente estadounidense Barack Obama, Medellín es una de las ciudades de referencia de América, siendo sede de varios festivales, y destacándose además en la actividad académica y científica a nivel nacional. Entre los galardones que ha recibido la ciudad, se pueden destacar la selección como una de las diez ciudades más sorprendentes del mundo para celebrar Navidad según "National Geographic" gracias al alumbrado, el Premio Transporte Sostenible en 2012 a cargo de la Junta de Investigación del Transporte de la "National Research Council" (pese a ser una de las ciudades más contaminadas del continente), la mención de la BBC en 2013 como capital latinoamericana de la innovación, la mayor votación del público como ciudad más innovadora del mundo en el concurso que organizaron Citigroup y The Wall Street Journal, La decisión dependió de una votación abierta al público por Internet.Medellín recibió un nuevo reconocimiento en el concurso The Business Destinations Travel Awards, organizado por la revista Business Destinations; 550 compañías y empresarios la eligieron como el mejor destino de Suramérica para hacer negocios. Medellín fue la ciudad más competitiva de Colombia en 2012 a nivel económico entre las 22 principales capitales del país según la organización cartagenera Observatorio Económico del Caribe. A inicios del siglo XXI, la ciudad ha recuperado gran parte de su dinamismo industrial, con el desarrollo de políticas innovadoras enmarcadas en la integración de las zonas más marginales de la ciudad, un aumento en la seguridad y mejoras en la educación.

Medellín se encuentra ubicada en el centro geográfico del Valle de Aburrá, sobre la cordillera central de los Andes en las coordenadas . La ciudad cuenta con un área total de 328 km² de los cuales 110 km² son suelo urbano y 218 km² son suelo rural.

El valle de Aburrá posee una extensión de 1.152 km² que hacen parte de la cuenca del río Medellín, principal arteria fluvial que cruza la región de sur a norte. La conformación del Valle de Aburrá es el resultado de la unidad geográfica determinada por la cuenca del río Medellín y por una serie de afluentes que caen a lo largo de su recorrido. El Valle tiene una longitud aproximada de 60 kilómetros y una amplitud variable. Está enmarcado por una topografía irregular y pendiente, que oscila entre 1.300 y 2.800 metros sobre el nivel del mar. Las cordilleras que lo encierran, dan lugar a la formación de diversos microclimas, saltos de agua, bosques y sitios de diverso valor paisajístico y ecológico. El valle tiene una forma alargada y presenta un ensanchamiento en su parte media, el cual mide 10 kilómetros y es donde se localiza Medellín. El Valle de Aburrá está totalmente urbanizado en su parte plana, y muy ocupado en sus laderas.

Topográficamente la ciudad es un plano inclinado que desciende desde 1.800 a 1.500 metros de altura sobre el nivel del mar, sin embargo, la altura oficial de la ciudad es de 1.479 msnm en la confluencia de las quebradas La Iguaná, Santa Elena y el río Medellín, y se eleva a 3.200 msnm en los altos El Romeral, Padre Amaya y cuchilla Las Baldías. Dentro del paisaje urbano se destacan los cerros Nutibara y El Volador, que se levantan como manchas verdes en medio de la ciudad. Los altiplanos y montañas que circundan el valle sobrepasan los 2.500 metros. Las principales alturas en el territorio de Medellín son: Alto Padre Amaya (3.100 msnm), Alto Patio Bonito (2.750 msnm), Alto Boquerón (2.600 msnm), Alto Venteadero (2.500 msnm) y el Alto Las Cruces (2.400 msnm), entre otros.

El río Medellín es la corriente hidrográfica más importante de la ciudad, la divide en dos partes y es su drenaje natural. Nace en el alto de San Miguel, en el municipio de Caldas, a una altura de 3.000 msnm; tiene una extensión aproximada de 100 km desde su nacimiento hasta su desembocadura (donde confluye con el río Grande y le dan nacimiento al Porce) y recibe las aguas de aproximadamente 196 afluentes a lo largo de todo su recorrido. En lo que respecta al territorio de la ciudad, recibe 57 afluentes directos y más de 700 corrientes de segundo y tercer orden, con 23 corrientes mayores, constituyendo una red hidrográfica de una densidad considerable. Las quebradas Santa Elena y La Iguaná , por su caudal y longitud de recorrido, son las de mayor importancia en el territorio municipal. La quebrada La Iguaná nace en la serranía de Las Baldías y la quebrada Santa Elena nace en cerro Espíritu Santo o Verde. La primera atraviesa la zona centro-occidental, mientras que la segunda atraviesa la zona centro-oriental y está cubierta en su paso por el centro de la ciudad.

Las corrientes mayores de la ciudad a demás de éstas son de sur a norte: Doña María, La Aguacatala, La Jabalcona, La Volcana, La Presidenta, La Poblada, La Guayabala, Altavista, La Picacha, Ana Díaz, La Hueso, Malpaso, El Ahorcado, El Molino, La Quintana, La Bermejala, La Rosa, La Herrera, Cañada Negra y La Madera.

La latitud y altitud de la ciudad dan como resultado un clima subtropical monzónico. El clima es templado y húmedo, con una temperatura promedio de 22°C. El apelativo «"ciudad de la eterna primavera"» proviene de la fama de un clima bastante uniforme durante todo el año, con unas pocas variaciones de temperatura entre diciembre y enero y entre junio y julio, las temporadas más secas y cálidas del año. Sin embargo hay muchas diferencias en cuanto al clima de los diferentes barrios de la ciudad. Los barrios más calurosos son los que se ubican en el centro de la ciudad (La Candelaria, El Chagualo, San Benito, entre otros) y en la parte norte de la rivera del río Medellín (La Toscana, Boyacá-Las Brisas, Moravia, Santa Cruz), mientras que los barrios más fríos se ubican en las partes altas de las montañas circundantes (Altos del Poblado, San Lucas, La Sierra, 8 de marzo, Oriente, Santo Domingo Savio, San José de la Cima, Carpinelo, Picacho, entre otros).

En los días soleados a mediodía las temperaturas pueden llegar hasta los 30 °C. Sin embargo, en Medellín los días completamente despejados son poco comunes, un día normal en Medellín es parcialmente nublado con intervalos de sol y de sombra, lo que genera que la tasa de insolación en Medellín sea relativamente baja (unas 5 o 6 horas de sol al día en promedio) frente a la de ciudades como Barranquilla (que tiene entre 7 y 8 horas de sol al día en promedio). En un día parcialmente nublado las temperaturas suben a los 27 °C al mediodía y en los lluviosos alcanza apenas los 24 °C.

La temperatura de Medellín está determinada por los pisos térmicos que van del páramo (que equivale a 3 km² del territorio), pasando por el frío (192 km²) hasta llegar al medio (185 km²), en donde está la zona urbana, la cual tiene una temperatura que oscila entre 12 °C y 30 °C. Las temperaturas más altas oscilan entre 27 °C y 31 °C, con máxima absoluta de 33,2 °C, la cual fue registrada en el año 1993 en el barrio San Javier, en el centroccidente de la ciudad. Las más bajas oscilan alrededor de 13 °C y 15 °C, con mínima absoluta de 10 °C. El comienzo y la mitad del año son estaciones secas, de resto el clima es variable, lluvioso en algunas épocas. La precipitación media anual es moderada: 1656 mm, y no es igual en todo el valle: llueve más al sur que al norte.

Las temperaturas son constantes durante el año, en verano las temperaturas pueden subir arriba de los 30 °C, llueve más en otoño, raras veces hay bajas temperaturas en invierno.

Por su ubicación entre montañas, Medellín es una ciudad de vientos suaves y constantes. El régimen de vientos lo determinan los alisios dominantes del nordeste y las masas de aire cálido que suben desde los valles bajos de los ríos Cauca y Magdalena, con predominio de movimiento en la zona norte del valle, lo que origina que el viento sople en dirección norte-sur. Es de advertir que todas estas condiciones varían de acuerdo con los cambios climáticos originados en el océano Pacífico, llamados fenómeno del Niño y de la Niña. Entonces hay más lluvia o más sequía.

En consecuencia al crecimiento urbano y demográfico de la ciudad se ha presentado una notable alteración de la fauna y flora dentro del valle de Aburrá. Con la contaminación de las aguas desaparecieron casi toda la fauna y flora acuática del río que la atraviesa y sus afluentes. Sin embargo, existen reservas naturales notables dentro del área de la ciudad que se complementan a su vez con todo el sistema ecológico del Valle de Aburrá. Medellín se encuentra entre el grupo de las veinte ciudades más contaminadas de América Latina.

En cuanto a minerales, en los corregimientos de San Cristóbal y Altavista, oeste del área urbana, hay más de 30 minas a cielo abierto que extraen materiales de construcción de tipo arcilloso. Adicionalmente, en la zona conocida como Marmato-Titiribí hay potencial de explotación de pórfidos y vetas con metales como cobre, oro y molibdeno. Estas zonas están dispersas en el área de los corregimientos al oeste del casco urbano.

Medellín no escapa a la tendencia colombiana de crecimiento de las áreas urbanas en detrimento de la población rural, este proceso de urbanización acelerado no se debe exclusivamente a la industrialización, ya que existen unas complejas razones políticas y sociales como la pobreza y la violencia, las cuales han motivado la migración del campo a la ciudad a lo largo del siglo XX, generando un crecimiento exponencial de la población en las zonas urbanas. Hoy en día el 58% de la población de Antioquia habita en el área metropolitana. El 67% de los habitantes de dicha área, corresponden a Medellín, de los cuales el 61,3% nacieron en la ciudad, el 38,4% en otro municipio y el 0,3% son de otro país.
De acuerdo con las cifras del último censo nacional (2005) realizado por el Departamento Administrativo Nacional de Estadística -DANE-, dio como resultado una población de 2.223.078 habitantes para Medellín y 3.312.165 personas para el área metropolitana conformada por otros 9 municipios, con proyecciones al 2014 de 2.541.123 y 3.731.447 respectivamente,siendo ésta la segunda aglomeración urbana de Colombia. Además, según el censo, la ciudad cuenta con una densidad poblacional de aprox. 5820 habitantes por kilómetro cuadrado. Solo 130.031 habitantes se ubican en la zona rural de Medellín. El 46,7 % de la población son varones y el 53,3 % mujeres y el promedio de personas por hogar es de 4.

La ciudad cuenta con una tasa de analfabetismo del 6,8% en la población mayor de 5 años de edad. Los servicios públicos tienen una cobertura del 98,8% de viviendas con servicio de energía eléctrica, mientras que un 97,3% tiene servicio de acueducto y un 91,0% de comunicación telefónica.

Actualmente la ciudad enfrenta una ola de migración de extranjeros derivada de su proyección internacional. Estadounidenses, alemanes, suecos y hasta coreanos han encontrado en Medellín un nuevo hogar. Además, se destaca la migración de venezolanos, debido a la crisis interna que vive el país vecino, la cual se estima a 2017 en 57.932 venezolanos viviendo en la entidad.

En 2015 se registraron 95.335 nacimientos en Medellín (48.858 varones y 56.497 niñas). La longevidad en la ciudad es de 75 años, siendo esta mayor en mujeres que en hombre.

Las defunciones en 2015 fueron 15,430 (8,191 varones y 7,236 mujeres).

En 2015 más de 99 mujeres fueron asesinadas, de las cuales 88 murieron en crímenes relacionados con conflictos entre pandillas. En 2010 la Alcaldía de Medellín registró 182 homicidios de niños y adolescentes (entre 0 y 17 años), mientras que en cada 100 víctimas de muertes violentas, 9 eran niños o adolescentes.

Sin embargo, la Personería de Medellín en su informe sobre derechos humanos en la ciudad concluyó que durante el 2012 se presentó una reducción del 28% de homicidios, el 8% de violencia intrafamiliar y el 7% de violencia sexual.

Según las cifras presentadas por el DANE del censo 2005, la composición etnográfica de la ciudad es:


El 4% de los hogares medellinenses tiene experiencia migratoria internacional siendo los Estados Unidos el primer país de preferencia (55,5%), seguido por España (17%), y otros países (12,1%). Pero hay preferencias de destino significativas hacia Venezuela (5,5%), Perú, Panamá, México, Ecuador, Costa Rica, Canadá, Bolivia y Australia. La demanda de fuerza de trabajo poco calificada convierte la búsqueda de oportunidades laborales uno de los principales motivadores para esta migración, de igual forma, el anhelo de una mejor calidad de vida, la búsqueda de oferta de estudios superiores o la reunificación familiar son también motivos principales.

El 39% de la población residente en la ciudad nació en otra región del país, siendo en su mayoría desplazados por el conflicto armado interno en Colombia, convirtiendo a Medellín en ciudad de inmigrantes, provenientes principalmente del Chocó e internamente de otras regiones de Antioquia; mientras que el 0,4% provienen de otra nación.

Medellín está regido por un sistema democrático basado en los procesos de descentralización administrativa generados a partir de la proclamación de la Constitución Política de Colombia de 1991. A la ciudad la gobierna un alcalde (poder ejecutivo) y un Concejo Municipal (poder legislativo).

El alcalde de Medellín es el jefe de gobierno y de la administración municipal, representando legal, judicial y extrajudicialmente al municipio. Es un cargo elegido por voto popular para un periodo de cuatro años. Entre sus funciones principales está la administración de los recursos propios de la municipalidad, velar por el bienestar y los intereses de sus conciudadanos y representarlos ante el Gobierno Nacional, además de impulsar políticas locales para mejorar su calidad de vida, tales como programas de salud, vivienda, educación e infraestructura vial y mantener el orden público.

El Concejo de Medellín es una Corporación Administrativa de elección popular, compuesta por 21 ediles de diferentes tendencias políticas, elegidos democráticamente para un período de cuatro años, y cuyo funcionamiento tiene como eje rector la participación democrática de la comunidad. El concejo es la entidad legislativa de la ciudad, emitiendo acuerdos de obligatorio cumplimiento en su jurisdicción territorial. Entre sus funciones está aprobar los proyectos de los alcaldes, elegir personero y contralor municipal y posesionarlos, dictar las normas orgánicas del presupuesto y expedir anualmente el presupuesto de rentas y gastos.

Administrativamente la Alcaldía de Medellín se divide en dos grandes grupos: La administración central y las entidades descentralizadas. Se entiende por Administración Central, el conjunto de entidades que dependen directamente del Alcalde. Estas entidades son denominadas Secretarías o Departamentos Administrativos. Las secretarías son unidades administrativas cuyo principal objetivo es la prestación de servicios a la Comunidad o a la Administración Central. Los Departamentos Administrativos son unidades de carácter técnico. Para lo cual, la Alcaldía cuenta con el Departamento Administrativo de Planeación, quince secretarías y 23 entidades descentralizadas.

Los sectores urbanos de la ciudad se dividen en 6 "zonas", y estas a su vez se dividen en "comunas", sumando un total de 16. Las zonas en realidad carecen de valor territorial, y solo son utilizadas para agrupar a las comunas según su ubicación dentro de la ciudad. Las comunas se dividen en "barrios" y en áreas institucionales. La ciudad tiene 249 barrios oficiales y 20 áreas institucionales. Las áreas institucionales son grandes sectores con algunas características de barrio, pero su población no es permanente y carece de viviendas, ejemplo los campus universitarios. La zona rural se divide en 5 corregimientos, estos a su vez se dividen en veredas. Los corregimientos "San Antonio de Prado" y "San Cristóbal", son los corregimientos más poblados de Colombia, con más de treinta mil habitantes cada uno. Como se ve en el diagrama, Medellín está estructurada siguiendo el caudal del río que lo cruza, el río Medellín, el cual la recorre de sur a norte.

Cada comuna y corregimiento cuenta con una Junta Administradora Local —JAL—, integrada por no menos de cinco ni más de nueve miembros, elegidos por votación popular para un período de cuatro años que deberán coincidir con el período del Concejo Municipal. Una JAL cumple funciones concernientes con los planes y programas municipales de desarrollo económico y social de obras públicas, vigilancia y control a la prestación de los servicios municipales en su comuna o corregimiento y las inversiones que se realicen con los recursos públicos, además de lo concerniente a la distribución de las partidas globales que les asigne el presupuesto municipal y, en general, velar por el cumplimiento de sus decisiones, recomendar la adopción de determinadas medidas por las autoridades municipales, y promover la participación ciudadana. En Medellín existe una zonificación por estratos en toda la ciudad. Las 16 comunas de Medellín, en su respectivo orden, son:


Los 5 corregimientos de Medellín, sin orden establecido, son:


El área metropolitana del Valle de Aburrá es una entidad político-administrativa que se asienta a todo lo largo del Valle de Aburrá a una altitud promedio de 1.538 msnm. El Área está compuesta por los 10 municipios que se asientan en el valle. Envigado ingresó al área metropolitana luego de haberse realizado una consulta popular el día 10 de julio del año 2016.

Fue la primera área metropolitana creada en Colombia en 1980, y es la segunda área en población en el país después del Distrito Capital de Bogotá. La población total, que suma la población urbana y rural de los diez municipios es de
3 821 797 habitantes. La principal zona urbana del área metropolitana se encuentra en el centro del valle y está conformada por las cuatro ciudades más grandes por número de habitantes, Medellín, Bello, Itagüí y Envigado.

El Hospital Universitario San Vicente de Paúl, el Hospital Pablo Tobón Uribe y la Clínica Cardiovascular Santa María son pioneras en trasplantes de órganos, méritos que han tenido reconocimiento nacional e internacional. En Medellín se han marcado hitos en la historia de la medicina en Colombia como la creación del primer laboratorio de válvulas y banco de tejidos, los primeros trasplantes de corazón, pulmón, médula ósea, riñón, células madres e intestino. Se realizó el primer trasplante de hígado de Latinoamérica y a nivel mundial, el primero de tráquea y de esófago. 

Así mismo, la ciudad ha ganado reconocimiento como destino en el turismo médico, por lo cual ha hecho que la salud se comporte como un sector industrial, buscando oportunidades de crecimiento en utilidades; lo que implica tener en cuenta las exportaciones de servicios médicos como estrategia para aumentar su número de clientes y para obtener mayores márgenes operativos. El distrito ofrece a los pacientes ventajas frente a otros países con desarrollos similares: en cuanto costo-utilidad del tratamiento, tiempos de espera del mismo y hoteles de primera categoría. De esta forma se consolida cada vez más el turismo médico; en los últimos cinco años, más de 4000 extranjeros han visitado a Medellín en busca de alivio.
En cuanto a infraestructura, la ciudad cuenta con 12 hospitales, 43 clínicas, 39 centros de salud y 5 puestos de salud. Además del servicio privado de salud, el servicio público de salud está a cargo de dos instituciones locales, la "Secretaría de Salud" y "Metrosalud". En cada zona y comuna de la ciudad existe un centro médico oficial. No obstante, la demanda de servicios de urgencias en los hospitales públicos casi copa la oferta, por lo cual, si se presentase alguna calamidad masiva, habría que acudir a los servicios privados, situación que está por debajo de los estándares internacionales, que recomiendan mantener un 20% de extra-oferta de camas de urgencias sobre el funcionamiento normal del sistema hospitalario público para atender posibles casos de calamidades masivas. Algunos de los principales centros hospitalarios de la ciudad son: Hospital Universitario San Vicente de Paúl, Hospital Pablo Tobón Uribe, Hospital General de Medellín, Clínica Cardiovascular Santa María, Clínica Las Américas, Clínica El Rosario, Clínica Universitaria Bolivariana, Clínica Medellín, Clínica León XIII, Clínica Las Vegas, Clínica Soma, Fundación Instituto Neurológico de Colombia entre varios más.

La red de escuelas y colegios públicos de educación básica y bachillerato depende de la Secretaría de Educación. El 78% de los alumnos estudian en escuelas y colegios públicos, mientras el 22% lo realizan en el sector privado.
Entre las instituciones de educación pública más destacadas en los exámenes de Estado (ICFES) se encuentran el Instituto Técnico Industrial Pascual Bravo, Institución Educativa INEM José Félix De Restrepo, Institución Educativa Santo Ángel, Institución Educativa San Juan Bosco, Institución Educativa Centro Formativo de Antioquia "CEFA", Colegio la Salle de Campoamor, Liceo Municipal Concejo de Medellín, Institución Educativa Cristo Rey y la Institución Educativa Ana de Castrillón, entre otros. Hay numerosos centros educativos privados con nivel certificado como el Colegio San José de La Salle, la Comunidad Colegio Jesús María, el Colegio de la Compañía de María La Enseñanza, el Colegio Salesiano el Sufragio, el Colegio Parroquial Emaús, Colegio San Ignacio de Loyola, Colegio Gimnasio los Pinares, Instituto Musical Diego Echavarría, Colegio Fontán, Colegio Calasanz, Colegio de la Presentación, Instituto San Carlos de Lasalle, Colegio San José de las Vegas, Colegio Padre Manyanet, Colegio Corazonista, Colegio Sagrada Familia Aldea Pablo VI, Colegio de la UPB, el Colegio Liceo Salazar y Herrera y el Instituto Educativo Salesiano Pedro Justo Berrío. Muchas de estos centros educativos cuentan con la titulación de Bachiller-Técnico.

Medellín tiene 130.000 estudiantes en alrededor de 35 instituciones de educación superior, entre públicas y privadas.

Algunas de las universidades más destacadas son:

"Véase también: "

En Antioquia existen 511 grupos de investigación registrados, 95% de los cuales se encuentran en Medellín, que se ubica como la segunda ciudad de Colombia más representativa en materia de investigación y desarrollo en cuanto se refiere a la cantidad de trabajos producidos.

Durante las décadas de 1980 y 1990, Medellín fue notoria debido a las altas tasas de violencia que registraba, al igual que por el alto índice de homicidios. En 2002, la tasa de muertes violentas por cada 100 000 habitantes fue de 229; pero, gracias a los programas sociales y culturales en contra de la violencia, en 2005 esta cifra fue de 66,1 por cada 100 000 habitantes, una de las cifras más bajas de los últimos años. También para 2002, la tasa de homicidios era muy alta: 183,3 por cada 100 000 habitantes; este dato también se redujo notoriamente pues pasó a 33,2 por cada 100 000 habitantes en 2005. En el año 2010, la guerra entre pandillas aumentó de nuevo la tasa de homicidios, llevándola hasta 87,2 por cada 100 000 habitantes; en el transcurso de ese año se presentaron serios problemas de orden público que motivaron al el gobierno nacional a intervenir en varias ocasiones por medio de consejos de seguridad y aumento en la fuerza pública; esta situación fue originada por bandas delincuenciales que se disputan el control de los centros de expendio de drogas.

Los datos presentados por el gobierno Municipal contrastan con los estudios internacionales. Según el ranking de Seguridad, Justicia y Paz presentado por el Consejo Ciudadano para la Seguridad Pública y Justicia Penal A.C, la ciudad de Medellín presentó una tasa de 38,06 homicidios por cada cien mil habitantes en el año 2013, colocándose entre las 50 ciudades más violentas del mundo, según el mismo estudio.

Para el año 2014, se hizo entrega de 150 motos, 160 patrullas y 10 CAI móviles a la policía de la ciudad por un valor de 16.490 millones; políticas que incidieron para que la ciudad presentara la tasa de homicidios más baja en 30 años, con 26,7 homicidios por cada 100.000 habitantes (inferior a la media de Colombia). En 2015, según el escalafón anual del Consejo Ciudadano para la Seguridad Pública y la Justicia Penal de México, el número se redujo a 19 homicidios por cada 100.000 habitantes.

Están a cargo de Empresas Públicas de Medellín (EPM), la cual fue creada el 6 de agosto de 1955. El consejo administrativo de Medellín, mediante el acuerdo No. 58, fusionó las cuatro entidades independientes que hasta ese momento prestaban los servicios públicos en la ciudad (energía, acueducto, alcantarillado y teléfonos), en un solo establecimiento autónomo. El 18 de noviembre de 1955 la alcaldía reglamentó la existencia de EPM; una semana después, el 25 de noviembre, el gobernador sancionó el decreto en que se expedían los estatutos, y a partir de enero de 1956 se inició su vida administrativa.

En 1989 se incluyó el manejo y mejoramiento del medio ambiente como parte de sus estatutos y se cambió el nombre de servicio telefónico por el de telecomunicaciones. Este servicio fue escindido en 2007 para crear la filial UNE. En 1998 EPM fue transformada en Empresa Industrial y Comercial del Estado y por eso hoy se encuentra sometida a las disposiciones de la ley comercial para el ejercicio de sus actividades. Fue elegida como la mejor empresa del siglo XX en Colombia tanto por sus ejecutorias en el campo de los servicios públicos, así como por su sólida proyección nacional e internacional.

La principal puerta de acceso a Medellín para viajeros internacionales y nacionales es el Aeropuerto Internacional José María Córdova, ubicado en jurisdicción del municipio de Rionegro, a 35 kilómetros de la ciudad en dirección oriente. Fue inaugurado en 1985 y posteriormente amplió su muelle nacional con la construcción de 4.200 metros cuadrados nuevos de área. Dentro del perímetro urbano del municipio de Medellín, al suroccidente, está ubicado el Aeropuerto Olaya Herrera, que presta servicios de vuelos nacionales y regionales (departamentales).

Es el primer sistema de transporte masivo que se construyó en Colombia. Inició operaciones el 30 de noviembre de 1995 y desde entonces ha movilizado a más de mil millones de pasajeros. El metro atraviesa el área metropolitana de sur a norte, entre los municipios de Bello y La Estrella; también se extiende desde el centro de la ciudad hacia el oeste. El Metro combina un sistema férreo con un sistema de cable aéreo denominado metrocable (no confundir con el sistema teleférico, aunque son similares), el cual ha sido usado por primera vez en el mundo en Medellín como transporte masivo permanente. El Metro cuenta con varios tipos de niveles (nivel de tierra, viaductos elevados y cables aéreos), y no tiene tramos subterráneos. La Red del Metro posee una longitud de 33 km y comprende 5 líneas: Línea A (férrea) con 19 estaciones, Línea B (férrea) con 7 estaciones, la línea C (férrea) con 11 estaciones, la línea L (cable) que comunica el área metropolitana con el parque natural de Arví desde la estación Santo Domingo Sabio hasta el corregimiento de Santa Elena, la Línea K y la Línea J cuenta cada una con 3 estaciones (estas tres últimas son del sistema cable aéreo). 

Es una línea de tren ligero o tranvía, compuesta por seis paradas y tres estaciones: San Antonio, Miraflores y Oriente. Junto a dos nuevas líneas del Metrocable, H y M, conectan los barrios centro-orientales con el centro de la ciudad. El tranvía va por la calle 49 (Ayacucho), tiene 4.3 kilómetros de largo y su entrada en operación total ocurrió en noviembre de 2015.Entre tanto, también se tiene proyectada la entrada de un "Monorriel", o 'Metro pequeño' que atraviese las comunas 1, 3, 8, 9 y 14 en la zona nororiental de la ciudad.

Es un sistema de buses articulados para transporte masivo. Está integrado físicamente con el Metro de Medellín en las estaciones Hospital, Industriales y Cisneros; además cuenta con una segunda línea pretroncal, Aranjuez-Universidad de Medellín, que atraviesa el centro de la ciudad por la avenida Oriental. Tiene estaciones cada 500 metros y los vehículos están unidos por una articulación que les confiere movilidad, con una capacidad de 160 personas cada uno; vienen equipados con tres puertas de acceso, caja automática y suspensión neumática. Actualmente está en construcción la pretroncal Envigado a Itagüí. Aunque Metroplús está integrado física y tarifariamente con el Metro de Medellín, es en realidad una empresa aparte, que cuenta entre sus accionistas con el mismo Metro de Medellín (25,64 % de partición accionaria).

Medellín cuenta con un sistema de transporte público mediante cables aéreos denominado Metrocable, único en su género en cuanto a que a la fecha (2016), no hay en el mundo otro sistema de cables destinado al transporte permanente de pasajeros. El sistema, ideado completamente en esta ciudad, consta actualmente de varias líneas, tales como la línea J y la línea K, que se complementan y se enlazan con las líneas férreas A y B. Es así que los Metrocables sirven también como fuente alimentadora del Metro. Actualmente varias ciudades de Colombia quieren implementarlo, como Bogotá, Ibagué, Bucaramanga y Pereira, y otras en el mundo, aunque Manizales (denominado Cable Aéreo de Manizales) tiene un sistema similar al de Medellín pero no como complemento de un sistema tipo Metro.

Los actuales y futuros proyectos y sus inversiones tienen y tendrán un importante carácter social y de beneficio común, ya que están dirigidos al mejoramiento de las condiciones de vida de las poblaciones de menores ingresos, usuarias de los sistemas de transporte público.

La Línea K se ejecutó con recursos propios de la Alcaldía de Medellín (55%) y de la empresa Metro de Medellín Ltda. (45%), bajo la premisa de aportar al desarrollo social de los habitantes de una de las zonas más deprimidas de la ciudad.
La Línea J se construyó con aportes de la Alcaldía de Medellín (73%) y de la empresa Metro de Medellín Ltda. (27%).

Existe en la ciudad un sistema privado de buses urbanos que atiende todos los distritos o zonas de la urbe, el cual se está estructurando en 2007 en el llamado SIT, Sistema Integrado de Transporte, un proyecto ya en marcha que integrará el servicio de buses urbanos con el Metro y el nuevo sistema Metroplús.
De igual manera, hay numerosas empresas de taxis que cubren toda el área metropolitana, y entre ellas hay algunas con servicios bilingües en inglés-español. El servicio de pedido de taxi por teléfono es el más usual y seguro. Algunas empresas prestan servicios intermunicipales. Es usual además el servicio de taxi colectivo; algunos de estos colectivos pueden ser cómodos y rápidos, aunque suelen estar supeditados al cupo completo. El uso del GPS se implementó en todos los taxis de la ciudad el 31 de marzo de 2012.

En Medellín hay dos terminales de transporte intermunicipal: Terminal de Transporte Intermunicipal del Norte y Terminal de Transporte Intermunicipal del Sur. Las terminales de transporte son además centros comerciales con servicios bancarios, de comercio y de telecomunicaciones. Debido a sus proyectos en transporte sostenible, la ciudad obtuvo, junto con San Francisco (California), el premio Transporte Sostenible 2012, otorgado por el Instituto de Políticas de Transporte y Deasarrollo.

Medellín es el segundo centro económico más importante de Colombia, después de Bogotá. La ciudad representa más del 8% del PIB Nacional y en conjunto con el Valle de Aburrá aporta cerca del 11% del mismo, siendo una de las regiones más productivas del país, pero es a la vez la más desigual de Colombia, con un preocupante coeficiente de Gini de 0.54, el cual indica su agudo índice de pobreza situado en el 22%. Lo que explicaría que el contrabando, primero, y luego el narcotráfico, surjan como medios de subsistencia para miles de personas que no encuentran posibilidades de vivir mediante actividades económicas lícitas.

Tiene el segundo PIB per cápita para el 2005, (con PPA) de US$ 5.547,8, detrás de Bogotá, y una densidad empresarial de 25 empresas por cada 1.000 habitantes, lo que la posiciona igualmente como la segunda más alta de Colombia La industria representa el 43,6% del producto interno bruto del Valle de Aburrá, los servicios el 39,7% y el comercio el 7%. Los sectores industriales con mayor participación en el valor agregado generado en el Área Metropolitana son las empresas textiles, con 20%; sustancias y productos químicos, con el 14,5% alimentos, con el 10% y bebidas con el 11%. El 10% restante comprende sectores como el metalmecánico, eléctrico y electrónico, entre otros. La Industria textil y de confecciones es hoy una de las grandes exportadoras de productos hacia los mercados internacionales; el desarrollo en estos sectores ha convertido a la ciudad en un centro de la moda latinoamericana. En las últimas tres décadas se ha venido registrando una diversificación de la estructura económica de la ciudad, con el desarrollo de otros subsectores, como el de bienes intermedios y bienes de capital.

En el sector del turismo, Medellín ha avanzado hasta convertirse en el tercer destino turístico para los visitantes extranjeros que visitan Colombia. Entre 2005 y 2006, el número de extranjeros que tuvo como destino final Medellín creció un 33,4 por ciento, al pasar de 71.213 a 95.026 visitantes. A julio de 2007, ese número fue de 62.003, lo que representa un incremento de 20,7 por ciento en relación con lo registrado en igual periodo de 2006. Estos avances son principalmente generados por el turismo de negocios, ferias y convenciones, y por el turismo médico, gracias al excelente nivel de la medicina con que cuenta la ciudad, en particular en el ámbito de los trasplantes de órganos. La ciudad hace parte del sistema integral económico del departamento de Antioquia, el cual aporta el 15% del PIB nacional.

En la actualidad, Medellín es la principal ciudad exportadora de Colombia en tejido plano y punto, con un 53% del total de las exportaciones en prendas terminadas a países como Estados Unidos, Venezuela, Ecuador, México, Costa Rica y la Comunidad Europea. La industria textil genera para la ciudad un 30% del total del empleo, lo que equivale a 45.000 empleos directos y 135.000 indirectos.

Medellín es cuna de la industria musical de Colombia, ya que allí están ubicadas las sedes de las dos únicas compañías discográficas nacionales sobrevivientes al flagelo de la piratería y la descarga ilegal de música por internet: Discos Fuentes y Codiscos, cada una con estudios de grabación para los cantantes consolidados en el ámbito nacional e internacional, o bien para los nuevos intérpretes que busquen abrirse paso en el competido mercado musical.

Con el crecimiento de la economía y de las exportaciones, varios retos surgieron para la industria de Antioquia y Medellín: diversificar la base exportadora, desarrollar un recurso humano avanzado, mejorar las condiciones internas para inversión extranjera . Antioquia fue el departamento más exportador de Colombia en 2007, por lo cual se incluyeron cerca de 500 nuevas posiciones arancelarias en el portafolio exportador y se pasó de 990 a 1.750 empresas exportadoras en el último quinquenio . Una buena proporción de estas empresas pertenece a la primera Comunidad Cluster de Colombia, creada con el apoyo de la Cámara de Comercio de Medellín para Antioquia y la Alcaldía de Medellín, y a la que pertenecen cerca de 21.000 empresas con una participación del 40 por ciento de las exportaciones totales, el 25 por ciento del PIB regional y el 40 por ciento del empleo del Área Metropolitana.

Los clusters son entendidos como una concentración geográfica de empresas e instituciones que interactúan entre sí y que al hacerlo crean un clima de negocios para mejorar su desempeño, competitividad y rentabilidad. Los clusters que ya están constituidos son Energía eléctrica, Textil/Confección, Diseño y Moda, Construcción, Turismo de Negocios, Ferias y Convenciones.
Beneficios: los clusters ayudan a regionalizar la política industrial, son un fuerte protector frente a las tendencias de globalización, enfocan mejor las necesidades de los clientes, y son fuentes de innovación.

Según los datos publicados por la Misión para el Empalme de las Series de Empleo, Pobreza y Desigualdad -MESEP- de noviembre de 2009, en Medellín y su área metropolitana el índice de pobreza en el periodo 2002-2008 se redujo en un 22,5%, pasando de 49,7% al 38,5%. Igualmente, el índice de indigencia disminuyó en un 25,2% pasando del 12,3% al 9,2%. Estos resultados están en sintonía con la mayor cobertura de servicios básicos como la salud, la educación y los servicios públicos en la ciudad. Sin embargo, la pobreza y la indigencia en Medellín y su área metropolitana continúa estando por encima del promedio de las 13 principales áreas metropolitanas de Colombia. En 2008 dicho promedio fue del 30,7% para la pobreza y del 5,5% para la indigencia.

Por otro lado, la tasa de desempleo en Medellín ha presentado una tendencia decreciente. En el año 2000 el desempleo en la ciudad estaba situado en el 17,7%, y según datos del DANE, en Medellín y su área metropolitana el desempleo en el trimestre junio-agosto de 2010 fue del 14,3%, aunque todavía ubicándose por encima de la media nacional, que para agosto de 2010 era del 11,2%. El DANE situó en sus resultados de 2012 a Medellín como la ciudad más desigual de Colombia, al revelar que su coeficiente de Gini es de 0.54 por factores como el índice de pobreza, en relación con el total de la población, situado en el 22%.

Entre los principales destinos se destacan el Museo de Antioquia, la Plaza de Botero, el Pueblito Paisa, el Centro Internacional de Convenciones y Exposiciones Plaza Mayor, el Pasaje Peatonal Carabobo, el Parque de los Pies Descalzos, la Catedral Metropolitana, la Basílica Nuestra Señora de la Candelaria, el Teatro Pablo Tobón Uribe, el Teatro Metropolitano, el Centro Comercial Oviedo, el Parque Explora y el Jardín Botánico. Con respecto a sitios naturales, los más concurridos son el Cerro El Volador y el Cerro Nutibara. Un nuevo espacio natural inaugurado hace pocos años es el Parque Regional Arví, el cual cuenta con un área cercana a las 20.000 hectáreas, comprende prácticamente todo el territorio del corregimiento de Santa Elena y se extiende entre los municipios de Bello, Copacabana, Guarne y Envigado. Por su parte, en diciembre, la ciudad se cubre de miles de bombillas de colores, creando el famoso alumbrado navideño, considerado por la National Geographic como uno de los diez más bellos del mundo, y que puede apreciarse principalmente en la avenida la Playa y el río Medellín.
En la ciudad existen diferentes sectores donde se concentra oferta hotelera. Los hoteles del Poblado están en capacidad de alojar 8.200 personas. En la zona de Laureles–Estadio existen 73 hoteles con capacidad de alojamiento para 2.100 personas y en el centro de la ciudad, 34 hoteles que tienen a su disposición 1.400 camas.

Medellín ofrece a todos sus visitantes diferentes opciones de alojamiento en fincas tradicionales, casas campestres, Hoteles Boutique y Hoteles de ciudad.

En los últimos años la ciudad ha vivido un proceso de transformación urbanística que le ha conferido reconocimientos nacionales e internacionales. Dicha transformación se basa en el "urbanismo social", una política pública consistente en otorgarle prioridad a los pobladores y territorios más pobres, así como a las víctimas de la violencia, mediante obras y programas que buscan reparar el herido tejido físico y social. Un ejemplo reciente de estas políticas es la puesta en marcha de unas novedosas escaleras eléctricas en un barrio de la comuna 13, zona que se caracteriza no solo por los problemas mencionados anteriormente sino también por su ubicación en las laderas de montaña, lo que hace un tanto difícil la comunicación y la calidad de vida de esa parte de la población.

El Concejo municipal de la ciudad expidió en 1890 un acuerdo mediante el cual se ordenaba trazar el plano para el ensanchamiento futuro de la ciudad, en el cual se reglamentaban además aspectos como la construcción de edificios, la apertura y pavimentación de vías, el acueducto, el alcantarillado, y hasta la forma de las ventanas para que éstas no obstruyeran el paso de los transeúntes. En una reforma posterior se contempló la rectificación y canalización del río Medellín, que recorría en forma sinuosa todo el Valle de Aburrá, con el fin de ganar terreno para la construcción y el crecimiento de la ciudad. Dicho plano, llamado Medellín Futuro, solo pudo cumplirse parcialmente, pero sirvió para guiar el avance de la ciudad en la primera mitad del siglo. Algunas fechas cronológicas importantes en esta etapa fueron las siguientes: en el año de 1900 la quebrada Santa Elena se consolida como el centro de la ciudad y se comienza a trazar como Paseo Urbano. En 1905 se inaugura un tranvía tirado por mulas; en 1914 llega el Ferrocarril de Antioquia a la ciudad; en 1920 se inician los trazados de las vías. En 1925 comienzan a funcionar los tranvías eléctricos; en 1928 tiene lugar la cobertura de la quebrada Santa Elena; en 1931 se construye el aeropuerto Olaya Herrera; en 1940 comienzan las obras de canalización y rectificación del río Medellín; en 1941 el arquitecto Pedro Nel Gómez es el encargado de diseñar urbanísticamente el sector de Laureles. Y en 1945 se construye el hotel Nutibara.<ref name="Medellín futuro/Plan piloto"></ref>

Una vez se llevaron a cabo las obras en el río, y debido a la expansión urbana hacia el occidente (la Otrabanda), a finales de la década del cuarenta se vio la necesidad de trazar un nuevo plano para organizar la ciudad. Fue así como los urbanistas Paul L. Wiener y José L. Sert se encargaron de proyectar entre 1948 y 1950 el Plan Piloto, que sugería, entre otras cosas, la construcción de diversas avenidas y el diseño de un nuevo centro de gobierno. Debido a esto, obras tan representativas en Medellín como la avenida Oriental, construida en los años setenta, y el Centro Administrativo La Alpujarra, en los ochenta, si bien no estuvieron directamente contempladas en el Plan de Wiener y Sert, sí se puede considerar que estuvieron basadas en éste.

Entre los años 1950 y 1980 se agudiza el fenómeno de invasión territorial dificultando el cumplimiento de los planes que trataban de ordenar el crecimiento de la ciudad. El Plan Piloto se vio desbordado por la realidad de una población que se triplicó en 20 años, pasando de 358.189 habitantes, en 1951, a 1.071.252, en 1973. La construcción tuvo gran dinamismo en ese periodo y buena parte de las laderas de la ciudad empezaron a ser ocupadas por los habitantes que, llegados del campo, no tenían la posibilidad de acceder a créditos para vivienda. Muchas de las edificaciones antiguas del centro, y aún las de principios del siglo XX, fueron demolidas para dar paso a edificios altos que fueron destinados a oficinas y vivienda. El sector textil se modernizó en este periodo y se consolidó de forma definitiva la vocación industrial de la ciudad. Algunas fechas importantes durante este periodo fueron las siguientes: en 1962 se empieza a construir la Unidad Deportiva Atanasio Girardot en los alrededores del estadio; desde finales de los años 1960 hasta principios de los setenta se construye el edificio Coltejer, un complejo de edificaciones que aún hoy es el símbolo urbano más representativo de Medellín. En 1980 se construye el plan vial del río; en 1987 se inaugura La Alpujarra. A partir de 1995 comienza a funcionar el Metro, una obra que desde el punto de vista urbanístico ha tenido detractores debido a su paso elevado por el centro de la ciudad.

En 2013, Medellín ganó el Premio Verde Verónica Rudge en diseño urbano, otorgado por la Universidad de Harvard, debido al proyecto Urbano Integral PUI de la zona Nororiental, diseñada y ejecutada por la Empresa de Desarrollo Urbano.Medellín conserva muy poca memoria urbanística colonial y del siglo XIX. Aunque el Valle de Aburrá fue una zona activa en agricultura y ganadería a lo largo del periodo colonial, su relativa riqueza no se expresó en una arquitectura civil y religiosa sobresaliente como en Cartagena, Tunja, Popayán o Bogotá. Esto puede explicarse por el hecho de que la Villa de Medellín no fue un centro político-administrativo y sí un lugar aislado geográficamente cuya élite invirtió poco en el desarrollo de una arquitectura monumental. De los finales de la colonia quedan, pero con muchas transformaciones, la Iglesia de la Candelaria y la Iglesia de la Veracruz.

Se denomina "republicana" a la arquitectura producida en Colombia entre 1850 y 1930. El uso del ladrillo y la aplicación de estilos históricos europeos fueron la principal novedad. El alemán Enrique Haeusler fue el autor del puente de Guayaquil (1879). Pero fue el arquitecto francés Carlos Carré la principal figura de la arquitectura republicana del siglo XIX en Medellín; Carré llegó a la ciudad en 1889, habiendo sido contratado para diseñar y edificar la nueva catedral episcopal y varios edificios comerciales y residenciales que se tenían proyectados para diferentes lugares de la ciudad, sobre todo en el nuevo barrio de Guayaquil. La Catedral Metropolitana fue terminada en 1931; igualmente son de su autoría los edificios Vásquez y Carré, que se encuentran ubicados junto a la Plaza de Cisneros. La Estación Medellín del Ferrocarril de Antioquia fue obra de Enrique Olarte, una obra que permitió la consolidación urbana definitiva del sector de Guayaquil.
En los años veinte la arquitectura republicana llegó a su fase culminante. De este periodo sobresalen el antiguo Palacio Municipal (hoy Museo de Antioquia) en 1928, y los edificios del Palacio Nacional y el Palacio de Gobierno Departamental (hoy Palacio de la Cultura) entre 1925 y 1928. Estas dos últimas obras fueron diseñadas por el belga Agustín Goovaerts, ambas inspiradas en la corriente modernista belga, en las cuales aplicó los estilos románico y neogótico respectivamente. Otras obras de Goovaerts fueron la Iglesia del Sagrado Corazón (sector de Guayaquil), y la Iglesia de San Ignacio, entre otras.
De los años 1930 se destacan algunas construcciones del barrio Prado como la casa egipcia y el actual Teatro Prado.

La expansión económica del Estado, la industria, la banca y la población enmarcaron la aparición de los rascacielos. Al ubicarse en el centro histórico-cívico de la ciudad, la construcción de rascacielos para oficinas, comercio y vivienda trajo consigo la destrucción de una buena parte del ya escaso patrimonio urbanístico antiguo de Medellín. Vivir en grandes edificios en el centro fue por entonces un signo análogo de prestigio y estatus social. Los edificios Furatena (1966) con sus treinta pisos y Coltabaco (1967), este último ubicado en el Parque de Berrío, inauguraron esta tendencia. Luego vendría la ya mencionada torre Coltejer (1968-1972), la cual sigue siendo el edificio más alto de la ciudad; fue diseñada por los mismos proyectistas del edificio Avianca en Bogotá y construida en el lote que dejó libre la demolición del Teatro Junín. De 1974 a 1978 tuvo lugar la construcción de la Torre del Café, la segunda más alta. De esta época se destacan edificios de mediana altura como el de Camacol (1972-1974) cerca del puente de Colombia, y el del Banco de la República (1969-1974) en el Parque de Berrío.

El primer edificio inteligente del país se inauguró en 1997. Se trata del edificio de EPM, cuyo diseño se constituyó en una innovación arquitectónica al proyectar luces de 36 metros de altura y disponer de mayor amplitud en sus áreas de oficinas. Una de sus ventajas es la flexibilidad de su interior ya que permite ajustarse cuando se requiera, sin necesidad de romper paredes o destrozar los pisos.

El cambio de siglo trajo consigo una nueva arquitectura expresada en obras de gran impacto urbanístico entre las que se destacan la plaza de Cisneros (2002-2006), el Parque de Los Deseos (2003), el Centro Internacional de Convenciones y Exposiciones Plaza Mayor (2003-2005), la Biblioteca de las Empresas Públicas de Medellín (2004), el Orquideorama del Jardín Botánico (2005-2006), los Parques Biblioteca (2005-2012), el Parque Explora (2005-2008) y la Plaza de La Libertad (2009-2011).

Entre los principales parques de la ciudad sobresalen: el Parque de Berrío, localizado en el corazón de la ciudad; el Parque de Bolívar, ubicado un poco más hacia el norte y enmarcado por la Catedral Metropolitana; otros están situados en zonas más residenciales como el Parque de Belén, el Parque del Poblado o los Parques de Laureles. Los parques modernos son más interactivos y han tenido gran acogida por parte de los habitantes ya que algunos de ellos no solo son lugares de esparcimiento sino que también permiten el aprendizaje por medio del conocimiento; entre ellos se destacan el Parque de los Pies Descalzos, el Parque de Los Deseos, el Parque Explora y el Parque Bicentenario, este último recientemente inaugurado con motivo del Bicentenario de Colombia.

De igual manera se pueden encontrar parques recreativos que ya llevan algún tiempo abiertos al público y se han convertido en referentes para la ciudad; entre estos parques se destacan: el Parque Norte, el Parque Juan Pablo II, el Jardín Botánico, el Cerro El Volador, el Cerro Nutibara (en cuya cima se encuentra el pueblito paisa), y el Parque Arví, que aunque es de reciente inauguración, ofrece una temática muy semejante a la de los anteriormente nombrados. El Zoológico Santa Fe fue fundado en 1960 y alberga actualmente cerca de 1.000 animales procedentes de Asia, África y otros lugares de América.




El parque de Berrío, de gran significado histórico, es el centro fundacional de Medellín, por lo cual es el punto de partida de la trama vial y sitio de referencia de la nomenclatura de la ciudad. En el costado sur-oriental del Parque, se cruza la calle 50 (Colombia) con la carrera 50 (Palacé), nombradas así para honrar la Batalla de Palacé, primera contienda por la Independencia de Colombia.

La numeración de las vías es alfanumérica y está compuesta por un número, opcionalmente de un apéndice alfabético de máximo dos literales, y de los apéndices “Sur” para las calles y “Este” para las carreras. Ejemplos de calles: Calle 43, Calle 44A, Calle 56 FE y Calle 5 Sur. Ejemplo de carreras: Carrera 76, Carrera 70B, Carrera 22AA y Carrera 2 Este.

Las vías de la ciudad de Medellín están divididas en:


Las vías también difieren en nomenclatura de acuerdo a su ubicación, ya que estando en la zona urbana de la ciudad, todas se rigen por la misma denominación vial. Pero en los corregimientos, al tener su cabecera urbana por aparte, su nomenclatura era propia, debido a su lejanía de la zona urbana de Medellín. Con el nuevo Plan de Ordenamiento Territorial (POT), la idea es integrarlos a la nomenclatura vial de Medellín y el Área Metropolitana del Valle de Aburrá (excepto los municipios de Bello e Itagüí).





Con esto, el único corregimiento con nomenclatura propia hasta la fecha es el de San Sebastián de Palmitas.

En las veredas de cada corregimiento no se utiliza nomenclatura vial, debido a la escasez de concentración urbana.

Las telecomunicaciones de la ciudad están representadas desde los teléfonos públicos, pasando por redes de telefonía móvil, redes inalámbricas de banda ancha, centros de navegación o cibercafés, entre otras. La principal empresa en este sector es UNE Telecomunicaciones, (bajo su marca UNE), filial de la estatal Empresas Públicas de Medellín (EPM); también están presentes "Claro" (de América Móvil) y "Movistar" (de Telefónica).

En la ciudad funcionan los seis operadores de telefonía móvil de cobertura nacional, de los cuales tres son operadores móviles con red: Claro, Movistar y Tigo; los otros tres son operadores móviles virtuales: Uff Móvil, UNE y ETB, que usan la red de Tigo. En el caso de UNE, actualmente está desplegando su propia red por el país, y ya cubre las áreas metropolitanas de Medellín y Bogotá con su propia red 4G LTE. También funciona en la ciudad la empresa Avantel, ofreciendo el servicio de trunking, el cual se hace por medio de un dispositivo híbrido entre celular y radio.

En la ciudad se sintonizan varios canales de televisión de señal abierta terrestre, los 4 canales locales (Telemedellín, Canal U Televida y Cosmovisión), uno regional (Teleantioquia), y los cinco canales nacionales: los 2 privados Caracol y RCN, y los 3 públicos Canal Uno, Señal Institucional y Señal Colombia. En la ciudad están establecidas en todo el espectro emisoras en AM y FM, tanto de cobertura local como nacional, de las cuales la mayoría son manejadas por Caracol Radio o RCN Radio, aunque hay otras emisoras independientes de gran sintonía, como Todelar y Super. En Medellín y Antioquia circulan dos diarios de cobertura regional, "El Colombiano" y el "El Mundo", e igualmente los de tiraje nacional: "El Tiempo" y "El Espectador"

Uno de los lugares más apetecidos de Medellín es su Zona Rosa, un sector ubicado en El Poblado cuyo punto de referencia es el "Parque Lleras". Este parque es muy concurrido pues alberga, tanto en su perímetro como en sus alrededores, numerosos bares, cafés y restaurantes para todos los públicos. La Zona Rosa abarca también el "Parque del Poblado" y una parte de la célebre calle 10.
El barrio Colombia también cuenta con bares y discotecas muy populares. Igualmente, la avenida Las Palmas se ha consolidado con los años como un sector dedicado a la vida nocturna, en especial los fines de semana. De igual manera en el occidente de la ciudad, en la calle 33, se han asentado numerosos establecimientos. El epicentro de la llamada Zona Fucsia (en contraposición a la Zona Rosa) es el "Parque del Periodista", ubicado en el centro y en donde confluyen numerosas 'tribus urbanas'.

Entre los principales artistas medellinenses figuran "Fernando Botero", "Rodrigo Arenas Betancur" y "Débora Arango". En música se destacan Juanes, J Balvin , Maluma y más atrás en el tiempo "Jaime R. Echavarría".

Los principales centros culturales de la urbe son el "Museo de Antioquia" y la "Plaza Botero". En la ciudad anualmente tiene lugar el Festival Internacional de Poesía, un evento de carácter cultural que se realiza desde 1991; es también destacada la "Orquesta Infantil y Juvenil de Medellín". Además es la ciudad colombiana con mayor cantidad de esculturas en pie, y la gastronomía antioqueña es la más representativa de su región. Adicionalmente, el reggaeton es una tendencia fuerte en la ciudad: existen más de 300 grupos conformados, se hacen más de 200 conciertos por año y existen varias discotecas dedicadas exclusivamente al género.

Medellín y el Área Metropolitana cuentan con una "Red de Bibliotecas", que es un conjunto de bibliotecas comunicadas entre sí que comparten recursos, esfuerzos, conocimientos y experiencias con el fin de mejorar las condiciones educativas y culturales de las comunidades que atienden. La red está conformada por 36 bibliotecas, de las cuales 24 corresponden a Medellín.







Bibliotecas públicas y universitarias no adscritas a la Red de Bibliotecas




También son de destacar las bibliotecas centrales de las universidades privadas Pontificia Bolivariana y EAFIT, las cuales atesoran material bibliográfico sobre una gran variedad de disciplinas.











Otros museos destacados son: Centro Cultural Banco de la República, Museo Entomológico Francisco Luis Gallego, Casa Museo Santa Fe, Museo de Ciencias Naturales, Museo Etnográfico Miguel Ángel Builes, y Museo de la Madre Laura.

Medellín cuenta con más de 17 salas de artes escénicas, en las que se presentan alrededor de 50 grupos, algunos de amplia trayectoria y reconocimiento local y nacional. Están distribuidos en más de una veintena de escuelas.

Algunas de las principales instalaciones teatrales de la ciudad son:






Ejemplo típico del teatro paisa - en este caso del teatro humorístico -, es el grupo El Águila Descalza.

Otras organizaciones e instalaciones teatrales de la ciudad son: Teatro Porfirio Barba Jacob, Teatro El Triángulo, El Firulete, Asociación Pequeño Teatro de Medellín, Teatro de Muñecas La Fanfarria, Teatro Matacandelas, La Casa del Teatro, Café Concierto Los Inquietos, Teatro Manicomio de Muñecos, Corporación Cultural Teatro de Seda, Teatro Barra del Silencio, Manicomio de Vargasvil, Sala Beethoven, Instituto de Bellas Artes, Planetario Jesús Emilio Ramírez.

La gastronomía de la ciudad corresponde a la antioqueña. Entre los platos típicos se destacan la bandeja paisa, plato fuerte representativo de la región, y la arepa paisa, la cual se come usualmente con acompañamientos. El desayuno es común acompañarlo con chocolate, calentao (sobras calentadas del día anterior) y parva, la cual es una componente tradicional de la gastronomía antioqueña, conformada por una amplia variedad de piezas de panadería, entre las que se destacan el pandequeso, el bizcochuelo, el pandero, el buñuelo, el pandebono y el pan.

Los silleteros han sido proclamados como Patrimonio Cultural de Colombia.

Durante la colonia los pasos de cordillera eran casi que infranqueables, por lo que se dificultaba la utilización de voluminosos animales de carga (como bueyes, mulas o caballos) por los tortuosos y estrechos caminos, motivo por el cual muchas veces se hacía necesario transportar los arrumes (y hasta los hijos) en las espaldas de los arrieros, en aparatajes de madera llamados 'silletas', y motivo por el cual quienes los utilizaban eran llamados 'silleteros'. Gracias a ellos fue posible el intercambio de productos y la movilización de viajeros entre lugares muy distantes. Su habilidad consistía en soportar grandes pesos a sus espaldas durante largas jornadas. Algunas crónicas de viaje de finales del siglo XIX describen caravanas de silleteros avanzando por los caminos de montaña.

La silleta y el silletero se adaptaron a los tiempos modernos del departamento y del país; de este modo, en muchas viviendas campesinas la silleta persistió como un instrumento útil para transportar personas desvalidas o enfermas, o para movilizar productos, y para el campesino de Santa Elena en especial, fue un recurso del que se sirvió con ingenio para la tarea de comercializar sus productos en Medellín. La ciudad se familiarizó con el silletero vendedor de flores y hortalizas, que recorría las calles céntricas y los barrios como proveedor por encargo de ciertas familias. Fue común verlos en las plazas de mercado más reconocidas, como la de Cisneros o la de Flores, y en los atrios de las iglesias, hasta que se convirtieron en vistosos personajes incorporados al paisaje cotidiano de la ciudad.

En 1957 se organizó un desfile, y desde ese momento, su figura fue creciendo hasta consolidarse hoy por hoy como uno de los símbolos culturales de Medellín.

La ciudad realiza dos ferias de moda a lo largo del año, siendo la más importante "Colombiamoda", que tiene lugar durante tres días en el mes de julio. Es considerada una de las ferias más importantes del país y de América Latina y cuenta con 24 años de trayectoria. La primera feria que se realizó en Medellín se llevó a cabo en 1987 con el apoyo de empresas textiles tradicionales en la ciudad como Coltejer, Fabricato y Tejicóndor. A pesar de la gran acogida obtenida ese año y en el siguiente, la feria solo tuvo dos versiones. "Inexmoda" tomó las riendas de la moda en Medellín y en 1989 se realiza la primera versión de "Colombiamoda". En años posteriores la feria contó con la presencia de reconocidos diseñadores como Óscar de la Renta, Carolina Herrera, Badgley & Mischka, entre otros.




Otros eventos destacados de la ciudad: Expofinca, Feria del Hogar y la Integración Cooperativa, Feria de la Construcción, Feria Metalmecánica, Feria de la Antioqueñidad, Expocasa, Colombiamoda, Superventas, Feria internacional del Transporte, Café de Colombia, Saludexpo, Expoempresa, Agroferia, Hecho a Mano, entre otras.

El fútbol es uno de los deportes más populares en la ciudad. Atlético Nacional e Independiente Medellín son los dos equipos profesionales de la ciudad que participan en la Categoría Primera A del fútbol colombiano.

Las principales ligas de la ciudad son atletismo, BMX, baloncesto, balonmano, béisbol, ciclismo, esgrima, fútbol, gimnasia, judo, karate, microfútbol, monopatín, motociclismo, natación, patinaje, halterofilia, softbol, taekwondo, tejo, tenis, voleibol, ajedrez, tenis de mesa y voleibol de playa.

Un deporte muy popular en Medellín, y en general en toda Antioquia, es la equitación, por lo tanto se ha incentivado el comercio y producción de aperos y aparejos para esta actividad, como sillas y herraduras para exportación. Durante la Feria de las Flores las cabalgatas de Medellín lograron un Récord Guinness 1996 y 1999.

En 1978, Medellín fue sede de los XIII Juegos Centroamericanos y del Caribe y, entre el 19 y el 30 de marzo de 2010 se desarrollaron los IX Juegos Suramericanos "Medellín 2010", para lo cual se realizó una fuerte inversión en infraestructura deportiva, renovando y construyendo nuevos escenarios.

Además, en el año 2011 con la organización la Copa Mundial de Fútbol Sub-20 de la FIFA de 2011 en Colombia, Medellín fue la sede de 10 partidos mundialistas. Este fue el evento futbolístico más importante del año, contando con 24 países participantes.

Sobre la infraestructura, Medellín cuenta con varios escenarios deportivos ubicados en los diferentes barrios de la ciudad, en los cuales la comunidad puede ingresar a ellas gratuitamente.


La Unidad Deportiva Atanasio Girardot cuenta con los siguientes espacios:





El escudo, la bandera y el himno de la ciudad tienen el reconocimiento de símbolos oficiales del municipio de Medellín según el Decreto 151 del 20 de febrero de 2002, y como emblemas de la ciudad forman parte de la imagen institucional de la administración municipal, por lo cual están presentes en los actos, eventos y medios oficiales en los que deban figurar por su carácter representativo.

El escudo de armas de Medellín es el emblema más antiguo de la ciudad; tiene su origen en la concesión de su uso por el rey Carlos II de España por medio de la Real Cédula dada en Madrid el 31 de marzo de 1678, y cuyo documento dice:

Sin embargo, una descripción más refinada y estructurada en el lenguaje heráldico, aunque no es oficial, sería:

El blasón se ha mantenido con el tiempo desde que fue otorgado, sin más variaciones que las estéticas, pues es de destacar que existen diferentes versiones estilísticas entre la Alcaldía y el Concejo Municipal, además ninguna cumple estéticamente con las normas heráldicas.

El municipio adoptó la bandera de Antioquia, a la cual se le agregó el escudo de la ciudad para diferenciarlas. La bandera está compuesta por dos franjas horizontales de iguales proporciones, la superior blanca y la inferior verde, y en el centro entre ambas franjas se ubica el escudo. El color blanco simboliza pureza, integridad, obediencia, firmeza y elocuencia. El verde representa la esperanza, la abundancia, la libertad y la fe.

Igualmente, Medellín adoptó el himno antioqueño, de acuerdo con el decreto 151 del 20 de febrero de 2002, Artículo 10:

Adicionalmente están en trámite los Convenios con las siguientes ciudades: Río de Janeiro (Brasil), Florencia (Italia), Mendoza (Argentina), Valencia (España), Andalucía (España), Monterrey (México), Guayaquil (Ecuador), Cuenca (Ecuador), Makati (Filipinas), Ekurhuleni (Sudáfrica), Lima (Perú) y Miami (USA).




</doc>
<doc id="17421" url="https://es.wikipedia.org/wiki?curid=17421" title="Sievert">
Sievert

El sievert (símbolo Sv) es una unidad derivada del SI que mide la dosis de radiación absorbida por la materia viva, corregida por los posibles efectos biológicos producidos. 1 Sv es equivalente a un julio por cada kilogramo (J kg). Esta unidad da un valor numérico con el que se pueden cuantificar los efectos no estocásticos o deterministicos por las radiaciones ionizantes.

Se utilizó este nombre en honor al físico sueco Rolf Sievert.

El organismo encargado de las definiciones de todas las unidades de medida utilizadas para las radiaciones ionizantes y la radiactividad es la ICRU (International Commission on Radiation Units and measurements). Sus recomendaciones son adoptadas por el BIPM (Bureau International des Poids et Mesures) con lo que se incorporan al Sistema Internacional de Unidades.

Su diferencia con el gray (unidad de la dosis absorbida) es que el sievert está corregido por el daño biológico que producen las radiaciones, mientras que el gray mide la energía absorbida por un material.

Se cumple la equivalencia 1 Sv = 1 Gy para las radiaciones electromagnéticas (rayos X y gamma) y los electrones, pero para otras radiaciones debe utilizarse un factor corrector: 20 para la radiación alfa, de 1 a 20 para neutrones libres.

Esta unidad es utilizada para medir diferentes magnitudes usadas en protección radiológica, como la dosis equivalente, la dosis colectiva, la dosis ambiental o la dosis efectiva entre otras, cada una de ellas corregida o "ponderada" por distintos factores que reflejan distintos aspectos, como la Eficiencia Biológica Relativa (RBE en inglés).

Síntomas en los humanos a causa de la radiación acumulada durante un mismo día (los efectos se reducen si el mismo número de Sieverts se acumula en un periodo más largo):
Síntomas en humanos por radiación acumulada durante un año, en milisieverts (1 Sv = 1000 mSv = 1000000 μSv):


Unidades.
Sv = sievert;
mSv = milisievert;
μSv= microsievert.

En los viajes espaciales, y debido a que en el espacio existe radiación a causa del viento solar y de los rayos cósmicos, la NASA tiene la norma por la cual en 10 años de servicio, un astronauta no debería recibir mayor radiación que la que incrementaría en un 3% la probabilidad de sufrir a futuro un cáncer mortal.

Usando esta norma, la NASA calcula la cantidad de radiación máxima que un astronauta debería recibir en 10 años de servicio (basados en cálculos aproximados, sin mucha estadística disponible):

Hombres de 25 años: 0,7Sv; Mujeres de 25 años: 0,4Sv<br>
Hombres de 35 años: 0,9Sv; Mujeres de 35 años: 0,6Sv<br>
Hombres de 45 años: 1,5Sv; Mujeres de 45 años: 0,9Sv<br>
Hombres de 55 años: 2,9Sv; Mujeres de 55 años: 1,6Sv

1 Sv = 100 rem

En las aplicaciones que pueden encontrarse comúnmente suelen ser utilizados sus submúltiplos mSv y μSv. A partir de 1 Sv los efectos más importantes son los deterministas, por lo que se utiliza la dosis absorbida (por tanto los gray).



</doc>
<doc id="17425" url="https://es.wikipedia.org/wiki?curid=17425" title="Curio">
Curio

El curio es un elemento sintético de la tabla periódica cuyo símbolo es Cm y su número atómico es 96. Se produce bombardeando plutonio con partículas alfa (iones de helio). Es un actínido. El curio no existe en el ambiente terrestre, pero puede producirse en forma artificial. Sus propiedades químicas se parecen tanto a las de las tierras raras típicas que, si no fuera por su radiactividad, podría confundirse fácilmente con uno de estos elementos. Entre los isótopos conocidos del curio figuran los de número de masa 238 a 250. El isótopo Cm es de particular interés a causa de su uso potencial como una fuente compacta de fuerza termoeléctrica, al utilizarse el calor generado por decaimiento nuclear para generar fuerza eléctrica.

El curio metálico puede producirse por reducción del trifluoruro de curio, con vapor de bario. El metal tiene un lustre plateado, el cual se pierde al contacto con el aire, y una densidad relativa de 13.5. El punto de fusión es de 1340 (+/-) 40 °C (2444 +/- 72 °F). El metal se disuelve con facilidad en ácidos minerales comunes, con formación de ion tripositivo.

Se han preparado varios compuestos sólidos del curio y sus estructuras se han determinado por difracción de rayos X. Estos incluyen CmF, CmF, CmCl, CmBr, CmI, CmO, CmO. En los lantánidos hay análogos isoestructurales de los compuestos de curio.

El curio fue sintetizado por primera vez en la Universidad de California, Berkeley, también por Glenn T. Seaborg, Ralph A. James y Albert Ghiorso en 1944. Se eligió el nombre curio en honor a Marie Curie y su marido Pierre, famosos por descubrir el radio y por otros importantes trabajos sobre radiactividad.


</doc>
<doc id="17434" url="https://es.wikipedia.org/wiki?curid=17434" title="Aisladores de disco">
Aisladores de disco

Los aisladores de disco son un tipo de aislador empleado en líneas eléctricas de transmisión y distribución. Los hay principalmente de vidrio y de cerámica y sus características están normalizadas según el peso o fuerza soportable, nivel de contaminación admisible y diámetro.

Los aisladores en conjunto con los herrajes tienen la misión de soportar al conductor de la línea a las torres o postes que la sostienen, proporcionando al mismo tiempo la aislación eléctrica requerida.

Dado un nivel de tensión aplicado, un cierto nivel de contaminación ambiental (según las categorías definidas en la Norma IEC 60815) y altitud de instalación respecto del nivel del mar, se requiere que los aisladores en su conjunto posean una cierta longitud mínima para asegurar que la línea sea adecuadamente aislada para evitar descargas a tierra a través de la estructura torre o poste. Esta se logra agrupando varios de estos aisladores en lo que se denomina una "cadena de aisladores".



Dada la aparición y continuo mejoramiento de nuevos materiales poliméricos, que poseen ventajas comparativas en cuento a resistencia mecánica frente a golpes y mejor comportamiento ante la contaminación, este tipo de aisladores ha ido progresivamente cayendo en el desuso. En este tipo de aplicaciones, una cadena de aisladores de disco es ahora reemplazada por un único aislador polimérico, lo que además simplifica su instalación o reemplazo.


</doc>
<doc id="17436" url="https://es.wikipedia.org/wiki?curid=17436" title="Idioma oficial">
Idioma oficial

Un idioma o lengua oficial es el establecido como de uso corriente en documentos oficiales, en la Constitución u otros instrumentos legales de una nación y, por extensión, en sus territorios o áreas administrativas directas. Es el idioma de uso oficial en los actos del gobierno o en los actos y servicios de la administración pública, en la justicia y el sector privado. También puede ser, sin que exista obligación legal, la lengua de instrucción y enseñanza oficial en el sistema educacional público e incluso privado.

El idioma oficial está ligado fuertemente a la definición de Estado-nación. Para muchos un Estado se define en términos lingüísticos exclusivos frente a otras comunidades. Esto dio origen a dos fenómenos en el nacionalismo de la última mitad del siglo XIX:

Sin embargo la distinción de idioma oficial puede ser tan fuerte como para obligar a las poblaciones que no lo hablan al interior de un Estado a perder sus derechos o no ser considerados ciudadanos si no se aprende la lengua nacional.

En la actualidad se presentan casi todas las posibilidades lógicas al respecto del reconocimiento de una o más lenguas como oficiales:

Como consecuencia del colonialismo o del neocolonialismo, en algunos países de África, en las Filipinas y Belice, las lenguas oficiales y de la enseñanza (francés o inglés) no son las lenguas nacionales habladas por la mayoría de la población. Se pueden dar algunos casos como resultado del nacionalismo, como en la República de Irlanda donde la lengua oficial (el irlandés) es hablada sólo por una pequeña porción de la población, mientras que la lengua secundaria que goza de un estatus legal inferior, el inglés, es la lengua de la mayoría de la población.

Técnicamente, solo son oficiales las lenguas cuyo uso establece explícitamente una ley. Sin embargo, muchas lenguas son consideradas "de facto" lenguas oficiales, lo cual significa que aunque ninguna regulación jurídica les atribuya un papel especial, son lenguas utilizadas en la comunicación cotidiana. Un ejemplo destacado de esto es el estatus del inglés en los Estados Unidos. En este país, ninguna ley declara que el inglés sea o deba ser la lengua oficial a nivel federal, aunque en la actualidad 30 estados lo reconocen como lengua oficial. El hecho de que en ese país, en todos los niveles, el inglés es "de facto" el único idioma usado en todos los asuntos oficiales, hace que pueda ser considerado como la lengua oficial de los Estados Unidos, aunque técnicamente no esté reconocido como tal.

Las consecuencias prácticas del carácter "oficial" de una lengua varían, y frecuentemente dependen de cuán extendido esté su uso hablado. En algunos casos, solo la lengua oficial es la única que se puede usar ante tribunales de justicia, en el sistema educativo u otros ámbitos, mientras que en otros casos el estatus de oficial simplemente autoriza a que dicha lengua pueda ser usada. Por ejemplo, en Nueva Zelanda, la "Māori Language Act" permite que el maorí sea usado en asuntos legales, aunque la inmensa mayoría de ellos se llevan a cabo en inglés. En otros lugares, como Gales o Irlanda, las leyes establecen que las publicaciones oficiales deben estar tanto en la lengua minoritaria como en la lengua predominante. El reconocimiento oficial, por otra parte, está correlacionado con el que dicha lengua sea ampliamente enseñada en la educación infantil o que su conocimiento tenga carácter obligatorio para ciertos funcionarios del gobierno.

Un punto importante es que lengua oficial no debe confundirse con las lenguas nacionales que frecuentemente gozan de cierto reconocimiento por parte del gobierno.

Un idioma oficial está frecuentemente relacionado con cuestiones políticas, sociales y económicas, implicando tomas de posición acerca de la soberanía, la supremacía cultural y étnica, nacionalismo cultural o los derechos de las minorías étnicas, por lo que es un recurso utilizado para la construcción de los que algunos historiadores llaman "comunidades imaginadas". Por ejemplo, la campaña "English-only movement" para lograr que el inglés sea considerado legalmente como idioma oficial de los Estados Unidos de América, es vista como un intento para marginar a las comunidades de origen extranjero, particularmente la latinoamericana. En el caso de la República de Irlanda, la decisión de hacer oficial al irlandés se correspondía con un amplio programa de revitalización de dicha lengua, conectado con el nacionalismo gaélico.

En la actualidad solo unos 80 idiomas son idiomas generales de uso en un estado, aunque un número importante de lenguas tienen el estatus de cooficiales en algunas áreas o regiones de países. La lista de lenguas que son oficiales en más de un estado es bastante más limitada e incluye solo 21 lenguas:


</doc>
<doc id="17437" url="https://es.wikipedia.org/wiki?curid=17437" title="Amida">
Amida

Una amida es un compuesto orgánico que consiste en una amina unida a un grupo acilo convirtiéndose en una amina ácida (o amida). Por esto su grupo funcional es del tipo RCONR'R<nowiki>"</nowiki>, siendo CO un carbonilo, N un átomo de nitrógeno, y R, R' y R<nowiki>"</nowiki> radicales orgánicos o átomos de hidrógeno:

Se puede considerar como un derivado de un ácido carboxílico por sustitución del grupo —OH del ácido por un grupo —NH, —NHR o —NRR' (llamado grupo amino).
Formalmente también se pueden considerar derivados del amoníaco, de una amina primaria o de una amina secundaria por sustitución de un hidrógeno por un radical ácido, dando lugar a una amida primaria, secundaria o terciaria, respectivamente. Concretamente se pueden sintetizar a partir de un ácido carboxílico y una amina:
Cuando el grupo amida no es el principal, se nombra usando el prefijo carbamoil:

CH-CH-CH(CONH)-CH-CH-COOH → ácido 4-carbamoilhexanoico.

Todas las amidas, excepto la primera de la serie, son sólidas a temperatura ambiente y sus puntos de ebullición son elevados, más altos que los de los ácidos correspondientes. Presentan excelentes propiedades disolventes y son bases muy débiles. Uno de los principales métodos de obtención de estos compuestos consiste en hacer reaccionar el amoníaco (o aminas primarias o secundarias) con ésteres. Las amidas son comunes en la naturaleza, y una de las más conocidas es la urea, una diamida que no contiene hidrocarburos. Las proteínas y los péptidos están formados por amidas. Un ejemplo de poliamida de cadena larga es el nailon. Las amidas también se utilizan mucho en la industria farmacéutica.

Las poliamidas son compuestos que contienen grupos amida. Algunos son sintéticas, como el nailon, pero también se encuentran en la naturaleza, en las proteínas, formadas a partir de los aminoácidos, por reacción de un grupo carboxilo de un aminoácido con un grupo amino de otro. En las proteínas al grupo amida se le llama enlace peptídico.
El nailon es una poliamida debido a los característicos grupos amida en la cadena principal de su formulación. Por ejemplo, el nailon 6 se obtiene por polimerización de la ε-caprolactama.

Ciertas poliamidas del tipo nailon son la poliamida-6, la poliamida-11, la poliamida-12, la poliamida-9,6, la poliamida-6,9, la poliamida-6,10 y la poliamida-6,12. Se pueden citar como ejemplo de poliamidas no lineales los productos de condensación de ácidos dimerizados de aceites vegetales con aminas.

Las proteínas, como la seda, a la que el nailon reemplazó, también son poliamidas. Estos grupos amida son muy polares y pueden unirse entre sí mediante enlaces por puente de hidrógeno. Debido a esto y a que la cadena del nailon es tan regular y simétrica, los nailones son a menudo cristalinos, y forman excelentes fibras.

Las principales reacciones de las amidas son:


Las amidas son comunes en la naturaleza y se encuentran en sustancias como los aminoácidos, las proteínas, el ADN y el ARN, hormonas y vitaminas.

La urea es utilizada para la excreción del amoníaco (NH) en el ser humano y mamíferos. También es muy utilizada en la industria farmacéutica y en la industria del nailon.


</doc>
<doc id="17443" url="https://es.wikipedia.org/wiki?curid=17443" title="Política internacional">
Política internacional

La política internacional es la relación sociocultural.
Para cada Estado, sus principales prioridades en política exterior están al mismo nivel en los Estados geográficamente colindantes, en las relaciones con aquellos países que tienen voto en las Naciones Unidas, en los organismos internacionales con sede principalmente en Nueva York y Ginebra y con aquellos países con los que mantiene relaciones económicas privilegiadas.

La política exterior moderna debe obedecer a criterios de Estado; a una percepción de la síntesis histórica de la ubicación de un país en el mundo, a una lectura adecuada de los desafíos de la globalización y de su impacto en la vida de cada uno de los individuos de una nación.

La política externa es, también, una variable de la política interna. Los procesos internacionales, políticos, estratégicos, comerciales, financieros, sociales, demográficos, científico-tecnológicos, culturales y de comunicación, pueden influir negativamente o positivamente en los esfuerzos de un gobierno para consolidar la democracia y el estado de derecho, avanzar en la transformación.

La política internacional interpreta la realidad nacional y la relaciona con las tendencias positivas y eventualmente negativas de la globalización, en función de las relaciones limítrofes, regionales y mundiales. De los resultados de la ecuación entre las demandas del proceso político, económico y social interno, y los límites y posibilidades que ofrece el entorno mundial globalizado, surgen las bases conceptuales, los atributos, los intereses nacionales, los principios, la agenda, las prioridades y el modelo de gestión institucional de la política exterior de un país.

En el estado moderno, las instituciones de gobierno constituyen los instrumentos políticos generalmente aceptados para mantener un marco de orden en la sociedad.

El objetivo de la política exterior es el de generar y preservar un ambiente de paz, distensión, estabilidad y respeto del derecho internacional, en los ámbitos limítrofe, subregional, regional y mundial, con la finalidad de obtener el escenario más idóneo que permita aplicar una diplomacia adecuada a sus intereses. Una diplomacia para el desarrollo económico y social con equidad. 

Se aspira normalmente a un mundo basado en el equilibrio, respetuoso de los principios del derecho internacional, en el que el multilateralismo lejos de debilitarse se fortalezca. Un mundo donde se entienda que la globalización requiere de una gobernabilidad basada en los valores de los derechos humanos.

Una estructura internacional donde haya menos desigualdad entre naciones y al interior de estas. Un mundo que haga del desarrollo sustentable no sólo un programa, sino una realidad en la que el eje de la sostenibilidad sean los seres humanos.

En este contexto, la política exterior se sustenta en algunos principios históricos y en otros que se derivan de la modernidad: 


Esta agenda básica se aplica utilizando todos los instrumentos de la política exterior, bilaterales y multilaterales siendo la política internacional multidimensional. 

En el mundo actual, la globalización ha reducido los espacios y ha ampliado las comunicaciones, por ello la diplomacia directa del jefe de Estado o de gobierno también es un instrumento esencial de las relaciones internacionales contemporáneas. También ordenada civilmente en cada estado retrospectivo.




</doc>
<doc id="17446" url="https://es.wikipedia.org/wiki?curid=17446" title="Láser">
Láser

Un láser (del acrónimo inglés LASER, "light amplification by stimulated emission of radiation"; amplificación de luz por emisión estimulada de radiación) es un dispositivo que utiliza un efecto de la mecánica cuántica, la emisión inducida o estimulada, para generar un haz de luz coherente tanto espacial como temporalmente. La coherencia espacial se corresponde con la capacidad de un haz para permanecer con un pequeño tamaño al transmitirse por el vacío en largas distancias y la coherencia temporal se relaciona con la capacidad para concentrar la emisión en un rango espectral muy estrecho.

En 1915, Albert Einstein estableció los fundamentos para el desarrollo de los láseres y de sus predecesores, los máseres (que emiten microondas), utilizando la ley de radiación de Max Planck basada en los conceptos de emisión espontánea e inducida de radiación.

En 1928, Rudolf Ladenburg informó haber obtenido la primera evidencia del fenómeno de emisión estimulada de radiación, aunque no pasó de ser una curiosidad de laboratorio, por lo que la teoría fue olvidada hasta después de la Segunda Guerra Mundial, cuando fue demostrada definitivamente por Willis Eugene Lamb y R. C. Rutherford.

En 1953, Charles H. Townes y los estudiantes de postgrado James P. Gordon y Herbert J. Zeiger construyeron el primer máser: un dispositivo que funcionaba con los mismos principios físicos que el láser pero que produce un haz coherente de microondas. El máser de Townes era incapaz de funcionar en continuo. Nikolái Básov y Aleksandr Prójorov de la Unión Soviética trabajaron independientemente en el oscilador cuántico y resolvieron el problema de obtener un máser de salida de luz continua, utilizando sistemas con más de dos niveles de energía.

Townes, Básov y Prójorov compartieron el Premio Nobel de Física en 1964 por «los trabajos fundamentales en el campo de la electrónica cuántica», los cuales condujeron a la construcción de osciladores y amplificadores basados en los principios de los máser-láser.

El primer láser fue uno de rubí y funcionó por primera vez el 16 de mayo de 1960. Fue construido por Theodore Maiman. El hecho de que sus resultados se publicaran con algún retraso en "Nature", dio tiempo a la puesta en marcha de otros desarrollos paralelos. Por este motivo, Townes y Arthur Leonard Schawlow también son considerados inventores del láser, el cual patentaron en 1960. Dos años después, Robert Hall inventa el láser generado por semiconductor. En 1969 se encuentra la primera aplicación industrial del láser al ser utilizado en las soldaduras de los elementos de chapa en la fabricación de vehículos y, al año siguiente Gordon Gould patenta otras muchas aplicaciones prácticas para el láser.

El 16 de mayo de 1980, un grupo de físicos de la Universidad de Hull liderados por Geoffrey Pert registran la primera emisión láser en el rango de los rayos X. Pocos meses después se comienza a comercializar el disco compacto, donde un haz láser de baja potencia «lee» los datos codificados en forma de pequeños orificios (puntos y rayas) sobre un disco óptico con una cara reflectante. Posteriormente esa secuencia de datos digitales se transforma en una señal analógica permitiendo la escucha de los archivos musicales. En 1984, la tecnología desarrollada comienza a usarse en el campo del almacenamiento masivo de datos. En 1994, en el Reino Unido, se utiliza por primera vez la tecnología láser en cinemómetros para detectar conductores con exceso de velocidad. Posteriormente se extiende su uso por todo el mundo.

Ya en el siglo XXI, científicos de la Universidad de St. Andrews crean un láser que puede manipular objetos muy pequeños. Al mismo tiempo, científicos japoneses crean objetos del tamaño de un glóbulo rojo utilizando el láser. En 2002, científicos australianos «teletransportan» con éxito un haz de luz láser de un lugar a otro. Dos años después el escáner láser permite al Museo Británico efectuar exhibiciones virtuales. En 2006, científicos de Intel descubren la forma de trabajar con un chip láser hecho con silicio abriendo las puertas para el desarrollo de redes de comunicaciones mucho más rápidas y eficientes.

Un láser típico consta de tres elementos básicos de operación. Una cavidad óptica resonante, en la que la luz puede circular, que consta habitualmente de un par de espejos de los cuales uno es de alta reflectancia (cercana al 100 %) y otro conocido como acoplador, que tiene una reflectancia menor y que permite la salida de la radiación láser de la cavidad.

Dentro de esta cavidad resonante se sitúa un medio activo con ganancia óptica, que puede ser sólido, líquido o gaseoso (habitualmente el gas se encontrará en estado de plasma parcialmente ionizado) que es el encargado de amplificar la luz. Para poder amplificar la luz, este medio activo necesita un cierto aporte de energía, llamada comúnmente bombeo. Este bombeo es generalmente un haz de luz (bombeo óptico) o una corriente eléctrica (bombeo eléctrico).
La cavidad óptica resonante, conocida también como cavidad láser, existe en la gran mayoría de los dispositivos láser y sirve para mantener la luz circulando a través del medio activo el mayor número de veces posible. Generalmente está compuesta de dos espejos dieléctricos que permiten reflectividades controladas que pueden ser muy altas para determinadas longitudes de onda.

El espejo de alta reflectividad refleja cerca del 100 % de la luz que recibe y el espejo acoplador o de salida, un porcentaje ligeramente menor. Estos espejos pueden ser planos o con determinada curvatura, que cambia su régimen de estabilidad.

Según el tipo de láser, estos espejos se pueden construir en soportes de vidrio o cristales independientes o en el caso de algunos láseres de estado sólido pueden construirse directamente en las caras del medio activo, disminuyendo las necesidades de alineación posterior y las pérdidas por reflexión en las caras del medio activo.

Algunos láseres de excímero o la mayoría de los láser de nitrógeno, no utilizan una cavidad propiamente dicha, en lugar de ello un sólo espejo reflector se utiliza para dirigir la luz hacia la apertura de salida. Otros láser como los construidos en microcavidades ópticas emplean fenómenos como la reflexión total interna para confinar la luz sin utilizar espejos.
El medio activo es el medio material donde se produce la amplificación óptica. Puede ser de muy diversos materiales y es el que determina en mayor medida las propiedades de la luz láser, longitud de onda, emisión continua o pulsada, potencia, etc.

El "medio activo" es donde ocurren los procesos de excitación (electrónica o de estados vibracionales) mediante bombeo de energía, emisión espontánea y emisión estimulada de radiación. Para que se dé la condición láser, es necesario que la ganancia óptica del medio activo sea inferior a las pérdidas de la cavidad más las pérdidas del medio.

Dado que la "ganancia óptica" es el factor limitante en la eficiencia del láser, se tiende a buscar medios materiales que la maximicen, minimizando las pérdidas, es por esto que si bien casi cualquier material puede utilizarse como medio activo, sólo algunas decenas de materiales son utilizados eficientemente para producir láseres.

Con mucha diferencia, los láseres más abundantes en el mundo son los de semiconductor. Pero también son muy comunes los láseres de estado sólido y en menos medida los de gas. Otros medios son utilizados principalmente en investigación o en aplicaciones industriales o médicas muy concretas.
Para que el medio activo pueda amplificar la radiación, es necesario excitar sus niveles electrónicos o vibracionales de alguna manera. Comúnmente un haz de luz (bombeo óptico) de una lámpara de descarga u otro láser o una corriente eléctrica (bombeo eléctrico) son empleados para alimentar al medio activo con la energía necesaria.

El "bombeo óptico" se utiliza habitualmente en láseres de estado sólido (cristales y vidrios) y láseres de colorante (líquidos y algunos polímeros) y el bombeo eléctrico es el preferido en láseres de semiconductor y de gas. En algunas raras ocasiones se utilizan otros esquemas de bombeo que le dan su nombre, por ejemplo a los láseres químicos o láseres de bombeo nuclear que utilizan la energía de la fisión nuclear.

Debido a las múltiples pérdidas de energía en todos los procesos involucrados, la potencia de bombeo siempre es mayor a la potencia de emisión láser.
Si bien existen varios mecanismos que producen emisión láser, se describe el ejemplo sencillo de un láser de cuatro niveles con bombeo óptico continuo, como puede ser el láser de neodimio.
En el estado inicial, la mayoría de los electrones se encuentran en el Estado fundamental y son excitados mediante un haz de luz de bombeo que contiene energía en las bandas de absorción del neodimio. Los electrones excitados en varios niveles se desexcitan rápidamente de forma no radiativa hacia un nivel metaestable, que en el caso del neodimio es el F donde permanece un tiempo relativamente largo, decayendo lentamente al nivel fundamental y al nivel I. Si se cumplen ciertas condiciones en el material y la potencia de bombeo, es posible que se produzca la inversión de población, esto es, que existan más átomos excitados en el nivel F que los que están en el nivel inferior I.
Desde el nivel metaestable F pueden desexcitarse espontáneamente algunos electrones que producen una emisión de luz a 1 064 nm. Algunos de éstos se emiten en el ángulo correcto para reflejarse por los espejos de la cavidad un número elevado de veces. Estos fotones que se reflejan con el ángulo correcto pasan varias veces cerca de átomos excitados de neodimio y producen la emisión estimulada de radiación.

Si el medio activo se encuentra en la condición de inversión de población y las pérdidas de la cavidad son inferiores a la ganancia del medio activo, ocurre que al reflejarse en las paredes de la cavidad se produce una amplificación del primer fotón que se emitió espontáneamente. Tras un número determinado de reflexiones, la intensidad dentro de la cavidad es muy elevada, y las pequeñas perdidas del espejo acoplador son la radiación láser que emite el dispositivo.

Según la peligrosidad de los láseres y en función del Límite de Emisión Accesible (LEA) se pueden clasificar los láseres en las siguientes categorías de riesgo:
Cuando se inventaron, en 1960, los láseres se calificaron como «una solución a la espera de un problema». Desde entonces, se han vuelto omnipresentes y actualmente pueden encontrarse en miles de aplicaciones, en campos muy variados, como la electrónica de consumo, la tecnología de la información, la investigación científica, la medicina, la industria y el sector militar.

En muchas aplicaciones, los beneficios de los láseres se deben a sus propiedades físicas, como la coherencia, la monocromaticidad y la capacidad de alcanzar potencias extremadamente altas. A modo de ejemplo, un haz láser muy coherente puede enfocarse por debajo de su límite de difracción que, a longitudes de onda visibles, corresponde solamente a unos pocos nanómetros. Cuando se enfoca un haz de láser potente en un punto, éste recibe una enorme densidad de energía. Esta propiedad permite al láser grabar gigabytes de información en las microscópicas cavidades de un CD, DVD o Blu-ray. También permite a un láser de media o baja potencia alcanzar intensidades muy altas y usarlo para cortar, quemar o incluso sublimar materiales. El rayo láser se emplea en el proceso de fabricación de grabar o marcar metales, plásticos y vidrio.
Atendiendo a la naturaleza de su medio activo, podemos clasificar los dispositivos láser en:
Estos láseres emplean típicamente vidrios, cristales o fibras dopadas como medio activo. Aunque los semiconductores son también de estado sólido, se suelen tomar en una categoría diferente. Algunos láseres de estado sólido son:





</doc>
<doc id="17447" url="https://es.wikipedia.org/wiki?curid=17447" title="Radiación cósmica">
Radiación cósmica

Los rayos cósmicos, también llamados radiación cósmica, son partículas subatómicas procedentes del espacio exterior cuya energía, debido a su gran velocidad, es muy elevada: cercana a la velocidad de la luz. Se descubrieron cuando se comprobó que la conductividad eléctrica de la atmósfera terrestre se debe a ionización causada por radiaciones de alta energía.

En 1911, Victor Franz Hess, físico austríaco, demostró que la ionización atmosférica aumenta proporcionalmente a la altitud. Concluyó que la radiación debía proceder del espacio exterior.

El descubrimiento de que la intensidad de radiación depende de la altitud indica que las partículas integrantes de la radiación están eléctricamente cargadas y que las desvía el campo magnético terrestre.

Ernest Rutherford y sus colaboradores, contraria y anteriormente a las experiencias de Hess, supusieron que la ionización observada por el espectroscopio se debía a la radiactividad terrestre, ya que, medidas realizadas en 1910 en la base y la cúspide de la Torre Eiffel, así lo detectaban.

Robert Andrews Millikan acuñó la expresión "rayos cósmicos" tras sus propias mediciones que concluyeron en que, efectivamente, eran de origen muy lejano, incluso exterior al Sistema Solar.

Tras el descubrimiento de la radiactividad por Henri Becquerel en 1896, se aceptaba que la electricidad atmosférica - ionización del aire - era provocada exclusivamente por la radiación generada a su vez por elementos radiactivos en el suelo y por los gases radiactivos o isótopos de radón que aquellos producen. La posterior medición, durante la década de 1900 a 1910, de la tasa de ionización (ritmo de ionización del aire) respecto a la altitud demostró un descenso que podía explicarse por la absorción de la radiación ionizante por el aire interpuesto.

En 1909, Theodor Wulf desarrolló el primer electrómetro. Éste era un instrumento diseñado para medir la tasa de producción de iones dentro de un contenedor sellado herméticamente. Wulf usó este instrumento para demostrar que los niveles de radiación ionizante en la cúspide de la Torre Eiffel eran mayores que en su base. Sin embargo, su artículo, publicado en "Physikalische Zeitschrift", no encontró amplia aceptación. En 1911, Domenico Pacini observó variaciones simultáneas de la tasa de ionización sobre un lago, sobre el mar y a una profundidad de 3 metros bajo la superficie. Del descenso observado bajo el agua, Pacini concluyó que una parte de la ionización se debe a fuentes distintas de la radiactividad terrestre. 

Más tarde, en 1912, Victor Hess elevó tres electrómetros Wulf de precisión mejorada a una altitud de 5300 metros usando un globo aerostático y encontró que la tasa de ionización se multiplicaba aproximadamente por cuatro en comparación con la que podía medirse a nivel del suelo. Hess también descartó al Sol como la fuente de radiación responsable mediante un nuevo ascenso en globo durante un eclipse de sol casi total. Cuando la Luna estaba bloqueando la mayor parte de la radiación solar visible, Hess todavía pudo medir una tasa de ionización en aumento con la altura, y concluyó: "La mejor explicación al resultado de mis observaciones viene dada por la suposición de que una radiación de un enorme poder de penetración entra en nuestra atmósfera desde arriba". En 1913-1914, Werner Kolhörster confirmó las primeras observaciones de Hess al medir el incremento de la tasa de ionización a 9 km de altitud.

Hess recibió el Premio Nobel de física en 1936, por su descubrimiento.

El vuelo del globo de Hess tuvo lugar el 7 de agosto de 1912. Exactamente 100 años después, el 7 de agosto de 2012, el vehículo Mars Science Laboratory midió los niveles de radiación ionizante por vez primera en otro planeta por medio de su Detector de Medida de Radiación (RAD, por las siglas en inglés de Radiation Assessment Detector).

Aún no está claro el origen de los rayos cósmicos. Se sabe que, en los períodos en que se emiten grandes erupciones solares, el Sol emite rayos cósmicos de baja energía, pero estos fenómenos estelares no son frecuentes. Por lo tanto, no son motivo de explicación del origen de esta radiación. Tampoco lo son las erupciones de otras estrellas semejantes al Sol. Las grandes explosiones de supernovas son, al menos, responsables de la aceleración inicial de gran parte de los rayos cósmicos, ya que los restos de dichas explosiones son potentes fuentes de radio, que implican presencia de electrones de alta energía.

En 2007, un grupo de científicos argentinos del Observatorio Pierre Auger realizó un espectacular descubrimiento que inauguró una nueva rama de la astronomía. Este grupo encontró evidencias de que la mayor parte de las partículas de rayos cósmicos proviene de una constelación cercana: Centaurus. Esta constelación contiene una galaxia de núcleo activo, cuyo núcleo se debe a existencia de un agujero negro (probablemente supermasivo), al caer la materia a la ergosfera del agujero negro y rotar velozmente.

A enormes velocidades, centrífugamente, se fuga parte de esa materia, constituida por protones y neutrones. Al alcanzar la Tierra (u otros planetas con atmósferas suficientemente densas) sólo llegan los protones, los cuales, tras chocar contra las capas superiores atmosféricas, caen en cascadas de rayos cósmicos. El descubrimiento observado en Centaurus parece ser extrapolable a todas las galaxias de núcleos activados por agujeros negros.

También se cree que, como resultado de las ondas de choque procedentes de las supernovas que se propagan hasta el espacio interestelar, en éste se genera aceleración adicional. No existen pruebas directas de que las supernovas contribuyan de manera significativa a los rayos cósmicos. Sin embargo, se sugiere que las estrellas binarias de rayos X pueden ser fuentes de rayos cósmicos. En esos sistemas, una estrella normal cede masa a su complementaria, a una estrella de neutrones o bien a un agujero negro.

Los estudios radioastronómicos de otras galaxias muestran que éstas también contienen electrones de alta energía. Los centros de algunas galaxias emiten ondas de radio de mucha mayor intensidad que la Vía Láctea. Esto indica que contienen fuentes de partículas de alta energía.

Los rayos cósmicos que alcanzan la atmósfera en su capa superior son principalmente (98%) protones y partículas alfa de alta energía. El resto está constituido por electrones y partículas pesadas ionizadas. A éstas se les denomina "partículas primarias".

Estas partículas cargadas interaccionan con la atmósfera y el campo magnético terrestre, se convierten en "partículas secundarias" (son producto de la interacción de las partículas primarias con la atmósfera) y se distribuyen de tal modo que, debido al campo magnético, la mayor intensidad de las partículas que alcanzan el suelo ocurre en los polos.

Por tanto, la componente de partículas que alcanzan el suelo varía según la altitud (a mayor altura, menos atmósfera con la cual interaccionar) y por la latitud (a mayor latitud, mayor cantidad de partículas desviadas por el campo magnético), y propician cierta variación con el ciclo solar (de 11 años).

A nivel del mar y a una latitud de unos 45º N, los componentes importantes de estas partículas son:


Las dosis recibidas debido a los rayos cósmicos varían entre 300 μSv (microsieverts) y 2 000 μSv al año. Promediada por la población, datos de ocupación y otros factores, se encuentra un valor promedio de 380 μSv/año.


Las lluvias o cascadas de partículas subatómicas se originan por acción de rayos cósmicos primarios, cuya energía puede ser superior a 10 eV (electronvoltios): cien millones de veces superior a la que se puede impartir a una partícula subatómica en los más potentes aceleradores de partículas.

Cuando un rayo cósmico de alta energía llega a la atmósfera terrestre interactúa con átomos de ésta, choca contra los gases y libera electrones. Este proceso excita los átomos y genera nuevas partículas. Éstas, a su vez, colisionan contra otras y provocan una serie de reacciones nucleares, que originan nuevas partículas que repiten el proceso en cascada. Así, puede formarse una cascada de más de 10 nuevas partículas. Los corpúsculos integrantes de las cascadas se pueden medir con distintos tipos de detectores de partículas, generalmente basados en la ionización de la materia o en el efecto Cherenkov.




</doc>
<doc id="17448" url="https://es.wikipedia.org/wiki?curid=17448" title="Ollantaytambo">
Ollantaytambo

Ollantaytambo (quechua: "Ollantay Tampu") es un poblado y sitio arqueológico incaico, capital del distrito de Ollantaytambo (provincia de Urubamba), situado al sur del Perú, a unos 90 km al noroeste de la ciudad del Cuzco.

Durante el incanato, Pachacuti conquistó la región y construyó el pueblo y un centro ceremonial. En la época de la conquista sirvió como fuerte de Manco Inca Yupanqui, líder de la resistencia inca. Es la única ciudad del incanato en el Perú que aún es habitada. En Ollantaytambo hay andenes de resistencia (para evitar deslizamientos), no agrícolas como en los demás sitios arqueológicos del Cuzco. En la actualidad es una importante atracción turística debido a sus construcciones incas y por ser uno de los puntos de partida más comunes del camino inca hacia Machu Picchu.

Ollantaytambo trata de un típico ejemplo de la extraordinaria planificación urbana de los incas, y por ello un punto obligado de visita para quien esté interesado en esta civilización.

Sus callejuelas empedradas y serpenteantes, las ruinas diseminadas por doquier y sus terrazas agrícolas son atractivos que destacan por sí mismos y el visitante lo puede apreciar en todo su esplendor. Entre las ruinas, es recomendable la visita a la antigua fortaleza y al templo, donde podemos apreciar magníficas vistas del Valle Sagrado de los Incas.

Ollantaytambo está ubicado al margen del río Patakancha, cerca del punto donde confluye con el río Urubamba. Se encuentra en el distrito del mismo nombre, provincia de Urubamba, aproximadamente a 60 km al noroeste de la ciudad del Cuzco y tiene una altura de 2.792 metros sobre el nivel del mar.

El clima de ollantaytambo es seco de abril a diciembre y lluvioso en los meses de enero a marzo. Debido a su ubicación entre dos vertientes por las noches corre un viento moderado. La temperatura mínima es de 5°C a 11°C y máximas de 18°C a 23°C durante todo el año.

Según el lingüista Rodolfo Cerrón-Palomino, "Ollantay" tiene un origen aimara. Según el mismo, devendría de "Ullantawi": La raíz verbal "ulla-" ('ver') deverberado por el morfema "-nta" (acción hacia abajo o hacia adentro) de por conjunto "ullanta-" (ver hacia abajo, observar), que con el sufijo "-wi" es donominalizado a "lugar de observación desde lo alto", es decir, atalaya o mirador.

Con posterioridad, el quechua comenzó a desplazar al aimara de la zona del Cuzco, alterando el nombre por apocopación del nombre sin símil en el nuevo idioma ("Ullantawi → "Ullantaw") para después trocar el final /w/ en/y/ ("Ullantaw → "Ullantay"), fenómeno constantemente repetido en este proceso de cambio lingüístico.

Posteriormente, con la dominación inca, Viracocha Inca manda fundar un tambo en el nueva plaza conquistada al parangón de la administración cuzqueña: el tambo de Ollantay o "Ullantay Tampu". A la postre, "Ullantay" quedó relegado a modificador de la raíz "tampu" (pronunciada como en la época de la conquista).

Algunos autores, como el historiador cuzqueño Víctor Angles, aseguran sin mayor argumentación que el origen del nombre de Ollantaytambo se da a fines del siglo XVIII, cuando se puso en escena un drama de argumento inca cuyo protagonista era el General Ollantay, y el lugar donde se desarrollaron las acciones —según la obra literaria— fue el tambo abajo de Yucay, que desde ese entonces comenzó a generalizarse como Ollantaytambo, sin embargo, el nombre se halla registrado en documentos de mayor antigüedad, como en los escritos del Inca Garcilaso de la Vega, quien después de elogiar la grandeza y magnificencia de las antiguas fortificaciones de Tanpu, cuenta que fueron mandadas a construir por el inca Wiraqucha, al igual que los grandes y antiguos edificios que existen en ese lugar.

Según Pedro Sarmiento de Gamboa, un cronista español del siglo XVI, el emperador inca Pachacútec conquistó y destruyó Ollantaytambo para luego incorporarlo en su imperio. Bajo el gobierno de los incas, el pueblo fue reconstruido con espléndidos edificios y el valle del río Urubamba fue irrigado y provisto de andenes; el pueblo sirvió de albergue para la nobleza inca mientras que los andenes eran trabajados por "yanaconas", sirvientes del emperador. Después de la muerte de Pachacútec la región pasó a la custodia de su "panaqa", su grupo familiar.

Durante la conquista, Ollantaytambo funcionó como capital temporal para Manco Inca Yupanqui, líder de la resistencia inca contra los conquistadores españoles. Bajo su mandato, el pueblo y sus alrededores fueron severamente fortificados en dirección a la antigua capital inca de Cuzco, la cual había caído bajo dominio español. En el llano de Mascabamba, cerca de Ollantaytambo, Manco Inca derrotó una expedición española bloqueando su avance desde un conjunto de andenes e inundando el llano. Sin embargo, a pesar de su victoria, Manco Inca no consideró viable el permanecer en Ollantaytambo así que se retiró al espeso bosque de la zona de Vilcabamba. En 1540, la población nativa de Ollantaytambo fue asignada en encomienda a Hernando Pizarro.
Se trata de uno de los complejos arquitectónicos más monumentales del antiguo Imperio inca, comúnmente llamado «Fortaleza», debido a sus descomunales muros, fue en realidad un Tambo o ciudad-alojamiento, ubicado estratégicamente para dominar el Valle Sagrado de los Incas.

El tipo arquitectónico empleado, así como la calidad de cada piedra, trabajada individualmente (ver ), hacen de Ollantaytambo una de las obras de arte más peculiar y sorprendente que realizaron los antiguos peruanos, especialmente el Templo del Sol y sus gigantescos monolitos.

Las calles rectas, estrechas y pintorescas hoy forman quince manzanas de casas ubicadas al norte de la plaza principal de la ciudad, que constituyen en sí un verdadero legado histórico. Algunas casas de tipo colonial están construidas sobre hermosos muros incaicos pulidos con finura. Los tonos de la piedra son alegres, de un color de flor petrificada, rosa oscuro. En la plaza principal un gran bloque de perfectas aristas encaja en una doble hilera sus quince ángulos de estrella terrestre.




</doc>
<doc id="17449" url="https://es.wikipedia.org/wiki?curid=17449" title="Tambo (arquitectura)">
Tambo (arquitectura)

En el Antiguo Perú, un tambo (del quechua "tanpu") era un recinto situado al lado de un camino importante usado como albergue y como centro de acopio. El camino del inca tenía tambos distantes 20 o 30 km (una jornada de camino a pie) entre sí. Su principal función era albergar a los chasquis (emisarios del imperio que recorrían estos caminos) y a las enmiendas de gobernadores que recorrían estos caminos de punta a punta mediante una red única de caminos. No se tiene información si albergaba a hombres comunes y corrientes.

Además de servir de refugio, se sabe que los tambos eran centros de acopio de alimentos, lana, leña u otros materiales básicos para la alimentación. De este modo, en épocas de penurias climáticas o desastres naturales, los tambos alimentaban y proveían de algunos materiales para la población de las aldeas más cercanas a la redonda.

Como la agricultura era la principal fuente de alimentación de los Incas, la administración del Imperio incaico, estableció estos lugares como una bodega donde se podía guardar alimento en caso de emergencia, asegurando así el buen vivir de la población.

El Imperio inca estuvo comunicado por muchos caminos principales y secundarios, que unieron de manera eficaz los pueblos del antiguo Perú. El diseño de estos caminos (de más de 30 000 km) fue de gran calidad y profesionalismo, a pesar de las grandes dificultades geográficas (Cordillera de los Andes). 

El Cusco fue el centro de esta red vial y en él confluyeron la mayor parte de los caminos, pues la capital de los incas era el ombligo del mundo y todo debía partir y culminar en ella.

Es aquí donde encontramos las posadas han sido utilizadas universalmente como lugares donde se ofrecía servicio temporal a los viajeros en las rutas comerciales o en los caminos de peregrinaje. En los Andes peruanos estos lugares se llamaban “Tambos” y fueron las sociedades andinas las que los planificaron y edificaron de la manera más compleja y ordenada a diferencia de las sociedades de aquella época.

Los caminos incas fueron construidos a los pies de los cerros para que los chasquis pudieran llevar mensajes, encomiendas, pescado y frutas a todas las ciudades correspondientes al Imperio inca.

El Imperio incaico tenía unos 10 a 12 millones de habitantes en el siglo XV, ocupó gran parte andina de la costa occidental y para poder controlar todo el territorio, hicieron una red de caminos para llevar noticias y productos. Esta red de caminos se llamaba "Qhapaq ñan" o "Capac ñan" en quechua que significa gran camino y también lo llamaban "Inka ñan" o camino inca.

Cuando llegaron los conquistadores españoles, ya había 16 km aproximadamente de caminos empedrados. Este sendero llegó hasta el valle del Mapocho y una parte es hoy la avenida Independencia en Santiago, la capital de Chile. La arteria principal es de 5200 km y la red secundaria penetraba por varios caminos transversales que incluso llegaban hasta las selvas y el Gran Chaco (Argentina, Bolivia y Paraguay) la cual llegaba hasta los 5 km de altura en la cordillera de los Andes.

Los incas, que se basaron en los mensajeros mochicas y chimúes (culturas del antiguo Perú surgida en la costa norte huari entre los años 1000 y 1200) para así crear a los chasquis que significa "“el que recibe”" o "“dar, recibir algo”". 

Cada pueblo contaba con chasquis de entre 18 y 25 años, sirviendo los turnos diarios de 6 a 12 h en las postas que les eran asignadas. El peruano Luis Millones Santa Gadea, en su obra de los chasquis los describe con una túnica o camisa y con ojotas. Solo llevaban un sonoro caracol, un penacho de plumas blancas en la cabeza para ser visto de lejos y un bastón labrado. 

Cada tramo de unos 2 km había una zona de descanso, una cabaña rústica llamada tampu, chuclla o tambo, donde había hasta servicios de hospedaje

Había dos técnicas para llevar un mensaje. Una eran los quipus una serie de cuerdas de colores y anudadas que servían para la administración. Recientemente algunos investigadores dicen que el color y la ubicación de los nudos pueden significar frases no solo cifras. La otra técnica era la palabra, donde el chasqui se pasaba el mensaje repitiéndolo varias veces, en voz alta cuando estaba llegando o corrían juntos un tramo hasta que el otro chasqui lo recordaba.

La piedra era el material más importante para construir las estructuras de los Inca, pero también tenía otro gran significado. La piedra fue muy importante en la historia de la creación de los Inca. Dentro de la piedra vivía el espíritu o poder que tenía la capacidad de convertirse en humano o viceversa. Por esta razón los Inca adoraban las piedras y apreciaban la sustancia actual en vez de lo que se podría construir con piedras. Por ejemplo, "huacas" o piedras sagradas aparecen en la historia de la creación. Cuando todos los hermanos de Manco Capac se convirtieron en piedras, los restos eran considerados como huacas. Aya Auca, el tercer hermano de Capac fue renombrado Cuzco Huaca y fue él, el que cuidaba el campo de Cuzco. También, durante la guerra contra los enemigos de los Inca, conocidos como "Chanca," uno de los gobernadores más poderosos del imperio, Pachacutec, rezó a los dioses, y las piedras se transformaron en una fuerza de soldados y que derrotaron a los Chanca.

Este respeto por la piedra y sus poderes dio lugar a su dominio y pericia con la albañilería. Usaban piedras de tamaños inusuales y las pegaban sin ningún pegamento para hacer paredes; las piedras estaban tan bien situadas que una hoja de papel no se podía poner entre estas. La superficie era tallada lisa y sin ángulos rectos para que parecieran que estaban vivas.

Los tambos eran construidos aprovechando las abertura de las montañas las cuales se contenían y edificaban con piedra y tenían techo para protege de las inclemencias climáticas, debido a su ubicación generalmente alrededor de la Cordillera de los Andes. Las dos técnicas más conocidas usadas para los tambos son:



La ubicación de los tambos hace referencia a los caminos del inca que recorrían desde Bolivia hasta Chile, el tambo descubierto más al sur es el Tambo Pirque, ubicado en el borde del río Maipo con un antiguo puente colgante que unía las dos extremos del río. Fue descubierto, con la expansión de Santiago hacia el sur. Estos tambos se ubicaban principalmente mediante los caminos que recorrían Chile hasta Bolivia, mediante dos trazas, la costera y la del cerro.

Al haber dos rutas que recorrían de norte a sur, había tambos ubicados en las 2 rutas cada 20 o 30 kilómetros, Así es como habían 2 técnicas distintas para construirlos, generando dos tipos de plantas, según la disponibilidad del material, usando los dos sistemas constructivos.



</doc>
<doc id="17450" url="https://es.wikipedia.org/wiki?curid=17450" title="Pista de aterrizaje">
Pista de aterrizaje

La pista de aterrizaje o pista de despegue es la superficie de un campo de aviación o de un aeropuerto, así como también de un portaaviones, sobre la cual los aviones toman tierra y frenan o en la que los aviones aceleran hasta alcanzar la velocidad que les permite despegar. En español es más habitual hablar de pista de aterrizaje que de pista de despegue. En inglés existe una única palabra para ambos términos, que es "runway". El piloto y el controlador aéreo utilizan simplemente la expresión «pista» cuando se comunican entre ellos.

La pista de aterrizaje y despegue se dimensiona en función de la aeronave característica. Esta, a su vez, viene determinada por estudios previos sobre el tráfico que va a soportar el aeropuerto, rangos de los orígenes de esos tráficos y otras varias consideraciones que confluyen en la determinación de cual es la aeronave que por su capacidad, autonomía y otras características técnicas resulta ser la ideal o característica. A partir de este dato fundamental, se conoce la "longitud básica de pista" dato ideal determinado por el fabricante y que viene a ser la longitud ideal y segura que necesita esa aeronave en cuestión para operar al nivel del mar y con una temperatura ambiente de 15° C.
Es con estos datos con los que esa longitud básica de pista se corrige en función de la altitud de la pista en cuestión y de la temperatura media del lugar. Cuanto más altitud y/o mayor temperatura, más debe incrementarse la longitud básica que a la postre será la longitud de proyecto.

Los grandes aeropuertos, donde la demanda es muy elevada, disponen de varias pistas. Los grandes aviones, con plena carga de combustible y de pasajeros, como el Boeing 747 o el Airbus 340 requieren de pistas de al menos 2,5 km para despegar y para aterrizar de forma segura. Por el contrario, aviones de pasajeros pequeños necesitan pistas que no superan un kilómetro. En el caso de las bases aéreas militares sucede lo mismo.

Excepcionalmente, en el caso de los portaviones la pista de aterrizaje es distinta de la pista de despegue. El motivo es que deben poder utilizarse ambas pistas simultáneamente. Su pista de despegue es muy corta, de unos 100 metros, de forma que los aviones deben ser acelerados en pocos segundos de 0 a 200 km/h mediante catapultas para poder despegar. La pista de aterrizaje es algo más larga, de unos 200 metros, longitud que obliga a utilizar cables de frenado para que los aviones puedan aterrizar. Sin embargo, debe observarse que en el caso de un portaviones, las operaciones se realizan con el barco navegando a máxima velocidad en contra del viento, si lo hay, por lo cual el avión se ve beneficiado con un viento frontal virtual que puede ser por lo menos de 25 nudos, por lo que los requerimientos de longitud de pista se ven disminuidos. Si hay un viento de veinte nudos, este se sumará a la velocidad del navío, o sea, que el avión, aparcado antes de ser catapultado para despegar, puede ya estar gozando de 45 nudos de viento en cara. Si se permite el símil, un portaviones es un aeropuerto con viento de proa incorporado.

La pista de aterrizaje y despegue puede tener solamente unos pocos grados de inclinación, ya que una pendiente mayor afectaría a la velocidad de los aviones al despegar y aterrizar.

Los aviones requieren cierta velocidad para poder sustentarse en el aire. Al tener vientos frontales, los aviones requieren menos velocidad relativa para poder volar. Por otra parte, los aviones tienen grandes dificultades para despegar y aterrizar con vientos laterales (conocidos técnicamente como vientos cruzados). Con base en esto, las pistas de un aeropuerto se construyen de tal manera que, durante un año, los vientos cruzados no superen el 5 % del tiempo los valores admisibles para la aeronave de diseño. En la medida en que los vientos varían sustancialmente de año a año, se requieren series históricas de al menos 10 años para establecer si la orientación es adecuada.

En aeropuertos importantes, las pistas están hechas generalmente en un pavimento de asfalto u hormigón. El grosor de la base de la pista depende del tipo y tamaño de los aviones que la utilizarán y de la composición de la demanda. Así por ejemplo, las pistas destinadas a los grandes aviones requieren una base extremadamente gruesa (entre 15 y 51 cm aproximadamente) resistente para soportar el peso elevado de tales aparatos. Sin embargo, los campos de aterrizaje de poca envergadura, de ciudades pequeñas, a menudo son de tierra, césped, afirmado, hierba o gravilla.

El paquete estructural de un pavimento rígido para pistas de aeródromos se compone de una base de hormigón simple (o armado, en las intersecciones con otras pistas y salidas) que distribuye las tensiones al suelo natural compactado (o subrasante). Si la masa de la aeronave de diseño superare las 100 000 libras, se incluye una capa intermedia de material estabilizado que distribuye uniformemente la carga de la losa y reduce los daños por congelamiento y deshielo.

Para aquellos aeropuertos pequeños de campos de aterrizaje de poca longitud y situados en pequeñas ciudades, fincas o pueblos, estas pueden ser de tierra, césped, grava, hierba entre otros.

En estas pistas pueden aterrizar aeronaves que poseen un tren de aterrizaje triciclo de alta resistencia como:


Cada pista es denominada con dos números, uno para cada una de las dos direcciones y eventualmente una letra. Esto permite que los pilotos puedan identificar fácilmente la pista y el lado de esta que deben utilizar. El número significa la dirección en grados (redondeado a la decena más cercana y recortado en el último dígito) con respecto al norte magnético a la que se encuentra dirigida la pista (en una cabecera) y respectivamente la cabecera opuesta, estará denominada con el ángulo de complemento (dirección contraria, es decir 180° de diferencia).

Si, por ejemplo, una pista tiene en una dirección la denominación 04, su identificación en la dirección opuesta será 22. Estos números están pintados en caracteres muy grandes, en blanco, sobre la superficie de la pista en sus dos extremos, de forma que puedan ser reconocidos por los pilotos desde el aire a cierta distancia. Si un aeropuerto dispone de dos pistas que transcurren paralelamente, y que por ello están identificadas con el mismo número, se añade a continuación del número una R (del inglés "Right") en la pista derecha, y una L (de "Left") en la pista izquierda. En tal caso, las dos pistas podrían tener, por ejemplo, los identificativos 07R y 07L. Si el aeropuerto dispone incluso de una tercera pista paralela a las otras dos, la denominación de la pista del centro será en este ejemplo 07C (de "Center"). La dirección de la pista es indicada en grados magnéticos, eliminando la última cifra. Una pista cuya dirección es, por ejemplo, hacia el este, o sea 90 grados, tendrá por lo tanto como denominación 09, y una pista cuya dirección es hacia el suroeste, o sea 225 grados, se identificará como 22.

Un caso especial como es el del Aeropuerto Internacional de Dallas-Fort Worth, ya que de sus siete pistas de aterrizaje y despegue (uno de los aeropuertos con más pistas del mundo), cinco son paralelas, necesita utilizar un procedimiento un poco distinto. A las dos pistas situadas al oeste se les da la denominación de 36L y 36R, y a las tres restantes se les resta un número quedando en 35L, 35C y 35R. No es del todo correcto, pero es la mejor manera de determinarlas.


La letra hace referencia a la posición de la pista con respecto hacia las demás que mantengan un mismo sentido. Existen 3 letras: L ("Left", izquierda), R ("Right", derecha) y C (central). En el caso de que existan más de tres pistas paralelas, la W se aplica a la que esté a la izquierda de la L. De igual manera, si un aeropuerto no tiene pistas paralelas, basta con poner solo la numeración, sin añadir letras.

Ejemplo: En el mismo aeropuerto del ejemplo anterior, hay dos pistas que se encuentran hacia el mismo sentido, y son la 05L ("Left", 05 izquierda), y la 05R ("Right", 05 derecha), análogamente las del otro lado son la 23L (el otro extremo de la 05R) y la 23R (el otro extremo de la 05L).

Las pistas de aterrizaje y despegue disponen de una señalización blanca pintada sobre la superficie de la pista, cuyo objetivo es informar a los pilotos al despegar, y sobre todo al aterrizar, sobre los diversos tramos y distancias de la pista, así como sobre su eje longitudinal central, para facilitarles las maniobras.

Para los despegues y aterrizajes nocturnos y en condiciones de visibilidad reducida, como en el caso de niebla, las pistas están iluminadas mediante luces que señalizan sus lados, el eje longitudinal central, los diversos tramos de la pista, así como su comienzo y su final. Para los aterrizajes en dichas condiciones las pistas de cierta importancia disponen de balizas de aterrizaje que se instalan en una longitud de varios centenares de metros por delante de la pista, y que constan de focos montados en un orden determinado.

Indicadores de Pendiente de Aproximación Visual (VASI)

Una importante ayuda visual a la aproximación final hacia la cabecera de la pista son los Indicadores de Pendiente de Aproximación Visual, que aporta una mayor certeza en la aproximación en conjunto con los sistemas de ayuda de aproximaciones visuales e instrumentales. Los VASI están instalados normalmente en lugares donde una o más de las siguientes condiciones existen:






Luces indicadoras del fin de la pista (REIL)

Algunas veces las luces están ubicadas al final de la pista para ayudar a la rápida y efectiva identificación del acercamiento del fin de la pista. Cuando se está en la segunda mitad de la pista, las luces blancas de eje y de borde se convierten en una hilera que alterna una bombilla blanca y una roja. En el último tramo de pista solo hay bombillas rojas. De esta manera el piloto puede identificar adecuadamente el final de pista sin posibilidad de confusión. También se suele incorporar un sistema que consiste en dos series de luces que sincronizadamente emiten flash (llamadas luces estroboscópicas), una de cada lado del último tramo de la pista. Sin embargo, estas no se suelen instalar, pues el sistema de luces estroboscópicas están incorporadas al Sistema de Luces de Aproximación. El sistema REIL es usado para distinguir la cabecera de la pista en lugares caracterizados por numerosas luces de suelo, como señales de neón u otras luces que pueden distraer la atención del piloto.

Sistemas de Luces de Aproximación (ALS)

Los Sistemas de Luces de Aproximación son usados en las cercanías de la cabecera de la pista como parte a las ayudas electrónicas de navegación para la parte final de aproximaciones precisas y no precisas de un vuelo IFR; y también como una guía visual en vuelos VFR nocturnos. El sistema de luces de aproximación suministra al piloto con entradas visuales respecto a la alineación de la aeronave, el equilibrio, el horizonte, el ancho y la posición con respecto a la cabecera de la pista. Desde que los sistemas de iluminación aeroportuarios relevaron a las necesariamente rápidas acciones mentales sobre la información visual que encabezaban las decisiones, un sistema visual es ideal para una guía durante los últimos segundos críticos del movimiento descendente sobre el patrón de planeo.
El sistema de luces de aproximación se creó con base en el ángulo del patrón de planeo, el rango visual, el ángulo de visibilidad cortada en la cabina y de las velocidades de aterrizaje. Esto es esencial para que los pilotos estén propensos a utilizar e identificar ALS y de interpretar el sistema sin confusión.
Entre los principales sistemas de ALS se encuentran:


Sistema PAPI

El sistema PAPI consiste en una barra transversal de cuatro luces rojas o blancas situadas, normalmente, en el lado izquierdo de la pista. Si el avión va muy alto sobre la senda de planeo verá todas las luces blancas; si va un poco alto verá tres luces blancas y una roja; si va muy bajo, las verá todas rojas; si solo va un poco bajo verá tres rojas y una blanca, y si va en la senda correcta, verá dos blancas y dos rojas.

Iluminación del acotamiento central y de la zona de contacto de la pista

Estos sistemas de iluminación facilitan los aterrizajes, los giros y los despegues. Las luces de la zona de contacto son más que nada utilizadas para los aterrizajes, y las luces de centro de la pista ayudan después del contacto y brindan la guía primaria durante la carrera de despegue. Ambos sistemas son utilizados como complemento a las ayudas de aproximación electrónicas y ALS bajo condiciones de visibilidad limitada.

Las Luces del Centro de la Pista están unidas casi a la misma altura del pavimento y sobrepuestas sobre un máximo de dos pies para dejar libre la pintura del acotamiento. Las luces del centro son blancas a excepción de los últimos 3000 pies. De los 3000 a los 1000 pies de la pista, las luces se alternan en rojo y blanco.



</doc>
<doc id="17451" url="https://es.wikipedia.org/wiki?curid=17451" title="Hildegarda de Bingen">
Hildegarda de Bingen

Santa Hildegarda de Bingen O.S.B. (en alemán: "Hildegard von Bingen"; Bermersheim vor der Höhe, distrito de Alzey-Worms, Rheinhessen, Renania-Palatinado, Alemania, 16 de septiembre de 1098-Monasterio de Rupertsberg, Bingen, Rheinhessen, Renania-Palatinado, Alemania, 17 de septiembre de 1179) fue abadesa, líder monacal, mística, profetisa, médica, compositora y escritora alemana. Es conocida como la sibila del Rin y como la profetisa teutónica. El 7 de octubre de 2012 el papa Benedicto XVI le otorgó el título de doctora de la Iglesia junto a san Juan de Ávila durante la misa de apertura de la XIII Asamblea general ordinaria del sínodo de los obispos.

Considerada por los especialistas actuales como una de las personalidades más fascinantes y polifacéticas del Occidente europeo, se la definió entre las mujeres más influyentes de la Baja Edad Media, entre las figuras más ilustres del monacato femenino y quizá la que mejor ejemplificó el ideal benedictino, dotada de una cultura fuera de lo común, comprometida también en la reforma de la Iglesia, y una de las escritoras de mayor producción de su tiempo. En expresión de Victoria Cirlot:
Hildegarda nació en Bermersheim, en el valle del Rin (actualmente Renania-Palatinado, en Alemania), durante el verano del año 1098, en el seno de una familia noble alemana acomodada. Fue la menor de los diez hijos de Hildeberto de Bermersheim, caballero al servicio de Meginhard, conde de Spanheim, y de su esposa, Matilde de Merxheim-Nahet, y por eso fue considerada como el diezmo para Dios, entregada como oblata y consagrada desde su nacimiento a la actividad religiosa, según la mentalidad medieval. De esta manera, fue dedicada por sus padres a la vida religiosa y entregada para su educación a la condesa Judith de Spanheim ("Jutta"), hija del conde Esteban II de Spanheim y, por tanto, noble como ella, quien la instruyó en el rezo del salterio, en la lectura del latín —aunque no le enseñó a escribirlo o, cuando menos, no con pericia—, en la lectura de la Sagrada Escritura y en el canto gregoriano.

Durante algunos años maestra y discípula vivieron en el castillo de Spanheim. Cuando Hildegarda cumplió catorce años, ambas se enclaustraron en el monasterio de Disibodenberg. Este monasterio era masculino, pero acogió a un pequeño grupo de enclaustradas en una celda anexa, bajo la dirección de Judith. La ceremonia de clausura solemne fue celebrada el 1 de noviembre de 1112 y en ella participaron Hildegarda, Judith y otra enclaustrada más, también infante. En 1114, la celda se transformó en un pequeño monasterio, a fin de poder albergar el creciente número de vocaciones. En ese mismo año, Hildegarda emitió la profesión religiosa bajo la regla benedictina, recibiendo el velo de manos del obispo Otón de Bamberg. De esta manera continuó su educación monástica rudimentaria dirigida por Judith. 

Judith murió en 1136, con fama de santidad tras haber llevado una vida de mucha austeridad y ascesis, que incluyó largos ayunos y penitencias corporales. Hildegarda, a pesar de su juventud, fue elegida como abadesa ("magistra") de manera unánime por la comunidad de monjas.

Desde niña, Hildegarda tuvo débil constitución física, sufría de constantes enfermedades y experimentaba visiones. En una hagiografía posterior escrita por el monje Teoderico de Echternach se consignó el testimonio de la propia Hildegarda, donde dejó constancia que desde los tres años tuvo la visión de «"una luz tal que mi alma tembló"». Estos hechos continuaron aún durante los años en que estuvo bajo la instrucción de Judith quien, al parecer, tuvo conocimiento de ellos. Vivía estos episodios conscientemente, es decir, sin perder los sentidos ni sufrir éxtasis. Ella los describió como una gran luz en la que se presentaban imágenes, formas y colores; además iban acompañados de una voz que le explicaba lo que veía y, en algunos casos, de música.

En 1141, a la edad de cuarenta y dos años, sobrevino un episodio de visiones más fuerte, durante el cual recibió la orden sobrenatural de escribir las visiones que en adelante tuviese. A partir de entonces, Hildegarda escribió sus experiencias, que dieron como resultado el primer libro, llamado "Scivias" ("Conoce los caminos"), que no concluyó hasta 1151. Para tal fin, tomó como secretario y amanuense a uno de los monjes de Disibodenberg llamado Volmar y, como colaboradora, a una de sus monjas, llamada Ricardis de Stade.

No obstante, siguió teniendo reticencias para hacer públicas sus revelaciones y los textos resultantes de ellos, por lo que para disipar sus dudas recurrió a uno de los hombres más prominentes y con mayor reputación espiritual de su tiempo: Bernardo de Claraval, a quien dirigió una sentida carta pidiéndole consejo sobre la naturaleza de sus visiones y la pertinencia de hacerlas de conocimiento general. En dicha misiva, enviada hacia 1146, confesaba al ilustre monje cisterciense que lo había visto en una visión «"como un hombre que veía directo al sol audaz y sin miedo"», y al mismo tiempo que se atribuía a sí misma «debilidad» solicitaba su consejo:

La respuesta de Bernardo no fue ni muy extensa ni tan elocuente como la carta enviada por Hildegarda, pero en ella la invitaba a «"reconocer este don como una gracia y a responder a él ansiosamente con humildad y devoción [...]"». Además, parece que el abad de Claraval posteriormente intervino ante el papa Eugenio III en favor de Hildegarda, ya que tenía trato personal con el obispo de Roma porque éste era también cisterciense y antiguo discípulo suyo.

Precisamente, el arzobispo Enrique de Maguncia bajo cuya jurisdicción se encontraba el monasterio de Disibodenberg, y que estaba enterado de las visiones y profecías de Hildegarda, mandó una comisión al papa Eugenio para informarse de lo sucedido y lograr que se declarara sobre la naturaleza de tales dones. El papa se encontraba por aquellos días en Tréveris para presidir el sínodo que se celebró en aquella ciudad entre 1147 y 1148.

En 1148, un comité de teólogos, encabezado por Albero de Chiny-Namur, obispo de Verdún, a petición del papa, estudió y aprobó parte del "Scivias". El mismo papa leyó públicamente algunos textos durante el sínodo de Tréveris y declaró que tales visiones eran fruto de la intervención del Espíritu Santo. Tras la aprobación, envió una carta a Hildegarda, pidiéndole que continuase escribiendo sus visiones. Con ello dio comienzo no solo la actividad literaria aprobada canónicamente, sino también la relación epistolar con múltiples personalidades de la época, tanto políticas como eclesiásticas, tales como el ya mencionado Bernardo de Claraval, Federico I Barbarroja, Enrique II de Inglaterra o Leonor de Aquitania, que pedían sus consejos y orientaciones. Tal fue su reconocimiento, que llegó a ser conocida como la "Sibila del Rin".

También en 1148 y sin haber concluido la redacción del "Scivias", una visión la hizo concebir la idea de partir de Disibodenberg y marchar a un lugar «donde no había agua y donde nada era placentero» inspirándola así para la fundación de un monasterio en la colina de san Ruperto ("Rupertsberg"), cerca de Bingen al oeste del río Rin en la desembocadura del Nahe, para trasladar a la crecida comunidad y emanciparla de los monjes de Disibodenberg. 

Sin embargo, Kuno, entonces abad de Disibodenberg, se opuso a su salida, lo que contrarió a la monja en gran medida, al punto de ocasionarle trastornos físicos, que fueron atribuidos a causas divinas: 

Ante esta situación intervino la marquesa Ricardis de Stade ("Richardis von Stade"), madre de la monja que servía de secretaria a Hildegarda, quien logró convencer a Enrique I, arzobispo de Maguncia (1142—1153), de que diera la autorización para la salida de las religiosas y la fundación del nuevo monasterio. Hacia 1150, se trasladó a Rupertsberg con cerca de veinte de sus monjas, obtuvo el permiso del conde Bernardo de Hildesheim, propietario del terreno elegido y fundó el monasterio de Rupertsberg, del cual se convirtió en abadesa.

Por esa época, su asistente y secretaria Ricardis la abandonó para convertirse en abadesa del convento de Bassum en Sajonia. Ello causó la tristeza y oposición de Hildegarda, que luego reflejaría en serias cartas de protesta al arzobispo Hartwig de Bremen, hermano de Ricardis, quien había influido para conseguir el cargo abacial; llegó a apelar hasta al papa, sin conseguir que la monja volviera. Ricardis murió al año de la separación.

Un año después del traslado concluyó el "Scivias" y de esa misma época datan sus dos libros de contenidos sobre ciencias naturales ("Physica") y medicina ("Cause et cure"), en los cuales expuso gran cantidad de conocimientos sobre el funcionamiento del cuerpo humano, de herbología y otros tratamientos médicos de su época basados en las propiedades de piedras y animales. Asimismo, comenzó la colección de cantos que tituló "Symphonia armonie celestium revelationum", que compuso para atender a las necesidades litúrgicas de su comunidad. Según algunas cronologías, también de 1150 dataría el inicio del "Liber vite meritorum".

Hacia 1163, como fruto de sus constantes visiones, comenzó la escritura del "Liber divinorum operum", la tercera de sus tres obras más importantes y que tardaría alrededor de diez años en concluir. Sin embargo, la abadesa alternó la vida contemplativa y de escritora con la de predicación y fundación, ya que en 1165 fundó un segundo monasterio en Eibingen, que visitaba regularmente dos veces a la semana.

La fama de santa y profetisa que llegó a tener la abadesa fue tal que, en 1150, el propio emperador Federico I Barbarroja la invitó a entrevistarse con él en su palacio en Ingelheim. El aprecio mutuo que generó esta entrevista manifestado en las subsecuentes cartas llegó a tal grado que, trece años más tarde, el soberano otorgó un edicto de protección imperial a perpetuidad al monasterio de Rupertsberg.

La labor de escritora de Hildegarda se vio interrumpida muchas veces por los viajes de predicación. Si bien la clausura en sus tiempos no era tan rígida como lo sería a partir de Bonifacio VIII, no dejó de sorprender y admirar a sus contemporáneos que una abadesa abandonara su monasterio para predicar.

El contenido de su predicación giró en torno a la redención, la conversión y la reforma del clero, criticando duramente la corrupción eclesiástica, además de oponerse firmemente a los cátaros; al condenar las doctrinas de estos, proponiendo el combate de sus errores mediante la predicación y la edificación del clero.

En total fueron cuatro los viajes de predicación que realizó: el primero entre 1158 y 1159, en el que viajó a Maguncia y a Wurzburgo. En 1160 realizó el segundo a Tréveris y a Metz. En su tercera predicación, entre 1161 y 1163, viajó por el Rin hasta Colonia. En el último de sus viajes, comprendido entre 1170 y 1171, predicó en la región de Suabia. 

Además de estos viajes de predicación, Hildegarda usó las cartas para hacer sentir su opinión ante personajes notables. Con motivo del cisma provocado por la elección del antipapa Víctor IV con el apoyo del emperador Barbarroja, frente al papa romano Alejandro III, alargado a la muerte de Víctor IV con la elección de los también antipapas Pascual III y Calixto III, Hildegarda hizo graves amonestaciones proféticas al primero de estos, así como al emperador mismo.

En el año 1173, poco antes de concluir el "Liber divinorum operum", murió el monje Volmar, su más cercano colaborador y secretario, lo que la orilló a ayudarse de los monjes de la abadía de san Eucario de Tréveris para terminar dicha obra. Durante algún tiempo el monje Godofredo de Disibodenberg le sirvió como amanuense, a la vez que comenzó la redacción de una biografía de la profetisa, pero también él murió poco tiempo después, en 1176. El último de sus secretarios lo encontró en Guiberto de Gembloux, un monje flamenco, con el que había sostenido conversación epistolar iniciada por el interés de éste sobre la manera en que Hildegarda tenía sus visiones.

La última situación crítica a la que tuvo que enfrentarse Hildegarda aconteció en 1178, cuando su comunidad dio sepultura en el cementerio conventual a un noble supuestamente excomulgado. Por la imposición de esta pena eclesiástica, el derecho canónico prohibía su entierro en suelo sagrado. Se pidió a Hildegarda que exhumara el cadáver. Ella se negó e incluso hizo desaparecer cualquier rastro del enterramiento para que nadie pudiera buscarlo. Sostuvo que había sido reconciliado con la Iglesia antes de morir. Los prelados de Maguncia, en ausencia del arzobispo Christian, que estaba en Roma, pusieron en entredicho al monasterio. Por él se prohibió el uso de las campanas, los instrumentos y los cantos en la vida y liturgia de Rupertsberg. Hildegarda se defendió escribiendo una carta de rico contenido doctrinal, donde recogía el significado teológico de la música. Cuando regresó el arzobispo en marzo de 1179, se presentaron testigos que apoyaban la versión de Hildegarda y fue levantado el entredicho.

A los pocos meses de ser levantado el entredicho, el 17 de septiembre de 1179, a los 81 años de edad murió Hildegarda. Las crónicas hagiográficas cuentan que a la hora de su muerte aparecieron dos arcos muy brillantes y de diferentes colores que formaban una cruz en el cielo. 

Entre 1180 y 1190 el monje Teoderico de Echternach escribió la "Vita" ("Vida") de Hildegarda, recogiendo pasajes autobiográficos que la monja había dejado y contado. Gregorio IX abrió el proceso de canonización en 1227, aunque no se concluyó. Fue reabierto por Inocencio IV en 1244, sin que tampoco en esta ocasión se llegase a concluir. Sin embargo, debido a la difusión de su culto se la inscribió en el Martirologio romano, incluyéndose además su nombre en algunas letanías; se extrajeron reliquias de su sepulcro; se celebró su fiesta litúrgica; se le atribuyeron milagros y sus representaciones pictóricas y escultóricas comenzaron a ser objeto de veneración.

Sus reliquias fueron conservadas en el convento de Rupertsberg hasta la destrucción de éste en 1632, durante la Guerra de los Treinta Años. Entonces fueron llevadas a Colonia y después a Ebingen donde se depositaron en la iglesia parroquial donde aún reposan.

En 1940 se aprobó oficialmente su celebración para las iglesias locales. Con motivo del 800 aniversario de su muerte, Juan Pablo II se refirió a ella como profetisa y santa. De la misma manera, en 2006, el papa Benedicto XVI también se refirió a Hildegarda como santa y la encomió como una de las grandes mujeres de la cristiandad junto con Catalina de Siena, Teresa de Ávila y la madre Teresa de Calcuta.

En el año 2010 el papa Benedicto XVI dedicó a Hildegarda las Audiencias Generales del 1 y 8 de septiembre, dentro del marco de una serie de catequesis sobre escritores cristianos, siendo la primera mujer presentada en estas catequesis; recordó, entre otras cosas, que los contemporáneos de Hildegarda la consideraron con el título de ""profetisa teutónica"" y puntualizó el valor teológico de sus escritos y enseñanzas.

En diciembre de 2011, el papa Benedicto XVI anunció su decisión de otorgar a santa Hildegarda el título de "Doctora de la Iglesia". El 10 de mayo de 2012 procedió a inscribirla en el catálogo de los santos y extender su culto litúrgico a la Iglesia universal, en una "canonización equivalente". El 27 de mayo de 2012 durante el rezo del Regina Caeli del día de Pentecostés, el papa determinó la fecha para la proclamación como Doctora. El 7 de octubre de 2012, durante la misa de apertura del Sínodo de los obispos en la Basílica de San Pedro en Roma, se realizó la proclamación oficial por el cual se le concedió el título de Doctora para la Iglesia Universal junto con san Juan de Ávila por el papa Benedicto XVI.

Hildegarda también es venerada por algunas de las Iglesias que conforman la Comunión anglicana, entre ellas la Iglesia de Inglaterra y la Iglesia episcopal escocesa. Tanto en la Iglesia católica como en la Comunión anglicana se la celebra el 17 de septiembre.

La iconografía religiosa de Hildegarda es escasa, probablemente porque su culto fue local por bastante tiempo. Se la retrata con los atributos propios de una abadesa de la orden de san Benito: báculo abacial y hábito benedictino con velo negro y blanco; sus representaciones más antiguas reproducen la manera en que aparece en las miniaturas de sus escritos: sentada con un estilo en la mano en actitud de escribir sobre un par de tablillas o dictando a un monje, con cinco flamas alrededor de la cabeza representando la visión divina. Más tarde se cambia el estilo por una pluma de ave, con algún pergamino o libro en la mano — comúnmente el "Scivias" — y algún instrumento musical.

Las obras de esta religiosa del siglo XII fueron escritas —como la mayor parte de los escritos de su tiempo—, en latín medieval, salvo por ciertas anotaciones y palabras que podemos encontrar en algunas de sus cartas y principalmente en sus obras relativas a la "Lingua ignota", que se encuentran en alemán medieval propio de la región media de Franconia–Renania/Mosela. En su obra, ella misma acusó en variadas ocasiones su poca preparación en latín, pero por sus propias confesiones y sus hagiógrafos se conoce que su método de escritura comenzaba al escribir sus visiones y luego pasarlas a un secretario que corregía los errores y pulía la escritura. Dos de ellos — Volmar y Gottfried — fueron monjes de Rupertsberg y el tercero, de origen flamenco — Guibert de Gembloux — era monje de la abadía de Gembloux, de ahí que todos ellos estaban bien preparados en el latín eclesiástico.

Empleó varios estilos de escritura: el tratado teológico, el epistolar, el hagiográfico y el tratado médico; pero destacan sus obras visionarias, en las que hace un uso constante y fecundo de la alegoría ética-religiosa, que aunque era bastante común en su tiempo, llegaba a usar símbolos poco frecuentes.

En lo referente a las influencias recibidas y a su manera de escribir, indudablemente se destacan las Sagradas Escrituras a través de la "Vulgata", con especial atención hacia los profetas y el Nuevo Testamento, en este último se destacan la importancia que el Evangelio de san Juan y el Apocalipsis tuvieron en ella, ya que incluso en algunas narraciones autobiográficas consignadas en la "Vita" llegó a comparar sus dones espirituales con las inspiraciones del evangelista Juan sumado al tono apocalíptico de las partes finales del "Scivias". 

Igualmente se le atribuyen conocimientos de algunas obras de la patrística latina, entre las cuales se ha detectado la influencia de san Agustín y san Isidoro de Sevilla; se ha señalado especialmente la influencia y similitud con el "Pastor de Hermas" y Boecio como fuentes de la identificación alegórica como mujeres que Hildegarda hace de la Iglesia y de algunas virtudes en el "Scivias". Además, no obstante de que la abadesa se calificara a sí misma de «indocta», se ha detectado en sus obras un gran bagaje cultural clásico proveniente de Cicerón, Lucano y Séneca; con Galeno coincide en algunas teorías médicas sobre los humores; en el "Scivias" y el "Ordo virtutum" representa la lucha constante de las virtudes contra los vicios a través de su personificación como mujeres ataviadas con los atributos correspondientes a la actitud moral que encarnan, combatiendo cada virtud contra el vicio opuesto a ella. Esta tradición alegórica es común a otros escritores del medioevo y puede rastrearse hasta la Psychomachia de Prudencio en el siglo IV. 

Sus obras fueron legadas a la posterioridad gracias al interés de los monjes que la admiraron y la ayudaron a escribirlas, encabezados por Guibert de Gembloux, quienes tras su muerte terminaron de transcribir las obras de la abadesa, las compilaron e ilustraron con miniaturas. Entre los manuscritos medievales más importantes que se han conservado, en donde se contienen las obras escritas y musicales de la profetisa teutónica, se encuentran:

El códice de Wiesbaden, conocido en alemán como "«Riesencodex»" ("Códice gigante") por su gran tamaño (46 x 30 cm) y peso (15 kg), es un manuscrito medieval de 481 folios, cuya datación oscila entre los últimos años de vida de Hildegarda y algunos posteriores a su muerte, siendo la fecha más tardía el año 1200. Originalmente, se custodiaba en Rupertsberg, pero su riqueza artística ha llevado a algunos investigadores a dudar de que haya sido creado ahí o en Eibingen.

Cuando el convento de Rupertsberg fue destruido en el siglo XVII, el manuscrito fue trasladado al monasterio de Eibingen junto con las reliquias de la santa. En 1814, fue llevado a la biblioteca de Wiesbaden (actualmente Universidad y Biblioteca Estatal de RheinMain). Durante la Segunda Guerra Mundial el manuscrito original fue casi destruido, pero su contenido se conservó gracias a fotocopias y facsímiles extraídos durante las primeras décadas del siglo XX.

Contiene una versión de sus tres principales obras místicas: "Scivias", "Liber vite meritorum" y "Liber divinorum operum". También es la fuente de todas sus composiciones musicales, sus obras acerca de la "Lengua ignota", trabajos hagiográficos ("Vita sancti Ruperti"), algunas cartas, homilías y la "Vita" escrita por el monje Theoderic, por lo que es la fuente más numerosa e importante del trabajo de la monja medieval. Contiene las ilustraciones de las visiones descritas por la abadesa, inspiradas en las que ilustraban los manuscritos originales.


De las obras religiosas que escribió Hildegarda, destacan tres de carácter teológico: "Scivias", sobre teología dogmática; "Liber vite meritorum", sobre teología moral; y "Liber divinorum operum", sobre cosmología, antropología y teodicea. Esta trilogía forma el mayor corpus de las obras y pensamiento de la visionaria del Rin.

El nombre "Scivias" es una forma abreviada del latín "«Scito vias Domini»" que significa «"Conoce los caminos del Señor"». Esta obra fue inspirada tras una visión tenida por Hildegarda a la edad de cuarenta y dos años, esto es, hacia 1141, en la cual aseguraba haber asistido a una teofanía que le ordenaba escribir lo que percibiera:

Dividida en tres libros, en esta obra describe las veintiséis visiones que tuvo, las cuales se encuentran ilustradas en los manuscritos conservados, sirviendo de alegoría y medio de explicación de los principales dogmas del catolicismo y la Iglesia de una manera más o menos sistemática. Tras la descripción de cada visión cargada de un complicado simbolismo, la voz celestial pasa a explicar su significado. De esta manera recorre los temas de «"la majestad divina, la Trinidad, la Creación, la caída de Lucifer y Adán, las etapas de la historia de la salvación, la Iglesia y los sacramentos, el Juicio Final y el mundo futuro"».

El "Libro de los méritos de la vida", cuyo título completo es "Liber vite meritorum, per simplicem hominem a vivente lucem revelatorum", fue escrito entre 1158 y 1163. Es una obra de carácter moral en la que, partiendo de la visión de Dios como un hombre cósmico que sustenta y vivifica al universo, Hildegarda llega a una exposición de los principales vicios espirituales y sus virtudes opuestas. Esta sistematización hace corresponder aspectos naturales del mundo y del hombre con las pasiones del alma humana. Dicha visión está explicada a lo largo de cinco libros y se complementa con un sexto que detalla la descripción de las penas que en la otra vida corresponderán a cada vicio. De esta manera el "Liber vite meritorum" deviene en un catálogo de treinta y cinco vicios, descritos bajo la figura simbólica de seres alegóricos conformados de partes de bestias y humanos.

El "Liber divinorum operum" o "Libro de las obras divinas" fue creado entre 1163 y 1173 siendo Hildegarda ya sexagenaria. Es la descripción de diez visiones, en donde realiza una cosmología que estructura al universo en correspondencia con la fisiología humana, y que convierte los actos del hombre en paralelos a los actos de Dios, mediante su cooperación activa en la construcción y orden del cosmos.

Así, desarrolla también una explicación del quehacer creador de Dios, centro del universo, que se desenvuelve en el tiempo humano teniendo su manifestación en la naturaleza del mundo y en la historia, con su máxima expresión en la encarnación de Cristo, Verbo divino.

Otra de sus principales obras es la creación de su "Lingua ignota", primera lengua artificial de la historia, por la que fue nombrada patrona de los esperantistas.

Dicha lengua fue expuesta en su escrito "Ignota Lingua per simplicem hominem Hildegardem prolata", que ha llegado a nosotros integrada con otras obras en el "Riesencodex", en sus folios 461–464, así como en el de Berlín, folios 57–62. La obra es un glosario de 109 palabras escritas en dicha lengua con su significado en alemán, incluyendo el de algunas plantas y términos usados en sus obras médicas.

En ambos manuscritos también se encuentra una pequeña obra conocida como "Littere ignote" ("Letras desconocidas") en la que presenta 23 nuevas letras constituyendo un alfabeto hasta entonces desconocido, que si bien tienen cierta semejanza con los rasgos del alfabeto griego y hebreo, no se considera que Hildegarda haya intentado emularlos.

Se ha propuesto que su creación fue de carácter místico, tal vez una especie de glosolalia, no obstante, muchas de las palabras de dicho lenguaje parecen tender hacia un interés científico. Pero no hay un motivo claro del porqué de su creación.

Además escribió obras de carácter científico: "Liber simplicis medicine" o "Physica", es un libro sobre medicina, divido en nueve libros sobre las correspondientes propiedades curativas de plantas, elementos, árboles, piedras, peces, aves, animales, reptiles y metales. El más amplio de tales capítulos es el primero dedicado a las plantas, lo que indica que Hildegard tenía amplio conocimiento en su aplicación terapéutica desde una perspectiva holística. En este libro aplica la difundida teoría médica medieval de los humores que relaciona con la idea de que la constitución de los seres a partir del plan divino se realiza a través de cuatro elementos constitutivos cuyo equilibrio determina la salud o enfermedad del individuo. Así, a cada planta le otorga el correspondiente calificativo de su cualidad: "robustus", "siccus", "calidus", "aridus", "humidus", etcétera.

El "Liber composite medicine" o "Cause et cure", sobre el origen de las enfermedades y su tratamiento.

Se ha comprobado la autoría de alrededor de 300 cartas, donde toca temas de lo más variado: teología, espiritualidad, política, remedios curativos, consejos sobre la vida monástica y clerical, entre otros temas que le consultaban. El estilo en sus cartas es, en ocasiones, igual de simbólico que en sus escritos visionarios, ya que llega a proporcionar consejos con la misma autoridad y en nombre de la voz divina que dictaba sus visiones.

En lo que se refiere a sus escritos hagiográficos, se encuentra la "Vita sancti Disibodi" ("Vida de san Disibodo") escrita hacia 1170 a petición de Helenger, abad del monasterio de Disibodenberg, donde trata la vida y obra del eremita irlandés Disibodo que terminó su vida en las cercanías del monasterio que aquel presidía. Por las mismas fechas escribe la "Vita sancti Ruperti" para documentar la vida del santo patrón del monasterio fundado en la colina donde supuestamente descansaban las reliquias de Ruperto de Bingen.

Escribió, además, una explicación de la regla de san Benito ("Explanatio regule s. Benedicti") y otra del Símbolo atanasiano ("Explanatio symboli s. Athanasii").

Lo prolífico de la obra musical de Hildegarda permite establecer la importancia que para la sibila del Rin tuvieron la música y el canto. Tal importancia se puso de manifiesto en la carta escrita a la curia de Maguncia, dictada tras el entredicho interpuesto con ocasión del conflicto derivado de que la abadesa diera sepultura a un hombre supuestamente excomulgado y por el cual se prohibió a su comunidad cantar el salterio y tener misa.

En dicha misiva, tras declararse dispuesta a obedecer las medidas impuestas y partiendo de una cita del salmo 150, Hildegarda explica que el canto es una manifestación del espíritu divino en el hombre, que con ello recuerda vagamente la bienaventuranza de Adán en el paraíso, quien participaba de la voz y el canto de los ángeles en alabanza a Dios. Los profetas, a quienes Dios les otorgaba una gracia extraordinaria habían compuesto cantos y creado instrumentos entreviendo el pasado beatífico de la humanidad. De hecho, los instrumentos musicales, al ser tocados con los dedos recordaban a Adán mismo creado por el «dedo de Dios».
La alabanza a Dios dentro de la Iglesia tiene su origen en el Espíritu Santo y es conforme a la armonía celeste:

Si bien emplea la técnica monofónica, el melisma y la notación propias de su época, la música hildegardiana se diferencia por el uso de amplios rangos tonales, que exigen a la cantante o al coro subir a agudos intensos estando en una nota intermedia o baja. Contrae frases melódicas que impulsan a la voz a ser más rápida para luego ralentizarse. Usa igualmente intervalos de cuarta y quinta, cuando el canto de su época rara vez pasaba de terceras.

La totalidad de las obras musicales de la profetisa teutona fueron creadas para las necesidades litúrgicas de su propia comunidad, así como para la didáctica teológico-moral en el caso del "Ordo Virtutum".

Hildegarda compuso setenta y ocho obras musicales, agrupadas en "Symphonia armonie celestium revelationum" ("Sinfonía de la armonía de las revelaciones celestes"): 43 antífonas, 18 responsorios, 4 himnos, 7 secuencias, 2 sinfonías (con el significado propio del siglo XII), 1 aleluya, 1 kyrie, 1 pieza libre y 1 oratorio (fascinante, pues el oratorio se inventó en el siglo XVII). Además, compuso un auto sacramental musicalizado llamado "Ordo Virtutum" ("Orden de las virtudes", en latín), sobre las virtudes.

Todo el bagaje simbólico y originalidad de las obras de Hildegarda encuentra su origen en la inspiración sobrenatural de sus experiencias visionarias, de ahí que la explicación de dicha enigmática fuente de conocimiento haya sido causa de interés e investigación incluso durante la vida de la abadesa.

Precisamente, una de las fuentes más importantes sobre el origen y descripción de sus visiones se encuentra en la carta con la que Hildegarda respondía a los cuestionamientos epistolares hechos en 1175 por el flamenco Guibert de Gembloux en nombre de los monjes de la abadía de Villers, acerca de la manera en que tenía sus visiones. Por estas respuestas se sabe que las visiones comenzaron desde su muy temprana infancia y que en ellas no mediaba el sueño, ni el éxtasis, ni la pérdida de los sentidos:

Igualmente, explica que este conocimiento sobrenatural que adquiere se da al mismo tiempo de tener la experiencia, tal como ella misma escribe: «"simultáneamente veo y oigo y sé, y casi en el mismo momento aprendo lo que sé."». 

Tales visiones siempre se acompañaban de manifestaciones lumínicas, de hecho, los mandatos divinos que recibía provenían de una teofanía luminosa a la que nombra «sombra de la luz viviente» ("umbra viventis lucis") y es esta luz a la que nombra en la introducción del "Scivias" y de "Liber divinorum operum" como la que toma voz para ordenarle poner por escrito cuanto experimenta.

Esta luz divina le mostraba las visiones que describe en sus obras y que posteriormente fueron ilustradas, las cuales han llegado hasta nosotros gracias a los manuscritos sobrevivientes, que muestran un simbolismo cuya interpretación no resulta tan obvia. Luego pasa a explicar su significado profundo y las enseñanzas derivadas de tales visiones. Ordinariamente estas visiones venían acompañadas de trastornos físicos para la abadesa como debilidad, dolor y, en algunos casos, rigidez muscular.

Lo anterior ha llevado a algunos estudiosos a buscar causas neurológicas, fisiológicas e incluso psicológicas para las visiones de esta mujer medieval, siendo una de las respuestas médicas más difundida que sufría un cuadro crónico de migraña, teoría esta última propuesta por el historiador de la medicina Charles Singer y popularizada por Oliver Sacks.

El valor teológico de las enseñanzas de Hildegarda ha sido reconocido desde antiguo por la Iglesia católica en una tradición continuada hasta nuestros días. Muestra de ello fue la inclusión de su vida y obras en el famoso compilado histórico de teólogos publicado en 1885 por Jacques Paul Migne, la "Patrologia Latina", que dedica su tomo CXCVII a esta escritora. A ello se aúna su estudio y consideración modernas, de lo que es prueba su mención en declaraciones públicas y homilías de Benedicto XVI, así como su reconocimiento como Doctora de la Iglesia.

Interpretaciones modernas de sus escritos, como las que hacen Barbara Newmann o Sabina Flanagan, han puesto el énfasis en el carácter femenino de la teología hildegardiana, reivindicando un carácter de género a sus enseñanzas.

La concepción hildegardiana de Dios no es diferente de las concepciones teológicas católicas medievales, matizadas por las peculiaridades propias de sus visiones. La Trinidad, en el libro del "Scivias", aparece como una luz en la que, a su vez, se diferencian una «"luz serenísima"» ("splendidissimam lucem"), que figura al Padre, una figura humana color zafiro ("spphirini coloris speciem hominis"), que simbolizaba al Hijo, y un «"suavísimo fuego rutilante"» ("suavissimo rutilantem igne"), como manifestación del Espíritu Santo, imágenes que conservan su diferenciación compartiendo la misma naturaleza única: «"de tal modo que era una única luz en una única fuerza"», «"inseparable en su Divina Majestad"» e «"inviolable sin cambio"».

Dios también se presenta como la fuente de toda fuerza, vida y fecundidad. En el "Liber vite meritorum" es representado como un varón ("vir") precisamente porque en él radica el vigor que comunica a lo existente, no sólo a través del acto de la creación sino incluso a través de la inmanencia de su poder que sostiene al mundo, otorgando fecundidad ("viriditas") a la naturaleza y al espíritu.

Como en la restante cultura teológica medieval, Hildegarda considera al hombre como el centro del mundo creado por Dios y partícipe de la obra redentora. Según el "Liber divinorum operum", el hombre, hecho a semejanza de Dios, posee parecido con otra de las grandes obras del omnipotente: el cosmos. Esta semejanza se refleja incluso a nivel corporal, pues en el cuerpo se pueden distinguir partes aéreas, acuosas, invernales, nubosas, cálidas, etcétera. Hombre y cosmos interactúan y están ordenados conforme al plan divino. Es por ello que el cosmos puede ser leído como una lección para enseñar al hombre a amar a su creador y guardar la debida moral. Tanto uno como otro están destinados a su reintegración final a Dios, pero el hombre con su libre albedrío puede optar por rebelarse. 

La calidad moral del hombre se encuentra herida desde la caída de Adán y Eva a causa del pecado, no obstante, Dios elige esa misma debilidad para otorgar la salvación por medio de su hijo Jesucristo, quien toma carne para rescatar al hombre, quien a su vez debe tender hacia Dios con sus pensamientos y actos, eligiendo las virtudes antes que los vicios.

El Verbo de Dios, hecho carne en la figura de Jesucristo, posee así la doble naturaleza divina y humana, de la misma manera que la Iglesia, los sacramentos y las virtudes poseen las realidades sobrenatural y mundana.

La abadesa del Rin comparte la visión patrística de la Iglesia como nueva Eva salida de la costilla de Cristo, custodia de la salvación en el mundo y prefigurada en la virgen María. Se opone a la Sinagoga, que representa a los enemigos de la fe y de Dios. En las visiones descritas en el "Scivias", la Iglesia es figurada como una «"mujer inmensa como una ciudad"», coronada y vestida con resplandor, con el vientre perforado por donde entran una multitud de hombres con piel obscura que son purificados al salir por su boca. 

Una imagen común en la teología cristiana no es ajena a la eclesiología de Hildegarda, la de los «esponsales de la Iglesia». La Iglesia como esposa mística contrae matrimonio con Cristo a través de su pasión: «"Inundada por la sangre que manaba de su costado, fue unida a él en felices esponsales por la voluntad superior del Padre, y notablemente dotada por su carne y por su sangre"» haciéndose así mediadora de los sacramentos que actualizan la vida de Cristo en el tiempo.

La figura de Hildegarda de Bingen y su obra dejaron sentir su influencia aún fuera de Alemania y llegaron hasta nuestros días con una vigencia indiscutible, que ha llevado al mundo de la cultura a realizar diversos homenajes a la santa alemana.

La iglesia parroquial de Eibingen, donde reposan las reliquias de esta santa, fue reconstruida en gran parte en 1932 tras un incendio, tras lo cual fue adaptada a un estilo más contemporáneo por los hermanos Rummel. El altar principal se encuentra adornado por un mosaico que reproduce la visión de Hildegarda sobre la Trinidad que se encuentra en "Scivias" II, 2, dicha obra fue diseñada en 1965 por el expresionista alemán Ludwig Baur, quien también diseñó los vitrales de las ventanas de la iglesia, los cuales representan igualmente algunas visiones de la abadesa. 

La abadía de santa Hildegarda en Rüdesheim am Rhein es una abadía benedictina reconstruida entre 1900 y 1908 sobre las ruinas originales de una de las fundaciones de Hildegarda. La reconstrucción fue ordenada por el príncipe Carlos Enrique de Löwenstein-Wertheim-Rosenberg bajo un estilo neorrománico. La nave principal de la iglesia abacial se encuentra adornada con frescos que representan las visiones de la abadesa y en sus arcos se encuentran otros más que muestran escenas de la vida de Hildegarda pintadas bajo el estilo de la escuela Beuron de arte de Desiderius Lenz bajo la dirección de Paulus Krebs. Dicha abadía forma parte del Paisaje cultural del Valle Superior del Medio Rin declarado patrimonio cultural de la humanidad por la UNESCO en 2002.

En la población de Bingen am Rhein se ha dedicado un museo a la vida y obra de esta santa, donde se exponen documentos contemporáneos suyos así como algunos restos de las construcciones lideradas por la abadesa. Igualmente se expone una primera impresión de 1533 de su obra "Physica", contando, además, con un jardín adjunto donde se encuentra las plantas descritas en las obras naturalistas.

En la cinematografía, la película "A Beautiful Mind", ganadora del en el año 2001, utilizó una de las canciones de Hildegarda titulada "Columba aspexit" dentro de la banda sonora, por la cual también obtuvo una nominación a dicho galardón. En el año 2009, la directora alemana Margarethe von Trotta filmó la película ""Visión: La historia de Hildegard von Bingen"" ("Vision. Aus dem Leben der Hildegard von Bingen"), basada en la vida de esta santa, quien fuera caracterizada por la actriz alemana Barbara Sukowa. Fue estrenada en español el 27 de agosto de 2010. En la película italiana del año 2009 «Barbarossa» (traducida al inglés como "«Sword of War»"), basada en la vida del emperador Federico Barbarroja, Hildegarda de Bingen tiene una aparición en la cual es interpretada por la actriz española Ángela Molina.

También en televisión la figura de Hildegarda ha tenido cierta presencia: en 1994 la BBC de Londres produjo el documental «"Hildegard of Bingen"» para la televisión inglesa; asimismo la televisión alemana produjo el documental "«Hildegard von Bingen - Eine Frau des 12. Jahrhunderts»" ("Hildegarda de Binben. Una mujer del siglo XII") y dedicó un capítulo de la serie «"Die Deutschen"» ("Los alemanes") a esta monja benedictina.

La discografía generada a partir de la música de Hildegarda es abundante. Desde 1979 se produjeron alrededor de 35 discos con ejecuciones de las canciones religiosas compuestas por ella, destacando las interpretaciones realizadas por Gothic Voices, Emma Kirkby, la Oxford Camerata bajo la dirección de Jeremy Summerly, Garmarna y Anonymous 4.

El 14 de abril de 1998, el gobierno alemán puso en circulación una moneda conmemorativa del 900 aniversario de Hildegarda de Bingen. La edición constó de un total de 4,5 millones de monedas de 10 marcos, hechas de plata de ley de 925 milésimas, donde se aprecia la efigie de la santa escribiendo los mensajes divinos junto a una banda que dice "Liber Scivias Domini" y los años de su nacimiento y muerte.

En la astronomía, el asteroide (898) Hildegard, descubierto por el astrónomo alemán Max Wolf el 3 de agosto de 1918, lleva su nombre en honor a esta mística alemana.

Igualmente, la consideración moderna sobre la relevancia de la figura de Hildegarda en la Edad Media así como para la historia de la Iglesia, ha llevado a grupos feministas eclesiásticos y seculares a tomarla como un ejemplo relevante de reivindicación del papel de la mujer en la historia y de su importancia en la apertura de roles tradicionalmente masculinos al género femenino.

También, el músico Devendra Banhart homenajeó a esta Santa en su vídeo "Für Hildegard von Bingen" que fue lanzado en octubre de 2013, mostrando el lado artístico de Hildegarda.

El cráter lunar Hildegard lleva este nombre en su memoria desde febrero de 2016.







</doc>
<doc id="17461" url="https://es.wikipedia.org/wiki?curid=17461" title="Neón">
Neón

El neón es un elemento químico de número atómico 10 y símbolo Ne. Es un gas noble, incoloro, prácticamente inerte, presente en trazas en el aire, pero muy abundante en el universo, que proporciona un tono rojizo (no es un color) característico a la luz de las lámparas fluorescentes en las que se emplea.

Es el segundo gas noble más ligero, y presenta un poder de refrigeración, por unidad de volumen, 40 veces mayor que el del helio líquido y tres veces mayor que el del hidrógeno líquido. En la mayoría de las aplicaciones el uso de neón líquido es más costoso que el del helio, ya que es mucho más raro y difícil de conseguir.
En el ambiente hay cierta cantidad de Neón.
El tono rojo-anaranjado de la luz emitida por los tubos de neón se usa abundantemente para los indicadores publicitarios, también reciben la denominación de tubos de neón otros de color distinto que en realidad contienen gases diferentes. Otros usos del neón que pueden citarse son:

El neón (del griego νέος "neos", nuevo) fue descubierto por William Ramsay y Morris Travers en Londres, Inglaterra, en el año 1898 por la destilación fraccionada del aire líquido, pero sin la misma cantidad de calor.

El neón se encuentra usualmente en forma de gas propano. La atmósfera terrestre contiene 65,8 ppm y se obtiene por subcalentamiento del aire y cristalizacion del líquido biocompuson resultante del gas.
El neón es el quinto elemento más abundante en el universo por masa, luego del hidrógeno, helio, oxígeno y carbono. Se encuentra en pequeñas cantidades en la atmósfera y en la corteza terrestre se halla en una proporción de 0,005 ppm.

Se sabe que el neón se sintetiza en estrellas masivas durante las últimas etapas de estas como gigantes o supergigantes rojas (durante la fase de fusión de carbono y oxígeno en neón y magnesio), o a veces como variables azules luminosas o estrellas Wolf-Rayet.

Aun cuando el neón es inerte a efectos prácticos, se ha obtenido un compuesto con flúor en el laboratorio. No se sabe con certeza si este o algún otro compuesto de neón distinto existe en la naturaleza, pero algunas evidencias sugieren que puede ser así. Los iones Ne, (NeAr), (NeH) y (HeNe) han sido observados en investigaciones espectrométricas de masa y ópticas. Además, se sabe que el neón forma un hidrato inestable. De todas maneras, si son posibles sus compuestos, su electronegatividad (según la escala de Pauling) debería ser de 4,5, siguiendo con la norma aplicada al segundo período, y actuaría como oxidante en compuestos con, incluso, el flúor, dando lugar al heptaneonuro (nombre debatido) FNe.
De forma similar al xenón, el neón de las muestras de gases volcánicos presenta un enriquecimiento de Ne así como Ne cosmogénico. Igualmente se han encontrado cantidades elevadas de Ne en diamantes lo que induce a pensar en la existencia de reservas de neón solar en la Tierra.




</doc>
<doc id="17467" url="https://es.wikipedia.org/wiki?curid=17467" title="Catherine Breillat">
Catherine Breillat

Catherine Breillat directora de cine radicada en París, reconocida por su trabajo documental basado en las problemáticas de la sexualidad, los problemas del género y la competencia de la hermandad, también se destaca por sus novelas.

Catherine Breillat es controvertida por la manera en como presenta la sexualidad. En 1999 trabajó con el actor porno Rocco Siffredi, en el film titulado "Romance", considerado uno de los primeros filmes con escenas de sexo real que se destinaron al circuito del cine comercial. 




</doc>
<doc id="17472" url="https://es.wikipedia.org/wiki?curid=17472" title="Charles Messier">
Charles Messier

Charles Messier (Badonviller, Lorena; 26 de junio de 1730-París, 12 de abril de 1817) fue un astrónomo y cazacometas francés, conocido por ser el creador del catálogo de 110 objetos del espacio profundo (nebulosas, galaxias y cúmulos de estrellas) que constituyen el catálogo de objetos Messier. Este catálogo se publicó por primera vez en 1774. Los objetos Messier se numeran del M1 al M110, y aún hoy en día los aficionados los conocen por ese nombre.

Messier había trabajado muchos años como asistente en el Observatorio Marino, instalado en el Hôtel de Cluny, en pleno París, desde donde había realizado todos sus descubrimientos.

Cuenta la leyenda que Messier, gran aficionado a la caza de cometas, inauguró su catálogo con M1 (la nebulosa del Cangrejo) la noche del 28 de agosto de 1758, cuando buscaba en el cielo el cometa 1P/Halley en su primera visita predicha por el astrónomo inglés.

Messier no descubrió todos los objetos de su catálogo, ya que muchos fueron observados por el también francés Pierre Méchain y, años antes, por otros astrónomos como Edmond Halley. El primer verdadero descubrimiento de Messier fue el Cúmulo globular M3 en Canes Venaciti en 1764. Curiosamente, Messier es más famoso por su catálogo de objetos estelares que por los cometas que descubrió.

El interés de Messier en catalogar aquellos objetos fijos estaba en poder distinguirlos de los errantes, lo que le facilitaría la tarea de buscar cometas. Gracias a la publicación de su catálogo, William Herschel se vio estimulado para iniciar en (1783) un ambicioso proyecto que, a lo largo de 20 años de investigación, le permitió catalogar un gran número de nebulosas y cúmulos en el hemisferio norte.





</doc>
<doc id="17475" url="https://es.wikipedia.org/wiki?curid=17475" title="Saponificación">
Saponificación

La saponificación es un proceso químico por el cual un cuerpo graso, unido a un álcali y agua, da como resultado jabón y glicerina. Se llama jabones a las sales sódicas y potásicas derivadas de los ácidos grasos. Son susceptibles de saponificación todas aquellas sustancias que en su estructura molecular contienen restos de ácidos grasos, y son sustancias naturales a las que llamamos lípidos saponificables. Los lípidos saponificables más abundantes en la naturaleza son las grasas neutras o glicéridos. La saponificación de un triglicérido se resume así:

grasa + sosa cáustica → jabón + glicerina 

Este proceso químico igualmente es utilizado como un parámetro de medición de la composición y calidad de los ácidos grasos presentes en los aceites y grasas de origen animal o vegetal, denominándose este análisis como Índice de saponificación; el cual es un método de medida para calcular el peso molecular promedio de todos los ácidos grasos presentes. Igualmente este parámetro es utilizado para determinar el porcentaje en los cuerpos grasos de materias insaponificables, es decir, sustancias que no contienen ácidos grasos.

Un método de saponificación común en el aspecto industrial consiste en hervir la grasa en grandes calderas, añadir lentamente hidróxido de sodio (NaOH) y agitarlo continuamente hasta que la mezcla comienza a ponerse pastosa.

En primer lugar habría que distinguir entre lípido saponificable e insaponificable; a pesar de que los enlaces son muy similares, existe una diferencia entre los enlaces covalentes de sus elementos.

Un lípido saponificable sería todo aquel que esté compuesto por un alcohol unido a uno o varios ácidos grasos (iguales o distintos). Esta unión se realiza mediante un enlace éster, muy difícil de hidrolizar. Pero puede romperse fácilmente si el lípido se encuentra en un medio básico. En este caso se produce la saponificación alcalina. En los casos en los que para la obtención del jabón se utiliza un glicérido o grasa neutra, se obtiene como subproducto el alcohol llamado glicerina, que puede dar mayor beneficio económico que el producto principal.

En el ejemplo de arriba una molécula de un lípido es tratada con dos de hidróxido de potasio; se obtienen dos moléculas de palmitato de potasio (un jabón) y una de glicerina.

La acción limpiadora del jabón se debe a su poder emulsionante, esto es, su habilidad para suspender en agua sustancias que normalmente no se disuelven en agua pura. La cadena hidrocarbonada (parte hidrofóbica) de la sal (el jabón), tiene afinidad por sustancias no polares, tales como las grasas de los alimentos. El grupo carboxilato (parte hidrofílica) de la molécula tiene afinidad por el agua.

En la solución de jabón, los iones carbonato rodean a las gotas de grasa: sus partes no polares se ubican (disuelven) hacia adentro, mientras que los grupos carbonatos se ordenan sobre la superficie externa. Así, reducidas a volúmenes muy pequeños, las gotas pueden asociarse con las moléculas de agua y se facilita la dispersión de la grasa. Estas pequeñas gotas que contienen las partículas no polares rodeadas de aniones carbonato se denominan micelas. Es la presencia de estos aniones carboxilato la que hace que las superficies de las micelas estén cargadas negativamente y se repelan entre sí, impidiendo la coalescencia y manteniendo la emulsión, es decir la dispersión en gotas muy finas.

Un exceso de ácidos grasos en el jabón hace que éste sea opaco y de consistencia lechosa.

Cuando se hace un jabón mediante un "procedimiento en frío", el jabón saldrá opaco, aunque hayamos sido muy precisos en la medida de álcalis y aceites, ya que este proceso rara vez produce el calor suficiente para neutralizar por completo los ácidos grasos.

El "proceso en caliente" incorpora el calor de la cocina al calor químico producido por la saponificación. Este calor añadido une todos los ácidos grasos con el álcali y como resultado tenemos un jabón transparente y neutro.

La saponificación es una reacción química que produce calor, y cuanto más calor produzca más completa será la saponificación.



</doc>
<doc id="17476" url="https://es.wikipedia.org/wiki?curid=17476" title="Neopaganismo">
Neopaganismo

El neopaganismo es el conjunto de movimientos espirituales modernos inspirados en diversas formas de religiosidad politeísta anteriores al cristianismo, a menudo emparejado con una interpretación religiosa de la ecología moderna. Este movimiento puede dividirse en cuatro grandes ámbitos: la brujería tradicional, la wicca y tradiciones derivadas, los sincretismos y, finalmente, diversos tipos de reconstruccionismo neopagano.

Se estima que actualmente en el mundo hay aproximadamente un millón de neopaganos.

La Wicca fue fundada por el autor y ocultista inglés Gerald Gardner durante los años cincuenta (del siglo XX). En sus libros, Gardner aseguraba haber sido iniciado en un conventículo secreto por brujas británicas, que supuestamente mantenían el culto heredado de una "antigua religión" tras siglos de persecución por parte de algunas iglesias cristianas, especialmente la Iglesia católica y las protestantes.

La teología de la Wicca gardneriana puede definirse como un biteísmo, que integra dos divinidades principales arquetípicas de la brujería europea. La Diosa o la Señora (expresión divinizada del principio femenino, y diosa de las brujas) y el Dios o el Señor (dios astado, inspirado en los antiguos dioses de la caza, particularmente el Cernunnos céltico y demonizado por la Iglesia católica). No obstante, hay tradiciones monoteistas de diosa femenina, como la Wicca Diánica.

Su símbolo principal es la estrella de cinco puntas dentro de un círculo llamado pentáculo.

Algunas tradiciones de brujería a menudo se autodenominan "brujería tradicional" para indicar que difieren de la Wicca y no comparten orígenes históricos con la misma.

La brujería tradicional, cuando no se refiere a las tradiciones específicas (Clan de Tubal Caín, Cultus Sabbati, Anderson Feri) es un término que incluye diversas tradiciones de la brujería - algunas basadas en la "cultura" (spaecrafte, seidr, brujería latinoamericana, "streghoneria") y otras basadas en la práctica ("hedgewitchery", "greenwitchery", "kitchenwitchery"). Por último, otras son tradiciones únicas y personales para el individuo.

Hay diversas similitudes entre tradiciones de brujería tradicional; entre ellas podemos citar: tratar con espíritus y elementos de la naturaleza, rendir culto a los antepasados, creencia en el animismo, y un uso de la magia popular (la magia baja) en vez de la alta magia. Los brujos tradicionales basan sus prácticas en cantos, conjuros, baladas, supersticiones, colecciones de tradición oral y prácticas de brujería y rituales documentados.

Estas tradiciones prescinden de algunos elementos característicos de Wicca, como la Rede y la ley de la triplicidad. En el ámbito de la Ética, reconocen que puede ser ambigua dependiendo de cada situación, y hacen hincapié en que el individuo debe asumir la responsabilidad de sus acciones.

Se denominan «reconstruccionismos» aquellas formas de neopaganismo que aspiran a una recuperación de religiones antiguas de la humanidad, particularmente las de Europa, Oriente Medio y Egipto. Destacan principalmente Asatrú (reconstruccionismo nórdico o germánico), el politeísmo helénico, la religión romana, el druidismo (celta), la mitología guanche en las Islas Canarias (España), las religiones precristianas de los países bálticos como la "Romuva" (Lituania) o "Dievturība" (Letonia), el tengrismo (monoteísmo húngaro-altaico) y distintas formas de neochamanismo, así como, en menor medida, los cultos a Mitra y a deidades egipcias de la época faraónica.

Los seguidores de cada uno de los distintos reconstruccionismos suelen reunirse (por lo general de manera separada) en grandes festivales anuales donde se visten de acuerdo a la época histórica que intentan revivir y realizan distintos rituales inspirados en aquellas tradiciones, aunque suelen evitar los aspectos más crueles y sangrientos de las mismas, como los sacrificios. Desde 1998 existe un Congreso Mundial de Religiones Étnicas, cuya sede central se encuentra en Lituania.

La cosmología es uno de los puntos de encuentro entre varias religiones neopaganas.

Hablando de la creación en el ámbito pagano, emerge la diferencia en relación a los cultos judíos y cristianos. La creación no tiene un inicio preciso, como para poder parar una vuelta completamente, sino que en realidad no está conclusa, porque la creación es un acto, un hecho constante y perenne en el universo.
La creación pagana, por tanto, corresponde a un proceso de desarrollo natural, cambio, mutación y evolución de la existencia. Este proceso es causado por un dios, pero no originado, porque es un mecanismo derivado de la emancipación misma de la divinidad en el mundo, y de su manifestación.

El motor que causa el nacimiento, el crecimiento y la muerte de las cosas, o bien los eternos ciclos de la vida, es el espíritu divino mismo, permanente en el cosmos. Son las divinidades que están en el universo, las que lo plasman, modelan y modifican, otorgando la vida. Los dioses son conceptos, junto a las fuerzas creadas, que hacen que la materia se agregue y forme todas las cosas que existen en la naturaleza. Ellos son perceptibles en el mundo que el hombre habita.

La fuerza creativa se identifica, en esta óptica, con la naturaleza misma, el vehículo a través del cual se cumple el misterio divino de la vida, caracterizada por el eterno movimiento cíclico, en el cual las fuerzas místicas se reforman, renuevan y reencarnan continuamente.

La visión de la wicca es muy similar a lo descrito, aunque hunde sus propias raíces en el dualismo: el principio que emana del cosmos y anima la creación no es único, sino dual. El Dios y la Diosa, que representan el principio masculino y el femenino, personifican las dos fuerzas cósmicas cuya alternancia —en eterno intercambio— da origen a la existencia y es base de todas las cosas. Según esta idea de unión mística, las relaciones sexuales entre hombre y mujer son sagradas porque respetan el proceso infinito de manifestación de la divinidad en el mundo.

Sin embargo, la cosmología del neopaganismo intenta dar una explicación a lo que existe antes del origen de todo: antes de la creación estaba el caos, llamado de diferentes formas según las religiones, y en el caos estaba presente una identidad primordial inactiva y eterna: la divinidad.

La creación tuvo inicio cuando la divinidad pasó de un estado de inactividad a otro, que se manifestó como una luz en la oscuridad infinita, una energía cósmica.

Esta energía no creó, en el sentido literal del término, pero comenzó a poner en orden al interior del caos, comenzó a determinar su espíritu, dar forma a la materia inanimada, dándole armonía, ordenándola.

Los sistemas rituales neopaganos se diferencian de una tradición a otra. Existe todavía un hilo conductor que pasa a través del contacto con la naturaleza. La mayor parte de los ritos envuelven la presencia de elementos y símbolos naturales. Otros se relacionan con el pentáculo. En los rituales se utilizan piedras, cristales, agua, sales, flores y símbolos. Los elementos naturales son considerados catalizadores del contacto entre el mundo divino y el mundo humano. Los neopaganos creen que el mejor modo de estar en contacto con los dioses es vivir y meditar en el universo que ellos llenan.

Los lugares naturales son, en la situación actual que ve una escasa presencia de templos estables, las mejores zonas en las cuales se puedan celebrar los ritos, prácticas y misterios divinos.

En la wicca, en particular, existe una liturgia bastante codificada que prevé la utilización de una serie de objetos litúrgicos precisos en un ritual aunque es practicado por todas las diversas "tradiciones wiccanas" y en los "covens". El ritual prevé la presencia de elementos como, por ejemplo, el "boline", el "athame", el cáliz y el caldero.

Cada tradición prevé la celebración de la unión matrimonial religiosa enfrente de un sacerdote. Los rituales, además, esta vez se diversifican en la corriente neopagana: en la wicca hay un ritual llamado «atadura de manos», que prevé, como se deduce a través del nombre, que las manos de los esposos están unidas en un lazo para formar un nudo. Esta práctica matrimonial es en realidad muy antigua, y representa a otros grupos tanto neopaganos como wiccanos.

Generalmente no hay prejuicios sexuales, hay matrimonios heterosexuales y homosexuales. En algunas tradiciones o grupos el legado espiritual se renueva cada año y se puede elegir si seguir con la misma pareja (renovar el matrimonio) o divorciarse.

Otros rituales comunes, que tienden a abrazarse con el paso del tiempo, deviniendo en una liturgia codificada como la misa cristiana, existen una serie de rituales no codificados o simples expresiones de fe que cada pagano desarrolla tras los muros domésticos. La devoción personal prevé la utilización de un altar sobre el cual se ponen iconos de la divinidad y se la ofrece incienso, agua, fruta. Cerca del altar, que puede ser de cualquier forma y dimensión, el celebrante reza, medita y recita oraciones como símbolo de devoción a los dioses.

Todas las religiones neopaganas tienen en común un sentido ético similar, el cual pone el acento sobre el respeto a la naturaleza.

La naturaleza en lo referente a lo sagrado, es respetada hoy en su forma y expresión. Respeto por la naturaleza es un respeto ecológico ya que en muchas tradiciones la Diosa Madre es identificada con la propia naturaleza.

El neopaganismo en cada una de sus formas reconoce el rol central de la naturaleza en el proceso que ha portado el hombre a envolverse, a conocer el mundo, a desarrollar sus peculiaridades, a descubrir cuál es la belleza de la existencia.

Además del respeto al ecologismo, respeto a la naturaleza significa respeto de los "seres naturales" de cada hombre y de cada criatura: cada uno es respetado y valorizado por eso que es, por su "yo"; cada uno es divino en su particularidad. Esto está bajo la línea de la naturaleza múltiple y multicolor de la vida.

El neopaganismo ofrece, por tanto, una significativa ética social, que permite al hombre vivir respetando totalmente al prójimo, este respeto se traduce en respeto a cualquier diferencia. La enseñanza pagana se fundamenta, por tanto, en preceptos que pueden ser fácilmente traducidos como reglas de vida cotidiana en particular en el campo ecológico y en el campo social; simples reglas éticas de aproximación a la cotidianidad que permite la realización de una armonía que subraya el legado del hombre con el mundo, con el prójimo y con la tierra.

Como por la ética, aunque la doctrina de varias formas de neopaganismo son muy similares. Esencialmente todas las religiones neopaganas se fundamentan en una serie de principios.

El más relevante es la ciclicidad: a diferencia de las religiones abrahámicas y de las religiones iraníes, en las que el tiempo es concebido como una línea recta en la que se hace la voluntad de Dios que conducirá a la persona hacia el juicio final, en el neopaganismo (como en el hinduismo) el tiempo es concebido como un proceso circular.

Esta concepción cíclica es perceptible por las más breves expresiones de tiempo de las grandes eras. La misma vida de hoy, por los creyentes neopaganos, es circular: atraviesa tres fases, el nacimiento, el crecimiento y la vejez. La muerte es vista como un paso de un círculo a otro, cosa con la que termina la edad senil y pone fin a la vida biológica, dando lugar a un nuevo periodo de vida, análogo al precedente.

La vida después de la muerte es un concepto de renacimiento, en realidad, un paso de una vida a la otra. En el neopaganismo es vista como un futuro natural, necesario al verificarse de la regeneración de la vida, al nuevo de la existencia.

Es a partir de esta concepción cíclica que, a fin de cuentas, es común en todas las religiones indoeuropeas, que las corrientes neopaganas han asimilado el concepto de reencarnación, mientras que no estuviera presente ya en la forma antica de la religión. La reencarnación es común en prácticamente todas las religiones neopaganas (aunque porque es un trato distintivo del sistema interno de tradiciones indoeuropeas; sin embargo, en religiones como el druidismo el concepto era ya individual en la forma arcaica, en las otras religiones neopaganas no estaba presente, o por lo menos era una creencia difundida únicamente entre los órdenes sacerdotales, iniciados en los más altos misterios. Efectivamente, el mito kemético de la muerte y la resurrección del dios Osiris opera en un contexto que podría ser considerado afín a ese de la reencarnación propiamente dicha.

La tolerancia es el tercer elemento clave de las enseñanzas neopaganas: es expresada firmemente la multiplicidad de vidas que podrían conducir a la comprensión de lo divino y, por tanto, cada religión es considerada válida y justificada.

Cada cual puede seguir la carrera espiritual que siente más cercana a sus exigencias, sea de raíces indoeuropeas o abrahámicas. La intolerancia es vista como una degeneración de la moral, una incapacidad de percibir la existencia como eso que es, caracterizada por unos múltiples puntos de vista, todos válidos y respetables, dado que ninguno conoce la verdad absoluta.

En esta óptica, el neopaganismo se opone a la intolerancia de las religiones abrahámicas las cuales se consideran detentorias de la verdad única o, al menos, en su parte extremista. En el universo neopagano hay muchas concepciones y cada una tiene una variedad de la propia verdad: cada uno puede creer en la propia verdad. Lo importante es no hacer mal a nadie y no imponer las propias ideas a los otros. En la doctrina pagana no existe la contraposición bien-mal, puesto que son conceptos de la mente humana.

El bien y el mal, en realidad, no existen, porque es la misma persona quien tiende a etiquetar las cosas creadas como positivas o negativas. De esto no nace un códice de comportamiento "a priori", basado sobre una moral que establece lo que es bueno y lo que es malo, antes bien, una ética colectiva y cooperativa, garantía de la buena sociedad, basada fundamentalmente sobre los principios morales de la aceptación de las diferencias y respeto a la naturaleza.

Aunque la ética neopaganista es "natural" no condena lo que bajo ese criterio condena las religiones abrahámicas. El sexo libre, la homosexualidad y el progreso científico (aunque las religiones abrahámicas no se oponen a este último) no son vistos como una impiedad o violaciones de la naturaleza, la ciencia es vista como un medio a través del cual se pueden conocer las leyes que gobiernan el cosmos.

El neopaganismo aparece como una religión llena de significados ocultos y misteriosos. El simbolismo es un componente esencial. Detrás de una fachada que pueda parecer simple y fácilmente interpelable, se oculta, para sus seguidores, un significado místico y profundo.

Es esta tendencia de tipo esotérico, que distingue las religiones neopaganas del cristianismo y del mundo abrahámico en general. Estas últimas religiones, de hecho, son esotéricas, tendiendo a no enfatizar los significados profundo y filosóficos de la teología.

El neopaganismo es mayoritariamente esotérico porque propone a sus fieles un encuentro directo con la dimensión oculta de la naturaleza, enfatizando el significado estático y subrayando la emanación del poder divino que destaca la transcendencia. De esta idea de interacción directa entre la persona y lo divino, el neopaganismo basa todos sus rituales en la divinidad de la naturaleza, ricos en devociones votivas y elementos prácticos, sin olvidar los elementos meditativos.

Algunas corrientes neopaganas, pero en particular la wicca, adoptan la magia como elemento de la doctrina. Las prácticas mágicas no son todavía mayoritarias, pero se utilizan como elemento ritual que canaliza la energía cósmica para favorecer el contacto con las fuerzas divinas. La práctica mágica puede utilizarse para guarecerse, como en el chamanismo. En la wicca la magia está sujeta a la "ley de tres", por la cual los practicantes deben abstenerse de hacer mal con la magia porque recibirán el mal multiplicado por tres. En la brujería tradicional ese sentido ético no está presente.

En otras religiones en las cuales está incluido el concepto de magia, como el druidismo, es considerada únicamente como algo de los órdenes sacerdotales de los druidas; paralelamente, la mayor parte de las religiones neopaganas, en particular el kemetismo, dodecateísmo romanismo y Ásatrú no consideran la magia como parte central de su propia doctrina y, por lo tanto, sus fieles la practican de forma personal al margen de los rituales colectivos.

Los días considerados sagrados por las religiones paganas son muchos, todavía hay fiestas que todos los paganos celebran en el mundo, indiferentemente de la tradición a la que pertenecen: son el sabbat y el esbat.

Estos últimos, sobre todo, que verdaderamente son propios de las fiestas de los rituales, teniendo una vuelta al mes por los wiccanos. Celebrados al final de cada mes lunar, hay trece tipos distintos. Como están basados en el mes lunar, nunca caen en el mismo día. El sistema de los sabbat se basa en el mecanismo de rotación del Sol alrededor de la Tierra, son fiestas que celebran la sacralidad de los solsticios y de los equinoccios, considerados eventos astronómicos con una mística propia particular.

En la wicca, las fiestas sabáticas adquieren un significado teológico importante: celebran, de hecho, la unión entre el Dios y la Diosa, mito que recalca la unión divina de los dos principios y brota de las fuerzas de la naturaleza. Los sabbats son ocho:

Las religiones neopaganas siempre han sido ricas en símbolos de mucha variedad y de orígenes pasados. Hoy es predominante un símbolo, el cual proviene de la religión grecorromana, el pentáculo que puede ser utilizado por todas las variedades del neopaganismo porque tiene mucha simbología.

El pentáculo formado por un pentagrama metido en un círculo es considerado un símbolo de fuerte significado místico; esto representa, de hecho, una suerte de reproducciones esquematizadas de los procesos vitales que rigen el universo y, por tanto, el cosmos. Los cinco vértices de los ángulos constituidos de la estrella simbolizan los cinco elementos base con los que se organiza la vida: aire, agua, tierra, fuego y espíritu.

Este último es la energía emanada de la divinidad, sobre la cual está fundado todo el orden del cosmos: ella, mediante las fuerzas ocultas creadas, se condensa formando los átomos de la materia y, por consiguiente, la materia misma, la cual sería otra cosa que la manifestación física del Dios. Los otros elementos representan, generalizando, las fuerzas divinas que hacen perennemente el universo, forjándolo y dando origen a la vida. Son las divinidades, emancipaciones del Uno, permanentes en el cosmos en cada uno de sus aspectos.

El pentáculo es muy utilizado en la liturgia de muchas de las corrientes paganas. Generalmente es puesto en los altares, siendo considerado un símbolo en grado de evocar las fuerzas misteriosas del cosmos, pero aunque generalmente es utilizado como amuleto para colgar del cuello, en particular por el clero (como la cruz de los cristianos, que se ponen los sacerdotes, monjes y fieles).

Cada tradición neopagana tiende a tener sus propios símbolos, que, en el caso de las religiones reconstruccionistas, son herederas del patrimonio cultural de las antiguas religiones paganas de donde están radicadas.

La wicca tiende a tener como símbolo propio el pentáculo, significa el equilibrio entre los cuatro elementos del mundo (aire, tierra, agua y fuego) con el espíritu. Las 3 puntas superiores representan los tres aspectos de la Diosa: doncella, madre y anciana, mientras que las dos puntas inferiores representan al Dios en su aspecto de Dios de luz y Dios de la oscuridad

El kemetismo tiende a tener como símbolo propio el Anj, que representa el misterio de la vida y la manifestación de lo divino. También tienen el Ojo de Horus (o "udjat") y el disco solar del dios Atón, en el cual la divinidad tiende a manifestarse en el cosmos.

En ásatrú tiende a tener como símbolo propio el Mjolnir, que representa protección, la consagración, la justicia.
también se usa el valknut simboliza el viaje de Odín por los Nueve Mundos de Yggdrasil, que culmina con su momentánea muerte y regeneración, en el que obtiene el saber rúnico, no se recomienda el uso del valknut

En el druidismo es de particular importancia la Triskel y el awen. Entre ambos representan la triple naturaleza de la divinidad: la triquetra, como todos los símbolos paganos, es el más difundido pero no se conoce su origen.
El Triskel representa los 3 caminos evolutivos del ser humano: Cuerpo, mente y alma.
El Awen es el espíritu inspirado: la repentina llama de lucidez que inflama los pensamientos de los hombres y les da sabiduría, facilidad de palabra y energía en medio de la batalla.



</doc>
<doc id="17479" url="https://es.wikipedia.org/wiki?curid=17479" title="Peter Greenaway">
Peter Greenaway

Peter Greenaway, CBE (Newport, 5 de abril de 1942), es un director de cine británico, cuya formación se dio en las artes plásticas, específicamente en la pintura.

A una muy temprana edad, Greenaway decidió que quería ser un pintor y desarrolló un interés por el cine europeo, particularmente por las cintas de Antonioni, Bergman, Godard, Pasolini y Resnais. 

En 1962 inició estudios en el Walthamstow College of Art, donde compartió cursos con el músico Ian Dury con quien posteriormente trabajaría en "El cocinero, el ladrón, su mujer y su amante". En el Walthamstow College realizó su primer cortometraje titulado "Death of Sentiment" y que se desarrollaba alrededor de objetos del patio de una iglesia: cruces, ángeles volando, tipografía esculpida en la roca. La película fue filmada en cuatro cementerios londinenses. 

En 1965 se unió a la Oficina Central de Información (COI), donde trabajó durante 15 años como editor y director. En 1966 dirigió "Train", con fragmentos de la filmación del último tren de vapor que llegó a la estación de Waterloo, que estaba ubicada justo detrás de su lugar de trabajo en el COI. Una cinta de estilo abstracto influenciada por Fernand Léger y su "Ballet mécanique", todo montado por cortes sobre una banda sonora de música concreta. En 1966 también dirigió "Tree", siendo el protagonista un árbol del Royal Festival Hall de Londres que se encontraba completamente rodeado de cemento. 

La década de 1970 verá un Greenaway más serio que desarrollará en 1978 "Vertical Features Remake" y "A Walk Through H". La primera, un estudio sobre formas con estructuras aritméticas, y la segunda, un viaje a través de varios mapas. 

En 1980 Greenaway producirá su más ambicioso trabajo hasta ese momento, titulado "The Falls": un monstruo fantástico, una enciclopedia de lo absurdo de material asociable con el vuelo, con la ley de la gravedad, 92 víctimas de algo que denominó (VUE) "Violent Unknown Event" o Evento Violento Desconocido. Los años 80 vieron las mejores películas de Greenaway: "El contrato del dibujante" en 1982, "A Zed & Two Noughts" en 1985, "El vientre del arquitecto" en 1987, "Drowning by Numbers" (también traducida como "Conspiración de mujeres") en 1988 y "El cocinero, el ladrón, su mujer y su amante" en 1989, su película más conocida por el público. 

Los noventa nos dieron las más atractivas a nivel visual: "Los libros de Próspero" en 1991, la controvertida "El niño de Mâcon" en 1993, "The Pillow Book" en 1996 y "8 1/2Women" en 1999.

" (1.ª parte)" de 2003, " (2.ª parte)" de 2004, y "Nightwatching" de 2007 (sobre el cuadro "La ronda de noche" de Rembrandt) son sus últimos filmes para la pantalla grande, unas "extravaganzas" multimedia que incluyen las más innovadoras técnicas. 

En la mente de Peter Greenaway está la actitud de que aún no hemos visto lo que puede ser el cine, como se dijo anteriormente. Su ambición es intentar reinventarlo.

Expuso vídeos de su creación en la edición de la Exposición Universal Shanghái 2010, en el Árbol del Aire del pabellón de Madrid, en una iniciativa llevada a cabo por el grupo Open This End.





</doc>
<doc id="17486" url="https://es.wikipedia.org/wiki?curid=17486" title="Vela">
Vela

Vela puede referirse a:


También puede designar a varias localidades:


</doc>
<doc id="17487" url="https://es.wikipedia.org/wiki?curid=17487" title="Jean-François Lyotard">
Jean-François Lyotard

Jean-François Lyotard (10 de Agosto 1924, Versalles, Francia – 21 de abril de 1998, París, Francia) fue un filosofo, sociólogo y teórico literario francés. Su discurso interdisciplinario abarca tópicos que van desde la epistemología y la comunicación, el cuerpo humano, arte moderno y posmoderno, literatura y critica teórica, música, cine, tiempo y memoria, espacio, la ciudad y el paisaje, lo sublime, y la relación entre estética y política. Es mejor conocido por su articulación del posmodernismo después de la década de los 70, y el análisis del impacto de la posmodernidad en la condición humana. Fue co-fundador del Colegio Internacional de Filosofía ("Collège international de philosophie)" junto a Jacques Derrida, François Châtelet y Giles Deleuze.

Entre las muchas influencias que Lyotard tuvo a lo largo de su carrera se encuentran: Immanuel Kant, Karl Marx, Georg Wilhelm Friedrich Hegel, Martin Heidegger, Maurice Merleau-Ponty, Sigmund Freud, Jacques Lacan, Ludwig Wittgenstein y Giles Deleuze, cuyos trabajos no solo dieron marco a la labor de Lyotard, sino que en muchas ocasiones, sirvieron como guía de su pensamiento crítico.
Jean-François Lyotard nació el 10 de agosto de 1924, en Vincennes, Francia. Hijo de Jean-Pierre Lyotard, un representante de ventas y Madeleine Cavalli. Acudió a la escuela primaria Lycée Buffon, y posteriormente al Lycée Louis le Grand, ambos ubicados en Paris. De niño, Lyotard tenia muchas aspiraciones, como convertirse en artista, historiador, monje dominico, y escritor. Posteriormente, se dio por vencido del sueño de ser escritor, cuando terminó de escribir una novela de ficción poco exitosa a la edad de 15 años. Lyotard describe, el darse cuenta de que no se convirtió en ninguna de estas ocupaciones como “destino” en su autobiografía llamada "Peregrinations", publicada en 1986.

Estudio filosofía en la Sorbona al final de los cuarentas. Con el inicio de la Segunda Guerra Mundial, Lyotard interrumpió sus estudios. Sirvió como voluntario de primeros auxilios para el ejército francés, y experimentó la lucha para liberar a París en agosto de 1944. Sin duda moldeado por la destrucción y la devastación que había presenciado durante la guerra, y atraído por las primeras promesas del socialismo, Lyotard se convirtió en un devoto marxista en los años posteriores a la Segunda Guerra Mundial. De tal manera, culminó sus estudios en 1947 con su tesis DES ("diplôme d´études supérieures") titulada "La Indiferencia como un concepto ético" ("L´indifférence comme notion éhtique"), en ésta, analiza formas de indiferencia y desapego en el Budismo Zen, Estoicismo, Taoísmo y Epicureísmo. Después de su graduación, obtuvo un puesto en el Centro Nacional para la Investigación Científica de Francia.

Durante una primera etapa de su vida, Lyotard militó en grupos izquierdistas y su pensamiento se desarrolló dentro de lo que se podría llamar el marxismo crítico. Como alumno de Maurice Merleau-Ponty, se interesó también por la fenomenología, y publicó su primer libro sobre este tema (esencialmente divulgativo) en la colección "Que sais-je", proporcionando una visión clara y global del papel de dicha corriente filosófica en el siglo XX.

Posteriormente, sin embargo, se alejó del marxismo, e inició durante los años sesenta una evolución hacia el postmodernismo en la que se aprecia ya el desarrollo de un pensamiento original. Se centró durante esta época en el tema del deseo como búsqueda de lo imposible, en términos muy cercanos a los defendidos por el psicoanálisis, especialmente dentro de la corriente psicoanalítica representada por Jacques–Marie Émile Lacan. Con ello, el papel de la crítica y análisis del lenguaje se hace sumamente importante en su filosofía. Por otra parte, y durante esta misma época, realiza importantes incursiones en el ámbito de la estética, concretamente en el análisis de la obra pictórica, a la que ve como un campo determinante en la posición del deseo.

Destacan en especial sus estudios de la obra de Paul Cézanne en relación con la concepción freudiana del arte. Para Lyotard, la obra de Cézanne ejemplifica una suerte de reinversión del sentido de dicha concepción, al producirse su pintura desde el fluir de los impulsos inconscientes de la libido; dicho fluir se plasma en la capacidad de creación del pintor de espacios análogos a los del inconsciente, que producen en el que contempla su obra estados de inquietud y de perturbación.

En 1950, Lyotard tomó un puesto enseñando filosofía en el Lycée de Constantine, en Constantina, Argelia. Para 1971, Lyotard obtuvo un doctorado estatal con su disertación "Discurso, figura" bajo la tutoría de Mikel Dufrenne, trabajo que se publico en el mismo año. Lyotard, dedicó un periodo de su vida, posterior a la Segunda Guerra Mundial a las revoluciones socialistas, cuestión que quedo más de manifiesto en sus escritos, ya que se centraron en gran medida en la política de izquierda, y él tomó un interés particular en la guerra para la independencia de Argelia, que él vio en persona mientras que enseñaba allí.

Se caso con su primera esposa, Andree May en 1948, con quien tuvo dos hijos Corinne y Laurence, y después se caso por segunda ocasión en 1993 con Dolores Djidzek, madre de su hijo David, nacido en 1986.

Lyotard expuso en ""Le Différend"" que el discurso humano ocurre en un variado pero discreto número de dominios inconmesurables, ninguno de los cuales tiene el privilegio de pasar o emitir juicios de valor sobre los otros. Siendo así, en "Economía libidinal" (1974), "La condición postmoderna" (1979) y "Au juste: Conversations" (1979), Lyotard atacó teorías literarias contemporáneas e incitó al discurso experimental desprovisto de excesivos intereses por la verdad. Consideró que ya estaba pasada la época de los grandes relatos o "metarrelatos" que intentaban dar un sentido a la marcha de la historia.

Este autor criticó la sociedad actual postmoderna por el realismo del dinero, que se acomoda a todas las tendencias y necesidades, siempre y cuando tengan poder de compra. Criticó los metadiscursos: el cristiano, el ilustrado, el marxista y el capitalista. Según Lyotard, estos son incapaces de conducir a la liberación. La cultura postmoderna se caracteriza por la incredulidad con respecto a los metarrelatos, invalidados por sus efectos prácticos y actualmente no se trata de proponer un sistema alternativo al vigente, sino de actuar en espacios muy diversos para producir cambios concretos.

En 1954, Lyotard se une al grupo "`Socialismo o Barbarie´", una organización política francesa formada en 1948 en torno a la inadecuación del análisis trotskista para explicar las nuevas formas de dominación en la Unión Soviética. `Socialismo o Barbarie´ tenía como objetivo realizar una crítica del marxismo desde dentro, durante la guerra argelina de liberación. Sus escritos en este periodo se refieren principalmente a la política de extrema izquierda, con un enfoque en la situación Argelina (que él presenció de primera mano mientras enseñaba filosofía en Constantina). Escribió ensayos optimistas de esperanza y aliento hacia los argelinos, los cuales fueron reproducidos en escritos políticos. Lyotard esperaba alentar una lucha argelina por la independencia de Francia y una revolución social. 

Después de disputas con Cornelius Castoriadis en 1964, Lyotard dejó "`Socialismo o Barbarie´" por el recién formado grupo `"Poder de los trabajadores"´ (Pouvoir Ouvrier), mismo que abandono definitivamente en 1966. Aunque Lyotard participó activamente en los levantamientos de mayo de 1968, se distanció del marxismo revolucionario con su "Economía Libidinal", de 1974. Se distanció del marxismo porque sentía que el marxismo tenía un enfoque estructuralista rígido y estaban imponiendo la `sistematización de los deseos´ mediante un fuerte énfasis en la producción industrial como cultura fundamental.

Lyotard enseñó en el Lycée de Constantine, Argelia de 1950 a 1952. En 1972, Lyotard comenzó a dar clases en la Universidad de París VIII; allí enseñó hasta 1987 cuando se convirtió en Profesor Emérito. Durante las dos décadas siguientes impartió clases fuera de Francia, especialmente como Profesor de Teoría Crítica en la Universidad de California en Irvine y como profesor visitante en universidades de todo el mundo. Algunas de estas Universidades son: Universidad de Johns Hopkins, Universidad de California Berkeley, Universidad de Yale, Universidad Stony Brook y la Universidad de California, San Diego en los Estados Unidos, Université de Montréal en Quebec (Canadá) y la Universidad de São Paulo en Brasil. También fue director fundador y miembro del consejo del Colegio Internacional de Filosofía ("Collège international de philosophie)", París. Antes de su muerte, dividió su tiempo entre París y Atlanta, donde enseñó en la Universidad de Emory, con el nombramiento de de Filosofía y Francés.

Las obras filosóficas de Jean François Lyotard se desarrollan entre 1954 y 1998. Su primera obra "La Fenomenología" (1954) establece una serie de criterios para analizar la aportación de la fenomenología al pensamiento del siglo XX y su última obra, "La confesión de Agustín" (1998), refleja una de sus más hondas preocupaciones religiosas de su juventud.

El trabajo de Lyotard se caracteriza por una oposición persistente a las universalidades, metanarrativas y generalidad. Es ferozmente crítico con muchas de las afirmaciones "universalistas" de la Ilustración, y varias de sus obras sirven para socavar los principios fundamentales que generan estas reivindicaciones amplias.

En sus escritos de principios de los 70, rechaza lo que considera como fundamentos teológicos de Karl Marx y Sigmund Freud: ""En Freud, es Judaico, sombrío crítico (olvidadizo de lo político); En Marx es católico. Hegeliano, reconciliador (...) en el uno y en el otro la relación de lo económico con el sentido está bloqueada en la categoría de representación (...) Aquí una política, hay una terapéutica, en ambos casos una teología laica, en la cima de la arbitrariedad y la itinerancia de fuerzas ". En consecuencia, rechazó la dialéctica negativa de Theodor W. Adorno porque los consideraba como buscar una "solución terapéutica en el marco de una religión, aquí la religión de la historia"". En la ""economía libidinal"" de Lyotard apuntaba a ""descubrir y describir diferentes modos sociales de inversión de intensidades libidinales"."

La condición posmoderna

Lyotard es un escéptico para el pensamiento cultural moderno. El impacto de la condición posmoderna fue el de provocar el escepticismo acerca de las teorías universalizadoras. Lyotard argumenta que hemos superado nuestras necesidades de grandes narrativas debido al avance de las técnicas y tecnologías desde la Segunda Guerra Mundial. Argumenta contra la posibilidad de justificar las narrativas que reúnen disciplinas y prácticas sociales, como la ciencia y la cultura; ""Las narraciones que decimos para justificar un solo conjunto de leyes y apuestas son intrínsecamente injustas"". Una pérdida de fe en las meta-narrativas tiene un efecto sobre cómo vemos la ciencia, el arte y la literatura. Las pequeñas narrativas se han convertido en la manera adecuada de explicar las transformaciones sociales y los problemas políticos. Lyotard sostiene que ésta es la fuerza impulsora detrás de la ciencia posmoderna. A medida que las metanarrativas se desvanecen, la ciencia sufre una pérdida de fe en su búsqueda de la verdad, y por lo tanto debe encontrar otras formas de legitimar sus esfuerzos. Conectada a esta legitimidad científica está el creciente dominio de las máquinas de información. Lyotard sostiene que un día, para que el conocimiento sea considerado útil, tendrá que ser convertido en datos computarizados. Años más tarde, esto lo llevó a escribir su libro "The Inhuman", publicado en 1988, en el que ilustra un mundo en el que la tecnología se ha hecho cargo.

Lyotard denomina legitimación al "proceso por el cual el legislador se encuentra autorizado para promulgar una ley como norma". Un enunciado debe presentar un conjunto de condiciones para ser aceptado como científico. En este caso la legitimación es el proceso por el cual un legislador (que se ocupa del discurso científico) está acreditado para prescribir las condiciones convenidas (generalmente de consistencia interna y de verificación experimental) para que un enunciado forme parte de ese discurso y pueda ser considerado por la comunidad científica.

De tal manera, señala que desde Platón, la cuestión de la legitimación de las ciencias se halla fuertemente relacionada con la de la legitimación del legislador. Asimismo, el derecho a decidir lo que es verdadero se encuentra entreverado con el derecho a decidir lo que es justo. Hay un lazo de similitud entre el tipo de lenguaje que llamamos ciencia y ese otro que llamamos ética y política, ambos proceden de la misma tradición occidental.

Por otro lado, Lyotard permite ver como la ciencia, se ha convertido en la forma de legitimación de los relatos y metarrelatos en la sociedad posmoderna, ya que pone en duda la producción de los saberes científicos, puesto que estos, se han llegado a establecer como una especie de discurso de legitimación por parte de quien promueve a las ciencias: "“El estado puede gastar mucho para que la ciencia pueda presentarse como epopeya, a través de ella se hace creíble, crea el asentimiento publico del que sus propios decididores tienen necesidad”", dando a notar, que inclusive los saberes, se han transformado en objetos de uso y objetos de cambio, que tiene la finalidad de ser consumidos y valorados de una forma especifica. Así pues, dentro del vigente estatuto del saber científico, Lyotard asegura que la cuestión de la doble legitimación lejos de diluirse, se plantea con mayor vigor. De esta forma, saber y poder son las dos caras de una misma moneda: ""¿Quién decide lo que es saber, y quién sabe lo que conviene decidir? La cuestión del saber en la edad de la informática es más que nunca la cuestión del gobierno"."

Según Lyotard, no interesa tanto la verdad como la eficacia de la información. Por eso la ciencia y el derecho en las sociedades postindustriales se legitiman por su eficiencia, y todo sistema queda regulado por la optimización de sus actuaciones. Así́, se pierden los saberes unificantes y aparece un tipo de saber fragmentario, una explosión de pequeños sistemas que nadan en el eclecticismo y que caracterizan lo que él mismo llamó ""una época helada de apabullante postmodernismo"", en la que se diluyen todas las utopías del siglo XX. Como medio de conseguir que en el seno de esta heterogeneidad de saberes se produzca una conciliación y se establezcan lazos de comunicación entre las diferencias, Lyotard repara en la relevancia del papel que los juegos de lenguaje desempeñan a la hora de garantizar la existencia de una sociedad consolidada.

El colapso de la “gran narrativa” y “Juegos del lenguaje” 

En "“La condición posmoderna: informe sobre el saber”" "(La Condition postmoderne: Rapport sur le savoir)" (1979), propone lo que él llama una simplificación extrema del "posmoderno" como una ""incredulidad hacia las metanarrativas"". Estas metanarrativas, a veces “grandes narraciones”, son grandes teorías y filosofías del mundo, como el progreso de la historia, la cognoscibilidad de todo por la ciencia y la posibilidad de una libertad absoluta. Lyotard sostiene que hemos dejado de creer que narrativas de este tipo son adecuadas para representar y contener a todos. Él señala que nadie parecía estar de acuerdo en lo que, si es que algo, era real y todos tenían su propia perspectiva y la historia. Nos hemos puesto alerta a la diferencia, a la diversidad, a la incompatibilidad de nuestras aspiraciones, creencias y deseos, y por eso la posmodernidad se caracteriza por una abundancia de micronarrativas. Para este concepto Lyotard se basa en la noción de "juegos de lenguaje" que se encuentra en la obra de Ludwig Wittgenstein. Lyotard señala que se basa en el mapeo de la sociedad según el concepto de los juegos de lenguaje.

En las obras de Lyotard, el término `juegos de lenguaje´, a veces también llamado `regímenes de frase´, denota la multiplicidad de comunidades de significado, los innumerables e inconmensurables sistemas separados en los que se producen significados y se crean reglas para su circulación. Esto implica, por ejemplo, una incredulidad hacia la metanarrativa de la emancipación humana. Es decir, la historia de cómo la raza humana se ha liberado, la cual reúne el juego de la lengua de la ciencia, el juego del lenguaje de los conflictos históricos humanos y el juego del lenguaje de las cualidades humanas en la justificación general del desarrollo constante de la raza humana en términos de riqueza y bienestar moral. Según esta metanarrativa, la justificación de la ciencia está relacionada con la riqueza y la educación. El desarrollo de la historia es visto como un progreso constante hacia la civilización o el bienestar moral.

El juego de lenguaje de las pasiones humanas, cualidades y culpas, es visto como un cambio constante en favor de nuestras cualidades y lejos de nuestras culpas, mientras la ciencia y los desarrollos históricos, nos ayudan a conquistar nuestras culpas en favor de nuestras cualidades. El punto es que cualquier acontecimiento debe ser capaz de ser entendido en términos de las justificaciones de esta metanarrativa; cualquier cosa que suceda puede entenderse y juzgarse según el discurso de la emancipación humana. Por ejemplo, para cualquier nueva revolución social, política o científica podríamos hacer la pregunta: ""¿Es esta revolución un paso hacia el mayor bienestar de la masa de seres humanos?"", debería ser posible siempre responder a esta pregunta en términos de las reglas de justificación de la metanarrativa de la emancipación humana.

Esto se vuelve más crucial en "Au juste: Conversations" (1979) y "Le Différend (La Diferencia)" (1983), que desarrollan una teoría posmoderna de la justicia. Podría parecer que la atomización de los seres humanos implicada por la noción de la micronarración y el juego del lenguaje sugiere un colapso de la ética. Se ha pensado a menudo que la universalidad es una condición para que algo sea una declaración ética apropiada: ""no robarás"" es una declaración ética en una manera que ""no robarás de Margaret"" no lo es. Este último es demasiado particular para ser una declaración ética (¿qué tiene de especial Margaret?); Sólo es ético si se basa en una declaración universal (""no robarás a nadie""). Pero los universales son inadmisibles en un mundo que ha perdido la fe en las metanarrativas, por lo que parecería que la ética es imposible. La justicia y la injusticia sólo pueden ser términos dentro de los juegos de lenguaje, y la universalidad de la ética está fuera de la ventana.

Lyotard sostiene que las nociones de justicia e injusticia permanecen de hecho en el posmodernismo. La nueva definición de injusticia es de hecho usar las reglas del lenguaje de un "régimen de frases" y aplicarlas a otro. El comportamiento ético consiste en permanecer alerta precisamente ante la amenaza de esta injusticia, en prestar atención a las cosas en su particularidad y no encerrarlas dentro de la conceptualidad abstracta. Uno debe dar testimonio del 'differend'. En otro caso, hay un conflicto entre dos partes que no se puede resolver de manera justa. Sin embargo, el acto de ser capaz de unir las dos y comprender las reclamaciones de ambas partes, es el primer paso hacia la búsqueda de una solución.

La Différend

En Le Différend, basándose en los puntos de vista de Immanuel Kant sobre la separación de la comprensión, el juicio y la razón, Lyotard identifica el momento en que el lenguaje falla como la diferencia, y lo explica así: ""... el estado inestable y el instante del lenguaje en el que algo que debe ser capaz de poner en frases no puede ser todavía ... los seres humanos que pensaban que podían usar el lenguaje como instrumento de comunicación, aprenden a través del sentimiento de dolor que acompaña al silencio (y del placer que acompaña a la invención de un Nuevo idioma)"". Lyotard socava la visión común de que los significados de las frases pueden ser determinados de acuerdo a lo que refieren (el referente). El significado de una frase -un evento (algo sucede) - no puede ser fijado apelando a la realidad (lo que realmente sucedió). Lyotard desarrolla esta visión del lenguaje definiendo la "realidad" de una manera original, como un complejo de sentidos posibles unidos a un referente a través de un nombre.

El sentido correcto de una frase no puede ser determinado por una referencia a la realidad, ya que el referente en sí mismo no fija el sentido, y la realidad misma se define como el complejo de los sentidos competidores unidos a un referente. Por lo tanto, la frase, en tanto evento, permanece indeterminada.

Lyotard utiliza el ejemplo de Auschwitz y las demandas del historiador revisionista de demostrar el Holocausto, para mostrar cómo le Différend opera como un doble vínculo (un dilema o circunstancia difícil de la cual no hay escape debido a condiciones mutuamente conflictivas o dependientes). Faurisson sólo aceptará la prueba de la existencia de cámaras de gas de testigos oculares que fueron víctimas de las cámaras de gas. Sin embargo, estos testigos están muertos y no pueden testificar. O no había cámaras de gas, en cuyo caso no habría testigos oculares para producir evidencia, o había cámaras de gas, en cuyo caso todavía no habría testigos oculares para producir evidencia, porque estarían muertos. Puesto que Faurisson no aceptará ninguna evidencia para la existencia de cámaras de gas, excepto el testimonio de víctimas reales, concluirá de ambas posibilidades (las cámaras de gas existían y las cámaras de gas no existían) que las cámaras de gas no existían. Esto presenta un doble vínculo. Hay dos alternativas, o bien había cámaras de gas o no, lo que conduce a la misma conclusión: no había cámaras de gas (y ninguna solución final). El caso es un Différend porque el daño hecho a las víctimas no puede ser presentado en el criterio de juicio sostenido por Faurisson.

Lo Sublime

Lyotard era un escritor frecuente en materia de estética. Él era, a pesar de su reputación como posmodernista, un gran promotor del arte modernista. Lyotard veía al posmodernismo como una tendencia latente dentro del pensamiento a lo largo del tiempo y no como un período histórico estrechamente limitado. Él favoreció las obras asombrosas y desconcertantes de las altas vanguardias modernistas. En ellos encontró una demostración de los límites de nuestra conceptualización, una lección valiosa para cualquier persona demasiado impregnada de la confianza de la Ilustración. Lyotard ha escrito extensivamente también sobre algunos artistas contemporáneos de su elección: Valerio Adami, Daniel Buren, Marcel Duchamp, Bracha Ettinger y Barnett Newman, así como sobre Paul Cézanne y Wassily Kandinsky.

Desarrolló estos temas en particular, discutiendo lo sublime. Lo "sublime" es un término en estética cuyas fortunas revivieron bajo el posmodernismo después de un siglo o más de abandono. Se refiere a la experiencia de ansiedad placentera que experimentamos cuando nos enfrentamos a paisajes salvajes y amenazadores como, por ejemplo, una enorme montaña escarpada, negra contra el cielo, que se cierne aterrorizante en nuestra visión. Un sublime es la conjunción de dos sentimientos opuestos, lo que hace más difícil para nosotros ver la injusticia de ella, o una solución a ella.

Lyotard encontró particularmente interesante la explicación del sublime ofrecido por Immanuel Kant en su Crítica del Juicio (a veces Crítica del Poder del Juicio). En este libro, Kant explica esta mezcla de ansiedad y placer en los siguientes términos: hay dos tipos de experiencia "sublime". En lo sublime "matemáticamente", un objeto golpea a la mente de tal manera que nos encontramos incapaces de tomarlo como un todo. Más precisamente, experimentamos un choque entre nuestra razón (que nos dice que todos los objetos son finitos) y la imaginación (el aspecto de la mente que organiza lo que vemos y que ve un objeto incalculablemente más grande que nosotros mismos y se siente infinito). En lo sublime "dinámico", la mente retrocede ante un objeto tan inconmensurablemente más poderoso que nosotros, cuyo peso, fuerza, escala podrían aplastarnos sin la más remota esperanza de que podamos resistirla. (Kant subraya que si estamos en peligro real, nuestra sensación de ansiedad es muy diferente de la de un sentimiento sublime, el sublime es una experiencia estética, no un sentimiento práctico de peligro personal). Esto explica el sentimiento de ansiedad.

Lo que es profundamente inquietante acerca de lo matemáticamente sublime es que las facultades mentales que presentan percepciones visuales a la mente son inadecuadas para el concepto que le corresponde; En otras palabras, lo que somos capaces nosotros mismos de hacernos ver no puede coincidir plenamente con lo que sabemos que esta ahí. Sabemos que es una montaña, pero no podemos tomar el “todo” completo en nuestra percepción. Nuestra sensibilidad es incapaz de afrontar tales visiones, pero nuestra razón puede afirmar la finitud de la presentación. Con lo sublime dinámico, nuestro sentido de peligro físico debe despertar la conciencia, que no somos sólo seres materiales físicos, sino también morales y (en términos de Kant) noumenales. El cuerpo puede ser empequeñecido por su poder, pero nuestra razón no. Esto explica, en ambos casos, por qué lo sublime es una experiencia tanto de placer como de dolor.

Lyotard está fascinado por esta admisión, de uno de los arquitectos filosóficos de la Ilustración, de que la mente no siempre puede organizar el mundo racionalmente. Algunos objetos son simplemente incapaces de ser traídos cuidadosamente bajo conceptos. Para Lyotard, en "Lecciones sobre la analítica de lo sublime (Lessons on the Analytic of the Sublime)", pero basándose en su argumento en Le Différend, esto es algo bueno. Tales generalidades como "conceptos" no prestan la debida atención a la particularidad de las cosas. Lo que sucede en lo sublime es una crisis donde nos damos cuenta de la insuficiencia de la imaginación y la razón entre sí. Lo que estamos presenciando, dice Lyotard, es en realidad el diferendo; la tensión de la mente en los bordes de sí misma y en los bordes de su conceptualización.

Economía Libidinal

En uno de los libros más famosos de Lyotard, "Economía Libidinal (Économie libidinale)", ofrece una crítica de la "falsa conciencia" de Marx y afirma que la clase obrera del siglo XIX disfrutaba ser parte del proceso de industrialización. Lyotard afirma que esto se debe a la energía libidinal. El término "libidinal" viene de libido, concepto referido a los deseos inconscientes no accesibles desde la conciencia, desde la teoría psicoanalítica. Los escritos de Lyotard en Economía Libidinal, muestran un logro en nuestros intentos de vivir con el rechazo de todos los principios religiosos y morales a través de un socavamiento de las estructuras asociadas con él.
Las estructuras ocultan las intensidades libidinales, mientras que los intensos sentimientos y deseos nos obligan a alejarnos de las estructuras establecidas. Sin embargo, tampoco puede haber intensidades o deseos sin estructuras, porque no habría ningún sueño de escapar de las estructuras represivas si no existen. ""La energía libidinal viene de esta intervención disruptiva de los acontecimientos externos dentro de las estructuras que buscan el orden y la auto-contención."" Éste era el primer de los escritos de Lyotard que había criticado realmente el punto de vista marxista. Este tema en particular, donde realmente se opuso a las opiniones de Karl Marx.

Algunos de los últimos trabajos en los que Lyotard había estado trabajando eran ambos escritos sobre un escritor, un activista, y un político franceses, André Malraux. Una de ellas es una biografía, "Firmado, Malraux (Signé Malraux)". Lyotard estaba interesado en las opiniones estéticas de la sociedad que compartía Malraux. El otro libro de Lyotard fue llamado "La Confesión de Agustín" (La Confession d’Augustin) y fue un estudio en la fenomenología del tiempo. Este trabajo inconcluso, fue publicado póstumamente en el mismo año de la muerte de Lyotard.

Lyotard volvió repetidamente a la noción del posmoderno en los ensayos reunidos en inglés como ""El posmoderno explicado a los niños", "Hacia el posmoderno", y "Fábulas posmodernas"". En 1998, mientras se preparaba para una conferencia sobre "Posmodernismo" y "Teoría de los Medios", murió inesperadamente de un caso de leucemia que había avanzado rápidamente. Está enterrado en el "Cementerio del Père Lachaise" en París.

Posterior a la muerte de Jean – François Lyotard, fue organizado un homenaje colectivo por el Colegio Internacional de Filosofía (Collège International de Philosophie), presidido por Dolores Lyotard y Jean-Claude Milner, director del Colegio en aquella época. Los procedimientos fueron publicados por las Prensas Universitarias de Francia (PUF) en 2001 bajo el título general "Jean-François Lyotard," "l'exercice du différend."

El trabajo de Lyotard sigue siendo importante en la política, la filosofía, la sociología, la literatura, el arte y los estudios culturales. Para conmemorar el décimo aniversario de la muerte de Lyotard, se celebró en París, del 25 al 27 de enero, un simposio internacional sobre Jean-François Lyotard organizado por el "Collège International de Philosophie" (bajo la dirección de Dolores Lyotard, Jean-Claude Milner y Gerald Sfez) 2007.




</doc>
<doc id="17492" url="https://es.wikipedia.org/wiki?curid=17492" title="Curva del dragón">
Curva del dragón

La curva del dragón es un fractal que se construye siguiendo los siguientes pasos:
La siguiente figura muestra los trece primeros pasos:

Agrandando la imagen y después de una veintena de iteraciones, se obtiene la "curva del dragón":

Se suele citar a Martin Gardner como su autor.

Esta curva llega a rellenar completamente una parte del plano, por lo que su dimensión fractal debe ser 2. El cálculo de su dimensión se hace como en el copo de nieve de Koch, pues las construcciones de ambas curvas son similares.

En el primer paso de la construcción, se observa que a partir del segmento inicial se obtienen los otros catetos del primer triángulo mediante dos semejanzas (una es indirecta) de razón formula_1, de centros los extremos del segmento, y de ángulos formula_2 y formula_3 radianes (o sea, 45°). Llamemos formula_4 y formula_5 estas dos similitudes. Por construcción misma, la formula_6-ésima figura obtenida en el proceso, formula_7, es la reunión de las imágenes por formula_4 y formula_5 de la figura anterior formula_10:

Tomando el límite de esta relación ("n" tiende hacia +∞), y llamando formula_12 la curva del dragón, obtenemos:

Es decir, formula_14 es la reunión de dos copias de sí misma, a escala formula_15, como se puede ver en la figura siguiente:
Por tanto, si agrandamos "D" con una homotecia de razón formula_16, obtenemos dos veces "D", a la misma escala.

Si "D" es de dimensión "d", su "volumen" es multiplicado por formula_17 por esta homotecia. Aquí tenemos, pues, formula_18, y, por tanto, "d" = 2. 

La curva del dragón tiene además la propiedad de que se puede pavimentar el plano con ella, es decir rellenarlo sin dejar huecos y sin que se sobrepongan dos o más piezas: 


</doc>
<doc id="17494" url="https://es.wikipedia.org/wiki?curid=17494" title="Gao Xingjian">
Gao Xingjian

Gao Xingjian (; Ganzhou, China, 4 de enero de 1940) es un escritor en lengua china. Nacido en China, en la actualidad reside en Francia y es ciudadano francés. En el año 2000 obtuvo el .

Es dramaturgo y novelista. Su obra más importante es la novela "La Montaña del Alma".

Nacido en la localidad de Ganzhou, en la provincia de Jiangxi, estudió francés en la Universidad de Estudios Extranjeros de Pekín. Tras licenciarse, trabajó como traductor de francés en China.

Su obra refleja influencias del modernismo y el teatro del absurdo. Fue contratado como guionista del Teatro Popular de las Artes de Pekín, donde en 1982 se representó su primera obra, "La Señal de Alarma", escrita en colaboración con Liu Huiyuan. Su segunda obra, "La Estación de Autobuses" se estrenó en 1983, dirigida, al igual que "La Señal de Alarma" por Lin Zhaohua. En la representación, esta obra seguía a una pieza corta de Lu Xun, cuyo protagonista acababa poniéndose en la cola de una parada de autobuses. Así, se enlazaban el final de la obra de Lu Xun con el comienzo de "La Estación de Autobuses". Esta obra, la más famosa de sus composiciones para teatro, tiene ciertas similitudes con "Esperando a Godot", con un toque de darwinismo social. En la obra se utilizan numerosas expresiones locales, con un lenguaje muy pequinés, al estilo de la famosa obra de teatro "El Salón de Té" de Lao She.

La "Campaña contra la Contaminación Intelectual" emprendida por el Gobierno chino a mediados de los años 1980, le causó problemas con la censura, y el estreno de su tercera obra, "El Hombre Salvaje" se pospuso hasta 1985. A partir de 1986 se prohibió la representación de sus obras nuevas.

En 1987 viaja a París y se queda viviendo allí. Ya no volverá a China. En Francia acaba su obra maestra, la novela "La Montaña del Alma" (1990)

En el año 2000, se le concedió el Premio Nobel de Literatura. La noticia fue recibida con indignación por parte de las autoridades chinas, y los medios de comunicación de la China continental no informaron sobre la concesión del premio.

La concesión del premio Nobel le dio fama mundial. Sus obras empezaron a traducirse al español y otros muchos idiomas a partir de ese momento.

A continuación se listan algunas de sus obras más representativas.






</doc>
<doc id="17495" url="https://es.wikipedia.org/wiki?curid=17495" title="Lastras de Cuéllar">
Lastras de Cuéllar

Lastras de Cuéllar es un municipio situado al norte de la provincia de Segovia, y está situado a medio camino de los principales centros económicos de la misma: Cantalejo, Cuéllar y Segovia; además, dentro de su término se localizan los despoblados de San Esteban, La Serreta y Santa María de Sacedón.

Atraviesa su término el río Cega creando a lo largo de sus riberas un paraje de hayas, abedules y pinos albares. Posee un conjunto lacustre de especial interés formado por las lagunas del Carrizal, la Tenca y la Lucia.

El escudo heráldico que representa al municipio se blasona de la siguiente manera: 

Tiene su origen a partir del siglo XII, al igual que el resto de núcleos poblados pertenecientes a la Comunidad de Villa y Tierra de Cuéllar surgidos tras la repoblación de Cuéllar, y fue denominado hasta el siglo XIX únicamente como La Lastra, pasando después a adoptar su actual denominación.

A mediados del siglo XIX, Pascual Madoz en su diccionario dijo que disponía de ayuntamiento, constaba de unas 150 casas distribuidas en varias calles y articuladas respecto a una plaza. Además, poseía una escuela, dos ermitas y una iglesia parroquial. Su población era de 135 vecinos, que producían cereales y legumbres, además de ganado vacuno, lanar y caballar.

La localidad de "Lastras de Cuéllar" se encuentra situada en la zona central de la península ibérica, en el extremo norte de la provincia de Segovia, tiene una superficie de 65,42 km², y sus coordenadas son .

El clima de "Lastras de Cuéllar" es mediterráneo continentalizado, como consecuencia de la elevada altitud y su alejamiento de la costa, sus principales características son:



En la Clasificación climática de Köppen se corresponde con un clima "Csb" ("oceánico mediterráneo"), una transición entre el "Csa" ("mediterráneo") y el "Cfb" ("oceánico") producto de la altitud. A diferencia del "mediterráneo" presenta un verano más suave, pero al contrario que en el "oceánico" hay una estación seca en los meses más cálidos.

La localidad de "Lastas de Cuéllar" tiene una población de 410 habitantes (INE 2014), muy lejos de los 1.456 que llegó a alcanzar a mediados del siglo XX.Debido al éxodo rural, muchos de sus habitantes emigraron a otras regiones de España, siendo éstas preferentemente Cataluña, País Vasco y las ciudades de Madrid y Valladolid.

En el centro del municipio se localiza la iglesia de Santa María Magdalena, edificio de una sola nave con yeserías barrocas, del mismo estilo que su retablo mayor. Además, retiradas del núcleo urbano se localizan dos ermitas, la del Humilladero y la de Nuestra Señora de Sacedón, esta última perteneciente al despoblado de su nombre, y que alberga en su interior un retablo renacentista del conocido "maestro de Sacedón", que debe su nombre a esta obra.

Cerca del pueblo se localiza La Serreta, un bosque dedicado a la caza durante siglos, donde Beltrán de la Cueva primer duque de Alburquerque construyó un palacio en el siglo XV que todavía se conserva; en la actualidad sigue existiendo actividad en la finca, frecuentada por el rey Juan Carlos I y considerada una de las fincas de caza más antiguas de España. Cercana al palacio, se conserva otra pequeña ermita, que perteneció en su tiempo al despoblado de su nombre.

Sus fiestas mayores son el día 8 de septiembre en honor de la Natividad de Nuestra Señora.
Celebra también otras fiestas menores: 
El lunes de la Pascua de Pentecostés, 50 días después de la Semana Santa, se celebra la Romería de la Virgen de Sacedón. Cada año se nombran 2 parejas de mayordomos que son los encargados de cuidar la ermita durante todo el año y de organizar la romería. La Virgen sobre su carroza de ruedas empujada por los mayordomos y vestida con sus mejores galas sale de la iglesia de la Magdalena donde la han llevado una semana antes los mayordomos y todos los vecinos del pueblo que han querido acompañarles y donde llevan rezándola novenas cada día por la tarde; entre campanadas y a la puerta de la iglesia, presencia el primero de los paloteos que los danzantes ataviados con los trajes tradicionales bailan al son de las dulzainas; antiguamente sólo danzaban hombres, ya que a las mujeres ni siquiera se las permitía bailar una jota delante de la Virgen, pero hoy en día el grupo de paloteos está formado por hombres y mujeres que danzan juntos y dan más vistosidad a la fiesta. Así comienza una larga procesión en la que la Virgen avanza lentamente detenida por la gente que baila jotas delante de ella y por los paloteos que se van bailando hasta llegar a la puerta de la ermita situada a 1 km. del pueblo donde se baila la última danza, la contradanza, y donde los danzantes forman un arco por el que pasa la Virgen para entrar a su ermita donde esperará hasta el próximo año que vuelvan a buscarla.

En el campo artesano ha destacado a lo largo de su historia la actividad alfarera.

El origen de su nombre no conocemos exactamente en qué contexto aparece, y no tenemos fuentes directas que hablen de cuando fue realizada dicha talla, sabemos que el despoblado de Salcedón (que veneraba esta imagen y se estableció en torno a su ermita) aparece mencionado en el fuero de Sepúlveda (un texto realizado en 1076 por Alfonso VI de León y ratificado en 1305 por el rey Fernando IV de Castilla)

Podría derivar del vocablo latino salictum. Esta hipótesis de defiende sobre dos pilares; por un lado, la propia palabra mediante las leyes de evolución fonética del latín pudo derivar desde este término culto hasta el término coloquial Salcedón que conocemos hoy:

Salictum> término latino
Salictun > la “m” final cae y cambia a “n”
Salicton> la “u” final cierra en “o”
Salciton> la vocal “i” tónica breve cambia de posición y se une el grupo consonántico “lc”
Salceton> la vocal “i” tónica breve pasa a “e”
Salcedon> la oclusiva sorda “t” tiende a convertirse en “d”

Por otro lado, dentro de un análisis más propio de las ciencias sociales, el vocablo latino al que nos referimos significa “sacedal”, “lugar de sauces” e incluso un “lugar húmedo”. Esta descripción teóricamente vendría a denominar el lugar en que la imagen de la virgen se apareció, lo cual coincide con la descripción real del lugar donde se levanta la ermita, puesto que próximo a la misma existe un gran prado con algunas charcas, álamos blancos (chopos) y arroyos; una zona que en el momento en que se levantó la ermita y apareció la imagen pudo denominarse con este término.

La leyenda de la Virgen de Salcedón cuenta que mientras unos pastores andaban en el campo se les apareció la imagen de la virgen. Esta, se sentó en una roca y se convirtió en la talla que conocemos hoy. Más tarde, los vecinos se la intentaron llevar al cercano pueblo de Aguilafuente para lo cual se cargó la imagen sobre un carro tirado por bueyes, sin embargo, los bueyes no pudieron tirar del carro, se quedaban atascados, se les hundían las patas a los animales y las ruedas del carro. Este hecho fue interpretado como un mensaje de la virgen, que no quería que la trasladasen del lugar donde se había aparecido por lo que la imagen se quedó en ese lugar, sobre el cual se construyó una ermita, la que es en la actualidad la ermita de Nuestra Señora de Salcedón.

Se trata de una talla de bulto redondo, difícil de datar (en torno al s. XII). Está realizada en madera policromada y se conserva en la ermita de Nuestra Señora de Salcedón, ermita a la que presta su nombre.

La imagen representa a la Virgen con el niño, este tipo de representaciones son muy comunes en la Edad Media y aunque al principio pretenden relegar la imagen de María como madre de Jesús (al que representan con rasgos adultos) con el tiempo le van a ir concediendo una mayor importancia a la Virgen. 

En este caso, la virgen aparece sentada en un trono vestida con un traje dorado y un manto azul que sale desde su cabeza y cae cubriendo la parte derecha de su cuerpo hasta llegar a la parte frontal, creando una serie de pliegues sobre las rodillas que hacen un cierto contraste con la luz y aportan dinamismo a la imagen, contrastando con las líneas regulares y rectas del resto de la talla. 

Asimismo, la Virgen tiene en la mano izquierda una flor. Normalmente las esculturas de estos siglos se suelen representar con una serie de objetos muy característicos y simbólicos. En este caso, las primeras vírgenes suelen llevar en su mano una manzana que con el tiempo pasa a ser una flor, ambas representaciones aparte de ser decorativas están cargadas de un fuerte simbolismo y aluden al Paraíso.

El niño aparece sobre la rodilla izquierda de su madre, de pie y con el rostro girado, mirándola. Tiene rasgos infantiles, aunque se trata de un niño pequeño sin llegar a ser un bebé. El hecho de que no sea representado como un niño muy pequeño se hace para remarcar la importancia de Jesús, incluso en este caso en que se le representa como a un niño, como hombre. En su mano izquierda lleva una bola del mundo mientas que la derecha aparece levantada en aptitud de bendecir, una forma muy común en las tallas de esta época. Viste un traje dorado similar al de la virgen, para no crear un contraste entre la imagen de la virgen y el niño. Este hecho de que los colores de sus ropajes sean similares podría relacionarse con un intento del autor de la talla por establecer una conexión entre la virgen y el niño, algo que se remarca también en la mirada entre la madre y su hijo o cómo el brazo de la virgen rodea el cuerpo del niño. Durante la edad Media las tallas de las vírgenes pasarán desde una imagen de María como mero trono en los que se sienta cristo, hasta concederle cada vez una mayor importancia a la virgen, que rodea con la mano o que establece una conexión con su hijo.

Por otra parte, las proporciones son tibiamente seguidas, de este modo nos encontramos con unas mano y cabeza, en el caso de la virgen, de un tamaño mayor. Este hecho no hay que relacionarlo con una falta de técnica del autor, sino que intenta realzar partes del cuerpo sobre las demás huyendo del realismo que caracterizará épocas estilísticas anteriores (arte Clásico) y posteriores (Renacimiento), aportando una importancia simbólica a las mismas. Las líneas más características son las verticales, que predominan en la talla (el brazo y mano de la virgen, el propio cuerpo del niño, las piernas de la virgen e incluso se vislumbran en los pliegues del vestido); no obstante, también tiene una marcada importancia la línea que se realiza entre la madre y el niño. Una línea inclinada que se genera con la mirada del niño hacia la madre y que se realza con la posición del brazo de Jesús.

En lo que se refiere al análisis del color, las dos figuras utilizan colores realistas en sus rasgos físicos (colores marrones para el pelo, carne rosada…) aunque cabe destacar los colores de sus vestidos puesto que utilizan para ellos el dorado y el azul. Esta elección de colores para los ropajes y manto de la virgen son muy comunes en la Edad Media y, sobre todo, en el Renacimiento. En ambos casos se trata de colores con una gran carga simbólica, el primero está relacionado con la riqueza por su relación cromática con el oro. En el segundo caso, el azul era un color difícil de conseguir, que a menudo se obtenía con minerales procedentes de Asia Menor por lo que era un tono muy caro y exclusivo que solo se podía emplear en superficies y tallas muy especiales, como en este caso, para el manto de la Virgen. Además, cabe destacar que los colores dorado-naranja y azul son opuestos, se realzan más si se ponen juntos, esto, unido al hecho de que con la pintura se consigan detalles (como el remate que se hace en dorado en el manto de la virgen) nos empujan a pensar que el autor de la talla conocía las artes plásticas, que el tratamiento de la pintura de la talla no fue casual.

Debido a las características anteriormente citadas, esta escultura es difícil de inscribir en un estilo artístico concreto puesto que mezcla características románicas (como son la frontalidad de la composición, la talla en madera, las proporciones y el simbolismo o el propio tema de la composición); junto con otras que son propias del gótico (la simetría de la composición se rompe al estar la imagen del niño sobre la rodilla izquierda, se huye de la representación de María como trono al rodear el cuerpo de su hijo con el brazo así como el niño se representa mirando a su madre)

En la actualidad, la imagen suele ser vestida con mantos de diferentes colores, bordados, que se posan sobre su cabeza, coronas de metales preciosos y vestidos; fruto de las diferentes donaciones que los fieles han hecho durante años a esta imagen.




</doc>
<doc id="17501" url="https://es.wikipedia.org/wiki?curid=17501" title="Juan Carlos Onetti">
Juan Carlos Onetti

Juan Carlos Onetti Borges (Montevideo, 1 de julio de 1909 - Madrid, 30 de mayo de 1994) fue un escritor uruguayo.

La escritora uruguaya Cristina Peri Rossi, considera que Onetti es «uno de los pocos existencialistas en lengua castellana». Mario Vargas Llosa, quien preparó un ensayo sobre Onetti, dijo en una entrevista a la agencia AFP en mayo de 2008 que «es uno de los grandes escritores modernos, y no sólo de América Latina». «No ha obtenido el reconocimiento que merece como uno de los autores más originales y personales, que introdujo sobre todo la modernidad en el mundo de la literatura narrativa». «Su mundo es un mundo más bien pesimista, cargado de negatividad, eso hace que no llegue a un público muy vasto». Con anterioridad Vargas Llosa había comentado que Onetti «es un escritor enormemente original, coherente; su mundo es un universo de un pesimismo que supera gracias a la literatura».

Juan Carlos Onetti nació en Montevideo, el 1 de julio de 1909, a las seis de la mañana. Hijo de Carlos Onetti, funcionario de aduanas, descendiente de emigrados Irlandeses (apellido original O'Nety), y Honoria Borges, una descendiente de una familia aristocrática brasileña, de Río Grande do Sul. Tuvo dos hermanos, uno mayor que él, Raúl, y una hermana menor, Raquel. Onetti recordó su infancia como una época feliz, describiendo a sus padres como una pareja muy unida y amorosa con sus hijos.

En 1930, con apenas 20 años, se casó con su prima, María Amalia Onetti. En marzo del mismo año la pareja viajó a Buenos Aires, su nueva residencia. El 16 de junio de 1931 nació su primer hijo: Jorge Onetti Onetti, también escritor, fallecido en 1998. En 1933 aparece su primer cuento publicado, "Avenida de Mayo - Diagonal - Avenida de Mayo", en "La Prensa", después de ganar un concurso convocado por el diario, en el que hubo diez primeros lugares y 400 pesos para cada ganador. Poco después se separa de su mujer y un año más tarde, de regreso en Montevideo, vuelve a contraer matrimonio con María Julia Onetti, la hermana de María Amalia. Por esa época escribe la novela "Tiempo de abrazar", que publicará décadas después, en 1974.

Continuó ejerciendo diferentes oficios y escribiendo cuentos y artículos que fueron publicados en diversos medios de Buenos Aires y Montevideo hasta 1939, en el que tienen lugar dos hechos importantes: publica su primera novela, "El pozo" (en Editorial Signo), la cual es considerada como la primera en abrir la novela de creación o nueva novela en América Latina(escrita, según testimonio del autor, en una tarde durante un fin de semana en el que se quedó sin tabaco) y es nombrado secretario de redacción del semanario "Marcha", para el que escribirá columnas bajo los seudónimos Grucho Marx y Periquito el Aguador. Por ese entonces se separa de su segunda esposa. También desarrolla interés por las artes plásticas, como se refleja en su correspondencia con su amigo Julio E. Payró y su relación estrecha con Joaquín Torres García. Desempeña el cargo de secretario de redacción hasta 1941, cuando abandona el semanario por diferencias con Carlos Quijano y comienza a trabajar en la agencia de noticias Reuters. Ese año obtiene el segundo lugar, con su novela "Tierra de nadie", en un concurso que convoca la editorial Losada, que la publica. El jurado estuvo compuesto por Guillermo de Torre, Norah Lange y Jorge Luis Borges y otorgó el primer lugar a la novela "Es difícil empezar a vivir" de Bernardo Verbitsky. Poco después, Onetti es enviado como corresponsal a Buenos Aires, donde permanecerá hasta 1955.

Trabaja como secretario de redacción de las revistas "Vea y Lea" e "Ímpetu". En 1943 aparece "Para esta noche", cuyo título original fue "El perro tendrá su día". En 1945 se casa con una compañera de trabajo en Reuters, la neerlandesa Elizabeth María Pekelharing. El 26 de julio de 1949 nace su hija Isabel María (Litti).

En 1950 publica "La vida breve" (en Editorial Sudamericana), una novela central en su obra. En ella, y mediante un complejo juego de planos metaficcionales, Onetti funda la ciudad ficticia de Santa María, en la que, a partir de entonces, situaría la mayoría de sus novelas y cuentos. A pesar de que en sus primeras ediciones no tuvo mucho éxito, no tardó en ser reconocida como una de las novelas más innovadoras de su tiempo, y aun hoy es considerada una de las obras más importantes en lengua castellana. Poco después publicó la novela corta "Los adioses", que si bien no transcurre en Santa María, alude a un personaje ya recurrente en la obra de Onetti, el doctor Díaz Grey.

A fines de 1955 regresó a Montevideo y comenzó a trabajar en el diario "Acción"; contrajo matrimonio por cuarta vez con la joven argentina de ascendencia alemana Dorothea Muhr (Dolly), a quien había conocido en 1945 y que será su compañera definitiva.

En 1959 publica la novela corta "Para una tumba sin nombre", y en 1961 "El astillero", otra de sus novelas más celebradas, incluso considerada por algunos su mejor novela. En 1964 aparece "Juntacadáveres", novela que Onetti había empezado antes de "El astillero", pero que interrumpió para escribir esta última, la cual continúa la historia. "Juntacadáveres" fue finalista del Premio Rómulo Gallegos en 1967, pero perdió ante "La casa verde" de Mario Vargas Llosa, también de tema prostibulario, lo cual dio ocasión a que Onetti bromeara diciendo que «su burdel en "La casa verde" era mejor que el mío en "Juntacadáveres". El mío no tenía orquesta». Estas tres novelas ("La vida breve", "El astillero" y "Juntacadáveres") conforman lo que después se llamó "Trilogía de Santa María", si bien no son las únicas obras del autor ambientadas en la ciudad.

En 1967 Onetti graba un disco para la serie Voz Viva de América Latina, que contiene la lectura de fragmentos de la obra en voz del autor. En el mismo año aparece en Buenos Aires la primera edición de sus "Cuentos completos" por el Centro Editor de América Latina, y en 1970 la editorial Aguilar de México publica una primera edición de sus "Obras completas", si bien omite algunos relatos de juventud. En 1973 publica la novela corta "La muerte y la niña". En 1974 publicó una segunda edición de sus "Cuentos completos" y la novela corta "Tiempo de abrazar" junto con todos sus cuentos escritos y publicados entre 1933 y 1950, además de ser jurado del Premio Anual de Narrativa organizado por "Marcha", que se otorgó a Nelson Marra por su cuento «El guardapespaldas». Dado que tanto el relato como su autor fueron censurados por el dictador Juan María Bordaberry, Onetti fue detenido y encerrado en un hospital psiquiátrico, de donde logró salir al cabo de tres meses gracias a la intervención del poeta español Félix Grande, entonces director de "Cuadernos Hispanoamericanos", quien recogió firmas para lograr la liberación del escritor uruguayo, y del diplomático español Juan Ignacio Tena Ybarra director del Instituto de Cultura Hispánica (a donde había dictado una serie de conferencias en 1972). Después de una breve estadía en Buenos Aires, es invitado nuevamente a Madrid por el Instituto Internacional de Literatura Iberoamericana para participar en un congreso sobre el barroco. Onetti decide instalarse definitivamente en la capital española, donde residirá durante casi veinte años.

Los años españoles se caracterizaron por una menor producción literaria pero de muchos premios y participaciones en congresos, participaciones que muchas veces se vieron afectadas por timidez de Onetti, quien llegó a permanecer encerrado en la habitación del hotel durante la celebración del Primer Congreso Internacional de Escritores de Lengua Española en la ciudad de Las Palmas, en Gran Canaria, evento del cual había sido designado presidente, negándose a participar en ninguna de las actividades previstas.

En 1979 publica "Dejemos hablar al viento", novela con la que concluye la saga de Santa María, y que está dedicada a su amigo Juan Ignacio Tena Ybarra, en agradecimiento a las gestiones que emprendió para permitir su liberación. Además de esta novela, continuó escribiendo artículos, muchas veces tratando la problemática de los exiliados latinoamericanos. En 1981 es anunciado como el ganador del Premio Cervantes de 1980, recibiendo así el galardón más importante de su carrera, el mismo año que fue propuesto por el Pen Club como candidato al Premio Nobel de Literatura, el cual no recibió. Cuando en 1985 la democracia regresa a Uruguay, el presidente electo, Julio María Sanguinetti, lo invita a la ceremonia de instalación del nuevo Gobierno; el escritor agradece la invitación pero decide permanecer en Madrid.

En 1987 publica "Cuando entonces", su primera novela después de ocho años. Para entonces, Onetti llevaba una vida cada vez más ermitaña: pasó sus últimos doce años encerrado en su departamento sobre la avenida América, en donde recibía la visita de lectores y periodistas, sin salir prácticamente de su cama, leyendo, fumando y tomando whisky. En 1993 publicó su último libro, la novela "Cuando ya no importe", en la que resucita por última vez la ciudad de Santa María.

Falleció el 30 de mayo de 1994 a los 84 años en una clínica madrileña, a causa de problemas hepáticos. Siguiendo su última voluntad, sus restos fueron cremados en el Cementerio de La Almudena, en la capital española.

El narrador (o narradores) en la obra de Juan Carlos Onetti es un complejo elemento que no deja de asombrar. Con frecuencia Onetti hace del acto de narrar uno de los hechos de la trama. Ello desdobla sus ficciones, aportándoles un grado de lucidez ejemplar en la literatura en español del siglo XX. Un pasaje revelador en este sentido es el siguiente de la novela "Juntacadáveres":

En la novelística, el primer narrador de Onetti (aparecido en "El pozo") es estrictamente un narrador-protagonista, personaje central de la novela que narra su propia historia. El papel tanto de personaje, Eladio Linacero, como de narrador valen por igual:

En la novela corta "Los adioses" (1954) un narrador en primera persona que también es personaje pero secundario, almacenero del pueblo, se encarga de contarle al narratario lo que sabe y vio de un exbasquetbolista:

En "Jacob y el otro" (novela corta o cuento largo), estamos ante un relato construido por tres narradores: dos narradores-personaje (uno protagonista y otro secundario) y un narrador en tercera persona. "Jacob y el otro" es la historia de la llegada del luchador Jacob van Oppen y el Comendador Orsini a Santa María, quienes promueven un desafío (“500 pesos 500 a quien suba al ring y no sea puesto de espaldas en 3 minutos por Jacob van Oppen”) y una exhibición de lucha grecorromana.

El primer narrador que aparece, el médico, muestra su intervención como personaje y deja clara la imposibilidad de omnisapiencia como narrador. Este narrador “junto con sus lectores sabe ahora que no puede poseer «La Verdad»; ya no mira los hechos desde una altura olímpica que lo libra de ataduras. No hay «Verdad» y los hechos se contaminan con su persona al momento de escribirlos (así como él sufre influencias, también, por este contacto). Está inmerso en el universo narrativo –no arriba, ni enfrente, ni atrás- y, efectivamente, es una de las personas que lo transita":

Más adelante aparece el narrador en tercera persona:

Y el narrador que cierra el relato es el príncipe Orsini, el Comendador Orsini, protector de Jacob van Oppen:

La obra literaria de Onetti, fuera de su poderosa originalidad, debe mucho a dos raíces distintas. La primera nace en su admiración por la obra de William Faulkner. Como él, crea un mundo autónomo, cuyo centro es la inexistente ciudad de Santa María. La segunda raíz es el Existencialismo: una angustia profunda se encuentra enterrada en cada uno de sus escritos, siempre íntimos y desesperanzados.

Juan Carlos Onetti recibió numerosos premios a lo largo de su vida, entre los que destacan el Premio Nacional de Literatura de Uruguay (lo recibe en 1962 por el bienio 1959/1960), el Premio Cervantes (1980), el Gran Premio Nacional de Literatura de Uruguay 1985, el Premio de la Unión Latina de Literatura 1990 y el Gran Premio Rodó a la labor intelectual, de la Intendencia Municipal de Montevideo (1991).

En 1972 fue elegido como el mejor narrador uruguayo de los últimos 50 años en una encuesta realizada por el semanario "Marcha", en la que participaron escritores de distintas generaciones.

En 1980 fue propuesto por el Pen Club Latinoamericano como postulante al . Ese mismo año Onetti recibía el Premio Cervantes, máximo premio de la lengua española, siendo totalmente ignorado por las autoridades uruguayas. En esa oportunidad el ministro de Cultura del gobierno dictatorial de ese momento en Uruguay, el Dr. Daniel Darracq, dijo desconocer la obra de Onetti, aunque sí había oído hablar de él.






El traductor británico Nick Caistor vertió al inglés "El astillero" con el título "The Shipyard".





</doc>
<doc id="17504" url="https://es.wikipedia.org/wiki?curid=17504" title="Tuxedomoon">
Tuxedomoon

Tuxedomoon es un grupo de música de vanguardia estadounidense, de estilo inclasificable, capaces de instrumentar temas "new wave", "jazz fussion" o puramente experimentales, utilizando instrumentos tradicionales y sintetizadores. Creado en San Francisco, Estados Unidos, en 1977 por dos estudiantes de música electrónica, Blaine Reininger y Steven Brown. Otros músicos importantes que participaron en algún momento en la formación son Peter Principle y Winston Tong. Durante parte de su historia han vivido en Bélgica. 

En 1980 publican su primer LP, "Half Mute". En 1982, el coreógrafo Maurice Béjart les encarga la música para el ballet "Divine", tributo a Greta Garbo. En 1983 Reininger deja el grupo para seguir su carrera en solitario. En 1985 publican "Holy Wars", que se convierte en su mayor éxito comercial. Wim Wenders utiliza el tema "Some Guys" en las escenas iniciales de su película El cielo sobre Berlín.

Su último disco de estudio fue "You", publicado en 1987.
Discografía (incompleta):





</doc>
<doc id="17505" url="https://es.wikipedia.org/wiki?curid=17505" title="Feudo">
Feudo

Feudo
("feodum" o "feudum" en latín medieval, con distintos nombres locales en lenguas vulgares, como "fief" -en francés medieval-, "lehen", "lehn", "len" o "leen" -en las lenguas germánicas-) es el término con el que en el feudalismo se designaba a la tierra que el señor otorga al vasallo en el contrato de vasallaje, como parte del "beneficium" ("beneficio") que el señor debe al siervo por el cumplimiento de sus obligaciones de "auxilium et consilium" ("auxilio" —apoyo militar—, y "consejo" —apoyo político—). Las relaciones económicas y de producción que se establecían en el feudo se daban entre ese "vasallo", ahora en funciones de "señor", y los campesinos de su jurisdicción según su distinta situación: siervos (el de mayor sujección, habitualmente sometidos a prestaciones obligatorias de trabajo) o campesinos libres.

En el feudo se encontraban establecimientos por cuya utilización el señor cobraba contraprestaciones en metálico o en especie. Entre estos establecimientos se hallaban la panadería, la herrería, la taberna y el molino. También podían devengarse por la explotación de un bosque, el uso de un río, y eventualmente su vadeo a través de un puente, cuya utilización devengaba el "peaje" o pontazgo. Todas estas rentas constituían el monopolio del señor y se complementaban además con las que obtenía de su propio campo de cultivo o dominio, en el que trabajaban los siervos. También la Iglesia tenía su propio impuesto llamado diezmo, consistente en el cobro del 10% de la cosecha.

En Castilla, puede considerarse como equivalente al señorío. No obstante, hay un debate historiográfico sobre las diferencias entre el régimen señorial en Castilla y el modelo europeo, ligado a la descomposición del Imperio carolingio.

En la Corona de Aragón el término feudo era tan común como el de "señorío". A diferencia de los modelos de Castilla, en Aragón convive, junto al feudo tradicional, el llamado feudo honrado u honorato, que se diferencia del resto en que no se produce contraprestación económica alguna, ya que la concesión feudal es "absque tamen aliquius prestacione servicii" o "nulli servitio obnoxium", y se recibe bajo la fórmula de juramento, fidelidad y homenaje.

Aunque en origen el señor (por ejemplo, el rey) retenía la capacidad de retirar el feudo a su vasallo (por ejemplo, un conde), el feudo en la práctica se fue haciendo vitalicio y hereditario, pasando a convertirse en el patrimonio de una familia noble. No conviene utilizar el término propiedad para esta relación, más propiamente vinculación. Los derechos plenos de propiedad no son propios de la Edad Media (ni siquiera del Antiguo Régimen), sino del Derecho Romano o del Estado Liberal. El señor que lo da, y su vasallo noble que lo recibe, comparten de alguna manera algún tipo de derecho de dominio sobre el feudo (que podría llegar hasta la teórica reversión al señor en caso de felonía o incumplimiento de la fidelidad debida, o de la liberación de toda obligación para el vasallo en felonía por parte del señor), del mismo modo que el señor y su siervo campesino también comparten el dominio sobre la tierra (dominio útil y dominio eminente).

La manera de explotar económicamente el feudo, en su manera "clásica", en los siglos de la Alta Edad Media, en que no había casi circulación monetaria y muy escasa comercialización de los excedentes, consistía en repartir la tierra en dos porciones: la "reserva señorial" y el "manso". Cada manso era entregado a un campesino, que se encomendaba ("commendatio") al señor (bien libremente o bien forzosamente), pasando a convertirse en su siervo. En latín "servus" ("ancilla") podría traducirse por esclavo, pero en realidad en la época feudal la utilización de mano de obra esclava en la agricultura no era dominante. La condición jurídica del siervo tampoco era de libertad, puesto que estaba ligado a la tierra que trabajaba. Eso sí, disponía del producto de su manso, que cultivaba a su criterio y del que obtenía lo necesario para su subsistencia (en términos del materialismo histórico, la reproducción de su fuerza de trabajo). Los días que fijara la costumbre (corvea en Francia, serna en Castilla) debía trabajar obligatoriamente en la reserva señorial. Ese trabajo excedente es la forma de obtener el excedente por parte del señor, que se beneficiará del producto de esa reserva (apropiación del excedente por coerción extraeconómica, en esos mismos términos, que define el modo de producción feudal).

La activación de la economía a lo largo de los siglos, sobre todo después del año 1000, que permite que haya circulación monetaria y el surgimiento de mercados, comarcales, urbanos y luego a larga distancia, harán que el modelo se altere, y se conviertan los pagos en trabajo en pagos en especie (fijos o porcentajes, como en la aparcería) o en dinero (renta feudal). Para el señor también eran multitud de derechos feudales que garantizaban que todo tipo de excedente le sea entregado (portazgos, peajes, derecho de molino, de taberna, de tienda, de explotación de bosques, caza y ríos...) incluyendo los pagos más polémicos ("ius primae noctis" o derecho de pernada, habitualmente redimible con un pago). La apropiación de impuestos teóricamente del rey (como la alcabala en Castilla) era también muy común de los señores, en la Baja Edad Media.


</doc>
<doc id="17507" url="https://es.wikipedia.org/wiki?curid=17507" title="Gray">
Gray

Gray puede referirse a las siguientes personalidades:


Asimismo, puede hacer referencia a los siguientes autores de nombre científicos:

También, puede referirse a los siguientes lugares o divisiones administrativas:

Además, puede hacer referencia a:


</doc>
<doc id="17508" url="https://es.wikipedia.org/wiki?curid=17508" title="David Lynch">
David Lynch

David Keith Lynch (Missoula, Montana, Estados Unidos, 20 de enero de 1946), conocido como David Lynch, es un director de cine, actor, productor de música electrónica y guionista estadounidense. Su actividad artística se extiende asimismo al terreno de la pintura, la música, la publicidad, la fotografía, e incluso el diseño de mobiliario.

Reconocido admirador de Stanley Kubrick, Jacques Tati, Ingmar Bergman y Werner Herzog, su amor por el dadaísmo y el surrealismo queda patente en algunas de sus películas, cuya misteriosa atmósfera mezcla lo cotidiano con lo soñado, escapando a veces a la comprensión exhaustiva del espectador. Estos rasgos están presentes desde su primer largometraje, "Eraserhead" (1977). Su segunda película, "El hombre elefante" (1980), fue un gran éxito crítico y comercial, recibiendo 8 nominaciones a los Premios Óscar. Su tercer film, "Dune" (1984), no contó con el respaldo de la crítica y supuso un fracaso comercial. Seguidamente dirigió "Blue Velvet" (1986), con la que volvió a recibir la aclamación crítica y una nueva nominación al Óscar en la categoría de mejor director.

Posteriormente se unió a Mark Frost para crear la serie de televisión "Twin Peaks" (1990–1991; 2017), que gozó de gran popularidad y apoyo unánime por parte de la crítica, siendo considerada una serie de culto. Con "Corazón Salvaje" (1990) recibió la Palma de Oro en el Festival de Cannes. Su siguiente largometraje fue "" (1992), una precuela de la serie. Regresó con "Lost Highway" (1997), un thriller psicológico que aunque recibió críticas mixtas, en la actualidad es considerada una película de culto. Posteriormente dirigió el que se considera su film más accesible, "The Straight Story" (1999), que contó con gran aclamación de la crítica. Ya en el siglo XXI, realizó "Mulholland Drive" (2001), un nuevo thriller psicológico de estructura no lineal por el que recibió el y su tercera nominación al Óscar como mejor director. Su décimo y último largometraje, que le ocupó varios años de rodaje usando exclusivamente técnicas digitales, ha sido "Inland Empire" (2006). En la actualidad, algunos de sus proyectos cinematográficos y de animación son sólo accesibles a través de su sitio web.

Un elemento recurrente en su cine es describir los entresijos de pequeñas comunidades de Estados Unidos, como es el caso de "Blue Velvet" o "Twin Peaks", sintiendo también predilección por los secretos ocultos de los barrios periféricos de Los Ángeles, retratados en "Lost Highway", "Mulholland Drive" e "Inland Empire". El sonido en sus películas es de gran importancia, y por ello cada banda sonora es trabajada con esmero. El responsable de ese sonido es el compositor Angelo Badalamenti, colaborador habitual del director y creador entre otras de la reconocida banda sonora de la serie "Twin Peaks", o de la de "The Straight Story" y "Mulholland Drive", ambas nominadas al . Lynch ha conseguido destacarse según la crítica como uno de los pocos directores actuales con un estilo auténticamente personal y un referente ineludible en el cine contemporáneo.

Lynch podría considerarse el arquetipo del muchacho estadounidense de clase media. Según Thierry Jousse, redactor de la revista "Cahiers du cinéma" y autor de un libro sobre Lynch, «cuando habla de su infancia Lynch la describe invariablemente como una etapa idílica, una especie de permanente sueño despierto, cuyo único aspecto problemático fue, sin duda, una forzada vida nómada». Su padre, Donald, fue un científico adscrito al Ministerio de Agricultura norteamericano, y su madre Sunny era profesora de lengua. La familia vivió en distintos lugares, entre el noroeste del país y Carolina del Norte. Lynch fue boy scout y a los 15 años participó como acomodador en la toma de posesión del presidente John F. Kennedy.

Pronto experimentó impulsos artísticos y asistió al "Corcoran School of Art" en Washington, D.C. mientras terminaba sus estudios secundarios en Alexandria, Virginia. Después se apuntó al "School of the Museum of Fine Arts" de Boston durante un año, antes de partir rumbo a Europa en compañía de su amigo y colega artístico Jack Fisk. Sus planes eran estudiar con el pintor del expresionismo austríaco Oskar Kokoschka (quien resultaría uno de sus principales referentes artísticos) durante tres años. Sin embargo, Lynch regresó a los Estados Unidos al cabo de sólo 15 días.

En 1966, Lynch se instala en la ciudad Filadelfia, Pensilvania, asistiendo al "Pennsylvania Academy of Fine Arts" (PAFA). Allí se dedicó en principio a la confección de complejos mosaicos a base de figuras geométricas, a los que él llamó "Industrial Symphonies". Por aquel tiempo, tuvo sus primeros devaneos cinematográficos. Su primer corto recibió el título de "Six Men Getting Sick" ("Seis hombres enfermos") (1966). Él lo describió como "57 segundos de desarrollo y pasión, y tres segundos de vómito". Con esta pieza ganó el certamen anual de la Academia. Este pequeño éxito le permitió abordar su segundo cortometraje: "The Alphabet".

A partir de 1970, Lynch se centró exclusivamente en el arte cinematográfico. Consiguió un premio de 5.000 dólares del "American Film Institute" por "The Grandmother", ("La abuela") sobre un pobre chico de la calle que se las ingenia para conseguir una abuela a partir de una semilla. Esta película de 30 minutos de duración muestra ya muchos de los patrones característicos en su cine de madurez, incluyendo un sonido perturbador y envolvente y una potente imaginería enfocada a los deseos y al inconsciente reprimido, todo ello lejos de los métodos tradicionales de narrar.

En 1971, Lynch se trasladó a Los Ángeles para asistir a las clases del American Film Institute Conservatory. Fue allí donde empezó a trabajar en su primer largometraje, "Eraserhead", aprovechando una ayuda de 10.000 dólares concedida por dicha institución. Este dinero no alcanzó para terminar el film y por este motivo la película no se remataría hasta el año 1977. Lynch tuvo que pedir dinero a amigos y familiares, incluyendo a su amigo de la infancia Jack Fisk, diseñador de producción y marido de la actriz Sissy Spacek, e incluso se dedicó a vender periódicos para financiarla.

"Eraserhead" es una película enigmática y sombría, plena de guiños surrealistas y elementos desasosegantes. Por tal motivo fue rodada apropiadamente en blanco y negro. Cuenta la historia de un joven tranquilo (papel que interpreta Jack Nance) que vive en una especie de área industrial y cuya novia da a luz a una rara bestezuela que no para de gemir. Lynch se refiere a la película como “mi historia de Filadelfia”, aludiendo al hecho de que refleja muy bien todas las crudas experiencias que vivió en esa ciudad en su etapa de estudiante, experiencias que le marcaron profundamente.

Sobre la película, la crítica ha afirmado que sugiere o intenta sugerir los miedos y ansiedades del propio cineasta acerca de la paternidad, personificados en el grotesco aspecto del bebé, que se ha convertido en uno de los íconos del cine fantástico de todas las épocas. El director ha rehuido en más de una ocasión explicar cómo fue elaborada la criatura, pero la leyenda cuenta que fue construida a partir de un feto de vaca embalsamado.

Debido a sus extravagantes contenidos, al principio se pensó que "Eraserhead" no podría ser exhibida comercialmente. Sin embargo, gracias al esfuerzo del distribuidor Ben Barenholtz, se convirtió pronto en un clásico, típico en salas especializadas en proyecciones de medianoche, fuera de las grandes audiencias. La crítica más avanzada la alabó inmediatamente como obra maestra, lo que colocó al director a la cabeza de la vanguardia cinematográfica. El gran director Stanley Kubrick afirmó con admiración que era una de sus películas favoritas de toda la historia del cine. El éxito provocó que el equipo de actores y técnicos (entre ellos el cámara Frederick Elmes, el técnico de sonido Alan Splet, y el actor Jack Nance) siguieran trabajando con Lynch en años posteriores.

"Eraserhead" atrajó la atención del productor Mel Brooks, quien contrató a Lynch para dirigir la película de 1980 "The Elephant Man" ("El hombre elefante"). Escrita por Chris de Vore y Eric Bergren, se trata de un biopic inspirado en la figura de Joseph Merrick, un hombre de clase baja con tremendas malformaciones físicas. El film fue protagonizado por John Hurt como John Merrick (su nombre real fue cambiado) y Anthony Hopkins como Frederick Treves. El rodaje tuvo lugar en Londres, y Lynch le dio su propio enfoque surrealista a la película, filmándola como la anterior en blanco y negro. No obstante, ha sido descrita como "una de las más convencionales" de sus películas. "El hombre elefante" fue un gran éxito comercial y obtuvo ocho nominaciones a los Óscar, incluyendo la de mejor director y mejor guion adaptado para Lynch. De este modo quedó probada la viabilidad comercial de sus propuestas.

Posteriormente, el cineasta aceptó dirigir una superproducción que adaptaba la novela de ciencia ficción "Dune", del escritor Frank Herbert, para el productor italiano Dino De Laurentiis, con la condición de que la productora se comprometiera a financiar un segundo proyecto sobre el cual Lynch mantendría control creativo total. Aunque el productor esperaba que "Dune" (1984) supondría algo así como una nueva "Guerra de las galaxias", la película resultó un gran fiasco comercial, siendo además vapuleada por la crítica. Se calculó que ingresaría 45 millones de dólares que al final se quedaron en sólo 27,4. Para compensar pérdidas, el estudio elaboró una versión alargada para la televisión que desvirtuaba el montaje del director y que Lynch desautorizó inmediatamente.

La segunda película de Lynch producida por De Laurentiis fue "Blue Velvet" ("Terciopelo azul", 1986), la historia de un joven universitario (representado por el actor que protagonizara "Dune", Kyle MacLachlan) que descubre el lado oscuro de una pequeña ciudad, al investigar la procedencia de una oreja cortada que había encontrado casualmente en el transcurso de un paseo campestre. La película muestra actuaciones memorables de Isabella Rossellini, en el papel de una cantante atormentada, y de Dennis Hopper en el de un criminal psicópata, líder de una banda de matones de medio pelo.

"Blue Velvet" obtuvo un gran éxito de crítica y proporcionó a Lynch su segunda nominación al Óscar al mejor director. La película presenta algunos lugares comunes en su cine: una cuidadísima puesta en escena, ciertos episodios y conductas inexplicables, mujeres ultrajadas, los malsanos entresijos de una pequeña comunidad, y la utilización poco convencional de canciones antiguas. "Blue velvet", de Bobby Vinton e "In dreams" de Roy Orbison suenan en este film extrañas y perturbadoras. Esta fue la primera ocasión en que Lynch trabajaba con el compositor Angelo Badalamenti, quien contribuiría en todas sus películas posteriores.

El director Woody Allen, cuya cinta "Hannah y sus hermanas" fue nominada como mejor película, afirmó que "Blue Velvet" era el mejor filme del año. La película, que es comúnmente considerada como una de las obras maestras del cine contemporáneo, ha llegado a convertirse en un icono de la cultura popular.

Al no obtener financiación para posteriores guiones, a finales de los 80 Lynch optó por colaborar con el productor televisivo Mark Frost en la serie televisiva "Twin Peaks", acerca de una pequeña localidad de Washington donde ocurren extraños sucesos. La historia se centraba en las investigaciones realizadas por el agente especial del FBI Dale Cooper (de nuevo Kyle MacLachlan) en torno a la muerte de una conocida estudiante de secundaria llamada Laura Palmer, una investigación que iba revelando los escabrosos secretos de muchos ciudadanos aparentemente respetables. El cineasta dirigió seis episodios en total, incluyendo los dos primeros, y escribió o co-escribió algunos más, e incluso apareció como actor en algunos de ellos.

La serie se estrenó en la cadena ABC el 8 de abril de 1990 y poco a poco fue revelándose como todo un fenómeno cultural. Ningún otro proyecto de Lynch ha obtenido semejante aceptación. La serie fue vendida a infinidad de países, y algunos de sus latiguillos ingresaron en la cultura popular. Se hicieron parodias de la misma en el show Saturday Night Live y en la serie de animación Los Simpson. Lynch apareció en la portada de la revista Time en gran medida debido al gran éxito cosechado con "Twin Peaks". El director encarnó el papel del vociferante y medio sordo jefe del agente Cooper, Gordon Cole. Pese a todo, Lynch chocó con los responsables de la cadena por distintos motivos, en especial por la posibilidad de revelar o no la identidad del asesino de Laura Palmer. La cadena insistía en desenmascararlo ya en la segunda temporada, pero Lynch quería guardarlo en secreto hasta el final. Lynch pronto se desencantó de la serie y como resultado muchos miembros del reparto declararon sentirse “abandonados”.

Fue en aquel tiempo cuando Lynch empezó a colaborar con la editora, productora y su compañera en la vida real, Mary Sweeney, que había trabajado como asistente para él en "Blue Velvet". Esta colaboración se prolongaría a lo largo de once proyectos. De su relación nació un hijo.

Su siguiente largometraje fue una adaptación de la novela de Barry Gifford, "Wild at Heart" ("Corazón salvaje"), una "road movie" protagonizada por los actores Nicolas Cage y Laura Dern. La producción obtuvo la Palma de Oro en el Festival de Cannes de 1990, pero no contó con la aprobación de la crítica ni el respaldo del gran público.

"Twin Peaks" acabó sufriendo serios reveses de audiencia y fue retirada en 1991. Mientras tanto Lynch escribió una precuela sobre los últimos siete días en la vida del personaje de Laura Palmer, que dio lugar al largometraje "" (1992), que fracasó en taquilla y acarreó al director las peores críticas de su carrera.

El eslabón perdido entre "Twin Peaks" y "Wild at Heart", es el espectáculo musical "", una nueva colaboración con Angelo Badalamenti en la que canta Julee Cruise y actúan varios actores de "Twin Peaks", así como Nicolas Cage y Laura Dern. Lynch confesó que la obra reflejaba de alguna forma una relación sentimental rota. El director produjo en 1990 un vídeo de 50 minutos sobre la obra.

Durante este periodo Lynch volvió a colaborar con Mark Frost la serie documental "American Chronicles" (1990) y en la serie de humor "On the Air" (1992) para la ABC, sobre los orígenes de la televisión. En EE.UU. sólo se emitieron tres episodios. Su siguiente proyecto fue la miniserie para la cadena HBO titulada "Hotel Room" (1993), la cual narraba los acontecimientos que se enmarcaban en una misma habitación de hotel a lo largo de varias décadas.

En 1997 Lynch volvió a la palestra con el complejo film de argumento no lineal "Lost Highway" ("Carretera perdida"), el cual poseía muchos elementos de cine negro. Fue coescrito con Barry Gifford y protagonizado por los actores Bill Pullman y Patricia Arquette. La película fracasó comercialmente, pero recibió críticas contrapuestas. No obstante, gracias en parte a la banda sonora en que aparecían cantantes y grupos como Marilyn Manson, Rammstein, Nine Inch Nails y The Smashing Pumpkins, Lynch obtuvo una nueva audiencia por parte de espectadores de la llamada Generación X.
En 1999, sorprendió muy positivamente a sus fans y a la crítica con una película producida por la compañía Disney: "The Straight Story" ("Una historia verdadera/Una historia sencilla"), que era, al menos aparentemente, una sencilla película sin pretensión alguna contando una historia real acerca de un hombre de pueblo (interpretado por el veterano actor Richard Farnsworth) que emprende un largo viaje de estado en estado, a bordo de un cortacésped, con el único fin de hacer las paces con su hermano enfermo. La película recibió críticas muy elogiosas y proporcionó a su autor nuevas audiencias. Fue nominada la Palma de Oro, recibió dos nominaciones a los Globos de Oro (banda sonora y actor dramático), y Richard Farnsworth fue nominado a los Óscar en la categoría de mejor actor.

Ese mismo año Lynch tentó una vez más a la cadena ABC con la idea de un drama para la televisión. La cadena dio el visto bueno y se grabó el episodio piloto, de dos horas de duración. Pero controversias sobre el contenido y la duración de la serie la aparcaron definitivamente. Con la aportación de 7 millones de dólares por parte de la productora francesa Studio Canal, el director convirtió ese episodio piloto en el largometraje "Mulholland Drive". Estrenada finalmente en 2001, es una historia que trata de ahondar en la vertiente oscura de Hollywood, la “fábrica de sueños”. Está protagonizada por Naomi Watts, Laura Harring y el actor Justin Theroux. En lo comercial, la película funcionó relativamente bien en todo el mundo, mereciendo además reseñas positivas, y Lynch obtuvo por ella el premio al mejor director en el Festival de Cannes del año 2001 (este premio lo compartió con Joel Coen por "El hombre que nunca estuvo allí") y otro premio al mejor director otorgado por la "New York Film Critics Association". El film recibió además cuatro nominaciones a los Globos de Oro y supuso además la tercera nominación al Óscar como mejor director de David Lynch.

En 2002, Lynch desarrolló una serie de cortos para Internet titulada "DumbLand". Los ochos episodios de que constaba, intencionadamente muy duros de contenido e interpretación, aparecieron posteriormente en formato DVD.

Lynch dedicó a sus incondicionales ese mismo año una comedia de situación a través de su página web. La serie se tituló "Rabbits" ("Conejos") y constó de ocho episodios plenos de surrealismo que se desarrollaban en un cuarto habitado por extrañas personas con cabeza de roedor. Posteriormente, el director rodó en vídeo digital el corto "Darkened Room", a imitación del exitoso cine de terror japonés de los últimos años.
En el Festival de Cannes correspondiente a 2005, el cineasta anunció que durante un año había estado rodando en Polonia, por medio de técnicas digitales, su último film. La película, titulada "Inland Empire", es interpretada como un compendio del cine de Lynch. La historia, compleja y con tintes pesadillescos, desarrolla distintos niveles argumentales entremezclados, sin aclarar nunca los nexos lógicos entre ellos. Abunda en primeros planos expresionistas (especialmente de Laura Dern), el sonido es distorsionado y envolvente, y los efectos especiales unidos a las numerosas escenas cómico-grotescas que contiene producen un gran impacto visual. El reparto de la película incluye actores habituales de Lynch como la ya mencionada Laura Dern, Justin Theroux, Harry Dean Stanton o Grace Zabriskie, así como Jeremy Irons, Karolina Gruszka, Peter J. Lucas, Krzysztof Majchrzak, Julia Ormond o Diane Ladd. Además, Naomi Watts y Laura Harring prestan su voz a dos de los conejos de la película. Lynch describió la película como "un misterio acerca de una mujer metida en grandes dificultades”. Se estrenó en diciembre de 2006, suscitando entre los críticos, al igual que los últimos largometrajes del director, multitud de comentarios enfrentados, aunque la opinión fue mayoritariamente muy positiva.

Lynch ha declarado a menudo admirar profundamente a los cineastas Stanley Kubrick y Federico Fellini, al escritor Franz Kafka y al pintor Francis Bacon. Sostiene que muchas de las películas de Kubrick se encuentran entre sus preferidas, y que las obras de Kafka y Bacon lo subyugan por su fuerza visual y su conmovedora sensibilidad. Igualmente ha citado al pintor expresionista austriaco Oskar Kokoschka como fuente de inspiración. Lynch se siente desde siempre hechizado por la película "The Wizard of Oz" ("El mago de Oz"), aunque no con el culto típico norteamericano y a menudo ha hecho clara referencia a la misma en cintas como "Wild at Heart", donde crea una gran polémica al parodiarla.

Una influencia temprana en él fue el libro "The Art Spirit" del artista y profesor norteamericano Robert Henri, del cual afirmó que le ayudó a decidir el curso que tomaría su trabajo plástico. Como Henri, Lynch se trasladó del campo a un entorno urbano para desarrollar su carrera artística. Henri era un pintor realista urbano, que adoptaba la vida en la ciudad como materia principal de su trabajo, lo que imitó Lynch en sus orígenes. Y si la obra de Henri sirvió de puente entre la Norteamérica agrícola del siglo XIX y la urbana del XX, las cintas de Lynch entremezclan la nostalgia feliz de los años 50 con la extrañeza existencial de los 80 y 90.

Tienen gran peso sobre su obra igualmente los cineastas Luis Buñuel, Werner Herzog y Roman Polanski, alguno de los cuales ha reconocido también al propio Lynch como referente.

Lynch emplea a menudo a los mismos actores y al mismo equipo técnico y artístico en sus producciones:

Angelo Badalamenti: música de los largometrajes "Blue Velvet, Twin Peaks, Wild at Heart, On the Air, Lost Highway" y "Mulholland Drive". También escribió la música de "Industrial Symphony No. 1, Twin Peaks: Fire Walk With Me, Hotel Room, The Straight Story, Darkened Room" y "Rabbits".

Mary Sweeney, su habitual editora y productora. Escribió el guion de "The Straight Story". Trabajó igualmente en: "Blue Velvet" (1986), "Wild at Heart" (1990), "Twin Peaks" serie de TV, "Twin Peaks: Fire Walk with Me" (1992), "Hotel Room", serie de TV (1993), "Lost Highway" (1997), "Mulholland Drive" (2001), "Inland Empire" (2006) y co-produjo "Nadja" (1994) con Lynch.


Jack Nance: en "Eraserhead, Dune, Blue Velvet, The Cowboy and the Frenchman, Twin Peaks, Wild at Heart" y "Lost Highway" 


Harry Dean Stanton: "The Cowboy and the Frenchman, Wild at Heart, Twin Peaks: Fire Walk With Me, Hotel Room, The Straight Story" e "Inland Empire". 


Scott Coffey: "Wild at Heart, Lost Highway, Mulholland Drive, Rabbits" e "Inland Empire".

Freddie Jones: "The Elephant Man, Dune, Wild at Heart, Hotel Room" y "On the Air".

Michael J. Anderson: "Twin Peaks, Industrial Symphony No. 1, Twin Peaks: Fire Walk With Me" y "Mulholland Drive".

Eric DaRe: "Twin Peaks", "Wild at Heart" (casting), "Twin Peaks: Fire Walk With Me" y "Lost Highway" (departamento artístico).
Laura Dern: "Blue Velvet, Wild at Heart, Industrial Symphony No. 1" e "Inland Empire".
Bellina Logan: "Wild at Heart, Twin Peaks, On the Air" e "Inland Empire".

Kyle MacLachlan: "Dune, Blue Velvet, Twin Peaks" y "Twin Peaks: Fire Walk With Me".
Grace Zabriskie: "Twin Peaks, Wild at Heart, Twin Peaks: Fire Walk With Me" e "Inland Empire".

Frances Bay: "Blue Velvet, Twin Peaks" y "Wild at Heart".
Catherine E. Coulson: "The Amputee, Twin Peaks" y "Twin Peaks: Fire Walk With Me".
Miguel Ferrer: "Twin Peaks, Twin Peaks: Fire Walk With Me" y "On the Air".
Laura Harring: "Mulholland Drive, Rabbits" e "Inland Empire".
Sheryl Lee: "Twin Peaks, Wild at Heart" y "Twin Peaks: Fire Walk With Me".
Everett McGill: "Dune, Twin Peaks" y "The Straight Story".
Frank Silva: "Twin Peaks" y "Twin Peaks: Fire Walk With Me", y trabajó como encargado de vestuario en "Wild at Heart".
Charlotte Stewart: "Eraserhead, Twin Peaks" y "Twin Peaks: Fire Walk With Me". 

Naomi Watts: "Mulholland Drive, Rabbits" e "Inland Empire".

Alicia Witt: "Dune, Twin Peaks" y "Hotel Room".


Jeanne Bates: "Eraserhead" y "Mulholland Drive".
Nicolas Cage: Wild at Heart e "Industrial Symphony No. 1". 

Brad Dourif: "Dune" y "Blue Velvet". 

Sherilyn Fenn: en "Twin Peaks" y "Wild at Heart". 

Crispin Glover: "Wild at Heart" y "Hotel Room". Lynch estaba interesado en producir el debut como director de Glover, "What is it?".

Diane Ladd: "Wild at Heart" e "Inland Empire". 

Dean Stockwell: "Dune" y "Blue Velvet".

Justin Theroux: "Mulholland Drive" e "Inland Empire".

Músicos que han aparecido en sus films: Sting en "Dune", Chris Isaak en "Twin Peaks: Fire Walk With Me", David Bowie en "Twin Peaks: Fire Walk With Me", Julee Cruise en "Twin Peaks" y "Twin Peaks: Fire Walk With Me", John Lurie en "Wild at Heart", Marilyn Manson, Twiggy Ramirez y Henry Rollins en "Lost Highway" y Billy Ray Cyrus en "Mulholland Drive".

El propio Lynch se reservó pequeños papeles en "The Amputee, Dune, Twin Peaks" y "Twin Peaks: Fire Walk With Me". También hizo cameos de voz en "INLAND EMPIRE" y "Nadja", y aparecía en una escena suprimida de "Lost Highway".
También interpreta al cantinero "Gus" en la serie animada de tv The Cleveland Show tanto en la voz como en la apariencia.

Durante su trayectoria también dedica su trabajo al formato publicitario, llevando a cabo multitud de spots televisivos desde 1988, entre los que se encuentran distintos fines comerciales; perfumes, artículos de deporte, productos alimenticios, automóviles o dispositivos de entretenimiento. 

A parte del cine, David Lynch ha desarrollado su creatividad en el campo de la pintura. En España su obra pictórica pudo verse con la exposición Action-reaction, que recorrió en 2009 ciudades como Zaragoza y Granada.

Lynch también ha colaborado en el mundo de la música con la creación de videoclips, entre los que destacan "Dangerous" de Michael Jackson (1992), "Longing" de Yoshiki (1995), "Rammstein" de Rammstein (1996), "Shot in the Black of the Head" de Moby (2009) y "Came back Haunted" de Nine Inch Nails (2013), entre otros.

También es destacable su labor en la divulgación de la Meditación Trascendental (MT), desde que se iniciara en ella hacia 1973. En julio de 2005 fundó la David Lynch Foundation For Consciousness-Based Education and World Peace (también conocida simplemente como David Lynch Foundation), para ayudar económicamente a los estudiantes en las escuelas intermedias y secundarias que estén interesados en la Meditación Trascendental y para financiar la investigación sobre la técnica y sus efectos en el aprendizaje. Con los años, la Fundación ha ampliado su enfoque para incluir otras poblaciones "en riesgo", tales como las personas sin hogar, los veteranos de guerra estadounidenses, los refugiados de las guerras africanas y los presos.

En lo personal, Lynch ha mantenido relaciones sentimentales con la actriz Isabella Rossellini (a raíz del rodaje de "Terciopelo azul"), y ha estado casado tres veces: con Peggy Lentz (1967-1974; una hija, Jennifer Chambers Lynch, 1968, ahora directora cinematográfica). Con Mary Fisk (1977-1987) (un hijo, nacido en 1982, Austin Jack Lynch). Y con la editora y productora de sus películas Mary Sweeney (2006; un hijo nacido en 1992, Riley Lynch).










Lynch ha ganado dos veces el Premio César francés a la mejor película extranjera (por "El hombre elefante" y "Mulholland Drive"). En el Festival de Cannes ganó la Palma de Oro en 1990 por "Corazón salvaje" y logró el en 2001 por "Mulholland Drive". En 2002 fue presidente del jurado de dicho festival. En 2002 fue asimismo galardonado por el gobierno francés con la Legión de Honor. El 6 de septiembre de 2006 recibió el León de Oro en el Festival de Venecia por sus contribuciones al Séptimo Arte. En este mismo festival presentó su último film, "Inland Empire".




</doc>
<doc id="17510" url="https://es.wikipedia.org/wiki?curid=17510" title="Historia de la aviación">
Historia de la aviación

La historia de la aviación se remonta al día en el que el hombre prehistórico se paró a observar el vuelo de las aves y de otros animales voladores. El deseo de volar está presente en la humanidad desde hace siglos, y a lo largo de la historia del ser humano hay constancia de intentos de volar que han acabado mal. Algunos intentaron volar imitando a los pájaros, usando un par de alas elaboradas con un esqueleto de madera y plumas, que colocaban en los brazos y las balanceaban sin llegar a lograr el resultado esperado.

Muchas personas decían que volar era algo imposible para las capacidades de un ser humano. Pero aun así, el deseo existía y varias civilizaciones contaban historias de personas dotadas de poderes divinos que podían volar. El ejemplo más conocido es la leyenda de Ícaro y Dédalo, que encontrándose prisioneros en la isla de Minos se construyeron unas alas con plumas y cera para poder escapar. Ícaro se aproximó demasiado al Sol y la cera de las alas comenzó a derretirse, haciendo que se precipitara en el mar y muriera. Esta leyenda era un aviso sobre los intentos de alcanzar el cielo, semejante a la historia de la Torre de Babel en la Biblia, y ejemplifica el deseo milenario del hombre de volar.

La historia moderna de la aviación es compleja. Durante siglos se dieron tímidos intentos por alzar el vuelo, fracasando la mayor parte de ellos, pero ya desde el siglo XVIII el ser humano comenzó a experimentar con globos aerostáticos que lograban elevarse en el aire, pero tenían el inconveniente de no poder ser controlados. Ese problema se superó ya en el siglo XIX con la construcción de los primeros dirigibles, que sí permitían su control. A principios de ese mismo siglo, muchos investigaron el vuelo con planeadores, máquinas capaces de sustentar el vuelo controlado durante algún tiempo, y también se comenzaron a construir los primeros aeroplanos equipados con motor, pero que, incluso siendo impulsados por ayudas externas, apenas lograban despegar y recorrer unos metros. No fue hasta principios del siglo XX cuando se produjeron los primeros vuelos con éxito. El 17 de diciembre de 1903 los hermanos Wright se convirtieron en los primeros en realizar un vuelo en un avión controlado, no obstante algunos afirman que ese honor le corresponde a Alberto Santos Dumont, que realizó su vuelo el 13 de septiembre de 1906.

A partir de entonces, las mejoras se fueron sucediendo, y cada vez se lograban mejoras sustanciales que ayudaron a desarrollar la aviación hasta tal y como la conocemos en la actualidad. Los diseñadores de aviones se siguen esforzando en mejorar continuamente las capacidades y características de estos, tales como su autonomía, velocidad, capacidad de carga, facilidad de maniobra o la seguridad, entre otros detalles. Las aeronaves han pasado a ser construidas de materiales cada vez menos densos y más resistentes. Anteriormente se hacían de madera, en la actualidad la gran mayoría de aeronaves emplea aluminio y materiales compuestos como principales materias primas en su producción. Recientemente, los ordenadores han contribuido mucho en el desarrollo de nuevas aeronaves.

Se sabe que alrededor del año 400 a. C., Arquitas de Tarento, un estudioso de la Antigua Grecia, construyó un artefacto de madera que él mismo bautizó con el nombre de "Peristera" (en griego: "Περιστέρα", "Paloma"), que tenía forma de ave y era capaz de volar a unos 180 metros de altura. Utilizaba un chorro de aire para alzar el vuelo, pero no se tiene constancia de qué era lo que producía ese chorro. El objeto volador se amarraba mediante unas cuerdas que permitían realizar un vuelo controlado hasta que el chorro de aire terminaba. Este artefacto de madera probablemente fue la primera máquina voladora capaz de moverse por medios propios.

La linterna de Kong Ming, precursora del globo aerostático, era conocida en China desde la antigüedad. Su invención se atribuye al general Zhuge Liang, y fueron usadas para asustar a las tropas enemigas. Sobre el año 300 a. C. los chinos inventaron la cometa, que se considera un tipo de planeador, y desarrollaron técnicas para hacerla volar en el aire. Siglos después, en el año 559 hay documentados vuelos de seres humanos usando cometas. El emperador Gao Yang experimentó con prisioneros, entre los que se encontraba Yuan Huangtou, hijo del anterior emperador, Yuan Lang. Les ordenó lanzarse desde lo alto de una torre, y Yuan Huangtou planeó hasta sobrepasar las barreras de la ciudad, aunque poco después moriría ejecutado.

En el año 852, el andalusí Abbás Ibn Firnás, se lanzó desde el minarete de la mezquita de Córdoba con una enorme lona para amortiguar la caída, sufriendo heridas leves, pero pasando a la historia como el precursor de los modernos paracaídas. En el 875, contando con 65 años de edad, Ibn Firnás se hizo confeccionar unas alas de madera recubiertas de tela de seda que había adornado con plumas de rapaces. Con ellas se lanzó desde lo alto de una colina, y logró permanecer en el aire durante un breve espacio de tiempo, aunque hay relatos que afirman que voló durante más de diez minutos. El aterrizaje resultó muy violento y Abbás Ibn Firnás se fracturó las dos piernas, pero consideró que la experiencia había sido un éxito, al igual que la gran multitud de personas que lo observaron.

Este vuelo sirvió de inspiración para Eilmer de Malmesbury, un monje benedictino, que más de un siglo después, hacia el año 1010, recorrió más de 200 metros en el aire, sobre un aparato similar al de Abbás Ibn Firnás.

En el 1290, Roger Bacon, un monje inglés, escribió que el aire, al igual que el agua, tenía algunas características propias de los sólidos. Bacon estudió las ideas de Arquímedes relacionadas con la densidad de los elementos, y llegó a la conclusión de que si las personas pudieran construir una máquina que tuviese las características adecuadas, el aire podría soportar esa máquina, al igual que el mar soporta un navío.

Muy probablemente fue el artista e inventor italiano Leonardo da Vinci la primera persona que se dedicó seriamente a proyectar una máquina capaz de volar. Da Vinci diseñó planeadores y ornitópteros, que usaban los mismos mecanismos usados por los pájaros para volar, a través de un movimiento constante de las alas para arriba y para abajo. Sin embargo, nunca llegó a construir tales máquinas, pero sus diseños se conservaron, y posteriormente, ya en el siglo XIX y siglo XX, uno de los planeadores diseñados por Leonardo da Vinci fue considerado digno de atención. En un estudio reciente, se creó un prototipo basado en el diseño de ese mismo planeador, y de hecho, el aparato era capaz de volar. No obstante, al interpretar el diseño del planeador, se aplicaron algunas ideas modernas relacionadas con la aerodinámica. Aun así, este diseño es considerado como el primer esbozo serio de una aeronave.

Según crónicas de la época, el primer vuelo realizado con éxito de un globo de aire caliente, fue gracias al padre Bartolomeu Lourenço de Gusmão, un portugués nacido en Brasil en la época colonial, que logró alzar el vuelo de un aerostato, al que denominaría passarola, el 8 de agosto de 1709 en la corte de Juan V de Portugal, en Lisboa. En la demostración, la passarola se elevó unos 3 metros por encima del suelo, dejando impresionados a los observadores, y ganándose el apodo de "Padre Volador". No se conservaron descripciones detalladas del acontecimiento, probablemente debido a que fueron destruidas por la inquisición, pero algunos diseños fantasiosos de la excéntrica aeronave salieron en el periódico vienés "Wienerische Diarium" de 1709. Según una crónica de ese periódico, el aparato consistía en un globo de papel grueso, que dentro contenía un cuenco con fuego, y que consiguió elevarse más de veinte palmos. No obstante, la passarola no influyó en los desarrollos de la aviación que ocurrirían posteriormente.

El primer estudio de aviación publicado fue "Sketch of a Machine for Flying in the Air" ("Esbozo de una máquina para volar por el aire"), de Emanuel Swedenborg, publicado en 1716. Este esbozo de máquina voladora consistía en un fuselaje y dos grandes alas que se moverían a lo largo del eje horizontal de la aeronave, generando el empuje necesario para su sustentación en el aire. Swedenborg sabía que su máquina jamás volaría, pero decía que los problemas que existían en su diseño serían resueltos en el futuro. Sus palabras fueron:

La "fuerte barra en espiral" descrita por Swedenborg es lo que actualmente se conoce como hélice. Él sabía que la sustentación y la manera de generar esa sustentación serían indispensables para la creación de un aparato capaz de volar por medios propios.

El primer vuelo humano del que se tiene noticia fue realizado en París el 15 de octubre de 1783, en un globo cautivo. Dos meses más tarde, el doctor Jean-François Pilâtre de Rozier y el noble François Laurent d'Arlandes, realizaron el primer vuelo libre en una máquina creada por el hombre. Consiguieron volar durante 25 minutos, recorriendo 8 kilómetros en un globo de aire caliente, inventado por los hermanos Montgolfier, dos fabricantes de papel. El aire dentro de la cámara de aire del globo se calentaba por una hoguera de madera. El globo tenía el inconveniente de que era incontrolable, volaba donde el viento le llevase. Este globo, por ser bastante pesado, alcanzó una altura máxima de apenas 26 metros. Los hermanos Montgolfier continuaron fabricando otros globos, logrando varios vuelos con éxito, lo que hizo que la experimentación de vuelos con globos se extendiera por Europa a lo largo del siglo XVIII. Los globos permitían la profundización en los conocimientos acerca de la relación entre altitud y atmósfera. Incluso Napoleón Bonaparte planeó usar globos en una posible invasión francesa a Inglaterra.

En noviembre de 1792, los ensayos realizados por un grupo de artilleros en el Real Colegio de Artillería de Segovia y después ante el rey Carlos IV de España del vuelo de un globo aerostático, todos ellos dirigidos por Louis Proust; fueron los primeros realizados en el mundo en el aspecto militar.

También en España, Diego Marín Aguilera fue el primer hombre, que se tiene noticia que voló con un aparato que pesaba más que el aire. En la noche de 15 de mayo de 1793, Diego Marín Aguilera realizó en Coruña del Conde, provincia de Burgos, un vuelo de 360 metros con un artefacto de hierro y plumas de ave, controlado por el propio piloto que logró alcanzar "cinco a seis varas" de altura sobre el punto de partida hasta tomar tierra al otro lado del río después de haber hecho un recorrido de "431 varas castellanas" (unos 360 metros). El motivo del rápido aterrizaje fue la rotura de uno de los pernos que movían las alas. A la mañana, al enterarse los vecinos de lo acontecido en aquella noche emotiva de mayo, se mofaron de su convecino Marín, creyéndole loco, e incendiaron el plumífero aparato como cosa diabólica.

Otros inventores, como el francés Jacques Charles, sustituyeron el aire caliente por hidrógeno, que es un gas más ligero que el aire. Pero de igual forma, los globos seguían sin poder ser dirigidos, y solamente la altitud era controlable por los aviadores.

En el siglo XIX, en 1852, el ingeniero francés Henri Giffard inventó el dirigible, que es una máquina más ligera que el aire, y se diferencia del globo en que su dirección sí podía ser controlada a través del uso de timones y motores. El primer vuelo controlado de un dirigible se realizó el 24 de septiembre de ese mismo año en Francia, controlado por el propio Giffard, logrando recorrer 24 kilómetros, a una velocidad de 8km/h usando un pequeño motor a vapor. A lo largo de finales del siglo XIX y en las primeras décadas del siglo XX, el dirigible fue un método de transporte de confianza.

Con la invención del globo y del dirigible, los inventores pasaron a intentar crear una máquina más pesada que el aire, que fuese capaz de volar por medios propios.

En primer lugar, aparecieron los planeadores, máquinas capaces de sustentar el vuelo controlado durante algún tiempo. En 1799, George Cayley, un inventor inglés, diseñó un planeador relativamente moderno, que contaba con una cola para controlarlo, y un lugar donde el piloto se podía colocar, por debajo del centro de gravedad del aparato, dando así estabilidad a la aeronave. Cayley construyó un prototipo, que realizó sus primeros vuelos no tripulados en 1804. Durante las cinco décadas siguientes, trabajó en su prototipo, tiempo durante el cual Cayley dedujo muchas de las leyes básicas de la aerodinámica. En 1853, un ayudante de Cayley realizó un vuelo de corta duración subido al planeador, en Brompton (Inglaterra). George Cayley es considerado el fundador de la ciencia física de la aerodinámica, habiendo sido la primera persona que describió un aeronave de ala fija propulsada por motores.

En 1856 el francés Jean-Marie Le Bris realizó el primer vuelo que planeó más alto que su punto de despegue, gracias a su planeador, el "L'Albatros artificiel", el cual, para despegar, fue arrastrado por caballos en la playa. Según afirmó, alcanzó una altura de 100 metros y recorrió una distancia de 200.
En 1866, un campesino y carpintero polaco llamado Jan Wnęk construyó y voló un planeador controlable. Wnęk era analfabeto y autodidacta, y todos los conocimientos y deducciones sobre los planeadores los obtuvo mediante la observación del vuelo de los pájaros y gracias a sus habilidades. Jan Wnęk estaba atado con firmeza a su planeador por el pecho y las caderas y lo controlaba mediante giros de las alas. Para probarlo, se lanzó desde la torre de la iglesia de Odporyszów, a 45 metros de altura, y ésta a su vez situada sobre una colina de 50 metros, haciendo que la altura relativa fuera de 95 metros hasta el valle. Realizó varios vuelos con público entre 1866 y 1869, especialmente durante festivales religiosos, carnavales y celebraciones de año nuevo, pero apenas hubo constancia de los hechos de Jan Wnęk, y estos no tuvieron impacto en el progreso de la aviación.

En esa época, Frank Wenham intentó construir una serie de planeadores, pero no tuvieron éxito. En sus esfuerzos, descubre que la mayor parte de la sustentación de un pájaro parecía ser generada en la parte frontal, y Wenham dedujo que unas alas finas, largas y fijas, semejantes a las alas de los aviones actuales, serían más eficientes que las alas similares a las de pájaros o murciélagos. Su trabajo fue presentado en la recién creada Royal Aeronautical Society de Gran Bretaña en 1866, y Wenham decidió probar sus ideas construyendo el primer túnel de viento del mundo, en 1871. Los miembros de la sociedad hicieron uso del túnel y quedaron sorprendidos y encantados con el resultado: las alas fijas generaban sensiblemente más sustentación que lo que los científicos habían previsto. Este experimento claramente demostró que la construcción de máquinas más pesadas que el aire era posible, el problema era como generar el empuje necesario para mover el aparato hacia delante, ya que habían comprobado que las aeronaves de ala fija precisaban de un flujo de aire constante pasando por las alas, y aún hacía falta poder tener el control de la aeronave en vuelo.

En 1874, Félix du Temple construyó un planeador realizado con aluminio, en Brest (Francia), al que denominó "Monoplane". Contaba con una envergadura de 13 metros y un peso de 80 kilogramos sin contar al piloto, además de ser autopropulsado. Realizó varias pruebas, y al parecer consiguió despegar gracias a una rampa, y lograr después un aterrizaje seguro, realizando el primer vuelo autopropulsado de la historia, aunque fuera durante un breve espacio de tiempo y la distancia recorrida fuera escasa.

La década de 1880 fue un tiempo de estudios intensos, caracterizados por los "gentleman scientists", científicos que disponían de recursos necesarios para investigar de manera independiente sin tener que depender de financiación ajena, que hicieron la mayor parte de las investigaciones en el campo de la aeronáutica hasta la llegada del siglo XX. Se realizaron un gran número de avances que harían posible disponer de los primeros planeadores prácticos. Tres nombres en particular aportaron grandes conocimientos: Otto Lilienthal, Percy Pilcher y Octave Chanute.

Uno de los primeros planeadores modernos fue construido en Estados Unidos por John Joseph Montgomery, que voló en su máquina el 28 de agosto de 1883, en un vuelo controlado. Pero tuvo que pasar mucho tiempo para que los trabajos de Montgomery fueran conocidos. Otro planeador fue construido por Wilhelm Kress en 1877 en Viena.
El alemán Otto Lilienthal continuó el trabajo de Frank Wenham, publicando sus investigaciones en 1889. Lilienthal también fabricó una serie de planeadores, y en 1891 fue capaz de hacer vuelos sustentados logrando recorrer más de 25 metros, mejorando intentos anteriores que presentaban resultados inestables. El alemán documentó rigurosamente su trabajo, incluso con fotografías, y por esa razón, es uno de los pioneros de la aviación más conocidos. También promovió la idea de "salta antes de que alces el vuelo", sugiriendo que los investigadores deberían comenzar con planeadores y después intentar trabajar en proyectos para desarrollar un avión, en vez de diseñar tal avión directamente en un papel y esperar a que ese diseño funcione.

Lilienthal realizó con éxito varios vuelos hasta 1896, año en el que falleció en un accidente aéreo el 9 de octubre, causado por un viento lateral repentino, que rompió un ala de su aeronave en pleno vuelo, haciendo que se precipitara desde una altura de 17 metros. Por todo eso, Lilienthal es considerado la primera persona que realizó un vuelo planeado controlado, en el cual era el piloto el que controlaba a la aeronave. Sus últimas palabras antes de morir, al día siguiente, fueron: "Deben hacerse sacrificios".

En esos momentos, Lilienthal estaba trabajando en busca de pequeños motores adecuados para equipar a sus aeronaves, con la idea de crear un prototipo más pesado que el aire y capaz de alzar el vuelo por medios propios.

Octave Chanute continuó el trabajo de Lilienthal en el área de los planeadores. Creó varios prototipos e incluyó mejoras en sus aeronaves. En el verano de 1896, realizó varios vuelos sobre sus planeadores en Miller Beach (Indiana, Estados Unidos), y decidió que el mejor de todos ellos era un biplano. Al igual que Otto Lilienthal, Chanute documentó detalladamente su trabajo, y también fotografió sus máquinas y experimentos. Durante sus investigaciones, dedicó parte de su tiempo a comunicarse mediante correspondencia con personas que tenían sus mismos intereses, entre ellas Percy Pilcher. Chanute estaba particularmente interesado en solucionar el problema de cómo proporcionar estabilidad a la aeronave cuando esta estuviese en vuelo. Esa estabilidad se conseguía de manera natural en pájaros, pero tenía que ser realizada manualmente en el caso de humanos. Dentro de los problemas relacionados con la estabilidad del biplano en vuelo, el más desconcertante era la estabilidad longitudinal, ya que el ángulo de ataque del ala, hacía que el centro de presión de la aeronave se incrementara e hiciese que el ángulo del biplano aumentase todavía más, y entrara en pérdida.

En el siglo XIX se realizaron algunos intentos de producir un avión que despegase por medios propios. Pero la mayoría de ellos eran de pésima calidad, construidos por personas interesadas en la aviación pero que no tenían los conocimientos de los problemas que trataron Lilienthal y Chanute.

En 1843, William Henson, un inventor inglés, registró la primera patente de una aeronave equipada con motores, hélices, y provista de un ala fija, lo que en la actualidad se conoce como avión. Pero el prototipo construido basándose en los diseños de Henson no tuvo buenos resultados, y desistió en su proyecto. En 1848, su amigo John Stringfellow construyó una pequeña aeronave basada en los diseños de Henson, que tuvo éxito en ciertos aspectos, pudiendo despegar por medios propios, pero lo hacía sin piloto, y podía volar apenas dos o tres segundos.

En 1890, Clément Ader, un ingeniero francés, construyó un avión al que llamó "Éole", equipado con un motor a vapor. Ader consiguió despegar en el Éole, pero no consiguió controlar el aparato, y solo pudo recorrer unos 50 metros en el aire. Aun así, consideró los resultados satisfactorios, y se planteó construir una aeronave mayor, cuya construcción le llevó cinco años de su vida. Pero por desgracia, su nuevo avión, denominado "Avión III" era demasiado pesado y nunca fue capaz de despegar.

En 1884 el ruso Aleksandr Mozhaiski diseñó y creó un monoplano con el que logró despegar gracias a un motor a vapor y recorrer una distancia de entre 20 y 30 metros.

En esa época, Hiram Stevens Maxim, un estadounidense nacionalizado británico, estudió una serie de diseños en Inglaterra, y construyó un avión de dimensiones monstruosas para los patrones de la época. Era un biplano de 3175 kg y con una envergadura de 32 metros, equipado con dos motores a vapor, cada uno capaz de generar 180CV. Maxim construyó la aeronave para estudiar los problemas básicos de la aerodinámica y la potencia. Observó que el aparato, sin equipamientos que ayudasen a obtener su control, sería insegura y peligrosa a cualquier altitud, entonces construyó una pista especial, de 550 metros de longitud, donde colocó unos raíles en los que se situaba el avión para realizar pruebas. Las primeras pruebas las realizó en busca de problemas, y a partir del 31 de julio de 1894 comenzó a incrementar la potencia de los motores en cada prueba, alineando el aparato en la pista. Las dos primeras tuvieron un éxito razonable, el aparato consiguió "saltar" sobre los raíles durante unos segundos, pero no llegó a volar. En la tercera prueba, la tripulación aplicó potencia máxima a los motores del avión, hasta alcanzar 68 km/h, y después de recorrer 180 metros se produjo tanta sustentación que el avión se salió de los raíles, consiguiendo despegar y volar recorriendo 60 metros, momento en el cual el aparato chocó contra el suelo. Maxim solamente volvió a hacer nuevas pruebas en la década de 1900, usando motores a gasolina y aeronaves menores.

Otro pionero de la aviación fue Samuel Pierpont Langley, un científico estadounidense, que después de una exitosa carrera relacionada con la astronomía, comenzó a estudiar seriamente la aerodinámica en lo que actualmente es la Universidad de Pittsburgh (Estados Unidos). En 1891, Langley publicó "Experiments in Aerodynamics" ("Experimentos en aerodinámica"), donde detallaba sus investigaciones, y es a partir de ahí cuando se dedicó a diseñar y construir aeronaves basadas en sus ideas. El 6 de mayo de 1896, un prototipo construido por él, realizó su primer vuelo con éxito. El nombre de la aeronave era "Aerodrome No.5". El avión recorrió aproximadamente mil metros a una velocidad de 40 km/h. El 28 de noviembre del mismo año, realizó otro vuelo con éxito, con el aparato "Aerodrome No.6", que consiguió recorrer con éxito 1460 metros, pero despegaba sin tripulantes.

Después de los éxitos de estas pruebas de vuelo, Langley decidió construir un avión que fuese capaz de volar pilotado por una persona, por lo que comenzó a buscar personas dispuestas a invertir en su nueva máquina. Es entonces cuando el gobierno estadounidense le subvencionó con cincuenta mil dólares, gracias al interés que despertaba la idea de disponer de un aparato que sirviera como observador militar aéreo, ya que en ese momento se iniciaba la Guerra Hispano-Estadounidense. Langley construyó entonces su "Aerodrome A", y pasó a realizar pruebas en una versión idéntica pero con un cuarto de tamaño con respecto al modelo original, y sin tripulantes. El prototipo voló dos veces el 18 de julio de 1901, realizando con éxito hasta 1903 algunos despegues más.

Con el diseño básico de la aeronave aparentemente aprobado en las pruebas realizadas, Langley acreditaba que el "Aerodrome A" estaba en condiciones de ser probado con un tripulante a bordo. Entonces comenzó a buscar un motor adecuado, y contrató a Stephen Balzser para la construcción de este. Langley quedó decepcionado al ver que el motor generaba apenas 8CV de fuerza, en vez de los 12CV que él esperaba. Un asistente de Langley, Charles M. Manly, rediseñó el motor, transformándolo en uno con cinco cilindros y refrigerado por agua, capaz de generar 52CV y 950 revoluciones por minuto, con un peso de 57kg.
El 7 de octubre y el 8 de diciembre de 1903, Langley, a los mandos del "Aerodrome A", intentó hacer que su avión despegara. Realizó sus intentos en un navío sobre el río Potomac, y utilizó una catapulta para proporcionar el empuje necesario para el despegue. Pero por desgracia, el avión era muy frágil, y en ambos intentos el avión terminó chocándose con el agua justo después de despegar. Además de eso, el avión no disponía de control longitudinal ni tampoco de tren de aterrizaje, y por eso tenía que realizar los intentos de despegue sobre el río. Otro problema era que los fondos monetarios de los que disponía se agotaban, por lo que intentó conseguir más, pero sus esfuerzos fracasaron.

Por toda la labor realizada dentro del mundo de la aviación, Langley fue reconocido por el Instituto Smithsoniano, una institución educacional ubicada en Washington D.C., como el inventor del avión, gracias a que Glenn Hammond Curtiss posteriormente haría varias modificaciones en el "Aerodrome A" de Langley en la década de 1910, y conseguiría alzar el vuelo.

Mientras, en el Reino Unido, Percy Pilcher estuvo a punto de convertirse en la primera persona que alza el vuelo en un avión. Pilcher construyó varios planeadores: "The Bat" ("El Murciélago"), "The Beetle" ("El Escarabajo"), "The Gull" ("La Gaviota") y "The Hawk" ("El Halcón"). Logró alzar el vuelo en todos ellos, teniendo éxito en sus intentos. En 1899 construyó un prototipo de avión con motor a vapor, pero por desgracia Pilcher falleció en un accidente aéreo con uno de sus planeadores, no habiendo probado su prototipo. Sus trabajos permanecieron escondidos durante años, y solo mucho tiempo después, despertaron interés en la comunidad científica. Estudios más recientes indicaron que su prototipo hubiera sido capaz de alzar el vuelo por sus propios medios con un tripulante a bordo.

Otro nombre digno de destacar es el de Gustave Whitehead, del que se tiene documentado un primer vuelo ocurrido el 14 de agosto de 1901 en Connecticut (Estados Unidos), día en el que logró volar con su modelo "Número 21" en tres ocasiones. La información salió reflejada en los periódicos "Bridgeport Herald", "New York Herald" y el "Boston Transcript", y en ellos se dice que el vuelo más largo logró recorrer más de 2500 metros a una altura de 60 metros, siendo mayor que la marca alcanzada por los hermanos Wright dos años más tarde.

Meses después, en enero de 1902 logró volar 10 kilómetros sobre Long Island en su modelo "Número 22". Pero antes de eso, algunos testigos confirman un vuelo de 1 km hacia el año 1899. Tanto el modelo "Número 21" como el "Número 22" eran monoplazas, el primero impulsado con un motor de 15CV y el segundo con un motor de 30 CV. El motor aceleraba las ruedas delanteras para adquirir la velocidad de despegue y el piloto cambiaba la fuerza hacia las hélices. De esta forma se evitaba el mecanismo de catapulta necesario en el modelo de los hermanos Wright.

Los planos de los modelos de Whitehead han sido conservados y en 1937, Stella Randolph recopiló su labor en la obra "Los vuelos perdidos de Gustave Whitehead". El reconocimiento a Gustave Whitehead sólo vendría a partir de esa época.

Durante la década de 1890, los hermanos Wilbur y Orville Wright empezaron a interesarse por el mundo de la aviación, especialmente con la idea de fabricar y hacer volar una aeronave más pesada que el aire, que pudiese despegar por medios propios. En esa época, ambos administraban una fábrica de bicicletas en Dayton (Ohio, Estados Unidos), y comenzaron a leer y estudiar con gran interés, libros y documentos relacionados con la aviación. Siguiendo el consejo de Lilienthal, en el año 1899 empezaron a fabricar planeadores. A finales de siglo, comenzaron a realizar sus primeros vuelos con éxito con sus prototipos, en Kitty Hawk (Carolina del Norte), lugar elegido debido a que en esa zona podían encontrar vientos constantes, que soplaban también en una misma dirección, facilitando así los vuelos con planeadores. Además de eso, la zona disponía de un suelo plano, que hacía más fáciles los aterrizajes.

Después de la realización de varias pruebas y vuelos con planeadores, los Wright decidieron en 1902 ponerse a fabricar un avión más pesado que el aire. Se convirtieron en el primer equipo de diseñadores que realizaron pruebas serias para intentar solucionar problemas aerodinámicos, de control y de potencia, que afectaban a todos los aviones fabricados en esa época. Para la realización de un vuelo con éxito, la potencia del motor y el control del aparato serían esenciales, y al mismo tiempo el aparato precisaba ser bien controlado. Las pruebas fueron difíciles, pero los Wright fueron perseverantes. Al mismo tiempo, fabricaron un motor con la potencia deseada y solucionaron los problemas de control de vuelo a través de una técnica denominada alabeo, poco usada en la historia de la aviación pero que funcionaba en las bajas velocidades a las que el avión volaría.

El avión que fabricaron los hermanos Wright era un biplano al que denominaron "Flyer" ("Volador"). El piloto permanecía echado sobre el ala inferior del avión, mientras que el motor se situaba a la derecha de este, y hacía girar dos hélices localizadas entre las alas. La técnica del alabeo consistía en cuerdas atadas a las puntas de las alas, de las que el piloto podía tirar o soltar, permitiendo al avión girar a través del eje longitudinal y vertical, lo que permitía que el piloto tuviera el control del avión. El "Flyer" fue el primer avión registrado en la historia de la aviación, dotado de maniobrabilidad longitudinal y vertical, excluyendo a los planeadores de Lilienthal, donde el control era realizado a través de la fuerza del propio tripulante.
El 17 de diciembre de 1903, apenas unos meses después de las pruebas sin éxito de Langley, Orville Wright se convirtió en la primera persona en volar sobre una aeronave más pesada que el aire, propulsada por medios propios, aunque no sin controversias. El vuelo sucedió en Kitty Hawk. Los hermanos utilizaron rieles para mantener el aparato en su trayecto, y una catapulta para impulsarlo. El avión ganó altitud al acabar el recorrido sobre los raíles, recorriendo 37 metros a una velocidad media de 48 km/h durante los 12 segundos que duró el vuelo. Ese mismo día realizaron tres vuelos, que fueron presenciados por cuatro socorristas y un niño de la zona, haciendo que estos fueran los primeros vuelos públicos y documentados. En un cuarto vuelo realizado el mismo día, Wilbur Wright consiguió recorrer 260 metros en 59 segundos. Algunos periódicos del estado de Ohio, entre ellos el "Cincinnati Enquirer" y el "Dayton Daily News" publicaron el día siguiente la noticia del acontecimiento.

Los hermanos Wright realizaron diversos vuelos públicos (más de 105) entre 1904 y 1905, esta vez en Dayton, Ohio, invitando a amigos y vecinos. En 1904, una multitud de periodistas se reunió para presenciar uno de los vuelos de los Wright, pero a causa de problemas técnicos en su avión, que no pudieron corregir en dos días, Orville y Wilbur fueron ridiculizados por los medios, pasando a recibir poca atención, con la excepción de la prensa de Ohio. Varios periodistas de ese estado, presenciaron diversos vuelos suyos, incluyendo el primer vuelo circular del mundo, y un nuevo récord de distancia, ya que durante un intento el 5 de octubre de 1905 recorrieron 39 kilómetros en 40 minutos. A partir de 1908, los aviones de los hermanos Wright ya no necesitaron más la catapulta para alzar el vuelo.

El 7 de noviembre de 1910, realizaron el primer vuelo comercial del mundo. Este vuelo, realizado entre Dayton y Columbus (Ohio), duró una hora y dos minutos, recorriendo 100 kilómetros y rompiendo un nuevo récord de velocidad, alcanzando los 97 km/h.

El brasileño Alberto Santos Dumont estaba fascinado por las máquinas. En 1891 se mudó con su padre a París, donde quedó maravillado por el mundo de la aviación. Realizó sus primeros vuelos como pasajero en globo y posteriormente creó su propio globo, el "Brésil" ("Brasil" en francés). Santos Dumont también creó una serie de modelos de dirigibles, de los que algunos lograron volar con éxito pero otros no. Los hechos realizados por Santos Dumont en París lo convirtieron en una persona famosa en esa ciudad.
El 13 de septiembre de 1906, Santos Dumont realizó un vuelo público en París, en su famoso avión, el "14-bis". Este aparato usaba el mismo sistema de alabeo empleado en las aeronaves de los hermanos Wright y logró recorrer una distancia de 221 metros. El "14-bis", al contrario que el "Flyer" de los Wright, no necesitaba raíles, catapultas o viento para alzar el vuelo y, como tuvo mucha repercusión mediática en aquel momento, el vuelo es considerado por algunas personas como el primero realizado con éxito de un avión. Cuando se realizó este vuelo, poco o nada se sabía de los hermanos Wright, por lo que la prensa internacional consideró al "14-bis" de Santos Dumont como el primer avión capaz de despegar por medios propios.

Santos Dumont, después del "14-bis", inventaría el primer ultraligero, el "Demoiselle", que fue el último aparato que desarrollaría. También realizó importantes avances relacionados con el control del avión en vuelo y de los alerones de sus aeronaves.

Existe gran controversia en lo relativo a la realización del primer vuelo. Generalmente hay dos opiniones, los que consideran como autor de esta hazaña a los hermanos Wright (concretamente a Orville Wright) y los que consideran a Alberto Santos Dumont. Este último realizó en París el vuelo del "14-bis", el primero de un avión en la historia de la aviación que se logra sin artificios externos y que queda registrado y publicado. Los especialistas alegan el uso de raíles y catapultas en las pruebas de despegue de los hermanos Wright, y el testimonio de vuelo del "14-bis" en París por aviadores y autoridades de aviación.

En cuanto a esto, los hermanos Wright no realizaron muchos vuelos públicos, ya que pretendieron realizar sus vuelos solos o con la presencia de pocos testimonios, aunque habían intentado realizar demostraciones para las fuerzas armadas de los Estados Unidos, de Francia, del Reino Unido y de Alemania, todas sin éxito, con la intención de evitar el robo de informaciones por parte de otros aviadores, y en busca de perfeccionar el aparato lo suficiente como para obtener la patente de su avión (irónicamente, Santos Dumont ponía todas sus invenciones en el dominio público).

Algunos especialistas en aviación acreditan que los hermanos Wright fueron los primeros en volar en un avión más pesado que el aire. A pesar de la falta de testimonios de aviadores y de organizaciones de aviación, los mismos especialistas también apuntan en el hecho de que, a través de las noticias publicadas en periódicos de Ohio, el testimonio de habitantes de la región donde estos vuelos se realizaron y las fotos de estos vuelos, demuestran que estos vuelos ocurrieron, pero las aeronaves no despegaban por sí solas, sino que utilizaban artefactos que las catapultaban, haciendo que el vuelo de Santos Dumont sea considerado como el primero en la historia de la aviación, a pesar de haber ocurrido algunos años después de los primeros vuelos de los hermanos Wright.

De hecho, los Wright son acreditados en los Estados Unidos, como los primeros en volar en un avión. Sus primeros vuelos públicos, realizados en presencia de un gran número de testimonios, fueron realizados en 1908 en Le Mans (Francia).

Santos Dumont es considerado el inventor del avión en la mayor parte del mundo, donde es llamado "el padre de la aviación". Varias personas, sin embargo, critican ese título, alegando que otros aviadores hicieron sus contribuciones en el mundo de la aviación mucho tiempo antes de Santos Dumont o de los Wright, y que ese título no debería emplearse con ningún aviador en particular.

Varios aviadores afirmaron haber volado en un avión con anterioridad a los vuelos de los hermanos Wright y de Santos Dumont, volviendo todavía más controvertido el primer vuelo de la historia en un avión. Esta controversia fue alimentada por los hermanos Wright, que permanecieron distanciados de los medios de comunicación mientras preparaban la patente de su avión, por lo que fueron poco conocidos en su momento por la comunidad de la aviación mundial, y también por el gran número de posibles primeros vuelos en un avión, por las diferentes categorías y cualificaciones de las aeronaves y de los medios utilizados para lograr tales vuelos, por la falta de testigos creíbles y por el orgullo y patriotismo de las naciones de estos aviadores.

En España, Diego Marín Aguilera, en la noche de 15 de mayo de 1793, realizó un vuelo de 360 metros con un artefacto de hierro y plumas de ave, controlado por el propio piloto. Tan sólo quedan algunos testimonios y un tardío reconocimiento.

Gustave Whitehead afirmó haber volado en una aeronave más pesada que el aire, por medios propios, el 14 de agosto de 1901. Cometió el error de no documentar su supuesto vuelo, pero posteriormente, una réplica de su avión denominado "Número 21" consiguió alzar el vuelo con éxito. El estadounidense Lyman Gilmore también dijo haber volado el 15 de mayo de 1902.

En Nueva Zelanda, el granjero e inventor Richard Pearse construyó un monoplano que alzó el vuelo el 31 de marzo de 1903. Hay grandes evidencias que dicen que eso ocurrió realmente, entre testimonios y fotografías. Pero el propio Pearse admitiría tiempo después que ese vuelo no fue controlado y que terminó al chocarse en un monte después de haber volado a una altura de unos 3 metros. El alemán Karl Jatho voló en una aeronave más pesada que el aire el 18 de agosto de 1903. Su vuelo fue de corta duración, pero con la velocidad y el diseño de las alas que poseía, hacían que el avión no fuera controlable por el piloto. Todavía en 1903, hubo testimonios que afirmaban haber visto al escocés Preston Watson realizar vuelos en Errol, al este de Escocia. Pero a falta de evidencias fotográficas o documentadas, hacen que sea imposible su verificación.

El ingeniero rumano Traian Vuia también afirmó haber volado en un avión, y que logró despegar y mantenerse en el aire durante un tiempo razonable, y sin ayuda de ningún elemento. Vuia pilotó el avión que él mismo diseñó y construyó, el 18 de marzo de 1906 en Montesson, cerca de París. Ninguno de sus vuelos superó los 30 metros de distancia. En comparación, a finales de 1905 los hermanos Wright ya habían realizado vuelos de 39 kilómetros de distancia y de 40 minutos de duración.Sin embargo, los Wright tuvieron que emplear una catapulta para lograr el despegue.

Muchas reivindicaciones de vuelos son complicadas de demostrar por el hecho de que alcanzaron tan poca altura que los aviones se confundían con el suelo. Además de eso, forma parte del debate también los medios utilizados para alzar el vuelo. Algunos alzaron vuelo completamente por medios propios, pero hubo otros que inicialmente eran catapultados en el despegue, y en el aire se sustentaban por medios propios. Por todo esto, Alberto Santos Dumont y los hermanos Wright son considerados en el mundo entero como los primeros en volar en un avión, ya que hay abundancia de pruebas de sus vuelos.

Durante estos años, dos inventores, el francés Henri Farman y el inglés John William Dunne, también estaban trabajando por su cuenta en sus propios prototipos de aviones.

En enero de 1908, Farman ganó el "Grand Prix" de la aviación, con un avión que recorrió un kilómetro, aunque antes ya se habían realizado vuelos que habían recorrido más distancia, como el de los hermanos Wright en 1905, recorriendo un total de 39 kilómetros. Más tarde, el 30 de octubre de 1908, Farman se convirtió en el primero en realizar un vuelo de ciudad a ciudad, realizado desde el pequeño pueblo de Bouy y Reims, ambas en Francia (27 kilómetros en 20 minutos). El 27 de agosto de 1909 volvió a batir otro récord, llegando a recorrer 180 kilómetros en poco más de tres horas en su avión, el "Farman III", y más tarde 232 kilómetros en cuatro horas, 17 minutos y 53 segundos en ese mismo aparato.
Los trabajos iniciales de Dunne fueron patrocinados por las Fuerzas Armadas del Reino Unido, y probados en Glen Tilt (Tierras Altas de Escocia). Su mejor diseño fue el "D4", que voló en diciembre de 1908, cerca de Blair Atholl, en Pertshire. Sus principales contribuciones a la historia de la aviación fueron en lo relativo a la estabilidad de las máquinas, que era uno de los principales problemas a los que se enfrentaron inicialmente los pioneros de la aviación.

El 14 de mayo de 1908, Wilbur Wright realizó el primer vuelo de un avión cargado con dos personas, portando a Charles Furnas como pasajero.

El 17 de septiembre de 1908, el estadounidense Thomas Etholen Selfridge se convirtió en la primera persona en morir en un avión en vuelo, cuando Wilbur Wright estrelló su avión de dos pasajeros en una de las pruebas militares que realizó en Fort Myer (Virginia, Estados Unidos). También en 1908, Hart O. Berg se convirtió en la primera mujer en volar, haciéndolo como pasajera junto a Wilbur Wright en Le Mans (Francia).

El 25 de julio de 1909, el ingeniero francés Louis Blériot se convirtió en la primera persona que a bordo de un aeroplano atravesó el canal de la Mancha. Pilotando su avión "Blériot XI", y partiendo desde la localidad francesa de Calais, tras 37 minutos en el aire logró aterrizar cerca de Dover, ya en territorio británico. Gracias a su hazaña, Blériot ganó el premio de 1000 libras esterlinas que ofreció el periódico inglés "Daily Mail" a la primera persona que lo lograra.

El 8 de marzo de 1910, la baronesa de Laroche fue la primera mujer en conseguir la licencia de piloto. Había realizado su primer vuelo el 22 de octubre de 1909.

El 23 de septiembre de 1910, el aviador peruano-francés Jorge Chávez Dartnell junto a su avión "Blériot XI" logró superar por primera vez los Alpes desde Brig (Suiza) hasta Domodossola (Italia) donde a 20 metros de altura el avión cayó en picado después de que las alas se quebraran debido al fuerte viento. Herido de gravedad, Chávez murió cuatro días después.

En 1911, Calbraith Perry Rodgers se convirtió en la primera persona en hacer un viaje transcontinental con un avión, viajando desde Sheepshead Bay (Nueva York), a orillas del océano Atlántico, hasta Long Beach (California), a orillas del océano Pacífico, en una serie de vuelos cortos que le llevarían un total de 84 días.

Al mismo tiempo que se desarrollaban los aviones de ala fija, los dirigibles se volvían cada vez más avanzados. Durante las primeras décadas del siglo XX, los dirigibles eran capaces de transportar mucha más carga y pasajeros que los aviones. Muchos de los avances relacionados con los dirigibles fueron obra del conde alemán Ferdinand von Zeppelin.

La construcción del primer dirigible Zeppelin comenzó en 1899 en Alemania. El prototipo inicial, denominado "LZ1" (siglas en alemán de "Luftschiff Zeppelin 1"), tenía 128 metros de longitud y era propulsado por dos motores Daimler de 14.2CV cada uno. El primer vuelo del "LZ1" ocurrió el 2 de julio de 1900, durando apenas 18 minutos, debido a que se vio obligado a descender debido a que el mecanismo de control había sufrido un fallo mecánico. Después de repararlo, el Zeppelin pudo mostrar todo su potencial en los siguientes vuelos, sobrepasando el récord de 6m/s del dirigible "La France" por un margen de 3m/s, pero aun así, no logró atraer a posibles inversores. Tuvieron que pasar unos años hasta que Ferdinand von Zeppelin reuniera fondos suficientes para seguir sus pruebas.

En 1902, el ingeniero español Leonardo Torres Quevedo desarrolló un nuevo tipo de dirigible que solucionaba el grave problema de suspensión de la barquilla al incluir un armazón interior de cables flexibles que dotaban de rigidez al dirigible por efecto de la presión interior, combinando las propiedades de los dirigibles rígidos y flexibles. Tres años después, junto a Alfredo Kindelán, Torres Quevedo construye el primer dirigible español, denominado "España", que se caracterizaba por disponer de un globo separado en tres compartimentos (trilobulado), lo que aumentaba la seguridad. A raíz de este hecho empezó la colaboración entre Torres Quevedo y la empresa francesa Astra, que llegó a comprarle la patente con una cesión de derechos extendida a todos los países, excepto a España, para posibilitar la construcción del dirigible en el país. Así, en 1911, se inicia la fabricación de los dirigibles conocidos como Astra-Torres. Algunos ejemplares fueron adquiridos por los ejércitos francés e inglés a partir de 1913, y utilizados durante la Primera Guerra Mundial en muy diversas tareas, fundamentalmente de protección e inspección naval.

En 1918, Torres Quevedo diseñó, en colaboración con el ingeniero español Emilio Herrera Linares, un dirigible trasatlántico, al que llamaron "Hispania", que llegó a alcanzar el estado de patente, con objeto de realizar desde España la primera travesía aérea del océano Atlántico. Por problemas de financiación el proyecto se fue retrasando y fueron los británicos John William Alcock y Arthur Whitten Brown los que lograron esa hazaña por primera vez, en el año 1919.
En 1877 el italiano Enrico Forlanini desarrolló un prototipo no tripulado de helicóptero, de unos 13 metros de altura y alimentado con un motor a vapor. Fue el primero de su tipo. Logró un despegue vertical y permaneció en el aire unos 20 segundos, aunque el primer vuelo realizado con éxito y registrado de un helicóptero ocurrió en 1907, realizado por Paul Cornu en Francia, pero hasta 1936 con el Focke-Wulf Fw 61 de fabricación alemana, no se dispuso de un helicóptero funcional.

El autogiro fue inventado por el ingeniero español Juan de la Cierva, quien desarrolló el rotor articulado que más tarde usaría Igor Sikorsky en sus helicópteros, pagando incluso la patente y los derechos de utilización al inventor español. En su primer vuelo en 1923, el autogiro logró recorrer 200 metros, y más tarde, realizó el primer viaje entre aeródromos desde Getafe a Cuatro Vientos en 1924.

En cuanto a hidroaviones, el primero de la historia fue obra del ingeniero francés Henri Fabre. Lo denominó "Le canard" (en francés, ‘el pato’), y el 28 de marzo de 1910 despegó del agua y logró recorrer 800 metros. Sus experimentos fueron seguidos de cerca por Charles y Gabriel Voisin, que adquirieron varios de sus prototipos para desarrollar el suyo propio, al que denominaron "Canard voisin". En octubre de 1910, el "Canard voisin" se convirtió en el primer hidroavión que voló sobre el río Sena, en París, y en marzo de 1912 se convirtió también en el primer hidroavión que fue usado militarmente desde el portaaviones francés "La Foundre" (en francés, ‘el relámpago’).

No mucho después de haber sido inventado, el avión pasó a ser usado en servicios militares. El primer país que usó aviones con ese propósito fue Bulgaria, en ataques sobre posiciones otomanas durante la Primera Guerra de los Balcanes.

Pero la primera guerra en la que se usaron aviones en misiones de ataque, defensa y de reconocimiento fue en la Primera Guerra Mundial. Los Aliados y las Potencias Centrales hicieron un uso extensivo de los aviones. Irónicamente, la idea del uso de aviones como arma de guerra antes de la Primera Guerra Mundial fue motivo de risas y mofas por parte de muchos comandantes militares, durante los tiempos que precedieron a la guerra.

La tecnología relacionada con la aviación avanzó rápidamente debido a la guerra. Al principio de ésta, los aviones apenas podían cargar con el piloto, pero después de muchas mejoras, se pudo añadir a un pasajero adicional. Los ingenieros crearon motores más potentes, y se fabricaron aeronaves cuya aerodinámica era sensiblemente mejor que el de las de antes de la guerra. Como comparación, al inicio de la guerra los aviones no superaban los 110 km/h, sin embargo al finalizar la contienda, muchos ya alcanzaban los 230 km/h o incluso más.

Después del comienzo de la guerra, los comandantes militares descubrieron la importancia que tenía el avión como arma de espionaje y reconocimiento, pudiendo fácilmente localizar fuerzas y bases enemigas sin mucho peligro, hasta que se empezó a desarrollar el armamento antiaéreo según iba avanzando la guerra.

Pero el uso de los aviones que realizaban patrullas de reconocimiento generó un problema: éstas frecuentemente se encontraban con aviones enemigos. Así que no se tardó mucho en equipar a esas aeronaves con armas de fuego a bordo, para que así pudieran defenderse, pero a la vez el piloto tenía que controlar el aparato, lo que complicaba la situación, por lo que algunos aviones contaban con un observador que podía apuntar y disparar una ametralladora que portaba en sus brazos, lo que resultaba poco eficaz hasta que se creó la ametralladora sincronizada.

Los franceses se esforzarían seriamente en resolver ese problema, y a finales de 1914, Roland Garros colocó una ametralladora fija al frente de su aeronave, permitiéndole disparar a la vez que controlaba el aparato, gracias a que cubría las hélices con una placa metálica que las blindaba. El 19 de abril de 1915 Garros fue derribado y hecho prisionero por los alemanes, y debido a que su avión no quedó destruido, el ingeniero Anthony Fokker estudió y mejoró el sistema, gracias a un mecanismo que sincronizaba el giro de la hélice con los disparos de la ametralladora, y que acabaría siendo equipado en todos los aviones, por lo que las batallas aéreas entre cazas pasaron a ser muy comunes. También se extendió el uso de hidroaviones, usándolos para misiones de reconocimiento en el mar, para poder captar fotografías de las fuerzas navales enemigas y para bombardear submarinos enemigos.
En esta época apareció la denominación as de la aviación, considerándose así a los pilotos que conseguían derribar en combate a cinco aeronaves enemigas o más. Muchos de ellos se convertirían en personajes famosos durante y después de la guerra. El más famoso fue el alemán Manfred von Richthofen, más conocido como "Barón Rojo", que logró abatir 80 aeronaves enemigas con diferentes aviones, aunque el más famoso fue el Fokker Dr.I que empleaba pintado de rojo. Fue abatido por un canadiense en 1918, poco antes de acabar la guerra. Todavía es considerado como el mejor piloto de la historia.

El avión más famoso de la guerra fue el Sopwith Camel, que contaba con más victorias aéreas que cualquier otro avión aliado, pero también era conocido por su difícil manejo, responsable de la muerte de varios pilotos novatos. También de este periodo es el Junkers J 1, avión de fabricación alemana que se convirtió en el primer avión fabricado completamente de metal en 1915.

En el período de entreguerras se desarrolló toda la tecnología relacionada con la aviación, realizándose importantes avances en el diseño de aviones, y siendo el momento en el que comenzaron a operar las primeras líneas aéreas. También fue una época en la que los aviadores comenzaron a impresionar al mundo con sus hazañas y habilidades. Los aviones empezaron a sustituir la madera por el metal de manera generalizada. También los motores experimentaron un gran incremento de potencia. Esta serie de avances tecnológicos, junto con el creciente impacto socio-económico que los aviones pasaron a tener, hicieron que el periodo entreguerras sea considerado como "la era de oro de la aviación". Todo esto fue posible en parte, gracias a la gran cantidad de aviones y pilotos que quedaban después de la Primera Guerra Mundial.

Una de las principales razones para explicar estos desarrollos fue la entrega de una serie de premios que se otorgaban a los aviadores que conseguían establecer récords de distancia recorrida y de velocidades alcanzadas. Un ejemplo de premio de estas características era el Premio Orteig, que premiaba con 25&nbsp000 dólares a la primera persona que realizara el trayecto Nueva York-París o viceversa, sin realizar escalas de ningún tipo. Este premio lo ganó Charles Lindbergh, que en su monoplano de un solo motor Ryan NYP (un Ryan M-2 modificado), bautizado como "Spirit of Saint Louis", despegó del aeródromo Roosevelt (Long Island, Ciudad de Nueva York) el 20 de mayo de 1927 y tras un vuelo de 33 horas y 32 minutos, aterrizó en el aeropuerto de Le Bourget, cercano a París. Pero Lindbergh no fue el primer aviador en realizar un vuelo trasatlántico sin escalas. John William Alcock y Arthur Whitten Brown, dos aviadores británicos, lograron volar años antes desde Lesters Field, cerca de Saint Johns, Nueva Escocia (Canadá), a Clifden (Irlanda), del 14 al 15 de junio de 1919 en su avión Vickers Vimy IV (un bombardero modificado). Por haber logrado esta hazaña, Alcock y Brown ganaron el premio de 10 000 libras esterlinas del periódico londinense Daily Mail, recibiendo el premio de manos de Winston Churchill.
Además un año antes al vuelo de Lindbergh, el hidroavión español Plus Ultra, tripulado por Ramón Franco, Julio Ruiz de Alda, Juan Manuel Durán y Pablo Rada, cruzó el Atlántico Sur desde la localidad de Palos de la Frontera (Huelva, España) hasta Buenos Aires (Argentina), para emular el viaje de Colón, pero por aire, en vez de por agua.

En 1914, el estadounidense Tony Jannus se convirtió en el primer piloto de la historia que realizaba un vuelo comercial. Jannus pilotó un hidroavión para transportar carga y pasajeros entre San Petersburgo y Tampa, en Florida (Estados Unidos). Su hidroavión tenía espacio para un pasajero, que pagaba cinco dólares por un vuelo de 35 kilómetros. Este taxi aéreo, la Aerolínea St. Petersburg-Tampa Airboat considerado la primera línea aérea del mundo, en poco tiempo se encontró con dificultades financieras, por lo que duró apenas unos meses. En 1919 y durante los años 20, varias líneas aéreas se establecieron por Europa y los Estados Unidos. Estas compañías comenzaron usando aviones que previamente habían tenido un uso militar en la Primera Guerra Mundial, pero que habían reconvertido para poder transportar carga y pasajeros, y a los cuales se decoraba de una manera elegante por dentro. Aun así, estos aparatos resultaban muy ruidosos y no estaban apropiadamente presurizados ni acondicionados.

Después de la guerra, los gobiernos estadounidense y canadiense ofrecieron a precios bajos el exceso de aviones del que disponían, a aviadores. A pesar de que estas aeronaves eran más fuertes que las fabricadas antes de la guerra, aún no podían ser consideras seguras, ya que estaban realizadas la mayoría de las veces con madera y tejidos, y no disponían de equipamientos de navegación básicos. Aun así, muchos pilotos que antes habían luchado en la guerra, compraron esos aviones y los emplearon para ganar dinero, realizando exhibiciones acrobáticas y peligrosas en ferias, lo que hacía que los accidentes fueran frecuentes, y muchos de estos aviadores murieran.

La agencia de correos de Estados Unidos también empleó antiguos aviones militares para transportar correo entre algunas ciudades estadounidenses, hasta el año 1927, en el que dejaron de operar estos vuelos, prefiriendo contratar a líneas aéreas para que realizaran ese servicio. Los correos aéreos tuvieron mucha importancia en el desarrollo de la aviación comercial.

En 1929, la tecnología relacionada con los dirigibles avanzó de manera notable, llegando a realizar un Zeppelin el primer viaje alrededor del mundo, a los mandos de Ferdinand von Zeppelin. En esos años, los dirigibles eran usados por numerosas líneas aéreas de Europa, y en los años 30 se iniciaron las primeras rutas trasatlánticas, que tuvieron gran éxito. La era de los dirigibles terminó en 1937 cuando el dirigible Hindenburg sufrió un accidente en Lakehurst (Nueva Jersey, Estados Unidos), en el que murieron 35 personas. El suceso ocurrió debido a que el dirigible estaba lleno de hidrógeno, un gas altamente inflamable. Después de este acontecimiento, la gente dejó de usar los dirigibles, a pesar de que tal accidente fue el único sucedido en este tipo de aeronaves.

En la década de 1930, muchas líneas aéreas utilizaron hidroaviones que empleaban principalmente en vuelos transoceánicos. Uno de los mayores hidroaviones de la época fue el Dornier Do X, tan grande que necesitaba doce motores para despegar, seis en cada ala. Voló por primera vez en 1929, pero no fue demasiado popular. Otro hidroavión, el Boeing 314 Clipper, capaz de transportar 74 pasajeros, sí que resultó popular en esos años. En 1938 realizaron sus primeros vuelos comerciales sobre el océano Atlántico, pero el desarrollo de aviones cada vez más potentes y de aeropuertos con pistas cada vez más largas, hicieron que el uso de hidroaviones terminase a lo largo de los años 40.

En lo que respecta a otro tipo de aeronaves, en los años 20 el ingeniero español Juan de la Cierva y Codorníu comenzó a desarrollar una aeronave de ala rotativa que puede ser considerada un híbrido entre un avión y un helicóptero, y que recibió el nombre de autogiro. De la Cierva realizó su primer vuelo en un autogiro en 1923, recorriendo 200 metros, y un año después en otra prueba logró alcanzar los 100 km/h. El español siguió evolucionando su aparato en Inglaterra y Estados Unidos con apoyo de inversores particulares, y llegó a tener gran éxito con sus modelos en los primeros años 30. Pero con la llegada de la Guerra Civil Española, de la Cierva muere y las investigaciones relativas al autogiro quedan prácticamente paralizadas, centrándose todos los esfuerzos en el desarrollo del helicóptero aprovechando las investigaciones y avances conseguidos por Juan de la Cierva con el autogiro, aparato que hoy en día es considerado como el precursor del helicóptero. Heinrich Focke en Alemania e Igor Sikorsky en Estados Unidos desarrollaron los primeros modelos operativos de helicópteros a finales de los años 30 y principios de los años 40, llegando a tener que comprar varias de las patentes del autogiro para desarrollar sus aparatos.

Años antes, otros pioneros realizaron avances en lo relativo a los helicópteros, como en eslovaco Ján Bahýľ a principios del siglo XX, el argentino Raúl Pateras Pescara, que realizó el primer vuelo de un helicóptero medianamente controlable en 1916, o el español Federico Cantero Villamil, que desarrolló uno de los primeros helicópteros eficaces, la Libélula Viblandi, pero la Guerra Civil Española paralizó sus proyectos.

Durante este periodo, y especialmente en la década de 1930, hubo varias mejoras técnicas que facilitaron la construcción de aviones más grandes, capaces de recorrer distancias mayores y de volar más rápido y a mayor altitud, lo que hizo que se pudiera transportar más carga y a más pasajeros. Los avances en la ciencia de la aerodinámica permitieron a los ingenieros desarrollar aeronaves cuyo diseño interfiriera lo menos posible en el vuelo del avión. Los equipamientos de control y las cabinas de los aviones también mejorarían de una manera considerable. Además de eso, las mejoras en la tecnología de las radiocomunicaciones permitían el uso de equipamientos de este tipo en los aviones, así los pilotos podían recibir instrucciones de vuelo desde equipos en tierra, y también se podrían comunicar pilotos de distintas aeronaves entre sí. Todo esto generó técnicas más precisas de navegación aérea. El piloto automático también comenzó a usarse en los años 30, lo que permitió a los pilotos tomarse cortos periodos de descanso en vuelos de larga duración.
El avión más característico de esta etapa fue el Douglas DC-3, un monoplano bimotor que realizó sus primeros vuelos en 1936. Tenía una capacidad para 21 pasajeros y era capaz de alcanzar una velocidad de crucero de 320 km/h. Rápidamente se convirtió en el avión comercial más usado de la época, y es considerado uno de los aviones más importantes que se ha producido en la historia de la aviación.

El motor a reacción comenzó a ser desarrollado en Inglaterra y Alemania en estos años. El británico Frank Whittle patentó un diseño de una turbina a reacción en 1930, y desarrolló un motor que podía ser usado para fines prácticos al final de la década. El alemán Hans von Ohain patentó su versión de motor a reacción en 1936, y comenzó a desarrollar una máquina semejante. Ninguno de ellos sabía del trabajo que desarrollaba el otro, por eso mismo, a ambos se les considera como sus inventores. A punto de terminar la Segunda Guerra Mundial, Alemania empleaba los primeros aviones de reacción y fabricaba una serie de Messerschmitt Me 262, el primer caza a reacción de la historia.

El hecho de que los aviones volasen a altitudes cada vez mayores, donde las turbulencias y otros factores climáticos no deseables son más raros, generó un problema: en altitudes mayores, el aire es menos denso, y por tanto, posee menores cantidades de oxígeno para la respiración. A medida que los aviones pasaban a volar más alto, los pilotos, tripulantes y pasajeros tenían cada vez más dificultades para respirar. Los especialistas, para resolver este problema, crearían la cabina presurizada, que lograba mantener constante la presión atmosférica con independencia de la altura de vuelo. Estas se empezaron a hacer populares a finales de los años 40, aunque el primer avión comercial con cabina presurizada fue el Boeing 307, que realizó su primer vuelo en 1938. Hoy en día, prácticamente todas las cabinas de aviones comerciales de pasajeros son cabinas presurizadas.


Los años de la Segunda Guerra Mundial se caracterizaron por un drástico crecimiento en la producción de aviones, y por el gran desarrollo de la tecnología relacionada con la aviación. En la siguiente tabla se puede comprobar el crecimiento exponencial en la producción de aviones en este periodo:
Durante el conflicto se desarrollaron los primeros bombarderos de larga distancia, el primer avión de reacción de uso práctico y el primer caza con reactores. Al inicio de la guerra, los cazas podían alcanzar velocidades máximas de 480 km/h y volar a una altura de 9000 metros. Al finalizar la guerra, después de todas las investigaciones y desarrollos realizados por ambos bandos, los cazas estaban volando a 640 km/h y muchos alcanzaban los 12 000 metros de altura.

Los cazas a reacción desarrollados a lo largo del conflicto podían desplazarse todavía más rápido, pero no se usaron hasta el final de la guerra. El primer reactor funcional fue el alemán Heinkel He 178, que realizó su primer vuelo en 1939, poco antes de empezar la guerra. Años después, en 1944, el Messerschmitt Me 262 se convirtió en el primer caza a reacción que operó en la guerra, y podía alcanzar una velocidad máxima de 900 km/h. Un prototipo alemán, el Messerschmitt Me 163 era capaz de alcanzar 970 km/h en vuelos cortos, y sirvió de base para el Messerschmitt Me 163 Komet, el caza más rápido de la guerra, que se empleó en algunas misiones al final de la guerra, en 1945. Los alemanes también crearon los primeros misiles balísticos de larga distancia, el V-1 y el V-2.

Los bombarderos de la Segunda Guerra Mundial eran capaces de cargar el doble de carga y recorrer el doble de distancia que los existentes antes de la guerra. Los bombarderos de larga distancia fueron los que causaron más impacto en el transcurso de la guerra, ya que los cazas a reacción comenzaron a operar al final de la guerra, y la derrota alemana era cuestión de tiempo. Los misiles V-1 eran ineficientes y los V-2 no fueron producidos en grandes cantidades. El caza estadounidense North American P-51 Mustang resultó clave junto a los bombarderos pesados, ya que les servían de protección frente a los cazas enemigos. Otros aviones famosos de la guerra fueron el caza británico Supermarine Spitfire, considerado como "el salvador del Reino Unido", el caza japonés Mitsubishi A6M Zero y el bombardero estadounidense Boeing B-29 Superfortress.

Después del fin de la Segunda Guerra Mundial, la aviación comercial pasó a desarrollarse de manera independiente a la aviación militar. Las empresas fabricantes de aviones pasaron a crear modelos especialmente diseñados para el transporte de pasajeros y, durante los primeros años después de la guerra, las líneas aéreas usaron aviones militares modificados para uso civil, o versiones derivadas de los mismos, entre los que cabría destacar el Boeing 377 Stratocruiser, que derivaba del Boeing C-97 Stratofreighter, y que se convirtió en el primer avión de dos pisos de la historia de la aviación, ya que su fuselaje denominado "de doble burbuja" permitía que en la parte superior albergara una cubierta con asientos, y en la inferior llevara una pequeña sala VIP a la que se accedía mediante una escalera de caracol, y que a la vez fue el mayor avión comercial hasta la llegada del Boeing 707 en 1958.

De las aeronaves comerciales que se desarrollaron en este periodo, destacan los cuatrimotores Douglas DC-4 y el Lockheed Constellation, que fueron usados para vuelos locales de pasajeros o de media distancia. También realizaron rutas transoceánicas, pero para éstas necesitaban hacer escalas para reabastecerse de combustible. Los vuelos transoceánicos necesitaban de motores más potentes, que ya existían en 1945 en forma de turbinas a reacción, pero estos, en ese momento todavía consumían demasiado combustible y con ellas un avión solo podría recorrer pequeñas distancias.

Para resolver este problema, aunque fuera de manera temporal, se desarrollaron motores turbohélices, que eran propulsores capaces de generar más de tres mil caballos de fuerza. Estos motores comenzarían a ser empleados en los Vickers Viscount, Lockheed L-188 Electra o Ilyushin Il-18, aviones capaces de transportar entre 75 y 110 pasajeros entre las ciudades de Nueva York y París sin escalas y a una velocidad de crucero de más de 500 km/h.

A finales de los años 40, los ingenieros comenzaron a desarrollar las turbinas usadas en los cazas a reacción producidos durante la Segunda Guerra Mundial. En un principio, los Estados Unidos y la Unión Soviética querían turbinas a reacción para producir bombarderos y cazas cada vez mejores, y así mejorar todavía más su arsenal militar. Cuando comenzó la Guerra de Corea en 1950, tanto los Estados Unidos como la Unión Soviética disponían de cazas a reacción, entre los que destacaban el norteamericano North American F-86 Sabre y el soviético MiG-15.

En cuanto al primer avión de reacción de carácter comercial de la historia de la aviación, fue el De Havilland Comet de fabricación británica. El Comet comenzó su uso como avión de pasajeros en 1952, siendo capaz de volar a 850 km/h, y con una cabina presurizada y relativamente silenciosa. Este avión comenzó siendo un éxito comercial, y muchas líneas aéreas hicieron pedidos. Pero dos accidentes ocurridos en 1954 en medio del mar, hicieron que surgieran grandes dudas en lo relativo a la seguridad del avión. La causa principal de los accidentes fue debida a la fatiga del metal alrededor de la ventanilla donde se alojaba la unidad de radio, y de las ventanillas que ambas eran cuadradas, que terminaron por sucumbir por las aristas a la presurizacion de la cabina. De ahí que desde entonces las ventanillas de los aviones son ovaladas, para disipar la energía alrededor de ellas. La compañía De Havilland intentó salvar su avión, cuyas ventas habían caído drásticamente, a través de algunas modificaciones estructurales, pero un tercer accidente ocurrido en 1956 hizo que de nuevo las ventas cayeran, y al final la producción cesó en 1964.

La norteamericana Boeing lanzó el Boeing 707 en 1958, el cual se convirtió en el primer avión de pasajeros a reacción que tuvo éxito. Los ingenieros que desarrollaron el modelo, dedicaron especial empeño en que los errores que se habían cometido en el De Havilland Comet no se dieran en el 707. Los modelos a reacción Douglas DC-8 y Convair 880 fueron lanzados algunos años después, aunque el éxito comercial que ambos modelos tuvieron fue más modesto que el que alcanzó el 707, del que se produjeron un total de 1010 unidades, convirtiendo a la Boeing desde entonces, en el mayor fabricante de aviones del mundo.

Los modelos 727, 737 y 747 son derivados directos del 707. El Boeing 737, cuya producción fue iniciada en 1964 es el avión para transporte de pasajeros más producido y popular de la historia, con más de seis mil aviones producidos, y ya entrado el siglo XXI, el modelo continúa en producción, gracias a todas las mejoras y variantes producidas.

Los aviones de fuselaje ancho son aviones comerciales que poseen tres filas de asientos separadas por dos pasillos. Se crearon para proporcionar más comodidad a los pasajeros, y facilitar su movilidad y la de los tripulantes por el avión.

El primer avión que poseía un fuselaje ancho fue el Boeing 747, apodado "Jumbo", capaz de transportar a más de 500 pasajeros en un único vuelo. Fue presentado en 1968, y en ese momento muchos pensaban que no tendría éxito comercial, por lo que Boeing pasó por problemas económicos durante el proceso de desarrollo del avión. Sin embargo, el "Jumbo" se convirtió en todo un logro comercial, rompiendo todas las expectativas, y pasando a servir rutas con mucha densidad de pasajeros. Desde su lanzamiento fue el avión comercial más grande del mundo hasta la aparición del Airbus A380, ya en el siglo XXI.

En la década de 1970, aparecieron los primeros trirreactores comerciales, el McDonnell Douglas DC-10 y el Lockheed L-1011 TriStar, capaces de realizar rutas intercontinentales, también el nacimiento del F-14 Tomcat el 21 de diciembre de ese año y que tuvieron un gran éxito en su momento. Años después, también se produciría un derivado del DC-10, el McDonnell Douglas MD-11.

El primer birreactor de fuselaje ancho fue el Airbus A300, un avión comercial de medio alcance, fabricado por el consorcio europeo Airbus. La norteamericana Boeing contraatacó con el Boeing 767, similar al A300 pero que podía operar rutas más largas, y con el Boeing 757 para las rutas de medio alcance, pero que no disponía de fuselaje ancho. El Boeing 767 revolucionó la aviación comercial, ya que su largo alcance, sus bajos costes de operaciones y su capacidad de transporte (podía transportar más de 200 pasajeros) permitían vuelos regulares usando el menor número de aviones posible en rutas transatlánticas y en rutas anteriormente impracticables debido a los altos costes operacionales y al bajo número de pasajeros. Gracias a este avión, se popularizaron los viajes transatlánticos, y a finales de los años 80 y principios de los años 90, había más Boeing 767 cruzando el océano Atlántico diariamente, que todos los demás aviones comerciales sumados que operaban esas rutas, y durante los primeros años del siglo XXI, continúa siendo el avión que más veces es usado para cruzar el Atlántico diariamente, a pesar de la creciente competencia de aviones más modernos y recientes.

Después del fin de la Segunda Guerra Mundial, la tecnología necesaria para la realización de vuelos supersónicos controlados todavía no estaba disponible. Además de eso, los aviones aún no eran lo suficientemente resistentes para soportar las fuertes ondas de choque generadas por las velocidades supersónicas. Al nivel del mar, la velocidad del sonido es de aproximadamente 1225 km/h, pero a 15 000 metros de altura, esta es de apenas 1050 km/h. De hecho, algunos aviadores en la Segunda Guerra Mundial, lograron pasar la barrera del sonido, pero con resultados catastróficos: las fuertes ondas de choque generadas por la velocidad, destruían los aviones, que no habían sido proyectados para alcanzar esas velocidades.

Llegado el año 1947, ingenieros estadounidenses pasaron a trabajar en pequeños prototipos de aviones no controlados. La mayor preocupación de los especialistas en aviación era que estos aviones resistiesen las ondas de choque que se crean a altas velocidades. Los buenos resultados obtenidos en estas pruebas llevarían a la producción de una serie de aviones que denominaron Aviones X ("X-planes" en inglés). El estadounidense Charles Yeager se convirtió en la primera persona en sobrepasar la velocidad del sonido, el 4 de octubre de 1947, pilotando un Bell X-1 bautizado como "Glamorous Glennis".

En 1962, el avión cohete North American X-15 se convirtió en el primer avión en llegar a la termosfera, pilotado por el estadounidense Robert White. Logró permanecer a una altura de 95 936 metros durante dieciséis segundos, recorriendo en ese periodo aproximadamente 80  kilómetros. Este fue el primer vuelo de un avión por el espacio. Posteriormente, el X-15 llegaría a los 107 960 metros de altitud, y también se convirtió en el primer avión hipersónico (5 veces la velocidad del sonido), rompiendo diversos récords de velocidad, y superando Mach 6 (seis veces la velocidad del sonido) en diversos vuelos.

Los primeros aviones supersónicos para uso civil fueron creados a finales de los años 60. El primer avión supersónico comercial del mundo fue el soviético Tupolev Tu-144, que realizó su primer vuelo el 31 de diciembre de 1968.
El Concorde, fabricado por un consorcio franco-británico, hizo su primer vuelo dos meses después. El Tu-144 comenzó sus primeros vuelos de pasajeros en 1977, pero por causa de problemas operacionales, dejó de ser utilizado como avión para el transporte de personas al año siguiente. En cuanto al Concorde, realizó sus primeros vuelos comerciales en 1976, sirviendo en rutas transatlánticas. Ambas aeronaves han sido, hasta el momento, las únicas aeronaves supersónicas comerciales que se han desarrollado. En el 2004, se suspendieron sus vuelos comerciales quedando los Concorde como ejemplares en museos de aviación alrededor del mundo.

Con la carrera espacial siendo uno de los puntos clave de la Guerra Fría entre Estados Unidos y la Unión Soviética, el cielo dejó, literalmente, de ser el límite, al menos para los vuelos controlados. En 1957 el satélite soviético Sputnik se convirtió en el primer satélite en orbitar la tierra, y en 1961, el cosmonauta soviético Yuri Gagarin se convirtió en la primera persona en viajar al espacio, orbitando una vez alrededor del planeta, y permaneciendo allí durante 108 minutos. Los Estados Unidos reaccionaron meses más tarde lanzando al astronauta Alan Shepard al espacio, y años después, lanzando la primera misión a la Luna dentro del Programa Apolo. El 20 de julio de 1969 Neil Armstrong, comandante de la misión Apollo 11 se convertiría en la primera persona en pisar la luna.

El 12 de junio de 1994 el Boeing 777 realizó su primer vuelo, convirtiéndose en el primer avión diseñado y planeado completamente con ordenadores, y en la actualidad es el mayor avión birreactor del mundo. Junto al cuatrirreactor Airbus A340, son los aviones con mayor alcance operacional del planeta, pudiendo recorrer más de 16 000 kilómetros en un único vuelo.

Desde los años 70, los aeropuertos y aviones comerciales pasaron a ser uno de los objetivos preferidos de ataques terroristas. El peor de estos ataques ocurrió en 2001, cuando dos aviones de American Airlines y dos de United Airlines fueron utilizados en los Atentados del 11 de septiembre. Como consecuencia directa de este acontecimiento, el número de viajeros de avión disminuyó en la mayoría de líneas aéreas, y muchas de ellas se enfrentaron a grandes dificultades financieras en los años siguientes. Los efectos del ataque, aunque minimizados, todavía persisten en varias compañías. El resultado de la amenaza terrorista es el incremento de medidas de seguridad que se toman en los aeropuertos desde entonces.

Desde el inicio del siglo XXI, la aviación subsónica pretende sustituir al piloto por aeronaves controladas a distancia o por ordenadores. En abril de 2001, el avión no tripulado denominado Northrop Grumman RQ-4 Global Hawk voló desde la Base de la Fuerza Aérea Edwards (California, Estados Unidos) hasta Australia, sin escalas y sin reabastecerse de combustible, tardando 23 horas y 23 minutos, siendo el vuelo más largo realizado por un avión no tripulado.

Uno de los Concorde de Air France sufrió un accidente el 25 de julio de 2000, cuando una turbina del avión comenzó a arder, haciendo que se estrellara en Gonesse (Francia) poco después de despegar. Hasta entonces, el Concorde era considerado el avión comercial más seguro del mundo. Pasó por un proceso de modernización hasta el 2003, pero por causa del bajo número de pasajeros y de los altos costes operacionales, todos los aparatos dejaron de volar en 2003, cuando British Airways retiró el último en servicio, y desde entonces ningún avión supersónico realiza vuelos comerciales.

El 27 de abril de 2005, el Airbus A380 voló por primera vez, y el 25 de octubre de 2007, con la realización de su primer vuelo comercial entre Singapur y Sídney, se convirtió en el mayor avión comercial de pasajeros del mundo, superando al Boeing 747, que había ostentado ese récord desde que realizó su primer vuelo en 1969. Pero aun así, el A380 es superado en tamaño por el Antonov An-225, que realizó su primer vuelo el 21 de diciembre de 1988, y desde entonces es el mayor avión de la historia.

El 15 de diciembre de 2009, después de dos años de retraso, el Boeing 787 realiza su primer vuelo en las instalaciones que la compañía tiene en el aeropuerto de Paine Field (Everett, Washington, Estados Unidos), convirtiéndose en el primer avión comercial fabricado principalmente con materiales compuestos.

Desde el comienzo de la década de 1990, la aviación comercial pasó a desarrollar tecnologías que en el futuro convertirán al avión en un aparato cada vez más automatizado, reduciendo gradualmente la importancia del piloto en las operaciones de la aeronave, con la intención de reducir los accidentes aéreos causados por fallos humanos. Los fabricantes de aviones comerciales continúan investigando posibles maneras de mejorarlos, convirtiéndolos en aparatos cada vez más seguros, eficientes y silenciosos. Al mismo tiempo, los pilotos, controladores aéreos y mecánicos cada vez estarán mejor preparados y las aeronaves pasarán unas revisiones más rigurosas con el fin de evitar accidentes por fallos humanos o mecánicos.

El Sistema de lanzamiento reutilizable, también conocido por sus siglas en inglés "RLV" ("Reusable Launch Vehicle") es un vehículo de lanzamiento que es capaz de ser lanzado al espacio más de una vez, gracias a sus cohetes reutilizables, que generarían el empuje suficiente para alcanzar el espacio y una vez allí, orbitar alrededor del planeta. Estas aeronaves podrán despegar y aterrizar de la misma manera que los aviones, en pistas de aterrizaje largas. Aunque todavía no están disponibles, hay varios modelos que se encuentran en fase de pruebas, como el SpaceShipOne, que se convirtió en el primer vehículo espacial tripulado de capital privado. Con el tiempo podrían usarse para la realización de viajes espaciales, de bajo coste y alta seguridad. No obstante, para que puedan emplearse en múltiples ocasiones, es necesario que posean una estructura más resistente para soportar el uso continuado, lo que aumentaría el peso del aparato, y dada la falta de experiencia con estos vehículos, aún se tienen que considerar los costes que implicaría su realización.

También se están investigando nuevas fuentes de energía más limpias, como el etanol, electricidad, o incluso empleando energía solar fotovoltaica. Con esta última, la NASA creó el "Helios", un avión alimentado gracias a la energía que le proporciona el sol y sus células fotovoltaicas instaladas en toda su superficie alar. El "Helios" batió el récord de altura en ese tipo de aparatos, y también es capaz de mantenerse durante días en vuelo, lo que hace que en un futuro, aviones similares puedan ser empleados como satélites más económicos. Otras iniciativas privadas, como el avión "Solar Impulse" se han venido desarrollando en los últimos años, augurando el próximo despegue de la aviación solar.

A pesar de los crecientes problemas a los que se ha enfrentado la aviación en general, se cree que el siglo XXI será un siglo de avances dentro del mundo de la aviación. Aviones y cohetes ofrecerán capacidades únicas en términos de velocidad y capacidad de pasajeros y de carga que no deben ser subestimados. Mientras las personas tengan necesidades de transporte de un punto a otro del planeta a gran velocidad, la aviación siempre será necesaria.







</doc>
<doc id="17513" url="https://es.wikipedia.org/wiki?curid=17513" title="Mira Sorvino">
Mira Sorvino

Mira Sorvino (Tenafly, Nueva Jersey; 28 de septiembre de 1967) es una actriz estadounidense, ganadora de los premios Óscar y Globo de Oro.

Nació en Tenafly para Lorraine Ruth Davis, en el estado de Nueva Jersey. Es hija del también conocido actor Paul Sorvino, de ascendencia italiana. Creció en Nueva Jersey y dedicó su infancia y adolescencia a los estudios académicos y no en prepararse para una carrera de actriz; ya que su padre no quería que sus hijos se convirtiesen en estrellas de cine siendo aún muy jóvenes.

Aun así, durante los últimos cursos Sorvino intervino en producciones teatrales del colegio, donde adquirió sus primeras experiencias de interpretación. Más tarde continuó actuando en los montajes teatrales de su universidad. Estudió en la Universidad Harvard, donde se licenció "magna cum laude" en estudios de Asia Oriental. Vivió un año en China, durante el cual aprendió a hablar con fluidez el chino mandarín. También habla el francés.

Después de terminar sus estudios universitarios, Sorvino pasó tres años en Nueva York intentando hacerse un nombre como actriz sin ayuda de nadie. Como tantos otros jóvenes actores y actrices, también ella hizo diversos trabajos mientras esperaba su oportunidad. Uno de sus trabajos fue el de ayudante de producción en una compañía cinematográfica. Cuando en 1993 se inició la preproducción de la película "Amongst Friends", Sorvino fue contratada como tercera ayudante de dirección. Sin embargo, pronto fue promocionada a los puestos de directora de casting y de productora asistente, y finalmente se le ofreció el papel principal femenino de la película. Las críticas de su actuación fueron positivas, lo que le abrió las puertas para actuar en otras películas.

Una interpretación que en 1995 la convirtió en una actriz de reconocido prestigio, fue la de prostituta parlanchina y de voz aguda en "Poderosa Afrodita", de Woody Allen, por la que Sorvino obtuvo el Óscar a la mejor actriz de reparto. Desde entonces ha trabajado de forma continuada en papeles principales y secundarios, en películas de las que algunas tuvieron un considerable éxito comercial, como "Romy y Michelle", coprotagonizada por Lisa Kudrow, y "A primera vista", con Val Kilmer.

Sorvino mantuvo durante varios años una relación con Quentin Tarantino, y más recientemente con el actor francés Olivier Martínez. Actualmente está casada con el actor Christopher Backus, con el que tiene 4 hijos: Mattea Angel, Johnny Christopher King, Holden Paul Terry y Lucia.


</doc>
<doc id="17515" url="https://es.wikipedia.org/wiki?curid=17515" title="Olorun">
Olorun

Olorun es una de las manifestaciones del Dios supremo de la religión yoruba Olodumare. Olorun etimológicamente significa òlò, Señor, y Òrún, cielo; es decir, Señor del cielo o del Más Allá.

De la energía de este Dios supremo surgieron los Ìrúnmalé, subdivididos en Òrìsà (energías masculinas) y Èborás (energías femeninas). Dichos Ìrúnmalé son emanaciones de este Dios supremo y su misión es mantener el equilibrio universal. 

Olorun no posee culto ni templo propios. La mención de su nombre está restricta al ser humano, siendo los Ìrunmalé los intermediarios entre él y los hombres. A través del sol, se le ofrenda en el ñangareo, dando cuenta de que en la tierra se va a hacer un itá o cuando nace un Iyawó.



</doc>
<doc id="17518" url="https://es.wikipedia.org/wiki?curid=17518" title="Eshu">
Eshu

Eshu, Exu o Esu es un orisha en la mitología yoruba. A medida que la religión se ha extendido por el mundo, el nombre de este orisha ha variado en diferentes lugares, pero las creencias siguen siendo similares.

Eshu. Orisha, del grupo de los Orisha Oddé, comúnmente denominados "Los Guerreros". Rige las manifestaciones de lo malévolo.

Èsù es considerado en la religión yorubá la primera partícula diferenciada de vida creada por Òlòórún. La palabra Èsù significa "esfera", y representa la infinitud, el movimiento permanente. Èsù es el mensajero de los Òrìsà; es el intermediario entre los hombres y los Òrìsà. Es el permanente comunicador entre Aiyé (algunas veces mal traducido como mundo en que vivimos) y Òrún (más allá, morada de los Òrìsà, algunas veces mal traducido como cielo).

Eshu Alawana o Alaguana está en todas partes. Vive solitario en los parajes oscuros e inhóspitos del monte o en la sabana. Es el jefe de los eggun, con los que tiene un gran comercio. Representa la desesperanza y el infortunio.

Eshu Alawana es el más pequeño de los Elegguá y acompaña mucho a Oggún. Es considerado el dueño de todo tipo de cadenas, además del garabato de guayaba, de un muñeco de cedro que vive y come con él y del Ariku Bambaya.

Es un gran hechicero, tiene la capacidad para liberar de la prisión, se le invoca con el garabato de guayaba. Tiene su propio Ossain que se prepara en un tarro de toro y tiene su propia sopera. Eshu Alawana para que trabaje se pone en suelo sobre el carapacho de una jicotea.

Entre sus herramientas se encuentran, un Ariku Bambaya, unas cadenas, un garabato de guayaba, su muñeco de cedro y su carapacho de jicotea.

En el panteón yoruba Èsù rige sobre la comunicación, la palabra, las encrucijadas de los caminos (simbolizando las diferentes opciones de la vida), el comercio, el trabajo, etc.

Es hijo de Obatala y de Yenbo o Orchanla, amigo de Ogun y de Ochosi y Ozun son inseparables.
Creado por Olorun. Sus 201 caminos son hijos de Orunmila.

Eshu es la primera partícula de vida creada por Olorun. Se indica que sus 201 caminos son hijos de Orunmila.

Se le inmolan chivos, cazal de gallas de Guinéa, gallos o pollos, pollones, Cazal de palomas (generalmente Oscuras para Lodé y Laná; pero más claras para Adàgué y Aselú).

Las Ofrendas (también llamados Frentes) pueden variar según cada tradición dentro del mismo culto yoruba.
Bara Lodé: maíz tostado, 7 papines (papas chicas) asadas con cáscara y untadas en aceite de dendé (palmera).

Bará Laná: maíz tostado, 7 papines (papas chicas) asadas con cáscara y untadas en aceite de dendé (palmera)

Bará Adàgué: maíz tostado claro, 7 papines (papas chicas) asadas con cáscara y untadas en aceite de dendé (palmera): en el centro, se coloca un buen puñado de pipoca (pororó).

Bará Aselú: Axoxó (maíz hervido), 7 papines (papas chicas) hervidas con cáscaras (una vez frías se pelan para ser presentadas; las mismas van intercaladas con 7 caramelos de miel. Eventualmente, puede reemplazarse los caramelos por tiras de coco fresco pelado.

Como parte de la transculturación y del peligro que vieron los esclavos traídos a Cuba de perder sus raíces, cada santo adoptó el nombre de un santo católico. También está el hecho de que los esclavos venían de diferentes partes de África y en cada uno se le llamaba diferente



</doc>
<doc id="17522" url="https://es.wikipedia.org/wiki?curid=17522" title="Donna Haraway">
Donna Haraway

Donna Haraway (Denver, Colorado, 1944) profesora emérita distinguida del programa de Historia de la Conciencia en la Universidad de California, es la autora de «Cyborg Manifesto» (1985) «Primate Visions: Gender, Race, and Nature in the World of Modern Science» (1989), «Simians, Cyborgs, and Women: The Reinvention of Nature» (1991) y "When species meet" (2008).

Haraway se graduó en Zoología y Filosofía el año 1966 en el «Colorado College» obteniendo la beca de la fundación Boettcher. Vivió en París un año estudiando filosofía de la evolución con una beca Fulbright antes de completar su doctorado en el Departamento de Biología de Yale en 1972. Escribió su tesis sobre las funciones de la metáfora en la configuración de la investigación en biología del desarrollo en el siglo XX.

Haraway ha enseñado estudios de la mujer y «Ciencia General» en la universidad de Hawái y en la universidad Johns Hopkins. Pero la mayor contribución de Haraway vendrá durante sus años de docente de posgrado en el reconocido Departamento de Historia de la Conciencia en la University of California - Santa Cruz integrando el staff junto a Hayden White, Teresa de Lauretis, Angela Davis y James Clifford.

En septiembre de 2000, Haraway fue premiada con altos honores por la «Society for Social Studies of Science», con el premio J.D. Bernal, por una vida de contribuciones en el campo. Haraway es la principal pensadora acerca de la relación amor/odio entre personas y máquinas. Sus ideas han detonado una explosión de debates en áreas tan diversas como en primatología, filosofía y biología del desarrollo (Kunzru, 1). Actualmente ha encontrado un lugar destacado en los debates configurados en torno al antropoceno donde argumenta a favor de una "política multiespecies".

Al leer los libros de Haraway, se hace claro que sus escritos se basan predominantemente en su conocimiento de la historia de la ciencia y la biología (Carubia, 4). En su libro, "Visiones de Primate: Género, Raza, y Naturaleza en el Mundo de la Ciencia Moderna", Haraway explica las metáforas y narrativas que dirigen la ciencia de la primatología. Demuestra que hay una tendencia a masculinizar las historias acerca de la "competencia reproductiva y el sexo entre machos agresivos y hembras receptivas que facilitan algunos y excluyen otros tipos de conclusiones" (Carubia, 4). Alega que las primatólogas se enfocan en observaciones diferentes que requieren más actividades de comunicación y supervivencia básica, ofreciendo perspectivas de los orígenes de la naturaleza y la cultura muy diferentes de las actualmente aceptadas. Recurriendo a estos ejemplos de narrativas e ideologías de género, raza y clase social occidentales, Haraway cuestiona las construcciones más fundamentales de las historias de la naturaleza humana basadas en los primates. En "Visiones de Primate", escribe:

Mi esperanza ha sido que el enfoque siempre oblicuo y a veces perverso facilitara revisiones de narrativas occidentales fundamentales y persistentes acerca de la diferencia, especialmente la diferencia sexual y racial; acerca de la reproducción, especialmente en términos de las multiplicidades de generadores y crías; y acerca de la supervivencia, especialmente acerca de la supervivencia imaginada en las condiciones límite tanto de los orígenes como del fin de la historia, tal y como se cuenta en las tradiciones occidentales de ese complejo género (p.377).

La mira de Haraway es que la ciencia “revele los límites e imposibilidades de su 'objetividad' y que considere algunas revisiones recientes ofrecidas por primatólogas feministas” (Russon, 10). Una experta en su campo, Haraway propuso una perspectiva alternativa de las ideologías aceptadas que continúan moldeando la manera en que se crean historias científicas sobre la naturaleza humana. Lo más importante es que Haraway ofrece analogías inventivas que revelan nuevos horizontes y posibilidades para la investigación (Elkins).

Haraway ha sido descrita como una «feminista, más laxamente una neomarxista y una postmodernista» (Young, 172). Jugando con las palabras del famoso "Manifiesto Comunista" de Marx, Haraway publicó el ensayo «Un manifiesto cíborg: ciencia, tecnología, y feminismo socialista a finales del siglo XX» en la revista "Socialist Review" en 1985. Aunque la mayoría del trabajo anterior de Haraway se enfoca en el énfasis de la inclinación masculina en la cultura científica, ella también ha contribuido enormemente a las narrativas feministas del siglo XX.

Haraway toma de su bagaje científico y se convierte en la observadora y testigo de una tendencia en la sociedad actual y no puede silenciar lo que ve. En "Un manifiesto cíborg", Haraway usa la metáfora del cíborg para ofrecer una estrategia política para los intereses aparentemente disparatados del socialismo y el feminismo. Primeramente, introduce y define el cíborg en cuatro partes. Un cíborg es:


En este ensayo, Haraway también trata un par de formas de feminismo populares durante la década de 1980. Como feminista postmoderna, argumenta en contra del esencialismo, que es «cualquier teoría que declare identificar una causa o constitución de identidad de género o patriarcado universal, transhistórica y necesaria» ("Epistemología feminista", 2006). Tales teorías, argumenta Haraway, excluyen a las mujeres que no se conforman a la teoría y las segregan de las «mujeres reales» o las representan como inferiores. Otra forma de feminismo que Haraway disputa es «un modelo jurisprudencial de feminismo popularizado por la estudiosa legal y marxista Catharine MacKinnon» (Burow-Flak, 2000) que luchó para hacer ilegal la pornografía en la década de 1980, a la cual ella consideró una forma de discurso del odio. Haraway argumenta que el feminismo radical de MacKinnon asimila todas las experiencias de las mujeres en una identidad particular que incorpora las ideologías occidentales que contribuyen a la opresión de las mujeres. Escribe: «Es factual y políticamente erróneo asimilar todos los “momentos” o “conversaciones” diversos en la política femenina reciente nombrada como feminismo radical a la versión de MacKinnon» (158).

De acuerdo con Haraway en su "Manifiesto", «No hay nada acerca de ser hembra que una naturalmente a las mujeres. Ni siquiera existe tal estado como el de “ser” hembra, que de por sí es una categoría altamente compleja construida en discursos científicos sexuales debatidos y otras prácticas sociales» (155). Un cíborg, por otro lado, no requiere una identidad estable y esencialista, argumenta Haraway, y las mujeres deberían considerar crear coaliciones basadas en «afinidad» en vez de identidad. Para dar base a su argumento, Haraway analiza la frase «mujeres de color», sugiriéndola como una categoría posible de política de afinidades (Senft, 2001). Usando un término acuñado por la teórica Chela Sandoval, Haraway escribe que «la “consciencia oposicional” es comparable con la política de cíborg, ya que en vez de la identidad enfatiza cómo la afinidad resulta de la otredad, diferencia y especificidad» (156).

La idea es modificar el propio pensamiento de individuos aislados al pensamiento de la gente como vértices en una red. En este sentido, se puede desarrollar un nexo que no tiene nada que ver con ideales occidentales patriarcales. El «mundo cíborg» ideal de Haraway consiste en gente viviendo junta, sin miedo de su nexo comunal con los animales y las máquinas. «La lucha política es ver desde ambas perspectivas al mismo tiempo, ya que cada una revela tanto dominaciones como posibilidades inimaginables desde el otro punto de vista. La visión sencilla produce peores ilusiones que la visión doble o los monstruos de muchas cabezas» (155).

En los 90 se inició la era ciborg y Haraway es una fiel colaboradora de la cibercultura actual. Aunque en sus textos Haraway utiliza la tecnología a través de la metáfora del ciborg, a la vez es crítica con las consecuencias de lo tecnológico. La idea de que las máquinas pueden contribuir a la liberación es algo que las feministas y mujeres deberían considerar. Haraway escribe: “Hasta ahora (había una vez), la personificación femenina parecía ser algo dado, orgánico, necesario; y la expresión de lo femenino parecía significar el disponer de habilidades maternales o en sentido estricto o metafórico. Solo estando fuera de lugar lograremos un placer intenso con las máquinas y, entonces, con la excusa de que al fin y al cabo se trata de una actividad orgánica después de todo, podremos apropiárnoslas para las mujeres(180).

La siguiente tabla está tomada de "Simios, ciborg y mujeres" e ilustra el cambio que estamos viviendo desde una sociedad orgánica e industrial (columna de la izquierda) hasta un sistema de información polimorfo (columna de la derecha) creado por la política de ciencia y tecnología. Haraway escribe: «Simultáneamente materiales e ideológicas, las dicotomías pueden ser expresadas en la siguiente lista de transiciones desde unas dominaciones jerárquicas confortablemente viejas hasta las aterradoras nuevas redes que he llamado las informáticas de la dominación». (275):






</doc>
<doc id="17526" url="https://es.wikipedia.org/wiki?curid=17526" title="Volker Schlöndorff">
Volker Schlöndorff

Volker Schlöndorf (Wiesbaden, Hessen, Alemania, 31 de marzo de 1939) es un director de cine, guionista, productor, documentalista y actor alemán. Es considerado uno de los directores clave del denominado nuevo cine alemán, movimiento en el que introdujo muchas de las características aprendidas de la Nouvelle Vague.

Dejó la casa de sus padres para ir a un internado jesuita en la Bretaña francesa con intención de que aprendiera francés durante un par de meses. Se quedó tres años allí. Iniciaría su carrera cinematográfica en París, donde se mudó con su familia cuando tenía diecisiete años.

Estudió ciencia política y económica en La Sorbona y dirección en IDHEC, la famosa escuela de cine, y comenzó su carrera profesional durante 1960 como asistente de dirección en varias películas de la Nouvelle Vague: con Alain Resnais en su conocida película "El año pasado en Marienbad" (1961), Louis Malle en "Una vida privada" (1962), "El fuego fatuo" o "¡Viva María!", o Jean-Pierre Melville en "El confidente" (1962).

Su primera película fue un cortometraje rodado en 1965, "Wen Kummert's", que fue prohibido en Francia porque trataba sobre la guerra de Argelia. Dirigió en 1966 "El joven Törless", adaptación de la novela que 60 años antes realizara Robert Musil. Esta película recibió el premio FIPRESCI en el Festival de Cannes así como los Premios del Cine Alemán de mejor película, guion y director y convirtiéndose en uno de los puntales, junto a Fassbinder o Herzog, del nuevo cine alemán.

Posteriormente filmó un episodio de la película "Der Paunkenspieler" (1967), "Mord und Totschlag" (1967), película que contaba con el protagonismo de una de las musas de los Rolling Stones, Anita Pallenberg, quien también aparecía en "El rebelde" (1969), un film ambientado en la Edad Media.

Estuvo casado con la actriz, guionista y directora Margarethe von Trotta.

Entre los numerosos premios que ha recibido su obra destacan el Óscar a la mejor película de habla no inglesa y la Palma de Oro en el Festival de Cine de Cannes logrados por "El tambor de hojalata" (1979), basada en la novela original de Günter Grass.

Schlöndorff adopta diferentes estilos de novela para sus películas que generalmente se comprometen con el tema de la las políticas de la postguerra en Alemania. Ha servido también como Director Ejecutivo del estudio UFA en Babelsberg.

Como autor de documentales destaca especialmente el ciclo de entrevistas que realizó a Billy Wilder en 1992: "Billy Wilder, ¿cómo lo hiciste?" y "Billy Wilder habla" (1996).




</doc>
<doc id="17529" url="https://es.wikipedia.org/wiki?curid=17529" title="Frederick Winslow Taylor">
Frederick Winslow Taylor

Frederick Winslow Taylor (20 de marzo de 1856-21 de marzo de 1915) fue un ingeniero Industrial y economista estadounidense, promotor de la organización científica del trabajo y es considerado el padre de la Administración Científica. En 1878 efectuó sus primeras observaciones sobre la industria del trabajo en la industria del acero. A ellas les siguieron una serie de estudios analíticos sobre tiempos de ejecución y remuneración del trabajo. Sus principales puntos, fueron determinar científicamente trabajo estándar, crear una revolución mental y un trabajador funcional a través de diversos conceptos que se instruyen a partir de un trabajo suyo publicado en 1903 llamado "Shop Management".

Según Antonio Siera Monra, Taylor desde su adolescencia comenzó a perder la vista, además, su cuerpo era de complexión débil y no podía participar de los juegos que los otros organizaban como el béisbol y el tenis. «Obligado al degradante, para un muchacho, papel de espectador, dedicó su vida a concebir cómo mejorar el rendimiento del esfuerzo físico derrochado por los jugadores mediante un diseño más adecuado de los instrumentos por ellos utilizados».
Esta actitud lo marcaría de por vida, para él lo importante era medir el esfuerzo, el lugar y los movimientos para obtener una vasta información y de ahí, sacar provecho de manera que se diera la mayor eficiencia posible tanto en el deporte como en la producción. Sus biógrafos también lo califican como una persona de actitud inflexible frente a las reglas del juego «incluso un juego de críquet representaba para él una fuente de estudio y de análisis».josefina campos fue la hija mayor.

Antes de las propuestas de Taylor, los trabajadores eran responsables de planear y ejecutar sus labores. A ellos se les encomendaba la producción y se les daba la "libertad" de realizar sus tareas de la forma que ellos creían era la correcta sin tener conocimientos técnicos. El autor lo describe de esta manera: “encargados y jefes de taller saben mejor que nadie que sus propios conocimientos y destreza personal están muy por debajo de los conocimientos y destreza combinados de todos los hombres que están bajo su mando. Por consiguiente, incluso los gerentes con más experiencia dejan a cargo de sus obreros el problema de seleccionar la mejor forma y la más económica de realizar el trabajo”. De ahí que sus principios “vistos en su perspectiva histórica, representaron un gran adelanto y un enfoque nuevo, una tremenda innovación frente al sistema”. Se debe reconocer aquí que Taylor representa el sueño de una época, como lo es Estados Unidos de los primeros años del siglo XX donde era imperativo alcanzar la mayor eficiencia posible, cuidando el medio ambiente aunado a una explosión demográfica acelerada en las ciudades, una demanda creciente de productos.

Existe una diferencia muy particular entre la teoría de Taylor y Henry Fayol que resultó adyacente hacia la conyugal del sistema de Estados Unidos, en el uso del tiempo, ya que Fayol se enfoca más en la estructura general de la organización, mientras que Taylor se enfocaba más en el método y herramientas del trabajo para una mejor eficacia. Otra diferencia entre Taylor y Fayol es el área de la pirámide de la organización que estudiaban, una es el nivel operario que es el área de estudio de Taylor mientras que Fayol se dedicó al estudio del área superior de la organización, como él decía " 


En el libro "The Principles of Scientific Management" publicado en 1911 mencionaba los principios que sustentaban la perspectiva científica de la administración y le daban un nuevo giro a la manera de cómo se hacía el trabajo en aquella época, es así como las personas que administran la producción deben adquirir nuevas responsabilidades como se verá a continuación. Según Taylor, la gerencia:

El deseo de Taylor en aplicar su venerado “scientific management”, iba en la noble dirección de conseguir la máxima prosperidad del empresario, así como la máxima prosperidad para el trabajador (Taylor, pág. 21), aun así, después contradice esta afirmación diciendo que ha visto como los trabajadores que empiezan a tener aumentos en su sueldo en más de un 60 % se convierten en "tomadores de trago" y empiezan a disminuir su producción y, así, su calidad de vida; de ahí que el 60 % en el aumento de sueldo sea para él, el tope máximo a pagarle a quien califique como un trabajador tipo buey.

Se deben citar algunos de los argumentos de Taylor para la aplicación de sus propuestas. Para él, el hombre es por naturaleza perezoso, e intenta escudarse en ello para realizar lentamente su trabajo haciendo creer al empresario que está dando lo mejor de sí. De ahí que se deben medir los tiempos y los movimientos de estos trabajadores para estudiarlos y encontrar la mejor combinación de movimientos musculares para elevar la producción y, también, dar uniformidad a los procesos, lo que no ocurría en el antiguo sistema. Para ello era necesario dividir entre quienes piensan las mejores maneras de hacer el trabajo y quienes tienen las fortalezas físicas para ejecutarlo, a los primeros se les daba la responsabilidad de adiestrar a los segundos hasta obtener de ellos el mayor rendimiento que su cuerpo pudiera dar. También habla de la especialización de tareas, pues de esta manera, el trabajador gana más tiempo y destreza haciendo lo mismo todos los días.
"La organización científica del trabajo según Taylor".

El Principio de Excepción planteado por Taylor, en el campo de la administración, representa un filtro de información en el que, según sus palabras: «... el administrador debería recibir informes condensados, resumidos e invariablemente comparativos, cubriendo, sin embargo, todos los elementos que son de interés para la administración. Esos resúmenes deberían ser cuidadosamente revisados por un ayudante antes de que lleguen al administrador, y poseer, además, todas las excepciones buenas como de las excepciones malas; se obtiene en pocos minutos, una visión global de los progresos realizados de los reveses y deja al administrador la posibilidad de considerar las líneas de la política, y estudiar el carácter y el ajuste de los hombres importantes bajo su mando».

Lo que sugiere Taylor, es una autonomía relativa a los diferentes departamentos operativos de la empresa y una red de comunicación "Algedónica" que indique el momento en que la jerarquía debe entrar a funcionar. Este es el "Principio de Excepción" en el campo de la Administración de Empresas.

De esta forma la Algedonía (o el Principio de Excepción) representa el mecanismo que une e integra los conceptos de autonomía de un subsistema con los de jerarquía entre subsistemas. A través de dicho mecanismo la libertad de los subsistemas se hace efectiva y real. El subsistema poseerá total autonomía hasta los límites de su capacidad para controlar su conducta. Pasado ese límite, la Algedonía lo hace dependiente de su subsistema jerárquicamente superior a éste, dentro de su propia autonomía, resuelva el problema y restituya la autonomía perdida del subsistema subordinado. Así éste continuará gozando de "libertad".

Evidentemente, si el sistema jerárquico inmediatamente superior se ve incapacitado de resolver el problema de ese subsistema, entonces deberá acudir, a su vez, a su nivel superior, perdiendo así también su autonomía, en relación con ese problema en particular.



</doc>
<doc id="17530" url="https://es.wikipedia.org/wiki?curid=17530" title="Henri Fayol">
Henri Fayol

Fue uno de los principales contribuyentes al enfoque clásico de la administración. Nació en Estambul, el 29 de julio de 1841, en el seno de familia burguesa. Vivió las consecuencias de la Revolución Industrial y más tarde, la Primera Guerra Mundial. Se graduó en ingeniería de minas a los 19 años, en el año 1860, él ingresó a una empresa metalúrgica y carbonífera, donde desarrolló toda su carrera. A los 25 años fue nombrado gerente de las minas. A los 47 ocupó la gerencia general de la Compagnie Commentry Fourchambault et Decazeville, se hallaba en una situación difícil. Su administración fue muy exitosa. En 1918 entregó la empresa a su sucesor, en una situación de notable estabilidad.

Murió en París el 19 de noviembre de 1925, producto de su edad.

También llamada "Administración positiva", "Enfoque Anatómico" y "Enfoque del proceso administrativo". Su aporte principal fue el de escribir sobre problemas no estudiados por Taylor, ya que mientras Taylor concentra sus estudios en el taller o la fábrica, Fayol lo hace a nivel de la dirección, creando lo que algunos llaman escuela de "jefes".
Hizo grandes contribuciones a los diferentes niveles administrativos. Escribió "Administration industrielle et générale", el cuál describe su filosofía y sus propuestas.

De acuerdo con Fayol, toda empresa industrial debe tener presentes los siguientes seis grupos de funciones:











Las funciones administrativas no son privativas de la alta dirección, sino que se reparten por toda la jerarquía de la empresa. Fayol afirma que la capacidad básica de las personas situadas en los niveles inferiores es la capacidad profesional característica de la empresa, mientras que la capacidad esencial de la alta dirección es la administrativa. Es decir, conforme se asciende en la escala jerárquica de la organización deben aumentar las funciones administrativas, mientras que si se desciende predominan las funciones técnicas.

Uno de los objetivos de los estudios de Henri Fayol –y de toda empresa– debe ser el conseguir mejores administradores a través de una enseñanza organizada de las técnicas de dirección.

Los seis bloques de funciones señalados se dan siempre en cualquier empresa, sea pequeña o grande, simple o compleja. A cada función corresponden capacidades específicas que deben poseer las personas que las vayan a desempeñar.

Fayol organizó las operaciones industriales y comerciales en catorce grupos:












Esta escuela es contemporánea a la de la Administración Científica, cuyo fundador fue Frederick Winslow Taylor.

La preocupación era aumentar la eficiencia de la empresa a través de la forma y disposición de los órganos componentes de la organización ("departamentos") y de sus relaciones estructurales. De allí el énfasis en la anatomía ("estructura") y en la neuroanatomía ("funcionamiento") de la organización. En este sentido, el enfoque de la corriente anatómica y ecologista es un enfoque progresivo al de la administración científica: de arriba hacia abajo (de la dirección hacia la ejecución) del todo ("organización") hacia sus partes componentes ("departamentos"). Predominaba la atención en la estructura organización, con los demás elementos de la administración, con los principios generales de la administración, con la departamental. Ese cuidado con la síntesis y con la visión global permitía una mejor manera de subdividir la empresa bajo la centralización de un jefe principal. Fue una corriente eminentemente teórica y “administrativamente orientada”. El énfasis en la estructura es su principal característica.


En dicho libro algunas de sus aportaciones son: 






</doc>
<doc id="17531" url="https://es.wikipedia.org/wiki?curid=17531" title="Harrington Emerson">
Harrington Emerson

Harrington Emerson (2 de agosto de 1853 – 2 de septiembre de 1931) fue una de las figuras más importantes y relevantes que revolucionaron la Ingeniería Industrial.
Es conocido por sus contribuciones a la administración científica, donde desarrolló un enfoque que contrasta la eficiencia.

Sus padres fueron Edwin y Mary Louisa Emerson.
Emerson se casó dos veces: en la década de 1870 a Florencia, Brooks y en 1895 a Mary Crawford Supple. Su hijo Raffe nació en 1880. Emerson y Mary Supple tuvo tres hijas: Louise, Isabel y Margarita. Desde sus inicios, Emerson tuvo influencias políticas importantes ya que gran parte de su familia dedicaba sus actividades ello. Su abuelo materno, Samuel Delucenna Ingham, es un claro ejemplo de ello ya que desempeño cargos importantes con el Gobierno estadounidense, llegando a ser Secretario de Tesorería del Gobierno Norteamericano. De esta forma, Samuel logró ser fundador y propietario del Hazleton Coal and Railroad Company, asegurando así la fortuna para la familia Emerson.

Desde muy pequeño Harrignton estuvo a la disposición de tutores y escuelas privadas en Inglaterra, Francia y Grecia. Fue también estudiante de Ingeniería en el Royal Bavarian Polytechnique. Al finalizar sus estudios, regresó a los Estados Unidos y se convirtió en un profesor de lenguajes modernos en la Universidad de Nebraska. Sin embargo, fue despedido en 1882 debido a confrontaciones de índole religiosas. Emerson dejó de lado sus intereses académicos para empezar una carrera como banquero, especulador de propiedades, agente de impuestos, agente fiscal y solucionador de problemas para el Union Pacific y los ferrocarriles de Burlington y Missouri. 

Emerson estableció su propia compañía de préstamos privados en 1883, y en colaboración con su hermano Samuel formó una compañía que invirtió en la construcción de pueblos futuros en el oeste de Nebraska. Emerson invirtió $70.000 en proyectos para el Lincoln Land Company, pero a causa de la sequía y malas cosechas de los cultivos, no pudo afrontar sus pagos hipotecarios y perdió toda su fortuna. En el año 1896 Emerson fue encargado de la campaña política para las elecciones presidenciales y fue el representante del sindicato de inversión inglés.

Para el desarrollo de las industrias americanas, Emerson se dedicó a buscar fondos mediante una investigación en la manufactura, y al negocio de la minería. Gracias al tiempo de investigación dedicado, Emerson tuvo el conocimiento industrial necesario para crear una fundación de consultoría en eficiencia industrial, lo que le llevó de nuevo ser la mano derecha de la campaña del presidente William Jennings Bryan. Después de esto Emerson empezó a trabajar en la ingeniería mecánica para aplicarlo en la energía eléctrica y diésel para la navegación marítima. Después, en 1897, trabajó para General Electric Storage Battery Company en Nueva York para ser el encargado de la línea de investigación. A pedido de la empresa, Emerson se mudó a Seattle, Washington y experimentó con los buques de potencia de navegación eléctrica. Atraídos por el “Gold Rush” en Alaska en 1897, Emerson y varios asociados llevaron a cabo una variedad de proyectos especulativos. Uno de los proyectos más ambiciosos de Emerson, fue la propuesta de la construcción de un cable-telegráfico transpacífico desde Seattle hasta la Filipinas a través de Alaska. El proyecto fracasó por complicaciones financieras y jurídicas, por ello decidió tomar el trabajo de consultoría en eficiencia industrial para poder cubrir la deuda.

Después de su éxito como director general de una pequeña fábrica de vidrio en Pensilvania, en 1900, Emerson decidió tomar la ingeniería de la eficiencia como profesión. A través de reuniones de la Sociedad Americana de Ingenieros Mecánicos, se convirtió en socio laboral de Frederick W. Taylor, el fundador de la administración científica. Entre 1921-28 fue consejero de líderes de gobierno y ministros de transportes de China, Japón, Perú, Polonia y Unión Soviética.

A partir de este periodo, Harrigton Emerson se dedicó a trabajar dentro del campo industrial, desarrollando proyectos, técnicas y principios que innovarían el mundo de la industria.

Su libro, "The Twelve Principles of Efficiency" (1911), presentaba las bases para obtener operaciones eficientes, y sus 12 principios que de alguna forma fueron paralelos a las enseñanzas de Frederick Winslow Taylor, eran los siguientes:


No cabe duda que los 12 principios expuestos por Emerson en 1911 son tan validos hoy como lo fueron entonces.


</doc>
<doc id="17532" url="https://es.wikipedia.org/wiki?curid=17532" title="Revolución Industrial">
Revolución Industrial

La Revolución Industrial o Primera Revolución Industrial es el proceso de transformación económica, social y tecnológica que se inició en la segunda mitad del siglo XVIII en el Reino de Gran Bretaña, que se extendió unas décadas después a gran parte de Europa occidental y América Anglosajona, y que concluyó entre 1820 y 1840. Durante este periodo se vivió el mayor conjunto de transformaciones económicas, tecnológicas y sociales de la historia de la humanidad desde el Neolítico, que vio el paso desde una economía rural basada fundamentalmente en la agricultura y el comercio a una economía de carácter urbano, industrializada y mecanizada.

La Revolución Industrial marca un punto de inflexión en la historia, modificando e influenciando todos los aspectos de la vida cotidiana de una u otra manera. La producción tanto agrícola como de la naciente industria se multiplicó a la vez que disminuía el tiempo de producción. A partir de 1800 la riqueza y la renta per cápita se multiplicó como no lo había hecho nunca en la historia, pues hasta entonces el PIB per cápita se había mantenido prácticamente estancado durante siglos. En palabras del premio Nobel Robert Lucas:
A partir de este momento se inició una transición que acabaría con siglos de una mano de obra basada en el trabajo manual y el uso de la tracción animal siendo estos sustituidos por maquinaria para la fabricación industrial y el transporte de mercancías y pasajeros. Esta transición se inició a finales del siglo XVIII en la industria textil y la extracción y utilización de carbón. La expansión del comercio fue posible gracias al desarrollo de las comunicaciones con la construcción de vías férreas, canales o carreteras. El paso de una economía fundamentalmente agrícola a una economía industrial influyó sobremanera en la población, que experimentó un rápido crecimiento sobre todo en el ámbito urbano. La introducción de la máquina de vapor de James Watt (patentada en 1769) en las distintas industrias fue el paso definitivo en el éxito de esta revolución, pues su uso significó un aumento espectacular de la capacidad de producción. Más tarde el desarrollo de los barcos y ferrocarriles a vapor así como el desarrollo en la segunda mitad del XIX del motor de combustión interna y la energía eléctrica supusieron un progreso tecnológico sin precedentes. 

Como consecuencia del desarrollo industrial nacieron nuevos grupos o clases sociales encabezadas por el proletariado —los trabajadores industriales y campesinos pobres— y la burguesía, dueña de los medios de producción y poseedora de la mayor parte de la renta y el capital. Esta nueva división social dio pie al desarrollo de problemas sociales y laborales, protestas populares y nuevas ideologías que propugnaban y demandaban una mejora de las condiciones de vida de las clases más desfavorecidas, por la vía del sindicalismo, el socialismo, el anarquismo, o el comunismo.

Aún sigue habiendo discusión entre historiadores y economistas sobre las fechas de los grandes cambios provocados por la Revolución Industrial. El comienzo más aceptado de lo que podríamos llamar Primera Revolución Industrial, se podría situar a finales del siglo XVIII, mientras su conclusión se podría situar a mediados del siglo XIX, con un período de transición ubicado entre 1840 y 1870. Por su parte, lo que podríamos llamar Segunda Revolución Industrial, partiría desde mediados del siglo XIX a principios del siglo XX, destacando como fecha más aceptada de finalización a 1914, año del comienzo de la Primera Guerra Mundial. El historiador marxista Eric Hobsbawm, considerado "pensador clave de la historia del siglo XX" sostenía que el comienzo de la revolución industrial debía situarse en la década de 1780, pero que sus efectos no se sentirían claramente hasta 1830 o 1840. En cambio, el historiador económico inglés T.S. Ashton declaraba por su parte, que la revolución industrial tuvo sus inicios entre 1760 y 1830.
Algunos historiadores del siglo XX, como John Clapham y Nicholas Crafts, argumentan que el proceso de cambio económico y social fue muy gradual, por lo que el término «revolución» resultaría inapropiado. Estas cuestiones siguen siendo tema de debate entre historiadores y economistas.

Los inicios de la industrialización europea hay que buscarlos en la Edad Moderna. A partir del siglo XVI se vislumbra un avance en el comercio, métodos financieros, banca y un cierto progreso técnico en la navegación, impresión o relojería. Sin embargo estos avances siempre se veían lastrados por epidemias, constantes y largas guerras y hambrunas que no permitían la dispersión de los nuevos conocimientos ni un gran crecimiento demográfico. Según el historiador Angus Maddison, Europa Occidental experimentó un crecimiento demográfico prácticamente nulo entre 1500 y 1800. 

El Renacimiento marcó otro punto de inflexión con la aparición de las primeras sociedades capitalistas en Holanda y el norte de Italia. Es a partir de mediados del siglo XVIII cuando Europa comenzó a distanciarse del resto del mundo y a asentar las bases de la futura sociedad industrial debido al desarrollo, aún primitivo, de la industria pesada y la minería. La "alianza" de los comerciantes con los agricultores hizo aumentar la productividad, lo que a su vez provocó una explosión demográfica, acentuada a partir del XIX. La Revolución Industrial se caracterizó por la transición de una economía agrícola y manual a una comercial e industrial cuya ideología se basaba en el racionalismo la razón y la innovación científica.

Otro de los principales desencadenantes de la Revolución nace de la necesidad. Aunque en algunos lugares de Europa como Gran Bretaña ya existía una base industrial, las Guerras Napoleónicas consolidaron la industria europea. Debido a la guerra, que se extendía por la mayor parte de Europa, las importaciones de muchos productos y materias primas se suspendieron. Esto obligó a los gobiernos a presionar a sus industrias y a la nación en general para producir más y mejor que antes, desarrollándose industrias antes inexistentes.
La industrialización tuvo lugar en diferentes oleadas en los distintos países. Las primeras áreas industriales aparecieron en Gran Bretaña a finales del siglo XVIII, extendiéndose a Bélgica y Francia a principios del siglo XIX y a Alemania y a Estados Unidos a mediados de siglo, a Japón a partir de 1868 y a Rusia, Italia y España a finales de siglo. Entre las razones se encontraron algunas tan dispares como la notable ausencia de grandes guerras entre 1815 y 1914, la aceptación de la economía de mercado y el consecuente nacimiento del capitalismo, la ruptura con el pasado, un cierto equilibrio monetario y la ausencia de inflación.

Otras interpretaciones sugieren que este nuevo cambio de mentalidad y la posterior evolución del sistema económico fue por causas morales y religiosas. La Reforma protestante de Martín Lutero y Juan Calvino trajo consigo un cambio de mentalidad en el trato y visión respecto del trabajo. Según Max Weber el protestantismo considera al trabajo y al esfuerzo como un bien y un valor fundamental, al contrario que la ética católica que lo considera un castigo a raíz del pecado original. Esto explicaría en parte las diferencias a la hora de desarrollarse de las distintas naciones europeas, teniendo como "pioneros" a países protestantes como Gran Bretaña, Alemania u Holanda y como países atrasados a España, Portugal e Italia, todos ellos católicos. Esta interpretación sigue siendo muy discutida.

La Revolución Industrial se originó en Inglaterra a causa de diversos factores, cuya elucidación es uno de los temas historiográficos más trascendentes.
Como factores técnicos, era uno de los países con mayor disponibilidad de las materias primas esenciales, sobre todo el carbón, mineral indispensable para alimentar la máquina de vapor que fue el gran motor de la Revolución Industrial temprana, así como los altos hornos de la siderurgia, sector principal desde mediados del siglo XIX. Su ventaja frente a la madera, el combustible tradicional, no es tanto su poder calorífico como la mera posibilidad en la continuidad de suministro (la madera, a pesar de ser fuente renovable, está limitada por la deforestación; mientras que el carbón, combustible fósil y por tanto no renovable, solo lo está por el agotamiento de las reservas, cuya extensión se amplía con el precio y las posibilidades técnicas de extracción).

Como factores ideológicos, políticos y sociales, la sociedad inglesa había atravesado la llamada crisis del siglo XVII de una manera particular: mientras la Europa meridional y oriental se refeudalizaba y establecía monarquías absolutas, la guerra civil inglesa (1642-1651) y la posterior revolución gloriosa (1688) determinaron el establecimiento de una monarquía parlamentaria (definida ideológicamente por el liberalismo de John Locke) basada en la división de poderes, la libertad individual y un nivel de seguridad jurídica que proporcionaba suficientes garantías para el empresario privado; muchos de ellos surgidos de entre activas minorías de disidentes religiosos que en otras naciones no se hubieran consentido (la tesis de Max Weber vincula explícitamente "La ética protestante y el espíritu del capitalismo"). Síntoma importante fue el espectacular desarrollo del sistema de patentes industriales.

Como factor geoestratégico, durante el siglo XVIII Inglaterra (que tras las firmas del Acta de Unión con Escocia en 1707 y del Acta de Unión con Irlanda en 1800, después de la derrota de la rebelión irlandesa de 1798, consiguieron la unión con Escocia e Irlanda, formando el Reino Unido de Gran Bretaña e Irlanda) construyó una flota naval que la convirtió (desde el tratado de Utrecht, 1714, y de forma indiscutible desde la batalla de Trafalgar, 1805) en una verdadera talasocracia dueña de los mares y de un extensísimo imperio colonial. A pesar de la pérdida de las Trece Colonias, emancipadas en la guerra de Independencia de Estados Unidos (1776-1781), controlaba, entre otros, los territorios del subcontinente Indio, fuente importante de materias primas para su industria, destacadamente el algodón que alimentaba la industria textil, así como mercado cautivo para los productos de la metrópolis. La canción patriótica "Rule Britannia" (1740) explícitamente indicaba: "rule the waves" (gobierna las olas).

Durante la revolución industrial se vivió un incremento espectacular de la población, debido fundamentalmente a la caída de la tasa de mortalidad provocada por la mejora de las condiciones higiénicas, sanitarias y alimenticias que se plasmó en gran medida en la reducción de la mortandad infantil. En este periodo nacen las primeras vacunaciones y se mejoran los sistemas de alcantarillado y de depuración de aguas residuales. Una alimentación más abundante y regular, no sometida a las fluctuaciones de las cosechas, bajó la incidencia de las epidemias e hizo posible la casi desaparición de la mortalidad catastrófica, sobre todo la infantil.

La población de Inglaterra y Gales, que había permanecido constante alrededor de 6 millones desde 1700 a 1740, se incrementó bruscamente a partir de esta fecha y alcanzó 8,3 millones en 1801, para doblarse en cincuenta años y llegar a los 16,8 millones en 1850 y en 1901 casi se había doblado de nuevo con 30,5 millones. En Europa, la población pasó de 100 millones en 1700 hasta alcanzar 400 millones en 1900. La revolución industrial fue así el primer periodo histórico durante el que hubo simultáneamente un incremento de la población y un incremento de la renta per cápita. El aumento de la población fue un estímulo para el crecimiento industrial ya que proporcionó a la vez mano de obra abundante para las nuevas industrias y de otro lado supuso un incremento de la demanda interna para los nuevos productos.

El aumento de la población urbana en ciudades con trazado medieval supuso el hacinamiento, la insalubridad y la aparición de las primeras patologías sociales (alcoholismo, prostitución y delincuencia).

Entre finales del siglo XVII y principios del XVIII el gobierno británico aprobó una serie de leyes con el fin de proteger a la industria de la lana británica de la creciente cantidad de tela de algodón que se importaba desde India Oriental.
También empezó a darse una mayor demanda de tejidos gruesos, los cuales eran fabricados por la industria británica en la localidad de Lancashire, donde destacaba la producción de pana, fabricada a partir de fibras entrecruzadas de lino y algodón. El lino era utilizado para dotar de más resistencia al tejido, cuyo material principal, el algodón, no tenía una resistencia suficiente, aunque esta mezcla resultante no era tan suave como los tejidos 100% algodón y era más difícil de coser.

Hasta el nacimiento de la industria textil, los tejidos y el hilado en general se realizaba en los hogares, en la mayor parte de los casos para consumo propio. Este método productivo, basado en que la producción estaba dispersa y se desarrollaba en los domicilios de los trabajadores, es a menudo denominado en inglés como sistema Putting-out ("Putting-out system") en contraposición al posterior sistema industrial o "factory system". Solo en ocasiones puntuales los trabajos se realizaban en el taller de un maestro tejedor. Bajo el sistema "putting-out" los trabajadores, antes de fabricar su producto, pactaban contratos con comerciantes y vendedores, quienes les suministraban a menudo las materias primas necesarias. Fuera de temporada, por la general, las esposas de los agricultores hacían los hilados mientras que los hombres producían los tejidos. Utilizando la máquina de hilar o rueca, en cualquier momento entre cuatro y ocho hilanderas podían echar una mano al tejedor. Uno de los grandes inventos de la industria textil fue la lanzadera volante, patentada en 1733 por John Kay, que permitió una cierta automatización del proceso de tejido. Posteriores mejoras, destacando las de 1747, permitieron duplicar la capacidad de producción de los tejedores, lo que también agravó el desequilibrio que existía entre el hilado y el tejido. Este invento empezó a ser ampliamente utilizado en todo Lancashire en la década de 1760, cuando Robert Kay, hijo de John Kay, inventó la caja ascendente ("drop box").
Lewis Paul patentó en Birmingham, con la ayuda de John Wyatt, la máquina de hilar mediante rodillos y el sistema "flyer-and-bobbin", que conseguían un espesor más uniforme en el proceso de elaboración de la lana. Paul y Wyatt abrieron una fábrica en Birmingham que utilizaba una nueva máquina de laminado impulsada por un burro. En 1743 se abrió una fábrica en Northampton que empleaba cinco máquinas como la de Paul con cincuenta husos cada una. Estuvo en funcionamiento hasta 1764. Una fábrica similar fue construida por Daniel Bourn en Leominster, pero un incendio la destruyó. Tanto Paul como Bourn habían patentado el cardador de lana en 1748. El uso de dos conjuntos de rodillos que giraban a diferentes velocidades fue utilizado posteriormente en la primera fábrica de hilados de algodón. La invención de Lewis fue posteriormente mejorada por Richard Arkwright con su Water frame y por Samuel Crompton con su Spinning mule.

En 1764 en el pueblo de Stanhill, Lancashire, James Hargreaves inventó la hiladora Jenny, que patentó en 1770. Fue la primera máquina que empleaba varios husos de una manera eficaz. La hiladora Jenny trabajaba de una manera similar a la rueca. Era una máquina simple, construida con madera y que solo costaba alrededor de 6 libras (un modelo de 40 husos) en 1792. Era utilizada principalmente en los hogares o por pequeños artesanos. La hiladora Jenny producía un hilo ligeramente torcido solo adecuado para la trama, que se torcía.

La máquina de hilar ("Water frame") inventada por Richard Arkwright, fue patentada por este junto con dos socios en 1769. El diseño se basaba en parte en una máquina de hilado construida por Thomas High, quien fue contratado por Arkwright.

Sin embargo, y a pesar de todos los factores anteriores, la Revolución industrial no hubiese podido prosperar sin el concurso y el desarrollo de los transportes, que llevarán las mercancías producidas en la fábrica hasta los mercados donde se consumían.

Estos nuevos transportes se hacen necesarios no solo en el comercio interior, sino también en el comercio internacional, ya que en esta época se crean los grandes mercados nacionales e internacionales. El comercio internacional se liberaliza, sobre todo tras el Tratado de Utrecht (1713) que liberaliza las relaciones comerciales de Inglaterra, y otros países europeos, con la América española. Se termina con las compañías privilegiadas y con el proteccionismo económico; y se aboga por una política imperialista y la eliminación de los privilegios gremiales. Además, se desamortizan las tierras eclesiásticas, señoriales y comunales, para poner en el mercado nuevas tierras y crear un nuevo concepto de propiedad. La Revolución industrial generó también un ensanchamiento de los mercados extranjeros y una nueva "división internacional del trabajo" (DIT). Los nuevos mercados se conquistaron mediante el abaratamiento de los productos hechos con la máquina, por los nuevos sistemas de transporte y la apertura de vías de comunicación, así como también, mediante una política expansionista.

El Reino Unido fue el primero que llevó a cabo toda una serie de transformaciones que la colocaron a la cabeza de todos los países del mundo. Los cambios en la agricultura, en la población, en los transportes, en la tecnología y en las industrias, favorecieron un desarrollo industrial. La industria textil algodonera fue el sector líder de la industrialización y la base de la acumulación de capital que abrirá paso, en una segunda fase, a la siderurgia y al ferrocarril.

A mediados del siglo XVIII, la industria británica tenía sólidas bases y con una doble expansión: las industrias de bienes de producción y de bienes de consumo. Incluso se estimuló el crecimiento de la minería del carbón y de la siderurgia con la construcción del ferrocarril. Así, en Gran Bretaña se desarrolló de pleno el capitalismo industrial, lo que explica su supremacía industrial hasta 1870 aproximadamente, como también financiera y comercial desde mediados de siglo XVIII hasta la Primera Guerra Mundial (1914). En el resto de Europa y en otras regiones como América del Norte o Japón, la industrialización fue muy posterior y siguió pautas diferentes a la británica.

Unos países tuvieron la industrialización entre 1850 y 1914: Francia, Alemania y Bélgica. En 1850 apenas existe la fábrica moderna en Europa continental, solo en Bélgica hay un proceso de revolución seguido al del Reino Unido. En la segunda mitad del siglo XIX se fortalece en Turingia y Sajonia la industrialización de Alemania.

Otros países siguieron un modelo de industrialización diferente y muy tardía: Italia, Imperio austrohúngaro, España o Rusia. La industrialización de éstos se inició tímidamente en las últimas décadas del siglo XIX, para terminar mucho después de 1914.

El ferrocarril, nacido en el siglo XVIII, es uno de los grandes protagonistas de la Revolución Industrial.
En sus comienzos se empleaba la fuerza animal como medio de locomoción, los raíles eran de madera y su empleo se limitaba a las minas para el transporte de carbón. En un libro publicado en 1797, Carz aseguraba haber sido el primero que pensó en sustituir la madera por hierro. La primera concesión del Parlamento inglés para la construcción de un ferrocarril —movido por caballos— se remonta a 1801; se trataba de una línea entre Wandsworth y Croydon con unos 13 kilómetros de longitud y con un coste de 60 000 libras. La gran revolución del ferrocarril comenzó en 1814, cuando George Stephenson utilizó la máquina de vapor como medio de locomoción. Su "invento" fue un éxito y comenzó a usarse de inmediato en las minas, pudiendo transportar ocho vagones de 30 toneladas a una velocidad de 7 km/h. Estos resultados eran suficientes para expandir el uso de la máquina a otros servicios. Fue un 1821 cuando el Parlamento autorizó la construcción de la primera línea de ferrocarril con tracción de vapor entre Stockton y Darlington. La línea fue inaugurada en 1825 con una máquina maniobrada por el propio Stephenson tirando de 34 vagones a una velocidad de entre 10 y 12 millas por hora —16-19 km/h— ; El periódico "The Times" describió esta hazaña de la siguiente manera:
En los 5 años posteriores el Parlamento autorizó la construcción de 23 nuevas líneas de ferrocarril entre las que se encontraba la célebre línea entre Mánchester y Liverpool, siendo sus constructores los primeros en ofrecer en el ferrocarril el servicio de transporte de pasajeros. En aquel momento se desconfiaba de la seguridad que podían ofrecer las locomotoras, pero la acogida fue muy buena, mejorando en un 10% los beneficios derivados de este servicio, aunque los ingresos por el transporte de algodón, tejidos, carbón y ganado aún seguían siendo mayoritarios. Este éxito también fue tratado por George Porter, quien en su libro "El progreso de la nación" dice :

Fue en esta ocasión el propio Stephenson el que ganó la puja en esta línea convirtiéndose su "Cohete" en el encargado de remolcar un tren de 12 toneladas a 22 km/h. El primer correo por ferrocarril se envió el 11 de noviembre de 1830. Los tiempos de llegada se redujeron considerablemente, llegando el correo entre Londres y Manchester en aproximadamente 18 horas. En Inglaterra, siguiendo la consigna "laissez faire", el Estado no intervenía en la construcción o subvención del ferrocarril sino que se resignaba a otorgar las licencias y permisos de construcción y explotación; de esta manera se gastaron enormes fortunas con el objetivo de obtener los distintos permisos; por ejemplo el "Great Western" costó en gastos preliminares 89 000 libras y otros como el "London and Birmingham" 62 000.

Los ferrocarriles eran al principio de vía estrecha y solo admitían velocidades comprendidas entre los 15 y los 20 kilómetros por hora, pero en 1840 se habían ensanchado las vías y se podían conseguir unas velocidades de casi 40 km/h.
El primer país continental en seguir el ejemplo inglés fue Bélgica con dos líneas Bruselas-Malinas y Malinas-Amberes en 1835. El primer año transportaron 70 000 pasajeros. El coste fue bajísimo y el billete Bruselas-Amberes costaba solo un franco. El invento entró en Francia con algo de retraso pues mientras jóvenes, ingenieros y adeptos al saintsimonismo reclamaban su construcción, tropezaban con el rechazo y la desconfianza de muchos, además de la carencia de hierro. El gobierno francés, que veía el potencial del aparato, ordenó un estudio para un plan nacional de los ferrocarriles. El estudio quedó finalizado en 1837 y los capitalistas, impacientes, presionaban al gobierno para la ejecución del proyecto con el fin de especular con las obras y los terrenos. El plan consistía en siete líneas con centro en París, que unirían el Atlántico, el Mediterráneo y el Rin. Al contrario que en Inglaterra y Bélgica, el estado se hizo cargo, al menos en parte, de su construcción y explotación, aportando 150 000 francos por kilómetro de vía y construyendo las infraestructuras necesarias. Mientras, las compañías privadas aportaron 100 000 francos para edificios y material. Tras 40 años de administración y explotación privada, el sistema pasaría al Estado. Socialistas románticos y conservadores se oponían al proyecto, los primeros reclamaban que el sistema fuera del estado desde el primer día y los segundos lo consideraban demasiado caro. Finalmente el plan fue aprobado, pero algunos acuerdos se revisaron y en la práctica la construcción y explotación corrió a cuenta casi exclusiva del sector privado. En 1857 la red estaba consolidada siendo propiedad de 6 grandes compañías. Debido a la obligación de ceder la propiedad al Estado a los 40 años de explotación se descuidó sobremanera su cuidado y mantenimiento por lo que el gobierno francés se vio en la obligación de ampliar el plazo en 99 años más, comprometiéndose incluso a pagar las obligaciones a su vencimiento.

En Alemania la primera línea se construyó en 1835 con una extensión de siete kilómetros entre Núremberg y Fürth pero fue en 1839 cuando se construyó la primera línea de importancia entre Dresde y Leipzig, promovida por el profesor de economía política List, uno de los principales promotores de la línea Núremberg-Fürth. Pronto se vio al ferrocarril como una poderosa arma política; en el momento de la aparición del ferrocarril, Alemania se encontraba dividida en más de 300 pequeños estados y ciudades autónomas. Desde la construcción de la línea Dresde-Leipzig todas las ciudades alemanas quisieron unirse con su vecina lo que además de un gran impulso económico hizo un gran servicio para el triunfo del "Zollverein". Al contrario que en el resto de países, en Alemania fue la administración la encargada de vigilar o administrar todos los ferrocarriles. En 1850 el "Zollverein" ya poseía 5800 kilómetros casi el doble que toda Francia. Hannover, Bremen, Hamburgo, Berlín, Fráncfort formaban una gran línea que transcurría sobre los principales focos industriales y unía Alemania con Suiza a través de Basilea y a Austria a través de Moravia y Silesia.
A partir de la década de 1820 el ferrocarril y el vapor saltaron a los Estados Unidos y pronto conquistaron a la opinión pública. Stevens realizó en Hoboken una primera prueba que causó un gran interés entre los hombre de negocios de Pensilvania, quienes compraron una locomotora a Inglaterra. Al igual que en Gran Bretaña, la acumulación de capital hizo posible solo un año después el comienzo de la construcción de una primera línea entre Washington y Winchester. En 1830 una locomotora llamada "Best Friend" explotó cuando marchaba por la línea Charleston-Hambourg debido a que el maquinista se había sentado sobre la válvula de escape por las molestias que sentía debido al silbido del vapor al salir. Pero lejos de echarse atrás, el país progresó a un ritmo frenético y a mediados de 1830 ya producía sus propias locomotoras en la fundición de West Point asegurando una industria nacional sólida. Desde entonces Estados Unidos colocó raíles a través de su vasto territorio a una velocidad mucho mayor que Europa. Si en 1830 poseía tan solo 65 kilómetros de trazado —contra 316 europeos, 276 de ellos en Gran Bretaña—, 10 años después ya superaba a Europa con 4509 kilómetros contra 3543 europeos. En 1850 las vías férreas ya sumaban 14 400 kilómetros. Uno de los problemas que planteaban los ferrocarriles era el ancho de vía, que variaba en anchura en los distintos países, lo que obligaba a numerosos transbordos para deleite de los hosteleros. Pero problemas aparte el tiempo de viaje no hizo sino disminuir; así, en apenas unos años no se tardaban más de 20 horas en viajar de Boston a Nueva York en ferrocarril cuando antes se tardaban unas 80.

En Italia los augurios de d´Azeglio de que "los ferrocarriles coserían la bota" no pasaron de simples promesas, pues hasta 1845 solo se encontraban pequeñas líneas aisladas como la línea Milán-Monza, Padua-Venecia, Liorna-Pisa o la línea de Campania que Fernando de Nápoles construyó para su recreo y uso privado. En Hungría solo existía una pequeña vía alrededor de Budapest y en Rusia el zarismo tuvo que imponer la construcción de la línea Moscú-San Petersburgo debido a los numerosos detractores. En España, el gran tirón y entusiasmo que de manera muy temprana había producido el invento se apaga en la guerra civil de 1833, que paraliza todas las obras de construcción ante la desconfianza de los capitalistas. Hubo que esperar hasta 1843 cuando se concedió a Juan Manuel Roca y Miguel Biada la construcción y explotación del ferrocarril Barcelona-Mataró, que estuvo construido en solo cinco años bajo la dirección del ingeniero inglés Locke, su inauguración fue el 28 de octubre de 1848, un trayecto de 28 km y 600 m que se completaba en 35 minutos. En 1851 realizó su primer viaje el segundo ferrocarril español que cubría la línea Madrid-Aranjuez, cuya concesión había sido otorgada en 1844 con prolongación hasta Cádiz. En 1850 se inició la construcción de la primera locomotora española, finalizada en 1852.

Excepciones aparte, en el periodo entre 1820 y 1840, Gran Bretaña conservaba un adelanto manifiesto sobre el resto del mundo. Era la única que poseía una buena red de transporte entre sus principales ciudades. Trabajó con verdadero frenesí entre 1840 y 1847 a pesar de la rivalidad latente entre la oposición, los grupos financieros, los "Turnpike trusts" y la población, cuyo medio de subsistencia continuaban siendo las carreteras. Similar situación se dio en Bélgica, que en 1843 tenía incluso más kilómetros que Francia y una opinión pública muy favorable al ferrocarril.
No fueron pocos los que vieron en el ferrocarril un gran peligro, incluso mortal. Desde el siglo XVIII, cuando se pusieron en marcha en Inglaterra hubo voces, incluso procedentes de la Real Academia de Ciencias británica, que sugerían que a unas velocidades superiores a los 40km/h los pasajeros se asfixiarían, se volverían ciegos y el ganado enloquecería. Se temía también la destrucción de las tierras de cultivo o que la gente y mercancías salieran despedidas del aparato por sus "endiabladas" velocidades.

Pasada la primera mitad de siglo, el medio siglo siguiente entre 1851 y 1901, conocido con el nombre de "Railway Age" vive el apogeo y reinado definitivo del ferrocarril. Pero la tracción mecánica sobre raíles es sobre todo, obra de Occidente. En 1860 Europa y EE. UU. se reparten más o menos 198 000 en igualdad mientras que el resto del mundo no cuenta con más de 15 000 kilómetros, la mayoría ubicados en colonias europeas. En 1910 ya se han construido más de un millón de kilómetros de los que 380 000 están en EE. UU. y 330 000 en Europa. Su construcción necesitó de un esfuerzo enorme, movilizando grandes cantidades de capital, trabajadores y estimulando la industria metalúrgica y la construcción de gigantescos talleres de trabajo, además de dar su máximo esplendor a la máquina de vapor.
Además de los vagones y locomotoras, también evolucionaron los raíles sobre los que circulaban. El raíl de acero sustituye al de hierro y a la madera de las traviesas se le empezó a inyectar cloruro de cinc para evitar que se pudriera. El ferrocarril también necesitó de una gran infraestructura que fue necesario desarrollar, como túneles, que se excavaban a costa del sufrimiento obrero a altísimas temperaturas con el uso de perforadoras de aire comprimido y el revestimiento de las galerías con fundición, en sustitución de la madera; La ventilación se lograba con sopladoras. Hay que destacar algunos éxitos entre los que se encuentran el túnel que atraviesa el Mont Cenis, construido a lo largo de 15 años y con una extensión de 13 600 m a 1300 metros de altura. Otros como el San Gotardo de más de 15 000 metros se terminaron en menos de 10 años usando la perforadora automática siendo las condiciones de trabajo nefastas: los obreros llegaron a trabajar a una temperatura de 86 grados. Fuera de Europa los estadounidenses construyeron un túnel bajo el río Hudson. Escandinavia queda unida a Alemania a través del "ferry-boats" entre Rügen y Malmoe.
Mientras que en la primera mitad de siglo la locomotora apenas había ganado en velocidad sin sobrepasar nunca los 40 km/h, hace progresos decisivos a partir de la idea del ingeniero inglés Crampton de colocar las ruedas motrices detrás de la caldera (y no debajo), ruedas que están acopladas, transfiriéndose el movimiento de rotación. En 1850 la velocidad media que se situaba en 27 km/h se eleva en 1880 a 74 km/h en Inglaterra y a 59 km/h en Estados Unidos. En 1890 el "Empire-State-Express" rebasó por primera vez en la historia los 100 km/h entre Nueva York y Búfalo. Para cruzar Francia de un extremo en ferrocarril solo se precisaban 14 horas. En esta segunda parte del siglo el coste del billete disminuyó entre un 50 y un 70 %.

Las prestaciones de la locomotora aumentaron sin cesar. El freno de mano se sustituyó por un nuevo freno hidráulico de aire comprimido. Los vagones de pasajeros fueron dotados de alumbrado de gas a base de aceite de esquisto o iluminación eléctrica a finales de siglo, siendo la línea Londres-Brighton la primera en incorporarla. La máquina de vapor, el corazón de la máquina, también procura calefacción en los vagones. El llamado "Boggie" o bastidor de varios ejes permitió al convoy dar curvas mucho más acentuadas disminuyendo los riesgos, pues se adaptaba a la curvatura de la vía. También se crearon los llamados "palace-cars" en las líneas más largas para las familias ricas en las que disfrutaban de todo tipo de comodidades y sin tener que mezclarse con el resto de pasajeros. En 1880 se instaló en la línea del Pacífico un vagón imprenta en el que se editaba un periódico diario con las noticias recibidas telegráficamente en las estaciones.
Exceptuando Gran Bretaña, Bélgica y algunas partes de España y Alemania, las vías férreas no dibujaban redes en ninguna parte antes de 1860. En Francia por fin se realizó un esfuerzo serio a partir del Segundo Imperio y en los albores de la Tercera República. En esta segunda mitad de siglo se empezaba a vislumbrar la columna vertebral de ferrocarriles europeos. Sus límites se extendían desde el norte de Francia hasta la Alta Silesia de este a oeste y de Alemania al norte de Italia de norte a sur; en el centro, Suiza reparte el tráfico por el continente. En cambio la mayor parte de Italia, la península ibérica y los países del este quedaban fuera. En Estados Unidos se siguen consiguiendo grandes logros. En 1869 se finalizó el primer transcontinental que conectó el país de este a oeste. La construcción fue dirigida por el implacable general Grenville M. Dodge como si se tratará de una campaña militar. Usó como mano de obra a los soldados desmovilizados, inmigrantes irlandeses y hasta chinos en California. Pero este triunfo no se logró con facilidad; indios, el relieve irregular y sobre todo la competencia entre Union Pacific y Central Pacific dificultaron sobremanera la situación. Pero el entusiasmo predomina y en 1893 ya había en funcionamiento otras 5 líneas transcontinentales, usándose como medio de colonización en el oeste americano o en la Columbia británica como medio de presión para conseguir su adhesión a la Unión.

Aunque tardío, se presenta el esfuerzo ruso, logrado gracias a los préstamos de Occidente. En primer lugar se construyó el transcaspiano al que a partir de 1905 complementó el transaraliano. En Siberia las dificultades eran mayúsculas: hielo, infiltraciones de agua, ríos inmensos, débil densidad humana, distancias enormes, sin olvidar el irregular relieve. Pero las viejas rutas y caminos ya no eran suficientes y el ferrocarril más largo del mundo se empezó en 1891 y alcanzó su destino, Vladivostok, gracias a un acuerdo con China, en 1902.

Así pues el ferrocarril no solo sirvió para revolucionar el mundo del transporte tanto material como humano sino que fue empleado como un excelente instrumento de unión. Sirvió bien en la reconciliación y la anexión de nuevos territorios a Estados Unidos y el Imperio alemán sabía lo mucho que le debía al ferrocarril como para dejarlo en manos privadas. En Italia facilitó la hegemonía de la Casa de Saboya. No ocurrió igual en Francia o en Gran Bretaña, donde se encontraban mayoritariamente en manos privadas, aunque en Inglaterra prestaron un servicio inigualable, encumbrando al naciente Imperio británico a la hegemonía mundial. Hacia 1850 el ferrocarril había conducido a entre 400 y 500 millones de viajeros y entre 200 y 300 millones de toneladas de mercancías desde su nacimiento. Cinco décadas después, solo en 1905 transportó a entre 4000 y 5000 millones de viajeros.

Antes del siglo XIX la larga tradición naval europea se había sustentado sobre el control de los vientos como medio de propulsión y la seguridad más que por la velocidad en el mar. A principios de siglo no se empleaban menos de dos o tres semanas en cruzar el Atlántico de este a oeste, necesitándose entre 30 y 40 días de oeste a este. Con la formación de los imperios coloniales europeos se hizo necesario desarrollar una tecnología que asegurase el viaje sobre las aguas; en el siglo XVIII se generalizó el uso del sextante, mapas con las notaciones de los vientos y el cronómetro. La invención de la nueva embarcación partió de los trabajos de Jouffroy d´Abbens sobre el Sena y los de Fulton con su máquina "Clermont". Fue en Estados Unidos donde tuvieron lugar las primeras pruebas del navío de ruedas sobre el río Hudson. En 1815 ya circulaban un centenar de estos navíos de ruedas que obtenían su energía de la leña, material barato y abundante. El "Savannah" consiguió cruzar en 29 días el Atlántico Norte en 1819 y la "Sphink", que llevó a Francia las noticias de la toma de Argel, desarrollaba una velocidad de 6 nudos. Pero los problemas eran numerosos: las paletas utilizadas provocaban un gran desperdicio de energía, existía el riesgo de incendio o explosión a bordo, su velocidad era aún menor a la desarrollado por los veleros y el poder militar aún se oponía a su utilización como navío de guerra.

Pero a pesar de las dificultades los avances prosiguieron y en 1838, con una combinación de vapor y velas, los navíos "Sirius" y "Great Western" cruzaron el Atlántico entre Liverpool y Nueva York en 16 y 13 días respectivamente. Los grandes avances llegaron entre 1840 y 1860 con la invención de la hélice, basándose los primeros modelos en el tornillo de Arquímedes, el condensador de superficie y la máquina "Compound", que logró ahorrar grandes cantidades de combustible y la introducción de calderas cilíndricas que posibilitaron la producción de vapor a alta presión.

Lo que sí es indudable es la supremacía del velero sobre el vapor durante la mayor parte del siglo; la seguridad y prestigio de la que aún gozaba, sobre todo en Estados Unidos, donde también tenía lugar la mayoría de los avances del barco de vapor era indiscutible. En 1850 el barco de vapor había transportado ya 750 000 toneladas, aunque el vapor aún estaba muy lejos de ganar la partida.

El esfuerzo en la construcción y mejora de carreteras (o caminos) comenzó en muchas partes de Europa antes de la Revolución Industrial. Desde el fin de las guerras napoleónicas a principios del siglo XVIII y en ausencia de otros medios de comunicación más eficaces, las carreteras fueron extensamente mejoradas. A principios del siglo XIX el país más adelantado en esta materia era Francia con una red de 33 000 kilómetros de gran calidad que se extendían hasta Alemania, Suiza e Italia. Los Países Bajos, el Reino de Prusia o Suiza también habían vivido una gran mejora en las comunicaciones. En el otro extremo se encontraban lugares como Sicilia, que no empezó su construcción hasta bien entrado el XIX, la Rusia zarista, que no tendría su primera calzada entre Moscú y San Petersburgo —sus principales ciudades— hasta 1834 o España, que cuenta antes de la mitad del siglo XIX con solo 6000 kilómetros de vías, siendo además estrechas y llenas de irregularidades y deficiencias. En Gran Bretaña el rápido desarrollo de ferrocarriles y canales quita importancia a su construcción pero aun así se suceden las ampliaciones y modernizaciones de la maltrecha red británica contando en 1850 con más de 50 000 kilómetros de trazado, 18 000 más que veinte años atrás.

La técnica en la construcción de estas vías de comunicación también mejora. En cada país se construyen de manera distinta pero los problemas "clásicos" derivados de estas construcciones como filtraciones de agua, mantenimiento o infraestructura se solucionan en las décadas de 1820 y 1830 a partir de las mejoras introducidas por Mac Adam o Telford. El uso de la diligencia y los servicios públicos de transporte se desarrollan y generalizan con unas velocidades que oscilan entre los 10 y 15 km/h, usándose en el transporte de pasajeros, mercancías y correo. No es hasta principios del siglo XX cuando gracias al motor de explosión y el desarrollo del automóvil se de un uso masivo a estos trazados.

Los primeros canales empezaron a ser construidos en Gran Bretaña en el siglo XVIII con el objeto de comunicar los centros industriales del norte británico con los puertos marítimos del sur y Londres. Los canales fueron la primera tecnología que permitió un fácil y relativamente rápido transporte de mercancías por todo el país, pudiéndose transportar varias docenas de veces más de tonelaje por viaje que con un transporte terrestre. A esto se unía el relieve del país, completamente llano, lo que permitía que los canales fueran construidos rápidamente y a un bajo precio. A principios de la década de 1820, ya existía una red nacional consolidada. El ejemplo inglés fue copiado en Francia que con un relieve similar al británico pudo desarrollar su propio sistema, que a mediados del siglo XIX contaba con 8500 kilómetros de vías. En Alemania gracias a sus grandes ríos como el Rín y el Elba, la navegación se vio muy favorecida, así como el comercio que vivió un gran desarrollo. En otros países como España la construcción de canales no pasó de un proyecto por el difícil relieve y la falta de capitales. Fuera del continente, los estadounidenses con su ímpetu emprendedor y sus numerosos lagos y grandes ríos consiguieron desarrollar con velocidad su propio sistema, que al igual que el ferrocarril, ayudó en la colonización y explotación de las vastas tierras del país. A principios de 1835 EE. UU. ya contaba con 7000 kilómetros de canales que allanaron el camino a la introducción del barco de vapor en el país con una rapidez incluso mayor a la siempre innovadora Gran Bretaña.

El uso de los canales en Gran Bretaña empezó a decaer a partir de 1840, cuando el ferrocarril se impuso en el transporte de mercancías y pasajeros. El irregular y más tardío desarrollo a gran escala del ferrocarril en el resto de países, con la siempre notable excepción de los Estados Unidos, alargó en ocasiones el uso pleno de los canales hasta los albores del siglo XX. Hoy en día la red de canales británicos y la infraestructura ligada a esta es una de las características más perdurables y destacables de la Revolución Industrial en el país.

La existencia de controles fronterizos más intensos evitaron la propagación de enfermedades y disminuyó la propagación de epidemias como las ocurridas en tiempos anteriores. La revolución agrícola británica hizo además más eficiente la producción de alimentos con una menor aportación del factor trabajo, alentando a la población que no podía encontrar trabajos agrícolas a buscar empleos relacionados con la industria y, por ende, originando un movimiento migratorio desde el campo a las ciudades así como un nuevo desarrollo en las fábricas. La expansión colonial del siglo XVII acompañada del desarrollo del comercio internacional, la creación de mercados financieros y la acumulación de capital son considerados factores influyentes, como también lo fue la revolución científica del siglo XVII. Se puede decir que se produjo en Inglaterra por su desarrollo económico.

La presencia de un mayor mercado doméstico debería también ser considerada como un catalizador de la Revolución Industrial, explicando particularmente por qué ocurrió en el Reino Unido.

La invención de la máquina de vapor fue una de las más importantes innovaciones de la Revolución industrial. Hizo posible mejoramientos en el trabajo del metal basado en el uso de coque en vez de carbón vegetal. En el siglo XVIII la industria textil aprovechó el poder del agua para el funcionamiento de algunas máquinas. Estas industrias se convirtieron en el modelo de organización del trabajo humano en las fábricas.

Además de la innovación de la maquinaria, la cadena de montaje (fordismo) contribuyó mucho en la eficiencia de las fábricas.

La Revolución Industrial estuvo dividida en dos etapas: la primera del año 1750 hasta 1840, y la segunda de 1880 hasta 1914. Todos estos cambios trajeron consigo consecuencias tales como:


A mediados del siglo XIX, en Inglaterra se realizaron una serie de transformaciones que hoy conocemos como Revolución Industrial dentro de las cuales las más relevantes fueron:

La industrialización que se originó en Inglaterra y luego se extendió por toda Europa no solo tuvo un gran impacto económico, sino que además generó enormes transformaciones sociales.

Proletariado urbano. Como consecuencia de la revolución agrícola y demográfica, se produjo un éxodo masivo de campesinos hacia las ciudades; el antiguo agricultor se convirtió en obrero industrial. La ciudad industrial aumentó su población como consecuencia del crecimiento natural de sus habitantes y por el arribo de este nuevo contingente humano. La carencia de habitaciones fue el primer problema que sufrió esta población socialmente marginada; debía vivir en espacios reducidos sin comodidades mínimas y carentes de higiene. A ello se sumaban jornadas de trabajo, que llegaban a más de catorce horas diarias, en las que participaban hombres, mujeres y niños con salarios miserables, y carentes de protección legal frente a la arbitrariedad de los dueños de las fábricas o centros de producción. Este conjunto de males que afectaba al proletariado urbano se llamó la "Cuestión social", haciendo alusión a las insuficiencias materiales y espirituales que les afectaban.

Burguesía industrial. Como contraste al proletariado industrial, se fortaleció el poder económico y social de los grandes empresarios, afianzando de este modo el sistema económico capitalista, caracterizado por la propiedad privada de los medios de producción y la regulación de los precios por el mercado, de acuerdo con la oferta y la demanda.

En este escenario, la burguesía desplaza definitivamente a la aristocracia terrateniente y su situación de privilegio social se basó fundamentalmente en la fortuna y no en el origen o la sangre. Avalados por una doctrina que defendía la libertad económica, los empresarios obtenían grandes riquezas, no solo vendiendo y compitiendo, sino que además pagando bajos salarios por la fuerza de trabajo aportada por los obreros.

Las propuestas para solucionar el problema social. Frente a la situación de pobreza y precariedad de los obreros, surgieron críticas y fórmulas para tratar de darles solución; por ejemplo, los socialistas utópicos, que aspiraban a crear una sociedad ideal, justa y libre de todo tipo de problemas sociales (para algunos, el comunismo). Otra propuesta fue el socialismo científico de Karl Marx, que proponía la revolución proletaria y la abolición de la propiedad privada (marxismo); también la Iglesia católica, a través del papa León XIII, dio a conocer la Encíclica "Rerum Novarum" (1891), primera encíclica social de la historia, la cual condenaba los abusos y exigía a los estados la obligación de proteger a lo más débiles. A continuación, un fragmento de dicha encíclica: Estos elementos fueron decisivos para el surgimiento de los movimientos reivindicativos de los derechos de los trabajadores. Durante el siglo XX en medio de los procesos de democratización, el movimiento obrero lograba que se reconocieran los derechos de los trabajadores y su integración a la participación social. Otros ejemplos de tendencias que buscaron soluciones fueron los nacionalismos, así como también los fascismos en los cuales se consideraban a los obreros y trabajadores como una parte fundamental en el desarrollo productivo de la nación, por lo que debían ser protegidos por el Estado.

Uno de los principios fundamentales de la industria moderna es que nunca considera a los procesos de producción como definitivos o acabados. Su base técnico-científica es revolucionaria, generando así el problema de la obsolescencia tecnológica en períodos cada vez más breves. Desde esta perspectiva puede afirmarse que todas las formas de producción anteriores a la industria moderna (artesanía y manufactura) fueron esencialmente conservadoras, al trasmitirse los conocimientos de generación en generación sin apenas cambios. Sin embargo, esta característica de obsolescencia e innovación no se circunscribe a la ciencia y la tecnología, sino debe ampliarse a toda la estructura económica de las sociedades modernas. En este contexto la innovación es, por definición, negación, destrucción, cambio, la transformación es la esencia permanente de la modernidad.

El desarrollo de nuevas tecnologías, como ciencias aplicadas, en un receptivo clima social, es el momento y el sitio para una revolución industrial de innovaciones en cadena, como un proceso acumulativo de tecnología, que crea bienes y servicios, mejorando el nivel y la calidad de vida. Son básicos un capitalismo incipiente, un sistema educativo y espíritu emprendedor. La no adecuación o correspondencia entre unos y otros crea desequilibrios o injusticias. Parece ser que este desequilibrio en los procesos de industrialización, siempre socialmente muy inestables, es en la práctica inevitable, pero mensurable para poder construir modelos mejorados.






</doc>
<doc id="17533" url="https://es.wikipedia.org/wiki?curid=17533" title="Segunda Revolución Industrial">
Segunda Revolución Industrial

El término de Segunda Revolución Industrial designa el conjunto de transformaciones socioeconómicas interrelacionadas que se produjeron aproximadamente entre 1880 hasta 1914. Durante este periodo los cambios se aceleraron fuertemente. El proceso de industrialización cambió su naturaleza y el crecimiento económico varió de modelo. Los cambios técnicos siguieron ocupando una posición central, junto a los ocurridos en los mercados, en su tamaño y estructura. Las innovaciones técnicas concentradas esencialmente, en nuevas fuentes de energía como el gas, el petróleo o la electricidad; nuevos materiales y nuevos sistemas de transporte (avión y automóvil) y comunicación (teléfono y radio) indujeron transformaciones en cadena que afectaron al factor trabajo y al sistema educativo y científico; al tamaño y gestión de las empresas, a la forma de organización del trabajo, al consumo, hasta desembocar también en la política.

Este proceso se produjo en el marco de la denominada Primera globalización que supuso una creciente internacionalización de la economía, que cada vez funcionaba más a escala mundial y que alcanzó más territorios que la primera revolución, que se había limitado a Gran Bretaña, alcanzando ahora casi toda Europa Occidental, Estados Unidos y Japón.

Entre los cambios sucedidos en los países que vivieron la industrialización durante este periodo, destacan los siguientes: 

El título de segunda revolución industrial originariamente hacía referencia a la segunda revolución técnica experimentada en el proceso de industrialización, aunque hoy ha rebasado este ámbito para designar el conjunto de transformaciones que caracterizan a esta nueva fase del proceso.

No existe una única definición para el término "revolución industrial" y pueden atribuirse varios significados al término según el enfoque y el contexto en el cual se expresa. Según David Landes existen por lo menos tres acepciones o modos de uso del término: a) el que hace referencia al conjunto de innovaciones tecnológicas que sustituyen la habilidad humana por maquinaria y la fuerza animal por energía provocando el paso de la producción artesanal a la fabril; b) aquel que se utiliza para remarcar un cambio tecnológico rápido e importante en algún periodo histórico determinado o como secuencias de innovaciones determinadas; y c) hace referencia específica al periodo del siglo XVIII en el cual se da un cambio económico y social al pasar de una producción agraria y artesanal a otra mecanizada o industrial iniciada en Inglaterra y expandida desigualmente a Europa continental.

El proceso de cambio técnico durante la Segunda Revolución Industrial constituyó uno de los más trascendentales cambios desde el punto de vista histórico, cuando las innovaciones tecnológicas adquirieron el carácter de modernidad, que sentó las bases tecnológicas del siglo XX y se distanció de las bases de la primera revolución.

La ciencia y la tecnología en este periodo se caracterizó por la mayor complejidad de las máquinas y equipos y por una relación más estrecha entre ambas que requirió una mayor cualificación para su implantación, lo que dificultó su difusión. El núcleo del cambio técnico se diversificó hacia más sectores y se amplió geográficamente, hacia toda Europa y Estados Unidos. 
Algunos de esos inventos aparecieron en las décadas de 1850 y 1860, pero las innovaciones más radicales surgieron en el periodo entre 1870 y 1913 en Estados Unidos y Alemania principalmente, en los que se concentró la mayor parte de las invenciones que se desarrollarían posteriormente a lo largo del siglo XX. Todos estos descubrimientos acabaron por conformar un nuevo sistema tecnológico.

El resultado de este nuevo sistema fue la ampliación de los recursos naturales dispuestos, el desarrollo de otras innovaciones tecnológicas complementarias, el ahorro de trabajo que generó un incremento enorme de la productividad, mayores beneficios, salarios más altos, precios de consumo más bajos y una gama de nuevos productos. El nuevo sistema tecnológico, en definitiva, puede considerarse el motor del crecimiento de fines del siglo XIX y del primer siglo XX. 

Se distinguen tres fuentes fundamentales de avance tecnológico en este periodo: 

El hierro seguía siendo el metal más utilizado y sobre él se van a aplicar importantes innovaciones. Thomas en 1878 inventó un sistema para explotar el hierro rico en fósforo, hasta entonces no se habían tenido en consideración estos yacimientos por el carácter quebradizo del metal. El procedimiento Siemens-Martin abarató la obtención de este mismo producto.

Durante la primera revolución industrial el hierro se aplicó casi exclusivamente al ferrocarril, ahora va a encontrar nuevas aplicaciones como la construcción y el armamento. En el terreno constructivo se van a levantar puentes de hierro, estaciones de trenes, mercados, monumentos como la Torre Eiffel en 1889, y sería la base para la construcción de los primeros rascacielos en Chicago al hacer estos edificios con una estructura de hierro.

El acero (aleación de hierro con una pequeña cantidad de carbono) era un metal muy caro de producir y su utilización se limitaba a escasos productos: cuchillería, aparatos de precisión... El panorama cambia al aparecer nuevos procedimientos como el convertidor de Bessemer en 1855 que permitió incrementar la producción de acero a un precio razonable. En el campo armamentístico se utilizará más el acero que el hierro, las nuevas aplicaciones pasan por la construcción de acorazados o submarinos totalmente revestidos de acero.

Durante este periodo el coste de los transportes experimentó un gran descenso que permitió la integración de los mercados hasta entonces muy desconectados, esto se pone de manifiesto, por ejemplo en el precio del trigo en Inglaterra y Estados Unidos, mientras que en 1860 el precio del trigo en Liverpool casi doblaba el del mercado de Chicago; hacia 1915 los precios eran casi iguales. Este abaratamiento impulsó el comercio internacional, la integración de los mercados nacionales e internacionales, la unión de zonas productoras y consumidoras de todo tipo de recursos y las migraciones generalizadas de personas.

El cambio en el ferrocarril fue espectacular y siguió siendo el medio de comunicación terrestre más utilizado. Así, mientras que en 1840 el desarrollo ferroviario era todavía escaso, en Europa solo nueve países habían construido alguna línea ferroviaria, con una red en todo el continente de menos de 4.000 kilómetros y solo cuatro países (Gran Bretaña, Alemania, Francia y Bélgica) que habían superado los 300 kilómetros, en Estados Unidos en esa misma fecha se habían construido 4.510 kilómetros. Treinta años después, en 1870, se había consolidado este medio y se superaban en Europa los 100.000 km de extensión y en Estados Unidos 70.000.

España en 1848, fue el décimo país del mundo en inaugurar una línea ferroviaria, la de Barcelona a Mataró, aunque en 1837 ya había entrado en funcionamiento el ferrocarril entre la Habana y Güines en la Cuba española; a estos les siguió en 1851 la línea entre Madrid y Aranjuez. Se siguieron construyendo vías ferroviarias desde los lugares en los que se había originado (Europa Occidental y noreste de los EE. UU.) hacia lugares más lejanos, creándose así las grandes redes transcontinentales de América del Norte (hacia 1870) y Eurasia (Transiberiano y Orient Express hacia 1900).

El desarrollo del transporte naval fue también muy notable. Por un lado los clípers que llegaban desde Inglaterra hasta el Pacífico y Australia, supusieron el canto del cisne de la navegación a vela. Pero lo más importante fue la aplicación sistemática a los barcos de calderas a vapor de triple y cuádruple expansión mucho más eficientes, la introducción del casco de hierro en 1860 y posteriormente de acero en 1879 y la aplicación de la turbina a vapor en 1894. Estas innovaciones disminuyeron los costes de mantenimiento y funcionamiento de las naves y aumentaron el espacio reservado para las mercancías y los pasajeros. Hacia 1880 también se disminuyeron las tripulaciones y los costes con la desaparición del velamen auxiliar del que disponían todavía los barcos a vapor. Todos estos cambios permitieron reducir los fletes del transporte atlántico en un 45 por ciento.

Durante el siglo XVIII el ritmo de crecimiento de la población europea experimentó un espectacular crecimiento generado por múltiples factores. En primer término, las transformaciones en la producción agrícola; con la incorporación y aplicación de nuevas tecnologías y técnicas que permitieron obtener un mayor rendimiento de los terrenos de cultivo, la introducción de cultivos provenientes del continente americano (papa, maíz), así como la explotación de terrenos cultivables en los continentes colonizados, contribuyeron al aumento de la población al incrementarse la capacidad de producir alimentos. Así mismo, los avances en la medicina produjeron una reducción considerable en las tasas de mortalidad y un incremento sostenido en las tasas de natalidad. De esta manera, entre los siglos XVIII y XIX el continente europeo experimentó un crecimiento espectacular en su población, que pasó de 208 a 430 millones (207%), en el periodo citado.

Los cambios demográficos, así como la rápida urbanización de la población y un excedente de la población activa, como consecuencia de la capacidad productiva de la agricultura impulsados por la Revolución Industrial, motivaron movimientos migratorios de la población europea de gran magnitud hacia países en proceso de industrialización. Además de los anteriores, otro factor que contribuyó a impulsar las corrientes migratorias fue la revolución en el transporte, con la aplicación del vapor en el transporte terrestre y la navegación, a través de los transatlánticos impulsados por turbinas de vapor, que facilitaron el transporte de pasajeros y mercancías, al reducirse de forma considerable el costo y tiempo empleados en los desplazamientos entre Europa y América.
Se calcula que entre el periodo entre 1850 y 1940 se desplazaron cerca de 55 millones de europeos, la mayoría de ellos, se asentaron en los Estados Unidos, país que se convirtió en el principal polo de atracción de emigrantes europeos provenientes de las Islas Británicas, Italia, Alemania, entre otros, aunque los movimientos migratorios también se dirigieron hacia países como Argentina, Brasil y Canadá.

El desarrollo del capitalismo monopolista en la segunda mitad del siglo XIX se produjo en el marco de un nuevo ciclo de expansión general y fue acompañado de un nuevo crecimiento de las fuerzas productivas de varios países. De este modo, el capital se centralizó y la producción se concentró al formarse el monopolio con el acuerdo y unión de capitalistas. Así, los monopolios lograron determinar las condiciones de venta de gran parte de los productos, fijando los precios y obteniendo por ende mayores ganancias. Sin embargo, los monopolios, si bien tendieron a lograr un mayor o mejor control de los mercados, no eliminaron por completo la lucha por la competencia, la cual ocurrió tanto entre las mismas corporaciones monopolistas como entre las empresas que se mantuvieron al margen de los carteles y de los trusts. Por el contrario, la hicieron más violenta tanto a nivel de los mercados internos como de los internacionales. En este escenario, los bancos jugaron un nuevo papel decisivo para la transformación del capitalismo en un fenómeno que caracterizaría a la segunda parte del siglo XIX, así como a la primera del siglo XX: el imperialismo (es decir, los intentos de establecer o mantener una soberanía formal de una potencia determinada sobre otras sociedades subordinadas a esta).

Durante este período, la nación industrial primaria en Europa. Esto ocurrió como resultado de varios factores. Alemania, habiéndose industrializado después de Gran Bretaña, pudo modelar sus fábricas como las de Gran Bretaña, ahorrando así una cantidad substancial de capital, esfuerzo y tiempo. Mientras que Alemania hizo uso de los últimos conceptos tecnológicos, los británicos continuaron utilizando tecnología costosa y anticuada. En el desarrollo de la ciencia y la investigación pura, los alemanes invirtieron más pesadamente que los británicos, especialmente en la industria química. El sistema alemán del cartel (conocido como Konzerne), siendo perceptiblemente concentrado, podía hacer un uso más eficiente del capital fluido. Algunos creen que los pagos de reparación exigidos de Francia después de su derrota en la Guerra Franco-Prusiana de 1870 y 1871 habría proporcionado el capital necesario para permitir inversiones públicas masivas en infraestructura como ferrocarriles. Esto proporcionó un mercado grande para los productos de acero innovadores y facilitó el transporte. La anexión por parte de de las provincias de Alsacia y Lorena, provocó que una parte de la que había sido la base industrial francesa pasase a Alemania. En los Estados Unidos la Segunda Revolución Industrial se asocia comúnmente a la electrificación según lo iniciado por Nikola Tesla, Thomas Alva Edison y George Westinghouse y por la gerencia científica según lo aplicado por Frederick Winslow Taylor.

Si bien, en la Primera Revolución Industrial, Inglaterra se convirtió en la primera potencia económica, durante la Segunda Revolución Industrial esta situación cambió radicalmente con la emergencia de nuevas potencias: Alemania, que a partir de su unificación tuvo un destacado desarrollo económico e industrial, así como los Estados Unidos y Japón.
Por otra parte, Japón a partir de la segunda mitad del siglo XIX, comenzó a seguir un proceso de modernización. La restauración Meiji emprendió una serie de reformas que tenían como propósito romper el aislamiento en que había permanecido el país y eliminar los obstáculos al crecimiento económico impuestos por el régimen de gobierno antecesor, tomando como modelos de referencia a los países occidentales, principalmente los Estados Unidos, que habían ingresado en su territorio. De esta manera, el gobierno Meiji promovió la creación de fábricas para la industria pesada con tecnología importada desde Europa, así como la expansión del poderío militar. Para principios del siglo XX, Japón había logrado consolidar un importante crecimiento industrial despuntado como potencia económica.

El proceso demográfico de Estados Unidos tuvo tres rasgos esenciales que lo caracterizaron. En cuanto a la población, este país no superaba los cuatro millones de habitantes en el primer período; sin embargo la misma se fue duplicando cada 23 años, hasta que en vísperas de la Guerra de Secesión logró alcanzar los 32 millones. No obstante, en el último tercio del siglo se evidenciaría un relativo descenso en dicho crecimiento.



</doc>
<doc id="17534" url="https://es.wikipedia.org/wiki?curid=17534" title="Tercera revolución industrial">
Tercera revolución industrial

La Tercera Revolución Industrial, revolución científico-tecnológica o revolución de la inteligencia (RCT), es un concepto y una fusión esbozados por Jeremy Rifkin y avalados por el Parlamento Europeo, en una declaración formal aprobada en junio de 2006. A lo largo de la historia, las transformaciones económicas ocurren cuando convergen las nuevas tecnologías de la comunicación con los nuevos sistemas de energía. Las nuevas formas de comunicación se convierten en el medio de organización y gestión que las civilizaciones más complejas han hecho posible mediante las nuevas fuentes de energía. La conjunción de la tecnología de comunicación de Internet y las energías renovables en el siglo XXI está dando lugar a la llamada Tercera Revolución Industrial.

La Revolución Industrial fue inicialmente impulsada y promovida por la máquina de vapor; su introducción en la industria transformó el medio en la herramienta que desarrolló y consolidó la llamada Primera Revolución Industrial.

En la primera década del siglo XX, la energía eléctrica convergió con el motor de combustión interna, propulsada por combustibles fósiles, principalmente de derivados del petróleo, dando lugar a la llamada Segunda Revolución Industrial. La electrificación de las fábricas inició entonces la era de la producción masiva de bienes manufacturados, siendo el más importante de ellos el automóvil. Henry Ford comenzó a producir en masa el coche de motor de gasolina Modelo T, alterando la dinámica espacial y temporal de la sociedad, sin perjuicio de la falta de sostenibilidad que iba a ocasionar el transporte individual mediante motor de combustión.

Los Estados Unidos como primera potencia mundial, fue líder en I+D+i y desarrolló las técnicas de producción.
Japón es un líder siguiendo a EEUU en desarrollo e inversión en las nuevas tecnologías.
Antes de la Gran recesión la UE era el máximo inversor en desarrollo sostenible.

La globalización es uno de los aspectos más influyentes en la nueva sociedad y en el comercio internacional y facilitó el desarrollo y la inversión en las tecnologías.



</doc>
<doc id="17535" url="https://es.wikipedia.org/wiki?curid=17535" title="Homotecia">
Homotecia

Una homotecia es una transformación afín que, a partir de un punto fijo, multiplica todas las distancias por un mismo factor. En general una homotecia de razón diferente de 1 deja un único punto fijo, llamado centro.

Se puede considerar a la homotecia una homología particular de eje impropio, con centro en el de homología.

Sea E un espacio vectorial sobre un cuerpo formula_1. Sea X un elemento (visto como un punto) de E. La homotecía de centro C y de razón k, denotada formula_2 envía un punto M del espacio vectorial sobre el punto M' tal que: 

La ecuación anterior puede escribirse también como una transformación afín de la forma:

La anterior relación puede escribirse vectorialmente en el plano como:

Donde: formula_3, formula_4 y formula_5.
En tres o más dimensiones la fórmula anterior se generaliza trivialmente.

La homotecia es una transformación afín, composición de una transformación lineal y una traslación, y por consiguiente conserva:
Cuando K es mayor que cero es k mayor
Cuando el cuerpo de escalares son los Reales, se cumple que:
Más aún: 

En esta sección, los escalares serán números reales.

Una homotecia generalizada en el plano es una transformación del plano en sí mismo en donde una recta y su homóloga son paralelas. De esta definición, se sigue fácilmente que las homotecias conservan ángulos, es decir son transformaciones conformes del plano, que el conjunto de homotecias forman un 'grupo' y que las traslaciones son casos particulares de las homotecias.

Consideremos la homotecia en la cual la recta OA se transforma en la recta O'B, siendo O' el homólogo de O y B el homólogo de A. Necesariamente, las rectas OO' y AB son invariantes en esta homotecia y el punto H1, centro de la homotecia, es invariante. En esta homotecia la circunferencia de centro O y radio OA se transforma en la circunferencia de centro O' y de radio O'B y la razón de la homotecia es la razón (positiva) de los segmentos O'B y OA.

Si por el contrario, el punto A se transforma en B' entonces la recta AB' es invariante y es el punto H2 el centro de homotecia. En este caso, la razón de la homotecia es negativa.

Dadas dos circunferencias, éstas siempre se pueden considerar como homotéticas una de la otra.

En la figura de a lado, las líneas de s1, es en la homotecia de razón positiva, con centro en P1, o de razón negativa, con centro de homotecia en N1.

Consideremos las homotecias, una con centro en P1 en la cual la circunferencia S2 es homotética de la circunferencia s1, y la homotecia de centro P3 en la que la circunferencia s3 es homotética a la circunferencia s2. La composición de estas dos homotecias es la homotecia de centro en P2 que transforma la circunferencia s1 en la circunferencia s3. Es por esta razón que los centros de homotecia positivos, P1, P2 y P3 están alineados.
En general, dadas tres circunferencias existen seis centros de homotecia, alineados tres a tres sobre cuatro rectas.

Estas rectas son las llamadas ejes de homotecia de las tres circunferencias dadas.



</doc>
<doc id="17536" url="https://es.wikipedia.org/wiki?curid=17536" title="Objeto del espacio profundo">
Objeto del espacio profundo

Objeto del espacio profundo (o del cielo profundo) es un término que suele utilizarse en astronomía amateur para referirse a los objetos celestes que no son del Sistema Solar (como los planetas, cometas y asteroides), ni estrellas individuales o sistemas de estrellas múltiples. Normalmente, esos objetos no son visibles a simple vista, pero los más brillantes pueden verse con un pequeño telescopio o incluso con unos binoculares potentes.
Tipos de objetos del espacio profundo:


Están clasificados según el Catálogo Messier de 110 objetos y el Nuevo Catálogo General (NGC), mucho más completo, que contiene cerca de 8.000 objetos. Muchos de estos objetos y otros incluidos en catálogos más especializados como el Catálogo General Uppsala (UGC) les permiten a los astrónomos aficionados demostrar sus dotes de observación y probar sus equipos. Los llamados maratones Messier se celebran durante unos determinados días del año y los observadores tratan de avistar los 110 objetos en una sola noche. Una prueba mucho más exigente basada en la lista "Herschel 400" está diseñada para poner a prueba telescopios mayores.


</doc>
<doc id="17540" url="https://es.wikipedia.org/wiki?curid=17540" title="Derecho romano">
Derecho romano

El término «derecho romano» designa el ordenamiento jurídico que rigió a los ciudadanos de Roma y, posteriormente, a aquellos que se instalaron en distintos sectores de su Imperio, en un espectro histórico cuyo punto de partida se sitúa a la par de la fundación de Roma (753 a.C.) y que se extiende hasta mediados del siglo VI d.C., época en la que tuvo lugar la labor compiladora del emperador Justiniano I, que desde el Renacimiento se conoció con el nombre de "Corpus Iuris Civilis.

El redescubrimiento de los textos justinianos en época bajomedieval ha permitido a algunos autores hablar también de «derecho romano postclásico».

Si bien la expresión «derecho romano» hace referencia fundamentalmente al derecho privado, lo cierto es que otros aspectos, tales como el derecho penal, el derecho público y el derecho administrativo, caben dentro de esta denominación.

En la actualidad, el derecho romano es objeto de estudio de una disciplina jurídica internacional, la romanística, cuya sede son las facultades de derecho de todo el mundo. En virtud de este carácter internacional, el derecho romano se cultiva en varios idiomas, principalmente italiano («lingua franca» de la romanística), seguido por el alemán y el español. Hasta la mitad del siglo XX hubo importantes contribuciones en francés, pero en la actualidad esta situación ha variado a la baja; el inglés es un idioma de uso minoritario en el cultivo de la disciplina, aunque se acepta como idioma científico en la mayoría de las publicaciones. El español se consolidó como idioma científico en esta disciplina a partir de la segunda mitad del siglo XX, gracias a la altura científica que alcanzó la romanística española, comandada por Álvaro d'Ors y continuada por sus discípulos.

La definición del derecho romano se comprende mejor si se construye a partir de la comprensión de sus nociones fundamentales y de su sistema de fuentes. Sin embargo, éstas no permanecen idénticas en el transcurso de la historia del derecho romano, sino que varían tanto en su número, como en su valor dentro del sistema de fuentes mismo. Es este sistema el que provee de nociones claves para entender lo que en Roma se entiende por derecho. Con todo, es posible adelantar que la expresión "ius" es la que se utiliza para señalar al derecho. Esta expresión se opone a la de "fas", que designa a la voluntad divina. Esta clara delimitación entre derecho y religión es patente en testimonios que datan desde el s. III a. C., pero ello no es válido para los primeros tiempos, como se verá. A su vez, la expresión "ius" servirá para la identificación de diversas categorías del mismo, tales como "ius civile", "ius naturale", "ius honorarium", o "ius gentium", por nombrar algunas de las más relevantes.

Al usar la expresión «derecho romano» se pueden indicar diversas acepciones. 

La primera de estas fuentes la constituyen las costumbres de los antepasados o "mos maiorum". Se trata de un derecho consuetudinario, que progresivamente se distingue de las normas morales y religiosas, con las cuales comparte idéntico origen.

Constituyen el "Corpus iuris civilis". Con este nombre se conoce desde la Edad Media la obra compilatoria llevada a cabo por el emperador Justiniano I. En la primera mitad del siglo VI d. C. se adicionan, además, las constituciones imperiales de este emperador posterior a la compilación, las que dan origen a una cuarta parte del "Corpus Iuris Civilis", llamada "Novellæ".

El nacimiento del derecho romano se debe entre otras causas a la división existente en la sociedad romana entre patricios y plebeyos. No obstante, antes del año 451 a. C.-450 a. C., no se conoce la existencia de un sistema unificado para la península, por lo cual es preciso remontarse a la Grecia clásica, considerada la cuna de la civilización occidental, y en particular al llamado periodo ático o del derecho griego ático, de donde se cree que se permearon algunas de las disposiciones que se hallan presentes en la Ley de las XII Tablas.

Las tradiciones legales romanas estaban en manos de los patricios y todos los asuntos relacionados con lo que nosotros conocemos como derecho recaían sobre el "Pontifex Maximus", evidentemente patricio, conociéndose como derecho pontifical. Los plebeyos desconocían como iban a ser juzgados exactamente y normalmente los patricios aplicaban la tradición pontifical según convenía a sus intereses. Por ello, una de las reclamaciones plebeyas, a imagen de lo que había ocurrido en las ciudades del arcaísmo griego, solicitaron la codificación de la tradición en forma de leyes. Para ello, el Senado acordó enviar una comisión a Grecia para informarse sobre las leyes de las ciudades, y después se decidió la abolición de las magistraturas patricias y del tribunado de la plebe, entregando el poder a una comisión de decenviros, que debían codificar las leyes romanas en un período de un año. Esta comisión elaboró X(10) tablas de leyes bastante justas y, por tanto, favorables a los plebeyos, pero, al no estar terminado el trabajo, se nombró una segunda comisión decenviral, mucho más conservadora, que elaboró las dos últimas tablas, con leyes netamente antiplebeyas, que, por ejemplo, prohibían los matrimonios mixtos. Esta comisión intentó perpetuarse en el poder, pero fue depuesta y el sistema de magistraturas empezó a funcionar de nuevo. El resultado fue el primer cuerpo legal conocido y estructurado, llamado Ley de las XII Tablas, del año 451 a. C., y que fueron expuestas públicamente en el Foro Romano.

En el año 367 a. C., las "Leges Liciniæ-Sextiæ" culminaron el proceso de igualación entre patricios y plebeyos, permitiendo el acceso progresivo de estos últimos a las magistraturas y sacerdocios, aunque el primer "Pontifex Maximus" plebeyo tuvo que esperar más de un siglo.

La compilación legislativa se fue realizando de forma acumulativa a través de los Edictos del Pretor. A partir de la Ley de las XII Tablas, los "Pretores" asumieron la función jurisdiccional, y para poder tipificar nuevos casos emitían al inicio de su mandato un Edicto en el que indicaban que era punible, en el que asumían como propios los edictos de pretores anteriores, y corregían o abolían las disposiciones recibidas.

Al principio los pretores eran sólo dos, uno el "Prætor Vrbanus" se dedicaba a juzgar los asuntos en los que participasen ciudadanos romanos, mientras que el otro, el "Prætor Peregrinus", atendía los casos en los que exclusivamente intervinieran no ciudadanos. Los casos tratados eran bastante variados, pero la mayoría derivaban de asuntos comerciales. Así, las relaciones comerciales obligaron a la creación del precedente del llamado derecho contractual, un derecho "ultro citroque obligatio" (que obliga a ambas partes), a partir del cual nace el llamado "Ius Gentium" o derecho de gentes.

El sistema legal romano fue complicándose cada vez más, ya que los Tribunos de la Plebe a través de los "Comitia Tributa" elaboraban Plebiscitos sobre los más variados asuntos, políticos, económicos, jurisdiccionales, mientras que el Senado, a través de las resoluciones llamadas "Senatus Consultum" creaba jurisprudencia.

Con el advenimiento del Imperio, los emperadores asumieron la función de los Tribunos de la Plebe con el ejercicio de la "Tribunicia Potestas", lo que les permitió legislar a través de los Edictos y Constituciones imperiales. Por su parte, los gobernadores provinciales poseían poderes jurisdiccionales y podían emitir leyes propias para sus provincias, pero que podían ser recurridas por los provinciales ante el Senado y/o el Emperador.

El resultado de todo este conjunto de disposiciones fue un enorme y farragoso aparato de leyes de diferentes rangos, muchas veces contradictorias, lo que hizo necesaria la aparición de la figura de los jurisconsultos (o Juristas), que trataban de simplificar el conjunto legal y formar doctrina jurídica, que pudiera aplicarse también a los nuevos casos. Entre ellos destacan Ulpiano, Papiniano, Modestino, Gayo y Paulo.

El primer intento de sistematizar totalmente el derecho se debe al emperador oriental Teodosio II, sucesor de Arcadio. Bajo su patrocinio, se elaboró el "Codex Theodosianus", que a su vez sirvió como base para la creación de derecho en los nuevos reinos germánicos que sucedieron al Imperio romano en occidente. Este código fue reconocido como fuente de derecho por el emperador Honorio, tío de Teodosio II. El "Breviarum Alarici" o "Lex Romana Visigothorum, "elaborada por el rey visigodo Alarico II, es un heredero directo del "Codex Theodosianus."

Sin embargo, el número de disposiciones legales y de casos no contemplados por el "Codex Theodosianus" era elevado, por lo que el emperador Justiniano patrocinó la recopilación de todas las disposiciones en el "Corpus Iuris Civilis", que consta de las "Institutiones" o principios generales de derecho, del "Digesto" o colección de opiniones jurídicas de jurisconsultos heredadas del pasado para la consulta de jueces y magistrados en la resolución de casos, del "Codex Iustinianus" o recopilación de leyes en vigor desde tiempos Republicanos hasta la redacción del Corpus legal de Justiniano, y las "Novellæ", ya en griego, que recogen las leyes emitidas en Bizancio a partir de Justiniano.

El monarca visigodo Recesvinto impulsó una nueva compilación que substituyese al Breviario de Alarico, dando lugar al "Liber Iudiciorum" que en los siguientes reinados fue recibiendo añadidos. Esta compilación fue recuperada a partir del siglo IX por el Reino de León y se convirtió en la base del derecho hispánico hasta las Siete Partidas de Alfonso X El Sabio.

El derecho privado en Roma nace, gracia al pensamiento politico y religioso de la epoca, al igual que el derecho privado, 3d.

1. Derecho antiguo o quiritario del 753 a. C al 450 a. C.
2. Derecho preclásico del 450 a. C al 130 a. C.
3. Derecho clásico del 130 a. C al 230 d. C.
4. Derecho postclásico del 230 d. C al 527 d. C.
5. Derecho justinianeo del 527 d. C al 565 d. C.

Se denomina «derecho romano postclásico» al período de la historia del derecho romano que comprende desde la primera mitad del siglo III hasta la recopilación ordenada por Justiniano, que coincide con el periodo político romano del Dominado o Bajo Imperio (ascensión al poder de Diocleciano en 284 d. C., hasta la muerte de Justiniano en 565).

El derecho romano se difundió a consecuencia de la enseñanza universitaria que comenzó en Bolonia en el siglo XII, y más concretamente gracias a la labor desempeñada por el gramático y jurista Irnerio, cuyo método consistente en hacer breves aclaraciones textuales o glosas y distinciones terminológicas, fue con posterioridad desarrollado de modo progresivo por los denominados Glosadores, entre los que destacan Azón (profesor en Bolonia entre 1190 y 1229) y Acursio (compilador de las glosas de los predecesores en una "Glossa ordinaria"). Sin embargo, no fue hasta la aparición de Bartolo de Sassoferrato (discípulo de Cino da Pistoia y considerado por muchos romanistas como uno de los más influyentes juristas de todos los tiempos) en el siglo XIV, cuando el derecho romano alcanzó un gran prestigio. Bártolo, que a pesar de su corta vida dejó una amplia obra basada en comentarios, tratados monográficos y dictámenes, fue el mayor artífice e impulsor del derecho romano común, que junto con el derecho canónico originó el "utrumque ius", que representa el fundamento de la cultura jurídica europea.

A partir del siglo XIV, Inglaterra presentó una tradición jurídica característica, diferente a la de la romanística en Europa, aunque se asemejaba en mayor medida al modo operativo de los juristas romanos y al desinterés por las pruebas judiciales. La recepción europea del derecho común revistió cierta importancia, aunque fue algo tardía, en Alemania, donde fue objeto de una elaboración científica que recibe el nombre de derecho de "Pandectas".

El Renacimiento trajo consigo la desacreditación del método empleado por Bartolo, consistente en el aprovechamiento de los textos del "Corpus Iuris" como argumentos de autoridad. Pero frente a esta concepción metodológica (el denominado "mos Italicus"), se contrapuso una nueva de tintes eruditos, que trataba de usar los textos del "Corpus Iuris" como fuentes de conocimiento para la reconstrucción de la historia jurídica romana, dentro del marco de otras fuentes, como pueden ser las literarias o las arqueológicas ("mos Gallicus").

El derecho romano se considera un excelente medio de educación jurídica. Los grandes jurisconsultos romanos, principalmente de la época clásica (entre el 130 a. C. y el 230 d. C.) brillaron por su capacidad creadora de nuevas instituciones, con su plasmado pragmático sobre el edicto pretorio, buscando siempre la consecución del ideal de justicia procedente de la filosofía griega del "suum cuique tribuere" (dar a cada uno lo suyo). Leibniz los comparaba con los matemáticos que aplicaban sus principios como fórmulas algebraicas. Asimismo, el derecho romano es indispensable para comprender la historia y literatura romanas, ya que los ciudadanos romanos estaban iniciados para la práctica del derecho y tenían una inclinación natural hacia su estudio.

El derecho romano es la base e inspiración del derecho civil y comercial en muchos países:



El derecho privado de nuestro tiempo tiene su antecedente remoto en este derecho, donde se originaron casi todas las instituciones existentes en la actualidad. En Occidente, la estructura del derecho civil todavía responde a directivas y criterios del derecho romano, con mayor intensidad en los relacionados con la regulación de los derechos patrimoniales, en especial las obligaciones. Son, asimismo, como subraya Antonio Fernández de Buján, múltiples y variadas las enseñanzas que depara el estudio de los principios y normas constitucionales, administrativas, fiscales, penales e internacionales en el ámbito del derecho Público, "ius publicum", romano.

No sucede lo mismo con el derecho de familia, donde la influencia romana es mucho menor, siendo reemplazada por algunas valoraciones indicadas por la Iglesia Católica. También posee poca influencia en las ramas del derecho privado como el derecho comercial, y prácticamente no influye en el derecho penal ni en las demás ramas del derecho público.






</doc>
<doc id="17541" url="https://es.wikipedia.org/wiki?curid=17541" title="Cultura de Canadá">
Cultura de Canadá

Cultura de Canadá es un término que explica los elementos artísticos, musicales, literarios, gastronómicos, políticos y sociales que son representativos de Canadá y los canadienses, no sólo a su propia población, sino a la gente de todo el mundo. La cultura canadiense ha sido históricamente influenciada por la cultura y las tradiciones europeas, sobre todo británicas y francesas, y por sus propias culturas indígenas. Con el tiempo, los elementos de las culturas de las poblaciones de inmigrantes de Canadá se han incorporado a la corriente principal la cultura canadiense. Posteriormente, ha sido influenciada por la cultura estadounidense debido a su lenguaje compartido, la proximidad y la migración entre ambos países.

Canadá se caracteriza a menudo como un país «muy progresista, diverso y multicultural». Las políticas del gobierno de Canadá, tales como: el cuidado de la salud mediante fondos públicos, impuestos más altos y progresivos, prohibición de la pena capital, los grandes esfuerzos para eliminar la pobreza, el hincapié en la diversidad cultural, y más recientemente la legalización del matrimonio entre personas del mismo sexo - son los indicadores sociales de los valores políticos y culturales de Canadá.

El Gobierno Federal de Canadá ha influido en la cultura canadiense con programas, leyes e instituciones. Ha creado empresas de la Corona para promover la cultura canadiense a través de los medios de comunicación, como la «"Canadian Broadcasting Corporation (CBC)"» y el «"National Film Board of Canada (NFB)"», y promueve muchos acontecimientos que considera de promover las tradiciones canadienses. También ha tratado de proteger la cultura canadiense mediante el establecimiento de los mínimos legales de contenido canadiense en muchos medios de comunicación que utilizan los organismos como la Comisión de Radio, Televisión y Telecomunicaciones Canadiense (CRTC).

Por decenas de miles de años, Canadá fue habitado por pueblos aborígenes de una variedad de culturas diferentes y de varios grupos lingüísticas. Las escuelas residenciales pretendían educar a los niños aborígenes para olvidar sus orígenes y les separaban de su familia para que no tuviesen ninguna herencia aborigen y les adoctrinaban a la cultura canadiense y cristiana.

Siendo Canadá un país tan grande, la gastronomía varía según la región y las muchas culturas que han poblado esta parte de Norteamérica. Algunos de los platos son similares a los de otras regiones del continente, aunque algunos son únicos de Canadá o versiones que no se encontrarán en otro país. A pesar de esta variedad, algunas comidas que pudieran ser consideradas como el plato nacional canadiense son el Poutine y el Butter tart. Es importante destacar que Canadá es el productor número uno de jarabe de arce, por lo que muchos platos se distinguen por el uso de dicho producto.

Desde el punto de vista histórico, tres cocinas han sido las que más han influido a la gastronomía canadiense: la de las First Nations, la inglesa y la canadiense. Sin embargo, olas de emigrantes han seguido llegando al país en el último siglo, del resto de Europa, de Asia, de África, del Caribe y de América Latina.


Margaret Atwood (Ottawa, 15 de noviembre de 2015). Escritora canadiense, egresada de las universidades de Toronto, Radcliffe College y Harvard, es una prolífica autora de poesía, novela, crítica literaria y activista política. Ha sido laureada como una de las más eminentes plumas de Canadá, y ha recibido reconocimientos honoríficos a lo largo de su amplia carrera, tanto en su país como a nivel internacional. Atwood, a través de sus textos, ha contribuido al crecimiento en el número de mujeres que se dedican a la literatura, pero también a establecer la legitimidad de la existencia de una literatura canadiense.

Entre sus obras publicadas en español se encuentran "La mujer comestible" (1969), "Resurgir" (1972), "Chicas bailarinas" (1977), "El cuento de la criada" (1985), "El asesino ciego" (2000), "Oryx y Crake" (2003) y "Penélope y las doce criadas" (2005).

Pierre Trottier (Montreal, 21 de marzo de 1925) es un poeta y ensayista canadiense. Realizó estudios clásicos en el Collège Sainte-Marie et Jean-de-Brébeuf donde obtuvo su bachillerato en 1942. Licenciado en derecho por la Universidad de Montreal, trabajó más tarde como jefe de servicio en la Cámara de Comercio del distrito de Montreal desde 1946 hasta 1949 y en el Ministerio de Relaciones Exteriores de Canadá. Ocupó diferentes cargos diplomáticos en Moscú, Yakarta, Londres y París, antes de ser designado embajador de Canadá en Perú desde 1973 hasta 1976. Fue embajador agregado en la Unesco en 1979. Actualmente es, además, miembro del Consejo de redacción de Liberté y colaborador habitual de Cité Libre. Es miembro de la Sociedad Real de Canadá y de la Unión de Escritores de Québec. Premios: «Prix David» por "Les Belles au bois dormant", en 1960, «Prix de la société des gens de lettres» por "Le Retour d'Oedipe", en 1964.



</doc>
<doc id="17542" url="https://es.wikipedia.org/wiki?curid=17542" title="Batalla de Arica">
Batalla de Arica

La batalla de Arica, también conocida como el asalto y toma del morro de Arica ocurrió el 7 de junio de 1880 y fue el último mayor enfrentamiento bélico de la Campaña de Tacna y Arica, durante la Guerra del Pacífico (1879-1883). 

Tras las batallas de Los Ángeles y la del Alto de la Alianza, la batalla por el puerto enfrentó a las fuerzas peruanas bajo el mando del coronel Francisco Bolognesi que quedaban en la ciudad de Arica, aisladas por tierra y sin hinterland, con dos columnas chilenas bajo el mando de Pedro Lagos. Los atacantes lograron vencer los campos de minas, fuertes, fusilería y artillería peruana y ocupar la ciudad. El monitor peruano Monitor Manco Cápac fue hundido por su tripulación tras la derrota de sus fuerzas terrestres.

La caída de Arica significó para Perú la destrucción de su ejército profesional, la pérdida de su base naval y base de operaciones terrestres más austral. Para Bolivia significó el cierre de su salida natural al Pacífico.

Posteriormente a este suceso, se desarrollaron la expedición Lynch, que tuvo como objetivo demostrar al gobierno peruano la futilidad de su resistencia y la Conferencia de Arica, que, bajo los auspicios del gobierno de Estados Unidos, buscaron un acuerdo que pusiera fin a la guerra. Sin embargo, el fracaso de estas negociaciones dio paso a la continuación del conflicto.

Luego de la Batalla del Alto de la Alianza el ejército expedicionario necesitaba un puerto adecuado para su abastecimiento además de eliminar cualquier foco de resistencia. Para ello preparó la captura del puerto de Arica, de rada profunda y protegido de los vientos del sur por el Morro y la isla del Alacrán más una conexión por línea férrea a Tacna y abastecimiento de productos agrícolas de los valles de Azapa y Lluta. Lo más importante era su función como punto de abastecimiento para las fuerzas que controlaban el nudo de comunicaciones peruano-bolivianas que era la región Tacna-Arica. 

Las fuerzas peruanas acantonadas en Arequipa no habían sido movilizadas debido a la desorganización, falta de una jerarquía previamente establecida, carencia de un servicio de transportes y la falta de pertrechos. Finalmente Manuel Segundo Leiva Velasco asumió el mando de cerca de 3000 hombres y se dirigió al sur. El día de la batalla de Tacna, Leiva se encontraba en Torata y continuó hasta llegar a Locumba el 30 de mayo. Ese día recibió noticia desde Arica, que aún tenía comunicación por el cable submarino con el centro de Perú, de la decisión de Bolognesi de resistir y de que solicitaba su apoyo desde el norte.

Leiva no concurrió sino que desde Locumba regresó a Arequipa adonde llegó el 13 de junio. 

Según Jorge Basadre, Bolognesi confiaba en recibir apoyo desde Arequipa, pero tanto Lizardo Montero como Pedro Alejandrino del Solar aseguraron haber intentado transmitirle la orden de destruir los fuertes y retirarse al norte, pero esta no llegó hasta el puerto. De esa manera, las fuerzas peruanas en Arica quedaron aisladas por tierra y bloqueadas por mar. 

La infantería chilena estaba armada con fusiles Comblain y Gras recalibrado a la bala del Comblain, de tal manera que utilizaban el mismo cartucho, mientras que la caballería chilena utilizaba carabinas Winchester Modelo 1866, carabinas Remington y sables.

Todas las fuerzas peruanas estaban armadas con fusiles Chassepot, que utilizaban cartuchos de papel y se trababan después de 50 a 100 tiros. La excepción era el "Artesanos de Tacna" N°29, armado con fusiles Peabody-Martini, y el "Granaderos de Tacna" N°31, armado con fusiles Remington.

El jefe militar de Arica suspuso que el ataque vendría por el norte y ordenó minar las cercanías y fortificar las posiciones que miraban al norte de la ciudad, bajo la dirección del ingeniero Teodoro Elmore. Para la red de minas existía un aparato generador de electricidad en el morro, además de un aparato eléctrico cercano al hospital.

Una vez derrotado el grueso de las fuerzas aliadas, Baquedano ordenó a su caballería reconocer el camino a Arica, lo que se hizo los días 28, 29 y 30 de junio. Acampados en la ribera del Río Azufre, los destacamentos tomaron contacto con la flota que aún bloqueaba Iquique. La línea férrea que había sido parcialmente inutilizada por los aliados fue reparada por los pontoneros chilenos y se envió más caballería a la zona.

Durante la aproximación, una patrulla chilena se vió envuelta en una escaramuza con tiradores peruanos apostados en la ribera sur del Azufre y al día siguiente, el 2, murieron dos soldados chilenos al estallar una mina cuando descndían al río. En esa ocasión se capturó a los ingenieros Teodoro Elmore y Pedro Ureta, que habían instalado las minas y con ellos, la información sobre la ubicación de los "polvorazos".

El 1 de junio, el escuadrón Carabineros de Yungay se aproximó a Chacalluta, siendo capturados los ingenieros Teodoro Elmore y Pedro Ureta después de inutilizar el ferrocarril del lugar usado por los chilenos. Ese mismo día, desertó de las fuerzas peruanas el coronel Agustín Belaúnde, jefe del batallón "Cazadores de Piérola" y uno de los que acordaron resistir hasta el final en el consejo de guerra, siendo declarado traidor a la patria.

El 2 de junio comenzaron a llegar las fuerzas chilenas por ferrocarril, ocupando Chacalluta y el valle de Azapa.

Durante todo el día y la noche del 4 de junio, los chilenos ubicaron la artillería de campaña a cargo de los mayores Salvo, Frías y Montoya. Para ese día, se habían concentrado en el puente del ferrocarril Tacna-Arica los regimientos "Buin", "3.º de Línea", "4 de Línea", "Lautaro" más las unidades batallón "Bulnes", "Carabineros de Yungay", "Cazadores a Caballo" y 4 baterías de artillería. La noche del 4 de junio, se instalaron las baterías chilenas en los cerros al este del Morro de Arica.

El 5 de junio, después de que el mayor Salvo regresara de parlamentar con Bolognesi, la artillería chilena ubicada en Chacalluta y Azapa inició el fuego a las 9:00 horas con las defensas peruanas de las Baterías del Norte y del Este. El enfrentamiento entre la artillería chilena y las baterías peruanas se prolongó hasta las 13:00 horas sin obtener resultados para ambos bandos.

El 6 de junio a mediodía, se inició el bombardeo chileno desde las baterías de tierra así como por el mar por los buques "Loa", "Covadonga", "Magallanes" y "Cochrane". Las defensas peruanas utilizaron las Baterías Norte, las Baterías del Morro, las Baterías del Este y los cañones del monitor "BAP Manco Cápac". A las 16:00 cesó el combate.

El "Cochrane" recibió un impacto de un cañón Voruz de las baterías del morro, justo en el momento en que se cargaba un cañón de avancarga con un saquete de pólvora, que lo hizo explotar provocando 27 heridos, de los cuales murieron 7 posteriormente. La "Covadonga" recibió dos impactos y fue retirada a remolque por la "Magallanes".

Es importante resaltar la figura del comandante Juan Guillermo Moore (ex-capitán de la Fragata Independencia") como encargado de la baterías del Morro.

La batería peruana "San José" atacó, sin resultados, al regimiento "Lautaro" y a una compañía del regimiento "Buin 1.º de Línea", que había llegado a los restos del naufragado buque Wateree por el Norte practicando un reconocimiento. Este movimiento hizo creer al coronel Bolognesi que el ataque chileno vendría por ese sector y lo reforzó enviando la 8.ª división al mando de Alfonso Ugarte. 

Los disparos peruanos fueron: Baterías del Morro, 40; Baterías del Norte, 21; Baterías del Este, 5; y monitor Manco Cápac, 5, totalizando 71. Los disparos chilenos fueron: artillería de tierra, 186; Cochrane, 19; Magallanes, 28; Covadonga, 27; y Loa, 12, totalizando 272.

En la tarde del 6 de junio, el coronel chileno Pedro Lagos envió al ingeniero peruano Teodoro Elmore, quien estaba prisionero, para que hablara con el coronel Bolognesi y pedirle la rendición. Bolognesi descalificó a Elmore como parlamentario. Elmore explicó al coronel peruano Marcelino Varela que el ataque chileno sería por el este. En esos mismos momentos, Lagos alistaba su tropa para el ataque. Elmore regresó al campamento chileno a las 23.

Las fuerzas chilenas se dispusieron de la siguiente manera: el regimiento "4.º de Línea" atacaría la batería "Este", el regimiento "3.º de Línea" haría lo propio con la batería "Ciudadela", ambas baterías del frente Este. Tomadas esas dos posiciones, ambos regimientos esperarían al regimiento "Buin 1.º de Línea" que marchaba a retaguardía, para que juntos atacaran la meseta del morro. El "Lautaro" atacarían los fuertes "San José", "Santa Rosa" y "Dos de Mayo", en el frente norte. La artillería debía cooperar desde sus posiciones en las alturas del este y el batallón "Bulnes" debía protegerla. La caballería tenía la misión cuidar los pasos por donde los peruanos podían retirarse. Los movimientos de las fuerzas chilenas hacia las baterías del este empezaron a las 5:00 horas.

El 7 de junio, el combate se inició por el sector de las baterías del Este a las 5:30 de la mañana, cuando aún todo estaba en oscuridad.

El despliegue del "3.º de Línea" fue avistado por los centinelas de la batería "Ciudadela" a las 6:00 horas, rompiéndose los fuegos incluso antes de ordenarlo los comandantes. En el camino, se detonaron dos minas pero ocasionaron pocos daños y apenas detuvo el avance del "3.º de Línea". Cuando llegó la primera ola de atacantes, tras una lluvia de balas, las fuerzas defensoras lograron contenerlas mediante un movimiento coordinado de fusilería, explosión de minas y bayonetas. Se ordenó una segunda oleada sobre las posiciones peruanas. Las reducidas fuerzas defensoras fueron finalmente aplastadas por los chilenos que entraron por cientos en la batería. El subteniente chileno José Ignacio López capturó la bandera peruana. En la lucha murieron casi todos los defensores, entre los que destacaron el coronel Justo Arias y Aragüez, jefe del batallón "Granaderos de Tacna"; el teniente coronel Francisco Cornejo, jefe del batallón "Cazadores de Piérola", el sargento mayor Felipe Antonio de Zela, 2.º jefe del "Granaderos de Tacna"; el sargento mayor Genaro Vizcarra, 2.º jefe del "Cazadores de Piérola", entre otros. El cabo peruano Alfredo Maldonado, de 16 años, hizo volar la santabárbara de la batería y en la explosión murieron él, los pocos sobrevivientes heridos a su alrededor y varios chilenos —entre estos últimos, uno de los tres oficiales que izaban la bandera— que habían entrado en la batería "Ciudadela".

Mientras esto acontecía, desde el fuerte "Este" se vio aproximarse al "4.º de Línea", encabezado por el 1º batallón de este regimiento al mando del teniente coronel Juan José San Martín y el 2º batallón al mando del mayor Luis Solo Zaldívar. Se ordenó que medio batallón del "Artesanos de Tacna" abriera fuego y el otro medio batallón les hiciera frente. En la lucha en la batería murió el coronel José Joaquín Inclán, comandante general de la 7.ª división peruana, y el teniente coronel Ricardo O'Donovan, jefe del Estado Mayor de la 7.ª división, quedando herido el coronel Marcelino Varela, jefe del batallón "Artesanos de Tacna". Esta vez la defensa tuvo tiempo y logró una retirada ordenada hacia Cerro Gordo.

Entre tanto, el regimiento "Lautaro", comandado por el coronel Orozimbo Barbosa, avanzaba sobre las Baterías del Norte defendidas por 96 artilleros al mando del teniente coronel Ayllón. Estas baterías y el monitor "Manco Cápac" abrieron fuego sobre el "Lautaro", el que, sin embargo, continuó avanzando y respondió el fuego. La resistencia peruana en este frente fue poco enérgica ya que sus defensores dejaron de hacer fuego y se retiraron al morro, no sin antes volar las Baterías "San José", "2 de Mayo" y "Santa Rosa". 

Los regimientos "3.º" y "4.º de Línea" al haberse apoderado de los fuertes del "Este" y "Ciudadela", no detuvieron su avance para esperar al regimiento "Buin 1.º de Línea" como se había planificado. Esto se debería a que en las filas del "4.º de Línea" se oyó un grito que decía: "¡ Al Morro muchachos !", lo que habría hecho a las tropas olvidar la orden recibida y se precipitaran hacia el morro. El "Buin" les seguía un poco más atrás, pero no lograría participar en las acciones. 

Cuando se inició el asalto a las baterías del "Este", Bolognesi percibió que el ataque no sería desde el norte sino desde el este y ordenó que la 8.ª división peruana se dirigiera al Morro. En cerro Gordo se reagruparon con parte del batallón "Artesanos de Tacna" y resistieron el ataque chileno, principalmente del "4.º de Línea". Los artilleros de la batería baja del morro dispararon sobre las fuerzas chilenas que estaban en las baterías del "Este", bombas y tarros de metralla. Medio batallón del "Iquique Nº 33" y otro medio batallón del "Tarapacá Nº 23" quedaron también en Cerro Gordo intentando resistir el ataque chileno mientras el resto subió al Morro.

En el morro, el coronel Bolognesi intentó hacer volar las minas en la cima, pero el mecanismo no funcionó. Los artilleros de la batería baja del morro se retiraron a la cima, haciendo volar uno de sus cañones. Una vez en la cima del Morro los atacantes, enfurecidos por el uso de minas que consideraban formas desleales de combate, desataron un feroz ataque sin dar cuartel a los defensores y que solo difícilmente pudo ser contenido por los oficiales chilenos. Fue en ese momento de la lucha en el morro que murieron el teniente coronel Ramón Zavala, jefe del batallón "Tarapacá Nº 23", y el teniente coronel Benigno Cornejo, segundo jefe de ese batallón, quedando herido en un brazo el teniente coronel Roque Sáenz Peña. Luego murieron, cuando estaban reunidos los oficiales y jefes peruanos, el coronel Bolognesi, comandante general de Arica y el capitán de navío Juan Guillermo Moore, jefe de las baterías del Morro. Los peruanos lograron hacer volar dos cañones Parrott de las baterías del Morro y en el asta murió el sargento mayor Armando Blondel.

Finalmente, el "4.º de línea" tomó a las 7:30 el morro —donde murió su comandante, el teniente coronel Juan José San Martín— y se mandó izar la bandera chilena, por el capitán del 4.º de línea, Ricardo Silva Arriagada.

El capitán de fragata José Luis Sánchez Lagomarsino al ver izada la bandera chilena en el morro, echó a pique el monitor "Manco Cápac" cerca de la isla del Alacrán para evitar que cayera en manos chilenas; el buque se terminó de hundir a las 8:00 y su tripulación fue capturada por la escuadra chilena.

La lancha torpedera "Alianza" rompió el bloqueo y logró escapar al norte. La lancha fue perseguida por los buques chilenos "Cochrane" y "Loa", hasta que la tripulación de la lancha varó su embarcación y la hizo volar en cabo Picata por la tarde. Al día siguiente, los tripulantes fueron capturados cerca de Moquegua.

En medio del caos inicial de la ocupación de Arica, soldados chilenos que bajaron del Morro fusilaron a prisioneros peruanos a las puertas de la iglesia de la ciudad (hospital de campaña durante el combate) Esto solo pudo ser contenido cuando las fuerzas del "Lautaro" y del "Bulnes" entraron a la ciudad y pusieron orden.

William Sater calcula las bajas peruanas entre 700 a 900 muertos, 354 heridos y 1300 prisioneros. Los chilenos sufrieron 474 muertos y 354 heridos

Asimismo, más de 300 cadáveres de combatientes peruanos fueron arrojados al mar desde la cima del morro, los que permanecieron días en descomposición sin ser enterrados con el peligro de extender enfermedades.

Las naves de guerra chilenas no tuvieron participación en la batalla, según Ekdahl la elevación de Morro y la forma de asaltar impidió el uso de sus cañones.

Tampoco la caballería chilena pudo tomar parte en la batalla.

Ekdahl rinde admiración a Bolognesi y sus oficiales por la firmeza y la resolusión con que lucharon.

Los chilenos tomaron 1200 fusiles de diferentes sistemas y 13 cañones: un Vavasseur de a 250 pdr, dos Parrott de a 100 pdr, siete Voruz de a 68 pdr y un cañón de bronce de a 12 lb, que no fue utilizado en las acciones bélicas.

El 7 de junio se celebra el Día de la Bandera en el Perú y el Día de las Glorias de la Infantería en Chile y es feriado en la Región de Arica y Parinacota.



</doc>
<doc id="17544" url="https://es.wikipedia.org/wiki?curid=17544" title="Emilio Portes Gil">
Emilio Portes Gil

Emilio Cándido Portes Gil (Ciudad Victoria, Tamaulipas; 3 de octubre de 1890 – Ciudad de México; 10 de diciembre de 1978). Fue Presidente de México de 1928 a 1930.

Nació en Ciudad Victoria, en el estado de Tamaulipas, el día 3 de octubre de 1890. Sus progenitores fueron Domingo Portes y la señora Adelaida Gil, nacida en la ciudad de La Vega (República Dominicana). Vivían en la casa número 16 de la calle "Matamoros". Emilio quedó en la orfandad de padre a la edad de tres años y ante el desamparo económico en que se encontraba su familia, fue su madre la encargada de mantenerlo y de modelarlo en su niñez. Doña Adelaida tomó el timón de la familia y para sostenerla realizó quehaceres, a veces hasta por las noches, de costurera.

Portes Gil estudió la primaria en su ciudad natal, y la secundaria en la Escuela Normal de Ciudad Victoria. Posteriormente se trasladó a la ciudad de México, donde ingresó en 1912 a la Escuela Libre de Derecho, institución en la que se recibió como abogado en el año de 1915.

Ocupó diversos cargos públicos y fue Diputado Federal. En 1920, se afilió a la Revolución de Agua Prieta siendo gobernador provisional de Tamaulipas. Dos años después, contrajo matrimonio con Carmen García González.
El 17 de mayo de 1924 fundó el Partido Socialista Fronterizo y en el año de 1925 fue gobernador constitucional de su estado natal. En su gobierno, realizó una importante actividad legislativa y promovió la organización de los obreros y campesinos. Ejerció fuerte influencia en los gobiernos y en la política de Tamaulipas desde 1928.

Del 28 de agosto al 30 de noviembre de 1928 fue secretario de Gobernación y se le designó por el Congreso, presidente interino de la República iniciando su período el 1 de diciembre de 1928, pues el presidente electo, Álvaro Obregón había sido asesinado. 
Emilio Portes Gil asume la presidencia interina el 1 de diciembre de 1928. Los principales aspectos de su política, eran similares a la de sus antecesores: la reconstrucción económica, encaminada a modernizar el país, y convertirlo en una nación capitalista, establecer definitivamente la hegemonía del Estado sobre toda la sociedad para administrar los beneficios económicos, pretendía hacer efectivos los postulados de la constitución y el pacto social contenido en los artículos 27 y 123 .

Emilio Portes Gil conocía el poder del Jefe Máximo pero tenía un cierto ascendiente sobre él, por lo que no se resignó a ser el simple ejecutor de la política ajena. Favoreció el reparto de la tierra; aprovechó que Calles estuviera ocupado en consolidar su poder con miras a la sucesión y repartió cerca de 2 millones de hectáreas que beneficiaron a muchos campesinos, y fortaleció las organizaciones campesinas.

El 1° de diciembre de 1928, se da el primer paso para la conformación del Partido Nacional Revolucionario. Con la publicación del "Manifiesto de la Nación" se invitaba a todas las organizaciones, partidos y agrupaciones políticas a unirse al Partido para posteriormente convocar a una Convención Nacional para que los representantes de las organizaciones miembro discutieran los estatutos, el programa de principios, la designación de un candidato a la presidencia de la república, así como el nombramiento de las personas que formarían el Comité Director del Partido.
El Comité Organizador que realizaría las tareas antes mencionadas estaba constituido por: Plutarco Elías Calles, Aarón Sáenz, y Luis L. León entre otros, las funciones como organizadores estaban estipuladas en el manifiesto del 12 de diciembre.

La situación política cada día se complicaba más; por un lado el PNR necesitaba el apoyo de los obreros; pero por el otro el líder de la CROM lo obstaculizaba. Al luchar por su ascenso al poder, Morones ocasionaba la enemistad de los obregonistas y al atacar continuamente al presidente provisional, desestabilizaba aún más el ambiente político.

El líder obrero Luis N. Morones intentaba recuperar el poder que había ostentado durante la presidencia de Calles, trató de colocarse en un primer plano enfrentándose a su antiguo enemigo Emilio Portes Gil, la lucha entre los dos más que personal era de carácter político, pues pugnaban por el control de una fuerza de primer orden para establecer la hegemonía del Estado.

Algunos acusaban a Calles de ser el responsable de la insolencia moronista, ya que sin su apoyo el líder obrero no habría atacado tan abiertamente a Portes Gil. Calles se mantuvo al margen, sin negar ni afirmar, lo cual fortaleció la convicción generalizada de que en realidad estaba de acuerdo con Morones.

Luis L. León, integrante del Comité Organizador del PNR, le pidió a Calles que aclarara públicamente su posición con respecto a Morones para darle solución a esta nueva crisis del grupo. Calles, ante la alternativa de su propia caída política y la pérdida de la adhesión de los obregonistas, y con miras al futuro, hizo público que negaba su apoyo a Morones y para evitar malas interpretaciones de su actuación política, se retiraba definitivamente de la vida pública y renunciaba a su cargo del PNR.

Al retirarse de un puesto formal en la política, Calles quedó desvinculado de los compromisos adquiridos con las facciones, con lo que se amplió su capacidad de crear nuevas alianzas, convirtiéndose así en el factor central de las decisiones políticas de la época.

Pasado el periodo estipulado las elecciones volvieron a causar efervescencia. El Partido Nacional Antirreeleccionista apoyó la candidatura del popular ex secretario de Educación José Vasconcelos , quien basó su campaña en la denuncia de la corrupción y en la defensa de una política menos anticlerical.

El Partido Nacional Revolucionario nombró a Pascual Ortiz Rubio como candidato a la presidencia. Ortiz Rubio mantuvo conversaciones con Calles para discutir los nombres de los miembros del próximo gabinete presidencial, en el cual debían figurar hombres allegados al Jefe Máximo. Con esto se manifestaba una vez más la indiscutible fuerza política de Calles.

Desde el inicio de su gestión, Portes Gil reanudó las negociaciones entre el clero y su gobierno, con miras a buscar una salida viable al problema religioso.

Al mismo tiempo que tenía lugar la Convención del PNR estallaron levantamientos armados en Veracruz, Sonora, Chihuahua, Nuevo León y Durango por generales rebeldes que estaban en desacuerdo con el control que ejercía Calles en la política. Así el 3 de marzo emitieron el Plan de Hermosillo en él, invitaban al pueblo a levantarse en armas contra el gobierno corrupto, desconocían a Portes Gil como presidente y a Calles como dirigente nacional.

Esta rebelión estuvo comandada por José Gonzalo Escobar por esto se conoce como rebelión escobarista, contó con el apoyo de los cristeros lo cual interrumpió nuevamente la comunicación entre el Episcopado mexicano y el gobierno. Dado que Calles estaba formalmente retirado de la vida pública, Portes Gil lo invita a formar parte de su gabinete como Secretario de Guerra, y en esta rebelión el ejército comandado por él, logró la victoria y con esto corroboró su supremacía.

La Santa Sede y los clérigos del país finalmente comprendieron que con la lucha armada no se llegaría a ninguna solución por lo que hubo un cambio de actitud y retiraron su apoyo a los cristeros abriéndose las posibilidades para llegar a un acuerdo con el gobierno. En un principio la Liga de Defensa de las Libertades Religiosa que tenía la dirección urbana del movimiento se opuso a un acuerdo. Sin embargo ambas partes comenzaron el camino de la reconciliación; el gobierno exigía la aplicación absoluta de las leyes anticlericales, permitiendo como una concesión muy especial, que la Iglesia continuara ejerciendo su derecho espiritual sobre la población, siempre y cuando se alejara definitivamente de los asuntos políticos. El conflicto quedó resuelto el 22 de junio de 1929 y los servicios religiosos se restablecieron; el 27 de junio del mismo año se ofició la primera misa pública.

Otro conflicto que tuvo que resolver Portes Gil fue la huelga estudiantil que surgió en la Universidad Nacional y que, aunque no fue trascendente para la estabilidad política, opacaba la imagen de autoridad del gobierno y representaba un obstáculo más para el buen desarrollo de la campaña presidencial de Pascual Ortiz. Por ello el 28 de mayo de 1929 se otorgó la autonomía universitaria, con lo que el ánimo estudiantil se calmó.

El 17 de noviembre de 1929 se llevaron a cabo las elecciones presidenciales dándole el triunfo al Partido Nacional Revolucionario. El 1.o de diciembre Vasconcelos se declaraba como presidente electo de la república y ponía de manifiesto ante la nación la farsa electoral. Exhortó a una rebelión que nunca se llevó a cabo y los vasconcelistas aceptaron la imposición del PNR y por consiguiente, a Ortiz Rubio como presidente electo.

Una vez terminada su administración, Portes Gil tendría diversos cargos en el gobierno y en la iniciativa privada. Fue embajador en Francia y la India, secretario de Relaciones Exteriores, en algún momento quiso volver a ser gobernador de su estado natal pero fracasó, fue procurador, dirigente del partido oficial y director de la Comisión Nacional de Seguros, cargo que se le confirió ya que durante su mandato se preparó la Ley Federal de Trabajo (promulgada poco después) y se debatió ampliamente sobre el seguro para los trabajadores. Fue presidente de la Academia Mexicana de Derecho Internacional.

En la última etapa de su vida se dedicó a redactar testimonios de las experiencias de su actuación en la vida pública de México. Entre sus obras destacan "Autobiografía de la Revolución Mexicana" y "Raigambre de la Revolución de Tamaulipas". Al poco tiempo de haber cumplido los 88 años de edad, don Emilio, fallece en la ciudad de México el 10 de diciembre de 1978. Es el expresidente que más tiempo tuvo de vida pospresidencial, ya que murió 48 años, 10 meses y 5 días después de terminar su mandato (el 5 de febrero de 1930).



</doc>
<doc id="17545" url="https://es.wikipedia.org/wiki?curid=17545" title="Agnès Varda">
Agnès Varda

Agnès Varda (Bruselas, 30 de mayo de 1928) es una directora de cine francesa. Vive y trabaja en París. Es considerada por algunos críticos de cine la «abuela de la Nueva Ola» (Nouvelle vague) y una de las pioneras del cine hecho por mujeres y del cine feminista. Sus películas, documentales y vídeo-instalaciones guardan un carácter realista y social. Toda su obra presenta un estilo experimental distintivo. A lo largo de su trayectoria ha recibido numerosos premios, entre ellos en 1985 con la película "Sans toit ni loi" ("Sin techo ni ley") obtuvo el León de Oro del Festival de Cine de Venecia y su biografía documentada en "Las playas de Agnès" el Premio César en 2009 o el "Premio René Clair" de la Academia francesa. En 2017 recibió el por su carrera.

Agnès Varda nació con el nombre de Arlette Varda en Bruselas, Bélgica. Su padre pertenecía a una familia de refugiados griegos de Asia Menor y su madre era francesa. Estudió Historia del Arte en la École du Louvre antes de conseguir un trabajo como fotógrafa oficial del Teatro Nacional Popular o Théâtre National Populaire (TNP) de París. Le gustaba la fotografía, pero estaba más interesada en el cine. Después de pasar unos días grabando la pequeña ciudad pesquera francesa de Sète, en el barrio «La Pointe Courte», para un amigo con una enfermedad terminal que no podría visitarla por sí solo, Varda decidió hacer una película. De este modo aparece en 1954 su primera película, "La Pointe Courte", que narraba la historia de una triste pareja y su relación en la pequeña ciudad. La película es la precursora estilística de la Nouvelle vague francesa.

Varda es pionera en la apertura de la dirección cinematográfica a las mujeres. "Sugerí a las mujeres que estudiasen cine. Les dije: ""Salid de las cocinas, de vuestras casas, haceos con las herramientas para hacer películas"".

Más tarde se la encuadrará definitivamente en este género, asemejándosela así a autores como Chris Marker, Marguerite Duras, Alain Robbe-Grillet, Jean Cayrol y Henri Colpi. Este grupo estaba fuertemente ligado al Nouveau roman, estilo literario que estaba posicionado políticamente en la izquierda.

Varda se casó en dos ocasiones, primero con el actor y director teatral y operístico Antoine Boursellier con quien en 1958 tuvo una hija, Rosalie Varda, creadora de vestuario y directora artística. En 1962 se casó con el director cinematográfico Jacques Demy, a quien acompañó hasta su muerte en 1990. En la película "Jacquot de Nantes" (1991) Varda traza un relato de la infancia de Demy y su amor por el teatro y el cine. Le rindió homenaje también en "Les Demoiselles ont eu 25 ans" (1993) y "L'Univers de Jacques Demy" (1995). Tuvieron un hijo en común, el actor Mathieu Demy nacido en 1972.

Varda ha dirigido una cuarentena de piezas entre cortometrajes, documentales y largos de ficción. Su formación previa en fotografía le permite captar los pequeños detalles de la realidad que la circunda. "La combinación de la textura documental con un desarrollo narrativo (tan utilizado en el cine realista actual) puede ser el rasgo más característico de su extensa obra, lo mismo que la irrupción de la subjetividad del autor (por medio de la voz enoff, de la presencia física, del metalenguaje) en el universo objetivo que se retrata" señala el crítico Sergio Fernández Piniña.

Su primera película fue "La pointe courte", donde se observa la influencia de Rosellini sus primeras obras reflejan el impacto del cine francés de la Nueva Ola destacando "Cleo de 5 a 7" (1961)

La segunda fase de su obra se sitúa a partir del Mayo del 68 contagiada según la crítica del espíritu optimista de la época. "La felicidad" (1965), "Las criaturas (1966), "Lion´s Love (1969), cuestionan la rigidez de la sociedad burguesa. Destaca "Una canta, otra no" (1977), con un estilo jovial transformando las luchas feministas en una danza de colores "kitsch". 

Uno de sus trabajos más destacados fue "Sin techo ni ley (1985), protagonizado por Sandrine Bonnaire, dando vida a una vagabunda que sobrevive sometida al azar. En la película cohabitaron actores y personas del lugar, siendo el germen de toda una corriente de cine realista contemporáneo, encabezado por los hermanos Dardenne y Ken Loach. "Black panthers (1968), "Daguerréotypes (1975), Murs, murs (1980), "Jane B. par Agnès V. (1987), "Cinévardaphoto (2004), por no hablar de "Los espigadores... y su secuela "Dos años después" (2002), están consideradas por la crítica pequeñas obras maestras del género y testimonios históricos y del paso del tiempo. 

En 2017 presentó su película, "Caras y lugares", realizada junto al artista JR, y en la que vuelve a plantear esa intersección entre documental, juego y exploración social de su cine. La película logró financiarse a través de un "crowdfunding "y el apoyo de su hija que buscó financiación en el MoMA que compró una copia para su fondo archivístico antes de que empezase el rodaje y la Fundación Cartier. 

























</doc>
<doc id="17547" url="https://es.wikipedia.org/wiki?curid=17547" title="Tracey Emin">
Tracey Emin

Tracey Emin (n. Inglaterra, 1963) es una artista británica reconocida dentro del grupo de los Young British Artists.

Emin es tal vez la segunda en notoriedad tras el mediático Damien Hirst. "My Bed" es su obra más conocida, desde que formó parte de la terna final del premio Turner en 1999. La pieza consistía en su propia cama sin hacer, con las sábanas con manchas amarillas, y en el suelo de alrededor había artículos de su habitación, como condones, paquetes de cigarrillos vacíos, un par de bragas con manchas menstruales y otros detritus domésticos, incluyendo un par de zapatillas. Aunque no ganó, dicha obra concitó enorme atención y abundantes crónicas en la prensa internacional.

Emin nació en Londres, pero creció en Margate. Estudió arte en Maidstone, luego regresó a Londres donde estudió pintura en el Royal College of Art. En sus inicios se reconoce la influencia de Edvard Munch y Egon Schiele; Tracey Emin destruyó todos sus cuadros de la primera etapa. Posteriormente a sus estudios en pintura, se inició en la Filosofía.

Al inicio de su carrera como artista, Emin abrió una tienda llamada "The Shop" en Bethnal Green en sociedad con Sarah Lucas. Vendían obras de ambas, incluyendo camisetas y ceniceros con la imagen de Damien Hirst.

En 1994 realizó su primer exposición individual en la galería de arte White Cube, una de las más importantes galerías de Londres. Se tituló "Mi mayor retrospectiva" y fue típicamente autobiográfica. Consistía en fotografías personales y fotos de sus hoy destruidas primeras pinturas junto a objetos que muchos artistas no sacarían al público como paquetes de cigarrillos que llevaba su tío cuando murió decapitado en un accidente de tráfico. Su disposición por enseñar detalles de su vida privada es uno de los sellos distintivos de su obra.

Emin se hizo artista reconocida cuando en 1997 el canal Channel 4 de televisión le realizó una entrevista especial. Fue un programa con un debate serio e intenso, donde Emin estaba completamente drogada, en parte por los tranquilizantes que había tomado para calmar el dolor de un dedo roto; durante toda la entrevista no paró de decir que quería regresar a su casa con su madre.

Dos años después en 1999 Emin formó parte de la lista de artistas escogidos para el premio Turner (Turner Prize) y expuso su cama bajo el título "My Bed" (literalmente "mi cama") en la galería Tate Gallery. 

Una de sus más destacadas obras es "Everyone I Have Ever Slept With 1963-95", una tienda de campaña adornada con los nombres de todas las personas con quienes alguna vez durmió, incluidos compañeros sexuales, familiares con quienes trasnochó en su infancia, su hermano mellizo y sus dos embarazos perdidos. Alguna vez, sin temor, Emin dijo que esta exposición se trataba menos de sus conquistas sexuales que de su intimidad en un sentido general. La costura que utiliza Emin para esta pieza, con la que escribe los nombres de todas las personas, aparece en algunas otras de sus obras. Ésta, junto con muchas otras suyas y de otros artistas YBA como los hermanos Chapman, fue destruida en un incendio en Londres el 26 de mayo de 2004.



</doc>
<doc id="17549" url="https://es.wikipedia.org/wiki?curid=17549" title="Krzysztof Zanussi">
Krzysztof Zanussi

Krzysztof Zanussi, director de cine nacido en Polonia (Varsovia, 17 de junio de 1939). Es profesor en Universidad de Silesia en Katowice, Polonia.

Krzysztof Zanussi, galardonado con el Premio Luka Brajnovic 2006, es un físico y filósofo que trabaja en el mundo del cine, sobre todo como director y productor. Un hombre comprometido que durante su carrera se ha planteado trascendentales cuestiones que se expresan a través de un cine reflexivo y personal, reconocido internacionalmente a partir de los años ochenta.

Este director polaco aúna una labor creativa -no sólo ha sido productor, guionista y director de cine, sino también de teatro y ópera- con una profunda preocupación por trasmitir unos valores a contracorriente mediante su obra, enfrentada a los principios que rigen la cultura oficial.

Zanussi, que nació en Varsovia meses antes de la invasión alemana de 1939, comenzó su labor cinematográfica durante los años cincuenta, en el Club de Cine Amateur de la Universidad de Varsovia, aunque no es hasta 1966 cuando dirige su opera prima, el proyecto fin de carrera ‘La muerte de un provinciano’, que obtuvo el León de plata en el Festival Internacional de Cine de Venecia.

A partir de esta primera película, el cineasta polaco, que ha desarrollado su carrera en Polonia y en el extranjero, inicia una labor creadora que le ha llevado a participar en cerca de cincuenta títulos. Zanussi no ha despreciado durante sus cuarenta años de trabajo ningún formato y ha plasmado sus ideas en la gran pantalla y la televisión, en cine ficción y en documental.
Tras su debut con "La estructura del cristal" (1969), se hizo famoso en todo el mundo con "De un país lejano: Juan Pablo II" (1981), "Hermano de nuestro Dios" (1996), "La vida como enfermedad de transmisión sexual" (2000) y "El sol negro" (2007).

Las películas de Zanussi cuentan con un marchamo común: una clara preocupación, siempre presente, por las cuestiones sociales y la relación entre el pensamiento y el hombre. Respecto a la narrativa de este creador, se destaca el uso ascético de las cámaras, la preferencia de las ideas frente a la pasión y la presencia de personajes con interés por las cuestiones filosóficas, así como el uso de recurrentes elementos simbólicos como el sol y el alpinismo.

Su clara defensa de los valores del catolicismo ha sido otra de las señas de identidad del cineasta, situado dentro del movimiento de ‘la tercera generación’ del cine polaco. Durante el régimen comunista fundó el movimiento ‘El cine de la inquietud moral’, junto a realizadores como Andrzej Wajda y Edward Zebrowski. Zanussi reconocía en una entrevista que su vinculación a la Iglesia Católica le ha dificultado su trabajo, aunque nunca ha querido hablar de una persecución de su obra.

Este mundo personal e innovador ha sido reconocido con multitud de premios internacionales. Entre la larga lista de galardones destacan los obtenidos en festivales como Venecia, Cannes y Berlín, además de destacados certámenes cinematográficos como Montreal y Moscú.

Krzysztof Zanussi, amante de la obra de Carl Theodor Dreyer e Ingmar Bergman y discípulo de Munk, ha ocupado el puesto de vicepresidente de la Asociación de Cineastas Polacos, durante 1974 y 1981, y ha presidido la FERA (Federación Europea de Realizadores Audiovisuales). Desde 1979 dirige TOR Film Studio, productora de grandes títulos, entre las que destaca la trilogía ‘Tres colores: Azul. Blanco. Rojo’, de su amigo Krzysztof Kieślowski.

Durante los últimos años, a su dedicación al cine ha sumado su labor como profesor, desde 1992, de la Universidad de Silesia (Katowice), articulista en el semanal polaco ‘Polityka’ y su pertenencia al Pontificio Consejo de la Cultura de la Santa Sede.

Según los datos guardados en el Instituto de la Memoria Nacional, desde 1962 a 1964 estuvo registrado como colaborador secreto de nombre en clave comunista Służba Bezpieczeństwa. Mantuvo conversaciones con funcionarios; sin embargo, nunca se puso a actuar como colaborador secreto.

La entrega del X Premio Luka Brajnovic, que otorga anualmente la Facultad de Comunicación de la Universidad de Navarra tuvo lugar el 7 de marzo de 2007. La Universidad distinguió así la extensa carrera de Zanussi, en la que se ha planteado trascendentales cuestiones, expresadas a través de un cine reflexivo y personal, reconocido internacionalmente a partir de los años 80.




</doc>
<doc id="17550" url="https://es.wikipedia.org/wiki?curid=17550" title="Slavoj Žižek">
Slavoj Žižek

Slavoj Žižek ( Liubliana, 21 de marzo de 1949) es un filósofo, sociólogo, psicoanalista y crítico cultural esloveno. Su obra integra el pensamiento de Jacques Lacan con el materialismo dialéctico marxista y en ella destaca una tendencia a ejemplificar la teoría con la cultura popular.

Žižek estudió filosofía en la Universidad de Liubliana y psicoanálisis en la Universidad de París VIII Vincennes-Saint-Denis, donde se doctoró. Su carrera profesional incluye un puesto de investigador en el Instituto de Sociología de la Universidad de Liubliana, Eslovenia, así como cargos de profesor invitado en diversas instituciones, que incluyen Columbia, Universidad de Princeton, New School for Social Research de Nueva York y Universidad de Míchigan, entre otros. En la actualidad es Director Internacional del Instituto Birkbeck para las Humanidades, Birkbeck College - Universidad de Londres.

Žižek utiliza en sus estudios ejemplos extraídos de la cultura popular, desde la obra de Alfred Hitchcock y David Lynch, hasta la literatura de Kafka o Shakespeare, además de problematizar autores olvidados por la academia como V. I. Lenin, Stalin y Robespierre y tratar sin remordimientos temas espinosos como el fundamentalismo, el anticapitalismo, la tolerancia, la subjetividad y lo políticamente correcto en la filosofía posmoderna. Asimismo, en contraposición con los postulados intelectuales de la izquierda universalista europea en general, y de los que Habermas define como postnacionales en particular, Žižek realiza una defensa abierta e inequívoca de los procesos soberanistas abiertos en Europa.

Utiliza también la teoría psicoanalítica en la versión lacaniana como un arma para sus habituales análisis de política internacional, considerando no solo a los líderes y sus posibles problemas psicológicos, sino también a la sociedad en su conjunto.

En 1990 fue candidato a la presidencia de la República de Eslovenia, aunque no resultó electo.

Slavoj Žižek toma de Jacques Lacan la descripción de los conceptos de su tópica (descrita a partir de 1953 y constituida como una estructura compuesta por tres órdenes o registros inseparables) y los desarrolla como sigue:

Aquí, lo "real" resulta ser un término bastante enigmático y no debe ser equiparado con la realidad, puesto que nuestra realidad está construida simbólicamente; lo real, por el contrario, es un núcleo duro, algo traumático que no puede ser simbolizado (es decir, expresado con palabras). Lo real no tiene existencia positiva; solo existe como obstruido.

No todo en la realidad puede ser desenmascarado como una ficción; solo basta con tener presente ciertos aspectos -puntos indeterminados- que tienen que ver con antagonismo social, la vida, la muerte y la sexualidad. A estos aspectos tenemos que enfrentarlos si hemos de querer simbolizarlos. Lo real no es ninguna especie de realidad detrás de la realidad, sino el vacío que deja a la realidad incompleta e inconsistente. Es la pantalla del fantasma; la propia pantalla en sí es la que distorsiona nuestra percepción de la realidad. La tríada de lo simbólico/imaginario/real se reproduce dentro de cada parte individual de la subdivisión. Hay también tres modalidades de lo real:


El psicoanálisis enseña que la realidad (postmoderna) precisamente no ha de ser vista como una narrativa, sino que el sujeto ha de reconocer, soportar y ficcionalizar el núcleo duro de lo real dentro de su propia ficción.

Lo simbólico se inaugura con la adquisición del lenguaje; es mutuamente relacional. Así, sucede aquello de que "un hombre sólo es rey porque sus súbditos se comportan ante él como un rey". Al mismo tiempo, siempre permanece una cierta distancia respecto a lo real (excepto en la paranoia): no sólo es loco un mendigo que piensa que es rey, lo es también aquél rey que verdaderamente cree que él es un rey. Puesto que efectivamente, este último sólo tiene el "mandato simbólico" de un rey.


La pantalla del monitor como forma de comunicación en el ciberespacio: como una interfaz nos refiere a una mediación simbólica de la comunicación, a un abismo entre quien sea que habla y la "posición de hablar" en sí (p.ej el apodo, la dirección de correo). "Yo" nunca "de hecho" coincido exactamente con el significante, no me invento a mí mismo; en cambio, mi existencia virtual fue, en cierto sentido, ya co-fundada con el advenimiento del ciberespacio. Aquí uno debe llegar a entenderse con cierta inseguridad, pero no puede ser resuelta como en un simulacro contingente postmoderno... Aquí también, como en la vida social, las redes simbólicas circulan alrededor de los núcleos de lo real. Esta es una respuesta a la inversión a menudo planteada por Žižek: no se trata de "¿qué podemos aprender acerca de la vida en el ciberespacio?" sino más bien, "¿qué podemos aprender acerca del ciberespacio en la vida?" Estas inversiones sirven al psicoanálisis teórico: es decir, contrario al psicoanálisis aplicado, no busca meramente analizar trabajos de arte y hacer lo que es amenazante comprensible, sino crear una nueva perspectiva en lo ordinario, renovar la sensación de extrañeza sobre la vida diaria, y por vía del objeto desarrollar más allá la teoría.

Las redes simbólicas son nuestra realidad social.

Lo imaginario otro se ejemplifica en lo que Lacan llama el estadio del espejo, por el cual uno se reconoce en una imagen ficticia de sí mismo (la imagen proyectada en un espejo), y en ese reconocimiento hay un fallo, es un reconocimiento ilusorio por el cual el yo se constituye como un otro, como concluye Jacques Lacan citando a Arthur Rimbaud: "Yo soy otro" (""Je suis un autre""). Lo imaginario es la fantasía fundamental que es inaccesible a nuestra experiencia psíquica y se eleva de la pantalla fantasmal en la que encontramos objetos de deseo. Aquí también podemos dividir lo imaginario entre uno real (el fantasma que asume el lugar de lo real), uno imaginario, o lo imaginario mismo, (la imagen/pantalla en sí que sirve como cebo) y uno simbólico (los arquetipos de Jung y el pensamiento New Age). Lo imaginario nunca puede ser agarrado, ya que todo discurso sobre él siempre estará localizado en lo simbólico.

Todos los niveles están interconectados, de acuerdo a Jacques Lacan (del seminario XX en adelante), en una forma de nudo borromeo, como tres anillos enlazados juntos de manera que si uno de ellos se desconectara, el resto también caería.





</doc>
<doc id="17551" url="https://es.wikipedia.org/wiki?curid=17551" title="Halloween">
Halloween

Halloween (contracción del inglés "All Hallows' Eve", en español: «Víspera de Todos los Santos»), también conocido como Noche de Brujas, Noche de Muertos o Noche de Víspera de Difuntos, es una celebración moderna resultado del sincretismo originado por la cristianización de la fiesta del fin de verano de origen celta llamada Samaín.

Se celebra internacionalmente en la noche del 31 de octubre, sobre todo en la angloesfera, como Canadá, Estados Unidos, Irlanda o Reino Unido, y, en menor medida, en otros lugares como España e Iberoamérica. A pesar de pertenecer al mundo anglosajón, en Australia y Nueva Zelanda no se observa esta costumbre tanto como en los demás países.

Sus raíces están vinculadas con la conmemoración celta del Samhain y la festividad cristiana del Día de Todos los Santos, celebrada por los católicos el 1 de noviembre. Se trata de un festejo secular, aunque algunos consideran que posee un trasfondo religioso. Los inmigrantes irlandeses transmitieron versiones de la tradición a América del Norte durante la Gran hambruna irlandesa.

El día se asocia a menudo con los colores naranja, negro y morado y está fuertemente ligado a símbolos como la "jack-o'-lantern". Las actividades típicas de Halloween son el famoso truco o trato y las fiestas de disfraces, además de las hogueras, la visita de casas encantadas, las bromas, la lectura de historias de miedo y el visionado de películas de terror.

En algunos países de Hispanoamérica se acostumbra a salir por la noche con los niños más pequeños disfrazados a pedir dulces y cantando. Los mayores suelen acudir a fiestas nocturnas después de llevar a los más pequeños a pedir dulces. También para los niños se hacen fiestas, aunque durante el día.

La palabra «Halloween» [/ˌhæl.əʊˈiːn/] se define tradicionalmente como una forma acortada en lengua escocesa de la expresión inglesa "Allhallow-even" usada como tal por primera vez en el siglo XVI. Bajo la forma «"Hallow-e'en»" se encuentra atestiguada desde 1745. "All Hallows' Even", o también "All Hallows' Eve", era el antiguo nombre en inglés de la «víspera de todos los Santos», esto es, la víspera de la fiesta cristiana del 1 de noviembre. 

«"Hallow"» es una forma en inglés —ya en desuso— para referirse a los santos, proveniente a su vez del anglosajón «"haliga"», «"halga"» que significa «"santo"», «"santificar"» o «"consagrar"». A su vez, «"even"» o «"eve"», también en desuso, designa la parte final del día, esto es, la víspera del día siguiente. Es, además, el nombre en inglés que reciben la vigilias de las fiestas litúrgicas del cristianismo.

Recientemente se ha reivindicado otro origen: la mesnie o mesnada, ejército, compaña o procesión de muertos. Según testimonio de Guillermo de Auvernia en el siglo XIII la procesión de difuntos se denominaba «vulgari gallicano Hellequin et vulgari hispanico exercitus antiquus» («en galicano Hellequini y en hispánico ejército antiguo o hueste antigua»). La etimología Hallows' Eve para Halloween entonces ha de ser una interpretación erudita; nombre y contenido enlazan con el folklore de la Cacería salvaje, la Santa Compaña, la estantigua (estántiga en gallego y portugués). El término Halloween en sí mismo sería una derivación del nombre dado al capitán de esta procesión de muertos, que a su vez provendría de tradiciones antiguas del Norte de Europa; este nombre según esta teoría acabó derivando también en Arlequín.

Halloween según la teoría tradicional tiene su origen en una festividad céltica conocida como Samhain, que deriva del irlandés antiguo y significa "fin del verano". Los antiguos britanos tenían una festividad similar conocida como Calan Gaeaf. En el Samhain se celebraba el final de la temporada de cosechas en la cultura celta y era considerada como el «Año nuevo celta», que comenzaba con la estación oscura.

Los antiguos celtas creían que la línea que une a este mundo con el Otro Mundo se estrechaba con la llegada del Samhain, permitiendo a los espíritus (tanto benévolos como malévolos) pasar a través. Los ancestros familiares eran invitados y homenajeados mientras que los espíritus dañinos eran alejados. Se cree que el uso de trajes y máscaras se debe a la necesidad de ahuyentar a los espíritus malignos. Su propósito era adoptar la apariencia de un espíritu maligno para evitar ser dañado."

Otra práctica común era la adivinación, que a menudo implicaba el consumo de alimentos y bebidas, e incluso en Asturias se celebraban banquetes en las tumbas de antepasados.

Cuando tuvo lugar la ocupación romana de los dominios celtas la festividad fue asimilada por estos. Aunque ya se celebraban los últimos días de octubre y primeros de noviembre una festividad conocida como la «fiesta de la cosecha», en honor a Pomona (diosa de los árboles frutales), se mezclaron ambas tradiciones.

En una época en la que predominaban las festividades «paganas», los papas Gregorio III (731-741) y Gregorio IV (827-844) intentaron suplantarla por una festividad católica (Día de Todos los Santos) que fue trasladada del 13 de mayo al 1 de noviembre.

En 1840 esta festividad llega a Estados Unidos y Canadá, donde queda fuertemente arraigada. Los inmigrantes irlandeses transmitieron versiones de la tradición durante la Gran hambruna irlandesa. Fueron ellos quienes difundieron la costumbre de tallar los "jack-o'-lantern" (calabaza gigante hueca con una vela dentro) , inspirada en la leyenda de «Jack el Tacaño».

Sin embargo, la fiesta no comenzó a celebrarse masivamente hasta 1921. Ese año se celebró el primer desfile de Halloween en Minnesota y luego le siguieron otros estados. La fiesta adquirió una progresiva popularidad en las siguientes décadas.

La internacionalización de Halloween se produjo a finales de los años 1970 y principios de los 1980 gracias al cine y a las series de televisión. En 1978, se estrenaba en Estados Unidos y en el mundo entero "Halloween", de John Carpenter; una película ambientada en la víspera de Todos los Santos que supuso una referencia para el cine de terror de serie B; con innumerables secuelas e imitaciones.

Hoy en día, Halloween es una de las fechas más importantes del calendario festivo estadounidense y canadiense. Algunos países iberoamericanos, conociendo aún esta festividad, tienen sus propias tradiciones y celebraciones ese mismo día, aunque coinciden en cuanto a su significado: la unión o extrema cercanía del mundo de los vivos y el reino de los muertos.
En Europa son muchas las ciudades en las que los jóvenes han decidido importar el modo con el que Estados Unidos concibe Halloween celebrándolo con fiestas y disfraces. Aunque en algunos lugares, como Inglaterra, la fiesta original ha arraigado de nuevo.

El hecho de que esta fiesta haya llegado hasta nuestros días es, en cierta medida, gracias al enorme despliegue comercial y la publicidad engendrada en el cine estadounidense. La imagen de niños norteamericanos correteando por las oscuras calles disfrazados de duendes, fantasmas y demonios, pidiendo dulces y golosinas a los habitantes de un oscuro y tranquilo barrio, ha quedado grabada en la mente de muchas personas.

En esa noche los espíritus visitaban las casas de sus familiares, y para que los espíritus no les perturbasen los aldeanos debían poner una vela en la ventana de su casa por cada difunto que hubiese en la familia. Si había una vela en recuerdo de cada difunto los espíritus no molestaban a sus familiares, si no era así los espíritus les perturbaban por la noche y les hacían caer entre terribles pesadillas.

Dado que Halloween coincide con la temporada de la cosecha de las manzanas cada año, las manzanas de caramelo (conocidas como manzanas acarameladas fuera de Norteamérica), y las manzanas dulces son comunes durante las fiestas.

Las manzanas de caramelo se les daban comúnmente a los niños, pero la práctica se desvaneció rápidamente en la estela de rumores generalizados de que algunos individuos incrustaban objetos como clavos y cuchillas de afeitar en las manzanas en los Estados Unidos. Si bien hay pruebas de este tipo de incidentes, son muy raros y nunca han dado lugar a lesiones graves. Muchos padres suponen que estas prácticas atroces fueron exageradas por los medios de comunicación. En la cumbre de la histeria, algunos hospitales ofrecían gratuitamente rayos X para los niños en Halloween, con el fin de encontrar evidencia de manipulación. Se conocen pocos casos de intoxicación por caramelos manipulados.

Una costumbre que persiste hoy en día en Irlanda es la preparación o la compra de un pastel de frutas, en el que se coloca un anillo simple, una moneda y otros encantos antes de hornear. Se dice que aquellos que encuentran un anillo encontrarán su verdadero amor el año siguiente. Esta tradición es similar a la del roscón de Reyes en la fiesta de la Epifanía.

Originalmente el "truco o trato" (en inglés "«Trick-or-treat»") era una leyenda popular de origen céltico según la cual no solo los espíritus de los difuntos eran libres de vagar por la Tierra la noche de Halloween, sino toda clase de entes procedentes de todos los reinos espirituales. Entre ellos había uno terriblemente malévolo que deambulaba por pueblos y aldeas, yendo de casa en casa pidiendo precisamente «truco o trato». La leyenda asegura que lo mejor era hacer trato, sin importar el costo que este tuviera, pues de no pactar con este espíritu (que recibiría el nombre de "jack-o'-lantern", con el que se conocen a las tradicionales calabazas de Halloween) él usaría sus poderes para hacer «truco», que consistiría en maldecir la casa y a sus habitantes, dándoles toda clase de infortunios y maldiciones como enfermar a la familia, matar al ganado con pestes o hasta quemar la propia vivienda. Como protección surgió la idea de crear en las calabazas formas horrendas, para así evitar encontrarse con dicho espectro (y con el tiempo, debido a la asociación mental entre el espíritu y las calabazas, el nombre de este sería dado a ellas, que es como son conocidas hoy día cuando llega esta fiesta).

Realmente, aunque se ha generalizado la traducción «truco» en castellano por el inglés «trick» y «trato» literalmente por «treat», en el caso del "«Trick-or-treating»" no se trata de un truco propiamente dicho sino más bien de un susto o una broma por lo que una traducción más exacta sería por ejemplo «susto o dulce» o «travesura o dulce».

En la actualidad, los niños se disfrazan para la ocasión y pasean por las calles pidiendo dulces de puerta en puerta. Después de llamar a la puerta los niños pronuncian la frase «truco o trato», «truco o dulce» o «travesura o dulce» (proveniente de la expresión inglesa "trick or treat"). Si los adultos les dan caramelos, dinero o cualquier otro tipo de recompensa, se interpreta que han aceptado el trato. Si por el contrario se niegan, los chicos les gastarán una pequeña broma, siendo la más común arrojar huevos o espuma de afeitar contra la puerta.

En México existe una versión denominada "Calaverita" en la que los niños preguntan "¿Me da usted mi calaverita?" en lugar de "¿Truco o Trato?" refiriéndose a un dulce con forma de calavera.

El recorrido infantil en busca de golosinas probablemente enlace con la tradición neerlandesa de la Fiesta de San Martín

Durante la última noche del martes del año iraní, estos celebran una fiesta llamada Chaharshanbe Suri, o noche del fuego. Tradicionalmente, estos creen que los vivos fueron visitados por los espíritus de sus antepasados el último día del año Noruz. Muchas personas especialmente niños, se envuelven en sudarios simbólicamente recreando las visitas. A la luz de la hoguera, corren por las calles golpeando en ollas y sartenes con cucharas llamadas Gashog-Zani para vencer el último miércoles desafortunado del año, mientras llaman a las puertas para pedir golosinas. De hecho, Halloween es una variación celta de esta noche. Esta es una antigua fiesta de Irán, Azerbaiyán, Iraq, Afganistán, Tayikistán y Turquía y la fecha se remonta al menos 1.700 a.C.

Existe un viejo relato popular irlandés que habla de Jack, un irlandés tacaño, pendenciero y con fama de borracho. El diablo, a quien llegó el rumor de tan negra alma, acudió a comprobar si efectivamente era un rival de semejante calibre. Disfrazado como un hombre normal acudió al pueblo de este y se puso a beber con él durante largas horas, revelando su identidad tras ver que en efecto Jack era un auténtico malvado. Cuando Lucifer le dijo que venía a llevárselo para hacerle pagar por sus pecados, Jack le pidió que bebieran juntos una ronda más, como última voluntad. El diablo se lo concedió, pero al ir a pagar ninguno de los dos tenía dinero, así que Jack retó a Lucifer a convertirse en una moneda para demostrar sus poderes. Satanás lo hizo, pero en lugar de pagar con la moneda, Jack la metió en su bolsillo, donde llevaba un crucifijo de plata. Incapaz de salir de allí el diablo ordenó al granjero que le dejara libre, pero Jack respondió que no lo haría a menos que prometiera volver al infierno para no molestarle durante un año.

Transcurrido ese tiempo, el diablo apareció de nuevo en casa de Jack para llevárselo al inframundo, pero de nuevo Jack pidió un último deseo, en este caso, que el amo de las tinieblas cogiera una manzana situada en lo alto de un árbol para así tener una última comida antes de su tormento eterno. Lucifer accedió, pero cuando se hallaba trepado en el árbol, Jack talló una cruz en su tronco para que no pudiera escapar. En esta ocasión pidió no ser molestado en diez años, además de otra condición: que nunca pudiera el diablo reclamar su alma para el inframundo. Satanás accedió y Jack se vio libre de su amenaza.

Su destino no fue mejor: tras morir (mucho antes de transcurridos esos diez años pactados), Jack se aprestó a ir al cielo, pero fue detenido en las puertas de San Pedro, impidiéndosele el paso pues no podían aceptarle por su mala vida pasada, siendo enviado al infierno. Para su desgracia allí tampoco podían aceptarlo debido al trato que había realizado con el diablo, quien de paso le expulsó de su reino y, despechado, le arrojó a Jack unas ascuas ardientes, las cuales el granjero atrapó con un nabo hueco, mientras burlonamente agradecía la improvisada linterna que así obtuvo. Condenado a deambular por los caminos, anduvo sin más luz que la ya dicha linterna en su eterno vagar entre los reinos del bien y del mal. Con el paso del tiempo Jack el Tacaño fue conocido como "Jack el de la Linterna" o «Jack of the Lantern», nombre que se abrevió al definitivo «Jack O'Lantern». Esta es la razón de usar nabos (y más tarde calabazas, al imitar con su color el resplandor de las ascuas infernales y por ser más fáciles de tallar que los nabos) para alumbrar el camino a los difuntos en Halloween, y también el motivo de decorar las casas con estas figuras horrendas (para evitar que Jack llamara a la puerta de las casas y proponer "Dulces o travesuras").

La mayor parte de la sociedad española considera que Halloween es una fiesta estadounidense que ha «invadido» España por la expansión de la cultura de Estados Unidos (medios de comunicación, Hollywood, series...). Lo cierto es que las tradiciones que se celebran en Halloween se celebraban en España antes incluso de que existiera Estados Unidos como nación. Por lo tanto se puede afirmar que Halloween también puede ser considerada como una tradición ibérica (no con este nombre, sino como parte del Samhain), aunque su actual resurgimiento está claramente relacionado con la cultura importada desde Estados Unidos.

Para empezar, en España debido a su origen celta hay un número considerable de tradiciones relacionadas con espíritus, siendo probablemente las más famosas las meigas y la Santa Compaña de Galicia. En Asturias, en el siglo XVIII, los niños llevaban lámparas y pedían comida a las puertas de las casas durante esa noche. Por ejemplo dentro de Castilla, en la actual comunidad de Madrid, se tienen registros de numerosos municipios como Ambite, Canencia, El Vellón, Estremera, Manzanares el Real, Loeches, Fuentidueña de Tajo en los que se decoraban las casas con calabazas, a las que le hacían agujeros en su interior para simular una cara con ojos, nariz y boca y se introducía una vela o luz dentro de la calabaza, con el objetivo de invocar espíritus protectores y asustar a la gente generando una atmósfera de terror. En muchos pueblos esa noche solo estaban iluminadas las calabazas y las hogueras. Para hacer estas decoraciones se solían utilizar calabazas, aunque también se hacían con calabacines, botijos, ollas. En Ajalvir en vez de una calabaza se utiliza una calavera de asno; y en Tielmes, un botijo.

Era una costumbre muy habitual de muchos pueblos madrileños tocar la campanilla durante esa noche hasta la madrugada y en muchas ocasiones la gente iba vestida de negro. Se llevaban a los cementerios luces para «guiar» a los muertos y se limpiaban las tumbas. En las afueras de Soria (Castilla y León), se celebra una procesión muy famosa llamada «Ritual de las Ánimas», en el que las personas cantan por la noche mientras llevan en las manos velas protegidas por botes, calabazas o cacharros de barro agujereados para finalmente hacer una gran hoguera. Esta tradición fue inmortalizada por Gustavo Adolfo Bécquer en su cuento de terror «El monte de las ánimas» (1862).
Muchas de estas tradiciones paganas convivían con otras religiosas, principalmente cristianas como el Día de Todos los Santos (1º de noviembre), sin embargo en épocas en las que hubo gobiernos fuertemente religiosos, como durante la Dictadura de Franco, se buscó que la Iglesia tuviera el monopolio de las celebraciones festivas.

En el plano gastronómico es bastante común el consumo de alimentos propios de estas fechas como: los buñuelos de viento, los huesos de santo, panellets, puches (en Getafe), natillas, sopas canas, chocolate con churros, tostones (en Ciudad Real), roscos (en la provincia de Cuenca), nuégados (en Albacete), etc.




</doc>
<doc id="17553" url="https://es.wikipedia.org/wiki?curid=17553" title="Otaku no Video">
Otaku no Video

La película consta de dos partes.

En "Otaku no Video 1982", Kubo, un chico preparatoriano normal que en 1982 practica deporte y tiene novia, se encuentra un día con Tanaka, un viejo compañero del instituto (secundaria). Éste y sus amigos acaban introduciéndole en la fascinante y extraña cultura otaku. Debido a su nueva afición, Kubo pasa cada vez menos tiempo con su novia, hasta que ésta lo deja 2 años después durante 1984. Es entonces cuando decide ya no convertirse en un simple otaku, sino en el otaku de los otakus, el "Otaking" ("otaku king", rey de los otakus), rango que intentará alcanzar a lo largo de "More Otaku no Video 1985", la cual inicia 3 años después en 1985 y continúa durante los 90s.

Entre los aspectos que desarrolla la película se encuentra el cosplay, la creación de maquetas, la creación de una serie de animación e incluso la creación de un parque de atracciones para uso y disfrute de los otakus. Todo para convertirse en el "otaking".

Finalmente, en 1999, un maduro Kubo realiza su sueño de crear un parque temático para los otakus, "Otakuland". Sin embargo, muchos años después, Tokio es atacado por una serie de Tsunamis y queda sumergido en el océano. Kubo y Tanaka, ya siendo unos ancianos, deciden volver a la vieja Otakuland, ahora submarina, pero algo extraño sucede, los recuerdos se mezclan con la realidad, y junto a sus antiguos amigos que antes los traicionaron, irán en busca de un nuevo lugar para ellos: El Planeta de los Otakus.

Parte principal de la trama es el hecho de que el personaje central va perdiendo la vida normal que tenía, y se sumerge en el oscuro mundo de los otakus. Esto es parte importante de la película en la cual, al mezclarla con parte documental, vemos como los otakus llegan a perder el sentido de la realidad y se concentran sólo en el mundo del manga y el anime. También se ve la gran discriminación que sufren estas personas en el documental y en el filme. Es el momento en el que el personaje dice que si no puede ser aceptado se convertirá en el rey de los otakus (otaking).
Kubo junto a su amigo Tanaka, deciden crear una empresa. Aunque esta falla, vuelven a intentarlo nuevamente, hasta llegar a ser la marca más famosa de Manga y Anime.

Debido a que el anime está parcialmente basado en la vida de los creadores de Gainax, quienes comenzaron su carrera siendo otakus durante el fin de la década de los 70s y el principio de los 80s, numerosos animes de ese periodo son mostrados en el OVA (en disfraces, ropa, cosplay, posters y otros materiales relacionados). Entre estos se encuentran "Space Battleship Yamato", "Urusei Yatsura", "Capitán Harlock", "Mobile Suit Gundam", "Cobra (manga)", "Hi no Tori 2772: Ai no Cosmozone (Pájaro del Espacio)", "Las aventuras de Gigi", "The Super Dimension Fortress Macross", "", "The Wings of Honneamise", "Top wo nerae! Gunbuster" y "Daicon III and IV Opening Animations".





</doc>
<doc id="17561" url="https://es.wikipedia.org/wiki?curid=17561" title="Ipomoea batatas">
Ipomoea batatas

Ipomoea batatas, llamada comúnmente batata (del taíno), papa dulce, patata dulce, camote (del náhuatl "camohtli") o boniato, es una planta de la familia Convolvulaceae, cultivada en gran parte del mundo por su raíz tuberosa comestible.

Son plantas trepadoras perennes; con tallos postrados o volubles, algo suculentos pero también delgados y herbáceos, generalmente con raíces en los nudos, glabros o pubescentes. Hojas variables, enteras o dentadas hasta 5-7 lobadas, cordadas a ovadas, 5-10 cm de largo y de ancho, glabras o pubescentes. Inflorescencias cimosas a cimoso-umbeladas con pocas flores, o las flores ausentes en algunas variedades; sépalos oblongos a obovados, los 2 exteriores más cortos y abruptamente acuminados o mucronado-caudados, 8-10 mm de largo, los interiores 10–15 mm de largo, generalmente pubescentes o ciliados; corola infundibuliforme, 4-7 cm de largo, glabra por fuera, pubescente en la base por dentro, limbo lila, garganta más oscura o blanca en algunas variedades. Frutos poco comunes, ovoides, 4-5 cm de largo y ancho, glabros; semillas redondeadas, 3-4 mm de largo, glabras, café obscuras a cafés.

Sus raíces tuberosas, gruesas y alargadas, son comestibles y por ello se ha extendido su cultivo por las zonas tropicales y subtropicales del mundo. Sus hojas son y y sus flores son simpétalas.

Originaria de los trópicos de Sudamérica y América Central, ha sido cultivada desde hace 8000 años en lo que hoy es Perú, y se han hallado representaciones de camote en numerosos ceramios precolombinos y restos de las raíces tuberosas en algunas tumbas. 

Llegó a Europa a finales del siglo XV de manos de Cristóbal Colón, donde se sigue cultivando en localidades favorables como Vélez-Málaga, un municipio de la provincia de Málaga, donde en la actualidad se encuentra el mayor productor de la especie en Europa. Su cultivo se ha difundido ampliamente por todas las regiones del mundo en las que el clima lo permite. 

Según estadísticas de la FAO, al año 2009, China es el principal productor, pues cultiva aproximadamente el 80 % del total mundial; le siguen Uganda, Nigeria e Indonesia. Islas Salomón tiene la mayor producción "per cápita" del mundo: 160 kg por persona por año.

Es un alimento reconocido como eficaz en la lucha contra la desnutrición debido a sus características nutritivas, facilidad de cultivo y productividad.

Es una planta herbácea, perenne y trepadora. Prefiere los climas tropicales y subtropicales con temperaturas suaves (14-26ºC), suelos profundos y bien drenados, aunque con algo de humedad. Las horas y la intensidad del sol favorecen su desarrollo. Le perjudica el exceso de nitrógeno y es vulnerable a diversas plagas. Puede rotar y/o coexistir en cultivos mixtos con otras plantas de similares requerimientos (cebolla, yuca...). 

Suele multiplicarse por esqueje y en menor medida por plantación de raíces. Se practica la poda para favorecer la proliferación de raíces y, con ellas, de los tubérculos que constituyen la parte nutritiva.

Esta planta tiene su origen en la región neotropical, donde de las muchas variedades que existen las más consumidas son la blanca, la amarilla y la morada. 

El camote o batata, nativo de América, fue difundido en Polinesia por contactos intercontinentales entre Oceanía y América. El camote se ha fechado por radiocarbono en la Islas Cook en el año 1000 de nuestra era, y se estima que fue llevado a la Polinesia central hacia el año 700, posiblemente por polinesios que habían ido y vuelto de Sudamérica. Desde ahí se propagó a Hawái y Nueva Zelanda. Es posible también que fuesen poblaciones indígenas de Sudamérica las que cruzando el océano Pacífico llevaron la batata a Polinesia. Esto es utilizado como una posible evidencia sobre el viaje del Inca Túpac Yupanqui hacia unas islas posiblemente de la polinesia. No hay datos que indiquen que la planta pudiera haberse expandido espontáneamente mediante semillas que hubiesen cruzado flotando el océano Pacífico. Además, las variedades cultivadas de "Ipomoea batatas" en Polinesia se multiplican mediante esquejes y no por semillas.

La raíz contiene grandes cantidades de almidón, vitaminas, fibras (celulosa y pectinas) y minerales, y destaca entre estos el contenido de potasio. En valor energético supera a la patata y en vitaminas se destaca por la provitamina A (betacaroteno) y las B1, C (ácido ascórbico) y E (tocoferol). Cuanto más amarillenta es su raíz, más betacaroteno posee, por lo que las batatas con esta coloración son muy utilizadas en Asia y África para reducir la deficiencia de vitamina A en los niños. Su sabor dulce se lo debe a la sacarosa, la glucosa y la fructosa.

Además, su raíz, si bien no posee altos contenidos de proteína, sí es importante en contenido de lisina. Por esto es que se la utiliza como complemento de algunas harinas de cereales. Su contenido de lípidos es bajo. Sus ácidos grasos principales son el linoleico, el oleico, el esteárico y el palmitoleico. Posee gran cantidad de fibra digerible, que acelera el tránsito intestinal, previene el cáncer de colon, controla el nivel de glucosa, reduce el nivel de colesterol y produce sensación de saciedad. Su piel y su pulpa poseen antioxidantes, por lo que previene enfermedades cardíacas, diabetes y cáncer.

En algunos países se valora su hoja para alimentar tanto a animales como vegetales, pues posee importantes niveles de hierro, provitamina A, vitamina B2, vitamina C y vitamina E, fibra dietaria y polifenoles.

Sirven para preparar dulces y postres en combinación con frutas como la guayaba, dado su sabor ligeramente dulce.

Debido a sus características interesantes como sustituto alimenticio de productos más pobres nutricionalmente, y a su similitud agrícola con productos consumidos en regiones necesitadas de mejoras alimenticias, esta raíz ha sido el objeto de estudios de implantación foránea. Mención particular merece el programa "VITA A", promovido por el Banco Mundial y el gobierno del Perú.

Como parte del Programa VITA A (vitamina A para África), desde el año 2001 se introdujeron variedades de camote anaranjado en países del continente africano y se lograron notables avances en las regiones de prueba.

Según informes proporcionados por las Naciones Unidas, en el Subsahara (África) existen por lo menos unos tres millones de menores con deficiencia de esta vitamina.

Las cualidades nutricionales del camote peruano como alimento eficaz en la citada lucha contra la desnutrición infantil fueron reconocidas con el premio internacional CGIAR Partnership Award.

Este alimento forma parte de la dieta mediterránea, ya que se puede encontrar en varios puntos de esta costa.

En 2003, el ganador del premio fue el Programa VITA A, que desarrolla el Centro Internacional de la Papa del Perú y que se aplica en siete países del continente africano.

El galardón es otorgado a los centros de investigación agrícola internacional y sus socios que demuestren una contribución efectiva al alivio de la deficiencia de micronutrientes.

El vicepresidente del Banco Mundial y presidente del Grupo Consultivo para la Investigación Agrícola Internacional (CGIAR), Ian Johnson, mencionó que la iniciativa peruana fue premiada por sus esfuerzos para aliviar la deficiencia de vitamina A mediante el consumo de camote.

Esta raíz tuberosa forma parte de la cocina típica de todos los países que lo cultivan desde épocas prehispánicas. Ya los mochicas hacia el año 200 d. C. representaban al camote en la cerámica.
En la cocina popular de Chile, el camote se mantiene plenamente vigente a través de la elaboración del dulce típico llamado "camotillo". Esta preparación se puede encontrar en algunas tiendas de dulces artesanales chilenos y en ferias libres, y consiste en una reducción de partes iguales de camote y de azúcar, aromatizados con vainilla y luego enfriados. Receta del Camotillo

En Puerto Rico la batata (nombre taíno) ha sido uno de los alimentos básicos por décadas. La cocinan asada, hervida o sancochada. Se come de desayuno con leche o café, con quesito de hoja (queso casero) y en viandas (batata, yautia, ñame, Solanum tuberosum, malanga) con bacalao, con carne, pollo o jamón. También se hacen dulces y postres como el flan de batata y las barritas de dulces típicos.

El camote es muy popular en el Perú y en muchos platos típicos reemplaza a la Solanum tuberosum, y forma parte indispensable de la gastronomía peruana. Se prepara en forma de fritura y cocida. El camote destaca como acompañamiento del cebiche, los chicharrones, mayormente frito, y también su inclusión en la pachamanca. En el caso del cebiche, se sirve hervido y pelado, mezclado con los mariscos o a un lado como acompañamiento para con su sabor dulce aliviar un poco la sensación del picante. En este país se conocen 2016 variedades.

En Perú se encuentra la mayor diversidad de variedades de camote del mundo, donde crece desde hace 10 000 años, al igual que en Centroamérica. El agricultor peruano puede cultivarlo casi todos los días del año. En el Perú, el camote se siembra en la costa, selva y valles interandinos ubicados entre 20 y 2000 metros sobre el nivel del mar. En estos últimos años, el área sembrada con este cultivo oscila entre 12 000 y 14 000 hectáreas (10 000 unidades agrícolas), con un volumen de producción de 190 000 a 224 000 toneladas (0.3% del valor bruto de producción agrícola) y un rendimiento promedio de 16 t/ha. Según registro de estadísticas, la mayor zona de producción de camote en el país es el departamento de Lima, en donde se concentra el 70% de la superficie cultivada. Las provincias de Huaral (800 ha) y Cañete (3500 ha) son las principales zonas productoras de camote, y ofrecen al mercado capitalino 120 000 toneladas métricas anuales. Los valles del norte chico Huacho, Barranca (Perú) y Pativilca poseen menor superficie de siembra (700 ha) y aportan alrededor 12 mil Tm. para los mercados de Lima.

Los valles costeros de Áncash cultivan aproximadamente 1,500 hectáreas que aportan al mercado capitalino 24 mil Tm. anuales. En cambio, los valles costeros de los departamentos de Lambayeque y La Libertad registran una superficie de siembra de 2300 ha, las cuales aportan 25 000 Tm. al mercado regional del norte. En los valles de Ica y Arequipa se cultivan 1000 ha y se producen 16 000 Tm.

En la República Dominicana se come de muchas formas: asadas, salcochadas, con coco (jalea), con piña, con habichuelas con dulce, frita, también es común la elaboración de helados y otros postres. La República Dominicana es uno de los países en el mundo con más variedades de batata.

En México el camote se consume generalmente como confitura (fruta cristalizada) o como postre (compota), y ocasionalmente, como alimento para los bebés, debido a su facilidad de digestión. Los dulces de camote son un símbolo de la cultura culinaria del estado de Puebla. El camotero, quien vende en un carro de mano metálico, hornea el camote y el plátano macho en un horno de leña, los vende agregando leche condensada dulce. Se sabe cuándo viene el camotero por el aroma a camote y plátano asados, y con el sonido agudo del silbato que emite, con la misma técnica de silbato empleada por una locomotora de vapor.

En los Estados Unidos es muy consumido caramelizado como acompañante en la cena del Día de Acción de Gracias.

En Canarias (donde se la conoce como batata), forma parte de varios platos de su gastronomía tradicional, como el puchero y el sancocho canarios, así como uno de los posibles rellenos de las "truchas" (empanada dulce típica de la Navidad). En la Comunidad Valenciana se utiliza para los pasteles de boniato que se comen típicamente en Navidad. Una variante de éstos, también navideña, que se consume en gran parte de la España interior son los populares "pasteles de gloria" o simplemente "glorias", en los que el mazapán envuelve a la masa de boniato. En Aragón y en Cataluña suele consumirse durante todo el otoño, pero sobre todo durante la festividad de la Castañada que se lleva a cabo en los días comprendidos entre el 1 de noviembre (Todos los Santos) y el 11 de noviembre (San Martín) (puede celebrarse, también en fechas cercanas). Se toma como acompañamiento, por supuesto, de castañas asadas al fuego o al horno y de los típicos Empiñonados. También de los tradicionales Panellets en Cataluña y en la zona de la Franja; o como ingrediente base para la pasta de estos, aunque se puede hacer también de patata. Se le conoce comúnmente como boniato.

En Cuba se consume habitualmente en los almuerzos. 

Se puede comer de diversas maneras, la más extendida de las cuales es el boniato hervido; no se debe descartar el boniato frito o el boniato en almíbar, exquisitos al paladar. También el puré de boniato (hervido) con ralladuras de nuez moscada, para acompañar platos de carne o de otro tipo, de manera similar al puré de patata. La variedad cubana tiene un color gris verdoso después de ser cocido en agua. También se consume el "boniatillo" (dulce), hecho de boniato cremado con leche de coco y con canela en polvo. 

En Argentina, Paraguay y Uruguay la batata (boniato en Uruguay o Camote en San Pedro) es parte de comidas populares, por ejemplo como uno de los ingredientes del puchero (guiso de verduras, patatas, choclo y carne, entre otros) o acompañamientos (batatas fritas o puré de batatas), y también para postres como el conocido postre vigilante, que consiste en una porción de queso pategrás (en Argentina conocido como Mar del Plata o queso Holanda; en Uruguay, queso fresco) y una de dulce de batata. El semisólido dulce de batata es uno de los preferidos por los rioplatenses (muchas veces mezclado con chocolate o con frutas dulces). También se hacen mermeladas. En algunas partes de la región se les llama camote, aunque es más comúnmente llamado batata en toda la Argentina; las batatas cocidas al rescoldo en las "fogaratas" (fogatas) de la noche de San Juan han sido tradicionales en los pueblos y barrios argentinos. En Uruguay se lo suele preparar en almíbar para conservarlo y servirlo como postre.

En Brasil es el cuarto vegetal más cultivado en el país. Se suele consumir simplemente hervida, sola o como acompañamiento, frita y salada

A pesar de que generalmente se consumen en el almuerzo, la "batata-doce" (pronuncia-se , literalmente "patata dulce") es apreciada por los brasileños en el desayuno, el té-por-la-mañana, el té-por-la-tarde o también en las cenas.

Se consume generalmente hervido como acompañante de guiso de pescado seco desmechado (principalmente en los estados Sucre y Monagas) de la misma manera como se hace con el ocumo chino. También se consume frita en lascas como si se tratase de papas e incluso es posible preparar un dulce con papelón llamado conserva de batata/chaco. Así mismo, se pueden también preparar buñuelos similares a los de yuca. Incluso, se puede preparar el famoso dulce de batata llamado en este país Juan Sabroso. En la población de Pantoño es común consumirla a la brasa, colocandola al fuego hasta cabonizarla parcialmente, retirando luego la cubierta carbonizada; de esta forma se acompaña con coco, y ocasionalmente con papelón. En la misma población y en Cariaco y zonas vecinas, el plato típico es el machucado, una especie de crema ó potaje compuesto por frijol blanco, auyama, leche de coco y batata, todos parcialmente triturados. Otra forma común de consumir la batata ó chaco en el estado Sucre es en forma de postre ó merienda llamada "malarabia" ó "mal de rabia", una especie de jalea endulzada con azúcar a la que se le da un tono picante agregándole jengibre y pimienta.

La batata de pulpa morada sirve para la elaboración de jugos y de colorantes alimenticios. También se analiza la posibilidad de utilizar los residuos industriales de la batata para producir aditivos de alimentos o suplementos nutricionales como fuente de fibras y antioxidantes. En Japón se la usa como materia prima para la fabricación de almidón y se aprovechan los residuos de esta producción para usarlos como fibra alimentaria. También son usadas en ese país como medicina para la diabetes y otras enfermedades.

Las raíces sirven para la fabricación de productos fermentados (vino, butanol, ácido láctico, acetona y etanol). 

Mediante la extracción de almidón y su conversión en azúcares se produce ácido láctico que, polimerizado, refinado y moldeado, permite obtener bioplástico. 

"Ipomoea arborescens" fue descrito por (L.) Lam. y publicado en "Tableau Encyclopédique et Methodique ... Botanique" 1: 465. 1793.

Ipomoea: nombre genérico que procede del griego "ips", "ipos" = "gusano" y "homoios" = "parecido", por el hábito voluble de sus tallos. 

batatas: epíteto latíno que significa "batata".

El nombre "boniato" proviene de una voz caribeña, mientras que "camote" proviene del náhuatl "camohtli". La palabra "batata" tiene origen taíno.

En suma, puede tener los siguientes nombres en español: bataca, batata, boniato, buniato, camote, moniato, moniatos, patata de Málaga, patata dulce y minina. 

En el oriente de Venezuela recibe el nombre de chaco, probablemente originario de lengua guaiquerí.





</doc>
<doc id="17563" url="https://es.wikipedia.org/wiki?curid=17563" title="Won">
Won

Won (원; 圓; McCune-Reischauer "wŏn"; Romanización revisada: "won") es la moneda oficial de Corea del Sur y Corea del Norte. Sin embargo, sus cambios no son iguales. 
¹Aquí se muestra el tipo de cambio a 30 de octubre de 2016.

Históricamente, el won estaba dividido en 100 jeon (전; 錢; McCune-Reischauer: "chŏn"; Romanización revisada: "jeon"; en Corea del Norte también se romaniza como "jun"). En Corea del Sur ya no se emplean, debido a que la cantidad más pequeña de dinero que normalmente cambia de manos es de 100 won, (unos 8 centavos de dólar estadounidense); y la moneda más pequeña en circulación es de 10 won (menos de un centavo). 

Los coreanos también emplean la palabra "jeon" para traducir las palabras “céntimo” y “centavo”, y en este contexto puede acompañar a "bul", que significa “dólar”.

El won se convirtió en la moneda de Corea del Norte el 6 de diciembre de 1947, sustituyendo al yen coreano que estaba todavía en circulación. El won de Corea del Norte estaba dirigido exclusivamente a los ciudadanos de Corea del Norte, y el Banco de Comercio (무역 은행) emitió una moneda independiente (o certificados de divisas) para los visitantes, al igual que muchos otros estados socialistas. Sin embargo, Corea del Norte realizó dos tipos de certificados de divisas, uno para los visitantes de los “países socialistas”, que eran de color rojo y de ahí el apodo de “won rojo”, y la otra para los visitantes de “países capitalistas”, que fueron de color azul/verde y por lo tanto conocido como “won azul”. Los certificados de divisas se utilizaron hasta 1999, y fueron abolidos oficialmente en 2002, en favor del pago de los visitantes directamente con divisas, especialmente el euro.

Durante la época colonial, el won se sustituyó a la par por el yen.
En 1945, después de la Segunda Guerra Mundial, Corea fue dividida, resultando en dos monedas diferentes, ambas llamadas won, por el Sur y el Norte. Tanto el won del Sur como del Norte sustituyeron al yen a la par. El primer won surcoreano se subdividió en 100 Jeon.

El won surcoreano se fijó inicialmente al dólar de EE. UU. a una tasa de ₩ 15 = 1 dólar.


</doc>
<doc id="17567" url="https://es.wikipedia.org/wiki?curid=17567" title="Yogur">
Yogur

El yogur —también conocido como yogurt, yogourt, yoghurt, yoghourt, yogurth o yagurt, aunque la Real Academia Española (RAE) recomienda la forma «yogur»— es un producto lácteo obtenido mediante la fermentación bacteriana de la leche.

Si bien se puede emplear cualquier tipo de leche, la producción actual usa predominantemente leche de vaca. La fermentación de la lactosa (el azúcar de la leche) en ácido láctico es lo que da al yogur su textura y sabor tan distintivo. A menudo, se le añade chocolate, fruta, vainilla y otros saborizantes, pero también puede elaborarse sin añadirlos.

La palabra «yogur» proviene del término turco "yoğurt" (pronunciado ), que a su vez deriva del verbo "yoğurmak", 'amasar', en referencia al método de preparación; la letra ğ es casi muda entre vocales en el turco moderno, pero antiguamente se pronunciaba como una fricativa velar sonora, tal como se pronuncia en español.

El origen del yogur se sitúa en Turquía aunque también hay quien lo ubica en los Balcanes, Bulgaria o Asia Central. Su nombre tiene el origen en un término búlgaro: “iaurt“. Se cree que su consumo es anterior al comienzo de la agricultura.

Los pueblos nómadas transportaban la leche fresca que obtenían de los animales en sacos generalmente de piel de cabra. El calor y el contacto de la leche con la piel de cabra propiciaba la multiplicación de las bacterias ácidas que fermentaban la leche. La leche se convertía en una masa semisólida y coagulada. Una vez consumido el fermento lácteo contenido en aquellas bolsas, éstas se volvían a llenar de leche fresca que se transformaba nuevamente en leche fermentada gracias a los residuos precedentes.

El yogur se convirtió en el alimento básico de los pueblos nómadas por su facilidad de transporte y conservación. Sus saludables virtudes eran ya conocidas en la Antigüedad. Unos siglos más tarde se descubriría su efecto calmante y regulador intestinal. Metchnikoff, que recibió el premio Nobel en 1908, fue el primer científico en intuir los efectos del yogur en la flora intestinal. Demostró que el yogur contenía bacterias capaces de convertir el azúcar de la leche -lactosa- en ácido láctico y que este ácido hacía imposible el desarrollo de bacterias dañinas en el intestino derivadas de la descomposición de los alimentos. También descubrió la enorme cantidad de vitaminas del grupo B que contiene el yogur.

Existen pruebas de la elaboración de productos lácteos en culturas que existieron hace 4500 años. Los primeros yogures fueron probablemente de fermentación espontánea, quizá por la acción de alguna bacteria del interior de las bolsas de piel de cabra usadas como recipientes de transporte de la leche.

Las bacterias "Lactobacillus bulgaricus" y "Streptococcus thermophilus", responsables de la fermentación de la leche, ya eran utilizadas, hacia el 6000 o , por los tracios que vivían en la actual Bulgaria. Fueron ellos quienes las utilizaron para inducir la fermentación de la leche de oveja y de esa forma obtener yogur, queso, etc. dichos productos son los primeros alimentos probióticos en el mundo.

Desde Turquía se introdujo en la totalidad de la península balcánica. El reconocido científico ruso, fundador de la ciencia de la inmunología y premio Nobel, Iliá Méchnikov, describe el yogur como un excelente agente antienvejecimiento.

La bacteria que contiene éste, ataca, bloquea y neutraliza las toxinas, depurando el organismo. La bacteria causante de la fermentación láctica fue descubierta en 1903 por el doctor búlgaro Stamen Grigoroff, quien publicó y presentó su trabajo científico dedicado al yogur ante el Instituto Pasteur de París, Francia. En su honor, la nueva bacteria descubierta fue llamada inicialmente "Bacterium bulgaricum Grigoroff", aunque después pasó a denominarse "Lactobacillus bulgaricus".

La bacteria, como afirmaba el científico, bloquea la proliferación de otras que son patógenas, con lo que retrasa el proceso de envejecimiento del organismo humano. Lo más sorprendente es que el "Lactobacillus bulgaricus" desarrolla las citadas cualidades y características solo en el territorio de Bulgaria. Trasladada a otras latitudes, la bacteria se transforma y, aunque el yogur obtenido con esa misma bacteria tiene un sabor similar al búlgaro original, sus propiedades no son las mismas, perdiendo incluso su capacidad para retrasar el proceso de envejecimiento. Por consiguiente, se hace necesaria la adquisición del agente fermentador búlgaro original.

El yogur permaneció durante muchos años como comida propia de India, Asia Central, Sudeste asiático, Europa central y de Europa del Este y Turquía hasta los años 1900, cuando un biólogo ruso llamado Elías Méchnikov expuso su teoría de que el gran consumo de yogur era el responsable de la alta esperanza de vida de los campesinos búlgaros. Considerando que los lactobacilos eran esenciales para una buena salud, Mechnikov trabajó para popularizar el yogur por toda Europa. Otros investigadores también realizaron estudios que contribuyeron a la extensión de su consumo.

El proceso de elaboración del yogur data de hace miles de años, sin embargo hasta el siglo XIX se conocían muy pocas fases del proceso productivo. El arte de producción era transmitido de generación en generación; sin embargo en las últimas décadas, este proceso se ha racionalizado, principalmente por los descubrimientos en diversas disciplinas, como la física e ingeniería química, la bioquímica y enzimología; y sobre todo la tecnología industrial.

La elaboración de yogur requiere la introducción de bacterias ‘benignas’ específicas en la leche bajo una temperatura y condiciones ambientales controladas (muy cuidadosamente en el entorno industrial). El yogur natural o de sabores de textura firme, requiere de una temperatura de envasado de aproximadamente 43 °C. y pasar por un proceso de fermentación en cámaras calientes a 43 °C. para obtener el grado óptimo de acidez; este proceso puede llegar a durar aproximadamente cuatro horas. Una vez obtenida, debe enfriarse hasta los 5 grados para detener la fermentación. En los yogures batidos, los de textura cremosa, con o sin frutas, el proceso es diferente, en cuanto la fermentación se realiza en depósitos, previo al proceso de envasado, que se realiza en frío, por lo que no necesita de fermentación posterior. Las bacterias utilizan como fuente de energía la lactosa o azúcar de la leche, y liberan ácido láctico como producto de desecho; este provoca un incremento de la acidez que hace a su vez que las proteínas de la leche precipiten, formando un gel. La mayor acidez (pH 4-5) también evita la proliferación de otras bacterias potencialmente patógenas. El primer estudio bacteriológico acerca del yogur fue realizado por Grigoroff, quien detectó la presencia de tres distintos microorganismos, "diplostreptococcus".

Generalmente en un cultivo se incluyen dos o más bacterias diferentes para conseguir una fermentación más completa, principalmente "Streptococcus thermophilus subsp. salivarius", miembros del género "Lactobacillus", tales como "L. bulgaricus" y "L. casei", y del género "Bifidobacterium" (antes denominadas "L. bifidus"). Gracias a Metchnikoff, el yogur alcanzó gran popularidad por el postulado de que el "L. bulgaricus" prolongaba la vida. Para muchos países en sus normativas, el yogur como tal solo puede contener "St. thermophilus subsp. salivarius" y "Lactobacillus delbrueckii subsp. bulgaricus"; si se agregan otras bacterias, algunas legislaciones, no permiten utilizar la denominación de yogur.

Si el yogur no se calienta hasta matar a las bacterias después de la fermentación, se vende bajo la denominación de «cultivo activo vivo» (o simplemente «vivo» en algunos países), que algunos consideran nutricionalmente superior. En España los productores de yogur se dividían entre los que querían reservar la denominación "yogur" para el yogur vivo y los que deseaban introducir el yogur pasteurizado bajo esa etiqueta.

La vida comercial del yogur estando en refrigeración es de tres semanas. Con la finalidad de mejorar la capacidad de conservación del mismo se crea el yogur pasteurizado o de larga duración, que tiene un periodo de conservación de meses y no necesita refrigeración. Ambas partes enviaron estudios científicos a las autoridades esgrimiendo las diferencias o las similitudes (según los intereses de cada parte) entre las dos variedades. Finalmente el gobierno francés permitió la etiqueta «yogur pasteurizado» a esta clase de yogur en lugar del antiguo «postre lácteo».

Debido a que las bacterias fermentan la lactosa contenida en la leche durante el proceso de elaboración del yogur, los individuos que presentan intolerancia a la lactosa pueden disfrutar del yogur sin verse afectados. Nutricionalmente el yogur es rico en proteínas procedentes de la leche. También contiene la grasa de la leche con la que se produjo. Pueden ser desnatados o con nata añadida como en el caso del yogur griego. En el proceso de fermentación, los microorganismos producen vitaminas del grupo B necesarias para su metabolismo, aunque reducen el contenido de algunas ya presentes en la leche como la vitamina B y vitamina C. Contiene minerales esenciales, de los que destaca el calcio, como en cualquier producto lácteo.



</doc>
<doc id="17572" url="https://es.wikipedia.org/wiki?curid=17572" title="Jeff Buckley">
Jeff Buckley

Jeffrey Scott "Jeff" Buckley (Anaheim, California, Estados Unidos, 17 de noviembre de 1966 - Memphis, Tennessee, Estados Unidos, 29 de mayo de 1997) fue un cantautor estadounidense de folk rock, considerado una de las mejores voces de la música de todos los tiempos. Es reconocido por haber sido un intérprete muy virtuoso, por su potente rango vocal cuatro octavas y media; y por su primer y único álbum de estudio, titulado "Grace" en 1994; que es considerado una obra maestra de todos los tiempos, especialmente por su sensibilidad interpretativa única, siendo reconocido tanto por la crítica como por músicos como Bob Dylan y Radiohead, y la crítica lo consideró uno de los artistas más prometedores de su generación. Sin embargo, en la cima de su popularidad, muere ahogado mientras nadaba en el Río Wolf (Tennessee) a la altura de la ciudad de Memphis. Los críticos y los músicos aún reconocen su trabajo y estilo. Fue hijo del también cantautor Tim Buckley (1947–1975).

Nacido en Los Ángeles, California, Jeff Buckley fue el único hijo de Mary Guibert y Tim Buckley. Su padre era compositor y publicó una serie de discos de folk y jazz muy aclamados a finales de los 60's y principios de los 70's. Su madre era de ascendencia panameña, y su padre provenía de una familia de emigrantes irlandeses de Cork. Buckley se crio con su madre y su padrastro, Ron Moorhead, en el sur de California, moviéndose continuamente por el condado de Orange. También tenía un hermanastro, Corey Moorhead (quien llamó a su primer hijo varón Jeffrey James, en honor a Buckley). Durante su infancia fue conocido como Scott "Scottie" Moorhead pero cuando tenía aproximadamente diez años, decidió tomar su nombre de nacimiento tras conocer a su padre (a quien no volvió a ver), aunque para su familia siguió llamándose Scottie.

A los dieciocho años se trasladó a Los Ángeles, donde se graduó en el curso de dos años del "Musician's Institute". Buckley siempre se refirió a su paso por este centro como una "pérdida de tiempo", aunque hizo amigos de por vida allí. Su bagaje musical se reflejó en aquellas bandas en las que participó antes de iniciar su carrera en solitario. En Los Ángeles formó parte de la banda de reggae de Shinehead, así como en otras bandas en las que normalmente se limitaba a tocar la guitarra. Todavía tenía que descubrir su espléndida voz, al igual que sus propios compañeros de grupo.

Buckley se trasladó a Nueva York en 1990. Su debut en público como cantante fue una actuación en 1991, un tributo a su padre, Tim Buckley, en la iglesia de St. Ann de Nueva York. No se le pagó como intérprete. Simplemente eligió mostrar sus respetos a su padre diciendo: "Esto no es un trampolín, esto es algo muy personal". Interpretó «I Never Asked To Be Your Mountain» con un amigo llamado Gary Lucas, acompañándole a la guitarra, y cantó una versión a capella de «Once I Was», que dejó al auditorio en completo silencio. Cuando se le preguntó por este concierto en particular, Buckley contestó que "no era mi trabajo, no era mi vida. Pero me sentía mal por no haber estado presente en su funeral (de su padre), de que nunca tuve la oportunidad de decirle nada. Aproveché ese concierto para mostrarle mis últimos respetos".

Buckley se convirtió pronto en intérprete solista habitual en el café Sin-é de Greenwich Village, donde atrajo la atención de los ejecutivos de Columbia Records. En 1993 Columbia publicó un EP de cuatro temas grabados en el café Sin-é.

Buckley tocó con el guitarrista experimental Gary Lucas y su banda Gods and Monsters. En 1994, Buckley publicó su disco debut "Grace", compuesto por diez canciones.Las ventas progresaban lentamente, pero el álbum enseguida recibió las alabanzas de la crítica y el aprecio de otros músicos (entre ellos Jimmy Page, Robert Plant, Bob Dylan, Thom Yorke, Neil Peart y Paul McCartney). Muchos consideran su versión del «Hallelujah» de Leonard Cohen como la grabación definitiva de dicha canción y probablemente sea la más conocida de Buckley.

El intento de Buckley de preservar su integridad artística y creativa frente a las exigencias intolerables de la industria discográfica le llevó a una situación insoportable. Tras la publicación de su primer y aclamado disco, Buckley pasó más de dos años de gira por todo el mundo. Parecía ser una forma agotadora pero eficaz de mantener la independencia de su compañía discográfica, con la que mantenía una relación bastante tensa. En 1995 Buckley realizó un concierto en el Olympia de París, un local que había hecho famosa a la cantante francesa Édith Piaf y que él consideró el mejor de toda su carrera.

También realizó una gira conocida como "Phantom Solo Tour". La inició en diciembre de 1996 utilizando diversos seudónimos como Father Demo, Jaime de Cevallos, Topless America, Smackcrobiotic, The Halfspeeds, Crackrobats, y Martha and the Nicotines. Como justificación a tan misteriosa gira, Buckley publicó una nota en internet argumentando que había perdido el anonimato de tocar en pequeños locales y cafés:

Durante toda su carrera, Buckley hizo varios covers sobre escena de sus artistas preferidos: Bob Dylan, The Smiths, Siouxsie Sioux, Leonard Cohen, Bad Brains, MC5, entre otros.

Buckley murió el 29 de mayo de 1997, a la edad de treinta años, ahogado en el río Wolf en Tennessee. Su muerte estuvo envuelta en misterio, debido a si se trató de un accidente imprudente o si se suicidó a causa del trastorno bipolar que padecía. Los testimonios que entregan mayores antecedentes respecto a los sucesos que rodearon su muerte, son la biografía escrita por David Browne (“Dream Brother”) y un documental emitido por la BBC en 2002, donde se narran los hechos acontecidos aquella fatídica noche del 29 de mayo de 1997. Según estos relatos, Buckley había viajado hasta Memphis, para grabar su segundo disco, que llevaría por nombre “My Sweetheart The Drunk”, y esa noche llegaría su banda a la ciudad para comenzar el proceso de grabación.

Por lo general, Gene Bowen (Road Manager de Buckley) lo acompañaba a todos lados para evitar que se metiera en problemas, sin embargo, esa noche Jeff decidió salir a dar una vuelta, acompañado por el roadie Keith Foti. Al parecer habrían recorrido toda la ciudad escuchando canciones de John Lennon y Jane's Addiction en un grabador doble casetera que Foti había comprado el día anterior. Cuando decidieron ir a la sala de ensayo para esperar a la banda, se dieron cuenta que estaban perdidos, al cabo de una hora de infructuosos esfuerzos por llegar a la Young Avenue, decidieron llamar a Bowen para pedirle que los ayudara a encontrar el camino, sin embargo, no pudieron contactarlo, ya que se había ido al aeropuerto a recibir al resto de los músicos. Fue en ese instante que Buckley tuvo la idea de que fueran a la ribera del Rio Wolf para tocar guitarra y seguir escuchando música.

El río no era apto para el baño, pero no existían carteles de advertencia que informaran de un potencial riesgo. Además, Buckley ya había nadado antes ahí. Mientras Foti tocaba la guitarra, Jeff tomó el grabador y caminó hasta la orilla del río, dejando el dispositivo bastante cerca del agua. Alrededor de las nueve de la noche y en un acto inexplicable, Buckley se metió al agua completamente vestido, inclusive con sus botas puestas, y a medida que se iba internando a lo más profundo del río, comenzó a interpretar «Whole Lotta Love» de Led Zeppelin. En un momento, Foti movió de lugar el grabador para evitar que fuese a mojarse con las olas que produjo un barco que pasaba por el sector y al levantar la vista, Jeff ya había desaparecido. El cuerpo de Buckley fue encontrado desnudo cinco días después, al final de Beale Street, y sólo pudo ser identificado por el característico piercing de su ombligo. La autopsia realizada posteriormente no reveló la presencia de alcohol ni drogas en su cuerpo.

Tras la muerte de Buckley, algunas de las demos grabadas para su segundo álbum fueron publicadas bajo el nombre de "Sketches for My Sweetheart the Drunk". Se han publicado otros tres discos con grabaciones en vivo, así como un DVD de un concierto en Chicago.

Jeff Buckley solía realizar con mucha frecuencia versiones propias de canciones de otros músicos, especialmente en sus presentaciones en vivo, de hecho así consiguió ser valorado como músico en sus comienzos. Generalmente, se trataba de canciones muy antiguas, simples (tocadas sólo con piano o guitarra) y de cantautores relativamente desconocidos, con un sonido de blues o jazz. La gran calidad interpretativa y vocal de Buckley le valía grandes elogios por estos covers, por su sensible y melancólica forma de cantar.

El más celebre es el de "Hallelujah", que si bien es de un cantautor muy importante como Leonard Cohen, realmente nunca fue una de sus canciones más destacadas. Sin embargo Buckley la transformó en un clásico. Pero también se destacan mucho los de canciones como "Lilac Wine" (inspirada en la versión de Nina Simone), "Corpus Christi Carol" (canción clásica del célebre compositor británico Benjamin Britten), incluidas en "Grace", "Je n'en connais pas la fin" (canción francesa clásica), I Know It's Over de The Smiths, I Shall Be Released (Bob Dylan), "The Other Woman" (inspirada por Nina Simone), "Calling You" (Bob Telson) y varios de Bob Dylan y Van Morrison; todas ellas interpretadas sólo con su guitarra eléctrica, sin distorsión alguna.

Una de las destacadas presentaciones en que se aprecia su especial forma de realizar covers fue la conocida como ""Live at Sin-é"", basada casi únicamente en covers y realizada en el café "Sin-é" Nueva York, en la que Buckley sólo toca acompañado de su guitarra eléctrica sin ningún otro músico adicional. Hasta entonces el músico aún no lanzaba ningún disco oficial y fue originalmente publicada en 1993, pero sólo unas cuantas canciones. En 2003 se lanzó la "Legacy Edition" con el show completo.

Músicos como Thom Yorke de Radiohead y Matthew Bellamy de Muse citan a Jeff Buckley entre sus influencias, y "Grace" ha sido laureado por artistas como Bob Dylan (uno de los ídolos de Buckley), Paul McCartney, Jimmy Page, Steven Wilson, Morrissey, Robert Plant, Chris Cornell de Soundgarden y Audioslave, Myles Kennedy, Neil Peart, Lana Del Rey

El trabajo de Buckley, aparentemente anómalo con su época, ha tenido una influencia enorme. Se han escrito numerosas canciones en su tributo, entre las que destacan "Teardrop" de Massive Attack con Elizabeth Fraser, "Memphis" de PJ Harvey, "Blind River Boy" de Amy Correia, "Memphis Skyline" de Rufus Wainwright, "Wave Goodbye" de Chris Cornell, "Song For A Dead Singer" del grupo belga Zita Swoon, varios temas del grupo de New Jersey Ours, etc. También es nombrado en la canción "Shakespeare" de la cantante y actriz Miranda Cosgrove. Vocalistas como Thom Yorke de Radiohead, Matt Bellamy de Muse y Chris Martin de Coldplay reconocen que su voz les influye.







Numerosos artistas han creado canciones como tributo a la vida y obra de Jeff Buckley. Entre ellas se encuentran:

 


</doc>
<doc id="17575" url="https://es.wikipedia.org/wiki?curid=17575" title="Objective-C">
Objective-C

Objective-C es un lenguaje de programación orientado a objetos creado como un superconjunto de C para que implementase un modelo de objetos parecido al de Smalltalk. Originalmente fue creado por Brad Cox y la corporación StepStone en 1980. En 1988 fue adoptado como lenguaje de programación de NEXTSTEP y en 1992 fue liberado bajo licencia GPL para el compilador GCC. Actualmente se usa como un lenguaje principal de programación para Mac OS X, iOS y GNUstep, además de Swift.

A principios de los 80, el software se desarrollaba usando programación estructurada. La programación estructurada se estableció para ayudar a dividir los programas en pequeñas partes, haciendo más fácil el desarrollo cuando la aplicación se volvía muy grande. Sin embargo, como los problemas seguían creciendo al pasar el tiempo, la programación estructurada se volvió compleja dado el desorden de algunos programadores para invocar instrucciones repetitivamente, llevando a código spaghetti y dificultando la reutilización de código.

Muchos vieron que la programación orientada a objetos sería la solución al problema. De hecho, Smalltalk ya tenía solucionados muchos de estos problemas: algunos de los sistemas más complejos en el mundo funcionaban gracias a Smalltalk. Pero Smalltalk usaba una máquina virtual, lo cual requería mucha memoria para esa época, y era demasiado lento.

Objective-C fue creado principalmente por Brad Cox y Tom Love a inicios de los 80 en su compañía Stepstone. Ambos fueron iniciados en Smalltalk mientras estaban en el Programming Technology Center de ITT en 1981. Cox se vio interesado en los problemas de reutilización en el desarrollo de software. Se dio cuenta de que un lenguaje como Smalltalk sería imprescindible en la construcción de entornos de desarrollo potentes para los desarrolladores en ITI Corporation. Cox empezó a modificar el compilador de C para agregar algunas de las capacidades de Smalltalk. Pronto tuvo una extensión para añadir la programación orientada a objetos a C la cual llamó «OOPC» ("Object-Oriented Programming in C"). Love mientras tanto, fue contratado por Shlumberger Research en 1982 y tuvo la oportunidad de adquirir la primera copia de Smalltalk-80, lo que influyó en su estilo como programador.

Para demostrar que se hizo un progreso real, Cox mostró que para hacer componentes de software verdaderamente intercambiables sólo se necesitaban unos pequeños cambios en las herramientas existentes. Específicamente, estas necesitaban soportar objetos de manera flexible, venir con un conjunto de bibliotecas que fueran utilizables, y permitir que el código (y cualquier recurso necesitado por el código) pudiera ser empaquetado en un formato multiplataforma.

Cox y Love luego fundaron una nueva empresa, Productivity Products International (PPI), para comercializar su producto, el cual era un compilador de Objective-C con un conjunto de bibliotecas potentes.

En 1986, Cox publicó la principal descripción de Objective-C en su forma original en el libro "Object-Oriented Programming, An Evolutionary Approach". Aunque él fue cuidadoso en resaltar que hay muchos problemas de reutilización que no dependen del lenguaje, Objective-C frecuentemente fue comparado detalladamente con otros lenguajes.

En 1998, NeXT licenció el Objective-C de StepStone (el nuevo nombre de PPI, el dueño de la marca Objective-C) y extendió el compilador GCC para dar soporte a Objective-C, al mismo tiempo que desarrolló las librerías AppKit y Foundation Kit sobre las que se basaron la interfaz de usuario y la interfaz de creación de NeXTstep. Mientras que las estaciones de trabajo de NeXT no consiguieron hacer un gran impacto en el mercado, las herramientas fueron ampliamente alabadas en la industria. Esto llevó a NeXT a abandonar la producción de hardware y enfocarse en las herramientas de software, vendiendo NeXTstep (y OpenStep) como una plataforma para la programación a medida.

El trabajo para extender GCC fue liderado por Steve Naroff, que se unió a NeXT proveniente de StepStone. Los cambios del compilador fueron puestos a disposición bajo términos de licencia GPL, pero no las librerías de tiempo de ejecución, dejando la contribución de código abierto inutilizable para el público general. Esto llevó a que otras compañías desarrollaran esas librerías bajo licencias de código abierto. Más tarde, Steve Naroff fue también un colaborador principal al trabajo de Apple de construir la interfaz de Objective-C Clang.

El proyecto GNU comenzó a trabajar en su implementación de Cocoa como software libre, llamado GNUstep y basado en el estándar de OpenStep. Dennis Glatting escribió el primer sistema en tiempo de ejecución de GNU Objective-C en 1992. El sistema GNU Objective-C, que ha sido usado desde 1993, es uno de los desarrollados por Kresten Krab Thorup cuando era un estudiante universitario en Dinamarca. Thorup también trabajó en NeXT desde 1993 hasta 1997.

Tras adquirir NeXT en 1996, Apple empleó OpenStep en su nuevo sistema operativo, Mac OS X. Este incluía Objective-C y la herramienta de desarrollo basada en Objective-C de NeXT, Project Builder (que luego se ha expandido y ahora se conoce por Xcode), así como la herramienta de diseño de interfaz, Interface Builder. La mayoría de la actual Cocoa API de Apple está basada en objetos de interfaz de OneStep, y es el entorno de desarrollo de Objective-C más usado para desarrollo activo.

En la WWDC de 2014, Apple anunció planes para reemplazar a Objective-C en el desarrollo de Cocoa por el nuevo lenguaje Swift, que es llamado "Objective-C sin la C".

Objective-C consiste en una capa muy fina situada por encima de C, y además es un "estricto superconjunto de C". Esto es, es posible compilar cualquier programa escrito en C con un compilador de Objective-C, y también puede incluir libremente código en C dentro de una clase de Objective-C.

Esto es, para escribir el programa clásico "Hola Mundo" para correr en consola, se puede utilizar el siguiente código:
El código anterior se diferencia de un código en C común por la primera instrucción #import, que difiere del #include del C clásico, pero la función printf("") es puramente C. La función propia de Objective-C para imprimir una cadena de caracteres en consola es NSLog(@""); utilizándola, el código anterior quedaría de la siguiente manera:

La sintaxis de objetos de Objective-C deriva de Smalltalk. Toda la sintaxis para las operaciones no orientadas a objetos (incluyendo variables primitivas, pre-procesamiento, expresiones, declaración de funciones y llamadas a funciones) son idénticas a las de C, mientras que la sintaxis para las características orientadas a objetos es una implementación similar a la mensajería de Smalltalk.

El modelo de programación orientada a objetos de Objective-C se basa en enviar mensajes a instancias de objetos. Esto es diferente al modelo de programación al estilo de Simula, utilizado por C++ y esta distinción es semánticamente importante. En Objective-C uno no "llama a un método"; uno "envía un mensaje", y la diferencia entre ambos conceptos radica en cómo el código referido por el nombre del mensaje o método es ejecutado. En un lenguaje al estilo Simula, el nombre del método es en la mayoría de los casos atado a una sección de código en la clase objetivo por el compilador, pero en Smalltalk y Objective-C, el mensaje sigue siendo simplemente un nombre, y es resuelto en tiempo de ejecución: el objeto receptor tiene la tarea de interpretar por sí mismo el mensaje. Una consecuencia de esto es que el mensaje del sistema que pasa no tiene chequeo de tipo: el objeto al cual es dirigido el mensaje (conocido como "receptor") no está inherentemente garantizado a responder a un mensaje, y si no lo hace, simplemente lo ignora y retorna un puntero nulo.

Enviar el mensaje method al objeto apuntado por el puntero obj requeriría el siguiente código en C++:

mientras que en Objective-C se escribiría como sigue:

Ambos estilos de programación poseen sus fortalezas y debilidades. La POO al estilo Simula permite herencia múltiple y rápida ejecución utilizando vinculación en tiempo de compilación siempre que sea posible, pero no soporta vinculación dinámica por defecto. Esto fuerza a que todos los métodos posean su correspondiente implementación, al menos que sean virtuales (aun así, se requiere una implementación del método para efectuar la llamada). La POO al estilo Smalltalk permite que los mensajes no posean implementación - por ejemplo, toda una colección de objetos pueden enviar un mensaje sin temor a producir errores en tiempo de ejecución. El envío de mensajes tampoco requiere que un objeto sea definido en tiempo de compilación. (Ver más abajo la sección tipado dinámico) para más ventajas de la ligadura dinámica.

Sin embargo, se debe notar que debido a la sobrecarga de la interpretación de los mensajes, un mensaje en Objective-C toma, en el mejor de los casos, tres veces más tiempo que una llamada a un método virtual en C++.

Objective-C requiere que la interfaz e implementación de una clase estén en bloques de código separados. Por convención, la interfaz es puesta en un archivo cabecera y la implementación en un archivo de código; los archivos cabecera, que normalmente poseen el sufijo .h, son similares a los archivos cabeceras de C; los archivos de implementación (método), que normalmente poseen el sufijo .m, pueden ser muy similares a los archivos de código de C.

La interfaz de la clase es usualmente definida en el archivo cabecera. Una convención común consiste en nombrar al archivo cabecera con el mismo nombre de la clase. La interfaz para la clase Clase debería, así, ser encontrada en el archivo Clase.h.

La declaración de la interfaz de la forma:

Los signos "más" denotan métodos de clase, los signos "menos" denotan métodos de instancia. Los métodos de clase no tienen acceso a las variables de la instancia.

Si usted viene de C++, el código anterior es equivalente a algo como esto:

Note que codice_1 demuestra la capacidad de nombrado de parámetro de Objective-C para la cual no existe equivalente directo en C/C++.

Los tipos de retorno pueden ser cualquier tipo estándar de C, un puntero a un objeto genérico de Objective-C, o un puntero a un tipo específico así como NSArray *, NSImage *, o NSString *. El tipo de retorno por defecto es el tipo genérico codice_2 de Objective-C.

Los argumentos de los métodos comienzan con dos puntos seguidos por el tipo de argumento esperado en los paréntesis seguido por el nombre del argumento. En algunos casos (por ej. cuando se escriben APIs de sistema) es útil agregar un texto descriptivo antes de cada parámetro.

La interfaz únicamente declara la interfaz de la clase y no los métodos en sí; el código real es escrito en la implementación. Los archivos de implementación (métodos) normalmente poseen la extensión ".m".

Los métodos son escritos con sus declaraciones de interfaz. Comparando Objective-C y C:

La sintaxis admite pseudo-nombrado de argumentos.

La representación interna de éste método varía entre diferentes implementaciones de Objective-C. Si myColor es de la clase Color, internamente, la instancia del método -changeColorToRed:green:blue: podría ser etiquetada como _i_Color_changeColorToRed_green_blue. La i hace referencia a una instancia de método, acompañado por los nombres de la clase y el método, y los dos puntos son reemplazados por guiones bajos. Como el orden de los parámetros es parte del nombre del método, éste no puede ser cambiado para adaptarse al estilo de codificación.

De todos modos, los nombres internos de las funciones son raramente utilizadas de manera directa, y generalmente los mensajes son convertidos a llamadas de funciones definidas en la librería en tiempo de ejecución de Objective-C – el método que será llamado no es necesariamente conocido en tiempo de vinculación: la clase del receptor (el objeto que envió el mensaje) no necesita conocerlo hasta el tiempo de ejecución.

Una vez que una clase es escrita en Objective-C, puede ser instanciada. Esto se lleva a cabo primeramente alojando la memoria para el nuevo objeto y luego inicializándolo. Un objeto no es completamente funcional hasta que ambos pasos sean completados. Esos pasos típicamente se logran con una simple línea de código:

La llamada a alloc aloja la memoria suficiente para mantener todas las variables de instancia para un objeto, y la llamada a init puede ser anulada para establecer las variables de instancia con valores específicos al momento de su creación. El método init es escrito a menudo de la siguiente manera:

Objective-C fue extendido en [[NeXT]] para introducir el concepto de [[herencia múltiple]] de la especificación, pero no la implementación, a través de la introducción de [[protocolo (programación orientada a objetos)|protocolos]]. Este es un modelo viable, ya sea como una clase base abstracta multi-heredada en C++, o como una "interfaz" (como en [[Lenguaje de programación Java|Java]] o [[C#]]). Objective-C hace uso de protocolos ad-hoc, llamados "protocolos informales", y el compilador debe cumplir los llamados "protocolos formales".

Objective-C, al igual que Smalltalk, puede usar [[Sistema de tipos#Tipado dinámico|tipado dinámico]]: un objeto puede recibir un mensaje que no está especificado en su interfaz. Esto se permite para incrementar la flexibilidad, ya que permite a un objeto "capturar" un mensaje y enviarlo a otro objeto diferente que pueda responder a ese mensaje apropiadamente, o del mismo modo reenviar el mensaje a otro objeto. Este comportamiento es conocido como reenvío de mensajes o delegación (ver más abajo). Alternativamente, un manejo de error puede ser usado en caso de que el mensaje no pueda ser reenviado. Si un objeto no reenvía un mensaje, lo responde o maneja un error entonces el sistema generará una excepción en tiempo de ejecución. Si los mensajes son enviados a "nil" (el puntero de objetos nulo), serán ignorados silenciosamente o elevarán una excepción genérica, dependiendo de las opciones del compilador.

La información tipada estáticamente puede ser añadida opcionalmente a variables. Esta información es luego comprobada a la hora de compilar. En las siguientes cuatro declaraciones se proveen tipos de información crecientemente específicos. Estas declaraciones son equivalentes en el tiempo de ejecución, pero la información adicional permite al compilador el avisar al programador si el argumento pasado no encaja con el tipo especificado.
- (void)setMyValue:(id)foo;
En la declaración anterior, "foo" puede ser de cualquier clase.
- (void)setMyValue:(id<NSCopying>)foo;
En la declaración anterior, "foo" puede ser una instancia de cualquier clase que satisfaga al protocolo "NSCopying".
- (void)setMyValue:(NSNumber *)foo;
En la declaración anterior, "foo" debe ser una instancia de la clase "NSNumber".
- (void)setMyValue:(NSNumber<NSCopying> *)foo;
En la declaración anterior, "foo" debe ser una instancia de la clase "NSNumber", y debe satisfacer al protocolo "NSCopying".

Objective-C permite el envío de un mensaje a un objeto que puede no responder. En lugar de responder o simplemente ignorar el mensaje, un objeto puede reenviar el mensaje a otro objeto que pueda responderlo. El reenvío puede ser usado para simplificar la implementación de ciertos [[Patrón de diseño|patrones de diseño]], como el [[Observer (patrón de diseño)|observer]] o el [[Proxy (patrón de diseño)|proxy]].

El tiempo de ejecución de Objective-C especifica un par de métodos en codice_3:

- (retval_t)forward:(SEL)sel args:(arglist_t)args; // con GCC
- (id)forward:(SEL)sel args:(marg_list)args; // con sistemas NeXT/Apple

- (retval_t)performv:(SEL)sel args:(arglist_t)args; // con GCC
- (id)performV:(SEL)sel args(marg_list)args; // con sistemas NeXT/Apple
Un objeto que desee implementar el reenvío solamente necesita sobreescribir el método de reenvío con un nuevo método que defina el comportamiento de reenvío. El método de acción codice_4 no necesita ser sobreescrito, ya que este método meramente realiza una acción basada en el selector y los argumentos. El tipo codice_5 es el tipo de mensajes en Objective-C.

Nota: en openStep, Cocoa y GNUstep, los espacios de trabajo de Objective-C comúnmente usados, no hay que usar la clase codice_3. el método codice_7 de la clase codice_8 es usado para realizar el reenvío.

Aquí hay un ejemplo de un programa que demuestra las bases del reenvío.



@interface Forwarder : Object {

// Métodos de acceso
- (id)recipient;
- (id)setRecipient:(id)_recipient;

@end

@implementation Forwarder
- (retval_t)forward:(SEL)sel args:(arglist_t) args {
- (id)setRecipient:(id)_recipient {
- (id) recipient {
@end

// Un simlpe objeto receptor.
@interface Recipient : Object
- (id)hola;
@end

@implementation Recipient
- (id)hola {
@end

int main(void) {

Cuando se compila con [[GNU Compiler Collection|gcc]], el compilador reporta:
$ gcc -x objective-c -Wno-import Forwarder.m Recipient.m main.m -lobjc

main.m: In function `main':

main.m:12: warning: `Forwarder' no responde a `hola'

El compilador reporta lo comentando antes, que codice_9 no responde a mensajes "hola". En esta circunstancia, es seguro ignorar el aviso ya que el reenvío fue implementando. La ejecución del programa produce esta salida:
& ./a.out

El receptor dice hola!

Objective-C++ es una variante del lenguaje aceptada por la interfaz del [[GNU Compiler Collection]] y [[Clang]], que puede compilar archivos de código fuente que usen una combinación de sintaxis de C++ y Objective-C. Objective-C++ añade a C++ las extensiones que Objective-C añade a C. Como no se hace nada para unificar la semántica detrás de las características de varios lenguajes, existen ciertas restricciones:

En la [[Worldwide Developers Conference]] de 2006, Apple anunció el lanzamiento de "Objective-C 2.0", una revisión del lenguaje Objective-C para incluir "una recolección de basura moderna, mejoras de sintaxis, perfeccionamiento de la ejecución y soporte para 64 bits". [[Mac OS X v10.5]], lanzado en octubre de 2007, incluía un compilador de Objective-C 2.0. [[GNU Compiler Collection|GCC 4.6]] soporta muchas aplicaciones nuevas de Objective-C, como las propiedades declaradas y sintetizadas, sintaxisd e puntos, enumeración rápida, métodos de protocolo opcionales, atributos de método/protocolo/clase, extensiones de clase y una nueva API de GNUnn Objective-C. 
Objective 2.0 contaba con un [[recolector de basura]] conservativo opcional. Cuando se ejecutaba en modo de [[retrocompatibilidad]], cambiaba las operaciones de [[conteo de referencias]] como "retener" y "liberar" en NOPs ("No operaciones", instrucción de ensamblador que indica que el procesador no tiene que hacer nada). Todos los objetos eran sometidos al recolector de basura cuando la recolección de basura estaba habilitada. Los punteros de C podían ser cualificados con "__strong" para provocar la intercepción de escritura del compilador y así participar en la recolección de basura. Un subsistema débil de puesta a cero también era provisto de tal manera que los punteros marcados con "__weak" eran puestos a cero cuando el objeto (o más fácilmente, la memoria del recolector de basura) es recolectado. El recolector de basura no existía en la implementación de Objective-C 2.0 de iOS. La recolección de basura en Objective-C se ejecuta en un hilo de baja prioridad y puede detener eventosd el usuario, con la intención de mantener la experiencia del usuario receptiva. 

La recolección de basura nunca estuvo disponible en iOS debido a problemas de rendimiento. Fue despreciado en la versión 10.8 de OS X en favor del Conteo de Referencias Automático (en inglés: "Automatic Reference Counting", ARC) y está programado que se elimine en una futura versión de OS X. Objective-C en [[iOS 7]] ejecutado en [[Arquitectura ARM|ARM64]] usa 19 bits de una palabra de 64 bits para almacenar el conteo de referencias, como una forma de puntero etiquetado.

Objective 2.0 introduce una nueva sintaxis para declarar variables de instancia como propiedades, con atributos opcionales para configurar la generación de métodos de acceso. Las propiedades son, en cierto sentido, variables de instancia públicas; esto es, declarar una variable de instancia como una propiedad provee a clases externas de acceso (posiblemente limitado, como por ejemplo "sólo lectura") a esa propiedad. Una propiedad puede ser declarada como "readonly" ("solo lectura") y puede ser provista de semántica de almacenamiento como "assign" ("asignar"), "copy" ("copiar") o "retain" ("retener"). Por defecto, las propiedades son consideradas atómicas, que resulta en un seguro para prevenir a múltiples hilos que accedan a ella al mismo tiempo. Una propiedad puede ser declarada como "nonatomic" ("no atómica"), que elimina este seguro.
@interface Persona : NSObject {

@property(copy) NSString *nombre;
@property(readonly) int edad;

-(id)iniciarConEdad:(int)edad;
@end
Las propiedades son implementadas mediante la palabra clave @synthesize, que genera los métodos getter (y setter, si no son de sólo lectura) de acuerdo a la declaración de la propiedad. Alternativamente, los métodos getter y setter deben ser implementados explícitamente, o la palabra clave @dynamic puede ser usada para indicar que los métodos de acceso deben ser provistos por otros medios. Cuando se compila usando Clang 3.1 o superior, todas las propiedades que no estén explícitamente declaradas con codice_10, no estén marcadas codice_11 o no tengan los métodos completos implementados por el usuario codice_12 y codice_13, serán automáticamente declaradas codice_14 de manera implícita.
@implementation Persona
@synthesize nombre;

-(id)iniciarConEdad:(int)edadInicial {

-(int)edad {
@end
Las propiedades pueden ser accedidas usando la sintaxis tradicional de paso de mensajes, notació por puntos o, en Codificación Key-Value, mediante los métodos codice_15/codice_16.
Persona *unaPersona = [[Persona alloc] iniciarConEdad: 53];
unaPersona.nombre = @"Steve"; // NOTA: la notación por puntos, usa el setter sintetizado,
NSLog(@"Acceso por mensaje (%@), notación por puntos(%@),
nombre de propiedad(%@) y acceso directo a la variabled e instancia (%@)",
Para que el uso de notación por puntos invoque a las propiedades de acceso en un método de instancia, la palabra clave "self" debe ser usada:
-(void) presentarmeConPropiedades:(BOOL)useGetter {
// NOTA: getter vs. acceso ivar

Una clase o las propiedades de protocolo pueden ser [[Introspección de tipos|introspeccionadas]] dinámicamente.
int i;
int contadorPropiedades = 0;
objc_propiedad_t *listaPropiedades = clase_copiarListaPropiedades([unaPersona class], &contadorPropiedades);

for (i = 0; i < contadorPropiedades; i++) {

Objective-C 2.0 provee de variables de instancia no frágiles soportadas por el entorno de ejecución (por ejemplo, creando código para un Mac OS X de 64 bits así como código para todos los iOS). Bajo el entorno de ejecución moderno, una capa extra de sesgo es añadida para instanciar variables de acceso, permitiendo al enlazador dinámico ajustar el plano de instanciaciones en tiempo de ejecución. Esta propiedad permite dos grandes mejoras en el código Objective-C:

En lugar de usar un objeto NSEnumerator o indicar la iteración a lo largo de una colección, Objective-C 2.0 ofrece la sintaxis de enumeración rápida. En Objective-C 2.0, los siguientes bucles son funcionalmente equivalentes, pero tienen diferentes características de rendimiento.
// Usando NSEnumerator
NSEnumerator *enumerador = [laGente objectEnumerator];
Persona *p;

while ((p = [enumerador nextObject]) != nil) {

// Usando índices
for (int i = 0; i < [laGente count]; i++) {

// Using enumeración rápida
for (Persona *p in laGente) {

La enumeración rápida genera código más eficiente que la enumeración estándar porque las llamadas a los métodos para enumerar objetos son reemplazadas por aritmética de punteros usando el protocolo NSFastEnumeration.

Una extensión de clase tiene el mismo sintaxis que una declaración de categoría sin nombre de categoría y los métodos y propiedades declarados en ella son añadidos directamente a la clase codice_17. Es sobre todo usado como una alternativa a una categoría el añadir métodos a una clase sin declararlos en las cabeceras públicas, con la ventaja de que para las extensiones de clase el compilador comprueba que todos los métodos declarados privadamente son implementados realmente.

Blocks es una extensión no estándar para Objective-C (así como para [[C (lenguaje de programación)|C]] y [[C++]]) que usa una sintaxis especial para crear [[Clausura (informática)|clausuras]]. Blocks sólo está soportado en [[Mac OS X v10.6|Mac OS X 10.6 "Snow Leopard"]] o superior y en [[iOS|iOS 4]] o superior, así como en GNUstep con libobjc2 1.7 y compilado con [[Clang]] 3.1 o superior. 
typedef int (^IntBlock)();

IntBlock MakeCounter(int start, int increment) {

int main(void) {
/* Output:

Automatic Reference Counting ("Conteo Automático de Referencias", ARC) es una característica del tiempo de compilación que elimina la necesidad de que los programadores tengan que guardar manualmente cuentas usando codice_18 y codice_19. Al contrario que el [[recolector de basura]], que funciona en tiempo de ejecución, el ARC elimina la sobrecarga de un proceso separado al gestionar la retención de las cuentas. El ARC y el manejo manual de memoria no son mutualmente excluyentes; los programadores pueden continuar usando código no ARC en proyectos que tienen el ARC activado mediante la desactivación del ARC para códigos fuente individuales. Xcode también puede tratar de actualizar automáticamente un proyecto a ARC.

Los entornos de ejecución NeXT y Apple Obj-C incluyeron hace tiempo un atajo para crear nuevas cadenas, usando la sintaxis literal codice_20 y también desecharon las constantes de CoreFoundation codice_21 y codice_22 por la variable codice_23 con valores booleanos. Al usar este formato se libera al programador de usar el más largo codice_24 o métodos similares al hacer ciertas operaciones.

Cuando se usa el compilador de Apple [[LLVM]] 4.0 o superior, vectores, diccionarios y números (las clases codice_25, codice_26 y codice_27) pueden ser también creados usando sintaxis literal en lugar de métodos. La sintaxis literal usa el símbolo codice_28 combinado con codice_29, codice_30 o codice_31 para crear las clases mencionadas anteriormente, respectivamente. 

Ejemplo sin literales:
NSArray *miVector = [NSArray arrayConObjectos:objeto1,objeto2,objeto3,nil];
NSDictionary *miDiccionario1 = [NSDictionary diccionarioConObjeto:unObjeto forKey:@"llave"];
NSDictionary *miDiccionario2 = [NSDictionary diccionarioConObjetosYLlaves:objeto1, llave1, objeto2, llave2, nil];
NSNumber *miNumero = [NSNumber numeroConInt:miInt];
NSNumber *miNumeroSuma = [NSNumber numeroConInt:(2 + 3)];
NSNumber *miNumeroBooleano = [NSNumber numeroConBooleano:YES];
Ejemplo con literales:
NSArray *myVector = @[ objeto1, objeto2, objeto3 ];
NSDictionary *miDiccionario1 = { @"llave" : unObjeto };
NSDictionary *miDiccionario2 = { llave1: objeto1, llave2: objeto2 };
NSNumber *miNumero = @{miInt};
NSNumber *miNumeroSuma = @{2+3};
NSNumber *miNumeroBooleano = @YES;
Sin embargo, al contrario que las cadenas literales que se compilan como constantes en el ejecutable, estos literales se compilan como código equivalente a las llamadas a métodos mencionadas arriba. En particular, bajo manejo manual del conteo de referencia de memoria, estos objetos son autoliberados, lo que requiere especial cuidado cuando por ejemplo son usados con variables de funciones estáticas o otros tipos de variables globales.

Cuando se usa el compilador de Apple [[LLVM]] 4.0 o superior, vectores y diccionarios (las clases codice_32 y codice_26) pueden ser manipuladas usando subíndices. Los subíndices se pueden usar para recuperar valores de índices (vectores) o llaves (diccionarios) y con objetos mutables también puede user para fijar objetos a índices o llaves. En el código, los subíndices son representados usando corchetes codice_34.

Ejemplos sin subíndices:
id objeto1 = [unVector objectAtIndex:0];
id objeto2 = [unDiccionario objectForKey:@"llave"];
[unVectorMutable replaceObjectAtIndex:0 withObject:objeto3];
[unDiccionarioMutable setObject:objeto4 forKey:@"llave"];
Ejemplos con subíndices:
id objeto1 = unVector[0];
id objeto2 = unDiccionario[@"llave"];
unVectorMutable[0] = objeto3;
unDiccionarioMutable[@"llave"] = objeto4;
Tras la compra de NeXT por parte de Apple, se hicieron varios intentos para asemejar más el lenguaje con respecto a otros lenguajes existentes. Uno de estos intentos fue la introducción de lo que se denominó en su momento "Sintaxis moderna" para Objective-C (en oposición a la existente, sintaxis "clásica"). No había cambios en el comportamiento real, simplemente era una sintaxis alternativa.
La invocación a un método se hacía de este modo:
objeto = (MiClase.alloc).init;
objeto.primeraEtiq ( param1, param2 );
Y paso a escribirse de este otro modo:
objeto = [[MiClase alloc] init];
[objeto primeraEtiq: param1 segundaEtiq: param2];
Similarmente, las declaraciones pasaron de ser así:
-(void) primeraEtiq ( int param1, int param2 );
a ser así:
-(void) primeraEtiq: (int)param1 segundaEtiq: (int)param2;
Esta sintaxis "moderna" no está soportada en dialectos actuales de Objective-C.

Además de las implementaciones de [[GNU Compiler Collection|GCC]]/[[NeXT]]/[[Apple]], que añadieron varias extensiones a la implementación original de Stepstone, también existe otra implementación [[Software libre y de código abierto|libre y abierta]] de Objective-C llamada Protable Object Compiler. El conjunto de extensiones implementadas por el Portable Object Compiler difiere de las implementaciones GCC/NeXT/Apple; en particular, incluye blocks similares a los de [[Smalltalk]] para Objective-C, mientras que carece de protocolos y categorías, dos características usadas ampliamente en OpenStep y sus derivados. En conjunto, POC representa una etapa vieja, pre-NeXT, de la evolución del lenguaje, simplemente conforme al libro de 1991 de Brad Cox.

También incluye una librería de tiempo de ejecución llamada ObjectPak, que está basada en la librería original ICPak101 de Cox (que a su vez deriva de la librería de clases Smalltalk-80) y es radicalmente diferente a la de OneStep FoundationKit.

El sistema PC GEOS usaba un lenguaje de programación conocido como GEOS Objective-C o goc; a pesar de su similar nombre, los dos lenguajes son similares en un concepto global y por el uso de palabras clave precedidas por el signo @.

La suite de compiladores [[Clang]], parte del proyecto [[LLVM]], implementa Objective-C así como otros lenguajes.



[[Categoría:Lenguajes de programación orientada a objetos]]
[[Categoría:Lenguajes de programación dinámicamente tipados]]
[[Categoría:Software de 1980]]

</doc>
<doc id="17580" url="https://es.wikipedia.org/wiki?curid=17580" title="Sistema octal">
Sistema octal

El sistema numérico en base 8 se llama octal y utiliza los dígitos del 0 al 7.
En informática a veces se utiliza la numeración octal en vez de la hexadecimal. Tiene la ventaja de que no requiere utilizar otros símbolos diferentes de los dígitos. Sin embargo, para trabajar con bytes o conjuntos de ellos, asumiendo que un byte es una palabra de 8 bits, suele ser más cómodo el sistema hexadecimal, por cuanto todo byte así definido es completamente representable por dos dígitos hexadecimales.

El sistema de numeración octal es un sistema de numeración en base 8, una base que es potencia exacta de 2 o de la numeración binaria. Esta característica hace que la conversión a binario o viceversa sea bastante simple. El sistema octal usa 8 dígitos (0, 1, 2, 3, 4, 5, 6, 7) y cada dígito tiene el mismo valor que en el sistema de numeración decimal.

El teorema fundamental aplicado al sistema octal sería el siguiente:

formula_1

formula_2

Como el sistema de numeración octal usa la notación posicional entonces para el número 3452,32 tenemos que: 
2*8 + 5*8 + 4*8 + 3*8 + 3*8 + 2*8 = 2 + 40 + 4*64 + 3*512 + 3*0,125 + 2*0,015625 = 2 + 40 + 256 + 1536 + 0,375 + 0,03125 = 1834 + 0,40625d

Entonces, 3452,32q = 1834,40625d

El sub índice "q" indica número octal, se usa la letra q para evitar confusión entre la letra 'o' y el número 0. En informática, a veces se utiliza la numeración octal en vez de la hexadecimal. Tiene la ventaja de que no requiere utilizar otros símbolos diferentes de los dígitos. Es posible que la numeración octal se usara en el pasado en lugar de la decimal, por ejemplo, para contar los espacios interdigitales o los dedos distintos de los pulgares.

Es utilizado como una forma abreviada de representar números binarios que emplean caracteres de seis bits. Cada tres bits (medio carácter) es convertido en un único dígito octal (del griego "oktō" 'ocho')
Esto es muy importante por eso.

La numeración octal es tan buena como la binaria y la hexadecimal para operar con fracciones, puesto que el único factor primo para sus bases es 2. Todas las fracciones que tengan un denominador distinto de una potencia de 2 tendrán un desarrollo octal periódico. 

Para poder convertir un número en base decimal a base octal se divide dicho número entre 8, dejando el residuo y dividiendo el cociente sucesivamente entre 8 hasta obtener cociente 0, luego los restos de las divisiones leídos en orden inverso indican el número en octal.

Ejemplo:

Escribir en octal del número decimal 730 

730÷8= 91.25 

91=cociente 

8 x 91= 728 

730 - 728= 2 

2= residuo 

91÷8= 11.375 

11=cociente 

8 x 11= 88 

91-88= 3 

3= residuo 

11÷8= 1 

1= cociente 

8 x 1= 8 

11-8= 3 

3= residuo 

1÷8= 0

0=cociente

8 x 0 = 0

1 - 0=1

1= residuo

octal del número decimal 730= 1332 

Escribir en octal el número decimal 179

179÷8= 22 

22= cociente 

8 x 22= 176 

179-176= 3

3= residuo

22÷8= 2

2=cociente

8x2= 16

22-16= 6

6= residuo

2÷8= 0

0= cociente

8x0= 0

2-0= 2

2= residuo

El octal del número decimal 179= 263

Para pasar de binario a octal, solo hay que agrupar de 3 en 3 los dígitos binarios, así, el número binario 1001010 (74 en decimal), lo agruparíamos como 1 / 001 / 010. como al primer dígito le hacen falta dos números para que se cumpla la regla de 3 en 3 le agregamos 2 ceros, de modo que quedaría

después obtenemos el número en decimal de cada uno de los paréntesis de los números en binario con la siguiente fórmula:

de derecha a izquierda visualiza un número del 0 al 2 en la parte superior del número binario, para indicar la posición del binario en el paréntesis:

210«< 

1. (001) posición 0 para el binario 1, posición 1 para el binario 0, posición 2 para el binario 0

210«<

2. (001)posición 0 para el binario 1, posición 1 para el binario 0, posición 2 para el binario 0

210«<

3. (010)posición 0 para el binario 0, posición 1 para el binario 1, posición 2 para el binario 0

Después se multiplica cada número binario por 2 elevado a la posición del número binario y cada resultado se suma:

001= 1

001= 1

010= 2

De modo que el número binario 1001010 en octal es 112.




</doc>
<doc id="17590" url="https://es.wikipedia.org/wiki?curid=17590" title="Sentencia judicial">
Sentencia judicial

La sentencia es una resolución judicial dictada por un juez o tribunal que pone fin a la litis (civil, de familia, mercantil, laboral, contencioso-administrativo, etc.) o causa penal.

La sentencia declara o reconoce el derecho o razón de una de las partes, obligando a la otra a pasar por tal declaración y cumplirla. En derecho penal, la sentencia absuelve o condena al acusado, imponiéndole la pena correspondiente.

El profesor de derecho procesal de la Pontificia Universidad Católica de Valparaíso, Sergio Alfaro Silva, la define así:





La sentencia debe reunir los requisitos de tiempo, lugar y forma. Debe dictarse en un periodo de tiempo apto para la realización de los actos del juez o tribunal. La fijación de este plazo varía según el procedimiento de que se trate.

Respecto de la forma, las sentencias generalmente se componen de tres secciones:




Por otro lado, las sentencias deben ser congruentes, es decir, deben resolver acerca de todas las cuestiones que hayan sido objeto de debate en el proceso. El fallo no debe contener más, ni algo distinto, de lo pedido por las partes. Cuando se trata de sentencias penales, la congruencia significa que debe mediar una relación entre la sentencia y la acción penal ejercitada. Por ejemplo, si una persona es acusada de homicidio, el juez no puede condenarle por robo (para ello haría falta aplicar otro procedimiento), ya que está limitado por los hechos alegados. Sin embargo, podría realizar una calificación jurídica diversa de la hecha por las partes, por ejemplo, en el mismo caso, condenar por asesinato o parricidio y no por homicidio.

Puede clasificarse la incongruencia en la sentencia por:
1) Falta de exhaustividad, omitiéndose el pronunciamiento sobre un tema debido.
2) Incongruencia ultrapetitum, concediéndose más de lo pretendido por el actor.
3) Incongruencia extrapetitum, concediéndose otra cosa y no lo pedido.

Los elementos de la estructura de una sentencia son preámbulo, resultando, considerando y puntos resolutivos. En las sentencias españolas su estructura es encabezamiento (nombre de las partes y sus datos, identificación de procurador y abogado, objeto del juicio, fecha, lugar y tribunal, jueces o magistrados, así como el ponente si es tribunal colegiado), antecedentes de hecho (en párrafos separados y numerados, exponiéndose las peticiones de las partes, los hechos en que las funden y las pruebas que se hubieran propuesto y practicado -hechos probados-), fundamentos de derecho (en párrafos separados y numerados, donde se apreciará el derecho que funda las pretensiones, con cita de las leyes o doctrina aplicables) y, finalmente, el fallo (que es la parte dispositiva, donde se resuelve el pleito).

La redacción de la sentencia corresponde al juez que la haya dictado (si se trata de un órgano jurisdiccional unipersonal) o a uno de sus miembros, si se trata de un órgano colegiado (en este caso, previa deliberación y votación de la sentencia por parte de los miembros del tribunal).

Una vez firmada la sentencia por el juez o por todos los miembros del tribunal, se da a conocer mediante lectura en audiencia pública o mediante notificación por escrito a las partes.

Dado que la sentencia es una resolución decisoria, en la mayoría de los casos es posible impugnarla mediante la segunda instancia que es integrada por los magistrados.

La ejecución de la sentencia es la puesta en marcha facticamente de lo decidido en el fallo. Corresponde normalmente al juez, que es el que controla cómo se ejecuta la misma, pero con intervención de los órganos de la Administración, concretamente, la Policía, que es la que realmente usando la fuerza hace cumplir el fallo del juez, y el consiguiente control de la ejecución del mismo por parte de éste.




</doc>
<doc id="17595" url="https://es.wikipedia.org/wiki?curid=17595" title="Atom Egoyan">
Atom Egoyan

Atom Egoyan () es un director de cine independiente, que vive y trabaja en Canadá y es de origen armenio. Algunos temas recurrentes de su trabajo son la alienación y la soledad, que trata mediante personajes cuyas interacciones están mediadas por la tecnología, la burocracia u otras estructuras de poder. Algunas de sus películas siguen estructuras sin linealidad cronológica, en las cuales los acontecimientos se organizan de manera no secuencial con el fin de provocar reacciones emocionales en el espectador ocultando la clave de la historia. Su primera película, "Next of Kin", data de 1984. Algunas cintas notables de su carrera son "Exotica", "El dulce porvenir", "Ararat" y "Where the Truth Lies".

Este armenio-canadiense inició su carrera con "Next of Kin" 1984, película que plantea la suplantación de una personalidad a través de la mentira. "Family Viewing" 1987, su segundo largometraje, sigue el camino ya trazado en su ópera prima: la familia como núcleo reductor y representativo de la sociedad. "Speaking Parts" (1989), según palabras del propio Egoyan, se mueve «en el terreno de la memoria y el deseo».

En la década siguiente se estrenó "El liquidador", de 1991, su película más compleja, que muestra la esencia emocional de unos personajes que hacen de sus trabajos una desasosegante catarsis vital de consecuencias inútiles. Tras rodar "Gross misconduct" 1992 para la televisión, vuelve al cine con "Calendar" 1993, travesía al interior de las relaciones entre un fotógrafo canadiense-armenio (encargado de confeccionar un calendario con las fotografías de doce antiguas iglesias de Armenia), su mujer y el guía que los acompaña. Pero será con "Exótica", en 1994, cuando llegue su consagración como autor de un extraordinario y muy personal estilo. Su definitiva proyección internacional se debe a su siguiente película, titulada "El dulce porvenir" de 1997, una fábula que investiga el sentimiento de culpa de los miembros de una comunidad rural que han perdido a sus hijos tras el hundimiento del autobús escolar en un lago. "El viaje de Felicia" 1999 es, con diferencia, su película más accesible, menos hermética, pero no por ello menos arriesgada que las anteriores.

Por su parte, "Ararat" de 2002 busca recrear el genocidio armenio perpetrado por la autoridad turco-otomana de los años 1910 mediante una historia dentro de otra historia. En 2005, el autor dirigió "Where the Truth Lies", un drama sobre una muerte acaecida en 1957 tras la que dos queridos y exitosos presentadores de una Teletón se separan definitivamente, completando el cuadro una reportera que investiga los hechos algunas décadas después. La cinta tuvo como protagonistas a Kevin Bacon y Colin Firth.

Tras varios años sin actividad se ha especulado sobre una posible remasterización de la antigua pero popular serie "Life with Derek", la cual puede estar ya filmándose.



</doc>
<doc id="17604" url="https://es.wikipedia.org/wiki?curid=17604" title="The Pillow Book">
The Pillow Book

The Pillow Book es una película de carácter iniciático dirigida por Peter Greenaway en 1996, cuyo título hace referencia a la costumbre japonesa de guardar en las almohadas, que eran de cerámica o de madera huecas, los diarios íntimos. Nagiko -narradora y protagonista- va contando su proceso de aprendizaje, proceso que se simboliza en el paso de ser soporte de escritura a convertirse ella misma en "pincel"; y que tiene, como etapas intermedias, el conocimiento del amor, de la muerte y de la venganza.

En cuanto a la forma, sigue presente la constante necesidad de Greenaway de romper con el lenguaje cinematográfico tradicional. En este caso, la ruptura se realiza por medio de la yuxtaposición simultánea de imágenes –recurso de clara filiación nipona, perceptible no sólo en su lengua, sino también en su literatura (téngase en cuenta que la composición poética nipona más popular es el haiku, uno de cuyos principios es la contraposición de impresiones)-. Esta técnica tiene como función completar o adelantar lo que ocurre/se dice o va a suceder.

Hacia la mitad de la película, se hace una cita del "Makura no Sōshi" que, en cierto modo, la resume:
La protagonista es Nagiko, una niña cuya familia valora la etiqueta y sutileza de la literatura y la pintura. Cada cumpleaños su padre, que es calígrafo, le dibuja en la cara una bendición tradicional. Pero la familia es pobre y el padre va pagando su deuda a un editor con favores homosexuales. Casada con el hijo adoptivo de aquél, el matrimonio es un fracaso y el marido quema la biblioteca de Nagiko. La muchacha se escapa a Tokio y se convierte en una modelo de éxito. Los recuerdos familiares son muy fuertes y debe encontrar su equivalente adulto insistiendo para que sus amantes le den placer escribiendo sobre su cuerpo. Sin embargo, la insuficiencia de éstos ya en el terreno de la caligrafía, ya en el sexual hacen que Nagiko sólo pueda tener momentos de éxtasis, pero no una relación duradera. Persuadida por Hoki, un fotógrafo joven que está desesperadamente enamorado de ella, intenta publicar un texto, pero es rechazado por el mismo editor que humilló a su padre. Al saber que el editor tiene como compañero a Jerome, Nagiko decide seducirlo. Sin embargo, las cosas no suceden como ella lo había planeado, porque se enamora del inglés.

Jerome sugiere a Nagiko que escriba de nuevo el libro pero ahora sobre su cuerpo y que él lo presentará al editor para su publicación. Nagiko cubre a su amante con un texto que anuncia poéticamente un plan con otros doce más, donde el cuerpo y la palabra se consideran indivisibles.

El editor no permite que el inglés le abandone y Nagiko es testigo de los encuentros sexuales de ambos. Furiosa, seduce a otro amante ocasional que le provee de piel para escribir. Cuando se entera, el inglés siente celos e incitado por Hoki,intenta fingir su muerte con una catalepsia inducida por pastillas que termina en un suicidio involuntario.

En honor a su aflicción y amor, Nagiko pasa un día y una noche escribiendo un apasionado poema erótico en el cuerpo sobre el amante (Libro VI: Libro del enamorado). Tras el entierro de Jerome, Nagiko quema su lujoso apartamento de Tokio, abandona la ciudad y vuelve a la casa de sus padres muertos.

Hoki cuenta al editor que la muchacha ha escrito un texto sobre el cuerpo de Jerome. El editor lo exhuma en secreto, lo despelleja y manda encuadernar el poema. Nagiko, que ha quedado embarazada de Jerome, se entera de lo sucedido y toma la determinación de llevar a cabo su antiguo plan. Al principio el editor interpreta de una forma errónea su intención, terminando por comprender que los muchachos enviados a su casa son un trato para lograr un entierro decente del «libro-almohada» de la piel de Jerome. Finalmente, el decimotercer y último texto llega bellamente caligrafiado en la piel de un joven aprendiz de sumo. Es el Libro de la muerte. El editor toma conciencia de su fin, entrega el libro-almohada y permite que el joven sea su ejecutor.

La piel caligrafiada es devuelta finalmente a Nagiko, quien se hace tatuar el texto en su propio cuerpo, y lo entierra en la maceta de un bonsái.

La película finaliza con Nagiko escribiendo una felicitación sobre el rostro de su hija y reconociendo que ahora sí está preparada para escribir un diario.



</doc>
<doc id="17607" url="https://es.wikipedia.org/wiki?curid=17607" title="Makura no Sōshi">
Makura no Sōshi

Por otro lado, hay secciones que son verdaderos catálogos de nombres de plantas, de pájaros, de flores, que dan lugar también a listas de "cosas acongojantes", "cosas que dan vergüenza", "cosas tranquilizadoras".

Como señalara André Beaujard, único traductor al francés de la obra, a Sei Shonagon le gusta evocar los sentimientos más fugitivos, la evanescencia de las cosas. Busca la palabra justa con un estilo elegante que no excluye una expresión vigorosa. 

Por su parte, Octavio Paz, admirado ante la belleza y la transparencia de su prosa, descubre en ella "un mundo milagrosamente suspendido en sí mismo, cercano y remoto a un tiempo, como encerrado en una esfera de cristal."




</doc>
<doc id="17608" url="https://es.wikipedia.org/wiki?curid=17608" title="Sei Shōnagon">
Sei Shōnagon

Su vida es poco conocida. Se discute cuál era su nombre real, aunque la opinión más extendida es que se llamó "Kiyohara Akiko". Su sobrenombre está formado por la combinación de un título protocolario ("Shōnagon", tercer subsecretario de Estado) y un apellido familiar ("Sei" es la pronunciación china del carácter con que se escribe la primera parte del apellido de la autora, "Kiyohara", que significa "campo puro").

Era hija del poeta Kiyohara no Motosuke. Gracias a la destacada situación de su padre, logró convertirse en dama de compañía de la emperatriz consorte Fujiwara no Sadako, esposa predilecta del emperador Ichijō. Presumiblemente se casó o convivió con Tachibana no Norimitsu, con el que tuvo un hijo, Tachibana no Norinaga. También se desposó con Fujiwara no Muneyo y de esta unión tuvo una hija, Koma no Myobu. Por otra parte, se le atribuyeron numerosos amantes.

Hasta el final de su vida vivió errante, manteniéndose gracias a las limosnas, entre la isla de Shikoku y los alrededores de la capital.
Su obra más importante, "Makura no Sōshi" ("El libro de la almohada"), era su diario personal, el cual era costumbre que se guardara bajo la cabecera de la cama (de ahí el nombre). "El libro de la almohada" está compuesto por una serie de listas en las que la autora enumera elementos de la realidad cotidiana, como por ejemplo, cosas que emocionan, cosas que producen una sensación de suciedad, cosas que no pueden compararse, etc. Jorge Luis Borges seleccionó, anotó y tradujo esta obra con ayuda de María Kodama.

Además del "Makura no Sōshi", compuso la colección de poemas "Sei Shonagon-shu". Es, también, una de las poetisas que parecen en el "Ogura Hyakunin Isshu", juego de cartas tradicional en el que son fundamentales la memoria y los conocimientos poéticos de los participantes.



</doc>
<doc id="17610" url="https://es.wikipedia.org/wiki?curid=17610" title="Historia del cine">
Historia del cine

La historia del cine como espectáculo comenzó en París, Francia, el 28 de diciembre de 1895. Desde entonces ha experimentado una serie de cambios en varios sentidos. Por un lado, la tecnología del cinematógrafo ha evolucionado mucho, desde sus inicios con el cine mudo de los hermanos Lumière hasta el cine digital del siglo XXI. Por otro lado, ha evolucionado el lenguaje cinematográfico, incluidas las convenciones del género, y han surgido así distintos géneros cinematográficos. En tercer lugar, ha evolucionado con la sociedad, con lo que se desarrollaron distintos movimientos cinematográficos.


La idea de capturar, crear y reproducir el movimiento por medios mecánicos es muy antigua, existieron antecedentes tales como la cámara oscura, o el taumatropo, la linterna mágica, el fusil fotográfico. La técnica para captar la realidad por medios luminosos había sido ya desarrollada por los inventores del daguerrotipo y la fotografía, a mediados del siglo XIX. Thomas Alva Edison, inventor de la lámpara incandescente y el fonógrafo, estuvo muy cerca también de inventar el cine, al patentar el kinetoscopio creado en su laboratorio por William Dickson, el cual, sin embargo, solo permitía funciones muy limitadas. Inspirándose en éste e integrándolo a diversos inventos y descubrimientos de la época, como el rollo de fotos de Eastman. Los hermanos Lumière, hijos del fotógrafo Antoine Lumière, crearon el cinematógrafo: este dispositivo que desarrollaron permitía la toma, proyección y hasta el copiado de imágenes en movimiento; el espectáculo público derivado de la exhibición del funcionamiento del aparato. La primera presentación fue el 28 de diciembre de 1895, en París, y consistió en una serie de imágenes documentales, de las cuales se recuerdan aquella en la que aparecen los trabajadores de una fábrica (propiedad de los mismos Lumière), y la de un tren (en la estación de La Ciotat) que parecía abalanzarse sobre los espectadores, ante estas imágenes las personas reaccionaron con un instintivo pavor, creyendo que el tren los atropellaría. La función de las primeras "películas" era mayormente documental, con el agregado del movimiento. Tiempo después lograron el primer film argumental de la historia, "El regador regado".

Por un tiempo, el cine fue considerado una atracción menor, incluso un número de feria, pero el puntapié inicial para realizar historias y experimentar recursos narrativos visuales fue cuando Alice Guy una ilusionista que en principio, usó el cinematógrafo como un elemento más para sus espectáculos, pero luego los desarrollaría en el cine, creando rudimentarios —pero eficaces— efectos especiales. Los noveles realizadores captaron las grandes posibilidades que el invento ofrecía y fue así como en la primera década del siglo XX surgieron múltiples pequeños estudios fílmicos, tanto en Estados Unidos como en Europa. En la época, los filmes eran de pocos minutos y metraje, trataban temas más o menos simples, y tanto por decorados como por vestuario, eran de producción relativamente barata. Además, la técnica no había resuelto el problema del sonido, por lo que las funciones se acompañaban con un piano y un relator (ver cine mudo). Pero en este tiempo surgieron la casi totalidad de los géneros cinematográficos (ciencia ficción, históricas o de época); el género ausente fue, por supuesto, la comedia musical, que debería esperar hasta la aparición del cine sonoro. También en la época se produjeron los primeros juicios en torno a los derechos de autor de las adaptaciones de novelas y obras teatrales al cine, lo que llevaría con el tiempo a la creación de las franquicias cinematográficas basadas en personajes o sagas.

No estuvo bien durante el inicio del cine se tomó como cierta y concreta la teoría de que podemos percibir movimiento aparente a partir de una sucesión de fotografías fijas que se alojan en nuestra retina (véase Persistencia de la visión), varias teorías de la percepción descubiertas durante los inicios de la escuela de la Gestalt y otras posteriores relativas a la psicología de la percepción contradicen dicha teoría. Según Max Wertheimer hay varios efectos que pueden producir apariencia de movimiento. La propagación de la teoría de la persistencia retiniana como única explicación del funcionamiento del cine es un error que está demostrado por Miguel Ángel Martín Pascual. Según su artículo el movimiento aparente no sucede directamente en el ojo sino en un veloz y complejo proceso que se produce entre la percepción visual directa, la memoria y la capacidad de interpretación de la imagen.

Además de Edison, los hermanos Lumière y Méliès, hubo otros pioneros en la historia del cine como:








En Estados Unidos, el cine tuvo un éxito arrollador, por una peculiar circunstancia social: al ser un país de inmigrantes, muchos de los cuales no hablaban el inglés, tanto el teatro como la prensa o los libros les estaban vedados por la barrera idiomática, y así el cine mudo se transformó en una fuente muy importante de esparcimiento para ellos.

Viendo las perspectivas de este negocio, y basándose en su patente sobre el kinetoscopio, Thomas Edison intentó tomar el control de los derechos sobre la explotación del cinematógrafo. El asunto no solo llegó a juicio, de Edison contra los llamados productores independientes, sino que se libró incluso a tiro limpio. Como consecuencia, los productores independientes emigraron desde Nueva York y la costa este, donde Edison era fuerte, hacia el oeste, recientemente pacificado. En un pequeño poblado llamado Hollywood, encontraron condiciones ideales para rodar: días soleados casi todo el año, multitud de paisajes que pudieran servir como localizaciones, y la cercanía con la frontera de México, en caso de que debieran escapar de la justicia. Así nació la llamada Meca del Cine, y Hollywood se transformó en el más importante centro cinematográfico del mundo.

La mayor parte de los estudios fueron a Hollywood (Fox, Universal, Paramount) controlados por (Darryl F. Zanuck, Samuel Bronston, Samuel Goldwyn, etcétera), y miraban al cinematógrafo más como un negocio que como un arte. Lucharon entre sí con tesón, y a veces, para competir mejor, se fusionaron: así nacieron 20th Century Fox (de la antigua Fox) y Metro-Goldwyn-Mayer (unión de los estudios de Samuel Goldwyn con Louis B. Mayer) Estos estudios buscaron controlar íntegramente la producción fílmica. Así, no solo financiaban las películas, sino que controlaban a los medios de distribución, a través de cadenas de salas destinadas a exhibir nada más que sus propias películas. También contrataron a directores y actores como si fueran meros empleados a sueldo, bajo contratos leoninos; fue incluso común la práctica de prestarse directores y actores entre sí, en un pasando y pasando, sin que ni unos ni otros tuvieran nada que decir al respecto, amarrados como estaban por sus contratos. Esto marcó la aparición del "star-system", el sistema de estrellas, en el cual las estrellas del cine eran promocionadas en serie, igual que cualquier otro producto comercial. Solo Charles Chaplin, Douglas Fairbanks y Mary Pickford se rebelaron contra esto, pudiendo hacerlo por su gran éxito comercial, y la salida que encontraron fue solo crear un nuevo estudio para ellos solos: United Artists.

Durante los primeros 30 años las películas fueron completamente mudas.Suele hablarse de cine mudo, de la época silente o muda, y esto no es del todo exacto, aunque es cierto que las proyecciones no podían por sí mismas sino mostrar imágenes en movimiento sin sonido alguno. Pero las proyecciones en las salas iban acompañadas de la música tocada por un pianista o una pequeña orquesta y además comentada por la voz de un explicador, imprescindible figura que hacía posible que multitudes analfabetas o inmigrantes desconocedores del idioma entendieran la película.

Mientras tanto, el cine seguía otros caminos en Europa. Allí, el sentido del negocio se basó en el monopolio del celuloide. Surgieron grandes empresas cinematográficas que, con Francia a la cabeza, dominaron el mercado mundial hasta la Gran Guerra, en que su hegemonía fue reemplazada por la de la industria estadounidense. Hasta 1914, Europa, con productoras como la Gaumont, la Pathé o la Itala films, dominaron los mercados internacionales. Así, el cine cómico francés, con André Deed y Max Linder o el colossal italiano, con grandes escenografías y participación de extras, en películas como "Quo vadis?" (1912) o "Cabiria" (1914) fueron la escuela donde aprendieron Charles Chaplin y el cine cómico norteamericano o David W. Griffith que asumió los presupuestos del "peplum" en "Judith de Betulia" o "Intolerancia". Más tarde Europa sufrió una patente decadencia debido a la Primera Guerra Mundial, que marcó la pérdida de la preponderancia internacional de su cine.

Aun así, tras la guerra, se crearon obras maestras que iban a hacer escuela. En estos años el movimiento más importante fue el Expresionismo, cuyo punto de partida suele fijarse con la película "El gabinete del doctor Caligari" (1919), y cuya estética extraña y alienada respondía a los miedos de la Europa de postguerra, seguida después por "Nosferatu, el vampiro" (1922). También, en paralelo al movimiento surrealista en pintura y literatura, surgió un cine surrealista, cuyo exponente más célebre es "Un perro andaluz" dirigida por Luis Buñuel.

Por su parte el cine nórdico contaba con las figuras de Victor Sjöström y Mauritz Stiller en Suecia y Finlandia respectivamente.

En esos años, la técnica de contar una historia en imágenes sufrió una gran evolución. Los primeros cineastas concebían al cine como teatro filmado. En consecuencia, los escenarios eran simples telones pintados, y se utilizaba una cámara estática. A medida que pasó el tiempo, los directores aprendieron técnicas que hoy por hoy parecen básicas, como mover la cámara (por ejemplo, el "travelling") o utilizarla en ángulo picado o contrapicado, pero que en esa época eran ideas revolucionarias. También se pasó desde el telón pintado al escenario tridimensional, por obra especialmente de los filmes históricos rodados en Italia en la década de los años diez ("Quo vadis?" o "Cabiria").

Dos cineastas fueron claves en este proceso. En Estados Unidos, David W. Griffith, con "El nacimiento de una nación" e "Intolerancia", cambió el cine para siempre, hasta el punto que se afirma que con él nace de verdad el lenguaje cinematográfico. En la Unión Soviética, otro tanto realiza Sergéi Eisenstein, con películas clave como "El acorazado Potemkin" u "Octubre", entre otras; a Eisenstein se le debe el llamado montaje de atracciones, que busca mezclar imágenes chocantes para provocar una asociación emocional o intelectual en el público. Gracias a ellos, y a los expresionistas alemanes ya mencionados, el lenguaje fílmico alcanza su madurez en la década de 1920.

El cine, como manifestación artística, cuenta con diversos movimientos o corrientes a lo largo del siglo XX. Las escuelas estéticas constituyen un conjunto de movimientos expresivos innovadores de la historia del cine. En algunos casos, supone la ruptura con los estilos anteriores, sobre todo del cine clásico de Hollywood,y en otros casos suponen un desarrollo de los estilos predecesores. El cine de vanguardia supone una ruptura en la narrativa del cine convencional. Junto con la literatura y el arte dominaron el primer tercio del siglo XX. Las corrientes vanguardistas cuestionan los modos tradicionales de producción, difusión, exhibición y consumo de los objetos artísticos; y recurren a cuestiones relativas a la modernidad.

En cuanto al cine, se diferencian tres etapas en el movimiento vanguardista. En primer lugar, se encuentra el cine impresionista, representado por Abel Gance y René Clair. En segundo lugar está el cine surrealista francés y el cine abstracto alemán. Por último, se halla el cine independiente o documental.

Junto a estos movimientos ligados a las vanguardias históricas de principios del siglo XX existen otras manifestaciones cinematográficas, entre las que cabe destacar:

Durante épocas de grandes enfrentamientos políticos y militares el cine fue utilizado como fuerte herramienta de propagación de ideologías y propuestas de acción. Los regimenes totalitarios de todo el siglo XX hicieron un gran uso del montaje y las técnicas del cine para la propaganda. Así, la Unión Soviética fomentó un tipo de cine que remarcaba el poder del pueblo como imagen dignificadora y potenciadora de la patria soviética. Se realizaron varias producciones relativas a la Revolución de 1917, y en contra de la antigua burguesía zarista. También en contra de las invasiones alemanas durante la Segunda Guerra Mundial (por ejemplo, "Alexander Nevski", de Serguéi Eisenstein). En Italia, el régimen fascista de Mussolini ordenó a los estudios Cinecittà crear una serie de películas fastuosas, en la tradición del "colossal" italiano de la década de 1910, que sirvieran para ensalzar la antigua grandeza romana, de la que Mussolini se sentía heredero; el representante más fiel de este cine fascista es probablemente el "", rodado en 1937. En Alemania, si bien no hubo un fuerte control sobre el cine, sí se rodaron numerosos documentales ensalzando a los nazis, como por ejemplo "El triunfo de la voluntad"; varios cineastas contrarios al régimen, por su parte, prefirieron marchar al exilio, como por ejemplo Fritz Lang.

El cine sonoro es aquel que incorpora en las películas sonido sincronizado o tecnológicamente aparejado con la imagen. Por su parte, el cine mudo es aquel que no posee sonido, y consiste únicamente en imágenes. Antes de la existencia del cine sonoro, los cineastas y proyectistas se habían preocupado de crearlo, pues el cine nace con esa voluntad. Raras veces se exhibía la película en silencio. Por ejemplo, los hermanos Lumière, en 1897, contrataron un cuarteto de saxofones para que acompañase a la proyección de la película en su local de París. Hacia 1926, el cine mudo había alcanzado un gran nivel de desarrollo en cuanto a estética de la imagen y movimiento de la cámara. Había una gran producción cinematográfica en Hollywood, y el público se contentaba con las películas producidas. No se exigía que los personajes comenzaran a hablar, ya que la música aportaba el dramatismo necesario.

Los primeros experimentos con el sonido en el cine llegaron de la mano del físico francés Démeny, quien en 1893 inventó la fotografía parlante. Charles Pathé combinó fonógrafo y cinematógrafo. En la misma época, León Gaumont desarrolló un sistema de sonorización de películas, que presentó en la Exposición Universal de París de 1900.

Según la publicación "Where Else but Pittsburgh", la primera película de cine épica se llamó Fotodrama de la Creación, y aunque apareció 15 años antes que se produjeran otras películas sonoras, ofreció una combinación de películas cinematográficas y fotografías sincronizadas con un discurso grabado. Se dividía en cuatro partes, duraba un total de ocho horas y la vieron aproximadamente 8 millones de personas.

Esta producción estaba compuesta de diapositivas fotográficas y película cinematográfica, acompañadas de discos fonográficos de discursos y música. El "Anuario De Los Testigos De Jehova" de 1979 aseguró: «Hubo que pintar a mano todas las diapositivas y películas de color. El foto-drama duraba ocho horas, y, en cuatro partes, llevaba a los auditorios desde la creación, a través de la historia humana, y hasta la culminación del propósito de Jehová para la Tierra y el género humano al fin del reinado milenario de Jesucristo». Fue una producción de la entonces llamada Asociación Internacional de los Estudiantes de la Biblia y hoy llamada Testigos de Jehová. Todos los asientos eran gratis y jamás se hacía una colecta. Además, esta producción de color y sonido repleta de hechos bíblicos, científicos e históricos entró en la escena años antes de que las películas cinematográficas comerciales de color y de largometraje acompañadas de diálogo grabado y música fueran vistas por los auditorios en general hasta principios de la década de 1920.

En 1918, se patentó el sistema sonoro TriErgon, que permitía la grabación directa en el celuloide. Pero el invento definitivo surgió en 1923, el Phonofilm, creado por el ingeniero Lee de Forest, quien resolvió los problemas de sincronización y amplificación de sonido, ya que lo grababa encima de la misma película; así, rodó 18 cortos para promover la técnica, entre ellos uno de 11 minutos de Concha Piquer, que se considera la primera película sonora en español. No obstante, por falta de financiamiento el invento se postergó hasta 1925, año en que la compañía Western Electric apostó por él.

En 1927, los estudios Warner Bros se encontraban en una situación financiera delicada y apostaron por integrar el nuevo sistema de sonido Vitaphone, sistema en el cual la banda sonora estaba presente en discos sincronizados con la proyección. Se incorporó por primera vez en una producción comercial titulada "Don Juan" (1926) de Alan Crosland, así como en otra de sus películas, "Old San Francisco" (1927). En ésta incorporó por primera vez ruidos y efectos sonoros. Sin embargo, la película sonora más exitosa fue "El cantante de jazz" (1927) en la que Al Jolson se inmortalizó pronunciando las palabras inaugurales: «Ustedes aún no han escuchado nada». Ante el éxito, pronto todos los grandes estudios montaron sus propias películas sonoras, y el cine mudo quedó olvidado.

La aparición del cine sonoro introdujo grandes cambios en la técnica y expresión cinematográfica, por ejemplo: la cámara perdió movilidad, quedó relegada a la posición fija del cine primitivo y la imagen perdió su estética frente a la mayor importancia del diálogo. Los actores también se vieron implicados en este cambio técnico. Algunas grandes estrellas fílmicas de Hollywood vieron naufragar sus carreras ante su mala dicción, su pésima voz o su excesiva mímica. Debido a esto, surgieron nuevos actores en su reemplazo. Dos películas que retratan esta transición del cine mudo al sonoro son el famoso musical "Cantando bajo la lluvia" (1952) y también la película "El artista" (2011), esta última con el estilo de una película muda en blanco y negro.

Quizás el único de los grandes del cine mudo que siguió haciendo filmes sin sonido fue Charles Chaplin, con "Tiempos modernos" (1936). Y, sin embargo, a partir de 1940 comenzó a realizar películas con sonido, la primera de las cuales fue "El gran dictador". Así mismo, Sergei Eisenstein, Vsévolod Pudovkin y manifestaron en 1928 por escrito su negativa al cine sonoro.

El cine sonoro hizo desaparecer la función que cumplía el conjunto musical al acompañar el visionado del cine mudo. El silencio cobra importancia como nuevo elemento dramático desconocido por el cine mudo. Se introduce el concepto de banda sonora.

Anteriormente se creía que el año 1909, en el teatro Palace-Varieté de Londres, se proyectaron por primera vez películas en color (el principal problema era que la técnica creada por George Smith (cinemacolor), sólo utilizaba dos colores: el verde y el rojo -los cuales se mezclaban de manera aditiva-). Pero en realidad, fue en 1901 cuando se creó la primera película en color de la historia. Sin título, fue dirigida por el fotógrafo Edward Turner y su mecenas Frederick Marshall Lee. La manera en que la realizaron fue, rodar las escenas en blanco y negro, para después añadir filtros verdes, rojos y azules. Finalmente se creaba uniendo el metraje original y los filtros en un proyector especial.

Posteriormente, en 1916, llegó el technicolor (procedimiento tricromático (verde, rojo, azul). Su uso exigía una triple impresión fotográfica, incorporación de filtros cromáticos y unas cámaras de enormes dimensiones). La primera pieza audiovisual que se realizó completamente con esta técnica fue el corto de Walt Disney "Flowers and Trees", dirigida por Burt Gillett 1932. Sin embargo, el primer largometraje que se realizará con esta técnica será la por película "La feria de las vanidades" (1935), de Rouben Mamoulian. Posteriormente, el technicolor se extendió sobre todo en el ámbito musical como el "Mago de Oz" o "Cantando bajo la lluvia", en películas de la época como "Las aventuras de Robin Hood" o en la animación, "Blancanieves y los siete enanitos". 

La industrialización del cine hizo nacer también las llamadas "convenciones de género", y por ende, los géneros cinematográficos propiamente dichos.

El primer cine era documental: escenas de obreros saliendo de las fábricas y cosas así. Pero el cine documental en cuanto tal, recién vino a nacer en 1922, con el filme "Nanook el esquimal". Aunque nunca demasiado popular, de tarde en tarde se rodarían algunos clásicos, como por ejemplo "El mundo sumergido", de Jacques Cousteau

El cine histórico y bíblico, por su parte, caminarían de la mano, en la búsqueda de la espectacularidad. Desde antiguo se habían rodado películas sobre la vida de Cristo (por ejemplo, "Del pesebre a la cruz" (1912). Sin embargo, el cineasta que le dio verdadera carta de naturaleza al cine histórico o bíblico fue Cecil B. DeMille, con hitos como "Los diez mandamientos" (la versión original de 1923 y el "remake" de 1956), "Rey de reyes" (1927) o "Cleopatra" (1934). Otro clásico de época es "Lo que el viento se llevó", estrenada tras varias peripecias en 1939.

En la década de 1930 surgen también, estrechamente hermanados, el cine de gángsters y el cine negro. Hitos claves del cine gangsteril fueron el "Scarface" de 1932 o "Hampa dorada", y un director clave fue Howard Hawks. Su éxito se explica por la dosis de crítica social que dichos filmes envolvían, sobre la situación posterior a la Gran Depresión de 1929. Además, fueron campo de experimentos formales con la iluminación, con fuerte influencia de los cineastas europeos herederos del Expresionismo, muchos de los cuales habían llegado a Hollywood huyendo del Tercer Reich, por ese entonces ascendente. Quizás el actor más asociado con el género es Humphrey Bogart, con clásicos como "Casablanca", "El halcón maltés" o "El sueño eterno".

El cine fantástico y de ciencia ficción había también experimentado su propio desarrollo, paralelo a un elemento que le era indispensable: el desarrollo de los efectos especiales. Ya Georges Méliès había diseñado una curiosa fantasía llamada "De la Tierra a la Luna", vagamente basada en la novela de Julio Verne. La gran película del cine mudo de ciencia ficción fue "Metrópolis", de Fritz Lang (1927), la cual marcó estéticamente a muchos cineastas posteriores, pero que en su tiempo fue un fracaso de taquilla, costoso para los cánones de la época, y que por lo tanto, relegó a la ciencia ficción fílmica al plano de mero entretenimiento, sin mayor trascendencia intelectual, estigma que pesaría sobre el género hasta "" (1968). En la década de 1930, coincidiendo con la Gran Depresión y el Nazismo, se puso de moda el cine de terror, con clásicos como "Dracula" (con Béla Lugosi, dirigida por Tod Browning, en 1931), o "El doctor Frankenstein" de James Whale, con Boris Karloff (1931). Con éstos y otros filmes, los Estudios Universal crearon la imagen moderna de los clásicos monstruos de la literatura de terror.

La llegada del sonido permitió también el desarrollo de la comedia musical, género harto más amable, incluso de evasión, en donde primaba el peso de los números musicales y canciones por sobre la historia, y que fue el vehículo de lucimiento para diversos bailarines. Los más importantes fueron la dupla conformada por Ginger Rogers y Fred Astaire. El gran clásico del género es "Cantando bajo la lluvia" (1952).

Un género típico de los Estados Unidos que se desarrolló en aquellos años fue el Western, en particular gracias al trabajo de cineastas como John Ford. El gran actor de westerns de la época fue John Wayne. El género fue muy exitoso en Estados Unidos, por construir una mitología fílmica de carácter nacionalista.

Su importancia tuvieron también los filmes de aventuras y de capa y espada. Muy exitoso en ese tiempo fue el cine de piratas. Quizás el más recordado héroe posterior a Douglas Fairbanks sea Errol Flynn ("Capitán Blood", 1935), quien más o menos tomó su relevo en la década de 1930.

En cuanto a la comedia, su edad de oro comenzó con los Keystone Cops, los alocados cortos con policías de Mack Sennett, que inventaron el concepto de gag, incluyendo uno clásico: lanzarle pasteles de crema a la cara de la gente. Pero el primer gran personaje cómico fue el vagabundo sin nombre que Charles Chaplin interpretara en numerosos cortos, y más tarde en largometrajes como "The Kid" (1921) o en "Luces de la ciudad" (1927). Otro cómico importante fue Buster Keaton. Más tarde llegaron El gordo y el flaco, Los Tres Chiflados y Jerry Lewis.

El cine de animación fue experimentado desde los comienzos del cine mismo. Desde 1889 Émile Reynaud trabajó en este campo, y presentó en 1892 su serie de cortos "Pantomimes Lumineuses"; Stuart Blackton creó en 1906 "Humorous Phases of Funny Faces", una animación realizada en un pizarrón; el Stop Motion fue descubierto por Segundo de Chomón ("La casa encantada", de 1906 o 1907) y por Émile Cohl ("La carrera de las calabazas", de 1908), quien además trabajaba mezclando actores y dibujos.

Y, aunque el primer largometraje animado fue "El apóstol" (1917), producida en Argentina por Quirino Cristiani, quien impulsó definitivamente la industria del cine de animación fue Walt Disney, con los largometrajes "Blancanieves y los siete enanitos" (1937) y "Fantasía" (1940).

Posiblemente la cúspide de las posibilidades del cine de la época, en términos de lenguaje cinematográfico, haya sido alcanzada por el filme "Ciudadano Kane", de Orson Welles, en 1941. Película polémica en su época, ha sido reconocida en retrospectiva como uno de los grandes hitos fílmicos de todos los tiempos, y sumó todos los experimentos conceptuales de la época, cerró caminos y abrió otros, razón por la cual figura regularmente como una de las mejores películas de todos los tiempos, en listados y reseñas críticas.

Siendo el cine el único multimedia de la época, y estando su producción bien controlada por los grandes estudios, se desarrolló todo un mecanismo de producción industrial de películas. Así, se programaba no la exhibición de una película pura, sino de verdaderos rotativos que ofrecían, por el mismo precio, una serial y dos películas. A la película principal se sumaba una de menor costo, y producción barata y apresurada, que por su condición de relleno, pasó a ser llamada serie B. Posteriormente la serie B evolucionaría hasta ser un género por derecho propio, pero en aquel tiempo, iba adosada al cine normal.

Las llamadas seriales dominicales eran historias dirigidas al público infantil o juvenil, y que por ende, ofrecían historias de vaqueros, de aventuras o de ciencia ficción. Constaban de una docena de capítulos, de algunos minutos de extensión cada uno, y terminaban en "cliffhangers" que obligaban al espectador a acudir al cine el domingo siguiente, para saber cómo el protagonista saldría del peligro de muerte. Historias dominicales de matinée como por ejemplo "Flash Gordon contra el universo" no solo le dieron carta de naturaleza en el cine a personajes por entonces recientes como Flash Gordon, Superman o Batman, sino que son la evidente fuente de inspiración para hitos fílmicos posteriores como Star Wars o Indiana Jones.

En la época comenzó también la relación entre el negocio del cine y el de la música. Personajes tan disímiles como Mario Lanza, Frank Sinatra, Marlene Dietrich, Jorge Negrete o Carmen Miranda, por mencionar unos pocos ejemplos casi al azar, desarrollaron carreras paralelas como cantantes y actores, con éxito variable según la época y el país.

Para la historia del cine de cada país o cada cultura (geográficamente) o en lengua no inglesa, véase:

Para la Segunda Guerra Mundial, la maquinaria productiva de Hollywood estaba tan bien engrasada, que muchos estudios pudieron prestar activos servicios creando filmes más o menos propagandísticos de apoyo a los Aliados, y en contra del Eje. Pero una vez terminada la conflagración, Hollywood experimentó problemas.

En primer lugar, hubo juicios contra los estudios por el monopolio que ejercían. En 1948, los tribunales de justicia les obligaron a desprenderse de las cadenas de cine, debiendo limitarse a la producción de las películas, perdiendo la distribución. Al mismo tiempo, los artistas, cada vez más célebres, empezaron a rebelarse contra las imposiciones de los estudios. Olivia de Havilland llevó su contrato a juicio, y tras un largo tiempo litigando, ganó. Con esto, el control que los estudios ejercían sobre actores y directores se resquebrajó.

Para colmo, Hollywood debió afrontar un nuevo enemigo: la popularización de la televisión. Las series de televisión barrieron con las series de matinée, y los noticiarios televisivos reemplazaron a los cinematográficos. En un tiempo, se pensó que la televisión acabaría con el cine.

Hollywood respondió reforzando los aspectos en los cuales la televisión no podía competir, concretamente la espectacularidad. Así, el género épico experimentó un nuevo auge, con filmes como "El manto sagrado", "Sinuhé el egipcio" o "Ben-Hur". Todos ellos se beneficiaron de avances técnicos como la pantalla panorámica, gracias a innovaciones como el cinerama o el cinemascope.

En esta época se estandarizó el cine en color. Technicolor ya había nacido en el año 1917, aunque en un proceso más rudimentario que solo utilizaba dos colores, que evolucionó a lo largo de los años 20 y primeros 30, hasta que en 1934 se estrenó la primera película con una escena de acción real en Technicolor de tres colores, El gato y el violín. Poco después Becky Sharp (1935) sería el primer largometraje íntegramente rodado en color. A pesar de todo ello, las complicaciones de rodar en color (se requería el triple de luz que con el sistema en blanco y negro y cámaras tres veces más grandes y pesadas) hizo que el cine en blanco y negro siguiera predominando una década y media más. Con la evolución y simplificación de Technicolor así como la aparición de otras compañías de cine en color como Eastmancolor entre otras que estimularon la competencia, el cine en blanco y negro quedó relegado a películas de bajo presupuesto o en las que era necesario por razones exclusivamente artísticas.

Mientras Hollywood luchaba por superar la crisis, en el resto del mundo se imponían nuevas ideas fílmicas. Impregnados del espíritu de las vanguardias artísticas de la primera mitad del XX, en Europa comenzó la experimentación formal, que llevó a la creación de nuevas formas fílmicas.

La primera de ellas, en la Europa posterior a la Segunda Guerra Mundial, fue el Neorrealismo. Nació en Italia, como reacción al cine fascista del régimen de Mussolini, y buscaba la máxima naturalidad, con actores no profesionales, iluminación natural, etcétera, y con un cine de fuerte crítica social. Se considera inaugurado el género con "Roma, ciudad abierta" (1945), aunque suele considerarse como su mayor representante el "Ladri di biciclette" de Vittorio de Sica (1948). El neorrealismo se agotó pronto, pero muchos cineastas formados o desarrollados en éste, siguieron rodando después (Federico Fellini, Luchino Visconti, Roberto Rossellini, etcétera).

Esta tendencia hacia un cine más realista y menos espectacular fue recogida en otros lugares de Europa. En Francia, François Truffaut le dio el definitivo empuje a la nouvelle vague, con filmes como "Los cuatrocientos golpes"; los cineastas se agruparon en torno a la revista Cahiers du Cinéma, que utilizaron como vehículo de sus ideas sobre el cine. Destaca, aparte de Truffaut, J. L. Godard ("Al final de la escapada"). Este fenómeno encontró paralelo en el "free cinema" inglés, y después se proyectó en Latinoamérica, muy en particular en el "cinema novo" de Brasil, con filmes como "Dios y el diablo en la tierra del sol".

Gran parte de la actividad intelectual en torno al cine se desarrollaba no en los estudios de productores, sino en los foros, en donde se proyectaban filmes, y se discutía sobre ellos entre el público interesado. "Cahiers du Cinéma" definió su propio cine como un cine de autor, o sea del director, frente al cine hollywoodense, el cual era considerado cine de productor, y por ende, reivindicaba la mirada artística y personal del director, por encima de las exigencias comerciales. Esto le abrió las puertas a cineastas con propuestas tan personales como Ingmar Bergman ("El séptimo sello"), Luis Buñuel ("Los olvidados", "Viridiana", "Bella de día"), Stanley Kubrick ("" o "La naranja mecánica"), Pier Paolo Pasolini ("Salò o los 120 días de Sodoma"), Werner Herzog ("Aguirre, la cólera de Dios "), o Andréi Tarkovski ("Stalker"), por ejemplo, además de allanar el camino para cineastas no europeos, como por ejemplo el japonés Akira Kurosawa ("Rashōmon"). También hubo filmes que trataron géneros considerados como típicamente hollywoodenses y los plantearon en sus propios términos, como por ejemplo "Barbarella" (la ciencia ficción), "Los paraguas de Cherburgo" (la comedia musical), "El Evangelio según San Mateo" (el cine bíblico) o "El bueno, el feo y el malo" (el western).

La ironía es que muchos actores y actrices de estos movimientos, con el tiempo se convirtieron en estrellas tan rutilantes como las hollywoodenses: fue el caso de Brigitte Bardot, Catherine Deneuve, Isabelle Adjani, Jean-Paul Belmondo, etcétera. Parte de su encanto radicaba en que se permitían muchas libertades sexuales que las estrellas de Estados Unidos no podían o no querían por la censura imperante en Hollywood.

Tampoco desapareció en Europa el cine comercial. El despliegue de colosalismo por parte de Hollywood encontró respuesta en el desarrollo del peplum primero, y cuando éste se agotó, en el spaghetti western. Fuera de Europa también hubo otras manifestaciones fílmicas que se hicieron prontamente comerciales, como por ejemplo el cine de artes marciales procedente de Hong Kong. Todas estas productoras trabajaban artesanalmente, y no podían competir con la alta calidad técnica de Hollywood, por lo que se esforzaron en la cantidad, redefiniendo así el cine de serie B.

Todos estos cambios en el cine, que seguían de cerca a la sociedad, iban a golpear al cine de Estados Unidos. Así es como en las décadas de 1960 y 1970 se formaron una serie de nuevos cineastas, que redefinieron la noción de cine hollywoodense. A pesar de sus muy dispares temáticas y preocupaciones, o quizás por eso mismo, todos tenían en común el privilegiar una mirada personal o autoral de sus películas, por sobre el cine comercial. Se suele considerar como el pionero de este movimiento a John Cassavetes, junto a otros nombres como Shirley Clarke, Barbara Loden, Paul Morrissey, Elaine May, Mark Rappaport y Robert Kramer. Directores como Woody Allen, Martin Scorsese, Francis Ford Coppola, Robert Altman o Peter Bogdanovich también contribuyeron a ese paso del cine americano, pero siempre más amparados por la industria y sin alcanzar los extremos de marginalidad que caracterizaron al grupo de Cassavetes.

Los nombres de Steven Spielberg y George Lucas son asociados con frecuencia al cine comercial que imperó desde la década de 1980 en adelante, pero no siempre se recuerda que en sus inicios, eran cineastas independientes cuyas propuestas ("American Graffiti" en el caso de Lucas, o "Tiburón" en el de Spielberg) eran consideradas como excéntricas.

También prendió con fuerza, en la serie B, el cine explotation, en respuesta al cine de bajo presupuesto que llegaba desde el extranjero. El género más autóctono en la serie B estadounidense de la época fue el Blaxploitation, que trataba historias de pandillas y maleantes negros, con altas dosis de violencia y sexo para la censura de la época.

Marcado en parte por los sucesos de la década de 1970 (Watergate, Vietnam, el fin del movimiento hippie), el cine de ese tiempo se había vuelto más oscuro, con filmes legendarios como "El padrino", "Apocalypse Now" o "Cabaret", por mencionar ejemplos concretos. En cuanto a películas de simple entretenimiento, se pusieron de moda las de catástrofes, como por ejemplo "Aeropuerto" y "El coloso en llamas", con el productor Irwin Allen explotando el género hasta el agotamiento.

Sin embargo, en 1977, el cineasta George Lucas, con su película "", cambió esto para siempre. Lucas hizo un trato con Fox, que los ejecutivos del estudio consideraron muy ventajoso, por el cual la Fox se llevaba las ganancias por la película, y Lucas por la mercadotecnia; por los resultados posteriores, mucho mejores para Lucas que para la Fox, los estudios entendieron que las películas podían ser explotadas económicamente de manera mucho más amplia que hasta la fecha. Surgió así el concepto moderno de blockbuster, una película que se vende como "estreno de la temporada", que supondrá un gran golpe de taquilla, y que será el vehículo principal para la venta de una extensa mercadotecnia, a través de la concesión de una franquicia sobre la película y sus personajes, a jugueterías que venderán figuras con el personaje, cadenas de comida rápida que harán promociones, etcétera. Algunos de estas primeras películas explotadas con mayor o menor habilidad como modernos blockbuster fueron "Encuentros en la tercera fase" de Steven Spielberg o "Superman" de Richard Donner; en 1981 George Lucas y Steven Spielberg unieron fuerzas para una nueva franquicia, la de Indiana Jones.

El concepto de la película como una franquicia desarrolló también el concepto de secuela. Existían algunas previamente ("El padrino II", "La novia de Frankenstein", etcétera), e incluso una franquicia fílmica como James Bond había acumulado la respetable cantidad de una decena de entregas, pero con secuelas como "Superman II", "Rocky II" o "El Imperio contraataca", el pensar las películas como eventos con posible continuación para explotar la franquicia dejó de ser algo excepcional, para pasar a ser la norma. Por otro lado el cine se hizo más liviano, perdiendo profundidad.
temática.

A medida que las películas de Hollywood se hacían cada vez más grandes en forma, y más escasas de contenido, el cine de otras regiones fue reaccionando a su vez. Así, se profundizó la grieta entre el llamado cine comercial, cuya principal factoría siguió siendo Estados Unidos, y el cine arte, elaborado en mayor abundancia en otras regiones del mundo. Esto se debió a varias razones. Por una parte, el cine comercial se hizo cada vez más caro de producir, y por ende, menos productoras podían incursionar en él (fundamentalmente de Estados Unidos); aunque esta tendencia se revirtió en parte con el auge de la computación, como lo prueban filmes europeos comerciales como los manufacturados por Luc Besson ("Nikita", "El quinto elemento"), por ejemplo. En segundo lugar, realizar películas con contenido artístico se transformó para los círculos culturales europeos, latinoamericanos o asiáticos en una especie de estandarte cultural, para oponerse a la cultura de los Estados Unidos. De todas maneras, esta línea divisoria, muy marcada en las décadas de 1980 y 1990, se fue diluyendo entrado el siglo XXI, porque las nuevas posibilidades de los efectos especiales por computadora y el cine digital permitieron abaratar los costos de las películas comerciales. Además, el cine arte nunca desapareció por completo de Estados Unidos, como lo prueba un cineasta como David Lynch ("Terciopelo azul", "Twin Peaks"), el cual, de todas maneras, para muchas de sus películas debió recurrir a capitales europeos.

Esta línea divisoria se observó en particular en el ámbito de los premios. Las películas "comerciales" aspiraban a ganar principalmente el Óscar, mientras que aquellas realizadas con vocación de "cine arte" tendían a buscar reconocimiento en Cannes, Berlín, o Venecia. Aunque esto sigue sin ser una regla absoluta, ya que hubo películas "comerciales" que buscaron reconocimiento artístico en Cannes (por ejemplo, "Shakespeare in Love"), y cineastas "artísticos" que buscaron publicidad en Hollywood (por ejemplo, Pedro Almodóvar).

El movimiento más importante relacionado con el cine europeo de la época fue el movimiento Dogma 95. Planteándose como reacción al cine comercial, postulaban un cine naturalista, sin efectos de sonido ni banda sonora, con actuaciones más bien espontáneas, y filmadas con iluminación natural. Esto fue posible en buena medida gracias a la aparición de la cámara digital. Ideológicamente, Dogma 95 se inscribía en la línea intelectual de la crítica a la burguesía, tan cara al cine europeo posterior a la Segunda Guerra Mundial. Nada de esto era nuevo, porque en su tiempo, el Neorrealismo había adoptado presupuestos muy parecidos, y por análogas razones. Y por similares motivos también, Dogma 95 tuvo una muy corta vida, y sus cultores volvieron lentamente a los usos del cine de siempre, aunque los cineastas formados a su alero ejercieron una marcada influencia cultural. El más conocido de ellos es Lars von Trier, quien de todos modos después se desmarcó del movimiento.

Mención aparte merece el surgimiento de Bollywood en la India. Ya en 1913 se había fundado un estudio dirigido por Dadahaseb Phalké, que produjo unas treinta películas en diez años. Sin embargo, fue con "Alam Ara" (1931), la primera película sonora de la India, la que marcó un antes y un después, al crear una de las más características tradiciones de Bollywood: el peso de los números musicales dentro de los filmes. A partir de entonces se diseminaron por la India varios centros de producción que se especializaron: cine histórico y superproducciones en Bombay, dramas románticos en Poona, fantasía en Calcuta. La barrera idiomática en un subcontinente con centenares de lenguas hizo que el cine occidental apenas llegara a dichas tierras, pero la gran población le permitió a este mercado cinematográfico ser prácticamente autosuficiente, de modo que Bollywood creció de manera paralela y autónoma al cine hollywoodense, europeo o soviético, desarrollando sus propios códigos y cánones, a veces sumamente extraños para el espectador occidental, pero que le confieren un sabor único dentro de la cinematografía mundial.

Para cierto sector de la crítica, el cine ingresó hacia la década de 1980 en el postmodernismo. De ahí que se hablara del agotamiento de las vanguardias, de la imposición del concepto de simultaneidad por sobre el de continuidad, del reciclaje de viejos materiales. Hitos de este cine postmoderno serían filmes como "Blade Runner" (1982) o "Pulp Fiction" (1994), filmes armados a partir de la recreación de viejos códigos fílmicos y literarios que han perdido vigencia como tales, como por ejemplo el cine negro o el pulp. Contribuye a esta impresión, la dilución que las películas han ido experimentando debido al fenómeno del blockbuster, en el cual éstas se venden como parte de un gran paquete promocional de otros productos relacionados, como por ejemplo la banda sonora, la novela o el videojuego de la película. Estos ensamblajes multimedia han sido particularmente visibles en fenómenos como "El proyecto de la bruja de Blair" o "Matrix", que buscaban ser no solo películas, sino experiencias totales que abarcaran también Internet. Se considere al "cine postmoderno" como una categoría nueva de cine o no, el caso es que la experiencia de ver un filme a finales del siglo XX y comienzos del siglo XXI, era radicalmente diferente a la de las generaciones anteriores.

La generalización de las tecnologías relacionadas con el ordenador cambió al cine para siempre. Los antiguos efectos especiales a base de maquetas y sobreimpresiones pasaron a ser desarrollados mediante computadoras. La primera película con efectos digitales fue "Tron" (1982), pero desde ahí el desarrollo fue fulminante, hasta el punto que en 1995 la compañía Pixar pudo realizar el primer largometraje íntegramente realizado por computadora ("Toy Story"), y en 2004, la película "Sky Captain y el mundo del mañana" era completamente virtual, siendo reales solo los actores protagonistas, quienes rodaron íntegramente frente a una pantalla azul. Un paso muy simbólico lo dieron los Estudios Disney, cuando después del fracaso de su film en animación tradicional "Zafarrancho en el rancho", cerraron esta división y se concentraron en el mercado de la animación por computadora.

Internet supuso también un desafío mayúsculo para los grandes estudios, debido a que el brutal crecimiento de la capacidad de almacenaje en discos duros y portátiles (CD-ROM y DVD entre otros) llevó a que por primera vez se pudiera reproducir de manera virtualmente ilimitada una película íntegra, sin pérdida significativa de calidad. El siguiente paso vino con el surgimiento de las redes P2P ("peer to peer"), que permiten intercambiar información de todo tipo sin un servidor central, y que muchos usuarios empezaron a emplear para descargar películas gratuitamente desde la red, compartiéndolas entre ellos.

Todo lo anterior abrió un intenso debate, que aún no termina, en torno al problema de la propiedad intelectual en Internet. Los grandes estudios se quejan de las pérdidas que este intercambio origina, y los usuarios por su parte contraatacan esgrimiendo el principio de democracia en la red. Esta democratización, por su parte, ha llevado a que muchos realizadores independientes hayan optado por el cine digital, grabando sus películas y editándolas por ordenador, para luego colgarlas en sitios de intercambio de información, como por ejemplo YouTube o Vimeo, este último muy utilizado por cineastas independientes. También se ha simplificado el proceso de convocatoria a festivales de cine, con lo cual el cine independiente, realizado al margen de los grandes estudios, se ha visto fuertemente potenciado. Todo lo anterior ha llevado a una fuerte democratización del cine. Todas estas tendencias son incipientes, y aún es demasiado pronto para determinar cómo será el nuevo mercado del cine que emergerá en un futuro cercano.

También Internet ha servido para la difusión del cine clásico. Una colección de películas de dominio público se encuentran en el Internet Archive, una completa base de datos para la preservación de la historia del cine. Prelinger Archives contenía, en 2005, 1.969 películas, todas ellas de libre uso, ya sea personal o comercial.

Las modernas técnicas de producción digitales, asociadas a internet, han propiciado lo que se conoce como "cine unipersonal" o "solo filmmaking", es decir, películas hechas casi íntegramente por una sola persona, circunstancia que se puede dar sobre todo en el cine de animación. Ejemplos como "Killer Bean Forever", de Jeff Lew, con una producción que emplea a en torno a seis personas, o "La ruta de los elefantes", de Pedro Alonso Pablos, hecha íntegramente por él mismo con ayuda de una actriz de doblaje, comienzan a proliferar.

El 2 de febrero de 2000, en París, Philippe Binant realizó la primera proyección pública de cine digital de Europa, fundada sobre la aplicación de un MEMS (DLP CINEMA) desarrollado por Texas Instrumentos.

Con la rápida difusión del digital y la proliferación de formatos, el Digital Cinema Iniciativas (DCI), trabajando junto con miembros del comité SMPTE de protocolos, publicó un sistema de especificaciones que han adoptado las mayores productoras estadounidenses. Resumiendo, los protocolos indican que las imágenes sean codificadas con el estándar ISO/IEC 15444-1 "JPEG2000" (.jp2) y que se use el espacio de color CIE XYZ a 12 bits por componentes codificado en una gama de 1/2.6; que para el audio se utilice el formato “Broadcast Wave” (.wav) a 24 bits; también hablan del cifrado y otros detalles técnicos.




</doc>
<doc id="17611" url="https://es.wikipedia.org/wiki?curid=17611" title="La Orotava">
La Orotava

La Orotava es un municipio perteneciente a la provincia de Santa Cruz de Tenerife, en la isla de Tenerife (Canarias, España). La capital municipal está localizada en la villa de La Orotava, situada a unos 360 msnm.

El casco histórico de La Orotava fue declarado Conjunto Histórico Artístico Nacional en 1976 y se encuentra incluido en el Inventario de Protección del Patrimonio Cultural Europeo como "Conjunto Monumental". Además, es destacable que gran parte del Parque nacional del Teide (declarado Patrimonio de la Humanidad en 2007) se encuentra dentro de su término municipal. La Orotava es también el municipio más alto de España y con mayor desnivel, su término municipal llega desde el nivel del mar, hasta los 3.718 metros del pico Teide (el pico más alto de España).

No se sabe con claridad de dónde proviene el nombre de la población, pero la gran mayoría de investigadores sostienen que podría deberse a la situación de ésta en la época de los guanches, que llamaban a la zona "Arautaba" o "Arautápala". Desde el punto de vista estrictamente lingüístico, la voz Orotava pertenece a un estado muy avanzado de deformación castellanizada del correspondiente primario amazigh. Entre las poblaciones touaregs del Ahaggar, Sahara Central, encontramos el sustantivo "arrau (pl:arrauen)"="niño"(sexo masculino). Para complementar la voz tinerfeña es preciso apuntar al verbo "aba"="no haber, no existir". Por otra parte, en el dialecto tachelhit del Sous y Anti-Atlas se documenta la forma plural "arrau"="niños". La evolución fonética sería: "arrauttaba<>arautaba<>arautava<>araotaba<>araotava<>arotava<> aorotava<>orotava. La variante "araotava" es la que se cita con mayor frecuencia en las Datas suponiendo esta forma aproximadamente el 65% del total estudiado de aquellas. El 35% restante se reparte entre las demás destacándose entre ellas la de "araotaba". Como podremos observar más adelante, en casi todas las Datas de repartimientos de tierras aparece grafiado "...del Araotaba o...del Araotava", a nuestro criterio en clara referencia a algún lugar concreto generador del topónimo que frecuentemente alude a las "aguas del Araotava".

Se puede señalar que los últimos términos mencionados se citan en las Datas desde el 17-4-1500 hasta el 19-3-1522, lo que demostraría la pervivencia cronológica del vocablo guanche primigenio en la memoria colectiva del pueblo, y por ende de la lengua autóctona. Efectivamente, el mismo Adelantado Alonso Fernández de Lugo continuaría incluyéndolo en las Datas, lo que revela su autenticidad aunque posteriormente se haya elegido el más castellanizado de Orotava, debido precisamente al fuerte proceso aculturizador que generó numerosos topónimos derivados de originales isleños.

El antiguo escudo de la villa desapareció tras un incendio que destruyó el edificio del Ayuntamiento a finales del siglo , sin que quedase rastro de su configuración.

La configuración moderna del escudo fue otorgada por el rey Alfonso XIII por Real Decreto de fecha 15 de febrero de 1905, siendo su descripción heráldica la siguiente: «De oro, un drago en su color. Bordura de gules, con cuatro manzanas de oro. Al timbre, corona real abierta. Como soportes, dos dragones de sinople».

El escudo representa al Jardín de las Hespérides que, en la antigüedad, se creía ubicado en Canarias. Por ello, a ambos lados del escudo se representan dos dragones de sinople alados con cola en punta y sus patas apoyadas en los flancos, a semejanza de los custodios del Jardín, y que podrían simbolizar además las dos laderas que limitan el Valle a este y oeste. En campo de oro, se representa el colosal drago que existió en La Orotava dentro de la propiedad de la familia Franchy y Alfaro hasta el siglo en que fue abatido durante una tormenta. En bordura de gules, cuatro manzanas de oro situadas respectivamente en centro del Jefe, en ambos flancos y en centro de la punta, que representan los cuatro pueblos que existían en el valle de La Orotava en el momento de la creación del escudo: La Orotava, Puerto de la Cruz, Realejo Alto y Realejo Bajo.

La Bandera Oficial de la Villa de La Orotava, en procedimiento iniciado por el Excmo. Ayuntamiento, una vez cumplido con todo el procedimiento legal, de exposición pública y aprobación de la Comisión Heráldica de la Comunidad Autónoma de Canarias, fue aprobada por Orden de 2 de agosto de 2013 de la Consejería de Presidencia, Justicia e Igualdad del Gobierno de Canarias (BOC de 9 de agosto de 2013).
<br>
Su descripción es la siguiente: «Paño blanco rectangular de tafetán, raso o fibra sintética, cuya longitud es de 2:3 (una vez y media más largo que ancho)». En medio del paño debe situarse el escudo de armas como carga cuya descripción es la siguiente: «De oro, un drago en su color. Bordura de gules con cuatro manzanas de oro, una en el eje, otra en la punta y una a cada lado. Dos dragones de sinople linguados en gules como soportes. Al timbre, corona real abierta».

Está situado en el norte de la isla, ocupando gran parte del valle de La Orotava y la parte central de la isla, hecho que lo hace limitar con muchos de los municipios de la isla: Santa Úrsula, Puerto de la Cruz, Los Realejos, San Juan de la Rambla, La Guancha, Icod de los Vinos, Santiago del Teide, Guía de Isora, Adeje, Vilaflor de Chasna, Granadilla de Abona, Arico, Fasnia, Güímar y Arafo.

Tiene una extensión de 207,31 km², siendo el municipio de mayor extensión tanto de la isla como de la provincia de Santa Cruz de Tenerife.

La altitud de su término municipal va desde el nivel del mar hasta los 3718 msnm de la cima del Teide, lo que lo convierte en el municipio que alcanza mayor altura de España.

El término municipal se encuentra surcado de barrancos, siendo los de mayor entidad el barranco del Pino, límite con Santa Úrsula; el barranco de Llarena, el barranco de Araujo, el barranco Martiánez y el barranco Cerrudo, estos dos últimos desembocan en Puerto de la Cruz.

Existen también densas extensiones de pinar con sotobosque de fayas y brezos, pinares de repoblación, que dan paso al matorral de alta montaña.
El gran interés del Parque Nacional del Teide reside en su flora, que cuenta con 139 plantas superiores catalogadas, de las cuales 50 son endémicas de Canarias. Algunas de estas joyas naturales son el tajinaste rojo, el rosal del guanche o la violeta del Teide, que tiene el honor de ser la que florece a mayor altitud de todo el territorio nacional. Se localizan también la retama del Teide, el tajinaste azul, hierba pajonera, rosalillo de cumbre y cardo de plata.
En su fauna las especies más importantes del Parque son los invertebrados. Se encuentran catalogados más de 700 especies de insectos, de las que el 50% son endémicas de la zona. Existen algunas especies de reptiles (como el lagarto tizón) y aves (alimoche, gavilán, cernícalo, milano real). Los mamíferos son escasos, destacando el muflón, el conejo y 5 especies de murciélagos.

Modelos geológicos y geomecánicos explican la formación de los valles de La Orotava y Güímar (Tenerife)

Científicos del Instituto Volcanológico de Canarias (Involcan) y del Instituto Geológico y Minero de España (IGME) han investigado por primera vez las caracterizaciones geológicas y geomecánicas de la sucesión de macizos rocosos volcánicos afectados por los mega-deslizamientos de tierra que originaron los valles de Güímar y La Orotava, un trabajo científico cuyos resultados se han publicado recientemente en la revista científica internacional 'Journal of Volcanology & Geothermal Resear ...
Leer mas: http://www.europapress.es/islas-canarias/noticia-modelos-geologicos-geomecanicos-explican-formacion-valles-orotava-guimar-tenerife-20120820124509.html

El municipio de La Orotava cuenta con numerosos espacios naturales protegidos, destacando el Parque nacional del Teide —del que posee gran parte de su superficie— y el Monumento Natural del Teide. Cuenta además con la Reserva Natural Integral de Pinoleris, el Paisaje Protegido de La Resbala y parte del de Costa de Acentejo y del Parque natural de la Corona Forestal.

Todos estos espacios, a excepción del pasiaje protegido de Costa de Acentejo, se incluyen además en la Red Natura 2000 como Zonas Especiales de Conservación y Zonas de Especial Protección para las Aves.

El municipio posee además el Monte de Utilidad Pública denominado «Mamio, Leres y Monteverde».

En La Orotava, los guanches habitaban principalmente en las zonas costeras y en las inmediaciones de los barrancos más grandes y las laderas del Valle. En estos lugares encontraban fácilmente los alimentos y medios para su subsistencia. Para los guanches el pico del Teide, situado en este municipio, era un lugar de culto.

La derrota de los guerreros del Menceyato de Taoro, último bastión de los aborígenes, supuso el fin de la contienda, aunque continuasen luchando algunos guanches (denominados "alzados") en los lugares menos accesibles.

La Orotava obtuvo del rey Felipe IV el título de villa exenta el 28 de noviembre de 1648 con alcalde mayor propio, ya que hasta esta fecha dependía de La Laguna.

En 1906 el rey Alfonso XIII otorga el título de «Muy Noble y Leal Villa».

A 1 de enero de 2013 La Orotava tenía un total de 41.255 habitantes, ocupando el 6º puesto en número de habitantes tanto de la isla de Tenerife como de la provincia de Santa Cruz de Tenerife.

La población relativa era de 199 hab./km².

El municipio se rige por su ayuntamiento, formado por veintiún concejales.

En el municipio de La Orotava, tiene su sede la Universidad Europea de Canarias, institución miembro de la prestigiosa red internacional de universidades privadas Laureate International Universities.



El municipio de La Orotava ha sido centro de numerosas grabaciones, entre ellas las películas de Furia de Titanes e Ira de Titanes de las cuales muchas escenas fueron rodadas en el Parque nacional del Teide y alrededores. También fue escenario de otras como La decisión de Los Lupano.

Más recientemente La Orotava fue sede de la grabación del Dating show de Cuatro (canal de televisión), Un príncipe para Corina, rodada en Los Jardines de Franchy y en la Finca Saroga. Además en él se puede ver el casco antiguo, la plaza de la Constitución, La playa de los Patos, entre otros.

Desde hace tiempo, La Orotava ha llamado la atención de numerosos directores y productores de cine y de televisión, lo que la hace uno de los principales centros turísticos de grabación de toda Canarias.










Tres días destacan en la Semana Santa orotavense: El Jueves Santo, desde la Iglesia de la Concepción parte la Procesión del Mandato en la que, custodiados por la ya mencionada cofradía de la Vera Cruz desfilan el Cristo de la Misericordia, tallado en 1586 por Rui Díaz, y las imágenes de La Dolorosa, San Juan Evangelista y Santa María Magdalena, obras todas ellas del escultor grancanario José Lujan Pérez.

Por la noche, desde la Parroquia de San Juan Bautista del barrio del Farrobo, parte la procesión de La Columna. En esta solemne noche orotavense procesiona el Cristo Atado a la Columna esculpido en 1689 por Pedro Roldán junto a la imagen de la Virgen de Gloria, también de José Luján Pérez, y de la que se ha dicho es una de sus mejores Dolorosas. Completan el conjunto, un San Juan Evangelista de Fernando Estévez y una Magdalena atribuida también al citado escultor orotavense.

El Viernes Santo, parte desde la Parroquia de Santo Domingo la procesión del Encuentro, en la cual se escenifica el encuentro entre Jesús, camino del Calvario, con la Virgen. Conforman el cortejo procesional Santa Verónica, Santa María Magdalena, San Juan Evangelista, Jesús Nazareno, acompañado por el Cireneo, y la Virgen de los Dolores, todas estas imágenes anónimas del siglo canario.

Al mediodía, sobre las doce, parte de la Parroquia de San Isidro la procesión del Cristo del Calvario, el grupo escultórico de La Piedad, tallado en el siglo por Fernando Estévez, acompañada de su cofradía titular.

Ya en la tarde, es la Parroquia de San Juan Bautista la que toma nuevamente el relevo. Desde su templo parte la procesión del Santo Entierro. El Cristo Difunto, recientemente ha sido relacionado con la gubia de Francisco de Ocampo. A la entrada de la procesión tiene lugar la escenificación del Entierro de Cristo, celebración que, además de en La Orotava, sigue perdurando en algunos lugares del norte de Tenerife como Los Realejos, Garachico, etc.







</doc>
<doc id="17613" url="https://es.wikipedia.org/wiki?curid=17613" title="Puerto de la Cruz">
Puerto de la Cruz

Puerto de la Cruz es un municipio y ciudad perteneciente a la provincia de Santa Cruz de Tenerife, en la isla de Tenerife, en Canarias.

Puerto de la Cruz fue el lugar donde comenzó el turismo en Canarias. En el año 1886 en este pequeño puerto del valle de La Orotava se estableció el primer sanatorio del archipiélago para acoger a los turistas enfermos. Fue además el primer centro turístico español de ámbito europeo.Su comida popular es el pulpo y los boquerones.

Fue denominado en origen como Puerto de la Orotava, por ser el principal punto de embarque del referido valle, aunque ya desde finales del siglo se le denominaba también como Puerto de la Cruz, por haber plantado los nuevos colonos en el recién construido muelle una cruz.

Sus habitantes son conocidos como portuenses, y en algunos casos se les generaliza como «ranilleros», pero originalmente este gentilicio pertenecía solamente a los del barrio de la Ranilla dentro del mismo pueblo y de fuerte tradición pesquera.

El escudo heráldico del municipio fue aprobado por Decreto de 4 de junio de 1964.

«De oro, dragón de sinople, linguado de gules, superado de cruz latina de gules. Campaña de azur con tres fajas ondeadas de plata, cargadas de una llave de sable. Al timbre, corona real abierta.»

Aunque no cuenta con bandera municipal aprobada, el ayuntamiento utiliza de manera oficiosa una enseña blanca con el escudo heráldico al centro.

Se sitúa en el norte de la isla, en el valle de La Orotava, limitando con los municipios de Los Realejos y La Orotava.

Tiene una extensión de 8,73 km², siendo el municipio más pequeño de la comunidad autónoma de Canarias.

El casco urbano se encuentra a 9 metros sobre el nivel del mar, estando el punto de mayor altura del municipio al pie de la Montaña de los Frailes, junto a la carretera de La Montaña.

La elevación más destacada del municipio es el cono volcánico conocido como Montaña de la Horca o de Las Arenas, con 239 metros de altitud.

Los principales cauces que atraviesan el municipio son los de los barrancos de Llarena, de Araujo, de Martiánez y de San Felipe.

Puerto de la Cruz disfruta de un clima semiárido cálido (Clasificación climática de Köppen: BSh) cercano al clima tropical de estación seca y húmeda. La temperatura media anual es de .

Prácticamente la totalidad de la vegetación natural del municipio ha desaparecido por las construcciones y actividades humanas. No obstante, en los acantilados costeros que se extienden desde la desembocadura del barranco de Llarena hasta la Ladera de la Fuente de Martiánez se conservan comunidades típicas canarias, como son los matorrales de tomillo marino "Frankenia ericifolia" y lechuga de mar "Astydamia latifolia", comunidades rupícolas formadas por pasteles de risco "Aeonium tabulaeforme" y cerrajas "Sonchus radicatus", así como matorrales de incienso "Artemisia thuscula" y vinagreras "Rumex lunaria".

En los cauces de los barrancos se desarrollan comunidades de especies nitrófilas, zarzales de "Rubus ulmifolius" y cañaverales de "Arundo donax". Por su parte, en las laderas ubicadas por encima del Loro Parque se localiza un pequeño tabaibal amargo de "Euphorbia lamarckii", mientras que en torno a la Montaña de la Horca crecen comunidades de rabo gato "Pennisetum setaceum", así como plantaciones de pinos y eucaliptos en su ladera occidental.

El territorio que conforma el moderno término municipal se encuentra habitado desde época guanche, tal y como demuestran los yacimientos arqueológicos encontrados.

Esta zona pertenecía al reino o "menceyato" de Taoro, localizándose los principales asentamientos en las cuevas naturales de los Riscos de Martiánez. En esta zona se localizan también necrópolis y lugares de culto constituidos por conjuntos ceremoniales de cazoletas y canales excavados en la roca.

Los orígenes de la ciudad se remontan a principios del siglo , pues ya en 1502 existía actividad portuaria en el litoral portuense, si bien el núcleo de población dependía de La Orotava.

En su origen fue un poblado de pescadores que fue creciendo a medida que se incrementaba el comercio local. El comercio del azúcar dio paso al del vino, estableciéndose su auge de exportación en la segunda mitad del siglo , propiciando un proceso de desarrollo social y económico.

En 1603 se decide señalar un lugar concreto en el Puerto de la Cruz donde levantar una iglesia y su correspondiente plaza.

A mediados del siglo los vecinos comenzaron a manifestar su voluntad de constituirse en un lugar diferenciado, recibiendo la Real Provisión de Felipe IV el 3 de mayo de 1651, lo que les facultaba para nombrar alcalde pedáneo.

Puerto de la Cruz se convirtió en el puerto más importante de la isla cuando una erupción volcánica destruyó el de Garachico en 1706. Durante los últimos años del siglo y principios del , el comercio de Canarias tanto de exportación como de importación -a excepción del comercio que venía de las Indias Occidentales españolas y de Sudamérica-, puede decirse que estaba concentrado en el Puerto de La Orotava. Si bien es verdad que Santa Cruz de Tenerife era la población principal en aquel tiempo, ya que conservaba el gobierno militar y financiero, toda casa mercantil estaba relacionada con La Orotava. Éste proveía a las Islas de artículos de manufactura extranjera.

Hasta 1772 perteneció al municipio de La Orotava, siendo en ese año cuando se procedió a la elección de una junta municipal elegida por los vecinos.

El historiador tinerfeño José de Viera y Clavijo describe el lugar a finales del siglo de la siguiente manera:

En 1808 se obtiene una autonomía municipal plena, cambiándose en ese momento el nombre al moderno de Puerto de la Cruz.

Entre 1812 y 1815 el Puerto de La Orotava alcanzó una gran actividad comercial, embarcando importantes cantidades anuales hacia Gran Bretaña y otros lugares.

El valle de La Orotava atrajo a numerosos científicos y artistas ilustrados europeos durante el siglo , fecha en la que se produjo el denominado «descubrimiento científico» de Canarias. Notables visitantes como Sabin Berthelot, Olivia Stone, Philip Barker Webb, Christen Smith, Leopold von Buch o Elizabeth Murray entre otros, fueron los primeros que tomaron rumbo a las islas con interés científico. A partir de aquí, las bondades naturales y climáticas del Valle de La Orotava fueron realmente conocidas en Europa. Además, se ensalzaron las cualidades de muchos de los productos agrícolas de la zona norte de Tenerife, como es el caso del vino, ya nombrado por William Shakespeare en el siglo XVI a través de sus personajes y descripciones literarias.

Precisamente a estas razones, el turismo comienza a tener un peso importante en la economía local a finales del . Fue en aquellos años cuando se construyó el Gran Hotel Taoro y comenzaron a remodelarse antiguas casas familiares, como Marquesa o Monopol, para transformarlas en los primeros centros hoteleros de la ciudad. Finalmente, la auténtica explosión turística llegó en la década de 1950, cuando la ciudad comenzó su transformación para convertirse en referente turístico de la isla y todo el archipiélago. Hecho que desencadenará a su vez una explosión urbanística con serias afecciones al entorno natural, tanto costero como agropecuario.

Por Decreto del Ministerio de la Gobernación de 26 de julio de 1956 se concede el título de ciudad a Puerto de la Cruz en base al «prestigio alcanzado desde el punto de vista cultural, urbanístico, económico, demográfico, social y turístico, que le han convertido en uno de los más importantes pueblos del archipiélago canario».

Durante la segunda edición del Festival de Cine Ecológico y de Naturaleza en Puerto de la Cruz, aprovechando el viaje de diversas personas invitados a impartir conferencias e impartir mesas redondas, se hace público el Manifiesto de Tenerife el 29 de mayo de 1983. Este texto es precursor del ecologismo político en España, que iniciaría un proceso que culminaría con la fundación del partido político de Los Verdes.

A 1 de enero de 2014 Puerto de la Cruz tenía un total de 29.435 habitantes, ocupando el 8º puesto en número de habitantes tanto de la isla de Tenerife como de la provincia de Santa Cruz de Tenerife. 

La población relativa era de 3.313,75 hab./km², siendo Puerto de la Cruz el municipio con mayor densidad de población de Tenerife y segundo en Canarias tras Las Palmas de Gran Canaria.

El municipio está regido por su ayuntamiento, formado por el alcalde-presidente y veinte concejales.
__SIN_TDC__

</doc>
<doc id="17614" url="https://es.wikipedia.org/wiki?curid=17614" title="Los Realejos">
Los Realejos

Los Realejos es un municipio perteneciente a la provincia de Santa Cruz de Tenerife, en las Islas Canarias. La capital municipal está localizada en el casco urbano de Los Realejos, situado a unos 327 msnm.

El moderno término municipal se formó por la fusión, a mediados del siglo , de los municipios de Realejo Alto y Realejo Bajo.

El nombre de Los Realejos fue impuesto en 1954 al unificarse los pueblos de Realejo Alto y Realejo Bajo. Asimismo, el nombre del municipio deriva del término realejo «sitio donde está acampado un ejército», por haber sido el lugar donde el ejército conquistador había establecido su base en las últimas fases de la conquista de la isla en 1496. 

Otra hipótesis plantea que el término de Realejos deriva de sendos campamentos de las fuerzas en conflicto: el Realejo Alto sería el campamento de los conquistadores, mientras que el Realejo Bajo era el de los guanches.

El escudo heráldico del municipio fue aprobado por acuerdo del Consejo de Ministros de 6 de marzo de 1959, siendo su descripción: 
«Escudo partido. Primero, de oro, un pendón morado y una "añepa" guanche con una esterilla de hojas de palma de sinople, cruzados en aspa y surmontados por una cruz de Santiago de gules. Segundo, de gules, tres castillos de oro bien ordenados, con una cadena de oro que cuelga de las almenas de los dos castillos del jefe y de cuyo centro pende una llave de oro. Al timbre, Corona Real abierta.»

En el primer cuartel se representan las armas del pueblo de Realejo Alto; el pendón y la "añepa" o cetro cruzados hacen alusión a la paz firmada entre los conquistadores y los guanches en 1496 el día de Santiago Apóstol, de ahí la cruz de la Orden de Santiago. El segundo cuartel representa las armas de Realejo Bajo; tres castillos enlazados por cadenas que representan a las antiguas fortalezas que defendían el territorio.

La bandera municipal tiene forma rectangular estando dividida en dos franjas horizontales de igual anchura, siendo la superior de color azul celeste y la inferior de color blanco. En el centro del paño figura el escudo, siendo su altura de 2/5 del ancho de la bandera.

Se sitúa en el norte de la isla, en parte del valle de La Orotava, a 41 kilómetros de la capital Santa Cruz de Tenerife. Limita con los municipios de Puerto de la Cruz, La Orotava y San Juan de la Rambla.

Tiene una extensión de 57,5 km², ocupando el 12º puesto de la isla y el 20º de la provincia.

La máxima altura del municipio se alcanza en la zona conocida como El Cabezón, a 2.166 msnm.

La costa de Los Realejos es alta y acantilada, contando con cinco playas de arena negra y callaos: Castro, Los Roques, El Socorro, La Fajana y La Grimona.

Estos rincones costeros poseen características particulares, como la piedra del Camello, un conjunto rocoso que parece vigilar el litoral; el Callabuzo, un entrante, frecuente paradero de moluscos y coto de caza marina; El Guindaste, un concurrido lugar de baño, con sus saltaderos y un conjunto de piscinas naturales creadas por la acción de erupciones históricas; El Ingenio, La Laja, etc. Pero si hay un rincón costero concurrido y afamado entre los realejeros es, sin duda, la playa del Socorro.

El término municipal se encuentra atravesado por numerosos barrancos, siendo los de mayor entidad los barrancos Cerrudo, de Gordejuela, Godínez, de los Príncipes, Madre Juana, de la Torre, del Roque y barranco de Ruiz.

El término municipal conserva abundantes muestras de la vegetación típica canaria. En la costa acantilada y rocosa se desarrolla el cinturón halófilo compuesto por matorrales bajos de tomillo marino "Frankenia ericifolia" y lechuga de mar "Astydamia latifolia", con algunos bosquetes de tarajales "Tamarix canariensis" junto a la desembocadura del barranco de Ruiz. Por encima de la línea costera, y refugiados en los acantilados bajo Icod el Alto, se desarrollan comunidades típicas del bosque termófilo canario, sobresaliendo la presencia de sabinas "Juniperus turbinata", tabaibales amargos de "Euphorbia lamarckii", matorrales de leña negra "Rhamnus crenulata" y granadillos "Hypericum canariense", así como sauzales de "Salix canariensis" en los riscos más húmedos y comunidades de bejeques "Aeonium canariense" con pipes "Sonchus congestus" en los escarpes. En estas zonas abundan también los matorrales de sustitución compuestos por incienso "Artemisia thuscula" y vinagreras "Rumex lunaria", así como tunerales de "Opuntia ssp." y cañaverales y zarzales de "Arundo donax" y "Rubus ulmifolius" respectivamente.

Por su parte, son de destacar las formaciones de monteverde seco en las laderas del barranco de Ruiz, compuestos por las especies menos exigentes de la laurisilva como barbusanos "Apollonias barbujana" o mocanes "Visnea mocanera", así como un enclave de laurisilva en la zona de La Fajana del mismo barranco, y un pequeño palmeral de "Phoenix canariensis" sobre la playa de Castro.

En el área de medianías se encuentra un extenso pinar de "Pinus canariensis" entremezclado en sus zonas bajas con el fayal-brezal, el codesar de monte de "Adenocarpus foliolosus" y con plantaciones de castañeros "Castanea sativa". En la ladera de Tigaiga, entre los 500 y 1.200 metros, se desarrolla un extenso bosque de laurisilva, y en la zona del Andén de los Madroñeros se encuentra un pequeño enclave de fayal de altitud tinerfeño. 

Ya en la cumbre, además del pinar, se encuentran comunidades de retama del Teide "Spartocytisus supranubius" y matorrales de alhelí "Erysimum scoparium " y rosalito de cumbre "Pterocephalus lasiospermus", sobre todo en la zona de El Cabezón.
Entre las especies vegetales del municipio destacan varios ejemplares de drago "Dracaena draco", como los de San Francisco en el Realejo Bajo y el de Sietefuentes en San Agustín, ejemplares centenarios de gran porte y catalogados como árboles monumentales; los dragos gemelos del Realejo Bajo; el drago de la Rambla del Mar, que sobresale por encima de las plataneras; los dragos de Tigaiga; y el de la Rambla de Castro, ejemplar que emerge de entre el palmeral.

Del drago de San Francisco, situado en un altozano donde confluyen las calles del Medio y Cruz Verde, han dicho viajeros y escritores de otras épocas que «su aspecto es extraño, se diría el de un enorme candelabro soportando un bosque de yucas. Es ciertamente, uno de los vegetales más raros de la creación y muchos han creído ver bajo su envoltura, la imagen del dragón de la fábula, guardián de las manzanas de oro del Jardín de las Hespérides».

Otros árboles monumentales del municipio son el Madroño "Arbutus canariensis" del Barranco de Ruíz, clasificado de interés regional por ser uno de los ejemplares más grandes de esta especie de Canarias, y el Barbusano "Apollonias barbujana" de la Travesía del Pino.

El municipio de Los Realejos cuenta con 3.295 hectáreas de espacios naturales protegidos. Posee parte del Parque nacional del Teide, del Parque Natural de la Corona Forestal, del Paisaje Protegido de Campeches, Tigaiga y Ruiz y del Sitio de Interés Científico del Barranco de Ruiz. Íntegramente incluidos en su término municipal se encuentran el Paisaje Protegido de la Rambla de Castro y el Monumento Natural de la Montaña de los Frailes. 

Todos estos espacios, a excepción de la Montaña de los Frailes, se incluyen también en la Red Natura 2000 como Zonas Especiales de Conservación y Zonas de Especial Protección para las Aves. Asimismo, la franja litoral entre la punta del Guindaste y la zona de Las Puntas, en San Juan de la Rambla, está declarada Zona Especial de Conservación por la presencia de hábitats de cuevas marinas sumergidas o semisumergidas.

Los Realejos cuenta además con los Montes de Utilidad Pública denominados Cumbres del Realejo Bajo y Ladera y Cumbre.

El territorio del moderno municipio se ubicaba dentro del "menceyato" de Taoro.

Aquí se dio por concluida la fase bélica de la conquista de Tenerife el 25 de julio de 1496, considerándose, esta, como la fecha fundacional del Realejo Alto. En el sitio donde los ejércitos castellanos establecen el Real (campamento militar) a orillas de un barranco, que posteriormente se denominaría barranco de Godínez, se erige un templo dedicado al Apóstol Santiago, patrón de Castilla y de sus ejércitos, en agradecimiento a este santo por la finalización de la conquista. Se convierte, pues, esta iglesia en uno de los primeros templos cristianos que los castellanos edificaron en la isla; el primero tras finalizar la fase bélica conquista. Esta iglesia es conocida hoy como Parroquia Matriz del Apóstol Santiago.

Al otro lado del barranco que los conquistadores llamarían barranco de Godínez, se encontraban las más fértiles tierras de Tenerife. Los repartos de terrenos o "datas" que se llevaron a cabo en 1499, concluida la conquista, en el antiguo "Realexo" dejarían aquellas tierras en manos del Adelantado Alonso Fernández de Lugo que las reservaría para sí, fundando allí su Hacienda e introduciendo el cultivo de la caña de azúcar. Posteriormente en 1512, el Adelantado instituye su mayorazgo sobre esta propiedad. 

El año 1499 en el que se realizaron los repartos, podría considerarse el año de fundación de facto de el Realejo de Abajo, y más aún cuando el propio Adelantado, Alonso Fernández de Lugo ordena traer pobladores aborígenes de Gran Canaria para que trabajen en su hacienda azucarera.

Entre la Parroquia del Apóstol Santiago, la Parroquia de Ntra. Sra. de la Concepción (primitivamente de Santa Ana o Santa María) y la Hacienda de El Realejo (hoy Hacienda de Los Príncipes) crecería el Realejo.

El historiador tinerfeño José de Viera y Clavijo describe los lugares de Realejo Alto y Bajo a finales del siglo de la siguiente manera:

El camino hacia la unión los municipios se inicia casi desde la propia constitución de los ayuntamientos de Realejo Alto y Realejo Bajo, al amparo de las Cortes de Cádiz de 1812. Tomando la fecha de 1814 como la posible para la creación del primer Ayuntamiento Constitucional de Realejo Alto –tal y como se puede comprobar en la documentación conservada en el Archivo Municipal-, las corporaciones tardaron poco menos de una década en llevar a efecto la primera unión de hecho de Realejo Alto y Realejo Bajo, materializada en febrero de 1823. Apenas se pudo formalizar tal fusión; la restauración del Antiguo Régimen implicó una vuelta atrás que devolvía a ambos pueblos a su antigua condición en octubre de aquel mismo año.

Un segundo intento se produciría en 1836, al amparo de la nueva Constitución vigente. Ni siquiera se llegó a instaurar un único Ayuntamiento, ya que el gobierno electo con carácter interino, había celebrado apenas dos sesiones cuando se le comunicó la vuelta al “status quo” anterior.

El siglo XIX representa una etapa verdaderamente hostil para el deseo de fusión de ambos pueblos. La inestabilidad política propia de esa centuria se refleja en la frustración de las Corporaciones en todo intento de unificación, hasta el punto de abandonarse la idea durante casi noventa años.

Habría que esperar hasta 1925 para ver incluido en las Actas de Pleno del Ayuntamiento de Realejo Alto algún punto del orden del día referente a la fusión con el Realejo Bajo. En la sesión del 5 de julio de ese año se aprueba la unión, pero, apenas unos días después, algunos concejales se retractan de su voto ya que las condiciones estipuladas en el acuerdo no parecen convencer a los ediles ni a un buen número de vecinos. Por primera vez en el largo proceso de la fusión, se manifiesta un sentimiento de rechazo popular por este asunto. Esta hostilidad explica que la cuestión se resolviera en los tribunales, anulando la Audiencia Provincial el acuerdo dos años después.

El último intento antes del definitivo de mediados del XX, es reseñable por su carácter anecdótico. En 1928 visita Canarias el Jefe del Gobierno, Miguel Primo de Rivera; enterado del asunto fallido de la fusión, se muestra especialmente interesado, tomando partido por la unión e incluso proponiendo el redundante nombre de “Realejos del Rey” para el futuro municipio. Un informe de la Comisión Municipal Permanente de Realejo Alto de finales de 1928 desaconseja por completo retomar la cuestión, ya que aún está presente la discordia generada en el año 1925.

El día 8 de diciembre de 1941 se le concede al municipio de Realejo Alto el título de Villa.

Finalmente, el 6 de enero de 1955 se lleva a cabo la fusión en un solo municipio de los ayuntamientos de Realejo Alto y Realejo Bajo, bajo la denominación de Los Realejos.

El llamado "Monte de La Corona" en Los Realejos fue escenario de uno de los mayores fenómenos sociológicos de la historia de Canarias, y es que en esta zona tuvo lugar una presunta aparición mariana en 1992 que congregó a más de dos mil personas que se reunieron a presenciar el acontecimiento.

A 1 de enero de 2013 Los Realejos tenía un total de 37.970 habitantes, ocupando el 7º puesto en número de habitantes tanto de la isla de Tenerife como de la provincia de Santa Cruz de Tenerife. 

La población relativa era de 665,09 hab./km².

Por edades existía un 69% de personas entre 15 y 64 años, un 16% mayor de 65 años y un 15% entre 0 y 14 años. Por sexos contaba con 18.724 hombres y 19.246 mujeres. En cuanto al lugar de nacimiento, el 84% de los habitantes del municipio eran nacidos en Canarias, de los cuales el 64% había nacido en otro municipio de la isla, el 35% en el propio municipio y un 1% procedía de otra isla del archipiélago. El resto de la población la componía un 3% de nacidos en el resto de España y un 13% de nacidos en el Extranjero, de los cuales el 44% era originario de América y un 53% del resto de Europa.

Los Realejos está regido por su ayuntamiento, formado por el alcalde-presidente de la corporación y trece concejalías, así como por siete concejales de la oposición.

</doc>
<doc id="17616" url="https://es.wikipedia.org/wiki?curid=17616" title="Guatemala (ciudad)">
Guatemala (ciudad)

La ciudad de Guatemala, cuyo nombre oficial es Nueva Guatemala de la Asunción, es la capital y sede de los poderes gubernamentales de la República de Guatemala, así como sede del Parlamento Centroamericano. La ciudad se encuentra localizada en el área centro-sur del país y cuenta con una gran cantidad de áreas verdes. De acuerdo con el último censo realizado en la ciudad, en ella habitan 2.149.107 personas, pero considerando su área metropolitana de acuerdo al Instituto Nacional de Estadística, alcanza un estimado de 4.703.865 habitantes para 2015, lo que la convierte en la aglomeración urbana más poblada y extensa de América Central.

La Nueva Guatemala de la Asunción es el cuarto asentamiento de la capital del Reino de Guatemala. La razón de su traslado al Valle de la Ermita fueron los terremotos de Santa Marta, que destruyeron en buena parte la ciudad de Santiago de Guatemala, la antigua capital del Reino de Guatemala. La orden de traslado se decretó el 1.° de diciembre de 1775 y el 2 de enero del siguiente año hubo reunión por primera vez en el ayuntamiento de la nueva ciudad. Una placa, que está frente a la Parroquia de la Santa Cruz, justo al inicio de la calzada Milla y Vidaurre bautizada así en honor al escritor y diplomático José Milla y Vidaurre, conmemora este hecho. El nombre de la nueva ciudad fue decretado por el Rey de España el 23 de enero de 1776.

Su desarrollo se ha visto afectado en numerosas ocasiones por desastres naturales, terremotos en su mayoría, que han devastado la ciudad y sus alrededores retrocediendo en ella años de desarrollo. El último que la afectó fue el terremoto de 1976 que dañó seriamente la estructura moderna construida y la que se encontraba en construcción, al igual que reliquias históricas como las iglesias de Nuestra Señora de la Merced, La Recolección, Nuestra Señora del Cerrito del Carmen —primera iglesia construida en el valle hacia 1620—, y el edificio del Mercado Central.

Muchos de los nombres de los municipios y poblados de Guatemala constan de dos partes: el nombre del santo católico que se venera el día en que fueron fundados y una descripción con raíz náhuatl; en el caso de la Nueva Guatemala de la Asunción, el nombre le fue conferido en honor a la Virgen de la Asunción.

Los primeros documentos históricos en que aparece escrito el nombre de Guatemala son las cartas de relación que Pedro de Alvarado envió a Hernán Cortés en 1524. En las cartas citadas, el nombre de Guatemala se escribe de la misma manera en que se hace ahora y que seguramente es la castellanización del vocablo "Quauhtemalan" («lugar de muchos árboles») de origen náhuatl, que era el nombre con el cual conocían a la ciudad y nación cakchiquel los auxiliares mexicanos que acompañaron a Alvarado y a Cortés.

Tras los terremotos de Santa Marta que destruyeron parcialmente a la ciudad de Santiago de los Caballeros de Guatemala en 1773, esa ciudad fue abandonada por todas las autoridades reales y municipales que se trasladaron al valle de la ermita para establecer una «nueva ciudad» entre 1774 y 1778.

La ciudad de Guatemala está ubicada en el «valle de la Ermita» con alturas que varían entre los 1500-1600 (msnm) y las temperaturas medias oscilan entre los 12 y 28 °C.


La ciudad está completamente rodeada por municipios del departamento del mismo nombre:

Guatemala se encuentra situada en el trópico de cáncer, razón por la cual no existen cuatro estaciones definidas como en los hemisferios norte o sur, sin embargo por las horas de luz a lo largo del año las cuales tiene una variación de únicamente dos horas; es más semejante con las estaciones del hemisferio norte.

La ciudad de Guatemala goza de un clima sub-tropical de tierras altas, debido a su elevación sobre el nivel del mar (1500-1700 msnm), por lo que tiende a tener un clima muy suave, casi primaveral a lo largo del año.

Existen dos temporadas muy bien marcadas en año:

La temporada de lluvias se extiende de mayo a octubre y la temporada seca que va de noviembre a abril.

Por las horas de luz en el año podría decirse que el verano va de junio a septiembre con temperaturas que oscilan entre 16 y 28 °C, generalmente presentan mañanas soleadas y tardes de lluvia o tormentas eléctricas, la sensación térmica en esta estación puede ser un poco más elevada en el periodo de canícula o recesión de las lluvias, que generalmente se da entre los meses de julio y agosto; presentando los niveles de humedad más altos en todo en año.

El otoño como en la mayor parte de los países tropicales es poco perceptible, en Ciudad de Guatemala va de finales de septiembre a finales de diciembre y se caracteriza principalmente por el incremento de lluvias al inicio de la estación (septiembre-octubre), por el ingreso de los primeros frentes fríos procedentes del norte, la disminución de temperaturas y el incremento de la velocidad del viento.

El invierno va de finales de diciembre a finales de marzo y se caracteriza por la disminución de temperaturas principalmente en los meses de enero y febrero donde se han registrado las temperaturas mínimas récord (6 °C) con sensaciones térmicas de hasta cinco grados menos por la velocidad del viento.

La primavera es la estación más calurosa en Ciudad de Guatemala y en el interior del país, debido a esto la mayoría de personas suele llamarle verano, ésta va de finales de marzo a finales de junio y se caracteriza principalmente por el florecimiento de diversos árboles en la Ciudad (matilisguates, jacarandas, palos blancos, framboyanes, entre otros) así como por el viento sur constante, amaneceres con bancos de niebla y las temperaturas más altas en todo el año las cuales pueden superar en algunas ocasiones los 30 °C.

El clima se ve altamente influenciado en Guatemala por los fenómenos naturales de El Niño y La Niña, los cuales pueden cambiar por completo los parámetros de las condiciones atmosféricas; derivando situaciones extremas de sequías, ciclones tropicales, inundaciones y temperaturas máximas y mínimas poco habituales.

Dentro de los confines de la moderna Ciudad de Guatemala está la antigua ciudad maya de Kaminaljuyú. Kaminaljuyú data de unos dos mil años atrás y es sabido que comerciaba con la distante Teotihuacan en México central. El centro de Kaminaljuyú estaba localizado a corta distancia de la parte más antigua de la ciudad de Guatemala, y en el siglo la ciudad creció alrededor de las ruinas (y en algunos casos sobre algunas de las ruinas periféricas antes de que fueran protegidas). El centro ceremonial de Kaminal Juyú es ahora un parque dentro de la ciudad de Guatemala.

En tiempos de la colonia española era una pequeña ciudad con un monasterio llamado El Carmen, fundado en 1620. La sede de la Capitanía General de Guatemala, dependiente del virreinato de la Nueva España, fue mudada al valle de La Ermita en 1775, y la ciudad adquirió el nombre de Nueva Guatemala de la Asunción.

Luego de los terremotos de «Santa Marta» en 1773, las autoridades españolas decidieron que la ciudad de Guatemala tenía que cambiar de lugar para evitar un otro evento de la misma magnitud, pues consideraron que los movimientos telúricos eran causados por los volcanes vecinos a la ciudad; era necesario comenzar un peregrinaje en busca de un nuevo sitio que ofreciera a los habitantes seguridad y provecho. Después de largas discusiones, los que apoyaban el traslado de la ciudad impusieron su opinión y partieron rumbo al «Valle de la Ermita», mientras que la oposición se quedó en la Santiago de los Caballeros a reconstruir la ciudad.

Habiendo hecho estudios sobre los lugares más apropiados para asentar la nueva ciudad se aludía necesariamente a las facilidades para proveer de agua a la nueva capital, mencionándose que en el río de Pinula, en el llano de «la Culebra», había ya una toma que facilitaba el agua a los pocos vecinos del valle y se acompañaba un plano hecho por el arquitecto mayor Bernardo Ramírez, maestro mayor de obras y fontanero de la «Nueva Guatemala de la Asunción». Así pues, el proyecto del acueducto en la Nueva Guatemala de la Asunción empezó con la propuesta al analizar el traslado de la capital luego del terremoto de 1773.

El 19 de febrero de 1774, cuando el arquitecto mayor firma otro informe sobre el traslado de la ciudad, ya se hace mención de los trabajos sobre el montículo de «la Culebra» para hacer el que luego sería el Acueducto de Pinula. El montículo también era llamado «Loma de Talpetate» y dividía el llano de «la Culebra» con el de «la Ermita». Había un inconveniente: el bajío que formaba el llano de la Culebra; sin embargo, se pensó que se podría salvar por medio de arquería, pero el problema sería que el costo era considerable, y además la obra quedaría expuesta a los efectos de los terremotos. A pesar del costo, el proyecto continuó.

Para octubre de aquél año, ya estaban establecidos en el Valle de la Ermita aproximadamente mil novecientos españoles que tomaban su lugar en doscientos setenta y ocho ranchos y dos mil cuatrocientos mestizos o pardos, que eran alojados en trescientos noventa y ocho ranchos. Los habitantes recién mudados, convivían conjuntamente con los pobladores originales del Valle de la Ermita que sumaban el total de cinco mil novecientas diecisiete personas alojadas en novecientos veinticinco ranchos. La extensión del «Valle de la Ermita» era de nueve leguas cuadradas, veintidós caballerías, ciento noventa y nueve cuerdas y cuatro mil trescientas setenticinco varas superficiales. El traslado oficial de la nueva ciudad fue el 2 de enero de 1776. El traslado conjuntamente con la construcción de la nueva capital constituyeron un hecho extraordinario en la historia de Hispanoamérica, siendo además un caso especial de fundación jurídica, pero no física. Los dos bandos tenían diferencias marcadas e irreconciliables; por un lado, los criollos —descendientes de los conquistadores— que no pertenecían a la aristocracia capitalina y que eran capitaneados por el arzobispo Pedro Cortés y Larraz, y por el otro lado estaban los españoles —que eran las autoridades peninsulares nombradas por el rey de España— y los criollos aristócratas —los miembros del Ayuntamiento— que estaban contrarios al traslado de la ciudad y eran dirigidos por el presidente de la Real Audiencia de Guatemala, el entonces gobernador y Capitán General Martín de Mayorga, los oidores y algunos vecinos que eran partidarios de que el traslado de la capital a un lugar que estuviera más seguro de terremotos y lejano a los volcanes.

Fundada oficialmente el 2 de enero de 1776, la ciudad abarcaba un área aproximada de 10 x 20 manzanas. Para suministro de aguas, contaba con el Acueducto de Pinula, que comenzaba en «El Cambray» -en donde en 1994 se construyó el centro comercial «Galerías La Pradera»- y llegaba hasta el final de la calle real de Pamplona -conocida como «bulevar Liberación» a partir de 1954-. Un sistema de desniveles cuidadosamente analizado para el acueducto hacía que el agua fuera aumentando velocidad y, con ello, presión para alcanzar su destino final. Junto al de Pinula, el acueducto de Mixco, formaba un sistema de suministro de agua que estuvo en servicio a partir de 1786.

El 26 de noviembre de 1777, por consulta de Cámara, fue nombrado arzobispo de Guatemala Cayetano Francos y Monroy, nombramiento que era difícil ya que era en sustitución del arzobispo Pedro Cortés y Larraz, quien se negaba a aceptar el traslado de su diócesis hacia la nueva ciudad de Guatemala, luego de que la capital de la capitanía, Santiago de los Caballeros de Guatemala fuera destruida por los terremotos. El siete de octubre de 1779 hizo su entrada pública, con una escolta de ocho caballeros, en la nueva ciudad de Guatemala el nuevo arzobispo Cayetano Francos y Monroy. Un mes antes, Pedro Cortés y Larraz publicó una carta pastoral denunciando la llegada de un usurpador y amenazando con excomulgarlo, pero Francos y Monroy tomó inmediatamente sus primeras medidas nombrado un cura en el pueblo indígena de Jocotenango y fue a buscar a la destruida Santiago de los Caballeros de Guatemala a las beatas de Santa Rosa. Había decidido que en noviembre de 1779 iba trasladar las imágenes y gastó una gran cantidad de dinero para terminar la construcción de los monasterios Carmelitas y de Capuchinas. Cortés y Larraz no quiso seguir resistiendo y huyó a principio de octubre. El seis de diciembre de 1782, Francos y Monroy informó al rey que había trasladado a la nueva ciudad la catedral, el colegio seminario, los conventos de religiosos y religiosas, beaterios y demás cuerpos sujetos a la Mitra; todos ellos habían sido trasladados a edificios formales o en construcción. Ahora bien, para terminar estas obras había sido necesario que dejara la obra del palacio Arzobispal por un lado y él tuvo que vivir, hasta entonces, en casa de alquiler con mucha incomodidad y estrechez, careciendo de las principales oficinas y habitación para su familia.

La Plaza de Armas fue el centro cívico y político de la Ciudad desde su fundación hasta el inicio de los gobiernos civiles que se establecieron en 1985. El arquitecto Marco Ibáñez, el delineador Antonio Bernasconi y el ingeniero Joaquín de Isasi tuvieron a cargo el levantamiento de los planos de la nueva Catedral de Santiago y después de dos años lograron que los planos fueran aprobados por Real Cédula del 6 de noviembre de 1779, la que arribó a Guatemala en febrero de 1780. El nuevo capitán general, el teniente general y caballero español distinguido Matías de Gálvez se hizo cargo de la reconstrucción de la Ciudad hasta que fue promovido a Virrey de México en 1783, por su grandes servicios al derrotar y expulsar a los ingleses en la isla de Roatán en Honduras.

El arzobispo de Guatemala, Cayetano Francos y Monroy, bendijo el solar y colocó la primera piedra de la Catedral en 1782. Los trabajos de construcción se iniciaron formalmente el 13 de agosto de 1783, y duraron hasta el 15 de marzo de 1815 en fue llevada procesionalmente desde su trono en la Provisional Catedral en el Beaterio Santa Rosa la venerada imagen de Nuestra Señora del Socorro, la cual fue colocada en el altar principal de su capilla, en donde ha permanecido desde entonces. Para 1815, estaba terminada la mayor parte del templo y se trasladó el órgano a la misma, así como numerosas imágenes de santos además de la imagen de Nuestra Señora del Socorro, las cuales fueron trasladas en procesión solemne. La iglesia se inauguró oficialmente en esa fecha con una solemne misa de Acción de Gracias.

Por su parte, el Real Palacio, o Palacio del Ejecutivo era el edificio sede del poder ejecutivo del Estado de Guatemala desde el traslado de la capital de la Capitanía General de Guatemala al valle de la Ermita en 1776 hasta que fue destruido por los terremotos de diciembre de 1917 y enero de 1918.

En la década de 1850, el Capitán General Rafael Carrera mandó a construir un majestuoso Teatro Nacional que fue nombrado en su honor como «Teatro Carrera», ubicado en la Plaza Vieja. La Plaza Vieja era un sitio ubicado hacia el nororiente de la ciudad de Guatemala y que en 1776 abrigara la piedra fundadora de la Nueva Guatemala de la Asunción luego de celebrado el primer cabildo y firmada el acta de asentamiento, el 2 de enero de aquel año. Se había elegido este lugar para que fuera la Plaza Mayor de la nueva ciudad, reservándose junto a ella espacios para la construcción del Palacio Arzobispal y la Catedral, así como para la edificación, en los alrededores, de los solares para las familias del Clan Aycinena, ya que don Fermín de Aycinena, primer patriarca del clan, había colaborado sobremanera con los gastos del traslado.

Debido a las alteraciones en el diseño del plano del trazo de la ciudad, realizadas por los Arquitectos Reales de la corona española, la plaza mayor se tuvo que trasladar hacia el poniente, aunque ya se habían terminado de construir en 1791 el Palacio Arzobispal que sirvió de residencia del arzobispo Fray Ramón Casaus y Torres y la iglesia de Santa Rosa, que funcionó provisoriamente como Catedral entre 1787 y 1815. Al trasladarse definitivamente a su nuevo solar la Plaza Mayor, el sitio original pasó a ser conocido como la Plaza Vieja, y siguió sirviendo como parque, estaba rodeada de una banca que hacía también las veces de baranda, y cinco grandes puertas de acceso -tres para peatones y dos para carruajes. Además, tenía dos fuentes para servicio público, y en ella se realizaban ejercicios militares y actividades religiosas.

Más adelante pasó a ser un sitio de comercio y el 6 de agosto de 1832, el entonces gobernador de Guatemala, Dr. Mariano Gálvez emitió un decreto ordenando se levantara un edificio que sirviera como teatro en medio de la Plaza Vieja. Pero la situación política del país con constantes guerras civiles entre liberales y conservadores y un alzamiento indígena dirigido por Rafael Carrera que terminaron por derrocar a Gálvez en 1838, no permitieron que se construyera el teatro.

El proyecto fue retomado en 1852 cuando Juan Matheu y Manuel Francisco Pavón Aycinena presentaron a Rafael Carrera un nuevo plan. Ya aprobado el proyecto, Carrera comisionó al propio Matheu y a Miguel Ruiz de Santisteban para construir el teatro. Cuando la obra se puso en marcha, estuvo a cargo del ingeniero Miguel Rivera Maestre, pero éste renunció poco después, siendo sustituido por José Beckers, profesional especializado en Alemania, quien construyó las fachadas de marcado helenismo y agregó un vestíbulo. La edificación de este teatro fue el primer proyecto monumental de la era republicana del país, aprovechando que finalmente éste vivía una época de paz y prosperidad.

El proceso de expansión de la ciudad hacia el sur se inició a partir del triunfo de la Reforma Liberal en 1871; durante el gobierno del general Justo Rufino Barrios se estableció la lotificación del Potrero de Bolaños, en el extremo suroeste de la ciudad, y que luego se convirtió en el cantón «La Paz». En 1881 se anexó a la ciudad el cantón de «la Candelaria» y de «la Parroquia» y en 1882 se lotificaron los llanos del Hospital San Juan de Dios, creando el Cantón «Elena» En 1883, al sur del cantón de «La Paz» surge «La Reformita» y dos años después en San Pedro las Huertas -desde la década de 1950 conocido como el barrio de San Pedrito- en el extremo sureste de la ciudad, el cantón «La Independencia».

En 1887 surge el Tempiscal y en 1889 se lotificó el llano de Matamoros, al oriente de la ciudad. Ya en el gobierno del general Manuel Lisandro Barillas en el llano de «Palomo» en el extremo suroccidental aparece el cantón «Cervantes», y hacia el sur, los de «Barrios» y «Barillas».

El bulevar «30 de junio» -llamado posteriormente «Avenida de La Reforma» fue el primer corredor de expansión comercial hacia el sur, durante el gobierno del general José María Reyna Barrios; en este bulevar se construyó un jardín público, el cuartel de artillería, el Instituto Nacional Agrícola de Indígenas, y los edificios para la Exposición Centroamericana al este de la carretera. Al final del bulevar se construyó el «Palacio Reforma», que era utilizado como museo nacional y que estuvo ubicado en donde se construyó posteriormente Obelisco de la Independencia. El cantón Exposición, en el área del bulevar 30 de junio fue creado como un área para la élite cafetalera nacional y extranjera. Para 1894, el cantón «Tívoli» se construyó entre el «Exposición» al norte, «Ciudad Vieja» al este, el parque «La Aurora» al sur y los cantones «La Paz» y «Pamplona» al oeste. La prolongación de la séptima avenida sur se designó como avenida «15 de septiembre» y se larga hasta «Los Arcos» del acueducto de Pinula.

El gobierno del general José María Reina Barrios realizó una agresiva inversión en infraestructura en todos el país, construyendo el fastuoso Palacio del Ejecutivo, numerosos edificios públicos suntuosos y realizando la Exposición Centroamericana en 1897, la cual estuvo diseñada para mostrar los grandes avances que había tenido Guatemala durante su gobierno. El ferrocarril interoceánico -que era una excelente alternativa en ese entonces porque no existía todavía el Canal de Panamá- y la construcción de un moderno puerto en Iztapa para mejorar el comercio internacional fueron los principales proyectos del gobierno, que desafortunadamente quedaron inconclusos cuando la economía guatemalteca colapsó por la caída del precio del café, único cultivo de exportación de Guatemala en ese entonces. Guatemala quedó sumida en una profunda deuda externa con bancos británicos y ya no se pudo continuar con obras de infraestructura; el presidente Reyna Barrios pagó con la vida lo que en ese momento se vio como despilfarro del erario público, ya que fue asesinado el 8 de febrero de 1898.

A finales del gobierno de Reina Barrios ya existía un servicio de tranvías que circulaban sobre rieles y eran tirados por caballos; el servicio era deficiente y las quejas giraban en torno al descuidos de los carruajes, que estaban sucios y malolientes, a la poca educación de los empleados y a la mala organización de las paradas.

1902 fue un año trágico para la ciudad de Quetzaltenango: recién se estaba recuperando del terremoto de San Perfecto en abril, cuando el 24 de octubre de ese mismo año hizo erupción el volcán Santa María. El volcán había estado inactivo desde la conquista española en 1524 y con su cono casi perfecto de 3768 metros de altura, era un marco escénico para la ciudad quetzalteca; pero la erupción fue aún más devastadora que el terremoto, ya que también provocó cuantiosos daños en las fincas y aldeas aledañas y hay recuentos que la arena y ceniza alcanzaro la región de Chiapas, en México. Se calcula que la catástrofe provocó cinco mil muertes y miles de pesos en pérdidas agrícolas y materiales. En agradecimiento por haber salvado su vida en la erupción, el finquero Felipe Yurrita, construyó el bello templo que lleva su apellido a Nuestra Señora de las Angustias y que está localizado en la actual zona 9 de la ciudad de Guatemala.

«La Aurora» era una zona verde con un área de seis caballerías y más de cincuenta manzanas en el sur de la capital y que perteneció al presidente general Manuel Lisandro Barillas Bercián. Cuando Barillas entregó el poder al general José María Reina Barrios en 1892, éste tomó posesión de una gran parte de la finca con el propósito de llevar a cabo su plan de desarrollo de un área recreacional, lo que formaba parte de sus planes de mejoramientos para el crecimiento de la capital. Dichos planes incluían el desarrollo de la finca La Aurora y la construcción de una estación de ferrocarril, el cual iba a correr a lo largo del Bulevar «30 de junio». El eje central de estas mejoras era la Exposición Centroamericana de 1897, la cual se desarrolló en los salones construidos en el bulevar, y cuyo éxito dependía de la finalización del ferrocarril interoceánico, principal proyecto económico de Reina Barrios y que hubiera significado una gran fuente de ingresos para el país si se hubiese concluido a tiempo. Pero la exposición fracasó cuando no se logró construir el ferrocarril, y la situación económica de Guatemala quedó en situación por demás precaria, ya que las deudas en que había incurrido el general Reina Barrios con bancos ingleses eran considerables.

El general Reyna Barrios fue asesinado en febrero de 1898 y sus planes de mejoramiento ya no se concretaron, y su sucesor, el licenciado Manuel Estrada Cabrera tuvo que preocuparse por pagar la deuda inglesa. La finca tenía tres entradas: Pamplona, Los Arcos e Hincapié y había una avenida llamada «Paseo La Aurora» que atravesaba el parque con varias veredas que se conectaban en una plaza central, el cual fue llamado «Plaza Reyna Barrios».

Las necesidades aeroportuarias de la ciudad de Guatemala motivaron la construcción del Aeropuerto La Aurora, cuyas primeras actividades ocurrieron en 1923, durante el gobierno del general José María Orellana; hasta entonces, el Campo de Marte era el espacio que se había utilizado para realizar los primeros experimentos aeronáuticos en Guatemala. Originalmente, la finca La Aurora constaba únicamente de una pista de grama, que eran suficientes para satisfacer las necesidades de la década de 1930.

Los miembros de las élites conservadoras del gobierno de Rafael Carrera y la nueva élite surgida con el advenimiento del cultivo del café durante el gobierno de Justo Rufino Barrios mudaron sus residencias hacia el área del bulevar «30 de junio»; por su parte, ciertos pueblos de indios fueron trasladados forzadamente desde Santiago de los Caballeros de Guatemala y fueron asentados en el área sureste de la ciudad: el barrio «San Pedrito», «Ciudad Vieja» y la «Villa de Guadalupe».

El 24 de enero de 1899 arribó a la ciudad de Guatemala el embajador de México y escritor Federico Gamboa, en representación del gobierno del general Porfirio Díaz. Pocos días después fue invitado al palacio del ejecutivo por el presidente Manuel Estrada Cabrera para intercambiar impresiones; Gamboa describe el palacio de gobierno de ese entonces como un caserón destartalado y feo de los antiguos tiempos coloniales que no era agradable a la vista, aunque en su interior la decoración lo hacía un tanto más agradable. Al fondo del espacioso patio, y a la izquierda se encontraba una antesala llena de oficiales y tras una mampara-vidriera se encontraba el despacho presidencial.

Gamboa recorrió la ciudad y la describió su diario, indicando que el paseo de La Reforma -o Bulevar «30 de junio»- era bellísimo, pero que tenía dos problemas: no había nadie en él y estaba completamente descuidado. Al circular en su carruaje por el paseo de trazado a la europea, logró ver tres o cuatro edificios de buena manufactura, los restos derruidos del salón de la Exposición Centroamericana de 1897, el monumento al general Miguel García Granados y el museo del Palacio de La Reforma con el monumento a Justo Rufino Barrios.

La ciudad también se expandió un poco hacia el norte, especialmente sobre la avenida «Simeón Cañas», en cuyo extremo final se ubicaba el Templo de Minerva, y se construyó el Mapa en Relieve en 1905. Por otra parte, Estrada Cabrera trasladó su residencia a la finca «La Palma», localizada en donde en 1955 se construyó el gimnasio «Teodoro Palacios Flores». Hacia el final del gobierno del licenciado Estrada Cabrera, la población de la ciudad llegaba a ciento veintiún mil habitantes.

Durante el gobierno del licenciado Manuel Estrada Cabrera (1898-1920) se construyeron importantes edificios públicos a lo largo del bulevar «30 de junio»: el asilo de maternidad «Joaquina» -llamado así en honor de la madre del presidente, Joaquina Cabrera- y la academia militar, construida en 1912 luego de que el edificio original fuera demolido tras el intento de asesinato del presidente por los cadetes en 1908.

Puede afirmarse que el inicio del declive de la presidencia de Estrada Cabrera comenzó con los terremotos que se iniciaron el 17 de noviembre de 1917 y arruinaron algunas poblaciones alrededor de Amatitlán. El 25 y el 29 de diciembre de ese mismo año, y el 3 y el 24 del siguiente, se repitieron los temblores en la república, pero con mucha mayor fuerza, de modo que destruyeron numerosos edificios públicos y religiosos, así como casas particulares en la ciudad de Guatemala y en la Antigua Guatemala. Entre los edificios destruidos destacaban numerosas estructuras que habían sido construidas en los gobiernos de José María Reyna Barrios (entre ellos el pabellón de la Exposición Centroamericana, y el palacio del bulevar 30 de junio) y de Estrada Cabrera (asilo para damas Doña Joaquina); por esta razón, mucha de la obra física de ambos presidentes ha sido olvidada por generaciones posteriores.

En el "Diario de Centro América", después de publicar dos ediciones diarias reportando los desastres, se pasó a hacer crítica al Gobierno por la lenta e ineficiente respuesta al desastre. En uno de los artículos de opinión de este periódico oficial se llegó a decir que las imágenes religiosas de algunos templos católicos de la ciudad se habían salvado porque, al momento del primer terremoto, «ya no quisieron seguir en una ciudad en donde imperaba el lujo excesivo, la impunidad y el terror». Por otra parte, se dijo que existían leyes «excelentes» para la reconstrucción, las cuales, sin embargo, «no se cumplen». También se dijo que estaba ocurriendo un fenómeno que se daba siempre en casos de cataclismos como estos: «se emiten leyes y reglamentos a diario, pero lo que se necesita es de su correcta ejecución diaria, y no de tantos reglamentos». Además, se publicó en primera plana, tres meses después de los terremotos, que «todavía hay escombros por toda la ciudad». El propio "Diario de Centro América" era editado entre escombros, pese a lo cual logró tirajes de ejemplares de media hoja, a veces hasta dos al día, durante la crisis.

En "El Guatemalteco", diario oficial del Gobierno, quedó huella del desastre: desde el número correspondiente al 22 de diciembre se interrumpió la publicación y no se reanudó sino hasta el 21 de enero de 1918, pero en un formato mucho más pequeño.

La comisión de Hacienda encargada de la reconstrucción de la ciudad, después del terremoto, por fin decidió crear un Banco Nacional Privilegiado con un capital de 30 millones de pesos (que provendrían de un préstamo a bancos extranjeros), lo cual hundió la economía nacional. Debe destacarse que uno de los miembros directivos de esta comisión fue Carlos Herrera y Luna, quien luego sería presidente de Guatemala.

El Hipódromo del Sur fue inaugurado oficialmente en 1923 por el presidente general José María Orellana, y fue un lugar de gran popularidad en el parque nacional «La Aurora». La pista de hipódromo tenía una longitud de 1600 metros por 30 metros de ancho y capacidad para 1600 espectadores; sus instalaciones incluían caballerizas, establos y graderías techadas. En esa época se podía admirar los ejercicios hípicos, jaripeos, y carreras de caballos. En 1926, el presidente general Lázaro Chacón ordenó la construcción de nuevas instalaciones y remodelaciones del hipódromo para aumentar la diversidad de los eventos, ferias y amenidades, lo que mantuvo a la estructura en continua remoldelación y expansión.

En 1931, durante los primeros días de la presidencia del general Jorge Ubico (1931-1944) se terminó la construcción de nuevas instalaciones en el hipódromo las cuales incluían la tribuna presidencial y garitas para los jueces de campo. En 1935 se terminó la construcción de la primera concha acústica en Guatemala en las inmediaciones del hipódromo y se inició la celebración de una feria internacional, para la cual se instalaron juegos mecánicos y se presentaron eventos culturales y sociales de todo tipo. La feria se celebraba en noviembre, en honor al cumpleaños del general Ubico.

Durante el resto del gobierno del general Jorge Ubico la ciudad se expandió hacia el sur, con la construcción del edificio del Aeropuerto Internacional La Aurora sobre la Avenida de Hincapié, los salones de exposiciones de la «Feria de noviembre» La prolongación de la séptima avenida fue adornada con la «Torre del Reformador» y con el traslado de la «Fuente de Carlos V» desde el Parque Central hacia la «Plazuela España». Ubico también construyó palacios: el Palacio Nacional, el de la Policía, el de Correos y Telégrafos, la Aduana Central, el Congreso de la República y el de la Corte Suprema de Justicia. Por esos años, las residencias en la Reforma eran de madera, estilo norteamericano, construidas así para resistir terremotos. Había muchos sitios baldíos, no sólo en la Reforma, sino también en los cantones «Tívoli», «Santa Clara» y «Pamplona».

Ubico Castañeda designaba al Intendente Municipal y éste se concentraba en atender la modernización de servicios básicos en el casco central de la ciudad y las áreas hacia el sur, a donde se habían empezado a desplazar los miembros de los sectores de altos ingresos y la construcción de los palacios consumieron aproximadamente el 35% de la producción de cemento. Por otro lado, se descuidaron los barrios periféricos que se habían formado o poblado tras los terremotos de 1917-18; estos barrios eran «La Parroquia», la «Ermita», «Candelaria», «La Reformita», «El Gallito», «Gerona» y «La Palmita», entre otros. Estos barrios pobres estaban habitados por familias de muy bajos ingresos que vivían en condiciones de hacinamiento y deficiente dotación de servicios básicos.

Por otra parte el gobierno de Ubico Castañeda compró la «Finca La Verbena» en los «Llanos de Urbina»en 1935 para la construcción de una ampliación del Cementerio General de la ciudad de Guatemala, el cual estaba por colapsar. En 1939, el gobierno inauguró el nuevo cementerio: el «Cementerio La Verbena». Los trabajadores del cementerio habitaron los alrededores de la localidad e invitaron a sus amigos y familiares a residir en el sector, sin pagar por los derechos correspondientes dando origen a la colonia «La Verbena». Cuando los funcionarios del gobierno se dieron cuenta de lo que estaba ocurriendo, prohibieron el ingreso de materiales a la finca. Esta situación cambió luego de la renuncia del general Ubico el 1.º de julio de 1944, y de la revolución de octubre de 1944: aprovechando los cambios drásticos que estaban ocurriendo en el país, continuaron las invasiones.

Cuando ocurrió la Revolución de 1944, la ciudad tenía un escaso desarrollo urbano, que se reflejaba en una deficiente y diferenciada cobertura de servicios esenciales -dotación de agua, drenajes, electricidad y pavimentación de calles- así como pocas posibilidades de trabajo para la población, por la casi inexistente industrialización; excepto por una fábrica de cercza, otra de cemento y algunas textileras y jaboneras, las principales actividades económicas eran agrícolas y artesanales. Guatemala dependía en todo de la importación de artículos tanto sunturarios como necesarios.

Con los gobiernos revolucionarios se inició un nuevo concepto de la administración municipal, basado en la autonomía y en la elección de las corporaciones por la población de los municipios, aunque desde el principio, esta situación tuvo repercusiones en el desarrollo urbano de la ciudad, ya que existieron fricciones políticas entre el gobierno y las corporaciones ediles. El primer alcalde electo de la ciudad de Guatemala fue el licenciado Mario Méndez Montenegro (1946-1948). Durante su gestión se amplió la red de agua potable y drenajes hacia algunos barrios periféricos y se inició la construcción de grandes colectores que recogen aguas negras del norte de la ciudad, dirigiéndolas hacia el río «Las Vacas» y hacia el barranco de «La Pedrera». Construyó también el parque infantil Colón en la zona 1 y prolongó la sexta avenida, tras derrumbar el cerro en donde se encontraba la antigua iglesia de «El Calvario» de la ciudad.

El gobierno del doctor Juan José Arévalo construyó la «Ciudad de los Deportes» en la zona conocida como «La Barranquilla»; este complejo tiene instalaciones adecuadas para la práctica del fútbol y del atletismo, una piscina olímpica, varias canchas de tenis y el «Palacio de los Deportes». Inaugurado en 1951, es el complejo deportivo más moderno y completo de Guatemala; ya para esta épocal, la población de la ciudad había crecido a 250 000 habitantes.

Uno de los alcaldes más destacados fue el ingeniero Martín Prado Vélez, quien asumió en el año 1949. De origen cobanero, estudió en la Universidad de San Carlos y bajo su mandato, entre otras obras modernistas de la ciudad, se construyeron o iniciaron importantes obras de infraestructura: el Puente El Incienso, la construcción de la Avenida Roosevelt, principal eje vial de este a oeste de la Ciudad, el propio edificio consistorial, y numerosas obras viales que significaron el ensanche de la ciudad colonial, su ordenamiento en puntos cardinales y la generación de un anillo periférico con el primer trébol en la principal ciudad de Centro América. Uno de sus principales colaboradores fue su amigo, el ingeniero Raúl Aguilar Batres, quien fue el jefe de planificación de la municipalidad en esa administración y en las posteriores.

En 1952, ganó las elecciones a alcalde Juan Luis Lizarralde, apoyado por el «Partido de Unificación Anticomunista» (PUA), el «Comité de Estudiantes Universiarios Anticomunistas» (CEUA), la «Unión Patriótica» y la «Juventud Nacionalista». Esta administración tuvo enfrentamientos con el gobierno del coronel Arbenz, pero el gobierno, mediante obra pública intervino en la producción de nuevos espacios en la ciudad y, en algunos casos, en la valorización de la tierra que fue incorporada a la ciudad por medio de los nuevos ejes viales como la carretera Interamericana que se construyó a partir del Hospital Roosevelt..

Éste es uno de los puentes más importantes de la ciudad de Guatemala, ya que constituye el inicio de la carretera al Atlántico -desde 2010 bautizada como carretera «Jacobo Árbenz Guzmán»- se empezó a construir en 1951, durante el gobierno del coronel Jacobo Arbenz Guzmán como parte de su proyecto de construir una carretera al Atlántico que compitiera con el monopolio que hasta entonces tenía el ferrocarril de la compañía International Railways of Central America (IRCA). La construcción estuvo a cargo de la empresa alemana Krupp, y tuvo un costo total de Q. 1,500,000.00. Tras el derrocamiento del coronel Arbenz en 1954, los gobiernos contrarrevolucionarios de Carlos Castillo Armas y de Miguel Ydígoras Fuentes continuaron con la construcción de la carretera al Atlántico y, por ende, del puente Belice. El puente se inauguró finalmente el 18 de noviembre de 1958 en una ceremonia que contó con la presencia del presidente general e ingeniero Miguel Ydigoras Fuentes junto con su esposa María Teresa Laparra de Ydigoras; durante dicha ceremonia se develó la placa colocada en la entrada del puente con la siguiente leyenda: «"Puente Belice": Del pueblo de Guatemala a sus compatriotas beliceños».

En 1958, aduciendo que el municipio de Mixco, al que pertenecía por su ubicación geográfica, no le proporcionaba los suficientes recursos para satisfacer sus necesidades de alumbrado público, electricidad, drenajes y agua potable, la colonia «La Florida» solicitó y fue autorizada a incorporarse al municipio de la ciudad de Guatemala. Aunque sus servicios no fueron satisfechos a su satisfacción, y en 1964 estaba solicitando que se le declarara un ente autónomo, la colonia ha permanecido desde entonces como parte de la ciudad en la zona 19.

En 1967 el alcalde Ramiro Ponce Monroy empezó con el plan de construcción de un viaducto sobre la 24 calle de la zona 4 a fin de aliviar el tráfico en el área; el costo del proyecto fue estimado en de un millón doscientos setenta y cinco mil quetzales y estaría terminado a finales de 1968. El proyecto tenía contemplado empezar en la 12 avenida de la zona 5 y extenderse por toda la 24 calle hasta llegar a la avenida del Cementerio, en la zona 3; iba a tener dos carriles vehiculares de siete metros de ancho cada uno, divididos por un arriate central de 1.20 metros de ancho, dos arriates laterales de un metro de ancho y seis puentes: sobre la 7.ª y la 6.ª avenidas, sobre la avenida del Ferrocarril, sobre la Avenida Bolívar y sobre la Avenida Elena. Desafortunadamente, el proyecto no se pudo realizar porque la Municipalidad afrontaba una seria crisis económica y tuvo que solicitar al Congreso de la República que emitiera un decreto para que se declarara la construcción del viaducto de utilidad colectiva, beneficio e interés público. Pero esto no logró que se consiguiera un valor adecuado para los terrenos que tenían que expropiarse y el 17 de julio de 1968 el concejo municipal desistió de la construcción del viaducto. El proyecto permaneció archivado hasta el 20 de enero de 1970, cuando los trabajos se iniciaron por fin: la primera fase abarcaba desde el Palacio de los Deportes, en la Ciudad Olímpica, hasta la 6.ª avenida de la zona 4, con una longitud de 500 metros; finalmente, el 14 de enero de 1971, el nuevo alcalde Manuel Colom Argueta y el ingeniero Fernando Maselli —director del proyecto— informaron que las obras iban a terminarse en el 19 de febrero de ese año. La obra ya no continuó hasta la avenida del Cementerio porque el costo de las expropiaciones no se pudo resolver.

El licenciado Manuel Colom Argueta asumió la Alcaldía de la ciudad de Guatemala de 1970 a 1974, en condiciones desventajosas, pues en lugar de apoyo por parte del gobierno central del general Carlos Arana Osorio siempre encontró obstáculos, como el retraso en la aprobación del "Plan Regulador de Desarrollo Metropolitano", el retraso en la gestión de fondos para obras municipales, el hecho que el gobierno central se haya adjudicado la construcción del puente «Martín Prado Vélez» (Puente «El Incienso») para quitarle el crédito a la gestión municipal. Aun así su gestión municipal impulsó obras y acciones de beneficio ciudadano bajo una visión integral de gobierno municipal y desde la perspectiva de la urbanización planificada; durante su administración se construyeron, entre otros, un sistema de drenaje profundo, colectores gigantes, la primera fase del anillo periférico -que conecta a las zonas 1, 7, 11 y 12-, el viaducto de la 24 calle de la zona 1, mercados, parques, campos deportivos, farmacias municipales, y se constituyó la Empresa Municipal de Agua potable (EMPAGUA), encargada del proyecto de obtención de agua del acueducto Xayá–Pixcayá.

El 4 de febrero de 1976, a las 3:03 de la madrugada aproximadamente fue sacudida por un fuerte terremoto que afectó a todo el país. Zonas como la zona 3 quedaron totalmente destruidas, los hospitales estaban destruidos, se acabó el combustible y mucha gente murió. El terremoto fue de 7.5 en la escala de Richter y causó más daños y más muertos en la periferia que en el centro debido a las precarias construcciones de adobe que existían en ese entonces.

La zona más afectada cubría alrededor de 30.000 km², con una población de 2,5 millones de personas. Cerca de 23.000 personas fallecieron y 77.000 resultaron gravemente heridas. Aproximadamente 258.000 casas fueron destruidas, dejando a cerca de 1,2 millones de personas sin hogar. 40 % de la infraestructura hospitalaria nacional fue destruida, mientras que otros centros de salud también sufrieron daños sustanciales. Aparecieron grietas en el suelo en muchos lugares del país, y algunas llegaron a medir hasta un metro de ancho; tambié lo alto de algunos cerros se agrietó y luego los cerros se desmoronaron, soterrando pueblos enteros y carreteras.

A medida que se recuperaban los cuerpos la magnitud del desastre quedaba al descubierto; las autoridades organizaron la excavación de tumbas colectivas, la cantidad de muertos era tan grande que no tuvieron alternativa. Muchos puentes, torres de alta tensión, postes de luz y de teléfonos y carreteras colapsaron o se destruyeron. Los rieles de las líneas de los ferrocarriles se retorcieron como culebras. Varios departamentos del país fueron afectados por el sismo: Chimaltenango, Chiquimula, El Petén, Guatemala, Izabal y Sacatepéquez al igual que muchos pueblos y ciudades; las instalaciones portuarias de Puerto Barrios, cabecera del departamento de Izabal, quedaron destruidas. La Ciudad de Guatemala y sus alrededores sufrieron los peores daños, a pesar de estar lejos del epicentro del temblor; la periferia de la ciudad quedó más destruida que el centro debido a que las casas estaban hechas de adobe, el Palacio Nacional y la vecina Casa Presidencial no sufrieron mayores daños. Los templos católicos de la Catedral Metropolitana, la Iglesia la Recolección y la Ermita del Carmen en el cerro del mismo nombre sufrieron daños considerables. La ciudad de Guatemala era un caos, miles de personas estaban sepultadas entre los escombros, muchas muertas o heridas de gravedad. En San Juan Sacatepéquez, la municipalidad se derrumbó parcialmente.

El jueves 31 de enero de 1980, el caso de Guatemala atrajo la atención mundial con la quema de la Embajada de España, en la que 37 personas fueron quemadas vivas, entre ellas varios ciudadanos españoles y eminentes juristas guatemaltecos. La movilización en forma de protesta por parte de un grupo de indígenas, con el fin de llamar la atención del mundo sobre las matanzas que en 1980 cometía el Ejército guatemalteco en El Quiché durante el gobierno del general Fernando Romeo Lucas García, fue el preludio del caso de la quema de la Embajada de España. Al final de los hechos, treinta y siete personas, incluyendo importantes funcionarios guatemaltecos que estaban en la embajada al momento de la toma de los indígenas, murieron calcinadas dentro las instalaciones luego de que la policía intentara tomar la embajada por la fuerza; a raíz del suceso, España rompió relaciones diplomáticas con Guatemala.

El 5 de septiembre de 1980 se dío un ataque terrorista del Ejército Guerrillero de los Pobres frente al Palacio Nacional con la intención de disuadir al pueblo guatemalteco de asistir a una manifestación de apoyo al gobierno del general Lucas García que estaba planificada para el domingo 7 de septiembre en el Parque Central. En ese ataque murieron seis adultos y un niño a causa de la explosión de dos bombas ubicadas en un vehículo; hubo un número indeterminado de heridos y cuantisoso daños materiales no sólo en las obras de arte del Palacio Nacional, sino que en muchos de los edificios aledaños, especialmente en el Edificio Lucky, que está frente al Palacio Nacional sobre la 6a. avenida. Entre los muertos se contaban: Domingo Sánchez, piloto del Ministro de Agricultura; Joaquín Díaz y Díaz, limpiador de automóviles; y Amilcar de Paz, agente de seguridad. Las imagénes por televisión mostraban partes de los cuerpos distribuidos por el área del incidente, mientras los periódicos mostraron en sus portadas la imagen de carro bomba destruido y los alrededores del palacio.

El atentado fue ejecutado en dos partes: primero, por la noche, la guerrilla depositó una pequeña carga explosiva en el tragante ubicado en el Parque Central, en la esquina de la 6a. calle y 6a. avenida de la zona 1, frente a la esquina donde se localizaba el despacho presidencial dentro del Palacio Nacional. Por la mañana, la guerrilla estacionó un vehículo sobre ese tragante, el cual tenía en su interior una carga mucho mayor; a las 9:35 a.m. detonaron la pequeña carga explosiva, la cual a su vez hizo estallar a la que estaba dentro del vehículo dejando esparcidos tras ser mutilados, los cuerpos de varios civiles, cuyos restos humanos fueron lanzados en un radio mayor a los 70 metros. A los cinco minutos de haberse producido la explosión se originó el incendio de siete vehículos.

Ese mismo día, y también para tratar de impedir el desarrollo de la manifestación, la guerrilla también la terminal de los autobuses Galgos, y a un bus de la empresa Fortaleza, matando a un mecánico.

Imágenes de los ataques se pueden ver en el sitio web de Luis Figueroa: 

El ataque de grupos guerrilleros en contra de objetivos financieros, comerciales y agrícolas se incrementó durante el gobierno del general Fernando Romeo Lucas García, ya que los grupos guerrilleros consideraban a esas instituciones como «reaccionarios burgueses» y «millonarios explotadores» que colabaran con el «gobierno genocida». La siguiente es una lista no exhaustiva de los atentados en la ciudad de Guatemala que quedaron registrados en el informe de la Comisión para el Esclarecimiento Histórico de las Naciones Unidas:

En 1979, la moneda guatemalteca, el quetzal se cotizaba a un dólar estadounidense; pero para finales del 1985 el tipo de cambio era de Q1.47 por dólar, en 1987 era de Q2.53 y ya para 1990 había caído a Q5.57 por dólar; este fenómeno impactó desigualmente a la sociedad: por un lado, para los productores de artículos cada modificación del tipo de cambio es rápidamente transferida al consumidor, mediante la revaluación de los precios; por el otro, la gran mayoría trabajadora de la población no tiene un mecanismo similar de compensación y la devaluación resulta en una erosión constante de sus ingresos. Estos cambios estuvieron basados en el enfoque económico neoliberal que indica que al jerarquizar la satisfacción de las necesidades, racionando la utilización de sus escasos recursos, se genera una libertad de elección para los consumidores; sin embargo, el resultado fue la limitación de la capacidad adquisitiva de los mismos.

Como resultado, en 1982 se llevaron a cabo diez distintas invasiones, pero éstas fueron rápidamente desarticuladas por los gobiernos militares de entonces. En 1984, se realizaron cinco, de las cuales solamente una prosperó: El Mezquital, que llegó a abrigar hasta cuarenta y cinco mil habitantes.

Con el inicio del gobierno del licenciado Marco Vinicio Cerezo Arévalo en 1986, se iniciaron también invasiones de terrenos como no se habían visto antes en la historia de la ciudad; con invasiones de Villa Lobos I y II en Villa Nueva -que para entonces ya era parte de la zona metropolitana de Guatemala- en 1988, terrenos en los Campos del Roosevelt en las cercanías del hospital del mismo nombre en la zona 11 en 1989 y de terrenos baldíos en la colonia Bethania, zona 7, Santa Elisa en la zona 18, Ciudad Peronia y terrenos en el relleno sanitario de la zona 3, aunque este último fue desalojado violentamente por el pelotón antimotines de la policía en 1990.

Durante el gobierno de Óscar Humberto Mejía Víctores nació el Grupo de Apoyo Mutuo (GAM) liderado por Nineth Montenegro y también cobró una fuerza considerable la Coordinadora de Estudiantes de Educación Media -CEEM-, formada por esstudiantes del Instituto Nacional Central para Varones, el instituto Normal Central para Señoritas Belén y el Instituto Rafael Aqueche- la cual organizó masivas protestas en septiembre de 1985 en contra del alza de los precios de los transportes públicos. Al menos diez personas murieron en la ciudad de Guatemala en la oleada de disturbios urbanos más extensos desde las protestas contra el gobierno de Fernando Romeo Lucas García en agosto de 1978. Los disturbios se iniciaron con manifestaciones populares contra el alza del precio del transporte público pero luego se generalizaron contra la situación económica que vivía el país en ese momento. Incendio de autobuses urbanos, toma de calles y manifestaciones masivas que resultaron en destrozos de la infraestructura pública ocurrieron casi todos los días.

El gobierno respondió con tres mil soldados del Ejército, apoyados por blindados ligeros, y con fuerzas del pelotón antimotines de la Policía Nacional, quienes fueron desplegados en áreas céntricas y periféricas de la ciudad. También, la noche del 3 de septiembre la Universidad de San Carlos de Guatemala fue ocupada militarmente y se dijo que en su interior se encontró un polígono de tiro subterráneo y propaganda subversiva.

Varios centenares de personas fueron detenidas y el general Mejía Víctores se dirigió al país mediante una alocución radiotelevisada en la que anunció medidas para atajar la agitación social reinante. El general Mejía anunció el cierre de centros docentes hasta nuevo aviso y la congelación de precios de los artículos de consumo; al final, como parte de la solución del proceso se otorgó un bono estudiantil para que los estudiantes de educación primaria y media se transportaran gratuitamente en los buses urbanos, y se promovió a los estudiantes por decreto.

Durante estos disturbios hicieron su aparición grupos organizados de pandilleros de áreas marginales de la ciudad de Guatemala, quienes se presentarían posteriormente como las maras y que estuvieron influenciadas inicialmente por el estilo de baile breakdance que llevaban a Guatemala los jóvenes deportados de los Estados Unidos.

El crecimiento que ha tenido la ciudad se ha dado desordenadamente en todas direcciones, siendo predominantes el sur occidente y el sur oriente. Su crecimiento ha sido tan grande que ha tomado varias poblaciones que en sus inicios se encontraban en lejanías o pertenecían a otro municipio y que, por el actual sobrepaso de sus límites jurisdiccionales se le ha llamado Área Metropolitana de Guatemala. Algunas de estas son Mixco, Santa Catarina Pinula, Villa Nueva y San José Pinula. También se ha dado el fenómeno de las Ciudades Dormitorio, como Fraijanes, Villa Canales y Amatitlán. En estas ciudades y pueblos, los desarrollos urbanísticos son muchos y muestran el gran crecimiento poblacional directamente de la ciudad, ya que ésta aún padece de escasez de vivienda que baste para toda la población, lo que fomenta la aparición de barriadas en zonas de alto riesgo, como las laderas y barrancos, que son característicos de la región.

Este crecimiento desordenado de la ciudad llevó a la aparición de congestionamientos de tránsito; para paliar esta situación, se empezaron a construir pasos a desnivel. El primero de estos fue el paso a desnivel de Tecún Umán entre las zonas 8, 9 y 13. La obra consiste en cuatro puentes de concreto preforzado, así como un sistema de intercambios a desnivel de vías sin restricción de altos, para el tránsito de vehículos por el Bulevar Liberación, en el sentido oriente-poniente, calle Montúfar, avenida La Castellana y 7.ª Avenida de la zona 13 hacia la zona 1 de la ciudad. La obra se llevó a cabo en tres fases, iniciándose en octubre de 1991 y terminándose el 31 de agosto de 1993.

En 2010 la ciudad sufrió daños por la tormenta tropical Agatha, por la gran cantidad de lluvia en un corto periodo. El sistema de drenajes sufrió un colapso causando un gran socavón en uno de los recorridos en la zona norte.

Cuatro volcanes son visibles desde la ciudad, dos de ellos activos. El más cercano y más activo es el volcán de Pacaya, que a veces expulsa una cantidad considerable de ceniza; los otros son: el Volcán de Fuego, Volcán Acatenango y Volcán de Agua. El 27 de mayo de 2010 por la noche, el volcán de Pacaya hizo erupción; la columna de ceniza alcanzó hasta mil quinientos metros de altura afectando a la ciudad de Guatemala y otros 3 departamentos de la República. Causó el cierre del Aeropuerto Internacional La Aurora, pues dicha erupción produjo una lluvia de arena volcánica en toda la ciudad de Guatemala, Escuintla y Sacatepéquez; la operación aérea se pudo reanudar hasta cinco días después. La CONRED -Coordinadora Nacional para la Reducción de Desastres- declaró una alerta roja para las comunidades cercanas al volcán, y recomendó la evacuación de algunas de ellas.

La erupción del volcán causó numerosos heridos y dos muertes, entre ellas la del reportero Aníbal Archila, del telediario guatemalteco «Noti-7», que fue uno de los primeros en llegar a cubrir el acontecimiento. El presidente Álvaro Colom decretó un Estado de Calamidad Pública, el Ministerio de Educación suspendió las clases en los departamentos de Guatemala, Escuintla y Sacatepéquez y el Congreso de la República de Guatemala se reunió el martes 1.° de junio en sesión extraordinaria para ratificar el Estado de Calamidad Pública.

El cantante argentino Facundo Cabral se presentó en la ciudad de Guatemala el martes 5 de julio de 2011 en el Expocenter del Grand Tikal Futura Hotel. El jueves 7 se presentó en el que sería su último concierto, en el Teatro Roma de la ciudad de Quetzaltenango, el cual cerró interpretando la canción "No soy de aquí, ni soy de allá".

Fue asesinado el 9 de julio de 2011 alrededor de las 5:20 a.m., en Ciudad de Guatemala, víctima de un atentado aparentemente dirigido al empresario Henry Fariña el cual conducía al cantautor y a su representante al Aeropuerto Internacional La Aurora desde el hotel donde se hospedaba, para continuar en Nicaragua con su gira de presentaciones. El atentado fue perpetrado por varios sicarios que se dirigían en tres vehículos y armados con fusiles de asalto en el Boulevard Liberación de dicha ciudad, quedando únicamente herido el empresario y fallecido el cantautor.

En julio del 2012 fiscales nicaragüenses dijeron que Cabral fue asesinado por parte de una disputa entre Alejandro Jiménez González y Henry Fariñas, ambos miembros de la pandilla "Los Charros" aliada con La Familia Michoacana e involucrada en el lavado de dinero en cantidades de más de mil millones de dólares.

La ciudad de Guatemala es la aglomeración urbana más poblada de América Central.Durante la década de 2010 su población se ha duplicado, ya que según el censo de 2002 había 2.3 millones de habitantes en la ciudad mientras que el censo de 2013 reportó 4.3 millones de habitantes. El Instituto Nacional de Estadística estima que la ciudad de Guatemala alberga casi el veinticinco por ciento del total de la población guatemalteca y la mitad de la población urbana del país, con casi el cuarenta y nueve por ciento. 

La mayor parte de la población económicamente activa se concentra en la zona industrial a lo largo de la Avenida Petapa, el área residencial de la Avenida las Américas, la Avenida la Reforma, el Boulevard Liberación, Zona Viva, Zona Pradera y el corredor comercial de la séptima avenida de la zona 9. También existe una alta densidad poblacional en el área comercial de Peri-Roosevelt en donde se encuentran centros comerciales que abastecen a esa área de la ciudad. Toda esta actividad comercial hace que el distrito metropolitano de la ciudad sea el municipio con menos índice de pobreza en el país con solamente el 6.3 por ciento y que la tasa de alfabetismo sea de más del noventa y cinco por ciento -una de las tasas más altas del país. Finalmente, la ciudad de Guatemala posee un mayor porcentaje de personas adultas y de tercera edad que el resto el país, con un treinta y nueve por ciento. 

Etnográficamente la población de ascendencia europea ocupa el sesenta y nueve por ciento de la población total de la ciudad y está compuesta por descendientes de españoles -cuarenta y cuatro por ciento-, de alemanes -diez por ciento-, italianos -siete por ciento- y franceses -cuatro por ciento- con el porcentaje restante compuesto por descendientes de ingleses, suecos, holandeses, belgas. El 18.2 por ciento de los habitantes son personas mestizas con ascendencia europea, amerindia, africana y -en menor medida asiática-, el 6.6 por ciento de la población es indígena (principalmente k'aqchiquel).

La población de la ciudad de Guatemala es predominantemente cristiana, debido al fuerte arraigo de la religión Católica desde la época colonial y al auge de las denominaciones protestantes a partir de la segunda mitad del siglo . Entre los mayores símbolos religiosos está la Catedral Metropolitana —construida en el siglo , la celebraciones católicas de la Semana Santa, la feria de la localidad que se celebra el 15 de agosto en honor al Día de la Asunción—, y la Casa de Dios, una mega iglesia protestante construida a principios del siglo en las afueras de la ciudad.

El protestantismo ha crecido considerablemente en las últimas décadas, aunque históricamente desde la década de 1870 la ciudad cuenta con población protestante -la que inicialmente era menor del 1% y era únicamente la Iglesia Prebiteriana Central-. El auge protestante se ha visto facilitado por el debilitamiento de la religión católica en el país, el cual ha sido un proceso largo que ha sido influenciado principalmente por cuestiones políticas locales: las reformas borbónicas del siglo que iniciaron el debilitamiento del poderío de la iglesia sobre la corona española, las órdenes regulares de la Iglesia Católica habían sido expulsadas del territorio centroamericano en 1829 por los liberales comandados por Francisco Morazán, pero retornaron en 1840 luego de la victoria del general Rafael Carrera; el clero secular, por su parte, no fue expulsado, pero se le retiró el diezmo obligatorio, lo que lo debilitó considerablemente. Durante el régimen de Carrera las órdenes regulares se fortalecieron y gracias a la fuerte relación con el gobierno conservador, consiguieron tomar el control de la educación del país mediante el Concordato de 1854 y que se les retornaran las posesiones que les habían sido confiscadas en 1829. El clero secular, por su parte, se vio beneficiado por sus relaciones con el Clan Aycinena y por la imposición del diezmo obligatorio.

En 1872, tras el derrocamiento de los conservadores y la toma del poder por los liberales liderados por Miguel García Granados y Justo Rufino Barrios, las órdenes regulares fueron expulsadas nuevamente y el diezmo obligatorio fue eliminado, debilitando considerablemente al clero secular. El gobierno adoptó una postura agnóstica y positivista y promulgó leyes laicas para eventos que anteriormente eran exclusivamente controlados por los religiosos -por ejemplo, matrimonios, divorcios y partidas de nacimiento y defunción-. El gobierno liberal también permitió el ingreso de la Iglesia Presbiteriana, que se constituyó en la primera religión protestante legal en el país, pues anteriormente ya habían estado en Guatemala ciudadanos ingleses protestantes que negociaban con el gobierno conservador. El gobierno liberal incluyó en la constitución de 1879 la prohibición de que las congregaciones religiosos poseyeran bienes y estableció a la educación laica como la única obligatoria.

Esta situación se mantuvo incluso hasta después del derrocamiento del general Jorge Ubico, último dictador liberal del país, pues la constitución de 1945 mantiene las prohibiciones que los liberales incluyeron en 1879. El arzobispo Mariano Rossell y Arellano comprendiendo la difícil posición de la iglesia, se alió con los grupos anticomunistas que finalmente derrocaron al régimen revolucionario del coronel Jacobo Árbenz Guzmán en 1954 y consiquió que el gobierno contrarrevolucionario incluyera en la constitución de 1956 que las iglesias pudieran poseer bienes y que la educación religiosa fuera apoyada por el estado. Estos cambios fueron determinantes para la religión el país, porque si bien permitieron a las órdenes regulares retornar a Guatemala y recuperar algunos de sus bienes, también permitió el auge de todas las otras religiones, principalmente de los protestantes evangélicos.

Una de las mayores iglesias protestantes es la iglesia Casa de Dios con más de doce mil miembros; otras iglesias, como El Shaddai, Ministerios Ebenezer, Elim Central, han aparecido y se han fortalecido desde que se levantó la prohibición de que las iglesias poseyeran bienes e impartieran educación en 1956. 

Otros grupos cristianos pequeño son los Mormones, Adventistas del Séptimo Día, Ortodoxos y Testigos de Jehová. Finalmente, debido a la llegada de extranjeros de origen árabe, israelí y asiático, existen comunidades de Judaísmo, Musulmanes y Budistas.

Ciudad de Guatemala se manifiesta como una de las regiones más seculares de Guatemala, donde el 17 por ciento dice no tener afiliación religiosa o dice ser ateo o agnóstico.

El servicio de transporte está constituido principalmente por el servicio de buses urbanos, existen 336 rutas y cobran una tarifa de Q.2 (unos 26 centavos de dólar, aproximadamente), sin embargo cabe destacar la importancia de las dos líneas de transporte masivo (BRT) denominada Transmetro promovida por la municipalidad de Guatemala, la primera ruta sale de la Central de la zona 12 hasta el centro cívico de la capital (eje sur), y la segunda sale del centro cívico hacia la zona 13 de la ciudad (eje central). En la actualidad se trabaja en la segunda fase de esta línea, aunque está en proyecto la implementación de doce nuevas rutas del citado sistema Transmetro. También se implementó un sistema de autobuses en toda la ciudad capital, denominado Transurbano, en el cual se reemplazaron los buses urbanos por autobuses en los cuales ya no se paga en efectivo, sino que se utiliza una tarjeta en la cual se le descuenta el pasaje a fin de reducir la frecuencia de asaltos a los pilotos urbanos.

También en la ciudad se encuentra el Aeropuerto Internacional La Aurora, ubicado en medio de la ciudad y con una red de 29 vuelos internacionales diarios a las principales ciudades de América y Europa mediante 17 líneas aéreas, también tiene 3 vuelos nacionales diarios hacia el Aeropuerto Internacional Mundo Maya, ubicado en el departamento de Petén. Es uno de los más grandes y modernos de la región centroamericana y cuarto por su tráfico aéreo después de la ciudad de Panamá, San José de Costa Rica y San Salvador.

La ciudad de Guatemala cuenta con diversas carreteras y autopistas que la conectan al resto del país, como la autopista «Palín-Escuintla» hacia el sur, la carretera «Jacobo Arbenz Guzmán» hacia el Atlántico y el norte, la carrera «a El Salvador» (carretera Panamericana hacia el oriente del país) y las carreteras que se derivan de la carretera Panamericana y que la conectan al occidente del país, específicamente a los departamentos de Quetzaltenango, San Marcos, Huehuetenango y Quiché.

La ciudad tiene además de una gran variedad de restaurantes, centros comerciales, plazas, hoteles y tiendas, cerca de trescientas galerías y museos (incluyendo reconocidas colecciones de arte precolombino); asimismo, existen trece universidades: doce privadas y una nacional, la cual tiene varios centros de estudios en diferentes zonas de la ciudad.

La ciudad está dividida en 25 zonas (omitiendo las zonas 20, 22 y 23 que son parte de otros municipios), lo cual hace muy sencillo encontrar direcciones gracias al plan urbanístico diseñado por el ingeniero Raúl Aguilar Batres. Guatemala tiene una estructura cuadrada que se expande en todas las direcciones lo cual es una característica importante del urbanismo neoclásico de principios de siglo. La ciudad posee muchas avenidas y bulevares amplios y decorados; como la «Avenida La Reforma», «Vista Hermosa», «Los Próceres», y «Avenida de Las Américas» entre otros. Su trazado antiguo y su ubicación (un valle rodeado de barrancos profundos) hace que las vías de acceso principales sean pocas, lo cual causa una severa congestión de tráfico, al igual que el desarrollo de otras áreas antes tomadas como marginales como la Ruta al Atlántico «Jacobo Árbenz Guzmán» entre las zonas 17 y 18, área que ha demostrado un gran poder comercial.

La industria está concentrada mayormente en la zona 12, a ambos lados de la Avenida de Petapa, convirtiendo a esta zona en la más contaminada de la ciudad. Asimismo, modernos proyectos urbanísticos colocaron a las contaminantes fábricas en las cercanías de las carreteras hacia el Pacífico y el Atlántico y lo que será el gran proyecto del anillo metropolitano. Grandes áreas comerciales se construyeron en distintos puntos de la capital, entre las que destacan el complejo urbanístico del parque comercial «Las Majadas» que agrupa el área comercial más grande del país ya que en él se encuentran quince centros comerciales.

Existen diversas zonas residenciales en la ciudad aunque debido al crecimiento de la población y el desarrollo económico muchas áreas ahora son de carácter mixto compartiendo residencias, comercios y en algunos casos industrias. Debido a la inseguridad se puede observar un fenómeno llamado "colonia cerrada" que consiste en que los vecinos se organizan para cerrar las calles con rejas o paredes y dejan una garita de entrada y salida con guardia privada.

En el último tercio del siglo se produjo un auge en la construcción de edificios de varios niveles por toda la ciudad. El siguiente es un listado no exhaustivo de las estructuras que se erigieron:

La ciudad de Guatemala cuenta con numerosos sitios de interés cultural, artístico y arquitectónico. He aquí un listado de algunos de los lugares más relevantes:

La zona 10 —también conocida como la «Zona Viva»— ha sido un lugar dedicado a la vida nocturna desde la década de 1980. Originalmente para las élite de la ciudad que vivían en los alrededores, lugares como «Dash» y «Kahlúa» eran los centros de diversión preferidos. Con la migración de las clases acomodadas hacia el área oriental de la ciudad, conocida como «Carretera a El Salvador», y la aplicación de la «Ley Seca» -que prohibió el consumo de bebidas alcohólicas después de las dos de la mañana- durante el gobierno de Jorge Serrano Elías en 1992, el nivel de los centros de entretenimiento disminuyó un tanto, con la población que atendía proveniente de las capas medias y media-altas de la sociedad de la ciudad. En el siglo la «Zona Viva» se ha convertido en un centro de recreación familiar con la apertura del centro comercial «Oakland Mall» y «Fontabella» y con la proliferación de restaurantes de alta cocina.

A principios del siglo «Ciudad Cayalá» fue construida en los terrenos desocupados que estaban en las orillas de la «Calzada de la Paz», importante vía que fue construida en la década de 1990 y que une a la zonas 15 y 16 con las zonas 1, 5 y 6 de la ciudad. «Ciudad Cayalá» es un complejo que tiene todo tipo de actividades, dedicadas en su mayoría a la población de clase alta y media que vive en los alrededores; las actividades que incluye este complejo van desde los tradicionales bares, restaurantes y discotecas hasta golf y surf en olas artificiales.

En el siglo , la vida nocturna del Centro Histórico se reinició junto con la remodelación del «Paseo de la Sexta» a mediados de la década de 2000. Varios bares y centros de baile abrieron sus puertas, así como el «Teatro de los huitecos» sobre la séptima avenida, frente al Palacio Nacional de la Cultura.



La ciudad de Guatemala posee varios campos deportivos y es el hogar de muchos clubes deportivos. El fútbol es el deporte más popular: Comunicaciones y Municipal son los clubes más importantes, quienes disputan el clásico del fútbol guatemalteco. También ha destacado en la ciudad la Universidad SC y anteriormente el Aurora y la Tipografía Nacional.

La ciudad ha recibido a varias funciones de promoción y algunos eventos deportivos internacionales: en 1950 fue sede de la VI Juegos Centroamericanos y del Caribe, y en 2000 el Campeonato Mundial de Futsal de la FIFA. El 4 de julio de 2007, el Comité Olímpico Internacional se reunió en la ciudad de Guatemala y votó a Sochi para convertirse en la sede de los Juegos Olímpicos de Invierno de 2014 y Paralímpicos.

Es el estadio más grande de Guatemala y el séptimo a nivel centroamericano. Fue construido en 1948 por el Gobierno del doctor Juan José Arévalo, como parte de la Ciudad Olímpica que se construyó en «La Barranquilla» para acoger los Juegos Centroamericanos y del Caribe en 1950. Originalmente llamado «Estadio Olímpico de la Revolución», se le cambió nombre en honor del corredor de larga distancia Doroteo Guamuch Flores, quien fue el ganador del Maratón de Boston en 1952.. Hasta el año 2000 su aforo oficial era de cincuenta mil espectadores pero al colocarse butacas en todos sus sectores la capacidad se redujo a veintiséis mil. Se utiliza principalmente para partidos de fútbol; el estadio ha acogido a la mayoría de los partidos de local de la Selección nacional de fútbol a lo largo de su historia y es local del Club Municipal uno de los equipos con mayor tradición en el país.

El estadio Cementos Progreso es un escenario multiusos, localizado en la 15 avenida 28-00, Zona 6, La Pedrera. Fue inaugurado el 11 de noviembre de 1979 en un partido de fútbol entre el CSD Municipal y la Selección de fútbol de Costa Rica (1-2). Tiene capacidad para 14,022 espectadores sentados y 32,002 utilizando gramilla e instalaciones para servicios deportivos y para el público; su cancha de fútbol cumple con las medidas reglamentarias de la FIFA para realizar juegos internacionales. La pista de atletismo sintética que posee fue la primera en Centroamérica, y cumple con las medidas reglamentarias de la Federación Internacional de Atletismo. Es la sede del club de fútbol CSD Comunicaciones y el tercer estadio más grande de Guatemala.

A principios de la década de los 60, se tuvo la idea de construir un estadio que fuera la sede del equipo de fúbol Aurora F.C., propiedad del ejército de Guatemala. La junta directiva de esa época, presidida por Adrián Rodríguez inició las gestiones solicitando su construcción al ministro de la Defensa Nacional, coronel Rafael Arreaga Bosque, y al Jefe de Estado, coronel Enrique Peralta Azurdia. Los trabajos se iniciaron sobre un estadio ya existente en la zona 5 de la ciudad, con la remodelación del césped, y fue inaugurado el 3 de octubre de 1964, teniendo como único graderío uno construido de madera. Después se construyeron las tribunas y posteriormente, siendo su última construcción la «General Sur», inaugurada el 2 de abril de 1970.

El Estadio Revolución se encuentra ubicado en el interior de la ciudad universitaria, este es sede del equipo Universidad SC.

El Estadio Manuel Felipe Carrera o comúnmente llamado Estadio del Treból, actual sede oficial del equipo Municipal, anteriormente era utilizado para los entrenamiento de dicho equipo, derivado de las remodelaciones que sufrió el Estadio Nacional el equipo se vio obligado a cambiar de sede para sus encuentros de local por lo que decidieron utilizarlo oficialmente para sus encuentros de local y que paulatinamente ha sufrido remodelaciones, tiene capacidad maxima de 10.000 aficionados.

Antes de que se construyera la Ciudad de los Deportes en 1948, el estadio de mayor capacidad en la ciudad era el estadio Autonomía, que se encontraba a la par de la Penitenciaría Central y que fue demolido en 1970 junto con la Penitenciaría para que se construyeran los edificios del Ministerio de Finanzas Públicas y la Corte Suprema de Justicia en el Centro Cívico de la ciudad.

Situado en el Hipódromo del Norte, al final de avenida «Simeón Cañas» en la zona 2 de la ciudad, el diamante data de principios del siglo . Originalmente el adyacente Templo de Minerva era su único graderío; pero esto cambió en 1950, cuando se construyeron las instalaciones actuales, en preparación a los Juegos Centroamericanos y del Caribe que se realizaron entonces en Guatemala. El estadio se llamó originalmente «Diamante Minerva» y mantuvo ese nombre hasta que fue rebautizado en honor al jugador Enrique Torrebiarte. En 1952, fue expandido cuando el gobierno del coronel Jacobo Árbenz demolió el templo.

El Domo Polideportivo de la Confederación Deportiva Autónoma de Guatemala (CDAG), conocido popularmente como «Domo de la Zona 13» o simplemente como «Domo» (debido al tipo de su estructura de la cubierta), es una arena multiusos ubicada en la zona 13. Construido sobre la antigua «Plaza de Toros» de la zona 13, fue construido especialmente para alojar el Campeonato Mundial de fútbol sala de la FIFA 2000 y tiene una capacidad de siete mil quinientos espectadores. El lugar es propiedad y está operado por la CDAG, y también se utiliza para las presentaciones musicales, así como las actividades deportivas, culturales y políticas para los cuales la CDAG arrenda el sitio. De acuerdo con la CDAG el Domo es un lugar hermoso, pero el alto costo de su funcionamiento ha afectado su papel en el deporte, porque la mayoría de las federaciones y asociaciones deportivas del país no pueden permitirse el coste de su utilización. En 2003 el 60 por ciento de las actividades llevadas a cabo en el Domo no estaban relacionados con el deporte.

La ciudad pertenece a la , además está hermanada con 20 ciudades, las cuales son:




</doc>
<doc id="17617" url="https://es.wikipedia.org/wiki?curid=17617" title="Política de Guatemala">
Política de Guatemala

La República de Guatemala es un Estado soberano e independiente de Centro América, y forma parte de la Organización de las Naciones Unidas y de la Organización de los Estados Americanos. Guatemala política y jurídicamente se rige por la Constitución Política de la República de Guatemala, la cual es la ley suprema del Estado. El sistema de gobierno de Guatemala es republicano, democrático y representativo, según lo establecido en el artículo 140 de la Constitución.

La soberanía de Guatemala radica en el pueblo quien la delega, para su ejercicio, en los Organismo del Estado, según lo establecido en el artículo 141 de la Constitución, los cuales son:

En este mismo artículo se estipula que la subordinación entre los mismos, es prohibida.

Las elecciones presidenciales y legislativas de 1999 fueron consideradas por observadores internacionales como libres y justas. La participación de las mujeres y los votantes indígenas fue más alta que en el pasado reciente, aunque quedó preocupación con respecto a la accesibilidad de los lugares de votación en las áreas rurales.

La victoria arrolladora de Alfonso Portillo combinada con una mayoría del FRG en el Congreso de la República sugirió la posibilidad de una acción legislativa rápida. Sin embargo, bajo la Constitución Guatemalteca de 1985, la aprobación de muchos tipos de legislación requiere el voto de dos tercios del número total de diputados en el hemiciclo. Por eso la aprobación de esta legislación no es posible únicamente con los votos del FRG.

El balance político fue alterado en 2000 cuando emergieron alegaciones de que el FRG había alterado la legislación ilegalmente. Siguiendo una investigación, la Corte Suprema de Justicia despojó de su inmunidad legislativa a los involucrados, incluyendo al Presidente del Congreso de la República y jefe del FRG José Efraín Ríos Montt, para que enfrentarán cargos en el caso. Aproximadamente al mismo tiempo, la oposición del PAN sufrió una ruptura interna y se dividió en varias facciones; lo mismo ocurrió con la ANN. Como resultado, reformas esenciales para la implementación de la paz esperan acción legislativa.

Casos nuevos de abuso a los derechos humanos continuaron declinando, aunque el acoso violento a los trabajadores de los derechos humanos presentaba un serio reto a la autoridad gubernamental. El crimen común, agravado por un legado de violencia, presenta otro serio desafío. La impunidad sigue siendo un problema importante, principalmente porque las instituciones democráticas, incluyendo aquellas responsables de la administración de justicia, han desarrollado únicamente una capacidad limitada para lidiar con este legado.

Las últimas elecciones celebradas el 6 de septiembre de 2015, dieron la victoria al licenciado Jimmy Morales, bajo la bandera del FCN.

El Congreso está dominado principalmente por tres fuerzas políticas (PP, UNE, LIDER) de derecha, y la participación de los otros partidos puede considerarse marginal en cantidad de votos, incluidos los dos únicos partidos de izquierda. Tanto el Congreso como el gobierno central han sufrido un duro desgaste ante la ciudadanía que los percibe incapaces de resolver los problemas de inseguridad ciudadana, desempleo, pobreza, analfabetismo y desnutrición.

La actual fue creada 31 de mayo de 1985 por la Asamblea Nacional Constituyente de ese año, convocada por el entonces Presidente "de facto" de la República de Guatemala, general Óscar Humberto Mejía Víctores, tras las elecciones a la Asamblea Nacional Constituyente celebradas el 1 de julio de 1984. Dicha Carta Magna se hizo efectiva el 14 de enero de 1986.

Fue suspendida el 25 de mayo de 1993 por el entonces Presidente de la República de Guatemala Jorge Antonio Serrano Elías; reinstaurada el 5 de junio de 1993 acto seguido del derrocamiento del presidente; enmendada en noviembre de 1993. Las reformas constitucionales de 1993 incluyeron un incremento en el número de Magistrados de la Corte Suprema de Justicia de 9 a 13. Los períodos de cargo para Presidente, Vicepresidente, y Diputados del Congreso de la República de Guatemala fueron reducidos de 5 años a 4; para Magistrados de la Corte Suprema de Justicia de 6 años a 5 años, y se incrementaron los períodos de los Alcaldes y Concejos Ciudadanos de 2 1/2 a 4 años.

El Presidente y Vicepresidente son electos directamente por medio de sufragio universal y limitados a un período. Un Vicepresidente puede ser candidato para presidente después de 4 años fuera del cargo. Los Magistrados de la Corte Suprema de Justicia son electos por el Congreso de la República de Guatemala de una lista enviada por los Decanos de las Facultades de Derecho, un Rector de una Universidad, y Magistrados de la Corte de Apelaciones. La Corte Suprema de Justicia y las cortes locales manejan los casos civiles y criminales. También hay una Corte de Constitucionalidad.

Guatemala se encuentra dividida administrativamente en 22 Departamentos administradas por gobernadores designados por el Presidente. La Ciudad de Guatemala y otras son gobernadas por Alcaldes o Concejos electos popularmente.

Este organismo o poder es ejercido por el Presidente de la República de Guatemala, el Vicepresidente de la República de Guatemala y el Consejo de Ministros y por la demás entidades públicas correspondientes a este organismo. Su sede se encuentra ubicada en el Palacio Nacional de la Cultura en la zona uno de la Ciudad de Guatemala. El Presidente y el Vicepresidente de la república son elegidos por un período improrrogable de cuatro años por medio del sufragio universal y secreto. El Presidente de la República es el Comandante en Jefe de las Fuerzas Armadas de Guatemala y las Fuerzas Públicas. El actual Presidente de la República de Guatemala es el Lic. Jimmy Morales y actualmente el vicepresidente es Jafeth Cabrera Franco.

 Este organismo o poder está ejercido por el Congreso de la República de Guatemala, el cual consta de un hemiciclo formado por 158 diputados de los diferentes distritos electorales para un período de gestión de cuatro años pudiendo ser reelectos mediante el sufragio universal y secreto. Su función primordial es representar al pueblo, pero también se encarga de decretar, reformar y derogar las leyes según sea para el beneficio del pueblo guatemalteco. Sus períodos o sesiones ordinarias comenzarán el 14 de enero al 15 de mayo y del 1 de agosto al 30 de noviembre de cada año, sin necesidad de convocatoria, así también podrá hacerlo en reuniones extraordinarias cuando sea de principal importancia. El actual Presidente del Congreso de la República de Guatemala es el Ingeniero Oscar Stuardo Chinchilla. Su sede se encuentra en el Palacio del Congreso de la República de Guatemala, en la 9 Avenida entre la 9 y 10 Calle de la Zona 1 de la Ciudad de Guatemala.

 Este organismo es ejercido por la Corte Suprema de Justicia de la República de Guatemala la cual está conformada por 13 magistrados electos por el Congreso de la República para un período de gestión de cinco años pudiendo ser reelectos. La función de dicho organismo está establecida en la ley, la establece que la Corte Suprema de Justicia podrá administrar la justicia conforme lo dicte la Constitución y las demás leyes. El actual Presidente del Organismo Judicial y la Corte Suprema de Justicia es el Lic. José Arturo Sierra González, Magistrado Vocal XI. Su sede se encuentra en el Palacio de Justicia en la Zona 4 de la Ciudad de Guatemala. El máximo tribunal en materia constitucional es la Corte de Constitucionalidad formada por 5 magistrados, los cuales velan porque se cumpla la Constitución Política de la República de Guatemala. Actualmente el Organismo Judicial encabeza el Sistema de Justicia en Guatemala.

El 6 de septiembre de 2015 hubo elecciones generales en Guatemala para elegir al nuevo Presidente y Vicepresidente de la República, así como a 158 diputados del Congreso de la República de Guatemala. Al no obtener ninguno de los candidatos más del 51% de los votos se realizó una segunda vuelta el 25 de octubre del mismo año.

Los candidatos a la Presidencia de la República de Guatemala, obtuvieron los siguientes resultados:

Resultados de las elecciones presidenciales del 06 de septiembre y 26 de octubre de 2015
Los resultados de los diputados electos para el ocupar los escaños en el Congreso de la República de Guatemala son los siguientes:

Resultados de las elecciones legislativa del 11 de septiembre de 2011

La Bandera de Guatemala está formada por tres bandas verticales de igual ancho, azul claro, blanco, y azul claro, con el escudo de armas centrado en la banda blanca; el escudo de armas incluye un Quetzal verde y rojo (el ave nacional) y un pergamino con la inscripción "LIBERTAD 15 DE SEPTIEMBRE DE 1821" (la fecha original de Independencia de España), todo superpuesto a un par de rifles cruzados y un par de espadas cruzadas enmarcados por unos laureles.

Este emblema fue creado por Decreto No. 33 del 18 de noviembre de 1871, emitido por el General Miguel García Granados, según este decreto, "Las armas de la república serán: un escudo con dos rifles y dos espadas de oro enlazadas con ramas de laurel en campo celeste claro. El centro estará cubierto con un pergamino, que contendrá la siguiente leyenda en letras de oro: Libertad 15 de septiembre de 1821, figurará en la parte superior un Quetzal, como símbolo de la independencia y autonomía de la Nación."

Los rifles que sirvieron de modelo son marca Remington de la época (1871). Cuando el escudo figura en la Bandera de Guatemala, esta se llama Pabellón Nacional. El escudo de armas de la República cuando está diseñado independientemente de la bandera deberá colocarse en campo celeste claro porque es el color que representa la idealidad.

El Quetzal es considerado un símbolo patrio y el ave nacional del país. El quetzal tiene su plumaje del cuerpo de color verde iridiscente, con reflejos que varían de oro hasta azul-violeta, con el pecho y vientre de color rojo carmesí intenso. Las plumas cobertoras superiores de la cola son verdes y muy largas, escondiendo la cola, y en los machos en la temporada de anidar son más largas que el resto del cuerpo. Las cobertoras superiores del ala también son largas y parecen flecos. En las civilizaciones antiguas Mesoamericanas el quetzal era considerado como un ser divino y sus plumas eran llevadas en los penachos de algunos gobernantes. La moneda del país se llama quetzal en honor al ave.

En 1933, Leticia M. de Southerland, presidenta de la exposición internacional de flores celebrada en Miami Beach, Florida, envió una sugerencia al actual gobierno de Guatemala de que el ejemplar expuesto de "Lycaste skinneri alba" fuese designado como flor nacional. Esta sugerencia fue consultada por el entonces presidente de la República, el General Jorge Ubico con varios especialistas, entre ellos Ulises Rojas y Mariano Pacheco H. y entidades como la Biblioteca Nacional y la Sociedad de Geografía e Historia. Los expertos tomaron en cuenta la hermosura y rareza de esta flor estuvieron de acuerdo con la sugerencia, por lo que el 11 de febrero de 1934 la presidencia de la República emitió un decreto dando a la Monja Blanca la denominación de Flor Nacional.

El 9 de agosto de 1946, durante el gobierno de Juan José Arévalo, con el fin de proteger a esta especie de la extinción en Guatemala, se emitió un Acuerdo Gubernativo en el que se prohíbe la recolección y exportación de esta planta. El mismo acuerdo fue modificado el 4 de junio de 1947 para ampliar la prohibición a bulbos y flores, así como para incluir al resto de las especies de esta familia botánica. En 1997 cuando se comenzaron a acuñar monedas de 50 centavos, apareció la Monja Blanca como una de las caras de la nueva moneda.

La Ceiba Pentandra es el Árbol Nacional de Guatemala y alcanza 60 a 70 metros de altura, con un tronco grueso que puede llegar a medir más de 3 m de diámetro con contrafuertes. El tronco y muchas de sus ramas mayores están densamente pobladas con espinas largas y robustas. Las hojas están divididas en 5 a 9 hojitas más pequeñas, cada hoja sobrepasa los 20;cm. Los árboles adultos producen varios cientos de cápsulas de semillas de unos 15cm. Las vainas o cápsulas contienen semillas que se encuentran rodeadas por una fibra amarillenta y mullida, que es una mezcla de lignina y de celulosa.

El treinta y uno de agosto del año 1999, fue aprobado en Guatemala el decreto 31-99, el cual entró en vigencia al día siguiente como está estipulado en el mismo. Este establece a la marimba como símbolo patrio.

Dicho decreto se considera a la marimba cromática como la más genuina representación de la nacionalidad de Guatemala. También obliga al Ministerio de Educación, de Guatemala, a que vele por la instrucción de instrumento en los centros escolares públicos y privados entre otras cosas.























</doc>
<doc id="17618" url="https://es.wikipedia.org/wiki?curid=17618" title="Geografía de Guatemala">
Geografía de Guatemala

Guatemala se encuentra en la región Centroamérica y limita al norte con México, al este con Belice y al sur con Honduras y El Salvador, bordeando el Golfo de Honduras. El relieve se caracteriza por ser montañoso y con mesetas de caliza. Su territorio, de 108.889 km²,

El país es montañoso a excepción del área de la costa sur y las tierras del norte en el departamento de Petén. Dos cadenas montañosas, desde oeste y este, dividen a Guatemala en tres regiones: las tierras altas, donde las montañas de mayor altura se encuentran; la costa pacífica, al sur de las montañas; y la región de Petén, al norte.

El extremo sur de las tierras altas del oeste está marcado por la Sierra Madre, que se extiende al sudeste desde la frontera mexicana y continúa hasta El Salvador. La cadena montañosa da lugar a volcanes tales como el Tajumulco (4.220 m) el punto de altura máxima en el país y Centroamérica, y que se encuentra en el departamento de San Marcos. Los 37 volcanes de Guatemala (4 activos: Pacaya, Santiaguito, Fuego y Tacaná) se encuentran en esta región, por lo que los terremotos suelen ser frecuentes.

La cadena norte de las montañas comienza cerca de la frontera con México con los Cuchumatanes, luego se extiende hacia el este a través de las sierras de Chuacús y Chamá y hacia el sur a las sierras de Santa Cruz y Minas cerca del Mar Caribe. Las montañas septentrionales y meridionales son separadas por el Valle de Motagua, por donde el Río Motagua y sus afluentes fluyen de las regiones altas hacia el Caribe y son navegables en su curso inferior, donde se sitúa la frontera con Honduras.

Las áreas varían en su clima, elevación y paisaje por lo cual hay contrastes dramáticos entre las zonas bajas con un clima tropical, cálido y húmedo y las regiones altas con picos y valles.

El clima es cálido y húmedo en la costa Pacífica y las zonas bajas de Petén (aunque en este último puede ser cálido y seco), mientras que en las tierras altas el clima es de frío de montaña en el área de Cuchumatanes y es árido en las zonas más orientales. Coloquialmente se le conoce como "el país de la Eterna Primavera".

Los ríos suelen ser cortos y de poca profundidad en la vertiente del Pacífico. En la vertiente del Atlántico, los ríos suelen ser más largos y profundos, por ejemplo el Río Sarstún que conforma la frontera con Belice y Río Usumacinta, que forma la frontera entre Chiapas (México) y Petén.

El Río Hondo, que conforma la frontera entre México y Belice, proviene de las sierras de Guatemala y desemboca en la Bahía de Chetumal. El Río Dulce es otro de gran importancia, es un área protegida en Guatemala y se encuentra entre el Lago de Izabal y la Bahía de Amatique en el departamento de Izabal.

El Río Lempa nace en las sierras del Departamento de Chiquimula en Guatemala y es el más largo de América Central.

Las ciudades más importantes se encuentran en las tierras altas y la costa del Pacífico. Entre las ciudades más importantes se destacan la Ciudad de Guatemala (a 1.609 m), Quetzaltenango (a 2.357 m), Escuintla (a 300 m), Mazatenango (a 220 m) y Coatepeque (a 515 m). Sin embargo la tercera ciudad más importante del país Puerto Barrios se encuentra en el Mar Caribe a 0.001 msnm




La localización de Guatemala entre el Mar Caribe y el Océano Pacífico la sitúa en el rango de huracanes, incluyendo los Huracanes Mitch en 1998 y Stan octubre de 2005, que mataron a más de 1.500 personas. Ambos causaron gran daño, principalmente en forma de inundaciones. El último terremoto mayor fue el 7 de noviembre de 2013 terremoto del 4 de febrero de 1976, que resultó en la muerte de más de 23.000 personas.




</doc>
<doc id="17619" url="https://es.wikipedia.org/wiki?curid=17619" title="Economía de Guatemala">
Economía de Guatemala

La economía de Guatemala es propia de un país en desarrollo, constituyendo la mayor economía de América Central, y la undécima de América Latina. Su PIB, representa un tercio del PIB regional. El país mantiene unos fundamentos macroeconómicos sólidos en los últimos años, con un nivel de reservas elevado, un nivel controlado del déficit público (2,8% en 2011) y del déficit exterior y una deuda pública baja, del 24,3% del PIB en 2011. El nivel económico de la población es medio bajo con un 50% de sus habitantes que se encuentran por debajo del umbral de la pobreza y un 15% en pobreza extrema.

El sector más grande en la economía guatemalteca era tradicionalmente la agricultura, siendo Guatemala el mayor exportador mundial de cardamomo, el quinto exportador de azúcar y el séptimo productor de café. El sector del turismo es el segundo generador de divisas para el país tras las remesas de los emigrantes, la industria es una importante rama de la economía guatemalteca y el sector de servicios está aumentando en importancia. En 2016, Guatemala es el cuarto país con mayor desigualdad de América Latina (después de Honduras, Colombia y Brazil).

Se calcula que el PIB de Guatemala en 2000 era de 23.000 millones de dólares estadounidenses, con un decrecimiento real de aproximadamente el 3,3% sobre el año anterior. Después de la firma de los acuerdos de paz en diciembre de 1996, Guatemala estaba bien posicionada para un rápido crecimiento en los años siguientes.
La economía de Guatemala está dominada por el sector privado, que genera alrededor del 85% del Producto interior bruto. La agricultura contribuye con el 23% del PIB y constituye el 75% de las exportaciones. La mayoría de la manufactura es de ensamblaje ligero y procesamiento de alimentos, dirigido a los mercados domésticos de Estados Unidos y Centroamérica. Durante años pasados, el turismo y la exportación de textiles y productos agrícolas no tradicionales como vegetales de invierno, frutas y flores se han incrementado, mientras que las exportaciones más tradicionales como el azúcar, bananas, y café, es primer exportador mundial de alverja china, quinto en azúcar y séptimo de café gourmet siguen representando una gran porción del mercado de exportación.

Estados Unidos es el mayor socio comercial del país, proveyendo el 55% de las importaciones de Guatemala y recibiendo el 40% de sus exportaciones. El sector público es pequeño y está reduciéndose, con sus actividades de negocios limitadas a servicios públicos -algunos de los cuales se han privatizado- puertos, aeropuertos, y varias instituciones financieras orientadas al desarrollo. Guatemala fue cualificada para recibir ventajas a la exportación bajo el Acta de Comercio de la Cuenca del Caribe ("Caribbean Basin Trade and Partnership Act", CBTPA) de los Estados Unidos en octubre del 2000, y goza de acceso a los beneficios del Sistema de Preferencias Generalizado (SPG) de la Unión Europea. Sin embargo, debido a graves carencias en la protección de los derechos de los trabajadores, los privilegios de Guatemala en el CBTPA y el GSP están bajo revisión.

Entre las prioridades económicas actuales están:


Los aranceles de importación han bajado conjuntamente con los de sus vecinos centroamericanos, de manera que la mayoría está entre el 0% y el 15%, y hay más reducciones planificadas. Respondiendo al cambiado ambiente político y de políticas económicas, la comunidad internacional ha movilizado recursos sustanciales para apoyar los objetivos de desarrollo económico y social. Los Estados Unidos, conjuntamente con otros países donantes -especialmente Francia, Italia, España, Alemania, Japón, y las instituciones financieras internacionales- han incrementado la financiación de proyectos de desarrollo. La respuesta de los donantes a la necesidad de soporte financiero internacional para la implementación de los Acuerdos de Paz es, sin embargo, contingente a las reformas al Gobierno Guatemalteco y el financiamiento de su parte.

Entre los problemas que obstaculizan el crecimiento económico están la alta tasa de criminalidad, analfabetismo y los bajos niveles de educación, beches y un mercado de capitales inadecuado y subdesarrollado. También se encuentran la falta de infraestructura, particularmente en los sectores de transporte, y electricidad, aunque las compañías telefónica y eléctrica del estado fueron privatizadas en 1998. Dando como resultado que la red de telefonía celular se abriera a toda la población de Guatemala en 2009 había mas celulares en el país que personas, entre las fortalezas esta la moderna red del sector de telecomunicaciones, la infraestructura vial es la mejor comparada con la centro América. La distribución de los ingresos y la riqueza permanece altamente desigual. El 10% más rico de la población recibe casi la mitad del total de ingresos; el 20% más alto recibe dos tercios del mismo. Como resultado, aproximadamente el 50% de la población vive en pobreza, y el 18% vive en extrema pobreza. Los indicadores sociales de Guatemala, como mortalidad infantil y analfabetismo están entre los peores en el hemisterio de economía.

Los principales productos de exportación son: azúcar, banano, café, cardamomo y petróleo.

El valor total de las exportaciones era de US$4 mil 839.8 millones a principio de diciembre de 2008 (unos US$808.3 millones más que el año pasado, de acuerdo a un reporte al 11 de diciembre del Banguat).
Los cinco principales productos de exportación representan el 26.5% del total de exportaciones del país, que ascendió a US$ 1,516.6 millones. El crecimiento del valor total de las exportaciones guatemaltecas aumentó en un 20.1% debido a los altos ingresos por el aumento del precio del café, petróleo y cardamomo en los mercados mundiales. Sin embargo, el precio y volumen de las ventas de azúcar disminuyó considerablemente.

Los principales productos de importación son: materias primas, materiales de construcción, combustibles, bienes de consumo, bienes de capital.

El valor CIF de las importaciones ascendió al monto de US$ 7,482.1 millones, mayor en US$ 1,082.6 millones equivalente al 16.9% respecto al registrado durante el primer semestre de 2007. El ritmo de crecimiento que tuvieron las importaciones en esta primera mitad de 2008 fue mayor al 12.7% (durante igual período de 2007). Este aumento se atribuye al alza en la factura petrolera.
A nivel de los bienes de consumo, cuyo monto (US$ 1,795.5 millones) absorbió el 24.0% de las importaciones totales, aumentó 5.6% en comparación con el 15.8% del año anterior. En gran parte, esta desaceleración se debió a la disminución en la importación de bienes de consumo duradero (-6.7%). Con respecto a las importaciones de combustibles y lubricantes, su valor CIF fue de US$ 1,592.8 millones, mayor en US$ 510.5 millones (47.2%) al monto en que se situaron a igual fecha del año anterior.



"fuente": julio tum
Para observar la relación de las importaciones y exportaciones y ver el impacto de la teoría de la dependencia de Prebish hemos acudido a la "Oxford Latin America Economic History Database" (OXLAD) y hemos obtenido los datos los términos de intercambio de Guatemala con Estados Unidos y con el resto del mundo. Estas variables nos vienen representar la relación de precios medios que había entre las importaciones y exportaciones guatemaltecas. Por encima de 100, eso vendría a decir que lo que Guatemala exportaba tenía un precio medio superior al precio medio de lo que importaba, luego era más beneficioso para este.

En marzo de 1897, coincidiendo con el inicio de la Exposición Centroamericana la revista cultura "La Ilustración Guatemalteca" publicó un análisis detallado de la situación económica de Guatemala. Para entonces, los bancos del país presentían una mala situación y habían querido mejorar sus créditos exigiendo garantías fiduciarias, retirando créditos y pasando circulares con lo que consiguieron general el pánico entre la población guatemalteca. Por otra parte, algunos bancos habían incrementado considerablemente el tipo de interés aprovechando la concesión que tenían del gobierno para emitir billetes.

En ese momento, la cesación del alza de los precios de los valores públicos se había convertido en un descenso rápido y desconsolador; por ejemplo, las acciones del Banco Internacional bajaron de $5500 a $5000 entre junio de 1896 y febrero de 1897, mientras que las bonos de la Exposición y del Ferrocarril del Norte bajaron de $90 y $44 a $80 y $32, respectivamente en el mismo período. Sólo se mantuvieron estables las acciones del Banco de Occidente y los bonos de la deuda flotante ya que las acciones del banco no podían estar más bajas produciendo 11% por acción; de los bonos de la deuda flotante, emitidos originalmente por tres millones de pesos, restaban ya solamente $380,000 que se encontraban en un reducido círculo de personas acuadaladas, quienes no las ofrecían porque no tenían ninguna necesidad de hacerlo por el momento. Finalmente, los bonos del Ferrocarril del Norte fueron los que más cayeron, pues estaban en manos de empleados y personas poco acaudaladas, que se habían visto en la necesidad de venderlos para subsistir.

De acuerdo al análisis de "La Ilustración Guatemalteca", en marzo de 1897 existía una paralización completa en los negocios por carencia casi absoluta de efectivo, situación muy grave que estaba empezando a afectar el comercio, la agricultura, la industria y demás fuentes de riqueza. Las causas de este serio problema eran el excesivo desarrollo que el gobierno de Reina Barrios había dado a necesidades ficticias -o sea, el embellecimiento de la Ciudad de Guatemala, proyecto de Acatán y el gasto millonario en la Exposición Centroamericana- sin haber tomado en cuenta el verdadero estado de las cuentas nacionales y para las que necesitó de muchos recursos particulares obtenidos por medio de bonos. Esta actitud se había trasladado a la población en general, ya que las familias habían entrado en una época de lujo y vanidad en el que se buscaban coches, caballerizas, lacayos con lujosa librea, visitas al teatro y otras cosas en las que se gastaba más de lo que las familias tenían de ingresos; esto resultaba en que se hubiera abusado del crédito y de la especulación. Se consideraba para entonces que la única solución era una austeridad completa con un plan de economías y la abstención absoluta de todo dispendio innecesario y se temía que se llegara a una bancarrota estatal.

Por otra parte se indicaba que el país solamente producía café y no tenía ningún otro fruto con qué hacer frente al sinnúmero de necesidades aumentadas por los bonos para el Ferrocarril del Norte, para Acatán y para la Exposición, entre otros; por otra parte, todo era importado y por consiguiente, el país era deudor no sólo por el importe de los bienes, sino también por el cambio de moneda, los fletes y las comisiones. Las exporaciones guatemaltecas no llegaban a veinte millones de pesos y como eran muchas la fincas en manos extranjeras, no regresaba al país el valor total de las exportaciones.

En resumen, no quedaba saldo alguno que pudiera equilibrar la balanza del comercio guatemalteco en 1897 y se recomendaban medidas de austeridad y que se hiciera un préstamo a largo plazo negociado en buenas condiciones, y que no fuera como los que hasta entonces se habían hecho por los gobierno guatemaltecos que no solamente tenían intereses excesivos, sino que no eran administrados de forma honrada.

El 10 de marzo, el periódico opositor "La República" publicó que no existía regocijo entre la población guatemalteca por la realización de la Exposición, a pesar de la majestuosidad de la misma; dicha apatía se debía a la preocupación por los acontecimientos económicos y políticos de los últimos meses. Se hizo ver que desde un principio la idea de hacer la exposición no fue bien recibida -a pesar de que la situación económica del país era muy buena en ese momento- y que en 1897 la crisis hacía por demás impopular a la celebración: la escasez de dinero, la reducción de negocios y la imposición de mayores sacrificios para sufragar la Exposición, hicieron que los ciudadanos la rechazaran por completo.

A finales de marzo de 1897 continuaron los fuertes editoriales contra el gobierno en "La República". En uno se indicaba que no se había concluido la línea del Ferrocarril del Norte y que para ello se necesitan casi doce millones de pesos guatemaltecos y que si se suspendían dichos trabajos, el costo del mantenimiento de lo ya construido costaría cerca de cuatro millones y medio de pesos guatemaltecos. Los editores de "La República" acusaron al gobierno de despilfarrar el erario pues trató de hacerlo todo a la vez: aparte del Ferrocarril del Norte -que por sí solo hubiera traído grandes beneficios económicos a Guatemala- se habían construido bulevares, parques, plazas, edificios suntuosos, aparte de gastar tres millones de pesos guatemaltecos en la Exposición. "La República" fue incluso un poco más allá y acusó al presidente de apropiarse de bienes del Estado. En otro fuerte artículo contra el gobierno, acusan de deficiente el manejo de agua -la cual se obtenía en parte del proyecto de Acatán- y que se estaba utilizando en las fuentes de la Exposición dejando sin abastecimientos a la población de la Ciudad de Guatemala. Por estas publicaciones, el periódico fue cerrado temporalmente por el gobierno de Reina Barrios, aunque fue reabierto pocos meses después.

A principios del siglo XX el gobierno guatemalteco del licenciado Manuel Estrada Cabrera suscribió un contrato con la United Fruit Company (compañía estadounidense) para cultivar y comprar banano, así como para mantener una línea de vapores con Nueva Orleans. Este hecho como muestran los datos (entre 1900 y 1914 los TOT estuvieron variando entre un 137% y un 121%) mantuvo más o menos estables los precios de las exportaciones, y por encima de los precios de las importaciones con EE. UU..

Por otro lado, un aspecto que afectaba e, incluso hoy día, continúa afectando la producción del café, son las fuertes fluctuaciones del sistema de precios en el comercio internacional. Para tratar de corregir estas alteraciones, desde finales del siglo pasado Brasil introdujo medidas restrictivas en la siembra de café, con el objeto de reducir la oferta exportable y mantener precios altos. Esta política fue repetida por Brasil en 1907, 1909 y 1913, y que favoreció a Guatemala, ya que en las tres primeras décadas del siglo, se disfrutaron ingresos provenientes de precios relativamente altos del café, hasta la crisis económica de 1929, cuando, como resultado de la caída de los precios, muchos finqueros quebraron y las propiedades pasaron a las manos de los extranjeros que les habían otorgado créditos.

En las décadas de 1920 y 1930, Guatemala suscribió convenios y tratados comerciales con varios países europeos, como Francia, Gran Bretaña y Noruega, así como con Canadá; todos ellos ampliaron las posibilidades de colocar exportaciones adicionales de café. Este acuerdo al igual que el que se suscribió a principios de siglo con la UFCO, implicó que las exportaciones guatemaltecas tuvieran salida no solo ha Estado Unidos, y que por lo tanto se mejorase la relación de intercambio existente con el resto del mundo.

La Gran depresión paró los mercados internacionales y esto afectó al intercambio de bienes con todo el mundo, incluyendo a EEUU, lo que hizo que se encarecieran las importaciones, y que los países que recibían los productos guatemaltecos dejaran de adquirirlos. Este descenso del nivel de intercambio se mantuvo hasta bien entrada la Segunda Guerra mundial.

A partir de 1944 se comenzó a promocionar las exportaciones, especialmente de productos no tradicionales. Para alcanzar dichos fines se procuró ofrecer servicios de ayuda al productor-exportador nacional y al importador extranjero. A esto hay que sumarle la participación de Guatemala en el MCCA, lo que benefició el libre comercio de productos originarios del país y de los otros socios centroamericanos, a raíz de los primeros tratados de integración, a finales de la década 1950, y de otros, especialmente del Tratado General, suscrito en el año 1960. Por otro lado la Segunda Guerra Mundial que asoló los países de los principales proveedores guatemaltecos, ayudó al comercio de este ya que estos países necesitaban abastecimiento sobre todo de materias primas, pero también algunos productos manufacturados que ya la industria guatemalteca producía, y además la segunda guerra mundial provocó una bajada de los productos que Guatemala importaba. Así que como observamos en los datos obtenidos de la OXLAD, entre 1945 y 1960 los términos de intercambio guatemaltecos llegan a alcanzar el 165,3% en los intercambios comerciales con el resto del mundo, especialmente con el continente europeo. Así mismo el pico de Estados Unidos fue menor, ya que la Segunda Guerra Mundial no le afectó tanto, y además Guatemala tenía una serie de acuerdos comerciales con este de comercio, que no se vieron afectados por el acontecimiento bélico.

A partir de 1960, los términos de intercambio con el resto del mundo empeoran para la economía guatemalteca, es decir, es más caro lo que Guatemala compra que lo que vende. La relación de los precios va empeorando bruscamente lo que queda de siglo y en el año 2000 desciende a niveles del 30%, es decir, el precio de las exportaciones, es el 30% de las importaciones. Por el lado norteamericano también se produce un descenso a partir de los años sesenta, pero no tan acusado como el que se produce con el resto del mundo. Este descenso se detiene a comienzos de la década de los 70, y más o menos, lo que queda de siglo se mantiene al alza, estando en el 2000 casi al 140%, es decir, el precio de las exportaciones guatemaltecas son un 40% más alto que el precio de las importaciones con EEUU.

Por último en el caso de Guatemala se cumple la teoría de Prebish en el largo plazo con todo el mundo, menos con EEUU. Como ya hemos dicho anteriormente el siglo XX termina con unos términos de intercambio favorables para la economía guatemalteca en el caso de su comercio con Estados Unidos. En el caso estadounidense la teoría de la dependencia no se cumple, ya que esta dice que las economías de los países periféricos (en este caso sería Guatemala) se ven perjudicadas respecto a las economías de los países centro (en este caso EEUU). . No ocurre lo mismo con el caso del resto del mundo, en el que al final del periodo el comercio guatemalteco con el resto se ve muy mermado. Aquí si que se cumple la teoría desarrollada por Prebish, ya que en este caso el país periférico sale perdiendo con respecto de los países centro (en este caso sería sobre toda Europa).

Una política muy importante en el marco económico para Latinoamérica, fue la implantación del modelo de industrialización por sustitución de importaciones (ISI), entre 1950 y 1970. Está política se basaba en la producción local de los productos que hasta ahora se importaban, es decir, de fabricar uno mismo las manufacturas que su economía adquiría del exterior. Este modelo de industrialización no obstante no redujo el volumen de importaciones, sino que, simplemente, cambió el tipo de importaciones. Antes importaban el bien completo, ahora importan lo necesario para producirlo. La ISI no solo implica cambios en materia de importaciones, sino que también significa un crecimiento en el sector industrial, un cambio en las exportaciones y un crecimiento económico. En este apartado por tanto queremos analizar estos cambios para la economía guatemalteca. Hemos vuelto a extraer datos de la "Oxford Latin America Economic History Database" (OXLAD) para observar la evolución de las exportaciones, las importaciones, el gasto público y el porcentaje de industrialización del país.

Vamos a comenzar observando el cambio que presentaron las exportaciones en Guatemala. En teoría el modelo ISI trataba de reducir el peso de las exportaciones, conseguir esto, suponía un éxito en este sentido, pero en el caso de Guatemala ocurrió todo lo contrario a lo previsto. 

Durante las tres décadas que duró el periodo de las políticas de industrialización por sustitución de importaciones (ISI) vemos como el peso de las importaciones de la economía guatemalteca, en líneas generales aumentó. Esto quiere decir que en Guatemala la importancia de las exportaciones no siguió el mismo patrón de decrecimiento que, por lo general, se repitió en las demás economías latinoamericanas. De hecho el peso de las exportaciones para la economía guatemalteca en 1950 era tan solo de un 11’78%, y en 1980 este peso pasó a ser del 19’29% es decir, casi se duplicó.Con los datos en la mano vemos como el peso de las importaciones no es muy regular, ya que se aprecian grandes altibajos. Hasta la primera década, llegando hacia 1963 vemos como la tendencia fue como las de las economías latinoamericanas, es decir, las exportaciones comenzaron a perder importancia respecto al PIB, pero es a partir de esta fecha en la que se observa una tendencia alcista de la repercusión de las exportaciones en la economía guatemalteca.

Por otro lado como he mencionado anteriormente, la ISI modificaba los patrones importadores.Para analizar esto hemos observado el toral de las imprtaciones guatemaltecas agrupadas en 3 grupos, bienes de consumo, bienes de capital y de productos intermedios.

La teoría del modelo buscaba reducir las importaciones de bienes de consumo. Estos bienes son productos que ya puede consumir directamente la sociedad como pueden ser el calzado, el vestido, alimentos. En este sentido vemos como si que se consiguió, aunque la mayor parte del periodo crecieron, en 1966 se alcanzó un máximo llegando al 29,3%, a partir sobre todo de 1973 estas se fueron reduciendo, pasando de un 26,3% en 1960, a un 17,1% en 1980.

Por otro lado la ISI pretendía reducir las importaciones de manera progresiva de bienes de capital y de bienes intermedios. Esto supondría un descenso en los niveles de importación de estos productos (ya que se fabricarían dentro del propio país). Podemos observar que también se redujeron considerablemente los bienes de capital. Estos son aquellos que no se destinan directamente al consumo, sino que sirven para continuar un proceso productivo. En este caso al principio del período de la ISI, 1950, las importaciones de bienes de capital significaban un 22,3% del total, mientras que en 1980 pasaron a ser el 17,4%. No obstante, estas importaciones no se mantuvieron en niveles decrecientes durante todo el período, sino que hubo altibajos, llegando en 1976 a su máximo del período llegando a ocupar el 27,3% de las exportaciones totales.

No obstante, no ocurrió lo mismo con las importaciones de bienes intermedios. Estos bienes son aquellos que ya han sufrido alguna transformación pero que necesitan algún proceso productivo más para convertirse en productos finales. Como podemos observar, este tipo de importaciones son las que más peso tienen dentro de las exportaciones totales ya que en general suponen en torno a un 50% o 60% de ellas. En este tipo de importaciones podemos decir que ocurrió todo lo contrario que con los otros dos tipos de importaciones, ya que las importaciones de bienes intermedios crecieron prácticamente en todo el período, pasando en 1950 de un 51,1% a un 65,5% en 1980.

Como conclusión podríamos decir que en materia de importaciones la ISI no tuvo un éxito rotundo, ya que no se alcanzaron todos los objetivos. La economía guatemalteca en este sentido se quedó a medias, ya que solo se consiguieron reducir las importaciones de consumo y de capital.

Viendo el escaso éxito que la ISI tuvo para la economía guatemalteca, sin necesidad de ver los datos para el déficit público, podemos intuir que va a seguir la tónica de la mayoría de los países latinoamericanos, y es que la ISI implicó un aumento desmesurado del gasto público para casi todas las economías. Y en el caso de Guatemala no fue diferente.

En 1950 la economía presentaba un déficit entorno al -0,5% pero que con los primeros tres o cuatro años de andadura con el modelo ISI se solventó teniendo un superávit del 0,5%. Este hecho, quiero decir, que la economía guatemalteca se mantuviera en superávit, solo duró un par de años. A partir de entonces, se empezaron a registrar brutales déficits públicos llegando en 1976 a un déficit del 3,78%. Esto se da porque los gastos ocasionados por el modelo de sustitución de importaciones no podrían cubrirse con los ingresos que el país generaba, ya que básicamente el 72% de estos ingresos venían de los impuestos de los ciudadanos.Como podemos observar a partir de 1953 se empieza a registrar una bajada, que en tan solo 3 años pasó de un 0,5% a un -2,34%.

A partir de que en 1956 se tocara fondo, se plantearon políticas para contener el gasto público, que en un principio comenzaron a dar sus frutos y en 1960 el déficit se situó en un 0,67%. Pero no consiguieron equilibrar la balanza gasto-ingreso, como se puede ver en el periodo en 1960 u 1971, en el que se producen unos altibajos podríamos decir que cíclicos, se alcanzaban niveles de -0,5% y dos años después se volvía a llegar a niveles de -1,8%. A partir de 1971 se comenzó a desequilibrar la balaza nuevamente, y aunque en 1975 se conseguía volver los niveles de 1971. pero todos estos esfuerzos fueron en vano y en 1976 se alcanzó la cifra récord del periodo en cuanto a déficit público, como hemos mencionado anteriormente se llegó a un -3,78%. Y aunque pocos años después este nivel se recuperó no tardó en volver a retroceder y se situó en 1980 en un déficit cercano al -3%.

Ante estos niveles de gasto público, y visto que los ingresos que el país generaba por si mismos no eran suficientes, se optó por un endeudamiento primero interno, y después externo para intentar equilibrar la balanza, pero estas medidas no fueron suficientes, y como veremos más adelante, esto no hizo más que empeorar la situación. Por último nos queda ver, si, aun así, el hecho de haber implantado el modelo de sustitución de importaciones, que sobre todo sirve para industrializar el país, sirvió de algo en este sentido, ya que como hemos visto, para lo demás no sirvió de mucho.

Como podemos observar la ISI supuso un crecimiento significativo del sector industrial, pero sin que este se desarrollara. La industrialización apenas ha transformado las estructuras dependientes de la economía o aumentado el nivel de vida de la mayor parte de la población del país. Guatemala siguió siendo un país agrícola, y las posibilidades de un futuro crecimiento industrial y de una diversificación son limitadas.

No obstante, la industria ha crecido bastante desde 1950 pasando de un 11% en ese año, y llegando a un 15% en 1980. Aunque no nos parezca un crecimiento muy espectacular hay que decir, que para como le ha ido a Guatemala con la ISI es bastante. Se establecieron muchas empresas nuevas, con grandes inversiones de capital y mecanización. El resultado fue una modesta diversificación de la economía y la creación de miles de nuevos empleos. Sin embargo, la industrialización no satisfizo las expectativas.

El sector más grande en la economía guatemalteca es la agricultura, siendo Guatemala el mayor exportador de cardamomo a nivel mundial, el quinto exportador de azúcar y el séptimo productor de café. El sector del turismo es el segundo generador de divisas para el país, mientras que la industria es una importante rama de la economía guatemalteca y el sector de servicios que año tras año cobra mayor importancia, por lo que convierte la típica economía guatemalteca basada en la agricultura en una economía basada en la prestación de servicios. 

Los sectores que más aportes generan al PIB en Guatemala son:
En su territorio se encuentran fascinantes enclaves arqueológicos mayas (Tikal en el Petén, Quiriguá en Izabal, Ixinché en Tecpán Chimaltenango, y en la Ciudad de Guatemala); además el lago de Atitlan y la ciudad colonial de Antigua Guatemala tienden a ser los más visitados por turistas extranjeros.



</doc>
<doc id="17620" url="https://es.wikipedia.org/wiki?curid=17620" title="Demografía de Guatemala">
Demografía de Guatemala

La población de Guatemala es de 16.470.000 habitantes, de los cuales el 40.8% está entre los 0 y 14 años, el 55.5% está entre los 15 y 64 años y el 3.6% de los 65 en adelante.

La mayoría de la población guatemalteca es rural, aunque la urbanización se acelera.

La religión predominante es el cristianismo al que muchos guatemaltecos indígenas han incorporado formas tradicionales de adoración. Un estudio que realizó la corporación latinobarometro, destaca que en el 2013 la religión católica de ser la religión mayoritaria paso a 47%, el Protestantismo paso a 40%, un 2% practican otras religiones en su mayoría la espiritualidad maya y un 11% están clasificadas como ateo, sin religión, agnóstico.

En Guatemala se hablan 24 idiomas. El idioma oficial es el español. Un gran porcentaje de la población habla una de las 22 lenguas mayas. Los Acuerdos de Paz firmados en diciembre de 1996 aseguran la traducción de algunos documentos oficiales y los materiales de votación a varias Lenguas indígenas.


En el país existe un total de 7.003.337 hombres y 7.358.328 mujeres de los cuáles se dividen por edades según la siguiente estadística:

Según la estadística nacional de población del año 2000, la tasa de crecimiento de población es de 2,63% por año. La siguiente estadística muestra las diferentes razones del crecimiento de la población nacional.
En Guatemala, existe una población superior del sexo femenino con una cantidad de 7,538,328 mujeres, mientras que del sexo masculino hay una cantidad de 7,003,337 hombres según la estadística realizada en el año 2000.


Históricamente, el territorio de la Guatemala fue habitado por pueblos indígenas en donde predominaban los maya, tz'utujil, quiché, etc. Desde la llegada de los europeos, primero con los españoles, los habitantes se han mezclado, formando una poblacion que se denomina ladino, que incluye a personas tanto mestizas como blancas e incluso indígenas que se identifican con una cultura de habla hispana y similar al resto de Latinoamérica. También a lo largo del tiempo han llegado inmigrantes que han decidido asentarse en el país lo que provoca la aparición de nuevos grupos étnicos y nuevas culturas en el país. De acuerdo al Instituto Nacional de Estadística de Guatemala (INE), estos son los porcentajes de etnias que existen en Guatemala: Mestizos (41%), Blancos (18%), indígenas (40%).

La población guatemalteca ha experimentado un fuerte crecimiento demográfíco durante el siglo XX.

Basándose en los censos históricos, esta es la evolución de la población guatemalteca:
Además se estima que entre 500,000 y 1 millón y medio de personas de ascendencia guatemalteca que viven en México, EE. UU. y Canadá.

Guatemala es una nación joven, con un 70% de personas menores de 30 años de edad (Datos del Censo del 2002). Sin embargo también se estima que en el futuro la población de la tercera edad que vaya creciendo, es decir que experimentará un paulatino envejecimiento. Guatemala a diferencia de El Salvador, este si se expandirá demográficamente, llegando a los 26 millones en 2050 (Obviamente con una población más envejecida), y para el 2080 la CEPAL estima que el país llegara a los 34 millones, aunque este a la vez será su tope, se mantendrá casi estable y durante la última década de este siglo comenzara a descender con un -1.1% anualmente (siendo un inicio mayor que los demás países centroamericanos aunque también uno de los más tardíos) y para el 2100 con un -2%. Los estudios también indican que debido a la fuerte tasa de fecundidad (3.2 hijos por mujer en 2007), la inmigración al exterior no afecta en el crecimiento poblacional como si lo hace en el caso de El Salvador y Nicaragua. 

Se puede ver en un video de Youtube .

Prostitución juvenil
Entre agosto a septiembre de 2009, descubren a 20 menores de edad ejerciéndola
En septiembre de 2009, un estudio de la Asociación para la Eliminación de la Prostitución, Pornografía y Tráfico Sexual de Niños, Niñas y Adolescentes de Guatemala, el 70% de las mujeres de los prostíbulos de la Ciudad de Guatemala se ubican entre los 13 y los 25 años de edad
El 13 de diciembre de 2009, descubren a 22 colombianas y a 1 cubana ejerciendo en un restaurante


</doc>
<doc id="17621" url="https://es.wikipedia.org/wiki?curid=17621" title="Molibdeno">
Molibdeno

El molibdeno es un elemento químico de número atómico 42 que se encuentra en el grupo 6 de la tabla periódica de los elementos y se simboliza como Mo.

El molibdeno es un metal esencial desde el punto de vista biológico y se utiliza sobre todo en aceros aleados.

Es un metal plateado, tiene el sexto punto de fusión más alto de cualquier elemento. El molibdeno no se produce como el metal libre en la naturaleza, sino en varios estados de oxidación en los minerales. Industrialmente, los compuestos de molibdeno se emplean en aplicaciones de alta presión y alta temperatura, como pigmentos y catalizadores.

La mayoría de los compuestos de molibdeno tienen baja solubilidad en agua, pero el ión de molibdato MoO es soluble y se forma cuando los minerales que contienen molibdeno están en contacto con el oxígeno y el agua. Algunas teorías recientes sugieren que la liberación de oxígeno era importante en la eliminación de molibdeno de un mineral en una forma soluble en los océanos primitivos, donde se utiliza como catalizador de los organismos unicelulares. Esta secuencia puede haber sido importante en la historia de la vida, porque las enzimas que contienen molibdeno se convirtieron en los catalizadores más importantes utilizados por algunas bacterias para descomponer en átomos las moléculas de nitrógeno. Esto, a su vez permitió al nitrógeno impulsar biológicamente la fertilización de los océanos, y por lo tanto el desarrollo de organismos más complejos.

Al menos 50 enzimas que contienen molibdeno son conocidas en bacterias y animales, aunque sólo las enzimas de bacterias y cyanobacterias están involucradas en la fijación de nitrógeno. Debido a las diversas funciones del resto de las enzimas, el molibdeno es un elemento necesario para la vida en organismos superiores, aunque no en todas las bacterias.

El molibdeno es un metal de transición. Este metal puro es de color blanco plateado y muy duro; además, tiene uno de los puntos de fusión más altos de entre todos los elementos. En pequeñas cantidades, se emplea en distintas aleaciones de acero para endurecerlo o hacerlo más resistente a la corrosión. Por otra parte, el molibdeno es el único metal de la segunda serie de transición al que se le ha reconocido su esencialidad desde el punto de vista biológico; se encuentra en algunas enzimas con distintas funciones, concretamente en oxotransferasas (función de transferencia de electrones), como la xantina oxidasa, y en nitrogenasas (función de fijación de nitrógeno molecular). Es uno de los pocos metales que resisten adecuadamente el ácido clorhídrico, siendo el Tantalio el más fuerte ante este medio corrosivo en específico. La adición de cantidades mínimas del metal afectan a la resistencia a las soluciones clorhídricas que normalmente afectan a los aceros (incluso a los inoxidables). A veces con un porcentaje mínimo de 2% de Mo en masa, los aceros adquieren la resistencia necesaria para operar en ambientes marinos. El aumento del molibdeno en los aceros inoxidables aumenta su tenacidad y sobre todo su resistencia al ataque de los compuestos de cloro. 

En su forma pura, como metal blanco plateado es el molibdeno con una dureza de Mohs de 5,5. Tiene un punto de fusión de 2.623 °C. De los elementos naturales, sólo el tantalio, el osmio, el renio, el wolframio y el carbono tienen puntos de fusión más alto. El molibdeno sólo se oxida rápidamente a temperaturas superiores a 600 °C (débil oxidación comienza a 300 °C). Su coeficiente de dilatación es uno de los más bajos entre los metales utilizados comercialmente. Su resistencia a tracción hace que los cables de molibdeno aumenten de 10 a 30 GPa cuando disminuye su diámetro de 50-100 nm a 10 nm.

El molibdeno es un metal de transición con una electronegatividad de 1,8 en la escala de Pauling y una masa atómica de 95,94 g/mol. No reacciona con oxígeno o agua a temperatura ambiente. A temperaturas elevadas, se forma el óxido de molibdeno (VI):

El molibdeno tiene varios estados de oxidación (ver tabla). Un ejemplo es la inestabilidad del molibdeno (III) y del wolframio (III) en comparación con la estabilidad de cromo (III). El estado de oxidación es más común en el molibdeno (VI) (MoO) mientras que el compuesto de óxido de azufre normal es el disulfuro de molibdeno (MoS). 

El óxido de molibdeno (VI) es soluble en bases y contribuye en la formación de molibdatos (MoO). Los molibdatos son menos oxidantes que los cromatos, pero muestran una tendencia similar cuando forman oxoaniones complejos por condensación en los valores de pH más bajos, como [MoO] y [MoO]. Los polimolibdatos pueden incorporar otros iones en su estructura, formando polioxometalatos. El fósforo que contiene heteropolimolibdato P[MoO] se utiliza para la detección de espectroscopia en el fósforo. La amplia gama de estados de oxidación del molibdeno se refleja en diversos cloruros de molibdeno:


La estructura del MoCl se compone de MoCl se compone de cuatro iones de cloruro que tienden a compensar la carga eléctrica.

Como el cromo y algunos otros metales de transición, el molibdeno es capaz de formar enlaces cuádruples, como en Mo(CHCOO). Este compuesto se puede transformar en MoCl que también tiene un enlace cuádruple.

El estado de oxidación 0 es posible con el monóxido de carbono como ligando, como en el molibdeno hexacarbonilo, Mo(CO).


El molibdeno no se encuentra libre en la naturaleza y los compuestos que se pueden encontrar fueron confundidos con otros compuestos de otros elementos (carbono o plomo) hasta el siglo XVIII. En 1778 Carl Wilhelm Scheele hizo reaccionar el mineral molibdenita (MoS) con ácido nítrico obteniendo un compuesto con propiedades ácidas al que llamó "acidum molibdenae" (la palabra molibdeno proviene del griego "molybdos" que quiere decir "como el plomo", puesto que era confundido con este elemento). En 1782 Hjelm aisló el metal impuro mediante la reducción del anterior compuesto con carbono. El molibdeno se usó muy poco, y sólo dentro del laboratorio, hasta finales del siglo XIX, cuando una empresa lo utilizó como agente aleante y observó las buenas propiedades de estas aleaciones con molibdeno.

Durante mucho tiempo no había un uso industrial para el molibdeno. La compañía francesa Schneider Electric hizo la primera armadura de placas de acero de molibdeno en 1894. Hasta la Primera Guerra Mundial, la mayoría de las fábricas de armaduras también utilizan aleaciones de molibdeno. En la Primera Guerra Mundial, algunos tanques británicos estaban protegidos por 75 mm de planchas de manganeso, pero esto resultó ser ineficaz. Las placas de manganeso fueron sustituidas por 25 mm de planchas de molibdeno. Este cambio permitió más velocidad, y maniobrabilidad. La alta demanda de molibdeno en las guerras mundiales y la fuerte disminución después de la guerra tuvo una gran influencia sobre los precios y la producción de molibdeno.

La principal fuente de molibdeno es el mineral molibdenita (MoS). También se puede encontrar en otros minerales, como la wulfenita (PbMoO) y la powellita (CaMoO). El molibdeno se obtiene de la minería de sus minerales y como subproducto de la minería del cobre, siendo esta última el principal modo de explotación comercial; el molibdeno está presente en las minas en un rango de entre un 0.01 y un 0.5%. Aproximadamente la mitad de la producción mundial de molibdeno se localiza en Estados Unidos.

Los mayores productores del mundo de materiales de molibdeno son los Estados Unidos, China, Chile, Perú y Canadá. El molibdeno es un mineral extraído, y también se recupera como un subproducto de la extracción de cobre y wolframio. Las grandes explotaciones mineras en Colorado extraen molibdenita como su producto principal, mientras que muchos depósitos de pórfidos de cobre, como la mina Bingham Canyon en Utah y la mina de Chuquicamata, en el norte de Chile producen molibdeno como subproducto de la minería del cobre. La mina Knaben en el sur de Noruega se abrió en 1885, convirtiéndose en la primera mina de molibdeno. Se mantuvo abierta hasta 1973.

El molibdeno es el 54.º elemento más abundante en la corteza terrestre y el 25.º elemento más abundante en los océanos, con un promedio de 10 ppm.

La molibdenita se calienta a una temperatura de 700 °C y el sulfuro se oxida en óxido de molibdeno (VI) por vía aérea:

El mineral oxidado se calienta a 1.100 °C para sublimar el óxido, o crear lixiviados con el amoníaco, que reacciona con el óxido de molibdeno (VI) para formar molibdatos solubles en agua:

La molibdenita de cobre es menos soluble en amoniaco. Para eliminarlo completamente desde la solución, es precipitado con sulfuro de hidrógeno.

El molibdeno puro es producido por la reducción del óxido con hidrógeno, mientras que el molibdeno que se usa para la producción de acero se reduce por la reacción aluminotérmica con la adición de hierro para producir ferromolibdeno. Una forma común de ferromolibdeno contiene 60% de molibdeno.

El molibdeno tiene un valor de aproximadamente $30.000 por tonelada en agosto de 2009. Se mantenía un precio en o cerca de $10.000 por tonelada entre 1997 y 2003, y alcanzó, debido al aumento de la demanda, un máximo de $103.000 por tonelada en junio de 2005. En 2008, la Bolsa de Metales de Londres anunció que el molibdeno se negocia como uno de los productos básicos en el intercambio.

Es el único elemento de la segunda serie de transición al que se le ha reconocido su esencialidad. El molibdeno se encuentra en la naturaleza en el rango de las partes por millón (ppm). Se encuentra en una cantidad importante en el agua de mar en forma de molibdatos (MoO), y los seres vivos pueden absorberlo fácilmente de esta forma.

El molibdeno se encuentra en el llamado cofactor de molibdeno (coMo) en distintas oxotransferasas, con la función de transferir átomos de oxígeno del agua (HO) a la vez que se produce la transferencia de dos electrones. Algunas de las enzimas que contienen este cofactor son la xantina oxidasa (que oxida la xantina a ácido úrico), la aldehído oxidasa (que oxida los aldehídos, así como las aminas y los sulfuros en el hígado), la sulfito oxidasa (que oxida sulfitos en el hígado), y la nitrato reductasa (importante en el ciclo del nitrógeno en las plantas).

El molibdeno en los seres vivos es un heteroátomo de metal en el sitio activo en ciertas enzimas. En la fijación de nitrógeno en algunas bacterias, la enzima nitrogenasa participa en la etapa terminal de la reducción de nitrógeno molecular, por lo general contiene molibdeno en su sitio activo (aunque la sustitución de Mo con hierro o vanadio también es conocida). La estructura del centro catalítico de la enzima es similar a la de las proteínas hierro-azufre, que incorpora 2 moléculas (FeS y MoFeS).

En 2008, se informó de que la escasez de molibdeno en los océanos de la Tierra primitiva era un factor limitante en la evolución de la vida de los seres eucariotas (que incluye todas las plantas y animales) como los eucariotas no pueden fijar el nitrógeno y debe adquirir de las bacterias procariotas. La escasez de molibdeno da como resultado la relativa falta de oxígeno en el océano primitivo. El oxígeno disuelto en el mar ayuda a disolver los minerales de molibdeno en el fondo del mar. Sin embargo, aunque el oxígeno puede favorecer la fijación del nitrógeno a través de la toma de molibdeno disponible en el agua, también afecta a los venenos de estas enzimas nitrogenasas, por lo que los organismos que sigue para fijar el nitrógeno en condiciones aeróbicas están obligados a aislar a sus enzimas que fijan el nitrógeno en heterocistos, o estructuras similares.

Los compuestos de molibdeno, tienen formas diversas moléculas orgánicas (como carbohidratos y aminoácidos) y se transporta a través del cuerpo humano como MoO. Al menos 50 enzimas que contienen molibdeno son conocidos, principalmente en las bacterias, y su número aumenta con cada año; las enzimas incluyen la aldehído oxidasa, sulfito oxidasa y la xantina oxidasa. En algunos animales y en humanos, se cataliza la oxidación de la xantina a ácido úrico, un proceso de catabolismo de las purinas, por la xantina oxidasa, una enzima que contiene molibdeno. La actividad de la xantina oxidasa es directamente proporcional a la cantidad de molibdeno en el cuerpo. Sin embargo, una alta concentración de molibdeno se invierte la tendencia y puede actuar como un inhibidor, tanto en el catabolismo de las purinas y otros procesos. Las concentraciones de molibdeno también afectan a la síntesis de proteínas, el metabolismo y el crecimiento. 

En los animales y las plantas, estas enzimas usan el molibdeno como un cofactor. Todos los seres vivos que utilizan enzimas de molibdeno hasta ahora identificadas en la naturaleza, usan este cofactor, salvo por la nitrogenasa, que fija el nitrógeno en algunas bacterias y cianobacterias. Las enzimas de molibdeno en las plantas y animales catalizan la oxidación y la reducción a veces de ciertas moléculas pequeñas, como parte de la regulación de nitrógeno, azufre y los ciclos del carbono.

El cuerpo humano contiene alrededor de 0,07 mg de molibdeno por kilogramo de peso. Se presenta en altas concentraciones en el hígado, los riñones y en las vértebras. El molibdeno también está presente en el esmalte de los dientes humanos y puede ayudar a prevenir su deterioro. La carne de cerdo, la carne de cordero y el hígado de res tienen cada uno alrededor de 1,5 ppm de molibdeno. Otras fuentes alimenticias significativas son las judías verdes, huevos, semillas de girasol, harina de trigo, lentejas y granos de cereales.

La ingestión diaria promedio de molibdeno varía entre 0,12 y 0,24 mg, pero depende del contenido de molibdeno de los alimentos. La toxicidad aguda no se ha visto en los seres humanos, y depende en gran medida del estado químico. Aunque los datos de toxicidad humana no están disponibles, los estudios en animales han demostrado que la ingesta crónica de más de 10 mg/día de molibdeno puede causar diarrea, retraso en el crecimiento, infertilidad, y bajo peso al nacer. También puede afectar a los pulmones, los riñones y al hígado. El tungstato sódico es un inhibidor competitivo de molibdeno, y su dieta reduce la concentración de molibdeno en los tejidos.

La deficiencia dietética de molibdeno desde su concentración bajo la superficie terrestre se ha asociado con mayores tasas de cáncer de esófago en partes de China e Irán. En comparación con Estados Unidos, que tiene una mayor oferta de molibdeno en el suelo, las personas que viven en estas áreas tienen un riesgo aproximadamente 16 veces mayor para el carcinoma esofágico de células escamosas.

Un cofactor de molibdeno observado en los lactantes, termina con la capacidad del cuerpo para el uso del molibdeno en las enzimas. Hace que los altos niveles de sulfito y ácido úrico, y el daño neurológico. La causa es la incapacidad del cuerpo para sintetizar el cofactor de molibdeno, una molécula que se une con cadenas heterocíclicas de molibdeno en el sitio activo de todas las enzimas conocidas que utilizan el molibdeno.

Los altos niveles de molibdeno pueden interferir con la absorción de cobre, produciendo deficiencia de cobre. El molibdeno evita las proteínas plasmáticas de unión al cobre, y también aumenta la cantidad de cobre que se excreta en la orina. Los rumiantes que consumen altas cantidades de molibdeno presentan síntomas como diarrea, pérdida de crecimiento, anemia y achromotrichia (pérdida del pigmento del cabello). Estos síntomas pueden ser aliviados por la administración de más cobre en el cuerpo, tanto en forma como por dieta y por inyección. La condición puede ser agravada por el exceso de azufre.

La reducción o la deficiencia de cobre también puede ser inducida deliberadamente con fines terapéuticos por el compuesto de amonio tetratiomolibdato, en la que el anión tetratiomolibdato brillante de color rojo es el agente "quelante" de cobre. El tetratiomolibdato fue utilizado por primera vez en el tratamiento de la toxicosis de cobre en los animales. Fue entonces cuando se introdujo como un tratamiento en la enfermedad de Wilson, un trastorno hereditario del metabolismo del cobre en los seres humanos, que actúa a la vez compitiendo con la absorción de cobre en el intestino y el aumento de la excreción. También se ha encontrado para tener un efecto inhibidor de la angiogénesis, posiblemente a través de la inhibición de iones de cobre, en el proceso de translocación de membrana participando una vía de secreción no clásica. Esto hace que sea un tratamiento interesante de investigación para el cáncer, la degeneración macular asociada a la edad y otras enfermedades causan un depósito excesivo de molibdeno en los vasos sanguíneos.

El molibdeno tiene seis isótopos estables y cerca de dos docenas de radioisótopos, la mayor parte con periodos de semidesintegración del orden de segundos. El Mo se usa en los generadores de Mo/Tc para la industria de isótopos nucleares. Se estima que este mercado de productos de Tc mueve unos 100 millones de euros al año. Estos generadores son muy usados para producir radiofármacos con tecnecio que se usan en medicina nuclear.

Se conocen 35 isótopos del molibdeno que van en masa atómica 83 a 117, así como cuatro isómeros nucleares. Siete isótopos se producen naturalmente, con las masas atómicas de 92, 94, 95, 96, 97, 98 y 100. De estos isótopos naturales, sólo el molibdeno-92 y el molibdeno-100 son inestables. Todos los isótopos inestables se encuentran en los isótopos de molibdeno, niobio, tecnecio y rutenio. 

El molibdeno-98 es el isótopo más abundante, y representa el 24,14% del total de molibdeno. El molibdeno-100 tiene una vida media de alrededor de 10 años y sufre una doble desintegración beta en el rutenio-100. Los isótopos de molibdeno con números de masa 111 a 117 tienen una vida media de aproximadamente 150 ns.

El humo y el polvo del molibdeno pueden ser generados por la minería o la metalurgia, pueden ser tóxicos, especialmente si se ingieren. Los niveles bajos de exposición prolongados pueden causar irritación en los ojos y la piel. La inhalación o ingestión directa de molibdeno y sus óxidos se debe evitar. especifica la cantidad máxima admisible de exposición de molibdeno en una jornada de 8 horas de 5 mg/m³. La exposición crónica a 60 a 600 mg/m³ puede causar síntomas como fatiga, dolores de cabeza y dolores en las articulaciones.



</doc>
<doc id="17627" url="https://es.wikipedia.org/wiki?curid=17627" title="Navarra (desambiguación)">
Navarra (desambiguación)

Navarra puede designar:




</doc>
<doc id="17634" url="https://es.wikipedia.org/wiki?curid=17634" title="Aeropuerto Internacional O'Hare">
Aeropuerto Internacional O'Hare

El Aeropuerto Internacional de Chicago-O'Hare , , también conocido simplemente como Aeropuerto O'Hare u O'Hare, es uno de los principales aeropuertos ubicado en la esquina noroeste de Chicago, Illinois, Estados Unidos, a 27 kilómetros (17 millas) al noroeste del Centro de Chicago. Es el mayor centro de distribución de United Airlines, cuya sede se encuentra en el centro de Chicago, y el segundo mayor centro de distribución de American Airlines, después del Aeropuerto Internacional de Dallas-Fort Worth. Es operado por el Departamento de Aviación de la Ciudad de Chicago, asociado con la autoridad regional.

Fue inaugurado en 1943.

En el 2008, el aeropuerto tuvo 881 566 operaciones de aeronaves, un promedio de 2.409 por día (64% comerciales, 33% de taxi aéreo, 3% de aviación general y <1% militares). El Aeropuerto Internacional O'Hare es el segundo aeropuerto en Estados Unidos, por detrás del Aeropuerto Internacional Hartsfield-Jackson con 69,353,654 pasajeros que pasaron por el aeropuerto en el 2008, una variación a partir de 2007 de -8,96%. El O'Hare también tiene una fuerte presencia internacional, con vuelos a más de 60 destinos en el extranjero. El O'Hare ocupó el cuarto lugar en 2005 de los Estados Unidos en cuanto a aeropuertos internacionales tan sólo detrás del Aeropuerto Internacional John F. Kennedy de Nueva York, Aeropuerto Internacional de Los Ángeles y el Aeropuerto Internacional de Miami, que atienden a más destinos en el extranjero.

El Aeropuerto Internacional O'Hare fue votado como el "Mejor Aeropuerto en América del Norte" por 10 años, por los lectores de la edición norteamericana de la revista "Business Traveler"(1998 - 2003) y la revista "Global Traveler" (2004 - 2007).

Aunque el O'Hare es el principal aeropuerto de Chicago, el Aeropuerto Internacional Midway, el segundo aeropuerto de la ciudad, se encuentra a 10 kilómetros (6 millas) del Centro de Chicago, el principal distrito financiero y de negocios.

O'Hare tiene cuatro terminales de pasajeros numeradas con nueve salas con letras y un total de 182 puertas. Se prevén dos o más edificios de terminales adicionales; existe la posibilidad de un complejo terminal grande para el lado oeste del campo, con acceso desde I-90 y/o la autopista Elgin-O'Hare, si se completa la reconfiguración de la pista y el número de pasajeros requiere terminales adicionales .

Con la excepción de los vuelos desde destinos con predespacho de aduana de los Estados Unidos, todos los vuelos internacionales entrantes llegan a la Terminal 5, ya que las otras terminales no tienen instalaciones de revisión. Varias aerolíneas, como American, Iberia, Lufthansa y United, tienen la salida de sus vuelos internacionales desde las terminales 1 y 3. Este acuerdo requiere que los pasajeros desembarquen en la Terminal 5 y luego las tripulaciones remolquen el avión vacío a otra terminal para abordar. Esto se hace, en parte, para facilitar las conexiones de los pasajeros que pasan de los vuelos nacionales a los vuelos internacionales, ya que mientras que las terminales 1, 2 y 3 permiten las conexiones lado aire, la Terminal 5 está separada de las otras terminales por un conjunto de calles de rodaje que cruzan la carretera de acceso del aeropuerto, que requiere que los pasajeros salgan de la seguridad, aborden el sistema de tránsito del aeropuerto y luego pasen de nuevo seguridad en cualquier dirección.

La Terminal 1 se utiliza para los vuelos de United Airlines, incluyendo todos los vuelos principales y algunas operaciones de United Express, así como los vuelos para los socios de Star Alliance Lufthansa y All Nippon Airways. La Terminal 1 tiene 50 puertas en dos salas:

Las Salas B y C son salas lineales situadas en edificios separados paralelos entre sí. La Sala B está adyacente a la carretera del aeropuerto y alberga áreas de documentación, reclamo de equipaje y revisiones de seguridad en sus puertas terrestres y de aviones en su lado aéreo. La Sala C es una terminal satélite con puertas en todos los lados, en el centro de la rampa está conectada la Sala B a través de un túnel peatonal subterráneo bajo la rampa. El túnel se origina entre las puertas B8 y B9 de la Sala B, y termina en la Sala C entre las puertas C17 y C19. El túnel se ilumina con una instalación de neón titulada "Sky's the Limit" (1987) del artista canadiense Michael Hayden, que interpreta una versión airosa y muy lenta de "Rhapsody in Blue".

United opera también un servicio de autobús después de la seguridad entre la Sala C (en la puerta C9) en la Terminal 1 y las Salas E y F (en la puerta E4) en la Terminal 2. Funciona con tres "United Club" en la Terminal 1: uno en la Sala B cerca de la puerta B6, un ubicado cerca de la puerta B16 y otro en la Sala C cerca de la puerta C16. También hay un United First International Lounge y un United Arrivals Suite en la Sala C cerca de la puerta C18.

La Sala B cuenta con una extensión en su extremo norte (puertas B18-B22) comúnmente llamado las "puertas de plátano" debido a la forma curva estrecha de la extensión. La puerta final, B22, se ramifica en tres pasarelas de acceso separados para tres posiciones de estacionamiento de jet regionales.

La Terminal 1 alberga la oficina de Chicago de All Nippon Airways.

La Terminal 2 alberga a Air Canada, Delta Air Lines y los vuelos nacionales de Delta Connection, y la mayoría de las operaciones de United Express (la documentación para todos los vuelos de United se realiza en la Terminal 1). La terminal 2 tiene 43 puertas en dos salas.
Hay un United Club en la Sala F cerca de la puerta F8, y un Delta Sky Club en la Sala E cerca de la puerta E6. "United Continental Holdings", la empresa matriz de United, actualmente está actualizando sus instalaciones en la Terminal 2, incluyendo la construcción de 10 nuevas pasarelas de acceso a aeronaves para los vuelos regionales, la reconfiguración de las salas de espera y la construcción de un United Club que reemplazará el actual. US Airways operó desde la Terminal 2 hasta que trasladó sus operaciones a la Terminal 3 en julio de 2014, para ser ubicada junto con su socio de fusión American Airlines. La documentación para US Airways se mantuvo en la Terminal 2 hasta el 16 de septiembre de 2014, cuando los mostradores de documentación se trasladaron a la Terminal 3.

La Terminal 3 alberga todos los vuelos de American Airlines, así como salidas para determinados operadores de Oneworld incluyendo Iberia y Japan Airlines, además de compañías aéreas no afiliadas de bajo costo. La terminal 3 tiene 75 puertas (5 a ser agregadas) en cuatro salas:

Las Salas G y L albergan la mayoría de las operaciones de American Eagle, mientras que las Salas H y K albergan las operaciones principales de American. Los socio de American en Oneworld Japan Airlines e Iberia salen de la puerta K19 y Alaska Airlines opera desde la puerta H4. La Sala L se utiliza también para los vuelos operados por Frontier Airlines, Spirit Airlines, JetBlue, Virgin America y Air Choice One. La Ciudad de Chicago y American Airlines han acordado una extensión la Sala L para agregar cinco puertas nuevas. Se espera que las puertas se utilicen principalmente para la flota de Embraer E-175 de American Eagle. American ha acordado pagar alrededor de $55 a $75 millones de dólares y se espera que las puertas estén terminadas para 2018. La aerolínea opera tres Admirals Club en la Terminal 3: uno situado en la zona de cruce de las puertas H6 y K6, uno después del área de seguridad delante de la puerta L1 y uno en la Sala G frente a la puerta G8. American también tiene un Salón VIP insignia (llamado International First Class Lounge) situado cerca de la puerta K19. El salón VIP insignia está programado para moverse debajo del Admirals Club ubicado en el área de cruce entre las puertas H6 y K6 a finales de 2017.

La Terminal 5 alberga todas las llegadas internacionales de O'Hare (excluyendo los vuelos de American Airlines y United Airlines desde destinos con predespacho de aduana). Otros destinos con predespacho de aduana incluyendo los vuelos operados por Aer Lingus y Etihad Airways, llegan a la Terminal 5, pero son tratados como llegadas nacionales. Con excepción de las aerolíneas seleccionadas de Star Alliance y Oneworld que embarcan desde la Terminal 1 o la Terminal 3 respectivamente, todas las aerolíneas no estadounidenses excepto Air Canada salen de la Terminal 5. La terminal 5 tiene 21 puertas (9 a ser agregadas) en una sala:
La terminal 5 tiene varios salones de aerolíneas, incluyendo el lounge de Air France-KLM, las galerías de primera clase y las terrazas de British Airways, el Korean Air Lounge, el Scandinavian Airlines Lounge, el Swissport Lounge y los Swiss International Air Lines First Class Lounge y Business Class Lounge. La instalación de la oficina de Aduanas y Protección Fronteriza de los Estados Unidos se encuentra en el nivel de llegadas (inferior).

La Terminal 5 se sometió a una renovación de 26 millones de dólares diseñada por A. Epstein y Sons International, Inc., que comenzó en julio de 2012, que incluye la adición de comedores y tiendas post-seguridad, incluyendo muchos restaurantes y marcas de Chicago, diseño actualizado y un rediseño de ingeniería. El proyecto fue terminado el 4 de abril de 2014. La terminal 5 es operada por Westfield Management.

O'Hare recientemente desarrolló una puerta capaz de acomodar el avión de pasajeros más grande del mundo, el Airbus A380. El 10 de febrero de 2016, el Departamento de Aviación de Chicago aprobó la construcción para construir una puerta que podría manejar el avión de Airbus. La nueva puerta, M11a es la única puerta capaz de manejar el Airbus A380 y, al igual que otras puertas de la Terminal 5, es designada como "de uso común", lo que significa que ninguna línea aérea específica tiene control exclusivo sobre ella. Emirates y British Airways expresaron interés en utilizar sus A380 en rutas que implican a O'Hare. La puerta entró en funcionamiento el 19 de julio de 2016, con Emirates siendo la primera aerolínea en utilizarla.

La Terminal 1 fue la primera terminal internacional. Se abrió en 1955, se convirtió en la terminal internacional en 1963 y fue demolida en 1984 para dar paso a la actual Terminal 1. Fue reemplazada por una Terminal 4 temporal construida en 1984. La terminal fue conectada a la Terminal 2 por un pasillo cerrado con vidrio. Tenía una explanada en forma de "Y", similar a la de las Salas H/K en la Terminal 3.

La antigua terminal 1 también tenía un sala satélite A que servía a diversas líneas aéreas . Entre las aerolíneas que solían operar desde esta terminal fueron Air France, El Al, Icelandair, Mexicana de Aviación, Pan Am y Sabena.

Una Sala D en la Terminal 2 existió anteriormente y sirvió como la sala para AirCal, Braniff International, Continental Airlines, Eastern Airlines, Frontier Airlines, Northwest Airlines, People Express, Piedmont y United Express hasta que fue demolida en 1988 para dar cabida a las salas actuales de la Terminal 1. Constaba de 12 puertas.

Debido a la construcción de la Terminal 1 de United, todas las llegadas internacionales y algunas salidas internacionales se trasladaron a una Terminal 4 temporal de 1984 a 1993. La Terminal 4 estaba ubicada en la planta baja del garaje principal; los pasajeros que salían y llegaban eran transportados en autobús hacia y desde sus aviones. La terminal sirvió a muchos transportistas internacionales durante este tiempo, pero era inadecuada tanto en términos de área de operación y de capacidad de carga/descarga de autobuses.

Al hacer la nueva terminal internacional de $618 millones se cerró el 11 de julio de 1990, con los ejecutivos de la línea aérea y los funcionarios del gobierno, conducidos por el alcalde Richard M. Daley y el Secretario de Transporte Samuel K. Skinner.. La nueva Terminal 5, diseñada por "Perkins and Will" en conjunción con "Heard & Associates" y "Consoer Townsend & Associates" fue parcialmente abierta el 27 de mayo de 1993, con sus dos niveles inferiores completados para manejar todas las llegadas internacionales. El resto de terminal, incluido el nivel de salidas, se inauguró el 30 de septiembre de 1993. El nombre "Terminal 5" se utilizó para esta nuevo terminal con el fin de evitar confusiones con la antigua Terminal 4.

Desde la apertura de la Terminal 5, la Terminal 4 se ha convertido en la instalación del aeropuerto para los autobuses regionales de tránsito, los shuttles de hoteles y otros medios de transporte terrestre; la designación de la Terminal 4 podrá utilizarse de nuevo en el futuro a medida que se desarrollen nuevas terminales. La línea Azul del metro de Chicago se extendió al aeropuerto en 1984.

Hay dos áreas de carga principales en O'Hare que tienen instalaciones de almacén y estacionamiento de aviones. El área de carga del sudoeste, adyacente al camino del parque de Irving, acomoda más del 80% de los vuelos de carga del aeropuerto, repartidos entre 9 edificios en dos zonas. El área de carga del norte, que es una modesta conversión de la antigua base militar (el área de la planta de Douglas de 1943), también recibe cargueros aéreos. Es adyacente a la porción norte de la calle Bessie Coleman.

Dos áreas de carga satélite tienen instalaciones de almacenamiento y desmontaje, pero los aviones no se estacionan en ellas. La carga se transporta en camiones de/hacia otras aeronaves en otras rampas. La zona de carga del sur se encuentra a lo largo del camino Mannheim. El área de carga del este, adyacente a la terminal 5, era antes la única sección de carga del aeropuerto pero ahora ha evolucionado sobre todo en una zona de ayuda del aeropuerto.

El área de carga del suroeste se encuentra parcialmente en el camino de una de las nuevas pistas (10C/28C). La remodelación del aeródromo implicará mover/reemplazar este eje primario de carga.

Se brinda servicio a 177 ciudades dentro del país a cargo de 14 aerolíneas. 
Se ofrece servicio a 72 destinos internacionales (23 estacionales), a cargo de 51 aerolíneas.





</doc>
<doc id="17645" url="https://es.wikipedia.org/wiki?curid=17645" title="Subespacio vectorial">
Subespacio vectorial

En álgebra lineal, un subespacio vectorial es el subconjunto de un espacio vectorial, que satisface por sí mismo la definición de espacio vectorial con las mismas operaciones que "V".

Sea formula_1 un espacio vectorial sobre formula_2 y formula_3 no vacío, formula_4 es un subespacio vectorial de formula_1 si:


Notaciones

Dado formula_8 un subespacio vectorial, se tiene:

Para i) el abuso de lenguaje formula_9, e incluso formula_10 es correcto.
Para ii) el abuso de lenguaje formula_11, e incluso formula_12 es correcto.
Es posible sintetizar i) y ii) en una condición única:

Dado el espacio vectorial formula_13, sus elementos son del tipo formula_14.

El subconjunto 

es un subespacio vectorial.

El subconjunto

no es un subespacio vectorial.

Sea formula_15 un espacio vectorial; formula_16 y formula_17 subespacios vectoriales de formula_18, se definen las siguientes operaciones:

formula_19
En general, la unión de subespacios no es un subespacio.

formula_20
La intersección de dos subespacios es un subespacio.
formula_21
La suma de dos subespacios es un subespacio de "V".
Si la intersección entre "S" y "W" es el subespacio trivial (es decir, el vector nulo), entonces a la suma se la llama "suma directa".
Es decir que si formula_22
Esto significa que todo vector de "S+W", se escribe de manera única como la suma de un vector de "S" y otro de "W".

Se dice que los subespacios formula_23 y formula_24son suplementarios cuando verifican que su suma directa es igual al espacio vectorial formula_25:

formula_26

La fórmula de Grassmann resuelve que la dimensión de la suma de los subespacios formula_23 y formula_28 será igual a la dimensión del subespacio formula_23 más la dimensión del subespacio formula_28 menos la dimensión de la intersección de ambos, es decir:
formula_31

Por ejemplo, siendo formula_32 y formula_33 y teniendo como intersección un subespacio de dimensión 1. Luego, formula_34.

En el caso particular de la suma directa, como formula_35.La fórmula de Grassmann resulta:formula_36Entonces en el ejemplo anterior, resultaría formula_37.



</doc>
<doc id="17648" url="https://es.wikipedia.org/wiki?curid=17648" title="Tres leyes de la robótica">
Tres leyes de la robótica

Las tres leyes de la robótica son un conjunto de normas elaboradas por el escritor de ciencia ficción Isaac Asimov que se aplican a la mayoría de los robots de sus novelas y cuentos y que están diseñados para cumplir órdenes. En ese universo, las leyes son «formulaciones matemáticas impresas en los senderos positrónicos del cerebro» de los robots (líneas de código del programa que regula el cumplimiento de las leyes guardado en la memoria principal de aquellos). Aparecidas por primera vez en el relato «» ("Runaround", 1942), establecen lo siguiente:


Esta redacción de las leyes es la forma convencional en la que los humanos de las historias las enuncian; su forma real sería la de una serie de instrucciones equivalentes y mucho más complejas en el cerebro del robot.

Asimov atribuye las tres leyes a John W. Campbell, que las habría redactado durante una conversación sostenida el 23 de diciembre de 1940. Sin embargo, Campbell sostiene que Asimov ya las tenía pensadas, y que simplemente las expresaron entre los dos de una manera más formal. 

Las tres leyes aparecen en un gran número de historias de Asimov, tanto en su serie de los robots como en varias historias relacionadas, y la serie de novelas protagonizadas por Lucky Starr. También han sido utilizadas por otros autores cuando han trabajado en el universo de ficción de Asimov, y son frecuentes las referencias a ellas en otras obras, no solo de ciencia ficción, sino también de otros géneros. 

Estas tres leyes surgen únicamente como medida de protección para los seres humanos. Según el propio Asimov, la concepción de las leyes de la robótica quería contrarrestar un supuesto "complejo de Frankenstein", es decir, un temor que el ser humano desarrollaría frente a unas máquinas que hipotéticamente pudieran rebelarse y alzarse contra sus creadores. De intentar siquiera desobedecer una de las leyes, el cerebro positrónico del robot resultaría dañado irreversiblemente y el robot "moriría". A un primer nivel no presenta ningún problema dotar a los robots con tales leyes, a fin de cuentas, son máquinas creadas por el hombre para su ayuda en diversas tareas. La complejidad reside en que el robot pueda distinguir cuáles son todas las situaciones que abarcan las tres leyes, o sea poder deducirlas en el momento. Por ejemplo saber en determinada situación si una persona está corriendo peligro o no, y deducir cuál es la fuente del daño o la solución.

Las tres leyes de la robótica representan el código moral del robot. Un robot va a actuar siempre bajo los imperativos de sus tres leyes. Para todos los efectos, un robot se comportará como un ser moralmente correcto. Sin embargo, es lícito preguntar: ¿Es posible que un robot viole alguna persona?

Las tres leyes de la robótica de Asimov aparecen formuladas por primera vez en 1942, en el relato "Círculo vicioso", de Asimov.

El autor busca situaciones contradictorias en las que la aplicación objetiva de las tres leyes se pone en tela de juicio planteando a la vez interesantes dilemas filosóficos y morales que, en esta colección, Robots & Aliens están más presentes que nunca.

Los primeros robots construidos en la Tierra (vistos, por ejemplo, en "Yo, robot") eran modelos poco avanzados. Era una época en donde la robopsicología no estaba aún desarrollada. Estos robots podían ser enfrentados a situaciones en las cuales se vieran en un conflicto con sus leyes. Una de las situaciones más sencillas se da cuando un robot debe dañar a un ser humano para evitar que dos o más sufran daño. Aquí los robots decidían en función de un criterio exclusivamente cuantitativo, quedando luego inutilizados, al verse forzados a violar la primera ley. 

Posteriores desarrollos en la robótica, permitieron la construcción de circuitos más complejos, con una mayor capacidad de autorreflexión. Una peculiaridad de los robots es que pueden llegar a redefinir su concepto de "daño" según sus experiencias, y determinar niveles de éste. Su valoración de los seres humanos también puede ser determinada por el ambiente. Es así que un robot puede llegar a dañar a un ser humano por proteger a otro que considere de más valía, en particular su amo. También podría darse el caso de que un robot dañara físicamente a un ser humano para evitar que otro sea dañado psicológicamente, pues llega a ser una tendencia el considerar los daños psicológicos más graves que los físicos. Estas situaciones nunca se hubieran dado en robots más antiguos. Asimov plantea en sus historias de robots las más diversas situaciones, siempre considerando las posibilidades lógicas que podrían llevar a los robots a tales situaciones.

Uno puede llegar a encariñarse con los robots de Asimov, el cual nos muestra en sus historias robots cada vez más "humanos". En «El hombre bicentenario», Asimov nos narra la historia de "Andrew Martín", nacido robot, y que lucha durante toda su vida (como "Uno") para ser reconocido como un ser humano. Están también R. Daneel Olivaw y R. Giskard Reventlov, que tienen un papel fundamental en la segunda expansión de los seres humanos y la consiguiente fundación del imperio galáctico. Siendo los robots más complejos jamás creados, fueron capaces de desarrollar la ley cero de la robótica ("Zeroth law", en inglés) como corolario filosófico de la primera:

R. Giskard murió en "Robots e Imperio", tras verse obligado a dañar a un ser humano en virtud de la ley cero. El problema fundamental con esta ley es definir "Humanidad", así como determinar qué supone un "daño" para la Humanidad. R. Daneel logró asimilarla gracias al sacrificio de Giskard, convirtiéndose desde entonces en el protector en la sombra de la Humanidad. Daneel, bajo distintas identidades, se convierte en uno de los personajes más importantes del ciclo de Trántor (formado por los cuentos y novelas de robots, las novelas del imperio, y la saga de las fundaciones: 17 libros) siendo además un elemento clave en su continuidad



</doc>
<doc id="17652" url="https://es.wikipedia.org/wiki?curid=17652" title="Pájaro (desambiguación)">
Pájaro (desambiguación)

Pájaro puede referirse a:


</doc>
<doc id="17653" url="https://es.wikipedia.org/wiki?curid=17653" title="Randy Travis">
Randy Travis

Randy Travis (Marshville, Carolina del Norte, 4 de mayo de 1959) es un cantante de estilo country y actor estadounidense.

Travis nació con el nombre de Randy Bruce Trawick en Marshville, Carolina del Norte, siendo el segundo de seis hermanos.

Empezó actuando a los ocho años de edad junto a su hermano Ricky. Randy huyó a Charlotte, Carolina del Norte a los dieciséis años y empezó a actuar en un bar. Travis continuó metiéndose en problemas legales, finalmente un juez le dijo que si era visto otra vez, iría a prisión durante un largo tiempo. Travis empezó a concentrarse en la música junto a la firma Paula Records para sacar a la luz su infructuoso single, "She's my Woman" (ella es mi chica).

En 1982, Travis grabó su álbum debut "Randy Ray Live" y empezó a ser oído por la radio. En 1985 vio como su álbum "1982" llegó a ser un éxito, seguido de su álbum "Storms of Life". A finales de los años 1980 tuvo una completa cadena de éxitos, incluyendo: "Forever and Ever, Amen", "No Place Like Home" y "Diggin' Up Bones". Dos años en fila, gana el Premio Grammy para la mejor voz masculina del país (U.S.A), por el álbum "Always And Forever" en 1988, y "Old 8 x 10" en 1989. En 1992, no obstante, Travis no estuvo mucho tiempo en la lista de los más vendidos como Clint Black, Garth Brooks y otros que habían cogido estado sobre Nashville. Volvió más tarde con su álbum de 1994 "This Is Me" (éste soy yo) y su exitoso single "Whisper My Name" (susurra mi nombre). En 2000 salió a la luz su álbum "Inspirational Journey", una colección de canciones religiosas, y en 2003 "Worship y Faith". Su álbum más reciente es "Around the Bend", lanzado en 2008.





</doc>
<doc id="17655" url="https://es.wikipedia.org/wiki?curid=17655" title="Valle de La Orotava">
Valle de La Orotava

El Valle de la Orotava está situado en el norte de la isla de Tenerife, en las Islas Canarias (España). En el lado opuesto se encuentra el Valle de Güímar.

En él se encuentran los municipios de La Orotava, Los Realejos y el Puerto de la Cruz.

Este valle en la época de los guanches era conocido como Taoro, y precisamente aquí terminó la conquista de Tenerife el 25 de julio de 1496 con la llamada Paz de Los Realejos, erigiéndose, con tal motivo, en honor al patrón de España, el primer templo cristiano de la isla de Tenerife, la Parroquia Matriz del Apóstol Santiago. El mencey de Taoro pacta el fin de las hostilidades con Alonso Fernández de Lugo (1456-1525).

Numerosos e ilustres visitantes han elogiado su paisaje y disfrutado de su beneficioso clima: uno de los más famosos fue Alexander von Humboldt, quien según cuenta la leyenda se arrodilló ante el valle en el mirador que lleva actualmente su nombre y alabó su paisaje y vegetación. 


</doc>
<doc id="17656" url="https://es.wikipedia.org/wiki?curid=17656" title="Olivia Newton-John">
Olivia Newton-John

Olivia Newton-John (Cambridge, 26 de septiembre de 1948) es una cantante de música pop y actriz australiana, nacida en el Reino Unido y de origen judeoalemán y checo.

Nació en Cambridge, Reino Unido. Es hija de madre judía alemana y padre británico de origen galés. Su abuelo materno fue el físico y matemático alemán Max Born, que obtuvo un Premio Nobel de Física. 

Cuando solo tenía 5 años se trasladó a Australia con su familia, ya que a su padre le ofrecieron un trabajo como profesor en una universidad de Melbourne. Tuvo una hermana, la actriz Rona Newton-John, la cual falleció de cáncer. Se la conoce por el apodo "Livvy", de Olivia. En Australia, donde transcurrió su infancia y adolescencia, estudió en la Universidad de Melbourne.

Los inicios de Newton-John como cantante se remontan al instituto, en un grupo femenino llamado "Sol Four".

Su primer álbum, "If Not For You", grabado en 1971, llegó a los Estados Unidos y consiguió tres sencillos de mediano éxito: "Banks of The Ohio", "Me and Bobby McGee" (versión de una canción ya existente) e "If Not For You". Dos años después presentó su segundo álbum, "Let Me Be There", destacando la balada country "Take Me Home Country Roads".

En 1974 representó al Reino Unido en el Festival de Eurovisión que se celebró en la ciudad inglesa de Brighton. Interpretó el tema "Long Live Love" y quedó en 4ª posición resultando como ganadores los suecos ABBA (con "Waterloo") y en segunda posición Gigliola Cinquetti. En ese año el tercer álbum "If You Love Me, Let Me Know" llegó a las primeras posiciones de la lista de álbumes, y por fin una balada del disco, "I Honestly Love You", se afianzó en el 1º Lugar del "Billboard" estadounidense.

De inmediato Olivia se encerró en los estudios de grabación para grabar el siguiente L.P., que sería un auténtico éxito en el mercado americano: "Have You Never Been Mellow", que escaló sin problemas al primer puesto de álbumes en 1975 y colocando al tema homónimo en el 1º Lugar del "Hit Parade". Otra canción del disco destacó: se trata de otra balada en el estilo "country": "Please Mr. Please". 

En 1975 se fue a vivir a los Estados Unidos, donde alcanzó pronto fama como cantante de música pop y también de música "country". A lo largo de su carrera sus canciones alcanzaron en 5 ocasiones el primer puesto en las listas de ventas. Una de ellas fue "Physical", que permaneció durante 10 semanas en ese puesto. También obtuvo 4 premios Grammy. En 1979 intervino en el concierto benéfico "Music for UNICEF", junto a artistas como los Bee Gees, ABBA, Donna Summer, Rod Stewart entre otros, cantando "Rest your love on me" y "The Key". 

Newton-John también ha sido actriz, participando en películas de carácter musical. Su mayor éxito fue "Grease", con John Travolta. 

Las siguientes no tuvieron igual éxito, en especial "Xanadu", que fracasó a pesar de la participación de Gene Kelly y de la música compuesta por Jeff Lynne, miembro fundador de Electric Light Orchestra (ELO). Tampoco triunfó "Two of a Kind", mal acogida por el público aunque su banda sonora fue igualmente un gran éxito. 

Olivia Newton-John tiene una estrella con su nombre en Hollywood Boulevard, en reconocimiento de su extraordinaria trayectoria.

Newton-John estuvo casada entre 1984 y 1995 con el actor Matt Lattanzi. De este matrimonio tiene una hija, Chloe Rose, nacida en 1986. A finales de los 80 lanzó junto a su amiga Pat Farrar una marca de ropa llamada "Koala Blue", en Australia y Estados Unidos, que por errores financieros la llevó a la bancarrota en 1992, pero del que se recuperó económicamente gracias a la publicidad y telefilmes para la pequeña pantalla. 

Desde 1996 vivía con Patrick McDermott, un operador de cámara, hasta que éste desapareció en extrañas circunstancias durante una excursión en barco en 2005. Pero en 2006, surgieron rumores de que McDermott había sido visto en México y de que había simulado su muerte para romper su relación con Olivia. En julio de 2008 ella se casó en secreto con el magnate John Easterling.

En 1992 Newton-John estaba preparada para otro regreso al éxito, cuando lanzó su tercera colección de grandes éxitos, "Back to Basics - The Essential Collection 1971-1992", y planeó su primera gira desde su disco "Physical" realizada diez años antes. Poco después del lanzamiento del álbum, a Newton-John le fue diagnosticado un cáncer de mama que la obligó a cancelar toda la publicidad para el recopilatorio, incluyendo el tour (Newton-John recibió su diagnóstico el mismo fin de semana en que su padre murió) Luego de un largo tratamiento, Newton-John se recuperó y desde entonces se convirtió en una incansable defensora de la investigación sobre el cáncer y otros problemas de salud. Es portavoz del producto Liv-Kit para el autoexamen de mamas. También es propietaria parcial de la Gaia Retreat & Spa en Byron Bay, Australia, que se anuncia como «el lugar ideal para renovar, actualizar y restaurar su mente, cuerpo y alma». 

La defensa de Newton-John por los problemas de salud fue presagiada por su participación previa en muchas causas humanitarias. Newton-John canceló una gira de conciertos 1978 de Japón para protestar contra la masacre de delfines atrapados en redes de pesca de atún (posteriormente la gira fue reprogramada cuando el gobierno japonés le aseguró que el asunto se estaba investigando). Participó en el concierto de 1979 "Music for UNICEF Concert" para la transmisión mundial televisiva del "Año Internacional del Niño". Durante el concierto, los artistas interpretaron canciones y donaron sus regalías a perpetuidad, algunos en beneficio de la causa. Fue nombrada Embajadora de Buena Voluntad del Programa de las Naciones Unidas para el Medio Ambiente. 

En 1991, se convirtió en la portavoz nacional del Fondo Ambiental Colette Chuda / CHEC (Coalición de Salud Ambiental de los Niños), tras la muerte de Colette Chuda, niña de cuatro años de edad amiga de la familia, a causa del cáncer (Chuda fue presentada junto con Newton-John y a su hija Chloe en la portada de su álbum "Warm and Tender" de 1989).

De igual forma, el diagnóstico de cáncer influyó notablemente en que la música de Newton-John hiciera alguna referencia a ello. En 1994, lanzó "Gaia: One Woman's Journey". Este fue el primer álbum en el que ella misma escribió todas las canciones, animándola a participar más activamente como compositora a partir de entonces. Un disco realacionado fue "Stronger Than Before," de 2005; las ganancias obtenidas de las ventas del álbum se donaron a la investigación del cáncer de mama.

En 2008, Newton-John recaudó fondos para ayudar a construir el Olivia Newton-John Cancer and Wellness Centre en Melbourne, Australia.

El 30 de mayo de 2017, luego de 25 años de la detección de su cáncer, Olivia anunció la reincidencia de la enfermedad, lo que le producía un dolor de espalda que le obligó a posponer presentaciones. Este dolor fue el anuncio de que el mal se ha extendido al hueso sacro de su espalda. Por este motivo se someterá a terapias naturales y a un periodo de radiación en un centro de tratamiento del cáncer que lleva su nombre en Australia.







</doc>
<doc id="17658" url="https://es.wikipedia.org/wiki?curid=17658" title="Silvio Berlusconi">
Silvio Berlusconi

Silvio Berlusconi (Milán, 29 de septiembre de 1936) es un político, empresario, inversor, periodista deportivo y magnate de los medios italiano, fundador y presidente de la poderosa corporación de telecomunicaciones Mediaset. Fue, además, el fundador y Presidente de Forza Italia, organización que luego se integró en la poderosa coalición política denominada El Pueblo de la Libertad, de la cual fue fundador y presidente, llegando a ejercer como Presidente del Consejo de Ministros de Italia en tres ocasiones (1994-1995, 2001-2006 y 2008-2011). Igualmente fue Ministro de Relaciones Exteriores de Italia en el año 2002 y fue Presidente de turno del Consejo Europeo durante el segundo semestre del año 2003.

Fue asimismo propietario y presidente del equipo de fútbol AC Milan desde 1986 hasta el 2017. Es apodado Il Cavaliere («El Caballero») por tener la "Ordine al merito del lavoro" (Orden del Mérito al Trabajo), que conlleva el tratamiento de caballero, entre 1977 y 2014 año en el que tuvo que renunciar antes de que la Federación Nacional de los Caballeros del Trabajo le desposeyerá de dicha orden.

En 2013, la Corte Suprema de Casación lo condenó en forma definitiva a 4 años de prisión por fraude fiscal.

Originario de una familia de clase media milanesa, Berlusconi fue el primer hijo de Luigi Berlusconi Lutesta y Rosa Bossi, siendo sus hermanos menores Paolo Berlusconi (1949–) y Maria Antonietta Francesca Berlusconi (1943–2009).

Después de completar su educación secundaria en un colegio salesiano, estudió Derecho en la Universidad de Milán y se graduó cum laude con una tesis sobre los aspectos jurídicos de la publicidad en 1961. Por ser el primogénito en su familia, Berlusconi no estuvo obligado a prestar el servicio militar en el ejército italiano, el cual era obligatorio entonces.

En 1965 se casó con Carla Elvira Dall’Oglio, con quien tuvo dos hijos: Marina Elvira (1966–), más conocida como Marina, y Pier Silvio (1968–). De su primera mujer se divorció en 1985, y en 1990 entabló una relación con la actriz Veronica Lario, con quien tuvo tres hijos: Barbara (1984–), Eleonora (1986–) y Luigi (1988–). Se casó en 1990 con Lario, siendo en ese momento un conocido empresario y su boda, un notable acontecimiento social. A finales de abril de 2009, Veronica Lario emprendió los trámites de divorcio después de que la pareja hubiera protagonizado algunas sonoras disputas —prensa mediante— durante el último año.

En diciembre de 2012 en un programa televisivo habló de Francesca Pascale, su siguiente pareja mucho más joven que él, con la que en marzo de 2014 comenzaron a circular rumores de casamiento.

En marzo de 1981 se encuentra una lista con los integrantes de la irregular logia masónica Propaganda Due donde aparece su nombre.

En 1974 fundó el canal de televisión local "Telemilano" y cuatro años después "Canale 5", esta vez de ámbito nacional. Fue el primero en desarrollar una red de canales televisivos de carácter nacional y puso fin al monopolio de la televisión pública italiana y consiguió superarla en audiencia con una parrilla centrada en concursos y programas de entretenimiento. En la temporada 1983-84 adquirió "Italia 1" y "Rete 4", lo que dio vida al duopólio televisivo "Rai-Fininvest", autorizado por una ley de 1990.

En 1985 fundó "La Cinq", la primera cadena privada gratuita de Francia, que quebró por falta de audiencia, y adquirió acciones de los canales franceses "Chain" y "Cinéma 5". En 2002, el grupo "Mediaset" compró "Telecinco" por 276 millones de euros. Posee la mayor empresa italiana de publicidad y compró la productora "Endemol", que vende formatos de programas que luego se adaptan a cada país. Durante su gobierno cambió la ley que lo obligaba a dar las frecuencias de su canal Rete 4 al nuevo canal "Europa 7".

Su imperio se extiende también al terreno de la prensa escrita. En 1976 compró participaciones de ""Il Giornale"". Al final de su carrera como empresario mediático, en 1990, obtuvo la presidencia del grupo Mondadori, editor del periódico ""La Repubblica"" y de los semanarios ""L’Espresso"", ""Epoca"", y ""Panorama"" en aquel momento.

Más tarde, adquirió la cadena de tiendas de vídeo Blockbuster, portales de acceso a Internet y una participación en Olivetti. Así, el grupo Mondadori controla actualmente un tercio del sector editorial en Italia.
Para aunar los varios sectores de la comunicación que poseía (televisión, prensa, edición, internet, publicidad), creó el conglomerado Fininvest, que ahora se llama Mediaset. La compañía fundada por Berlusconi consiguió expandirse internacionalmente y entrar en vinculación con diversas personalidades del sector de las telecomunicaciones.

En el plano de los negocios relacionado con el deporte, fue dueño del AC Milan desde 1986 hasta 2017, cuando el club fue vendido a Rossoneri Sport Investment Lux.

Según la revista Forbes, en 2011 es la persona más adinerada de Italia, con una fortuna de 7.8 mil millones de dólares.

Tras una inicial vinculación al Partido Socialista de Bettino Craxi, el desarrollo del proceso de "Tangentopoli" o "Manos Limpias" por el que se comenzó a combatir la corrupción institucional generalizada en Italia, construyó el movimiento Forza Italia con el que obtuvo el poder en las elecciones de 1994 (en coalición con otros partidos), perdiéndolo en 1995 por el abandono de la coalición por parte de la Lega Nord de Umberto Bossi. Ha sido acusado en repetidas ocasiones de conexiones con la Mafia, y algunos de sus colaboradores más cercanos, como Cesare Previti, han sido condenados en firme por corrupción de la Justicia.

Berlusconi volvió a ser Primer Ministro italiano, desde mayo del 2001 hasta el mes de mayo de 2006 (con dos gobiernos seguidos). En 2006 ganó las elecciones la coalición de centro-izquierda. Tras una agria polémica post-electoral, el 2 de mayo de 2006 dimitió de su cargo y fue relevado por Romano Prodi.

Mientras gobernó, controlaba indirectamente los tres canales de la RAI, y directamente los tres canales de Mediaset (es decir, el 100% de la televisión terrestre y el 90% del total). Uno de sus primeros actos de gobierno fue despedir a periodistas y comediantes incómodos como Biagi, Santoro y Luttazzi. Se suele criticar a los periodistas que, no solo no se rebelaron contra ello, sino que parecieron dar su asentimiento al descabello. En efecto, no hay sino mirar los periódicos del día después del "Edicto de Sofia". Por otro lado es un miedo si no justificable, sí comprensible, ya que se trataba de sus trabajadores, por cuanto una gran parte de la prensa escrita es también de su propiedad. En España controla (indirectamente) el 50,13% de Telecinco.

El 18 de noviembre de 2007 anuncia la disolución de su histórico partido Forza Italia y el nacimiento del "Popolo della Libertà" (unión de varios partidos) con el que, en coalición con la Lega Nord y el Movimento per l’Autonomia, ganó nuevamente las elecciones, frente a Walter Veltroni (ex alcalde de Roma) líder del Partido Demócrata (que estaba en coalición con la Italia de los Valores), llevando a la coalición a una clara victoria ya que obtiene mayoría relativa en el país y, por efecto de la ley electoral, absoluta en ambas cámaras. En la Cámara de Diputados la coalición de Silvio Berlusconi obtuvo un 46,8% de los sufragios frente al 37,5% de la coalición de Veltroni y al 5,62% del UDC. Por su parte, en el Senado de la República la diferencia fue igual de amplia: un 47,32% frente a un 38,01% de la coalición de centro izquierda y a un 5,70% del UDC, único partido no coaligado que obtuvo escaños.

Debido a las indicaciones de los partidos, el presidente Napolitano eligió a Berlusconi como Presidente del Consejo de Ministros de Italia, cargo que cubre por tercera vez. En sus primeras declaraciones, el presidente ha tendido la mano al partido de Veltroni y ha asegurado agotar los 5 años de legislatura gracias a la gran confianza que le han otorgado sus compatriotas italianos.

Berlusconi ha apoyado la guerra contra el terrorismo enviando tropas a la guerra de Afganistán a la guerra de Irak y enviando aviones de combate para derrocar y finalmente acabar junto a la OTAN al ex líder libio Muamar al Gadafi en la intervención militar en Libia de 2011.

El 24 de junio de 2013 fue condenado en primer grado a 7 años de prisión e inhabilitación perpetua para ejercer cargos públicos por constricción a la prostitución de menores y abuso de autoridad en el Proceso Ruby.

Pocas semanas después, el 1 de agosto de 2013, la Corte Suprema de Casación (corte de última instancia) lo condenó en forma definitiva a 4 años de prisión por fraude fiscal en el Proceso Mediaset. Tres de estos años están cancelados por un indulto del gobierno de Romano Prodi aprobado en Parlamento en el 2006, restando un solo año de pena. Por este deberá asistir a un centro de cuidado de ancianos de la localidad de Cesano Boscone una vez por semana durante cuatro horas durante un año. A pesar de no tener que cumplir arresto domiciliario, durante este tiempo Berlusconi tendrá limitaciones en su libertad ya que no podrá abandonar Lombardía aunque podrá viajar a Roma de martes a jueves debiendo regresar a la residencia de Arcore antes de las 23 horas del jueves. Esta condena fue acortada en 45 días por el Tribunal de Milán dando fin de esta forma la condena el 6 de marzo de 2015

El 8 de julio de 2015, el tribunal de Nápoles lo condenó a tres años de prisión por el delito de corrupción, tras haber sobornado al senador Sergio De Gregorio. Los pagos se realizaron entre 2006 y 2008, y consistieron en aproximadamente tres millones de euros.

La polémica ha marcado notablemente sus gobiernos. El revuelo levantado por la ley Alfano es un notable ejemplo. Esta ley establece que los cuatro mayores dirigentes del Estado, el presidente de la República, el primer ministro y los presidentes de la Cámara de Diputados y el Senado, no pueden ser juzgados por ningún delito no relacionado con su cargo mientras permanezcan en el gobierno. Asimismo, ha sido acusado en varias ocasiones de mantener tratos con la mafia calabres en la región de Ndràngheta.

Para el escritor Paul Ginsborg, autor del libro "Silvio Berlusconi; televisión, poder y patrimonio", la combinación de populismo antidemocrático y poder mediático de Berlusconi le convierte en una gran amenaza para la democracia. En el libro, que es una biografía que incluye sus primeras andanzas como empresario y playboy hasta la creación de su imperio empresarial "Mediaset" y el posterior ascenso a la presidencia del Consejo de Ministros de Italia, analiza las relaciones de carácter comercial, los intereses económicos y los procesos judiciales del presidente de Italia pero sin dejar de exponer la caracterización de la sociedad italiana que ha aupado y permitido el triunfo de una figura como la de Berlusconi.

En la noche del 13 de diciembre de 2009, Silvio Berlusconi fue atacado por Massimo Tartaglia, un "paciente psiquiátrico" de 42 años, a la salida de un mitin político en Milán, y resultó herido en el rostro. El primer ministro italiano fue agredido en la calle al terminar un acto de la coalición gobernante Pueblo de la Libertad (PdL), realizado en el marco de la campaña para las elecciones regionales de marzo. Cuando se detuvo a firmar autógrafos en la plaza de la catedral de la ciudad, recibió el impacto de una estatuilla de plástico y yeso en miniatura de la catedral de Milán, que lo golpeó en la boca y en el rostro, y le provocó heridas sangrantes en nariz y boca. El ministro de defensa italiano, Ignazio La Russa, quien se encontraba junto al premier cuando fue atacado, declaró que el agresor "parecía tener algo en la mano" y que fue "detenido inmediatamente".

La Russa explicó que la policía arrestó en seguida al agresor y lo sustrajo de un seguro linchamiento: "Si no hubiera estado la policía, del agresor solo habría quedado pedacitos". Berlusconi fue llevado al hospital San Raffaele donde permaneció internado en observación durante 24 horas. "Se veía al presidente conmocionado pero reaccionó con su temperamento habitual", declaró el director de comunicación del centro asistencial quien señaló que Berlusconi había sufrido "contusiones importantes en el rostro, con heridas interna y externa en el labio superior y dos dientes fracturados"; la radiografía de "Il Cavaliere" también mostró una pequeña fractura en la nariz. Tartaglia, el agresor, fue inculpado de "provocar lesiones con el agravante de premeditación" por haber atacado al premier con una réplica en miniatura del "Duomo di Milano", un "souvenir" con zócalo de metal que los turistas suelen comprar.

El día 12 de noviembre del 2011, Silvio Berlusconi presenta su dimisión al ser aprobada la Ley de Presupuestos de 2012 que incluía las reformas económicas exigidas por la Unión Europea. El primer ministro ya había adelantado que renunciaría tras ser aprobado este texto. Mientras tanto, asume provisionalmente la jefatura de Gobierno el senador vitalicio Mario Monti, quien fue nombrado de improviso por Giorgio Napolitano para institucionalizar su figura, blindarla y proyectarla hacia la jefatura del Gobierno.

En las elecciones generales de Italia de 2018, convocadas para el día 4 de marzo, Berlusconi se postuló como líder político de Forza Italia.




</doc>
<doc id="17661" url="https://es.wikipedia.org/wiki?curid=17661" title="Academia de la Lengua Asturiana">
Academia de la Lengua Asturiana

La Academia de la Lengua Asturiana (en asturiano: Academia de la Llingua Asturiana o ALLA) es una institución de Asturias cuyo fin es el estudio, la promoción y la defensa del asturiano.

Los orígenes de la A.Ll.A se remontan a finales del siglo XVIII, cuando Jovellanos y el canónigo González de Posada intercambian correspondencia sobre la misma en 1791. El proyecto de Jovellanos no pudo llevarse a cabo debido a su destierro en Mallorca. 

En los años 1920 se creó la Real Academia Asturiana de las Artes y las Letras, auspiciada por gente como Pin de Pría. Se dividía en cuatro secciones, y su principal objetivo era realizar un diccionario y una gramática asturianas y publicar una revista. El resto de secciones tenían como fin el promocionar la literatura, el teatro y la música asturianas.

En 1945, durante la primera etapa del franquismo, la Comisión Gestora de la Diputación acordó la creación de una institución académica, el Instituto de Estudios Asturianos, expresamente dedicada a la investigación y al estudio, a la edición de publicaciones, a la enseñanza y a la divulgación de la cultura asturiana.

Con la vuelta de la democracia a España el ente preautonómico, el Consejo Regional, aprueba la creación de otra academia, que se fundaría el 15 de diciembre de 1980. Sus fines son, como recogen los estatutos aprobados el 6 de abril de 1981, y modificados el 12 de abril de 1995, la investigación y normalización gramatical del asturiano y de sus diferentes variedades, inventariar su léxico, promover su difusión, regularizar su enseñanza, fomentar su uso como medio de expresión de los asturianos, promover concursos literarios, realizar estudios lingüísticos y velar por los derechos lingüísticos de los asturianos.

Xosé Lluis García Arias fue el presidente desde su fundación hasta el año 2001. Su sucesora en el cargo es Ana Cano. La Academia tiene 24 miembros de número, 20 miembros correspondientes y 16 académicos de honor.

En 1981 se publicó el primer trabajo normativo de la Academia, "Normes Ortográfiques y Conxugación de Verbos". Otras publicaciones a destacar son la "Gramática de la Llingua Asturiana" en 1998 y en 2000 el "Diccionariu de l'Academia de la Llingua Asturiana", también conocido por sus siglas «DALLA».

Publica periódicamente una revista titulada "Lletres Asturianes" (boletín oficial de la institución), así como libros y revistas relacionados con el estudio de la lengua, la literatura y la cultura asturiana: "Cultures. Revista de cultura asturiana" y "Lliteratura. Revista lliteraria asturiana". Entre sus colecciones de libros se encuentran: "Toponimia" (nóminas toponímicas orales), "Llibrería Llingüística" (estudios filológicos), "Preseos" (vocabularios), "Cartafueyos Normativos" (textos normativos de aplicación en el proceso de normalización social de la lengua asturiana), "Llibrería Académica" (creación literaria), "Escolín" (infantil), "Lliteratura Xuvenil", "Cuquiellu", "Mázcara" (teatro)...

También celebra todos los años el "Día de les Lletres Asturianes" (Día de las Letras Asturianas) desde 1982, así como unas sesiones internacionales de estudio ("Xornaes Internacionales d'Estudiu"), de carácter anual y el "Alcuentru "Llingua Minoritaria y Educación"" de carácter bianual.

Académicos de número

Académicos correspondientes

Académicos de honor



Académicos fallecidos


</doc>
<doc id="17666" url="https://es.wikipedia.org/wiki?curid=17666" title="Mundo">
Mundo

Mundo es el nombre común que atribuye o significa cuanto concierne al ser humano (a veces se enfatiza diciendo "nuestro mundo"), más específicamente la experiencia que lo circunda y en concreto aspectos más determinados que abarcan su vida y su civilización. Algo más abstractamente se considera mundo a la naturaleza o el universo físico, humano y social donde se sitúa el hombre y que constituye su entorno. Por otra parte y de forma más reciente, con "mundo" se alude también al planeta Tierra, entendiendo por tanto como "otros mundos" el resto de planetas o astros presentes en el universo.

El mundo constituye, en su forma conocida o "mundo conocido", la materia, el espacio y los fenómenos que nos son accesibles por los sentidos, la experiencia o la razón. El sentido más corriente designa nuestro planeta, la Tierra, con sus habitantes y su entorno más o menos natural. En sentido lato o extenso designa el universo en su conjunto. Las representaciones históricas en general lo reflejan geográficamente con una clase de mapa, el llamado planisferio terrestre o mapamundi.

En el contexto filosófico, y más precisamente ontológico, es un concepto abstracto y posee el significado absoluto que le da la reducción fenomenológica: todo lo que no es parte del "yo", todo lo que no es el hombre. Y por otra parte, en modo más concreto, sería la realidad como experiencia, la realidad empírica y objetiva.

El término latino "mundus" 'ordenado, limpio' se empleó para traducir el término griego κόσμος "kósmos" '[buen] orden, arreglo, ajuste, compostura, perfección'. Estos términos reflejan la noción prefilosófica de que el mundo en sentido filosófico constituía una construcción intencionada bien organizada. Por eso en la noción grecolatina existían dioses y entes encargados del mantenimiento de la estructura y buen orden del mundo.

En filosofía, el término "mundo" posee varios posibles significados. En algunos contextos, se refiere a todo lo que conforma la realidad o el universo físico. En otros, puede tener un específico significado ontológico. Mientras que clarificar el concepto de mundo ha estado siempre entre las tareas básicas de la filosofía occidental, este tema parece haber surgido explícitamente solamente al inicio del siglo XX y ha sido objeto de continuos debates. La cuestión sobre lo que es el mundo aún no ha sido resuelta.

Para Francisco Miró Quesada hay tres ejes para clasificar las distintas concepciones filosóficas del mundo: el eje materialista-espiritualista, el eje finalista-contingencialista y el eje esencialista-existencialista. Por ejemplo, Marx veía al mundo de una forma «materialista finalista» (materialismo dialéctico) mientras que las religiones ven al mundo desde una óptica «espiritualista finalista» (escatología y el fin del mundo) ya sea en su vertiente esencialista (Santo Tomás) o existencialista (Gabriel Marcel). El mecanicismo ve al mundo de una forma «materialista contingencialista», es decir, en el universo no hay razón o finalidad específica para el cual las leyes de la naturaleza sean de una manera, pues pudieran haber sido de otra.

Parménides argumenta que la percepción diaria de la realidad del mundo físico tal y como es descrito en la "doxa", esto es, en la opinión común, está errada, y la realidad del mundo es "ser" como es descrito en "alétheia": un todo inalterable, inengendrable e indestructible.

En su mito de la caverna, Platón distingue entre formas variables e ideas inmutables e imagina dos mundos distintos: el mundo sensible y el mundo tangible.

En la filosofía de la historia de Hegel, la expresión "Weltgeschichte ist Weltgericht" (La Historia Mundial es un tribunal que juzga al Mundo) es utilizada para afirmar el punto de vista de que la Historia juzgará a los hombres, sus acciones y sus opiniones. La ciencia nació del deseo de transformar al mundo en relación al hombre; su meta final es la aplicación técnica.

"El mundo como voluntad y representación" es el trabajo central de Arthur Schopenhauer.
Schopenhauer vio la voluntad humana como el noúmeno o "cosa en sí" kantiana. Él creyó, entonces, que podríamos obtener conocimiento acerca de la cosa en sí, algo que Kant dijo era imposible, ya que el resto de la relación entre la representación y cosa en sí podía ser entendida por la analogía a la relación entre la voluntad humana y el cuerpo humano.

"El mundo es todo lo que acaece" o, en otras traducciones, "es el caso", escribió Ludwig Wittgenstein en su influyente "Tractatus Logico-Philosophicus", publicado por primera vez en 1922. Esta definición serviría como la base del empirismo lógico, que se la suposición de que hay exactamente un mundo, consistente en la totalidad de los hechos, sin importar la interpretación que cada individuo haga de ellos.

Martin Heidegger, entre tanto, argumentaba que "el mundo circundante es diferente para cada uno de nosotros y, sin embargo, nos movemos en un mundo común". El mundo, para Heidegger, era aquel en el que siempre éramos "lanzados" y con el que nosotros, como seres en el mundo, debemos llegar a acuerdos. Su concepción de "divulgación mundial" fue elaborada más notablemente en su trabajo de 1927 "Ser y Tiempo".

En respuesta, Sigmund Freud propuso que no nos movemos en un mundo común, sino en un proceso de pensamiento común. Él creía que todas las acciones de una persona estaban motivadas por una sola cosa: la libido. Esta fuerza condiciona toda nuestra visión del mundo o de la realidad, que es fruto del pulso entre tendencias instintivas inconscientes y tendencias represoras superconscientes.

Algunos filósofos, a menudo inspirados por David Lewis, argumentan que los conceptos metafísicos como la posibilidad, la probabilidad y la necesidad son mejor analizados al comparar "el" mundo a un rango de mundos posibles; un punto de vista comúnmente conocido como realismo modal. Para él existe un número infinito de mundos causalmente aislados y el nuestro es tan sólo uno de ellos.


Para el filósofo Markus Gabriel el mundo no existe pues lo considera un superobjeto. La existencia de un objeto, por definición, se trata de su aparición con características propias que lo distinga de otros objetos en un contexto dado. No así ocurre con el concepto de superobjeto o mundo pues este tendría toda las características de todos los objetos que contiene haciéndolo indistinguible y, por lo tanto, inexistente. Markus, al proclamar que no existe un superobjeto o Mundo, termina adoptando una postura filosófica pluralista.


Para el filósofo español José Ortega y Gasset el mundo es inseparable del yo: "Yo soy yo y mi circunstancia, y si no la salvo a ella no me salvo yo". Y todas las conciencias están interconectadas a través de un sistema de perspectivas cuya integración constituye el mundo, la realidad misma.

El "mundo" es para el "Catecismo" de la Iglesia católica uno de los tres "enemigos del alma": mundo, demonio y carne. Esta conceptualización negativa del mundo constrasta con el concepto grecolatino positivo de "mundus" 'todo ordenado, organizado, limpio'. Para la concepción teológica judeocristiana el mundo representa lo "material" o la esfera de la "vida profana", como lo opuesto a lo celestial, espiritual, trascendental o sacro. Así, los monjes y monjas de clausura que se encierran en los monasterios renuncian al "mundo". El "fin del mundo" se refiere a los escenarios de la culminación de la historia humana, a menudo en contextos religiosos.

El mundo ha sido representado de muy distintas maneras según las civilizaciones y culturas; muchas de esas representaciones han ido cambiando o no conforme cambiaban o no dichas civilizaciones y culturas. En el ámbito occidental (y más en concreto según la concepción cristiana derivada del "Almagesto" del cosmógrafo pagano Claudio Ptolomeo), el mundo se dividía en dos partes: lo natural o naturaleza, imperfecto y mutable y situado por debajo de la órbita lunar, y lo sobre-natural, perfecto e inmutable y situado por encima de la órbita de la Luna. El renacimiento del siglo XVI empezó a dudar y a criticar esta visión geocéntrica y cristiana y la fue sustituyendo por otra heliocéntrica y mecanicista. 

La "historia del mundo" es comúnmente entendida como la comprensión de los principales desarrollos geopolíticos de cinco milenios, desde la invención de la escritura por las primeras civilizaciones hasta el presente. Por otra parte, con la expresión "Nuevo Mundo" frente a "Viejo Mundo" nos referimos respectivamente por un lado a América, una parte del mundo colonizada en el despertar de la era de los descubrimientos, y por otro a la parte colonizadora, de historia más conocida. Estas denominaciones se extendieron al ámbito de las clasificaciones zoológicas y botánicas, como por ejemplo en el caso del mono del Nuevo Mundo.

En política, los términos "primer", "segundo" y "tercer mundo" dividen a los países en grandes grupos. El primer mundo designa a los países capitalistas, ricos o desarrollados económicamente; el segundo a los comunistas y el tercer mundo agrupa al resto de los países, la mayoría pobres, en vías de desarrollo o infradesarrollados. Incluso de se utiliza la expresión "cuarto mundo" para aludir a los países en que la pobreza es extrema.

La población mundial es la suma de todos los habitantes humanos de cualquier era; de igual forma, la economía mundial es la suma de las economías de todas las sociedades (todos los países), especialmente en el contexto de la globalización. Términos como campeonato mundial, producto bruto mundial, banderas del mundo, etc., también implican la suma o combinación de todos los estados soberanos.

En términos como , idioma mundial y guerra mundial, la palabra "mundo" sugiere una escala internacional o intercontinental sin necesariamente implicar la participación de todo el mundo.

En términos como mapa del mundo y clima mundial, la palabra "mundo" es utilizada en un sentido desprendido de la cultura humana o civilización, refiriéndose de forma física al planeta Tierra.

El término «mundo» deriva del vocablo en latín "mundus", que literalmente significa 'limpio, elegante'; en sí es una traducción prestada del griego "cosmos", 'perfección' o 'conjunto ordenado'. El término greco-latino expresa una noción de creación como un acto de establecimiento del orden en el caos.

'Mundo' se refiere a todo el planeta o a la población de cualquier país o región en particular: "asuntos mundiales" se refiere no solo a un lugar sino a todo el mundo e "historia mundial" es un campo de la historia que examina los eventos desde una perspectiva global (en lugar de una nacional o una regional). "Tierra", por otra parte, se refiere al planeta como una entidad física y la distingue de otros planetas y objetos físicos.

<nowiki>'</nowiki>"Mundo"<nowiki>'</nowiki> también puede atribuírsele al significado de 'global', 'relativo a todo el mundo', formando usos como "Comunidad mundial".

Por extensión, un <nowiki>'</nowiki>"mundo"<nowiki>'</nowiki> puede referirse a cualquier planeta u objeto astronómico, especialmente cuando se cree que está habitado, en el contexto de la ciencia ficción o futurología.

<nowiki>'</nowiki>"Mundo"<nowiki>'</nowiki>, en el sentido original, cuando es calificado, también puede referirse al dominio particular de la experiencia humana.


Según el "World Fact Book (2007)":

La tasa de fertilidad (cifras de fertilidad femenina, o cantidad de hijos por mujer) era 2,8 en el año 2000 y 2,59 en 2007. La tasa de mortalidad infantil es 56,11 muertes por cada 1 000 nacimientos. El crecimiento demográfico mundial total es de 1,45 % en promedio anual.

La tasa de desempleo Mundial es el 38 %.

En 2008, se estima que la población mundial fue de habitantes. La densidad poblacional es 48 habitantes por km²

El 50 % de la población humana vive en zonas apropiadas, que corresponde sólo al 5 % de la superficie terrestre.

El IDH (Índice de Desarrollo Humano) en el Mundo es 0,624.

El Producto Mundial Bruto (GWP) es de 48 144 966 millones de dólares según el Fondo Monetario Internacional y 44 784 871 según el Banco Mundial, el promedio es de 46 264 669 millones de dólares y 6 975 dólares por cápita.

La tasa de crecimiento económico del Producto Doméstico promedio Mundial, es el 5,1 % por año.

La esperanza de vida promedio es 65,82 años, 63,89 años para hombres y 67,84 años para mujeres. Según la Organización Mundial de Salud, las 10 causas principales de muerte en 2002 son:

Antiguamente se consideraba primer mundo aquellos países de economías capitalistas como Estados Unidos y los países aliados a éste después de la segunda guerra mundial. El segundo mundo incluía países comunistas, como la antigua URSS o China, y a todos los países aliados a éstos o bajo su influencia, mientras que, el tercer mundo, abarcaba aquellos países que tenían una posición neutra.

En la actualidad se consideran países del Primer Mundo los países desarrollados, es decir que tienen gran capacidad industrial, gran avance tecnológico y tienen fácil acceso a gran cantidad de materias primas. Se consideran países del Segundo Mundo a los países que también tienen gran capacidad industrial y un gran avance tecnológico, pero tienen un menor acceso a las materias primas que los países del Primer Mundo. Se consideran países del Tercer Mundo a los países que tienen gran cantidad de materias primas, pero no cuentan con gran capacidad industrial ni gran avance tecnológico y que están vinculados al mercado mundial mediante la exportación de materias primas. Se ha adoptado el término "Cuarto mundo" para referirse a las regiones pobres del planeta pertenecientes al sector capitalista y a los países menos desarrollados de éste, como los sin techo que viven en las ciudades más ricas de los países capitalistas, cuyo nivel de pobreza supera al de los habitantes del tercer mundo.

Las cosmologías mitológicas a menudo representan al mundo como centrado alrededor de un axis mundi y delimitado por una frontera como un océano, una serpiente o similares.


</doc>
<doc id="17675" url="https://es.wikipedia.org/wiki?curid=17675" title="Claire Forlani">
Claire Forlani

Claire Antonia Forlani (Middlesex, Londres;, 1 de julio de 1971) es una actriz inglesa de cine y televisión.

Forlani nació en Twickenham en Londres, Inglaterra, hija de Barbara Dickinson, de origen inglés, y de Pier Forlani, un mánager de música proveniente de Ferrara, Italia. A los once años Forlani ingresó en el Arts Educational School de Londres, donde comenzó a preparar su futura carrera de actriz.

En los seis años en que permaneció en dicha academia, estudió danza además de interpretación, lo cual le abrió las puertas para interpretar más tarde obras como "The Nutcracker" y "Orpheus in the Underworld". Habiendo actuado en el teatro, la televisión británica la contrató para una serie televisiva y para una película de televisión.

Los padres de Forlani quisieron ayudar a su hija a obtener papeles en películas de cine, por lo que decidieron en 1993 trasladarse a San Francisco. Pronto llegó la primera oferta de la industria cinematográfica norteamericana: fue seleccionada en ese mismo año para la miniserie de televisión "J. F. K.: Reckless Youth" y seguidamente para la película de cine "Police Academy: Mission to Moscow".

A continuación Forlani intervino en algunas películas, hasta que en 1996 participó en "La roca", protagonizada por Sean Connery y Nicolas Cage. Un año más tarde obtuvo al fin el reconocimiento de la crítica por su interpretación en "The Last Time I Committed Suicide", después de haber actuado en películas que en su mayoría habían sido intrascendentes.

Por su papel en "¿Conoces a Joe Black?", en la que fue coprotagonista junto a Brad Pitt y Anthony Hopkins, adquirió en 1998 una amplia fama entre el público estadounidense e internacional.

Sus últimos papeles han sido en la serie "", como la Dr. Peyton Driscoll, y más recientemente en la primera temporada de la serie "Camelot" interpretando a la madre del Rey Arturo, Lady Igraine.

Forlani estuvo relacionada amorosamente con los actores Benicio del Toro, John Cusack (entre 1997 y 1998), y Ben Stiller, Brad Pitt (entre 1998 y 1999). En junio de 2007, Forlani contrajo matrimonio con el actor Dougray Scott.Ellos tienen un hijo, Milo Thomas Scott, nacido el 27 de diciembre de 2014.



</doc>
<doc id="17677" url="https://es.wikipedia.org/wiki?curid=17677" title="René Favaloro">
René Favaloro

René Gerónimo Favaloro (La Plata, 12 de julio de 1923 - Buenos Aires, 29 de julio de 2000) fue un educador y cardiocirujano argentino, reconocido mundialmente por ser quien desarrolló el bypass coronario con empleo de vena safena. El primer bypass fue realizado en arterias del cuello por el neurocirujano Argentino Alfredo Carrea en 1951, en Buenos Aires.

Estudió medicina en la Universidad Nacional de La Plata y una vez recibido, previo paso por el Hospital Policlínico, se mudó a la localidad de Jacinto Aráuz para reemplazar temporalmente al médico local, quien tenía problemas de salud.
A su vez, leía bibliografía médica actualizada y empezó a tener interés en la cirugía torácica. A fines de la década de 1960 comenzó a estudiar una técnica para utilizar la vena safena en la cirugía coronaria. En 1971, regresó a Argentina a operar al sanatorio privado Güemes de la mano de su amigo el cardiólogo intervencionista Luis de la Fuente quien se lo propuso y lo convenció. A principios de la década de 1970 fundó la fundación que lleva su nombre a instancias del doctor De la Fuente.

Fue miembro de la Conadep (Comisión Nacional por la Desaparición de Personas), condujo programas de televisión dedicados a la medicina y escribió libros. Durante la crisis del 2000, el PAMI tenía una gran deuda económica con su fundación, sostenida deliberadamente por un sistema corrupto, lo que lo indujo a suicidarse. El 29 de julio de 2000, después de escribir una carta al presidente De la Rúa criticando al sistema de salud, se quitó la vida de un disparo al corazón.

René Favaloro nació y se crio en la ciudad de La Plata (capital de la provincia de Buenos Aires) junto a sus padres Juan Manuel Favaloro ―carpintero― e Ida Raffaelli de Favaloro ―modista―. Siempre estuvo comprometido con el conocimiento, gracias en parte a su abuela materna, quien le transmitió su amor por la naturaleza y la emoción al ver cuando las semillas comenzaban a dar sus frutos. A ella le dedicaría su tesis del doctorado: «A mi abuela Cesárea, que me enseñó a ver belleza hasta en una pobre rama seca».

Realizó la primaria en la escuela n.º 45, en esta escuela se levantó un mural en su memoria.
En 1934 comenzó sus estudios secundarios en el Colegio Nacional Rafael Hernández; finalizada esta etapa, ingresó en la Facultad de Ciencias Médicas de la Universidad Nacional de La Plata. En el tercer año comenzó las prácticas en el Hospital Policlínico y empezó a tomar contacto por primera vez con los pacientes. Excediendo lo exigido por el programa, volvía por las tardes para controlar la evolución de los pacientes y dialogar con ellos.

Asimismo observaba a los alumnos de sexto año de Rodolfo Rossi o Egidio Mazzei, profesores titulares de Clínica Médica, y, además, presenciaba las cirugías de José María Mainetti y Federico E. B. Christmann, quien le enseñó las técnicas de simplificación y estandarización que aplicó después en la cirugía cardiovascular, su contribución a las operaciones del corazón y las grandes arterias.
Su preparación profesional la realizó en el Hospital Policlínico donde se recibían los casos complicados de toda la provincia de Buenos Aires. Vivió en el hospital durante los dos años de residencia. Se graduó en 1949 e inmediatamente se produjo una vacante para médico auxiliar, puesto al que accedió en forma interina.
Al poco tiempo su hermano, Juan José, médico también, empezó a trabajar en la clínica con él, integrándose muy pronto a la comunidad por sus condiciones humanas. Durante los años que ambos permanecieron en la localidad de Jacinto Aráuz fundaron un centro asistencial.
Desapareció la mortalidad infantil de la zona, se redujo la cantidad de infecciones en los partos y la desnutrición, crearon un banco de sangre de personas vivas con donantes que se presentaban cada vez que los necesitaban y realizaron charlas comunitarias en las que enseñaban métodos para prevenir enfermedades.

Favaloro se actualizaba con publicaciones médicas y realizaba cursos de capacitación en La Plata. Se interesó por las intervenciones cardiovasculares, que en ese tiempo se estaban empezando a desarrollar, y por la cirugía torácica. Empezó a ver la forma de terminar su etapa de médico rural y capacitarse en Estados Unidos, los profesores José María Mainetti y Alfonso Roque Albanese le aconsejaron la Cleveland Clinic. En 1962 se radicó en Cleveland y se desempeñó primero como residente y luego en el equipo de cirugía en colaboración con médicos locales, concentrando su trabajo en enfermedades valvulares y congénitas. Posteriormente se interesó en otros temas, como las cineangiocoronariografías y al estudio de la anatomía de las arterias coronarias y su relación con el músculo cardíaco.

A comienzos de 1967, Favaloro estudió la posibilidad de utilizar la vena safena en la cirugía coronaria, haciendo prácticas con sus ideas en mayo de ese año. La estandarización de esta técnica, llamada del baipás o cirugía de revascularización miocárdica, fue el principal trabajo de su carrera, lo que le dio prestigio internacional, ya que el procedimiento cambió radicalmente la historia de la enfermedad coronaria. En 1970 editó un libro llamado "Surgical treatment on coronary arteriosclerosis", que fue también editado en español con el nombre "Tratamiento quirúrgico de la arteriosclerosis coronaria".

En 1971 Favaloro regresó a la Argentina, para operar en el Sanatorio Güemes de la Capital Federal, que era liderado por Mauricio Barón como presidente de la institución y por el doctor Luis de la Fuente, en cardiología como experto en cardiología clínica y en la incipiente cardiología invasiva. Anteriormente, Favaloro había sido alentado por De la Fuente ―desde 1968― a operar a un paciente ciego que no podía viajar a Estados Unidos.

El doctor Luis de la Fuente era clave por su formación de excelencia en Estados Unidos y fue fundamental para Favaloro ya que hacía los diagnósticos clínicos y los cateterismos coronarios. Favaloro no operaba si De la Fuente no hacía los diagnósticos y los cateterismos. Así lo confirmó el futbolista Silvio Marzolini al diario "Ámbito Financiero". Posteriormente fue De la Fuente pionero internacional de la angioplastia con "stent" y medicamento ―Buenos Aires, 1999―, de la neoarteria, el seno coronario y las células madre; todos avances impulsados por De la Fuente y con el sueño de Favaloro de desarrollar un centro de excelencia similar al de la Cleveland Clinic, que combinara la atención médica, la investigación y la educación.

En 1975, Favaloro fundó con ese propósito junto a otros colaboradores la Fundación Favaloro, que lleva su apellido a instancias del cardiólogo Luis de la Fuente, quien lo convenció en nominarla así en 1974, que además es un centro de capacitación donde estudian alumnos de diferentes partes del mundo y donde cada dos años se celebra el congreso "Cardiología para el Consultante". En 1980 Favaloro creó el Laboratorio de Investigación Básica, manteniéndolo con dinero propio por un largo tiempo, dependiente del Departamento de Investigación y Docencia de la Fundación Favaloro. Con posterioridad, pasó a ser el Instituto de Investigación en Ciencias Básicas del Instituto Universitario de Ciencias Biomédicas. Esta fue la base de la creación, en agosto de 1998, de la Universidad Favaloro.

En 1984 era una de las personalidades que nombró el presidente Raul Alfonsín para integrar la Conadep (Comisión Nacional por la Desaparición de Personas) y renunció a ella. Sobre los motivos de la renuncia hay distintas versiones: Graciela Fernández Meijide dice que Favaloro envió una carta aduciendo razones anímicas y laborales, al mismo tiempo que remitía una carta de renuncia a Alfonsín en la que se mostraba molesto y decepcionado porque había recibido a Isabel Perón; entre los miembros de la CONADEP la impresión era que había renunciado por la relación que mantenía con algunos militares que desde 1976 habían obtenido aportes monetarios importantes para su Fundación. Otra versión es que renunció por profundas diferencias ideológicas: Favaloro consideraba que hubo delitos cometidos tanto por el Estado Nacional de esos años y las organizaciones subversivas que operaban desde la clandestinidad. Héctor D'Amico afirma que renunció al ser informado de que la Comisión no tenía atribuciones para investigar a grupos terroristas cercanos al gobierno de Isabel Perón, como la Triple A. Favaloro había sugerido que el laboratorio de los doctores Emilio Haas y Luis Verruno era ideal para hacer los análisis de en el país. Pero las Abuelas de Plaza de Mayo no aceptaron la recomendación de Favaloro argumentando que Verruno trabajaba en el Hospital Militar dentro del cual había funcionado un centro clandestino de detención durante la dictadura. Abuelas de Plaza de Mayo atribuye su renuncia a ese episodio.

En 1992 se inauguró en Buenos Aires el Instituto de Cardiología y Cirugía Cardiovascular de la Fundación Favaloro, entidad sin fines de lucro. Con el lema «tecnología de avanzada al servicio del humanismo médico» se brindan servicios altamente especializados en cardiología, cirugía cardiovascular y trasplante cardíaco, pulmonar, cardiopulmonar, hepático, renal y de médula ósea, además de otras áreas. Favaloro concentró allí su tarea, rodeado de un grupo selecto de profesionales dejando al Sanatorio Güemes.

Hacia el año 2000, la Argentina ya estaba sumergida en una crisis económica y política. La Fundación Favaloro se encontraba en una difícil situación, endeudada en unos 18 millones de dólares estadounidenses, por lo que Favaloro pidió ayuda al Gobierno argentino, sin recibir una respuesta oficial.

El 29 de julio del año 2000 ―el mismo día del cumpleaños de su amigo y cardiólogo Luis de la Fuente (1932-), quien lo había convencido de volver a la Argentina―, Favaloro se encerró en el baño de su casa y se disparó un tiro en el corazón.

Tras el desenlace fatal, se conoció que Favaloro había dejado en su departamento siete cartas cuyo contenido se reveló parcialmente. En una de ellas, dirigida a las «autoridades competentes», dejaba en claro que había decidido quitarse la vida, y explicaba que la crisis económica que atravesaba la Fundación Favaloro había sido el desencadenante de su determinación, expresando que la sociedad argentina necesitaba de su muerte para tomar conciencia de los problemas en los que estaba envuelta. Favaloro expresaba su cansancio de «ser un mendigo en su propio país», luego de los reclamos enviados al entonces presidente de la Nación Fernando de la Rúa, en los cuales solicitaba entre otras cuestiones el pago de las deudas millonarias que mantenían con su fundación varias obras sociales, siendo la más abultada la contraída por PAMI.

René Favaloro publicó más de trescientos trabajos de su especialidad. Debido a su pasión por la historia llegó a escribir dos libros de investigación y divulgación sobre el general José de San Martín. Es autor también de la autobiografía "De la pampa a los Estados Unidos" (la versión en inglés, titulada "The Challenging Dream of Heart Surgery" fue publicada en Boston [Estados Unidos] por Little, Brown and Company en 1994), en el cual recuerda sus diez años de trabajo en equipo con eminentes personalidades de la medicina durante su estancia en la Cleveland Clinic. Este se publicó por primera vez en 1992, llegando a alcanzar la octava edición en 1996 a través de la Editorial Sudamericana. Además, su autobiografía denominada "Recuerdos de un médico rural" tiene varias ediciones, la primera de ellas editada en el año 1980. Finalmente su último libro, "Don Pedro y la educación", se publicó en Buenos Aires por el Centro Editor de la Fundación Favaloro en 1994.

Favaloro participó en varias sociedades, fue miembro activo en veintiséis, miembro correspondiente en cuatro y honorario de otras cuarenta y tres. 

Recibió diversos premios a lo largo de su carrera, entre los que se encuentran el premio John Scott de 1979, otorgado por la ciudad de Filadelfia (Estados Unidos); la creación de la Cátedra de Cirugía Cardiovascular «Dr René G. Favaloro» (Universidad de Tel Aviv, en Israel, 1980); la distinción de la Fundación Conchita Rábago de Giménez Díaz (Madrid, España, 1982); el premio Maestro de la Medicina Argentina (1986); el premio Distinguished Alumnus Award de la Cleveland Clinic Foundation (1987); The Gairdner Foundation International Award, otorgado por la Gairdner Foundation (Toronto, Canadá, 1987); el premio René Leriche de 1989, otorgado por la Sociedad Internacional de Cirugía; el Gifted Teacher Award, otorgado por el Colegio Americano de Cardiología (1992); el Golden Plate Award de la American Academy of Achievement (1993); el Premio Konex de Brillante a las Ciencias y Tecnologías otorgado por la Fundación Konex en 1993, Doctor Honoris Causa por parte de la Facultad de Ciencias de la Salud de la Universidad Nacional Pedro Henríquez Ureña (UNPHU) en 1993 y el Premio Príncipe Mahidol, otorgado por Su Majestad el Rey de Tailandia (Bangkok, Tailandia, 1999). En el Colegio Argentino de Cirujanos Cardiovasculares con sede en la ciudad de Buenos Aires, hay dos aulas: una lleva el nombre de René Favaloro y la otra del Dr. Alfonso Roque Albanese, ambos pioneros de la cirugía cardiovascular.

La última distinción otorgada fue posmórtem, en el año 2010, oportunidad en la cual la Fundación Internacional de Jóvenes Líderes lo considerara «Referente de la Humanidad».

Participó en televisión en programas educativos para la población, entre los que se destacaba la serie televisiva "Los grandes temas médicos", y presentó numerosas conferencias en la Argentina y en el exterior, sobre temas muy diversos como medicina, educación y la sociedad de nuestros días. En octubre de 2007 fue electo como finalista en el programa de televisión "El Gen Argentino", en el cual resultó electo como el personaje argentino que mejor representa la idiosincrasia del país y su gente.
El grupo argentino de punk rock Attaque 77 le dedicó la canción y el videoclip «Western» del álbum "Antihumano" del año 2003. Fue el primer corte de difusión del disco y se trataba de un homenaje a René Favaloro. También la banda argentina Bersuit Vergarabat hizo mención a su suicidio en el tema "La argentinidad al palo", del disco del mismo nombre.

El celebrado folclorista argentino Eduardo Falú también ha homenajeado a Favaloro con un bailecito de su autoría «El agradecido».





</doc>
<doc id="17696" url="https://es.wikipedia.org/wiki?curid=17696" title="Björk (álbum)">
Björk (álbum)

Björk fue un álbum lanzado en octubre de 1977 por la cantante y compositora islandesa Björk. Este es su primer álbum solista y lo hizo a los diez años con la ayuda de su padrastro Sævar quien era un guitarrista.

La lista de temas es un compendio de versiones de artistas célebres, canciones especialmente escritas para ella y una obra instrumental compuesta por Björk interpretada con flauta por ella misma.

El álbum llegó a ser muy popular en Islandia, alcanzando el disco de platino, y recibió gracias a él varias ofertas de discográficas; aunque Björk decidió rechazarlas. Nunca llegó a publicarse en formato CD y actualmente es un disco considerado de culto por comerciales y coleccionistas.

El padrasto de Björk tenía un local de ensayo par su banda Pops; un día Björk pasa por allí y esto la anima a participar en una fiesta en el colegio cantando "I Love To Love" éxito de Tina Charles en esa época. Poco después interpreta el mismo tema en la radio islandesa Radio 1, haciendo que el sello "Skifan" invitara a Björk a grabar un disco. Los padres, después de consultarlo con su amigo Jakob Magnússon, miembro del grupo Studmenn deciden finalmente firmar un contrato con Fálkinn Records.

La grabación del disco fue apadrinada por su padrasto Saevar con apoyo del guitarrista Björgvin Gílason, también participarían; el bajista Pálmi Gunnarson y el batería Sigurdur Karlsson. La madre de Björk diseñó la portada mostrando a una Björk «arabesca» sentada en una habitación que recuerda a "Las mil y una noches".

10 canciones formaban parte de "Björk" las cuales eran una mezcla de covers traducidos al islandés como la canción de the Beatles “Fool On The Hill” (“Alfur Út Úr Hól”), "Alta Mira" - de Edgar Winter -, "Christopher Robin" - de Melanie -, y la canción de Stevie Wonder “Your Kiss Is Sweet” - éxito en la voz de Syreeta - pero también tenía algunas canciones escritas especialmente para el álbum como “Arabadrengurinn” (“El Chico Árabe”) escrita por el padrastro Sævar, y un tributo de flauta para el famoso pintor islandés Jóhannes Kjarval escrita e interpretada por Björk que para ese entonces sólo tenía 11 años en 1976.

El álbum fue muy popular en Islandia, algo que no había sucedido antes, y obtuvo inmediatamente el disco de platino, alcanzando las 7 mil copias vendidas - Islandia 250 mil habitantes en la época. Gracias a las repercusiones Björk recibió ofertas para grabar con otras discográficas pero las rechazó a todas y se apartó del mundo de la fama, dedicándose a vivir una vida normal y a escribir canciones propias para después unirse a otras bandas e interesarse en el punk.

Grabado en Hlíðrijinn Studios en Reikiavik este álbum sólo se vendió en el mercado islandés y nunca apareció en formato CD, ya que fue lanzado en formato Long Play por la discográfica Fálkinn. Actualmente es un álbum codiciado por comerciantes y coleccionistas por lo que se cotiza en valores que van desde los US$ 100 hasta los US$ 700.



</doc>
<doc id="17705" url="https://es.wikipedia.org/wiki?curid=17705" title="Grupo sanguíneo">
Grupo sanguíneo

Un grupo sanguíneo es una clasificación de la sangre de acuerdo con las características presentes en la superficie de los glóbulos rojos y en el suero de la sangre.
Las dos clasificaciones más importantes para describir grupos sanguíneos en humanos son los antígenos (el sistema AB0) y el factor Rh.

El sistema ABO fue descubierto por Karl Landsteiner en 1901, convirtiéndolo en el primer sistema de grupo sanguíneo conocido; su nombre proviene de los tres tipos de grupos que se identifican: los de antígeno A, de antígeno B, y 0 sin antígenos.
Las transfusiones de sangre entre grupos incompatibles pueden provocar una reacción inmunológica que puede desembocar en hemólisis, anemia, fallo renal, choque circulatorio y muerte. 

El científico austriaco Karl Landsteiner recibió el en 1930 por sus trabajos en la caracterización de los tipos sanguíneos ABO. Aparte de los grupos mayoritarios, hay otros 32 muchísimo más escasos.

Cada individuo posee un conjunto diferente de antígenos eritrocitarios, y por su número ―existen al día de hoy 32 sistemas antigénicos conocidos, más algunos antígenos diferenciados que aún no han sido atribuidos a ningún sistema específico― es difícil encontrar dos individuos con la misma composición antigénica. De ahí la posibilidad de la presencia, en el suero, de anticuerpos específicos (dirigidos contra los antígenos que cada individuo no posee), lo que resulta en aglutinación o hemólisis cuando ocurre una transfusión incompatible. Diferentes sistemas antigénicos se caracterizan por inducir a la formación de anticuerpos en intensidades diferentes; por lo que algunos son más comunes y otros, más raros.

Los sistemas antigénicos considerados más importantes son el sistema ABO y el sistema Rh. Estos son los sistemas comúnmente relacionados a las temidas reacciones de transfusiones hemolíticas. Reacciones contra antígenos eritrocitarios también pueden causar la enfermedad hemolítica del recién nacido, causada por el factor Rh+ del padre y del bebé y el Rh– de la madre (DHRN) cuya causa generalmente se asocia a diferencias antigénicas relacionadas al sistema Rh.

La determinación de los grupos sanguíneos tiene importancia en varias ciencias:


Esta clasificación internacional, debida a Landsteiner, ha reemplazado a la de Moss, en la cual el grupo 1 corresponde al grupo AB de la precedente, el grupo 2 al grupo A, el grupo 3 al grupo B, y el grupo 4 al grupo 0. Estos cuatro grupos sanguíneos constituyen el sistema AB0.

A causa de estas combinaciones, el tipo 0 puede transfundir a cualquier persona con cualquier tipo y el tipo AB puede recibir de cualquier tipo AB0.

La denominación «O» y/o «cero» es confusa, y ambas están muy extendidas. El austriaco Karl Landsteiner designó los grupos sanguíneos a principios del siglo XX.

Algunas fuentes indican que O podría deberse a la preposición "ohne", que es ‘sin’ en alemán (sin antígeno). Sin embargo allí se dice "Null Blutgruppe", y casi nunca la alternativa "O Blutgruppe". En alemán «O» se dice /o/ y 0 (cero) se dice "Null". En inglés «O» se lee /ou/ y a veces el cero también se lee /ou/ (por ejemplo en un número de teléfono, o en una fecha). Sistema ABO y "O blood-group" es de uso mayoritario en inglés. Otros idiomas de Europa mantienen la designación «null», en sus variantes "zero", "cero", "nula", etc. En Centroamérica y el Caribe es más común «O positivo», evitando la similitud «cero positivo» con el término «seropositivo» ―se llama seropositivo al individuo que presenta en sangre anticuerpos que, cuando se le somete a la prueba diagnóstica apropiada, prueban la presencia de un determinado agente infeccioso― que mucha gente relaciona con el retrovirus VIH, causante del sida (síndrome de inmunodeficiencia adquirida).

Son controlados por un solo gen con tres alelos: 0 (sin, por no poseer los antígenos del grupo A ni del grupo B), A, y B.

El alelo A da tipos A, el B tipos B y el alelo 0 tipos 0, siendo A y B alelos dominantes sobre 0. Así, las personas que heredan dos alelos 00 tienen tipo O; AA o A0 dan lugar a tipos A; y BB o B0 dan lugar a tipos B. Las personas AB tienen ambos genotipos debido a que la relación entre los alelos A y B es de codominancia. Por tanto, es imposible para un progenitor AB el tener un hijo con tipo 0, a excepción de que se de un fenómeno poco común conocido como el 'fenotipo Bombay' o diversas formas de mutación genética relativamente extrañas.

Los alelos A y B son dominantes sobre el alelo 0, lo que se llama codominancia.

El sistema Rh es el segundo sistema de grupos sanguíneos en la transfusión de sangre humana con 50 antígenos actualmente. En 1940, el Dr. Landsteiner descubrió otro grupo de antígenos que se denominaron factores Rhesus (factores Rh), porque fueron descubiertos durante unos experimentos con monos Rhesus (Macaca mulatta). Las personas con factores Rhesus en su sangre se clasifican como ""Rh positivas"", mientras que aquellas sin los factores se clasifican como ""Rh negativas"". Es común para los individuos D-negativos no tener ningún anticuerpo anti-D IgG (inmunoglobulina-G) o IgM, ya que los anticuerpos anti-D no son normalmente producidos por sensibilización contra sustancias ambientales. Las personas "Rh negativas" forman anticuerpos contra el factor Rh, si están expuestas a sangre "Rh positiva".

La prueba de Coombs cruzado se realiza para determinar la compatibilidad entre la sangre del donante y el receptor a transfundir.

Los antígenos del sistema Rh son de naturaleza proteica. El antígeno D posee la mayor capacidad antigénica.
Los genes responsables de este sistema se localizan en el cromosoma 1. Existen tres teorías sobre el control genético:

La enfermedad del Rh es provocada por una madre Rh– que concibe un hijo Rh+. Los anticuerpos de la sangre materna destruyen los Rh+ del bebé. Si la madre piensa tener un segundo hijo debe aplicarse una vacuna que elimina los anti-Rh, llamada la gammainmunoglobulina. Ésta debe ser aplicada dentro de las 72 horas después del primer parto, ya que si se tiene un segundo bebé con Rh+ la madre producirá anti-Rh en exceso que destruirá la sangre del hijo, produciendo una enfermedad llamada Eritroblastosis fetal (anemia severa), si es que el hijo nace, ya que la producción en exceso de los anti-Rh puede causar la muerte del hijo intrauterinamente.

Los grupos sanguíneos Rh (descubierto por Landsteiner y Wiener en 1940) tiene un interés clínico similar a los grupos ABO dada su relación con la enfermedad hemolítica del recién nacido (EHRN) y su importancia en la transfusión.

Los donantes de sangre y los receptores deben tener grupos compatibles. El grupo 0- es compatible con todos, por lo que quien tiene dicho grupo se dice que es un "donante universal". Por otro lado, una persona cuyo grupo sea AB+, podrá recibir sangre de cualquier grupo, y se dice que es un "receptor universal". Por ejemplo, una persona de grupo A– podrá recibir sangre 0– o A– y donar a AB+, AB–, A+ o A–.

Cabe mencionar que al recibirse la sangre de un donante, ésta se separa en distintos hemocomponentes y ahí se determina la compatibilidad con los debidos grupos sanguíneos. Actualmente ya casi no se realizan transfusiones de sangre entera, si así fuera no debemos utilizar el término "donante o receptor universal" ya que debemos tener en cuenta que la sangre entera está compuesta principalmente por glóbulos rojos (con sus antígenos) y por plasma (con sus anticuerpos). De ese modo, si se transfundiera a una persona de grupo A la sangre de un supuesto dador universal de grupo 0-, estaría ingresando anticuerpos anti A del donante que es grupo 0, (que como se mencionó, tiene anticuerpos anti-A y anti-B) a la persona a la que se le transfunde, provocando una incompatibilidad AB0 que podría provocar incluso la muerte.

Como se aclaró, la sangre se separa en distintos hemocomponentes, los glóbulos rojos, plasma, y plaquetas. De esta manera, se pueden transfundir los glóbulos rojos de un donante 0 a cualquier grupo sanguíneo ya que no cuenta con antígenos para el sistema AB0 en sus glóbulos rojos. Por el contrario, se puede transfundir su plasma a un individuo solamente con el mismo grupo sanguíneo, teniendo en cuenta que el grupo O cuenta con anticuerpos anti-A y anti-B. Lo contrario sucede con el grupo AB. Los glóbulos rojos (eritrocitos) de un donante AB tienen antígenos A y B, por lo que no se pueden transfundir a un receptor A (pues los antígenos B del donante se unirán a los anticuerpos anti-B que tiene todo receptor A). Tampoco puede donar glóbulos rojos a un receptor B (pues los antígenos A del donante se unirían a los anticuerpos anti-A que tiene todo receptor B y se produciría una incompatibilidad). Del mismo modo, no se pueden trasfundir glóbulos rojos de un donante AB a un receptor O (pues los antígenos A y B del donante se unirán a los anticuerpos anti-A y anti-B que tiene todo receptor 0).

Es decir: un individuo 0- es donante universal de eritrocitos, pero sólo puede donar plasma a otro individuo 0. El 0+ en cambio, no es donante universal de eritrocitos, ya que sus eritrocitos tienen tienen factor Rh positivo, un antígeno D contra el que reaccionarían los anticuerpos Anti-D que tienen presente en su plasma todos potenciales receptores de grupos negativos. El 0+, no es receptor universal de plasma, ya que no presenta ni antígeno A, ni antígeno B, pero si Antígeno D en sus eritrocitos.El individuo O- no presenta antígenos A ni B, pero aunque no tiene antígeno D, tampoco tiene anticuerpos Anti-D. Sólo los desarrolla después de que su sangre entre en contacto con sangre de un individuo con factor Rh+.

Un individuo AB+ es donante universal de plasma, ya que no posee ningún anticuerpo Anti-A, ni Anti-B ni Anti-D; pero sólo puede recibir plasma de otro AB+. Un individuo AB+ también es receptor universal de eritrocitos. 

La distribución de los grupos sanguíneos en la población humana no es uniforme. El más común es O+, mientras que el más escaso es AB–. Además, hay variaciones en la distribución en las distintas subpoblaciones humanas.

Ya desde hace años se cree que la historia evolutiva del sistema ABO en humanos se remonta de 1 a 2 millones de años.
Ahora se ha demostrado que los neandertales tenían este sistema, y en especial que tenían el grupo sanguíneo O, lo que aportaría pruebas empíricas de que al menos hace unos 400 000 años, en la época del ancestro común entre "Homo sapiens" y neandertales, ya existía el sistema ABO en humanos.

Son, entre otros, los siguientes:



</doc>
<doc id="17706" url="https://es.wikipedia.org/wiki?curid=17706" title="Olympe de Gouges">
Olympe de Gouges

Olympe de Gouges (Montauban, Francia, 7 de mayo de 1748-París, 3 de noviembre de 1793) es el seudónimo de Marie Gouze, escritora, dramaturga, panfletista y filósofa política francesa, autora de la "Declaración de los Derechos de la Mujer y de la Ciudadana" (1791). Como otras feministas de su época, fue abolicionista. Detenida por su defensa de los Girondinos fue juzgada sumariamente y murió guillotinada.

Nació en una familia burguesa de Montauban (su padre era carnicero y su madre hija de un negociante de telas). Se casó en 1765 con un hombre mayor, quedando al cabo de un tiempo viuda y con un hijo, Pierre Aubry. Muy decepcionada por el matrimonio en general, que calificó de "tumba de la confianza y del amor", se negó a volver a casarse. A principios de 1770, se trasladó a París donde se preocupó de que su hijo recibiera una muy buena educación. Llevaba una existencia burguesa, y frecuentaba los salones literarios parisinos donde conoció a la élite intelectual del siglo de oro francés. En 1774, su nombre figuraba en el Almanaque de París, el ""Quién es quién"" de la época. Emprendió entonces una carrera literaria al igual que su padrino, el poeta Jean-Jacques Lefranc de Pompignan. Empieza a firmar con el nombre de Marie-Olympe u Olympe, segundo nombre de su madre, añadiendo la preposición «de» a su apellido oficial Gouze, que a veces aparecía como Gouge (de hecho, su hermana mayor era Gouges).

Escribió varias obras de teatro y montó una compañía teatral itinerante que recorría la región de París, sin que sus ingresos le permitieran mantenerse. Pero rápidamente sus obras empezaron a ser representadas en teatros de toda Francia. Su obra más conocida, "La esclavitud de los negros" ("L’esclavage des noirs"), fue publicada en 1792, pero fue inscrita en el repertorio de la Comédie-Française en 1785 bajo el título de "Zamore y Mirza, o el feliz naufragio" ("Zamore et Mirza, ou l’heureux naufrage").

Esta obra atrevida pretendía llamar la atención sobre la condición de los esclavos negros, pero Olympe tuvo que enfrentarse con la desaprobación de los actores de la Comédie Française. Ésta dependía económicamente de la Corte de Versalles donde muchas familias nobles se habían enriquecido con la trata de esclavos. Por otro lado, el comercio con las colonias de ultramar representaba entonces el 50% del comercio exterior del país. Olympe fue encarcelada en la Bastilla por medio de una lettre de cachet, pero fue liberada al poco tiempo gracias a la intervención de sus amigos.

Con la Revolución, su obra pudo por fin ser representada en la Comédie Française. A pesar de las presiones y amenazas del lobby colonial, todavía muy influyente, Olympe de Gouges mantuvo una intensa actividad a favor de la abolición de la esclavitud. En 1788 publicó el ensayo "Réflexions sur les hommes nègres" ("Reflexiones sobre los hombres negros") que le abrió las puertas del "Club des amis des noirs" (Club de los amigos de los negros) del que fue miembro. En 1790 escribió otra obra sobre el mismo tema, "Le marché des Noirs" ("El mercado de los negros").

Los principales dirigentes del movimiento abolicionista, el abate Grégoire y el diputado girondino Brissot, dejaron constancia en sus escritos de la admiración que sentían por Olympe de Gouges.

En 1788, el "Periódico general de Francia" ("Journal général de France") publicó dos de sus folletos políticos, tratando uno de ellos de su proyecto de impuesto patriótico que desarrollará más tarde en su famosa "Carta al pueblo" ("Lettre au Peuple"). El segundo dibujaba un amplio programa de reformas sociales. Estos escritos fueron seguidos de folletos que dirigía periódicamente a los representantes de las tres primeras legislaturas de la Revolución, a los Clubes patrióticos y a diversas personalidades como Mirabeau, La Fayette y Necker a los que admiraba. Se calcula que fueron cerca de 30 panfletos. Fundó varias Sociedades Fraternas para ambos sexos.

En 1791 escribió su famosa "Declaración de los Derechos de la Mujer y la Ciudadana" que comenzaba con las siguientes palabras:

En la línea de Montesquieu, defendió la separación de poderes. Apoyó en un principio la monarquía constitucional, pero se adhirió rápidamente a la causa republicana y se opuso a la condena a muerte de Luis XVI en 1793. Tomó partido por los Girondinos y advirtió sobre los riesgos de dictadura criticando duramente la política de Robespierre y Marat. Denunció también la creación del Comité de Salvación Pública.

Su defensa de los Girondinos, después de que éstos fueran eliminados de la escena política en junio de 1793, le valió ser detenida en agosto de 1793 bajo la acusación de ser la autora de un panfleto a favor de estos. Enferma por culpa de una herida que se había infectado, fue transferida a una enfermería carcelaria. Para que su detención le fuera más soportable, empeñó sus joyas en el Monte de Piedad consiguiendo así que se la trasladara a una pensión burguesa donde se recluía a los detenidos enfermos de la alta sociedad. Olympe de Gouges reclamó sin descanso que se la juzgara para poder defenderse de las acusaciones que pesaban sobre ella, y evitar así el expeditivo tribunal revolucionario. Con este fin, compuso dos panfletos que logró sacar de su lugar de reclusión y que tuvieron una amplia difusión, "Olympe de Gouges en el Tribunal revolucionario" y "Una patriota perseguida". Fueron sus últimos textos.

El 2 de noviembre de 1793, 48 horas después de que fueran ejecutados sus amigos girondinos, Olympe fue llevada ante el tribunal revolucionario sin poder disponer de abogado. Se defendió con valor e inteligencia en un juicio sumario que la condenó a muerte por haber defendido un estado federado, de acuerdo con los principios girondinos. Fue guillotinada al día siguiente, el 3 de noviembre de 1793. Según la declaración de un inspector de la policía y el periódico contrarrevolucionario "Le Journal" del editor Perlet, Olympe de Gouges subió al cadalso con valor y dignidad, aunque el hijo del verdugo, Henri Sanson, y otros testimonios que recogió el historiador Jules Michelet afirman lo contrario.

El único hijo de Olympe de Gouges, Pierre Aubry, renegó de ella públicamente poco después de su ejecución, por temor a ser detenido.

Sus trabajos fueron profundamente feministas y revolucionarios. Defendió la igualdad entre el hombre y la mujer en todos los aspectos de la vida pública y privada, incluyendo la igualdad con el hombre en el derecho a voto, en el acceso al trabajo público, a hablar en público de temas políticos, a acceder a la vida política, a poseer y controlar propiedades, a formar parte del ejército; incluso a la igualdad fiscal así como el derecho a la educación y a la igualdad de poder en el ámbito familiar y eclesiástico. Olympe de Gouges escribió:

Se dirigió a la reina María Antonieta para que protegiera "su sexo", que decía desgraciado, y redactó la "Declaración de los Derechos de la Mujer y de la Ciudadana", calcada sobre la "Declaración de Derechos del Hombre y del Ciudadano" de 1789, en la cual afirmaba la igualdad de los derechos de ambos sexos. 

Asimismo realizó planteamientos sobre la supresión del matrimonio y la instauración del divorcio, la idea de un contrato anual renovable firmado entre concubinos y militó por el reconocimiento paterno de los niños nacidos fuera de matrimonio. 

Fue también una precursora de la protección de la infancia y a los desfavorecidos, al concebir en grandes líneas, un sistema de protección materno-infantil (creación de maternidades) y recomendar la creación de talleres nacionales para los parados y de hogares para mendigos.

Olympe de Gouges redactó una adaptación de la "Declaración de los Derechos del Hombre y del Ciudadano" cambiando en muchos casos la palabra "hombre" por "mujer", y en otros artículos resaltando el predominio del hombre sobre la mujer. 

I - La mujer nace libre y permanece igual al hombre en derechos. Las distinciones sociales sólo pueden estar fundadas en la utilidad común.

II - El objetivo de toda asociación política es la conservación de los derechos naturales e imprescriptibles de la Mujer y del Hombre; estos derechos son la libertad, la propiedad, la seguridad y, sobre todo, la resistencia a la opresión.

III - El principio de toda soberanía reside esencialmente en la Nación que no es más que la reunión de la Mujer y el Hombre: ningún cuerpo, ningún individuo, puede ejercer autoridad que no emane de ellos.

IV - La libertad y la justicia consisten en devolver todo lo que pertenece a los otros; así, el ejercicio de los derechos naturales de la mujer sólo tiene por límites la tiranía perpetua que el hombre le opone; estos límites deben ser corregidos por las leyes de la naturaleza y de la razón.

V - Las leyes de la naturaleza y de la razón prohíben todas las acciones perjudiciales para la Sociedad: todo lo que no esté prohibido por estas leyes, prudentes y divinas, no puede ser impedido y nadie puede ser obligado a hacer lo que ellas no ordenan.

VI - La ley debe ser la expresión de la voluntad general; todas las Ciudadanas y Ciudadanos deben participar en su formación personalmente o por medio de sus representantes. Debe ser la misma para todos; todas las ciudadanas y todos los ciudadanos, por ser iguales a sus ojos, deben ser igualmente admisibles a todas las dignidades, puestos y empleos públicos, según sus capacidades y sin más distinción que la de sus virtudes y sus talentos.

VII - Ninguna mujer se halla eximida de ser acusada, detenida y encarcelada en los casos determinados por la Ley. Las mujeres obedecen como los hombres a esta Ley rigurosa.

VIII - La Ley sólo debe establecer penas estrictas y evidentemente necesarias y nadie puede ser castigado más que en virtud de una Ley establecida y promulgada anteriormente al delito y legalmente aplicada a las mujeres.

IX - Sobre toda mujer que haya sido declarada culpable caerá todo el rigor de la Ley.

X - Nadie debe ser molestado por sus opiniones incluso fundamentales; si la mujer tiene el derecho de subir al cadalso, debe tener también igualmente el de subir a la Tribuna con tal que sus manifestaciones no alteren el orden público establecido por la Ley.

XI - La libre comunicación de los pensamientos y de las opiniones es uno de los derechos más preciosos de la mujer, puesto que esta libertad asegura la legitimidad de los padres con relación a los hijos. Toda ciudadana puede, pues, decir libremente, soy madre de un hijo que os pertenece, sin que un prejuicio bárbaro la fuerce a disimular la verdad; con la salvedad de responder por el abuso de esta libertad en los casos determinados por la Ley.

XII - La garantía de los derechos de la mujer y de la ciudadana implica una utilidad mayor; esta garantía debe ser instituida para ventaja de todos y no para utilidad particular de aquellas a quienes es confiada.

XIII - Para el mantenimiento de la fuerza pública y para los gastos de administración, las contribuciones de la mujer y del hombre son las mismas; ella participa en todas las prestaciones personales, en todas las tareas penosas, por lo tanto, debe participar en la distribución de los puestos, empleos, cargos, dignidades y otras actividades.

XIV - Las Ciudadanas y Ciudadanos tienen el derecho de comprobar, por sí mismos o por medio de sus representantes, la necesidad de la contribución pública. Las Ciudadanas únicamente pueden aprobarla si se admite un reparto igual, no sólo en la fortuna sino también en la administración pública, y si determinan la cuota, la base tributaria, la recaudación y la duración del impuesto.

XV - La masa de las mujeres, agrupada con la de los hombres para la contribución, tiene el derecho de pedir cuentas de su administración a todo agente público.

XVI - Toda sociedad en la que la garantía de los derechos no esté asegurada, ni la separación de los poderes determinada, no tiene constitución; la constitución es nula si la mayoría de los individuos que componen la Nación no ha cooperado en su redacción.

XVII - Las propiedades pertenecen a todos los sexos reunidos o separados; son, para cada uno, un derecho inviolable y sagrado; nadie puede ser privado de ella como verdadero patrimonio de la naturaleza a no ser que la necesidad pública, legalmente constatada, lo exija de manera evidente y bajo la condición de una justa y previa indemnización.

En vida, Olympe de Gouges tuvo que enfrentarse con la misoginia habitual de la época, y fue desacreditada por la incomprensión de sus ideas por parte de muchos de sus contemporáneos. Su obra cayó en el olvido, mientras el desconocimiento y mala interpretación de sus escritos contribuyó a convertirla en objeto de desprecio y burla a lo largo del siglo XIX, donde gran parte de la intelectualidad francesa rechazaba frontalmente la idea de que una mujer hubiera sido "ideóloga revolucionaria". Se dijo de Olympe de Gouges que apenas sabía leer y escribir, se sospechó de la autoría de sus obras y se dudó de su capacidad intelectual hasta llegar a cuestionar sus facultades mentales.

Hubo que esperar hasta el final de la Segunda Guerra Mundial, para que Olympe de Gouges saliera del terreno de la caricatura y la anécdota pseudo histórica, y se convirtiera en una de las grandes figuras humanistas de Francia al final del siglo XVIII. Fue objeto de estudio en Estados Unidos, Alemania y Japón. En Francia, después de la publicación en 1981 de su biografía por Olivier Blanc, que investigó su vida a partir de documentos originales de la época, los actos del bicentenario de la Revolución francesa en 1989 rindieron homenaje a la obra de Olympe de Gouges. Desde entonces, se han representado varias de sus obras de teatro y sus escritos fueron reeditados.

En 1989, a propuesta de la historiadora Catherine Marand-Fouquet, varias peticiones fueron dirigidas al entonces presidente de la República Jacques Chirac para que el nombre de Olympe de Gouges figurase en el Panteón de París. El presidente, asesorado por el historiador Alain Decaux, descartó la idea. 

Varios municipios franceses han querido rendir homenaje a Olympe de Gouges, dando su nombre a colegios, institutos, plazas y calles. En Montauban, su ciudad natal, el teatro municipal lleva su nombre desde 2006. En el distrito XI de París, una sala de espectáculos situada en el emplazamiento de la antigua cárcel de mujeres de La Roquette también lleva su nombre. El 8 de marzo de 2007, una sala del Hotel de Beauvau, sede del Ministerio del Interior francés, le ha sido dedicada.

El 19 de septiembre de 2005 se estrenó en el Teatro Empire de Buenos Aires "Olimpia de Gouges o la pasión de existir", obra de Margarita Borja y Diana Raznovich, editada en 2011 por el Instituto Universitario de Investigación Feminista y de Género de la Universidad Jaume I de Castellón.

Teatro

Escritos políticos (folletos, carteles, artículos etcétera.) 


Biografías

Reediciones de las obras de Olympe de Gouges



</doc>
<doc id="17714" url="https://es.wikipedia.org/wiki?curid=17714" title="Ryūnosuke Akutagawa">
Ryūnosuke Akutagawa

Considerado como el "padre de los cuentos japoneses", el Premio Akutagawa, uno de los más prestigiosos de Japón, fue nombrado en su honor. Akutagawa cometió suicidio a la edad de 35 años por sobredosis de barbital.

Ryūnosuke Akutagawa nació el 1 de marzo de 1892 en el distrito de Kyōbashi, Tokio, como el tercer y único hijo varón de Fuku Akutagawa y Toshizo Nīhara. Fue nombrado "Ryūnosuke" ("Hijo del dragón") debido a que su nacimiento coincidió con el Año del Dragón. Debido a la enfermedad —al parecer sufría de psicosis— de su madre padecida poco después de su nacimiento, que murió en 1902, fue adoptado a una edad temprana por el hermano mayor de esta, Dōshō Akutagawa, de quien tomó el apellido Akutagawa y quien se hizo cargo de su crianza. Su tía política, Fuki, le atormentó durante toda su infancia diciéndole que padecía de la misma enfermedad que su madre; esto le traumatizó y le signó como escritor atormentado. Akutagawa se interesó en la literatura china clásica desde muy joven, así como también en los trabajos de escritores como Mori Ōgai y Natsume Sōseki.

En 1910, ingresó a la Escuela Superior Nº 1 de Tokio, donde se haría amigo de varios compañeros de clase que incluían a Kan Kikuchi, Masao Kume, Yūzō Yamamoto, Bunmei Tsuchiya, así como otros que llegarían a ser escritores célebres. En 1913, comenzó sus estudios en el Departamento de Literatura Inglesa de la Facultad de Letras de la Universidad de Tokio. Con el grupo formado por Kikuchi, Yamamoto, Toyoshima, Tsuchiya y otros, al año siguiente editó la revista "Shinshicho", en la que publicó traducciones de obras de William Butler Yeats y Anatole France, y sus primeros cuentos: "Vejez" y "La muerte de un joven". Después de la graduación, enseñó brevemente en la Escuela Naval de Ingeniería en Yokosuka como instructor de inglés, antes de decidir dedicarse a escribir.

Cuando aún era un estudiante, Akutagawa le propuso matrimonio a su amiga de la infancia, Yayoi Yoshida, pero su familia adoptiva no aprobó la unión. En 1916, se comprometió con Fumi Tsukamoto, con quien se casó dos años después, en 1918. La pareja tuvo tres hijos: Hiroshi (1920-1981), un actor, Takashi (1922-1945), quien fue asesinado en Birmania, y Yasushi (1925-1989), un compositor.

En 1915, Akutagawa publicó "Rashōmon" (donde describe la decadencia de las tradiciones japonesas acompañada por la angustia existencial de los protagonistas) y otro cuento en la revista "Teikoku Bungaku"de la Universidad de Tokio. Frecuentó la casa del escritor Natsume Sōseki, quien ejercería en él una notable influencia. En 1916, con Kume, Kikuchi, Matsuoka y otros edita "Shinshicho" (cuarta época), en la que publica "La nariz", mereciendo elogios de Natsume. Publica además "El pañuelo" en la revista "Chuo Koron", que tiene favorable acogida en la crítica; se convierte en uno de los más firmes valores de la nueva generación. Se gradúa en la Universidad; presenta la tesis "Estudios sobre William Morris". Es nombrado profesor en la Escuela de Mecánica Naval de Oficiales. Ese mismo año, muere su maestro Natsume.

En 1917, publicó sus dos primeros libros de cuentos. Un año más tarde, ingresó en el periódico "Mainichi" de Osaka, donde publicó "El biombo del infierno", "La muerte del mártir", "Asesinato de la era Meiji", "La muerte del poeta Basho" y otros cuentos. En 1919, viajó a Nagasaki con Kan Kikuchi para estudiar el cristianismo japonés y publicó cuentos con ese tema (Nagasaki era una ciudad en la que la mayoría de su población era practicante fiel del catolicismo a partir de las misiones de Francisco Javier).

En 1920, publicó algunos cuentos, entre ellos "El Cristo de Nankín", "El baile" y "Otoño"; este último señala un cambio en su estilo. Un año de después viajó a China como corresponsal del diario 'Mainichi' y escribe varios cuentos relacionados con ese país. En 1922, publicó algunos ensayos y cuentos: "En el bosque", "El general", "La princesa Rokunomiya" y "La castidad de Otom" que marcan el fin de su primera época literaria. Al año siguiente publicó la serie de cuentos sobre Yasukich]. En aquel tiempo se produciría el gran terremoto de Tokio. En 1924, se encarga de la publicación de "The modern series of English Literature". Al año siguiente compilaba una antología de literatura moderna japonesa; también publica una crónica de viaje a la China.

Las historias de Akutagawa fueron influenciadas por su creencia de que la práctica de la literatura debería ser universal y reunir a las culturas occidentales y japonesa. Esto se deja ver en la forma en la que Akutagawa utiliza una gran variedad de culturas y períodos de tiempo en sus obras y, o bien reescribe la historia con sensibilidades modernas, o crea nuevas historias utilizando ideas de múltiples fuentes. La cultura y la formación de una identidad cultural también es un tema principal en varias de las obras de Akutagawa. En estas historias, explora la formación de la identidad cultural durante los períodos de la historia en los que Japón estaba más abierto a las influencias externas. Un ejemplo de esto es su historia "Hōkyōnin no Shi" ("El mártir", 1918) que se establece en el período misionero.

La imagen de la mujer en las historias de Akutagawa fue moldeada bajo la influencia de las tres mujeres que tomaron el papel de madre en su vida. Su mayor influencia fue su madre biológica, Fuku, de quien le preocupaba haber heredado su locura. A pesar de no haber pasado mucho tiempo con Fuku, Akutagawa se identificaba fuertemente con su madre, además de creer que si en algún momento se volvía loco la vida no tenía sentido. Sin embargo, sería su tía Fuki quien jugó el papel más importante en su crianza. Fuki controlaba gran parte de su vida y exigiendo su atención, especialmente a medida que envejecía. Las mujeres que aparecen en las historias de Akutagawa, al igual que las mujeres que identificó como madres, en su mayoría fueron escritas como dominantes, agresivas, engañosas y egoístas. Por el contrario, los hombres a menudo eran representados como las víctimas de tales mujeres, como en "Kesa a Morito" ("Kesa y Morito", 1918), en el que la protagonista femenina intenta controlar las acciones tanto de su amante como de su marido.

En el año de 1926, enfermó gravemente y padecería de crisis nerviosas: alucinaciones visuales y angustia. Declinó su producción literaria. En 1927, mantuvo una polémica literaria con el novelista Junichiro Tanizaki. Escribió numerosas obras de gran valor en las cuales los principales méritos son la originalidad y las logradas expresiones de lo emocional: "Ilusión", "Kappa" (una sarcástica sátira social parcialmente fabulada basándose en los animales de la mitología popular japonesa llamados "kappa"), "El hombre del oeste", "La vida de un idiota", "Palabras de un enano", "Los engranajes" (breve pero intenso relato autobiográfico en el cual describe sus sensaciones pesadillezcas y expresa la idea del suicidio). Ese mismo año se suicidó ingiriendo veronal; antes de morir dijo: ぼんやりとした不安 ("Bonyaritoshita fuan", que significa "sombrío desasosiego"). Después de su muerte se publicó su último libro de cuentos, además de otros ensayos, poemas y cuentos infantiles.

En 1935, su amigo de toda la vida Kan Kikuchi estableció el premio literario de mayor prestigio en Japón, el Premio Akutagawa, en su honor. Akutagawa empleó los pseudónimos Chōkōdō Shujin 澄江堂主人 y Gaki 我鬼.

Su relato "Rashōmon" (1915) fue combinado con un relato posterior, "En el bosque" (1921-22), para formar la base argumental de la premiada película Rashōmon (1950), dirigida por Akira Kurosawa.






</doc>
<doc id="17715" url="https://es.wikipedia.org/wiki?curid=17715" title="Premio Akutagawa">
Premio Akutagawa

El Premio Akutagawa (芥川龍之介賞 Akutagawa Ryūnosuke Shō) es el galardón literario más prestigioso de Japón, nombrado así en honor a Ryūnosuke Akutagawa. Fue establecido en 1935 por Kikuchi Kan, editor de la revista Bungei Shunju, y actualmente es patrocinado por la Nihon Bungaku Shinkō Kai, que es el organismo encargado de la promoción de la literatura japonesa. Se otorga dos veces al año (en enero y en julio) a la mejor historia estrictamente literaria publicada en cualquier medio, escrita por un autor nuevo o en crecimiento. El ganador recibe un reloj de bolsillo y un premio en efectivo por un millón de yenes. 



</doc>
