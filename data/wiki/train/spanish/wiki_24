<doc id="4511" url="https://es.wikipedia.org/wiki?curid=4511" title="Mike Oldfield">
Mike Oldfield

Michael Gordon Oldfield (Reading, Reino Unido, 15 de mayo de 1953) es un músico, compositor, multiinstrumentista y productor británico. Ganador de un Grammy en 1975 por mejor composición Pop-Rock álbum instrumental por Tubular Bells (1973).

El padre del músico, Raymond Oldfield, adquirió una guitarra cuando servía en la Royal Air Force en Egipto durante la Segunda Guerra Mundial. Mike recuerda cómo su padre "solía tocar la guitarra cada Nochebuena, cantando la única canción que sabía tocar, "Danny Boy". Mike también atribuyó su temprano interés por la música al hecho de haber visto de niño al virtuoso guitarrista Bert Weedon: "Le vi en la tele cuando tenía siete años y enseguida convencí a mi padre para que me comprara mi primera guitarra. De hecho, creo que de no haber sido por Bert nunca hubiera llegado a ser lo principal en mi vida".

Los Oldfield se convirtieron en una familia enlazada a la música: el hermano mayor de Mike, Terry Oldfield, es un compositor de prestigio en el campo de la música para documentales televisivos, y tiene varios álbumes en el mercado; su hermana, Sally Oldfield, consiguió un gran éxito a principios de los 80 con el tema vocal "Mirrors", y en la actualidad continúa en activo.

A la edad de 10 años, Mike ya componía piezas instrumentales para guitarra acústica. La guitarra era para él más que un instrumento, era una vía de escape de una situación familiar que fue empeorando y apartándolo del mundo exterior durante mucho tiempo. A lo largo de esa década, la escena musical acústica había gozado de muy buena salud, debido al resurgimiento de la cultura folclórica británica que tuvo lugar en las décadas anteriores. Fue en uno de los muchos clubes dedicados a este movimiento donde el joven Mike empezó a darse cuenta de que su virtuosismo musical era del agrado del público.

"Tenía dos instrumentales de 15 minutos cada uno, que tocaba en los clubes de folk locales en los que iba repasando todos los estilos", decía. "Incluso desafinaba las cuerdas totalmente y las doblaba sobre el mástil y hacía todo tipo de cosas. En cuanto me daban vacaciones en la escuela, pasaba la semana entera practicando y tocando la guitarra". Probó también con la música eléctrica, tocando piezas instrumentales de The Shadows en un grupo amateur.

Cuando Mike cumplió 13 años, la familia Oldfield se trasladó a Romford, Essex. En 1967 dejó la escuela y junto con su hermana Sally formó The Sallyangie, un dúo folk-hippie de voz y guitarra. Firmaron por la compañía Transatlantic, que les editó el álbum "Children of the Sun" en 1968 y el single "Two Ships" en 1969. Por esta época el toque de guitarra de Mike fue fuertemente influido por el "folk barroco" popularizado por John Renbourn, líder de Pentangle y Bert Jansch. Después de un año, llegó el fin de Sallyangie.

Mike se aproximó en más profundidad a la música rock, formando otro grupo de corta vida llamado Barefoot, con su hermano Terry. Eso le condujo a trabajar como bajista en Kevin Ayers & The Whole World. Kevin Ayers había sido miembro fundador de Soft Machine, pero abandonó el grupo en 1968. Al año siguiente publicaron el álbum "Joy of a Toy", que les llevó a hacer una gira en 1970.

Entre los miembros de The Whole World se encontraba David Bedford ocupándose de los teclados. Bedford, un compositor de formación clásica, entabló una buena amistad con Mike, ayudándole en la composición de una temprana versión del que sería su primer álbum en solitario. Estando de gira con The Whole World, Mike entró en contacto con Centipede, una enorme orquesta de jazz dirigida por Keith Tippett. La amplia gama de instrumentos de que disponían influyó a Mike en el carácter multiinstrumentalista que más tarde daría a sus propias composiciones.

Kevin Ayers & The Whole World grabaron dos álbumes, Shooting At The Moon y "Whatevershebringswesing", antes de disolverse en agosto de 1971. Para entonces, Mike había pasado de ser bajista a ser el guitarrista principal de la banda, y sus magistrales solos ya le habían dado una notable reputación.

Entre 1971 y 1973 Mike comenzó a ordenar las ideas musicales que bullían en su cabeza. Usando una grabadora de cuatro pistas que le prestó Ayers, dos pistas en un sentido y las otras dos en el otro, descubrió que si cubría el cabezal de borrado con un trocito de cartón podía grabar en cuatro pistas. De esta forma podría empezar a grabar las ideas necesarias para realizar su gran proyecto: crear una sinfonía, similar a las composiciones de gran escala para orquesta con diferentes movimientos que se podían encontrar en muchas obras de música clásica, pero utilizando para ello instrumentos de toda índole, sobre todo pertenecientes al mundo del pop-rock. Se ha mencionado que la "Quinta Sinfonía" de Jean Sibelius le influyó profundamente por aquel entonces.

Con la grabadora prestada se metió en el dormitorio de la casa que compartía con los otros miembros del grupo, y las ideas para su nuevo trabajo empezaron lentamente a tomar forma. Ya metido en faena, Mike se decidió a tocar todos los instrumentos él mismo, y pensó que no le sería difícil con su don natural para la música el poder dominar casi cualquier instrumento; desde el xilófono al piano de cola, la guitarra clásica, el órgano Farfisa... Mientras aún trabajaba con Kevin Ayers, ayudaba también en las grabaciones que se hacían en los famosos estudios Abbey Road de Londres, donde tuvo la oportunidad de compartir algunas conversaciones con The Beatles. Pronto descubrió que el estudio tenía un almacén repleto de todo tipo de instrumentos, algunos de los cuales pertenecían al cuarteto de Liverpool, así que se las arreglaba para llegar más temprano y, mientras los demás usuarios del estudio llegaban, él experimentaba con esos instrumentos e incorporaba nuevos sonidos y texturas a su proyecto. Ensimismado en un trabajo que sabía iba a ser revolucionario, se propuso plasmar en él todas las profundas emociones que estaba experimentando como explorador de un campo musical virgen. La obra que estaba componiendo sería, además, un trabajo que se convertiría gradualmente en el vehículo para descargar sus emociones más profundas, y con las que más le estaba costando vivir.

Después de crear una primera maqueta, empezó a recorrer todas las discográficas tratando de convencer a alguien para que apoyase su proyecto. Por toda respuesta obtuvo negativas de las discográficas, que argumentaban que aquello "no era comercial" y que, si en algún caso llegaba a editarse, nadie lo compraría; obviamente, eso le había pasado por poner su fe en aquella poco trabajada maqueta. Tras haber compuesto la hipnótica introducción (la melodía más emblemática de su primera obra), seguiría acordándose de aquello: ¡si tan solo pudiese grabarlo, editarlo y promocionarlo!

Un rayo de luz iluminaría el futuro de Oldfield. Cuando Mike dejó la banda de Kevin Ayers definitivamente, para ganarse la vida trabajó ocasionalmente como guitarrista de sesión. Uno de esos trabajos lo llevó en la banda de acompañamiento de la producción londinense de "Hair", el "musical de amor-rock tribal" por 5 £ la noche. También tocó por un tiempo el bajo en una banda comandada por el cantante de soul Arthur Lewis. El grupo iba a grabar a un estudio recientemente inaugurado en una mansión de Shipton-on-Cherwell, a 20 millas de Oxford. Los estudios de grabación The Manor fueron construidos por aquel entonces para Richard Branson por Tom Newman, asistido entre otros por Simon Heyworth. El reunido en The Manor era un equipo de buenos amigos, y también estaban allí las novias de algunos de ellos, así como un cocinero, limpiadoras y jardineros. Como Mike comentó más tarde, "todos los problemas que surgían los tratábamos como si fuesemos una gran familia".

El magnífico ambiente que reinaba en el estudio y la actitud de Newman y Heyworth dieron a Mike la oportunidad de grabar una nueva maqueta basada en los mismos desarrollos instrumentales que ya manejaba desde hacía tiempo. A Heyworth y Newman les encantó y asombró el abanico de ideas de Oldfield, y emprendieron una campaña de persuasión a Branson para que editara aquello y les dejara el estudio durante algún tiempo para grabarlo. De entrada parecía que aquel no era el momento apropiado; el proyecto debía esperar un poco a la llegada de Simon Draper (que se uniría a Branson, poseedor de una cadena de tiendas de discos) para crear una discográfica propia. Draper tenía un amplio conocimiento musical, y cuando escuchó las ideas de Mike, las apoyó inmediatamente.

Mike continuó desarrollando y refinando sus ideas, a las que ahora podía dar un nombre: "Tubular Bells" aunque en principio se barajasen nombres como "Breakfast in Bed" (Desayuno en la cama) y "Opus One" (Opus 1).

Casi se había agotado la paciencia de Mike Oldfield cuando Draper le ofreció una semana de tiempo de estudio en The Manor. Una amplia selección de instrumentos fue llevada al estudio, y comenzó el trabajo. Durante esa semana se grabó algo más de la primera parte del álbum, y el resto emergió durante sesiones repartidas a lo largo de los siguientes meses. Desde el principio Mike ponía las facilidades que le daba la tecnología de la época al límite para hacer sus grabaciones; muy pronto empezó a usar 16 pistas. Como se iban añadiendo a la grabación más y más instrumentos, las sesiones también fueron una prueba para la inventiva de Newman y Heyworth, que mezclaron aquello todo lo bien que les fue posible en un período limitado de tiempo. El equipo de que disponía el estudio no estaba automatizado, y todo el trabajo fue hecho manualmente por Mike, ya que Simon Heyworth y Tom Newman ya usaban todos los dedos de que disponían en la mesa de mezclas; esto hacía menos cercana la relación entre productores y artista, pero aun así cada uno de los tres aprendió muchas cosas de sus otros dos compañeros.

Durante las sesiones, Mike tocó más de 20 instrumentos y se grabaron aproximadamente 2000 cintas de prueba. La música fue interpretada casi al completo por él mismo, con la excepción de Viv Stanshall (voces), Jon Field (flauta), Steve Broughton (percusión) y Mundy Ellis (voces); Newman y Simon Heyworth recibieron crédito como co-productores. Cuando terminaron las sesiones, Branson se llevó las cintas de Tubular Bells a la feria de la industria musical, MIDEM, en Cannes en enero de 1973. Un ejecutivo de la compañía americana Mercury Records le dijo, "si le pones letra te lo compró por 20.000 $". Como nadie se mostraba interesado en respetar el concepto original, Branson y Draper decidieron editar el álbum ellos mismos en su nueva discográfica, Virgin Records.

Tubular Bells vio la luz el 25 de mayo de 1973. Surgió de un proceso de grabación y mezcla al que habría podido llamarse arte en estado puro. Los críticos hicieron lo que pudieron para definirlo, pero los aplausos fueron unánimes: el público simplemente abrió su corazón al nuevo artista y su magistral debut.
La prensa británica se quedó perpleja. El influyente radio-DJ de la BBC John Peel escribió que aquel era "un disco que cubría genuinamente un nuevo e inexplorado territorio", con música que "combina lógica con sorpresa, sol con lluvia". "Una extensa obra, casi clásica en su estructura y en la forma en cómo el tema está establecido y diestramente trabajado", dijo el Melody Maker. Algunos entrevistadores incluso creían poder enumerar las influencias de Mike : "La textura de Tubular Bells recuerda bastante a Sibelius, Vaughan Williams, Michel Legrand y The Last Night of the Proms", escribió el productor televisivo Tony Palmer.

"Tubular Bells" siempre se recordará como un momento en la historia de la música rock que cautivó el corazón y la imaginación de mucha gente. Fue también un punto de partida desde el cual poder apreciar los muchos cambios y descubrimientos hechos por este creador que, a partir de los 19 años, fue creciendo en madurez. El álbum entró en las listas del Reino Unido en julio y pronto llegó al primer puesto. "Tubular Bells" comenzó a venderse masivamente en toda Europa.

En junio de 1973, Tubular Bells se presentó en vivo en el Queen Elizabeth Hall de Londres. Para esta ocasión, se unieron a Mike los guitarristas Mick Taylor (de The Rolling Stones), Steve Hillage (de Gong), Fred Frith (de Henry Cow) y Ted Speight. También participaron David Bedford, Kevin Ayers y Pierre Moerlen, el percusionista de la vanguardista banda de rock Gong, y que sería uno de los nombres fijos en la plantilla de músicos de Mike durante muchos años. La respuesta del público fue descrita por un periodista del New Musical Express así: "Todo el público se puso de pie y empezó a pedir más. Eso sólo fue una de esas raras y espontáneas muestras de agradecimiento".

"Tubular Bells" también se editó en los Estados Unidos, pero allí todo estaba sucediendo de una forma más lenta. El empujón necesario para que las ventas del disco subieran como la espuma vino cuando el director de cine William Friedkin, animado por Richard Branson, decidió usar un extracto de 4 minutos en la película de terror El Exorcista. Mike no fue consultado respecto a la asociación de su obra con aquella película, y más tarde diría a los periodistas que aquello no le había gustado del todo. En el Reino Unido, se lanzó un single de "Tubular Bells" con una versión remezclada del álbum en versión "cuadrofónica", un sistema que necesitaba de cuatro altavoces para su pleno aprovechamiento. Para mostrar las maravillas de aquel novedoso sistema, el "Tubular Bells Quad" incluía una secuencia extra de un avión que parecía moverse alrededor del oyente, y que fue grabado después de "The Sailor's Hornpipe."

Mike Oldfield había soñado por mucho tiempo con el momento en que se editase "Tubular Bells". Cuando aquello ocurrió no pudo aguantar la presión acumulada y, emocionalmente exhausto por el proceso de grabación y sus propias inseguridades ante la fama desorbitada que estaba adquiriendo, se retiró a su nueva casa de Herefordshire. Fue allí donde comenzó a crear su nueva obra, que más tarde adoptaría el nombre de la cercana colina Hergest Ridge.

Editado en el Reino Unido en septiembre de 1974, al igual que su predecesor, "Hergest Ridge" era un álbum que contenía un único tema musical, dividido en dos suites por las exigencias obvias del formato LP. De nuevo casi todos los instrumentos fueron tocados por el propio Mike. El efecto más comentado del disco fue el que un crítico llamó "tormenta eléctrica", un segmento de la cara B en el que se interpretaban simultáneamente múltiples guitarras eléctricas distorsionadas. Los demás músicos que contribuyeron al álbum fueron Sally Oldfield y Clodagh Simmonds (voces), June Whiting y Lindsay Cooper (oboes) y Ted Hobart (trompeta). Para Mike, la composición musical era una constante obra en progreso regida por leyes lógicas o emocionales, como si de un cuadro cubista se tratase. El esquema sinfónico usado en "Tubular Bells" fue continuado en una serie de obras posteriores: "Hergest Ridge", "Ommadawn", "Incantations", "Amarok"...

"Hergest Ridge" saltó directamente al número uno de las listas de ventas del Reino Unido, desbancando a "Tubular Bells", lo que supone aún hoy en día un hecho excepcional. Virgin Records también lo promocionó en televisión, aunque el eslogan tuvo que cambiarse para este propósito. El anuncio decía originalmente que el álbum estaba disponible en "Virgin (Virgen) y otras inmaculadas tiendas de discos", y tuvo que ser modificado debido a las posibles objeciones que pudiera presentar la Iglesia católica. Aunque algunos críticos vieron "Hergest Ridge" como una obra inferior a "Tubular Bells", la mayoría dio su visto bueno. Un crítico dijo que era "la música rock más cotidiana, con algo de sinfonía clásica", y otro escribió que era "una serie de picos emocionales haciendo explosión aquí y allá a través de una cosquilleante tranquilidad". Hoy en día el álbum ha creado a su alrededor un cierto halo de disco maldito, tal vez por la sombra alargada de su predecesor, o por las circunstancias personales de su compositor en el momento de su grabación. A pesar de todo, su elegante tono pastoral, así como su acertada instrumentación, lo convierten en un disco muy recomendable.

En diciembre de 1974 se presentaron en concierto las versiones orquestales de "Tubular Bells" y "Hergest Ridge" en el Royal Albert Hall de Londres. El concierto fue organizado por David Bedford, que dirigió a la Royal Philharmonic Orchestra con solos de guitarra de Steve Hillage. El mismo Mike tocaría la guitarra en la versión de estudio de la primera composición, que fue editada en enero de 1975 con el nombre de "The Orchestral Tubular Bells". La escasa repercusión comercial del álbum llevó a la compañía a ahorrarse la publicación de "The Orchestral Hergest Ridge". Ese mismo año, un poco más tarde, se presentaron esos mismos arreglos orquestales en conciertos en Glasgow y Newcastle. En Escocia, Hillage tocó las partes de guitarra con la Scottish National Orchestra, y el solista en la zona noreste fue Andy Summers, el que más tarde fuera miembro de The Police.

El sentido del humor que a menudo rodeaba algunos fragmentos de las obras de Oldfield fue nota destacable en "Don Alfonso", un single que fue editado en marzo de 1975; con la ayuda de Chris Cutler (tambores), David Bedford (voz) y Kevin Ayers (Botellas de vino), Mike contaba la historia de un cómico torero que trabajaba para Oxo ("Worked for Oxo").

En una dirección ya un poco más seria, se editó "Ommadawn" en septiembre de 1975. Su tercera gran obra de rock sinfónico instrumental, le había llevado nueve meses de grabación. En "Ommadawn", Mike tocaba unos 20 instrumentos que iban desde las guitarras al piano de cola y la espineta. El álbum incorporaba música de África e Irlanda por medio del grupo de percusión africano Jabula y la gaita irlandesa de Paddy Moloney, líder de The Chieftains. Otros artistas colaboradores fueron Terry y Sally Oldfield, los miembros de la Hereford City Band y el solista de flauta dulce Leslie Penning. Penning también acompañó a Mike en el single navideño de aquel año, una versión del villancico tradicional "In Dulci Jubilo" que consiguió alcanzar el cuarto puesto en las listas de ventas del Reino Unido. Desde aquel momento y durante varios años, Oldfield publicaría un single navideño con regularidad.

Este tercer álbum en el mercado británico en octubre de 1975, siendo criticado y alabado por igual. Sólo el tiempo ha situado este trabajo entre los más maduros de la etapa sinfónica del músico de Reading, y por dos razones: se denota en primer lugar la elaborada producción del álbum, con las cuidadas transiciones sobre y entre melodías de la primera parte de la obra, en las que Oldfield reivindica al estudio de grabación como un instrumento musical más de sus creaciones; y en segundo lugar, por la consolidación de la faceta multiinstrumentista de Oldfield, que en esta obra llegaría a utilizar bajo y guitarra acústica, banjo, bouzouki, bodhrán, guitarra española, bajo y guitarra eléctrica, teclados, glockenspiel, arpa, mandolina, percusiones, piano, espineta, steel guitar, sintetizadores y bajosextos (guitarras de doce cuerdas), además de su propia voz. La obra respira influencias celtas y africanas, y aunque resultaría arriesgado quitar méritos a los enormes esfuerzos llevados a cabo por músicos como Peter Gabriel, se le puede considerar un claro precedente de la llamada World Music.
Como curiosidad, se puede destacar que la obra original contiene un tercer corte no especificado en la carátula, una pieza vocal compuesta por Oldfield y William Murray llamada "On Horseback". Dicha pieza apareció en un single en diciembre de 1985 como cara B de "In Dulci Jubilo", y es el propio Mike quien canta acompañado de un coro infantil.

En definitiva Mike Oldfield ya no era sólo objeto de famas pasajeras, y fue admitido dentro de la élite del rock del momento. Ello se observa en las colaboraciones de músicos veteranos que comenzaron a interesarse por el trabajo del de Reading.

Aunque todavía no había regresado de la pequeña gira que estaba haciendo para promocionar aquel trabajo, Mike contribuyó en álbumes de otros músicos a los cuales estaba asociado estilística o personalmente. Su toque de guitarra se puede oír en los discos editados en 1975 por David Bedford, Edgar Broughton y Tom Newman.

El impacto de "Tubular Bells" continuó in crescendo en 1975. En ese año le fue concedido un Premio Grammy a la mejor composición instrumental, y la enorme popularidad que estaban alcanzando las campanas tubulares movió a la empresa que las fabricaba, Premier, a lanzar a la venta una nueva gama de tubos rígidos metálicos.

En los años siguientes, el por entonces mundialmente famoso tema de "Tubular Bells" aparecía en versión discotequera por los Champs Boys, un grupo de músicos de estudio franceses. Eso fue casi todo lo que se escuchó de la música de Mike en una temporada, aunque los fans de los deportes ecuestres oyeran un extracto de "Ommadawn" como introducción de la retransmisión televisada del Horse Of The Year Show ("El show del caballo del año").
La única novedad de Mike en 1976 fue el single navideño de rigor, "Portsmouth", otra canción tradicional arreglada por Oldfield. Llegó al nº 3, un puesto por encima del que había alcanzado "In Dulci Jubilo".

Entre 1976 y 1978 Oldfield, debido a los problemas psicológicos que acarreaba desde muy atrás, se recluyó en su casa de Gloucestershire. Allí inició los esfuerzos que acabarían con la publicación de "Incantations". En ese impasse de tiempo, Virgin editó el cuádruple álbum Boxed, un set de coleccionista que contenía sus tres álbumes editados hasta entonces y un cuarto disco que contenía singles, colaboraciones especiales en discos de otros artistas, y un extraño tema cantado por el propio Mike y David Bedford llamado "Speak (Tho' You Only Say Farewell)".

En enero de 1977, Mike hizo su primera aparición en un escenario en dos años y medio, como guitarrista invitado en una presentación en vivo de la suite de David Bedford titulada "The Odyssey", basada en la obra de Homero. A ello siguió la edición casi simultánea de dos singles. Uno fue una versión de Rossini, "The William Tell Overture" y el otro "Cuckoo Song", otro arreglo de una canción folk tradicional inglesa. Ninguno tuvo demasiado éxito.

Aunque Mike continuó inactivo el resto del año, sus obras siguieron presentándose en conciertos en vivo. En mayo, Steve Hillage repetía su solo de guitarra con la Scottish Symphony Orchestra en "Tubular Bells" y "Hergest Ridge"; seguramente proceda de este concierto la grabación no oficial que se ha dado a conocer de "The Orchestral Hergest Ridge". Por aquella época fue anunciado que el primer concierto de "Ommadawn" en vivo sería dado por el Trinity College de Dublín, con el acompañamiento de la Liffey Light Orchestra.

El cuarto álbum original de Mike Oldfield, "Incantations", finalmente aparecería a finales de 1978. En los años posteriores a "Ommadawn", el rock sinfónico y su grandilocuencia habían perdido interés mundial debido a la llegada del punk rock, mucho más accesible para una juventud que reclamaba ídolos a la altura de sus propias posibilidades personales, y sin nada que ver con las superbandas de genios musicales como Pink Floyd o Genesis. Dentro de su mismo país, el punk impactó negativamente a Mike. Cuando fue preguntado en 1977 por un entrevistador acerca de lo que pensaba de aquella tendencia, contestó: "¿Punk rock? Nunca oí hablar de eso". Tal vez a causa de todo ello, Incantations resultó un tanto fuera de tono. Era el primer doble LP de Oldfield, y consistía en cuatro suites con diferentes movimientos, de nuevo partiendo de sonidos célticos y étnicos a los que se unía una atmósfera legendaria, acrecentada por largos cánticos rituales.

El cambio de atmósfera de "Incantations", más hipnótico y rítmico, hizo que llegara a ser menos exitoso que sus predecesores, aunque se mantuvo por un tiempo en el Top 20 en el Reino Unido. Varias pistas que al final no se incluyeron en "Incantations", y porciones de "Tubular Bells" y "Portsmouth", fueron usadas en la banda sonora de "The Space Movie", un documental de Tony Palmer para la televisión que celebraba el décimo aniversario del aterrizaje en la luna en julio de 1969 por astronautas estadounidenses. Por esta época, Mike concedió numerosas entrevistas para promover el álbum y hablar de su radical cambio de personalidad, producido principalmente por su asistencia a unos seminarios basados en la exégesis, una forma de terapia creada para mejorar la autoconfianza. Gracias a la exégesis, creyó haber descubierto el lado más positivo de su carácter. En una entrevista de aquella época dijo, literalmente, "he experimentado lo que podría describir como un `renacimiento´, que me ha ayudado a profundizar en mí mismo y en la naturaleza humana. He empezado de nuevo".

En marzo de 1979, Mike editó un single, "Guilty", cuyo sonido se acercaba bastante al de la música de moda. Algunos periodistas detectaron un cierto estilo "disco" en aquella pieza que había grabado con músicos de estudio en Nueva York.

Aunque era ya un maestro incontestable de las grabaciones en estudio, los conciertos en vivo también formaban una parte importante de la vida artística de Mike desde sus inicios. Después de la terapia a la que se sometió a finales de los 70, se sentía preparado para ir de gira con un gran grupo de músicos; ello resultó en la gira "Exposed", también conocida como "Tubular Shows". La primera gira internacional en la que se embarcó Mike Oldfield tuvo lugar en 1979, casi seis años después del lanzamiento de "Tubular Bells". El costoso espectáculo estaba formado por una orquesta y un coro de 50 músicos; llevaban un séquito de 25 roadies y técnicos, y tres tráilers que llevaban todo el equipo. Entre los músicos participantes estuvieron Maddy Prior (poniendo voz a la secuencia incluida en "Incantations" que lleva como letra el poema de Henry Wadsworth Longfellow, "Hiawatha's Song"), los guitarristas Phil Beer y Nico Ramsden y Pierre Moerlen y su hermano Benoit Moerlen en la percusión. En el grupo también estaban dos músicos de folk tradicional, Robin Morton y Ringo McDonough, así como miembros del Queen's College Girls Choir. Pero no todo fue música, hubo también un elemento visual aportado por las películas creadas especialmente para este evento por Ian Eames, que se irían proyectando en el fondo del escenario durante las representaciones. La gira comenzó con sendos conciertos en Barcelona (Palacio Municipal, 31 de marzo y 1 de abril de 1979) y Madrid (Palacio de los Deportes, 2 y 3 de abril de 1979), donde Mike Oldfield y su troupe tocaron "Incantations" y "Tubular Bells". Hubo después 11 conciertos en Bélgica, Francia, Holanda y Alemania.

En agosto, Virgin lanzó a la venta "Exposed", un doble álbum en vivo grabado durante la gira. En los años posteriores, Mike revelaría que aquella aventura supuso un desastre económico, con un millón de libras esterlinas en deudas, que cubrió en parte con el lanzamiento del disco de la gira, y las finiquitó con el acelerado lanzamiento de "Platinum".

"Platinum" rompió con el patrón de sus cuatro primeros discos, estructurados en largas pistas sin divisiones claras entre sus movimientos. La composición principal, "Platinum", está partida en cuatro segmentos, a los que siguen canciones cortas e instrumentales, con un cierto afán experimental y lúdico. Entre ellas estuvieron "Punkadiddle", una sátira que ridiculizaba al movimiento punk, y "Sally", una canción para la madre de su hija pequeña Molly.

La década terminaba para Mike con la publicación del single de Navidad al que los fans de Mike ya se habían acostumbrado durante los últimos cuatro años: al igual que "Portsmouth", "Blue Peter" fue una adaptación de una canción tradicional, utilizada en este caso como sintonía de un programa infantil del mismo nombre. A pesar de ello, el single de Mike sólo alcanzó el nº 19 de las listas del Reino Unido. Los royalties de Mike por el single "Blue Peter" fueron donados a la campaña de ayuda a Camboya que lanzó aquel mismo programa infantil.

En la primavera de 1980, Mike formó un grupo de once componentes para otra gira de 40 días por Europa, con un espectáculo en el que tocarían temas de "Platinum". Sus miembros incluían al saxofonista Bimbo Acock, el percusionista Pierre Moerlen y la vocalista Wendy Roberts. Ian Eames de nuevo hizo secuencias de película para proyectarlas en el fondo del escenario, entre las que se incluía una imagen del mar con un hidroavión que despegaba y se volvía hacia la cámara. Tales espectáculos en vivo tuvieron como culminación la actuación ante 43.000 personas en el Knebworth Fairy Park Festival el 21 de junio de 1980. Después de su llegada en helicóptero, le tocaba actuar tras The Beach Boys y Lindisfarne; Santana también tocaría aquella noche. La excelente actuación de Mike y sus músicos llamó la atención de un periodista de la revista Record Mirror, que destacó el sonido cristalino que la banda había logrado.

En armonía con el nuevo énfasis que se le estaba dando a los aspectos más destacables de su obra, editó dos versiones cover como singles en el otoño de 1980. El primero fue "Arrival", un tema de ABBA con el que Mike les rindió homenaje. El otro single fue una de esas canciones de tributo, "Wonderful Land", una recreación de una canción de 1962 de The Shadows, cuyo líder Hank Marvin sirvió de inspiración a todos los jóvenes guitarristas de la generación de Oldfield. Es realmente irónico que la mayoría de la gente que no conoce la música de Mike piense que es principalmente un teclista; su instrumento preferido (y el que más utiliza) es de hecho la guitarra. En su toque de guitarra se puede distinguir un cierto parecido al estilo de John Renbourn y Bert Jansch, dos multiinstrumentistas acústicos que influyeron desde pequeño en él. Pasaba muchas horas analizando y aprendiendo de su música, y durante este proceso desarrolló una formidable técnica guitarrística.

"Arrival" y "Wonderful Land" aparecieron en "QE2", un álbum parecido a Platinum en su estructura y que, en un principio, iba a llamarse "Carnival". Esta vez la pista que da título al disco no está en la cara A del disco, sino que aparece al final de la cara B. "QE2" fue coproducido y mezclado por el ingeniero David Hentschel, que previamente había trabajado con Genesis. Hentschel contó a un periodista: "siempre me gustó el carácter de Mike. Todas sus ideas sirvieron de refresco a las mías, y creo que las mías también lo fueron para él. Todo era muy divertido, y creo que, si quieres hacer un trabajo que sea realmente bueno, debes divertirte haciéndolo". Los músicos que contribuyeron a la grabación de "QE2" incluyeron a Phil Collins (percusión), Rick Fenn (guitarra) y la cantante Maggie Reilly. La vocalista del grupo de soul/rock escocés Cado Belle, Maggie Reilly, llegaría a convertirse en uno de los miembros más importantes del equipo de Mike en los siguientes cinco años. Las críticas hacia "QE2" fueron de todo tipo, con algunos de los fans acérrimos de Mike en la prensa diciendo que más que haber presentado nuevas ideas, con aquel disco había marcado el principio de una época. Sin embargo, había fans de Mike que escribían a revistas musicales manifestando haber quedado sorprendidos por la respuesta general de la crítica; uno escribió al Record Mirror para quejarse de los críticos que "no tenían ni idea de su verdadera grandeza. Dentro de 50 años, esta música seguirá escuchándose y gustando a la gente". Las giras se estaban convirtiendo ya en un evento anual; en la de 1981 por Europa, Mike llevó un número más pequeño de músicos, cuyo núcleo central estaba formado por Maggie Reilly (voces), Tim Cross (teclados), Rick Fenn (bajo) y los percusionistas Morris Pert y Mike Frye.

Si sus discos más recientes no habían estado en las listas mucho tiempo, el "fenómeno Tubular Bells" continuaba. En julio de 1981, Virgin anunció la venta de los diez millones de copias. En el mismo mes, Mike tocaría un concierto gratuito como parte de los festejos organizados por la ciudad de Londres por la boda del Príncipe Carlos y Lady Diana Spencer. En reconocimiento por esto, y por sus méritos por dar a conocer el Reino Unido fuera de sus fronteras, fue galardonado con el "Freedom of the City Of London". También formó parte, junto con otros iluminados como Billy Idol, Phil Linott y Noddy Holder, de un jurado para un concurso nacional de jóvenes grupos pop. Para poner la guinda a un año en el que pareció que Mike había vuelto a recuperar su lugar en la sociedad, fue incluido en el Who's Who, la exclusiva guía de las personas más importantes del Reino Unido: era el único músico pop que allí aparecía, aparte de Paul McCartney. Cuando se le preguntó a una integrante del equipo del Who's Who por qué habían incluido a Mike Oldfield en el libro, insegura de ello dijo: "bueno, todo el mundo ha escuchado algo de él, ¿verdad?". En su apartado del Who's Who, Mike dice que su hobby es la "aviación (ultraligeros, helicópteros)".

Se sacó su licencia de piloto en 1979, y un accidente un año después le inspiró para hacer la canción que da título al álbum "Five Miles Out" de 1982. En agosto de 1980, Mike iba pilotando un Piper PA-31 Navajo bimotor sobre los Pirineos cuando se metió en una tormenta. "Fuimos lanzados como una tortita de harina, había hielo acumulándose en las hélices y lluvia en el parabrisas, y todo el mundo gritó ¡aaargh!", dijo en una entrevista. Aquel incidente sería conmemorado con una pintura encargada especialmente por Mike a un renombrado pintor de cuadros de aviones. Al igual que "Platinum" y "QE2", "Five Miles Out" combinaba una pista de larga duración con una serie de canciones individuales. La pieza más larga era "Taurus II", que incluía contribuciones del gaitero Paddy Moloney y un grupo de baile de Morris. Entre las canciones estaba "Family Man", con la voz solista de Maggie Reilly. Cuando "Family Man" fue editado como single, estuvo pululando por los puestos más bajos de las listas del Reino Unido. Al año siguiente, paradójicamente, una versión de Daryl Hall & John Oates fue un Top 10 Hit en América. "Family Man" fue un claro ejemplo de lo que Mike había conseguido con su trabajo. "Moonlight Shadow", "Family Man", "Shadow On The Wall", "Five Miles Out" y "Islands" son mucho más que simples canciones pop, pero de nuevo todas éstas hacen uso de un cambio dinámico y de textura. Gran parte del álbum "Five Miles Out" fue grabado en el estudio instalado en la casa de Mike en Buckinghamshire. La casa fue elegida debido a la cercanía a los accesos a Londres y a un pequeño aeropuerto local en el que Mike podría volar con sus aviones.

"Five Miles Out" fue el mayor éxito de Mike en el Reino Unido desde "Ommadawn", y ello a pesar de que las críticas fueron desfavorables. Su single "Mistake" fue calificado por un escritor como "rock de mediados de los 70 para tocar en estadios", mientras otro crítico dijo que "Oldfield seguía tonteando consigo mismo sin ton ni son". Pero Mike daba todo lo que tenía. Cuando se le preguntó en el New Musical Express por su "odio a los animales", él contestó: "Posiblemente odie su decrépito periódico más que nada en este mundo". También dijo al NME que su película favorita era , y sus héroes eran Sibelius y el Capitán Kirk (de "Star Trek").

En 1982 Mike emprendió su gira más larga hasta la fecha, tocando en Europa y Norteamérica. Para su gira mundial formó un nuevo grupo en el que lo acompañaron Maggie Reilly y el ex-percusionista de Gong Pierre Moerlen, junto con dos teclistas. El concierto en Londres fue comentado compasivamente por Ray Coleman en el Daily Express, quien describió al público como "jóvenes parejas de recién casados que buscaban sentarse cómodos en algún sitio para pasar la noche oyendo música".

Mayo de 1983 fue el décimo aniversario del lanzamiento de "Tubular Bells". Mike editó su octavo álbum, "Crises", y tocó un gran concierto en julio en el estadio londinense de Wembley. Los músicos que lo acompañaron en este evento incluían al batería Simon Phillips (quien tocara en Roxy Music) y a Phil Spalding, el bajista de Toyah.

"Crises" sería el primer disco hecho con Simon Phillips como coproductor. Sus vocalistas fueron Jon Anderson de Yes y Roger Chapman de Family (en "Shadow On The Wall"), así como la imprescindible Maggie Reilly. La pista más destacada fue "Moonlight Shadow", cantada por Maggie Reilly, que fue entendida por todos como un tributo al por aquel entonces recientemente fallecido John Lennon, y que se convirtió en el single de más éxito de Mike desde que se editara "Portsmouth" siete años antes. El tema que da nombre al disco comienza con una dulce melodía similar al inicio de Tubular Bells, continuando con una parte blusera seguida de ácidas guitarras, con Mike gritando "Crises, crises... you can't get away". Después, una parte mucho más fresca, seguida de una hermosa transición a base de guitarras y sintetizadores y un final apoteósico sustentado en la percusión. Moonligth Shadow fue un éxito enorme. En España (x3 platino), Alemania (×5 platino). Siendo una de las "canciones" representativas de 1983.
Y se convirtió en el "Tema" (canción) por excelencia de Mike Oldfield, con la voz de Maggie Reilly. Virgin aprovechó la promoción y la popularidad obtenida por el álbum "Crises" para anunciar que se celebraba los 10 años del mítico "Tubular Bells". Y que se superaban los 10 millones de copias vendidas.

Sus actividades en 1984 incluyeron la edición de un nuevo álbum, una gira de cincuenta conciertos por Europa y la preparación de su primera banda sonora. Esa banda sonora sería para la película "The Killing Fields", ("Los Gritos del Silencio") de Roland Joffé, una muy alabada película que trataba sobre la guerra civil camboyana. A Mike le fue muy difícil hacer música para una película en la que se plasmaban tantas emociones. Para componer utilizó un sincronizador de vídeo conectado a su Fairlight. Gran parte de ella está basada en la música étnica de Camboya. El tema principal, "Etude", era una adaptación de un tema de Francisco Tárrega (Recuerdos de la Alhambra) y fue editado como single en diciembre de ese mismo año.

El álbum "Discovery" de 1984 fue el primero que Mike grababa fuera de Inglaterra. Para ello construyó un estudio en una casa a 2000 m sobre una montaña en los Alpes suizos, desde la que se divisaba el lago Ginebra y donde, junto con Phillips, coprodujo una nueva selección de canciones y un instrumental titulado "The Lake". Esta vez, la tarea de poner voz a las canciones fue compartida entre Maggie Reilly y Barry Palmer. Durante la grabación del disco, Barry Palmer sufrió problemas de garganta, imposibles de solucionar en el tiempo que tenían para la grabación del disco, por lo que así se quedó para siempre, siendo imposible luego reproducir esos tonos de voz que, al fin y al cabo, no habían quedado tan mal.
Entre las canciones del disco destaca "To France", inspirada en la vida de María Estuardo, reina de Escocia. Aunque sólo consiguió un éxito moderado en Inglaterra, en toda Europa fue un bombazo.

Por aquel entonces las habilidades de Mike como guitarrista de rock estaban seduciendo a un gran número de aficionados a la música heavy. En la revista de música heavy "Kerrang!", el veterano periodista Chris Welch citaba entusiásticamente palabras del griego Tucídides en alabanza a "Discovery": "Porque somos amantes de la belleza aún sencilla en nuestros gustos, y cultivamos la mente sin perder nuestra virilidad". La música de "Discovery" fue protagonista en la gira europea de 1984, para la que se haría acompañar por una banda en la que estuvieron Maggie Reilly, Simon Phillips, Phil Spalding y Barry Palmer.

En 1985, Virgin editó una recopilación de material de los 12 años de carrera de Mike con la discográfica, y publicó un álbum doble llamado "The Complete". Una de sus cuatro partes fue dedicada a grabaciones en vivo de giras de los anteriores cinco años; esto incluía su sobresaliente toque a la guitarra en la gira de "Platinum" en el concierto de Hanóver de 1980. Por entonces, los intereses de Mike se movían cercanos al uso del vídeo para la creación de sus obras musicales. Para ello equipó su casa-estudio en Buckinghamshire con lo último en adelantos tecnológicos, como un ordenador Quantel Mirage con el que generó las imágenes para el vídeo de "Pictures In The Dark". Con vocalistas como Barry Palmer, Anita Hegerland y el joven soprano de 15 años Aled Jones, concibió un "video single" y lo lanzó al mercado en diciembre de 1985. El estudio de Mike fue dotado con siete sintetizadores y, en una entrevista de 1986, Mike contaba que sus métodos de trabajo eran diametralmente opuestos a los de los músicos que se dedicaban únicamente a samplear extractos de discos de otra gente: "Tengo un montón de samples propios y normalmente dedico un tiempo al final de cada sesión para grabar los instrumentos que he utilizado". En una entrevista posterior explicaba su preferencia por los instrumentos reales ante los instrumentos sintetizados: "A lo que me opongo es a hacer música sólo con computadoras. Es como si cogieras algún tipo sofisticado de pianola u órgano barrel. Carecen totalmente de alma". Durante 1986, Mike se concentró en la creación de un vídeo álbum que se editaría más tarde, en octubre de 1988 en VHS y Laserdisc, y que se llamaría "Wind Chimes". Entre sus colaboradores estuvieron encargándose del lado visual personajes como Alex Proyas ("El cuervo", "Dark City"), que creó las imágenes para el vídeo de "Magic Touch" y que anteriormente había trabajado haciendo vídeoclips para Crowded House y otras muchas bandas. Lo único nuevo que Mike lanzó al mercado en 1986 fue el single "Shine/The Trap", con la voz de Jon Anderson. El álbum que acompañaría a "Wind Chimes" sería "Islands", que se editó en septiembre de 1987. La pieza instrumental de dos partes "Wind Chimes" estaba inspirada en música que Mike había oído en una visita a Bali, y fue coproducida por Simon Phillips. Entre los músicos que contribuyeron a la creación de "Islands" estuvieron Kevin Ayers, el saxofonista de Roxy Music, Andy Mackay y Geoff Downes a los teclados. La vocalista encargada del tema que le daría título al disco sería Bonnie Tyler, y en octubre de 1987 Mike haría una de esas extrañas apariciones en televisión en la que tocó la canción con Bonnie.

En 1989, Mike creó una versión de siete minutos de "Tubular Bells" para el Show de Nick Campbell en la BBC Radio One. Eso le hizo retomar la idea de crear una continuación de su primer gran disco, volviendo a trabajar sus temas, pero esta vez con la tecnología de 1990. "Tubular Bells II" había estado guardado en su agenda durante muchos años; los ejecutivos de Virgin habían estado esperándolo con anhelo y, en 1982, el New Musical Express se inventó la noticia de que el lanzamiento de "Tubular Bells II" era inminente y que Mike se estaba preparando para el lanzamiento de la segunda parte de la saga. Antes de que eso ocurriera, sacó tres discos más. El primero fue "Earth Moving", en 1989 en el cual cantaban nada más y nada menos que siete vocalistas para nueve canciones. Maggie Reilly volvió cantando "Blue Night", mientras Chris Thompson, de Manfred Mann's Earth, se ocuparía de poner su voz a dos de las pistas.

"Amarok" (1990) fue concebido como una venganza de Mike contra Virgin, que no quería publicarle un disco sinfónico salvo que fuese llamado "Tubular Bells II". Mike se desquitó así, y además escondió a lo largo de la larga pista musical toda una serie de claves en morse donde hablaba de Virgin, así como espontáneos altibajos en el sonido, con la única intención, según sus propias palabras "para incordiar a los ricos directivos de las discográficas que van en su Ferrari". Éste fue un retorno al formato de la gran trilogía de 1973-75. Al igual que "Tubular Bells", "Hergest Ridge" y "Ommadawn", era una única sinfonía de larga duración. "Amarok" volvió a reunir a Mike con Tom Newman, el ingeniero de sonido de "Tubular Bells". De alguna forma, éste fue el último trabajo de Mike que guardaba ciertas similitudes con "Tubular Bells". Las campanas tubulares y el cavernícola también hacían su aparición en este disco. "Amarok" era una única pieza de música que mezclaba estilos de folk inglés, flamenco y música africana, y que unía la última tecnología musical y de estudio con la tecnología clásica de Oldfield. Con 60 minutos de duración sin interrupción alguna, Amarok es uno de los temas musicales más largos jamás publicados en un álbum. Es interesante contrastar el sonido producido por los adelantos tecnológicos de 1990 con los que se utilizaban cuando se creó "Tubular Bells" en los, por aquel entonces, recién creados estudios The Manor. Pero en ambos casos, Oldfield mostró su dominio de todos los últimos avances y su habilidad para incorporarlos al proceso creativo. "Amarok" es considerado por muchos de sus fans como su mejor disco junto con "Ommadawn", aunque por desgracia también es uno de los menos conocidos por el gran público. Curiosamente es la única de todas sus obras en la que Mike no inteviene en su producción, recayendo esta en manos de Tom Newman, dedicándose únicamente a su faceta como músico, dejando el trabajo de estudio aparte. De ahí que muchos fans hayan reconocido una sonoridad diferente en este trabajo que lo hace realmente especial.

"Heaven's Open" se editó en 1991, y estaba basado en la estructura que ya hiciera familiar "Platinum": una composición larga y algunas canciones. Por primera vez, todas las canciones fueron cantadas por el propio Mike (o "Michael Oldfield", nombre que usó para firmar el disco), sin invitar a ningún otro vocalista. Como dijo en una entrevista, "me desenvuelvo mucho mejor ahora con mi voz. Ha sido para mí un verdadero placer el descubrir que no era tan malo cantando como había pensado". En este disco liberador para Mike, se escuchan canciones que destilan la esperanza y la ilusión de la nueva etapa que se abre ante él, así como otras cargadas de dolor por todo lo que su compañía le había hecho pasar.
Acompañaba a Mike una banda formada entre otros por la saxofonista Courtney Pine, Simon Phillips y el pianista Mickey Simmonds. La pieza larga de "Heaven's Open" fue el opus de 20 minutos titulado "Music From The Balcony" una verdadera obra maestra de lo experimental, lo sinfónico y lo instrumental en general. Se trata de un compendio de melodías y ritmos completamente variados en constante cambio y repetición, muy distinto de "Amarok". Tras cumplir las obligaciones contractuales que le habían atado durante dieciocho años con Virgin Records, la discográfica que lo había hecho famoso en 1973, Mike se preparaba para grabar "Tubular Bells II", esta vez para otra compañía. Los días de Mike Oldfield con Virgin habían llegado a su fin, tenía el Cielo Abierto.

Previsiblemente, las expectativas que la WEA (Warner/Elektra/Atlantic, su nueva discográfica, que más tarde sería conocida como Warner Music) puso en "Tubular Bells II" no fueron defraudadas; editado en 1992, fue un rotundo éxito de ventas. Superando los 1'5 millones de álbumes vendidos. (3'4 millones de álbumes vendidos, 2002).Además, todo fue acompañado por una extensa gira por Europa y Norteamérica, donde hacía tiempo que no actuaba. Para colmo, los directivos de Warner colocaron al famosísimo productor Trevor Horn a las órdenes de Mike. Desde hacía tiempo, el mismo Mike ya había dicho a los medios de comunicación que pensaba hacer una reedición de "Tubular Bells" con cosas que en el primer disco de la saga tubular se le habían quedado en el tintero, y pensó que sería buena idea esperar hasta estrenar nueva compañía, en este caso WEA, que a la postre prometía al autor libertad de movimientos y una promoción de su disco por Norteamérica, un mercado donde Virgin no había podido tocar siquiera.

La portada del disco le fue encargada al mismo artista Trevor Key que ya diseñara la del "Tubular Bells" original; el resultado es realmente impactante: una campana tubular amarilla doblada en tres partes, flotando sobre un fondo azul marino que de esta manera realza la imagen de la campana.

"Tubular Bells II" en esencia guarda mucha similitud con "Tubular Bells". De hecho, si lo escuchamos podremos notar como hay partes que son totalmente análogas entre los dos discos. Es decir, hay una secuencia de piano que introduce la primera parte, igual que en el original; también encontramos un reflejo del fragmento del Hombre de Piltdown, o cavernícola, que podemos oír en "Tubular Bells". Además, es muy parecida la secuencia del final de la primera parte en la que un maestro de ceremonias va introduciendo los diferentes instrumentos que aparecen tras ser mencionados. El pasaje que en "Tubular Bells" se sacó como single promocional del disco, y que se llamó "Mike Oldfield's Single", encuentra un hermano casi gemelo en la pista que ahora en "Tubular Bells II" se llama "Tattoo", y que es interpretada a las gaitas por la banda de gaiteros del departamento de policía de la ciudad de Nueva York. No obstante, este álbum no es idéntico a su predecesor pese a que tiene la misma estructura, pues mientras que los pasajes de Tubular Bells suelen ser oscuros y melancólicos, los de Tubular Bells II tienden a ser más alegres y dinámicos. Realmente es una obra maestra de la producción. Aparecieron tres singles: "Sentinel", "Tattoo" y "The Bell" (de la cual hay unas 5 ó 6 versiones, con maestros de ceremonias distintos y anunciando los instrumentos en diferentes idiomas). Una de ellas, y curiosamente la más cara por lo difícil de encontrar, fue una colaboración de un locutor de Cadena 100 Radio, Carlos Finaly, buen amigo de Mike, quien tuvo el placer de entrevistarlo y de poner la voz en castellano a dicha pista. 

La presentación de "Tubular Bells II" se hizo con un gran concierto en la explanada que hay delante del castillo de Edimburgo, en Escocia. Aunque en principio tal presentación estaba previsto hacerla en Sevilla, problemas de última hora con la organización del evento hicieron necesario trasladarla a Edimburgo. Se vio de todo: fuegos artificiales, gaiteros, algún loco gritando por un micrófono, una gran banda de músicos y, lo más importante, un Mike Oldfield pletórico que alegró los oídos del auditorio ofreciéndoles una imponente interpretación a la guitarra. Alcanzó
el puesto N°1 en: España (5 x Platino, +500.000 copias vendidas), Reino Unido (3° álbum de Mike Oldfield, en lograrlo, tras: Tubular Bells (1973) y Hergest Ridge (1974), Alemania, Italia, Suecia, Finlandia, Noruega, Australia, Grecia...
Fue 5° en las lista de álbumes New Age de 1992.

Tras dos años saboreando el éxito de "Tubular Bells II", a finales de 1994 Mike volvió a sorprender a sus fans con algo que sería un verdadero desafío para ciertas sensibilidades. Se presentaba un disco casi totalmente hecho con sintetizadores, loops y cajas de ritmos; es decir, música electrónica. Los que amaban la sencillez y el sabor acústico de obras como "Hergest Ridge" u "Ommadawn" con este disco se llevaron una total decepción. Otros, por el contrario, lo alabaron como uno de sus mejores discos. 

El disco llevaba por título "Songs Of Distant Earth", y era una sinfonía electrónica evocada por la lectura del libro homónimo de Arthur C. Clarke, el mismo autor de , novelización de la película favorita de Mike. Dicho libro comienza con el fin del Sistema Solar y trata sobre cómo el ser humano busca un nuevo sitio en el universo donde implantarse como civilización. Aunque el disco está dividido en 17 pistas, los últimos acordes de cada corte enlazan con el siguiente, creando así una auténtica epopeya musical.

Destacan, del primer corte, las palabras pronunciadas por el astronauta William Anders a bordo del Apolo 8 extraídas del "Génesis", en referencia a la creación del Universo citada en la Biblia. El single comercial de este disco fue el tema "Let There Be Light". El vídeoclip ponía de manifiesto el gran interés de Mike Oldfield por el diseño 3D y las nuevas tecnologías, ya que incluía en casi todas sus tomas personajes, lugares o situaciones fantásticas creados por ordenador. Estos efectos fueron pioneros para su época, aunque no se les hizo mucho caso. Además la versión CD contaba con un elemento innovador: era el primer disco sacado para su venta en el mercado musical que incorporaba una pista de datos para su uso en un ordenador personal. Mike eligió hacerlo para MacOS, y dejó a los usuarios de PC un tanto desilusionados.

Más tarde, en 1996, sale a la luz "Voyager", un disco con el que quiso volver a acercarse a las raíces celtas que tanto influyeron en discos como "Ommadawn" y "Hergest Ridge". El disco se compone de 9 canciones cortas en las que hace buen uso de la guitarra eléctrica y otros elementos del rock sinfónico tradicional, aunque acompañado por efectos realizados con sintetizador. La última pista es la única composición de más de 10 minutos de la "etapa WEA", y se trata de una composición orquestal. En el disco hay varias versiones de temas tradicionales como "The woman of Ireland" y contiene una versión de "O son do ar" ("The song of the Sun") de Luar na Lubre. Además, y durante el periodo en que fue grabado el disco, el propio Mike no estuvo en el mejor ambiente: se compró una casa en Ibiza con vistas al mar para, como él dijo, "buscar la unión con los elementos" y relajarse. Ibiza es conocida por su movida y sus discotecas, y eso no pasó desapercibido para Mike, que era visto frecuentemente trasnochando en muchas de ellas. Incluso protagonizó un incidente un día en que volvía borracho de madrugada en su Mercedes y lo estrelló contra un árbol. Vivió en Ibiza durante dos años, en los que dio origen y forma a su siguiente creación.

El álbum fue nominado para los premios Grammy en el año 1998 como mejor álbum de música "New Age", compitiendo en esta categoría junto con el disco "Oracle" del entonces fallecido Michael Hedges, ganando este último a título póstumo. También estuvieron nominados en esta categoría "Le Roi Est Mort, Vive Le Roi!" de Enigma, "Oceanic" de Vangelis y "Canyon Lullaby", de Paul Winter.

En 1998 publicó "Tubular Bells III", del que ya había dado una muestra en el recopilatorio "XXV", aunque la versión del álbum de su tema "Secrets" está mucho más trabajada. Si bien los dos anteriores Tubular Bells tenían la estructura de una sinfonía dividida en dos partes; en Tubular Bells III, entre la primera y segunda parte, se incluyó la canción "Man in the rain". Con este disco Mike volvió a demostrar que aún no había salido del bache musical que tuvo en la etapa ibicenca, aunque contiene pistas realmente brillantes; una muy destacable es la que utiliza como conclusión al disco, y que podría haberse llamado "The Bell III", ya que era otra revisión de la citada pista de los anteriores "Tubular Bells". En este caso se llamó "Far Above The Clouds", y es presentada como maestro de ceremonias por su hija Greta Marie, que en aquel tiempo contaba con 10 años. Con este disco Mike quería plasmar de alguna forma las frustraciones que sufrió durante su estancia en Ibiza, aunque con "Far Above The Clouds" simboliza la vuelta a la paz y el recuerdo de lo que dejó allí, añadiendo un sonido de pájaros cantando que se escucha al final del disco. 

La presentación, como todas, fue muy bien montada y desarrollada, y tanto Mike como sus músicos ofrecieron un gran espectáculo a su audiencia. Tuvo lugar en el Horse Guards Parade de Londres el 4 de septiembre de 1998 junto al palacio real de Buckingham, pero se estropeó un poco a causa de la lluvia y de un apagón que hubo en mitad del espectáculo. Aquí Mike nos presentaba a la que a partir de entonces parecía que iba a ser su cantante musa, tal como lo fue Maggie Reilly en la década de los 80: Pepsi Demacque, una cantante negra que no pudo tener mejor presentación ante los muchos millones de espectadores que estaban viendo aquel espectáculo. Su debut fue magnífico, aunque sus fans, tal vez comparando a la debutante con Maggie Reilly, empezaron a dividirse en sus criterios sobre ella; lo cierto es que eran cantantes totalmente diferentes. Esta vez el diseño de la portada corrió a cargo de un estudio de diseño infográfico, el Bill Smith's Studio, que se basó en los anteriores diseños de Trevor Key, ya que éste había muerto algunos años atrás. Mike Oldfield recibió el premio de las Ondas, entregado por el periodista español Iñaki 
Gabilondo, a la trayectoria musical y a la mejor composición instrumental; recibiendo cuatro discos de platino, por las ventas de TB III (×4 PL) en España. Su recepción global, aunque menor que la anterior edición, fue bastante aceptable 
sobrepasando 1'3 millones de copias vendidas. Curiosamente, su enfoque tecno, le permitió ser reconocido y aceptado
en los circuitos de "Musica Electrónica y ChillOut" de las "raves" y "discotecas" de España y Europa. Como uno de los 
compositores fundamentales del nacimiento, la experimentación y desarrollo de estos estilos musicales contemporaneos.

En el año 1999, a Mike se le ocurrió hacer un "disco-experimento". Este disco se llamaría "Guitars", y ya el título da una buena pista de lo que es: absolutamente todos los "instrumentos" que se escuchan están interpretados por guitarras. Esto fue posible gracias a pastillas MIDI en las que la vibración de una cuerda real de guitarra es transformada a comandos MIDI, que son entonces enviados al sintetizador o sampler para reproducir cualquier otro instrumento anteriormente se haya seleccionado. Gracias a esto, Mike pudo incluir percusiones, instrumentos de viento, sintetizadores y absolutamente todo lo que se le ocurrió, "tocado con guitarras". "Guitars" no llegó a ser un disco suficientemente admirado entre los seguidores de Mike. Algunas de sus pistas destacables son "Muse", un tema acústico que recuerda las composiciones acústicas de los 70; "Cochise", en la que Mike derrocha toda la energía que se puede sacar de las guitarras, y "Summit Day", una de las preferidas por su público y que destaca por el enorme sentimiento y sensibilidad que irradian sus notas. 

Poco después de la edición del disco, se embarcó en un tour que le llevó por toda Europa. Se llamó "Live Then & Now Tour" y en él tocó temas del álbum "Guitars" y "Tubular Bells III", pero también dio un repaso a piezas anteriores, como algunos temas de "Songs Of Distant Earth", y sus imprescindibles "Shadow On The Wall" y "Moonlight Shadow", cantadas por Pepsi, que allá donde estuvo supo ganarse el calor del público. En la gira hicieron de teloneros el grupo gallego Luar na Lubre, cuya cantante y chelista, Rosa Cedrón, ya conocía a Mike tras haber cantado para él en el tema "The Inner Child" del álbum "Tubular Bells III". Además, el compositor de este grupo, Bieito Romero, fue quien compuso el tema original en el que se basó Mike para hacer "The Song Of The Sun" que aparece en su disco "Voyager" de 1996. El tema en cuestión, y en formato original, se llamaba "O Son do Ar" ("El sonido del viento"), y Luar Na Lubre tuvo que tocarlo, cómo no, en todos los conciertos que dieron en esta gira en que acompañaron a Mike.

Ya en tiempos de la promoción de su álbum "Guitars", Mike reconoció en algunas entrevistas que estaba envuelto en la composición de un álbum que sería un homenaje a los 2000 años de historia transcurridos desde el nacimiento de Cristo. Y a finales de 1999 WEA sacó al mercado el disco "The Millennium Bell". La portada dice mucho del concepto del disco: una campana doblada, como ya es habitual, flotando entre una amalgama de objetos como planetas, guitarras, espadas, mariposas, astronautas, el famoso reloj derretido de Dalí, y algunas cosas más. La portada fue diseñada por la compañía infográfica Blue Cactus. 

Posiblemente sea el disco más extraño que Mike haya sacado en toda su carrera. Da un repaso no sólo a 2000 años de historia, sino también a muchos estilos musicales con los que parece querer demostrar que, aparte de dominar muchísimos instrumentos, también dominaba muchos estilos. El disco empieza con "Peace On Earth", una especie de canción navideña en la que se recuerda el nacimiento de Cristo; después "Pacha Mama", inspirada por un viaje que Mike hizo a Cuzco, en Perú. "Pacha Mama" fue uno de los singles del álbum, y para hacer que reflejara y evocara el ambiente de la época y la magia de los chamanes incas llamó a la cantante Miryam Stockley (conocida por sus trabajos en Adiemus y con Karl Jenkins), y a un coro. Es curioso que, antes de salir el disco, en todas sus reseñas aparecía una pista que al final o no se incluyó en el disco, o era la misma "Pacha Mama" con otro nombre. Esta pista se llamaba "Excalibur". La aparición de una "demo", posteriormente, demostró que "Excalibur", era un tema original, cantado por Camilla Darlow, con la misma melodía del tema "Broad Sunlit Uplands", pero Mike pensó que no encajaba bien y fue sacada del álbum finalmente. Para conmemorar el descubrimiento de América quiso poner en el disco "Santa María", una pista muy parecida en estilo a alguna que ya Vangelis hizo en su día para la banda sonora de la película "". Le sigue "Sunlight Shining Through Clouds", una canción magnífica en la que se recuerda la esclavitud en América. Para ello Mike aportó a la música una letra ya hecha, exactamente la misma que tiene la canción de gospel "Amazing Grace". Éste es el tema que Mike dejó a Pepsi en el disco, y aunque no le da oportunidad a lucirse, la verdad es que queda bastante bien. En principio hubo rumores de que la que aparecería en el disco sería una canción rap, y a sus fans esto no les sentó nada bien. Sin embargo, la demo antes citada demostró que, en sus orígenes, este tema pero con otra letra efectivamente era un rap bastante conseguido. ¡¡Una sorpresa!!, "The Doge's Palace". Fue un recuerdo de una de las familias más influyentes de la Venecia renacentista. En ella, una orquesta toca un rondo que es acompañada por un coro, y de vez en cuando cantan en voz alta los nombres de varios de los Doges, que eran los gobernantes de la época en Venecia. Después llega "Lake Constance" otro ejemplo de que un músico como Mike puede hacer cosas con muchísimo sentimiento. Le sigue "Mastermind", que recuerda a la Chicago de los años 20 con sus bandas de gangsters. "Broad Sunlit Uplands" y "Liberation" fueron añadidas como un triste recuerdo de la Segunda Guerra Mundial. Otra de las sorpresas del disco fue "Amber Light", que sirvió para conmemorar la llegada del amanecer del nuevo milenio. Lo impresionante de este tema es, aparte de la belleza de la melodía, la unión de dos coros cantando a la par junto con Miryam Stockley, David Serame y Nicola Emmanuel, que llevarían las voces principales. Se intentó hacer una versión de este tema con la colaboración especial de Nelson Mandela, que citaría las palabras de introducción, pero los numerosos compromisos de este personaje impidieron que esto llegara a producirse en la fecha prevista, así que se abortó el proyecto. Como colofón, llega la pista que le da nombre al disco, "The Millennium Bell", un repaso a todas las canciones del disco, pero esta vez en versión "reprise". 

Como première dio un concierto para celebrar la llegada del nuevo milenio en la Columna de la victoria de Berlín, a unos 300 m de la Puerta de Brandeburgo. Se calcula que cerca de un millón de personas estuvieron allí presentes. Mike quiso conmemorar aquella ocasión con la creación de un tema, "Berlín 2000", que serviría para poner fin al concierto.

Después del concierto de Berlín, Mike se dedicó por completo a la creación de un juego de realidad virtual musical, llamado, en un principio "Sonic Reality", y que más tarde cambió su nombre a "Music VR". Su lanzamiento fue fijado en un principio para septiembre de 2000, pero se fue posponiendo hasta que salió acompañando a "Tr3s Lunas", lanzado el 3 de junio de 2002. "Tr3s Lunas" fue editado por WEA, pero no por la propia multinacional, como había sucedido desde "Tubular Bells II", sino por la filial WEA Music Spain, y fue el primero de un contrato de tres discos. 

La discográfica lanzó una intensa campaña de márketing, con abundantes anuncios en las televisiones nacionales y en las radiofórmulas. En esta campaña se catalogaba la música contenida como "chill-out", pese al continuo rechazo de Mike hacia dicho calificativo. En una entrevista realizada con motivo del lanzamiento del "Tubular Bells III" llegó a decir: "si quisiera hacer música relajante, dejaría el disco vacío".

La presentación del disco y de "Music VR" (el juego virtual) se realizó en la Ciudad de las Artes y de las Ciencias de Valencia, e incluyó una "fiesta chill-out" en L'Hemisfèric. Se vendieron más de 200.000 copias del disco sólo en España, y cifras similares en Alemania y otros países, por lo que se puede calificar de éxito comercial. Para este nuevo álbum, Mike apostó por una música más etérea, sustentada en melodías suaves y en una instrumentación electrónica. No faltan, por supuesto, sus habituales guitarras y sus teclados. Destaca sobre todo el sonido del saxofón y la canción "To be free".

En 2003 publicó "Tubular Bells 2003", regrabación de su exitoso "Tubular Bells" con la tecnología actual, pues, según Mike, la grabación original contenía muchísimos errores que las versiones remasterizadas no consiguieron evitar. También se sustituyeron las voces de Viv Stanshall por la del ex-Monty Python John Cleese, y además en su momento no contaba con los medios que creía adecuados para la obra. Este disco fue un éxito relativo, vendiendo poco más de 50.000 copias en España.

Después de esto, Mike se dedicó a la versión DVD de "Tubular Bells 2003", con sonido Dolby Digital 5.1 que, cuando fue editado, contuvo además las demos originales del "Tubular Bells" de 1971 (la maqueta que presentó a las discográficas y que fue rechazada). Posteriormente, hubo noticias de que pensaba regrabar "Ommadawn" en versión 5.1, pero en marzo de 2004 lanzó un nuevo videojuego, "Maestro".

En mayo de 2005 Mike Oldfield anunciaba que estaba en mitad de la grabación de un nuevo disco llamado 'Quicksilver'.

Otra de las cosas que sorprendieron es que, sin terminar el contrato con Warner Spain, Mike dejaba sin editar su tercer disco con ellos y firmaba por Universal, productora que se hizo con todo el catálogo de Virgin en 2008.

Durante los siguientes meses se dio más información acerca del disco, aparte de ir apareciendo nuevas fotos del músico con motivo del lanzamiento de la nueva obra, el cual llevaría el título de 'Light+Shade'. Mike ofreció dos discos en lugar de uno; el primero, denominado 'Light', constaba de canciones relajantes con sonidos chill out; el segundo, denominado 'Shade', constaba de canciones algo más oscuras y dance.

El doble disco se lanzó el 26 de septiembre en España, llegando al puesto 9 en listas. La promoción fue muy decepcionante: un solo anuncio de 10 segundos, visto pocas veces por la TV, y una entrevista hecha en su casa repartida de forma comercial. Como single (que no se llegó a comercializar) teníamos a 'Surfing', una de las canciones más pegadizas del disco.

En Inglaterra, la edición que se comercializó, aparte de llevar las 8 canciones por disco, llevaba una canción extra por disco. Además, una semana después apareció otra canción por internet acercándose algo más al estilo folk de sus inicios.

En marzo de 2006 Virgin publicó una nueva recopilación de 3 CD, "The Platinum Collection", con los temas clásicos de Oldfield, y en la que destacó la primera edición en formato digital de las versiones extendidas de sus éxitos de los años 80.

En el mes de diciembre de 2006, tras casi siete años de ausencia de los escenarios, Mike Oldfield participó en la gira Nokia Nights of the Proms por distintas ciudades alemanas, junto con artistas como OMD, John Miles, etc. Además también actuó en Marzo de 2007 en las ciudades españolas de Madrid y Valencia como figura principal de la primera celebración del Night of the Proms en España.

Mike Oldfield, que a fecha de 2007 aún seguía con Universal Music, manifestó, en numerosas entrevistas promocionales del recopilatorio anterior, que estaba trabajando para que su próxima obra fuera instrumental "a la antigua usanza", dividida en secciones, con instrumentos reales, más que los múltiples "samplers" de sus últimas obras. El proyecto se llama "Music of the Spheres". Obra de corte clásico, con la colaboración de Karl Jenkins (Soft Machine, Adiemus) y en el que Oldfield toca guitarra española y acústica, y piano. El disco fue grabado en Abbey Road Studios en Londres, por Oldfield y Jenkins en junio de 2007.

En un principio el disco iba a ser publicado en noviembre de 2007, sin embargo asuntos personales (su esposa estaba embarazada) retrasaron la fecha hasta enero de 2008, y luego a marzo de 2008. La razón del nuevo retraso es poder promocionar debidamente el álbum, cosa que Oldfield no quiso hacer hasta que hubiera pasado algún tiempo desde el nacimiento de su nuevo hijo. Aún con la fecha de lanzamiento algo lejana, en septiembre de 2007 el disco ya estaba disponible en diversas redes de intercambio.
A su vez, en 2007, "Virgin Books" publicó "", la autobiografía de Oldfield.
Finalmente, Mike Oldfield estrenaría su nuevo álbum "Music of the Spheres" el 7 de marzo de 2008 en el atrio del Museo Guggenheim de Bilbao .
Este concierto, en el que tocó junto a la Orquesta Sinfónica de Euskadi y la Sociedad Coral de Bilbao, sirvió como estreno mundial de su último disco, "Music of the Spheres".
El concierto, cerrado al público, se grabó y estuvo disponible en internet, a partir de la siguiente semana a su presentación, a través del iTunes de Apple. Junto a la guitarra de Oldfield, tocaron en el atrio 112 músicos y un coro formado sólo por mujeres.

El álbum, al igual que otros trabajos puramente instrumentales como Tubular Bells, Hergest Ridge u Ommadawn, está formado por dos partes de más de 20 minutos de duración cada una. Está compuesto para orquesta sinfónica, piano, coro, soprano y guitarra clásica que interpreta el propio Mike Oldfield. En general podría decirse que la obra pertenece al romanticismo musical, muy en la línea de trabajos anteriores como Hergest Ridge o Incantations. En la obra abundan los clásicos sonidos oldfianos: melodías minimalistas, cambios de texturas armónicas y tono melódico. Es una obra armoniosa y muy agradable al oído, con un tono ancestral muy apreciable. Pese a todo, no logra incorporar grandes dosis de originalidad. Ganó el Grammy 2008, por mejor composición musical, de Clásica.

En abril de 2008 se retira temporalmente, su dedicación a partir de ahí será disfrutar de su familia. Actualmente reside en Bahamas, aunque vivió en Ibiza y Mallorca y es un visitante habitual de estas islas. Recientemente ha comenzado a reeditar y remezclar sus grandes discos de la década de los setenta, incorporando en las reediciones material inédito y conciertos de los años 80, de indudable interés para los aficionados a su música.

Desde que termina la promoción de su último disco, dedica su tiempo productivo a hacer remezclas de sus primeros discos para las reediciones de su catálogo, programadas por Universal, haciendo curiosas remezclas de sus primeras tres obras, y redescubriendo rarezas que los fans tienen la suerte de ir disfrutando poco a poco en dichas reediciones.

Además, colabora con varios artistas y en varios discos, tales como Amazon Tribe, un disco con la banda sonora de un programa de televisión conducido por Bruce Parry. También colabora con el grupo de música electrónica York, en un tema de su disco Islanders, y con su hermano Terry Oldfield en su disco Journey Into Space donde colabora en 3 temas.

Pero Oldfield no vuelve a la productividad propiamente dicha hasta la ceremonia de apertura de los Juegos Olímpicos de Londres 2012. Evento para el cual, colabora con Danny Boyle y crea una nueva versión de 12 minutos de su Tubular Bells con el añadido final de In Dulci Jubilo y un solo de piano, y lo presenta en el evento, televisado para millones de espectadores. Gracias a ello, salen nuevas compilaciones de Oldfield llamadas , Classic Album Selection (Six Albums 1973-1980) y Music From The Opening Ceremony. (Durante la ceremonia, se anunció que el álbum Tubular Bells, alcanzó este año, la cifra oficial de 29 millones de álbumes vendidos en todo el mundo)situándose en el puesto 6 de las listas británicas.

Tras su colaboración en la inauguración de las Olimpiadas 2012, Oldfield vuelve a conceder entrevistas y habla de un nuevo disco a publicar en marzo de 2014, un disco de rock para el cual vuelve a contratar la ayuda de su asistente personal, Caroline Monk, que ya trabajó para él en 1996-1999. El disco se titula "Man On The Rocks", y está formado íntegramente por canciones de rock, en las que Mike Oldfield aporta sus ya legendarias guitarras eléctricas.

Todos los temas están interpretados por Luke Spiller, cantante de la banda inglesa The Struts. Los temas se sitúan dentro de la música pop, aunque algunos contienen sonoridades cercanas al folk y a la música electrónica. Además, se incluye una versión personal del tema religioso "I give my self away", del músico William McDowell. En la edición deluxe, Mike Oldfield incluye las versiones intrumentales de todos los temas y demos interpretadas por él mismo.

A finales de 2015, Mike Oldfield comienza a preparar su próximo disco, un álbum instrumental similar a sus trabajos más legendarios. Este disco estaría basado en una obra anterior muy apreciada por sus fans: "Ommadawn". Compuesto con sus habituales guitarras, teclados y percusión, el álbum contaría con dos partes largas de corte folk. Esta es la lista publicada de instrumentos interpretados por el propio Mike Oldfield:

Cuerdas: Acoustic Steel-Andy Manson Heron, Flamento-Paco de Lucía, Bass-Fender Roscoe Beck, Gibson SG Standard P90, Fender-Telecaster, Fender-Stratocaster, PRS Signature, Mandolins-Ovation and Washburn, Banjo, Ukele, Celtic Arp.

Teclados: OrganVox Continental, Farfisa, Hammond, Mellotron, Solina, Clavioline, Grandma's Pub Piano.

Percusión: Bodhran, African Table Drums, Glokenspiel.

Flautas: Penny Whistles In Bb, Cc, Eb, F and G.

Amplificador: Mesa Boogie Mark Five

Tras superar algunas dificultades técnicas debidas al paso de Huracán Matthew por las Islas Bahamas, el disco salió a la venta el 20 de Enero de 2017. En general, el disco tuvo muy buena acogida, tanto de crítica como de público. Se valoró enormemente su tono folk y la manera artesanal de concebirlo. Con 42 minutos de duración, Mike Oldfield incluye un buen puñado de melodías sustentadas en una variedad considerable de guitarras y percusiones. El tono del disco es agradable, con continuos cambios de ritmo y con un final realmente bello: una variación en forma de rondó celta del clásico tema "On Horseback".

También las ventas del disco fueron positivas. RTO llegó al cuarto puesto en Reino Unido y al tercer puesto en Alemania. En España y Escocia alcanzó puestos muy elevados. Ha sido, por lo tanto, uno de los trabajos más exitosos de Mike Oldfield hasta la fecha.




</doc>
<doc id="4516" url="https://es.wikipedia.org/wiki?curid=4516" title="2 de enero">
2 de enero

El 2 de enero es el segundo día del año del calendario gregoriano. Quedan 363 días para finalizar el año y 364 en los años bisiestos.














</doc>
<doc id="4517" url="https://es.wikipedia.org/wiki?curid=4517" title="3 de enero">
3 de enero

El 3 de enero es el tercer día del año del calendario gregoriano. Quedan 362 días para finalizar el año y 363 en los años bisiestos.












</doc>
<doc id="4518" url="https://es.wikipedia.org/wiki?curid=4518" title="4 de enero">
4 de enero

El 4 de enero es el cuarto día del año del calendario gregoriano. Quedan 361 días para finalizar el año y 362 en los años bisiestos.














</doc>
<doc id="4519" url="https://es.wikipedia.org/wiki?curid=4519" title="5 de enero">
5 de enero

El 5 de enero es el quinto día del año del calendario gregoriano. Quedan 360 días para finalizar el año y 361 en los años bisiestos.











</doc>
<doc id="4520" url="https://es.wikipedia.org/wiki?curid=4520" title="Galileo Galilei">
Galileo Galilei

Galileo Galilei (Pisa, Toscana; 15 de febrero de 1564-Arcetri, Toscana; 8 de enero de 1642) fue un astrónomo, filósofo, ingeniero, matemático y físico italiano, relacionado estrechamente con la revolución científica. Eminente hombre del Renacimiento, mostró interés por casi todas las ciencias y artes (música, literatura, pintura). Sus logros incluyen la mejora del telescopio, gran variedad de observaciones astronómicas, la primera ley del movimiento y un apoyo determinante a la «Revolución de Copérnico». Ha sido considerado como el «padre de la astronomía moderna», el «padre de la física moderna» y el «padre de la ciencia».

Su trabajo experimental es considerado complementario a los escritos de Francis Bacon en el establecimiento del moderno método científico y su carrera científica es complementaria a la de Johannes Kepler. Su trabajo se considera una ruptura de las teorías asentadas de la física aristotélica y su enfrentamiento con la Inquisición romana de la Iglesia católica se presenta como un ejemplo de conflicto entre religión y ciencia en la sociedad occidental.

Galileo, nacido en Pisa cuando esta pertenecía al Gran Ducado de Toscana, fue el mayor de seis hermanos, hijo de Giulia Ammannati y del músico y matemático florentino Vincenzo Galilei. Los Galilei, una familia de la baja nobleza que se ganaba la vida gracias al comercio, se encargaron de la educación de Galileo hasta los 10 años del niño, edad a la que pasó a cargo de un vecino religioso llamado Jacobo Borhini cuando sus padres se trasladaron a Florencia. Por mediación de este, el pequeño Galileo accedió al convento de Santa María de Vallombrosa de Florencia y recibió una formación piadosa que le llevó a plantearse unirse a la vida religiosa, algo que a su padre le disgustó. Por eso, Vincenzo Galilei —un hombre bastante escéptico— aprovechó una infección en el ojo que padecía su hijo para sacarle del convento alegando «falta de cuidados». Dos años más tarde, Galileo fue inscrito por su padre en la Universidad de Pisa, donde estudió medicina, filosofía y matemáticas.

Si bien su padre quería que Galileo se dedicara a la medicina, en 1583 Galileo se inició en la matemática de la mano de Ostilio Ricci, un amigo de la familia, alumno de Tartaglia. Ricci tenía la costumbre, rara en esa época, de unir la teoría a la práctica experimental.

Atraído por la obra de Euclides, sin ningún interés por la medicina y todavía menos por las disputas escolásticas y la filosofía aristotélica, Galileo reorienta sus estudios hacia las matemáticas. Desde entonces, se siente seguidor de Pitágoras, de Platón y de Arquímedes, y opuesto al aristotelismo. Todavía estudiante, descubre la ley de la isocronía de los péndulos, primera etapa de lo que será el descubrimiento de una nueva ciencia: la mecánica. Dentro de la corriente humanista, redacta también un panfleto feroz contra el profesorado de su tiempo. Toda su vida, Galileo rechazará el ser comparado a los profesores de su época, lo que le supondrá numerosos enemigos.

Dos años más tarde, retorna a Florencia sin diploma, pero con grandes conocimientos y una gran curiosidad científica.

Galileo comienza por demostrar muchos teoremas sobre el centro de gravedad de ciertos sólidos en "Theoremata circa centrum gravitatis solidum" y emprende en 1586 la reconstitución de la balanza hidrostática de Arquímedes o "bilancetta". Al mismo tiempo, continúa con sus estudios sobre las oscilaciones del péndulo pesante e inventa el pulsómetro. Este aparato permite ayudar a medir el pulso y aporta una escala de tiempo, que no existía aún en la época. También comienza sus estudios sobre la caída de los cuerpos.

En 1588, es invitado por la Academia florentina a presentar dos lecciones sobre «la forma, el lugar y la dimensión del infierno de Dante Alighieri».

Paralelamente a sus actividades, busca un empleo de profesor en una universidad; se encuentra entonces con grandes personajes, como el padre jesuita Christopher Clavius, excelencia de la matemática en el Colegio pontifical. Coincide también con el matemático Guidobaldo del Monte. Este último recomienda a Galileo ante el duque Fernando I de Médici, que lo nombra para la cátedra de matemáticas de la universidad de Pisa por 60 escudos de oro al año. Su lección inaugural tendrá lugar el 12 de noviembre de 1589.

En 1590 y 1591, descubre la cicloide y se sirve de ella para dibujar arcos de puentes. Igualmente experimenta sobre la caída de los cuerpos y redacta su primera obra de mecánica, "De motu". La realidad es que estas «experiencias» son puestas en duda hoy por hoy y podrían ser una invención de su primer biógrafo, Vincenzo Viviani. Este volumen contiene ideas nuevas para la época, pero expone también, evidentemente, los principios de la escuela aristotélica y el sistema de Ptolomeo. Galileo los enseñará durante mucho tiempo después de estar convencido de la exactitud del sistema copernicano, falto de pruebas tangibles.

En 1592 se trasladó a la Universidad de Padua y ejerció como profesor de geometría, mecánica y astronomía hasta 1610. La marcha de Pisa se explica por diferencias con uno de los hijos del gran duque Fernando I de Médici.

Padua pertenecía a la poderosa República de Venecia, lo que dio a Galileo una gran libertad intelectual, pues la Inquisición no era poderosa allí. Incluso si Giordano Bruno había sido entregado por los patricios de la república a la Inquisición, Galileo podía efectuar sus investigaciones sin muchas preocupaciones.

Enseña mecánica aplicada, matemática, astronomía y arquitectura militar. Después de la muerte de su padre en 1591, Galileo debe ayudar a cubrir las necesidades de la familia. Comienza a dar numerosas clases particulares a los estudiantes ricos, a los que aloja en su casa. Pero no es un buen gestor y solo la ayuda financiera de sus protectores y amigos le permiten equilibrar sus cuentas.

En 1599, Galileo participa en la fundación de la Accademia dei Ricovrati con el abad Federico Cornaro.

El mismo año, Galileo se encuentra con Marina Gamba, una atractiva joven veneciana con la cual mantendrá una relación hasta 1610 (no se casan ni viven juntos). En 1600, nace su primera hija Virginia, seguida por su hermana Livia en 1601; luego un hijo, Vincenzo, en 1606. Después de la separación (no conflictiva) de la pareja, Galileo se encarga de su hijo y envía sus hijas a un convento, ya que el abuelo las sentencia de «incasables» al ser ilegítimas. En cambio el varón Vincenzo será legitimado y se casará con Sestilia Bocchineri.

1604 fue un año "mirabilis" para Galileo:


Retomando sus estudios sobre el movimiento, Galileo «mostró» que los proyectiles seguían, en el vacío, trayectorias parabólicas. Hizo falta la ley de la gravitación universal de Newton para generalizar los misiles balísticos, donde las trayectorias son en efecto elípticas.

En 1606, Galileo construye su primer termoscopio, primer aparato de la historia que permite comparar de manera objetiva el nivel de calor y de frío. Ese mismo año, Galileo y dos de sus amigos caen enfermos el mismo día de una misma enfermedad infecciosa. Solo sobrevive Galileo, que permanecerá lisiado de reumatismo por el resto de sus días.

En los dos años que siguen, el sabio estudia las estructuras de los imanes. Actualmente se pueden contemplar sus trabajos en el museo de historia de Florencia.

En mayo de 1609, Galileo recibe de París una carta del francés Jacques Badovere, uno de sus antiguos alumnos, quien le confirma un rumor insistente: la existencia de un telescopio que permite ver los objetos lejanos. Fabricado en Holanda, este telescopio habría permitido ya ver estrellas invisibles a simple vista. Con esta única descripción, Galileo, que ya no da cursos a Cosme II de Médicis, construye su primer telescopio. Al contrario que el telescopio holandés, este no deforma los objetos y los aumenta 6 veces, o sea, el doble que su oponente. También es el único de la época que consigue obtener una imagen derecha gracias a la utilización de una lente divergente en el ocular. Este invento marca un giro en la vida de Galileo.

El 21 de agosto, apenas terminado su segundo telescopio (aumenta ocho o nueve veces), lo presenta al Senado de Venecia. La demostración tiene lugar en la cima del Campanile de la plaza de San Marco. Los espectadores quedan entusiasmados: ante sus ojos, Murano, situado a 2km y medio, parece estar a 300 m solamente.

Galileo ofrece su instrumento y lega los derechos a la República de Venecia, muy interesada por las aplicaciones militares del objeto. En recompensa, es confirmado de por vida en su puesto de Padua y sus emolumentos se duplican. Se libera por fin de las dificultades financieras.

Sin embargo, contrario a sus alegaciones, no dominaba la teoría óptica y los instrumentos fabricados por él son de calidad muy variable. Algunos telescopios son prácticamente inutilizables (al menos en observación astronómica). En abril de 1610, en Bolonia, por ejemplo, la demostración del telescopio es desastrosa, como así lo informa Martin Horky en una carta a Kepler.

Galileo reconoció en marzo de 1610 que, entre los más de 60 telescopios que había construido, solamente algunos eran adecuados.

Durante el otoño, Galileo continuó desarrollando su telescopio. En noviembre, fabrica un instrumento que aumenta veinte veces. Emplea tiempo para volver su telescopio hacia el cielo. Rápidamente, observando las fases de la Luna, descubre que este astro no es perfecto como lo creía la teoría aristotélica. La física aristotélica, que poseía autoridad en esa época, distinguía dos mundos:

Galileo, por su parte, observó una zona transitoria entre la sombra y la luz, el "terminador", que no era para nada regular, lo que por consiguiente invalidaba la teoría aristotélica y afirma la existencia de montañas en la Luna. Galileo incluso estima su altura en 7000 metros, más que la montaña más alta conocida en la época. Hay que decir que los medios técnicos de la época no permitían conocer la altitud de las montañas terrestres sin fantasías. Cuando Galileo publica su "Sidereus nuncius" piensa que las montañas lunares son más elevadas que las de la Tierra, si bien en realidad son equivalentes.

En pocas semanas, descubrirá la naturaleza de la Vía láctea, cuenta las estrellas de la constelación de Orión y constata que ciertas estrellas visibles a simple vista son, en verdad, cúmulos de estrellas. Galileo observa los anillos de Saturno pero no los identifica como tales sino como extraños «apéndices» (como dos asas), no será hasta medio siglo más tarde cuando Huygens utilizando telescopios más perfectos, pueda observar la verdadera forma de los anillos. Estudia igualmente las manchas solares.

El 7 de enero de 1610, Galileo hace un descubrimiento capital: percibe tres estrellas pequeñas en la periferia de Júpiter. Después de varias noches de observación, descubre que son cuatro y que giran alrededor del planeta. Se trata de los satélites de Júpiter llamados hoy "satélites galileanos": Calixto, Europa, Ganimedes e Ío. A fin de protegerse de la necesidad y sin duda deseoso de retornar a Florencia, Galileo llamará a estos satélites por algún tiempo los «astros mediceos» I, II, III y IV, en honor de Cosme II de Médicis, su antiguo alumno y gran duque de Toscana. Galileo no ha dudado entre "Cósmica sidera" y "Medicea sidera". El juego de palabras entre cósmica y Cosme es evidentemente voluntario y es solo después de la primera impresión que retiene la segunda denominación (el nombre actual de estos satélites se debe sin embargo al astrónomo Simon Marius, quien los bautizó de esta manera a sugerencia de Johannes Kepler, si bien durante dos siglos se empleó la nomenclatura de Galileo).

El 4 de marzo de 1610, Galileo publica en Florencia sus descubrimientos dentro de "El mensajero de las estrellas" ("Sidereus nuncius"), resultado de sus primeras observaciones estelares.

Para él, Júpiter y sus satélites son un modelo del sistema solar. Gracias a ellos, piensa poder demostrar que las órbitas de cristal de Aristóteles no existen y que todos los cuerpos celestes no giran alrededor de la Tierra. Es un golpe muy duro a los aristotélicos. Así mismo, corrige también a ciertos copernicanos que pretenden afirmar que todos los cuerpos celestes giran alrededor del Sol.

El 10 de abril, muestra estos astros a la corte de Toscana. Es un triunfo. El mismo mes, da tres cursos sobre el tema en Padua. Siempre en abril, Johannes Kepler ofrece su apoyo a Galileo. El astrónomo alemán no confirmará verdaderamente este descubrimiento —pero con entusiasmo— hasta septiembre, gracias a una lente ofrecida por Galileo en persona.

El 10 de julio de 1610, Galileo deja Venecia para trasladarse a Florencia.

A pesar de los consejos de sus amigos Sarpi y Sagredo, que temen que su libertad sea restringida, él ha, en efecto, aceptado el puesto de Primer matemático de la Universidad de Pisa (sin carga de cursos, ni obligación de residencia) y aquel de Primer matemático y Primer filósofo del gran duque de Toscana.

El 25 de julio de 1610, Galileo orienta su telescopio hacia Saturno y descubre su extraña apariencia. Serán necesarios 50 años e instrumentos más poderosos para que Christiaan Huygens comprenda la naturaleza de los anillos de Saturno.

El mes siguiente, Galileo encuentra una manera de observar el Sol en el telescopio y descubre las manchas solares. Les da una explicación satisfactoria.

En septiembre de 1610, prosiguiendo con sus observaciones, descubre las fases de Venus. Para él, es una nueva prueba de la verdad del sistema copernicano, pues es fácil de interpretar este fenómeno gracias a la hipótesis heliocéntrica, puesto que es mucho más difícil de hacerlo basándose en la hipótesis geocéntrica.

Fue invitado el 29 de marzo de 1611 por el cardenal Maffeo Barberini (futuro Urbano VIII) a presentar sus descubrimientos al Colegio pontifical de Roma y en la joven Academia de los Linces. Galileo permanecerá dentro de la capital pontifical un mes completo, durante el cual recibe todos los honores. La Academia de los Linces le reserva un recibimiento entusiasta y le admite como su sexto miembro. Desde ese momento, el lince de la academia adornará el frontispicio de todas las publicaciones de Galileo.

El 24 de abril de 1611, el Colegio Romano, compuesto de jesuitas de los cuales Christopher Clavius es el miembro más eminente, confirma al cardenal Roberto Belarmino que las observaciones de Galileo son exactas. No obstante, los supuestos sabios se guardan bien de confirmar o de denegar las conclusiones hechas por el florentino.

Galileo retorna a Florencia el 4 de junio.

Según Bertrand Russell, el conflicto entre Galileo y la Iglesia católica fue un conflicto entre el razonamiento inductivo y el razonamiento deductivo. La inducción basada en la observación de la realidad, propia del método científico que Galileo usó por primera vez, ofreciendo pruebas experimentales de sus afirmaciones, y publicando los resultados para que pudiesen ser repetidas, frente a la deducción, a partir en última instancia de argumentos basados en la autoridad, bien de filósofos como Aristóteles o de las Sagradas Escrituras. Así, en relación a su defensa de la teoría heliocéntrica, Galileo siempre se basó en datos extraídos de observaciones experimentales que demostraban la validez de sus argumentos. En resumen, y a pesar de que, en ocasiones, se sostiene que Galileo no demostró el movimiento de la Tierra, las pruebas de carácter experimental, publicadas por él mismo de su argumentación son las siguientes:








Galileo parece ir de triunfo en triunfo y convence a todo el mundo. Por tanto, los partidarios de la teoría geocéntrica se convierten en enemigos encarnizados y los ataques contra él comienzan con la aparición de "Sidereus nuncius". Ellos no pueden permitirse el perder la afrenta y no quieren ver su ciencia puesta en cuestión.

Además, los métodos de Galileo, basados en la observación y la experiencia en vez de la autoridad de los partidarios de las teorías geocéntricas (que se apoyan sobre el prestigio de Aristóteles), están en oposición completa con los suyos, hasta tal punto que Galileo rechaza compararse con ellos.

Al principio, solo se tratan de escaramuzas. Pero Sagredo escribe a Galileo, recién llegado a Florencia: «El poder y la generosidad de vuestro príncipe [el duque de Toscana] permiten esperar que él sepa reconocer vuestra dedicación y vuestro mérito; pero en los mares agitados actuales, ¿quién puede evitar de ser, yo no diría hundido, pero sí al menos duramente agitado por los vientos furiosos de los celos?».

La primera flecha viene de Martin Horky, discípulo del profesor Magini y enemigo de Galileo. Este asistente publica en junio de 1610, sin consultar a su maestro, un panfleto contra el "Sidereus nuncius". Exceptuando los ataques personales, su argumento principal es el siguiente: «Los astrólogos han hecho sus horóscopos teniendo en cuenta todo aquello que se mueve en los cielos. Por lo tanto los astros mediceos no sirven para nada y, Dios no crea cosas inútiles, estos astros no pueden existir».

Horky es ridiculizado por los seguidores de Galileo, que responden que estos astros sirven para una cosa: hacerle enfadar. Convertido en el hazmerreír de la universidad, Horky finalmente es recriminado por su maestro: Magini no tolera un fallo tan claro. En el mes de agosto, un tal Sizzi intenta el mismo tipo de ataque con el mismo género de argumentos, sin ningún éxito.

Una vez que las observaciones de Galileo fueron confirmadas por el Colegio Romano, los ataques cambiaron de naturaleza. Ludovico delle Colombe ataca sobre el plan religioso y se pregunta si Galileo cuenta con interpretar la Biblia para ponerla de acuerdo con sus teorías. En esta época en efecto, antes de los trabajos exegéticos del siglo XIX, un salmo () da a entender una cosmología geocéntrica (dentro de la línea: «Tú has fijado la Tierra firme e inmóvil»).

El cardenal Roberto Belarmino —quien había participado en el proceso a Giordano Bruno— ordenó que la Inquisición realizase una investigación discreta sobre Galileo a partir de junio de 1611.

Galileo, de retorno a Florencia, es inatacable desde el punto de vista astronómico. Sus adversarios van entonces a criticar su teoría de los cuerpos flotantes. Galileo pretende que el hielo flota porque es más ligero que el agua, mientras que los aristotélicos piensan que flota porque es de su naturaleza el flotar (física cuantitativa y matemática de Galileo contra física cualitativa de Aristóteles). El ataque tendrá lugar durante un almuerzo en la mesa de Cosme II en el mes de septiembre de 1611.

Galileo se opone a los profesores de Pisa y en especial al mismo Delle Combe, durante lo que se denomina la «batalla de los cuerpos flotantes». Galileo sale victorioso del intercambio. Varios meses más tarde, sacará una obra en la que se presentará su teoría.

Además de estos asuntos, Galileo continúa con sus investigaciones. Su sistema de determinación de longitudes es propuesto en España por el embajador de Toscana.

En 1612, emprende una discusión con Apelles Latens Post Tabulam (seudónimo del jesuita Christoph Scheiner), un astrónomo alemán, sobre el tema de las manchas solares. Apelles defiende la incorruptibilidad del Sol argumentando que las manchas son en realidad conjuntos de estrellas entre el Sol y la Tierra. Galileo demuestra que las manchas están sobre la superficie misma del Sol, o tan próximas que no se puede medir su altitud. La Academia de los Linces publicará esta correspondencia el 22 de marzo de 1613 con el título de "Istoria e dimostrazioni intorno alle macchie solari e loro accidenti". Scheiner terminará por adherirse a la tesis galileana.

El 2 de noviembre de 1612, las querellas reaparecen. El dominico Niccolo Lorini, profesor de historia eclesiástica en Florencia, pronuncia un sermón resueltamente opuesto a la teoría de la rotación de la Tierra. Sermón sin consecuencias particulares, pero que marca los comienzos de los ataques religiosos. Los opositores utilizan el pasaje bíblico en el "Libro de Josué" () en el cual Josué detiene el movimiento del Sol y de la Luna, como arma teológica contra Galileo.

En diciembre de 1613, el profesor Benedetto Castelli, antiguo alumno de Galileo y uno de sus colegas en Pisa, es encargado por la duquesa Cristina de Lorena de probar la ortodoxia de la doctrina copernicana. Galileo vendrá en ayuda de su discípulo escribiéndole una carta el 21 de diciembre de 1613 (traducida como "Galileo, diálogos y cartas selectas") sobre la relación entre ciencia y religión. La gran duquesa se tranquiliza, pero la controversia no se debilita.

Galileo mientras tanto continúa con sus trabajos. Del 12 al 15 de noviembre, recibe a Jean Tarde, a quien presenta su microscopio y sus trabajos de astronomía.

El 20 de diciembre, el padre Caccini ataca muy violentamente a Galileo en la iglesia Santa Maria Novella. El 6 de enero de 1614 un copernicano, el carmelita Paolo Foscarini, publica una carta tratando positivamente la opinión de los pitagóricos y de Copérnico sobre la movilidad de la Tierra. Él percibe el sistema copernicano como una realidad física. La controversia toma una amplitud tal que el cardenal Belarmino debe intervenir el 12 de abril. Este escribe una carta a Foscarini donde condena sin equívocos la tesis heliocéntrica en ausencia de refutación concluyente del sistema geocéntrico. En dicha carta escribe:

En 1614, conoce a Juan Bautista Baliani, físico genovés, que será su amigo y correspondiente durante largos años.

Como reacción, Galileo escribe a Cristina de Lorena una carta extensa en la cual desarrolla admirablemente sus argumentos en favor de la ortodoxia del sistema copernicano. Esta carta, escrita hacia abril de 1615 y también muy difundida, es una pieza esencial de la documentación. Ahí se evidencian los pasajes de las escrituras que poseen problemas desde un punto de vista cosmológico.

A pesar de ello, Galileo es obligado a presentarse en Roma para defenderse contra las calumnias y sobre todo para tratar de evitar una prohibición de la doctrina copernicana. Pero le falta la prueba irrefutable de la rotación de la Tierra para apoyar sus requerimientos. Su intervención llega demasiado tarde: Lorini, por carta de denuncia, ya había avisado a Roma de la llegada de Galileo y el Santo Oficio ya había comenzado la instrucción del caso.

El 8 de febrero de 1616, Galileo envía su teoría de las mareas ("Discorso del flusso e reflusso") al cardenal Orsini. Esta teoría (a la cual se le ha reprochado durante mucho tiempo el estar en contradicción con el principio de la inercia enunciado por el mismo Galileo, y que solo puede explicar pequeños componentes del fenómeno) pretendía demostrar que el movimiento de la Tierra producía las mareas, mientras que los astrónomos jesuitas ya postulaban con acierto que las mareas eran producidas por la atracción de la Luna.

A pesar de pasar dos meses removiendo cielo y tierra para impedir lo inevitable, es convocado el 16 de febrero de 1616 por el Santo Oficio para el examen de las proposiciones de censura. Es una catástrofe para él. La teoría copernicana es condenada como «una insensatez, un absurdo en filosofía, y formalmente herética».

El 25 y 26 de febrero de 1616, la censura es ratificada por la Inquisición y por el papa Paulo V.

Aunque no se le inquieta personalmente, se ruega a Galileo exponer su tesis presentándola como una hipótesis y no como un hecho comprobado, cosa que no hizo a pesar de que no le fue posible demostrar dicha tesis. Esta petición se extiende a todos los países católicos.

La intransigencia de Galileo, que rechaza la equivalencia de las hipótesis copernicana y de Ptolomeo, pudo haber precipitado los hechos. En un estudio del proceso por Paul Feyerabend (véase por ejemplo el "Adiós a la razón") se argumenta que la actitud del inquisidor (Roberto Belarmino) fue al menos tan científica como la de Galileo, siguiendo criterios modernos.

Este asunto afecta a Galileo profundamente. Sus enfermedades le van a atormentar durante los dos años siguientes y su actividad científica se reduce. Solo retoma su estudio de la determinación de las longitudes en el mar. Sus dos hijas, Arcángela y Celeste, entran en órdenes religiosas.

En 1618, observa el paso de tres cometas, fenómeno que relanza la polémica sobre la incorruptibilidad de los cielos.

En 1619, el padre jesuita Horazio Grassi publica "De tribus cometis ani 1618 disputatio astronomica". En él defiende el punto de vista de Tycho Brahe sobre las trayectorias elípticas de los cometas. Galileo responde al principio por la intermediación de su alumno Mario Guiducci que publica en junio de 1619 "Discorso delle comete" donde desarrolla una teoría errónea sobre los cometas, afirmando que solo se trataba de ilusiones ópticas, incluyendo causas de fenómenos meteorológicos. Los astrónomos jesuitas del Observatorio Vaticano decían, en cambio, que eran objetos celestes reales.

En octubre, Horazio Grassi ataca a Galileo en un panfleto más hipócrita: sobre consideraciones científicas, se mezclan las insinuaciones religiosas malvadas, muy peligrosas en tiempos de la Contrarreforma.

Es entonces cuando Galileo, animado por su amigo el cardenal Maffeo Barberini y sostenido por la Academia de los Linces, responderá con ironía en "Il saggiatore". Grassi, uno de los sabios jesuitas más importantes, es ridiculizado.

Mientras tanto, Galileo había comenzado su estudio de los satélites de Júpiter. Por culpa de dificultades técnicas se ve obligado a abandonar el cálculo de sus efemérides. Galileo se ve cubierto de honores en 1620 y 1622.

El 28 de agosto de 1620, el cardenal Barberini envía a su amigo el poema "Adulatio perniciosa" que él ha compuesto en su honor. El 20 de enero de 1621, Galileo se convierte en cónsul de la Academia Florentina. El 28 de febrero, Cosme II, el protector de Galileo, muere súbitamente.

En 1622, en Fráncfort, aparece una "Apología de Galileo" redactada por Tommaso Campanella en 1616. Un defensor bastante poco confiable, puesto que Campanella ya está condenado por herejía.

El 6 de agosto de 1622, el cardenal Maffeo Barberini es elegido papa bajo el nombre de Urbano VIII. El 3 de febrero de 1623 Galileo recibe la autorización para publicar su "Saggiatore" que dedica al nuevo papa. La obra aparece el 20 de octubre de 1623. Gracias a las cualidades polémicas (y literarias) de la obra, se aseguró el éxito en la época. No permanece más que unos meses allí, pero Galileo se convierte de alguna manera en el representante de los círculos intelectuales romanos en rebelión contra el conformismo intelectual y científico impuesto por los jesuitas.

Los años siguientes son bastante tranquilos para Galileo a pesar de los ataques de los aristotélicos. Aprovecha para perfeccionar su microscopio compuesto (septiembre de 1624), y pasa un mes en Roma donde es recibido numerosas veces por Urbano VIII. Este último le da la idea de su próximo libro "Diálogo sobre los dos sistemas del mundo", obra que presenta de manera imparcial a la vez el sistema aristotélico y el sistema copernicano. Encarga escribirla a Galileo.

En 1626, Galileo prosigue sus investigaciones sobre la estructura del imán. También recibe la visita de Élie Dodati, que llevará las copias de sus manuscritos a París. En marzo de 1628, Galileo cae gravemente enfermo y está a punto de morir.

El año siguiente, sus adversarios intentan privarle de la asignación que recibe de la Universidad de Pisa, pero la maniobra falla.

Hasta 1631 Galileo consagra su tiempo a la escritura del "Diálogo" y a intentar que este sea admitido por la censura. La obra se imprime en febrero de 1632. Los ojos de Galileo comienzan a traicionarle en marzo y abril. Las posiciones del teólogo valón Libert Froidmont (de la Universidad Católica de Lovaina) esclarecen bien todos los equívocos de la condena de Galileo.

El 21 de febrero de 1632, Galileo, protegido por el papa Urbano VIII y el Fernando II de Médici, publica en Florencia su diálogo de los "Massimi sistemi" ("Diálogo sobre los principales sistemas del mundo") ("Dialogo sopra i due massimi sistemi del mondo"), donde se burla implícitamente del geocentrismo de Ptolomeo. El "Diálogo" es a la vez una revolución y un verdadero escándalo. El libro es en efecto abiertamente pro-copernicano, ridiculizando audazmente la interdicción de 1616 (que no será levantada hasta 1812: a verificar).

El "Diálogo" se desarrolla en Venecia durante cuatro jornadas entre tres interlocutores: Filipo Salviati, un florentino seguidor de Copérnico, Giovan Francesco Sagredo, un veneciano ilustrado sin tomar partido, y Simplicio, un mediocre defensor de la física aristotélica, un personaje que algunos quieren ver inspirado en Urbano VIII. Pero, mientras que se le reprocha el carácter ostensiblemente peyorativo del nombre, Galileo responde que se trata de Simplicio de Cilicia. Muchos autores coinciden en que Galileo no esperaba estas reacciones ni que el papa reaccionara posicionándose entre sus enemigos.

En estos cuatro días de discusión, Galileo, aunque lo tenía prohibido por el decreto de 1616, presenta dos nuevas pruebas de carácter experimental y observacional a favor de la teoría copernicana. La basada en el movimiento de las mareas, errónea, y la basada en la rotación de las manchas solares, acertada y que refutaba tanto la ptolemaica (ya descartada por las fases de Venus), como la de Tycho Brahe, en cuya defensa se habían refugiado los jesuitas del Colegio Romano. Esto motivó la intervención de la Inquisición, que solo le permitía a Galileo el presentar la teoría como mera hipótesis, y no presentar pruebas a su favor.

Por otra parte, Galileo tiene en Roma poderosos enemigos, fundamentalmente entre los jesuitas del Colegio Romano, especialmente Christoph Scheiner y Orazio Grassi, quienes se consideraban la rama intelectual de la Iglesia, y quienes pudieron ser quienes iniciaron el rumor de que el papa Urbano era, en realidad, el simpático pero poco brillante Simplicio. Esto fue muy perjudicial para Galileo, pues en Roma era muy conocida la enorme autoestima del papa. Por otro lado, tampoco ayudó a Galileo el escribir su citada obra en lengua vulgar, en vez de hacerlo en el idioma culto utilizado entonces entre los hombres de ciencia, el latín, pues a la Iglesia no le gustaba que las obras llegaran directamente al hombre de la calle.

El proceso realizado por la Inquisición fue irregular, pues a pesar de que el libro había pasado el filtro de los censores, se le acusaba de introducir doctrinas heréticas. Puesto que esto dejaba en mal lugar a dichos censores, la acusación oficial fue de violar la prohibición de 1616.

Galileo fue requerido para presentarse en Roma, sin embargo, estaba sumamente enfermo y agotado, y ya contaba 68 años, por lo que se demoró en acudir, además de que en esos momentos existía una epidemia de peste en Italia. Aunque presentó certificados médicos alegando estas circunstancias, a finales de diciembre de 1632 fue conminado a acudir inmediatamente de grado o por fuerza. Que no era voluntad suya el retrasar el viaje lo prueba el que, debido a la peste, fuera retenido por espacio de 42 días para abandonar la Toscana. Por otra parte, el trato recibido durante el proceso fue correcto, alojado en las habitaciones del palacio de la Inquisición, y recibiendo todas las atenciones que necesitaba, si bien no fue ningún trato especial distinto al resto de otras personalidades importantes y personas de su condición.

El proceso comenzó con un interrogatorio el 9 de abril de 1633, donde Galileo no reconoce haber recibido expresamente ninguna orden del cardenal Bellarmino. Por otra parte, dicha orden aparece en un acta que no estaba firmada ni por el cardenal ni por el propio Galileo. Con pruebas endebles es difícil realizar una condena, por lo que es conminado a confesar, con amenazas de tortura si no lo hace y promesas de un trato benevolente en caso contrario. Galileo acepta confesar, lo que lleva a cabo en una comparecencia ante el tribunal el 30 de abril. Una vez obtenida la confesión, se produce la condena el 21 de junio. Al día siguiente, en el convento romano de Santa Maria sopra Minerva, le es leída la sentencia, donde se le condena a prisión perpetua, y se le conmina a abjurar de sus ideas, cosa que hace seguidamente. Tras la abjuración el papa conmuta la prisión por arresto domiciliario de por vida.

Giuseppe Baretti afirmó que después de la abjuración Galileo dijo la famosa frase "Eppur si muove" («Y sin embargo se mueve»), pero según Stillman Drake Galileo no pronunció la famosa frase en ese momento ya que no se encontraba en situación de libertad y sin duda era desafiante hacerlo ante el tribunal de cardenales de la Inquisición. Para Stillman si esa frase fue pronunciada lo fue en otro momento.

El texto de la sentencia fue difundido por doquier: en Roma el 2 de julio y en Florencia el 12 de agosto. La noticia llega a Alemania a finales de agosto, en Bélgica en septiembre. Los decretos del Santo Oficio no se publicarán jamás en Francia, pero, prudentemente, René Descartes renuncia a la publicación de su "Mundo".

Muchos (entre ellos Descartes), en la época, pensaron que Galileo era la víctima de una confabulación de los jesuitas, que se vengaban así de la afrenta sufrida por Horazio Grassi en el "Saggiatore".

Galileo permanece confinado en su residencia en su casa de Florencia desde diciembre de 1633 a 1638. Allí recibe algunas visitas, lo que le permitió que alguna de sus obras en curso de redacción pudiera cruzar la frontera. Estos libros aparecieron en Estrasburgo y en París en traducción latina.

En 1636, Luis Elzevier recibe un boceto de los "Discursos sobre dos nuevas ciencias" de la parte del maestro florentino. Este es el último libro que escribirá Galileo; en él establece los fundamentos de la mecánica en tanto que ciencia y que marca así el fin de la física aristotélica. Intenta también establecer las bases de la resistencia de los materiales, con menos éxito. Terminará este libro justo antes de perder el uso de su ojo derecho el 4 de julio de 1637.

El 2 de enero de 1638, Galileo pierde definitivamente la vista. Por aquel entonces, Dino Peri había recibido la autorización para vivir en casa de Galileo para asistirlo junto con el padre Ambrogetti que tomará nota de la sexta y última parte de los "Discursos". Esta parte no aparecerá hasta 1718. La obra completa aparecerá en julio de 1638 en Leiden (Países Bajos) y en París. Será leída por las más grandes personalidades de la época. Descartes por ejemplo enviará sus observaciones a Mersenne, el editor parisino.

Galileo, entre tanto, ha recibido autorización para instalarse cerca del mar, en su casa de San Giorgio. Permanecerá allí hasta su muerte, rodeado de sus discípulos (Viviani, Torricelli, Peri, etc.), trabajando en la astronomía y otras ciencias. A fines de 1641, Galileo trata de aplicar la oscilación del péndulo a los mecanismos del reloj.

Unos días más tarde, el 8 de enero de 1642, Galileo muere en Arcetri a la edad de 77 años. Su cuerpo es inhumado en Florencia el 9 de enero. Un mausoleo será erigido en su honor el 13 de marzo de 1736 en la iglesia de la Santa Cruz de Florencia.

Galileo, especialmente en su obra "Diálogo sobre los principales sistemas del mundo" (1633), cuestionó y resquebrajó los principios sobre los que hasta ese momento se había sustentado el conocimiento e introdujo las bases del método científico que a partir de entonces se fue consolidando. En filosofía aparecieron corrientes de pensamiento racionalista (Descartes) y empirista (Francis Bacon y Robert Boyle).

La teoría del heliocentrismo, suponía cuestionar que los textos bíblicos (como por ejemplo que la Tierra fuera el centro del Universo —geocentrismo—) fueran válidos para una verdadera ciencia. Las consecuencias no solo fueron para la teología y la ciencia incipiente, también se produjeron consecuencias metafísicas y ontológicas, que producirán reacciones de los científicos.

El papa Benedicto XIV autoriza las obras sobre el heliocentrismo en la primera mitad del siglo XVIII, y esto en dos tiempos:


A partir de Pío XII se comienza a rendir homenaje al gran sabio que era Galileo. En 1939 este papa, en su primer discurso a la Academia Pontificia de las Ciencias, a pocos meses de su elección al papado, describe a Galileo como «el más audaz héroe de la investigación... sin miedos a lo preestablecido y los riesgos a su camino, ni temor a romper los monumentos». Su biógrafo de 40 años, el profesor Robert Leiber, escribió: «Pío XII fue muy cuidadoso en no cerrar ninguna puerta a la ciencia prematuramente. Fue enérgico en ese punto y sintió pena por el caso de Galileo».

En 1979 y en 1981, el papa Juan Pablo II encarga a una comisión estudiar la controversia de Ptolomeo-Copérnico de los siglos XVI y XVII. Juan Pablo II considera que no se trataba de rehabilitación.

El 31 de octubre de 1992, Juan Pablo II rinde una vez más homenaje al sabio durante su discurso a los partícipes en la sesión plenaria de la Academia Pontificia de las Ciencias. En él reconoce claramente los errores de ciertos teólogos del siglo XVII en el asunto.

El papa Juan Pablo II pidió perdón por los errores que hubieran cometido los hombres de la Iglesia a lo largo de la historia. En el caso de Galileo propuso una revisión honrada y sin prejuicios en 1979, pero la comisión que nombró al efecto en 1981 y que dio por concluidos sus trabajos en 1992, confirmó una vez más la tesis de que Galileo carecía de argumentos científicos para demostrar el heliocentrismo y sostuvo la inocencia de la Iglesia como institución y la obligación de Galileo de reconocer y prestar obediencia a su magisterio, justificando la condena y evitando una rehabilitación plena. El propio cardenal Ratzinger, prefecto de la Congregación para la Doctrina de la Fe, lo expresó rotundamente el 15 de febrero de 1990 en la Universidad romana de La Sapienza, cuando en una conferencia hizo suya la afirmación del "filósofo agnóstico y escéptico" Paul Feyerabend:

Estas declaraciones serán objeto de una fuerte polémica cuando en el año 2008 el ya papa Benedicto XVI tenga que renunciar a una visita a la Universidad de La Sapienza de Roma.

Es habitual en Ratzinger la cita de autores, a priori contrarios a las posturas de la Iglesia, para reforzar sus tesis, de la misma forma que cita a Paul Feyerabend al que califica de «filósofo agnóstico y escéptico», cita también al que califica de «marxista romántico» Ernst Bloch para justificar científicamente, acogiéndose a la teoría de la relatividad, la corrección de la condena a Galileo no solamente contextualizada en su época sino desde la nuestra:

Sin duda resulta más escandalosa para los científicos la aseveración, que también hace suya en esas mismas páginas, de C. F. von Wizsäcker:

Si bien Ratzinger considera que Galileo abrió la «caja de Pandora» no se puede olvidar que será la Inquisición romana o Santo Oficio quien condena a Galileo.

El Santo Oficio prohibió en 1633 el "Diálogo", texto escrito en 1632 por Galileo y le condenó a la cárcel, pero sin que se cumpliera la sentencia que no fue ratificada por el papa.

En relación a las aportaciones científicas de Galileo, además de a las realizadas por Copérnico y Kepler, es frecuente referirse a ellas como una revolución científica en la astronomía que inició la ciencia moderna (caracterizada por la matematización, el mecanicismo y la experimentación) y supuso un cambio de paradigma tanto en la astronomía (paso del geocentrismo al heliocentrismo) como en modo de trabajo en otras disciplinas que se fundamentó en el método científico:

Para Stephen Hawking, Galileo probablemente sea, más que cualquier otro, el máximo responsable del nacimiento de la ciencia moderna; Albert Einstein lo llamó padre de la ciencia moderna.

Joseph Ratzinger, ya como papa, había sido invitado a participar de la ceremonia de inauguración del curso académico prevista para el 17 de enero de 2008, pero tuvo que renunciar ante la protesta iniciada unos meses antes por 67 profesores de la Universidad de La Sapienza y apoyada después por numerosos profesores y estudiantes para declararle "persona non grata". El claustro de profesores no aceptaba la posición «medieval» del papa ante la condena de Galileo y condenaba las afirmaciones que había realizado en el discurso público pronunciado por el papa en la Universidad de La Sapienza en 1990.

Según "L'Osservatore Romano", en realidad ni el discurso fue pronunciado en Parma ni en esa fecha concreta: los profesores de la Sapienza se basaron en una información incorrecta de Wikipedia, no la contrastaron y sacaron la frase de contexto haciendo decir a Ratzinger lo contrario de lo que dijo.

En la Wikipedia en español aparecía, hasta el 17 de marzo de 2009, Parma en vez de Roma y la fecha del 30 de marzo de 1990 en vez del 15 de febrero de 1990 como lugar y fecha de la conferencia de Ratzinger. La conferencia completa está publicada en el capítulo 4 del libro de Joseph Ratzinger "Una mirada a Europa".

En defensa de Ratzinger una gran manifestación reúne fieles en la Plaza de San Pedro el 20 de enero de 2008.

376 años después de su condena y la prohibición de sus libros, en el marco de los eventos del Año Internacional de la Astronomía, la Federación Mundial de Científicos promovió la celebración de una misa en su honor, que fue oficiada el 15 de febrero de 2009 por monseñor Gianfranco Ravasi, presidente del Consejo Pontificio de la Cultura. La Santa Sede aprovechó dicha celebración para hacer sentir la aceptación del legado del científico dentro de la doctrina católica.

También en 2009, dentro de la celebración del Año Internacional de la Astronomía, la Santa Sede organizó un congreso internacional sobre Galileo Galilei.

En marzo se presentó en Roma el libro escrito en italiano "Galileo y el Vaticano" que ofrece un «juicio objetivo por parte de los historiadores» para comprender la relación entre el gran astrónomo y la Iglesia. Al presentar el libro, el presidente del Consejo Pontificio para la Cultura, el arzobispo Gianfranco Ravasi consideró que esta obra facilita a la Iglesia comprometerse «en una relación más vivaz y calmada con la ciencia».

En julio se presentó una nueva edición sobre las investigaciones del proceso realizado a Galileo. El nuevo volumen se titula "I documenti vaticani del processo di Galileo Galilei" ("Los documentos vaticanos del proceso de Galileo Galilei"), Archivo Secreto Vaticano. La edición ha ido a cargo del prefecto del Archivo Secreto Vaticano, monseñor Sergio Pagano.




En el siglo XX la figura de Galileo ha inspirado los nombres de numerosos objetos astronómicos así como diferentes misiones tecnológicas.




</doc>
<doc id="4521" url="https://es.wikipedia.org/wiki?curid=4521" title="1 de mayo">
1 de mayo

El 1 de mayo es el 121.º (centésimo vigesimoprimer) día del año en el calendario gregoriano y el 122.º en los años bisiestos. Quedan 244 días para finalizar el año.
















</doc>
<doc id="4522" url="https://es.wikipedia.org/wiki?curid=4522" title="3 de mayo">
3 de mayo

El 3 de mayo es el 123.º (centésimo vigesimotercer) día del año en el calendario gregoriano y el 124.º en los años bisiestos. Quedan 242 días para finalizar el año.









</doc>
<doc id="4523" url="https://es.wikipedia.org/wiki?curid=4523" title="4 de mayo">
4 de mayo

El 4 de mayo es el 124.º (centésimo vigesimocuarto) día del año en el calendario gregoriano y el 125.º en los años bisiestos. Quedan 241 días para finalizar el año.










</doc>
<doc id="4526" url="https://es.wikipedia.org/wiki?curid=4526" title="Bato">
Bato

Bato puede referirse a varios conceptos:








</doc>
<doc id="4532" url="https://es.wikipedia.org/wiki?curid=4532" title="Cerveza">
Cerveza

La cerveza (del celto-latín "cerevisĭa") es una bebida alcohólica, no destilada, de sabor amargo, que se fabrica con granos de cebada germinados u otros cereales cuyo almidón se fermenta en agua con levadura (básicamente "Saccharomyces cerevisiae" o "Saccharomyces pastorianus") y se aromatiza a menudo con lúpulo, entre otras plantas.

De ella se conocen múltiples variantes con una amplia gama de matices debidos a las diferentes formas de elaboración y a los ingredientes utilizados. Generalmente presenta un color ambarino con tonos que van del amarillo oro al negro pasando por los marrones rojizos. Se la considera «gaseosa» (contiene CO disuelto en saturación que se manifiesta en forma de burbujas a la presión ambiente) y suele estar coronada de una espuma más o menos persistente. Su aspecto puede ser cristalino o turbio. Su graduación alcohólica puede alcanzar hasta cerca de los 30 % vol., aunque principalmente se encuentra entre los 3 % y los 9 % vol.

Según Anderson y Hull, «el lúpulo da a la cerveza ese sabor límpido y amargo, sin el que malamente puede llamarse cerveza». En la Baja Edad Media se originó la costumbre de cocer el mosto con flores de lúpulo. A partir de entonces nació la bebida que hoy identificamos como cerveza, distinta del vino de malta. Tal costumbre se originó en Alemania hace unos mil años. El lúpulo sustituyó a los aromatizantes hasta entonces utilizados, dando a la cebada fermentada alcohólicamente su amargor característico. El lúpulo contribuye también decisivamente a su conservación. Además obra como eficaz antiséptico y estabilizador. También sirve para detener la fermentación acética y clarificar el líquido, causando la precipitación de las sustancias albuminosas. Los primeros testimonios que tenemos sobre el uso del lúpulo se remontan a la Alemania del siglo XI, con motivo de los impuestos por el uso del allí llamado "grut", que en inglés llaman "gruit" —el conjunto de yerbas utilizadas en la elaboración de la cerveza— que fue sustituido por el lúpulo.

Sin el uso del lúpulo, el fermentado proveniente de la cebada no pasa de ser un vino de malta —que no lleva lúpulo y, si lo lleva, no puede ser fresco—, que recuerda por su sabor más al vino que a la cerveza. Cuanto menos lúpulo se usa, la bebida resulta más vinosa. Si la malta está muy tostada no hace falta usar tanto lúpulo para evitar el sabor vinoso. En francés el vino de malta es llamado "vin d’orge", en inglés "barley wine", en alemán "Gerstenwein" y "Maltonwein" y en italiano "vino d’orzo". Sabe a vino, se sirve en copa de vino, tiene una graduación similar a la del vino y los mismos usos que el vino. Se distinguen incluso vinos de malta de mesa y de postre. No se los considera cerveza, aunque los famosos vinos de malta de Bélgica —aderezados con frutas— suelen ser incluidos al tratar de las cervezas, en calidad de «cervezas especiales». Tritton señala en su manual que, para elaborar cerveza en vez de vino de malta, basta añadir lúpulo y un fermento de los usados para elaborar cerveza. En el caso del vino de malta, se suprime el lúpulo y se utiliza fermento de vino en vez de fermento de cerveza. El lúpulo identifica tanto o más la individualidad de la cerveza, que la cebada u otros cereales. Tampoco tienen la consideración de cerveza, ni se llama cerveza, pues carece de lúpulo, el fermentado alcohólico, de unos 7 % vol. del que se extrae por destilación el whisky.

Además del vino de malta, existen otras bebidas alcohólicas con características o apariencia diferentes pero fabricadas también a base de almidón fermentado que, cuando no tienen un nombre específico —como es el caso del "sake"—, son asimiladas a cervezas. En este último caso se añade un complemento al nombre de «cerveza» a fin de evitar malentendidos —por ejemplo, cerveza de banana—. La cerveza sin alcohol es un caso especial ya que su contenido alcohólico es despreciable o nulo, aunque comparte las mismas características de base que el resto de las cervezas porque se ha desalcoholizado durante la elaboración.

Se podría clasificar el "sake" como cerveza de arroz —aunque hay varias diferencias— si se adoptase un criterio analógico. La cerveza es para los europeos lo que el "sake" para los japoneses. En sentido analógico, la cerveza también puede ser clasificada como un sake. Las clasificaciones analógicas suelen rechazarse científicamente por poco rigurosas, pues no distinguen adecuadamente el género de la especie. Si denominamos a todos los mamíferos «vacas», posteriormente hay que distinguir entre vacas «propiamente dichas» y otros animales que sólo son vacas por asimilación. No existe una palabra para designar a todas las bebidas provenientes de cereales alcohólicamente fermentados. Para el inglés, Harold J. Grossman ha propuesto "brews" y "malt beverages".

En Japón la cerveza, tal y como se conoce en Occidente, fue inicialmente un producto importado. Hoy en día existen fábricas de cerveza japonesas y para designar dicha bebida se adaptó la locución "bier" a dicho idioma como "biiru" (ビール). Aunque para hacer cerveza se utiliza muchas veces arroz, no sólo la elaboración es distinta, sino también la fermentación. En la tradición oriental, en la fermentación alcohólica del arroz, el sorgo o el mijo, el fermento utilizado proviene de esos mismos cereales, y está basado en las esporas del "Aspergillus Orizae", un hongo asexuado. Produce la enzima llamada "takadiastasa". Ese fermento se llama "koji". Es palabra de origen japonés, pero que se utiliza en cualquier idioma, si se quiere designar ese fermento. El "koji" no incluye sólo el "Aspergillus Orizae", relativo al arroz, sino también otros como el "A. sojae" relativo a la soja. Tiene la virtud de hacer fermentar en alcohol no sólo la sacarosa, sino también la lactosa. En la obtención de esas bebidas no se tuesta el cereal. También es distinta en consecuencia la preparación del "wort". En una cultura cervecera en la que se efectúan clasificaciones tan sutiles como la distinción entre "ale" y "beer" sería muy difícil clasificar el "sake" como una "ale" o como una "beer".

A diferencia de las bebidas obtenidas a partir de zumos de frutas fermentados, como los vinos, en la cerveza el cereal de base no contiene originalmente ni agua ni azúcar, caracterizando ambas carencias el proceso de elaboración. Para conseguir azúcar a partir del almidón del cereal, es necesario primero modificarlo mediante el malteado y sumergirlo en agua a la temperatura adecuada a fin de completar la conversión. El líquido resultante, compuesto de azúcares, proteínas y residuos procedentes del cereal, se filtra, se hierve vigorosamente y se le añade el lúpulo en caliente, aunque también existe la costumbre de lupular en frío —"dry hopping", «en seco», en inglés—, operación que consiste en añadir las flores al mosto ya frío, bien en las cubas de fermentación, bien en las cubas de almacenamiento. Una vez enfriado a una temperatura que permita el desarrollo de las levaduras, se añaden éstas y se inicia la fermentación que producirá el alcohol y el dióxido de carbono (CO).

Existen varias opiniones:

En todo caso, la raíz común es fácilmente apreciable en sus voces española «cerveza», portuguesa "cerveja", catalana "cervesa", gallega "cervexa", extremeña "cervécia" y retorrománica "gervosa". En otros idiomas europeos se emplean derivados de la misma raíz que la palabra germánica "bier", como es el caso del inglés "beer", francés "bière" e italiano "birra". En inglés también se utiliza la palabra "ale", equivalente a "öl", que es la palabra escandinava para cerveza. Charlie Papazian sostiene que "ale" significaba originariamente hidromiel —"mead" en inglés— muy rebajado con agua, mientras el hidromiel fuerte era denominado "biuza", de donde "beer".

Históricamente la cerveza fue desarrollada por los antiguos pueblos elamitas, egipcios y sumerios. Las evidencias más antiguas de la producción de cerveza datan de alrededor de IV milenio a. C. fueron halladas en Godin Tepe, en el antiguo Elam (actual Irán). Algunos la ubican conjuntamente con la aparición del pan entre 10 000 a. C. y 6000 a. C. ya que tiene una parecida preparación agregando más o menos agua. Parece ser que las cervezas primitivas eran más densas que las actuales, similares al actual "pombe" africano, de culturas igualmente primitivas. Según la receta más antigua conocida, el Papiro de Zósimo de Panópolis (siglo III), los egipcios elaboraban la cerveza a partir de panes de cebada poco cocidos que dejaban fermentar en agua. Su cerveza fue conocida como "zythum", que es palabra griega, pero en una fase más tardía. Antiguamente en Oriente se usaba arroz y también bambú. Del bambú, lo mismo que de la caña de azúcar, lo que se fermenta es su savia; pero no su fruto. Tal es el "ulanzi" propio de Tanzania. No puede ser considerado un fermentado alcohólico de cereal. Las bebidas alcohólicas más antiguas quizá sean derivadas de la leche.
Michael Jackson, en su "Michael Jackson's Beer Companion", recoge la opinión del profesor de la Universidad de Pensilvania Salomon Katz, que data la aparición de una bebida de cebada fermentada alcohólicamente en la Mesopotamia del año 4000 a. C. con el nombre de "sikaru", pero señala que se hacía con pan de cebada; es decir, se trataba de lo que hoy llamamos "kuas", que no es considerado propiamente cerveza, aunque es un fermentado alcohólico proveniente de cereal. La cerveza propiamente dicha aparece en Europa en el siglo XIII, en la medida en que el concepto de cerveza incluye el amargor propio del lúpulo. El malteado ya se había inventado antes. En el primer capítulo de sus "Études sur la bière", Pasteur hace notar que cuando se dice que en el siglo IV a. C. ya Teofrasto hablaba de «cerveza», en realidad no hablaba de cerveza, ni de "cervoise", ni de "beer", sino de vino de cebada, de οίνος εκ κριθεόν. Atribuir un origen muy antiguo a la cerveza se hace sobre la base de proporcionar un concepto muy amplio de lo que haya de entenderse por cerveza.

Los restos arqueológicos más antiguos de producción de cerveza en Europa fueron descubiertos en 1999 en el yacimiento de la Cova de Can Sadurní en el término municipal de Begas (Barcelona, España) los restos hallados eran del neolítico en una estratificación de entre 5500 a. C.-4000 a. C., por Manel Edo Benaiges, Pepa Villalba Ibáñez y Anna Blasco Olivares, de la Universidad de Barcelona (UB). Sin duda alguna este hallazgo desplazó el que hasta ese momento se creía como más antiguo descubrimiento de elaboración de cerveza en Europa en el yacimiento del valle de Ambrona, dentro del término municipal de Miño de Medinaceli, (Soria, España) y que databan de alrededor de siglo XXV a. C., según el trabajo arqueológico del equipo dirigido por el profesor Manuel Ángel Rojo Guerra, de la Universidad de Valladolid. También se han encontrado evidencias arqueológicas de elaboración de cerveza en el yacimiento de Genó, en Aitona (Lérida, España), tras los trabajos de investigación arqueológica, dirigidos por el profesor José Luis Maya González, que han establecido que estos restos arqueológicos databan de alrededor de siglo XII a. C.

Los celtas conocían la elaboración de la cerveza y llevaron consigo este conocimiento cuando se extendieron por la península ibérica, donde su uso y su elaboración se desarrolló muy pronto.

Con el paso de los siglos, sobre todo a partir de la romanización, la mediterránea se consolidó como una zona básicamente vinícola mientras que la cerveza se producía en el norte y centro de Europa y adquiría la forma de lo que entendemos hoy por cerveza. De esta manera, se extiende el uso de la malta como ingrediente principal y también se empieza a introducir el uso del lúpulo como aromatizante. Esta planta cannabáceas confiere a la cerveza su sabor amargo característico, a la vez que favorece la conservación.

El año 1516, el duque Guillermo IV de Baviera redactó la primera ley que fijaba qué se entendía por cerveza. Esta ley de pureza ("Reinheitsgebot") establecía que solamente podía utilizarse agua, malta de cebada y lúpulo para elaborar la cerveza. En cambio, en Inglaterra, Enrique VIII prohibió el uso del lúpulo, ante la presión del gremio de cerveceros; prohibición que levantó su hijo Eduardo VI, y que continuó por algún tiempo más en Escocia. Los cerveceros ingleses tardaron mucho en aceptar el uso del lúpulo. En su momento se llamó "ale" a la cerveza sin lúpulo y "beer" a la cerveza con lúpulo. Todavía hoy, para designar los vinos de malta sin lúpulo más que de "barley wine", que simplemente puede designar una cerveza de alta graduación, se habla de "gruit ale".

La cerveza empezó a recuperar su presencia social en España a partir del reinado del emperador Carlos I, que trajo consigo maestros cerveceros de Alemania. Todo ello queda reflejado entre las pertenencias del emperador a la muerte de éste en Yuste por su Secretario Martín de Gaztelu. Por aquel entonces, la cerveza era aún un producto de temporada. No se sabía conservar y con el calor perdía toda su fuerza. La cerveza llamada "lager", sin embargo, recibe ese nombre en razón de su posibilidad de almacenamiento. Se elaboraba en otoño, para ser consumida en primavera. La fermentación baja y a baja temperatura favorece la conservación. En realidad iba fermentando lentamente mientras estaba almacenada. Actualmente todas las cervezas, incluso las de alta fermentación, son almacenables y llevan fecha de caducidad que alcanza unos tres años. "Lager" ha sufrido un cambio semántico, y ha pasado a significar cerveza de fermentación baja.

La posibilidad de conservación de la cerveza se debe no tanto al invento de las neveras eléctricas, como al de conservantes distintos del lúpulo, y a la posibilidad de elaborar a gran escala y con facilidad envases herméticamente cerrados. Las botellas industriales hechas en serie aparecen en el siglo XIX. Antes se fabricaban a soplete. La cerveza enlatada comienza en 1933 en Estados Unidos, tras la abolición de la ley seca. Los barriles de cerveza han desaparecido prácticamente. No se puede hablar de una verdadera industria cervecera hasta el siglo XIX, cuando empiezan a aparecer pequeñas fábricas más que artesanales ya industriales. La primera gran fábrica de cerveza en España fue abierta en 1864 por el alsaciano Louis Moritz en Barcelona. Y la siguieron marcas como La Salve Bilbao (1886), Mahou (1890), Cruzcampo (1904) o Estrella Galicia (1906).

La elaboración de la cerveza se puede hacer con cualquier cereal que pueda producir azúcares fermentables. Para ello debe ser preparado para que la gran mayoría de sus azúcares sean fermentables. En algunos casos una simple cocción es suficiente (como en el caso del maíz) y en otros casos es preciso «maltear» el cereal. En la elaboración de la cerveza se utilizan numerosos cereales en su estado crudo o malteado, siendo la cebada el único que debe maltearse necesariamente y el más utilizado en la cervecería occidental.

Los azúcares que contiene el grano de cebada no son inmediatamente accesibles y, en una fase previa, es preciso activar unas enzimas presentes en el propio grano que reducirán las largas cadenas de almidón para liberar azúcares. Esta operación, también denominada malteo o malteado, consiste simplemente en hacer germinar los granos. Cuando se estima que la activación enzimática de la germinación se encuentra en su punto óptimo, se para el proceso reduciendo la humedad del grano hasta su mínimo. Este producto recibe el nombre de "malta verde". Después hay que hornearlo. A bajas temperaturas, el tostado es mínimo y se habla de "maltas claras" (llamadas también maltas "lager" o "pale" según el país en que se producen). A medida que se aumenta la temperatura del horno, la malta resultante es cada vez más oscura. Se puede llegar al punto de quemarla, produciendo «malta negra». El grado de tostado de la malta determina el color de la cerveza. Los demás cereales se pueden utilizar malteándolos previamente, aunque solamente es indispensable hacerlo en el caso de la cebada. Con los demás cereales, el malteado sirve para conseguir aromas diferenciados o efectos técnicos concretos.

Mezcla se refiere a la masa de grano que se utilizará para elaborar el mosto. Puede ser de un único tipo de malta o el resultado de una mezcla de maltas, o de maltas y grano crudo. Las proporciones y los componentes de esta mezcla son básicos para determinar el tipo o estilo de cerveza que se quiere producir.

Los diversos cereales que se utilizan para la cervecería presentan cada uno variedades botánicas que multiplican las posibilidades de elección del elaborador. Actualmente pueden encontrarse en el mercado hasta 60 tipos diferentes, cifra que aumenta considerablemente si tenemos en cuenta el malteo casero. Básicamente los cereales se distinguen en cuatro categorías:

La calidad de los cereales, sus variedades, y la calidad del proceso de malteo definen en gran medida la calidad de la cerveza. Las bebidas alcohólicas hechas de la fermentación de azúcares obtenidos de otras fuentes generalmente no se llaman cerveza, a pesar de ser producido por un proceso similar a la reacción bioquímica de la levadura. Como ejemplos, el zumo de manzana fermentado se llama sidra, el jugo fermentado de la pera se llama perada, y el jugo de uva fermentado se llama vino.

Actualmente, en la elaboración occidental de la cerveza, el aditivo principal que se utiliza para hacer de contrapeso (de equilibrante si se prefiere) al dulzor de la malta es el lúpulo ("Humulus lupulus"). De esta planta se utiliza sin fecundar la flor hembra, llamada “cono”, salvo en Inglaterra. Flores masculinas y femeninas crecen en plantas distintas, por lo que es usual suprimir las masculinas, con lo que se obtienen inflorescencias femeninas sin semillas. En Inglaterra, sin embargo, es costumbre tener un lúpulo masculino por cada doscientos femeninos, con lo que los “conos” tienen semillas. Ello parece proporcionar mayor resistencia a las plantas.

En la base de sus bracteolas, hay unas glándulas que contienen la "lupulina", que es el ingrediente que aportará a la cerveza su sabor amargo y los aromas propios. Del amargor son responsables los ácidos amargos y los aromas proceden de aceites elementales constituidos en especial por compuestos bastante volátiles y delicados a base de ésteres, y de resinas. Existen numerosas variedades botánicas del lúpulo que son objeto de investigaciones intensas. El lúpulo es la causa de la estimulación del apetito que produce la cerveza. Para su comprensión, también se clasifican en categorías:

Estos lúpulos son los que aportan más ácidos amargos que aromas. Los representantes más conocidos de esta categoría son el "brewer's gold" y el "northern brewer" o "nordbrauer".
Lógicamente, éstos aportan más elementos aromáticos que amargos. En este apartado se conocen especialmente el "saaz/zatec" que definen el estilo "pilsner" de cerveza, el "spalt" y el "tettnang" en el área alemana, y los "golding" y "fuggler" en el área anglófona.

El lúpulo es muy delicado, solamente se puede utilizar fresco durante los pocos meses de su cosecha, que coincide con la de la viña: finales de agosto a octubre según las variedades y el sitio. Fuera de este intervalo temporal se tiene que condicionar, de manera que el mercado presenta diversas formas que van desde el lúpulo deshidratado hasta extracto de lúpulo. Lógicamente, en cada manipulación se van perdiendo características y no es lo mismo utilizar un lúpulo fresco o congelado que un aceite de concentrado de lúpulo. El efecto organoléptico sobre la cerveza es muy diferente. La variedad y el frescor del lúpulo influyen muy sensiblemente en la calidad final de la cerveza.
Las formas de uso son en extracto, "pellet" o en polvo; aunque la forma más habitual es en "pellet".

El lúpulo puede adquirirse y usarse en forma de “pellets”, palabra inglesa utilizada en la jerga cervecera, que significa “pildorita”. Las hay de dos clases: para impartir amargor y para impartir aroma. Los pellets tienen la ventaja de evitar la rápida degradación propia de las flores. Las grandes fábricas utilizan extracto de lúpulo, que apenas tiene aroma; pero la gran masa de bebedores no es consciente de ello. También utilizan en ocasiones para dar aroma extractos de esencias de aceites. Tienen el inconveniente de que en mayor o menor cantidad contienen “mirceno”, que también proporciona olor desagradable. Esos extractos se añaden inmediatamente antes del embotellado.

Al margen del lúpulo, la historia recoge numerosos aditivos botánicos. Hoy en día podemos citar los siguientes:


Entre el 85 y 92 % de la cerveza es agua.

Aparte de las características bacteriológicas y minerales de potabilidad, cada tipo o estilo de cerveza requerirá una calidad diferente de agua. Algunas requieren de agua de baja mineralización, otras necesitan aguas duras con mucha cal. Actualmente, prácticamente ya no se hacen cervezas tal y como fluyen. Casi todas las cervecerías tratan las aguas de manera que siempre tenga las mismas características para una misma receta de cerveza.

Entre los minerales del agua que más interesan a los cerveceros están el calcio, los sulfatos y los cloruros. El calcio aumenta la extracción tanto de la malta como del lúpulo en la maceración y en la cocción y rebaja el color y la opacidad (o lo turbia que es) de la cerveza. El cobre, el manganeso y el zinc, inhiben la floculación de las levaduras. Los sulfatos refuerzan el amargor y la sequedad del lúpulo. Los cloruros dan una textura más llena y refuerzan la dulzura.

Actualmente, se consumen aproximadamente 3Hl de agua por cada Hl de cerveza producido. Por esta razón, la tendencia es reducir el consumo de agua.

La mayoría de los estilos de cerveza se hacen usando una de las dos especies unicelulares de microorganismos del tipo "Saccharomyces" comúnmente llamados levaduras, hongos que (como indica su nombre) consumen azúcar y producen alcohol y anhídrido carbónico. Existen dos tipos básicos diferentes de levadura que definen los dos grandes grupos estilísticos de cervezas:

En la elaboración de la cerveza, especialmente en las llamadas de fermentación espontánea, también pueden intervenir otras levaduras. En estas cervezas el elaborador no selecciona ninguna levadura sino que permite que todas las levaduras en suspensión en el aire se introduzcan en el mosto. Esas levaduras producen una fermentación tumultuosa similar a la del vino, no localizada particularmente ni en la parte alta ni en la baja del recipiente. Se instalan, aparte del "Saccharomyces", más de 50 fermentadores diferentes entre los cuales hay que citar el "Lactobacillus" (es una bacteria), que produce el ácido láctico, y el "Brettanomyces", que produce el ácido acético. Estas cervezas son pues ácidas por definición, y su elaboración requiere procedimientos especiales destinados a rebajar la acidez.

La tradición cervecera desapareció de la península ibérica probablemente con la introducción del cristianismo. De manera que el español no posee un lenguaje especializado de elaboración. Es por esto que en algunas ocasiones, se pondrá entre paréntesis la expresión alemana o inglesa para algún proceso o etapa.


Existen diversos criterios de clasificación de las cervezas. Las diversas asociaciones y los expertos se pusieron de acuerdo en los años 1970 para elaborar una clasificación de las cervezas basadas en estos criterios y en las descripciones de los propios elaboradores.

Habitualmente se suele indicar con qué grano se ha elaborado la cerveza cuando no ha sido elaborada exclusivamente con malta de cebada: cerveza de trigo, de avena, etcétera. En la mayoría de los casos se trata de una mezcla de malta de cebada y del grano indicado. No se suele indicar con qué lúpulo está hecha la cerveza, pero existe un estilo particular que se define por el uso de uno en particular: se trata de la cerveza "Pils" o "Pilsener", que originalmente tenía que hacerse con cebadas de Moravia y lúpulos de "Žatec" (o "Saaz") de Bohemia. También se pueden llamar "Pils" a algunas imitaciones históricas alemanas elaboradas con cebadas y lúpulos muy parecidos a la "Pils" original.

Muchas cervezas reciben el distintivo de su color: cerveza ámbar, roja, rubia, negra. Otras vienen definidas por su transparencia: cervezas turbias o translúcidas. Normalmente, la translucidez de una cerveza puede ser debida a las proteínas en suspensión, procedentes del grano (menos de cebada), o bien puede ser debida al hecho de ser poco o no haber sido filtrada y llevar levadura en suspensión. Las cervezas negras son llamadas así por el uso que se hace en la receta de maltas tostadas o quemadas. Algunas cervezas negras especialmente robustas son nombradas normalmente "stout" («robusto» en inglés).

Algunas cervezas se definen por algún procedimiento particular: la "Rauchbier" (cerveza ahumada) está hecha con maltas que se han tostado dejando que el humo de la leña impregne en grano. La "Dampfbier" o "Steambeer" vienen definidas por el uso de maquinaria de vapor en su elaboración. No son exactamente estilos pero se definen de esta forma. Algunas cervezas de Alemania, en invierno, eran servidas calientes y además se solía mojar una barrita de hierro ("Stachel") al rojo para aumentar la temperatura y caramelizar algunos azúcares: "Stachelbier". Este procedimiento también se ha descrito en Irlanda. La "Steinbier" es una especialidad en la que se calienta el mosto lanzándole piedras ("Stein") muy calientes.

Muchas cervezas se definen por su lugar de origen o por una denominación de origen controlada. Es preciso hablar en especial de las cervezas de abadía, que suelen recibir su nombre y su denominación por su relación, no siempre evidente ni directa con algún cenobio. El ejemplo más conocido es el de las cervezas "Trappistes" dependientes exclusivamente de monasterios de este orden. Estas cervezas suelen ser densas y con un notable contenido en alcohol. Existen dos denominaciones de origen: la "bière de garde" del Norte de Francia, y la Kölsch que sólo se puede elaborar en Colonia. También son muy características las cervezas regionales, como lo son las cervezas alemanas o las cervezas artesanales belgas (la Bush, La Binchoise, la De Coninck, etc.).

Sin embargo, a diferencia de lo que sucede con el vino, la comercialización de las cervezas no está basada en un sistema de “denominaciones de origen”, a las que se asigna una “región determinada” que es la única en la que se permite fabricar el correspondiente producto y la única que tiene derecho a usar esa “denominación de origen”. Las cervezas adoptan por nombre marcas comerciales registradas en los usuales registros de patentes y marcas. Muchas marcas de cerveza son famosas. Una gran fábrica encarga en distintos países la elaboración de una misma cerveza, sobre la base de exigirles una muy concreta receta. La producción no está ligada a una “región determinada”. El consumidor bebe “la misma cerveza” independientemente de que esté elaborada en Japón, en España o en Burdeos.

Esta es la clasificación más sencilla. Según el tipo de fermentación las cervezas se dividen en dos grandes grupos, "lager" de baja fermentación, y "ale" las de alta fermentación, en las que se incluyen también las de fermentación espontánea.

No obstante, se trata de una división demasiado genérica, por lo que normalmente se denominan "lager" las cervezas que no tienen ninguna otra característica especial. Por lo general, las cervezas "lager" son ligeras, claras, con bastante gas y una graduación moderada. También suelen ser muy refrescantes. Las "ale", en cambio, son menos habituales, al menos en el mediterráneo, aunque en Reino Unido y el centro de Europa son las más populares. Se trata de cervezas más oscuras, espesas y con poco gas. Suelen tener mayor graduación y un sabor mucho más intenso, en el que se nota más el cereal. El nombre "ale" suele aplicarse únicamente a las cervezas inglesas, mientras que el resto suelen adoptar su denominación en función de otras propiedades.

El hombre comenzó a cultivar los cereales entre el milenio XI a. C. y el milenio VII a. C. en la zona de Mesopotamia. Es entonces bastante probable que tanto el pan como la cerveza fuesen descubiertas al mismo tiempo ("véase": Historia del pan). Sólo es una cuestión de proporciones: si se ponía más harina que agua y se dejaba fermentar, se obtenía pan; si se invertía la proporción poniendo más agua que harina y se dejaba fermentar, se conseguía cerveza. Los rastros más antiguos que atestiguan la existencia de panificación y de cervecería aparecen en Mesopotamia, pero sería ocioso buscar una filiación con procedimientos idénticos descubiertos en el resto de Europa. Dadas las circunstancias climáticas que se estaban dando tras la recesión de la última glaciación conocida en la parte de la cuenca Mediterránea así como en la desembocadura del Éufrates, el Delta del Nilo, etc. tendemos a creer que la cerveza se descubrió o inventó en muchos lugares del Mediterráneo y de Europa de forma bastante simultánea.

Originalmente es preciso concebir la cerveza como un alimento que ofrecía dos ventajas básicas. En primer lugar, permitía un uso más comedido de un ingrediente no muy fácil de cultivar al principio. En efecto, era más fácil hacer mucha cerveza con un poco de grano que mucho pan con la misma cantidad de grano. De hecho, muchas cervezas se hicieron remojando panes fermentados, cocidos en agua y dejando fermentar la mezcla. La cerveza se chupaba con cañas para evitar encontrarse con grumos de pan. En segundo lugar, la fermentación producía alcohol y desinfectaba el agua ofreciendo así una bebida limpia de contaminación bacteriana. No en vano, en sitios como la República Checa o Baviera, se llama a la cerveza hasta hoy "pan líquido".

El fenómeno de la fermentación era concebido como un acto procedente de las divinidades con fuerte carácter mágico. Así fue como la cerveza fue concebida como bebida sagrada y placiente a los dioses. Y no son raros los textos en los que se describe una ofrenda en la que figura la cerveza como alimento sagrado.

Cuando la cerveza se produjo en grandes cantidades, también bajó sensiblemente su calidad. Así es como en muchos lugares del Mediterráneo clásico apareció la cerveza como bebida de taberna. El único lugar donde parece que la cerveza no tuvo mucho papel fue en la antigua Grecia, donde dominaba el vino. Por todo el resto de la cuenca, la cerveza fue la bebida popular y a la vez sagrada. En concreto, en Roma, en los bajos fondos, se consumía en cantidades ingentes. Y para elaborarla se tuvieron que arrancar viñas, lo que creó un importante conflicto con los adeptos del vino.

Originalmente, las cervezas se solían hacer con un cereal antecesor del trigo llamado espelta. Pero rápidamente se impusieron el trigo y la cebada en la cervecería. El trigo, más agradable en su forma sólida, fue reservado a la panificación y la cebada destinada a la cerveza. Curiosamente, ya en épocas muy remotas, la cebada no se servía cruda. Se hacían unos panes, cocidos a diferentes niveles y que se conservaban muy bien. Para hacer la cerveza, se hacía trocitos el pan y se mezclaba con agua. Después de calentar y cocer la mezcla, se dejaba fermentar unos días. Existen muchos testimonios gráficos y documentales en la región de Mesopotamia que describen cómo los consumidores usaban una caña para beber la cerveza sin encontrarse con los trozos de pan. Los egipcios comenzaron su cervecería con panes como los sumerios, pero parece ser que fueron los inventores del malteo. Y tanto en la Mesopotamia como en Egipto, se hicieron grandes cantidades de cerveza de muchos tipos diferentes identificados por su color, cosa que indica que ya controlaban el grado de torrefacción de los panes o del grano.

La cerveza tuvo una gran importancia social hasta hace poco. La nutrición de un babilonio era constituida principalmente de cerveza, grano, frutas, verdura y cebolla, dieta poco diferente de la mayoría de la gente modesta de la antigüedad. Muchos salarios se cobraban en grano o directamente en cerveza. La gente con más poder adquisitivo no cambió el consumo aunque lo sofisticó: filtraban la cerveza, haciéndola más densa (más cara). Hasta se describe cómo los pobres bebían cerveza con cañitas del río, mientras que los ricos disponían de tubos en oro para hacer el mismo servicio. Otro indicio de la importancia social de la cerveza consiste en el hecho que en aquellos países, los elaboradores de cerveza no tenían la obligación de participar en guerras. En cambio eran obligados a seguir a los ejércitos por tal de asegurarles el avituallamiento de cerveza. Como era un alimento de primera necesidad, la cerveza, a lo largo de la historia, fue objeto de codicias diversas por parte de la gente poderosa que hizo en algún caso un monopolio. También cargó el comercio con importantes impuestos o bien se establecieron leyes de uso exclusivo de algún cereal para favorecer un monopolio de dicho cereal. Se describen algunos enfrentamientos y revueltas en diversos momentos y en diversos lugares cuando esta presión se reveló insoportable.

La cerveza posee un alto contenido en vitaminas, sales minerales, proteínas, fibras, micro nutrientes y carbohidratos. Según un estudio realizado en la Universidad de Cardiff (Reino Unido), la cerveza incrementa el colesterol «bueno», mejora la coagulación de la sangre, tiene un alto valor nutricional y favorece la digestión.

El consumo moderado de bebidas fermentadas, como la cerveza, puede formar parte de una alimentación saludable como la Dieta Mediterránea actual, por las propiedades que les confieren su baja graduación y las materias primas con las que están elaboradas. Por este motivo, la Sociedad Española de Nutrición Comunitaria (SENC), incluye en la Pirámide de la Alimentación Saludable —principal referencia en materia nutricional en España— las bebidas fermentadas (cerveza, vino, cava o sidra) de forma opcional y moderada en la dieta de adultos sanos.

Al norte del Pirineo, la Edad Media fue la edad de oro de la cerveza, y producirla fue un negocio favorable que extendió la práctica hasta incluso los frailes. Pronto, se estableció un conflicto de intereses entre los elaboradores laicos que tenían que pagar impuestos de todo tipo y los elaboradores monacales que disponían de materia prima en grandes cantidades y en condiciones muy ventajosas gracias a exenciones fiscales diversas, un caso flagrante de competencia desleal. Hacia el siglo XV, los elaboradores laicos tuvieron que inventarse un nuevo tipo de cerveza, más barata, que les permitiese sobrevivir a pesar de la competencia de los frailes. Aquí radica la diferencia histórica entre la "cerevisia" de los frailes, más densa, más aromatizada, y más cara, y la "bier/beer/bière" de los laicos, menos alimenticia, más refrescante y barata, aromatizada simplemente con lúpulo.

La historia de la cerveza se puede también analizar según el ángulo de la sanidad. En efecto, ya se ha hablado de que la presencia de alcohol permite desde siempre el consumo de una bebida sin algunas bacterias corrientes como la salmonela y otros. Pero también desde muy antes, los elaboradores han añadido numerosas cosas en la cerveza. Están documentadas incluso exageraciones como el hígado de ternera. Tanto es así que desde el siglo XIV, aparecen en Alemania e Inglaterra leyes para regular aquello que se añadía a la cerveza. La culminación de todas estas leyes es la ley de pureza bávara ("Reinheitsgebot") dictada por el rey Guillermo IV de Baviera el día de San Jorge de 1516. En ella el rey determinaba que la cerveza solamente podía hacerse con agua, malta de cebada y lúpulo. Esta ley hizo desaparecer muchas recetas particulares de cerveza de los territorios donde se aplicó, especialmente de las especialidades en las que era preciso añadir algún azúcar o variar los aromatizantes botánicos. En otros países, las leyes no fueron tan estrictas y se permitieron conservar recetas en las que figuraban algunos aditivos. La ley de pureza también contribuyó notablemente a aumentar la fortuna del rey, que tenía el monopolio de la producción de cebada.

Durante el siglo XIX los cerveceros checos y alemanes inventaron y desarrollaron una cerveza que tenía que tener buen aspecto, pues se empezaba a expandir el uso de los recipientes transparentes. Se inventaron formas diversas y más eficaces de filtrar la cerveza y la hicieron más clara. Una forma de clarificar las bebidas era la de alargar considerablemente la maduración a bajas temperaturas. Así apareció la cerveza "Lager" (en alemán, «almacén, bodega») y la propia levadura de baja fermentación que fue identificada "posteriori". Actualmente, la mayoría de las cervezas industriales están hechas según este sistema. Dentro de la categoría de las cervezas "Lager", las "Pils", originarias de la localidad checa de Pilsen, están hechas con maltas de Moravia y, sobre todo, lúpulo ("Hopfen", en alemán).

Precisamente desde finales del siglo XIX la historia de la cerveza se confunde con el desarrollo de métodos que permitían la elaboración masiva de la cerveza, en detrimento muchas veces de los criterios de calidad. Hasta bien entrados los años 1970, fueron desapareciendo grandes cantidades de recetas y se fue uniformizando mundialmente la producción, principalmente de cervezas "lager" de calidad mediana a baja, al mismo tiempo que se hacen y se consumen cada vez cantidades más grandes. Aun así, algunas asociaciones de productores y consumidores especialmente ingleses, alemanes y americanos siguen exigiendo cervezas de calidad.

Precisamente en los años 1940, se puede decir que vuelve a aparecer la idea de producir cerveza casera. De hecho, el 80 % de todas las cervezas históricas son caseras o artesanales. Las mujeres europeas fueron excelentes cerveceras pero, como se ha dicho, la costumbre de hacer cerveza casera desapareció, y volvió a brotar por el interés que tuvieron los elaboradores caseros americanos para reproducir las cervezas tradicionales europeas. Hasta el punto que importantes productores de talla mediana han apostado por producir cervezas históricas y por resucitar recetas perdidas. Las asociaciones de elaboradores y consumidores desarrollaron (o propiciaron) también la degustación y la apreciación científica o profesional de la cerveza. Esta corriente pasó de nuevo el Atlántico para llegar en los años 1980 primero a Inglaterra y después al resto de países de Europa.
En la actualidad existen diversos manuales y textos para la elaboración casera de cerveza

La cerveza no tuvo una producción en masa hasta finales del siglo XVIII, no adquiriendo una relativa importancia hasta mediados del XIX. Hasta 1914 los primeros productores fueron Alemania y Gran Bretaña, a partir de entonces el primer productor fue Estados Unidos. En el período de entreguerras la producción mundial alcanzó los 250 millones de hectolitros, siendo la URSS uno de los principales productores.

España es una potencia productora de cerveza, siendo el cuarto productor de cerveza de la Unión Europea, por detrás de Alemania, Reino Unido y Polonia, con una producción de 33 millones de hectolitros en 2012 y un consumo per cápita de 47,5 litros por persona y año. A nivel mundial, se sitúa en décima posición. En 2011, último año del que se tienen datos oficiales, la facturación por venta de cerveza en España fue de casi tres mil millones de euros.

Los principales estilos de cerveza son:

Fermentación baja

Fermentación alta






Fermentación espontánea

Cerveza sin gluten

Sus ingredientes pueden ser: Agua, cereal o pseudo cereal malteado, jarabe de maíz, flor de lúpulo, extracto de lúpulo.
Los cereales o pseudo cereales más utilizados son el trigo sarraceno, el maíz, el sorgo, la Quinoa y el arroz.
Las cervezas elaboradas con esos componentes en forma cuidadosa para evitar las contaminaciones con otras, son consideradas seguras para quienes deben llevar una dieta libre de gluten.
Hay países que producen cervezas a base de cebada que aseguran que son libres de gluten.
La certificación necesaria para ser vendido como producto libre de gluten, depende de cada país (o región). Los métodos de análisis para determinar el posible contenido de gluten de una cerveza de estos tipos, son muy controvertidos, y se discute la validez del clásico ELISA R5 para estos fines. La comunidad científica no se ha puesto aún de acuerdo en como medir el gluten en algunas cervezas, porque los procesos enzimáticos de clarificación utilizados hoy en día, cortan las cadenas de proteínas en trozos más pequeños, que dificultan su detección por los métodos más tradicionales. Hay en general acuerdo en que el método más exacto es el PCR.

El gluten es una proteína que se encuentra en los granos de trigo, cebada,
centeno y posiblemente en la avena. Ciertas personas son alérgicas al gluten y no pueden tomar cerveza normal. Véase también: Celiaquía, artículo sobre la enfermedad.

Existen varios fabricantes que comercializan cerveza sin gluten, como por ejemplo Bi-Aglut o Damm con su cerveza Daura.






</doc>
<doc id="4533" url="https://es.wikipedia.org/wiki?curid=4533" title="Circuito integrado">
Circuito integrado

Un circuito integrado (CI), también conocido como chip o microchip, es una estructura de pequeñas dimensiones de material semiconductor, normalmente silicio, de algunos milímetros cuadrados de superficie (área), sobre la que se fabrican circuitos electrónicos generalmente mediante fotolitografía y que está protegida dentro de un encapsulado de plástico o de cerámica. El encapsulado posee conductores metálicos apropiados para hacer conexión entre el circuito integrado y un circuito impreso.

Los CI se hicieron posibles gracias a descubrimientos experimentales que mostraban que artefactos semiconductores podían realizar las funciones de los tubos de vacío, así como a los avances científicos de la fabricación de semiconductores a mediados del siglo XX. La integración de grandes cantidades de pequeños transistores dentro de un pequeño espacio fue un gran avance en la elaboración manual de circuitos utilizando componentes electrónicos discretos. La capacidad de producción masiva de los circuitos integrados, así como la fiabilidad y acercamiento a la construcción de un diagrama a bloques en circuitos, aseguraba la rápida adopción de los circuitos integrados estandarizados en lugar de diseños utilizando transistores discretos.

Los CI tienen dos principales ventajas sobre los circuitos discretos: costo y rendimiento. El bajo costo es debido a los chips; ya que posee todos sus componentes impresos en una unidad de fotolitografía en lugar de ser construidos un transistor a la vez. Más aún, los CI empaquetados usan mucho menos material que los circuitos discretos. El rendimiento es alto ya que los componentes de los CI cambian rápidamente y consumen poco poder (comparado sus contrapartes discretas) como resultado de su pequeño tamaño y proximidad de todos sus componentes. Desde 2012, el intervalo de área de chips típicos es desde unos pocos milímetros cuadrados a alrededor de 450  mm, con hasta 9 millones de transistores por mm.

Los circuitos integrados son usados en prácticamente todos los equipos electrónicos hoy en día, y han revolucionado el mundo de la electrónica. Computadoras, teléfonos móviles, y otros dispositivos electrónicos que son parte indispensables de las sociedades modernas, son posibles gracias a los bajos costos de los circuitos integrados.

En abril de 1958, el ingeniero alemán Werner Jacobi (Siemens AG) completa la primera solicitud de patente para circuitos integrados con dispositivos amplificadores de semiconductores. Jacobi realizó una típica aplicación industrial para su patente, la cual no fue registrada.

Más tarde, la integración de circuitos fue conceptualizada por el científico de radares Geoffrey Dummer (1909-2002), que estaba trabajando para la Royal Radar Establishment del Ministerio de Defensa Británico, a finales de la década de 1940 y principios de la década de 1950.

El primer circuito integrado fue desarrollado en 1959 por el ingeniero Jack S. Kilby (1923-2005) pocos meses después de haber sido contratado por la firma Texas Instruments. Se trataba de un dispositivo de germanio que integraba seis transistores en una misma base semiconductora para formar un oscilador de rotación de fase.

En el año 2000 Kilby fue galardonado con el por la enorme contribución de su invento al desarrollo de la tecnología.

Robert Noyce desarrolló su propio circuito integrado, que patentó unos seis meses después. Además resolvió algunos problemas prácticos que poseía el circuito de Kilby, como el de la interconexión de todos los componentes; al simplificar la estructura del chip mediante la adición de metal en una capa final y la eliminación de algunas de las conexiones, el circuito integrado se hizo más adecuado para su producción en masa. Además de ser uno de los pioneros del circuito integrado, Robert Noyce también fue uno de los co-fundadores de Intel Corporation, uno de los mayores fabricantes de circuitos integrados del mundo.

Los circuitos integrados se encuentran en todos los aparatos electrónicos modernos, tales como relojes, automóviles, televisores, reproductores MP3, teléfonos móviles, computadoras, equipos médicos, etc.

El desarrollo de los circuitos integrados fue posible gracias a descubrimientos experimentales que demostraron que los semiconductor, particularmente los transistores, pueden realizar algunas de las funciones de las válvulas de vacío.

La integración de grandes cantidades de diminutos transistores en pequeños chips fue un enorme avance sobre el ensamblaje manual de los tubos de vacío (válvulas) y en la fabricación de circuitos electrónicos utilizando componentes discretos.

La capacidad de producción masiva de circuitos integrados, su confiabilidad y la facilidad de agregarles complejidad, llevó a su estandarización, reemplazando circuitos completos con diseños que utilizaban transistores discretos, y además, llevando rápidamente a la obsolescencia a las válvulas o tubos de vacío.

Son tres las ventajas más importantes que tienen los circuitos integrados sobre los circuitos electrónicos construidos con componentes discretos: su menor costo; su mayor eficiencia energética y su reducido tamaño. El bajo costo es debido a que los CI son fabricados siendo impresos como una sola pieza por fotolitografía a partir de una oblea, generalmente de silicio, permitiendo la producción en cadena de grandes cantidades, con una muy baja tasa de defectos. La elevada eficiencia se debe a que, dada la miniaturización de todos sus componentes, el consumo de energía es considerablemente menor, a iguales condiciones de funcionamiento que un circuito electrónico homólogo fabricado con componentes discretos. Finalmente, el más notable atributo, es su reducido tamaño en relación a los circuitos discretos; para ilustrar esto: un circuito integrado puede contener desde miles hasta varios millones de transistores en unos pocos milímetros cuadrados.

Los avances que hicieron posible el circuito integrado han sido, fundamentalmente, los desarrollos en la fabricación de dispositivos semiconductores a mediados del siglo XX y los descubrimientos experimentales que mostraron que estos dispositivos podían reemplazar las funciones de las válvulas o tubos de vacío, que se volvieron rápidamente obsoletos al no poder competir con el pequeño tamaño, el consumo de energía moderado, los tiempos de conmutación mínimos, la confiabilidad, la capacidad de producción en masa y la versatilidad de los CI.

Entre los circuitos integrados más complejos y avanzados se encuentran los microprocesadores, que controlan numerosos aparatos, desde teléfonos móviles y horno de microondas hasta computadoras. Los chips de memorias digitales son otra familia de circuitos integrados, de importancia crucial para la moderna sociedad de la información. Mientras que el costo de diseñar y desarrollar un circuito integrado complejo es bastante alto, cuando se reparte entre millones de unidades de producción, el costo individual de los CI por lo general se reduce al mínimo. La eficiencia de los CI es alta debido a que el pequeño tamaño de los chips permite cortas conexiones que posibilitan la utilización de lógica de bajo consumo (como es el caso de CMOS), y con altas velocidades de conmutación.

A medida que transcurren los años, los circuitos integrados van evolucionando: se fabrican en tamaños cada vez más pequeños, con mejores características y prestaciones, mejoran su eficiencia y su eficacia, y se permite así que mayor cantidad de elementos sean empaquetados (integrados) en un mismo chip (véase la ley de Moore). Al tiempo que el tamaño se reduce, otras cualidades también mejoran (el costo y el consumo de energía disminuyen, y a la vez aumenta el rendimiento). Aunque estas ganancias son aparentemente para el usuario final, existe una feroz competencia entre los fabricantes para utilizar geometrías cada vez más delgadas. Este proceso, y lo esperado para los próximos años, está muy bien descrito por la International Technology Roadmap for Semiconductors. 

Sólo ha trascurrido medio siglo desde que se inició su desarrollo y los circuitos integrados se han vuelto casi omnipresentes. Computadoras, teléfonos móviles y otras aplicaciones digitales son ahora partes de las sociedades modernas. La informática, las comunicaciones, la manufactura y los sistemas de transporte, incluyendo Internet, todos dependen de la existencia de los circuitos integrados. De hecho, muchos estudiosos piensan que la revolución digital causada por los circuitos integrados es uno de los sucesos más significativos de la historia de la humanidad.

Existen al menos tres tipos de circuitos integrados:


Atendiendo al nivel de integración —número de componentes— los circuitos integrados se pueden clasificar en:


En cuanto a las funciones integradas, los circuitos se clasifican en dos grandes grupos:



Algunos son diseñados y fabricados para cumplir una función específica dentro de un sistema mayor y más complejo.

En general, la fabricación de los CI es compleja ya que tienen una alta integración de componentes en un espacio muy reducido, de forma que llegan a ser microscópicos. Sin embargo, permiten grandes simplificaciones con respecto a los antiguos circuitos, además de un montaje más eficaz y rápido.

Existen ciertos límites físicos y económicos al desarrollo de los circuitos integrados. Básicamente, son barreras que se van alejando al mejorar la tecnología, pero no desaparecen. Las principales son:

Los circuitos eléctricos disipan potencia. Cuando el número de componentes integrados en un volumen dado crece, las exigencias en cuanto a disipación de esta potencia, también crecen, calentando el sustrato y degradando el comportamiento del dispositivo. Además, en muchos casos es un sistema de realimentación positiva, de modo que cuanto mayor sea la temperatura, más corriente conducen, fenómeno que se suele llamar "embalamiento térmico" y, que si no se evita, llega a destruir el dispositivo. Los amplificadores de audio y los reguladores de tensión son proclives a este fenómeno, por lo que suelen incorporar protecciones térmicas.

Los circuitos de potencia, evidentemente, son los que más energía deben disipar. Para ello su cápsula contiene partes metálicas, en contacto con la parte inferior del chip, que sirven de conducto térmico para transferir el calor del chip al disipador o al ambiente. La reducción de resistividad térmica de este conducto, así como de las nuevas cápsulas de compuestos de silicona, permiten mayores disipaciones con cápsulas más pequeñas.

Los circuitos digitales resuelven el problema reduciendo la tensión de alimentación y utilizando tecnologías de bajo consumo, como CMOS. Aun así en los circuitos con más densidad de integración y elevadas velocidades, la disipación es uno de los mayores problemas, llegándose a utilizar experimentalmente ciertos tipos de criostatos. Precisamente la alta resistividad térmica del arseniuro de galio es su talón de Aquiles para realizar circuitos digitales con él.

Este efecto se refiere principalmente a las conexiones eléctricas entre el chip, la cápsula y el circuito donde va montada, limitando su frecuencia de funcionamiento. Con pastillas más pequeñas se reduce la capacidad y la autoinducción de ellas. En los circuitos digitales excitadores de buses, generadores de reloj, etc, es importante mantener la impedancia de las líneas y, todavía más, en los circuitos de radio y de microondas.

Los componentes disponibles para integrar tienen ciertas limitaciones, que difieren de sus contrapartidas discretas.


Durante el proceso de fabricación de los circuitos integrados se van acumulando los defectos, de modo que cierto número de componentes del circuito final no funcionan correctamente. Cuando el chip integra un número mayor de componentes, estos componentes defectuosos disminuyen la proporción de chips funcionales. Es por ello que en circuitos de memorias, por ejemplo, donde existen millones de transistores, se fabrican más de los necesarios, de manera que se puede variar la interconexión final para obtener la organización especificada.




</doc>
<doc id="4534" url="https://es.wikipedia.org/wiki?curid=4534" title="Melchor Pérez de Holguín">
Melchor Pérez de Holguín

Melchor Pérez de Holguín (Cochabamba, Virreinato del Perú, 1660–1732) fue un pintor barroco. Nacido en Cochabamba, pasó la mayor parte de su vida y desarrolló su arte en la Villa Imperial de Potosí (Alto Perú, actual Bolivia).
Hijo legítimo de Diego Pérez Holguín y de Doña Esperanza Flores", contrajo matrimonio con la potosina Micaela del Castillo el 25 de marzo de 1695 en la Villa Imperial de Potosí.

Se desconoce quién pudo ser su maestro. Su producción principal se centró en los encargos realizados para órdenes religiosas católicas, como la franciscana y la dominicana.

Entre sus principales obras destacan: "El Juicio Final" (1706), "Triunfo de la Iglesia" (1708, parroquia de San Lorenzo, en Potosí), "Entrada del Virrey Morcillo en Potosí" (1718) "San Mateo" (1724), perteneciente a la serie de los Evangelistas de la moneda, "Virgen de la Merced", "La peregrina", "San Francisco de Asís" (1693, Museo de la Moneda, Potosí) y "San Pedro de Alcántara en éxtasis" (1701, Museo Nacional de Arte).

Su obra se inscribe en una Potosí crédula y milagrosa, donde el arte barroco se fundía con el carácter religioso español. La fe de Pérez de Holguín y sus conocimientos de religión, combinados con ciertas creencias sobrenaturales (paganismos), le mantuvieron en numerosas ocasiones al borde de la herejía.

Toda la obra de Holguín se realizó en la Villa Imperial. Hasta la fecha no se ha encontrado un solo cuadro firmado en otro lugar. Más tarde, sus obras fueron llevadas de Potosí a otras ciudades de Bolivia, y también al extranjero. 

El principal repositorio de cuadros de Holguín es la Casa Nacional de Moneda, que posee cuadros auténticos, entre los que sobresalen los bustos de San Mateo Evangelista y de San Pedro de Alcantara, los retratos de San Bernardo y San Juan de Dios, un Pentecostés, la excelente Sagrada Familia con San Luis Rey de Francia y San Luis de Gonzaga, el Nacimiento (fechado en 1701), un San Francisco de Asís (firmado en 1694, y que hace par con otro San Pedro de Alcántara), y la serie de los cuatro Evangelistas de cuerpo entero, firmada en 1724.

No se puede calcular la cantidad de los cuadros que salieron de Bolivia, pues su exportación fue clandestina. Se conoce solamente lo que se exhibe en museos públicos, por ejemplo, un San Francisco de Paula que hoy se conserva en el Museo de Arte Hispanoamericano Isaac Fernández Blanco de Buenos Aires, una Huida a Egipto, identificada por Cecilio Guzmán de Rojas en el Museo de Santiago de Chile, y la Entrada del Virrey Morcillo en Potosí, que se expone en el Museo de América en Madrid.

¿Cuanto produjo Holguín? Esta es una pregunta que tal vez nunca pueda responderse, pero la gran cantidad de cuadros existentes en Bolivia, después de un saqueo secular que sufre Potosí, nos da la pauta. Cobró fama desde la época virreinal, no otra cosa significa que su nombre sea el único que aparezca en el inventario de la pinacoteca de los jesuitas de Potosí, levantado en 1769, que se conserven hasta el presente otros documentos de esa época que nos refieran de sus obras, y que, finalmente, un informante de fines del virreinato, diga que Holguín fue un "pintor eminente", a quien llamaban "Brocha de Oro".




</doc>
<doc id="4535" url="https://es.wikipedia.org/wiki?curid=4535" title="Surrealismo">
Surrealismo

El surrealismo es un movimiento artístico surgido en Francia a partir del dadaísmo, en la década de los años 1920, en torno a la personalidad del poeta André Breton.

El término proviene del francés: "surréalisme"; "sur" ['sobre o por encima'] más "réalisme" ['realismo']. Fue acuñado por el escritor francés Guillaume Apollinaire en 1917. En el programa de mano que escribió para el musical "Parade" (mayo de 1917) afirma que sus autores han conseguido:

La palabra surrealista aparece en el subtítulo de "Las tetas de Tiresias (drama surrealista)", en junio de 1917, para referirse a la reproducción creativa de un objeto, que lo transforma y enriquece. Como escribe Apollinaire en el prefacio al drama:

También es definido como:

Los surrealistas señalaron como precedentes de la empresa surrealista a varios pensadores y artistas, como el pensador presocrático Heráclito, el Marqués de Sade y Charles Fourier, entre otros. Las teorías psicoanalíticas de Sigmund Freud sobre el sueño y el subconsciente fueron sin duda uno de los pilares en la creación del pensamiento surrealista. 

En cuanto a las artes, la poesía surrealista bebe de la dialéctica y encuentra precursores en Arthur Rimbaud, Alfred Jarry o Lautréamont. En la pintura, el precedente más notable es Giorgio de Chirico y su pintura metafísica, así como Hieronymus Bosch "el Bosco", que en los siglos XV y XVI creó obras como "El jardín de las delicias" o "El carro de heno". El surrealismo retoma estos elementos y ofrece una formulación sistemática de los mismos. Sin embargo su precedente más inmediato es el dadaísmo, corriente de la que retoma diferentes aspectos.

La primera fecha histórica del movimiento es 1916, año en que André Breton, precursor, líder y gran pensador del movimiento, descubre las teorías de Sigmund Freud y Alfred Jarry, además de conocer a Jacques Vaché y a Guillaume Apollinaire. Durante los siguientes años se da un confuso encuentro con el dadaísmo, movimiento artístico precedido por Tristan Tzara, en el cual se decantan las ideas de ambos movimientos. Estos, uno inclinado hacia la destrucción nihilista (dadá) y el otro a la construcción romántica (surrealismo) se sirvieron como catalizadores entre ellos durante su desarrollo.

En el año 1924 Breton escribe el primer "" y en este incluye lo siguiente:

Tal fue la definición del término dada por los propios Breton y Soupault en el primer "Manifiesto Surrealista" fechado en 1924. Surgió por tanto como un movimiento poético, en el que pintura y escultura se conciben como consecuencias plásticas de la poesía.

En "El surrealismo y la pintura", de 1928, Breton expone la psicología surrealista: el inconsciente es la región del intelecto donde el ser humano no objetiva la realidad sino que forma un todo con ella. El arte, en esa esfera, no es representación sino comunicación vital directa del individuo con el todo. Esa conexión se expresa de forma privilegiada en las casualidades significativas (azar objetivo), en las que el deseo del individuo y el devenir ajeno a él convergen imprevisiblemente, y en el sueño, donde los elementos más dispares se revelan unidos por relaciones secretas. El surrealismo propone trasladar esas imágenes al mundo del arte por medio de una asociación mental libre, sin la intromisión censora de la conciencia. De ahí que elija como método el automatismo, recogiendo en buena medida el testigo de las prácticas mediúmnicas espiritistas, aunque cambiando radicalmente su interpretación: lo que habla a través del médium no son los espíritus, sino el inconsciente.

Durante unas sesiones febriles de automatismo, Breton y Soupault escriben "Los Campos Magnéticos", primera muestra de las posibilidades de la escritura automática, que publican en 1921. Más adelante Breton publica "Pez soluble". Dice así el final del séptimo cuento:
A partir de 1925, a raíz del estallido de la Guerra del Rif, el surrealismo se politiza; se producen entonces los primeros contactos con los comunistas, que culminarían ese mismo año con la adhesión al Partido Comunista por parte de Breton.

Entre 1925 y 1930 aparece un nuevo periódico titulado "El Surrealismo al servicio de la Revolución" en cuyo primer número Louis Aragón, Buñuel, Dalí, Paul Éluard, Max Ernst, Yves Tanguy y Tristan Tzara, entre otros, se declaran partidarios de Breton. Por su parte Jean Arp y Miró, aunque no compartían la decisión política tomada por Breton, continuaban participando con interés en las exposiciones surrealistas. Poco después se incorporaron Magritte (1930), Masson (1931), Giacometti y Brauner en 1933 y también Matta (que conoce a Breton en 1937 por mediación de Dalí) y Lam; el movimiento se hizo internacional apareciendo grupos surrealistas en los Estados Unidos, Dinamarca, Londres, Checoslovaquia y Japón. Desde este momento, se abrirá una disputa, a menudo agria, entre aquellos surrealistas que conciben el surrealismo como un movimiento puramente artístico, rechazando la supeditación al comunismo, y los que acompañan a Breton en su giro a la izquierda.

En 1929 Breton publica el "Segundo Manifiesto Surrealista", en el que condena entre otros intelectuales a los artistas Masson y Francis Picabia. En 1936 expulsa a Dalí por querer mantenerse neutral frente a la politización del movimiento y no condenar el nazismo alemán, y a Paul Éluard. En 1938 Breton firma en México junto con León Trotski y Diego Rivera el "Manifiesto por un Arte Revolucionario Independiente".

El surrealismo tomó del dadaísmo algunas técnicas de fotografía y cinematografía así como la fabricación de objetos. Extendieron el principio del "collage" (el "objeto encontrado") al ensamblaje de objetos incongruentes, como en los poemas visibles de Max Ernst. Este último inventó el "frottage" (dibujos compuestos por el roce de superficies rugosas contra el papel o el lienzo) y lo aplicó en grandes obras como "Historia Natural", pintada en París en 1926.

Crearon el cadáver exquisito, en el cual varios artistas dibujaban las distintas partes de una figura o de un texto sin ver lo que el anterior había hecho pasándose el papel doblado. Las criaturas resultantes pudieron servir de inspiración a Miró.

En el terreno literario, el surrealismo supuso una gran revolución en el lenguaje y la aportación de nuevas técnicas de composición. Como no asumía tradición cultural alguna, ni desde el punto de vista temático ni formal, prescindió de la métrica y adoptó el tipo de expresión poética denominado como versículo: un verso de extensión indefinida sin rima que se sostiene únicamente por la cohesión interna de su ritmo. Igualmente, como no se asumía la temática consagrada, se fue a buscar en las fuentes de la represión psicológica (sueños, sexualidad) y social, con lo que la lírica se rehumanizó después de que los ismos intelectualizados de las Vanguardias la deshumanizaran, a excepción del Expresionismo. Para ello utilizaron los recursos de la transcripción de sueños y la escritura automática, y engendraron procedimientos metafóricos nuevos como la imagen visionaria. El lenguaje se renovó también desde el punto de vista del léxico dando cabida a campos semánticos nuevos y la retórica se enriqueció con nuevos procedimientos expresivos.

Masson adoptó enseguida las técnicas del automatismo, hacia 1923-1924, poco después de conocer a Breton. Hacia 1929 las abandonó para volver a un estilo cubista. Por su parte, Dalí utilizaba más la fijación de imágenes tomadas de los sueños, según Breton, «...abusando de ellas y poniendo en peligro la credibilidad del surrealismo...»; inventó lo que él mismo llamó método paranoico-crítico, una mezcla entre la técnica de observación de Leonardo da Vinci, por medio de la cual, observando una pared se podía ver cómo surgían formas y técnicas de "frottage"; fruto de esta técnica son las obras en las que se ven dos imágenes en una sola configuración. Óscar Domínguez inventó la decalcomanía (aplicar gouache negro sobre un papel el cual se coloca encima de otra hoja sobre la que se ejerce una ligera presión, luego se despegan antes de que se sequen). Además de las técnicas ya mencionadas de la decalcomanía y el "frottage", los surrealistas desarrollaron otros procedimientos que incluyen igualmente el azar: el raspado, el "fumage" y la distribución de arena sobre el lienzo encolado.

Miró fue para Breton el más surrealista de todos, por su automatismo psíquico puro. Su surrealismo se desenvuelve entre las primeras obras donde explora sus sueños y fantasías infantiles ("El Campo labrado"), las obras donde el automatismo es predominante ("Nacimiento del mundo") y las obras en que desarrolla su lenguaje de signos y formas biomorfas ("Personaje lanzando una piedra"). Arp combina las técnicas de automatismo y las oníricas en la misma obra desarrollando una iconografía de formas orgánicas que se ha dado en llamar "escultura biomórfica", en la que se trata de representar lo orgánico como principio formativo de la realidad.

René Magritte dotó al surrealismo de una carga conceptual basada en el juego de imágenes ambiguas y su significado denotado a través de palabras poniendo en cuestión la relación entre un objeto pintado y el real. Paul Delvaux carga a sus obras de un espeso erotismo basado en su carácter de extrañamiento en los espacios de Giorgio de Chirico.

El surrealismo penetró la actividad de muchos artistas europeos y americanos en distintas épocas. Pablo Picasso se alió con el movimiento surrealista en 1925; Breton declaraba este acercamiento de Picasso calificándolo de «...surrealista dentro del cubismo...». Se consideran surrealistas las obras del período Dinard (1928-1930), en que Picasso combina lo monstruoso y lo sublime en la composición de figuras medio máquinas medio monstruos de aspecto gigantesco y a veces terrorífico. Esta monumentalidad surrealista de Picasso puede ponerse en paralelo con la de Henry Moore y en la poesía y el teatro con la de Fernando Arrabal.

Otros movimientos pictóricos nacieron del surrealismo o lo prefiguran, como por ejemplo el Art brut.

En 1938 tuvo lugar en París la Exposición Internacional del Surrealismo que marcó el apogeo de este movimiento antes de la guerra. Participaron entre otros, Marcel Duchamp, Jean Arp, Dalí, Max Ernst, Masson, Man Ray, Óscar Domínguez y Meret Oppenheim. La exposición ofreció al público sobre todo una excelente muestra de lo que el surrealismo había producido en la fabricación de objetos.

Con el estallido de la Segunda Guerra Mundial, los surrealistas se dispersan, algunos de ellos (Dalí, Breton, Ernst, Masson) abandonan París y se trasladan a los Estados Unidos, donde siembran el germen para los futuros movimientos americanos de posguerra (expresionismo abstracto y Arte Pop).

En España el surrealismo aparece en torno a los años veinte no en su vertiente puramente vanguardista sino mezclado con acentos simbolistas y de la pintura popular. Además de Joan Miró y Salvador Dalí, el surrealismo español lo componen Maruja Mallo, Gregorio Prieto, José Moreno Villa, Benjamín Palencia y José Caballero, además de los neocubistas que se pasan al surrealismo (Alberto Sánchez y Ángel Ferrant).

Hubo un importante núcleo surrealista en las Islas Canarias, agrupado en torno a la "Gaceta de Arte" de Eduardo Westerdahl, del que un grupo de poetas invitaron a André Bretón a venir en 1935; allí compuso este el poema "Le chateau etoilé" y otras obras. Los máximos representantes de la pintura surrealista en el archipiélago fueron Óscar Domínguez, Juan Ismael y el propio Westerdahl.

En Latinoamérica se consideran surrealistas, además de los ya citados Roberto Matta (Chile) y Lam, a Remedios Varo y Leonora Carrington (ambas inmigrantes europeas posteriormente nacionalizadas mexicanas).

La que es considerada como la primera exposición surrealista en Latinoamérica se llevó a cabo en Lima, Perú en 1935 por iniciativa de los poetas y pintores surrealistas peruanos César Moro y Emilio Adolfo Westphalen. Posteriormente en México, en enero de 1940, el mismo César Moro con André Breton y Wolfgang Paalen logran presentar en la Galería de Arte Mexicano una selección de cuarenta obras tanto de representantes del movimiento surrealista como de americanos cuyo trabajo tenía afinidad con el movimiento.. Existe un debate sobre si la obra de Frida Kahlo pertenece a la corriente surrealista. Breton consideraba a México la esencia del surrealismo e interpretaba sus obras como surrealistas, si bien la propia Kahlo decía claramente "Yo no pinto sueños... pinto mi realidad".

Es de destacar el aporte al movimiento realizado desde Buenos Aires, Argentina, en ese entonces considerada como la capital latinoamericana de la cultura, de artistas y literatos como Aldo Pellegrini, Planas Casas y Batlle Planas. 

El surrealismo fue seguido con interés por los intelectuales españoles de los años 30. Existía el precedente de Ramón Gómez de la Serna, quien utilizaba algunas fórmulas vinculables al surrealismo, como la greguería.

Varios poetas de la generación del 27 se interesaron por las posibilidades expresivas del surrealismo. El primero en adoptar sus métodos fue José María Hinojosa, autor de "La flor de Californía" (1928), libro pionero de prosas narrativas y oníricas. Su huella también es evidente en libros como en la sección tercera de "Sobre los ángeles" y en "Sermones y moradas" de Rafael Alberti; en "Poeta en Nueva York" de Federico García Lorca y "Un río, un amor" y "Los placeres prohibidos" de Luis Cernuda. Vicente Aleixandre se definió a sí mismo como "un poeta superrealista", aunque matizando que su poesía no era en modo alguno producto directo de la escritura automática. Miguel Hernández sufrió una efímera etapa surrealista y durante la posguerra la impronta surrealista se percibe en los poetas del Postismo y en Juan Eduardo Cirlot, y en la actualidad existe un cierto postsurrealismo en la obra de algunos poetas como Blanca Andreu.

Pero puede decirse que fue solo en Canarias donde la aventura surrealista tuvo, en el primer minuto del movimiento, auténtica expresión, esto es, declarada vinculación al movimiento pero sin instalarse en París: la Facción Surrealista de Tenerife, tal como la describiera Domingo Pérez Minik posteriormente. Todos sus componentes, liderados por Agustín Espinosa y vinculados a París por el pintor tinerfeño Óscar Domínguez, venían de la experiencia de la vanguardia insular con la revista "La Rosa de los Vientos", aparecida en 1926, y continuarían trabajando en la renovación artística y literaria de las islas en Gaceta de Arte, una de las más importantes revistas de la vanguardia hispánica, con diverso contenido de vanguardia internacional y con colaboradores no surrealistas como Domingo Pérez Minik y Eduardo Westerdahl. Aparte de Espinosa, Pedro García Cabrera, Emeterio Gutiérrez Albelo, Domingo López Torres y José María de la Rosa completan la nómina de escritores surrealistas con obras como "Crimen" (1934) -considerada por algunos como la mejor prosa surrealista en lengua castellana-, "Romanticismo y cuenta nueva" (1933), "Enigma del invitado" (1936), "Dársena con despertadores" (1936), "Lo imprevisto" (1937) y "Vértice de sombra" (1936). Juan Ismael se uniría a Óscar Domínguez en la plástica, pero desarrollando su actividad en las islas. Como en los demás casos, la Guerra Civil Española acabó con el grupo y con la vida de alguno de ellos, como López Torres -ahogado por los nacionales- o Espinosa, que murió poco después del golpe de Estado; García Cabrera, por su parte, sería detenido y huiría, uniéndose a las tropas republicanas. Sin embargo, la actividad había llegado a su culmen con la visita de André Breton y Benjamin Péret a Tenerife en 1935, organizando una exposición de pintura, firmando el Segundo Boletín Internacional del Surrealismo, intentando proyectar La Edad de Oro de Luis Buñuel -prohibida por el gobierno de la isla- y dejando en Breton un recuerdo que constituirá el contenido del capítulo V de su L'amour fou (1937).

Aunque no se le pueda considerar un surrealista estricto, el poeta y pensador Juan Larrea vivió de primera mano la eclosión del movimiento en París y reflexionó más tarde sobre su valor y trascendencia en obras como "Surrealismo entre viejo y nuevo mundo" (1944). En la actualidad existe una corriente de neosurrealismo en la poesía de Blanca Andreu. El español Fernando Arrabal tuvo una asistencia diaria al "café surrealista" La Promenade de Vénus de 1960 a 1963. André Breton publicó su teatro, su "Piedra de la locura" y algunos de sus cuadros.

En Hispanoamérica el surrealismo contó con la adhesión entusiasta de poetas como el chileno Braulio Arenas y los peruanos César Moro, Xavier Abril y Emilio Adolfo Westphalen, además de influir en la obra del escritor cubano Alejo Carpentier y de los poetas chilenos Pablo Neruda, Gonzalo Rojas y el peruano César Vallejo. En Argentina, pese al desdén de Jorge Luis Borges, el surrealismo sedujo aún al joven Julio Cortázar y produjo un fruto tardío en la obra de Alejandra Pizarnik. El poeta y pensador mexicano Octavio Paz ocupa un lugar particular en la historia del movimiento: amigo personal de Breton, dedicó al surrealismo varios ensayos esclarecedores.

El surrealismo tuvo como antecedente la patafísica de Alfred Jarry, y el movimiento dadaísta fundado en Zúrich en 1916 por T. Tzara, H. Ball y H. Arp. Animados por idéntico espíritu de provocación, André Breton, Louis Aragon y Philippe Soupault fundaron en París la revista "Littérature" (1919), mientras en EE. UU. manifestaban actitudes similares Man Ray, Marcel Duchamp y Francis Picabia, y en Alemania, Max Ernst y Hugo Ball.

A esta fase sucedió una actitud más metódica de investigación del inconsciente, emprendida por Breton, junto a Aragon, Paul Éluard, Soupault, Robert Desnos, Max Ernst, etc. La primera obra de esta tendencia, que cabe calificar de primera obra literaria surrealista, fue "Los campos magnéticos" (1921), escrita conjuntamente por Breton y Soupault. Tras la ruptura con Tzara, se adhirieron al movimiento Antonin Artaud, André Masson y Pierre Naville.

Breton redactó la primera definición del movimiento en su "Manifiesto del surrealismo" (1924), texto que dio cohesión a los postulados y propósitos del movimiento. Entre los autores que citaba como precursores del movimiento figuran Freud, Lautréamont, Edward Young, Matthew Lewis, Gérard de Nerval, Jonathan Swift, Marqués de Sade, François-René de Chateaubriand, Victor Hugo, Edgar Allan Poe, Charles Baudelaire, Arthur Rimbaud, Mallarmé y Jarry. En el mismo año se fundó el Bureau de recherches surréalistes y la revista "La Révolution Surréaliste", que sustituyó a "Littérature", de cuya dirección se hizo cargo el propio Breton en 1925 y que se convirtió en el órgano de expresión común del grupo.

La producción surrealista se caracterizó por una vocación libertaria sin límites y la exaltación de los procesos oníricos, del humor corrosivo y de la pasión erótica, concebidos como armas de lucha contra la tradición cultural burguesa. Las ideas del grupo se expresaron a través de técnicas literarias, como la «escritura automática», las provocaciones pictóricas y las ruidosas tomas de posición públicas. El acercamiento operado a fines de los años veinte con los comunistas produjo las primeras querellas y cismas en el movimiento.

En 1930 Breton publicó su "Segundo manifiesto del surrealismo", en el que "excomulgaba" a Joseph Delteil, Antonin Artaud, Philippe Soupault, Robert Desnos, Georges Limbour, André Masson, Roger Vitrac, Georges Ribemont-Dessaignes y Francis Picabia. El mismo año apareció el nuevo órgano del movimiento, la revista "Le Surréalisme au Service de la Révolution", que suplantó al anterior, "La Révolution Surréaliste", y paralelamente, Aragon (tras su viaje a la URSS), Éluard, Péret y Breton ingresaron en el Partido Comunista. A fines de 1933, Breton, Éluard y Crevel fueron expulsados del partido. En los años treinta se sumaron al movimiento Salvador Dalí, Luis Buñuel, Yves Tanguy, René Char y Georges Sadoul. Ya expulsado del grupo por Breton, Dalí publicó en 1942 "La Vida Secreta de Salvador Dalí", autobiografía que reúne muchos de los elementos propios del surrealismo y que constata las virtudes literarias de un Dalí en pleno auge creativo.

Tras los años previos a la II Guerra Mundial, marcados por la militancia activa de Breton, y los años de exilio neoyorquino de la mayoría de sus miembros, durante la ocupación alemana de Francia, el movimiento siguió manteniendo cierta cohesión y vitalidad, pero a partir de 1946, cuando Breton regresó a París, el surrealismo era ya parte de la historia.

Al principio el surrealismo era un movimiento fundamentalmente literario, y hasta un poco más tarde no produciría grandes resultados en las artes plásticas. Surge un concepto fundamental, el automatismo, basado en una suerte de dictado mágico, procedente del inconsciente, gracias al cual surgían poemas, ensayos, etc., y que más tarde sería recogido por pintores y escultores.

La primera exposición surrealista se celebró en la Galerie Pierre de París en 1925, y en ella, además de Jean Arp, Giorgio de Chirico y Max Ernst, participaron artistas como André Masson, Picasso, Man Ray, Pierre Roy, P. Klee y Joan Miró, que posteriormente se separarían del movimiento o se mantendrían unidos a él adoptando únicamente algunos de sus principios. A ellos se adhirieron Yves Tanguy, René Magritte, Salvador Dalí y Alberto Giacometti.

La rebelión del surrealismo contra la tradición cultural burguesa y el orden moral establecido tuvo su cariz político, y un sector del surrealismo, que no consideraba suficientes los tumultos de sus manifestaciones culturales, se afilió al Partido Comunista Francés. Sin embargo, nacieron violentas discrepancias en el seno del grupo a propósito del debate sobre la relación entre arte y política; se sucedieron manifiestos contradictorios y el movimiento tendió a disgregarse. Es significativo, a este respecto, que la revista «La révolution surréaliste» pase a llamarse, desde 1930, «Le surréalisme au service de la révolution». En los años 1930, el movimiento se extendió más allá de las fronteras francesas. Se celebró en 1938 en París la Exposición Surrealista Internacional.

La segunda guerra mundial paralizó toda actividad en Europa. Ello motivó que Breton, como muchos otros artistas, marchase a los EE. UU. Allí surgió una asociación de pintores surrealistas alemanes y franceses que se reunió en torno a la revista VVV. Estos surrealistas emigrados a EE. UU. influyeron en el arte estadounidense, en particular en el desarrollo del expresionismo abstracto en los años 1940. Cuando Breton regresó a Europa en 1946 el movimiento estaba ya definitivamente deteriorado.

Entre los artistas plásticos se manifiesta una dualidad en la interpretación del surrealismo: los surrealistas abstractos, que se decantan por la aplicación del automatismo puro, como André Masson o Joan Miró, e inventan universos figurativos propios; y los surrealistas figurativos, interesados por la vía onírica, entre ellos René Magritte, Paul Delvaux, o Salvador Dalí, que se sirven de un realismo minucioso y de medios técnicos tradicionales, pero que se apartan de la pintura tradicional por la inusitada asociación de objetos y las monstruosas deformaciones, así como por la atmósfera onírica y delirante que se desprende de sus obras. Max Ernst es uno de los pocos surrealistas que se mueve entre las dos vías. La obra de Ernst ha influido particularmente en un epígono tardío del surrealismo en Alemania que es Stefan von Reiswitz.

En la vertiente cinematográfica, el surrealismo dio lugar a varios intentos enmarcados en el cine de las vanguardias históricas, como "La Coquille et le clergyman" (1926) 'La caracola y el clérigo', de Germaine Dulac o "L'étoile de mer" (1928) 'La estrella de mar', de Man Ray y Robert Desnos, un cortometraje dadaísta.

Luis Buñuel, en colaboración con Dalí, realizó las obras más revolucionarias: "Un perro andaluz" ("Un chien andalou", 1928) y "La edad de oro" ("L'âge d'or", 1930).

Alfred Hitchcock y Salvador Dalí colaboraron cuando el primero encargó al artista catalán parte de la escenografía de "Recuerda" ("Spellbound").

Cineastas contemporáneos, como David Lynch, Jean-Pierre Jeunet, Alejandro Jodorowsky, Julio Médem, o Carlos Atanes, Jan Švankmajer entre otros, muestran la influencia del surrealismo.





</doc>
<doc id="4536" url="https://es.wikipedia.org/wiki?curid=4536" title="Puntillismo">
Puntillismo

El puntillismo es un estilo de pintura que consiste en hacer una obra mediante puntos. Aparece por primera vez en 1886, encabezado por el pintor neoimpresionista Georges Seurat, y contando entre sus seguidores más fieles tales como Henri-Edmond Cross y Vlaho Bukovac. El procedimiento de pintura empleado por estos artistas, consiste en poner puntos de colores puros en vez de pinceladas sobre la tela. Este fue el resultado de los estudios cromáticos llevados a cabo por Georges Seurat (1859-1891), pintor francés, quien en 1884 llegó a la división de tonos por la posición de toques de color que, mirados a cierta distancia, crean en la retina las combinaciones deseadas. Otro de los más importantes seguidores del puntillismo fue Paul Signac, participante junto con Seurat y otros neoimpresionistas en la Société des Artistes Indépendants (1884), todos ellos seguidores del puntillismo o divisionismo.

Este movimiento, dentro de las coordenadas del postimpresionismo, parte también de la imagen de la naturaleza, es decir, del mismo motivo que los impresionistas, pero para ellos serán unas leyes físicas y fisiológicas muy determinadas las que caractericen la esencia de la pintura. Su material de reflexión serán, sobre todo, los escritos de Charles Blanc y, de un modo más radical los impresionistas, los tratados científicos de Chevreul, Sutter, Rood y otros. 

Gracias a ellos, el puntillismo vio abierto ante sí un campo en el que su tarea habría de ser la aplicación metódica de sus conocimientos y la reconciliación de los rígidos principios del dibujo con los principios ópticos intuidos por los grandes coloristas. La mente lógica y reflexiva de estos pintores pedía la reducción del instinto al orden, del impulso al cálculo, reduciendo a lo esencial, no solo los temas de la vida moderna o el paisaje, sino también el método impresionista de presentarlo
De hecho, la declaración de Charles Blanc («El color, que está controlado por leyes fijas, se puede enseñar como la música»), publicada por primera vez en 1865 en su conocida "Gramatica Ades arts du dessin", resume perfectamente la actitud de los puntillistas ante las posibilidades expresivas del arte e indica su programa. Según esto, al igual que existen relaciones matemáticas entre los tonos musicales, hay relaciones físicas entre los colores, que pueden demostrarse en el laboratorio y llevarse a efecto en el estudio. Con el fin de estudiar con más detalle la interacción de los colores y sus complementarios, algunos puntillistas confeccionaron un disco en el que reunían todos los matices del arco iris, unidos unos a otros mediante un número determinado de colores intermedios.

En su paleta también utilizaban el blanco mezclado con los colores primarios, lo que les permitía obtener una multitud de tonos que iban de un color con una ligera presencia de blanco hasta un blanco casi puro. El disco se completaba de manera que los matices puros se concentraban en torno al centro, desde donde iban desvaneciéndose hacia el blanco hasta llegar a la periferia.

Los experimentos físicos habían probado también que la mezcla de colores los ensucia y desemboca finalmente en el negro. Por ello, la única mezcla capaz de producir el efecto deseado es la mezcla óptica, que se convierte así en el factor predominante de su ejecución. Tras haber reunido por separado en sus telas los elementos individuales de color presentes en la naturaleza, el pintor asignaba a la retina del espectador la tarea de unirlos de nuevo. La técnica de pinceladas de los impresionistas no permitía la exactitud matemática que necesitaban los puntillistas para aplicar su sistema con pleno rendimiento. 

Mediante la adopción de minúsculas pinceladas en forma de punto lograron acumular, incluso sobre superficies reducidas, una gran variedad de colores y tonos, cada uno de los cuales se correspondía con uno de los elementos que contribuía a la apariencia del objeto. A una distancia determinada esas partículas diminutas se mezclan ópticamente y el resultado tenía que producir una intensidad de colores mucho mayor que cualquier mezcla de pigmentos. 

En este sentido, sus estudios de luz y color sobrepasan los realizados por cualquiera de los impresionistas, pero también se encontraron con mayores dificultades. Con más conocimientos y un ojo más disciplinado, tenían que hallar todos los matices del espectro luminoso, así como un modo de iluminar u oscurecer un matiz dado en relación con los contrastes simultáneos producidos por los colores que le rodeaban. Una de las obras más notables en ese sentido es "Tarde de domingo en la isla de la Grande Jatte" de Surat.

A pesar de lo aparentemente acertado de la denominación de puntillismo, sobre todo en lo que se refiere a la técnica de este grupo, ni Seurat ni Signac la aceptaron nunca y ambos condenaron y evitaron rigurosamente este término a favor del de divisionismo, que abarcaba mejor todas sus innovaciones.


Algunos compositores trasladaron las conclusiones del método puntillista al campo musical. Así como el ojo compone colores que no están ahí, el oído hace lo propio: relaciona los sonidos separados y los interpreta como una melodía. Pero, al contrario que el movimiento pictórico, el puntillismo musical persigue la disociación.
Cabe notar que esta tendencia sirve como base para el desarrollo y creación de imágenes musicales tomando los pixeles musicales como estructura básica en la percepción visual de una imagen. teniendo en cuenta la teoría del cromatismo para la deficion del color dentro de la escala cromatica musical.



</doc>
<doc id="4537" url="https://es.wikipedia.org/wiki?curid=4537" title="Manuel Pereira">
Manuel Pereira

Manuel Pereira (Oporto, 1588-Madrid, 29 de enero de 1683) fue un escultor barroco portugués avecindado en Madrid, donde realizó buena parte de su obra.

Nacido en Oporto en 1588, no se conoce otro dato de su vida y actividad hasta 1624, cuando ejecutó las estatuas en piedra de la iglesia de la Compañía de Jesús en Alcalá de Henares. Un año después se encontraba ya en Madrid, a donde se había trasladado en compañía de su madre y de su hermano Pantaleón Gómez, también escultor, que colaboró con él hasta su muerte en 1645. En 1625 contrajo matrimonio en Madrid con María González de Estrada, del que nacerán dos hijos, enviudando en 1639. En 1635 se encontraba en prisión por deudas, saliéndole fiadores el ensamblador Juan Bautista Garrido y el pintor Jusepe Leonardo, policromador de algunas de sus obras. 

En un curioso contrato, por el que el ensamblador y arquitecto Pedro de la Torre se comprometía en 1652 a realizar el retablo de la capilla del beato Simón de Rojas en la iglesia de la Trinidad de Madrid, se pone como condición que las esculturas han de ser de mano de Pereira o de Juan Sánchez Barba, «y no de ningún otro», condición que se repetiría en 1661 en el contrato de un retablo para el convento de la Merced con el ensamblador Juan de Ocaña. En ambos casos parece que el elegido fue Sánchez Barba, el único imaginero que podía competir en Madrid con Pereira en estos años. 

Obtuvo el nombramiento de Familiar del Santo Oficio, título que preferirá en su testamento al de escultor, para lo que hubo de presentar pruebas de limpieza de sangre. El mismo prurito nobiliario pondrá de manifiesto al casar a su hija Damiana con José de Mendieta, caballero de la Orden de Santiago, a la que también pertenecerán sus nietos, alegando un testigo «que él y sus ascendientes eran cavalleros fidalgos del Reyno de Portugal, donde havían exercido los oficios y ocupaciones que en aquel Reyno sólo pueden tener los cavalleros hixodalgos». Murió en Madrid en 1683, casi ciego y después de más de diez años de inactividad.

Discípulos o colaboradores fueron, además de su hermano Pantaleón ya citado, Manuel Correa, natural también de Oporto y doce años más joven, Manuel Delgado y el navarro José Martínez.

Aunque se supone que su formación tuvo lugar en Oporto Pereira se va a convertir en uno de los grandes representantes de la escuela madrileña de escultura. A excepción de un grupo de esculturas destinadas al convento portugués de Santo Domingo de Benfica, de las que se ocupó sin salir de Madrid en 1636 por encargo del conde de Figueiro, todas sus obras conocidas se distribuyen entre Madrid, Alcalá de Henares, Burgos, Segovia y otras localidades próximas. Pereira fue exclusivamente escultor, en piedra, alabastro o madera, no ocupándose nunca de la arquitectura de sus retablos ni del policromado. Tampoco se conocen relieves de su mano y su obra, aun trabajando para la corte, es casi exclusivamente religiosa, mencionándose tan sólo la ejecución de una escultura de "Neptuno" fuera de ese género.

Establecido en la corte desde joven, su obra revela un espíritu clásico. En sus figuras de canon alargado, expresión sobria y sereno patetismo, evitará siempre la crudeza y el gesto desgarrado. Su primera obra conocida es de 1624, para la fachada de la iglesia de la Compañía de Jesús de Alcalá de Henares, donde realizó varias figuras de santos. A la manera de la escuela castellana, las figuras son de volúmenes amplios y pliegues secos y quebrados, pero en el "San Bernardo" que realizó en fecha poco posterior para la fachada de las Bernardas de la misma ciudad se encuentran ya las características de su propio estilo, quizá influido por Alonso Cano. Estas obras hechas en Alcalá le proporcionarán de inmediato notable fama y los siguientes encargos irán en la misma línea: estatuas en madera para retablos y santos en piedra para ocupar las hornacinas de las fachadas de iglesias y otros edificios públicos, como la Cárcel de Corte, destacando entre las conservadas el "San Antonio de Padua" de la iglesia de San Antonio de los Portugueses en Madrid (1647) y, muy especialmente, el "San Bruno" de la Hospedería que la Cartuja de El Paular tenía en la calle de Alcalá de Madrid (1652), actualmente en la Real Academia de Bellas Artes de San Fernando, talla ante la que, según Antonio Palomino, acostumbraba a detenerse el rey Felipe IV.

En madera realizó una serie de imágenes de gran realismo y de extraordinaria intensidad expresiva, entre las que se pueden destacar el "San Marcos" de la parroquial de Martín Muñoz de las Posadas (Segovia), en actitud mística, el "San Antonio de Padua" del retablo mayor de la iglesia de San Antonio de los Portugueses en Madrid, 1631, o el "San Bruno" de la Cartuja de Miraflores, anterior a 1635. Muy notables son también una serie de Cristos crucificados, de cuerpo estilizado y rostro intensamente emotivo, encabezados, al parecer, por el "Crucifijo" de la parroquia del Sagrario de la catedral de Sevilla. Consta que en 1646 don Alonso de Aguilar, regidor de Segovia, encargó a Pereira otro Cristo que había de seguir el modelo del que anteriormente había realizado para el obispo de la misma ciudad castellana. Este segundo Crucificado ha sido identificado con el llamado "Cristo de Lozoya", actualmente localizado en la catedral de Segovia, que es, sin duda, el más célebre de la serie y aquél en el que Cristo se presenta con los brazos elevados en mayor tensión. Otro más, ricamente policromado, se encuentra en el Oratorio del Olivar de Madrid, diferente de los anteriores por la posición más abierta de los brazos. 

Suyas serán también las esculturas en madera que ocupan los altares de los machones en el madrileño Convento de San Plácido, con el ladeamiento de las cabezas y la estilización de los cuerpos que son características del maestro. Fueron célebres, además, algunas esculturas destruidas al estallar la guerra civil de 1936, entre ellas el "Cristo del Perdón" de los dominicos del Rosario de Madrid, según Palomino «cosa portentosa, a que ayudó mucho la encarnación, de mano de Camilo», del que existe una réplica, posiblemente del propio Pereira, en la capilla de los marqueses de Comillas en Cantabria, y la talla del santo titular en el retablo, labrado según trazas de Alonso Cano, de la iglesia de San Andrés. Para la capilla de San Isidro en la misma iglesia madrileña, iniciada su construcción en 1657, ejecutó una serie de santos labradores que, ya en el reinado de Carlos III, tras la expulsión de los jesuitas, pasaron a la iglesia del Colegio Imperial repintadas de blanco conforme a la moda neoclásica, resultando igualmente destruidas en 1936. 

Otras obras que se pueden relacionar con Pereira son una Inmaculada Concepción en el convento de Agustinas Recoletas de Pamplona, el "Ecce Homo" de las Carmelitas de Larrea (Vizcaya) y un crucifijo conservado en la iglesia de San Juan de Rabanera de Soria, lleno de tensión barroca y elevando su mirada hacia lo alto.



</doc>
<doc id="4538" url="https://es.wikipedia.org/wiki?curid=4538" title="Francisco Pérez Sierra">
Francisco Pérez Sierra

Francisco Pérez Sierra (c. 1627-1709) fue un pintor barroco español.

Nacido en Nápoles fue, según Antonio Palomino, hijo de un militar español casado con una hija del gobernador de Calabria. Según el mismo biógrafo, fue discípulo de Aniello Falcone en Nápoles y de Juan de Toledo en Madrid, al tiempo que servía de paje a don Diego de la Torre, secretario en la corte para los asuntos de Italia.

Poco se sabe de su pintura, aparte de lo que cuenta de él Palomino, quien asegura que fue experto en pintar batallas, países y "cabañas", además de realizar algunas obras religiosas, entre las que destacaba una de San Francisco de Paula para el desaparecido convento de la Victoria de Madrid. También pintó al fresco y al temple en colaboración con Francisco Rizi y Juan Carreño de Miranda en la Huerta de Sora, propiedad del marqués de Eliche y debió de alcanzar cierto prestigio como pintor de perspectivas fingidas para altares y otras arquitecturas efímeras destinadas a solemnidades festivas. De todo ello únicamente se conserva una "Inmaculada Concepción" firmada en 1655 en el convento de las Trinitarias Descalzas de Madrid, obra de composición compleja con fuertes resonancias de Rizi manifiestas también en dos óleos propiedad del Museo del Prado, procedentes del convento de Santa María de los Ángeles de Madrid: "Santa Ana conduciendo a la Virgen" (depositado en San Jerónimo el Real) y "San Joaquín" (Museo de Bellas Artes de Granada).

Palomino, que lo conoció, asegura que tras obtener por mediación de Diego de la Torre el cargo de agente general de los Presidios de España y disponiendo de una considerable hacienda, se aplicó por gusto «a pintar flores y frutas por el natural (con ocasión de un muy pulido jardín que tenía en su casa) que era en la calle de las Infantas». Un par de floreros, a él atribuidos, propiedad del Patrimonio Nacional, pueden servir de testimonio de su obra en este terreno, en el que mereció los elogios de sus contemporáneos. Murió a edad avanzada en Madrid, en 1709.




</doc>
<doc id="4540" url="https://es.wikipedia.org/wiki?curid=4540" title="Neocubismo">
Neocubismo

Neocubismo (o cubismo neoclásico) es un término de la historiografía del arte por el que se conoce el estilo de pintura en que empezaron a expresarse los artistas de la primera vanguardia en España en torno a los años veinte. Mientras que el cubismo reduce la naturaleza a las formas geométricas que el artista considera esenciales o más significativas, el neocubismo perfila enérgicamente los estilos y los modos que caracterizan a la vanguardia europea; mezcla de simbolismo, surrealismo y realismo.

La situación del arte en España en esos años era muy distinta a la del resto de Europa:
Los principales representantes en España de esta tendencia fueron, entre otros, los pintores Daniel Vázquez Díaz y Francisco Cossío, o los escultores Alberto y Ángel Ferrant. También se consideran neocubistas algunas etapas de la obra de Salvador Dalí y Joan Miró.

En los años cuarenta, esta tendencia neocubista se conoce también como figuración esquemática y sus elementos formales están tomados del cubismo y del "Art Decó". Además acusa la influencia de Henry Moore y de los figurativos italianos Marini, Campigli y Morandi. Esta tendencia es desplazada por el informalismo de los años cincuenta, y los artistas que la representaban optaron por distintas trayectorias, dentro de la pintura abstracta o la figurativa. Entre otros cabe señalar a Cristino de Vera, Adolfo Estrada, Gloria Merino, Carlos Pascual de Lara, Vaquero Turcios, Juan Méjica García, Manuel Hernández Mompó, Antoni Tàpies, Modesto Ciruelos y Hernando Viñes.


</doc>
<doc id="4541" url="https://es.wikipedia.org/wiki?curid=4541" title="Derecho informático">
Derecho informático

El derecho informático es un conjunto de principios y normas que regulan los efectos jurídicos de la relación entre el Derecho y la Informática. También se le considera como una rama del derecho especializada en el tema de la informática, sus usos, sus aplicaciones y sus implicaciones legales. 

El término Derecho Informático ("Rechtsinformatik") fue acuñado por el Dr. Wilhelm Steinmüller, académico de la Universidad de Ratisbona de Alemania, en los años 1970. Sin embargo, no es un término unívoco, pues también se han buscado una serie de términos para el Derecho Informático como Derecho Telemático, Derecho de las Nuevas Tecnologías, Derecho de la Sociedad de la Información, Iuscibernética, Derecho Tecnológico, Derecho del Ciberespacio, Derecho de Internet, etcétera. En la actualidad, el término Derecho de las Tecnologías de la Información y Comunicación ha tomado fuerza en América Latina, llegando incluso a privilegiarse sobre el uso de Derecho Informático.

Se considera que el Derecho Informático es un punto de inflexión del Derecho, puesto que todas las áreas del derecho se han visto afectadas por la aparición de la denominada Sociedad de la Información, cambiando de este modo los procesos sociales y, por tanto, los procesos políticos y jurídicos"."

El derecho informático, surge como esa medida de regulación de carácter jurídico. El concepto más completo que podemos encontrar de derecho informático es:
Los conceptos de tecnología y sociedad de información son antecedentes necesarios del derecho informático, con la finalidad de regular el comportamiento en un ámbito tecnológico. Actualmente el derecho informático no es muy especifico en sí, sino que lo abordan las materias de derecho penal, derecho civil y derecho comercial. 

Desde la aparición de la computación como un fenómeno, ésta ha sido benéfica en las distintas áreas de la ciencia y la cultura. Sin embargo, la aparición de actos delictivos a través de la informática ha devenido en la creación de esta rama del derecho. 

En derecho penal se afronta un reto en cuanto la sanción y clasificación de los delitos, ya que el delito se define como una conducta que es sancionada por las leyes de defensa social. No obstante, debido a su novedad, el derecho aún no prevé muchos actos informáticos ilegales como delitos o el castigo por la misma causa.

Según el Dr Zelarayan Juri, Federico: este derecho tiene surgimiento en el medioevo con el invento de la aguja de tejer, el nombre proviene de la aguja que significa recto, por lo tanto derecho e informático proviene de los puntos, la manera en que los hacemos, en su forma de transmitirlos, lo cual es información.

El derecho informático cuenta, al igual que las demás ramas de derecho, con sentencias de tribunales y razonamientos de teóricos del derecho. Las fuentes del derecho informático afectan a las ramas tradicionales del derecho:

En el derecho público

En derecho privado

Lo que aún se discute en la actualidad es si este derecho es una nueva disciplina o es una serie de normas dispersas que engloba a varias disciplinas.

El Derecho Informático afecta a distintas disciplinas dentro del Derecho. Este hecho, suscita un debate teórico sobre si estamos ante una nueva disciplina jurídica o si, por el contrario, se trata de un sector de normas dispersas pertenecientes a diferentes disciplinas jurídicas. 

Para poder hablar de autonomía de una rama del derecho se precisa la existencia de una legislación específica (campo normativo), un estudio particularizado de la materia (campo docente), investigaciones y doctrinas que traten la materia (campo científico) e instituciones propias que no se encuentren en otras áreas del derecho (campo institucional), con la finalidad de que se de un tratamiento específico de estos conocimientos determinados.

Una parte de los autores defienden que en el Derecho Informático existe legislación específica basada en leyes, tratados y convenios, que protegen al campo informático con la finalidad del control y aplicación lícita de los instrumentos informáticos (campo normativo). Dispone, además, de instituciones propias que no se encuentren en otras áreas del Derecho (campo institucional) tales como el contrato informático, el documento electrónico, el comercio electrónico, delitos informáticos, firmas digitales, habeas data, libertad informática, entre otras, que llevan a la necesidad de un estudio particularizado de la materia (campo docente), dando como resultado la investigaciones, doctrinas que traten la materia (campo científico). Es, por tanto, un Derecho autónomo con instituciones propias que se encarga de brindar soluciones legales a los problemas planteados por el avance científico en el ámbito de su competencia. 

De otro lado, se sostiene la postura que anula la autonomía del Derecho Informático desde el punto de vista de que en cada rama jurídica la actividad informática se encuentra presente, rechazando así la integración de normas en un cuerpo aislado. Niega la autonomía del Derecho Informático en virtud de que no existe claridad respecto a su área jurídica de influencia; es decir, como el Derecho Informático tiene relación con otras disciplinas jurídicas como el derecho civil, penal, laboral, administrativo, etc., y es a través del espectro normativo de estas la forma en que pueden incluirse las conductas y problemáticas jurídicas del impacto tecnológico. Por último, esta corriente argumenta la falta de autonomía del Derecho Informático en virtud de su constante y necesaria recurrencia a los principios jurídicos de otra rama para la solución de los casos concretos.








Publicaciones periódicas, por orden de aparición:

En cuanto a estudios formales de la disciplina en Iberoamérica, el pionero fue el desaparecido Máster en Informática y Derecho (1994-2004) de la Universidad Complutense de Madrid, liderado por Emilio Suñe Llinás.

Desde más de 10 años, la Universidad París-Sur con el Instituto de Derecho del Espacio y de las Telecomunicaciones (IDEST) proponen un Máster 2 en Derecho de Actividades Espaciales y de Telecomunicaciones. Este Máster es sostenido por numerosas empresas del sector de las telecomunicaciones y espacial.

Más tarde, en 2007, la Universidad de Cuenca (Ecuador) inició una Maestría de Derecho Informático mención en Comercio Electrónico y la siguió la Universidad de la Américas-UDLA (Ecuador) y el CETID con la Universidad de Cuenca (Ecuador) con una Maestría en Derecho Informático, mención en Comercio Electrónico. 

En México el posgrado pionero en esta materia es el de INFOTEC, denominado "Maestría en Derecho de las Tecnologías de la Información y Comunicación (MDTIC)", creada con el apoyo del grupo consultor de Lex Informática Abogados, S.C. y el Instituto de Investigaciones Jurídicas de la UNAM. La Universidad Panamericana Campus Aguascalientes cuenta con un programa similar, la "Maestría en Derecho de la Propiedad Industrial, Derechos de Autor y Nuevas Tecnologías".

Destacan a nivel internacional el "Advanced Master of Laws (LL.M.) in Information & Communications Technology Law" de la Universidad Católica de Lovaina (Bélgica), el "Máster Universitario en Derecho de las Nuevas Tecnologías" de la Universidad Pablo de Olavide, de Sevilla (España), el "Máster en Derecho de las Telecomunicaciones y Tecnologías de la Información" de la Universidad Carlos III de Madrid (España), el "Master in Diritto delle Nuove Tecnologie e Informática Giuridica" de la Universidad de Bolonia (Italia), el "Master of Laws in Information and Communication Technology Law" de la Universidad de Oslo (Noruega), el "Master of Law and IT" de la Universidad de Estocolmo (Suecia), entre otros.

Como programas de postítulo y/o especialización, la Pontificia Universidad Católica Argentina Santa María de los Buenos Aires (UCA) estableció en forma pionera en 1997 una Especialización en Derecho de Alta Tecnología; la Universidad de Chile ofrece desde 2003 un Magíster y Diplomados en Derecho de la Informática y de las Telecomunicaciones y la Universidad Externado de Colombia, en asociación con la Universidad Complutense de Madrid, ofrece desde el 2007 un programa de especialización y de Maestría en Derecho Informático y de las Nuevas Tecnologías desde el año 2015.

Para algunos ejemplos de situaciones en las que se haga uso del derecho informático son:



</doc>
<doc id="4549" url="https://es.wikipedia.org/wiki?curid=4549" title="25 de julio">
25 de julio

El 25 de julio es el 206.º (ducentésimo sexto) día del año en el calendario gregoriano y el 207.º en los años bisiestos. Quedan 159 días para finalizar el año.










</doc>
<doc id="4556" url="https://es.wikipedia.org/wiki?curid=4556" title="8 de julio">
8 de julio

El 8 de julio es el 189.º (centésimo octogésimo noveno) día del año en el calendario gregoriano y el 190.º en los años bisiestos. Quedan 176 días para finalizar el año.








</doc>
<doc id="4560" url="https://es.wikipedia.org/wiki?curid=4560" title="Giovanni Battista Piranesi">
Giovanni Battista Piranesi

Giovanni Battista Piranesi (Mogliano Veneto, cerca de Treviso, 4 de octubre de 1720 – Roma, 9 de noviembre de 1778) fue un arqueólogo, arquitecto, investigador y grabador italiano. Realizó más de 2.000 grabados de edificios reales e imaginarios, estatuas y relieves de la época romana así como diseños originales para chimeneas y muebles.

Piranesi nació en Mogliano Veneto, que entonces pertenecía a la República de Venecia. Estudió Arquitectura en Venecia con su tío materno Matteo Lucchesi, que era "Magistrato delle Acque" en la ciudad. Allí descubrió las obras de Palladio, Vitruvio y algunos edificios de la antigüedad. Piranesi apenas llegó a ejercer como arquitecto (sólo se erigió un diseño suyo), si bien sus estudios le permitieron dibujar con mayor facilidad, e hizo gala de su formación firmando algunos grabados como "Piranesi architetto". 

Se trasladó en 1740 a Roma, junto a Marco Foscarini, enviado del papa en Venecia. Las ruinas del imperio romano encendieron su entusiasmo y la necesidad de representarlas. En aquella época, la arqueología no era aún una ciencia demasiado rigurosa, y en muchas ocasiones se trataba de simple saqueo. Combinando afán descriptivo y fantasía, Piranesi levantó acta de las ruinas romanas y de los hallazgos que se iban produciendo.

Conoció en Roma al erudito G. G. Bottari y aprendió la técnica del aguafuerte con Giuseppe Vasi, con quien firmó algunas imágenes. Sus primeros grabados fueron vistas de la ciudad, destinadas a guías ilustradas. En 1743 publicó su primera gran serie de estampas, "Prima Parte di Architettura e Prospettiva". Elaborada con apenas 23 años, desvela ya su maestría como grabador y su inventiva.

Abrió su taller frente a la Academia de Francia en Roma lo cual hizo que viviera en constante relación con los estudiosos de aquel país. Tuvo mucho éxito con sus grabados puesto que la mayoría de los visitantes que iban a Roma gustaban de volver con algún recuerdo, y sus grabados se imprimían en grandes tiradas que los hacían muy asequibles.

En 1761 se convirtió en miembro de la "Academia di San Luca". Murió en 1778 y fue enterrado en la única iglesia que construyó: Santa María del Priorato.

Sus entusiastas reproducciones e interpretaciones de antiguos monumentos romanos supusieron una importante contribución para la formación y desarrollo del neoclasicismo. En estos grabados se incluían imágenes fidedignas y exactas de las ruinas existentes, al igual que reproducciones imaginarias de antiguos edificios en las que la alteración de la escala y la yuxtaposición de elementos contribuyen a realzar el carácter de grandiosidad de los mismos.

Una de las primeras y más renombradas colecciones de grabados de Piranesi fueron sus Prisiones ("Carceri d'Invenzione", 1745-1760), en donde transformó las ruinas romanas en fantásticos y desmesurados calabozos dominados por enormes y oscuros pasadizos, empinadas escaleras a increíbles alturas y extrañas galerías que no conducen a ninguna parte. Estos grabados ejercieron una enorme influencia en el romanticismo del siglo XIX, jugando también un destacado papel en el desarrollo, ya en el siglo XX, del surrealismo e incluso en los decorados para el cine de terror.

También fue sumamente famosa su magna obra "Le Antichità Romane": más de 200 grabados en cuatro tomos, publicados en 1756. Incluye vistas de ruinas de monumentos funerarios de Roma y de sus alrededores así como detalladas ilustraciones del urbanismo romano, incluso del modo en que se adoquinaban las calles. Para crear esta obra, Piranesi exploró personalmente casi todos los yacimientos y ruinas, tomando con rigor medidas y apuntes para elaborar grabados muy precisos. Fue una labor titánica que requirió diez años de trabajo.

Los grabados de Piranesi, muchos de ellos de gran formato y ordenados en libros, se exportaron rápidamente a Inglaterra y otros países, a modo de souvenirs del "Grand Tour", antecedente del moderno turismo cultural. Esas láminas influyeron en la arquitectura palaciega, especialmente en las casas campestres inglesas.

Muchas planchas del artista se siguieron imprimiendo hasta principios del siglo XIX en París; primero las explotó su hijo Francesco Piranesi y a su muerte pasaron al taller "Firmin Didot". En 1839 estas matrices de cobre fueron adquiridas por emisarios del papa Gregorio XVI con destino a la "Calcografia Camerale" fundada por Clemente XII, antecesora de la actual "Calcografia Nazionale de Roma", dependiente del "Istituto Nazionale per la Grafica", donde aún se conservan.
Existen grabados de Piranesi en casi todas las bibliotecas antiguas de Europa. En España, destacan los fondos de la Biblioteca Nacional y del Museo de Bellas Artes de Valencia, que posee unas 880 estampas, casi todas adquiridas en el mismo siglo XVIII. 

Aún hoy los grabados de este artista son muy demandados y cotizados, en parte porque se siguen enmarcando y empleando como elemento decorativo en interiores de todos los estilos. 

Sus principales obras como grabador y teórico fueron:


Prianesi tan sólo vio construido uno de sus diseños arquitectónicos: la iglesia de Santa María del Priorato en Roma, sede de los caballeros de la Orden de Malta, así como la plaza que da acceso desde el Aventino.



</doc>
<doc id="4562" url="https://es.wikipedia.org/wiki?curid=4562" title="Fernando Fader">
Fernando Fader

Fernando Fader (Burdeos, Francia, 11 de abril de 1882-Loza Corral, Córdoba, Argentina, 28 de febrero de 1935) fue un pintor y dibujante argentino nacido en Francia, principal seguidor del impresionismo alemán en su país.

Fernando Fader nació el 11 de abril de 1882, en Burdeos, Francia. En 1898 realizó sus primeras obras pictóricas, entre las que destaca el óleo "El viejo piojoso".
Realiza estudios primarios en Francia y estudios secundarios en Alemania, en la Realschule del Palatinado del Rhin. Allí también estudia pintura con Heinrich von Zügel (1850-1941), un partidario de la pintura al aire libre, cuyos ejes temáticos eran los animales y la concepción naturalista del paisaje, derivados de la escuela de Barbizón. En 1900 ganó una medalla de oro por su pintura "detrás del arco iris". En 1904 vuelve al país y en 1906 realiza su primera muestra en Argentina, que no tuvo éxito. 'Participó del grupo Nexus -de temática localista y técnica que vacilaba entre el impresionismo y el academicismo- , con Collivadino, Ripamonte, Bernaldo de Quirós y, marginalmente, Emilio Caraffa. Nexus presentó tres exposiciones que abrieron el camino al Salón de Primavera de 1911. Impulsado por su otra pasión, la ingeniería, invirtió toda su fortuna en una empresa hidráulica que lo llevó a la quiebra. Este duro momento económico coincidió con los primeros síntomas de tuberculosis, que lo llevaron a buscar el clima suave de las sierras (de Córdoba) en 1917 (hay otra versión que sitúa esta mudanza en 1916). Pintó en las Sierras de Achala e Ischilín, en poblaciones como Candelaria, La Higuera, Pocho, San Pedro Norte y San Francisco del Chañar.'3'"/

Entre sus múltiples retratos, óleos y acuarelas se destacan "La mantilla", "La madre" y "La liga azul", estas últimas expuestas en el V salón Nacional de 1915, así como "La vida de un día", serie de ocho telas de (80x100 cm) en las que se representa el mismo paisaje con sus variantes de luz a lo largo del día, pintadas durante 1917. Esta serie está expuesta en el Museo Municipal de Bellas Artes de Rosario "Juan B. Castagnino". 

En su pintura se aprecian distintos periodos emocionales, como la etapa de interiores oscuros con predominio de los colores ocres y pardos y su otro momento de más luminosidad, donde la luz artificial cae sobre los objetos relacionando el color-luz con el objeto-luz. ""Sus paisajes serranos son uno de los momentos culminantes de la historia de la pintura en Córdoba. Su última obra es de 1931'
Sus obras pueden apreciarse entre otro lugares en:

En 1914 después de su quiebra, se instala en Buenos Aires y presenta dos obras en el Salón Nacional.Con "La mantilla" comparte el premio Adquisición con Ernesto de La Cárcova.
En la exposición Internacional de California gana el primer premio con "La comida de los cerdos"

3 "Los colores de un siglo- Grandes obras de la pintura de Córdoba” Fundación Benito Roggio, 1998, Edit. Arcángel Maggio, Bs.As. Arg.; p. 59/60

"Fader en el Fader" (1994) "200 obras en el Museo Emiliano Guiñazú de Mendoza" (catálogo).


</doc>
<doc id="4563" url="https://es.wikipedia.org/wiki?curid=4563" title="Winslow Homer">
Winslow Homer

Winslow Homer (Boston, 24 de febrero de 1836 - 29 de septiembre de 1910) fue un pintor estadounidense del siglo XIX.

Artista autodidacta, en 1857 empezó a trabajar como ilustrador de revistas, colaborador asiduo de "Harper's Weekly". Durante la Guerra Civil, Homer visitó en repetidas ocasiones el frente de Virginia donde habría de pintar su primer cuadro al óleo importante, "Los prisioneros del frente" (1866, Museo Metropolitano de Arte de Nueva York), obra notable por su fría objetividad y su vigoroso realismo.

En 1856 se trasladó a Francia durante un año pero, aunque su interés en las posibilidades pictóricas de la luz natural se desarrolla de forma paralela al de los primeros impresionistas, nunca sufrió la influencia directa del impresionismo o del arte francés.

En 1873 comenzó a utilizar la acuarela, medio de expresión tan importante en su obra como el óleo. Durante la década de 1870 los temas predominantes de sus obras fueron los de inspiración rural o idílica: escenas de la vida agrícola, niños jugando y escenas de lugares conocidos poblados de mujeres elegantes. De estas últimas el ejemplo más conocido es Long Branch, Nueva Jersey (1869, Museum of Fine Arts, Boston).

El año transcurrido en Inglaterra (entre 1881 y 1882), durante el cual Homer vivió en un pueblo de pescadores, provocó un cambio definitivo en la temática de su obra. A partir de entonces se concentró en escenas de la naturaleza a gran escala, en particular escenas marinas, de pescadores y sus familias. Después de fijar su residencia en solitario en Prout's Neck, en la costa de Maine (donde moriría el 29 de septiembre de 1910), produjo obras maestras del realismo tales como Eight Bells (1886, Addison Gallery, Andover, Massachusetts). En esta obra el dramatismo de la escena marina está imbuido de una cualidad épica y heroica que representa el tema dominante de su madurez: la lucha del hombre con las fuerzas de la naturaleza.

A partir de 1884, Homer pasó muchos inviernos en Florida, en las Bahamas y en Cuba, ejecutando gran parte de su obra plenairista, en especial acuarelasnumerosa o incluso de pintura rápida, con un estilo muy avanzado para su época: fresco, suelto, espontáneo, casi impresionista, pero sin perder jamás su relación básica con el realismo américano. 



</doc>
<doc id="4564" url="https://es.wikipedia.org/wiki?curid=4564" title="Ricardo Yrarrázaval">
Ricardo Yrarrázaval

Ricardo Yrarrázaval Larraín (Santiago, 12 de octubre de 1931) es un pintor y ceramista chileno. El tema central de su obra es el hombre y su situación en la sociedad.

Nació en Santiago de Chile, 1931. Su vocación artística despertó a muy temprana edad. Después de enrolarse en un barco con destino a Egipto, viajó a Nápoles y a Roma, donde ingresó en la Escuela de Bellas Artes para estudiar pintura. 

Más tarde, abandonó la capital italiana y marchó a Francia para finalmente instalarse en Vallauris. Allí entró en contacto con las técnicas de la cerámica, actividad a la que se dedicó durante varios años, sin nunca abandonar la pintura.

Su producción pictórica se caracteriza por su profunda e intensa busqueda, tanto en lo formal como en lo temático. Después de una trascendental experiencia con la abstracción, que le valió el reconocimiento de una beca de la Fundación Guggenheim en 1966, (estadía de un año en Nueva York), en la década de 1970 su obra adquirió tintes surrealistas y comenzó a pintar en un estilo que algunos denominaron realismo subjetivo y que más tarde evolucionaría hacia lo objetivo. Los personajes de sus cuadros son figuras de volúmenes rotundos y formas distorsionadas que representan arquetipos de la sociedad moderna.

Su pintura más reciente se destaca por su irrenunciable búsqueda de nuevas técnicas, y una inconfundible relación con lo moderno y su vinculo con la sociedad actual, la figura del ser humano siempre al centro.

De los numerosos galardones que ha obtenido destacan el segundo premio de la Bienal de Lima (1968) y el primer premio de pintura del I Concurso de la Colocadora Nacional de Valores de Chile (1975).

Exhibiciones Individuales

Exhibiciones Colectivas

del Museo Guggenheim, Nueva York, Estados Unidos.




</doc>
<doc id="4565" url="https://es.wikipedia.org/wiki?curid=4565" title="Jacob Jordaens">
Jacob Jordaens

Jacob Jordaens (Amberes, 19 de mayo de 1593 – 18 de octubre de 1678) fue un pintor barroco flamenco. Es el último gran maestro de la época en los Países Bajos, tras la muerte de Rubens (1640) y Van Dyck (1641). A diferencia de sus contemporáneos, nunca realizó un viaje formativo a Italia para conocer el arte clásico, y su carrera destaca por cierta indiferencia hacia las ambiciones cortesanas o intelectuales. Se le considera, por sus contados viajes fuera de los Países Bajos, como un pintor de considerable genio pese a su carácter local. 

Fue un pintor de éxito, grabador ocasional y notable diseñador de tapices. Al igual que Rubens, Jordaens fue un maestro de los tapices, las escenas mitológicas y las alegorías, y a partir de 1640 -año de la muerte de Rubens- fue el más notable pintor de Amberes, y como tal recibió numerosos encargos de cortesanos, familias adineradas y otros mecenas. Hoy, sin embargo, es más conocida su obra "de género", pinturas basadas en escenas costumbristas al modo de su contemporáneo Jan Brueghel el Viejo. Entre sus influencias se cuentan no solo pintores flamencos como Brueghel o el mencionado Rubens, sino también artistas del norte de Italia como Jacopo Bassano, Paolo Veronese o Caravaggio.

Jacob Jordaens nació en Amberes el 19 de mayo de 1593, primogénito entre los once hijos del rico mercader de lino Jacob Jordaens y Barbara van Wolschaten. Se sabe poco sobre su primera educación, pero se admite que debió recibir una formación aventajada como heredero de una rica familia. Esta idea se ve confirmada por su dominio de la gramática, su conocimiento del francés y su competencia en cuestiones mitológicas. Su familiaridad con los temas bíblicos se manifiesta en sus muchas pinturas de tema religioso, y su vinculación con estas cuestiones se ve confirmada por su tardía conversión del catolicismo al protestantismo. Al igual que Rubens estudió con Adam van Noort, quien fue su único maestro. Durante esta etapa Jordaens residió en la casa de Van Noort y estableció estrechos lazos con la familia. Después de ocho años de formación con Van Noort, se unió a la Guilda de San Lucas como "waterscilder" o "acuarelista". A la sazón éste era un medio que solía emplearse como base de los tapices y tal vez ello explica que no se conserven acuarelas del autor.
En 1616, el mismo año en que se le admitió en la hermandad, Jordaens contrajo matrimonio con la hija mayor de su maestro, llamada Anna Catharina van Noort, con la que tuvo tres hijos. En 1618 la pareja compró una vivienda en Hoogstraat, la calle donde se había criado. Hacia 1639 la amplió sobre la vivienda colindante, tal como había hecho Rubens dos décadas antes. Allí residió y trabajó hasta su muerte en 1678.

Jordaens nunca realizó el clásico viaje de aprendizaje a Italia para estudiar el arte clásico y renacentista. A pesar de esto, se esforzó notablemente para adquirir láminas de los grandes maestros italianos que podían encontrarse en aquel entonces en el norte de Europa. Así es como conoció a Tiziano, Veronese, Caravaggio y Bassano. Su obra, sin embargo, delata su fuerte arraigo como pintor local, y su apego a la pintura de género de artistas como Brueghel el Viejo, de carácter costumbrista y un tono más bien jocoso. La mayoría de sus encargos le llegaban de ricos mecenas flamencos y miembros del clero, si bien hacia el final de su carrera el maestro ya recibía encargos de cortesanos y gobiernos de toda Europa. Además de una considerable cantidad de pinturas al óleo, a lo largo de su carrera realizó numerosísimos tapices, una huella de su temprana vocación de acuarelista.

La importancia de Jordaens puede calibrarse por la cantidad de discípulos que tuvo: el registro de la Hermandad de San Lucas -el tradicional gremio de los pintores- apunta a unos quince entre 1621 y 1667, y a éstos hay que añadir otros seis aprendices que aparecen registrados como tales en documentos de la corte. Entre ellos se contaría su primo, y su propio hijo Jacob. Como Rubens y otros artistas de la época, el estudio de Jordaens dependía en gran medida de sus ayudantes para la producción de sus pinturas. Aunque no muchos de sus discípulos adquirieron fama, tener un cargo en el taller de Jordaens era una posición codiciada por artistas de toda Europa.

Pedro Pablo Rubens fue tal vez el pintor que más influyó en la obra de Jordaens. El maestro le encargó algunas reproducciones de sus bocetos, que tal vez explican su afinidad por una paleta cromática cálida, su común interés por el naturalismo y su similar adaptación del chiaroscuro y el tenebrismo italianos. Jordaens, que en vida de Rubens solo tuvo un moderado éxito como pintor de retratos, brillaba especialmente en la representación de personajes comunes de la vida cotidiana, tanto en sus pinturas de tema pastoril, de raíces profundamente clásicas, como en escenas morales similares a las que había popularizado Jan Steen. Aunque no fue un especialista, Jordaens solía repetir ciertos temas a lo largo de sus obras, con la intención de personalizar caracteres que van apareciendo a lo largo de su obra con diferentes edades, formando parte de la abigarrada multitud que rodea la mesa de un gran banquete. En cuanto a los temas mitológicos, Jordaens se ciñó a los motivos elaborados por Rubens, si bien filtrándolos a través de su tendencia a la personalización y el costumbrismo realista, así como un cierto aire burlesco que impregna incluso sus obras de temática mitológica o religiosa. El "Prometeo", de c. 1640 es un ejemplo claro de la influencia combinada de Rubens y Frans Snyders.

Además de ser conocido como notable retratista, Jordaens realizó obras de temática religiosa, obras de carácter alegórico y mitológico, así como un buen número de grabados. Aunque principalmente fue un pintor histórico, también trabajó sobre proverbios flamencos, del tipo ""el viejo canta, el joven parlotea"", o representaciones de festivales flamencos (""El Rey bebe""). Algunas de sus obras prueban su interés por la pintura de animales: en su obra figuran con frecuencia imágenes de caballos, vacas, aves de corral, gatos, perros y ovejas; generalmente eran modelos del natural. A lo largo de toda su vida realizó gran cantidad de apuntes del natural de animales y personas. Después de la muerte de Rubens, acaecida en 1640, Jordaens se convirtió en el pintor más popular de Amberes, y a partir de entonces empezó a recibir encargos de las principales cortes de Europa, especialmente de los reinos nórdicos. Los mismos herederos de Rubens solicitaron su ayuda para terminar un cuadro de "Hércules liberando a Andrómeda" (Museo del Prado) encargado por el rey Felipe IV de España.

Entre 1635 y 1640, aquejado Rubens por la gota, se concedió a Jordaens autorización para utilizar los bocetos del maestro flamenco para continuar la decoración de la entrada triunfal del Cardenal-Infante Ferdinando, el recién nombrado gobernador de las posesiones españolas en los Países Bajos. Aunque la obra se perdió finalmente, Jordaens también recibió el encargo de concluir las pinturas que decoraban la cámara de la Reina en Greenwich, encargo que igualmente había sido encomendado inicialmente a Rubens, quien rechazó el trabajo a causa de sus crecientes problemas de salud.

Por último debemos destacar que Jordaens también tuvo un papel importante en la decoración de la Torre de la Parada, erigida entre 1636 y 1641. Dos de las obras atribuidas a Jordaens son ""Apolo y Pan"" (1637, realizada según los esbozos de Rubens) y ""Vertumno y Pomona"" (1638). A esta producción se sumarían posteriormente una ""Caída de los Titanes"", el ""Matrimonio entre Peleo y Tetis"" y el ""Cadmo sembrando los dientes del dragón"". En 1661 recibió el encargo de elaborar tres tondos de considerable tamaño para el ayuntamiento de Ámsterdam.

Profesar el protestantismo estaba prohibido en Amberes, a la sazón territorio español. Sin embargo, en la última etapa de su vida, Jordaens se hizo protestante, si bien continuó recibiendo -y realizando- los encargos de las ricas iglesias católicas de su región. Por otra parte, la redacción de algunos textos heréticos publicados entre 1651 y 1658 le costaron pagar una multa de 200 libras y 15 chelines. En 1877 se levantó en Putte un monumento conmemorativo que contenía las lápidas del pintor y sus colegas Simon de Pape (I) y Adriaen van Stalbemt, en el lugar donde se encontraban la iglesia y el cementerio protestantes antes de su demolición. 

Jordaens falleció en octubre de 1678 a consecuencia de una misteriosa enfermedad endémica de Amberes -llamada 'zweetziekte' o 'polderkoorts', en neerdlandés-, en el mismo día que se había llevado a su hija soltera Elizabeth, quien permanecía en la casa familiar. Sus cuerpos fueron enterrados juntos bajo una lápida del cementerio protestante de Putte, una aldea al norte de la frontera con Bélgica, donde ya descansaban los restos de su fallecida mujer Catharina. Un año después de su muerte, el hijo de Jordaens realizó una generosa donación de ""veinticinco libras flamencas a la Camer van den Huysarmen de Amberes"", a las que añadió "El lavatorio y unción del cuerpo de Cristo", que fue reubicado en un orfanato para niñas. Aparentemente esta donación se realizó en correspondencia con el testamento de Jordaens, aunque lamentablemente no se conserva este documento. Incluso sin haberse encontrado el testamento de Jordaens, su gentileza fue ampliamente reconocida por todos los que le conocían.

Hacia el final de su carrera (1652-1678) el talento creativo y artístico del pintor se fue recrudeciendo. De su brillante paleta juvenil pasó a tonos acres y terrosos, aplicando tan poca pintura que podía verse la tela debajo. Salvo contadas excepciones -como la "Historia de Psyche" que realizó para su propia casa-, su dedicación profesional se fue relajando y en cierto modo sus pinturas parecen afectadas de cierta fatiga.

"La adoración de los pastores" (1616 - 1618) presenta a la Virgen amamantando al niño Jesús mientras unos pastores, de aspecto flamenco, se postran en adoración. La escena muestra a cinco figuras que, a excepción del niño, aparecen recortadas a la altura de la cintura, subrayando la intimidad de la escena. 

Antes de 1616, Jordaens había estado interesado por la paleta cromática manierista, clara y brillante. Sin embargo, con esta pintura, empieza a utilizar la luz, y no el color, como el medio principal de modelar las figuras en el espacio, haciendo evidente su interés por Caravaggio. La principal fuente de luz en "La adoración..." es una vela sostenida por San José. El efecto puede ser una posible muestra de la influencia de pintores como Adam Elsheimer, conocido por situar la principal fuente de luz en el centro de sus composiciones. Otra posible prueba de la influencia de Caravaggio puede encontrarse en el enfoque "realista" que Jordaens aplica al tema: La Virgen y el Niño se presentan de manera sencilla, casi rústica, lejos de los arquetipos idealizados que solían seguirse en las representaciones de este mismo tema.

Jordaens realizó al menos otras seis versiones del tema de la "Adoración". Generalmente, la composición incluye a media docena de figuras agrupadas y recortadas de diversas maneras, que centran la atención del observador en la Sagrada Familia. Este tipo de composición pretendía intensificar el aspecto narrativo de la escena y acentuar la expresión individual de los personajes.

Esta escena en particular, de la que Jordaens realizó multitud de versiones, ilustra una fábula moralizante de Esopo. La historia comienza con el encuentro entre un hombre y un sátiro. Un frío día, mientras conversaban, el hombre se llevó los dedos a la boca y sopló. Cuando el sátiro le preguntó por ese gesto, el hombre le contestó que era para calentarse las manos. Después, cuando se sentaron a comer, el hombre se llevó el plato caliente a la boca y volvió a soplar. Cuando el sátiro le preguntó el motivo, le contestó que era para enfriar la comida. El sátiro entonces replicó, ""no puedo considerarte un amigo, si dices que el mismo soplo calienta y enfría"". La historia pretende ilustrar sobre la dualidad de la naturaleza humana, aunque algunos críticos sostienen que el interés del autor estaba más en el tema campesino que en la moraleja de la fábula.

El momento particular representado en la pintura es cuando el sátiro declara su desconfianza en el hombre. El hombre aún está comiendo, cuando el diablo se incorpora, alzando la mano, preparándose para salir de la casa. Jordaens escogió situar la escena en el interior de una granja abundante en animales: un toro, un perro, un gato y un gallo se acomodan sobre el mobiliario. Del mismo modo, alrededor de la mesa se reúnen figuras de todas las edades: hay un joven detrás de la silla del hombre, una vieja sosteniendo a un niño pequeño, y una joven que se asoma tras el hombro del sátiro.
Es característico del estilo pictórico de Jordaens el modo en que las figuras se empujan hacia el centro de la composición, amontonándose en un pequeño espacio. Jordaens sigue las técnicas tenebristas del claroscuro para definir una iluminación dramática, que resalta algunas figuras de la escena, como el bebé que descansa en el regazo de la anciana. Además, Jordaens recrea efectos naturalistas, como la suciedad en el pie del campesino sentado en primer plano, muy característico del estilo tenebrista flamenco de su época. Jordaens recreó otras versiones de este tema entre 1620 y 1621. En esta versión, parece haber situado a la niñera para "El sátiro y el campesino" del mismo modo en que aparecía en "La adoración de los pastores", y a juzgar por la gran cantidad de copias que se han encontrado -todas ellas sin el sello del maestro-, se cree que Jordaens había utilizado este cuadro como ejercicio de práctica para sus asistentes y alumnos en el taller.

Los diseños de tapices representan una parte muy significativa de su obra. Ricas tapicerías, que se contaban entre las obras más lucrativas realizadas entre el Renacimiento y el Barroco, cubrían los salones de las lujosas mansiones de la aristocracia europea desde el siglo XIV. Artistas como Jacob Jordaens, Pedro Pablo Rubens o Pietro da Cortona solían realizarlos por encargo, representando a sus ricos mecenas en escenas mitológicas o históricas cargadas de simbolismo y significación propagandística. Jordaens se convirtió en un especialista en este tipo de obras, y su dedicación y habilidad le ganaron un buen número de clientes. Se le consideró uno de los mayores diseñadores de tapices de su época.

El proceso de creación de tapices comenzaba con un boceto preliminar de la obra. El dibujo se transfería a un formato mayor, pintado al óleo sobre cartón, que era entregado al molino donde se transformaba en una pieza de tela. Jordaens también solía ejecutar pequeños bocetos acuarelados de sus composiciones, aunque hacia el final de su carrera sustituyó el cartón por el mismo lienzo como formato final. Sus tapices estaban concebidos para poder ser transportados por sus ricos propietarios, que solían llevarlos en sus viajes o campañas militares como símbolo de su categoría. El campo de temas a tratar era muy amplio, y pasaba desde la mitología o la vida rural hasta la historia de Carlomagno. Algunos expertos subrayan que un rasgo característico de la producción de Jordaens en esta área era la composición con masas de personajes, aplanados por el formato bidimensional de la tela, que enfatizaba fuertemente las tramas de la textura. De algún modo, Jordaens trasladó a los tapices su gusto por incluir multitud de caracteres en sus obras, ya fuesen tapices o pinturas.

El boceto para "interior de una cocina", que aquí presentamos, es un ejemplo de un estado de trabajo típico en la obra de Jordaens. Utilizando tinta ocre, aplicaba el color sobre una mancha de tiza negra, esbozando sobre el papel la composición final de la naturaleza muerta sobre la mesa y la disposición de las figuras. El resultado final difería ligeramente, pero como algunos autores han señalado la obra se inspiraba, en sus estados iniciales, en las naturalezas muertas del artista de Amberes Frans Snyders, muy afín a los intereses de Jordaens.

Algunos críticos han señalado que la obra de Jordaens continuó estilísticamente el "pictoricismo" característico de los dibujos de Rubens o Van Dyck en sus propios bocentos. Actualmente, los dibujos atribuidos al maestro rondan los 450, aunque lo parecido de sus técnicas hace que exista cierta disensión entre los expertos a la hora de distinguir su obra de la de Rubens. De cualquier modo, Jordaens y sus coetáneos fueron los principales exponentes de la tendencia flamenca hacia la realización de bocetos y apuntes preparatorios de menor escala que la imagen definitiva. Jordaens fue un consumado dibujante que no dudó en utilizar técnicas pictóricas -como el gouache o la acuarela- en la ejecución de sus bocetos. Su obra en papel también se caracteriza por su economía de medios, y no era raro que añadiese tiras de papel, recortase secciones del formato o pegase fragmentos aislados (al modo de un "collage") sobre el papel, hasta lograr el efecto deseado.

El tema de este dibujo (de fecha desconocida) ha sido objeto de cierta controversia. Este retrato de una mujer desnuda a lomos de un toro sería muy probablemente una representación del conocido tema mitológico de "el rapto de Europa", que presenta a Júpiter metamorfoseado en toro. No obstante, algunas teorías lo interpretan como una alegoría del mes de abril: según esa lectura, el toro representaría el signo zodiacal de Tauro, mientras que la mujer, que sostiene un ramo de flores, se identificaría con Flora, la diosa de la Primavera. Las figuras que la escoltan serían por tanto Ceres, la divinidad de la agricultura, y Sileno, instructor y consejero de Baco.

La faceta de Jordaens como grabador no es conocida entre el público no iniciado y apenas suele merecer atención en las monografías de arte, si exceptuamos los libros específicos sobre grabado antiguo. El experto Hollstein asignaba a Jordaens siete imágenes grabadas, varias de ellas con la fecha 1652; autoría que secunda en tiempos modernos (1993) el experto D'Hulst.

Los siete grabados ostentan inscrito el nombre de Jordaens como «"inventor"» (diseñador de la imagen), lo que da pie a pensar que el trabajo de grabar las matrices lo hizo otra mano; pero la convicción general es que él hizo todo el trabajo. Están hechos al aguafuerte con un resultado digno en cuanto a dibujo, si bien carecen de la destreza y expresividad de los aguafortistas más celebrados como Rembrandt y José de Ribera. 

Sus temas son variados y Jordaens ya los había plasmado casi todos en pinturas: "Cristo expulsando a los mercaderes del templo", "Lamentación ante Cristo muerto", "Juno sorprendiendo a Júpiter e Ío", "Mercurio matando a Argos", "Júpiter alimentado por la cabra Amaltea", "La huida a Egipto" y un tema rural, "Granjero agarrando a una vaca por la cola" (antes identificado como "Caco robando el rebaño de Gerión"). Ejemplares de estos grabados se conservan en museos de medio mundo: Museo Británico de Londres, National Gallery de Washington, Art Institute de Chicago...



</doc>
<doc id="4570" url="https://es.wikipedia.org/wiki?curid=4570" title="José Hierro">
José Hierro

José Hierro del Real (Madrid, 3 de abril de 1922 - ibídem, 21 de diciembre de 2002), conocido como José Hierro o Pepe Hierro, fue un poeta español. Pertenece a la llamada primera generación de la posguerra dentro de la llamada poesía desarraigada. 

En sus primeros libros, Hierro se mantuvo al margen de las tendencias dominantes y decidió continuar la obra de Juan Ramón Jiménez, Antonio Machado, Pedro Salinas, Gerardo Diego e, incluso, Rubén Darío. Posteriormente, cuando la poesía social estaba en boga en España, hizo poesía con numerosos elementos experimentales ("collage" lingüístico, monólogo dramático, culturalismo...).

Nació en Madrid en 1922, aunque la mayor parte de su vida la pasó en Cantabria, puesto que su familia se trasladó a Santander cuando José contaba apenas dos años. Allí cursó la carrera de perito industrial, pero se vio obligado a interrumpirla en 1936, al comienzo de la Guerra Civil Española.

Al finalizar la guerra fue detenido y encarcelado por pertenecer a una "organización de ayuda a los presos políticos", uno de los cuales era su propio padre, Joaquín Hierro, un funcionario de Telégrafos que el 18 de julio de 1936 interceptó el cable con que la Capitanía Militar de Burgos quería sublevar a la guarnición de Santander, pagándolo con la cárcel. Su hijo también fue a prisión por sacar información de la misma cuando lo visitaba. Pasó cinco años encarcelado y fue liberado en enero de 1944 en Alcalá de Henares. Hasta 1946 vivió en Valencia. Allí, en el Café El Gato Negro, participó en una tertulia literaria a la que asistían [Ricardo Blasco], Angelina Gatell, Alejandro y Vicente Gaos, y Pedro Caba Landa, entre otros. Desempeñó entonces diversos oficios "pane lucrando". En 1948, en el "Diario Alerta" de Santander, hizo su primera crítica pictórica, sobre la obra del pintor burgalés Modesto Ciruelos (íntimo amigo que falleció también en 2002), labor que continuó ejerciendo en distintos medios de comunicación, especialmente en Radio Nacional de España y el "Diario Arriba" de Madrid. En 1949 contrajo matrimonio con María de los Ángeles Torres. Fundó la revista "Proel", junto con Carlos Salomón y hasta 1952 dirigió las publicaciones "Cámara de Comercio" y "Cámara Sindical Agraria", para instalarse al fin en Madrid, donde reanudó su carrera de escritor. Trabajó en el CSIC y en la Editora Nacional. Colaboró en las revistas poéticas "Corcel", "Espadaña", "Garcilaso. Juventud creadora", "Poesía de España" y "Poesía Española", entre otras. Participó en los Congresos de Poesía de Segovia, (del 17 al 24 de junio de 1952) y Salamanca (5 de julio de 1953). En 1995 es nombrado Doctor Honoris Causa por la Universidad Internacional Menéndez y Pelayo de Santander. Además en 1998, recibe, como reconocimiento final a su grandísima carrera, el Premio Cervantes. Fue elegido miembro de la Real Academia Española en 1999. En 2002 es nombrado también Doctor Honoris Causa de la Universidad de Turín. 

Fallece el 21 de diciembre de 2002 a los 80 años de edad en Madrid. Sus cenizas se honran en el Pabellón de Santanderinos Ilustres situado en la entrada del Cementerio de Ciriego de la capital cántabra desde el 28 de marzo de 2003. 

Poseía la curiosa superstición de no poder escribir nunca en su propia casa; era normal verlo en la cafetería de Avenida Ciudad de Barcelona, en Madrid; en ella y en otros cafés escribió toda su obra. Era sin embargo un trabajador lento y minucioso: algunos de sus poemas tardaron años en encontrar la forma definitiva.

José Hierro fue Premio Adonáis en 1947, Premio Nacional de Poesía (1953 y 1999), Premio de la Crítica (1958 y 1965), Premio de la Fundación Juan March (1959), Premio Príncipe de Asturias de las Letras en 1981, Premio Fundación Pablo Iglesias en 1986, Premio Nacional de las Letras Españolas en 1990, Premio Reina Sofía de Poesía Iberoamericana en 1995, Premio Cervantes y de nuevo el Premio de la Crítica en 1998, Premio Europeo de Literatura Aristeión, Premio Francisco de Quevedo y el Premio Ojo Crítico Especial por la belleza de su obra en 1999.

Fue declarado Hijo Adoptivo de Cantabria en 1982. En 2002 el Ayuntamiento de Madrid le concedió la Medalla de Oro de la ciudad. El 25 de abril de 2008 la ciudad de Santander le rindió homenaje colocando un busto del poeta en el Paseo Marítimo, junto a Puertochico, inspirado en los versos de uno de sus poemas sobre la bahía: "Si muero, que me pongan desnudo, desnudo junto al mar. Serán las aguas grises mi escudo y no habrá que luchar". 

En San Sebastián de los Reyes (Madrid) también existe un busto del poeta frente al edificio que alberga la Universidad Popular José Hierro. En esta localidad tiene lugar el Premio Nacional de Poesía José Hierro, organizado por la Universidad Popular José Hierro y dotado con un único premio de 9000 euros. En Cabezón de la Sal (Cantabria), lugar que visitaba cada año con motivo de la velada de la poesía en el Día de Cantabria, también se le rindió tributo dedicándole una calle y colocando otro busto en el Parque del Conde San Diego.

En 2003, con el impulso de la Comunidad de Madrid, el Ayuntamiento de Getafe y la familia Hierro se creó el Centro de Poesía José Hierro, un proyecto dedicado íntegramente al estudio, difusión y creación de su poesía y a perpetuar la memoria del poeta. En 2006 pasó a ser la Fundación Centro de Poesía José Hierro donde se imparten talleres y seminarios y se organizan recitales de poesía y otros eventos de carácter artístico y literario. Además se puede disfrutar allí de la única exposición de pintura de José Hierro con carácter permanente. Era una afición que muchos desconocen más allá de lo meramente anecdótico, pero a la que José Hierro dedicó gran parte de su vida, sobre todo en sus últimos años.

Sus primeros versos aparecen en distintas publicaciones del frente republicano. Acabada la contienda, pasa cuatro años en la cárcel, y esta experiencia lo marca indeleblemente. De ahí que, al reaparecer en el panorama lírico de los años cuarenta, con dos libros casi simultáneos, lo haga urgido por un amargo poso autobiográfico que dota a su poesía de una madurez poco frecuente en jóvenes poetas. Se titula el primero "Tierra sin nosotros" (1947), marbete que nos proporciona las desoladas claves donde arraiga, no ya sólo este libro, sino buena parte de la producción surgida de la guerra: la patria un día habitable aparece en ruinas. 

El libro siguiente, "Alegría" (1947) (Premio Adonáis), continúa la reflexión de "Tierra sin nosotros". 

"Con las piedras, con el viento" (1950), es el testimonio de una experiencia amorosa abocada, también, al fracaso. 

Con "Quinta del 42" (1953) comienza la exploración de la vía solidaria, nunca ajena a Hierro, pero, hasta ahora, sostenida en penumbra; no es, sin embargo, la suya una poesía social al uso, y esta diferencia desencadena, con anticipación de años, los mecanismos superadores de un realismo que por entonces amordazaba a la poesía española.

Antirrealista es, en efecto, "Cuanto sé de mí" (1957), libro que acentúa la preocupación verbal, reivindica ámbitos imaginativos y se aleja de la historia y del tiempo para acceder a la «sonora gruta del enigma». 

Estos elementos culminan en el "Libro de las alucinaciones" (1964). Marcado por una poderosa veta irracionalista que se canaliza con frecuencia en el versículo, este poemario rompe definitivamente con las categorías espacio-temporales. 

En 1974 publicará una nueva edición de "Cuanto sé de mí"; en 1991, un nuevo libro de poemas titulado "Agenda"; en 1995 "Emblemas neurorradiológicos" y a finales de los años 90 "Cuaderno de Nueva York", considerada esta última una obra maestra contemporánea.

Su poesía es poderosamente evocativa y ahonda en una intimidad erosionada por un tiempo implacable. Se percibe la influencia de Gerardo Diego. Se inició con una temática reivindicativa testimonial, la memoria de un niño de la guerra, si bien no es un poeta social al uso; poco a poco fue haciéndose más colectiva y existencial.

José Hierro produjo las siguientes obras, principalmente poéticas:






</doc>
<doc id="4571" url="https://es.wikipedia.org/wiki?curid=4571" title="Ángel González">
Ángel González

Ángel González Muñiz (Oviedo, 6 de septiembre de 1925 – Madrid, 12 de enero de 2008) fue un poeta español de la Generación del 50. Premio Príncipe de Asturias de las Letras en 1985 y académico y Premio Reina Sofía de Poesía Iberoamericana en 1996, publicó su primer libro de poemas en 1956.

Nació en Oviedo el 6 de septiembre de 1925. Su infancia se vio fuertemente marcada por la muerte de su padre, fallecido cuando apenas tenía dieciocho meses de edad. La descomposición del seno familiar continuó durante la Guerra Civil Española, cuando su hermano Manolo murió a manos del bando nacional en 1936. Posteriormente su hermano Pedro se exilió por sus actividades republicanas y su hermana Maruja no pudo ejercer como maestra por el mismo motivo. En 1943 enfermó de tuberculosis, por lo que inició un lento proceso de recuperación en Páramo del Sil, donde se aficionó a leer poesía y empezó a escribirla él mismo. Tres años más tarde se halló ya por fin recuperado, aunque siempre arrastraría una insuficiencia respiratoria que al cabo le produciría la muerte. Decidió estudiar derecho en la Universidad de Oviedo y también magisterio; en 1950 se trasladó a Madrid para estudiar en la Escuela Oficial de Periodismo. El poeta Luis García Montero publicó en 2009 "Mañana no será lo que Dios Quiera", donde transcribe las memorias de Ángel González. Cuatro años después, en 1954, González opositó para Técnico de Administración Civil del Ministerio de Obras Públicas e ingresó en el Cuerpo Técnico; le destinaron a Sevilla, pero en 1955 pidió una excedencia y marchó a Barcelona durante un periodo en el que ejerció como corrector de estilo de algunas editoriales, entablando amistad con el círculo de poetas de Barcelona, formado por Carlos Barral, Jaime Gil de Biedma y José Agustín Goytisolo; en 1956 publicó su primer libro de poemas, "Áspero mundo", fruto de su experiencia como hijo de la guerra; con él obtuvo un accésit del "Premio Adonais". Volvió a Madrid para trabajar de nuevo en la Administración Pública y conoció al grupo madrileño de escritores de su generación, Juan García Hortelano, Gabriel Celaya, Caballero Bonald y algunos poetas más (luego conocida como Generación del 50 o del medio siglo). En 1959, participó en los actos del 20º aniversario de la muerte de Antonio Machado en la localidad francesa de Colliure.

Varios de sus poemas fueron seleccionados en la antología "Veinte años de poesía española (1939-1959)" de 1960 preparada por Josep María Castellet para la editorial Seix Barral. Tras su segundo libro, "Sin esperanza, con convencimiento" (1961), Ángel González pasó a ser adscrito al grupo de poetas conocido como "Generación del 50" o "Generación de medio siglo". En 1962 fue galardonado en Colliure con el "Premio Antonio Machado" de la editorial Ruedo Ibérico de París por su libro "Grado elemental".

El año 1970 fue invitado a dar conferencias a la Universidad de Nuevo México en Albuquerque y luego extendieron su invitación para que enseñara durante un semestre; fijó su residencia en Estados Unidos y en 1973 pasó por las Universidades de Utah, Maryland y Texas bajo la misma condición de profesor invitado, regresando en 1974 a la Universidad de Nuevo México en Albuquerque como fijo de Literatura Española Contemporánea, cargo en que se jubiló en 1993. En 1979 viajó a Cuba para formar parte del jurado del Premio Casa de las Américas de Poesía. Ese mismo año conoció a Susana Rivera, con la que se casó en 1993. Tras su jubilación siguió residiendo en Nuevo México aunque a partir de 2006 las visitas a España eran cada vez más reiteradas. 

En 1985 le concedieron el "Premio Príncipe de Asturias de las Letras" y en 1991 el "Premio Internacional Salerno de Poesía". En enero de 1996 fue elegido miembro de la Real Academia Española en el sillón "P" sustituyendo al escritor Julio Caro Baroja. Fue propuesto por los académicos Gregorio Salvador, Miguel Delibes y Emilio Alarcos. El mismo año, además, obtuvo el "Premio Reina Sofía de Poesía Iberoamericana". En 2001 obtuvo el "Premio Julián Besteiro de las Artes y las Letras". En 2004 se convirtió en el primer ganador del Premio Internacional de Poesía Federico García Lorca.

Su obra es una mezcla de intimismo y poesía social, con un particular y característico toque irónico, y trata asuntos cotidianos con un lenguaje coloquial y urbano, nada neopopularista ni localista. El paso del tiempo y la temática amorosa y cívica son las tres obsesiones que se repiten a lo largo y ancho de sus poemas, de regusto melancólico pero optimistas. Guillermo Díaz-Plaja define así su poesía:

Su lenguaje es siempre puro, accesible y transparente; se destila en él un fondo ético de digna y humana fraternidad, que oscila entre la solidaridad y la libertad, al igual que el de otros colegas generacionales como José Ángel Valente, Jaime Gil de Biedma, Carlos Barral, José Agustín Goytisolo y José Manuel Caballero Bonald.

González colaboró con el cantautor Pedro Guerra en el libro-disco "La palabra en el aire" (2003) y también con el tenor Joaquín Pixán, el pianista Alejandro Zabala y el acordeonista Salvador Parada en el álbum "Voz que soledad sonando" (2004). El cantautor Joaquin Sabina le rendiría tributo con su canción "Menos dos alas".

La madrugada del 12 de enero de 2008 falleció el poeta, a los 82 años, en Madrid, a causa de la insuficiencia respiratoria crónica que padecía.







</doc>
<doc id="4574" url="https://es.wikipedia.org/wiki?curid=4574" title="Ciencias de la comunicación">
Ciencias de la comunicación

Las ciencias de la comunicación o comunicología estudian, analizan o discuten los fenómenos sociales relacionados con la información y la comunicación, así como los medios de difusión masivos e industrias culturales, y el conjunto semiótico que construyen, generando sus propios métodos de estudio y herramientas analíticas.

Se trata de un campo de estudios interdisciplinario, cuyos conceptos teóricos son compartidos con frecuencia es también abordado por otras disciplinas, entre las que es posible mencionar la sociolingüística, la sociología, la antropología social, la cibernética y la psicología social, entre otras.

Aunque es posible hablar de comunicación masiva desde la invención de la imprenta por Gutenberg, no fue sino hasta la década de 1920 cuando se llevaron a cabo los primeros estudios sobre la influencia de la propaganda en el contexto de la Europa de la Segunda Guerra Mundial, con el ascenso de los regímenes fascistas de Alemania e Italia. Si bien los clásicos griegos como Aristóteles, Gorgias y Sócrates, hablaron de la persuasión como un modo para llevar a cabo el proceso de la comunicación; estos autores se quedaron en el nivel lógico-semántico de la cuestión y no plantearon el asunto desde el punto de vista de una sociedad completa.

Aunque la retórica fue elaborada por Aristóteles hace ya más de 2300 años, se basó en la observación empírica y esto fue el cimiento de la gran infraestructura de la comunicación. Cabe destacar que, sobre todo, se enfocaba en el orador. La retórica tuvo mucho menos interés en lo que había más allá del orador, en los que escuchaban (el público), ni tampoco en la retroalimentación que en algún momento se podía dar. En la antigüedad, la retórica tuvo un enorme prestigio como disciplina, y fue vista como un modelo en el cual una sola persona podía convencer a todo un público. Sin embargo este enfoque tiene un interés limitado desde el punto de vista más descriptivo de la ciencia moderna. El enfoque científico social de la comunicación exigía un análisis empírico de los efectos medibles u observables de la comunicación. También se puede asumir una perspectiva crítica, basada en modelos verificables y susceptibles de ser mejorados, perfeccionados o generalizados. El campo de estudio de las ciencias de la comunicación es muy extenso y, por esta razón, es muy complicado abordar todos los aspectos relevantes y cada uno de sus aspectos.

La comunicación es un sistema de intercambio de información que altera el estado de conocimiento del receptor de la misma. Se supone que el estado de conocimiento afecta a las opiniones, preferencias y conductas de los individuos, el receptor de una información puede re-evaluar sus opiniones, cambiar sus preferencias o adaptar sus conductas en función de la información recibida (sea ésta veraz o no).

En la comunicación de las sociedades humanas se consideran importantes los fenómenos estudiados por la psicología social, así como los procesos organizativos y los nuevos fenómenos sociales emergentes. Es más, la altísima especialización existente en las sociedades humanas modernas requiere que los individuos u organizaciones que tienen acceso a determinados conocimientos transmitan dicho conocimiento a individuos cuya especialización no les permitiría acceder directamente a ellos. Las ciencias de la comunicación analizan cómo es ese proceso de comunicación desde los individuos con conocimientos más específicos a otros menos especializados, así como el efecto recíproco de un grupo sobre otro. En muchas sociedades, gran parte de la información se difunde a través de periodistas y expertos dedicados a la recopilación, análisis y difusión de información específica que pueden resultar importantes para individuos especializados en otras tareas y que por tanto no disponen de tiempo, medios u oportunidad de acceder por si mismos a ciertos hechos o realidades.

En términos generales existen diferentes tipos de comunicación, el cual se refiere a las formas o maneras de comunicación:

La información organizacional se refiere al análisis del flujo de informaciones relativas a los objetivos y medios de una organización entre los individuos de dicha organización. Frecuentemente dicha comunicación tiene al director de la misma como emisor y a los subordinados como receptores y el mensaje tiene que ver con la obtención de un resultado laboral asertivo, aunque existen otras posibles combinaciones de emisor, receptor y mensaje.

Si en la comunicación organizacional no hay un mensaje adecuado que sea recibido por el receptor, el resultado será una comunicación fallida que no modificará el estado de conocimiento del receptor en el sentido adecuado. Por el contrario si el mensaje es recibido de manera correcta y el receptor tiene la capacitación adecuada para extraer las consecuencias correctas el proceso de comunicación resultará satisfactorio.

Cuando el emisor es el director de la organización es importante verificar que no exista ruido (distorsión del mensaje) dentro del canal para enviar el mensaje, ya que siendo director o subdirector depende gran parte del trabajo de los receptores subordinados la existencia de ruido tiene grandes posibilidades de acabar en comunicación fallida.

Áreas de enfoque laboral:

Es muy difícil dar una definición concreta de qué constituye una información, dado que los estados de conocimiento de los individuos son en gran parte abstracciones no directamente accesibles. Informalmente, la información está asociada a mensajes propiamente lingüísticos, conductas sociales ampliamente difundidas y patrones de conducta o esquemas que están culturalmente determinados. El proceso de aculturación de un niño consiste no sólo en aprender la lengua o lenguas de su comunidad sino en deducir qué conductas son adecuadas y qué patrones de conducta son pertinentes en cada caso. Si bien la comunicación se transmite de manera preferentemente lingüística es evidente que los símbolos y las conductas socialmente admitidas son fuente de información. De hecho el choque cultural puede producirse cuando un individuo que desconoce algún aspecto simbólico o conducta de una sociedad diferente a la que se aculturuó interfiere con su manera de actuar.

Este sentido amplio de información es complicado de formalizar. Por eso la teoría de la información toma un enfoque menos holístico y más reduccionista. Propiamente, en teoría de la información un mensaje es cualquier secuencia de un conjunto finito de signos. En la mayor parte de actos comunicativos esos signos pueden representar entidades de tipo lingüístico aunque no estrictamente, ya que en la teoría de la información los signos no necesariamente tienen por qué representar palabras, letras o fonemas. El conjunto de tales signos se llama alfabeto por analogía con el caso lingüístico aunque aquí alfabeto es sólo un conjunto finito de signos distinguibles que se combinan de acuerdo a cierta combinatoria. Las probabilidades de aparición de ciertas secuencias de signos son objeto de estudio de la teoría de la información, de hecho la cantidad total de información en una secuencia de cierto tipo viene dada por:

donde:
El número anterior es la cantidad de información esperada en una secuencia de "M" caracteres expresada en bits.

A un nivel más general la información consta de proposiciones complejas que describen hechos y de proposiciones que describen objetivos o intenciones. La decodificación adecuada de las informaciones requiere que emisor y receptor estén de acuerdo sobre los términos usados y que el receptor tenga conocimientos suficientes para interpretar el significado correcto de los mensajes. Actualmente no existe una teoría cuantitativa del significado, por lo que en teoría de la información una secuencia de letras inteligibles puede tener la misma cantidad de bits que un discurso psicológicamente motivado. Esto es así, porque la teoría de la información no trata sobre el contenido proposicional de los mensajes o la significación psicológica de los mismos, sino simplemente de la complejidad de los algoritmos necesarios para generar dicha secuencia de signos.

La comunicación abarca una gran variedad de especialidades, entre las que destacan:




</doc>
<doc id="4575" url="https://es.wikipedia.org/wiki?curid=4575" title="Videojuego de disparos en primera persona">
Videojuego de disparos en primera persona

Los videojuegos de disparos en primera persona (en inglés First-person shooter), son un género de videojuegos y subgénero de los videojuegos de disparos en los que el jugador observa el mundo desde la perspectiva del personaje protagonista.

En 1974 apareció el que algunos consideran como el primer videojuego de este género: "Maze War"; además, fue también el primer videojuego multijugador (en red local), siendo así uno de los padres de los videojuegos de disparos en primera persona, junto con "Spasim", del mismo año, que permitía batallas multijugador en línea de hasta 32 jugadores. En los años siguientes, con títulos como "Driller" (1987) u otros, aunque importantes, los videojuegos en primera persona no superaban a los clásicos videojuegos de plataformas o tercera persona, pero con la salida de "Wolfenstein 3D" en 1992, y "Doom", en 1993, revivieron el mercado y popularizaron el género.

Entre 1996 y 1998 salieron juegos como "Quake", "Duke Nukem 3D" y "Exhumed / PowerSlave" (los tres de 1996), "Half-Life" y "Unreal" (ambos de 1998) que revolucionaron el género por sus gráficos, jugabilidad y por el modo multijugador en línea y en red local. Aparte de estas mejoras, "Half-Life" daba la posibilidad de relacionarse con otros personajes no jugadores.

Sin lugar a dudas un juego que no puede dejarse de lado es el mítico GoldenEye 007], para la consola Nintendo 64, lanzado en 1997; este juego renovó el modo multijugador creando diferentes tipos de juego como capturar la bandera, un tiro y eras liquidado, entre otros; igualmente trajo la lucha por equipos todos estos aspectos que ahora se han estandarizado en los nuevos juegos. Respecto a su modo de un solo jugador, abandonó el sistema de correr por el nivel liquidando enemigos para involucrar elementos de sigilo y algo muy innovador para aquella época, que fue la inclusión de objetivos para poder terminar misiones; es por esto que "Golden Eye 007" marcó un antes y un después dentro del género FPS.

Sin "Half-Life", "Unreal" o el motor "Havok", los FPS serían muy diferentes de como se conocen actualmente, ya que todos los videojuegos de disparos en primera persona posteriores a éste poseen un poco de cada uno.

Un importante lanzamiento en el mercado de los FPS en línea fue "Quake 3 Arena", de 1999, que, a pesar de no tener historia relevante como los dos primeros juegos, innovaba en el modo multijugador en línea. A diez años de su lanzamiento se sigue usando en torneos y campeonatos, lo que da una idea de su fama.

2000 fue el año de publicación de "Deus Ex", un videojuego en primera persona para un solo jugador que mezclaba elementos de los videojuegos de rol y los videojuegos de aventura. Incluía muchas misiones que no formaban parte de la trama principal y existían múltiples maneras de completar cada misión. El juego también poseía un sistema de construcción de personajes similar al de un videojuego de rol, donde se ganaban puntos de experiencia por completar varios objetivos que podían ser gastados en mejoras para el personaje.

En el 2001 destaca "Aliens vs. Predator", lanzado por Fox interactive. El jugador puede elegir ponerse en la piel de un marine, un alien o un predator. El juego está caracterizado por su ambiente oscuro y terrorífico. Destaca también "" que aparte de su excelente inteligencia artificial y su ambientación, tanto en espacios pequeños como en zonas extensas, tiene la posibilidad de utilizar vehículos y sienta las bases de control de lo que será el género en las consolas.

En 2002 fue publicado un "videojuego" que supuso la consagración de los videojuegos en primera persona, multijugador masivo, conocido como "World War II Online", e hizo que los vehículos controlados por el jugador se convirtieran en una característica estándar en los juegos en primera persona.

También en 2002, el juego "Metroid Prime" fue lanzado. Era un juego en primera persona para Nintendo Gamecube con un gran mundo que se centraba más en la exploración que en el combate. Fue denominado como un videojuego de aventura en primera persona por los expertos debido a su enfoque en la exploración. El juego poseía unos gráficos de última generación y un sistema de elección de objetivos similar al utilizado en "".

En 2004, "Doom 3" apareció. Hacía uso de complejas iluminaciones y efectos de sombras para crear una atmósfera lo más tensa y terrorífica posible al jugador. Otros proyectos ya han hecho uso de estas características que permiten explotar al máximo el potencial del hardware moderno. Un ejemplo de esto es el proyecto "Tenebrae", una modificación del motor de "Quake" que implementa sombras y luces realistas y texturas con relieve.

2004 fue un año donde muchos videojuegos de disparos en primera persona salieron, como el ya mencionado "Doom 3", "Half-Life 2" (junto con "" y "", que son los mismos mods llevados al motor Source de "Half-Life 2"), "Far Cry", "Unreal Tournament 2004", "", "", entre otros. "Half-Life 2" y el "Far Cry" emplearon el uso de reflejos de agua detallados y la tecnología "High Dynamic Range" (HDR). "Half Life 2" agregó la posibilidad de que uno o varios NPC acompañaran al jugador durante un gran tramo del juego, ya sea ayudando a matar enemigos, haciendo comentarios de lo que ven o piensan, curando, dando munición, o avisando que al arma en uso se le está acabando el cargador.

Existen muchos intentos de combinar los géneros de acción en primera persona con los juegos de rol o la estrategia en tiempo real. La modificación "Natural Selection" unía un juego en primera persona multijugador con elementos de la estrategia en tiempo real. "" también contenía algunos elementos de los juegos de rol, con un sistema de experiencia y habilidades que funcionaba incluso a lo largo de varios enfrentamientos.

Luego, en octubre de 2005, salió "Quake 4" basado en el motor de "Doom 3" con muchas actualizaciones y optimizaciones, permitiendo escenarios tanto abiertos como cerrados .

En 2006-2007 se lanzaron juegos como: "", "Gothic 3", o "Hellgate London" que combinan el rol en tercera persona y la interacción de la primera persona como modalidades de juego. También salió el juego "Combat Arms", el cual ha sorprendido por sus buenos gráficos, poco peso (MB)y el hecho de que es gratuito (requiere registrarse), y por su buena jugabilidad, desafortunadamente sólo está disponible en ciertas áreas.

En 2007-2008 se lanzaron los juegos con mejores gráficos de la historia del FPS "Crysis" y posteriormente "Crysis Warhead", ambos de la empresa Crytek utilizando éstos el motor CryEngine 2. También se destaca la salida de juegos como "BioShock" utilizando el Unreal Engine, "" en la consola Wii, la cual no solo destacaba en aspecto gráfico, sino también es el que abrió el camino de una jugabilidad novedosa, "The Conduit" se convertiría luego en su sucesor, "Call of Duty 4" de Activision, "Far Cry 2" de Ubisoft, "Halo 3" de Bungie, en 2009 se lanzó "Killzone 2" para PlayStation 3 con los mejores gráficos en consola para un FPS desarrollado por la empresa Guerrilla.




</doc>
<doc id="4582" url="https://es.wikipedia.org/wiki?curid=4582" title="Vasili Kandinski">
Vasili Kandinski

Vasili Vasílievich Kandinski —, translit.: Vasíli Vasílievič Kandínskij— (Moscú, -Neuilly-sur-Seine, 13 de diciembre de 1944) fue un pintor ruso, precursor de la abstracción en pintura y teórico del arte. Se considera que con él comienza la abstracción lírica y el expresionismo.

Vasili Kandinski nació el 16 de diciembre (en el antiguo calendario ruso: 4 de diciembre) de 1866, proveniente de una familia de clase media alta. Su padre Vasili Silvéstrovich Kandinski era un comerciante de té procedente de Kiajta, una población siberiana cercana a la frontera con Mongolia. La abuela de Vasili era una aristócrata mongola de la dinastía Gantimúrov. Lidia Ivánovna Tijéieva, la madre de Vasili, era de Moscú. Pasó su infancia y juventud entre Moscú y Odesa, donde se trasladó la familia en 1871. Tras el divorcio de sus padres vivió con su padre. Su tía Elizavet Tijéieva también lo cuidó. Su abuela materna era alemana y le hablaba en alemán. En Odesa tomó clases de piano y de violonchelo. En 1886 Kandinski comenzó sus estudios de Derecho y Ciencias económicas en la Universidad de Moscú. También estudió etnografía. En 1892 se casó con su prima Anna Chemyákina, con quien vivió hasta 1904. En 1893 fue nombrado profesor asociado en la Facultad de Derecho. En 1896 la Universidad de Tartu le ofreció una plaza de profesor que rechazó para dedicarse por completo al arte. Esta decisión estuvo influida por la exposición de los impresionistas en Moscú en 1895, al ver las obras de Monet y la representación de "Lohengrin" de Richard Wagner en el teatro Bolshói.

Se trasladó a Múnich donde inicialmente no fue admitido en la Academia de Arte. Estudió un tiempo en la academia privada de Anton Ažbe hasta 1900, cuando fue admitido en la Academia. Su profesor fue Franz von Stuck y, como consideró que la paleta de Kandinski era demasiado brillante, le hizo pintar en una gama de grises durante un año.

En 1901 fundó el grupo Phalanx, cuyo propósito principal era introducir las vanguardias francesas en el provinciano ambiente muniqués, para lo que abrió una escuela en la que daba clases. Sus pinturas de los primeros años del siglo eran paisajes ejecutados con espátula, en un principio sombríos, para luego adquirir una intensidad casi "fauve". También pintó temas fantásticos basados en tradiciones rusas o en la Edad Media alemana. Este período estuvo marcado por la experimentación técnica, en particular en el uso del temple sobre un papel oscuro, para dar una impresión de superficie transparente, iluminada desde atrás. La consistencia tonal del claroscuro enfatiza el esquema, borrando la distinción entre las figuras y el fondo, resultando una composición casi abstracta.

En 1902 expuso por primera vez con la Secesion de Berlín y realizó sus primeras xilografías. En 1903 y 1904 viaja por Italia, Países Bajos, África y visita Rusia. En 1904 expuso en el Salón de Otoño de París. En 1903 se divorció de Anna Chemyákina y se casó con la joven artista Gabriele Münter. Durante cinco años viajó con su esposa por Europa pintando y participando en exposiciones. Volvió a Baviera y se asentó en Murnau am Staffelsee en la falda de los Alpes. En 1909 fue elegido presidente de la Nueva Asociación de Artistas de Múnich (NKVM). La primera exposición del grupo tuvo lugar en la galería Thannhauser de Múnich ese mismo año. Hacia el final de la década, las pinturas de Kandinski denotan una gran tendencia a la plenitud, por la equivalencia en intensidad de las áreas de color y la superficie reluciente, que destruye toda ilusión de profundidad. Las series de cuadros de jinetes en combate comenzaron en 1909, y en ellas, la línea del horizonte se va erradicando gradualmente, al igual que otras referencias espaciales.

En 1913 escribió sus memorias y una colección de poesías.
En 1913 una obra suya se presentó en el Armory Show de Nueva York.

Al estallar la Primera Guerra Mundial abandonó Alemania y junto a su esposa Gabriele se mudaron a Suiza el 3 de agosto de 1914. En noviembre de 1914 Gabriele volvió a Múnich y Kandinski volvió a Moscú. En el otoño de 1916 conoció a Nina Andreevskaya, que era hija de un general ruso. Se casó con ella en febrero de 1917.

A partir de la Revolución de octubre de 1917, Kandinski desarrolló un trabajo administrativo para el Comisariado del Pueblo, para la Educación; entre los proyectos de este organismo estaba la reforma del sistema educativo de las escuelas de arte. En 1920 fue uno de los fundadores en Moscú del INJUK (Instituto para la Cultura Artística), a lo largo de este año surgió el conflicto entre Kandinski, Malévich y otros pintores idealistas frente a los productivistas (o constructivistas), Vladímir Tatlin y Aleksandr Ródchenko, este último grupo encontró un fuerte apoyo en "el plan de propaganda monumental" ideado por las autoridades políticas de la Revolución. La situación de tensión propició la salida de Kandinski de Rusia.

En 1922 se trasladó a Weimar (Alemania), donde impartió clases teóricas para la Escuela de la Bauhaus. En 1926 se publicó su libro "Punto y línea sobre el plano. Contribución al análisis de los elementos pictóricos". Una continuación orgánica de su trabajo anterior "De lo espiritual en el arte".

Hacia 1931 los nacionalsocialistas iniciaron una campaña a gran escala contra la Bauhaus que llevó a su cierre en 1932. Kandinski y su esposa emigraron a Francia y fijaron su residencia en Neuilly-sur-Seine, suburbio de París.

El desarrollo de Kandinski hacia la abstracción encuentra su justificación teórica en "Abstracción y empatía" de Wilhelm Worringer, que se había publicado en 1908. Worringer argumenta que la jerarquía de valores al uso, basada en las leyes del Renacimiento, no es válida para considerar el arte de otras culturas; muchos artistas crean desde la realidad pero con un impulso abstracto, que hace que las últimas tendencias del arte se den en sociedades menos materialistas.

Kandinski, al igual que Piet Mondrian, estaba interesado también en la teosofía, entendida como la verdad fundamental que subyace detrás de doctrinas y rituales en todas las religiones del mundo; la creencia en una realidad esencial oculta tras las apariencias, proporciona una obvia racionalidad al arte abstracto.

En 1912 publicó "De lo Espiritual en el Arte", donde critica a las instituciones académicas tradicionalistas y la idea de arte en general. Es el primer libro que describe la fundación teórica del movimiento abstracto y habla de una nueva época de gran espiritualidad y de la contribución de la pintura a ella. El arte nuevo debe basarse en un lenguaje de color y Kandinski da las pautas sobre las propiedades emocionales de cada tono y de cada color, a diferencia de teorías sobre el color más antiguas, él no se interesa por el espectro sino solo en la "respuesta del alma".

Entre 1926 y 1933 pintó 159 óleos y 300 acuarelas. Muchos de ellos se perdieron después de que los nazis declararon "degeneradas" sus pinturas.
En 1939 se nacionalizó francés.

Kandinski recuerda la fascinación por el color como un niño. Su fascinación por el simbolismo del color y la psicología continuó a medida que crecía. En 1889, formó parte de un grupo de investigación etnográfica que viajó a Vólogda al norte de la región de Moscú. En "Mirada retrospectiva", relata que las casas e iglesias fueron decoradas con colores tan brillantes que al entrar en ellos, sentía que se movía en una pintura. Esta experiencia, y su estudio de arte popular de la región (en particular, el uso de colores brillantes sobre un fondo oscuro), se reflejó en gran parte de sus primeros trabajos. Unos años más tarde, primero comparó pintura para componer música de la manera por la cual se convertiría en señalar, escribiendo, "El color es la tecla. El ojo es el martillo. El alma es el piano. El artista es la mano que, con una u otra tecla hace vibrar el espíritu del ser humano".

En 1896, a la edad de 30 años, Kandinski abandonó una prometedora carrera docente en el mundo de la ley y la economía para inscribirse en la escuela de arte de Múnich. No se le concedió inmediatamente la admisión, y comenzó a aprender el arte por sí mismo. Ese mismo año, antes de salir de Moscú, vio una exposición de pinturas de Monet. Quedó impactado con el estilo impresionista de la serie de los , por su fuerte sentido de color casi independiente de los objetos mismos.

Kandinski fue influenciado de manera similar durante este período por Richard Wagner que, según él, empujó los límites de la música y la melodía más allá de lirismo estándar. Fue también espiritualmente influenciado por Helena Blavatsky (1831-1891), la mejor exponente conocida de la teosofía. La Teoría teosófica postula que la creación es una progresión geométrica, a partir de un solo punto. El aspecto creativo de la forma que se expresa mediante una serie descendente de círculos, triángulos y cuadrados. Los libros de Kandinski De lo espiritual en el arte (1910) y Punto y línea sobre el plano (1926) se hicieron eco de esta doctrina teosófica.

La escuela de arte, por lo general se considera difícil, pero era fácil para Kandinski. Fue durante este tiempo que comenzó a surgir como un teórico del arte, y como un pintor. El número de sus pinturas existentes aumentó a principios del siglo xx, queda mucho de los paisajes y pueblos que pintó, con amplios sectores de formas de color y reconocible. En su mayor parte, sin embargo, las pinturas de Kandinski no cuentan con ninguna figura humana, una excepción es "Domingo. (Rusia antigua)" (1904), en la que Kandinski recrea una vista muy colorida (y de fantasía) de los campesinos y los nobles frente a los muros de una ciudad. "Pareja a caballo" (1907) representa a un hombre a caballo con una mujer, con la ternura y el cuidado que cabalgan junto a un pueblo ruso con paredes luminosas a través de un río. El caballo está en silencio mientras las hojas de los árboles, la ciudad, y los reflejos en el río brillan con manchas de color. Este trabajo demuestra la influencia del puntillismo en la forma en que se pierde la profundidad de campo en una superficie plana y luminiscente. La influencia del fovismo es también evidente en estas primeras obras. Los colores se utilizan para expresar la experiencia de Kandinski con la materia, no para describir la naturaleza objetiva.

Quizás la más importante de sus pinturas de la primera década de 1900 fue "El Jinete Azul" (1903), la cual muestra una pequeña figura envuelta en un caballo veloz corriendo por un prado rocoso. La capa del jinete es azul medio y la sombra proyectada es de color azul oscuro. En el primer plano son sombras azules más amorfas, las traseras de los árboles en otoño, en el fondo. El jinete azul en la pintura destaca (aunque no claramente definido) y el caballo tiene un andar anormal (que Kandinski debía saber). Algunos historiadores del arte creen que una segunda figura (tal vez un niño) va agarrado por el piloto, aunque puede tratarse de una sombra del jinete solitario. Esta disyunción intencional, que permite a los espectadores a participar en la compleción de la obra de arte, se convirtió en una técnica cada vez más consciente utilizada por Kandinski en los años siguientes, y culminó en las obras abstractas del período 1911-1914. En "El Jinete Azul", Kandinski muestra el jinete más como una serie de colores que en los detalles específicos. Esta pintura no es una excepción en este sentido en comparación con los pintores contemporáneos, pero muestra la dirección que Kandinski tomaría solo unos pocos años después.

Entre 1906 y 1908 Kandinski pasó mucho tiempo viajando por Europa (él era un asociado de grupo simbolista de Moscú), hasta que se instaló en la pequeña ciudad bávara de Murnau. El cuadro "Montaña Azul" (1908-1909) fue pintado en este momento, lo que demuestra su tendencia hacia la abstracción. Una montaña azul está flanqueada por dos árboles grandes, uno amarillo y uno rojo. Una procesión, con tres jinetes y varios figuras, se cruza en la parte inferior. Las caras, ropa y sillas de montar de los jinetes son cada una de un solo color y ni ellos ni las figuras caminando muestran cualquier detalle real. Los planos y los contornos también son indicativos de la influencia fauvista. El amplio uso del color en "Montaña Azul" ilustra la inclinación de Kandinski hacia un arte en el que el color se presenta independientemente de la forma, y en el que a cada color se le da la misma atención. La composición es más plana, el cuadro se divide en cuatro secciones: el cielo, el árbol rojo, el amarillo y el árbol de la montaña azul con los tres jinetes.

En 1911, Vasili Kandinski y Franz Marc y otros artistas, fundaron en Múnich un movimiento expresionista Der Blaue Reiter ("El Jinete Azul" en español) que transformó el expresionismo alemán.

De 1918 a 1921, Kandinski trabaja en la política cultural de Rusia y colabora en la educación artística y la reforma de los museos. Pintó poco durante este período dedicando su tiempo a la enseñanza artística con un programa basado en el análisis de la forma y del color. También ayudó a organizar el Instituto de Cultura Artística en Moscú. En 1916 conoció a Nina Andreievskaya, con quien se casó al año siguiente. Su punto de vista espiritual y expresionista del arte fue finalmente rechazado por los miembros radicales del Instituto (Tallin, Rodchenko) como demasiado individualista y burgués. En 1921, Kandinski fue invitado a ir a Alemania, para asistir a la Bauhaus de Weimar, por su fundador el arquitecto Walter Gropius.

Kandinski no solo enseñó en las clases de diseño básico para principiantes y el curso sobre teoría avanzada en el Bauhaus, sino que también llevó a cabo clases de pintura y un taller en el que aumentó su teoría del color con los nuevos elementos de la psicología de la forma. El desarrollo de sus trabajos sobre el estudio de las formas, en particular en los puntos y formas de línea, dio lugar a la publicación de su segundo libro teórico "Punto y línea sobre el plano" en 1926. Los elementos geométricos adquieren una importancia cada vez mayor tanto en su enseñanza y como en su pintura, especialmente el círculo, medio círculo, el ángulo, las líneas rectas y curvas. Este período fue sumamente productivo. Esta libertad se caracteriza en sus obras por el tratamiento rico en colores y matices —como en el amarillo-rojo-azul (1925), donde Kandinski ilustra su distancia desde el constructivismo y el suprematismo, movimientos influyentes de la época—.

Los dos metros de ancho amarillo- rojo-azul (1925) se componen de varias formas: un rectángulo vertical amarillo, una cruz inclinada roja y un gran círculo azul oscuro, una multitud de líneas negras rectas (o sinuosa), arcos circulares, círculos monocromáticas y dameros de colores dispersos, contribuyendo a su delicada complejidad. Esta simple identificación visual de las formas y de las masas principales de los colores presentes en el lienzo son solo una primera aproximación a la realidad interna de la obra, cuyo reconocimiento exige la observación más profunda, no solo de formas y colores que intervienen en la obra, sino su relación absoluta, las posiciones relativas en el lienzo y su armonía.

Kandinski fue uno de Die Blaue Vier (Blue Four), formada en 1924 con Paul Klee, Feininger y Alekséi von Jawlensky, que dio conferencias y exhibió en los Estados Unidos en 1924. Debido a la hostilidad de la derecha y a la izquierda de la Bauhaus de Weimar, se establecieron en Dessau en 1925. Después de una campaña de difamación nazi de la Bauhaus Dessau en 1932 se marcha a Berlín, hasta su disolución en julio de 1933. Kandinski luego abandonó Alemania y se estableció en París.

Al vivir en un pequeño apartamento en París, Kandinski creó su trabajo en un estudio de la sala. Con formas biomórficas, flexibles, no geométricas, los contornos de las formas que aparecen en sus pinturas sugieren organismos microscópicos que no hacen sino expresar la vida interior del artista. Kandinski utiliza composiciones originales en color, que evocan el arte popular eslavo. También en ocasiones mezcla con arena la pintura para dar a sus obras una textura granular y rústica.

Este período corresponde a una síntesis de los trabajos previos de Kandinski en el que utilizó todos los elementos, enriqueciéndolos. En 1936 y 1939 pintó sus dos últimas composiciones principales; el tipo de telas elaboradas no se había producido durante muchos años. "Composición IX" tiene mucho contraste y diagonales poderosas cuya principal forma da la impresión de un embrión en el útero. Pequeños cuadrados de colores y bandas de colores destacan sobre el fondo negro del cuadro "Composición X" como fragmentos de estrellas (o filamentos ), mientras enigmáticos jeroglíficos con tonos pastel cubren una gran masa marrón que parece flotar en la esquina superior izquierda del lienzo. En la obra de Kandinski, algunas características son evidentes, mientras que ciertos toques son más discretos y velados, y solo se revelan progresivamente tras profundizar en la relación con su trabajo. Tenía la intención de sus formas (sutilmente armonizados y colocados) para resonar con el alma del observador.

En este período muchas de sus obras fueron adquiridas por Solomon Guggenheim, que fue uno de sus apoyos más entusiastas.

Al igual que en las teorías de los ensayos Der Blaue Reiter, Almanac y las indicaciones del compositor Arnold Schoenberg, Kandinski expresó también la comunión entre el artista y el espectador como puestas a disposición tanto de los sentidos como de la mente (sinestesia). Escuchando tonos y acordes mientras pintaba, Kandinski afirma que, por ejemplo, el amarillo es el color del centro en una trompeta de latón, negro es el color del cierre y el fin de las cosas, y que las combinaciones de colores producen frecuencias vibratorias, similares a los acordes tocados en un piano. Kandinski también desarrolló una teoría de las figuras geométricas y sus relaciones, afirmando, por ejemplo, que el círculo es la forma más pacífica y representa el alma humana. Estas teorías se explican en "Punto y línea sobre el plano" (ver más abajo).

Durante los estudios que Kandinski hizo en preparación para "Composición IV", se sintió agotado y se fue a dar un paseo. Mientras estaba fuera, Gabriele Münter arregló su estudio y sin querer le dio vuelta el lienzo. Al regresar y ver la tela (sin reconocerla) Kandinski cayó de rodillas y lloró, diciendo que era la pintura más hermosa que había visto nunca. Había sido liberado del apego a un objeto. Como la primera vez que vio "Pilas de Heno" de Monet, experiencia que cambiaría su vida.

En otro episodio con Münter durante los años expresionistas-abstractos bávaros, Kandinski estaba trabajando en su "Composición VI" que le tomó casi seis meses de estudio y preparación. La obra pretendía evocar una inundación, el bautismo, la destrucción y renacimiento al mismo tiempo. Después de describir el trabajo sobre un panel de madera de tamaño mural, se quedó bloqueado y no pudo continuar. Münter le dijo que él estaba atrapado en su intelecto y no alcanzaba el verdadero sujeto de la fotografía. Le sugirió que se limitara a repetir la palabra "uberflut" ("diluvio" o "inundación") y se centrara en su sonido y no su significado. Repitiendo esta palabra como un mantra, Kandinski pintó y completó la obra monumental en un lapso de tres días.

El análisis sobre las formas y los colores de Kandinski resulta, no de simples y arbitrarias asociaciones con ideas, sino de la experiencia interior del pintor. Pasó años creando pinturas abstractas, sensorialmente ricas, trabajando con formas y colores sin descanso, observando sus pinturas y las de otros artistas, teniendo en cuenta sus efectos sobre su sentido del color. Esta experiencia subjetiva es algo que el filósofo francés Michel Henry llama "subjetividad absoluta" o la "absoluta vida fenomenológica ".

Publicado en 1911, el libro de Kandinski compara lo espiritual en la vida de la humanidad a una pirámide: el artista tiene la misión de guiar a otros a la cima con su obra. La punta de la pirámide son esos pocos artistas, grandes. Se trata de una pirámide espiritual, avanzando y ascendiendo lentamente, incluso si a veces parece inmóvil. Durante los períodos decadentes, el alma se hunde hasta el fondo de la pirámide, la humanidad solo busca el éxito externo, haciendo caso omiso de las fuerzas espirituales.

La evolución del Arte y del mundo espiritual se produce en libertad, fuera de influencias, a veces se centra en el color y otras veces se centra en las formas.

La evolución en la pintura depende de las formas y los colores, de cómo se vayan utilizando y combinando. Una serie de figuras iguales pueden transmitir un mismo mensaje, sin embargo, si existe una variación de color y/o formas en la composición, el mensaje se distorsiona.

Al igual que los colores las formas tendrán sus efectos espirituales, los triángulos se relaciona más con los tonos cálidos (amarillo, rojo) esto por la agudeza de sus ángulos, en el caso de los colores profundos se relacionan con formas más cuadradas y redondas.

La espiritualidad humana va a reaccionar según como el artista utilice las formas y los colores; con un simple color se pueden transmitir diferentes sentimientos, como tristeza o alegría, dependiendo de su matiz.

Las propiedades obvias que podemos ver cuando miramos un color aislado y se le deja actuar solo, por un lado son la calidez o frialdad del tono de color y por el otro la claridad u oscuridad de ese tono. El calor es una tendencia hacia el amarillo, y la frialdad una tendencia hacia el azul; amarillo y azul, forman el primer gran contraste y dinámica. El amarillo tiene un movimiento excéntrico y el azul un movimiento concéntrico; una superficie amarilla parece moverse más cerca de nosotros, mientras que una superficie azul parece alejarse. El amarillo es un color típicamente terrestre, cuya violencia puede ser dolorosa y agresiva. El azul es un color celeste, que evoca una profunda calma. La combinación de los rendimientos de azul y amarillo da un resultado de inmovilidad y de calma, que es el verde.

La claridad es una tendencia hacia el blanco, y la oscuridad es una tendencia hacia el negro. Blanco y negro forman el gran contraste segundo, que es estático. El blanco es un silencio profundo, absoluto, lleno de posibilidades. El negro es la nada sin posibilidad, un silencio eterno sin esperanza, y se corresponde con la muerte. La mezcla de blanco con negro da gris, que no posee ninguna fuerza activa y cuya tonalidad es cercana a la de verde. El gris corresponde a la inmovilidad sin esperanza, pero tiende a la desesperación cuando se pone oscuro, recuperando un poco de esperanza cuando se ilumina.

El rojo es un color cálido, alegre y agitado, es contundente, un movimiento en sí mismo. Mezclado con negro se vuelve marrón, un color fuerte. Mezclado con amarillo, gana en calidez y se vuelve naranja, que imparte un movimiento de irradiación en sus alrededores. Cuando se mezcla con rojo y azul se aleja para convertirse en púrpura, que es un rojo fresco. Rojo y verde forman el gran contraste tercero, y naranja y púrpura el cuarto.

El ojo humano puede relacionar todo tipo de vivencias y sentimientos por medio de los colores y las formas. No necesariamente tiene que tener una representación exacta para identificarse con la misma. No es sino el uso correcto de los colores y/o formas lo que hace que una pintura pueda transmitir un mensaje e incluso armonizar con el alma humana.

En sus escritos Kandinski analizó los elementos geométricos que componen cada pintura: el punto y la línea. Llamó al soporte físico y la superficie del material en el que el artista dibuja o pinta el plano básico, o PB. Él no los analiza objetivamente, sino desde el punto de vista de su efecto sobre el observador interior.

Un punto es un elemento pequeño de color formulado por el artista en el lienzo. No es ni un punto geométrico ni una abstracción matemática, sino que es la extensión, forma y color. Esta forma puede ser un cuadrado, un triángulo, un círculo, una estrella o algo más complejo. El punto es la forma más concisa, aunque de acuerdo con su ubicación en el plano básico tomará una tonalidad diferente. Puede ser aislado o resuenan con otros puntos o líneas.

Una línea es el producto de una fuerza que se ha aplicado en una dirección dada: la fuerza ejercida sobre el lápiz o pincel por el artista. Las formas producidas lineales pueden ser de varios tipos: una línea recta, que resulta de una fuerza única aplicado en una sola dirección; una línea angular, como resultado de la alternancia de dos fuerzas en diferentes direcciones, o una curva (o en forma de onda) línea, producido por el efecto de dos fuerzas que actúan simultáneamente. Un avión se pueden obtener por condensación (desde unos girar alrededor de la línea de uno de sus extremos).

El efecto subjetivo producido por una línea depende de su orientación: una línea horizontal corresponde con el suelo en el que el hombre se apoya y se mueve, sino que posee una tonalidad afectiva oscura y fría similar a la de color negro o azul. Una línea vertical corresponde con la altura, y no ofrece ningún apoyo, sino que posee una tonalidad luminosa cálida próximo al blanco y amarillo. Una diagonal posee una más o menos caliente o frío tonalidad, de acuerdo con su inclinación hacia la horizontal o la vertical.

Una fuerza que se despliega, sin obstáculos, como la que produce una línea recta se corresponde con lirismo, varias fuerzas que se enfrentan (o molestar) sí forman un drama. El ángulo formado por la línea angular también tiene una sonoridad interior que es cálido y cercano al amarillo para un ángulo agudo (un triángulo), el frío y similar a azul por un ángulo obtuso (un círculo), y similar al rojo por un ángulo recto (un cuadrado).

El plano de base es, en general, rectangular o cuadrada. por lo tanto, que se compone de líneas horizontales y verticales que delimitan y definen como una entidad autónoma que soporta la pintura, comunicando su tonalidad afectiva. Esta tonalidad se determina por la importancia relativa de las líneas horizontales y verticales: las horizontales que dan una tonalidad calma, frío al plano de base, mientras que las verticales impartir una tonalidad calma, cálido. El artista intuye el efecto interior del formato de lienzo y dimensiones, que él elige de acuerdo a la tonalidad que quiere dar a su obra. Kandinski considera el plano básico de un ser vivo, que el artista "fecunda" y se siente "respirar".

Cada parte del plano básico posee una coloración afectiva, lo que influye en la tonalidad de los elementos pictóricos que redactará en él, y contribuye a la riqueza de la composición resultante de la yuxtaposición en el lienzo. Lo anterior del plano básico se corresponde con soltura y ligereza que, mientras que la continuación evoca la condensación y la pesadez. El trabajo del pintor es escuchar y conocer estos efectos para producir pinturas que no son solo el resultado de un proceso al azar, sino el fruto del trabajo auténtico y el resultado de un esfuerzo hacia la belleza interior.



</doc>
<doc id="4586" url="https://es.wikipedia.org/wiki?curid=4586" title="Enlace">
Enlace

Enlace puede referirse a:






</doc>
<doc id="4589" url="https://es.wikipedia.org/wiki?curid=4589" title="Genealogía">
Genealogía

Genealogía (del latín "genealogia", "genos" , ': raza, nacimiento, generación, descendencia + "logos" , ': ciencia, estudio) también conocida como historia familiar, es el estudio y seguimiento de la ascendencia y descendencia de una persona o familia. También se llama así al documento que registra dicho estudio expresado como árbol genealógico. La genealogía es una de las Ciencias Auxiliares de la Historia y es trabajada por un genealogista. El objetivo principal en genealogía es identificar todos los ascendientes y descendientes en un particular árbol genealógico y recoger datos personales sobre ellos. Como mínimo, estos datos incluyen el nombre de la persona y la fecha y/o lugar de nacimiento, matrimonio y muerte. 

Lo primero al iniciar una investigación genealógica es recopilar la mayor cantidad de antecedentes a través de dos fuentes: orales y documentales. Estos antecedentes deben comprender nombres de personas, lugares y fechas. En caso que se desconozca la fecha exacta, se puede utilizar una aproximación.

Las fuentes orales son aquellas que se obtienen verbalmente de otra persona, generalmente dentro del núcleo familiar, padres, abuelos, tíos, primos, bisabuelos. Estas fuentes, dado que están nutridas de la tradición familiar, suelen ser inexactas en cuanto a fechas de nacimiento, bautizos, matrimonios y defunciones, profesiones y lugares de origen. Sin embargo, ofrecen un acervo de información que muchas veces no se encuentra documentada, además de permitir determinar el marco general familiar como punto de partida del trabajo posterior.

Lo mejor es consultar con aquellos miembros de mayor edad dentro de la familia extendida, cualquier antecedente por insignificante que parezca puede llegar a servir. Si también vive dentro de una comunidad pequeña, se debe consultar con las personas de mayor edad que vivan en ella o en sus inmediaciones.

Existen datos que pueden obtenerse exclusivamente de fuentes orales, bien sea por no existir documentación, por ejemplo el padre de un hijo natural no reconocido, o bien porque haya sido destruido el documento durante catástrofes naturales, accidentes o guerras, por lo que siempre es recomendable validar la información con personas y autores coetáneos, sin que ello implique despreciar la fuente primaria oral.

Es recomendable sistematizar siempre la información obtenida, creando fichas personales para cada persona que se está investigando, y dejando siempre bien definido quién fue la persona que informó de dichos datos. Estas fichas pueden tener un formato tanto físico como electrónico, utilizándose, generalmente, en este último caso programas o softwares genealógicos de tipo comercial (software propietario) o libres, algunos de ellos de gran calidad.

Las fuentes documentales son aquellas que se pueden encontrar en cualquier medio escrito (sea impreso o manuscrito). Quienes investigan una genealogía acuden a éstas una vez que han agotado todos los recursos que la memoria intrafamiliar pueda dar, tanto para corroborar la información verbal, como para ampliar la información y retroceder la búsqueda en el tiempo.
Son los documentos escritos que se hallan en posesión de una familia o comunidad y son traspasados de una generación a otra. Estos documentos generalmente son inéditos y son copias únicas de valiosa información y en sí constituyen un archivo. El contenido de estos archivos va desde cartas personales hasta documentos legales, como copias de expedientes, títulos de dominio, libretas de familia, etc. En algunos casos estos archivos, por estar en poder de particulares, no son custodiados bajo estándares bibliotecológicos que permitan su conservación en el tiempo, sea por manipulación o por almacenamiento. Por estas razones sus propietarios en algunos casos donan estos documentos a alguna institución seria, como los archivos nacionales, para evitar su destrucción o pérdida, mientras que en otros casos son tan ocultados que sólo se conocen hasta que muere el dueño de ellos y en la mayoría de las veces se encuentran en un estado de deterioro casi total.

Dependiendo del país se podrán rastrear antecedentes en las oficinas del Registro Civil hasta aproximadamente 1871 (si bien en Francia existen desde la época de la Revolución francesa, y en muchos lugares de España hay registros locales en los respectivos ayuntamientos, algunos desde los años 40 del siglo XIX). Los datos que manejan los registros civiles son nacimientos, defunciones, matrimonios, divorcios, condenas judiciales, nacionalizaciones.

Si se desea consultar por personas en fechas anteriores a la creación de los registros civiles, es aconsejable acudir a las parroquias que correspondan al domicilio de las personas investigadas. En ellas se encuentran libros de bautismos, defunciones y matrimonios. Todas las Parroquias creadas desde el siglo XVI en adelante tienen la obligación de llevar estos libros. 

En 1563 el Concilio de Trento instauró de forma oficial la obligación de registrar en los libros parroquiales las actas de bautismo, boda y defunción. A partir de ese momento los libros sacramentales registran los hechos vitales de cada individuo bautizado en la fe cristiana. De este modo, los registros parroquiales conservan una parte fundamental de la memoria histórica de algunos países, principalmente los colonizados por españoles, cuyo legado fue la enseñanza de la religión católica. Estos registros poblacionales eran realizados por el corregidor o máxima autoridad del recinto y luego eran entregados a un representante de la parroquia. Antes de 1563, no era obligación llevar registros, por lo que a veces la búsqueda de ancestros se detiene en esta fecha. Sin embargo, existen algunas parroquias donde es posible encontrar libros desde el siglo XIII en adelante. 

Hay que tener en cuenta que, en muchos países, la información contenida en los libros parroquiales es traspasada periódicamente a los Archivos Diocesanos, situados normalmente en la sede del obispado al que pertenece la parroquia. Esto es importante, porque muchas veces en la parroquias se han perdido por diversas razones (incendios, guerras, robos, mala conservación) los libros originales. Sin embargo, existe una copia de las inscripciones en los archivos diocesanos. Por otra parte, la La Iglesia de Jesucristo de los Santos de los Últimos Días o iglesia mormona ha hecho convenios con algunos obispados para microfilmar tanto los archivos diocesanos como los libros parroquiales, estando en algunos casos esta información disponible por internet en su base de datos. No obstante, en el caso de los microfilmes que no han sido digitalizados, esta información aparece incompleta, ya que no figuran nombres de testigos o padrinos, y a veces los nombres de las personas han sido mal transcritos, resultando imposible encontrarlos en su buscador, razón por la cual en algunos casos se debe consultar directamente estos registros en sus centros de documentación.

Otras fuentes importantes de datos son los Archivos notariales, que guardan información y documentos emanados por las actuales notarías y las antiguas escribanías, en los cuales se pueden hallar testamentos, cartas de dote, transacciones comerciales, ventas, arriendos, etc. y en general todos aquellos documentos suscritos entre particulares.

En casi todos los países existe un Fondo de Documentos Históricos o Archivo Histórico en el que se depositan cada cierta cantidad de años los documentos que generan los diversos organismos públicos o estatales durante su gestión, vale decir expedientes judiciales, expedientes militares, hojas de vida de los funcionarios públicos, nóminas de inmigrantes, censos, etc. También en estos archivos se reciben las donaciones de documentos de particulares, que pueden contener cartas, nóminas de empleados y una serie de documentos inéditos.

Muchos antecedentes que conciernen a los países hipanoamericanos se encuentran en el Archivo General de Indias, organismo que recibió la documentación generada por las colonias españolas hasta su independencia.

En países más descentralizados, como México y España, los estados o comunidades mantienen sus propios archivos donde se suelen encontrar archivos notariales y documentos relacionados con temas de tierras y aguas. 

También existen corporaciones, fundaciones y universidades privadas y estatales que han hecho grandes esfuerzos por digitalizar muchos documentos históricos. Dentro de estas últimas cabe señalar a La Iglesia de Jesucristo de los Santos de los Últimos Días que ha digitalizado mucha información de organismos públicos que no está disponible en los archivos estatales, como censos de población y registros civiles, que puede ser consultada sin costo en su sitio web.

Asimismo es aconsejable consultar las publicaciones que realizan periódicamente los institutos, asociaciones y academias de genealogía, historia y geografía de cada país donde se está realizando la investigación: siempre cabe la posibilidad de que ya se haya hecho un estudio sobre la familia o apellido que se desea investigar. Además algunas universidades y fundaciones mantienen guías de fuentes documentales.

Hay que destacar la existencia de listas de correo, en las cuales se suele encontrar la colaboración desinteresada de otras personas que realizan su propio árbol genealógico.

Estas listas son generalmente monográficas por ámbitos geográficos, aunque existen igualmente algunas dedicadas a algún apellido concreto.

Actualmente existen varias iniciativas para incorporar dentro de los proyectos de la Wikimedia Foundation. Todas ellas cumplen con la condición de ser gratuitas y de acceso libre para añadir, consultar y editar registros o fichas genealógicas y utilizan softwares del tipo "open-source" MediaWiki - del mismo tipo que se usa en otros proyectos de WikiMedia Foundation.

Listas de genealogía por tipo de licencia








</doc>
<doc id="4594" url="https://es.wikipedia.org/wiki?curid=4594" title="Francisco Nieva">
Francisco Nieva

Francisco Nieva (Valdepeñas, Ciudad Real, 29 de diciembre de 1924-Madrid, 10 de noviembre de 2016) fue un dramaturgo, escenógrafo, director de escena, narrador, ensayista y dibujante español.

Académico de la Real Academia Española desde 1990, donde ocupó el , su producción teatral le valió el Premio Nacional de Teatro en dos ocasiones (1980 y 1992), el Premio Nacional de Literatura en la modalidad de Literatura Dramática y el Premio Valle-Inclán (2011), por la escritura y dirección de "Tórtolas, crepúsculo y... telón". Por su producción literaria en general, se le otorgó el Premio Príncipe de Asturias de las Letras en 1992.

El propio Francisco Nieva escribió un volumen de memorias titulado "Las cosas como fueron" (2002). Su familia descendía de conversos ricos emigrados a España en el siglo XVII y fue bisnieto del helenista y sacerdote Ciriaco Cruz. El padre, el oficial del Ayuntamiento de Valdepeñas Francisco Morales, fue gobernador civil de Toledo con la República en 1931, y allí se trasladaron a vivir hasta que estalló la guerra en 1936. Un tío, Cirilo del Río, fue ministro también durante los años de la República y el abuelo paterno fue durante muchos años Presidente de la Diputación Provincial. 

Sus padres amaban la cultura y el arte y llevaban a sus hijos al teatro, al cine y a la zarzuela. El abuelo materno era aficionado a la ópera y a la lectura y la abuela tocaba con gran destreza el piano. El hermano de Francisco, Ignacio, llegó a ser un notable compositor; en cuanto a él, se vio atraído por el arte muy tempranamente, en especial por el teatro, y se entretenía con escenografías, títeres y muñecos de cartón. La Guerra Civil les pilló en Valdepeñas y durante 1939 vivieron aislados en una casa de Sierra Morena; de vuelta a su lugar natal recibió clases particulares de Juan Alcaide, un poeta relacionado con el "Postismo" y amigo de Carlos Edmundo de Ory, y con él lee obras clásicas y modernas españolas y europeas ("La Celestina", José Gutiérrez Solana, Alfred Jarry). Su familia decidió emigrar a Madrid en 1945, donde Nieva estudió pintura en la Real Academia de Bellas Artes de San Fernando y se hizo amigo de Eduardo Chicharro Briones y Ory, líderes "postistas", intentando abrirse paso como autor plástico dentro de ese movimiento de vanguardia de posguerra, que contaba en sus filas con otros representantes manchegos como Ángel Crespo. Mientras su hermano compositor se hacía pastor evangélico y emigraba a Estados Unidos y Puerto Rico, él residió entre 1953 y 1963 en París, donde asistió al estreno de "Esperando a Godot" de Samuel Beckett, disfrutando de una beca concedida en 1953 por el doctor Piterbag, un judío argentino del Instituto Francés de París, y allí trabajó como pintor y dibujante, en medio de un ambiente sumamente bohemio. En el entorno del fallecido Antonin Artaud, esboza su obra "El combate de Ópalos y Tasia" y recibe el premio Polignac por el conjunto de su obra artística (1963). En París se casa por el rito protestante con Geneviève Escande, que ocupa un alto cargo en el Centre National de la Recherche Scientifique, conoce al editor de los surrealistas José Corti y alterna con conocidos hispanistas franceses, publicando estudios pioneros sobre la influencia de Miguel de Cervantes en el teatro de García Lorca y la plástica en la obra de Valle-Inclán. Tras residir un año en Venecia, regresó a Madrid en 1964 y, salvo largas estancias en Berlín y Roma, permaneció afincado en esta ciudad, entregado a su trabajo como escenógrafo, autor dramático y colaborador de diversas publicaciones periódicas.

Como escenógrafo su labor empezó de la mano de José Luis Alonso Mañés, con quien colaboró realizando los escenarios de "El rey se muere" de Ionesco para el teatro María Guerrero. Trabajó después con Adolfo Marsillach en las escenografías de "Pigmalión" de George Bernard Shaw y "Después de la caída" de Arthur Miller. Estos trabajos lo transformaron en una figura de referencia en su campo, y a lo largo de los años sesenta se ocupó de "La dama duende" de Pedro Calderón de la Barca, "El zapato de raso" de Paul Claudel, "El burlador de Sevilla" de Tirso de Molina, "El señor Adrián" de Carlos Arniches y, por supuesto, "Marat-Sade" de Peter Weiss, de nuevo bajo la dirección de Adolfo Marsillach y Antonio Malonda.

Sin embargo, se mantuvo inedito como escritor teatral hasta que publicó en "Primer Acto" y representó privadamente "Es bueno no tener cabeza" en 1971. Sus ideas teatrales se expresaron en el texto conocido como "Breve poética teatral" en torno a los conceptos de "transgresión", "contravalor" y "culpa"; pretende exhibir escénicamente lo prohibido como si fuera lo más anodino, convencional y corriente en lo público ("contravalor") en busca de una liberación (catarsis) total. Esta poética bebe fundamentalmente del Artaud que conoció en París, pero también de Alfred Jarry, Ghelderode, Eugène Ionesco, Samuel Beckett y Jean Genet; lo original de Nieva es insertar conscientemente esta vanguardia en la tradición literaria española de lo grotesco y lo esperpéntico, otorgando a lo cómico un papel fundamental en lograr dicha inversión, prosiguiendo la tradición de Cervantes, Quevedo, José Gutiérrez Solana y Valle-Inclán.

Aunque clasificó su teatro inicialmente en "Teatro furioso", "Teatro de farsa y calamidad" y "Teatro de crónica y estampa", la publicación de su "Teatro completo" en 1991 le hizo distinguir otros grupos:


Esta clasificación se modificó en la edición de sus "Obras completas" (2007), donde distingue seis grupos: "Centón de teatro", "Teatro Furioso", "Teatro de Farsa y Calamidad", "Teatro de crónica y estampa", "Tres versiones libres" y "Varia teatral".

A todas estas obras hay que añadir sus adaptaciones de clásicos; fuera de la ya citada de Larra, están "La paz" de Aristófanes, "Los baños de Argel" de Cervantes, "Casandra" de Galdós, "Las aventuras de Tirante el Blanco" de Joanot Martorell, "El manuscrito encontrado en Zaragoza" de Jan Potocki, "Divinas palabras" de Valle-Inclán adaptada a la ópera con música de Antón García-Abril, "Don Álvaro o la fuerza del sino", del Duque de Rivas, "El desdén con el desdén", de Agustín Moreto y "Electra", de Benito Pérez Galdós.

Como director de escena montó óperas, zarzuelas y ballets como "Cinderella" de Sergei Prokofiev, "Capricho español" de Enrique Granados, "La vida breve" de Manuel de Falla, "L'heure espagnole" de Maurice Ravel, "Pepita Jiménez" de Isaac Albéniz, "Tosca" de Giacomo Puccini, "Curro Vargas" de Ruperto Chapí, "I due Foscari" de Giuseppe Verdi, "Don Giovanni" de Mozart y "La señorita Cristina" de Luis de Pablo.

Su última vertiente fue la de novelista: escribió "El viaje a Pantaélica" (1994), "La llama vestida de negro" (1995), "Granada de las mil noches" (1995), "Oceánida" (1996), "Carne de murciélago. Cuento de Madrid" (1998)...

Colaborador habitual del diario "La Razón", de Madrid, en 1990 ingresó en la Real Academia de la Lengua Española con un discurso titulado "Esencia y paradigma del género chico".

Ya desde 1949 había escrito teatro, pero solo empezó a estrenarlo y publicarlo a partir de 1971.

La obra dramática de Francisco Nieva puede dividirse en dos grandes grupos, llamados por el autor "Teatro furioso" y "Teatro de farsa y calamidad". Un modelo más imaginativo y vitalista que el teatro popular desarrollado de la posguerra española, con un lenguaje ‘valleinclanesco’ y una escenografía barroca.

Su obra narrativa es una prolongación de ese particular universo, con ejemplos como "El viaje a Pantaélica", "Oceánida" y "La llama vestida de negro: novela de misterios y sobrecogimiento" (1995), una especie de ciclo narrativo protagonizado por el caballero gallego Cambicio de Santiago, que se prolonga con "Granada de las mil noches" y "La mutación del primo mentiroso" (I Premio de Novela Ducado de Loeches en 2004).

Aunque ya existía una edición de su "Teatro completo" de 1991 en dos volúmenes, la "Obra completa" publicada en 2007 modifica bastante los textos, recopilando en dos tomos de unas 2500 páginas cada uno toda su producción. El primero está dedicado a su Teatro y el segundo recoge toda la Narrativa y una selección de artículos.









</doc>
<doc id="4595" url="https://es.wikipedia.org/wiki?curid=4595" title="La Fura dels Baus">
La Fura dels Baus

La Fura dels Baus es una compañía de teatro española creada en 1979 por Marcel·lí Antúnez Roca, Carlus Padrissa, Pere Tantinyà, Quico Palomar y Teresa Puig. Autodefinidos como un grupo de teatro «de fricción» que busca un espacio escénico distinto del tradicional, sus montajes y productos diversos han evolucionado mezclando imaginación, morbosidad, performance, mecatrónica e instalaciones de gran espectacularidad, en un contexto dramático de creación colectiva.

En la actualidad, la compañía funciona como una empresa artística de grandes espectáculos, que integra diversos registros del teatro de texto, el teatro digital, la ópera y el género cinematográfico. Su equipo está integrado por cientos de personas, incluyendo actores, atletas, funambulistas, técnicos, diseñadores, gestores y colaboradores, entre otros. Entre los miembros más reconocidos que han pasado por la compañía se encuentran, además de los mismos fundadores, Àlex Ollé, Miki Espuma, Jürgen Müller, Pep Gatell, Jordi Arús, Hansel Cereza y Michael Summers, Quico Palomar, Teresa Puig y Mireia Romero. Entre los colaboradores más cercanos, figura el actor Eduard Fernández, ganador de un Goya por su interpretación en "Fausto 5.0".

Su vasta trayectoria suma a la fecha cerca de tres mil representaciones y alrededor de tres millones de espectadores.

El nombre de la compañía, intraducible, hace alusión a un hurón («fura» en catalán) supuestamente endémico de una zona conocida como "Els Balçans" o "Els Baus", un torrente que cruza la localidad de Moyá, más tarde convertido en vertedero.

La Fura dels Baus, se inició como grupo de teatro de calle en la localidad catalana de Moyá a fines de los años 1970, haciendo pasacalles y participando en fiestas y «entoldados». En 1979, los directores de entonces, Marcel·lí Antúnez Roca, Carlus Padrissa y Pere Tantinyà, abandonaron su pueblo de origen para trasladarse a Barcelona.

Allí el grupo comenzó a integrar herramientas del teatro independiente, para luego desarrollar un estilo más personal, en el que se inscribe la mayoría de sus montajes del primer periodo, entre 1979 y 1990. Antúnez Roca abandonó el colectivo a fines de este periodo.

La compañía saltó a la fama durante los años 1990, luego de su participación en la ceremonia de apertura de los Juegos Olímpicos de Barcelona 1992, como compañía de teatro experimental, junto a la compañía Comediants, de teatro más tradicional, y a distinguidos músicos internacionales, tales como Ryūichi Sakamoto. A este evento le siguieron millonarias contrataciones para promocionar reconocidas marcas comerciales, como Pepsi, Mercedes-Benz, Peugeot, Volkswagen, Swatch, Airtel, Microsoft, Absolut Vodka, Columbia Pictures, Warner Bros., Puerto de Barcelona, Telecom Italia o Sun Microsystems, así como la contratación para la realización de masivas participaciones en eventos tales como los Juegos Mediterráneos de 2005, en Almería; el SummerTyne 2007, en Newcastle; o el Perth International Arts Festival 2010, en Perth.
Desde 1996 la compañía también se inició en la realización de óperas, con "Atlántida", de Manuel de Falla y Ernesto Halffter. A esta ópera le siguieron varias otras, entre ellas "El martirio de San Sebastián" de Claude Debussy, al año siguiente; "La condenación de Fausto", de Hector Berlioz, para el Festival de Salzburgo en 1999, o "La fábula de Orfeo", de Claudio Monteverdi, realizado en las bodegas de su barco «Naumon» en el Puerto Viejo de Barcelona por el 400 aniversario de su estreno en 1607, en la ciudad italiana de Mantua.

En cuanto a otros formatos, la compañía realizó en 1997 "Work in progress", un espectáculo de teatro digital donde a través de Internet se conectaban escenas que ocurrían simultáneamente en diversas ciudades. En 2001 también se adentraron en la industria cinematográfica, con la película "Fausto 5.0", en colaboración con el director Isidro Ortiz.

La compañía también ha realizado giras por América Latina. En 2011 abrió el Bicentenario de Uruguay, y más tarde realizó funciones en espacios como el Teatro Colón de Buenos Aires (2012) y el Teatro Municipal de Santiago de Chile.

Los trabajos de la compañía buscan estimular la imaginación y también provocar al espectador, a través de elementos de morbosidad, performance, mecatrónica e instalaciones de gran espectacularidad.

En sus creaciones más personales utilizan lo que ellos mismos denominan el «lenguaje furero», esto es, el uso de procesos de creación colectiva a partir de ejercicios de desinhibición actorales, que dan lugar a espectáculos en espacios no convencionales, donde los actores interactúan con el público, la música, el movimiento y una escenografía que recurre a diversos materiales orgánicos, industriales y tecnológicos.

El estilo de sus trabajos no ha estado exento de controversias. Algunos críticos han reprochado su cierta incapacidad para despertar sentimientos positivos que vayan más allá de las sensaciones elementales que genera la espectacularidad. Pese a lo anterior, la compañía ha presentado montajes como "Ascenso y caída de la ciudad de Mahagonny", que han generado una destacada recepción del público.

A continuación de incluye una selección de sus diversos trabajos.





</doc>
<doc id="4596" url="https://es.wikipedia.org/wiki?curid=4596" title="Física estadística">
Física estadística

La física estadística o mecánica estadística es una rama de la física que mediante la teoría de la probabilidad es capaz de deducir el comportamiento de los sistemas físicos macroscópicos constituidos por una cantidad estadísticamente significativa de componentes equivalentes a partir de ciertas hipótesis sobre los elementos o "partículas" que los conforman y sus interacciones mutuas.

Los sistemas macroscópicos son aquellos que tienen un número de partículas cercano a la constante de Avogadro, cuyo valor, de aproximadamente formula_1, es increíblemente grande, por lo que el tamaño de dichos sistemas suele ser inconcebible por el ser humano, aunque el tamaño de cada partícula constituyente sea de escala atómica. Un ejemplo de un sistema macroscópico sería, por ejemplo, un vaso de agua.

La importancia del uso de las técnicas estadísticas para estudiar estos sistemas radica en que, al tratarse de sistemas tan grandes es imposible, incluso para las más avanzadas computadoras, llevar un registro del estado físico de cada partícula y predecir el comportamiento del sistema mediante las leyes de la mecánica, además del hecho de que resulta impracticable el conocer tanta información de un sistema real.

La utilidad de la física estadística consiste en ligar el comportamiento microscópico de los sistemas con su comportamiento macroscópico o colectivo, de modo que, conociendo el comportamiento de uno, pueden averiguarse detalles del comportamiento del otro. Permite describir numerosos campos de naturaleza estocástica como las reacciones nucleares; los sistemas biológicos, químicos, neurológicos, entre otros.

Empíricamente, la termodinámica ha estudiado los gases y ha establecido su comportamiento macroscópico con alto grado de acierto. Gracias a la física estadística es posible deducir las leyes termodinámicas que rigen el comportamiento macroscópico de un gas, como la ecuación de estado del gas ideal o la ley de Boyle-Mariotte, a partir de la suposición de que las partículas en el gas no están sometidas a ningún potencial y se mueven libremente con una energía cinética igual a:

colisionando entre sí y con las paredes del recipiente de forma elástica (sin fuerzas disipativas). El comportamiento colectivo del gas depende de tan sólo unas pocas variables macroscópicas (como la presión, el volumen y la temperatura). Este enfoque particular para estudiar el comportamiento de los gases se llama teoría cinética.

Para predecir el comportamiento de un gas, la mecánica exigiría calcular la trayectoria exacta de cada una de las partículas que lo componen (lo cual es un problema inabordable). La termodinámica hace algo radicalmente opuesto, establece unos principios cualitativamente diferentes a los mecánicos para estudiar una serie de propiedades macroscópicas sin preguntarse en absoluto por la naturaleza "real" de la materia de estudio. La mecánica estadística media entre ambas aproximaciones: ignora los comportamientos individuales de las partículas, preocupándose en vez de ello por promedios. De esta forma podemos calcular las propiedades termodinámicas de un gas a partir de nuestro conocimiento genérico de las moléculas que lo componen aplicando leyes mecánicas.

En el siglo XVIII Daniel Bernoulli aplica razonamientos estadísticos para explicar el comportamiento de sistemas de fluidos.

Los años cincuenta del siglo XIX marcaron un hito en el estudio de los sistemas térmicos. Por esos años la termodinámica, que había crecido básicamente mediante el estudio experimental del comportamiento macroscópico de los sistemas físicos a partir de los trabajos de Nicolas Léonard Sadi Carnot, James Prescott Joule, Clausius y Kelvin, era una disciplina estable de la física. Las conclusiones teóricas deducidas de las primeras dos leyes de la termodinámica coincidían con los resultados experimentales. Al mismo tiempo, la teoría cinética de los gases, que se había basado más en la especulación que en los cálculos, comenzó a emerger como una teoría matemática real. Sin embargo, fue hasta que Ludwig Boltzmann en 1872 desarrolló su teorema H y de este modo estableciera el enlace directo entre la entropía y la dinámica molecular. Prácticamente al mismo tiempo, la teoría cinética comenzó a dar a luz a su sofisticado sucesor: la teoría del ensamble.

El poder de las técnicas que finalmente emergieron redujo la categoría de la termodinámica de "esencial" a ser una consecuencia de tratar estadísticamente un gran número de partículas que actuaban bajo las leyes de la mecánica clásica. Fue natural, por tanto, que esta nueva disciplina terminara por denominarse mecánica estadística o física estadística.

La mecánica estadística puede construirse sobre las leyes de la mecánica clásica o la mecánica cuántica, según sea la naturaleza del problema a estudiar. Aunque, a decir verdad, las técnicas de la mecánica estadística pueden aplicarse a campos ajenos a la propia física, como por ejemplo en economía. Así, se ha usado la física estadística para deducir la "distribución de la renta", y la distribución de Pareto para las rentas altas puede deducirse mediante la mecánica estadística, suponiendo un estado de equilibrio estacionario para las mismas (ver econofísica).

La relación entre estados microscópicos y macroscópicos (es decir, la termodinámica) viene dada por la famosa fórmula de Ludwig Boltzmann de la entropía:

donde formula_4 es el número de estados microscópicos compatibles con una energía, volumen y número de partículas dado y formula_5 es la constante de Boltzmann.

En el término de la izquierda tenemos la termodinámica mediante la entropía definida en función de sus variables naturales, lo que da una información termodinámica completa del sistema. A la derecha tenemos las configuraciones microscópicas que definen la entropía mediante esta fórmula. Estas configuraciones se obtienen teniendo en cuenta el modelo que hagamos del sistema "real" a través de su hamiltoniano mecánico.

Esta relación, propuesta por Ludwig Boltzmann, no la aceptó inicialmente la comunidad científica, en parte debido a que contiene implícita la existencia de átomos, que no estaba demostrada hasta entonces. Esa respuesta del medio científico, dicen, hizo que Boltzmann, desahuciado, decidiera quitarse la vida.

Actualmente esta expresión no es la más apropiada para realizar cálculos reales. Ésta es la llamada ecuación puente en el Colectivo Micro Canónico. Existen otros colectivos, como el Colectivo Canónico o el Colectividad macrocanónica, que son de más interés práctico.

El postulado fundamental de la mecánica estadística, conocido también como "postulado de equiprobabilidad a priori", es el siguiente:

Este postulado fundamental es crucial para la mecánica estadística, y afirma que un sistema en equilibrio no tiene ninguna preferencia por ninguno de los microestados disponibles para ese equilibrio. Si Ω es el número de microestados disponibles para una cierta energía, entonces la probabilidad de encontrar el sistema en uno cualquiera de esos microestados es "p" = 1/Ω.

El postulado es necesario para poder afirmar que, dado un sistema en equilibrio, el estado termodinámico (macroestado) que está asociado a un mayor número de microestados es el macroestado más probable del sistema. Puede ligarse a la función de teoría de la información, dada por:

Cuando todas las rho son iguales, la función de información "I" alcanza un mínimo. Así, en el macroestado más probable además es siempre uno para el que existe una mínima información sobre el microestado del sistema. De eso se desprende que en un sistema aislado en equilibrio la entropía sea máxima (la entropía puede considerarse como una medida de desorden: a mayor desorden, mayor desinformación y, por tanto, un menor valor de "I").

En todos los libros de termodinámica se interpreta la entropía como una medida del desorden del sistema. De hecho, a veces se enuncia el segundo principio de la termodinámica diciendo: "El desorden de un sistema aislado sólo aumenta".

Es importante saber que esta relación viene, como acabamos de saber, de la mecánica estadística. La termodinámica no es capaz de establecer esta relación por sí misma, pues no se preocupa en absoluto por los estados microscópicos. En este sentido, la mecánica estadística es capaz de "demostrar" la termodinámica, ya que, partiendo de unos principios más elementales (a saber, los mecánicos), obtiene por deducción estadística el segundo principio. Fue ésa la gran contribución matemática de Ludwig Boltzmann a la termodinámica.

La formulación moderna de esta teoría se basa en la descripción del sistema físico por un elenco de conjuntos o colectividad que representa la totalidad de configuraciones posibles y las probabilidades de realización de cada una de las configuraciones.

A cada colectividad se le asocia una función de partición que, por manipulaciones matemáticas, permite extraer los valores termodinámicos del sistema. Según la relación del sistema con el resto del Universo, se distinguen generalmente tres tipos de colectividades, en orden creciente de complejidad:

<noinclude>



</doc>
<doc id="4598" url="https://es.wikipedia.org/wiki?curid=4598" title="Relatividad general">
Relatividad general

"Algunas partes de este artículo pueden resultar complicadas, en ese caso se recomienda Introducción a la relatividad general."
La teoría general de la relatividad o relatividad general es una teoría del campo gravitatorio y de los sistemas de referencia generales, publicada por Albert Einstein en 1915 y 1916.

El nombre de la teoría se debe a que generaliza la llamada teoría especial de la relatividad. Los principios fundamentales introducidos en esta generalización son el principio de equivalencia, que describe la aceleración y la gravedad como aspectos distintos de la misma realidad, la noción de la curvatura del espacio-tiempo y el principio de covariancia generalizado. 

La intuición básica de Einstein fue postular que en un punto concreto no se puede distinguir experimentalmente entre un cuerpo acelerado uniformemente y un campo gravitatorio uniforme. La teoría general de la relatividad permitió también reformular el campo de la cosmología.

Poco después de la formulación de la teoría de la relatividad especial en 1905, Albert Einstein comenzó a elucubrar cómo describir los fenómenos gravitatorios con ayuda de la nueva mecánica. En 1907 se embarcó en la búsqueda de una nueva teoría relativista de la gravedad que duraría ocho años. Después de numerosos desvíos y falsos comienzos, su trabajo culminó en noviembre de 1915 con la presentación a la Academia Prusiana de las Ciencias de su artículo, que contenía las que hoy son conocidas como "Ecuaciones de Campo de Einstein". Estas ecuaciones forman el núcleo de la teoría y especifican cómo la densidad local de materia y energía determina la geometría del espacio-tiempo. 

Las ecuaciones de campo de Einstein son no lineales y muy difíciles de resolver. Einstein utilizó los métodos de aproximación en la elaboración de las predicciones iniciales de la teoría. Pero ya en 1916, el astrofísico Karl Schwarzschild encontró la primera solución exacta no trivial de las Ecuaciones de Campo de Einstein, la llamada Métrica de Schwarzschild. Esta solución sentó las bases para la descripción de las etapas finales de un colapso gravitacional, y los objetos que hoy conocemos como agujeros negros. En el mismo año, se iniciaron los primeros pasos hacia la generalización de la solución de Schwarzschild a los objetos con carga eléctrica, obteniéndose así la solución de Reissner-Nordström, ahora asociada con la carga eléctrica de los agujeros negros.

En 1917, Einstein aplicó su teoría al universo en su conjunto, iniciando el campo de la cosmología relativista. En línea con el pensamiento contemporáneo, en el que se suponía que el universo era estático, agregó a sus ecuaciones una constante cosmológica para reproducir esa "observación". En 1929, sin embargo, el trabajo de Hubble y otros demostraron que nuestro universo se está expandiendo. Esto es fácilmente descrito por las soluciones encontradas por Friedmann en 1922 para la expansión cosmológica, que no requieren de una constante cosmológica. Lemaître utilizó estas soluciones para formular la primera versión de los modelos del Big Bang, en la que nuestro universo ha evolucionado desde un estado anterior extremadamente caliente y denso. Einstein declaró más tarde que agregar esa constante cosmológica a sus ecuaciones fue el mayor error de su vida. 

Durante ese período, la relatividad general se mantuvo como una especie de curiosidad entre las teorías físicas. Fue claramente superior a la gravedad newtoniana, siendo consistente con la relatividad especial y contestaba varios efectos no explicados por la teoría newtoniana. El mismo Einstein había demostrado en 1915 cómo su teoría lograba explicar el avance del perihelio anómalo del planeta Mercurio sin ningún parámetro arbitrario. Del mismo modo, en una expedición de 1919 liderada por Eddington confirmaron la predicción de la relatividad general para la desviación de la luz estelar por el Sol durante el eclipse total de Sol del 29 de mayo de 1919, haciendo famoso a Einstein instantáneamente. Sin embargo, esta teoría ha entrado en la corriente de la física teórica y la astrofísica desarrolladas aproximadamente entre 1960 y 1975, ahora conocido como la edad de oro de la relatividad general. Los físicos empezaron a comprender el concepto de agujero negro, y a identificar la manifestación de objetos astrofísicos como los cuásares. Cada vez más precisas, las pruebas del sistema solar confirmaron el poder predictivo de la teoría, y la cosmología relativista, también se volvió susceptible a encaminar pruebas observacionales.

Los éxitos explicativos de la teoría de la relatividad especial condujeron a la aceptación de la teoría prácticamente por la totalidad de los físicos. Eso llevó a que antes de la formulación de la relatividad general existieran dos teorías físicas incompatibles:

La necesidad de buscar una teoría que integrase, como casos límites particulares, las dos anteriores requería la búsqueda de una teoría de la gravedad que fuese compatible con los nuevos principios relativistas introducidos por Einstein. Además de incluir la gravitación en una teoría de formulación covariante, hubo otra razón adicional. Einstein había concebido la teoría especial de la relatividad como una teoría aplicable sólo a sistemas de referencia inerciales, aunque realmente puede generalizarse a sistemas acelerados sin necesidad de introducir todo el aparato de la relatividad general. La insatisfacción de Einstein con su creencia de que la teoría era aplicable sólo a sistemas inerciales le llevó a buscar una teoría que proporcionara descripciones físicas adecuadas para un sistema de referencia totalmente general.

Esta búsqueda era necesaria, ya que según la relatividad especial "ninguna información puede viajar a mayor velocidad que la luz", y por lo tanto no puede existir relación de causalidad entre dos eventos unidos por un intervalo espacialoide (space-like). Sin embargo, uno de los pilares fundamentales de la gravedad newtoniana, el principio de acción a distancia, supone que las alteraciones producidas en el campo gravitatorio se transmiten instantáneamente a través del espacio. La contradicción entre ambas teorías es evidente, puesto que asumir las tesis de Newton llevaría implícita la posibilidad de que un observador fuera afectado por las perturbaciones gravitatorias producidas fuera de su cono de luz.

Einstein resolvió este problema interpretando los fenómenos gravitatorios como simples alteraciones de la curvatura del espacio-tiempo producidas por la presencia de masas. De ello se deduce que el campo gravitatorio, al igual que el campo electromagnético, tiene una entidad física independiente y sus variaciones se transmiten a una velocidad finita en forma de ondas gravitacionales. La presencia de masa, energía o momentum en una determinada región de la variedad tetradimensional, provoca la alteración de los coeficientes de la métrica, en una forma cuyos detalles pormenorizados analizaremos en las secciones siguientes.

En esta visión, la gravitación sólo sería una pseudo-fuerza (equivalente a la fuerza de Coriolis, o a la fuerza centrífuga) efecto de haber escogido un sistema de referencia no-inercial.

Las características esenciales de la teoría de la relatividad general son las siguientes:

El principio de covariancia es la generalización de la teoría de la relatividad especial, donde se busca que las leyes físicas tengan la misma forma en todos los sistemas de referencia. Esto último equivale a que todos los sistemas de referencia sean indistinguibles, y desde el punto de vista físico equivalentes. En otras palabras, que cualquiera que sea el movimiento de los observadores, las ecuaciones tendrán la misma forma matemática y contendrán los mismos términos. Ésta fue la principal motivación de Einstein para que estudiara y postulara la relatividad general. 

El principio de covariancia sugería que las leyes debían escribirse en términos de tensores, cuyas leyes de transformación covariantes y contravariantes podían proporcionar la "invariancia" de forma buscada, satisfaciéndose el principio físico de covariancia.

 Un hito fundamental en el desarrollo de la teoría de la relatividad general lo constituye el principio de equivalencia, enunciado por Albert Einstein en el año 1912 y al que su autor calificó como «"la idea más feliz de mi vida"». Dicho principio supone que un sistema que se encuentra en caída libre y otro que se mueve en una región del espacio-tiempo sin gravedad se encuentran en un estado físico similar: en ambos casos se trata de sistemas inerciales.

Galileo distinguía entre cuerpos de movimiento inercial (en reposo o moviéndose a velocidad constante) y cuerpos de movimiento no inercial (sometidos a un movimiento acelerado). En virtud de la segunda ley de Newton (que se remonta a los trabajos del dominico español Domingo de Soto), toda aceleración estaba causada por la aplicación de una fuerza exterior. La relación entre fuerza y aceleración se expresaba mediante esta fórmula:

donde "a" es la aceleración, "F" la fuerza y "m" la masa. La fuerza podía ser de origen mecánico, electromagnético o, cómo no, gravitatorio. Según los cálculos de Galileo, la aceleración gravitatoria de los cuerpos era constante y equivalía a 9,8 m/s sobre la superficie terrestre. La fuerza con la que un cuerpo era atraído hacia el centro de la Tierra se denominaba peso. Evidentemente, según los principios de la mecánica clásica un cuerpo en caída libre no es un sistema inercial, puesto que se mueve aceleradamente dentro del campo gravitatorio en que se encuentra.

Sin embargo, la teoría de la relatividad considera que los efectos gravitatorios no son creados por fuerza alguna, sino que encuentran su causa en la curvatura del espacio-tiempo generada por la presencia de materia. Por ello, un cuerpo en caída libre es un sistema (localmente) inercial, ya que no está sometido a ninguna fuerza (porque la gravedad tiene este carácter en relatividad general). Un observador situado en un sistema inercial (como una nave en órbita) no experimenta ninguna aceleración y es incapaz de discernir si está atravesando o no, un campo gravitatorio. Como consecuencia de ello, las leyes de la física se comportan como si no existiera curvatura gravitatoria alguna. De ahí que el principio de equivalencia también reciba el nombre de Invariancia Local de Lorentz: En los sistemas inerciales rigen los principios y axiomas de la relatividad especial.

El principio de equivalencia implica asimismo que los observadores situados en reposo sobre la superficie de la tierra no son sistemas inerciales (experimentan una aceleración de origen gravitatorio de unos 9,8 metros por segundo al cuadrado, es decir, "sienten su peso").

Aunque la mecánica clásica tiene en cuenta la aceleración medida por un observador en reposo respecto al campo gravitatorio (p.e. un astrónomo); el Principio de Equivalencia, contrariamente, toma en consideración la aceleración experimentada por un observador situado en el sistema en cuestión: cualquier cuerpo que se mueva sin restricciones por un campo gravitatorio puede ser considerado como un sistema inercial. Es el caso de los planetas que orbitan en torno del Sol y de los satélites que orbitan alrededor de los primeros: los habitantes de la Tierra no llegan a percibir si nos estamos acercando o alejando del Sol, ni si nos encontramos en el afelio o en el perihelio, a pesar de las enormes diferencias de la gravedad solar.

La gravedad se convierte, en virtud del Principio de Equivalencia, en una fuerza aparente, como la fuerza centrífuga y la fuerza de Coriolis: en estos dos últimos supuestos su aparición es debida a la elección de un marco de referencia acelerado (un observador situado en la superficie de una esfera en rotación). En el caso de la gravedad, únicamente percibimos la "fuerza aparente gravitatoria" cuando escogemos un sistema de referencia no inercial (en reposo sobre la superficie terrestre), pero no cuando nos situamos en otro que sí lo es (un cuerpo en caída libre).

Aunque el principio de equivalencia fue históricamente importante en el desarrollo de la teoría, no es un ingrediente necesario de una teoría de la gravedad, como prueba el hecho de que otras teorías métricas de la gravedad, como la teoría relativista de la gravitación prescindan del principio de equivalencia. Además conviene señalar que el principio de equivalencia no se cumple en presencia de campos electromagnéticos, por ejemplo una partícula cargada moviéndose a lo largo de una geodésica de un espacio-tiempo cualquiera en general emitirá radiación, a diferencia de una partícula cargada moviéndose a lo largo de una geodésica del espacio de Minkowski. Ese y otros hechos sugieren que el principio de equivalencia a pesar de su equivalencia histórica no es parte esencial de una teoría relativista de la gravitación.

La aceptación del principio de equivalencia por Albert Einstein le llevó a un descubrimiento ulterior: la contracción o curvatura del tiempo como consecuencia de la presencia de un campo gravitatorio, que quedó expresado en su artículo de 1911 ""Sobre la influencia de la gravedad en la propagación de la luz"".

Supongamos que un fotón emitido por una estrella cercana se aproxima a la Tierra. En virtud de la ley de conservación del tetramomentum la energía conservada del fotón permanece invariante. Por otro lado, el principio de equivalencia implica que un observador situado en el fotón (que es un sistema inercial, es decir, se halla en caída libre) no experimenta ninguno de los efectos originados por el campo gravitatorio terrestre. De ello se deduce que la energía conservada del fotón no se altera como consecuencia de la acción de la gravedad, y tampoco lo hace la frecuencia de la luz, ya que, según la conocida fórmula de la física cuántica, la energía de un fotón es igual a su frecuencia "v" multiplicada por la constante de Planck "h": "E = hν".

Ahora bien, si las observaciones las realizara un astrónomo situado en la superficie de la Tierra, esto es, en reposo respecto su campo gravitatorio, los resultados serían muy diferentes: el astrónomo podría comprobar cómo el fotón, por efecto de su caída hacia la Tierra, va absorbiendo progresivamente energía potencial gravitatoria y, como consecuencia de esto último, su frecuencia se corre hacia el azul. Los fenómenos de absorción de energía por los fotones en caída libre y corrimiento hacia el azul se expresan matemáticamente mediante las siguientes ecuaciones:
donde formula_4 es la energía medida por un observador en reposo respecto al campo gravitatorio (en este caso un astrónomo), formula_5 el potencial gravitatorio de la región donde se encuentra éste, formula_6 la energía conservada del fotón, formula_7 la frecuencia de emisión, formula_8 es la frecuencia percibida por el observador (y corrida hacia el azul) y formula_9 la constante de Planck.

Ahora bien, en el párrafo anterior hemos demostrado que la energía conservada del fotón permanece invariante. Por tanto, ¿cómo es posible que exista esta divergencia entre los resultados de la medición de la energía obtenidos por el astrónomo (formula_10) y la energía conservada del fotón (formula_11)? La única manera de resolver esta contradicción es considerando que el tiempo se ralentiza como consecuencia de la presencia de un campo gravitatorio. De este modo, la citada ecuación:

puede escribirse de este modo:

\frac{\mbox{ciclos}}{\Delta t_{em}} e^{-\Phi}</math>

Es decir, la frecuencia es igual al número de ciclos que tienen lugar en un determinado período (generalmente, un segundo). Donde formula_12 es el tiempo medido por un observador situado a una distancia infinita del cuerpo masivo (y por lo tanto no experimenta la atracción gravitatoria de éste), mientras que formula_13 es el tiempo medido por un observador bajo la influencia del campo gravitatorio y en reposo respecto a este (como, por ejemplo, una persona situada sobre la superficie terrestre). De ahí se deduce que cerca de un cuerpo masivo el tiempo se ralentiza, siguiendo estas reglas matemáticas:
En una singularidad espacio-temporal (como las que existen en el interior de los agujeros negros), la densidad de masa-materia y el campo gravitatorio tienden al infinito, lo que provoca la congelación del tiempo y por lo tanto la eliminación de todo tipo de procesos dinámicos:

La contracción del tiempo debido a la presencia de un campo gravitatorio fue confirmada experimentalmente en el año 1959 por el experimento Pound-Rebka-Snider, llevado a cabo en la universidad de Harvard. Se colocaron detectores electromagnéticos a una cierta altura y se procedió a emitir radiación desde el suelo. Todas las mediciones que se realizaron confirmaron que los fotones habían experimentado un corrimiento hacia el rojo durante su ascenso a través del campo gravitatorio terrestre.

Hoy en día, el fenómeno de la contracción del tiempo tiene cierta importancia en el marco del servicio localizador GPS, cuyas exigencias de exactitud requieren de una precisión extrema: Basta con que se produzca un retraso de 0.04 microsegundos en la señal para que se produzca un error de posicionamiento de unos 10 metros. De ahí que las ecuaciones de Einstein hayan de ser tenidas en cuenta al calcular la situación exacta de un determinado objeto sobre la superficie terrestre.

Desde un punto de vista teórico, el artículo de Einstein de 1911 tuvo una importancia aún mayor. Pues, la contracción del tiempo conllevaba también, en virtud de los principios de la relatividad especial, la contracción del espacio. De ahí que fuera inevitable a partir de este momento descartar la existencia de un espacio-tiempo llano, y fuera necesario asumir la curvatura de la variedad espacio-temporal como consecuencia de la presencia de masas.

En la relatividad general, fenómenos que la mecánica clásica atribuye a la acción de la fuerza de gravedad, tales como una caída libre, la órbita de un planeta o la trayectoria de una nave espacial, son interpretados como efectos geométricos del movimiento en un espacio-tiempo curvado. De hecho una partícula libre en un campo gravitatorio sigue líneas de curvatura mínima a través de este espacio tiempo-curvado.

Finalmente, podemos hacer referencia a la desviación de los rayos de la luz como consecuencia de la presencia de un cuerpo masivo, fenómeno que da lugar a efectos ópticos como las lentes gravitacionales o los anillos de Einstein.

Frente de onda desviado. Lente gravitacional. Experimento de Eddington.

Matemáticamente, Einstein conjeturó que la geometría del universo deja de ser euclidiana por la presencia de masas. Einstein modelizó que el universo era un tipo de espacio-tiempo curvo mediante una variedad pseudoriemanniana y sus ecuaciones de campo establecen que la curvatura seccional de esta variedad en un punto está relacionada directamente con el tensor de energía-momento en dicho punto.

Dicho tensor es una medida de la densidad de materia y energía. La curvatura "le dice a la materia como moverse", y de forma recíproca la "materia le dice al espacio como curvarse". En términos más precisos las trayectorias de las partículas se ven afectadas por la curvatura, y la presencia de muchas partículas en una región altera notoriamente la curvatura. La relatividad general se distingue de otras teorías alternativas de la gravedad por la simplicidad de acoplamiento entre materia y curvatura. 

Aunque todavía no existe una teoría cuántica de la gravedad que incorpore tanto a la mecánica cuántica como a la teoría de la relatividad general y que proponga una ecuación de campo gravitatorio que sustituya a la de Einstein, pocos físicos dudan que una teoría cuántica de la gravedad pondrá a la relatividad general en el límite apropiado, así como la relatividad general predice la ley de la gravedad en el límite no relativista.

Uno de los conceptos esenciales sobre el que gira toda la teoría de la relatividad general es el de derivada covariante (a veces impropiamente llamada conexión afín), que fue definida por primera vez por el matemático italiano Tullio Levi-Civita y que puede ser considerada tanto desde una perspectiva física como desde otra matemática. 

Desde un punto de vista físico, la derivada ordinaria de la velocidad es la aceleración de un cuerpo medida por un observador externo en reposo respecto a un campo gravitatorio (por ejemplo, un astrónomo situado sobre la superficie terrestre). En este caso el observador se mantiene a una distancia r constante del centro de masas, pero no así el objeto observado, que si consideramos que está en caída libre, progresivamente se irá aproximando al origen del campo gravitatorio, y el observador externo detectará que tiene una aceleración constante g.

Por el contrario, la "derivada covariante de la velocidad" formula_16 ó formula_17 es la aceleración medida por un "observador comóvil", es decir, que está en reposo respecto al cuerpo en caída libre (por ejemplo, el piloto de un avión en caída libre o los tripulantes de una nave espacial con sus motores apagados) y que a diferencia de la derivada ordinaria, no detectará ninguna aceleración, a menos que el piloto encienda los motores o que algún meteorito lo impacte.

En resumidas cuentas, la derivada ordinaria se utiliza para computar la aceleración ordinaria de un cuerpo, mientras que la derivada covariante es empleada para calcular su aceleración inercial. Según la mecánica galileana y newtoniana estos dos tipos de aceleración son idénticos, y sobre la base de este axioma se desarrollaron nuevos principios mecánicos como el Principio de d'Alembert. Sin embargo, del principio de equivalencia de Einstein se deduce que cuando un cuerpo está en caída libre tiene una aceleración ordinaria que depende de la masa del cuerpo sobre el cual está cayendo, pero su aceleración inercial es nula, a menos que se le aplique alguna otra fuerza. De ahí que para Einstein fuera absolutamente necesario introducir en su teoría el concepto de derivada covariante.

Desde un punto de vista estrictamente matemático, el cálculo de la derivada covariante tiene lugar a través de un sencillo procedimiento. Se procede en primer lugar al cómputo de la derivada parcial covariante y luego se generaliza ésta.

La derivada ordinaria se aplica exclusivamente sobre los componentes de un vector, mientras que la derivada covariante se aplica también sobre las bases del espacio vectorial, ya que la percepción del espacio-tiempo dependerá de la velocidad del "observador comóvil":

Sobre esta ecuación procedemos a aplicar la regla del producto (o de Leibniz),

Llegados a este punto introducimos una nueva notación, los símbolos de Christoffel, que pueden ser definidos como el componente formula_20 de la derivada parcial de formula_21 respecto a formula_22: formula_23. De este modo:

Realizamos un intercambio de índices (formula_20 por formula_26) en el último término del segundo miembro de la ecuación:

Y obtenemos con ello los componentes de la derivada parcial covariante de la velocidad, que equivalen a la expresión entre paréntesis:

Generalizamos dichos componentes multiplicándolos por el componente formula_22 de la tetravelocidad (formula_31) y obtenemos con ello la derivada covariante de la velocidad:

Puesto que para un observador inercial (p.e. un cuerpo en caída libre) formula_34, esta última ecuación toma la siguiente forma:

Estas fórmulas reciben el nombre de ecuación de las líneas geodésicas, y se utilizan para calcular la aceleración gravitatoria de cualquier cuerpo.

A los lectores principiantes puede chocarles la propia definición de los símbolos de Christoffel. A fin de cuentas, en el espacio euclideo, la derivada de una base (por ejemplo formula_37) respecto a otra coordenada (pongamos formula_38) es siempre cero, por la simple razón de que las bases de ambas coordenadas son ortogonales. Sin embargo, esto no sucede así en las variedades curvas, como por ejemplo las superficies de un cilindro o de una esfera: En tales casos, los símbolos de Christoffel no son iguales a cero, sino que son funciones de las derivadas del tensor métrico. La relación matemática entre estas dos magnitudes matemáticas se expresa mediante la siguiente ecuación:

Los símbolos de Christoffel constituyen el parámetro principal que determina cuán grande es el grado de curvatura existente en una región determinada y con su ayuda podemos conocer cuál va a ser la trayectoria de una geodésica en un espacio curvo. En el caso de la variedad espacio-temporal, la Teoría de la Relatividad afirma que la curvatura viene originada por la presencia de tetramomentum y por ello, cuanta mayor sea la densidad de materia existente en una determinada región, mayores serán los valores de los símbolos de Christoffel.

En un espacio-tiempo curvo, las leyes de la física se modifican mediante el Principio de acoplamiento mínimo, que supone que las ecuaciones matemáticas en cuya virtud se expresan aquellas experimentan las siguientes modificaciones:


De este modo, la ecuación galileana de los sistemas inerciales se transforma en virtud de dicho principio en la ecuación relativista de las líneas geodésicas:

Ley de conservación de la energía:

Sin embargo, en virtud del principio de simetría de los símbolos de Christoffel, las leyes electromagnéticas en general no experimentan modificaciones debidas a la curvatura gravitatoria:


La medición de la curvatura de cualquier variedad (ya se trate del espacio-tiempo, de una esfera o de una silla de montar) viene determinada por el tensor de curvatura o tensor de Riemann, que es una función de los símbolos de Christoffel y sus derivadas de primer orden.

El tensor de Riemann tiene una importancia fundamental a la hora de calcular la desviación de dos líneas en origen paralelas cuando se desplazan a través de una superficie curva. Es bien sabido que en una variedad llana las líneas paralelas jamás se cortan, sin embargo esta regla no rige en el caso de las superficies curvas de geometría elíptica. Supongamos que dos viajeros salen del Ecuador en dirección norte. En ambos casos, el ángulo que la trayectoria de su barco forma con el Ecuador es inicialmente de 90º, por lo que se trata de dos líneas paralelas. Sin embargo, conforme los viajeros se van desplazando hacia el norte, su distancia recíproca se hace cada vez más pequeña hasta que se hace nula en el Polo Norte, que es donde se cortan sus trayectorias de viaje. Para calcular la tasa de aproximación entre las dos geodésicas utilizamos la siguiente ecuación:

donde formula_48 y formula_49 representan el recorrido desde el Ecuador de ambas líneas geodésicas y formula_50 la distancia de separación entre ellas.

En el espacio-tiempo, que también es una variedad curva, las cosas funcionan de un modo parecido: el tensor de Riemann determina la aceleración recíproca entre las líneas de universo de dos sistemas inerciales (p.e. dos asteroides que se acercan progresivamente como consecuencia de su mutua atracción gravitatoria). Para calcular dicha aceleración, aplicamos de nuevo la conocida fórmula, modificándola ligeramente:
donde formula_51 es un parámetro afín (el tiempo local) y formula_52 y formula_53 son los vectores de cuadrivelocidad de ambos cuerpos que, según el esquema de Minkowski, equivalen geométricamente a campos vectoriales tangentes a ambas líneas de universo.

Todo esto nos conecta con lo que en física newtoniana se denominan "fuerzas de marea", responsables de múltiples fenómenos astronómicos y cuya base teórica reposa en el planteamiento siguiente: Supongamos que una determinada nave espacial está cayendo a un agujero negro. Es evidente que la proa de la nave experimenta una fuerza gravitatoria más intensa que la popa, por el simple hecho de que la primera está más próxima que la segunda al horizonte de sucesos. Si la diferencia de aceleraciones entre la proa y la popa es lo suficientemente intensa, la nave puede llegar a distorsionarse y quebrarse definitivamente.

El gradiente gravitatorio es también responsable del ciclo de mareas: Las zonas de la tierra más cercanas a la Luna, experimentan una mayor atracción gravitatoria que las más lejanas a ella, lo que provoca que el agua del mar se acumule en aquellas áreas de la superficie terrestre que están alineadas con la Luna.

En relatividad general, la aceleración de marea viene originada por el tensor de Riemann. Hay una correspondencia casi natural entre las ecuaciones newtonianas y las relativistas. En efecto, la ecuación newtoniana utilizada para computar las fuerzas de marea es la siguiente:

donde a es la aceleración de marea, formula_54 el potencial gravitatorio y formula_55 la distancia entre las dos partículas. Las fuerzas de marea vienen determinadas por las derivadas de segundo orden del potencial gravitatorio.

Desde el punto de vista relativista, las fuerzas de marea vienen determinadas por el tensor de Riemann y si la región del espacio tiene una escasa densidad de cuadrimomento y una distribución uniforme de la curvatura, los componentes aquél toman aproximadamente los valores siguientes:

De ahí que sea muy simple deducir la ecuación clásica partir de la relativista:

Como se puede deducir de los párrafos anteriores, en relatividad general las fuerzas de marea están determinadas por el tensor de Riemann y las primeras derivadas de los símbolos de Christoffel. Si estas magnitudes tienen un valor no nulo, el diferencial de los símbolos de Christoffel provoca la dispersión de las geodésicas correspondientes a partículas de un fluido determinado.

Las geodésicas (trayectorias inerciales en el espacio-tiempo) vienen determinadas por los valores de los símbolos de Christoffel. Si éstos son constantes, las partículas de un fluido se mueven uniformemente, a una misma velocidad y aceleración, y no se altera su distancia entre sí. Pero si los componentes de los símbolos de Christoffel varían a lo largo de una determinada región, ello conlleva la divergencia de las líneas de universo de las partículas y la distorsión del fluido, en la medida en que cada una de sus partes constituyentes acelera distintamente.

Las fuerzas de marea y el tensor de Riemann tienen una importancia fundamental en la formación y configuración de los sistemas planetarios, así como en multitud de procesos astrofísicos y cosmológicos. Sirva de ejemplo nuestro propio Sistema Solar: Hace cerca de 4.500 millones de años, una nube molecular alcanzó la densidad y la compresión suficientes como para transformarse en un sistema planetario. La mayor parte del material de la nube se precipitó sobre en torno al núcleo, dando lugar al Sol. Sin embargo, ciertas cantidades de gas y de polvo continuaron rotando bajo la forma de un disco de acreción, y se aglutinaron para dar origen a planetesimales y posteriormente a planetas.
Sin embargo, en la zona situada entre Marte y Júpiter, los tensores de Riemann correspondientes a las masas del Sol y de Júpiter generaron unas intensas fuerzas de marea que dispersaron las líneas de universo de los planetesimales allí situados, impidiendo que se agregaran entre sí para dar lugar a un cuerpo masivo. Los planetesimales permanecieran dispersos bajo la forma de un cinturón de asteroides. Este fenómeno que acaba de describirse no es exclusivo de nuestro Sistema Solar, sino que ha sido observado en multitud de sistemas exoplanetarios descubiertos desde principios de los años noventa hasta la actualidad, como los mostrados en las ilustraciones de esta sección.

Las fuerzas de marea también poseen cierta importancia en el desarrollo de otros fenómenos astronómicos como las supernovas de tipo II, deflagraciones cósmicas que suelen tener lugar en el marco de sistemas estelares dobles. En efecto, en los sistemas binarios es frecuente que una estrella masiva orbite alrededor de una enana blanca. Si el tamaño de la primera sobrepasa el límite de Roche, el componente del tensor de Riemann formula_61 generado por la masa de la enana blanca extrae material de las capas exteriores de su compañera y lo precipita sobre la enana blanca, en torno a la cual dicho material orbita formando un disco de acreción. El plasma queda sometido a enormes temperaturas que provocan la emisión de rayos X y la aparición de explosiones periódicas conocidas con el nombre de supernovas de tipo II.

Según la teoría laplaciana-newtoniana de la gravitación universal, una masa esférica de gas reduce su volumen (como consecuencia de la atracción recíproca de sus moléculas) con una aceleración equivalente a formula_62:

Es evidente, que dicha ecuación no es compatible con la relatividad especial, por las razones reseñadas anteriormente:

En este sentido, cabe señalar que en un espacio-tiempo curvo la aceleración del volumen viene cuantificada por un objeto geométrico específico, el tensor de Ricci formula_65, que puede definirse como la aceleración coordenada del hipervolumen formula_66, normal al vector unitario formula_67. De este modo, el componente formula_68 expresa la aceleración temporal del volumen tridimensional:

La relación entre el tensor métrico y el tensor de Ricci se expresa a través de la llamada "ecuación de flujo de Ricci", que tiene la forma siguiente:

Según esta ecuación, la existencia de valores positivos del tensor de Ricci implica la disminución a lo largo del tiempo de los coeficientes del tensor métrico, y como consecuencia de ello la disminución de los volúmenes en esa región de la variedad. Por el contrario, la presencia de valores negativos en el tensor de Ricci lleva consigo una expansión progresiva de las distancias, las superficies y los volúmenes.

Por todo lo dicho, los tensores de energía-momentum y de Ricci permitían expresar de manera tensorial y covariante la "fórmula de Poisson", y de ahí que originalmente Einstein propusiera las siguientes "ecuaciones de universo":

En relatividad general, el tensor de Ricci tiene la virtualidad de representar aquellos efectos gravitatorios originados por la presencia inmediata y local de cuadrimomento, que son con gran diferencia los más importantes a pequeña y gran escala.

El tensor de Ricci rige, pues, la mayor parte de los procesos astrofísicos que tienen lugar en el Cosmos: constituye una medida de la contracción de nubes moleculares que dan lugar al nacimiento de estrellas y planetas; cuantifica el colapso de las grandes cuerpos estelares y su conversión en enanas blancas, estrellas de neutrones y agujeros negros; y proporciona una medida de la expansión del universo.

Del tensor de Ricci, particularmente de la forma que toma en los campos gravitatorios esféricos (como las estrellas estáticas), se deriva la llamada "Ley de equilibrio hidrostático", que regula el equilibrio entre la presión del fluido estelar (que tiende a expandir el volumen de la estrella) y la curvatura gravitatoria (que lo contrae). Este equilibrio se mantiene prácticamente durante toda la vida de la estrella y sólo se rompe en dos ocasiones diferentes: 1) Cuando la estrella deviene en una gigante roja, en cuyo caso los efectos de la presión de radiación desbordan los del tensor de Ricci, y como resultado, el volumen de la estrella se expande hasta alcanzar una nueva situación de equilibrio. 2) Cuando la estrella agota su combustible. Se produce entonces un descenso en la presión del fluido, y la estrella, bien se transforma en una enana blanca, en una estrella de neutrones, o bien colapsa definitivamente convirtiéndose en un agujero negro.

Einstein tuvo pronto que modificar ligeramente sus ecuaciones de universo, pues estas no eran compatibles con la ley de la conservación de la energía [Demostración 1]. Esto constriñó a Einstein a modificar sus ecuaciones de Universo, que adquirieron su forma definitiva tras la publicación en 1915 del artículo "Aplicación de la teoría de la relatividad general al campo gravitatorio":

Donde formula_65 es el tensor de Ricci, formula_70 el tensor métrico, formula_71 el escalar de Ricci, formula_72 la constante de gravitación universal y formula_64 el tensor de energía-impulso. El miembro izquierdo de la ecuación recibe el nombre genérico de tensor de Einstein, se representa con la notación formula_74 y satisface las mismas relaciones de conservación que el tensor de tensión-energía:

Teniendo en cuenta que el escalar de curvatura formula_75 es proporcional a la traza del tensor de Einstein formula_76, las ecuaciones de universo de Einstein pueden reformularse de la manera siguiente:

En un fluido no relativista, como una nebulosa o una estrella de la secuencia principal, todos los componentes del tensor de energía-impulso son nulos o de muy poca importancia, salvo el elemento formula_77, que corresponde a la densidad de masa y que es el único que contribuye sensiblemente a la atracción gravitatoria y a la curvatura del espacio-tiempo. Si deseamos medir la contracción de volumen producida por la masa-energía presente en una determinada región, hemos de aplicar las ecuaciones de universo de Einstein:

Computemos ahora los valores de formula_78:

Tras ello obtenemos:

O bien:

Donde formula_80 es la presión del fluido, que en general es muy pequeña comparada con formula_81, por lo que tenemos es una ligera corrección de la anteriormente citada fórmula newtoniana. Como vemos, la atracción gravitatoria viene determinada no sólo por la masa-energía sino también por la presión, aunque la contribución de ésta es formula_82 inferior a la de la primera. Por eso, en las regiones del espacio-tiempo sometidas a bajas presiones y temperaturas, como las nebulosas o nuestro Sistema Solar, la masa es prácticamente la única fuente de atracción gravitatoria y por ello las ecuaciones de la gravitación universal newtonianas constituyen una muy buena aproximación de la realidad física. En cambio, en fluidos sometidos a altas presiones, como las estrellas que se colapsan, la materia que se precipita en los agujeros negros o los chorros que son expelidos de los centros de las galaxias; en todos ellos la presión puede tener cierta importancia a la hora de computar la atracción gravitatoria y la curvatura del espacio-tiempo.

En un fluido electromagnético, la traza del tensor de energía-impulso es nula. Como consecuencia de ello, las ecuaciones de universo de Einstein toman la siguiente forma.

Como vemos, los valores del tensor de Ricci son justo el doble de los calculados para las soluciones de polvo. Esto es lo que explica que la deflexión de los rayos de la luz sea dos veces superior en el ámbito relativista que en el newtoniano, y que la expansión de un universo cíclico de Tolman (dominado por la radiación) sea más lenta que la de un universo cíclico de Friedman (dominado por la materia).

Es importante notar que, puesto en un espacio-tiempo de cuatro dimensiones, el tensor pleno de curvatura contiene más información que la curvatura de Ricci. Eso significa que las ecuaciones del campo anterior, con Λ = 0, no especifican completamente el tensor de curvatura sino una parte del mismo, el tensor de Ricci. La parte de la curvatura no especificada por las ecuaciones de Einstein, coincide precisamente con el tensor de Weyl. Eso significa que las ecuaciones de Einstein no especifican por completo el tensor de curvatura, ni la forma global del universo.

Desde el principio Einstein apreció que matemáticamente el miembro derecho de su ecuación de campo podía incluir un término proporcional al tensor métrico sin que se violara el principio de conservación de la energía. Aunque inicialmente no incluyó dicho término, ya que no parecía tener una interpretación física razonable, más tarde lo incluyó. Esto se debió a que en sus primeros intentos de encontrar soluciones exactas a las ecuaciones de campo consideró que lo que hoy conocemos como modelo estacionario de Einstein. Einstein apreció que esa solución, explicaba adecuadamente los datos disponibles en su tiempo, y correspondía a un universo estático similar a los datos observados. Sin embargo, dicha solución era inestable matemáticamente lo cual no parecía corresponderse con la estabilidad física observable, y se dio cuenta de que con el término proporcional a la métrica la solución podía ser similar pero esta vez estable.

Por esa razón Einstein introdujo en sus ecuaciones un término proporcional al tensor métrico. Siendo la constante de proporcionalidad precisamente la constante cosmológica. El trabajo de varios científicos (FLRW): Alexander Friedman, Georges Lemaître, Howard Percy Robertson y Arthur Geoffrey Walker, probó que existían soluciones estables no estacionarios sin el término proporcional a la constante cosmológica. Y aunque Einstein inicialmente había rechazado el trabajo de Friedman por describir un universo en expansión que no parecía ser descriptivamente adecuado a un universo que él creía estacionario, los datos del corrimiento al rojo del astrónomo Edwin Hubble sólo parecían explicables mediante un modelo de universo en expansión. Esto convenció a Einstein de que la solución FLRW era de hecho correcta y descriptivamente adecuada y por tanto la constante cosmológica innecesaria.

Recientemente la evidencia de la aceleración de la expansión del Universo han llevado a reintroducir la constante cosmológica diferente de cero como una de las posibles explicaciones del fenómeno.

Matemáticamente las ecuaciones de campo de Einstein son complicadas porque constituyen un sistema de 10 ecuaciones diferenciales no lineales independientes. La complejidad de dicho sistema de ecuaciones y las dificultades asociadas para plantear el problema como un problema de valor inicial bien definido, hicieron que durante mucho tiempo sólo se contara con un puñado de soluciones exactas caracterizadas por un alto grado de simetría. En la actualidad se conocen algunos centenares de soluciones exactas de las ecuaciones de Einstein.

Históricamente la primera solución importante fue obtenida por Karl Schwarzschild en 1915, esta solución conocida posteriormente como métrica de Schwarzschild, representa el campo creado por un astro estático y con simetría esférica. Dicha solución constituye una muy buena aproximación al campo gravitatorio dentro del sistema solar, lo cual permitió someter a confirmación experimental la teoría general de la relatividad explicándose hechos previamente no explicados como el avance del perihelio de Mercurio y prediciendo nuevos hechos más tarde observados como la deflexión de los rayos de luz de un campo gravitatorio. Además las peculiaridades de esta solución condujeron al descubrimiento teórico de la posibilidad de los agujeros negros, y se abrió todo una nueva área de la cosmología relacionada con ellos. Lamentablemente el estudio del colapso gravitatorio y los agujeros negros condujo a la predicción de las singularidades espaciotemporales, deficiencia que revela que la teoría de la relatividad general es incompleta.

Algunas otras soluciones físicamente interesantes de las ecuaciones de Einstein son:

Por otra parte, el espacio-tiempo empleado en la teoría especial de la relatividad, llamado espacio de Minkowski es en sí mismo una solución de las ecuaciones de Einstein, que representa un espacio-tiempo vacío totalmente de materia.

Fuera de las soluciones exactas y a efectos comparativos con la teoría de campo gravitatorio también es interesante la aproximación para campos gravitatorios débiles y las soluciones en forma de ondas gravitatorias.

Cuando Einstein formuló en 1915 las ecuaciones de universo de la Relatividad general, el científico alemán pensó, en un principio, que dichas ecuaciones eran irresolubles debido a su carácter no lineal, que se manifestaba tanto desde un punto de vista físico como desde otro matemático:



Para sorpresa de Albert Einstein, pocas semanas después de la publicación de sus ecuaciones de campo llegó a su despacho un correo de Karl Schwarzschild, un profesor universitario que en esos momentos se encontraba en el frente de la I guerra mundial, realizando trabajos de balística para las unidades de artillería del ejército alemán. En esa histórica carta se contenían las primeras soluciones exactas de las ecuaciones de la relatividad general, que serían conocidas por la posteridad con el nombre genérico de Solución de Schwarzschild.

El principio sobre el que pivotaba dicha solución era el siguiente: Dado que el Principio de la Covariancia General permitía hacer funcionar las ecuaciones de campo de la relatividad general en cualquier sistema de coordenadas, Schwarzschild procedió a calcular los valores de los tensores de energía-momento y de Einstein en coordenadas espacio-temporales esféricas formula_89. El alto grado de simetría proporcionado por dicho sistema de coordenadas, así como el carácter estático de la métrica, permitieron integrar directamente el conjunto de ecuaciones diferenciales. Siendo en el caso general el tensor métrico para un problema con simetría esférica de la forma:

Para el espacio la parte exterior de un astro esférica más concretamente se tenía:

Las comprobaciones experimentales mostraron que la métrica de Schwarzschild describe con enorme precisión lo que sucede en sistemas esféricos estáticos, similares al sistema solar.

 Las ecuaciones de un campo con simetría esférica permiten también estudiar la curvatura en el interior de las estrellas masivas. El resultado de ese análisis, es que para estrellas de la secuencia principal del diagrama de Hertzsprung-Russell, la curvatura originada por la gravedad es compensada por la presión de la materia estelar. Esa compensación conduce a una ley de equilibrio hidrostático que hace que la estrella, aún sometida a su propio campo gravitatorio, pueda mantener durante millones de años su volumen y su densidad a niveles constantes. Matemáticamente, el hecho de que la métrica tenga un carácter estático implica los valores del tensor formula_87 se mantengan estables en el tiempo. La ley de equilibrio hidrostático que relaciona la densidad y la presión en una estrella esférica viene dada por la ecuación de Tolman-Oppenheimer-Volkoff:

Donde:

La solución de Schwarzschild permitió aplicar los postulados de la relatividad general a disciplinas como la mecánica celeste y la astrofísica, lo cual supuso una verdadera revolución en el estudio de la cosmología: Apenas seis años después de la publicación de los trabajos de Einstein, el físico ruso Aleksander Fridman introdujo el concepto de singularidad espacio-temporal, definido como un punto del espacio-tiempo en el que confluyen todas las geodésicas de las partículas que habían atravesado el horizonte de sucesos de un agujero negro. En condiciones normales, la curvatura producida por la masa de los cuerpos y las partículas es compensada por la temperatura o la presión del fluido y por fuerzas de tipo electromagnético, cuyo estudio es objeto de la física de fluidos y del estado sólido. Sin embargo, cuando la materia alcanza cierta densidad, la presión de las moléculas no es capaz de compensar la intensa atracción gravitatoria. La curvatura del espacio-tiempo y la contracción del fluido aumentan cada vez a mayor velocidad: el final lógico de este proceso es el surgimiento de una singularidad, un punto del espacio-tiempo donde la curvatura y la densidad de tetramomentum son infinitas.

Ahora bien, el físico Subrahmanyan Chandrasekhar fue el primero en darse cuenta que la gravedad podía ser contenida no sólo por fuerzas de tipo mecánico, sino también por un fenómeno de origen cuántico al que llamó "presión de degeneración", derivado del principio de exclusión de Pauli y que era capaz de sostener a estrellas cuya masa no superase el "límite de Chandrasekhar". Estas ideas tan audaces le costaron caras a su autor, que fue ridiculizado en público por Sir Arthur Eddington durante un congreso de astrónomos. Sin embargo, los cálculos de Chandrasekhar se revelaron certeros, y sirvieron de base para la comprensión de un tipo estelar cuya naturaleza física hasta entonces era desconocida: la enana blanca.

Dado que para muchos sistemas físicos no resulta sencillo obtener las expresiones exactas de las soluciones de las ecuaciones de Einstein, los físicos teóricos han desarrollado aproximaciones bastante precisas empleando series de potencias. De entre ellas las más importantes funcionan en coordenadas armónicas y reciben los nombres de "aproximación posnewtoniana" y "aproximación para campos gravitatorios débiles".

En virtud del principio de la covariancia general, ya examinado en secciones anteriores, es posible hacer funcionar a las ecuaciones de universo de Einstein en cualquier tipo de coordenadas, incluidas las armónicas, que son aquéllas en las que se cumple la relación formula_93 (como, por ejemplo, en el caso de las coordenadas cartesianas). Se hace necesario en este punto distinguir con claridad entre los conceptos de "planitud" del espacio-tiempo y "armonicidad" de un sistema de coordenadas: en una espacio-tiempo de curvatura nula, como el espacio-tiempo de Minkowski, es posible utilizar coordenadas no-armónicas como las esféricas o las cilíndricas, sin que ello implique que el espacio se curve, ya que la curvatura es una cualidad instrínseca de cualquier variedad e independiente de nuestro sistema de referencia.

Para campos gravitatorios poco intensos, como los existentes en el espacio interestelar, es recomendable utilizar la llamada "aproximación para campos débiles", que es, como veremos, muy similar en su estructura a la fórmula de Poisson newtoniana, si bien las diferencias con esta última son enormes.

La fórmula de Poisson afirma que el laplaciano del potencial gravitatorio formula_54 es igual formula_95:

Esta fórmula plantea un grave inconveniente, y es que presupone el principio de acción a distancia: No tiene en cuenta el retardo en la medición del campo gravitatorio realizada por un determinado observador (pongamos, un observador en la tierra) situado a cierta distancia a la masa del cuerpo que genera dicho campo gravitatorio (p.e. el Sol, situado a 8 minutos luz de nuestro planeta).

De ahí que uno de los primeros intentos de compatibilizar la teoría de la Relatividad Especial y la Gravitación Universal consistiera en sustituir el laplaciano de la fórmula de Poisson por un d'Alembertiano, una de cuyas soluciones es, precisamente, un potencial retardado:

Como vemos, el potencial gravitatorio medido por el observador en el tiempo "t", es proporcional a la densidad de masa que tiene el cuerpo estelar observado en el tiempo "t - r/c", donde "c" es la velocidad de la luz, "r" es la distancia entre el observador y el objeto y "r/c" es el "retardo", es decir, el tiempo que la luz tarda en desplazarse desde la estrella en cuestión hasta el observador.

Ahora bien, la relatividad general es una teoría métrica de la gravedad, y explica los fenómenos gravitatorios en términos de perturbaciones de la métrica. Es conveniente, por tanto, introducir en nuestra ecuación el pseudotensor formula_97, que representa la desviación de los coeficientes del tensor métrico respecto a la métrica de Minkowski formula_98. Aplicando el límite newtoniano, en cuya virtud formula_86 es igual a formula_100, obtenemos el resultado siguiente:

A grandes rasgos, la sustitución del laplaciano formula_104 por el d'alembertiano formula_105 viene exigida por la obligada eliminación del principio de acción a distancia; el empleo del pseudotensor formula_97 en lugar del potencial formula_5 como elemento definitorio del campo gravitatorio es una consecuencia de la del carácter métrico de la teoría de la relatividad general; y finalmente, la eliminación, en el lado derecho de la ecuación, del parámetro formula_108 y su sustitución por la expresión tensorial formula_109 viene exigida por el principio de la covariancia general.

Sin embargo, en el análisis de la evolución de sistemas astronómicos como el solar o el formado por estrellas dobles o tripoles, la aproximación para campos débiles no es útil, ya que el uso de esta última se restringe a zonas del espacio-tiempo con poca densidad de tetramomentum. En estos casos es preferida la "aproximación posnewtoniana" que como su propio nombre indica prescinde del empleo de la compleja notación del cálculo tensorial y describe el movimiento de los cuerpos celestes utilizando los conceptos matemáticos que empleó el propio Newton a la hora describir las leyes de la mecánica y de la gravitación universal (vectores, gradientes, etc.).

En los siglos XVIII y XIX, astrónomos como Laplace y Le Verrier habían aplicado los postulados de la mecánica newtoniana al estudio de la evolución del Sistema Solar, obteniendo unos resultados muy fructuosos: La precisión de los cálculos astronómicos obtenidos había permitido incluso prever la existencia de un planeta hasta entonces nunca observado por los astrónomos, Neptuno. Por este motivo no es de extrañar que cuando la relatividad general obtuvo pleno reconocimiento, se desarrollase por parte de los astrofísicos una aproximación que siguiera en su estructura el modelo newtoniano y que fuese fácilmente aplicable tanto por los astrónomos como por los ordenadores.

De acuerdo con la teoría clásica de la gravitación, la aceleración de un cuerpo en caída libre es el gradiente negativo del potencial gravitatorio:

Como ya se ha avanzado en secciones anteriores, esta fórmula presupone la asunción del principio newtoniano de acción a distancia, contrario a los postulados de la Relatividad Especial, y además no tiene en cuenta los efectos gravitatorios generados por la energía y por el momentum. La "aproximación posnewtoniana" soslaya estos inconvenientes introduciendo otros dos nuevos potenciales: el potencial formula_111, que constituye una aproximación en segundo grado del potencial formula_112 y el potencial formula_113, derivado de la presencia de momentum en el fluido.

Las ecuaciones de movimiento quedarían reformuladas de la siguiente forma:

Existen un cierto número de soluciones exactas de las ecuaciones que describen un universo completo y por tanto pueden ser consideradas modelos cosmológicos entre ellas destacan:

Se considera que la teoría de la relatividad general fue comprobada por primera vez en la observación de un eclipse total de Sol en 1919, realizada por Sir Arthur Eddington, en la que se ponía de manifiesto que la luz proveniente de estrellas lejanas se curvaba al pasar cerca del campo gravitatorio solar, alterando la posición aparente de las estrellas cercanas al disco del Sol. Desde entonces muchos otros experimentos y aplicaciones han demostrado las predicciones de la relatividad general. Entre algunas de las predicciones se encuentran:


Esto implica el comportamiento del espacio-tiempo alrededor de un objeto masivo rotante.



La teoría de la relatividad general ha sido confirmada en numerosas formas desde su aparición. Por ejemplo, la teoría predice que la línea del universo de un rayo de luz se curva en las proximidades de un objeto masivo como el Sol. La primera comprobación empírica de la teoría de la relatividad fue a este respecto. Durante los eclipses de 1919 y 1922 se organizaron expediciones científicas para realizar esas observaciones, entre ellas la expedición de Arthur Eddington. Después se compararon las posiciones aparentes de las estrellas con sus posiciones aparentes algunos meses más tarde, cuando aparecían de noche, lejos del Sol. Einstein predijo un desplazamiento aparente de la posición de 1,745 segundos de arco para una estrella situada justo en el borde del Sol, y desplazamientos cada vez menores de las estrellas más distantes. Se demostró que sus cálculos sobre la curvatura de la luz en presencia de un campo gravitatorio eran exactos. En los últimos años se han llevado a cabo mediciones semejantes de la desviación de ondas de radio procedentes de quásares distantes, utilizando interferómetros de radio. Las medidas arrojaron unos resultados que coincidían con una precisión del 1% con los valores predichos por la relatividad general.

Otra confirmación de la relatividad general está relacionada con el perihelio del planeta Mercurio. Hacía años que se sabía que el perihelio (el punto en que Mercurio se encuentra más próximo al Sol) gira en torno al Sol una vez cada tres millones de años, y ese movimiento no podía explicarse totalmente con las teorías clásicas. En cambio, la teoría de la relatividad sí predice todos los aspectos del movimiento, y las medidas con radar efectuadas recientemente han confirmado la coincidencia de los datos reales con la teoría con una precisión de un 0,5%.

Se han realizado otras muchas comprobaciones de la teoría, y hasta ahora todas parecen confirmarla. Prácticamente con la más reciente prueba del satélite Gravity Probe B, se podría considerar a la teoría como una ley.

Los relojes en los satélites GPS requieren una sincronización con los situados en tierra para lo que hay que tener en cuenta la teoría general de la relatividad y la teoría especial de la relatividad. Si no se tuviese en cuenta el efecto que sobre el tiempo tiene la velocidad del satélite y su gravedad respecto a un observador en tierra, se produciría un adelanto de 38 microsegundos por día en el reloj del satélite (sin corrección, su reloj retrasaría al día 7 microsegundos como consecuencia de la velocidad y adelantaría 45 microsegundos por efecto de la gravedad), que a su vez provocarían errores de varios kilómetros en la determinación de la posición. Puede considerarse otra comprobación de ambas teorías.

En esta parte, la mecánica clásica y la relatividad especial están entrelazadas debido a que la relatividad general en muchos modos es intermediaria entre la relatividad especial y la mecánica cuántica.

Sujeto al principio de acoplamiento mínimo, las ecuaciones físicas de la relatividad especial pueden ser convertidas a su equivalente de la relatividad general al reemplazar la métrica de Minkowski ("η") con la relevante métrica del espacio-tiempo ("g") y reemplazando cualquier derivada normal con derivadas covariantes.

Tanto en mecánica cuántica como en relatividad se asumía que el espacio, y más tarde el espacio-tiempo, eran planos. En el lenguaje de cálculo tensorial, esto significaba que "R = 0", donde "R" es el tensor de curvatura de Riemann. Adicionalmente, se asumía que el sistema de coordenadas era un sistema de coordenadas cartesianas. Estas restricciones le permitían al movimiento inercial ser descrito matemáticamente como: 

formula_117 donde

Hay que notar que en la mecánica clásica, "x" es tridimensional y "τ ≡ t", donde "t" es una coordenada de tiempo. 

En la relatividad general, si estas restricciones son usadas en la forma de espacio-tiempo y en el sistema de coordenadas, éstas se perderán. Ésta fue la principal razón por la cual se necesitó una definición diferente de movimiento inercial. En relatividad especial, el movimiento inercial ocurre en el espacio de Minkowski como parametrizada por el tiempo propio. Esto se generaliza a espacios curvos matemáticamente mediante la ecuación de las geodésicas:

formula_119 donde

Como "x" es un tensor de rango uno, estas ecuaciones son cuatro y cada una está describiendo la segunda derivada de una coordenada con respecto al tiempo propio. (En la métrica de Minkowski de la relatividad especial, los valores de conexión son todos ceros. Esto es lo que convierte a las ecuaciones geodésicas de la relatividad general en formula_121 para el espacio plano de la relatividad especial).

En gravitación, la relación entre la teoría de la gravedad de Newton y la relatividad general son gobernadas por el principio de correspondencia: la relatividad general tiene que producir los mismos resultados, así como la gravedad lo hace en los casos donde la física newtoniana ha demostrado ser certera.

Alrededor de objetos simétricamente esféricos, la teoría de la gravedad de Newton predice que los otros objetos serán acelerados hacia el centro por la ley:
</math>
Donde: M: masa que genera el Campo gravitatorio, y m es la masa del cuerpo que es atraído.

En la aproximación de campo débil de la relatividad general tiene que existir una aceleración en coordenadas idénticas. En la solución de Schwarzschild, la misma aceleración de la fuerza de gravedad es obtenida cuando la constante de integración es igual a 2"m" (donde "m" = "GM"/"c").

El electromagnetismo planteó un obstáculo fundamental para la mecánica clásica, debido a que las ecuaciones de Maxwell no son invariantes según la relatividad galileana. Esto creaba un dilema que fue resuelto por el advenimiento de la relatividad especial. 
En forma tensorial, las ecuaciones de Maxwell son:

Donde:
El efecto de un campo electromagnético en un objeto cargado de masa "m" es entonces:

Donde
En la relatividad general, las ecuaciones de Maxwell se convierten en 

formula_127 , y
formula_128.

La ecuación para el efecto del campo electromagnético sigue siendo la misma, aunque el cambio de métrica modificará sus resultados. Nótese que al integrar esta ecuación para cargas aceleradas las hipótesis habituales no son válidas (ya que implican que una carga sujeta en un campo gravitato debe comportarse como si estuviera uniformemente acelerada, lo que muestra que una carga uniformemente acelerada no puede radiar).

En la mecánica clásica, la conservación de la energía y el momentum son manejados separadamente. En la relatividad especial, la energía y el momentum están unidos en el cuadrimomento y los tensores de energía. Para cualquier interacción física, el tensor de energía-impulso formula_129 satisface la ley local de conservación siguiente:

En la relatividad general, esta relación es modificada para justificar la curvatura, convirtiéndose en:

donde ∇ representa aquí la derivada covariante.

A diferencia de la mecánica clásica y la relatividad especial, en la relatividad general no es siempre posible definir claramente la energía total y el momentum. Esto a menudo causa confusión en espacio-tiempos dependientes del tiempo, en los que no existen temporales, los cuales no parecen conservar energía, aunque la ley local siempre se satisfaga (Ver energía de Arnowitt, Deser y Misner).

La teoría de la relatividad especial presenta covariancia de Lorentz esto significa que tal como fue formulada las leyes de la física se escriben del mismo modo para dos observadores que sean inerciales. Einstein estimó, inspirado por el principio de equivalencia que era necesaria una teoría que presentara una para la que valiera un principio de covariancia generalizado, es decir, en que las leyes de la física se escribieran de la misma forma para todos los posibles observadores fueron estos inerciales o no, eso le llevó a buscar una teoría general de la relatividad. Además el hecho de que la propia teoría de la relatividad fuera incompatible con el principio de acción a distancia le hizo comprender que necesitaba además que esta teoría general incorporase una descripción adecuada del campo gravitatorio.

Hoy sabemos que Einstein consideraba que la teoría de la relatividad sólo era aplicable a sistemas de referencia inerciales estrictamente, aunque Logunov ha probado en el marco de la teoría relativista de la gravitación que de hecho fijado un observador inercial o no, cualquier otro que se mueva con velocidad uniforme respecto al primero escribirá las leyes físicas de la misma forma. Probando así que la relatividad especial de hecho es más general de lo que Einstein creyó en su momento. Además el trabajo de Logunov prueba que siempre que el espacio-tiempo sea plano puede establecerse para cada observador existe un grupo decaparamétrico de transformaciones de coordenadas que generaliza las propiedades del grupo de Lorentz para observadores no inerciales.

El principio de geometrización y el principio de equivalencia fueron las piedras angulares en las que Einstein basó su búsqueda de una nueva teoría, tras haber fracasado en el intento de formular una teoría relativista de la gravitación a partir de un potencial gravitatorio. La teoría escalar de la gravitación de Nordström y la interpretación geométrica que extrajo de ella Adriaan Fokker (1914), el estudiante de doctorado de Hendrik Lorentz, llevaron a Einstein a poder relacionar el tensor de energía-impulso con la curvatura escalar de Ricci de un espacio-tiempo con métrica:

que involucraba la métrica del espacio-tiempo plano y un campo escalar relacionado con el campo gravitatorio. La superación de las deficiencias de la teoría de la gravitación escalar de Nordström llevaron a Einstein a formular las ecuaciones correctas de campo.





</doc>
<doc id="4599" url="https://es.wikipedia.org/wiki?curid=4599" title="Borís Spaski">
Borís Spaski

Borís Vasílievich Spaski (Бори́с Васи́льевич Спа́сский), nacido el 30 de enero de 1937 en Leningrado (actual San Petersburgo). Se proclamó décimo campeón del mundo de ajedrez en 1969 al derrotar al también soviético Tigrán Petrosián.

Fue un niño prodigio del ajedrez y su estilo era universal: ganaba a Mijaíl Tal con ataques al rey, a Tigrán Petrosián en profilaxis.

Aunque hizo méritos suficientes para pasar a la historia como un gran jugador, más que por su contribución al desarrollo del ajedrez, es conocido por haber sido el jugador que perdió con el estadounidense Robert James Fischer en el encuentro disputado en Reikiavik (Islandia) en 1972, al cual se denominó «"match" del siglo». Se celebró en plena guerra fría y fue todo un símbolo del enfrentamiento entre las dos superpotencias. Hasta ese momento, Fischer no había ganado a Spaski, que además preparó el campeonato con Yefim Géler, el cual también había superado a Fischer en el pasado. Pero el estadounidense ganó con contundencia mediante una serie de salidas sorprendentes, que buscaban tirar por tierra la preparación de Spaski. El resultado final fue 12,5 - 8,5 a favor del estadounidense. Tras el encuentro, Spaski no volvió a ser el jugador dominante que había sido.
Pero ganaría el Torneo Internacional de Ajedrez Ciudad de Linares en 1983.
Cayó en desgracia en la Unión Soviética, nacionalizándose francés en 1984.

Posteriormente, participó en varios ciclos clasificatorios para el título mundial. En 1974, fue eliminado en semifinales por Anatoli Kárpov, futuro campeón del mundo, y en 1978 llegó hasta la final, donde fue derrotado por Víktor Korchnói.

En 1992, jugó un encuentro de revancha contra Bobby Fischer en Sveti Stefan (en lo que hoy es Montenegro, entonces Yugoslavia), en el que volvió a ser derrotado. En este último "match", el nivel de los contendientes distaba mucho del que los encumbró en el mundo del ajedrez; pero creó una gran expectación, ya que suponía el regreso de Bobby Fischer a los tableros después de veinte años de ausencia.

Un empresario yugoslavo organizó la revancha Spaski-Fischer por 5 millones de dólares (3,35 millones para el ganador y 1,65 millones para el segundo clasificado). Una vez más, Fischer derrotó a su viejo rival para luego desaparecer de nuevo y definitivamente de la vista del público, pues falleció en 2008.



</doc>
<doc id="4600" url="https://es.wikipedia.org/wiki?curid=4600" title="Hidrodinámica">
Hidrodinámica

La hidrodinámica estudia la dinámica de los líquidos.

Para el estudio de la hidrodinámica normalmente se consideran tres aproximaciones importantes: 

La hidrodinámica tiene numerosas aplicaciones industriales, como diseño de canales, construcción de puertos y presas, fabricación de barcos, turbinas, etc. 

Daniel Bernoulli fue uno de los primeros matemáticos que realizó estudios de hidrodinámica, siendo precisamente él quien dio nombre a esta rama de la física con su obra de 1738, "Hydrodynamica".

La hidrodinámica o fluidos en movimientos presenta varias características que pueden ser descritas por ecuaciones matemáticas muy sencillas. Entre ellas:


donde formula_1 es la densidad, formula_2 la velocidad, formula_3 es el diámetro del cilindro y formula_4 es la viscosidad dinámica. Concretamente, este número indica si el fluido es laminar o turbulento, o si está en la zona de transición. formula_5 indica laminar, formula_6 turbulencia.

El caudal o gasto es una de las magnitudes principales en el estudio de la hidrodinámica. Se define como el volumen de líquido formula_7 que fluye por unidad de tiempo formula_8. Sus unidades en el Sistema Internacional son los m/s y su expresión matemática:

Esta fórmula nos permite saber la cantidad de líquido que pasa por un conducto en cierto intervalo de tiempo o determinar el tiempo que tardará en pasar cierta cantidad de líquido.

El principio de Bernoulli es una consecuencia de la conservación de la energía en los líquidos en movimiento. Establece que en un líquido incompresible y no viscoso, la suma de la presión hidrostática, la energía cinética por unidad de volumen y la energía potencial gravitatoria por unidad de volumen, es constante a lo largo de todo el circuito. Es decir, que dicha magnitud toma el mismo valor en cualquier par de puntos del circuito. Su expresión matemática es:

donde formula_9 es la presión hidrostática, formula_1 la densidad, formula_11 la aceleración de la gravedad, formula_12 la altura del punto y formula_13 la velocidad del fluido en ese punto. Los subíndices 1 y 2 se refieren a los dos puntos del circuito.

La otra ecuación que cumplen los fluidos no compresibles es la ecuación de continuidad, que establece que el caudal es constante a lo largo de todo el circuito hidráulico:

donde formula_14 es el área de la sección del conducto por donde circula el fluido y formula_13 su velocidad media. 

En el caso de fluidos compresibles, donde la ecuación de Bernoulli no es válida, es necesario utilizar la formulación más completa de Navier y Stokes. Estas ecuaciones son la expresión matemática de la conservación de masa y de cantidad de movimiento. Para fluidos compresibles pero no viscosos, también llamados fluidos coloidales, se reducen a las ecuaciones de Euler.



</doc>
<doc id="4602" url="https://es.wikipedia.org/wiki?curid=4602" title="Pinyin">
Pinyin

El hànyǔ pīnyīn (), o deletreo Han, normalmente llamado pinyin, es un sistema de transcripción fonética del chino mandarín ("hànyǔ") y está reconocido oficialmente en la República Popular China. Cambia el uso de los caracteres tradicionales chinos de conceptual a fonética. Esto es, se usa la escritura latina para transcribir fonéticamente el idioma chino. Aunque siendo una ayuda para el aprendizaje, según críticos, obvia aspectos inherentes del mismo que pueden distorsionar su comprensión. No hay duda de que este sistema ayuda a quienes no conocen la escritura china a pronunciar las palabras chinas y también se utiliza para introducir caracteres chinos en teclados QWERTY a través de programas específicos para ello (véase métodos informáticos para escritura china).

En 1979, la ISO adoptó el pinyin como el sistema de romanización estándar del chino.

El "hànyǔ pīnyīn" se ha consolidado como el principal sistema de transcripción del chino en la época actual, pero no es sino uno más de muchos sistemas existentes (véase sistemas de transcripción del chino).

El sistema pinyin posee un complejo sistema de diacríticos para marcar los tonos, que se describe más abajo. Para su correcta escritura no se debe omitir ningún signo. También hay reglas que determinan si dos o más palabras deben ser escritas juntas o separadas.

El pinyin fue creado por el intelectual chino Zhou Youguang, llamado «el padre del Pinyin», como parte de un programa iniciado en la década de 1950 por el gobierno de China para convertir el mandarín en la lengua nacional de China, simplificar los caracteres e idear un nuevo alfabeto fonético. Zhou estaba trabajando en un banco de Nueva York cuando volvió a China para ayudar a reconstruir el país después de la victoria del Partido Comunista Chino (PCR) y su acceso al poder en 1949. Zhou fue profesor de economía en Shang'hái. En el año 1954 el Ministro de Educación de China creó el Comité para la Reforma de la lengua escrita china. Zhou trabajó en el desarrollo de un nuevo sistema caligráfico romanizado que permitió erradicar el analfabetismo en China. Zhou señaló años después que no era el padre del pinyin. «Soy el hijo del pinyin, que es el resultado de una larga tradición que se inicia en los últimos años de la dinastía Qing. Hemos estudiado el trabajo hecho y lo hemos mejorado».

La utilidad principal del pinyin es la transcripción del chino al alfabeto latino. Al mismo tiempo trata de ser un sistema de escritura fonémico (una letra, o un dígrafo, por fonema) del chino mandarín.

Taiwán ha estado en proceso de adoptar el pinyin. En sus escuelas primarias se ha utilizado el sistema zhuyin, y no hay un sistema de romanización oficial, a pesar de los múltiples esfuerzos. A finales de los noventa, el gobierno de Taiwán decidió remplazar el sistema zhuyin por el sistema pinyin. Esto ha originado una discusión de qué sistema utilizar, si el "hànyǔ pīnyīn" o el "tōngyòng pīnyīn".

Esta controversia es paralela con las tensiones políticas entre los partidarios de la independencia de Taiwán (que apoyan el uso del sistema "tōngyòng pīnyīn") y los de la reunificación con China o mantenimiento del "statu quo" (partidarios del "hànyǔ pīnyīn", el utilizado en China continental).

En octubre de 2002, el gobierno de Taiwán eligió el sistema "tōngyòng pīnyīn" como oficial. Sin embargo, los gobiernos locales tienen derecho a elegir si aplican o no esta orden administrativa en su territorio, y las localidades bajo el mando del Kuomintang han elegido utilizar el sistema "hànyǔ pīnyīn".

El objetivo principal del pinyin en las escuelas chinas es enseñar la pronunciación del Mandarín (lengua oficial de China) a hablantes de otras lenguas chinas. En Occidente hay quien cree que el pinyin se utiliza para que los niños asocien los caracteres chinos con las palabras que ya saben decir. Esto es falso. No todos los chinos hablan mandarín como lengua materna. Algunos chinos aprenden su pronunciación en la escuela, con ayuda del "pinyin".

Cada carácter chino habitualmente representa una sílaba. Por ejemplo "Yo soy mexicano" se escribe con seis caracteres, es decir con seis sílabas (Wo3 shi4 mo4 xi1 ge1 ren2):

La sílaba en mandarín tiene dos partes, una inicial (en azul en el ejemplo) y una final (en rojo). El verde indica el tono (el mandarín tiene cuatro tonos y un tono neutro, que no se escribe).

El primer cuadro de abajo muestra las partes iniciales y el segundo cómo se leen las vocales y las lecturas especiales de algunas partes finales:

El chino mandarín es un idioma tonal. Los tonos se marcan mediante el uso de acentos gráficos sobre una vocal no medial.


Como muchos tipos de letra utilizados en un ordenador carecen de acentos como el guion o el circunflejo invertido, una convención común es indicar el número correspondiente al tono justo después de cada sílaba (por ejemplo, "tóng" (tong con el tono ascendente) se escribiría "tong2"). El dígito se numera en el orden que se indica arriba, con una excepción: el "quinto tono", además de tener el número 5, puede no indicarse o indicarse con un 0, como en la partícula interrogativa "ma0" (吗/嗎). 

Las vocales pinyin se ordenan en el siguiente orden: "a, o, e, i, u, ü". En general, la marca tonal se coloca en la vocal que aparece antes en el orden indicado. "Liú" es una excepción superficial cuya auténtica pronunciación es "lióu", y como la "o" precede a la "i", se marca la "óu" (que se contrae a "ú").




</doc>
<doc id="4607" url="https://es.wikipedia.org/wiki?curid=4607" title="Lenguas quechuas">
Lenguas quechuas

El quechua o quichua es una familia de idiomas originarios de los Andes centrales que se extiende por la zona occidental de América del Sur a través de seis países. La cantidad de hablantes de lenguas quechuas se estima entre ocho a diez millones.

Esta familia lingüística se habría originado en un territorio que se correspondería con la región central y occidental de lo que actualmente es Perú. En el siglo V, se separaron las dos ramas de la familia. Hacia el siglo XV, la llamada "lengua general" se convirtió en una importante lengua vehicular y oficial por el Estado incaico. Esta variante fue la lengua más importante empleada para la catequesis de los indígenas durante la administración española. En el siglo XX, el castellano sobrepasó al quechua como lengua mayoritaria en el Perú. El quechua sureño, descendiente de la lengua general colonial, es la lengua quechua más extendida, seguido del quichua norteño (de Ecuador, Colombia y Loreto) y del quechua ancashino. En la década de 1960, estudios dialectológicos determinaron la existencia de lenguas separadas dentro del quechua.

Las lenguas quechuas tienen una morfología aglutinante, con raíces regulares y repertorios amplios de sufijos productivos, que permiten formar palabras nuevas de forma regular. Entre sus rasgos gramaticales, se distingue la fuente de la información o evidencialidad, varios casos nominales, un "nosotros" inclusivo y otro excluyente, el beneficio o la actitud del hablante al respecto de una acción, y opcionalmente el tópico. Los verbos transitivos concuerdan con el sujeto y el objeto. Expresan predicaciones nominales yuxtaponiendo el sujeto y el atributo. A diferencia del español, el quechua funciona sin artículos o conjunciones y sin distinguir géneros gramaticales. Aunque varias de estas características son mayormente conservadas, ciertas variedades han perdido de algunas de las características mencionadas durante su desarrollo histórico.

De los datos conseguidos a la fecha, se sabe que las lenguas quechuas no tenían autoglotónimos o al menos no existen registros de que así haya podido ser. Por el contrario, es a partir de los estudios y de las crónicas de la época de la Conquista que se les da nombres a las lenguas del mosaico lingüístico que constituía el Virreinato del Perú del siglo XVI. Algunas frases se emplearon para designar a la lengua con la cual los gobernantes del Antiguo Perú se entendían con el Estado incaico, siendo la más temprana registrada la de "lengua general". Sin embargo, en la región andina no solo el quechua clásico recibió dicho epíteto, sino también más tarde el aimara, el puquina y el mochica.

El nombre de quechua es empleado por primera vez por fray Domingo de Santo Tomás en su "Grammatica..." así como el origen de la expresión, también citado por Cieza de León y Bernabé Cobo: al ser preguntados los orejones por los cronistas por el origen de la llamada "lengua general", estos respondían ser originaria de la nación quichua, que habitaba en lo que es hoy la Provincia de Andahuaylas. El vocablo variante "quechua" comenzó a emplearse hacia mediados del siglo XVII. Tanto "quichua" como "quechua" provienen de algún cognado de la originaria ('valle templado'), que es empleada para aquellos valles de clima benigno.

En muchas variantes, como en el quechua sureño, este cognado muestra una consonante uvular que, cuando aparece delante de /i/, ya sea oclusiva o fricativa, provoca una alófono [e] en esta vocal. A las regiones que guardan esta alofonía suele corresponder el quechuismo "quechua". En algunas otras, la transformación de la original */q/ en consonantes no uvulares provoca la pérdida de la alofonía en las vocales, por lo que a estas variantes suele corresponder más bien el nombre de "quichua". Sin embargo, hay algunas salvedades, como en Santiago del Estero, donde se usa el nombre "quichua", y algunas zonas donde no se emplea el autónimo.

El autoglotónimo "runa simi" («lengua de gente») está extendido en algunas variedades del quechua sureño. Luego de la Conquista, el término "runa" sufrió una aculturación, ya que se tergiversó su sentido original de «ser humano» y se usó para designar a los nativos en contraposición a "wiraqucha", que se usó para designar a los españoles. Es así que "runa simi" se puede traducir como "lengua de indígenas", es decir, cualquier lengua nativa, para diferenciarlas del español ("kastilla simi"; "misu simi").

Otra interpretación posible es que la expresión "runa" haga referencia a categorías de la administración pública: el runa es el indio tributante, independientemente de si es quechua o no. Una razón potente en favor de esta hipótesis es la existencia de una expresión similar para las lenguas de la familia aimara: El glotónimo "jaqaru" procede de "jaqi" + "aru", con un significado idéntico.

No existen referencias tempranas ni tardías dentro de las crónicas españolas del uso de epíteto similar a "runa šimi" para designar a alguna lengua en particular, sino como referencia simplemente de que la lengua en mención era hablada por los indígenas. Una de las primeras referencias, citada por Cerrón-Palomino (2008), es la del quechuista Middendorf, apenas en 1891.

En ambos dialectos colombianos se le llama "inka shimi" («idioma de los incas») por ser los incas quienes lo llevaron a aquellas latitudes, mientras que en la periferia de Huancayo, el quechua huanca es llamado como "wanka shimi", es decir, "lengua de los huancas", y no se emplea por los vernáculos ni "nuna shimi" ni "qichwa shimi"

Los primeros estudios conocidos de la lingüística quechua se dieron a inicios del Virreinato del Perú. Los misioneros católicos emplearon este y otros idiomas locales para evangelizar a los indígenas, para lo cual se escribieron varios manuales ("artes") y diccionarios ("vocabularios") de estos idiomas, como el aimara, el mochica o el guaraní, así como catecismos.

Fray Domingo de Santo Tomás O.P., fraile dominico que según su propio testimonio llegó al Perú en 1540, fue el primer misionero que aprendió la lengua de la región central de Perú durante su tarea evangelizadora; predicando luego en su propia lengua a los nativos de los actuales Departamentos de La Libertad, Ancash, Lima, Ica, Apurímac, Huancavelica, Ayacucho, Junín y Huánuco. En 1560, como fruto del conocimiento de la lengua de los naturales, publicó en Valladolid las dos primeras obras en quechua, la "Gramática o arte de la lengua general de los indios de los reinos del Perú", y el "Lexicón o vocabulario de la lengua general del Perú", por Fray Domingo.

El diputado limeño Juan de Balboa fue el primer catedrático de lengua quechua (lengua quichua), cuando se organizó la Universidad de San Marcos en 1576, y el primer peruano que en ella se graduó de doctor. Posteriormente, en 1608 Diego González Holguín (1552 -1618) publicó el "Vocabvlario de la lengua general de todo el Perv llamada qquichua o del Inca".

En la segunda mitad del siglo XX, se dieron los primeros estudios científicos modernos del quechua. Los lingüistas Alfredo Torero y Gary Parker publicaron los primeros estudios sobre el tema, secundados por Rodolfo Cerrón Palomino, Félix Quesada, Antonio Cusihuamán, Clodoaldo Soto Ruiz, Amancio Chávez, Francisco Carranza, entre muchos otros, y el literato José María Arguedas. Entre los lingüistas extranjeros también se publicaron estudios importantes, como los de Willem Adelaar, Gerald Taylor, César Itier, Wolfgang Wolck, Pieter Muysken y otros más. Sin embargo, es también la época del progresismo en los Andes, donde las lenguas originarias, así como sus costumbres, eran vistas como derroteros del desarrollo de las naciones, por lo cual la incipiente educación rural se dirigió a la directa sustitución de las mismas por el castellano. El trabajo del Instituto de Estudios Peruanos y el impulso de Alberto Escobar y la publicación de sendos diccionarios de seis variedades del quechua y de sus respectivas gramáticas. Al respecto, Escobar dice 

El quechua no presenta vínculos genéticos demostrados con otras familias de lenguas. Anteriormente se vertieron algunas hipótesis que fueron posteriormente descartadas, como la propuesta de las familia amerindia de Joseph Greenberg (1987), que situaba al quechua dentro de la rama Andina del tronco andino-chibcha-paezano.

Aunque la tesis de una relación genética entre el quechua y las lenguas aimaras se halla también descartada, el consenso de los especialistas acepta una antigua relación de mutua influencia entre las protolenguas de estas familias. Parte importante del léxico de estas familias es compartido y se desconoce de cuál de ambas han provenido. De esta forma, tras un largo periodo de contacto, el protoquechua aparece a inicios del I milenio en la parte centro-occidental del Perú. El protoquechua divergió en dos ramas hacia el siglo V: el Quechua I inicia una nueva expansión en dirección norte a través de la vertiente oriental hasta el Callejón de Huailas y el Quechua II se expande en dirección sur por la sierra de la vertiente pacífica.

En el siglo XIII acontecía la expansión más reciente del quechua, impulsada a consecuencia del comercio del reino de Chincha, que produjo la adopción del quechua clásico como lengua franca en gran parte del Antiguo Perú y en lo que modernamente es la sierra ecuatoriana, empleada por los curacas de pueblos diversos para comunicarse entre gobernantes independientes para el intercambio de productos. Este avance condujo a la adopción del quechua en la sierra y la Amazonía ecuatoriales, por un lado, y hacia la sierra sur sobre territorio de habla aimara. Finalmente, la variante ecuatoriana divergió del habla del sur, produciéndose la última escisión de la familia quechua. Sin embargo, en varias regiones eran solo los curacas quienes conocían el quechua, mientras que el pueblo llano continuaba usando sus lenguas propias, como era el caso de la región mochicahablante. En medio de este proceso, cuando los incas iniciaron la conquista del Chinchaysuyo, adoptaron esta lengua para sus asuntos administrativos, si bien ellos también eran aimarahablantes, e impusieron su aprendizaje en las diversas provincias de su imperio, sin que esto significara que dejaran de lado las lenguas vernáculas. Algunos pueblos de la selva que mantuvieron contacto comercial con los incas resultaron también influenciados por el quechua.

Durante el Virreinato del Perú, los misioneros católicos emplearon este y otros idiomas locales para evangelizar a los indígenas; se escribieron varios manuales ("artes") y lexicones de este y otros idiomas importantes, como el aimara, el mochica o el guaraní, así como catecismos. Ello la expansión de del quechua a otros pueblos andinos e amazónicos.

Los estudios dialectológicos seminales de los lingüistas Gary Parker (1963) y Alfredo Torero (1964) clasificaron las variedades de la familia lingüística quechua en dos subfamilias o ramas. Una de estas ramas es el llamado "Quechua I" en la nomenclatura de Torero o "Quechua B" según Parker. Esta rama comprende las variedades distribuidas en la sierra central y norcentral del Perú, por ambas vertientes de la cordillera de los Andes, dentro de las jurisdicciones de los departamentos peruanos de Lima, Junín, Pasco, Huánuco y Ancash. La otra rama es la denominada "Quechua II" (Torero) o "Quechua A" (Parker). Se expande por el norte entre el suroeste de Colombia, Ecuador y el norte de Perú, mientras que por el sur se expande entre el Perú meridional, Bolivia y el noroeste argentino, con probables hablantes en la región próxima de Chile. Torero articuló en su trabajo una subdivisión tripartita del grupo Quechua I. 


En una reciente revisión, Adelaar recuerda que la posición taxonómica del grupo Quechua II A fue cuestionada por el propio autor y reconsiderada a la luz de posteriores investigaciones en la zona de Yauyos. El quechua de Pacaraos, por consideraciones principalmente morfológicas se considera como una rama del Quechua I, divergente del resto de quechuas centrales, mientras que las variedades restantes del II A inicial de Torero se consideron como separaciones tempranas del proto-Quechua II, anterior a una probable bifurcación entre Quechua II B y Quechua II C.

En el subgrupo Periférico (II, B, Wampuy), encontramos zonas alta y medianamente definidas de dialectos inteligibles. Caso destacable es la subrama Chinchay meridional, donde todas las variantes son inteligibles, caso similar al Chinchay septentrional. Dentro de las Yungay (QIIa), los dialectos de Cañaris y Cajamarca se intercomunican fácilmente; mientras que las otras dos variantes Laraos y Lincha se intercomunican con diferentes variedades de otras ramas, como se verá más adelante.

En la subfamilia Central (I, A, Waywash), el panorama es más complejo: las hablas del sur del departamento de Junín (Jauja y Huanca) son mutuamente inteligibles a pesar de la divergencia, mientras que las hablas al norte de este sector (incluida la de Pacaraos, del QIIa) conforman un enmarañado continuo dialectal, es decir, la intercomprensión de las variantes es relativo a la distancia entre las mismas. Las hablas de las provincias de Yauyos y Chincha (tanto Waywash como Yungay) son inteligibles a pesar de pertenecer a grupos tan distintos.

El lingüista Alfredo Torero, además, propuso una agrupación de las múltiples variedades empleadas en el Perú en siete "supralectos" o lenguas según su inteligibilidad mutua:

El quechua yauyino está compuesto por dialectos de ambas ramas del quechua que son mutuamente inteligibles a pesar de sus divergencias.

El Instituto Lingüístico de Verano ha catalogado la familia como "macrolengua", categoría creada por esta institución para describir aquellos linajes que por razones políticas o sociales son consideradas como si fueran un solo idioma en contra de la evidencia lingüística. Paralelamente, indexa 42 variantes como idiomas individuales, al margen del grado de inteligibilidad mutua.

No existe actualmente una lengua estándar (caso del árabe) o sistema escrito común (como en el chino) que utilicen los usuarios de lenguas ininteligibles para comunicarse: antes recurren al español, si lo conocen.

A nivel oficial, la constitución política del Perú habla del quechua como de un solo idioma; sin embargo el Ministerio de Educación emite libros distintos para al menos seis variedades lingüísticas (Áncash, Ayacucho, Cajamarca-Cañaris, Cuzco, Junín, San Martín). En Bolivia se utiliza en la educación y en textos oficiales un solo "Quechua Normalizado" (sureño) y en Ecuador un "Kichwa Unificado". Todas las variedades habladas en estos dos países son mutuamente inteligibles.

Divergiendo del conceso de los especialistas, la llamada Academia Mayor de la Lengua Quechua afirma que el quechua es un solo idioma, con el quechua cuzqueño como dialecto estándar y las demás variantes como "deformaciones" de la misma.

Posteriormente a la convergencia formativa de las familias quechua y aimara, el quechua continuó teniendo una intensa relación de contacto lingüístico con la familia lingüística aimara, sobre todo las variedades meridionales. En muchas regiones el quechua llegó con el tiempo a sustituir al aimara. De hecho, muchas de las características del quechua IIC parecen deberse a que muchas de estas variedades se formaron sobre un substrato aimara.

Además, el quechua ha estado históricamente en contacto con lenguas amazónicas como el asháninka además de otras lenguas de las familias arawak y pano. En la cuenca del Marañón el quechua reemplazó completamente un número importante de lenguas preincaicas. En el sur el imperio incaico se extendió hasta el domino lingüístico del mapudungun, el cacán y las huarpe.

El quechua también influenció en el español, aportando muchos quechuismos para describir las nuevas realidades que conocieron los conquistadores. Análogamente, la lengua castellana ha dejado también préstamos en varias lenguas quechua. Posteriormente, el bilingüismo español-quechua en los Andes ha dado lugar a la incorporación de fonemas oclusivos sonoros en el Quechua II, y por otro lado a la formación del español andino.

Las lenguas quechuas se hablan en un amplio rango geográfico de forma discontinua en la zona occidental de América del Sur, desde el suroeste de Colombia hasta el Norte argentino.

Entre el suroeste de Colombia, Ecuador y el extremo norte de la Amazonía del Perú, predomina el llamado quichua norteño o ecuatoriano. Este conjunto diverso se extiende desde regiones discretas de los departamentos de Nariño, Putumayo y Cauca (Colombia) hasta las vertientes septentrinales del río Amazonas en el departamento de Loreto (Perú), pasando por gran parte de la Sierra y del Oriente ecuatorianos.

Dos variedades relacionadas al quichua norteño se hablan en los departamentos peruanos de Amazonas y San Martín. El quechua chachapoyano se emplea en la montaña amazonense mientras que el quechua lamista se emplea en las vertientes de los ríos Mayo y Sisa. Al oeste, el quechua cajamarquino se extiende por los alrededores de la ciudad de Cajamarca, en localidades como Chetilla y Porcón. La variedad de Incahuasi-Cañaris, inteligible con la variedad cajamarquina, se extiende el noreste por los distritos andinos de Incahuasi y Cañaris (Lambayeque) y cercanías en las provincias de Cutervo y Jaén (Cajamarca), además de un pueblo alejado en la vecina provincia de Huancabamba (Piura)

En la Sierra central del Perú se ubican principalmente lenguas de la rama Quechua I. Estas conforman un continuo dialectal esparcido entre los departamentos de Áncash y Huánuco por el norte, y los de Junín, Huancavelica e Ica por el sur, incluyendo los departamentos de Pasco y Lima.

La lengua más ampliamente hablada de estas regiones es el quechua ancashino, hablado en el extremo norte (Ancash y noroeste de Huánuco). El llamado quechua huanca o simplemente huanca se habla en las provincias de Huancayo, Chupaca y Concepción en el departamento de Junín. Al sur, en el departamento de Lima, dos dialectos Quechua II comparten su ámbito con las variedades de Quechua II de la provincia de Yauyos; una se ubica en el distrito de Laraos y el segundo se halla al sur de la provincia.

El "macrolecto" más extendido de la familia quechua, el quechua sureño, se habla entre el sur del Perú y el norte de Argentina formando tres regiones separadas. La primera incluye la Sierra sur del Perú entre el departamento de Huancavelica y los de Puno y Moquegua, proyectándose en una pequeña región al norte del departamento de La Paz. Está región está separada de otra más al sur por el dominio lingüístico del aimara, segunda la cual se extiende en el centro y el suroeste de Bolivia por los departamentos de Cochabamba, Chuquisaca y Potosí además de partes limítrofes de otros departamentos, y en el norte argentino en las provincias argentinas de Jujuy , Salta, Tucumán. Por último, el quichua tiene una distribución "semi-aislada" en la región del centro-oeste de la Provincia de Santiago del Estero, que es el llamado "quichua santiagueño".

Las sílabas de las lenguas quechuas se componen como mínimo de una vocal como núcleo. Por regla general, aceptan una consonante en posición de ataque y coda (principio y fin de sílaba, respectivamente); no obstante, los préstamos más recientes pueden aceptar hasta dos consonantes en ataque, especialmente con consonantes líquidas. La entonación y la acentuación tienen roles menores.

Se distinguen tres fonemas vocálicos: una vocal abierta y las cerradas redondeada no redondeada . Además, los quechuas centrales distinguen dos cantidades vocálicas: vocales cortas y largas . La pronunciación precisa de estos fonemas vocálicos varía con su entorno fonético. La vecindad de una consonante uvular produce alófonos más centralizados como , , , , y la de la semiconsonante palatal también provoca un adelantamiento de a . Se produce la monoptongación de grupos como y en el quechua de Chachapoyas, así también en algunas variantes del quechua ancashino, donde también se afecta el grupo .

En cuanto a las consonantes, se presenta una alta diversificación producto de diversos cambios diacrónicos han afectado este inventario original. El protoquechua habría contado con tres nasales cuatro oclusivas , dos africadas , tres fricativas , dos aproximantes y dos o tres líquidas . La fricativa retrofleja se hizo fricativa postalveolar sorda desde muy antiguo, conservándose solo en el huanca.

El inventario consonántico del protoquechua pasó por importantes reducciones más de una vez en su proceso de desarrollo. La glotal inicial desapareció en el Quechua I y en el quechua de Cajamarca e Incahuasi-Cañaris. Algunos consonantes se fundieron, como la oclusiva uvular con la velar en el QIIB y las sibilantes en el QIIC; ambos grupos además fundieron las africadas en una sola postalveolar, al igual que el quecha del Huallaga, con excepción del quechua de Chachapoyas y el del Pastaza. En esta última, la africada retrofleja, fue adelantada hasta la posición alveolar .

Por otro lado, se registran al menos dos expansiones o adiciones mayores del conjunto de consonantes. Por el contacto prolongado con el castellano, se han incorporado plosivas sonoras como , y , allí donde el quechua originalmente distinguía entre sonoras y sordas, además de la fricativa retrofleja entre los principales préstamos, como en "bindiy" (vender), "Diyus" (Dios) o "karru" (carro). En el quechua sureño, por muy probable influencia del aimara y salvo la variante ayacuchana, se añadieron eyectivas y aspiradas al repertorio fonémico de oclusivas y a la africada.

Un cambio reciente importante en el Quechua I ha afectado la articulación de las africadas. La postalveolar se adelantó hasta una alveolar en gran parte del norte y centro de este continuo dialectal. Posteriormente, algunas áreas adelantaron también la retrofleja a la posición postalveolar dejada por el cambio precedente. Algunas variantes, como el quechua de Cajatambo, pasaron inclusive por una desafricación de la nueva alveolar, coincidiendo con una previa glotalización de la sibilante alveolar .

Largamente se viene debatiendo acerca del empleo prehispánico de algún método de escritura andina. Se ha propuesto que los quipus y los tocapus podrían ser un sistema de escritura, pero existen demostraciones generalmente aceptadas. 

Los primeros españoles (principalmente cronistas y evangelizadores) así como los aborígenes buscaron graficar el(los) quechua, principalmente en quechua clásico y en formas tempranas de la variante cuzqueña, empleando el alfabeto latino; esta situación generó múltiples grafías para distintos fonemas y viceversa. Sin embargo, las lenguas quechua permanecieron como esencialmente orales hasta muy entrado el siglo veinte.

El 29 de octubre de 1939, se da uno de los primeros intentos de graficación del quechua aun bajo el paradigma de un solo idioma. En esta ocasión, es aprobado un alfabeto para las lenguas indígenas americanas que consta de 33 signos durante el XXVII Congreso Internacional de Americanistas, en Lima (Perú).

El 29 de octubre de 1946, el Ministerio de Educación del Perú aprueba el Alfabeto de las Lenguas Quechua y Aimara, con 40 signos utilizables en las cartillas de alfabetización rural que proyectaba dicha institución.

En la semana del 2 al 13 de agosto de 1954, durante el III Congreso Indigenista Interamericano, realizado en La Paz, se creó el "Alfabeto fonético para las lenguas quechua y aimara", basándose en los acuerdos de los dos congresos anteriores, realizados en Pátzcuaro (1940) y Cuzco (1949).

El 16 de octubre de 1975, a finales del gobierno militar de Juan Velasco Alvarado, el Ministerio de Educación peruano nombra una Comisión de Alto Nivel para implementar la Ley de Oficialización de la Lengua Quechua. Esta informa y recomienda el Alfabeto Básico General del Quechua, aprobado por el ministerio mediante la , cuyas letras eran a, aa, ch, e, h, i, ii, k, l, ll, m, n, ñ, o, p, q, r, s, sh, t, tr, ts, u, uu, w, y. Diez años más tarde, mediante Resolución Ministerial Nº 1218-85-ED, el alfabeto oficial suprimió las letras e y o; se usan sólo tres vocales, a, i y u, que corresponde a la fonología del quechua. Sin embargo, la Academia Mayor de la Lengua Quechua en el Cuzco todavía promueve una versión del alfabeto quechua cusqueño con las cinco vocales del español.

Los números dígitos y el diez, no se señala el cero, en diferentes lenguas quechuas son:

En la tabla anterior se han empleado los símbolos del Alfabeto Fonético Internacional.

Las lenguas quechuas son aglutinantes y las reglas para la formación de palabras se conservan bastante bien. Los morfemas son altamente regulares, no suelen variar debido al entorno en donde se insertan. Las palabras se componen de tan solo dos tipos de morfemas: raíces y sufijos. Existen raíces independientes, que forman una palabra completa sin ser modificadas, y existen también las dependientes de sufijos para este fin. Los sufijos son de dos tipos: derivativos, que modifican el significado de los lexemas, y flexivos, que determinan los paradigmas de los rasgos gramaticales. Algunos sufijos son enclíticos, los cuales pueden unirse al final de cualquier palabra de la oración. Los sufijos son altamente productivos, pues conforman significados predictibles por el interlocutor.

Las lenguas quechuas se caracterizan por preferir un orden SOV variable, las palabras que cumplen una función adjetivos y las cláusula relativas anteceden siempre al nombre que modifican (lengua centrípeta). El alineamiento morfosintáctico suele ser de tipo acusativo, marcando el objeto directo con sufijos cognados de *"-kta". La frase posesiva completa se conforma anteponiendo el poseedor al poseído y marcando respectivamente con sufijos de caso genitivo y personal relativo.

La evidencialidad se conserva como rasgo gramatical en toda la familia. Así, se distingue siempre entre información presencial, reportada, conjeturada e inferida. Esta categoría se expresa en la forma de enclíticos o partículas que pueden ser libremente añadidas a virtualmente cualquier palabra del enunciado.

Por otro lado, el protoquechua habría contado con cuatro personas gramaticales definidas simultáneamente por la inclusión del hablante y la del oyente. El número no habría estado gramaticalizado inicialmente. Este sistema se mantiene en el quechua de Pacaraos y se trasluce en las demás variantes.
Posteriormente, aparecieron diversas marcas gramaticales verbales y nominales para los plurales, superponiéndose al esquema inicial. Con este cambio, el sistema pronominal vira a uno de siete personas: tres personas en singular, dos en primera persona plural (incluyente y omitente) y plurales de segunda y tercera persona. Además, la diferencia entre las dos primeras personas plurales ha desaparecido en el quichua norteño.

El número no parece haber tenido mayor relevancia hasta el advenimiento de la Conquista española. Otros rasgos gramaticales, como el género, no han ingresado a las lenguas quechuas. Solo la definitud se agregó al huanca mediante el sufijo -"kaq", derivado del agentivo del verbo "ka"- (‘haber’).

La morfología verbal es riquísima en esta familia. Las lenguas quechuas cuentran con repertorios amplios de sufijos derivativos. Estos se unen directamente a la raíz en cantidades virtualmente ilimitadas, formando nuevos temas. El protoquechua tuvo cuatro sufijos verbales que expresan dirección: "-rku-" (‘hacia arriba′), "-rpu-" (‘hacia abajo′), "-yku-" (‘hacia adentro’) y "-rqu-" (‘hacia afuera’). Solo en el quechua I y en el caso de los sufijos de dirección vertical se han conservado productivos, mientras que en otras instancias se presentan fosilizados o ausentes.

Los temas verbales son dependientes de sufijos flexivos de modo y tiempo, los cuales son específicos de la persona gramatical del sujeto de la oración. Los verbos quechuas concuerdan tanto con el sujeto como con el objeto directo cuando son transitivo, habiendo excepciones en el quichua ecuatoriano, región donde se ha perdido la conjugación binominal.

En cuanto al modo, se distingue la flexión del imperativo de la del indicativo con conjuntos distintos de sufijos. El quechua distingue típicamente dos tiempos: futuro y no futuro. Un verbo en el modo no futuro se puede especificar para el pasado mediante el sufijo *-"rqa". Muchas veces, el aspecto se marca mediante sufijos derivativos.

La gran mayoría de raíces nominales son morfológicamente independientes; esto es, no necesitan sufijos para formar una palabra completa. Ejemplos de excepciones son los pronombres relativos como "kiki"- (‘uno mismo’) o "llapa"- (‘todos’), que requieren sufijos posesivos para ser completos. Véase la forma ancashina "llapantsik" (‘todos nosotros’). Los sustantivos y adjetivos formados no presentan diferencias. Un nombre modifica a otro anteponiéndosele directamente. Juntos conforman una frase nominal que tiene su núcleo en la palabra final. Pueden anteponerse modificadores indefinidamente.

La flexión nominal admite sufijos posesivos específicos de cada persona gramatical, seguidos típicamente de un sufijo de plural opcional como -"kuna"; sin embargo, el orden se invierte en el quichua santiagueño. En tercer lugar van los sufijos de caso. Las frases nominales se flexionan añadiendo los sufijos solamente a su núcleo. Una frase sin sufijo de caso se considera nominativo. Los sufijos de caso acusativo (*-"kta"), lativo (-"man"), instrumental (-"wan"), comitativo (-"ntin"), genitivo (-"pa", salvo -"pi" en Laraos), benefactivo (-"paq") y causativo (-"rayku") son conservados en toda la familia quechua. Existen además sufijos de caso en los que se presentan variación, como el locativo (*-"ćhaw", -"pi", -"pa", "-man"), el ablativo (-"piq", -"pita", -"manta", -"paq", -"pa"), el prolativo (-"pa", -"nta"), el terminativo (*-"kama", -"yaq") y el comparativo (*-"naw", -"hina", -"yupay").

Actualmente el quechua es lengua nacional oficial en el Perú, Ecuador y Bolivia. También se habla sin ser oficial a nivel nacional en regiones limítrofes de Argentina y Chile. Las constituciones de Colombia, de Ecuador y del Perú estipulan a sus respectivas lenguas indígenas –entre ellas el quechua o quichua– como segundas lenguas oficiales después del español ("oficiales en las zonas donde predomina" u "oficiales en su territorio"). En Chile y en Argentina carecen de este reconocimiento oficial.









</doc>
<doc id="4610" url="https://es.wikipedia.org/wiki?curid=4610" title="Álvaro del Amo">
Álvaro del Amo

Álvaro del Amo y de Laiglesia (Madrid, 1942) es un guionista y dramaturgo, director de cine y de teatro, crítico musical y novelista español.
Su labor como autor teatral está en parte inédita, pero en sus montajes ("Geografía", 1985 y "Motor", 1988) se aprecia una traslación del lenguaje y la estética cinematográfica a la escena. Es el suyo un teatro que funde la realidad y la ficción, la vida y la apariencia, en un tono escéptico e irónico.

Como narrador, se inicia con "Mutis" (1980, La Gaya Ciencia). Otras obras suyas son "Libreto" (1985), "Contagio" (1991), "El horror" (finalista del premio Herralde en 1993), "Incandescencia" (colección de relatos, 1998) y "Los melómanos" (2000). Fue también guionista de "Amantes", de Vicente Aranda, obra que lleva a la escena en 2014 en el teatro Valle-Inclán de Madrid.




</doc>
<doc id="4611" url="https://es.wikipedia.org/wiki?curid=4611" title="Sergi Belbel">
Sergi Belbel

Sergi Belbel Coslado (Tarrasa, 29 de mayo de 1963) es un dramaturgo, director y traductor teatral español.

Licenciado en Filología Romántica y Francesa por la Universidad Autónoma de Barcelona en 1986. Fue miembro fundador del Aula de Teatro de la Universidad Autónoma de Barcelona. En 1985 recibe el Premio Marqués de Bradomín por "Caleidoscopios y faros de hoy", que se estrena al año siguiente. A partir de ese momento se han sucedido los estrenos, y Belbel ha pasado a convertirse en uno de los valores jóvenes más firmes del país.

Su actividad teatral se amplía al campo de la dirección, y desde 1988 es profesor de Dramaturgia del Instituto del Teatro de Barcelona.

En 1996 obtuvo el Premio Nacional de Literatura en la modalidad de Literatura Dramática y en 2005 fue nombrado director del Teatro Nacional de Cataluña, cargo al que renunció en 2013.

Ha dirigido obras de autores clásicos y contemporáneos, entre otros, de Shakespeare, Calderón, Molière, Goldoni, Beckett, Koltés, Mamet y De Filippo.

Tiene escritas unas veinte obras teatrales escritas, entre las que se destacan "Caleidoscopios y faros de hoy", "Después de la lluvia", "Elsa Shneider", "Tálem", "Caricias" y "La sangre". Ha obtenido entre otros galardones el Premio Marqués de Bradomín (1985), el Premio Nacional Ignasi Iglesias (1987). Varias de sus obras han sido llevadas al cine por el director Ventura Pons.

Aparte de capítulos sueltos de otras series televisivas, escribió "Nissaga l'herència" para TV3. En 2011, participa en el guión de la película "Eva", guión por el que es candidato al Goya.

En 2014, dirige los guiones de la serie "Sin identidad" de Atresmedia.





</doc>
<doc id="4616" url="https://es.wikipedia.org/wiki?curid=4616" title="Bobby Fischer">
Bobby Fischer

Robert James Fischer, más conocido como Bobby Fischer (Chicago, Illinois; 9 de marzo de 1943-Reikiavik, Islandia; 17 de enero de 2008),
fue un gran maestro de ajedrez, campeón mundial entre 1972 y 1975. Obtuvo el título máximo del ajedrez mundial al vencer al soviético Borís Spaski en el denominado «Match del Siglo». Sin embargo, después de lograr el título, no volvió a jugar nunca más en torneos internacionales. Estadounidense de nacimiento, su país dictó orden de busca y captura contra él en 1992 por haber jugado otro encuentro contra Borís Spaski en Sveti Stefan (Yugoslavia, país contra el cual Estados Unidos había decretado un bloqueo) y más tarde revocó su pasaporte. En julio de 2004, Fischer fue detenido en el aeropuerto Narita ―en Tokio (Japón)―, por intentar salir del país utilizando un pasaporte no válido; fue liberado ocho meses después y autorizado a viajar a Islandia, país que acababa de concederle la nacionalidad a pesar del malestar que ello generó en las autoridades de Estados Unidos. Falleció en Islandia tres años después.

Estrictamente hablando, Bobby Fischer no fue un niño prodigio como lo fueron José Raúl Capablanca, Samuel Reshevsky o Arturo Pomar. Su desarrollo al principio fue más bien lento. Hasta los trece años no comenzó a despuntar como un jugador de capacidad superior; antes de esa edad no se apreciaban en sus resultados y su calidad de juego signos de extraordinario talento ajedrecístico. Es exacta la aseveración del árbitro internacional español Pablo Morán en el sentido de que «Como "niño prodigio" no fue muy brillante; en cambio, como "adolescente prodigio" no ha tenido parangón en la historia del ajedrez».

Fue hijo de la enfermera suiza Regina Wender, inteligente y políglota, y del físico de origen alemán Hans-Gerhardt Fischer, aunque existe controversia respecto de si este último fue el padre biológico de Bobby, pues Regina y Hans-Gerhardt no vivían juntos desde 1939.
Se considera casi seguro que su padre biológico fue el físico húngaro Paul Nemenyi, dotado de asombrosa inteligencia de tipo matemático. En cualquier caso, Regina y Hans-Gerhardt no obtuvieron el divorcio hasta 1945; Bobby, que entonces tenía dos años, quedó, junto con su hermana mayor Joan, al cuidado de su madre. En 1949 Regina se trasladó con sus dos hijos a Nueva York, a un pequeño apartamento en Brooklyn. Fischer aprendió a jugar ajedrez por sí mismo a la edad de 6 años,a partir de las instrucciones que venían en un estuche con diversos juegos que le regaló su hermana. Su afición por el ajedrez fue aumentando hasta llegar a la obsesión; su madre, preocupada, le llevó a la consulta de un psiquiatra pero la actitud del chico no varió. En enero de 1951, gracias a un anuncio en el periódico, Bobby participó en una sesión de simultáneas contra el maestro Max Pavey; esa fue su primera aparición pública como ajedrecista, y aunque perdió le sirvió, según confesión propia, para seguir esmerándose en ajedrez. El presidente del Brooklyn Chess Club, Carmine Nigro, fue su mentor de ajedrez, le enseñó los fundamentos de la estrategia y le introdujo en el mundo del ajedrez de competición.

En 1955 ingresó en el Manhattan Chess Club y participó por primera vez en el Campeonato Junior de Estados Unidos, finalizando en décimo lugar. Un año después, en Filadelfia, conquistaría el título juvenil, ganando ocho partidas, empatando una y perdiendo otra. Poco después de esta victoria, Fischer abandonó la Erasmus Hall High School a los 16 años para dedicarse por completo al ajedrez; aducía que estudiar era una pérdida de tiempo. Sus profesores le recordaban como un muchacho difícil. Probablemente tenía un coeficiente intelectual alto (tal vez de 187), aunque era asocial. En 1956, John Collins, que había sido tutor de otros jugadores sobresalientes como Robert Byrne y William Lombardy, le aceptó como alumno. En algunas ocasiones se ha descrito a Collins como una figura paterna para Fischer.

Sobre su partida con Donald Byrne, conocida por algunos como la «partida del siglo» en 1956, el doctor Max Euwe, campeón del mundo entre 1935 y 1937, comentó: «Que un renombrado maestro se confíe demasiado ante un jugador joven en pleno progreso, y sufra por ello una seria derrota, no tiene en sí nada de particular, y en la historia del ajedrez se registran bastantes ejemplos. Mas lo que no sucede todos los días es que un escolar de trece años supere francamente en la combinación a uno de los mejores jugadores de Estados Unidos. Las combinaciones de Fischer no son particularmente profundas, aunque tampoco evidentes».

Cuando Bobby tenía 17 años su madre le abandonó, dejando solo a su hijo en el apartamento de Brooklyn, entregado totalmente al ajedrez.

Su carrera coincide con el encumbramiento de la escuela soviética de ajedrez que, subvencionada por el Estado, dominó la disciplina desde 1948 hasta la desintegración de la Unión Soviética en 1991, con el paréntesis de Fischer; y aun después de dicha desintegración, los jugadores formados en dicha escuela soviética estuvieron en la cima durante años. El campeonato de Estados Unidos de 1957 tuvo para la Federación Internacional de Ajedrez (FIDE) en el sistema de Candidatos al título mundial, categoría Zonal. Bobby, ya campeón juvenil de Estados Unidos y que había terminado noveno en la edición anterior del campeonato absoluto, se alzó con el primer lugar, y se clasificó para el Torneo Interzonal de Portoroz (hoy Eslovenia) del año siguiente, en el que obtuvo el sexto puesto. Un resultado magnífico que le permitió acceder al torneo de Candidatos y obtener de forma automática el título de gran maestro. Muchos jugadores han superado desde entonces el récord de precocidad de Fischer en obtener el título de gran maestro (lo hizo con quince años y medio); cabe señalar, sin embargo, que el estadounidense lo alcanzó con recursos muy limitados, en una época en la que la información ajedrecística, particularmente la que llegaba a Estados Unidos, era mínima; en solitario y sin entrenadores (mientras que los jugadores soviéticos recibían apoyo oficial), y sin el auxilio de potentes programas de juego y bases de datos disponibles para los jugadores actuales. Debieron pasar treinta y tres años para que la húngara Judit Polgár estableciera una nueva marca.

Disputó nueve veces el Torneo Rosenwald de Nueva York, en el que se dirimía el campeonato de Estados Unidos. En su primera participación solo pudo ganar un par de partidas, aunque una de ellas, su victoria ante Donald Byrne de la que ya hemos hablado, lo proyectó a la fama internacional pues se publicó en revistas especializadas prácticamente de todo el mundo. En dicho juego Fischer venció mediante un brillantísimo juego combinativo, aún más sorprendente si se toma en cuenta que apenas contaba con trece años de edad. En sus restantes ocho apariciones obtuvo en todas el título nacional con al menos un punto de ventaja sobre el segundo clasificado. En la edición de 1963 logró además la proeza de coronarse campeón venciendo en todas las partidas; una hazaña sin precedentes pues participaban en el certamen figuras de la talla de Reshevsky, Larry Evans, Pal Benko y Robert Byrne.

Bobby Fischer acudió a cuatro Olimpiadas de ajedrez con el equipo de Estados Unidos. En todas ellas consiguió resultados sobresalientes, incluyendo dos medallas de plata y una de bronce defendiendo el primer tablero de su país. Sus enfrentamientos contra el equipo de la Unión Soviética, cuyo primer tablero generalmente ocupaba el campeón del mundo, produjeron partidas extraordinarias que recogen las antologías. En Leipzig (Alemania), en 1960, empató espectacularmente con el soviético entonces campeón del mundo Mijaíl Tal; al término del juego, Fischer le dijo con sorna al campeón: «No juega usted mal», a lo que Tal respondió: «Es la primera vez que usted lo reconoce, y si me hubiera ganado afirmaría que jugué como un genio».

En Varna (Bulgaria), dos años después, se encontraría con el legendario Mijaíl Botvinnik, al que dominó durante toda la partida aunque este salvaría el empate gracias a la ayuda en el análisis de la posición aplazada de sus compañeros de equipo, especialmente de Efim Geller, alcanzando un final de tablas teóricas en desventaja material. En la Olimpiada de La Habana (Cuba), el equipo de la Unión Soviética reservó al campeón mundial Petrosián, por lo que Fischer se enfrentó al entonces subcampeón Borís Spassky con quien firmaría las tablas después de cincuenta y siete movimientos en una partida que comenzó con la Apertura Española o Ruy López. En su última presentación «olímpica», en Siegen (Alemania), Spassky, ya como campeón mundial, derrotaría brillantemente al gran maestro de Brooklyn. Fischer en total ganó 40 partidas, empató 18 y perdió 7 en la máxima competición por equipos del ajedrez, con un porcentaje de efectividad de 75,4 por ciento.

Aun con su enorme talento y dedicación al juego, el campeonato del mundo habría de esperar algunos años. En el maratoniano torneo de Candidatos 1959, en Yugoslavia (se jugó en tres ciudades: Bled, Zagreb y Belgrado), terminó en quinto lugar, empatado a puntos con Svetozar Gligorić, gran figura del ajedrez internacional; en esta ocasión Fisher perdió sus cuatro partidas con Tal. En 1962, triunfó en el Interzonal de Estocolmo (Suecia), con dos puntos de ventaja sobre Tigrán Petrosián (1929-1984), quien se coronaría campeón del mundo un año después, y Geller. En el torneo de Candidatos de Curaçao (Antillas Holandesas), sin embargo, Fischer terminaría sorprendentemente en un lejano cuarto lugar, detrás de Petrosián, Paul Keres y Geller, y denunciaría en un artículo de revista que los soviéticos jugaban en equipo, asistiéndose, y haciendo tablas fáciles entre ellos para repartirse los puntos y reservarse, con objeto de alejar de los puestos preferentes a otros jugadores. Desde luego, las acusaciones de Fischer no pudieron probarse, pero poco después la FIDE cambiaría las reglas del campeonato del mundo, sustituyendo el sistema del torneo de Candidatos por el de los enfrentamientos individuales.

Fischer se apartó temporalmente del ajedrez profesional durante algunos meses entre 1964 y 1965, se dedicó a dar exhibiciones y no participó en el ciclo de candidatos que culminó con el encuentro por el título mundial entre Petrosián y Boris Spassky en 1966, ni acudió a la Olimpiada de Tel Aviv (Israel). En 1967, no obstante, se presentaría al Interzonal de Sousse (Túnez) en una nueva acometida por el título mundial. Después de diez rondas, Fischer encabezaba la clasificación con un récord impresionante de siete victorias y tres empates, cuando decidió intempestivamente abandonar el torneo, alegando un calendario cargado. La crítica de Fischer parecía injusta pues el torneo se había estructurado, entre otras cosas, para respetar los días de descanso que sus creencias religiosas le imponían. De ese certamen es memorable su partida frente a Reshevsky, pues Fischer apareció en la sala de juego pocos minutos antes de perder por incomparecencia, y con la mitad del tiempo asignado en su reloj derrotó con relativa facilidad a su ilustre contrincante.

Bobby Fischer ganó todos los torneos en los que participó desde el mes de diciembre de 1962 hasta el Campeonato del Mundo de 1972, con solo dos excepciones: el Torneo Memorial Capablanca de 1965 (que se celebró en La Habana y Bobby jugó por teletipo desde Nueva York), en el que quedó empatado en segundo lugar con Borislav Ivkov y Geller, medio punto por detrás del ganador Smyslov; y la Copa Piatigorsky de 1966, en la que ocupó el segundo lugar, un punto y medio detrás de Spassky. En toda su carrera jamás perdió un enfrentamiento individual o match, como se le conoce en la jerga ajedrecística. Derrotó al filipino Cardoso en 1957, y en 1961 dejó inconcluso un duelo con Reshevsky, que quedó en empate después de once partidas, a causa de desacuerdos con los organizadores; en su camino al campeonato del mundo se adjudicó tres victorias inapelables (ante el danés Bent Larsen y los soviéticos Mark Taimanov y Petrosián), y finalmente derrotó a Spassky en el ya mencionado y famoso Match del Siglo. Veinte años después, en 1992, disputó frente a su viejo rival Spassky un encuentro de exhibición, del que hablaremos.

Una de las características que distinguían a Fischer era la rapidez de su juego. En muy contadas ocasiones se veía en apuros de tiempo, pues casi siempre jugaba de manera ágil y muy correcta. No es de extrañar que con su excepcional talento se convirtiera en uno de los mejores jugadores de partidas rápidas (llamadas "blitz", donde cada jugador dispone de cinco minutos para toda la partida). En 1970 se disputó en Herceg Novi (Montenegro, antigua Yugoslavia), el torneo de partidas rápidas más importante celebrado hasta entonces. Fischer triunfó al lograr diecinueve de los veintidós puntos posibles contra rivales de primerísima fila, como los ex campeones mundiales Tal, Petrosián y Smyslov y los exaspirantes David Bronstein y Reshevsky. Solo Fischer y Tal fueron capaces de reproducir de memoria, una vez terminada la competencia, las partidas que habían jugado.

Ese mismo año se llevó a cabo en Belgrado (Serbia, antigua Yugoslavia) el entonces anual encuentro entre la Unión Soviética y el resto del mundo. Bobby Fischer accedió a jugar en el segundo tablero, cediendo el primero a Larsen, que había obtenido mejores resultados en los meses anteriores, pues el estadounidense había permanecido inactivo. Fischer tuvo que enfrentarse a Petrosián, entonces subcampeón mundial, a quien venció convincentemente 3 a 1 (dos victorias y dos tablas), a pesar de haber permanecido alejado de los tableros. En la edición 1971, el estadounidense ganaría por primera vez el Óscar del Ajedrez, distinción que repetiría los dos años siguientes.

En 1972, finalmente, alcanzó el derecho a disputar el Campeonato del Mundo. Obtuvo el primer lugar en el Torneo Interzonal de Palma de Mallorca (Islas Baleares, España) de 1970, en el que ganó quince de las veinticuatro partidas que disputó (las últimas siete del torneo de forma consecutiva), algo verdaderamente inusual tomando en consideración el nivel del torneo. Posteriormente, en el apogeo de su fuerza, arrolló en el ciclo de Candidatos disputado a lo largo de 1971 a los grandes maestros Mark Taimánov (soviético) y Bent Larsen (danés, el único que había logrado derrotarle en el Interzonal del año anterior), por idéntico resultado en sus respectivos enfrentamientos al mejor de 10 partidas: un sonrojante 6 a 0 que, en el caso de Taimánov, le supuso serios problemas con el aparato comunista soviético que lo acusó falta de carácter y de no haber sabido defender la honra patriótica. De hecho, ese resultado causó un enorme revuelo entre las autoridades ajedrecísticas de la Unión Soviética, que no solo acusaron a Taimánov, sino a todo el potente equipo de analistas que lo acompañó durante el encuentro.

Lo excepcional de estos resultados solamente se puede explicar diciendo que el gran talento de Fischer había llegado a su máximo esplendor. Para comprender la magnitud de la hazaña de Fischer, hay que tener en cuenta que, en el ajedrez de alto nivel, el empate es un resultado natural, pues lo normal es que a los contendientes les cueste trabajo romper el equilibrio. Hay que remontarse casi cien años atrás para hallar un resultado similar: en 1876, una época de ajedrez aún rudimentario, el primer campeón mundial Wilhelm Steinitz derrotó por 7 a 0 a Joseph Henry Blackburne, uno de los mejores jugadores de la época, aunque, en ese caso, Steinitz contaba con la gran ventaja de acabar de sentar las bases del ajedrez moderno que le proporcionaba una evidente superioridad sobre el resto de jugadores. En 1971 repetir ese resultado en la alta competición resultaba increíble, y más aún repetirlo dos veces consecutivas.

En la final de Candidatos, Fischer derrotó en Buenos Aires (Argentina) al ex campeón mundial, el soviético Tigrán Petrosián, por 6,5 a 2,5, ganando con ello el derecho a enfrentarse a Spassky con el título mundial en juego. Su cadena de 20 victorias consecutivas (las siete últimas del Interzonal, las de sus enfrentamientos con Taimánov y Larsen y la primera de su encuentro con Petrosian) constituye un auténtico hito en la historia del ajedrez de élite, como también lo es el haber cedido solo 2,5 puntos (una derrota y tres tablas) en las 21 partidas que disputó en las tres eliminatorias del ciclo de Candidatos. Algo que asombraba al mundo ajedrecístico y amedrentaba a sus rivales.

A partir de 1970, la Federación Internacional de Ajedrez adoptó la fórmula del científico húngaro Árpád Élő para estimar la fuerza de juego en el ajedrez. Robert Fischer, a la luz de este sistema, vigente en nuestros días, alcanzó la marca de 2785 puntos, registro que durante mucho tiempo se consideró el mejor rendimiento conseguido por un ajedrecista. Con el tiempo, varios jugadores notables han ido superando la barrera de los 2800 puntos, entre ellos, cinco campeones del mundo, Gari Kaspárov, Veselin Topálov, Vladímir Krámnik, Viswanathan Anand y Magnus Carlsen, así como los grandes maestros Levon Aronian, Alexander Grischuk y Fabiano Caruana. Este hecho por sí solo, sin embargo, no significa que su desempeño haya sido superior al logrado por Fischer años atrás, al menos desde el punto de vista estadístico. Esto se debe al fenómeno conocido como «inflación del Elo».
Los ratings de los jugadores han ido aumentando de manera imperceptible pero sostenida a través de los años, y aunque excede el propósito de este artículo referir las causas del fenómeno en cita, al que constantemente se le busca solución,
es cosa establecida que la evaluación Elo no resulta un criterio fiable para comparar el nivel de ajedrecistas pertenecientes a diferentes épocas. No obstante hay que reconocer, siendo justos, que el nivel general de los maestros de ajedrez en los tiempos modernos ha aumentado considerablemente, lo que hace más difícil ascender en el «escalafón».

Con independencia de cómo pueda medirse la potencia de un ajedrecista, Fischer fue, sin duda, un jugador excepcional. Su estilo no es fácil de definir, pero, según sus propios rivales, se basaba en una combinación de energía y ambición de victoria, precisión táctica, preparación teórica, firmeza estratégica y confianza en sí mismo.

El encuentro por el campeonato del mundo de 1972 fue singular por diversas razones, aunque algunas de ellas nada tenían que ver con el ajedrez. Reikiavik, capital de Islandia, representó el enfrentamiento de dos mitos del tablero. El primero era el propio Fischer, que nunca había ocultado su fobia deportiva hacia los grandes maestros soviéticos. Sus excentricidades, exigencias y reacciones eventualmente infantiles, para bien o para mal lograron interesar al gran público, de ordinario ajeno a las incidencias del ajedrez profesional. Lo excepcional del estadounidense, sin embargo, eran sus resultados. Su puntuación Elo era 125 puntos superior a la de Spassky. Si no se hubiera tratado del número uno y dos del escalafón mundial, la estadística indicaría solamente el enfrentamiento de dos ajedrecistas de diferente categoría. Tal era la distancia que Fischer llegó a tener con relación a sus contemporáneos.

El retador, en efecto, parecía invencible. No obstante, se enfrentaba a un rival temible, otro auténtico mito de invulnerabilidad. Ese rival no era solamente Spassky, un jugador de talento excepcional al que Fischer no había podido vencer antes de este encuentro, sino la poderosa estructura de ajedrez de la Unión Soviética, dirigida por el Comité de Educación Física y Deportes, que había producido a todos los campeones y subcampeones mundiales desde 1948, y había ganado todas y cada una las Olimpíadas que se habían efectuado desde entonces. Ningún campeonato del mundo desde 1951 se había disputado fuera de Moscú.

El ajedrez, en definitiva, era una cosa muy seria en la Unión Soviética, con importantes implicaciones políticas, pues sus frecuentes triunfos eran considerados una prueba de la superioridad del régimen; no podían permitirse, en consecuencia, perder el título a manos de un aspirante de Estados Unidos. El ex campeón mundial Mijaíl Botvinnik puso a disposición del equipo de Spassky un análisis exhaustivo de las partidas de Fischer; Ígor Bondarevski abordaría la parte técnica; Efim Geller el repertorio de aperturas; Nicolay Krogius, de la asistencia psicológica; e Ivo Ney se encargaría de la puesta a punto física del campeón.
El apoyo de Fischer lo componían Lombardy, el abogado Paul Marshall (que tuvo un papel destacado) y Fred Cramer, por parte de le Federación de Ajedrez de Estados Unidos. El match no podía ser, por sus circunstancias particulares, un mero evento deportivo. Se enfrentaban dos maneras muy distintas de entender al mundo que aspiraban a la supremacía. Por unos meses la Guerra Fría se trasladó a un tablero de ajedrez.

Tras la jugada número 30 de la primera partida, los dos jugadores llegaron a una posición completamente simétrica (dos alfiles de casillas negras y seis peones repartidos de igual manera por ambos flancos). Fischer perdió cuando cometió un error amateur al comer un peón con su alfil que después del movimiento de un peón de Spassky queda sin escapatoria siendo una presa fácil para el rey que se encontraba cerca. No se presentó a la segunda partida alegando disconformidad con la organización. Parecía que Spassky retendría el título para el ajedrez soviético; pero Bobby Fischer venció en la tercera. La cuarta partida fue tablas y, desde la quinta, se impuso rotundamente el gran maestro estadounidense. Después de un tenso desarrollo, Fischer venció a su rival tras 21 partidas (Spassky abandonó por teléfono la última partida, que había quedado aplazada) y se coronó campeón mundial el 1 de septiembre de 1972 con un total de 7 partidas ganadas, 3 perdidas y 11 tablas. Ha sido el único estadounidense en conquistar el título.

Resultó incomprensible para todo el mundo que el momento culminante de la carrera de Bobby Fischer al conquistar el campeonato mundial significase también su abrupto y completo final, pues nunca más quiso volver a jugar una sola partida de competición oficial a pesar de tener solamente 29 años. La única explicación plausible para esta actitud es un temor insuperable a ser derrotado, lo cual se suma a los diversos indicios de obsesión y desequilibrio mental que hasta entonces había dado. Además de que al no volver a jugar frustró las expectativas de todos los aficionados y organizadores del mundo, hay que observar que la única fuente de futuros ingresos de Bobby sería el ajedrez o estaría en estrecha relación con este.

Cumplido el siguiente ciclo de clasificación tres años más tarde, en 1975, llegó una vez más la ocasión de que el campeón defendiera su título frente al nuevo aspirante, en este caso el joven soviético Anatoli Kárpov (n. 1951), de 24 años. Entonces Bobby planteó a la FIDE que no deseaba defender su título de la misma forma que lo había ganado, sino según otro esquema anterior a 1948, que consistía, entre otras cosas, en que la victoria sería para quien primero alcanzara 10 victorias (sin contar las tablas), reteniendo el título el campeón en caso de empate a 10. Hasta aquí puede decirse que es un planteamiento equitativo y razonable; de gustos personales, si se quiere, pero razonable. El gran inconveniente es que Fischer pretendía introducir además la condición de que él (Fischer) también retendría el título si se empataba a nueve.

Aunque la FIDE y la delegación soviética aceptaron las restantes exigencias de Fischer, la cuestión del empate a nueve no era razonable ni admisible. Para que se entienda mejor lo irracional de esta condición, podemos enunciarla así: «El campeón será Kárpov si gana diez partidas, y Fischer si gana nueve». Esta condición sería ridícula en otros deportes que se disputan a un tanteo prefijado, como el tenis, o cuando en fútbol hay que recurrir al lanzamiento de penaltis. Botwinnik calificó esta condición de " «unfair»" (injusta). La FIDE desautorizó esta pretensión, pero entonces Fischer se negó en redondo a jugar. No quedó otra opción que desposeer a Fisher de su título y proclamar campeón a Kárpov, quien, con sus resonantes triunfos en grandes torneos y matches por el campeonato mundial durante los diez años siguientes, se hizo merecedor indiscutible al título mundial y, con el paso del tiempo, ha demostrado ser uno de los jugadores más formidables de la historia del ajedrez, que ha ganado un casi increíble total de 160 torneos de ajedrez de élite.

Fischer, decepcionando profundamente a la afición mundial, continuó sin jugar e incluso desapareció de la vida pública. Kárpov, que dijo sentirse como un niño al que no le dan un juguete largo tiempo prometido, se entrevistó en 1976 con Bobby para concertar un encuentro, pero su intento no tuvo éxito. En 1981 Bobby, con aspecto de vagabundo, fue detenido en Pasadena (California) cuando la policía le confundió con el atracador de un banco.

Mucho después, en 1992, Fischer, a la sazón de 49 años, aceptó jugar un encuentro amistoso de exhibición contra su antiguo adversario Spassky, de entonces 55 años de edad. El match comenzaría en Sveti Stefan, a orillas del Adriático, y acabaría en Belgrado, enclaves ambos de la República Federal de Yugoslavia, nación procedente del desmembramiento de la antigua Yugoslavia. Aunque tuvo notoriedad por ser la reaparición de Fischer después de veinte años, este encuentro estaba muy lejos de ser una repetición del famoso de 1972, pues la Unión Soviética se había disuelto y ya no había intereses ni tensiones internacionales; Spassky se había nacionalizado francés y ―esto es destacable― había retrocedido en la clasificación internacional Elo hasta el puesto 124; y, por último, no había en juego ningún título oficial ni extraoficial. Lo único realmente relevante era el apartado financiero, pues la exhibición estaba dotada con sustanciosos premios en metálico: 3,65 millones de dólares para el vencedor y 1,35 para el perdedor. El Gobierno de Estados Unidos prohibió a Fischer ―como a todos sus conciudadanos― involucrarse en el match a causa de las restricciones en el comercio impuestas a la República Federal de Yugoslavia por su intervención en la reciente guerra de Bosnia. Ante las cámaras, Fischer (que jugaba con una bandera estadounidense en la mesa) escupió sobre la carta del gobierno de su país que le conminaba a desistir de jugar. El encuentro se celebró y acabó con la victoria del estadounidense, aunque la calidad de las partidas y el desarrollo general del acontecimiento despertaron escaso interés en el mundo del ajedrez. Las autoridades de Estados Unidos dictaron orden de búsqueda y captura contra Fischer, lo cual podía llegar a costarle hasta 10 años de cárcel.

A lo largo de años, al mismo tiempo que su salud mental comenzaba a deteriorarse, Bobby Fischer se había caracterizado por lanzar furibundos pronunciamientos antisemitas y antiestadounidenses. A pesar de ser él mismo de ascendencia judía por el lado materno, admiraba a Adolf Hitler y era un negacionista del Holocausto.
En al menos una oportunidad se había declarado a favor de un hipotético golpe militar derechista en su país, seguido de la destrucción de sinagogas y la ejecución de cientos de miles de judíos.

En una entrevista a una radio filipina el 12 de septiembre de 2001, Fischer proclamó su satisfacción por los ataques terroristas contra las Torres Gemelas y el Pentágono ocurridos el día anterior y se pronunció en durísimos términos contra Estados Unidos e Israel.
Sin embargo, cabe aclarar que su odio nunca se extrapoló al tablero pues durante toda su vida mantuvo una cordial relación con otros ajedrecistas judíos.

En julio de 2004 fue detenido en el aeropuerto de Narita, en Tokio (Japón) por utilizar un pasaporte no válido, pues Estados Unidos lo había anulado. Bobby, permaneció ocho meses detenido hasta que en marzo de 2005, finalmente, Islandia le concedió la ciudadanía islandesa, con lo que las autoridades japonesas le autorizaron a que viajase a ese país. Islandia hizo este gesto por razones sentimentales, pues el encuentro de 1972 hizo famosa su capital, Reikiavik, en todo el mundo. Las autoridades estadounidenses, sin embargo, expresaron su malestar por la concesión de dicha nacionalidad, pues reclamaban que el ajedrecista fuese extraditado a Estados Unidos para ser juzgado.

Tres años más tarde, el 18 de enero de 2008, Fischer falleció a los 64 años en Reikiavik (Islandia) a causa de una enfermedad renal y fue enterrado en una tumba sencilla en un cementerio cercano a Selfoss, pequeña localidad costera al sudoeste del país.

En junio de 2010 la Corte Suprema de Islandia determinó que el cuerpo de Fischer fuese exhumado para obtener una muestra de su ADN y poder así establecer si había sido el padre de Jinky Young, una niña filipina de nueve años cuya madre aseguraba haber tenido una relación con el excampeón. En julio de 2010 el cuerpo fue exhumado y, tras tomar muestra de su ADN, inhumado de nuevo. Magnus Skulason, íntimo amigo de Fischer, sostenía que el ajedrecista no era el padre de la niña. En agosto de 2010 se informó de que la prueba de ADN había revelado que Jinky Young no era hija del excampeón del mundo.





</doc>
<doc id="4617" url="https://es.wikipedia.org/wiki?curid=4617" title="Cisne">
Cisne

Cisne es el nombre común de varias aves anseriformes de la familia Anatidae. Son aves acuáticas de gran tamaño. La mayoría de las especies pertenecen al género "Cygnus".

Varias especies de aves son conocidas como cisne:


El cisne era un ave consagrada a Apolo, como dios de la música, porque se creía que el cisne poco antes de morir, cantaba melodiosamente. Por esto dijo Pitágoras, que esta ave se asemejaba a un alma que jamás muere y que su canto antes de morir viene de la alegría que experimenta porque va a ser librada de su cuerpo mortal. Platón parece ser de la misma opinión y algunos otros dicen que está consagrada a Apolo, porque goza del don de prever los bienes de la otra vida de los cuales espera gozar después de su muerte. 

Ovidio coloca a los cisnes en los Campos Elíseos. Estaban también consagrados a Venus, ya por su maravillosa blancura, ya por su temperamento bastante semejante al de la diosa del deleite. La carroza de Venus es tirada algunas veces por cisnes. Zeus se transformó en esta ave para engañar a Leda.



</doc>
<doc id="4618" url="https://es.wikipedia.org/wiki?curid=4618" title="Estación">
Estación

Estación hace referencia a varios artículos:







</doc>
<doc id="4627" url="https://es.wikipedia.org/wiki?curid=4627" title="Baltasar Gracián">
Baltasar Gracián

Baltasar Gracián y Morales (Belmonte de Gracián, Calatayud, Zaragoza, 8 de enero de 1601-Tarazona, Zaragoza, 6 de diciembre de 1658) fue un jesuita, escritor español del Siglo de Oro que cultivó la prosa didáctica y filosófica. Entre sus obras destaca "El Criticón" —alegoría de la vida humana—, que constituye una de las novelas más importantes de la literatura española, comparable por su calidad al "Quijote" o "La Celestina".

Su producción se adscribe a la corriente literaria del conceptismo. Forjó un estilo construido a partir de sentencias breves muy personal, denso, concentrado y polisémico, en el que domina el juego de palabras y las asociaciones ingeniosas entre estas y las ideas. El resultado es un lenguaje lacónico, lleno de aforismos y capaz de expresar una gran riqueza de significados.

El pensamiento de Gracián es pesimista, como corresponde al periodo barroco. El mundo es un espacio hostil y engañoso, donde prevalecen las apariencias frente a la virtud y la verdad. El hombre es un ser débil, interesado y malicioso. Buena parte de sus obras se ocupan de dotar al lector de habilidades y recursos que le permitan desenvolverse entre las trampas de la vida. Para ello debe saber hacerse valer, ser prudente y aprovecharse de la sabiduría basada en la experiencia; incluso disimular, y comportarse según la ocasión.

Todo ello le ha valido a Gracián ser considerado un precursor del existencialismo y de la postmodernidad. Influyó en librepensadores franceses como La Rochefoucauld y más tarde en la filosofía de Schopenhauer. Sin embargo, su pensamiento vital es inseparable de la conciencia de una España en decadencia, como se advierte en su máxima «floreció en el siglo de oro la llaneza, en este de yerro la malicia».

Nacido en Belmonte de Gracián, muy cerca de Calatayud, en 1601, las noticias sobre su infancia son muy escasas. Todo indica que estudió letras desde los diez o doce años en su ciudad natal, quizá en el colegio de jesuitas de esta localidad. Hacia 1617 debió residir uno o dos años en Toledo con su tío Antonio Gracián, capellán de San Juan de los Reyes, donde aprendería lógica y profundizaría en el latín.

En 1619 ingresó en el noviciado de la provincia jesuítica de Aragón, situado en Tarragona, en el que se le dispensó de los dos años preceptivos de estudio de humanidades debido a su excelente formación anterior. En 1621 volvió a Calatayud, donde cursó dos años de Filosofía. De esta etapa data su aprecio por la ética, que influyó en toda su producción literaria. Otros cuatro cursos de Teología en la Universidad de Zaragoza completaron su formación religiosa.

Ordenado sacerdote en 1627, comenzó a impartir Humanidades en el Colegio de Calatayud. Parece ser que fue un periodo grato, pero pocos años más tarde tuvo graves enfrentamientos con los jesuitas de Valencia, adonde fue trasladado en 1630. De allí pasó a Lérida en 1631 para encargarse de las clases de Teología Moral. En 1633 viajó a Gandía para enseñar Filosofía en el colegio jesuita de la villa y se renovaron las enemistades con sus antiguos correligionarios valencianos.

En el verano de 1636 volvió a tierras aragonesas, a Huesca, como confesor y predicador. Esta ciudad tuvo una importancia capital en la vida del jesuita, puesto que con el apoyo del erudito mecenas Vincencio Juan de Lastanosa pudo publicar su primer libro: "El Héroe" (1637).

Lastanosa reunía en su casa-museo un importante cenáculo literario y artístico. El palacio del prócer oscense, que fue visitado por Felipe IV, era conocido por sus exquisitos jardines, por una estupenda armería, por la colección de medallas y por una magnífica biblioteca de cerca de siete mil volúmenes, una cantidad extraordinaria en esa época. En este propicio ambiente Gracián traba contacto con la intelectualidad cultural aragonesa, entre la que se cuenta el poeta Manuel de Salinas o el historiador Juan Francisco Andrés de Uztarroz.

En 1639 llegó a Zaragoza, nombrado confesor del virrey de Aragón Francisco María Carrafa, duque de Nochera, con quien viaja a Madrid, donde predicó. No obstante, su estadía en la Corte fue desalentadora, pues, aunque aspiró a medrar entre la república literaria de la capital, sus ambiciones se saldaron con un franco desengaño. Con todo, publicó allí su segunda obra, "El Político" (1640) y ultimó la primera versión de su tratado teórico sobre estética literaria barroca, titulado "Arte de ingenio, tratado de la agudeza" (1642).

De 1642 a 1644 ejerció el cargo de vicerrector del Colegio de Tarragona, donde auxilió espiritualmente a los soldados que tomarían Lérida en la Sublevación de Cataluña (1640). De resultas de esta campaña, cayó enfermo, y fue enviado a Valencia para reponerse. Al calor de la magnífica biblioteca del hospital, preparó una nueva obra, "El Discreto" (1646), que verá la luz en Huesca. De nuevo en su refugio oscense, impartió clases de Teología Moral hasta 1650. Es en esta época cuando más activamente pudo dedicarse a la literatura. Aparecieron entonces el "Oráculo manual y arte de prudencia" (1647) y la segunda versión del tratado sobre el ingenio y el concepto "Agudeza y arte de ingenio" (1648).

Fue destinado a Zaragoza el verano de 1650 con el cargo de Maestro de Escritura, y al año siguiente publica la primera parte de su obra cumbre: "El Criticón". A excepción de "El Comulgatorio", Gracián publicó toda su obra sin el preceptivo permiso de la Compañía, lo que provocó protestas formales que fueron elevadas a las instancias rectoras de los jesuitas. Tales quejas no le disuadieron al punto de que apareciera en Huesca la segunda parte de esta obra. Algunos jesuitas valencianos, a consecuencia de viejas enemistades, interpretaron uno de sus pasajes como una ofensa a sus personas, lo que le granjeó nuevos ataques ante los superiores de la Compañía que apuntaban al contenido escasamente doctrinal de sus obras, impropias de un jesuita profeso, ya que, ocupándose todas ellas de la Filosofía Moral, esta se aborda desde una óptica profana. Quizá para contribuir a su descargo publicó, por primera vez con su auténtico nombre, "El Comulgatorio" (1655), un libro acerca de la preparación para la Eucaristía.

Pero la aparición en 1657 de la tercera parte de "El Criticón" determinó su caída en desgracia. El nuevo provincial de Aragón, el catalán Jacinto Piquer, recriminó públicamente a Gracián en el refectorio, le impuso como penitencia ayuno a pan y agua —prohibiéndole incluso disponer de tinta, pluma y papel—, y le privó de su cátedra de Escritura del Colegio Jesuita de Zaragoza. A comienzos de 1658 Gracián es enviado a Graus, un pueblo del prepirineo oscense.

Al poco tiempo, Gracián escribió al General de la Compañía para solicitar el ingreso en otra orden religiosa. Su demanda no fue atendida, pero se le atenuó la pena: en abril de 1658 ya fue enviado a desempeñar varios cargos menores al Colegio de Tarazona, hoy Hogar Doz. Los últimos contratiempos debieron acelerar su decadencia física, pues en junio no pudo asistir a la congregación provincial de Calatayud, falleciendo, poco más tarde, en Tarazona, el 6 de diciembre de 1658. Probablemente fue enterrado en la fosa común del colegio.

Vista en conjunto la producción de Baltasar Gracián, podemos observar una estrecha relación con su biografía. Desde el juvenil entusiasmo por el triunfo y la gloria del hombre ejemplar, configurado en "El Héroe", se llegará al desengaño de la vejez y la muerte en los últimos capítulos de "El Criticón". Así se presenta como escritor en 1637 en el prólogo :Dos tratados más continuarían esta línea de delinear el hombre perfecto: "El Político", que extrae tales cualidades del rey Fernando el Católico, y "El Discreto", un manual de conducta para el hombre en sociedad, sea cual sea su posición en ella.

Por otro lado, Gracián dedicó grandes esfuerzos a elaborar un tratado de estética literaria barroca: la "Agudeza y arte de ingenio", que refunde una versión anterior titulada "Arte de ingenio, tratado de la agudeza". Allí teoriza sobre el «concepto» y propone una nueva retórica basada en la "praxis" barroca que se distancia, en parte, de la tradición aristotélica de la "Poética", pues su análisis está fundamentado en textos, que a su vez ejemplifican una clasificación de los distintos tipos de agudeza de su propia invención.

Toda la obra de Gracián, ocupada siempre de su aplicación práctica a la vida del hombre, tiene por objeto la Filosofía Moral. Las ideas acumuladas en tratados anteriores sobre el modo de conducirse en el mundo son sintetizadas y reunidas en el libro más lacónico y sentencioso de su producción, el "Oráculo manual y arte de prudencia". Con él culmina el proyecto de «manuales del vivir» para la persona cabal, y en él también se subsumen, probablemente, libros proyectados —en "El Discreto" se habla de los «doce gracianes», que se titularían «El Atento», «El Galante»— que no llegaron a ver la luz.

Fue admirado por moralistas franceses de los siglos XVII y XVIII, y en el XIX por Schopenhauer, quien recibió la influencia del pensamiento graciano y tradujo al alemán el "Oráculo manual y arte de prudencia". Esta versión, muy fiel al espíritu del aragonés, fue conocida por Nietzsche, que dijo en una de sus cartas: «Europa no ha producido nada más fino ni más complicado en materia de sutileza moral». Gracias a ellos la obra del filósofo español fue objeto de estudio en la universidad alemana.

Solo le quedaba ensayar la fabulación. Poner todo su trabajo de investigación retórica al servicio de una novela, que fuera a la vez tratado de filosofía moral, bajo el género que él mismo denominó «agudeza compuesta fingida», lo que viene a significar «alegoría novelada». Se concretó en las tres partes de "El Criticón", que recorre todo el ciclo de la vida de un hombre, que debe, además, vencer a las circunstancias del mundo en crisis de la sociedad del barroco.

El último libro que publicaría, quizá por hacer una concesión a los oficios propios de la orden jesuita, que no veía con buenos ojos su abordar la lucha por la vida siempre al margen de auxilio cristiano, fue "El Comulgatorio". Es el único que publicó con su auténtico nombre y cumplió con la preceptiva revisión por parte de los censores de su orden. Sin embargo, tras la aparición en 1657 de la tercera parte de "El Criticón" —de nuevo sin consentimiento de la Compañía y con su conocido (a estas alturas) seudónimo de Lorenzo Gracián—, el aragonés fue confinado a una celda y castigado a ayuno riguroso. Los tintes pesimistas que destila "El Criticón" corren parejas con su última peripecia vital.

El título de "El Héroe" remite a la cualidad máxima del hombre en la antigüedad clásica, esto es, la "virtus" latina o la "areté" (αρετη) griega. El primero de los libros publicados por Baltasar Gracián es un tratado en el que se describen las cualidades del hombre de excepción. Cada una de esas prendas relevantes de que está formado el héroe se autoriza con la mención de su presencia en un eminente personaje histórico, entroncando con los "Dicta et facta memorabilia" de la tradición latina de Valerio Máximo. Este ejemplo funciona como colofón de cada uno de los capítulos, llamados «primores». El término alude al sentido etimológico de esta palabra, derivándolo de "primus" como sustantivo, esto es, «el mejor», «el primero».

La obra remite también al "El Príncipe" de Maquiavelo, pues es un doctrinal de buen gobierno, si bien aplicado al ámbito de la rección de la propia persona. Pero, en contraste con el tratadista italiano, esta «razón de estado de uno mismo» no olvida conciliar la política y la moral, ya que en la España de la Contrarreforma al príncipe maquiavélico se opuso un príncipe cristiano, como pregona el título de la obra de su contemporáneo Diego Saavedra Fajardo "Idea de un príncipe político cristiano" (1640).

Por otro lado, "El Héroe" conecta con "El Cortesano" de Baltasar de Castiglione, aunque ya no basta con los modales corteses renacentistas. En Gracián el cortesano necesita también astucia, inteligencia, buen discernimiento e incluso disimulo.


En "El político don Fernando el Católico", bajo la forma de una tesis que defiende que Fernando el Católico fue el mayor rey de la monarquía española, se describen sus dotes políticas y sus virtudes como ejemplo de emulación para el hombre político. Se trata pues, no tanto de una biografía sino de otro tratado de moral práctica, solo que encarnada en el mayor príncipe, en un rey.

Construye este texto sobre la falsilla genérica del encomio biográfico, caracterizado como un discurso académico ante un auditorio, modelo que tuvo un importante cultivo en el Renacimiento y el Barroco. Se ofrece con él un modelo concreto de gobernante que destaca sobre todos los monarcas pasados, y que constituye un espejo en el que se deben reflejar los posteriores, incluido Felipe IV, en la línea de los conocidos «espejos de príncipes».


Gracián escribió dos tratados sobre el ingenio y la agudeza. El primero de ellos lo publicó en Madrid en 1642 con el título de "Arte de ingenio, tratado de la agudeza". El segundo apareció en 1648, con el título de "Agudeza y arte de ingenio". La teoría sobre el concepto que aborda en esta obra ilumina la producción literaria contemporánea a Gracián. Los géneros empleados en las distintas obras de Gracián se definen aquí de modo teórico. Posteriormente fue refundida, revisada y ampliada en una edición definitiva titulada "Agudeza y arte de ingenio", publicada en 1648.


Es su primer fruto de plena madurez. De nuevo estamos ante un tratado en el que se describe cómo ha de ser el hombre que quiere llegar a ser «persona»: un completo caballero prudente, sagaz, dotado de buen gusto y de buena educación. Por discreción entiende la capacidad de discernimiento, que es al fin y al cabo la inteligencia para elegir lo mejor y para distinguir y valorar aquello que el hombre necesita para ser un varón de todas las horas y todas las circunstancias.

Pero ahora se renuncia a conseguir la excelsitud heroica, contentándose con ayudar a mejorar al hombre de mundo para que destaque entre sus semejantes. El modelo propuesto ya no es un ser excepcional, un héroe de fama, gobernante o rey, como sucedía en sus dos anteriores tratados de parecida temática. Ahora se trata de adiestrar a un hombre prudente que no solo necesita muchas cualidades para gobernar, sino tan solo para desenvolverse en sociedad. Con el tiempo, el pesimismo de un Gracián que contempla la malicia del mundo se ha hecho más agudo. Su desengaño hace que el objetivo del triunfo del héroe planteado en el primer tratadito sea una utopía. Ahora basta con llegar a ser persona, es decir, ser, en el sentido clásico, un hombre virtuoso.

En los capítulos de este tratado —llamados ahora «realces» en consonancia con el destacar, y no ya ser el mejor, que revelaba el «primor»— se ensayan gran variedad de géneros: diálogo, apólogo, emblema, sátira, fábula, epístola, discurso académico, o panegírico, entre otros. En ellos utiliza por vez primera la fábula o la alegoría, creando ya un módulo de ficción que servirá a los propósitos de la «agudeza compuesta fingida», o novela alegórica, que será su empeño final. El último de sus «realces», que no lleva indicación de género, titulado , muestra un esquema de división de la vida del hombre en edades que preludia el de su novela "El Criticón".


El "Oráculo manual y arte de prudencia" (1647) supone la síntesis de los tratados didáctico-morales anteriores. El libro consta de trescientos aforismos comentados, y ofrece un conjunto de normas y orientaciones para guiarse en una sociedad compleja y en crisis.

No sólo ha interesado a aficionados a la literatura. A la obra se han acercado desde su publicación hasta la actualidad pensadores y filósofos. La admiración que por ella mostró Arthur Schopenhauer le llevó a traducirla al alemán y su versión fue la más difundida del "Oráculo" en esta lengua.

Este «arte de prudencia» escrito por Gracián ha tenido vigencia incluso en la actualidad, como demuestra el hecho de que una versión al inglés, titulada "The art of worldly wisdom: a pocket oracle" llegó a vender más de ciento cincuenta mil ejemplares en el ámbito anglosajón, al ser presentado como un manual de autoayuda para ejecutivos. En 1992, permaneció dieciocho semanas (dos en primera posición) en la lista de los más vendidos del Washington Post en el apartado "Nonfiction/General".

Se ha pensado que esta obra es una mera recopilación de sentencias de sus libros anteriores, pero esto solo es cierto, y en parte, en los cien primeros aforismos. El hecho de glosar apotegmas de obras propias era un proceder nuevo, pues hasta entonces estaba reservado a la autoridad de las citas extraídas los clásicos de la antigüedad, o al menos a autores de reconocido prestigio. El ser el "Oráculo" una antología de sus máximas indica que Gracián se eleva a sí mismo al rango de los autores que constituían el canon literario de la época.

El sintagma bimembre «oráculo manual y arte de prudencia», funciona como antítesis, pues oráculo tiene un sentido de «secreto emanado de la divinidad», y a este término se une el adjetivo «manual», esto es, «para un uso práctico y portátil». La palabra «arte» se usa en la acepción de «reglas y preceptos para hacer rectamente las cosas», como recoge el "Diccionario de Autoridades". Pero se le opone la prudencia, pues no hay normas ciertas y universales para la conducta del hombre. En conclusión, el libro sería un precioso y secreto manual de normas de uso práctico para la conducta del hombre en un mundo conflictivo.

El género que adopta el "Oráculo", a diferencia de los tratados anteriores, prescinde de la argumentación y la autoridad de ejemplos históricos que habían sido habituales en "El Héroe", "El Político" o "El Discreto". La observación del mundo y la aplicación de estos consejos en la práctica bastan para garantizar la validez y utilidad de estos oráculos mundanos.

Su estilo es la quintaesencia de la economía expresiva y la concisión graciana. En esta obra se da la mayor intensidad en cuanto a concentración semántica en frases breves y elípticas, que se suceden en un encadenado de sentencias. Este carácter hace del "Oráculo" su obra de más difícil lectura, pero también la de mayor contenido en ideas, constituyendo una "summa" de su pensamiento anterior.


Con la "Agudeza y arte de ingenio" Gracián escribe su definitiva estética literaria barroca. Se trata de un tratado de retórica en el que se analizan las figuras literarias dominantes en su época.

Esta obra supone el comentario definitivo acerca del concepto y también una teorización de su propia producción literaria anterior y posterior, y de la de sus contemporáneos. No es una retórica más, pues su análisis del hecho literario parte de los ejemplos extraídos de los textos, que en esta versión se amplían considerablemente, y no de una preceptiva previa.

En esta revisión de su trabajado "Arte de ingenio", en gran medida una reedición muy ampliada, incluyó más traducciones castellanas de textos latinos —sobre todo de Marcial—, debidas a Manuel de Salinas. Pero también reorganiza los materiales de 1642 y revisa, corrige y pule el estilo.

Es en este tratado donde aparece la definición que del concepto da Gracián:

No se trata, en puridad, de una obra sobre el conceptismo, tal y como lo concibió Menéndez Pelayo en su "Historia de las ideas estéticas en España", pues el concepto en Gracián es la expresión de una semejanza, desde un símil a una metáfora, desde una dilogía hasta la alegoría sostenida. Y estos tropos son utilizados tanto por escritores caracterizados como «conceptistas» como por los denominados «culteranistas». Tan es así que la mayor cantidad de ejemplos (que avalan las figuras que define como conceptos) son traídos de la poesía de Góngora. Además ejemplifica con escritores no solo del barroco español, sino de todos los tiempos. Y de ese modo encuentra conceptos ingeniosos en epigramas de Marcial, sentencias de Séneca, aforismos de Tácito, discursos de Cicerón o "exempla" de Juan Manuel.


"El Comulgatorio" se ocupa de la preparación del cristiano para recibir la comunión. Según desvela la portada, el tratado «contiene varias meditaciones para que los que frecuentan la sagrada Comunión puedan prepararse, comulgar y dar gracias». «Meditaciones» es el nombre que el jesuita asigna a los capítulos de este libro, en la línea de obras anteriores, donde se titulaban «primores» ("El Héroe"), «realces» ("El Discreto"), «discursos» ("Agudeza y arte de ingenio") o «crisi (s)» ("El Criticón"). El capítulo o meditación primera sirve a la preparación del cristiano para recibir la comunión, el segundo al acto de la comunión propiamente dicha, el tercero a los frutos que se obtienen de recibir el cuerpo de Cristo y el cuarto a dar gracias. Estas meditaciones están divididas en puntos o temas de reflexión y, a su vez, cada punto presenta dos partes separadas tipográficamente por un asterisco.

Con "El Comulgatorio" Gracián abandona el estudio del ingenio y se dedica al de las emociones, en línea con los escritores espirituales del Siglo de Oro. Es este un libro de carácter religioso, muy distinto de los hasta ahora escritos por el aragonés, tanto en temática como en estilo. Lo publica por primera vez con su verdadero nombre y no con el de su hermano «Lorenzo Gracián» o bajo un anagrama como el «García de Marlones» con el que ve la luz la primera parte de "El Criticón". "El Comulgatorio" es más discursivo y apela a los afectos. Está más cercano a la oratoria sagrada que a la sentenciosa filosofía moral.

En cuanto al género de "El Comulgatorio", la crítica se divide entre quienes piensan que es una pieza de oratoria sagrada, es decir, un sermón, y los que sostienen que la obra pertenece al género de los libros de devoción.


Las tres partes del "Criticón", publicadas en 1651, 1653 y 1657, constituyen, sin duda, la obra maestra de su autor y es una de las obras cumbres del Siglo de Oro español. Bajo la forma de una extensa novela alegórica de carácter filosófico, esta novela reúne en forma de ficción toda la trayectoria literaria de su autor. "El Criticón" conjuga la prosa didáctica y moral con la fabulación metafórica, y con ello, cada «crisi» (capítulo), alberga una doble lectura —si no más— en los planos real y filosófico. En ella se unen invención y didactismo, erudición y estilo personal, desengaño y sátira social.

La obra constituye una extensa alegoría de la vida del hombre, representado en sus dos facetas de impulsivo e inexperto (Andrenio) y prudente y experimentado (Critilo). Estos dos personajes simbólicos, persiguiendo la Felicidad (Felisinda, madre para Critilio y esposa para Andrenio), acaban recorriendo todo el mundo conocido persiguiendo el aprendizaje de la virtud que, pese al engaño que ofrece comúnmente el mundo, les llevará a ganar la inmortalidad por sus hechos al llegar la muerte al final de la novela. Es, por tanto, la culminación literaria de la visión filosófica del mundo de Gracián, donde prima el desengaño vital y el pesimismo, si bien la persona cabal consigue elevarse sobre este mundo de malicia.

La obra podría verse, desde el punto de vista del género empleado, como una gran epopeya moral: fábula menipea la llamó Fernando Lázaro Carreter. Además se ha relacionado con la novela bizantina por la multitud de peripecias y aventuras que sufren los personajes y con la novela picaresca por la visión satírica que de la sociedad se muestra a lo largo del peregrinaje de sus protagonistas Critilo y Andrenio.

Aunque "El Criticón" se plantea inicialmente como una novela bizantina, en la que los dos peregrinos tienen como fin la búsqueda de Felisinda, pronto se descubre esto como un imposible, y con ello la estructura de la novela se conforma como una serie de episodios ensartados, al modo de la novela itinerante habitual de la picaresca. Tras este desengaño, el verdadero objetivo de nuestros protagonistas es alcanzar la virtud y la sabiduría. Pronto se abandona, con ello, una tenue intriga para demorarse en sucesivos cuadros alegóricos que dan cauce a la reflexión filosófica partiendo de una óptica satírica del mundo.

En cuanto a la estructura externa, "El Criticón" apareció, como dijimos, en tres entregas. En la "Primera parte", subtitulada «En la primavera de la niñez y en el estío de la juventud», los protagonistas se encuentran en la isla de Santa Elena, se cuentan las peripecias vitales que les han llevado allí y emprenden el viaje a España, comenzando por la Corte. La "Segunda parte", que aparece con el epígrafe de «Juiciosa cortesana filosofía en el otoño de la varonil edad», transcurre por tierras de Aragón y Francia. En la "Tercera Parte", titulada más llanamente «En el invierno de la vejez», entran por tierras de Alemania y acaban en la meca del peregrino cristiano, Roma, para ser anunciados a la muerte y llegar a la inmortalidad cruzando las aguas de tinta de la fama. Los tres tomos ofrecen un equilibrio estructural en lo externo muy notable. Las dos primeras partes constan de trece «crisis» cada una y la tercera tiene doce.

El tiempo del relato se configura a través de un eje cronológico marcado por el ciclo vital del hombre y asociado a las estaciones del año, tal y como aparece esbozado en el último capítulo de "El Discreto". El tiempo de la ficción novelesca progresa de manera lineal, pero recorrido por constantes digresiones e interrupciones. En estos remansos se da cuenta de todo un mundo alegórico y supone una detención del tiempo, muy adecuada a la generalización filosófica y moral.

Parece seguro que había un plan de la obra preconcebido en "El Criticón", lo que se observa en el hecho de que el arranque y desenlace de la obra suceden en una isla, según apuntó Klaus Heger. La misma tesis recoge Ricardo Senabre, que señala también la existencia de principios estructurales basados sobre todo en la antítesis. Esta se hace presente ya en los dos protagonistas medulares, Andrenio-Critilo, y recorre toda la obra, desde los distintos comportamientos que ante determinadas situaciones tienen cada uno de los protagonistas, hasta la abundancia de periodos bimembres en frases e incluso en la figura literaria de la anfibología. Por otro lado, si nos atenemos a los temas que recorren la obra, encontramos una recurrente antinomia entre el engaño y el desengaño, eje temático que estructura toda la narración.

En fin, Correa Calderón, considera que "El Criticón" no es sino una serie de cuadros alegóricos yuxtapuestos, constituidos a modo de fantasías morales, y enlazados tan solo por la andadura de sus dos protagonistas, como ocurre en los libros satíricos de la época. Así lo hacían obras tal "El Diablo Cojuelo", de Luis Vélez de Guevara, que adoptaba una estructura de pequeños módulos alegóricos independientes, como son los ensartados en el hilo del camino de los dos peregrinos de Gracián.

El autor exhibe constantemente una técnica perspectivista que desdobla la visión de las cosas según los criterios o puntos de vista de cada uno de los personajes, pero de forma antitética, y no plural como en Cervantes. La novela refleja, con todo, una visión pesimista de la sociedad, con la que se identificó uno de sus mejores lectores, el filósofo alemán del XIX Arthur Schopenhauer. Se trata de una mirada amarga y desolada, aunque su pesimismo alberga una esperanza en los dos virtuosos protagonistas, que consiguen escapar a la mediocridad reinante alcanzando la fama eterna.







Se conservan 32 cartas completas de Gracián, dirigidas a Vincencio Juan de Lastanosa, Andrés de Uztarroz, Manuel de Salinas, o el tortosino Francisco de la Torre Sevil. También conservamos epístolas dirigidas a sus superiores y compañeros jesuitas.

Importan sobre todo las enviadas a un jesuita de Madrid en 1646, en las que se refiere a la batalla de Lérida, donde se muestra orgulloso de su valerosa intervención. Nos cuenta cómo muchos capellanes cayeron enfermos o prisioneros, y cómo hubo de multiplicar su trabajo para absolver y dar el jubileo a los soldados en la misma línea del frente, como un combatiente más.

En estas cartas, además de obtener jugosos datos sobre su biografía, se muestra escritor en un estilo natural, que dista mucho del que él mismo se forjó para vehicular su obra literaria. En cambio, las aprobaciones y prólogos citados, escritos en su peculiar estilo conceptista, no tienen tanto interés, pues además hay que tener en cuenta su tono laudatorio y obligado formulismo.



El estilo de Baltasar Gracián, el generalmente llamado «conceptismo», se caracteriza por la elipsis y la concentración de un máximo de significado en un mínimo de forma, procedimiento que Gracián lleva a su extremo en el "Oráculo manual y arte de prudencia", compuesto íntegramente de casi tres centenas de máximas comentadas. En ellas se juega constantemente con las palabras y cada frase se convierte en un acertijo por obra de los más diversos mecanismos de la retórica.

Si los manieristas, como Herrera o Góngora, tuvieron por modelo el estilo oratorio de Virgilio y Cicerón, Gracián —barroco— adopta el estilo lacónico de Tácito, Séneca y Marcial, su paisano. Ello no significa, sin embargo, que el suyo sea un estilo llano, al modo de Cervantes. La dificultad es patrimonio tanto de cultistas gongorinos como de conceptistas. La diferencia estriba en que el esfuerzo de comprensión del lector de estos últimos exige descifrar los múltiples significados ocultos tras cada expresión lingüística. La concisión sintáctica, además, obliga frecuentemente a suponer elementos elididos, ya sean palabras con significado léxico o conectores lógicos.

La prosa de Gracián está conformada por oraciones independientes y breves separadas por signos de puntuación (coma, punto y punto y coma) y no por nexos de subordinación. Predomina, pues, la yuxtaposición y la coordinación. La escasa presencia de oraciones subordinadas en periodos complejos, lejos de facilitar la comprensión, la hace ardua, se hace necesario suplir la lógica de las relaciones entre las sentencias, deduciéndola del sentido, de la idea que se expresa, lo que no siempre es fácil. La profundidad de Gracián, pues, está en el concepto y en la elusión, no en la sintaxis.

La concisión expresiva se manifiesta en la frecuente deixis de elementos con función anafórica que aparecen sobreentendidos por el contexto lingüístico que lo antecede o porque (como en el caso frecuente de los nexos) la relación lógica se da por supuesta y delegada a la inteligencia del lector. De modo que es habitual la elipsis del verbo «ser», como se aprecia en su conocida máxima «Lo bueno, si breve, dos veces bueno. Y aun lo malo, si poco, no tan malo» (), que además es una declaración de intenciones que se puede aplicar al laconismo de su elocución. Muy frecuente es, con este mismo objetivo, la utilización del zeugma. También se da la elipsis del sustantivo. Aquí vemos un ejemplo de sustantivo omitido en zeugma: «Dieron luego conmigo en un calabozo cargándome de hierros, que este fue el fruto de los míos» (mis yerros —de errar—, se entiende: ).

La riqueza semántica, casi siempre polisémica, ofrece en Gracián la mayor intensidad que se había dado hasta entonces en la literatura española. Nunca bastará con el principal significado denotativo, sino que se han de buscar todas las acepciones simultáneas. La dilogía, la ambivalencia semántica, los dobles y hasta triples sentidos son constantes en el quehacer de Gracián. No para crear ambigüedad, sino para ofrecer todas las posibilidades de conocimiento y percepción del mundo. La doble interpretación en el plano real y el alegórico o filosófico es lo que confiere una densidad extraordinaria a su obra. Y esto sucede tanto a nivel morfológico o léxico como oracional y textual. Así, ejemplos de dobles sentidos frecuentes en él son «río» (de ‘reír’ y ‘corriente de agua’) o «yerro» (‘metal’ y ‘error’).

En la lengua de Gracián domina el verbo y el sustantivo, en contraposición al escaso uso del epíteto, pues «el estilo lacónico los tiene desterrados en primera ley de atender a la intensión, no a la extensión» ("Agudeza y arte de ingenio", discurso LX). Muchas de sus sentencias, preferentemente en el "Oráculo manual y arte de prudencia", comienzan con un verbo, a veces precedido de la partícula negativa. En muchas ocasiones el verbo se convierte en el eje de la frase.

Por otro lado Gracián usa constantemente la antítesis, el contraste, la paradoja, reforzándolos en sintagmas y oraciones de estructura bimembre, que se oponen entre sí. Esta simetría conduce a un ritmo ágil, una prosa binaria, semejante a la utilizada por fray Antonio de Guevara en el siglo XVI. Destaca cómo construye oposiciones con el uso de la paronomasia, como se observa en los dobletes "cielo-cieno", "tálamo-túmulo", "joyas-hoyas", "vestal-bestial" o "gusto-gasto". El mismo retruécano sirve a menudo a la expresión del contraste: el hombre «no come ya para vivir, sino que vive para comer» ("Criticón", I, X); los españoles «tienen tales virtudes como si no tuviesen vicios, y tienen tales vicios como si no tuviesen virtudes» ("Criticón", II, III); «así que de todo hay en el mundo: unos que siendo viejos quieren parecer mozos, y otros que siendo mozos quieren parecer viejos.» ("Criticón", III, I).

Otro rasgo estilístico de la prosa de Gracián es la búsqueda de la precisión léxica, para la que en muchas ocasiones se recurre al neologismo de creación. Y en este terreno, es donde aparece el sustantivo, la verdadera piedra de toque del estilo de Gracián, en detrimento de adjetivos, adverbios y nexos de subordinación. Así aparecen términos como «conreyes», «descomido», «desañar», «despenado» o «reconsejo», nuevos en el acervo del léxico español.

Otras veces recurre a acepciones caídas en desuso y que él pone en primer plano (plausible=admirable, plático=práctico, brujulear=sondear el carácter, sindéresis=capacidad natural para el juicio correcto, etc.) o a cultismos traídos de nuevo a enriquecer el idioma, como «crisis» (estimación, juicio), «especiosidad» (perfección), «delecto» (capacidad de discernimiento), «deprecar» (pedir con insistencia), «exprimir» (expresar), «convicio» (ofensa), «intensión» (efectividad). Otras veces trae a colación nombres propios para crear vocablos comunes: «su minerva» (su inteligencia o sabiduría). Por último encontramos aragonesismos que concurren a aumentar el caudal del vocabulario español: «podrecer» (pudrir), «defecarse» (decantarse el vino de impurezas, y por extensión, lustrarse, perfeccionarse), entre otros.

Es muy característica la polisemia etimológica o falsamente etimológica en el nombre, a partir de peregrinas etimologías inventadas por él. Así, de Dios dirá «que del dar (...) tomó el Señor su Santísimo y Augustísimo remombre de "Dí-os" en nuestra lengua española» . En el mismo lugar ("Agudeza...", XXXII), nos aporta otro caso similar: «Ponderaba un varón grave y severo el tiempo que roban en España las comedias, y las llamaba come-día y come-días.» . Otras veces utiliza procedimientos de derivación y composición para crear neologismos nominales insólitos, como «espantaignorantes», «arrapaltares», «marivenido», llegando a extremos de monstruosidad lingüística, en casos como los de «serpihombre» o «monstrimujer». El proceso inverso a la composición se da también en ejemplos como «casa y miento» (perversa interpretación de las raíces léxicas de ‘casamiento’), o «cumplo y miento» (de ‘cumplimiento’).

Conocido es su uso de máximas de tradición grecolatina y humanística y también del refranero popular, pero siempre llevándolas unas y otro a su terreno, reinterpretando su sentido o acomodándolo a los tiempos y, en el caso de los dichos del folclore paremiológico, tergiversando su enunciación y manipulándolo a su gusto. Así, a la dificultad y concisión de su estilo le cuadra una de sus más acertadas manipulaciones del acervo común: su frase «A pocas palabras, buen entendedor», que otorga un sentido radicalmente distinto al proverbio popular, pues justifica su estilo elíptico por la inteligencia de los lectores que han de acercarse a la obra de Gracián.

La prosa de Gracián no es producto de la espontaneidad, pues el estudio del autógrafo de "El Héroe" realizado por Romera-Navarro demuestra que corregía y pulía constantemente su estilo. Elabora la forma tanto como cuida el contenido ideológico, lo que muestra su clara conciencia de escritor. La búsqueda de la originalidad y el rechazo del lenguaje manido hacen del suyo un arte minoritario, distinguido y elevado; pues como dice en el prólogo —aunque a nombre de Lastanosa, debido indudablemente a su pluma— :





</doc>
<doc id="4628" url="https://es.wikipedia.org/wiki?curid=4628" title="Siglo de Oro">
Siglo de Oro

El Siglo de Oro español fue un periodo de florecimiento del arte y la literatura en España, que coincidió con el auge político y posterior declive de la dinastía de los Austrias o Habsburgo españoles. El Siglo de Oro no supone fechas precisas y generalmente se considera que duró más de un siglo. Su inicio no sería antes de 1492, con el fin de la Reconquista, los viajes de Cristóbal Colón al Nuevo Mundo, y la publicación de la "Gramática castellana" de Antonio de Nebrija. Políticamente terminó en 1659, con el Tratado de los Pirineos, ratificado entre Francia y España. El último gran escritor Pedro Calderón de la Barca, falleció en 1681, y su muerte es generalmente considerada como el fin del Siglo de Oro español de las artes y las letras.

El término 'Siglo de Oro' fue concebido por el erudito y anticuario dieciochesco Luis José Velázquez, marqués de Valdeflores (1722-1772), quien lo empleó por primera vez en 1754, en su obra crítica pionera "Orígenes de la poesía castellana", aunque para referirse exclusivamente al siglo XVI. Posteriormente la definición se amplió, entendiendo toda la época clásica o de apogeo de la cultura española, esencialmente el Renacimiento del siglo XVI y el Barroco del siglo XVII. Para la historiografía y los teóricos modernos, pues, y ciñéndose a fechas concretas de acontecimientos clave, el Siglo de Oro abarca desde la publicación de la "Gramática castellana" de Nebrija en 1492 hasta la muerte de Calderón en 1681.

A finales del siglo XVIII ya se había popularizado la expresión «Siglo de Oro» (creada a mediados del siglo por Valdeflores, como dijimos, y que pronto prendió) que suscitaba la admiración de don Quijote en su famoso discurso sobre la "Edad de Oro". En el siglo XIX la terminó de consagrar el hispanista norteamericano George Ticknor en su "Historia de la Literatura española", aludiendo al famoso mito de la "Teogonía" de Hesíodo.

Con su unión dinástica, los Reyes Católicos esbozaron un estado políticamente fuerte, consolidado más adelante, cuyos éxitos envidiaron algunos intelectuales contemporáneos, como Nicolás Maquiavelo; pero ideológicamente dominado por la Inquisición eclesiástica. Los judíos que no se cristianizaron fueron expulsados en 1492 y se dispersaron fundando colonias hispanas por toda Europa, Asia y Norte de África, donde siguieron cultivando su lengua y escribiendo literatura en castellano, de forma que produjeron también figuras notables, como José Penso de la Vega, Miguel de Silveira, Jacob Uziel, Miguel de Barrios, Antonio Enríquez Gómez, Juan de Prado, Isaac Cardoso, Abraham Zacuto, Isaac Orobio de Castro, Juan Pinto Delgado, Rodrigo Méndez Silva o Manuel de Pina, entre otros. En enero de 1492 Castilla conquista Granada, con lo que finaliza la etapa política musulmana peninsular, aunque una minoría morisca habite más o menos tolerada hasta tiempos de Felipe III. Además, en octubre Colón llega a América y el afán guerrero cultivado durante las guerras medievales de la Reconquista se proyectará sobre las nuevas tierras, como asimismo sobre Europa en "la gesta más extraordinaria de la historia de la Humanidad" según escribe el historiador Pierre Vilar. Sin embargo, y sobre todo a mediados del XVI, son perseguidos o tienen que emigrar los erasmistas y los protestantes españoles, entre ellos los traductores de la Biblia al castellano, como Francisco de Enzinas, Casiodoro de Reina y Cipriano de Valera, además de los humanistas protestantes Juan Pérez de Pineda, Antonio del Corro o Juan de Luna, entre otros.

Durante el apogeo cultural y económico de esta época, España alcanzó prestigio internacional en toda Europa. Cuanto provenía de España era a menudo imitado; y se extiende el aprendizaje y estudio del idioma (véase Hispanismo).

Las áreas culturales más cultivadas fueron literatura, las artes plásticas, la música y la arquitectura. El saber se acumula en las prestigiadas universidades de Salamanca y Alcalá de Henares.

Las ciudades más importantes de este periodo son: Sevilla, por recibir las riquezas coloniales y a los comerciantes y banqueros europeos más importantes, Madrid, como sede de la Corte, Toledo, Valencia, Valladolid (que fue capital del Reino a comienzos del siglo XVII) y Zaragoza.

En el terreno de las humanidades su cultivo fue más extenso que profundo y de matiz más divulgativo que erudito, a pesar de que la filología ofreció testimonios eminentes como la "Biblia políglota complutense" o la "Biblia regia" o "Políglota de Amberes" de Benito Arias Montano y las numerosas gramáticas y vocabularios de las lenguas indígenas recién descubiertas, obra de los numerosos frailes misioneros que evangelizaron el continente recién descubierto.

También en el campo científico hubo avances importantes que, por ejemplo, en agronomía llegaron a constituir una revolución (el Viejo mundo aportó al Nuevo la caña de azúcar, el trigo y la vid; el Nuevo aportó al Viejo la patata, el maíz, el frijol, el cacao, el pimiento y el tabaco); la Lingüística se desarrolló notablemente (Francisco Sánchez de las Brozas y su "Minerva"; Geografía y Cartografía (el cosmógrafo Martín Cortés de Albacar descubre la declinación magnética de la brújula y el polo norte magnético, que sitúa entonces —se mueve a lo largo de la historia— en Groenlandia y desarrolla el nocturlabio, y su discípulo Alonso de Santa Cruz inventa la carta esférica o proyección cilíndrica; la Antropología y Ciencias naturales (Botánica, Mineralogía, etc.), como consecuencia del descubrimiento de América. Hubo también figuras eminentes en Matemáticas (Sebastián Izquierdo desarrolla el cálculo de la combinación y la permutación y preconiza el empirismo; Juan Caramuel esboza el cálculo de probabilidades; Pedro Nunes descubre la loxodrómica e inventa el nonio; Omerique, Pedro Ciruelo, Juan de Rojas y Sarmiento, Rodrigo Zamorano), Física, Medicina, Farmacología (Andrés Laguna; en 1638 la Condesa de Chinchón, esposa del virrey del Perú Luis Fernández de Cabrera, descubre y divulga las propiedades contra las fiebres y la malaria de la quina, antecesor de la quinina, que los curanderos nativos empleaban), Psicología (Juan Luis Vives, Juan Huarte de San Juan) y Filosofía (Francisco Sánchez el Escéptico formula el punto de partida para el Racionalismo y la filosofía de Descartes; Francisco Suárez comprendía y se replantea toda la filosofía occidental anterior). Igualmente se desarrollaron, a causa del gran impacto que tuvieron los descubrimientos de nuevos pueblos, el derecho natural y el derecho de gentes, con figuras como Bartolomé de las Casas, influyente precursor de los derechos humanos y defensor del iusnaturalismo en su "De regia potestate", o Francisco de Vitoria.
El Siglo de Oro abarca dos periodos estéticos, que corresponden al Renacimiento del siglo XVI (reinados de los Reyes Católicos, Carlos I y Felipe II), y al Barroco del siglo XVII (reinados de Felipe III, Felipe IV y Carlos II). El eje de estas dos épocas o fases puede ponerse en el Concilio de Trento y la reacción contrarreformista.

España produjo en su edad clásica algunas estéticas y géneros literarios característicos que fueron muy influyentes en el desarrollo ulterior de la Literatura Universal.

Entre las estéticas, fue fundamental el desarrollo de una realista y popularizante tal como se había venido fraguando durante toda la Edad Media peninsular como contrapartida crítica al excesivo, caballeresco y nobilizante idealismo del Renacimiento: se crean géneros tan naturalistas como el celestinesco ("Tragicomedia de Calisto y Melibea" de Fernando de Rojas, "Segunda Celestina" de Feliciano de Silva, etc.), la novela picaresca ("Lazarillo de Tormes", anónimo, "Guzmán de Alfarache", de Mateo Alemán, "La vida del Buscón" de Francisco de Quevedo, "Estebanillo González"), o la proteica novela polifónica moderna ("Don Quijote de la Mancha"), que Cervantes definió como «escritura desatada».

A esta vulgarización literaria corresponde una subsecuente vulgarización de los saberes humanísticos mediante los populares géneros de las misceláneas o silvas de varia lección, leidísimas y traducidísimas en toda Europa, y cuyos autores más importantes son Pero Mexía, Luis Zapata, Antonio de Torquemada, etcétera.

A esta tendencia anticlásica corresponde también la fórmula de la comedia nueva creada por Lope de Vega y divulgada a través de su "Arte nuevo de hacer comedias en este tiempo" (1609): una explosión inigualable de creatividad dramática acompañó a Lope de Vega y sus discípulos (Juan Ruiz de Alarcón, Tirso de Molina, Guillén de Castro, Antonio Mira de Amescua, Luis Vélez de Guevara, Juan Pérez de Montalbán, entre otros), que quebrantaron como él las unidades aristotélicas de acción, tiempo y lugar: todos los autores dramáticos de Europa acudieron luego al teatro clásico español del Siglo de Oro en busca de argumentos y como una rica almoneda y cantera de temas y estructuras modernas cuyo pulimento les ofrecerá obras de carácter clásico.

A fines del siglo XVI se desarrolla notablemente la Mística (Juan de la Cruz, San Juan Bautista de la Concepción, San Juan de Ávila, Santa Teresa de Jesús) y la Ascética (fray Luis de León, fray Luis de Granada), para entrar en el siglo XVII en decadencia tras una última corriente innovadora, el Quietismo de Miguel de Molinos.

Muchos de los temas literarios del siglo XVI provenían de la rica tradición medieval pluricultural, árabe y hebrea, del "Romancero" y de la impronta italianizante de la cultura española, a causa de la presencia política del reino español en la península itálica durante largos siglos. Por otra parte, géneros dramáticos como el entremés y la novela cortesana introdujeron también la estética realista en los corrales de comedias, y aun la comedia de capa y espada tenía su representante popular en la figura del gracioso.

A esta corriente de realismo popularizador sucedió una reacción religiosa, nobiliaria y cortesana de signo Barroco que también hizo notables aportaciones estéticas, pero que ya correspondía a una época de crisis política, económica y social. Al lenguaje claro y popular del siglo XVI, el castellano vivo, creador y en perpetua ebullición de Bernal Díaz del Castillo y Santa Teresa («sin afectación alguna escribo como hablo, y solamente tengo cuidado en escoger las palabras que mejor indican lo que quiero decir», escribía Juan de Valdés, de lo que se hacía eco Garcilaso cuando decía «"más a las veces son mejor oídos / el puro ingenio y lengua casi muda / testigos limpios de ánimo inocente / que la curiosidad del elocuente"») sucederá la lengua más oscura, enigmática y cortesana del Barroco. Y así resulta la paradoja de que la literatura española del Renacimiento de hace cinco siglos es más clara, legible y entendible que la literatura del Barroco de hace tan solo cuatro.

En efecto, la lengua literaria del siglo XVII se enrarece con las estéticas del Conceptismo y del Culteranismo, cuyo fin era elevar lo noble sobre lo vulgar, intelectualizando el arte de la palabra; la literatura se transforma en una especie de escolástica, en un juego o un espectáculo cortesano, aunque las producciones moralizantes y por extremo ingeniosas de un Francisco de Quevedo y un Baltasar Gracián distorsionan la lengua, aportándole más flexibilidad expresiva y una nueva cantera de vocablos (cultismos). El lúcido Calderón crea la fórmula del auto sacramental, que supone la vulgarización antipopular y esplendorosa de la Teología, en deliberada antítesis con el entremés, que, sin embargo, todavía sigue teniendo curso; pues estos autores todavía son deudores y admiradores de los autores del XVI, a los que imitan conscientemente, aunque para no repetirse refinan sus fórmulas y estilizan cortesanamente lo que otros ya crearon, de forma que se perfeccionan temas y fórmulas dramáticas ya usadas por otros autores anteriores. La escuela de Pedro Calderón de la Barca (Francisco de Rojas Zorrilla, Agustín Moreto, Antonio de Solís y Rivadeneyra, Juan Bautista Diamante, Agustín de Salazar, Álvaro Cubillo de Aragón y Francisco Bances Candamo entre otros) proseguirá con este modelo, que continuarán y cerrarán definitivamente a comienzos del siglo XVIII José de Cañizares y Antonio de Zamora.

España experimentó una gran ola de italianismo que invadió la literatura y las artes plásticas durante el siglo XVI, lo que constituye uno de los rasgos de identidad del Renacimiento: Garcilaso de la Vega, Juan Boscán y Diego Hurtado de Mendoza introdujeron el verso endecasílabo italiano y el estrofismo y los temas del Petrarquismo; Boscán escribió el manifiesto de la nueva escuela en la "Epístola a la duquesa de Soma" y tradujo "El cortesano" de Baltasar de Castiglione, ideal del caballero renacentista, en perfecta prosa castellana; contra estos se levantó una corriente nacionalista encabezada por el nostálgico Cristóbal de Castillejo, residente en Viena, o fray Ambrosio Montesino, partidarios ambos del octosílabo, de las coplas castellanas y de la inspiración popular; todos eran, sin embargo, renacentistas.

En la segunda mitad del siglo XVI la tendencia italiana y la autóctona castellana coexistieron y se desarrolló la ascética y la mística, alcanzándose cumbres como las que representan San Juan de la Cruz, Santa Teresa y Fray Luis de León, entre muchas otras que merecerían larga reseña; Ignacio de Loyola crea la Compañía de Jesús, que instruirá a grandes eruditos por toda Europa en todos los órdenes del conocimiento y además fomentará el estudio de las lenguas clásicas. El petrarquismo siguió siendo cultivado por autores como Fernando de Herrera, y un grupo de jóvenes nuevos autores comenzó a desarrollar un "Romancero" nuevo, a veces de tema morisco: Lope de Vega, quien desarrollará además un culto casticismo a través de sus diversos cancioneros ("Rimas", "Rimas sacras", "La Circe", "La Filomela", "Rimas humanas y divinas"...) Luis de Góngora y Miguel de Cervantes, entre otros; el mejor poema de épica culta en español fue compuesto en esta época por Alonso de Ercilla: "La Araucana", que narra la conquista de Chile por los españoles. En 1584, año de publicación de "La Araucana", Francisco Hernández Blasco dio a luz otro extenso poema épico en estancias de asunto evangélico, la "Universal redención", que tendría numerosas ediciones posteriores y notable éxito. Entre las figuras excepcionales de la lírica aparecen poetas tan interesantes como Francisco de Aldana, Andrés Fernández de Andrada, autor de la serena y meditativa "Epístola moral a Fabio", los hermanos Bartolomé y Lupercio Leonardo de Argensola, Fernando de Herrera, Francisco de Medrano, Francisco de Rioja, Rodrigo Caro, Baltasar del Alcázar o Bernardo de Balbuena, quien en 1624 dará al mundo la segunda gran epopeya culta en español, "El Bernardo o Victoria de Roncesvalles".

Posteriormente, durante el siglo XVII, la expresión literaria fue dominada por los movimientos estéticos del conceptismo y del culteranismo, expresado el primero en la poesía de Francisco de Quevedo, principalmente satírica, moral y filosófico-existencial, y el segundo en la lírica de Luis de Góngora (los "Sonetos", la "Fábula de Polifemo y Galatea" y sobre todo sus "Soledades"). El conceptismo se distinguía por la economía en la forma, a fin de expresar el máximo significado en un mínimo de palabras; esta complejidad se expresaba sobre todo en paradojas y elipsis. El culteranismo, por el contrario, extendía la forma de un significado mínimo y se distinguía por la complejidad sintáctica, por el uso constante del hipérbaton, que hace muy difícil la lectura, y por la profusión de los elementos ornamentales y culturalistas en el poema, que debía descifrarse como un enigma. Ambos parecen sin embargo las caras de una misma moneda que intentaba aquilatar la expresión para hacerla más difícil y cortesana. Luis de Góngora atrajo a su estilo a poetas importantes de personalidad muy acusada, como el Conde de Villamediana, Gabriel Bocángel, sor Juana Inés de la Cruz o Juan de Jáuregui, mientras que el conceptismo tuvo a seguidores más templados, como el Conde de Salinas o imbuidos de un culto casticismo, como Lope de Vega o Bernardino de Rebolledo.

El «monstruo de la naturaleza», como lo llamó Cervantes, fue, en el Siglo de Oro, Lope de Vega, también conocido como «el Fénix de los Ingenios», autor de más de 400 obras teatrales, así como de novelas, poemas épicos, narrativos y varias colecciones de poesía lírica profana, religiosa y humorística. Lope destacó como consumado maestro del soneto. Su aportación al teatro universal fue principalmente una portentosa imaginación, de la que se aprovecharon sus contemporáneos, sucesores españoles y europeos extrayendo temas, argumentos, motivos y toda suerte de inspiración. Su teatro, polimétrico, rompe con las unidades de acción, lugar, tiempo, y también con la de estilo, mezclando lo trágico con lo cómico. Expuso su peculiar arte dramático en su "Arte nuevo de hacer comedias en este tiempo" (1609). Flexibilizó las normas clasicistas del aristotelismo para adecuarse a su tiempo y abrió con ello las puertas a la renovación del arte dramático. También creó el molde de la llamada comedia de capa y espada. En comedia palatina, fue el autor que más recurrió a la ambientación en el reino de Hungría, recurso que se convertiría en frecuente en la literatura de la época. El ciclo de de Lope consta de alrededor de veinte obras.

Junto a él, destacan sus discípulos Guillén de Castro, que prescinde del personaje cómico del gracioso y elabora grandes dramas caballerescos sobre el honor junto a comedias de infelicidad conyugal o tragedias en las que se trata el tiranicidio; Juan Ruiz de Alarcón, que aportó su gran sentido ético de crítica de los defectos sociales y una gran maestría en la caracterización de los personajes; Luis Vélez de Guevara, al que se le daban muy bien los grandes dramas históricos y de honor; Antonio Mira de Amescua, muy culto y fecundo en ideas filosóficas, y Tirso de Molina, maestro en el arte de complicar diabólicamente la trama y crear caracteres como el de Don Juan en "El burlador de Sevilla".

Pueden citarse como obras maestras representativas del teatro áureo español la "Numancia" de Miguel de Cervantes, un sobrio drama heroico nacional; de Lope, "El caballero de Olmedo", drama poético al borde mismo de lo fantástico y lleno de resonancias celestinescas; "Peribáñez y el Comendador de Ocaña", antecedente del drama rural español; "El perro del hortelano", deliciosa comedia donde una mujer noble juguetea con las intenciones amorosas de su plebeyo secretario, "La dama boba", donde el amor perfecciona a los seres que martiriza, y "Fuenteovejuna", drama de honor colectivo, entre otras muchas piezas donde siempre hay alguna escena genial.

"Las mocedades del Cid" de Guillén de Castro, inspiración para el famoso «conflicto cornelliano» de "Le Cid" de Pierre Corneille; "Reinar después de morir" de Luis Vélez de Guevara, sobre el tema de Inés de Castro, que pasó con esta obra al drama europeo; "La verdad sospechosa" y "Las paredes oyen", de Juan Ruiz de Alarcón, que atacan los vicios de la hipocresía y la maledicencia y sirvieron de inspiración para Molière y otros comediógrafos franceses; "El esclavo del demonio" de Antonio Mira de Amescua, sobre el tema de Fausto; "La prudencia en la mujer", que explora el tema de la traición reiterada y donde aparece el recio carácter de la reina regente María de Molina, y "El burlador de Sevilla", de Tirso de Molina, sobre el tema del donjuán y la leyenda del convidado de piedra.

El otro gran dramaturgo áureo en crear una escuela propia fue Pedro Calderón de la Barca; sus personajes son fríos razonadores y con frecuencia obsesivos; su versificación reduce conscientemente el repertorio métrico de Lope de Vega y también el número de escenas, porque las estructuras dramáticas están más cuidadas y tienden a la síntesis; se preocupa también más que Lope por los elementos escenográficos y refunde comedias anteriores, corrigiendo, suprimiendo, añadiendo y perfeccionando; es un maestro en el arte del razonamiento silogístico y utiliza un lenguaje abstracto, retórico y elaborado que sin embargo supone una vulgarización comprensible del culteranismo; destaca en especial en el auto sacramental, género alegórico que se avenía con sus cualidades y llevó a su perfección, y también en la comedia.
De Calderón destacan obras maestras como "La vida es sueño", sobre los temas del libre albedrío y el destino; "El príncipe constante", donde aparece una concepción existencial de la vida; las dos partes de "La hija del aire", la gran tragedia de la ambición en la persona de la reina Semíramis; los grandes dramas de honor sobre personajes enloquecidos por los celos, como "El mayor monstruo del mundo", "El médico de su honra" o "El pintor de su deshonra". De entre sus comedias destacan "La dama duende", y cultivó asimismo dramas mitológicos como "Céfalo y Procris", de los que él mismo sacó la comedia burlesca del mismo título; también, autos sacramentales como "El gran teatro del mundo" o "El gran mercado del mundo" que sugestionaron la imaginación de los románticos ingleses y alemanes.

Tuvo por discípulos e imitadores de estas cualidades a una serie de autores que refundieron obras anteriores de Lope o sus discípulos puliéndolas y perfeccionándolas: Agustín Moreto, maestro del diálogo y la comicidad cortesana; Francisco de Rojas Zorrilla, tan dotado para la tragedia como para la comedia; Antonio de Solís, también historiador y propietario de una prosa que ya es neoclásica, o Francisco Bances Candamo, teorizador sobre el drama, entre otros no menos importantes.

Entre sus discípulos tenemos las comedias clásicas de Agustín Moreto, como la comedia palatina "El desdén, con el desdén", la de figurón "El lindo don Diego" y el drama religioso "San Franco de Sena", que remite a "El condenado por desconfiado" de Tirso de Molina; Francisco de Rojas Zorrilla con la comedia de figurón "Entre bobos anda el juego", el drama de honor "Del rey abajo ninguno" y la deliciosa y moderna comedia "Abre el ojo". De Antonio de Solís, "El amor al uso" y "Un bobo hace ciento"; de Francisco Bances Candamo, las tragedias políticas "El esclavo en grillos de oro" y "La piedra filosofal".

Otro género teatral importante, y a veces descuidado por la crítica, es el entremés, donde mejor y con más objetividad puede estudiarse la sociedad española durante el Siglo de Oro. Se trata de una pieza cómica en un acto, escrita en prosa o verso, que se intercalaba entre la primera y la segunda jornada de las comedias. Corresponde a la farsa europea, y en él destacaron autores como Luis Quiñones de Benavente y Miguel de Cervantes, entre otros.

La prosa en el Siglo de Oro ostenta géneros y autores que han pasado a la historia de la literatura universal. La conquista de América dio lugar al género de las "Crónicas", entre las que podemos encontrar algunas obras maestras, como las de Fray Bartolomé de las Casas, el Inca Garcilaso de la Vega, Bernal Díaz del Castillo, Antonio de Herrera y Tordesillas y Antonio de Solís. También son espléndidas algunas autobiografías de soldados, como las de Alonso de Contreras o Diego Duque de Estrada. La primera obra maestra fue sin duda "La Celestina", pieza teatral irrepresentable y originalísima obra de un desconocido autor y de Fernando de Rojas, que, junto a sus continuaciones por parte de otros autores (el llamado género celestinesco) o sus imitaciones libres (entre ellas la portentosa "La Lozana andaluza" (1528), obra maestra de Francisco Delicado) marcó para siempre el Realismo en una parte esencial de la literatura española, cuya riqueza abona también ficciones caballerescas tan maravillosas y fantásticas como los libros de caballerías, menos leídos en la actualidad de lo que merecen, habida cuenta de que figuran entre sus piezas más destacadas novelas como "Tirante el Blanco", escrita en valenciano, "Amadís de Gaula" o el "Palmerín de Inglaterra"; un autor característico del género fue Feliciano de Silva.

La novela sentimental se abre y se cierra en medio siglo con dos obras maestras: "Cárcel de amor" (1492) de Diego de San Pedro y "Proceso de cartas de amores" (1548), una novela epistolar de Juan de Segura (1548). Junto a estas hay que hablar también de otras dos obras maestras del género de la novela morisca: la "Historia del Abencerraje y de la hermosa Jarifa (1565) y "Ozmín y Daraja" de Mateo Alemán (1599).

La novela picaresca tiene entre sus máximas creaciones, obras maestras como el anónimo "Lazarillo de Tormes" (1554), una sátira anticlerical y descarnada de las ínfulas de nobleza y el sentido de la honra de la clase alta; "Vida del pícaro Guzmán de Alfarache" (1599 y 1604) de Mateo Alemán, pesimista reflexión sobre el destino humano; la "Vida del escudero Marcos de Obregón" (1618) de Vicente Espinel, llena por el contrario de alegría de la vida; "La vida del Buscón" (1604-1620) de Francisco de Quevedo, una obra maestra del humor y del lenguaje conceptista, la anticlerical "Segunda parte de la vida de Lazarillo" (1620) del protestante Juan de Luna, y la obra de enigmática autoría Estebanillo González (1646), que ofrece una visión espléndida de la decadencia de España en el escenario europeo, y de la Guerra de los Treinta Años. La novela cortesana suministró las obras maestras que constituyen las "Novelas ejemplares" (1613) de Miguel de Cervantes, cada una en sí misma un experimento narrativo; su inmortal "Don Quijote de la Mancha" (1605 y 1615), de la que habría que escribir capítulo aparte a causa de la riqueza de los contenidos y cuestiones que plantea, que viene a ser la primera novela polifónica de la literatura europea. La novela pastoril cuenta con obras maestras como las "Dianas" de Jorge de Montemayor (1559 y 1604) y de Gaspar Gil Polo (1564), "La constante Amarilis" (1607) de Cristóbal Suárez de Figueroa o "Siglo de Oro en las selvas de Erifile" (1608) de Bernardo de Balbuena. La novela bizantina cuenta con ejemplos como "El peregrino en su patria" (1634) de Lope de Vega, quien realiza la hazaña de incluir todas sus aventuras en la Península, el "Persiles" (1617) de Cervantes o el "León prodigioso" (1634) de Cosme Gómez Tejada de los Reyes.

Novela filosófica emparentada con este género es el "Criticón" (1651, 1653 y 1657), de Baltasar Gracián, alegoría de la vida humana. La prosa doctrinal, en ciernes ensayística, tiene por autores modélicos a Pero Mexía, Luis Zapata, Fray Antonio de Guevara ("Epístolas familiares", 1539, "Relox de príncipes", 1539), Fray Luis de León ("De los nombres de Cristo"), San Juan de la Cruz ("Comentarios" al "Cántico espiritual" y otros poemas), Francisco de Quevedo ("Marco Bruto" y "Providencia de Dios") y Diego Saavedra Fajardo ("República literaria" y "Corona gótica").

Jean Rotrou (1609-1650) y Paul Scarron (1610-1660) alcanzaron grandes éxitos traduciendo o imitando a los autores españoles, y estos influyeron en los mayores dramaturgos galos, como por ejemplo Pierre Corneille y Molière, por no mencionar otros de menor importancia, como Thomas Corneille, Alain René Lesage, John Vanbrugh etc. Las obras de teatro españolas extendieron su influjo al ser traducidas, por ejemplo, en Holanda (por Theodore Rodenburg) e Inglaterra (John Webster, Fletcher, Dryden, etc.)

La filosofía del Siglo de Oro español abarca todo el pensamiento que va desde el primer Humanismo hasta la llegada del Racionalismo en el siglo XVIII. A pesar de que en España convivían tres religiones; el Judaísmo, el Cristianismo y el Islam, es cierto que se desarrolló una filosofía que llegaría a culminar en el período Barroco.
La filosofía del Siglo de Oro se divide en dos apartados, la del Renacimiento y la del Barroco.

Durante el Renacimiento encontramos al primer gran humanista de España, Antonio de Nebrija, con su gramática española. Nebrija consiguió crear las primeras reglas de la lengua que luego tanta difusión tendrían con la fundación de la Real Academia Española.

Por otra parte, el gran mecenas durante el humanismo fue el cardenal Francisco Jiménez de Cisneros, quien puso su empeño en reformar las costumbres clericales. En 1499 fundó la Universidad de Alcalá de Henares, que superó en prestigio e influencia a todas las demás excepto la de Salamanca, su mayor rival.

Carlos I defendió las nuevas teorías de Erasmo y la nueva corriente humanista. Fiel seguidor del Erasmismo fue Juan Luis Vives. Se convirtió en un reformador de la educación europea y en un filósofo moralista de talla universal, proponiendo el estudio de las obras de Aristóteles en su lengua original y adaptando sus libros destinados al estudio del latín a los estudiantes; substituyó los textos medievales por otros nuevos, con un vocabulario adaptado a su época y al modo de hablar del momento e hizo los primeros aportes a una ciencia en germen, la psicología.

Los nuevos descubrimientos en el Nuevo Mundo y la colonización española de las Indias llevaron a hacer reflexionar a algunos pensadores sobre el trato que los indígenas merecían. Las controversias fue suscitada por el dominico Fray Bartolomé de las Casas en su "Brevísima relación de la destrucción de las Indias", donde describía con tintes horrorosos la colonización española de América y defendía el iusnaturalismo. El contenido del escrito hizo convocar una disputa entre 1550 y 1551 en Valladolid contra su principal contrincante, Juan Ginés de Sepúlveda, que defendía el consuetudinarismo, la bondad de la colonización española y el derecho de guerra. Esta disputa llegó a llamarse la «Junta de Valladolid».
La Universidad de Salamanca contribuyó al pensamiento político, económico y moral.
El resurgimiento del nuevo espíritu se ve encarnado en la principal figura con Francisco de Vitoria, teólogo dominico, profesor de Salamanca, que rechazó toda argumentación basada en puras consideraciones metafísicas por estar a favor del estudio de los problemas reales que planteaba la vida política y social contemporánea. Fue el primero en establecer los conceptos básicos del derecho internacional moderno, basándose en la regla del derecho natural. Afirmaba así las libertades fundamentales como la palabra, de comunicación, comercio y tránsito por los mares, siempre que las naciones y razas no se perjudicaran mutuamente.

El Cristianismo en España dio sus propios pensadores y teólogos, la mayoría ortodoxos mediante la Contrarreforma, pero también heterodoxos en una Reforma que sólo pudo cuajar en el extranjero. En cuanto a los ortodoxos, destaca San Ignacio de Loyola, que escribió sus "Ejercicios espirituales" y fundó la Compañía de Jesús, con la que se quería llegar a la unidad religiosa y que con su red de colegios renovó la enseñanza de las lenguas clásicas. En poesía se desarrollaron movimientos de ascética y mística muy profundos y personales. La lírica del Renacimiento se caracteriza por tener a un grupo de religiosos que transmitían su filosofía mediante la poesía. Cabe destacar a San Juan de la Cruz, Santa Teresa de Jesús y a fray Luis de León como figuras eminentes entre un gran conjunto de figuras importantes.

La llegada del Barroco cambió por completo la mentalidad renacentista del humanismo. La visión de la vida se volvió pesimista y todas las perspectivas desembocaron en el desengaño. La prosa filosófica brilla con Luis de Molina, iluminado establecido en Roma. Su doctrina apodada molinismo tuvo una gran repercusión e influencia en los pensadores y escritores barrocos posteriores a él. Su pensamiento mezcla los principios de la religión con una elaborada filosofía moral. Molina combatió el determinismo con el libre albedrío. Sus obras acerca de la libertad fueron muy seguidas por los pensadores del siglo posterior.

El filósofo y médico Gómez Pereira rechaza los conceptos medievales para defender los métodos empíricos en que se basaría la ciencia de los dos siglos posteriores. Se le considera, junto con el escéptico Francisco Sánchez, uno de los precursores de Descartes e influyó en sus trabajos posteriores, siendo el primero en sugerir el automatismo de las bestias, la teoría del conocimiento humano y la inmortalidad del alma.

La Universidad de Salamanca también aportó bastante al pensamiento del Barroco temprano. Melchor Cano escribió "De Locis Theologicis", obra en la que estableció las diez fuentes para la demostración teológica: la Sagrada Escritura, la Tradición Apostólica, la autoridad de la Iglesia católica, la autoridad de los Concilios ecuménicos, la autoridad del Sumo Pontífice, la doctrina de los Padres de la Iglesia, la doctrina de los doctores escolásticos y canonistas, la verdad racional humana, la doctrina de los filósofos y la historia.

En la transición del Renacimiento al Barroco se encuentra Francisco Suárez, hombre de gran cultura y sabio en los aspectos clásicos. Continuó con la doctrina tomista. En su gran obra jurídica "De legibus ac Deo legislatore", muy fecunda para la doctrina del iusnaturalismo y el derecho internacional, se encuentra ya la idea del pacto social.

Con la antropología se hicieron grandes avances. La principal figura fue José de Acosta, que adelantó tres siglos la teoría de la evolución darwiniana.

En las artes plásticas destaca la pintura; a la primera fase corresponden los dos Berruguetes, el pintor Pedro y el escultor Alonso, Pedro Machuca, Luis de Morales «el Divino», los leonardescos Juan de Juanes y Fernando Yáñez de la Almedina; a la segunda Juan Fernández de Navarrete, «el Mudo», Alonso Sánchez Coello así como el Greco, principal exponente del Manierismo pictórico en Castilla.

Al barroco pertenecen Diego Velázquez, pintor de complejas composiciones intelectualizadas que ahonda en el misterio de la cruda e intensa luz y la perspectiva aérea; los tenebristas caravaggiescos Francisco de Zurbarán, gran pintor de frailes y bodegones, Francisco Ribalta y José de Ribera, formado en Italia, donde era llamado «el Españoleto», y a quien se le daban especialmente bien las tonalidades de la piel; en Sevilla los dos Herreras (el Viejo y el Mozo), Bartolomé Esteban Murillo, polo positivo frente al lúgubre Juan de Valdés Leal, y, en Córdoba, Antonio del Castillo.

Hay que citar también a Juan Bautista Maíno, pintor de alegorías políticas, Claudio Coello, Juan Carreño de Miranda, el florentino Vicente Carducho, el retratista Juan Pantoja de la Cruz; Luis Tristán, uno de los escasos discípulos del Greco, que añade al estilo del maestro elementos naturalistas; Juan Bautista Martínez del Mazo, Pedro Orrente, Bartolomé González y Serrano, el cartujo Juan Sánchez Cotán, famoso por sus místicos bodegones, Eugenio Cajés, Antonio Pereda, autor de "El sueño del caballero"; Mateo Cerezo, el paisajista Francisco Collantes, Juan Antonio Frías y Escalante, José Antolínez, el aragonés Jusepe Martínez y otros muchos.

En lo tocante a escultura tenemos ya en el Prerrenacimiento y primeros años del XVI las figuras extranjeras que trabajaron en España: Domenico Fancelli, Pietro Torrigiano y Jacopo Florentino, también llamado "el Indaco". La primera generación de escultores españoles del Renacimiento en Castilla estuvo compuesta por Vasco de la Zarza (trascoro de la catedral de Ávila), Felipe Vigarny (retablo mayor de la catedral de Toledo), Bartolomé Ordóñez (sillería del coro de la catedral de Barcelona) y Diego de Siloé (sepulcro de don Alonso de Fonseca y Acevedo en el Convento de las Úrsulas de Salamanca); en la Corona de Aragón destaca el trabajo de Damián Forment (retablo mayor de la Basílica del Pilar, 1509 y del monasterio de Poblet, 1527), Gil Morlanes el Viejo (portada de la iglesia de Santa Engracia de Zaragoza) y Gabriel Yoly, que talló en madera sin policromar el retablo mayor de la catedral de Teruel en 1536.

En el Manierismo hay que nombrar por supuesto el correlato de la ascética y la mística de la segunda mitad del siglo XVI: el gran Alonso Berruguete, el gallego Gregorio Fernández (1576-1636) que trabajó en Valladolid, los escultores clasicistas italianos Leone Leoni y su hijo Pompeyo Leoni, que trabajaron para el Real Monasterio de San Lorenzo de El Escorial; los barrocos Francisco del Rincón (h.1567-1608) y Pedro Vicálvaro, de la Escuela castellana, y Juan de Juni; de la Escuela andaluza Jerónimo Hernández (1540-1586), Andrés de Ocampo (1555?-1623), Juan Martínez Montañés (1568 - 1649), Juan de Mesa (1583 - 1627), Francisco de Ocampo y Felguera (1579-1639), Alonso Cano (1601-1667), también pintor, que desembocaron en el pleno Barroco ya con escultores como Pedro de Mena (1628-1688), Pedro Roldán (1624 – 1699), su hija Luisa Roldán (la Roldana) y su nieto Pedro Duque y Cornejo; Francisco Ruiz Gijón (1653- 1720), José Risueño, Bernardo de Mora, su hijo José de Mora etc. De Guipúzcoa procedía Juan de Ancheta, de estilo clasicista romano, cuya obra se desarrolló fundamentalmente en Navarra, La Rioja y Aragón. La temática tratada es casi exclusivamente religiosa y sólo en el ámbito de la Corte se da escultura monumental; los temas mitológicos y profanos están ausentes. Se realizan retablos, donde aparecen figuras exentas y en bajorrelieve. Destaca con mucho la imaginería en madera de tradición hispana. En estas obras se pierde la técnica del estofado y posteriormente se usará la policromía. Las figuras son aisladas: para iglesias, conventos y para las procesiones de Semana Santa.

También para la música española fue este el siglo de oro. La labor de compositores cortesanos, que unían su labor de músico a la de dramaturgo y poeta, tiene un buen ejemplo en Juan del Encina en el siglo XV y XVI o en el siglo XVII Juan Hidalgo, que musicó las zarzuelas de Pedro Calderón de la Barca como también hará Tomás de Torrejón y Velasco. En tiempos de Carlos V componen Mateo Flecha "el Viejo" (1481-h.1549), autor de Las "Ensaladas" (Praga, 1581), género que mezcla versos en diversas lenguas. Cristóbal de Morales (Sevilla, h.1500-1553) estudió en Roma, donde publicó algunas misas en 1544. Otros músicos fueron Pedro de Pastrana, Juan Vázquez o Diego Ortiz.

A la época de Felipe II corresponden Gabriel Gálvez, Andrés de Torrentes, Juan Navarro o Rodrigo de Cevallos. En Sevilla trabajó Francisco Guerrero (h.1527-1599), que viajó a Italia y publicó su obra entre 1555 y 1589.

Pero más importante aún fue la labor de compositores y organistas que, partiendo del motete y el madrigal italiano de Palestrina, desarrollaron una gran polifonía, al servicio sobre todo de los oficios religiosos. Destacan las figuras ya mencionadas de Cristóbal de Morales, Francisco Guerrero y sobre todo la del gran Tomás Luis de Victoria, majestuosa, inspirada y mística. Se ha comparado en su profundidad y emoción ascética a la pintura de el Greco, y hoy, gracias a la labor de estudiosos y difusores de su música como Jordi Savall, es reconocido como uno de los más grandes compositores de todos los tiempos. En Roma, que fue donde trabajó principalmente, publicó unas 170 obras -65 motetes, 34 misas, 37 oficios de Semana Santa, "Magnificat" y "Salmos"- desde 1572. A partir de 1587 trabaja para la Emperatriz, a cuya muerte compuso un famoso "Officium Defunctorum" (1605) para seis voces. Su policoralismo -composiciones para dos coros- y cuidado de la armonía -en la escritura de bemoles y sostenidos- lo señalan como precursor del Barroco.

Destaca la escuela de vihuela española del siglo XVI. Aparecieron grandes figuras, como Esteban Daza, Luys de Milán (autor de "El Maestro", 1536, que incluye fantasías, pavanas, tientos, villancicos, romances y obras originales en que la vihuela admite el canto), Alonso Mudarra (con sus "Tres libros de música en cifra para vihuela", Sevilla, 1546), Luis de Narváez ("El Delphín", 1538), Enríquez de Valderrábano ("Silva de Sirenas", 1547), Diego Pisador ("Libro de música de vihuela", 1552), Miguel de Fuenllana ("Orphénica Lyra") y Gaspar Sanz, ya en el último cuarto del siglo XVII, quien dio un impulso definitivo a la guitarra con su obra "Instrucción de música sobre la guitarra española".

Por su obra para teclado ganaron fama el burgalés Antonio de Cabezón (1510-1566) en el siglo XVI, y Juan Bautista Cabanilles y Francisco Correa de Arauxo, en el siglo XVII. Las obras clásicas al respecto son las "Obras de música para tecla, harpa y vihuela" (1578) de Antonio de Cabezón, preparadas por su hijo, y "El Libro de Cifra Nueva para tecla, harpa y vihuela" (Alcalá de Henares, 1557) de Luis Venegas de Henestrosa: ambas muestran la versatilidad de estas composiciones para adaptarse a instrumentos o a voces humanas.

Todos ellos conformaron un periodo de esplendor para la música española, que, salvo figuras aisladas, no volvió a alcanzar las cotas a las que se llegó en esta época. Sin embargo, gran parte de este patrimonio musical se ha perdido y, por ejemplo, de la obra de Francisco de Salinas, que tanto deleitaba a Fray Luis de León, no se ha conservado partitura alguna, sino sólo un tratado teórico.

(véase y ).

En el siglo XVI se pasa del estilo plateresco del Renacimiento durante los Reyes Católicos al más plenamente renacentista durante el reinado de Carlos I; después, durante el de su hijo Felipe II, surge el Manierismo de Juan de Herrera, creador del Estilo herreriano y del monumental monasterio de San Lorenzo de El Escorial y de la espectacular y tristemente inacabada catedral de Valladolid, y durante el siglo XVII domina el Barroco y Churrigueresco.

En España, el Renacimiento comenzó unido a las formas góticas en las últimas décadas del siglo XV. El estilo comenzó a extenderse sobre todo a manos de arquitectos locales: es la razón de un estilo renacentista específicamente español, que reunió la influencia de la arquitectura del sur de Italia, a veces proveniente de libros ilustrados y pinturas, con la tradición gótica y la idiosincrasia local. El nuevo estilo se llama plateresco, debido a las fachadas decoradas en exceso, que recuerdan a los intrincados trabajos de los plateros. Órdenes clásicas y motivos de candeleros ("candelieri") se combinan con libertad en conjuntos simétricos.

En este contexto, el Palacio de Carlos V realizado por Pedro Machuca, en Granada, supuso un logro inesperado dentro del Renacimiento más avanzado de la época. El palacio puede ser definido como una anticipación al manierismo, debido a su dominio del lenguaje clásico y sus logros estéticos rupturistas. Fue construido antes de las principales obras de Miguel Ángel y Palladio. Su influencia fue muy limitada y mal entendida, las formas platerescas se imponían en el panorama general.

Según pasaban las décadas, la influencia gótica desaparece y la búsqueda de un clasicismo ortodoxo alcanzó niveles muy altos. Aunque el plateresco es un término usado habitualmente para definir a la mayoría de la producción arquitectónica de finales del siglo XV y primera mitad del siglo XVI, algunos arquitectos adquirieron un gusto más sobrio, como Diego de Siloé, Rodrigo Gil de Hontañón y Gaspar de Vega. Ejemplos de plateresco son las fachadas de la Universidad de Salamanca, el Colegio Mayor Santa Cruz de Valladolid y del Hostal San Marcos de León.

La cumbre del Renacimiento español está representado por el Real Monasterio de El Escorial, realizado por Juan Bautista de Toledo y Juan de Herrera, en el que una adherencia excesiva al arte de la antigua Roma fue superado por el estilo extremadamente sobrio. La influencia de los techos flamencos, el simbolismo de la escasa decoración y el preciso corte del granito establecieron la base para un estilo nuevo, el herreriano.

Con un estilo más próximo al manierismo, el siglo se cierra con arquitectos como Andrés de Vandelvira (Catedral de Jaén).

Cuando las influencias barrocas italianas llegaron a España, gradualmente sustituyeron en el gusto popular al sobrio gusto clasicista que había estado de moda desde el siglo XVI. Tan pronto como en 1667, las fachadas de la Catedral de Granada de Alonso Cano y la de Jaén de Eufrasio López de Rojas indican la facilidad de su interpretación a la manera barroca de los motivos tradicionales de las catedrales españolas.

El barroco local mantiene raíces en Herrera y en la construcción tradicional en ladrillo, desarrollada en Madrid a lo largo del siglo XVII (Plaza Mayor y Ayuntamiento de Madrid).





</doc>
<doc id="4629" url="https://es.wikipedia.org/wiki?curid=4629" title="Villamartín">
Villamartín

Villamartín es un municipio español de la provincia de Cádiz, Andalucía. Según el INE, en el año 2016 contaba con 12.267 habitantes. Sus coordenadas geográficas son 36º 52' N, 5º 38' O, en el centro de la Sierra de Cádiz. Se encuentra situada a una altitud de 169 metros y a 80 kilómetros de la capital de provincia, Cádiz.

V
Tan cerca de Sevilla (85,3 km) como de la propia capital provincial (85,7 km), su término municipal ocupa una extensión de 210 kilómetros cuadrados. Linda con los términos municipales sevillanos de Utrera y El Coronil, por el norte, y con los términos municipales gaditanos de Espera, Bornos, Arcos de la Frontera, Prado del Rey, Algodonales y Puerto Serrano, en el resto de su contorno, de oeste a este. A una altitud de 167 metros sobre el nivel del mar, su término es la transición de la Campiña a la Sierra.

Su estratégica situación, como nudo articulador de las comunicaciones entre las localidades de la comarca y, por ende, entre las provincias de Cádiz, Sevilla y Málaga, la han ido configurando como el centro de los servicios públicos comarcales.

La principal vía de comunicación es la carretera A-384 Arcos de la Frontera-Antequera, tramo de la antigua carretera nacional CN-342 Jerez-Cartagena. Formará parte, cuando se transforme, de la Autovía A-382 Jerez-Antequera que, actualmente, llega hasta Arcos, En Villamartín, a 22 km de Arcos de la Frontera y a 118 km de Antequera, se produce la distribución de las vías de comunicación con el entorno.

En efecto, las carreteras A-371 Villamartín-Las Cabezas de San Juan (Sevilla) y A-376 Sevilla-Ronda (Málaga) se cruzan aqui y comunican la capital andaluza y el sur de la provincia de Sevilla con la Sierra de Cádiz y el norte de la provincia de Málaga y la A-373 (Villamartín-Gaucín (Málaga) comunica la Sierra con la costa malagueña. Esta situación la convierte en la vía de entrada al Parque Natural de la Sierra de Grazalema por el noroeste y al Parque Natural de los Alcornocales, por el norte.

La autopista Jerez-Antequera, ahora en construcción, pasará por la localidad gaditana en los próximos años (proyecto anulado temporalmente).

Villamartín estuvo habitada desde la Prehistoria, como demuestra el Dolmen de Alberite, monumento megalítico situado en la finca homónima. En 1994 se descubrió un Yacimiento Tartésico en la cima de la colina en que se asienta la ciudad. En ella existió un conjunto de villas romanas dedicadas a la agricultura, cuyos restos se conservan aún en sus numerosos cortijos, que, después del breve dominio visigodo, se convirtieron en machares musulmanes.

De la época medieval se conserva el Castillo de Matrera, que se derrumbó en 2013 debido a la falta de mantenimiento. Este castillo guardaba la frontera sur del reino de Sevilla, de los ataques musulmanes procedentes del reino nazarí de Granada. La actual ciudad fue fundada el 4 de febrero de 1503, mediante Carta-Puebla otorgada por la ciudad de Sevilla a un grupo de 118 vecinos procedentes en su mayoría de los pueblos circundantes. Durante 2003 se celebran los actos del Quinto Centenario de su fundación

La economía de la zona se centra en agricultura y ganadería. Se está construyendo el mayor centro avícola del país

Son muy populares las zopas de tomate y de espárragos, protagonistas de las reuniones de familiares y de amigos.

También tiene una buena confitería, en la que destacan dulces como los Roscos Blancos, los Pitisús, los Cuernos de crema, los Palos de Nata y Torpedos, las Cañas y cordobesas, las sultanas de coco o de almendras, las Palmeras, los Piononos y un sinfín de pasteles artesanos que hacen las delicias de cualquier visitante... También se fabrican alfajores y turrones.

Por otro lado Villamartín también cuenta con pan artesano de buena calidad, fabricándose de varios estilos, además son muy apreciados los molletes, pieza imprescindible en los desayunos villamartinenses.

Desde hace unos años se ha consolidado quesería de prestigio internacional

También posee uno de los mejores quesos de la comarca "Quesos Pajarete" el cual lleva muchísimos premios.

Villamartín cuenta en la actualidad con 4 Colegios públicos, de los cuales tres son de Educación Infantil y Primaria y uno específico de Educación Especial:


También cuenta con 2 institutos: el IES La Loma, situado en la calle Consolación y el IES Castillo de Matrera, en la avenida de Sevilla.

Villamartín cuenta además con varias organizaciones como Asparei-Asadifisa y AFANAS que enriquecen la atención que se ofrece al colectivo de discapacitados/as.

Y un centro de protección de menores (C.P.M. La Cañada), tutorizan a menores de edad sin familias en España

La localidad es sede de la Mancomunidad de municipios de la Sierra de Cádiz, que se ubica en la Alameda de la diputación, y en ella existe un juzgado de paz, situado en la Plaza del Ayuntamiento.

También cuenta con un Hospital Comarcal; el Hospital Virgen de las Montañas, que se ubica junto al IES Castillo de Matrera y a la oficina de empleo.

En la Avenida de la Feria está situado el centro de salud y centro de especialidades de la localidad, al que también acuden personas de localidades vecinas, al igual que al hospital, debido a su cartera de servicios.

También en Villamartín existe una oficina de atención de la Seguridad Social, una sede de ITV, una jefatura de policía local, un parque de bomberos y un cuartel de la guardia civil.

Está previsto que comience a funcionar el geriátrico comarcal instalado junto al hospital de Villamartín.

Villamartín cuenta con unas excelentes instalaciones deportivas, posiblemente las mejores de la Comarca, y la mayoría de ellas situadas en el Polideportivo Municipal, donde podemos encontrar instalaciones de: Baloncesto, Fútbol Sala (ambas contando con diferentes pistas tanto cubiertas como al descubierto), Tenis, Pádel (tanto de hormigón como cristaleras), Ping-Pong, un excelente estadio de fútbol con graderíos cubiertos, pista de atletismo, y césped artificial donde practicar Fútbol 7 o Fútbol 11, una piscina exterior, una piscina cubierta climatizada y un pabellón cubierto con pista polideportiva entre otras muchas instalaciones.

El equipo de fútbol de la localidad es la Unión Deportiva Villamartín. Fue fundado en 1957 con motivo de la unión entre los dos antiguos clubes de "Los Cazadores" y el "Guadalete". También Villamartín cuenta con el equipo A.C.U.DE de Baloncesto, el cuál ha cosechado numerosos éxitos a lo largo de su aún reciente nacimiento.

FERIA DE GANADO Y FIESTAS DE SAN MATEO (SEPTIEMBRE)

Es la Feria ganadera mas antigua de Andalucía, celebrándose desde el siglo XVI. Del 20 al 24 de septiembre.  





</doc>
<doc id="4640" url="https://es.wikipedia.org/wiki?curid=4640" title="Los Guayos">
Los Guayos

Los Guayos es una capital del Municipio Los Guayos del Estado Carabobo en la Región Central de Venezuela, al noroeste del Lago de Valencia. Forma parte del área urbana de la ciudad de Valencia. Tiene una población estimada para el 2011 de 179.568 habitantes.

Los Guayos debe su nombre a una alteración fonética del vocablo indígena "uayos", que significa goma o resina extraída de la corteza del "huayales". 

El pueblo de Los Guayos se halla en la parte norte del municipio homónimo. Actualmente se haya conectado con otras poblaciones que se han expandido con especial celeridad en las últimas décadas. Al Norte-Noreste de Los Guayos pasa la Autopista Caracas-Valencia. El río de Los Guayos fluye del Noreste y Este hacia el Sureste.

El clima es cálido como también intenso de 28·C a 30·C en la temporada de verano.

Los científicos no han llegado a una conclusión sobre el idioma y la clasificación de las etnias que vivían alrededor del Lago de Valencia y, por extensión, en la zona de Los Guayos. Por algunas narrativas como las de Oviedo y Baños y las de Pimentel se puede suponer que en general las etnias de la zona eran de la familia lingüística caribe.
El primer encomendero conocido de los indios Guayo fue el capitán Gaspar Matute Villalobos, vecino de la Nueva Valencia del Rey. Al morir este y quedar vacante su encomienda se le otorga en 1642 a Domingo Vásques de Rojas y Alfaro, como hijo homónimo del maestre de campo Domingo Vásquez, mencionándose entonces a los indios Guayos como de nación Jiraharas, en cantidad de 'sesenta indios útiles' (no cuentan ni viejos ni infantes) y poblados en el pueblo de San Antonio de los Guayos ya para esa fecha.
El 20 de febrero de 1694 don Francisco Berroterán, gobernador de la Provincia de Venezuela, llama a Los Guayos "pueblo de indios". El territorio era parte de la tribu indígena de los Guayos.

El 6 de junio de 1710 "Los Guayos" se convierte en ayuda de parroquia o parroquia sufragánea de Guacara.

En 1751 los vecinos de Los Guayos se suman a otras poblaciones venezolanas en el levantamiento de Francisco de León contra la imposición de la Compañía Guipuzcoana.
En 1785 el gobernador Manuel Torres de Navarra declara a los Guayos como parroquia.
En mayo de 1812 Francisco de Miranda deja un ejército en el pueblo de Los Guayos para repeler a las fuerzas realistas mientras él continúa la guerra en otras partes de la región. Este grupo es desbaratado el 8 de mayo cuando uno de sus comandantes, un español, se pasa al bando de las fuerzas monárquicas.
En 1837 concluye la reconstrucción de la iglesia.

Templo colonial de San Antonio de Padua o iglesia de Los Guayos: La iglesia es una de las más antiguas de Venezuela. Su primera construcción data de 1650, cuando servía de iglesia para el pueblo de indios de la zona. El campanario actual, con dos cuerpos anexos, data de 1779.





</doc>
<doc id="4643" url="https://es.wikipedia.org/wiki?curid=4643" title="PH">
PH

El pH es una medida de acidez o alcalinidad de una disolución. El pH indica la concentración de iones hidrógeno presentes en determinadas disoluciones. La sigla significa potencial de hidrógeno o potencial de hidrogeniones. El significado exacto de la p en «pH» no está claro, pero, de acuerdo con la Fundación Carlsberg, significa «poder de hidrógeno». Otra explicación es que la p representa los términos latinos "pondus hydrogenii" («cantidad de hidrógeno») o "potentia hydrogenii" («capacidad de hidrógeno»). También se sugiere que Sørensen usó las letras p y q (letras comúnmente emparejadas en matemáticas) simplemente para etiquetar la solución de prueba (p) y la solución de referencia (q). Actualmente en química, la p significa «cologaritmo decimal de» y también se usa en el término p"K", que se usa para las constantes de disociación ácida.

Este término fue acuñado por el bioquímico danés S. P. L. Sørensen (1868-1939), quien lo definió en 1909 como el opuesto del logaritmo de base 10 o el logaritmo negativo de la actividad de los iones hidrógeno. Esto es:

Esta expresión es útil para disoluciones que no tienen comportamientos ideales, disoluciones no diluidas. En vez de utilizar la concentración de iones hidrógeno, se emplea la actividad formula_1, que representa la concentración efectiva.

El término pH se ha utilizado universalmente por lo práctico que resulta para evitar el manejo de cifras largas y complejas. En disoluciones diluidas, en lugar de utilizar la actividad del ion hidrógeno, se le puede aproximar empleando la concentración molar del ion hidrógeno.

Por ejemplo, una concentración de , lo que equivale a: 0.0000001 M y que finalmente es un pH de 7, ya que .

En disolución acuosa, la escala de pH varía, típicamente, de 0 a 14. Son ácidas las disoluciones con pH menores que 7 (el valor del exponente de la concentración es mayor, porque hay más iones hidrógeno en la disolución). Por otro lado, las disoluciones alcalinas tienen un pH superior a 7. La disolución se considera neutra cuando su pH es igual a 7, por ejemplo el agua.

El pH se define como el logaritmo negativo de base 10 de la actividad de los iones hidrógeno:

Se considera que "p" es un operador logarítmico sobre la concentración de una disolución p = –log[...]. También se define el pOH, como el logaritmo negativo de la concentración de iones hidróxido.

Puesto que el agua está adulterada en una pequeña extensión en iones [OH] y [HO], se tiene:

formula_4
Donde:

Por lo tanto,

Por lo que se pueden relacionar directamente los valores del pH y del pOH.

En disoluciones no acuosas o fuera de condiciones normales de presión y temperatura, un pH de 7 puede no ser el neutro. El pH al cual la disolución es neutra está relacionado con la constante de disociación del disolvente en el que se trabaje.

El valor del pH se puede medir de forma precisa mediante un potenciómetro, también conocido como pH-metro (/pe achímetro/ o /pe ache metro/), un instrumento que mide la diferencia de potencial entre dos electrodos: un electrodo de referencia (generalmente de plata/cloruro de plata) y un electrodo de vidrio que es sensible al ion de hidrógeno.

El pH de una disolución se puede medir también de manera aproximada empleando "indicadores"":" ácidos o bases débiles que presentan diferente color según el pH. Generalmente se emplea un papel indicador, que consiste en papel impregnado con una mezcla de indicadores cualitativos para la determinación del pH. El indicador más conocido es el papel de litmus o papel tornasol. Otros indicadores usuales son la fenolftaleína y el naranja de metilo.


La determinación del pH es uno de los procedimientos analíticos más importantes y más utilizados en química y bioquímica. El pH determina muchas características notables de la estructura y de la actividad de las moléculas, por lo tanto, del comportamiento de células y organismos.

El pH que es medido en el laboratorio, generalmente no es el mismo que el calculado mediante la ecuación: formula_12, porque el valor numérico de la concentración de iones hidrógeno, no es igual al valor de su actividad, excepto, para las disoluciones diluidas.

Diversas reacciones químicas que se generan en disolución acuosa necesitan que el pH del sistema se mantenga constante, para evitar que ocurran otras reacciones no deseadas. Las disoluciones reguladoras, amortiguadoras o búfer, son capaces de mantener la acidez o basicidad de un sistema dentro de un intervalo reducido de pH.

En 1917 Hasselbalch propuso la ecuación pertinente para calcular el pH de disoluciones amortiguadoras. La ecuación que postuló es la siguiente: 

formula_13

Adiconalmente se debe establecer la concentración total del par conjugado, formula_14 para fijar un valor de pH determinado.

Estas disoluciones contienen como especies predominantes, un par ácido/base conjugado en concentraciones apreciables. La capacidad reguladora que posea la disolución depende de la cantidad presente del ácido débil y su base débil conjugada, mientras mayor sea esta cantidad, mayor será la efectividad de dicha disolución. El que sean ácidos y bases débiles significa que actúan como electrólitos débiles, en pocas palabras, no se ionizan por completo en agua. La reacción de neutralización es una reacción entre un ácido y una base. Generalmente en las reacciones acuosas ácido-base se generan agua y una sal.

El organismo dispone de tres recursos para mantener el pH en valores compatibles con la vida:


Las variaciones de pH en nuestro organismo pueden modificar ciertos procesos fisiológicos, tal es el caso de la reacción enzimática. Cada enzima de nuestro cuerpo tiene un intervalo de pH, que comúnmente se le conoce como "pH óptimo", en el cual la enzima desarrolla su máxima actividad. Si esta se encuentra en condiciones fuera del pH óptimo, puede reducir su velocidad de activación, modificar su estructura, o lo que es peor, dejar de funcionar.

Algo más cotidiano para nosotros son las inyecciones. Los fluidos que se emplean para preparar específicamente las inyecciones intravenosas, incluyen un sistema amortiguador para que la sangre mantenga su pH. Con todo esto se refleja la importancia de las disoluciones amortiguadoras, ya que sin estas, todas las reacciones químicas de los organismos, no podrían realizarse de manera eficaz.

Para obtener un indicador orgánico se puede utilizar col morada siguiendo estos pasos:


Si los resultados son los siguientes se extrajo el indicador con éxito:

El pH se relaciona mucho con la calidad del agua en las piscinas. Esto es así porque el cloro solo hace efecto si el pH del agua de la piscina está entre 6.5 y 8. Si el pH del agua es superior a 8 o inferior a 6.5, por más cloro que se añada este no actuará. Por ello es importante vigilar que el pH esté siempre entre 6.5 y 8. Esta previsión es clave para asegurar que la piscina permanezca en buen estado. Un pH de agua demasiado elevado (superior a 8) produce agua turbia, incrustaciones e irritación de ojos, orejas, nariz y garganta.




</doc>
<doc id="4644" url="https://es.wikipedia.org/wiki?curid=4644" title="Elemento">
Elemento

El término elemento puede referirse, en esta enciclopedia:






</doc>
<doc id="4646" url="https://es.wikipedia.org/wiki?curid=4646" title="12 de enero">
12 de enero

Es el 12.º (duodécimo) día del año en el calendario gregoriano. Quedan 353 días para finalizar el año y 354 en los años bisiestos.








</doc>
<doc id="4647" url="https://es.wikipedia.org/wiki?curid=4647" title="13 de enero">
13 de enero

El 13 de enero es el 13.º (decimotercer) día del año en el calendario gregoriano. Quedan 352 días para finalizar el año y 353 en los años bisiestos.







</doc>
<doc id="4648" url="https://es.wikipedia.org/wiki?curid=4648" title="19 de enero">
19 de enero

El 19 de enero es el decimonoveno día del año del calendario gregoriano. Quedan 346 días para finalizar el año y 347 en los años bisiestos.







</doc>
<doc id="4649" url="https://es.wikipedia.org/wiki?curid=4649" title="20 de enero">
20 de enero

El 20 de enero es el vigésimo día del año en el calendario gregoriano. Quedan 345 días para finalizar el año y 346 en los años bisiestos.








</doc>
<doc id="4654" url="https://es.wikipedia.org/wiki?curid=4654" title="Oda (desambiguación)">
Oda (desambiguación)

Oda puede referirse a:

</doc>
<doc id="4658" url="https://es.wikipedia.org/wiki?curid=4658" title="Tragicomedia">
Tragicomedia

Una tragicomedia es una gran obra dramática en la que se mezclan los elementos trágicos y cómicos, aunque también hay lugar para el sarcasmo y parodia. También se le conoce como pieza, porque se parece a dicho concepto; generalmente en estos están sintetizadas las características de una clase social, por lo que también se le denomina "género psicológico".

Una "pieza" es una obra literaria del tipo realista, en donde la situación y los personajes están claramente presentados. Si bien en lo que se relata y expone hay cambios inesperados, ellos son lógicos y explicables, y el suspenso va en continuo aumento, llegando por momentos a clímax con intensas emociones. La resolución o conclusión de la obra es consecuencia de los actos y de las situaciones planteadas con bastante claridad y sin ambigüedades, donde los actos de los personajes son verosímiles.

En la Grecia clásica, el drama satírico o la tragicomedia suele tratar un tema legendario, aunque con efectos cómicos protagonizados, fundamentalmente, por el coro. Los dioses no intervienen en la muerte de los hombres y puede haber más de una acción al mismo tiempo.

La tragicomedia principalmente va a mostrar la trayectoria del héroe tragicómico, que tiene un objetivo que perseguir (el amor, la justicia, la ambición, un trono, etc) y de cómo éste lo consigue o no pasando por una serie de obstáculos para llegar a su fin. Si los obstáculos se presentan como positivos, es decir que parece que lo acercan cada vez más a su objetivo, más que obstáculos son como pruebas superadas. Por su parte el final será negativo, si los obstáculos son negativos, y parece que le impiden llegar a su objetivo, aunque por lo general el final será positivo y aunque sea a último minuto alcanzará su objetivo.

Su creador fue Lope de Vega cuando rompió las estructuras del teatro aristotélico. Lope se negaba a obedecer las unidades, y entonces creó la tragicomedia.

Aristóteles (384 a.C. - 322 a.C.), en el primer capítulo de "Poética" (1,6), hace una aproximación entre tragedia y comedia, mostrando que ambas se sirven de los mismos medios - mismos ritmos, mismos cantos y metros. Pero es probable que Plauto (254 a.C.-184 a.C.) haya sido el primero en emplear la palabra "tragicomedia", definiéndola como un género híbrido de comedia y tragedia, conforme explica a través del personaje Mercurio, en el prólogo de su pieza "Amphitryon o Amphitruo:"

Esas mezclas o alternancias de estilo ocurren en varias piezas griegas y romanas, como en "Alceste" de Eurípides (c. 485 a.C.-406 a.C.), que, en razón de su "final feliz", por el tono levemente humorístico de algunos pasajes, es vista por algunos eruditos como un drama satírico o una tragicomedia, mucho más que como una tragedia.

En Francia, el término fue introducido por el dramaturgo Robert Garnier (1545-1590).

En el inicio del siglo XVII, este tipo de teatro estaba de moda, más el estilo aún no estaba claramente definido. Poco a poco, los autores fueron sometiendo sus obras a las reglas del teatro clásico. Y entre los clásicos franceses del siglo XVII (Molière, Pierre Corneille, Jean Racine), el término en cuestión designaba una historia trágica con desenlace feliz.

El género no siempre agradó al público. ""El Cid"" de Corneille, por ejemplo, tuvo que ser reescrito para transformarlo en una tragedia, después que la primera versión recibió numerosas críticas desfavorables. No obstante, este caso fue algo peculiar, pues pudo haber estado contaminado por el cabale promovido por el cardenal Richelieu.

Un caso que también corresponde citar, es el de Victor Hugo, que con su drama romántico intentó imponer una escritura que se situaba entre lo "sublime" y lo "grotesco", pero que no tuvo mucho éxito. Solamente en el siglo XX, con el "Teatro del absurdo", el público comenzaría a aceptar que las risas no necesariamente excluyen la profundidad dramática.


</doc>
<doc id="4660" url="https://es.wikipedia.org/wiki?curid=4660" title="Reggae">
Reggae

El reggae es un género musical que se desarrolló por primera vez en Jamaica hacia mediados de los años 1960. Aunque en ocasiones el término se utiliza de modo amplio para referirse a diferentes estilos de música jamaiquina, por "reggae" se entiende en sentido estricto un género musical específico que se originó como desarrollo de otros anteriores como el "ska" y el "rocksteady".

El "reggae" se caracteriza rítmicamente por un tipo de acentuación del "off-beat", conocida como "skank". Normalmente, el tiempo del "reggae" es más lento que el del "ska" y el "rocksteady". El reggae suele acentuar el segundo y cuarto pulso de cada compás, y utiliza la guitarra para poner o bien énfasis en el tercer pulso o para mantener el acorde desde el segundo hasta el cuarto. Es generalmente este "tercer beat", tanto por la velocidad como por la utilización de complejas líneas de bajo, lo que diferencia al reggae del rocksteady.

The Wailers, una banda formada por Bob Marley, Peter Tosh y Bunny Wailer en 1963, son quizá el grupo más conocido que hizo la transición a través de las tres etapas la primera música popular jamaiquina: "ska", "rocksteady" y "reggae". Otros pioneros del "reggae" incluyen a Prince Buster, Desmond Dekker y Jackie Mittoo.

La edición de 1977 del "Diccionario de inglés jamaiquino" incluía "reggae" como "una expresión recientemente establecida para "rege"", equivalente a "rege-rege", una palabra que podía significar tanto "trapos, ropa andrajosa" como "una pelea o riña".
El término "reggae" con un sentido musical apareció tanto en Desmond Dekker como en el hit "rocksteady" de 1968 "Do the Reggay" de The Maytals, pero ya se utilizaba en Kingston, Jamaica, para denominar una forma más lenta de bailar y tocar "rocksteady".
El artista reggae Derrick Morgan expresa en este sentido:

No nos gustaba el nombre "rocksteady", así que probé diferentes versiones de "Fat Man". Cambió el ritmo, el órgano se utilizó para sorprender. A Byron lee, el productor, le gustaba. Él creó el sonido con el órgano y la guitarra rítmica. Sonaba como 'reggae, reggae' y ese nombre simplemente despegó. Byron Lee comenzó a utilizar la palabra (sic) y pronto todos los músicos estaban diciendo 'reggae, reggae, reggae'.

El historiador del "reggae" Steve Barrow atribuye a Clancy Eccles la alteración del término patois "streggae" (mujer fácil), convirtiéndolo en "reggae". Sin embargo, según Toots Hibbert:

Hay una palabra que solíamos utilizar en Jamaica llamada 'streggae'. Si una chica pasa y los chicos la miran y dicen 'tío, ella es "streggae"', eso significa que no viste bien, que se ve reggay (andrajosa). Las chicas dirían lo mismo de un hombre también. Esta mañana yo y unos amigos estábamos jugando y yo dije, 'vale tío, hagamos el reggay'. Fue solo algo que me vino a la cabeza. Así que empezamos a cantar 'do the reggay, do the reggay' (haz el reggay, haz el reggay) y creamos un beat. La gente me dijo después que le habíamos dado al sonido ese nombre. Antes de eso la gente lo llamaba blue-beat y todo tipo de nombres. Ahora está en el "Libro Guinness de los Records".

Se dice que Bob Marley atribuía como origen de la palabra "reggae" un término del idioma español para referirse a la "música del rey".

Aunque poderosamente influenciada por el mento y el calipso tradicionales, el jazz estadounidense y el primer "rhythm and blues", el "reggae" es deudor directo en su origen de los diferentes desarrollos que tuvieron lugar en el "ska" y el "rocksteady" durante los años 1960 en Jamaica. Uno de los individuos que más contribuyeron a este desarrollo fue Count Ossie.

El "reggae" le debe su éxito en Inglaterra al movimiento "skinhead" que lo adoptaron como su música propia y a esto también surge la "Gran guerra del reggae".

El "ska" surgió en los estudios de Jamaica alrededor de 1959. Se desarrolló a partir del mento. El "ska" se carateriza por un tipo de línea de bajo llamado "walking bass" o "bajo galopante", ritmos de guitarra o piano acentuados en el "offbeat", y en ocasiones "riffs" de viento similares a los del jazz. Además de ser muy popular dentro de la subcultura jamaiquina de los "rude boys", hacia 1964 también había ganado una larga audiencia en la cultura mod inglesa.

Los "rude boys" comenzaron a poner deliberadamente los discos de "ska" a la mitad de velocidad, ya que preferían bailar más despacio como parte de su imagen de tipos duros. Hacia mediados de los años 1960, muchos músicos habían comenzado a tocar "ska" con ese tempo lento, al tiempo que ponían énfasis en el walking bass y los offbeats. El sonido más lento fue denominado rocksteady como consecuencia de un single de Alton Ellis. Esta fase de la música jamaiquina duró hasta 1968, cuando los músicos comenzaron a aumentar la velocidad de la música de nuevo, añadiendo también otros efectos. Ello condujo a la creación del "reggae".

El "reggae" se desarrolló a partir del "rocksteady" en los años 1960. El cambio del "rocksteady" al "reggae" es ilustrada por el empleo del "shuffle" en el órgano, cuyo pionero fue Byron Lee. Este rasgo ya aparecía en algunos sencillos de transición como "Say What You're Saying" (1967) de Clancy Eccles o "People Funny Boy" (1968) de Lee "Scratch" Perry. El tema "Long Shot Bus' Me Bet" publicado por el grupo The Pioneers en 1967 es considerado como el ejemplo grabado más temprano del nuevo sonido que pronto sería conocido como reggae.

Es en los comienzos de 1968 cuando los primeros discos de reggae genuino fueron publicados: "Nanny Goat" de Larry Marshall y "No More Heartaches" de The Beltones. El hit "Hold Me Tight" del artista estadounidense Johnny Nash de 1968 ha sido reconocido como el primero en poner el "reggae" en las listas de éxitos de Estados Unidos. 

Otros pioneros del "reggae" incluyen a Prince Buster, Desmond Dekker y Jackie Mittoo y The Wailers, una banda formada por Bob Marley, Peter Tosh y Bunny Wailer. 

En el desarrollo que llevó el "ska" hacia el "rocksteady" y posteriormente al "reggae", fue fundamental la contribución de varios productores jamaiquinos. Entre los más importantes están Coxsone Dodd, Lee "Scratch" Perry, Leslie Kong, Duke Reid, Joe Gibbs y King Tubby. Chris Blackwell, que fundó el sello Island Records en Jamaica en 1960, se mudó a Inglaterra en 1962, donde continuó promocionando la música jamaiquina. Se alió a Trojan Records, fundado por Lee Gopthal en 1968. Trojan publicó discos de artistas reggae en UK hasta 1974, cuando Saga compró el sello.
En 1972, la película "The Harder They Come", en la que actuaba Jimmy Cliff, generó un considerable interés y popularidad para el "reggae" en Estados Unidos, y la versión de Eric Clapton en 1974 del tema de Bob Marley "I Shot the Sheriff" ayudó a llevar el "reggae" al "mainstream". Hacia mediados de los años 1970, el "reggae" recibía un considerable espacio en la radio inglesa, especialmente gracias al programa de John Peel. Lo que se conoció después como la "edad dorada del reggae" corresponde aproximadamente al apogeo del "roots reggae".

En la segunda mitad de los años 1970, la escena de "punk rock" de Gran Bretaña comenzaba a formarse, y el reggae fue una importante influencia para ello. Algunos DJs de "punk" ponían canciones de "reggae" durante sus sesiones y numerosas bandas de "punk" incorporaron estas influencias "reggae" en su música. En Inglaterra el "reggae" se expandió gracias a la nueva inclusión del género en la música de The Rolling Stones con mayor influencia desde 1974. Al mismo tiempo, el "reggae" comenzó una cierta recuperación en Inglaterra en los años 1980 abanderada por grupos como Steel Pulse, Aswad, UB40 y Musical Youth. Otros grupos que recibieron interés internacional a comienzos de los 1980 fueron Third World, Black Uhuru y Sugar Minott.

"Early reggae", también conocido como "skinhead reggae" debido a su popularidad dentro de esa subcultura inglesa de clase obrera, fue el primer reggae que existió después del Rocksteady, comenzó hacia finales de los años 60; A medida que la influencia de la música "funk" de sellos estadounidenses como Stax comenzó a penetrar en la forma de tocar de los músicos de "reggae". Lo que caracteriza al "early reggae" del "rocksteady" es el órgano Hammond "burbujeante", un estilo percusivo de tocar que atrajo mayor atención hacia la subdivisión en ocho octavas dentro del groove. Los "skanks" de la guitarra en la segunda y cuarta nota del compás eran frecuentemente "doblados" en estudio utilizando efectos electrónicos de eco, complementando de ese modo la sensación de doble-tiempo del órgano. En general se daba mayor énfasis al groove de la música. La creciente tendencia en la época de grabar una "versión" en la cara B del single produjo, además, innumerables instrumentales lideradas por vientos o el órgano.

Entre los principales grupos de "skinhead reggae" se incluyen John Holt, Toots & the Maytals, The Pioneers y Symarip. Eran frecuentes las versiones de temas de "soul" de sellos como Motown, Stax y Atlantic Records, reflejando la popularidad de la música soul entre los "skinheads" y los "mods".

"Roots reggae" es un tipo de música espiritual cuyas letras se dedican predominantemente a enaltecer a Jah (Dios). Entre los temas más recurrentes se encuentran la pobreza y la resistencia al gobierno y a la opresión racial. Muchas de las canciones de Bob Marley y de Peter Tosh pueden considerarse "roots reggae". La cima creativa del "roots reggae" se dio hacia finales de los años 1970 con cantantes como Burning Spear, Gregory Isaacs, Freddie McGregor, Johnny Clarke, Horace Andy, Ijahman Levi, Barrington Levy, Big Youth y Linval Thompson, y bandas como Culture, Israel Vibration, The Meditations y Misty in Roots, mano a mano con productores como Lee 'Scratch' Perry y Coxsone Dodd. Musicalmente, en la canción "Roots, Rock, Reggae" Marley concibió un nuevo estilo de música "off beat" con un compás de seis "beats", donde el "skank" de la guitarra tiene lugar en el cuarto y sexto beat. Aunque totalmente separado de los ritmos del "ska", "rocksteady", "reggae", "skank", "flyers", "rockers" y otros estilos, este ritmo único está tan asociado a Marley que muy pocos otros lo adoptaron.

El "dub" es un género de reggae desarrollado en sus primeros tiempos por productores de estudio como King Tubby o Lee Perry. Se caracteriza por basarse en la remezcla (remix) de material previamente grabado, y por dar un particular énfasis a la batería y la línea de bajo. Las técnicas utilizadas provocaban en el oyente sensaciones viscerales, descritas por Tubby como "un volcán en tu cabeza". Augustus Pablo y Mikey Dread fueron otros importantes proponentes de este estilo.

El estilo "rockers" fue creado hacia mediados de los años 70 por Sly & Robbie. El "rockers" es descrito como un estilo fluido, mecánico y agresivo de tocar reggae. Un artículo describe el rockers como la "edad dorada del reggae".

El subgénero del "lovers rock" subgenre se originó en el sur de Londres a mediados de los años 1970. Las letras tratan normalmente sobre amor. Es similar al "rhythm and blues". Algunos artistas significativos de "lovers rock" incluyen Gregory Isaacs, Freddy McGregor, Dennis Brown, Maxi Priest y Beres Hammond. Bob Marley en su disco "Kaya", hizo un prototipo de "lovers rock" con sus baladas románticas "reggae" entre ellas "Waitin in Vain".

El Rap es un estilo de cantar o hablar sobre un disco instrumental que fue utilizado por primera vez en Jamaica en 1960, donde se le conocía como Toasting, por deejays como U-Roy y Dennis Alcapone. Este estilo influyó poderosamente sobre el DJ jamaiquino Kool Herc, quien utilizó este estilo en Nueva York, pero usando las partes instrumentales de discos de funk, a mediados de los años 1970, sentando el precedente directo del hip hop y el rap. El sonido de bajo y bombo saturado en la música dub también influyeron sobre el sonido de buena parte del hip hop.

El dancehall, primero conocido como rub-a-dub, fue desarrollado alrededor de 1980, por artistas como Yellowman, Super Cat y Shabba Ranks. El estilo se caracterizó por cantar como los "deejay" y rapear o hacer toasting sobre rhythms crudos y rápidos. Ragga (también conocido como "raggamuffin") y reggae fusion son subgéneros del dancehall donde actualmente la instrumentación principalmente es llevada a cabo mediante música electrónica y sampling (el primer ritmo 100 % digital fue "Under My Sleng Teng", de la mano del productor Prince Jammys y el cantante Wayne Smith por el año 1984 y que en su primera aparición hizo ganar al sound de Jammy's en un clash contra Black Scorpio). Entre los pioneros del ragga están Shinehead y Buju Banton.

El reggae fusion es una mezcla de reggae o dancehall con elementos de otros géneros, como hip-hop, R&B, jazz, rock, drum and bass, punk o polka.

Los principales intérpretes y grupos de reggae en Latinoamérica son: 

El reguetón es un género musical bailable que tiene sus raíces en la música de América Latina y el Caribe. Su sonido se deriva del reggae jamaicano, influenciado por el hip hop. Se desarrolló por primera vez en Panamá en los años 1970 y principios de los años 1990 en Puerto Rico, nace y surge a raíz de la comunidad jamaicana cuyos ancestros llegaron a Panamá, junto a inmigrantes de ascendencia afro-antillana durante el siglo XX.




</doc>
<doc id="4663" url="https://es.wikipedia.org/wiki?curid=4663" title="Geografía de Venezuela">
Geografía de Venezuela

El territorio continental de Venezuela está ubicado al norte de América del Sur, su límite está muy cerca del Ecuador terrestre, por lo tanto forma parte de la zona intertropical. Sus límites geográficos son: Mar Caribe (norte), Colombia y Brasil (sur), Guyana (este) y Colombia (oeste), además su Mar Patrimonial le otorga fronteras con los mares territoriales de: Estados Unidos de América (Puerto Rico e Islas Vírgenes de los EE.UU.), el Reino de los Países Bajos (Aruba y Antillas Neerlandesas: Bonaire, Curazao, Saba, y San Eustaquio), la República Dominicana, Francia (Guadalupe y Martinica), Trinidad y Tobago, Colombia, San Cristóbal y Nieves, el Reino Unido , Dominica, Santa Lucía, San Vicente y las Granadinas, Granada y Guyana. El territorio comprendido entre el límite oficial con Guyana (Río Cuyuní) y el río Esequibo comprende una extensa zona que Venezuela reclama como propia, conocida como la Guayana Esequiba.

Tomando como referencia el centro geográfico del territorio continental venezolano, el área que se encuentra exactamente al otro lado del globo terráqueo (antípoda) es la Península de Malaca, en el Sudeste Asiático, específicamente la región sur de Tailandia.
El territorio de Venezuela está formado por el territorio continental (tierra firme), que comprende 1.075.945 km²; el territorio insular (islas), que abarca 1.270 km²; el espacio aéreo; y las áreas marinas y submarinas. Entre las áreas marinas y submarinas se encuentran el mar territorial (el cual suma 71.295 km² al territorio general), la zona contigua (22.224 km²), la zona económica exclusiva (348.176 km² de extensión marina que incluyen la zona contigua), la plataforma continental (que corresponde al fondo marino, hasta la extensión de la zona económica exclusiva) y las aguas interiores, históricas y vitales. Visto así, el territorio (continental y marítimo) de Venezuela abarca 987.740 km², ya que de las áreas marinas y submarinas sólo el mar territorial suma extensión al territorio, aun cuando en todas ellas el estado ejerce soberanía.
Reclama 159.542 km² del territorio de lado a Guyana. Venezuela.

El país comprende muchas regiones geológicamente muy variadas. Al oeste se extienden la Cordillera de los Andes venezolanos. Estos se prolongan hacia el norte y se transforman allí en la Cordillera de la Costa (Venezuela). Al sur de esta cadena montañosa se encuentran los Llanos, con gran cantidad de ríos. Al sur de los Llanos corre el río Orinoco. Al sur del Orinoco está la región de las Guayanas, un escudo de la era precámbrica, una parte del cual se ubica en la cuenca del Río Negro e indirectamente en la del Río Amazonas y otra parte en la cuenca del Orinoco. La Guayana venezolana es la región más extensa del país y está formada, además del antiguo escudo guayanés, por amplias y elevadas mesetas que toman el nombre de Tepuyes, que le dan los pemones, indígenas que habitan en la Gran Sabana.

Por encontrarse en la zona intertropical, Venezuela posee un clima cálido y lluvioso en general, pero debido a la orografía, los vientos, la influencia del mar y la orientación de las cadenas montañosas, hay diferencias climáticas. La latitud ejerce cierta importancia en la estacionalidad y cantidad de las lluvias, pero su papel es mucho menor en cuanto al efecto que tiene en las temperaturas. La altitud, sin embargo, constituye un factor que cambia drásticamente el clima, sobre todo en lo que se refiere a la temperatura, alcanzando valores muy diferentes según la disposición del relieve en lo que se conoce como pisos térmicos, bióticos o ecológicos.

Durante el Pleistoceno tardío la extensión de los glaciares en la Cordillera de Mérida y Sierra de Perija era de más de 700 km2 y el nivel del mar era 125 m. más bajo.

La medida anual de temperatura se reduce sólo con la altitud, como por ejemplo en Los Teques (situada a 1.300 metros) con sus 19,8;°C de promedio anual contrasta con los pueblos y ciudades en el nivel del mar que superan los 27 °C de medida anual, aunque la amplitud térmica es muy escasa en todo el país (nunca supera los 4 °C de diferencia). No existen las estaciones bien marcadas, como sucede con las zonas templadas de ambos hemisferios. Por el contrario, por influencia de la lengua castellana introducida por los españoles durante el período colonial, se le denomina invierno a la época de lluvias, aunque ésta coincide, aproximadamente, con el verano (térmico) en el Hemisferio Norte. Y, por el contrario, se le denomina verano a la época de sequía que corresponde, también aproximadamente, al invierno en el Hemisferio norte (noviembre a abril).
Los climas venezolanos están estructurados en "pisos térmicos", como se menciona a continuación:


La influencia del mar incide en cambios climáticos aunque en menor grado que la altitud, así en las zonas de costas las temperaturas máximas son altas, pero no tanta como Los Llanos, localizadas en el interior, además de esta región junto la Guayana los efectos de la continentalidad incide en amplitudes térmicas diarias más altas (de más de 0 °C), con respecto a la costa (no superior a 4 °C de amplitud media por lo general). Aunque en cualquier caso, en todo el territorio nacional las amplitudes térmicas anuales son insignificantes Con respecto a las precipitaciones hay variaciones en las distintas regiones venezolanas, en Los Llanos es tropical con una granpat estación seca (Clima intertropical de sabana), así en la zona costera del Mar Caribe es árido con escasas precipitaciones, exceptuando la vertiente del Atlántico donde llueve abundantemente. En las zonas montañosas de la Cordillera de la Costa (Venezuela), las lluvias varían según las disposición de las montañas, pero son suficientes y más regulares.El clima puede definirse como la resultante de las condiciones de la atmósfera y de sus efectos sobre la vida en la superficie terrestre, durante un período suficientemente largo. El conocimiento del clima en Venezuela es indispensable para comprender las características de los otros componentes del ambiente como los suelos, la vegetación y los recursos hidráulicos, así como para la evaluación de las potencialidades y limitaciones que ofrecen las diferentes regiones geográficas en el desarrollo del país.

Venezuela se encuentra ubicada en la zona intertropical del Hemisferio Norte, entre 0º 38’ 53” y 12º 11’ 22” de latitud norte, y 59º 48’ 10” y 73º 25’ 00” de longitud oeste. Como consecuencia de esta localización geográfica, las condiciones climatológicas dependen de los patrones de circulación atmosférica y de los sistemas atmosféricos planetarios y regionales que afectan el norte de Sur América y el sur del Mar Caribe.

El territorio venezolano está bajo la influencia directa de los vientos alisios del noreste, los cuales se originan en una zona del Atlántico norte donde la presión atmosférica es alta.

La franja o área donde convergen en la superficie los vientos alisios del noreste del Hemisferio Norte y los del sureste del Hemisferio Sur, recibe el nombre de Zona de Convergencia Intertropical (ZCIT). Ocasionalmente, esta convergencia es muy activa, dando lugar a la formación de grandes nubes de desarrollo vertical, que permiten claramente su identificación en las imágenes satelitales. Esta convergencia se centra, en promedio, alrededor de los 5º N, desplazándose hacia el norte y hacia el sur, en los períodos de los solsticios de verano correspondientes.

Las condiciones generales del clima pueden verse modificadas regionalmente por factores diversos, tales como la altitud del relieve, su exposición a los vientos, la continentalidad, e incluso por la presencia recurrente del llamado fenómeno El Niño-La Niña.

De estos sistemas atmosféricos, los más importantes debido a la amplitud geográfica y a su significado climático, son la Zona de Convergencia Intertropical, el Sistema de Alta Presión del Atlántico norte, las vaguadas, ondas del este y los relictos de frentes fríos del norte. Las ondas del este son perturbaciones que se propagan en la región del Atlántico-Caribe desde el este hacia el oeste, produciendo fuertes precipitaciones.

Por su situación latitudinal, el territorio nacional es esencialmente isotérmico, cuya oscilación térmica estacional es en general menor a 5 °C; en cambio, la amplitud térmica diaria (ATD) es más importante, alcanzando valores superiores a 8 °C y posiblemente aún más altos en situaciones de altitudes significativas, como en los casos de las zonas elevadas de Guayana y los Andes. Es bueno recalcar que los factores de altitud y distancia al mar (continentalidad) ejercen también influencia, pero de manera moderada.

La altitud del relieve es el factor que introduce la mayor variación de la temperatura en Venezuela. A la disminución de la temperatura con respecto a una determinada elevación se le conoce como Gradiente Térmico Vertical y su valor varía entre 0.63 °C/m cerca del ecuador y 0,62 ºC/m a 12° de Latitud Norte. De manera que en las regiones montañosas, la variación de la temperatura con la altitud es más marcada, generando una secuencia de pisos térmicos que en combinación con las otras variables atmosféricas da como resultado un patrón de pisos climáticos.

Cabe destacar que la variación estacional de los períodos secos y lluviosos es la característica más sobresaliente del clima de las regiones ubicadas al norte del Paralelo 6° N. La estación seca puede iniciarse en noviembre y se extiende hasta mediados de mayo cuando comienza la estación lluviosa, lo cual ocurre en casi todo el país, particularmente en los Llanos Orientales y Centrales, donde la precipitación promedio anual varía entre 800 a 1100 mm al año, así como en los Llanos Occidentales y Meridionales más húmedos con promedios anuales entre 1500 y 2400 mm. En las regiones semi-áridas las lluvias son escasas, de alta intensidad y de carácter errático. Por lo general, las regiones de clima árido no presentan un período de humedad marcado, excepto en años excepcionalmente muy lluviosos.

En el territorio venezolano se pueden diferenciar los siguientes tipos climáticos relevantes:

I. Climas Cálidos de Tierras Bajas

Corresponde a las regiones ubicadas por debajo de 1000 m de altitud, con temperaturas medias anuales entre 22 y 26 °C para los tipos cálidos y superior a 26 °C para los tipos muy cálidos. Desde el punto de vista de la lluviosidad se distinguen seis tipos de climas cálidos de tierras bajas con diferentes subtipos; a saber:

Climas del Sur: Comprenden los tipos cálidos superhúmedo y muy húmedo de carácter ecuatorial.

Climas de los Llanos: Húmedo en las tierras bajas y muy húmedo en el piedemonte oeste de Barinas. En la generalidad de los casos, los climas de los llanos se caracterizan por tener una marcada estacionalidad de las lluvias. Así, en el período lluvioso se concentra más del 85% del total anual de precipitación, mientras que en los meses secos llueve muy poco, especialmente en enero, febrero, marzo y abril.

Climas de la Depresión del Lago de Maracaibo: En la Depresión del Lago de Maracaibo se pueden distinguir los siguientes tipos climáticos: Superhúmedo: en los Piedemontes de las cuencas de los ríos Tarra, Socuavo y Catatumbo. Muy Húmedo: en el sector oeste, sur y sureste del Lago. Húmedo: al suroeste, sur y este del Piedemonte Andino. Subhúmedo: en las costas Occidental y Oriental del Lago. Semiárido: en la Altiplanicie de Maracaibo, Laguna de Sinamaica y Paraguachón.

Climas del Sistema de Relieve Lara-Falcón-Yaracuy: En esta región conformada por una sucesión de serranías bajas, colinas y valles longitudinales, existe una variedad de climas que van desde muy húmedo hasta el árido.

Climas del Litoral Central: El Litoral Central está ubicado entre los meridianos 66°30’ y 68° W y se encuentra bajo los efectos del fenómeno de surgencia, resultante de la exposición de la línea de costa en sentido oeste-este y de la inversión de los vientos alisios. Tales situaciones originan en este sector un clima semiárido.

Climas de la Región Nororiental: En esta región se pueden encontrar climas muy húmedos. En el estado Nueva Esparta predomina el clima semiárido, exceptuan¬do el sector nororiental de la isla de Margarita que incluye el Cerro Copey, un poco más húmedo y más fresco por efecto de la altura.

II. Climas de Tierras Altas

Tierras Altas de Guayana: Están conformadas por una topografía escalonada y extensa en la que se intercalan los tepuyes, sierras y serranías, con altitudes superiores a los 1000 m, enclavadas en la extensa región de clima cálido super¬húmedo de Guayana. Se presenta, básicamente dos tipos de clima: el mesotérmico superhúmedo y el mesotérmico muy húmedo.

Cordillera de la Costa Central y Oriental: En esta Cordillera, tanto en su parte central como oriental, los tipos climáticos que se destacan son el mesotérmico húmedo que cubre las franjas altitudinales entre 1000 y 2000 m, el mesotérmico subhúmedo ubicado en el mismo piso altitudinal y el templado subhúmedo locali¬zado por encima de los 2000 m. Este último presenta una temperatura media anual entre 15 °C en su parte inferior y 10 °C en sus partes más altas. El factor altitud se une con los factores marítimos y de continentalidad para producir alta diversidad climática.

Cordillera de Mérida: En la Cordillera de los Andes, es donde existe la mayor variabilidad climática de las tierras altas situa¬das por encima de los 1000 m de altitud. En efecto, la vigorosidad de su relieve expresada en diferentes franjas altitudinales que culminan casi a 5000 m, la masividad, su orientación e incluso su exposición a los vientos y a los rayos solares, así lo determinan. Los tipos y subtipos de climas que pueden encontrarse en esta Cordillera, van desde el Mesotérmico muy húmedo, hasta el Piso Gélido. La variabilidad climática andina determina, a su vez, una marcada biodiversidad, muy impor¬tante para la localización de los tipos de vegetación natural y el uso agrícola de la tierra. Es lo que se conoce como pisos bioclimáticos, cuyo escalonamiento en la Cordillera de Mérida es el más conspicuo de todo el territorio nacional.

Cordillera de Perijá: La Cordillera de Perijá presenta una gran diversidad climática, en estrecha relación con la altitud y la orientación de la exposición de las vertientes, lo cual origina impor¬tante variabilidad en la cantidad de lluvia media anual. Es así como en la cuenca del río Guasare, ubicada en el sector más hacia el norte de la cordillera, la precipitación varía entre 1600 mm/año en la zona montañosa baja hasta un poco más de 3000 mm/año en las estriba¬ciones de la zona fronteriza con Colombia. Mientras que en extremo sur de la Cordillera, la cantidad de lluvia es aún mucho mayor, alcan¬zando promedios anuales entre 2200 mm/año en la zona montañosa baja hasta 4000 mm/año en los valles de los ríos de Oro e Intermedio. Asimismo, en las cumbres sobre los 3000 m de altura donde están las nacientes del río Apón y sus tributarios, se encuentra un zona de Páramo muy húmedo, bordeando la zona limítrofe con Colombia.

Fuente: Atlas de Venezuela - Instituto Geográfico de Venezuela Simón Bolívar.

Venezuela está conformada por tres vertientes hidrográficas: la del Mar Caribe, la del Océano Atlántico y la del Lago de Valencia, que forma una cuenca endorreica. La principal es la del Caribe por el número de ríos que la constituyen, aunque suelen ser de corto curso y de caudal escaso e irregular, con alguna excepción como es el caso del Río Catatumbo, que nace en Colombia y desagua en la cuenca del Lago de Maracaibo. Al Océano Atlántico drena la extensa cuenca del río Orinoco, cuya superficie es superior a la de toda Venezuela. La cuenca del Orinoco es la tercera de América del Sur por su superficie y da origen a un caudal de unos 33000 metros por segundo, lo que convierten al Orinoco en uno de los ríos más caudalosos del mundo y también en uno de los más valiosos desde el punto de vista de los recursos naturales renovables. Un río que constituye un caso único en el mundo es el Casiquiare, que constituye una derivación natural del Orinoco y que, después de unos 500 km de longitud, desagua en el río Negro el cual es afluente, a su vez, del Amazonas.

Los principales afluentes venezolanos del Orinoco son el Arauca y el Río Apure por la margen izquierda y el Ventuari, el Caura y el Río Caroní por la margen derecha, entre otros.

Venezuela posee un relieve variado que va desde las cumbres de la Cordillera Andina en el oeste hasta las planicies deltaicas en el este pasando por los llanos en el centro-sur, la Cordillera de laeve Costa en el norte (considerada por muchos como continuación de la Cordillera Andina) y la amplia zona de mesetas del Macizo Guayanés al sur del Orinoco (la región más extensa, con el 50 % de la superficie total del país).

El país Venezuela es considerado como uno de los Países Mega diversos por poseer una gran cantidad y diversidad de especies, sobre todo en lo que se refiere a las especies vegetales y a las aves. Y la diversidad climática y, al mismo tiempo, la estabilidad de los elementos del clima, han hecho que muchas especies vegetales y animales de otras partes del mundo se hayan introducido y hayan encontrado un hábitat sumamente apropiado para su desarrollo: casi todos los cultivos y especies domesticadas por el hombre pueden cultivarse en Venezuela en condiciones muy favorables, un hecho ya señalado hace casi dos siglos por Andrés Bello en su "Silva a la agricultura de la Zona Tórrida".

Entre ellos destacan los minerales como petróleo, gas natural, hierro, bauxita, carbón, oro y diamantes y otros; los recursos pesqueros son abundantes en la fachada marítima caribeña y atlántica así como en los ríos de los Llanos; los recursos forestales y las vastas extensiones agrícolas y pecuarias están muy subutilizados y se hallan en Los Llanos y en las zonas andinas, así como en el norte del país. Además, el enorme potencial hidroeléctrico presente en la región Sur del país (Guayana) viene a complementar y hasta sustituir en su mayor parte, el potencial termoeléctrico de las plantas que consumen gas natural y gasóleo. 

Caracas es la ciudad capital de la república, una metrópoli en donde se asientan los poderes públicos nacionales. Le siguen en importancia Maracaibo, Valencia, Barquisimeto ,Maracay y muchas otras.

Venezuela tiene siete regiones naturales continentales y una región natural marítima.



La población venezolana es bastante heterogénea. La mayoría de los habitantes tiene antepasados europeos, indígenas americanos y africanos, principalmente. Gran cantidad de inmigrantes han llegado a Venezuela en el siglo XX. Desde el punto de vista demográfico, Venezuela es un país relativamente joven, con una pirámide de población bastante ancha en la base, aunque tiene la tendencia a hacerse más angosta como resultado de un progresivo descenso de la tasa de natalidad. A comienzos de los años 90 (siglo XX), la proporción de la población femenina comenzó progresivamente a sobrepasar a la masculina, lo que representa una tendencia consistente con la etapa de transición demográfica. La mayor parte de la población vive en el norte del país (más del 70 % de la población), con una amplia zona casi despoblada al sur del Orinoco (la mitad de la superficie del país sólo concentra el 5 % de sus habitantes) y la región de Los Llanos, con algo más del 20 % de la población total. Alrededor del 80 % de la población es urbana, la mayor parte de la cual se concentra en las grandes ciudades.




</doc>
<doc id="4664" url="https://es.wikipedia.org/wiki?curid=4664" title="Historia de Venezuela">
Historia de Venezuela

La historia de Venezuela se remonta al poblamiento del territorio por las migraciones amerindias hace años. La historia escrita de Venezuela comienza con la llegada de los primeros españoles a finales del siglo 15 Venezuela se conforma como estado en 1777 a partir de la Capitanía General de Venezuela, colonia del Imperio español que había sido fundada en 1527.

Se cree que el ser humano apareció en el territorio que hoy se conoce como Venezuela hace unos 30.000 años aproximadamente, proveniente de la Amazonia, los Andes y el Caribe. La época precolombina en Venezuela a partir de ese instante puede dividirse en cuatro períodos: Paleoindio (30.000 a. C-5000 a. C.), mesoindio (5000 a. C.-1000 a. C.), neoindio (1000 a. C.-1500 d. C.) e indohispano (1500 hasta el presente). Los períodos paleoindio y mesoindio se caracterizaron por la elaboración de instrumentos para cazar grandes animales como el megaterio, el mastodonte y el gliptodonte; así como el posterior desarrollo de artes de pesca y la navegación hacia a las islas del Caribe.
Grupos de personas que llegan durante el Pleistoceno Tardío, posiblemente desde el Norte, comienzan a ocupar la costa septentrional del territorio. Taima-Taima, Muaco y El Jobo son algunos de los lugares que presentan restos de esta población. La presencia de estos grupos se remonta al menos al año 13000 A.C. Los humanos que vivían en lo que es Falcón compartían su hábitat con una mega fauna como los megaterios, los gliptodontes y los toxodontes. La fauna de los años prehistóricos y precolombinos estaba formada en parte por dantas, tigres dientes de sable, armadillos gigantes, entre otros.

Los arqueólogos identifican un período Mesoindio entre el 7000-5000 A.C. y el 1000 A.C.. En este período los grupos de cazadores de mega animales pasan a formar estructuras tribales más organizadas.

El desarrollo que se produce aproximadamente a partir del 1000 A.C, pero muy diferente según las regiones, se conoce como el período Indígena. Se produce un desarrollo de la agricultura entre diversos grupos.

La población indígena al momento del primer contacto con los europeos aproximadamente medio millón de personas habitando lo que hoy es territorio venezolano, habría llegado, por el norte, desde la región del Calabozo; por el oeste, de los Andes, y por el norte, del Caribe. Los principales pueblos indígenas eran los chibchas en los Andes, los caribes, situados en casi todas las costas, y los arawakos, asentados en parte de las costas y más al sur, y los wayúu, o guajiros. Sin embargo, el territorio de la actual Venezuela era muy diverso lingüística y culturalmente durante el período precolombino, existe base para afirmar que los diferentes grupos indígenas pertenecían al menos a 16 grupos lingüísticos diferentes entre estas familias lingüísitas estarían presentes:

Y además existe un número de pueblos indígenas que hablaban lenguas aisladas o no clasificadas, cuya filiación no se conoce con precisión (maku, pumé, sapé, uruak, warao, guamo y otomaco).

Dentro de estos grupos existía también una notable diversidad, así las familias caribe y arahuaca ocupan un territorio muy extenso e incluían a pueblos que hablaban lenguas diferentes aunque emparentadas entre sí (dentro de cada familia). Las regiones de oriente, Guayana y centro del país así como también partes de Zulia y los llanos fueron habitados por tribus caribes que migraron de la cuenca del Amazonas en Brasil, aunque después a causa de guerras territoriales ocuparon la costa norte de Suramérica. Los arawakos provenientes de la Amazonía occidental poblaron regiones del que es hoy el estado Amazonas, en las planicies y buena parte del occidente y centro occidente del país, los waraos se encontraban en los caños de la desembocadura del río Orinoco, los Timoto-cuicas en las montañas de los Andes y también los yanomamis en las selvas del Amazonas. </ref>

Grupos chibchas provenientes de la zona hoy conocida como Colombia comienzan a entrar en territorio de los Andes venezolannos. Aparecen grupos Caquetíos de Paraguaná. También se producen pequeñas migraciones de grupos independientes que pueblan la cuenca del Orinoco y otras reducidas zonas del país. Al llegar los españoles existían en Venezuela numerosas etnias que hablaban idiomas caribes, arawakos, chibchas, tupí-guaraníes y de otras familias lingüísticas.
Los aborígenes usaban tecnologías rudimentarias para construir viviendas, terrazas, diques, canales de riego, etc. Habitaban comunidades nómadas, agricultores sedentarios, como los sembradores de maíz, cultivo que necesitaba de complejos sistemas de riego y embalses para controlar ríos, había cazadores de dantas y manatíes, recolectores de conchas marinas y pescadores, los cuales utilizaban embarcaciones fabricadas con base en un tronco de un árbol caído para transportarse, no derribaban una palma si no había necesidad de ello.
Unos adecuaban el terreno montañoso para la agricultura construyendo terrazas, otros construían muros de piedra en los valles para ordenar los sembradíos. En los Llanos, pueblos originarios construyeron una extensa red de calzadas, las cuales comunicaban a las aldeas, crearon los "campos elevados" que incrementaban la producción agrícola en las zonas anegadizas, con lo cual lograban dominar las inundaciones en las épocas de lluvias.

No solían traer materiales de regiones lejanas para construir sus viviendas o sus instrumentos. Casas de piedra unifamiliares en las regiones más frías, churuatas colectivas de madera y palmas agrupaban al grupo familiar extendido, palafitos de wayúus y waraos eran viviendas comunes apoyadas sobre pilotes en las lagunas y manglares. 

El trueque solía constituir en el intercambio de tubérculos de la montaña por frutas de tierras bajas, maíz por huevos de tortuga, pescado salado por yuca, y así sucesivamente. Los kariña lograron desarrollar amplias áreas de trueque, cultivaban algodón, yuca, árboles frutales y tabaco, los cuales cambiaban por canoas y hamacas. También producían cestería, cerámica, adornos corporales de plata, perlas, oro y carey de conchas de tortuga que encontraban en zonas distantes de su hábitat. La vestimenta variaba según la región, ya que se fabricaba con las fibras naturales que encontraban en su entorno, así, atavíos de lana para el frío de los Andes y guayucos para el calor. 

Se sancionaba fuertemente la acumulación de distintas riquezas en varias comunidades, ya que la propiedad era colectiva, la producción era social y no individual, en la mayoría de esas comunidades la comida solía prepararse para toda la población. Sin embargo, pretensiones territoriales de algunas poblaciones agresivas desembocaban en grandes guerras, ejércitos de hasta 40 mil hombres combatieron en la guerra entre catuches y teques.

En otras regiones, los warao, huyendo de los caribe dejaron su territorio ancestral, y encontraron un nuevo hogar dentro de los caños del delta del río Orinoco. La organización social variaba según la región, había algunos pueblos que se constituían en comunidades tribales, jerarquizadas, con caciques y autoridades de paz, y otras con una organización comunitaria donde sólo el chamán, curandero y guía espiritual tenía un rango superior, usaban las plantas con fines medicinales.

Lo que sería con el tiempo Venezuela fue avistada y recorrida inicialmente en agosto de 1498 por Cristóbal Colón quien se acerca a las bocas del río Orinoco yendo desde las islas Canarias, y recorre la costa desde la isla Trinidad hasta quizás el actual cabo de la Vela, en la península de la Guajira, al este de Colombia. Siendo ésta la primera vez que los europeos avistaban el continente, el almirante, al observar la variedad de flora y fauna, llamó a la zona "Tierra de Gracia", en clara alusión al Edén bíblico

Viajes subsiguientes como el de Alonso de Ojeda, Diego de Lepe, Cristóbal Guerra y Alonso Niño. Entre 1499 y 1502 delimitan rápidamente dos porciones de territorio para hacer de ellos gobernaciones, y ejercer jurisdicción: la una desde las bocas del Orinoco hasta el "morro de Maracapana", actualmente en la ciudad de Lechería, en la costa oriental de Venezuela, área que llega a ser conocida como la Gobernación de Cumaná, y de allí en adelante costeando hasta el cabo de la Vela sería luego hacia 1528 la Gobernación de Venezuela o Gobernación de Coquivacoa.

Hacia 1523 una ciudad castellana en el oriente de Venezuela, con el nombre de Nueva Cádiz florece en la isla de Cubagua a base de la enorme extracción de perlas de sus aguas y luego con el comercio esclavista de indios de toda la costa firme cercana.

Esta efímera ciudad es, sin embargo, la más sólida de cuantas se construyen en ese siglo en Venezuela, pues está toda ella hecha de calicanto, tejas y piedra, por la riqueza que genera la explotación perlífera. Dura poco como establecimiento poblado castellano, hasta 1542, en que se la abandona en favor de la cercana Isla de Margarita, por la extinción final de los ostrales de sus aguas, y calamidades naturales como un posible temblor y un seguido huracán en esos años. No obstante su influencia como ente irradiador de presencia castellana en el territorio y de base para expediciones al interior del mismo fue notable.

Carlos I le otorga la administración de Venezuela a la sociedad de los Welser de Augsburgo a cambio de fondos financieros. El rey prescribe que los Welser debían fundar una cierta cantidad de ciudades y promover la inmigración, pero estos se dedican ante todo a la búsqueda de El Dorado y la esclavización de los indios.

Ambrosio Alfinger (Ambrosius Ehinger) es el primer gobernador de la provincia. Llega a Coro en 1529 y desde allí marcha hacia el Occidente. En la entrada de un lago ataca a las tribus de la zona y funda la ciudad de Maracaibo.

Desde 1529 hasta 1538 los Welser registran la exportación de unos 1005 indígenas, aunque el rey ya había prohibido la esclavitud de indios en 1528. Las expediciones realizadas por los Welser y sus subalternos significan la destrucción de las sociedades indígenas en grandes zonas en especial alrededor del Valle de Barquisimeto y El Tocuyo.

En 1530 Alfinger le cede por unos meses la administración a Nicolas Federmann y parte a la Hispaniola con el fin de recuperarse de la malaria. Regresa el mismo año y comienza exploraciones entre lo que sería territorio venezolano y colombiano. Muere en 1533 en un ataque de indios.

Georg von Speyer toma la gobernación de la provincia en 1535 y hasta 1538 emprende expediciones por el Occidente de Venezuela y la Cordillera Andina de Colombia en búsqueda del Dorado. Descubre diversos ríos que desembocan en la orilla occidental del Alto Orinoco.

El asesinato de Phlipp von Hutten por el conquistador Juan de Carvajal en 1546 lleva al colapso de la administración de los Welser en Venezuela.

La abdicación de Carlos V en 1556 trae consigo la pérdida definitiva de los derechos de comercio para los alemanes.

En 1561 Venezuela ve la llegada de Lope de Aguirre y sus marañones provenientes del Perú. Este toma primero la isla de Margarita en 1561. De allí parte hacia Borburata, donde desembarca y continúa su camino a través de Valencia hacia Barquisimeto. En ese tiempo causa terror entre las poblaciones a las que llega con sus seguidores. El 27 de octubre de 1561 llega a Barquisimeto, donde es asesinado por sus propios expedicionarios.

El siglo XVI ve el nacimiento posteriormente, de forma más o menos espasmódica y con muchas vicisitudes de ciudades castellanas definitivas y estables, tales como Coro (1527), Maracaibo (1578), Barquisimeto (1552), Mérida (1558), Trujillo (1558), El Tocuyo (1545), Valencia (1553), Barinas (1597), Caracas (1568), Cumaná (1569), Carora, La Asunción y San Tomé, en la Guayana.

Los piratas y contrabandistas, ante todo grupos británicos y franceses, pero también holandeses, azotan las zonas costeras de Venezuela por más de dos siglos. Entre los ataques más importantes figuran los de John Hawkins y Francis Drake. John Hawkins desembarca en dos ocasiones en el pueblo costero de Borburata y vende allí esclavos que había apresado en Guinea.

A fines del siglo XVI ya el orden colonial está bien establecido y funcionan en debida forma las instituciones coloniales castellanas, como el Cabildo, la Iglesia, la Real Hacienda y el régimen de encomienda indígena. En 1576 el gobernador se establece en Caracas, por su buen clima y estar defendida de piratas por la serranía costera que la separa del litoral, ciudad donde residirá, haciendo a ella en adelante la capital del país. En 1584 se mudan a Caracas contadores de la Real Hacienda y para esa época ya reside allí el obispo.

El comercio del trigo florece, así como la ganadería, la minería de extracción aurífera y la curtimbre de los cueros para la exportación. Se importan esclavos para las plantaciones y el servicio doméstico.

Durante la conquista y colonización del territorio venezolano se organizan varias gobernaciones o provincias, sin continuidad en el tiempo, como las de Nueva Andalucía o Cumaná, Coro, Venezuela (o Caracas), Trinidad, Gobernación de La Grita, Nueva Extremadura o Mérida, Guayana y la efímera de Barcelona, en 1636. Cabe señalar que las mismas funcionaban independientemente.

Las provincias de Caracas, Cumaná, Guayana y Maracaibo dependen inicialmente de la Real Audiencia de Santo Domingo y luego de la Real Audiencia de Santafé de Bogotá o del Virreinato de la Nueva Granada, en diversas ocasiones, alternándose en esta función, sobre todo en el ámbito judicial, con la Real Audiencia de Santo Domingo, dependiente del Virreinato de la Nueva España.

El siglo XVII ve el surgimiento del cacao (1615) como un gran producto de exportación, así como la caña de azúcar, el tabaco, la sal y los cueros. El trigo decae hacia el consumo interno, por aumento poblacional.

Se ordena la fundación hacia 1618 de pueblos de doctrina para recoger a los indios y nacen así pueblos como Turmero, Guarenas, Choroní, Petare, Baruta, La Victoria, Cagua, "San Mateo", "Santa Lucía", El Valle, "Antímano", etc., impulsados por orden real y localmente por acción del obispo y el gobernador, acatando dicha orden.

Las ciudades costeras se fortifican ante el auge pirata. Se construyen fortalezas como la de Araya en el oriente (1622-1646), Pampatar y Santa Rosa en Margarita, San Antonio en Cumaná o San Carlos de la Barra, en la entrada del Lago de Maracaibo, del Estado Zulia. Maracaibo es asaltada por piratas en 1642, y luego repetidamente en otras ocasiones, así como Gibraltar, en el propio lago, Trujillo, Cumaná y Margarita.

La Catedral del Obispado se muda en 1637 de Coro, en donde residía desde 1530, a Caracas y las misiones como institución de varias órdenes como la de los franciscanos y jesuitas comienzan a ejercer su labor pobladora, ordenadora y evangelizadora en todo el territorio, a partir de la segunda mitad del siglo XVII.

El así llamado "terremoto de San Bernabé" ocurrido en junio de 1641 destruye la mayor parte de las edificaciones de Caracas y poblaciones cercanas.
Enfermedades contagiosas tales como el cólera, el sarampión, la Peste Negra y la gripe, atacan en varias ocasiones las poblaciones castellanas, produciendo estragos entre los indios, esclavos y españoles. Una de las más graves ocurrida en 1657, que produce muchos fallecidos en Guarenas y otras ciudades.

Hacia 1780 se extingue por etapas la institución de la Encomienda de Indios.

En 1728 el escritor neogranadino José de Oviedo y Baños escribe "Historia de la Conquista y Población de la Provincia de Venezuela", que hasta hoy es un clásico de las letras y la historia nacional. José de Oviedo y Baños nació en Santa Fé de Bogotá en 1671 y murió en Caracas en 1738.

El siglo XVIII ve la llegada de la "Real Compañía Guipuzcoana", o Compañía de Caracas, que se establece en 1728 y deviene en un ente monopolizador del comercio del cacao y de la venta de productos importados directamente de España, tales como vinos, trigo, telas y hierro, eliminando tanto para los productores como para los consumidores locales la posibilidad de acceder a otro mercado, lo cual genera enormes fricciones sociales y animadversión de productores y comerciantes criollos en contra de dicha compañía, sus medidas y sobre todo, sus prácticas con respecto a la fijación de precios de las mercancías.

Sin embargo, el establecimiento de la Compañía trae también beneficios, impulsando -por su propio interés- el desarrollo o mejora de la infraestructura de puertos locales, tales como Puerto Cabello, Maracaibo, Coro y La Guaira, así como el resguardo de toda la costa desde el río Esequibo hasta la Goajira, al occidente, y su defensa en contra de contrabandistas que saboteaban su monopolio. Se requisan barcos, se revisan paquetes y caletas marinas y se crean alcabalas de aduana y control. Sus prácticas monopólicas y excluyentes produjeron varias revueltas, siendo una de ellas la liderada por el zambo Andresote, en San Felipe, en 1735. Sin embargo, la más relevante ocurrió en Barlovento, extendiéndose después hacia Caracas, entre 1748 y 1752, la cual estuvo liderada por el cosechero local de origen canario Juan Francisco de León y a la cual se plegaron todos los sectores marginados por las prácticas de la Compañía Guipuzcoana, incluyendo esclavos, pardos y canarios, por lo cual adquirió tintes de revolución social. Ambas fracasan por falta de apoyo de la élite criolla local, que decide plegarse a la Corona.

A mediados del siglo XVIII se fundan ciudades como Angostura (1764), en el Orinoco, y San Fernando de Apure (1788), y crecen otras como San Carlos, Calabozo y San Cristóbal, en los Andes.

Los jesuitas son expulsados hacia 1766, al igual que en el resto de América por orden real.

En 1777 se produce la integración de las varias provincias en la así llamada Gobernación de Venezuela y luego en la Capitanía General de Venezuela, que constituye esencialmente desde entonces el actual territorio de la nación.
El libre comercio se instaura y se extingue en esa década la Compañía Guipuzcoana.

A fines de siglo se crea la "Real Audiencia de Caracas", con jurisdicción judicial para conocer de los pleitos en segunda instancia, que sustituye en esa función a la antigua Audiencia de Santo Domingo.

Las provincias existentes para el momento de la creación y organización de la Capitanía General de Venezuela eran, aparte de la Provincia de Venezuela serían:

Provincia de Trinidad, creada en 1532, por el conquistador Antonio Sedeño, y originalmente bajo la jurisdicción de Santo Domingo, posteriormente a su incorporación a la Capitanía General, fue atacada por una flota inglesa, que obtuvo la rendición de la plaza, del gobernador de la isla, en el año 1797, y fue reconocida su ocupación por Tratado de Amiens en el año 1802.

Provincia de Nueva Andalucía, está reunió a las anteriores provincias o gobernaciones de Nueva Andalucía y Paria, en una única entidad, la misma fue originalmente dependiente de la Real Audiencia de Santo Domingo a partir del año 1569, hasta que fue sujeta a la jurisdicción del Virreinato de la Nueva Granada, de 1749 a 1777.

Provincia de Margarita, la isla fue una provincia hasta el año 1600, cuando pasa a depender directamente de la Corona Española hasta 1777.

Provincia de Guayana, también conocida como Provincia de Angostura, y fundada en el año 1591.

Provincia de Maracaibo, formada en 1740, con la unión de las anteriores provincias de La Grita y Mérida.

La Provincia de Venezuela o Caracas, depende siempre de la Real Audiencia de Santo Domingo, en la isla La Española, hasta 1718, cuando el nuevo régimen borbónico en España, por Real Cédula la hace depender en adelante del recién creado Virreinato de Nueva Granada. Se independiza de nuevo de este Virreinato de la Nueva Granada en el año 1742. Treinta años después se le anexan los territorios de las provincias de Maracaibo, Guayana, Cumaná, dependientes del Virreinato de la Nueva Granada, la provincia de Trinidad, dependiente de Santo Domingo y Margarita, dependiente de la Corona Española, para formar la Capitanía General de Venezuela, con capital en la ciudad de Santiago de León de Caracas, por Real Cédula emitida por el Rey Carlos III de España, el 8 de septiembre de 1777.

La autoridad de la Capitanía General abarca los asuntos de índole política, militar y económica, de todas las anteriormente señaladas provincias; sin embargo, las mismas continúan dependiendo judicialmente de la Real Audiencia de Santo Domingo, y sus gobernadores eran nombrados directamente por la Corona Española.

La influencia de Caracas como ciudad central de gobierno oficial, y residencia del Gobernador en un área que abarcaba económicamente varias otras gobernaciones como la de Nueva Andalucía, Mérida o Guayana, influye finalmente para integrar todo el conjunto de provincias y gobernaciones del área de Venezuela alrededor de la Gobernación de Caracas.

La economía colonial de Venezuela gira alrededor de la exportación de "cueros", trigo, tabaco y cacao, con auges en diferentes épocas, siendo este producto, el cacao tan apreciado en el exterior por su finura, aroma y calidad que impulsa durante los dos siglos finales de la etapa colonial el desarrollo económico, y genera una casta ilustrada de descendientes de los conquistadores, conocida como los mantuanos, que basa su riqueza y poder en este producto durante esos 2 siglos.

El Imperio Español descuida y limita la promoción de la educación en sus colonias. Venezuela, al ser una provincia particularmente pobre después del colapso de la explotación de las perlas en el siglo XVII, es particularmente olvidada. Los grupos de mulatos y otros no tienen acceso a la educación siquiera básica.

En 1727 se crea la primera universidad en Venezuela, siglos después de que se hubiera hecho en México o el Perú.

En 1760 el gobernador de la provincia de Caracas le otorga un permiso al coronel de ingenieros Nicolás de Castro para introducir los estudios de matemáticas con una Academia de Geometría y Fortificación exclusivamente para sus oficiales. Manuel Centurión crea en 1761 una Academia Militar de Matemáticas. En 1763 el maestro Lorenzo Campins y Ballester introduce una Cátedra de Medicina.

La fuerza militar hispana es bastante reducida para la población. Para 1777 hay en teoría unos 12000 militares para una población de unas 800 mil personas. Es así como en 1797 las tropas inglesas del general Abercromby conquistan con facilidad las islas de Trinidad y Tobago: el gobernador José María Chacón y Sánchez de Soto apenas había conseguido movilizar unos quinientos soldados mal armados en contra de una armada con 59 buques y 6750 soldados de infantería.

Varias tímidas intentonas de emancipación se producen, una de ellas liderada por el ex esclavo José Leonardo Chirino en Coro, y otra por los criollos Manuel Gual y José María España y el español Juan Bautista Picornell influenciados por las ideas de la Revolución francesa, establecidos en La Guaira, denominada "la Conspiración de Gual y España". Sus cabecillas son presos y algunos ahorcados en la Plaza Mayor de Caracas en 1799.

Alexander von Humboldt informa que para el comienzo del siglo XIX Venezuela importaba productos por más de 35 millones de francos de la época y que cuatro quintas partes de esta mercancía viene de Europa. Dice que los cueros de Carora, las hamacas de Margarita y las mantas de algodón del Tocuyo son productos muy poco importantes "incluso para el mercado interno".

Dentro de las causas internas se destacaba el conocimiento de las ideas de la ilustración por los "criollos". Constituían un grupo social caracterizado por poseer un alto nivel educativo por lo que su preparación intelectual y contactos con el extranjero les permitieron conocer las ideas revolucionarias.

En referente a las causas externas que dieron lugar a las causas de la independencia de Venezuela destacamos las siguientes:
Las ideas de igualdad, libertad y fraternidad van a jugar una influencia decisiva en el ánimo de los criollos, además de las diversas independencias surgidas (independencia de Estados Unidos, independencia de Haití) y la Revolución Francesa.


A finales del siglo XVIII tienen lugar los primeros conatos independentistas en Venezuela. La primera de ellas es una rebelión armada en 1795 con José Leonardo Chirinos a la cabeza. La otra se trata de una conspiración por parte de Manuel Gual y José María España, en 1797, y es la primera de raíces populares. Ambas intentonas resultan fallidas, con sus respectivos líderes ejecutados. Francisco de Miranda, por su parte, intenta dos veces en 1806 invadir el territorio venezolano por La Vela de Coro con una expedición armada proveniente de Haití. Sus incursiones terminan en fracasos por la prédica religiosa en su contra y la indiferencia de la población.

La independencia de Venezuela se desarrolló entre 1810 y 1823. Fue marcada por dos importantes acontecimientos:

• La independencia de Estados Unidos de Inglaterra en 1776, abriendo camino a otras colonias como Venezuela.
• La revolución francesa (1789)

En 1806, el criollo Francisco de Miranda, precursor de la independencia, emprendió una expedición liberadora de Venezuela con una armada proveniente de Haití y apoyada por los británicos. En una primera ocasión el intento fue fallido. Miranda se refugió en Tobago, y pocos meses después volvió a intentarlo, logrando el éxito. 

La fecha del 19 de abril de 1810 marcó el inicio de la revolución venezolana y da inicio a la independencia de Venezuela. Vicente Emparan, para ese entonces era el Capitán General de Venezuela, fue destituido de su cargo por el Cabildo de Caracas. Ello dio paso a la formación de la Junta Suprema de Caracas, la primera forma de gobierno autónoma. La Junta gobernó hasta el 2 de marzo de 1811, día en que se instaló el Primer Congreso Nacional, ente que nombra un triunvirato compuesto por Cristóbal Mendoza, Juan Escalona y Baltasar Padrón. Meses después, el 5 de julio de ese año, se procede a declarar la independencia y el 7 de julio del mismo año, finalmente se firma el Acta de la Declaración de Independencia de Venezuela. 

Aun así, los ánimos estaban caldeados y muchos realistas planeaban una conspiración para regresar al estado anterior al 19 de abril de 1810, alzándose varias poblaciones con tal propósito, entre ellas Valencia, Caracas y Los Teques, con el apoyo de la guarnición de Puerto Cabello y varias tropas españolas procedentes de Maracaibo que aún permanecía en manos realistas. La ciudad de Valencia es declarada capital de la República por el Congreso Nacional el 9 de enero de 1812 luego de ser sofocada la rebelión, con el objetivo de asegurar el apego de la ciudad (al igual que el de otras importantes poblaciones dependientes, como Puerto Cabello) a los intereses independentistas. A pesar de ello, esta Primera República colapsa con la llegada de Domingo de Monteverde, quien recupera el control de la Provincia. El 25 de julio de 1812 Miranda, Comandante en Jefe del recién creado ejército, capituló en San Mateo; Simón Bolívar y otros militares entregaron a Miranda a los españoles liderados por Monteverde, quien les dio carta de salida del país.
La región occidental, junto con Atanasio Girardot y José Félix Ribas. Luego de hacer público el polémico Decreto de Guerra a Muerte, enfrentó a los realistas en cuatro batallas a lo largo de la ruta hacia la capital. Al terminar la campaña, el 6 de agosto entró triunfalmente en Caracas, donde se le tituló como Libertador. Así se dio inicio a la Segunda República, aunque continuaron los combates en otros puntos del país. Sin embargo, al año siguiente estalló una rebelión leal a la Corona a cargo de José Tomás Boves. El violento empuje de sus tropas forzó a los seguidores de Bolívar a huir a oriente y a la expulsión de los patriotas de tierra firme, con lo que cayó la Segunda República.

Bolívar intentó una reedición de la Campaña Admirable para rescatar la república, pero por falta de apoyo se trasladó a Jamaica para conseguir apoyo británico, y luego a Haití. Allí se refugió el resto de los líderes patriotas. Estos planificaron una expedición a tierra firme, la cual zarpó en marzo de 1816. Luego de tomar la Isla de Margarita, los republicanos prosiguieron su gesta atacando Carúpano y Maracay. Bolívar huyó al poco tiempo. Se hizo una . Piar había conseguido liberar Guayana. Bolívar aprovechó esto para trasladarse allí junto con las tropas de mercenarios europeos - ante todo británicos - que llegaban a Venezuela a través de Oriente. Bolívar tomó el mando de las tropas republicanas acantonadas en Guayana y estableció la Tercera República. La rivalidad con Piar creció rápidamente y al final Bolívar mandó a aprehender a este. Al poco tiempo, Piar fue ejecutado. Por su parte, José Antonio Páez realizó importantísimas operaciones militares para liberar la región central del país al mando de sus "llaneros".

La guerra en el llano sigue hasta 1819. En febrero de ese año, Bolívar intentó la reorganización del Estado con la instalación del Congreso de Angostura, cuyo resultado es la creación de la Gran Colombia. En 1820, se firmó el Tratado de Armisticio y Regularización de la Guerra, poniendo fin a la guerra a muerte y cesando hostilidades hasta el 28 de abril de 1821. El 24 de junio de ese mismo año, Bolívar se enfrentó a Miguel de la Torre en la Batalla de Carabobo, que se salda con la victoria republicana. Esta victoria significó la liquidación de las tropas realistas en Venezuela, dejando remanentes que serían vencidos en la Batalla naval del Lago de Maracaibo en 1823.

La República de la Gran Colombia, según la ley fundamental que la crea, integra a Venezuela con el Virreinato de Nueva Granada y la Provincia Libre de Guayaquil, a la que luego se une la Audiencia de Quito. El congreso elegido en Angostura se mueve a Cúcuta, donde se sanciona la Constitución de Cúcuta en agosto de 1821, y en la que se define la organización política de este Estado. Bolívar es elegido presidente por mayoría, y Francisco de Paula Santander es hecho vicepresidente. Bolívar continúa sus campañas de liberación por el sur, en la que propicia la liberación del Perú y la creación de Bolivia.

El nuevo Estado reguló sobre el comercio y las instituciones públicas, y también decretó la abolición de la esclavitud. Pero la discrepancia entre bolivarianos (centralistas) y santanderistas (federalistas) tensionó el orden interno. Aunado a la crisis económica, la carente infraestructura, las diferencias idiosincráticas y de intereses, y el deseo de autonomía por parte de los venezolanos para con su territorio, germinó la secesión. La Cosiata de 1826, liderada por Páez, fraguó dicha inconformidad del departamento de Venezuela con el gobierno de Bogotá. Para aquietar la convulsión, Bolívar gobernó por decreto desde 1828, pero ello no impidió la separación de Venezuela, que se manifestó finalmente en noviembre de 1829. En mayo de 1830 se instaló el Congreso de Valencia en Valencia (capital provisional del país con motivo del congreso) para tomar decisiones con respecto a los pasos a seguir por el Departamento de Venezuela en vista el creciente y continuo distanciamiento con el Gobierno Central, lo cual terminó en la separación definitiva de Venezuela de la Gran Colombia y el nacimiento del Estado de Venezuela, adoptándose una nueva constitución.

El principal jefe político y hombre fuerte de Venezuela en sus albores como nación independiente es José Antonio Páez, quien se juramenta como Presidente el 11 de abril de 1831, y su Vicepresidente es Diego Bautista Urbaneja. En su persona se constituye el Partido Conservador, integrado en su mayoría por militares de alto rango que participaron en la Guerra de Independencia. En su mandato hay relativa paz y la economía muestra una recuperación estimulada por la Ley de Libertad de Contratos de 1834 y la masiva exportación de café. En 1835 delega el poder en José María Vargas, el primer civil en dirigir el país. Esto último no es de gusto para los militares de pensamiento liberal, encabezados por Santiago Mariño y Pedro Carujo que se levantan para exigir la reconstitución de la Gran Colombia y el fin del poderío de una minoría de comerciantes. Entre tales oficiales hay bolivarianos sobresalientes, como el edecán del Libertador, Luis Perú de Lacroix o el granadino José María Melo, así como también un enemigo de Bolívar, Pedro Carujo. Obtienen un efímero triunfo y designan como presidente provisional a Mariño, pero llaman al general Páez con el fin de que los respaldara; sin embargo éste restaura a Vargas en el gobierno y decreta amnistías a los oficiales de la revolución, muchos de los cuales sin embargo resultan desterrados.

Páez, tras haber derrotado una rebelión liberal, vuelve a resultar electo en 1838. Afrontó la crisis económica mundial de ese año, que golpeó duramente a Venezuela, y a la creciente oposición liberal representada por Antonio Leocadio Guzmán, a la vez que iniciaba las disputas territoriales contra los británicos por la cuestión del Esequibo. Soublette fue nuevamente presidente en 1843, y en 1847 es elegido el general José Tadeo Monagas con gran apoyo, pero rompió luego con los conservadores. El intento de éstos en deponerlo desembocó en el atentado al Congreso de 1848. El General se aseguró de que su hermano José Gregorio Monagas fuese hecho presidente en 1851, quien proclamó la definitiva abolición de la esclavitud en 1854. José Tadeo volvió al poder en 1855, pero su régimen autoritario vio su fin en la Revolución de Marzo de 1858, comandada por Julián Castro; siendo este último nombrado como Presidente Provisional de la República en la Convención de Valencia y posteriormente en Presidente Interino, haciendo de la ciudad de Valencia nuevamente la capital provisional del país.

Los decretos del nuevo gobierno crearon descontento en liberales, y la inestabilidad hizo inminente el estallido de un conflicto armado conocido como la Guerra Federal.

El "" marca su inicio, y se desarrolla como una guerra de guerrillas. En las batallas iniciales, los federalistas liberales obtuvieron importantes triunfos, a pesar de la muerte en combate de su líder Ezequiel Zamora en 1860. Su mando es ocupado por Juan Crisóstomo Falcón. Los refuerzos y el apoyo conseguido por Falcón fortalecen a los liberales. Los enfrentamientos posteriores les dan ventaja y merman las fuerzas del gobierno centralista. Finalmente, en abril de 1863 se firma el Tratado de Coche, que significa la victoria de los liberales y su acceso al poder. No obstante este resultado, se conforman nuevos caudillismos regionales con ejército propio que mantiene el control de grandes porciones de tierra, cosa que contraria el anti-latifundismo liberal. Ese año, Falcón asume la presidencia y promulga su Decreto de Garantías que elimina la pena de muerte, cosa que es ratificada en la nueva constitución, y convirtiendo a Venezuela en el primer Estado moderno del mundo en llevarlo a práctica.

Las medidas de Falcón causaron rencor tanto entre los conservadores como en los disidentes de la facción liberal. Ambos bandos se unieron para derrocar al gobierno en 1867 en la llamada Revolución Azul. Un ejército dirigido por Miguel Antonio Rojas se alzó en la región central del país, mientras que el expresidente José Tadeo Monagas se alzó en la región oriental. Por la difícil situación, Falcón delegó el poder en Manuel Ezequiel Bruzual. A mediados de 1868 Rojas rodeó la capital, y firmó el Tratado de Antímano, reconociendo al gobierno y asumiendo el mando militar del país. Los orientales, considerando el tratado como una traición, prosiguieron su campaña hacia Caracas, a la que capturaron en junio de ese año, instaurando el gobierno de los "azules", Guillermo Tell Villegas y José Ruperto Monagas.

Antonio Guzmán Blanco, hijo de Antonio Leocadio Guzmán, había luchado en las filas del bando liberal durante la Guerra Federal y luego formó parte del gobierno de Falcón. Luego de iniciado el régimen de los azules, tramó junto con su padre el retorno al poder de los liberales. Al huir por el rechazo de turbas azuzadas por el gobierno, organizó una invasión que logró el apoyo de caudillos regionales federalistas, tales como Joaquín Crespo y Francisco Linares Alcántara. En febrero de 1870 desembarcó en Curamichate y tomó posiciones por el centro-occidente del país mientras engrosaba sus fuerzas. Tomó Caracas en abril de ese año, por lo que su acceso al poder se conoce como la Revolución de Abril.

Por haber vivido varios años en Europa, una vez hecho presidente implementó una serie de medidas tendientes a modernizar el país e instaurar el orden definitivo. En los decretos de ese año, creó el Conservatorio de Bellas Artes, reestructuró la Alta Corte Federal, dictó el Decreto de Instrucción Pública y Obligatoria promoviendo la educación, reorganizó la Universidad Central hizo del peso venezolano la moneda nacional, fomentó la agricultura, mejoró la infraestructura, e inició una ambiciosa transformación urbanística de Caracas, ciudad a la que según los historiadores se empeñó en darle cualidades parisinas, sin abandonar una tendencia centralista y autoritaria. También combatió los alzamientos en Apure, Guayana y Coro, logrando someter a los caudillos. Inició una promoción del culto a los héroes del pasado, especialmente a Simón Bolívar, como una estrategia para unir el país. Igualmente, debilitó el poder de la Iglesia Católica en Venezuela, al pasar al Estado funciones que tradicionalmente eran realizadas por ésta.

En 1877 viajó a Europa tras pasar el mando a Francisco Linares Alcántara, quien poco después comenzó un movimiento contra Guzmán Blanco. Ello, y la descontinuación de la línea progresista mantenida por su antecesor, provocó la Revolución Reivindicadora que le derrocó en 1879. Tras regresar al país, Guzmán Blanco inició un segundo gobierno en el que designó al bolívar como moneda nacional, y decretó el canto "Gloria al Bravo Pueblo" como himno nacional, además de continuar las medidas que habían tenido éxito en su anterior período, con la ganadería y el agro recuperándose de la caída en el pasado. Luego de cinco años pasó el mando a Joaquín Crespo. La introducción del positivismo y la creciente oposición del sector estudiantil condujeron al cierre de la universidad por parte del gobierno. Como resultado, el Congreso eligió a Guzmán Blanco para presidir entre 1886 y 1888, quien se retiró en 1887, dejando a Hermógenes López como presidente interino para la transición.

Le siguió Juan Pablo Rojas Paúl, quien se alejó de la línea centralista mantenida hasta el momento, creó la Academia Nacional de la Historia, y enfrentó disturbios y alzamientos anti-guzmancistas. En 1890 fue elegido Raimundo Andueza Palacio para el período constitucional de dos años, pero su intento por extender su mandato provocó la Revolución Legalista de 1892 encabezada por Joaquín Crespo, que le derrocó del poder. Crespo asumió la dirigencia como producto del movimiento en octubre de ese año, y aprobó una nueva constitución estableciendo la duración de la presidencia a cuatro años, y el voto directo. Mientras era jefe del país los recursos públicos fueron mal invertidos y se crearon nuevas deudas para el país, pero permaneció popular entre sus soldados. Su candidato a sucesor, Ignacio Andrade, venció en las elecciones de 1897, pero su contrincante José Manuel Hernández, desconoció los resultados acusando fraude, y se rebeló en Queipa, Valencia en 1898. Crespo, al mando de las tropas del gobierno, pereció en la Batalla de la Mata Carmelera, pero el alzamiento fue derrotado. El saldo al final del siglo XIX fue de recesión económica, pero de avances en la cultura, la tecnología y el urbanismo.

La Revolución Liberal Restauradora de 1899 organizada por Cipriano Castro y Juan Vicente Gómez hizo huir del país a Andrade, llevando al poder a Castro, quien sin embargo, ratificó en sus cargos a algunos ministros del derrotado gobierno, desvirtuando el lema principal de su campaña: «"Nuevos hombres, nuevos ideales, nuevos procedimientos"». En 1901, la Asamblea Nacional Constituyente lo eligió Presidente y como segundo vicepresidente a Gómez. Al igual que sus predecesores, por su autoritarismo combatió sediciones internas. La más sobresaliente de éstas fue la Revolución Libertadora, liderada por el banquero Manuel Antonio Matos, que culminó con el triunfo de Castro en 1903 tras las batallas de La Victoria y de Ciudad Bolívar, y cerrando el capítulo de las grandes rebeliones caudillistas. Además, su gestión siguió una fuerte línea anti-imperialista contra las grandes potencias extranjeras, negándose a cancelar la deuda nacional con el Reino Unido y Alemania. Debido a esto, debió encarar el bloqueo naval que impusieron estos países.

Debido a una enfermedad, en noviembre de 1908 Castro se dirigió a París con el propósito de someterse a tratamientos pertinentes. Días después, su vicepresidente y amigo Gómez perpetró un golpe de estado en diciembre de ese año, traicionando a Castro y prohibiendo su regreso a Venezuela. Gómez fue oficialmente presidente desde 1910, cuando el Congreso lo eligió para un término de cuatro años, pero decidió permanecer el poder, y para solventar la crisis posterior suspendió las elecciones. Gómez sería designado como Presidente Constitucional por períodos de siete años establecidos por una nueva constitución, con gobernantes títere presidiendo por poco tiempo y actuando de fachada a Gómez. Fue inmisericordioso tanto con opositores como con todo aquel que le cuestionase. Muchos prisioneros políticos cumplieron su condena realizando trabajos forzados para construir diversas carreteras por todo el país. Para resistir protestas del estudiantado, cerró la Universidad Central de Venezuela durante diez años, con lo cual sumió al país en un franco atraso educativo. También promulgó la primera Ley del Trabajo, creó bancos para obreros y agricultores, inició la explotación petrolera y logró la cancelación de la deuda externa en 1930. El movimiento opositor más recordado de su época fue protagonizada por los estudiantes universitarios en 1928, de donde surgirían nuevos líderes políticos. En 1929 también tuvo lugar un intento de golpe de estado en los cuarteles de Caracas tras los fallidos alzamientos de los generales, Emilio Arévalo Cedeño y Jose Rafael Gabaldón, así como la toma de Curazao por Rafael Simón Urbina y la invasión del "Falke" liderada por Román Delgado Chalbaud. La mayor contribución del general Gómez fue la pacificación definitiva del país, al exterminar a los caudillos importantes y crear la Academia Militar de Venezuela, como base de un Ejército Nacional consolidado. Su régimen es considerado como la dictadura más férrea que ha tenido Venezuela y Latinoamérica.

Gómez murió en 1935, y el General Eleazar López Contreras fue designado Encargado de la Presidencia hasta 1936, y luego Presidente Constitucional por siete años. Con él se inicia la transición a la democracia: decreta amnistía para los prisioneros políticos y restablece la libertad de prensa. En los Carnavales de este año una gran manifestación pública frente al Palacio de Miraflores demandando por mayores libertades civiles, a las que López accedió en parte con su "Programa de febrero". En julio reformó la constitución, reduciendo el período presidencial de 7 a 5 años, y focalizó sus políticas gubernamentales en la creación de programas asistenciales de salud pública. Además, concretó obras de suma importancia para la nación como la creación de la Guardia Nacional de Venezuela en 1937, la apertura del Museo de Bellas Artes y del Museo de Ciencias en 1938, y la creación del Banco Central de Venezuela en 1940.

Al término de su mandato en abril de 1941, el Congreso designó como Presidente a Isaías Medina Angarita, militar que promulgó una Ley de Hidrocarburos en 1943 que traería más dividendos monetarios al país y restringiría la participación de las empresas multinacionales. En su gestión se decretó la elección directa de los diputados, el sufragio femenino y la legalización de todos los partidos, se permitió el regreso de todos los exiliados políticos y la liberación de la totalidad de los presos políticos. También creó el primer plan de cedulación venezolana en 1944, activó una reforma agraria, e inició la modernización de las ciudades. Apoyó a los aliados en la Segunda Guerra Mundial e intentó la anexión de las Antillas Neerlandesas. El aspecto más negativo fue la firma del Tratado de Límites de 1941 entre Colombia y Venezuela. Aunque continuó con mayor rapidez el camino a la democracia, existían muchos adversarios políticos, como Rómulo Betancourt y su partido Acción Democrática. Desde su seno se fraguó en 1945 un golpe de estado con ayuda de un grupo de jóvenes militares dirigidos por los Tenientes Coroneles Marcos Pérez Jiménez, Luis Llovera Páez y Carlos Delgado Chalbaud, quienes disentían con el tipo de elección presidencial empleada y con muchas medidas de Medina.

Se instauró entonces una Junta Revolucionaria de Gobierno presidida por Betancourt. En breve tiempo la Junta llamó a comicios libres y directos. El famoso escritor Rómulo Gallegos resultó ser el primer presidente venezolano electo de esta forma, asumiendo en febrero de 1948. A pesar de eso, Gallegos no completó su período debido al golpe de estado del 24 de noviembre de ese año, en el que se hizo con el control del país una Junta Militar integrada por los mismos rebelados de hace tres años, y que derogó la constitución de 1947. De los triunviros, Carlos Delgado Chalbaud era candidato a presidir el país luego de que la Junta Militar convocara a elecciones, pero es secuestrado y asesinado por un grupo liderado por Rafael Simón Urbina y su sobrino Domingo Urbina el 13 de noviembre de 1950. Tras el incidente, Germán Suárez Flamerich fue designado presidente provisional. Aunque no se ha podido confirmar, es creencia popular que el autor intelectual del magnicidio fue Marcos Pérez Jiménez, el segundo triunviro que ejercía como Ministro de Defensa.

Pérez Jiménez permaneció en tal cartera hasta diciembre de 1952, fecha de las votaciones para una Asamblea Constituyente. Al observar que el partido opositor URD se estaba llevando el mayor porcentaje de votos, el oficialista Frente Electoral Independiente desconoció los resultados y suspendió las elecciones. Dos días más tarde, los poderes de la Junta fueron transferidos en su totalidad a Pérez Jiménez, quien en abril de 1953 es proclamado Presidente Constitucional por cinco años. Su gobierno, que en ese año impulsó una constitución, tuvo el formato de una dictadura personalista que no vaciló en proscribir a la oposición, coartar libertades civiles y censurar sistemáticamente a los medios de comunicación. Su principal organismo policial, la Dirección de Seguridad Nacional en su Sección Político-Social (f. 1949), tuvo la tarea de arrestar a opositores, recluirlos en el Campo de Concentración de Guasina, y también ejecutarlos. Tuvo especial apoyo del gobierno de los Estados Unidos por ser parte de la red de distribución petrolera y por su lucha contra el comunismo. Sin embargo, su régimen también se caracterizó por un progreso en infraestructura sin igual para el país, lo que posteriormente se conocería como la «dictadura desarrollista» de Venezuela. La explosión de la infraestructura visionaria y tecnológicamente puntera, el fomento especial a la inmigración europea que cambió a la sociedad venezolana, y la completación de ambiciosos y emblemáticos proyectos de obras públicas, se enmarcaron como la práctica de una corriente de pensamiento nacionalista denominada el Nuevo Ideal Nacional. A pesar de esto, la antipatía generada por sus actos represivos y sus intenciones de perpetuarse en el poder, incrementó el descontento en su contra.

En diciembre de 1957 se organizó un plebiscito para definir su permanencia para otro período en el poder. Los boletines oficiales le dieron la victoria, aunque era de sobre entendimiento en la población en general que se trató de un fraude orquestado. Esto produjo un fraccionamiento en las Fuerzas Armadas que lo habían apoyado hasta entonces, y que protagonizó una rebelión fallida en el día de Año Nuevo de 1958. La crisis política que se originó entonces desestabilizó las bases del régimen, concluyendo con su deposición por un movimiento cívico-militar en la madrugada del 23 de enero, lo que le obligó a huir hacia República Dominicana para posteriormente trasladarse a los Estados Unidos junto a su familia. Al día siguiente se organizó una Junta de Gobierno presidida por el contralmirante Wolfgang Larrazábal. Aunque se llamó a elecciones para ese año, la Junta rechazó varios conatos de golpe por parte de militares perezjimenistas. En octubre se procedió a la firma del Pacto de Puntofijo, que disponía de la alternancia en el poder de los partidos Acción Democrática, COPEI y URD, para encauzar la futura vida política del país y excluyendo a los partidos de izquierda. Larrazábal renunció a la junta en noviembre para participar en los comicios, siendo sustituido por Edgar Sanabria. La elección a Presidente se decantó finalmente por Rómulo Betancourt, quien asumió el cargo en febrero del año siguiente.

Las obras más perdurables de Pérez Jiménez se manifiestan en la construcción de gran parte de la infraestructura vial en el Distrito Federal. La Autopista Caracas-La Guaira, Autopista Tejerías-Valencia, Autopista Francisco Fajardo, el Paseo de los Próceres y otras muchas fueron obras del Gobierno Militar. Una Junta cívico - militar de Gobierno, presidida por el Contralmirante Wolfgang Larrazábal Ugueto se encarga del gobierno de transición hasta las nuevas elecciones presidenciales. Una medida populista de esta Junta de Gobierno, denominada Plan de Emergencia, por la cual se le daba una especie de salario mientras conseguía trabajo a todos los campesinos y obreros que lo solicitaran, dio origen a un masivo éxodo rural que se dirigió a las ciudades, especialmente, a Caracas, lo cual dio origen, a su vez, a una macrocefalia de la capital con respecto al resto del país, y al rápido y descontrolado incremento de las áreas de poblamiento marginal en las barriadas de las principales ciudades.

La nueva era democrática trajo consigo cambios a nivel político y económico. En su gobierno no se otorgó más concesiones petroleras a las empresas que operaban en el país, se constituyó la Corporación Venezolana del Petróleo, y se creó la OPEP en 1960, por iniciativa de Juan Pablo Pérez Alfonzo. Paralelamente se adelantó una ley de Reforma Agraria que redistribuiría los terrenos improductivos con el fin de detener el declive de la producción agrícola, debido al "boom" petrolero. Igualmente, se sancionó una nueva constitución en 1961. El nuevo orden tuvo sus antagonistas. Durante un desfile militar, el Presidente sufrió un atentado planeado por el dictador dominicano Rafael Leónidas Trujillo con el fin de reiniciar la dictadura en Venezuela. Los grupos izquierdistas excluidos del Pacto iniciaron una insurgencia armada, organizados en los focos guerrilleros de las Fuerzas Armadas de Liberación Nacional, auspiciadas por el Partido Comunista. En 1962, intentaron la desestabilización vía los cuerpos militares, protagonizando dos fallidas revueltas, una en Carúpano y otra en Puerto Cabello. Paralelo a esto, Betancourt promovió una doctrina internacional, en la que sólo reconocía a los gobiernos electos por votación popular y rompía con los regímenes dictatoriales.

En las siguientes elecciones de 1963 resultó electo Raúl Leoni. Su gobierno comenzó con una coalición de partidos a la que se denominó la "Amplia Base", integrando a AD, URD y el FND. Aunque su gobierno fue de concordia general y entendimiento entre los sectores de la población, tuvo que lidiar con numerosos ataques de la guerrilla. De entre éstos destaca la invasión a las playas de Machurucuto en mayo de 1967. Viendo que rendía pocos frutos, la mayor parte de los guerrilleros abandonaron la lucha armada por la política electoral en ese año. El gobierno de Leoni también se destacó por la conclusión de obras públicas y el desarrollo cultural.

Rafael Caldera resultó vencedor en los siguientes comicios. Antes de tomar posesión, en 1969, estalló la insurrección de Rupununi en Guyana, que representó una oportunidad para anexar parte del Esequibo que reclamaba Venezuela. En este contexto, firmó el Protocolo de Puerto España en 1970, congelando las reclamaciones por 12 años. Pactó la tregua definitiva con la guerrilla y garantizó su integración a la vida política, legalizando el PCV. En 1974 asumió la presidencia Carlos Andrés Pérez. En su gobierno se hizo notable el profuso ingreso de divisas por concepto del petróleo y los altos estándares de vida que adquirió la población, llegándose a la acepción de la "Venezuela Saudita", en la que creció aceleradamente el Producto Interno Bruto. En 1975 nacionalizó la industria del hierro, y al año siguiente, la del petróleo, creando la empresa estatal PDVSA. Tanto Caldera como Pérez rompieron parcialmente con la Doctrina Betancourt.

En 1979, Luis Herrera Campins es investido como Presidente. Inauguró múltiples instalaciones culturales y deportivas, así como el Metro de Caracas. Aunque los ingresos petroleros siguieron acrecentándose, ello no impidió que el país se endeudara en las finanzas internacionales, forzando el apego a los dictámenes del Fondo Monetario Internacional. 

En 1983 se produjo la devaluación del bolívar en el llamado "Viernes Negro", desatando una fuerte crisis económica. En el gobierno del próximo presidente, Jaime Lusinchi, se haría poco para contrarrestarla. Los índices de corrupción se vieron incrementados, y la política económica siguió manteniendo la línea rentista. Por otra parte, en 1987 se vivió el mayor momento de tensión militar internacional en los últimos años, cuando la corbeta colombiana "A.R.C. Caldas" ingresó clandestinamente en aguas del Golfo de Venezuela. Fue una crisis que se originó en la disputa por la soberanía en dicho golfo entre ambas naciones, y sobre la que no se había alcanzado acuerdo. Los medios hablaban de una posible guerra, pero el conflicto se resolvió por medio del diálogo y el retiro de la corbeta.

Carlos Andrés Pérez es nuevamente elegido en 1988. Buscando solventar la crisis, adoptó medidas que originaron grandes protestas como el Caracazo de 1989. Se produjeron dos intentos de golpe de Estado liderados el teniente coronel Hugo Chavez en febrero y en noviembre de 1992. Pérez fue finalmente destituido por el Congreso en 1993. Octavio Lepage fue Presidente provisional por pocos días, hasta que el historiador y parlamentario Ramón José Velázquez fue designado como interino por el Congreso Nacional.

Caldera llega al poder por segunda vez en 1994. Tuvo que manejar una fuerte crisis bancaria en 1994. El derrumbe e intervención de una decena de bancos culminó con la fuga de capitales, provocando también el quiebre de empresas. Para frenar la crisis, inició una política de privatizaciones, pero la grave situación económica continuaría. La situación catalizó el decaimiento de los partidos políticos que habían estado activos desde mediados del siglo XX.

Con la elección de Hugo Chávez como presidente de Venezuela en 1998, dando inicio a un proyecto ideológico y social que denominaron Revolución bolivariana. Lo primero que tuvo que afrontar como presidente fue la Tragedia de Vargas a finales de 1999. Para el 2002 comenzaron grandes protestas en su contra. El 11 de abril del 2002 se consumó un golpe de estado contra Chávez que lo derrocó por dos días, ese mismo día se genera uno de los hechos violentos más relevantes de la historia contemporánea. El dirigente de Fedecamaras (Cámara de comerciantes) Pedro Carmona se autoproclama presidente de Venezuela violando el hilo constitucional, y aprovecha junto a otro grupo de personas de disolver el Tribunal, los ministerios, la Asamblea y en general la constitución lo cual le dejaba pleno poder para gobernar la nación, hecho que fue repudiado por el pueblo debido a su fuerte contenido dictatorial. Este mina rápidamente la imagen del gobierno, pierde el apoyo de los militares, y Chávez es restituido el 13 de abril.

Tras el fallecimiento de Hugo Chávez en 2013, el CNE convoca a elecciones presidenciales y es electo presidente Nicolás Maduro. Tras el mandato de Maduro, se agudiza la escasez en Venezuela, esta situación se da en productos con precios regulados, como la leche, diversos tipos de carne, pollo, café, arroz, aceite, harina pre-cocida, mantequilla; así como también, productos de primera necesidad como papel higiénico, productos de aseo personal, medicinas para tratar el cáncer, entre otros. Son frecuentes las filas de personas que quieren comprar productos básicos en supermercados y otros negocios. Esta situación ha llevado al gobierno venezolano a impulsar medidas como el "Sistema Biométrico de Abastecimiento".

Para las elecciones parlamentarias del 2015 la oposición obtiene 112 de los 167 diputados de la Asamblea Nacional (56,2% de los votos), y la primera victoria electoral de peso para la oposición en 17 años.

En febrero de 2016, el presidente Nicolás Maduro, anunció el aumento de la gasolina, quedando en 1 Bs. para la de 91 octanos y en 6 Bs. para la de 95 octanos. Representando un 1328,57% y 6085,56% de incremento en el precio que se manejaba desde 1996. De igual forma, el salario mínimo se aumentó a 11.578 Bs.y el CestaTicket se incrementó a 13.275 Bs. Por su parte, el sistema marginal de divididas (SIMADI) pasa a ser "sistema complementario flotante", pasando de un dólar a 6,13 Bs., a 10 Bs. A finales de abril, es re-inaugurado el Teleférico Mukumbarí del estado Mérida. De igual forma, la Cervecería Polar paralizó la producción de malta y cerveza en el país, por no importar materia prima para su fabricación debido a la falta de divisas adjudicadas por el gobierno venezolano. Nicolás Maduro, anuncia el aumento del salario mínimo en un 30% quedando en 15.051 bolívares y el cesta ticket a 3.5 UT ubicándose en 18.585 bolívares. El 1 de mayo del mismo año entra en vigencia el nuevo huso horario del sistema UTC -4:30 horas a UTC -4:00 horas en toda Venezuela.
Se realizan fuertes protestas y marchas en contra del gobierno de Nicolas Maduro entre abril y julio de 2017, exigiendo elecciones. Por su parte, Nicolas Maduro anunció llamar a una Asamblea Nacional Constituyente (ANC). Sectores opositores al gobierno rechazaron el anuncio y expresaron inconstitucional la medida. Para el 16 de julio, la oposición al gobierno de Maduro realizó una consulta popular donde 7.535.529 venezolanos rechazan la ANC y da posteas a la Asamblea Nacional (AN) de tomar decisiones. El gobierno desconoció esta consulta. De igual forma, la comunidad internacional manifiestan su descontento y desconocimiento de la ANC, entre los países que se expresaron, están Argentina, Brasil, Colombia, Estados Unidos, entre otros; así como organismos internacionales como la OEA en los cuales plantearon la suspensión de la ANC, por su parte Mercosur, anunció la posibilidad de expulsar a Venezuela de su organismo. Las elecciones de la Asamblea Nacional Constituyente se realizó el 30 de julio, donde el Consejo Nacional Electoral dio a conocer que 8.089.320 personas sufragaron. El mismo día, se reportaron al menos 15 muertos en las protestas que surgieron a raíz del rechazo a la ANC.

En la madrugada del 6 de agosto de 2017, un grupo de militares toman por asalto el Fuerte Paramacay, Municipio Naguanagua del Estado Carabobo, presuntamente comandados por el capitán Juan Caguaripano. En octubre se celebraron elecciones para elegir gobernadores, donde resultaron electas 28 del partidos del gobierno, miestras que cuatro fueron ganadas por AD y el estado Zulia, pese haber ganado Guanipa, ante la negativa de juramentarse con la ANC, el consejo legislativo del estado, declaró vació de poder y designó un nuevo gobernador. Para noviembre del mismo año, tras ajustes a los precios de la carne, este rubro comienzó a desaparecer de los locales dedicados a su venta. Después de los anuncios ofrecidos por el presidente Nicolás Maduro, a principios de noviembre de 2017, como el aumento salarial y la pues en circulación del billete de 100000 bolivares; economistas y medios de comunicación afirmarón que Venezuela, ha iniciado una hiperinflación, tras arrojar el pasado mes de octubre una inflación del 50,6%. Luego el gobierno de Maduro, llamó a refinanciar la deuda externa. La Asamblea Nacional Constituyente promueve la Ley contra el Odio, por la Convivencia Pacífica y la Tolerancia, quien para algunos sectores limita la libre expresión dentro del territorio venezolano. Por su parte, desde el exterior se imponen fuertes sanciones económica contra partidarios afectos al gobierno, incluyendo al presidente Nicolas Maduro, por gobiernos como Estados Unidos y Canadá. A finales del año miembros del gobierno y fracciones de la oposición venezolana, realizaron diferentes encuentros con el fin de lograr acuerdos políticos. El 3 de diciembre de 2017, Nicolás Maduro dio a conocer la creación de la criptomoneda "petro", para evitar el bloqueo financiero.

A principio de enero de 2018, ocurrieron saqueos en diversas ciudades de Venezuela.
En la madrugada del 15 de enero de 2018, el área de El Junquito, fue acordonado por cuerpos de seguridad del estado, incluyendo militares. Luego se dio a conocer el paradero de Óscar Pérez en este sector, quien difundió por las redes sociales su situación, posteriormente manifestó su rendición, mientras las fuerzas de seguridad seguían disparando. En primera instancia resultó muerto Heiker Vásquez, quien ha estado relacionado con los grupos llamados "colectivos". La versión oficial de los cuerpos de seguridad, exclamaron que dos funcionarios resultaron muertos y al menos cinco heridos. El mismo día, Nicolás Maduro rindió su Memoria y cuenta del 2017, ante la Asamblea Nacional Constituyente. Al día siguiente, el ministro de Interior y Justicia, Néstor Reverol en rueda de prensa declaró la muerte de Óscar Pérez y otros seis miembros, quien calificó como una "célula terroristas". Por su parte, Luisa Ortega Díaz desde el exilio exclamó, que la muerte de Pérez, fue una violación de los derechos humanos. Por otro lado, la Asamblea Nacional investigará la muerte de Pérez, así también señaló que la presentación de memoria y cuenta por parte del presidente viola la Constitución de Venezuela, ya que está debió realizarse ante tal institución. El mismo día, algunos medios difundieron videos donde se observan funcionarios ejecutando un lanza cohete RPG-7, contra la vivienda donde se localizaba Óscar Pérez.

El 9 de abril de 2018, desde Colombia el Tribunal Supremo de Justicia venezolano en el exilio dicta prisión preventiva contra el presidente Nicolás Maduro, por corrupción. Tras la crisis, trabajadores del sector petrolero protestan por mejoras salariales, mientras tanto en PDVSA se prohíbe renunciar. 



</doc>
<doc id="4665" url="https://es.wikipedia.org/wiki?curid=4665" title="Economía de Venezuela">
Economía de Venezuela

La "Economía de Venezuela" está orientada a las exportaciones. La principal actividad económica de Venezuela es la explotación y refinación del petróleo para la exportación, la extracción y refinación está a cargo de la empresa estatal Petróleos de Venezuela (PDVSA). 

La producción inicial data de 1875, con la participación de la Compañía Petrolera del Táchira en la hacienda «La Alquitrana» localizada en el estado Táchira; luego es construida la primera refinería en la cual se obtenían productos como el queroseno y el gasóleo. El reventón del pozo Zumaque I en 1914 marca el comienzo de la explotación petrolera comercial a gran escala, accionando una gran cantidad de eventos que cambiaron drásticamente el rumbo del país. Mediante iniciativa y participación de Venezuela dentro del mercado petrolero mundial es fundada la Organización de Países Exportadores de Petróleo (OPEP).

Desde la década de 1950 hasta principios de 1980 la economía venezolana experimentó un crecimiento constante que atrajo a muchos inmigrantes. Durante la caída de los precios del petróleo en los años 1980 la economía se contrajo, y la inflación se disparó hasta alcanzar picos de 84 % en 1989 y 99 % en 1996, tres años antes de que Hugo Chávez asumiera el cargo de Presidente.

A pesar de las tensas relaciones con los Estados Unidos, este país es el más importante socio comercial de Venezuela. Las exportaciones estadounidenses a Venezuela incluyen maquinarias, productos agrícolas, instrumentos médicos y vehículos. Venezuela es uno de los principales proveedores de petróleo extranjero a los Estados Unidos. Cerca de 500 empresas de Estados Unidos están representadas en Venezuela.

De acuerdo con el Banco Central de Venezuela, el gobierno recibió de 1998 a 2008 alrededor de 325 mil millones de dólares a través de la producción petrolera y la exportación en general, y de acuerdo con la Agencia Internacional de la Energía (AIE), para agosto de 2015 tiene una producción de 2,4 millones de barriles por día, 500 mil de los cuales van a los Estados Unidos.

Desde el final de la crisis de principios de los años 1990, la economía venezolana tuvo más de una década expansiva de crecimiento macroeconómico, por encima de la media del resto de America Latina. Sin embargo, desde 2014 sufre una fuerte recesión. El número de desempleados alcanzó un máximo de 2,77 millones en abril de 2017.

Desde que Hugo Chávez impuso estrictos controles de cambio en 2003, en un intento de evitar la fuga de capitales, se han producido una serie de devaluaciones de la moneda. Para 2015, Venezuela tiene la tasa de inflación más alta del mundo, superando el 100 % interanual, convirtiéndose en la tasa más alta en la historia del país.

A principios del siglo XX, la economía venezolana tenía su eje en la producción agropecuaria particularmente del café del que llegó a ser segundo productor a nivel mundial solo superado por el Brasil. La renta por cápita de Venezuela era notablemente inferior a la de los países de América del Sur (Argentina, Chile, Uruguay), e incluso era inferior a la de países demográfica y geográficamente comparables como Perú y Colombia. Para el año 1920, el papel que jugaba la producción petrolera era mínima. Los principales productos de exportación eran el café, el cacao, el ganado vacuno, el azúcar, papelón, tabaco, balatá, cueros de res y caucho. Pero por otro lado el año 1920 constituye un punto de inflexión en la economía venezolana, a partir de entonces, las exportaciones agrícolas disminuirán exponencialmente en detrimento de las exportaciones petroleras. 

Para 1929, Venezuela fue el segundo mayor país productor de petróleo (solo por detrás de Estados Unidos) y el mayor exportador de petróleo del mundo. Con un espectacular desarrollo de la industria, el sector del petróleo había comenzado a dominar todos los demás sectores económicos del país.

Con la expansión petrolera vino el abandono del campo, debido a que la producción agrícola estaba primordialmente en manos de muy pocos terratenientes que ofrecían salarios minúsculos para las pésimas condiciones de vida que brindaba el campo. Por lo tanto no podían competir con los salarios que ofrecían las empresas petroleras en sus concesiones. El abandono del campo inundó al mercado laboral con un crecimiento abrumador de la oferta de trabajo.

A partir de 1925, gracias a la explotación del petróleo a gran escala Venezuela había superado la renta per cápita de Perú y Colombia, y a partir de 1926 experimentó un vertiginoso crecimiento que haría de Venezuela el país de América Latina de mayor renta per cápita lo que motivo la llegada de numerosos inmigrantes europeos y latinoamericanos. Entre 1950 y 1995 Venezuela siguió siendo el país de América Latina con mayor renta per cápita, aunque a partir de 1996 esta empezó a disminuir. La inflación en los años 90 fue entre 32 % (1992) y 100 % (1996).

La economía venezolana se aprovechó de los altos precios del petróleo durante la crisis petrolera de la década de 1970 y del superávit que esta le proveía; esto fue el detonante para que el Gobierno se endeudara con el exterior. Cuando la deuda externa se tornó impagable en 1983 se tuvo que devaluar la moneda en el episodio conocido como el Viernes Negro. A partir de entonces las políticas económicas de los gobiernos de Luis Herrera Campíns y Jaime Lusinchi no fueron capaces de frenar la espiral inflacionaria, generando desconfianza en las inversiones y pérdida de credibilidad en la moneda nacional. Algunas de las políticas que emplearon estos gobernantes para frenar los efectos estructurales fueron controles de cambio a través de RECADI (Luis Herrera Campins) y un control de precios (Jaime Lusinchi), medidas que devinieron en corrupción administrativa y mercado negro de divisas y bienes. Sin embargo la quiebra estructural del mercado interno, la falta de soberanía económica y alimentaria, generó una escasez gradual. En 1988 resulta electo presidente Carlos Andrés Pérez, apoyado en un discurso populista que apelaba a la justicia social. Con un gran respaldo electoral, el gobierno de Pérez, en lugar de buscar un cambio hacia la inclusión social, giró a liberar la economía, imponiendo su desregulación a través de un programa de ajustes macroeconómicos promovido por el Fondo Monetario Internacional (FMI), al que se le llamó "Paquete Económico", concebido para generar cambios sustanciales en la economía del país dentro del modelo neoliberal. Se anunciaron medidas de aplicación inmediata y otras de aplicación gradual en plazos breves. El paquete comprendía decisiones sobre política cambiaria, deuda externa, comercio exterior, sistema financiero, política fiscal, servicios públicos y política social. Sin embargo, la liberación de precios y la eliminación del control de cambio generó un reajuste sumamente brusco para las personas de menores ingresos, que eran la gran mayoría, lo que derivó en más hambre y desempleo. El descontento popular se manifestó en los trágicos sucesos del Caracazo (1989) lo cual no fue obstáculo para que se aplicaran con relativo éxito algunas de las medidas propuestas. Sin embargo dos intentos fallidos de golpe de estado (1992) liderados por el teniente coronel Hugo Chávez agravaron
la crisis económica en una vorágine de sucesivas devaluaciones y una volatilidad inflacionaria, lo que llevó a que se perdieran miles de empleos y el país cayera en una grave situación de pobreza, de la cual algunos economistas y políticos creen que el país no se ha recuperado completamente.

En 2001 el crecimiento del Producto interno bruto o PIB fue del 3,4 %. Un aumento significativo de los precios internacionales del petróleo permitió recuperar la economía de una fuerte recesión sufrida durante el año 1999. Sin embargo, un sector no petrolero relativamente débil, una alta fuga de capitales y una caída temporal en los precios del petróleo evitó que la recuperación fuera mayor.

A principios de 2003 se estableció un control de cambio, de un esquema con tasa de cambio libre flotando en bandas a un esquema de precio fijo controlado por el gobierno, haciendo al bolívar considerablemente. En 2003, como consecuencia de la grave inestabilidad política, diversos conflictos sociales y la paralización de actividades de la principal empresa estatal petrolera PDVSA, la economía venezolana tuvo una caída de su PIB del 7,7 %.

El 6 de febrero de 2003, el gobierno venezolano implanta un sistema regulatorio de cambio en la compra/venta de divisas extranjeras. La institución gubernamental encargada en ese entonces, CADIVI, inicialmente estableció el cambio de 1600 bolívares por dólar para la venta. El 3 de marzo de 2005 se devaluó la moneda frente al dólar, pasando el cambio oficial de 1920 a 2150 bolívares por dólar.

Durante el año 2004 Venezuela experimentó un crecimiento del 17,9 % en su PIB, aunado a la realización del Referéndum Revocatorio Presidencial con el triunfo del presidente Chávez con el 60 % de los votos, el ambiente político se mejoró y afectó positivamente a la economía. La inversión social del gobierno mediante las llamadas misiones en los campos educativos, alimenticios y de salud, lograron incrementar la calidad de vida de los ciudadanos con más bajos recursos (37 % de la población).

En 2005 Venezuela presentó un balance positivo en sus cuentas externas (31 000 millones de dólares) ya que las exportaciones alcanzaron 56 000 millones de dólares, representado el tercer lugar en importancia en América Latina detrás de México y Brasil. En tanto las importaciones totalizaron 25 000 millones de dólares.

Venezuela concluyó el 2005 con un crecimiento de la economía del 9,4 % del Producto Interno Bruto, ubicándose en el primer lugar entre los países del continente por segundo año consecutivo. Además en 2005 Venezuela registró la inflación más baja de los últimos siete años cayendo hasta un 8,9 % según cifras del Banco Central de Venezuela (BCV) y de la CEPAL.

Según el informe anual del BCV durante 2006, el PIB venezolano tuvo un incremento del 10,3 %. Ese año el sector no petrolero de la economía tuvo un incremento anual de 11,4 % y las reservas internacionales alcanzaron la cifra de 37 299 millones de dólares.

El 7 de marzo de 2007 el Gobierno anunció un proceso de reconversión monetaria, y la moneda llevó el nombre transitorio de Bolívar Fuerte (BsF). Su emisión fue controlada por el BCV, ente que estableció un cambio de 2,15 bolívares fuertes por dólar, lo que supone dividir entre mil (correr tres ceros a la izquierda) el bolívar que circulaba desde 1879. La nueva escala monetaria venezolana fue aprobada mediante decreto presidencial con la publicación en la Gaceta Oficial N° 38.638 por iniciativa del Presidente Hugo Chávez con la intención de reducir estéticamente la inflación y facilitar el sistema de pagos nacionales adecuándose a los estándares internacionales respecto a las cifras y el número de billetes que debería portar cada persona.

En 2007 en su informe Panorama social de América Latina de ese mismo año, la CEPAL reconoció que Venezuela entre 2002 y 2006, disminuyó en ese período sus tasas de pobreza en 18,4 % e indigencia en 12,3 %, pasando de una pobreza de 48,2 % y una indigencia de 22,2 % en 2002, a 37,9 % y 15,9 % respectivamente en 2005 y a 30,2 % y 9,9 % respectivamente en 2006.

Al cierre del año 2007 y según las cifras reportadas por el BCV la economía venezolana tuvo un crecimiento de 8,4 % impulsado por la expansión de la inversión y del consumo, con lo que se llegó a 17 trimestres de crecimiento consecutivo del PIB desde finales de 2003, registrándose desde ese mismo periodo un crecimiento interanual promedio de 11,8 %, el consumo registro la tasa de variación más alta desde 1997, al crecer 18,7 %, Los sectores o actividades económicas que registraron el mayor crecimiento fueron comunicaciones (21,7 %), actividad financiera y seguros (20,6 %) y construcción (10,2 %).
A finales de agosto, el ministro Rodríguez repasó sus cifras, estimando ahora una inflación anual de 26 % y un crecimiento del PIB cercano al 1 %. Sin embargo, el PIB venezolano experimentó finalmente una caída de 3,3 %;

El presupuesto nacional de 2009 fue calculado estimando el ingreso de 60 dólares por barril de petróleo, pero a finales de marzo se reformuló a 40 dólares, para ajustar la caída de los precios del petróleo a nivel global de 2009 y 2010, lo que desencadenó a su vez una crisis energética interna.

A inicios de 2010, el ministro de Finanzas Jorge Giordani estimó un crecimiento de 0,5 %, pero diversos especialistas calcularon una caída de entre 1,7 % y 3 %. A mediados de abril, el FMI estimó que Venezuela continuaría en recesión en 2010, con una caída de 2,6 %.

Finalmente, el PIB cayó 1,4 %; dentro del contexto regional, Venezuela queda detrás del resto de Latinoamérica y el Caribe, que experimentó en promedio un crecimiento de 6 %. Luego de la crisis energética, Venezuela sería la única nación petrolera y una de las dos naciones americanas aún en recesión en 2010. La otra nación es Haití, que a inicios de año experimentó un devastador terremoto.

Para expertos de la CEPAL, la crisis energética, y la caída en la exportación de petróleo venezolano estuvieron entre las razones para que Venezuela entrara en recesión, que duraría 18 meses desde segundo trimestre de 2009 hasta el tercer trimestre de 2010. El gobierno venezolano culpó a la lenta recuperación económica mundial de alargar la crisis, así como a la reducción de las cuotas de producción petrolera dictadas por la OPEP. De acuerdo a la oposición venezolana, las políticas del presidente Chávez para intentar aplicar el socialismo del siglo XXI estaban detrás de la crisis y estarían llevando "la economía a la ruina".

En septiembre de 2010, el bolívar fue devaluado nuevamente, pasando de 2,15 bolívares por dólar, a un sistema de cambio dual de 2,60 y 4,30 bolívares por dólar, dependiendo del tipo de transacciones a realizar con dichas divisas. Para aquel entonces, ya el dólar en el mercado negro se cotizaba por sobre los 9 bolívares.

Venezuela en el 2011 experimentó un crecimiento de 4,2 % de su PIB. El PIB no petrolero subió 4,3 % y el petrolero 0,6 %. Por segundo año consecutivo la economía venezolana siguió teniendo la inflación más alta del continente ya que los precios de los bienes y servicios subieron 27,6 %, un poco más que en 2010 cuando fue 27,2 %. Las exportaciones venezolanas al exterior, principalmente petróleo, subió 42,8 % en 2011. En total, Venezuela exportó mercancías por un total de 93 896 millones USD. Logrando así una balanza comercial supervitaria. Las importaciones se incrementaron 18 %, al cerrar el año 2011 con un monto de 45 615 millones USD. Las reservas internacionales del país cerraron el año en 29 899 millones USD, la cifra es 433 millones USD menor al cierre de 2010. El informe del presidente del BCV, señala que por la vía de Cadivi se liquidaron 35 394 millones USD en todo el año. En tanto, a través del Sitme se negoció un total de 8777 millones USD durante 2011.

En 2012 la economía venezolana cerró con un crecimiento de 5,5 %, una inflación de 20,1 % y un desempleo de 6,4 % ligeramente más bajo que en 2011. Los sectores que más crecieron fueron finanzas y entidades bancarias (32,9 %) y construcción 16,8 %.

Para el 2013, el gobierno nacional anunció un aumento del 20 % en los precios controlados de la carne de res, pollo, leche y quesos. En 2013 Venezuela se ubicó como el país más igualitario de Latinoamérica según cifras del gobierno venezolano. El coeficiente de Gini habría alcanzado 0,435 puntos (1 es la desigualdad absoluta y cero la igualdad absoluta).

Durante el período de estabilidad de precios entre 1951 y 1973, Venezuela presentó una de las inflaciones más bajas del mundo, la interanual promedio fue de 1,6 % con una tasa de crecimiento del PIB de 5,7 %, caracterizado por disciplina fiscal y el tipo de cambio fijo.

Desde hace algunos años, Venezuela ha tenido una de las tasas de inflación más altas del mundo. En el último lustro supera en este parámetro a todos los países de la región, cosa que no pasaba en la década de los noventa, cuando países como Brasil, Perú y México tenían una tasa inflacionaria muy superior a la de Venezuela.

En el 2007 la inflación superó con creces la meta gubernamental de 11 %. El gobierno venezolano había emprendido una serie de medidas para frenar la inflación, como la disminución del Impuesto al Valor Agregado (IVA) de 16 % a 14 % y actualmente a 12 %, así como la emisión del bolívar fuerte.

Una de las causas principales de la elevada inflación en el país, según algunos economistas, es la política del Estado de imprimir dinero inorgánico en la economía del que correspondería según la producción del país: hay mucho más dinero líquido persiguiendo muy pocos productos.

El viernes 8 de febrero de 2013 el gobierno del entonces vicepresidente Nicolás Maduro informa las medidas económicas y cambiarías que entrarían en vigencia en Venezuela el 13 de febrero. El ministro de Finanzas, Jorge Giordani, y el presidente del BCV, Nelson Merentes, informaron que el precio del dólar que distribuía CADIVI se devaluaría de 4,30 bolívares hasta 6,30 bolívares. Esto correspondía a un 46,5 % de diferencia entre una cotización y la otra. Según el gobierno esto permitiría incrementar los recursos con los que cuenta el estado para seguir impulsando el crecimiento de la economía. En enero de 2015, La medidora de riesgo internacional Moody's le bajó la calificación a Venezuela de "CAA1" a "CAA3", lo que significa que la nación incrementa el riesgo de incumplimiento de pagos debido a la dependencia y devaluación del petróleo.

Para 2014 el gobierno realizó otra devaluación al comenzar a vender dólares a dos tasas diferentes: en 6,30 la tasa CADIVI (estudiantes, casos especiales, jubilaciones y pensiones, gastos consulares y diplomáticos, salud y alimentación) y el 11,30 la tasa SICAD (cupos para viajeros, las remesas familiares y las divisas para las líneas aéreas). El presidente Nicolás Maduro anunció la adhesión de CADIVI al Centro Nacional de Comercio Exterior a finales de 2014.

Aunque durante gran parte del 2014 el precio de la cesta petrolera venezolana se mantuvo en el promedio de 103 dólares el barril, la deuda externa de la República continuó creciendo velozmente y registró un salto de 8 % respecto a 2011 para ubicarse en 105 779 millones de dólares, de acuerdo con las estadísticas del BCV. Al cierre del 2014, el PIB registro una caída de 3,9 % durante tres trimestres consecutivos entrando en una nueva recesión, con un aumento exorbitante de la inflación que para diciembre de 2014 se encontraba en 64 % acumulado.

Para el 10 de abril de 2015, una nueva providencia del CENCOEX, restringe dólares para viajeros y designa que la banca pública (Banco de Venezuela, Banco del Tesoro o el Banco Bicentenario), serán los únicos operadores cambiarios de divisas.

Para julio de 2017, Kansei Le Car filial de Kansei Motors, empezó operaciones en Venezuela, está empresa ofrece servicios a la marca Peugeot.

El 22 de marzo de 2018, el presidente Maduro anunció que eliminará tres ceros a la moneda nacional, con un nuevo cono monetario.

La Economía de Venezuela históricamente ha estado orientada a las exportaciones del petróleo y sus derivados, y ha sido dependiente de las importaciones de importantes rubros, razón por la cual la cotización histórica del bolívar venezolano expresada en unidades de moneda local por dólar estadounidense ha sido clave en la toma de decisiones de los agentes económicos. Desde mediados del siglo XX se mantuvo la estabilidad y fiabilidad que había caracterizado al bolívar como signo monetario, cuya última cotización libre el 18 de febrero de 1983 fue de 4,30 bolívares por dólar. Desde entonces la devaluación constante del bolívar, complicaciones con el pago de la deuda externa, el acelerado deterioro del poder adquisitivo y la implantación de un control de cambio llamado "Régimen de Cambio Diferencial" (RECADI) —que funcionó entre el 28 de febrero de 1983 y el 10 de febrero de 1989 y que tuvo graves casos de corrupción durante el gobierno de Jaime Lusinchi— hicieron desaparecer la estabilidad cambiaria de la moneda venezolana.

El valor implícito o "valor de mercado negro" es lo que los venezolanos creen que el Bolívar Fuerte vale en comparación con el dólar estadounidense. En los primeros años de mandato de Chávez, sus programas sociales recién creados, requerían grandes inversiones a fin de realizar los cambios deseados en el país. El 5 de febrero de 2003, el gobierno creó CADIVI, un sistema de control de cambio encargado de los procedimientos de manejo de divisas. La razón de su creación fue controlar la fuga de capitales, estableciendo límites a los individuos y ofreciéndoles solamente una cantidad fijada de una moneda extranjera. Este límite en moneda extranjera condujo a la creación de una economía de mercado negro de divisas, debido a que los comerciantes venezolanos necesitaban un flujo confiable y constante de divisas extranjeras para adquirir los productos importados que el estado no conseguía suplir. El Banco Central de Venezuela comenzó a imprimir más bolívares para cubrir sus programas sociales, así que el bolívar continuó devaluándose para el ciudadano común y comerciantes, ya que el gobierno se quedaba con la mayoría de las divisas.

Desde enero de 2014, el tipo de cambio oficial es de 1 USD a 6,3 BsF. VEF, mientras que la tasa de cambio del mercado negro es sesenta veces mayor; esto se debe a que el valor real del bolívar está sobrevaluado para el comercio venezolano. Desde que algunos comerciantes sólo pueden recibir una cantidad fija de moneda extranjera de lo que necesitan para importar, por parte del gobierno, deben recurrir al mercado negro que a su vez aumenta los precios del comerciante para la venta al público. Las altas tasas en el mercado negro hacen que sea difícil para las empresas la compra de bienes necesarios ya que el gobierno a menudo obliga a estas empresas a hacer regulación de precios. Esto lleva a las empresas a vender sus productos con baja ganancia e incluso pérdida; por ejemplo, las franquicias venezolanas de McDonalds que ofrecen una comida de Big Mac por sólo 1 USD. Dado que las empresas obtienen beneficios bajos, esto lleva a la escasez, debido a que son incapaces de importar la cantidad necesaria de bienes que Venezuela necesita y depende para funcionar. La compañía de Venezuela más grande de producción de alimentos, Empresas Polar, declaró que era posible que necesiten suspender parte de la producción durante casi todo el año de 2015, ya que les deben a los proveedores extranjeros 463 millones de dólares USD. El último informe de escasez en Venezuela mostró que 22,4 % de los productos necesarios no se encontraban en stock. Este fue el último informe del gobierno debido a que el banco central ya no publica el índice de escasez. Esto ha llevado especulación, y de esa forma un mecanismo del gobierno para ocultar su incapacidad para controlar la economía que podría crear dudas futuras sobre la veracidad de los datos económicos suministrados por el gobierno.

A partir de 2013 la economía venezolana ha sufrido una caída de sus índices macroeconómicos, dando paso a un período de recesión y crisis.
El origen de esta caída es una combinación de problemas estructurales propios en la economía venezolana y la fuerte influencia externa de la crisis financiera mundial con la caída de los precios del petróleo.
En 2014, el PIB tuvo una variación -3,9 %, en 2015 de -5.7 %. A finales de 2015 se vivió una ligera mejoría con una subida del 0,1 %, pero de nuevo en 2016 volvió a descender un 1,6 %. Con especial dureza la Crisis en Venezuela se ha manifestado, en un fuerte aumento del desempleo, con una tasa de desempleo del 14 % en el primer trimestre de 2015 según los datos del INE. Dañado el motor de la economía antes de la crisis enmarcado por el control de cambio (CADIVI), y una fuerte acumulación de deuda, se hace patente la debilidad estructural del modelo económico venezolano de los últimos años.

Además de todo, la inflación ha sido un hecho importante en este contexto, la cual en el 2014 llegó hasta 68.5 %. Esa cifra es una de las más altas que se han registrado en la historia económica del país y fue la más elevada en el mundo durante el 2013. Asimismo la inflación del año 2015 fue de 180.9 %, y para el 2016 el FMI pronosticó una inflación superior a 700 %.

La caída de los precios del petróleo ha sido una de las causas de la crisis económica. El Banco Central de Venezuela anuncia la caída de las Reservas Internacionales ubicándose en 13 501 millones de dólares. Tras la cancelación de la deuda externa en Bonos Global 2016 por 1 543 millones de dólares.

Para noviembre de 2017, el gobierno de Nicolás Maduro, llamó a refinanciar la deuda externa.

Uno de los fenómenos más particulares en la última década ha sido la escasez de productos de consumo diario, en particular de aquellos con precios regulados, como la leche, diversos tipos de carne, el aceite y otros. Los gobiernos de Chávez y Maduro han relacionado dicha escasez en primer lugar a un aumento en el consumo, que no puede ser rápidamente satisfecho por la producción, y cada vez más al acaparamiento y el contrabando. Los economistas en general consideran que el control de precios a un valor por debajo de los costes, el exceso de liquidez monetaria ante un sistema de poca producción nacional y la expropiación por parte del Estado de cerca de 1200 empresas privadas que abastecían el mercado nacional son las causas principales de tal escasez. Consideran que la economía de Venezuela padece los efectos típicos de una economía de escasez. El factor de contrabando es admitido por ambos grupos: varios productos son mucho más baratos en Venezuela que en Colombia, Brasil y otros países limítrofes. Para diciembre de 2013 el grado de escasez según el BCV indicaba que había una escasez de 22 %. Esto quiere decir que un 22 % de los productos que el consumidor buscaba en los negocios no se encontraba.

Para una mejora económica, en febrero de 2015, es incorporado un nuevo sistema de cambio que se ha denominado Sistema Marginal de Divisas (SIMADI). Al empezar a cotizar el día 13, el precio del dólar se ubicó a 170 bolívares. En marzo del 2016, se elaboran dos nuevos sistemas de divisas, Tipo de Cambio Protegido (DIPRO) y Tipo de Cambio Complementario (DICOM), el primero a un costo de 10 bs. por dólar y el otro empezó en 206 bs., el anuncio lo dio a conocer Miguel Pérez Abad. El 23 de mayo de 2017 el dólar DICOM estaba en 727,97 bolívares. Este día entró en vigor un nuevo sistema DICOM. La primera subasta fue convocada el 25 de mayo con una banda de posibles ofertas para la compra de dólares entre 1800 y 2000 Bs, equivalente a una devaluación de por lo menos 60 %.

Después de los anuncios ofrecidos por el presidente Nicolás Maduro, a principios de noviembre de 2017, como el aumento salarial y la pues en circulación del billete de 100 000 bolívares; economistas y medios de comunicación afirmaron que Venezuela, ha iniciado una hiperinflación, tras arrojar el pasado mes de octubre una inflación del 50,6 %. Analistas del tema y medios de comunicación afirman, que para frenar la hiperinflación, primero deben detener la impresión de billetes, unificar el tipo de cambio, aumentar la producción nacional e importación bienes de consumo que sean necesarios, además de suprimir los controles de precios.

La economía de Venezuela se centra en la exportación de petróleo. La dependencia del petróleo ha aumentado en los últimos años. Mientras que en 1999 las exportaciones de bienes y servicios petroleros representaban el 76 % de las exportaciones, en 2005 el porcentaje había pasado a 86  % y en 2012 se elevaba al 96 %.
El porcentaje de las exportaciones petroleras en las exportaciones totales había sido de 91,9 % en 1958, 92,8 % en 1968, 93,6 % en 1978 y 81,1 % en 1988.
A finales de 2013 Venezuela exportaba unos 1,7 millones de barriles diarios de petróleo.

Las cifras de producción real y exportación de petróleo han sido objeto de mucha polémica. El presidente de PDVSA, Rafael Ramírez, declaró en 2011 que Venezuela aumentaría su producción de petróleo y produciría unos 4,02 millones de barriles de petróleo para 2012. En 2012, Ramírez declaró que Venezuela produciría 4 millones de barriles para 2014. En diciembre de 2013 el presidente de PDVSA dijo que la producción petrolera en 2014 estaría en 3 millones 11 mil barriles de petróleo.

La compañía estatal PDVSA es la encargada de administrar los recursos petroleros. En 1998 trabajaban en esta empresa unas 36 000 personas, las cuales producían más 3.48 millones de barriles de petróleo diarios. En 2011 PDVSA contaba con 121 187 trabajadores, de los cuales 104 187 trabajaban en la producción de petróleo produciendo 2.76 millones de barriles de petróleo diarios, una baja significativa de la productividad.

En 2012 PDVSA produjo 2,91 millones de barriles de crudo diariamente. En 2013 esta cifra fue de 2,89 millones de barriles. De estos se exportan unos 2,42 millones de barriles diarios.

En 1998 el país exportaba bienes no petroleros por un valor de 5 mil 529 millones de dólares mientras que en 2012 la cifra era de tan solo 3 mil 771 millones de dólares.

En 2012 Venezuela importó bienes y servicios (CIF) por un valor total de 65 360 000 000 de dólares. En 1998 el total de importaciones de bienes y servicios se elevaba a 15 492 000 000 de dólares.

El país ha sido tradicionalmente importador de gran cantidad de productos manufacturados, pero en los últimos años esta tendencia se ha acentuado. En 2012-2013 los renglones más importantes de importación eran aquellos de maquinarias y repuestos para apartados y maquinarias mecánicos y eléctricos o electrónicos.

Según el ministro de Agricultura Yván Gil, Venezuela importaba un 50 % de los alimentos que consumía en 2013. Venezuela era en 2008 el principal importador mundial de leche en polvo.

El país actualmente importa productos que tradicionalmente exportara, como el café, el arroz y el maíz. En 2012 se importaron dichos productos por un monto aproximado de 1028 millones de dólares. También se han venido importando otros productos típicos de Venezuela como el azúcar.

Venezuela pasó a ocupar el puesto número 13 de los países que más gastaron en importaciones de armamento en 2012. Ocupaba el puesto 46 en 2002. El presidente Chávez había justificado estos gastos con el argumento de que era necesario reemplazar armamento obsoleto. Venezuela se ha convertido en el principal importador de armas en Sudamérica, por encima de Brasil. El principal vendedor de armas a Venezuela fue Rusia, con un 66 % de las importaciones, seguido de España, con un 12 % y de China, con un 6 %.

En Venezuela la minería no es muy alta, así que hay poca exportación en esta área.

Las reservas de hierro de Venezuela son unas de las más importantes en el mundo. Aun así, la extracción de hierro ha venido cayendo en los últimos años. SIDOR ha sido desde hace décadas la empresa estatal encargada de gerenciar la extracción y el procesamiento de este metal. En 1997 la empresa fue privatizada durante la ola de privatizaciones generadas por la falta de ingresos petroleros que permitiesen financiar la inversión en diversas industrias que se habían vuelto ineficientes. La empresa llegó a aumentar su producción hasta el 2007. A comienzos de 2008 fue nuevamente estatizada. A partir de ese momento ha vuelto a caer la producción. En 2013 la empresa producía tan solo un 45 % de su capacidad instalada.

Venezuela es uno de los principales países extractores de bauxita, la principal mena para extraer aluminio.
Como en el caso del hierro y del acero, desde la estatización de Alcasa ha habido una caída en la producción.
Tan solo entre 2012 y 2013 la producción disminuyó en un 28%.
Al mismo tiempo, la cantidad de trabajadores aumentó en 18 %: pasó de 8606 a 10 169 trabajadores.

Actualmente hay dos federaciones rivales en el área de la producción ganadera: Fedenaga, la federación tradicional, y Fegaven, que está aliada al gobierno.

Los datos estadísticos sobre la producción agrícola en Venezuela son altamente disputados, con cifras bastante divergentes entre lo que dicen empresas privadas y el gobierno y asociaciones cercanas al gobierno.
Venezuela producía 1410 millones de litros de leche en 1998 según estudios de la Universidad de Los Andes.

Según el gobierno, en 2010 se producían unas 4 697 784 toneladas de carne en el país o lo que equivaldría a un 80 % del consumo nacional. El representante de Fedenaga calculaba para comienzos de 2013 que en realidad Venezuela estaría importando un 50 % de la carne que consumía.

Según Fevearroz, Venezuela producía 699 toneladas de arroz para 1998 y 1080 en 2008. La mayor parte de la producción se concentraba en Guárico y Portuguesa (para un 93 % de la producción).

Venezuela se abastecía a sí misma en el consumo de maíz hasta 2007. En 2012 se obtuvieron 772 853 toneladas de maíz, lo que equivalió a un 55 % de la demanda.

Venezuela posee una gran cantidad de paisajes con potencial turístico, pero la industria turística está mucho menos desarrollada que en otros países de América. En 1998, 685 000 turistas extranjeros visitaron el país. En 2011, fueron 595 000 los turistas que visitaron el país, en 2015 fueron 789 000. Regiones como Guatemala, Aruba y El Salvador, que en 1998 recibían menos visitantes extranjeros que Venezuela, en 2015 recibían mucho más. Entre las causas que se discuten por el limitado crecimiento del turismo se hallan la inseguridad, y una moneda sobrevaluada.




</doc>
<doc id="4670" url="https://es.wikipedia.org/wiki?curid=4670" title="SQL">
SQL

SQL (por sus siglas en inglés Structured Query Language; en español lenguaje de consulta estructurada) es un lenguaje específico del dominio que da acceso a un sistema de gestión de bases de datos relacionales que permite especificar diversos tipos de operaciones en ellos. Una de sus características es el manejo del álgebra y el cálculo relacional que permiten efectuar consultas con el fin de recuperar, de forma sencilla, información de bases de datos, así como hacer cambios en ellas.

Originalmente basado en el álgebra relacional y en el cálculo relacional, SQL consiste en un lenguaje de definición de datos, un lenguaje de manipulación de datos y un lenguaje de control de datos. El alcance de SQL incluye la inserción de datos, consultas, actualizaciones y borrado, la creación y modificación de esquemas y el control de acceso a los datos. También el SQL a veces se describe como un lenguaje declarativo, también incluye elementos procesales.

SQL fue uno de los primeros lenguajes comerciales para el modelo relacional de Edgar Frank Codd como se describió en su papel de 1970 "El modelo relacional de datos para grandes bancos de datos compartidos". A pesar de no adherirse totalmente al modelo relacional descrito por Codd, pasó a ser el lenguaje de base de datos más usado.

SQL pasó a ser el estándar del Instituto Nacional Estadounidense de Estándares (ANSI) en 1986 y de la Organización Internacional de Normalización (ISO) en 1987. Desde entonces, el estándar ha sido revisado para incluir más características. A pesar de la existencia de ambos estándares, la mayoría de los códigos SQL no son completamente portables entre sistemas de bases de datos diferentes sin ajustes.

Los orígenes de SQL están ligados a las bases de datos de las pc o móvil aun a los de las bases de datos relacionales. En 1970 E. F. Codd propone el modelo relacional y asociado a este un sublenguaje de acceso a los datos basado en el cálculo de predicados. Basándose en estas ideas, los laboratorios de IBM definieron el lenguaje SEQUEL (Structured English Query Language) que más tarde fue ampliamente implementado por el sistema de gestión de bases de datos (SGBD) experimental System R, desarrollado en 1977 también por IBM. Sin embargo, fue Oracle quien lo introdujo por primera vez en 1979 en un producto comercial.

El SEQUEL terminó siendo el predecesor de SQL, que es una versión evolucionada del primero. SQL pasa a ser el lenguaje por excelencia de los diversos sistemas de gestión de bases de datos relacionales surgidos en los años siguientes y fue por fin estandarizado en 1986 por el ANSI, dando lugar a la primera versión estándar de este lenguaje, "SQL-86" o "SQL1". Al año siguiente este estándar es también adoptado por ISO.

Sin embargo, este primer estándar no cubría todas las necesidades de los desarrolladores e incluía funcionalidades de definición de almacenamiento que se consideró suprimirlas. Así que, en 1992, se lanzó un nuevo estándar ampliado y revisado de SQL llamado "SQL-92" o "SQL2".

En la actualidad SQL es el estándar "de facto" de la inmensa mayoría de los SGBD comerciales. Y, aunque la diversidad de añadidos particulares que incluyen las distintas implementaciones comerciales del lenguaje es amplia, el soporte al estándar SQL-92 es general y muy amplio.

El ANSI SQL sufrió varias revisiones y agregados a lo largo del tiempo:

SQL es un lenguaje de acceso a bases de datos que explota la flexibilidad y potencia de los sistemas relacionales y permite así gran variedad de operaciones.

Es un lenguaje declarativo de "alto nivel" o "de no procedimiento" que, gracias a su fuerte base teórica y su orientación al manejo de conjuntos de registros —y no a registros individuales— permite una alta productividad en codificación y la orientación a objetos. De esta forma, una sola sentencia puede equivaler a uno o más programas que se utilizarían en un lenguaje de bajo nivel orientado a registros.
SQL también tiene las siguientes características:


Algunos de los tipos de datos básicos de SQL son:


Como ya se dijo antes, y suele ser común en los lenguajes de acceso a bases de datos de alto nivel, SQL es un lenguaje declarativo. O sea, que especifica qué es lo que se quiere y no cómo conseguirlo, por lo que una sentencia no establece explícitamente un orden de ejecución.

El orden de ejecución interno de una sentencia puede afectar seriamente a la eficiencia del SGBD, por lo que se hace necesario que éste lleve a cabo una optimización antes de su ejecución. Muchas veces, el uso de índices acelera una instrucción de consulta, pero ralentiza la actualización de los datos. Dependiendo del uso de la aplicación, se priorizará el acceso indexado o una rápida actualización de la información. La optimización difiere sensiblemente en cada motor de base de datos y depende de muchos factores.

Existe una ampliación de SQL conocida como FSQL (Fuzzy SQL, SQL difuso) que permite el acceso a bases de datos difusas, usando la lógica difusa. Este lenguaje ha sido implementado a nivel experimental y está evolucionando rápidamente.

El lenguaje de definición de datos (en inglés "Data Definition Language", o "DDL"), es el que se encarga de la modificación de la estructura de los objetos de la base de datos. Incluye órdenes para modificar, borrar o definir las tablas en las que se almacenan los datos de la base de datos. Existen cuatro operaciones básicas: CREATE, ALTER, DROP y TRUNCATE.

Este comando permite crear objetos de datos, como nuevas bases de datos, tablas, vistas y procedimientos almacenados.

Este comando permite modificar la estructura de una tabla u objeto. Se pueden agregar/quitar campos a una tabla, modificar el tipo de un campo, agregar/quitar índices a una tabla, modificar un trigger, etc.

Este comando elimina un objeto de la base de datos. Puede ser una tabla, vista, índice, trigger, función, procedimiento o cualquier objeto que el motor de la base de datos soporte. Se puede combinar con la sentencia ALTER.

Este comando trunca todo el contenido de una tabla. La ventaja sobre el comando DROP, es que si se quiere borrar todo el contenido de la tabla, es mucho más rápido, especialmente si la tabla es muy grande. La desventaja es que TRUNCATE sólo sirve cuando se quiere eliminar absolutamente todos los registros, ya que no se permite la cláusula WHERE. Si bien, en un principio, esta sentencia parecería ser DML (Lenguaje de Manipulación de Datos), es en realidad una DDL, ya que internamente, el comando TRUNCATE borra la tabla y la vuelve a crear y no ejecuta ninguna transacción.

Un lenguaje de manipulación de datos ("Data Manipulation Language", o "DML" en inglés) es un lenguaje proporcionado por el sistema de gestión de base de datos que permite a los usuarios llevar a cabo las tareas de consulta o manipulación de los datos, organizados por el modelo de datos adecuado.

El lenguaje de manipulación de datos más popular hoy día es SQL, usado para recuperar y manipular datos en una base de datos relacional.

La sentencia SELECT nos permite consultar los datos almacenados en una tabla de la base de datos.

 codice_1codice_2
Ejemplo:

Para formular una consulta a la tabla Coches y recuperar los campos matricula, marca, modelo, color, numero_kilometros, num_plazas debemos ejecutar la siguiente consulta. Los datos serán devueltos ordenados por marca y por modelo en orden ascendente, de menor a mayor. La palabra clave FROM indica que los datos serán recuperados de la tabla Coches.

Ejemplo de Consulta simplificada a través de un comodín de Campos (*):

El uso del asterisco indica que queremos que la consulta devuelva todos los campos que existen en la tabla y los datos serán devueltos ordenados por marca y por modelo.

La cláusula" WHERE" es la instrucción que nos permite filtrar el resultado de una sentencia SELECT. Habitualmente no deseamos obtener toda la información existente en la tabla, sino que queremos obtener sólo la información que nos resulte útil en ese momento. La cláusula WHERE filtra los datos antes de ser devueltos por la consulta. Cuando en la Cláusula WHERE queremos incluir un tipo texto, debemos incluir el valor entre comillas simples.

Ejemplos:

En nuestro ejemplo, se desea consultar un coche en concreto, para esto se agregó una cláusula WHERE. Esta cláusula especifica una o varias condiciones que deben cumplirse para que la sentencia SELECT devuelva los datos. En este caso la consulta devolverá sólo los datos del coche con matrícula para que la consulta devuelva sólo los datos del coche con matrícula codice_5o bien la matrícula codice_6 . Se puede utilizar la cláusula WHERE solamente, ó en combinación con tantas condiciones como queramos.

Una Condición WHERE puede ser negada a través del Operador Lógico NOT. La Siguiente consulta devolverá todos los datos de la tabla Coches, menos el que tenga la Matrícula codice_8 .

La Siguiente consulta utiliza la condicional DISTINCT, la cual nos devolverá todos los valores distintos formados por los Campos "Marca y Modelo". de la tabla "coches".

La cláusula" ORDER BY" es la instrucción que nos permite especificar el orden en el que serán devueltos los datos. Podemos especificar la ordenación ascendente o descendente a través de las palabras clave ASC y DESC. La ordenación depende del tipo de datos que este definido en la columna, de forma que un campo numérico será ordenado como tal, y un alfanumérico se ordenará de la A a la Z, aunque su contenido sea numérico. El valor predeterminado es ASC si no se especifica al hacer la consulta.

Ejemplos:

SELECT matricula, <br> marca, <br> modelo, <br> color, <br> numero_kilometros, <br> num_plazas <br>
'FROM' coches<br>
'ORDER BY' marca 'ASC', modelo 'DESC';
Este ejemplo, selecciona todos los campos matricula, marca, modelo, color, numero_kilometros y num_plazas de la tabla coches, ordenándolos por los campos marca y modelo, marca en forma ascendente y modelo en forma descendente.

Este ejemplo, selecciona todos los campos matrícula, marca, modelo, color, numero_kilometros y num_plazas de la tabla coches, ordenándolos por el campo "marca", ya que aparece en segundo lugar dentro de la lista de campos que componen la SELECT.

Una subconsulta es una sentencia SELECT que está embebida en una cláusula de otra sentencia SQL.

Las subconsultas pueden resultar útiles si necesitas seleccionar filas de una tabla con una condición que depende de los datos de la propia tabla o de otra tabla.

La subconsulta (consulta interna), se ejecuta antes de la consulta principal; el resultado de la subconsulta es utilizado por la consulta principal (consulta externa).En este ejemplo, se seleccionan las matriculas y los modelos de los coches cuyas multas superan los u$s 100.

Una sentencia "INSERT" de SQL agrega uno o más registros a una (y sólo una) tabla en una base de datos relacional.

Las cantidades de columnas y valores deben ser iguales. Si una columna no se especifica, le será asignado el valor por omisión. Los valores especificados (o implícitos) por la sentencia codice_10 deberán satisfacer todas las restricciones aplicables. Si ocurre un error de sintaxis o si alguna de las restricciones es violada, no se agrega la fila y se devuelve un error.

Cuando se especifican todos los valores de una tabla, se puede utilizar la sentencia acortada:

Ejemplo (asumiendo que 'nombre' y 'número' son las únicas columnas de la tabla 'agenda_telefonica'):

Una característica de SQL (desde SQL-92) es el uso de "constructores de filas" para insertar múltiples filas a la vez, con una sola sentencia SQL:

Esta característica es soportada por DB2, PostgreSQL (desde la versión 8.2), MySQL, y H2.

Ejemplo (asumiendo que 'nombre' y 'número' son las únicas columnas en la tabla 'agenda_telefonica'):

Que podía haber sido realizado por las sentencias

Notar que las sentencias separadas pueden tener semántica diferente (especialmente con respecto a los triggers), y puede tener diferente rendimiento que la sentencia de inserción múltiple.

Para insertar varias filas en MS SQL puede utilizar esa construcción:

Tenga en cuenta que no se trata de una sentencia SQL válida de acuerdo con el estándar SQL (), debido a la cláusula subselect incompleta.

Para hacer lo mismo en Oracle se usa la Tabla DUAL, siempre que se trate de solo una simple fila:

Una implementación conforme al estándar de esta lógica se muestra el siguiente ejemplo, o como se muestra arriba (no aplica en Oracle):

Un INSERT también puede utilizarse para recuperar datos de otros, modificarla si es necesario e insertarla directamente en la tabla. Todo esto se hace en una sola sentencia SQL que no implica ningún procesamiento intermedio en la aplicación cliente. Un SUBSELECT se utiliza en lugar de la cláusula VALUES. El SUBSELECT puede contener JOIN, llamadas a funciones, y puede incluso consultar en la misma TABLA los datos que se inserta. Lógicamente, el SELECT se evalúa antes que la operación INSERT esté iniciada. Un ejemplo se da a continuación.

Una variación es necesaria cuando algunos de los datos de la tabla fuente se está insertando en la nueva tabla, pero no todo el registro. (O cuando los esquemas de las tablas no son iguales.)

El SELECT produce una tabla (temporal), y el esquema de la tabla temporal debe coincidir con el esquema de la tabla donde los datos son insertados.

Una sentencia "UPDATE" de SQL es utilizada para modificar los valores de un conjunto de registros existentes en una tabla.

Una sentencia "DELETE" de SQL borra uno o más registros existentes en una tabla.

Los diseñadores de base de datos que usan una clave suplente como la clave principal para cada tabla, se ejecutará en el ocasional escenario en el que es necesario recuperar automáticamente la base de datos, generando una clave primaria de una sentencia SQL INSERT para su uso en otras sentencias SQL. La mayoría de los sistemas no permiten sentencias SQL INSERT para retornar fila de datos. Por lo tanto, se hace necesario aplicar una solución en tales escenarios.

Implementaciones comunes incluyen:



Los disparadores, también conocidos como desencadenantes ("triggers" en inglés) son definidos sobre la tabla en la que opera la sentencia INSERT, y son evaluados en el contexto de la operación. Los desencadenantes BEFORE INSERT permiten la modificación de los valores que se insertarán en la tabla. Los desencadenantes AFTER INSERT no puede modificar los datos de ahora en adelante, pero se puede utilizar para iniciar acciones en otras tablas, por ejemplo para aplicar mecanismos de auditoría Excel.

Los sistemas de gestión de base de datos con soporte SQL más utilizados son, por orden alfabético:


El lenguaje de consultas de los diferentes sistemas de gestión de bases de datos son incompatibles entre ellos y no necesariamente siguen completamente el estándar. En particular, la sintaxis de fecha y tiempo, la concatenación de cadenas, nulas, y la comparación de textos en cuanto al tratamiento de mayúsculas y minúsculas varían de un proveedor a otro. Una excepción particular es PostgreSQL, que se esfuerza por lograr el cumplimiento del estándar.

Las implementaciones populares de SQL omiten comúnmente soporte para funciones básicas de SQL estándar, como la de los tipos de dato codice_11 o codice_12. Es el caso del manejador de bases de datos de Oracle (cuyo tipo codice_11 se comporta como codice_14, y carece de un tipo codice_12) y MS SQL Server (antes de la versión de 2008). Como resultado, el código SQL rara vez puede ser portado entre los sistemas de base de datos sin modificaciones.

Hay varias razones para esta falta de portabilidad entre sistemas de bases de datos:


El estándar ODBC (Open Database Connectivity) permite acceder a la información desde cualquier aplicación independientemente del sistema de gestión de base de datos (DBMS) en el que esté almacenada la información, desacoplando así la aplicación de la base de datos.



</doc>
<doc id="4678" url="https://es.wikipedia.org/wiki?curid=4678" title="Inducción">
Inducción

El término inducción hace referencia a varios artículos:






</doc>
<doc id="4679" url="https://es.wikipedia.org/wiki?curid=4679" title="Numeración en base constante">
Numeración en base constante

Sea b un entero superior a uno. Escribir un entero n en la base b significa descomponerlo en las potencias de b, es decir determinar los coeficientes ( también llamados cifras) a tales que:


Bien es sabido que el sistema vigente por doquier es el decimal; es decir que se emplea la base diez: b = 10. La escritura de cualquier entero utiliza las potencias de 10 así:

1492 = 1000 + 400 + 90 + 2 = 1×1000 + 4×100 + 9×10 + 2×1 = 1x10 + 4x10 + 9x10 + 2x10 .

Para pasar de las unidades a las decenas, y de las decenas a las centenas, se multiplica por el mismo número, aquí diez, por eso se dice que el sistema es la numeración en base constante.

Se ha empleado la numeración en base constante, con otras bases que diez, principalmente las bases cinco (los Aztecas) y veinte. Quedan rastros del empleo de la base veinte en algunos idiomas occidentales, como el francés ("ochenta" se dice "quatre-vingts" es decir "cuatro veintes", ya que la palabra "huitante" se emplea en Suiza y Bélgica), en danés (para los números 50, 60 y 70), en inglés ("score", una veintena, "two-score", "three-score", "four scores" para "ochenta"), y en latín (donde "18" no se decía "10 + 8" sino "20 - 2").

Se cree que la elección de las bases 5, 10 ó 20 se debe a causas biológicas, pues el hombre siempre contó con los dedos (hasta de los pies).

Por la mitad del siglo XX, se descubrió un interés descomunal por la base dos o "base binaria", pues tiene la ventaja de necesitar solamente dos cifras, 0 y 1. Esto debido al desarrollo del cálculo electrónico y el procesamiento de datos. El sistema encaja bien con los dos estados de un circuito electrónico: sin corriente o con corriente. El sistema binario puro tiene la ventaja de ser sencillo, pero su principal inconveniente reside en que la expresión de un número en base 2 es muy extensa.

Reagrupando las cifras por cuatro o por cinco se obtiene la base hexadecimal (base dieciséis) y la base treinta y dos. Cuando se trabaja en una base superior a diez, se tiene que inventar nuevas cifras, para notar los números que van de diez a b-1 (b sigue siendo la base). Por ejemplo, cuando se emplea la base "doce", se añade las cifras alfa y beta para diez y once. Para la base hexadecimal, la costumbre es utilizar las letras mayúsculas A, B, ... F.

Han existido históricamente numeraciones en base variable, como la de los Sumerios, que empleaban una mezcla de base 60 y de base 10. Han legado al mundo actual el que una hora se divide en sesenta minutos, y no en diez o cien, la semana de siete días, la docena y el que el círculo se divide en 360 = 6×60 grados = 12x30 grados (en el Zodíaco), y no en cien o cuatrocientos (que también existe, pero no es tan común).

La desventaja de aquel sistema, era que multiplicar por 10 o 60 no resultaba fácil, pues no se puede sencillamente mover las cifras (a la izquierda) y añadir una casilla vacía (un cero, que no se había inventado todavía) a la derecha.

Cuando mayor sea la base, más complicado es calcular en ella, pues se necesita aprender tablas (de multiplicación) más largas (con b productos). 

Cuando menor sea la base, más largos se vuelven la escritura de los números: por ejemplo, la escritura de un número en base binaria es ln 10/ ln 2 veces más larga que su escritura en base decimal, o sea 3,3 veces más, en promedio (la longitud es proporcional al inverso del logaritmo de la base).

La cuestión de saber qué base es la más práctica no tiene respuesta sencilla. Sin embargo, se puede afirmar que la base decimal no tiene nada de excepcional, y que es superada con creces por la base seis, que ofrece la ventaja de tener criterios de divisibilidad sencillos para dividir por 2, 3, 4, ... hasta once; mientras que en base decimal, el 7 no tiene criterio asequible.

Todo número real se puede escribir en "base b", es decir, descomponer en las potencias de b, las b, con k entero positivo o negativo.
Por ejemplo, en base diez:

Si la descomposición necesita una infinidad de cifras, se dice que el número no es decimal. 1/3 = 0,333333333333... no es decimal, pero en base tres, un tercio es 1/10 = 0,1 que si lo es (habría que inventar una palabra como "triemal" para significar "decimal en base tres").
No hay unicidad de la escritura de un real en una base, como lo muestra la igualdad 1 = 0,999999999999... pero, si se decide que no se autoriza la sucesión infinita de dígitos "b-1" en base b, se demuestra que sí hay una única manera de escribir un real en base b



</doc>
<doc id="4680" url="https://es.wikipedia.org/wiki?curid=4680" title="E">
E

La e (en mayúscula E, nombre "e", plural "es" o "ees") es la quinta letra del alfabeto español y del alfabeto latino básico y su segunda vocal. Tiene dos formas para el plural: es o ees, siendo más recomendada la primera. 

Representa en español el sonido de una vocal media y anterior.

La "hê" semítica probablemente representó inicialmente una oración o figura humana que se llamaba ("hillul" festejar), y probablemente estaba basada en un jeroglífico egipcio similar que era pronunciado y utilizado en forma distinta. En semítico, la letra representaba (y en palabras extranjeras), en griego "hê" se convirtió en Εψιλον (Epsilon) con el valor . Los etruscos y romanos la empleaban de la misma forma. El uso en inglés puede ser distinto como consecuencia del "Great Vowel Shift", o sea (a partir de como en las palabras inglesas "me" o "bee"), mientras que en otras palabras, como por ejemplo "bed"; la pronunciación es similar al latín y otras lenguas en uso.

En español, antiguamente se usaba como conjunción copulativa, proveniente del latín "et". Actualmente se utiliza la semivocal "y" /i/, salvo cuando se encuentra antes del sonido /i/ formando diptongo con la sucesiva, para evitar el hiato. Aunque sí debe usarse "y" cuando comienza una frase empleándose de manera adverbial para expresar énfasis (por ejemplo ""¿Y Inés?"").
Ejemplos de palabras que empiezan con E: Elefante, Estambul, Estanco, Everest, Europa, Elisa, etc.
Se considera que es la letra que más se repite en los textos en español. También es la más frecuente en los idiomas checo, danés, neerlandés, inglés, francés, alemán, húngaro, latín, noruego y sueco.

En alfabeto fonético aeronáutico se le asigna la palabra Eco.
En código Morse es: codice_1

En Unicode la E mayúscula posee el código U+0045 y la e minúscula es U+0065.

El código ASCII para la E mayúscula es 69 y para la e minúscula es 101; o en sistema binario 01000101 y 01100101, respectivamente.

El código EBCDIC para la E mayúscula es 197 y para la e minúscula es 133.

Las referencias numéricas en HTML y XML son "E" y "e" para la mayúscula y minúscula, respectivamente.





</doc>
<doc id="4682" url="https://es.wikipedia.org/wiki?curid=4682" title="Función exponencial">
Función exponencial

La función exponencial, es conocida formalmente como la función real e, donde "e" es el número de Euler, aproximadamente 2.71828.; esta función tiene por dominio de definición el conjunto de los números reales, y tiene la particularidad de que su derivada es la misma función. Se denota equivalentemente como "f"("x")=e o exp("x"), donde e es la base de los logaritmos naturales y corresponde a la función inversa del logaritmo natural.

En términos mucho más generales, una función real "E"("x") se dice que es del tipo exponencial en base "a" si tiene la forma

siendo "a", "K" ∈ R números reales, con "a" > 0, "a" ≠ 1. Así pues, se obtiene un abanico de exponenciales, todas ellas similares, que dependen de la base "a" que utilicen.

La función exponencial e puede ser definida de diversas maneras equivalentes entre sí, como una serie infinita o bien como un límite de una sucesión. En particular puede ser definida como una serie de potencias:

o como el límite de la sucesión:

En análisis matemático, cuando previamente se ha definido la función logaritmo natural como la integral, respecto a la variable "t", de la función 1/"t" desde "t"=1 hasta "t"="y", y conociendo que la función logaritmo natural es creciente continua, se define "y" = e como la solución de la siguiente ecuación:

La función exponencial (y exponenciales en base distinta a "e") satisfacen las siguientes propiedades generales.






La importancia de las funciones exponenciales en matemática y ciencias radica principalmente de las propiedades de su derivada. En particular,

Es decir, "e" es su propia derivada. Es la única función con esa propiedad (sin tomar en cuenta la multiplicación de la función exponencial por una constante).
Otras formas de expresar lo anterior:

Si la base de la función exponencial es cualquier número real "a" mayor que 0, entonces su derivada se puede generalizar así:

donde la función ln("a") es el logaritmo natural de "a". En el caso particular de "a" = "e" resulta que ln("e") = 1 y por lo tanto formula_11.

Como en el caso real, la función exponencial puede ser definida como una función holomorfa en el plano complejo de diferentes maneras. Algunas de ellas son simples extensiones de las fórmulas que se utilizan para definirla en el dominio de los números reales. Específicamente, la forma más usual de definirla para el dominio de los números complejos es mediante la serie de potencias, donde el valor real "x" se sustituye por la variable compleja "z":

para valores imaginarios puros se cumple la identidad

en el que un caso particular es la identidad de Euler, conector de números tan importanes como el uno, el cero, e, número pi y la unidad imaginaria.

Usando la identidad anterior, donde ahora "z"="x"+"y"i, con "x" e "y" números reales, se obtiene una definición equivalente a la primera,

ecuación que muestra que esta función, además de ser holomorfa, es periódica, con un periodo para la parte imaginaria de formula_15.
Si se toma como base el número complejo "a" diferente de "e", y como variable el exponente "z", se tiene que la función exponencial general "w" = f("z")=formula_16, se define como: :
Es una familia de funciones unívocas, no ligadas entre sí, que se distinguen por los factores exp(2kπi"z"), siendo "k" cualquier número entero. 





</doc>
<doc id="4684" url="https://es.wikipedia.org/wiki?curid=4684" title="23 de enero">
23 de enero

El 23 de enero es el 23.º (vigesimotercer) día del año en el calendario gregoriano. Quedan 342 días para finalizar el año y 343 en años bisiestos.

















</doc>
<doc id="4686" url="https://es.wikipedia.org/wiki?curid=4686" title="24 de enero">
24 de enero

El 24 de enero es el vigesimocuarto día del año en el calendario gregoriano. Quedan 341 días para finalizar el año y 342 en los años bisiestos.















</doc>
<doc id="4687" url="https://es.wikipedia.org/wiki?curid=4687" title="26 de enero">
26 de enero

El 26 de enero es el 26.º (vigesimosexto) día del año en el calendario gregoriano. Quedan 339 días para finalizar el año y 340 en los años bisiestos.








</doc>
<doc id="4689" url="https://es.wikipedia.org/wiki?curid=4689" title="Ignacio Domeyko">
Ignacio Domeyko

Ignacy Domeyko Ancuta (; Niedźwiadka Wielka, Imperio ruso, - Santiago, Chile, ) fue un científico polaco con nacionalidad chilena (su placa se puede encontrar en la Calle Didzioji gatvè). Chile le concedió la nacionalidad por gracia en 1848.

Nació el 31 de julio de 1802 en la localidad de (en bielorruso: "Мядзведка", Miadzviedka), en ese entonces territorio polaco-lituano que recientemente había pasado a dominio del Imperio ruso. En la actualidad, el pueblo forma parte administrativamente del raión de Kareličy, Goradnia, Bielorrusia.

Perteneciente a la antigua nobleza polaca, Domeyko se consideró siempre polaco. Estudió en la Universidad de Vilna. Tuvo que exiliarse de su país tras la derrota de los patriotas polacos y lituanos en la insurrección de 1831 en contra de la dominación rusa. En París estudió en La Sorbona, el Colegio de Francia, el Jardín Botánico y la Escuela de Minas. En 1838 llega a Chile contratado por las autoridades de la provincia de Coquimbo para comenzar la enseñanza de mineralogía y química en el liceo San Bartolomé de La Serena, institución que también financia su viaje, instrumentos, materiales y colecciones, donde posteriormente revoluciona los métodos de enseñanza.

Entre 1840 y 1846 realizó viajes por gran parte del país. En estos viajes, describió la geología de extensas zonas. En 1847 fue contratado como profesor del Instituto Nacional de Chile, más tarde se le concedió la nacionalidad por gracia y contrajo matrimonio con una joven chilena, Enriqueta Sotomayor, con quien tuvo tres hijos.

Dándose cuenta de la enorme pero casi inexplorada riqueza minera de Chile impulsó presionando fuertemente a las autoridades chilenas para que se creasen las Escuelas de Minas de La Serena y Copiapó respectivamente; en la primera Domeyko se encargó personalmente de crearla, dirigirla y hacer clases, en tanto que en la escuela copiapina dirigió su creación, eligiendo con pinzas a sus académicos, varios de ellos egresados de la recién creada Universidad de Chile y la mayoría provenientes de Alemania y Francia, visitándola de vez en cuando para supervisarla.

Fue miembro del claustro académico de la Universidad de Chile y posteriormente fue electo rector de la misma. En tal cargo desarrolló una extensa labor, siendo la principal de ella, la separación de las funciones de superintendencia de educación que ejercía sobre el sistema desde su creación, traspasando tales responsabilidades al recién creado Ministerio de Educación. En 1879 el Congreso Nacional dictó una ley por la que se separaban las funciones del Instituto Nacional, encomendándosele a la Universidad el trabajo de convertirse desde una unidad exclusivamente académica a una de docencia.

No retornó a su patria natal hasta el viaje que hizo entre 1884 y 1889 a Siria otomana (actual Israel), la Ciudad del Vaticano, Polonia (Cracovia y Varsovia), Lituania y la actual Bielorrusia. De su país natal trajo un saco de tierra que puso en su patio. Aún es conservado por sus descendientes.

Falleció en Santiago el 23 de enero de 1889 por causas naturales, a los 87 años.






</doc>
<doc id="4691" url="https://es.wikipedia.org/wiki?curid=4691" title="27 de enero">
27 de enero

El 27 de enero es el 27.º (vigesimoséptimo) día del año en el calendario gregoriano. Quedan 338 días para finalizar el año y 339 en los años bisiestos.







</doc>
<doc id="4692" url="https://es.wikipedia.org/wiki?curid=4692" title="28 de enero">
28 de enero

El 28 de enero es el 28.º (vigesimoctavo) día del año en el calendario gregoriano. Quedan 337 días para finalizar el año y 338 en los años bisiestos.











</doc>
<doc id="4693" url="https://es.wikipedia.org/wiki?curid=4693" title="Juan Carlos I de España">
Juan Carlos I de España

Juan Carlos I de España (Roma, 5 de enero de 1938) fue rey de España desde el 22 de noviembre de 1975 hasta el 19 de junio de 2014, fecha de su abdicación y del acceso a la jefatura del Estado de su hijo Felipe VI. Ostenta de forma vitalicia el título de rey y es capitán general de las Fuerzas Armadas en la reserva, aunque no ejerce funciones constitucionales sino solo protocolares como miembro de la familia real.

Fue proclamado el 22 de noviembre de 1975, tras la muerte de Francisco Franco, de acuerdo con la Ley de Sucesión en la Jefatura del Estado de 1947. La Constitución española, ratificada por referéndum popular el 6 de diciembre de 1978 y promulgada el 27 de diciembre del mismo año, lo reconoce expresamente como rey de España y legítimo heredero de la dinastía histórica de Borbón, otorgándole la jefatura del Estado. La Carta Magna confiere a su dignidad el rango de símbolo de la unidad nacional. Anteriormente a su proclamación, había desempeñado funciones interinas en la jefatura del Estado durante la enfermedad de Franco.

A lo largo de su reinado, el rey gozó de un elevado apoyo popular en España, y en menor grado, en Iberoamérica. Sin embargo, en 2012 esta tendencia cambió de forma drástica y el apoyo se fue reduciendo hasta el punto de que, en abril de 2013, un 53 % de la población desaprobaba la forma en que desempeñaba sus funciones, frente al 42 % que lo aprobaba, si bien siguió manteniendo una valoración positiva superior al resto de instituciones del sistema político español. No obstante, tres meses después de este dato, la confianza ciudadana en España subió ocho puntos hasta situarse en el 50 % de aprobación.

El papel del rey en la Transición española y su intervención durante el intento de golpe de Estado de 1981, su apoyo a la unidad europea y su contribución a la hora de estrechar relaciones diplomáticas, han sido objeto de diversos homenajes, reconocimientos, premios y galardones internacionales como el Premio Carlomagno (1982), el Premio Félix Houphouët-Boigny para la Búsqueda de la Paz de la Unesco (1995), la «Medalla de la Democracia» de la Universidad Yeshiva (1997), el Premio «Estadista Mundial» de la Fundación Appeal of Conscience (1997) o el Premio Estatal de la Federación Rusa (2011), entre otros. Sobre su papel durante los primeros años de su reinado, la revista "Time" publicaría que el rey Juan Carlos surgió «como uno de los héroes más improbables e inspiradores de la libertad del siglo XX, desafiando un intento de golpe militar que buscaba subvertir a la joven democracia posfranquista de España».

El 2 de junio de 2014, anunció su abdicación de la Corona de España. El 19 de junio de 2014 le sucedió su hijo, Felipe, tras la aprobación de la Ley Orgánica 3/2014, de 18 de junio, tal y como establece el artículo 57.5 del texto constitucional.

Bautizado como Juan Carlos Alfonso Víctor María de Borbón y Borbón, Juan Carlos I es nieto por vía paterna de Alfonso XIII, hijo del matrimonio habido entre Juan de Borbón y Battenberg, , y de María de las Mercedes de Borbón y Orleans.

Juanito, como lo llaman sus más cercanos para diferenciarlo de su padre, Juan de Borbón, nació, como se desprende de un comunicado de la Casa Real Española, en un apartamento del edificio situado en el número 122 del viale dei Parioli de Roma (Italia), ciudad donde vivían sus padres, durante el exilio de la Familia Real, ausente de España desde la proclamación de la Segunda República en 1931. Fue bautizado el 26 de enero de 1938 en la capilla de la Orden de Malta de Roma por el cardenal secretario de Estado de la Santa Sede, monseñor Eugenio Pacelli, futuro papa Pío XII. Su abuela paterna, la reina Victoria Eugenia, fue la madrina, y su abuelo materno, Carlos Tancredo de Borbón-Dos Sicilias, príncipe de las Dos Sicilias e infante de España, el padrino. En 1942 se trasladó junto con el resto de su familia a Lausana, en Suiza.

En una entrevista celebrada el 25 de agosto de 1948 entre Franco y el conde de Barcelona en el golfo de Vizcaya, se acordó que el príncipe se trasladaría a España para cursar allí sus estudios. El 8 de noviembre de 1948, a los diez años de edad, Juan Carlos pisó por primera vez suelo español. Allí estudiaría durante ese año académico. Tras el verano de 1949, sin embargo, el deterioro de las relaciones entre Franco y don Juan llevarían a este último a decidir que su hijo no volviera por el momento a España.

Tras un año en Estoril, Juan de Borbón accedió a que Juan Carlos regresara a España en el otoño de 1950 para continuar sus estudios, en esta ocasión acompañado de su hermano menor Alfonso. Para el verano de 1954, Juan Carlos había terminado el bachillerato. Posteriormente realizó su instrucción militar en la Academia General Militar de Zaragoza (1955-1957), en la Escuela Naval Militar de Marín en Pontevedra (1957-1958) y finalmente en la Academia General del Aire de San Javier en Murcia (1958-1959). Completó su formación en la Universidad Complutense de Madrid, donde cursó estudios de Derecho Político e Internacional, Economía y Hacienda Pública.

Durante las vacaciones de Semana Santa de 1956, el 29 de marzo, Jueves Santo, en la residencia familiar de Estoril, llamada todavía hoy "Villa Giralda", a Juan Carlos, que ya tenía 18 años cumplidos, se le disparó accidentalmente un revólver mientras jugaba en el desván de la casa con su hermano menor, Alfonso, lo que causaría la muerte de Alfonso. El hermano mayor del conde de Barcelona y tío de Juan Carlos, Jaime de Borbón, solicitaría meses después una investigación judicial del suceso; petición calificada por el historiador Paul Preston como de inaudita «insensibilidad y pura malevolencia» y que seguramente fue motivada por procurarse beneficios políticos a su propia causa.

El 13 de septiembre de 1961 se anunció oficialmente el compromiso de Juan Carlos con la princesa Sofía de Grecia, su prima tercera. Ocho meses después, el 14 de mayo de 1962, la pareja contraía matrimonio en Atenas por los ritos ortodoxo y católico. Con anterioridad a su celebración, Franco había manifestado su interés en que Juan Carlos y Sofía vivieran en España, de modo que, a principios de 1963, y a pesar de la oposición inicial de Juan de Borbón, el matrimonio se trasladaba a Madrid para fijar su residencia en el Palacio de La Zarzuela.

El 5 de marzo de 1966, se celebró una reunión del Consejo Privado del Conde de Barcelona en Estoril para conmemorar el veinticinco aniversario de la muerte de Alfonso XIII, a la que había sido invitado Juan Carlos. La reunión debía ser un acto de reafirmación de los derechos dinásticos de Juan de Borbón. Pese a que dos meses antes, Juan Carlos había declarado que «jamás» aceptaría la Corona mientras viviera su padre, decidió no asistir a la reunión a instancias de su esposa, Sofía de Grecia, utilizando como pretexto una indisposición. Juan de Borbón consideró aquel hecho como una ruptura de la unidad dinástica por parte de Juan Carlos.

En virtud de la Ley de Sucesión en la Jefatura del Estado de 1947, Franco estableció que el futuro rey de España sería designado por él. En julio de 1969 designaría a Juan Carlos como sucesor a título de rey, nombramiento ratificado por las Cortes Españolas el 22 de julio de 1969, ante las que el joven príncipe prestaría juramento el mismo día de guardar y hacer guardar las Leyes Fundamentales del Reino y los principios del Movimiento Nacional, es decir, el ideario franquista.No obstante, se basó en las facultades que dichas leyes le otorgaban para impulsar el cambio de régimen y facilitar el advenimiento de la democracia.

Siguiendo las reglas dinásticas, la sucesión hubiera debido recaer en su padre, Juan de Borbón y Battenberg, tercer hijo y heredero del rey Alfonso XIII. Sin embargo, las no muy cordiales relaciones entre Juan y Franco determinaron el salto en la línea de sucesión y el nombramiento de Juan Carlos como príncipe de España, título de nuevo cuño con el que Franco pretendía salvar distancias con respecto a la monarquía liberal. Dicho salto fue aceptado por el príncipe Juan Carlos, creando un conflicto interno en la Casa Real de Borbón. El Conde de Barcelona no renunciaría oficialmente a sus derechos sucesorios hasta 1977.
Juan Carlos I asumió interinamente la jefatura del Estado entre el 19 de julio al 2 de septiembre de 1974, y después desde el 30 de octubre al 20 de noviembre de 1975 por enfermedades de Franco. El 9 de julio de 1974, Franco era ingresado por una flebitis en la pierna derecha. Antes de partir hacia el hospital, llamó al presidente del Gobierno, Carlos Arias Navarro, y al presidente de las Cortes Españolas, Alejandro Rodríguez de Valcárcel, para que prepararan el traspaso interino de poderes al príncipe. Con todo, dos días más tarde, Juan Carlos, que no quería un traspaso interino por parte de Franco, intentó persuadir a Arias para que hiciera ver al dictador que debía traspasarle el poder de manera definitiva. Ante la negativa del presidente del Gobierno, el príncipe pidió a Franco que no firmara el decreto de traspaso. El 19 de julio, el estado del dictador se agravó, por lo que Arias acudió al hospital para que aprobara el traspaso. El yerno de Franco, Cristóbal Martínez-Bordiú, intentó impedir que Arias entrara en la habitación del jefe del Estado. Finalmente consiguió acceder, tras lo cual convenció al dictador para que cediera el poder de manera interina, lo que provocó la furia del marqués de Villaverde y de la esposa del dictador, Carmen Polo. Juan Carlos asumía por primera vez la jefatura del Estado de manera interina.

Tras un nuevo empeoramiento de la salud de Franco, el 23 de octubre de 1975, Valcárcel y Arias Navarro acudieron a La Zarzuela para proponer al príncipe que asumiera de nuevo interinamente la jefatura del Estado. Juan Carlos se negó si la sustitución no era definitiva. El 30 de octubre, Franco padeció una peritonitis. Informado de la gravedad de su estado por el equipo médico que lo atendía, el dictador ordenó su sustitución por parte del príncipe Juan Carlos, lo que este aceptó, una vez tuvo la certeza de que la enfermedad del dictador era terminal.

Al anunciarse la muerte de Franco (20 de noviembre de 1975), juró acatar los Principios del Movimiento Nacional, destinados a perpetuar el franquismo. Fue proclamado rey de España por las Cortes Españolas como Juan Carlos I de España el 22 de noviembre de 1975 y exaltado al trono el 27 de noviembre con una ceremonia de unción llamada: «Misa de Espíritu Santo» (el equivalente a una coronación) celebrada en la histórica Iglesia de San Jerónimo el Real de Madrid. Pese a haber jurado fidelidad a las leyes del Movimiento, con su actitud, promovió y alentó la Ley para la Reforma Política, que fue votada por el Congreso de los Diputados el 18 de noviembre de 1976 y aprobada en referéndum con un abrumador apoyo del 94%, lo que inició la Transición Española hacia la democracia.

El 14 de mayo de 1977, su padre, el Conde de Barcelona, renunció a sus derechos dinásticos históricos y a la jefatura de la Casa Real en la persona de Juan Carlos, una vez que hubo constatado la imposibilidad de acceder personalmente al trono. Con esta renuncia se reanudaba la dinastía histórica; y de esta forma, tras la proclamación de Juan Carlos I como rey de España y con la renuncia de Juan de Borbón a sus derechos, Felipe se convirtió en Heredero de la Corona y asumió el título de Príncipe de Asturias el 1 de noviembre de 1977. Don Juan efectuó su renuncia en un acto en donde estuvo presente, entre muchos, Landelino Lavilla en calidad de Notario Mayor del Reino; tras la ceremonia Don Juan declaró que renunciaba «con mucho amor a España y cariño por mi hijo».

El 22 de junio de 1977, Juan Carlos I envió una carta al sah de Irán, Reza Pahleví, en la que confirmaba su apuesta por la democracia, pero veía peligrar la monarquía, puesto que Adolfo Suárez, el candidato de su «plena confianza» y que consideraba soporte del sistema monárquico, carecía de las fuentes externas de financiación que disponían otras ideologías como la derecha, los comunistas y los socialistas, recalcando de estos últimos su ideología marxista (el PSOE se definió como tal hasta 1979). Finalmente, el rey solicitaba al sah «en nombre del partido político del presidente Suárez» un préstamo de diez millones de dólares como su «contribución personal al fortalecimiento de la monarquía española». La carta fue desvelada tras la publicación en 1991 del diario de Asadollah Alam, ministro del Interior y primer ministro del sah.

Durante su reinado se aprobó la Constitución española, que define las funciones del rey, suprimiendo toda participación política de la Corona y convirtiendo España en una monarquía parlamentaria de corte europeo occidental; asimismo, el artículo 57 de la Constitución le reconoce como el heredero legítimo de la «dinastía histórica».
La Constitución fue ratificada en referéndum del 6 de diciembre y el rey la sancionó el 27 de diciembre.

Uno de los momentos más graves a los que tuvo que hacer frente el rey Juan Carlos I fue el intento de golpe de Estado del 23 de febrero de 1981, el conocido como «23-F». Ese día, durante la segunda votación de la investidura del candidato a la Presidencia del Gobierno Leopoldo Calvo-Sotelo, se produjo la toma del Congreso de los Diputados por parte de fuerzas de la Guardia Civil al mando del teniente coronel Antonio Tejero. Simultáneamente en la Capitanía General de la III Región Militar (Valencia) el teniente general Jaime Miláns del Bosch ocupó las calles de la ciudad con tanques y hubo diversos conatos en otros puntos, tales como la toma de los estudios de Televisión Española en Prado del Rey (Madrid).

La intervención televisiva de Juan Carlos I desautorizando el golpe acabó con la insurrección, que pensaba contar con el apoyo de la Corona, y contribuyó a aumentar su carisma entre sectores políticos que hasta entonces no eran muy afines a la forma de gobierno monárquica. Después de este conflicto la monarquía quedó definitivamente consolidada.

El 9 de febrero de 2012, el semanario alemán "Der Spiegel" publicó un cable diplomático desclasificado por Alemania según el cual el rey habría mostrado simpatía por los golpistas durante un encuentro con el entonces embajador de Alemania en España, Lothar Lahn. En respuesta, Rafael Spottorno, jefe de la Casa del Rey, desmintió esta atribuida simpatía y afirmó: «Ni su Majestad ni la Casa Real acostumbran a valorar escritos u opiniones de terceros, que es una responsabilidad exclusiva de sus autores y que, en este caso, no se compadecen con la realidad de unos hechos, cuyo desarrollo y corolario final son de público conocimiento».
En 1992, ante las especulaciones acerca de que Juan Carlos mantenía una relación sentimental con la catalana Marta Gayá, tanto el jefe de la Casa del Rey, Sabino Fernández Campo, como el presidente del Gobierno, Felipe González, manifestaron su preocupación sobre que se pudiera haber orquestado una campaña contra el rey.

La publicación en 1993 por el aristócrata José Luis de Vilallonga de "El Rey", última biografía autorizada hasta el momento por el rey Juan Carlos, suscitó controversia, por cuanto la edición española omitía comentarios de Juan Carlos I acerca del 23-F que sí aparecían en otras ediciones europeas del libro, del mismo modo que ponía en boca de Vilallonga comentarios que en otras ediciones se atribuían al propio Juan Carlos. Vilallonga había declarado meses antes en una entrevista que el rey le había pedido que, respecto del 23-F, en el libro, «dijese yo [por Vilallonga] casi todas las cosas».

El 12 de diciembre de 2011, tras las informaciones aparecidas en los medios de comunicación acerca de la probable imputación por malversación, fraude, prevaricación, falsedad y blanqueo de capitales del yerno del Rey, Iñaki Urdangarin, duque consorte de Palma de Mallorca, La Zarzuela anunció que lo apartaba de todos los actos institucionales, por entender que su conducta no había sido «ejemplar». Además, durante su tradicional mensaje de Nochebuena, el Rey insistió en la necesidad de un comportamiento ejemplar por parte de todas las personas con responsabilidades públicas, tras lo que afirmó que «la justicia es igual para todos», lo que se interpretó como una alusión a la probable imputación de su yerno. Con todo, tras su discurso en la solemne apertura de la X Legislatura, el 27 de diciembre, el rey Juan Carlos lamentó que se hubiera personalizado su mensaje de Navidad. Dos días más tarde, el juez instructor José Castro imputaba a Iñaki Urdangarin.

Durante su declaración ante el juez instructor en Palma, los días 25, 26 y 27 de febrero de 2012, Urdangarin manifestó que el Rey le había pedido que abandonara sus negocios en marzo de 2006. Sin embargo, el 16 de abril de 2012, se hicieron públicos tres correos electrónicos escritos por Urdangarin y aportados al juez instructor por su exsocio, Diego Torres, que implicarían al Rey en negocios a favor de su yerno con posterioridad a esa fecha.

El 14 de abril de 2012, Juan Carlos I sufrió una fractura de cadera durante una cacería de elefantes a la que había sido invitado en Botsuana, lo que levantó críticas desde distintos ámbitos debido a que ocurrió en la peor semana de la crisis económica y tras un discurso en el que el Rey había pedido "rigor" y "sacrificios" a los españoles. Mientras que Partido Popular y Partido Socialista no quisieron valorar públicamente el percance, Izquierda Plural, Unión Progreso y Democracia y Esquerra Republicana de Catalunya anunciaron que preguntarían al Gobierno por este asunto en el Congreso de los Diputados. El lendakari, Patxi López, afirmó que «no estaría mal» una disculpa pública por parte del monarca. El 18 de abril, al salir del hospital donde fue intervenido, el Rey se disculpó públicamente por esos hechos, situación sin precedentes desde que comenzara su reinado, calificada como un episodio absolutamente nuevo en toda la historia de la realeza.

En el año 2013, a raíz de salir a la luz la «estrecha relación» que el rey mantenía con la empresaria alemana Corinna zu Sayn-Wittgenstein, algunos medios de comunicación hicieron público que la Casa del Rey, utilizando dos millones de euros procedentes de fondos públicos de Patrimonio Nacional, remodeló profundamente la finca "La Angorrilla" —lugar muy cercano al Palacio de la Zarzuela, donde durante varios años habría vivido Corinna.







El 2 de junio de 2014 Juan Carlos I manifestó su disposición a renunciar en su hijo Felipe, que asumió el cargo con el nombre de Felipe VI. La abdicación se produce de acuerdo con la fórmula recogida en la Carta Magna, concretamente en el título segundo de la misma (De la Corona española) en favor de su hijo. Tal como estipula la constitución es necesaria una ley orgánica para aplicar dicha sucesión, que fue aprobada por las Cortes Generales y sancionada en un acto solemne. En el Congreso de los Diputados dicha ley fue ampliamente respaldada: de 350 escaños, que posee la cámara, contó con 299 votos a favor, 23 abstenciones y 19 votos negativos. En el Senado contó con una amplio respaldo: 233 votos a favor, 5 en contra y 20 abstenciones de los 266 posibles. 

El mismo día de hacerse público el anuncio, los principales partidos republicanos, como IU, BNG y ERC, así como movimientos sociales antimonárquicos y radicalistas,
como la Coordinadora 25-S y el Movimiento 15-M, convocaron manifestaciones en las principales capitales del país y en otros municipios, difundidas a través de las redes sociales, para reivindicar la república y la celebración de un referéndum sobre la forma de Estado, a las que asistieron decenas de miles de personas. En dichas manifestaciones se pudieron observar numerosas banderas tricolores republicanas. En Cataluña, las manifestaciones fueron principalmente convocadas por ERC, mediante un llamamiento para apoyar una república catalana independiente; en dichas manifestaciones, sumándose a la tricolor, se observaron banderas catalanas independentistas y pancartas a favor de la secesión de Cataluña.Similar situación se produjo en Galicia, cuyas manifestaciones fueron apoyadas, entre otros mentados, por el BNG y Nós-Unidade Popular, ambos a favor de la autodeterminación de Galicia; observándose banderas gallegas independentistas y consignas a favor de una república gallega independiente.El sábado 7 de junio, se impulsaron nuevamente, entre otros, por plataformas y partidos ya mencionados, manifestaciones en más de 40 ciudades españolas, reiterando la demanda anterior. La presencia en esta convocatoria fue bastante menor que la que precedió el día 2. La participación, en ambas manifestaciones, fue muy inferior a la de otras convocatorias a favor de la república desde la restauración de la monarquía.

Según sondeos de opinión, durante la mayor parte de su reinado el rey gozó de un nivel de popularidad muy elevado en España y en ciertas partes de Iberoamérica, donde llegó a ser considerado el líder más popular en 2008. Su figura, considerada una garantía de orden y estabilidad, siempre gozó de un elevado apoyo popular, incluso durante los primeros años de la crisis económica iniciada en 2008, mientras se producía un profundo desencanto ciudadano hacia el resto de instituciones del Estado.

Sin embargo, esta tendencia sufrió el primer cambio drástico en abril de 2012, tras una cacería llevada a cabo en Botsuana durante los peores momentos de la crisis económica. En aquel momento, el apoyo de la población, que se encontraba en el 74 %, cayó hasta el 52 %. A pesar de que el porcentaje de aprobación creció lentamente y se situó en diciembre del mismo año en el 58 %, en 2013 este porcentaje se desplomó. En abril de aquel año, por primera vez, y pese a seguir siendo la figura del sistema político español con mejor valoración —por encima de los Ayuntamientos, el Parlamento, el Gobierno, los partidos políticos y los representantes políticos—, la mayoría de la población, un 53 %, desaprobaba la forma en que el rey desempeñaba sus funciones, frente al 42 % que lo aprobaba. No obstante, dos meses después de este dato, la confianza ciudadana subió ocho puntos porcentuales hasta situarse en el 50 % de aprobación. A pesar de situarse lejos de los datos obtenidos en años anteriores, el apoyo ciudadano seguía siendo superior al obtenido por el resto de instituciones del sistema político español y también superior al obtenido por otros jefes de Estado en sus respectivos países (como en Estados Unidos, Francia o Italia).

En un sondeo de opinión realizado en junio de 2014, pocos días después de anunciarse su abdicación, el rey Juan Carlos obtuvo un 6,9 sobre 10 a la hora de calificar el respeto que inspiraba su figura entre la ciudadanía.

Según José Álvarez Junco:
Según Santos Juliá:
Según Juan Pablo Fusi:

Según Victoria Prego, autora del libro "Así se hizo la Transición" (1995):
Según Charles Powell:

Algunas ONG y movimientos sociales sostuvieron que, en sus visitas a Marruecos, el rey actuaba como intermediario del Gobierno español en la venta de armas a este país que habrían sido utilizadas para reprimir al pueblo saharaui. También se le ha criticado su conocida amistad con las familias reales de países de Oriente medio como Arabia Saudí, Kuwait o Emiratos Árabes Unidos, países con regímenes autoritarios, destacando el caso de Arabia Saudí, cuya monarquía absoluta controla todos los organismos del Estado y ha sido durante años acusada de corrupción masiva y de constituir un régimen "feudal" y "no libre".

Dentro de las críticas al rey a menudo también se han incluido a los medios de comunicación españoles, que según sus críticos dan una imagen deliberadamente positiva de su figura, que incluso algunos medios extranjeros han señalado como un auténtico culto a la personalidad.

Otras críticas se refirieron a la irresponsabilidad penal del monarca, consagrada en la Constitución Española, que lo hacían inimputable por cualquier delito que pudiera cometer. Además, diversos autores han señalado el tabú existente en los medios de comunicación españoles en torno a la figura del Rey. También ha sido criticado en algunos sectores su papel en el 23-F, el fallido golpe de Estado que tuvo lugar en 1981, pues el rey habría sabido previamente de su existencia o incluso podría haber sido partícipe. Del mismo modo, algunos autores consideraron inadecuado el "¿Por qué no te callas?" que el rey espetó al presidente venezolano Hugo Chávez en la XVII Cumbre Iberoamericana.

En el año 2007, "The Times", uno de los periódicos más importantes del Reino Unido, criticó el "lujoso estilo de vida" del rey y la "idealización" que se ha hecho de su figura durante 30 años, al tiempo que lo calificaba de "playboy".

Según una investigación periodística del diario Público, que tuvo acceso a documentos clasificados, publicada en 2014, el rey Juan Carlos I habría intermediado entre la dictadura militar de Jorge Rafael Videla en Argentina y el gobierno de España presidido por Adolfo Suárez desde 1976. Según la investigación y los documentos confidenciales, España habría proporcionado ayuda económica a través de acuerdos comerciales y diplomáticos. A su vez, el rey también habría hecho de intermediario entre la dictadura argentina y grandes empresarios y banqueros españoles, entre los que se encontraría Emilio Botín padre, propietario del Banco Santander. La necesidad de Argentina por obtener divisas provendría de los grandes gastos que suponían en esos años sus programas de represión política "(véase Vuelos de la muerte y Desaparecidos durante el Proceso de Reorganización Nacional"). La investigación también señalaba el intercambio de regalos y condecoraciones entre altos cargos de ambas naciones —por ejemplo el rey en 1978 le concedió a Videla la gran cruz de la Orden del Mérito Militar y el collar de la Orden de Isabel la Católica, mientras que el entonces príncipe Felipe (Felipe VI) fue nombrado por la Armada argentina Guardiamarina Honoris Causa en 1981—. España también habría dado cursos a 33 militares argentinos entre 1976 y 1983 (ya en democracia) partícipes de la represión en su país.

En septiembre de 2012 el diario "The New York Times" publicó un artículo titulado «Un Rey escarmentado que busca la redención, para España y su Monarquía». En el texto, difundido cinco días después de que el monarca visitara al periódico para explicar la situación española y mejorar la imagen del país, se indicaba, entre otros datos, que «la fortuna de la Familia Real española ha sido estimada en hasta 2.300 millones de dólares [casi 1.800 millones de euros]». Fuentes del diario neoyorquino indicaron posteriormente que el cálculo no había sido producto de una investigación propia, sino que se basaba en un promedio de cifras ya publicadas.

Las únicas publicaciones que, hasta esa fecha, habían incluido una cifra para la fortuna del rey de España, habían sido las revistas "Eurobusiness" (2000 y 2002) y "Forbes" (2003). Precisamente, esta última justificó la inclusión del monarca español en sus listas de 2003 por el dato que un año antes había publicado "Eurobusiness". "Eurobusiness" fue la primera en hablar de 1.790 millones de euros en la lista que publicó en 2002 con las 400 personas más ricas de Europa. Aunque en el suplemento anterior, publicado en el año 2000, el rey ya había aparecido con una fortuna estimada en unos 1.681 millones, el dato pasó desapercibido y las reacciones no llegaron hasta que se publicó el número del año 2002, donde se afirmaba:

En aquella ocasión el Gobierno y la Casa del Rey sí tuvieron conocimiento de la información y reaccionaron desmintiéndola. El embajador español en Reino Unido, país en el que se editaba la revista, envió una carta al director de la misma en la que le transmitía «el estupor de la Casa de Su Majestad el Rey de España» y calificaba de «disparatada» la estimación de "Eurobusiness", a lo que añadía la posible explicación al «erróneo» cálculo de la revista:

Sobre la cuestión de si los bienes inmuebles de Patrimonio Nacional fueron incluidos en la estimación de la fortuna, el artículo de "The New York Times" sentencia: «una suma [los 2.300 millones de dólares] que sus defensores afirman que fue inflada por la inclusión de propiedades del gobierno».

La prensa generalista española que analizó la información sobre la supuesta fortuna, alineó sus tesis con el dictamen del Gobierno, calificando el dato de «exorbitante» e «inverosímil», de «cálculo incorrecto», «cifra equivocada» e «inflada» o de «chocante». Sin embargo, en España, otras voces, como el economista y catedrático de la UPM, además de antiguo consejero delegado de Campsa, Roberto Centeno, dio por válida la cifra del "New York Times", y acusó al monarca y su antiguo administrador, Manuel Prado y Colón de Carvajal, de cobrar comisiones por el petróleo importado por el Estado procedente de países de Oriente Medio —de 1 a 2 dólares por barril— desde finales de la década de 1970. En 2015 se filtró una conversación, grabada por el Centro Nacional de Inteligencia, donde el empresario Javier de la Rosa afirmaba que el bróker Arturo Fassana, implicado en varias tramas de corrupción y lavado de dinero, «guardó» en algún momento 300 millones a Juan Carlos I.

El ingeniero, economista y escritor español Roberto Centeno González, cuya trayectoria profesional ha discurrido en diversas empresas públicas del Estado español (Butano, SA, ENAGAS, CAMPSA, Saras Energía, ERG Petróleos y ENEROIL),​ ha afirmado que tras hacerse responsable de la contratación de un cargamento de petróleo kuwaití, el entonces Ministro de Hacienda, Francisco Fernández Ordóñez, le hizo una llamada de atención para que no volviera a formalizar contrato de suministro de petróleo alguno en Oriente Próximo porque ese terreno estaba reservado para Manuel Prado y Colón de Carvajal. Así, según nos cuenta el propio Centeno,​ Fernández Ordóñez le llegó a decir lo siguiente: «Mira, ha estado aquí Manolo Prado, que se ha enterado que estabas en Kuwait y me ha montado un pollo que no puedes imaginar, me ha dicho que Arabia Saudí y los Emiratos son exclusivamente suyos y nadie más que él puede negociar ni un barril, así que ni se te ocurra volver a hacer nada parecido».

Termina diciendo que Juan Carlos I, a través de su representante y administrador privado Manuel de Prado, «tenía el monopolio de nuestros suministros extra durante la crisis [del petróleo]», y que «Hacienda pagaba por el petróleo lo que ponía en la factura, sin entrar en averiguación alguna y menos cometer la ordinariez de decir que se podía comprar más barato cuando el conseguidor era Prado».

El 14 de mayo de 1962 se casó en Atenas con la princesa Sofía de Grecia y Dinamarca, con la que tuvo tres hijos:




A raíz de la polémica surgida por la cacería del rey en Botsuana en abril de 2012, se apuntó, desde determinados ámbitos periodísticos, que los reyes harían vidas separadas, extremo que no ha sido confirmado por la Casa del Rey. La prensa española, periódicos extranjeros como "Bild", "La Stampa" y "Middle East Times International" así como la periodista Pilar Eyre en su libro "La soledad de la reina" y el exdirector del periódico "ABC", José Antonio Zarzalejos, señalaron también una posible relación sentimental de varios años del rey con Corinna Larsen, hechos que fueron negados por esta última. Asimismo, se le atribuyen otros importantes affaires extramatrimoniales con otras mujeres como Barbara Rey o la mallorquina Marta Gayá. 
La residencia oficial de la Familia Real es el Palacio Real de Madrid, pero se reserva para las ceremonias oficiales. Los reyes residen en el Palacio de La Zarzuela y la familia del rey Felipe reside también dentro del recinto de la Zarzuela, en una construcción reciente llamada "Pabellón del Príncipe". La infanta Elena vive en una residencia privada en Madrid y Cristina reside en Ginebra desde el verano de 2013.

En la época estival, la Familia Real reside en el Palacio de Marivent, en Palma de Mallorca, pero para las ceremonias oficiales se reserva el Palacio Real de La Almudaina.

El rey Juan Carlos participó como regatista en los compitiendo en la clase Dragon con su embarcación "Fortuna". Sus dos tripulantes fueron Félix Gancedo y Gonzalo Fernández de Córdoba. Posteriormente formó parte del equipo Bribón. Tras varias décadas de alta competición, incluyendo un breve retiro entre 2011 y 2016, Juan Carlos I se proclamó campeón del mundo de vela en 2017, a los 79 años, en la categoría de embarcaciones clásicas de 6 metros en el Mundial de Vancouver (Canadá).

También es radioaficionado (su indicativo es EA0JC), y aficionado al esquí y a la caza. Esta afición ha suscitado distintas polémicas, además de la desatada a raíz de su viaje a Botsuana en 2012. Así, el 8 de octubre de 2004 participó en una cacería de osos en Rumanía. En 2006, distintos medios de Rusia lo acusaron de haber cazado a un oso drogado, lo que llevó a la apertura de una investigación por parte de las autoridades rusas. Este hecho fue desmentido por la Casa del Rey. A raíz de esas polémicas, el 21 de julio de 2012 la sección española del Fondo Mundial para la Naturaleza (WWF) decidió suprimir el cargo de Presidente de Honor de sus estatutos, cargo que ostentaba el Rey desde la fundación de la organización.

Fue ganador del Premio Carlomagno en 1982 y del Premio Simón Bolívar en 1983, y ha recibido doctorados "honoris causa" en universidades como las de Bolonia (1988), Oxford (1986), Cambridge (1988), Harvard (1983) o La Sorbona (1985).

Ha tenido que someterse a varias intervenciones quirúrgicas en las últimas décadas. La noche del 21 al 22 de junio de 1981 tuvo que ser operado de urgencia como consecuencia de un golpe contra una puerta de cristal cuando se disponía a bañarse en la piscina del La Zarzuela, que le produjo un corte en el nervio radial. El 3 de enero de 1983 sufrió una fisura en la pelvis mientras esquiaba en Gstaad (Suiza), por la que hubo de estar tres meses de baja. El 19 de julio de 1985 tuvo que ser intervenido nuevamente para extirparle una fibrosis consecuencia de aquel accidente de esquí. El 28 de diciembre de 1991 padeció un nuevo accidente de esquí en Baqueira Beret, tras el que hubo de ser operado de la rodilla, lo que le llevó a estar cuatro meses de baja.

El 8 de mayo de 2010 le fue extraído un tumor benigno del pulmón en Barnaclínic, entidad sanitaria privada vinculada al Hospital Clínic de Barcelona. El 14 de abril de 2012 tuvo que ser operado de urgencia de la cadera en el Hospital Quirón San José de Madrid, después de una rotura acaecida durante una cacería de elefantes a la que había sido invitado en Botsuana. El 23 de noviembre de 2012, el rey es intervenido de nuevo en el Hospital Quirón San José de Madrid, en esta ocasión para implantarle una prótesis en la articulación de la cadera izquierda.

El 3 de marzo de 2013, el monarca fue intervenido quirúrgicamente en la Clínica La Milagrosa de Madrid, en este caso de discopatías y de estenosis de canal lumbar. El 24 de septiembre de 2013, el rey es operado de su cadera izquierda en el Hospital Universitario Quirón de Pozuelo de Alarcón, Madrid. La intervención quirúrgica estuvo dirigida por el doctor Miguel Cabanela. El 21 de noviembre de 2013, el monarca fue operado de nuevo de su cadera izquierda, para sustituir la prótesis provisional implantada en la anterior intervención por una definitiva. La intervención se realizó también en el Hospital Universitario Quirón de Pozuelo de Alarcón, Madrid.

La Constitución Española, en su título II, artículo 56, párrafo 2, designó el título de rey para Juan Carlos I, pudiendo hacer uso de otros títulos y dignidades, generalmente referidas a entidades históricas, y que han estado tradicionalmente asociadas a la Corona española:


No obstante, la mayoría de estos títulos tienen un carácter meramente honorífico. Otros títulos y dignidades asociados al titular de la Corona son los siguientes:


Tras abdicar, Juan Carlos y Sofía mantienen con carácter honorífico y de forma vitalicia el título de reyes, y reciben tratamiento de "Majestad" y honores análogos a los establecidos para los herederos de la Corona.


Numerosos lugares, infraestructuras y objetos han sido nombrados en homenaje al rey Juan Carlos I, en la propia España, así como en el resto del mundo. Entre los más significativos están: la Base Antártica Juan Carlos I en la isla Livingston (Islas Shetland del Sur), el Buque de Proyección Estratégica Juan Carlos I (perteneciente a la Armada Española), el Parque Juan Carlos I en Madrid, la Universidad Rey Juan Carlos en Móstoles o el Centro Rey Juan Carlos I de España ("The King Juan Carlos I of Spain Center") en Nueva York (Estados Unidos).

A lo largo de los años, la figura de Juan Carlos I se ha convertido en personaje de películas y telefilmes en España, pudiendo mencionarse los siguientes:




 


</doc>
<doc id="4694" url="https://es.wikipedia.org/wiki?curid=4694" title="29 de enero">
29 de enero

El 29 de enero es el 29.º (vigesimonoveno) día del año en el calendario gregoriano. Quedan 336 días para finalizar el año y 337 en los años bisiestos.












</doc>
<doc id="4696" url="https://es.wikipedia.org/wiki?curid=4696" title="Azúcar">
Azúcar

Se denomina azúcar, en el uso más extendido de la palabra, a la sacarosa, cuya fórmula química es CHO, también llamada «azúcar común» o «azúcar de mesa».

La sacarosa es un disacárido formado por una molécula de glucosa y una de fructosa, que se obtiene principalmente de la caña de azúcar o de la remolacha. El 27 % de la producción total mundial se realiza a partir de la remolacha y el 73 % a partir de la caña de azúcar.

La sacarosa se encuentra en todas las plantas, y en cantidades apreciables en otras plantas distintas de la caña de azúcar o la remolacha, como el sorgo y el arce azucarero.

En ámbitos industriales se usa la palabra azúcar o azúcares para designar los diferentes monosacáridos y disacáridos, que generalmente tienen sabor dulce, aunque por extensión se refiere a todos los hidratos de carbono.

Funde a los 160 °C y calentada a 210 °C se transforma en una masa de color pardo denominada "caramelo", utilizada en la elaboración de dulces y pasteles, así como para la saporización y coloración de líquidos.

Si se calienta por encima de 145 °C en presencia de compuestos amino, derivados por ejemplo de proteínas, tiene lugar el complejo sistema de reacciones de Maillard, que genera colores, olores y sabores generalmente apetecibles, y también pequeñas cantidades de compuestos indeseables.

El azúcar es una importante fuente de calorías en la dieta alimenticia moderna, pero es frecuentemente asociada a calorías vacías, debido a la completa ausencia de vitaminas y minerales.

En alimentos industrializados el porcentaje de azúcar puede llegar al 80 %. La Organización Mundial de la Salud recomienda que el azúcar no supere el 10% de las calorías diarias consumidas.

El azúcar se ha producido en el subcontinente indio desde la antigüedad. No era abundante o barata en los primeros tiempos y la miel se utilizaba con más frecuencia para endulzar en casi todo el mundo. Originalmente, la gente masticaba la caña de azúcar en bruto para extraer su dulzura. La caña de azúcar era una especie nativa de los trópicos, en Asia meridional y en el sudeste asiático. Las diferentes especies de caña parecen tener su origen en diferentes lugares, siendo "Saccharum barberi" originaria de la India y "S. edule" y "S. officinarum" provenientes de Nueva Guinea. Una de las referencias históricas más tempranas a la caña de azúcar está en manuscritos chinos del siglo VIII a. C. que afirman que el uso de la caña de azúcar se originó en la India.

El azúcar no tuvo apenas importancia hasta que los indios descubrieron métodos para convertir el jugo de la caña de azúcar en cristales granulados que eran más fáciles de almacenar y transportar. Fueron descubiertos cristales de azúcar de la época de la Gupta Imperial, alrededor del siglo V d. C. En la lengua indígena local, estos cristales se llaman "khanda" (खण्ड, khaṇḍa).

Los marineros indios, que llevaban mantequilla y azúcar como suministros, introdujeron el conocimiento del azúcar en las diversas rutas comerciales que viajaban. Los monjes budistas, en sus viajes, llevaron los métodos de cristalización de azúcar a China. Durante el reinado de Harsha (606 a 647) en el norte de la India, los enviados de la India en la China Tang enseñaron métodos de cultivo de la caña de azúcar después del reinado de Li Shimin (que reinó de 626-649), que manifestó su interés por el azúcar. Posteriormente, China estableció sus primeras plantaciones de caña de azúcar en el siglo VII. Los documentos chinos confirman, al menos, dos expediciones a la India, iniciadas en el 647, para obtener la tecnología para el refinado del azúcar. En el sur de Asia, en Oriente Medio y en China, el azúcar se convirtió en un elemento básico de la cocina y de los postres.

Las conquistas de Alejandro Magno se detuvieron a orillas del río Indo por la negativa de sus tropas para ir más al este. Allí vieron a las personas en el subcontinente indio cultivando la caña y fabricando un dulce granulado, localmente llamado "sharkara" (शर्करा, "sarkara"), pronunciado como "saccharum" (ζάκχαρι). En su viaje de regreso, los soldados macedonios se llevaron "cañas de miel" con ellos. La caña de azúcar se mantuvo como un cultivo poco conocido en Europa durante más de un milenio. El azúcar era un bien escaso y los comerciantes de azúcar eran ricos.

Los cruzados trajeron con ellos el azúcar a Europa después de sus campañas en Tierra Santa, donde se encontraron con caravanas que transportaban esa "sal dulce". A principios del siglo XII, Venecia adquirió algunas aldeas cerca de Tiro y estableció fincas para producir azúcar para exportar a Europa, donde se complementaba con la miel, que anteriormente había sido el único edulcorante disponible. El cronista de las cruzadas Guillermo de Tiro, en un escrito de finales del siglo XII, describió el azúcar como un producto "muy necesario para el uso y la salud de la humanidad". En el siglo XV, Venecia era el principal centro de refinación y distribución de azúcar de Europa.

En agosto de 1492, Cristóbal Colón se detuvo en La Gomera, en las Islas Canarias, para cargar vino y agua, con la intención de permanecer sólo cuatro días. No obstante, tuvo una relación sentimental con Beatriz de Bobadilla y se quedó un mes. Cuando finalmente iba a partir, ella le dio unas cañas de azúcar, que fueron las primeras en llegar a América.

Los portugueses llevaron el azúcar a Brasil. En torno a 1540 había 800 fábricas de azúcar de caña en la isla de Santa Catarina y había otras 2.000 en la costa norte de Brasil, en Demarara y en Surinam. La primera zafra tuvo lugar en la isla de La Española en 1501; y se construyeron muchos ingenios azucareros (fábricas) en Cuba y Jamaica en la década de 1520.

El azúcar fue un lujo en Europa hasta el siglo XVIII, en que se hizo más asequible. Luego se popularizó y en el siglo XIX el azúcar llegó a ser considerado una necesidad. Esta evolución del gusto y de la demanda de azúcar como ingrediente de alimentos esenciales desató grandes cambios económicos. Durante los siglos XVIII y XIX muchos europeos prosperaron con la industria azucarera en las Antillas y otros lugares de América. La demanda de mano de obra barata para realizar el duro trabajo necesario para su cultivo y procesamiento aumentó la demanda de la trata de esclavos del África subsahariana. También hubo una gran demanda de trabajadores semi-esclavos contratados en Asia. La mezcla étnica moderna de muchas regiones ha sido influenciada por la demanda de azúcar.

El azúcar también llevó a algunos industrialización de las antiguas colonias. Por ejemplo, el teniente J. Paterson, del establecimiento de Bengala, convenció al gobierno británico que la caña de azúcar podría ser cultivada en la India británica con muchas ventajas y a menor coste que en las Indias Occidentales. Como resultado, las fábricas de azúcar se establecieron en Bihar, al este de la India.

Durante las guerras napoleónicas, la producción de remolacha azucarera aumentó en la Europa continental debido a la dificultad de importar azúcar cuando el envío fue objeto de bloqueo. En 1880, la remolacha azucarera fue la principal fuente de azúcar en Europa. Esta se cultivaba en Lincolnshire y otras partes de Inglaterra, aunque el Reino Unido siguió importando la parte principal de su azúcar de sus colonias.

Hasta finales del siglo XIX, el azúcar fue comprado en bloques alargados (en inglés, "sugarloafs", que significa hogazas de azúcar), que tenían que ser cortados. En años posteriores, el azúcar se vendió habitualmente granulado y en bolsas.

Los terrones de azúcar se produjeron en el siglo XIX. El primer inventor de un proceso para disponer el azúcar en forma de cubo fue el moravo Jakub Kryštof Rad, director de una empresa azucarera en Dačice. Comenzó la producción de terrones de azúcar después de haber adquirido una patente de 5 años, el 23 de enero de 1843. Henry Tate, de Tate & Lyle, fue otro de los primeros fabricantes de terrones de azúcar en sus refinerías en Liverpool y Londres. Tate adquirió una patente para la fabricación de terrones de azúcar del alemán Eugen Langen, quien en 1872 había inventado un método diferente de procesamiento de terrones de azúcar.

El azúcar es un endulzante de origen natural, sólido, cristalizado, constituido esencialmente por cristales sueltos de sacarosa, obtenidos a partir de la caña de azúcar ("saccharum officinarum L") o de la remolacha azucarera ("beta vulgaris L") mediante procedimientos industriales apropiados. Un grano de azúcar es entre 30 y 70 % menor que el grano de arroz.

El azúcar blanco se somete a un proceso de purificación química —llamado sulfitación— haciendo pasar a través del jugo de caña el gas SO obtenido por combustión de azufre.

La película de miel que rodea el cristal de azúcar moreno o rubio contiene sustancias como minerales y vitaminas. En el argot azucarero, a estas sustancias se les llama impurezas. Cabe aclarar que, durante el proceso de refinación, a todas las sustancias que no son sacarosa se consideran impurezas, pero son inofensivas para la salud. Y son estas las que le otorgan el color y sabor particular.

Cada día es mucho más frecuente en platos y dulces preparados encontrarse otros azúcares diferentes; glucosa, fructosa —básicamente de la planta de maíz, preferida por su asimilación más lenta - o combinados con edulcorantes artificiales.

La palabra azúcar viene del sánscrito "sharkara", que los persas transformaron en "sakar". Los griegos tomarían el término persa y lo llamarían "sakjar". El árabe clásico tomó el término griego y lo llamó "sukkar", y posteriormente el árabe hispano lo llamó "assúkar". El sánscrito tomó la palabra "sharkara" de "çarkara", que significa arenilla, ya que llamaban así al polvo blanquecino de la caña de azúcar.

Según la Real Academia Española, el azúcar tiene género ambiguo, pero cuando va sin especificativo es mayoritario su empleo en masculino.

A pesar de que no empieza con una letra "a" tónica, su artículo siempre se utiliza masculino.

El azúcar se puede clasificar por su origen (de caña de azúcar o remolacha), pero también por su grado de refinación o sus características. Normalmente, la refinación se expresa visualmente a través del color (azúcar moreno, azúcar rubio, blanco), que está dado principalmente por el porcentaje de sacarosa que contienen los cristales.

Los tipos de azúcar que se comercializan habitualmente son los siguientes:


El procesamiento del azúcar se puede dividir en las siguientes etapas:

En el mercado del azúcar se distinguen dos tipos de productos, el azúcar cruda y el azúcar refinada o blanca. Dentro de cada tipo existen diferentes categorías según sus diferentes calidades. El azúcar cruda se produce solamente de caña de azúcar, en tanto el azúcar refinada se produce tanto de caña de azúcar como de remolacha azucarera. En este sentido, se considera que la industria de la caña de azúcar tiene una mayor flexibilidad para responder a los cambios de precios relativos entre azúcar cruda y azúcar refinada.

El mercado mundial del azúcar es uno de los más distorsionados del mundo como resultado de un amplio conjunto de políticas de protección y de subsidio a la producción y exportaciones por parte de los principales países productores y consumidores del mundo. A nivel general, se pueden distinguir, básicamente, dos tipos de mercados de azúcar: el mercado protegido y el mercado libre.

El mercado protegido consiste en acuerdos preferenciales y contratos de largo plazo que incluyen el sistema de cuotas de los Estados Unidos, las cuotas de la Unión Europea, las exportaciones de Cuba a China y las exportaciones de Australia a Canadá.

En el mercado libre se transan los volúmenes no cubiertos por convenios especiales. Estas transacciones se realizan preferentemente en las diferentes bolsas azucareras, entre las cuales se encuentran las de Nueva York, Londres, París y Hong Kong. Además de transacciones spot, en el mercado libre de azúcar se utilizan instrumentos tales como forward, futuros y derivados.

Los principales productores de azúcar son:

En 2003, 16 países concentraban el 87,1 % de la producción mundial.

El consumo mundial se presenta del siguiente modo:

El alto consumo de azúcar demostró que aumenta significativamente la tensión sistólica y la presión arterial diastólica, las personas que consumen el 25% o más de calorías de azúcar tienen casi tres veces mayor riesgo de muerte por enfermedad cardiovascular.

Algunas personas creen que el azúcar produce hiperactividad y otros problemas de comportamiento en los niños y sostienen que deben seguir dietas especiales que limiten estas sustancias, para evitar este tipo de efectos. Otros expertos no están de acuerdo con esta teoría. Varios estudios demuestran que la cantidad de azúcar en la dieta no influye en el comportamiento infantil, sino que los padres que tienen prejuicios hacia los efectos de los dulces perciben erróneamente que sus hijos están más inquietos y nerviosos cuando comen golosinas.

Existen numerosas razones para reducir el azúcar que consume un niño, que no guardan relación con el efecto sobre el nivel de actividad:


Diversos estudios de investigación indican que las células cancerosas consumen más azúcar (glucosa) que las células normales. No obstante, ningún estudio ha demostrado que consumir azúcar empeore el cáncer ni que eliminar su consumo lo haga disminuir o desaparecer y diferentes estudios evidencian que no existe asociación entre el consumo de azúcar y el cáncer. Sólo existe evidencia posible de una relación entre la ingesta de monosacáridos (fructosa y glucosa) y el riesgo de desarrollar cáncer de páncreas, y entre el índice glucémico (IG) y el cáncer colorrectal.

No obstante, algunos autores señalan que una alimentación con un alto contenido de azúcar puede ocasionar un excesivo aumento de peso, y la obesidad está asociada a un riesgo elevado de padecer diversos tipos de cáncer. Otros autores señalan que la evidencia sobre la asociación entre la ingesta de azúcar añadido y el riesgo de obesidad en adultos o en niños es insuficiente.

Actualmente, se conoce que las dietas ricas en azúcar pueden provocar un aumento excesivo de peso y resistencia a la insulina, lo cual predispone a padecer diabetes mellitus tipo 2 (DMT2). Esta enfermedad ha experimentado un drástico aumento de incidencia en las últimas décadas, principalmente debido a factores del estilo de vida occidental, como la falta de ejercicio y las dietas altas en calorías. Asimismo, se ha demostrado consistentemente que la DMT2 es un factor de riesgo para la enfermedad de Alzheimer. Por lo tanto, los cambios en la dieta pueden reducir significativamente el riesgo de desarrollar DMT2 y enfermedad de Alzheimer, y con ello aumentar la calidad de vida y mejorar la longevidad.




</doc>
<doc id="4698" url="https://es.wikipedia.org/wiki?curid=4698" title="Glucosa">
Glucosa

La glucosa es un monosacárido con fórmula molecular CHO. Es una hexosa, es decir, contiene 6 átomos de carbono, y es una aldosa, esto es, el grupo carbonilo está en el extremo de la molécula (es un grupo aldehído). Es una forma de azúcar que se encuentra libre en las frutas y en la miel. Su rendimiento energético es de 3,75 Kcal/gr. en condiciones estándar. Es un isómero de la galactosa, con diferente posición relativa de los grupos -OH y =O. 

La aldohexosa glucosa posee dos enantiómeros, si bien la D-glucosa es predominante en la naturaleza. En terminología de la industria alimentaria suele denominarse dextrosa (término procedente de «glucosa dextrorrotatoria») a este compuesto.

El término «glucosa» procede del idioma griego "γλεῦκος" (gleûkos; "mosto", "vino dulce"), y el sufijo «-osa» indica que se trata de un azúcar. La palabra fue acuñada en francés como "glucose" (con anomalía fonética) por Dumas en 1838; debería ser fonéticamente "gleucosa" (o "glicosa" si partimos de glykos, otro lexema de la misma raíz).

La glucosa, libre o combinada, es el compuesto orgánico más abundante de la naturaleza. Es la fuente primaria de síntesis de energía de las células, mediante su oxidación catabólica, y es el componente principal de polímeros de importancia estructural como la celulosa y de polímeros de almacenamiento energético como el almidón y el glucógeno.

A partir de su estructura lineal, la D-glucosa sufre una ciclación hacia su forma hemiacetálica para dar sus formas furano y pirano (D-glucofuranosa y F-glucopiranosa) que a su vez presentan anómeros alfa y beta. Estos anómeros no presentan diferencias de composición estructural, pero si diferentes características físicas y químicas.

La glucosa es uno de los tres monosacáridos dietéticos, junto con fructosa y galactosa, que se absorben directamente al torrente sanguíneo durante la digestión. Las células lo utilizan como fuente primaria de energía y es un intermediario metabólico. La glucosa es uno de los principales productos de la fotosíntesis y combustible para la respiración celular.

Todas las frutas naturales tienen cierta cantidad de glucosa (a menudo con fructosa), que puede extraerse y concentrarse para preparar un azúcar alternativo. Sin embargo, a escala industrial tanto el jarabe de glucosa (disolución de glucosa) como la dextrosa (glucosa en polvo) se obtienen a partir de la hidrólisis enzimática de almidón de cereales (generalmente trigo o maíz).

Los organismos fotoautótrofos, como las plantas, sintetizan la glucosa en la fotosíntesis a partir de compuestos inorgánicos como agua y dióxido de carbono, según la reacción:

Los seres heterótrofos, como los animales, son incapaces de realizar este proceso y toman la glucosa de otros seres vivos o la sintetizan a partir de otros compuestos orgánicos. Puede obtenerse glucosa a partir de otros azúcares, como fructosa o galactosa. Otra posibilidad es la síntesis de glucosa a partir de moléculas no glucídicas, proceso conocido como gluconeogénesis. Hay diversas moléculas precursoras, como el lactato, el oxalacetato y el glicerol.

También existen ciertas bacterias anaerobias que utilizan la glucosa para generar dióxido de carbono y metano según esta reacción:

La glucosa es el constituyente básico de diversos polímeros de gran importancia biológica, como son los polisacáridos de reserva almidón y glucógeno, y los estructurales celulosa y quitina.

Celulosa. En su forma cíclica D-glucopiranosa, dos moléculas de glucosa se unen mediante un enlace ß-glucosídico en el que reaccionan los -OH de sus carbonos 1 y 4, respectivamente, para formar el disacárido celobiosa; la unión de varias de estas moléculas forma celulosa, constituyente esencial de la pared celular de las células vegetales.

Quitina. Un derivado nitrogenado de la glucosa, la N-acetilglucosamina, también en su forma cíclica ß-D-glucopiranosa, forma el disacárido quitocina, cuya repetición da lugar a la quitina, el componente del exoesqueleto de los artrópodos, el grupo animal con mayor éxito evolutivo.

Glucógeno y almidón. La unión de dos moléculas de D-glucopiranosa mediante enlace α-glucosídico da lugar a la maltosa y a la isomaltosa, disacáridos que son la base de los polisacáridos glucógeno (reserva energética propia de animales y hongos) y almidón (reserva típica de los vegetales y muchas algas).

En repostería se utiliza un derivado de la sacarosa, producido mediante hidrólisis ácida o enzimática, que se llama azúcar invertido, compuesto a partes iguales de fructosa y glucosa. Añadido a la mezcla o formado durante el proceso, se usa en la elaboración de bollería, caramelos y otros productos de confitería.

La mezcla cristaliza con más dificultad que la sacarosa, evita la desecación de los productos congelados y hace descender el punto de congelación de helados.




</doc>
<doc id="4699" url="https://es.wikipedia.org/wiki?curid=4699" title="Murcia">
Murcia

Murcia es una ciudad española, capital del municipio del mismo nombre y de la comunidad autónoma de la Región de Murcia. Es el centro de la comarca de la Huerta de Murcia y de su área metropolitana. Está situada en el sudeste de la península ibérica a orillas del río Segura, en la denominada depresión prelitoral murciana, a 40 kilómetros del mar Mediterráneo. Con 441.003 habitantes, Murcia ocupa el 7º puesto en la lista de .

El área urbana de la ciudad (o zona metropolitana), aunque no establecida oficialmente, comprendería a unos diez municipios de la Región de Murcia, contando con una población de 643 854 habitantes en 2013, repartidos en una superficie total de 1230,92 km, con una densidad de población de 515 hab/km. De este modo, el área urbana de Murcia ocuparía el 10º puesto en la lista de .

Murcia es un importante municipio de servicios en la que el sector terciario ha sucedido a su antigua condición de exportadora agrícola por antonomasia, gracias a su célebre y fértil huerta, por la cual era conocida con el sobrenombre de "la Huerta de Europa". Entre sus industrias más destacadas se encuentran la alimentaria, la textil, la química, la de destilación y la fabricación de muebles y materiales de construcción, estando muchas de ellas ubicadas en el Polígono Industrial Oeste, considerado uno de los más grandes de la península (compartido con el municipio de Alcantarilla).

Es también un importante centro de gran tradición universitaria desde que fuera fundada la primera universidad en 1272. Actualmente es sede de dos universidades, la pública Universidad de Murcia y la privada Universidad Católica San Antonio, que atraen alrededor de 50.000 estudiantes al municipio.

De orígenes inciertos, hay constancia de que fue fundada en el año 825 con el nombre de "Madīnat Mursiya" ( en árabe) por orden de Abderramán II, probablemente sobre un asentamiento anterior de origen romano. Durante la Edad Media, Murcia llegó a ser capital de la cora de Tudmir (siglo X), posteriormente fue cabeza de distintos reinos de taifas de creciente importancia en los siglos XI, XII y XIII y entre 1243-1266 se incorporó a la Corona de Castilla como capital del Reino de Murcia, siendo además ciudad con voto en cortes y sede episcopal desde 1291.

De su patrimonio histórico-artístico destacan su célebre Catedral, de fachada barroca e interior principalmente gótico, el afamado Casino, de suntuosos interiores; el denso patrimonio escultórico de Francisco Salzillo, y un gran conjunto de edificios barrocos. En el ámbito cultural es conocida por su rico folclore, especialmente vistoso durante las Fiestas de Primavera y las procesiones de Semana Santa, declaradas de . El Consejo de Hombres Buenos de la Huerta de Murcia, ejemplo de tribunal consuetudinario de regantes del Mediterráneo español, está declarado Patrimonio cultural inmaterial de la Humanidad por la Unesco.

El origen del topónimo "Murcia" no está claro y tanto historiadores como lingüistas sostienen varias hipótesis agrupadas en torno a dos orígenes básicos: el árabe y el latino. Según palabras de Menéndez Pidal: "el topónimo Murcia era azote de filólogos".

El origen pre-islámico, probablemente latino, parece el más lógico, aunque no se sabe con seguridad cuál es la raíz primera, y son muchas la hipótesis que se aventuran. La más extendida actualmente ya la enunció Francisco Cascales en sus "Discursos históricos de la muy noble y muy leal ciudad de Murcia" publicados en 1621,
Aunque la evolución de la palabra que propone Cascales está descartada, lo cierto es que el topónimo "Murcia" era usado por los romanos, siendo como dice el autor el nombre de una divinidad primitiva que tenía un templo en el valle situado entre las colinas del Aventino y el Palatino en la misma ciudad de Roma, creyéndose que la denominación de dicha diosa está relacionado con el latín "myrtus", con el significado de "mirto", evolucionando a "Myrtea"/"Murtea"/"Murcia".

Por lo tanto, parece que los estudios históricos han llegado a la conclusión de que -al igual que la mencionada divinidad- "Murcia" es un topónimo de origen latino que deriva muy probablemente de Myrtea o Murtea (“lugar de mirtos” o “lugar donde crecen los mirtos”) o de Murtia, y que de esa forma "Mursiya" -en árabe: مدينة مُرْسية- (primera denominación documentada ya en época islámica) no fue más que la adaptación árabe del término latino preexistente.

El escudo de la ciudad de Murcia tiene orígenes medievales, con diversos añadidos posteriores. Está compuesto por 7 coronas sobre fondo rojo. Debajo de la corona central se halla un corazón en cuyo interior se disponen un león rampante y una flor de lis rodeados por una leyenda ("Priscas novissima exaltat et amor"). Completa el escudo una orla con castillos y leones.

El origen de este emblema está en el rey Alfonso X, quien concedió un sello concejil con 5 coronas como representación legal y simbólica de la ciudad y su reino (conmemorando el hecho de que el reino de Murcia era el quinto en ser reconquistado).

Más tarde, en el 1361, Pedro I firmó un privilegio por el que se concedía a Murcia la sexta corona para que figurara en el sello y en el pendón municipal, añadiendo además una orla con los símbolos de la Corona de Castilla (en agradecimiento al papel murciano en la Guerra de los Dos Pedros).

Posteriormente, en 1575, el Concejo solicitó a Felipe II la inclusión de un corazón para conmemorar que las entrañas y el corazón de Alfonso X descansan en la ciudad como quedó establecido en el testamento del rey sabio (y que se encuentran en la Capilla Mayor de la Catedral de Murcia).

El actual escudo se completaría en 1709 por Felipe V. El monarca premió la fidelidad murciana en la Guerra de Sucesión concediendo otra corona real sobre un león y una flor de lis unida bajo el texto: "Priscas novissima exaltat et amor" (ensalzar y amar lo antiguo y lo nuevo).

La bandera del municipio es roja en su totalidad, con el escudo arriba descrito dispuesto en el centro de la misma. Así pues, el rojo es el color de la ciudad (como se puede comprobar, por ejemplo, en la indumentaria del Real Murcia Club de Fútbol).

El "Himno de Murcia" es obra del poeta y periodista murciano Pedro Jara Carrillo, quien puso la letra a la música del maestro Emilio Ramírez. Se estrenó el 9 de junio de 1922. El poeta también compuso el "Himno a la Virgen de la Fuensanta" con motivo de su coronación en 1927.

Un popular himno no oficial del municipio es "El Canto a Murcia" de La Parranda, zarzuela de ambiente murciano compuesta por el maestro Francisco Alonso, con libreto de Luis Fernández Ardavín y estrenada en 1928. El "Canto a Murcia" está considerado uno de los finales de acto más impresionantes de la historia de la zarzuela, y se le atribuyen características de himno regional.

Otros símbolos de Murcia son la Matrona o el León del Malecón.

El término municipal tiene una extensión de 881,86 km² y se divide de norte a sur en dos partes diferentes separadas por una serie de sierras que conforman la llamada "Cordillera Sur": Sierra de Carrascoy (1.065 metros), del Puerto (531 metros), Cresta del Gallo (609 metros), Villares (487 metros), Columbares (647 metros), Altaona (534 metros) y Escalona (345 metros). Estas dos zonas se denominan: "Campo de Murcia" al sur, que geográficamente forma parte del Campo de Cartagena, y Huerta de Murcia al norte de la sierra, constituida por la vega segureña. Entre estas dos áreas, atravesando la sierra, se encuentran los pasos naturales del puerto de La Cadena, el puerto del Garruchal y el puerto de San Pedro.

La Vega del Segura, donde se encuentra la conocida huerta, es un llano de inundación depositado sobre una fosa tectónica que constituye la "depresión prelitoral murciana", a 40Km en línea recta del Mar Mediterráneo. Las elevaciones montañosas que la encajonan en sus flancos norte y sur están compuestas de materiales geológicos pertenecientes al dominio Bético. En la vertiente norte aparece el denominado "reborde interior de la depresión prelitoral", formado por una sucesión de suaves colinas, constituidas por areniscas y margas, restos de la sedimentación miocénica que queda en forma de resalte como consecuencia del hundimiento de la depresión del Segura. Sus alturas son modestas y aisladas, sin llegar a superar los 200 msnm, con los cabezos de Guadalupe, Espinardo, El Puntal, Cabezo de Torres, Monteagudo y Esparragal (que hacen de límite con el término de Molina de Segura), prolongándose en la Comunidad Valenciana a través de la Sierra de Orihuela. El zócalo sur de la depresión está formado por las sierras de la referida Cordillera Sur, constituidas por materiales calizos, dolomías, esquistos, filitas y cuarcitas.
Los aportes y arrastres de estas colinas y montañas junto con las avenidas del Segura y el Guadalentín fueron rellenando y colmatando la depresión hasta formar una llanura aluvial de débiles pendientes. La ciudad de Murcia se encuentra en la parte central de la vega, a una altitud para el centro de la urbe de 42 msnm, mientras que la altitud del municipio varía desde los 25 metros en el último tramo del río Segura en el municipio, hasta los 1031 metros en el Morro de la Fuente, en la Sierra de Carrascoy.

La referida zona sur del municipio, llamada Campo de Murcia, no es sino la cabecera o parte norte de la llanura litoral del Campo de Cartagena, extendiéndose de forma descendente desde la Sierra de Carrascoy hasta los límites municipales de Fuente Álamo de Murcia, Torre Pacheco y San Javier. Un caso especial es el de la pedanía de Lobosillo que se sitúa como un enclave del municipio de Murcia en el centro del Campo de Cartagena.

La parte más occidental de la zona septentrional del municipio, la formada por las pedanías de Sangonera La Seca, Sangonera la Verde, Barqueros y Cañada Hermosa, constituye realmente la parte final del valle del Guadalentín, justo antes de su conexión con la vega del Segura (el punto en donde el río Segura entra en la depresión prelitoral), formando un valle encajonado entre la Sierra de Carrascoy al sur y las estribaciones montañosas del reborde norte de la depresión, valle al que también se le denomina "campo de Sangonera".

El río Segura es el principal eje hidrográfico del municipio. Discurre por la vega del mismo nombre y atraviesa la ciudad de Murcia con dirección oeste-este, siendo un río de régimen pluvial mediterráneo, de escaso caudal pero con fuertes crecidas, como las de 1946, 1948, 1973, 1987 o 1989 que inundaron diversas zonas del municipio.

El Segura entra en la "depresión prelitoral" procedente de la Vega Media (de los municipios de Las Torres de Cotillas y Molina de Segura), a la altura de las pedanías de Javalí Nuevo y Javalí Viejo, justo en donde se sitúa la denominada Contraparada. En este primer tramo todavía lleva una dirección norte-sur, que cambiará por la descrita "oeste-este" a su paso por la pedanía de Puebla de Soto y el límite municipal con Alcantarilla. Tras atravesar la ciudad, entre las pedanías de Santa Cruz y Alquerías el río adquiere una dirección "suroeste-noreste", abandonando el municipio a la altura de El Raal introduciéndose en el de Beniel y en el término de Orihuela, dentro ya de la Vega Baja.

El río transcurre a partir de la Contraparada a través de una canalización realizada en los años 90 que modificó el cauce anterior recortando los clásicos meandros y aumentando la capacidad de desagüe de cara a controlar las periódicas riadas. A su paso por la ciudad, el Segura cuenta con una amplia canalización en piedra realizada en los años 50 del siglo XX, sustituta de la anterior del siglo XVIII.

El río Guadalentín, el principal afluente del Segura por su margen derecha (también llamado "Sangonera" en su tramo final), discurre a través del Canal del Reguerón por la zona sur de la vega proveniente del valle del Guadalentín -que no es sino la misma depresión prelitoral antes de que el Segura acceda a ella-, concretamente de la comarca del Bajo Guadalentín (de los municipios de Librilla y Alhama de Murcia). Este río desemboca artificialmente en el Segura a la altura de la pedanía de Beniaján gracias al mencionado Canal del Reguerón, que fue realizado en el siglo XVIII para evitar que las riadas del Guadalentín confluyeran con las del Segura aguas arriba de la ciudad de Murcia.

También hay que destacar la presencia de numerosas ramblas, situadas principalmente en los piedemontes de los dos rebordes montañosos de la depresión prelitoral, destacando las ramblas de Espinardo y Churra en la zona norte, o la rambla del Garruchal en la zona sur. En la zona del Campo de Murcia también son típicos estos cauces, pero vierten sus aguas ocasionales hacia el Campo de Cartagena y el Mar Menor, destacando la rambla de La Murta, la rambla de Corvera o la rambla del Ciprés.

El Segura y su afluente el Guadalentín son famosos por sus furiosas crecidas y temidas inundaciones, teniéndose registro de algunas ya en la baja Edad Media, por lo que su control ha sido desde tiempo inmemorial motivo de construcción de obras de defensa tales como cortas, motas, canales de derivación y encauzamiento en algunos tramos. La propia muralla musulmana de la ciudad se pensó como una forma de protección, al igual que elementos tan característicos como el Paseo del Malecón o el Canal del Reguerón. Pese a la construcción de embalses en la cabecera, los desbordamientos continuaron afectando a la ciudad de Murcia y su huerta durante el siglo XX, por lo que se tuvo que ejecutar un definitivo plan integral contra las avenidas desarrollado entre 1987 y 1994.

Las crecidas del Segura están documentadas desde la baja Edad Media, siendo una de las primeras la de octubre de 1328, destacando la frecuencia de las mismas, con 17 episodios de importancia durante el siglo XV. El episodio más importante de ese siglo fue el de septiembre de 1452, lo que llevó a desarrollar mejoras en el cauce y varios proyectos de encauzamiento en la capital murciana.

En 1545 el desbordamiento del Segura inundó Murcia y su huerta siendo la más importante crecida hasta la fecha. En 1651 la "Riada de San Calixto" causó 1.500 muertos en Murcia con un caudal de 1.700 m³/s. En 1802 el Guadalentín rompió el Pantano de Puentes lo que provocó una riada que destruyó completamente la pedanía murciana de Buznegra. En 1879 la célebre "Riada de Santa Teresa" superó los 1.800 m³/s a su paso por el Puente de los Peligros, marcando los registros históricos más altos de la historia y causando más de 1.000 muertos y numerosos destrozos.

En el siglo XX las riadas de 1946, 1948, 1973, 1982, 1987 y 1989 han pasado a la historia superándose en muchas de ellas los 1.000 m³/s de caudal máximo instantáneo. Gracias a las obras desarrolladas (encauzamiento total del tramo urbano en los años 50, encauzamiento y recorte de meandros en todo el municipio a finales de los 80 principios de los 90 y presas de contención en ríos y ramblas de toda la cuenca) se evitó el desbordamiento en las crecidas de 1997, 2000 y 2012, por lo que no se ha desbordado el río en el casco urbano desde octubre de 1982.

Murcia tiene un clima mediterráneo seco. De acuerdo con la clasificación climática de Köppen es en general un clima semiárido cálido de tipo "BSh". Con una temperatura media anual de 18,6 °C en Murcia (Centro Meteorológico) y de 18,2 °C en Murcia / Alcantarilla (Base Aérea), el área urbana y sus zonas más próximas se sitúan por encima de la barrera de los 18 °C que separa las variantes fría (BSk) y cálida (BSh) de este tipo de clima, si bien las medias son inferiores a los 18 °C en las zonas circundantes de huerta más expuestas a la inversión térmica, en las Sierras del Valle-Carrascoy y en el Campo de Murcia, en la zona sur del municipio, en donde la temperatura media se sitúa en torno a los 17-17.5 °C, dando lugar al clima "BSk" (semiárido frío).

Con inviernos suaves y veranos calurosos, las temperaturas oscilan entre los 16 °C y los 4 °C de enero y los 34 °C y los 21 °C de agosto, si bien las temperaturas extremas pueden superar los 40 °C en verano y descender de los 0 °C en invierno. Los valores extremos absolutos en las estaciones principales existentes en el municipio oscilan entre los 46,1 °C de máxima registrados en Murcia / Alcantarilla el día 4 de julio de 1994, y los -7,5 °C registrados en Murcia (Centro Meteorológico) el día 16 de enero de 1985. De la histórica estación meteorológica de Murcia / Instituto, puesta en marcha en 1866 en la azotea del actual Instituto Licenciado Cascales, y en funcionamiento hasta mediados del siglo XX, existen valores extremos de 47,8 °C de máxima registrados el día 29 de julio de 1876, y de -5,5 °C de mínima registrados el día 15 de enero de 1871. El valor de 47,8 °C es récord absoluto de temperatura máxima registrada en España en el siglo XIX, aunque hay que considerar que, el mismo día de ese registro, otras estaciones peninsulares alcanzaron registros superiores, aunque no fueron finalmente homologados por dudosos.

Respecto a las precipitaciones, los acumulados medios anuales se sitúan en el entorno de los 300 mm en gran parte del municipio, siendo superiores a los 350 mm en la cara norte de las Sierras del Valle-Carrascoy y zonas próximas. Las precipitaciones se concentran normalmente en pocos días, principalmente en invierno, primavera y sobre todo otoño, pudiendo ser torrenciales en situaciones de gota fría, con valores superiores a los 100 mm en menos de 24 horas, ocasionando riadas e inundaciones. La precipitación máxima en un día es de 136 mm registrados en Murcia / Alcantarilla el 10 de octubre de 1943. La nieve, extraordinariamente rara en la ciudad y el valle del Segura, puede caer en las cumbres y zonas altas de las Sierras del Valle-Carrascoy en episodios de entradas frías en invierno. En zonas bajas, la nevada más importante del siglo XX se produjo el 26 de diciembre de 1926, en donde según la prensa de la época, se llegó a acumular más de un metro de espesor en menos de 36 horas. Las dos últimas nevadas generalizadas en el municipio se produjeron el 12 de febrero de 1983 y el 18 de enero de 2017; esta fue la primera nevada generalizada del siglo XXI, cuajando en toda la Región de Murcia, incluyendo zonas de montaña, litoral y la huerta de Murcia.

El viento sopla normalmente de componente este-sureste desde los últimos meses de primavera, influenciado por la entrada de la brisa marina. Y gira a componente oeste a finales de otoño, durante el invierno y primeros meses de primavera. La máxima racha de viento, registrada el 4 de octubre de 1987 en Murcia (Centro Meteorológico), es de 108 km/h. Murcia / Alcantarilla tiene un registro máximo de 103 km/h. Sin embargo, es en las cumbres de las Sierras del Valle-Carrascoy donde el viento sopla con mayor intensidad, habiéndose llegado a medir rachas de hasta 141,6 km/h el día 24 de enero de 2013 en la estación meteorológica del Pico Relojero, a 609 msnm. En esta estación automática, en funcionamiento desde el año 2012, se alcanzan anualmente rachas máximas superiores a los 100 km/h, y tiene una media, para sus primeros 3 años de funcionamiento, de 44 días al año con rachas de viento superior a los 62 km/h, fuerza temporal según la definición establecida en la Escala de Beaufort.

Además de la huerta y las zonas urbanas, el término municipal cuenta por su gran tamaño con distintos paisajes: "tierras baldías", pinares de pino carrasco en las sierras de la Cordillera Sur y zonas de típico secano mediterráneo en el Campo de Murcia.
En el municipio se encuentra la mayor parte del de El Valle y Carrascoy, compartido con los municipios de Fuente Álamo de Murcia y Alhama de Murcia y que comprende gran parte de las sierras de la ya referida Cordillera Sur, siendo el pulmón verde de la ciudad. Dentro del parque, las sierras de Carrascoy, del Puerto y Cresta del Gallo están declaradas LIC, mientras que las sierras de la Cresta del Gallo, Villares, Columbares y Altaona, cuentan además con protección ZEPA.

El grupo faunístico más destacado en el ámbito del parque es el de las aves, y en especial las rapaces como "Águila perdicera", "Águila real", "Águila culebrera", "Águila calzada", "Ratonero" y "Halcón peregrino", destacando también la abundante presencia del "Búho real", especie que posibilitó la declaración de ZEPA al contar con una de las colonias más numerosas de España y con mayor densidad del Mundo. En cuanto a los mamíferos, está constatada la existencia de "Jabalí", "Zorro", "Gato montés" o distintas especies de mustélidos como "Garduña", "Tejón", "Comadreja", al igual que siete especies de "Murciélago".

La vegetación del parque está constituida principalmente por un bosque de "Pino carrasco", que en algunas zonas presenta "Pino piñonero" o manchas de "Carrasca". Hay que destacar los ejemplares relictos de "Alcornoque" presentes en el área denominada "Majal Blanco". El sotobosque mejor conservado cuenta con un matorral típicamente mediterráneo en el que el "lentisco", "acebuche", "palmito", "enebro", "espino negro" y "coscoja" son los más representativos.

Dentro de la fauna fluvial presente en el río Segura, destaca la recuperada presencia de la "Nutria" en el tramo inicial del río desde la Contraparada hasta la las proximidades de la ciudad. Igualmente se pueden encontrar "Ánades reales", "Garzas", "Fochas", "Garcetas", "Gallineta común", "Barbos" o "Carpas", ejemplos de especies antiguamente desaparecidas en el municipio y que han pasado a ser habituales de nuevo tras un largo proceso de recuperación ambiental y depuración de aguas. Incluso, en áreas del río alejadas de núcleos urbanos se pueden observar "Carriceros", "Martinetes", el "Martín pescador" o el "Avetorillo".

Asimismo, en la zona norte del término municipal, lindando con el de Santomera, se encuentra el paraje boscoso protegido llamado "Coto Cuadros", declarado "Monte de Utilidad Pública".

El paisaje más conocido y significativo del término municipal es la antiquísima Huerta de Murcia, espacio que dominaba gran parte de la vega segureña rodeando la ciudad, pero que desde hace décadas sufre la presión de la expansión urbana que junto a la terciarización de la economía y la ausencia de políticas de conservación ha reducido notablemente su extensión.

Entorno cultural

El paisaje huertano se muestra como un inmenso mosaico de poblamiento disperso fruto de la necesidad de los habitantes de vivir junto a sus cultivos. Entorno natural caracterizado por las acequias con sus mondas y su típica vegetación de cañas y árboles de ribera, además de los árboles frutales, donde destaca el limonero en un espacio parcelario alineado de hortalizas y con la abundante presencia de la morera.

El sistema de riegos de la huerta de Murcia se basa en una compleja red de acequias y demás canales de irrigación de antiquísimo origen. Los musulmanes fueron los que aprovecharon las áreas agrícolas romanas presentes en la vega segureña desde siglos antes, ya que la depresión aluvial tenía especiales características para el desarrollo de regadío. La auténtica transformación del valle tuvo lugar con la construcción del azud de la Contraparada, situado en el lugar en que el Segura hace su entrada en la "depresión prelitoral" y que se encarga de retener y elevar las aguas hacia las acequias mayores, la de "Aljufía" (al norte del río Segura) y "Alquibla" (al sur). Canales que el geógrafo árabe Al-Himyari describía como: 

El crecimiento demográfico impulsó la necesidad de colonizar tierras cada vez más lejanas de la Contraparada, aumentando la complejidad de todo el sistema. Algunas acequias se destinaron al servicio de la ciudad como la "Argualexa", proporcionando caudal necesario para el abastecimiento de los edificios públicos y de las industrias artesanas. La red de acequias surtía de energía a la industria murciana, ya que a su vera se desarrollaron molinos harineros, de batanes, de pimentón, fábricas de pólvora y salitre, fábricas de curtidos, de paños, de hilaturas de seda hasta llegar a finales del siglo XIX, cuando aparecen las primeras industrias conserveras.

La superficie de la huerta de Murcia ha vivido vaivenes a lo largo de la historia, desde un importante retroceso sufrido en el siglo XIV como consecuencia de la crisis e inseguridad reinante, hasta la expansión del siglo XVIII con motivo del auge del sector sericícola.A finales de los años 90 del siglo XX, tras varias décadas de terciarización económica, abandono de cultivos y expansión urbana, el espacio de regadío cubría una superficie próxima a las 12.500 hectáreas (menor hoy día tras el reciente boom urbanístico), que poco a poco ha ido cediendo sitio a la urbanización del suelo, cambiando radicalmente los usos tradicionales.

Medio físico

Así, la Huerta de Murcia se extiende por toda la vega del Segura desde el azud de la Contraparada al oeste hasta Orihuela, ya en la Vega Baja, al este, recorrida por más de 500 kilómetros de cauces.

Los "heredamientos" son las tierras que riega cada una de las acequias mayores, dividiéndose en dos grandes heredamientos generales subdivididos a su vez en particulares, destacando los del lado norte -margen izquierda del Segura- (Aljufía, Churra la Vieja, Alfatego, Beniscornia, Béndame, Arboleja, Caravija, Zaraiche, Santomera, Zaraichico, Casteliche, Nelva, Benetúcer, Raal Viejo, Aljada, Azarbe de Monteagudo, Azarbe Mayor, Pitarque y Raal Nueva).

Los del lado sur -margen derecha del Segura- (Alquibla, Barreras, Dava, Turbedal, Benialé, La Raya o Puxmarina, Almohajar, la Herrera, Condomina, Beniaján, Batán o Alcatel, Junco, Alguazas, Aljorabia, Alfande, Alarilla, Azarbe de Beniel, Riacho, Zeneta, las Parras y Carcanox).

La acequía de Churra la Nueva forma sin embargo un heredamiento independiente al resto, tomando sus aguas antes de la Contraparada.

Leyes y normas propias. El Consejo de Hombres Buenos

La existencia de la Huerta y su sistema de riego implicaba la cooperación de los huertanos mediante la regulación de los riegos. Para ello, desde los tiempos de los musulmanes y tras la reconquista, el concejo de la ciudad dictó una serie de leyes y normas encaminadas a proteger la Huerta y solucionar los conflictos que se generan. Como consecuencia de esto, aparecen una serie de instituciones y figuras jurídicas encargadas de velar por este espacio y sus riegos comunitarios dando lugar al desarrollo de una legislación local, en parte escrita y en parte consuetudinaria, sobre reparto, uso del agua y control de las infracciones. Todas ellas están recogidas en las "Ordenanzas y Costumbres de la Huerta de Murcia" que se recogen por escrito desde el siglo XIX, regulando también a la Junta de Hacendados de la Huerta de Murcia y el Consejo de Hombres Buenos.

Este consejo es una institución que se remonta a la Edad Media y cuya función es conocer y resolver las reclamaciones y pleitos, en un orden arbitral y extrajudicial, permitiendo resolver los litigios mediante actuaciones baratas, rápidas y especializadas haciendo posible una eficaz y pronta recuperacuón del orden quebrantado. Sus actuaciones eran verbales y no se comienzan a recoger por escrito hasta el siglo XVIII, estando sus decisiones reconocidas dentro del ordenamiento jurídico español.

En el año 2009, el Consejo de Hombres Buenos de la Huerta de Murcia fue declarado Patrimonio Cultural Inmaterial de la Humanidad por la Unesco como ejemplo de tribunal consuetudinario de regantes del Mediterráneo español.

En la siguiente tabla aparecen los municipios que limitan con el término municipal de Murcia, en la secuencia geográfica en la que están situados:

Además, el municipio de Alcantarilla está completamente rodeado por el término municipal de Murcia.

Existen muchas dudas sobre los orígenes de la ciudad de Murcia. Hay constancia de que fue mandada fundar con el nombre de "Madina Mursiya" el 25 de junio del año 825 por el emir de Al-Ándalus Abderramán II con el objetivo de sofocar las revueltas entre yemeníes, muladíes y las castas dominantes hispanogodas que ensangrentaban las tierras de la Cora de Tudmir, así como para hacer más fuerte el poder del Emirato de Córdoba en una cora escasamente islamizada. Historiadores como Rodríguez Llopis defienden sin embargo que lo que se produjo en aquel año no fue la fundación sino el traslado de la capitalidad de Tudmir a una Murcia ya existente.

Lo cierto es que todo parece indicar que ya existía un pequeño lugar poblado en esta misma zona, cuyos órígenes se remontarían a una villa romana denominada "Murtia", en clara referencia a la existencia de humedales y mirtos -arrayanes- en torno a ella. De hecho, está arqueológicamente demostrado el desarrollo de un extenso complejo de villae romanas en el valle del Segura que aprovechaban la feracidad de las terrazas fluviales y la abundancia del agua del río.

Sin embargo, las evidencias humanas más antiguas en el actual territorio del municipio de Murcia pertenecen a la Cultura del Argar; cultura desarrollada durante la Edad del Bronce que tuvo su centro en el sureste ibérico con un avanzado concepto de urbanismo, además del dominio de la agricultura y la metalurgia del bronce.

En la época prehistórica, así como en la antigüedad, la mayoría de asentamiento humanos se concentraron en los rebordes montañosos de la "depresión prelitoral" o vega del Segura. Así, en el reborde sur destacan los yacimientos del "Puntarrón Chico" de Beniaján de época argárica, o "Santa Catalina del Monte" del Bronce Final. En el reborde norte destaca el yacimiento de la "Cuesta de San Cayetano" de Monteagudo, con una secuencia que va desde el Argar, pasando por el Bronce Tardío y el mundo íbero, finalizando en la Roma altoimperial.

Con la llegada de la Edad del Hierro, los íberos, concretamente los contestanos, tuvieron un especial desarrollo en el reborde sur con los yacimientos del "Verdolay", en donde aparece un importante poblado, con una necrópolis asociada (el "Cabecico del Tesoro") y un santuario (el "Santuario de la Luz") datados entre el 500 a. C. y la romanización.

Fue en plena época romana cuando comenzaron los asentamientos en el fondo del valle del Segura, zona de almarjales y aguas estancadas que fueron convertidas al cultivo a través de las primeras evidencias de aprovechamiento hídrico de la zona, comprobándose en yacimientos de época tardoantigua como el de "Senda de Granada". Como ya se ha comentado, el origen antiguo de Murcia estaría en una de esas villae que aparecieron en áreas más próximas al río Segura.

La referida zona de la Cordillera Sur vivió otro impulso poblacional en época tardorromana-visigoda, como parecen demostrar algunas infraestructuras que han llegado hasta nosotros. Es el caso de los yacimientos del "Martyrium de La Alberca" del siglo IV y la "Basílica del Llano del Olivar" de Algezares (siglo VI).

Aunque la explotación agraria y el aprovechamiento hídrico a gran escala del valle en donde se encuentra Murcia se remonta a tiempos romanos; fueron los árabes los que, valiéndose del curso del río Segura que atraviesa la depresión prelitoral, perfeccionaron y ampliaron una compleja red hidrológica formada por acequias, brazales y regaderas, dando impulso a la ciudad convirtiéndola en uno de los centros de producción agraria más importantes de Al-Andalus. Esto llevó a que a partir del siglo X Murcia se convirtiera en capital política y centro económico de la Cora de Tudmir.

No fue hasta la segunda mitad del siglo XI, tras el fin del Califato, cuando la ciudad de Murcia encabezó su primer reino taifa independiente bajo el mandato de Abu Abd al-Rahman Ibn Tahir. Conquistada por Al-Mutamid de Sevilla, fue epicentro del conflicto entre este y su visir Ibn Ammar.

La ciudad capitalizó un segundo reino taifa de la mano de Ibn Mardanis; conocido por los cristianos como Rey Lobo. Durante este periodo (1147-1172) Murcia vivió un momento de esplendor convertida en un centro político y cultural comparable a las principales capitales islámicas del momento, siendo cabeza de la resistencia andalusí frente al Imperio Almohade.

Tras la victoria cristiana en Las Navas de Tolosa (1212), Castilla se expandió hacia el sur, dirigiéndose hacia la taifa de Murcia, que en su tercer periodo estuvo regida por la dinastía de los Banu Hud, que tras 1228 se habían sublevado contra los almohades consiguiendo el control de casi toda Al-Andalus teniendo su capital en Murcia. Finalmente, el infante Alfonso de Castilla (futuro Alfonso X el Sabio) acordó con Ibn Hud al-Dawla el vasallaje de la ciudad en 1243 a través del Tratado de Alcaraz, incorporándola a la Corona de Castilla en forma de protectorado.

En 1264 los mudéjares murcianos se sublevaron contra los castellanos por el incumplimiento de lo pactado. Alfonso X, empleado entonces en el asedio de Niebla (Huelva), pidió ayuda urgente a su suegro Jaime I de Aragón. Tropas de la Corona aragonesa sofocaron la rebelión en 1266, eliminando los restos de autonomía musulmana al devolver la ciudad a la jurisdicción de Castilla en virtud del Tratado de Almizra. Jaime I de Aragón licenció a 10000 aragoneses para repoblar la zona, concediéndoles tierras, en algunos casos grandes extensiones.

Murcia pasó a concentrar así tres núcleos de población (cristianos, judíos y musulmanes). Tras el fin del protectorado, Alfonso X el Sabio estableció las bases sociopolíticas del municipio al concederle el Fuero de Sevilla, convirtiéndola en capital del nuevo Reino de Murcia al ser la sede del "Adelantado Mayor" y tener voto en Cortes.

En el contexto de la Corona de Castilla, Murcia fue durante el reinado de Alfonso el Sabio una de las tres capitales en las que iba rotando la corte itinerante, junto a Toledo y Sevilla, creando un "studium arabicum et hebraicum". En ella quiso ser enterrado por disposición testamentaria, aunque finalmente acabaran por reposar su corazón y entrañas.

En el año 1291 Murcia se convirtió de manera oficial en la sede episcopal de la Diócesis de Cartagena tras el beneplácito de Sancho IV el Bravo.

En el contexto de la crisis dinástica en la corona castellana, Jaime II de Aragón ocupó la ciudad en el 1296, devolviéndola posteriormente a control castellano en virtud de la Sentencia Arbitral de Torrellas (1304).
Durante el siglo XIV se vivió una profunda crisis que afectó a la actividad agrícola de la huerta de Murcia y por ende a la ciudad, debido a las epidemias de peste y al contexto de inseguridad que se vivía en todo el reino de Murcia, afectado como estaba por una triple frontera (con la corona de Aragón, con un Mediterráneo atestado de corsarios y sobre todo con los musulmanes granadinos).

A mediados del siglo XV comenzó una recuperación económica gracias al final de la amenaza granadina. En 1452 las tropas de la ciudad de Murcia junto con las de Lorca vencieron en la batalla de Los Alporchones a huestes musulmanas provenientes del reino nazarí. A partir de 1482, tanto Murcia como Lorca se convirtieron en la base de operaciones para las campañas militares que los Reyes Católicos lanzaron sobre la parte oriental del reino de Granada. La ciudad de Murcia sirvió de residencia a los monarcas en 1488.

En el 1520 Murcia se unió al movimiento comunero aunque con unos matices totalmente distintos al resto de Castilla por su claro sentimiento antioligarquico que entroncaba con los conflictos que se vivían en la región a finales del siglo XV. Los comuneros murcianos implantaron una junta de síndicos con cierta representación popular y elegidos por parroquias.

En el reinado de Felipe II, tropas murcianas bajo mando de Luis Fajardo; II Marqués de los Vélez y adelantado del reino de Murcia, ayudaron a sofocar la rebelión morisca en el Reino de Granada. Este hecho hará que se le conceda a Murcia el título de "Muy noble y muy leal". El conflicto de las Alpujarras supondrá así mismo el hundimiento del sector sedero granadino, y en consecuencia, el auge de la seda murciana que permitirá a la ciudad y su reino esquivar los efectos de la crisis finisecular del siglo XVI a diferencia de Castilla. De hecho, la crisis no llegaría a Murcia hasta la tercera década del siglo XVII.

En el año 1613, Felipe III decidió la expulsión de los moriscos murcianos que todavía quedaban en las diseminadas aljamas de la huerta y que tan vitales fueron para la producción sericícola.

La crisis se precipitó sobre la ciudad con la epidemia de peste de 1648 y la posterior "Riada de San Calixto", que en 1651 arrasó Murcia con una avenida del río Segura que causó más de 1000 muertos.

En el año 1705 fue nombrado obispo de Cartagena Luis Belluga y Moncada. En el contexto de la Guerra de Sucesión Española fue el artífice del triunfo de la causa borbónica en la ciudad, por lo que se tuvo que enfrentar a varios regidores pro austriacos, organizando la defensa de Murcia ante el avance de la causa austracista en el sureste. Con la ciudad cercada por tropas austracistas, Belluga ordenó la inundación intencionada de la huerta para evitar que Murcia fuera tomada y organizó las milicias que vencieron en la batalla del Huerto de las Bombas, a las afueras de la ciudad. Esta victoria supuso un giro en la Guerra de Sucesión comenzando así el avance de la causa borbónica a nivel nacional que culminaría en la batalla de Almansa.

Durante el siglo XVIII Murcia vivió una importante expansión económica. La base de este crecimiento se cimentó en un impulso agrícola basado así mismo en el aumento de la superficie cultivada. Las roturaciones provocaron una mayor extensión de la huerta de Murcia y de cultivos de secano en la zona de campo, algo que trajo consigo la aparición de asentamientos humanos en dichas áreas (el origen de muchas de las actuales pedanías). Como afirma el historiador Rodríguez Llopis, Murcia alcanzó a finales de siglo la cifra de 70.000 habitantes. En este contexto de riqueza continuó teniendo un importante papel el comercio de la seda, de hecho en 1770 se instaló en Murcia la "Real Fábrica de Hilar Sedas a la Piamontesa".

La boyante coyuntura quedó reflejada en las artes y el urbanismo de la ciudad. Es la época de las iglesias y palacios barrocos y del escultor Francisco Salzillo. La expansión motivó que el primer asentamiento humano en la margen derecha del Segura se afianzara; el hoy conocido como Barrio del Carmen.

A finales del siglo XVIII, el murciano José Moñino Redondo, conde de Floridablanca fue nombrado ministro de Carlos III. Floridablanca favoreció notablemente a la tierra que le vio nacer a través de infraestructuras y medidas de carácter ilustrado.

Con el estallido de la Guerra de la Independencia española en 1808, en la ciudad de Murcia se creó una Junta Suprema presidida por el conde de Floridablanca que pretendió extender su autoridad en todo el reino de Murcia ante la ausencia del poder real.

En 1810 se produjo la entrada de las tropas francesas de Sebastiani, el día 24 de abril la ciudad fue saqueada brutalmente.
En enero de 1812 las tropas francesas del general Soult entraron también en la ciudad. En la calle de San Nicolás se produjo un encontronazo entre los soldados de Soult y las milicias del general Martín de la Carrera, que murió en dicho combate.

En febrero de 1820, tras el alzamiento de Riego que supuso el inicio del Trienio Liberal, el vizconde de Huertas orquestó con campesinos de la huerta y algunos militares el asalto a la prisión para liberar a los presos políticos, como el general Torrijos, proclamándose en la ciudad la Constitución de 1812.

Con la creación de las actuales provincias en 1833, Murcia se convirtió en capital de la de igual nombre, mientras que el antiguo reino de Murcia se dividió en las provincias de Murcia y Albacete.
En 1862 comenzaron a discurrir trenes entre Murcia y Cartagena en un viaje inaugural presidido por la reina Isabel II, y en 1865 la ciudad ya estaba conectada por ferrocarril con Albacete y Madrid. La llegada de este medio de transporte supuso una ampliación urbana hacia el sur, desarrollándose más aún el mencionado Barrio del Carmen.

Durante el Sexenio Democrático, se produjeron dos levantamientos en Murcia de carácter federal, el primero en 1869 y el segundo en 1872, dirigidos ambos por el revolucionario Antonio Gálvez Arce, conocido popularmente como "Antonete Gálvez". En el verano de 1873 la ciudad se unió al "Cantón Murciano" que se había proclamado en la sublevación cantonal de Cartagena, siendo uno de los principales conflictos a los que se tuvo que enfrentar la I República Española.

El 15 de octubre de 1879 acaeció la conocida como riada de Santa Teresa, una de las mayores de la historia de Murcia, la región murciana y toda la cuenca del Segura, que produjo cerca de 800 muertos en la ciudad y su huerta.

En los años de la II República, Murcia fue una ciudad con voto mayoritario de izquierdas en las sucesivas elecciones que tuvieron lugar. Durante la guerra civil, la ciudad permaneció fiel a la República hasta el 29 de marzo de 1939 cuando la IV División Navarra al mando de Camilo Alonso Vega tomó Murcia, apenas dos días antes del final de la contienda, en la llamada Ofensiva final.

Durante la dictadura franquista, tras la dura posguerra Murcia vivió una gran expansión urbana que le llevó a superar sus tradicionales límites bajo el sello del desarrollismo de la época, a costa de la huerta circundante y de parte del casco histórico.

Con la llegada de la Transición y la nueva organización territorial por autonomías, la ciudad se convirtió en capital de la comunidad autónoma de la Región de Murcia, siendo sede de la presidencia y las consejerías, no así del parlamento, sito en la ciudad de Cartagena.

El crecimiento económico de los años 60 y 70, vino acompañado de un auge demográfico que llevó a la ciudad a crecer a gran velocidad y crear infraestructuras viarias acorde con las nuevas necesidades. En la última década del siglo XX y aproximadamente la primera del siglo XXI, la creación de nuevos barrios, avenidas y costeras, han transformado la ciudad, que se ha convertido el séptimo municipio por población de España y en un importante centro de negocios. La Crisis económica de 2008-2015, ha ralentizado este crecimiento. Actualmente se buscan nuevos modelos turísticos y formas de atraer inversiones a la ciudad.

El municipio de Murcia contaba en 2015 (INE) con 439.889 habitantes, siendo el . Sin embargo, debido a la gran extensión del término municipal (881,86 km²), su densidad demográfica (498,82 hab./km²) está lejos de los primeros puestos.

Del total de la población del municipio en 2015, 168.925 personas residían en el distrito de la capital (que con una superficie de 11,88 km² contaría con una densidad de 14.222 hab./km²), lo que representa un 38% del total municipal, repartiéndose el 61% restante (270.964 personas) entre las 54 pedanías. Algunas de éstas han sido anexionadas de facto por la expansión urbana de la ciudad, constituyendo auténticos barrios aunque administrativamente sigan siendo pedanías, por lo que su población no se computa junto a la del distrito de la capital, caso de Los Dolores, San Benito, Zarandona, Puente Tocinos, Santiago y Zaraiche o El Puntal. Si se sumara la población de esta conurbación al distrito de la capital, la ciudad estaría en torno a los 226.000 habitantes (el 51% del total municipal).

La mayoría de las pedanías tienen varios núcleos de población hasta alcanzar un total ampliamente superior a los 100 núcleos en el conjunto del municipio. Esto, sumado a la existencia de numerosos diseminados, indica una población muy dispersa. En el nomenclátor del INE aparecen 157 núcleos de población, pero en ese total están incluidos 28 que, en realidad, son barrios de la capital y uno más que aparece sin población, lo que dejaría el total en 128 núcleos habitados.

Dentro de las dos grandes zonas en las que se divide el municipio, el Campo de Murcia y la Huerta de Murcia, es en esta última donde se localiza la gran mayoría de las pedanías (45) y de la población (93,57% si incluimos la población de núcleo urbano), por lo que la densidad en la Huerta de Murcia es mucho mayor que la del Campo de Murcia o la del cómputo total del municipio (816 hab./km² frente a 75 hab./km²) siendo por tanto el poblamiento mucho más denso que en el Campo de Murcia. La tipología de poblamiento también es muy diferente: en las pedanías de la Huerta la densidad de población es alta con numerosos núcleos de población, algunos de ellos de gran tamaño, cercanos entre sí y muchas viviendas dispersas fuera de los núcleos, lo que produce un paisaje que, o bien es urbano, o tiene la constante presencia de viviendas; en las pedanías que no son de la Huerta (las del Campo de Murcia junto a las del Campo de Sangonera) la densidad de población es mucho más baja con pocos núcleos de población, todos de pequeño tamaño, y grandes zonas libres de población.

Fue a finales del siglo XVIII cuando se realizó el primer censo, ordenado por el Conde de Floridablanca. Murcia se componía entonces de 63.665 habitantes (1787). En el Siglo XX ha mantenido una evolución positiva constante, salvo en los años sesenta, con un ligero descenso.

De acuerdo con los datos oficiales del INE, en el año 2015 el 11,97% de la población del municipio era de nacionalidad extranjera, concretamente 49.152 personas, siendo las comunidades más importantes las formadas por ciudadanos marroquíes, ecuatorianos, ucranianos, bolivianos, rumanos, búlgaros, chinos, colombianos, británicos y argelinos.

Evolución demográfica del municipio de Murcia desde 1842:

Murcia es el centro de un área metropolitana que, si bien no está delimitada administrativamente, si está reconocida como área urbana por el Ministerio de Fomento de España. La extensión y población de esta área dependen de cada estudio realizado al respecto, pero el del Ministerio incluye dentro de la misma a los municipios de Alcantarilla, Alguazas, Archena, Beniel, Ceutí, Lorquí, Molina de Segura, Santomera y Las Torres de Cotillas. Esta área estaría formada por 10 municipios, con una población de 646.810 habitantes en 2017 (siendo la décima más poblada de España), distribuidos en una superficie de 1.230,9 Km2 y contando con una densidad de 525 hab/km2.

El proyecto AUDES5 también define la conurbación de Murcia-Orihuela, la cual, integraría la aglomeración metropolitana anteriormente descrita de Murcia, Molina de Segura y Alcantarilla junto al área urbana de Orihuela. Esta área metropolitana suprarregional contaría con una población total de 776.784 habitantes (INE 2009), una superficie de 1.787 km² y una densidad de 445,54 hab/km², por lo que sería la séptima de España.

De forma tradicional el municipio de Murcia fue un importante productor de materia prima agrícola gracias a su feraz y milenaria huerta. Durante la primera mitad del siglo XX su agricultura se convirtió en especializada e intensiva, permitiendo comercializar sus productos en mercados internacionales, algo que se intensificó en las décadas de 1950 y 1960. El municipio de Murcia participó en la exportación de tomates, lechuga y, especialmente limones y naranjas a toda Europa junto con otros muchos municipios de la Región de Murcia. Pese a que este sector fue antaño la base económica del municipio, su importancia es ahora mucho menor tras la terciarización vivida a partir de los años 60-70, la redistribución regional del suelo agrícola tras la llegada del Trasvase Tajo-Segura (concentrando la producción en otras comarcas anteriormente de secano y poco productivas, entre ellas el Campo de Murcia perteneciente al municipio) y la expansión urbana. Estos factores han generado la desaparición casi total en algunas zonas de la huerta de Murcia y su degradación paisajística actual.

El principal sector económico de Murcia es el sector servicios, de los que destacamos los administrativos, financieros, culturales y de otro tipo. Históricamente la ciudad de Murcia siempre ha sido un centro de intercambio comercial, ejerciendo de redistribuidor de la producción agrícola y artesanal del interior murciano y del sureste ibérico. A partir de finales de la década de 1960 y comienzos de la de 1970, la terciarización en el municipio comenzó a ser omnipresente. En 1991, la ciudad era junto con los municipios de la costa, donde más elevados porcentajes de empleo se daban en el sector servicios en el Levante meridional. Murcia actúa hoy como centro de intercambio comercial de toda la Región de Murcia y de toda la cuenca del Segura, y su área de influencia se extiende a las provincias limítrofes: Alicante, Albacete y Almería.

El sector secundario industrial apareció con fuerza en el municipio de Murcia a comienzos del siglo XX a través de sectores derivados de su potente agricultura. En la antigüedad, el sector sericícola de tipo pre-industrial tuvo una fuerza importante en el municipio, pero decayó durante el siglo XIX. Entre 1900 y 1930 se vivió la época dorada de la industria del pimentón, con firmas como "F.F." o "Albarracín". Tras la profunda crisis de la posguerra y la autarquía, en la década de 1960, los productores murcianos consiguieron el liderato en España, constituyendo la mitad de la oferta nacional. Las factorías pimentoneras capitalinas se concentraban fundamentalmente en el barrio de Espinardo, al norte de la ciudad. El sector de la conserva vegetal murciana alcanzó el liderato español hacia 1930, recuperándose de la crisis de posguerra en la década de 1950 y alcanzando un nuevo apogeo en la de 1960, hasta mediados de la década de 1970.

Actualmente, la actividad industrial del municipio se concentra en los polígonos industriales de Cabezo Cortao, Camposol y el polígono Oeste. Siendo este último el más grande de la Región de Murcia, compartido con el municipio de Alcantarilla. La potente industria conservera y del pimentón dio paso tras la crisis de principios de la década de 1990 a un sector industrial más diversificado en el que destaca el alimentario, con factorías como la cervecera "Estrella de Levante", los zumos de fruta de "Juver" o "AMC" o los gazpachos envasados "Alvalle" de PepsiCo. En la confección textil destaca la central de "Liwe Española", en la pedanía de Puente Tocinos. También son destacables los sectores químicos (con la antigua Fábrica de la Pólvora, hoy "General Dynamics - Santa Bárbara Sistemas" en Javalí Viejo), de destilación y la fabricación de muebles y materiales de construcción.

A principios del siglo XXI emergió con fuerza en el municipio el turismo residencial, orientado a ciudadanos europeos, principalmente nórdicos, localizado principalmente en el "Campo de Murcia", actividad que se ha visto frenada tras el pinchazo de la burbuja inmobiliaria.

Como capital de la Región de Murcia la ciudad es sede de la Presidencia de la Comunidad Autónoma, del Consejo de Gobierno (ambos sitos en el Palacio de San Esteban), de las distintas Consejerías, del Tribunal Superior de Justicia (sito en el Palacio de Justicia del Paseo de Garay), del Defensor del Pueblo de la Región de Murcia y el Consejo Jurídico de la Región de Murcia (ambos con sede en la calle Alejandro Seiquer) además del Consejo Económico y Social (CES).

Por parte del Gobierno de España también es sede de la Delegación del Gobierno en la comunidad autónoma, así como de la Confederación Hidrográfica del Segura.

Desde la restauración de los ayuntamientos democráticos en 1979, el gobierno de la ciudad estuvo en manos de diversos alcaldes del PSRM-PSOE hasta 1995, fecha en la que se hizo con la alcaldía el Partido Popular.

En la actualidad el alcalde es José Ballesta Germán (PP), quien gobierna en minoría tras la abstención de los ediles de Ciudadanos en la votación de investidura.

En las elecciones municipales de 2015, de los 29 concejales a elegir:

El territorio del municipio de Murcia se organiza administrativamente en el núcleo urbano de la capital y 54 pedanías.

El distrito de la capital ocupa 11,88 km² del total del término municipal y se divide en 28 , agrupados a su vez en 8 distritos.

Dichos barrios son: En la margen derecha del Segura, pertenecientes al distrito de "El Carmen", los barrios de El Carmen, Buenos Aires y Nuestra Señora de la Fuensanta, el distrito de "Infante Don Juan Manuel", con el Polígono del mismo nombre, mientras que los barrios de Santiago el Mayor, San Pío X y La Purísima-Barriomar no forman parte de distrito alguno. 

En la margen izquierda se hallan los distritos de "La Flota-Vistalegre", formado por los barrios de Vistalegre y La Flota, el distrito "Este", formado por los barrios de La Paz, Vistabella y La Fama, el distrito "Santa María de Gracia-San Antonio", con los barriadas de Santa María de Gracia y San Antonio. Los barrios de San Basilio, El Ranero y San Antón forman parte del distrito "Norte". El barrio de Espinardo no forma parte de ningún distrito.

También en la margen izquierda se encuentran los 10 barrios del centro histórico, que corresponden a las 10 parroquias originarias de la ciudad medieval y sus arrabales: San Andrés (que forma parte del distrito "Norte"), San Antolín, San Miguel, San Nicolás, San Pedro y Santa Catalina (que forman el distrito "Centro-Oeste"), San Juan, San Lorenzo, Santa Eulalia y San Bartolomé-Santa María (que constituyen el distrito "Centro-Este").

Mientras que cada distrito poseen su respectiva Junta de Distrito, aquellos barrios que no forman parte de ningún distrito poseen en su lugar una Junta Municipal, de la misma forma que las pedanías del municipio.

Actualmente, la extensión del núcleo urbano de la ciudad de Murcia supera ampliamente su distrito administrativo, habiéndose extendido por la práctica totalidad de la pedanía de Santiago y Zaraiche, formando también un continuo urbano con San Benito (formada por el Barrio del Progreso y Patiño) y con el núcleo de El Puntal. La colmatación del distrito de la ciudad ha llevado a que los nuevos desarrollos invadan territorio que realmente pertenece a diversas pedanías cercanas como Zarandona, Los Dolores, Churra, Puente Tocinos o El Puntal.

A lo largo de los siglos se han producido diversos cambios en el mapa municipal. Varias pedanías se convirtieron en concejos independientes durante el Trienio Liberal (1820-1823), volviendo a integrarse a partir de los años 1830 en adelante ante su falta de sostenibilidad económica, mientras que los de la comarca del Mar Menor (San Pedro del Pinatar, San Javier y Torre-Pacheco) quedaron definitivamente segregados en 1836.

En 1960 y debido a la fuerte expansión urbana de la capital, la mayor parte de la antigua pedanía de Espinardo se incorporó al distrito de la ciudad como barrio. Lo que no se anexionó constituye actualmente la pedanía de El Puntal.

En 1978 se segregó la pedanía de Santomera y se constituyó en un nuevo municipio que incluía El Siscar y La Matanza.

En 1987, una superficie de 10,2 km² de la pedanía de Cañada Hermosa se incorporaron al municipio de Alcantarilla.

El edificio más emblemático de la ciudad es la Catedral de Santa María, sede de la diócesis de Cartagena que se encuentra en pleno casco antiguo, en la Plaza de Belluga. Comenzó a construirse sobre la antigua mezquita mayor o "aljama" en el siglo XIV, y se consagró en 1467, aunque diversas partes fueron añadidas o reformadas hasta finales del siglo XVIII, cuando se terminó su famosa torre. Por este motivo presenta diferentes estilos arquitectónicos, especialmente gótico, renacentista y barroco.

Su ornamentada fachada principal (1737-1754), proyectada como un retablo al aire libre, es considerada a menudo una obra maestra del barroco levantino español. Destaca también su alto campanario, de 93 metros (98 con la veleta) siendo el segundo más alto de las catedrales de España tras la Giralda de Sevilla y dotado de veinte campanas que antaño también anunciaban las terribles avenidas del río Segura. Éste muestra una mezcla de estilos arquitectónicos: los dos primeros cuerpos son de estilo renacentista (1521-1555), el tercer cuerpo es barroco y el cuerpo del campanario y la cúpula son de influencias rococó y neoclásicas.

El interior del templo es mayoritariamente gótico. Destacan la "Capilla de los Vélez" y la "Capilla de Junterones" de un total de veintitrés. La primera es de estilo gótico flamígero, con una impresionante cúpula estrellada de diez puntas, y la otra es una de las grandes obras del renacimiento español. La capilla de los Vélez sobresale por el exterior de la catedral, destacando la cadena esculpida que la rodea y sobre la que pesa una famosa leyenda.
En la capilla mayor se encuentra el sepulcro con el corazón y las entrañas de Alfonso X el Sabio.

La Catedral cuenta con un renovado museo (Museo de la Catedral de Murcia) en el edificio que antaño fuera el claustro y en el que se exhibe el tesoro catedralicio.

Junto a la fachada de la catedral, en la misma Plaza de Belluga, se encuentran la Escuela Superior de Arte Dramático y Danza (antiguo Seminario Mayor de San Fulgencio) y el Palacio Episcopal, ambos del siglo XVIII. El majestuoso palacio se divide en dos partes: el cuerpo central articulado sobre un patio porticado y el denominado "Martillo", que fue el mirador de los obispos sobre el Segura y sus jardines y que constituye el cerramiento arquitectónico del contiguo "paseo del Arenal", actual Glorieta.

A pocos metros de la Catedral y Belluga, al lado del río Segura, se encuentra la referida plaza de La Glorieta, que ha sido tradicionalmente el centro político de la ciudad. Construida en el siglo XVIII, es un espacio ajardinado donde se encuentra la Casa Consistorial (siglo XIX), con un edificio anexo que da a la Plaza Belluga, obra señera de Rafael Moneo.

Aún es posible apreciar el antiguo entramado urbano medieval de época andalusí, antaño divisorio de religiones y ahora reconvertido en bellas calles peatonales, como la Platería y la famosa Trapería, la cuál comunica la "Plaza de la Cruz" (donde se encuentra la torre de la Catedral) con la conocida Plaza de Santo Domingo, uno de los puntos de encuentro más apreciados por los murcianos. En la misma Trapería puede observarse la bella fachada ecléctica del Casino (fundado en 1847), con un interior suntuoso que aúna diferentes estilos, desde un patio árabe inspirado en los salones reales de La Alhambra y en los Reales Alcázares de Sevilla, pasando por un patio romano-pompeyano, una maravillosa biblioteca inglesa con más de 20.000 volúmenes y un bellísimo salón de baile neobarroco, entre otras estancias.

En la susodicha Plaza de Santo Domingo, podemos contemplar la Casa Cerdá; imponente inmueble de estilo ecléctico del primer tercio del siglo XX, además del bello conjunto formado por el Palacio Almodóvar (del siglo XVII pero reformado en 1908) y el arco que lo comunica con la Capilla del Rosario (siglo XVI) y la contigua Iglesia de Santo Domingo (siglo XVIII).

Otras plazas con encanto son la cercana Plaza de Julián Romea; donde además del teatro de igual nombre se asoman algunos palacetes como el Palacio Vinader (del siglo XVIII), la Plaza de las Flores, punto neurálgico del tapeo en Murcia, y su vecina la Plaza de Santa Catalina; que hasta el siglo XVIII era considerada como la plaza mayor de la ciudad.

Uno de los monumentos más importantes de Murcia es el Monasterio de Santa Clara la Real, construido entre los siglos XIV y XVIII y en cuyo interior se encuentran los restos del al-Qasr al-Sagir (Alcázar Seguir), un palacio árabe del siglo XIII del que se han recuperado la alberca, los arriates y parte del salón norte (visitables a través del Museo de Santa Clara), destacando también un claustro gótico final.

Por todo el casco antiguo se alzan numerosas iglesias o conjuntos monásticos de gran valor. Además de las construcciones góticas ya señaladas como la Catedral o el Monasterio de Santa Clara, destaca la antigua Ermita de los Pasos de Santiago, con artesonado mudéjar.

Del renacimiento, además de la mencionada Capilla del Rosario, destaca el Colegio de San Esteban, primer colegio jesuita en España comenzado en 1555, sede actual del Gobierno autonómico bajo el nombre de "Palacio de San Esteban", del que destacan su iglesia y claustro. De principios del siglo XVII encontramos la Iglesia de San Pedro y el claustro del antiguo Convento de la Merced. De la misma centuria son la Iglesia de Jesús, sede de la Cofradía de "Los Salzillos", la iglesia del mencionado Monasterio de Santa Clara, el antiguo Convento de San Antonio y la "Capilla de la Arrixaca" de la Iglesia de San Andrés.

Dentro del barroco murciano desarrollado principalmente durante el siglo XVIII, hay que reseñar desde los primeros ejemplos de finales del XVII y principios de la siguiente centuria como la Iglesia de San Miguel, el Convento de las Agustinas del Corpus Christi o las iglesias de los ya referidos conventos de la Merced, Santo Domingo o Santa Ana; hasta las posteriores iglesias de influencia rococó (tras el impacto que supusieron las obras de la fachada principal de la Catedral en la ciudad) como el Carmen, San Nicolás de Bari, Santa Eulalia y San Juan de Dios (o también el Hospicio de Santa Florentina, el mencionado Seminario Mayor de San Fulgencio, el Seminario Menor de San Leandro, la portada y claustro del Colegio de la Anunciata -posterior Real Fábrica de Seda- o el Antiguo Colegio de Teólogos de San Isidoro). 

Las tendencias neoclásicas llegaron a la ciudad de la mano de la Iglesia de San Juan Bautista, además de las iglesias de San Lorenzo y San Bartolomé, adentrándose estas dos últimas en el siglo XIX, completándose San Bartolomé con fachada y nave historicista.

De la época musulmana en Murcia, además de los referidos restos del Alcázar Seguir, encontramos los restos de la mezquita y el panteón real del Alcázar Nasir del siglo XII. También dispone de diferentes tramos de la muralla árabe mandada edificar por Ibn Mardanis (siglo XII) para proteger a la capital de su reino, destacando el tramo de la "muralla de Verónicas" y el que se conserva dentro del "Centro de Interpretación de la muralla de Santa Eulalia". También hay que destacar el reciente hallazgo del arrabal de la Arrixaca en el antiguo jardín de San Esteban, del siglo XII y XIII, cuya musealización está en proyecto.

Dentro de los inmuebles de la ciudad, como ejemplos del renacimiento destacan el Palacio Pacheco y las portadas del derruido Palacio Riquelme. Del auge de la seda que vivió Murcia a comienzos del siglo XVII quedan, además del Palacio Almodóvar, las muestras del Palacio del Almudí, antiguo pósito municipal, hoy sala de exposiciones, y las portadas del derruido Contraste de la Seda. Avanzado el siglo se construyó el Palacio de los Saavedra, actual Colegio Mayor Azarbe.

Del siglo XVIII murciano y su característica arquitectura barroca-rococó hay que resaltar el Palacio de Fontes, sede de la Confederación Hidrográfica del Segura, el Palacio de los Pérez-Calvillo, además de los referidos palacios Episcopal y Vinader. De finales de siglo y adquiriendo tintes neoclásicos encontramos el Palacio de Floridablanca, actual Hotel "Arco de San Juan", el Palacio Campuzano y el Palacio de la Inquisición, sede del Colegio de Arquitectos, ya del XIX.

Del eclecticismo decimonónico encontramos el ya mencionado Real Casino de Murcia, el Teatro Romea; inaugurado en 1862 pero reconstruido tras varios incendios siendo el exterior de 1880 y el interior de 1899, o la Plaza de toros de La Condomina, inaugurada en 1887 (ambos del arquitecto Justo Millán).

Habría que incluir dentro de las corrientes modernistas que llegaron a la ciudad el Mercado de Verónicas, plaza de abastos de principios del siglo XX; además de la Casa Díaz-Cassou, la Casa Almansa (actual Cámara de Comercio) y la Casa Guillamón, obras de los arquitectos Pedro Cerdán (autor de la fachada del Casino) y J. A. Rodríguez. Sin embargo el eclecticismo continuó teniendo presencia a principios de dicho siglo con la Convalecencia, el Cuartel de Artillería o la ya mencionada Casa Cerdá, así como ejemplos de inspiración neoyorquina como la Casa de los Nueve Pisos.

Dentro de la arquitectura de vanguardia desarrollada a partir de la década de 1930, también se hace necesario destacar el "Edificio de cinco plantas de la Calle Trapería" del famoso arquitecto Pedro Muguruza, construido en 1935 en una línea de regionalismo castizo, siendo del mismo autor y estilo el antiguo edificio de Correos. Dentro del racionalismo también se encuentra la "Casa de seis plantas de la Calle Trapería" de José Luis de León y Díaz-Capilla (1934-1941) -del mismo autor es el edificio llamado ""El Acorazado"" de la Plaza Santo Domingo- o el Edificio Coy, de Gaspar Blein (1935).

Varios puentes de diversos estilos atraviesan el río Segura a su paso por Murcia, desde el más antiguo (del siglo XVIII) hasta varios de reciente creación de afamados autores contemporáneos.









También resulta de especial interés como elemento arquitectónico relacionado con el río Segura el popular Paseo del Malecón, antiguo muro de defensa contra las inundaciones y avenidas de agua, de origen medieval pero convertido en paseo durante el siglo XVIII.

Dentro de los principales parques y jardines de la ciudad, destacan:





En el resto del municipio son de reseñar el barroco Monasterio de los Jerónimos (en la pedanía de Guadalupe), y sobre todo el Santuario de la Fuensanta (en la pedanía de Algezares), donde se venera a la Virgen de la Fuensanta, patrona de la ciudad. Junto al Santuario, un amplio mirador nos permite contemplar una panorámica que abarca toda la ciudad, la vega del Segura y las sierras que la rodean. El Santuario está dentro del parque regional de Carrascoy y El Valle. Este parque, situado a menos de 5 km del casco urbano tiene una elevación máxima de 1065 metros. En El Valle se pueden practicar la escalada y el senderismo y realizar varias visitas tomando como punto de partida el Centro de Visitantes de La Luz. En él podremos conocer la flora y la fauna del lugar, la historia de los monasterios de la zona (San Antonio el Pobre, el Eremitorio de la Luz, Santa Catalina del Monte), así como de los yacimientos y restos arqueológicos de época íbera que dispone el parque: el Santuario ibérico de la Luz; visitable en la actualidad, y la necrópolis del Cabecico del Tesoro. En las mismas faldas de la sierra también se encuentran restos de época tardo-romana-visigoda, como el Martyrium de La Alberca o la Basílica del Llano del Olivar. Y también los restos de varios castillos musulmanes como el Castillo de la Luz, el Castillo de la Asomada, y el Castillo del Portazgo.

En la parte norte de la ciudad, en la pedanía de Monteagudo, se encuentra el Centro de Visitantes de San Cayetano, sito sobre el yacimiento del mismo nombre formado por un poblado de la Cultura del Argar y un posterior asentamiento íbero además de restos romanos.
También destacan en esta pedanía los restos del llamado Castillejo (palacio de Ibn Mardanis) y del Castillo de Monteagudo, también de época andalusí, coronado por un gran Cristo construido en 1951. De orígenes árabes es la noria hidráulica de La Ñora, muestra de la explotación milenaria de la huerta de Murcia, cuya red de riego comienza en la antiquísima Contraparada (situada entre las pedanías de Javalí Nuevo y Javalí Viejo).

En el ámbito cultural de la ciudad, destaca la existencia de dos universidades, una pública y otra privada; numerosos museos, cines y teatros, sus concurridas fiestas populares e importantes festivales.

En el término municipal de Murcia hay varios teatros, entre los que destaca el Teatro Romea. Situado en la plaza de Julián Romea, fue inaugurado en 1862 por la reina Isabel II. Llamado inicialmente "Teatro de los Infantes" y luego "Teatro de la Soberanía Popular", para finalmente adoptar su nombre actual en honor al actor murciano Julián Romea.

Otros espacios escénicos destacados son el Teatro Circo, inaugurado en 1892 y que tras décadas de abandono ha vuelto a abrir sus puertas tras una profunda rehabilitación; el Auditorio y Centro de Congresos Víctor Villegas inaugurado en 1995; y el Teatro Bernal situado en la pedanía de El Palmar.

La Red de Auditorios Municipales cuenta con el Auditorio de Beniaján, el Auditorio de Cabezo de Torres y el Auditorio de La Alberca, con una amplia oferta de teatro y música; a ellos hay que agregar otros dos auditorios de reciente construcción: el de Algezares y el de Guadalupe.

La ciudad ha visto cómo han ido desapareciendo los cines de barrio y los situados en el centro, hasta el punto de que desde 2006 sólo permanecían abiertos al público en esta zona el cine Rex, los cines Centrofama y la Filmoteca Regional de Murcia "Francisco Rabal" (antiguo cine Salzillo).

Años antes abrieron los primeros multicines, los de Atalayas y Zig Zag, ambos ya cerrados. En 2006 se inauguraron unos de última generación en los complejos comerciales Nueva Condomina y Thader, al norte de la ciudad. En este último se abrió la sala Xpand 6D, la primera en España que combinaba la proyección en 3D con butacas móviles SFX y efectos de lluvia, viento, luz, niebla y olor. Posteriormente se abrieron otros multicines en el centro comercial El Tiro.

La ciudad de Murcia tiene dos universidades: la Universidad de Murcia (UMU) y la Universidad Católica San Antonio de Murcia (UCAM).

La Universidad de Murcia es una universidad pública. Tiene su origen en 1272, aunque su fundación definitiva fue en 1914. Está formada por cinco campus de los cuales tres se encuentran en el municipio: el de la Merced, en el casco urbano; el de Espinardo; y el de Ciencias de la Salud en El Palmar. Hay un cuarto campus en el municipio de San Javier y un quinto en Lorca. En la institución estudian unos 38.000 alumnos.

La UCAM es una universidad privada católica fundada en 1996. Tiene su campus en el Monasterio de los Jerónimos en la pedanía de Guadalupe.

Dentro de la educación superior, la capital murciana alberga el Conservatorio Superior de Música de Murcia y la Escuela Superior de Arte Dramático y Danza de Murcia (ESAD).

Murcia cuenta con una gran cantidad de museos, muchos de ellos reformados recientemente, como el Salzillo, el Bellas Artes o el Museo Arqueológico. A destacar el Museo de Santa Clara, inaugurado en 2005 en el interior del conjunto monumental del Monasterio del mismo nombre.

Los diferentes museos de la ciudad de Murcia son:

Murcia acoge la celebración de varios festivales de distintos ámbitos culturales:





La Virgen de la Fuensanta es la patrona principal de la ciudad de Murcia. Constituye una de las advocaciones marianas más relevantes del levante peninsular. Es protagonista de dos romerías al año que trasladan a la imagen desde su Santuario a la Catedral y otras dos de vuelta que se desarrollan de cara a las festividades importantes que tienen lugar en la ciudad, en primavera (Semana Santa y Fiestas de Primavera) y septiembre (la Feria de Septiembre), siendo esta última la más multitudinaria.

El dialecto murciano es el dialecto romance tradicional e histórico de la Región de Murcia que tiene sus orígenes en el Reino de Murcia en los siglos XIII y XIV cuando diversas variantes lingüísticas (romance andalusí, árabe, castellano, catalán, aragonés, etc) se fundieron para dar lugar al dialecto murciano.

Algunos lingüistas lo clasifican como dialecto del español, por otro lado la RAE hasta hace poco consideraba al murciano como un dialecto del aragonés, mientras que fuentes catalanas sostienen que el murciano es un dialecto de transición entre el castellano y el catalán.

La variante comarcal del dialecto murciano, típica de los valles del Segura, es la que popularmente se ha venido denominando como "panocho", de la que participa el municipio de Murcia a pesar de la estandarización creciente del castellano normativo que se habla en él.

Los principales hospitales del municipio de Murcia son los siguientes:

Desde abril de 2015 existe MuyBici, un Sistema de Transporte Público en bicicleta que persigue fomentar el uso de la misma como medio de transporte eficiente y saludable en la ciudad, contribuyendo a que los desplazamientos sean más sostenibles. Este es un Plan Experimental puesto en marcha por el Ayuntamiento para lograr la reducción del uso del vehículo privado y potenciar otros medios de transporte no motorizados, como el transporte público, el desplazamiento a pie o la propia bicicleta. No es un sistema público de alquiler de bicicletas para uso turístico o recreativo. Es un complemento al transporte público. Su finalidad es cubrir los pequeños desplazamiento que a diario se producen por dentro de la ciudad.

El anterior Alcalde de Murcia, Miguel Ángel Cámara, firmó un Protocolo de Actuaciones con el presidente de Iberdrola, Ignacio Sánchez Galán, para la ejecución del proyecto piloto del vehículo eléctrico, que convertirá a Murcia en referente en la implantación de este medio de transporte. Asimismo, el Ayuntamiento, a través de ALEM, se encargará de elaborar un plan que contemple la previsión de la demanda de carga y la disponibilidad de puntos y tipos de recarga en los espacios públicos. La fiscalidad municipal recoge desde 2008 una bonificación del 30% en el impuesto de vehículos durante los tres primeros años para los coches eléctricos o con bajas emisiones contaminantes. El ayuntamiento está adquiriendo 8 coches eléctricos que se destinarán a varios servicios municipales. Por otra parte, la licitación del servicio de limpieza viaria y recogida de residuos recogerá en el pliego de condiciones la obligación de incorporar a la flota vehículos eléctricos

Existen diversos medios de transporte público disponibles en la ciudad y en el municipio de Murcia.

Murcia cuenta con una estación de autobuses situada en el barrio de San Andrés. Dispone conexiones a diversos destinos regionales, nacionales e internacionales.

Las líneas de autobús en el municipio están divididas en dos concesiones: una para las líneas urbanas (gestionada por el Ayuntamiento) y otra para líneas interurbanas (gestionada por el gobierno regional).

La empresa concesionaria de es Transportes de Murcia, una UTE entre Martín, Ruiz y Fernanbús (Grupo Transvía). Los vehículos son de color grana, por lo que se les conoce coloquialmente como 'los coloraos'.

Actualmente prestan servicio 10 líneas:

La empresa concesionaria de las líneas interurbanas (hacia las pedanías y otros municipios cercanos) es LAT. Opera 35 líneas y cuenta con una flota de más de 100 unidades.

En relación con la intermodalidad, el servicio público de alquiler de bicicletas de Murcia no posibilita la intermodalidad. Por otro lado, el Plan de Movilidad Urbana Sostenible del Ayuntamiento de Murcia no contempla la implantación de portabicicletas, la subida de bicicletas plegables, la conexión con el autobús y las tarjetas que integran los diversos servicios de movilidad (tren cercanías, autobús regional, autobús urbano, alquiler de bicicletas), como ya ocurre en otras comunidades autónomas como Asturias.

A diferencia de otros municipios, aún no se ha puesto en marcha ningún plan piloto de autobús eléctrico.

Hasta 2012 existió la Entidad Pública del Transporte (EPT). Fue pionera a nivel nacional al poner en marcha un nuevo sistema de pago en la flota pública de autobuses con el teléfono móvil que permitía sustituir al bonobús, y que empleaba la tecnología NFC (Near Field Communication) para poder, además, recargar o consultar el saldo, así como conocer los últimos movimientos.

Murcia cuenta con una línea de tranvía metropolitano inaugurada en mayo de 2011, cuatro años después del estreno de un tramo experimental que recorría la Avenida Juan Carlos I.

La línea actualmente en servicio une la Plaza Circular con los campus de las universidades UMU y UCAM, en Espinardo y Guadalupe respectivamente, y los centro comerciales y el Estadio Nueva Condomina sitos entre las pedanías de Churra y Cabezo de Torres, formando una gran V en el norte de Murcia. Esta línea forma parte de un proyecto que incluye otras tres líneas por construir.

Murcia cuenta con una estación de ferrocarril, denominada "Murcia del Carmen" y situada en el barrio del mismo nombre.

Varias líneas de largo recorrido comunican la ciudad con Madrid, vía Albacete, así como con la Comunidad Valenciana y Cataluña. "Murcia del Carmen" es asimismo el centro de una red de Cercanías, denominada Cercanías Murcia/Alicante. La línea C-1 conecta la ciudad con Alicante a través de Orihuela y Elche, y la C-2 la une con Lorca y Águilas a través de Alcantarilla y Totana, atravesando una parte de la provincia de Almería en el ramal que lleva a la localidad costera de Águilas.

También cuenta con una línea Regional que la enlaza con Cartagena, y otra de Media Distancia que llega hasta Valencia y Zaragoza.

Hasta el año 1985 existía una conexión directa con la ciudad de Granada y Andalucía. Era el llamado ferrocarril del Almanzora. En los últimos años debido al nuevo auge del transporte por ferrocarril existen planes para volver a poner en funcionamiento la línea, conectando así el arco mediterráneo con el puerto de Algeciras.

Están en fase de ejecución varias líneas ferroviarias de alta velocidad que integrarán a Murcia en dos grandes líneas de alta velocidad: el Corredor Mediterráneo que se extenderá desde la frontera francesa hasta Cádiz y Algeciras; y la Línea de alta velocidad Madrid-Levante que unirá la capital española con Valencia, Alicante, Murcia, Cartagena y Almería. El proyecto incluye el de las vías a su paso por la ciudad.

El municipio también cuenta con la estación de Murcia-Cargas, en la pedanía de Nonduermas, siendo la terminal de carga para mercancías de Renfe, contando también con unos talleres ferroviarios y con la Aduana de mercancías.

En la ciudad existía otra estación (esta de tipo término), la de Murcia Zaraiche, también denominada "Estación de Caravaca", cabeza del antiguo ferrocarril Murcia-Caravaca, hoy desmantelado. El antiguo edificio de la estación es hoy la sede de la empresa municipal Aguas de Murcia, situado en la Plaza Circular.

El municipio de Murcia no cuenta con aeropuerto propio debido a la cercanía de los aeropuertos de San Javier (a 45 km de la capital por autovía) y de Alicante-Elche (a 70 km).
Sin embargo, hay un nuevo aeropuerto ubicado en la pedanía de Corvera, a 23 km de Murcia, que actualmente se encuentra sin uso, el Aeropuerto Internacional de la Región de Murcia.

A día de hoy la apertura de este aeropuerto se encuentra bloqueada sine die debido a los problemas entre la concesionaria privada y el ejecutivo regional, a lo que se ha unido el hecho de que su viabilidad iría unida a un traslado de las operaciones desde San Javier hacia este aeropuerto, algo que dependería de la predisposición de AENA y del pago de una indemnización.

Las siguientes autovías tienen parte de su trazado en el municipio de Murcia:

Las siguientes carreteras nacionales tienen parte de su trazado en municipio de Murcia:

Murcia cuenta con una Agencia Local de la Energía y el Cambio Climático. En el marco de la labor que ejerce la Agencia, el Ayuntamiento va a desarrollar la Estrategia Local Contra el Cambio Climático del municipio.

La nueva Ordenanza Municipal de Captación Solar establece que los nuevos edificios, a aquellos edificios que se rehabiliten y a las piscinas de nueva construcción o aquellas ya construidas que deseen instalar un sistema de climatización de agua, estarán obligados a que el agua caliente provenga de energía solar y, como novedad, se incluye también a los bajos comerciales, algo que no recoge el Código Técnico de la Edificación. Uno de los artículos de la Ordenanza Municipal de Captación Solar trata sobre la protección del paisaje y obliga a adoptar medidas que atenúen al máximo el impacto visual de las placas solares, consiguiendo la adecuada integración al paisaje.

Murcia pertenece a la Red Española de Ciudades por el Clima.

Por otro lado, existe un proyecto para que las nuevas farolas instaladas en la ciudad funcionen con energía solar fotovoltaica se están instalando marquesinas con placas solares en su techo para su alumbrado nocturno sin consumo de la red de energía eléctrica

El Ayuntamiento ha sacado a concurso tres parcelas de propiedad municipal, con el objetivo de que los adjudicatarios instalen plantas de energía solar. Las dimensiones de las parcelas son: Gea y Truyols con 5,6 hectáreas, La Peraleja en Sucina cuenta con 43 hectáreas y la finca El Escobar en Jerónimo y Avileses con 100 hectáreas.


La ciudad cuenta con uno de los equipos históricos del fútbol español, el ya centenario Real Murcia. Juega en el estadio de fútbol de propiedad municipal de la Nueva Condomina.




En 2006, Murcia fue sede de dos campeonatos del mundo:

En 2001, Murcia fue sede del VI Festival Olímpico de la Juventud Europea, donde participaron 2.500 jóvenes deportistas sub-18 de 46 países europeos y compitieron en diez modalidades deportivas diferentes. Murcia fue elegida por el Comité Olímpico Europeo en una reunión celebrada en Estocolmo, en noviembre de 1997. La ceremonia inaugural del Festival se celebró en la gran plaza central del antiguo Cuartel de Artillería el día 22 de julio de 2001.

En torno al centro de Murcia se halla el núcleo tradicional del comercio de la ciudad, pudiéndose encontrar desde el pequeño comercio hasta las franquicias de grandes marcas. En la ciudad se pueden encontrar tres centros comerciales de El Corte Inglés, uno en la Avenida de la Libertad y otro en la Gran Vía, y otro más junto con un Hipercor en el centro comercial El Tiro, inaugurado en diciembre de 2009. Además, el municipio cuenta con el parque comercial Viapark Murcia (situado en las inmediaciones del Polígono Industrial Oeste) y con siete centros comerciales (Atalayas, ZigZag City, Nueva Condomina, Thader, El Tiro, Montevida y La Noria Murcia Outlet Shopping) y tres más en construcción: Citymur y El Palmeral del Thader (estos dos últimos junto al centro comercial Thader e Ikea dentro del parque comercial Thader) y el centro comercial El Palmar. Además hay que destacar algunos centros comerciales más antiguos y pequeños, tales como el emblemático Centrofama (situado en el centro de la ciudad), centro comercial Arrixaca, o las galerías comerciales de Trapería y Boulevard Cetina, también en el centro.

En febrero de 2006 se inauguró el Ikea de Murcia, convirtiéndose así en el primero de todo el levante español.

En junio de 2008 abrió sus puertas el outlet La Noria, situado en la pedanía de La Ñora, uno de los únicos en toda España. Representa un pueblo mediterráneo, con sus calles, plazas, fuentes, jardines, etc. Los comercios se localizan en las casas del pueblo ficticio.

En Murcia se encuentra el parque temático Terra Natura, que recrea el hábitat de África y la Península Ibérica. Abrió sus puertas en la Semana Santa de 2007 y cuenta con el primer parque acuático de la Región de Murcia.

Otro centro de ocio importante es el ZigZag City, un centro al aire libre con una gran variedad de restaurantes, pubs y discotecas.

Entre las zonas de tapas de la ciudad cabe destacar la calle de las Mulas, la plaza de las Flores, la plaza Cardenal Belluga, la Plaza de San Juan y la zona de la Plaza de Europa y del campus de la Merced.

Murcia además goza de una amplia variedad de lugares de ocio nocturno. Son de destacar la zona de "las tascas", Atalayas y Mariano Rojas.

A lo largo de su historia son numerosas las personas ilustres que nacieron en Murcia o que por su especial vinculación con la ciudad pueden considerarse murcianos de adopción. De todos ellos la figura más relevante es probablemente Ibn Arabi (1165-1240), llamado también Abenarabi, místico sufí, poeta, filósofo, viajero y sabio andalusí. Ibn Arabi es una figura de nivel mundial en el ámbito del misticismo, especialmente musulmán.

En cuanto a las figuras de talla nacional, se puede considerar al rey Alfonso X de Castilla y León (1221-1284), llamado "el Sabio", como murciano de adopción ya que su vinculación con la ciudad llegó al extremo de pedir que su corazón y sus entrañas descansaran en la capital del reino de Murcia. Luis Antonio de Belluga y Moncada, más conocido como el cardenal Belluga (1662-1743), fue obispo de Cartagena y virrey de Murcia y Valencia durante el reinado de Felipe V. Aunque nacido en Motril, Belluga desarrolló la parte más intensa de su vida pública en Murcia, dejando una honda huella en la ciudad y sus alrededores. Murciano de nacimiento fue José Moñino y Redondo, conde de Floridablanca (1728-1808), prominente estadista que ocupó diversos cargos durante los reinados de Carlos III y Carlos IV, además de ser el primer presidente de la Junta Central Suprema durante la Guerra de la Independencia. Floridablanca fue un gran modernizador y benefactor de su ciudad natal. Bajo su dirección se realizó entre 1785 y 1787 el llamado "Censo de Floridablanca", primer censo de población realizado en España con técnicas estadísticas modernas.

Otros murcianos ilustres son: Ibn Sabin al-Mursí (1217-1270), maestro sufí y filósofo; Abu al-Abbas al-Mursi (1219-1287), maestro sufí que da nombre a la mezquita más importante de Alejandría (Egipto); Ibn Razin al-Tuyibi (1227-1293), poeta y gastrónomo; Luis Fajardo de la Cueva (1509-1574), noble, político y militar; Andrés de Claramonte (1560-1626), dramaturgo y actor; Pedro Orrente (1580-1645), pintor barroco difusor del naturalismo italiano en España; Diego de Saavedra Fajardo (1584-1648), escritor y diplomático de Felipe IV; Salvador Jacinto Polo de Medina (1603-1676), escritor y poeta; Diego Mateo Zapata (1664-1745), médico y filósofo; Francisco Salzillo (1707-1783), escultor e imaginero, el más representativo del XVIII español y creador de la escuela murciana de escultura; Roque López (1747-1811), escultor e imaginero, discípulo del anterior; Diego Clemencín (1765-1834), escritor y político liberal; Juan Palarea y Blanes (1780-1842), guerrillero y militar liberal; Julián Romea (1813-1868), actor teatral romántico; Antonete Gálvez (1819-1898), diputado y revolucionario cantonal; Manuel Fernández Caballero (1835-1906), compositor de zarzuelas; Mariano Padilla y Ramos (1842-1906), barítono; José Martínez Tornel (1845-1916), periodista y escritor; Antonio García Alix (1852-1911), político conservador y ministro; Fernando Díaz de Mendoza y Aguado, (1862-1930), actor y empresario teatral; Mariano Ruiz-Funes (1889-1953), jurista, político republicano y ministro; José Pérez Mateos (1884-1956) médico otorrinolaringólogo y Presidente de la Organización Médica Colegial de España; Juan de la Cierva y Codorníu (1895-1936), ingeniero e inventor, creador del autogiro y Pedro Flores (1897-1967), pintor vanguardista.

De los nacidos en el siglo XX la lista de murcianos ilustres se amplia con Juan González Moreno (1908-1996), escultor e imaginero; Ramón Gaya (1910-2005), pintor y escritor, Premio Nacional de Artes Plásticas; Jaime Campmany (1925-2005), periodista, novelista y poeta satírico; Eloy Sánchez Rosillo (1948-), poeta; Luis del Rivero (1950-), empresario presidente del grupo Sacyr Vallehermoso; Juan del Olmo (1958-), juez; Jerónimo Tristante (1969-), novelista; Alejandro Valverde (1980-), ciclista campeón de España 2008, vencedor en la general del circuito UCI ProTour 2006 y 2008 y de la Vuelta Ciclista a España 2009; Nicolás Almagro (1985-), tenista profesional, ganador de siete torneos de la ATP; Miguel Ángel López (1988-), campeón del mundo en en 2015, los grupos musicales M Clan, Second, Maldita Nerea, Varry Brava, Funambulista, Klaus & Kinski, The Leadings o los cantantes Ruth Lorenzo y Muerdo.

Las ciudades hermanas de Murcia son:




</doc>
<doc id="4701" url="https://es.wikipedia.org/wiki?curid=4701" title="Turbocompresor">
Turbocompresor

Un turbocompresor o también llamado turbo es un sistema de sobrealimentación que usa una turbina centrífuga para accionar mediante un eje coaxial con ella, un compresor centrífugo para comprimir gases. Este tipo de sistemas se suele utilizar en motores de combustión interna alternativos, especialmente en los motores diésel.

En algunos países, la carga impositiva sobre los automóviles depende de la cilindrada del motor. Como un motor con turbocompresor tiene una mayor potencia máxima que otro de la misma cilindrada, un modelo turbocargado pagaría menos impuestos que un motor no turbocargado de la misma potencia.


En los motores sobrealimentados mediante este sistema, el turbocompresor consiste en una turbina accionada por los gases de escape del motor de explosión, en cuyo eje se fija un compresor centrífugo que toma el aire a presión atmosférica después de pasar por el filtro de aire y lo comprime para introducirlo en los cilindros a mayor presión que la atmosférica.

Los gases de escape inciden radialmente en la turbina, saliendo axialmente, después de ceder gran parte de su energía interna (mecánica + térmica) a la misma.

El aire entra al compresor axialmente, saliendo radialmente, con el efecto secundario negativo de un aumento de la temperatura más o menos considerable. Este efecto se contrarresta en gran medida con un enfriador (intercooler).

Este aumento de la presión consigue introducir en el cilindro una mayor cantidad de oxígeno (masa) que la masa normal que el cilindro aspiraría a presión atmosférica, obteniéndose más par motor en cada carrera útil (carrera de expansión) y por lo tanto más potencia que un motor atmosférico de igual cilindrada, y con un incremento de consumo proporcional al aumento de masa de aire en el motor de gasolina. En los diésel la masa de aire no es proporcional al caudal de combustible, siempre entra aire en exceso al ser por inyección el suministro de combustible al cilindro, por ello es en este tipo de motores en donde se ha encontrado su máxima aplicación (motor turbodiésel).

Los turbocompresores más pequeños y de presión de soplado más baja ejercen una presión máxima de 0,25 bar (3,625 psi), mientras que los más grandes alcanzan los 1,5 bar (21,75 psi). En motores de competición se llega a presiones de 3 y 8 bares dependiendo de si el motor es gasolina o diésel.

Como la energía utilizada para comprimir el aire de admisión proviene de los gases de escape, que se desecharía en un motor atmosférico, no resta potencia al motor cuando el turbocompresor está trabajando, tampoco provoca pérdidas fuera del rango de trabajo del turbo, a diferencia de otros compresores de admisión, como los sistemas con compresor mecánico (volumétrico), en donde el compresor es accionado por una polea conectada al cigüeñal.

En los motores diésel el turbocompresor está más difundido debido a que un motor diésel trabaja con exceso de aire al no haber mariposa, por una parte; esto significa que a igual cilindrada unitaria e igual régimen motor (rpm) entra mucho más aire en un cilindro diésel.

Por otra parte, y esto es lo más importante, las presiones alcanzadas al final de la carrera de compresión y sobre todo durante la carrera de trabajo son mucho mayores (40 a 80 bares) que en el motor de ciclo Otto (motor de gasolina) (15-25 bares). Esta alta presión, necesaria para alcanzar la alta temperatura requerida para la auto-inflamación o auto-ignición del gasóleo, es el origen de que la fuerza de los gases de escape, a igual régimen, cilindrada unitaria y carga requerida al motor sea mucho mayor en el diésel que en la gasolina.

En épocas recientes la sobrealimentación en motores a gasolina se ha visto más difundida como una técnica para sacar provecho de los motores de baja cilindrada. Esto con el fin de no mermar el desempeño a raíz de las exigencias de consumos más reducidos. Casi siempre es similar el funcionamiento que en los motores diésel, sin embargo aquí la sobrealimentación juega un papel muy importante debido a que debe ser realizada de manera precisa con cantidades exactas con márgenes de error de +/- 0.50 cm/3 , en este caso al haber una mariposa en el múltiple de admisión de aire, se debe regular la proporción de aire y combustible en el sistema de inyección, así como calcular el valor de la relación de compresión con el fin de maximizar el desempeño y mejorar el consumo. Indirectamente estos motores pueden funcionar a mayor altitud sin tener una merma significativa de potencia.

Asimismo se requiere calibrar el momento de la actuación del turbocompresor debido al retardo de este mismo (turbo-lag). Generalmente esto se da porque la actuación del mismo depende de la velocidad a la que se expulsan los gases de escape, los cuales a su vez dependen de las RPM del mismo motor, casi siempre el mismo tendrá un desempeño óptimo en regímenes de rango medio (de 3000 a 5000 rpm), a su vez también esto depende de la presión de soplado del mismo, que en automóviles comunes casi siempre es calibrada en unos pocos bares o psi, mientras que en vehículos de competencia siempre dependerán de más PSI o Bares debido a las exigencias mayores las cuales pueden variar. Por ejemplo, los vehículos de rally en ocasiones deben depender de placas restrictoras en el mismo turbo para mantener una cifra de potencia pareja, además de mecanismos especiales que mantengan el mismo girando a tope sin importar el ralentí o la carrera del acelerador, con el fin de que se tenga la potencia necesaria tanto en HP, como en Torque (par) lo cual a su vez causa esas llamativas llamaradas y explosiones de los mismos vehículos así como su tono característico de motor.

Su funcionamiento se percibe con un silbido agudo que indica que la misma parte principal está girando de acuerdo a la velocidad de los gases de escape, a su vez en algunos motores al dejar de acelerar se puede distinguir un siseo similar al de los frenos de aire de un camión, indicación de que el turbo vuelve a un giro lento acorde al ralentí del motor.

Entre las primeras marcas que implementaron turbocompresores en motores de reducida cilindrada de manera más frecuente al principio del siglo XXI fueron las pertenecientes al Grupo Volkswagen posteriormente desarrollaron sistemas que implementarían la combinación de la carga estratificada de combustible y a su vez una combinación de turbocompresor y supercargador que permite obtener una potencia relativamente alta sin sacrificar el consumo de combustible, pues el segundo puede funcionar al principio ya que se impulsa por el mismo motor. 

Posteriormente, más marcas automotrices se sumaron al concepto, entre ellas Ford, quienes desarrollaron para la mayoría de sus motores tanto grandes como pequeños y en casi todos sus modelos los llamados Motores Ecoboost esto con el mismo fin de obtener más potencia sin gastar más combustible del necesario a la vez que se reducen las emisiones.

El aire, al ser comprimido, se calienta y pierde densidad; es decir, en un mismo volumen tenemos menos masa de aire, por lo que es capaz de quemar menos combustible y, en consecuencia, se genera menos potencia. Además, al aumentar la temperatura de admisión aumenta el peligro de detonación, picado, o autoencendido y se reduce la vida útil de muchos componentes por exceso de temperatura, y sobreesfuerzos del grupo térmico.

Para disminuir esta problemática se interpone entre el turbocompresor y la admisión un "intercambiador de calor" o "intercooler". Este sistema reduce la temperatura del aire, con lo que se aumenta la densidad de éste, que se introduce en la cámara de combustión.

En el lado negativo, los intercambiadores de calor provocan una caída de presión, por lo que se disminuye la densidad del aire, aunque en muchos casos es necesario instalar uno para evitar la detonación o autoignición.

Los motores provistos de turbocompresor padecen de una demora mayor en la disposición de la potencia que los motores atmosféricos (NA-Normal Aspiration o Aspiración Normal) o con compresor mecánico, debido a que el rendimiento del turbocompresor depende de la presión ejercida por éste. En esta demora influyen la inercia del grupo (su diámetro y peso) y el volumen del colector entre la turbina y la salida de los gases de escape del cilindro.

Un turbocargador no funciona de igual manera en los distintos regímenes de motor. A bajas revoluciones, el turbocargador no ejerce presión ya que la escasa cantidad de gases no empuja con suficiente fuerza como para generar una cantidad de inercia considerable que se considere como respuesta de turbocarga. Un turbocompresor más pequeño evita la demora en la respuesta, pero ejerce menos fuerza a altas revoluciones. Distintos fabricantes de motores han diseñado soluciones a este problema.

También Mazda, tiene un prototipo de turbo eléctrico. El sistema eléctrico del coche no puede dar suficiente caudal para el motor a altas revoluciones, pero sí a bajas; así ambos se complementan. Con baja carga y revoluciones, la ayuda eléctrica permite un rápido aumento de presión y después la turbina puede suministrar toda la potencia para comprimir el aire. Este sistema ahorra mucha más energía que combinándolo con un compresor mecánico movido por el motor.

Fiat Auto, S.P.A., anteriormente, Fiat Group Automobiles (FGA) creó y desarrolló el sistema turbo + compresor mecánico durante la década de 1.980. El vehículo en el cual se desarrolló y se implantó fue en el Lancia Delta (MKI), fabricado entre los años 1.985 y 1.990. Alcanzando su máximo exponencial y desarrollo en el Lancia Delta Integrale WRC.

Se conoce como Overboost el periodo durante el cual el sistema produce a plena carga una presión de sobrealimentación mayor a la normal, con objetivo de aumentar el par motor. 

Actualmente este sistema, con el control electrónico adecuado, puede tener en cuenta diferentes aplicaciones.

La filosofía de aplicación de los turbocompresores ha ido cambiando: desde priorizar la potencia a altas revoluciones a priorizar que el coche responda bien en todo el régimen de giro de uso.

La válvula llamada "waste-gate" evita presiones excesivas que dañen el motor. La "waste-gate" o válvula de descarga es la que regula que cantidad de gases de escape que se fugan del caracol de escape del turbo directamente hacia el escape del vehículo mediante la apertura de la válvula, de esa forma a más gases fugados menos presión de turbo, con la válvula cerrada se alcanza la máxima presión del turbo al pasar todos los gases de escape por el caracol.

La "dump valve" o válvula de alivio (también llamada blow off) abre una fuga en el conducto de admisión cuando se deja de acelerar para que la presión generada por la enorme inercia del turbo no sature estos conductos, evitando al mismo tiempo la brusca des-aceleración de la turbina, alargando su vida útil.

Normalmente el turbocompresor suele estar refrigerado con un sistema propio por aceite que circula mientras el motor está en marcha. Si se apaga bruscamente el motor después de un uso intensivo y el turbocompresor está muy caliente, el aceite que refrigera los cojinetes del turbocompresor se queda estancado y su temperatura aumenta, con lo que se puede empezar a carbonizar, disminuyendo su capacidad lubricante y acortando la vida útil del turbocompresor.

El turbo timer es un sistema que mantiene circulando el aceite en el turbocompresor durante un lapso de tiempo después del apagado del motor. Algunos modelos funcionan con sensores que detectan la intensidad en el uso del turbocompresor para permitir la lubricación forzada del mismo por un tiempo prudencial después del apagado del motor.




</doc>
<doc id="4702" url="https://es.wikipedia.org/wiki?curid=4702" title="Motor de explosión">
Motor de explosión

Un motor de explosión es un tipo de motor de combustión interna que utiliza la explosión de un combustible, encendido de manera provocada mediante una chispa, para expandir un gas que empuja un pistón. El ciclo termodinámico utilizado es conocido como Ciclo Otto. Existen motores de explosión de dos tiempos y de cuatro tiempos..

Este motor, también llamado motor de gasolina o motor Otto, es junto al motor diésel, el más utilizado hoy en día para mover vehículos autónomos de transporte de mercancías y personas. 

El combustible que se usa tradicionalmente en un motor de explosión es la gasolina. Actualmente, algunos motores de explosión pueden funcionar también con etanol, gas natural comprimido, gas licuado del petróleo o hidrógeno, además de gasolina.

En los países como Argentina (ejemplo) se utiliza más motores a gasolina para el uso de GNC (Gas Natural Comprimido), además de ser económico daña menos al ecosistema.


El combustible se inyecta pulverizado y mezclado con el gas (habitualmente aire u oxígeno) dentro de un cilindro. La combustión total de 1 gramo de gasolina se realizaría teóricamente con 14,7 gramos de aire pero como es imposible realizar una mezcla perfectamente homogénea de ambos elementos se suele introducir un 10% más de aire del necesario (relación en peso 1/16), a veces se suele inyectar más o menos combustible, esto lo determina la sonda lambda (o sonda de oxígeno) la cual envía una señal a la ECU. Una vez dentro del cilindro la mezcla es comprimida. Al llegar al punto de máxima compresión (punto muerto superior o PMS) se hace saltar una chispa, producida por una bujía, que genera la explosión del combustible. Los gases encerrados en el cilindro se expanden empujando un pistón que se desliza dentro del cilindro (expansión teóricamente adiabática de los gases). La energía liberada en esta explosión es transformada en movimiento lineal del pistón, el cual, a través de una biela y el cigüeñal, es convertido en movimiento giratorio. La inercia de este movimiento giratorio hace que el motor no se detenga y que el pistón vuelva a empujar el gas, expulsándolo por la válvula correspondiente, ahora abierta. Por último el pistón retrocede de nuevo permitiendo la entrada de una nueva mezcla de combustible.

La gasolina, la cual se obtiene mediante la destilación fraccionada del petróleo, fue descubierta en 1857. Más adelante, en 1860, Jean Joseph Etienne Lenoir creó el primer motor de combustión interna quemando gas dentro de un cilindro. Pero habría que esperar hasta 1876 para que Nikolaus August Otto construyera el primer motor de gasolina de la historia, de cuatro tiempos, que fue la base para todos los motores posteriores de combustión interna. En 1886 Karl Benz comienza a utilizar motores de gasolina en sus primeros prototipos de automóviles.


De interés relacionado:



</doc>
<doc id="4703" url="https://es.wikipedia.org/wiki?curid=4703" title="Rudolf Diesel">
Rudolf Diesel

Rudolf Christian Karl Diesel (París, 18 de marzo de 1858 – Canal de la Mancha, 29 o 30 de septiembre de 1913) fue un ingeniero alemán, inventor del carburante diésel y del motor de combustión de alto rendimiento que lleva su nombre, el motor diésel.

Diesel nació en París en 1858, segundo de los tres hijos de Elise Strobel y Theodor Diesel. Sus padres eran inmigrantes bávaros asentados en París. En 1870 la familia tuvo que abandonar Francia al estallar la guerra franco-prusiana, y Rudolf fue enviado a Augsburgo. Luego regresó a París como representante de la empresa de máquinas frigoríficas de su maestro.

Entre 1893 y 1897 construyó en los talleres de la compañía MAN AG, perteneciente al grupo empresarial alemán Krupp, el primer motor del mundo que quemaba aceite vegetal (aceite de palma) en condiciones de trabajo. Éste fue presentado en la feria internacional de París y posteriormente fue llamado con el apellido de su inventor.

El Instituto de Ingenieros Mecánicos le concedió la Orden del Mérito por sus investigaciones y desarrollos sobre los motores con aceite de maní (cacahuete), que posteriormente usaron petróleo por ser un combustible más económico.

Se consideraba así mismo como un filósofo social, aunque de su libro "Solidarismus", donde describe su visión de la empresa, solamente se vendieron 200 ejemplares.

Se supone que murió ahogado por noche del 29 al 30 de septiembre de 1913, pues desapareció del buque que cubría el trayecto de Amberes a Inglaterra en el que viajaba. Un par de días después, un bote de la guardia costera encontró su cuerpo. Como era lo común en aquel entonces, sólo se tomaron sus pertenencias (identificadas posteriormente por su hijo) y el cuerpo fue arrojado de nuevo al mar. La inexistencia de una nota o carta de suicidio ha inducido a pensar que podría haberse tratado de un accidente: Diesel, víctima de frecuentes dolores de cabeza, tal vez habría salido a pasear a cubierta, y caído al agua en un descuido. Sin embargo, también es cierto que no se puede descartar totalmente el suicidio, dado que su situación económica entonces era desesperada, pues se encontraba casi en quiebra. Existe la hipótesis de que agentes alemanes lo asesinaran para evitar la difusión de sus inventos, todavía no se ha comprobado que esto sea real, pero continúa siendo un misterio su muerte.

Después de la muerte de Diesel, el motor diésel experimentó mucho desarrollo y se convirtió en un reemplazo muy importante para el motor de pistón de vapor en muchas aplicaciones. Debido a que el motor diésel requería una construcción más pesada, más robusta que un motor de gasolina, no era ampliamente utilizado en la aviación. El motor diésel se generalizó en muchas otras aplicaciones, sin embargo, tales como motores estacionarios, máquinas agrícolas, submarinos, barcos, y mucho más tarde, locomotoras, camiones y en automóviles modernos.

Los motores diésel se encuentran con mayor frecuencia en aplicaciones en las que existe un alto requerimiento de par y un bajo requerimiento de RPM. Debido a su construcción generalmente más robusta y alto par, los motores diésel también se han convertido en los caballos de carga de la industria del camión. Recientemente, los motores diésel que han superado su peso han sido diseñados, certificados y volados en aviones ligeros. Estos motores están diseñados para funcionar con combustible diésel o más comúnmente con combustible para reactores.

El motor diésel tiene el beneficio de funcionar con más eficiencia de combustible que los motores de gasolina debido a relaciones de compresión mucho más altas y una mayor duración de la combustión, lo que significa que la temperatura aumenta más lentamente, permitiendo que más calor se convierta en trabajo mecánico. diésel estaba interesado en utilizar el polvo de carbón [9] o el aceite vegetal como combustible, y de hecho, su motor funcionaba con aceite de cacahuete. [10]

Aunque estos combustibles no fueron inmediatamente populares, durante 2008 los aumentos en los precios del combustible, junto con las preocupaciones sobre las reservas de petróleo, han llevado a un uso más extendido de aceite vegetal y biodiésel. La fuente primaria de combustible sigue siendo lo que se conoce como combustible diésel, un subproducto del petróleo derivado del refinamiento del petróleo , que es más seguro almacenar que la gasolina (su punto de inflamación es aproximadamente 175 grados más alto) y no explotará.




</doc>
<doc id="4705" url="https://es.wikipedia.org/wiki?curid=4705" title="Telepatía">
Telepatía

La telepatía (del griego τῆλε "tēle", «lejos» y παθέειν "pathéein", 'sufrir, experimentar') consiste en la transmisión de contenidos psíquicos, entre individuos, a través de la mente sin el uso de agentes físicos conocidos. Es considerada como una forma de percepción extrasensorial o cognición anómala, además se piensa que esta es instantánea.

Aunque se han llevado a cabo muchos experimentos sobre la telepatía, su realidad no es aceptada por la gran mayoría de la comunidad científica, argumentando que las magnitudes de energía que el cerebro humano es capaz de producir resultan insuficientes para permitir la transmisión de información. No obstante, algunos investigadores señalan que, con la tecnología necesaria, en un futuro será posible interpretar las ondas cerebrales mediante algún dispositivo y enviar mensajes textuales a un receptor de manera inalámbrica. Sin embargo, descartan que este proceso pueda llevarse a cabo de cerebro a cerebro sin mediación tecnológica. Hasta la fecha, las únicas pruebas de la telepatía son las narraciones testimoniales, pues jamás se ha podido reproducir un fenómeno telepático en laboratorio. 

La telepatía es tratada frecuentemente en ufología, novelas y películas de ficción.

Se han encontrado muy pocas referencias a la telepatía en las culturas antiguas de las que se tienen registros escritos (a diferencia de, por ejemplo, la precognición, que sí aparece en muchos mitos). La noción de telepatía y las especulaciones relacionadas con ellas se hicieron frecuentes sólo a partir del siglo XIX.

Se considera que la primera investigación sobre la telepatía fue la realizada por la , cuyos resultados fueron publicados en 1886 en la obra "Phantasms of the Living" (‘Fantasmas de los vivos’). Años antes, en 1882, , uno de los fundadores de la Sociedad de Investigaciones Psíquicas (SPR), introdujo, en un artículo publicado en "Proceedings of the Society for Psychical Research", el término «telepatía» (inspirado por la incipiente eclosión tecnológica de la época en que las técnicas electromagnéticas de telecomunicación reciben nombres como teléfono y telégrafo), para diferenciarlo de la falsa «lectura del pensamiento». Aunque gran parte de las investigaciones iniciales consistieron en la recopilación de relatos anecdóticos, también se llevaron a cabo experimentos con aquellos que afirmaban poseer habilidades telepáticas. Sin embargo, sus protocolos experimentales no eran muy estrictos.

En 1917 el psicólogo John E. Coover de la Universidad de Stanford dirigió una serie de pruebas sobre telepatía consistentes en transmitir y adivinar naipes. Los aciertos fueron levemente superiores a los esperados por azar, concluyéndose que el resultado había sido aleatorio.

Quizá los ejemplos más conocidos de experimentos sobre telepatía fueran los de Joseph Banks Rhine y sus asociados en la Universidad de Duke, que comenzaron en 1927 usando los distintivos «Naipes ESP» de Karl Zener (véase Cartas Zener). Estos experimentos incorporaron protocolos más rigurosos y sistemáticos que los anteriores, seleccionándose lo que se asumió que eran participantes «normales» y no aquellos que afirmaban tener habilidades excepcionales, y aplicando los nuevos avances en el campo de la estadística para evaluar los resultados. Estos y los de otros experimentos fueron publicados por Rhine en su conocido libro "Extra Sensory Perception" (‘Percepción extrasensorial’), que popularizó este término.

Otro libro influyente sobre la telepatía en su día fue "Mental Radio", publicada en 1930 por el ganador del premio Pulitzer Upton Sinclair (con prólogo de Albert Einstein). En él, Sinclair describe la aparente capacidad de su esposa de reproducir a veces los dibujos realizados por él y por otros, incluso cuando estaban separados por distancias de varias millas, en experimentos al parecer informales que recuerdan algunos de los usados por investigadores de la visión remota en épocas posteriores. En su libro, los Sinclair señalaban que los resultados podían también explicarse como una clarividencia más general, e hicieron algunos experimentos cuyos resultados sugerían que en realidad no hacía falta ningún emisor y algunos dibujos podían ser reproducidos precognitivamente.

En los años 1960, muchos parapsicólogos no estaban satisfechos con los experimentos de elección forzada de J. B. Rhine, debido en parte al aburrimiento de los participantes en las pruebas tras muchas repeticiones de adivinación monótona de naipes y al rechazo de la sugerencia de los magos de añadir naipes totalmente en blanco, y en parte por el «efecto de declive» por el que la precisión de la adivinación de cartas disminuía tras cierto tiempo para cada participante.

Algunos parapsicólogos recurrieron al formato de experimentos basados en «respuesta libre», donde el objetivo no estaba limitado a un pequeño conjunto finito predeterminado de respuestas (p. e. las cartas Zener), sino que podía consistir en su lugar en cualquier clase de cuadro, dibujo, fotografía, fragmento de película, composición musical, etcétera.

Como resultado de encuestas sobre experiencias psi espontáneas que concluían que más de la mitad de éstas sucedían en estado de sueño, los investigadores Montaque Ullman y Stanley Krippner de Maimonides Medical Center de Brooklyn (Nueva York) emprendieron una serie de experimentos para comprobar la telepatía durante el sueño. Un participante «receptor» en un cuarto insonorizado y electrónicamente blindado sería monitorizado mientras dormía en busca de patrones encefalográficos y movimientos oculares rápidos que caracterizan el estado de sueño. Un «emisor» en otra habitación intentaría entonces enviar una imagen, aleatoriamente seleccionada de un conjunto, al receptor concentrándose en dicha imagen durante los estados de sueño detectados. Cerca del final de dichos estados, el receptor sería despertado y se le pediría que describiese su sueño durante tal periodo. Los datos recogidos sugerían que algunas veces la imagen era incorporada de alguna forma en el contenido de los sueños del receptor.

Aunque los resultados de los experimentos de telepatía durante el sueño eran interesantes, llevarlos a cabo exigía muchos recursos (tiempo, esfuerzo, personal). Otros investigadores buscaron alternativas más económicas, como los llamados experimentos "ganzfeld". Hasta la fecha no ha habido ningún protocolo experimental satisfactorio diseñado para distinguir la telepatía de otras formas de percepción extrasensorial tales como la clarividencia.

La telepatía está considerada por la gran mayoría de la comunidad científica como una pseudociencia. Sus críticos objetan los experimentos con resultado positivo, diciendo que no han tenido el rigor científico adecuado. Por otro lado los miembros de los laboratorios de las universidades y asociaciones en donde sí se estudia sostienen que estos estudios tienen el rigor necesario, y que existen indicios favorables para continuar con las pruebas. Además existen argumentos evolutivos y físicos que hacen muy inverosímil la posibilidad de fenómenos telepáticos.

Un experimento típico procede como sigue:

Algunos defensores de la telepatía han usado conceptos científicos tomados de la psicología y la mecánica cuántica, de manera un tanto controvertida para explicar mecanismos reales que podrían hacer físicamente posible la telepatía. Sin embargo, al igual que sucede con la clarividencia, la telepatía presenta problemas de plausibilidad física similares. Si bien ciertas áreas de la psicología y la mecánica cuántica, siguen existiendo problemas abiertos para los que no existe una respuesta generalmente aceptada, eso no implica que dichos problemas puedan aportar ningún argumento prometedor para la plausibilidad física de la telepatía.

En un experimento realizado por investigadores de la Universidad de Mánchester se pretendía medir, mediante el uso de la realidad virtual, las capacidades telepáticas humanas. En el experimento, en el que participaron 100 voluntarios, se separaba a los participantes por parejas. Los dos miembros de cada pareja, equipados con un visor y un guante que les permite moverse e interactuar con los objetos del mundo virtual, entraban en salas separadas. A continuación se les mostraban una serie de objetos escogidos al azar (un teléfono, una trompeta, un paraguas...). Al primer participante sólo se le enseñaba uno de los objetos y se le pedía que se concentrase e interactuase con él. En la segunda habitación, el otro participante ve el mismo objeto y otros tres más. Entonces debe señalar el objeto que cree que su compañero está intentando transmitirle telepáticamente. Los investigadores estaban especialmente interesados en observar en qué medida afectan los lazos familiares y otro tipo de relaciones a las capacidades telepáticas. Los responsables del experimento no creen que esta prueba sirva para demostrar la existencia o inexistencia de la telepatía, tan sólo pretenden "crear un método experimental que facilite la investigación científica en esta área".

Varias de las razones, por las cuales muchos científicos han desechado la idea de la telepatía como un fenómeno viable, están en las dificultades para proponer un mecanismo físico de transmisión. Dada la escala y magnitud del cerebro, de existir señales telepáticas parece que deberían basarse, en la interacción electromagnética o más improbablemente en la interacción gravitatoria. Sin embargo, la anatomía no parece disponer de áreas diferenciadas u orgánulos capaces de producir de manera consistente ondas electromagnéticas, que pudieran ser recibidas e interpretadas por áreas anatómicas especializadas en cerebros vecinos. Todas esas razones indican que hay una ausencia de argumentos para pensar que los cerebros puedan, de alguna manera, producir señales telepáticas interceptables e interpretables por otros cerebros.

En algunas ocasiones, hay personas que se imaginan o, incluso, que se inventan transmisiones telepáticas. Creen poseer la facultad telepática sin ser verdaderamente así. En el caso de las personas que padecen de esquizofrenia en alguna ocasión pueden sentir pensamientos erróneos o sensaciones referidas a la telepatía.

La telepatía es un . Un buen número de superhéroes y supervillanos de varias novelas de ciencia ficción, etc, usan telepatía. Un notable ejemplo es la novela de Alfred Bester, "El hombre demolido" (1952), donde una comunidad de telépatas conviven con el resto de los seres humanos. Entre los telépatas más destacados se incluyen los jedis y los siths en el universo "Star Wars". Las habilidades telepáticas en la ficción varían considerablemente. Algunos telépatas ficticios sólo pueden transmitir pensamientos con otros telépatas, o recibir pensamientos sólo de otras personas específicas. Por ejemplo, en la novela de Robert A. Heinlein, "La hora de las estrellas" (1956), una pareja de gemelos pueden comunicarse telepáticamente, pero sólo entre ellos. En la novela de ciencia ficción de A. E. van Vogt, "Slan" (1940), el héroe mutante Jommy Cross puede leer la mente de los humanos corrientes, pero no la de otros mutantes. Sookie Stackhouse, la camarera telépata de la serie de novelas "The Southern Vampire Mysteries" de Charlaine Harris, puede leer la mente de los humanos y de otros seres sobrenaturales, pero no la de los vampiros. Algunos telépatas pueden leer la mente sólo si hay algún tipo de contacto físico, como los vulcanos en el universo de "Star Trek", Abe Sapien en las películas de Guillermo del Toro "Hellboy" (2004) o Aro, un vampiro de la novela "Luna nueva" de Stephenie Meyer (2006). El consultor y escritor del universo "Star Trek", André Bormanis, ha revelado que la telepatía en "Star Trek" es posible gracias a una especie de "campo psiónico"; según Bormanis, el campo psiónico es el medio por el cual los pensamientos y los sentimientos pueden ser transmitidos a través del espacio. Algunos humanoides pueden tener acceso perceptivo a dicho medio gracias a un órgano sensorial localizado en el cerebro; del mismo modo que el ojo humano puede percibir rangos dentro del campo electromagnético que los ojos de otras especies no pueden percibir, los telépatas pueden percibir el campo psiónico. Este campo es el equivalente al "plano astral" o "dimensión astral" en los cómics del Universo Marvel. En el libro "Eragon", de Christopher Paolini (2003), Eragon puede comunicarse telepáticamente con su dragona "Saphira" y con muchos otros, aunque puede bloquear los pensamientos con barreras psíquicas. En las series de novelas de "Harry Potter", de J. K. Rowling, la telepatía es una habilidad mágica conocida como legeremancia, la habilidad para bloquear los pensamientos ante hechizos de legeremancia se conoce como oclumancia. En la novela de John Wyndham "Las Crisálidas" (1955), el personaje principal y narrador, David Strorm, forma parte de un grupo de nueve telépatas, al igual que los sesenta niños de "Los cuclillos de Midwich" (1957) quienes poseen vastos poderes psíquicos y pueden comunicarse telepáticamente unos con otros, incluso con otros niños distantes y dispersos por todo el planeta. En la serie de novelas "Los guardianes" de Anthony Horowitz, los gemelos, Jamie y Scott Tyler, pueden leer y controlar las mentes de los demás, además de comunicarse entre ellos, por lo que siempre saben en qué está pensando el otro. 

Algunos escritores consideran la telepatía como un salto más en la evolución humana. En la novela de Tony Vigorito, "Just a Couple of Days" (2001), la telepatía se encuentra en todos los humanos gracias a un virus, el cual pasa inadvertido a causa de otras capacidades humanas. Por tanto, la telepatía es una habilidad latente que se puede desarrollar si se consigue eliminar otro tipo de distracciones, como la comunicación por el lenguaje.

En muchas obras de ficción, la telepatía está combinada con otra clase de poderes psíquicos, como en el caso de la novela "El Resplandor" (1977) de Stephen King, donde el niño Danny Torrance tiene poderes precognitivos y de mediumnidad además de habilidades telepáticas. Otros telépatas ficticios, poseen habilidades de control mental, incluyendo la capacidad de "implantar" pensamientos, sentimientos o visiones alucinatorias dentro de las mentes de los demás. Mediante ataques psíquicos pueden causar dolor, parálisis, desvanecimiento o incluso la muerte. Pueden alterar o borrar la memoria o controlar completamente la mente y el cuerpo de otros, similar a una "posesión espiritual". Ejemplos de este tipo de telépatas son Charles Xavier, Emma Frost, Jean Grey, Psylocke y, en general, casi todos los telépatas del universo Marvel. Otro ejemplo son los telépatas de la serie de televisión Héroes, como Matt Parkman entre otros. También los telépatas más poderosos dentro del mundo ficticio de Babylon 5 pueden desarrollar este tipo de habilidades, como Lyta Alexander o Al Bester.

El justiciero La Sombra tiene la habilidad de "nublar las mentes de los demás", el cual utiliza para ocultar su presencia frente a los demás.

La serie de películas de "Scanners" (Exploradores) trata de un grupo de personas que nacieron con vastos poderes telepáticos, al igual que ciertas habilidades psicoquinéticas. En el primer film de la serie, el Doctor Paul Ruth (interpretado por Patrick McGoohan) explica que el fenómeno telepático no es la transferencia de pensamiento, sino el encuentro entre los sistemas nerviosos, permitiendo a los telépatas (o "exploradores" como los definen en el film) acceder al sistema nervioso (y por tanto a los pensamientos) de los demás. Los exploradores más poderosos pueden, además, controlar y manipular el sistema nervioso ajeno. Estas habilidades pueden inhibirse mediante un fármaco llamado "Ephemerol" que altera la sinapsis cerebral de los exploradores bloqueando sus capacidades.

La obra "Devta" de Mohiuddin Nawab (1977), escrita en urdu, está basado en el personaje de Farhad Ali Taimur, un telépata implicado en la lucha entre el Bien y el Mal.

La película "Thoughtcrimes" de Breck Eisner (2003), narra la vida de la telépata Freya McAllister, desde sus problemáticos inicios hasta su inserción en la unidad especial de la ASN (Agencia de Seguridad Nacional).

La serie canadiense de televisión, "The Listener", narra las peripecias de Toby Logan, un paramédico telépata.

Mención especial merece la novela de Robert Silverberg "Muero por dentro" (1972), una novela introspectiva que narra la historia del telépata David Selig. Éste nos cuenta los problemas y sinsabores que le ha causado su don, pero que después siente cómo "muere por dentro" al descubrir que va perdiendo progresivamente su capacidad telepática, aquella habilidad que le arruinó la vida pero que teme perder por darle una distinción especial frente a los demás.

Muchos pokémon, sobre todo legendarios, pueden hablar con los humanos mediante este método, como Lugia, Arceus, Mewtwo, , Jirachi, Shaymin, Darkrai, Reshiram, Zekrom, Keldeo, Cobalion, Terrakion, Virizion, Kyurem, Diancie o Xerneas.

En la serie de televisión estadounidense "The Tomorrow People" se sostiene que hay una nueva especie en la evolución humana que posee telequinesia y telepatía, además de tener la capacidad de teletransportarse.





</doc>
<doc id="4706" url="https://es.wikipedia.org/wiki?curid=4706" title="Pseudociencia">
Pseudociencia

La pseudociencia o seudociencia (‘falsa ciencia’) es aquella afirmación, creencia o práctica que es presentada incorrectamente como científica, pero que no sigue un método científico válido, no puede ser comprobada de forma fiable, o carece de estatus científico. A menudo se caracteriza por el uso de afirmaciones vagas, contradictorias, exageradas o infalsables; la dependencia de la confirmación en lugar de pruebas rigurosas de refutación; poca o nula disposición por parte de sus seguidores a aceptar evaluaciones externas de expertos; y en general, la ausencia de procedimientos sistemáticos para el desarrollo racional de teorías.

Un área, práctica o cuerpo de conocimiento puede ser razonablemente llamada pseudocientífica cuando se presenta como congruente con los criterios de la investigación científica, pero manifiestamente no cumple con los requisitos de esta. La ciencia se diferencia de la revelación, la teología y la espiritualidad en que ofrece un entendimiento de la realidad mediante el conocimiento obtenido a través de la investigación y experimentación empíricas. La divulgación científica tendenciosa puede nublar las fronteras entre la ciencia y la pseudociencia del público general y puede además incluir ciencia ficción. Algunas creencias pseudocientíficas están ampliamente arraigadas, incluso entre periodistas y profesores de ciencia de escuelas laicas.

El problema de la demarcación entre ciencia y pseudociencia tiene implicaciones políticas, además de presentar problemas científicos y filosóficos. Distinguir entre ambas tiene importancia práctica en áreas como la asistencia médica, el peritaje judicial, las políticas ambientales y la educación en ciencias. Es parte de la educación y el alfabetismo científicos diferenciar los hechos y teorías científicos de las creencias pseudocientíficas, como las encontradas en la astrología, la alquimia, la charlatanería y las creencias ocultistas, que a menudo están unidas falazmente a conceptos científicos.

El término "pseudocientífico" a menudo se considera inherentemente peyorativo, debido a que sugiere que algo es presentado vaga o incluso embusteramente como ciencia cuando no lo es. En consecuencia, los seguidores de ideas categorizados como pseudocientíficas usualmente rechazan esta etiqueta.

El término "pseudociencia" se suele considerar como inherentemente negativo, ya que sugiere que algo está siendo incorrectamente presentado como ciencia, quizá incluso de forma intencionada. En consecuencia, aquellos de los que se afirma que practican o defienden pseudociencias normalmente discuten tal etiqueta pero por otro lado se encuentran miembros de la comunidad científica que cuestionan el uso peyorativo de la etiqueta como calificativo ante nuevas teorías, tesis o investigaciones.

El término "pseudociencia" o "seudociencia" es un neologismo formado a partir de la raíz griega "pseudo", «falso», y la palabra latina "ciencia", «conocimiento». Aunque el término como tal se emplea desde por lo menos finales del siglo XVIII, el concepto de "pseudociencia" como algo distinto de la ciencia real o auténtica parece haber surgido a mitad del siglo XIX. Uno de los primeros usos de la palabra "pseudociencia" proviene de 1844 en el "Northern Journal of Medicine". También se registra un uso anterior del término en 1843, en la obra del fisiólogo francés François Magendie.

Aunque los elementos que determinan si un cuerpo de conocimiento, metodología o práctica es científico pueden variar según el ámbito de actuación, existen ciertos principios generales con los que la comunidad científica se muestra en general de acuerdo. La noción básica es que todos los resultados experimentales deben ser reproducibles, y susceptibles de ser verificados por otros investigadores. Estos principios pretenden asegurar que los experimentos pueden ser reproducidos bajo las mismas condiciones, permitiendo mediante la investigación posterior determinar si una hipótesis o teoría acerca de un fenómeno es a la vez válida y fiable. Para ser considerado científico, un estudio debe aplicar el método científico en todos sus ámbitos, y el sesgo cognitivo debe ser controlado o eliminado mediante el muestreo al azar, técnicas específicas como el doble ciego, y otros métodos. Se espera que todos los datos recopilados, incluyendo especificaciones de las condiciones ambientales o experimentales, estén documentados y disponibles para su revisión por pares, permitiendo la realización de nuevos experimentos que confirmen o desmientan los resultados previos.

En general, y en la medida en que pueda resultar aplicable, la metodología científica exige que las teorías puedan someterse a pruebas empíricas rigurosas, mientras que a las pseudociencias, o bien no será posible aplicarles sistemas de refutación (por tratarse de formulaciones ambiguas), o bien sus partidarios protegerán la teoría (por ejemplo, con hipótesis auxiliares o "ad hoc", formuladas "a posteriori"), en lugar de someterla a ensayos que puedan refutarla.

Karl Popper introdujo a mediados del siglo XX el concepto de falsabilidad para distinguir la ciencia de la no-ciencia. Un resultado es "falsable" cuando puede ser demostrado como erróneo, es decir, cuando puede diseñarse un experimento teórico con el que demostrar si es falso. De este modo, las afirmaciones "falsables" pueden ser consideradas como ciencia, mientras que las no "falsables" se consideran no-ciencia. Por ejemplo, la afirmación de que "Dios creó el Universo" puede ser cierta o falsa, pero no puede diseñarse ningún experimento que demuestre una cosa u otra; simplemente está más allá de la capacidad de la ciencia, ergo, no es "falsable" y por tanto es no-ciencia. Popper usó la astrología y el psicoanálisis como ejemplos de pseudociencias, y la teoría de la relatividad de Einstein como ejemplo de ciencia. Luego clasificó las formulaciones no-científicas en las categorías filosófica, matemática, mitológica, religiosa y/o metafísica por un lado, y pseudocientífica por otro, aunque no dio criterios claros para definir cada una.

El término tiene connotaciones peyorativas, porque se usa para indicar que las materias así etiquetadas son errónea o engañosamente presentadas como científicas. Por este motivo, aquellos que cultivan determinada "pseudociencia", normalmente rechazan esta clasificación. El apelativo se ha aplicado a disciplinas como ciertas hipótesis de la física cuántica, las ciencias sociales, el psicoanálisis, la parapsicología y la criptozoología por la naturaleza de sus objetos de estudio difícil de aplicarle la misma rigurosidad científica que en otras disciplinas, no obstante esto es relativo y algunas de estas disciplinas acusadas de pseudocientíficas son aceptadas como científicas por universidades, asociaciones científicas, centros médicos, gobiernos, etc., por ejemplo, el psicoanálisis.

Muchas veces la discusión sobre un concepto o campo de conocimiento gira más alrededor de su consideración como ciencia o pseudociencia que acerca de los hechos y métodos reales. El filósofo de la ciencia Larry Laudan ha manifestado que el concepto "pseudociencia" no tiene significado científico y se usa mayoritariamente para describir una apreciación subjetiva: "Si quisiéramos permanecer firmes al lado de la razón, deberíamos deshacernos de términos como ‘pseudociencia’ y ‘acientífico’ de nuestro vocabulario; son solo palabras huecas que cumplen una función emotiva." Del mismo modo, Richard McNally afirma que "el término "pseudociencia" se ha convertido en poco más que una injuriosa palabra de moda para ningunear a los propios oponentes en las discusiones en los medios", y que "cuando los emprendedores terapéuticos hacen afirmaciones a favor de sus tratamientos, no deberíamos perder el tiempo intentando determinar si estos califican como pseudocientíficos. En su lugar se deberían hacer preguntas como: ¿Cómo sabe que su tratamiento funciona? ¿Cuáles son sus pruebas?".

Los autores que diferencian entre ciencias reales y pseudociencias señalan características cuya presencia simultánea, no necesariamente de todas a la vez (definición politética), ayuda a reconocer a las pseudociencias como tales:


Algunos autores afines al relativismo epistémico o al llamado «programa fuerte» (o «estándar») de la sociología de la ciencia (Barry Barnes, Steve Shapin y David Bloor), la Escuela de París, (Bruno Latour y Michael Callon), el grupo de Bath, (Harry Collins y Steven Yearley), el grupo de norteamericanos y su “Etnometodología”, (Harold Garfinkel y Michael Lynch), ponen en duda que sea posible diferenciar con rigor y objetividad el límite que demarca la "ciencia" de la "pseudociencia", respaldando en algunos casos posiciones abiertamente contrarias a determinadas concepciones de lo que es ciencia y criticando el método científico. Estas posiciones relativistas fueron contestadas por los científicos Alan Sokal y Jean Bricmont en su libro "Imposturas intelectuales" (1997),el cual a su vez recibió contrarréplicas.

Algunos críticos de la pseudociencia consideran algunas o todas las formas de pseudociencia como pasatiempos inofensivos. Otros, como Richard Feynman, Richard Dawkins, Carl Sagan, Michael Shermer y Mario Bunge consideran que todas las formas de pseudociencia son dañinas, causen o no daños inmediatos a sus seguidores. Estos críticos generalmente consideran que la defensa de la pseudociencia puede suceder por varias razones, que van desde la simple candidez sobre la naturaleza de la ciencia y el método científico, hasta un engaño deliberado por beneficios económicos o políticos. No es apropiado tratar de pseudociencia cualquier cuerpo sistemático de creencias solo por no considerar veraces sus postulados, sino que solo tiene sentido hacerlo cuando desde la disciplina en cuestión se proclama sin fundamento su carácter científico.

El pensamiento pseudocientífico se ha explicado en términos de psicología y psicología social. La tendencia humana a buscar confirmación en vez de refutación, la de mantenerse aferrado en las creencias confortables, y la de sobregeneralizar han sido mencionadas como razones comunes para la adherencia al pensamiento pseudocientífico. De acuerdo con Beyerstein (1991) los humanos son propensos a realizar asociaciones en función de la apariencia, y a menudo cometen errores en el pensamiento sobre causa y efecto.

Paul Feyerabend argumenta que una distinción entre ciencia y seudociencia no es ni posible ni deseable.Richard McNally, catedrático de Psicología de la universidad de Harvard, manifiesta: "El término 'pseudociencia' se ha convertido en poco más que una palabra de moda incendiaria para desacreditar rápidamente a un oponente a través de los medios de comunicación" y "Cuando los terapeutas manifiestan haber obtenido logros con sus prácticas, no deberíamos gastar nuestro tiempo en tratar de averiguar si sus prácticas se las pueden calificar de pseudocientíficas. En vez de eso, se le debería preguntar: ¿Cómo sabe usted que su práctica funciona? ¿Cuál es su evidencia?"

La protociencia engloba áreas de conocimiento en proceso de consolidación. Por ejemplo la alquimia en el siglo XVII entraba dentro de esta categoría. Cuando se descubrió que los principios en la que se basaban (como la influencia de los planetas en los metales) no tenían respaldo experimental, pasó a ser una pseudociencia. Lo mismo puede decirse de la parapsicología en el siglo XIX y principios del XX. No todas las protociencias desembocan en pseudociencias. Existen autores que consideran que la alquimia dio origen a la química y la astrología a la astronomía; aunque se debe tener en cuenta que otros historiadores de la ciencia rebaten este punto, considerando al ocultismo y a la ciencia como tradiciones paralelas.

No hay un acuerdo para la diferenciación entre protociencia, pseudociencia y ciencia. Hay ejemplos de teorías científicas vigentes que alguna vez fueron criticadas y etiquetadas como pseudocientíficas. La transición se caracteriza por una mayor investigación científica sobre el tema y el descubrimiento de más evidencias que sustenten la teoría. Así, la teoría de la deriva continental fue, en su momento, considerada pseudocientífica.

Se han hecho varios intentos para aplicar rigor filosófico a la demarcación de la ciencia con resultados diversos. Estos incluyen el criterio de falsabilidad de Karl Popper y la aproximación histórica de Imre Lakatos, quien lo critica en su "Methodology of scientific research programmes" "(Metodología de los programas de investigación científica)".
Historiadores y filósofos de la ciencia, principalmente Thomas Kuhn y Paul Feyerabend, sostienen desde otras perspectivas epistemológicas del conocimiento, que incluye la dimensión social, que no siempre es posible una distinción nítida y objetiva entre ciencia y pseudociencia.

Mario Bunge, filósofo de la ciencia, es conocido por su posición de incluir al psicoanálisis entre las pseudociencias. Críticas hacia la inconsistencia entre teoría y experiencia, o hacia el carácter especulativo del discurso se dirigen también a veces desde las ciencias naturales hacia ciertas ciencias sociales, como la economía o la psicopedagogía. El "escándalo Sokal", por el nombre del físico que lo puso en marcha, mostró que desde una cierta orientación de la Sociología de la Ciencia postmoderna también se ha recurrido a veces a usar inconsistentemente el lenguaje de las llamadas "ciencias duras", en lo que parece un intento irregular de legitimación científica, siendo esta una de las líneas de conducta frecuentemente reprochadas hacia las llamadas pseudociencias.

Para algunos sectores de la filosofía de la ciencia no existe un criterio de demarcación perfectamente delimitado, metodológico y objetivo para definir universalmente qué es ciencia y qué es pseudociencia,

Un campo en el que se usan frecuentemente alegaciones seudocientíficas es el de la curación de enfermedades.

Entre las pseudoterapias sin ningún resultado e incluso con contraindicaciones o efectos secundarios negativos que se han recomendado para curar el cáncer están la angeloterapia, biomagnetismo, bioneuroemoción o biodescodificación, constelaciones familiares, dianética, dieta alcalina, desensibilización por medio de movimientos oculares, flores de bach, limpieza de colon, homeopatía, iridología, iriogenética, homotoxicología, suplemento mineral milagroso, naturopatía, osteopatía, ozonoterapia, programación neurolingüística, psicoanálisis, quiropráctica, reflexología, acupresión, reiki, terapia gerson, terapia gestalt o terapia humanista, terapia neural, terapia ortomolecular o medicina ortomolecular, terapia quelante y el toque terapéutico. Se desaconsejan estas pseudoterapias apoyadas en pseudociencias para la cura del cáncer.

Existe un importante mercado de métodos curativos y diagnósticos presentados como mecanismos curativos de validez demostrada por estudios, que en muchos casos utilizan métodos mágicos tradicionales, como la imposición de manos o procedimientos sin fundamento científico, como la radiestesia o el empleo de pirámides. La mayoría de estos curanderismos, cuya extensión creciente debe mucho a internet, busca la credibilidad y el prestigio que tiene la ciencia, alegando por ejemplo desconocidas propiedades del agua, la supuesta acción de fenómenos cuánticos, o presuntas energías de naturaleza difusa.

El cartílago de tiburón se ha promocionado falsamente como cura para el cáncer con base en una supuesta inexistencia de cánceres en tiburones. De acuerdo con Ostrander, esta práctica ha llevado a una continua disminución de las poblaciones de tiburones, y, lo que es más importante, ha alejado a los pacientes de terapias contra el cáncer que sí son efectivas. Los autores sugieren que "los mecanismos basados en la evidencia dada por la comunidad científica deberían añadirse al aprendizaje de los profesionales de los medios de comunicación y gubernamentales".

Un caso especial, por su extensión, es el de la homeopatía, cuya incongruencia con el conocimiento científico fue indicada ya en vida de su fundador, Samuel Hahnemann, y respecto a la que se han utilizado recientemente términos prestados de la mecánica cuántica (como el entrelazamiento) de manera admitidamente metafórica.

Lo mismo ocurre con la reflexología podal, llegándose incluso a impartir cursos que a veces están financiados por la administración pública sanitaria y dirigidos a matronas, personas con formación científica e inmersas en el ámbito sanitario, lo que puede confundir a la ciudadanía dando apariencia de estar avalado por la ciencia. Estos cursos, en España los imparte gente sin formación médica reglada, por lo que su credibilidad deja mucho que desear. Cualquier persona, independientemente de su formación, tiene acceso a cursos de reflexología y puede obtener un diploma que lo capacita para la práctica profesional de dicha disciplina.

Algunos tratamientos alternativos de carácter pseudocientífico han producido accidentes graves, incluso muertes; pero se admite en general que el mayor peligro para la salud de los pacientes ocurre cuando, confiando en un método ineficaz, renuncian a medidas más efectivas, como hábitos más saludables o un tratamiendo médico de eficacia demostrada.

Las pseudociencias y paraciencias promueven la patologización y medicalización: intentan mostrar como problemas de salud susceptibles de tratamiento a características biológicas a comportamientos fisiológicos o vitales que no son problemas de salud.

Las pseudociencias extienden diagnósticos existentes a personas que no los padecen, establecen diagnósticos sin base científica probada (véase en psiquiatría la disputa de la controversia de la biopsiquiatría) y llegan a la creación de enfermedades sin ningún fundamento científico -pseudoenfermedades- (p.e. "síndrome del intestino permeable" o "permeabilidad intestinal aumentada") con el objeto de crear una clientela que compre sus libros y remedios.

Algunos autores que defienden la posibilidad de un criterio de demarcación estricto entre ciencia y pseudociencia como Mario Bunge, Carl Sagan, Robert L. Park, James Randi, o Michael Shermer consideran que en algunos de los campos siguientes una parte significativa de sus practicantes presentan su disciplina como más o menos equivalente a campos del conocimiento rigurosos, imitándolos a veces formalmente en el lenguaje o las formas de comunicación, y adoptando títulos científicamente prestigiosos ante el público como «doctor» o «profesor», legitimados o no académicamente. Tal como se deduce de la caracterización del concepto, los practicantes de estas actividades afirman su carácter científico.



</doc>
<doc id="4707" url="https://es.wikipedia.org/wiki?curid=4707" title="Chamanismo">
Chamanismo

El chamanismo se refiere a una clase de creencias y prácticas tradicionales similares al animismo que aseguran la capacidad de diagnosticar y de curar el sufrimiento del ser humano, y en algunas sociedades, la capacidad de causarlo. Los chamanes creen lograrlo contactando con el mundo de los espíritus y formando una relación especial con ellos. Aseguran tener la capacidad de controlar el tiempo, profetizar, interpretar los sueños, usar la proyección astral y viajar a los mundos superior e inferior. Las tradiciones de chamanismo han existido en todo el mundo desde épocas prehistóricas.

Algunos especialistas en antropología definen al chamán como un intermediario entre el mundo natural y espiritual, que viaja entre los mundos en un estado de trance. Una vez en el mundo de los espíritus, se comunica con ellos para conseguir ayuda en la curación, la caza o el control del tiempo. Michael Ripinsky-Naxon describe a los chamanes como «personas que tienen fuerte ascendencia en su ambiente circundante y en la sociedad de la que forman parte».

Un segundo grupo de antropólogos discuten el término chamanismo, señalando que es una palabra para una institución cultural específica que, al incluir a cualquier sanador de cualquier sociedad tradicional, produce una uniformidad falsa entre estas culturas y crea la idea equívoca de la existencia de una religión anterior a todas los demás. Otros les acusan de ser incapaces de reconocer las concordancias entre las diversas sociedades tradicionales.

El chamanismo se basa en la premisa de que el mundo visible está impregnado por fuerzas y espíritus invisibles de dimensiones paralelas que coexisten simultáneamente con la nuestra, que afectan todas a las manifestaciones de la vida. En contraste con el animismo, en el que todos y cada uno de los miembros de la sociedad implicada lo practica, el chamanismo requiere conocimientos o capacidades especializados. Se podría decir que los chamanes son los expertos empleados por los animistas o las comunidades animistas. Sin embargo, los chamanes no se organizan en asociaciones rituales o espirituales, como hacen los sacerdotes.

Hay muchas variantes de chamanismo en el mundo; lo siguiente son creencias compartidas por todas las formas de chamanismo:
—hay que aclarar que el chamanismo proviene del «chamán», quien es propio de la región oriental de Siberia, aunque, como señala Mircea Eliade en su intento por hacer una historia general del chamanismo, hay una diversidad de chamanes esparcidos en todo el mundo, y les caracteriza el hecho de ser médicos y guías espirituales que realizan «ascensos hacia el cielo»—.


El chamanismo se basa en la premisa de que el mundo visible está dominado por fuerzas o espíritus invisibles que afectan las vidas de los vivientes. A diferencia de las religiones organizadas como el animismo o el animatismo que están lideradas por párrocos y que todos los miembros de una sociedad practican, el chamanismo requiere conocimientos individualizados y capacidades especiales. Los chamanes actúan fuera de religiones asentadas, y, tradicionalmente, actúan solos. Los chamanes pueden juntarse en asociaciones, como han hecho los practicantes tántricos indios.

La palabra «chamán» se refería originalmente a los sanadores tradicionales de las áreas túrquicas y mongolas del centro-norte de Asia (Siberia) y Mongolia. Chamán significa ‘médico’ en turco-tungus ―significa literalmente ‘el que sabe’―.
Otros académicos afirman que la palabra viene directamente del idioma manchú.
En turco fueron llamados "kam" y a veces "baksı".

La palabra tungusa "šamán" proviene de la china "sha men" tomada del palí, "śamana", y en última instancia del sánscrito "śramana:" ‘asceta’, que proviene de "śrama" ‘fatiga, esfuerzo’. La palabra pasó a través del ruso y el alemán antes de que fuera adoptada por el inglés, "shaman" (/sháman/), y llegara al español, donde «chamán» (plural, «chamanes») es correcto tanto en masculino como en femenino.

Otra explicación analiza el hecho de que esta palabra tungusa contiene la raíz "sha-", que significa ‘saber’. El "shamán" sería entonces ‘el o la que sabe’.

En su uso común, es equivalente al de brujo, un término que une las dos funciones del chamán: conocimiento del saber mágico y capacidad de curar a las personas y de reparar una situación problemática. Sin embargo, este último término se considera generalmente peyorativo y antropológicamente inexacto. La objeciones al uso de la palabra "chamán" vienen dadas por ser una palabra que viene de un lugar, de una gente, y de un sistema de prácticas específicas.

Ciertos antropólogos, como Alicia Kehoe, rechazan el término moderno por lo que implica de apropiación cultural. Se refieren a las formas occidentales modernas de chamanismo, que no solo falsifican y diluyen las prácticas indígenas genuinas, sino que lo hacen de tal forma que refuerzan ideas racistas, tales como la del "buen salvaje".

Kehoe es muy crítica con el trabajo de Mircea Eliade. Eliade, siendo historiador más que antropólogo, nunca había hecho ningún trabajo de campo ni había tenido contacto directo con los chamanes o las culturas que practican chamanismo. Según Kehoe, el chamanismo de Eliade es una invención sintetizada de varias fuentes sin apoyo de ninguna investigación directa. Opina que lo que éste y otros estudiosos definen como propio del chamanismo, los trances, cánticos, comunicación con los espíritus, curaciones, son prácticas que existen en culturas no chamánicas como en algunos rituales judeocristianos. En su opinión, son propios de varias culturas que los utilizan, y no se pueden englobar en una religión general llamada chamanismo. Por lo mismo, rechaza que el chamanismo sea una antigua religión superviviente del Paleolítico.

Hoppál también discute si el término chamanismo es apropiado. Recomienda el usar «chamanidad» para marcar la diversidad y las características específicas de las culturas discutidas. Este es un término usado en viejos informes etnográficos, tanto rusos como alemanes, de principios del siglo XX. Cree que este término es menos general y permite marcar diferencias locales.

Los chamanes realizan una plétora de funciones dependiendo de la sociedad donde practican sus artes:
curación;
liderar un sacrificio;
conservar la tradición con historias y canciones;
videncia;
actuar como un psicopompo
En algunas culturas, un chamán puede cumplir varias funciones en una única persona.

El nigromante en la mitología griega puede ser considerado un chamán ya que el nigromante puede reunir espíritus y levantar a los muertos para utilizarlos como esclavos, soldados e instrumentos para la adivinación.

Los chamanes actúan como «mediadores» en su cultura.
El chamán es visto como un comunicador de la comunidad con los espíritus, incluyendo los espíritus de los muertos. En algunas culturas, esta función de mediador del chamán puede ser bien ilustrada por algunos de los objetos y símbolos del chamán. Por ejemplo, entre los selkups, un informe menciona a un pato marino como un animal-espíritu: los patos son capaces tanto de volar como de bucear bajo el agua, así se les considera pertenecientes tanto al mundo superior como al mundo inferior.

De modo parecido, el chamán y el jaguar son identificados en algunas culturas amazónicas: el jaguar es capaz de moverse libremente en la tierra, en el agua y trepando árboles (como el alma del chamán). En algunas culturas siberianas, son algunas especies de aves acuáticas las que están relacionadas con el chamán de una manera similar, y se cree que el chamán toma su forma.

«El árbol chamánico» es una imagen encontrada en varias culturas (yakutos, dolganos, evenkis), celtas, como un símbolo de mediación. El árbol es visto como un ser cuyas raíces pertenecen al mundo inferior; su tronco pertenece al medio, mundo habitado por humanos; y su copa se relaciona con el mundo superior.

En algunas culturas puede haber más tipos de chamanes, que realizan funciones más especializadas. Por ejemplo, entre el pueblo nanai, un tipo diferente de chamán actúa como un psicopompo.
Otros chamanes especializados pueden ser distinguidos según el tipo de espíritus, o reinos del mundo de los espíritus, con los cuáles el chamán interacciona más comúnmente. Estos roles varían entre los chamanes nenets, enets y selkup (artículo; en línea). Entre los huicholes, hay dos categorías de chamán. Esto demuestra las diferencias entre los chamanes dentro de una misma tribu.

En los bosques tropicales, los recursos para el consumo humano son fácilmente agotables. En algunas culturas de los bosques tropicales, como los tucano, existe un sistema sofisticado para la gestión de los recursos, y para evitar el agotamiento de estos recursos a través de la sobreexplotación. Este sistema está conceptualizado en un contexto mitológico, involucrando simbolismo y, en algunos casos, la creencia de que la ruptura de las restricciones de caza puede causar enfermedades. Como principal maestro de simbolismo tribal, el chamán puede tener un papel principal en esta gestión ecológica, restringiendo activamente la caza y la pesca. El chamán es capaz de «sacar» los animales de caza (o sus almas) de sus ocultas moradas.

El chamán desana tiene que negociar con un ser mitológico por las almas de los animales de caza.
No solo los tucanos, sino también algunos otros indígenas de bosques tropicales tienen estas preocupaciones ecológicas relacionadas con su chamanismo, por ejemplo los piaroa.

Además de los tucanos y los piaroa, también muchos grupos esquimales piensan que el chamán es capaz de traer almas de animales de caza desde lugares remotos; o emprender un viaje del alma para promover suerte en la cacería, p. ej. pidiendo animales de caza a los seres mitológicos (Mujer del mar).

La plétora de funciones descritas en la sección de encima pueden parecer tareas bastante distintas, pero algunos conceptos subyacentes importantes les unen.

En algunos casos, en algunas culturas, el concepto de alma puede explicar más los fenómenos aparentemente no relacionados:
El aspecto ecológico de la práctica chamanística (y las creencias relacionadas) ya ha sido mencionado más arriba en el artículo.

La infertilidad de las mujeres puede curarse «obteniendo» el alma del niño que se espera que nazca.

También las creencias relacionadas con los espíritus pueden explicar muchos diferentes fenómenos.
Por ejemplo, la importancia de narrar historias, o actuar como un cantante, puede entenderse mejor si examinamos el sistema de creencias entero: una persona que es capaz de memorizar textos o canciones largas (y tocar un instrumento) puede considerarse como que ha logrado esta capacidad a través del contacto con los espíritus (por ejemplo entre el pueblo janty).

Como se ha mencionado, un enfoque (discutido) explica la etimología de la palabra «chamán» significando «uno que sabe».
Realmente, el chamán es una persona experta en mantener juntos los múltiples códigos a través de los cuales este complejo sistema de creencias aparece, y tiene una visión de conjunto de él en su mente con certeza de conocimiento.
El chamán usa (y el público entiende) múltiples códigos. El chamán expresa significados de muchas maneras: verbalmente, musicalmente, artísticamente y en baile. Los significados pueden manifestarse en objetos, como amuletos.

El chamán conoce bien la cultura de su comunidad, y actúa en consecuencia. Así, su público conoce los símbolos usados y los significados — esto es por lo que el chamanismo puede ser eficiente: la gente en el público confía en ello.
Estos sistemas de creencias pueden parecer para sus miembros con certeza de "conocimiento" ―esto explica la etimología descrita más arriba para la palabra «chamán»―.

Hay enfoques teóricos semióticos hacia el chamanismo, («etnosemiótica»). Los símbolos en el traje del chamán y el tambor pueden referirse a animales (como espíritus ayudantes), o al rango del chamán. Había también ejemplos de «símbolos mutuamente opuestos», distinguiendo chamanes «blancos» practicando de día contactando con espíritus celestes, y chamanes «negros» practicando de noche contactando con espíritus malignos para malos propósitos.

Series de estos símbolos opuestos se referían a una visión del mundo detrás de ellos. Análogamente a la manera que la gramática ordena las palabras para expresar significados y expresar un mundo, también esto formó un mapa cognitivo.
La tradición del chamán está arraigada en el folclore de la comunidad, que proporciona un «mapa mental mitológico».
Juha Pentikäinen usa el concepto «gramática de la mente».
Enlazando con un ejemplo sami, Kathleen Osgood Dana escribe:

Algunos enfoques se refieren a la hermenéutica, «etnohermenéutica», acuñada e introducida por Armin Geertz. El término puede ser extendido: Hoppál incluye no solo la interpretación de textos orales o escritos, sino la de los «textos visuales también (incluyendo movimientos, gestos y rituales más complejos, y ceremonias celebradas por ejemplo por chamanes)».
Esto puede no solo revelar las visiones animistas que se esconden detrás del chamanismo, sino también expresar su relevancia para el mundo reciente, donde los problemas ecológicos hacen los paradigmas sobre el equilibrio y la protección válidos.

Otros trabajos de campo usan conceptos de la teoría de sistemas y consideraciones ecológicas para entender la tradición del chamán. Los indígenas desana y tucano han desarrollado un sofisticado simbolismo y conceptos de «energía» fluyendo entre la gente y los animales en caminos cíclicos. Gerardo Reichel-Dolmatoff relaciona estos conceptos con los cambios en cómo la ciencia moderna (teoría de sistemas, ecología, algunos nuevos enfoques en antropología y arqueología) trata la causalidad de una manera menos lineal.
También sugiere una cooperación de la ciencia moderna y la tradición indígena (en línea).

Según Vladimir Basilov y su obra "Chosen by the spirits", un chamán ha de estar en las mejores condiciones saludables para realizar sus funciones al máximo. La creencia del chamán es más popular para la gente situada en Asia Central y Kazajistán. Las tradiciones del chamanismo están también presentes en las regiones de tadzhikos y uzbekos. Los cuerpos de los chamanes han de estar formados por un tipo fuerte, alguien teniendo una complexión pequeña sería apartado en seguida. La edad es un requisito también, sin duda tener más de cincuenta años descalificaría a aquellos que quieren estar involucrados en servir a los espíritus. Los chamanes son siempre del más alto intelecto y se les mira desde una perspectiva diferente, tienen una forma que les hace rápidos con sus pies y con enfermedades curarán a aquellos necesitados.

Una de las cualidades más significativas y relevantes que separan a un chamán de otros líderes espirituales son sus comunicaciones con el mundo sobrenatural. Ya a principios de siglo la autohipnosis era muy considerada por aquellos que rendían culto. Otra característica del chamán es el talento para encontrar objetos y descubrir ladrones, impresionando a aquellos de su tribu y a aquellos otros también alrededor para presenciarlo. La creencia en los espíritus o lo sobrenatural es lo que atrae a aquellos que creen en el chamán. Aquellos que tienen hijos enfermos o están débiles de salud ellos mismos es lo que les lleva a las curaciones espirituales del chamán. Aunque los chamanes aún existen, la población está sin duda disminuyendo.

En las culturas chamánicas del mundo, el chamán juega un papel de párroco; no obstante, hay una diferencia esencial entre los dos, como Joseph Campbell describe:
Un chamán puede ser iniciado a través de una enfermedad grave, siendo alcanzado por un relámpago y soñando con un trueno para convertirse en un Heyoka, o por una experiencia cercana a la muerte (p. ej., el chamán Alce Negro), o uno puede seguir una «llamada» para convertirse en chamán. Hay normalmente un conjunto de imaginería cultural que se espera que se experimente durante la iniciación chamánica sin importar el método de inducción. Según Mircea Eliade, esta imaginería a menudo incluye ser transportado al mundo de los espíritus e interaccionar con seres que habitan el mundo distante de los espíritus, encontrar un guía espiritual, ser devorado por algún ser y aparecer transformado, o ser «desmontado» y «vuelto a montar» de nuevo, a menudo con amuletos implantados tales como cristales mágicos. La imaginería de la iniciación generalmente habla de transformación y de los poderes otorgados para trascender la muerte y el renacimiento.

En algunas sociedades chamánicas se considera que los poderes son heredados, mientras que en otros lugares del mundo se considera que el chamán ha sido «llamado» y requiere un entrenamiento largo. Entre los chukchis siberianos uno puede comportarse de maneras que los clínicos biomédicos «occidentales» caracterizarían tal vez como psicótico, pero que los pueblos siberianos pueden interpretarlo como una posesión por un espíritu que demanda que uno asuma la vocación chamánica. Entre los Tapirapé sudamericanos, los chamanes son llamados en sus sueños. En otras sociedades el chamán elige su carrera. En América del Norte, los pueblos de las Naciones Originarias buscarían la comunión con los espíritus a través de una «búsqueda de visión»; mientras que los shuar sudamericanos, buscando el poder para defender a su familia contra los enemigos, aprenden ellos mismos para lograr ser un chamán. Asimismo los urarina de la amazonia peruana tienen un elaborado sistema cosmológico basado en el consumo ritual de ayahuasca. Junto con los impulsos milenarios, el chamanismo ayahuasca de los urarina es una de las características clave de esta sociedad poco documentada.

Supuestamente también pueden observarse «tradiciones» chamánicas habituales entre los pueblos indígenas kuna de Panamá, que confían en poderes chamánicos y talismanes sagrados para curar. Por eso, gozan de una posición popular entre los pueblos locales.

La enfermedad chamánica, también llamada crisis iniciática chamanística, es una crisis psicoespiritual, normalmente involuntaria, o un rito de paso, observado entre aquellos que se convierten en chamán. El episodio a menudo marca el inicio de un episodio de confusión o comportamiento inquietante limitado en el tiempo donde el iniciado chamánico puede cantar o bailar de una manera poco convencional, o tener la experiencia de ser «perturbado por espíritus». Los síntomas no se consideran normalmente como signos de enfermedad mental por intérpretes de la cultura chamánica; más bien, son interpretados como señales indicadoras introductorias para el individuo que se supone que tomará el cargo de chamán (Lukoff et. al, 1992). Las similitudes de algunos síntomas de la enfermedad chamánica al proceso kundalinī han sido a menudo apuntadas.
El papel significativo de las enfermedades iniciáticas en la llamada de un chamán puede encontrarse en el detallado historial de Chuonnasuan, el último maestro chamán entre los pueblos tungus del nordeste de China.

El chamán juega el papel de curandero en las sociedades chamánicas; los chamanes adquieren conocimiento y poder atravesando el axis mundi y trayendo conocimiento de los cielos. Incluso en las sociedades occidentales, esta antigua práctica de curación está referenciada por el uso del caduceo como el símbolo de la medicina. A menudo el chamán tiene, o adquiere, una o más entidades familiares ayudantes en el mundo de los espíritus; estas son a menudo espíritus en forma de animal, espíritus de plantas medicinales, o (a veces) aquellas de los chamanes difuntos. En muchas sociedades chamánicas, la magia, la fuerza mágica y el conocimiento son todos denotados por una palabra, como el término quechua "«yachay»".

Aunque se considera que las causas de una enfermedad se encuentran en el mundo espiritual, siendo afecctadas por espíritus maliciosos o brujería, se utilizan tanto métodos espirituales como físicos para curar. Comúnmente, un chamán «entra en el cuerpo» del paciente para hacer frente al espíritu que pone enfermo al paciente, y cura el paciente desterrando el espíritu infeccioso. Muchos chamanes tienen conocimiento experto de la vida de las plantas en su área, y a menudo se receta un régimen de hierbas como tratamiento. En muchos lugares los chamanes afirman aprender directamente de las plantas, y ser capaces de aprovechar sus efectos y propiedades curativas solo después de obtener permiso de su espíritu permanente o patrón. En América del Sur, los espíritus individuales son llamados con el canto de canciones llamadas icaros; antes de que un espíritu pueda ser llamado el espíritu debe enseñar al chamán su canción. El uso de elementos totémicos como rocas es común; se cree que estos elementos tienen poderes especiales y un espíritu vivo. Estas prácticas son supuestamente muy antiguas; alrededor del 368 a. C., Platón escribió en el "Fedro" que «las primeras profecías fueron las palabras de un roble», y que todos los que vivieron en esa época encontraron suficientemente gratificante «escuchar a un roble o a una piedra, mientras dijera la verdad».

La creencia en la brujería, es frecuente en muchas sociedades chamánicas. Algunas sociedades distinguen los chamanes que curan de los hechiceros que hacen daño; otros creen que todos los chamanes tienen el poder tanto de curar como de matar; es decir, en algunas sociedades también se piensa que los chamanes son capaces de hacer daño. El chamán normalmente goza de un gran poder y prestigio en la comunidad, y es célebre por sus poderes y conocimientos; pero también pueden ser sospechosos de hacer daño a otros y por lo tanto son temidos.

Por dedicarse a este trabajo, el chamán se expone a un riesgo personal significativo, del mundo de los espíritus, de cualquier chamán enemigo, así como de los medios utilizados para cambiar su estado de conciencia. Ciertos materiales de las plantas usados pueden ser mortales, y el fallo de volver de un viaje extracorpóreo puede llevar a la muerte física. Los hechizos se usan a menudo para protegerse de estos peligros, y el uso de plantas más peligrosas está muy normalmente ritualizado.

Generalmente, el chamán atraviesa el "axis mundi" y entra en el mundo de los espíritus llevando a cabo una transición de conciencia, entrando en un trance extático, bien autohipnóticamente o bien a través del uso de enteógenos. Los métodos utilizados son diversos, y se usan a menudo juntos. Algunos de los métodos para llevar a cabo estos trances:
Los chamanes a menudo cumplen restricciones alimenticias o costumbres particulares de su tradición. A veces estas restricciones son más que solo culturales. Por ejemplo, la dieta seguida por los chamanes y aprendices antes de participar en una ceremonia ayahuasca incluye alimentos ricos en triptófano (un precursor biosintético de la serotonina) así como evita alimentos ricos en tiramina, que pueden inducir crisis hipertensivas si se ingieren con inhibidores de monoamino oxidasa como se encuentra en los brebajes de ayahuasca.

Justo como el propio chamanismo, la música y las canciones relacionadas con él en varias culturas son diversas, lejos de ser parecidas. En algunas culturas y en varios casos, algunas canciones relacionadas con el chamanismo intentan imitar también los sonidos naturales, a veces a través de onomatopeyas.

Por supuesto, en varias culturas, la imitación de sonidos naturales puede cumplir otras funciones, no necesariamente relacionadas con el chamanismo: objetivos prácticos como atraer animales en la caza; o entretenimiento (katajjaqs de los esquimales).

La música una de las arte más antiguas que conecta al ser humano con su yo espiritual pues a través de estas vibraciones el espíritu se abre camino en el mundo espiritual llegando a las puertas de su propio dios interno y de las entidades espirituales quien lo provee de fuerza y sabiduría para sanar o resolver conflictos terrenales.

La música es un medio muy importante en varias prácticas espiritistas no solo en el chamanismo.

Como se ha mencionado más arriba, las culturas calificadas como chamánicas puede ser muy diferentes. Por lo tanto, los chamanes pueden tener varios tipos de parafernalia.

El tambor se usa por los chamanes de varios pueblos de Siberia; lo mismo se aplica a muchos grupos esquimales, aunque puede carecer de uso chamánico entre los esquimales de Canadá.

El redoble del tambor permite al chamán lograr un estado alterado de conciencia o hacer un viaje. El tambor es por ejemplo referido como, «"caballo" o "puente del arco iris" entre los mundos físico y espiritual».
El viaje mencionado es uno en donde el chamán establece una conexión con uno o dos de los mundos de los espíritus. Con el redoble del tambor vienen efectos neurofisiológicos. Mucha fascinación rodea al papel que la acústica del tambor juega en el chamán. Los tambores de los chamanes siberianos son generalmente construidos con una piel de animal estirada sobre un aro de madera curvado, con un asa cruzando el aro.
Hay dos mundos diferentes, el superior y el inferior. En el mundo superior, imágenes como «subir una montaña, árbol, acantilado, arco iris o escalera; ascender al cielo con el humo; volar en un animal, alfombra, o limpiar y encontrar un maestro o guía», son típicamente vistas. El mundo inferior consta de imágenes que incluyen, «entrar en la tierra a través de una cueva, vaciar un tocón de árbol, un charco, un túnel, o un tubo».
Siendo capaz de relacionarse con un mundo diferente en un estado alterado y consciente, el chamán puede entonces intercambiar información entre el mundo en donde él vive y el que ha viajado.

Estas plumas se han visto usándose como un tipo de bisturí espiritual.

Encontrado generalmente entre los pueblos sudamericanos y africanos.
También usado en ceremonias entre los navajos y de manera tradicional en sus bendiciones y ceremonias.

También se sabe que entre algunas de las facultades que el chamán puede desarrollar, esta la de transformarse en alguna forma animal

A menudo encontrado entre los pueblos del Sureste Asiático y Extremo Oriente.

Encontrado principalmente entre los diferentes pueblos aborígenes de Australia.

Mientras que algunas culturas han tenido mayor número de chamanes hombres, otras como las culturas coreanas nativas han tenido una preferencia por las mujeres. La evidencia arqueológica reciente sugiere que los primeros chamanes conocidos —datados en la era del Paleolítico Superior en lo que es hoy la República Checa— eran mujeres.

En algunas sociedades, los chamanes muestran una identidad de dos espíritus, adoptando la vestimenta, los atributos, el rol o función del sexo opuesto, la fluidez del género o la orientación sexual hacia personas del mismo sexo. Esta práctica es común, y se encuentra entre los chukchis, los dayaks del mar, los patagones, los mapuches, los arapahos, los cheyennes, los navajos, los pawnees, los lakotas, y los utes, así como en muchas otras tribus nativas americanas. En efecto, estos chamanes de dos espíritus estuvieron tan extendidos como para sugerir un origen muy antiguo de la práctica. Véase, por ejemplo, el mapa de Joseph Campbell en "The Historical Atlas of World Mythology" (volumen I: «The Way of the Animal Powers», parte 2: pág. 174). Se cree que estos chamanes de dos espíritus son especialmente poderosos, y el chamanismo tan importante para las poblaciones ancestrales que puede haber contribuido al mantenimiento de los genes de los individuos transgénero en poblaciones de reproducción durante el tiempo evolucionario a través del mecanismo de «selección de parentesco».
Son muy respetados y buscados en sus tribus, ya que traerán un alto estatus a sus compañeros.

La dualidad y la bisexualidad también se encuentran en los chamanes del pueblo dogón de Malí (África). Se pueden encontrar referencias sobre esto en varios trabajos de Malidoma Somé, un escritor que nació y fue iniciado allí.

En algunas culturas, la frontera entre el chamán y la persona laica no es nítida:

La diferencia es que el chamán conoce más mitos y entiende mejor su significado, pero la mayoría de los hombres adultos también conocen muchos mitos.

Algo similar puede observarse entre algunos pueblos esquimales. Muchas personas laicas han sentido experiencias que son normalmente atribuidas a los chamanes de esos grupos esquimales: la experimentación de sueños despiertos, la ensoñación o el trance no están restringidos a los chamanes.
Es el control sobre los espíritus ayudantes lo que es principalmente característico de los chamanes, la gente laica usa amuletos, hechizos, fórmulas y canciones.
En Groenlandia entre algunos esquimales, hay personas laicas que pueden tener la capacidad de tener relaciones más cercanas que otros con seres del sistema de creencias. Estas gentes son chamanes aprendices que no consiguieron llevar a cabo su proceso de aprendizaje.

El ayudante de un chamán oroqen (llamado "jardalanin", o «segundo espíritu») sabe muchas cosas sobre las creencias asociadas: él/ella le acompaña en los rituales e interpreta el comportamiento del chamán.
A pesar de esto, el jardalanin no es un chamán. Por su rol interpretativo y de acompañamiento, sería incluso inoportuno entrar en trance.

La manera cómo los chamanes obtienen sustento y toman parte en la vida cotidiana varía entre culturas. En muchos grupos esquimales, proporcionan servicios para la comunidad y obtienen un «pago vencido» (algunas culturas creen que el pago se le da a los espíritus ayudantes), pero estos bienes son solo «añadidos bienvenidos». No son suficientes para permitir hacer de chamán como una actividad a tiempo completo. Los chamanes viven como cualquier otro miembro del grupo, como cazador o ama de casa.

El chamanismo es considerado por algunos como el antecedente de todas las religiones organizadas, ya que nació antes del Neolítico. Alguna de sus aspectos se mantienen en el fondo de estas religiones, generalmente en sus prácticas místicas y simbólicas. El paganismo griego estaba influenciado por el chamanismo, como se refleja en las historias de Tántalo, Prometeo, Medea y Calipso entre otros, así como en los misterios, como los de Eleusis. Algunas de las prácticas chamánicas de la religión griega fueron copiadas más adelante por la religión romana.

Las prácticas chamánicas de muchas culturas fueron marginadas con la propagación del monoteísmo en Europa y el Oriente Medio. En Europa, comenzó alrededor del año 400, cuando la Iglesia Católica consiguió la primacía sobre las religiones griega y romana. Los templos fueron destruidos sistemáticamente y sus ceremonias prohibidas o apropiadas. La caza de brujas fue la última persecución para acabar con el remanente del chamanismo europeo.

La represión continuó con la influencia católica en la colonización española. En el Caribe, y América Central y del Sur, los sacerdotes católicos seguían los pasos de los conquistadores y eran el instrumento de destrucción de las tradiciones locales, denunciando a sus practicantes como "representantes del diablo" y ejecutándolos. En Norteamérica, los puritanos ingleses realizaron campañas periódicas de ataque contra los pueblos indígenas a quienes consideraban como brujos. Más recientemente, ataques contra participantes de prácticas chamánicas han sido llevados a cabo por misioneros cristianos en países del Tercer Mundo. En la década de 1970, algunos misioneros desfiguraron petroglifos históricos en el Amazonas. Una historia semejante de destrucción se puede contar entre budistas y los chamanes, por ejemplo, en Mongolia.

Hoy, el chamanismo sobrevive sobre todo en pueblos indígenas. Su práctica continúa en las tundras, las selvas, los desiertos y otras áreas rurales, y también en ciudades, pueblos, suburbios, y aldeas de todo el mundo. Está especialmente extendido en África, y también en Sudamérica, donde existe el llamado "chamanismo mestizo".

Aunque el chamanismo tenía una gran tradición en Europa antes de la llegada del monoteísmo cristiano, permaneció como una religión organizada y tradicional solamente en Mari-El y Udmurtia, dos provincias semiautónomas de Rusia cuya población era mayoritariamente finesa y húngara.

Entre las tribus húngaras, el centro de la religión era la adoración al ciervo sagrado y al águila celestial conocida como Turul. El universo se hallaba sobre un árbol titánico, el «árbol de la vida», hallándose el inframundo en sus raíces y el mundo superior de los dioses en la copa. A lo largo de su tronco y copa había tres bosques, el bosque de oro, el de cobre y el de plata, y esta era la región corpórea donde habitaban los seres humanos. En el tope del árbol, se sentaba el águila Turul y vigilaba el universo; cuidaba de las almas de los que nacerán, que existían en forma de pájaros, que habitaban en la copa del árbol.

Aquellos que eran chamanes nacían con cualidades físicas, como alguna deformidad o un par de dedos extra en sus manos, que legitimaban sus cualidades divinas y les permitirían comunicarse con los dioses. En el chamanismo húngaro se adoraba a los ríos, rocas, árboles y colinas, a los espíritus de los ancestros y a un dios superior, padre del universo, que se hallaba servido por una corte de dioses menores y otras entidades espirituales.

Un resto del chamanismo en Europa podría ser la brujería, ejercida sobre todo por mujeres que ayudaban en la curación o procuraban los deseos de sus vecinos por medio de hierbas y conjuros. La brujería europea fue perseguida masivamente desde fines del siglo XV, sobre todo en Alemania y Suiza. Eran acusadas de pactar con el diablo, realizar aquelarres o "sabbat", causar mal de ojo, causar todas las enfermedades que se producían, desde la peste a la muerte de niños, y por lo tanto quemadas vivas. La persecución acabó en el siglo XVIII, con la llegada de la Ilustración.

En las Islas Canarias (España), los aborígenes guanches tenían una clase de sacerdotes o chamanes llamados guadameñes.

Todavía se practica en algunas zonas, aunque en muchos otros casos el chamanismo ya estaba en decadencia a comienzos del siglo XX.

La región oriental de Rusia, conocida como Siberia, es un centro de chamanismo en donde muchas de las gentes que pueblan los Urales y Altái han mantenido estas prácticas vivas hasta épocas modernas. Variadas fuentes etnográficas han sido recogidas entre sus gentes.

Muchos grupos de cazadores y criadores de renos practicaron el chamanismo como tradición viva también en época moderna, especialmente los que han vivido aislados hasta tiempos recientes como los naganasan.

Cuando la República Popular China se creó en 1949 y la frontera con la Siberia rusa fue sellada formalmente, quedaron confinados grupos nómadas de tungus que practicaban el chamanismo en Manchuria y Mongolia. El último chamán conocido de los Oroqen, Chuonnasuan (Meng Jin Fu), murió en octubre del 2000.

El chamanismo todavía se practica en Corea del Sur, en donde el papel de chamán lo representan mujeres llamadas "mudang", mientras que los escasos varones son conocidos como "baksoo mudang". Ambos suelen ser miembros de clases bajas.

El título puede ser hereditario o deberse a una capacidad natural. En la sociedad contemporánea se les consulta para tomar decisiones tales como financieras y maritales.

El uso que las "mudang" y los "baksoo mudang" hacen de la "Amanita muscaria" era una práctica tradicional que se creía suprimida desde la dinastía Choseon. Otra seta (extremadamente venenosa) fue retitulada como la seta del chamán, "무당버섯". Los chamanes coreanos son conocidos también por utilizar arañas. Mantienen los trajes de colores, las danzas, los tambores y las armas rituales características.

Hay una gran influencia chamánica en la religión de Bön de Asia central, y en el budismo tibetano; el budismo llegó a ser popular entre los chamanes tibetanos, mongoles, y manchúes a principios de siglo VIII. Las formas rituales chamánicas impregnaron el budismo tibetano, y se institucionalizaron como religión de estado bajo las dinastías chinas Yuan y Qing. Un elemento común entre ambas religiones es la consecución de la realización espiritual, conseguido ocasionalmente por sustancias psicodélicas. De todas formas, la cultura chamánica todavía se practicó por varios grupos étnicos en áreas de Nepal y norte de India, donde no se considera extinguida actualmente, e incluso hay gentes que temen las maldiciones de los chamanes.

En Tíbet, la escuela de Nyingma en particular, mantenía la tradición tántrica de casar a sus sacerdotes, conocidos como Ngakpas (masc.) o Ngakmas/mos (fem.). El Ngakpas se ocupaba de librar a las aldeas de demonios o enfermedades, creando amuletos protectores, realizando los ritos oportunos, etc. Eran despreciados por la jerarquía de los monasterios, que, como en muchas instituciones religiosas convencionales, deseaban preservar sus propias tradiciones, a veces a expensas de otras: dependían de la liberalidad de mecenas que los ayudasen. Esta situación condujo a menudo a un choque entre los pueblos de carácter chamánicos con cultura Ngakpa y el sistema monástico más conservador.

También se practica en las islas de Ryukyu (Okinawa), donde se conocen a los chamanes como "nuru", y en algunas otras áreas rurales de Japón.

Muchos coreanos todavía creen que el sintoísmo es el resultado de la transformación del chamanismo en religión del estado.

El desarrollo de los cultos tribales en África, como en tantas partes del mundo, está adscrito muchas veces, si no a un brujo o chamán de la tribu, a una clase sacerdotal que adquiere particular desarrollo como institución. En multitud de comunidades se dan sacerdotes de distinta categoría y especialidad que cabe estudiar en dos grupos clásicos:

Además de estos chamanes, en África occidental existe la figura del djeli, un bardo cantante y músico ambulante, que es el depositario de las tradiciones orales, y a veces la única fuente que guarda los acontecimientos históricos. Es una figura que permanece en Malí, Gambia, Guinea y Senegal, entre los pueblos manden, fula, wólof, peul, serer entre otros.

Los "chamanes" americanos tienen creencias espirituales diversas. Nunca existió una religión o sistema espiritual común en las Américas siendo estas prácticas asociadas a cada etnia y su territorio. Es más, en el chamanismo amazónico, cada etnia que utiliza las diferentes técnicas chamánicas como el uso de enteógenos, la música y cantos repetitivos, y las dietas y aislamientos prologandos, entre otras prácticas, tienen diferentes cosmogonías asociadas a los mundos alternos que visitan los chamanes.

Algunas de estas religiones indígenas han sido falsificadas burdamente por los observadores y los antropólogos, tomando aspectos superficiales e incluso totalmente erróneos que eran tomados como "más auténticos" que los relatos de los miembros de esas culturas. Se contribuye al error al pensar que las religiones americanas son algo que existió solamente en el pasado, y que se pueden obviar las opiniones de las comunidades nativas.
No todas las comunidades indígenas tienen individuos con un papel específico de mediador con el mundo de los espíritus en nombre de su comunidad. Entre las que tienen esta estructura religiosa, métodos espirituales y creencias pueden tener algunas similitudes, aunque muchas de estas concordancias son debido a las relaciones entre naciones de la misma región o a que las que las políticas gubernamentales post-coloniales mezclaron naciones independientes en las mismas reservas. Esto puede dar la impresión de que hay más uniformidad entre creencias de las que realmente existieron en la antigüedad.

Entre el pueblo mapuche de América del Sur, sirve a la comunidad como chamán una mujer, llamada "machi", que realiza ceremonias y prepara hierbas para curar enfermedades, expulsar demonios e influenciar sobre el tiempo y la cosecha.

La etnia Aymara tiene como parte de la comunidad los Yatiris que son los médicos y los curanderos de la comunidad entre los aymaras de Bolivia, Chile y Perú, que utilizan en su práctica tanto en los símbolos y los materiales tales como hojas de coca. Sus curaciones no solo se restringen al cuerpo humano, si no sobre todo al "alma" o la que llaman AJAYU.

En el inmenso territorio compartido por Argentina (nordeste), Brasil (Estado do Paraná) y Paraguay (este), cerca de la confluencia de los ríos Iguazú y Paraná, habitan los mbyá (hombres del monte o de la selva), que son una etnia guaraní. Sus médicos-chamanes se denominan caraí opy´guá (señor del op´y o recinto ceremonial). Son avanzados curadores físicos y espirituales. Sus rituales de sanación en ocasiones son masivos con la confluencia de los chamanes de muchas comunidades regionales.

En la Amazonía colombiana, ecuatoriana, peruana y boliviana diferentes etnias utilizan plantas enteógenas como la ayahuasca, el yopo, el tabaco y la coca en rituales chamánicos dentro de sus prácticas de medicina tradicional. En ese sentido fue que el Gobierno del Perú declaró el 2008 a la ayahuasca como Patrimonio Cultural de la Nación en la categoría de Conocimientos, saberes y prácticas asociadas a la medicina tradicional. Hoy en día, pueblos como el Shipibo-conibo son un referente para la utilización chamánica de la enredadera de la ayahuasca en combinación con el arbusto chacruna.

Los «hombres medicina» navajos, conocidos como "hatalii", utilizan varios métodos para diagnosticar las dolencias del paciente. Usan herramientas especiales tales como rocas cristalinas, y habilidades tales como trances, acompañados a veces de cánticos. El "hatalii" selecciona un canto específico para cada tipo de dolencia. Los curadores navajos tienen que ser capaces de realizar correctamente la ceremonia de comienzo a fin, ya que en caso contrario no surtirá efecto. El entrenamiento de un "hatalii" es largo y difícil, casi como un sacerdocio. El aprendiz aprende observando a su maestro, memorizando las palabras de todos los cánticos. En ocasiones, un hombre medicina no puede aprender todas las ceremonias tradicionales, así que puede optar por especializarse en unas pocas.

En México es relevante la supervivencia de elementos y rituales de tipo mágico-religioso de los antiguos grupos indígenas, no solo en los indígenas actuales sino en los mestizos y blancos que conforman la sociedad mexicana rural y urbana.En zonas rurales el ó la son de mucha importancia para la vida de la comunidad rural al grado que estas personas pueden en cierta forma dirigir la vida de la gente, de forma muy discreta se acude a ellos y es muy difícil que estas personas acepten que visitan a un chaman, sin embargo, lo hacen muy frecuentemente siguiendo todos sus rituales, aunque existen muchos charlatanes, también hay mucha gente dedicada a la sanación del cuerpo, el alma y el espíritu, los que verdaderamente conocen los saberes de nuestros antepasados en herbolaría y demás si son capaces de sanar y mejorar la vida de las personas.

Hoy en día se mantiene viva la tradición chamánica en la costa y sierra norte del Perú incorporando elementos ancestrales, coloniales y contemporáneos. El cactus de San Pedro que contiene el alcaloide mescalina es un elemento central en esta tradición. Los especialistas rituales, andinos y mestizos, de la mesa curandera norteña en Cajamarca, La Libertad, Lambayeque y Piura utilizan rezos, cantos y música para entrar en trance para diagnosticas y tratar algunas enfermedades. Estas prácticas han sido estudiadas por antropólogos como Douglas Sharon, Luis Millones Santagadea y Alfredo Menacho, entre otros.

En las leyendas de la Tierra del Fuego, el "xon" tiene habilidades sobrenaturales, por ejemplo puede controlar el tiempo.

En las culturas chamánicas, los brujos desempeñan un papel similar al de los sacerdotes, aunque con una diferencia esencial:

Un chamán se puede iniciar a causa de una enfermedad grave, porque ha soñado con un rayo o un trueno, o por una experiencia cercana a la muerte, o bien porque se siente llamado a serlo. Hay todo un bagaje de imágenes culturales para experimentar en la iniciación, sin importar el método de inducción. Según Mircea Eliade, tales imágenes incluyen a menudo el viaje al mundo de los espíritus y el conocimiento de los seres que lo habitan, encontrando una guía espiritual, para emerger transformado, a veces con amuletos implantados, como cristales mágicos. Las imágenes de la iniciación hablan generalmente de la transformación y de los poderes concedidos para superar la muerte y renacer.

En algunas sociedades se considera que los poderes chamánicos son hereditarios, mientras que en otras deben ser "llamados" y necesitan un largo entrenamiento. Entre los Chukchis siberianos uno puede comportarse de forma tal que un médico "occidental" quizás caracterizaría como sicópata, pero que los siberianos interpretan como la prueba de la posesión por un espíritu, que le exige al poseso que asuma su vocación de chamán. Entre los Tapirapes suramericanos los chamanes son llamados en sus sueños. En otras sociedades eligen libremente su carrera. En Norteamérica, buscan la comunión con los espíritus a través de una visión, mientras que el shuar suramericano, busca el poder de defender a su familia contra enemigos aprendiendo de otros chamanes. El urarina de la Amazonía peruana tiene un elaborado sistema, afirmado en la consumición ritual de ayahuasca. Junto con impulsos milenarios, el chamanismo del ayahuasca de los urarinas es una característica dominante de esta mal documentada sociedad.

Estas supuestas tradiciones chamánicas también se pueden observar entre los indígenas kuna de Panamá, que confían en poderes y talismanes sagrados para sanar. Los chamanes gozan de una posición privilegiada entre la gente local.

La enfermedad del chamán, también llamada crisis iniciática chamánica, es una crisis sico-espiritual, o un rito del paso, observado entre los chamanes novicios. Marca a menudo el principio de un corto episodio de confusión o disturbios del comportamiento en que el iniciado puede cantar o bailar en una manera poco convencional, o tiene una experiencia de «ser molestado por espíritus». Los síntomas no son considerados como muestras de enfermedad mental por los intérpretes de la cultura chamánica; más bien se interpretan como indicaciones al individuo para que tome el oficio de chamán.
El papel significativo de las enfermedades iniciáticas, se puede encontrar en la historia detallada de Chuonnasuan, el último chamán de los tungus en el noreste de China.

El movimiento "New Age" se ha apropiado de algunas ideas del chamanismo, así como de creencias y prácticas de las religiones de oriente y de distintas culturas indígenas. Como con otras apropiaciones, los seguidores originales de estas tradiciones condenan su uso, considerándolo mal aprendido, superficialmente entendido y mal aplicado.

Hay un esfuerzo en algunos círculos ocultistas y esotéricos para reinventar el chamanismo en una forma moderna, partiendo de la base de un sistema de creencias y de prácticas sintetizadas por Michael Harner a partir de varias religiones indígenas. Harner ha hecho frente a muchas críticas por creer que partes de diversas religiones se pueden sacar de contexto para formar una cierta forma de tradición chamánica universal. Algunos de estos neochamanes también se centran en el uso ritual de enteógenos, así como en la magia del caos. Alegan que se basan en tradiciones investigadas (o imaginadas) de la Europa antigua, en donde creen que muchas prácticas y sistemas místicos fueron suprimidos por la iglesia cristiana.

Algunos de estos practicantes expresan su deseo de utilizar un sistema que se base sobre sus propias tradiciones ancestrales. Algunos antropólogos han discutido el impacto de tal neochamanismo en las tradiciones americanas indígenas, ya que estos "practicantes chamánicos" no se llaman a sí mismos chamanes, sino que usan nombres específicos derivados de las viejas tradiciones europeas; el völva (varón) o el seidkona (mujer) de las sagas son un ejemplo.










</doc>
<doc id="4708" url="https://es.wikipedia.org/wiki?curid=4708" title="Horóscopo">
Horóscopo

El horóscopo, y la carta natal, en astrología, son métodos de predicción no demostrada basados en la posición arbitraria de los astros en el momento del nacimiento. El término deriva del griego "ὥρα" ("hora", "hora"), y "σκοπέω" ("skopeo", "examinar")

No existe ninguna prueba o estudio científico que apoye la validez de las predicciones obtenidas mediante cualquiera de las diferentes versiones de esta práctica.

Algunas personas sostienen que la creencia en la efectividad del horóscopo se ve potenciada por un fenómeno psicológico normal (basado en la búsqueda automática de patrones por parte del cerebro) en las personas, por el que se recuerdan fácilmente las coincidencias y se olvidan las faltas de coincidencia. La vaguedad unida a la alta probabilidad de las supuestas predicciones permiten un índice de aciertos bajo, pero lo suficientemente alto para que funcione el mecanismo psicológico descrito.

Muchas culturas utilizaron formas de predicción similares basándose en sus propios calendarios en relación directa con los astros. La civilización Maya, por ejemplo.

Antes de que el horóscopo tuviera el carácter que le otorgó la cultura grecolatina, se ha descubierto que en Babilonia, bajo el reinado persa, como lo afirma Van der Waerden, nació la astronomía horoscópica, sin embargo existen datos relacionados con cuentas astronómicas y en esa etapa, astrológicas, desde la antigüedad:


El horóscopo es una representación gráfica de las posiciones planetarias en un momento especial; que normalmente es el de nacimiento de una persona, aunque también puede ser el momento en el que se inicia un proyecto empresarial, se tiene una idea especial, se realiza un trato, se realiza una boda, comienza un viaje, etc.

Esta representación de un horóscopo utiliza cálculos matemáticos y astronómicos que deberían ser idénticos independientemente de quien lo haga, siempre que se le faciliten los mismos datos iniciales.

La interpretación que se haga de ese horóscopo desde el punto de vista de la astrología pasa a ser una labor subjetiva, cuyas normas de interpretación varían dependiendo de la experiencia del astrólogo y de su formación como tal.

Para realizar un horóscopo es necesario conocer la fecha, la hora y el lugar de nacimiento.

Las posiciones planetarias y de los demás cuerpos celestes se consideran desde una visión geocéntrica.

En el horóscopo se representan la posición de los planetas, pero también las posiciones resultantes de hacer una división de la franja zodiacal en 12 partes, que es lo que se denominan las "casas astrológicas". La primera de esas 12 casas astrológicas comienza por lo que se denomina el "Ascendente".

En el horóscopo se representan los planetas astrológicos, que incluyen todos los Astros del Sistema Solar, la Luna y el Sol incluidos. La razón de ello es que esos cuerpos celestes, que no son planetas desde el punto de vista de la astronomía, son llamados astros en la astrología el Sol y la Luna sin embargo son llamados luminarias.

El horóscopo se suele representar como un círculo dividido en 12 partes y compuesto primero de la división zodiacal.

La segunda de las divisiones se corresponde con las "casas astrológicas", que raramente tienen 30 grados exactos y que dependen del espacio geográfico en el que se calcula el horóscopo. Así, si 2 personas nacen en el mismo momento, pero una en Australia y otra en Inglaterra, sus respectivos horóscopos serán iguales en cuanto a posiciones planetarias, pero muy diferentes en cuanto a las casas astrológicas; y eso determinaría una interpretación astrológica muy diferente en ambos casos.

Las divisiones del círculo por "casas" y por "signos" son independientes, de forma que el comienzo de las "casas" puede coincidir con cualquier posición en la división por "signos".

Los planetas astrológicos se distribuyen por el círculo según su posición en el cielo en el momento en el que se calcula el horóscopo. En ocasiones, están muy agrupados, en otras están más o menos dispersos.

También se suelen representar en el horóscopo los "aspectos", que son una selección de algunas de las distancias angulares entre los planetas y/o puntos sensibles, como podría ser el ascendente. De esta manera, si la posición de Saturno y la del Sol están separados por 120 grados, se diría que forman el aspecto llamado Trígono. Si su separación fuera de 180 grados, formarían un aspecto de Oposición, etc.

Teniendo en cuenta las posibles posiciones de los planetas en las "casas" y los "signos y sus aspectos", se dan muchísimas combinaciones que determinan diferencias en el momento de interpretar astrológicamente un horóscopo.

La tradición de la creación de horóscopos proviene sobre todo de las creencias de la historia antigua. Por aquel entonces se creía que la posición y movimiento de los cuerpos celestes podían predecir futuros acontecimientos o el desarrollo de la personalidad de un ser humano. Por el contrario, estas suposiciones han sido refutadas en numerosas publicaciones científicas. Por esta razón, horóscopos y la práctica general de su composición así como la astrología misma, están asignados al Esoterismo.



</doc>
<doc id="4711" url="https://es.wikipedia.org/wiki?curid=4711" title="Mallorquín">
Mallorquín

El mallorquín (en mallorquín: "mallorquí") es «la variedad del catalán que se habla en Mallorca». Es similar a los dialectos que se hablan en las otras islas del archipiélago balear: el ibicenco —"eivissenc"— en Ibiza y Formentera; y el menorquín —"menorquí"— en Menorca.

Hay indicios de que antes de la conquista se hablaba en la isla, además de árabe, un romance local o "mozárabe" sin relación con el catalán, del que pervivirían algunos topónimos como Muro o Campos. 

Debido al exterminio o expulsión de la mayor parte de la población autóctona, no había suficiente mano de obra para el cultivo del campo. La lengua catalana fue introducida en Mallorca por los repobladores, tras ser conquistada para la Corona de Aragón en 1229. Los repobladores procedían de diversos lugares y llegaron en diferentes proporciones. Según el "Llibre del Repartiment", las tierras conquistadas fueron repartidas entre gente proveniente de Cataluña (39,71 %), de Occitania (24,26 %), Italia (16,19 %), Aragón (7,35 %), Navarra (5,88 %), Francia (4,42 %), Castilla (1,47 %) y Flandes (0,73 %). En 1230 se dictaron las Franquezas de Mallorca, privilegios que atrajeron a más repobladores para cultivar el campo. La nueva población de Mallorca provenía esencialmente de Cataluña, más específicamente del Rosellón y del Ampurdán, por lo cual se conservan características dialectales emparentadas con variantes de dichas zonas, como el uso del "article salat". Quizá por este origen, la lengua propia de Mallorca es un dialecto oriental del catalán.

La posición estratégica del archipiélago balear ayudó a que se convirtiera en puente para la expansión de la Corona de Aragón y en un centro de comercio marítimo, así, tanto el mallorquín como otros dialectos baleares cuentan con numerosos préstamos léxicos tomados de otros idiomas, como el francés, el italiano, el provenzal y el griego. En el siglo XVIII el dominio británico sobre Menorca introdujo algunas palabras de origen inglés, como: “"xoc"” —de “"chalk"”: “tiza”—, “"escrú"” —“"screw"”: “tornillo”—, etc.

Aclaraciones previas:

En fonética:

En morfología: 

En morfología verbal:

En sintaxis:

En léxico:





</doc>
<doc id="4712" url="https://es.wikipedia.org/wiki?curid=4712" title="Habitación china">
Habitación china

La habitación china es un experimento mental, propuesto originalmente por John Searle y popularizado por Roger Penrose, mediante el cual se trata de rebatir la validez del Test de Turing y de la creencia de que el pensamiento es simplemente computación.

Searle se enfrenta a la analogía entre mente y ordenador cuando se trata de abordar la cuestión de la conciencia. La mente implica no sólo la manipulación de símbolos (gramática o sintaxis), sino que además posee una capacidad semántica para darse cuenta, o estar consciente, de los significados de los símbolos.

En 1995, cuando Herbert Simon y Allen Newell Simon escribieron que "Ahora hay máquinas que leen, aprenden y pueden crear", se trataba de dar a entender que se había dado una solución al problema mente-cuerpo.

Pero Searle en su texto de "Mentes, Cerebros, Ciencia" ataca este pensamiento, y con el experimento de la Habitación China muestra cómo una máquina puede realizar una acción sin siquiera entender lo que hace y el por qué lo hace. Por lo tanto según Searle la lógica usada por las computadoras es nada más que una que no busca el contenido en la acción como la usada por los seres humanos.

Supongamos que han pasado muchos años, y que el ser humano ha construido una máquina aparentemente capaz de entender el idioma chino, la cual recibe ciertos datos de entrada que le da un hablante natural de ese idioma, estas entradas serían los signos que se le introducen a la computadora, la cual más tarde proporciona una respuesta en su salida. Supóngase a su vez que esta computadora fácilmente supera la Prueba de Turing, ya que convence al hablante del idioma chino de que sí entiende completamente el idioma, y por ello el chino dirá que la computadora entiende su idioma.

Ahora Searle nos pide que supongamos que él está dentro de ese computador completamente aislado del exterior, salvo por algún tipo de dispositivo (una ranura para hojas de papel, por ejemplo) por el que pueden entrar y salir textos escritos en chino.

Supongamos también que fuera de la sala o computador está el mismo chino que creyó que la computadora entendía su idioma y dentro de esta sala está Searle que no sabe ni una sola palabra en dicho idioma, pero está equipado con una serie de manuales y diccionarios que le indican las reglas que relacionan los caracteres chinos (algo parecido a "Si entran tal y tal caracteres, escribe tal y tal otros").

De este modo Searle, que manipula esos textos, es capaz de responder a cualquier texto en chino que se le introduzca, ya que tiene el manual con las reglas del idioma, y así hacer creer a un observador externo que él sí entiende chino, aunque nunca haya hablado o leído ese idioma.

Dada esta situación cabe preguntarse:


De acuerdo a los creadores del experimento, los defensores de la inteligencia artificial fuerte -los que afirman que programas de ordenador adecuados pueden comprender el lenguaje natural o poseer otras propiedades de la mente humana, no simplemente simularlas- deben admitir que, o bien la sala comprende el idioma chino, o bien el pasar el test de Turing no es prueba suficiente de inteligencia. Para los creadores del experimento ninguno de los componentes del experimento comprende el chino, y por tanto, aunque el conjunto de componentes supere el test, el test no confirma que en realidad la persona entienda chino, ya que como sabemos Searle no conoce ese idioma.

Esto es así en el contexto de la siguiente argumentación:


Una puntualización importante: Searle no niega que las máquinas puedan pensar -el cerebro es una máquina y piensa-, niega que al hacerlo apliquen un programa.

El experimento mental de la habitación china confirmaría la premisa 2, a juicio de sus defensores.
A juicio de sus detractores, la premisa 2 basada en la inferencia a partir del experimento mental no es concluyente. Las objeciones suelen seguir una de las tres líneas siguientes:


No hay razón para decir que estos modelos sólo exhiben una comprensión aparente, como en el caso de la habitación y su habitante, pero son modelos de Inteligencia Artificial.









</doc>
<doc id="4714" url="https://es.wikipedia.org/wiki?curid=4714" title="DocBook">
DocBook

DocBook es una aplicación del estándar SGML/XML e incluye una DTD propia y que se utiliza de manera más destacada en el área de la documentación técnica, especialmente para documentar todo tipo de material y programas informáticos. Existe un Comité Técnico de DocBook en OASIS (originalmente "SGML Open") que mantiene y actualiza este estándar. DocBook inicialmente comenzó como una DTD de SGML, pero a partir de la versión 4 existe un equivalente para XML.

Como lenguaje semántico que es, DocBook nos permite crear documentos en un formato neutro, independiente de la presentación. En este formato neutro se recogen tanto el contenido como la estructura lógica del mismo, permitiendo así que pueda ser publicado (presentado) automáticamente en multitud de formatos: HTML, XHTML, EPUB, PDF, man pages , HTML Help, etc., simplemente aplicando "plantillas" de presentación, sin que sea necesario ningún cambio sobre el documento original.

DocBook es un lenguaje XML. En su versión actual (5.0), está formalmente definido por un esquema RELAX NG con reglas Schematron integradas. (Existen también un XML Schema+Schematron y un DTD, pero actualmente se consideran no estándares.)

Los documentos DocBook no describen ni la apariencia ni la presentación de sus contenidos, sino únicamente el "sentido" de dichos contenidos. Por ejemplo, en lugar de indicar exactamente cómo ha de visualizarse una determinada frase que es el título de un capítulo, DocBook simplemente indica que dicha frase "es" un título de capítulo. Posteriormente, el decidir dónde y cómo se ha de mostrar dicho título dentro de la página será tarea de una herramienta procesadora externa o de la aplicación visualizadora que estemos manejando.

DocBook dispone de un gran número de etiquetas para describir elementos semánticos, englobándose estas en tres grandes categorías: estructurales, de bloque y de línea.

Las etiquetas estructurales especifican características generales de sus contenidos. Por ejemplo, el elemento "book" especifica que sus elementos hijo serán partes de un libro: "títulos", "capítulos", "glosarios", "apéndices", etc.
Algunas etiquetas estructurales son:
Los elementos estructurales pueden contener a otros elementos estructurales, pero han de ser siempre elementos de primer nivel dentro de un documento DocBook.

Las etiquetas de bloque representan elementos tales como "párrafos", "listas", etc., y no todos ellos han de contener necesariamente texto en su interior. Estos elementos de bloque suelen ir distribuidos secuencialmente, y serán visualizados uno "debajo" de otro. (Aunque "debajo" puede variar dependiendo del entorno cultural: en la mayoría de lenguajes occidentales "debajo" significará un sentido descendente en la página; pero en algunos lenguajes orientales, "debajo" significará un sentido en columnas de derecha a izquierda. La especificación DocBook es completamente neutral a ese tipo de conceptos intrínsecos de cada cultura.)

Las etiquetas de línea representan elementos tales como "letras enfatizadas", "hyper-enlaces", etc, y se suelen aplicar a porciones de texto en el interior de un elemento de bloque, provocando habitualmente que la herramienta procesadora de presentación aplique algún tipo de tratamiento tipográfico especial a dichas porciones. (La especificación de DocBook indica que se espera un tratamiento tipográfico especial, pero no indica exactamente qué tratamiento específico se debe aplicar. Por ejemplo, "letras enfatizadas" no implica necesariamente "letras en cursiva"; la herramienta de presentación puede optar por aumentarles el tamaño de letra o por cambiarles el color de fondo.)

Desde un punto de vista semántico, este documento es un "artículo" (article), con su respectivo "título" (title). Se identifica claramente al "autor" (author), y se podría haber incluido también otro tipo de "información" adicional (articleinfo). Este artículo de ejemplo consta de una sola "sección", también con su respectivo "título"; y con "párrafos" (paragraph) de texto.

Desde un punto de vista semántico, este documento es un "libro" (book), con un "título" (title); consta de dos "capítulos" (chapter), cada uno de ellos con sus propio "título", y estos "capítulos" tienen "párrafos" (paragraph) de texto. Todo ello expresado en un formato fácilmente comprensible por humanos.

Tanto los distintos elementos que forman un DocBook, como las reglas para combinarlos (por ejemplo, que todo elemento "libro" ha de contener un elemento "título", previo a cualquier otro elemento estructural tal como "capítulo"), se definen formalmente en un esquema (schema), de tal forma que los programas informáticos pueden validar el documento contra dicho esquema, y determinar así, en todo momento, si el documento está "bien formado".

Como documentos XML que son, los documentos DocBook pueden ser escritos con cualquier editor de texto, aunque siempre será más sencillo escribirlos con un editor XML, o, mejor aún, con un editor XML que lleve integrados los esquemas específicos de DocBook. Por ejemplo Emacs, trabajando en modo nXML, o XML Copy Editor.

También existen editores más "visuales" (WYSIWYG), tales como XMLmind Editor ("XXE"), Oxygen XML Editor, capaz de representar los documentos DocBook formateándolos con CSS; o Syntext Serna, que realiza transformaciones XSL en tiempo real.

Asimismo, como documentos XML que son, los documentos DocBook pueden ser validados y procesados automáticamente por cualquier herramienta o lenguaje de programación que soporte XML.

Estas herramientas se suelen utilizar para crear documentos de salida en un amplio abanico de formatos, habitualmente haciendo uso de "hojas de estilo" DocBook XLS, un tipo de hojas XSLT que nos permiten transformar documentos DocBook a otros formatos tales como HTML, PDF, etc., permitiendo conversiones tan sofisticadas como para que contemplen la generación automática de tablas de contenido, de glosarios y/o de índices, o que permitan incluso filtrados previos de contenidos, extractando solo ciertas partes del DocBook original.

DocBook es muy utilizado en algunos contextos, entre los que destacan Linux Documentation Project (Proyecto de documentación Linux), las referencias de las APIs de GNOME y GTK+, así como la documentación del núcleo Linux. Las páginas "man" del Entorno Operativo Solaris se generan también a partir de documentos que utilizan las DTDs o los esquemas de DocBook.

DocBook nació en 1991, de un proyecto conjunto de HAL Computer Systems y O'Reilly & Associates, evolucionando posteriormente hasta tener su propia organización (el Grupo Davenport), para acabar, en 1998, siendo gestionado por el consorcio "SGML Open", que más tarde se convertiría en la organización OASIS, en cuyo seno existe actualmente el "DocBook Technical Committee", encargado del mantenimiento del estándar DocBook.

La especificación DocBook está disponible tanto en el formato SGML como en el formato XML, estando definida tanto por un documento DTD, como por un esquema RELAX NG - W3C XML Schema. A partir de la versión 5, el esquema RELAX NG es el "normativo", siendo el resto de formatos meras adaptaciones del mismo.

DocBook nació como una aplicación de SGML, pero actualmente su adaptación XML la ha sustituido en la mayoría de usos. (A partir de la versión 4 del DTD SGML, la versión DTD XML ha tomado su propio camino y su propio esquema de numeración.)

En un principio, el uso del formato DocBook estaba prácticamente reducido al grupo de compañías participantes en su diseño, pero en estos momentos ha sido ampliamente adoptado por toda la comunidad de software libre y por un amplio espectro de compañías, existiendo en el mercado multitud de herramientas que hacen uso de él.

Norman Walsh y el equipo de desarrollo del DocBook Open Repository mantienen un conjunto de hojas de estilo DSSSL y XSL para generar versiones PDF y HTML de documentos DocBook (así como para desarrollar otros formatos, incluyendo páginas de referencia "man" y de ayuda en HTML). Walsh es también el principal autor del libro "DocBook: The Definitive Guide" (DocBook: La Guía Definitiva), la documentación oficial de DocBook. Este libro se puede obtener bajo licencia GFDL o en su versión impresa (ISBN 1565925807), editada por O'Reilly & Associates."


</doc>
