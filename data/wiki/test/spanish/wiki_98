<doc id="27991" url="https://es.wikipedia.org/wiki?curid=27991" title="Tratado de Verdún">
Tratado de Verdún

El Tratado de Verdún fue un pacto alcanzado el 10 de agosto de 843 entre Lotario I, Luis el Germánico y Carlos el Calvo —hijos de Ludovico Pío y nietos de Carlomagno—, en la localidad francesa homónima. Este tratado tuvo como origen la "ordinatio imperii", que decretaba el modo de proceder si fallecía uno de los monarcas subsidiarios sin descendencia. No obstante, esto dio como resultado una serie de conflictos en el imperio que, lejos de solventar las divisiones, las acentuó. El documento estableció las regiones que le correspondían a cada heredero y previo a la rúbrica de este tratado, se acordó entre ellos un compromiso de ayuda mutua. Así, se puso fin a la «guerra civil carolingia» y al proyecto de Carlomagno de hacer resurgir el Imperio romano, mediante la firma de los Juramentos de Estrasburgo el 14 de febrero de 842. Tras ser llevado a cabo el reparto, surgieron tres territorios que pasaron a denominarse Francia Occidental, Francia Media y Francia Oriental.

Lotario I se estableció en Italia y fue el depositario del título de emperador. Luis el Germánico fijó su residencia en Baviera y se le concedieron los territorios germánicos y anexos que iban desde los Alpes hasta el Rin. Carlos el Calvo recibió la parte occidental de lo que restaba del Imperio carolingio. Gracias a este reparto surgieron tres realidades socio-políticas desarrolladas como reinos independientes de las que Francia Oriental y Francia Occidental (germen del futuro Reino de Francia) subsistieron hasta el siglo X, a diferencia del territorio central que fue absorbido por los territorios occidental y oriental tras la defunción de los herederos de Lotario I.

Tras la muerte de Luis el Piadoso, el Imperio carolingio se dividió entre sus tres hijos: Carlos el Calvo, Lotario I y Luis el Germánico, siguiendo lo firmado en el Tratado de Verdún. De este modo, a cada uno de los herederos le fue otorgado un reino: a Lotario I se le otorga Italia, Luis el Germánico se establece en Baviera y Carlos el Calvo en Aquitania. En dicho acuerdo Lotario I se reservó el título de emperador y el reparto del Imperio de Luis el Piadoso se realizó de la siguiente manera entre sus herederos:


Tras la muerte de Luis el Piadoso y el reparto a raíz del Tratado de Verdún, el título imperial quedó reducido a un carácter simbólico. Después del reparto, Carlos II el Calvo recibió el territorio de la Francia Occidentalis, precursor de la actual Francia. Tras llegar a Verdún, cada hermano recibió su territorio: Lotario I recibe la Francia Media, a Luis el Germánico se le entregó la Francia Orientalis y el territorio restante hasta España se le hizo entrega a Carlos, hecho reflejado en los Anales de Flodoard.

El acuerdo tuvo resultados políticos considerables. Asimismo, se evidenció el fracaso de la restauración imperial carolingia, gestando el germen de lo que posteriormente serían las naciones de Francia — al oeste— sobre la base del territorio de Carlos; y en el poniente Alemania —sobre la base de las regiones de Luis al este—. La demarcación de Lotario (que suele denominarse Lotaringia, aunque es más correcto denominar con ese apelativo a la zona septentrional que se le concedió a su vástago Lotario II), comprendía el área que la historiografía designa con el nombre de Flandes —los actuales Países Bajos, Bélgica y Luxemburgo—; el sector ubicado al oeste del Rin — las actuales comarcas francesas de Alsacia y Lorena y parajes de las actuales áreas alemanas denominadas Renania — y los actuales territorios de Borgoña, Provenza y el norte de la actual Italia.

Su estabilidad fue muy insegura por sus divisiones y reparto. Primero entre los vástagos de Lotario —Tratado de Prüm, 855— y después entre las monarquías vecinas —Tratado de Mersen, firmado el 8 de agosto de 870, y Tratado de Ribemont, en el 880— y gracias al Tratado el Imperio quedó de la siguiente forma: el Imperio franco fue dividido en tres partes diferenciadas formando tres reinos: el reino central, oriental y occidental. El título de emperador recayó sobre Lotario I, que a su vez recibió el reino central, cuya extensión iba desde el mar del Norte hasta el golfo de Gaeta; incluyéndose las ciudades de Aquisgrán y Roma. Por su parte, Luis el Germánico se hizo con el reino oriental. Por último, Carlos el Calvo recibió el reino occidental y, a pesar de esta división del Imperio carolingio, formalmente sí se reconocería la unidad imperial, siendo coronado como rey en el año 848 en Orleans.

Tras el reparto de Verdún, Carlos el Calvo recibió el territorio denominado Francia Occidental, cuyo marco cronológico se extendía desde el año 843 hasta el año 987, surgiendo a raíz de la fragmentación del Imperio carolingio tras el Tratado de Verdún. También se le denominó Reino de los francos occidentales y es el germen del Reino de Francia. Cronológicamente, se situó entre los años 843 al 987. Este reino surgió tras producirse la división del Imperio carolingio a raíz del Tratado de Verdún y geográficamente abarcaba el sur de la actual Francia, culminando en la denominada Marca Hispánica. No obstante, Carlos sostuvo un enfrentamiento con su sobrino Pipino II de Aquitania, dado que al fallecer su padre fue reconocido como soberano solo por la nobleza sin tener en cuenta el beneplácito del emperador, quien en la asamblea de Worms del año 939, eligió a Carlos como monarca. Por su parte, Carlos el Calvo entró en guerra con Pipino en el año 840. Así, tras varias derrotas, en el año 845 se rubricó el tratado de Benoît-sur-Loire, reconociendo los derechos de su sobrino. A partir del año 840, proliferaron batidas vikingas, siendo París saqueada entre los años 856 y 862. Por ello, Carlos el Calvo tomó medidas que fueron ineficaces, siendo necesario llegar a un vasallaje con los vikingos, cediéndoles el territorio que se denominaría Normandía. Además a esto se unieron las incursiones de los magiares a partir del año 920.

Por su parte, el primogénito de Ludovico Pío sobre el que recae el título de emperador, Lotario I, obtuvo como reino la Francia Media, que estaba situada en medio del mar del Norte y el mar Mediterráneo. Comprendía lo que actualmente son los Países Bajos, Luxemburgo, Bélgica, el oeste del Rin, Francia, Suiza y el norte de Italia. A su vez, el Reino de los Francos Orientales, llamado también Francia Oriental, sería el germen de la futura monarquía en Alemania. A Luis el Germánico le correspondió la parte oriental mayoritariamente germano parlante, hecho que es referido en los Annales fuldenses, que hacían mención a la división del Imperio y a la parte oriental que se le otorgó a Luis el Germánico. Este territorio estaba compuesto de conquistas procedentes del siglo , que incluía los ducados de Alemania, Baviera, Sajonia y Turingia junto con las marcas danesa y eslava.

El 10 de agosto del año 843, fallecido Luis el Piadoso y tras una añada, sus vástagos y herederos rubricaron el Tratado de Verdún mediante el que Luis el Germánico obtuvo la parte oriental denominada Francia Oriental, que estaba formada por incorporaciones regionales del siglo al Imperio carolingio, entre las que se incluían: Alemania, Baviera, Sajonia, Turingia y las marcas danesa y eslava cuya población era germano y eslavo parlantes mayoritariamente, formando una población que se dividía por raza, costumbres y lengua.





</doc>
<doc id="27992" url="https://es.wikipedia.org/wiki?curid=27992" title="Viaje al centro de la Tierra">
Viaje al centro de la Tierra

Viaje al centro de la Tierra (Voyage au centre de la Terre) es una novela de Julio Verne, publicada el 25 de noviembre de 1864, que trata de la expedición de un profesor de mineralogía, su sobrino y un guía al interior del globo o al interior de la Tierra.

Esta es una de las pocas novelas de Julio Verne que no fue serializada.

El protagonista de la historia, Axel, reside en una vieja casa situada en la Königstrasse, en Hamburgo, junto a su tío Otto Lidenbrock, un prestigioso profesor de mineralogía en el "Gelehrtenschule des Johanneums" (designado en libro como "Johanneum"), a quien describe como un hombre temido por su fuerte carácter pero muy original, su pareja Gräuben y su sirvienta, Marta. Un día el profesor le llama a su despacho, donde le enseña un manuscrito de gran valor del Heimskringla, de Snorri Sturluson. Pero ese libro esconde una gran sorpresa: un pergamino de origen rúnico que oculta un mensaje secreto. Tras muchos esfuerzos y gracias a un descubrimiento casual de Axel, lograrán descifrarlo. En él, un alquimista islandés llamado Arne Saknussemm revela cómo llegar al centro de la tierra. El profesor, eufórico, decide ir al lugar indicado en el pergamino junto con su sobrino Axel. 

Axel está muy asustado y no quiere ir, pero no tiene otra opción, y salen hacía el punto indicado en el pergamino: Islandia. Tras un largo viaje, llegarán a Reikiavik, ciudad cercana al Snæfellsjökull, volcán por el que tendrán que introducirse para alcanzar el corazón terrestre, siguiendo las indicaciones de Saknussemm. Allí contratan a Hans, un cazador de éiders profesional, que les acompañará a lo largo de su odisea. Equipados con víveres, herramientas, armas, instrumentos, linternas eléctricas y un botiquín, emprenden el viaje hacia el volcán. 

Emprenden el asalto del Sneffels por caminos difíciles. La marcha es penosa, pero al fin alcanzan la cumbre del volcán. Allí encontrarán una grata sorpresa: Saknussemm ha señalado su presencia inscribiendo su nombre en una roca, mostrando así que su viaje era real. Llegados al fondo del cráter, se abren tres chimeneas. Siguiendo una vez más las instrucciones dejadas por el alquimista en el pergamino, averiguan cuál de las tres chimeneas es la que conduce al centro de la Tierra: aquella que la sombra del pico Scartaris acaricie antes de las calendas de julio. Por medio de una cuerda, se van deslizando y bajan así 2 800 pies en once horas. Allí improvisan una cama para dormir y recuperar fuerzas.

A la mañana siguiente, siguen hundiéndose en las entrañas del Globo dejándose caer por pendientes inclinadas, formadas por lava seca que tapiza el interior del cráter. Tras un largo descenso, llegan al fondo de la chimenea, donde se encuentran con dos caminos. El profesor Lidenbrock decide tomar el del Este, y tal camino resulta ser el erróneo, pues al tercer día se quedan sin agua y han de retroceder para ir hacia el Oeste. Cuando los personajes están muriéndose de sed tras varios días sin hallar nada de agua, Hans, el guía que los acompaña, halla un torrente bajo las rocas. Perforan la piedra con las herramientas que llevan y consiguen agua, pero a 100º de temperatura; la dejan enfriar y de ese modo sacian su sed y llenan las cantimploras.

A la mañana siguiente, siguen su camino descendiendo y acercándose cada vez más al centro de la tierra. Axel se despista de su tío y de Hans, y se pierde en un túnel. No obstante, la peculiar acústica del lugar le permite conversar con su tío a pesar de encontrarse muy lejos de él. Siguiendo las indicaciones de éste, se pone en camino. Cae accidentalmente por un pozo, pero providencialmente la inclinación de éste le llevará hasta donde están Hans y su tío. Cuando vuelve en sí, ve que se encuentran junto a un mar: están en una caverna capaz de contener la cantidad de agua de un océano. Cerca de allí, hay un bosque de hongos donde hallan esqueletos de animales y de humanos.

Hans construye una balsa, y de ese modo embarcan e inician una travesía con el fin de alcanzar nuevas salidas en las orillas opuestas. El viaje por mar se hace más largo de lo que pensaban. Durante la travesía pescarán peces extintos del género pterichthyodes y se encuentran con monstruos marinos enormes, un ictiosaurio y un plesiosaurio pero por suerte los animales están luchando entre ellos y no se percatan de la presencia de la balsa.

Axel y sus dos acompañantes continúan el viaje con su monótona uniformidad. Pasan al lado de un islote, llamado por ellos "Islote de Axel", en el que hay un géiser de agua hirviendo a una temperatura de 163ºC.
Siguen su camino y les amenaza una tempestad, el viento sopla a una velocidad incalculable, los relámpagos no cesan, el calor aumenta. De repente ven un disco de fuego pasearse por el espacio a la velocidad de un huracán (posiblemente un rayo globular), que les arranca la vela con el mástil, y los tres amigos son arrastrados con gran rapidez hasta que la almadía choca con los arrecifes de la costa.

Axel y su tío se libran de la muerte gracias al guía, Hans, que los arranca del abismo tumbándolos en la arena de la playa. Consiguen rescatar la pólvora, la brújula, el manómetro y alimentos para cuatro meses, si bien han perdido las armas.

Con la ayuda de la brújula, comprueban su situación y ven que durante la tempestad han retrocedido en lugar de avanzar. Furioso y desafiando todos los peligros, el profesor Lidenbrock dice que han de volver a la balsa para seguir el viaje, pero antes quiere inspeccionar el lugar donde habían llegado a la deriva. Este lugar les reserva más sorpresas: un cementerio de cuerpos fosilizados en el cual hallan primero un cráneo humano y luego un cadáver entero semimomificado de la era cuaternaria . 

Siguen explorando el terreno y se alejan de la orilla del mar. Llegan a un bosque de vegetación de la era terciaria con palmeras, pinos, cipreses y helechos. Debajo de esos árboles ven agitarse unos mastodontes gigantes y lo que creen un ser humano de más de cuatro metros de altura con una cabeza del tamaño de un búfalo que los pastorea como si fueran ovejas. Les parece imposible y piensan que podría ser una visión, pero huyen a gran velocidad hacia el mar, donde han dejado la balsa. En su huida encuentran un puñal que perteneció a Arne Saknussemm, el alquimista que 300 años atrás hizo ese mismo viaje al centro de la Tierra, y más adelante en una roca encuentran grabadas sus iniciales, señalándoles el camino una vez más.

Según Lidenbrock, para llegar al centro del Globo aún tienen que bajar 1 500 leguas. Para seguir el viaje deben tomar una galería, pero una roca enorme obstruye la entrada y no les permite penetrar por ningún sitio. Optan por romper la roca con la pólvora que tienen. Preparan todo, encienden la mecha y se refugian en la almadía que tienen en la playa. No obstante, la extremada inestabilidad del terreno hace que la explosión provoque un terremoto y que el mar, convertido en una ola gigante, se los lleve violentamente a lo largo de diversas galerías. Pronto acabarán en una galería vertical, pero el agua entonces, al recobrar su nivel natural, empieza a subirles a gran velocidad, a modo de un ascensor superrápido. Los tres exploradores se consideran perdidos, viendo que a causa de la velocidad de su ascensión apenas pueden respirar y que el calor se hace insoportable.

Las paredes se mueven, los vapores se condensan... Son los síntomas de una erupción, y están dentro de la chimenea de un volcán en actividad. De repente, un movimiento giratorio se apodera de la balsa, que se balancea sobre las olas de lava en medio de una lluvia de cenizas, y salen disparados por el abrasador orificio del cráter.

Cuando Axel abre los ojos, comprueba que se hallan al aire libre, en la superficie de la tierra. Pero no están en Islandia sino en la isla de Estrómboli, Italia, en pleno Mediterráneo. Habían entrado por un volcán, el Snæfellsjökull, y han salido por el Estrómboli situado a más de 1 200 leguas del primero. Un cono de prodigiosa altura, coronado de humos, se divisa hacia el poniente: es el Etna. 

Axel y su tío regresan a casa. La noticia de su viaje al centro de la Tierra se había propagado por todas partes, pero nadie se había creído semejante aventura. No obstante, la presencia de Hans y varios informes llegados de Islandia cambian la opinión pública. El profesor Lidenbrock y Axel pasan a ser hombres famosos, y Hans regresa a su tierra natal de Islandia.

Al final del libro descubrirán que la indicación de la brújula por la cual habían creído retroceder era errónea: la bola luminosa con la que se encontraron en la tempestad había alterado los polos, haciendo que señalara el norte donde en realidad estaba el sur.


° Marta: empleada domestica del profesor Lidenbrock



</doc>
<doc id="27993" url="https://es.wikipedia.org/wiki?curid=27993" title="Zenobia">
Zenobia

Septimia Bathzabbai Zainib (; ; ), más conocida como Zenobia (23 de diciembre 245-274), fue la segunda mujer del príncipe Septimio Odenato de Palmira y reina del Imperio de Palmira entre 267 y 272. Al casarse, adoptó el praenomen "Septimia", aunque firmaba con su nombre arameo "Bat-Zabbai". Odenato (castellanización del nombre Odenat) era un príncipe cliente del Imperio romano, pero fue asesinado en el 267 y entonces Zenobia tomó las riendas del poder a nombre de su joven hijo heredero.

Aprovechando las disputas en el interior del imperio por la corona del mismo, el reino de Palmira se sublevó e intentó crear su propio imperio con la intención de dominar a los dos que le flanqueaban, el romano y el sasánida. También tenían el incentivo de aprovechar el vacío de poder que el Imperio sasánida aún no había alcanzado a llenar. Las campañas militares de Zenobia le permitieron crear un imperio que abarcaba toda el Asia Menor e incluso logró tomar Egipto con sus tropas en el año 269, ya que allí se había levantado un posible candidato al trono romano. Zenobia logró deponer al pretendiente y reclamó la corona del imperio para su hijo. 

Gobernó Egipto hasta el año 272, cuando fue derrotada y enviada como rehén a Roma por el emperador Aureliano. A partir de este momento, el destino de Zenobia parece confuso. Existen múltiples teorías desde que una enfermedad acabó con la vida de Zenobia, hasta que fue una huelga de hambre o una ejecución por decapitación la causa de su muerte. La versión más optimista y aceptada cuenta que Aureliano quedó tan impresionado por Zenobia que la liberó, otorgándole una villa en Tibur (actual Tívoli, Italia) donde se convirtió en una filósofa destacada de la alta sociedad, viviendo como una matrona romana más.

La "Historia Augusta" contiene detalles acerca de su corta vida, aunque su grado de certeza es dudoso, en su niñez su pasatiempo era la caza y aparentemente no era una plebeya sino que habría recibido una educación apropiada para una noble muchacha de Palmira. Además de su lengua materna el Arameo de Palmira, Zenobia era capaz de hablar en Latín y fluidamente el Arameo Egipcio y el Griego.

Alrededor de sus 14 años (255-258) ella se convirtió en la segunda esposa de Septimio Odenato el "raz" (señor) de Palmira.

La sociedad de Palmira era una amalgama de tribus semíticas (en su mayoría arameos y árabes) y Zenobia no puede ser identificada en ningún grupo; como ella era de Palmira puede que habría tenido sangre árabe y aramea. La información sobre sus ancestros y sus conexiones familiares inmediatos es escasa y contradictoria. No se sabe nada acerca de su madre y se discute la identidad de su padre. Fuentes maniqueas mencionan a una "Nafsha", hermana de la "reina de Palmira", pero esas fuentes son confusas y "Nafsha" puede referirse a Zenobia misma; es dudoso que Zenobia tuviera una hermana.

Zenobia se casó en 258 con el rey de Palmira Septimio Odenato como su segunda esposa. Ella tenía un hijastro llamado Hairan, hijo del primer matrimonio de Odenato. 

Alrededor de 266 Odenato y Zenobia tuvieron un hijo, "Lucius Iulius Aurelio Septimio Vaballathus Atenodoro", más conocido como Vabalato.

En 267 el marido de Zenobia y su hijastro fueron asesinados. Vabalato tenía solo un año de edad, por lo que su madre sucedió a su esposo y gobernó Palmira como regente del menor. A Zenobia y su hijo le fueron otorgados los títulos honoríficos de Augusta y Augusto.

Zenobia fortificó y embelleció la ciudad de Palmira con una avenida custodiada por grandes columnas corintias de más de 15 metros de altura. Estatuas de héroes y de benefactores se encontraban por toda la ciudad, pidiendo a todos los nobles de la ciudad que mandaran esculpir sus estatuas y con ellas levantaran una columna en la que exhibirlas. Todos los notables de la ciudad, posaron ante los artistas para satisfacción de los ediles. En Palmira podían encontrarse cerca de doscientas estatuas en sus columnas y en las paredes del ágora.

También mandó erigir en el año 271 d. C. un par de estatuas de ella y de su difunto esposo. La ciudad contaba entonces con una población que superaba los 150 000 habitantes y estaba llena de hermosos templos, monumentos, jardines y edificios públicos, entre ellos destacaba el Templo del Sol. Las murallas que rodeaban la ciudad, según se decía, tenían 21 kilómetros de circunferencia.

Tras la muerte de Galieno en el año 268 d. C. y viendo que su sucesor, Claudio el Gótico, tenía que dedicar todos sus esfuerzos a contrarrestar una invasión goda, Zenobia sublevó al reino de Palmira e intentó crear su propio imperio, con la intención de dominar a los dos imperios que le flanqueaban, el Imperio sasánida y el Imperio romano.

Roma, envuelta en un nuevo periodo de caos debido a las distintas sucesiones, dejaba a la reina de Palmira, que estaba bien asentada en su reino, intentar aspirar a crear un tercer imperio que dominara a ambos.

Zenobia fue conquistando nuevos territorios, aumentando el territorio del Imperio de Palmira en memoria de su esposo y como un legado a su hijo. Su objetivo declarado era proteger el Imperio romano de Oriente del Imperio sasánida, por la paz de Roma, sin embargo, sus esfuerzos aumentaron significativamente el poder de su trono.

En 269, Zenobia, su ejército, y el general Zabdas conquistaron violentamente Egipto con la ayuda de su aliado egipcio, Timágenes, y su ejército. El prefecto romano de Egipto, Probus Tenagino y sus fuerzas, trataron de expulsarles de Egipto, pero el ejército de Zenobia capturó y decapitó a Probus. Zenobia se proclamó reina de Egipto y acuñó monedas con su nombre. En ese momento su reino se extendía desde el Nilo hasta el Éufrates.
Después de estas incursiones iniciales, Zenobia llegó a ser conocida como "la reina guerrera" al dirigir personalmente a su ejército, demostrando ser buena jinete, capaz de caminar tres o cuatro millas con sus soldados a pie.

Zenobia hizo expediciones con su gran ejército y conquistó Anatolia hasta Ancira y Calcedonia, y más tarde Siria, Palestina y el Líbano. En su imperio de corta duración, Zenobia tomó rutas de comercio vitales para los romanos. El emperador Aureliano, subido al trono en el año 270, tras estabilizar la frontera del Danubio, decidió finalmente emprender una campaña militar contra ella. Mandó algunas de sus fuerzas hacia Egipto y el grueso de su ejército hacia el este a través de Asia Menor. Zenobia contaba con un gran ejército, formado por sus arqueros y catafractos comandado por dos generales, Zabdas y Zabbai. Pero Aureliano conquistó Egipto y lanzó sus fuerzas hacia Siria.

Zenobia fue derrotada en Emesa (actual Homs), y se retiró a Palmira, donde fue sitiada por Aureliano. Palmira había hecho acopio de víveres y confiaba en la fuerza de sus excelentes arqueros, esperando resistir durante meses, pero gracias a los jefes árabes del desierto, que Zenobia había desdeñado, Aureliano venció la resistencia de la ciudad. Zenobia y su hijo se escaparon de allí en camello con la ayuda de los sasánidas, pero fueron capturados en el río Éufrates por los jinetes de Aureliano. El corto reinado de Zenobia sobre Egipto y el Imperio de Palmira habían terminado. Los palmiranos restantes que se negaron a rendirse fueron capturados y ejecutados por orden de Aureliano.









</doc>
<doc id="27995" url="https://es.wikipedia.org/wiki?curid=27995" title="Molecularidad">
Molecularidad

La molecularidad es el número de moléculas que forman parte como reactivos en un proceso elemental, es decir, la suma de las moléculas de cada reactivo antes de formar el complejo activado para convertirse en los productos.

Es un concepto teórico que indica el nº de partículas individuales que participan en un paso elemental del mecanismo de reacción.

En los procesos (pasos) elementales del mecanismo de reacción pueden coincidir orden de reacción y molecularidad. No puede haber reacciones elementales con molecularidad superior a 3 (Termoleculares).

formula_1


formula_2


formula_3


formula_4


</doc>
<doc id="27996" url="https://es.wikipedia.org/wiki?curid=27996" title="Sofia Kovalévskaya">
Sofia Kovalévskaya

Sofia Vasilyevna Kovalévskaya (Moscú, 15 de enero de 1850-Estocolmo, 10 de febrero de 1891), , fue la primera matemática rusa de importancia y la primera mujer que consiguió una plaza de profesora universitaria en Europa (Suecia, 1881). Nacida y criada en el seno de una familia gitana rusa de buena formación académica, Sofía era también descendiente de Matías Corvino, . Su abuelo, por casarse con una gitana y estar emparentado con dicha etnia, perdió el título hereditario de príncipe. Su nombre en ocasiones se translitera como "Sophie, Sonya, Sonja o Sonia". Su apellido "Kovalévskaya" significa «la mujer de Kovalevski».

Vivió su infancia en Palibino, Bielorrusia. Amaba desde niña la lectura y la poesía, se sentía poeta en su interior. Además de su hermana, dos de sus tíos influyeron notablemente en su vida. Uno de ellos, un auténtico amante de la lectura, que aunque no era matemático, le apasionaba esta ciencia; su otro tío le enseñaba ciencias y biología. A menudo se sentaba en un banco del patio para ver oscilar con el oleaje provocado por el viento una pelota sobre un estanque, quedándose sumergida en sus pensamientos matemáticos.

Bajo la guía del tutor de su familia, Y. I. Malevich, Sofía comenzó sus primeros estudios reales de matemáticas. A los trece años empezó a mostrar muy buenas cualidades para el álgebra. Por esa época escribió: «Comencé a sentir una atracción tan intensa por las matemáticas, que empecé a descuidar mis otros estudios». Pero su padre, a quien le horrorizaban las mujeres sabias, decidió interrumpir las clases de matemáticas de su hija. Aun así Sofia siguió estudiando por su cuenta con libros de álgebra. Pidió prestado un ejemplar del "Álgebra" de Bourdeu que leía por la noche cuando el resto de la familia dormía. Así, aquello que nunca había estudiado lo fue deduciendo poco a poco. Un año más tarde un vecino, el profesor Tyrtov, presentó a la familia de Sofía un libro del que él era autor y Sofía trató de leerlo. No entendió las fórmulas trigonométricas e intentó explicárselas a sí misma.

A partir de los conocimientos que ya tenía, Sofia explicó y analizó por sí misma lo que era el concepto de seno tal y como había sido inventado originalmente. Un profesor descubrió las facultades de Sofia, y habló con su padre para recomendarle que facilitara los estudios a su hija. Al cabo de varios años su padre accedió y Sofia comenzó a tomar clases particulares.

Los años de su adolescencia fueron años de rebelión, la época de las grandes revoluciones y manifestaciones del en las que el socialismo feminista iba perdiendo terreno. Su apellido de soltera era Korbin-Kukóvzkaya y era descendiente de un rey de Hungría. A los once años se enamoró del escritor Fiódor Dostoyevski, exnovio de su hermana. Más tarde, al casarse, adopto el apellido de su marido.
En su estadía en Alemania recibió clases de Karl Weierstraß, las mismas que éste impartía en la universidad. Al mismo tiempo que estudiaba, comenzaba su trabajo de doctorado. Durante sus años en Berlín escribió tres tesis: dos sobre temas de matemáticas y una tercera sobre astronomía. Más tarde el primero de estos trabajos apareció en una publicación matemática a la que contribuían las mentes más privilegiadas.

Gracias a Mittag-Leffer, Sofia pudo trabajar a prueba durante un año en la Universidad de Estocolmo. Durante este tiempo Sofia escribió el más importante de sus trabajos, que resolvía algunos de los problemas al que matemáticos famosos habían dedicado grandes esfuerzos para resolverlos.

Sofia Kovalévskaya murió a los 41 años, de gripe y neumonía. Entre sus trabajos figuran: "Sobre la teoría de las ecuaciones diferenciales", que aparece en el "Journal de Crelle", y "Sobre la rotación de un cuerpo sólido alrededor de un punto fijo", por el cual obtiene un importante premio otorgado por la Academia de Ciencias de París, en 1888.

El cuento homónimo del libro "Demasiada felicidad", de la Premio Nobel de Literatura Alice Munro, está inspirado en la vida de Kovalévskaya.

El día «Sofia Kovalevsky» sobre Matemáticas, en las secundarias de Estados Unidos es un programa de la Asociación de Mujeres en Matemáticas (AWM), que promueve la financiación de talleres en los Estados Unidos para alentar a las niñas a explorar las matemáticas.

La Conferencia Sofia Kovalevsky es patrocinada anualmente por la AWM, y tiene por objeto destacar las contribuciones significativas de las mujeres en los campos de la matemática aplicada o computacional. Entre las galardonadas, destacan: Irene Fonseca (2006), Ingrid Daubechies (2005), Joyce R. McLaughlin (2004) y Linda R. Petzold (2003).

El cráter lunar Kovalevskaya es nombrado en su honor, al igual que el asteroide (1859) Kovalevskaya.

La Fundación Alexander von Humboldt de Alemania otorga un premio bi-anual llamado Sofia Kovalevskaya a prometedores jóvenes investigadores de todos los campos.




</doc>
<doc id="27997" url="https://es.wikipedia.org/wiki?curid=27997" title="Ascensor espacial">
Ascensor espacial

Un ascensor espacial es un ascensor hipotético que conecta la superficie de un planeta con el espacio.

Básicamente es una estación espacial en una órbita geosíncrona, y de la que parte un cable de 35.786 km de largo que llega hasta el suelo, y que puede tener forma de riel. Para mantener el equilibrio de la estructura, además de situar el anclaje en algún punto lo más cerca posible del ecuador, para minimizar los efectos de tensión por la diferencia entre la rotación de la Tierra y la órbita geosincrónica del satélite, los ponentes de esta tecnología futurista proponen utilizar un tramo de cable idéntico extendido hacia el espacio o bien un contrapeso, de tal suerte que el cable estaría en equilibrio con su centro de masas en órbita geosíncrona. Una vez el cable en su lugar, pueden subir y bajar por él naves y cargas a un coste unas cien veces menor que el que supone lanzarlas por medio de un cohete (prácticamente, el coste de la electricidad necesaria para impulsar el ascensor, que puede ser electricidad renovable procedente de placas solares situadas en el contrapeso).

El concepto fue formulado, tal y como se conoce hoy día, por el ingeniero ruso Yuri Artsutanov en 1960, dentro de un artículo del diario Pravda «В Космос — на электровозе» (traducido al inglés como ""To the cosmos by electric train""), aunque reconocía que la resistencia a la tracción necesaria para construir el cable no podía obtenerse con ningún material conocido en ese momento. Sin embargo, la idea de un ascensor espacial se remonta al 1895, concebida por el físico ruso Konstantin Tsiolkovsky.

Los ascensores espaciales eran hasta hace muy poco un tema exclusivo del género de la ciencia ficción, pues ningún material conocido podía soportar la enorme tensión producida por su propio peso. Actualmente ciertos materiales comienzan a parecer viables como materia prima: los expertos en nuevos materiales consideran que teóricamente los nanotubos de carbono pueden soportar la tensión presente en un ascensor espacial. Debido a este avance en la resistencia de los nuevos materiales, varias agencias están estudiando la viabilidad de un futuro ascensor espacial:

En Estados Unidos, un antiguo ingeniero de la NASA llamado Bradley C. Edwards ha elaborado un proyecto preliminar que también están estudiando científicos de la NASA. Edwards afirma que ya existe la tecnología necesaria, que se necesitarían 20 años para construirlo y que su costo sería 10 veces menor que el de la Estación Espacial Internacional. El ascensor espacial de Edwards no se parece a los presentes en las obras de ficción, al ser mucho más modesto y a la vez innovador en lo que concierne a su eventual método de construcción.

Edwards propone que el ascensor espacial se construya de manera análoga a como se construían los puentes en tiempos pasados: tendiendo una cuerda entre ambos extremos del obstáculo natural, y reforzar progresivamente la cuerda inicial con tramos cada vez más gruesos y resistentes. El elevador de Edwards sería una cinta extremadamente fina (unos cuantos nanómetros) de nanotubos de carbono, que sería lanzada al espacio de manera convencional. Una vez en órbita geosíncrona, la cinta sería descendida a la Tierra con la ayuda de un peso. La cinta sería tan ligera que la nave en la que fue lanzada serviría de contrapeso.

El cable sería recuperado al llegar a la superficie terrestre y anclado en una plataforma flotante en algún punto del ecuador. Con eso se terminaría la construcción del primer elevador espacial. Pese a su finura, la cinta de nanotubos de carbono sería lo suficientemente resistente para soportar el ascenso de un vehículo eléctrico de un centenar de kilogramos.

Edwards también propone utilizar tal capacidad de carga inicial no para carga, sino para reforzar el cable añadiendo más cintas a la primera, utilizando un vehículo eléctrico que montaría el cable sujetándose de él, tal proceso se repetiría hasta lograr construir un cable compuesto capaz de llevar a órbita geosíncrona la capacidad de carga deseada.

También las agencias europea y japonesa están trabajando en sus propios diseños. Asimismo, la Spaceward Foundation ha establecido diversos concursos y premios para quienes aporten mejoras para la construcción de dicho ascensor.

En noviembre de 2009 un proyecto desarrollado en Seattle en los Estados Unidos ganó un concurso apoyado por la NASA que tenía como objetivo diseñar un ascensor espacial basado en las ideas presentadas en la literatura científica y de ficción. La máquina ganadora, llamada "LaserMotive LLC" logró ascender 899 metros a lo largo de un cable que colgaba desde un helicóptero e impulsada por un motor eléctrico el cual recibía su carga a partir de un conjunto de celdas voltaicas que convertían en energía eléctrica la luz emitida por un láser en tierra que apuntaba directamente a la máquina.

Esta máquina consiguió mediante este método ascender los 899 metros de cable en tres minutos y 48 segundos por lo cual se le entregó un premio de 900.000 dólares por parte del Proyecto Retos Centenarios de la NASA.

Hay una cierta disputa entre Arthur C. Clarke y Charles Sheffield como introductores del concepto en una obra de ficción. El primero introdujo el concepto a una audiencia más amplia en su novela "Las fuentes del paraíso" (en inglés "The Fountains of Paradise") de 1978; en dicha obra, los ingenieros construyen un ascensor espacial en la cima de la isla ecuatorial de Taprobane (que tiene cierta semejanza con Sri Lanka). Charles Sheffield menciona un ascensor espacial en su novela "La telaraña entre los mundos", que fue terminada unos meses antes, aunque no logró publicarla hasta después de aparecer la novela de Clarke. 

Los ascensores espaciales se han convertido en una figura recurrente de la ciencia ficción dura, al ser uno de los pocos métodos eficientes para colocar grandes cargas en órbita. Los ascensores espaciales son argumentos narrativos en obras tales como:





</doc>
<doc id="27998" url="https://es.wikipedia.org/wiki?curid=27998" title="Delta">
Delta

Delta puede referirse a:

La diferencia entre dos valores próximos de una magnitud y varias funciones y operadores:


Un delta fluvial es un accidente geográfico producido por el depósito de sedimentos en la desembocadura de un río.














</doc>
<doc id="27999" url="https://es.wikipedia.org/wiki?curid=27999" title="K-Pax">
K-Pax

K-PAX es una película coproducida entre Estados Unidos y Alemania. Basada en la novela K-PAX de Gene Brewer. Ha habido mucha controversia en torno a su argumento, ya que se la acusa de plagiar la película argentina "Hombre mirando al sudeste", de Eliseo Subiela, con un punto de partida prácticamente idéntico. La denuncia fue retirada posteriormente.

En un hospital psiquiátrico uno de los pacientes que se hace llamar Prot (Kevin Spacey) declara ser de otro planeta.
tal psiquiátrico Prot hace dudar al mismísimo doctor, así como al resto del personal del centro y los pacientes sobre su verdadera identidad, demostrando conocimientos sobre el campo de la astronomía que ningún ser humano conoce, así como ayudando a los pacientes del centro a curarse de sus enfermedades mentales. El médico de Prot siente que éste "lo ha elegido" con lo cual sigue atendiéndolo a pesar de que se intenta trasladar a Prot a otro nivel del hospital psiquiátrico. Mediante hipnosis a la que es sometido Prot, Powell obtiene información que lo guía a una pequeña ciudad y a la aparente identidad de Prot, junto a su historia: siendo casi un genio, decide casarse con su novia (embarazada) de secundaria y trabajar al lado de su padre en un matadero, para mantener a su familia. Un día, regresando del trabajo, descubre con horror que un ex convicto ha violado y asesinado a su mujer y a su hija, por lo que lo mata y luego se mete en un río cercano con intención de suicidarse. Oficialmente, nunca fue procesado pues desapareció y el sherif del lugar tampoco tiene interés en ubicarlo, pues comprende el actuar de Prot. Esto explica parte de su comportamiento, pero lo inexplicable se produce al llegar el plazo de término de la "visita" de Prot al planeta, fecha en que el doctor temía que se suicidara, cosa que no ocurre, sino que queda en estado catatónico (dejando abierta la posibilidad de que la entidad extraterrestre haya abandonado el cuerpo dejándolo como un recipiente vacío o que, en caso de ser sólo un enfermo mental, que dicha enfermedad terminase por cortar sus vínculos con la realidad), al tiempo que una de las pacientes del hospital desaparece, entendiendo los demás que fue ella la elegida para acompañar a Prot a K-pax, el supuesto planeta de donde provenía. Al final de la película se puede ver el reencuentro de Powell y su hijo con quien estaba distanciado, pero que gracias a Prot logra amistarse.



</doc>
<doc id="28001" url="https://es.wikipedia.org/wiki?curid=28001" title="La noche de la iguana">
La noche de la iguana

La noche de la iguana es una película estadounidense de 1964 dirigida por John Huston, basada en la obra teatral del mismo título de Tennessee Williams. Protagonizada por Richard Burton, Deborah Kerr y Ava Gardner en los papeles principales, ganó un premio Óscar al mejor diseño de vestuario (Dorothy Jeakins), y fue nominada a la mejor actriz de reparto (Grayson Hall), a la mejor dirección artística (Stephen Grimes) y a la mejor fotografía (Gabriel Figueroa). El rodaje atrajo mucha atención de la prensa, que perseguían a las estrellas por los platós para conseguir información y fotos de la reciente pareja Elizabeth Taylor y Richard Burton.

Fue filmada en 1963 en Puerto Vallarta, Jalisco, México, y sus alrededores (playa Mismaloya).

Un sacerdote anglicano retirado y alcohólico (Richard Burton) sufre una severa crisis emocional mientras preside una ceremonia eclesiástica. Como resultado decide retirarse a México, viéndose obligado a tomar la ocupación de guía turístico de maestras estadounidenses, en su mayoría solteras. Durante su último tour, es víctima de los audaces avances románticos de una jovencita (Sue Lyon) que hace todo lo posible por seducirlo, y se gana el odio del resto de las damas de la expedición. La jefa del grupo despide al guía por su comportamiento. Al borde de otra crisis nerviosa, arriba a Puerto Vallarta y se refugia en el colorido hotel de una vieja amiga, Maxine (Ava Gardner), con la que mantiene una buena relación. Allí conocerá a Hannah (Deborah Kerr), mujer rígida y anticuada que se dedica a la pintura itinerante, y que viaja siempre en compañía de su abuelo, un inspirado poeta de casi cien años. Las relaciones del guía con todas estas mujeres le marcarán para el futuro.


</doc>
<doc id="28002" url="https://es.wikipedia.org/wiki?curid=28002" title="Alguien a quien amar">
Alguien a quien amar

Alguien a quien amar (1994) es una extraña película independiente, triste y optimista a la vez. Dirigida por Alexandre Rockwell y protagonizada por Rosie Pérez. 

Mercedes (Rosie Pérez) es una bailarina de discoteca que aspira a ser actriz. Mantiene una relación con Harry (Harvey Keitel), que está casado y se considera a sí mismo un actor apreciado por el público. Otro hombre está enamorado de Mercedes, pero no tiene dinero ni sabe cómo conseguir que ella se interese por él.


</doc>
<doc id="28003" url="https://es.wikipedia.org/wiki?curid=28003" title="American Buffalo">
American Buffalo

American Buffalo es una película estadounidense, dirigida por Michael Corrente y estrenada en el año 

Donny (Dennis Franz) es propietario de una misera tienda en el centro de la ciudad, donde se reúne cada día con sus dos amigos y hace planes para el futuro. Teach (Dustin Hoffman) es demasiado corto u obcecado para reconocer lo que la vida le ha dado, y no hace más que quejarse. Bobby (Sean Nelson) es un adolescente que no aprovecha las experiencias que le cuentan los otros dos y que podrían serle útiles ya que es el único de ellos que aún tiene ocasión de orientar su vida de forma positiva. De todo ello sale un plan que cada uno ve de manera diferente.

Película basada en la obra teatral del mismo título de David Mamet.


</doc>
<doc id="28004" url="https://es.wikipedia.org/wiki?curid=28004" title="Procedimiento ilegal">
Procedimiento ilegal

Procedimiento ilegal es una película estadounidense de 1987, del género comedia, policíaco, con ingredientes románticos y de suspense, dirigida por John Badham. Protagonizada por Richard Dreyfuss, Emilio Estévez, Madeleine Stowe, Aidan Quinn y Forest Whitaker en los papeles principales. El film fue rodado en Vancouver, British Columbia.

El film fue un éxito de crítica y público. Ganadora del premio BMI Film Music Award 1988 (Arthur B. Rubinstein), y del premio Edgar Allan Poe Awards 1988 a la Mejor película (Jim Kouf).

Tuvo una secuela en 1993; "Another Stakeout".

Los policías Lecce ("Richard Dreyfuss") y Reimers ("Emilio Estévez") tienen el encargo de observar a una mujer joven ("Madeleine Stowe"), cuyo ex novio es un delincuente que se ha fugado de prisión ("Aidan Quinn"). El aburrimiento se hace cada vez más insoportable, hasta que Lecce entra en la casa de la mujer y posteriormente la conoce. Entretanto, el preso fugado se dirige a la casa de su ex novia.


La película recibió generalmente críticas positivas, manteniendo un 87% en Rotten Tomatoes y un 6,6/10 en IMDb.

La película fue numero su primera semana. Acabó recaudando 65,6 millones de dólares y fue el octave filme más visto de ese año.



</doc>
<doc id="28007" url="https://es.wikipedia.org/wiki?curid=28007" title="Ascensor">
Ascensor

Un ascensor o elevador es un sistema de transporte vertical, diseñado para mover personas u objetos entre los diferentes niveles de un edificio o estructura. Está formado por partes mecánicas, eléctricas y electrónicas que funcionan en conjunto para ponerlo en marcha. 

De acuerdo a su método de funcionamiento existen dos tipos: el ascensor electromecánico y el ascensor hidráulico u oleodinámico.

La primera referencia a un ascensor aparece en las obras del arquitecto romano Vitruvio, quien sostiene que Arquímedes (ca. 287 a. C. – ca. 212 a. C.) había construido el primer elevador probablemente en el año 236 a.C. Fuentes literarias de épocas posteriores mencionan ascensores compuestos de cabinas sostenidas con cuerda de cáñamo y accionadas a mano o por animales. Se estima que ascensores de ese tipo estaban instalados en un monasterio de Sinaí, Egipto.

Hacia el año 1000, en el "Libro de los Secretos" escrito por Ibn Khalaf al-Muradi, de la España islámica se describe el uso de un ascensor como dispositivo de elevación, a fin de subir un gran peso para golpear y destruir una fortaleza. 

En el siglo XVII, había prototipos de ascensores en algunos edificios palaciegos ingleses y franceses.

Los ascensores antiguos y medievales utilizaban sistemas de tracción basados en el mecanismo de la grúa. La invención de otro sistema basado en la transmisión a tornillo, fue tal vez el paso más importante en la tecnología del ascensor desde la antigüedad, que finalmente condujo a la creación de los ascensores de pasajeros modernos. El primer modelo fue construido por Ivan Kulibin e instalado en el Palacio de Invierno en 1793, mientras que varios años más tarde, otro ascensor Kulibin fue instalado en Arkhangelsk, cerca de Moscú. En 1823, se inaugura una "cabina de ascensor" en Londres.

En 1851, Waterman inventó el primer prototipo de montacargas. Se trataba de una simple plataforma unida a un cable, para subir y bajar mercancías y personas.

A medida que se fueron construyendo edificios más altos, la gente se sintió menos inclinada a subir escaleras largas. Los grandes almacenes comenzaron a prosperar, y surgió la necesidad de un aparato que trasladara a los clientes de un piso a otro con mínimo esfuerzo. 

El montacargas inspiró al estadounidense de Vermont, Elisha G. Otis, para inventar un elevador con un sistema dentado, que permitía amortiguar la caída del mismo en caso de que se cortara el cable de sustento. Fue la primera demostración de un sistema de seguridad para elevadores de pasajeros. 

Por extraño que parezca, el talento de Elisha Otis como diseñador se descubrió mientras trabajaba como maestro mecánico en una fábrica de armazones de camas de Albany (estado de Nueva York). Inventó varios dispositivos que ahorraban trabajo, y por eso fue enviado a Yonkers (Nueva York), donde podría utilizarse mejor su aptitud. Allí diseñó y construyó este primer ascensor con mecanismo automático de seguridad en caso de que hubiera alguna avería en el cable. En 1853 ya había establecido su propio negocio para fabricar ascensores, la compañía Otis Elevator Company, que aún existe en la actualidad y es la mayor compañía de ascensores del mundo ya que ha instalado 2,5 millones de elevadores y escaleras mecánicas por todo el planeta. Al año siguiente Otis demostró este invento en una exposición que se llevó a cabo en Nueva York.

El 30 de agosto de 1957 se aplicó un sistema de puertas automáticas en los ascensores de pasajeros, lo que permitió prescindir de puertas actuadas manualmente.

Otro tipo de ascensor es el conocido como "paternoster"; consiste en una serie de cabinas abiertas, de capacidad limitada, que se mueven lentamente por dos huecos contiguos. Por uno suben las cabinas y, al llegar a la parte superior, se cambian al otro hueco por el que bajan en un ciclo continuo, sin detenerse. Los pasajeros suben y bajan en marcha. Era muy práctico en lugares de mucha circulación de personas entre pisos, aunque tenía problemas de seguridad, por lo que fue sustituido por las escaleras mecánicas, mucho más seguras.
Los comercios pronto se dieron cuenta del potencial del invento, y en 1857 se instaló el primer ascensor de pasajeros en un gran almacén ubicado en la avenida Broadway, esquina calle Broome, en la ciudad de Nueva York, Estados Unidos. Movido a vapor, este elevador subía cinco pisos en menos de un minuto. En aquel entonces, eso era rápido. En contraste con eso, hoy los ascensores de uno de los edificios más altos del mundo, la Torre Willis, en Chicago, suben 412 metros en menos de un minuto. En la actualidad, el edificio más alto del mundo, la Torre Burj Khalifa en Dubái, con 828 m de altura, tiene ascensores de la compañía Otis Elevator Company que suben la distancia más larga del mundo: 504 metros; también tiene el acceso de ascensor situado a mayor altura del mundo: a 638 metros; y el ascensor con doble cabina más rápido del mundo: 10 metros por segundo.

La cabina es el elemento básico del sistema de ascensores. Está formada por dos partes: el bastidor o chasis y la caja o cabina, o por una cabina autoportante. El bastidor se apoya en unas guías verticales

La mayoría de los ascensores tienen un contrapeso, que tiene una masa igual a la de la cabina, más la mitad de la carga máxima autorizada, para que el motor no tenga que mover toda la masa de la cabina, sino solo una fracción. Debido a ello, un ascensor vacío, pesa menos que el contrapeso. El contrapeso también está conducido por unas guías. Su función es equilibrar la carga para facilitar el trabajo del motor y no forzarlo en su funcionamiento.

Los grupos tractores para ascensores están formados normalmente por un motor acoplado a un reductor de velocidad, en cuyo eje de salida va montada la polea acanalada que arrastra los cables por adherencia.

En los extremos inferior o superior del bastidor de la cabina, se encuentra el sistema de paracaídas, ya sea instantáneo o progresivo. Este libera unas cuñas contra las guías para frenar la cabina en caso de que baje a una velocidad mayor que la permitida por el limitador, impidiendo así que la cabina caiga libremente incluso en el caso de que se cortaran todos los cables que la sujetan. En los ascensores modernos y según normativa de cada país o región también frena en subida.

En ocasiones, se instala también un sistema de frenado en el contrapeso.

El control de los sistemas de ascensores se realiza mediante sistemas electrónicos, encargados de hacer funcionar la dirección de movimiento de la cabina y de seleccionar los pisos en los que esta deba detenerse.

En 1862 la compañía de ascensores Otis inventó el primer sistema de control con "memoria" para grupos de ascensores, lo que permitió su automatización y prescindir de los ascensoristas.

Actualmente, los controles de ascensores funcionan con microprocesadores electrónicos que mediante algoritmos de inteligencia artificial determinan la forma de administrar la respuesta a los pedidos de llamadas coordinando la operación de los distintos equipos.

Los cuadros de maniobra actuales tienen un sistema de información de errores, que en caso de avería muestran en una pantalla el código de error de tal forma que el mecánico del ascensor sepa cuál ha sido el motivo de que el ascensor se detuvo. 

Un ascensor cuenta con múltiples dispositivos de seguridad para evitar cualquier riesgo de accidentes y en cuanto cualquier dispositivo falla el ascensor queda automáticamente detenido. Cualquier elevador por antiguo que sea tiene contactos en: las puertas exteriores, puertas de cabina, contacto de rotura de cables (actualmente ya no se montan), de disparo de polea del limitador superior, de aflojamiento de cable en polea de limitador inferior, de acuñamiento en cabina, etc. En cuanto cualquiera de estos contactos falle, el ascensor se parará indicando el contacto o dispositivo que ha fallado.

La seguridad del sistema es un elemento clave en los ascensores. Para maximizar la seguridad se emplean varios dispositivos específicos:

En el acceso a los pisos, que hace imposible la apertura de todas las puertas de acceso excepto la del piso en que se halla detenida la cabina.

Todas las cerraduras, una en cada rellano, tienen un fleje o un brazo con una ruedita, que al ser oprimido permite el destrabe de la puerta, y solo cuando está mecánicamente trabada mediante el gancho de doble uña, queda habilitada la parte eléctrica que permite el movimiento del ascensor. Hay dos tipos de mecanismos que permiten abrir las puertas exteriores cuando la cabina llega a planta. En los ascensores antiguos hay un elemento llamado electroleva, que es el encargado de oprimir el fleje de la puerta del piso de destino. Esta electroleva es retráctil, es decir, viaja con la cabina retraído para no oprimir los flejes de cada piso por el que va pasando (lo que permitiría la apertura de cada una de las puertas y la detención del ascensor), por lo que solo cuando el control de maniobras le indica mediante una señal eléctrica que la cabina se encuentra en la parada pertinente, la electroleva se expande y acciona el fleje de la puerta correspondiente. El proceso inverso se da cuando el ascensor es requerido desde otro sitio: la electroleva se retrae antes de la partida y solo se expande al llegar a él. En los ascensores modernos hay otro tipo de mecanismos. Si las puertas exteriores son automáticas, es decir se abren por sí mismas, una de las hojas de cabina lleva instalado un patín retráctil que abre la puerta exterior al mismo tiempo que abre la interior de la cabina. Si las puertas exteriores son manuales o semi-automáticas (las abre la persona que va a entrar en el ascensor y se cierran solas), las puertas de cabina incorporan un patín que empuja la polea de la cerradura para permitir abrir la puerta exterior.

Existen instantáneos y también progresivos, para ascensores de alta y media velocidad. Consiste en un sistema de palancas cuyo movimiento acciona unas cuñas o rodillos que se encuentran en una caja junto a las guías (caja de cuñas). Cuando se da la caída de la cabina o sobrepasa la velocidad nominal , las guías son mordidas por las cuñas o rodillos y se produce la detención de la cabina.

Lo componen dos poleas: una instalada en el cuarto de máquinas y otra alineada verticalmente con la primera en el fondo del hueco. A través de ambas pasa un cable de acero cuyos extremos se vinculan, uno a un punto fijo del bastidor de la cabina, y otro a un sistema de palancas cuyo extremo se encuentra en la parte superior del bastidor. El cable acompaña a la cabina en todo momento y es absolutamente independiente de los cables de tracción, es decir, no interviene en la sujeción de la cabina y el contrapeso. En la polea superior del limitador se produce la detención brusca del cable cuando la velocidad de dicha polea (y por tanto la de la cabina) supera el 25% de la velocidad nominal. El cable limitador activa el sistema de palancas, llamado paracaídas. Asimismo incorpora un contacto eléctrico tanto en el mecanismo de acuñamiento de la cabina como en la polea superior que corta la serie principal para evitar que el motor siga funcionando una vez que la cabina ha quedado "clavada" a las guías mediante el mecanismo de acuñamiento. Este mecanismo fue patentado por Rubén Lorenzo Curiel en 1853.

Interrumpen la alimentación cuando la cabina rebasa los extremos en ascenso o en descenso.

Interrumpe la maniobra, corta la alimentación del grupo tractor y actúa el freno. Permite la detención del ascensor dejando sin efecto los mandos de cabina y pisos. Normalmente deja bajar la cabina a la parada más baja. Si nos referimos al STOP o PARADA normalmente debe dejar parar la cabina en la parada siguiente tanto hacia arriba como abajo. Este sistema de emergencia también se puede denominar "Rescata-matic". En ascensores antiguos, la pulsación del botón de PARADA o STOP, producía una detención instantánea de la cabina, pudiendo el viajero quedar atrapado entre dos pisos sin posibilidad de salida. En los modelos actuales, este botón ha dejado de existir en los tableros de cabina, quedando únicamente el botón de alarma como dispositivo de emergencia en manos del usuario.

Para que lo utilicen los pasajeros en caso de emergencia. En ocasiones está conectado a una línea de teléfono desde la que se puede solicitar asistencia en caso de quedar atrapado.

Ilumina la cabina en caso de que el alumbrado normal sea interrumpido. 

Debe existir una fuente de socorro, de recarga automática que sea capaz de alimentar al menos una lámpara de un vatio durante una hora, en el caso de interrupción de la corriente de alimentación del alumbrado normal. El alumbrado de emergencia debe conectarse automáticamente desde que falle el suministro del alumbrado normal.

En los ascensores modernos suele instalarse un dispositivo llamado pesacargas. La función de este elemento es evitar que el ascensor mueva más peso del máximo permitido, evitando así el desgaste excesivo del grupo tractor y los frenos. Hay varios tipos de sistema de pesacargas y en la actualidad todos ellos son digitales, por lo que tienen una exactitud bastante elevada. 

En ascensores antiguos a los que quiera adaptarse un sistema de pesacargas, se suele emplear un mecanismo que consta de unos sensores que se adaptan en los cables de tracción y una centralita que recoge la información dada por los sensores. Esta centralita está conectada a su vez a la caja de revisión del ascensor, por lo que el cuadro de maniobra sabe en cada momento si el ascensor tiene más peso del permitido.

En los ascensores nuevos, el sistema es parecido, pero los sensores se colocan entre el suelo de la cabina y el chasis, permitiendo una exactitud todavía mayor.

Los cuadros de maniobra tienen 3 estados diferentes en lo que al pesacargas se refiere:


La construcción y característica de los grupos tractores y de los motores con que estos van equipados, varían según sea la velocidad nominal del ascensor y del servicio que deben prestar.

Se le llama así al sistema en suspensión compuesto por un lado por una cabina, y por el otro por un contrapeso, a los cuales se les da un movimiento vertical mediante un motor eléctrico. Todo ello funciona con un sistema de guías verticales y consta de elementos de seguridad como el amortiguador situado en el foso (parte inferior del hueco del ascensor) y un limitador de velocidad mecánico, que detecta el exceso de velocidad de la cabina para activar el sistema de paracaídas, que automáticamente detiene el ascensor en el caso de que esto ocurra. 

El ascensor eléctrico es el más común para transporte de personas a baja y alta velocidad (superior a 0,8 m/s), elevadores con alta exigencia de confort (hospitales, hoteles) o elevadores que sirven más de 6 pisos.

Los grupos tractores con motores de una velocidad solo se utilizan para ascensores de velocidades no mayores de 0,7 m/s. Por lo general, se instalan en ascensores de viviendas de 300 kg o 4 personas de carga máxima.

Su nivel de parada es muy impreciso y varía mucho con la carga, incluso es distinto en subida como en bajada. En muchos países está prohibida su instalación para nuevos ascensores por su falta de precisión en la parada.

Los grupos tractores de dos velocidades poseen motores trifásicos de polos conmutables, que funcionan a velocidad rápida y otra lenta según la conexión de los polos. De esta manera se obtiene con una velocidad de nivelación baja un frenado con el mínimo de error (aproximadamente 10 mm de error) y un viaje más confortable.

Estos grupos tractores en la actualidad están siendo retirados, ya que consumen demasiada energía y son algo ruidosos.

La aceleración en la arrancada y la desaceleración antes de que actúe el freno se llevan a cabo mediante un variador de frecuencia acoplado al cuadro de maniobra. El freno actúa cuando el ascensor está prácticamente parado y se consigue así una nivelación y un confort que superan incluso los del sistema de dos velocidades .

En los ascensores hidráulicos el accionamiento se logra mediante una bomba, acoplada a un motor eléctrico, que inyecta aceite a presión, por unas válvulas de maniobra y seguridad, desde un depósito a un cilindro, cuyo pistón sostiene y empuja la cabina, para ascender. En el descenso se deja vaciar el pistón del aceite mediante una válvula con gran pérdida de carga para que se haga suavemente. De este modo el ascensor oleodinámico solamente consume energía en el ascenso. Por el contrario, la energía consumida en el ascenso es cuatro veces superior a la que consume el ascensor electro-mecánico, por lo que el resultado es que, por término medio, consumen más o menos el doble que estos. Este tipo de ascensor, no tiene contrapeso.

El grupo impulsor realiza las funciones del grupo tractor de los ascensores eléctricos, y el cilindro con su pistón la conversión de la energía del motor en movimiento.

El fluido utilizado como transmisor del movimiento funciona en circuito abierto, por lo que la instalación necesita un depósito de aceite. La maquinaria y depósito de este tipo de ascensor pueden alojarse en cualquier lugar, situado a una distancia de hasta 12 metros del hueco del mismo, con lo cual permite más posibilidades para instalar este ascensor en emplazamientos con limitación de espacio.

Son los más seguros, más lentos y los que más energía consumen, aunque son los más indicados para instalar en edificios sin ascensor.

Actualmente se está generalizando el ascensor eléctrico sin cuarto de máquinas o MRL ("Machine Room Less"). Las ventajas desde el punto de vista arquitectónico son claras: el volumen ocupado por la sala de máquinas de una ejecución tradicional desaparece, ahorrando los costes de la tradicional sala de máquinas, pudiendo ser aprovechada para otros fines o haciendo posible que se pueda llegar con el ascensor hasta la terraza o planta más alta donde anteriormente se situaba la sala de máquinas. En este tipo de ascensores se suelen utilizar motores "gearless" de imanes permanentes, accionados mediante una maniobra con control por variador de frecuencia, situados en la parte superior del hueco sobre una bancada directamente fijada a las guías, que están ancladas a cada forjado. Con ello, las cargas son transferidas al foso en lugar de transmitirse a las paredes del hueco, evitando así vibraciones y molestias a las viviendas adyacentes.

La empresa alemana ThyssenKrupp Elevator es el primer fabricante de ascensores en inventar e implantar un sistema de dos cabinas viajando independientemente en un mismo hueco de ascensor. Gracias a un extraordinario trabajo de ingeniería y un avanzado sistema de control, con un concepto de alta seguridad, es posible que operen las dos cabinas de forma independiente, creándose inmensos beneficios potenciales para su uso en nuevas instalaciones y en modernizaciones de edificios.

El corazón del sistema es un control de selección de destino, capaz de asignar de manera inteligente a cada ascensor las llamadas de los distintos pisos. Cuando un usuario llama a un ascensor desde el pasillo, antes de que el pasajero entre allí, recoge la información de la planta en la que está y a la que se dirige, y le asigna el elevador más adecuado para su trayecto.

La principal ventaja de este sistema, es que incrementa la capacidad de transporte de los ascensores del edificio, utilizando un menor volumen de construcción y de espacio.

Para lograr un funcionamiento más eficaz, los sistemas de ascensores más modernos poseen una memoria que almacena los pedidos de llamada y los atienden priorizando las peticiones que están en dirección al coche, según distintos algoritmos de funcionamiento:

Las botoneras colocadas en los pasillos de los pisos poseen un solo botón.

En subida:
El ascensor va deteniéndose en todos los pisos marcados desde la cabina, pero no atiende ninguna llamada de piso, salvo la del piso más alto por encima del último registrado por los pasajeros. Una vez llegada la cabina al último piso cuya llamada haya sido registrada, y pasado un tiempo sin nuevos pedidos, el ascensor cambia de dirección.

En bajada:
El ascensor va deteniéndose en todos los pisos registrados en la cabina y también atiende los pedidos de llamada de los pisos, que supone son de bajada, hasta llegar al piso inferior que tenga un pedido de atención. En caso de que el ascensor disponga de dispositivo pesacargas el elevador no parará en las plantas intermedias si la cabina tiene la carga completa.

Las botoneras colocadas en los pasillos de los pisos poseen dos botones: uno para pedidos de subida y otro para bajada.

En subida:
El ascensor va deteniéndose en todos los pisos marcados desde la cabina y también en los pedidos de piso marcados como subida, pero no los de bajada. Al llegar al piso más alto por encima del último registrado por los pasajeros o desde los rellanos, y pasado un tiempo sin nuevos pedidos, el ascensor cambia de dirección.

En bajada:
El ascensor va deteniéndose en todos los pisos registrados en la cabina y también atiende los pedidos de llamada de los pisos en bajada pero no los de subida, hasta llegar al piso inferior que tenga un pedido de atención.

Los modernos ascensores disponen de avanzados sistemas de inteligencia artificial con algoritmos lógicos que maximizan el rendimiento de los equipos coordinando las operaciones de cada uno, para lograr acelerar la atención de llamadas y aumentar la capacidad de transporte.

Este modo de funcionamiento, llamado "en batería", logra una máxima eficiencia mediante índices que calculan varias veces por segundo las circunstancias de funcionamiento en que se halla cada equipo, decidiendo cuál de todos posee una situación más ventajosa frente al conjunto para atender el pedido de llamada.

Los equipos de última generación emplean un microprocesador especialmente para realizar la tarea de coordinación, debido a la gran cantidad de variables y datos en tiempo real que tienen en cuenta los complejos algoritmos.

En teoría un cuerpo que cayera de 443 m de altura se precipitaría a una velocidad de 320 km/h. Pero esos ascensores están dotados de mecanismos de seguridad.

El perfeccionamiento de los ascensores modernos tuvo sus orígenes en 1854, cuando el ingeniero estadounidense Elisha Graves Otis instaló el primer mecanismo de seguridad en un elevador de carga, en la exposición del Palacio de Cristal en New York. Antes, los elevadores de ese tipo eran muy inseguros: sus cables se rompían con frecuencia y, en ocasiones se producían accidentes mortales.

Con cierto espíritu teatral, Otis hizo una demostración de su elevador: se subió en él, junto con cajas, barriles y demás cargas; luego ordenó que cortaran el cable. En los montacargas anteriores, esto hubiera sido mortal. Pero el mecanismo de seguridad funcionó y el elevador se detuvo inmediatamente.

¿El secreto de Otis? Un recio muelle fijado en la parte superior de la plataforma del elevador. Al subir la plataforma, el muelle se arqueaba y sus extremos no tenían contactos con los rieles guía que había en cada lado. Pero al cortar el cable, el muelle recuperaba su forma y sus extremos se trababan en los rieles evitando así el desplome.
En 1857, Otis instaló el primer elevador de pasajeros, en un edificio de cinco pisos de Broadway, New York. La invención del elevador de seguridad fue un factor decisivo en la aparición de los rascacielos. Antes los edificios eran de un máximo de seis pisos, ya que la gente se oponía a subir demasiadas escaleras, por lo agotador.
El elevador de pasajeros y las técnicas de construcción con estructuras de hierro, proporcionaron los medios para las edificaciones de gran altura.

Los ascensores modernos no difieren en esencia del modelo Otis. Consisten en una cabina que se iza, mediante cables de acero, por dos rieles guía, y cuentan además con un mecanismo de seguridad que impide el desplome.
Los cables salen de la cabina y van hasta una polea situada en la parte superior del cubo del elevador, y que es accionada por un motor. Los cables bajan por la fuerza de un contrapeso que corre por rieles guía. 

Un componente clave de la protección es el limitador de velocidad, que está unido por medio de un cable al dispositivo de seguridad montado debajo de la cabina del elevador.

El limitador se sirve de la velocidad, cuando alcanza una velocidad superior a la velocidad nominal del elevador este dispositivo se enclava a su vez y por medio de la fricción jala al cable y este activa al sistema de paracaídas montado en la parte inferior de la cabina, momentos antes de que se enclave el limitador de velocidad se activa un contacto eléctrico lo cual manda una señal al control para detener el equipo eléctricamente, en caso de que no funcione este contacto se activa el limitador de velocidad, entonces tenemos dos formas de detener el elevador una es mecánica por medio del paracaídas y otro es eléctrico por medio de los contactos eléctricos. El primero en accionarse es el contacto eléctrico si no funciona se detiene mecánicamente.

El ascensor cuenta con un eje de tran, o bien vías reforzadas de tran las cuales evitan que la caja se salga de su eje, brindando mayor seguridad y menos esfuerzo de reparación a los operarios de algunos ascensores. El tran es un elemento de metal o hierro reforzado en titanio o los mismos elementos excentes de metal o hierro.
Si la cabina continúa acelerándose, el regulador tira con fuerza de su cable, y este activa el mecanismo de seguridad.
En algunos mecanismos especiales se utilizan rodillos o levas de bordes dentados, que se calzan en los rieles guía y detienen la cabina. Otros usan cuñas similares a las zapatas del freno de los automóviles.
Como tal el elevador es un medio de transporte seguro que evita la fatiga y las molestias que implica el hecho de subir y bajar escaleras actualmente, este también es un medio muy favorable para el uso de personas con discapacidades físicas.

En España, los ascensores están regulados por el Real Decreto 2291/1985, de 8 de noviembre, por el que se aprueba el Reglamento de Aparatos de Elevación y Manutención de los mismos. En él se han separado las normas de carácter general de aquellas otras propiamente técnicas más afectadas por el progreso previsible, las cuales están recogidas en las Instrucciones Técnicas Complementarias (ITC).

A partir del 1 de septiembre de 2017, entran en vigor las normas EN 81-20 y En 81-50 mucho más actualizadas y completas, anulando así la normativa anterior.




</doc>
<doc id="28010" url="https://es.wikipedia.org/wiki?curid=28010" title="Restauración Meiji">
Restauración Meiji

La describe una cadena de eventos que condujeron a un cambio en la estructura política y social de Japón en el período comprendido de 1866 a 1869, un período de cuatro años que abarca parte del período Edo (también denominado Shogunato Tokugawa tardío) y el comienzo de la Era Meiji.

La restauración Meiji "Bakumatsu no Dōran" (fin del régimen del "shōgun") fue la sucesión política que llevó al Shogunato Tokugawa a su final para renovar el poder de gobierno de Japón al Tennō, cedido a la figura del shogún durante el shogunato Kamakura. Este régimen era muy parecido al feudalismo europeo, el emperador (que se creía que descendía de los dioses) no tenía el poder real sino que dependía del "daimyō" (señor feudal o hacendado de familias importantes) más importante. Este se titulaba "shōgun", que es el mayor rango que un daimyō podía obtener. Por eso el régimen político se llamaba shogunato Japón hasta 1853 había permanecido aislado del resto del mundo económica y políticamente (excepto para China y los Países Bajos). En esta fecha llega una escuadra de la Armada estadounidense (al mando del Comodoro Perry) que tenía como propósito exigir un tratado de comercio. Este hecho se conoce también como "Kuro-fune raikō" (llegada de los barcos negros). Al no tener Japón una armada para hacerle frente tuvo que aceptar el tratado, evidenciando lo débil que era el país.

Esta revolución tuvo una particularidad única en la historia; la misma clase dominante (la aristocracia) fue la que vio la necesidad de cambio y de renunciar a sus derechos especiales. Por eso estaban divididos en dos bandos: los "Ishin shishi" y los partidarios del shogunato. Los terratenientes ("daimyō") que estaban en contra del shogunato lideraron el Ishin shishi. Entre ellos destacan tres dirigentes, el llamado "Ishin sanketsu" (el triunvirato "Ishin"), cuyos integrantes eran Toshimichi Okubo, "Saigō Takamori" y Kogoro Katsura.

Los partidarios del shogunato contaban con diferentes fuerzas para enfrentarse a estos revolucionarios; entre ellos el Shinsengumi (una fuerza paramilitar-policial situada en Kyoto). Para 1867 el movimiento revolucionario había logrado un avance decisivo y el emperador Meiji (que no tenía poder real) dicta la orden de disolver el bakufu (shogunado). Pero el shōgun Tokugawa Yoshinobu se resiste a dejar el poder en manos del Ishin shishi y en 1868 se desarrollan cinco batallas más, llamadas las Guerras Boshin, en orden cronológico son estas: Toba-Fushimi, Monte Ueno, Nagoaka, Aizu y Hakodate. 

Posteriormente los samuráis tras los radicales cambios realizados por el emperador, se rebelan contra él, formando un ejército cuyo enemigo será el emperador al abolir los privilegios de la clase samurái, los contrincantes fueron el recién fundado cuerpo de policía, formada en gran parte por samuráis que se pusieron al servicio del emperador y samuráis de los clanes vencedores en las Guerras Boshin: Satsuma y Chozu. 

Los resultados de las cinco guerras fueron determinantes y el "shōgun" convocó a consejo al "ishin" "Saigō Takamori", en el que estuvo presente el jefe de marina shogunal, Katsu Kaishū. El resultado de este consejo fue la rendición del shogunato.

La formación en 1866 de la alianza Satsuma-Chōshū entre Saigō Takamori, el líder del territorio Satsuma, y Kido Takayoshi, el líder del territorio Chōshū, construyen los cimientos de la restauración Meiji. Estos dos líderes apoyaron al Emperador Kōmei (padre del emperador Meiji) y se aliaron junto a Sakamoto Ryoma con el propósito de cambiar el gobierno del Shogunato Tokugawa ("bakufu") y devolver el poder al emperador. A finales de 1867, el Emperador Meiji asciende al trono después de la muerte del emperador Kōmei. 
Este periodo también supuso un cambio a Japón desde el comienzo de una sociedad feudal a tomar una economía capitalista con una persistente influencia occidental.

En 1868 comienza la era Meiji (o Restauración Meiji). En esta, quedan abolidos los privilegios especiales de los samuráis, se le da a la población la posibilidad de portar apellido (privilegio hasta entonces de la aristocracia, mientras que la gente llevaba el nombre de su profesión, por ejemplo, el capitán de un barco se llamaba "Anjin" (capitán). Estos cambios provocaron la inestabilidad del país en el comienzo de la era Meiji. Hubo muchos levantamientos, pero se puede destacar el de "Saigō Takamori", integrante del triunvirato ishin, amigo y compañero de Toshimichi Ookubo. Saigō es derrotado por Ōkubo y hecho ejecutar. La era Meiji logró la "estabilidad total" después de cuatro décadas.




</doc>
<doc id="28011" url="https://es.wikipedia.org/wiki?curid=28011" title="Min">
Min

Min era el dios lunar, de la fertilidad y la vegetación, dios de la lluvia, protector de los comerciantes y los mineros, representaba la fuerza generadora de la naturaleza en la mitología egipcia. 


Fue representado como hombre de piel negra o verde manteniendo el falo erecto, sobre un pedestal, y portando corona de dos largas plumas y flagelo. En algunas ocasiones se representa como un toro negro o un león.

Min era de las deidades egipcias más antiguas, su culto se remonta a la época predinástica; procedía de Coptos, cerca de la ruta caravanera del Uadi Hammamat donde era el protector de los viajeros mercaderes y de los mineros. Min era un dios lunar relacionado con el calendario. Estaba vinculado a la realeza pues aseguraba la abundancia. 

Se le consideraba hijo de Ra, o de Shu, y Jentit-Iabet era su madre-esposa; formaba pareja con Repit en Atribis, y con Aperetisis en la época griega, siendo su hijo Kolanthes. También formaba tríada con Kadesh y Reshep. En una estela del museo del Louvre se le cita como hijo de Osiris e Isis.

Fue denominado "Jefe del Cielo" y "Abridor de las nubes", en la época predinástica, como dios de la lluvia, y fuerza generadora; también era el "Guardián de los caminos", pues era el protector de los comerciantes y caravanas que viajaban por el desierto. Min, como dios lunar, era el "Protector de la Luna". Era llamado "toro de su madre", como fecundador de la diosa-cielo; también era el "Señor del desierto oriental". 

Durante el Imperio Medio fue asociado a Horus el Viejo como Min-Horus, y en el Imperio Nuevo con Amón-Ra, siendo muy popular. Muchos de los atributos de Min fueron recogidos por Amón, a quien también se le representó a veces con el falo erecto, para destacar su potencia fecundadora. Se le asoció a la serpiente Kamutef en Luxor. Como dios de la fertilidad y la vegetación, los griegos lo asociaron con el dios Pan. 

El culto a Min fue uno de los más duraderos y extendidos, siendo popular en la totalidad de Egipto en todos los periodos. Los griegos llamaron a la ciudad de "Ipu" o "Jent-Min", donde era adorado, Panópolis, la acual Ajmin. También fue venerado en "Jemnis" y Coptos, donde se le adoró en la forma de toro blanco llamado "Tep Hesepet" durante el Imperio Nuevo.

Era el dios del mes de Tybi, al comienzo de la estación de Peret. Además, el último día del mes lunar estaba consagrado al Min y era llamado el día de "La salida de Min". Durante el Imperio Nuevo era muy popular, celebrándose en su honor fiestas orgiásticas el día 28 del mes de Mesore. 

Se le ofrecía la primera cosecha de trigo en la "Fiesta de la Escalera". La lechuga, debido a sus presuntas propiedades afrodisíacas, era la planta sagrada de Min, y al principio de la estación de la cosecha, se sacaba su imagen del templo a los campos. Ello formaba la parte central del "festival de la salida de Min", durante el cual se bendecían los cultivos y se celebraban juegos gimnásticos en su honor.




</doc>
<doc id="28012" url="https://es.wikipedia.org/wiki?curid=28012" title="Historia de Europa">
Historia de Europa

La historia de Europa se refiere al conjunto de sucesos relativos al continente europeo, desde que fue poblado por los primeros seres humanos hasta la actualidad.

El Homo sapiens habría aparecido hace unos 130.000 años en África, según la opinión científica mayoritaria. La llegada del Homo sapiens a Europa podría haberse dado desde el Cercano Oriente a Europa, donde se asentaron entre 40.000 y 25.000 a. C. (Paleolítico Superior).

La Antigüedad clásica está dominada por el influjo de la civilización greco-latina sobre el resto de Europa. La fragmentación política de Europa y los sucesivos intentos forzados de unificación sumieron al continente en numerosos conflictos y guerras durante la Edad Media, como la Guerra de los Cien Años (que duró más de un siglo).

La Edad Moderna marca para Europa el inicio de procesos que mucho después darán lugar a la globalización, y es el tiempo en el que los conflictos bélicos se hicieron cada vez más desastrosos, como la llamada guerra de los Treinta Años. Los procesos económicos y el desarrollo científico y tecnológico se aceleraron en desmedro de otros continentes de manera mucho más notoria durante la Edad Contemporánea, produciendo tensiones por competencias que desencadenaron más guerras (como las guerras Napoleónicas y las guerras mundiales). Hoy los procesos tendentes a la unificación se procuran pacíficamente, tal es el caso de la formación de la Unión Europea, si bien no exenta de avances y retrocesos.

Las evidencias arqueológicas y lingüísticas sugieren que durante el III milenio a. C., contingentes importantes de pueblos que hablaban lenguas indoeuropeas entraron en Europa, encontrándose con poblaciones preindoeuropeas cuyo origen no es fácil de precisar. Los diversos pueblos indoeuropeos del II milineo a. C. ya hablaban lenguas diferentes, en particular en durante el milenio I a. C. ya es posible distinguir los grupos lingüísticos presentes en la actualidad: pueblos celtas, pueblos germanos, pueblos baltos y eslavos, pueblos itálicos, pueblos paleobalcánicos y pueblos helénicos (algunas ramas indoeuropeas como los daco-albaneses no se testimoniarían hasta más tarde).

No se conoce mucho sobre la lengua o la identidad étnica de los pueblos asentados en Europa antes de las migraciones indoeuropeas, se conoce que los aquitanos, los iberos, los taresios y etruccos y retios hablaban lenguas no indoeuropeas que se conocen muy imperfectamente, al igual que la lengua de los minoicos (eteocretense) o el eteochipriota.

Hacia el año 3000 a. C., por influencia de la cultura del Medio Oriente, en la isla de Creta surgió una civilización que construyó un imperio marítimo que abarcó a todo el mar Egeo, y que comerció con Egipto y el Levante.

Los griegos se estructuraron políticamente en torno a comunidades autónomas llamadas polis ("ciudad-estado"). A diferencia de otras culturas, los griegos nunca formaron un solo gran imperio; cuando fueron unificados, sucedió por obra de invasores externos (macedonios y romanos), y no por sí mismos.

Por su parte, los griegos emprendieron dos oleadas colonizadoras, a Jonia primero, y luego por toda la cuenca del mar Mediterráneo y el mar Negro posteriormente, fundando las ciudades que después serían Marsella, Nápoles, Tarento, Síbaris, Bizancio, etc. Aunque centrándose en África, los fenicios y cartagineses también llevaron a cabo labores de fundación de ciudades en Europa, incluyendo a Tartessos y Cartagena. En el norte de Italia, de manera paralela, surgió la cultura de los etruscos.

Durante la segunda mitad del Primer Milenio, el Mediterráneo se convirtió en campo de batalla para distintas potencias políticas. Atenas intentó hacerse con la hegemonía del Mediterráneo a través de la Liga de Delos, a la vez que vivió un período de esplendor durante el llamado Siglo de Pericles, pero colapsó después de su derrota en las Guerras del Peloponeso (431 a. C.-404 a. C.). Siguió un siglo de inestabilidad en Grecia, hasta que Filipo II la unificó bajo su hegemonía. Posteriormente, Alejandro Magno emprendió la conquista del mundo oriental, y aunque después de su muerte (323 a. C.) las potencias orientales volvieron a ser independientes, Macedonia permaneció como gran potencia.

En el Occidente, por su parte, empezó a surgir el poderío de la República Romana. Esta se enfrentó a los etruscos en una larga serie de guerras, que culminaron con la anexión de las principales ciudades etruscas hacia 250 a. C.. A la vez se enfrentaron al poderío cartaginés y lo doblegaron en las guerras púnicas (264 a. C.-146 a. C.). Durante el siglo siguiente, los romanos se extendieron por Grecia y por Oriente. En Europa, los romanos siguieron extendiendo sus fronteras tierra adentro, hasta que en la época de Octavio Augusto (31 a. C.-14 d. C.), el Imperio romano cubría todas las tierras europeas al sur de los ríos Rin y Danubio.

En este proceso de expansión, los romanos destruyeron la cultura de los celtas en Hispania y en la Galia. Después, al saltar a Gran Bretaña en el año 43, los romanos destruyeron los núcleos celtas en Inglaterra y Gales. Con todo, la cultura druidídica se conservó en Irlanda y Escocia.

Al otro lado del río Rin, por su parte, vivían las tribus de los germanos. No formaron un reino unificado, sino que eran colecciones de tribus comandadas por un rey y una aristocracia tribal. Algunas tribus de germanos intentaron cruzar la frontera y atacar a los romanos, aunque sin éxito (los cimbrios y teutones, por ejemplo). Durante los cuatro siglos que van desde la época de Julio César hasta la de Teodosio el Grande, la frontera de los ríos Rin y Danubio fue efectivamente el límite entre la cultura de los romanos y la de los germanos.

En el año 235, el Imperio romano entró en un período de caos y confusión, del cual salió medio siglo después, pero fuertemente debilitado, y con una economía y políticas de corte marcadamente más totalitarias; este nuevo régimen se denomina el Dominado. Durante esta crisis, los bárbaros germanos empezaron a presionar con mayor fuerza al Imperio romano, e incluso colonizaron (o fueron llamados como colonos) a varias tierras romanas fronterizas.

En esta época, dentro del Imperio romano, prosperó la religión del cristianismo. En 313, Constantino decretó la tolerancia religiosa hacia los cristianos en el llamado ""Edicto de Milán"", mientras que en 395, Teodosio el Grande proclamó al cristianismo como religión oficial del Imperio. En este período, y en particular desde el Concilio de Nicea en adelante, el cristianismo desarrolló fuertes estructuras jerárquicas, además de desarrollar fuertemente la doctrina y los dogmas de fe. En ese sentido, el cristianismo empezó a desarrollar la fisonomía que presentaría la Iglesia Católica durante la Edad Media.

En el año 378, en la batalla de Adrianópolis, los germanos infligieron una dura derrota a los romanos. A partir de entonces la presión de los germanos aumentó aún más. En 406 cruzaron el Rin, y ante la impotencia de los romanos, se instalaron en varias tierras del Imperio. En 410, los visigodos saquearon Roma (por primera vez en siete siglos la ciudad imperial es hollada), y los vándalos repiten esto en 455. Aunque todavía nominalmente en pie, el Imperio romano se disgrega. En 476, Odoacro (jefe de la tribu de los hérulos) toma el poder, pero en vez de proclamarse Emperador, envía las enseñas imperiales a Bizancio, terminando así "de iure" el Imperio romano de Occidente.

Los caudillos germánicos se lanzaron entonces, durante los siglos V y VI, a varias guerras que los debilitaron políticamente. Hacia el año 600 sobrevivían sólo los reinos de los visigodos, los lombardos, los francos y los anglosajones. Estas monarquías eran verdaderas aristocracias militares, en las que el rey era más un ""primus inter pares"" que un verdadero monarca absoluto.

Después de la desintegración del mundo antiguo como consecuencia de las irrupciones de los pueblos germánicos: Bélgica (259), Galia (268-78), Italia (260-70), Tracia, Grecia y Asia Menor (258-69), cuando los persas derrotaron y capturaron al emperador Valeriano (260). viene la época de la Alta Edad Media o de las "Edades Oscuras", que abarca el periodo comprendido desde la caída del Imperio romano hasta el feudalismo. En el año 409 los jutos, anglos y sajones desalojan a los romanos de la Gran Bretaña; En el 490 visigodos y vándalos llegan a España, mientras que los hunos alcanzan Orleáns y Milán. Estas invasiones suponen la disolución y desplazamiento del centro del poder imperial de Roma hacia el norte de Europa en lo que sería el Imperio carolingio.

Los germanos se lanzaron también a la tarea de unificar la sociedad germánica con la romana. En muchos casos esto se reflejó en un proceso legislativo que tendió a unificar las leyes aplicables a los germanos y a los romanos. Este proceso legislativo vino a quedar completo en el siglo VII, época en la que ya no era posible distinguir entre ambas poblaciones.

Mientras el Imperio romano de Occidente era destrozado por los bárbaros, el Imperio romano de Oriente consiguió sobrevivir. Algunos consideran a Constantino I (reinó 306-337) como el primer "emperador bizantino". Fue él quien trasladó la capital imperial en 324 de Nicomedia a Bizancio, refundándola como Constantinopla, o Nova Roma ( "Nueva Roma"). La ciudad de Roma en sí no había servido como capital desde el reinado de Diocleciano. Otros fechan los inicios del Imperio en el reinado de Teodosio I (379-395) y consideran que el cristianismo se instauró como religión oficial suplantando a la religión pagana romana, tras su muerte en 395, cuando la división política entre el Este y el Oeste se convirtió en permanente. Sin embargo, otros fechan todavía más tarde el inicio del imperio, en 476, cuando Rómulo Augústulo, tradicionalmente considerado el último emperador occidental, fue depuesto, con lo que el único que conservó la autoridad imperial, fue el emperador griego en el Oriente. Otros apuntan a la reorganización del imperio en la época de Heraclio (620), cuando los títulos latinos fueron sustituidos oficialmente con versiones en griego. En cualquier caso, el cambio fue gradual y para la década de 330, cuando Constantino inauguró su nueva capital, el proceso de helenización y el aumento de la cristianización ya estaban en marcha. Se considera generalmente que el imperio terminó después de la caída de Constantinopla bajo los turcos otomanos en 1453.

Bajo la égida de Justiniano I (527-565), los generales bizantinos iniciaron una ambiciosa serie de campañas militares para anexarse los antiguos territorios romanos de Occidente, conquistando el norte de África a los vándalos, Italia a los ostrogodos (aunque por breve tiempo, porque en 568 se apoderaron de ella los lombardos) y partes de Hispania, que consiguieron mantener en su poder hasta 622. Sin embargo, el desgaste de estas guerras, más las emprendidas por Justiniano y sus sucesores contra la potencia persa de los sasánidas, debilitaron mortalmente al Imperio. Además, la "Peste de Justiniano" afectó al Imperio bizantino, incluida su capital Constantinopla, en los años 541-542. Se estima que la plaga provocó hasta un máximo de 100 millones de muertes en todo el mundo, causado la caída de alrededor del 50% de número de habitantes de Europa entre 541 y 700. El éxito de las conquistas árabes, también puede haber contribuido a la catástrofe demográfica. En el siglo VII la irrupción de los árabes le asestó al Imperio bizantino un duro golpe, privándolo de sus territorios africanos (incluyendo Egipto), de Palestina y de Siria. A partir de entonces el Imperio bizantino sería una potencia que basaría su poderío en el dominio de la Anatolia y los Balcanes.

Las conquistas árabes llegaron hasta Europa. En el año 711, al mando de Tarik y enviados por el gobernador africano Muza, los árabes conquistaron y destruyeron el Reino Visigótico, y se anexaron Hispania. Aun así, un núcleo de montañeses asturianos resistió, y se transformaría en la semilla del contragolpe cristiano contra los musulmanes. En 732, una incursión musulmana contra la Galia fue frenada en la Batalla de Poitiers por Carlos Martel, marcando el máximo de expansión musulmana en Europa. Algo después, en 756, el Emir Abderramán I se independizó del Califato Abasida, y creó en España el Emirato de Córdoba, que se transformó en un importante núcleo del saber y la cultura en la Europa de la Edad Media.

Después de la caída del Imperio romano en Occidente en el siglo V, Europa occidental emerge como una nueva civilización. Tras las invasiones bárbaras y la separación del Imperio bizantino (Imperio romano de Oriente), éste sobrevivió otro milenio.

El Feudalismo reemplazó al Imperio romano en Europa. La única institución que sobrevivió fue la Iglesia Católica, que preservó parte de la cultura romana, y se convirtió en la principal fuente de aprendizaje hasta el siglo XIII. Hasta el año 1000 crece el feudalismo, que debilita al Sacro Imperio Romano y define a la Iglesia Católica como el mayor poder cristiano, ya que el papado no sólo tenía su propio estado, sino que atesoraba todo el saber grecorromano y era el guía espiritual de todos los poderosos estados europeos, consiguiendo controlar en muchas ocasiones sus políticas exteriores y de conquistas.

La Casa de los Pipínidas, a la que pertenecía como mayordomo de palacio de los francos el mencionado Carlos Martel, pidió el reconocimiento al papado como reyes, y fueron entronizados. La Dinastía Merovingia fue reemplazada así por la Dinastía Carolingia. Como parte del acuerdo entre Pipino el Breve (hijo de Carlos Martel) y el papado, varios territorios italianos fueron entregados a éste, transformándose en la semilla de los futuros Estados Pontificios.

El hijo de Pipino el Breve fue Carlomagno, quien gobernó el Imperio carolingio desde 771 hasta su muerte en 814. Carlomagno, aliado con el papa, hacia el año 800, conquista Francia, el oeste de Alemania, gran parte de Italia y partes de otros países. Surge el Sacro Imperio Romano Germánico cuyo emperador intenta dominar al papado que había constituido un estado independiente en el centro de Italia.

Carlomagno protegió al papado, lidiando varias guerras contra sus enemigos tradicionales los lombardos y fortaleciendo el rol social de la Iglesia. Creó también la Escuela Palatina, a cargo de Alcuino de York, y propulsó el llamado "Renacimiento carolingio". En política exterior intentó atacar a los musulmanes de España, operación que se vio frustrada por la dura derrota sufrida en la Batalla de Roncesvalles (778), aunque en 804 creó la Marca Hispánica. Libró también una guerra de aproximadamente 30 años contra los sajones, e inició la cristianización de Alemania. Entabló relaciones diplomáticas tanto con el Imperio bizantino como con el Califato Abasida. En el ámbito interno llevó a cabo una serie de reformas administrativas, dividiendo su imperio en marcas y condados, algunos de los cuales sobrevivieron a su Imperio como entes independientes.

Sin embargo, al morir Carlomagno en 814, su heredero Ludovico Pío resultó ser un monarca débil y no pudo proseguir la obra de su antecesor. En 843, los hijos de Ludovico Pío (nietos de Carlomagno) se repartieron el Imperio en el Tratado de Verdún, surgiendo así las coronas de Francia y de Alemania (otro territorio surgido de dicho tratado, la Lotaringia, se desintegró rápidamente).

Después del Gran Cisma de Oriente y Occidente, el cristianismo occidental fue aprobado por los recién creados reinos de Europa Central: Polonia, Hungría y Bohemia. La Iglesia católica se desarrolló como una gran potencia, dando lugar a conflictos entre el papa y el Emperador. En 1129 la Iglesia Católica estableció la Inquisición para hacer a los europeos occidentales sus miembros por la fuerza. La Inquisición castigaba a aquellos que practican la herejía para que se arrepintiesen. Si no lo hacían, sufrían la pena de muerte. Durante este tiempo muchos nobles gobernaron la iglesia. Los monjes de Cluny consiguieron establecer una iglesia donde no existían los nobles. El papa Gregorio VII, continuó la labor de los monjes con 2 objetivos principales: librar la iglesia del control de los reyes y nobles y aumentar el poder del papa. La influencia de la Iglesia católica había crecido enormemente debido a las conversiones de reyes paganos (Escandinavia, Polonia, Hungría, Lituania ), Reconquista cristiana de Al-Ándalus, y las cruzadas. Como resultado, la mayor parte de Europa era católica en el siglo XV.

Los primeros signos del renacimiento de la civilización en Europa occidental comenzaron a aparecer en el siglo XI, cuando el comercio comenzó de nuevo en Italia, dando lugar a la situación económica y el crecimiento cultural de ciudades-estado independientes, tales como Venecia y Florencia y, al mismo tiempo, los estados-nación empezaron a tomar forma en lugares como Francia, Inglaterra, España y Portugal, aunque el proceso de su formación (por lo general marcado por la rivalidad entre la monarquía, la aristocracia señores feudales y la iglesia) en realidad duró varios siglos. Estos nuevos estados-nación comenzaron a escribir en sus propias lenguas en lugar del tradicional latín. Por otra parte, el Sacro Imperio Romano, basado esencialmente en Alemania e Italia, se vio fragmentado en un sinnúmero de principados feudales o pequeñas ciudades-estado, cuya subordinación al emperador fue sólo formal.

Los siglos XIII y XIV, cuando el Imperio mongol llegó al poder, se denomina a menudo la edad de los mongoles. Ejércitos mongoles se extendieron hacia el oeste bajo el mando de Batu Kan. Sus conquistas incluyeron la parte occidental de Rusia (salvo Novgorod, que se convirtió en vasallo), las tierras de los cumanos, Hungría y Polonia (que había permanecido como Estado soberano). Registros mongoles indican que Batu Kan estaba planeando una completa conquista de las restantes potencias europeas, comenzando con un ataque de invierno en Austria, Italia y Alemania, cuando debió regresar a Mongolia tras la muerte del Gran Kan Ogodei. En Rusia, los mongoles de la Horda de Oro gobernaron durante casi 250 años. En Europa, el Centro y el Oriente estaba dominado por el Reino de Polonia, Chequia y Hungría. Hasta la batalla de Grunwald fue también fuerte la Orden Teutónica.

La peste negra fue una devastadora pandemia que asoló Europa en el siglo XIV y que causó la muerte de un 30 a un 60% de la población del continente europeo, reduciendo la población mundial estimada desde 450 millones hasta 350 o 375 millones en el año 1400. La mayor parte de los científicos cree que la peste negra fue un brote de peste bubónica, una terrible enfermedad que se ha extendido en forma de epidemia varias veces a lo largo de la historia. La peste es causada por la bacteria Yersinia pestis que se contagia por las pulgas con la ayuda de la rata negra (Rattus rattus), que hoy conocemos como rata de campo.

Durante el siglo XV en Francia, Inglaterra y España, nuevos monarcas formaron poderosas naciones.
En el Centro y Oriente de Europa dominaba la República de las Dos Naciones. Después del año 1655 Polonia- Lituania fue el estado más fuerte en la parte oriental del continente. Más tarde comenzó la era de la dominación de Rusia y Austria.

La Iglesia Católica estaba perdiendo poder por la corrupción, los conflictos internos, y el surgimiento de la cultura en lo artístico, filosófico, científico y tecnológico, del movimiento renacentista.

Las nuevas naciones se encontraban envueltas en guerras y problemas políticos.

Martín Lutero empezó la reforma en 1517, la reforma y la contrarreforma fue acompañada de guerras y persecuciones religiosas, con enormes implicaciones para Europa. En Inglaterra, Enrique VIII también rompió con la iglesia católica, autoproclamándose cabeza de la Iglesia en su reino, y el imperio Alemán encabezado por los Habsburgo fue atacado por los príncipes protestantes de Alemania.

En Europa Central, polacos, lituanos, y húngaros, adoptaron la tolerancia religiosa entre los católicos, protestantes, ortodoxos y judíos. También los reyes católicos Isabel de Castilla y Fernando de Aragón estaban muy preocupados por la unidad religiosa de sus reinos por lo que tomaron medidas cautelarias, como por ejemplo la creación de la Inquisición española (1478) y la expulsión de los judíos que no quisieran convertirse al cristianismo(1492). Su nieto Carlos I, heredará el título imperial, y hará de España el motor de un gran imperio que liderará Europa durante todo el siglo XVI y parte del XVII. Según el historiador Kamen, sería esta dominación española la primera globalización económica de la historia europea, y también el primer estado cosmopolita, puesto que estaba integrado por alemanes, austriacos, portugueses, italianos, flamencos y españoles de los varios reinos peninsulares, Aragón, Castilla y Navarra.

En innumerables ocasiones a través de todo el siglo XVII en el antiguo continente han estallado muchos conflictos políticos y religiosos. El objetivo de dichas guerras fueron la lucha por la supremacía en el continente. Durante este período, se concentraron en Europa del Este numerosas guerras entre Polonia, Rusia y Turquía, después también Suecia entró en guerras. Durante el período comprendido entre 1612-1613 el ejército polaco ocupó Moscú, y hasta mediados del siglo XVII, Polonia continuó dominando dicha parte de Europa. La época dorada del imperio polaco finalizó después de dos hechos acaecidos, el primer hecho, la Rebelión de Jmelnytsky y el segundo, el Diluvio. Mientras, en Europa central, sucedería una terrible guerra, la denominada Guerra de los Treinta Años. Hacia finales de este siglo, Imperio otomano comenzó a ser una amenaza por sus ánsias expansionistas, llegando a ser una amenaza para Austria. Durante la Batalla de Kahlenberg Turquía fue vencida por la alianza austríaco-polaca, frenando así la amenaza invasiva turca.

República de las Dos Naciones con sistema político de la mancomunidad, llamado "Democracia de los Nobles", se caracterizaba por la limitación del poder del monarca por las leyes y la cámara legislativa (Sejm) controlada por la Nobleza de Polonia (Szlachta). Este sistema fue el precursor de los conceptos modernos de democracia,Monarquía constitucional, y federación.

Desde principios del siglo XV extendiéndose hasta comienzos del siglo XVII los navíos de Europa surcaron los mares del mundo en busca de nuevos socios y rutas comerciales con los que se pudo contribuir al floreciente capitalismo europeo. Durante estas exploraciones, los europeos descubrieron naciones y cartografiaron territorios que anteriormente no conocían.

La Ilustración ("Lumières", en francés; "Enlightenment", en inglés; "Illuminismo", en italiano; "Aufklärung", en alemán), en frase de uno de sus más importantes representantes, D'Alembert, «lo discutió, analizó y agitó todo, desde las ciencias profanas a los fundamentos de la revelación, desde la metafísica a las materias del gusto, desde la música hasta la moral, desde las disputas escolásticas de los teólogos hasta los objetos del comercio, desde los derechos de los príncipes a los de los pueblos, desde la ley natural hasta las leyes arbitrarias de las naciones, en una palabra, desde las cuestiones que más nos atañen a las que nos interesan más débilmente». Esto mismo nos indica que, más que el contenido mismo de sus doctrinas, lo original del movimiento fue la forma de pensamiento y valoración.

El siglo XVIII constituye, en general, una época de progreso de los conocimientos racionales y de perfeccionamiento de las técnicas de la ciencia. Fue un período de enriquecimiento que potenció a la nueva burguesía, si bien se mantuvieron los derechos tradicionales de los órdenes privilegiados dentro del sistema monárquico absolutista. Sin embargo, la historia del siglo XVIII consta de dos etapas diferenciadas: la primera supone una continuidad del Antiguo Régimen (hasta la década de 1770), y la segunda, de cambios profundos, culmina con la Revolución estadounidense, la Revolución francesa y Revolución industrial en Inglaterra.

Desde Gran Bretaña, donde algunos de los rasgos esenciales del movimiento se dieron antes que en otro lugar, la Ilustración se asentó en Francia, donde la anglofilia fue difundida por Voltaire, y produjo aquí su cuerpo ideológico, el enciclopedismo, y sus más representativas personalidades (Montesquieu, Diderot, Rousseau, Buffon, etc); también dio sus frutos, en ocasiones más o menos autónomamente, pero en la mayoría de casos dependientes de Gran Bretaña y, sobre todo, de Francia, en otras zonas europeas (Países Bajos, la península italiana y la ibérica, el conglomerado germánico, Polonia, Rusia, Suecia, etc.) o en sus colonias americanas; frutos condicionados por el grado de desarrollo ideológico y sociopolítico adquirido en el momento de lanzamiento de la nueva ideología y por el proceso interno seguido a lo largo de su desenvolvimiento.

En la segunda mitad del siglo XVIII se inicia en Inglaterra una transformación de las estructuras económicas y sociales que sirvió de base para el posterior desarrollo, la revolución industrial en el siglo XIX. La expansión colonial conllevó un aumento en la demanda de productos que no podía cubrirse con la protoindustria tradicional. La creación de fábricas, con el consiguiente aumento significativo de la producción y las consecuencias sociales que éstas trajeron; el cambio en el comercio textil, pasando de la lana al algodón, con el desarrollo de nuevas tecnologías aplicadas a todo el proceso de producción textil; así como la invención de la máquina de vapor y su aplicación práctica en el ferrocarril; todo ello supuso una revolución económica que conllevó una auténtica ruptura con el modelo económico medieval.

Cuando se creó la máquina de vapor gran parte de las empresas la adquirieron y su producción se volvió más rápida y sofisticada.

Al final del siglo XVIII, la negativa del rey francés Luis XVI (apoyada por la nobleza y el clero) de compartir el poder político con el llamado Tercer Estado originó la Revolución francesa en 1789, como un intento de crear una nueva forma de gobierno basada en los principios de "Liberté, Égalité, Fraternité" (Libertad, Igualdad y Fraternidad). El rey fue ejecutado, Francia fue proclamada una república y una especie de gobierno democrático fue establecido. En el subsiguiente conflicto (relacionado con la coalición de la mayoría de las monarquías europeas que le declararon la guerra a la Francia republicana) el general Napoleón Bonaparte tomó el poder.

En los años de la era Napoleónica, Francia venció repetidamente a Austria (cuyo monarca fue forzado a abdicar al título de Emperador del Sacro Imperio romano Germánico), Rusia, Prusia y a otras potencias aliadas principalmente a Inglaterra. También organizó la Confederación del Rin. Después de ser proclamado emperador francés en 1804, Napoleón fue derrotado finalmente en la Batalla de Waterloo en 1815.

Luego de la derrota de la Francia revolucionaria, las otras potencias mayores trataron de restaurar la situación que existía antes de 1789. De cualquier forma, sus esfuerzos no fueron suficientes como para detener la proliferación de los movimientos revolucionarios: las clases medias estaban fuertemente influidas por los ideales de democracia emanados de la Revolución francesa, la Revolución industrial trajo otros cambios sociales y económicos, las clases bajas empezaron a ser influenciadas por ideas socialistas, comunistas y anarquistas (especialmente las resumidas por Karl Marx en el Manifiesto del Partido Comunista, y la preferencia de los nuevos capitalistas por el Liberalismo).

Mayor inestabilidad vino de la formación de varios movimientos nacionalistas (en Alemania, Italia, Polonia, etc), que buscaban la unificación nacional o su liberación del gobierno extranjero. Como resultado, el periodo entre 1815 y 1871 vio un gran número de intentos revolucionarios y guerras de independencia. Aunque los revolucionarios eran comúnmente derrotados, la mayoría de los estados europeos se habían convertido en monarquías constitucionales (dejando de ser absolutistas). Hacia el año 1871, Alemania (victoriosa en la Guerra Franco-prusiana) se había desarrollado como un estado nacional unificado, llevándose a cabo la unidad alemana, bajo la figura del Imperio alemán, cuyo arquitecto fue Otto von Bismarck. Italia, cuyos estados también habían estado divididos, logró la unificación bajo el liderazgo de Camillo di Cavour y Giuseppe Garibaldi.

La dinámica política de Europa cambió en dos ocasiones durante el siglo XIX. La primera, tras el Congreso de Viena, y la segunda, después de la Guerra de Crimea. En 1815, durante el Congreso de Viena, las principales potencias de Europa se las arreglaron para producir un balance pacífico del poder entre los imperios después de las guerras Napoleónicas (a pesar de que ocurrieran movimientos revolucionarios internos). Pero la paz sólo duraría hasta que el Imperio otomano hubiera declinado lo suficiente como para convertirse en blanco de los demás. Esto provocó la Guerra de Crimea en 1854 y se inició así un tenso periodo de choques menores dentro de los imperios de Europa que prepararon el estallido de la Primera Guerra Mundial.

Desde 1870, la hegemonía que Bismarck ejerció a lo largo de Europa puso a Francia en una situación crítica, obligando al país galo a reconstruir sus relaciones internacionales, buscando alianzas con Rusia e Inglaterra para controlar el creciente poderío de Alemania. De esta manera, Europa se dividió en dos.

Luego de la relativa paz durante el siglo XIX, la rivalidad entre las potencias europeas estalló en 1914, cuando se inició la Primera Guerra Mundial. En un lado se encontraban Alemania, el Imperio austrohúngaro y el Imperio otomano (las Potencias Centrales), mientras que del otro lado se encontraban Serbia y la "Triple Entente" - la vaga coalición de Francia, Inglaterra y Rusia, a la que se le uniría Italia en 1915 y los Estados Unidos en 1917. A pesar de la derrota de Rusia en 1917 (la guerra fue una de las principales causas de la Revolución rusa, que culminó en la formación de la Unión Soviética), la "Entente" finalmente consiguió el triunfo en el otoño de 1918.

En el Tratado de Versalles de 1919 los vencedores le impusieron duras condiciones a Alemania y reconocieron a los nuevos estados (como: Polonia, Checoslovaquia y Yugoslavia creados en Europa Central con territorios que pertenecieron a Alemania, Austria-Hungría, y al Imperio ruso, tomando como base la supuesta autodeterminación de los pueblos. En las siguientes décadas, el temor al comunismo y a la Depresión económica de 1929-33 provocaron el auge de gobiernos extremistas - Fascista o Nazi - en Italia (1922), Alemania (1933), España (luego de una guerra civil que finalizó en 1939) y en otros países como Hungría.

Desde 1936 los futuros beligerantes de Europa en la Segunda Guerra Mundial comienzan a enfrentarse directa o indirectamente en el marco de la Guerra Civil Española. El 25 de octubre el Ministro de Asuntos Exteriores italiano, sostuvo una visita en la Alemania nazi que dio lugar al "Pacto del Eje Roma-Berlín". El acuerdo consolidó las posiciones de Alemania e Italia contra Gran Bretaña y Francia. El 25 de noviembre siguiente, Japón y Alemania firmaron el "Pacto Anti-Komintern". En 1939 Alemania y la URSS firman el Pacto Molotov-Ribbentrop. El protocolo secreto definía la repartición de la Europa del este y central bajo influencia alemana y rusa, y establecía la cuarta partición de Polonia. El 1 de septiembre Hitler ordenó la invasión de Polonia sin previa declaración de guerra, lo que motivó que Francia y el Reino Unido declararan la guerra a Alemania el 3 de septiembre, aún existiendo un tratado que comprometía a estos países. La URSS ocupó la parte oriental de Polonia, hecho acordado en el pacto germano-soviético, matando a miles de oficiales polacos en lo que se conoce como la Masacre de Katyn; posteriormente atacó a Finlandia el 30 de noviembre, en lo que se conoce como la Guerra de Invierno, pero enfrentada a una resistencia inesperada, ambos países firmaron la paz en Moscú el 12 de marzo de 1940, tras ceder Finlandia posesiones territoriales a cambio de conservar su independencia.

Tras la conquista de Polonia, Alemania invadió Dinamarca y Noruega, esperando la intervención de Francia y Reino Unido, pero como estos dos países no tomaron la iniciativa de atacar, no se produjo ninguna acción bélica en varios meses (conocido con el término francés "Drôle de guerre", "guerra graciosa"), hasta la invasión de los Países Bajos, Francia y Bélgica por parte de Alemania en mayo y junio de 1940 ("Blitzkrieg" o guerra relámpago).

Desde la guerra contra Finlandia, Stalin había estado realizando esfuerzos apurados para modernizar el Ejército Rojo, ya que tanto él como Adolf Hitler sabían que el tratado de paz firmado no duraría mucho tiempo. Sin embargo, Hitler se adelantó a los planes de Stalin y en junio de 1941 Alemania lanzó la Operación Barbarroja contra la Unión Soviética, cuyo objetivo final era la derrota del país eslavo en sólo tres meses, de esta manera Alemania despojaría a los ingleses de un posible aliado.

Después de derrocar a Mussolini, Italia, invadida por el sur, cambió al bando aliado en 1943, y Rumanía hizo lo mismo en 1944, al ser invadida por los rusos. Alemania capituló el 7 de mayo de 1945, tras haber caído Berlín el día 2 de mayo ante las fuerzas soviéticas. El día 8 de mayo se firmó el armisticio que puso fin a la guerra en Europa. Las Guerras Mundiales terminaron con la posición preeminente de Europa Occidental.

El mapa de Europa fue redibujado en la Conferencia de Yalta y fue dividido como la principal zona de contención en la Guerra Fría entre las dos nuevas potencias emergentes, la capitalista Estados Unidos y la comunista Unión Soviética. Los Estados Unidos pusieron a Europa Occidental (Inglaterra, Francia, Italia, Alemania Occidental, España, etc.) dentro de su esfera de influencia, estableciendo la OTAN como una medida precautoria en contra de una posible invasión soviética; la Unión Soviética hizo lo mismo con Europa Central (Polonia, Checoslovaquia, Hungría, Rumanía, Bulgaria, Alemania Oriental) formando el Pacto de Varsovia. Europa fue dividida, conociéndose a esta situación con la metáfora de "Telón de acero". Esta situación duró hasta 1989, cuando el debilitamiento de la Unión Soviética originó la Glásnost y el fin de la división de Europa - los gobiernos satélites soviéticos se vieron libres para disolver los regímenes comunistas (y las dos Alemanias pudieron reunificarse). En 1991 la misma Unión Soviética se colapsó, dividiéndose en varios estados (el principal quedó como la Federación Rusa) y se disolvieron la mayoría de los gobiernos comunistas.

Después del fin de la Segunda Guerra Mundial, Europa Occidental inició lentamente un proceso de integración política y económica, con el deseo de unir a Europa y así prevenir otra guerra. Este proceso dio como resultado el desarrollo eventual de organizaciones como la Eurozona y la Unión Europea. Al final de la Guerra Fría, los países de Europa Central comenzaron a ser incluidos en estas organizaciones.

El 9 de mayo de 1950, Robert Schuman pronuncia el célebre discurso en el que tal como lo reconoce oficialmente la Unión Europea (UE) se dio el primer paso para la formación de esta organización. La UE se iniciaba como una vaga alianza económica entre naciones europeas, pero se requería un mayor esfuerzo para integrar estrechamente a los estados miembros y convertir a la UE en una organización supranacional. El proceso de integración de Europa fue lento debido a la negativa de la mayoría de los estados miembros a ceder su soberanía.

De cualquier forma, el proceso empezó a acelerarse a principios de los años 1990. Las naciones dentro de la Unión Europea crearon una "zona de libre comercio" y eliminaron la mayoría de las barreras aduaneras a lo largo de sus fronteras. La nueva moneda para Europa, el Euro, fue establecida electrónicamente en 1999, uniendo oficialmente a las monedas de cada nación participante. El Euro fue puesto en circulación en 2002 y las viejas monedas se volvieron obsoletas.

Pese al fortalecimiento de la unidad continental, Europa no supo evitar conflictos como las Guerras yugoslavas y en 2003 algunos países europeos, encabezados por Alemania, Francia y Rusia, se opusieron al nuevo concepto de "guerra preventiva" y rechazaron participar en la Invasión de Iraq. Otros países europeos, encabezados por Italia, España y Polonia, respaldaron la Guerra de Iraq y enviaron efectivos militares.

Desde 2013 la UE está conformada por 28 países europeos y algunos territorios de ultramar. Ese mismo año los jefes de gobierno de los países que forman la UE aprobaron el Tratado de Lisboa, que deberá ser ratificado por cada uno de los estados miembros antes de finales del 2008. Actualmente la UE se basa en cuatro tratados (Tratados de Roma, Maastricht y Amsterdam) que fijan sus normas de actuación.

Por otra parte la UE es la primera potencia comercial, representando el 20% de las importaciones y exportaciones mundiales.

Un aspecto interesante de la demografía europea durante la segunda mitad del siglo XX y principios del siglo XXI, es que durante la segunda mitad del siglo XX, la baja natalidad y las condiciones económicas imperantes en Europa y las regiones adyacentes, favoreció enormemente los procesos migratorios, y numerosos países de Europa recibieron grandes cantidades de migrantes de Asia, África y menor medida América Latina, llegando a tener muchos países porcentajes de población inmigrantes procedente de esas regiones de entre el 5 y 15%.




</doc>
<doc id="28027" url="https://es.wikipedia.org/wiki?curid=28027" title="Birthday (canción de The Sugarcubes)">
Birthday (canción de The Sugarcubes)

Birthday fue el segundo sencillo de los Sugarcubes correspondiente a su primer álbum: "Life's Too Good". Este sencillo fue lanzado en octubre de 1987 a través de One Little Indian.
Con la canción “Birthday” los Sugarcubes se dieron a conocer en todo el mundo teniendo especial repercusión la voz de Björk por la que la crítica ubicaron a la banda en lo alto de las listas británicas como en "Melody Maker".




</doc>
<doc id="28028" url="https://es.wikipedia.org/wiki?curid=28028" title="Regina (canción)">
Regina (canción)

Regina fue el primer sencillo de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en julio de 1989 a través de One Little Indian.




</doc>
<doc id="28029" url="https://es.wikipedia.org/wiki?curid=28029" title="Tidal Wave (single)">
Tidal Wave (single)

Tidal Wave fue el segundo single de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en 1989.



</doc>
<doc id="28030" url="https://es.wikipedia.org/wiki?curid=28030" title="Sódóma Reykjavík (álbum)">
Sódóma Reykjavík (álbum)

Sódóma Reykjavík es un álbum lanzado en agosto de 1992 y corresponde a la banda sonora de la película "Sódóma Reykjavík", también conocida como "Remote Control".
Este compilado está integrado por 13 canciones interpretadas por bandas islandesas, dentro de sus participantes más importantes se encuentra la cantante Björk, quien interpretó la canción "Ó Borg Mín Borg" acompañada de KK Band y la canción "Takk", junto a Þórhallur.





</doc>
<doc id="28031" url="https://es.wikipedia.org/wiki?curid=28031" title="Leyes de la óptica">
Leyes de la óptica

Leyes de la óptica: La óptica está dividida en óptica geométrica y óptica ondulatoria.

Óptica geométrica: estudia los fenómenos que se producen cuando un haz de radiación luminosa incide sobre cuerpos transparentes u opacos, o interfiere con otras radiaciones luminosas. El ojo contiene partículas donde se puede ver que la pantalla refleja Cavidades luminosas Su teoría, que es de origen geométrico, presupone que la luz se propaga en línea recta en un medio homogéneo.

Óptica ondulatoria: se ocupa de los fenómenos de difracción, interferencia y polarización, que pueden explicarse admitiendo la naturaleza ondulatoria de la luz. Supone que la luz se propaga según ondas transversales. Los rayos luminosos son las trayectorias perpendiculares a la superficie de la onda.

Cociente entre la velocidad de la luz en el vacío y la velocidad de la luz en el medio.
Éste índice siempre será mayor que 1 ya que la velocidad de la luz en el vacío es la máxima que puede tener la luz.
En los medios homogéneos este índice es constante

Cuando un rayo luminoso que viaja por un medio incide en una superficie que lo separa de otro medio con distintos índices de refracción, ocurren éstos dos fenómenos. Los rayos que pasan al otro medio se dicen que han sufrido una Refracción y se les denomina rayos refractados. Y los rayos que no cambian de medio, podríamos decir que "rebotan", han sufrido una Reflexión y se les denomina rayos reflejados.

La onda reflejada (y también la refractada) está formada por la envolvente de las ondas elementales producidas al mismo tiempo en puntos distintos de la superficie. El rayo reflejado es perpendicular a la onda reflejada, como el rayo incidente respecto a la onda incidente.

El rayo incidente se divide en dos partes, de manera que satisface las condiciones para las cuales el recorrido entre dos puntos a través de la superficie de separación, se realiza en un tiempo mínimo.

Este fenómeno se da cuando el rayo de luz no es refractado. Si el rayo proviene de un medio con un índice de refracción mayor n, incide sobre una superficie con índice de refracción menor, n, se refleja totalmente:

Donde α es el ángulo de incidencia que recibe el nombre de ángulo límite o crítico.

La birrefringencia, también conocida como doble refracción, se observa cuando una radiación luminosa incide sobre un medio no isótropo, la onda se descompone en dos distintas que se propagan en diferentes direcciones.
La primera sigue las leyes normales de la refracción y se llama "rayo ordinario"; la otra tiene una velocidad y un índice de refracción variables y se llama "rayo extraordinario". Ambas ondas están polarizadas perpendicularmente.

Este efecto se puede observar en la calcita o espato de Islandia.


</doc>
<doc id="28032" url="https://es.wikipedia.org/wiki?curid=28032" title="12.11 (canción)">
12.11 (canción)

12.11 fue el tercer single de un total de 6 correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes en la que se encontraba la cantante y compositora Björk. El mismo fue lanzado en 1989.

Este lanzamiento consistía de una caja formada por 11 discos de 12 pulgadas.

</div>

Véase también:


</doc>
<doc id="28033" url="https://es.wikipedia.org/wiki?curid=28033" title="7.8">
7.8

7.8 fue el cuarto single de un total de seis correspondiente al álbum "Here Today, Tomorrow, Next Week!" de la banda islandesa The Sugarcubes,de la que formaba parte la cantante y compositora Björk. El mismo fue lanzado en noviembre de 1989.

"7.8" estaba compuesto de 8 discos de 7 pulgadas.



</doc>
<doc id="28034" url="https://es.wikipedia.org/wiki?curid=28034" title="Altruismo">
Altruismo

El altruismo (del francés antiguo "altrui", «de los otros») se puede entender como:

De acuerdo a la Real Academia Española, el altruismo proviene del francés "altruisme" y designa la «diligencia en procurar el bien ajeno aún a costa del propio». 

El término altruismo se refiere a la conducta humana y es definido como la preocupación o atención desinteresada por el otro o los otros, al contrario del egoísmo. Suelen existir diferentes puntos de vista sobre el significado y alcance del altruismo.

Auguste Comte acuñó la palabra "altruisme" en 1851 y ésta fue adoptada luego por el castellano. Muchos consideran su sistema ético algo extremo, en el que los únicos actos moralmente correctos son aquellos que intentan promover la felicidad de otros. Esto llevó al desarrollo de la acepción de las personas.

Es aquella conducta que beneficia a otros, que es voluntaria y cuyo autor no anticipa beneficios externos.
Aunque la finalidad propia del altruismo puede presentar varias dificultades. El motivo de esto se debe a que los agentes morales presentamos toda una serie de prejuicios cognitivos que hacen las labores altruistas y activistas más dificultosas. Algunos de estos prejuicios se reflejan en una parcialidad que lleva a dar prioridad a algunos individuos sobre otros. Esto provoca que asignemos menos importancia a ciertas causas que en realidad son más significativas que otras consideradas como menos relevantes. Algunos de estos prejuicios pueden ser las actitudes sexistas, racistas, xenofobia, chovinistas entre otras. Además las tendencias egoístas llevan a que nos desentendamos de causas que podrían conseguir un impacto mayor en el mundo. 

Por otra parte, otros prejuicios provocan que adoptemos patrones irracionales en nuestra toma de decisiones. Esto se debe a que muchas de nuestras inclinaciones e intenciones a la hora de actuar han sido seleccionadas a lo largo de la historia natural por razones de carácter evolutivo. Esto se debe a que éstas presentaron ventajas en la transmisión de nuestro material genético. Pero, en realidad, éstas no presentan ninguna ventaja a la hora de deliberar sobre la forma en la que debemos actuar. Más bien todo lo contrario. Pero es necesario recalcar que estas intenciones no determina necesariamente lo que buscamos y como lo debemos buscar. Pero es cierto que si pueden modifican nuestras inclinaciones y condicionan nuestra forma de actuar en muchos casos. A lo largo de la historia evolutiva, las capacidades y disposiciones que se acabaron estableciendo no son las que estimulan la realización de ciertas funciones de la mejor manera, sino las que hicieron que el material genético se transmitiera de forma eficiente. Esto provoca que cuando intentemos formar parte de una causa de forma activa no utilicemos nuestros recursos de la forma mejor forma por culpa de los distintos prejuicios o sesgos cognitivos que tenemos por causas evolutivas. Algunos ejemplos de estos sesgos cognitivos:

-Una incompetencia a la hora de comparar correctamente distintas magnitudes cuando estas son muy grandes.

-Confundimos aquello que deseamos que suceda con aquello que es previsible que suceda.

-Creemos que nuestras propias experiencias representan adecuadamente el conjunto de lo que ocurre.

-Nos cuesta cambiar nuestra forma de ver las cosas incluso cuando se nos presentan evidencias nuevas que deberían cambiar nuestras posiciones o inclinaciones. 

-Tendemos a no incluir en nuestras consideraciones aquellas opciones en las que hay incertidumbre.

Esta solo es una lista reducida. Los prejuicios cognitivos son muy numerosos. Los sesgos cognitivos inducen resultados nefastos cuando se intenta analizar la importancia relativa que puedan tener las distintas causas. Por esta razón presentan dificultades graves a la hora de llevar a cabo nuestra participación en causas de carácter altruista.

El altruismo en etología y, por consiguiente, en la biología evolutiva, es el patrón de comportamiento animal en el cual un individuo pone en riesgo su vida para proteger y beneficiar a otros miembros del grupo. Casi todas estas teorías explican cómo un individuo puede sacrificar incluso su propia supervivencia por proteger la de los demás, aunque siempre añaden el hecho de que entre los miembros de ese grupo ha de hallarse algún miembro que comparta parte de sus mismos genes. Esta sería una manera de asegurar la continuidad de su información genética. Pese a ello, esta teoría resulta insuficiente para explicar las conductas altruistas que se desarrollan hacia individuos no emparentados, es decir, con los que no se comparte información genética.

Para explicar el altruismo no emparentado, se ha postulado que, en estos casos, la conducta altruista se lleva a cabo cuando el individuo espera de alguna forma ser recompensado por el otro o por algún otro miembro del grupo; o que por último algunas de las conductas altruistas pueden ser el resultado de la necesidad del individuo de sentirse aceptado por el grupo o una persona, por sentirse partícipe dentro de él, con lo cual indirectamente también obtiene un beneficio. Esta acepción fue propuesta por científicos que exploraban las razones por las que podría haber evolucionado el comportamiento no egoísta. Se aplica no sólo a las personas (altruismo psicológico), sino también a animales e incluso a plantas.

Existe, sin embargo, una interpretación de la noción de altruismo contraria a la anteriormente expuesta. En su obra "El gen egoísta" (1976), Richard Dawkins acusa a estas tesis de desviarse del darwinismo ortodoxo y propone, a cambio, una concepción que entiende la evolución considerando el bien del individuo (gen), y no el de la especie, como factor capital. Dawkins sostiene que lo que habitualmente se entiende por altruismo, esto es: la conducta de un organismo cuando "se comporta de tal manera que contribuya a aumentar el bienestar de otro ser semejante a expensas de su propio bienestar" se trataría de un "altruismo individual aparente" y, por lo mismo, la conducta contraria sería un egoísmo individual aparente. Así, su tesis fuerte consiste en que existe una ley fundamental denominada "egoísmo de los genes" que explica tanto el altruismo como el egoísmo individual desde el punto de vista genético. En definitiva, Dawkins sostiene que la interpretación ortodoxa de la "selección natural" darwiniana es aquella que la concibe como selección de genes (egoísmo del gen), y no como selección de grupos (altruismo entre individuos).

En el siglo XIX, algunos filósofos como John Stuart Mill defendían que el ser humano no es naturalmente altruista, sino que necesita ser educado para llegar a serlo. Pitirim A. Sorokin reconocía limitaciones en el mismo. Recientemente se han hecho investigaciones que muestran que el altruismo aparece en el ser humano al cumplir los 18 meses, al igual que en el chimpancé; lo que sugiere que los seres humanos tienen una tendencia natural a ayudar a los demás.

Hay una serie de situaciones que nos incitan a los humanos a ayudarnos los unos a los otros y son las siguientes: cuando nos recompensan, cuando estamos de buen humor cuando alguien más ayuda al hacer una atribución de altruismo y cuando las normas dictan ayuda.




</doc>
<doc id="28035" url="https://es.wikipedia.org/wiki?curid=28035" title="Human Behaviour">
Human Behaviour

Human Behaviour fue el primer single de la cantante y compositora islandesa Björk. También es el primer single de "Debut", su primer álbum solista. Contiene una muestra de «Go down dying» de Tom Jobim. La canción refleja la naturaleza y las emociones humanas desde un punto de vista animal. Forma parte de una trilogía de canciones que incluye Isobel y Bachelorette.
También hay editada una versión acústica de Human Behaviour que Bjork grabó para el programa de TVE Planeta Rock el 13 de octubre de 1993. Es parte de una de las versiones single Violent Happy.

En Francia se publica una versión en digipack cuando se alcanzan las 100000 copias vendidas del álbum en el que se incluye un CD que contiene un agradecimiento grabado por la propia Björk a los fans del país galo.

El videoclip de Human Behaviour fue dirigido por el director francés Michel Gondry. El vídeo es algo surrealista: Björk es cazada por un oso en el bosque. Además, vuela a la Luna y planta una bandera de la URSS. Acaba siendo comida por el oso y atrapada en su estómago.

El vídeo recibió 6 nominaciones a los Premios MTV: Mejor Vídeo Femenino, Mejor Vídeo de Artista Revelación, Vídeo Revelación, Mejores Efectos Especiales, Mejor Dirección Artística y Mejor Director, ganando ninguno de ellos. Además fue nominado a los Premios Grammy, perdiendo contra "Steam" de Peter Gabriel.

UK CD 1


UK CD 2


UK Vinilo 12"

"Cara A"
"Cara B"

UK Vinilo 12" Promo (1)

"Cara A"
"Cara B"

UK Vinilo 12" Promo (2)

"Cara A"
"Cara B"

UK Vinilo 10" Promo Edición Limitada

"Cara A"
"Cara B"

EUR CD


FRA CD Promo


FRA Vinilo 12" Promo (1)

"Cara A"
"Cara B"

FRA Vinilo 12" Promo (2)

"Cara A"
"Cara B"

EEUU CD Promo


EEUU Vinilo 12"

"Cara A"
"Cara B"

EEUU Vinilo 12" Promo

"Cara A"
"Cara B"

JPN CD





</doc>
<doc id="28037" url="https://es.wikipedia.org/wiki?curid=28037" title="All is full of love">
All is full of love

All is Full of Love es un single lanzado en junio de 1999 por la cantante y compositora islandesa Björk. Pertenece a "Homogenic", su tercer álbum como solista, o cuarto si se toma en cuenta "Björk".

El videoclip de la canción seguía emitiéndose en el 2011 en la MTV en su bloque de viedobox clásicos, junto a vídeos como "Ava Adore" de The Smashing Pumpkins, "Friday I'm in Love" de The Cure.

En EE. UU. la canción fue un éxito dance de rock alternativo, de hecho alcanzó el puesto nº. 8 en las listas dance de EE. UU.. El sencillo fue el primero en la discografía de Björk en publicarse en el nuevo formato de "DVD single" para mejorar la calidad del vídeo. 

La canción tiene sonidos inspirados por máquinas y está acompañado por instrumentos orquestales y clavicordio tocado por Guy Sigsworth. Fue originalmente lanzada como sencillo dance por Funkstorung con sus remixes a finales del 1998, pero después recibió un sencillo propio con un vídeo hecho para la canción en el verano de 1999.

El videoclip fue dirigido por Chris Cunningham y en él los protagonistas son dos robots que se aman.

"All is Full of Love" recibió una candidatura a los premios Grammy y ganó varios, como "Mejor Video" y "Mejores Efectos Especiales" en los "MTV Video Awards" del año 2000. El video es en sí mismo una muestra de la contradicción existente en "Homogenic", el blanco y el negro y el amor y la máquina (metáforas de la cuerda y la electrónica existentes en el propio disco).

El vídeo fue censurado por algunas cadenas porque se decía que daba una imagen homosexual, al ser los robots más bien femeninos.










Se lanzaron tres versiones de "All is Full of Love".

Nombre: "All is Full of Love"
Fecha de lanzamiento: junio de 1999
Formato: CD

Nombre: "All is Full of Love"
Fecha de lanzamiento: junio de 1999
Formato: DVD




</doc>
<doc id="28038" url="https://es.wikipedia.org/wiki?curid=28038" title="Hunter (canción de Björk)">
Hunter (canción de Björk)

Hunter es un single lanzado en octubre de 1998 por la cantante y compositora islandesa Björk. El mismo corresponde a "Homogenic", su tercer álbum solista.
La canción también apareció en la de la película .

El videoclip fue dirigido por Paul White de Me Company y fue realizado con animación de imágenes en tres dimensiones (3D) a cargo de la compañía de efectos especiales Digital Domain. En vemos a una Björk calva revolviéndose y en algunos momentos transformándose en oso polar. La metamorfosis representa la fusión entre orgánico y tecnológico presente en la canción, y el "cazador" del cual habla la letra.

Se lanzaron tres versiones de "Hunter".

Nombre: "Hunter".
Fecha de lanzamiento: octubre de 1998.
Formato: CD.

Nombre: "Hunter".
Fecha de lanzamiento: octubre de 1998.
Formato: CD.




</doc>
<doc id="28039" url="https://es.wikipedia.org/wiki?curid=28039" title="Pagan Poetry">
Pagan Poetry

«Pagan Poetry» (en español: «Poesía pagana») es una canción de la cantante islandesa Björk, tomado de su álbum "Vespertine". La canción alcanzó el número 38 en los gráficos musicales de Reino Unido y número 12 en Canadá. Fue escrita y producida por Björk con una producción adicional por Marius De Vries y mezclado por Mark "Spike" Stent. El video musical de la canción fue uno de los más controvertidos en toda la carrera de la cantante.

La canción «Pagan Poetry» fue escrita y producida por Björk.

Hemos discutido cómo hacer algo con la imagen en movimiento que era un espejo de lo que estaba pasando musicalmente. . . . Tenía que tener una mirada diferente de las imágenes de vídeo y de las imágenes de vídeo alteradas digitalmente. Sabía que tenía que mirar como exquisitos como sea posible. Es quitando el artificio y los efectos digitales, en la imagen cruda de Björk.

El video musical fue dirigido por Nick Knight quien ya había fotografiado a Björk para la portada del álbum "Homogenic" de (1997). Knight explica que el video narra sobre «una mujer preparándose para el matrimonio y para su amante». Fue considerado uno de los vídeos más controvertidos de Björk. El video contiene tres escenas: una toma de video de perforaciones, un vídeo privado real grabado por Björk y una escena con el vestido blanco diseñado por Alexander McQueen.

La escenas de los pírsines y la escena del vestido se hicieron en un día, en junio de 2001, en el estudio de fotografía de Nick Knight al noroeste de Londres. Las primeras escenas pertenecen a efectos visuales de post-producción por Peter Marin. Marin editó principalmente las escenas privadas y de perforaciones con un efecto abstracto, lineal y casi acuarelístico. Para las perforaciones se utilizaron dobles, un equipo de pírsines y una enfermera. Björk solo perforó su oreja con los hilos de perlas. La escena con el vestido fueron grabadas directamente, sin ninguna edición y cortes.

El video comienza con una imagen desenfocada de un hilo, por donde caen algunas perlas. Seguido a éste, un líquido blanco salta a la toma, haciendo alusión a un orgasmo. A continuación, se muestra escenas explícitas de sexo no simulado (como felación y penetración vaginal) veladas por un efecto rotoscópico y animaciones en 3D. A lo largo de estas escenas, aparecen perforaciones reales de alto riesgo. Estas escenas, junto a las escenas sexuales se entrecortan y son mostradas con los efectos mencionados. Luego, Björk aparece con el vestido blanco diseñado por Alexander McQueen, que cubre de cintura a abajo del cuerpo. En toda la parte superior, principalmente en el pecho, varias perlas se encajan a través de su piel. Ella se agita emocionalmente al ritmo de la música, jalándose algunos hilos con perlas. Finalmente, aparece la "espalda" de Björk perforada por un corsé de pírsines.

El video musical fue considerado en la lista de MTV como uno de los videos más controvertidos, al poseer imágenes de sexo explícito, sexo oral y perforaciones de alto riesgo. Fue censurado en Estados Unidos y Latinoamérica. Fue finalmente pasado a MTV2 para ser mostrado sin ninguna edición.

El sencillo fue lanzado en CD dobles y un DVD. Los cedés incluyen un remix por Mathew Herbert, una nueva versión de la canción «Aurora» del álbum Vespertine, y unos canciones de lado B «Batabid» y «Domestica». En un comienzo, "Domestika" era el título de trabajo para "Vespertine", y la canción era incluida como «Lost Keys», pero más tarde se cambió.

"Pagan Poetry" ha sido muy elogiado por la crítica, citando como un punto culminante del álbum. Allmusic, dijo de "Pagan Poetry", que "comparte una serenidad amplia con más los más silenciosos momentos del álbum" e incluyó esta canción como una selección de pista, la revista Rolling Stone dijo: "Pagan Poetry", despliega los cielos de Zeena Parkins con el arpa y un buque de cajas de música con un toque de casa de té asiático. Blender dijo: "Pagan Poetry" suena como el preludio de un interludio sexual particularmente exótico". En marzo de 2006, en el número 77 de la edición española de Rolling Stone, "Pagan Poetry" fue clasificado con el número 38 por los profesionales de la música española y los expertos en una lista de las mejores canciones del siglo 21. Slant Magazine dijo del álbum "Vespertine delicadamente deja rastros del ciclo de dicha relación" y llamó a la canción "la pérdida de la identidad personal y la completa trampa posesiva" Pitchfork Media colocó la canción en el número 227 en su lista de "El Top 500 canciones de la década de 2000".







</doc>
<doc id="28040" url="https://es.wikipedia.org/wiki?curid=28040" title="The Plainsman">
The Plainsman

The Plainsman, conocido en idioma castellano como El llanero en la Argentina y como Bufallo Bill en España, es una película protagonizada por Gary Cooper.

Buffalo Bill es un relato sobre tres personajes reales del Oeste americano, Wild Bill Hickok (Gary Cooper), Calamity Jane (Jean Arthur) y Buffalo Bill (James Ellison).

La película se llamaba originalmente The Plainsman y estaba dirigida por Cecil B. DeMille, a pesar de que la participación del personaje de Buffalo Bill es destacada es secundaria pues la trama principal está llevada por la historia de amor entre Wild Bill Hickok y Calamity Jane. 


</doc>
<doc id="28043" url="https://es.wikipedia.org/wiki?curid=28043" title="Bat 21">
Bat 21

Bat 21 es una película basada en el libro del mismo título de William C. Anderson.

Durante la Guerra de Vietnam, un avión EB-66 de observación es derribado. El único superviviente es el navegante aéreo Teniente Coronel Hambleton (Gene Hackman), que además es un experto en misiles. Ya que Hambleton es un militar de gran interés para el ejército estadounidense, se pone en marcha una misión de rescate, a pesar de ser ésta muy peligrosa. Hambleton se comunica con el equipo de rescate mediante una radio portátil. El problema es que el Vietcong le está escuchando, y Hambleton lo sabe. El seguimiento de la operación de rescate es asignado a un controlador aéreo avanzado (Danny Glover). Puesto que el rescate en la zona del derribo es imposible, el propio Teniente Coronel Hambleton idea un plan para llegar a otra zona de rescate más segura. Idea de igual forma un sistema basado en la forma de diferentes hoyos de campos de golf que conoce, con el cual transmite sus movimientos al equipo de rescate sin que los enemigos, que escuchan sus transmisiones, puedan descifrarlo (en teoría al ser el golf un deporte desconocido para ellos). 

La película estaba basada en hechos reales, el navegante y experto en contramedidas electrónicas (y con el nombre en tierra de Bat 21 por cuestiones de inteligencia y para evitar el rastreo enemigo o el uso del derribado con otros fines, se coloca un alias que es éste que da nombre a la película) es tratado de rescatar, pero la misión resulta muy difícil debido a que el Vietcong está lanzando la mayor ofensiva terrestre de la guerra, durante las celebraciones del Tet (podría hacerse una analogía con la Navidad cristiana), momento en el cual, los norteamericanos no iban a atacar como respeto a la fe local y para continuar la simpatía de Vietnam del Sur que mantenían esas creencias.


</doc>
<doc id="28054" url="https://es.wikipedia.org/wiki?curid=28054" title="Pat Garrett y Billy the Kid">
Pat Garrett y Billy the Kid

Pat Garrett y Billy The Kid es un western de 1973 procedente de EE. UU., dirigido por Sam Peckinpah y protagonizado por los conocidos actores James Coburn y Kris Kristofferson.

La película también cuenta con Bob Dylan para la música (aparte de actuar), lo cual dio lugar a la banda sonora del mismo nombre.

Pat Garrett (James Coburn), que había sido compañero del bandido Billy the Kid (Kris Kristofferson), se ha pasado al otro lado de la ley y es ahora sheriff del condado de Lincoln. Defiende los intereses del Gobernador Lew Wallace (Jason Robards) y de los ganaderos del territorio en el que actúa su antiguo compañero. 

Pocos días después de ser nombrado sheriff, Garrett consigue frustrar un intento de robo de Billy y lo lleva a prisión. Sin embargo, éste consigue escapar matando a cuatro hombres. Garrett lo persigue sin descanso durante semanas. Sin embargo, los ganaderos son tan poderosos que algunas cosas escapan de su poder.

El trabajo fuera de la ley (pero a su vez dentro de ella) del sheriff Pat Garrett, consiste básicamenete en perseguir y conseguir información de viejos amigos y conocidos, y deshacerse así del que alguna vez fue compañero suyo de fechorías tiempo atrás y termino muerto gracias a un sherif del condado.




</doc>
<doc id="28058" url="https://es.wikipedia.org/wiki?curid=28058" title="Meiji">
Meiji

Meiji es un término que puede referirse a:

</doc>
<doc id="28079" url="https://es.wikipedia.org/wiki?curid=28079" title="Sabrina (película de 1954)">
Sabrina (película de 1954)

Sabrina ("Sabrina") es una película estadounidense de 1954. Es adaptación de la obra de teatro de 1953 "Sabrina Fair" (subtitulada "A Woman of the World"), escrita por Samuel A. Taylor (1912 - 2000).

La película fue dirigida por Billy Wilder, y contó con Audrey Hepburn, Humphrey Bogart y William Holden como actores principales. Fue candidata a seis Oscar, entre ellos al mejor director, a la mejor actriz principal (Hepburn) y al mejor guion adaptado, pero finalmente solo ganaría el de mejor vestuario.

Sabrina Fairchild (Audrey Hepburn) es la hija de Thomas, el chófer de la familia Larrabee, y desde niña está locamente enamorada de David Larrabee (William Holden). David es un vividor y mujeriego, divorciado ya tres veces, que sin embargo nunca ha reparado en ella, lo que provoca que, desconsolada, decida suicidarse envenenándose con monóxido de carbono, encerrándose en el garaje y poniendo en marcha a la vez los ocho coches de la familia. Lo impide Linus (Humphrey Bogart), el hermano mayor de David, un hombre dedicado a la familia y a sus empresas.

Avergonzada por la situación, Sabrina se marcha a París para estudiar en una escuela de cocina. Cuando dos años después vuelve a la residencia de los Larrabee, se ha convertido en una mujer sofisticada y atractiva que llama la atención de David cuando casualmente la encuentra en la estación, pese a no reconocerla al principio como la hija del chófer. Esa misma tarde, la invita a una recepción en la mansión. Linus, conociendo el carácter de su hermano, teme que el compromiso de David con Elizabeth Tyson (Martha Hyer) acordado por el patriarca de los Larrabee peligre, y con él la fusión entre Larrabee Industries y la empresa del padre de Elizabeth. Linus discute con David sobre su responsabilidad ante la familia, pero éste no quiere saber nada más allá de su propio interés, así que Linus se decide por una maniobra alternativa: intentará seducir a Sabrina, de manera que se enamore de él y olvide a su hermano, y luego la mandará de nuevo a París para asegurar el matrimonio de David y el acuerdo empresarial.

Ayudado por un accidente que sufre David, Linus y Sabrina comienzan a pasar más tiempo juntos, y ella se da cuenta de que él no sólo es un hombre de negocios sin tiempo para los sentimientos. Sin embargo, Linus acaba también enamorado de Sabrina, y llevado por los remordimientos le cuenta su plan dirigido ante todo por los intereses de las empresas familiares. Sabrina, profundamente decepcionada, se muestra de acuerdo en dejar la mansión Larrabee a la mañana siguiente. Linus habla con David para ponerle al corriente de la situación; David comprende que Linus está enamorado de Sabrina pero siempre va a anteponer las necesidades de la familia a su propia felicidad.

Al día siguiente está convocada la reunión del consejo de administración de la empresa para formalizar la firma de la fusión. Cuando David no se presenta a la hora indicada, Linus asume que ha escapado a París con Sabrina, pero en el último momento el hermano menor aparece, disculpándose por el retraso, y confirma su decisión de casarse con Elizabeth Tyson y llevar adelante la fusión de las empresas. Liberado de su compromiso con el negocio, Linus acepta sus sentimientos hacia Sabrina y corre para reunirse con ella en el barco para zarpar juntos hacia su nueva vida en París.

Sabrina supone el retorno de Wilder a la comedia romántica sofisticada, al estilo de Ernst Lubitsch y de la primera época de Wilder en la Paramount. Wilder quiso subrayar un aspecto poco desarrollado en la obra de Samuel Taylor: la idea de que Bogart se utiliza a sí mismo para que la chica desista de su hermano y éste pueda casarse con la hija de un magnate azucarero y garantizar así una lucrativa fusión para la familia.

Wilder se centra en el personaje de Bogart y lo convierte en una Ninotchka masculina que da la espalda a la vida y cuya sombría actitud es el fruto de su dedicación al trabajo. Muchos de los memorables toques visuales ponen de relieve su planteamiento de una vida dedicada a los negocios (por ejemplo, llama a una docena de secretarias de mediana edad para saltar sobre una lámina de plástico y comprobar su resistencia ante un avergonzado William Holden). Los planos desconexos de Bogart paseando por su cavernoso despacho subrayan una vida de éxitos pero solitaria. Cuando dimite para seguir a Hepburn en su viaje por Europa, Wilder le sitúa corriendo por una larga perspectiva de puertas que se abren, el final de su vacua vida de ejecutivo.

Bogart se presta a engañar a Hepburn sustituyendo a Holden por motivos puramente egoístas, pensando en sus negocios, pero una vez la conoce, se siente tan culpable como Charles Boyer en "Si no amaneciera", a la vez que admite necesitar amor, como Greta Garbo en "Ninotchka". Wilder y Lehman revisten de gran refinamiento dichas revelaciones.

Durante la película las relaciones entre Bogart y el resto del reparto fueron bastante tensas. Bogart aceptó ese papel porque su agente le convenció de que debía participar en una comedia, para mitigar la imagen de duro que tenía.En cambio, la relación entre Hepburn y Holden fue excelente durante todo el rodaje. 

La película tuvo un "remake" en 1995, dirigido por Sydney Pollack, con Julia Ormond como Sabrina, Greg Kinnear como David y Harrison Ford como Linus.

Escenas de "Sabrina"


</doc>
<doc id="28089" url="https://es.wikipedia.org/wiki?curid=28089" title="Meiji Tennō">
Meiji Tennō

Mutsuhito conocido por su nombre póstumo como (Kioto, 3 de noviembre de 1852 - Tokio, 30 de julio de 1912) fue hijo de Kōmei Tennō y la consorte Nakayama Yoshiko, fue el emperador de Japón número 122º, de acuerdo con el orden tradicional de sucesión imperial Japonés, reinando desde el 3 de febrero de 1867, hasta su muerte.
Como todos sus predecesores, desde su muerte ha sido llamado por su nombre póstumo. Desde su muerte, la tradición de dar al emperador el nombre de la era conjuntamente con su reinado fue establecida. Habiendo gobernado este en el periodo Meiji, ahora es conocido como Emperador Meiji. Su nombre personal era Mutsuhito. Fuera de Japón, algunas veces se refieren a él, como Emperador Mutsuhito, sin embargo, en Japón, los emperadores sólo son llamados por su nombre póstumo. Llamar a un emperador por su nombre personal podría ser considerado un exceso de confianza e incluso un acto despectivo.

Cuando nació a finales de 1852 Japón era un país aislado, preindustrial y feudal, dominado por el shogunato Tokugawa y los "daimyō", que controlaban los más de 250 dominios descentralizados del país. Cuando fallece, en 1912, Japón había experimentado una revolución política, industrial y social que trajo como resultado la transformación del país en una potencia mundial.

Meiji Tennō fue el líder simbólico de la restauración Meiji en donde el shogunato Tokugawa fue abolido por fuerzas imperiales en una breve convulsión interna conocida como la guerra Boshin. Tras esto el Emperador Meiji proclamó la conversión del Japón a un gobierno democrático de corte occidental. Sin embargo, el Parlamento Japonés carecía de poderes reales y tampoco los tenía el Emperador Meiji, ya que el poder pasó entonces de mano de los Tokugawa a una nueva nobleza "genrō" formada por los daimyō y samuráis que habían ayudado a la restauración. Esta nueva oligarquía ubicó a sus hombres en las esferas políticas y militares del nuevo gobierno.
La restauración y modernización consecuente convirtió al Japón en una potencia industrial ubicándola por encima de otras naciones en el Pacífico. Si bien la función del Emperador en la restauración es discutida, su influencia pudo haber sido importante en las guerras en que Japón se vio involucrada a comienzos del Siglo XX. Entre las medidas que tomó se destacan, además de las ya mencionadas, el traslado de la capital de Kioto a Tokio, la implantación de un nuevo sistema de estudios (1872), la institución del Senado, "Genroin" (1875), la inauguración de la Asamblea Nacional (1890) y la anexión de Corea (1910). El Emperador Meiji demostró una gran longevidad en el trono manteniéndose en el poder por más de 40 años, tras la cual, se consolida el desarrollo económico y político de Japón, alzándose como potencia dominante en Asia.

En la película "El último samurái" al emperador se le representa como un hombre débil y fácil de manejar, sin hacer alusión al riesgo de golpe de Estado, teniendo la presión de los shogunatos rebeldes que veían intereses económicos con Estados Unidos. La determinación del Emperador solo se muestra al final cuando hace respetar sus ideas rompiendo el tratado con los estadounidenses, después de consolidar su poder tras la batalla.



</doc>
<doc id="28094" url="https://es.wikipedia.org/wiki?curid=28094" title="Verdún (desambiguación)">
Verdún (desambiguación)

Verdún puede referirse a:

</doc>
<doc id="28104" url="https://es.wikipedia.org/wiki?curid=28104" title="Tratado de Versalles (desambiguación)">
Tratado de Versalles (desambiguación)

Tratado de Versalles puede referirse a alguno de los siguientes tratados firmados en el Palacio de Versalles de Francia:

</doc>
<doc id="28105" url="https://es.wikipedia.org/wiki?curid=28105" title="Presidente de los Estados Unidos">
Presidente de los Estados Unidos

El presidente de los Estados Unidos (; acrónimo: POTUS) es el jefe de Estado y de Gobierno de los Estados Unidos. Es el más alto cargo político del país por influencia y reconocimiento. El presidente lidera el poder ejecutivo del Gobierno federal.

Entre otros poderes y responsabilidades, el Artículo II de la Constitución de los Estados Unidos encarga al presidente la «fiel ejecución» de la ley federal, hace del presidente el comandante en jefe de las Fuerzas Armadas, lo autoriza a nombrar oficiales ejecutivos y judiciales con el consejo y consentimiento del Senado, lo sitúa al frente de la política exterior de los Estados Unidos, y permite al presidente conceder indultos o moratorias.

El presidente es elegido mediante sufragio indirecto por un colegio electoral (o por la Cámara de Representantes si el colegio electoral no concede la mayoría de votos a ningún candidato) para un mandato de cuatro años. Desde la ratificación de la Vigesimosegunda Enmienda en 1951, ninguna persona puede ser elegida para el cargo de presidente más de dos veces. En caso de muerte, destitución, dimisión o renuncia de un presidente, el vicepresidente asume la presidencia.

Hasta la fecha, ha habido un total de personas que han asumido el cargo y cuarenta y cinco presidencias. Esto ocurre porque el presidente Grover Cleveland sirvió en dos mandatos no consecutivos y se le cuenta por orden cronológico tanto como el vigesimosegundo como el vigesimocuarto presidente. De las personas elegidas para el cargo, cuatro murieron durante su mandato por causas naturales, uno dimitió y cuatro fueron asesinados. El primer presidente fue George Washington, que fue investido en 1789 después de un voto unánime del colegio electoral. William Henry Harrison fue el que menos tiempo permaneció en el cargo, con tan solo 32 días, y Franklin D. Roosevelt, con sus 12 años en el puesto, fue el que permaneció por más tiempo y el único presidente que sirvió por más de dos mandatos (ganó cuatro veces las elecciones presidenciales).

El actual presidente es el republicano Donald Trump, que tomó posesión el 20 de enero de 2017.

Desde principios del siglo XX, el papel hegemónico de los Estados Unidos en el escenario político y económico internacional ha llevado al presidente de este país a ser una figura conocida a nivel global y, debido a la condición del país como única superpotencia, en 2009 la revista "Forbes" calificaba a su titular como «la persona más poderosa del mundo».

El Tratado de París (1783) puso fin a la Guerra de Independencia y reconoció la constitución de las Trece Colonias como los Estados Unidos de América, pero con una estructura gubernamental inestable. El Segundo Congreso Continental había redactado los Artículos de la Confederación en 1777, describiendo una Confederación permanente, pero concediendo al Congreso de la Confederación (la única institución federal) poco poder para financiarse o para asegurar el cumplimiento de sus resoluciones. En parte, esto reflejaba la visión antimonárquica del período revolucionario y el nuevo sistema estadounidense fue explícitamente diseñado para prevenir el ascenso de un tirano estadounidense en sustitución del monarca británico.

Sin embargo, durante la depresión económica debida al colapso del dólar continental tras la Revolución estadounidense, la viabilidad del gobierno estadounidense se vio amenazada por el malestar político en varios estados, el empeño de los deudores en utilizar el gobierno popular para eliminar sus deudas y la aparente incapacidad del Congreso Continental de hacer frente a las obligaciones públicas asumidas durante la guerra. El Congreso también parecía incapaz de convertirse en un foro para la cooperación productiva entre los estados, que animaban el comercio y el desarrollo económico. En respuesta a esta problemática se convocó una Convención constitucional, inicialmente para reformar los Artículos de la Confederación, pero que posteriormente comenzó el diseño de un nuevo sistema de gobierno que incluiría un mayor poder ejecutivo aunque reteniendo un esencial control y equilibrio con la idea de restringir cualquier tendencia imperial en la presidencia.

Las personas que presidieron el Congreso Continental durante el período Revolucionario, y conforme a los Artículos de la Confederación, ostentaban el título de «presidente de los Estados Unidos en el Congreso Reunido» y a menudo se abreviaba como «presidente de los Estados Unidos». El cargo tenía poco poder ejecutivo claramente definido. Con la ratificación de la Constitución en 1787, se creó un poder ejecutivo separado, encabezado por el presidente de los Estados Unidos.

La autoridad ejecutiva del presidente conforme a la Constitución, moderada por el control de los poderes legislativo y judicial del gobierno federal, fue diseñada para solucionar los problemas políticos afrontados por la recién creada nación y para intentar superar futuros desafíos, siempre previniendo la subida al poder de un autócrata en una nación cautelosa frente a las autoridades monárquicas.

La Constitución de los Estados Unidos y sus posteriores Enmiendas fija los poderes y deberes del presidente:

El primer poder conferido al presidente por la Constitución estadounidense es el poder legislativo del veto presidencial. La llamada «Cláusula de Presentación» ("Presentment Clause") requiere que cualquier proyecto de ley aprobado por el Congreso sea presentado al presidente antes de que pueda convertirse en ley. Una vez que norma legal ha sido presentada, el presidente tiene tres opciones:


En 1996, el Congreso intentó cambiar el poder de veto presidencial con la "Line Item Veto Act". La legislación autorizó al presidente a firmar cualquier propuesta de ley de gastos en ley al mismo tiempo que eliminaba ciertos artículos de gastos dentro de la propuesta, en particular cualquier nuevo gasto, cualquier cantidad de gastos discrecionales, o cualquier nuevo beneficio fiscal limitado. Si el presidente eliminaba un artículo, el Congreso podría aprobar ese artículo en particular otra vez. Si el presidente vetara entonces la nueva legislación, el Congreso podría anular el veto con el procedimiento ordinario, o sea, con el voto de las dos terceras partes en ambas Cámaras. En el caso "Clinton contra la Ciudad de Nueva York" (1998), la Corte Suprema estadounidense resolvió que esta modificación del poder de veto presidencial era inconstitucional.

Quizás el más importante de todos los poderes presidenciales es su posición al frente de las Fuerzas Armadas de los Estados Unidos como su Comandante en Jefe. Mientras que el poder de declarar la guerra corresponde constitucionalmente al Congreso, el presidente comanda y dirige a sus ejércitos y es responsable de planear la estrategia militar. Los padres de la Constitución fueron cautos limitando los poderes presidenciales en cuanto a los militares; Alexander Hamilton lo explica en su "Ensayo Federalista nº 69":

El Congreso, de acuerdo con la Resolución de Poderes de Guerra ("War Powers Resolution") de 1973, debe autorizar cualquier despliegue de tropas de más de 60 días de duración a menos que el propio Congreso haya declarado la guerra. Además, el Congreso ejerce cierta limitación al poder militar presidencial por su control y regulación de los gastos militares.

Junto con las fuerzas armadas, el presidente también está al frente de la política exterior. A través del Departamento de Estado y el Departamento de Defensa, el presidente es responsable de la protección de los estadounidenses en el extranjero y de los ciudadanos extranjeros en los Estados Unidos. El presidente decide si hay que reconocer nuevas naciones y nuevos gobiernos y negocia tratados con otras naciones, que se hacen vigentes en los Estados Unidos cuando son aprobados por las dos terceras partes del Senado. El presidente también puede negociar «acuerdos ejecutivos» con poderes extranjeros que no están sujetos a la confirmación de Senado.

El presidente es el director ejecutivo de los Estados Unidos, y está a la cabeza del poder ejecutivo del gobierno, cuya responsabilidad es «cuidar que las leyes sean fielmente ejecutadas». Para llevar a cabo este deber, se le otorga el control de los cuatro millones de empleados del poder ejecutivo federal.

Al presidente le corresponde el nombramiento de varios miembros del poder ejecutivo. Embajadores, miembros del Gabinete y otros oficiales federales, son todos designados por el presidente con el «consejo y consentimiento» de una mayoría del Senado. Los nombramientos realizados mientras el Senado no está en periodo de sesiones son temporales y expiran al final de la siguiente sesión del Senado. El presidente puede proponer unos 6000 nombramientos mientras ejerce su mandato.

El poder del presidente para cesar a funcionarios ejecutivos ha sido durante mucho tiempo objeto de debate. Generalmente, el presidente puede cesar a los funcionarios ejecutivos a su discreción. Sin embargo, el Congreso puede reducir por decreto la autoridad presidencial para cesar a comisionados de agencias reguladoras independientes y a ciertos oficiales ejecutivos inferiores.

El presidente también tiene la facultad de proponer jueces federales, incluidos miembros de la Corte Suprema de los Estados Unidos y de las Cortes de Apelaciones. Sin embargo, estos nombramientos requieren la confirmación del Senado y esto puede suponer un escollo importante ante la posibilidad de que un presidente quisiera formar una judicatura federal con una postura ideológica particular. El presidente puede designar jueces para los tribunales de distrito de los Estados Unidos, pero a menudo deferirá a la cortesía senatorial estos nombramientos. También puede conceder perdones e indultos, como se hace a menudo justo antes del final de un mandato presidencial.

El llamado «privilegio ejecutivo» otorga al presidente la capacidad de retener información al público, al Congreso y a los tribunales cuando el asunto atañe a la seguridad nacional. George Washington fue el primero en reclamar el privilegio cuando la Cámara de Representantes solicitó ciertos documentos sobre la negociación del Tratado Jay con el Reino de Gran Bretaña. Aunque el privilegio no figura en la Constitución ni en ninguna otra ley, la acción de Washington creó el precedente para el privilegio. Cuando Richard Nixon trató de usarlo como razón para no aportar unas pruebas ante una citación del Congreso durante el escándalo Watergate, la Corte Suprema sentenció en el caso "Estados Unidos contra Nixon", , que el privilegio ejecutivo no era de aplicación en casos donde un presidente intentaba evitar un procesamiento criminal. Cuando el presidente Bill Clinton intentó usar el privilegio ejecutivo en cuanto al escándalo Lewinsky, la Corte Suprema sentenció en el caso "Clinton contra Jones", , que el privilegio tampoco podía invocarse en los casos de pleitos civiles. Estos casos establecieron el precedente legal de que el privilegio ejecutivo es válido, pero el grado exacto del privilegio todavía está pendiente de una definición clara.

Aunque el presidente de los Estados Unidos no tiene capacidad para introducir legislación directamente, puede desempeñar un papel importante en su conformación, sobre todo si el partido político del presidente tiene mayoría en una o ambas Cámaras del Congreso. Los miembros del poder ejecutivo no pueden ocupar simultáneamente su puesto y un escaño en el Congreso, pero es habitual que redacten la legislación y que un Senador o Representante la presente por ellos. El presidente puede influir de una forma importante en el poder legislativo a través del informe anual, escrito u oral, que constitucionalmente debe presentar al Congreso, y que en la actualidad se denomina Discurso del Estado de la Unión. Este discurso a menudo perfila la oferta legislativa para el año próximo.

De acuerdo con el , el presidente puede convocar a una o a ambas Cámaras del Congreso para una sesión extraordinaria. Si ambas Cámaras no llegan a un acuerdo sobre la fecha de celebración de la convocatoria, el presidente puede designar una fecha para la reunión del Congreso. Esta facultad del presidente de convocar de forma extraordinaria el Congreso sólo se ejerció en 27 ocasiones en toda la historia de los Estados Unidos. La última fue ejercida en 1948 por Harry Truman.

El de la Constitución marca los requisitos necesarios para tener la consideración de elegible como presidente. Un candidato presidencial debe:


Con respecto al tema de la ciudadanía estadounidense, cumple aclarar que el Artículo II de la Constitución dice textualmente que es requisito ser «"a natural born Citizen, or a Citizen of the United States, at the time of the Adoption of this Constitution"», o sea, un ciudadano de nacimiento de los Estados Unidos. La Decimocuarta Enmienda, adoptada en 1868, define en su Sección 1, Cláusula 1 que «"All persons born or naturalized in the United States, and subject to the jurisdiction thereof, are Citizens of the United States and of the State wherein they reside."», esto es, que cualquier persona nacida o naturalizada en los Estados Unidos es legalmente ciudadano estadounidense, sin embargo, sin el requisito de nacimiento en suelo estadounidense, no serían elegibles. Este es un tema ampliamente debatido en el país, y para algunos columnistas como John W. Dean, antiguo consejero presidencial, es una cláusula constitucional obsoleta que contradice el espíritu del llamado «sueño americano» y entra en conflicto con el propio «Estatuto de Libertad» estadounidense, que da la bienvenida a los extranjeros, pero que les impide acceder al máximo puesto de responsabilidad del país.

Conforme a la Vigesimosegunda Enmienda, nadie puede ser elegido presidente más de dos veces. La Vigesimosegunda Enmienda también especifica que alguien que sirve más de dos años como presidente o presidente interino, de un mandato para el cual otro fue elegido como presidente, sólo puede optar a la presidencia una vez. Los estudiosos de la Constitución discrepan sobre si una persona que ya no es elegible para la presidencia podría ser elegida como vicepresidente, de acuerdo con los requisitos establecidos en la Decimosegunda Enmienda.

La Constitución contempla la descalificación de algunas personas para la presidencia. Bajo el , el Senado tiene la opción, a su criterio, de descalificar a altos cargos condenados tras un "impeachment" para ocupar otros cargos federales, incluida la presidencia. También, la Sección 3 de la Decimocuarta Enmienda prohíbe a cualquier persona que, habiendo prestado juramento para apoyar la Constitución, y que posteriormente se rebelara contra los Estados Unidos, pueda ser elegida para servir como presidente, a menos que cada Cámara del Congreso haya retirado la descalificación por un voto favorable de dos terceras partes de sus miembros.

La campaña presidencial contemporánea comienza antes de las elecciones primarias, cuando los dos principales partidos políticos estadounidenses hacen una selección de candidatos antes de sus convenciones nacionales de nominación, donde el elegido se convierte en el candidato del partido para la presidencia. Por lo general, el candidato presidencial del partido elige a un candidato a la vicepresidencia y esta opción es confirmada por la convención.

Los candidatos participan en debates televisados a escala nacional, que generalmente están restringidos a las candidaturas Demócrata y Republicana aunque en algunas ocasiones se invitan a terceros partidos, como el caso de Ross Perot en los debates de 1992. Los nominados de cada partido hacen campaña a lo largo de todo el país para explicar sus programas electorales, convencer a los votantes y solicitar contribuciones a la campaña. La mayor parte del proceso electoral moderno se centra en hacer campaña en los llamados «estados oscilantes» (aquellos en los que un partido no tiene históricamente una mayoría clara), a través de visitas frecuentes y anuncios en los medios de comunicación.

En los Estados Unidos el presidente es elegido mediante sufragio indirecto. Un determinado número de Electores representantes, conocidos colectivamente como Colegio electoral, eligen oficialmente al presidente. Durante el «"Election Day"» (el martes siguiente al primer lunes de noviembre), el electorado de cada uno de los estados y el Distrito de Columbia selecciona a estos electores por votación. Cada estado tiene asignado un determinado número de electores, que se corresponden con la suma de delegados de ese estado en cada una de las Cámaras del Congreso. En la mayoría de los estados la candidatura que obtiene la mayoría de los votos gana la totalidad de los electores del estado para votar en el Colegio electoral.

Los electores ganadores se reúnen el primer lunes después del segundo miércoles de diciembre, aproximadamente seis semanas después de la elección, para elegir el presidente y el vicepresidente de los Estados Unidos. Ninguna disposición constitucional o ley federal exige que los Electores voten de acuerdo con el voto popular en su respectivo estado, sin embargo en la actualidad es raro que los electores hagan caso omiso del voto popular y emitan su voto electoral a favor de alguien que no sea el candidato de su partido. Tras la votación, los Electores envían un registro de la misma al Congreso. La apertura del voto de los Electores corresponde al vicepresidente, que actúa en su calidad de presidente del Senado y es leído en voz alta en una sesión conjunta de ambas Cámaras del Congreso entrante, que fue elegido al mismo tiempo que el presidente.

La determinación de quien será el presidente depende de los votos del colegio electoral, no de quien obtuvo el mayor número de votos populares en el país. Sin embargo, sólo en cinco ocasiones (en las elecciones de 1824, 1876, 1888, 2000 y 2016) el candidato que obtuvo el mayor número de votos populares no consiguió la mayoría de votos electorales ni, por tanto, su elección como presidente. Si ningún candidato obtuviera la mayoría de los votos electorales, la Duodécima Enmienda establece que la elección del presidente corresponde a la Cámara de Representantes. La Cámara ha tenido que seleccionar al presidente en dos ocasiones, en 1800 y 1824.

De acuerdo con la Vigésima Enmienda, el mandato presidencial comienza en el mediodía del 20 de enero del año siguiente a la elección. Esta fecha, conocida en los Estados Unidos como «"Inauguration Day"» (día inaugural), marca el principio del mandato de cuatro años tanto del presidente como del vicepresidente. Antes de poder ejercer, debe realizar un acto de toma de posesión del cargo y, de acuerdo con la Constitución, se requiere que preste el juramento presidencial:

Aunque no es una exigencia, los presidentes han utilizado tradicionalmente una Biblia para prestar el juramento, y añadiendo al final del mismo «"So help me God!"» (¡con la ayuda de Dios!). Del mismo modo, aunque ninguna disposición legal requiere que el juramento del cargo sea administrado por una persona concreta, tradicionalmente el presidente presta su juramento ante el juez presidente de la Corte Suprema de los Estados Unidos.

La duración del mandato del presidente y del vicepresidente de los Estados Unidos es de cuatro años. Inicialmente la Constitución no fijaba un límite en el número de mandatos, pero pocos presidentes se presentaron a una tercera reelección. Sin embargo, en 1940, Franklin D. Roosevelt presentó su candidatura y fue elegido para su tercer mandato (posteriormente fue elegido para el cuarto, pero murió unos meses después de su toma de posesión), convirtiéndose en el único presidente en ejercer la presidencia en más de dos ocasiones. Con anterioridad a Roosevelt, Ulysses S. Grant quiso presentarse a un tercer mandato en 1880 tras permanecer en el cargo de 1869 hasta 1877, pero no consiguió la nominación de su partido. Theodore Roosevelt accedió a la presidencia tras el asesinato de William McKinley y fue posteriormente elegido en 1904 para un mandato completo, y así sirvió en el cargo de 1901 hasta 1909. Presentó posteriormente su candidatura (para un mandato no consecutivo) en 1912, pero perdió ante Woodrow Wilson.

Con la ratificación de la Vigesimosegunda Enmienda en 1951, se prohíbe a cualquier persona elegida para la Presidencia, y que ha servido como presidente, ser reelegida más de una vez y si ha actuado como presidente interino durante más de dos años del mandato no vencido de su precursor, ser elegida más de una vez. Harry S. Truman, que ocupaba la presidencia en el momento de la ratificación de la enmienda (que eximía expresamente de esta limitación al presidente en el cargo en el momento de su entrada en vigor) también buscó un tercer mandato antes de retirarse de las elecciones de 1952.

Desde la ratificación de la enmienda, cinco presidentes han servido en dos mandatos completos: Dwight D. Eisenhower, Ronald Reagan, Bill Clinton, George W. Bush y Barack Obama, mientras que Jimmy Carter y George H. W. Bush se presentaron a la reelección para un segundo mandato, pero fueron derrotados. Richard Nixon fue elegido para un segundo mandato, pero dimitió antes de completarlo. Lyndon B. Johnson fue el único presidente que conforme a la enmienda podía ser elegible para servir más de dos mandatos, pues sólo permaneció en el cargo durante catorce meses tras el asesinato de John F. Kennedy. Sin embargo decidió no participar en las elecciones de 1968. Gerald Ford buscó un mandato completo después de servir los últimos dos años y cinco meses del segundo mandato de Nixon, pero no fue elegido.

El cargo de presidente puede quedar vacante por varias circunstancias: muerte, dimisión y destitución.

En cuanto a la destitución, la Sección 4 del contempla que la Cámara de Representantes puede someter a un proceso de "impeachment" a altos funcionarios federales, incluido el presidente, en casos de «traición, cohecho u otros delitos mayores o infracciones penales». Tras este proceso, la Cláusula 6 de la Sección 3 del otorga al Senado el poder de destituir de su puesto a los funcionarios acusados, si dos terceras partes de sus miembros votan su culpabilidad. Dos presidentes han sido procesados por la Cámara de Representantes, Andrew Johnson en 1868 y Bill Clinton en 1998, aunque ninguno fue condenado posteriormente por el Senado.
De acuerdo con la Sección 3 de la Vigesimoquinta Enmienda, el presidente puede transferir los poderes y deberes presidenciales al vicepresidente, que pasaría a actuar como presidente interino, presentando una declaración al presidente de la Cámara de Representantes y al presidente "pro tempore" del Senado manifestando las razones de la transferencia. El presidente recobra los poderes y deberes presidenciales cuando les presenta a ambos representantes del Congreso una declaración escrita declarando dicha reanudación. Esta transferencia de poderes puede darse por cualquier motivo que el presidente considere apropiado. En 2002 y 2007 el presidente George W. Bush transfirió durante un corto período la autoridad presidencial al vicepresidente Dick Cheney. En ambas ocasiones fue debido a un proceso médico que requirió que Bush fuera sedado; Bush recuperó el poder presidencial el mismo día.

La Sección 4 de la Vigesimoquinta Enmienda contempla la posibilidad de transferencia de los poderes presidenciales al vicepresidente si este último y la mayoría del Gabinete transmiten al presidente de la Cámara de Representantes y al presidente "pro tempore" del Senado una declaración de incapacidad presidencial para desempeñar el cargo. En este caso el vicepresidente asumiría los poderes presidenciales en calidad de presidente interino; sin embargo, el presidente puede rechazar su inhabilitación y continuar en el puesto. Si el vicepresidente y el Gabinete impugnan esta decisión, es entonces el Congreso, que debe reunirse en el plazo de dos días si no se encuentra ya en sesión, quien debe decidir al respecto de la incapacidad o no del presidente para desempeñar el cargo.

La Constitución de los Estados Unidos menciona la dimisión del presidente, pero no regula la forma de ejecutar tal dimisión o las condiciones para su validez. Por acuerdo del Congreso, la única prueba válida de la decisión presidencial es un documento escrito declarando su dimisión firmado por el propio presidente y entregado en la oficina del Secretario de Estado. El 9 de agosto de 1974, afrontando su probable destitución en pleno escándalo Watergate, Richard Nixon se convirtió en el único presidente en dimitir del puesto.

Al igual que en el caso de dimisión, para la no aceptación del puesto también basta con la presentación de un escrito en ese sentido ante el Secretario de Estado.

La Constitución especifica que el vicepresidente debe ser el sucesor presidencial en caso de producirse una vacante en el puesto por muerte, dimisión, renuncia, inhabilitación, destitución o cualquier otra causa. Si tanto el puesto de presidente como el de vicepresidente están vacantes o están ocupados por personas incapacitadas para el puesto, el presidente de la Cámara de Representantes ocuparía el puesto como presidente interino. La línea sucesoria presidencial continúa con el presidente "pro tempore" del Senado, seguido a su vez por cada miembro del Gabinete en un orden establecido, siempre y cuando reúnan los requisitos determinados constitucionalmente para ser presidente.

En 1789, aunque inicialmente no se mostró de acuerdo con recibir un salario por sus servicios, el primer Congreso de los Estados Unidos acordó pagar a George Washington un salario de 25 000 dólares al año (aproximadamente unos 566 000 dólares del año 2009), un sueldo realmente elevado para la época, aunque el gobierno por entonces no proporcionaba una mansión oficial y Washington debía asumir los elevados gastos de una residencia presidencial con ese salario, por lo que manifestó que el salario era apenas suficiente para costear estos gastos.

El salario presidencial ha ido experimentando sucesivos aumentos a lo largo de los años y en 1999, siendo presidente Bill Clinton, el Congreso aprobó el actual salario presidencial de 400 000 dólares anuales, que entró en vigor en 2001. Le corresponde además (año 2005) una cuenta de gastos de 50 000 dólares, 100 000 dólares libres de impuestos para viajes y una cuenta de gastos personales de 19 000 dólares.

Anteriormente a 1958, al cesar sus mandatos los presidentes no recibían ninguna pensión, sin embargo a partir de ese año, con la "Former Presidents Act" (3 U.S.C. § 102) el Congreso aprobó que los presidentes salientes empezaran a recibir una pensión vitalicia de 25 000 dólares anuales, además de una oficina y personal. Esta pensión ha ido aumentando desde entonces con la aprobación del Congreso. Los ex presidentes reciben una pensión basada en el sueldo de los secretarios del gabinete de la administración vigente, cuyo sueldo es de 193 400 dólares en el caso del año 2009. La viuda de un presidente tiene derecho a una pensión de 20 000 dólares anuales, si no cuenta con otra pensión.

Desde 1800, ocupando la presidencia John Adams, la Casa Blanca, en Washington D. C., sirve como residencia oficial del presidente estadounidense. Mientras permanezca en el cargo tiene derecho al uso de sus instalaciones y personal, incluida asistencia médica, recreo, servicios domésticos y servicio de seguridad. La Instalación de Apoyo Naval Thurmont, popularmente conocida como Camp David, es una instalación militar en el "Catoctin Mountain Park", un área recreativa situada en el condado de Frederick (Maryland), a las afueras de Washington D. C., que se utiliza en la actualidad como residencia oficial de descanso del presidente y sus invitados.

El Servicio Secreto de los Estados Unidos es el encargado de la protección del presidente y su familia. Como parte de su protección, a los presidentes, las primeras damas, sus hijos y otros miembros de la familia inmediata, así como otras personas y lugares relevantes, se les asigna un nombre en clave por parte del Servicio Secreto. La utilización de estos nombres en clave era por motivos de seguridad en un tiempo en que las comunicaciones electrónicas no se cifraban de forma habitual, como hoy en día; actualmente estos nombres en clave simplemente se utilizan por tradición, así como por su brevedad y claridad.

Cuando realiza viajes de larga distancia, el presidente utiliza alguno de los dos aviones identificados por la Fuerza Aérea estadounidense como VC-25 (una versión militar muy modificada del modelo civil Boeing 747-200B) denominados con el indicativo «"Air Force One"» cuando el presidente los está utilizando, que están profusamente equipados y en los que puede llevar a cabo todas sus funciones. El presidente también utiliza un helicóptero del Cuerpo de Marines, identificado como «"Marine One"» cuando el presidente se encuentra a bordo. Para desplazamientos por tierra, utiliza una limusina blindada basada en un chasis Cadillac ampliamente modificado, denominada en ocasiones «"Cadillac One"» en referencia al avión presidencial.

Algunos presidentes han tenido carreras significativas después de dejar el cargo. Tal es el caso de William Howard Taft que fue presidente del Tribunal Supremo, o el de Herbert Hoover con su trabajo en la reorganización del gobierno después de la Segunda Guerra Mundial. Grover Cleveland, cuya candidatura para la reelección fracasó en 1888, fue posteriormente elegido nuevamente presidente cuatro años más tarde, en 1892. Dos antiguos presidentes sirvieron en el Congreso después de abandonar la Casa Blanca; John Quincy Adams fue elegido para la Cámara de Representantes, donde permaneció diecisiete años, y Andrew Johnson volvió al Senado en 1875. John Tyler sirvió en el Congreso provisional de los Estados Confederados durante la Guerra de Secesión y fue elegido para la Cámara de Representantes Confederada, aunque murió antes de que ésta se reuniera. Más recientemente, Richard Nixon realizó numerosos viajes al extranjero, incluyendo la República Popular China y Rusia. Jimmy Carter actuó como mediador internacional, defensor de los derechos humanos en todo el mundo y fue galardonado con el en 2002. Bill Clinton también ha realizado gestiones de mediación y negociación a nivel internacional, como en el caso de sus gestiones para la liberación de dos periodistas estadounidenses, Laura Ling y Euna Lee, en Corea del Norte. Bill Clinton también ha participado activamente en política, como en el caso de las primarias presidenciales del partido Demócrata de 2008 en apoyo de su esposa, Hillary Clinton.

Hasta 1997, todos los expresidentes y sus familias, contaban con la protección del Servicio Secreto hasta la muerte del presidente. El último presidente que recibió protección vitalicia del Servicio Secreto tras este cambio legislativo fue Bill Clinton; George W. Bush y todos los presidentes posteriores serían protegidos por el Servicio Secreto durante un máximo de diez años tras la finalización de su mandato. Sin embargo, el 10 de enero de 2013, el presidente Obama firmó una ley que restableció la protección del Servicio Secreto de por vida para él, George W. Bush y todos los presidentes subsiguientes. Si el cónyuge vuelve a casarse, pierde el derecho de protección por parte del servicio secreto.

Todos los presidentes desde Herbert Hoover han creado un lugar donde preservar y poner a disposición del público documentos, archivos, colecciones y otros objetos históricos relacionados con sus mandatos, que, aunque no es exclusivamente una biblioteca, es conocido como Biblioteca Presidencial. Las Bibliotecas son constituidas y mantenidas por la Administración Nacional de Archivos y Documentos ("NARA" por sus iniciales en inglés). Hay actualmente trece bibliotecas presidenciales en el sistema NARA. También hay varias bibliotecas presidenciales mantenidas por gobiernos estatales y fundaciones privadas, como la Biblioteca y Museo Presidencial de Abraham Lincoln, que está al cargo del estado de Illinois.






</doc>
<doc id="28107" url="https://es.wikipedia.org/wiki?curid=28107" title="Colonia">
Colonia

El término colonia puede referirse:














</doc>
<doc id="28111" url="https://es.wikipedia.org/wiki?curid=28111" title="Emperador de Japón">
Emperador de Japón

El es el símbolo constitucionalmente reconocido de la nación japonesa y de la unidad de su pueblo. Es la cabeza de la familia imperial japonesa, la familia real del Japón.

El papel del emperador de Japón oscilaba, hasta mediados del siglo XX, entre un clérigo de alto rango con grandes poderes simbólicos y un auténtico gobernante imperial. Ha existido un culto imperial (Arahitogami) que considera al "tennō" como sumo sacerdote mediador entre los hombres y la divinidad, debido a sus cercanos lazos con los dioses japoneses (lazos de herencia). La violencia y las operaciones militares han sido considerados incompatibles con el papel del "tennō" al menos durante 14 siglos: por ello los monarcas japoneses no han actuado como comandantes militares, al contrario de lo habitual en Occidente. La principal función del emperador durante la mayor parte de los últimos mil años habitualmente ha sido la de simplemente autorizar u otorgar legitimidad a aquellos situados en el poder.

Bajo la , el emperador se ha convertido en una figura ceremonial y simbólica con funciones similares a las de un jefe de Estado en una monarquía constitucional (ver Política de Japón). Sin embargo, ni la constitución japonesa ni ninguna otra norma atribuyen expresamente al emperador la titularidad de la jefatura del Estado.
El actual emperador, Su Majestad Imperial el emperador Akihito, sucedió a su fallecido padre Hirohito en 1989.

La residencia del emperador japonés es el palacio de "Kōkyo", localizado en el centro de Tokio, desde mediados del siglo XIX es la residencia oficial del emperador. Anteriormente los emperadores residían en Kioto.

Ciertos datos y fechas referentes a la institución imperial son objeto de discusión entre los historiadores japoneses. Muchos emperadores citados en la murieron a una edad muy temprana y difícilmente se puede considerar que hubieran "gobernado" de verdad. Otros fueron eclipsados por sus predecesores, los cuales se habían retirado aparentemente a un monasterio pero continuaron ejerciendo su influencia, en un proceso llamado "reinado enclaustrado". De todos modos, es importante mantener la lista oficial entera, porque incluso hoy día la forma habitual de datación en la historia japonesa es por los reinados de los emperadores.

Aunque el emperador haya sido un símbolo de continuidad con el pasado, el grado de poder ejercido por el emperador de Japón ha variado considerablemente a lo largo de la historia japonesa.

Se considera que los más antiguos emperadores registrados en Kojiki y Nihonshoki, como el Emperador Jimmu,
no tienen credibilidad histórica. El primer monarca ahora en lista como emperador que es generalmente reconocido por los historiadores como existente históricamente fue el Emperador Ojin, pero el tiempo de su reinado es impreciso (presumiblemente fue el siglo IV d. C. tardío y/o en el comienzo del siglo V d. C.). Estos dos libros declaran que la casa imperial mantuvo un linaje continuo, aunque hoy algunos historiadores creen que muchos emperadores antiguos que se decía eran descendientes del Emperador Ōjin no tenían una conexión genealógica con su predecesor. Sin embargo, la genealogía que inicia en el siglo V tardío puede ser considerada como fiable, lo que quiere decir que la dinastía ha continuado por lo menos unos 1500 años.

Los emperadores enclaustrados han entrado en conflicto con sus correspondientes emperadores oficiales de vez en cuando. Un ejemplo notable es la Rebelión Hogen de 1156, en la que el ex-emperador Sutoku trató de arrebatar el poder al emperador Go-Shirakawa (en ejercicio). Otros ejemplos, como la rebelión del emperador Go-Toba en 1221 contra el Shogunato Kamakura, o la Restauración Kenmu en 1336 bajo el emperador Go-Daigo, muestran claramente la lucha de poder que ha tenido lugar entre la Casa Imperial y los gobiernos militares en Japón.
No es sino hasta los siglos recientes que Japón incorpora diversas zonas remotas de su territorio actual. El nombre Nippon no se empieza a utilizar sino varios siglos después del inicio del actual línea imperial. Realmente, el gobierno centralizado comenzó a aparecer poco antes de la época del Príncipe Shotoku. El Emperador era más bien una venerada encarnación de la armonía divina más que la cabeza de una administración estatal. En Japón siempre ha sido fácil para los señores ambiciosos mantener su poder, dado que dicha posición no era en absoluto contradictoria con la del emperador. El Parlamentarismo de hoy recoge esa coexistencia que tenía el emperador con diferentes shogunes, señores de la guerra, regentes, guardianes, etc. Podemos decir que técnicamente es un error traducir como "emperador" el término japonés "tennō", que no logra definir de manera exacta su labor, si lo comparamos con el término imperial en el sentido occidental.

Históricamente los títulos del "tennō" en japonés nunca incluyeron designaciones territoriales como sí sucedía con los monarcas europeos. La posición del emperador es un fenómeno territorialmente independiente - el emperador es el emperador, incluso aunque tenga seguidores en una sola provincia (como a veces sucedió con las cortes del norte y del sur).

Desde fines de 1100 a 1867, el poder real estuvo en manos del "shōgun", cuya autoridad provenía, en teoría, directamente del emperador. Cuando los exploradores portugueses llegaron por primera vez a Japón (ver “período Nanban”), consideraron la relación entre el emperador y los shogunes como la del Papa (de raigambre divina, pero con poco poder político) y el rey (terrenal, pero con un amplio poder político), aunque esto es en cierto punto inexacto ya que, como el Emperador, los Papas han manejado distintos grados de poder a lo largo de la historia.

La Restauración Meiji fue, de hecho, una especie de revolución, con los dominios de Satsuma y Choshu uniéndose para derribar al Shogunado Tokugawa. El Padre del Emperador Meiji, el Emperador Komei, comenzó a hacer valer su poder político luego que las naves del Comodoro Matthew Perry visitan Edo. Para principios de 1860, la relación entre la Corte Imperial y el Shogunado había cambiado drásticamente. Irónicamente, Komei levantó la voz contra el Shogunado dado que él y otros nobles estaban molestos ante la ineficacia del Shogunado en expulsar a los intrusos bárbaros. Dominios insatisfechos y rōnin comenzaron a reunirse bajo el lema “sonno, joi,” o “respeta al emperador, expulsa a los bárbaros.” Satsuma y Choshu usaron este alboroto para moverse contra el enemigo histórico, y obtuvieron una importante victoria militar en las afueras de Kyoto contra las fuerzas Tokugawa. En 1868 se declara la “restauración” imperial, y el Shogunado fue despojado de sus poderes. En los próximos años se verá un significativo desorden y descontento, además de esporádicas rebeliones.

Sin embargo, los modernistas de la élite japonesa se dieron cuenta que los llamados al “joi” eran surrealistas. Si los extranjeros no podían ser expulsados, concluyeron que Japón debía volverse una nación fuerte y moderna para evitar el destino y las humillaciones que sufrían las otras naciones orientales. Otros tenían el propósito de expandir el territorio japonés más allá de las fronteras para la gloria del emperador, y muchos fueron atraídos por los ideales de la Iluminación occidentales. Mediante la constitución de 1889, el emperador de Japón transfirió gran parte de sus antiguos poderes como monarca absoluto a los representantes del pueblo, pero permaneció como cabeza del imperio. Aunque inspirada en las constituciones de Europa, la nueva Constitución Meiji no fue tan democrática como muchos esperaban. Al emperador se le dieron amplios y vagos “poderes reservados” que a su turno eran explotados por el primer ministro y por varios camarillas alrededor del emperador. Para 1930 el gabinete japonés estaba mayoritariamente compuesto por líderes militares seudo-fascistas que usaron al emperador y su supuesta divinidad como un punto de partida ultranacionalista para la expansión del imperio. Cuando estalló la II Guerra Mundial, el emperador era el símbolo por el cual los soldados peleaban y morían. El mismo emperador estaba fuera de la vista, sin embargo, y su rol durante este período es discutido. La concepción tradicional posterior a la Segunda Guerra Mundial sostiene que estaba dominado por el ejército, aunque la documentación publicada desde 1989 apunta a una participación más activa del emperador en la política bélica. Aún hay controversia sobre el rol que jugó Hirohito en el comando de las fuerzas japonesas durante la Segunda Guerra Sino-Japonesa y la Guerra del Pacífico.

El papel del emperador es definido en el Capítulo I de la Constitución de Japón de 1947:

A diferencia de otros monarcas constitucionales, el emperador del Japón no tiene poderes reservados.
Aunque el emperador actualmente lleva a cabo muchos de los roles de un soberano ceremonial como jefe de estado, ha habido una persistente controversia sobre si el emperador es de hecho un verdadero monarca en un sentido político o meramente un pretendiente, ostentando dicho cargo en una república constitucional parlamentaria. En una monarquía tradicional, el poder político deviene de la soberanía monárquica, cuya prerrogativa real es luego ejercida al capricho de los legisladores electos, de la forma establecida en la convención constitucional. Sin embargo, si no hay prerrogativa real, entonces la soberanía debe descansar en el pueblo, tal como lo establece el Artículo 1º de la Constitución de Japón. Por lo tanto, el emperador es simplemente un actor político dentro de un gobierno que realmente no adhiere al sistema de Westminster donde la posición de “jefe de estado” requiere de una persona con soberanía o con mandato popular para asumir tal oficio. Los esfuerzos en los años 1950 de los políticos conservadores en enmendar la constitución para nombrar explícitamente al emperador como jefe de estado fueron rechazados. A pesar de todo, el emperador lleva a cabo todas las funciones diplomáticas asociadas normalmente al jefe de estado y así es reconocido por los poderes extranjeros.

El tratamiento de los emperadores de Japón es a menudo problemático, debido a las diferencias lingüísticas y culturales entre Japón y el mundo occidental. Mientras los japoneses llaman “{nombre} "tennō"” (para los anteriores) o "Kinjou Heika" (今上陛下) para el actual, los académicos hispano y angloparlantes han usado distintas variantes, como “Emperador {nombre}” y, menos comúnmente, “{nombre} "tennō"”. Lo que a menudo no es comprendido, sin embargo, es que los emperadores son llamados póstumamente “{nombre} "tennō"”, y así la palabra "tennō", o “emperador”, forma parte de su propio nombre. Esto es particularmente malentendido desde el Emperador Meiji en adelante, dado que el nombre póstumo que se da a los emperadores ahora es el mismo que el de la época que ellos presidieron, mientras que antes el reinado de un emperador podía contener una sucesión de eras. Términos tales como “Emperador Meiji” deben ser entendidos en inglés como “el emperador del período Meiji”, que no es siempre lo que se entiende en japonés.

En español, el término mikado (御門 o 帝 o みかど), que significa “la Puerta”, se usaba antiguamente para referirse al emperador del Japón; este uso ahora es obsoleto. En japonés, los emperadores de Japón, no así los de los otros países, son conocidos como "tennō" (天皇). Literalmente, la palabra "tennō" combina los caracteres de “gobernante” y “cielo”, pero este no es un signo de divinidad; el uso de ten (天, “cielo”) en la palabra japonesa fue una adopción del concepto chino de Enviado del Cielo, que implica que un emperador ha sido designado por los cielos para equilibrar los asuntos políticos y religiosos en sus dominios.

Hay dos palabras en japonés equivalente a la palabra hispana “emperador”: "tennō" (天皇) es usada específicamente para describir al emperador del Japón, "kōtei" (皇帝, el título usado por el emperador chino) es usado para describir a los emperadores extranjeros. Sumeramikoto (literalmente “gobernante celestial sobre las nubes”) fue también usado en el japonés antiguo.

Tradicionalmente, los japoneses consideran de mala educación el llamar a un noble por su nombre propio. Esta costumbre está en retirada, pero aún es observada ante la familia imperial. "Tennō" se agrega de forma póstuma (como prefijo), pero no al emperador reinante. Al contrario, los emperadores pasados son llamado por sus nombres póstumos, tales como el Emperador Jimmu, Emperador Kammu, Emperador Meiji. Desde la Era Meiji, los nombres de era son también usados como nombres póstumos. El emperador reinante es casi siempre referido como "Tennō Heika" (天皇陛下, que literalmente significa “Su Majestad el Emperador”) o de forma más solemne como "Kinjō Heika" (今上陛下). Por otra parte, en lenguaje coloquial siempre se le refiere como "Heika", "Okami" o "To-gin san" ("To-gin" es sinónimo de "Kinjō"). El emperador actual no es llamado por el nombre de la era, el que se el egregará luego como nombre póstumo.

Hoy en día esta costumbre es menos considerada. En español, los recientes emperadores han sido llamados por sus nombres personales, de acuerdo con los usos occidentales. Como bien se explicó, en japonés esto suena ofensivo y, en cierto modo, blasfemo.

Por ejemplo, el emperador anterior era usualmente llamado Hirohito en español, pero luego de su muerte fue rebautizado como "Shōwa Tennō" y es llamado de esa forma en japonés. Sin embargo, durante su reinado, nunca se le llamó Hirohito o "Shōwa Tennō" en japonés. Más bien, se hacía referencia a él simplemente como "Tennō Heika" (que significa “Su Majestad el Emperador”).

El gobernante de Japón era conocido como ヤマト大王/大君 (yamato ōkimi, Gran Rey de Yamato), 倭王/倭国王 (waō/wakokuō, Rey de Wa, usado externamente), o 治天下大王 (amenoshita shiroshimesu ōkimi o sumera no mikoto, Gran Rey que gobierna todo bajo el cielo, de uso interno) en las fuentes chinas y japonesas anterior al Siglo VII. El uso más antiguo documentado de la palabra "tennō" es en una tablilla de madera, o "mokkan", que fue desenterrada en Asuka-mura en la prefectura de Nara en 1998 y fechada en la era del Emperador Tenji y la Emperatriz Jitō. La introducción del término se dio en medio del proceso de Sinización de Japón, y es considerado por muchos como un intento de los gobernantes japoneses de igualarse con los Emperadores Chinos. Notablemente, "Tianhuang" (天皇), el equivalente chino de "tennō", estaba entre los títulos adoptados por Emperador Gaozong de la China Tang del mismo período, a pesar que no se sabe si los dos surgieron independientemente o si uno fue influenciado por el otro.

A lo largo de la historia, contrariamente a cualquier suerte de práctica de harén, en que no se reconoce una esposa jefa y sólo manteniendo un surtido de mujeres mueble, los emperadores japoneses y los nobles solían nombrar una esposa jefa.

La dinastía imperial practicó de forma consistente la poliginia oficial, una práctica que sólo terminó en el período Taisho (1912-1926). Además de la emperatriz, el emperador podía tomar, y casi siempre tomaba, varias consortes secundarias (“concubinas”) de distintos grados jerárquicos. Los otros dinastas (shinno) también podían tener concubinas. Luego de un decreto del Emperador Ichijō, algunos emperadores tuvieron incluso dos emperatrices simultáneamente (kogo y chugu son los dos títulos separados en esta situación). Con el auxilio de esta poligamia, el clan imperial fue capaz de producir una mayor descendencia. (Los hijos de consortes secundarias eran usualmente reconocidos como príncipes imperiales, y podían ser reconocidos como herederos al trono si la emperatriz no daba a luz un heredero.)

De las ocho mujeres "tennō" (emperatriz reinante) de Japón, ninguna se casó ni dio a luz luego de ascender al trono. Algunas de ellas, siendo viudas, habían tenido hijos antes de su reinado.
En la sucesión, los hijos de la emperatriz eran preferidos a los de las consortes secundarias. Así, era significativo qué familias tenían oportunidades preferenciales de proveer esposas jefe a los príncipes imperiales, esto es, dar futuras emperatrices.

Aparentemente la más antigua tradición de matrimonios oficiales en la dinastía imperial eran aquellos entre miembros de la dinastía, incluso entre medios hermanos o entre tío y sobrina. Dichos matrimonios eran arreglados para preservar mejor la sangre imperial o estaban destinados a producir hijos como modo de reconciliación entre dos ramas de una dinastía. Las hijas de las consortes permanecían como concubinas, hasta que el Emperador Shōmu —en lo que se reportó como la primera elevación de este tipo— ascendió a su consorte Fujiwara a esposa jefa.

Los monarcas japoneses han sido, así como muchos otros en otras partes, dependientes de las alianzas con jefes poderosos y con otros monarcas. Muchas de dichas alianzas eran selladas con matrimonios. La específica característica en Japón era el hecho que esos matrimonios pronto se incorporaron como elementos de tradición que controlaban los matrimonios de las generaciones venideras, aunque la alianza original haya perdido su significado real. Un patrón repetido ha sido un yerno imperial bajo la influencia de su poderoso suegro no imperial.

Desde los siglos VII y VIII, los emperadores solían tomar a las mujeres del Clan Fujiwara como sus más altas esposas – las más probables madres de los futuros monarcas. Esto era encubierto como una tradición matrimonial entre los herederos de dos kamis, dioses Shinto: los descendientes de Amaterasu con los descendientes de la familia kami de los Fujiwara. (Originalmente, los Fujiwara eran descendientes de una nobleza relativamente menor, así su kami es difícilmente reconocible en la mitología japonesa.) El producir niños imperiales, herederos de una nación, descendiente por ambas ramas de dos kamis, era considerado deseable – o al menos así parecía a los Señores Fujiwara, que así recibían preferencia en el mercado de los matrimonios imperiales. La realidad tras esos matrimonios era la alianza entre un príncipe imperial y un Señor Fujiwara, su suegro o abuelo, este último con sus recursos apoyando el ascenso del príncipe al trono y más a menudo controlando el gobierno. Estos arreglos crearon la tradición de los regentes (Sessho y Kampaku), cuyo puesto podía ser utilizado sólo por un señor sekke Fujiwara.

Anteriormente los emperadores se casaban con mujeres de familias del clan gobernante Soga, y con mujeres de la misma familia imperial, ya sea con primas en variados grados y a menudo con sus hermanas (medias hermanas). Muchos miembros de la familia imperial de los siglos VI y VII eran hijos de parejas de medios hermanos. Estos matrimonios usualmente eran aparatos de alianza o sucesión: los señores Soga se aseguraban de mantener dominado a un príncipe, para ser puesto como títere en el trono; o un príncipe se aseguraba la combinación de dos descendientes imperiales, para fortalecer su propia pretensión al trono y la de sus hijos. Estos matrimonios también eran una manera de sellar una reconciliación entre dos ramas de la familia imperial.

Luego de un par de siglos, los emperadores ya no pudieron desposar a ninguna mujer fuera de esas familias como primera esposa, sin importar el poder o la riqueza que ese matrimonio pudiese traer. Rara vez un príncipe sin una madre proveniente de estas familias era autorizado para ascender al trono. La primitiva necesidad y conveniencia dieron paso a una estricta tradición que no hacía sino dar a determinadas mujeres el carácter de posibles novias, porque estas familias habían producido posibles esposas por siglos. La tradición se hizo más fuerte que la misma ley.

Las mujeres Fujiwara eran a menudo emperatrices, y las concubinas provenían de familias nobles menos importantes. En el último milenio, los hijos de un varón de la familia imperial con una mujer Fujiwara eran preferidos en la sucesión.

Las cinco familias Fujiwara, Ichijo, Kuji, Nijo, Konoe y Takatsukasa, fueron la fuente principal de novias imperiales desde los siglos VIII a XIX, incluso más comúnmente que las mismas hijas del clan imperial. Así, las mujeres Fujiwara, por lo común eran las emperatrices y madres de los emperadores.

La fuente aceptable de esposas imperiales, novias para el emperador y el príncipe heredero, fueron incluso reglamentadas en las leyes de la casa imperiales durante la era Meiji (1889), que establecían que las hijas de Sekke (las cinco ramas principales de la familia Fujiwara) y las hijas del mismo clan imperial eran primariamente novias aceptables.

Luego de que esa ley fue abolida a consecuencia de la IIGM, el actual emperador Akihito fue el primer príncipe heredero en más de mil años en tener una emperatriz no elegida del círculo aceptable.

La dinastía imperial japonesa basa su posición en el hecho de que ha reinado “desde tiempos inmemoriales”. Es cierto que sus orígenes están escondidos tras las nieblas del tiempo: no hay pruebas que muestren la existencia de cualquier emperador que no haya sido descendiente de su predecesor, hasta los más tempranos emperadores. Un antiguo ancestro de la dinastía, el Emperador Keitai (aparecido en los años 500 d. C.), a pesar que se sospecha no era descendiente de su predecesor, la tradición lo coloca como un pariente lejano de sus antecesores. De acuerdo a los registros, la familia que él inició en el trono, desciendo al menos de una, o probablemente de varias princesas imperiales de la dinastía inmediatamente anterior. La tradición erigida por estas leyendas ha elegido reconocer sólo al ancestro masculino putativo para legitimar su sucesión, sin dar importancia al peso de los lazos por parte de las princesas. Hace milenios, la familia imperial japonesa creó su propio y particular sistema de sucesión hereditaria. Este es no basado en la primogenitura, más o menos patrilineal, basado mayoritariamente en rotación. Hoy, Japón usa un estricto sistema de primogenitura patrilineal – en otras palabras, Ley Sálica pura. Esta fue adoptada según el modelo prusiano, por el que Japón fue fuertemente influenciado en la década de 1870.

La primogenitura patrilineal estricta es, no obstante, directamente contradictoria con muchas antiguas tradiciones japonesas sobre la sucesión imperial.

Los principios controladores y su interacción eran aparentemente bastante complejos y sofisticados, llevando incluso a resultados idiosincrásicos. Algunos principios básicos de la sucesión parecen ser:

- Las mujeres podían suceder (pero existían niños que no les eran propios y cuyo padre tampoco era patrilineal de la casa imperial, así no hay precedente de que un hijo de una mujer imperial con un hombre no imperial fuera autorizado para suceder, así como tampoco lo hay prohibiéndolo a los hijos de las emperatrices). Sin embargo, la accesión femenina era claramente mucho más rara que la de los hombres.

- La adopción era posible y una forma muy utilizada para incrementar el número de herederos capaces de suceder (sin embargo, el niño adoptado debe ser hijo de otro miembro patrilineal de la casa imperial.

- La abdicación era común, y de hecho se dio mucho más que la muerte en el trono. En aquellos días, el principal papel del emperador era ser una especie de sacerdote (o dios), que contenía muchísimos y repetitivos rituales, que se juzgaba que, tras un servicio de alrededor de diez años, el susodicho merecía un retiro digno como un honorable ex emperador.

- La primogenitura no era usada – al contrario, en la época temprana, la casa imperial practicó un sistema parecido a la rotación. Muy a menudo un hermano (o hermana) sucedía al más viejo incluso en caso que su predecesor dejara descendencia. El “turno” de la siguiente generación venía luego de varios individuos de la generación anterior. La rotación era común entre dos o más ramas de la casa imperial, así primos más o menos distantes se sucedían entre ellos. El Emperador Go-Saga incluso decretó la alternación entre los herederos de sus dos hijos, cuyo sistema continuó por un par de siglos (llevando a una lucha inducida por los shogunes entre dos ramas, los emperadores “del norte” y “del sur”). Hacia el fin de esto, los alternantes eran primos muy lejanos contados en grados de descendencia masculina (pero siempre hubo matrimonios entre miembros de la casa imperial, así que la relación sería más cercana si se contasen los grados femeninos). Durante los últimos 500 años, sin embargo, debido probablemente a la influencia del confucianismo, la sucesión por parte de los hijos –no siempre, aunque más comúnmente, el hijo de más edad que sobrevivía al emperador- ha sido la norma.

Históricamente, la sucesión al Trono del Crisantemo japonés ha pasado siempre por línea masculina el linaje imperial. Generalmente han sido hombres, aunque de los más de cien monarcas masculinos ha habido seis mujeres como emperatrices en ocho ocasiones.

Hace unos mil años, comenzó la tradición de que el emperador debe ascender al poder relativamente joven. Un dinasta que ha pasado la infancia se considera apta y lo suficientemente crecido. El alcanzar la edad de mayoría legal no era un requisito. Así, una multitud de emperadores han ascendido desde pequeños, jovencitos de 6 a 8 años de edad. Las labores ceremoniales eran juzgadas posibles de ser realizadas por un niño. Un reino de alrededor de diez años era reputado un servicio suficiente. Ser un niño aparentemente era un buen atributo, para soportar deberes tediosos y para tolerar la subyugación de los poderes políticos, así como a veces para esconder a los verdaderos miembros poderosos de la dinastía imperial. Casi todas las emperatrices japonesas y docenas de emperadores abdicaron, y vivieron el resto de sus vidas en el retiro, y/o ejerciendo influencia tras los velos. Muchos emperadores abdicaron y pasaron a su retiro cuando aún eran adolescentes. Estas tradiciones se aprecian en el folclore, teatro y literatura japoneses, así como en otras formas de arte, donde el emperador es usualmente descrito o representado como un adolescente.

Antes de la Restauración Meiji, Japón tuvo ocho "tennō", o emperatrices reinantes, todas hijas por línea de padre de la Casa Imperial. Ninguna de ellas ascendió como esposa o viuda de un emperador. Las hijas y nietas imperiales, sin embargo, usualmente ascendían al trono como una suerte de “medida de intervalo” – si un hombre apto no estaba disponible o algunas ramas imperiales estaban en conflicto, por lo que se necesitaba un compromiso. Casi todas las emperatrices japonesas y docenas de emperadores abdicaron – muchas emperatrices una vez que un menor apto alcanzaba la edad de ascender. Tres emperatrices, la Emperatriz Suiko, la Emperatriz Kōgyoku (también llamada Emperatriz Saimei) y la Emperatriz Jitō, eran viudas de emperadores fallecidos y princesas de sangre imperial por derecho propio. Una, la Emperatriz Genmei, era la viuda de un príncipe de la corona y princesa de sangre imperial. Las otras cuatro, la Emperatriz Genshō, la Emperatriz Kōken (también llamada Emperatriz Shōtoku), la Emperatriz Meishō y la Emperatriz Go-Sakuramachi, eran hijas solteras de emperadores anteriores. Ninguna de estas emperatrices se casaron o tuvieron hijos luego de ascender al trono.

El Artículo 2º de la Constitución Meiji de 1889 (la Constitución del Imperio del Japón) estatuía, “El Trono Imperial debe ser sucedido por los descendientes imperiales varones, de acuerdo con las providencias de la ley de la Casa Imperial.” La Ley de la Casa Imperial de 1889 fijó la sucesión en los descendientes varones de la línea imperial, y excluyó específicamente a las mujeres descendientes de la sucesión. En el evento que no hubiese varones en la línea principal, el trono pasaría a la línea colateral más cercana, nuevamente en línea masculina. Si la emperatriz no fuese capaz de dar a luz a un heredero, el emperador podía tomar una concubina, y le hijo que llas tuviera sería reconocido como heredero al trono. Esta ley, promulgada el mismo día que la Constitución Meiji, gozaba de igual estatus con aquélla.

El Artículo 2º de la Constitución de Japón, promulgada en 1947 bajo la influencia de la ocupación estadounidense y aún con fuerza, provee que “El Trono Imperial será dinástico y sucedido de acuerdo con la Ley de Casa Imperial aprobada por la Dieta.” La Ley de la Casa Imperial de 16 de enero de 1947, promulgada por la 92º sesión de la Dieta Imperial, retuvo la exclusión de las dinastas mujeres contenida en la ley de 1889. El gobierno del Primer Ministro Yoshida Shigeru remendó rápidamente la legislación para dar a la Ley de la Casa Imperial concordancia con la Constitución de Japón escrita por los estadounidenses, que entró en efecto en mayo de 1947. En un esfuerzo por controlar el tamaño de la familia imperial, la ley establece que sólo los legítimos descendientes varones en la línea de sucesión masculina pueden ser dinastas; que los príncipes y princesas imperiales pierden su estatus de miembros de la Familia Imperial si se casan fuera de ésta; y que el Emperador y otros miembros de la Familia Imperial no pueden adoptar hijos. También evitó que otras ramas que no descendiesen de Taisho accedieran a ser príncipes imperiales.

La Sucesión se regula por las leyes promulgadas por la Dieta de Japón. La ley actual excluye a las mujeres de la sucesión, si bien muy ocasionalmente las mujeres ocuparon el trono en siglos precedentes. Un cambio a esta ley ha sido considerado desde 2005 dado que el Príncipe Heredero Naruhito es padre sólo de una niña. Esto crea un desafío tanto logístico como político: cualquier cambio en la ley puede significar una revisión para establecer la sucesión en el primogénito más que en el primer varón; no obstante, el actual emperador no es el primogénito, sino que tiene hermanas mayores.

Hay una potencial crisis sucesoria dado que no han nacido niños varones en la familia imperial desde el Príncipe Akishino en 1965. Luego del nacimiento de la Princesa Aiko, ha habido cierto debate público sobre la enmienda a la Ley de la Casa Imperial para permitir a las mujeres suceder en el trono. En enero de 2005, el Primer Ministro Jun'ichirō Koizumi designó a un panel especial compuesto de magistrados, catedráticos e intelectuales en orden a estudiar cambios en la Ley de la Casa Imperial y para hacer recomendaciones al gobierno.

El panel referido recomendó el 25 de octubre de 2005 enmendar la ley para permitir a las mujeres de la descendencia masculina ascender al trono japonés. El 20 de enero de 2006, el Primer Ministro Jun'ichirō Koizumi dedicó parte de su cuenta anual a la controversia, plegándose a la idea de convocar a un plebiscito para permitir a las mujeres ascender al trono para asegurar que la sucesión continúe de manera estable. Sin embargo, poco después del anuncio de que la Princesa Kiko estaba embarazada por tercera vez, Koizumi suspendió estos planes. El 6 de septiembre de 2006, la esposa del Príncipe Fumihito dio a luz a un varón, el Príncipe Hisahito, y que es el tercero en la línea de sucesión, luego de su tío el Príncipe Naruhito y de su padre.

El emperador es símbolo del Estado japonés y de unidad colectiva, el trono imperial es dinástico, y la sucesión de acuerdo con la Ley de la Casa Imperial debe ser aprobada por la Dieta; tiene funciones de consejo y aprobación en cuestiones de Estado y el gabinete es responsable ante él, delega el cumplimiento de sus actos en cuestiones de Estado tal como sea previsto por ley, lleva adelante solamente los actos en cuestiones de Estado y no tiene poderes relativos al gobierno, asimismo, la Casa Imperial no debe recibir nada sin permiso previo de la Dieta, toda propiedad de la misma corresponde al Estado y los gastos son determinados por la Dieta.




</doc>
<doc id="28124" url="https://es.wikipedia.org/wiki?curid=28124" title="Conferencia de Paz de París (1919)">
Conferencia de Paz de París (1919)

La Conferencia de Paz de París fue la reunión en 1919 de los Aliados después del armisticio para acordar las condiciones de paz con los países de las Potencias Centrales: Alemania, el Imperio otomano, Bulgaria, Austria y Hungría, estos dos últimos como representantes del desaparecido Imperio austrohúngaro. Los aliados empezaron sus labores de negociación entre sí el 18 de enero de 1919 bajo la dirección del "Comité de los Cuatro": Wilson, Clemenceau, Lloyd George y Orlando, aunque los que realmente dirigieron las negociaciones fueron los tres primeros. A los países vencidos no se les dejó asistir a estas reuniones, así que los que decidieron el futuro de los vencidos, fueron los países vencedores, que tenían distintas posturas.





A partir de junio de 1919 se presentan los tratados para su firma a los países derrotados. 

De las muchas disposiciones del tratado, una de las más importantes y controvertidas rezaba que Alemania y sus aliados aceptasen toda la responsabilidad de haber causado la guerra y, bajo los términos de los artículos 231-248, desarmarse, realizar importantes concesiones territoriales y pagar indemnizaciones a los estados vencedores. El Tratado fue socavado tempranamente por acontecimientos posteriores a partir de 1922 y fue ampliamente violado en los años treinta con la llegada al poder del nazismo.


El Tratado de Saint-Germain-en-Laye fue firmado el 10 de septiembre de 1919 entre las potencias aliadas y Austria. En este tratado se establecía el desmembramiento de la antigua monarquía de los Habsburgo, el Imperio Austrohúngaro, y Austria quedó limitada a algunas zonas en las que se hablaba solamente el alemán.

Mediante este tratado se reconocía la independencia de Hungría y la creación de los nuevos estados de Checoslovaquia (con Bohemia, Moravia, Silesia y Eslovaquia) y Yugoslavia (con Eslovenia, Bosnia y Herzegovina, parte de Dalmacia, Croacia y Voivodina). Hungría cedería Transilvania, parte del Bánato y Bucovina a Rumania, algo que se concretó en el Tratado de Trianón, y el Burgenland a Austria. 

Polonia se anexó Galitzia e Italia obtuvo el Trentino, Tirol del Sur, Trieste e Istria, sin embargo, los ingleses se negaron a cumplir completamente lo acordado en el Tratado de Londres oponiéndose a que Italia recuperara Dalmacia, antiguo territorio veneciano. Esto último fue visto por los italianos como una traición por parte de Inglaterra y fue uno de los principales motivos que llevaron al posterior ascenso del Fascismo.

Una cláusula importante era la prohibición de revisar o revocar la independencia de Austria, con el fin de impedir una unión política y/o económica con Alemania (Anschluss), sin la autorización de la Sociedad de Naciones, ya que tras la pérdida de su Imperio los austriacos se plantearon la posibilidad de la unificación fracasada en 1866 tras la Guerra Austro-Prusiana.

El Tratado de Trianon, firmado posteriormente entre los aliados y Hungría, completa el proceso de desmembramiento del Imperio Austrohúngaro.

Con este tratado, la mitad de los doce millones de habitantes del Imperio que eran de lengua alemana quedaron fuera de la nueva República de Austria, como fueron los Sudetes en Checoslovaquia, la región del Tirol del Sur, con capital en Bolzano, en Italia, y algunas comunidades en Hungría y Transilvania. Esto llevó a problemas que precedieron la Segunda Guerra Mundial.

La desintegración del Imperio Austrohúngaro causó tensiones y dificultades entre las nuevas naciones. Austria quedó reducida a un territorio de 80.000 km² con una población de unos 6 millones de habitantes, un tercio de los cuales vivían en Viena que se convirtió en una capital muy grande para un país tan pequeño. Se le prohibió unirse a Alemania y fue obligada a pagar compensaciones de guerra y a reducir su ejército a 30.000 soldados.

El Tratado de Neuilly-sur-Seine fue firmado el 27 de noviembre de 1919 en Neuilly-sur-Seine (Francia) entre Bulgaria y las potencias vencedoras en la Primera Guerra Mundial.

De acuerdo con lo estipulado en el tratado, Bulgaria reconocía el nuevo Reino de Yugoslavia, pagaba 400 millones de dólares en concepto de indemnización y reducía su ejército a 20.000 efectivos. Además, perdía una franja de terreno occidental en favor de Yugoslavia y cedía Tracia occidental a Grecia, por lo que quedaba sin acceso al Mar Egeo.

El tratado es conocido en Bulgaria como la "Segunda Catástrofe Nacional", siendo la primera su derrota en la Guerra Balcánica de 1913.

Hungría proclamó su independencia frente a Austria en el 16 de noviembre de 1918. Las fronteras temporales «de facto» de Hungría fueron las mismas que las trazadas por las líneas de la tregua de noviembre-diciembre de 1918. En comparación con el antiguo Reino de Hungría, esas fronteras no incluían:





La Triple Entente pidió reconocer a Hungría los nuevos territorios pertenecientes a Rumanía, a través de una línea trazada a lo largo del río Tisza. Sin la posibilidad de rechazar esos términos, pero tampoco queriendo aceptarlos, los líderes de la Primera República Húngara dimitieron y los comunistas llegaron al poder. Se formó la República Soviética Húngara y se organizó rápidamente un Ejército Rojo Húngaro. Ese Ejército tuvo, en un principio, éxito en contra de las legiones checoslovacas y llegó cerca de la antigua frontera de Galitzia (polaca), separando de esa manera a las tropas checoslovacas de las tropas rumanas. En el 1 de julio de 1919 se firmó la cesación de hostilidades entre el Ejército Rojo y las tropas checoslovacas, mientras que las tropas rumanas cruzaron el río Tisza, derrotaron al Ejército Rojo y ocuparon Budapest en el 4 de agosto de 1919.

El Estado húngaro fue restablecido por la Triple Entente, quien ayudó al almirante Horthy a llegar al poder, en el mes de noviembre de 1919. En diciembre de 1919 una delegación húngara fue invitada a la Conferencia de Paz de Versalles. Las fronteras definitivas de Hungría fueron establecidas por el Tratado de Trianon, firmado en el 4 de junio de 1920. Además de los territorios mencionados anteriormente, Hungría perdió otros territorios ocupados como parte del Imperio austrohúngaro:


Conforme al Tratado de Trianon, las ciudades Pécs, Mohács, Baja y Szigetvár, temporalmente bajo administración yugoslava, pasaron a Hungría. Un comité asignó pequeñas partes del norte de los antiguos distritos Árva y Szepes a Polonia, puesto que ahí vivía una mayoría de población polaca.

Los dirigentes de Francia, Gran Bretaña y los Estados Unidos declararon sus diferentes objetivos en relación con el Imperio otomano durante la Conferencia de Paz de París, 1919. 

El Tratado dejaba al Imperio otomano sin la mayor parte de sus antiguas posesiones, limitándolo a Estambul y parte de Asia Menor. En Anatolia Oriental se creaba un estado autónomo para los kurdos (Kurdistán), y varios distritos pasaban a Armenia (la República de Armenia se independizó de Rusia en 1918) para formar la Gran Armenia. Grecia recibía Tracia Oriental, Imbros, Ténedos y la región de Esmirna. Se reconocía la separación de Egipto, Hedjaz y Yemen; mientras que Mosul, Palestina y Transjordania pasaban a administración británica y Siria, Líbano y Alejandreta a administración francesa, que también recibía una zona de influencia en Cilicia. Chipre quedó para los británicos que ya lo administraban y Castellorizo para los italianos con una zona de influencia en la región de Antalya. La navegación en los estrechos sería libre y controlada por una comisión internacional.

El Tratado logró la expulsión del Imperio otomano de Europa. Esto había sido el sueño del cristianismo durante casi quinientos años contados a partir de la Liga Santa, se le puso la condición al Imperio otomano, tal que nunca podía ser reactivado de nuevo en su antigua forma.

Se configuró un nuevo mapa político de Europa creándose nuevas naciones: Yugoslavia, Checoslovaquia, Hungría, Finlandia, Estonia, Letonia y Lituania. Se ratificaron las fronteras de los países vencidos. También se creó el conocido como "Cordón sanitario" para aislar el mundo capitalista del comunista.

La delegación de Japón, encabezada por Makino Nobuaki, planteó el reconocimiento de la igualdad racial en los estatutos de la Sociedad de Naciones, pero su petición no fue atendida. Desde el principio la delegación japonesa no fue tratada igual que los "cuatro grandes" y no sólo se les asignó un puesto en el extremo de la mesa de las negociaciones, sino que sus miembros tuvieron que soportar comentarios denigratorios y chistes racistas —el presidente francés Georges Clemenceau, por ejemplo, se quejó de tener que estar junto a los «feos» japoneses en una ciudad llena de atractivas mujeres rubias; el presidente australiano Billy Hughes, defensor a ultranza de una "Australia Blanca", hizo chistes sobre el canibalismo en referencia a los pueblos del Pacífico—. En el curso del debate sobre la igualdad racial, cuando al británico Lord Balfour se le argumentó que en la Constitución de Estados Unidos se reconocía que «todos los hombres son creados iguales», él respondió que no creía que «un hombre de África central fuera creado igual que un europeo». Entonces Makino pidió que se votara la propuesta y consiguió que fuera aprobada por la mayoría de los países representados en la conferencia, pero la oposición de Gran Bretaña y sus Dominios, especialmente Australia, fue tan radical que finalmente el presidente norteamericano Woodrow Wilson dictaminó que el voto quedaba anulado debido a la disconformidad expresada por varios países. Como ha señalado el ensayista indio Pankaj Mishra, la resolución en la que se rechazaba la igualdad racial «iba a ser recordada durante décadas por los nacionalistas japoneses».

Según este mismo autor indio, Wilson no respaldó la propuesta japonesa —que en el fondo respondía a los principios expresados en los Catorce Puntos— porque, además de que podía poner en cuestión la legislación antiasiática de Estados Unidos, «temía perder el apoyo de los británicos y de sus aliados australianos. En gran medida, la anglofilia cegaba a Wilson y a sus asesores (en su mayoría miembros de la élite blanca anglosajona y protestante de la costa Este), lo que le impedía ver la pasión anticolonial que existía en Asia y África».

Los vencidos, sobre todo Alemania, se quedaron con la sensación de haber sido tratados injustamente (revanchismo y nacionalismo), que, entre otras cosas, causaría el estallido de la Segunda Guerra Mundial. Además no se resolvió el problema de las nacionalidades quedando en evidencia el principio teórico de las negociaciones.


</doc>
<doc id="28133" url="https://es.wikipedia.org/wiki?curid=28133" title="Kartum">
Kartum

Kartum es el título de una película británica del género de cine histórico de tipo bélico, dirigida en 1966 por el director cinematográfico Basil Dearden, con la participación de actores de renombre, como Charlton Heston, Laurence Olivier, Ralph Richardson, Richard Johnson, Alexander Knox y Johnny Sekka. La película fue nominada a un Oscar de la Academia.

En 1883, el Primer Ministro británico Gladstone (Richardson) envía al General Charles Gordon (Charlton Heston) a Jartum, Sudán, donde miles de civiles viven bajo la amenaza del fanático musulmán autodenominado como el Mahdi (Lawrence Olivier), y sus ejércitos de seguidores llamados los derviches. El Mahdi ha reforzado su autoridad al masacrar un ejército de soldados sudaneses probritánicos y amenazan con extender su influencia por toda la región.

El Muhammad Ahmad-El Mahdi es un místico líder musulmán que se siente llamado por el profeta "Mahomed-El Bendecido" para hacer huir a sus enemigos infieles (el Imperio otomano y el británico) de sus tierras ancestrales y sus intenciones son nada menos que llegar hasta Constantinopla.

Gordon es un militar británico que camina entre la marcialidad inglesa cumpliendo las órdenes del Imperio británico y un espíritu renegado y con un profundo amor nacionalista a los sudaneses. El Imperio británico, representado por Gladstone, se resiste a enviar refuerzos al Sudán debido a que la presencia de tropas puede desestabilizar la región y pretende abandonar Sudán. Gordon se opone a las intenciones británicas y es en esta postura renegada la que acarrea la respuesta de los derviches y se desata una cruenta yihad por parte de El Mandhi.

Gordon consigue ganarse el respeto de El Mahdi al presentarse sin armas y solo acompañado por un ayudante al campamento enemigo pidiendo una tregua; pero el Mahdi no puede impedir que sus seguidores sitien la ciudad. En este momento en que el destino de la historia se encuentra pendiente de un hilo, Gordon se enfrenta a la mayor batalla de su vida en defensa de la ancestral ciudad de Jartum.

Charton Heston como el General Gordon y Laurance Olivier como el Mahdi, ambos ganadores de premios Oscar de la Academia, se enfrentan actoralmente en este épico y conmovedor drama personificando con gran calidad artística a dos hombres aguerridos, místicos y sólidos en sus convicciones; pero que se respetan entre sí y dos imperios que se oponen por una región convulsionada por el fanatismo religioso de los derviches y los intereses colonialistas británicos. 
La batalla final por la sitiada ciudad de Jartum termina de manera ignominiosa para los intereses británicos.

Filmada en Cinerama, con asombrosas batallas en el desierto orquestadas por el creador de la carrera de cuadrigas de "Ben-Hur", "Kartum" ofrece un magnífico espectáculo de acción con excelentes interpretaciones y asombrosa cinematografía, si bien se pierde por un exceso de diálogos haciéndola poco dinámica, aspecto que es acentuado al no aprovechar al máximo la espectacularidad de la historia, hechos y escenarios.

Por lo que se refiere a los aspectos técnicos, la película fue rodada en Ultra Panavision 70 mm y presentada en "Cinerama", lo que dota de gran vistosidad a varias escenas, en especial las relativas a combates en el desierto. Destaca la actuación de Lawrence Olivier como el Mahdi.

Añadir que, inicialmente el papel del General Gordon iba a recaer en el actor Burt Lancaster, propuesta que tuvo que rechazar al coincidir con otro rodaje: "El Gatopardo".


La película fue nominada a un Oscar al mejor guion original.



</doc>
<doc id="28134" url="https://es.wikipedia.org/wiki?curid=28134" title="Who's Afraid of Virginia Woolf?">
Who's Afraid of Virginia Woolf?

Who's Afraid of Virginia Woolf? es una película estadounidense de 1966 de comedia negra y drama dirigida por Mike Nichols. El guión de Ernest Lehman es una adaptación de la obra teatral del mismo título de Edward Albee. Tuvo como protagonistas a Elizabeth Taylor como Martha y Richard Burton como George, con George Segal como Nick y Sandy Dennis como Honey.

La película fue nominada a trece Premios Oscar, incluyendo Mejor Película y Mejor Director por Mike Nichols, y es una de las dos únicas películas en ser nominada en todas las categorías elegibles (la otra es "Cimarron"). Los cuatro actores principales de la película fueron nominados en sus respectivas categorías de actuación. De gran éxito de público en el momento de su estreno, lanzó a la fama a un joven realizador que en 1967 reeditaría el éxito de crítica y público con otro clásico, "El graduado".

La película ganó cinco premios, incluyendo un segundo premio de la Academia a la Mejor actriz por Elizabeth Taylor y el de Mejor actriz de reparto por Sandy Dennis. Sin embargo, la película pierde frente a "A Man for All Seasons" en las categorías Mejor película, Mejor director, Mejor actor y Mejor guion adaptado, y ni Richard Burton ni George Segal ganaron en sus categorías. En 2013, la película fue seleccionada para su preservación en el Registro Nacional de Cine de la Biblioteca del Congreso de los Estados Unidos como "cultural, histórica o estéticamente significativa". Además, se la reconoce como uno de los filmes más importantes de la carrera de Elizabeth Taylor, por su actuación y por el gran elenco que compone la producción.

El título hace una referencia a la famosa escritora Virginia Woolf y a su apellido, utilizándolo como una parodia de la frase y canción clásica de Frank Churchill y Ann Ronell, "Who's Afraid of the Big Bad Wolf?" ("¿Quién le teme al lobo feroz?").

La película se centra en un vecindario inglés de la universidad de Nueva Inglaterra, se basa en la relación volátil de un profesor de Historia en la universidad llamado George y su esposa alcohólica Martha, quien además era la hija del presidente de la universidad. George y Martha se involucran en juegos emocionales entre sí, pero ignorando que es peligroso. Ambos van a una fiesta y al salir de aquel lugar, eran las dos de la madrugada, razón en la que Martha llega a su casa con su esposo y producen una pequeña discusión en cuanto a las películas de Bette Davis.

Después de la discusión, Martha revela que había invitado a un joven matrimonio, a quien conoció en la fiesta para tomar una copa. George no acepta al ver que era tarde, pero al final, termina aceptando las ideas y decisiones de su esposa. Luego, llegan los huéspedes, Nick, un profesor de biología (Martha piensa que enseña matemáticas en la pequeña discusión anterior) y su esposa, Honey. Mientras los cuatro comienzan a beber, Martha y George son capaces de practicar un abuso verbal frente a los invitados, ellos sienten vergüenza y revelan que era mejor no haber ido, pero más tarde se quedan al enredarse con el matrimonio de George y Martha. 

Honey y Martha se separan un tiempo de los esposos, Martha decide mostrarle la casa a su amiga. Cuando regresan, Honey revela que Martha le ha mencionado asuntos relacionados de su hijo y el de George y añade que al día siguiente (domingo) marcará su decimosexto cumpleaños. George se enoja ya que anteriormente le pidió a Martha no comentar sobre este tema y Martha ha divulgado esta información. 

Más tarde, Martha se burla de George agresivamente y este se aleja de los huéspedes y de su esposa para ir a otra habitación de la casa. Martha cuenta una historia muy vergonzosa de cómo ella humilló a George delante de su padre. Las burlas de Martha continúan y George reacciona violentamente tomando una escopeta y trata de dispararle a Martha. Al disparar, Honey se asusta y grita, pero se trataba de un paraguas que se abrió al disparar. Después de esta pesada broma, Martha continúa burlándose de George y este rompe una botella como producto de su enojo. Nick y Honey son cada vez más inestables, y Honey pronto corre al baño a vomitar, debido al exceso de alcohol.

La película fue la única nominada para los Premios Óscar en cada categoría en la que podía ser elegible (película, actor, actriz, actor de reparto, actriz de reparto, director, guion, dirección artística/decoración del set (blanco y negro), cinematografía (blanco y negro), sonido, diseño de vestuarios (blanco y negro), música y montaje). 

Cada uno de los cuatro actores fue nominado para un Oscar, pero sólo Elizabeth Taylor (Oscar a la mejor actriz) y Sandy Dennis (Oscar a la mejor actriz de reparto), lo ganaron. La película también ganó el premio de Oscar a la mejor fotografía en blanco y negro por el gran trabajo de cámara de Haskell Wexler (fue la última película en ganar en dicha categoría antes de que fuera eliminada). También recibió:

Recibió además:


Un gran duelo interpretativo entre Richard Burton y Elizabeth Taylor, por aquel entonces casados, bien secundado por la otra pareja protagonista del filme, George Segal y Sandy Dennis. Célebre por contener una de las mejores interpretaciones, si no la mejor, de Taylor y por una puesta en escena brillante que, sin deshacerse de su origen teatral, logra tener entidad propia como largometraje.



</doc>
<doc id="28135" url="https://es.wikipedia.org/wiki?curid=28135" title="Benimámet">
Benimámet

Benimámet (en valenciano y oficialmente Benimàmet) es una pedanía de Valencia, situada en el noroeste de su término municipal, en el distrito de Poblados del Oeste limitando con las poblaciones de Burjasot y Paterna. Su población censada en 2012 era de 14.174 habitantes (INE). Fue un municipio independiente hasta 1882, año en que pasó a ser una pedanía de Valencia. Conforma, junto con Beniferri, el distrito de Poblados del Oeste (en valenciano "Poblats de l'Oest"). En sus alrededores se encuentra ubicada la Feria Muestrario Internacional de Valencia y el Velódromo Municipal Lluís Puig.

El término Benimámet proviene de la forma árabe "Benimahaber", "Benimahabar" o "Benimabar", probablemente escrita ("Banī Maḥbar"). Sin embargo, también se lo ha hecho derivar de ("Banī Muḥammad"). Carmen Barceló, por su parte, defiende la forma ("Banī Maḥbit"), antropónimo árabe conocido. En todo caso, el topónimo deriva de un antropónimo formado por "banī" («hijos de») y el nombre en cuestión. La actual forma Benimámet aparece mencionada por primera vez en 1310.

En Benimámet pudo haber un asentamiento romano, dado que ha habido en su término algunos hallazgos, sobre todo monetarios. Sin embargo, sólo hay certeza de que fue una alquería andalusí, y apenas se tiene documentación anterior a su conquista por Jaime I de Aragón. Su primera mención aparece en el Llibre del Repartiment con la forma "Benimahaber". En él consta que el 21 de agosto de 1238 se entegan a Sanchis de Stada de los bienes pertenecientes hasta entonces a Hibraim Alfachar.

La incorporación a Valencia como municipio anexionado, respondía a la ley que permitía a las ciudades anexionarse municipios limítrofes de una población inferior a 2000 habitantes. Por ello, a finales de la década del siglo XX, surge un movimiento de segregación representado por el colectivo "Benimàmet Poble" amparado en la escasa atención prestada por el Ayuntamiento de Valencia a la población de Benimámet y en la comparación de las infraestructuras propias de la pedanía con las de las poblaciones colindantes, iniciándose así, el largo proceso jurídico-administrativo que pretende segregar a la población de la ciudad de Valencia.

Benimámet se encuentra al noroeste de la ciudad de Valencia, está considerado como parte de Valencia. La superficie geográfica es llana en gran parte. Aunque, en la zona noreste, en la zona de la Feria de Valencia se eleva entre diez y veinte metros más que en el centro de Benimámet, misma que se encuentra a cuarenta y tres msnm.. En cuanto a la distancia, se encuentra a cinco kilómetros con setecientos metros de Valencia.

Benimámet limita, al oeste con Paterna, al norte con Burjasot, al sur con la Huerta Valenciana y al este con Valencia.

Benimámet tiene características de población dormitorio de Valencia. A prinicipios del siglo XX fue lugar de segunda residencia para algunos miembros de la pequeña burguesía de la capital que en verano habitaban los chalets del barrio de Las Carolinas, así como en la parte norte de la Calle Felipe Valls y Plaza de Luis Cano. De aquella época han quedado todavía algunos chalets y viviendas de recreo, aunque un número importante han sido pasto de la construcción de pisos. En la década de 1950 y, de manera continuada desde entonces, Benimámet ha aumentado de población gracias a la inmigración que ha recibido de las provincias de Teruel, Cuenca y del interior de Valencia.

A lo largo de los años 1970 llegaron inmigrantes procedentes de Andalucía, particularmente de la provincia de Jaén, y en la actualidad la población continúa acogiendo inmigración de origen pakistaní, de países africanos, de América latina, del Magreb y de Europa del este, convirtiendo a la población en una amalgama cultural y pluriétnica.

Benimámet depende del ayuntamiento de Valencia en consideración de barrio del distrito de Poblados del Oeste (en valenciano "Poblats de l'Oest"). Sin embargo, dada su condición de poblamiento rural, cuenta, de acuerdo con las leyes estatales y autonómicas pertinentes, con un alcalde de barrio, compartido con Beniferri, que se encarga de velar por el buen funcionamiento del barrio y de las relaciones cívicas, firmar informes administrativos y elevar al ayuntamiento de la ciudad las propuestas, sugerencias, denuncias y reclamaciones de los vecinos.

Al tratarse de una ciudad dormitorio, la mayor parte de sus habitantes trabajan fuera de la población, razón por la cual, en la actualidad, tanto la industria como la agricultura tienen una importancia marginal en la economía de la población.

Históricamente, la actividad principal de Benimámet fue la agricultura (cítricos fundamentalmente) y alguna pequeña industria manufacturera, aunque entre los años sesenta y ochenta del siglo XX tuvo cierta importancia la fabricación de muebles, particularmente Sanfélix Villarrubí, donde a principios de los setenta del siglo pasado llegó a tener más de cien trabajadores. En la actualidad, a consecuencia del urbanismo desaforado que sufre la población las zonas dedicadas a la agricultura son mínimas. 

Una importante fuente de ingresos la constituye el turismo de convenciones dada la proximidad de la Feria Muestrario Internacional de Valencia, o más conocida como la Feria de muestras.

Se fundó en 1917, en la actualidad se organizan alrededor de 40 eventos anuales, más de la mitad son eventos internacionales. Se ha contabilizado más de un millón trescientos mil visitantes. Con un presupuesto anual de 75 millones de euros, se estima un impacto económico de 750 millones de euros anuales en promedios. Existe un calendario de ferias.











Benimámet tiene muchos lugares ajardinados, lo que constituye en la posibilidad de encontrar muchos lugares de esparcimiento y recreo: la Plaza Luis Cano que dispone de área infantil de reciente acabado, el Parque Camales con áreas infantiles, deportiva y para mayores, también hace poco arreglados y este último pintados, el Parque del Chalet Panach en la calle Campamento y a las afueras del Velódromo Lluis Puig es posible la práctica deportiva y el esparcimiento.

Se celebran en marzo, como en muchos pueblos de Valencia, las Fallas dedicadas a San José. Benimámet agrupa 5 fallas, siendo la más antigua, creada en el año 1944, la Falla de Benimámet-Plaza Luis Cano (que en la dictadura fue protagonizada por los elementos más pro-régimen del pueblo). También está la Falla del Secanet, barrio de tradición inmigrante, la Falla de la Plaza de la Tienda, la Falla Evaristo Bas-Cullera y la Falla Campamento-La Yesa. 

En Verano las fiestas consideradas patronales: San Francisco de Paula, por los agricultores, y San Vicente Mártir, patrono del pueblo, y fiesta que de alguna manera ha sido utilizada por ciertos sectores más creyentes. En el barrio de Las Carolinas, la Fiesta de San José, que actualmente cuenta con mucha popularidad.

Las fiestas más antiguas son a la Virgen del Rosario que hoy no se celebra, la Minerva que es por tradición familiar, la custodia del Altísimo y San Vicente Mártir que en la actualidad es la fiesta con más clavarios. Desde 1885 se celebra a San Francisco de Paula por el milagro de la salvación del cólera y que hoy cuenta con numerosos devotos ("véase": Pandemias de cólera en España).
También en Benimámet se celebra la cabalgata de Reyes, la Bendición de los Animales de San Antonio Abad, la cruz de Mayo en la plaza de Camporrobles, el canto de "los mayos" por diferentes entidades festeras y falleras, la noche de San Juan, se celebraba la Virgen de Agosto y San Agustín con grandes festejos y también se celebra la patrona de la música, Santa Cecilia, que clavariesas y la Banda de Música de la Sociedad Instructiva del Obrero Agrícola y Musical llenan las calles de festejos musicales.

Benimámet cuenta actualmente con 2 centros de Educación Infantil, 3 colegios de Educación Primaria y un instituto, así como diversos centros de enseñanza extraescolar. Destaca asimismo la Sala Cervantes como centro de iniciativas culturales. Asimismo, en Benimámet se sitúa una sede de la Universidad Popular de Valencia, en la que se realizan actividades de culturización, expresión plástica y corporal y formación ocupacional, entre otras. 

Benimámet cuenta además con la biblioteca Teodoro Llorente, ubicada en el Chalet de Panach. Ésta fomenta la investigación y la lectura con su amplio catálogo de libros, CD y DVD, además de libre disposición de Internet por WIFI.


Francisco Mir Belenguer, (nacido en 1934), pintor de estilo impresionista y luego realista



</doc>
<doc id="28136" url="https://es.wikipedia.org/wiki?curid=28136" title="Risky Business">
Risky Business

Risky Business (titulada "Negocios arriesgados" en México, "Negocios riesgosos" en Hispanoamérica y "Risky Business" en España) es una película estadounidense de 1983, escrita y dirigida por Paul Brickman. Fue protagonizada por Tom Cruise, Rebecca De Mornay, Richard Masur, Bronson Pinchot y Joe Pantoliano. 

Los padres de Joel (Tom Cruise) se van de viaje un tiempo y éste se queda solo en casa. Una noche decide contratar los servicios de Lana (Rebecca De Mornay) y empiezan a verse con frecuencia, hasta que el proxeneta de la prostituta (Joe Pantoliano) empieza a ver la situación con malos ojos y amenaza al chico si no deja de ver a Lana. Entonces, Joel y Lana deciden ofrecer servicios sexuales en casa de él con compañeras de la misma Lana, lo que enfurece más al proxeneta y, por ello, decide vengarse.




</doc>
<doc id="28137" url="https://es.wikipedia.org/wiki?curid=28137" title="Teorema de Sarkovskii">
Teorema de Sarkovskii

Sea una aplicación continua "f" : formula_1formula_2. Si esta función tiene un punto periódico de período "k", entonces tiene puntos periódicos de todos los períodos inferiores a "k" según el orden "«" siguiente:

Este teorema es "óptimo", es decir, si m « k según el orden precedente, existen aplicaciones continuas con puntos periódicos de periodo m pero sin punto periódico de período k. 
En particular, una función que presenta un punto x periódico de orden tres, es decir tal que:

donde formula_3 es la composición de las funciones, entonces presentará puntos periódicos de cualquier orden:

Se dice que el periodo tres implica el caos, y esta propiedad es fundamental en la teoría del caos.
Este corolario recibe el nombre de Teorema de Li y Yorke, matemáticos que redescubrieron en Estados Unidos parte del teorema ruso, que había pasado totalmente inadvertido en Occidente.

El ejemplo fundamental es "f(x)= a·x·(1 - x)", con "x" en el intervalo [ 0; 1], y "a" en [0; 4]. Cuando "a" crece de 0 a 4, va apareciendo puntos periódicos de orden 2, luego 4, luego 8, 16, ... y finalmente 3.

En las abcisas está el parámetro a. El período 3 aparece para "a" algo mayor que 3,8, justo al salir de la zona caótica (en gris). 

El teorema utiliza el que R es totalmente ordenado y unidimensional, no se aplica a los números complejos:
La función "f" :C →C definida por f(z) = e·z es tal que todos los puntos del plano son periódicos de orden 3, pero de ningún otro orden (excepto 0 que es de orden 1) - f es una rotación de ángulo 120 grados o 2·π/3 radianes y no existe equivalentes de las rotaciones en una dimensión.


</doc>
<doc id="28139" url="https://es.wikipedia.org/wiki?curid=28139" title="Teorema de Li y Yorke">
Teorema de Li y Yorke

El teorema de Li y Yorke es un teorema matemático que afirma que, siendo "f": R → R una aplicación continua, si "f" tiene un punto periódico de periodo 3 entonces tiene puntos de cualquier periodo.



</doc>
<doc id="28140" url="https://es.wikipedia.org/wiki?curid=28140" title="Pan (mitología)">
Pan (mitología)

Pan (en griego, Πάν) era el semidiós de los pastores y rebaños en la mitología griega. Era especialmente venerado en Arcadia, a pesar de no contar con grandes santuarios en su honor en dicha región. En la mitología romana se identifica a este dios como un Fauno.

Pan era también el dios de la fertilidad y de la sexualidad masculina. Dotado de una gran potencia y apetito sexual, se dedicaba a perseguir por los bosques, en busca de sus favores, a ninfas y muchachas. En muchos aspectos, el dios Pan tiene cierta similitud con Dioniso.

Era el dios de las brisas del amanecer y del atardecer. Vivía en compañía de las ninfas en una gruta del Parnaso llamada Coricia. Se le atribuían dones proféticos y formaba parte del cortejo de Dioniso, puesto que se suponía que seguía a este en sus costumbres. Era cazador, curandero y músico. Habitaba en los bosques y en las selvas, correteando tras las ovejas y espantando a los hombres que penetraban en sus terrenos. 

Portaba en la mano el cayado o bastón de pastor y tocaba la siringa, a la que también se conoce como Flauta de Pan. Le agradaban las fuentes y la sombra de los bosques, entre cuya maleza solía esconderse para espiar a las ninfas. 

Se dice que Pan era especialmente irascible si se le molestaba durante sus siestas. Los habitantes de Arcadia tenían la creencia de que, cuando una persona dormía la siesta, no se la debía despertar bajo ningún motivo ya que, de esa forma, se interrumpía el sueño del dios Pan. En este caso, Pan se aproxima a la noción de Demonium Meridianum (Demonio del Mediodía).

Por último, como deidad, Pan representaba a toda la naturaleza salvaje. De esta forma, se le atribuía la generación del miedo enloquecedor. De ahí la palabra pánico que, en principio, significaba "el temor masivo que sufrían manadas y rebaños ante el tronar y la caída de rayos".

Pan tiene diecinueve genealogías diferentes; en la mayoría de ellas su padre fue Hermes, en tanto que el nombre de la madre varía (usualmente ésta pertenecería a la raza de las ninfas; una hija de Dríope, Timbris, Sose, Calisto u Orneo). 

Según una de las tradiciones, cuando Hermes pastoreaba los rebaños de Dríope, tuvo una relación amorosa con una de las hijas de éste, de la que nació el dios Pan. Según esta versión, cuando nació, presentaba sus miembros inferiores en forma de macho cabrío y el resto del cuerpo con apariencia de hombre. En la cabeza tenía dos cuernos y su cara era arrugada, con una barbilla prominente, con todo el cuerpo cubierto por una espesa capa de pelo. Se dice que, apenas nacido, escapó a las montañas, donde Hermes tuvo que buscarlo para llevarlo al Olimpo envuelto en una piel de liebre. Una vez allí, lo llamaron Pan, puesto que era la diversión de "todos".

Otra de las tradiciones cuenta que Penélope, durante la ausencia de su esposo Odiseo, tuvo varios amantes, quedando encinta de uno de ellos. De esta manera, nació Pan, nombre que significa "hijo de todos". 

Otra de ellas decía que, tras el regreso de sus viajes, Odiseo repudió a Penélope por sus infidelidades y que, una vez abandonada, concibió al dios Pan, fruto de su unión con Hermes.

Otras tradiciones apuntan a que fue hijo de Zeus y de la ninfa Hibris, de Zeus y Calisto o de Hermes y una ninfa.

En cuanto a su descendencia, varía según el autor. En las "Dionisíacas" de Nono se dice que Pan engendró a los doce Panes, una raza de sátiros menores que colaboraron con Dioniso. En otras fuentes aparece como padre de Croto (con Eufeme), Acis (con Simetis), Eurimedonte (sin especificar la mujer), Creneo (con la ninfa Isménide o Ismenis), Iinge (con la ninfa Eco) y finalmente el también célebre Sileno (habido con la Oceánide Melia).

En cuanto a sus relaciones, se dice que tuvo amores correspondidos con la ninfa Pitis, que también era pretendida por Bóreas. Este último, arrastrado por los celos, arrojó a Pitis desde lo alto de una roca. Sintiendo pena, la diosa Gea la transformó en pino, siendo Pan, desde entonces, coronado con las hojas del pino. También existe la creencia de que el pino gime cuando sopla Bóreas.

Asimismo, Pan estaba intensamente enamorado de la ninfa Siringa, quien no le correspondía. Se dice que una vez, mientras huía de Pan, se lanzó al río Ladón. Quedó acorralada y pidió ayuda a sus hermanas las ninfas quienes, conmovidas, la convirtieron en un cañaveral. Se cuenta que, cuando Pan llegó, sólo pudo abrazar las cañas que se mecían por el viento y el rumor que producían le causó tal agrado que decidió construir un nuevo instrumento musical con ellas. Así, creó la flauta siringa, en recuerdo de la ninfa de igual nombre.

Del mismo modo, sedujo a Selene regalándole un vellón de gran blancura. Desde entonces, ambos fueron venerados en una caverna del monte Liceo.

Según cuenta Heródoto, unos días antes de la batalla de Maratón, un mensajero ateniense que volvía de pedir ayuda a Esparta encontró al dios y éste le prometió que vencerían a los persas. Por ello, tras ganar efectivamente la batalla a causa de un súbito pánico en las filas enemigas, fue incluido entre los grandes dioses reconocidos por el estado. En la propia ciudad de Atenas se le consagró una de las grutas de la vertiente norte de la Acrópolis y se decretó en su honor una fiesta anual donde se realizaban carreras de antorchas.

También estaban consagrados a Pan los montes Ménalo, Lampea y Nomia, todos ellos en Arcadia. Por otra parte, en Licosura existía un santuario oracular de Pan. 

Los ritos de fertilidad originales fueron asumidos a partir del siglo V por las Bacantes, que duraron hasta bien entrada la Edad Media. Desde entonces, y hasta nuestros días, la imagen tradicional de Pan se asocia con la imagen del diablo (en forma de macho cabrío) y los aquelarres.














</doc>
<doc id="28141" url="https://es.wikipedia.org/wiki?curid=28141" title="Pan (satélite)">
Pan (satélite)

En astronomía, Pan es una de las lunas del planeta Saturno, llamada también Saturno XVIII. Es el más interno de los satélites conocidos de este planeta (apenas a 133 583 km del centro de Saturno), y se encuentra en la división Encke del anillo A de Saturno, de la que actúa como luna pastora, siendo responsable de mantenerla abierta. Fue descubierto por Mark R. Showalter en 1990 mientras examinaba las viejas fotografías obtenidas nueve años antes por el Voyager en su encuentro con Saturno.

También Pan, en la mitología griega, era el dios de los bosques, los campos y la fertilidad, hijo de Hermes, mensajero de los dioses, y de una ninfa. 

La existencia de un satélite en la división Encke fue predicha por Jeffrey N. Cuzzi y Jeffrey D. Scargle en 1985, basado en los bordes ondulados de la división que indicaba una distorsión gravitacional. En 1986 Showalter y su equipo infirió su órbita y masa modelando su estela gravitacional. Llegaron a una muy precisa predicción de 133.603 ± 10 km para el semieje mayor y una masa de 5–10 masas de Saturno, e infirieron que había un solo satélite dentro de la división. El actual semieje mayor difiere solo en 19 km y la masa actual es de 8,6 masas de Saturno.

El satélite fue encontrado después en la primera posición predicha. La búsqueda fue realizada considerando todas las imágenes del "Voyager 2" y usando cálculos computacionales para predecir si el satélite sería visible en condiciones favorables en cada una de ellas. Cada imagen cualificada del Voyager 2 con resolución mejor a ~50 km/Pixel muestra a Pan claramente. Entre todas, aparece en once imágenes del "Voyager 2".

La excentricidad orbital de Pan produce que la distancia entre él y Saturno varíe en cerca de 4 kilómetros. Su inclinación orbital, que debería causar que se mueva de arriba a abajo, no es distinguible del cero con los datos actuales. La división Encke, en la cual Pan orbita, es de cerca de 325 kilómetros de ancho.

Los científicos de "Cassini" han descrito a Pan como con forma de nuez debido a la cresta ecuatorial, similar a la del satélite Atlas, que es visible en las imágenes. La cresta se debe al material del anillo de Saturno que ha sido barrido desde la división Encke.

La división Encke contiene un anillo que es coincidente con la órbita de Pan, indicando que Pan mantiene las partículas en órbita de herradura.

El satélite fue nombrado el 16 de septiembre de 1991 basado en la figura mitológica Pan, quién fue (entre otras cosas) el dios de los pastores. Esta es una referencia al rol de Pan como el satélite pastor. También es designado como .

Fue descubierto por Mark R. Showalter en 1990 analizando las antiguas fotos de la sonda "Voyager 2" y recibió su designación provisional debido a que las imágenes del descubrimiento estaban fechadas en 1981.

También hay un asteroide llamado (4450) Pan.

Ha sido seleccionada como APOD ( Astronomy Picture of the Day ) el 13 de marzo de 2017



</doc>
<doc id="28145" url="https://es.wikipedia.org/wiki?curid=28145" title="Río Grande (película de 1950)">
Río Grande (película de 1950)

Río Grande ("Rio Grande") es una película estadounidense de 1950 dirigida por John Ford, que tiene como protagonistas a John Wayne y a Maureen O'Hara.

Junto con "Fort Apache" (1948) y "She Wore a Yellow Ribbon" ("La legión invencible", 1949), "Río Grande" integra la conocida como "trilogía de la caballería" de John Ford.

El coronel Kirby Yorke (John Wayne) combate a los apaches desde un fuerte cercano a la frontera con México. Su hijo, que ha fracasado en West Point, se alista, siendo enviado al regimiento del coronel Yorke, su padre. Dispuesta a sacarlo de allí, también llega al fuerte la esposa de Yorke (Maureen O'Hara), distanciada de él por el gran apego del coronel hacia el ejército y sus normas. Es el reencuentro del matrimonio tras muchos años de separación. En medio de un agrio conflicto familiar, la lucha con los indios se recrudece.





</doc>
<doc id="28146" url="https://es.wikipedia.org/wiki?curid=28146" title="Río Lobo">
Río Lobo

Río Lobo es un western procedente de Estados Unidos dirigido y producido por el conocido cineasta Howard Hawks en el año 1970, siendo la última película dirigida por éste, y que está protagonizada por los actores John Wayne, Jorge Rivero y Jennifer O'Neill.

Esta película supuso la quinta colaboración a lo largo de 22 años de John Wayne y del legendario director Howard Hawks, y cierra la trilogía de los ríos cinematográficos de la filmografía de Howard Hawks comenzada con "Río Bravo" (1959) y "El Dorado" (1966).

Este western clásico repleto de acción trata del espectacular robo de un tren de la Unión por las guerrillas confederadas. El coronel del tren (John Wayne) encarcela a los jefes enemigos Cordona (Jorge Rivero) y Tuscarora (Christopher Mitchum), pero los tres hombres acaban haciéndose amigos al terminar la guerra.

Tras esto, comienzan a buscar a los traidores de la Unión responsables de una serie de robos a trenes por parte de los confederados, y que los conducirá a la ciudad de Río Lobo, donde se les unirá la joven Shasta Delaney (Jennifer O'Neill), la cual destapa la trama de corrupción de la ciudad.


La película se estrenó en los Estados Unidos el 16 de diciembre de 1970 y en España el 11 de abril de 1971. Fue un éxito de taquilla. Según El País esta película, siguiendo los esquemas y la brillantez de los otros Ríos de Hawks, este western recrea con humor y sentido del espectáculo una trama de venganzas y ambiciones de oro, por lo que es un clásico. Fue, según "Alohacriticón", un buen western de Howard Hawks que supuso la despedida cinematográfica del estupendo director estadounidense.



</doc>
<doc id="28149" url="https://es.wikipedia.org/wiki?curid=28149" title="Sabrina (película de 1995)">
Sabrina (película de 1995)

Sabrina es una película dirigida por Sydney Pollack.

Sabrina (Julia Ormond) es la hija del chófer de una gran mansión. Está enamorada de David, el hermano menor (Greg Kinnear), que se dedica a la buena vida, mientras que Linus, el hermano mayor (Harrison Ford), dirige los negocios de la familia. David está decidido a casarse con Sabrina (después de que ella estuvo por varios años en París y se transforma en una bella dama) en contra de la opinión de su familia, que considera que la hija del chófer no es la esposa adecuada para él. Cuando Linus interviene para disuadir a Sabrina de la boda, en lo que utiliza toda clase de artimañas, ella descubre que a quien quiere realmente es a Linus.

La película es un remake del filme también titulado Sabrina de 1954 dirigido por Billy Wilder, con Humphrey Bogart, Audrey Hepburn y William Holden. Fue nominada a dos Oscar.




</doc>
<doc id="28151" url="https://es.wikipedia.org/wiki?curid=28151" title="Escila">
Escila

En la mitología griega, Escila (en griego Σκύλλα) es un monstruo marino que anteriormente fue una hermosa ninfa hija de Forcis y Ceto.

Escila es descrita como un monstruo con torso de mujer y cola de pez, así como con seis perros partiendo de su cintura con dos patas cada uno, haciendo un total de doce; según otras versiones, sería un ser con seis largos y serpentinos cuellos con cabezas grotescas, mientras que sus doce patas serían de otra naturaleza; finalmente, según otras fuentes, compartiría algo de ambas descripciones. Sin embargo, se dice siempre que poseía en cada cabeza tres apretadas hileras de afilados dientes, así como que emitía un aullido estridente similar al de un perro.

Este ser habitaba en un estrecho paso marítimo, en el lado opuesto a su contraparte Caribdis. Los lados del canal estaban dentro del alcance de una flecha, de modo que los barcos que intentasen evitar a Caribdis deberían acercarse a Escila, y viceversa. Con el tiempo fue transformada por los dioses en una roca, aún existente, que suponía graves peligros para los navegantes.

Esta figura mitológica aparece en las aventuras de Odiseo.

En la "Odisea" de Homero, Circe advierte a Odiseo en el canto XII de navegar más cerca de Escila que de Caribdis, ya que mientras Escila devoraría a seis de sus hombres, su contrapartida succionaría su barco entero: 

Según la obra "Las metamorfosis", de Ovidio, Escila fue una vez una hermosa ninfa. El dios marino Glauco, anteriormente un pescador, se enamoró de ella, pero ella huyó de él hacia la tierra, donde no podía alcanzarla. Desesperado, Glauco fue a la isla de la diosa hechicera Circe, para que le preparase una poción de amor y así derretir el corazón de la joven. Circe, que estaba secretamente enamorada de Glauco, le recomendó dedicar su amor a alguien más digno de él, intentando cortejarlo con dulces palabras y miradas, pero el dios no quiso saber nada de ella. Circe se enfureció tanto, mas con Escila, no con Glauco, por ello, fingió ayudar al dios entregándole un frasco, recomendándole que lo vertiese en la charca donde Escila solía bañarse. Glauco siguió sus instrucciones y vertió la poción; en cambio, tan pronto como la ninfa entró en el agua se transformó en un horrible monstruo de seis cabezas perrunas. Glauco, que vigilaba esa triste escena desde la lejanía, perdió su interés por ella y se marchó llorando amargamente.

En mitos griegos posteriores, se dice que Heracles encontró a Escila durante un viaje a Sicilia y le dio muerte. Luego Forcis, el padre de Escila, le aplicó antorchas ardientes al cuerpo y le devolvió la vida.

Según el comentario de Servio sobre la "Eneida", Escila fue una hermosa náyade de la que se enamoró Poseidón, pero fue convertida en un monstruo por la celosa Anfitrite.

De la narración sobre Escila y Caribdis surge una expresión: «Estar entre Escila y Caribdis», vale decir, «estar entre la espada y la pared», o sea, en un problema de difícil (si no imposible) solución.








</doc>
<doc id="28153" url="https://es.wikipedia.org/wiki?curid=28153" title="Programador">
Programador

Un programador es aquella persona que escribe, depura y mantiene el código fuente de un programa informático, es decir, el conjunto de instrucciones que ejecuta el hardware de una computadora, para realizar una tarea determinada.

Un programador o programadora, es la persona que elabora programas de computadora.

Los programadores también son denominados desarrolladores de software, aunque estrictamente forman parte de un equipo de personas de distintas especialidades (mayormente informáticas), y siendo que el equipo es propiamente el desarrollador.

La programación es una de las principales disciplinas dentro de la informática.

En muchos países, el/la programador/a es también una categoría profesional reconocida.

Ada Lovelace, hija del prestigioso poeta Lord Byron, es considerada la primera programadora de la historia. Su contribución más notable consistió en elaborar un método para calcular los números de Bernoulli en la máquina analítica de Charles Babbage. En homenaje a Ada Lovelace, fue puesto el nombre al lenguaje de programación Ada.

El programador se encarga de la implementación de prototipos mediante un lenguaje de programación, que compilados pueda entender la computadora.

Inicialmente, la profesión se formalizó desde el enfoque tayloriano de la especialización de funciones en la empresa. Así, el proceso de producción de software se concibe como un conjunto de tareas altamente especializadas donde está claramente definido el papel de cada categoría profesional:


Hoy día se reconoce que este enfoque no es válido para organizar tareas de tipo intelectual, como es el desarrollo de software. De manera que la profesión de programador ha ido evolucionando. Las dificultades de comunicación entre analistas y programadores (un mero documento no basta para describir lo que se quiere hacer) dio origen a una categoría de profesional intermedia, denominada analista-programador. La concepción original del programador ha desaparecido siendo sustituida por la de un profesional mucho más formado y con unas funciones menos "mecánicas".

La profesión de analista también ha evolucionado, surgiendo el concepto diseñador (de software). Esto se debe a los avances de la ingeniería del software donde se reconoce que el análisis es una actividad compleja y distinta del diseño. Escuetamente, el análisis describe el problema (es decir, “qué” hacer) mientras que el diseño describe la solución (“cómo” hacerlo).

En la mayoría de países industrializados esto ha dado lugar a la categoría diseñador o arquitecto del software.

Estrictamente hablando, la profesión de programador si conoce especialidades. No obstante, existen diversas ramas por las que se decantan los propios profesionales y que se ven reflejadas en la oferta de empleo. Así, es posible mencionar algunas:



</doc>
<doc id="28154" url="https://es.wikipedia.org/wiki?curid=28154" title="¡Hatari!">
¡Hatari!

¡Hatari! es una película estadounidense de 1962, dirigida por Howard Hawks y protagonizada por John Wayne. El título significa "peligro" en swahili. La película presenta un grupo de cazadores que captura animales salvajes para posteriormente ser vendidos a zoológicos, mostrando un retrato interesante pero anticuado de África, dominado todavía por los no africanos.

"¡Hatari!" fue filmado en los que hoy es el norte de Tanzania. Muchas escenas fueron filmadas cerca de la ciudad de Arusha, en un rancho de caza de Ngorongoro, que en aquella época fue propiedad del actor Hardy Krüger. 

Un grupo de cazadores dirigido por Sean Mercer (John Wayne) está cumpliendo en Tanzania el encargo de capturar animales de muy variadas especies, cuando se incorpora al grupo Ana María D'Allesandro (Elsa Martinelli), que será llamada Dallas y que tiene la tarea de fotografiar su trabajo, y el tirador francés Charles Maurey (Gerard Blain) al que llamarán Chips. 

Todos ellos van a tener muchas diversiones y aventuras... y algunos de ellos también una historia de amor. 

La película reúne varios personajes de diferentes partes del mundo.
En 1963 fue nominada a los Oscar, y obtuvo el segundo lugar en los premios "Laurel de oro" en la categoría "Top action drama".




</doc>
<doc id="28155" url="https://es.wikipedia.org/wiki?curid=28155" title="Yakuza (película)">
Yakuza (película)

Yakuza es una coproducción estadounidense-japonesa de 1975, dirigida por Sydney Pollack. Protagonizada por Robert Mitchum en el papel principal.

Basada en una historia de gánsters escrita por Leonard Schrader.

Harry Kilmer ("Robert Mitchum") regresa al Japón después de una larga ausencia para ayudar a su amigo George Tanner ("Brian Keith") a rescatar a su hija que ha sido secuestrada. Allí se reencuentra con la que fue su mujer, Eiko ("Keiko Kishiuna"), una japonesa a la que tuvo que abandonar a petición de Ken ("Ken Takakura"), el hermano de ella. Ken odia a Kilmer por ser estadounidense y por haber convivido con su hermana, pero a la vez tiene una deuda con él por haberla salvado durante la posguerra. Kilmer le pedirá que salde dicha deuda ayudándole a rescatar a la hija de su amigo.


"Yakuza" retrata el choque de los valores tradicionales japoneses durante la transición entre la ocupación de los Estados Unidos y el éxito económico a principios de 1970. Los temas que trata la historia son los conceptos de endeudamiento y obligación moral, la lealtad a la familia y a los amigos, y el sacrificio; los valores culturales orientales y occidentales son contrastados, y la tradición clásica japonesa frente a la moderna y occidentalizada, tradición contemporánea de Japón.

Tras una decepcionante lanzamiento inicial, la película ganó seguidores de culto.


</doc>
<doc id="28158" url="https://es.wikipedia.org/wiki?curid=28158" title="Wyatt Earp (película)">
Wyatt Earp (película)

Wyatt Earp es una película estadounidense de wéstern de 1994 basada en la vida de Wyatt Earp y su trabajo como marshal en el pueblo de Tombstone, Arizona. La película fue nominada al .

La película presenta una mirada más a la vida de Wyatt Earp, su labor para
restablecer la ley en Tombstone, y el famoso Tiroteo en el O.K. Corral,
entre la familia Earp y los Clanton.
La trama comienza con la juventud de Earp en California y sus vivencias en un mundo de brutalidad propia del Oeste.
Earp desarrolla la capacidad de reaccionar efectivamente ante agresiones de matones e ilegales y esto le vale ser nombrado alguacil en un pueblo donde impera sólo la ley del más fuerte.

Earp con su gestión gana fama de ser un sheriff duro, enérgico e intransigente con quienes no respetan la ley colocando el pueblo de Dodge City en orden, y su fama trasciende las fronteras estatales. Además se gana muchos enemigos. Sólo tiene además de sus hermanos un solo amigo, Doc Holliday, un ex-médico aquejado de una tuberculosis en progreso y quien lo secunda y apoya en sus acciones.

Earp además está casado con Urilla Sutherland, una mujer a la que no ama y su relación con ella es tormentosa debido a sus exigencias de amor, por lo que se mantiene alejado de ella. Sus hermanos obtienen empleos de policía en el pequeño poblado de Tombstone, Arizona, donde el desorden, las bandas de desalmados como los Clanton y otras, provocan a gusto desórdenes callejeros.

Wyatt Earp es reclutado por sus hermanos como policía y pronto ocupa el oficio de marshal. En esto compite con el otro comisario deshonesto que apoya a estas bandas con tal de mantener su empleo, y además exhibe la foto de su novia desnuda como trofeo de guerra. Es entonces cuando Wyatt Earp conquista a la novia de éste comisario.

Los Clanton desafían a los Earp en un Corral y en el tiroteo fallece un asociado y los Clanton quedan heridos. Estos se vengan dejando casi lisiado al hermano mayor y matan al hermano menor de Wyatt Earp. Wyatt Earp los elimina en tiroteos en diferentes lugares desconocidos sin piedad.

Una vez acabado, el lleva a Doc Holliday a un hospital, donde se queda hasta su inevitable muerte, mientras que Wyatt continua con su vida, que se convierte gradualmente en leyenda.



</doc>
<doc id="28161" url="https://es.wikipedia.org/wiki?curid=28161" title="Mutiny on the Bounty (película de 1935)">
Mutiny on the Bounty (película de 1935)

Mutiny on the Bounty (en Hispanoamérica, Rebelión a bordo; en España, La tragedia de la Bounty) es una película estadounidense basada en la novela del mismo título de Charles Nordhoff y James Norman Hall. Fue dirigida por Frank Lloyd, y contó con Clark Gable, Charles Laughton, Herbert Mundin, Franchot Tone, Donald Crisp y Dudley Digges representando los personajes principales. 

"Mutiny on the Bounty" ganó el Oscar a la mejor película del año, y tuvo candidaturas a otros siete: las de Laughton, Gable y Tone al mejor actor, así como las de mejor director, mejor montaje, mejor banda sonora y mejor guion.

Basada en la trilogía de novelas por Charles Nordhoff y James Norman Hall sobre el motín a bordo de la ""Bounty"", la película relata el viaje del barco a Tahití para recoger retoños del árbol del pan con la finalidad de ser plantados en las colonias británicas de las Indias Occidentales y proveer de alimento barato a los esclavos. Pero durante el viaje la actitud tiránica del capitán Bligh (Charles Laughton) convierte el viaje en algo insoportable para la tripulación. El primer oficial Fletcher Christian (Clark Gable) no está de acuerdo con la estricta aplicación de la disciplina que hace el capitán, ya que considera que resulta nefasta para la moral de los marineros, cuya vida es de por sí bastante dura. El contraste entre la vida paradisíaca en Tahití y el regreso a la rutina de a bordo desemboca en un motín dirigido por Christian, que regresa a Tahití con la "Bounty" abandonando a Bligh y unos cuantos de sus fieles en una chalupa en alta mar. Bligh, al que hasta ahora conocíamos como pésimo gestor de recursos humanos, se revela como un magnífico navegante y un tipo corajudo capaz de llevar el pequeño bote hasta el lejano puerto de Timor. Bligh regresa a Tahití a bordo del "Pandora" para ajustar las cuentas con los amotinados, pero Christian avista el barco y prepara la "Bounty" para zarpar de Tahití... conseguirán escapar?

Este hecho resulta fílmicamente muy dramático pero es históricamente inexacto: en la realidad histórica, Bligh navegaba en esos momentos a bordo del "Providence" en una segunda misión -esta vez coronada por el éxito- en pos del árbol del pan, siendo el "Pandora" capitaneado por el capitán Edward Edwards.

En su reposición en las pantallas españolas tras la guerra civil, "Mutiny on the Bounty" se tituló "La tragedia de la Bounty", por considerar las autoridades de la dictadura franquista que la palabra «rebelión» no era aceptable. El título se ha mantenido tras el estreno de la versión de 1962, que en subsiguientes reposiciones, pases televisivos y ediciones en vídeo usurparía el título original en castellano con el que se estrenó la de 1935.



</doc>
<doc id="28162" url="https://es.wikipedia.org/wiki?curid=28162" title="Mutiny on the Bounty (película de 1962)">
Mutiny on the Bounty (película de 1962)

Mutiny on the Bounty (Motín a bordo o Rebelión a bordo) es una película estadounidense de 1962 dirigida por Lewis Milestone, con Marlon Brando y Trevor Howard como actores principales. Está basada en la novela del mismo título de Charles Nordhoff (1887 - 1947) y James Norman Hall (1887 - 1951).

En la película, el narrador es el horticultor de la expedición, interpretado por Richard Haydn.

"Mutiny on the Bounty" tuvo siete candidaturas a los Oscar, aunque no ganó ninguno, pues ese año la gran triunfadora resultó ser " Lawrence de Arabia". Con ligeros cambios y omisiones respecto a la novela (como el desembarco en Tenerife), la película logra relatar cómo era la vida en el mar y las normas que regían el destino de la tripulación, además de mostrar el estilo de vida isleño en el sur del Pacífico.

Durante el rodaje, Marlon Brando conoció a Tarita, que sería su tercera esposa y con la que tendría dos hijos. Brando sostuvo una agria competencia con Trevor Howard, quien lo consideraba irreverente, durante todo el rodaje de la película.

En 1787, la fragata británica "Bounty" comienza un viaje a Tahití para trasladar un cargamento de árbol del pan a Jamaica. El orgullo y la ambición del capitán Bligh (Trevor Howard) llevan a la tripulación a luchar contra su trato despótico, al tiempo que lo hace también contra el hambre y contra las inclemencias del mar. 

Los marinos llegan a la paradisíaca isla, donde son recibidos por los isleños. El carácter libre y desinhibido de las mujeres subyuga a la tripulación, y se inician muchos romances, como el del segundo oficial Fletcher Christian (Marlon Brando) con Maimiti (Tarita), hija del jefe de la isla.

Pero los marinos han de abandonar Tahití para cumplir con su misión. En el viaje de vuelta, un enfrentamiento con el segundo oficial por el racionamiento exagerado del agua en beneficio del cargamento desencadena un motín encabezado por el tripulante John Mills (Richard Harris). Los amotinados logran hacerse con el barco y eligen a Fletcher Christian como nuevo capitán. El capitán Bligh y los tripulantes que lo apoyan - entre ellos, Fryer, el contramaestre (Eddie Byrne) - son desalojados del barco y puestos a bordo de un bote en las cercanías de Tofoa, una de las Islas Tonga. 

En lugar de dirigirse a Tofoa, el capitán Bligh se embarca en una peligrosa aventura de 4.000 millas hasta Timor, para regresar cuanto antes al Reino Unido y dar a conocer los hechos al almirantazgo británico, el cual lanza una expedición para encontrar y enjuiciar a los amotinadores. Aun así inculpan a Bligh por lo ocurrido, aunque el no haya infringido la ley. 

Por su parte, los amotinados regresan a Tahití, y, después de aprovisionarse y embarcar a algunas isleños con ellos (mujeres incluidas), buscan un lugar donde vivir escondidos. Encuentran la isla de Pitcairn, que, por estar apartada de las rutas marítimas y por venir mal señalada en los mapas del almirantazgo británico, tras quemar la nave, se convierte en su nuevo hogar.




</doc>
<doc id="28164" url="https://es.wikipedia.org/wiki?curid=28164" title="Still of the Night (película)">
Still of the Night (película)

Still of the Night (Bajo sospecha en España y En la quietud de la noche en Hispanoamérica) es una película estadounidense de 1982.

George Bynum, un paciente del psiquiatra de Manhattan Dr. Sam Rice (Roy Scheider), es brutalmente asesinado. Poco después, el doctor Rice recibe la visita de un compañero de trabajo de Bynum y su amante Brooke Reynolds (Meryl Streep), además del detective Vitucci, a cargo de la investigación. Rice revisa las notas de sus sesiones con Bynum y comienza su propia investigación. Al mismo tiempo, se enamora de la enigmática Brooke, a pesar de que su comportamiento es cada vez más sospechoso. Cuanto más se acerca Rice a la verdad, más pone su vida en peligro.

</doc>
<doc id="28169" url="https://es.wikipedia.org/wiki?curid=28169" title="Bajo sospecha (película de 1943)">
Bajo sospecha (película de 1943)

Bajo sospecha (Above Suspicion título original en inglés) es una película estadounidense basada en la novela "Above Suspicion" de Helen MacInnes.

En 1939 Richard Myles (Fred MacMurray), un profesor estadounidense que enseña en Oxford, y su nueva esposa Frances (Joan Crawford) se encuentran en viaje de novios por Europa. Antes de salir Myles fue contactado por el servicio secreto británico, que le solicitó su colaboración mientras se encontrase en Alemania, ya que el comienzo de la guerra es inminente. Myles accedió porque lo consideró interesante. Cuando inician sus gestiones en Alemania, Myles y su esposa incluso se divierten, pero pronto cambia su opinión sobre este asunto.


</doc>
<doc id="28174" url="https://es.wikipedia.org/wiki?curid=28174" title="Tuvalu">
Tuvalu

Tuvalu (antiguamente Islas Ellice), es uno de los cuatro países que forman la Polinesia, o uno de los catorce que conforman Oceanía. Su capital es Funafuti.

Es un país insular localizado en el océano Pacífico, aproximadamente a mitad de camino entre Hawái y Australia. Los países más cercanos a Tuvalu son Kiribati, Samoa y Fiyi. Consta de 4 arrecifes de coral y 5 atolones, con un área total de 26 km². Después de la Ciudad del Vaticano (932 hab.) y antes de la República de Nauru (13 048 hab.) es la nación independiente con menor número de habitantes. También es el miembro de las Naciones Unidas con menor número de habitantes, ya que dispone solamente de 11 810.

Tiene una altitud máxima de 5 metros sobre el nivel del mar, siendo, después de Maldivas (2 metros sobre el nivel del mar), el país con la menor altitud máxima. Tiene clima tropical marítimo, moderado por los vientos alisios del este de marzo a noviembre, los meses restantes con abundantes lluvias y la vegetación típica está compuesta de palmeras (cocoteros).

Debido al cambio climático y a la progresiva subida del nivel del mar, su terreno va decreciendo, las playas de estas islas tienden a su desaparición y debido a los continuos tifones, las aguas marinas salinizan progresivamente los cultivos, parece irremediable que el aumento del nivel del mar anegue el archipiélago.
Todos estos cambios climáticos han sido confirmados por el Grupo Intergubernamental de Expertos sobre el Cambio Climático (IPCC), quienes asumen que lo peor todavía no ha llegado.
Tuvalu como miembro de las Naciones Unidas solicita ayuda para que el país pueda sobrevivir a la catástrofe que parece irreparable. Se esta intentando reubicar su población, aunque trasladar a todos sus habitantes es realmente

El término Tuvalu proviene del idioma indígena local en el que Tuvalu significa "8 islas", y hasta el año 1949 en el que los indígenas poblaron la isla de Niulakita eran las islas que disponían de población permanente y estable.

Tuvalu está habitado desde comienzos del primer milenio a.C., cuando se trasladaron habitantes desde los países de Tonga y Samoa. Estas islas fueron descubiertas por los españoles en 1568, con la llegada de Álvaro de Mendaña y Neyra y nombraron al archipiélago como Islas Nombre de Jesús. Algunos comerciantes de esclavos y balleneros procedentes de Perú visitaron frecuentemente las islas. En 1865 la Sociedad Misionera de Londres, de religión protestante, comenzó su proceso de evangelización de Tuvalu mediante la cual convirtió a la población al anglicanismo por completo en la década de 1920. También a finales de 1800, los comerciantes europeos comenzaron a asentarse en las islas con la esperanza de beneficiarse de los recursos locales.
En 1892, las islas pasaron a formar parte del protectorado británico de las Gilbert y Ellice (Micro-Polinesia británica), este protectorado se convirtió en colonia en 1915.

Durante la Segunda Guerra Mundial, Marines de los Estados Unidos desembarcaron en Funafuti (Villaolivos) el 2 de octubre de 1942. Por esas fechas los japoneses ya habían ocupado Tarawa y otras islas de lo que hoy en día es Kiribati. Un batallón de construcción naval ("abejas del mar" o "Seabees" en inglés) construyeron una pista de aterrizaje principal en Funafuti y aeródromos satélites en Nanumea y Nukufetau. La pista construida en Funafuti continúa siendo utilizada hoy día en el Aeropuerto Internacional de Funafuti. Las bajas civiles durante la Segunda Guerra Mundial fueron escasas. En una ocasión en abril de 1943, durante un bombardeo japonés, 680 personas se refugiaron en una iglesia. Afortunadamente para ellos, un soldado norteamericano (el cabo Ladd) les convenció de salir y refugiarse en trincheras. Poco después una bomba destruyó la iglesia. Tuvalu sirvió como base de apoyo para las ofensivas contra los atolones de Makin y Tarawa.

En 1974, diferencias étnicas dentro de la colonia provocaron que los Polinesios de las Islas Ellice decidieran separarse de los Micronesios de las Islas Gilbert (después Kiribati). Al año siguiente, las Islas Ellice se convirtieron en la colonia británica de Tuvalu. La independencia se concedió en 1978.

Tuvalu firmó en 1979 un tratado de amistad con los Estados Unidos que reconoce la legítima posesión tuvaluana de cuatro pequeñas islas reclamadas anteriormente por los Estados Unidos.

Entre 1995-1997, Tuvalu adoptó una nueva bandera pero, finalmente, se restituyó la antigua Bandera de Tuvalu, que es la que posee en la actualidad.

Según el Primer Ministro de Tuvalu, su país se encuentra amenazado por el cambio climático y piden responsabilidad a los países contaminantes y a la ONU por lo cual sus habitantes tendrán que decidir urgentemente sobre dos cuestiones: acerca de mantener la monarquía constitucional o convertir Tuvalu en una república, y sobre la conveniencia de trasladar a Nueva Zelanda a sus 11.810 habitantes, ya que las islas viven en continua alerta debido a los ciclones y otros fenómenos meteorológicos y corren el riesgo de inundarse debido al aumento del nivel del mar. Mientras que algunas personas han sugerido para la reubicación de la población de Tuvalu a Australia, Nueva Zelanda, o Kioa (Fiyi), el ex Primer Ministro Maatia Toafa dijo que su gobierno no considera el aumento del nivel del mar como una amenaza por la que toda la población tendría que ser evacuada.

La isla de Tuvalu es el país propietario del famoso dominio de internet .tv. La ICANN ya se ha enfrentado a las desaparición de países por causas políticas, aunque esta vez podría ser por causas geográficas.

Tuvalu es una monarquía constitucional perteneciente a la Commonwealth, en la que la reina Isabel II es reconocida oficialmente como reina de Tuvalu. Está representada en Tuvalu por un Gobernador General, nombrado a propuesta del Primer Ministro. El parlamento local, o Fale I Fono tiene 15 miembros y es elegido cada cuatro años. Sus miembros eligen a un Primer Ministro que es el jefe de gobierno. El Gabinete es nombrado por el Gobernador General, con el asesoramiento del Primer Ministro. Cada isla tiene su propio jefe o "Ulu-Aliki", y varios sub-jefes ("Alikis") además de los ancianos. Los ancianos forman juntos un consejo de ancianos o "fenua te sina" (literalmente: 'gris-pelos'). En el pasado, otra casta, a saber, la de los sacerdotes ("tofuga") también fue una de las encargadas de tomar decisiones. Las "sinas" o "fenuas", "Aliki" y "Ulu-Aliki" forman la autoridad a nivel local. El Ulu-Aliki es seleccionado sobre la base de su ascendencia familiar, y sus competencias están compartidas con la "pule" o "kaupule" que es un grupo formado por los elegidos presidentes, uno en cada atolón. No hay partidos políticos oficiales y las campañas electorales son en gran medida sobre la base personal y los lazos familiares además de la reputación.

El Gobierno de Tuvalu está representado en el Reino Unido por un cónsul honorario, con sede en la Casa de Tuvalu, en Londres.

Hay ocho tribunales (uno en cada isla), con jurisdicción limitada. El más alto tribunal de Tuvalu es el Tribunal Superior. Las sentencias del Tribunal Superior pueden ser recurridas ante el Tribunal de Apelación de Tuvalu. Sólo se puede recurrir una sentencia del Tribunal de Apelación ante "la Reina (o el Rey) en Consejo", es decir, en el Consejo Privado en Londres.

Tuvalu no tiene fuerzas militares regulares, y no gasta dinero en tenerlas. Su fuerza de policía incluye una Unidad de Vigilancia Marítima para misiones de búsqueda y salvamento y para realizar las operaciones de vigilancia. La policía tiene una sola patrullera, de la clase "Pacific" ("HMTSS Te Mataili"), suministrada por Australia en virtud del programa para la vigilancia marítima y la pesca en el océano Pacífico.

Tuvalu mantiene estrechas relaciones con Fiyi, Nueva Zelanda, Australia y el Reino Unido. Tiene relaciones diplomáticas con la República de China (Taiwán), Taiwán mantiene la única embajada residente en Tuvalu y tiene un gran programa de asistencia en las islas. También posee buenas relaciones con los Estados Unidos tras la firma de un contrato con ellos en el que Estados Unidos reconoce como de Tuvalu un grupo de islas que se disputaban los dos países.

Tuvalu se convirtió en miembro de la ONU en el año 2000 y mantiene una misión de la ONU en Nueva York. Una importante prioridad internacional para Tuvalu en las Naciones Unidas, en la Cumbre Mundial sobre el Desarrollo Sostenible en Johannesburgo y en otros foros internacionales es la promoción de preocupación sobre el calentamiento global y la posible elevación del nivel del mar. En Tuvalu son defensores de la ratificación y aplicación del Protocolo de Kyoto. Tuvalu también es miembro del Banco Asiático para el Desarrollo.

Tuvalu es un miembro pleno del Foro de las Islas del Pacífico y la Comisión del Pacífico Sur. Tuvalu tiene una casa en Londres, Inglaterra que cumple una función principalmente de consulado. Tuvalu declaró su zona sur una zona libre de armas nucleares en el Tratado del Pacífico Sur en el año 1985.

La poca población de Tuvalu está distribuida en 9 islas, 6 de las cuales son atolones. La isla más pequeña, Niulakita, estaba deshabitada hasta 1949, cuando se desplazó gente desde Niutao.

Es uno de los países más pequeños en el mundo, de hecho, el cuarto más pequeño, sólo le superan la Ciudad del Vaticano (0.44 km²); Mónaco (1.95 km²) y Nauru (21 km²). Tuvalu también tiene tierras muy pobres. No hay agua potable, y la tierra es escasamente utilizable para la agricultura.

Aunque Tuvalu técnicamente no tiene ninguna subdivisión administrativa - su población es demasiado pequeña (estimada en 11.000 en 2004) - el país puede ser dividido en 9 islas, o más bien atolones, a mitad del camino entre Hawái y Australia. Originalmente, sólo ocho de estas islas estaban habitadas, de ahí el nombre Tuvalu que quiere decir "ocho islas" en idioma tuvaluano. Las nueve islas son: Funafuti, Nanumea, Nanumanga, Niutao, Nui, Niulakita, Nukufetau, Nukulaelae y Vaitupu.

En el 2001 el gobierno de Tuvalu anunció que las islas, de las cuales el punto más elevado es de 5 msnm, tendrían que ser evacuadas en caso de aumento del nivel del océano. En efecto, la elevación que se viene produciendo del nivel del océano a causa del recalentamiento global, aunque aún es poco perceptible en otros países, resulta evidente en Tuvalu debido a su escasísima altitud y a lo exiguo del territorio, de modo que durante las mareas altas acompañadas de tormentas gran parte del país queda sumergido.

Nueva Zelanda ha aceptado recibir un contingente anual de 75 evacuados, mientras que Australia rechazó las peticiones.

El producto interno bruto de Tuvalu es de 36 millones de USD (según estimaciones de 2012), lo cual lo coloca como el país más pobre del mundo. Suponía unos ingresos medios de 3,048 dólares per cápita.

El dólar de Tuvalu tiene el mismo valor que el dólar australiano, que también circula en las islas (en 2010, 1,1208 dólares australianos equivalían a un dólar estadounidense). La economía de Tuvalu es la menos dinámica de cualquier Estado independiente del mundo, está basada en una agricultura de subsistencia; la ganadería de cerdos y aves de corral; la pesca tiene una importancia creciente, aunque la única exportación es la copra (médula de coco utilizada para la extracción de aceite). Gran parte de los ingresos estatales se obtiene de la venta de sellos y monedas; la inversión exterior y los ingresos que remiten los emigrantes que trabajan en el extranjero apuntalan la economía del país.

Ésta recibió una inyección muy importante en 2000, tras la cesión de las letras de su matrícula (TV, que le había sido concedida un año antes por la Unión Internacional de Telecomunicaciones), para su uso en Internet, a una empresa estadounidense a cambio de 50 millones de dólares en 12 años. El Gobierno de Tuvalu recibe un millón de dólares cada 3 meses y posee el 20% de la empresa que gestiona el dominio .tv.

La emisión de sellos postales, principalmente destinado al coleccionismo filatélico, es también una importante fuente de ingreso para su economía.

Debido a la lejanía del país con respecto a otros países, el turismo no aporta mucho los ingresos, se estima que un centenar de turistas visita anualmente Tuvalu. Casi todos los visitantes son los funcionarios de gobierno, los trabajadores, las organizaciones no gubernamentales funcionarios o consultores.

Tuvalu presuntamente participó en Japón en la compra de votos en el régimen de Comisión Ballenera Internacional en 2006. Greenpeace sostiene que la compra de votos se llevó a cabo y Tuvalu es uno de los países que para recibir asistencia económica de Japón en 2006 sostiene que no.

La moneda de Tuvalu es el Dólar tuvaluano, actualmente 1 dólar de Tuvalu equivale a 1,22 de dólar en Nueva Zelanda (2010). Sólo hay un Banco de Tuvalu, que se encuentra en la capital del país Funafuti. En Tuvalu sólo se puede pagar en efectivo, no aceptan tarjetas de crédito y las divisas se deben cambiar en el Banco de Tuvalu.

El 1 de enero de 1976 Tuvalu inició la impresión de sus propios sellos. En Funafuti existe una Oficina de Correos para que apoye sus propios sellos, que representa a la isla o momentos importantes en la historia nacional, bailes o trajes tradicionales. Existe una Sociedad Filatélica conjunta con Kiribati (anteriormente formaban las Islas Ellice).

La denominación .tv es la utilizada como propia por Tuvalu después de haber comprado los derechos. Antes estaba permitido que lo utilizasen todas las empresas de cualquier país siempre y cuando le entregasen un aporte al gobierno de Tuvalu.

El problema es que esta denominación es muy popular puesto que en muchos idiomas tv es la abreviatura de la televisión, el tener esta denominación no solo es interesante para las televisiones, sino también para sitios pornográficos.

En el año 2000 la gestión de esta denominación ha sido vendida por el gobierno de Tuvalu a la empresa dotTV, una filial de VeriSign, durante 12 años a cambio de 50 millones de dólares estadounidenses. Esta venta ha aportado grandes ingresos al micro-estado, que era, antes de la venta de la propiedad, uno de los países más pobres del mundo. Actualmente el Gobierno de Tuvalu posee una participación del 20% en la empresa DotTv.

Los inesperados ingresos generados por la venta es un tema de controversia en el país. Parte de la población local protestó contra esta práctica, debido a que muchos sitios con esa denominación son sitios de pornografía. Para la mayoría de la población cristiana, este dinero se considera impuro.

A pesar de la controversia, el dinero ha ayudado a mejorar la infraestructura vial y dotar así al país de carreteras.

Los servicios de transporte en Tuvalu son limitados. Un ferry comunica los principales atolones. Además hay unos 8 kilómetros de carreteras, pero no dispone de ferrocarriles.

Funafuti es el puerto de mayor importancia aunque también hay un puesto de atraque de aguas profundas en el puerto en Nukufetau. Desde el año 1999, la flota de la marina mercante se compone de cuatro buques de 1.000 toneladas de registro bruto o más, que pueden transportar un total de 33.199 toneladas métricas de peso entre todos. Esto incluye dos buques de carga y un buque de transporte de pasajeros. El único aeropuerto del país es el Aeropuerto Internacional de Funafuti, es una franja de grava. El código IATA de este aeropuerto es FUN. Las calles de Funafuti se encuentran pavimentadas desde el 2002. Otras calles menos importantes están sin pavimentar. Tuvalu es uno de los pocos países del mundo que no cuentan con vías férreas.

La principal emisora de radio en el país es Radio Tuvalu, operada por Tuvalu Media Corporation, la empresa estatal de comunicaciones, y que posee una estación en AM y otra en FM.

"Tuvalu Echoes" es el único periódico editado en el país. Publica dos ediciones quincenales, una en inglés y la otra en tuvaluano (denominada "Sikuleo o Tuvalu"), y pertenece al Estado.

La población de la isla se ha más que duplicado desde 1980 y se estima que llegaba a 11.810 en julio de 2006. La población de Tuvalu es sobre todo de la etnia polinesia; aproximadamente el 4% de la población es de Micronesia. Cerca del 97% de la población de Tuvalu son miembros de la Iglesia de Tuvalu, una iglesia protestante. La religión se ha mezclado con algunos elementos de las religiones indígenas. Otras religiones que se practican en la isla son los Adventistas del Séptimo Día (1.4%) y Bahaí (1%) ambas relacionadas con culturas indígenas.

El tuvaluano es el idioma hablado por casi todo el país, mientras que un dialecto del idioma gilbertés se habla en Nui. El inglés es también un idioma oficial, pero no se habla por la gente en la calle sino que es hablado en el parlamento y en las funciones oficiales que se llevan a cabo en Tuvalu.

Educación en Tuvalu es gratuita y obligatoria entre las edades de 6 y 15 años . Cada isla tiene una escuela primaria. Para la educación secundaria existe la Motufoua Secondary School que se encuentra localizada en Vaitupu. Los estudiantes viajan a la escuela durante el curso escolar, regresan a sus islas de origen en sus vacaciones escolares. Fetuvalu High School, una escuela operada por la Iglesia de Tuvalu, está ubicada en Funafuti.

La alfabetización de adultos es un 99,0% (2002). En 2010, había 1.918 alumnos que pasaron por 109 profesores ( 98 certificados y 11 no certificados) . La relación maestro - estudiante para las escuelas primarias en Tuvalu es de alrededor de 1:18 para todas las escuelas , con la excepción de "Nauti School", que tiene una relación maestro-alumno de 1:27 . "Nauti School" en Funafuti es la más grande escuela primaria de Tuvalu con más de 900 estudiantes (45 por ciento de la matrícula total de la educación primaria). La relación alumno-maestro para Tuvalu es baja en comparación con la región del Pacífico (relación de 1:29). 

Centros de formación comunitarios (CTC por sus siglas en inglés) se han establecido dentro de las escuelas primarias en cada atolón . Los "CTC" proporcionan formación vocacional a los estudiantes que no progresan más allá del octavo gravo porque fallaron los requisitos de acceso a la educación secundaria. Los CTC ofrecen formación en carpintería básica , la jardinería y la agricultura , costura y cocina. Al final de sus estudios, los graduados pueden postura para continuar los estudios en la escuela secundaria Motufoua o en el Instituto de Formación Marítima de Tuvalu ( TMTI ) . Los adultos también pueden asistir a cursos en los CTC. 

La Ordenanza sobre el empleo tuvaluano de 1966 establece la edad mínima para el empleo remunerado a los 14 años y prohíbe que los niños menores de 15 realizar trabajos peligrosos .

El sistema tradicional de la comunidad todavía sobrevive en gran medida en Tuvalu. Cada familia tiene su propia tarea, o salanga que llevar a cabo para la comunidad, como la pesca, la construcción de viviendas o de la defensa. Las habilidades de una familia se transmiten de padre a hijo.

La mayoría de las islas tienen su propia Futi, o tiendas de propiedad del gobierno. Estas tiendas son similares a una tienda de conveniencia en las que usted puede comprar alimentos enlatados o empaquetados y en los que las mercancías son más baratas y los Futis dan mejores precios para sus propios productos, debido a las subvenciones del gobierno.

Otro componente importante es el falekaupule o ayuntamiento, donde se debaten los temas importantes y que se utiliza con ciertos eventos.

Las comidas tradicionales que son consumidos en Tuvalu son: pulaka, mariscos entre los que se incluyen normalmente cangrejos, tortugas, y algunos peces, los plátanos con pan, coco, y la carne de cerdo. El "Pulaka" (una raíz que también recibe a veces el nombre de taro) es la principal fuente de hidratos de carbono, se cultiva en grandes fosas por debajo de la capa freática en compost natural del suelo. El pescado es la principal fuente de proteínas. El pan y los plátanos son platos suplementarios. Por último, el coco es utilizado por sus jugos en bebidas y alimentos para hacerlas más sabrosas. Se suele comer carne de cerdo con fateles (o partes de la danza para celebrar ciertos acontecimientos).

La música tradicional antes del contacto europeo incluye poemas realizados en una especie de recitación monotonal, aunque esta tradición se ha extinguido, así como canciones de trabajo que realizan las mujeres para alentar a los hombres mientras trabajaban.

El más famoso estilo de música de baile de Tuvalu, fatele, está influenciado por las melodías y la armonía. Se celebra una competición dividiendo a cada isla en dos partes o equipos (llamados "feitu's"). Los "Feitus" existen sólo al bailar la fatele (que se lleva a cabo como una competición), pero no para otras actividades.

Los dos principales bailes tradicionales de Tuvalu son los fakanu y fakaseasea. De éstas, la fakanu ha desaparecido, aunque sobrevive la fakaseasea, realizada únicamente por personas mayores.

La actual bandera de Tuvalu se creó cuando la nación se separó de Kiribati en 1978. Al igual que muchas antiguas y actuales dependencias británicas, la bandera de Tuvalu se basa en el "Union Jack" que aparece en la parte superior izquierda del cantón. Cuando se unió con las Islas Gilbert en una sola colonia, la bandera fue la "Union Jack" con las armas, ahora adoptada por Kiribati.

Las estrellas representan las 9 islas que forman Tuvalu incluidas aquellas en las que no hay vida humana ni animal. En 1995 la bandera fue sustituida después de un cambio de gobierno, esta bandera no se basó en la bandera británica, y también mostró las islas como estrellas. Este pabellón, sin embargo, no fue muy apreciado por los habitantes, y el antiguo pabellón fue restaurado en 1997, con algunas modificaciones menores.


Un deporte tradicional que se desempeña en Tuvalu es "kilikiti", que es similar al cricket. Otro deporte popular y específico de Tuvalu es el "ano", que se juega con 2 bolas redondas de 12 cm de diámetro.

Es más común la práctica de deportes como el fútbol y el ciclismo. Tuvalu tiene una selección nacional de fútbol, organizada por la Asociación Nacional de Fútbol de Tuvalu, miembro de la OFC pero no de la FIFA. Existen tres divisiones futbolísticas, la División-A, B y C, mientras que se organiza la Copa Navidad, la NBT, la Independencia y los Juegos de Tuvalu durante el receso de las ligas. El club más ganador es el Nauti FC que posee 7 títulos en la División-A, 2 en Copa NBT y 4 en la Independencia.

Tuvalu participó por primera vez en los Juegos Olímpicos en 2008, en Pekín, China, con el envío de tres competidores en dos deportes.




</doc>
<doc id="28175" url="https://es.wikipedia.org/wiki?curid=28175" title="Primera Edad del Sol">
Primera Edad del Sol

La Primera Edad del Sol, también conocida como los Días Antiguos, es una etapa de la cronología de la historia de la Tierra Media, el mundo ficticio en que transcurre la mayor parte de las obras del escritor británico J. R. R. Tolkien. Las historias que tratan los sucesos de esta época son las primeras que Tolkien empezó a escribir en su juventud, y a las que aún seguía dando forma, retocando detalles aquí y allá, cuando le alcanzó la muerte. Abarca un período de aproximadamente 590 años solares.

La parte más importante (en extensión) del Silmarillion, y que le da el nombre, es el "Quenta Silmarillion", que en Quenya, la lengua de los elfos Noldor, significa "La historia de los Silmarils"; y las narraciones a ella pertenecientes se inscriben casi en su totalidad en la Primera Edad.

Las Edades de los Árboles tocan a su fin con la destrucción de los Dos Árboles de Valinor (Telperion y Laurelin) a manos de Melkor y Ungoliant. Transcurriría todavía un lapso de tiempo antes de que se alzasen en los cielos la Luna (Isil) y el Sol (Anar), creados gracias a las artes de Yavanna Kementári a partir de la última hoja de Telperion (para hacer de ella la Luna) y el último fruto de Laurelin (para hacer de él el Sol), cuando los dos árboles estaban agonizantes pero todavía no del todo muertos.

La frontera entre las Edades de los Árboles y la Primera Edad es difusa, puesto que se puede interpretar que se sitúa en cualquier instante entre estos dos acontecimientos, aunque es de común acuerdo que comienza con la primera salida, ya sea de la Luna, que salió primero, o del Sol, que salió cuando ya la Luna había descrito siete viajes a través del cielo.

La Primera Edad comienza con el levantamiento de la Luna y del Sol. En ese momento los hombres despiertan en el Este y algunos, luego de sucesos que se pierden en el misterio, emprenden el viaje hacia el Oeste. Los noldor llegan a la Tierra Media y los sindar los reciben gustosos. Al inicio los noldor salen victoriosos y organizan el largo asedio de casi 400 años contra la fortaleza de Melkor, Angband. En este período los hombres llegan a Beleriand y se convierten en aliados de los elfos contra Melkor y de hecho entre estos hombres (conocidos como los Edain) y los elfos se lleva a cabo una unión tan especial de la que son producto algunos hijos llamados los medio elfos. Sin embargo los eventos comienzan a ser desafortunados para ellos y batalla tras batalla Beleriand se ve perdida en manos de Melkor. El hado de los Noldor muestra sus efectos en cada rincón de sus reinos, y los desastres ocurren siempre. Al final sólo un reducido número de noldor, sindar y hombres resisten, y los medio elfos toman el protagonismo, intercediendo por los elfos y los hombres, con lo que los Valar deciden ayudar y Melkor es vencido al final.

Mientras los noldor caminan por el Helcaraxë guiados por Fingolfin, y mientras Fëanor organiza a los que le siguen para comenzar a guerrear contra Morgoth, los Valar debaten sobre lo que debe hacerse a continuación. Es entonces cuando se decide rescatar lo poco que queda de los árboles y alumbrar con ellos a toda la Tierra Media, un poco por compasión a los Noldor, pero sobre todo en consideración a los elfos que ya vivían antes en la Tierra Media y que ahora recibirían la furia de Morgoth, y sobre todo pensando en los segundos hijos de Eru, los Hombres, que aún estaban por llegar.

Así, Yavanna levanta con el poder de Varda la última hoja de Telperion, formando así la Luna, que guiaría Tilion, un maia de Oromë. Cuando la Luna se levantó por primera vez, los noldor de Fingolfin terminaron su travesía por el Helcaraxë y llegaron a las puertas de Angband donde se refugiaba Morgoth, y lo desafiaron, aunque por precaución después se retiraron, llegando a las orillas del lago Mithrim, donde los noldor de Fëanor estaban acampados.

A las siete ocasiones en que la Luna viajó por el cielo, Yavanna tomo el último fruto de Laurelin, formando así el Sol, que sería guiado por Arien, una maia de fuego. Cuando el Sol se levantó por primera vez lo hizo en el Oeste, y en ese instante se dice que sucedió el despertar de los Hombres en un lugar desconocido en el oriente de la Tierra Media. El Sol hizo su primera travesía pero fue capturado por las criaturas marinas de Ulmo, a las que les gustó su luz, y por eso desde entonces el Sol sale en el Este.

Puesto que los noldor están exiliados, los Valar levantan numerosas islas encantadas en el mar, de forma tal que ningún marinero por hábil que sea pueda encontrar el camino de regreso a Aman a través del mar.

Morgoth guerrea con los elfos, en numerosas batallas. En la primera de ellas, casi vence a los sindar que aún no conocían del regreso de los noldor. En la segunda de ellas (Dagor-nuin-Giliath, la Batalla bajo las Estrellas), los noldor de Fëanor atacan pero Fëanor muere en manos de los Balrogs, con lo que su primogénito Maedhros debería convertirse en el Rey Supremo de los Noldor en el exilio, pero este cede el trono a su tío Fingolfin, gracias a la amistad que lo une con su primo, el primogénito de Fingolfin, Fingon el Valiente y a su deseo de restaurar a los noldor como pueblo unido.

Elwë, que para entonces ya es conocido como Thingol, recibe a los noldor en sus tierras y les concede establecer reinos al Norte, de forma tal que protegieran Beleriand de Morgoth, pues su regreso resultó muy oportuno para los sindar. Sin embargo siempre hubo recelo entre Thingol y los noldor, excepto con los hijos de Finarfin, que eran sus parientes cercanos. La tercera batalla (Dagor Aglareb, la Batalla Gloriosa) supuso un fracaso total para Morgoth, que no esperaba que los noldor estuvieran tan unidos desde que los dejó en Aman con sus peleas internas.

Comienza entonces el largo asedio de Angband, de casi 400 años del Sol. Durante esta época, los sindar se separan de los noldor, al descubrir por los hijos de Finarfin de la matanza de Alqualondë, y el Quenya (idioma oficial de los noldor, que aprendieron en Aman) queda prohibido en Beleriand, quedando el sindarin como idioma oficial. Igualmente en esta época, Turgon hijo de Fingolfin, funda la ciudad oculta de Gondolin, inspirado en sueños por el Vala Ulmo. Finrod hijo de Finarfin funda a su vez la ciudad secreta de Nargothrond, también inspirado en sueños por Ulmo.

En esta época también llegan a Beleriand los primeros hombres, que fueron conocidos como los Edain. Finrod los conoce y conserva con la casa de Bëor (los primeros en llegar) una larga y verdadera amistad. Estos hombres se establecen en Dorthonion (territorio de Finrod y sus hermanos), bajo el permiso de Thingol. Después llegan los hombres "Haladin" (la casa de Haleth), que se establecen junto con los drúedain que los acompañan en el bosque de Brethil, en el extremo oeste del bosque de Doriath, bajo permiso de Thingol y con la condición de que cuiden el paso norte hacia Beleriand. Por último llegan los hombres de Marach (la casa de Hador), que bajo permiso de Thingol se establecen en el territorio de Fingolfin, en Dor-lómin.

Con la cuarta batalla, la Dagor Bragollach (la Batalla de la Llama Súbita), se rompe el asedio. Muchos noldor mueren, en especial de la casa de Finarfin, entre ellos sus hijos Angrod y Aegnor. Los hijos de Fëanor quedan dispersos. Barahir rescata a Finrod y este le da su anillo en prenda de ayudarlo a él o cualquier pariente suyo siempre que lo necesiten. Fingolfin muere al ir desesperadamente a retar en combate singular a Morgoth. Su hijo Fingon queda entonces como Rey Supremo de los noldor en el exilio. Eöl se desposa a la fuerza con Aredhel hija de Fingolfin y esta concibe a Maeglin, con quien luego huye a Gondolin con su hermano Turgon. Morgoth comienza a ganar terreno. Sauron conquista Dorthonion y Tol Sirion. De esta manera el reino que perteneció a los hijos de Finarfin cae en manos de Morgoth, sólo Nargothrond sobrevive por ser un reino secreto, que además se encuentra dentro de Beleriand, al que Morgoth todavía no accede (aunque controlando Tol Sirion ya tiene paso a él). Igualmente algunos de los reinos de los hijos de Fëanor caen en manos de Morgoth, con lo que Curufin y Celegorm se van a refugiar a Nargothrond y el resto se queda agrupado alrededor de Maedhros.

Nacen Húrin y su hermano Huor, de hombres de la tercera y la segunda casas. Húrin y Huor son rescatados cuando muy jóvenes por las águilas, que los llevan a la ciudad escondida de Gondolin, donde según las reglas del lugar jamás podrían salir; sin embargo mantienen una fuerte amistad con el rey Turgon y éste los deja salir con la condición de que no revelen nunca el lugar en que se encuentra Gondolin. Húrin y Huor se desposan después con mujeres de la primera casa, y tienen respectivamente a sus hijos Túrin y Tuor.

En esta época, Beren hijo de Barahir huye de Dorthonion, y conoce en Doriath a la hija de Thingol, Lúthien, y ambos se enamoran. Thingol no permite la unión de un hombre con su hija, y le encomienda a Beren la misión de capturar un Silmaril de la corona de Morgoth como prenda por su hija. Beren desesperado acude a Finrod en Nargothrond, quien, por el juramento hecho a su padre Barahir, le brinda ayuda con pocos elfos, ya que la ciudad entera fue convencida por Curufin y Celegorm, hijos de Fëanor, de no ayudar en tal empresa que equivaldría a traicionar a Fëanor, por el Juramento que sus hijos hicieron. Son capturados por Sauron y Finrod muere defendiendo a Beren. Beren es rescatado por Lúthien y Huan, el perro cazador de Celegorm. Beren y luego Lúthien con él, van a Angband, y disfrazados logran robar un Silmaril de la corona de Morgoth. Beren pierde la mano donde tenía el Silmaril y casi muere pero son rescatados por las águilas. Thingol entonces permite la unión pero antes deben matar a Carcharoth, el lobo de Morgoth que le arrancó la mano a Beren, y que huyó hasta Doriath consumido por el Silmaril en sus entrañas. El lobo es muerto por Huan, pero también mata a Beren y a Huan. Lúthien muere de pena.

En Aman, los Valar conocen a Lúthien y ella canta con dolor por su amor por Beren y por los hijos de Ilúvatar abandonados en la Tierra Media. Los Valar entonces, bajo el permiso de Eru, permiten que Beren regrese de la muerte junto con Lúthien, quien para que esto se lleve a cabo elige un destino mortal distinto al de los elfos, e idéntico al de los Hombres. Se lleva a cabo entonces la Primera Unión de Elfos con Hombres. Beren y Lúthien se van a vivir a Ossiriand. Nace de ellos Dior, que luego se casa con Nimloth de Doriath y de ellos nace Elwing y otros dos hijos, los primeros medio elfos.

Esta es la quinta gran batalla de Beleriand. En ella los noldor se vuelven a aliar para combatir contra Melkor. El Señor de Doriath, el sinda Thingol, no acude con ellos pero tampoco evita que quien lo desee vaya a luchar, lo mismo sucede con Nargothrond, ahora al mando de Orodreth, hermano de Finrod, que sufrió durante la época de Beren y Lúthien por la codicia de los hijos de Fëanor. Los enanos también se alían con los noldor, y junto con los hombres de las Tres casas y los hombres cetrinos que llegaron después a Beleriand (y que estaban aliados con los hijos de Fëanor), organizan una gran batalla contra Melkor, que se llegaría a llamar Nírnaeth Arnoediad, «la batalla de las lágrimas innumerables».

Morgoth por su parte contraataca con todas sus fuerzas (orcos, Glaurung el Dragón, Balrogs, y los hombres cetrinos que traicionan a los hijos de Fëanor). Al final la batalla queda perdida para los noldor, y aunque hasta Turgon salió de Gondolin para combatir, son vencidos y éste tiene que retirarse. Fingon muere a manos de los Balrogs y su hermano Turgon queda como Rey Supremo de los noldor en el exilio, escondido en Gondolin. Huor muere y Hurin defiende hasta el final la huida de Turgon, quedando al final preso por Melkor, quien lo maldice a él y a los suyos. Los enanos se retiran de la batalla luego de que su rey muere a manos de Glaurung. Los hijos de Fëanor se retiran por la traición de los hombres cetrinos. Muchos elfos, noldor y sindar, son capturados y llevados a Angband. De esta forma, el resto de los reinos de los hijos de Fëanor quedan conquistados y estos tienen que vivir por los bosques sin poder establecerse.

Todo el reino que antiguamente pertenecía a Fingolfin y su hijo Fingon, así como a los hombres de la casa de Hador, es capturado y cedido por Melkor a los hombres cetrinos como recompensa. Así mismo, las Falas son conquistadas, cayendo sus ciudades Brithombar y Eglarest, por las fuerzas de Melkor, al no haber ya protección en esa región de Beleriand.

Túrin, hijo de Húrin, comienza sus desgracias, primero en Doriath a donde huyó dejando atrás a su madre Morwen y hermana Nienor en Dor-lómin. Luego huye a las zonas invadidas de Beleriand donde se convierte en un bandido en la guarida de Mîm el enano. Su amigo Beleg el arquero de Doriath se le une pero son traicionados por Mîm y huyendo al Norte, en una lamentable equivocación, Túrin mata a Beleg con su propia espada. Túrin llega a Nargothrond donde se pone el apodo de Mormegil, la "Espada negra" (por Gurthang (antes llamada Anglachel), la espada negra que porta). Ahí gana fama como capitán, y a pesar de las advertencias de unos elfos del mar, por parte de Ulmo, consigue hacer de Nargothrond ya no una ciudad secreta sino una fortaleza para enfrentar a Morgoth. Este lanza un ataque con Glaurung y vence, destruyendo Nargothrond, matando a Orodreth, capturando a los elfos y dejando a Túrin desesperado. Este quiere rescatar a la hija de Orodreth, Finduilas, pero no lo consigue. Túrin huye al bosque de los Haladin, donde se pone el (cruelmente irónico) sobrenombre de Turambar, el "Amo del destino". Ahí conoce a su hermana menor, a la que no reconoce porque nació después de su partida, y que tiene amnesia debida a una maldición de Glaurung, y sin saberlo se casan y conciben un hijo. Glaurung ataca a los Haladin y Túrin los defiende, matando a Glaurung, no sin antes revelarles a Túrin y Nienor el espantoso error que cometieron. Enloquecida, Nienor se suicida lanzándose al río con el hijo que lleva en el vientre. Túrin se suicida sobre su propia espada.

Húrin es liberado de Angband, quien va a Nargothrond, ya abandonado por las fuerzas de Morgoth y tomada por Mîm, a quien mata por traicionar a su hijo, y roba de Nargothrond el Nauglamír de Finrod, hecho por los Enanos. Se lo da a Thingol y después, sin deseos de vivir por las desgracias de los suyos, se avienta al mar. Thingol le pide a los enanos engarzar el Silmaril de Beren en el Nauglamir y estos lo quieren robar, Thingol muere a sus manos y Melian se retira de la Tierra Media para siempre. Beren y Lúthien recuperan el Nauglamir de los enanos, a los que matan con ayuda de los Ents. Dior se convierte en rey de Doriath y ahí él se entera de la muerte natural de Beren y Lúthien años después, de quienes hereda el Nauglamir con el Silmaril. Los hijos de Fëanor exigen se les entregue el Silmaril pero Dior se niega. En una Segunda Matanza de elfos contra elfos, los hijos de Fëanor destruyen Doriath, pero varios de ellos mueren, Dior también. Elwing alcanza a huir con el Nauglamir al Sur, a la bahía de Balar, donde los últimos reductos libres de elfos y hombres existen en el mar, con Círdan el carpintero de barcos al mando.

Durante esta época, Tuor, el hijo de Huor, es criado en Dor-lómin por los elfos de Mithrim, quienes lo educan en las costumbres élficas, y luego huye hacia el mar, donde Ulmo lo contacta para que vaya a avisar a Turgon que el tiempo de Gondolin ha terminado. Tuor llega por fin a Gondolin pero Turgon no quiere hacer caso, y Tuor termina desposándose con la hija de Turgon, Idril, dando lugar a la Segunda Unión de Elfos con Hombres. Nace de esa unión Eärendil. Maeglin, celoso de Tuor, traiciona Gondolin, revelándosela a Morgoth, quien la conquista rápidamente. Tuor, Idril, Eärendil y otros sobrevivientes huyen de Gondolin hacia el Sur, a la bahía de Balar; mientras huyen, un Balrog les cierra el paso en las montañas de Gondolin y Glorfindel los salva a todos sacrificando su propia vida. Turgon muere defendiendo Gondolin, y Ereinion Gil-Galad, hijo de Fingon, que en ese entonces ya vivía en Balar, queda como Rey Supremo de los Noldor en el exilio.

Eärendil y Elwing se conocen y se casan. Nacen de ellos los gemelos Elros y Elrond, los medio elfos. Eärendil emprende el viaje en busca de su padre, que se había embarcado al Oeste en busca de Valinor, y de quien se dice (aunque no se sabe con certeza), que se le concedió ser contado entre los elfos, para vivir en Aman junto a su esposa Idril. Los hijos de Fëanor exigen el Silmaril a Elwing y realizan la Tercera Matanza de elfos contra elfos, en la que también mueren otros más de los hijos de Fëanor. Elwing huye tirándose al mar con el Silmaril, pero deja a sus hijos en manos de Maedhros y Maglor, los únicos hijos de Fëanor que quedan, los cuales, a pesar de todo, los cuidan.

Elwing es levantada por Ulmo del mar con forma de ave, se dirige al barco de Eärendil y juntos van al Oeste y llegan a Aman con la ayuda del Silmaril. Eärendil habla con los Valar en nombre de todos los hombres y elfos de la Tierra Media y pide perdón por los noldor. Los Valar conceden y organizan la Guerra de la Cólera, en que por fin Morgoth es vencido.

Los noldor de Finarfin, junto con los Valar, los Maiar y los Vanyar, y con Eärendil en su barco (que se le destinó a volar para siempre por los cielos), van a la Tierra Media en barcos de los Teleri de Olwë, todos al mando de Eönwë, el heraldo de Manwë. Eärendil, portando el Silmaril de Beren y Lúthien, se levanta por primera vez en el cielo occidental como señal de esperanza.

Morgoth no puede soportar el ataque. Caen muchos Balrogs (aunque algunos alcanzan a esconderse bajo tierra), cae también Sauron, los dragones alados salen a la batalla por primera vez y son vencidos por Eärendil. Beleriand comienza a hundirse bajo el mar por la furia de la batalla y sólo quedan algunos promontorios e islas pequeñas sobre el mar.

Morgoth es expulsado y exiliado al Vacío Intemporal, donde debe permanecer para siempre, sin embargo se dice que al final del tiempo logrará salir y guerreará contra las criaturas libres de Arda por última ocasión (ver Dagor Dagorath, la Última Batalla). Sauron en cambio mostró arrepentimiento, orillado por el miedo, y fue convocado por los Valar para responder por sus actos en Aman. Sin embargo, por el mismo miedo, decidió no presentarse y se escondió en la Tierra Media por mucho tiempo.

Los últimos dos Silmarils son recuperados, pero los dos últimos hijos de Fëanor sobrevivientes (Maedhros y Maglor) los roban del ejército de los Valar. Sin embargo, por la maldición de los noldor, las joyas ya no les pertenecen y les queman y enloquecen. Maedhros se tira en una fosa volcánica, junto con el Silmaril que lleva, que se queda en la tierra. Maglor arroja su Silmaril al mar, y él desde entonces vaga por las orillas del mar lleno de arrepentimiento. El tercer Silmaril pertenece al aire y Eärendil lo porta sin repercusión para él.

Los noldor son perdonados y aquellos que lo deseen pueden regresar a Aman, a habitar la isla de Tol Eressëa, donde antaño vivieron los Teleri antes de fundar Alqualondë. Sin embargo no todos los noldor regresan, y se quedan con sus líderes, Gil-Galad como Rey Supremo y Galadriel hermana de Finrod, desposada con Celeborn de Doriath. Los noldor establecen sus reinos en Lindon y Eriador. A los Edain se les concede como regalo por su lealtad la isla de Númenor, donde establecen un largo reinado.

Se les concede a los medio elfos el poder de elegir su destino, si mortal o élfico. Elros elige el destino de los hombres y se convierte en el primer rey de Númenor. Elrond elige el destino de los elfos y se convierte en el segundo al mando de Gil-Galad, el cual vive en Mithlond, los Puertos Grises, con Círdan. Galadriel y Celeborn se van a Eregion, región fundada entonces por los noldor, al lado de la ciudad de Khazad-dûm de los enanos.

Con el fin de la Guerra de la Ira y el hundimiento de Beleriand comienza la Segunda Edad del Sol.


</doc>
<doc id="28176" url="https://es.wikipedia.org/wiki?curid=28176" title="Ivanhoe (película de 1952)">
Ivanhoe (película de 1952)

Ivanhoe es una película de coproducción angloestadounidense de 1952 basada en la novela del mismo título escrita en 1819 por Sir Walter Scott. 

La película, que contó con la dirección de Richard Thorpe y con la actuación de Robert Taylor, Elizabeth Taylor, Joan Fontaine, George Sanders y Finlay Currie, tuvo tres candidaturas a los Premios Óscar.

A su regreso de las Cruzadas, el rey Ricardo Corazón de León (Norman Wooland) es apresado en Austria. Para su rescate es necesaria una elevada suma de dinero que su hermano Juan sin Tierra (Guy Rolfe) se niega a pagar, ya que así puede seguir usurpando el trono de Inglaterra. Entre los partidarios de Ricardo se encuentra el caballero sajón Wilfred de Ivanhoe (Robert Taylor), quien lucha por conseguir el rescate. Ivanhoe era hijo de Cedric el sajón (Finlay Currie), dirigente de la resistencia sajona frente a la dominación normanda. Pero éste había renegado de su hijo porque había marchado a las Cruzadas sin su autorización, abandonando temporalmente a Lady Rowena (Joan Fontaine), última descendiente de la realeza sajona. 

Por ese motivo, Ivanhoe tendrá que reconciliarse primero con su padre, para conseguir con él y los demás sajones que apoyan al rey Ricardo, luchar contra Juan Sin Tierra a fin de lograr restaurar en el trono a su legítimo rey. 
Para conseguir el perdón paterno, Ivanhoe acude a un torneo organizado por el príncipe Juan y sus barones traidores, pero antes de participar en él, Ivanhoe salva a un judío, Isaac de York (Felix Aylmer), de ser asesinado. Como recompensa por su acción, su hermosa hija, Rebeca, (Elizabeth Taylor) le obsequia sus joyas a Ivanhoe con el fin de que pueda adquirir armadura, armas y caballo para participar en el torneo. Rebeca ha comenzado a enamorarse de Ivanhoe.

Cuando Ivanhoe llega de incógnito al torneo, con el nombre de "El Desheredado", los campeones normandos han vencido a todos los sajones que han osado enfrentarse a ellos. Ivanhoe los enfrentará uno a uno hasta derrotarlos a todos; a saber, sir Ralph de Vipont, Phillip de Malvoisin, Front de Boeuf (Francis De Wolff), sir Hugh de Bracy (Robert Douglas) y el templario sir Brian de Bois-Gilbert (George Sanders), quien ya se había enfrentado con Ivanhoe en Tierra Santa. 

Es precisamente Bois-Gilbert quien hiere gravemente a Ivanhoe en el último combate, aunque igualmente cae derrotado pues De Bracy lo había herido levemente en el anterior choque.

Finalmente, Ivanhoe es declarado vencedor y se le concede el derecho de elegir a la reina del torneo, Ivanhoe elige a Lady Rowena, ante la decepción de Rebeca que ha acudido con su padre a ver el encuentro.

Ivanhoe se desploma a causa de sus heridas y todos descubren su identidad, que hasta entonces había permanecido oculta; incluso su padre lo ensalza por su hazaña. Pero, es Rebeca, quien previa conversación y acuerdo con Lady Rowena, también muy preocupada por la suerte del guerrero Ivanhoe, se ocupa de trasladarlo a su casa a fin de cuidarlo y curar sus heridas hasta alcanzar su completa recuperación. 

A partir de este momento la acción se torna agitada. En el traslado de Ivanhoe, es hecho prisionero junto con sus protectores judíos, al igual que su padre y su séquito, en el cual está Lady Rowena. Todos ellos son llevados al castillo de Frente de Buey, donde Bois-Gilbert cortejará a Rebeca, y De Bracy a Lady Rowena. 

Pero los traidores normandos son sorprendidos por Robin de Locksley (Robin Hood) (Harold Warrender) y sus hombres, que asaltan el castillo. Frente de Buey muere en la defensa, de Bracy se rinde, y Bois-Gilbert huye con Rebeca al santuario de los Templarios.

Ivanhoe logra reunir el rescate para Ricardo, recibiendo entre otras la aportación de Isaac de York y parte del pueblo judío que contribuyen con dinero emolumentos de su pueblo para lograr la liberación del rey Ricardo.

Mientras, Rebeca es juzgada como hechicera o bruja, por usar sus conocimientos de herbolaria para curar enfermos, y acusada de haber hechizado al caballero Bois-Gilbert, quien en el fondo está perdidamente enamorado de ella. A punto de ser condenada, Ivanhoe lanza su guante, como símbolo de reto y solicita un "Juicio de Dios", en el cual la inocencia o culpabilidad de Rebeca se decidirá en un torneo a muerte entre el retador de la acusada, Ivanhoe, y el campeón elegido por la acusación, que definitivamente es Bois-Gilbert.

Rebeca asiste al duelo entre los dos valerosos guerreros: uno, al que ella ama, empeñado en demostrar su inocencia; el otro que la ama a ella, condenado a demostrar su culpabilidad, tras una demostración de los dos caballeros en su habilidad en manejo de las armas, Ivanhoe dará muerte a Gilbert y salvará a Rebeca. En ese instante, el rey Ricardo Corazón de León irrumpe en el torneo junto a sus caballeros, su hermano Juan Sin Tierra, el usurpador, baja la cabeza en señal de sumisión y es sometido, mientras el verdadero rey, Ricardo Corazón de León, exhorta a todo el pueblo a fortalecer la unión.




</doc>
<doc id="28177" url="https://es.wikipedia.org/wiki?curid=28177" title="Klute">
Klute

Klute (en Argentina y en España, Klute; en México y en Venezuela, Mi pasado me condena) es una película estadounidense de 1971 dirigida por Alan J. Pakula y con Jane Fonda y Donald Sutherland en los papeles principales.

La película fue galardonada con varios premios cinematográficos estadounidenses y uno internacional.

Trata de la historia de una prostituta que colabora con un detective en la solución de un caso.


En papeles menores aparecen Sylvester Stallone, Harry Reems, Richard Jordan, Veronica Hamel y Kevin Dobson.




</doc>
<doc id="28181" url="https://es.wikipedia.org/wiki?curid=28181" title="The Usual Suspects">
The Usual Suspects

The Usual Suspects (llamada Los sospechosos de siempre o Sospechosos comunes, en Hispanoamérica, y Sospechosos habituales, en España) es una película estadounidense de 1995, escrita por Christopher McQuarrie (quien ganó un por este trabajo) y dirigida por Bryan Singer. Fue protagonizada por Kevin Spacey (Oscar al Mejor Actor de Reparto), Gabriel Byrne, Stephen Baldwin, Benicio del Toro y Kevin Pollak.

La película, con un presupuesto de 4 millones de dólares, no fue muy bien recibida en las salas de cine durante su lanzamiento, formando parte de la lista de «Las películas más odiadas por Roger Ebert», pero fue atractiva para muchos seguidores del género de crimen/drama y es considerada una película de culto. Diez años después de su estreno permanece en el Top 25 de Internet Movie Database «Top 250 Movie List». Forma parte del AFI's 10 Top 10 en la categoría de "Películas de misterio".

Roger «Verbal» Kint (Kevin Spacey) es un pequeño estafador lisiado que se encuentra en un interrogatorio de la policía de Los Ángeles y le cuenta a su interrogador, el Agente Kujan (Chazz Palminteri), una historia sobre los acontecimientos que desencadenaron un tiroteo y una masacre dentro de un barco apostado en el puerto de Los Ángeles. Usando la narración en retrospectiva, la historia de Verbal llega a ser cada vez más compleja, mientras él intenta "aclarar" los hechos, para la satisfacción del Agente Kujan, que está interesado en saber por qué él y sus compañeros de crimen estaban en ese barco.

En un barco en la bahía de San Pedro, una figura sin rostro identificada como "Keyser" habla brevemente con un hombre herido llamado Keaton (Byrne), entonces Keyser parece dispararle a Keaton, antes de poner el barco en llamas. Al día siguiente, el agente del FBI Jack Baer (Giancarlo Esposito) y los del Servicio de Aduanas del agente especial David Kujan (Palminteri) llegan a San Pedro por separado para investigar lo sucedido en el barco en eso llega el agente federal Josh Hillman junto con el comisario Peter Turner de los U.S Marshals debido aque Uno de ellos es un fugitivo. Parece que hay sólo dos supervivientes: Roger "Verbal" Kint (Spacey), un estafador con una leve parálisis y un criminal llamado Arkosh Kovash (Morgan Hunter). Baer interroga a Kovash quien está atendiendo sus graves quemaduras en el hospital. Este afirma que Keyser Söze, un genio criminal turco con una reputación casi mítica, se encontraba en el puerto para "matar a muchos hombres". Kovash comienza a describir a Söze a través de un intérprete, mientras que un dibujante de la policía hace una representación de la cara de Söze. Mientras tanto, Verbal ha testificado en detalle sobre el incidente a cambio de casi total inmunidad. A la espera de pagar la fianza por el cargo menor de armas, Verbal se coloca en la abarrotada oficina del sargento de policía de San Pedro, Jeffrey Rabin (Dan Hedaya) donde Kujan exige escuchar su historia desde el principio. Verbal comienza seis semanas antes en Nueva York:

Cinco delincuentes se unen en una línea de policía: Dean Keaton (Gabriel Byrne), un oficial de policía corrupto que aparentemente ha renunciado a su vida de crimen; Michael McManus (Stephen Baldwin), un ladrón profesional de mal genio; Fred Fenster (Benicio del Toro), Verbal Kint y Todd Hockney (Kevin Pollak).

Mientras están los cinco detenidos, McManus convence a los demás de unir fuerzas para cometer un robo dirigido a "El mejor servicio de taxis en New York", un grupo de corruptos agentes de policía que escoltan a contrabandistas a sus destinos en la ciudad. Tras el robo con éxito, el quinteto viaja a Los Ángeles para vender su botín a un conocido de McManus, "Redfoot" (Peter Greene), quien les propone otro trabajo: robar a un comerciante de joyas. En lugar de llevar joyas o dinero como se les dijo, llevaba heroína . Un enfrentamiento furioso entre los ladrones y Redfoot revela que el trabajo vino de un abogado llamado Kobayashi (Pete Postlethwaite). Los ladrones más tarde se reúnen con Kobayashi, quien afirma que trabaja para Keyser Soze y los chantajea para atacar un barco en el puerto de San Pedro. Kobayashi describe la misión de un barco de contrabando de 91 millones de dólares en cocaína, va a ser vendida por rivales de Söze. Los ladrones deben a destruir la droga y, si deciden esperar hasta que los compradores lleguen, pueden dividir el dinero como quieran.

En la actualidad, Verbal le cuenta a Kujan la historia de Keyser Söze: después de que sus rivales húngaros invadieron su casa, son sorprendidos de que mata a su propia esposa e hijos, y luego masacra a la multitud entera, menos a uno. Después de ese incidente Söze pasó a la clandestinidad, nunca trata directamente con alguien en persona, y dice que se convirtió en "un cuento de miedo que cuentan los criminales a sus hijos por la noche". Kujan no está familiarizado con Söze, Verbal dice que ha oído rumores durante años sobre criminales que trabajan para Söze pero en realidad no saben para quién trabajan. Verbal también dice que Fenster intentó huir, dando lugar a una sentencia de muerte por Kobayashi. Los restantes cuatro ladrones secuestran a Kobayashi, con la intención de matarlo si él no los deja en paz. Amenazado, Kobayashi revela que Edie Finneran (Suzy Amis), abogada y novia de Keaton, está en su oficina (creyendo que fue contratada para los servicios jurídicos), y amenaza con matarla, así como a las familias de los cuatro ladrones, en caso de negarse a hacer el trabajo.

En la noche de la venta de cocaína, los vendedores (un grupo de argentinos mafiosos) y los compradores (un grupo de mafiosos húngaros) se encuentran en el muelle. Keaton le dice a Verbal que no vaya y que tome el dinero si el plan sale mal para que junto con Edie (su novia) puedan perseguir a Kobayashi en "su camino". Verbal acepta a regañadientes, y mira el barco desde la distancia. Keaton, McManus, Hockney atacan a los hombres en el muelle, matando a la mayoría de ellos. Keaton y McManus están a bordo de la nave para encontrar la droga mientras Hockney va detrás de la furgoneta que transportaba el dinero pero es fatalmente disparado por alguien invisible cuando la encuentra. Keaton y McManus descubren que no hay cocaína en el barco. Mientras, un pasajero argentino muy bien resguardado, es asesinado por el asaltante invisible mientras éste es buscado. McManus es asesinado con un cuchillo en la parte posterior de su cuello y Keaton, dándose la vuelta para irse, es herido por una bala por un hombre vestido con un traje negro y sombrero. La misteriosa figura parece hablar brevemente con Keaton antes de dispararle de nuevo.

Cuando Verbal termina la historia, Kujan revela lo que sabe: el cuerpo del hombre argentino fue encontrado por la mañana en la costa, y se revela al hombre, Arturo Márquez (Castulo Guerra), quien con el fin de escapar de la cárcel, le había revelado a las autoridades que él podría identificar a Keyser Söze. El asume que el grupo de húngaros son el mismo grupo que Söze casi aniquila en Turquía y se ofrecen a comprar a Márquez del grupo argentino por 91 millones de dólares. Con la fabricación de un acuerdo, Kujan especula, Söze contrató a Verbal y su equipo para que fueran a robar a los muelles, cuando en realidad se trataba de una tapadera para que Söze entrara personalmente en el barco y matara a Márquez sin ser detectado. Kujan a través de su análisis concluye que Keaton era realmente Keyser Söze. Está convencido de que Keaton ha fingido su muerte (como lo había hecho unos años antes de escapar de otra investigación), y deliberadamente dejó a Verbal como testigo. Bajo un interrogatorio agresivo de Kujan, Verbal entre lágrimas admite que todo el asunto era idea de Keaton desde el principio, pero se niega a declarar.

Verbal sale por libertad bajo fianza después de haber sido arrestado, Verbal recupera sus cosas personales del funcionario de la propiedad. Momentos más tarde, Kujan, relajado en la oficina de Rabin, se da cuenta con sorpresa de que los detalles y los nombres de la historia de Verbal son extraídos de varios objetos alrededor de la habitación, incluyendo el tablón de anuncios lleno de gente de Rabin y el logo de la "Compañía de porcelana Kobayashi" en la parte inferior de la taza de café. Kujan se da cuenta de que la mayor parte de la historia de Verbal fue improvisada para su beneficio y va tras él, corriendo junto a una máquina de fax, que recibe la impresión del dibujo de la policía de la cara de Keyser Söze, que se asemeja a nada menos que a Verbal Kint.

Mientras tanto, Verbal se aleja de la comisaría de policía, dejando de fingir su parálisis cerebral. Se sube a un coche esperando conducido por "Kobayashi", alejándose mientras Kujan sale fuera, buscando en vano. Verbal cita a Charles Baudelaire: "El mayor truco del diablo fue convencer al mundo de que no existía". Esto es seguido por la descripción anterior de Keyser Söze: "Y así, él se ha ido".


</doc>
<doc id="28183" url="https://es.wikipedia.org/wiki?curid=28183" title="Gelsa">
Gelsa

Gelsa es una localidad y municipio español de la Ribera Baja del Ebro, provincia de Zaragoza, Aragón.
Tiene una población de 1 122 habitantes (INE 2014).

Gelsa está situada en la Depresión del Ebro sobre depósitos cuaternarios, en la margen izquierda del río a 147 msnm, siendo uno de los municipios de Aragón situado a menor altitud.
Se encuentra a tan sólo 5 km de la capital comarcal, Quinto, y a 45 km de Zaragoza.

Tiene una temperatura media anual de 13,9 °C y una precipitación anual de 340 mm.

El topónimo Celsa proviene de la colonia romana Lépida Celsa, primera colonia romana fundada en el valle del Ebro, y que originariamente era un poblado íbero de los ilergetes denominado Kelse.
Aunque el núcleo de dicha población se encuentra en la vecina Velilla de Ebro, es muy probable que se extendiera también hasta la actual Gelsa, como parecen atestiguar los hallazgos de enterramientos y de una lápida dedicada a la diosa Obana.
Julio César concedió a Celsa título y honores de colonia romana antes del año 43 a.C., y la distinguió con singulares privilegios como la acuñación de moneda.
Con Augusto empezó una lenta decadencia de esta colonia a favor de Caesaraugusta, actual Zaragoza.
Se piensa que el fin de Celsa pudo producirse durante la invasión de Hispania por los bárbaros.

La localidad de Gelsa fue probablemente fundada por los árabes tras su conquista de la península ibérica; algunas construcciones son de dicha época, como las calles de los Cubiertos y Ocho Esquinas, el Pilón de las Levatas y el Pilón de la Atalaya, hoy desaparecido.
La huella árabe está también presente en los sistemas de riego tales como el azud, las norias y las acequias.

Posiblemente Gelsa fue reconquistada para los reinos cristianos por Pedro I poco después de la conquista de Barbastro, aunque la población musulmana continuó ocupando estas tierras tras la ocupación.
En 1210, Pedro II cedió Gelsa en señorío, junto con otros lugares de la baronía de Quinto, a los Torrellas Ortiz, que las vendieron al conde Lope de Luna en 1358.
En 1431, el señorío pasó a Juan de Funes; el octavo señor de esta casa, Antonio de Funes, fue quien mandó construir el palacio de la plaza Mayor.

El fogaje de 1495 realizado en el Reino de Aragón deja constancia de que en aquella época la práctica totalidad de los habitantes de Gelsa —unos 400 aproximadamente— eran moriscos.
En 1610, era el pueblo de Zaragoza donde más moriscos vivían (en torno a 1 700) y el tercero de todo Aragón.
En consecuencia, la expulsión de los moriscos de España a partir de 1609 hizo necesario repoblar la villa, por lo que Juan de Funes y Villalpando expidió una carta puebla para Gelsa (1628).
Por otra parte, María Francisco Climente, primera esposa de Juan, fue quien aportó a la localidad la reliquia de la «Santa Espina» —véase más abajo—, quedando custodiada en el Monasterio de la Purísima Concepción y la Santa Espina.

La Iglesia Parroquial, dedicada a San Pedro, fue erigida en el último tercio del siglo XVII y en 1728 se construyó una fábrica de tejidos de lana dirigida por el ingeniero gelsano José Genzor y López de Perea. Los graneros del conde —actualmente el Centro Cultural— fueron construidos antes de 1779.

Pascual Madoz, en su Diccionario geográfico-estadístico-histórico de España de 1845, refiere que «Jelsa» —escrito de esta manera— «"cuenta con 380 casas, inclusa la del ayuntamiento y cárcel, el palacio del Sr. conde de Montijo, barón de Quinto... la iglesia parroquial (San Pedro Apóstol)... una pequeña capilla llamada de Pedro, que se dice fue la primera parroquia y cuyo edificio se halla bastante quebrantado [y] una ermita dedicada a la virgen del Buen Suceso"».
Menciona también la existencia de «"telares donde se elaboran estameñas, fajas y mantas, un molino harinero con 4 muelas, 2 de aceite y un batán"».

A principios del siglo XV, la población de Gelsa era de unos 1 700 habitantes, cifra que, tras la expulsión de los moriscos, se vio disminuida a menos 400 habitantes.
Ya en el siglo XIX, el censo de España de 1857 registra 2 818 habitantes para Gelsa, que era en ese momento el segundo municipio más poblado del partido judicial de Pina —al que entonces pertenecía—, después de Pina de Ebro.
Sin embargo, su evolución demográfica en los dos últimos tercios del siglo XX ha sido regresiva: 2 120 habitantes en 1930, 1 595 habitantes en 1970 y 1 239 habitantes en 2001. En 2014 el municipio contaba con 1 122 habitantes.
La economía de la localidad se basa en la agricultura, la ganadería y la industria del yeso, ya que existen dos fábricas dedicadas a la producción de yesos y escayolas.

En el terreno agrícola, es muy importante el cultivo de secano —trigo—, mientras que la agricultura de regadío o de huerta es de gran calidad. Destaca el contraste del paisaje de la ribera del Ebro con la aridez del resto del paisaje monegrino.
Por su parte, la ganadería es actividad menos importante y se dedica al ganado ovino y bovino.

Actualmente se intenta desarrollar el polígono industrial "La Atalaya".

Es de interés artístico el casco antiguo, también llamado «barrio morisco», lugar donde se agruparon tras la reconquista las viviendas de los musulmanes. Esta parte está caracterizada por sus calles estrechas y «cubiertos» (edificaciones situadas sobre la calle que comunican las casas de uno y otro lado).

La iglesia parroquial de la localidad, dedicada a San Pedro Mártir de Verona, fue construida en el último tercio del siglo XVII y posteriormente reformada en 1863.
Presenta fábrica de ladrillo, tapial y zócalo de sillar. Tiene tres naves, crucero, cabecera plana, cubierta de bóveda de lunetos y cúpula sobre el crucero.
Su torre fue levantada en 1826 y el reloj con campanas fue instalado en 1899.
La parroquia alberga en su interior un relicario de cristal guarnecido en oro con forma de columna; contiene la llamada «Santa Espina», que según la leyenda procede de la corona de espinas que llevó Jesús de Nazaret.

El Convento de las Monjas Clarisas, emplazado frente a la iglesia, fue construido por mandato de D. Juan de Funes Villalpando y Ariño, Marqués de Osera, en 1621. Lo ocuparon durante diez años los Padres Franciscanos venidos de Pina de Ebro, que después volvieron a Pina.

La Ermita de Nuestra Señora del Buen Suceso, patrona de la villa, tiene fábrica de ladrillo y tapial.
Posee ábside semicircular y cubierta de bóveda de lunetos, sobre el porche de entrada, con tres arcos de medio punto. Edificada en el siglo XVIII, fue quemada en 1936 y posteriormente reconstruida con donativos de los vecinos.

En cuanto a la arquitectura civil, cabe destacar el edificio del Ayuntamiento, casino durante los siglos XIX y XX, así como la casa palacio de la familia Funes, situada en la plaza Mayor, que data del siglo XV.





</doc>
<doc id="28187" url="https://es.wikipedia.org/wiki?curid=28187" title="Sesgo estadístico">
Sesgo estadístico

En estadística se llama sesgo de un estimador a la diferencia entre su esperanza matemática y el valor numérico del parámetro que estima. Un estimador cuyo sesgo es nulo se llama "insesgado" o "centrado".

En notación matemática, dada una muestra formula_1 y un estimador formula_2 del parámetro poblacional formula_3, el sesgo es:

El no tener sesgo es una propiedad deseable de los estimadores. Una propiedad relacionada con esta es la de la consistencia: un estimador puede tener un sesgo pero el tamaño de este converge a cero conforme crece el tamaño muestral.

Dada la importancia de la falta de sesgo, en ocasiones, en lugar de estimadores "naturales" se utilizan otros corregidos para eliminar el sesgo. Así ocurre, por ejemplo, con la varianza muestral.

En el diseño y elaboración de un estudio de investigación en clínica, puede haber distintos tipos de sesgos:




</doc>
<doc id="28191" url="https://es.wikipedia.org/wiki?curid=28191" title="Metaanálisis">
Metaanálisis

El metaanálisis es un conjunto de herramientas estadísticas, que son útiles para sintetizar los datos de una colección de estudios. El meta-análisis se inicia recopilando estimaciones de un cierto efecto (expresado en un índice de tamaño del efecto, como la diferencia de medias tipificada, la razón de riesgo, o la correlación) de cada estudio. El metaanálisis permite valorar estos efectos en contexto: si el tamaño del efecto es consistente, el efecto del tratamiento puede ser considerado como fuerte y el tamaño del efecto se estima con mayor precisión que con un solo estudio. Si el tamaño del efecto varía, esa variación puede ser descrita y, potencialmente, explicada.

El término metaanálisis, como tal, fue inicialmente aplicado en las ciencias sociales y en psicología. A partir de la década de los 80, se comenzó a aplicar de forma creciente en medicina y a partir de los 90 son muy frecuentes los artículos que describen resultados de metaanálisis en publicaciones médicas.

El término "metaanálisis" fue acuñado por "Gene V. Glass" en 1976, siendo el primer estadístico moderno en señalar que su mayor interés era "a qué hemos llamado el "meta-análisis" de la investigación científica". Aún cuando esto le permitiera ser ampliamente reconocido como el fundador del método moderno, no fue sino hasta la década de los 1990's cuando la práctica de los meta-análisis comenzó a figurar, pero no siempre, como los componentes importantes de un proceso de revisión sistemática. La teoría estadística en torno al metaanálisis mejoró notablemente gracias al trabajo desempeñado por Nambury S. Raju, Larry V. Hedges, Harris Cooper, Ingram Olkin, John E. Hunter, Jacob Cohen, Thomas C. Chalmers, Robert Rosenthal, y Frank L. Schmidt.

Conceptualmente hablando, se utiliza un enfoque estadístico para combinar los resultados de múltiples estudios. Por tanto, sus ventajas son las siguientes:


El metaanálisis que arrojan varios estudios de corto alcance, no predice los resultados de un solo estudio amplio. Algunos han argumentado que una debilidad del método es que los focos de sesgo no están controlados por el método: un buen metaanálisis de estudios mal diseñados todavía dará lugar a malas estadísticas. Esto significaría que sólo los estudios metodológicamente sólidos deben ser incluidos en un metaanálisis, una práctica llamada «síntesis de la mejor prueba». Otros analistas incluirían estudios más débiles, y añadirían una variable de predicción a nivel de estudio que refleje la calidad metodológica de los estudios para examinar el efecto de la calidad del estudio sobre el tamaño del efecto. Sin embargo, otros han argumentado que el mejor enfoque es el de preservar la información sobre la variación en la muestra del estudio, echando una red tan amplia como sea posible, y que los criterios de selección metodológica introduzcan subjetividad no deseada, anulando el propósito de este enfoque.

Otro escollo potencial es la confianza en lo disponible de estudios publicados, lo que puede generar resultados exagerados debido a dicho sesgo, pues los estudios que muestran resultados negativos o insignificantes tienen menos probabilidades de ser publicados. Para cualquier área de investigación determinado, no se puede saber cuántos estudios han sido ocultados o descartados.

Este problema resulta en la distribución de tamaños del efecto que están sesgados, asimétricos o totalmente aislados; creando un "error común de razonamiento lógico", en el que se sobreestima la importancia de los estudios publicados, mientras otros estudios ni se publican. Esto debiera ser considerado en serio al interpretar los resultados de un metaanálisis.

Esto se puede visualizar con un gráfico de embudo, el cual, es un diagrama de dispersión del tamaño de muestra y de efecto. Para un cierto nivel de efecto, cuanto menor sea el estudio, mayor es la probabilidad de encontrarlo por casualidad; al mismo tiempo, cuanto mayor sea el nivel de efecto, menor será la probabilidad de que un estudio más grande pueda resultar así de positivo. En caso de que muchos estudios negativos no fuesen publicados, los positivos restantes darían lugar a tal gráfico de embudo en el cual el tamaño de efecto es inversamente proporcional al tamaño de muestra, es decir, una parte importante del efecto que se muestra se debe a la posibilidad de que no se equilibra en el diagrama por ausencia de datos negativos no publicados. En cambio, al publicarse la mayoría de estudios, el efecto mostró no tener razón para sesgarse por el tamaño de estudio; por lo cual resulta, un gráfico de embudo simétrico. Así que, si no hay sesgo de publicación, no habría relación alguna entre el tamaño de muestra y el tamaño de efecto. Una relación negativa entre el tamaño de muestra y el de efecto implicaría que los estudios que encontraron efectos significativos fueran más propensos de publicarse y/o enviarse para tal fin. Hay varios procedimientos disponibles que intentan corregir el problema de cajón al identificarse, tales como adivinar en la mecha de distribución de los efectos de estudio.

Los métodos para detectar el sesgo de publicación han sido polémicos ya que suelen tener bajo impacto para detectarlo, incluso pueden generar falsos supuestos bajo ciertas circunstancias. Un método conjunto para analizar el sesgo de publicación ha sido propuesto para abatir falsos supuestos y sugerir que el 25% de los metaanálisis en psicología podrían tener sesgo de publicación. Sin embargo, los posibles problemas de bajo impacto siguen siendo controvertidos y las estimaciones de sesgo podrían ser inferiores a la cantidad real.

El error más grave en el metaanálisis (H. Sabhan) ocurre a menudo cuando la(s) persona(s) realizando un metaánálisis tiene(n) una agenda económica, social, o política, como la aprobación o la reprobación legislativa. La gente con estos tipos de agendas podrían ser más propensos de utilizar indebidamente los metaanálisis debido a sus prejuicios.


Para conocer las directrices de informes, consulte los artículos de Reporte Preferidos para Revisiones Sistemáticas y los Meta-análisis ("Preferred Reporting Items for Systematic Reviews and Meta-Analyses" - PRISMA, por sus siglas en inglés).

En general, existen dos tipos de prueba que se pueden distinguir al realizar un metaanálisis: los datos iniciales aportados por cada participante (DIP) y los datos de agregado (AD). Considerando que los datos iniciales representan la información en bruto procedente de los centros de estudio, los agregados de hecho son más comunes y disponibles (por ej: desde la literatura) y típicamente representan estimaciones globales, tales como razones de ventaja (odds ratio) o riesgos relativos. Esta distinción ha incrementado las necesidades de diferentes métodos cuando la prueba es deseada, conduciendo al desarrollo de métodos de una o dos etapas; en los de una etapa, los datos iniciales son simultáneamente modelados mientras representan la agrupación de participantes dentro de los estudios; por el contrario, los métodos de dos etapas, sintetizan los datos agregados de cada estudio y consideran aquí las cargas de estudio. Reduciendo los datos iniciales a datos agregados, los métodos de dos etapas pueden incluso aplicarse cuando se cuenta con los datos iniciales; lo que presenta una alternativa de acción al realizar el metaanálisis.

Aunque se cree que los métodos de una o dos etapas arrojan resultados parecidos, estudios recientes han demostrado que dichos métodos pueden a veces llevar a diferentes conclusiones.

El modelo de efectos fijos ofrece una ponderación de estimaciones seriadas: se suele emplear el inverso de la varianza de cada estimación como peso del estudio, de tal manera que los estudios con muestras mayores tienden a contribuir más a la media ponderada que los estudios con muestras menores. En consecuencia, cuando los estudios en un metaanálisis son dominados por uno grande, los hallazgos en estudios más pequeños resultan prácticamente ignorados. Lo más importante, este modelo supone que todos los estudios incluidos son idénticos: estudian a la misma población, usan la misma variable y definiciones de resultados, etc. Este supuesto es típicamente irreal porque toda investigación es propensa a ser influida por varias fuentes de heterogeneidad; así, los efectos del tratamiento pueden diferir según la configuración regional, los niveles de dosificación, las condiciones de estudio.

Un modelo común para sintetizar estudios heterogéneos, es el "modelo de efectos aleatorios"; este es tan solo la media ponderada de los tamaños del efecto de un grupo de estudios. El peso que se aplica en este proceso de ponderación con un metaanálisis de efectos aleatorios se realiza en dos pasos:


En un caso extremo en el que la varianza específica sea muy grande puede ocurrir que el peso esté muy condicionado por esa varianza, resultando despreciable en términos prácticos los tamaños muestrales de los estudios. De esta forma, la media ponderada será muy cercana a la media aritmética simple, no ponderada. En el extremo opuesto está el caso en que la estimación de la varianza específica proporciona el valor cero. En este caso los pesos serán iguales a los inversos de las varianzas de muestreo y el resultado será idéntico al que se obtiene bajo el modelo de efecto fijo. El modelo de efecto fijo es un caso particular del modelo de efectos aleatorios, que se produce cuando la varianza específica es igual a cero.

La medida de esta inversión depende únicamente de dos factores: la heterogeneidad de precisión, y la heterogeneidad del tamaño del efecto:

El método más utilizado para estimar la varianza específica y tener en cuenta la heterogeneidad es el método de DerSimonian-Laird (DL), o método de los momentos, propuesto en 1986. Posteriormente se han propuesto otros métodos, como el de máxima verosimilitud restringida (REML), un método iterativo y computacionalmente más intensivo. Sin embargo, una comparación entre estos dos modelos (y otros) demostró que hay pocas diferencias prácticas y DL es bastante adecuado en la mayoría de los escenarios.

La Meta-regresión es una herramienta utilizada en el metaanálisis para examinar el impacto de las variables moderadoras en el estudio del tamaño del efecto utilizando técnicas basadas en regresión. La meta-regresión es más eficaz en esta tarea, de lo que son las técnicas de regresión estándar.

En Medicina, un metaanálisis es el estudio basado en la integración estructurada y sistemática de la información obtenida en diferentes ensayos clínicos, sobre un problema de salud determinado. Consiste en identificar y revisar los estudios controlados sobre un determinado problema, con el fin de dar una estimación cuantitativa sintética de todos los estudios disponibles. Dado que incluye un número mayor de observaciones, un metaanálisis tiene un poder estadístico superior al de los ensayos clínicos que incluye. Los dos principales problemas metodológicos de los metaanálisis de ensayos clínicos son:
Un metaanalisis clínico se basa principalmente en una integración o reciclaje entre la información ya obtenida y poder obtener un análisis mayor.

El primer "metaanálisis clínico" fue realizado por Karl Pearson en 1904, en un intento de superar el problema del reducido poder estadístico de los estudios con pequeños tamaños muestrales; si se analizan los resultados de un grupo de estudios similares, se puede alcanzar una valoración más exacta de los efectos.

En Estadística, un metaanálisis se refiere al conjunto de métodos enfocados a contrastar y combinar los resultados de diferentes estudios; con la esperanza de identificar patrones entre los resultados de estudio, las fuentes de desacuerdo entre dichos resultados, u otras relaciones interesantes que pueden salir a la luz en el contexto de múltiples estudios.

En su más simple forma, se lleva a cabo al identificar una medida común del tamaño de efecto; del cual un promedio ponderado podría ser el dato de salida en un metaanálisis. La ponderación podría estar relacionada con tamaños de muestra dentro de los estudios individuales.

Más a menudo, hay otras diferencias entre los que necesitan ser permitidos; pero el objetivo general de un metaanálisis radica en estimar con mayor fuerza el tamaño real de efecto, en contraste a uno menos preciso derivado en un solo estudio bajo un sencillo conjunto determinado de supuestos y condiciones.






</doc>
<doc id="28194" url="https://es.wikipedia.org/wiki?curid=28194" title="Yakuza">
Yakuza

La yakuza (ヤクザ) es el equivalente del crimen organizado; es una mafia japonesa que data del siglo XVII. El origen de la palabra no se conoce con exactitud, pero se dice que proviene de un juego de cartas llamado Hanafuda, muy famoso entre los "bakuto", en el que la peor mano consiste en un 8 (ya), un 9 (ku) y un 3 (za). La Yakuza moderna ha extendido sus actividades a la corrupción bancaria y política. Esta mafia en 2009, el último año del que se tiene registro, tenía un estimado de 87 900 miembros en Japón.

Es la mafia más temida de Japón. Durante el período Edo, la figura del samurái era privilegiada dentro de la sociedad debido a su eficiencia militar y los servicios de seguridad que prestaban a la comunidad, a través de los "daimyō", señores feudales. Al final del período de guerras, Japón inicia su era moderna y continúa unificándose en un solo gobierno, así que muchos samuráis eran despedidos porque resultaban inútiles a los nuevos destinos de la nación y se convertían en mercenarios ambulantes conocidos como "rōnin". Estos siguieron haciendo trabajos de manera independiente para sus jefes y la alta sociedad. Al cabo del tiempo se empezaron a organizar en bandas paramilitares que protegían regiones a cambio de comida y comodidades que proporcionaba la comunidad. Poco tiempo después terminan dominando los negocios ilegales de Japón.

A finales del siglo XIX y al iniciarse el XX tenían el control de las apuestas, el contrabando, lavado de dinero, los espectáculos, la especulación de bienes inmobiliarios, la extorsión, el tráfico de drogas y armas. Además, después de la Segunda Guerra Mundial ciertas bandas de ideología ultraderechista comenzaron a operar y extorsionar dentro de grupos políticos.

Su organización se derivó de los códigos de los samuráis pero mucho más estructurados y fortalecidos; todo el clan se considera una familia donde se profesa la fidelidad absoluta a la banda, el ultranacionalismo, la obediencia al mayor rango y su estricto y brutal código de honor. Los novatos se adoctrinan a través del sistema Senpai-kōhai, en el cual se especifican los procedimientos de castigo a la deslealtad, como por ejemplo la amputación de un dedo meñique para aquel miembro que cometa algún fallo grave o incurra en traición. Dicha amputación sirve aún en la actualidad para reconocer a los miembros retirados o disidentes.

Los tatuajes dentro de la organización son muy importantes; revelan muchas veces el rango dentro de la organización, el clan al que se pertenece, el lema del clan, algunos incluyen dragones y referencias a su genealogía samurái. La mayoría empieza como un tatuaje pequeño al que se le hacen adiciones y terminan cubriendo grandes partes del cuerpo; el tatuaje es uno de los rasgos físicos más característicos de la "yakuza". Tales tatuajes son aplicados con la técnica "tebori", la cual es muy dolorosa, y el tiempo que lleva terminar el tatuaje puede ser de meses o hasta años; no se tatúa con una sola aguja sino con varias. Los yakuzas llevan estos tatuajes para demostrar que pueden soportar el dolor.

En la actualidad la Yakuza está dividida en 3000 clanes con un total de 100 000 miembros. El más importante es el denominado Yamaguchi-gumi, el cual se estima en un tamaño de 40 000 miembros activos, considerándose el grupo dedicado al hampa más grande del mundo, no sólo por el número de miembros sino también por su poder económico. Son también importantes los clanes Sumiyoshi Rengo-Kai e Inagawa-kai, que en conjunto con el clan Yamaguchi-gumi mueven alrededor de 15 000 millones de dólares anuales.

A causa del Terremoto de Japón de 2011 los distintos grupos yakuza se movilizaron anónimamente en tareas de ayuda a las poblaciones afectadas.

De la palabra "yakuza" se desconoce el origen, pero está extendida la creencia de que proviene del estilo de vida de los "bakuto" (博徒, «apostadores»), una de las dos clases sociales que dieron origen a los yakuza, siendo los otros los "tekiya" («vendedores ambulantes»), los bakuto estaban muy abajo en la sociedad japonesa del Periodo Edo, por ser las apuestas ilegales. De ahí derivó su imagen indeseable y el nombre "ya" (ocho), "ku" (nueve) y "za" (tres), ya que 8, 9 y 3 son 20 puntos, que es la peor mano en el Oicho-Kabu, una variante del juego de cartas Hanafuda.

A continuación se listan los clanes yakuza más importantes, ordenados según el número de miembros que los integran:




</doc>
<doc id="28196" url="https://es.wikipedia.org/wiki?curid=28196" title="Jardines Colgantes de Babilonia">
Jardines Colgantes de Babilonia

Los Jardines Colgantes de Babilonia eran considerados una de las Siete Maravillas del Mundo Antiguo, y fueron construidos en el siglo VI a. C. durante el reinado de Nabucodonosor II en la ciudad de Babilonia (la Babel de los textos bíblicos), a orillas del río Éufrates (Mesopotamia). Las aguas para regar las plantas eran traídas desde las orillas del río Éufrates, que se encontraba en las faldas de la montaña. En los jardines se plantaban palmeras y árboles frutales, como el dátil y los cocos.

Se cree que sus diseños y construcciones se iniciaron en 600 a. C., por orden del rey Nabucodonosor II de la dinastía caldea del Imperio neobabilónico, como muestra de amor hacia su esposa Amytis, hija de rey Ciáxares del Imperio medo (Media o "Umman Manda"), para recordarle a las montañas de su tierra.
Era considerada una de las 7 maravillas del mundo junto con la Gran Pirámide de Guiza, el templo de Artemisa en Éfeso, la estatua de Zeus en Olimpia, el Mausoleo de Halicarnaso, el Coloso de Rodas y el Faro de Alejandría.

Una leyenda similar con menor sustento histórico, expresa lo siguiente: hacia el año 600 a. C., Sofía II, reina de los caldeos, quiso regalar a su esposo Octavio V, hijo del rey de los medos, algo que demostrara su amor por él y le recordara las hermosas montañas de su florida tierra, tan diferentes de las grandes llanuras de Babilonia.

Según otra leyenda, en cambio, los jardines habrían sido creados en el siglo IX a. C. Cerca de 810 a. C., reinaba Sammuramat en Asiria y Babilonia, llamada Semíramis por los griegos, viuda de Shamshiadad V, y regente de su hijo Adad-nirari III. Fue una reina valiente. Se dice que conquistó India y Egipto, pero no resistió que su hijo conspirara para derrotarla, y se suicidó.

Los jardines pertenecían a la Mesopotamia antigua y se cuentan entre las siete maravillas del mundo antiguo.

Los jardines estaban junto al palacio del Rey, contiguo al río, para que los viajeros los pudieran contemplar, ya que el acceso al pueblo estaba prohibido.
En la más alta de las terrazas se situaba un depósito de agua desde el cual corrían varios arroyos.

Los Jardines Colgantes de Babilonia no "colgaban" realmente en el sentido de estar suspendidos por cables o cuerdas. El nombre proviene de una traducción incorrecta de la palabra griega "kremastos" o del término en latín "pensilis", que no significa precisamente "colgar" pero si "sobresalir", como en el caso de una terraza o de un balcón.

El geógrafo griego Estrabón, quién describió los jardines en el siglo I a. C., escribió:
Las excavaciones arqueológicas más recientes en la antigua ciudad de Babilonia, en el actual territorio de Irak destaparon el asentamiento del palacio. Otros hallazgos incluyen la construcción abovedada con paredes gruesas y una irrigación cerca del palacio meridional.

Un grupo de arqueólogos examinó el área meridional del palacio y recreó la construcción abovedada como los Jardines Colgantes. Sin embargo, el historiador griego Estrabón había indicado que los jardines estaban situados en el río Éufrates, mientras que la construcción abovedada está alejada varios cientos de metros. Reconstruyeron el lugar del palacio y localizaron los jardines en el área que se extendía del río al palacio.

En la orilla del río, las paredes recientemente descubiertas de 25 metros de espesor pudieron estar escalonadas en forma de terrazas, tal como las describen las referencias griegas. Sin embargo, hay pocas pruebas para cualquiera de estas teorías, pues no se menciona nada en los numerosos documentos babilónicos de la época.

Con la posible decadencia de Babilonia y el fin del Imperio neobabilónico, los jardines fueron abandonados progresivamente. Cuando Alejandro Magno llegó a la ciudad en el siglo IV a.C., los jardines ya estaban parcialmente en ruinas y totalmente abandonados. Finalmente los jardines fueron destruidos por el rey Evemero en el año 126 a. C.




</doc>
<doc id="28197" url="https://es.wikipedia.org/wiki?curid=28197" title="Consentimiento informado">
Consentimiento informado

El consentimiento informado es el procedimiento mediante el cual se garantiza que el sujeto ha expresado voluntariamente su intención de participar en la investigación, después de haber comprendido la información que se le ha dado, acerca de los objetivos del estudio, los beneficios, las molestias, los posibles riesgos y las alternativas, sus derechos y responsabilidades.

En algunos casos, tales como el examen físico de un médico, el consentimiento es tácito y sobreentendido. Para procedimientos más invasivos o aquellos asociados a riesgos significativos o que tienen implicados alternativas, el consentimiento informado debe ser presentado por escrito y firmado por el paciente.

Bajo ciertas circunstancias, se presentan excepciones al consentimiento informado. Los casos más frecuentes son las emergencias médicas donde se requiere atención médica inmediata para prevenir daños serios o irreversibles, así como en casos donde por razón de incapacidad de hecho o biológica, el sujeto no es capaz de dar o negar permiso para un examen o tratamiento.

Consentimiento médico informado es el documento mediante el cual se garantiza que el candidato y/o trabajador, es informado y acepta voluntariamente la realización de las evaluaciones médicas ocupacionales después de haber comprendido la información que se le ha dado, acerca de los objetivos del examen, los beneficios, y las directrices a seguir.

El consentimiento informado tiene sus raíces legales en 1947 con el Código de Núremberg, a través del cual se juzgó a un grupo de médicos acusados de realizar experimentos caracterizados como crímenes en contra de la humanidad, cometidos contra prisioneros de guerra en campos de concentración nazis durante la Segunda Guerra Mundial, los cuales se realizaban sin información o consentimiento sobre los riesgos a los que se enfrentaban las víctimas.

En 1964 se promulgó en la Asamblea Médica Mundial la Declaración de Helsinki, que ha sido modificada en varias ocasiones, agrupando un conjunto de reglamentos que orientan a los médicos en experimentos con seres humanos, y resalta la importancia del consentimiento voluntario dentro de los protocolos de estudio.
La primera sentencia del consentimiento informado tuvo lugar en las islas británicas en 1767 en el caso Slater vs. Baker & Stapleton (Cfr. Galán Cortés Julio César, Responsabilidad civil médica), pero el documento se perdió.

El consentimiento informado debe reunir al menos cuatro requisitos que son:

Estudios a nivel internacional demuestran que hay una fuerte tendencia a considerar el consentimiento informado como una herramienta que protege a los proveedores de salud de problemas legales y reclamos, en vez de un proceso en el que se toman las decisiones en forma conjunta y responsable por parte del paciente y el profesional. Dado el aumento en los últimos años de las demandas contra profesionales sanitarios, éstos se protegen con la práctica de la llamada "medicina defensiva".

Todo paciente tiene el derecho a no ser informado si así lo expresa previamente, es decir, el paciente puede revocar libremente por escrito su consentimiento en cualquier momento. En caso de que el paciente posea un riesgo para la salud pública, se admite la ausencia del consentimiento informado para el internamiento, cuarentena u hospitalización del paciente. En caso de riesgo inmediato grave para la integridad física o psíquica del paciente, el consentimiento puede obviarse. En caso de pacientes menores de edad o de incapacidad del paciente legalmente reconocida, física o mental, se admite que el consentimiento informado sea pedido a su representante legal, que será generalmente el familiar más próximo. En caso de riesgo grave para la salud pública o la vida del paciente el consentimiento del representante legal sólo se tendrá en cuenta.

El consentimiento informado está basado en el principio de autonomía, es decir, el derecho del paciente a ser reconocido como persona libre y dueña de tomar sus decisiones. El paciente debe estar en condiciones de comunicar su decisión y éste ha sido informado adecuadamente de sus opciones, es decir, no pueden ser decisiones hechas como resultado de delirio o alucinaciones. La decisión del paciente es consistente con sus valores y metas y se mantiene estable en el tiempo si no ha habido modificaciones hechas por el mismo sujeto. Los familiares de un paciente no están en el derecho de requerir al médico del paciente que no se le comunique ciertos detalles o información al mismo.

Los componentes de la capacidad de tomar decisiones incluye la habilidad de comprender las opciones, de entender las consecuencias de escoger una u otra opción y poder evaluar el costo y beneficio personal de cada consecuencia y relacionarla a sus valores y prioridades.

En algunos casos cuando el paciente no es capaz de comprender los componentes y opciones que le son presentadas, sus familiares o representantes designadas por una corte pueden servir para tomar decisiones por el individuo.

La capacidad de tomar decisiones se conoce legalmente como «competencia». El término se usa a menudo de manera amplia en la medicina para indicar si una persona tiene capacidad de decisión. Técnicamente, una persona sólo puede ser declarada "incompetente" por un tribunal de justicia.

El informe Belmont estadounidense identificó los principios éticos básicos a tener en cuenta durante una investigación biomédica y los catalogó «de beneficio» (beneficencia y no maleficencia), «de respeto por las personas» (autonomía) y «de equidad» (justicia). El principio de beneficencia se refiere a la obligación ética de medir la relación riesgo/beneficio, es decir, lograr los máximos beneficios y de reducir al mínimo el daño y la equivocación. De manera que el diseño de la investigación sea acertado y que los investigadores sean competentes, tanto para realizar la investigación como para salvaguardar el bienestar de las personas que participan en ella.

El proceso de consentimiento informado se consideran uno de los principios de autonomía, que obliga a la selección equitativa de los sujetos de investigación.

Para muchos procedimientos, como exámenes de sangre de rutina, radiografías, y férulas o yesos, el consentimiento suele estar implícito. Para otras pruebas invasivas o para tratamientos con riesgo significativo, se le debe dar un formulario de consentimiento escrito al paciente y una explicación verbal, de preferencia en su idioma nativo. Por lo general, se incluye en el formulario de consentimiento informado una explicación de la condición médica que justifique la prueba, procedimiento o tratamiento, así como una explicación de la finalidad y los beneficios de la prueba propuesta de procedimiento o tratamiento. El profesional de la salud suele verse obligado a dar una explicación o descripción de la prueba procedimiento o tratamiento propuesto, incluyendo las posibles complicaciones o efectos adversos y una descripción de las opciones alternativas, si las hubiere, y sus beneficios y riesgos relativos, así como un análisis de las consecuencias de no aceptar la prueba, procedimiento o tratamiento en cuestión.

El formulario de consentimiento debe estar firmado y fechado tanto por el profesional de la salud como por el paciente o su representante legal. Una copia del formulario de consentimiento firmado siempre está disponible para el paciente y su médico.

Salvo para tratamientos autorizados legalmente de manera involuntaria, los pacientes legalmente competentes para tomar decisiones médicas o que sean calificados por los proveedores salud de tener la capacidad de decisión, tienen el derecho legal y moral de rechazar cualquier tratamiento. Esto aplica incluso si el paciente opta por hacer una "mala decisión" que pueda resultar en una discapacidad grave o incluso la muerte.

Con el fin de documentar que se le ha dado al paciente la opción de obtener un tratamiento recomendado, y ha optado por rechazarlo, se le suele pedir que firme un formulario «contra opinión médica», que es la forma de proteger al médico de responsabilidad legal de no proporcionar el procedimiento en cuestión. El rechazar una prueba, tratamiento o procedimiento no significa necesariamente que se niegan todos los cuidados. Se espera que se le ofrezca al paciente las mejores opciones disponibles después de rechazar la ofrecida en inicio.

Si a causa de la intoxicación, lesión, enfermedad, estrés emocional, u otra razón, un proveedor de cuidado de salud decide que un paciente no tiene capacidad de decisión, el paciente puede no ser capaz de rechazar el tratamiento. por lo general, la ley presume que una persona razonable diera consentimiento para tratamientos en la mayoría de las situaciones de emergencia para prevenir la discapacidad permanente o muerte.

En una declaración jurada o documento de voluntades anticipadas se puede dejar en escrito la voluntad de un sujeto antes de que ocurra una emergencia. Estos documentos legales encaminan a los médicos y otros proveedores de atención de salud en cuanto a qué tratamientos específicos el individuo desea o rechaza, en caso de enfermedad o lesión que le impida tener la capacidad de decisión.





</doc>
<doc id="28198" url="https://es.wikipedia.org/wiki?curid=28198" title="Computación paralela">
Computación paralela

La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia.Como el consumo de energía —y por consiguiente la generación de calor— de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.

Las computadoras paralelas pueden clasificarse según el nivel de paralelismo que admite su hardware: equipos con procesadores multinúcleo y multi-procesador que tienen múltiples elementos de procesamiento dentro de una sola máquina y los clústeres, MPPS y "grids" que utilizan varios equipos para trabajar en la misma tarea. Muchas veces, para acelerar tareas específicas, se utilizan arquitecturas especializadas de computación en paralelo junto a procesadores tradicionales.

Los programas informáticos paralelos son más difíciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los más comunes. La comunicación y sincronización entre diferentes subtareas son algunos de los mayores obstáculos para obtener un buen rendimiento del programa paralelo.

La máxima aceleración posible de un programa como resultado de la paralelización se conoce como la ley de Amdahl.

Tradicionalmente, los programas informáticos se han escrito para el cómputo en serie. Para resolver un problema, se construye un algoritmo y se implementa como un flujo en serie de instrucciones. Estas instrucciones se ejecutan en una unidad central de procesamiento en un ordenador. Sólo puede ejecutarse una instrucción a la vez y un tiempo después de que la instrucción ha terminado, se ejecuta la siguiente.

La computación en paralelo, por el contrario, utiliza simultáneamente múltiples elementos de procesamiento para resolver un problema. Esto se logra mediante la división del problema en partes independientes de modo que cada elemento de procesamiento pueda ejecutar su parte del algoritmo de manera simultánea con los otros. Los elementos de procesamiento son diversos e incluyen recursos tales como una computadora con múltiples procesadores, varios ordenadores en red, hardware especializado, o cualquier combinación de los anteriores.

El aumento de la frecuencia fue la razón dominante de las mejoras en el rendimiento de las computadoras desde mediados de 1980 hasta el año 2004. El tiempo de ejecución de un programa es igual al número de instrucciones multiplicado por el tiempo promedio por instrucción. Manteniendo todo lo demás constante, el aumento de la frecuencia de reloj reduce el tiempo medio que tarda en ejecutarse una instrucción, por tanto un aumento en la frecuencia reduce el tiempo de ejecución de los programas de cómputo.

Sin embargo, el consumo de energía de un chip está dada por la ecuación P = C × V × F, donde P es la potencia, C es el cambio de capacitancia por ciclo de reloj —proporcional al número de transistores cuyas entradas cambian—, V es la tensión, y F es la frecuencia del procesador (ciclos por segundo).Un aumento en la frecuencia aumenta la cantidad de energía utilizada en un procesador. El aumento del consumo de energía del procesador llevó a Intel en mayo del 2004 a la cancelación de sus procesadores Tejas y Jayhawk, este hecho generalmente se cita como el fin del escalado de frecuencia como el paradigma dominante de arquitectura de computadores.

La ley de Moore es la observación empírica de que la densidad de transistores en un microprocesador se duplica cada 18 a 24 meses. A pesar de los problemas de consumo de energía, y las repetidas predicciones de su fin, la ley de Moore sigue vigente. Con el fin del aumento de la frecuencia, estos transistores adicionales —que ya no se utilizan para el aumento de la frecuencia— se pueden utilizar para añadir hardware adicional que permita la computación paralela.

Idealmente, la aceleración a partir de la paralelización es lineal, doblar el número de elementos de procesamiento debe reducir a la mitad el tiempo de ejecución y doblarlo por segunda vez debe nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos algoritmos paralelos logran una aceleración óptima. La mayoría tienen una aceleración casi lineal para un pequeño número de elementos de procesamiento, y pasa a ser constante para un gran número de elementos de procesamiento.

La aceleración potencial de un algoritmo en una plataforma de cómputo en paralelo está dada por la ley de Amdahl, formulada originalmente por Gene Amdahl en la década de 1960. Esta señala que una pequeña porción del programa que no pueda paralelizarse va a limitar la aceleración que se logra con la paralelización. Los programas que resuelven problemas matemáticos o ingenieriles típicamente consisten en varias partes paralelizables y varias no paralelizables (secuenciales). Si formula_1 es la fracción de tiempo que un programa gasta en partes no paralelizables, luego

es la máxima aceleración que se puede alcanzar con la paralelización del programa. Si la parte secuencial del programa abarca el 10% del tiempo de ejecución, se puede obtener no más de 10× de aceleración, independientemente de cuántos procesadores se añadan. Esto pone un límite superior a la utilidad de añadir más unidades de ejecución paralelas. «Cuando una tarea no puede divididirse debido a las limitaciones secuenciales, la aplicación de un mayor esfuerzo no tiene efecto sobre la programación. La gestación de un niño toma nueve meses, no importa cuántas mujeres se le asigne».

La ley de Gustafson es otra ley en computación que está en estrecha relación con la ley de Amdahl. Señala que el aumento de velocidad con formula_3 procesadores es

Ambas leyes asumen que el tiempo de funcionamiento de la parte secuencial del programa es independiente del número de procesadores. La ley de Amdahl supone que todo el problema es de tamaño fijo, por lo que la cantidad total de trabajo que se hará en paralelo también es independiente del número de procesadores, mientras que la ley de Gustafson supone que la cantidad total de trabajo que se hará en paralelo varía linealmente con el número de procesadores.

Entender la dependencia de datos es fundamental en la implementación de algoritmos paralelos. Ningún programa puede ejecutar más rápidamente que la cadena más larga de cálculos dependientes (conocida como la ruta crítica), ya que los cálculos que dependen de cálculos previos en la cadena deben ejecutarse en orden. Sin embargo, la mayoría de los algoritmos no consisten sólo de una larga cadena de cálculos dependientes; generalmente hay oportunidades para ejecutar cálculos independientes en paralelo.

Sea P y P dos segmentos del programa. Las condiciones de Bernstein describen cuando los dos segmentos son independientes y pueden ejecutarse en paralelo. Para "P", sean "I" todas las variables de entrada y "O" las variables de salida, y del mismo modo para "P". "P" y "P" son independientes si satisfacen


Una violación de la primera condición introduce una dependencia de flujo, correspondiente al primer segmento que produce un resultado utilizado por el segundo segmento. La segunda condición representa una anti-dependencia, cuando el segundo segmento ("P") produce una variable que necesita el primer segmento ("P"). La tercera y última condición representa una dependencia de salida: Cuando dos segmentos escriben en el mismo lugar, el resultado viene del último segmento ejecutado.

Considere las siguientes funciones, que demuestran varios tipos de dependencias:

La operación 3 en Dep(a, b) no puede ejecutarse antes de —o incluso en paralelo con— la operación 2, ya que en la operación 3 se utiliza un resultado de la operación 2. Esto viola la condición 1, y por tanto introduce una dependencia de flujo.

En este ejemplo, no existen dependencias entre las instrucciones, por lo que todos ellos se pueden ejecutar en paralelo.

Las condiciones de Bernstein no permiten que la memoria se comparta entre los diferentes procesos. Por esto son necesarios algunos medios que impongan un ordenamiento entre los accesos tales como semáforos, barreras o algún otro método de sincronización.

Las subtareas en un programa paralelo a menudo son llamadas hilos. Algunas arquitecturas de computación paralela utilizan versiones más pequeñas y ligeras de hilos conocidas como hebras, mientras que otros utilizan versiones más grandes conocidos como procesos. Sin embargo, «hilos» es generalmente aceptado como un término genérico para las subtareas. Los hilos a menudo tendrán que actualizar algunas variables que se comparten entre ellos. Las instrucciones entre los dos programas pueden entrelazarse en cualquier orden. Por ejemplo, considere el siguiente programa:

Si la instrucción 1B se ejecuta entre 1A y 3A, o si la instrucción 1A se ejecuta entre 1B y 3B, el programa va a producir datos incorrectos. Esto se conoce como una condición de carrera. El programador debe utilizar un bloqueo ("lock") para proporcionar exclusión mutua. Un bloqueo es una construcción del lenguaje de programación que permite a un hilo de tomar el control de una variable y evitar que otros hilos la lean o escriban, hasta que la variable esté desbloqueado. El hilo que mantiene el bloqueo es libre de ejecutar su sección crítica —la sección de un programa que requiere acceso exclusivo a alguna variable—, y desbloquear los datos cuando termine. Por lo tanto, para garantizar la correcta ejecución del programa, el programa anterior se puede reescribir usando bloqueos:

Un hilo bloqueará con éxito la variable V, mientras que el otro hilo no podrá continuar hasta que V se desbloquee. Esto garantiza la correcta ejecución del programa. Si bien los bloqueos son necesarios para asegurar la ejecución correcta del programa, pueden ralentizar en gran medida un programa.

Bloquear múltiples variables utilizando cerraduras no atómicas introduce la posibilidad de que el programa alcance un bloqueo mutuo ("deadlock"). Un bloqueo atómico bloquea múltiples variables a la vez, si no puede bloquearlas todas, no se bloquea ninguna de ellas. Si hay dos hilos y cada uno necesita bloquear las mismas dos variables utilizando cerraduras no atómicas, es posible que un hilo bloquee uno de ellas y el otro bloquee la segunda variable. En tal caso se produce un bloqueo mutuo donde ningún hilo puede completar la ejecución.

Muchos programas paralelos requieren que sus subtareas actúen en sincronía. Esto requiere el uso de una barrera. Las barreras se implementan normalmente mediante un bloqueo. Una clase de algoritmos, conocida como algoritmos libres de bloqueo y libres de espera, evitan el uso de bloqueos y barreras. Sin embargo, este enfoque es generalmente difícil de implementar y requiere estructuras de datos correctamente diseñadas.

No todas las paralelizaciones conllevan una aceleración. Por lo general, mientras una tarea se divida en cada vez más hilos, estos hilos pasan una porción cada vez mayor de su tiempo comunicándose entre sí. Eventualmente, la sobrecarga de comunicación domina el tiempo empleado para resolver el problema, y la paralelización adicional —dividir la carga de trabajo entre incluso más hilos— aumenta la cantidad de tiempo requerido para terminar. Esto se conoce como desaceleración paralela.

Las aplicaciones a menudo se clasifican según la frecuencia con que sus subtareas se sincronizan o comunican entre sí. Una aplicación muestra un paralelismo de grano fino si sus subtareas deben comunicase muchas veces por segundo, se considera paralelismo de grano grueso si no se comunican muchas veces por segundo, y es vergonzosamente paralelo si nunca o casi nunca se tienen que comunicar. Aplicaciones vergonzosamente paralelas son consideradas las más fáciles de paralelizar.

Los lenguajes de programación en paralelo y computadoras paralelas deben tener un modelo de consistencia de datos —también conocido como un modelo de memoria—. El modelo de consistencia define reglas para las operaciones en la memoria del ordenador y cómo se producen los resultados.

Uno de los primeros modelos de consistencia fue el modelo de consistencia secuencial de Leslie Lamport. La consistencia secuencial es la propiedad de un programa en la que su ejecución en paralelo produce los mismos resultados que un programa secuencial. Específicamente, es un programa secuencial consistente si «... los resultados de una ejecución son los mismos que se obtienen si las operaciones de todos los procesadores son ejecutadas en un orden secuencial, y las operaciones de cada procesador individual aparecen en esta secuencia en el orden especificado por el programa».

La memoria transaccional es un tipo de modelo de consistencia. La memoria transaccional toma prestado de la teoría de base de datos el concepto de transacciones atómicas y las aplica a los accesos a memoria.

Matemáticamente, estos modelos se pueden representar de varias maneras. Las Redes de Petri, que se introdujeron en 1962 como tesis doctoral de Carl Adam Petri, fueron un primer intento de codificar las reglas de los modelos de consistencia. Más tarde fueron creadas las arquitecturas de flujo de datos para implementar físicamente las ideas de la teoría del flujo de datos. A principios de la década de 1970, los cálculos de procesos tales como la Comunicación de Sistemas y Comunicación de Procesos Secuenciales se desarrollaron para permitir un razonamiento algebraico sobre sistemas compuestos por elementos que interactúan entre sí. Adiciones más recientes a la familia de cálculo de proceso, como el cálculo-π, han añadido la capacidad para razonar acerca de las topologías dinámicas. Lógicas tales como la TLA+ de Lamport, y modelos matemáticos se han desarrollado para describir el comportamiento de sistemas concurrentes.

Michael J. Flynn creó uno de los primeros sistemas de clasificación de computadoras, programas paralelos y secuenciales, ahora conocida como la taxonomía de Flynn. Flynn clasifica los programas y computadoras atendiendo a si están operando con uno o varios conjuntos de instrucciones y si esas instrucciones se utilizan en una o varias series de datos.

La clasificación instrucción-única-dato-único (SISD) es equivalente a un programa totalmente secuencial. La clasificación instrucción-única-datos-múltiples (SIMD) es análoga a hacer la misma operación varias veces sobre un conjunto de datos grande. Esto se hace comúnmente en aplicaciones de procesamiento de señales. Instrucciones-múltiples-dato-único (MISD) es una clasificación que rara vez se utiliza. A pesar de que se diseñaron arquitecturas de computadoras en esta categoría —como arreglos sistólicos—, muy pocas aplicaciones se materializaron. Los programas instrucciones-múltiples-datos-múltiples (MIMD) constituyen el tipo más común de programas paralelos.

Según David A. Patterson y John L. Hennessy, «Algunas máquinas son híbridos de estas categorías, por supuesto, este modelo clásico ha sobrevivido porque es simple, fácil de entender, y da una buena primera aproximación. Además, es, tal vez por su comprensibilidad, el esquema más utilizado.»

Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo. El aumento del tamaño de la palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra. Por ejemplo, cuando un procesador de 8 bits debe sumar dos enteros de 16 bits, el procesador primero debe adicionar los 8 bits de orden inferior de cada número entero con la instrucción de adición, a continuación, añadir los 8 bits de orden superior utilizando la instrucción de adición con acarreo que tiene en cuenta el bit de acarreo de la adición de orden inferior, en este caso un procesador de 8 bits requiere dos instrucciones para completar una sola operación, en donde un procesador de 16 bits necesita una sola instrucción para poder completarla.

Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación de propósito general durante la última década.

Un programa de ordenador es, en esencia, una secuencia de instrucciones ejecutadas por un procesador. Estas instrucciones pueden reordenarse y combinarse en grupos que luego son ejecutadas en paralelo sin cambiar el resultado del programa. Esto se conoce como paralelismo a nivel de instrucción. Los avances en el paralelismo a nivel de instrucción dominaron la arquitectura de computadores desde mediados de 1980 hasta mediados de la década de 1990.

Los procesadores modernos tienen "pipeline" de instrucciones de varias etapas. Cada etapa en el "pipeline" corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un "pipeline" de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. El ejemplo canónico de un procesador segmentado es un procesador RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 tenía un "pipeline" de 35 etapas.

Además del paralelismo a nivel de instrucción del "pipelining", algunos procesadores pueden ejecutar más de una instrucción a la vez. Estos son conocidos como procesadores superescalares. Las instrucciones pueden agruparse juntas sólo si no hay dependencia de datos entre ellas. El "scoreboarding" y el algoritmo de Tomasulo —que es similar a "scoreboarding" pero hace uso del renombre de registros— son dos de las técnicas más comunes para implementar la ejecución fuera de orden y la paralelización a nivel de instrucción.

El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. «La paralelización de ciclos conduce a menudo a secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran estructura de datos». Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.

Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos. Por ejemplo, considere el siguiente pseudocódigo que calcula los primeros números de Fibonacci:

Este bucle no se puede paralelizar porque CUR depende de sí mismo (PREV2) y de PREV1, que se calculan en cada iteración del bucle. Dado que cada iteración depende del resultado de la anterior, no se pueden realizar en paralelo. A medida que el tamaño de un problema se hace más grande, la paralelización de datos disponible generalmente también lo hace.

El paralelismo de tareas es la característica de un programa paralelo en la que «cálculos completamente diferentes se pueden realizar en cualquier conjunto igual o diferente de datos». Esto contrasta con el paralelismo de datos, donde se realiza el mismo cálculo en distintos o mismos grupos de datos. El paralelismo de tareas por lo general no escala con el tamaño de un problema.

La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida —cada elemento de procesamiento tiene su propio espacio local de direcciones—.El término memoria distribuida se refiere al hecho de que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente. La memoria distribuida-compartida y la virtualización de memoria combinan los dos enfoques, donde el procesador tiene su propia memoria local y permite acceso a la memoria de los procesadores que no son locales. Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local.

Las arquitecturas de ordenador en las que cada elemento de la memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA). Típicamente, sólo se puede lograr con un sistema de memoria compartida, donde la memoria no está distribuida físicamente. Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los sistemas de memoria distribuidos tienen acceso no uniforme a la memoria.

Los sistemas informáticos suelen hacer uso de cachés, pequeños recuerdos rápidos ubicados cerca del procesador que almacenan las copias temporales de los valores de la memoria —cercano, tanto en el sentido físico y lógico—. Los sistemas computacionales paralelos tienen dificultades con las cachés y la posibilidad de una ejecución incorrecta del programa debido a que se puede almacenar el mismo valor en más de un lugar. Estos equipos requieren coherencia en la caché del sistema, generalmente realizan un seguimiento de los valores almacenados en caché y estratégicamente los eliminan, garantizando la correcta ejecución del programa. "Bus sniffing" es uno de los métodos más comunes para hacer el seguimiento de los valores a los que se está accediendo. El diseño de grandes sistemas de coherencia caché y de alto rendimiento es un problema muy difícil en arquitectura de computadores. Como resultado, las arquitecturas de memoria compartida no son tan escalables como los sistemas de memoria distribuida.

La comunicación procesador-procesador y procesador-memoria se puede implementar en hardware de varias maneras: a través de memoria compartida —ya sea multipuerto o multiplexado—, un conmutador de barras cruzadas ("crossbar switch"), un bus compartido o una red interconectada de una gran variedad de topologías como estrella, anillo, árbol, hipercubo, hipercubo grueso —un hipercubo con más de un procesador en un nodo—, o de malla n-dimensional.

Las computadoras paralelas basadas en redes interconectadas deben tener algún tipo de enrutamiento para permitir el paso de mensajes entre nodos que no están conectados directamente. Es probable que el medio utilizado para la comunicación entre los procesadores de grandes máquinas multiprocesador sea jerárquico.

Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo. Estos no son excluyentes entre sí, por ejemplo, los grupos de multiprocesadores simétricos son relativamente comunes.

Un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip. Los procesadores superescalares pueden ejecutar múltiples instrucciones por ciclo de un flujo de instrucciones (hilo), a diferencia de este, un procesador multinúcleo puede ejecutar múltiples instrucciones por ciclo de secuencias de instrucciones múltiples. Cada núcleo en un procesador multinúcleo potencialmente puede ser superescalar, es decir, en cada ciclo, cada núcleo puede ejecutar múltiples instrucciones de un flujo de instrucciones.

El "Multithreading" simultáneo —de la cual Intel HyperThreading es el más conocido— era una forma de pseudo-multinúcleo. Un procesador con capacidad de "multithreading" simultáneo tiene una sola unidad de ejecución (núcleo), pero cuando esa unidad de ejecución está desocupada —por ejemplo, durante un error de caché—, se utiliza para procesar un segundo hilo. El microprocesador Cell de IBM, diseñado para su uso en la consola Sony PlayStation 3, es otro prominente procesador multinúcleo.

Un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a través de un bus. La contención del bus previene el escalado de esta arquitectura. Como resultado, los SMPs generalmente no comprenden más de 32 procesadores. «Debido al pequeño tamaño de los procesadores y de la significativa reducción en los requisitos de ancho de banda de bus, tales multiprocesadores simétricos son extremadamente rentables, siempre que exista una cantidad suficiente de ancho de banda».

Un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden considerarse como un solo equipo. Los clústeres se componen de varias máquinas independientes conectadas por una red. Mientras que las máquinas de un clúster tienen que ser simétricas, de no serlo, el balance de carga es más difícil de lograr. El tipo más común de clúster es el cluster Beowulf, que es un clúster implementado con múltiples ordenadores comerciales idénticos conectados a una red de área local TCP/IP Ethernet. La tecnología Beowulf fue desarrollada originalmente por Thomas Sterling y Donald Becker. La gran mayoría de los superordenadores "TOP500" son clústeres.

Un procesador paralelo masivo (MPP) es un solo equipo con varios procesadores conectados en red. Tienen muchas de las características de los clúster, pero cuentan con redes especializadas de interconexión —en tanto que las clústeres utilizan hardware estándar para la creación de redes—. Los MPPs también tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores. En un MPP, «cada CPU tiene su propia memoria y una copia del sistema operativo y la aplicación. Cada subsistema se comunica con los demás a través de un interconexión de alta velocidad».

La computación distribuida es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado. Debido al bajo ancho de banda y la latencia extremadamente alta de Internet, la computación distribuida normalmente sólo se refiere a problemas vergonzosamente paralelos. Se han creado muchas aplicaciones de computación distribuida, SETI@home y Folding@home son los ejemplos más conocidos.

La mayoría de las aplicaciones de computación distribuida utilizan "middleware", software que se encuentra entre el sistema operativo y la aplicación para administrar los recursos de red y estandarizar la interfaz de software. El más común es la Infraestructura Abierta de Berkeley para Computación en Red (BOINC). A menudo, los programas de computación distribuida hacen uso de «ciclos de repuesto», realizando cálculos cuando el procesador de un equipo está desocupado.

Dentro de la computación paralela, existen dispositivos paralelos especializados que generan interés. Aunque no son específicos para un dominio, tienden a ser aplicables sólo a unas pocas clases de problemas paralelos.

El cómputo reconfigurable es el uso de un arreglo de compuertas programables (FPGA) como coprocesador de un ordenador de propósito general. Un FPGA es, en esencia, un chip de computadora que puede reconfigurarse para una tarea determinada.

Los FPGAs se pueden programar con lenguajes de descripción de hardware como VHDL o Verilog. Sin embargo, los lenguajes de programación pueden ser tediosos. Varios vendedores han creado lenguajes «C a HDL» que tratan de emular la sintaxis y/o semántica del lenguaje de programación C, con el que la mayoría de los programadores están familiarizados. Los lenguajes «C a HDL» más conocidos son Mitrion-C, C Impulse, DIME C y C-Handel. También se pueden utilizar para este propósito subconjuntos específicos de SystemC basados en C++.

La decisión de AMD de abrir HyperTransport a otros fabricantes la ha convertido en la tecnología que permite la computación reconfigurable de alto rendimiento. De acuerdo con Michael D'Amour R., Director de Operaciones de la DRC Computer Corporation, «cuando entramos en AMD, nos llamaban ladrones de zócalos. Ahora nos llaman socios».

El cómputo de propósito general en las unidades de procesamiento de gráficos (GPGPU) es una tendencia relativamente reciente en la investigación de ingeniería informática. Los GPUs son co-procesadores que han sido fuertemente optimizados para procesamiento de gráficos por computadora. El procesamiento de gráficos por computadora es un campo dominado por operaciones sobre datos en paralelo, en particular de álgebra lineal y operaciones con matrices.

Al principio, los programas de GPGPU normalmente utilizaban el API de gráficos para ejecutar programas. Sin embargo, varios nuevos lenguajes de programación y plataformas se han construido para realizar cómputo de propósito general sobre GPUs, tanto Nvidia como AMD han liberado de entornos de programación con CUDA y Stream SDK, respectivamente. Otros lenguajes de programación de GPU incluyen: BrookGPU, PeakStream y RapidMind. Nvidia también ha lanzado productos específicos para la computación en su serie Tesla. El consorcio de tecnología Khronos Group ha lanzado OpenCL, que es un marco para la escritura de programas que se ejecutan en distintas plataformas conformadas por CPUs y GPUs. AMD, Apple, Intel, Nvidia y otros están apoyando OpenCL.

Se han diseñado varios circuitos integrados de aplicación específica (ASIC) para hacer frente a las aplicaciones paralelas.

Debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación. Como resultado, para una aplicación dada, un ASIC tiende a superar a un ordenador de propósito general. Sin embargo, los ASICs son creados con litografía de rayos X. Este proceso requiere una máscara, que puede ser extremadamente cara. Una máscara puede costar más de un millón de dólares. Mientras más pequeño sean los transistores necesarios para el chip, más cara será la máscara. Mientras tanto, el incremento del rendimiento en computadoras de propósito general —como se describe en la Ley de Moore— tiende a eliminar esta diferencia en sólo una o dos generaciones de chips. El alto costo inicial, y la tendencia a ser superados por la ley de Moore, ha hecho inviable el uso de ASICs para la mayoría de las aplicaciones paralelas. Sin embargo, algunos han sido construidos, un ejemplo es el peta-flop RIKEN MDGRAPE-3 de la máquina que utiliza ASICs para la simulación de dinámica molecular.

Un procesador vectorial es un CPU o un sistema computacional que puede ejecutar la misma instrucción en grandes conjuntos de datos. «Los procesadores vectoriales tienen operaciones de alto nivel que trabajan sobre arreglos lineales de números o vectores. Un ejemplo de operación con vectores es: "A" = "B" × "C", donde "A", "B", y "C" son vectores de 64 elementos, donde cada uno es un número de punto flotante de 64 bits». Están estrechamente relacionadas con la clasificación SIMD de Flynn.

Las computadoras Cray se volvieron famosas por su procesamiento de vectores en los años 1970 y 1980. Sin embargo, los procesadores vectoriales, tanto CPUs como sistemas computacionales, han desaparecido. Los conjuntos de instrucciones de los procesadores modernos incluyen algunas instrucciones de procesamiento de vectores, por ejemplo: AltiVec y Streaming SIMD Extensions (SSE).

Los lenguajes de programación concurrentes, bibliotecas, APIs y modelos de programación paralela han sido creados para la programación de computadores paralelos. Estos generalmente se pueden dividir en clases basadas en las suposiciones que se hacen sobre la arquitectura de memoria subyacente: compartida, distribuida, o compartida-distribuida. Los lenguajes de programación de memoria compartida se comunican mediante la manipulación de variables en la memoria compartida. En la arquitectura con memoria distribuida se utiliza el paso de mensajes. POSIX Threads y OpenMP son dos de las API más utilizadas con la memoria compartida, mientras que Message Passing Interface (MPI) «Interfaz de Paso de Mensajes» es el API más utilizado en los sistemas de paso de mensajes. El concepto «valor futuro» es muy utilizado en la programación de programas paralelos, donde una parte de un programa promete proporcionar un dato requerido a otra parte del programa en un tiempo futuro.

Las empresas CAPS entreprise y Pathscale están intentando convertir las directivas de HMPP (Hybrid Multicore Parallel Programming) en un estándar abierto denominado OpenHMPP. El modelo de programación OpenHMPP basado en directivas ofrece una sintaxis para descargar de manera eficiente los cálculos sobre aceleradores de hardware y optimizar el movimiento de datos hacia y desde la memoria del hardware. Las directivas OpenHMPP describen llamadas a procedimientos remotos (RPC) en un dispositivo acelerador —por ejemplo el GPU— o de forma más general un conjunto de núcleos. Las directivas permiten anotar código C o Fortran para describir dos grupos de funcionalidades: la descarga de los procedimientos en un dispositivo remoto y la optimización de las transferencias de datos entre la memoria principal de la CPU y la memoria del acelerador.

La paralelización automática de un programa secuencial por un compilador es el santo grial de la computación paralela. A pesar de décadas de trabajo por parte de los investigadores, la paralelización automática ha tenido un éxito limitado.

Los principales lenguajes de programación en paralelo permanecen explícitamente paralelos o en el mejor de los casos parcialmente implícitos, en los que un programador le da al compilador directivas de paralelización. Existen pocos lenguajes de programación paralelos totalmente implícitos: SISAL, Parallel Haskell, y (para FPGAs) Mitrion C.

Mientras un sistema computacional crece en complejidad, el tiempo medio entre fallos por lo general disminuye. Un punto de control de aplicación es una técnica mediante la cual el sistema informático toma una «instantánea» de la aplicación, un registro de todas las asignaciones actuales de recursos y estados variables, semejante a un volcado de memoria, esta información se puede utilizar para restaurar el programa si el equipo falla. Disponer de un punto de control significa que el programa puede reiniciar desde este y no desde el principio. Mientras que los puntos de control proporcionan beneficios en una variedad de situaciones, son especialmente útiles en los sistemas altamente paralelos con un gran número de procesadores que son utilizados en la computación de altas prestaciones.

Mientras que las computadoras paralelas se hacen más grandes y más rápidas, se hace factible resolver problemas que antes tardaban demasiado tiempo en ejecutarse. La computación en paralelo se utiliza en una amplia gama de campos, desde la bioinformática (plegamiento de proteínas y análisis de secuencia) hasta la economía (matemática financiera). Los tipos de problemas encontrados comúnmente en las aplicaciones de computación en paralelo son:

Los orígenes del verdadero paralelismo (MIMD) se remontan a Federico Luigi, Menabrea Conte y su «Bosquejo de la máquina analítica inventada por Charles Babbage». IBM introdujo el IBM 704 en 1954, a través de un proyecto en el que Gene Amdahl fue uno de los principales arquitectos. Se convirtió en el primer equipo disponible en el mercado que utilizaba comandos aritméticos de punto flotante totalmente automáticos.

En abril de 1958, S. Gill (Ferranti) analizó la programación en paralelo y la necesidad de la ramificación y la espera. También en 1958, los investigadores de IBM John Cocke y Daniel Slotnick discutieron por primera vez el uso del paralelismo en cálculos numéricos. Burroughs Corporation presentó la D825 en 1962, un equipo de cuatro procesadores que accede a un máximo de 16 módulos de memoria a través de un conmutador de barras cruzadas. En 1967, Amdahl y Slotnick publicaron un debate sobre la viabilidad de procesamiento en paralelo en la Conferencia de la Federación Americana de Sociedades de Procesamiento de la Información. Fue durante este debate que la Ley de Amdahl fue acuñada para definir los límites de aceleración que se pueden alcanzar debido al paralelismo.

En 1969, la compañía estadounidense Honeywell introdujo su primer sistema Multics, un sistema con multiprocesador simétrico capaz de ejecutar hasta ocho procesadores en paralelo.En 1970, C.mmp, un proyecto en la Universidad Carnegie Mellon con varios procesadores, fue «uno de los primeros multiprocesadores con más de unos pocos procesadores». «El primer bus con conexión multi-procesador y caché espía fue el Synapse N+1 en el año 1984».

Las computadoras paralelas SIMD se remontan a la década de 1970. La motivación detrás de las primeras computadoras SIMD era amortizar el retardo de la compuerta de la unidad de control del procesador en múltiples instrucciones. En 1964, Slotnick había propuesto la construcción de un ordenador masivamente paralelo para el Laboratorio Nacional Lawrence Livermore. Su diseño fue financiado por la Fuerza Aérea de los Estados Unidos, que fue el primer esfuerzo por lograr la computación en paralelo SIMD. La clave de su diseño fue un paralelismo bastante alto, con hasta 256 procesadores, lo que permitió que la máquina trabajara en grandes conjuntos de datos en lo que más tarde sería conocido como el procesamiento de vectores. Sin embargo, ILLIAC IV fue llamado «el más infame de los superordenadores», pues solo se había completado una cuarta parte del proyecto. Tardó 11 años, costando casi cuatro veces la estimación original. Cuando estaba listo para ejecutar una aplicación real por primera vez en 1976, fue superado por supercomputadoras comerciales, como el Cray-1.



</doc>
<doc id="28203" url="https://es.wikipedia.org/wiki?curid=28203" title="Dances with Wolves">
Dances with Wolves

Dances with Wolves (conocida como Bailando con lobos en España y Danza con lobos en Hispanoamérica) es una película estadounidense dirigida y protagonizada por Kevin Costner. Estrenada en 1990, la película está basada en la novela homónima de Michael Blake y recibió siete premios Óscar.

Durante la Guerra de Secesión estadounidense, el condecorado teniente John J. Dunbar (Kevin Costner) es enviado por el mayor Fambrough (Maury Chaykin) a un puesto avanzado en la frontera del territorio indio sin ningún tipo de compañía más que su fiel caballo "Cisco". Al llegar debía relevar al oficial al mando, pero se encuentra que el puesto está abandonado. El transportista de pertrechos que acompañaba a Dumbar es asesinado por fieros indios Pawnee apenas abandona a Dumbar.
El sentido del deber impulsa a Dumbar a mantener su puesto, Dumbar lo convierte en un puesto militar limpio, ordenado, pero en completa soledad.

A medida que avanzan los días, traba amistad con un desconfiado lobo de pradera al que llama "Calcetines" y que lo acompaña en sus patrullas.

Dumbar en una de sus patrullas rescata del suicidio a una mujer blanca que se ha naturalizado con los Sioux llamada "Erguida con puño en alto" y la devuelve a su aldea de origen, además establece con dificultad una relación amistosa con un líder sioux llamado "Ave que patea" (Graham Greene) que ve la nobleza de alma de Dumbar y convence a su tribu que lo admita. 
Así, Dunbar va conociendo más la cultura de su rival, descubre la esencia de vida de los Sioux y que la enemistad no debería existir entre ambos bandos.
Dumbar sin darse cuenta adopta el estilo de vida indio y estos los bautizan como "Danza con lobos" por su amistad con un lobo de pradera. Dumbar se enamora y se casa con "Erguida con puño en alto" pasando a ser un miembro más de la tribu. 
Pronto Dumbar se dará cuenta del abismo de humanidad que existe entre el hombre blanco y los naturales y deberá decidir qué camino tomar.


Dirigida y protagonizada por Kevin Costner y basada en la novela del mismo título de Michael Blake.

La música de la película fue compuesta y dirigida por el renombrado compositor John Barry, que le reportó su cuarto Óscar de la academia, pasando a convertirse en una de sus obras más valoradas por el público. La edición de la partitura salió en 1990, pero posteriormente salió una reedición en 1995 y en el 2004 que contenía toda la partitura en su totalidad.

Es una obra compuesta para orquesta sinfónica y presenta una factura y desarrollo clásicos, fieles a la tradición musical del género de las bandas sonoras. Se estructura a partir de varios temas: el de John Dumbar, Two Socks, Stands with The Fist Remember, los indios lakota y las praderas americanas. Barry se esforzó por dotar a la composición de una emotividad lo más compatible posible con los objetivos de Kevin Costner. Una de sus características es, paradójicamente, el no presentar música en ciertos pasajes de la película, reservándola para otros más pertinentes: presentación de personajes, transiciones entre secuencias, escenas de acción.

Su orquestación es típicamente "barryniana". Alterna de manera sencilla el metal (especialmente trombones y trompas) con tuttis de cuerda y adornos a base de percusiones y trompetas. Su ritmo es en general pausado, sentimental, pero contundente. Como queriendo resaltar la sencillez de las emociones que pretende representar la película: libertad, amor, amistad, etc. Su sonido es americano, pero alejado del sonido western típico, acaso porque la película no es un western al uso, sino un drama épico ambientado en la frontera americana.

Este es el listado de canciones de la edición de 1995:


La canción "Journey To Fort Sedgewick" fue utilizado por Repsol en sus anuncios publicitarios durante los años 1990.




</doc>
<doc id="28204" url="https://es.wikipedia.org/wiki?curid=28204" title="Conflicto de interés">
Conflicto de interés

Un conflicto de interés es aquella situación en la que el juicio del individuo -concerniente a su interés primario- y la integridad de una acción tienden a estar indebidamente influidos por un interés secundario, de tipo generalmente económico o personal.

Existe conflicto de interés cuando en el ejercicio de las labores dentro de una institución, sobreviene una contraposición entre el interés propio e institucional. A continuación presentamos algunas situaciones que conllevan conflicto de interés:




</doc>
<doc id="28207" url="https://es.wikipedia.org/wiki?curid=28207" title="George Segal">
George Segal

George Segal, Jr. (nacido el 13 de febrero de 1934) es un actor estadounidense ganador del Globo de Oro. Nació en Great Neck, Long Island, en el estado de Nueva York. Es un gran intérprete del banjo. Mientras estudiaba en el colegio organizó un conjunto de música que cosechó muchos éxitos. Después estudió artes dramáticas en la Universidad de Columbia, en Nueva York, donde organizó nuevamente un grupo musical. Una vez terminados sus estudios se ganó la vida limpiando lavabos en un teatro de Nueva York, esperando que llegase su oportunidad.

Por fin, en 1955, Segal debutó en el teatro con la obra "Don Juan", de Molière. Al año siguiente actuó en otra obra, esta vez de Eugene O'Neill. A continuación tuvo que cumplir el servicio militar. A su regreso, consiguió participar en el festival Shakespeare de Nueva York, hasta que en 1960 tuvo su primer éxito importante en "The Premise", una obra con características de revista, que estuvo en cartel durante un plazo prolongado.

En 1961, Segal actuó en su primera película. En los años siguientes hizo varias películas más, aunque en todos los casos en papeles pequeños. En la película de Stanley Kramer de 1965 "Ship of Fools" ya comenzó a ser conocido. Sin embargo, fue con el film de ese mismo año "King Rat", una historia sobre la Segunda Guerra Mundial, con el que saltó a la fama como actor de cine. Mientras rodaba esas películas, Segal continuó actuando en el teatro, donde trabajó también con el director Mike Nichols, con quien coincidió en 1966 en el rodaje de "Quién teme a Virginia Woolf", película que cosechó varios Oscar.

En los años siguientes Segal intervino en multitud de películas, generalmente en papeles principales o secundarios importantes. Sus dotes de interpretación son extensas, y es capaz de actuar en papeles cómicos con la misma facilidad que en papeles dramáticos. Su aspecto risueño le ha hecho ganar la simpatía de las audiencias.

Segal fue introduciéndose también en la televisión, aunque hasta la década de los años 90 no comenzó a trabajar en serio en este medio. Desde entonces ha intervenido regularmente en una o dos producciones de películas o mini-series para la televisión cada año, hasta el extremo de que últimamente parece sentirse más a gusto en este medio que en el cine. Con sus intervenciones en televisión ha cosechado también un notable éxito.

Segal se casó en tres ocasiones. Con su primera esposa tuvo dos hijas. Su segundo matrimonio duró hasta 1996, año en que falleció su esposa. En ese mismo año se volvió a casar por tercera vez.

En el año 1974, se publica el LP "A Touch of Ragtime", figurando como "George Segal and the Imperial Jazzband". En la portada del disco se lo ve sonriente con un banjo. Entre otros, participa en este disco Harry Nilsson.



</doc>
<doc id="28209" url="https://es.wikipedia.org/wiki?curid=28209" title="Multiplexación">
Multiplexación

En telecomunicación, la multiplexación es la combinación de dos o más canales de información en un solo medio de transmisión (permite varias comunicaciones de forma simultánea) usando un dispositivo llamado multiplexor. El proceso inverso se conoce como demultiplexación. Un concepto muy similar es el de control de acceso al medio.

Existen muchas estrategias de multiplexación según el protocolo de comunicación empleado, que puede combinarlas para alcanzar el uso más eficiente; los más utilizados son: 


Cuando existe un esquema o protocolo de multiplexación pensado para que múltiples usuarios compartan un medio común, como por ejemplo en telefonía móvil o WiFi, suele denominarse control de acceso al medio o método de acceso múltiple. Como métodos de acceso múltiple destacan:


En informática y electrónica, la multiplexación se refiere al mismo concepto si se trata de buses de datos que haya que compartir entre varios dispositivos (discos, memoria, etc.). Otro tipo de multiplexación en informática es el de la CPU, en la que a un proceso le es asignado un quantum de tiempo durante el cual puede ejecutar sus instrucciones, antes de ceder el sitio a otro proceso que esté esperando en la cola de procesos listo a ser despachado por el planificador de procesos. También en informática, se denomina multiplexar a combinar en un mismo archivo contenedor, varias pistas de dos archivos, por ejemplo de audio y vídeo, para su correcta reproducción, también en informática multiplexar un archivo, es una forma que se mantengan varias copias idénticas de este archivo, esto para respaldar información en caso de que ocurra un fallo en el archivo principal.

Se denomina al transmitir, por el mismo medio diferentes tipos INTERCALADOS de información sin mezclarse. Ya sea audio, vídeo o imagen.

En las telecomunicaciones se usa la multiplexación para dividir las señales en el medio por el que vayan a viajar dentro del espectro radioeléctrico. El término es equivalente al control de acceso al medio.

De esta manera, para transmitir los canales de televisión por aire, vamos a tener un ancho de frecuencia x, el cual habrá que multiplexar para que entren la mayor cantidad posible de canales de TV. Entonces se dividen los canales en un ancho de banda de 6 MHz (en gran parte de Europa y América, mientras que en otros países el ancho de banda es de 8 MHz). En este caso se utiliza una multiplexación por división de frecuencia FDM.

Multiplexar un paquete de datos, significa tomar los datos de la capa de aplicación, etiquetarlos con un número de puerto (TCP o UDP) que identifica a la aplicación emisora, y enviar dicho paquete a la capa de red.



</doc>
<doc id="28210" url="https://es.wikipedia.org/wiki?curid=28210" title="Pedro y el lobo">
Pedro y el lobo

Pedro y el lobo (en ruso: Петя и волк) es una composición sinfónica de Serguéi Prokófiev (Op. 67) escrita en 1936. La obra de Prokófiev es una historia para niños, con música y texto adaptado por él, con un narrador acompañado por la orquesta. 

En 1935, Natalya Sats y el teatro central infantil de Moscú encargaron a Sergei Prokofiev una nueva sinfonía musical para niños. Se intentaba cultivar el gusto musical en los niños desde los primeros años de escuela. Intrigado por la invitación, Prokofiev completó "Pedro y el lobo" en solo cuatro días. El estreno se produjo el 2 de mayo de 1936, y su acogida fue desfavorable. En palabras del propio autor, «...[la asistencia] fue pobre y no consiguió atraer mucha atención».

"Pedro y el lobo" está escrita para una flauta, un oboe, un clarinete en la, un fagot, tres trompas en mi, un timbal y cuerdas para la alegoría de los personajes principales, y un acompañamiento de trompeta en si bemol, trombón, triángulo, pandereta, platillos, castañuelas, tambor de caja, y bombo en la orquestación.

Cada personaje de la historia tiene asignado un instrumento y un tema musical: 


Pedro, un joven pionero ruso, vive con su abuelo, que es leñador, en una casa en un claro del bosque. Un día Pedro sale de casa, dejando abierta la puerta del jardín, y se hace amigo de un pájaro. Un pato ve la puerta abierta y decide salir a nadar al estanque cercano. El pájaro y el pato empiezan a discutir: «¿qué clase de ave eres tú que no puedes volar?», a lo que el pato replica: «¿Qué clase de ave eres tú que no puedes nadar?». Entonces el gato de Pedro sale sigiloso intentando atrapar a las aves y Pedro les aconseja que se pongan a salvo, el pájaro vuela a un árbol y el pato nada al centro del estanque.

Entonces llega el abuelo y regaña a Pedro por estar en el prado, y le dice que fuera le puede atrapar el lobo del bosque. Pedro responde diciendo que no tiene miedo, que es muy valiente y puede atrapar al lobo. El abuelo lo mete en la casa de la oreja y cierra la puerta. Poco después en efecto aparece un enorme lobo, el gato se pone a salvo en un árbol, pero el lobo atrapa al pato y se lo come. Pedro presencia la escena mirando a través de una ranura de la puerta. 

Pedro se engancha a una cuerda y salta el muro del jardín, y se encarama a la rama de un árbol. Le pide al pájaro que vuele alrededor del lobo para distraerlo, mientras él desde la rama prepara un nudo corredizo, baja la cuerda y consigue enlazar al lobo por la cola. El lobo trata de liberarse pero Pedro tira con todas sus fuerzas y logra atar la cuerda al árbol. En esto llegan tres cazadores que venían rastreando al lobo y se preparan para dispararle. Pero Pedro les convence para que le ayuden a llevarlo vivo al zoológico. Y todos emprenden un desfile triunfal hacia el zoo, celebrando felices el fin del terror. Al final se puede incluso oír al pato en el interior de la barriga del lobo pues se lo había tragado sin morderlo.

Walt Disney produjo una versión animada de esta obra en 1946, con Sterling Holloway como narrador. Se estrenó como un fragmento de "Música maestro", que se reeditaría al año siguiente acompañando a "Fantasía" (un corto anterior a la película), y que posteriormente en los años 1990 se editó en vídeo por separado.
Esta versión realiza varios cambios respecto al original:


El estudio de animación ruso Soyuzmultfilm produjo una versión de la obra en 1958 en cortometraje, llamado también "Pedro y el lobo". Está realizado con marionetas en animación por fotograma. Fue dirigido por Anatoly Karanovich y narrado por I. Medvedyeva. Esta versión hace los siguientes cambios en la historia:
Esta versión no se estrenó fuera del bloque soviético.

En 2006 Suzie Templeton dirigió con como productor Hugh Welchman, otra adaptación en animación stop-motion, "Peter and the Wolf". Destaca por carecer totalmente de diálogos y narración. La banda sonora fue interpretada por la Philharmonia Orchestra, y la orquesta acompañó en directo su estreno en el Royal Albert Hall. Esta película ganó el premio "Cristal de Annecy" y el premio de la audiencia en el Festival Internacional de Cine de Animación de Annecy de 2007, y también ganó el . Esta versión hace más cambios respecto a la historia original de Prokofiev que las anteriores:


</doc>
<doc id="28212" url="https://es.wikipedia.org/wiki?curid=28212" title="Complejo activado (química)">
Complejo activado (química)

En química, un complejo activado de una reacción química elemental es la disposición particular de los átomos en la cima de la barrera energética. Si representamos su energía frente a todas las coordenadas del sistema, generalmente veremos cómo es un mínimo energético en todas ellas, menos en la coordenada de reacción -que lleva de los reactivos a los productos-, en la que es un máximo. 

Esta teoría fue desarrollada por Eyring e Polanyi (1935).
La estabilización del complejo activado, por ejemplo, a través de enzimas (o catalizadores en general) conlleva generalmente una aceleración sustancial de la reacción.


</doc>
<doc id="28214" url="https://es.wikipedia.org/wiki?curid=28214" title="Carga eléctrica">
Carga eléctrica

La carga eléctrica es una propiedad física intrínseca de algunas partículas subatómicas que se manifiesta mediante fuerzas de atracción y repulsión entre ellas a través de campos electromagnéticos. La materia cargada eléctricamente es influida por los campos electromagnéticos, siendo, a su vez, generadora de ellos. La denominada interacción electromagnética entre carga y campo eléctrico es una de las cuatro interacciones fundamentales de la física. Desde el punto de vista del modelo estándar la carga eléctrica es una medida de la capacidad que posee una partícula para intercambiar fotones.

Una de las principales características de la carga eléctrica es que, en cualquier proceso físico, la carga total de un sistema aislado siempre se conserva. Es decir, la suma algebraica de las cargas positivas y negativas no varía en el tiempo.

La carga eléctrica es de naturaleza discreta, fenómeno demostrado experimentalmente por Robert Millikan. Por razones históricas, a los electrones se les asignó carga negativa: –1, también expresada "–e". Los protones tienen carga positiva: +1 o "+e". A los quarks se les asigna carga fraccionaria: ±1/3 o ±2/3, aunque no se los ha podido observar libres en la naturaleza.

En el Sistema Internacional de Unidades la unidad de carga eléctrica se denomina culombio o coulomb (símbolo C). Se define como la cantidad de carga que pasa por la sección transversal de un conductor eléctrico en un segundo, cuando la corriente eléctrica es de un amperio, y se corresponde con:


Desde la Antigua Grecia se conoce que al frotar ámbar con una piel, ésta adquiere la propiedad de atraer cuerpos ligeros tales como trozos de paja y plumas pequeñas. Su descubrimiento se le atribuye al filósofo griego Tales de Mileto (ca. 639-547 a. C.), quién vivió hace unos 2500 años.

En 1600 el médico inglés William Gilbert observó que algunos materiales se comportan como el ámbar al frotarlos y que la atracción que ejercen se manifiesta sobre cualquier cuerpo, aun cuando no fuera ligero. Como el nombre griego correspondiente al ámbar es "ἤλεκτρον" (ēlektron), Gilbert comenzó a utilizar el término "eléctrico" para referirse a todo material que se comportaba como aquél, lo que originó los términos "electricidad" y "carga eléctrica". Además, en los estudios de Gilbert se puede encontrar la diferenciación de los fenómenos eléctricos y magnéticos. 

El descubrimiento de la atracción y repulsión de elementos al conectarlos con materiales eléctricos se atribuye a Stephen Gray. El primero en proponer la existencia de dos tipos de carga es Charles du Fay, aunque fue Benjamin Franklin quién al estudiar estos fenómenos descubrió como la electricidad de los cuerpos, después de ser frotados, se distribuía en ciertos lugares donde había más atracción; por eso los denominó (+) y (-).

Sin embargo, fue solo hacia mediados del siglo XIX cuando estas observaciones fueron planteadas formalmente, gracias a los experimentos sobre la electrólisis que realizó Michael Faraday, hacia 1833, y que le permitieron descubrir la relación entre la electricidad y la materia; acompañado de la completa descripción de los fenómenos electromagnéticos por James Clerk Maxwell.

Posteriormente, los trabajos de Joseph John Thomson al descubrir el electrón y de Robert Millikan al medir su carga, fueron de gran ayuda para conocer la naturaleza discreta de la carga.

La carga eléctrica es una propiedad intrínseca de la materia que se presenta en dos tipos. Estas llevan ahora el nombre con las que Benjamin Franklin las denominó: cargas positivas y negativas. Cuando cargas del mismo tipo se encuentran se repelen y cuando son diferentes se atraen. Con el advenimiento de la teoría cuántica relativista, se pudo demostrar formalmente que las partículas, además de presentar carga eléctrica (sea nula o no), presentan un momento magnético intrínseco, denominado "espín", que surge como consecuencia de aplicar la teoría de la relatividad especial a la mecánica cuántica.

Las investigaciones actuales de la física apuntan a que la carga eléctrica es una propiedad cuantizada. La unidad más elemental de carga se encontró que es la carga que tiene el electrón, es decir alrededor de 1,602 176 487(40) × 10 culombios (C) y es conocida como carga elemental. El valor de la carga eléctrica de un cuerpo, representada como "q" o "Q", se mide según el número de electrones que posea en exceso o en defecto.

Esta propiedad se conoce como "cuantización de la carga" y el valor fundamental corresponde al valor de carga eléctrica que posee el electrón y al cual se lo representa como "e". Cualquier carga "q" que exista físicamente, puede escribirse como formula_1 siendo "N" un número entero, positivo o negativo. 

Por convención se representa a la carga del electrón como "-e", para el protón "+e" y para el neutrón, "0". La física de partículas postula que la carga de los quarks, partículas que componen a protones y neutrones toman valores fraccionarios de esta carga elemental. Sin embargo, nunca se han observado quarks libres, y el valor de su carga en conjunto, en el caso del protón suma +e y en el neutrón suma 0.

Aunque no tenemos una explicación suficientemente completa de por qué la carga es una magnitud cuantizada, que sólo puede aparecer en múltiplos de la carga elemental, se han propuestos diversas ideas:


En el Sistema Internacional de Unidades la unidad de carga eléctrica se denomina culombio (símbolo C) y se define como "la cantidad de carga que a la distancia de 1 metro ejerce sobre otra cantidad de carga igual una fuerza de 9×10 N".

Un culombio corresponde a la carga de 6,241 509 × 10 electrones. El valor de la carga del electrón fue determinado entre 1910 y 1917 por Robert Andrews Millikan y en la actualidad su valor en el Sistema Internacional de acuerdo con la última lista de constantes del CODATA publicada es:

Como el culombio puede no ser manejable en algunas aplicaciones, por ser demasiado grande, se utilizan también sus submúltiplos:

Frecuentemente se usa también el sistema CGS cuya unidad de carga eléctrica es el Franklin (Fr). El valor de la carga elemental es entonces de aproximadamente 4,803×10 Fr.

En concordancia con los resultados experimentales, el "principio de conservación de la carga" establece que no hay destrucción ni creación neta de carga eléctrica, y afirma que en todo proceso electromagnético la carga total de un sistema aislado se conserva.

En un proceso de electrización, el número total de protones y electrones no se altera, sólo existe una separación de las cargas eléctricas. Por tanto, no hay destrucción ni creación de carga eléctrica, es decir, la carga total se conserva. Pueden aparecer cargas eléctricas donde antes no había, pero siempre lo harán de modo que la carga total del sistema permanezca constante. Además esta conservación es local, ocurre en cualquier región del espacio por pequeña que sea.

Al igual que las otras leyes de conservación, la conservación de la carga eléctrica está asociada a una simetría del lagrangiano, llamada en física cuántica invariancia gauge. Así por el teorema de Noether a cada simetría del lagrangiano asociada a un grupo uniparamétrico de transformaciones que dejan el lagrangiano invariante le corresponde una magnitud conservada. La conservación de la carga implica, al igual que la conservación de la masa, que en cada punto del espacio se satisface una ecuación de continuidad que relaciona la derivada de la densidad de carga eléctrica con la divergencia del vector "densidad de corriente eléctrica", dicha ecuación expresa que el cambio neto en la densidad de carga formula_6 dentro de un volumen prefijado formula_7 es igual a la integral de la densidad de corriente eléctrica formula_8 sobre la superficie formula_9 que encierra el volumen, que a su vez es igual a la intensidad de corriente eléctrica formula_10:
Otra propiedad de la carga eléctrica es que es un invariante relativista. Eso quiere decir que todos los observadores, sin importar su estado de movimiento y su velocidad, podrán siempre medir la misma cantidad de carga. Así, a diferencia del espacio, el tiempo, la energía o el momento lineal, cuando un cuerpo o partícula se mueve a velocidades comparables con la velocidad de la luz, el valor de su carga no variará.

Se llama densidad de carga eléctrica a la cantidad de carga eléctrica por unidad de longitud, área o volumen que se encuentra sobre una línea, una superficie o una región del espacio, respectivamente. Por lo tanto se distingue en estos tres tipos de densidad de carga. Se representaría con las letras griegas lambda (λ), para densidad de carga lineal, sigma (σ), para densidad de carga superficial y ro (ρ), para densidad de carga volumétrica.

Puede haber densidades de carga tanto positivas como negativas. No se debe confundir con la densidad de portadores de carga.

A pesar de que las cargas eléctricas son cuantizadas con q y, por ende, múltiplos de una carga elemental, en ocasiones las cargas eléctricas en un cuerpo están tan cercanas entre sí, que se puede suponer que están distribuidas de manera uniforme por el cuerpo del cual forman parte. La característica principal de estos cuerpos es que se los puede estudiar como si fueran continuos, lo que hace más fácil, sin perder generalidad, su tratamiento. Se distinguen tres tipos de densidad de carga eléctrica: lineal, superficial y volumétrica.

Se usa en cuerpos lineales como, por ejemplo hilos.

Donde formula_11 es la carga encerrada en el cuerpo y formula_12 es la longitud. En el Sistema Internacional de Unidades (SI) se mide en C/m (culombios por metro).

Se emplea para superficies, por ejemplo una plancha metálica delgada como el "papel de aluminio".

donde formula_11 es la carga encerrada en el cuerpo y formula_9 es la superficie. En el SI se mide en C/m (culombios por metro cuadrado).

Se emplea para cuerpos que tienen volumen.

donde formula_11 es la carga encerrada en el cuerpo y formula_7 el volumen. En el SI se mide en C/m (culombios por metro cúbico).

Se denomina electrización al efecto de ganar o perder cargas eléctricas, normalmente electrones, producido por un cuerpo eléctricamente neutro. Los tipos de electrificación son los siguientes:




</doc>
<doc id="28217" url="https://es.wikipedia.org/wiki?curid=28217" title="Serguéi Prokófiev">
Serguéi Prokófiev

Serguéi Serguéievich Prokófiev (en ruso Серге́й Серге́евич Проко́фьев) (Sóntsovka, 23 de abril de 1891–Moscú, 5 de marzo de 1953), conocido como Serguéi Prokófiev, fue un compositor, pianista y director de orquesta ruso.

Prokófiev nació en 1891 en Sontsovka (ahora Sontsivka, Raión Pokrovsk, Óblast de Donetsk, Ucrania oriental), una finca rural remota en la gobernación de Yekaterinoslav del Imperio ruso. Su padre, Serguéi Alexeyevich Prokófiev, era ingeniero agrónomo. La madre de Prokófiev, María (de soltera Zhitkova), provenía de una familia de antiguos siervos que habían sido propiedad de la familia Sheremetev, bajo cuyo patrocinio se enseñó a los siervos desde una edad temprana. Fue descrita por Reinhold Glière (el primer profesor de composición de Prokófiev) como "una mujer alta con hermosos ojos inteligentes ... que supo crear una atmósfera de calidez y sencillez sobre ella". Después de su boda en el verano de 1877, los Prokófiev se mudaron a una pequeña propiedad en la gobernación de Smolensk. Eventualmente, Sergei Alexeyevich encontró empleo como ingeniero de caminos, empleado por uno de sus antiguos compañeros de estudios, Dmitri Sontsov, a cuya propiedad en las estepas ucranianas se mudaron los Prokófiev.

En el momento del nacimiento de Prokofiev, María, que había perdido dos hijas anteriormente, había dedicado su vida a la música; durante la primera infancia de su hijo, pasó dos meses al año en Moscú o San Petersburgo tomando clases de piano. Sergei Prokofiev se inspiró en escuchar a su madre practicando el piano por la noche, en su mayoría obras de Chopin y Beethoven, y escribió su primera composición para piano a la edad de cinco años, un ""Galope indio"", que fue escrito por su madre en una escala mayor con un cuarto grado de escala elevado, ya que el joven Prokofiev sentía "renuencia a abordar las notas negras". A los siete años también había aprendido a jugar al ajedrez. El ajedrez seguiría siendo una pasión suya, y se familiarizó con los campeones mundiales de ajedrez como José Raúl Capablanca, a quien venció en un partido de exhibición simultánea en 1914, y Mijaíl Botvínnik, con quien jugó varios partidos en la década de 1930. A la edad de nueve años, estaba componiendo su primera ópera, "The Giant", así como una obertura y otras piezas.

En 1902, la madre de Prokófiev se encontró con Serguéi Tanéyev, director del Conservatorio de Moscú, quien inicialmente sugirió que Prokófiev debería comenzar las clases de piano y composición con Alexander Goldenweiser. Incapaz de arreglar eso, Taneyev en cambio arregló las cosas para que el compositor y pianista Reinhold Glière pasara el verano de 1902 en Sontsovka enseñando a Prokófiev. La primera serie de lecciones culminó, ante la insistencia de Prokófiev, de 11 años, con el incipiente compositor haciendo su primer intento de escribir una sinfonía. El verano siguiente, Glière volvió a visitar Sontsovka para dar más clases. Cuando, décadas después, Prokófiev escribió sobre sus lecciones con Glière, dio crédito al método simpático de su maestro, pero se quejó de que Glière le había presentado la estructura de frase "cuadrada" y las modulaciones convencionales, que posteriormente tuvo que desaprender. Sin embargo, equipado con las herramientas teóricas necesarias, Prokófiev comenzó a experimentar con armonías disonantes y marcas de tiempo inusuales en una serie de piezas cortas de piano que llamó ""ditties"" (a partir de la llamada "forma de canción", más precisamente de forma ternaria, en la que se basaron), sentando las bases para su propio estilo musical.

A pesar de su creciente talento, los padres de Prokófiev dudaron sobre iniciar a su hijo en una carrera musical a tan temprana edad, y consideraron la posibilidad de que asistiera a una buena escuela secundaria en Moscú. En 1904, su madre se había decidido en cambio por San Petersburgo, y ella y Prokófiev visitaron la entonces capital para explorar la posibilidad de mudarse allí para su educación. Fueron presentados al compositor Aleksandr Glazunov, profesor en el Conservatorio de San Petersburgo, quien pidió ver a Prokofiev y su música. Prokofiev había compuesto dos óperas más, "Desert Islands" y "The Feast during The Plague", y estaba trabajando en su cuarta, "Undina". Glazunov quedó tan impresionado que instó a la madre de Prokofiev a que su hijo solicitara la admisión al Conservatorio. Pasó las pruebas introductorias y se inscribió ese año.

Varios años más joven que la mayoría de su clase, Prokofiev era visto como excéntrico y arrogante, y molestaba a varios de sus compañeros manteniendo estadísticas sobre sus errores. Durante ese período, estudió bajo, entre otros, Alexander Winkler para el piano, Anatoly Lyadov para armonía y contrapunto, Nikolai Tcherepnin para dirección, y Nikolai Rimsky-Korsakov para orquestación (aunque cuando Rimsky-Korsakov murió en 1908, Prokófiev señaló que era solo uno de muchos estudiantes en una clase muy concurrida y lamentó que de otro modo "nunca tuvo la oportunidad de estudiar con él"). También compartió clases con los compositores Boris Asafyev y Nikolai Myaskovsky, y este último se convirtió en un amigo relativamente cercano y de por vida.

Como miembro de la escena musical de San Petersburgo, Prokófiev desarrolló una reputación como un rebelde musical, mientras recibía elogios por sus composiciones originales, que interpretó él mismo en el piano. En 1909, se graduó de su clase en composición con notas poco impresionantes. Continuó en el Conservatorio, estudiando piano con Anna Yesipova y continuando sus clases de dirección bajo Tcherepnin.

En 1910, el padre de Prokofiev murió y el apoyo financiero a Sergei cesó. Afortunadamente, comenzó a hacerse un nombre como compositor y pianista fuera del Conservatorio, haciendo apariciones en las noches de música contemporánea de San Petersburgo. Allí interpretó varias de sus obras para piano más aventureras, como sus altamente cromáticos y disonantes, "Etudes" op. 2 (1909). Su actuación impresionó a los organizadores de las Noches lo suficiente como para invitar a Prokofiev a dar el estreno ruso de "Drei Klavierstücke" op. 11, de Arnold Schoenberg. La experimentación armónica de Prokófiev continuó con "Sarcasmos para piano", op. 17 (1912), que hace un uso extenso de politonalidad. Compuso sus primeros dos conciertos para piano alrededor de ese momento, el último de los cuales causó un escándalo en su estreno (23 de agosto de 1913, Pavlovsk). Según una versión, el público salió de la sala con exclamaciones de "¡Al diablo con esta música futurista! ¡Los gatos en el tejado hacen mejor música!", Pero los modernos estaban en éxtasis.

En 1911, llegó la ayuda del renombrado musicólogo y crítico ruso Alexander Ossovsky, quien escribió una carta de apoyo al editor de música Boris P. Jurgenson (hijo del fundador de la editorial Peter Jurgenson [1836-1904]); y así se le ofreció un contrato al compositor. Prokófiev hizo su primer viaje al extranjero en 1913, viajando a París y Londres, donde se encontró por primera vez con los Ballets Rusos de Sergei Diaghilev.

En 1914, Prokófiev terminó su carrera en el Conservatorio al participar en la "batalla de los pianos", una competencia abierta a los cinco mejores estudiantes de piano, cuyo premio fue un piano de cola Schreder: Prokófiev ganó al interpretar su propio "Concierto para piano n.º 1". Sus primeras obras, como el "Concierto para piano n.º 1" (1911) y la "Suite escita" para orquesta (1914), le valieron mala fama como músico, pues no correspondía con la línea nacionalista rusa.

Poco después, viajó a Londres, donde se puso en contacto con el empresario Sergei Diaghilev. Diaghilev encargó el primer ballet de Prokofiev, "Ala y Lolli"; pero cuando Prokofiev le trajo el trabajo en curso a Italia en 1915, lo rechazó como "no ruso". Instando a Prokofiev a escribir "música que fuera de carácter nacional", Diaghilev luego le encargó el ballet "Chout" ("The Fool", el título original en ruso fue "Сказка про шута, семерых шутов перешутившего" ("Skazka pro shuta, semerykh shutov pereshutivshevo"), que significa ""El cuento del bufón que supera a otros siete bufones""). Bajo la guía de Diaghilev, Prokofiev eligió su tema de una colección de cuentos populares recopilados por el etnógrafo Alexander Afanasyev. La historia, relacionada con un bufón y una serie de trucos de confianza, había sido previamente sugerida a Diaghilev por Igor Stravinsky como posible tema para un el ballet, y Diaghilev y su coreógrafo Léonide Massine ayudaron a Prokofiev a darle forma de guion de ballet. La inexperiencia de Prokófiev con el ballet lo llevó a revisar el trabajo extensamente en la década de 1920, siguiendo la detallada crítica de Diaghilev, antes de su primera producción. El estreno del ballet en París el 17 de mayo de 1921 fue un gran éxito y fue recibido con gran admiración por un público que incluía a Jean Cocteau, Igor Stravinsky y Maurice Ravel. Stravinsky llamó al ballet "la única pieza de música moderna que podía escuchar con placer", mientras que Ravel lo llamó "una obra de genio".
En paralelo durante la Primera Guerra Mundial, Prokófiev regresó al Conservatorio. Estudió órgano para evitar ser reclutado. Compuso "El jugador", ópera basada en la novela homónima de Fiódor Dostoievski, pero los ensayos estuvieron plagados de problemas y el estreno, previsto para el año 1917, tuvo que ser cancelado debido a la Revolución de febrero. En el verano de aquel año, Prokófiev compuso su primera sinfonía, la "Clásica". Este es el nombre que él mismo le dio, dado que fue compuesta en un estilo que, según Prokófiev, Joseph Haydn habría usado si estuviera vivo en esa época. Es de estilo más o menos clásico, pero incorpora elementos musicales más modernos (ver Neoclasicismo). La sinfonía también fue una obra contemporánea exacta del "Concierto para violín n.º 1, en re mayor, op. 19", que estaba programado para estrenarse en noviembre de 1917. Compuso la melodía de apertura del concierto en 1915, durante su historia de amor con Nina Mescherskaya. Los movimientos restantes se inspiraron en parte en la representación en San Petersburgo de 1916 de la obra "Mitos" de Karol Szymanowski por el violinista polaco Paul Kochanski.

Las primeras interpretaciones de ambas obras debieron esperar hasta el 21 de abril de 1918 y el 18 de octubre de 1923, respectivamente. 

A pesar de los acontecimientos que llevaron a la abdicación del zar Nicolás II de Rusia y, finalmente, la Revolución de Octubre, 1917 se convirtió en el año más productivo de Prokófiev en términos de composición. Junto con el "Primer concierto para violín" y la "Sinfonía "clásica"", compuso la "tercera y cuarta sonatas para piano" y las "Visiones fugitivas para piano". También comenzó la cantata "Siete, eran siete", basada en textos caldeos, y trabajó en el "Tercer concierto para piano".

Se quedó brevemente con su madre en Kislovodsk en el Cáucaso. Después de completar la composición de la cantata "Siete, ellos eran siete", una "invocación caldea" para coro y orquesta, Prokófiev dice "quedé sin nada que hacer y el tiempo colgó pesadamente de mis manos". Creyendo que Rusia "no tenía ningún uso para la música en ese momento", Prokófiev decidió probar fortuna en América hasta que la confusión en su tierra natal hubiera pasado. Partió hacia Moscú y Petersburgo en marzo de 1918 para resolver cuestiones financieras y organizar su pasaporte. En mayo se dirigió a los Estados Unidos, obteniendo el permiso oficial de Anatoly Lunacharsky, el Comisario del Pueblo para la Educación, quien le dijo: "Eres un revolucionario en la música, somos revolucionarios en la vida. Debemos trabajar juntos. Si quieres ir a América, no me interpondré en tu camino".

Al llegar a San Francisco después de haber sido liberado de los interrogatorios por funcionarios de inmigración en la Isla de los Ángeles el 11 de agosto de 1918, Prokofiev pronto fue comparado con otros exiliados rusos famosos (como Sergei Rachmaninoff). Su concierto de debut como solista en Nueva York dio lugar a varios compromisos más. También firmó un contrato con el director musical de la Chicago Opera Association, Cleofonte Campanini, para la producción de su nueva ópera "El amor de las tres naranjas"; sin embargo, debido a la enfermedad y la muerte de Campanini, el estreno fue pospuesto. La demora fue otro ejemplo de la mala suerte de Prokófiev en asuntos operísticos. El fracaso también le costó su carrera como solista estadounidense ya que la ópera le tomó demasiado tiempo y esfuerzo. Pronto se encontró en dificultades financieras, y en abril de 1920, se fue a París, no queriendo regresar a Rusia y reconocer un fracaso.

En París, Prokófiev reafirmó sus contactos con los Ballets Rusos de Diaghilev. También completó algunas de sus obras más antiguas, inacabadas, como el "Tercer Concierto para piano". "El amor de tres naranjas" finalmente se estrenó en Chicago, bajo la batuta del compositor, el 30 de diciembre de 1921. Diaghilev se interesó lo suficiente en la ópera como para pedirle a Prokófiev que diera una audición de la partitura vocal en junio de 1922, mientras ambos estaban en París para una reactivación de "Chout", por lo que podría considerarlo para una posible producción. Stravinsky, que estuvo presente en la audición, se negó a escuchar más que el primer acto. Entonces acusó a Prokófiev de "perder el tiempo componiendo óperas", Prokófiev replicó que Stravinsky "no estaba en posición de establecer una dirección artística general, ya que él mismo no es inmune al error". Según Prokófiev, Stravinsky "se volvió incandescente por la ira" y "casi llegamos a las manos y nos separamos solo con dificultad". Como resultado, "nuestras relaciones se tensaron y durante varios años la actitud de Stravinsky hacia mí fue crítica".

En marzo de 1922, Prokófiev se mudó con su madre a la ciudad de Ettal, en los Alpes bávaros, donde durante más de un año se concentró en un proyecto de ópera, "El Ángel de Fuego", basado en la novela de Valery Bryusov. Su música posterior había adquirido seguidores en Rusia, y recibió invitaciones para regresar allí, pero decidió quedarse en Europa. En 1923, Prokófiev se casó con la cantante española de madre rusa, Carolina Codina (1897-1989, de nombre artístico Lina Llubera) antes de regresar a París.

En París, varias de sus obras, incluida la "Segunda Sinfonía", se representaron, pero su recepción fue tibia y Prokófiev sintió que "evidentemente ya no era una sensación". Aún así, la "Segunda Sinfonía" pareció incitar a Diaghilev a encargar "Le pas d'acier (El paso de acero)", una partitura de ballet "modernista" destinada a retratar la industrialización de la Unión Soviética. La obra fue recibida con entusiasmo por audiencias y críticos parisinos.

Alrededor de 1924, Prokofiev fue introducido a la Ciencia Cristiana. Comenzó a practicar sus enseñanzas, que creía que eran beneficiosas para su salud y su temperamento ardiente y a las que permaneció fiel por el resto de su vida, según el biógrafo Simon Morrison.

Prokofiev y Stravinsky restauraron su amistad, aunque a Prokofiev le disgustó particularmente la "estilización al modo de Bach" de Stravinsky en obras tan recientes como el "Octeto" y el "Concierto para piano y instrumentos de viento". Por su parte, Stravinsky describió a Prokofiev como el Compositor ruso de su tiempo, después de él.

En 1927, Prokófiev hizo su primera gira de conciertos en la Unión Soviética. En el transcurso de más de dos meses, pasó un tiempo en Moscú y Leningrado (el nuevo nombre a San Petersburgo), donde disfrutó de una exitosa puesta en escena de "El amor de las tres naranjas" en el Teatro Mariinsky. En 1928, Prokófiev completó su "Tercera Sinfonía", que se basaba ampliamente en su ópera no estrenada "El Ángel de Fuego". El director Serguéi Kusevitski caracterizó a la Tercera como "la mayor sinfonía desde la Sexta de Chaikovski".

Mientras tanto, sin embargo, Prokófiev, bajo la influencia de las enseñanzas de la Ciencia Cristiana, se había vuelto contra el estilo expresionista y el tema de "El Ángel de Fuego". Ahora prefería lo que llamó una "nueva simplicidad", que creía más sincera que las "artimañas y complejidades" de tanta música moderna de la década de 1920. Durante 1928-29, Prokofiev compuso lo que iba a ser su último ballet para Diaghilev, "El hijo pródigo". Cuando se representó por primera vez en París el 21 de mayo de 1929, con coreografía de George Balanchine, Serge Lifar en el papel principal y decorados de Georges Rouault, la audiencia y los críticos quedaron especialmente impresionados por la escena final en la que el hijo pródigo se arrastra sobre el escenario arrodillado para ser bienvenido. su padre. Diaghilev había reconocido que en la música de la escena, Prokofiev "nunca había sido más claro, más simple, más melodioso y más tierno". Solo unos meses después, Diaghilev murió.

Ese verano, Prokofiev completó el "Divertimento, op. 43" (que había comenzado en 1925) y revisó su "Sinfonietta, op. 5/48", un trabajo que comenzó en sus días en el Conservatorio. En octubre de ese año, tuvo un accidente automovilístico mientras conducía a su familia de regreso a París después de sus vacaciones: cuando el auto volcó, Prokófiev perdió algunos músculos en su mano izquierda. Prokófiev, por lo tanto, no pudo actuar en Moscú durante su gira poco después del accidente, pero pudo disfrutar viendo las interpretaciones de su música en público. Prokófiev también asistió a la "audición" del Teatro Bolshoi de su ballet "El paso de acero", y fue interrogado por miembros de la Asociación Rusa de Músicos Proletarios (RAPM) sobre el trabajo: se le preguntó si la fábrica retrataba "una fábrica capitalista, donde el trabajador es un esclavo, o una fábrica soviética, donde el trabajador es el maestro. Si se trata de una fábrica soviética, cuándo y dónde lo examinó Prokófiev, que desde 1918 hasta el presente había estado viviendo en el extranjero y vino aquí por primera vez en 1927 durante dos semanas?" Prokófiev respondió: "Eso se refiere a la política, no a la música, y por lo tanto no responderé". La RAPM condenó el ballet de manera dogmática como una "anécdota antisoviética llana y vulgar, una composición contrarrevolucionaria que linda con el fascismo". El Bolshoi no tuvo más opción que rechazar el ballet.Con la mano izquierda sanada, Prokofiev recorrió los Estados Unidos con éxito a principios de 1930, apoyado por su reciente éxito europeo. Ese año Prokofiev comenzó su primer ballet no Diaghilev con "En el Dnieper, op. 51", una obra encargada por Serge Lifar, que había sido nombrado maitre de ballet en la Ópera de París. En 1931 y 1932, completó su "cuarto y quinto conciertos para piano". El año siguiente vio la finalización de la "Canción Sinfónica, Op. 57", de la que el amigo de Prokofiev, Myaskovsky, pensando en su posible audiencia en la Unión Soviética, le dijo "no es para nosotros ... carece de lo que entendemos por monumentalismo - una simplicidad familiar y amplios contornos, de los cuales eres extremadamente capaz, pero que temporalmente estás evitando cuidadosamente".
A principios de la década de 1930, tanto Europa como América sufrían la Gran Depresión, que inhibió tanto las nuevas producciones de ópera como las de ballet, aunque las audiencias para las apariciones de Prokófiev como pianista no habían disminuido, al menos en Europa. Sin embargo, Prokófiev, que se veía a sí mismo como un compositor en primer lugar, estaba cada vez más resentido por la cantidad de tiempo que perdía para la composición a través de sus apariciones como pianista. Después de haber estado nostálgico por algún tiempo, Prokófiev comenzó a construir puentes sustanciales con la Unión Soviética. Tras la disolución de la RAPM en 1932, actuó cada vez más como embajador musical entre su país de origen en Europa occidental, y sus estrenos y comisiones fueron cada vez más bajo los auspicios de la Unión Soviética. Uno de ellos fue "El teniente Kijé", que fue comisionado como la banda sonora de una película soviética. Otra comisión, del Teatro Kirov (como se denominaba entonces al Mariinsky) en Leningrado, fue el ballet "Romeo y Julieta", compuesto para un guion creado por Adrian Piotrovsky y Sergei Radlov siguiendo los preceptos de "drambalet" (ballet dramatizado, oficialmente promovido en el Kirov para reemplazar las obras basadas principalmente en la visualización coreográfica y la innovación). Tras la amarga renuncia de Radlov al Kirov en junio de 1934, se firmó un nuevo acuerdo con el Teatro Bolshoi de Moscú, en el entendido de que Piotrovsky seguiría participando. Sin embargo, el final feliz original del ballet (contrario a Shakespeare) provocó controversia entre los funcionarios culturales soviéticos; la producción del ballet fue pospuesta indefinidamente cuando el personal del Bolshoi fue 

revisado a instancias del presidente de la Comisión de Asuntos de Arte, Platon Kerzhentsev. Nikolai Myaskovsky, uno de sus amigos más cercanos, mencionó en varias cartas cómo le gustaría que Prokofiev permaneciera en Rusia. 

El "Concierto para violín n.º 2 en sol menor" opus 63, escrito en 1935 fue estrenado el 1 de diciembre de 1935 en Madrid por el violinista francés Robert Soëtans y la Orquesta Sinfónica de Madrid dirigida por Enrique Fernández Arbós.

En 1936, Prokófiev y su familia se establecieron permanentemente en Moscú, después de desplazarse entre Moscú y París durante los últimos cuatro años. Ese año compuso una de sus obras más famosas, "Pedro y el lobo", para el Teatro Central para Niños de Natalya Sats. Se trata de un trabajo programático para narrador, instrumentos individuales y orquesta. Sats también persuadió a Prokófiev para que escribiera dos canciones para niños, "Sweet Song" y "Chatterbox"; finalmente se unieron a "The Little Pigs" y se publicaron como "Tres canciones para niños, op. 68". Prokófiev también compuso la gigantesca "Cantata para el vigésimo aniversario de la Revolución de Octubre", originalmente destinada a la presentación durante el año del aniversario, pero efectivamente bloqueada por Kerzhentsev, quien exigió en la audición del trabajo ante la Comisión de Asuntos de las Artes: "¿Qué crees tú?" ¿Ha vuelto, Sergey Sergeyevich, tomando textos que pertenecen a la gente y poniéndoles una música tan incomprensible? La Cantata tuvo que esperar hasta el 5 de abril de 1966 para un estreno parcial, algo más de 13 años después de la muerte del compositor.

Obligado a adaptarse a las nuevas circunstancias (cualesquiera que fueran los recelos privados que tuviera sobre ellas), Prokófiev escribió una serie de ""Canciones de masas"" (Opp. 66, 79, 89), utilizando las letras de los poetas soviéticos oficialmente aprobados. En 1938, Prokófiev colaboró ​​con Serguéi Eisenstein en la épica película histórica "Alejandro Nevski", parte de su música más creativa y dramática. Aunque la película tenía una grabación de sonido muy pobre, Prokófiev adaptó gran parte de su partitura a una cantata de gran escala para mezzosoprano, orquesta y coro, que fue interpretada y grabada extensamente. Tras el éxito de "Alejandro Nevski", Prokófiev compuso su primera ópera soviética, "Semyon Kotko", que debía ser producida por el director Vsevolod Meyerhold. Sin embargo, el estreno de la ópera se pospuso porque Meyerhold fue arrestado el 20 de junio de 1939 por la NKVD (policía secreta de Joseph Stalin) y fusilado el 2 de febrero de 1940. Solo meses después del arresto de Meyerhold, Prokófiev fue 'invitado' a componer "Zdravitsa" (literalmente traducido '¡Salud!', pero con más frecuencia conocida por el título inglés "Hail to Stalin") (Op. 85) para celebrar el 60º cumpleaños de Joseph Stalin.

Más tarde, en 1939, Prokófiev compuso sus "Sonatas para piano Nos. 6, 7 y 8, Opp. 82-84", ampliamente conocidas hoy como las ""Sonatas de Guerra"". Estrenadas respectivamente por Prokófiev (n.º 6: 8 de abril de 1940), Sviatoslav Richter (n.º 7: Moscú, 18 de enero de 1943) y Emil Guilels (n.º 8: Moscú, 30 de diciembre de 1944), que fueron posteriormente muy interpretadas en particular por Richter. El biógrafo Daniel Jaffé argumentó que Prokófiev, "habiéndose forzado a componer una alegre evocación del nirvana que Stalin quería que todos creyeran haber creado" (es decir, en "Zdravitsa"), posteriormente, en las tres sonatas, "expresó sus verdaderos sentimientos". Como evidencia, Jaffé ha señalado que el movimiento central de Sonata No. 7 se abre con un tema basado en Robert Schumann 'Wehmut' ('Tristeza', que aparece en el "Liederkreis" de Schumann, Op. 39): sus palabras se traducen, "A veces puedo cantar como si estuviera contento, pero secretamente las lágrimas son buenas y así liberas mi corazón. Los ruiseñores... cantan su canción de anhelo desde la profundidad de su mazmorra ... todo el mundo se deleita, pero nadie siente el dolor, la profunda tristeza en la canción". Irónicamente (parece que nadie notó su alusión), la Sonata No. 7 recibió un Premio Stalin (Segunda Clase), y la No. 8 un Premio Stalin (Primera Clase). 

Mientras tanto, "Romeo y Julieta" finalmente fue montado por el Kirov Ballet, coreografiado por Leonid Lavrovsky, el 11 de enero de 1940. Para sorpresa de todos sus participantes, los bailarines que lucharon para arreglárselas con los ritmos sincopados de la música y casi boicotearon la producción, el ballet fue un éxito instantáneo, y fue reconocido como el mayor logro del ballet dramático soviético.

Ante la Operación Barbarroja, con la invasión alemana de la Unión Soviética en junio de 1941, se ordenaron diversas evacuaciones hacia territorios más alejados los presuntos teatros de operaciones militares. Prokófiev era uno de los que estaba dentro de esos planes y marchó hacia el Cáucaso. El año ya había empezado mal para el compositor, había sufrido un ataque al corazón en primavera. Lina se quedaba en Moscú con sus dos hijos. Prokófiev se separa de Lina en 1941, aunque nunca se divorciaron formalmente. Desde entonces estaba ligado sentimentalmente con la escritora y libretista de 25 años Mira Mendelson (1915-1968), que era evacuada de Moscú junto con Prokófiev.

Durante los años de la guerra, las restricciones sobre el estilo y la petición de que los compositores escribieran en un estilo de "realismo socialista" se aflojaron, y Prokofiev generalmente pudo componer a su manera.

Siguió escribiendo la ópera "Guerra y paz", basada en la novela monumental de Tolstoi. El tratamiento que le dio Prokófiev también fue igualmente monumental. La partitura para piano fue completada en el verano de 1942 (cambiando dos escenas de la versión original), y fue sometida al Comité soviético para las Artes. El Comité exigió que las escenas de la segunda parte (la Guerra) fueran más patrióticas y tuvieran mayor énfasis heroico. Prokófiev, que quería ver su obra maestra representada cuanto antes, añadió marchas, coros, y otros materiales a la segunda parte para satisfacer al comité. Además, compuso el Prólogo coral, que enfatiza el desafío del pueblo ruso frente al enemigo.

Estaba previsto estrenarla en 1943 en el Teatro Bolshói de Moscú con dirección de Serguéi Eisenstein y dirección de Samuil Samosud. Pero solo se pudo hacer una representación privada de ocho escenas con acompañamiento para piano en el Centro de Actores de Moscú el 16 de octubre de 1944, y una representación pública en versión de concierto, con nueve escenas, dirigida por Samosud, que tuvo lugar en el Gran Hall del Conservatorio de Moscú el 7 de junio de 1945. La primera representación escenificada fue de una versión ampliada en siete 

escenas, que tuvo lugar el 12 de junio de 1946 en el Teatro Maly de Leningrado, con dirección de Samosud. La segunda parte, también con una escena adicional (escena 10), se iba a representar en julio de 1947, pero después del ensayo no se ofrecieron representaciones públicas, «"por razones ajenas al control del teatro y del compositor"». Después del Decreto Zhdánov de febrero de 1948, Prokófiev comenzó a trabajar en una versión más reducida de la ópera, para un sólo día, al tiempo que hizo varias revisiones del esquema original, aunque mantuvo la estructura de 13 escenas. Esta versión se interpretó por primera vez el 26 de mayo de 1953 en el Teatro Comunale, Florencia, dirigida por Artur Rodziński, dos meses después de la muerte del compositor.

También empezaba en 1942 un borrador para otra ópera, "Khan Buzay", que abandonaría. Asimismo, también escribía música para cuatro películas, el ballet "La cenicienta", varias suites sinfónicas, el "Cuarteto de cuerda núm. 2", una "Sonata para flauta y piano", una transcripción de la misma para violín y piano (hecho a instancias del violinista David Oistrakh), dos marchas militares y unas cuantas canciones folclóricas.

En 1943 Prokofiev se unió a Eisenstein en Alma-Ata, la ciudad más grande de Kazajstán, para componer más música de cine ("Iván el Terrible") y el ballet de Cenicienta (Op. 87), una de sus composiciones más melódicas y célebres. En 1944, Prokofiev compuso su "Quinta Sinfonía (Op. 100)" en la colonia de compositores fuera de Moscú. Dirigió su estreno el 13 de enero de 1945, justo quince días después del triunfante estreno el 30 de diciembre de 1944 de su "Octava Sonata de Piano" y, el mismo día, la primera parte de "Ivan el Terrible" de Eisenstein. La obra rápidamente emergió como su sinfonía más popular y se le otorgó su segundo premio Stalin. Con el estreno de su "Quinta Sinfonía", que fue programada junto a "Pedro y el Lobo" y la "Sinfonía Clásica" (dirigida por Nikolai Anosov), Prokófiev pareció alcanzar el cenit de su fama como compositor líder de la Unión Soviética. 

"La Cenicienta", el segundo ballet más popular de Prokófiev después de Romeo y Julieta, fue originalmente encargada por el Teatro Kírov, justo antes de la invasión alemana. Pero no fue estrenado hasta el 1945 en el escenario del Bolshoi con un éxito considerable y con la famosa bailarina Galina Ulanova. El estreno en el Kírov de Leningrado se produjo cinco meses más tarde y se repitió el éxito. Antes del estreno hizo varias transcripciones para piano de la misma (Op. 95, 97 y 102).

Esta etapa brillante en su vida como compositor culmina desgraciadamente en enero de 1945, cuando Prokófiev sufrió una conmoción cerebral en una caída. Su vida corrió peligro los siguientes días y a partir de entonces sufriría a menudo dolores de cabeza y periodos de presión arterial peligrosamente alta. No se recuperaría nunca más de forma completa de este accidente, aunque la grandeza de sus trabajos no den esta impresión.

Prokofiev tuvo tiempo de escribir su "Sexta Sinfonía" de posguerra y su "Novena Sonata para Piano" (para Sviatoslav Richter) antes del llamado "Decreto Zhdanov". A principios de 1948, después de una reunión de compositores soviéticos convocada por Andrei Zhdanov, el Politburó emitió una resolución denunciando a Prokofiev, Dmitri Shostakovich, Myaskovsky y Khachaturian por el crimen del "formalismo", descrito como una "renuncia a los principios básicos de la música clásica" ... "a favor de sonidos confusos, nerviosos que convierten la música en cacofonía". Ocho de las obras de Prokofiev fueron prohibidas: "El año 1941", la "Oda al final de la guerra", el "Poema festivo", la "Cantata por el trigésimo aniversario de la revolución de octubre", la "Balada de un niño desconocido", "Los pensamientos" ciclo para piano de 1934 y la "sonata para piano núms. 8". Tal era la amenaza percibida detrás de la prohibición de las obras que incluso las obras que habían evitado la censura ya no fueron programadas: en agosto de 1948, Prokófiev estaba en graves aprietos financieros, su deuda personal ascendía a 180.000 rublos.

Mientras tanto, el 20 de febrero de 1948, la esposa de Prokófiev, Lina, fue arrestada por "espionaje", ya que había intentado enviar dinero a su madre en España. Después de nueve meses de interrogatorio, fue sentenciada por un Colegio Militar de tres miembros del Tribunal Supremo de la URSS a 20 años de trabajos forzados. Finalmente fue liberada después de la muerte de Stalin en 1953 y en 1974 abandonó la Unión Soviética.

Los últimos proyectos de ópera de Prokófiev, entre ellos su desesperado intento de apaciguar a las autoridades culturales, "La historia de un hombre real", fueron cancelados rápidamente por el Teatro Kirov. El libreto de esta ópera era del compositor y Mira Mendelson, y se basa en la novela homónima de Boris Polevoy, que a su vez se basó en la historia del piloto Alexey Maresyev. El desaire, en combinación con su salud en declive, hizo que Prokófiev se retirara progresivamente de la vida pública y de diversas actividades, incluso su apreciado ajedrez, y se dedicó cada vez más a su propio trabajo. Después de una grave recaída en 1949, sus médicos le ordenaron limitar su composición a una hora por día.

En la primavera de 1949, escribió su "Sonata para violonchelo en C, op. 119", para Mstislav Rostropovich, de 22 años, quien dio la primera presentación en 1950, con Sviatoslav Richter. Para Rostropovich, Prokofiev también recompuso extensivamente su "Concierto para violonchelo", transformándolo en un Concierto sinfónico, su última gran obra maestra y un hito en el repertorio de violonchelo y orquesta de la actualidad. La última presentación pública a la que asistió fue el estreno de la "Séptima Sinfonía" en 1952, por la cual recibió el premio Stalin. La música fue escrita para la División de Radio para Niños.

Prokofiev murió a la edad de 61 años el 5 de marzo de 1953, el mismo día que Joseph Stalin, cuando acababan de comenzar los ensayos para su ballet "La flor de piedra" (1950), que fue puesto en escena el año siguiente. Había vivido cerca de la Plaza Roja, y durante tres días las multitudes se reunieron para llorar a Stalin, por lo que era imposible transportar el cuerpo de Prokófiev para el funeral en la sede de la Unión de Compositores Soviéticos. Está enterrado en el cementerio de Novodevichy en Moscú. Era ateo.

El principal periódico musical soviético reportó la muerte de Prokófiev con un breve artículo en la página 116. Las primeras 115 páginas se dedicaron a la muerte de Stalin. Por lo general, la muerte de Prokófiev se atribuye a una hemorragia cerebral. Había estado enfermo crónicamente durante los ocho años anteriores; la naturaleza precisa de la enfermedad terminal de Prokofiev sigue siendo incierta.

Lina Prokofiev sobrevivió a su marido distanciado por muchos años, muriendo en Londres a principios de 1989. Las regalías de la música de su difunto esposo le proporcionaron unos ingresos modestos, y actuó como narradora de una grabación de "Pedro y el lobo" de su marido (actualmente lanzada en CD por Chandos Records) con Neeme Järvi dirigiendo la Orquesta Nacional Escocesa. Sus hijos Sviatoslav (1924-2010), arquitecto, y Oleg (1928-1998), artista, pintor, escultor y poeta, dedicaron una gran parte de sus vidas a la promoción de la vida y el trabajo de sus padres.



</doc>
<doc id="28221" url="https://es.wikipedia.org/wiki?curid=28221" title="Enlace químico">
Enlace químico

Un enlace químico es el proceso químico responsable de las interacciones atractivas entre átomos y moléculas, y que confiere estabilidad a los compuestos químicos diatómicos y poliatómicos. La explicación de tales fuerzas atractivas es un área compleja que está descrita por las leyes de la "química cuántica".

Una definición más sencilla es que un enlace químico es la fuerza existente entre los átomos una vez que se ha formado un sistema estable.

Las moléculas, cristales, metales y gases diatómicos (que forman la mayor parte del ambiente físico que nos rodea) están unidos por enlaces químicos, que determinan las propiedades físicas y químicas de la materia.

Las cargas opuestas se atraen porque al estar unidas adquieren una situación más estable que cuando estaban separadas. Esta situación de mayor estabilidad suele darse cuando el número de electrones que poseen los átomos en su último nivel es igual a ocho, estructura que coincide con la de los gases nobles ya que los electrones que orbitan el núcleo están cargados negativamente, y que los protones en el núcleo lo están positivamente, la configuración más estable del núcleo y los electrones es una en la que los electrones pasan la mayor parte del tiempo "entre" los núcleos, que en otro lugar del espacio. Estos electrones hacen que los núcleos se atraigan mutuamente.

En la visión simplificada del denominado enlace covalente, uno o más electrones (frecuentemente un par de electrones) son llevados al espacio entre los dos núcleos atómicos. Ahí, los electrones negativamente cargados son atraídos a las cargas positivas de "ambos" núcleos, en vez de sólo su propio núcleo. Esto vence a la repulsión entre los dos núcleos positivamente cargados de los dos átomos, y esta atracción tan grande mantiene a los dos núcleos en una configuración de equilibrio relativamente fija, aunque aún vibrarán en la posición de equilibrio. En resumen, el enlace covalente involucra la compartición de electrones en los que los núcleos positivamente cargados de dos o más átomos atraen simultáneamente a los electrones negativamente cargados que están siendo compartidos. En un enlace covalente polar, uno o más electrones son compartidos inequitativamente entre dos núcleos.

En una visión simplificada de un enlace iónico, el electrón de enlace no es compartido, sino que es transferido. En este tipo de enlace, el orbital atómico más externo de un átomo tiene un lugar libre que permite la adición de uno o más electrones. Estos electrones recientemente agregados ocupan potencialmente un estado de menor energía (más cerca al núcleo debido a la alta carga nuclear efectiva) de lo que experimentan en un tipo diferente de átomo. En consecuencia, un núcleo ofrece una posición de más fuerte unión a un electrón de lo que lo hace el otro núcleo. Esta transferencia ocasiona que un átomo asuma una carga neta positiva, y que el otro asuma una carga neta negativa. Entonces, el "enlace" resulta de la atracción electrostática entre los átomos, y los átomos se constituyen en ((iones)) de carga positiva o negativa.

Todos los enlaces pueden ser explicados por la teoría cuántica, pero, en la práctica, algunas reglas de simplificación les permiten a los químicos predecir la fuerza de enlace, direccionalidad y polaridad de los enlaces. La regla del octeto y la (TREPEV) teoría de repulsión de pares de electrones de la capa de valencia son dos ejemplos.

Existen teorías más sofisticadas, como la teoría del enlace de valencia, que incluye la hibridación de orbitales y la resonancia, y el método de combinación lineal de orbitales atómicos dentro de la teoría de los orbitales moleculares, que incluye a la teoría del campo de los ligantes. La electrostática es usada para describir polaridades de enlace y los efectos que ejerce en las sustancias químicas.

Las primeras especulaciones respecto a la naturaleza del "enlace químico" son tan tempranas como en el siglo XII. Se suponía que ciertos tipos de especies químicas estaban unidas entre sí por un tipo de afinidad química. 

En 1704, Isaac Newton esbozó su teoría de enlace atómico, en "Query 31" de su "Opticks", donde los átomos se unen unos a otros por alguna "fuerza". Específicamente, después de investigar varias teorías populares, en boga en aquel tiempo, de cómo los átomos se podía unir unos a otros, por ejemplo, "átomos enganchados", "átomos pegados unos a otros por reposo", o "unidos por movimientos conspirantes", Newton señaló lo que inferiría posteriormente a partir de su cohesión que:

En 1819, a raíz de la invención de la pila voltaica, Jöns Jakob Berzelius desarrolló una teoría de combinación química, introduciendo indirectamente el carácter electropositivo y electronegativo de los átomos combinantes. A mediados del siglo XIX, Edward Frankland, F. A. Kekule, A. S. Couper, A. M. Butlerov y Hermann Kolbe, ampliando la teoría de radicales, desarrollaron la teoría de valencia, originalmente llamado "poder combinante" en que los compuestos se mantenía unidos debido a la atracción entre polos positivo y negativo. En 1916, el químico Gilbert N. Lewis desarrolló el concepto de enlace de par de electrones, en el que dos átomos pueden compartir uno y seis electrones, formando el enlace de un solo electrón, enlace simple, enlace doble, o enlace triple:

En las propias palabras de Lewis:

El mismo año, Walther Kossel lanzó una teoría similar a la de Lewis, con la diferencia de que su modelo asumía una transferencia completa de electrones entre los átomos, con lo que era un modelo de enlace iónico. Tanto Lewis y Kossel estructuraron sus modelos de enlace a partir de la regla de Abegg (1904).

En 1927, el físico danés Oyvind Burrau derivó la primera descripción cuántica matemáticamente completa de un enlace químico simple, el producido por un electrón en el ion de hidrógeno molecular (dihidrogenilio), H. Este trabajo mostró que la aproximación cuántica a los enlaces químicos podrían ser correctas fundamental y cualitativamente, pero los métodos matemáticos usados no podrían extenderse a moléculas que contuvieran más de un electrón. Una aproximación más práctica, aunque menos cuantitativa, fue publicada en el mismo año por Walter Heitler y Fritz London. El método de Heitler-London forma la base de lo que ahora se denomina teoría del enlace de valencia. En 1929, "sir" John Lennard-Jones introdujo el método de combinación lineal de orbitales atómicos (CLOA o dentro de la teoría de orbitales moleculares, sugiriendo también métodos para derivar las estructuras electrónicas de moléculas de F (flúor) y las moléculas de O (oxígeno), a partir de principios cuánticos básicos. Esta teoría de orbital molecular representó un enlace covalente como un orbital formado por combinación de los orbitales atómicos de la mecánica cuántica de Schrödinger que habían sido hipotetizados por los electrones en átomos solitarios. Las ecuaciones para los electrones de enlace en átomos multielectrónicos no podrían ser resueltos con perfección matemática (esto es, "analíticamente"), pero las aproximaciones para ellos aún producen muchas predicciones y resultados cualitativos buenos. Muchos cálculos cuantitativos en química cuántica moderna usan tanto las teorías de orbitales moleculares o de enlace de valencia como punto de partida, aunque una tercera aproximación, la teoría del funcional de la densidad, se ha estado haciendo más popular en años recientes.

En 1935, H. H. James y A. S. Coolidge llevaron a cabo un cálculo sobre la molécula de dihidrógeno que, a diferencia de todos los cálculos previos que usaban funciones sólo de la distancia de los electrones a partir del núcleo atómico, usó funciones que sólo adicionaban explícitamente la distancia entre los dos electrones. Con 13 parámetros ajustables, ellos obtienen el resultado muy cercano al resultado experimental para la energía de disociación de enlace. Posteriores extensiones usaron hasta 54 parámetros y producen gran concordancia con los experimentos. Este cálculo convenció a la comunidad científica que la teoría cuántica podría concordar con los experimentos. Sin embargo, esta aproximación no tiene relación física con la teoría de enlace de valencia y orbitales moleculares y es difícil de extender a moléculas más grandes.

En el año 1927, la teoría de enlace de valencia fue formulada, argumentando esencialmente que el enlace químico se forma cuando dos electrones de valencia, en sus respectivos orbitales atómicos, trabajan o funcionan para mantener los dos núcleos juntos, en virtud a los efectos de disminución de energía del sistema. En 1939, a partir de esta teoría, el químico Linus Pauling publicó lo que algunos consideran uno de las más importantes publicaciones en la historia de la química: "Sobre la naturaleza del enlace químico". En este documento, tomando en cuenta los trabajos de Lewis, la teoría del enlace de valencia (TEV) de Heitler y London, así como su propio trabajo preliminar, presentó seis reglas para el enlace de electrones compartidos, aunque las tres primeras ya eran conocidas genéricamente: 

Sus tres últimas reglas eran nuevas:

A partir de este artículo, Pauling publicaría en 1939 un libro de texto, "Sobre la Naturaleza del Enlace Químico', que vendría a ser llamado por algunos como la "biblia" de la química moderna. Este libro ayudó a los químicos experimentales a entender el impacto de la teoría cuántica sobre la química. Sin embargo, la edición posterior de 1939 falló en explicar adecuadamente los problemas que parecían ser mejor entendibles por la teoría de orbitales moleculares. El impacto de la teoría del enlace de valencia declinó durante la década de 1960 y 1970 a la par con el crecimiento en popularidad de la teoría de orbitales moleculares, que estaba siendo implementada en muchos programas de grandes ordenadores. A partir de la década de 1960, los problemas más difíciles de la implementación de la teoría del enlace de valencia en programas de computadoras habían sido mayormente resueltos y la teoría del enlace de valencia vio un resurgimiento.

La teoría de los orbitales moleculares (TOM) usa una combinación lineal de orbitales atómicos para formar orbitales moleculares, que abarcan la molécula entera. Estos orbitales son divididos frecuentemente en orbitales enlazantes, orbitales antienlazantes, y orbitales de no enlace. Un orbital molecular es simplemente un orbital de Schrödinger que incluye varios, pero frecuentemente sólo dos, núcleos. Si este orbital es del tipo en que los electrones tienen una mayor probabilidad de estar "entre" los núcleos que en cualquier otro lugar, el orbital será un orbital enlazante, y tenderá a mantener los núcleos cerca. Si los electrones tienden a estar presentes en un orbital molecular en que pasan la mayor parte del tiempo en cualquier lugar excepto entre los núcleos, el orbital funcionará como un orbital antienlazante, y realmente debilitará el enlace. Los electrones en orbitales no enlazantes tienden a estar en orbitales profundos (cerca a los orbitales atómicos) asociados casi enteramente o con un núcleo o con otro y entonces pasarán igual tiempo entre los núcleos y no en ese espacio. Estos electrones no contribuyen ni detractan la fuerza del enlace.

En algunos aspectos, la teoría del enlace de valencia es superior a la teoría de orbitales moleculares. Cuando se aplica a la molécula más simple de dos electrones, H, la teoría del enlace de valencia, incluso al nivel más simple de la aproximación de Heitler-London, produce una aproximación más cercana a la energía de enlace, y provee una representación más exacta del comportamiento de los electrones al formarse y romperse los enlaces químicos. En contraste, la teoría de orbitales moleculares simple predice que la molécula de hidrógeno se disocia en una superposición lineal de átomos de hidrógeno, e iones positivos y negativos de hidrógeno, un resultado completamente contrario a la evidencia física. Esto explica en parte por qué la curva de energía total versus la distancia interatómica del método de orbitales de valencia yace por encima de la curva del método de orbitales moleculares a todas las distancias y, más particularmente, para distancias mucho más grandes. Esta situación surge para todas las moléculas diatómicas homonucleares y es particularmente un problema para el F, para el que la energía mínima de la curva con la teoría de orbitales moleculares es aún mayor en energía que la energía de los dos átomos de flúor no enlazados.

Los conceptos de hibridación son versátiles, y la variabilidad en el enlace en muchos compuestos orgánicos es tan modesta que la teoría del enlace permanece como una parte integral del vocabulario del químico orgánico. Sin embargo, el trabajo de Friedrich Hund, Robert Mulliken, y Gerhard Herzberg mostró que la teoría de orbitales moleculares provee una descripción más apropiada de las propiedades espectroscópicas, magnéticas y de ionización de las moléculas. Las deficiencias de la teoría del enlace se hicieron aparentes cuando las moléculas hipervalentes (por ejemplo, el PF) fueron explicadas sin el uso de los orbitales "d" que eran cruciales en el esquema de enlace basado en hibridación, propuesto para tales moléculas por Pauling. Los complejos metálicos y compuestos deficientes en electrones (como el diborano) también resultaron ser mejor descritos por la teoría de orbitales moleculares, aunque también se han hecho descripciones usando la teoría del enlace de valencia.

En la década de 1930, los dos métodos competían fuertemente hasta que se observó que ambas eran aproximaciones a una teoría mejor. Si se toma la estructura de enlace de valencia simple y se mezcla en todas las estructuras covalentes e iónicas posibles que surgen de un juego particular de orbitales atómicos, se llega a lo que se llama la función de onda de interacción de configuración completa. Si se toma la descripción de orbital molecular simple del estado fundamental y se combina dicha función con las funciones que describen todos los estados excitados posibles usando los orbitales no ocupados que surgen del mismo juego de orbitales atómicos, también se llega a la función de onda de interacción de configuración completa. Puede verse que la aproximación de orbital molecular simple da demasiado peso a las estructuras iónicas, mientras que la aproximación de enlace de valencia simple le da demasiado poco. Esto puede ser descrito diciendo que la aproximación de orbitales moleculares simple es demasiado "deslocalizada", mientras que la aproximación de enlaces de valencia es demasiado "localizado".

Estas dos aproximaciones son ahora observadas como complementarias, cada una proveyendo sus propias perspectivas en el problema del enlace químico. Los cálculos modernos en química cuántica generalmente empiezan a partir de (pero finalmente van más allá) un orbital molecular en vez de una aproximación de enlace de valencia, no por algún tipo de superioridad intrínseca de la primera, sino porque la aproximación de orbitales moleculares es mucho más rápidamente adaptable a computación numérica. Sin embargo, ahora hay mejores programas de enlace de valencia disponibles.

La tridimensionalidad de los átomos y moléculas hace difícil el uso de una sola técnica para indicar los orbitales y enlaces. En la fórmula química, los enlaces químicos (orbitales enlazantes) entre átomos están indicados por varios métodos diferentes de acuerdo al tipo de discusión. Algunas veces, se desprecian completamente. Por ejemplo, en química orgánica, la fórmula molecular del etanol (un compuesto en bebidas alcohólicas) puede ser escrito en papel como isómeros conformacionales, tridimensional, completamente bidimensional (indicando cada enlace con direcciones no tridimensionales), bidimensional comprimida (CH–CH–OH), separando el grupo funcional del resto de la molécula (CHOH), o sus constituyentes atómicos (CHO), de acuerdo a lo que se esté discutiendo. Algunas veces, incluso se marcan los electrones no enlazantes de la capa de valencia (con las direcciones aproximadas bidimensionalmente, estructura de Lewis). Algunos químicos pueden también representar los orbitales respectivos.

Estos enlaces químicos son fuerzas "intramoleculares", que mantienen a los átomos unidos en las moléculas. En la visión simplista del enlace localizado, el número de electrones que participan en un enlace (o están localizados en un orbital enlazante), es típicamente un número par de dos, cuatro, o seis, respectivamente. Los números pares son comunes porque las moléculas suelen tener estados energéticos más bajos si los electrones están apareados. Teorías de enlace sustancialmente más avanzadas han mostrado que la fuerza de enlace no es siempre un número entero, dependiendo de la distribución de los electrones a cada átomo involucrado en un enlace. Por ejemplo, los átomos de carbono en el benceno están conectados a los vecinos inmediatos con una fuerza aproximada de 1.5, y los dos átomos en el óxido nítrico no están conectados con aproximadamente 2.5. El enlace cuádruple también son bien conocidos. El tipo de enlace fuerte depende de la diferencia en electronegatividad y la distribución de los orbitales electrónicos disponibles a los átomos que se enlazan. A mayor diferencia en electronegatividad, con mayor fuerza será un electrón atraído a un átomo particular involucrado en el enlace, y más propiedades "iónicas" tendrá el enlace ("iónico" significa que los electrones del enlace están compartidos inequitativamente), estos enlaces son frecuentes entre átomos que se ubican a la izquierda de la tabla periódica (baja electronegatividad) y átomos que se encuentran a la derecha de la tabla periódica (más electronegativos), porque permite la transferencia de electrones de valencia produciendo iones. A menor diferencia de electronegatividad, mayores propiedades covalentes (compartición completa) del enlace, generalmente entre átomos vecinos de la tablas periódica.

Los átomos enlazados de esta forma tienen carga eléctrica neutra, por lo que el enlace se puede llamar no polar.

Ejemplo:


Los enlaces covalentes pueden ser simples (H - H) cuando se comparte un solo par de electrones, dobles (O = O) al compartir dos pares de electrones, triples cuando comparten tres tipos de electrones, o cuádruples cuando comparten cuatro tipos de electrones.

Los enlaces covalentes no polares se forman entre átomos iguales, no hay variación en el número de oxidación.
Los enlaces covalentes polares se forman con átomos distintos con gran diferencia de electronegatividades. La molécula es eléctricamente neutra, pero no existe simetría entre las cargas eléctricas originando la polaridad, un extremo se caracteriza por ser electropositivo y el otro electronegativo.

El enlace covalente polar es intermediado en su carácter entre un enlace covalente y un enlace iónico. Los enlaces covalentes polares se forman con átomos distintos con gran diferencia de electronegatividades. La molécula es eléctricamente neutra, pero no existe simetría entre las cargas eléctricas originando la polaridad, un extremo se caracteriza por ser electropositivo y el otro electronegativo.

Los enlaces covalentes pueden ser simples cuando se comparte un solo par de electrones, dobles al compartir dos pares de electrones, triples cuando comparten tres pares de electrones, o cuádruples cuando comparten cuatro pares de electrones.

Los enlaces covalentes no polares (0 o menor que 0,4) se forman entre átomos iguales, no hay variación en el número de oxidación. Los átomos enlazados de esta forma tienen carga eléctrica neutra.

En otras palabras, el enlace covalente es la unión entre átomos en donde se da un compartimiento de electrones, los átomos que forman este tipo de enlace son de carácter no metálico. Las moléculas que se forman con átomos iguales (mononucleares) presentan un enlace covalente pero en donde la diferencia de electronegatividades es nula.

Se presenta entre los elementos con poca diferencia de electronegatividad (< 1.7), es decir cercanos en la tabla periódica de los elementos químicos o bien, entre el mismo elemento para formar moléculas diatómicas.

El enlace iónico es un tipo de interacción electrostática entre átomos que tienen una gran diferencia de electronegatividad. No hay un valor preciso que distinga la ionicidad a partir de la diferencia de electronegatividad, pero una diferencia sobre 2.0 suele ser iónica, y una diferencia menor a 1.7 suele ser covalente. En pocas palabras, un enlace iónico es aquel en el que los elementos involucrados aceptan o pierden electrones (se da entre un catión y un anión) o dicho de otra manera, es aquel en el que un elemento que tiene más el electronegatividad se atrae con los electrones con menos electronegatividad. El enlace iónico implica la separación en iones positivos y negativos. Las cargas iónicas suelen estar entre –3e a +3e, este tipo de enlace es frecuente entre átomos de los grupos IA, IIA, IIIA que pierden electrones (Cationes) y átomos de los grupos VA, VIA, VIIA que ganan electrones (aniones).

Ejemplo:

La unión entre el sodio y el cloro, es un enlace iónico donde el sodio pierde 1 electron del último nivel de energía (3s) y el cloro gana ese electrón, completando 8 electrones en el último nivel de energía.

Na = formula_4 pierde un electrón formula_5 (catión)

Cl = formula_6 gana un electrón formula_7 (anión)

El enlace covalente coordinado, algunas veces referido como enlace dativo, es un tipo de enlace covalente, en el que los electrones de enlace se originan sólo en uno de los átomos, el donante de pares de electrones, o base de Lewis, pero son compartidos aproximadamente por igual en la formación del enlace covalente. Este concepto está cayendo en desuso a medida que los químicos se pliegan a la teoría de orbitales moleculares. Algunos ejemplos de enlace covalente coordinado existen en nitronas y el borazano. El arreglo resultante es diferente de un enlace iónico en que la diferencia de electronegatividad es pequeña, resultando en una covalencia. Se suelen representar por flechas, para diferenciarlos de otros enlaces. La flecha muestra su cabeza dirigida al aceptor de electrones o ácido de Lewis, y la cola a la base de Lewis. Este tipo de enlace se ve en el ion amonio y en los complejos químicos, donde un átomo central (por lo general un catión metálico) está unido a otras moléculas denominadas ligandos.

Los enlaces con uno o tres electrones pueden encontrarse en especies radicales, que tienen un número impar de electrones. El ejemplo más simple de un enlace de un electrón se encuentra en el catión hidrógeno molecular, H. Los enlaces de un electrón suelen tener la mitad de energía de enlace, de un enlace de 2 electrones, y en consecuencia se les llama "medios enlaces". Sin embargo, hay excepciones: en el caso del dilitio, el enlace es realmente más fuerte para el Li de un electrón, que para el Li de dos electrones. Esta excepción puede ser explicada en términos de hibridación y efectos de capas internas.

El ejemplo más simple de enlace de tres electrones puede encontrarse en el catión de helio dimérico, He, y puede ser considerado también medio enlace porque, en términos de orbitales moleculares, el tercer electrón está en un orbital antienlazante que cancela la mitad del enlace formado por los otros dos electrones. Otro ejemplo de una molécula conteniendo un enlace de tres electrones, además de enlaces de dos electrones, es el óxido nítrico, NO. La molécula de oxígeno, O, también puede ser vista como si tuviera dos enlaces de 3-electrones y un enlace de 2-electrones, lo que justifica su paramagnetismo y su orden formal de enlace de 2.

Las moléculas con número impar de electrones suelen ser altamente reactivas. Este tipo de enlace sólo es estable entre átomos con electronegatividades similares.

Los enlaces flexionados, también conocidos como enlaces banana, son enlaces en moléculas tensionadas o impedidas estéricamente cuyos orbitales de enlaces están forzados en una forma como de banana. Los enlaces flexionados son más susceptibles a las reacciones que los enlaces ordinarios.
El enlace flexionado es un tipo de enlace covalente cuya disposición geométrica tiene cierta semejanza con la forma de una banana. doble enlace entre carbonos se forma gracias al traslape de dos orbitales híbridos sp3. Como estos orbitales no se encuentran exactamente uno frente a otro, al hibridarse adquieren la forma de banana.

En el enlace de tres centros y dos electrones ("3c-2e"), tres átomos comparten dos electrones en un enlace. Este tipo de enlace se presenta en compuestos deficientes en electrones, como el diborano. Cada enlace de ellos (2 por molécula en el diborano) contiene un par de electrones que conecta a los átomos de boro entre sí, con un átomo de hidrógeno en el medio del enlace, compartiendo los electrones con los átomos de boro.

El enlace de tres centros y cuatro electrones ("3c-4e") explica el enlace en moléculas hipervalentes. En ciertos compuestos aglomerados, se ha postulado la existencia de enlaces de cuatro centros y dos electrones.

En ciertos sistemas conjugados π (pi), como el benceno y otros compuestos aromáticos, y en redes conjugadas sólidas como el grafito, los electrones en el sistema conjugado de enlaces π están dispersos sobre tantos centros nucleares como existan en la molécula o la red.

En muchos casos, la ubicación de los electrones no puede ser simplificada a simples líneas (lugar para dos electrones) o puntos (un solo electrón). En compuestos aromáticos, los enlaces que están en anillos planos de átomos, la regla de Hückel determina si el anillo de la molécula mostrará estabilidad adicional.

En el benceno, el compuesto aromático prototípico, 18 electrones de enlace mantiene unidos a 6 átomos de carbono para formar una estructura de anillo plano. El orden de enlace entre los diferentes átomos de carbono resulta ser idéntico en todos los casos desde el punto de vista químico, con una valor equivalente de aproximadamente 1.5.

En el caso de los aromáticos heterocíclicos y bencenos sustituidos, las diferencias de electronegatividad entre las diferentes partes del anillo pueden dominar sobre el comportamiento químico de los enlaces aromáticos del anillo, que de otra formar sería equivalente.

En un enlace metálico, los electrones de enlace se encuentran situados en una estructura de átomos. En contraste, en los compuestos iónicos, la ubicación de los electrones enlazantes y sus cargas son estáticas. Debido a la deslocalización o el libre movimiento de los electrones, se tienen las propiedades metálicas de conductividad, ductilidad y dureza.
El enlace metálico es similar al ionico; sin embargo, el primero es mas compacto que el segundo, ya que el numero de átomos que rodean a cada uno de ellos es mayor.

Hay cuatro tipos básicos de enlaces que se pueden formar entre dos o más moléculas, iones o átomos que de otro modo no estarían asociados. Las fuerzas intermoleculares originan que las moléculas se atraigan o repelan unas a otras. Frecuentemente, esto define algunas de sus características físicas (como el punto de fusión) de una sustancia.

Una gran diferencia de electronegatividad entre dos átomos enlazados fuertemente en una molécula ocasiona la formación de un dipolo (un par positivo-negativo de cargas eléctricas parciales permanentes). Los dipolos se atraen o repelen unos a otros.

En alguna forma este es un ejemplo de un dipolo permanente especialmente fuerte. Sin embargo, en el enlace de hidrógeno, el átomo de hidrógeno está más cerca a ser compartido entre los átomos donante y el receptor, en un enlace 3-c 2-e. Los enlaces de hidrógeno explican el punto de ebullición relativamente alto de los líquidos como el agua, amoníaco, y fluoruro de hidrógeno, comparado con sus contrapartes más pesadas en el mismo grupo de la tabla periódica.

Los dipolos instantáneos a dipolo inducido, o fuerzas de London, son las interacciones más débiles, pero también las más ubicuas, entre todas las sustancias químicas. Imagine el átomo de helio: en cualquier instante, la nube electrónica alrededor del átomo (que, de otro modo sería neutral) puede estar ligeramente desbalanceada, con momentáneamente más carga negativa en un lado que en el otro. Esto es a lo que se refiere como un dipolo instantáneo. Este dipolo, con su carga ligeramente desbalanceada, puede atraer o repeler a los electrones en los átomos de helio vecinos, estableciendo otro dipolo (dipolo inducido). Los dos átomos se estarán atrayendo por un instante, antes que la carga se rebalancee y los átomos se muevan.

La interacción catión-pi se presenta entre la carga negativa localizada de los electrones de un orbital pi, ubicados sobre y debajo del plano de un anillo aromático, y una carga positiva.

En el límite (irrealístico) del enlace iónico puro, los electrones están perfectamente localizados en uno de los dos átomos en el enlace. Tales enlaces pueden ser interpretados por la física clásica. Las fuerzas entre los átomos están caracterizadas por potenciales electrostáticos continuos isótropos. Su magnitud es una proporción simple a la diferencia de cargas.

Los enlaces covalentes se entiende mejor por la teoría del enlace de valencia o la teoría del orbital molecular. Las propiedades de los átomos involucrados pueden ser interpretadas usando conceptos tales como número de oxidación. La densidad electrónica en el enlace no está asignada a átomos individuales, en vez de ello está deslocalizada entre los átomos. En la teoría del enlace de valencia, los dos electrones en los dos átomos se emparejan con una fuerza de enlace que depende del traslape entre los orbitales. En la teoría del orbital molecular, la combinación lineal de orbitales atómicos (CLOA) ayuda a describir las estructuras de orbitales moleculares deslocalizados y las energías basadas en los orbitales atómicos de los átomos de los que proviene. A diferencia de los enlaces iónicos puros, los enlaces covalentes pueden tener propiedades de direccionalidad (anisotropía). Estas pueden tener sus propios nombres, como sigma y pi.

En el caso general, los átomos forman enlaces que son intermedios entre iónico y covalente, dependiendo de la electronegatividad relativa de los átomos involucrados. Este tipo de enlace es llamado algunas veces enlace covalente polar.

En 1985, los químicos de la Universidad de Rice en Texas, Robert F. Curl y Richard E. Smalley, y uno de la Universidad de Sussex, Harold Kroto utilizaron un láser de alta potencia para vaporizar grafito en un esfuerzo por crear moléculas poco comunes, que se creía existían en el espacio interestelar. La espectrometría de las masas reveló que uno de los productos resultó ser una especie desconocida con la fórmula (C). Debido a su tamaño y al hecho de que es carbono puro, esta molécula tiene una forma extraña en la que trabajaron varios investigadores utilizando papel, tijeras y cinta adhesiva. Posteriormente, mediciones espectroscópicas y de rayos X confirmaron que el (C) tenían la forma similar a una esfera hueca con un átomo de carbono localizado en cada uno de sus 60 vértices. Geométricamente, el buckybalón (abreviatura de "buckminsterfulerene") es la molécula más simétrica que se conoce. Sin embargo, a pesar de sus características peculiares, su esquema de enlace es simple. Cada carbono tiene una hibridación sp2, y tiene orbitales moleculares deslocalizados que se extienden sobre la estructura completa. El buckybalón, así como otros miembros de mayor peso representan un concepto completamente nuevo en la arquitectura molecular con implicaciones de largo alcance. Por ejemplo, se ha preparado con un átomo de helio dentro de su estructura. Por el descubrimiento del buckybalón los tres científicos fueron premiados con el premio Nobel de química 1996. 

Un descubrimiento fascinante, realizado en 1991 por científicos japoneses, fue la identificación de estructuras relacionadas con el buckybalón. Estas moléculas tienen una longitud de cientos de nanómetros y presentan una forma tubular con una cavidad interna aproximada de 15 nanómetros de diámetro.




</doc>
<doc id="28226" url="https://es.wikipedia.org/wiki?curid=28226" title="Complejo (química)">
Complejo (química)

En química se denomina complejo a una entidad que se encuentra formada por una asociación que involucra a dos o más componentes unidos por un tipo de enlace químico, el "enlace de coordinación", que normalmente es un poco más débil que un enlace covalente típico.

Por una costumbre histórica el término complejo se utiliza principalmente para describir a aquel tipo de estructura molecular que usualmente se encuentra formada por un átomo central (el cual es con frecuencia un catión metálico) que se encuentra enlazado a otras entidades moleculares que lo rodean llamadas ligandos. Esta última acepción también se conoce como entidad de coordinación.

El término también es utilizado para referirse a una enorme cantidad de estructuras inestables o metaestables que participan como intermediarias en diferentes reacciones; por lo cual es preferible utilizar siempre que se pueda un término más explicativo para referirse a estos compuestos. En este sentido el término complejo es mucho más amplio, pero menos preciso. En química inorgánica, por ejemplo, se prefiere utilizar el término "entidad de coordinación" en lugar de complejo.

La química de los complejos tiene numerosas aplicaciones tanto teóricas como prácticas sirviendo por ejemplo: para explicar detalles tan comunes como el color de las piedras preciosas; la elaboración industrial de polímeros, pigmentos, vidrios incoloros y de colores; electrodepósito de metales; formulación de ablandadores de agua para productos de limpieza hogareños y hasta el tratamiento de algunas intoxicaciones y la base teórica que permite comprender la mayoría de las reacciones enzimáticas que permiten la existencia de la vida.

Los complejos más sencillos responden a un tipo de estructura molecular que se encuentra generalmente formada por un grupo central (generalmente un catión) llamado núcleo de coordinación que posee orbitales de valencia no ocupados, rodeado por un cierto número de moléculas o iones que poseen pares de electrones no compartidos. Estos electrones no compartidos pueden ser inyectados en los orbitales vacíos del grupo central para formar enlaces coordinados.

Aunque en general el grupo central es un catión también puede ser un átomo neutro, por ejemplo un átomo de gas noble, o una molécula y puede poseer carga positiva, negativa o carecer por completo de carga.

A los iones o moléculas que participan de la estructura molecular inyectando su par de electrones no compartidos se les denomina genéricamente ligandos.

Al aducto formado por el grupo central y los ligandos se le denomina entidad de coordinación y a los compuestos que contienen entidades de coordinación en su constitución se les denomina compuestos de coordinación.

Un ligando enlazado a un átomo central se dice que está coordinado a ese átomo. El número de pares de electrones que es capaz de aceptar el grupo central se denomina número de coordinación.

Los átomos de los elementos metálicos tienen una clara tendencia a perder electrones para convertirse en iones con carga positiva (cationes), esto es así porque en general poseen un radio atómico elevado en relación a la carga de sus núcleos, lo que posibilita que sus electrones de valencia se desprendan con mucha facilidad. (Al ser los electrones de valencia los que se encuentran a mayor distancia del núcleo, son los que menos atracción electrostática experimentan y por lo tanto son los que se desprenden con mayor facilidad.)

Esto puede conducir a la idea de que los iones metálicos con carga positiva (cationes) deberían ser muy abundantes en la naturaleza. Sin embargo los cationes metálicos rara vez se encuentran en estado libre en la naturaleza, esto es así porque al perder uno o más electrones su radio disminuye y su carga eléctrica aumenta. Un aumento en la relación carga/radio significa una disminución de la estabilidad termodinámica de una especie química.

En general los cationes metálicos poseen una relación carga/radio tan elevada que rápidamente interactúan con otros iones, átomos o moléculas, para adquirir una estructura que resulte termodinámicamente más estable. A esta estabilización la consiguen ya sea interactuando con moléculas neutras, lo que provoca un aumento del radio molecular y una consiguiente disminución de la relación carga/radio; o con iones de con carga negativa (aniones) los que además de provocar un aumento en el radio molecular brindan una estabilidad adicional al “aliviar” al catión aportando cargas negativas.

Es común que en estas asociaciones, las moléculas o iones que otorgan estabilidad al catión central actúen como bases de Lewis, es decir, que al poseer uno o más pares de electrones no compartidos sean capaces de "inyectar" esos electrones en orbitales vacíos del catión para aumentar su estabilidad.

Los cationes metálicos casi siempre se encuentran en la naturaleza formando algún tipo de complejo que los estabiliza; con mucha frecuencia el agente acomplejante suele ser el solvente donde se encuentran disueltos.

Una buena parte de las sales metálicas de los metales de los grupos principales y de transición se encuentran hidratadas. Las aguas de hidratación actúan como ligandos que rodean al metal, enlazándose a través de un par electrónico no compartido del agua. Un ejemplo notable de esto son las sales de cobalto que se utilizan para "predecir el tiempo" en algunos juegos infantiles, en estas el cobalto se encuentra coordinado por un número de moléculas de agua que cambia con la humedad ambiental, el cambio en la coordinación del cobalto provoca un cambio en el color de la sal, de azul a rosado al aumentar la humedad y a la inversa.

La mayor parte de la química de complejos conocida trata de complejos formados por entidades de coordinación con núcleos de coordinación que son cationes metálicos, sin embargo debe quedar claro que también existen complejos en los cuales estos núcleos de coordinación son átomos no metálicos, o participan con carga cero, o se trata de moléculas en lugar de átomos. Incluso hasta hay algunos en los cuales el núcleo tiene carga negativa.

Con el constante avance que tuvo la química en sus comienzos como ciencia exacta, pronto se sintetizaron una serie de nuevos compuestos que resultaron muy llamativos, especialmente por sus colores. Estos compuestos químicos, a falta de una descripción más adecuada, tomaron los nombres de sus creadores. Así se dieron a conocer por ejemplo la sal de Magnus (2·2) o la sal de Erdmann (··2). Otro de estos vistosos compuestos fue el azul de Prusia, también conocido como Berliner Blau o azul de Berlín, (KCN··) producido por Diesbach en Berlín a comienzos del siglo XVIII. Muchos de los primeros complejos fueron utilizados como pigmentos por los pintores de la época. 

Estos compuestos presentaban dos notables propiedades que los diferenciaban de los conocidos hasta el momento: Primero los brillantes cambios de color asociados a su formación, y segundo la reactividad alterada de los iones que participaban. 

Hasta mediados del siglo XIX los químicos no comenzaron a interesarse por la verdadera naturaleza de su constitución y por su relación con otros compuestos más sencillos.

Al principio se encontró, como se puede notar en las fórmulas arriba expresadas, que estos compuestos parecían estar formados por la asociación de otros compuestos más sencillos. Esto llevó a identificarlos como "compuestos moleculares", para diferenciarlos de los "compuestos atómicos" más simples; y por último, se les dio el nombre de COMPLEJOS, para diferenciarlos de los compuestos simples. A decir verdad, éste era un nombre acertado para la época, pues era difícil encontrarles una estructura valedera que pudiera explicar todas sus propiedades. A la par de ello el número de complejos conocidos aumentaba a medida que progresaba su estudio.

El desarrollo de modelos que permitieran explicar su naturaleza, tuvo que esperar la aparición de teorías y modelos válidos para compuestos más sencillos. Los pasos fundamentales en este sentido fueron en primer lugar, la definición de lo que se consideraba un compuesto "verdadero", más conocida como Ley de las proporciones definidas, propuesta por J.L. Proust en 1799, la cual establece que: «"un compuesto determinado siempre estará constituido por las mismas proporciones de sus elementos constituyentes"». En otras palabras lo que hoy conocemos como "estequiometría definida". Esta primera definición fue trascendental para separar unos compuestos de otros, especialmente en el caso de los complejos. 

Luego, en 1827, J.J. Berzelius introdujo el concepto de isomería, el cual complementa la definición anterior pero introduce una pregunta clave: ¿cómo se unen entre sí los átomos? Para encontrar una respuesta a esta pregunta fue definitiva la teoría de los tipos, propuesta por Ch. Gerhardt (hacia el año 1853), desarrollada para el amoníaco por Ch. A. Wurtz en 1849 y ampliada y trabajada por A. W. Von Hofmann (), hoy conocida como "Teoría del amonio"; esta teoría fue una primera aproximación para explicar cómo estaban unidos los átomos en los abundantes "complejos" que contenían amoníaco. 

Simultáneamente, se desarrolla la "Teoría de la Fuerza de Combinación" o "Teoría de la atomicidad" (una primera aproximación al actual concepto de valencia, propuesta por E. Frankland en 1852 como una extensión de la ley de las proporciones definidas; esta teoría establece que «"cada elemento sólo se puede unir a un número fijo de otros elementos"». Así, se podía asegurar que la atomicidad del cinc siempre era dos y la del nitrógeno o la del fósforo era 3 o 5.
F.A. Kekulé en 1858, propone la noción de que muchos compuestos orgánicos tenían que ser producto de la unión entre sí de átomos de carbono en forma de cadenas. Además de lo conocido con anterioridad, esta noción influyó necesariamente en un segundo modelo desarrollado en 1869 y sustentado con éxito durante varias décadas por los escandinavos Blomstrand, profesor de Química en Lund (Suecia) y su alumno Jörgensen, quien fuera más tarde profesor en la Universidad de Copenhague y uno de los experimentadores más sobresalientes de la química de la coordinación. Sin embargo el mismo Jörgensen habría de sintetizar el compuesto que definiría la validez de su teoría, concluyendo al final que su modelo, conocido como teoría de las cadenas, era incorrecto.
El reconocimiento de la verdadera naturaleza de los "complejos", se inicia con Alfred Werner (1866-1919) profesor de Química en Zurich, quien demostró que las moléculas neutras que participaban en la formación de un complejo (entidad de coordinación) estaban directamente enlazadas al metal, de manera tal que las sales complejas como el ·6 debían ser formuladas correctamente como . También demostró que se originaban profundas consecuencias estereoquímicas si se hacía la suposición de que las moléculas o iones (ligandos) alrededor del metal ocupaban posiciones en los vértices de un cuadrado o de un octaedro.

Alfred Werner, propuso que los átomos podían exhibir simultáneamente más de un tipo de valencia. La primera parte de su teoría de la coordinación, publicada en 1893, puede resumirse en los siguientes tres postulados:

Estos tres postulados daban una explicación satisfactoria a las principales preguntas que se venían planteando los químicos con respecto a los "complejos". Tomando como ejemplo para la aplicación de los postulados la bien conocida serie de las aminas ·6, ·5, ·4, ·3, se tiene que la valencia primaria o estado de oxidación del cobalto en todos los casos es 3+, y la valencia secundaria o número de coordinación de este ion es 6. El estado de oxidación 3+ del cobalto está compensado, como se ve claramente en todos los casos, por 3 iones cloruro. En el primer ejemplo todos los cloruros son iónicos y no forman parte del catión complejo ; el número de coordinación 6 está satisfecho por 6 grupos . En el segundo ejemplo, el número de coordinación está satisfecho por 5 y 1 , y únicamente dos cloruros son iónicos. En el tercer caso, 4 y 2 satisfacen el número de coordinación y en el último caso lo satisfacen 3 y 3 , .

El tercer postulado llevó a Werner a afirmar que la presencia de isomería óptica para complejos del tipo (Donde AA es un ligando bidentado) era evidencia de una estructura octaédrica y que esta isomería era debida a la asimetría de la molécula; algunos químicos orgánicos trataron de refutar su hipótesis aduciendo que la actividad óptica se debía a la presencia de átomos de carbono en la estructura y que esta propiedad era exclusivamente debida al carbono. Esta controversia llevó a Werner y su grupo en 1914 a sintetizar el más extraordinario complejo de la época, el hexol (), que no contenía carbono en su estructura.
El hexol presentó, como hoy es obvio, isomería óptica, consolidando la teoría de la coordinación, y además mostrando que esta isomería es una función de las operaciones de simetría de las moléculas en general y no específica de un único tipo de átomo. 

La conclusión de Werner sentó uno de los argumentos de mayor peso para considerar a la química como una sola, con normas generales, y derrumbar murallas impuestas artificialmente entre la química orgánica y la inorgánica.

Werner obtuvo el Premio Nobel en 1913 por el desarrollo de su teoría de la coordinación. En sus conceptos fundamentales, esta teoría continúa vigente ya que permite explicar correctamente muchos de los aspectos estructurales de los compuestos de coordinación.

Los estudios estereoquímicos de Werner fueron seguidos más tarde por las ideas de G. N. Lewis y N. V. Sidgwick, quienes propusieron que eran los electrones de la última órbita de un átomo los responsables de los enlaces químicos y que «"un enlace químico requería compartir un par de electrones"» de manera tal que quedara cumplida la condición de que cada átomo participante en el enlace obtuviera al final ocho electrones en su capa más externa (Regla del octeto).

Con respecto a los compuestos de coordinación, Lewis postuló que: «"los grupos que están unidos al ion metálico, conformando la entidad de coordinación, poseen pares libres de electrones, es decir, que no están compartidos en un enlace"» y definió el número de coordinación como «"el número real de pares de electrones que están unidos al átomo metálico"».

En otro aspecto de su teoría, Lewis propuso una definición más general para ácidos y bases, en la cual una base es aquella que tiene un par libre de electrones que puede donar a otro átomo, mientras que un ácido es la sustancia que puede aceptar un par libre de electrones para formar un enlace. En este sentido, el ion metálico en un complejo es un ácido de Lewis y los grupos que están unidos a este ion en la entidad de coordinación son bases de Lewis. 

Lewis propuso su modelo en 1916 y Sidgwick lo amplió hacia 1927, y resultó una verdadera revolución en la química porque permitió explicar de manera sencilla la naturaleza del enlace químico en compuestos sumamente diversos, llegando por ejemplo a considerar bajo esta óptica, a toda la química de complejos como simples reacciones ácido-base.

EL modelo de Lewis fue posteriormente ampliado y completado por la Teoría del Enlace de Valencia (TEV) y la Teoría de Orbitales Moleculares (TOM) que nos permiten actualmente interpretar la gran mayoría de las reacciones y propiedades de los complejos.

Normalmente los ligandos son nucleófilos, aniones, moléculas polares o fácilmente polarizables que poseen al menos un par de electrones de valencia no compartidos, tales como , , , , etc. 
Esto induce en un principio a tratar de explicar de manera sencilla las atracciones que se establecen entre ligandos y cationes como de naturaleza electrostática: el par de electrones del ligando es intensamente atraído por la alta carga del catión, forzando a la molécula o anión que lo posee a acercarse.

Sin embargo este enfoque no permite explicar cómo se forman los complejos con grupos centrales neutros o con carga negativa.

Una mejor aproximación es considerar a la unión grupo central-ligando como un tipo particular de aducto de Lewis en el cual participan los electrones del par electrónico no compartido del ligando y los orbitales vacíos (ya sean atómicos o moleculares) del grupo central. En este enlace el ligando aporta un par de electrones de valencia no compartidos (base de Lewis), y el grupo central los acepta (ácido de Lewis) para formar uno de los enlaces covalentes del complejo.

La unión que se establece entre grupo central y ligando es por tanto de tipo covalente.

Este tipo de unión covalente en el cual uno de los átomos aporta los dos electrones del enlace, recibe el nombre de enlace covalente coordinado.

Con base en este modelo, algunos autores hacen una diferencia entre el enlace covalente propiamente dicho, en donde se supone que cada átomo comprometido aporta un electrón para formar el enlace por par electrónico, y el enlace de coordinación, en donde se propone que sólo uno de los átomos comprometidos en el enlace aporta el par de electrones. Si bien esta diferenciación ayuda a entender el origen del enlace, una vez formado el compuesto de coordinación ya no tiene sentido, puesto que los enlaces son equivalentes. 
El ejemplo más sencillo para ilustrar lo anterior es el del y el - o mejor , en el que se podría pensar que este último enlace es diferente por ser coordinado y en algunos textos hasta se llega a representar como →; sin embargo, el ion es un tetraedro regular, en el que cada uno los cuatro enlaces es equivalente a los otros y por lo tanto, imposible de diferenciar. 

La facilidad con la cual se forma este enlace covalente es explicada de manera sencilla por la capacidad del grupo central para deformar la nube de electrones del ligando, esta capacidad es tanto mayor cuanto mayor es la relación carga/radio del mismo.

Esto permite deducir por qué los cationes, y en especial aquellos con mayor carga y menor tamaño son los que forman complejos con mayor facilidad.

Esta última regla tiene, sin embargo, algunas desviaciones: por ejemplo el cromo que tiene un radio iónico de 0.62 Å forma complejos con mayor facilidad que el aluminio , que posee un radio iónico de 0.45 Å. En estos casos cabe considerar el impedimento que poseen determinados aniones o moléculas de gran tamaño para acercarse lo suficiente como para formar el enlace con los orbitales vacíos del grupo central.

La posibilidad de que se forme un enlace entre ligando y grupo central se encuentra condicionada en primer lugar por la existencia o no de orbitales vacíos en el grupo central, y en segundo lugar por la interferencia espacial que se ocasionan entre si las mismas moléculas de ligando al al tratar de acceder a las posiciones donde seria posible que se forme el enlace; esto se conoce como impedimento estérico. Uno se puede hacer una idea bastante buena del impedimento estérico al imaginar un montón de cerditos tratando de acceder a un comedero demasiado pequeño.

Es en gran parte por esto que la química de coordinación está dominada por los metales de transición y de transición interna, ya que se trata de átomos capaces de adquirir elevadas relaciones carga/radio, que poseen en general un gran número de orbitales de valencia desocupados (orbitales d en metales de transición y orbitales f en los de transición interna), y que aun así poseen un radio lo suficientemente elevado como para permitir el acercamiento de un gran número de ligandos.

Los aniones o moléculas capaces de actuar como ligandos deben poseer átomos que cuenten al menos con un par de electrones de valencia no compartidos. Estos átomos se encuentran en la esquina superior derecha de la tabla periódica, y entre ellos los más importantes son el oxígeno y el nitrógeno, dando paso luego al carbono, fósforo, azufre, cloro, flúor, etc.

Las moléculas que poseen un único átomo donador de electrones se denominan ligandos monodentados, mientras que las que poseen más de un átomo donador reciben el nombre de ligandos polidentados o agentes quelantes. Existe también un tercer tipo de ligandos conocidos genéricamente como "ligandos ambidentados" que son en realidad ligandos que actúan como monodentados, pero de dos maneras diferentes.

Los ligandos de este tipo poseen un único punto de anclaje al núcleo de coordinación, de allí el nombre monodentado que quiere decir un único diente. Comúnmente se trata de moléculas pequeñas, que poseen un único átomo donador de electrones tales como el amoníaco (), el agua (), o los aniones halogenuro (), alcóxido (), o alquilo () entre otros.

Cuando se forma un complejo de un catión metálico a partir de unión con ligandos monodentados se alteran notoriamente las propiedades de solubilidad del catión, en general esto debido a que el complejamiento provoca un aumento en el tamaño del ion, lo que a su vez se traduce en una disminución en la fuerza de atracción entre el catión y sus contraiones. Esto por lo general provoca un aumento en la solubilidad del ion, o, mejor expresado, una disminución de su tendencia a precipitar.

Los ligandos de este tipo son capaces de establecer dos o más uniones simultáneas con el núcleo de coordinación, pueden ser "bidentados", "tridentados", "tetradentados" etc. A este tipo de ligandos se les suele llamar también "agentes quelantes" un nombre derivado de la palabra griega kela que significa "pinza" porque el tipo de estructura espacial que se forma se asemeja a un cangrejo con el núcleo de coordinación atrapado entre sus pinzas. Muchas veces se utiliza a los agentes quelantes como agentes precipitantes, ya que al ser capaces de establecer dos o más uniones simultáneas también pueden funcionar como "puentes" entre dos o más núcleos de coordinación, facilitando la formación de enormes agregados macromoleculares que precipitan con facilidad.

Entre este tipo de compuestos encontramos por ejemplo a los aniones fosfato (), carbonato (), oxalato (-OOC-COO-), etilendiamina (---) y bipiridina. Un ligando polidentado de enorme importancia por la cantidad de aplicaciones que tiene es el EDTA, el EDTA posee seis sitios de unión.

Este tipo de ligandos podría considerarse un caso especial de los ligandos polidentados, porque poseen más de un átomo capaz de donar pares de electrones no compartidos, sin embargo poseen un tamaño demasiado pequeño como para ser capaces de donar electrones con ambos átomos a la vez, y en lugar de ello se enlazan de una manera ú otra dependiendo de las circunstancias.

Dentro de este grupo encontramos por ejemplo a los aniones tiocianato (S=C=N-), nitrito (O=N-O-) e isotiocianato (NC-S-)

La carga total de un ion complejo se determina por la sumatoria de las cargas del núcleo de coordinación, más la de los ligantes que participan; por ejemplo en el ion hexacianoferrato (III) 3-, la carga del catión es +3, y cada uno de los iones cianuro posee carga -1, luego:
que es la carga total del ion.

Los ligandos se unen al núcleo de coordinación en una región bastante próxima al mismo llamada esfera de coordinación que es el lugar en el espacio donde es posible que los electrones del ligando interactúen con los orbitales vacíos del grupo central.

Cada uno de los átomos del ligando que accede a la esfera de coordinación para aportar un par de electrones no compartidos se denomina átomo donador.

El número de coordinación de un núcleo de coordinación en es directamente el número de pares de electrones que recibe de los átomos del o de los ligandos. Este valor depende del tamaño del núcleo de coordinación y del tamaño de los ligantes que participan en el complejo. Por ejemplo el hierro se coordina con hasta 6 aniones fluoruro para formar el complejo (número de coordinación = 6), pero sólo puede coordinarse con hasta 4 iones cloruro (número de coordinación = 4) debido al tamaño mayor de este último.

Para expresar la fórmula de los compuestos de coordinación es conveniente tener presentes las reglas de formulación recomendadas por IUPAC, estas reglas son:

En cuanto a la nomenclatura IUPAC recomienda:













Prácticamente todos los compuestos metálicos están formados por algún tipo de compuesto de coordinación (con excepción de los metales en estado de vapor, plasmas y aleaciones). Por lo que el estudio de la química de coordinación es en gran medida equivalente al estudio de la química inorgánica, desde el momento que la química de coordinación es la química de la mayor parte de la tabla periódica. Los átomos e iones metálicos solo existen en la fase condensada rodeados por ligandos.

Las áreas de la química de coordinación de metales pueden ser clasificadas de acuerdo a la naturaleza de sus ligandos. A grandes razgos estas divisiones son:





Aunque en muchos casos es difícil clasificar a un caso dentro de un grupo particular y es más fácil interpretarlo como una combinación de varios de ellos. Ejemplos: [FeS(Cisteinil)], que es en realidad un clúster contenido dentro de una proteína biológicamente activa.

La mineralogía, la tecnología de materiales, y la química del estado sólido (mientras se aplique a iones metálicos); pueden ser consideradas subdivisiones de la química de coordinación, en el sentido de considerar a metales rodeados de ligandos. En muchos casos estos ligandos son óxidos o sulfuros. Es verdad que el foco de la mineralogía, la tecnología de materiales y la química del estado sólido difiere del foco usual de la química de coordinación. Las primeras se ocupan principalmente de estructuras poliméricas, y de las propiedades que se derivan de los efectos colectivos de un enorme número de metales interconectados. Mientras que la segunda, en contraste, se enfoca en la reactividad y propiedades de complejos que contienen átomos metálicos individuales, o pequeños agrupamientos de átomos; pero aun así los metales se encuentran coordinados, y los lineamientos y principios considerados para complejos también se les aplica.

Las estructuras moléculares en la química de coordinación se encuentran descritas principalmente por el número de coordinación, es decir por el número de ligandos unidos al grupo central (más específicamente, al número de enlaces sigma entre ligandos y grupo central). Normalmente es posible contar los ligandos unidos, pero algunas veces la cuenta de ligandos puede tornarse un poco ambigua. El número de coordinación se encuentra normalmente comprendido entre uno y nueve, pero no son extraños números de coordinación aun mayores para los lantánidos y actínidos. El número de coordinación va a depender del tamaño, carga, y configuración electrónica del grupo central y de los ligandos.

Los iones metálicos pueden presentar más de un número de coordinación.

La química de los complejos se encuentra dominada por las interacciones entre los orbitales moleculares s y p del ligando y los orbitales d de un ion metálico central. En conjunto los orbitales s, p y d del ion central pueden acomodar 18 electrones (ver la regla de 18 electrones), aunque para elementos del bloque f, esta regla se extiende hasta 32 electrones. El número máximo de coordinación para determinado elemento se encuentra por lo tanto relacionado con su configuración electrónica, (más específicamente con el número de orbitales vacíos que posee), y a la relación entre el tamaño de los ligandos y del grupo central. Grupos centrales grandes y ligandos pequeños permiten números de coordinación elevados, por ejemplo el [Mo(CN)]. Grupos centrales pequeños y ligandos de gran tamaño tienden a desarrollar números de coordinación pequeños, por ejemplo Pt[P(CMe]. Es debido precisamente a su gran tamaño, que los lantánidos, actínidos y primeros elementos de transición tienden a desarrollar números de coordinación elevados.

De los diferentes números de coordinación resultan diferentes arreglos estructurales. La mayoría de las estructuras siguen un patrón cuasiesférico, (o, visto de otro modo, como si el grupo central se encontrara en medio de un poliedro y los grupos ligandos se ubicaran en los vértices del mismo). Es en estos puntos donde es posible que se produzca el solapamiento entre los orbitales de los ligandos y el grupo central. Las repulsiones ligando-ligando tienden a dirigir esta organización hacia determinadas geometrías regulares que minimizan las interferencias. Hay sin embargo, numerosos casos de desviaciones de estas organizaciones regulares, por ejemplo en los casos donde se unen ligandos de diferentes tipos, lo que causa diferentes longitudes de enlace, apartando a los ligandos de su organización cuasiesférica, o cuando se producen distorsiones por efectos electrónicos, por ejemplo en la distorsión de Jahn-Teller.

Para los números de coordinación entre dos y nueve los arreglos geométricos más comunes que se presentan en complejos son aquellos que tienden a minimizar las fuerzas de repulsión entre orbitales de la capa de valencia

Se deben notar sin embargo algunas excepciones y previsiones:



La Lineal es la estructura de menor energía para un número de coordinación dos. En esta disposición el grupo central se encuentra entre los dos grupos ligandos y los tres forman una línea con un ángulo de enlace L-G-L de 180º

La geometría molecular trigonal plana es la estructura que minimiza las interacciones para un número de coordinación tres. En esta disposición el grupo central se encuentra en el centro de un triángulo equilátero y los grupos ligandos se ubican en los vértices del mismo, con un ángulo de enlace L-G-L de 120º

La estructura tetraédrica es la de menor energía posible para un número de coordinación cuatro. En esta disposición el grupo central se encuentra en medio de un tetraedro regular y los grupos ligandos se ubican en los vértices del mismo con un ángulo de enlace L-G-L de 109,5º

La geometría molecular plano cuadrada es otra estructura posible para un número de coordinación cuatro, en esta los cuatro ligandos se disponen en un mismo plano en los vértices de un cuadrado. Aparentemente es de energía mayor que la tetraédrica ya que los ángulos L-G-L son de 90º, pero aquí participan repulsiones debidas a orbitales con pares solitarios que se encuentran en las posiciones polares (los pares están en un plano perpendicular al plano que comparten las moléculas en disposición cuadrada). Los metales con configuración electrónica nd tienden a adoptar la geometría cuadrada plana.

La geometría molecular bipiramidal trigonal es la que maximiza los ángulos de separación, y por lo tanto minimiza la energía para un número de coordinación de cinco. se puede ver como dos tetraedros unidos por la base y está muy próxima en energía a su isocoordinada. Esta disposición es anisotrópica, los ligandos en posición ecuatorial se encuentran separados 120º entre sí, pero un ligando ecuatorial se encuentra separado 90º de uno polar.

La geometría molecular piramidal cuadrada se obtiene desplazando ligeramente uno de los vertices polares de una bipirámide trigonal hasta dejarlo en el mismo plano que el formado por dos de los vertices ecuatoriales y el restante vértice polar.

La octaédrica es la más típica disposición geométrica para los elementos de transición, y no resulta difícil ver porqué, si pusiéramos una esfera en el interior de un cubo (esfera inscrita), la esfera tocaría las caras del cubo en los vértices de un octaedro. Esta disposición consta de cuatro ligandos colocados en un mismo plano (llamado plano ecuatorial) y un ligando a cada uno de los lados de ese plano en "posición polar", en esta estructura el mínimo ángulo entre ligandos es de 90º.

La geometría molecular prismática trigonal es la siguiente en estabilidad para un número de coordinación seis, suele ser de menor estabilidad porque implica que los ligandos de los vértices del prisma queden enfrentados unos a otros, esta interferencia se minimiza en la disposición octaédrica (que en cierta forma podría ser considerada un antiprisma trigonal, donde se ha girado la cara superior para que los vértices no queden enfrentados). Por lo general esta estructura se presenta por una estabilización debida a algún otro factor no exclusivamente geométrico, por ejemplo por distorsión forzada de orbitales.

La configuración bipiramidal pentagonal es la preferida para un número de coordinación siete, como su nombre lo indica se puede ver como dos pirámides de base pentagonal unidas por la base.

La geometría molecular antiprismática cuadrada es la configuración de menor energía entre las tres posibles configuraciones para un número de coordinación ocho, se puede pensar como un cubo en el que se ha girado la cara superior para que los vértices no queden enfrentados.

La estructura molecular bipiramidal hexagonal es la siguiente en estabilidad para un número de coordinación ocho.

La estructura molecular tetraédrica triapicada es una estructura muy extraña entre los metales de transición, pero para elementos de transición interna resulta ser la estructura que minimiza todas las interacciones entre ligandos y las distorsiones orbitales por lo que se presenta incluso en compuestos muy sencillos tales como el ThCl. Puede ser racionalizado como un dodecaedro de caras triangulares.

Es la geométricamente menos estable de las configuraciones para el número de coordinación ocho y prácticamente no existe para los elementos de transición, aunque parece ser bastante común entre los elementos de transición interna, principalmente debido a que los orbitales f(xyz) apuntan hacia los vértices de un cubo, lo que disminuye la distorsión de estos orbitales al interactuar con los ligandos.

La Prismática trigonal triapicada es la geometría más regular y estable que existe para un número de coordinación nueve. La aproximación más sencilla para comprender esta estructura tridimensional es imaginarse un prisma trigonal y a media altura insertar un triángulo de modo que los vertices de este queden apuntando al centro de las caras cuadradas del prisma.

Aunque más de las dos terceras partes de los complejos conocidos presentan índices de coordinación entre 6 y 9, se conocen algunos ejemplos de lantánidos y actínidos con índices de coordinación superiores: 10, 11 o 12. 

El número de coordinación 12 presenta un mayor número de ejemplos que el número de coordinación 10 y son muy pocos los descritos para número de coordinación 11. Sin embargo debe mencionarse que, en todos los casos, son complejos que implican ligandos quelato o macrociclo, no se conocen ejemplos de complejos con índices de coordinación mayores que 9 formados por ligandos monodentados.

Para un número de coordinación 12, cabría esperar una estructura regular con forma icosaédrica. Sin embargo, esta estructura prácticamente no existe en la química práctica. Por el contrario, la gran mayoría de las estructuras descriptas corresponden a tetraedros truncados, cubooctaedros o cubos tetraapicados. 

Existen trabajos de química computacional que concluyen que en realidad la mejor manera de plasmar los índices de coordinación superiores a 9 para estas estructuras es mediante esquemas de enlace más simples (tetraedro, bipirámide trigonal u octaedro) y que las estructuras pseudoregulares observadas son en realidad una consecuencia de la interacción de los orbitales del ligando quelato con la gran superficie de los orbitales 4f, 5f, 5d o 6d del grupo central, y no sólo es debida a la coordinación con los átomos dadores.

Isomería es la propiedad que relaciona dos o más compuestos que poseen el mismo tipo y número de átomos, pero organizados estructuralmente de manera diferente.

Por razones de claridad se lo ha ubicado en una sección diferente, aunque técnicamente se encuentra dentro del estudio de la geometría de complejos.

La organización estructural de un determinado complejo es, en general, fija y estable, y se encuentra determinada por la disposición de menor energía posible, (esto es más o menos equivalente a decir que adopta la disposición con menores tensiones internas), sin embargo en algunos de estos casos existe más de una arquitectura con energías equivalentes o muy similares, lo que permite que los componentes de ese complejo adopten más de una disposición estructural. En esos casos se presenta la isomería de complejos.

Existe una gran variedad de tipos de isomería en los complejos de coordinación, sólo comparable en complejidad por la isomería de los compuestos de carbono.

Estereoisomería es el tipo de isomería que se produce cuando en dos compuestos existen no sólo el mismo tipo y número de átomos; sino también el mismo tipo y número de enlaces, pero organizados espacialmente de manera diferente.

El estereoisomerismo puede ser clasificado en:

La isomería geométrica ocurre en complejos octaédricos y cuadrados planos (no así en los tetraédricos). Cuando dos ligandos 
ocupan posiciones relativas diferentes uno con respecto a otro. Así cuando dos ligandos se encuentran opuestos uno al otro se dice que son "trans" y cuando son mutuamente adyacentes se dice que son "cis". Cuando tres ligandos idénticos ocupan una de las caras de una disposición octaédrica, se dice que se trata de un isómero facial o "fac". Si los tres ligandos se encuentran en el mismo plano que el grupo central, se dice que el isómero es meridional o "mer".

Por ejemplo, en un compuesto octaédrico con tres ligandos de un tipo y tres ligandos de otro, existen dos isómeros geométricos: el "mer" en el cual cada uno de los dos grupos de tres ligandos se encuentra en uno de los meridianos, y el "fac" en el cual cada grupo de tres ligandos se encuentra en una de las caras del octaédro.

La isomería óptica se da cuando la imagen especular de un compuesto no es superponible con el compuesto original. Se denomina isomería óptica debido a que los compuestos son "ópticamente activos", esto es, que hacen girar el plano de vibración de la luz polarizada. Este comportamiento desigual se produce porque los enlaces, que no son más que grupos de electrones, resuenan de manera diferente sometidos al campo electromagnético que es la luz. En los compuestos ópticamente activos la suma de todas las resonancias da como resultados vectores diferentes, porque los enlaces tienen ciertamente orientaciones diferentes.

se utiliza el símbolo Λ (lambda) para describir la hélice con giro a la izquierda formada por tres ligandos bidentados, tal como se muestra. De manera similar se utiliza el símbolo Δ (delta) como prefijo para describir la hélice con giro hacia la derecha.

Este tipo de isomería se da cuando el número y tipo de átomos son iguales, pero enlaces son diferentes entre sí. Existen dos grandes tipos de isomería estructural en los compuestos de coordinación, la isomería de enlace que se produce cuando los ligandos que acceden a la esfera de coordinación son los mismos, y la isomería de esfera de coordinación, en la que los ligandos en la esfera de coordinación son diferentes. 

La isomería de enlace se produce cuando un ligando se puede unir de más de una forma al grupo central, un claro ejemplo es lo que ocurre con los ligandos ambidentados, por ejemplo el NO es un ligando ambidentado: se puede unir al grupo central por cualquiera de sus oxigenos (que son equivalentes) o por el nitrógeno.

Este tipo de isomería se produce cuando un compuesto de coordinación alterna los grupos ligandos que acceden a su esfera de coordinación por grupos que se encuentran fuera de la misma en el retículo sólido (ver agua de cristalización). Por ejemplo, el CrCl(HO) existe en tres formas comunes: [Cr(HO)]Cl (de color violeta), [Cr(HO)Cl]Cl·HO (de color verde), y [Cr(HO)Cl]Cl·2HO (también de color verde). En los compuestos segundo y tercero, el agua ha sido desplazada de la esfera de coordinación por iones cloruro y en su lugar pasa a ocupar posiciones en en el retículo sólido del cristal.

Prácticamente todas las propiedades que se observan en los complejos son producto de sus estructuras electrónicas, esto es, son funciones de la manera en que los electrones se organizan dentro de la molécula, tratar de entender entonces como es que estos electrones se encuentran organizados es una buena forma de tratar de empezar a entender las propiedades de los complejos.

A partir de los descubrimientos de Werner, comenzaron a aparecer diferentes modelos teóricos que trataron de explicar los extraños comportamientos observados en los complejos.

Hacia 1929 aparece la teoría del campo cristalino (TCC) propuesta por los físicos Hans Bethe y Van Vleck, que permite explicar de manera conceptualmente muy sencilla el color y las propiedades magnéticas de los complejos, aunque no se correlaciona de buena manera con todos los complejos, ni permite explicar la naturaleza de los enlaces.

Hacia 1933 Linus Pauling introduce la teoría del enlace de valencia (TEV), que trata de explicar el porqué de la direccionalidad de los enlaces en los compuestos y comienza a dar una explicación de la naturaleza de los mismos.

La teoría de orbitales moleculares (TOM) es una consecuencia natural de la teoría del enlace de valencia que avanza sobre los aspectos cuánticos del enlace químico, permite una comprensión mucho más profunda de los fenómenos implicados en la formación de un enlace químico y permite explicar los comportamientos de muchas clases de complejos, sin embargo para muchas aplicaciones resulta demasiado complicada.

La teoría del campo de ligandos (TCL) es un modelo combinado que permite una derivación sencilla de la teoría de orbitales moleculares, utilizando para resolver las ecuaciones formales una aplicación de la teoría de grupos. Goza casi de la misma sencillez conceptual que la teoría de campo cristalino y permite explicar de manera razonablemente precisa una gran cantidad de compuestos.

En todas las disciplinas científicas siempre se trata de utilizar el modelo más sencillo que sirva para explicar cada situación en particular, es por ello que, a pesar de que la teoría de orbitales moleculares es la que brinda una simulación más realista, en general para situaciones sencillas se suele utilizar la teoría de campo cristalino como modelo.

Esta teoría considera sólo la geometría de los orbitales d de un catión central y su interacción con unos ligantes considerados como cargas negativas puntuales. Según este modelo los ligandos son atraídos por la carga positiva del metal, pero al aproximarse generan repulsiones sobre los electrones d del catión deformando los orbitales en los que estos se encuentran. Un orbital deformado presenta una mayor energía que uno con su forma "natural" por lo que los electrones tienden a ocupar posiciones en los orbitales "nativos" siempre que resulte posible, esto es siempre que la diferencia de energía entre los orbitales de mayor y los de menor energía no sea menor que la energía de apareamiento debida a la repulsión de los electrones en un mismo orbital.

Un ejemplo sencillo es lo que ocurre para un complejo octaédrico, si se hace la suposición de que los ligandos avanzan sobre los ejes de un sistema cartesiano tridimensional, los orbitales que se van a ver principalmente afectados son los que tienen componentes principales sobre estos ejes. al ver el gráfico de orbitales d se puede notar que estos orbitales son el d z y el dx-y. Como consecuencia aumentan su energía y se separan del resto de los orbitales d, formando dos subgrupos de orbitales: el grupo de alta energía e y el grupo de baja energía t.

El grado de separación entre orbitales e y t va a depender de la "fuerza" de los ligantes, es decir del grado en que estos ligantes sean capaces de deformar los orbitales d. La serie espectroquímica es una tabla empírica que ordena los ligandos de acuerdo al grado de separacíon que causan en los orbitales d, de menor a mayor fuerza son:

I < Br < S < SCN < Cl.


Si se elige cuidadosamente los ligandos que rodean al núcleo de coordinación, este grupo central puede ser utilizado para catalizar la transformación de otras moléculas o puede ser utilizado como indicador o sensor.




</doc>
<doc id="28231" url="https://es.wikipedia.org/wiki?curid=28231" title="Química supramolecular">
Química supramolecular

La química supramolecular es la rama de la química que estudia las interacciones supramoleculares, esto quiere decir entre moléculas. Su estudio está inspirado por la biología y está basada en los mecanismos de la química orgánica e inorgánica sintética.

La química supramolecular estudia el reconocimiento molecular y la formación de agregados supramoleculares lo que nos da paso para comprender e interfasear el mundo biológico, los sistemas complejos y la nanotecnología.La química Supramolecular se define como:

""La química supramoelcular es la química de los enlaces intermoleculares, cubriendo las estructuras y funciones de las entidades formadas por asociación de dos o más especies químicas"" J-M- Lehn

""La química supramolecular se define como la química más allá de la molecular, una química de interacciones intermoleculares diseñadas" F. Vögtle"

Los agregados supramoleculares que son objeto de estudio por la química supramolecular son muy diversos, pudiendo abarcar desde sistemas biológicos donde intervienen un número elevado de moléculas que se organizan espontáneamente formando estructuras más grandes, como monocapas, bicapas, micelas, complejos enzimáticos y lipoproteínas, hasta conjuntos de pocas moléculas que sufren un fenómeno de autoensamblaje molecular, como los catenanos, rotaxanos, poliedros moleculares y otras arquitecturas afines.

El concepto de química supramolecular fue definido por primer vez en 1978 por el Premio Nobel Jean-Marie Lehn, que la define como "“la química de los enlaces intermoleculares”" pero antes se realizaron diversos trabajos que llevaron al desarrollo de la química supramolecular a como la conocemos hoy día.

En 1810 Humphry Davy demuestra que el cloro es un elemento químico y le da ese nombre debido a su color amarillo verdoso. En 1823 los estudios en cloro continúan y Michael Faraday diseña la fórmula de los hidratos de cloro. En 1891 los científicos Villiers y Hebd desarrollan una investigación donde descubren las ciclodextrinas, las cuales son consideradas como moléculas anfitrionas; estos conceptos dieron paso a las contribuciones más importantes como la que realiza Alfred Werner en 1893 introduciendo el término de química de coordinación, concepto básico para entender la química supramolecular.

En 1894 el premio Nobel Hermann Emil Fischer desarrolló las raíces filosóficas de la química supramolecular, sugirió que las interacciones enzima-sustrato se asemejan a una interacción "cerradura-llave", principio fundamental del reconocimiento molecular y la química hospedador-huésped (del inglés host-guest) . A principios del siglo XX los enlaces no covalentes se entendieron con más detalle, como el enlace de hidrógeno que describieron Latimer y Rodebush en 1920. 

El uso de estos principios condujo a una mayor comprensión de la estructura de las proteínas y otros procesos biológicos. Por ejemplo, el importante avance que permitió la elucidación de la estructura de doble hélice del ADN se produjo cuando se vio que hay dos cadenas distintas de nucleótidos conectadas a través de enlaces de hidrógeno. El uso de enlaces no covalentes es esencial para la replicación, ya que permiten que las hebras se separen y se utilizan para nueva plantilla de ADN de doble cadena. Al mismo tiempo, los químicos empezaron a reconocer y estudiar estructuras sintéticas sobre la base de interacciones no covalentes, tales como micelas y microemulsiones.

Con el tiempo, los químicos fueron capaces de tomar estos conceptos y aplicarlos a los sistemas sintéticos. El avance se produjo en la década de 1960 con la síntesis de los éteres corona por Charles J. Pedersen. A raíz de este trabajo, otros investigadores como Donald James Cram, Jean-Marie Lehn y continuaron trabajando con esta química a lo largo de la década de 1980, lo que les permitió ganar el Premio Nobel de Química en 1987.

Los sistemas
supramoleculares funcionan particularmente debido al arreglo de sus componentes
usando moléculas como bloques básicos, del mismo modo se pueden crear moléculas
independientes con diferentes especies de átomos para crear moléculas complejas
de las cuales se usaran para crean un sistema con propiedades sobre la base de las de la
moléculas.

Las únicas alternativas
que se han encontrado para crear sistemas complejos son por medios bottom-up el
cual ofrece una gran diversidad de métodos de los cuales se siguen investigando
para crear nano estructuras de las cuales no se podrían comprender si usamos
medios top-bottom debido a la dificultad de la manipulación a esa escala.

Las fuentes de las cuales
podemos asegurarnos de que la aproximación bottom-up up es confiable se
encuentran principalmente en sistemas biológicas o que se originan en la
naturaleza. Estos sistemas no utilizan interacciones covalentes por lo que sus
costos de entropía de formación son prácticamente nulos al ser la mayoría de
las interacciones reversibles, la forma de crear nano estructuras
sintéticas imitando sistemas biológicos
para que puedan reconocer componentes de moléculas es los objetivos que se
quieren alcanzar con la aproximación bottom-up.

El reconocimiento molecular explica las uniones que se desarrollan de manera específica en una molécula hacia su receptor molecular. Las moléculas que logran un reconocimiento eficiente y selectivo se llaman moléculas anfitrión "(host)" las cuales pueden ser compuesto cíclicos llamados macrocilos que tienen cavidades de tamaños específicos en su interior, útiles para albergar a otras moléculas más pequeñas definidas como huéspedes "(huest)"

Este reconocimiento molecular está relacionado con los procesos catalíticos ya sea mediante el uso de catalizadores sintéticos o naturales como las enzimas que formaran compuestos supramoleculares en conjunto con el sustrato a través de tres pasos esenciales que son:


Un concepto que explica de manera concreta el reconocimiento molecular es el modelo de llave-cerradura propuesto en 1884 por el bioquímico alemán E.Fisher

Auto
ensamblaje.

Algunos de los sistemas biológicos que utilizan el autoensamblaje más conocidos es la replicación del ADN en una estructura con doble hélices unida por puentes de hidrógeno donde las interacciones están hechas por 4 moléculas que se unen 2 a 2: Guanina (G) con Citosina (C) formando 3 puentes de hidrógeno y Adenina (A) con Tiamina (T) formando 2 puentes de hidrógeno, creando las interacciones de unión entre las 2 hélices de ADN.

En esta estructura solo depende de la afinidad de las moléculas para que se creen los puentes de hidrógeno siendo nada efectivo las diferentes combinación entre las moléculas para que se unan como lo hacen con la combinación convencional. Los errores que podrían ocurrir en la formación de la estructura del ADN son altamente nulos ya que la entropía de formación impide que las moléculas se acomoden en combinaciones equivocadas, por lo que nos proporcionaría una modalidad mucho más eficiente, óptima y rápida para crear sistemas nano estructurados en el futuro para que no existan costos por error en su fabricación.

Metalosupramolecular

Los compuestos de coordinación son usados en la química inorgánica para poder crear estructuras compuestas de una parte orgánica con algún ion o metal el cual queden a fines sus propiedades para crear nano estructuras, estos sistemas dependen de los factores en los cuales son sintetizados ya que al varias sus dimensiones general grandes cambios en la forma en la cual van a interactuar con moléculas que se les este dispuestas a cambiar.

Estas estructuras son generalmente polígonos en dos dimensiones donde el tamaño y el Ángulo en donde los ligantes hace conexión con otras estructuras que harán al sistema óptimo para las moléculas que tengan afinidad con esta, de esta forma la selectividad tendrá un espectro específico con posibles especies que estén en su entorno.

Rejillas

Involucran una serie de componentes paralelos en una orientación ortogonal en otra serie de iones metálicos ligandos en una sección cruzada creando una red conforme se le va agregando más iones a las rejillas.

Los costos de entropía se
toman en consideración a la hora de crear nano estructuras para su arreglo y
agregación adecuado y no sean inestables del cual dependen sus grados de
libertad y se pueden estimar de diferentes formas en diferentes tipos de
agregación.

La magnitud de la entropía de traslación refleja la posibilidad de diferentes arreglos en una molécula en un espacio determinado pero en entornos líquidos donde igual se puede aplicar para gases, sin embargo al ser un gas su entropía será mucho mayor a la de un líquido por lo que se
dificulta más la predicción de la entropía de formación en dichas estructuras en modelación computacional.

Se define la densidad molecular de una molécula como su masa molecular en KG/molécula dividida por su volumen en compuestos orgánicos compuestos principalmente de carbón, nitrógeno y oxígeno dadas en estructuras esféricas en solución, la agregación de otros componentes dependerá de la inercia en la cual la molécula girara en una solución. 

La frecuencia de las vibraciones a las que se puede someter una molécula puede tener efectos en el momento de agregar otras moléculas, algunas de ellas necesitas de vibraciones para poder agregarse correctamente en los sitios adecuados de otras, es por eso que las altas frecuencias aumentaras la entropía y en algunos casos puede ser favorable para la vinculación o agregación, por otro lado las bajas frecuencias igual favorecerán sistemas que necesiten de una vibración tenue.

Las interacciones supramoleculares nos sirven para entender como es que las especies se mantiene unidas mediante una variedad de interacciones no covalentes donde su fuerza va de 2-300 kJmol-1. Las interaccione no covalentes utilizadas para la formación de sistemas supramoleculares son:
Ión-Ión: Esta interacción se presenta cuando dos especies con cargas opuestas están en contacto, por lo que no presentan dependencia de la direccionalidad. Un aspecto que afecta la estabilidad de la
interacción es la fuerza iónica del medio, la cual puede ser analizada
empleando la ecuación de DebyeHückel. Para el desarrollo de estas interacción se suele utilizar disolventes con constantes dieléctricas bajas como el cloroformo, acetonitrilo o diclorometano y evitar el agua en el medio ya es altamente competitivo.

ión-dipolo: Estas interacciones se establecen entre una especie neutra y otra que estará cargada por lo que mostraran dependencia a la orientación del dipolo de tal manera que cuando la molécula orienta su dipolo hacia la especie cargada resulta una fuerza de enlace de alrededor de 5-200 kJmol-1

En la química Supramolecular existen sistemas que explican esta interacción como los complejos formados por éteres corona con diferentes derivados de amonio, donde la interacción se establecerá entre los oxígenos del éter y el hidrógeno del huésped que estará cargado positivamente y la complejación de los anfitriones con metales alcalinos y alcalinos-térreos. También se ha observado al formación de rotaxanos a través de ciclodextrinas utilizadas como macrocilos y como ejes los cationes bipiridino.
Dipolo-dipolo: Existen dos tipos de interacciones dipolo-dipolo, una es cuando las dos moléculas adyacentes alinean sus dipolos donde solo es necesario que solo una de las moléculas se oriente adecuadamente, el otro tipo es cuando simultáneamente ambas moléculas se alinean sus dos momentos dipolares, en este caso se es dependiente de la direccionalidad. Los sistemas que más frecuentemente se detectan como formadores de estas interacciones son neutros polares y por lo regular son los que presentan grupos carbonilo, nitro y aminas, como por ejemplo C=O/C=O,C=O/CN,
Dentro de estas interacciones existen tres tipos de asociaciones entre dipolos, las cuales surgen a partir de las fluctuaciones de la distribución de electrones entre dos especies que se encuentran cercanas; estas interacciones van a mostrar dependencia a la polarización de las moléculas, siendo las más polarizables las que forman las interacciones fuertes.

La interacción de Keersom es cuando las moléculas se encuentran interactuando a ciertas distancias poseen dipolos permanentes por lo que se alinean a esos dipolos de manera atractiva, por otro lado cuando una molécula con un dipolo permanente
induce un dipolo en otra cercana se conocen como interacción de Debye y por
último la interacción entre dos moléculas no polares pero polarizables es
conocida como interacción de London. En la química supramolecular, más específicamente en sistemas anfitrión-huésped, estas interacciones juegan roles importantes.
La química supramolecular se basa en los comportamientos biológicos para imitarlos y desarrollar técnicas de reacción. Los enlaces π- π son de gran importancia pues pueden observarse en el apilamiento de proteínas y la estructura del ADN.
Esta interacción ocurre entre especies donadoras parcialmente negativas con otras aceptoras de protones y un hidrógeno localizado entre ellas. Se considera que los puentes de hidrógenos con geometría lineal son más fuertes por lo que el requisito de direccionalidad lo hace selectivo al momento de formar complejos por lo que dentro de la química Supramolecular se considera la inteacción que será responsable de un ensamble organizado y estable pero es difícil hacerlo en un sistema acuoso dado que el agua es un excelente donador y aceptor de puentes de hidrógeno

A modo de ejemplo:



</doc>
<doc id="28250" url="https://es.wikipedia.org/wiki?curid=28250" title="Jardín zoológico">
Jardín zoológico

Un jardín zoológico, parque zoológico, casa de fieras, zoológico o zoo, es una instalación en la que se exhiben animales dentro de los recintos expuestos al público y en las que también pueden ser criados.

El término jardín zoológico se refiere a la zoología, el estudio de los animales, un término que se derivan del griego "zωο" ("zoo": "animal") y "λóγος" ("lógos": "estudio"). Actualmente el número de colecciones de animales abiertas al público en todo el mundo supera los 1000, alrededor del 80% de ellos en las ciudades.

En su inauguración en 1828, el Zoológico de Londres se catalogó a sí mismo como una «casa de fieras» o «jardín zoológico». La abreviatura «zoo» comenzó a usarse por primera vez en una impresión hecha en Reino Unido aproximadamente en 1847, para referirse al Zoo de Clifton. Sin embargo, no fue sino dos décadas después que se popularizó, a causa del impacto cultural de la canción «Walking in the Zoo on Sunday» interpretada por el artista "music hall" Alfred Vance. En Estados Unidos, el término «parque zoológico» fue usado para instalaciones más amplias ubicadas en Washington D. C. y en Nueva York, abiertas en los años 1890.

Colecciones de animales y parques zoológicos aparecen ya en la civilización china y la egipcia, a la vez que a lo largo de la historia todas las civilizaciones que se han ido desarrollando han dejado de una u otra manera pruebas de la relación hombre-animal.

Los primeros zoológicos fueron en realidad colecciones privadas de animales exóticos vivos, colecciones en su mayoría pertenecientes a reyes. En ese sentido el primer zoo del que se tiene noticia fehaciente fue el zoológico de Moctezuma que tuvo el emperador azteca en su capital Tenochtitlán, y que fue descrito por Hernán Cortés en 1520 y destruido poco después. Más de un siglo más tarde, en 1664, se inauguró el primer zoo europeo: la "ménagerie royale de Versailles" («casa de fieras real de Versailles»), concebida por Luis Le Vau para Luis XIV. El primer zoológico moderno fue el Zoológico de Viena, inaugurado en 1765. Tres décadas después, en 1793, la revolución francesa disolvía la casa de fieras de Versailles y reinstalaba los animales en un nuevo zoo, abriendo de este modo al público el que hoy en día está considerado como el segundo zoo más antiguo del mundo, la "ménagerie" («casa de fieras») del Jardín de Plantas, en París, regida desde entonces por el Museo Nacional de Historia Natural de Francia. Con el tiempo, en 1934, este museo nacional francés abrió un zoo más grande, en el límite municipal de París, el zoológico de París, que desde entonces se convirtió en el zoo oficial de la ciudad, aunque la antigua casa de fieras del Jardín de Plantas nunca fue cerrada y sigue abierta todavía hoy en día, completándose de este modo mutuamente con el zoo oficial.

El Zoológico de Central Park fue inaugurado en Nueva York en 1864. Es el más antiguo de Estados Unidos y cuenta con una de las mayores colecciones del mundo. Ciudades como San Luis (Misuri), Bombay, Tokio, Madrid, Roma, Berlín, San Diego, Chicago, Filadelfia o Múnich albergan colecciones de gran importancia. En Latinoamérica algunos de los más importantes son el Buin Zoo y Zoológico Nacional en Chile, el Parque de las Leyendas en Perú, el Zoológico de Chapultepec, el Zoológico Miguel Álvarez del Toro y el Zoológico Guadalajara en México, el Zoológico Matecaña y el Zoológico de Cali en Colombia, el Zoológico de Buenos Aires en Argentina, el Zoológico El Pantanal en Ecuador y el Zoológico La Aurora en Guatemala.

Con el tiempo, la misión de los zoológicos ha pasado de ser la mera exposición de animales exóticos al estudio científico de los animales (el zoológico de Londres fue el primer zoológico científico del mundo) y, más tarde, la cría en cautividad y en particular la protección de especies en peligro de extinción o incluso ya extinguidas en estado salvaje, como el cóndor de California, el ganso de Hawái, el ibis eremita y el oso panda.

En un zoológico, los animales habitan en recintos diseñados de tal forma que se asemejen a sus hábitats naturales o que permitan el desarrollo de patrones de comportamiento estables, para garantizar su bienestar. En el caso de las especies nocturnas —aquellas que son más activas durante la noche—, se construyen edificios especiales que proveen de luces tenues blancas o rojas durante el día para que los animales estén activos y puedan ser observados por los visitantes, y de luces más brillantes por la noche para que duerman. Respecto a los animales que viven en ambientes extremos, como por ejemplo los pingüinos, es necesario su alojamiento en estructuras con condiciones climáticas específicas. Hay un tipo de recinto para cada especie, desde los insectos y aves hasta los reptiles, mamíferos y criaturas acuáticas. Algunas instalaciones se adecuan inclusive para que los visitantes puedan entrar y tocar a animales que no son violentos, bajo la condición de que se mantengan durante el recorrido en un camino previamente identificado, y que no alimenten o muestren siquiera alimentos a los animales.

El Convenio sobre la Diversidad Biológica es el primer instrumento jurídico internacional que recoge como mecanismos de protección de los recursos biológicos y genéticos los términos conservación "in situ" (conservación de los ecosistemas y los hábitats naturales y el mantenimiento y la recuperación de poblaciones viables de especies en sus entornos naturales) y "ex situ" (medidas financieras, científicas y técnicas orientadas a la conservación y la investigación de plantas, animales y microorganismos fuera de su hábitat natural). Los zoológicos son un claro ejemplo de instalaciones destinadas a la conservación "ex situ", pueden y deben ser sujetos activos de gran valor en la conservación.

La Directiva 1999/22/CE, de 29 de marzo "relativa al mantenimiento de animales salvajes en parques zoológicos", exige el establecimiento de un régimen de autorización y de inspección de los parques zoológicos, que garantice el cumplimiento de condiciones básicas de sanidad, bienestar y seguridad, para mantener la buena salud física y psíquica de los animales salvajes los habitan. Pretende así favorecer la correcta aplicación de la legislación comunitaria en materia de conservación de la fauna silvestre, así como asegurar el papel en la educación pública, la investigación científica y la conservación de las especies por parte de los zoos.

El Reglamento (CE) nº 338/97 del Consejo, de 9 de diciembre de 1996, "relativo a la protección de especies de la fauna y flora silvestres mediante el control de su comercio", obliga a los Estados miembros a disponer de instalaciones adecuadas para el albergue y cuidado para los casos de importación de especímenes vivos de gran número de especies, y se prohíbe la exposición pública con fines comerciales de especímenes de las especies de su anexo A, salvo en caso de concreta excepción justificada por fines educativos, de investigación o cría.

La Directiva 79/409/CEE del Consejo, de 2 de abril de 1979, "relativa a la conservación de las aves silvestres", y la Directiva 92/43/CEE del Consejo, de 21 de mayo de 1992, "relativa a la conservación de los hábitats naturales y de la fauna y flora silvestres", prohíben la captura, mantenimiento y comercio de gran número de especies, pero permiten determinadas excepciones, precisamente, para la investigación, la educación y la cría, repoblación y reintroducción de especies.

La directiva europea se transcribió en la Ley 31/2003, de 27 de octubre, "de conservación de la fauna silvestre en los parques zoológicos".
Esta ley establece que los parques zoológicos deben ser una fuente de conocimientos científicos a disposición de universidades, de instituciones dedicadas a la investigación, y de organizaciones comprometidas con la conservación de la naturaleza, a fin de que estas entidades puedan contribuir a la conservación "ex situ" de las especies silvestres, así como a su conservación "in situ". Especifica también que los zoos deben tener como función el fomento de la educación y de la toma de conciencia por el público en lo que respecta a la conservación de la biodiversidad.

Las competencias sobre la gestión de los zoos están transferidas a las comunidades autónomas, que quedan obligadas a mantener un registro de los parques zoológicos autorizados en su territorio, con información actualizada sobre las colecciones de animales que mantengan en sus instalaciones. También deberán mantener informado al Ministerio de Medio Ambiente de los datos de sus registros.

La mayoría de los zoológicos modernos mantiene a los animales encerrados en reproducciones reducidas de sus hábitats naturales. Estos microambientes deben ser lo suficientemente grandes como para permitir el ejercicio y privacidad del animal. Algunos diseños modernos tienen en consideración tanto la comodidad del animal como la facilidad de los visitantes para observarlos, evitando que los animales se enteren de ello. Para esto son utilizados algunos trucos como vidrios polarizados detrás de un refugio del sol.

En muchos jardines zoológicos hay edificios especiales para animales nocturnos, donde se proyecta una luz tenue y rojiza durante el día a para que el animal esté activo durante las visitas y una luz intensa durante la noche para garantizar el sueño del animal.

Casi toda ciudad importante del mundo cuenta con un zoológico, a pesar de la variación en tamaño y calidad de cada uno. Los zoológicos mayores son importantes atracciones turísticas, de manera que muchos gobiernos deciden subsidiar los gastos operacionales del zoológico. La estatalización de zoológicos es también justificada por su valor educativo, ya que los zoológicos son a menudo visitados por escolares en salidas de estudio. Sin embargo, la mayor parte de la financiación de un zoológico proviene de donaciones y el costo de entrada a visitantes.

Las asociaciones de zoos y acuarios -WAZA (mundial), AAZA (América), EAZA (Europa), etc.- coordinan actuaciones para la conservación de especies amenazadas y llevan a cabo proyectos de reproducción ex-situ.

En Europa los dos principales programas de este tipo son el Programa Europeo de Especies en Peligro (EEP) y el European Stud-Book (ESB).

Hay especies o subespecies extintas en estado salvaje de las que solo quedan individuos en los zoos. Es el caso del ciervo del Padre David ("Elaphurus davidianus") o el león del Atlas ("Panthera leo leo").

Algunos colectivos se oponen a que los animales sean privados de libertad. Argumentan que no es ético utilizar seres con capacidad de sentir para el ocio de las personas y por ello piden el cierre de los zoológicos, oceanarios, y acuarios públicos. La mayoría de estas críticas no van para los zoológicos que contienen animales en alto riesgo de extinción, sino que van para los zoos que tienen animales que podrían estar en su hábitat natural. Algunos zoos liberan los animales a sus hábitat.

Los zoológicos deben cumplir con los objetivos de investigación, recreación, educación y conservación. Por lo tanto, un zoológico no debe adquirir sus animales sacándolos de sus respectivos hábitats o comprándolos a cazadores. Además de compras e intercambios con otros parques, algunos zoológicos adquieren legalmente animales por medio de instituciones que confiscan animales silvestres a traficantes de fauna, coleccionistas, cazadores, o gente que los tiene ilegalmente como mascotas. Los individuos de fauna silvestre que llegan al zoológico son acogidos porque es su última alternativa para una vida más o menos adecuada, con especialistas en su salud y hábitats específicos. Cuando un animal silvestre tiene contacto con humanos pierde posibilidades de reintegrarse a la naturaleza, por esa razón los traficantes y coleccionistas ya mencionados acaban completamente con las posibilidades de que el individuo silvestre pueda volver a integrarse a su medio natural. La dificultad de la reintegración radica en lo siguiente:




</doc>
<doc id="28253" url="https://es.wikipedia.org/wiki?curid=28253" title="Monarca">
Monarca

El monarca es el jefe de Estado de un reino cuya forma de estado recibe el nombre de monarquía, ejerce normalmente la más alta representación del estado y arbitra y modera el funcionamiento de sus instituciones. Puede ser jefe de una etnia (zulúes, maoríes, etc.) o de un país (46 Estados o Instituciones elevadas a la categoría de Estado -Orden de Malta-, reconocidas por la ONU). Uno de esos jefes de Estado, en concreto, la reina del Reino Unido ostenta el papel de cabeza de la Mancomunidad de Naciones, organización que comparte lazos históricos con el Reino Unido. Quitando unos poquísimos casos, que son elegidos por un cónclave (Ciudad del Vaticano), asamblea (Orden de Malta), por decisión papal (copríncipe eclesiástico de Andorra) o por elección democrática del pueblo francés (presidente de Francia y copríncipe de Andorra), tal y como señala la Constitución de este Estado pirenaico, es un título hereditario y, en principio, vitalicio (de nuevo, la excepción la marcan los copríncipes de Andorra).

Aunque tradicionalmente han actuado como autócratas (en el sentido de ejercer por sí sola la autoridad suprema de un Estado, caso del emperador o zar de Rusia, también han podido ser figuras de carácter ceremonial sin ningún poder real (caso del emperador de Japón), con el poder restringido a sus territorios patrimoniales (caso del emperador del Sacro Imperio Romano Germánico o el rey de Francia en la Edad Media antes de que extendiera su autoridad a la totalidad del país), o con unos poderes más o menos limitados por una constitución, en cuyo caso se habla de monarca constitucional (caso del estatúder en los Países Bajos, el rey de España o el rey de Inglaterra).

Habiendo estado extendidos por casi todo el globo, el origen de los distintos regímenes monárquicos es a veces un tanto incierto, sobre todo por la antigüedad de muchos de ellos y por la carencia de fuentes relevantes que lo refieran; en estos casos, es relativamente común que la monarquía se asocie a alguna leyenda de carácter mítico, usualmente asociada a una intervención divina, (caso del emperador en Japón, supuesto descendiente de la diosa Amaterasu; y también de los emperadores julio-claudios de Roma, que decían descender de la diosa Venus). En muchos otros casos, existen abundantes fuentes documentales que describen la aparición de la monarquía, como por ejemplo en el advenimiento del régimen imperial romano y de su directo descendiente el Imperio bizantino, en el establecimiento del Sacro Imperio Romano Germánico. De todas formas, dentro del contexto de las monarquías cristianas (que van desde el Bajo Imperio romano y el Imperio bizantino hasta los reyes de Francia, Inglaterra, Austria, España, entre otras) se extendió como había sido en la Edad Antigua, a modo de justificar el régimen, el concepto de "monarquía divina", en virtud del cual el rey lo era "por la gracia de Dios" (derecho divino de los reyes), lo cual confería un carácter sagrado a la monarquía. Conceptos parecidos se empleaban en el Imperio chino, donde el emperador (el 'Hijo del Cielo'), ostentaba el llamado "mandato del Cielo", que lo habilitaba para gobernar.

La monarquía es mayoritariamente hereditaria y presuntamente perpetua, excepto en casos excepcionales como en la Ciudad del Vaticano, donde el monarca es un pontífice elegido por inspiración divina, por un grupo cerrado de personas que conforman el Colegio Cardenalicio. El modo de herencia más común ha sido de padres a hijos, por línea paterna; las monarquías matrilineales han sido algo excepcional. En algunas dinastías, las mujeres han podido gobernar, bien porque no hubiera ningún hermano varón, bien porque ellas fueran las primogénitas; ello, empero, dependía de las tradiciones de la propia dinastía: por ejemplo, la dinastía Capeto de Francia, se regía por la Ley Sálica que impedía gobernar a las mujeres, mientras que la Casa de Trastámara de Castilla no lo hacía, y algunas mujeres pudieron llegar al poder.

Los monarcas pueden recibir distintos títulos, como rey / reina, "emperador" / "emperatriz", "gran duque" / "gran duquesa", "príncipe"/"princesa", "papa" (con dignidad religiosa), rara vez se les denomina "caudillo"; en algunas civilizaciones americanas "cacique" (sobre todo de carácter tribal), "pishin" (en las culturas mayas), "inca" (en el Imperio inca). Existen además términos específicos para los monarcas de algunos estados, derivados de los idiomas locales o de adaptaciones lingüísticas, como "zar" (de Rusia, de Bulgaria), "faraón" (de Egipto), "sah" (de Persia), kan (o khan, para los pueblos tártaros). Los monarcas de los estados gobernados por la ley islámica eran llamados sultanes, y si estaban investidos de la suprema autoridad religiosa, califa (que significa algo así como "representante del profeta" o "comendador de los creyentes"). En la antigua Grecia, los monarcas recibían el título de "tirano" o basileo; este último fue retomado por los emperadores bizantinos. Los términos "príncipe" y "princesa" provienen del latín "princeps", primer ciudadano; fue el título empleado durante el Alto Imperio romano por los emperadores (a su vez, emperador viene del latín "imperator", título militar equivalente a "soberano" o "jefe del Ejército"). Algunos monarcas soberanos, sobre todo de Italia, mantuvieron el título de príncipe, y en ciertos países como en Francia fue empleado como título nobiliario; en otros casos se destinó a los hijos, descendientes o herederos del monarca (príncipe de Asturias, príncipe de Gales, príncipe de Orange, entre otros). Nótese que en algunos países europeos, asiáticos y africanos un "rey" es el jefe de Estado de una nación-estado, pero en otros países, el rey puede que sea el jefe de una tribu, y que no se corresponda con un Estado independiente.

Antiguamente, y aún en algunas naciones monárquicas actuales, solían atribuirse al monarca, poderes divinos (por ejemplo, los monarcas ungidos de Israel, e Inglaterra o Francia, supuestamente podían curar a los enfermos imponiendo las manos), como una muestra de que eran elegidos o enviados de Dios para gobernar.

La palabra monarca, en latín "monarcha", proviene de la griega μονάρχης, monárkhēs (de monos, μόνος, "uno/singular", y ἄρχω, árkhō, "gobernar" (compárese con archon, ἄρχων, "liderar/gobernar/mandar")) la cual se refería a un solo gobernante absoluto, al menos nominalmente hablando.

Por su parte el término “rey” en el español moderno deriva del latín “"rex"” con igual significado, y de forma análoga la palabra “reino” del latín “"regnum"”. Todas estas provienen a su vez de la raíz indoeuropea “"reg"” que significa regir o gobernar además de referir al lado derecho o recto del cuerpo, razón por la cual se conserva en la etimología del término para diestro de algunas lenguas germánicas.

En hebreo el término para rey es mé·lekj. Uno de los monarcas más antiguos, Nemrod, es mencionado por la biblia (Gé 10:8-12.) y numerosas tradiciones antiguas.

El sistema de sucesión al trono no es igual en todas las monarquías. Tradicionalmente, lo más común es que el sucesor de un rey sea su hijo primogénito varón; en caso de que no los tuviera, le sucedería su hija mayor o algún familiar de sexo masculino, dependiendo de si la monarquía permite a las mujeres reinar, e incluso que la sucesión pase por una rama femenina del linaje.

Algunas monarquías han abolido esta preferencia por los hombres, y es el hijo primogénito del monarca, varón o mujer, quien sucede al rey.

En España, fue abolida en 1830 la ley sálica que impedía reinar a las mujeres, pero sigue existiendo una preferencia por los hombres en la sucesión al trono. Felipe VI sucedió al rey Juan Carlos I, a pesar de tener dos hermanas mayores que él.

También han existido algunos monarcas electos, como los papas, los reyes de Polonia, y dictadores que se han declarado líderes de una monarquía autoproclamada.



















</doc>
<doc id="28254" url="https://es.wikipedia.org/wiki?curid=28254" title="Jugo de frutas">
Jugo de frutas

El jugo de frutas o zumo es la sustancia líquida que se extrae al licuar habitualmente por presión, aunque el conjunto de procesos intermedios puede suponer la cocción, molienda o centrifugación del producto original. Generalmente, el término hace referencia al líquido resultante de exprimir un fruto. Así, por ejemplo, el jugo o zumo de naranja es el líquido extraído de la fruta del naranjo. A menudo se venden jugos envasados, que pasan por un proceso durante su elaboración que les hace perder parte de sus beneficiosas propiedades nutricionales, una porción de jugo equivale a una porción de fruta.

El término "zumo" sólo se aplica al líquido que se obtiene de las hierbas, flores, frutas u otros vegetales.

Generalmente, el nombre "jugo" se aplica a los líquidos que son obtenidos por presión, en tanto que los obtenidos por cocción son llamados infusiones. Por su parte, el producto obtenido de la cocción de piezas cárnicas se suele llamar caldo o consomé. También se llama "jugo", al líquido que contiene o impregna un producto fresco o cocinado —carnes, pescados, verduras—, y que normalmente rezuma cuando este es cortado o manipulado. 

Algunos líquidos encontrados en organismos animales son también llamados "jugo", como por ejemplo el jugo gástrico.

Los jugos recién exprimidos son una bebida muy nutritiva, principalmente por las vitaminas que contienen. Los jugos conservados en tetra brik, también conocido como tetra pack, suelen ser "jugo hecho a partir de jugo concentrado". Esto significa que, después de ser exprimidos, han sido concentrados evaporando el agua mediante calor, y posteriormente se les ha añadido agua para envasarlos. Esto permite transportar menos agua y ahorrar costos, pero este proceso destruye gran parte de las vitaminas, lo que elimina la principal cualidad nutritiva de los jugos. 

Otra de las cualidades nutritivas que se pierden de las frutas al realizar zumos es la eliminación de la fibra propia del fruto, como por ejemplo, la naranja, ya que al exprimir la fruta se elimina la ""pulpa"", que es lo que aporta la fibra.

Para prepararlos en casa, es necesario poseer un aparato llamado exprimidor o escariador para obtener jugo de naranja, limón o pomelo. También se utiliza un extractor para obtener jugo de otras frutas u hortalizas como las manzanas o zanahorias.

Tanto la producción de zumos como su preservación tienen una gran importancia comercial ya que permite procesar un producto perecedero como son los frutos, para convertirlo en un bien muy apreciado por los consumidores.

A partir del año 1.930, cuando las industrias comenzaron a producir zumos de frutas, los rendimientos eran muy bajos y se presentaban dificultades en la filtración del mismo que impedía la obtención de una claridad aceptable. Sin embargo, la investigación y desarrollo industrial de pectinasas, celulasas y hemicelulasas obtenidas a partir "Aspergillus niger" y "Trichoderma sp"., sumado al incremento del conocimiento de los componentes de las frutas, facilitaron solucionar esas dificultades.

Durante el proceso de producción de un zumo de frutas podemos diferenciar dos etapas generales: la primera es la de manipulación y extracción del zumo de la fruta y segunda la de tratamiento del zumo obtenido​. Dentro de la manipulación y extracción de zumo hay diferentes pasos​:
En cuanto al tratamiento del zumo extraído, se realiza la clarificación, corrección y mezcla, desaireación y pasteurización.

- Clarificación: el zumo obtenido tras la extracción tiene un contenido de pulpa del 22% aproximadamente y con la clarificación se consigue eliminar la turbidez, las cortezas, piel, semillas y reducir la concentración de pulpa a un 12%.

- Corrección y mezcla: se realiza en tanques donde se realiza la formulación el zumo.

- Desaireación: se deben eliminar los gases que luego pueden condensarse y recuperarse en forma de aromas que modificarían el zumo.

- Pasteurización: en este proceso se destruyen las enzimas que están presentes en forma natural en el zumo y son las responsables de la turbidez del mismo. Además, este proceso permite prolongar la vida útil del zumo. Finalmente se envasa el zumo y se almacena para ser distribuido y que llegue al consumidor. El envasado comúnmente se realiza en frío con temperaturas de entre 1-7°C para evitar contaminaciones microbiológicas. La mayoría de los zumos así envasados tienen una vida útil de 3 meses desde la fecha de producción y una vez abierto es recomendable consumirlo antes de 7 días​.

Hoy en día, la utilización de enzimas en la producción de zumos de frutas y verduras es indispensable, pues están implicadas en varias etapas del proceso de obtención​:
Así mismo, en el proceso de producción es necesario tener en cuenta una serie de parámetros en los que directa o indirectamente está implicada la enzima.

Por una parte, su mecanismo de acción dependerá de la relación entre la concentración de enzima, la temperatura aplicada y el tiempo de reacción. Así, estos se podrán modular en función de las necesidades de operación. Por otra parte es necesario destacar el papel de las pectinas en la degradación del fruto, que a su vez dependerá del sustrato a tratar. Estas enzimas pueden ser seleccionadas previamente para actuar sobre moléculas peptídicas específicas, de manera que la composición del sustrato y su viscosidad irá cambiando en función del porcentaje relativo de pectina soluble e insoluble presente.  

Los frutos, como parte de la planta, están constituidos por células vegetales, cuya pared está formadas en un 90% por polisacáridos (celulosa, hemicelulosas y pectinas) y en un 10% por proteínas. En concreto, la lámina media de la pared celular debe su estructura a las pectinas, cuya degradación favorece la descomposición natural de los vegetales. Estas, a su vez, en contacto con líquidos, son capaces de absorber agua, formando un gel.

En la producción industrial de jugos de frutas y vegetales, las pectinas deben ser eliminadas para evitar la retención de líquidos y turbidez del producto. Es aquí donde intervienen las pectinasas, enzimas que hidrolizan la pectina, favoreciendo su eliminación y  un consecuente aumento del rendimiento de extracción del jugo y mejorando su calidad. Esta enzima se engloba dentro de la familia de las denominadas enzimas macerativas cuya demanda desde el sector alimentario incrementa mundialmente en la producción de zumos de un amplio rango de frutas y vegetales.

La combinación de pectinasas (pectin lyase, pectin metilesterase, endo y exo-poligalacturonasas, pectin acetylesterase, rhamnogalacturonase, endo y exo-arabinasas), celulasas (engoglucanasas, exoglucanasas y cellobiosas) y hemicelulasas (endo y exo-xilanasas, galactonasas, xiloglucanasas y manonasas)- colectivamente llamadas enzimas macerativas, son las mayormente empleadas en los procesos comentados anteriormente.

Las pectinasas, debido a su acción pectinolítica, liberan el jugo retenido en la pectina de las paredes celulares vegetales, aumentando el rendimiento de extracción del jugo y mejorando su calidad. También facilitan la clarificación como se mencionó anteriormente. Por lo general, dichas enzimas provienen de levaduras y en su mayoría son endo-poligalacturonasas, lo que quiere decir, que degradan la pectina principalmente por hidrólisis de los enlaces alfa-1,4-glicosídicos. Actualmente, la principal fuente de dicha enzima a nivel industrial proviene de Aspergillus niger ya que produce una gran cantidad de las mismas y es un microorganismo GRAS (Generally Recognised As Safe). 

Las celulasas son producidas por algunas bacterias ("Cellulomonas, Clostridium, Trichoderma", etc.) como así también por protozoos y hongos. Su función principal es realizar la hidrólisis de enlaces 1,4 beta-D- glucosídicos en celulosa. La celulosa, principal componente de la pared celular, impide la liberación de los componentes del sabor, es por esto, que la utilización de celulasas en la producción de zumos es de gran importancia. Existen diferentes tipos de celulasas que se caracterizan por su mecanismo de acción; en primera instancia las beta-1,4- gluconasas actúan aleatoriamente sobre enlaces beta-1,4 de unidades de glucosa que forman la celulosa permitiendo la obtención de oligosacáridos a partir de cadenas largas. Dicha acción disminuye la longitud de las cadenas de celulosa y la creación de nuevos extremos que servirán para reacciones posteriores. A continuación, las beta-1,4- glucanasas cortan cadenas de 1,4-beta-D-glucano del extremo no reductor de moléculas de celulosa y celodestrinas causando de esta manera la eliminación de celobiosa o glucosa. Finalmente, actúan las endoglucanasas y las exoglucanasas sinérgicamente.

Las hemicelulasas, responsables de la degradación de la hemicelulosa (polisacárido estructural presente en la pared celular), deben actuar conjuntamente debido a la heterogeneidad que presentan dichos polisacáridos.



</doc>
<doc id="28259" url="https://es.wikipedia.org/wiki?curid=28259" title="Modelo físico">
Modelo físico

Un modelo físico puede referirse a una construcción teórica (modelo matemático) de un sistema físico. También a un montaje con objetos reales que reproducen el comportamiento de algunos aspectos de un sistema físico o mecánico más complejo a diferente escala (modelo material en miniatura). El término aparece con diferentes acepciones en el ámbito de la física o en el de la física aplicada, como la ingeniería.

Se dice que una determinada teoría física es un modelo o un modelo físico teórico cuando su dinámica interna (las leyes básicas de evolución temporal que vienen determinadas por el hamiltoniano) no se conocen exactamente. O cuando son conocidas pero, si lo que se busca es estudiar exclusivamente algunos detalles particulares de un sistema complejo, puede resultar rentable (técnicamente) emplear otro tipo de dinámica (ficticia) que hace que el comportamiento en estudio del sistema completo sea aproximadamente igual que el que tendría con la dinámica más complicada.

Estos modelos se aplican en todas las áreas de la física (meteorología, termodinámica, física nuclear, materiales, etc.) excepto en física teórica. Como cualquier teoría física, un modelo de este tipo, reduciendo el comportamiento observado a hechos fundamentales más básicos, ayuda a explicar y predecir el comportamiento de un sistema físico bajo circunstancias diversas. Sin embargo, al no estar basado en una descripción fundamentalmente correcta, se espera que el modelo falle fuera de su campo de aplicación.

Los modelos físicos teóricos a veces se plasman en forma de un hamiltoniano efectivo o hamiltoniano modelo: aquel hamiltoniano que no considera explícitamente todas las variables del sistema, sino que las resume en un pequeño número de interacciones. Aunque sus funciones propias sólo contienen una pequeña parte de la información necesaria para una descripción completa, se busca que las diferencias entre sus valores propios se corresponden exactamente a las diferencias entre las energías reales, por lo que pueden usarse para racionalizar propiedades medidas experimentalmente. Su objetivo es comúnmente una descripción simplificada del problema, en la que se estudia de forma rigurosa el efecto de un fenómeno concreto, usando una descripción implícita del resto de fenómenos. Estrictamente, hay diferencias sutiles entre los hamiltonianos efectivos y los hamiltonianos modelo, derivadas de la forma de parametrizar las interacciones. Se usan hamiltonianos modelo como herramienta auxiliar en un amplio rango de campos de la física, incluyendo la física de la materia condensada, la óptica y la física nuclear.

El uso de hamiltonianos efectivos, frente a los hamiltonianos cuánticos completos, tiene como principal ventaja el hacer el sistema más comprensible de forma intuitiva, ya que resulta más sencillo razonar y proponer modelos teóricos sirviéndose de interacciones parametrizadas. Por otra parte, es posible trabajar con sistemas mucho mayores, ya que los cálculos cuánticos completos son mucho más costosos computacionalmente. La principal desventaja de los hamiltonianos efectivos es que carecen por sí mismos de poder predictivo: han de apoyarse en datos experimentales (o en cálculos rigurosos) externos para estimar los valores de los parámetros.

En la descripción de compuestos magnéticos, se usan comúnmente hamiltonianos efectivos en vez de, por ejemplo, el hamiltoniano molecular completo, que incluye gran cantidad información química que resulta irrelevante para la descripción de las propiedadesmagnéticos. Se habla, por ejemplo, de hamiltonianos de espín para describir fenómenos tan variados como el campo de ligantes, el canje magnético, el acoplamiento espín-órbita, el desdoblamiento a campo nulo, el efecto Zeeman, la estructura hiperfina o el acoplamiento vibrónico. Efectivamente, los principales operadores incluidos en estos hamiltonianos sólo dependen de variables de espín, como formula_1, formula_2 y/o formula_3.

Por otro lado un modelo físico práctico es una realización material concreta, con la que no necesariamente pretende construirse una teoría sino ampliar el conjunto de hechos observados que pueden servir para confirmar o reformular las teorías. Estos modelos físicos prácticos son objeto de experimentos sobre los que amplian la base de los hechos observados. En física los modelos físicos prácticos son sólo un paso intermedio hacia la formulación de modelos físicos teóricos, que a su vez son la base de las teorías físicas.
En ingeniería los modelos físicos, por contraposición a los modelos matemáticos y a los modelos analógicos,normalmente son construcciones en escala reducida o simplificada de obras, máquinas o sistemas de ingeniería para estudiar en ellos su comportamiento y permitir así perfeccionar los diseños, antes de iniciar la construcción de las obras u objetos reales. Por ese motivo, a este tipo de modelo se le suele llamar también modelo reducido o modelo simplificado.

Se utilizan con frecuencia para el estudio de represas, puentes, esclusas, puertos, aeronaves en túneles de viento, etc. Muchas veces, para obras complejas como, por ejemplo, una represa, se puede requerir la construcción de más de un modelo. En este ejemplo se acostumbra estudiar un modelo general de la disposición de la presa, con todas sus partes, un modelo específico a una escala mayor para el vertedero y la cuenca de disipación, otro para la o las bocatomas, uno diferente para la descarga de fondo.




</doc>
<doc id="28261" url="https://es.wikipedia.org/wiki?curid=28261" title="Fanático (película)">
Fanático (película)

Fanático (El Fanático en Hispanoamérica) es una película estadounidense de 1996, dirigida por Tony Scott.

Bobby Rayburn (Wesley Snipes) es un jugador de béisbol que ha estado en los mejores puestos de la liga nacional. Se incorpora al equipo de los San Francisco Giants. Un aficionado obsesivo que se dedica a la venta de navajas para cazar, Gil Renard (Robert De Niro), está entusiasmado con este fichaje. Sin embargo, Bobby juega muy mal durante esa temporada y Renard hace todo lo posible para ayudarle. Pero va demasiado lejos.


Película basada en el libro del mismo título de Peter Abrahams. La discográfica "TVT" lanzó un disco recopilatorio con la banda sonora de la película en agosto de 1996.



</doc>
<doc id="28262" url="https://es.wikipedia.org/wiki?curid=28262" title="Artes escénicas">
Artes escénicas

Las artes escénicas son las artes destinadas al estudio y/o práctica de cualquier tipo de obra escénica o escenificación. Toda forma de expresión capaz de inscribirse en la escena: el teatro, la danza, la música, el cine y, en general, cualquier manifestación del denominado mundo del espectáculo ("show business" -farándula-) o que se lleve a cabo en algún tipo de espacio escénico, habitualmente en las salas de espectáculos, pero también en cualquier espacio arquitectónico o urbanístico construido especialmente o habilitado ocasionalmente para realizar cualquier tipo de espectáculo en vivo, como ocurre con los espectáculos ambulantes (como el circo, el guion, los tradicionales cómicos de la legua y comedia del arte o el actual teatro callejero). 
Las partes Otras expresiones, como desfiles, procesiones de Semana Santa y multitud de ritos religiosos, fiestas populares, o carnavales, tienen una clara dimensión escénica.

El espacio de las artes escénicas, aparte de notables diferencias producidas por los distintos conceptos que del espectáculo y todo lo referido a este mundo, se han tenido que cambiar a lo largo de la historia, mantienen inalterable una cierta disposición de ámbitos dependiendo de la utilización que de ellos se haga. Esto hace referencia a aquellas zonas que van a albergar los dos elementos esenciales para que el espectáculo se produzca: los actores y el público.

El teatro sacro es tan antiguo como el propio teatro, pues puede considerarse su causa de aparición. Junto con los olímpicos y los demás Juegos Panhelénicos (píticos, ístmicos y nemeos) el teatro griego nació como una más de las competiciones sagradas musicales y poéticas (como en Roma serían los juegos florales). El considerado fundador del teatro, Tespis, lo fue por ser el primer ganador de uno de estos certámenes: las Dionisias de Atenas (536 a. C.). El teatro adquirió enseguida, especialmente en las tragedias, una evidente función ritual y espiritual. Destacaba su función purificadora (la "catarsis") además de la transmisión de altos valores morales; y de informar a los espectadores de cuál era su papel como hombres y ciudadanos dentro de la "polis" y del "cosmos" junto a los demás hombres y los dioses, y le invitaba a identificarse con los héroes conducidos por su destino a una misión trascendente.

Las civilizaciones asiáticas desarrollaron artes escénicas también con profundos sentidos religiosos y sociales, entre los que la reproducción y vivencia de los mitos alcanzaba la mayor importancia (teatro chino, teatro japonés, cultura de Indonesia, teatro de Bali -"ketchak", representación colectiva del Ramayana de altísima fuerza expresiva-)

El teatro sacro cristiano, precedente inmediato del teatro clásico europeo del Renacimiento y el Barroco, surgió en la Edad Media (drama litúrgico, auto sacramental, misterio (teatro), moralidad (teatro)); y junto con la música sacra tuvo en las iglesias y catedrales el contexto escénico para el que fue concebido.



</doc>
<doc id="28263" url="https://es.wikipedia.org/wiki?curid=28263" title="Feliz Navidad, Mr. Lawrence">
Feliz Navidad, Mr. Lawrence

Feliz Navidad, Mr. Lawrence es una película de 1983, dirigida por Nagisa Oshima, basado en el libro "The seed and the sower", de Laurens van der Post.

Durante la Segunda Guerra Mundial el mayor australiano Jack Celliers (David Bowie) llega a un campo de prisioneros japonés. El comandante del campo, el capitán Yonoi (Ryuichi Sakamoto) impone valores como la disciplina, el honor y la gloria al más puro estilo nipón, pero su celo oculta una homosexualidad reprimida ya que desvelarla le reportaría la ignominia absoluta. El comandante, en su extremo celo en el honor y la gloria, afirma que los soldados aliados son cobardes al entregarse en vez de suicidarse.

El argumento se complicará al enamorarse el comandante de Jack Celliers, provocando no pocas tensiones entre guardianes y prisioneros, a lo que se debe añadir el choque de la mentalidad nipona contra la británica. Uno de los prisioneros, el teniente coronel John Lawrence (Tom Conti), tratará de explicar a sus compañeros la forma de pensar de los japoneses, pero estos le considerarán un traidor.


</doc>
<doc id="28264" url="https://es.wikipedia.org/wiki?curid=28264" title="Flecha rota">
Flecha rota

La película "Flecha rota" fue un western norteamericano de 1950, basada en la novela "Blood Brother" de Elliott Arnold. Obtuvo tres nominaciones a los Oscar, al mejor actor de reparto (Jeff Chandler), al mejor guion, y a la mejor fotografía.

En 1870 ya son diez los años de luchas sangrientas entre los colonos y los apaches del jefe Cochise. Tom Jeffords (James Stewart) es un soldado licenciado que salva la vida a un niño apache. A raíz de ello quiere averiguar si los indios son humanos y agradecen lo que ha hecho.

Decide aprovechar esta circunstancia para convertirse en intermediario entre los apaches y los blancos. Contra todo pronóstico, su actuación en solitario es bien recibida por Cochise y se establece un diálogo.

El presidente de la nación envía un general para que llegue a un acuerdo de paz con los Apaches. Pero el odio acumulado en ambos bandos pone en peligro todo el trabajo realizado por Jeffords.

</doc>
<doc id="28265" url="https://es.wikipedia.org/wiki?curid=28265" title="Forja de hombres">
Forja de hombres

Forja de hombres es una película de 1938, dirigida por Norman Taurog. La película ganó dos Oscar: al (Spencer Tracy, como el padre Edward J. Flanagan), y a la mejor historia original (Eleanore Griffin y Dore Schary); y obtuvo otras tres nominaciones: a la mejor película, al mejor director, y al mejor guion original.

El padre Flanagan (Spencer Tracy) consigue fundar en contra de todos los pronósticos la Ciudad de los Muchachos, un lugar en el que viven jóvenes descarriados y donde reciben una educación para convertirse en personas útiles. Whitey (Mickey Rooney) es uno de ellos, pero se escapa varias veces. La primera vuelve hambriento, la segunda porque un compañero se ha lesionado. La última vez se une a la banda de malhechores de su hermano. El padre Flanagan y los muchachos acaban capturando la banda y reciben la recompensa que había ofrecido la población. Con este dinero el futuro de la "ciudad" está asegurado.


</doc>
<doc id="28266" url="https://es.wikipedia.org/wiki?curid=28266" title="The Killers (película)">
The Killers (película)

The Killers (conocida en español por los títulos de Los asesinos, Asesinos y Forajidos) es una película estadounidense de 1946 dirigida por Robert Siodmak, esta basada en el cuento homónimo de Ernest Hemingway. Esta protagonizada por Burt Lancaster, Ava Gardner, Edmond O'Brien y Sam Levene. Tuvo cuatro candidaturas a los premios Óscar: al , al , a la y al .

En el 2008, la película fue considerada «cultural, histórica y estéticamente significativa» por la Biblioteca del Congreso de Estados Unidos y seleccionada para su preservación en el National Film Registry.

Dos asesinos a sueldo llegan a una pequeña población y matan al empleado de una gasolinera: Ole Andreson "el Sueco" (Burt Lancaster), que los estaba esperando. El detective Reardon (Edmond O'Brien) investiga el caso para la compañía de seguros de la que es empleado, a pesar de que su jefe le dice que no lo haga, por tratarse de un asunto de poca importancia económica. Reardon comienza a atar cabos y descubre que la vida de "el Sueco" estuvo llena de engaños y de crímenes, y que en todo ello tenía algo que ver la misteriosa Kitty Collins (Ava Gardner).

En 1958, Andréi Tarkovski, en ese entonces un estudiante de cine, creó un cortometraje de 19 minutos basado en la historia.

De la misma obra de Hemingway se haría más tarde otra adaptación: "El código del hampa" ("The Killers", 1964), dirigida por Don Siegel y con Lee Marvin, John Cassavetes, Angie Dickinson y Ronald Reagan como actores principales.



</doc>
<doc id="28268" url="https://es.wikipedia.org/wiki?curid=28268" title="Fort Bravo">
Fort Bravo

Fort Bravo es una película estadounidense de 1953, del género western, dirigida por John Sturges. Protagonizada por William Holden, Eleanor Parker, John Forsythe, William Demarest, Polly Bergen. 

Durante la Guerra de Secesión, Fort Bravo se ha convertido en un campo de prisioneros confederados. Debido a su ubicación alejada y a los indígenas hostiles que se encuentran en la zona, resulta muy difícil escapar. Aun así, los prisioneros que lo intentaron fueron capturados por el comandante Roper ("William Holden"), un hombre implacable. Un grupo de prisioneros desarrolla un plan para poder fugarse. Consiguen traer al fuerte a una atractiva mujer sureña, Carla Forester ("Eleanor Parker"), que deberá distraer la atención del comandante. Al principio todo indica que el plan tendrá éxito, pero el comandante no adopta la actitud adecuada respecto a la mujer.

</doc>
<doc id="28270" url="https://es.wikipedia.org/wiki?curid=28270" title="Flor de cactus">
Flor de cactus

Flor de cactus es una película estadounidense de 1969, comedia dirigida por Gene Saks y protagonizada por Walter Matthau, Ingrid Bergman, y Goldie Hawn. El guion es una adaptación de una obra de teatro de Broadway, escrita por Abe Burrows, que se basó en la obra francesa "Fleur de cactus" de Pierre Barillet y Jean-Pierre Grédy. La película fue la séptima película más taquillera de 1970.

La película comienza con Toni Simmons, de 21 años de edad, tratando de cruzar la carretera para enviar una carta. Posteriormente, regresa a su apartamento e intenta ahogarse usando una estufa de segunda mano. Afortunadamente, su vecino, Igor Sullivan, huele el gas y la rescata de la muerte inminente, usando la respiración de boca a boca, que evoluciona a un beso francés después de que Toni recupera el conocimiento.

La trama de la película se mueve a causa del intento de suicidio. El amante de Toni, Dr Julian Winston, un dentista soltero y mujeriego, había dicho a Toni que tenía esposa y tres hijos, para romper la relación y evitar el compromiso. Sin embargo, al enterarse del intento de suicidio, decide replantearse su condición de soltero y casarse con Toni, pero necesita una mujer de la que divorciarse para no descubrir su mentira.

A fin de resolver su problema, el Dr. Watson decide pedir a la señorita Stephanie Dickinson, su enfermera sueca solterona desde hace diez años, que se haga pasar por su mujer. Aunque al principio se niega, finalmente acepta el papel, ya que está enamorada secretamente de su jefe. Cuando Toni conoce a la señorita Dickinson se da cuenta de que también ama a Julian y se le ocurre que Julian ayude a la señorita Dickinson a encontrar a otro hombre, para que todo el mundo sea feliz. Para resolver la situación, Julian involucra a otros personajes, incluyendo a su amigo Harvey, el señor Arturo Sánchez, e Igor. En última instancia, Toni se entera de la mentira y deja Julian por Igor, mientras que Julian se enamora de la señorita Dickinson.

El título de la película es sobre un cactus que la señorita Dickinson mantiene sobre su escritorio en la consulta del dentista. Como la propia señorita Dickinson, el cactus es frío e inhóspito. Sin embargo, al final, tanto el cactus y Stepahnie florecen.

Película basada en la obra teatral "Fleur de cactus" de Pierre Barillet y Jean-Pierre Grédy. Goldie Hawn ganó un y un Globo de Oro a la mejor actriz de reparto, además, recibió una nominación a los BAFTA a la mejor actriz. 

Además del premio para Goldie en los Globo de Oro, la película recibió otras cuatro nominaciones: Globo de Oro a la mejor película - Comedia o musical Ingrid Bergman: Globo de Oro a la mejor actriz - Comedia o musical, Globo de Oro a la mejor canción original y Globo de Oro a la nueva estrella del año - Actriz.

En su lanzamiento, la película recibió una aclamación considerable, tanto por la crítica como por el público en general, convirtiéndose en una de las películas más taquilleras de 1969 y 1970. Howard Thompson, de The New York Times señaló que "tanto el escenario expansivo de I.A.L. Diamond como la dirección flexible de Gene Saks abren e incluso ventilan la historia". Roger Ebert declaró que "la química funciona" y "la película resulta mejor que la puesta en escena".


</doc>
<doc id="28272" url="https://es.wikipedia.org/wiki?curid=28272" title="Esmog fotoquímico">
Esmog fotoquímico

Se denomina esmog fotoquímico a la contaminación del aire, principalmente en áreas urbanas, por ozono originado por reacciones fotoquímicas, y otros compuestos. Como resultado se observa una atmósfera de un color plomo o negro. El ozono es un gas oxidante y tóxico que puede provocar en el ser humano problemas respiratorios.

Este tipo de esmog se describió por primera vez en Los Ángeles en los años 40, y se suele dar en ciudades con bastante tráfico (emisión de monóxido de nitrógeno, NO, y compuestos orgánicos volátiles, COVs), cálidas y soleadas, y con poco movimiento de masas de aire.

Los principales contaminantes primarios son los óxidos de nitrógeno (NO) y los compuestos orgánicos volátiles.

El monóxido de nitrógeno (u óxido nítrico) se forma cuando el oxígeno y el nitrógeno atmosféricos reaccionan a altas temperaturas. Esta reacción se da, por ejemplo, en los motores de combustión de los automóviles de la siguiente forma:

Sin embargo, el óxido nítrico es una molécula altamente inestable en el aire, ya que se oxida rápidamente en presencia de oxígeno, convirtiéndose en dióxido de nitrógeno según la reacción:

Entre los compuestos orgánicos volátiles (COVs) se encuentran los hidrocarburos no quemados que pueden ser emitidos también por vehículos, así como disolventes o combustibles que se pueden evaporar fácilmente. También éstos pueden provenir de zonas arbóreas, al emitirse de forma natural hidrocarburos, principalmente isopreno, pineno y limoneno.

Los contaminantes secundarios, formados a partir de los anteriores, a través de una serie compleja de reacciones propiciadas por la radiación solar, son el ozono, el HNO, el nitrato de peroxiacilo (PAN) y otros compuestos.

Durante el día el dióxido de nitrógeno se disocia en monóxido de nitrógeno y radicales oxígeno:
El O· se combina con oxígeno molecular generando ozono:
En ausencia de COVs este ozono oxida al monóxido de nitrógeno de la etapa anterior:
Pero en presencia de COVs, éstos se transforman en radicales peroxi que a su vez oxidan al NO:
formula_6
De esta forma el NO no está disponible para reaccionar con el ozono y éste se acumula en la atmósfera.

Muchos de los radicales RO· generados terminan formando aldehídos. Éstos, cuando la concentración de NO es baja (conforme avanza el día), pueden reaccionar con NO dando lugar a compuestos del tipo RCOOONO (cuando R es un metilo se denomina peróxido de acetilnitrato, PAN, un compuesto tóxico).

La formación del HNO se produce al final del día por reacción del NO con radicales oxhidrilo:
Durante la noche los radicales OH· pueden reaccionar con el NO dando ácido nitroso, que se disocia en presencia de luz, pero es estable durante la noche.
Durante la noche las reacciones de "smog" fotoquímico se ven muy reducidas al necesitar la luz para funcionar, aunque éstas pueden continuar a través de otros compuestos.

Para reducir la formación de "smog" fotoquímico es necesario disminuir la emisión de los NO y los COVs.

Las cantidades de hidrocarburos volátiles en la atmósfera son bastante grandes comparadas con las de NO, por lo que suelen estar en exceso. De esta forma, una reducción de éstos conduce a una disminución del "smog" fotoquímico menor de la esperada. Además, los hidrocarburos emitidos de forma natural pueden ser suficientes para que siga produciéndose "smog" (aunque en áreas urbanas no suelen ser éstos los más importantes). En cualquier caso, sigue siendo importante la reducción de los niveles de estos hidrocarburos volátiles en la atmósfera.

Una de las mayores fuentes de NO la constituyen los vehículos. La disminución de las emisiones de óxidos de nitrógeno se hace empleando catalizadores de tres vías (los de dos vías no tratan estos gases) que los reducen a nitrógeno y oxígeno moleculares. Estos catalizadores, en el caso de los motores de gasolina, tienen una efectividad de entre un 80% a un 90%, pero sólo cuando están calientes. Además, el catalizador se va desgastando y con el tiempo va siendo menos efectivo. En el caso de los motores diésel, la efectividad es menor.

Otra de las principales fuentes de NO es la emisión de las centrales eléctricas. También se pueden disminuir los NO mediante procesos de reducción, aunque hay otros métodos como por ejemplo llevando a cabo la combustión en varias etapas o disminuir la temperatura de la llama.



</doc>
<doc id="28273" url="https://es.wikipedia.org/wiki?curid=28273" title="Eiffel (lenguaje de programación)">
Eiffel (lenguaje de programación)

Eiffel es un lenguaje de programación orientado a objetos que sigue el estándar ISO diseñado por Bertrand Meyer (defensor de los lenguajes orientados a objetos y autor de la construcción de Software Orientado a Objetos) y Software Eiffel. El diseño del lenguaje esta estrechamente relacionado con el método de programación Eiffel. Ambos se basan en una serie de principios incluyendo: el diseño por contrato, la separación de comandos y consultas, el principio de acceso uniforme, el principio de elección única, el principio abierto-cerrado y la separación operación-operando.

Muchos conceptos inicialmente introducidos por Eiffel aparecen más tarde en Java, C# y otros lenguajes. Nuevas ideas de diseño de lenguaje, particularmente a través del proceso de estandarización ECMA/ISO, se continúan incorporando al lenguaje Eiffel.

Las características claves del lenguaje Eiffel incluyen:

Eiffel destaca enunciados declarativos sobre el código de procedimiento y los intentos de eliminar la necesidad de instrucciones de contabilidad.
Eiffel evita trucos o técnicas de codificación destinadas como sugerencias de optimización para el compilador. El objetivo no es sólo para hacer el código más fácil de leer, sino también para permitir a los programadores concentrarse en los aspectos importantes de un programa sin atascarse en los detalles de implementación. La simplicidad de Eiffel está destinada a promover respuestas sencillas, extensibles, reutilizables y fiables a los problemas informáticos. Los compiladores de programas informáticos escritos en Eiffel ofrecen amplias técnicas de optimización, tales como autommatic in-lining, que alivian el programador de parte de la carga, mientras que la optimización de la producción de código cuya eficacia es comparable a la de código escrito en C++ [cita requerida].

Eiffel fue desarrollado originalmente por Eiffel Software, una compañía fundada por Bertrand Meyer. El Software de Construcción Orientado a Objetos contiene un tratamiento detallado de los conceptos y la teoría de la tecnología de objetos que llevaron al diseño de Eiffel.

El objetivo de diseño detrás del lenguaje Eiffel, las librerías y los métodos de programación es permitir a los programadores crear módulos de software fiables y reutilizables. Eiffel soporta herencia múltiple, generalidad, polimorfismo, encapsulación, conversiones de tipo seguro, y covarianza de los parámetros. La contribución más importante de Eiffel de la ingeniería de software es el diseño por contrato (DBC), en el que se emplean las aserciones, precondiciones, postcondiciones y clases invariantes para ayudar a garantizar la corrección del programa sin sacrificar la eficiencia.

El diseño de Eiffel se basa en la teoría de la programación orientada a objetos, con solo un poco influencia de otros paradigmas o algunos conceptos por el soporte de código heredado. Eiffel soporta formalmente los tipos abstractos de datos. En el diseño de Eiffel, un texto de software debe ser capaz de reproducir su documentación de diseño del texto en si, usando una implementación formalizada del tipo de datos abstracto. El lenguaje interactivo de aprendizaje Blue, precursor de BlueJ, también está basado en Eiffel. El Apple Media Tool incluye un Apple Media Lenguaje basado en Eiffel.

EiffelStudio es un entorno de desarrollo integrado disponible en virtud de un código abierto o licencia comercial. Ofrece un entorno orientado a objetos para la ingeniería del software. EiffelEnvision es un plugin para Microsoft Visual Studio que permite a los usuarios editar, compilar y depurar proyectos Eiffel desde el Microsoft Visual Studio IDE. EiffelStudio y EiffelEnvision son gratuitos para uso no comercial. Hay otras cuatro implementaciones de código abierto: "The Eiffel Compiler" tecomp, Gobo Eiffel, SmartEiffel - la implementación GNU, basada en una versión anterior del lenguaje-, LibertyEiffel-basado el compilador de SmartEiffel- y VisualEiffel.

Diversos lenguajes de programación incorporan elementos aportados por primera vez en Eiffel. Sather, por ejemplo, se basó originalmente en Eiffel, pero ha variado desde entonces, y ahora incluye características de la programación funcional.

La definición del lenguaje Eiffel es un estándar internacional de la ISO. El estándar fue desarrollado por Ecma International, que por primera vez aprobada la norma, el 21 de junio de 2005, como estándar ECMA 367, Eiffel: Analysis, Design and Implementation Language. En junio de 2006, ECMA e ISO aprobaron la segunda versión. En noviembre de 2006, la ISO publicó por primera vez. El estándar se puede encontrar y utilizar de una manera gratuita en la web de ECMA. La versión de ISO es idéntica en todos los aspectos salvo en el formato.

El estándar cita los siguientes predecesores de especificaciones del lenguaje Eiffel:

La versión actual del estándar de junio de 2006 contiene algunas inconsistencias (por ejemplo, las redefiniciones de la covarianza). El comité ECMA no ha anunciado ningún calendario ni en que dirección se resolverán estas inconsistencias.

Un "sistema" o "programa" Eiffel es una colección de clases. Por encima del nivel de clases, Eiffel define el cluster, que es esencialmente un grupo de clases, y posiblemente de subclubsters. Las agrupaciones no son una estructura de control sintáctica, sino más bien una convención de la organización estándar. Normalmente una aplicación Eiffel se organizara con cada clase en un archivo separado, y cada clúster en un directorio o carpeta que contiene los ficheros de las clases. En esta organización, los subclústers son subdirectorios. Por ejemplo, en virtud de las convenciones estándar de la organización y el entorno, x.e podría ser el nombre de un fichero que define una clase llamada X.

Una clase contiene características, que son similares a los "miembros, "atributos" o "métodos" en otros lenguajes de programación orientados a objetos. Una clase también define a sus invarianzas,y contiene otras propiedades, como una sección de "notas" para documentación y metadatos. Los tipos estándar de datos como entero, string o array, son todos ellos clases.

Cada sistema tiene que tener una clase designada como raíz, y uno de sus procedimientos de creación designado como "procedimiento raíz". La ejecución de un sistema consiste en la creación de una instancia de la clase raíz y en ejecutar el procedimiento raíz. En general, eso crea nuevos objetos, llama a nuevas características, y así sucesivamente.

Eiffel tiene cinco instrucciones básicas ejecutables: asignación, creación de objetos, llamada de rutina, condición, e iteración. Las estructuras de Eiffel de control son estrictas en el cumplimiento de la programación estructurada: cada bloque tiene exactamente una entrada y una salida.

A diferencia de muchos lenguajes orientados a objetos, pero como Smalltalk, Eiffel no permite una asignación en los campos de los objetos, excepto dentro de las características de un objeto. Eiffel hace hincapié en ocultar la información, y la abstracción de datos, en requerir interfaces formales para la mutación de datos. Para expresarlo en el formato de otros lenguajes orientado a objetos, todos los campos Eiffel son privados, y los métodos "set" son necesarios para modificar los valores. Una consecuencia de esto es que el método "set" puede, y normalmente lo hace, implementa las invariancias por los cuales Eiffel proporciona sintaxis.

El primer contacto con un lenguaje de programación se hace a menudo con el uso de un programa "Hola, mundo!". Este programa escrito en Eiffel podría ser:

Este programa contiene la clase codice_1. El constructor (rutina creadora) para la clase, de nombre codice_2, invoca codice_3 que es la rutina de la biblioteca del sistema para escribir un mensaje codice_4 codice_5 al dispositivo de salida.

El concepto de diseño por contrato es fundamental para Eiffel. Los mecanismos están estrechamente integrados con el lenguaje. Los contratos guian la redefinición de las características en la herencia.

Además, el lenguaje soporta una "instrucción de verificación" (una especie de "asserción") y los invariantes de bucle.

La propiedad principal de una clase es que contiene un conjunto de características. Como una clase presenta un conjunto de objetos en tiempo de ejecución, o "casos", una característica es un atributo o una operación en estos objetos. Hay dos tipos de funciones: consultas y órdenes. Una consulta proporciona información sobre una instancia. Una orden modifica una instancia.

La distinción consulta-orden es importante para el método Eiffel. En particular:

Eiffel no permite la sobrecarga de argumentos. Cada nombre de característica dentro de una clase siempre se asigna a una característica específica dentro de la clase. Un nombre, dentro de una clase, significa una cosa. Esta opción de diseño ayuda a la legibilidad de las clases, evitando una de las causas de ambigüedad sobre que rutina será invocada con una llamada. También simplifica el mecanismo del lenguaje. En particular, eso es lo que hace posible el mecanismo de la herencia múltiple de Eiffel.

Los nombres pueden, por descontado, son reutilizadas en diferentes clases. Por ejemplo, el operador "+" se define en diversas clases: INTEGER, REAL, STRING, etc.

Las clases pueden ser genéricas, para expresar que están parametrizadas para tipos. Los parámetros genéricos aparecen entre corchetes:
codice_6 se conoce como un "parámetro formal genérico". (Eiffel reserva "argumento" para las rutinas, y utiliza "parámetro" solo para las clases genéricas.) Con esta declaración codice_6 representa dentro de la clase un tipo arbitrario, para el que una función puede retornar un valor de tipo codice_6, y una rutina puede tener un argumento de este tipo:

La codice_9 y codice_10 són "derivaciones genéricas" de esta clase. Combinaciones permitas (y con codice_11, codice_12, codice_13, codice_14) son:

codice_15 y codice_16 son los "parámetros genéricos actuales" en estas derivaciones genéricas.

También es posible tener "restricciones" de los parámetros formales, de manera que el parámetro real a de heredar de una clase dada, la "restricción". Por ejemplo, en

una derivación codice_17 es válida únicamente si codice_18 hereda de codice_19 (como de hecho hacen las típicas bibliotecas Eiffel). Dentro de la clase, después de haber restringido codice_20 mediante codice_19 que para codice_22 es posible aplicar a codice_23 todas las características de codice_19, como en codice_25.

Para heredar de otra o otras, una clase incluirá una cláusula de heredar al principio:
La clase puede redefinir algunas o todas les características heredadas. Eso ha de ser declarado explícitamente al comienzo de la clase a través de la cláusula codice_26 subcláusula de la cláusula de herencia, como en:
Las clases se pueden definir con deferred class en lugar de con class para indicar que la clase no puede ser instanciada directamente. Las clases no instanciables se dicen clases abstractas en otros lenguajes de programación orientados a objetos. En el lenguaje Eiffel, solo se pueden crear instancias de una clase "efectiva" (que puede ser una descendiente de una clase diferida). Una característica también puede ser diferida mediante cláusula deferred en lugar de una cláusula do. Si una clase tiene características diferidas se ha de declarar como diferida, pero, no obstante una clase sin características diferidas puede ser diferida por si misma.
Las clases diferidas juegan un papel parecido al de las interfaces en lenguajes como Java, a pesar de que muchos teóricos de la programación orientada a objetos crean que las interfaces son en gran medida una respuesta a la falta de Java de herencia múltiple (que tiene Eiffel).

Una clase que hereda de otra u otras obtiene todas sus características, por defecto con sus nombres originales. Puede cambiar el nombre a través de la cláusula rename. Eso es necesario en el caso de herencia múltiple si hay conflictos de nombres entre las características heredadas, sin cambiar el nombre, la clase resultante violaría el principio de no sobrecargar, antes mencionada, y por tanto, no seria válida.

Los tipos tuples pueden ser vistos como una forma simple de clase, proporcionando solo los atributos y el correspondientemente método "set". Un tipo tupla típico
podría ser utilizado para describir una simple acta de nacimiento si no fuese necesaria una clase. Un ejemplo de esta tupla es simplemente una secuencia de valores con el tipo dado, entre paréntesis, como
Los componentes de una tupla como tal se pueden acceder si las etiquetas de la tupla son atributos de una clase, por ejemplo, si t ha sido asignado a la tupla entonces t.pes tiene un valor 3.5.
Gracias a la noción de asignador de órdenes, la notación de puntos también se puede utilizar para asignar los componentes de esta tupla, como en
Las etiquetas tuple son opcionales, de manera que también es posible escribir un tipo tupla como TUPLE [STRING, REAL, DATE]. (En algunos compiladores esta es la única forma de tuple, ya que las etiquetas se van introduciendo en el estándar ECMA).
La especificación precisa de, por ejemplo, TUPLE [A, B, C] que describe secuencias de al menos tres elementos, el primero de tres que son de los tipos A, B, C, respectivamente. Como resultado TUPLE [A, B, C] se ajusta a (se puede asignar a) TUPLE [A, B], a TUPLE [A] y TUPLE (sin parámetros), la tuple más grande se ajusta a todas las otras tuples.

El mecanismo del' "agente" de Eiffel agrupa les operaciones dentro de los objetos. Este mecanismo puede ser utilizado por la interacción, la programación dirigida por eventos, y en otros contextos es útil para pasar operaciones alrededor de la estructura del programa. Otros lenguajes de programación, especialmente los que hacen énfasis en la programación funcional, permiten un patrón similar con las continuaciones, clausuras, o generadores; los agentes Eiffel enfatizan el paradigma de los lenguajes orientados a objetos, y usa una sintaxis y semántica similares a los bloques de código en Smalltalk y Ruby.
Por ejemplo, para ejecutar el bloque accion_propia para cada elemento de lista_propia, se podría escribir:
Para ejecutar accion_propia solo los elementos que satisfacen condicion_propia, una limitación de filtro se puede añadir:
En estos ejemplos, accion_propia y condicion_propia son rutinas. Prefijándolos con agente cede un objeto que representa la rutina correspondiente, con todas sus propiedades, en particular, la capacidad de ser llamado con los argumentos adecuados. Así que si a representa un objeto (por ejemplo, porque a es el argumento para do_all), la instrucción
llamara a la rutina original con el argumento x, como si hubiesen llamado directamente a la rutina original: accion_propia (x). Los argumentps para llamar se pasan como una tupla, aquí [x].
Es posible mantener algunos argumentos para un agente abierto y hacer los otros cerrados. Los argumentos abiertos se pasan como argumentos para la llamada (call): que se proporcionan en el momento de utilizar el agente. Los argumentos son siempre cerrados en el momento de la definición de el agente. Por ejemplo, si acción2 tiene dos argumentos, la iteración
itera acción2 (x, y) para valores sucesivos de x, donde el segundo argumento ha quedado establecido en y. El signo de interrogación? indica un argument abierto, y es un argumento cerrado del agente. Hay que tener en cuenta que la sintaxis básica agent f es una abreviatura de agent f (?,?...) con todos los argumentos abiertos. También es posible crear el target de un agente libre a través de la notación {T}? donde T es el tipo de el objetivo.
La distinción entre operandos abiertos y cerrados (operandos = argumentos + target) corresponde a la distinción entre las variables libres i ligades en el cálculo lambda. Un agente de expressión, como acción2 (?, y) con algunos operandos cerrados y algunos abiertos corresponde a una versión de la operación original currificada sobre los operandos cerrados.
El mecanismo de agent ha estado recientemente generalizado por permetro la definición de un agent sin hacer referencia a una rutina existente (como accion_propia, condicion_propia, acción2), a través de agentes en línea como en
lista_propia.do_all (agent (s: STRING)
El agente en línea se ha pasado aquí puede tener todos la elementos de una rutina normal, incluyendo precondición, postcondición, la cláusula de rescate (aquí no se usa), y una signatura completa. Esto evita la definición de rutinas cuando todo lo que se necesita es un cálculo que se agrupara en un agent. Esto es útil en particular para los contratos, como en una cláusula invariante que expresa que todos los elementos de una lista son positivos:
El mecanismo agent actual deja una posibilidad de error en tiempos de ejecución (en caso de una rutina con n argumentos se pase a un agent que está esperando m arguments siendo m < n). Esto puede evitarse mediante un control en tiempo de ejecución a través de la precondición valid_arguments de la llamada (call). Hay diversas propuestas para una corrección puramente estática de este problema, incluyendo una propuesta de camabio en el lenguaje de Ribet y otros.

El resultado de una rutina puede ser almacenado en memoria caché y la palabra clave codice_27 en lugar de codice_28. Las llamadas a una rutina de estos tipos, salvo la primera vez, no requieren cálculos adicionales o la asignación de recursos, si no que simplemente devuelve un resultado previamente calculado con la primera llamada. Un patrón común para las "funciones de ejecución única" es proporcionar objetos compartidos, la primera llamada creara el objeto, a las subsiguientes volverá la referencia a este objeto. El esquema típico es:

El objeto retornado -codice_29 en el ejemplo- en si puede ser mutable, pero su referencia sigue siendo la misma.

A menudo, las "rutinas de ejecución única", realizan una inicialización necesaria: múltiples llamadas a una library que pueden incluir una llamada al procedimiento de inicialización, pero solo la primera llamada se realizan las acciones requeridas. Usando este patrón la inicialización puede ser descentralizada, evitando la necesidad de un módulo especial de inicialización. Las "rutinas de ejecución única" son similares en propósito y efecto al patrón Singleton de muchos lenguajes de programación, y para el patrón utilizado por Borg en Python.

Por defecto, una "rutina de ejecución única" se llama "una vez por hilo de ejecución". La semántica se puede ajustar a "una vez por proceso" o "una vez por objeto" calificando con una palabra clave ""once"", por ejemplo, codice_30.

Eiffel proporciona un mecanismo que permite las conversiones entre diferentes tipos. El mecanismo coexiste con el de herència y el de complementa. Para evitar cualquier confusión entre los dos mecanismos, el diseño ha de cumplir el siguiente principio:

Por ejemplo codice_31 puede ajustarse a codice_32, pero codice_15 (enter) se convierte en codice_34 (y no hereda de el).

El mecanismo de conversión simplemente generaliza las normas ad hoc de conversión (tal y como entre enteros -codice_15- y reales -codice_34-) que hay a la mayoría de los lenguajes de programación, haciéndole entonces aplicable a cualquier tipo siempre que se respecte este principio. Por ejemplo, una clase codice_37 puede ser declarada para convertir en codice_18; lo que hace posible la creación de un text a partir de un data simplemente a través de

como un acceso directo para el uso de la creación explícita de un objeto con un procedimiento de conversión:

Para hacer la primera forma posible como un sinónimo de la segunda, hay bastante con incluir el procedimiento de creación (constructor) codice_39 en una cláusula codice_40 al comienzo de la clase.

Como en otro ejemplo, si existe un procedimento de conversión incluye en codice_41, entonces uno puede asignar directamente una tupla a una data, haciendo que la conversión apropiada, como en
El Manejo de excepciones en Eiffel es basa en los principios de diseño por contrato. Por ejemplo, se produce una excepción cuando quien llama a una rutina no satisface la precondición, o cuando en una rutina no se puede garantizar el cumplimiento de la postcondición. En Eiffel, el tratamiento de excepciones no se utiliza para a les estructuras de control o para corregir errores de los datos de entrada.

Un controlador de excepciones Eiffel se define utilizando la palabra clave codice_42. Dentro de la sección codice_42, la palabra clave codice_44 ejecuta la rutina de nuevo. Por ejemplo, la siguiente rutina controla el número de intentos de ejecución de la rutina, y solo lo vuelve a intentar un cierto número de veces:
connect_to_server (server: SOCKET)
Esto ejemplo es, sin duda, imperfecto, pero en los programes más simples tendría que estar previsto que pueda fallar la conexión. Pero a la mayoría de los programes seria mejor un nombre de rutina como codice_45 y la postcondición no prometía una conexión, dejando a quien la llame el hecho de tomar las medidas apropiadas si la conexión no se ha abierto.

Hay disponibles varias librerías de redes y de hilos de ejecución, como EiffelNet y EiffelThreads. Un modelo de concurrencia de Eiffel, basado en los conceptos de diseño por contrato, es el SCOOP, o Programación Concurrente Simple Orientada a Objetos, aún no forma parte de la definición oficial del lenguaje, pero está disponible como a un "add-on" de ETH Zurich. CAMEO es una variación (no implementada) de SCOOP de Eiffel. La concurrencia también interactúa con las excepciones. Les excepciones asíncronas pueden ser un problema (una rutina activa una excepción después de que su llamada se termine).

La visión del cálculo en Eiffel es completamente orientada al objeto en el sentido que cada operación es relativa a un objeto, el'"objetivo". Así, por ejemplo, una suma

es conceptualmente entendida como si se tratase de una llamada a la función

con el objetivo codice_46, la característica codice_47 i el argumento codice_48.

Por descontado, [1] es la sintaxis convencional y la preferida normalmente. La sintaxis del operador hace posible el uso de una o de la otra manera, al declarar la función (por ejemplo, en codice_15 (nombre enter), pero eso se aplica a otras clases básicas y se puede utilizar en cualquier otro para que este operador sea apropiado):

La gamma de operadores que pueden utilizarse como un "alias" es bastante amplio, e incluyen operadores predefinidos como "+" pero también "los operadores libres" hechos de símbolos no alfanuméricos. Eso hace posible diseñar notaciones especiales infijos y prefijos, por ejemplo, en aplicaciones de matemáticas y de física.

Cada clase podrá tener "una" función alias de "[]", el operador "corchete", permito que la notación codice_50 como un sinónimo de codice_51 donde codice_52 es la función escogida. Eso es particularmente útil para las estructuras de contenedores, como matrices, tablas "hash", listas, etc. Por ejemplo, el acceso a un elemento de una tabla "hash" con claves "string" se puede escribir

Las "órdenes de asignación" son un mecanismo de acompañamiento diseñado con el mismo espíritu de permitir la solidez, la conveniente notación reinterpretada en el marco de la programación orientada a objetos. Las órdenes de asignación permiten sintaxis de asignación como llamadas a procedimentos ""setter"". Una asignación adecuada no puede ser de la forma codice_53 ya que esto viola la ocultación de información, se debe usar una orden "setter". Por ejemplo la clase tabla "hash" puede tener la función y el procedimento

Después, para insertar un elemento que debe utilizar una llamada explícita a la orden "setter":

Es posible escribir este equivalente como

(De la misma manera que codice_54 es un sinónimo de codice_55), siempre que la declaración codice_56 ahora comienza (substitución de [3]) con

Eso declara codice_57 como una orden de asignación asociada con codice_56 y, combinado con los alias de corchetes, hace [5] legal y equivalente a [4]. (También se puede escribir, sin aprovechar los corchetes, como codice_59.)

Nota: La lista de argumentos de la asignación de codice_46 está obligada a ser: (el tipo de retorno decodice_46, toda la lista de argumentos de codice_46...)

Eiffel no distingue entre mayúsculas y minúsculas. Eso quiere decir que codice_2, codice_64 y codice_65 corresponden todos ellos al mismo identificador. Veamos las "regles de estilo" a continuación.

Los comentarios son introducidos por -- (dos guiones consecutivos) y se extienden hasta el final de línea.

El punto y coma (;), como separador de instruccions, es opcional. La mayoría de las veces el punto y coma es omitido, excepto para separar múltiples instrucciones en una línea. Eso se traduce en menos desorden en la página del programa.

No hay anidación de las declaraciones de las características y de la clase. Como resultado la estructura de una clase Eiffel es simple: algunas cláusulas a nivel de clase (herencia, invariante) y una sucesión de declaraciones de características, están todas al mismo nivel.

Se acostumbra a agrupar las características en diferentes "cláusulas de características" para facilitar más la lectura, con un conjunto estándar de etiquetas de característica básica que figuren en un orden estándar, por ejemplo:

En contraste con los lenguajes de programación funcionales más complicados, Eiffel hace una clara distinción entre las expresiones y las instrucciones. Eso esta en consonancia con el principio de separación orden-consulta del método Eiffel.

Gran parte de la documentación de Eiffel utiliza las convenciones de estilo distintivas, diseñadas para velar por un aspecto consistente. Algunas de estas convenciones se aplican al formato de código en si, y otros para la representación tipográfica estándar del código Eiffel en formatos y publicaciones en las que estas convenciones son posibles.

Mientras que el lenguaje no distingue entre mayúsculas y minúsculas, las normas de estilo de prescriben que los nombres de clase estén totalmente en mayúsculas (codice_66), todo en minúsculas para nombres de características (codice_2), e iniciales en mayúscula para las constantes (codice_68). El estilo recomendado también sugiere el guion bajo (codice_69) para separar los componentes de un identificador de diversas palabras, como en codice_70.

La especificación de Eiffel incluye directrices para los textos del programa que muestra en formato composición tipográfica: palabras clave en codice_71, identificadores definidos por el usuario y las constantes se muestran en "codice_72", los comentarios, los operadores y marcas de puntuación en codice_73, con el texto del programa en azul como en el presente artículo para distinguirlo de un texto explicativo. Por ejemplo, el "Hola, mundo!" programa dado anteriormente quedaría de la siguiente manera en la documentación Eiffel:

class

Eiffel es un lenguaje puramente orientado a objetos, pero proporciona una arquitectura abierta para la interconexión con otro programa "externo" en cualquier lenguaje de programación.

Es posible, por ejemplo, programar a nivel máquina y sistema operativo en C. Eiffel proporciona una interfaz sencilla para las rutinas en C, incluido el soporte a "C en línea" (escribir el cuerpo de una rutina de Eiffel en C, en general para pequeñas operaciones a nivel máquina).

Aunque no exista una conexión directa entre Eiffel y C, muchos compiladores son Eiffel (Visual Eiffel no es una excepción) el Código fuente surgido de C como un lenguaje intermedio, a someter a un compilador de C, para la optimización y la portabilidad. El compilador Eiffel de tecomp puede ejecutar cogido Eiffel directamente (como un intérprete) sin tener que pasar a través de un código C intermedio ni emitir código C que se pasara a un compilador de C para obtener el código nativo optimizado. En.NET, el compilador EiffelStudio genera directamente código en CIL (Common Intermediate Language). El compilador SmartEiffel puede también generar la salida en bytecode de Java.



</doc>
<doc id="28274" url="https://es.wikipedia.org/wiki?curid=28274" title="Funny Girl">
Funny Girl

Funny Girl ("La Graciosa" y "Chica rara" en Hispanoamérica y "Una chica divertida" en España) es una película musical de 1968, dirigida por William Wyler y basada en la obra teatral del mismo título de Isobel Lennart. Streisand debutó en el cine con el papel que le había hecho famosa en los teatros de Broadway y Londres. Tuvo su secuela en "Funny Lady" en 1975.

La película relata la vida de la comediante Fanny Brice (Barbra Streisand), desde los días en los barrios judios de clase baja de Nueva York hasta la cumbre de su carrera artística con las Ziegfeld Follies. Durante esta época Fanny se casa con Nick Arnstein (Omar Sharif), del cual acaba divorciándose.

En el musical original de Broadway, Anne Bancroft sería la elegida para protagonizar el musical, pero a ella no le gustaron las canciones que le propusieron, entonces buscaron a Barbra Streisand y a Sidney Chaplin, ella obtuvo la segunda nominación al Tony como mejor actriz en un musical, que perdió contra la protagonista de "Hello Dolly" Carol Channing.




</doc>
<doc id="28276" url="https://es.wikipedia.org/wiki?curid=28276" title="Paso">
Paso

El término paso puede referirse a:







</doc>
<doc id="28278" url="https://es.wikipedia.org/wiki?curid=28278" title="Yasujirō Ozu">
Yasujirō Ozu

Siendo estudiante, Ozu se afincó en la prefectura de Mie, de donde era originario su padre y donde, según diría, descubrió el cine al resultar muy impresionado por "La cruz de la humanidad (Civilization)" de Thomas Harper Ince. Tras terminar sus estudios en la escuela de Ujiyamada de la ciudad de Ise (Mie), trabajó como profesor suplente durante un año en la escuela primaria Iidaka antes de regresar a Tokio, donde en 1923, gracias a una recomendación de su tío, empezó a trabajar en los Estudios Shochiku en Kamata. Allí empezó como ayudante de fotografía, pero tras tres años se hizo ayudante de dirección de Tadamoto Okubo. En 1927 se estrenó como director de un drama de época (el único de su filmografía) "Zange no yaiba ("La espada de la penitencia")".

Durante la Segunda Guerra Mundial, estuvo destinado en China. Cuando terminó la contienda se encontraba en Singapur, donde fue hecho prisionero. En 1947 volvió a la actividad con su guionista Kogo Noda; otros colaboradores regulares fueron el cámara Yuharu Atsuta y los actores Chishu Ryu y Setsuko Hara.

Como director era reconcentrado y perfeccionista. Era visto como uno de los directores "más japoneses" y, como tal, su trabajo era raramente mostrado en el extranjero antes de la década de los sesenta. No empleó el sonido hasta 1935 ("¿para qué buscar el ruido cuando reina el silencio?", decía, según recuerda A. Santos. Su plano característico era el tomado desde solamente unos 90 centímetros sobre el suelo, esto es, el punto de vista de un adulto sentado sobre un tatami. También fue un firme defensor de la cámara estática y las composiciones meticulosas donde ningún actor dominase la escena.

Ozu recibió una medalla del gobierno japonés en 1958, año en el que también ganó el premio de la Academia de las Artes de Japón. En 1959 se convirtió en el primer representante del mundo del cine en ingresar en dicha academia. En 1961 se celebró una retrospectiva de las películas de Ozu en el Festival de Cine de Berlín, donde el director y su obra recibieron la atención mundial. Donald Richie escribió, en 1974, la primera biografía de Ozu en inglés. Y en 1979 se hizo un amplio ciclo en la Semana Internacional de Cine de Valladolid, que había empezado a conocerse en cine-club y filmoteca.

Rodó un total de 53 películas, 26 de ellas en sus primeros cinco años como director. Y todas menos tres con los estudios Sochiku. Murió de cáncer en su sexagésimo cumpleaños, cuando se encontraba en el punto culminante de su fama. Fue enterrado en el cementerio de Engaku-ji, templo de la comunidad donde pasó sus últimos años, Kita Kamakura. 

Tras su muerte, la fama de Ozu alcanzó cotas aún más altas y su obra ha ejercido gran influencia en directores tanto de Japón como de otros países, tales como Jim Jarmusch, Wim Wenders, Claire Denis, Aki Kaurismäki y Hou Hsiao-Hsien.





</doc>
<doc id="28279" url="https://es.wikipedia.org/wiki?curid=28279" title="Obturador">
Obturador

En fotografía, el obturador es el dispositivo que controla el tiempo durante el que llega la luz al dispositivo fotosensible (película en la fotografía química o sensor en la fotografía digital). Este tiempo es conocido como la velocidad de obturación, y de él se desprenden conceptos como el congelado o el barrido fotográfico. Junto con la abertura del diafragma (apertura), la velocidad de obturación es el principal mecanismo para controlar la cantidad de luz que llega al elemento fotosensible.

Existen básicamente tres tipos de obturador: obturador de lámina simple en el extremo exterior del estenopo u objetivo, obturador central (o de laminillas) y de plano focal (o de cortina)

Un obturador de hoja simple es un tipo primitivo de obturador de la cámara fotográfica consiste en un mecanismo con uno o más hojas de metal pivotantes que normalmente no permiten que la luz penetre a través del objetivo y llegue a la película, pero que cuando se activa la apertura del obturador se mueven las hojas para descubrir la lente del objetivo durante el tiempo requerido para realizar la exposición, y posteriormente se cierra.

El obturador central lo incorporan los objetivos de gran formato, así como cámaras Cámara réflex de objetivos gemelos y algunas de formato medio como algunos modelos de Hasselblad. Suele encontrarse en el objetivo, y está compuesto por unas láminas que se abren de forma radial, de forma similar a la de un diafragma. Su ventaja es que pueden sincronizarse con el flash a cualquier velocidad, y su desventaja es que la velocidad máxima de exposición no puede superar 1/500 s.

El obturador de plano focal se encuentra en todas las cámaras réflex de único objetivo. Está situado justo delante del dispositivo fotosensible, y está formado generalmente por dos cortinillas, una de apertura y otra de cierre, que se mueven en la misma dirección.

Al presionar el botón de obturación, baja una cortinilla iniciando la exposición; posteriormente, una vez transcurrido el tiempo de exposición seleccionado, baja la segunda cortinilla cerrando la ventana que da paso de luz a la película. Una desventaja frente al obturador central es la dificultad de sincronización con el flash, que suele encontrarse entre 1/30 y 1/500 s, dependiendo de su tamaño y materiales utilizados. Esto es debido a que la primera cortina tarda un tiempo (relativamente) largo en realizar su recorrido, superior generalmente a la milésima de segundo; por lo tanto, en velocidades altas de obturación, la segunda cortina empieza a cerrarse antes de que la primera haya abierto completamente el cuadro; la exposición, por tanto, se forma por una franja de luz entre una cortina y la siguiente, en forma de barrido. El destello del flash dura una cantidad de tiempo muy breve (de milésimas a millonésimas de segundo), haciendo que la luz del destello ilumine únicamente la zona donde está la franja de luz que está expuesta en la película o el sensor. Esto puede resolverse con un flash que mantenga la iluminación durante el tiempo total que tarda la exposición en realizarse, por lo general son flashes especiales dedicados de cada marca (sincronización FP).

El obturador de plano focal era controlado de modo mecánico, alcanzando normalmente velocidades máximas entre 1/500 y 1/1000 s. La velocidad máxima alcanzada por medio puramente mecánico fue de 1/4000 s en la Nikon FM2, introducida en 1982.

Hoy en día los obturadores suelen ser controlados de modo electrónico mediante electroimanes. Con ello se consigue mayor precisión, velocidades que alcanzan los 1/12.000 como es el caso de las Minolta Dynax 9 y mejor control en velocidades lentas pudiéndose ajustar normalmente hasta 30 s.



</doc>
<doc id="28286" url="https://es.wikipedia.org/wiki?curid=28286" title="Monterrubio de la Demanda">
Monterrubio de la Demanda

Monterrubio, también conocido como "Monterrubio de la Demanda", es una localidad y un municipio situados en la provincia de Burgos, comunidad autónoma de Castilla y León (España), comarca de La Demanda, partido judicial de , cabecera del ayuntamiento de su nombre.

Monterrubio lleva en su apellido el nombre de la Sierra con todo el merecimiento, pues atesora las más sublimes esencias de esta región. Ganadero, minero, agrícola y forestal... de larga historia y buenas perspectivas de futuro, Monterrubio de la Demanda, recostado sobre la ladera, se asoma al balcón de la Sierra desde su privilegiada situación.

Se accede a Monterrubio siguiendo la ruta que desde Salas de los Infantes llega hasta Nájera, en el límite mismos de la provincia de Burgos con La Rioja. Durante la mayor parte del año, su población apenas llega al centenar de vecinos, triplicándose en verano. La villa está situada en la mitad norte de la Sierra de la Demanda, a más de 1.000 metros sobre el nivel del mar, en un territorio compuesto por montes, valles y collados en su mayor parte cubiertos por robles, pinos, hayas y acebos. La fauna, enormemente rica y variada, tiene ejemplos emblemáticos en especies como el corzo, el ciervo, el jabalí y, ocasionalmente, el lobo ibérico.

La vía verde que sigue el trazado del ferrocarril minero, que en su día unió Monterrubio con Villafría, nos permitirá penetrar en los secretos naturales de esta región y fuente de su riqueza. En la historia de la villa hay dos actividades que brillan con luz propia: la ganadería y la actividad minera. La primera estuvo vinculada al fenómeno histórico de la trashumancia; mientras que la segunda actividad, la explotación del subsuelo, fue iniciada en época de los romanos, y trajo a Moterrubio de la Demanda a finales del siglo XIX un nuevo impulso que se cerró a finales de la década de los 30 con el desmantelamiento de las vías del ferrocarril por parte de los propios vecinos.

Del noble pasado de la villa de Monterrubio de la Demanda dan fe los escudos labrados en varias fachadas de las casonas; aunque escasos, quedan restos de palacetes y casas señoriales. Entre los edificios religiosos destaca la iglesia parroquial de San Juan Bautista, que mezcla varios estilos que van desde el románico hasta la definitiva reforma realizada en el siglo XVIII. También destaca la ermita románica de Nuestra Señora de la Caraba, que data del siglo XI.

Pueblo situado al sureste de la provincia de Burgos, y que pertenece a la Comunidad de Castilla y León (España).

Yacimiento de cobre en las proximidades de la localidad: Descansadero de la Virgen, Los Hoyos de Veleto y San Juan.

Escudo Partido y medio cortado:
• Primero : En azur, torre de oro , mazonada de sable, con medio cuerpo de hombre en sus almenas mostrando un pendón de oro.
• Segundo: En gules, espadaña de oro.
• Tercero: En oro, horno a su color, flameante, acompañado de dos árboles (haya y pino).
• Entado en punta de sinople con cabeza de oveja merina en planta.
• Al Timbre, corona real cerrada.



</doc>
<doc id="28289" url="https://es.wikipedia.org/wiki?curid=28289" title="Juan Miguel Bákula Patiño">
Juan Miguel Bákula Patiño

Juan Miguel Bákula Patiño (Huaura, Huacho, Lima, Perú, 17 de febrero de 1914 - Miraflores, Lima, 18 de octubre de 2010), fue un historiador, escritor y diplomáticoperuano.

Fue hijo de Juan Clímaco Bákula Pacheco, exportador de algodón, y de Antonia Patiño Albarracín. En 1941 desposó a Laura Budge Nosiglia, con quien tuvo cinco hijos.

Sus primeros estudios los hizo en el Colegio de las Monjas de la Reparación y luego, desde cuarto de primaria y toda la secundaria, en el Colegio de la Inmaculada de los jesuitas, en Lima.

Fue doctor en Derecho. Estudió en la Universidad Nacional Mayor de San Marcos y en la Pontificia Universidad Católica del Perú también de Lima. Además, hizo dos años de Ciencias Económicas y otro tanto de Humanidades.

Se incorporó al Ministerio de Relaciones Exteriores del Perú el 4 de enero de 1934 como mecanógrafo meritorio y al Servicio Diplomático del Perú el 31 de octubre de 1939 hasta que decidió renunciar, al día siguiente del autogolpe de Estado del 5 de abril de 1992.

Fue director de Fronteras de la Cancillería por largos años; representante del Perú en todos los países limítrofes; director de la Academia Diplomática, y, finalmente, viceministro de Relaciones Exteriores (1963-1964).

Fue también Embajador del Perú en Francia entre 1975 y 1978.""Una de las grandes figuras de la diplomacia peruana de todos los tiempos"", según declaraciones del canciller José Antonio García Belaúnde al lamentar su pérdida.

Juan Miguel Bákula Patiño tuvo un rol sobresaliente en la consagración de la tesis de las 200 millas del mar territorial peruano, en la Conferencia de las Naciones Unidas sobre el Derecho del Mar y como Secretario General de la Comisión Permanente del Pacífico Sur.

Juan Miguel Bákula fue un diplomático que dedicó los 50 años de su carrera profesional a estudiar y compenetrarse con el tema de las fronteras del Perú. Esa experiencia vasta le enseñó a distinguir claramente lo que es "determinante" de lo que es "consecuente" en la definición del concepto de fronteras.

El embajador Bákula manifestó en un discurso que "Lo esencial es la formación del espacio nacional, o sea, la manera como se expresa el esfuerzo del país por ocupar su territorio. Otra cuestión distinta es la delimitación territorial con hitos, que no es otra cosa sino una operación mecánica, objetiva". "Las fronteras no existen porque se coloque un hito. Las fronteras existen porque hasta allí llegaron los hombres de uno y otro lado con su esfuerzo, su voluntad y su trabajo".

El 20 de octubre de 2003, el embajador Juan Miguel Bákula recibió el Premio Southern Perú 2003. También recibió la Medalla José de la Riva-Agüero y Osma por la Pontificia Universidad Católica del Perú. Igualmente le fue otorgada la "Orden al Mérito por Servicios Distinguidos" en el grado de Gran Cruz por parte de la República del Perú. El 26 de agosto del 2010 (a menos de 2 meses de su fallecimiento) es distinguido con el grado de Doctor Honoris Causa por parte de la Universidad Nacional Mayor de San Marcos. Todas estas distinciones constituyen los reconocimientos más importantes al trabajo intelectual en el Perú.


Entre sus más de 40 obras, se pueden mencionar:




</doc>
<doc id="28295" url="https://es.wikipedia.org/wiki?curid=28295" title="Greystoke, la leyenda de Tarzán, el rey de los monos">
Greystoke, la leyenda de Tarzán, el rey de los monos

Greystoke, la leyenda de Tarzán, el rey de los monos es una película basada en la novela "Tarzán de los monos", de Edgar Rice Burroughs. Fue nominada a tres Oscar: al mejor actor de reparto (Ralph Richardson, nominado a título póstumo), al mejor guion adaptado y al mejor maquillaje. No ganó ninguno.

En el siglo XIX, se produce un motín a bordo de un barco, y un matrimonio queda abandonado en la selva africana. La mujer está embarazada, y pronto da a luz a un niño. Poco después, un grupo de chimpancés corren por la cabaña que los padres han construido; éstos entran en pánico y mueren. Una hembra se hace cargo del bebé, en sustitución de su cría, que también ha muerto. Veinte años más tarde, el capitán belga Phillipe D'Arnot (Ian Holm) descubre al hombre (Christopher Lambert), a quien confunde con un primate en un principio. Al ver su cabaña y sus utensilios, se da cuenta de que tiene que ser John Clayton, hijo único del conde de Greystoke (Ralph Richardson), y lo lleva consigo de regreso a la civilización. Allí, John conoce a Jane Porter (Andie MacDowell), su prima norteamericana, y se enamora de ella. El capitán Phillipe D'Arnot piensa que Jane y John congenian y podrían casarse.


</doc>
<doc id="28296" url="https://es.wikipedia.org/wiki?curid=28296" title="Ordinary People">
Ordinary People

Ordinary People (en España, Gente corriente; en Hispanoamérica, Gente como uno) es un filme estadounidense de 1980 dirigido por Robert Redford y con Donald Sutherland, Mary Tyler Moore, Timothy Hutton, Elizabeth McGovern, Dinah Manoff, Judd Hirsch y M. Emmet Walsh en los papeles principales. 

La película, primera dirigida por Robert Redford, fue galardonada con importantes premios cinematográficos estadounidenses. Está basada en la novela "Ordinary People" de Judith Guest.

Las relaciones de una familia estadounidense modelo (padre, madre, dos hijos) se ven alteradas por un accidente ocurrido en un bote. El mayor de los hermanos muere y el menor, agobiado por la culpa de haber sobrevivido, intenta suicidarse y es internado durante un tiempo en un psiquiátrico. El film narra el regreso a casa del joven, con sus problemas atrapados entre la frialdad de su madre y la impostada alegría de su padre.









</doc>
<doc id="28297" url="https://es.wikipedia.org/wiki?curid=28297" title="Cine hogareño">
Cine hogareño

El cine en casa, también llamado cine hogareño, cine casero o teatro en casa (en inglés "home cinema") es un sistema que busca reproducir la calidad de vídeo y audio de una sala de cine en el hogar. 

El aspecto de vídeo a menudo incluye una pantalla grande o televisor de alta definición, o un sistema de proyección. La reproducción de audio de calidad se consigue con un sistema envolvente de alta fidelidad.

El cine en casa, técnicamente, podría ser tan básico como una añadir al televisor un reproductor de vídeo y un grupo de altavoces. Es, por tanto, difícil especificar exactamente lo que distingue un "home cinema" de un televisor con sistema estéreo.

Sin embargo, el cine en casa implica una verdadera "experiencia de cine" y por tanto una mayor calidad de sus componentes. Un sistema clásico incluiría lo siguiente:


Algunos entusiastas del cine en casa llegan a construir una habitación dedicada solo a ello. Dicha habitación a menudo se decora para recordar un cine real, con mobiliario especial, pósters de cine o una máquina de palomitas. Estas instalaciones más avanzadas a menudo incluyen elementos de diseño acústico sofisticados, incluyendo un aislamiento de sonido. Estas instalaciones a menudo son llamadas "habitaciones pantalla" para diferenciarlas de las instalaciones sencillas. 

A día de hoy es posible comprar kits de "cine en casa en una caja" lanzados por varias conocidas compañías de productos electrónicos. Estos kits comprenden un conjunto de altavoces de sistema surround, un amplificador/selector para ajustar el volumen y seleccionar los canales de vídeo y a veces un reproductor de DVD o VCR. Aunque estos kits palidecen en comparación con una instalación real de "home cinema", su precio también resulta más atractivo. Uno sólo necesita añadir un televisor y algunas películas para crear una sala de cine en casa.

Algunos equipamientos incluyen instalaciones de altavoces sin cable con amplificadores: 
Se estima que van a salir sistemas de cine en casa sin cables que abarquen todos los altavoces.

Algunas conexiones incluidas en home cinema son:





El sonido surround es un término que se asocia con los home Cinema desde su lanzamiento en 1982. Fue diseñado por los laboratorios Dolby y permitía emitir un sonido envolvente a través de un proceso que se conoce como la decodificación Matrix. Se trataba de la decodificación de diferentes señales de audio dentro de una fuente estéreo. Puso los cimientos para que posteriormente se desarrollaran muchos otros formatos de sonido envolvente:

Dolby utilizó el sistema Matrix con el Pro Logic para lograr un sonido surround. Lo hizo decodificando señales separadas desde los canales izquierdo y derecho de los equipos de sonido caseros. Esta innovación permitió que ya con las cintas VHS se reprodujera el sonido con dos canales extras. 

Con la aparición de los discos laser (LD) aumentó la calidad de de las grabaciones. Dolby aprovechó esta nueva tecnología para diseñar el formato AC-3, conocido actualmente como Dolby Digital. Supuso una notable mejora en el desempeño del Pro Logic. Además, se añadió un canal dedicado a las frecuencias graves manejado por un subwoofer.

El sistema DTS ("Digital Theater Systems") apareció en los cines con la película "Jurassic Park de" Steven Spielberg"(1993)." Más tarde esta tecnología se integró en los DVD. El formato DTS utiliza un mayor ancho de banda que el Dolby Digital, por lo que provee mayor información de audio y es de mayor calidad.

Con la llegada de los DVD-HD y los discos Blu-ray aparecieron los sistemas Home Cinema 7.1 (siete altavoces distribuidos por la estancia más un subwoofer). Y con ellos llegaron nuevos formatos de Dolby y DTS con mayores prestaciones que permiten aprovechar la mayor capacidad de memoria de estos discos. Dolby Digital Plus funciona con archivos de audio comprimidos que ocupan menos espacio. Dolby TruHD, es una versión sin compresión. DTS cuenta con dos opciones: DTS-HD, que trabaja con archivos comprimidos; y Dolby TrueHD, para archivos sin compresión.

Son nuevos sistemas que han mejorado mucho el sonido en los equipos de cine en casa. Pro Logic II es capaz de generar un sonido surround para sistemas Home Cinema 5.1 desde una fuente estéreo. Pro Logic IIx es un formato que puede tomar las mezclas de sonido surround 5.1 y expandirlas a sistemas 6.1 o 7.1, por lo que da mucho juego. Por otro lado, Pro Logic IIz permite añadir dos altavoces más (por encima del altavoz central y entre los altavoces frontales laterales). Con esta nueva suma se logra una mayor profundidad de sonido envolvente y una sensación sonora mucho mejor.

Es un nuevo códecs de sonido surround basado en objetos que permite representar objetos sonoros en un espacio 3D. Cada objeto contiene información de audio independiente.El Dolby Atmos puede procesar hasta 128 objetos de audio distintos en una escena y dar una nueva sensación de tridimensionalidad sonora. Puede lograr que el sonido de una explosión se emita desde diferentes puntos. También consigue un efecto 3D muy real gracias a que usa altavoces de techo adicionales.



</doc>
<doc id="28298" url="https://es.wikipedia.org/wiki?curid=28298" title="Ghost">
Ghost

Ghost, conocida en idioma castellano como Ghost, la sombra del amor en Argentina, Colombia, Chile, Costa Rica, México, Perú, Uruguay y Venezuela, Ghost, más allá del amor en España y Ghost, el fantasma del amor en Paraguay, es una película estadounidense, un drama-thriller dramático-fantástico y romántico, con un toque de comedia, de 1990. Está protagonizada por Patrick Swayze, Demi Moore y Whoopi Goldberg, escrita por Bruce Joel Rubin y dirigida por Jerry Zucker. Ganó dos Oscar, a la mejor actriz de reparto (Whoopi Goldberg) y al mejor guion original, y fue nominada a otros tres: a la mejor película, a la mejor música y al mejor montaje.

Sam Wheat (Patrick Swayze), un ejecutivo de banca e inversiones, y Molly Jensen (Demi Moore), una escultora de cerámica, son una pareja feliz que vive en la ciudad de Nueva York. El único problema en su relación es la incomodidad de Molly por el hecho de que cuando le dice a Sam "Te amo" ("I love you" en inglés) éste simplemente le responde "ídem" ("igual" en latín, "ditto" en la versión original en inglés, en toscano "lo dicho") y él nunca es quien toma la iniciativa diciéndoselo a su chica antes de que lo haga ella. Esto molesta a Molly, que siente que necesita escucharlo diciéndole "Te amo" como respuesta o bien en primer lugar antes de que sea ella quien lo exprese. 

Una noche, mientras caminan hacia su nuevo apartamento tras una salida al teatro, son atacados por un ladrón llamado Willy López (Rick Avilés). Éste saca una pistola y durante el forcejeo entre Sam y el atracador, la pistola se dispara. Tras el disparo, Sam comienza a perseguir al ladrón, que sale huyendo, aunque finalmente lo pierde de vista. Cuando regresa hacia Molly, se da cuenta de la verdad: el disparo le ha alcanzado en el corazón y ha muerto prácticamente en el acto. Como un espectador invisible, presencia a Molly meciendo su cadáver, intentando desesperada e inútilmente mantenerlo con vida, y se da cuenta que se ha convertido en un fantasma, atrapado entre ambos mundos. La luz viene a buscarlo desde lo alto pero él no quiere dejar sola a Molly, y logra escapar. Poco a poco, logra hacerse a la idea de que ya no está vivo.

En el hospital donde llevaron su cuerpo se encuentra con un anciano, quien también es un fantasma, e intentan reanimarlo. En ese momento ven a un paciente que se está muriendo y viene la luz para llevarse su alma, ésta sale del cuerpo del paciente, mientras que el anciano dice que tuvo suerte de que no vinieran los "otros" para llevárselo. Sam intenta preguntarle "¿quiénes son...?" cuando el anciano desaparece. En su sepelio, Sam ve a una mujer de azul cruzar una lápida mientras ésta le saluda.

Mientras poco a poco va aceptando que ha muerto, y que ya no puede estar con Molly. Sam se da cuenta de que el robo había sido planeado cuando Willy entra en la casa y camina entre sus pertenencias. Sam sigue a Willy hacia su casa y descubre que su amigo y compañero de trabajo, Carl Bruner (Tony Goldwyn), había contratado a Willy para robarle a Sam y así obtener la contraseña del ordenador de su oficina. Carl estaba envuelto en un blanqueo de dinero en el banco en el cual trabajaban él y Sam. Sam había cambiado recientemente su contraseña, encerrando a Carl fuera de las cuentas falsificadas en las que Carl había ocultado el dinero. Sam se llena de resentimiento hacia su supuestamente mejor amigo, pero se da cuenta de que, como fantasma, no puede hacer mucho. 

Sam teme que Molly esté en peligro pero él se encuentra indefenso, incapaz de comunicarse con ella en su estado actual. Sin embargo, encuentra a Oda Mae Brown (Whoopi Goldberg), una artista que se hace pasar por médium que irónicamente descubre (después de escuchar a Sam criticando su negocio fraudulento) que realmente tiene el poder de su familia de escuchar a los fantasmas, aunque no puede verlos. Viéndola como su única esperanza de comunicarlo con Molly, Sam comienza a acosar a Oda Mae hasta que ella finalmente se rinde y accede a ayudarlo.

Oda Mae, reticente, llama a Molly y le dice que se está comunicando con Sam, pero Molly es escéptica. Sólo logra convencerla cuando le cuenta cosas privadas que sólo sabía Sam, principalmente su uso de la palabra "ídem". 

Mientras perseguía a Willy hasta su apartamento, Sam conoce a un fantasma inquieto (Vincent Schiavelli) rondando en el subterráneo de Nueva York, quien le enseña a mover y tocar objetos focalizando sus emociones en el blanco. También descubre que Oda Mae estaba siendo solicitada por fantasmas provenientes de lugares tan lejanos de Nueva York como Nueva Jersey para que hablase con sus parientes vivos. Uno la posee brevemente, pero este acto baja la energía de los fantasmas. Sam le promete a Oda Mae que ya no la molestarían si lo ayuda. 

Mientras tanto, Molly va a la policía, ya que había vuelto su escepticismo acerca de las palabras de Oda Mae. El sargento le asegura que tenía razón al dudar, y que no había carpeta alguna con el expediente de 'Willy López', aunque sí había una gran carpeta con datos de Oda Mae Brown, quien es reconocida entre los policías locales como una impostora. 

Sam y Oda Mae deciden frustrar el plan de Carl. Carl había robado cuatro millones de dólares y los había depositado en una cuenta fraudulenta. Bajo las instrucciones de Sam, Oda Mae se hace pasar por 'Rita Miller' (el nombre de la cuenta) para retirar el dinero, Sam le dice que debe entregar el dinero para no ser perseguida por Carl y de mala gana le da el cheque a dos monjas que pedían caridad. Carl entra en pánico cuando se da cuenta de que la cuenta había sido cerrada, y es atormentado por Sam quien, invisible, se comporta como un poltergeist y teclea la palabra "ASESINO" y cuando en su desesperación pregunta Carl al aire quién lo está acosando, Sam teclea SAM numerosas veces en su computadora.

Carl piensa que Sam le quitó el dinero por lo que termina en la puerta de la casa de Molly, preguntando por Oda Mae. Molly revela que Oda Mae "era" Rita Miller y que es una timadora. Carl se da cuenta de que el fantasma de su antiguo compañero de trabajo está presente y que usó a Oda Mae para quitarle el dinero, por lo que le dice (a Sam) que regresaría a las 11 pm a matar a Molly si no le devolvía el dinero. Sam corre a advertirle a Oda Mae, pero casi de inmediato Willy y Carl llegan a tratar de quitarles el cheque de la cuenta liquidada. Oda Mae y sus hermanas escapan mientras Sam aterroriza a Willy, propiciándolo a huir hacia la calle en estado de pánico. Willy es golpeado por un camión y muere, pero su alma no fue llevada por la luz, sino que unas sombras comenzaron a convertirse en seres demoníacos quienes lo tomaron a la fuerza y lo arrastraron hacia el infierno mientras pide desesperadamente por ayuda. Presenciando esto, Sam comprende que esos demonios son los "otros" que el anciano en el hospital le había mencionado.

Sam y Oda Mae se dirigen rápidamente a advertirle a Molly que está en peligro, pero Molly sigue sin estar segura acerca de Oda Mae; no obstante, se convence luego de que ésta pasa un penique bajo la puerta y Sam usa sus poderes para ubicar el penique en la mano de Molly (Molly y Sam coleccionaban peniques para tener buena suerte). Molly le habla a la policía para que las proteja de Carl y en lo que la esperan Sam usa el cuerpo de Oda Mae para lograr tocar por última vez a Molly pero en eso Carl llega, eran las 11 pm ya, amenazando con matar a Molly si Oda Mae no le da su dinero. Sam es eyectado a la fuerza del cuerpo de la médium y trata de detener a Carl, pero la posesión había bajado la fuerza de sus poderes.

Molly y Oda Mae escapan hacia un desván ubicado sobre el departamento, perseguidas por Carl. Éste trata desesperadamente de atrapar a las mujeres y finalmente atrapa a Oda Mae, empuñando un arma. Molly sale a defensa de la médium, pero Carl la supera y la toma como rehén. La energía de Sam regresa y obliga a Carl a arrojar el arma, permitiéndole a Molly huir sin sufrir daños. Peleando en vano para detener los ataques de Sam, Carl torpemente le arroja el gancho de la grúa (polea) del edificio para subir cosas. El gancho pasa a través del cuerpo transparente de Sam y golpea una ventana abierta, de la cual caen rotos los vidrios de la misma y matando a Carl mientras trata de escapar. Carl ve a Sam cuando su alma sale de su cuerpo y se entristece cuando se da cuenta de que murió y los demonios se lo van a llevar porque había sido malo. Los demonios salen de las sombras y se lo llevan, y Carl expresa terror mientras su espíritu es arrastrado al infierno. 

Cuando Sam regresa hacia donde estaban Oda Mae y Molly, les pregunta si están bien. Molly se da cuenta de que puede oír a Sam, luego comienza a brillar una luz y Sam asume una forma parcialmente visible. Tras despedirse de Oda Mae, comparte un último beso con Molly y le dice que la ama, a lo que ella responde con "ídem". Sam luego se va acompañado por una luz brillante.

Ghost es el nombre de la banda sonora de la película homónima de 1990, protagonizada por Patrick Swayze, Demi Moore y Whoopi Goldberg. Fue producida bajo la discográfica Milan América, con la producción de Maurice Jarre.

Está catalogada como una de las más exitosas en ventas y publicidad en la historia del cine y la música, sobre todo por representar un sector orquestado de una época en particular. Se mantuvo en el primer lugar de ventas y listas por varias semanas en su año de publicación.




</doc>
<doc id="28300" url="https://es.wikipedia.org/wiki?curid=28300" title="Precesión">
Precesión

La precesión o movimiento de precesión nutación es el movimiento asociado con el cambio de dirección en el espacio, que experimenta el eje instantáneo de rotación de un cuerpo.

Un ejemplo de precesión lo tenemos en el movimiento que realiza una peonza o trompo en rotación. Cuando su eje de rotación no es vertical, la peonza posee un movimiento de «cabeceo» similar al de precesión.

Más exactamente una precesión pura es aquel movimiento del eje de rotación que mantiene su segundo ángulo de Euler (nutación) constante. Este movimiento de nutación también se da en el eje de la Tierra.

Hay dos tipos de precesión: la precesión debida a los momentos externos, y la precesión sin momentos de fuerzas externos.

Este movimiento ocurre cuando un cuerpo está en movimiento alrededor de un eje que no es ni el de máximo momento de inercia ni el de menor momento de inercia. La precesión puede estar acompañada de otros movimientos propios de los cuerpos en rotación como la nutación.
Hay un tipo especial de curvas sobre la superficie del objeto, llamadas polodia y herpolodia, las cuales describen el movimiento del mismo.

Se llama peonza simétrica en movimiento libre a un sólido rígido de revolución, con dos de sus momentos de inercia principales iguales formula_1. Como en una peonza simétrica se pueden escoger arbitrariamente los ejes 1 y 2, conviene aprovechar ese hecho para simplificar las expresiones tomando el eje 1 paralelo a la línea nodal de los ángulos de Euler lo cual equivale a que ψ = 0.

Lo cual lleva a que las velocidades angulares en el sistema de referencia no inercial vengan dadas por:

La energía cinética de rotación una peonza simétrica (formula_2) puede expresarse en términos de los ángulos de Euler sencillamente:

Por otro lado si se toma el eje Z del sistema de referencia alineado con el momento angular del sólido rígido se tiene que las componentes del momento angular y la relación con la velocidad angular son:

Escribiendo componente a componente estas ecuaciones se tiene que:

La primera ecuación nos dice que en el movimiento libre de una peonza simétrica ésta no cabecea; es decir, no hay movimiento de nutación ya que el ángulo formado por eje de rotación y el momento angular se mantiene constante en el movimiento. La segunda describe el movimiento de precesión de acuerdo con el cual el eje de rotación (que coincide con la dirección de la velocidad angular) gira alrededor de la dirección del momento angular (eje Z). La tercera ecuación da la velocidad de rotación del sólido alrededor de su tercer eje de inercia.

Recordemos que el momento angular es un vector que tiene como módulo, el producto del momento de inercia del cuerpo alrededor del eje de rotación, multiplicado por la velocidad angular. La dirección del vector es la misma que la del vector asociado a la velocidad angular y está dada por la regla de la mano derecha. La ecuación de base del momento angular de un cuerpo es:

donde formula_3 es el momento angular del cuerpo y formula_4 es el momento de fuerza aplicado al cuerpo. Esta ecuación corresponde, en el movimiento lineal, a la ecuación formula_5 donde formula_6 es la fuerza aplicada a un cuerpo y formula_7 es el momento lineal del cuerpo.

Cuando el momento de fuerza es paralelo al momento angular, o sea, paralelo al eje de rotación, nada cambia en la rotación. En cambio, una componente del momento, perpendicular al eje de rotación, no cambia el módulo de la velocidad angular sino su dirección, es decir la dirección del eje de rotación del cuerpo.

Consideremos el cuerpo en rotación de la imagen de derecha. Cuando se le aplica un momento dinámico como el indicado por las fuerzas dibujadas, la dirección de la variación del momento angular es la indicada en el dibujo. Esta variación es perpendicular al momento angular y paralela al momento.
La variación de formula_8 durante un intervalo de tiempo formula_9 es:

Nótese que formula_10 tiene la misma dirección que formula_11. El ángulo formula_12 que el nuevo momento angular formula_13 hace con el precedente formula_8 cumple que:

Si el cociente formula_16 es pequeño (e. g. menor a 5 ° en magnitud, típicamente causado por un intervalo de tiempo formula_17 pequeño), el ángulo formula_12 se puede obtener de la aproximación de la ecuación anterior mostrada a continuación:

La velocidad de precesión del giroscopio es la velocidad angular del vector formula_3 que es la misma que la del eje de rotación de este último:
La velocidad de precesión es una velocidad angular y se mide en radianes/segundo.

La velocidad de precesión es tanto más pequeña cuanto más grande es el momento angular del cuerpo.

Si el eje de rotación del trompo, "z", forma un cierto ángulo formula_22 con la vertical, como ocurre generalmente, dicho eje se mueve en el espacio generando una superficie cónica de revolución en torno al eje vertical fijo "Z". Este movimiento del eje de rotación recibe el nombre de precesión de la peonza y el eje "Z" es el eje de precesión. Generalmente, el ángulo formula_22 varía periódicamente durante el movimiento de precesión de la peonza, de modo que el eje de rotación oscila acercándose y alejándose del eje de precesión (decimos que el trompo cabecea); a este movimiento se le llama nutación y al ángulo formula_22 se le llama ángulo de nutación. En el estudio elemental que sigue no tendremos en cuenta este último movimiento; i.e., consideraremos un ángulo de nutación constante.

Utilizaremos dos referenciales para describir el movimiento del trompo. Uno de ellos es el referencial fijo "XYZ", con origen en el punto O (estacionario) del eje de rotación del trompo. El otro referencial es el referencial móvil "xyz", cuyo origen es también el punto O (estacionario). Haremos coincidir el eje "z" con el eje de rotación del trompo; el eje "x" lo elegimos de modo que permanezca siempre horizontal, contenido en el plano "XY". El ángulo formula_25 que forma en cada instante el eje "x" con el eje "X" recibe el nombre de ángulo de
precesión. En consecuencia, el eje "y" estará siempre contenido en el plano definido por los ejes "z" y "Z", como se muestra en la Figura 1, formando un ángulo formula_22 con el plano "XY". Obsérvese que el referencial "xyz" no es solidario con el trompo, i.e., no es arrastrado por la rotación de éste, sino que presenta una rotación con respecto al referencial fijo "XYZ" con una cierta velocidad angular formula_27 llamada velocidad angular de precesión.

Como al aplicar la ecuación del movimiento de rotación del sólido rígido, M = dL/d"t", tanto el momento externo (M) como el momento angular (L) deben estar referidos a un mismo punto fijo en un referencial inercial (o al CM del cuerpo), tomaremos el punto O como origen o centro de reducción.

Puesto que el trompo está girando, con una velocidad angular intrínseca ω, alrededor del eje principal de inercia "z", su momento angular será paralelo a la velocidad angular (o sea, será paralelo al eje "z"), y viene dado por

Por otra parte, el momento externo que actúa sobre el trompo se debe al peso "m"g que actúa en el centro de gravedad G y es igual al producto vectorial

de modo que el momento externo M resulta ser perpendicular al eje de rotación, o sea que formula_28. El módulo del momento aplicado es

siendo "h"=OG la distancia entre el punto estacionario del trompo (el extremo de su púa) y el centro de gravedad del mismo. La dirección de M es la del eje "x".

Como el momento externo aplicado al trompo no es nulo, el momento angular no permanecerá constante. Durante un intervalo de tiempo infinitesimal d"t" el cambio infinitesimal experimentado por el momento angular vale

de modo que el cambio dL en el momento angular tiene siempre la misma dirección que el momento aplicado M (del mismo modo que el cambio en la cantidad de movimiento tiene siempre la misma dirección que la fuerza). Como el momento M es perpendicular al momento angular L, el cambio dL en el momento angular también es perpendicular a L. Por consiguiente, el vector momento angular cambia de dirección, pero su módulo permanece constante (figura 2). Naturalmente, puesto que el momento angular tiene siempre la dirección del eje de rotación éste cambiará también su orientación en el espacio en el transcurso del tiempo.

El extremo del momento angular L describe una circunferencia, de radio formula_29, alrededor del eje fijo "Z" y en un tiempo d"t" dicho radio experimenta un desplazamiento angular dψ. La velocidad angular de precesión Ω se define como la velocidad angular con la que gira el eje "z" en torno al eje fijo "Z". Esto es

y está representado por un vector situado sobre eje "Z".

Puesto que L es un vector de módulo constante que precesa alrededor del eje "Z" con una velocidad angular Ω, podemos escribir la ecuación diferencial del movimiento de rotación en la forma

obteniéndose para el módulo del momento

expresión de la que despejaremos Ω para tener

donde hemos sustituido las expresiones (1) y (2) para el momento angular y el momento, respectivamente. La velocidad angular de precesión, Ω, resulta ser inversamente proporcional al momento angular ("L") o a la velocidad angular intrínseca ("ω"), de modo que si éste o ésta es grande, aquélla será pequeña.

Obsérvese que la velocidad angular de precesión no depende del ángulo de inclinación del trompo. Esta propiedad es muy importante en el fundamento de la resonancia magnética nuclear y de sus aplicaciones.

Pero, ¿por qué no cae el trompo? La respuesta es que la fuerza vertical ejercida sobre él por el suelo (en el extremo O de la púa) es exactamente igual al peso del trompo, de modo que la fuerza resultante vertical es nula. La componente vertical de la cantidad de movimiento permanecerá constante pero, debido a que el momento no es nulo, el momento angular cambia con el tiempo. Si el trompo no estuviera en rotación, al abandonarlo no habría momento angular y al cabo de un intervalo de tiempo infinitesimal, d"t", el momento angular dL adquirido, en virtud del par de fuerzas que actúa sobre él, tendría la misma dirección que el vector M; esto es, que caería. Pero si el trompo se encuentra inicialmente en rotación, la variación del
momento angular, dL, producida por el par, se suma vectorialmente al momento angular que ya tiene, y puesto que dL es horizontal y perpendicular a L, el resultado es el movimiento de precesión anteriormente descrito.

Los resultados obtenidos en nuestra discusión del movimiento del trompo son solamente aproximados. Son correctos si ω es muy grande en comparación con Ω (situación compatible con la ec. [7]). La razón es que si el trompo está precesando en torno al eje fijo vertical "Z" tendrá un momento angular con respecto a dicho eje, de modo que el momento angular total no será simplemente Iω, como supusimos. Sin embargo, si la precesión es muy lenta, el momento angular correspondiente a esa precesión puede despreciarse, como implícitamente hemos hecho en nuestros cálculos anteriores.

Por otra parte, una discusión más detallada nos mostraría que en general el ángulo de nutación formula_22 no permanece constante, sino que oscila entre dos valores fijos, de modo que el extremo del vector L, al mismo tiempo que precesa alrededor de "Z", oscila entre dos círculos, como se muestra en la figura 3, describiendo la trayectoria indicada.

Para comprender el porqué de estas oscilaciones deberemos considerar el modo en que se origina el movimiento de precesión. Si inicialmente mantenemos fija la orientación del eje de rotación "z" (apoyando su extremo superior) el peso del trompo estará compensado por la reacción normal "N" en el punto O más la reacción normal en el apoyo del extremo superior del eje, de modo que resultará ser "N" < "mg". Si una vez que el trompo ha adquirido un rápido movimiento de rotación, abandonamos el eje, entonces, aún un instante después será "N" < "mg", de modo que tenemos una fuerza resultante vertical y dirigida hacia abajo. El trompo comienza a caer, pero en ese instante comienza la precesión. Como consecuencia del movimiento de caída, la púa del trompo se apoya en el suelo con más fuerza, de modo que aumenta la fuerza de reacción vertical "N", que finalmente llegará a ser mayor que el peso. Cuando esto sucede, el centro de masa del trompo comienza a acelerar hacia arriba. El proceso se repite, y el movimiento se compone de una precesión acompañada de una oscilación del eje de rotación hacia abajo y hacia arriba, que recibe el nombre de nutación. La nutación, al igual que la precesión, contribuye al momento angular total, pero en general su contribución es aún menor que la de la precesión.




</doc>
<doc id="28301" url="https://es.wikipedia.org/wiki?curid=28301" title="Nutación">
Nutación

Nutación (del latín “nutare”, cabecear u oscilar) es un movimiento ligero irregular en el eje de rotación de objetos simétricos que giran sobre su eje. Ejemplos comunes son los giroscopios, los trompos y los planetas. Más exactamente, una nutación pura es el movimiento del eje de rotación que mantiene el primer ángulo de Euler (precesión) constante.

El movimiento de nutación de la Tierra fue descubierto en 1728 por el astrónomo inglés James Bradley, y dado a conocer en el año 1748. Hasta 20 años más tarde no se supo que la causa de este movimiento extra del eje de la Tierra era la atracción gravitatoria ejercida por la Luna.
Giro de una casa

Para el caso de la Tierra, la Nutación es la oscilación periódica del eje de rotación de la Tierra alrededor de su posición media en la esfera celeste, debido a las fuerzas externas de atracción gravitatoria entre la Luna y el Sol con la Tierra. Esta oscilación es similar al movimiento de una peonza (trompo).

En el caso de la Tierra, la nutación se superpone al movimiento de precesión y al balanceo de la oblicuidad de la eclíptica de forma que no sean regulares, sino un poco ondulados, los teóricos conos que dibujaría la proyección en el espacio del desplazamiento del eje de la Tierra debido al movimiento de precesión. La nutación hace que cada 18,6 años el eje de rotación de la Tierra oscile hasta unos nueve segundos de arco a cada lado del valor medio de la oblicuidad de la eclíptica y hasta unos 17 segundos a cada lado del valor medio de desplazamiento del punto Aries sobre la eclíptica debido a la precesión de los reiner
El Sol produce otro efecto de nutación de mucha menor relevancia, con un período medio de medio año incrementando la oscilación del eje mencionada hasta 1.1" de arco en oblicuidad y hasta alrededor de 2" de arco en longitud (precesión).

Los demás planetas también producen variaciones, denominadas perturbaciones, pero que carecen de importancia por su pequeño valor.

Actualmente la oblicuidad media es de poco menos de 23°26'16", correspondiendo dicho ángulo y su complemento (66°33'44") a la latitud media de los trópicos y los círculos polares respectivamente. La oblicuidad media está decreciendo 0.47" por año, lo cual se refleja en un desplazamiento anual de 14.4 m de los trópicos y círculos polares medios, sin embargo la nutación modifica continuamente la oblicuidad hasta en poco más de 3" de un año a otro en años de máxima diferencia, mismos que cuando son del mismo signo que la variación de la oblicuidad llegan a sumar 3.5", los que en la tierra representan hasta 110 m de diferencia de un año a otro entre la ubicación de los trópicos y círculos polares verdaderos.

En cada ciclo de 18.6 años la diferencia de ubicación entre trópicos y círculos polares medios y verdaderos puede alcanzar hasta cerca de 300 m y la ubicación de los trópicos y círculos polares verdaderos puede superar los 700 m de distancia en 10 años, período máximo de alejamiento antes de empezar el siguiente ciclo. 

Al depender el movimiento de nutación de la estructura interna de la Tierra, las discrepancias entre los valores predichos y observados proporcionan información sobre modelos para el núcleo terrestre.

Los fenómenos de movimiento del polo e inconstancia de la rotación terrestre aparecen como consecuencia de pequeños cambios en el momento angular de la Tierra. Este cambio es debido a muy diversos fenómenos, entre los que se pueden citar el intercambio de momento angular entre la Tierra y su atmósfera y, entre la Tierra y la Luna, cambio de la altura del nivel del mar y corrientes oceánicas, producidas por el fenómeno de las mareas, acoplamientos mecánicos entre los movimientos de los fluidos del núcleo y manto, etc.



</doc>
<doc id="28302" url="https://es.wikipedia.org/wiki?curid=28302" title="Campo de exterminio de Treblinka">
Campo de exterminio de Treblinka

Treblinka fue un campo de exterminio construido por los nazis, cerca de la aldea polaca de Treblinka al noroeste de la Polonia ocupada por los alemanes, como parte de la Solución final, el aniquilamiento sistemático de judíos y otros grupos.

Estuvo funcionando desde julio de 1942 hasta noviembre de 1943 durante la Segunda Guerra Mundial. En total unas 780 000 personas fueron asesinadas en Treblinka, la gran mayoría judíos polacos, entre ellos unos 265 000 procedentes de la liquidación del gueto de Varsovia.

Treblinka fue uno de los seis campos de exterminio que se incluyeron en el marco de la Operación Reinhard. Los otros cinco fueron Auschwitz-Birkenau, Belzec, Sobibor, Majdanek y Chelmno. 

El campo de Chelmno fue construido originalmente como un proyecto piloto para los otros tres campos. La Operación Reinhard fue concebida por Heinrich Himmler (alto oficial del gobierno nazi y comandante de las Tropas de Seguridad--Schutzstaffel, mejor conocidas como las SS). A diferencia de otros campos de concentración, los campos de la Operación Reinhard informaban directamente a la oficina de Hitler (la Oficina de Cancillería del Reich) en Berlín. Hitler mantuvo el control del programa muy cercano a él pero delegó el trabajo a Himmler. La Operación Reinhard utilizó el programa de eutanasia (T-4) para la selección del lugar, construcción y entrenamiento del personal en territorios ocupados por la Wehrmacht, dado que no podían manejar los millones de judíos, especialmente de los guetos más grandes ubicados en Varsovia y Leópolis. Treblinka estaba especialmente diseñado para el rápido exterminio de judíos en los guetos. Sobibor estuvo listo para operar el 1 de agosto de 1942.

El campo estaba ubicado a 100 km al noreste de la capital de Polonia, Varsovia (6), a 500 m de la carretera Malkinia-Koskow y a cerca de 1,5 km de la estación de trenes de Treblinka. El campo estaba organizado en dos subdivisiones: "Treblinka I" y "Treblinka II", construidos en 1941 y 1942, respectivamente.

Treblinka I contaba con una sección administrativa. También había barracas para las tropas de las SS, los guardias Ucranianos, el comandante del campo de barracas, una cocina, un almacén y barracones para los 1.000 prisioneros que eran utilizados en labores de intendencia del campo. Un camino a la izquierda de este campo conectaba con la carretera. La otra sección de Treblinka I era el área donde se recibía a los prisioneros.

Treblinka II se encontraba en una pequeña colina. Desde el primer campo había una ruta de subida delineada con barreras de alambre electrificadas – el embudo – que llevaba directamente adentro del edificio de las cámaras de gas. Detrás de este edificio existía una fosa de un metro de fondo por veinte metros de largo, dentro de la cual había hornos para quemar los cuerpos. Las vías estaban tendidas a lo largo de la fosa y los cuerpos de las víctimas gaseadas eran puestos en las vías para la incineración. También había una barraca para los 500 prisioneros que operaban el segundo campo.

Treblinka estuvo listo el 22 de julio de 1942, cuando comenzó la deportación de judíos: “De acuerdo al informe de Jürgen Stroop, "Brigadeführer" de las SS", un total de aproximadamente 310.000 judíos fueron transportados en trenes de carga desde el gueto de Varsovia a Treblinka durante el período comprendido entre el 22 de julio de 1942 y el 3 de octubre de 1942”.

La línea ferroviaria llegaba hasta el interior de Treblinka. Había dos barracas próximas a las vías del tren que se empleaban para almacenar las pertenencias de los prisioneros. Una estaba camuflada para que pareciese una estación corriente. En otros dos edificios, situados a unos 100 metros de distancia, se guardaban las pertenencias de los prisioneros asesinados y se les cortaba el pelo a las mujeres.

A diferencia de otros campos de exterminio, como Auschwitz, en Treblinka no había barracones para alojar a los prisioneros, pues los judíos llegados al campo eran asesinados directamente. Debido a ello, ha sido difícil llevar el registro de las víctimas.

La esperanza de vida en Treblinka era de aproximadamente una hora y media.

Al llegar al campo, los prisioneros se encontraban en dos filas, separados según su sexo, los hombres a la derecha y mujeres a la izquierda. Los alemanes conducían a los judíos y golpeaban o mataban a quienes se resistían a obedecer, algo que, por otra parte, rara vez sucedía, pues la inmensa mayoría de los judíos ignoraban que se hallaban en un campo de exterminio.

Una vez asesinados en la cámara de gas, los prisioneros eran despojados de sus pertenencias. Previamente, un oficial había recaudado los objetos de mayor valor con el pretexto de ponerlos a salvo.

Durante la entrevista de Claude Lanzmann con el "SS Unterscharführer" Franz Suchomel, quien operaba en el campo, éste nos cuenta sobre los primeros días de Treblinka en agosto de 1942:

El trabajo era llevado a cabo por cuadrillas especiales ("Sonderkommandos") de prisioneros judíos. La cuadrilla azul era responsable de descargar el tren, cargar el equipaje y limpiar los vagones. La cuadrilla azul tenía la tarea de desvestir a los pasajeros y llevar sus ropas al área de almacenamiento. Los "Goldjuden" ('judíos de oro') se encargaban de administrar el dinero, oro, acciones y joyas. Efectuaban una búsqueda minuciosa en los prisioneros antes de enviarlos a las cámaras de gas. La dentista abría las bocas de los muertos y sacaba el oro de los dientes. Uno de los oficiales de las SS más crueles y responsables de crímenes contra la humanidad en el campo de Treblinka fue el Untersturmführer Kurt Franz.

Según los testimonios de Franz Suchomel en la película Shoah de Claude Lanzmann y de Franz Stangl, Treblinka, bajo el mando del Doctor Eberl era un completo desorden. Suchomel llegó a Treblinka el 18 de agosto de 1942 con otros siete alemanes, viniendo de Berlín, haciendo escalas de Varsovia hacia Lublin, volviendo a Varsovia y de ahí a Treblinka. El campo de exterminio funcionaba a toda marcha. Su primera impresión del campo fue catastrófica; sus superiores no les habían dicho que allí mataban a la gente y le encargaron vigilar talleres de sastres y zapateros. «El Führer ordenó acciones de transferencia», le dijeron. El oficial Otto Stadie les enseñó el campo, y cuando pasaban Suchomel y los de su grupo, las puertas de las cámaras de gas se estaban abriendo y las personas cayeron. Según Suchomel eso tuvo un efecto devastador en él, fue a sentarse sobre sus maletas con sus demás amigos de las SS y se pusieron a llorar.

Los alemanes escogían a cien judíos para arrastrar los cadáveres a las fosas, por la noche los ucranianos los llevaban a las cámaras de gas y los liquidaban, eso pasaba todos los días, en medio de un fuerte calor de agosto, la tierra ondulaba como el mar a causa del gas de los cadáveres. Muchos recién llegados de las SS vomitaban y lloraban.

Muchos judíos se cortaban las venas antes de llegar al campo, presintiendo su destino, había mujeres judías que les abrían las venas a sus hijos y luego se las abrían ellas, otras se envenenaban.

Una noche llegó Wirth, el inspector de campos de la acción Reinhard, lo inspeccionó todo y se marchó inmediatamente. Luego llegó con gente de Belzec, eran técnicos, las autoridades interrumpieron el transporte debido al ineficiente ritmo de las primeras cámaras de gas, como caía tanta gente y al haber tantos muertos, los cuerpos se amontonaban alrededor de la cámara de gas y allá quedaban durante días. Bajo esa montaña de cuerpos había una cloaca de diez centímetros con sangre, gusanos y excrementos. Nadie quería recoger esos cadáveres, los judíos preferían dejarse fusilar, enterraban a sus parientes y veían con sus ojos la carne de los cadáveres que les quedaba en las manos. Entonces Wirth fue en persona con algunos alemanes y mandó cortar correas largas que pasaban por el torso de los cadáveres para arrastrarlos hasta las fosas. Alemanes y judíos fueron obligados a hacer esto.

Existía una regla: si un prisionero había sido golpeado en la cara, le disparaban esa tarde al pasar lista, o a la mañana siguiente si es que la contusión aún no había aparecido antes. Muchos prisioneros, en su desesperación por las horribles muertes de sus familiares y ya sin deseos de vivir, se suicidaban colgándose en las barracas con sus cintos (Steiner 84). Normalmente, los 1500 trabajadores eran totalmente reemplazados cada tres a cinco días.

Muy al comienzo, la gente era enterrada en fosas comunes o apilada en el campo II, debido a que los trabajadores no tenían tiempo suficiente para enterrarlos. El hedor de los cuerpos en descomposición se podía oler hasta a diez kilómetros de distancia (p. 54). Los judíos que esperaban en los vagones del tren sabían lo que sucedería y miles se suicidaban en los convoyes. En septiembre de 1942 se construyeron nuevas cámaras de gas, los motores que alimentaban las cámaras de la muerte se escuchaban a veces desde la estación y eran de un tanque T-34.

Las puertas de las cámaras de gas eran de acero, provenían de búnkeres soviéticos transportados a Kielce.

Herbert Floss, el encargado de las fosas comunes reveló su secreto para quemar cuerpos: la composición de la hoguera. Según explicó, no todos los cadáveres se quemaban de manera pareja. Había cadáveres buenos y malos, incombustibles y fácilmente inflamables. El arte consistía en usar los buenos para quemar los malos. Según sus investigaciones que obviamente estaban muy adelantadas, los cadáveres viejos ardían mejor que los frescos, gordos mejor que flacos, mujeres mejor que hombres, y niños, no tan bien como mujeres, pero mejor que hombres. De esto resultaba que cadáveres viejos de mujeres gordas eran los cadáveres ideales. Herbert Floss los hizo poner a un costado como así también a los de hombres y de niños. Después de haber sido desenterrados y clasificados casi 1 000 cadáveres, se procedió a apilarlos, colocándose el mejor material combustible abajo y el de menor calidad arriba. Floss rechazó los bidones de gasolina que se le ofrecieron y como reemplazo hizo traer madera. Su acto debía ser perfecto. La leña se juntó debajo de la parrilla de la hoguera formando pequeños focos, cual fogatas. La hora de la verdad había llegado. Con solemnidad le entregaron una caja de fósforos; él se agachó, encendió el primer foco seguido de los otros y mientras la madera empezaba a quemarse paulatinamente, con su caminar tan extraño se acercó a los funcionarios que esperaban a cierta distancia.

Las llamas crecían más y más, lamiendo los cadáveres, vacilantes primero pero después llameando con brío. De repente, toda la hoguera quedó envuelta en llamas que crecían expulsando nubes de humo. Se percibió un crepitar intenso, los rostros de los muertos se contraían dolorosamente y reventaba su carne. Un espectáculo infernal. Por un momento, hasta los hombres de las SS quedaron como petrificados, observando mudos el milagro. Herbert Floss estaba radiante. La hoguera echando llamas era la vivencia más hermosa de su vida...

Un acontecimiento tal debía festejarse. Se trajeron mesas que fueron colocadas frente a la hoguera y cargadas de botellas de aguardiente, cerveza y vino. El día llegaba a su ocaso y el cielo crepuscular parecía reflejar las altas llamas de la hoguera, allá en el horizonte, donde el sol se ponía con el esplendor de un incendio.

A una señal de Lalka sonaron los corchos y empezó una fiesta fantástica. El primer brindis fue dedicado al Führer. Los operarios de las dragas habían regresado a sus máquinas. Cuando los hombres de las SS levantaron las copas para los brindis, las máquinas parecieron cobrar vida; con un movimiento abrupto levantaron el brazo de acero hacia el cielo en un repentino y vibrante saludo hitleriano. Fue como una señal. Diez veces levantaron también los hombres el brazo haciendo resonar cada vez el "Sieg-Heil". Las máquinas animadas respondían al saludo de los hombres-máquina y el aire retumbó de los vivas al Führer. La fiesta duró hasta que la hoguera se extinguió. Después de los brindis se cantó. Se oyeron cantos salvajes y crueles, cantos llenos de odio, horripilantes, cantos en honor a la Alemania eterna. (Steiner, Treblinka, editorial Gerhard Stalling Verlag, 1966, p. 294 y sgtes.

Los cadáveres se hacían embeber en gasolina. Esto causaba costos importantes y el resultado no era satisfactorio; los cadáveres masculinos sencillamente no querían cremarse. Siempre que aparecía un avión en el cielo, el trabajo se interrumpía y los cadáveres se cubrían con hojarasca para no ser detectados desde arriba. Era un espectáculo espantoso, el más horrible visto jamás por ojo humano. Cuando los cadáveres de mujeres encintas se quemaban, los vientres reventaban y era posible ver llamear a los embriones en el cuerpo materno.

Para amenizar la monotonía de las matanzas, los alemanes fundaron una orquesta judía en Treblinka. Esta cumplía una doble función: Por un lado, su música cubría en lo posible los gritos y gemidos de las personas empujadas a las cámaras de gas y, por el otro, servía como diversión musical de los guardias del campo, que provenían de dos naciones amantes de la música: alemanes y ucranianos.

El 2 de agosto de 1943, los prisioneros de los comandos de trabajo se rebelaron. Fabricaron pequeñas armas, rociaron queroseno en todos los edificios y los incendiaron. En la confusión, muchos alemanes murieron, pero muchos más prisioneros fueron muertos. De los aproximadamente 1000 prisioneros que había en los campos I y II de Treblinka, unos 600 consiguieron salir del campo y solamente unos 40 sobrevivieron a la revuelta y a las posteriores persecuciones sufridas por alemanes, ucranianos y campesinos polacos, así como a otros acontecimientos propios de la guerra. El campo detuvo sus operaciones. El comandante del campo, Kurt Franz, dijo durante su testimonio: «Después de la rebelión en agosto de 1943 sólo operé el campo por un mes. Sin embargo, durante ese período no hubo gaseos. Fue durante ese período cuando el campo original fue nivelado y se plantaron los altramuces» (2) p. 247).

Esta revuelta fue planificada durante algo más de un año. A la cabeza de la misma estaba un comité del que fue miembro destacado el kapo Galewski, quien durante la revuelta defendió las posiciones dentro del campo permitiendo la huida de los prisioneros junto a un pequeño grupo de hombres que resistieron durante bastantes minutos y, con su acción, ayudaron a crear la confusión necesaria para que la «REVOLUCIÓN EN BERLÍN» (consigna con la que se inició la revuelta) fuese un notable éxito, habida cuenta de que, con toda la esperanza prácticamente perdida y sintiendo ya cercano el final de la vida del campo y de las suyas propias, lo que buscaron fue dejar testimonio al mundo de todo lo que habían sufrido durante ese largo año en Treblinka, donde el reloj siempre marcaba las 3 de la tarde.

Después de la revuelta en Sobibor, que sucedió casi al mismo tiempo, el (14 de octubre de 1943), se decidió cerrar los campos de exterminio de la Operación Reinhard. El comandante de la Operación, Odilo Globocnik, escribió a Himmler el 19 de octubre de 1943: «He completado la acción Reinhard y cerrado todos los campos». (5) p. 40).

En 1965, después de un informe del Dr. Helmut Kraunsnick, director del Instituto para la Historia Contemporánea en Múnich, el Tribunal de Casación en Düsseldorf concluyó que el número de personas asesinadas en Treblinka ascendía al menos a 700 000. En 1969, el mismo tribunal, después de tener nuevas pruebas reveladas en un informe por el experto Dr. Scheffler, elevó el número a 900 000. De acuerdo con los guardias alemanes y ucranianos que estaban de servicio en Treblinka, se cree que el número de víctimas estuvo entre 1 000 000 y 1 400 000. Entre aquellos que perecieron estaba Lidia Zamenhof, hija del iniciador del Esperanto, L. L. Zamenhof.

Es muy complicado establecer una cifra correcta del número real de personas, pues muchos testigos fueron asesinados posteriormente durante la guerra (que terminaría dos años después de que los campos hubieran sido cerrados, el 8 de mayo de 1945). Muchos archivos se perdieron o fueron destruidos, especialmente los concernientes a los transportes ferroviarios, los cuales fueron duramente bombardeados por la aviación aliada. Fueron encontrados menos de cien sobrevivientes de Treblinka al terminar la guerra.

En Israel, John Demjanjuk fue sentenciado a muerte el 25 de abril de 1988 por los crímenes de guerra cometidos en el campo. Fue acusado de ser un guardia notorio conocido como «Iván el Terrible» por los sobrevivientes y absuelto en 1993. Su deportación de Estados Unidos fue ordenada en 2006, pero no fue hasta el año 2008 que el investigador jefe de crímenes de guerra nazis, Kurt Schrimm, solicitó a la fiscalía de Múnich —donde Demjanuk vivía antes de emigrar a EE UU— que se le acusara de la participación en el asesinato de 290 000 judíos. Desde entonces, su caso ha estado sumergido en entramados y aplazamientos legales.

En la actualidad Treblinka es Monumento Nacional de Polonia.





</doc>
<doc id="28307" url="https://es.wikipedia.org/wiki?curid=28307" title="RNA (desambiguación)">
RNA (desambiguación)

RNA puede referirse a:





</doc>
<doc id="28309" url="https://es.wikipedia.org/wiki?curid=28309" title="The Misfits (película)">
The Misfits (película)

The Misfits ("Vidas rebeldes" en España, "Los inadaptados" en Hispanoamérica) es una película estadounidense en blanco y negro, de 1961, del género drama, dirigida por John Huston, con un guion escrito por Arthur Miller a partir de un relato corto que el dramaturgo había publicado inicialmente en la revista Esquire en 1957. Protagonizada por Clark Gable, Marilyn Monroe, Montgomery Clift, Thelma Ritter y Eli Wallach en los papeles principales. 

Roslyn ("Marilyn Monroe") es una mujer muy atractiva que se acaba de divorciar. Conoce a dos amigos, Guido ("Eli Wallach") y Gay ("Clark Gable"), con los que pasa unos días en la casa de Guido en el campo. Pronto ambos hombres se enamoran de ella y, compitiendo por Roslyn, muestran los rasgos negativos de sus personalidades. Después de unos días aparece otro amigo, Perce ("Montgomery Clift"), que es quien llega a gustar a Roslyn. Los cuatro se van a cazar caballos salvajes. La situación se hace insostenible.

La película fue filmada en el estado de Nevada y estuvo llena de incidentes, mayormente ocasionados por los problemas personales de John Huston y Marilyn Monroe y por el clima desértico que superaba los 40 grados.

Fue la última película que rodaron tanto Clark Gable como Marilyn Monroe y James Barton. El rodaje terminó el 4 de noviembre de 1960 y Clark Gable sufrió un infarto agudo de miocardio tres días después, muriendo el 16 de noviembre del mismo año. En 1962 Marilyn empezó a rodar otra película, la comedia "Something's Got to Give" junto a Dean Martin, pero falleció antes de terminarla y el filme no llegó a completarse.
James Barton falleció también en 1962 debido a un infarto agudo de miocardio

 en inglés

</doc>
<doc id="28310" url="https://es.wikipedia.org/wiki?curid=28310" title="Calidad de vida">
Calidad de vida

Calidad de vida es un concepto que hace alusión a varios niveles de generalización pasando por sociedad, comunidad, hasta el aspecto físico y mental, por lo tanto, el significado de calidad de vida es complejo y contando con definiciones desde sociología, ciencias políticas, medicina, estudios del desarrollo, etc.

Hay muchos tipos de condiciones de vida:

La calidad de vida se evalúa analizando cinco áreas diferentes. Bienestar físico (con conceptos como la salud, seguridad física), bienestar material (haciendo alusión a ingresos, pertenencias, vivienda, transporte, etc.), bienestar social (relaciones personales, amistades, familia, comunidad), desarrollo (productividad, contribución, educación) y bienestar emocional (autoestima, mentalidad, inteligencia emocional, religión, espiritualidad).

Un indicador comúnmente usado para medir la calidad de vida es el Índice de Desarrollo Humano (IDH), establecido por las Naciones Unidas para medir el grado de desarrollo de los países a través del Programa de las Naciones Unidas para el Desarrollo (PNUD), cuyo cálculo se realiza a partir de las siguientes variables:
Los países con el IDH más alto son Noruega, Nueva Zelanda, Australia, Suecia, Canadá y Japón.

La producción industrial y el crecimiento económico eran, en el pasado, los únicos elementos considerados en el nivel de desarrollo de un país. Aunque esta perspectiva dejaba de lado otros aspectos no tan directamente materiales, que el IDH sí considera. Si bien el IDH, se considera más adecuado para medir el desarrollo, este indicador no incorpora algunos aspectos considerados importantes para la medición del desarrollo, como el acceso a la vivienda, a una buena alimentación y a la cultura y las artes; entre otros.

La Organización Mundial de la Salud en su grupo estudio de Calidad de Vida la ha definido como "la percepción de un individuo de su situación de vida, puesto que en su contexto de su cultura y sistemas de valores, en relación a sus objetivos, expectativas, estándares y preocupaciones". Es un concepto amplio que se ha operacionalizado en áreas o dominios: la salud física, el estado psicológico, el nivel de independencia, las relaciones sociales, las creencias personales y su relación con las características más destacadas del medio ambiente.
Es en este sentido, que la operacionalización del concepto Calidad de Vida ha llevado a tal formulación y construcción de instrumentos o encuestas que valoran la satisfacción de personas, desde una mirada general. Sin embargo, las particularidades de los diferente procesos patológicos y la presión por objetivar su impacto específico, ha motivado la creación de instrumentos específicos relacionados a cada enfermedad y su impacto particular sobre la vida de las personas. De este modo, podemos distinguir instrumentos generales de calidad de vida y otros relacionados a aspectos específicos de los diferentes cuadros patológicos (instrumentos calidad de vida relacionados a la enfermedad) los factores básicos son la familia, educación, trabajo, infraestructura, y salud de cada persona.

Perfil de las Consecuencias de la Enfermedad:





</doc>
<doc id="28315" url="https://es.wikipedia.org/wiki?curid=28315" title="A Fish Called Wanda">
A Fish Called Wanda

A Fish Called Wanda (titulada "Un pez llamado Wanda" en España y "Los enredos de Wanda" en Argentina y en México) es una película británica-estadounidense de 1988, del género comedia, escrita por John Cleese y dirigida por Charles Crichton. Sus protagonistas principales son John Cleese, Michael Palin (ex-miembros del grupo cómico Monty Python), Jamie Lee Curtis y Kevin Kline.
Se hizo acreedora al Premio Óscar al mejor actor de reparto (para Kevin Kline) y a dos Premios BAFTA al mejor actor (para John Cleese) y a un premio BAFTA al mejor actor de reparto (para Michael Palin). 

La película gira en torno al robo a una joyería, planeado por George Thomason (Tom Georgeson), y las consecuencias que esto trae. La persona de confianza de George es Ken Pile (Michael Palin), un amante de los animales que además sufre de tartamudez. Junto con ellos vienen dos estadounidenses, la sensual estafadora Wanda Gershwitz (Jamie Lee Curtis) y el sicario y algo torpe Otto West (Kevin Kline); este último suele presumir de ser un intelectual, aunque el resto del grupo suele ratificarle su ignorancia, llamándolo estúpido —calificativo que él detesta. 

El robo se logra realizar a la perfección. Sin embargo, después del hecho, Wanda y Otto traicionan a George reportándolo con la policía. Tardíamente descubren que George había escondido el botín en un nuevo escondite, en un casillero, y no planeaba revelarles cuál específicamente. Wanda decide que la mejor forma de obtener información es seducir al abogado de George, Archibald Leach (John Cleese), un hombre atrapado en un matrimonio sin amor con una mujer rica y de mal carácter. Mientras tanto, Otto decide que el mejor método es hablar con Ken, primero pretendiendo estar enamorado de él, y luego atándolo y amenazándolo con comerse su pez tropical (uno de los cuales es un pez ángel llamado Wanda).

George encarga a Ken que asesine a una testigo, una mujer de edad avanzada (Patricia Hayes), dueña de tres Yorkshire terriers. En sus intentos por asesinarla, Ken termina matando accidentalmente a cada uno de los perros. A continuación de la muerte del último perro, la mujer muere de un ataque al corazón.

Después de varias traiciones entre el equipo y de que la llave del casillero cambiara varias veces de manos, todos corren al aeropuerto en un intento de huir con el dinero. Ken logra vengarse de Otto, lo que provoca que supere sus problemas de tartamudez. Mientras tanto, Wanda y Archibald, que se habían enamorado, logran huir. George finalmente queda preso.


</doc>
<doc id="28317" url="https://es.wikipedia.org/wiki?curid=28317" title="The Adventures of Robin Hood">
The Adventures of Robin Hood

The Adventures of Robin Hood (en España, Robin de los bosques; en Hispanoamérica, Las aventuras de Robin Hood) es una película de aventuras estadounidense de 1938 dirigida por Michael Curtiz y William Keighley, basada en la leyenda de Robin Hood. Protagonizada por Errol Flynn en el papel principal, Olivia de Havilland como Lady Marian, Basil Rathbone como Sir Guy de Gisbourne y Claude Rains como el Príncipe Juan. Se considera una de las mejores películas de aventuras de todos los tiempos.

Se trata de la primera versión a color del mito de Robin Hood. Consiguió tres Óscar de Hollywood: el de , y .

La película costó más de 2 millones de dólares, la mas costosa de Warner Bros. en su tiempo, y fue una de las pocas películas de la década de los 30 filmada en color. Fue una producción inusualmente extravagante para el estudio de Warner Bros, que hasta ese momento se había caracterizado por producir películas de gánsteres de bajo presupuesto, pero las películas de aventuras con Errol Flynn habían tenido éxito y esta película fue pensada para aprovechar el momento de éxito.

En 1995, la película fue considerada «cultural, histórica y estéticamente significativa» por la Biblioteca del Congreso de Estados Unidos y seleccionada para su preservación en el National Film Registry.

Inglaterra está devastada. El usurpador Juan Sin Tierra ha ocupado el trono tras la desaparición del rey Ricardo Corazón de León, que ha sido hecho prisionero por Leopoldo V de Austria, en su regreso de la Segunda Cruzada. 

Cuando la noticia llega a Inglaterra, Juan decide usurpar el trono con el apoyo de la nobleza normanda y usa el falso pretexto de pagar el rescate de Ricardo para imponer nuevos tributos que los más pobres no pueden pagar. Sir Guy de Gisbourne, partidario del príncipe Juan, intenta un día arrestar a un campesino que, llevado por la necesidad, ha cazado un ciervo en el bosque de Sherwood, acto penado con la muerte. Pero se lo impide Robert de Locksley, un caballero que desafía la autoridad de Juan y trata de proteger al pueblo sajón de los abusos de los nobles y que defiende los derechos de Ricardo. 

Proscrito por el usurpador, Robert de Locksley toma el nombre de Robin Hood y forma una banda de hombres proscritos como él con los que hostiga a los nobles que apoyan al usurpador. El malvado sheriff de Nottingham abusa de la población. Sólo Robin Hood vela por los pobres. 

Cuando Sir Guy y su prometida, Lady Marian, que le ha sido asignada por el príncipe Juan, transportan un tesoro en marcos al castillo de Kenworth, son asaltados por Robin Hood, que humilla de nuevo a Sir Guy.

Lady Marian descubre la verdad acerca de Robin y sus hombres y del usurpador. Se enamora del proscrito y decide ayudarle. Mientras, Sir Guy decide tenderle una trampa a Robin. Convoca un concurso de arqueros y el vencedor será declarado el mejor arquero de Inglaterra y recibirá una flecha de oro de manos de Lady Marian. Robin acude disfrazado de calderero.

La película tuvo una buena acogida y se convirtió en la sexta más taquillera del año, con unos 4 millones de dólares de ganancias en una época en la que la entrada costaba menos de 25 centavos. Warner Bros quedó tan encantada con el resultado que filmó otras dos grandes epopeyas en color antes de que llegara la siguiente década: "Dodge City" y "La vida privada de Elizabeth y Essex".

Debido a la popularidad de la película, el nombre e imagen de Errol Flynn quedaron unidos a la figura de Robin Hood a los ojos del público, incluso más que Douglas Fairbanks, quien había interpretado el papel previamente en 1922.

Las escenas y los trajes usados por los personajes han sido imitados y parodiados continuamente. Otro de los legados de la película fue la carrera de Trigger, el caballo que lleva Olivia de Havilland en la película y que aparecería en muchas otras producciones.



</doc>
<doc id="28319" url="https://es.wikipedia.org/wiki?curid=28319" title="Robin Hood: príncipe de los ladrones">
Robin Hood: príncipe de los ladrones

Robin Hood: príncipe de los ladrones ("Robin Hood: Prince of Thieves") es una película de aventuras de 1991 dirigida por Kevin Reynolds. Está protagonizada, entre otros, por Kevin Costner, Morgan Freeman, Mary Elizabeth Mastrantonio, Alan Rickman y Christian Slater. La música fue compuesta, orquestada y dirigida por el compositor Michael Kamen. Esta película se estrenó el 14 de junio de 1991 en Estados Unidos, el 21 de junio en España, y en julio y agosto del mismo año en el resto de Latinoamérica.

Robin Hood (Kevin Costner) es un noble inglés que, unido al rey Ricardo, Corazón de león en la Tercera Cruzada, es encarcelado en una prisión de Jerusalén. En su huida, conocerá al también preso Azeem (Morgan Freeman), que, agradecido porque Hood le ha salvado la vida, decide quedarse con él hasta devolverle el favor. 

Cuando Robin y Azeem llegan a Inglaterra, gobernada ahora por el déspota "sheriff" de Nottingham (Alan Rickman), ayudado por su primo Guy de Gisborne (Michael Wincott) y la bruja Mortianna (Geraldine McEwan), descubren que el padre de Robin, lord Locksley (Brian Blessed), ha sido asesinado por el "sheriff". Como venganza, Robin, ayudado por Azeem, empieza robar a la nobleza y la Iglesia enriquecida para alimentar a los más necesitados. Por ello, el "sheriff" pone precio a la cabeza de Hood en cien piezas de oro.

Escondidos en el bosque de Sherwood, Robin y Azeem conocen a personas que, por un motivo u otro, también se ocultan del poder del "sheriff" de Nottingham. Unidos por una misma causa, el grupo, liderado por Robin Hood, planea su venganza conjunta. Con lo que no cuenta nadie es que lady Marian (Mary Elizabeth Mastrantonio), con quien el "sheriff" quiere casarse y tener descendencia, y Hood están enamorados el uno del otro. 

Finalmente, cuando lady Marian es obligada a casarse con el "sheriff", será el grupo de Hood quien saquee la fortaleza real y libere al país de ese grupo de crueles gobernantes y, también, a la joven "lady".

Está ambientada en la época medieval.

Con 170 millones de dólares recaudados en Estados Unidos y 230 millones en el resto del mundo, "Robin Hood: Príncipe de los ladrones" únicamente fue superada en ventas ese año por "".

La crítica fue positiva con la película, pero no con Costner, al cual le recriminaron por su acento inglés en el filme. En cambio, Rickman fue alabado por su actuación de antagonista.

La balada «(Everything I Do) I Do It For You», de Bryan Adams, se mantuvo como número 1 en el Reino Unido durante 16 semanas, siendo también un éxito en Canadá y Estados Unidos.


La película fue nominada a los Óscars de 1992 en el apartado de mejor canción compuesta para una película por «(Everything I Do) I Do It For You», pero no consiguió la tan apreciada estatuilla dorada.

Además de esa nominación, la película ganó los premios ASCAP, BAFTA Film, BMI Film Music, Evening Standard British Film, Golden Screen, Grammy, ALFS, MTV Movie, Golden Reel, Razzie y el premio al artista joven.



</doc>
<doc id="28320" url="https://es.wikipedia.org/wiki?curid=28320" title="Romeo y Julieta (película de 1936)">
Romeo y Julieta (película de 1936)

Romeo y Julieta es una película basada en la obra teatral del mismo título de William Shakespeare.

Además de la música compuesta por Herbert Stothart para la película, también se utilizó la de la Obertura-Fantasía "Romeo y Julieta" de Piotr Ilich Chaikovski.

Fue la última película producida por Irving Thalberg, este moriría poco después de concluir el rodaje, el 14 de septiembre de 1936 de neumonía en Santa Mónica (California).

En la Verona medieval, Romeo Montesco y Julieta Capuleto se enamoran. No obstante, es un amor prohibido pues ambas familias están enfrentadas.
Al final de la obra Romeo Montesco y Julieta se "suicidan por el destino".





</doc>
<doc id="28322" url="https://es.wikipedia.org/wiki?curid=28322" title="Romeo y Julieta (película de 1968)">
Romeo y Julieta (película de 1968)

Romeo y Julieta es una película basada en la obra teatral del mismo título de William Shakespeare. Es la historia de dos adolescentes, cuya incontenible y desbordada pasión coloca el amor por encima de la muerte. Su relación se ve dramáticamente marcada por el absurdo y ancestral odio que se profesan sus familias: los Montesco y los Capuleto. La lucha por llevar adelante su amor desencadenará en una tragedia que los unirá finalmente en la muerte.

Esta es quizás la película más famosa de su director, el italiano Franco Zeffirelli, quien intentó seguir al pie de la letra el texto original de Shakespeare. Su deseo de ser enteramente fiel con la obra le llevó a respetar incluso la edad real de sus protagonistas, que habitualmente eran encarnados por actores adultos. Así, Romeo y Julieta fueron interpretados por un actor de 17 años y una actriz de 16, los entonces desconocidos Leonard Whiting y Olivia Hussey. El filme, en su propósito de combinar romanticismo y realismo, incluía escenas de semidesnudo consideradas audaces para la época, y que el director consideró lógicas y hasta necesarias en un relato de amor pasional.

Además, la experiencia de Zeffirelli en la ópera y el teatro (fue amigo y colaborador de Maria Callas) se dejó notar en la realización del film, muy cuidado en su dirección artística, en su fotografía en color y también en su banda sonora, compuesta por Nino Rota. La melodía "A Time for Us" alcanzó un perdurable éxito y sigue siendo versionada por cantantes melódicos (como Josh Groban) y orquestas de música clásica.

En Verona hay dos familias rivales, los Montesco y los Capuleto. Romeo, de la casa Montesco, conoce a Julieta, una hermosa joven, hija única de los Capuleto, y ambos se enamoran a primera vista. Se casan en secreto, con ayuda de Fray Lorenzo.

El mismo día de la ceremonia, Teobaldo insulta a Romeo; a pesar de ello, este rehúsa batirse en duelo. Pero Mercucio, el mejor amigo de Romeo, entabla duelo a muerte con Teobaldo. Romeo trata de separarlos y Teobaldo aprovecha para herir mortalmente a Mercucio. Romeo reta a Teobaldo y venga a su amigo matando a su adversario. El Príncipe de Verona condena a Romeo al destierro, por lo que hizo

El Conde Paris, pariente del príncipe, pide la mano de Julieta y le es concedida. Julieta se niega y pide auxilio a Fray Lorenzo, quien le aconseja que acepte la boda y le entrega un elixir que la sumirá en un estado parecido a la muerte. Le indica tomarlo la noche anterior a la boda y se compromete a estar con ella cuando despierte en la cripta de su familia, acompañado de Romeo; después, ambos jóvenes escaparían. Fray Lorenzo envía un mensajero a Romeo para que venga por Julieta en el momento de despertar. Pero el mensajero no encuentra a Romeo, ya que éste, avisado por su criado de que Julieta ha muerto, ha salido inmediatamente hacia Verona.

Romeo llega al cementerio e ingresa a la cripta de los Capuleto; junto a Julieta, la besa por última vez e ingiere un veneno que acaba con su vida a los pies de su amada. En ese momento llega Fray Lorenzo. 

Julieta despierta y el fraile trata de convencerla para que huya con él, pero la joven se niega al ver a su esposo muerto. Se acerca a Romeo, lo besa y se hiere con la daga de su esposo: muere abrazando a su amado.

En la última escena, el príncipe de Verona pronuncia un discurso en el que llama a la concordia a las dos familias enlutadas.




Ganó dos Premios Óscar en 1968:
y tuvo dos candidaturas más:






</doc>
<doc id="28326" url="https://es.wikipedia.org/wiki?curid=28326" title="Filipo II de Macedonia">
Filipo II de Macedonia

Filipo II (en griego: Φίλιππος Βʹ ὁ Μακεδών ["Phílippos II ho Makedṓn"], 382-336 a. C.) fue rey de Macedonia desde 359 a. C. hasta su muerte. Fue el padre de Alejandro Magno, y es posible que también de Ptolomeo I Sóter, fundador de la dinastía ptolemaica.

Su nombre en griego era Φίλιππος Β', que proviene del griego antiguo Φίλος "(filos):" ‘amigo’; e ἵππος "(ippos):" ‘caballo’.

Nacido en Pella, Filipo era el hijo más joven de Amintas III (394-370 a. C.) y Eurídice I. Filipo permaneció como rehén en Tebas, por entonces la polis hegemónica en Grecia, durante tres años (368-365 a. C.). En esa época Filipo recibió educación militar y diplomática de Epaminondas y vivió con Pamenes de Tebas, un entusiasta defensor del Batallón Sagrado de Tebas.

En 364 a. C. Filipo volvió a Macedonia, participando en asuntos de gobierno. A raíz de la muerte de sus hermanos mayores, los reyes Alejandro II y Pérdicas III, llegó a ser regente de su sobrino Amintas IV, hijo de Pérdicas III. El joven Filipo, de 22 años, se convirtió en el gobernante "de facto".

En sus tres años de estancia en Tebas, Filipo estudió de cerca los ejércitos griegos y su política. Se dio cuenta de que la nueva táctica de la ruptura que se enseñaba a los soldados, basada íntegramente en la falange, podía mejorarse mucho. En el campo político se apercibió que Tebas ya no era la ciudad fuerte ante Atenas, que se debilitaba y dejaría de dominar. La idea de este rey era llegar a la unidad política de todos los pueblos griegos bajo su mando.

Su primer cometido fue organizar un buen ejército, competente, disciplinado y numeroso, capaz de enfrentarse con los más grandes pueblos de aquel mundo conocido, capaz de dominarlo, como lo hizo, a lo largo de dos siglos. Filipo preparó el ejército no con mercenarios, sino con sus súbditos, para el posterior triunfo de Alejandro Magno, de la misma manera que Cayo Mario preparó en Roma el ejército que haría triunfar a César. El biógrafo griego Plutarco (c. 46-125 d. C.) escribiría siglos más tarde sobre esta coincidencia en su gran obra "Vidas paralelas".

El rey proporcionaba las armas:

Filipo reorganizó el ejército de Macedonia, que hasta entonces se basaba en la caballería, integrada a su vez por la nobleza. Aumentó el número de infantes, se preocupó por su equipamiento y les dotó de un arma nueva, la sarissa. Creó la falange, cuerpo concentrado de infantería formado por 16 filas de soldados, las seis primeras filas bajaban la sarissa para entrar en combate. Los flancos estaban protegidos por la caballería.

Se componía de:

Al principio este ejército lo componían 10 000 soldados. Poco a poco fue engrosando en número y alcanzó los 30 000 efectivos. Llegó a ser muy superior a todos los demás ejércitos de los distintos pueblos griegos, siendo no solo superior en número de contingentes, sino en un aspecto fundamental como era la organización y la disciplina. Filipo sabía que los griegos se habían ido relajando en sus costumbres y por tanto trató de corregir los fallos y errores. Los soldados griegos temían las grandes marchas, nunca se ponían en campaña si no era primavera, llevaban muchos carros y sirvientes consigo, lo que hacía que se llenaran los campos y retrasaran las marchas. Desde un principio, Filipo obligó a sus soldados a caminar 50 km diarios llevando sus armas e impedimentas, prohibió llevar vehículos y solo consintió un sirviente por cada 10 hombres y uno también para cada jinete. Además hizo campañas en invierno. Era muy rígido y contaba con la disciplina por encima de todo.

Para la lucha en el campo de batalla se colocaban en falange, que era la masa regular. La falange no era un invento de Filipo, ya existía entre los griegos, pero él supo perfeccionarla. La falange macedonia constaba de 16 filas de hombres armados con la "sarissa". Los de las 6 primeras filas sostenían con las dos manos la lanza en dirección al enemigo. Por delante de ellos iban asomando las lanzas de las filas de los que estaban detrás, de manera que la formación quedaba así:


Las últimas filas sostenían su lanza hacia arriba, se mantenían a la expectativa y cubrían bajas. En caso necesario, las ocho últimas filas hacían frente al lado opuesto, volviendo la espalda a sus compañeros. Entonces se formaba una agrupación impenetrable. La falange era una masa pesada, de movimientos lentos, que solo podía maniobrar en llano. Para movimientos rápidos, escalar alturas y atrincheramientos, Filipo contaba con infantes que llevaban un escudo pequeño y armas ligeras.

Otra cuestión de la que se ocupó el rey fue de la maquinaria de guerra, que llegó a ser la más completa que los historiadores hayan conocido hasta ahora. Se empleaba para sitiar ciudades y constaba de catapultas (que lanzaban grandes piedras y tizones encendidos) y torres móviles para alcanzar las murallas. Con este ejército tan preparado y tan bien equipado Alejandro Magno pudo realizar los sueños de su padre Filipo: conquistar Persia.

Sus ideas expansionistas de Macedonia y su capacidad militar pronto le llevaron a lograr grandes éxitos. Inmediatamente asentó el poder de la monarquía macedonia tanto dentro como fuera de sus fronteras. En el interior, acabó con los pretendientes que le veían como un usurpador y dominó a los príncipes de las regiones altas (Lincestia, Eilimia y Orestis). En el exterior, venció a una coalición de peonios e ilirios en 358 a. C., con lo que Filipo extendió sus dominios tierra adentro hasta el lago Ócrida.

Luego aprovechó la Guerra Social (o Guerra de los Aliados) de 357-355 a. C. para expandirse. En 357 a. C. tomó la colonia ateniense de Anfípolis, que controlaba las minas de oro del monte Pangeo, reteniéndola a pesar de las promesas de devolvérsela a los atenienses. Ese mismo año, Filipo se casó con la princesa Olimpia de Epiro, hija del rey de Molosia.

En 356 a. C. conquistó Pidna, y a continuación Potidea, ciudad que entregó a la Liga Calcídica en contra de los intereses de Atenas. Tras derrotar a una nueva coalición de tracios, ilirios y peonios, apoyada por Atenas, Filipo se sintió lo suficientemente fuerte como para postergar a su sobrino, dejarse de ficciones y proclamarse rey de Macedonia, con el nombre de Filipo II.

En el mismo 355 a. C. conquistó la ciudad de Crénidas (a la que bautizó con su nombre llamándola Filipos o Filípolis) cerca de la costa del mar Egeo, a orillas del río Hebro y al otro lado de la zona minera del monte Pangeo. Desde esta ciudad podía tener el control absoluto de la producción de oro y a partir de ese momento, Filipo pudo acuñar en este metal y dejar de lado la plata que patrocinaban otras ciudades.

También atacó Abdera y Maronea, en la costa de Tracia, ciudad que antes había pertenecido a Atenas. Con la conquista de Metone, en la que Filipo perdió el ojo derecho, finalizó la primera fase de expansión por la costa (354 a. C.). Aliado con los Aleuadas de Larisa, intervino en Tesalia, desgarrada por la Tercera Guerra Sagrada, siendo derrotado por Onomarco en dos ocasiones (353 a. C.). Sin embargo, en la llamada batalla del Campo de Azafrán, en 352 a. C., Filipo aniquiló por completo a las huestes de Onomarco, el cual fue crucificado. Tres mil prisioneros fueron arrojados al mar, y como consecuencia de la derrota, el tirano Licofrón fue expulsado definitivamente de Feras.

Sin embargo, no pudo penetrar en la Grecia central, al estar bloqueadas las Termópilas por los focidios de Failo, apoyados por atenienses y espartanos. Entonces, reorganizó Tesalia bajo su hegemonía y se retiró hacia Epiro primero, y hacia el noreste después, extendiendo su área de influencia y sometiendo las ciudades costeras griegas del Mar Negro hasta el río Hebro (352-351 a. C.).

Su siguiente ataque lo lanzó en 350 a. C. sobre la península Calcídica, con la que hasta entonces había mantenido relaciones amistosas. Sincronizó la campaña con una revuelta que instigó en Eubea para impedir la intervención ateniense. Ese mismo año conquistó Estagira, y en el 348 a. C. destruyó su principal ciudad, Olinto, con lo que la Calcídica quedó sometida al dominio macedonio. Con Macedonia y las regiones adyacentes consolidadas, Filipo celebró unos juegos olímpicos en Dion. En 347 a. C. avanzó para conquistar los distritos más orientales del Hebro y obligó a someterse al príncipe Cersobleptes de Odrisios.

Estos hechos provocaron que en Atenas se empezara a hablar de paz, aunque todavía predominara la tendencia favorable a la guerra, por lo que Filipo esperó a la primera ocasión favorable. Esta se dio en 347 a. C., con motivo del final de la Tercera Guerra Sagrada: los beocios llamaron en su auxilio al poderoso Filipo, quien acudió inmediatamente. En consecuencia, los focidios apelaron nuevamente a Atenas y Esparta. Sin embargo, aprovechando las disensiones internas de los focidios, Filipo llegó a un acuerdo con su jefe Faleco, el hijo de Onomarco, que se había apostado en las Termópilas con un ejército mercenario. Faleco dejó pasar a Filipo y se retiró al Peloponeso. Respecto a Filipo, penetró en la Grecia central (346 a. C.), derrotando a los focidios en la batalla de la llanura de Crocus. Esta batalla le convirtió en el gobernador ("tagus") de Tesalia, en donde reclamó también el control de Magnesia, que tenía el importante puerto del Golfo de Pagasae. Focea fue expulsada de la Anfictionía de Delfos, y sus votos pasaron a Filipo, que fue admitido en la misma (aunque no de muy buen grado), con lo que adquirió una sólida posición de poder y prestigio en el mundo griego. Filipo aprovechó su posición en la Anfictionía para dominar los asuntos de Grecia y tener el control del Oráculo de Delfos, de suma importancia para cualquier decisión militar o política que hubiera que tomar.

A Atenas no le quedó otra solución que la paz, que solicitó al monarca macedonio a través de Filócrates. En ella se garantizaba a cada parte sus territorios conquistados, y se establecía una alianza defensiva, lo que dio ocasión al orador Isócrates para exhortar a Filipo a dirigir sus ejércitos contra los persas. 

Con las principales ciudades estado griegas sometidas, Filipo se dirigió contra Esparta y les envió un mensaje:

La respuesta de Esparta, fiel a su tradición lacónica, fue sencillamente: «Si». 

A pesar de las advertencias de Demóstenes, los atenienses dejaron hacer a Filipo, que consolidó su influencia en Grecia y reconoció la independencia de Mesenia y Arcadia. Al mismo tiempo, asentó sus dominios en Iliria, reorganizó de nuevo Tesalia (343-342 a. C.), intervino en Epiro, expulsando a Arribas y entronizando a Alejandro de Epiro, y firmó un tratado con el gran rey de los persas, Artajerjes III (343 a. C.), lo que le permitió extender sus posesiones en el territorio tracio, dirigiendo una gran expedición militar que conquistó la ciudad fortificada de Eumolpia, renombrándola "Filipópolis" (hoy Plovdiv). En 342 a. C., negoció un acuerdo secreto con Hermias, tirano de Atarneo, asistido por Aristóteles, con el objeto de tener una cabeza de puente en caso de invadir Asia.

Demóstenes ansiaba la guerra contra los macedonios, considerados unos bárbaros, y con sus discursos solivianta y prolonga la enemistad de Atenas con Macedonia: son las famosas "Filípicas". La expansión macedonia en la región de los Estrechos alarmó a los atenienses, que, conducidos por Demóstenes, declararon la guerra a Filipo (340 a. C.). Éste comenzó los asedios de Perinto (340 a. C.) y Bizancio (339 a. C.), fracasados por su carencia de fuerzas navales, y vio temporalmente comprometida su influencia en toda Grecia. Sin embargo, aprovechó la Cuarta Guerra Sagrada para decidir el conflicto en tierra. Nombrado "hegemon" de la Anfictionía, Filipo penetró en la Grecia central y venció en la Batalla de Queronea (338 a. C.) a los tebanos y atenienses aliados. En esta batalla, su hijo Alejandro, de 18 años de edad, llevó a cabo su primera acción militar al mando de 1800 jinetes. Tras la victoria Filipo erigió un león de mármol en memoria del Batallón Sagrado de Tebas por su valentía en la batalla.

Después de esta gran victoria, Filipo demostró una gran sabiduría política al no humillar a los vencidos. El macedonio instauró su hegemonía sobre Grecia, constituyendo la Liga de Corinto (337 a. C.), que incluía a todos los Estados griegos, a excepción de Esparta. La Liga garantizaba la paz general, la autonomía interna de cada miembro, salvo para reprimir revoluciones, y una alianza perpetua bajo el mando de Filipo, a quien la Liga concedió el mando de la guerra contra Persia.
Mientras se realizaban los preparativos de la expedición, con el envío de un ejército a Asia Menor bajo el mando de Parmenión y Átalo, Filipo fue asesinado.

En el año 337 a. C., Filipo se divorcia de Olimpia. Su intención era volverse a casar con una noble macedonia, Eurídice, sobrina del general Átalo. Para aplacar el descontento de los nobles de Molosia (de donde era Olimpia), trama un matrimonio de conveniencia entre su propia hija Cleopatra y un hermano de Olimpia, Alejandro de Epiro, que era rey vasallo en Molosia.

Para la boda se organizaron grandes fiestas en Egas (primera capital de la antigua Macedonia). Desde el amanecer avanzaban en procesión solemne las estatuas de los doce dioses sentados en tronos lujosos muy adornados. Una estatua hacía la número trece: era la efigie del gran Filipo. Hubo un gran banquete y a continuación todos se dirigieron al teatro para terminar allí el agasajo. Llegó Filipo, que se había vestido de blanco para la ocasión, y cuando se disponía a entrar en el recinto sin guardaespaldas (resaltando ante los diplomáticos griegos ahí presentes su cercanía al pueblo), se le abalanzó un joven noble macedonio y le hirió en un costado. Murió al instante allí mismo. El asesino se llamaba Pausanias (como el famoso general del siglo V a. C. y el famoso historiador del siglo II), uno de sus siete guardaespaldas. El asesino inmediatamente intentó escapar y alcanzar a sus compañeros en la conspiración, que le esperaban con caballos en la entrada de Egas. Fue perseguido por tres guardaespaldas de Filipo y murió a sus manos.

Las razones para la acción de Pausanias son difíciles de responder completamente, dado que existe controversia incluso entre los historiadores antiguos. El único relato contemporáneo que ha llegado es el de Aristóteles, que comenta que Filipo fue asesinado porque Pausanias había sido ofendido previamente por los seguidores del general Átalo, suegro del rey.

Cincuenta años más tarde, el historiador Clitarco de Alejandría amplió y embelleció la historia. Siglos más tarde su versión sería narrada por Diodoro Sículo y por todos los historiadores que se basaron en Clitarco. En el libro dieciséis de la historia de Diodoro, Pausanias habría sido un amante de Filipo, que habría tenido un ataque de celos cuando Filipo cambió sus preferencias por otro hombre más joven, también llamado Pausanias. Sus intentos por conseguir al joven acabarían haciendo que éste se suicidase, lo que llevaría a que su amigo Átalo se enemistase de Pausanias. Átalo acabaría vengándose invitando a Pausanias a cenar, emborrachándole y sometiéndole a abusos sexuales.

Cuando Pausanias acudió a Filipo, el rey se vio incapaz de castigar a Átalo, dado que estaba a punto de enviarle a Asia con Parmenión para preparar la invasión. También se había casado con la sobrina o hija de Átalo, Eurídice. En lugar de ofender a Átalo, Filipo trató de compensar a Pausanias ascendiéndole dentro de la guardia real. Sin embargo, parece que el deseo de venganza de Pausanias habría dado un giro contra el hombre que no había cumplido en vengar su honor herido, por lo que planeó matar a Filipo y, algún tiempo más tarde, con Átalo ya en Asia, puso su plan en marcha.

Otros historiadores (por ejemplo, Juniano Justino 9.7) sugieren que Alejandro o su madre Olimpia eran conocedores de la intriga, si no incluso los instigadores. Al parecer, según el historiador, Olimpia habría agradecido a Pausanias su acción poniendo una corona encima del cuerpo del asesino, erigiendo un monumento en su memoria y ordenando sacrificios anuales en su honor.

Muchos historiadores modernos entienden que todos los relatos son improbables. En el caso de Pausanias, el motivo que se alega para el crimen parece muy forzado. Por otro lado, la implicación de Alejandro y de Olimpia arroja dudas: actuar como se supone que hicieron habría requerido actuar directamente contra la máquina militar, que era leal a la persona de Filipo. Lo que parece que se recoge en estas historias son las sospechas naturales que recaen en los principales beneficiarios del asesinato. Podría incluso haber parte de propaganda esparcida por los enemigos políticos dentro de los relatos posteriores al acontecimiento, y más teniendo en cuenta que Átalo sería posteriormente ejecutado en la consolidación del poder por Alejandro tras el asesinato.

Por todo ello, los historiadores de todos los tiempos han barajado muchas teorías sobre el caso. Lo primero que han hecho siempre ha sido preguntarse quién salía beneficiado con la muerte de Filipo, pero esta pregunta tiene muchas réplicas. Varios personajes pudieron estar implicados, como por ejemplo:

Cada autor presenta su tesis y sus teorías, pero el asesinato de Filipo sigue siendo un misterio. Para evitar caer en el vicio de la soberbia, el rey Filipo de Macedonia, situó un esclavo a la puerta de su dormitorio que cada mañana le decía: ""Levántate, rey, y piensa que no eres más que un miserable mortal"". De forma parecida, los emperadores romanos se hacían acompañar en sus triunfos de un siervo que les decía: ""Recuerda que eres solo un hombre"".

De él se dice que era un excelente jinete, gran nadador y un soldado muy sufrido en campaña. De maneras afables, conversación animada y gusto por los festines.

Con Fila.

Carano, hijo varón, asesinado durante la segunda mitad de 336 a. C. luego del asesinato de su padre durante el transcurso de la boda entre Alejandro I de Épiro y Cleopatra de Macedonia.

Con Audata, princesa iliria.

Hijos:

Aproximadamente en 358 a. C.: de una relación (ilegítima) con Filina, una bailarina de Tesalia, nació Filipo III de Macedonia o también Filipo Arrideo. Se decía que era la encarnación de Gaia y esa fue la razón por la que su medio hermano Alejandro Magno no le asesinó al subir al trono, como hizo con algunos de sus otros hermanos. Esta era una práctica habitual y de costumbre en esa época. También su condición de hijo ilegítimo no constituía riesgo político sucesorio alguno para Alejandro III por lo cual fue el único hijo varón de Filipo II que sobrevivió a la muerte de su padre durante la segunda mitad del año 336 a. C., al asumir Alejandro Magno como rey de Macedonia

Con Polixena (a partir de ahora Mirtale), quien luego volvió a modificar su nombre por Olimpia de Epiro al nacer Alejandro III en 356 a. C. en homenaje a la gran batalla en la que Filipo II venció en el monte Olimpo para dicha fecha.

Hijos:

Aproximadamente en 342 a. C.: de una relación (ilegítima) con Nicesípolis de Feres (Tesalia), nació Tesalónica de Macedonia. Su madre murió a los pocos meses de tenerla, y su madrastra, Olimpia de Epiro, es quien aparentemente se ocupó tanto de su educación como de su propia crianza como si fuera su propia hija, ya que al parecer Olimpia y Nicesípolis eran grandes amigas, más allá de esta relación ilegítima que mantenía Filipo II en esta oportunidad con Nicesípolis, siendo Olimpia de Epiro, la legítima reina de Macedonia.

Con Cleopatra (conocida históricamente como Cleopatra Eurídice de Macedonia), sobrina de un noble llamado Atalo, perteneciente a la nobleza macedónica de Pella, la ciudad capital durante el reinado de Filipo II.

Hijos:
Luego del asesinato de Filipo II, fue también asesinada junto con el príncipe Carano y otros familiares del difunto rey luego de mediados del año 336 a. C. Se atribuyen todos estos asesinatos posteriores al del rey Filipo II a Alejandro III aunque cabe evaluar la hipótesis más amplia del resultado de toda una combinación de tensiones políticas internas en el Reino de Macedonia que favorecieron y facilitaron tanto el asesinado de Filipo II como la llegada de su hijo Alejandro III al Trono, pudiendo estar involucrados adicionalmente a Alejandro Magno, integrantes de la nobleza macedónica y/o rivales políticos internos del propio Filipo II en una alianza con su hijo Alejandro III.

El 8 de noviembre de 1977, el arqueólogo griego Manolis Andronikos encontró, entre otras tumbas, un sepulcro real intacto en la necrópolis de la antigua Vergina en la prefectura de Emacia. Los descubrimientos que se hicieron en esta tumba fueron mostrados al público en una exposición itinerante llamada "La Búsqueda de Alejandro", que se mostró en cuatro ciudades de Estados Unidos entre 1980 y 1982.

Si bien inicialmente se identificaron como pertenecientes a Filipo II, Eugene Borza y otros historiadores han sugerido que la tumba realmente perteneciese a su hijo, Filipo Arrideo. Las discusiones acerca del particular a menudo se centran en contradicciones entre "el cuerpo" y el "esqueleto" de Filipo II, así como en las fuentes más fiables sobre su vida (y sus heridas).

En junio de 2015 se dieron a conocer los resultados de un estudio osteoarqueológico profundo realizado por Theodore Antikas y Laura Wynn-Antikas que apoyaba la identificación de los huesos hallados en la tumba II de Vergina con los de Filipo II de Macedonia, aunque no se pudo confirmar mediante pruebas de ADN. Por otra parte, en julio de 2015 se publicaron los resultados de otro estudio realizado por un equipo de investigadores liderado por Antonis Bartsiokas y Juan Luis Arsuaga que defiende, en cambio, que los restos de Filipo II corresponden a los de un varón de mediana edad hallado en la tumba I.





</doc>
<doc id="28327" url="https://es.wikipedia.org/wiki?curid=28327" title="Taxi Driver">
Taxi Driver

Taxi Driver es una película estadounidense dramática de dirigida por Martin Scorsese y escrita por Paul Schrader. Está protagonizada por Robert De Niro.

El filme está ambientado en la Nueva York de los años '70, poco después de que terminara la guerra de Vietnam, y se centra en la vida de Travis Bickle, un excombatiente solitario y mentalmente inestable que comienza a trabajar como taxista, incorporándose a la turbia vida nocturna de la ciudad. El reparto cuenta también con la presencia de Cybill Shepherd como la mujer que trabaja en la propaganda del candidato presidencial Palantine y de quien Travis está enamorado; Jodie Foster como una prostituta de 13 años con quien Travis forma un lazo, y Harvey Keitel como su proxeneta. El propio Scorsese realiza un pequeño cameo.

La película obtuvo varios premios, entre ellos la Palma de Oro del Festival de Cannes, y cuatro nominaciones al Oscar. Actualmente es considerada tanto una película de culto como una de las mejores de su época; también suele ser evaluada por críticos profesionales como una de las mejores películas de todos los tiempos y una obra maestra de su director.

En 1994, la película fue considerada «cultural, histórica y estéticamente significativa» por la Biblioteca del Congreso de Estados Unidos y seleccionada para su preservación en el National Film Registry.

Travis Bickle, un ex-marine solitario y deprimido que vive en la ciudad de Nueva York de fines de los años '70. Al padecer de insomnio crónico, se pone a trabajar como taxista, conduciendo pasajeros cada noche por los suburbios. También pasa tiempo en los cines porno de mala muerte y escribe un diario. Travis se enamora de Betsy (Cybill Shepherd) una voluntaria en la campaña presidencial del senador Charles Palantine. Después de ver a Betsy charlar con otro voluntario, Travis entra como voluntario en la campaña del senador, tan solo con el pretexto para hablar con ella y consigue llevarla a tomar un café. Más adelante, en una segunda cita, la lleva a ver una película sexual educativa sueca, ella se ofende, sale del cine y se va a casa sola en un taxi. Travis intenta arreglar la situación enviándole flores que serán rechazadas y llamándole en otras ocasiones por teléfono, siendo rechazado consecutivamente.

Travis comenta con un compañero sus pensamientos, pues teme que le vayan a empujar a la violencia, pero éste le asegura que todo se calmará e irá mejor. Travis comienza un programa de entrenamiento físico intenso. Compra armas y adapta una pistola para poder ocultarla en la manga del brazo. Una noche, Travis entra en una tienda antes de que un hombre intente robar, y le dispara. El dueño de la tienda se hace responsable y Travis se va. Otra noche, una prostituta menor de edad, Iris (Jodie Foster), entra en el taxi de Travis, escapando de su proxeneta, Matthew "Sport" Higgins. Higgings saca a Iris del taxi y lanza a Travis un billete de veinte dólares. Más adelante Travis contrata los servicios de Iris, pero en lugar de tener relaciones sexuales con ella, intenta disuadirla de continuar en la prostitución, y consigue citarse con ella para el desayuno del día siguiente. A Travis le obsesiona ayudarla para que regrese a casa de sus padres, y envía dinero y una carta en la que afirma que pronto estará muerto. 

Después de afeitarse la cabeza al estilo mohawk, Travis asiste a un acto público en el que intenta asesinar al senador Palantine, pero los agentes de seguridad recelan de él y se ve forzado a huir sin llegar siquiera a disparar. Regresa a su apartamento y luego conduce hasta el East Village, donde se enfrenta a “Sport” Higgings. Travis le pregunta si conoce a Iris pero sport se niega a responder aludiendo que no conoce a nadie llamada Iris y le pide que se largue, finalmente Travis le pregunta si lleva un arma, por lo cual Sport le lanza su Cigarro que estaba fumando, le da una patada y le dice de forma brusca que se largue, acto seguido Travis saca su arma y después de decirle "Trágate esto" le dispara y a continuación, entra en el burdel en busca de Iris. Al entrar Travis se encuentra con el hombre que había pagado por los servicios de Iris, por lo cual Travis le dispara en la mano derecha volándosela en pedazos, el sonido del disparo sonó tan fuerte que el estruendo se escuchó hasta la habitación donde se encontraba Iris. Después de esto aparece “Sport” Higgings quien había quedado herido y le dispara a Travis en el cuello sin llegar a matarlo. Travis vuelve a disparar y mata a Higgings, entonces Travis se acerca al cadáver de Sport y le vuelve a disparar para asegurarse de que este muerto. Acto seguido, Travis se dirige a donde está Iris mientras que el hombre al que había disparado anteriormente (dolorido de su mano recién mutilada) comienza a perseguirlo y a insultarlo, alegando de que lo va a matar. Inmediatamente, el encargado de las habitaciones sale de la habitación donde estaba Iris, con un arma en mano para disparar a Travis, que dándole en el brazo provoca que su arma caiga y quede fuera de su alcance. En ese instante Travis extrae una pistola de repuesto que llevaba escondida en la manga y dispara al encargado acertando en la cara, provocado que este retroceda debido al dolor de los disparos hacia la habitación de donde salio y caiga muerto en frente de Iris, quien presencia este acto con horror. Después, Travis se dirige a la habitación, pero al entrar el proxeneta que lo persigue lo tumba al suelo y comienza a golpearlo con su mano izquierda, pero Travis desenvaina un cuchillo que tenía oculto en su pierna y se lo clava al hombre en su respectiva mano. Inmediatamente toma el arma del encargado y le dispara dándole muerte. Iris comienza a llorar horrorizada mientras Travis intenta suicidarse, pero no queda pistola con munición a su alcance, por lo cual se sienta desfallecido en el sofá que está junto a Iris, quedando ambos en absoluto silencio. La escena finaliza con la policía entrando en la habitación donde se encuentran ambos, que al ver a Travis este les devuelve un gesto simbólico de él mismo disparándose en la cabeza 3 veces con sus dedos en forma de pistola (probablemente en alusión a los 3 asesinatos que acababa de cometer) mientras sonríe pícaramente, dando a entender su culpabilidad. 

Travis queda convaleciente, y mientras se recupera recibe una carta de los padres de Iris, agradeciéndole que salvara a su hija. Los medios de comunicación lo califican de héroe. Al poco tiempo Travis vuelve a su trabajo y se encuentra con que Betsy sube a su taxi. Ella habla de su nueva fama, pero él niega ser un héroe. Al llegar a su casa, ella baja del taxi y le pregunta de pie al lado de la ventanilla del conductor cuánto marca el taxímetro. Travis le sonríe contestándole un seco "Adiós", y arranca el auto para verla por el espejo retrovisor. Luego se aleja y vuelve a perderse en sí mismo, mientras contempla la ciudad.


Martin Scorsese le ofreció el papel de Travis a Dustin Hoffman. Según Hoffman, rechazó el papel porque pensó que "Scorsese estaba loco"; después de ver el film, Hoffman lamentó su decisión. Hay dos intervenciones de Scorsese en el film: la primera y la más conocida, es la del cliente que está siendo engañado por su esposa, el cual le cuenta a Travis sus intenciones de matarla. La segunda es en la primera aparición de Betsy, donde le vemos sentado en un banco dirigiendo su mirada a la chica.

Robert De Niro trabajó un mes como taxista para poder interpretar el papel. La escena en la que Travis está parado frente al espejo y finge una confrontación fue totalmente improvisada, ya que en el guion solo aparecía la frase: "Travis se mira al espejo". La frase "¿estás hablando conmigo?" se ha convertido en una de las frases más famosas de la historia del cine, haciendo aparición en una gran cantidad de películas y series.

Paul Schrader terminó el guion en cinco días, y mientras lo escribía mantenía una pistola cargada en su escritorio, para motivarse e inspirarse.

Jodie Foster tenía trece años cuando la película fue filmada, por lo que no pudo hacer escenas que incluían desnudos. Su personaje también tenía trece años. Connie Foster, la hermana mayor de Jodie (quien tenía diecinueve años cuando la cinta fue hecha) fue elegida como su doble para realizar esas escenas.

La película recaudó más de $28.000.000 de dólares, superando por mucho su presupuesto de $1.300.000.

Las críticas en el momento de su estreno fueron en general positivas, y con el tiempo fue aclamada casi unánimemente como una de las mejores películas de todos los tiempos. Actualmente posee un promedio de aprobación de 98% en Rotten Tomatoes.




</doc>
<doc id="28334" url="https://es.wikipedia.org/wiki?curid=28334" title="Comunismo">
Comunismo

El comunismo es un tipo de organización socioeconómica caracterizada por la propiedad en común de los medios de producción, la ausencia de propiedad privada sobre el trabajo, la inexistencia de clases sociales y de Estado. 

El comunismo como proyecto de socialización de los medios de producción surgió en el siglo XVI bajo la forma de diversas utopías basadas en el colectivismo agrario. Las más conocidas fueron la obra "Utopía" de Tomás Moro y la ideología revolucionaria babuvina que derivó del movimiento jacobino de la Revolución francesa. El ideario comunista se convirtió a comienzos del siglo XIX en un complejo proyecto económico industrial gracias a las diferentes corrientes del llamado socialismo utópico, del anarcocomunismo y las ramas obreras del comunismo cristiano. El actualmente más conocido de estos movimientos fue el que adoptó la escuela del denominado socialismo científico de los pensadores alemanes Karl Marx y Friedrich Engels, bajo la cual sería rebautizado como Liga de los comunistas. Por la influencia de su obra, el movimiento comunista adoptó una interpretación revolucionaria de la historia y la forma de partido político, convirtiéndose luego en una organización internacional unificada bajo la doctrina marxista.

Según el marxismo, la historia es entendida como un permanente conflicto por el excedente material, cuyo inicio se debe a la aparición de la propiedad. Las diferentes formas de propiedad ponen fin al comunismo primitivo y estratifican a la sociedad en clases de acuerdo a sus relaciones de producción. Las diferentes relaciones de producción que vinculan a los hombres y mujeres requieren de la explotación, y estas relaciones generan con el tiempo las condiciones para ser reemplazadas por otras formas de explotación superiores, en una secuencia revolucionaria de modos de producción. En cada uno de estos modos se desarrolla una lucha de clases interna entre los diferentes tipos de trabajadores y explotadores que los integran, y que se resuelve con el surgimiento de nuevas clases dominantes. Sin embargo, la sociedad capitalista genera una serie creciente de crisis internas y cíclicas que sólo pueden ser resueltas por sus trabajadores asalariados en una revolución proletaria, que requiere a su vez de la construcción del comunismo. Para llegar a este fin debe organizarse un partido comunista que conquiste el poder político liderando una fase de transición en la que el Estado funcione como una dictadura del proletariado. Este período termina cuando desaparecen las clases sociales, lo cual lleva a que el Estado, de acuerdo a su concepción como herramienta de dominación de una clase sobre la otra, deba extinguirse. A esta transición le siguen inmediatamente dos períodos en el desarrollo del comunismo: una primera fase y una fase superior. Existen discrepancias cruciales entre las diferentes corrientes del marxismo sobre cual debería ser la naturaleza de cada una de estas tres fases.

El comunismo (de "común"), entendido como concepto sociológico, refiere a un orden socioeconómico basado en la posesión colectiva de los bienes, sea de producción o de consumo. 

En la definición del sociólogo Émile Durkheim, el comunismo es descrito como aquel orden social (propiamente comunal) en el que el consumo se organiza colectivamente, mientras persiste una elección libre e individual del papel en la producción (aunque el producto del trabajo se dedique al servicio de la comunidad). El comunismo es así definido en oposición al socialismo en el cual se pauta colectivamente la producción y la forma del trabajo, mientras que el consumo se disfruta en privado y depende de un libremente elegido aporte laboral a la sociedad:

El economista y sociólogo Max Weber parece coincidir con esta definición respecto al llamado "comunismo doméstico", pero no respecto al comunismo en general. Para Weber el término "socialismo" se puede usar a fines prácticos como una forma de describir una forma "racional" de comunismo en la cual la producción y el consumo de los individuos son también organizados en forma colectiva, mientras que en los eventuales comunismos premodernos tanto la producción como el consumo son individualmente libres pero su objetivo y origen, respectivamente, son siempre un fondo colectivo común: 

Weber describe la naturaleza de la forma más cabal del comunismo como una planificación general que organiza la producción, contrastándola con una sociedad de mercado:

El sociólogo Ferdinand Tönnies describe cómo en el comunismo la finalidad última de los medios sociales de producción y de los bienes fabricados es colectiva y a la vez compartida por todos, mediante la participación directa de los miembros en un único ámbito de vida común que los implica, noción que es compartida como el matiz etimológico para deducir el concepto del término.
Karl Marx describió en sus primeros manuscritos la naturaleza del desarrollo y formas que toma la idea del comunismo como proyecto social en función de la naturaleza de la propiedad privada que genera las condiciones para su desarrollo, pero sin intentar una definición esencialista ni una diferenciación entre comunismo y socialismo:

Por su parte Friedrich Engels tomó del antropólogo Lewis Henry Morgan la idea de que hubo un período de comunismo primitivo en el inicio del desarrollo histórico de las sociedades humanas, y la sistematizó en su libro "El origen de la familia, la propiedad privada y el Estado", en el cuál se describe la naturaleza del mismo desde una óptica más cercana a la de la sociología empírica. 

El marxismo comparte con la sociología clásica posterior que el comunismo se distingue por implicar la no especialización en la división del trabajoy la inexistencia de dinero para la circulación de los bienes.

Entre los ejemplos históricos concretos de ordenamientos sociales que pueden ser definidos propiamente como comunistas desde el punto de vista sociológico, se puede contar a: el comunismo cristiano premoderno (el comunismo familiar de la Iglesia católica primitiva), y el moderno (sistematizado por Tomás Moro y experimentado por los Shakers de Mánchester, los Cavadores de Gerrard Winstanley y el propulsado por el movimiento obrero de la Liga de los justos de Wilhelm Weitling), las formas protocomunistas del mazdakismo persa, el comunismo feudal que llamó la atención del último Marx (los Mir tradicionales rusos, los isleños escoceses de St Kilda), variantes secularizadas del comunismo religioso milenarista (Gabriel Bonnot de Mably, Morelly) y movimientos no revolucionarios como el de las comunas hippies y los kibbutz israelíes, entre otros. Mayoritariamente estas formas de vida comunista no han dependido de una doctrina política que las establezca.

El comunismo, en el sentido político, es un movimiento cuya doctrina se basa en el marxismo y que, de acuerdo con esta doctrina, tiene por principal objetivo la toma transitoria del poder del Estado para la instauración de una revolución social que, a través de tres fases, implante una organización económica y social socialista/comunista basada en el control colectivo de la producción.
El comunismo está representado por una organización internacional que lleva el nombre de Internacional Comunista y que coordina en cada región a un partido político que a su vez suele llevar el nombre de comunista. Cada corriente doctrinal comunista tiene su propia "Internacional".

Históricamente los múltiples partidos comunistas adoptaron, bajo su liderazgo, la obra de Karl Marx y Friedrich Engels como doctrina y programa político-revolucionario, la cual fue sistematizada bajo el nombre de marxismo. Con la toma del poder por parte de los comunistas en Rusia bajo el mando de Vladimir Lenin en octubre de 1917, el liderazgo ideológico sobre los partidos comunistas del mundo pasó a estar en manos de la Internacional Comunista. Posteriormente a su muerte, las aportaciones teóricas aportadas por Lenin al marxismo fueron conocidas mediante el nombre de leninismo. Son, por ejemplo, la teoría del imperialismo como fase superior del capitalismo, o la teoría del partido de vanguardia como herramienta necesaria para encabezar al movimiento obrero y al resto de clases explotadas en la conquista del poder político y la subversión del modo de producción capitalista, mediante la destrucción del Estado burgués y su sustitución por un Estado obrero.

Iosif Stalin, bajo su mandato en la Unión Soviética, utilizaría posteriormente el nombre marxismo-leninismo para formular su ideología política, oficialmente basada en el marxismo y el leninismo. Este nombre, sin embargo, no alude a la unión de ambas ideologías, sino que es un término específico creado para describir la línea que Stalin implantó en el PCUS y la Comintern y sus partidos, así como en la mayoría de Estados bajo la órbita soviética, gobernados estos. Desde entonces los partidos marxistas y leninistas no stalinistas (los trotskistas y leninistas anti-stalinistas, como el POUM, entre otros) han utilizado frecuentemente otros nombres para referirse al leninismo, tales como bolchevique-leninismo o leninismo a secas, así como indistintamente, el término marxismo-leninismo. A la muerte de Stalin, el Partido Comunista Ruso abandonó oficialmente la versión original estalinista del marxismo-leninismo y su forma de organizar en forma verticalista la estructura interna del partido y de éste con el resto del Estado, acusándola de imponer un culto a la personalidad a la persona del líder. Sin nuevos liderazgos ideológicos relevantes en Rusia, quedaría en China Mao Tse Tung como continuador de la estructura política estalinista y de sus posiciones doctrinales. Se produjo entonces una segunda ruptura entre los partidos comunistas pro-soviéticos (en principio marxistas-leninistas, pero no estalinistas) y los partidos comunistas que siguieron o bien la ortodoxia de Stalin, autodenominada marxismo-leninismo y por sus críticos stalinismo, o bien la de Mao, luego denominada marxismo-leninismo-maoísmo.

Desde que el movimiento comunista adoptó los criterios leninistas como forma de organización, todos los partidos y los estados construidos bajo el control de estos partidos han creado instituciones similares, organizados bajo la premisa de que cada partido comunista es una vanguardia del proletariado de cada país y representa sus intereses en tanto clase. La organización política de las naciones gobernadas por el Comunismo es, generalmente, una república de partido único. Las repúblicas comunistas se autotitularon oficialmente como "repúblicas obreras" ya que sólo daban acceso a su control a la clase proletaria, pero finalmente y luego de la Segunda Guerra Mundial pasarían a denominarse como "repúblicas populares" en las cuales la dirección proletaria da acceso al poder a otras "clases populares" como el campesinado. En ambos casos el partido comunista se encarga de la dirección ideológica del país.

En este sistema, el partido subordina las burocracias del Estado y la legislación a sus objetivos políticos y propagandísticos. A su vez el aparato estatal es utilizado para promover en la sociedad civil sus objetivos de transformación social y cultural hacia una economía planificada. La frecuente imposición coercitiva de estos objetivos a toda la población así como la eventual subordinación de la sociedad civil a la militancia del partido comunista han sido usualmente caracterizadas como parte de un sistema totalitario, criticado por algunos de sus defensores como una degradación de la política comunista, y por sus detractores como intrínseco a la misma.

La mayoría de variantes de partidos comunistas han adoptado una categorización histórica del pasado y el futuro social de Occidente de acuerdo a la demarcación de modos de producción establecida por la doctrina marxista: el comunismo primitivo (sin clases), el esclavismo, el feudalismo, el mercantilismo, el capitalismo, y finalmente el modo de producción comunista (sin clases), dividido en dos fases, cuya realización estaría en manos de la clase social llamada proletariado organizada bajo la dirección de un partido comunista revolucionario, y que desaparecería en tanto clase durante la realización del mismo.

Asimismo, el propio Marx utilizaba una periodización alternativa para describir la historia social de otras regiones geográficas, como la de despotismo oriental o modo de producción asiático en países como China.

Esta conceptualización sociológica de lo que es un orden social comunista posible, es propia de la doctrina marxista adoptada por los partidos comunistas, y se considera que ha variado con el marxismo-leninismo respecto a sus características correspondientes. Todos los autores marxistas sin embargo coinciden en que la sociedad comunista se desarrolla en un período de transición y dos fases:

El "período de transición del capitalismo al comunismo" (o "transición al socialismo" propiamente según Lenin), se define por la toma del poder político por parte del proletariado llamada dictadura del proletariado:

Durante este período y antes de llegar al comunismo, se reemplazará al modo de producción capitalista y con éste a la burguesía, mediante la apropiación estatal de los medios de producción:

Según el bolchevismo, la violencia política debe ser parte de la dictadura del proletariado en este período, y por tanto se trataría de una “dictadura” en dos sentidos distintos a la vez: que el poder del Estado esté en manos de una clase y no de otra, y que ese poder elimine las libertades de expresión y asociación de la clase enemiga. La interpretación leninista agregaría que la vanguardia del proletariado puede gobernar en nombre del proletariado, movilizándolo por entero o limitándose a organizar a una fracción del mismo, y siendo encabezada eventualmente por sólo una persona. Además la dictadura del proletariado del período de transición podría usarse para fines de reeducación ideológica, tanto de la pequeña burguesía como del mismo proletariado.

La "primera fase del comunismo" (o "socialismo" propiamente según Lenin), se define por establecer la propiedad colectiva de los medios de producción en manos de una sociedad liderada por trabajadores. En esta fase las limitaciones de las fuerzas productivas debidas al abrupto inicio del nuevo modo de producción requieren la utilización del racionamiento y la organización de la producción de acuerdo a las necesidades colectivas del sistema social y recién luego a la compensación al trabajador mediante certificados de cantidades de trabajo, y no a las necesidades de los trabajadores en tanto hombres:

Aquí las interpretaciones de la categorización marxiana se dividen en dos: la posición de Lenin y la marxista-leninista en general, establece que esta fase del comunismo es cualitativamente distinta a la siguiente y debe mejor ser llamada socialismo. En esta fase, para los leninistas, tanto la dictadura del proletariado como el proletariado subsisten, ya que el Estado debe seguir teniendo el dominio de los medios de producción por cuanto debe preservarse para la lucha contra potenciales contrarrevoluciones de ex-burgueses. El marxismo-leninismo, desde su fundación por Stalin, agregaría a su vez otra diferencia con Lenin: bajo el socialismo podía subsistir la utilización del dinero, a diferencia del socialismo como era entendido por los bolcheviques y fuera intentado durante el período que luego sería denominado como "comunismo de guerra".

La crítica marxista y socialista al leninismo considera, en cambio, que Marx utilizaba indistintamente los términos socialismo y comunismo para referirse a ambas fases, que la primera fase excluye la dictadura del proletariado, y que la dictadura del proletariado no puede ser el medio de organización de la economía socialista o comunista: el Estado en tanto órgano de represión política no puede controlar los medios de producción si la burguesía ya fue enteramente expropiada, puesto que dicho dominio implicaría que puede existir un Estado sin clases sociales, que la dictadura se ejerce políticamente sobre la oposición obrera, y que incluso se utiliza la dictadura (como violencia política y hasta unipersonal) no sólo para la representación sino hasta para la organización interna castrense de la clase proletaria, entendiéndose al socialismo como un colectivismo de Estado organizado autoritariamente y hasta dictatorialmente por una jefatura. Para estos, si en la primera fase se continúa la política del período de transición, la utilización de las empresas colectivas seguiría estando al servicio de una función política del partido comunista y no del proletariado, con lo cual se trataría de un capitalismo de Estado o un colectivismo burocrático (cuya justificación ideológica sólo podría ser la de un "comunismo grosero"), en el cual la existencia del Estado sólo podría explicarse en términos marxistas como herramienta de represión de los trabajadores por parte de una nueva clase económica o de una elite política (grupo explotador no formado por una clase suma de propietarios privados e independientes sino colectivamente propietaria como grupo organizado, en forma similar al modo de producción asiático).

"La fase superior del comunismo" (o "comunismo" propiamente, según Lenin) se define igualmente por la propiedad colectiva de los medios de producción en manos de la sociedad liderada por trabajadores, pero en esta fase se puede superar, gracias al desarrollo de la capacidad productiva, el derecho burgués de intercambio de equivalentes así como la especialización en la división del trabajo, por lo cual tanto la contribución a la sociedad como la provisión de bienes sería gratuita y sólo limitada a la libre voluntad de los miembros de trabajar cuando y como deseen, y de consumir lo que consideren necesario:

La interpretación marxista-leninista sostiene que esta fase es cualitativamente distinta de la anterior y que sólo en ésta se podrá llegar a la extinción del Estado, puesto que Lenin atribuye al Estado funciones no-clasistas como la organización interna del proletariado para la represión de sus propios miembros que no deseen trabajar para la organización colectivista. Sólo en tanto no existan "haraganes", que se presumen minoritarios, el Estado podrá desaparecer ya que habrá terminado de combatir las costumbres capitalistas heredadas.

Para los marxistas que critican esta posición, el Estado ya debería haber desaparecido mucho antes en tanto ya no existen clases, y que por eso mismo las empresas no podrían ser posesión colectiva del Estado sino de los trabajadores asociados colectivamente, ni tampoco la represión de los excesos debería de estar en manos de un órgano separado de los trabajadores armados. Esta distinción y la propia disolución del Estado carecería de sentido si acaso éste puede ser un instrumento igualmente funcional de administración económica y social por parte de los obreros.

Las doctrinas de las diversas corrientes marxistas coinciden en la necesidad de suprimir la propiedad privada (especialmente la de los medios de producción sociales) para establecer una economía planificada, y en la emancipación del proletariado como la primera clase oprimida sin economía propia, negación de toda posible apropiación privada y por ende tendiente a desaparecer como clase en una comunidad comunista.

Debido a la popularidad de la revolución bolchevique y la polarización política entre los colectivismos soviéticos y los mercados capitalistas, el comunismo se ha identificado casi naturalmente con la doctrina marxista-leninista. A diferencia de lo concebido por Marx y Engels, bajo esta doctrina la primera fase del comunismo, que es la más fácilmente alcanzable, es considerada "socialismo". Esta reconceptualización leninista se popularizaría en el léxico político-económico, y desde entonces se afirma que casi todos los gobiernos comunistas han implantado formalmente economías socialistas y no comunistas, puesto que son excepcionales los casos de naciones controladas por partidos comunistas que hayan alcanzado la fase superior del comunismo (o sea, el "comunismo" de acuerdo a esta terminología). Sin embargo el gobierno leninista no había dejado de entender la organización económica socialista de la producción como una economía colectiva que decidiera directamente la organización de la producción sin uso del dinero. El contraste de Lenin con Marx era sólo que en su interpretación de la primera etapa del comunismo se agregaba a la distribución por función prevista por Marx, la idea de una economía estatal dirigida por una junta de planificación, mientras que recién en su etapa final el comunismo funcionaría como Marx preveía en cambio para las dos fases: como una auto-organización común de todos los individuos. De manera que, a pesar de tal diferencia con Marx respecto a un colectivismo de Estado para la primera fase, Lenin sí coincidía con éste en que ambas fases del comunismo requirieran la abolición del dinero y una planificación directa de los recursos mediante su provisión centralizada a la producción y al consumo, por lo cual, coherentemente con esta descripción, fue éste el tipo de sistema que se intentaría implantar durante los primeros años del régimen bolchevique. Luego del fracaso de este experimento económico, Lenin lideraría la transformación de la economía rusa de vuelta hacia una economía de mercado bajo el nombre de Nueva Política Económica. Cuando sus sucesores abolieron nuevamente estas reformas capitalistas para reimponer el socialismo, el concepto de socialismo (o primera fase del comunismo) ya no implicaba la planificación por asignación de bienes que Marx y Lenin entendían como un prerrequisito del mismo: sea por parte de una comunidad de productores en Marx o provisoriamente por parte del Estado en Lenin, cualquier planificación consciente produce un bien ya conociendo cómo será utilizado y por tanto en ningún caso requiere del uso de dinero ("producción para el uso"). Tanto en los modelos personalistas de Stalin y Mao como en el de las burocracias soviéticas posteriores y los nuevos regímenes comunistas alrededor del mundo, el socialismo terminaría limitándose a un régimen de metas de producción para un sistema de empresas estatales entre las cuales operaba un intercambio general de bienes dentro de una economía monetaria en la cual su compraventa no era determinante directa de los ingresos. En el colectivismo soviético post-NEP, los bienes de producción (y eventualmente los de consumo) eran producidos como mercancías con valoraciones abstractas monetarias, pero al mismo tiempo sus precios y cantidades estaban condicionados por un plan general centralizado al que una economía de empresas estatales debía adecuarse. Los planes quinquenales se basaban en metas generales de producción por las cuales las unidades de producción eran compensadas en dinero según criterios ajenos a los precios por los que eran vendidos los bienes de producción, por lo cual no operaban cabalmente como mercancías. La organización del cálculo económico en este sistema fue problemático para las juntas de planificación económica y usualmente degeneraba en una provisión racionada de los bienes de consumo, sea por desinterés o desconocimiento del Estado de los intereses del consumo individual, o por desabastecimiento producto de la descoordinación de la producción.
En casi la mitad de los países del mundo luego de la Segunda Guerra Mundial fue implementado este modelo de socialismo bajo dirigencias marxistas, sea o no bajo el nombre de partidos comunistas.
Los territorios más importantes en ser incorporados por el movimiento comunista marxista-leninista fueron: primero, los que correspondían a las repúblicas que serían asimiladas al nuevo Estado de la Unión Soviética bajo el control de un mismo partido comunista, entre los que se encontraban Rusia, Bielorrusia, Armenia, Azerbaiyán, Estonia, Georgia, Kazajistán, Kirguistán, Letonia, Lituania, Moldavia, Tayikistán, Turkmenistán y Ucrania. A estos se agregaron los países alineados o satélites de la URSS en Europa del Este, América Latina y Asia, cuyos estados serían gobernados por partidos únicos propios (comunistas o no) basados en el socialismo soviético: Mongolia, Bulgaria, Yugoslavia, Hungría, Checoslovaquia, Polonia, Albania, Alemania Oriental, Rumania, Cuba, Vietnam del Norte (luego Vietnam), Corea del Norte, Yemen del Sur, Camboya (bajo el dominio de Vietnam), China, Laos, Yemen, Etiopía, Angola, Somalía, Congo-Brazzaville, Mozambique, Guinea-Bisáu, Benín, Argelia, Birmania, Nicaragua, Granada y Afganistán entre otros.

En el caso de Yugoslavia, Hungría y Checoslovaquia se intentó una variante de este mismo modelo soviético llamado "socialismo de mercado" que intentaba emular la formación de precios en un mercado por diferentes vías según el país (empresas autogestionarias, estatales competitivas, etc.) pero sin posibilitar el derecho a la propiedad privada sobre el capital y la libre empresa en función de la ganancia.

Las únicas excepciones en las que se concretó el proyecto marxista-leninista originario de planificación económica, fueron el "Comunismo de guerra" en Rusia, el "Gran salto adelante" en China, la política del "Hombre Nuevo" inaugurada por Ernesto Guevara en Cuba, y la "Vuelta al campo" de la Revolución camboyana. Sólo en todos estos breves episodios se alcanzó lo que Lenin había denominado como socialismo (organización de la producción como "una sola fábrica" más distribución por función), y en algunos casos se llegó inclusive al comunismo en el sentido que Lenin aceptaba del término (ídem más distribución por necesidad), pero finalmente se regresaría en una u otra forma al socialismo en el sentido soviético post-bolchevique (estalinista o post-estalinista) que es hoy su denominación usual.

Luego de la caída del "bloque socialista", los países que permanecen hasta el día de hoy en mayor o menor medida con el modelo económico socialista de tipo soviético bajo control de partidos únicos marxistas son Corea del Norte y Cuba. En cambio China, Vietnam y Laos son gobernados por partidos comunistas que han decidido virar sus economías reguladas a formas mayormente mercantiles y capitalistas.

Además del comunismo como fue entendido por Marx y sus sucesores, existen otras doctrinas comunistas (algunas previas al marxismo, otras contemporáneas, y otras posteriores) tales como el anarcocomunismo con fundamento en posturas sociobiologistas (Piotr Kropotkin, Aldous Huxley) y el comunismo de consejos de base marxista pero no leninista.

Karl Marx vio el comunismo primitivo como el estado original cazador-recolector de la especie humana del que surgió el comunismo temprano. Para Marx, sólo después de que la humanidad fue capaz de producir excedentes (y de que algunos miembros de la sociedad se apropiaron de ellos), se desarrolló la propiedad privada y el Estado.

Se designa con esta expresión a todas las doctrinas pre marxistas, que con muchísima diversidad, se les puede englobar como utopías sociales que abogaban por la propiedad colectiva (a diferencia de un régimen de propietarios iguales) y la igualdad total (incluyendo todas las necesidades) de todos los productores. Tales doctrinas primitivas resolvían el problema de las relaciones del individuo con la sociedad a través de la «sociedades de iguales», que bien podía ser una comuna, el Estado, etc.

Tales doctrinas se desarrollaron en la Época Clásica y en la Edad Media. Un ejemplo de comunismo igualitario es el implantado en Esparta por Licurgo también designado como "comunismo militar". Este gobierno sólo consideraba como «iguales» a los ciudadanos de la "polis", ya que mantenía un régimen esclavista.

Otro ejemplo de ciertas doctrinas comunistas en un marco antiguo son las propuestas por Platón en "La República":

Las tendencias igualitarias se desarrollaron en algunas de las primeras herejías cristianas, como también en las comunas anabaptistas.

El comunismo como tradición política e ideológica surge a partir del siglo XVIII impulsado por las fuertes contradicciones sociales en Europa. Durante el gobierno del Directorio (1795-1799) en la Francia revolucionaria François-Noël Babeuf lleva a cabo la "Conjuration des Égaux" ("Conspiración de los iguales"), la primera acción revolucionaria llevada a cabo en nombre de una ideología comunista. El babuvismo proponía la abolición de la propiedad privada, la instauración de la propiedad comunitaria para asegurar la única y verdadera igualdad, no sólo política, sino también económica. El movimiento fue salvajemente reprimido, si bien su pensamiento resistió el paso del tiempo y engendró la mayoría de los comunismos posteriores.

Sobre 1835, las ideas comunistas prosiguieron su desarrollo fuertemente vinculadas al concepto de socialismo, a partir del llamado socialismo utópico (también denominado "comunismo utópico"), siendo sus principales exponentes Robert Owen, Charles Fourier y Saint-Simon.

Robert Owen fue el primer autor en considerar que el valor de los productos debía medirse con base al trabajo incorporado a ellos, y no al valor en dinero que se les atribuye. Charles Fourier fue el primero en proponer la abolición del capitalismo para la formación de una sociedad comunista. Y el Conde de Saint-Simon consideró que la nueva sociedad debía estar planificada para atender las necesidades de los pobres. Estos autores propusieron la transición hacia nuevas sociedades a través de comunidades rurales autosuficientes por el trabajo de voluntarios; sin embargo, no consideraban que la sociedad capitalista estuviera compuesta por clases sociales antagónicas.

Las palabras «comunista» y «comunismo» surgen en Francia hacia 1840, unos diez años después de la aparición de los términos «socialista» y «socialismo». Así el adjetivo «comunista» fue empleado para referirse a un banquete celebrado el 1 de julio de 1840 en las afueras de París en el que participaron más de mil comensales, en su mayoría obreros, y en el que se defendió la necesidad de aplicar reformas que no fueran meramente políticas para alcanzar la «igualdad real».

En Francia existían entonces dos tendencias «comunistas», el cabetismo, más influyente, y el neobabuvismo. La primera estaba formada por los seguidores de Étienne Cabet, llamados icarianos, quien en 1839-1840 había publicado "Viaje a Icaria", una obra que retomaba la tradición utopista iniciada por Tomás Moro y por Tommaso Campanella, aunque bajo la apariencia de una novela histórica. La segunda, enlazaba directamente con la herencia de François Babeuf y su Conspiración de los Iguales de 1797 y que había mantenido viva Filippo Buonarroti. Estos «neobabuvistas» hicieron pública en 1840 la "Profesión de fe de los trabajadores igualitarios" en la que decían:

Desde Francia, donde según el poeta alemán residente en París Heinrich Heine los «comunistas» se había convertido en «el único partido que merece atención», los términos «comunismo» y «comunista» se difundieron por los Estados alemanes y por Suiza gracias al libro de Lorenz von Stein publicado en 1842 en Leipzig con el título "El socialismo y el comunismo en la Francia contemporánea" ("Der Sozialismus und Communismus des heutigen Frankreichs") —Wilhelm Weitling, August Becker y otros lo utilizaron enseguida— y también por Gran Bretaña a través de otros canales. Becker en 1844 publicó "¿Qué quieren los comunistas?" ("Was wollen die Kommunisten?") en el que decía:
El término «comunismo» fue sustituyendo progresivamente al originario de «socialismo» o al menos se confundió con él. Sin embargo «comunista» y «socialista» no eran términos estrictamente equivalentes ya que los comunistas se distinguían de los socialistas por unas ideas que en ellos estaban más claramente afirmadas, como la realidad de la lucha de clases de la que se derivaba la necesidad de la revolución —la conquista del Estado— para alcanzar la nueva sociedad. Estas diferencias fueron las que motivaron que Karl Marx y Friedrich Engels adoptaran el término «comunista» y no el de «socialista» para llamar a la Liga que fundaron en 1847 y al manifiesto de la misma hecho público al año siguiente. Engels explicó en 1890 que en la década de 1840 «la parte de los obreros que, convencida de la insuficiencia de las revoluciones meramente políticas, exigía una transformación radical de la sociedad, se llamaba entonces "comunista"» mientras que la mayoría de los que se hacían llamar «socialistas» «se hallaban fuera del movimiento obrero y buscaban apoyo más bien en las clases "instruidas"», «y como nosotros ya en aquel tiempo sosteníamos muy decididamente el criterio de que "la emancipación de la clase obrera debe ser obra de la clase obrera misma», no pudimos vacilar un instante sobre cuál de las dos denominaciones procedía elegir».

Después de 1848, los términos «socialismo» y «comunismo» se afirmaron y se superpusieron, identificándose en unos períodos y diferenciándose en otros, y también se utilizaron para caracterizar etapas de desarrollo histórico distintas.

Karl Marx y Friedrich Engels fundan en Bruselas a principio de 1846 el Comité Comunista de Correspondencia que se introduce en el seno del movimiento obrero revolucionario alemán llamado la Liga de los Justos (otrora Liga de los Proscritos), que hasta entonces había sido dirigido por Wilhelm Weitling y se encontraba orientado hacia el comunismo cristiano. Luego del congreso celebrado a razón de la nueva dirección, la organización revolucionaria cambia en 1847 su nombre por el de Liga de los Comunistas. La Liga encarga entonces a Marx y a Engels una proclama del movimiento comunista. En 1848 éstos publican el "Manifiesto Comunista" ("Manifest der Kommunistischen Partei").

Para Marx y Engels, la clase obrera industrial es la única que, por su imposibilidad de una adquisición privada, puede superar mediante la síntesis comunista la contradicción sin salida de la socialización estatal: es la negación comunista de la sociedad porque no puede transformarse en nueva clase explotadora, es la negación comunista del Estado porque sólo transformándose ella misma en poder público puede superar su carácter asalariado remanente de la sociedad burguesa, y es la negación comunista de la propiedad porque sólo distribuyendo de acuerdo a las necesidades y las capacidades puede adquirir los frutos de los medios de producción. De ello se deriva el lema "De cada cual, según sus capacidades; a cada cual según sus necesidades".

El "Manifiesto Comunista" es considerado uno de los tratados políticos más influyentes de la historia.

En la Asociación Internacional de los Trabajadores se evidenciaron los conflictos ideológicos entre anarquismo y marxismo. La principal diferencia entre estos dos grupos fue que los marxistas proponían un período de transición después de la revolución social antes de la disolución final del estado, idea que los bakuninistas no aceptaban considerando que la revolución debía acabar inmediatamente con el estado. El resultado final de esta división fue la expulsión de los anarquistas y anarcosindicalistas de la Primera Internacional y su posterior disolución en 1876.

El anarcocomunismo es anarquismo porque niega toda jerarquía y es comunismo porque busca una sociedad comunista (la sociedad comunista es una sociedad sin Estado donde toda la propiedad es común), representada entre otros por Pedro Kropotkin y Errico Malatesta.

En los desarrollos posteriores a Marx del comunismo marxista, ha existido cierto debate sobre cuáles son los métodos más eficaces para lograr un cambio del sistema socioeconómico capitalista. En gran parte estos debates y desarrollos de estrategias consiguientes han estado ligados a personas influyentes dentro del movimiento comunista internacional. En ocasiones el debate ha estado más caracterizado por alineamientos personales con los principales teóricos, que por verdaderas e irreconciliables posturas ideológicas.

El marxismo-leninismo es una ideología política formulada por Stalin, oficialmente basada en el marxismo y el leninismo. Sin embargo, no es simplemente la unión de ambas ideologías sino que es una ideología política específica creada para describir la línea que Stalin implantó en el PCUS y la Comintern. Además, contiene desviaciones tanto del marxismo como del leninismo, como puede ser el concepto del socialismo en un solo país. No hay un acuerdo entre historiadores sobre si Stalin realmente siguió los principios de Marx y Lenin.

El objetivo del marxismo-leninismo es la creación de un Estado unipartidista que tenga el control total sobre la economía. Según el marxismo-leninismo, este Estado refleja el concepto del socialismo (medios de producción controlados por la sociedad), que eventualmente desarrollara el comunismo. Otras tendencias comunistas y marxistas no están de acuerdo: argumentan que los Estados marxistas-leninistas realmente formaron el capitalismo de Estado. En definitiva, estas tendencias concluyen que el marxismo-leninismo no es ni marxismo, ni leninismo, ni la unión de ambos; sino un término artificial creado para justificar lo que consideran la distorsión ideológica de Stalin, el PCUS y la Comintern. En la URSS, esta lucha contra el marxismo-leninismo fue llevada a cabo por el trotskismo, que se define como una tendencia marxista y leninista.

Según el marxismo-leninismo, la propiedad privada de los medios de producción (el elemento clave para decidir si se ha llegado al socialismo o no) había desaparecido en los Estados marxistas-leninistas; sin embargo, según Engels, co-fundador del marxismo, la propiedad por parte del Estado es una forma de propiedad privada con naturaleza capitalista, que solo se convierte en propiedad pública si el proletariado está en control de este Estado. Según el marxismo-leninismo, contrario a lo que dicen otras tendencias marxistas, el proletariado estaba en el control de los Estados que siguen esta doctrina. Por lo tanto, otra crítica de estas tendencias es la falta de democracia (en varios ámbitos) en Estados como pueden ser, por ejemplo, la URSS.

El trotskismo es una tendencia marxista y leninista que se opone al marxismo-leninismo y estalinismo, a través de las teorías de la revolución permanente y el internacionalismo, que se opone al socialismo en un solo país de Stalin. Trotski y sus seguidores compitieron contra Stalin por el poder en la Unión Soviética.

El marxismo-leninismo se refiere a el sistema socioeconómico e ideología política implementada por Stalin en la URSS y después adoptada por otros Estados basados en el modelo soviético (economía centralizada, estado unipartidista, etc.); mientras que estalinismo se refiere al estilo de gobernar de Stalin (represión política, culto a la personalidad, etc.); el marxismo-leninismo se quedó después de la desestalinización, mientras que el estalinismo no lo hizo. Sin embargo, el término "estalinismo" es a veces utilizado para referirse al marxismo-leninismo, a veces para evitar sugerir que el marxismo-leninismo está relacionado con el marxismo y el leninismo.

El maoísmo se refiere a la forma de el marxismo-leninismo asociada con Mao Tse-tung y que se aplicó en China. Después de la desestalinización, aunque se preservó el marxismo-leninismo en la URSS, tanto el maoísmo como el hoxhaismo argumentaron que las políticas de la URSS se había desviado de este, y por tanto Albania y China se distanciaron de la URSS, además de pasarse a llamar "anti-revisionistas" y aplicar otras políticas.

Surgido a partir de la revolución alemana y de la ruptura de la izquierda comunista germano-holandesa con el bolchevismo ruso, el comunismo de consejos hizo centro en la auto organización de la clase proletaria en los consejos obreros, en vez de la dirección política de la misma de un "partido revolucionario". Sus principales referentes fueron Otto Rühle, Anton Pannekoek y Paul Mattick.

El austromarxismo surge a partir de la mezcla de principios del capitalismo con principios leninistas y marxistas.

El socialismo autogestionario o socialismo de autogestión es el sistema político que está basado en la participación de las diferentes comunidades cercanas a la vida cotidiana colectivizada (empresa, sindicato, localidad, partido) en la gestión de comunidades políticas superiores (Estado, federaciones, confederaciones, etc.).

Según algunos comentarios se logró algo similar a una sociedad comunista libertaria, es decir, comunismo anarquista o anarcocomunismo, con tendencias económicas y sociales a las perspectivas desarrolladas por Bakunin y Kropotkin, en Aragón durante la Guerra Civil Española gracias a la colaboración de CNT y POUM. Sectores de UGT apoyaron el proceso revolucionario en Aragón pese a que la dirección del partido consideraba que entorpecería la lucha contra Franco. 

George Orwell describió una escena de Aragón durante este periodo, en el cual participó como parte de la División Lenin del POUM, en su célebre libro "Homenaje a Cataluña":

El comunismo se ha desarrollado organizativamente a través de la historia por medio de diversos movimientos políticos. Este desarrollo se ha llevado a cabo mediante la formación de las Internacionales Comunistas.

La Primera Internacional (AIT) fue la primera organización que reunió a los sindicatos y a los partidos asociados a la clase trabajadora. Se fundó en Londres durante una reunión entre trabajadores llevada a cabo en Saint Martin's Hall. Su primer congreso se llevó a cabo en 1866 en Ginebra. En 1872 su sede se traslada desde Londres a Nueva York. En su momento la Internacional llegó a contar con 1,2 millones de miembros en todo el mundo, aunque su gaceta oficial publicaba 8 millones.

En la Asociación Internacional de los Trabajadores se evidenciaron los conflictos ideológicos entre anarquismo y marxismo.

La AIT no debe ser confundida con la Asociación Internacional de los Trabajadores fundada en los años 1922 y 1923 por los anarquistas y anarcosindicalistas.

Tras varios fracasos por refundar la Primera Internacional, se fundó en 1889 la Segunda Internacional (SI) que agrupó a diversos partidos socialistas y laboristas. La SI es parte de la historia del comunismo únicamente en referencia a los grupos al interior de ésta que luego formaron la Tercera Internacional debido a su carácter eminentemente socialdemócrata. La SI se disolvió en 1916 después del inicio de la Primera Guerra Mundial. La Segunda Internacional asentaría las bases de lo que sería la socialdemocracia actual.

Al disolverse la Segunda Internacional los grupos socialistas revolucionarios que se habían opuesto a la Primera Guerra Mundial convocaron a la Conferencia de Zimmerwald en septiembre de 1915 y a la Conferencia de Kienthal en abril de 1916. Estas conferencias fueron el antecedente directo de la Tercera Internacional también conocida por su abreviatura en ruso "Komintern" (Коминтерн, abreviatura de Коммунистический Интернационал, ""Internacional Comunista""), la cual fue fundada en su primer congreso de Petrogrado en 1919 por iniciativa del Partido Comunista de la Unión Soviética. La Tercera Internacional rompió definitivamente con los grupos socialdemócratas y siguió las directrices marcadas por el Partido Comunista de la Unión Soviética.

En esta internacional también se manifestó el conflicto entre estalinistas y trotskistas. Los trotskistas sólo reconocen la legitimidad de los primeros cuatro congresos de la Internacional, ocurridos antes de la llegada al poder de Hitler en Alemania, momento en el que los trotskistas se separan definitivamente de la Internacional y empieza la formación de una Cuarta Internacional.

El 15 de mayo de 1943, después de celebrada la Conferencia de Teherán, el "Presidium" del Comité Ejecutivo de la Internacional Comunista, «teniendo en cuenta la madurez de los partidos comunistas», y para evitar los recelos de los países capitalistas aliados decide disolver la Internacional Comunista.

La primera revolución que seguía los postulados marxistas no se produjo en un país central, sino en Rusia, en 1917. El líder del movimiento, Vladimir Ilich Uliánov, «Lenin», explicó esta imprevista (por Marx y Engels) resolución de las contradicciones capitalistas señalando que el capitalismo había fallado en su «eslabón más débil». En efecto, Rusia era un país de escaso desarrollo industrial y predominante base campesina semifeudal.

A partir de la Revolución rusa, la denominación de comunista quedó restringida a los partidos marxistas que se alinearon con la Unión Soviética. La Revolución rusa llevó a cabo la supresión de la propiedad privada en la industria, creó cooperativas agrarias, fomentando su incorporación entre los campesinos (convertida más tarde, durante el régimen estalinista, en colectivización forzosa), y avanzó hacia la multiplicación de los medios de producción, en medio de una guerra civil que duró cuatro años. Uno de los primeros objetivos de Lenin fue electrificar Rusia (Lenin dijo en una ocasión que el comunismo era «soviets más electricidad»).

Durante la dirección de Stalin, la industrialización se hizo a paso acelerado, dadas las circunstancias internacionales, sin tenerse en cuenta la capacidad de aguante del proletariado ni condiciones de explotación resultantes a que se vio sometido junto con el medio. La Segunda Guerra Mundial agudizó el proceso de creación de industria pesada y de alimentos, al mismo tiempo que aumentó los controles estatales. Este período se caracterizó por una etapa de transición hacia el socialismo a través de diversos planes quinquenales , en contraste con la gradual concentración de poder político en manos de la burocracia del Partido y del Comité Central, según los partidarios de Stalin, necesaria por las condiciones de Guerra. También conllevó, a nivel político, un aumento de las persecuciones políticas, por parte del régimen, a los distintos sectores disidentes y de oposición dentro del Partido Comunista de la Unión Soviética, extendido más tarde al resto de la Tercera Internacional, cuyo máximo exponente será la Gran Purga.

La Kominform fue creada como sustituto de la Komintern entre el 22 y el 27 de septiembre de 1947 durante una conferencia de dirigentes de Partidos Comunistas celebrada en Szklarska Poręba (Polonia). Oficialmente, fue creada el 5 de octubre de 1947. El impulsor de la creación de la Kominform fue el representante soviético, Andréi Zhdánov, quien en respuesta al Plan Marshall impulsado por el presidente de los EE. UU, Truman, en Europa Occidental, pronunció un discurso en el que sentó las bases de la nueva política internacional de la Unión Soviética en la que se llamó Doctrina Zhdánov. Su creación fue la respuesta de Stalin al Plan Marshall y con ella buscaba agrupar a los partidos comunistas de la zona bajo influencia soviética (Polonia, Checoslovaquia, Hungría, Bulgaria y Rumanía), a ella se sumaron los poderosos partidos comunistas de Francia e Italia. El Partido del Trabajo de Albania solicitó el ingreso en el Kominform el 26 de octubre de 1947, pero esto no se llegó a materializar.

En Francia, Trotsky y sus simpatizantes de la Oposición de Izquierda, tras ser expulsado éste de la Unión Soviética a causa de su rivalidad con Stalin (apoyado por la burocracia del Partido), consideraron que la tercera internacional había quedado sometida al estalinismo y que sería incapaz de llevar a la clase trabajadora al poder. En consecuencia fundaron la Cuarta Internacional (CI). A través de su historia, la CI fue perseguida tanto por los gobiernos capitalistas como por la policía secreta soviética y los miembros de la Tercera Internacional. Los antirrevisionistas, estalinistas y maoístas consideran a la Cuarta Internacional y al trotskismo en general como una corriente ilegítima y reformista del marxismo, el bolchevismo y del comunismo hasta la actualidad.

A partir de 1945, servicios de seguridad estadounidenses y británicos reclutarían a intelectuales de agrupaciones provenientes de la Cuarta Internacional para promover una ideología que rivalice con el comunismo soviético, el estalinismo de finales de los 40s, una «guerra psicológica» en contra de la URSS. Antiguos colaboradores de Trotsky como Daniel Bell, Sidney Hook, James Burnham e Irving Kristol (conocidos como los "New York Intellectuals") trabajarían conjunto a las agencias de seguridad estadounidenses y formarían las bases del movimiento neoconservador en Estados Unidos.

La Cuarta Internacional sufrió una escisión en 1940 y otra aún más importante en 1953. A pesar de la reunificación parcial ocurrida en 1963, varias organizaciones se atribuyen en la actualidad la exclusividad como representantes o herederas de la Cuarta Internacional, si bien muchas reivindican su legado o programa político y, conscientes de la dispersión existente entre sus organizaciones herederas, reivindican su reconstrucción. Muchas de ellas provienen de algunos jóvenes dirigentes o miembros de esta organización como Ernest Mandel, Nahuel Moreno, Tony Cliff, Pierre Lambert o Ted Grant.

En cada lugar del mundo tuvieron suertes diversas, pero pocas veces llegaron al poder. Las excepciones fueron los países de Europa del Este que estuvieron bajo el control del régimen político instaurado en la URSS tras el ascenso al poder de Stalin (heredado por los sucesivos gobiernos), durante más de 40 años a partir de la derrota del Ejército Nazi y la conquista militar de la región por el Ejército Rojo después de la Segunda Guerra Mundial; además de China, Corea del Norte, Vietnam y Cuba, donde el poder lo obtuvieron direcciones militares o guerrilleras, dirigidas o influenciadas por su respectivo Partido Comunista, con apoyo campesino y de sectores populares.

En Chile, a comienzos de los 70, la Unidad Popular (UP) llegó al gobierno presidencial, tras ganar con su abanderado Salvador Allende las elecciones de septiembre de 1970. La coalición de gobierno era una alianza de partidos y movimientos de izquierda que tenían representación (minoritaria) en el parlamento. El Partido Comunista conformaba esta alianza junto a otros, como el Partido Socialista, la Izquierda Cristiana, el Partido Radical, y el Movimiento de Acción Popular Unitaria (o MAPU, escindido de la Democracia Cristiana), entre otros. Su principal consigna fue la «vía pacífica al socialismo», base programática de la alianza política en torno a Allende, pero que no era apoyada por todos los movimientos revolucionarios presentes en el acontecer político de la época. Esta vía implicaba la construcción del socialismo a través de las instituciones propias del Estado parlamentario burgués, siguiendo a estrategia de los llamados "frentes populares" de establecer gobiernos sobre la base de la coalición electoral entre distintas fuerzas políticas consideradas «progresistas» o populares. Esta experiencia fue frustrada por la férrea oposición de las fuerzas de centro y derecha, las que apoyadas por los Estados Unidos, produjeron finalmente un golpe de estado en 1973, con la inmediata consecuencia de la aniquilación de los focos de resistencia obrera (como los Cordones industriales) liderados por el MIR o la facción marxista del MAPU, el suicidio del presidente socialista Salvador Allende, el cierre del parlamento y el establecimiento de un régimen militar, para continuar en los años siguientes con una represión sostenida y sistemática de los principales dirigentes y activistas de todas las organizaciones políticas y sindicales, tanto del Partido Comunista, como de los demás partidos políticos que apoyaron o participaron en el gobierno de la Unidad Popular.

El movimiento comunista internacional atravesó grandes crisis en el siglo XX. La primera de ellas relacionada con el alejamiento de León Trotsky de la conducción de la Unión Soviética debido a sus diferencias con Stalin. Trotsky se exilió en México, donde fue asesinado por un agente bajo el mando de la GPU: Ramón Mercader. El ex conductor del Ejército Rojo postulaba la "revolución permanente". La segunda gran crisis la provocó el enfrentamiento de la Unión Soviética y China en lo referente a la política internacional. Desde los años del encumbramiento del fascismo en Europa, la Unión Soviética sostuvo una política de "unidad con las fuerzas democráticas" de la burguesía para los partidos comunistas que actuaban en el mundo capitalista y de coexistencia pacífica con el imperialismo. El Partido Comunista de China tenía una política de confrontación directa con el imperialismo, aunque apoyaba acuerdos con las burguesías "nacionales" confrontadas con él mismo. Esta política provocó otro cisma en muchos partidos comunistas. En los 70 del siglo XX el comunismo pro-chino viró hacia extrañas alianzas según fuera la relación de cada gobierno con Pekín.

Al terminar la Segunda Guerra Mundial, la Unión de Repúblicas Socialistas Soviéticas (URSS), que agrupaba los antiguos dominios del zar, era una potencia mundial. Con la muerte de Stalin, en 1953, sobrevino la crítica a sus métodos y al denominado "culto a la personalidad", tolerados y auspiciados desde el poder. Esta etapa, abanderada por Jrushchov, fue conocida como "etapa del deshielo". Lo que no impidió que, con posterioridad, se acusase a Jrushchov de los mismos métodos de que él había acusado a Stalin.

La República Popular China, surgida tras la victoria, en 1949, de la dirección militar del Partido Comunista Chino, liderado por Mao Tse Tung y apoyado por un numeroso ejército, una revolución campesina en el medio agrario, y una revuelta estudiantil en la ciudad, siguió adelante el proceso, en medio de crecientes contradicciones, hasta que comenzó a aceptar formas económicas mixtas desde finales de los años 70, con Deng Xiaoping, sin cambiar el sistema político de partido único, y aún ejerciendo un fuerte control político y policial estatal.

Después de la Segunda Guerra Mundial, dos partidos comunistas europeos, el francés y el italiano, crecieron hasta el punto de convertirse en fuerzas políticas clave en sus respectivos países. Dominaban ampliamente el movimiento sindical, tenían una importante representación parlamentaria y jugaban una compleja política de alianzas en el plano interno. Fueron críticos, en muchos aspectos, de la Unión Soviética. Esta posición independiente convirtió a ambos partidos en núcleo del eurocomunismo, cuyo sesgo distintivo era la confianza en alcanzar el poder en los países capitalistas a través de las elecciones pluripartidistas parlamentarias. El eurocomunismo se enfrentó en ocasiones a la Unión Soviética, y terminó encontrando apoyos en un sector de la burguesía de sus respectivos países (sobre todo en lo referente a fuentes de financiación). El Partido Comunista Francés no modificó, sin embargo, el método de conducción centralista hacia lo interno, así como el método dirigista desarrollado en época de Stalin. Menos rígido fue en ese sentido el Partido Comunista Italiano. Éste, además, diseñó una política de "compromiso histórico" hacia la Democracia Cristiana (centroderecha) que significaba mucho más que eventuales alianzas tácticas. El Partido Comunista de España, menos poderoso, se sumó al eurocomunismo, renunciando, con Carrillo a muchas de las reivindicaciones del movimiento comunista y obrero desarrollado durante la transición de la dictadura fascista al régimen constitucional, aceptando así la monarquía y apoyando los Pactos de la Moncloa, y ejerciendo un fuerte control a su vez sobre la dirección sindical de Comisiones Obreras (CC.OO.).

En 1991, tras un proceso de sucesivos intentos de reformas privatizadoras en lo económico, conocido como Perestroika, que acelerarán la crisis interna, y presionado por la Guerra Fría y las potencias occidentales, el país sucumbe ante sus propias contradicciones, dando lugar a la desintegración de la URSS y a que las repúblicas que integraban la URSS se independicen. La destrucción del Muro de Berlín que separaba la zona de influencia soviética de la zona capitalista (herencia de la división territorial posterior a la Segunda Guerra Mundial) es considerada uno de los símbolos de esta caída.

Después de la caída de la Unión Soviética, los partidos comunistas sufrieron transformaciones y divisiones en todo el mundo. Algunas fracciones adoptaron una política reformista, otras desarrollaron una táctica de oposición a la globalización capitalista buscando estrechar sus lazos con las masas marginadas por el llamado capitalismo consumista, y orientándose en algunos casos hacia el comunismo libertario. Muchos simpatizantes del marxismo en las décadas anteriores, apoyaron movimientos socialdemócratas en Europa y América latina.

En Cuba, la revolución de 1959 fue conducida por jóvenes revolucionarios que no pertenecían al Partido Comunista. Pero éste se convirtió en fuerza hegemónica en la medida en que la economía del país se hacía cada vez más dependiente de la Unión Soviética, en gran parte debido al bloqueo económico que estableció Estados Unidos. Caída esta, Cuba permaneció como un solitario baluarte del comunismo en América, aunque aceptando la participación de capitales privados extranjeros en su débil economía, centrada en el turismo.

Incluso en la República Popular China se han desarrollado profundas transformaciones en torno a una internacionalización y un modelo económico que distan mucho de los principios políticos que promulgan. Una mezcla de comunismo en el discurso político teórico y capitalismo, en la práctica cada vez más amplios sectores económicos.

Vietnam ha iniciado reformas en el mismo sentido de China. Los otros países socialistas de la actualidad son Laos y Corea del Norte. Este último se ha destacado por el rechazo de reformas liberalizadoras, y una defensa férrea del patriotismo y la economía socialista, aunque últimamente está adoptando mecanismos para permitir la entrada de capital extranjero.

En Rusia se fundó el Partido Comunista de la Federación Rusa en 1993 a partir del Partido Comunista de la Unión Soviética. Se ha centrado en las características propias de Rusia, y en consecuencia ha combinado el comunismo con un fuerte patriotismo en sus planteamientos. Ideológicamente se ha denominado nacional-bolchevismo a la combinación de la lucha social anticapitalista con el nacionalismo, tendencia que desde la década de 1920 estuvo presente en cierto modo en el PCUS.

El comunismo se ha confundido con el marxismo-leninismo. En este sentido, la crítica al «comunismo» no sólo ha venido de los sectores derechistas o centristas, sino también del comunismo de izquierda, p. ej. consejismo, autonomismo.

Existen varias críticas contemporáneas al comunismo marxista y al marxismo-leninismo que van desde los sectores de extrema derecha (fascismo) y derecha (liberalismo, conservadurismo) hasta centro-izquierda (demócratas cristianos, social liberales, social demócratas). También se les suelen oponer sectores sin espectro político, como los anarquistas o libertarios.

La Iglesia católica rechaza la ideología comunista, por ejemplo, en la encíclica "Divini Redemptoris", del papa Pío XI:

Sin embargo, existen comunistas cristianos que se distinguen del comunismo marxista (así como de las justificaciones cristianas a los procesos revolucionarios liderados por los partidos comunistas, como en el caso de la Teología de la Liberación), basando en cambio su comunismo directamente en la religión y recogiendo conclusiones sociales de algunas enseñanzas de los primeros apóstoles, por ejemplo:

Los cristianos anticomunistas han replicado que la forma de organización socioeconómica descrita no era una forma de comunismo en el sentido colectivista descrito por el marxismo, sino de una forma de economía del don o bien un comunitarismo en el cual los integrantes seguían siendo propietarios privados que contribuían libremente a la distribución, y en su favor agregan a la misma cita de la Biblia otras que las pondrían en contexto:

Por fuera del debate ideológico, el sociólogo clásico Max Weber clarificó la vida social de la Iglesia primitiva como una comunidad basada en una organización de propietarios que niegan, sin embargo, la propiedad en la práctica: 






</doc>
<doc id="28338" url="https://es.wikipedia.org/wiki?curid=28338" title="Marxismo">
Marxismo

El marxismo es el modelo teórico explicativo de la realidad compuesto principalmente por el pensamiento desarrollado en la obra de Karl Marx, filósofo, sociólogo y periodista revolucionario alemán de origen judío, quien contribuyó en campos como la sociología, la economía, el derecho, y la historia; así como también la serie de pensadores que complementan o re-interpretan este modelo, tradición que va desde el coeditor de Marx, Friedrich Engels, hasta otros pensadores como Lenin, León Trotski, Rosa Luxemburgo, Antonio Gramsci, Georg Lukács o Mao Zedong. Por lo tanto es correcto hablar de marxismo como una corriente del pensamiento humano. 
El "marxismo" se asocia principalmente al conjunto de movimientos políticos y sociales que surgieron durante el siglo XX, entre los que destacaron la Revolución rusa, la Revolución china y la Revolución cubana. Para estos movimientos sociales el nombre correcto es "comunismo" o "socialismo". Es incorrecto plantear estos movimientos como sinónimo de "marxismo", porque ni todo su componente humano ni toda su doctrina política se basó en el marxismo como tal. 

Los componentes centrales del modelo teórico explicativo marxista son esencialmente cuatro elementos: En primer lugar el concepto de «lucha de clases», que es formulado por primera vez en el "Manifiesto comunista" y que progresivamente se va transformando en el método de análisis de la historia humana en torno a los conceptos de «clase social», «contradicción» y «división social del trabajo». Este método está a la vez basado en la mecánica hegeliana comúnmente llamada «dialéctica» (aunque en términos estrictamente hegelianos se trata de una «lógica ontológica», modelo que a la vez sobrepasa al concepto hegeliano de dialéctica). Curiosamente, Marx nunca especificó en una obra en particular cuáles eran los límites globales de este método, ni cuál era el concepto que él tenía de dialéctica, sin embargo se cita el prólogo de la "Crítica de la economía política" de 1859 como su formulación más precisa. 

El segundo punto central del modelo teórico marxista es la crítica a la economía capitalista, el cual es desarrollado extensamente en su obra "El capital", compuesta por tres tomos oficiales y un cuarto tomo editado de manera póstuma bajo el nombre de "Historia crítica de la teoría de plusvalía". En esta obra Marx desarrolla, entre otras cosas, un modelo alternativo para calcular el concepto de «valor» de la economía capitalista, basado en el «tiempo de trabajo socialmente necesario» para la producción de «mercancías». Esta investigación tiene directas consecuencias políticas, pues la hipótesis marxista probaría que en realidad la sociedad capitalista se funda en torno al robo del trabajo humano a través del concepto de «plusvalor», legitimado en el estado de derecho a través de la propiedad privada sobre los medios de producción y el libre usufructo de esas ganancias. 

El tercer punto central es el concepto de «ideología», que es desarrollado por Marx en sus primeros libros como "La ideología alemana" (en coautoría con Engels) y que intenta explicar las formas de dominación mental de la sociedad capitalista y su relación con la composición económica de esta. Este concepto es abandonado durante algunos años por Marx para centrarse en el análisis político. Sin embargo, vuelve a aparecer con fuerza en su libro "El capital" bajo el concepto de «fetichismo de la mercancía», que sería una forma de explicar la incapacidad psicológica de una persona de percibir el «valor de uso» de una mercancía. Este concepto es extremadamente importante porque describe todas las consecuencias de las formas de producción de la vida dentro del capitalismo.

El cuarto punto central del modelo teórico marxista es el concepto de «comunismo», el cual es una teórica y utópica sociedad humana que puede sobrepasar los límites de la sociedad capitalista fundada en la explotación humana. Marx utilizó muchas veces la palabra, pero jamás explicó cuales eran sus alcances y características (salvo algunas referencias relativamente cortas pero lúcidas, como por ejemplo las que pueden encontrarse en su "Critica del programa de Gotha" de 1875). Un análisis crítico de la obra de Marx demostraría que él no hubiera estado dispuesto a describir algo que todavía no existe, por lo tanto el significado de comunismo se encuentra en una síntesis, tanto como de los problemas económicos fundamentales encontrados de manera explícita en "El capital", como un análisis de la crítica política-jurídica hecha por Marx a las instituciones capitalistas. 

Engels acuñó el término socialismo científico para diferenciar el marxismo de las corrientes socialistas anteriores englobadas por él bajo el término socialismo utópico. También se emplea el término socialismo marxista para referirse a las ideas y propuestas específicas del marxismo dentro del marco del socialismo.

El objetivo que se propone es que los trabajadores tengan acceso a los medios de producción en forma institucionalizada; es decir, utilizando las instituciones públicas del Estado para que los trabajadores obtengan medios de producción y evitar que: «La burguesía vaya concentrando cada vez más los medios de producción, la propiedad y la población del país. Reúne a la población, centraliza los medios de producción (principalmente, las fábricas) y concentra en pocas manos la propiedad».

Marx propone la abolición de la apropiación privada (un concepto más amplio que el de propiedad, que es meramente jurídico) sobre los medios de producción, esto es, "la abolición del sistema de propiedad burguesa", tal y como lo menciona en su "Manifiesto comunista": «Lo que caracteriza al comunismo no es la abolición de la propiedad en general sino la abolición del sistema de propiedad burgués» ya que la burguesía no solamente se apropia del producto social mediante la ley, sino que también corrompe las instituciones u otros mecanismos legales para apropiarse de la propiedad de los trabajadores. Un ejemplo de ello ha sido el robo (despojo) de tierras a indígenas y campesinos para la instalación de agroindustrias y proyectos minero-energéticos.

Con el acceso a los medios de producción por parte de los trabajadores, el marxismo concluye que se logrará una sociedad sin clases sociales donde todos vivan con dignidad, sin que exista la acumulación de propiedad privada sobre los medios de producción por unas cuantas personas, porque supone que ésta es el origen y la raíz de la división de la sociedad en clases sociales. Esto implicaría una enorme competencia y eficiencia en la economía; además, el trabajador no se podría explotar a sí mismo ni tampoco podría explotar a otro trabajador porque ambos tendrían medios de producción. Lo que dicho panorama podría ocasionar es que los trabajadores se organizarían para crear empresas más grandes a través de asociaciones justas; por tal motivo Marx expresa que «El precio medio del trabajo asalariado es el mínimo posible. Es decir, el mínimo necesario para que el obrero permanezca vivo. Todo lo que el obrero asalariado obtiene con su trabajo es, pues, lo que estrictamente necesita para seguir viviendo y reproduciéndose. Nosotros no aspiramos en modo alguno a impedir los ingresos generados mediante el trabajo personal, destinados a adquirir los bienes necesarios para la vida». Y recalca en su "Manifiesto" «Solo aspiramos a destruir el carácter ignominioso de la explotación burguesa, en la que el obrero solo vive para multiplicar el capital». Así entonces, el trabajador o trabajadores serán dueños de sus propios negocios, iniciando un elevado comercio; por esa razón en el "Manifiesto" especifica que «El comunismo no priva a nadie del poder adquirir bienes y servicios».

Marx considera que cada país tiene sus particularidades y por tanto las medidas para proveer a los trabajadores de medios de producción pueden ser diferentes y que al principio parecerá que no son suficientes. Marx tiene en clara la ley de la escasez y por ende la distribución de medios de producción en forma institucionalizada y legal se dará poco a poco en una transición lenta pero efectiva; por tal motivo concluye en su Manifiesto "(...) por medio de medidas que, aunque de momento parezcan económicamente insuficientes e insostenibles, en el transcurso del movimiento serán un gran resorte propulsor, y de las que no puede prescindirse, como medio para transformar todo el régimen de producción vigente".

En conclusión, Marx propone el uso de las instituciones del Estado, como por ejemplo el uso de los impuestos para financiar la compra y distribución de los medios de producción a los trabajadores, que al paso del tiempo formará un mercado de competencia perfecta.

Marx tuvo dos grandes influencias filosóficas: la de Feuerbach, que le aportó y afirmó su visión materialista de la historia, y la de Hegel, que inspiró a Marx para la aplicación de la dialéctica al materialismo. Aunque para su trabajo de disertación doctoral eligió la comparación de dos grandes filósofos materialistas de la antigua Grecia, Demócrito y Epicuro, Marx ya había hecho suyo el método hegeliano, su dialéctica. Ya en 1842 había elaborado su "Crítica de la filosofía del derecho de Hegel" desde un punto de vista materialista. Pero a principios de la década de 1840, otra gran influencia filosófica hizo efecto en Marx: la de Feuerbach, especialmente con su obra "La esencia del cristianismo". Tanto Marx como Engels abrazaron la crítica materialista de Feuerbach al sistema hegeliano, aunque con algunas reservas. Según Marx, el materialismo feuerbachiano era inconsecuente en algunos aspectos, por ello lo llama "contemplativo". Fue en las "Tesis sobre Feuerbach" (Marx, 1845) y "La ideología alemana" (Marx y Engels, 1846) donde Marx y Engels ajustan sus cuentas con sus influencias filosóficas y establecen las premisas para la concepción materialista de la historia.

Si en el idealismo de Hegel la historia era un devenir de continuas contradicciones que expresaban el autodesarrollo de la Idea Absoluta, en Marx son el desarrollo de las fuerzas productivas y de las relaciones de producción las que determinan el curso del desarrollo socio-histórico. Para los idealistas el motor de la historia era el desarrollo de las ideas. Marx expone la base material de esas ideas y encuentra el hilo conductor del devenir histórico.

Marx y Engels se basaron en la filosofía alemana de Hegel y de Feuerbach, la economía política inglesa de Adam Smith y de David Ricardo, y el socialismo y comunismo francés de Saint-Simon y Babeuf respectivamente, para desarrollar una crítica de la sociedad que fuera tanto científica como revolucionaria. Esta crítica alcanzó su expresión más sistemática en la obra más importante dedicada a la sociedad capitalista, "El capital: crítica de la economía política".

Además de las raíces mencionadas, algunos pensadores marxistas del siglo XX, como Louis Althusser o Miguel Abensour, han señalado en la obra de Marx el desarrollo de temas presentes en la obra de Maquiavelo o Spinoza. También diversos sociólogos y filósofos, como Raymond Aron y Michel Foucault, han rastreado en la visión marxista del final del feudalismo como comienzo del absolutismo y la separación del Estado y la sociedad civil, la influencia de Montesquieu y Tocqueville, en particular en sus obras sobre el bonapartismo y la lucha de clases en Francia.

Marx resumió la génesis de su concepción materialista de la historia en "Contribución a la crítica de la economía política" (1859):

La economía política es esencial para esta visión, y Marx se basó en los economistas políticos más conocidos de su época, los economistas políticos clásicos británicos, para posteriormente criticar su forma de pensar. La economía política, que es anterior a la división que se hizo en el siglo XX de las dos disciplinas, trata las relaciones sociales y las relaciones económicas considerándolas entrelazadas. Marx siguió a Adam Smith y a David Ricardo al afirmar que el origen de los ingresos en el capitalismo es el valor agregado por los trabajadores y no pagado en salarios. Esta teoría de la explotación la desarrolló en "El capital", investigación dialéctica de las formas que adoptan las relaciones de valor.

En su labor política y periodística, Marx y Engels comprendieron que el estudio de la economía era vital para conocer a fondo el devenir social. Fue Marx quien se dedicó principalmente al estudio de la economía política una vez que se mudó a Londres. Marx se basó en los economistas más conocidos de su época, los británicos, para recuperar de ellos lo que servía para explicar la realidad económica y para superar críticamente sus errores.

Vale aclarar que la economía política de entonces trataba las relaciones sociales y las relaciones económicas considerándolas entrelazadas. En el siglo XX esta disciplina se dividió en dos.

Marx siguió principalmente a Adam Smith y a David Ricardo al afirmar que el origen de la riqueza era el trabajo y el origen de la ganancia capitalista era el "plustrabajo no retribuido a los trabajadores en sus salarios". Aunque ya había escrito algunos textos sobre economía política ("Trabajo asalariado y capital" de 1849, "Contribución a la Crítica de la Economía Política" de 1859, " Salario, precio y ganancia" de 1865) su obra cumbre al respecto es "El capital".

"El capital" ocupa tres volúmenes, de los cuales sólo el primero (cuya primera edición es de 1867) estaba terminado a la muerte de Marx. En este primer volumen, y particularmente en su primer capítulo ("Transformación de la mercancía en dinero"), se encuentra el núcleo del análisis marxista del modo de producción capitalista. Marx empieza desde la «célula» de la economía moderna, la mercancía. Empieza por describirla como unidad dialéctica de valor de uso y valor de cambio. A partir del análisis del valor de cambio, Marx expone su teoría del valor, donde encontramos que el valor de las mercancías depende del tiempo de trabajo socialmente necesario para producirlas. El valor de cambio, esto es, la proporción en que una mercancía se intercambia con otra, no es más que la forma en que aparece el valor de las mercancías, el tiempo de trabajo humano abstracto que tienen en común. Luego Marx nos va guiando a través de las distintas formas de valor, desde el trueque directo y ocasional hasta el comercio frecuente de mercancías y la determinación de una mercancía como equivalente de todas las demás (dinero).

Así como un biólogo utiliza el microscopio para analizar un organismo, Marx utiliza la abstracción para llegar a la esencia de los fenómenos y hallar las leyes fundamentales de su movimiento. Luego desanda ese camino, incorporando paulatinamente nuevo estrato sobre nuevo estrato de determinación concreta y proyectando los efectos de dicho estrato en un intento por llegar, finalmente, a una explicación integral de las relaciones concretas de la sociedad capitalista cotidiana. En el estilo y la redacción tiene un peso extraordinario la herencia de Hegel.

La crítica de Marx a Smith, Ricardo y al resto de los "economistas burgueses" reside en que sus análisis económicos son ahistórico (y por lo tanto, necesariamente idealista), puesto que toman a la mercancía, el dinero, el comercio y el capital como propiedades naturales innatas de la sociedad humana, y no como relaciones sociales productos de un devenir histórico y, por lo tanto, transitorias. Junto con la teoría del valor, la ley general de la acumulación capitalista, y la ley de la baja tendencial de la tasa de ganancia, son otros elementos importantes de la economía marxista.

Los marxistas consideran que la sociedad capitalista se divide en clases sociales, de las que toman en consideración principalmente dos:

Existen otras clases que integran aspectos de las dos principales, o que estando asociadas a alguna, manifiestan nuevos rasgos propios particulares.

El marxismo ha sido tradicionalmente opuesto a todas las religiones. Marx escribió al respecto que "«el fundamento de la crítica irreligiosa es: el ser humano hace la religión; la religión no hace al hombre» y la frase cuyo final se haría célebre:

La referencia al opio ha prestado a una interpretación vulgar ya que éste no es –como suele suponerse– un estupefaciente ni tampoco un alucinógeno, sino un narcótico analgésico. Este equívoco del lector contemporáneo ha derivado en una confusión frecuente respecto de la sentencia marxista, según la cual parecería que Marx despreciaba la religión. La cita completa revela el porqué de la referencia a un opiáceo: jamás pretende que la religión se considere una forma de degradación intelectual ni tampoco una mera ilusión generada por las clases dominantes (interpretación no marxista que suprimiría la idea que éste tenía de la ideología, esto es, la ilusión de universalidad dentro de cada clase), sino que la religión sea, por el contrario, el anestésico necesario de la sociedad entera frente a la alienación social y de las clases oprimidas frente a sus condiciones materiales de existencia.

En Marx, la crítica de la religión no es una defensa del ateísmo, sino la crítica de la sociedad que hace necesaria a la religión. La supresión de estas condiciones y la realización plena de la comunión humana se desvincula de la condición biológica, proyectándose «al cielo» como intervención divina en una parusía futura, particularmente en el especial caso del cristianismo, en vez de construirse políticamente mediante la abolición de la propiedad privada y la división del trabajo. El fundamento filosófico del rechazo marxista de la religión ha estado vinculado al desarrollo del materialismo dialéctico por parte de Engels y Lenin.

En cualquier caso, ha habido diversos teóricos que consideran que ser marxista y religioso es compatible. Dentro de ellos se puede señalar al irlandés James Connolly y a diversos autores dentro de la teología de la liberación como Camilo Torres y Leonardo Boff.
Pero la crítica teórica hacia cualquier religión se basa en que ésta es concebida como el resultado de la producción de la superestructura de la sociedad, es decir, de la fabricación de ideas "ideológicas" que se hace una sociedad sobre sus propios modos de producción económicos. Así, la religión siempre es una concepción de ideas "políticas" que tienden a reafirmar la estructura económica existente.
Los textos marxistas donde se puede encontrar información sobre la concepción marxista de la religión son: "La ideología alemana" de Marx y Engels, y "La filosofía como arma de la revolución" de Louis Althusser. Marx describe a la religión como un ente alienador, el cual le pone como meta alcanzar a Dios, situación imposible para un humano pues Dios es la esencia humana deificada, es decir: la humanidad le ha dado sus mejores características a Dios. La religión haría conformista al hombre y lo obligaría a no luchar en este mundo, pues este es solo un preludio del verdadero. La síntesis cristiano-marxista de los teólogos de la liberación replica que el marxismo no implica este aserto y que, de ser así, también las clases dominantes impregnadas de espíritu religioso serían conformistas respecto de su existencia material e incluso serían pasivas frente a un conflicto con otras clases sociales. Para estos, en cambio, la religión –y en particular la cristiana– siempre exige una lucha en este mundo en función de una comunidad religiosa: sea con o sin clases dependiendo de cómo se la entienda políticamente. Debe recordarse que para el catolicismo la resurrección es el regreso al edén en la tierra y que, aunque dependa de Dios, ningún esfuerzo individual tendría sentido si estuviera coronado por una muerte sin retorno (incluso si la realización plena de la humanidad pudiera hacerse sólo socialmente y no biológicamente como en la resurrección cristiana), ya que la salvación de cada hombre de acuerdo a su esfuerzo dentro del alienado mundo presente sólo puede ser asegurado con la eternidad y la participación en el mundo venidero. Esto es igualmente cierto tanto para el ideario de autorrealización personal de la derecha cristiana (calvinista o al menos reconciliada con la burguesía), como para la lucha de clases de la izquierda cristiana (marxista o no), como para las originarias posiciones ascéticas y apolíticas del cristianismo primitivo. Estas últimas en particular dieron forma estamental a la dicotomía interna entre la vida económica y la religiosa del occidente medieval extramundano y a su peculiaridad histórica de fusión entre «sociedad civil» y «sociedad política» descrita con atención por Marx en su obra "Sobre la cuestión judía", cuya visión llegaría, junto con la opuesta de Nietzsche, a Max Weber, y que entroncaría en el debate marxista-weberiano sobre la influencia económica de la religión.

En su versión más ortodoxa, la interpretación marxista de la religión sería la de una forma de alienación cuya consecuencia para el hombre sería perder sus virtudes para adjudicárselas a un inventado ser supremo. Según Karl Marx, esto es lo que ocurriría en particular con la religión monoteísta: el hombre toma toda virtud que posee y toda idealización metafísica posible, y se la atañe a un ser supremo de su propia creación, devaluándose a sí mismo y dedicando su ser y propio destino a su voluntad y una trascendencia irreal posibilitada por su existencia.

El concepto de clase social no fue inventado por Karl Marx, sino por los fundadores de la economía política (Adam Smith…), los fundadores de la tradición de la historia política francesa (Alexis de Tocqueville), y de la historia de la revolución francesa (Guizot, Mignet, Thierry). Para los teóricos ingleses, los criterios de identidad de una clase social, se encuentran en el origen de los ingresos: los tipos de ingresos, la renta de la tierra, las ganancias y los salarios. Estos tres grupos son los principales para la nación; terratenientes, trabajadores y empresarios.

Entre los pensadores franceses, el término de “clase” es un término político. Por ejemplo para autores como Tocqueville, existen diferencias entre clases cuando los diversos grupos sociales compiten por el control de la sociedad.

Por lo tanto, Marx toma prestado de los economistas clásicos la idea implícita de clases como un factor de producción, la historia de las clases y el conflicto como productor de la historia. A todas estas teorías, Marx aporta el concepto del estado de la clase social como su lucha intrínseca: sin lucha no hay clases. Las clases sociales se consiguen con las luchas perpetuas históricamente determinadas. Marx señaló su contribución a la comprensión de las clases sociales:
Para Marx, las clases sociales son parte la realidad social. Las luchas de estas clases sociales, señalan el cambio social como un fenómeno duradero. Estas clases son el resultado de un mecanismo de división del trabajo, que se desarrolló al mismo tiempo que la privatización de los medios de producción. Las clases sociales surgen cuando la diferenciación de las tareas y las funciones dejan de ser cosa del azar para convertirse en una herencia. Hay una tendencia hacia la polarización entre las dos clases más antagónicas entre sí. Este antagonismo es la base de toda transformación que afecte al funcionamiento de la organización social y que modifique el curso de la historia. Para Marx, el proceso de producción capitalista crea dos posiciones: la de los explotadores (empresarios) y los explotados (trabajadores). Los comportamientos individualistas y colectivos se explican a través de estas posiciones en la reproducción de un sistema. El conflicto de clase es un rasgo cultural de la sociedad. Estos conflictos son el motor de los grandes cambios sociales. Marx se interesa por los cambios endógenos, es decir, aquellos que nacen del funcionamiento de la sociedad.

Cada etapa de la sociedad que se ha dado a lo largo de la historia se puede caracterizar a través de un modo de producción diferente.

Un modo de producción se basa en el conjunto formado por las fuerzas productivas y las relaciones sociales de producción que se dan en la sociedad. En cada una de las etapas de la evolución, el modo de producción demuestra un estado de la sociedad. Este es tomado como algo social, ya que sin fuerzas productivas, no puede haber ninguna duda sobre la falta de producción. Dichas fuerzas productivas son: los instrumentos de la producción, la fuerza de trabajo de los hombres, los objetos de trabajo, los conocimientos y las técnicas, la organización… Con motivo de todas estas actividades de producción y a través de ellas, los hombres entran en las relaciones sociales. El modelo de producción no puede ser reducido a un simple aspecto técnico, ya que es uno de los conceptos más importantes para Marx.

La sucesión de modos de producción a lo largo de la historia se puede resumir de la siguiente manera: se pasa de un comunismo primitivo al modo de producción esclavista, de este al feudal, después al capitalista y finalmente al socialista/comunista (ambos son sinónimos). En la sociedad comunista/socialista, la contribución productiva será aplica al principio resumido en la frase: “de cada cual según su capacidad, a cada cual según su necesidad”.

Sin embargo, Marx forma parte de un pensamiento dialéctico, en contraposición al mecanismo que está presente en el materialismo anterior, ve la convivencia entre clases, como un papel determinante en el desarrollo de la historia. A través de esta visión, el proletariado se transforma en una clase en sí y para sí, se vuelve consciente de sus intereses de clases, que son: socializar los medios de producción (socialismo) con el fin de maximizar las fuerzas productivas, la extinción de las diferentes clases sociales y la existencia de un estado político (comunismo). La historia sigue siendo la suma de las contingencias sujetas a los vaivenes de las luchas sociales de clases. La historia no es una evolución lineal entre los modos de producción, sino que es una transformación dialéctica de tomar conciencia de clases que experimentan fluctuaciones de lucha de clases en determinados momentos de la historia. En este desarrollo, las fuerzas productivas son cada vez más contradictorias con respecto a las relaciones sociales de producción, ya que no evolucionan al mismo ritmo.

Más allá de un cierto nivel de producción, los sistemas sociales se bloquean. Una época de revolución social que comienza a funcionar, permite eliminar las viejas relaciones de producción para dar paso al desarrollo de relaciones más coherentes al nivel alcanzando por las fuerzas productivas.

La acumulación primitiva de capital está definida como: proceso de creación de las condiciones para el nacimiento del capitalismo. La creación del capitalismo supone el uso de dos condiciones anteriores: la existencia de un grupo social (formado por hombres desprovistos de medios de producción y obligados a vender su fuerza de trabajo a cambio de un salario) y la acumulación de la riqueza indispensable para crear negocios capitalistas. Esta creación requiere de la unión de las condiciones necesarias para el nacimiento de dos clases fundamentales de la sociedad capitalista: explotados (trabajadores) y explotadores (empresarios).

La distinción entre trabajo y fuerza de trabajo es central para el análisis de la distribución. La retribución del obrero se establece en un nivel correspondiente a los gastos socialmente necesarios para asegurar su renovación. Es una mercancía cuyo valor está determinado por la cantidad de trabajo social que pide la producción de cada obrero.

Lo que afirma Marx se basa en la teoría aristotélica de la materia prima que, distingue el valor de uso (utilidad del objeto) del valor de cambio (lo que el objeto nos permite conseguir). En el proceso de intercambio se produce tanto, una inversión en el valor de cambio como, una inversión en el valor de uso.

El diagrama de Adam Smith: ley de la oferta y la demanda, informa de la existencia de un valor añadido al producto en el que los beneficios son obtenidos por los capitalistas, pero no por el trabajador. Los salarios a partir del valor social del producto (el valor social del objeto producido es una función de las materias primas, las herramientas de producción y la mano de obra necesaria para la producción).

El valor de cambio de un producto es el valor social que se aplica a una ganancia como resultado de un exceso de trabajo. Es en torno a los beneficios del valor agregado, que está emergiendo la lucha de clases, como proletarios capitalistas. Marx va a demostrar que el trabajador está en su derecho de reclamar el beneficio de este valor añadido, ya que este es un valor del mismo uso. Lo que hará el empresario capitalista, es hacer del trabajo un producto que cueste menos que el que utiliza, o dar más trabajo del que se requiere en la mano de obra. La ganancia es el valor añadido producido por el empleado, que el capitalista se apropia gratuita y legalmente.

El aumento de la producción, por parte del capitalista se puede obtener mediante la ampliación de la jornada laboral, aumentando la intensidad de trabajo o reduciendo los salarios de desempleo, el cual es la presión a la baja sobre los salarios. Esta ganancia es la forma de expoliación del proletariado en el capitalismo. Es la ganancia modificada que se produce como una forma excedente, es la búsqueda del beneficio, es el motivo principal del capitalismo. Una actividad se desarrolla si es rentable, y esta rentabilidad es la tasa de beneficio obtenido (relación entre las ganancias y el capital total invertido). La acumulación de capital conlleva una disminución a largo plazo de la tasa de beneficio y una bajada en la tendencia de la tasa de provecho. Es un índice de los límites históricos del capitalismo.

Si la modernización se incrementa, se trata de una sustitución creciente entre el "trabajo muerto" y "trabajo vivo”. En este momento sólo existe el trabajo vivo, que está creando valor, el trabajo muerto no anima al capital por medio de la fuerza de trabajo. La acumulación excesiva de capital dará como resultado el empobrecimiento de la clase obrera.

El capitalismo es víctima de su propia lógica. Hay cada vez menos capacidad de manejar sus contradicciones y avances hacia una crisis inevitable.

El trabajo no se trata solo de la transformación de una persona física (puesto que también podemos encontrarlo en los animales), esto implica una facultad de representación por parte de las personas.

La razón por la que Marx se dio cuenta de que esta actividad es totalmente aristotélica (ya que comienza por la representación de un fin), fue mostrando por lo que el fin es un mismo principio. El trabajo es principalmente una representación comprensiva que comprende la finalidad del objeto y difiere a este respecto al caso de los animales. El producto del trabajo humano debe existir en la representación ideal del trabajador, es decir, el trabajo deseado es un objeto que cumple perfectamente una de las funciones de la vida humana. En el capítulo VII de "El capital", Marx toma el esquema aristotélico en el que, es el trabajador el que está subordinado al mismo fin que el mismo da. El trabajo es tal, que el individuo se identifica y se reconoce con lo que hace: al realizar el trabajo, el hombre también lleva a cabo su propio poder, su poder de conceptualización y puede mejorar, por lo tanto, su capacidad de producción. La Inteligencia, puesto que es relevada a través de la realización del trabajo, en tanto que el hombre actualice en su trabajo las facultades que le son propias, será conducido a un proceso de identificación: en el producto del trabajo, el individuo una parte de su identidad.

Como el trabajo participa en la identidad de la persona, podemos decir que, el trabajo no es solamente tener (la producción), pero igualmente debe de ser una dimensión ontológica adecuada al trabajo.

Por eso Marx acusa al modelo de producción industrial capitalista de alienar a los trabajadores. En efecto, el trabajador ya no se encuentra en este caso, en el de la representación comprensiva, ya que se ignora el producto final y por lo tanto, la razón de su actividad. La cuestión relativa a la identidad es entonces anulada porque el único problema es el de la remuneración. Lo humano se convierte en animal, revelando un reflejo del automatismo mecánico (véase la película "Tiempos modernos" de Charlie Chaplin). En este sentido, se puede entender la abolición de la esclavitud, no como una cuestión ética, sino más bien como un cuestión de interés económico, ya que cuesta más mantener a la gente en la servidumbre bajo el marco de la esclavitud que en el del trabajo bajo marco del asalariado (véase la película “Queimada” de Gillo Pontecorvo con Marlon Brando).

Para Karl Marx y Friedrich Engels, "La historia de todas las sociedades humanas hasta nuestros días es la historia de la lucha de clases” (aunque sea en una nota posterior Engels califica esta afirmación).

La posición del individuo en las relaciones de producción (trabajador o explotador) es según él, es el elemento que permite la definición de la clase. Marx considera que, para que no haya una clase social, debe haber una conciencia de clase: la conciencia de tener un lugar común en la sociedad. Marx señaló que no basta con que muchos hombres estén del lado de un solo plan económico para que se forme el espíritu de clase. Según Marx, los personajes principales en la lucha de clases son, en la época capitalista, la burguesía y el proletariado. El comunismo constituye para él, el estado de la sociedad sin divisiones de clase y por lo tanto, es una sociedad sin lucha de clases.

Según el análisis marxista, la clase social dominante organiza la sociedad mediante la protección de sus mejores privilegios.

Para ello, se instaura el Estado, instrumento político de dominación: “policía y ejército responsable de mantener la seguridad y el orden público, el orden “burgués”. Marx también habla de "la ideología dominante". En cualquier sociedad, hay ideas, creencias y valores que dominan la vida social y cultural. Estas ideas dominantes son producidas por la clase dominante, es decir, la burguesía. Por lo tanto, estas ideas expresan la opinión de estas clases, es decir, la justifican y se esfuerzan en perpetuarse. Estas ideas penetran la mente, y a menudo funcionan como una visión del mundo en contra de sus intereses reales. Karl Marx no "inventó" el concepto de la lucha de clases. En realidad, la lucha de clases se ha teorizado mucho antes que él, por historiadores de la restauración, como François Guizot y Augustin Thierry.

La contribución fundamental de Marx en este concepto, en relación a estos historiadores, es haber demostrado que la lucha de clases no se extingue en la Revolución Francesa, sino que se prolonga en oposición burguesía/trabajadores en la de era capitalista. Así, al final de la lucha de clases se llegaría a una clase única, una vez extinguidas las clases sociales en el comunismo.

Desde la muerte de Marx en 1883, varios grupos del mundo entero han apelado al marxismo como base intelectual de sus políticas, que pueden ser radicalmente distintas y opuestas. Una de las mayores divisiones ocurrió entre los reformistas, también denominados socialdemócratas, que alegaban que la transición al socialismo puede ocurrir dentro de un sistema pluripartidista y capitalista, y los comunistas, que alegaban que la transición a una sociedad socialista requería una revolución para instaurar la dictadura del proletariado. La socialdemocracia resultó en la formación del Partido Laborista y del Partido Socialdemócrata de Alemania, entre otros partidos; en tanto que el comunismo resultó en la formación de varios partidos comunistas; en 1918 en Rusia, previo a la formación de la Unión de Repúblicas Socialistas soviéticas, dimanan dos partidos del Partido Obrero Social Demócrata de Rusia: el Partido Comunista, formación comunista, y el Partido Social Demócrata de Rusia.

En la actualidad sigue habiendo muchos movimientos revolucionarios y partidos políticos en todo el mundo, desde el final de la Unión Soviética, aunque el internacionalismo obrero ha sufrido una grave crisis. Aunque hay partidos socialdemócratas en el poder en varias naciones de Occidente, hace mucho que se distanciaron en aspectos relevantes de sus lazos históricos con Marx y sus ideas. En la actualidad en Laos, Corea del Norte, Vietnam, Cuba, la República Popular China y Moldavia hay en el poder gobiernos que se autoproclaman marxistas.

Muchos gobiernos, partidos políticos, movimientos sociales y teóricos académicos han afirmado fundamentarse en principios marxistas. Ejemplos particularmente importantes son los movimientos socialdemócratas de la Europa del siglo XX, el bolchevismo ruso, la Unión Soviética (Lenin, Trotsky, Stalin) y otros países del bloque oriental, Mao Zedong, Fidel Castro, Ernesto "Che" Guevara, Santucho, Kwame Nkrumah, Julius Nyerere, Thomas Sankara y otros revolucionarios en países agrarios en desarrollo. Estas luchas han agregado nuevas ideas a Marx y, por lo demás, han transmutado tanto el marxismo que resulta difícil especificar el núcleo de éste. Actualmente las transformaciones socio-económicas han obligado a repensar al marxismo en una línea llamada posmarxismo en la cual se encuentran autores como Ernesto Laclau y Chantal Mouffe.

La Revolución de octubre de 1917, encabezada por los bolcheviques (cuyas figuras principales eran Vladímir Lenin y León Trotsky) fue el primer intento a gran escala de poner en práctica las ideas socialistas de un Estado obrero.

Se suceden otra serie de gobiernos o dobles poderes obreros de relativamente breve duración, impulsados por revueltas proletarias con activa participación de los partidos comunistas locales, inspirados en el modelo de república de consejos obreros. La mayoría de estos son aplastados por las fuerzas de la reacción capitalista de las distintos gobiernos y potencias burguesas y fracasan. Son el caso de la Revolución de noviembre de 1918, encabezada por los espartaquistas en Alemania, la República Soviética Húngara de 1919, la República Soviética Bávara de 1919, el bienio rojo o movimiento de consejos de fábrica del norte de Italia de 1919 a 1920, el Sóviet de Nápoles, la República Socialista Soviética Galiciana en 1920, la República Popular Soviética de Bujará de 1920 a 1925, la República Socialista Soviética de Persia o República Soviética de Gilan, de 1920 a 1921, etc.

Tras morir Lenin, Iósif Stalin se había hecho con una gran concentración de poder en sus manos en el seno del Partido Comunista y del Estado soviético, el cual fue fortaleciendo en detrimento de los propios soviets (ya de por sí debilitados durante el hambre, la bancarrota económica y las masacres ocasionadas por la Guerra Civil Rusa). Hasta su muerte, numerosas purgas se vivieron en la URSS, bajo consignas tales como la "lucha contra el trotskismo", "los sabotajes", o "los agentes del fascismo", en las que se logró inhabilitar a los principales elementos críticos del PCUS y la sociedad soviética, muchos de ellos comunistas, testigos directos de la Revolución y opositores en mayor o menor medida a la deriva burocrática y la concentración de poderes que se estaba generando en seno de la URSS, encarnada en una casta de funcionarios y burócratas del partido, cuya divergencia de intereses respecto a la clase trabajadora y el peligro que entrañaban para la revolución obrera comienzan a manifestarse desde la primera mitad de los años 20, aún en vida del propio Lenin. Dichas purgas sólo logran fortalecer el poder de la nueva dirección del PCUS, encabezada ahora por Stalin, y pronto se extenderán a las secciones nacionales del Komintern, que, a nivel internacional, comienza a ser dirigido desde el comisariado de asuntos exteriores en Moscú.

Aunque llevaron a cabo pequeñas aportaciones teóricas al marxismo, Stalin y sus seguidores se caracterizan por haber dado cobertura ideológica a sus métodos y posicionamientos tácticos y políticos, encaminados al fortalecimiento del control sobre los medios de producción y administración del Estado por parte de la burocracia y dirección central del partido, a través de la falsificación o la adaptación de los principios ideológicos del marxismo y del leninismo a sus propios fines. Esto derivará en un sistema de gobierno y pensamiento formulado bajo el nombre de marxismo-leninismo (si bien sus críticos dentro del leninismo rechazan que se lo denomine de esta forma y reclaman para sí esta denominación) y la teoría del socialismo en un solo país, también llamado estalinismo, considerado por sus críticos marxistas como un alejamiento o distorsión de los postulados y principios de la tradición marxista y pensadores como Marx, Engels o Lenin; particularmente insistentes en esta postura son aquellas corrientes basadas en los planteamientos de Trotsky y Lenin (trotskismo) y las del denominado comunismo de izquierda, el marxismo libertario o el comunismo de consejos, también críticos en este sentido con la denominada corriente del leninismo (y por ende el trotskismo). A raíz de la muerte de Stalin, esta burocracia termina por acaparar el poder y afianzarse en la llamada nomenklatura. Ésta comenzará a medio plazo un proceso de progresiva liberalización de la economía, que culminará con la perestroika.

Al final de la II Guerra Mundial se produjo una expansión, por la vía militar, del poder político de la URSS, que se consolidó mediante el establecimiento de los llamados "Estados satélites" o del Pacto de Varsovia, en los países del Este que quedaron bajo su zona de influencia tras los acuerdos de Yalta y de Potsdam. Estos Estados reprodujeron estructuras políticas y sociales y tipos de economía y de gobierno muy similares a los de la Unión Soviética. Fueron gobernados mediante la formación de Partidos Comunistas, encuadrados en la Komintern, y adscritos a las fórmulas del marxismo-leninismo oficial. Algunos de los partidos adscritos a la Internacional Comunista que llegaron a formarse por sí mismos, lograron a la postre tomar el poder a través de insurrecciones guerrilleras y, en algunos casos, con bastante apoyo popular, y establecer un estado que seguía el modelo marxista-leninista oficial. Estas naciones comprendían a la República Popular China, Vietnam, Corea del Norte, Yugoslavia, Albania, Etiopía, Yemen del Sur, Angola, y otros. Después de la invasión militar por parte de Vietnam de Kampuchea Democrática, gobernada por el Jemer Rojo, un gobierno de estructura similar a aquél será establecido en Camboya.

En Chile, el gobierno de la Unidad Popular, encabezado por Salvador Allende, que duró desde 1970 hasta el golpe de estado de 1973, tenía una fuerte inspiración marxista. Si bien cambió radicalmente las formas de lucha conocidas al concretar un gobierno por la vía electoral, la "revolución a la chilena" buscaba la transformación de la sociedad hacia el socialismo. Al mismo tiempo, la coalición que llevó a Allende al gobierno estaba construida por la unión del Partido Comunista y el Partido Socialista, ambos declarados marxistas-leninistas en ese tiempo.

En 1991, la Unión Soviética se disolvió y el nuevo Estado ruso ya no se identificó con el marxismo. Otras naciones del mundo siguieron el mismo camino. Actualmente el socialismo científico ha dejado de ser una fuerza política prominente en la política mundial. China, donde gobierna el Partido Comunista, relajó su concepción económica del marxismo en 1978 avanzando progresivamente hacia un sistema económico más cercano al libre comercio. Este proceso continúa hoy en día.

Desde el comienzo de la democracia en España, en 1975, el PSOE se presentó a las elecciones como un partido marxista, proclamándose primera fuerza de oposición en el gobierno. Posteriormente, en 1982, con Felipe González a la cabeza, el PSOE abandonó su postura marxista; ese mismo año el partido ganó las elecciones.

Durante el siglo XIX y sobre todo en el siglo XX, el marxismo se divide en varias corrientes, entre otras:

El marxismo, tomado como cosmovisión, implica por su propia naturaleza un sistema de pensamiento y un sistema de organización política dirigido a la realización particular y socialmente consciente de un orden social mediante la planificación central de la economía (p.e. un socialismo políticamente establecido) que según éste es un necesario paso de la historia del hombre. El marxismo funciona, según su propia doctrina, a manera de catalizador e impulsor de la transición para la clase que de otra manera no podría ver edificado para sí el socialismo y la realización posterior del comunismo. Es por esto que es difícil de separar a sus más importantes críticos en categorías, siendo que estos se han confrontado por separado o a la vez con los regímenes marxistas instaurados por diferentes partidos únicos, usualmente comunistas, con los movimientos que los llevaron al poder y con la teoría marxista del mundo (i.e., el materialismo dialéctico y el materialismo histórico), sin que nunca termine de quedar suficientemente claro si estos tres aspectos del marxismo son verdaderos corolarios. En términos generales se puede, sin embargo, diferenciar a efectos prácticos las críticas al marxismo por las disciplinas de estudio más comprometidas en ellas.

Antropológicamente, el marxismo se confrontaría con el darwinismo quien rechazaría que dicha teoría se analogara con el materialismo histórico y con Sigmund Freud quien llegaría decir que "las obras de Marx, como una fuente de revelación, han tomado el lugar de la Biblia y el Corán, a pesar de que éstas no están más libres de contradicciones y oscuridades que aquellos antiguos libros sagrados"
En contraposición a la antropología del americano Lewis H. Morgan que Marx y Engels hicieran suya en "El origen de la familia" y según la cual todas las economías primitivas serían de carácter comunista, la antropología contemporánea de autores como Bronisław Malinowski y Fustel de Coulanges entre otros, presenta una visión casi opuesta del origen de la propiedad privada, que es resumida en la obra del historiador Richard Pipes "Propiedad y libertad". Respecto de la noción marxista de "ideología de clase", el autor liberal-conservador Kenneth Minogue fue uno de los primeros en invertirla en "La teoría pura de la ideología", volviendo contra las propias doctrinas sistémico-clasistas (que tratan de "ideológico" a todo pensamiento) la acusación de reificación ideológica por parte de intereses revolucionarios en una lucha de clases cuya existencia no puede ser puesta en duda sin apelar a una instancia neutral.

El sociólogo clásico Max Weber continuaría la afirmación de Engels acerca de la evolución propia, autónoma e interactiva de cada uno de los factores determinantes del progreso histórico, pero insistiría en que no podría haber entonces un determinante económico-tecnológico de última instancia: si se acepta, con Engels, que la historia es la suma de todos estos factores entonces necesariamente la influencia recíproca de fuerzas en un todo debe implicar que, si la religión y la cultura no se adaptan necesariamente a la producción económica, la economía como producción debe adaptarse a estas. Implícitamente en su obra "La ética protestante y el espíritu del capitalismo" se demostró la independencia de la superestructura ideológica respecto a la infraestructura tecnológica, tesis usualmente malentendida como una suerte de reverso del marxismo, como sí sería el caso del espiritualismo histórico de Werner Sombart. Esta exposición weberiana creó un cisma dentro de la sociología académica respecto del marxismo más dogmático, y la apertura a posiciones más complejas como la del historiador Eric Hobsbawm o las amistosamente separadas del marxismo como las esbozó el sociólogo analítico Charles Wright Mills.

El economista y sociólogo austríaco Joseph Schumpeter revisó los orígenes del capitalismo y rechazó la noción marxista de acumulación originaria como una contradicción autorreferente que requiere capital inicial para la actividad de una supuesta burguesía violenta originaria. A su vez, el institucionalista Douglass North ha ofrecido en sus estudios una revisión paralela de la historia del capitalismo que ha sido tenido muy en cuenta entre los historiadores marxistas.

La deontología marxista respecto de la praxis revolucionaria se enfrentaría a serios problemas filosóficos que intentarían ser resueltos por pensadores como Sartre desde una vía existencialista. Éticamente Marx llegó a considerar que "un fin que requiere medios injustificables no es un fin justificable", sin embargo dentro del marxismo como sistema la moral es en sí misma consecuencialista ya que en éste los fines juzgan a los medios, luego toda justificación depende de su funcionalidad para un fin determinado (fin que tampoco es juzgado desde un set de principios morales salvo el interés "históricamente determinado" de un grupo de pertenencia: en su caso, una clase social). Contra este historicismo predeterminado (con sus contradicciones éticas para un interés individual enfrentado al interés del progreso histórico), el epistemólogo y filósofo Karl Popper realizaría sus más agudas críticas en "La sociedad abierta y sus enemigos", obra que podría considerarse a su vez una de las principales réplicas globales al marxismo, y que junto con las objeciones de Bertrand Russell sería la más representativa de entre las críticas epistemológicas al marxismo como un "dogma reforzado" imposible de ser puesto a prueba mediante falsación, lo que llevaría a muchos marxistas a volcarse a una posición epistemológica en las ciencias en general cercana a la de Thomas Kuhn por la cual las contradicciones del marxismo deberían ser probadas dentro de la misma teoría, y no frente a hechos que serían en sí expresiones de una carga teórica previa.

En lo económico, V. K. Dmitriev en 1898 y Ladislaus von Bortkiewicz en 1906-07 y subsecuentes críticos expusieron que la teoría del valor de Marx y su ley de tendencia a la baja en la tasa de beneficio eran internamente inconsistentes. Como contrapropuesta, los más importantes economistas marxistas y/o sraffianos, tales como Paul Sweezy, Nobuo Okishio, Ian Steedman, John Roemer, Gary Mongiovi y David Laibman, propusieron sus propias versiones correctas de lo que debería ser la economía marxista abandonando como inadecuado el intento de Marx en "El capital" para el mismo fin, confrontándose así con los marxistas que defienden a aquel y que en respuesta se apoyan en una segunda teoría desarrollada a fines del siglo XX para interpretar, según ellos en forma más adecuada, las últimas obras de Marx.

En el ambiente académico las críticas a la teoría económica de Marx derivaron principalmente de su incompatibilidad (nunca resuelta por ninguna de las partes) con los descubrimientos microeconómicos del marginalismo. El conflicto con la visión marxista de la producción tomó forma en la obra de dos de los más importantes sistematizadores del marginalismo, representantes de las variantes austríaca y británica: primero Eugen von Bohm-Bawerk, que dirigiría las más conocidas críticas a la teoría del valor-trabajo y con ésta la explotación por adquisición de plusvalía, tanto dentro de la teoría marxista como desde el subjetivismo austríaco (por el cual incluso los costos dependen de la demanda); y luego Alfred Marshall que insistiría en la utilidad del capital y la gestión en la creación del valor, así como la consideración de la demanda como autónoma de la oferta aunque ésta se reconozca determinada por los costos.

Desde la macroeconomía, John Maynard Keynes llegaría a decir que "El capital" era "un manual obsoleto" al cual no sólo encontraba "científicamente equivocado sino además sin interés o aplicación para el mundo moderno", consideración que Joan Robinson criticaría como consecuencia de una pobre lectura de Marx, así como de Say. Una aproximación macroeconómica compatible con el marxismo fue esbozada por el economista polaco Michał Kalecki.

Respecto a la aplicación práctica del método marxista y a sus resultados políticos, las críticas usuales han sido menos a la doctrina marxista y más a los aspectos empíricos contra el movimiento Comunista y sus regímenes. Estas críticas se sostienen en términos humanistas y objetan el sacrificio en vidas humanas en persecuciones sociales y políticas, y además sólo se han dirigido al fenómeno totalitario como una situación circunstancial impuesta deliberadamente por los dirigentes marxistas, o sea, como un fenómeno aislado o al menos aislable de la teoría. Sin embargo algunas de estas críticas han tenido una dimensión teórica (especialmente por parte de liberales clásicos como Mises, Hayek, Isaiah Berlin y Raymond Aron, y anarquistas como Proudhon, Bakunin, Piotr Kropotkin y Noam Chomsky) según las cuales el fracaso político del totalitarismo, la interdependencia entre la falta de propiedad personal y libertad personal, el colapso de la planificación centralizada de la economía y la doctrina marxista-leninista serían elementos inseparables y codependientes, por lo cual, o la teoría marxiana del progreso histórico debe de estar equivocada y la dictadura científica pasaría a ser una profecía autocumplida con resultados perjudiciales para la clase obrera, o bien la noción de un "necesario progreso histórico" puede ser mayormente verdadera pero sin embargo el marxismo la habría malinterpretado a su favor: esta última opción sería planteada por el heredero de la crítica hegeliana al marxismo de Alexandre Kojève, el neoconservador Francis Fukuyama.

Finalmente, diversos autores de orientación centrista y socialdemócrata han hecho profundas reflexiones críticas de las bases filosóficas del marxismo, a saber Jürgen Habermas, Hannah Arendt, Anthony Giddens, y particularmente –por recordar las implicancias de que las relaciones sociales de producción no pueden determinar la superestructura jurídico-política ya que la presuponen– el jurista y pensador político Hans Kelsen quien, en su libro "La teoría comunista del derecho y el Estado", realizaría la que tal vez pueda considerarse la objeción más incisiva a casi todos los aspectos relevantes de la doctrina marxista, tanto en sus facetas políticas, su teoría jurídica e institucional, social y económica.






</doc>
<doc id="28344" url="https://es.wikipedia.org/wiki?curid=28344" title="À bout de souffle">
À bout de souffle

À bout de souffle (Sin aliento o Al filo de la escapada; en España, Al final de la escapada) es una película francesa de 1960, dirigida por Jean-Luc Godard y protagonizada por Jean-Paul Belmondo, Jean Seberg, Daniel Boulanger y Jean-Pierre Melville. La fotografía -realizada en blanco y negro- fue llevada a cabo por Raoul Coutard. 

No existe guion de este film. El asunto fue imaginado por François Truffaut y éste lo entregó a su amigo Godard, quien escribió una vaga guía de filmación y la abandonó muy pronto para confiarse a su genio improvisador. 
La película ganó el Oso de Plata a la mejor dirección en la edición de 1960 del Festival Internacional de Cine de Berlín.
Michel (Jean-Paul Belmondo) es un delincuente que, tras robar un coche en Marsella, emprende viaje a París para cobrar un dinero que se le adeuda y volver a ver a su amiga estadounidense, Patricia (Jean Seberg). En el camino, perseguido por la policía de tráfico, mata a un agente. Llega a París, pero no tiene dinero, por lo que recurre a varios amigos. Pasa su tiempo con Patricia, intentando convencerla de volver a acostarse con él, y de acompañarle a Roma. Los dos van de un lugar a otro, mientras Michel trata de recuperar su dinero y se oculta de la policía. Patricia duda acerca de sus sentimientos hacia él. Cuando descubre que lo está buscando la policía, empieza por ayudarle. Pero al final, para obligarse a alejarse de él, lo denuncia a la policía. Michel, cansado y enamorado, se niega a huir, lo que provocará su fin.















</doc>
<doc id="28347" url="https://es.wikipedia.org/wiki?curid=28347" title="Under Fire">
Under Fire

Under Fire (Bajo fuego en Hispanoamérica y Bajo el fuego en España) es una película estadounidense de 1983 ambientada en Nicaragua durante el año 1979, en los últimos días de la dictadura de Anastasio Somoza seguidos del triunfo de la Revolución Sandinista. La historia es ficticia, pero está inspirada en hechos históricos reales.

El famoso fotógrafo de guerra estadounidense Russell Price (Nick Nolte) se encuentra en la Nicaragua de 1979 para realizar un reportaje sobre la revolución contra el dictador Anastasio Somoza. Le cuesta informar con neutralidad a la vista de la crueldad de la lucha de la población civil contra la Guardia Nacional. Cuando la guerrilla del FSLN le encarga una fotografía del comandante Rafael, uno de sus líderes más populares, del cual se dice que está muerto, Price se ve involucrado en los acontecimientos. Junto a sus colegas Claire (Joanna Cassidy) y Alex (Gene Hackman) tiene que ocultarse para que no le encuentre la Guardia Nacional, que cuenta con la ayuda del amoral mercenario norteamericano Oates (Ed Harris), un viejo conocido de Price.


Parte de la historia está inspirada en el caso real del periodista estadounidense Bill Stewart, quien en junio de 1979 fue asesinado en Managua, junto a su intérprete nicaragüense Juan Espinoza, a manos de la Guardia Nacional de Somoza. El crimen, que fue registrado por el camarógrafo de Stewart, provocó repulsa internacional y motivó que la administración Carter le pusiera fin a 43 años de apoyo militar estadounidense a la dictadura somocista, lo que permitió el triunfo de la revolución sandinista al mes siguiente.

Fue rodada en el sureste de México, para ser precisos en Chiapa de Corzo, Chiapas, usando como locaciones el Cañón del Sumidero y una pequeña colonia del municipio de Chiapa de Corzo llamada América Libre y en Oaxaca de Juárez, Oaxaca, destacando varios edificios históricos de la misma.

La banda sonora, compuesta por Jerry Goldsmith e interpretada por el destacado guitarrista de jazz Pat Metheny, estuvo nominada al Óscar. La pieza instrumental que aparece en los créditos finales ("Nicaragua") fue utilizada por Quentin Tarantino para musicalizar una escena de la película "Django Unchained" (2012).




</doc>
<doc id="28348" url="https://es.wikipedia.org/wiki?curid=28348" title="Barry Lyndon">
Barry Lyndon

Barry Lyndon es una película angloamericana dramática-histórica de 1975 escrita y dirigida por Stanley Kubrick; y protagonizada por Ryan O'Neal, Marisa Berenson, Patrick Magee y Hardy Krüger. Está basada en la novela homónima de William Makepeace Thackeray, publicada en 1844. 
La cinta describe las aventuras ficticias de un personaje irlandés durante el siglo XVIII, y está ambientado en parte durante la Guerra de los Siete Años. Los exteriores fueron rodados en diversas localizaciones de Irlanda, Inglaterra y Alemania.

La película ganó cuatro premios Óscar a la , , y , y fue nominada también a , y . Además Kubrick ganó el premio de la Academia Británica de Cine y Televisión (BAFTA) a la Mejor Dirección y John Alcott ganó el de Mejor Fotografía, y la cinta fue nominado a Mejor Película, Mejor Dirección Artística y Mejor Vestuario. En numerosas encuestas, entre ellas del "Village Voice" (1999), "Sight & Sound" (2002), "Time" (2005) y la BBC, se la ha considerado una de las mejores películas jamás rodada.

El afamado director de cine Martin Scorsese ha citado a "Barry Lyndon" como su película favorita de Stanley Kubrick. Algunas citas del guion de esta película han aparecido en otras obras cinematográficas tan dispares como "Los duelistas" de Ridley Scott, "La edad de la inocencia" del propio Scorsese, "Rushmore" de Wes Anderson y "Dogville" de Lars von Trier.

Cuenta las peripecias del aventurero irlandés Barry Lyndon (Ryan O'Neal) y su ascenso y caída en la sociedad inglesa. La historia comienza en Irlanda en el siglo XVIII. El joven Redmond Barry se enamora de su provocadora prima Nora Brady y se bate en duelo por su amor aparentemente matando a su prometido el rico capitán inglés Quin. Barry huye, se enrola en el ejército inglés y vive muchas aventuras. Pasado un tiempo descubre que el duelo fue amañado por su propia familia y que el capitán inglés está vivo y se casó con Nora. Barry viaja por Europa como soldado, agente secreto al servicio de Prusia y finalmente como jugador profesional, buscando fortuna.

Seduce y se casa con una rica viuda, Lady Lyndon (Marisa Berenson), a la que no ama. Barry es indiferente a ella y a su hijo, Lord Bullingdon, quien sabe que Barry es simplemente un oportunista. Barry se convierte en un hombre cínico y un marido egoísta. La pareja tiene un hijo, Brian, que crece gozando del gran cariño de su padre pero que muere tras sufrir una caída de caballo. En un duelo con Lord Bullingdon Barry pierde una pierna y bajo amenaza de encarcelamiento por deudas impagadas, acepta abandonar Inglaterra. Después de pasar algunos años con su madre en Irlanda, Barry transcurre el resto de su vida jugando en Europa.

Rodada enteramente en decorados de época (sobresaliendo el Castillo de Howard) y en luz natural (con velas en las escenas nocturnas o de interior), mediante objetivos de cámara muy luminosos (modificación de una cámara Mitchell y de objetivos Zeiss de focal 50 mm y de apertura F0.7) y mediante el tratamiento especial del negativo, esta película presenta una fotografía excepcional, auténtica proeza técnica que le confiere una estética más bien sombría y muy particular, en el tono de la historia y las pinturas de la época. El espectador se encuentra de esta forma imbuido en la intimidad de los personajes, tal y como pretendía Kubrick, que quería realizar un documental que se desarrollara durante el siglo XVIII.

La banda sonora incluye con varias piezas. Entre las barrocas están una adaptación del segundo movimiento del concierto BWV 1060 de Bach, una transcripción de la sonata para violonchelo RV 40 de Vivaldi , una adaptación orquestal de la zarabanda de la suite para tecla HWV 437 de Händel, la marcha "Hohenfriedberger" de Federico II el Grande. Entre las clásicas, "El barbero de Sevilla" de Paisiello y el segundo movimiento del trío para piano nº 2 de Schubert. A su vez, la incluye música popular irlandesa interpretada por The Chieftains.

Cabe señalar que el último tercio de la película no respeta el argumento original de la novela, en la que el hijo de Redmon Barry fallece en un accidente de caballo y el protagonista acaba arruinado en la cárcel, en compañía de su anciana madre. Además, su hijastro, al que se daba por muerto en las guerras coloniales de Norteamérica, regresa a Inglaterra y reclama sus posesiones como legítimo heredero, hecho que acaba por producirse.





</doc>
<doc id="28349" url="https://es.wikipedia.org/wiki?curid=28349" title="Manco Cápac">
Manco Cápac

Manco Cápac (quechua: "Manqu Qhapaq"), Manco Inca o Ayar Manco, según algunos cronistas, fue el primer gobernador y fundador de la cultura Inca en Cuzco (¿inicios siglo XIII?). Es el protagonista de las dos leyendas más conocidas sobre el origen de los incas. Tuvo como esposa principal a Mama Ocllo, con quien engendró a su sucesor Sinchi Roca y otras esposas más como Mama Huaco de quien se dice que era una mujer aguerrida. Si bien su figura es mencionada en crónicas y se tiene como base para la explicación histórica del origen de los incas, su verdadera existencia no está del todo clara.

Algunos historiadores consideran a Manco Cápac un personaje mítico poniendo así en duda su existencia como personaje histórico. Sin embargo, la mayoría de autores lo consideran un personaje real, y basan sus argumentos en pruebas como la descendencia de su familia real llamada "Chima Panaca", la cual mantuvo su lugar en la nobleza inca hasta la conquista. También se basan en pruebas arqueológicas como su propio palacio, el Inticancha (ahora Coricancha), ambos prevalecen en el Cuzco moderno y según las crónicas fueron hechas por Manco Cápac. La historia oficial dice que Manco Cápac fue un personaje histórico.

Manco Cápac es el protagonista de las dos principales leyendas que explican el origen del imperio inca. Ambas leyendas coinciden en que fue él el fundador de la etnia inca en Cuzco, en que su esposa principal fue Mama Ocllo.

La leyenda de los hermanos Ayar es una leyenda en la tradición oral inca en la cual se cuenta que cuatro hermanos con sus cuatro esposas llegan a Cuzco tras pasar una serie de aventuras. Uno de estos cuatro hermanos, Ayar Manco, llegaría a fundar la ciudad inca de "Qosqo" (Cuzco actual) siendo así el primer gobernante del imperio inca llamado desde entonces Manco Cápac.

Leyenda en la cual se cuenta que Manco Cápac y Mama Ocllo, pareja de esposos y hermanos hijos del dios sol, nacen de las espumas del lago Titicaca, con la misión de fundar la capital del futuro imperio en un lugar fértil. El sitio de fundación sería marcado por el lugar donde se hundiría el báculo sagrado de Manco Cápac, cosa que sucedió en el valle del río Huatanay, en Cuzco.

Sin embargo, al carecer de una tradición escrita, a no ser de aquella que se inició con la publicación de "Comentarios reales de los incas", obra del Inca Garcilaso de la Vega, la autenticidad de esta leyenda como leyenda inca se pone en duda. Algunos afirman inclusive que Garcilaso fue el autor intelectual de esta leyenda cerca del año 1609.

Manco Cápac, es protagonista de dos leyendas más conocidas sobre el origen de los incas, sin embargo, la historia oficial tiene su propia versión sobre la base de crónicas.

Manco Cápac nació en Tamputoco, "Los Incas", pág 38. – Pedro Cortázar "Documental del Perú: Cuzco", pág 148. Ambos afirman que esta ciudad se encontraría en la actual Provincia de Pumaurco, Cuzco. Al lugar de uno de los muchos descansos que hicieron los sobrevivientes de su etnia: Taipicala al escapar de las invasiones Aimaras en el Altiplano andino. Su padre se llamó Apu Tambo, el cual dio lugar luego a que los jefes locales se llamen así. El éxodo en el cual nació Manco Cápac duró 20 años aproximadamente y recorrieron sólo 500 kilómetros llevando un estilo de vida seminómade.

Manco Cápac hizo muchas leyes humanas y sabias, condenando con pena capital el homicidio, el adulterio y el hurto; mandó que cada uno tomase mujer de su propia familia, pero nunca antes de los 20 años de edad; propuso el culto del sol como primera divinidad, y le labró un templo en el Cuzco, e inmediata a él una casa para las vírgenes consagradas a aquella deidad, las cuales debían ser de la sangre real de los incas.

Manco Cápac nació en medio de un lento éxodo, y para cuando murió su padre tuvo que continuar la dirección de su etnia calculada en una decena de familias ("ayllus"). 

La trayectoria que recorrieron los Taipicala según las versiones oficiales concuerda claramente con la trayectoria descrita en la leyenda de los hermanos Ayar, mas no en el tiempo que les tomó hacerlo.

Al llegar al valle de Cuzco, los incas derrotaron a tres pequeñas etnias (Sahuares, Huallas y Ayar Uchos o Alcahuisas).
El terreno que ocuparon inicialmente los incas en Cuzco fueron los alrededores de donde hoy está la Plaza de Armas de Cuzco, en esa época era una zona pantanosa atravesada por dos riachuelos.

En Cuzco, Manco Cápac fundó cuatro barrios llamados: Chumbicancha (barrio de tejedores), Quinticancha (barrio del picaflor), Sairecancha (barrio de tabaco) y Yarambuycancha (¿barrio de alisal?).

Una vez establecidos en Cuzco, Manco Cápac y su etnia ocupaban sólo una pequeña fracción del territorio del valle de Cuzco, otras etnias más poderosas ocupaban el mismo valle e inclusive por el norte amenazaba un estado confederado de Ayamarcas y Pinaguas. Todas estas etnias veían a los incas como una etnia invasora y ciertamente lo eran. Manco Cápac durante su permanencia en el gobierno tuvo que luchar y defenderse de los continuos ataques de estas etnias. En algunas ocasiones, su sucesor Sinchi Roca tuvo que pelear él mismo en la defensa contra estas etnias.

Tras una muerte natural, dejando a su hijo, Sinchi Roca, como sucesor, Manco Cápac fue momificado y guardado en el inticancha hasta el reinado de Pachacútec, quien ordenó su traslado al templo del lago Titicaca. En Cuzco sólo quedó una estatua en su honor.
Fue Pachacútec también quien inventó y esparció las leyendas del origen de los incas como un intento de ""divinizar"" las hazañas incas y de promover la identidad, y por ende la unificación de su imperio.

Los años en que vivió y reinó Manco Cápac están envueltos en una gran duda y debate entre los historiadores y cronistas, casi tanto como si es un personaje histórico o uno mítico. Las fechas que dan los diversos estudiosos varían incluso por varios siglos de diferencia, como las fechas de Sarmiento (en 1572), el historiador se refiere a que el primer inca nació en el año 521 y que reinó entre 565 y 656, es decir, vivió por 135 años y reinó por 91. Según Cabello Balboa (en 1586) reinó entre 945 y 1006, es decir, por 61 años. Otras fuentes hablan de 41 años de reinado, entre 1021 y 1062. Según otros historiadores reinó por 28 años, entre 1150 y 1178. Las cifras más tardías hablan de 30 años de reinado entre 1226 y 1256.




</doc>
<doc id="28350" url="https://es.wikipedia.org/wiki?curid=28350" title="Bus Stop">
Bus Stop

Bus Stop es una película dirigida por Joshua Logan en 1956, protagonizada por Marilyn Monroe y Don Murray. Está basada en la obra teatral del mismo título de William Inge. Ganó un Oscar al mejor actor de reparto (Don Murray).

Beauregard (Don Murray) es un vaquero que se gana la vida participando en rodeos él ha vivido en su rancho en Montana desde su niñez y no ha tenido nunca una relación con ninguna mujer siendo virgen a los 21 años, justo antes del participar en el rodeo que es un evento de vaqueros se dirige al bar local en donde conoce a la cantante principal Cherie (Marilyn Monroe), y se enamora de ella. El conversa con Cherie en un granero en donde ella le manifiesta que se siente atraída físicamente por Beauregard y el le comenta que sus amigos le dicen Bo, en ese instante se dan un beso romántico y el en un malentendido piensa que la atracción física es lo mismo que el amor y declara a su amigo que después del rodeo se casaran como esposo y esposa. Cherie se siente aturdida por tal declaración y enseguida sabe que Bo ha malinterpretado el beso. Bo participa en el rodeo en diferentes concursos dentro del mismo y al terminar cada concurso le dedica la victoria a Cheri a viva voz delante de todo el mundo. Al terminar el rodeo se da a entender que Bo ha ganado en 4 de los 5 concursos ganando una cantidad de 4.000 dólares. El compra 3 boletos de bus hacia su rancho en Montana, en ese mismo momento Cherie quiere escapar, se dirige a la estación de buses, pero Bo la encuentra y usando sus habilidades la enlaza con un lazo para el ganado y la obliga a venir con él en autobús a su casa en Montana. Durante el viaje ocurre una inmensa nevada bloqueando el paso en la carretera, y el conductor se ve obligado a quedarse junto con los demás pasajeros en una estación de buses en el camino hasta que despejen la nieve de la carretera, durante el viaje Cherie le comenta que lo desprecia, ellos se quedan una noche en la estación de buses en donde ocurre una pelea entre Bo y el conductor del bus debido a su trato rudo hacia Cherie, el conductor gana la pelea y Bo sintiéndose avergonzado se disculpa con todos los pasajeros del bus, acto seguido él se disculpa con Cherie por todo lo acontecido y Cherie le comenta que ella ha tenido muchos amigos antes que Bo y él le confiesa que no ha tenido ninguna amiga antes de Cherie y le dice a Cherie que, como él no ha tenido amigas y ella ha tenido muchos amigos eso los complementaria a ambos y al mismo tiempo le dice que a el no le importa su pasado y que la ama por como es ella, Cherie cuyos sentimientos han aflorado durante todo el viaje le confiesa que nunca le habían dicho algo tan romántico y se enamora de él y al final, ella accede a ir con él a su casa en Montana.


</doc>
<doc id="28351" url="https://es.wikipedia.org/wiki?curid=28351" title="Brubaker">
Brubaker

Brubaker es una película de 1980 dirigida por Stuart Rosenberg, que tiene a Robert Redford como protagonista principal. Es una película basada en el libro del mismo título de Joe Hyams y Thomas O. Murton y está basada en hechos reales sobre la historia real de Tom Murton, quien a finales de los 60 reformó y denunció el salvaje y corrupto sistema penintenciaro de Arkansas.

Brubaker, el nuevo alcaide de una prisión en el sur de los Estados Unidos, se viste como un preso para conocer de cerca las condiciones en las que estos viven. Observa la corrupción, el mal estado del lugar y la violencia existente por parte de los guardias y funcionarios. También observa los negocios que ellos hacen a costa de los presos sometiéndolos a trabajos de esclavo en beneficio de las empresas del lugar. 

Cuando se da a conocer y comienza a tomar medidas para frenar la corrupción y la violencia y mejorar la situación allí, se encuentra con la resistencia de todo el cuerpo de guardias de la cárcel. El asunto trasciende incluso a la administración de prisiones del estado, cuyos responsables tampoco están dispuestos a tolerar las actuaciones de Brubaker, ya que también están corrompidos y se han aprovechado también de los presos.

Finalmente, cuando el descubre un cementerio clandestino con 200 prisioneros muertos, que fueron asesinados en la cárcel, la administración le expulsa bajo una excusa y abole todas las reformas que trajo consigo en un intento de volver al pasado corrupto. Sin embargo aún así deja un legado. A través de él los prisioneros aprendieron como hacer la cárcel más humana, lo que lleva a su rebelión dos años mas tarde, cuando denuncian la situación ante el Tribunal Supremo, el cual luego ordena la reforma incondicional de la cárcel por ser inconstitucional.


La dirección de "Brubaker" le fue encomendada en un principio al director Bob Rafelson, pero una serie de discrepancias en el rodaje llevó pronto a la sustitución de Rafelson por otro director, Stuart Rosenberg, porque en 1967 dirigió de manera magistral para la gran pantalla La leyenda del indomable, gran drama carcelario protagonizado por Paul Newman. La película se rodó en Ohio.

La película fue estrenada el 20 de junio de 1980 en los Estados Unidos y en España el 23 de enero de 1981. No fue un gran éxito de taquilla a pesar de que, según ABC, la película es de gran calidad gracias al carisma de Redford y a su espléndido elenco de actores secundarios.

Según Séptimo Arte esta película es una clara denuncia de la brutalidad diaria en las cárceles norteamericanas, donde eran corrientes las palizas aleatorias, los asesinatos selectivos y la constante vulneración de los derechos humanos de los presos, que deja un mal sabor de boca. Por otro lado, Fotogramas opina que la trama de la película, aunque esté montada con bastante habilidad, no va en su discurso más allá de los latiguillos del más convencional melodrama carcelario. Finalmente "Decine21" describe la película como un impactante drama carcelario, que es un sólido alegato a favor de los derechos humanos.




</doc>
<doc id="28353" url="https://es.wikipedia.org/wiki?curid=28353" title="Isla del Rey (Chafarinas)">
Isla del Rey (Chafarinas)

La isla del Rey es una isla española perteneciente al grupo de las islas Chafarinas, en el mar Mediterráneo frente a la costa del norte de África. Actualmente la isla está protegida como zona natural. Su extensión es de unas 1,6 hectáreas.


</doc>
<doc id="28354" url="https://es.wikipedia.org/wiki?curid=28354" title="Bajo el volcán (película)">
Bajo el volcán (película)

Bajo el volcán es una película de 1984, dirigida por John Huston, basada en la novela del mismo título de Malcolm Lowry. Protagonizada por Albert Finney, Jacqueline Bisset, Anthony Andrews y Katy Jurado en los papeles principales. Obtuvo dos nominaciones a los Premios Óscar, al ("Albert Finney") y a .

Fiel a la novela de Lowry, John Huston relata la historia de un alcoholizado cónsul británico en el pueblo de Quauhnahuac, México, el Día de Muertos en 1938.

Narración sobre un día en la vida de Geoffrey Firmin ("Albert Finney"), durante la fiesta mexicana del Día de Muertos y mientras crece en Europa la inestabilidad que dará lugar a la Segunda Guerra Mundial. Firmin es un ex cónsul británico entregado a la bebida, que reside en la Capital Histórica del Estado de Morelos Cuernavaca, al pie de los volcanes Popocatépetl e Iztaccíhuatl. El comportamiento autodestructivo de Firmin contrasta con el ingenuo idealismo de su hermanastro Hugh ("Anthony Andrews"). Yvonne ("Jacqueline Bisset"), la mujer con la que Firmin compartió aquel paraíso, ha regresado con la esperanza de poder ayudar a Firmin y de recomponer su relación. Sin embargo, la tristeza y el alcoholismo del cónsul van poco a poco revelando traiciones y desencuentros pasados entre estos tres personajes centrales, que determinan su incapacidad para restablecer cualquier pasado.

La película se filmó en las ciudades de Acapantzingo, Cuautla, Cuernavaca y Yautepec, en el estado de Morelos, México.



</doc>
<doc id="28355" url="https://es.wikipedia.org/wiki?curid=28355" title="Billy Bathgate">
Billy Bathgate

Billy Bathgate es una película del año , dirigida por Robert Benton y protagonizada por Dustin Hoffman, Nicole Kidman, Loren Dean y Bruce Willis. Está basada en el libro del mismo título escrito por E. L. Doctorow.

La película se inspira en los sindicatos del crimen de los años '20 y '30. Billy Bathgate (Loren Dean) es un joven que de la nada se convierte en la mano derecha de Dutch Schultz (Dustin Hoffman), un poderoso gánster. A Schultz le impresionó el joven, por lo que hace de él su protegido. Bathgate se dará cuenta de que en este mundo en el que vive, la riqueza y el poder van unidos con el peligro y la muerte.


"Billy Bathgate" fue filmada en Hamlet, Carolina del Norte, y Saratoga Springs, Nueva York. El radaje comenzó en 1990 y concluyó en febrero de 1991 en la ciudad de Fayetteville.


</doc>
<doc id="28356" url="https://es.wikipedia.org/wiki?curid=28356" title="Inti">
Inti

Inti es el nombre en quechua del Sol, considerado como la deidad más significativa en la mitología inca. 

Los quechuas del Imperio inca tenían al dios Sol en el primer peldaño del escalafón celeste, con el nombre sagrado de Inti; Las culturas anteriores tenían como deidad suprema a Viracocha, una abreviatura al nombre completo del dios Apu-Qun-Tiqsi-Wira-Qutra (Apu Kon Titi Wiracocha), que es, por antonomasia, la definición total de su poder omnímodo, puesto que este nombre no es sino la enumeración de sus poderes (supremo ser del agua, la tierra y el fuego). Aunque más tarde fue evolucionando hacia una personalidad más compleja y universal, que terminó por absorber a la divinidad.

Este nuevo y mucho más poderoso dios Sol no estaba solo en su reino. Estaba casado con su hermana, la Luna; con quien compartía una igualdad de rango en la corte celestial. La Luna era conocida bajo el nombre de Mama Quilla.

A Inti se le representaba con la forma de un elipsoide de oro en el que también podían aparecer los rayos como otro de sus atributos de poder, y la luna tenía la forma ritual de un disco de plata. 
También a inti se lo usa en las fiestas del "Inti Raymi"
Como creador, era adorado y reverenciado, pero a él también se acudía en busca de favores y ayuda, para resolver los problemas y aliviar las necesidades, ya que sólo él podía hacer nacer las cosechas, curar las enfermedades y dar la seguridad que el ser humano requiere.

A la Mama Quilla estaba adscrito el fervor religioso de las mujeres y ellas eran quienes formaban el núcleo de sus fieles seguidoras, ya que nadie mejor que la Quilla podía comprender sus deseos y temores, y darles el amparo buscado.

Los incas adoraban a Inti porque sabían que el sol daba mediante su energía alimento fotosintético a sus tierras. Convirtieron al sol su deidad protectora particular. El sol era el origen y el progenitor de los ayllus reales y del inca en sí. Se fundaron templos del sol en todo el Imperio, siendo el más importante el de Cuzco, llamado Coricancha. inti era el dios sol; fuente de toda riqueza, rey del cielo, de las plantas, y el universo. se le consideraba además el ancestro del emperador sapa inca, que como representante suyo gobernaba con poder absoluto sobre el Tahuantinsuyo.

El sol tiene un importante significado cultural en el Perú, Argentina, Bolivia y Uruguay. Inti, dios del sol para los incas, está presente en la cultura peruana y los actuales países que formaron parte del antiguo territorio del Imperio Inca, que se extendía desde el norte del Perú hasta las praderas de Argentina. La moneda peruana es denominada Sol (antesNuevo Sol) y en Perú se encuentran aun en pie varios templos incas en honor al sol, a la par que varios grupos indígenas mantienen la sabiduría en los poderes del sol y celebran festivales en su honor, como ser el festival del sol celebrado desde 1995 en los templos incas del Perú, así como en Puente del Inca y el valle de la Luna en Argentina, y las ruinas de la Puerta del Sol en Bolivia.




</doc>
<doc id="28357" url="https://es.wikipedia.org/wiki?curid=28357" title="Buffalo Bill y los indios">
Buffalo Bill y los indios

Buffalo Bill and the Indians, or Sitting Bull's History Lesson es una película estadounidense de 1976, del género western, comedia. Escrita, producida y dirigida por Robert Altman. Protagonizada por Paul Newman, Joel Grey, Kevin McCarthy, Harvey Keitel, Geraldine Chaplin, Frank Kaquitts, Will Sampson, Pat McCormick, Shelley Duvall y Burt Lancaster entre otros. Basada en la obra teatral "Indians" de Arthur L. Kopit.

Ganadora del premio Oso de Oro 1976 del Festival Internacional de Cine de Berlín.

Buffalo Bill ("Paul Newman") está pensando en montar su propio espectáculo del Oeste. El jefe amerindio Toro Sentado ("Frank Kaquitts") ya le ha confirmado su participación. No obstante, Toro Sentado tiene sus planes secretos, que involucran al general Custer y al mismísimo presidente Grover Cleveland ("Pat McCormick").


</doc>
<doc id="28359" url="https://es.wikipedia.org/wiki?curid=28359" title="Año cero">
Año cero

El año cero (0) no existe en el calendario gregoriano ni en el juliano. El año 1 a. C. inmediatamente precede al año 1 d. C. Es decir que después del 31 de diciembre del año 1 a. C. comenzó el 1 de enero del año 1 d. C. Lo mismo acontecería con las décadas, empezando la primera de nuestra Era en el año 1 d. C. y hasta el año 9 d. C., ambos dentro, para conformar así la década (diez años), pero en este caso, durando nueve años.

Los historiadores adoptaron esta convención a partir de su utilización por Beda en su "Historia ecclesiastica gentis Anglorum" ("Historia eclesiástica del pueblo inglés", de 731). Beda no utilizó el cero debido a que los años se cuentan a partir de uno y no de cero. Él conocía bien el número cero, dado que cero fue la primera epacta del ciclo de 19 años utilizado para calcular la fecha de la Pascua, tal como explicó en su obra "De temporum ratione" ("Sobre el recuento del tiempo", de 725).

La palabra latina "nullae", que significa 'nada', se utilizó para nombrar esta epacta, mientras que el resto de las epactas fueron numeradas con cifras romanas.

En cualquier caso, los años, como los días o los siglos, no se "cuentan" con números cardinales, sino que se "ordenan" con números ordinales, entre los que no hay "cero" (por ejemplo, en una lista ordenada, antes del primero no hay una "posición cero"). Así pues, no hay "año cero" del mismo modo que no hay "siglo cero", ni "día cero" de los meses, ni hay ningún "día cero de la semana". También el cómputo de las horas se hizo tradicionalmente por números ordinales ("hora prima, hora secunda, hora tercia, etc." en la terminología latina; o "doce en punto de la noche", "doce y un minuto de la madrugada", etc. en la terminología española clásica), hasta que en la segunda mitad del siglo XX, la generalización de la numeración propia de las pantallas digitales y del vocabulario militar estadounidense, así como la práctica de cronometrar para comparar la duración de periodos de tiempo vinculados a actividades populares como los deportes, introdujeron en el uso cotidiano los novedosos conceptos de "hora cero", "minuto cero", "segundo cero" y sus submúltiplos.

Los astrónomos introdujeron el año cero para normalizar la cronología atendiendo a sus propios criterios. El calendario que lo utiliza se llama "Calendario juliano proléptico". Esta decisión implica un desfase de los años anteriores: el primer año antes de Cristo corresponde al año cero, porque después del 31/12/01 a.C llegaría a ser directamente el 01/01/01 d.C 

Existen dos razones para usar el año 0:


Hay tres razones para no hacerlo:




</doc>
<doc id="28363" url="https://es.wikipedia.org/wiki?curid=28363" title="Dulce pájaro de juventud">
Dulce pájaro de juventud

Dulce pájaro de juventud es una película basada en la obra teatral homónima de Tennessee Williams.

Chance Wayne (Paul Newman) es un hombre joven que vuelve a su población natal después de una larga ausencia, en la que ha intentado sin éxito convertirse en actor de cine. Durante el camino ha conocido a Alexandra del Lago (Geraldine Page), una actriz ya mayor, con la que inicia una relación, esperando que ella le ayude a conseguir un papel en una película. Se alojan en el hotel de la ciudad y Wayne, mientras sigue con Alexandra, va en busca de su antigua novia Heavenly (Shirley Knight). Heavenly es la hija del principal político de la población, que en su día le obligó a marcharse preocupado por las relaciones entre él y su hija.

La película ganó un Premio por la actuación de Ed Begley, y obtuvo dos nominaciones, a la por Geraldine Page y a la por Shirley Knight.

De este argumento existe una versión televisiva, grabada en 1989 con la participación de Elizabeth Taylor.

</doc>
<doc id="28365" url="https://es.wikipedia.org/wiki?curid=28365" title="Mar Negro">
Mar Negro

El mar Negro se ubica entre el sureste de Europa Oriental y Asia Menor. Está cerrado por Europa, la península de Anatolia y el Cáucaso. El estrecho del Bósforo lo conecta con el mar de Mármara y el estrecho de Dardanelos conecta a este con el mar Egeo, que es una región del mar Mediterráneo. Estas aguas separan Europa del Este de Asia Menor. También está conectado con el mar de Azov por el estrecho de Kerch. Tiene una superficie de 436 400 km (sin incluir el mar de Azov), una profundidad máxima de 2212 m y un volumen de 547 000 km. 

Este mar forma una depresión elíptica con una pendiente de este a oeste, y que yace en los países de Bulgaria, Georgia, Rumania, Rusia, Turquía y Ucrania.

Está delimitado por los montes Pónticos al sur y por las montañas del Cáucaso al este, y cuenta con una amplia meseta al noreste. Su mayor longitud de este a oeste es de 1 175 km. Entre las ciudades importantes de sus costas están: Batumi, Burgas, Constanza, Giresun, Hopa, Estambul, Kerch, Mangalia, Năvodari, Novorossiysk, Odesa, Ordu, Poti, Rize, Sinope, Samsun, Sevastopol, Sochi, Sozopol, Sukhumi, Trabzon, Varna, Yalta y Zonguldak. Es decir, hay una salida neta de agua de 300 km al año a través del Bósforo y del estrecho de Dardanelos hacia el mar Egeo. El agua del Mediterráneo discurre hacia el mar Negro como parte de un camino de ida y vuelta de intercambio hidrológico. El flujo que sale del mar Negro es más frío y menos salino, y el flujo que entra desde el Mediterráneo es más cálido y salino, por lo que este flujo es el resultado de los cambios de densidad causados por la diferente salinidad, lo que da lugar a una gran cantidad de agua anóxida bajo la superficie. El mar Negro también recibe agua del gran sistema fluvial de Eurasia por el norte del mar. Los ríos que le aportan más agua son el Don, el Dniéper y el Danubio.

Los niveles de agua de este mar han variado significativamente a lo largo de la historia. Debido a estas variaciones del nivel del agua en la cuenca, los límites actuales de este mar han sido a veces terrazas geológicas secas. Cuando se dan determinados niveles de agua elevados es posible que el mar se conecte con otras aguas cercanas para estabilizarse. Es a través de una de estas rutas de conexión más activas, el estrecho turco, donde este mar se conecta con los océanos del mundo. Cuando este enlace hidrológico no está presente, el mar Negro se transforma en una cuenca endorreica que opera de forma independiente del sistema global de los océanos, como es el caso del mar Caspio. El estrecho turco conecta el mar Negro con el Egeo, y abarca el Bósforo, el mar de Mármara y el estrecho de Dardanelos.

La Organización Hidrográfica Internacional define los límites del mar Negro de la siguiente forma:

Los nombres modernos de este mar son equivalentes al nombre "mar Negro", incluyendo los que se dan en los países que están bañados por este mar:


Estos nombres no han quedado establecidos del todo hasta el siglo XII, pero hay indicios de que podrían ser bastante más antiguos.

En Grecia, el nombre histórico "mar "Euxine"", que significa otra cosa, sigue siendo usado ampliamente:


En la obra "Geografía" (1.2.10) Estrabón dice que en la antigüedad, el mar Negro era llamado a menudo "El Mar" (ὁ πόντος, "ho pontos"). Durante mucho tiempo, la tradición greco-romana se ha referido al mar Negro como el mar Hospitalario (Εὔξεινος Πόντος, "Eúxeinos Póntos"), lo que reemplazó a un nombre anterior, el de mar Inhóspito (Πόντος Ἄξεινος, "Póntos Áxeinos"), citado por primera vez por Píndaro (c. 475 a. C.). Estrabón (7.3.6) cree que el mar Negro fue llamado "Inhóspito" antes de la colonización griega porque era difícil de navegar y porque sus costas estaban pobladas por tribus salvajes. El nombre fue cambiado por el de "Hospitalario" después de que los milesios griegos colonizaran la costa sur, el Ponto, convirtiéndola en parte de la civilización griega.

También es posible que el epíteto "Áxeinos" venga etimológicamente de la palabra escita "axšaina", que significa "oscuro"; por lo que la designación de mar Negro podría provenir de la antigüedad.

Un mapa de Asia de 1570 titulado "Asiae nova descriptio", de la obra "Theatrum orbis terrarum" de Abraham Ortelius, lo llama "mar Maggior" (mar Mayor). Los escritores de lengua inglesa del siglo XVIII usaron el nombre de "Euxine Sea" para referirse al mar Negro. Edward Gibbon, por ejemplo, llamaba al mar de esta forma en su obra "La historia del declive y la caída del imperio romano". Durante el periodo imperial otomano, el mar Negro fue llamado también "Bahr-e Siyah" o "Karadeniz", que significan "mar Negro" en el idioma turco otomano.

Los orígenes geológicos de la cuenca pueden trazarse desde dos relictos anteriores que se crearon a partir de un arco volcánico albiano que fue subsumido por los océanos Paleo-Tetis y Tetis, pero el momento en que ocurrieron estos eventos sigue siendo objeto de discusión.

Desde sus comienzos, el ambiente de presión de las placas tectónicas provocó el hundimiento de la cuenca, lo que fue intercalado con fases en que las que esta se extendió como resultado de la actividad volcánica a gran escala y las numerosas orogenias, que provocaron el levantamiento de la cordillera del Cáucaso, los Montes Pónticos, los Balcanes y del sur de la península de Crimea.

La colisión, que aún continúa, entre las placas Euroasiática y la Africana y el arrastre hacia el oeste de la placa de Anatolia, que produce las fallas del norte y del este de Anatolia, han dictado el actual régimen tectónico, que cuenta con un hundimiento mayor en la cuenca del mar Negro y con una actividad volcánica significativa en la región de Anatolia. Son estos mecanismos geológicos los que han causado que, a lo largo del tiempo, se produjesen aislamientos periódicos del mar Negro del resto del sistema oceánico global.

La cuenca moderna está dividida en dos subcuencas por una depresión que comienza a extenderse al sur de la península de Crimea. Se trata, en primer lugar, de una gran terraza submarina (equivalente a una plataforma continental) cuya parte más amplia tiene 190 km de largo desde la costa hasta el desnivel. La ladera del desnivel cuenta con una inclinación que de entre 1:10 y 1:1000. El borde sur recorre el norte de Turquía y el borde oriental recorre el litoral de Georgia, aunque en estos lugares se caracteriza por ser una plataforma estrecha que rara vez tiene más de 20 km y cuya ladera tiene una pendiente de 1:40, con grandes cañones submarinos y con extensos canales. En el centro del mar Negro se encuentra la llanura abisal de Euxine, que tiene una profundidad máxima de 2 212 m en un punto al sur de la ciudad de Yalta, en la península de Crimea.

El litoral del mar Negro es referido a menudo como el Litoral Póntico o la Zona Póntica. Al norte está el "cinturón de Chernozem", que va desde el este de Croacia (Eslavonia), a lo largo del Danubio (el norte de Serbia, la llanura búlgara del Danubio y el sur de Rumania, por la llanura de Valaquia) al noreste de Ucrania y a través de la región de Tierras Negras y al sur de de Rusia para adentrarse en Siberia.

El mar Negro es un mar marginal y la mayor masa de agua en una cuenca meromítica del mundo. Las aguas profundas no se mezclan con las aguas superficiales que reciben oxígeno de la atmósfera. Como resultado de esto, aproximadamente el 90% de las aguas más profundas del mar Negro es anóxica. Los patrones de circulación de agua en el mar Negro están controlados sobre todo por la topografía de la cuenca y la entrada por vías fluviales, lo que desemboca en una estructura estratificada y vertical. A causa de esta estratificación extrema, se clasifica como un estuario "de cuña salina".

El mar Negro solo experimenta un intercambio de agua con el Mediterráneo, de modo que todos los flujos de salida y entrada se dan en el estrecho del Bósforo y en el estrecho de Dardanelos. El flujo hacia el interior desde el Mediterráneo tiene una salinidad y una densidad mayor que el flujo saliente, creando la clásica circulación estuarina. Esto significa que el flujo hacia el interior del agua más densa del Mediterráneo ocurre al fondo de la cuenca mientras que el flujo de salida del agua de la superficie del mar Negro hacia el mar de Mármara ocurre cerca de la superficie. El agua de la superficie es producto del saldo de los ríos, por lo que esto convierte al mar Negro en un mar positivo. La red de introducción de agua nueva en el Mediterráneo hace que el volumen de agua que sale del mar Negro sea el doble de la que entra. La evaporación es aproximadamente igual a las precipitaciones, estando en torno a los 300 km3 al año.

Debido a la estrechez y a la falta de profundidad del Bósforo y del estrecho de Dardanelos (sus profundidades respectivas son de solamente 33 y 70 metros), las velocidades de las corrientes de entrada y de salida son altas y con poca verticalidad. Esto provoca una mezcla turbulenta de las dos capas. El agua superficial deja el mar Negro con una salinidad de 17 (escala práctica de salinidad) y toma agua del Mediterráneo con una salinidad de 34. El flujo de entrada del Mediterráneo, que tiene una salinidad de 38,5, experimenta una disminución de su salinidad hasta los 34 aproximadamente.

La principal circulación de la superficie es cíclica y las aguas que rodean el perímetro del mar Negro circulan por el talud de la cuenca en un giro conocido como "corriente del borde". La corriente del borde tiene una velocidad máxima de unos 50-100 cm/s. Además de esto, hay dos recorridos cíclicos más pequeños que están en los sectores este y oeste de la cuenca. Los "giros" del este y del oeste son sistemas bien organizados en invierno pero se disipan en una serie de remolinos interconectados en verano y otoño. La actividad de la mesoescala en el flujo periférico se hace más pronunciada durante estas estaciones más cálidas y está sujeta a la variabilidad interanual.

Fuera de la corriente del borde, hay numerosos remolinos casi permanentes que se forman como resultado de la surgencia que hay en el entorno de la plataforma costera y los mecanismos de los vientos. La duración interanual de estos fenómenos se controla por las variaciones fluviales y atmosféricas de cada estación. Durante la primavera, se forma el remolino de Batumi en la esquina sureste del mar.

Debajo de las aguas superficiales (50-100 metros) existe una haloclina que se detiene en la capa fría intermedia (CFI). Esta capa está compuesta por las frías y saladas aguas superficiales, que son el resultado del frío atmosférico y la disminución de la llegada de agua fluvial durante los meses de invierno. Esta capa está mezclada con el agua invernal de la superficie. La base de la CFI está marcada por una picnoclina principal de unos 100-200 metros y la disparidad de su densidad es el mecanismo principal para el aislamiento del agua de las profundidades.

Debajo de la picnoclina está la masa de agua profunda, donde la salinidad aumenta hasta 22,3 y las temperaturas alcanzan los 8,9 ºC. El ambiente hidroquímico cambia de lo oxigenado a lo anóxico. El débil calor geotérmico y el largo tiempo de permanencia crean una capa convectiva "espesa" al fondo.

La materia orgánica, incluidos artefactos antropogénicos como los cascos de los barcos, están bien preservados. Durante los periodos de producción alta de la superficie, la brotación de algas efímeras forma nutridas capas orgánicas conocidas como sapropel. Los científicos han documentado una brotación de fitoplancton anual que puede apreciarse en las fotografías de la NASA de la región. Como resultado de esta característica, el mar Negro ha granjeado el interés de la arqueología marina y se han descubierto pecios en excelente estado de conservación, como el pecio bizantino Sinop D, localizado en la capa anóxida de la costa de Sinop, en Turquía.

Las recreaciones han mostrado la liberación de nubes de sulfuro de hidrógeno en el caso de impactase un asteroide en el mar Negro, lo que podría suponer una amenaza para la salud o para la vida de las personas que viven en las costas del mar Negro.

Se han registrado casos aislados de fogonazos en el mar Negro durante las tormentas, posiblemente a causa de la ignición luminosa de gas inflamable que se filtra desde las profundidades del lago.

El mar Negro sostiene un activo y dinámico ecosistema marino, dominado por especies adaptadas a las condiciones salobres y de abundancia de nutrientes. Al igual que en todas las redes alimentarias marinas, el mar Negro cuenta con un abanico de grupos tróficos, con algas autotróficas, incluyendo diatomeas y dinoflagelados, que actúan como productores primarios. El sistema de drenado fluvial de Eurasia y Centroeuropa introduce grandes volúmenes de sedimentos y nutrientes disueltos en el mar Negro, pero la distribución de estos nutrientes está controlada por la disminución de la estratificación fisioquímica, que se desarrolla fisiográficamente de forma variante dependiendo de la estación.

Durante el invierno, los fuertes vientos benefician a los ciclos convectivos y al afloramiento de nutrientes, mientras que las temperaturas veraniegas derivan en la creación de una capa de mezcla superficial cálida y con una estratificación marcadamente vertical.
La longitud del día y la intensidad de la insolación también controlan la extensión de la zona fótica.

La productividad bajo la superficie está limitada por la disponibilidad de nutrientes. Las aguas anóxicas del fondo actúan como un sumidero de nitratos, que son reducidos a amoníaco. La zona bentónica también juega un importante papel en el ciclo de los nutrientes. Los organismos químicosintéticos y las vías geoquímicas anóxicas reciclan los nutrientes, que pueden ser elevados a la zona fótica, aumentando su productividad.

Los principales grupos de fitoplancton presentes en el mar Negro son los dinoflagelados, las diatomeas, los cocolitofóridos y las cianobacterias. Generalmente, el ciclo anual del desarrollo del fitoplancton produce la predominancia de dinoflagelados y diatomeas en primavera, seguida por una comunidad mezclada de los distintos tipos desarrollados en menor número que se produce bajo el termoclina estacional de los meses de verano, y seguida por una producción intensa de fitoplancton en la superficie en otoño. Este patrón de productividad aumenta por un florecimiento (o "bloom") de "emiliania huxleyi" durante los meses de primavera y de verano.

La distribución anual de los dinoflagelados está definida por un extenso periodo de florecimiento debajo de las aguas superficiales durante la primavera y el verano. En noviembre, la producción de plancton debajo de la superficie se combina con la producción de la superficie, debido a la mezcla vertical de las masas de agua con nutrientes como los nitritos. La especie de dinoflagelado de mayor afloramiento es la "gymnodinium". Se estima que la diversidad de dinoflagelados en el mar Negro puede ir de las 193 a las 267 especies. Este número de especies es relativamente bajo en comparación con el Mediterráneo, lo que es atribuible a las condiciones de salobridad, la transparencia de las aguas bajas y la presencia de aguas anóxicas al fondo. También es posible que las bajas temperaturas invernales del mar Negro, por debajo de los 4ºC, eviten el establecimiento de especies de termófilos. La relativamente alta cantidad de materia orgánica de las aguas superficiales del mar Negro favorecen el desarrollo especies de heterótrofos (unos organismos que utilizan el carbón orgánico para crecer) o de dinoflagelados mixotróficos (capaces de aprovechar diferentes vías tróficas) en relación con los autótrofos. A pesar de su configuración hidrográfica única, no existen especies de dinoflagelados endémicas del mar Negro.


El mar negro está poblado por muchas especies de diatomeas marinas, que normalmente conviven en colonias de algas unicelulares, no móviles y auto/heterotróficas. El ciclo de la vida de muchas diatomeas puede ser descrito como de "florecimiento y desaparición" y el mar Negro no es una excepción, con florecimientos de diatomeas en la superficie a lo largo del año, sobre todo en marzo.

En términos simples, la fase de crecimiento rápido de la población de diatomeas es causa de la llegada de los sedimentos terrestres de silicio y, cuando se agota el suministro de silicio, las diatomeas comienzan a hundirse y a quedar fuera de la zona fótica, donde se encostran. Además hay otros factores, como la depredación por el zooplancton y la regeneración de la producción de derivados del amonio, que también tienen un papel en el ciclo anual de las diatomeas. Sobre todo, en los florecimientos de "proboscia alata" y "pseudosolenia calcar-avis" durante el verano.


Los cocolitróficos son un tipo de fitoplancton móvil y autotrófico que produce placas de CaCO, conocidas como cocolitos, como parte de su ciclo de vida. En el mar Negro, el periodo principal de crecimiento de los cocolitróficos ocurre cuando ya han crecido la mayor parte de los dinoflagelados. En mayo, los dinoflagelados ya se han desplazado bajo la termoclina estacional, hacia las aguas profundas, donde hay más nutrientes disponibles. Esto permite a los cocolitróficos utilizar los nutrientes de las aguas superiores, y a finales de mayo, con condiciones de temperatura y de luz favorables, crecen a su nivel más grande. La especie que llevan a cabo un mayor afloramiento es la "emiliania huxleyi", que también es responsable de la liberación de sulfuro de dimetilo a la atmósfera. Aunque la diversidad de cocolitróficos es baja en el mar Negro, y aunque en los sedimentos recientes hay sobre todo "E. huxleyi" y "braarudosphaera bigelowii", los sedimentos del Holoceno también han mostrado contenidos de las especies "helicopondosphaera" y "discolithina".


Las cianobacterias son del grupo de de las bacterias picoplanctónicas (plancton que varían en tamaño de 0,2 a 2,0 micras), las cuales obtienen su energía a través de la fotosíntesis, y están presentes en todos los océanos del mundo. Exhiben una gama de morfologías, incluyendo colonias filamentosas y películas biológicas. En el mar Negro hay varias especies presentes, como la "synechococcus", que se pueden encontrar a través de la zona fótica, aunque la concentración disminuye al aumentar la profundidad. Entre los otros factores que influyen en la distribución de los nutrientes están la depredación y la salinidad.


El mar Negro y el mar Caspio son parte del entorno nativo del mejillón cebra. El mejillón ha sido introducido accidentalmente a lo largo de todo el mundo y se ha convertido en una especie invasora allí donde ha sido introducido.


La carpa común tiene su entorno nativo en el mar Negro, el mar Caspio y el mar de Aral. Al igual que el mejillón cebra, es una especie invasora cuando se introduce en otros hábitats.


El gobio redondo es otro pez nativo que también se encuentra en el mar Caspio. Al igual que el mejillón cebra y la carpa común, se convierte en especie invasora cuando se introduce en otros ambientes, como los Grandes Lagos.

Desde la década de 1960, el gran crecimiento de la industria en el entorno del mar Negro y la construcción de un embalse más grande han incrementado significativamente la variación anual de la N:P:Si (relación de Redfield) en la cuenca. En las zonas costeras, los efectos biológicos de estos cambios han incrementado la frecuencia de afloramientos de fitoplancton monoespecífico, dejando una frecuencia de afloramiento de diatomeas que se incrementa con factor de 2,5 y con un afloramiento de especies no-diatomeas que se ha incrementado con un factor de 6. Las especies no diatomeas, como las primnesiofíceas "emiliania huxleyi" (cocolitrofo) y "chromulina", y los euglenofitos "eutreptia lanowii", son capaces de competir con las especies de diatomeas a causa de la disponibilidad limitada del silicio, un constituyente necesario de las frústulas de las diatomeas. Como consecuencia de estos afloramientos, las poblaciones de macrófitos son privadas de luz y la anoxia causa la mortalidad masiva en los animales marinos.

El declive de los macrófitos fue acompañado por la sobrepesca durante la década de 1970, mientras el ctenóforo "mnemiopsis" redujo la biomasa de copépodos y otras especies de zooplacton a finales de la década de 1980. Además, una especie de fuera, la "mnemiopsis leidyi", fue capaz de establecerse por sí misma en la cuenca, pasando de ser unos pocos especímenes a conformar una biomasa de un billón de toneladas. El cambio en las especies del mar Negro también tuvo consecuencias en su hidroquímica, como en el calcio, lo que produciendo la influencia de los cocolitrofos en la salinidad y en el pH, aunque esto todavía no ha sido cuantificado. En las aguas centrales del mar Negro, los niveles de silicio también se redujeron significativamente, debido a una disminución del flujo de silicio asociado con la advección a través de superficies isopícnicas. Este fenómeno demuestra el potencial que tiene una alteración de nutrientes localizada en toda la cuenca del mar Negro.

La reducción de la polución y los esfuerzos reguladores han permitido una recuperación parcial del ecosistema del mar Negro durante la década de 1990, y el ejercicio de monitorización de la Unión Europea, el EROS 21, reveló la disminución de los valores N y P (de la relación N:P:Si) en comparación con el pico medido en 1989. Recientemente, los científicos han notado signos de recuperación ecología, debidos en parte a la construcción de nuevas depuradoras de aguas residuales en Eslovaquia, Hungría, Rumania y Bulgaria, en colaboración con los miembros de la Unión Europea. Las poblaciones de "mnemiopsis leidyi" se han controlado con la llegada de otras especies de fuera que se alimentan de ellas.

Las variaciones climáticas a corto plazo en el mar Negro están influenciadas significativamente por el comportamiento de la oscilación del Atlántico Norte, que es el conjunto de mecanismos climáticos que resultan de la interacción entre el norte del Atlántico y las masas de aire de las latitudes medias. Aunque los mecanismos exactos que causan la oscilación del Atlántico Norte no están claros, se cree que las condiciones climáticas establecidas en Europa Occidental por el calor y las precipitaciones fluyen hacia Centroeuropa y Eurasia, regulando la formación de vientos ciclónicos, que son, en buena medida, responsables de las precipitaciones regionales que van a esa zona e influyen en la temperatura de la superficie del Mediterráneo.

La fuerza relativa de estos sistemas también limita la cantidad de aire frío que llega a las regiones norteñas durante el invierno. Entre otros factores influenciables está la topografía, habiendo depresiones y sistemas de tormentas que llegan desde el Mediterráneo y que se canalizan a través de las tierras bajas del entorno del Bósforo. Los Montes Pónticos y las montañas del Cáucaso actúan como guías de estas ondas meteorológicas, limitando la velocidad y la trayectoria de los ciclones que pasan por la región.

El mar Negro está conectado con el océano mundial por dos estrechos, el de Dardanelos y el del Bósforo. En la edad de hielo el nivel del mar estaba 100 metros por debajo de donde está ahora.

Hay evidencias de que el nivel del agua en el mar Negro ha sido considerablemente más bajo en algún momento posterior al periodo glacial. Por ejemplo, los arqueológos han encontrado conchas de especies de agua dulce y estructuras realizadas por el hombre a 100 metros bajo del mar en la costa de Turquía. Por ello se cree que el mar Negro fue un lago de agua dulce sin salida al mar (al menos en su superficie) durante la última glaciación y algún tiempo después.

A raíz de la última glaciación, el nivel del agua en el Mar Negro y en el mar Egeo se elevaron de forma independiente hasta que fueron lo suficientemente altos para intercambiar sus aguas. El momento exacto de este proceso sigue siendo objeto de debate. Una posibilidad es que el Mar Negro se llenase primero y que el exceso de agua fluyera por encima del Bósforo hacia el Mediterráneo. También hay escenarios catastróficos, como la "teoría del diluvio del mar Negro" de William Ryan, Walter Pitman y Petko Dimitrov.

El diluvio del mar Negro es una hipotética catástrofe natural que elevó el nivel del mar Negro, en torno al 5 600 a.C., debido a que las aguas del Mediterráneo encontraron un abismo en el estrecho del Bósforo. Esta hipótesis se dio a conocer cuando el periódico "The New York Times" la publicó en diciembre de 1996. Poco tiempo antes había sido publicada en una revista científica. Aunque está aceptado que la secuencia de eventos que se narra ocurrió, hay un debate sobre lo repentina que fue, la fecha y la magnitud de los eventos. Esta teoría destaca que la descripción prehistórica de este evento quedaría recogida en los mitos del diluvio universal.

Por el mar Negro pasaban muchas rutas habituales del mundo antiguo: hacia los Balcanes, hacia las estepas del norte de Eurasia, al Cáucaso y a Asia Central, a Asia Menor y a Mesopotamia, y hacia Grecia desde el suroeste.

Los procesadores más antiguos del oro se encontraban en Varna. Además, el mar Negro fue, supuestamente, navegado por los argonautas. La tierra al este del mar Negro, la Cólquida (actualmente Georgia) era el fin oriental del mundo conocido por los griegos. 

Las estepas al norte del mar Negro pueden ser la tierra natal (Urheimat) de los primeros hablantes del lenguaje proto-indo-europeo, del cual descienden las lenguas indo-europeas. Esta teoría ha sido sostenida por los discípulos de Marija Gimbutas. Otros trasladan el lugar natal de esa lengua más al este, al mar Caspio o a Anatolia. Hay muchos enclaves portuarios cuya historia se remonta a los tiempos en los que se hicieron las pirámides de Egipto.

El mar Negro se convirtió en un "lago" de la marina otomana durante tres siglos, desde que Génova perdió la península de Crimea en 1479, tras lo cual los únicos barcos mercantes occidentales que cruzaban sus aguas fueron los de la República de Ragusa, que era rival de la República de Venecia. Esta restricción fue cambiada gradualmente por la marina rusa desde 1783 hasta la relajación del control de exportaciones en 1789 por la Revolución Francesa.

El mar Negro fue un teatro de operaciones navales de la I Guerra Mundial y se dieron en él un par de batallas navales del frente oriental de la II Guerra Mundial.

Las rutas antiguas de la región están siendo estudiadas por científicos. La región fue recorrida por hititas, carios, tracios, griegos, persas, cimerios, escitas, romanos, bizantinos, godos, hunos, ávaros, búlgaros, eslavos, varegos, cruzados, venecianos, genoveses, lituanos, polacos, georgianos, tártaros, turcos y rusos.

Tal vez las áreas más prometedoras para la arqueología submarina son los asentamientos prehistóricos sumergidos de la plataforma continental y los pecios antiguos de la zona anóxica, que se espera que estén bien preservados debido a la ausencia de oxígeno. Esta concentración de poderes históricos, combinada con la capacidad de preservación de las aguas anóxicas del Mar Negro, ha aumentado el interés de los arqueólogos marinos que han empezado a descubrir un gran número de barcos antiguos y restos orgánicos en buen estado de conservación.

De acuerdo con la OTAN, el mar Negro es un pasillo estratégico con redes de contrabando para mover bienes legales e ilegales, incluyendo drogas, materiales radioactivos y productos falsificados que pueden ser utilizados para financiar el terrorismo.

De acuerdo con un estudio de 2013 de la Federación Internacional de Trabajadores del Transporte hay al menos 30 puertos mercantes operativos en el mar Negro (incluyendo, al menos, 12 en Ucrania).

De acuerdo con un estudio de 2013 de la Federación Internacional de Trabajadores del Transporte, hay en torno a 2 400 buques comerciales operando en el mar Negro.

Anchoas: la flota comercial turca pesca 300 000 toneladas al año de media. La pesca se lleva a cabo sobre todo en invierno, aunque la mayor parte del stock se pesca entre noviembre y diciembre.

Desde la década de 1980, la Unión Soviética empezó a perforar en alta mar para extraer petróleo en la parte occidental de este mar (cerca de la costa de Ucrania). La Ucrania independiente continuó e intensificó estos esfuerzos dentro de su "zona económica exclusiva", invitando a las mayores petroleras internacionales a que explorasen. El descubrimiento de nuevos y masivos pozos de petróleo en el área estimuló un flujo de inversiones extranjeras. También provocó a corto plazo una disputa territorial pacífica con Rumania que se resolvió en 2011, cuando un tribunal internacional redefinió la zona económica exclusiva entre los dos países.

En los años posteriores al fin de la Guerra Fría, la popularidad del mar Negro como destino turístico fue en aumento. El turismo de "resorts" en el mar Negro se ha convertido en una de las industrias en auge de la región.

La convención de Montreux de 1936 proveyó de paso libre a los barcos civiles en aguas internacionales del mar Negro y del Mediterráneo. No obstante, un solo país (Turquía) tiene el control completo sobre el estrecho que conecta ambos mares. Las enmiendas de 1982 a la convención de Montreux permiten a Turquía cerrar el estrecho a su discreción tanto en tiempo de guerra como en tiempo de paz.

La convención de Montreux de 1936 regula el paso de buques entre los mares Mediterráneo y Negro y la presencia de buques militares pertenecientes a los estados que no tienen litoral en las aguas del mar Negro.



</doc>
<doc id="28366" url="https://es.wikipedia.org/wiki?curid=28366" title="Días de vino y rosas">
Días de vino y rosas

Días de vino y rosas ("Days of Wine and Roses") es una película estadounidense de 1962 dirigida por Blake Edwards y con Jack Lemmon, Lee Remick, Charles Bickford y Jack Klugman como actores principales. Fue ganadora del 1962 a la mejor música y la mejor canción: Henry Mancini y Johnny Mercer, por la canción "Days of Wine and Roses".

Asimismo, ganó el premio Golden Laurel 1963, en las categorías de drama, mejor actriz dramática (Lee Remick) y mejor actor dramático (Jack Lemmon), el premio Concha de Plata de la edición de 1963 del Festival Internacional de Cine de San Sebastián al mejor director (Blake Edwards), al mejor actor (Jack Lemmon), y a la mejor actriz (Lee Remick), el premio Sant Jordi de 1964 a la mejor interpretación en película extranjera (Jack Lemmon) y el premio Fotogramas de Plata de 1964 al mejor intérprete de cine extranjero (Jack Lemmon). 

La película es una adaptación de un dramático televisivo homónimo de mucho éxito que se había emitido en 1958 como episodio de la serie de antología "Playhouse 90", de la CBS, dirigido por John Frankenheimer y con Cliff Robertson, Piper Laurie y Charles Bickford como actores principales. 

Con guion del mismo autor, J.P. Miller, se esperaba que la adaptación al cine fuera dirigida por Frankenheimer; sin embargo, el productor cambió el reparto y reemplazó al director.

Joe Clay (Jack Lemmon) conoce a Kirsten Arnesen (Lee Remick), una brillante secretaria de la que se enamora, y se acaban casando. Tienen un bebé, y todo parece ir bien. Pero Joe bebe cada vez más y, lo que es peor, arrastra también a su mujer, que es abstemia. Los dos se convierten en alcohólicos, y en sus ratos sobrios piensan en cómo dejar la bebida.

La película es un estudio de lo destructivas que pueden ser las adicciones en la vida moderna.

Este film muestra una particularidad con respecto al alcoholismo: la tendencia latente a adquirirlo. Joe, una vez en recuperación, discute con su “padrino” (compañero de la comunidad AA que lo acompaña emocionalmente en su ardua lucha para mantenerse sobrio), acerca de la culpa que siente por haber inducido a Kirsten al alcoholismo; se siente totalmente responsable. En esa discusión surgen aspectos reveladores de las tendencias que su esposa ya tendría para desarrollar esta enfermedad, sin saberlo.

Es una película muy realista, en dos aspectos: demuestra claramente que las adicciones son enfermedades perversas porque, a diferencia de todas las otras, dependen exclusivamente de la voluntad propia para acceder a la recuperación; y que algunas personas no poseen, ni son capaces de crear para sí mismas, las herramientas necesarias para detenerlas. Recomendable para quienes son, o han sido afectados, por alcohólicos u otros adictos en su entorno más cercano.


En el reparto aparece Jennifer Edwards, hija del director:.


El título de la canción, que a su vez da título al dramático televisivo y a la película, está tomado del texto del poema de Ernest Dowson "Vitae Summa Brevis":

Letra de la canción, obra de Johnny Mercer:

Trompa: Vince De Rosa.







</doc>
<doc id="28367" url="https://es.wikipedia.org/wiki?curid=28367" title="Regiones de Italia">
Regiones de Italia

Italia está subdividida en 20 regiones que se agrupan en cinco grandes áreas geopolíticas usadas tradicionalmente. Cada región está dirigida por el Presidente y la Junta regional que ejercen el poder ejecutivo, y el Consejo regional que ejerce el poder legislativo.

En la siguiente tabla se muestra las 20 regiones que componen el territorio de Italia, agrupadas por área geopolítica, indicando la capital, sigla y el número que lo identifica en el mapa ubicado a la derecha.

La Región en la legislación italiana es un ente territorial autónomo, dotado de órganos y funciones propias.

La Constitución de la República Italiana reconoce dos tipos de regiones, las regidas por el "estatuto regional ordinario" y las regidas por un "estatuto especial". El estatuto regional es el principal documento normativo de las regiones que define el funcionamiento y las organizaciones, siempre en "armonía" con la constitución.

15 de las 20 regiones italianas están dotadas de "estatuto ordinario". El estatuto es aprobado y modificado por el "Consejo regional" por mayoría absoluta, y luego debe ser aprobado en un referéndum.

La "autonomía financiera" prevista en la constitución aún no se ha hecho efectiva, pero las regiones disponen del IRAP ("Impuesto regional a la actividad productiva") y una parte del IVA.

Los organismos de las regiones entraron en funciones en 1970.

5 regiones están dotadas de un "estatuto especial", aprobado por el parlamento Italiano como está previsto en la constitución.

El "estatuto especial" garantiza una autonomía más amplia, sobre todo en el ámbito financiero, que a las "regiones ordinarias". Por ejemplo, la región Trentino-Alto Adigio (900.000 habitantes) dispone de un presupuesto correspondiente a la región de Véneto, con 4,5 millones de habitantes. También por esta razón varios municipios colindantes han solicitado pasar a ser parte de éstas (más ricas) regiones autónomas, con el permiso de la constitución. Por otra parte las regiones disponen de notables poderes legislativos y administrativos en materia de educación y salud.

4 regiones autónomas fueron instituidas por la Asamblea constituyente en 1948: Sicilia y Cerdeña debido a sus fuertes movimientos autonomistas y separatistas, el Valle de Aosta para proteger a la minoría francófona y Trentino-Alto Adigio para la protección de los germanófonos como se determinó en el Acuerdo de París. En 1963 fue constituida la región con estatuto especial Friuli-Venecia Julia, y en 1972 entró en vigor el nuevo estatuto especial para Trentino-Alto Adigio.

La región de Trentino-Alto Adigio está constituida por las Provincias autónomas de Trento y Bolzano. Tales provincias están dotadas de los poderes (también legislativos) correspondientes a los de las regiones. También se las denomina "provincias con estatuto especial".

Los órganos de las regiones indicados en la constitución son:

Estos órganos, de dictamen constitucional, no pueden ser alterados por estatutos o leyes regionales.

Las regiones son representadas por el "Presidente de la Región", o mejor Presidente de la Junta regional, que es electo directamente por el pueblo, a menos que el "estatuto regional" no considere la elección de parte del consejo. Si el Presidente pierde la confianza, muere, renuncia o es impedido permanentemente, el Consejo se disuelve y se realiza nuevas elecciones.

Las regiones están dotadas de un Consejo regional, electo por los ciudadanos mayores de edad residentes en la región. En Sicilia, región autónoma, se llama "Asamblea regional" y sus miembros, quienes llevan el título de "honorables" , son llamados "diputados" y no consejeros. El Consejo ejerce el poder legislativo para las materias que la constitución y los estatutos especiales para las regiones autónomas le asignan autoridad exclusiva o concurrente.

Las funciones administrativas corresponden a la Junta Regional, compuesta por asesores y encabezada por el Presidente de la Región. En Sicilia la junta es llamada "gobierno regional".

Las autonomías reconocidas a las regiones y garantizadas a nivel constitucional que se diferencian de las del estado y de las entidades territoriales menores son cinco:

Solamente las regiones con "estatuto ordinario" están dotadas de ésta autonomía, ya que los "estatutos especiales" de las "Regiones Autónomas" tienen rango de leyes constitucionales. Cada región ordinaria adopta con ley regional un estatuto que, determina la forma de gobierno y los principios fundamentales de organización y funcionamiento.

Como consecuencia de la reforma constitucional del 2001, el poder legislativo general corresponde al Estado y a las Regiones; la competencia es atribuida por materia.

Las competencias a legislar pueden ser:

Las regiones tienen poder reglamentario sobre las materias de competencia exclusiva y sobre aquellas que el Estado y las Regiones tienen competencia de tipo "concurrente". Tienen también poder reglamentario en materia de competencia exclusiva del Estado si le han sido delegadas.

El poder reglamentario de las Regiones es ejercido por las Juntas regionales, a menos que el estatuto regional se la asigne al Consejo regional, cosa que ocurre en Cerdeña y el Valle de Aosta.

La autonomía administrativa de las regiones, como todas las administraciones públicas debe adherirse a los principios de subsidiariedad, diferenciación y probidad.

Las regiones, vía ley regional, pueden delegar las funciones administrativas de las cuales son titulares en los municipios, las provincias o las "Urbes metropolitanas".

Las regiones tienen autonomía financiera de ingresos y gastos. Definiendo y aplicando tributos e ingresos propios. Deciden también como repartir lo recaudado en impuestos relacionados a su territorio, tienen su propio patrimonio y puede endeudarse solo para realizar inversiones.

La constitución no les permite establecer tasas al comercio con las otras regiones.

A excepción del Valle de Aosta, las regiones se dividen en provincias (actualmente 106), y el nivel inferior de las subdivisión administrativa es el municipio .

Las "Urbes metropolitanas", superprovincias dotadas de competencia comunal, pese a estar contempladas en la constitución, hasta ahora no han sido instituidas.

La siguiente tabla contiene los datos de población, superficie y densidad poblacional, capital, número de municipios y provincias que pertenecen a cada una de las 20 regiones italianas. Las regiones se encuentran ordenadas de acuerdo a su población.

En la siguiente tabla se indica la renta "per cápita" en las distintas macrorregiones y regiones de Italia según datos del Eurostat. En el caso especial de Trentino-Alto Adigio se considera independientemente cada una de las provincias autónomas como "regiones".




</doc>
<doc id="28368" url="https://es.wikipedia.org/wiki?curid=28368" title="A Shock to the System">
A Shock to the System

A Shock to the System es una película basada en la novela del mismo título de Simon Brett. Una comedia ácida, interpretada por Michael Caine en el papel del directivo cínico.

Graham Marshall (Michael Caine) es un ejecutivo que cuenta firmemente con un ascenso. Sin embargo, en el último momento le dan el puesto a otro directivo. A partir de entonces Marshall comienza a ver su vida de otra forma y se propone eliminar todos los obstáculos existentes. La secretaria, Stella (Elizabeth McGovern), descubre su juego, pero como por arte de magia Marshall la tiene totalmente controlada.


</doc>
<doc id="28369" url="https://es.wikipedia.org/wiki?curid=28369" title="Presidente de la República Italiana">
Presidente de la República Italiana

El presidente de la República Italiana (italiano: "presidente della Repubblica Italiana") es el jefe de Estado de Italia y el cargo tiene el objeto de representar la unidad nacional, más allá de tendencias políticas. Es elegido por el Parlamento en sesión común de sus miembros por un período de siete años.
El actual presidente de la República es Sergio Mattarella que asume el cargo el 31 de enero de 2015, elegido al término de la cuarta votación, cuando bastaba sólo la mayoría simple, obtuvo 665 votos, superando ampliamente los 505 necesarios, según el conteo oficial.

El presidente de la República es el jefe del Estado y representa la unidad nacional.

Otras funciones consisten en:


En caso de que el presidente de la República no pueda cumplir sus funciones, éstas serán ejercidas por el presidente del Senado.

El artículo 84 de la constitución establece que Asimismo, "El cargo de Presidente de la República será incompatible con cualquier otro cargo", debiendo cesar en cualquier otro cargo que ostentara en caso de ser elegido presidente.

Si bien la constitución italiana no establece límites a la reelección, hasta la reelección de Giorgio Napolitano en 2013 ningún presidente hasta la fecha había optado a un segundo mandato.

El presidente de la República es elegido por el Parlamento en una sesión conjunta de la Cámara de Diputados y el Senado. Además, las 20 regiones de Italia aportan 58 representantes, en calidad de electores especiales, de modo que cada región aporta tres electores, salvo el Valle de Aosta, que aporta uno.

De acuerdo con la constitución, la elección se desarrolla mediante la emisión del voto secreto de los 630 diputados, 315 senadores y 58 representantes regionales. En la votación se requieren dos tercios a favor de un candidato para su elección; no obstante, si tras tres rondas no se ha elegido un presidente, bastará con alcanzar mayoría absoluta. El nuevo presidente electo toma posesión de su cargo tras jurarlo y pronunciar un discurso.

La elección se celebra en el Palazzo Montecitorio, sede de la Cámara de Diputados, y es presidida por el presidente de dicha cámara.

Denominados "presidente della Repubblica", en italiano. Magistratura vigente desde 1948.




</doc>
<doc id="28371" url="https://es.wikipedia.org/wiki?curid=28371" title="Esplendor en la hierba">
Esplendor en la hierba

Esplendor en la hierba es una película dirigida en 1961 por Elia Kazan, ganadora de un Óscar y una nominación. 

La película cuenta la historia de amor entre Bud Stamper (Warren Beatty) y Dennie Loomis (Natalie Wood). En dicha historia subyace el conflicto sobre el mantenimiento de relaciones sexuales entre ambos pese a ver lejos la posibilidad de matrimonio. El padre de Bud se opone al matrimonio porque quiere que su hijo estudie en la Universidad de Yale, cuando lo que éste sinceramente ansía es tener un rancho y trabajar el campo. Finalmente Bud deja a Dennie, y ésta entra en una depresión, teniendo que acudir a una clínica psiquiátrica para recuperarse.

El título de la película procede de un poema del inglés William Wordsworth (1770-1850), "Ode on Intimations of Immortality from Recollections of Early Childhood":
"Nada nos devolverá los días
"del esplendor sobre la hierba," 
"pero nos recordaremos
"y fortaleza hallaremos" 
"en lo que de ello nos queda"""."

Una película sobre las incomprensiones entre padres e hijos, y sobre los tabúes existentes en cuanto al sexo, todavía antes de la revolución cultural de los años 60. Ganó un Oscar al mejor guion original (para William Inge, que interpreta al párroco de la película), y obtuvo una nominación a la mejor actriz principal para Natalie Wood, que realizó la mejor interpretación de su carrera. Warren Beatty empezó en el cine con esta película. En muchas listas, especialmente francesas, Esplendor en la Hierba figura como uno de los mejores films en la historia del cine.


</doc>
<doc id="28372" url="https://es.wikipedia.org/wiki?curid=28372" title="Alien">
Alien

El anglicismo alien, término no aceptado por la Real Academia de la Lengua, se puede referir a:


También puede hacer referencia cinematográfica:


</doc>
<doc id="28374" url="https://es.wikipedia.org/wiki?curid=28374" title="Carlo Azeglio Ciampi">
Carlo Azeglio Ciampi

Carlo Azeglio Ciampi (Livorno, 9 de diciembre de 1920 - Roma, 16 de septiembre de 2016) fue un político y banquero italiano, décimo presidente de la República Italiana desde 1999 hasta 2006.

Ha sido gobernador del Banco de Italia desde 1979 hasta 1993, presidente del Consejo de Ministros de Italia (1993-1994), y ministro de Hacienda y de Planificación Económica en distintos mandatos. En 1999 se convirtió en el primer jefe del estado italiano independiente de cualquier formación parlamentaria, así como en el segundo exgobernador del Banco de Italia en llegar al puesto tras Luigi Einaudi en 1948.

Aunque de joven fue militante del Partido de Acción, Ciampi no estuvo adscrito a ningún partido político. Como presidente de la República ha encargado formar gobierno a tres primeros ministros: Massimo D'Alema (1999), Giuliano Amato (2000-2001) y Silvio Berlusconi (2001-2006). Además ha nombrado cinco senadores vitalicios: Rita Levi-Montalcini (2001), Emilio Colombo (2003), Mario Luzi (2004), Giorgio Napolitano y Sergio Pininfarina (2005).

Carlo Azeglio Ciampi nació el 9 de septiembre de 1920 en Livorno. Se licenció en Literatura en 1941 de la Scuola Normale de Pisa, una de las universidades más prestigiosas del país, graduándose luego en Derecho por la Universidad de Pisa en 1946. Ese mismo año comenzó a trabajar en el Banco de Italia. 

En 1960 fue ascendido para trabajar en la administración central del Banco y en 1973 se convirtió en secretario general, vicedirector general en 1976 y director general en 1978. En octubre de 1979 finalmente llegó a los cargos de Gobernador del Banco de Italia y presidente del Ufficio Italiano Cambi, los cuales ocupó hasta 1993.

Desde abril de 1993 hasta mayo de 1994 fue primer ministro, ejerciendo un gobierno "técnico" durante un período de transición. Poco después ocupó el cargo de ministro del Tesoro, de 1996 hasta mayo de 1999, durante los gobiernos de Romano Prodi y Massimo D'Alema. En este tiempo se llevó a cabo la integración de Italia en la zona del euro. El 13 de mayo de 1999 fue nombrado presidente de la República Italiana por el Parlamento. 

El 5 de mayo de 2005 recibió el Premio Carlomagno en la ciudad de Aquisgrán. La École Normale Supérieure de París lo nombró doctor "honoris causa" el 15 de junio del mismo año. Durante su mandato, Ciampi mantuvo, mediante viajes al exterior de Italia buenas relaciones con distintos países del globo, mientras que en el frente interno se transformaba en un punto de referencia tanto para líderes opositores como para líderes gubernamentales. 

Al finalizar su mandato, en mayo de 2006, Ciampi renunció a una eventual reelección por siete años más, aduciendo su avanzada edad (86 años) y optando por la senaturía vitalicia dispuesta para los expresidentes.

Dejó el cargo el 15 de mayo de 2006, siendo sucedido por Giorgio Napolitano.

El 16 de septiembre de 2016 falleció en una clínica de Roma a la edad de 95 años.



</doc>
<doc id="28375" url="https://es.wikipedia.org/wiki?curid=28375" title="Bandera de Italia">
Bandera de Italia

La bandera de República Italiana es una tricolor formada por tres franjas verticales e iguales con los colores verde, blanco (en el centro) y rojo.

Tiene su origen en un estandarte con esos mismos colores entregado por Napoleón en noviembre de 1796 a un cuerpo de voluntarios de la Legión Lombarda que se incorporaron al ejército francés.

El 7 de enero de 1797, el estandarte tricolor fue adoptado como emblema de la República Cispadana reunida en Reggio Emilia. Comprendía un territorio de unos 40.000 km² atravesados por el río Po y con Milán como sede del gobierno. Contaba con un ejército integrado por tropas francesas.

La República Cisalpina creada el 9 de julio de 1797 por Napoleón Bonaparte utilizó la disposición actual de las franjas tricolores.

Existe una teoría sobre el origen de los tres colores que los vincula con la insignia de una sociedad secreta que ejercía una influencia notable en la política de aquellos tiempos. Los representantes de Reggio Emilia propusieron adoptar la tricolor como bandera del nuevo Estado libre que se había creado en aquellos momentos. En la asamblea de Reggio se propuso unir Milán a las cuatro ciudades de Reggio Emilia que se encontraban bajo dominio napoleónico, pero como no fue posible, se decidió por lo menos establecer una misma bandera. Este fue el origen de la bandera italiana. Con la caída de Napoleón en 1814 fue abolida, pero volvió a ser utilizada durante las cinco jornadas de Milán.

Poco tiempo después fue izada sobre los campanarios de Milán y en el punto más alto de la ciudad. El 24 de marzo de 1848, los austríacos tuvieron que abandonar Milán, que había estado bajo dominio suyo. El rey de Piamonte-Cerdeña, Carlos Alberto de Saboya, repartió la bandera tricolor entre las diferentes unidades del ejército piamontés que entraban en Lombardía en apoyo de los insurgentes y dispuso que en el centro de la misma se incorporase el escudo de la Casa de Saboya. Desde este episodio, la bandera tricolor ha sido el símbolo de la nación italiana. 

En 1849, se constituyó en Roma la República Romana, y Giuseppe Mazzini adoptó como bandera la tricolor, escribiendo sobre la franja blanca las iniciales de la República Romana. Pero oficialmente, con la proclamación del reino de Italia, el 17 de marzo de 1861 se adoptó la versión creada por Carlos Alberto de Saboya, con el escudo saboyano rematado por una corona real en la bandera estatal. Este modelo permaneció vigente ochenta años, hasta la caída de la monarquía el 2 de junio de 1946, y desde aquel momento la bandera nacional está conformada sin ninguna insignia o escudo.

El poeta del siglo XIX, Francesco Dall'Ongaro, expuso la simbología de los colores de la bandera empleando una descripción del territorio italiano. ""Blanco como los Alpes, rojo como los volcanes y verde como las llanuras de Lombardía"".

La ley, según el artículo 12 de la Constitución Italiana y posteriormente a que Italia pertenezca a la Unión Europea, establece las disposiciones generales que rigen el uso y la exhibición de la bandera de la República Italiana y de la bandera de la Unión Europea (en su territorio).

No hay convenios internacionales en que se enarbole el pabellón, pero el protocolo adoptado por un gran número de países tienen similitudes como para sugerir líneas de la práctica comúnmente aceptada. En general, dos áreas de exposición se identifican: eventos nacionales e internacionales. En ambos casos, se sigue generalmente la práctica de que las banderas nacionales aparecen en un grupo que debe ser de igual tamaño y cada una izada en el mástil de la bandera propia, de la misma altura, o en cuerdas separadas, si está fija en el mástil. La bandera ondea desde el amanecer hasta el anochecer, excepto en caso de mal tiempo; la exposición en la noche está permitida siempre y cuando sea adecuadamente iluminada. La bandera se iza y arría vivamente y con solemnidad, siempre ha der ser tratada con dignidad y no se debe permitir que toque el suelo o el agua.

Cuando aparece junto a otras banderas, la bandera nacional toma la posición de honor. Las otras banderas nacionales deben estar dispuestas en orden alfabético. Cuando dos (o más de tres) banderas aparezcan juntas, la bandera nacional debe ser colocada a la derecha (izquierda del observador). Si se despliegan tres banderas en fila, la bandera nacional ocupa la posición central. La bandera europea es trasladada diariamente desde los edificios del gobierno. En presencia de un visitante extranjero que pertenezca a un Estado miembro, ésta tiene prioridad sobre la bandera italiana. Como señal de luto, las banderas ondearán a media asta. Pueden atarse dos cintas negras. Tradicionalmente, la bandera puede ser decorada con una franja dorada que rodea el perímetro.



</doc>
<doc id="28378" url="https://es.wikipedia.org/wiki?curid=28378" title="Lira italiana">
Lira italiana

La lira italiana (plural italiano "lire", símbolo monetario: ₤) fue la moneda oficial de Italia desde 1861 hasta 2002. Entre 1999 y 2002 coexistió con el euro, siendo reemplazada definitivamente por éste.
La tasa de cambio fija era de 1,936.27 liras por cada euro. 

La lira fue también la moneda oficial del Reino Napoleónico de Italia, entre 1807 y 1814.

El término proviene del valor del peso físico de una libra de plata de alta pureza, guardando una relación directa con la libra esterlina; en algunos países, como Chipre y Malta, las palabras liras y libra fueron utilizados como sinónimos, antes de que el euro fuera aprobado en 2008 en ambos países.

La lira data desde antes de Carlomagno. Al igual que la libra esterlina, representaba una libra peso de plata, y era equivalente a 20 "soldi" o 240 "denari". Antes de la unificación, muchos de los estados italianos utilizaban la lira como su moneda oficial.

En 1807, el Reino Napoleónico de Italia, que ocupaba el noreste del actual territorio italiano, presentó la lira como su moneda. Igual al franco francés, estaba dividido en 20 soldi o 100 centesimi. Esta lira circuló hasta 1814 cuando el reino se desmembró.

Tras la creación del Reino de Italia bajo el gobierno de Víctor Manuel II en 1861, una lira se estableció, en 4,5 g de plata o 290,322 miligramos de oro. Esto fue una continuación directa de la liras utilizadas en el Reino de Cerdeña. Otras monedas que sustituyeron a la lira italiana fueron el florín de Lombardía, el piastra de Dos Sicilias, el fiorino de Toscana, el escudo pontificio y las liras de Parma. En 1865, Italia formó parte de la Unión Monetaria Latina, estableciéndose una paridad entre su valor y el del franco francés, el franco suizo y el franco belga.

La Primera Guerra Mundial rompió la Unión Monetaria Latina, traduciéndose en un aumento de precios generalizado en Italia. La Inflación fue parcialmente frenada por el entonces dictador Benito Mussolini, quien el 18 de agosto de 1926, estableció que el tipo de cambio entre liras y libra sería de £1 = 90 liras —la denominada "Cuota 90"-, aunque la tasa de cambio real había sido cercana a los 140-150 liras por libra. En 1927 un dólar estadounidense equivalía a 19 liras. Este tipo de cambio perduró hasta 1934, con una tasa de cambio separada para turistas, de US$1 = 24.89 liras. En 1939, el cambio oficial fue de 19,8 liras por dólar.

Después de la invasión de los aliados a Italia en junio de 1943, el tipo de cambio se fijó en US$1 = 120 liras (1 libra británica = 480 liras), reducido a 100 liras al mes siguiente. En las zonas ocupadas por Alemania, el tipo de cambio se fijó en 1 marco = 10 liras.
Después de la guerra, el valor de la lira fluctuó, hasta fijar una paridad de US$1 = 575 liras dentro del sistema Bretton Woods en noviembre de 1947. El 21 de septiembre de 1949 fue devaluada a 625 liras por dólar. Esta tasa se mantuvo hasta el final del sistema de Bretton Woods en la década de 1970. En los años siguientes ocurrieron varios episodios inflacionarios, hasta que la lira fue sustituido por el euro.

La lira fue la unidad monetaria oficial de Italia hasta el 1 de enero de 1999, cuando fue reemplazada por el euro. La lira moneda dejó de ser legal el 28 de febrero de 2002. El tipo de conversión fue de 1936,27 liras por euro. Todos los billetes en uso inmediatamente antes de la introducción del euro, fueron intercambiables por euros en el Banco de Italia hasta el 29 de febrero de 2012, momento a partir del cual esta moneda quedó sin ningún valor.

Aunque los billetes italianos llegaron a ser difíciles de utilizar debido a la gran cantidad de ceros, los esfuerzos para una redenominación no llegaron a fructificar por razones políticas hasta la introducción del euro, que ha tenido el efecto de eliminar demasiados ceros.

Durante el Reino Napoleónico de Italia se acuñaron monedas entre 1807 y 1813 en las denominaciones de 1 y 3 centésimos, y un sueldo de cobre; 10 centésimos con un 20% de plata, 5, 10 y 15 sueldos; y 1, 2 y 5 liras con un 90% de plata, y 20 y 40 liras con un 90% de oro. Todas, excepto la moneda de 10 centésimos llevaban el retrato de Napoleón; las denominaciones inferiores a 1 lira tenían en su diseño una corona radiada, y las denominaciones mayores un escudo con los distintos territorios que formaban el Reino.

En 1861, las monedas se acuñaron en las cecas de Florencia, Milán, Nápoles y Turín en denominaciones de 1, 2, 5, 10 y 50 centésimos, y 1, 2, 5, 10 y 20 liras. Las monedas de valor más bajo se acuñaban en cobre, y las demás en metales preciosos. En 1863 las monedas inferiores a 5 liras redujeron su cantidad de plata de un 90% a un 83.50%, además de introducirse las monedas de 20 centésimos. En la década de los 70 se unificaron todas las cecas en Roma.

Aparte de la introducción en 1894 de los 20 centésimos de cuproníquel y las de 25 centésimos de níquel en 1902, el cono monetario se mantuvo prácticamente igual hasta la I Guerra Mundial

En 1919, con una devaluación de la lira reducida a un quinto de su fuerza en 1914, la producción de monedas de 20 centésimos se detuvo y se acuñaron nuevas monedas de menor tamaño en denominaciones de 5, 10 y 50 centésimos, seguidas de monedas de 1 y 2 liras en 1922 y 1923, respectivamente. En 1926 se acuñaron monedas de plata de 5 y 10 liras con el mismo tamaño que las previas de 1 y 2 liras. En 1927 se introdujeron monedas de 20 liras de plata.

En 1936 se acuñó una última serie de monedas de plata, mientras que en 1939 el alto coste del cobre hizo que se empezaran a acuñar monedas de latón y níquel. En 1943 se detuvo toda la acuñación de monedas.

En 1946 la acuñación de monedas se restableció parcialmente, aunque solamente en 1948, con una devaluación de formula_1 respecto a 1939, el número de monedas acuñadas excedió del millón de piezas. Para empezar, se acuñaron cuatro denominaciones en aluminio de 1, 2, 5 y 10 liras. Estas monedas circularon junto con las acuñaciones especiales del bando aliado (AM-Lira) y algunas de las devaluadas monedas del periodo monárquico. En 1951 el gobierno decidió reemplazar todas las monedas y billetes con nuevos tamaños reducidos en denominaciones de 1, 2, 5 y 10 liras de aluminio (aunque la moneda de 2 liras no se comenzó a acuñar entre 1951-1952) y en 1954-1955, se introdujeron monedas de acmonital en denominaciones de 50 y 100 liras, seguidas por las de 20 liras de bronce-aluminio en 1957 y las de 500 liras de plata en 1958. Debido al alto precio de la plata solo se acuñó un pequeño número de monedas para coleccionistas después de 1967.

En 1977 se introdujeron denominaciones de 200 liras de bronce-aluminio, seguidas en 1982 por las monedas de 500 liras bimetálicas. Este tipo de moneda fue el primero en acuñarse, utilizando un sistema patentado por la "Zecca dello Stato". También fueron las primeras monedas en introducir su denominación en alfabeto braille.

La producción de monedas de 1 y 2 liras cesó en 1959, pero volvieron a acuñarse desde 1982 a 2001 para los coleccionistas. La producción de monedas de 5 liras se redujo a finales de la década de los 70 y dejó de circular en 1998. De manera análoga, en 1991 la producción de monedas de 10 y 20 liras se limitó, también para el coleccionismo. Los tamaños de las monedas de 50 y 100 liras se redujeron en 1990, pero en 1993 aumentaron de nuevo y cambió su diseño. En 1997 se acuñó una moneda bimetálica de 1,000 liras que dejó de producirse en 1998.

Antes de la adopción del euro en Italia, las denominaciones que circulaban eran las siguientes:

En 1882 el gobierno comenzó a emitir pequeños valores en papel con el nombre de "Biglietto dello Stato". Estos se imprimieron en denominaciones de 5 y 10 liras, y ocasionalmente los de 25 liras desde 1895. También se emitieron pagarés con el nombre de "Buono di Cassa" entre 1893 y 1922 en denominaciones de 1 y 2 liras. La producción de los "Biglietti dello Stato" cesó en 1925, pero en 1935 se reanudó con denominaciones de 1, 2, 5 liras, y los de 10 liras en 1939.

La Banca d'Italia empezó a imprimir billetes en 1896 en denominaciones de 50, 100, 500 y 1,000 liras. Entre 1918 y 1919 también se emitieron billetes de 25 liras, sin embargo no se introdujeron cambios hasta el final de la II Guerra Mundial.

En 1943, el bando aliado introdujo billetes de 1, 2, 5, 10, 50, 100, 500 y 1,000 liras, seguidos en 1944 de una serie de "Biglietti dello Stato" de 1, 2, 5 y 10 liras, que circularon hasta ser reemplazados por las monedas de la última década de los años 40. En 1945, la Banca introdujo billetes de 5.000 y 10.000 liras.

En 1951 el gobierno volvió a emitir billetes con el nombre oficial del país: "Repubblica Italiana". Las denominaciones eran de 50 y 100 liras que sustituían a las emisiones de los "Biglietti dello Stato", y que circularon hasta que se acuñaron monedas de esas mismas denominaciones en los años 50. En 1966 se introdujeron billetes de 500 liras que sustituyeron a los antiguos "Biglietti" y que fueron reemplazados por las monedas bimetálicas en 1982.

En 1967 se imprimieron billetes de 50,000 y 100,000 liras, seguidos de las denominaciones de 20.000 liras en 1975 y 500,000 liras en 1997.

Antes de la entrada del euro, las denominaciones que circulaban eran las siguientes:

La lira vaticana fue la unidad monetaria oficial de la Ciudad del Vaticano. Tenía su paridad fijada a la lira italiana de acuerdo a los tratados económicos firmados con Italia. Dentro de la Ciudad del Vaticano también circulaba la lira italiana. Se acuñaron monedas en la Zecca dello Stato, con un valor más numismático que de uso común entre la población. Tras la adopción del euro por parte de Italia, y con los acuerdos económicos firmados por ambos estados, y con la aprobación de la Comisión Europea, la Ciudad del Vaticano también emite sus propios euros.

La lira de San Marino fue la unidad monetaria oficial de la República de San Marino. Al igual que la lira vaticana, tenía su paridad fijada a la lira italiana de acuerdo a los tratados económicos firmado con Italia. Asimismo, la lira italiana era de curso legal dentro de sus fronteras. Se acuñaron monedas en la Zecca dello Stato, con los mismos fines de coleccionismo que la lira vaticana, y con la adopción del euro por parte de Italia, al igual que la Ciudad del Vaticano, emite sus propias monedas de euro.




</doc>
<doc id="28379" url="https://es.wikipedia.org/wiki?curid=28379" title="Parasitología">
Parasitología

La parasitología expedición de la biología que estudia el fenómeno del parasitismo. Por un lado, estudia a los organismos vivos parásitos, y la relación de ellos con sus hospedadores y el medio ambiente. Convencionalmente, se ocupa solo de los parásitos eucariotas como son los protozoos, helmintos (trematodos, cestodos, nematodos) y artrópodos; el resto de los organismos parásitos (virus, procariotas y hongos) tradicionalmente se consideran una materia propia de la microbiología. Por otro lado, estudia las parasitosis o enfermedades causadas en el hombre, animales y plantas por los organismos parásitos.

Por definición, un parásito es un organismo que vive a expensas de un huésped, si bien el ámbito de la Parasitología se circunscribe a aquellos organismos eucariotas, tanto unicelulares como pluricelularess, que han elegido este modo de vida. Aun así, quizás pueda sorprender el hecho de que existen muchos más organismos parásitos que organismos de vida libre, aun excluyendo a los virus y muchos grupos de bacterias y hongos que también son parásitos estrictos en cuanto a su modo de vida. Por tanto, hay que concluir que el parasitismo es un modo de vida exitoso y como tal ha surgido en todos los grupos evolutivos eucariotas: protistas, animales y plantas.

La Parasitología nació como una disciplina dentro de la Zoología, y en sus orígenes fue esencialmente descriptiva. En consecuencia, los primeros parásitos descritos fueron metazoos, y con el empleo posterior del microscopio se amplió al campo de la Protozoología. La expansión colonial europea y la constatación de los graves problemas para la salud humana y de los animales, que son causados por parásitos sobre todo en las zonas tropicales, conllevaron un aumento en el interés médico por la parasitología (ver abajo). Como consecuencia, la parasitología comenzó a estudiarse desde una perspectiva etiológica-patológica, en la que la relación parásito-hospedador desempeña un papel clave. Los llamativos mecanismos de adaptación presentes en estos sorprendentes organismos pronto estimularon estudios más profundos. Fruto del interés por estos organismos, cabe mencionar que muchos avances en la ciencia básica se han producido a partir de las investigaciones con parásitos. 

La importancia de los parásitos desde una perspectiva sanitaria es indiscutible. Estimaciones de la Organización Mundial de la Salud indican que hay más de 260 millones de personas que padecen malaria, 200 millones sufren esquistosomiasis, 500 millones de afectados por amebiasis, 700 millones con ascariasis, y más de 40 millones con patologías producidas por tripanosomátidos (la enfermedad del sueño, la enfermedad de Chagas o las leishmaniasis).
Nemotodos= su morfología es cilíndrica 
Platelmintos= su morfología es plana

Aristóteles (384 – 322 a. C.) describió y clasificó un grupo de gusanos (helmintos) intestinales. Otros como Plinio el Viejo y Galeno estudiaron parásitos humanos y animales.

En la edad Media el sabio Avicena elaboró en Persia un tratado completo sobre helmintos y nematodos y métodos para combatirlos y curarlos.

Francesco Redi (1686) y luego Lázaro Spallanzani. (1729-1799) usaron parásitos como evidencia para refutar la teoría de la generación espontánea. Desde entonces cada parásito tiene su anécdota; a finales del siglo XIX, por ejemplo, se descubrió la malaria y su vector.

Muchos parasitólogos iniciaron observaciones al microscopio para descubrir distintos protozoarios, pero realmente el primer protozoario de tipo parásito que se observó fue por los doctores suizos Malmsten (1857) y Stein (1862) descubriendo "Balantidium coli", que es uno de los protozoarios más grandes y que habita en los intestinos del cerdo.

Para un estudio más específico, la parasitología se divide en tres ramas:

La parasitología es una rama de la biología, y concretamente de la ecología, aunque por sus importantes repercusiones en la salud humana y animal, gran parte de la investigación de esta ciencia se centra en sus implicaciones en medicina, veterinaria y farmacia, ya que los parásitos causan enfermedades al hombre, animales y plantas de gran interés sanitario o económico y uno de los objetivos clave es el aprender diagnosticarlas (por ejemplo, a través de un análisis coprológico o inmunológico), curarlas y erradicarlas. Dentro de esta rama de la parasitología sanitaria médica y veterinaria es también el estudio de la epidemiología de estas enfermedades parasitarias, dentro de lo que se puede calificar como parasitología ambiental, ya que estudia los factores que explican la distribución y frecuencia de los parásitos.

La principal importancia de esta rama radica en que muchas de las "enfermedades tropicales" que nosotros conocemos son de origen parasitario y se deben en gran medida a falta de higiene y condiciones ambientales propicias en los países subdesarrollados (aprox. 75 % de la población mundial )

El efecto de una infección parasitaria se relaciona estrechamente con factores geográficos, sociales, y económicos, de modo que otro de los objetivos de la parasitología recae en el campo de la epidemiología al estudiar la incidencia, morbilidad y mortalidad así como los métodos de control y lucha en contra de los parásitos y sus vectores (organismos parásitos más o menos inocuos "per se", pero que pueden ser transmisores de otros organismos causantes de enfermedades). El objetivo sería el de controlar las poblaciones de estos vectores o proporcionar directrices que permitan solucionar problemas sanitarios y epidemiológicos. Al tratarse de organismos a un tiempo muy simplificados y con interesantes mecanismos para burlar las defensas de su hospedador a menudo los parásitos han recibido atención por parte de la genética o la biología molecular. Asimismo han proporcionado datos para interpretar la evolución de las especies.

En general, la historia de la parasitología esta fuertemente ligada con la Historia de la medicina Tropical , que no es otra cosa que el estudio de las enfermedades típicas de los países subdesarrollados que se encuentran generalmente en los trópicos.
La historia de la medicina tropical inicia cuando las grandes potencias europeas empezaron en el s.XIX. la colonización de zonas tropicales en Asia y África principalmente con esto muchos europeos observaron que sus colonos al regresar de las colonias a Europa presentaban enfermedades muy extrañas (en su mayoría parasitarias).
Naturalmente Inglaterra , Francia y Alemania empezaron a crear institutos y centros hospitalarios donde atender estas raras enfermedades , un caso típico es el "London School of Tropical Medicine" fundado en 1899 , en uno de los barrios céntricos de Londres.

Actualmente la OMS clasifica en 3 grupos las 11 principales enfermedades tropicales:

Aunque no lo parezca, estas enfermedades siguen siendo muy comunes en países subdesarrollados, sobre todo en niños y en ancianos.




</doc>
<doc id="28382" url="https://es.wikipedia.org/wiki?curid=28382" title="Mama Quilla">
Mama Quilla

En la mitología incaica, Mama Quilla, o Mamaquilla, era la hermana y la esposa del dios sol Inti. Esta diosa, representada por la Luna, acompañaba a Inti. También conocida como "Quilla, Illa", o "Mama Illa". Representa a la Luna, y acompañaba a Inti en igualdad de rango en la corte celestial. Madre del firmamento, marca las épocas de las cosechas, asumía la protección de todo el universo femenino.

A la diosa Mama Quilla estaba adscrito el fervor religioso de las mujeres, las que formaban el núcleo de sus fieles seguidores, ya que nadie mejor que ella podía comprender sus deseos y temores, y darles el amparo buscado. La plata se vinculó con la Luna, y en sus templos había objetos de ese metal.

En el décimo mes del calendario inca "Coya Raymi" (Setiembre), se llevaba a cabo una celebración en su honor, un fiesta especial para las mujeres.



</doc>
<doc id="28383" url="https://es.wikipedia.org/wiki?curid=28383" title="My Fair Lady">
My Fair Lady

My Fair Lady (o Mi bella dama en algunos países de Hispanoamérica) es un musical basado en la obra de teatro "Pigmalión" de George Bernard Shaw, con música de Frederick Loewe y libreto y letras de Alan Jay Lerner. Su trama central se desarrolla en torno a Eliza Doolittle, una florista callejera de los bajos fondos londinenses cuyo vulgar lenguaje despierta el interés de un profesor de fonética llamado Henry Higgins. Fascinado por la joven y su marcado acento "cockney", Higgins apuesta con su amigo el Coronel Pickering a que es capaz de enseñar a Eliza a hablar correctamente y hacerla pasar por una dama de la alta sociedad.
La producción original de Broadway se estrenó en 1956 y fue un rotundo éxito, convirtiéndose en su día en el musical de mayor permanencia en cartel de la historia. Desde entonces se ha representado en numerosas ocasiones a lo largo de todo el mundo y ha sido calificado como ""el musical perfecto"". En 1964 fue llevado a la gran pantalla bajo la dirección de George Cukor.

En una noche lluviosa en el Londres eduardiano, el público asistente a la ópera de Covent Garden espera bajo los arcos del edificio para tomar un taxi. Eliza Doolittle, una florista callejera de los bajos fondos, tropieza con un joven de la alta sociedad llamado Freddy Eynsford-Hill. Ella se enfada y le reprocha que haya tirado sus violetas al barro, pero enseguida se anima al conseguir vender un ramillete a un caballero de mayor edad. De pronto, Eliza advierte que otro hombre está apuntando todo lo que ella dice en un cuadernillo y le increpa. El hombre le explica que es un estudioso de la fonética y presume de que puede identificar la procedencia de cualquier persona solo por su acento. También se lamenta de la horrible pronunciación de Eliza, preguntándose por qué muchos ingleses no son capaces de hablar el idioma con propiedad, cuando esto es lo que en realidad provoca la diferencia de clases, más que la apariencia o el dinero ("Why Can't the English?"). En ese punto, declara que en seis meses él podría convertir a Eliza en una dama respetable enseñándole a hablar correctamente. Entonces, el caballero al que la florista había vendido un ramillete de violetas al principio se presenta como el Coronel Pickering, un lingüista que ha estudiado los dialectos de la India. El fonetista resulta ser el Profesor Henry Higgins y puesto que ambos siempre habían querido conocerse, Higgins invita a Pickering a alojarse en su casa durante su estancia en Londres. Antes de marcharse lanza algo de calderilla a la cesta de Eliza, dejando a ésta y a sus amigos imaginando cómo sería vivir una vida mejor y llena de comodidades ("Wouldn't It Be Loverly?").

A la mañana siguiente, el padre de Eliza, Alfred P. Doolittle, acompañado de sus amigos de borrachera Harry y Jamie, todos ellos basureros, llega a Covent Garden y le pide a su hija que comparta las ganancias de la noche anterior para poder seguir bebiendo ("With a Little Bit of Luck"). Más tarde, Pickering y Higgins están en casa discutiendo acerca de las vocales cuando la Sra. Pearce, el ama de llaves, anuncia que una joven con un acento horrible ha venido a ver al profesor. La joven no es otra que Eliza, que quiere tomar clases de dicción para conseguir trabajo en una floristería y así dejar las calles. Pickering está convencido de que Higgins no será capaz de enseñar a Eliza a hablar correctamente y se ofrece a pagar sus lecciones si el profesor logra transformarla en una dama en el plazo de seis meses. Higgins acepta el desafío y se fija como prueba de fuego el baile anual de la embajada, donde Eliza será presentada en sociedad. La joven se traslada a casa de Higgins y comienza su preparación para corregir su acento, sus modales y su forma de vestir. En esta tesitura, Higgins se ve a sí mismo como un hombre paciente y de buen corazón que no puede convivir con mujeres ("I'm an Ordinary Man"), cuando en realidad es un hombre egocéntrico y misógino.
Doolittle se entera de que Eliza se ha mudado a casa de Higgins y decide sacar provecho de la situación ("With a Little Bit of Luck (Reprise)"). Al día siguiente se presenta en casa del profesor y le acusa de estar comprometiendo la virtud de su hija. Higgins queda fascinado por el don natural del hombre para el lenguaje y su desvergonzada falta de moralidad. Entre los dos acuerdan que Eliza siga con sus lecciones en casa de Higgins a cambio de que Doolittle reciba cinco libras esterlinas para sus juergas. Higgins aprovecha la ocasión para burlarse de un millonario estadounidense que le escribió buscando un experto en valores morales y le recomienda a Doolittle.

Eliza soporta duras clases de dicción repitiendo sin cesar frases como ""In Hertford, Hereford and Hampshire, hurricanes hardly ever happen"" (para aprender cómo se aspira la "h") o ""The rain in Spain stays mainly in the plain"" (para practicar la pronunciación de la "a" larga). Frustrada, sueña con diferentes formas de matar a Higgins, como ahogarlo o llevarlo al pelotón de fusilamiento ("Just You Wait"). Los sirvientes de la casa se quejan del trabajo tan repetitivo de Higgins ("Poor Professor Higgins") y justo cuando éste está a punto de dejarlo por imposible, de pronto Eliza recita ""The rain in Spain stays mainly in the plain"" en perfecto inglés de la reina. Higgins, Eliza y Pickering celebran su triunfo bailando en el estudio del profesor ("The Rain in Spain") y a partir de ese momento la pronunciación de la joven se vuelve impecable. La Sra. Pearce intenta que Eliza se vaya a dormir, pero ella está demasiado excitada por las emociones vividas como para irse a la cama ("I Could Have Danced All Night").
Para su primera aparición en público, Higgins lleva a Eliza al palco de su madre en el hipódromo de Ascot ("Ascot Gavotte"). La Sra. Higgins acepta a regañadientes ayudar a Eliza a mantener una conversación siguiendo la recomendación de su hijo de limitarse a dos únicos temas, el tiempo y la salud. En un principio, Eliza causa una buena impresión con sus educadas maneras, pero después deja a todo el mundo en shock cuando se levanta del palco para animar al caballo por el que habían apostado de la forma más vulgar. Aun así, Eliza cautiva a Freddy, el joven con el que chocó al principio de la historia, quien había acudido al palco de la Sra. Higgins acompañado de su madre. Esa misma noche, Freddy va a buscar a Eliza a la casa de Higgins, pero ella no quiere verlo. El muchacho promete que la esperará en la calle el tiempo que sea necesario ("On the Street Where You Live").

La prueba final consiste en hacer pasar a Eliza por una dama de la nobleza en el baile anual de la embajada, y tras semanas de preparación, ella está lista para el gran acontecimiento. Todos los asistentes a la velada la admiran y la reina de Transilvania la invita a bailar con su hijo, el príncipe ("Embassy Waltz"). Después Eliza baila con Higgins, mientras Zoltan Karpathy, un fonetista húngaro antiguo alumno y rival del profesor, recibe el encargo por parte del anfitrión de averiguar la procedencia de la joven a través de su habla. A pesar de las advertencias de Pickering y su madre, Higgins deja a Karpathy bailar con Eliza.

Eliza sale airosa de la prueba y consigue engañar incluso a Karpathy, haciéndole creer que es una princesa húngara. Tras el baile, Higgins presume de su triunfo ante Pickering y sus sirvientes, y se muestra complacido porque el experimento ha llegado a su fin ("You Did It"). Eliza se sienta utilizada e ignorada por Higgins, y cuando éste le pregunta por sus zapatillas, ella descarga toda su rabia dejándolo desconcertado por su aparente ingratitud. Desconsolada, la joven decide dejar la casa de Higgins ("Just You Wait (Reprise)"). En la calle, Eliza se encuentra con Freddy, quien aún sigue esperándola ("On the Street Where You Live (Reprise)"), y el muchacho empieza a declararle su amor. Sin embargo, ella le corta alegando que ya ha escuchado suficientes palabras y que, si de verdad la ama, debe mostrárselo ("Show Me").

Eliza regresa a Covent Garden acompañada de Freddy, donde sus amigos no la reconocen por su nuevo aspecto refinado ("Wouldn't It Be Loverly? (Reprise)"). Por casualidad también se encuentra con su padre, quien va vestido elegantemente. Él le explica que ha recibido una herencia sorpresa del millonario estadounidense al que Higgins le recomendó y, puesto que ahora es un ciudadano respetable de clase media, debe casarse con la "madrastra" de Eliza, la mujer con la que lleva viviendo muchos años. Eliza ve que ya no pertenece al ambiente humilde de Covent Garden y se marcha con Freddy, mientras Doolittle y sus amigos se corren una última juerga antes de la boda ("Get Me to the Church on Time").

Higgins se despierta a la mañana siguiente para encontrarse con que, sin Eliza, tiene té para desayunar en lugar de café y ni siquiera puede localizar sus propios archivos. El profesor se pregunta por qué ella se marcharía tras el triunfo en el baile y concluye que los hombres, especialmente él, son superiores a las mujeres ("A Hymn to Him"). Pickering, molesto con su anfitrión, decide marcharse para alojarse en casa de sus amigos del Ministerio del Interior. Higgins acude a casa de su madre en busca de consejo y allí encuentra a Eliza tomando el té con ella. La Sra. Higgins los deja solos y Eliza le recrimina que él siempre la ha visto como una florista callejera. También le dice que si aprendió a comportarse como una dama fue porque Pickering la trató como tal. Higgins asegura que él siempre la ha tratado igual que Pickering y le pide que vuelva, pero Eliza le acusa de usarla solo para hacer sus recados y anuncia que se casará con Freddy porque él la ama de verdad. La joven declara que no necesita a Higgins y se lamenta de lo tonta que ha sido por pensar que sí ("Without You"). El profesor se queda deslumbrado con la actitud e independencia de Eliza, pero ella le dice que no la verá más.

Mientras Higgins camina de regreso casa, se da cuenta de lo que siente por Eliza ("I've Grown Accustomed to Her Face"), aunque no es capaz de reunir el valor para confesarle su amor y se regodea pensando que, si se casa con Freddy y después vuelve a él, no la aceptará. Pero al mismo tiempo le resulta difícil imaginarse solo de nuevo. En casa vuelve a repasar las grabaciones que hizo la primera vez que Eliza vino a pedirle que le diese lecciones de dicción y escucha sus dura palabras: ""¡Es tan deliciosamente vulgar! ¡Tan gloriosamente sucia!"". De repente, el fonógrafo se apaga y una voz real con acento "cockney" dice: ""Oiga, que antes de venir me he lavado la cara y las manos"". Higgins se gira y ve a Eliza en el umbral dudando si volver o no con él. La obra acaba en un punto ambiguo de posible reconciliación entre maestro y alumna, con Higgins preguntando ""Eliza, ¿dónde están mis zapatillas?"".

A mediados de los años 30, el productor cinematográfico Gabriel Pascal adquirió los derechos para llevar a la gran pantalla varias piezas de George Bernard Shaw, entre ellas "Pigmalión". Sin embargo, Shaw no dio permiso para que "Pigmalión" fuese convertida en un musical, ya que venía de una mala experiencia con "The Chocolate Soldier", una opereta vienesa basada en su obra "Arms and the Man". Tras la muerte de Shaw en 1950, Pascal pidió a Alan Jay Lerner que escribiera el libreto y éste accedió, encargando a su socio Frederick Loewe que se ocupase de la música. Pronto se dieron cuenta de que la obra violaba varias reglas clave para la composición de un musical: el argumento principal no era una historia de amor, tampoco existía una subtrama romántica y no había lugar para un cuerpo de baile. Muchos profesionales del sector, incluyendo a Oscar Hammerstein, quien junto a Richard Rodgers ya había intentado sin éxito adaptar "Pigmalión" en forma de musical, advirtieron a Lerner que convertir esa obra en un espectáculo de Broadway era inviable, por lo que el proyecto fue abandonado por dos años. 
Durante ese tiempo, los dos colaboradores se separaron y Gabriel Pascal falleció. Lerner estaba intentado musicalizar la tira cómica "Li'l Abner" cuando leyó la esquela de Pascal y de pronto se encontró a sí mismo pensando de nuevo en "Pigmalión". Al reunirse con Loewe, todo encajó de repente. Los obstáculos insuperables de dos años atrás desaparecieron y se dieron cuenta de que en realidad la pieza necesitaba muy pocos cambios más allá de, según palabras del propio Lerner, ""añadir la acción que tiene lugar entre los actos de la obra"". Emocionados comenzaron a escribir el espectáculo a pesar de no contar aún con los derechos y de que la productora Metro-Goldwyn-Mayer también andaba detrás de ellos. Los ejecutivos de la MGM se pusieron en contacto con Lerner y le desaconsejaron desafiar al estudio, pero Loewe dijo ""Escribiremos el espectáculo sin los derechos, y cuando llegue el momento de decidir a quién se los conceden, estaremos tan avanzados respecto al resto que se verán forzados a dárnoslos a nosotros"". Durante cinco meses, Lerner y Loewe se dedicaron a componer el musical, contratar al equipo de producción y empezar a pensar en el reparto. Finalmente, el Chase Manhattan Bank, gestor de los bienes de Pascal, les otorgó la licencia tal y como había adelantado Loewe.
Después de barajar nombres como "Come to the Ball" o "Lady Liza", Lerner optó por el título "My Fair Lady", en referencia al último verso de la canción infantil "London Bridge Is Falling Down" y a uno de los títulos provisionales que Shaw había manejado para "Pigmalión", "Fair Eliza". Pero una vez fijado el nombre, Lerner recordó que "Tell Me More", un musical de George Gershwin de 1925, ya se había llamado así antes de su legada a Broadway y además incluía una canción con ese mismo título. Para evitar problemas futuros, Lerner realizó una llamada de cortesía a Ira Gershwin y le puso al corriente de la reutilización del nombre.
Noël Coward fue el primer actor al que se ofreció el rol de Henry Higgins, pero éste lo rechazó y sugirió a los productores que hicieran una prueba a Rex Harrison. Tras muchas deliberaciones, Harrison aceptó el papel. Para el personaje de Eliza Doolittle en un principio se consideró a la actriz Mary Martin, pero ella también declinó la propuesta. Finalmente la elegida fue una joven Julie Andrews, descubierta en el musical "The Boy Friend", con el que había debutado en Broadway. Moss Hart aceptó dirigir la obra tras escuchar solo dos canciones, y los orquestadores Robert Russell Bennett y Philip J. Lang fueron contratados para realizar los arreglos de la partitura. Una vez reunido el equipo artístico enseguida comenzaron los ensayos.
El libreto de Lerner incorporó varias escenas que Shaw había escrito específicamente para la versión cinematográfica de "Pigmalión" de 1938, incluyendo el baile en la embajada y la secuencia final, que reemplazó al desenlace de la obra original. Los pasajes dedicados a las lecciones de Eliza fueron ampliados combinando diálogos de Lerner y Shaw. La ilustración del programa original fue realizada por el caricaturista Al Hirschfeld y representaba a Shaw como un titiritero moviendo los hilos del personaje de Henry Higgins, quien a su vez controlaba los de Eliza Doolittle.

Antes de su llegada a Broadway, "My Fair Lady" se representó a modo de prueba en el Shubert Theatre de New Haven, Connecticut, entre el 4 y el 11 de febrero de 1956, y en el Erlanger Theatre de Filadelfia, Pensilvania, entre el 13 de febrero y el 10 de marzo de ese mismo año. La noche del estreno en New Haven, Rex Harrison, quien no estaba acostumbrado a cantar con una orquesta en directo, anunció que ""de ninguna manera actuaría esa noche con 32 entrometidos en el foso"" y se enclaustró en su camerino, permaneciendo encerrado hasta apenas una hora antes de que se levantara el telón. Para entonces, la compañía entera se había marchado, pero rápidamente fueron convocados de nuevo y la velada terminó siendo un éxito.
La "première" oficial en Broadway tuvo lugar el 15 de marzo de 1956 en el Mark Hellinger Theatre, donde el espectáculo se mantuvo en cartel hasta el 24 de febrero de 1962, para a continuación ser transferido al Broadhurst Theatre entre el 28 de febrero y el 14 de abril de 1962, y al Broadway Theatre entre el 18 de abril y el 29 de septiembre de 1962. En total realizó 2.717 funciones, estableciendo un nuevo récord para la época.
Julie Andrews como Eliza Doolittle y Rex Harrison como Henry Higgins encabezaron el elenco original, que además contó con Stanley Holloway como Alfred P. Doolitlle, Robert Coote como Coronel Pickering, Cathleen Nesbitt como Sra. Higgins, John Michael King como Freddy Eynsford-Hill y Philippa Bevans como Sra. Pearce. A lo largo de su andadura de seis años y medio, el montaje fue renovándose con diferentes protagonistas, incluyendo a Pamela Charles, Lola Fisher, Sally Ann Howes, Margot Moser y Rosemary Rainer como Eliza Doolitlle, y a Michael Allinson, Bramwell Fletcher, Tom Hellmore y Edward Mulhare como Henry Higgins.
El equipo creativo estuvo formado por Moss Hart en la dirección, Hanya Holm en la coreografía, Oliver Smith en el diseño de escenografía, Cecil Beaton en el diseño de vestuario, Abe Feder en el diseño de iluminación, Robert Russell Bennett y Philip J. Lang en los arreglos musicales, y Franz Allers en la dirección musical. El vestuario de Cecil Beaton, así como algunos de sus patrones, están expuestos en la Costume World Broadway Collection de Pompano Beach, Florida.

Un álbum grabado por el reparto original fue editado por Columbia Masterworks y se convirtió en el disco más vendido en Estados Unidos en 1956. En la edición de los Tony de 1957, "My Fair Lady" fue premiado en las categorías de mejor musical, mejor actor principal (Rex Harrison), mejor dirección, mejor diseño de escenografía, mejor diseño de vestuario y mejor dirección musical.
El primer revival de Broadway se estrenó el 25 de marzo de 1976 en el St. James Theatre, protagonizado por Christine Andreas como Eliza Doolitlle, Ian Richardson como Henry Higgins, George Rose como Alfred P. Doolitlle, Robert Coote repitiendo como Coronel Pickering, Brenda Forbes como Sra. Higgins, Jerry Lanning como Freddy Eynsford-Hill y Sylvia O'Brien como Sra. Pearce. La dirección corrió a cargo de Jerry Adler, mientras que las coreografías fueron creadas por Crandall Diehl a partir de las originales de Hanya Holm. Tanto Ian Richardson como George Rose fueron nominados al Tony al mejor actor, alzándose este último con el premio.

El 5 de diciembre de 1976, el espectáculo se despidió del St. James Theatre y fue trasladado al Lunt-Fontanne Theatre entre el 9 de diciembre de 1976 y el 20 de febrero de 1977, donde se despidió definitivamente tras haber alcanzado las 377 representaciones.
Entre el 18 de agosto y 29 de noviembre de 1981, una nueva puesta en escena dirigida por Patrick Garland y coreografiada por Crandall Diehl pudo verse en el Uris Theatre de Broadway, donde realizó 120 representaciones después de haber recorrido algunas ciudades estadounidenses durante casi un año. Cheryl Kennedy, quien había dado vida a Eliza Doolittle en la gira, tuvo que abandonar la compañía tras la primera función previa en el Uris Theatre debido a un caso grave de laringitis, siendo reemplazada por su suplente Nancy Ringham. En el elenco también estuvieron Rex Harrison y Cathleen Nesbitt, de la producción original, repitiendo sus papeles de Henry Higgins y Sra. Higgins respectivamente, acompañados de Milo O'Shea como Alfred P. Doolitlle, Jack Gwillim como Coronel Pickering, Nicholas Wyman como Freddy Eynsford-Hill y Marian Baer como Sra. Pearce.
"My Fair Lady" regresó a la cartelera neoyorquina con un montaje que se instaló en el Virginia Theatre de Broadway entre el 9 de diciembre de 1993 y el 1 de mayo de 1994, protagonizado por Melissa Errico como Eliza Doolittle, Richard Chamberlain como Henry Higgins, Julian Holloway como Alfred P. Doolitlle (siguiendo los pasos de su padre Stanley Holloway), Paxton Whitehead como Coronel Pickering, Dolores Sutton como Sra. Higgins, Robert Sella como Freddy Eynsford-Hill y Glynis Bell como Sra. Pearce. Howard Davies fue el director de esta versión mucho más modesta, que realizó 165 funciones en el Virginia Theatre tras haber estado de gira por Estados Unidos durante ocho meses. El resto del equipo creativo lo completaron Donald Saddler en la coreografía, Ralph Koltai en el diseño de escenografía, Patricia Zipprodt en el diseño de vestuario, Natasha Katz en el diseño de iluminación, Peter J. Fitzgerald en el diseño de sonido y Jack Lee en la dirección musical.

Veinticinco años después de la última producción de Broadway, el Lincoln Center acogerá una nueva puesta en escena que se estrenará el 19 de abril de 2018 en el Vivian Beaumont Theater, con un reparto aún por confirmar. Dirigido por Bartlett Sher, este revival contará con diseño de escenografía de Michael Yeargan, diseño de vestuario de Catherine Zuber y diseño de iluminación de Donald Holder.

El éxito obtenido en Nueva York posibilitó el salto al West End londinense, donde el espectáculo debutó el 30 de abril de 1958 en el Theatre Royal, Drury Lane, con varios de los protagonistas originales de Broadway, incluyendo a Julie Andrews como Eliza Doolitlle, Rex Harrison como Henry Higgins, Stanley Holloway como Alfred P. Doolitlle y Robert Coote como Coronel Pickering. El resto del elenco lo completaron Zena Dare como Sra. Higgins (siendo ésta su última aparición sobre los escenarios), Leonard Weir como Freddy Eynsford-Hill y Betty Woolfe como Sra. Pearce. El musical se mantuvo en cartel hasta el 19 de octubre de 1963, realizando un total de 2.281 representaciones.

La segunda vez que "My Fair Lady" pudo verse en Londres fue en el Adelphi Theatre entre el 25 de octubre de 1979 y el 31 de octubre de 1981, con un montaje producido por Cameron Mackintosh que previamente había girado por Reino Unido. La dirección recayó en el propio Alan Jay Lerner (en sustitución de Robin Midgley, quien había sido el director durante el "tour" nacional), mientras que Gillian Lynne se hizo cargo de la coreografía. El reparto estuvo liderado por Liz Robertson como Eliza Doolitlle, Tony Britton como Henry Higgins, Peter Bayliss como Alfred P. Doolitlle, Richard Caldicot como Coronel Pickering, Anna Neagle como Sra. Higgins, Peter Land como Freddy Eynsford-Hill y Betty Paul como Sra. Pearce. Tanto Liz Robertson como Tony Britton fueron nominados a un Olivier por sus interpretaciones, pero ninguno logró hacerse con el premio.

Cameron Mackintosh volvió a producir el musical en 2001, con una nueva puesta en escena dirigida por Trevor Nunn y coreografiada por Matthew Bourne, que se representó primero en el Royal National Theatre entre el 15 de marzo y el 30 de junio, para después ser transferida al Theatre Royal, Drury Lane a partir del 21 de julio de ese mismo año. Martine McCutcheon como Eliza Doolitlle, Jonathan Pryce como Henry Higgins, Dennis Waterman como Alfred P. Doolitlle, Nicholas Le Prevost como Coronel Pickering, Caroline Blakiston como Sra. Higgins, Mark Umbers como Freddy Eynsford-Hill y Patsy Rowlands como Sra. Pearce fueron los protagonistas de este montaje, que en la edición de los Olivier de 2002 se alzó con los premios al mejor musical, mejor coreografía y mejor actriz (Martine McCutcheon).

Tras numerosos problemas de salud durante los cuales fue cubierta por su suplente Alexandra Jay, Martine McCutcheon tuvo que abandonar el espectáculo en diciembre de 2001, siendo reemplazada por Joanna Riding como Eliza Doolitlle. El segundo cambio de elenco importante se produjo en abril de 2002, cuando Alex Jennings (Henry Higgins), Malcolm Sinclair (Coronel Pickering), Peter Prentice (Freddy Eynsford-Hill), Dilys Laye (Sra. Pearce) y Katie Knight Adams (alternante de Eliza Doolitlle) se unieron a la compañía. En febrero de 2003, "My Fair Lady" consiguió otros dos premios Olivier en las categorías de mejor actor (Alex Jennings) y mejor actriz (Joanna Riding).

El reparto fue renovado una vez más en marzo de 2003, con la incorporación de Laura Michelle Kelly como Eliza Doolitlle, Anthony Andrews como Henry Higgins, Russ Abbot como Alfred P. Doolitlle, Stephen Moore como Coronel Pickering, Hannah Gordon como Sra. Higgins, Michael Xavier como Freddy Eynsford-Hill y Patsy Rowlands retornando como Sra. Pearce, quienes permanecieron en la producción hasta su cierre definitivo el 30 de agosto de 2003.

El primer país en acoger una versión en idioma español fue México, donde "My Fair Lady" debutó el 19 de enero de 1959 en el Teatro María Teresa Montoya de Monterrey, bajo el título "Mi bella dama". Robert W. Lerner, hermano de Alan Jay Lerner que por aquel entonces residía en territorio mexicano, fue el impulsor de este montaje que posteriormente también pudo verse en el Teatro Degollado de Guadalajara y, ya en Ciudad de México, en el Palacio de Bellas Artes y en el Teatro Esperanza Iris (actual Teatro de la Ciudad). Producido, dirigido y protagonizado por el actor Manolo Fábregas, el espectáculo fue todo un éxito de crítica y público, pero aun así no logró recuperar la enorme inversión que supuso. Además de Fábregas como Henry Higgins, otros intérpretes que formaron parte de la compañía fueron Cristina Rojas, una joven completamente desconocida que llegó a las audiciones solicitando un puesto en el coro y acabó obteniendo el papel de Eliza Doolitlle, Mario Alberto Rodríguez como Alfred P. Doolitlle, Miguel Suárez como Coronel Pickering, Salvador Quiroz como Freddy Eynsford-Hill y un joven Plácido Domingo como uno de los amigos de Alfred P. Doolitlle. Mario Ruiz Armengol estuvo al frente de la orquesta como director musical, mientras que Berta Maldonado realizó la traducción del libreto y Luis de Llano Palmer se encargó de la adaptación de las canciones.

Al igual que en Broadway y Londres, se editó un álbum interpretado por el elenco original, siendo la primera vez que un musical mexicano era grabado en disco.
El 15 de mayo de 1977, Manolo Fábregas reestrenó "Mi bella dama" en el recién construido Teatro San Rafael de Ciudad de México, un nuevo teatro de su propiedad especialmente diseñado para albergar grandes producciones, que se inauguró precisamente con esta obra. Fábregas volvió a dirigir el espectáculo y también repitió su papel de Henry Higgins, acompañado en esta ocasión de Manoella Torres como Eliza Doolitlle, Moisés Suárez como Coronel Pickering, Marilú Elizaga como Sra. Higgins y Xavier del Valle como Freddy Eynsford-Hill.

Después de más de dos décadas de ausencia, "Mi bella dama" regresó a la cartelera mexicana con una nueva puesta en escena que tuvo su "première" oficial el 6 de noviembre de 2002 en el Teatro de los Insurgentes de Ciudad de México Producido por Biosphera Entertainment y protagonizado por Olivia Bucio como Eliza Doolitlle (posteriormente reemplazada por Yolanda Orrantia), Alejandro Tommasi como Henry Higgins (posteriormente reemplazado por Manuel Landeta), Arturo García Tenorio como Alfred P. Doolitlle, Miguel Palmer como Coronel Pickering, Irma Dorantes como Sra. Higgins, Manuel Pereyra como Freddy Eynsford-Hill y Carmen Durand como Sra. Pearce, el montaje contó con dirección de Alejandro Orive, coreografía de Óscar Carapia, diseño de vestuario de Ignacio Aranda, diseño de escenografía de Óscar Acosta, dirección musical de Jorge Neri y adaptación al español de Marco Villafán.

En Argentina debutó en 1961 en el Teatro El Nacional de Buenos Aires, dirigido por Carlos A. Petit y protagonizado por Rosita Quintana como Eliza Doolitlle (posteriormente reemplazada por Beatriz Bonnet), José Cibrián como Henry Higgins (posteriormente reemplazado por Délfor Medina y Duilio Marzio) y Dringue Farías como Alfred P. Doolitlle.

Una versión producida por el Teatro Estable de la Provincia de Tucumán se estrenó el 15 de agosto de 1979 en la Sala Paul Groussac de San Miguel, con Viviana Pereyra como Eliza Doolitlle y Juan Carlos Di Lullo como Henry Higgins. Dirigido por Carlos Olivera, el montaje fue todo un éxito y se mantuvo en cartel durante dos temporadas. Posteriormente también pudo verse en el Teatro Presidente Alvear de Buenos Aires, en el Teatro del Libertador General San Martín de Córdoba y en el Teatro San Martín de San Miguel de Tucumán.

Entre el 7 de marzo y el 29 de octubre de 2000, Alejandro Romay produjo una nueva puesta en escena en el Teatro El Nacional de Buenos Aires, que fue reabierto para la ocasión después casi dos décadas cerrado debido al incendio de 1982. Paola Krum como Eliza Doolitlle, Víctor Laplace como Henry Higgins, Pepe Soriano como Alfred P. Doolitlle, Juan Manuel Tenuta como Coronel Pickering, Aída Luz como Sra. Higgins, Marcelo Trepat como Freddy Eynsford-Hill y Alicia Mouxaut como Sra. Pearce encabezaron el elenco de esta versión, que fue dirigida por Mick Gordon y coreografiada por Michael King.
El estreno de "My Fair Lady" en España tuvo lugar el 3 de noviembre de 1982 en el Palacio del Progreso de Madrid (actual Teatro Nuevo Apolo), con Ángela Carrasco como Eliza Doolitlle, Alberto Closas como Henry Higgins, Alfonso del Real como Alfred P. Doolitlle, Manuel Alexandre como Coronel Pickering, Amelia de la Torre como Sra. Higgins, Sergio Fachelli como Freddy Eynsford-Hill, Mercedes Borqué como Sra. Pearce y Helena Bianco como alternante de Eliza Dolittle. La dirección y adaptación al castellano corrió a cargo de Juan José Alonso Millán, quien volvió a apostar por el musical norteamericano después de haber llevado a los escenarios españoles títulos como "Oh! Calcutta!", "Annie" o "El sonido de la música", e invirtió 15 millones de pesetas (algo más de 90.000 euros) para poner en marcha la obra. El resto del equipo creativo lo formaron Mario Watusi en la coreografía, Antonio Cortés en el diseño de escenografía y Teddy Bautista en la dirección musical.

Aunque inicialmente la acogida del público fue buena, la producción se vio obligada a echar el cierre el 9 de enero de 1983, motivado por la caída de espectadores que sufrió tras la emisión en TVE de la versión cinematográfica de George Cukor.

Después del éxito obtenido cuatro años antes con "El hombre de La Mancha", Paloma San Basilio y José Sacristán volvieron a unirse para protagonizar "My Fair Lady" en el Teatro Coliseum de Madrid, donde el espectáculo se representó entre el 17 de octubre de 2001 y el 11 de mayo de 2003, superando las 500 funciones y siendo visto por más de 700.000 espectadores. Dirigido por Jaime Azpilicueta, quien también realizó la adaptación al castellano junto a Nacho Artime, este montaje contó con coreografía de Goyo Montero, diseño de escenografía de Gerardo Trotti, diseño de vestuario de José Ramón de Aguirre y Gabriela Salaverri, diseño de iluminación de José Ramón de Aguirre y Javier Armendariz, diseño de sonido de Ricardo Gómez y dirección musical de Alberto Quintero. La producción corrió a cargo de Cartel Teatro y CIE España, con un presupuesto de más de 4 millones de euros, sin contar los 2,5 que costó la remodelación del Teatro Coliseum.

Además de Paloma San Basilio como Eliza Doolitlle y José Sacristán como Henry Higgins, en el elenco también estuvieron Joan Crosas como Alfred P. Doolitlle (premio Max al mejor actor de reparto), Nicolás Dueñas como Coronel Pickering, Carmen Bernardos como Sra. Higgins, Víctor Díaz como Freddy Eynsford-Hill y Selica Torcal como Sra. Pearce.

En 2012, Stage Entertainment produjo la primera gira nacional de "My Fair Lady" en España, con Paloma San Basilio de nuevo al frente del reparto en el papel de Eliza Doolitlle. Junto a ella, Juan Gea como Henry Higgins, Joan Crosas repitiendo como Alfred P. Doolitlle, José Ramón Henche como Coronel Pickering, Ana María Vidal como Sra. Higgins, Víctor Díaz repitiendo como Freddy Eynsford-Hill y Luisa Fernanda Gaona como Sra. Pearce completaron el elenco.

El espectáculo fue totalmente rediseñado para la ocasión, incorporando como novedad principal el uso de proyecciones para recrear las diferentes localizaciones del Londres de principios del siglo XX. Parte del equipo creativo de la anterior puesta en escena volvió a participar en esta versión, incluyendo a Jaime Azpilicueta en la dirección, Goyo Montero en la coreografía y Gabriela Salaverri en el diseño de vestuario. Otros profesionales involucrados fueron Montse Amenós en el diseño de escenografía, Albert Faura en el diseño de iluminación, Gastón Briski en el diseño de sonido, Joan Rodón en el diseño de vídeo, Enrique Sequero en la dirección residente y Sergi Cuenca en la dirección musical. La adaptación al castellano utilizada fue la misma que en 2001, realizada por Jaime Azpilicueta y Nacho Artime, aunque se eliminaron algunos números musicales como "Just You Wait", "Show Me" o "A Hymn to Him".

El "tour" arrancó el 3 de julio de 2012 en el Auditorio Adán Martín de Santa Cruz de Tenerife y tenía previsto visitar más de veinte ciudades durante un año, pero la subida del IVA cultural hizo que resultase inviable continuar con la gira y el cierre fue adelantado al 4 de noviembre de 2012, tras finalizar su estancia en el Teatro Principal de Valencia.

"My Fair Lady" se ha representado en más de 30 países a lo largo de todo el mundo, incluyendo Alemania, Argentina, Australia, Austria, Bélgica, Brasil, Canadá, Cuba, Dinamarca, España, Estados Unidos, Francia, Hungría, Irlanda, Israel, Italia, Japón, México, Noruega, Nueva Zelanda, Países Bajos, Perú, Polonia, Portugal, Reino Unido, República Checa, Rusia, Singapur, Sudáfrica, Suecia y Suiza.

En Estados Unidos ha salido de gira en varias ocasiones. El primer "tour" nacional arrancó el 18 de marzo de 1957 en el Auditorium Theatre de Rochester, Nueva York, protagonizado por Anne Rogers como Eliza Doolitlle y Brian Aherne como Henry Higgins, y estuvo en la carretera durante siete años consecutivos.

En 1962, el Teatro Carlos Gomes de Río de Janeiro acogió la "première" brasileña con Bibi Ferreira como Eliza Doolitlle y Paulo Autran como Henry Higgins. Posteriormente, esa misma producción también pudo verse en el Teatro Paramount de São Paulo (actual Teatro Abril).

En Cuba se estrenó en 1980 en el desaparecido Teatro Musical de La Habana, dirigido por Nelson Dorr y protagonizado por Mirtha Medina como Eliza Doolitlle y Hector Quintero como Henry Higgins.

El 3 de agosto de 2003, un concierto semiescenificado tuvo lugar en el Hollywood Bowl de Los Ángeles, con un reparto liderado por Melissa Errico como Eliza Doolittle, John Lithgow como Henry Higgins, Roger Daltrey, vocalista de The Who, como Alfred P. Doolitlle, Paxton Whitehead como Coronel Pickering, Rosemary Harris como Sra. Higgins, Kevin Early como Freddy Eynsford-Hill y Lauri Johnson como Sra. Pearce.

Siguiendo al revival londinense de 2003 producido por Cameron Mackintosh, "My Fair Lady" salió de gira por Reino Unido entre el 5 de octubre de 2005 y el 12 de agosto de 2006. Amy Nuttall y Lisa O'Hare encabezaron el elenco alternándose el papel de Eliza Doolittle, acompañadas de Christopher Cazenove como Henry Higgins, Russ Abott como Alfred P. Doolitlle (posteriormente reemplazado por Gareth Hale), Stephen Moore como Coronel Pickering, Honor Blackman como Sra. Higgins (posteriormente reemplazada por Hannah Gordon), Stephen Carlile como Freddy Eynsford-Hill y Romy Baskerville com Sra. Pearce. Tras su etapa británica, el "tour" dio el salto a Norteamérica, donde estuvo en la carretera entre el 12 de septiembre de 2007 y el 22 de junio de 2008, con Lisa O'Hare y Christopher Cazenove repitiendo sus papeles de Eliza Doolitlle y Henry Higgins respectivamente. Junto a ellos, Tim Jerome como Alfred P. Doolitlle, Walter Charles como Coronel Pickering, Sally Ann Howes como Sra. Higgins (posteriormente reemplazada por Marni Nixon, la voz de Audrey Hepburn en las canciones de la adaptación cinematográfica de 1964), Justin Bohon como Freddy Eynsford-Hill, Alma Cuervo como Sra. Pearce (posteriormente reemplazada por Barbara Marineau) y Dana DeLisa como Eliza Doolitlle en algunas representaciones completaron el reparto.

Entre el 7 y el 10 de marzo de 2007, la Orquesta Filarmónica de Nueva York ofreció una serie de conciertos semiescenificados en el Avery Fisher Hall del Lincoln Center, con Kelli O'Hara como Eliza Doolittle, Kelsey Grammer como Henry Higgins, Brian Dennehy como Alfred P. Doolitlle, Charles Kimbrough como Coronel Pickering, Marni Nixon como Sra. Higgins, Philippe Castagner como Freddy Eynsford-Hill y Meg Bussert como Sra. Pearce.

El Théâtre du Châtelet de París acogió una temporada limitada de 27 únicas funciones entre el 9 de diciembre de 2010 y el 2 de enero de 2011, protagonizada por Sarah Gabriel y Christine Arand alternándose como Eliza Doolitlle, Alex Jennings como Henry Higgins, Donald Maxwell como Alfred P. Doolitlle, Nicholas Le Prevost como Coronel Pickering, Margaret Tyzack como Sra. Higgins, Ed Lyon y Pascal Charbonneau alternándose como Freddy Eynsford-Hill, y Jenny Galloway como Sra. Pearce. Robert Carsen fue el director de esta versión, que contó con coreografía de Lynne Page y diseño de vestuario de Anthony Powell. Las representaciones fueron en inglés con subtítulos proyectados en grandes pantallas. Debido al éxito obtenido, el musical regresó al mismo escenario entre el 5 de diciembre de 2013 y el 1 de enero de 2014, con algunas caras nuevas en el elenco, incluyendo a Katherine Manley como Eliza Doolitlle (alternándose con Christine Arand), Caroline Blakiston como Sra. Higgins y Lee Delong como Sra. Pearce.

Para celebrar el 60º aniversario del espectáculo, Julie Andrews dirigió un montaje producido por John Frost y Opera Australia, que pudo verse en el Joan Sutherland Theatre de la Ópera de Sídney entre el 6 de septiembre y el 5 de noviembre de 2016. Anna O'Byrne como Eliza Doolitlle, Alex Jennings como Henry Higgins, Reg Livermore como Alfred P. Doolitlle, Tony Llewellyn-Jones como Coronel Pickering, Robyn Nevin como Sra. Higgins, Mark Vincent como Freddy Eynsford-Hill y Deidre Rubenstein como Sra. Pearce encabezaron el reparto de esta puesta en escena, que posteriormente también se representó en el Queensland Performing Arts Centre de Brisbane (entre el 19 de marzo y el 30 de abril de 2017), el Regent Theatre de Melbourne (entre el 16 de mayo y el 27 de julio de 2017), y el Capitol Theatre de Sídney (entre el 27 de agosto y el 24 de septiembre de 2017), con la incorporación de Charles Edwards como Henry Higgins.

En 1964, "My Fair Lady" fue llevado a la gran pantalla bajo la dirección de George Cukor, con Audrey Hepburn como Eliza Doolitlle y Rex Harrison y Stanley Holloway, protagonistas de las producciones originales de Broadway y Londres, repitiendo sus papeles de Henry Higgins y Alfred P. Doolitlle respectivamente. El resto del reparto lo completaron Wilfrid Hyde-White como Coronel Pickerin, Gladys Cooper como Sra. Higgins, Jeremy Brett como Freddy Eynsford-Hill y Mona Washbourne como Sra. Pearce.

La elección de Audrey Hepburn como Eliza Doolitlle causó cierta controversia, ya que quienes habían visto a Julie Andrews sobre el escenario coincidían en que ella era la candidata perfecta para el personaje. Además, Hepburn tuvo que ser doblada en las canciones por Marni Nixon al no estar a la altura de la exigente partitura. Jack Warner, presidente de Warner Bros., quería una gran estrella para el papel protagonista y descartó a Julie Andrews por su falta de experiencia cinematográfica. Curiosamente, ese mismo año Andrews obtuvo el Óscar a la mejor actriz por "Mary Poppins", que se convirtió en la cinta de acción real más exitosa de la factoría Disney hasta que "" le arrebató el título en 2003. El propio Alan Jay Lerner expresó su disconformidad con el resultado, especialmente por no seguir los estándares de la dirección original de Moss Hart, por la elección de Audrey Hepburn y porque el rodaje tuvo lugar en los estudios Warner y no en Londres como a él le hubiese gustado. La película finalmente se alzó con ocho premios Óscar, incluyendo mejor película, mejor dirección (el único premio de la Academia que George Cukor recibió en toda su carrera), mejor actor (Rex Harrison), mejor fotografía, mejor sonido, mejor música original, mejor dirección artística y mejor diseño de vestuario.

En 2008, Columbia Pictures anunció una nueva adaptación cinematográfica con la intención de rodarla en las localizaciones reales de Covent Garden, Drury Lane, Tottenham Court Road, Wimpole Street y el Hipódromo de Ascot. Aunque se llegaron a hacer públicos los nombres de John Madden como director y Emma Thompson como adaptadora del guion, e incluso se barajaron los nombres de Carey Mulligan y Colin Firth para los papeles protagonistas, finalmente en mayo de 2014 Cameron Mackintosh confirmó la cancelación del proyecto.



Según el libro "Enchanted Evenings: The Broadway Musical from Show Boat to Sondheim" de Geoffrey Block, ""La noche del estreno los críticos reconocieron inmediatamente que My Fair Lady estaba totalmente a la altura del modelo de musical integrado de Rodgers y Hammerstein ... Robert Coleman... escribió 'Las canciones de Lerner y Loewe no solo son deliciosas, sino que también hacen avanzar la acción. Siempre son mucho más que interpolaciones o interrupciones'"".

Por su parte, William A. Everett y Paul R. Laird recogen en su ensayo "The Cambridge Companion to the Musical" que "My Fair Lady" se estrenó con ""excelentes críticas unánimes, una de las cuales decía 'No se moleste en leer esta reseña ahora. Mejor siéntese y encargue sus entradas'... Los críticos alabaron el inteligente uso de la novela original de Shaw, la genialidad de las letras y la partitura bien integrada de Loewe"".

Ejemplos de elogios de la crítica extraídos de la edición en forma de libro del musical publicada en 1956:

Sin embargo, la acogida de los seguidores de George Bernard Shaw no fue tan entusiasta. Eric Bentley, por ejemplo, se refirió a "My Fair Lady" como ""un terrible tratamiento de la obra de Mr. Shaw y de su idea básica"", aunque también reconoció que era ""un espectáculo delicioso"".

Existen multitud de álbumes interpretados en sus respectivos idiomas por los elencos de las diferentes producciones que se han estrenado a lo largo de todo el mundo, además de la banda sonora de la versión cinematográfica y numerosas grabaciones de estudio. 

En español se han editado los discos oficiales de las producciones de México (1959), Buenos Aires (1963 y 2000) y Madrid (2001), así como la banda sonora de la película con el doblaje para España.

 


</doc>
<doc id="28385" url="https://es.wikipedia.org/wiki?curid=28385" title="Presumed Innocent (película)">
Presumed Innocent (película)

Presumed Innocent es un filme estadounidense de 1990, dirigido por Alan J. Pakula. Protagonizado por Harrison Ford, Brian Dennehy, Raúl Juliá, Bonnie Bedelia, Greta Scacchi y Paul Winfield en los papeles principales.

Galardonada con el premio BMI Film Music Award 1991 por la banda sonora de John Williams.

Un fiscal, Rozat Sabich, que tuvo una relación extramatrimonial con una compañera de trabajo es sospechoso de su posterior asesinato. Todo el sistema legal, por el que él ha luchado, está ahora en su contra y finalmente el caso se lleva ante un juez. Durante el juicio, sin embargo, se descubren muchos fallos de la acusación, por lo que el caso debe ser cerrado por el juez con una disculpa hacia el acusado, que no cometió el asesinato.

Depués del juicio la vida de Sabich vuelve a su cauce hasta que un día descubre por casualidad, que fue su mujer la que mató a la compañera de trabajo suyo, porque se había enterado de su relación extramatrimonial y reaccionó "destruyendo a la destructora". Horrorizado Sabich, por consideración a su hijo, decide no informar a las autoridades sobre lo que ha hecho su mujer. Según su parecer, "hay una víctima, hay un victimario y hay un castigo".




</doc>
