<doc id="14274" url="https://fr.wikipedia.org/wiki?curid=14274" title="Empreinte écologique">
Empreinte écologique

L'empreinte écologique est un indicateur et un mode d'évaluation environnementale qui comptabilise la "pression" exercée par les hommes envers les ressources naturelles et les « services écologiques » fournis par la nature. Plus précisément, elle mesure les surfaces alimentaires productives de terres et d'eau nécessaires pour produire les ressources qu'un individu, une population ou une activité consomme et pour absorber les déchets générés, compte tenu des techniques et de la gestion des ressources en vigueur. Cette surface est exprimée en hectares globaux (hag), c'est-à-dire en hectares ayant une productivité égale à la productivité moyenne.

Le calcul de l'empreinte écologique d'une entité ou d'un territoire répond à une question scientifique précise, et non à tous les aspects de la durabilité, ni à toutes les préoccupations environnementales. L'empreinte écologique aide à analyser l'état des pressions sur l'environnement sous un angle particulier, en partant de l'hypothèse que la capacité de régénération de la Terre pourrait être le facteur limitant pour l'économie humaine si elle continue à surexploiter ce que la biosphère est capable de renouveler. Une métaphore souvent utilisée pour l'exprimer est le nombre de planètes nécessaires à une population donnée si son mode de vie et de consommation était appliqué à l'ensemble de la population mondiale.

La Journée internationale de l'empreinte écologique est célébrée le 3 mai. 

C'est une méthode de comptabilité environnementale, elle permet de mesurer "l'empreinte" d'une population par rapport à la surface qu'elle utilise. 
Être en « "dépassement écologique" » signifie que l'on déprécie (localement, pour le présent ou le futur) du capital naturel (en puisant dans les stocks plutôt que dans le surplus généré annuellement par la nature) et/ou que l'on accumule des déchets dans l'environnement (en émettant plus de déchets que ce que la nature peut assimiler annuellement).

L'empreinte écologique peut aussi donner une mesure de la pression environnementale découlant de la production d'objets tels que, par exemple, voiture, ordinateur ou téléphone portable.

L'empreinte écologique est un indicateur et un mode d'évaluation environnementale qui comptabilise la pression exercée par les hommes sur les ressources naturelles et les « services écologiques » fournis par la nature.

Le professeur britannique Colin Fudge propose une définition simple : pour lui, l'empreinte écologique est .

Pour William E. Rees, un des pères du concept d'« empreinte écologique », économiste environnemental à l'université de la Colombie-Britannique (Vancouver), l'empreinte écologique est la .

Pour l'OCDE il s'agit de la .

Par extension, on peut calculer l'empreinte d'un objet (un ordinateur, une voiture, un meuble en bois exotique) grâce à l'analyse du cycle de vie, en considérant la surface moyenne liée aux ressources nécessaire à l'extraction et au transport des matériaux, à sa fabrication, son fonctionnement et son élimination. 

Par exemple, les empreintes en l'an 2000 étaient estimées respectivement à :

Cette « surface » métaphorique est virtuelle mais traduit une réalité très concrète ; dans un monde fini où la population croît, plus cette « empreinte » est large, plus on s’éloigne de l'idéal de soutenabilité et de durabilité du développement (autrement dit, métaphoriquement, plus l'entité est « lourde », plus son empreinte sera profonde et moins réversible sur la planète, surtout si la surface dont elle dispose est petite).

En d'autres termes :
avec
et

Le terme d'empreinte écologique s’inscrit dans la lignée du Club de Rome qui voit l'apparition de plusieurs indicateurs mesurant l'impact humain sur la nature, avec notamment l', et apparaît au moment de la Conférence de Rio (« Sommet de la Terre ») en 1992 dans le premier article académique intitulé "Ecological Footprints and Appropriated Carrying Capacity: What Urban Economics Leaves Out" (empreintes écologiques et capacité de charge appropriée : ce que l'économie urbaine laisse de côté) écrit par le Professeur de planification urbaine William Rees de l'Université de la Colombie-Britannique. La méthode se développe comme thèse de doctorat de Mathis Wackernagel sous la direction de William Rees, entre 1990 et 1994. Le résultat de la thèse est publié en 1995 : constatant que les habitants d'une ville avaient besoin d'une certaine surface de terres biologiquement productives (surfaces agricoles, espaces forestiers), un indicateur peut mesurer cette pression humaine sur les ressources naturelles en comparant « l'offre » en ressources naturelles à la « demande » humaine sur ces ressources. Wackernagel et Rees publient alors un livre intitulé "Our Ecological Footprint: Reducing Human Impact on the Earth" dans lequel ils affinent le concept et la méthode de calcul, l'indicateur d'empreinte écologique étant étendu à l'ensemble de la planète. Ce livre est traduit en français en 1999 sous le titre "Notre empreinte écologique".

Depuis 2003, le think tank , ONG cofondée par Mathis Wackernagel et Susan Burns, est chargé du perfectionnement de la méthodologie ainsi que de la mise à jour des résultats. Global Footprint Network publie ainsi chaque année un atlas détaillant l'empreinte écologique de chaque pays.

Des logiciels dits « calculateurs » ont été produits et affinés pour mesurer des empreintes écologiques à diverses échelles, sur la base de données publiées et comparables, par exemple le calculateur carbone personnel de l'ADEME.

L'empreinte écologique a connu un succès croissant à partir de la fin des années 1990. Le WWF a fortement contribué à le populariser, avec en France l'association 4D, puis Agora 21, quelques collectivités (Conseil Régional Nord pas de Calais, Ville de Paris, puis certains conseils généraux (Conseil Général du Nord), encouragés par la DATAR qui le cite en exemple de bonne pratique mais sans cependant l'utiliser. Il est publié tous les deux ans par l'association WWF, dans le Rapport Planète Vivante. La notion d'empreinte écologique a été diffusée au Sommet de Johannesburg par WWF en 2002. Cet indicateur est notamment considéré comme un moyen de communication puissant pour le grand public.

L’empreinte écologique tire aussi son inspiration des approches géobiophysiologiques de la biosphère et de l'écologie du qui ont contribué à la notion unifiante de "sustainability" (soutenabilité du développement) et au concept économique d'« internalisation des coûts externes (environnementaux et sociaux) ».

La boite à outil de l’empreinte écologique dérive aussi des approches « Étude d’impact » et « Mesures conservatoires et compensatoires » qu’elle contribue à grandement rénover, avec d’autres outils tels que le Bilan carbone ou le Profil environnemental. Le calcul de l'empreinte en lui-même est neutre : il ne fait qu'exposer des faits. On peut cependant interpréter le dépassement actuel (et l'augmentation de la dette écologique) comme une nécessité de développer des mesures compensatoires écologiquement efficientes et fonctionnelles.

Selon le guide du "Global Footprint Networks", le calcul actuel de l'empreinte se fonde sur les concepts et sous-calculs suivants :

Sur l’ensemble de la surface terrestre (environ 51 milliards d’hectares), on estime qu’environ 12 milliards d’hectares (terrestres et aquatiques) sont bioproductifs au sens où ils créent chaque année une certaine quantité de matière organique grâce à la photosynthèse. Dans les déserts et la majeure partie des océans, la photosynthèse existe aussi mais est trop diffuse pour que ses produits soient exploités par l’homme.

On distingue cinq types de surfaces bioproductives (données 2009) :

Afin de pouvoir agréger ces différentes surfaces, on les convertit en une nouvelle unité, l’hectare global (hag), qui représente un hectare de bioproductivité moyenne sur Terre une année donnée. Le poids de chaque type de surface est ainsi modifié ce qui s’explique par le fait qu’ils ne produisent pas tous la même quantité de services (un hectare de pâturages est par exemple moins productif qu’un hectare de cultures).

Au niveau national, le calcul de la biocapacité pour chaque type de surface prend en compte la productivité du pays par rapport à la moyenne mondiale. Cette productivité inférieure ou supérieure à la moyenne s’explique par les différences dans la technologie disponible, le climat, la qualité des sols…

On notera que des pratiques agricoles non durables peuvent faire augmenter la biocapacité du terrain considéré : l’empreinte écologique n’est pas un outil prédictif et constate donc les gains instantanés engendrés par ces pratiques. Cependant, l’empreinte pourra rendre compte d’une éventuelle détérioration dans le futur : les sols pollués verront leur productivité et donc leur biocapacité diminuer.

Les activités humaines consomment des ressources et produisent des déchets. Aux cinq types de surfaces bioproductives correspondent six types d’empreintes (5 pour les ressources, un pour un type de déchet : le )

Les forêts offrent donc deux services différents et en compétition : fournir des produits à base de bois ou séquestrer une partie du carbone émis par l’homme. Les forêts ne peuvent fournir les deux services à la fois : si l'on souhaite qu'une partie des forêts séquestrent du sur le long terme, il faut accepter de ne jamais les couper.

L'exemple simplifié qui suit permet de comprendre le principe de calcul utilisé pour chacune des empreintes partielles : "10 tonnes de bois sont nécessaires à une activité donnée ; or la productivité moyenne des forêts dans le monde est de 2 tonnes de bois par hectare par an. L’activité mobilise donc 5 hectares de forêts." On peut encore par la suite transformer les 5 hectares de forêts en hectares globaux ce qui permettra d’agréger les différentes empreintes partielles.

Avec une biocapacité d’environ (milliards d'« hectares globaux ») et une population de d'hommes, la biocapacité disponible par personne en 2013 était de (« hectares globaux »). Or, un Terrien moyen avait besoin en 2013 de . Le dépassement a donc été de 68 %, autrement dit il aurait fallu pour fournir la consommation humaine de façon durable en 2013. 

L'empreinte écologique mondiale a en fait dépassé la capacité biologique de la Terre à produire nos ressources et absorber nos déchets depuis le milieu des années 1980, ce qui signifie que l'on surconsomme déjà les réserves, en réalité en surexploitant les milieux.

La tendance à l'augmentation n'a pas encore pu être inversée, en raison de la difficulté de changer les modes de consommation et de production, en dépit des engagements et objectifs de développement durable établis aux sommets de la Terre de Rio de Janeiro en 1992 et de Johannesburg en 2002. 

Quelques repères pour l'année 2013 :

D'après la base de données du Global Footprint Network, les empreintes écologiques par personne étaient en 2013 :

NB : aucun des pays pétroliers de la péninsule arabique ne figure dans cette base.

L'empreinte écologique française est pour la moitié due à l'empreinte carbone (i.e. aux émissions de ). Au cours du dernier demi-siècle, la part de celle-ci a explosé, passant de 13 % en 1961 à 52 % en 2005, devant l'agriculture.

Dès lors que les données de bases sont disponibles, l’empreinte écologique permet à tous, de manière transparente de : 

Plus encore, l'empreinte écologique permet de visualiser précisément l'inégalité des conséquences du développement économique sur les différents territoires et populations. Son calcul pour différentes situations permet en effet plusieurs opérations éloquentes :
L'empreinte écologique est ainsi un instrument pédagogique irremplaçable pour démontrer les liens du caractère plus ou moins soutenable du développement avec l'accroissement des inégalités.

Une empreinte écologique faible peut être choisie ou subie, plus ou moins facilement ou difficilement selon la productivité de l'environnement dans lequel on vit, et selon le nombre de personnes qui ont besoin d'y prélever les ressources nécessaires à leur vie. Les hommes ne sont pas égaux non plus face à la géographie des conséquences des dérèglements climatiques et écologiques. Les pays les plus pauvres ont encore une empreinte écologique par personne inférieure au niveau moyen qui serait supportable par la planète, mais aspirent à se développer et ont généralement une démographie élevée.

Certains évoquent une double dette écologique :
Les premiers « empruntent » (sans les payer ou en ne les payant pas au juste prix, tant qu’il n’y a pas de fortes taxes) d’énormes surfaces de ressources naturelles, terres arables, forêts, essentiellement situées dans les pays du Sud. Ils y exportent une partie de leurs pollutions (et notamment celles qui ne connaissent pas de frontière, dont les gaz à effet de serre).

L’inégalité mondiale face aux ressources bioproductives et à leur accès se retrouve aux niveaux national, régional et local. En toute première approximation, l’empreinte écologique des ménages est proportionnelle à leur consommation, et donc à leur revenu, si l’on raisonne à un moment donné du temps. Les personnes à très faible pouvoir d'achat ne prennent pas l’avion et n'achètent pas de 4x4 ou d'habitations de luxe, et n'ont pas non plus accès à la nourriture bio, aux appareils basse-consommation ou au HQE.

Un autre aspect des relations entre questions écologiques et inégalités sociales transparaît dans l'importance que les organisations internationales accordent aux « objectifs du millénaire » des Nations unies, visant à réduire fortement la pauvreté. Il est rarement rappelé que ces objectifs ne pourront être atteints qu'en y intégrant les questions environnementales. Or l'évolution de l'empreinte écologique montre que ces buts impliquent une remise en cause du « "dogme de la croissance économique et matérielle continue" ». 

Dans les cas des modifications climatiques, l'accroissement de l'empreinte écologique par personne associée à la croissance économique et démographique se traduit par d’autres signaux alarmants, attestés par de nombreux travaux scientifiques :

Or ces catastrophes toucheront d'abord les populations les plus pauvres de la planète qui dépendent le plus des « aléas » climatiques. Elles pourraient réduire à néant les objectifs du millénaire pour 2015, et provoquer des régressions au-delà. On estime que 90 % des personnes concernées par les désastres « naturels » liés au réchauffement habitent dans des pays ou régions pauvres. Selon la Croix-Rouge et le Croissant Rouge, le nombre de personnes gravement affectées par de telles catastrophes est passé de 740 millions dans les années 1970 à plus de 2 milliards dans les années 1990. Les pertes économiques correspondantes seraient passées de 131 milliards à 629 milliards, soit plus que dix ans d’aide publique au développement. Selon le PNUE (Programme des Nations Unies pour l’Environnement), le coût du réchauffement climatique double tous les dix ans. La moitié de la population mondiale vit dans des zones côtières qui seraient submergées si le niveau des mers s’élevait d’un mètre, évaluation possible pour le siècle à venir si les tendances actuelles persistent. Ces nouvelles diminutions de la surface disponible se traduiraient dans un accroissement de la contrainte de l'empreinte écologique. Concrètement, il faudrait donc s’attendre dans les décennies à venir à des migrations massives de « réfugiés environnementaux » : vingt millions avant la fin du siècle rien que pour le Bangladesh, cent cinquante millions dans le monde dès 2050 selon des chercheurs d’Oxford.

Nous savons que la planète et la vie s’adapteront d’une façon ou d’une autre. Mais, si l’on réfléchit aux solutions qu’il faudra bien mettre en œuvre pour « sauver la planète » (qui s’en sortira d’une façon ou d’une autre; cette formule désigne la vie humaine et sociale, ainsi que sa qualité), le problème de l'accroissement des contraintes de l'empreinte écologique se traduit au premier plan dans l'accroissement des inégalités. Or l’acceptabilité sociale des perspectives de réduction drastique de la pression écologique des hommes ne va pas de soi. Deux conditions semblent nécessaires pour cela. La première concerne l’information sur les dégâts aujourd’hui et le débat sur les risques d’une poursuite dans la voie actuelle et sur les alternatives. Sans cette condition, la prise de conscience sera tardive et l’urgence imposera des décisions orchestrées autoritairement par les politiques et des spécialistes au nom des catastrophes majeures qu’ils n’auront su prévenir. C’est hélas ce qui semble aujourd’hui le plus probable. La seconde concerne la justice. Les efforts de reconversion économique et mentale et de transformation des modes de vie qui nous attendent dans tous les scénarios envisageables seront insupportables s’ils ne s’accompagnent pas d’une forte réduction des inégalités sociales, dans le monde et dans chaque pays.

L'empreinte écologique est très liée à l'utilisation des énergies fossiles, mais pas seulement. 

En ce qui concerne les agrocarburants, certains, notamment l'éthanol, ont une forte empreinte écologique, soit directe (déforestation au Brésil, déplacements de productions alimentaires dans d'autres pays) soit indirecte (forte consommation de dérivés pétroliers pour produire de l'éthanol dans les pays tempérés).

Le calcul de l'empreinte écologique ne prend pas en compte :

Des experts donnent néanmoins des estimations utiles à l'évaluation prospective d'empreinte écologique par type d'énergie.
Par exemple, pour les énergies fossiles, et plus particulièrement le pétrole, les études de prospective initiées il y a quelques années en Suède sur le pic pétrolier ( « "oil peak" » en anglais) ont cherché à définir des stratégies innovantes. Le pic de consommation du pétrole devrait intervenir entre 2015 et 2025 (selon les experts). D'autres estiment que nous sommes bien plus proches de la fin des réserves de pétrole. Certains auteurs comme Nicole Stricker estiment qu'il faudrait aussi mieux quantifier la quantité d'eau consommée ou dégradée par les différentes options énergétiques ou d'atténuation des émissions de gaz à effet de serre (par exemple si les agrocarburants en plus de consommer de grandes surfaces utilisent aussi des plantes consommant beaucoup d'eau.

Pour réduire l'empreinte écologique d'une zone, il faut agir sur l'empreinte environnementale des organisations ou des produits dans cette zone.




</doc>
<doc id="14275" url="https://fr.wikipedia.org/wiki?curid=14275" title="Cristallographie">
Cristallographie

La cristallographie est la science qui se consacre à l'étude des substances cristallines à l'échelle atomique. Les propriétés physico-chimiques d'un cristal sont étroitement liées à l'arrangement spatial des atomes dans la matière. L'état cristallin est défini par un caractère périodique et ordonné à l'échelle atomique ou moléculaire. Le cristal est obtenu par translation dans toutes les directions d'une unité de base appelée maille élémentaire.

Elle est en rapport avec des disciplines aussi diverses que la physique, la chimie, les mathématiques, la biophysique, la biologie, la médecine, la science des matériaux, la métallurgie ainsi que les sciences de la terre.

Le cristal, d'abord simple objet de curiosité, passionna les collectionneurs avant d'intriguer les savants qui, en étudiant sa structure, ébauchèrent les premières théories sur la constitution intime de la matière.
La loi des indices rationnels ou des troncatures simples fut définie par l'abbé René Just Haüy en 1774. Par observation du phénomène de clivage de la calcite, il a déterminé les « molécules intégrantes », c'est-à-dire les parallélépipèdes identiques constituant les cristaux et à la suite de cela, il en a déduit que chaque face d'un cristal peut être repérée dans l'espace par des nombres entiers.

Max von Laue obtient le prix Nobel de physique de 1914 « pour sa découverte de la diffraction des rayons X par des cristaux ». Commémorant ce centenaire, 2014 est proclamée « année internationale de la cristallographie » par l’Organisation des Nations unies.

La matière solide est composée d'atomes, que l'on peut voir comme des boules élémentaires, qui s'assemblent de plusieurs manières : reliées par des liaisons chimiques covalentes, les atomes forment une molécule,comme c'est le cas de gaz (ex l'oxygène O), de liquides (l'eau HO), de matériaux solides ou souples (ex polymères (caoutchoucs, plastiques, papiers, protéines... pouvant comporter des milliards de molécules semblables ou non en mélanges).

Les atomes (ou les molécules) peuvent s'agencer de manière irrégulière, on a alors de la matière dite « amorphe » (ou « vitreuse »), comme le verre (SiO). Enfin elles peuvent s'entasser de manière ordonnée, c'est alors un cristal (ex.le quartz SiO). Dans ces cristaux non moléculaires, la structure est composée d'atomes ou d'ions qui forment un réseau tridimensionnel de polyèdres de coordination sans qu'aucune unité moléculaire n'existe : c'est le cas de la quasi-totalité des minéraux et de la majorité des cristaux inorganiques. Les cristaux de molécules (ex. d'insuline) comportent des structures plus complexes.

Le « cristal parfait » est un modèle utilisé pour représenter la structure de la matière cristalline. Ce modèle considère qu'un cristal est un empilement ordonné et infini d'atomes, d'ions ou de molécules.

Le cristal est un solide à structure constituée d'atomes ordonnés dans un réseau périodique et même tripériodique et symétrique. Il a des propriétés de symétrie avec des axes de rotation directs et inverses, des miroirs, des plans et des centres de symétrie.

La maille cristalline élémentaire est le plus petit volume cristallin construit sur trois translations les plus courtes indépendantes du cristal. Elle est définie par trois vecteurs qui génèrent ainsi six paramètres de maille : les trois longueurs des vecteurs formula_1, formula_2, formula_3 et les trois angles entre ces vecteurs α, β, γ.

Un réseau est un ensemble de points ou « nœuds » en trois dimensions qui présente la propriété suivante : lorsque l'on se translate dans l‘espace selon certains vecteurs, on retrouve exactement le même environnement. Il y a donc une périodicité spatiale.

Il existe sept systèmes réticulaires de base : cubique, hexagonal, rhomboédrique, quadratique (ou tétragonal), orthorhombique, monoclinique et triclinique.

Auguste Bravais définit, en 1848, à partir des différentes combinaisons des éléments de symétrie cristalline, 32 classes de symétrie, qui elles-mêmes se répartissent en 14 types de réseaux (il n'existe pas d'autre façon de disposer des points dans l'espace, afin de réaliser un réseau ou une maille, de manière à ne laisser aucun volume libre entre les réseaux). Les 14 réseaux de Bravais sont des expansions des 7 formes primitives de cristaux.

Voici deux exemples de réseaux de Bravais :

Le groupe ponctuel de symétrie d'un système cristallin est le groupe (au sens mathématique) regroupant l'ensemble des opérations de symétrie qui laissent un nœud du réseau invariant. Ce nœud est donc situé à l'intersection de toutes les opérations de symétrie, dont la translation ne fait pas partie. Il existe 32 groupes ponctuels de symétrie distincts.

Le groupe d'espace d'un système cristallin regroupe l'ensemble des opérations de symétrie du groupe ponctuel, auxquelles s'ajoutent les opérations de translation. Vers 1890, Fedorov et Schoenflies démontrèrent - indépendamment l'un de l'autre - l'existence de 230 groupes d'espace, qui représentent toutes les combinaisons possibles de réseaux et d'opérations de symétrie.

Pour plus d'information, voir les articles :

De par leur nature, tous les cristaux sont anisotropes. Mais cette anisotropie dépend des propriétés considérées.

. Propriétés optiques

- À la lumière visible : transparence, réfraction, réflexion, diffraction, etc.
Une grande partie des cristaux minéraux sont transparents, ce qui permet d'étudier leur réfraction. Seuls les cristaux cubiques sont isotropes, tous les autres étant anisotropes (indices de réfraction différents selon la direction d'observation).
Par contre, les cristaux métalliques sont opaques à la lumière, ce qui ne permet que l'étude de leur réflexion. Pour étudier leur diffraction, il faut utiliser les rayons X.

- Aux rayons X : voir cristallographie.

. Propriétés mécaniques : élasticité, dureté, résilience, etc.
Tous les cristaux sont anisotropes.

Haüy a défini des indices ("P", "Q", "R") qui permettent de repérer dans l'espace les faces d'un cristal. Miller, pour simplifier, a dit qu'il ne fallait pas utiliser "P", "Q" et "R" mais leurs inverses (1/"P", 1/"Q", 1/"R") qui seront notés "h", "k", "l". Ils doivent être entiers naturels, premiers entre eux et de valeurs simples.

La cristallogenèse est la formation d'un cristal, soit en milieu naturel, soit de façon expérimentale.

Max von Laue eut l'idée d'irradier les cristaux avec des rayons X, car il pensait que le réseau cristallin ferait dévier le rayonnement de la même façon que la lumière est déviée dans certains minéraux transparents. L'expérience que des collègues réalisèrent sur un cristal de sulfate de cuivre lui permit de faire la démonstration de la structure périodique des empilements d'atomes dans les cristaux et de la nature ondulatoire du rayonnement X.

La détermination de la structure atomique d'un cristal s'effectue le plus souvent par diffraction des rayons X ou des neutrons, dont les longueurs d'onde sont de l'ordre des distances qui séparent les plans atomiques de la structure cristalline. Lorsque le cristal à étudier est irradié par un fin faisceau de rayons X, chacun des atomes du cristal diffuse une onde de faible amplitude, qui se propage dans toutes les directions. Les ondes issues des atomes interfèrent et donnent lieu à la diffraction, faisant apparaître sur le détecteur qui les reçoit des taches qui correspondent au maximum des ondes en phase ; les autres, en opposition de phase, s'annulent.

Au niveau d'un écran situé à une distance des centres diffuseurs secondaires, on observera des figures de diffraction qui permettent de visualiser les perturbations créées par les interférences citées précédemment. Le réseau réciproque est l'image que l'on obtient à partir de la figure de diffraction.


On utilise les propriétés de diffraction des cristaux en physique, chimie, biochimie, biologie, médecine et en sciences de la terre.

Leur analyse donne des informations sur des substances cristallines inorganiques et organiques (distance entre atomes, agencement spatial des atomes, identification de phases cristallines, taille des cristallites).




</doc>
<doc id="14279" url="https://fr.wikipedia.org/wiki?curid=14279" title="Hymne national argentin">
Hymne national argentin

L'Hymne national argentin est l'hymne national de l'Argentine. Les paroles ont été écrites par Vicente López y Planes et la musique a été composée par Blas Parera. La version actuelle fut adoptée en 1900 pendant la présidence de Julio Argentino Roca.



</doc>
<doc id="14281" url="https://fr.wikipedia.org/wiki?curid=14281" title="Ariane 1">
Ariane 1

La fusée Ariane 1 est la première version de la famille de lanceurs fusées Ariane développée dans les années 1970 par l'Agence spatiale européenne pour que l'Europe puisse lancer ses satellites en toute autonomie. Cette version pouvait placer en orbite de transfert géostationnaire (GTO) Le premier vol a lieu le . Ariane 1 est utilisée à 11 reprises et connait 2 échecs. Elle est rapidement remplacée par des versions plus puissantes - Ariane 2, Ariane 3 et surtout Ariane 4 - mieux adaptées au poids croissant des satellites de télécommunications. La fusée était lancée depuis un pas de tir construit à son intention au Centre spatial guyanais (CSG), à Kourou en Guyane française.

Avec une masse au décollage de , pour une hauteur de et un diamètre de , elle était capable de placer une charge utile de en orbite de transfert géostationnaire (GTO). Elle pouvait emmener au choix un seul gros satellite ou un assemblage de deux plus petits.

Ariane 1 est une fusée à 3 étages :

Cette architecture sera conservée dans les versions suivantes du lanceur.

Le premier étage d'Ariane 1, à la base du lanceur, est nommé L140 car transportant près de (, plus précisément) d'ergols liquides (UH25 + ). Ses dimensions sont de de hauteur et de diamètre, pour un poids de à vide. Équipé de quatre moteurs Viking 2, fournissant au décollage une poussée totale de , il est allumé à H-0 jusqu'à . Pour sa conception ont été utilisés des matériaux à faible densité, à savoir un alliage d'aluminium, de zinc et de magnésium.

Le deuxième étage d'Ariane 1 se situe au-dessus du premier étage. Il embarque moins d'ergols (), et n'est pourvu que d'un seul moteur Viking 4. De plus petites dimensions que l'étage L140, de hauteur pour un diamètre de , il pèse et a été conçu en aluminium. La connexion avec le L140 est rendue possible par une conique.

Le Viking 4 qui équipe le L33 présente des caractéristiques proches des Viking 2 du L140. Cependant, il est monté sur un dispositif assurant 2 degrés de liberté, permettant le contrôle de l'orientation en lacet et en tangage. Sa principale différence réside dans sa tuyère, ne devant fonctionner que dans le vide car étant employée à partir d'une altitude d'environ . À l'opposé des Viking 2 qui devaient propulser Ariane dans l'atmosphère et dans le vide, il n'était pas nécessaire de le doter d'une tuyère aussi courte. En effet, de telles tuyères permettent une détente plus rapide des gaz sortant de la chambre de combustion face à la pression atmosphérique. Dans le vide, une tuyère longue donnera un taux de détente plus important. Les gaz sortant du Viking 4 sont donc éjectés à la vitesse de pendant , en développant une poussée de . Le lanceur atteint l'altitude de et une vitesse proche de , puis intervient la séparation entre étages 2 et 3. Le L33 s'autodétruit une trentaine de secondes après cette séparation.

Situé au-dessus du deuxième étage et de même diamètre que ce dernier, il mesure de haut et contient d'ergols liquéfiés (O et H liquides). Il est propulsé par un moteur cryotechnique HM7, qui peut fournir une poussée de et dont la durée de fonctionnement est de . Au sommet de cet étage se trouve la case à équipements, qui contient le système de guidage de la fusée, ainsi que les différents systèmes assurant l'acquisition en temps réel par le contre de contrôle des données concernant sa mission.

La case à équipements est placée au sommet du et renferme les équipements qui permettent de piloter le lanceur. D'un diamètre de 2,6 mètres pour une hauteur de 1,15 mètres elles pèse 326 kg. La coiffe qui couronne le lanceur et protège la charge utile (satellite) et mesure 3,2 m de diamètre pour 8,65 m de hauteur (dimensions extérieures) et pèse 826 kg. 

Le lancement de la fusée est effectué suivant un minutage très précis, dont la référence est établie à H0, qui correspond au moment précis de la mise à feu des moteurs du premier étage du lanceur. Les opérations effectuées avant ce point de départ sont désignées par H0-x secondes, et celles effectuées après le départ de la fusée par H0+x secondes.


Le premier vol a lieu le et est un succès. Le deuxième se termina par une explosion au cours du décollage. Il y eut encore deux vols de qualification, à partir du , qui se déroulèrent cette fois sans problème. Lors du troisième vol, ce sont 3 satellites qui furent mis en orbite. Le , son cinquième vol, qui était le premier vol commercial, fut un échec. La fusée s'arrêta après sept minutes de vol. Après une revue profonde de toute la fusée, les six vols suivants se déroulèrent sans accroc. Le vol 14 du envoya la sonde Giotto vers la comète de Halley. Le dernier vol, le onzième d'Ariane 1, eut lieu le , il lança le premier satellite Spot.





</doc>
<doc id="14282" url="https://fr.wikipedia.org/wiki?curid=14282" title="Orbite de transfert géostationnaire">
Orbite de transfert géostationnaire

Une orbite de transfert géostationnaire est une orbite intermédiaire qui permet de placer des satellites en orbite géostationnaire. Le sigle anglais correspondant est "GTO", pour "".

C'est une orbite elliptique, dont le périgée se situe à basse altitude et l'apogée à l'altitude de l'orbite géostationnaire . Le périgée est approximativement à l'altitude de fin de combustion du dernier étage du lanceur, souvent une altitude de l'ordre de , équivalant à une valeur de périgée de . La valeur de l'apogée est approximativement de ou une altitude de par rapport au géoïde terrestre.

Une fois la charge utile — le satellite — arrivée à l'apogée, la propulsion est relancée pour circulariser l'orbite et modifier le plan de l'orbite, ce qui demande de modifier la vitesse (delta-V) d'environ . Cela est généralement assuré par un moteur-fusée à ergols solides ou liquides intégré au satellite (moteur d'apogée).

La manœuvre d'apogée doit comprendre également une impulsion permettant de changer le plan orbital (l'inclinaison de l'orbite). Car, après combustion du lanceur et séparation du satellite, l'orbite de transfert est inclinée par rapport au plan de l'équateur, d'un angle équivalent à la latitude de la base de lancement. Or, l'orbite géostationnaire est "obligatoirement" dans le plan de l'équateur. Cette manœuvre va donc consommer une part plus ou moins importante des ergols situés dans le satellite. D'où le plus grand intérêt des lancements d'une base située le plus proche possible de l'équateur. De plus, la rotation de la terre fournit une vitesse (appelé « effet fronde » de la Terre : à partir de Kourou, sachant que le satellite a une vitesse de pour une orbite basse), qui est d'autant plus grande qu'on est proche de l'équateur. C'est le grand intérêt — et le succès — du Centre spatial guyanais situé à seulement de latitude nord. Un lancement depuis l'équateur lui-même est encore plus performant, d'où la conception de la plateforme "Sea Launch".

La « sur-consommation » d'ergols pour les lancements depuis les autres ports spatiaux, aux latitudes plus élevées, sera préjudiciable à la durée de vie en orbite du satellite et donc de son économie (retour sur investissement).

À noter que cette orbite est très encombrée de débris spatiaux, dont les derniers étages des lanceurs.

Données sources d'une visite à Airbus Safran Launcher (ex Snecma), Vernon.




</doc>
<doc id="14283" url="https://fr.wikipedia.org/wiki?curid=14283" title="Ariane 2">
Ariane 2

Ariane 2 est la deuxième génération de la fusée Ariane.

La structure de l'Ariane 2 était identique à celle d'Ariane 1 avec un troisième étage H10 rallongé : la hauteur passant à 49 mètres et le poids à 219 tonnes.

Sa capacité d'emport en orbite de transfert géostationnaire était de , soit de plus qu'Ariane 1.

Ariane 3 qui était identique à Ariane 2, hormis l'ajout de deux propulseurs supplémentaires à poudre au niveau du premier étage, a volé avant Ariane 2.

Il y a eu six lancements d'Ariane 2. Le premier vol eut lieu le et fut un échec. Les autres vols seront des succès, le dernier lancement fut réalisé en 1989.



</doc>
<doc id="14284" url="https://fr.wikipedia.org/wiki?curid=14284" title="Céléno">
Céléno


</doc>
<doc id="14285" url="https://fr.wikipedia.org/wiki?curid=14285" title="Ariane 3">
Ariane 3

Ariane 3 était une fusée du programme européen Ariane qui permettait de placer des satellites en orbite autour de la Terre (on parle aussi de "lanceur").

Ariane 3 était identique à Ariane 2, une Ariane 1 avec un troisième étage allongé. Par rapport à Ariane 2, elle était équipée de 2 propulseurs supplémentaires à poudre, ce qui portait sa masse à .

Sa capacité d'emport en orbite de transfert géostationnaire était de 2 700 kg, soit de plus qu'Ariane 2 et de plus qu'Ariane 1.

Son premier vol eut lieu, avec succès, le , avec le satellite Telecom 1A. Fait particulier, Ariane 3 a volé avant Ariane 2 ( le 31 mai 1986).

Ariane 3 effectuera en tout onze vols. Seul le cinquième, le , sera un échec.

Le nombre réduit de vols des Ariane 2 et 3 s'explique par l'arrivée d'Ariane 4, qui était plus puissante et plus modulaire (6 versions différentes).

Le dernier vol a eu lieu le 12 juillet 1989 avec le satellite Olympus-1. Il y eut au total 10 vols utilisant le SYLDA (SYstème de Lancement Double Ariane) et un vol ne lançant qu'un satellite.


</doc>
<doc id="14287" url="https://fr.wikipedia.org/wiki?curid=14287" title="Double fécondation">
Double fécondation

En botanique, la double fécondation (ou xénie) est une fonction particulière à la reproduction des angiospermes. Le grain de pollen contient deux noyaux (tous haploïdes), alors que par exemple le spermatozoïde des mammifères n'en contient qu'un. Un de ces noyaux est destiné à féconder l'oosphère, ce qui donnera l’embryon, à l’origine de la future plante. Le deuxième s'unit aux noyaux polaires à l'origine de l'albumen, tissu alors triploïde (3n chromosomes) qui fait partie de la graine et qui servira généralement à nourrir l'embryon



</doc>
<doc id="14288" url="https://fr.wikipedia.org/wiki?curid=14288" title="Haploïde">
Haploïde

Une cellule biologique est haploïde (du grec ἁπλόος ("haploos"), simple et εἶδος ("eidos"), en forme de) lorsque les chromosomes qu'elle contient sont chacun en un seul exemplaire (n chromosomes). Le concept est généralement l'opposé de diploïde, terme désignant les cellules avec des chromosomes en double exemplaire (2n chromosomes).

Un organisme ou une partie d'organisme sont dits haploïdes lorsque ses cellules sont elles-mêmes haploïdes.

Ces définitions ne concernent que les organismes eucaryotes (Protistes, Animaux, Végétaux, Champignons), qui possèdent de vrais chromosomes. Elle exclut donc par exemple les bactéries qui n'ont pas de noyau et possèdent des chromosomes d'un type particulier.

Chez les humains, et la plupart des animaux, la phase haploïde (n) est très réduite. Elle correspond à la formation des gamètes : spermatozoïde ou ovocyte. L'organisme (le corps) se développe en phase diploïde (2n): les cellules contiennent chacune les chromosomes en double exemplaire.

Chez les mousses et chez certaines algues, la partie végétative développée de l'organisme correspond à la phase haploïde (n).
La phase diploïde (2n) est au contraire beaucoup plus limitée (restreinte au zygote, voire inexistante). Chez les Angiospermes, il est possible d'obtenir des plantes entières haploïdes (des gamétophytes) par culture "in vitro" de microspores - avant ou au moment de la première mitose pollinique .

Le mâle chez les abeilles, le faux-bourdon, est issu d'un ovule de reine non fécondé et donc il est également haploïde.

Un organisme est haploïde lorsque dans son cycle de développement, la méiose suit directement la fécondation. C'est le cas chez Sordaria (un champignon), où la formation de la cellule-œuf grâce à la fécondation, est suivie d'une méiose et d'une mitose, qui conduit à la création de spore.

La double haploïdie, aussi appelée haplodiploïdisation, dihaploïdie ou technique des haploïdes doublés, est une technique de sélection variétale consistant à prélever des cellules haploïdes issues de gamètes d'une plante pour provoquer le doublement de leur stock chromosomique afin d'obtenir une lignée stable (ou lignée pure) en seulement deux générations.



</doc>
<doc id="14289" url="https://fr.wikipedia.org/wiki?curid=14289" title="Diploïde">
Diploïde

Une cellule biologique est diploïde (du , "diploos", « "double" » et "eidos", « "en forme de" ») lorsque les chromosomes qu'elle contient sont présents par "paires" (2n chromosomes). Le concept est généralement opposé à haploïde, terme désignant les cellules avec des chromosomes en simple exemplaire (n chromosomes).

Une cellule compte alors deux allèles pour chacun de ses gènes (exception faite des parties spécifiques aux chromosomes sexuels), les deux chromosomes d'une même paire possédant les mêmes gènes. Ces deux versions sont d'origine maternelle pour l'une et paternelle pour l'autre, et ont été rassemblées lors de la fécondation (rencontre de deux cellules haploïdes).

Un organisme ou une partie d'organisme est dit diploïde lorsque ses cellules sont elles-mêmes diploïdes.

Ces définitions ne concernent que les organismes eucaryotes (protistes, animaux, végétaux, champignons), qui possèdent de vrais chromosomes. Elles excluent donc par exemple les bactéries qui n'ont pas de noyau et possèdent des chromosomes d'un type particulier.

Chez les humains et la plupart des animaux, la phase diploïde ("2n") est très dominante. L'organisme (le corps) se développe entièrement avec des cellules qui contiennent chacune les chromosomes en double versions. La phase haploïde ("n"), quant à elle, ne concerne que la formation des gamètes : spermatozoïde ou ovule.
Chez les mousses, chez certaines algues, le schéma est inversé : la phase diploïde (2n) n'accompagne que très brièvement la fécondation. Le végétal se développe grâce à la méiose, sous forme haploïde (n). Chez les fougères et les plantes à graines (ou spermaphytes), la phase diploïde prédomine.

La diploïdie a pu être favorisée parce qu'elle permet de réparer les cassures doubles-brins de l'ADN. Elle permet également de masquer l'effet des mutations délétères, qui sont pour la plupart récessives.



</doc>
<doc id="14294" url="https://fr.wikipedia.org/wiki?curid=14294" title="Intégration (mathématiques)">
Intégration (mathématiques)

En mathématiques, l'intégration est le fait de calculer une intégrale. C'est aussi une des deux branches du calcul infinitésimal, appelée également calcul intégral, l'autre étant le calcul différentiel.

Les opérations de mesure de grandeurs (longueur d'une courbe, aire, volume, flux...) et de calcul de probabilités étant souvent soumises à des calculs d'intégrales, l'intégration est un outil scientifique fondamental. C'est la raison pour laquelle l'intégration est souvent abordée dès l'enseignement secondaire.

Les différents domaines dans lesquels peuvent se rencontrer des intégrales ont conduit à donner des définitions différentes de l'intégrale permettant d'en calculer pour des fonctions de moins en moins régulières. On rencontre ainsi les intégrales dites de Riemann, de Lebesgue ou de de Kurzweil-Henstock. Mais toutes ces définitions coïncident dans le cas des fonctions continues.

Le symbole mathématique représentant l'intégration, formula_1, est appelé "signe somme", "signe d'intégration," "signe intégral" ou "intégrateur" ; il a été introduit par Leibniz.

Le présent article décrit l'intégrale des fonctions d'une variable réelle. Pour les extensions aux fonctions de plusieurs variables, voir les articles intégrale curviligne, intégrale multiple et intégrale de surface. Le cas général de l'intégrale des fonctions définies sur un espace mesurable muni d'une mesure positive est traité dans l'article intégrale de Lebesgue. Une autre extension est l'intégrale des formes différentielles.

Dans un plan muni d'un repère cartésien, on choisit comme unité d'aire, l'aire du quadrilatère OIKJ où O est l'origine du repère et I, J et K les points de coordonnées respectives (1 ; 0), (0 ; 1) et (1 ; 1).

Si est une fonction réelle positive continue prenant ses valeurs dans un segment , alors l'intégrale de sur , notéeformula_2est l'aire d'une surface délimitée par la représentation graphique de et par les trois droites d'équation , , , surface notée . (Voir schéma ci-contre pour l'intervalle .)

formula_3

On donne un signe positif à l'aire des surfaces comme situées au-dessus de l'axe des abscisses. Pour pouvoir traiter aussi les fonctions négatives, on donne un signe négatif aux portions situées sous cet axe.

Ainsi, pour définir l'intégrale d'une fonction continue dans le cas général (positive ou négative), il suffit de définir et , communément appelées parties positive et négative de respectivement, comme suit :

puis de définir l'intégrale de à partir de et , fonctions continues et positives :

Plus précisément, définir l'aire de cette surface consiste, dans la définition de la théorie de Riemann, à approcher par une suite de fonctions dont on connait l'intégrale (en général : des rectangles qu'on définit d'aire ) et telle que la différence entre et tende vers 0 quand tend vers l'infini.

Il se trouve qu'avec cette méthode, il est possible de définir l'aire d'une fonction continue bornée présentant un ensemble dénombrable de points de discontinuité.
On appelle un intégrande, et on note ∫ (un s allongé, mis pour somme) l'opérateur mathématique, appelé intégrateur, qui est associé à l'intégration. Ce symbole est un ancien "s" long : en effet, Leibniz s'est servi de l'initiale du mot latin "summa", « somme », lequel était le plus souvent écrit "ſumma". À la différence du "s" long, "∫", en typographie, garde toujours une hampe descendant au-dessous de la ligne de base, en romaine comme en italique. "(Voir l'article Notation de Leibniz pour une justification de la notation complète, et en particulier du symbole d"x".)."

Le but du calcul intégral est de développer des méthodes permettant de calculer les intégrales. La principale méthode pour calculer une intégrale passe par la notion de primitive d'une fonction. La « primitivation » est l'opération qui, à partir d'une fonction , donne une fonction dérivable et dont la dérivée est égale à : .

On montre que toute fonction continue sur un segment admet des primitives, et que l'intégrale de à est égale à , indépendamment de la primitive choisie.

formula_7

De plus l'ensemble des primitives d'une fonction continue sur un intervalle I est donné par l'ensemble de ses intégrales indéfinies

formula_8
où est un point de I et K un réel quelconque.

Le théorème fondamental de l'analyse affirme que les deux approches de l'intégrale (« aire sous une courbe » et « primitivation »), sont sous certaines conditions les mêmes. Ces conditions peuvent varier selon le type d'intégrale considéré. Ainsi, les fonctions qui admettent des primitives presque partout, sont aussi intégrables au sens de Kurzweil-Henstock, mais pas nécessairement au sens de Riemann ou au sens de Lebesgue.

L'histoire des mathématiques doit beaucoup à la théorie de l'intégration, et sa place prédominante a façonné l'analyse en offrant à qui une solution, à qui un problème. Le lustre des « méthodes intégrales » en Grèce antique l'atteste (voir méthode d'exhaustion), et bien qu'il faille attendre le calcul infinitésimal pour une première formalisation, elles nous avaient déjà offert de profonds et beaux résultats : les Athéniens évaluèrent les grandeurs de l'espace puis en démontrèrent implicitement l'existence et l'unicité ; au naissent des méthodes générales de « calcul de l'infini » (rectification de courbes, quadratures, etc.) C'est alors que la méthode des indivisibles de Cavalieri voit le jour.

C'est Leibniz qui opère le fondement de la théorie de l'intégration ("Geometria recondita", 1686), perpétué jusqu'aujourd'hui, d'une part par un symbolisme inégalé reliant intégration et dérivation, d'autre part par la mise en place des principaux théorèmes.

La formalisation de cette théorie a revêtu diverses formes. Elle aboutit tardivement, à cause de la complexité des problèmes soulevés :

L'intégrale de Riemann (Bernhard Riemann, 1854, publication posthume en 1867) puis l'intégrale de Lebesgue (Henri Lebesgue, 1902) ont marqué les esprits par leur formalisation aboutie. L'intégration est encore un sujet pour la recherche contemporaine ; en témoignent des extensions telles que l'intégrale d'Itō, l'intégrale de Kurzweil-Henstock, ou la récente construction de Bongiorno (1996).

Le schéma général utilisé pour construire une intégrale et qui cherche à mesurer l'aire du domaine sous la courbe est le même pour les trois approches de l'intégration :

D'abord, on considère une famille de fonctions élémentaires, pour lesquelles nous avons un moyen évident de mesurer l'aire sous la courbe. Dans le cas de l'intégrale de Riemann ou de Kurzweil-Henstock, ce sont les fonctions en escalier dont l'aire sous la courbe est égale à la somme des aires des rectangles ; les fonctions en escalier étant constantes sur des intervalles, le domaine sous la courbe d'une telle fonction peut alors être vu comme une réunion de rectangles. Pour l'intégrale de Lebesgue, les fonctions élémentaires sont les fonctions étagées, constantes, non plus sur des intervalles, mais sur des parties mesurables (approche plus souple et plus générale).

L'intégrale de Riemann permet d'intégrer entre autres les fonctions croissantes ou décroissantes, et les fonctions continues, donc aussi les fonctions continues par morceaux, ainsi que les fonctions monotones par morceaux. Toute limite uniforme d'une suite de fonctions intégrables au sens de Riemann est intégrable au sens de Riemann. Cependant une limite simple (c'est-à-dire que pour tout de l'intervalle sans condition d'uniformité en ) de fonctions Riemann intégrables n'est pas nécessairement Riemann intégrable. Il est possible de caractériser les fonctions intégrables au sens de Riemann : ce sont les fonctions bornées dont l'ensemble des points de discontinuité est de mesure nulle (critère de Lebesgue).

L'intégration au sens de Lebesgue permet d'intégrer plus de fonctions (dont des fonctions qui ne sont même pas localement bornées), et elle donne la même valeur à l'intégrale lorsque la fonction est déjà intégrable au sens de Riemann. Elle a l'avantage de munir l'espace vectoriel des fonctions intégrables (modulo l'égalité presque partout) d'une structure d'espace normé complet. Ceci est essentiel pour beaucoup d'applications. Cependant, on perd la notion de sommes de Riemann, et il existe des contextes (étude des suites uniformément distribuées par exemple) où les fonctions intégrables au sens de Riemann surviennent naturellement ; pour une généralisation de cette dernière permettant néanmoins d'intégrer également toutes les fonctions mesurables (au sens de Lebesgue), voir l'intégrale de Kurzweil-Henstock.

Si sur le segment (ainsi est inclus dans ), alors nous aurons .

Si l'on suppose par exemple la fonction monotone sur , il est possible d'approcher son aire en utilisant soigneusement une fonction élémentaire (dans le cas de l'intégration de Riemann ou de Kurzweil-Henstock, une fonction en escalier, et dans le cas de l'intégration de Lebesgue, une fonction étagée). Nous choisissons telle que mais en supposant très proche de , au sens où, ayant préalablement fixé un arbitrairement petit, les valeurs prises par s'éloignent de celles prises par d'au plus , ce qui se note formula_9.

L'aire sous , facilement calculable comme somme d'aires de rectangles, est majorée par l'intégrale de , et est appelée somme inférieure.

Dans le cas de l'intégrale de Riemann ou de Kurzweil-Henstock, nous fabriquons aussi des sommes supérieures de la même façon : nous choisissons une fonction en escalier, disons , telle que en supposant de la même manière très proche de , et nous considérons une somme supérieure comme un majorant de l'aire du domaine sous . Dans le cas de l'intégrale de Riemann, les rectangles utilisés ont des bases de longueur majorée par une constante ; dans le cas de l'intégrale de Kurzweil-Henstock, les rectangles ont des bases de longueur variable. La théorie de Lebesgue n'utilise pas de sommes supérieures.

On montre que l'ensemble des aires sous les fonctions que l'on peut choisir (respectivement sous les fonctions dans la théorie de Riemann ou de Kurzweil-Henstock), admet une borne supérieure (resp. inférieure, et c'est la même). Cette valeur est alors appelée intégrale de sur .

Les fonctions que nous pouvons intégrer sont appelées fonctions "intégrables".

Cependant, les différences commencent ici ; la théorie de Riemann est de loin la plus simple, mais de cette simplicité résulte que l'ensemble des fonctions intégrables est plus restreint que celui de la théorie de Lebesgue ou de Kurzweil-Henstock. En plus, l'interaction entre les limites et l'intégrale sont plus difficiles à décrire dans la théorie de Riemann.

La généralisation de l'intégrale à un intervalle quelconque se fait en se basant sur la notion d'intégrale définie sur un segment.

Soit une fonction à valeurs réelles positives, continue définie sur un intervalle quelconque, noté, où est réel ou égal à et est réel ou égal à ), et les parenthèses signifiant [ ou ] (exclusion si valeur infinie).

On dit que est intégrable sur l'intervalle lorsque l'ensemble formula_10 est majoré. Partie non vide et majorée de ℝ, il admet une borne supérieure : on la note alors formula_11 et on l'appelle intégrale de sur .

Avec ces mêmes données, on a l'équivalence logique : intégrable sur si et seulement si toute primitive de sur admet une limite finie en et en .

Dans le cas où une fonction est intégrable sur un intervalle , on aformula_12

Enfin, pour une fonction continue définie sur un intervalle quelconque et à valeurs dans ℂ, on pose par définition : intégrable sur si intégrable sur en tant que fonction à valeurs réelles positives.

De même pour continue définie sur et à valeurs dans un espace vectoriel normé , est intégrable sur si et seulement si est intégrable sur en tant que fonction à valeurs réelles positives.

Il se peut très bien que « l'aire sous la courbe » d'une fonction définie et continue sur et à valeurs réelles (changeant de signe) ait une limite en faisant tendre les extrémités d'une suite de segments inclus dans vers les bornes de , sans toutefois que la fonction en jeu soit intégrable sur au sens de la définition. On parle alors d'intégrale semi-convergente, la valeur de l'aire trouvée est appelée Intégrale impropre. C'est le cas avec l'exemple classique de la fonction de dans ℝ qui à tout associe : elle peut être prolongée continûment par 1 en zéro mais le problème de l'intégrabilité se pose au voisinage de . On peut calculer son intégrale impropre (puisqu'elle n'est que semi-convergente) : on trouve formula_13.

Pour toute fonction continue (ou même seulement continue par morceaux) sur un segment tel que , la valeur moyenne de sur est le réel défini par :formula_14Cette notion généralise celle de moyenne d'un nombre fini de réels en l'appliquant à un nombre infini de valeurs prises par une fonction intégrable. Elle sert par exemple dans la décomposition en série de Fourier d'une fonction périodique : c'est la composante constante. En traitement du signal, pour les signaux périodiques, il s'agit de la composante continue (offset).

On peut aussi, par analogie avec les moyennes pondérées d'un nombre fini de réels, affecter « à chacune des valeurs prises par la fonction » un coefficient strictement positif. On utilise alors ce que l'on appelle une fonction poids formula_15 (formula_16 pour l'initiale de "", poids en anglais) :formula_17 

Ce procédé peut aussi s'utiliser sur un intervalle ouvert ou semi-ouvert mais borné (c.-à-d. aucune de ses bornes n'est infinie) où la fonction est intégrable. On peut citer l'exemple classique servant à montrer l'orthogonalité de la famille des polynômes de Tchebychev :formula_18où la fonction est continue sur le fermé et où la fonction poids est formula_19Son intégrale est bien définie et vaut .

Soient une fonction continue sur et et trois réels de .

Soient et deux fonctions continues sur et deux réels de .


Soient et deux fonctions continues sur et deux réels de .
Soient et deux fonctions de classe C (i. e. dérivables de dérivées continues sur le segment ) : 
formula_28

Soit une fonction numérique continue, et une fonction de classe C sur dont l'image est contenue dans le domaine de définition de . Alors :
formula_29

On ne connaît pas toujours une formule pour décrire une fonction, par exemple dans le cas d'une courbe expérimentale. Dans d'autres cas, on ne connaît pas de méthode analytique pour exprimer la primitive, ou bien on n'a pas besoin de l'expression analytique et seule la valeur numérique suffit. On a recours dans ces cas-là à une méthode numérique.

Les méthodes numériques consistent à prendre une suite de valeurs , les valeurs des étant si possible équidistantes : . On peut ensuite appliquer différentes méthodes, dont les deux principales consistent à faire la somme d'aires "S" :
Les méthodes numériques sont automatisables sur les ordinateurs et calculatrices programmables.

D'autres méthodes sont possibles.

On peut utiliser des méthodes graphiques utilisant le fait que la valeur de la fonction en un point est la pente de la primitive.

Considérant le même découpage que précédemment, on découpe l'intervalle d'intégration en bandes verticales de largeur centrées sur les valeurs . Sur un graphique voisin, le graphique polaire, on place des vecteurs formula_32 à l'origine O et l'on considère un point P sur l'axe des , distant de O ; P est appelé le pôle. Si l'on relie P aux extrémités des vecteurs, on obtient des droites dites polaires, dont les coefficients directeurs sont proportionnels aux valeurs de : formula_33

On reporte ensuite les directions de ces droites polaires pour former un polygone funiculaire. L'axe des ordonnées est à une échelle 1/OP. L'ordonnée de départ du funiculaire correspond à la constante d'intégration.

Si, au lieu de placer l'origine des vecteurs en O, on les met bout à bout, on effectue alors une double intégration, puisque les valeurs sont cumulées. Le pôle n'est plus nécessairement sur l'axe des ; cela incline différemment la courbe obtenue, et correspond à la constante d'intégration de la première intégrale. Ceci est par exemple appliqué pour déterminer le diagramme des moments fléchissants d'une poutre en flexion à partir des charges, ou bien la forme de cette poutre à partir du diagramme des moments fléchissants.
Il est possible d'estimer la valeur d'une intégrale par des mesures physiques. Par exemple, on trace la courbe sur une feuille de papier, on découpe la feuille suivant le tracé puis on pèse le résultat. En effet, si la masse surfacique est uniforme, alors le poids mesuré est proportionnel à l'aire. Ce principe était notamment utilisé pour déterminer l'aire d'un pic dans des mesures, par exemple pour faire de l'analyse quantitative par diffractométrie X.

On peut utiliser d'autre phénomènes physiques « intégrateurs », comme le chauffage d'un corps :
puisque la variation de température est reliée à la chaleur reçue par l'équation :
Cette variation est donc proportionnelle à l'intensité par la loi d'Ohm :
soit




</doc>
<doc id="14301" url="https://fr.wikipedia.org/wiki?curid=14301" title="Indice de confiance">
Indice de confiance

En économie, un indice de confiance est un chiffre calculé qui aide à prévoir la consommation future des ménages ou entreprises. Il sert donc à émettre des prévisions sur la croissance économique. Autre signification : l'indice de confiance de prévision météorologique, qui indique si les prévisions sont fiables (indice de 5) ou pas (indice de 0).

Il existe divers indices de confiance et plusieurs instituts chargés de les calculer.




</doc>
<doc id="14302" url="https://fr.wikipedia.org/wiki?curid=14302" title="John William Strutt Rayleigh">
John William Strutt Rayleigh

John William Strutt, troisième baron Rayleigh, plus connu sous son titre lord Rayleigh ( à Landford Grove, Essex, Angleterre - à Witham, Essex, Angleterre) était un physicien anglais. Il est lauréat du prix Nobel de physique de 1904.

John William Strutt est né le 12 novembre 1842 près de Maldon dans l'Essex.

Il fait des études de mathématiques à Trinity College (Cambridge), dont il sort diplômé en 1865, obtenant le titre de "Senior Wrangler" au Tripos de mathématiques de 1868.

Après quelques voyages en Europe et aux États-Unis, il occupe un poste de chercheur au Trinity College de 1866 à 1871. Ses travaux sont momentanément suspendus durant le conflit franco-prussien de 1870, par son impact sur la famille de John William, pourtant peu impliquée.

En 1871, il se marie avec Evelyne Georgiana Mary Balfour, fille de James Maitland Balfour et de sa femme Blanche, fille du second marquis de Salisbury. De ses trois fils, l'aîné devient professeur de physique à l"'Imperial College of Science and Technology" de Londres.

À la mort de son père en 1872, il prend sa succession et devient baron Rayleigh, troisième du titre, et consacre une partie importante de son temps à la gestion du domaine. Afin de pouvoir se consacrer à la science, il abandonne cette responsabilité à son jeune frère en 1875.

En 1879, il accepte la place laissée vacante au laboratoire Cavendish de Cambridge par la disparition de Maxwell.

À partir de 1884, il poursuit ses recherches en grande partie dans son domaine de Terling où il installe un laboratoire.

Il est « "" » puis « "Scientific Advisor to Trinity House" » jusqu'à sa mort le 30 juin 1919.

Aux dires de ses compatriotes, c'est l'un des très rares nobles de haut rang à être devenu célèbre par des découvertes scientifiques.

Les premiers travaux de Lord Rayleigh consistent en l'approche mathématique de l'optique et des systèmes vibratoires, puis s'étendent à pratiquement toute la physique de l'époque : le son, les vibrations, la vision des couleurs, l'électrodynamique, l'électromagnétisme, la diffraction de la lumière, la mécanique des fluides, la viscosité, la capillarité, l'élasticité et la photographie.

Parmi ses premiers travaux, on note une théorie de la résonance qui fit de lui une autorité en acoustique.

Son traité sur le son, écrit lors d'une croisière sur le Nil et enrichi de mises à jour, a longtemps eu valeur de référence.

En 1871, il fournit une explication de la couleur du ciel en la reliant à la diffusion de la lumière par les molécules d'air.

Dans les années 1880, il contribue à la définition des unités fondamentales de l'électricité : l'ampère, l'ohm et le volt.

En 1892, il détermine la masse volumique de l'azote. En 1894, il découvre l'argon avec sir William Ramsay.

En 1892, Rayleigh réussit à déterminer les dimensions de certaines molécules par l'étude des couches minces. Examinant un rapport d'expérience de Cavendish daté de 1795, alors qu'il étudiait la densité des gaz en collaboration avec Ramsay, Rayleigh découvre un nouveau constituant de l'air, l'argon. Ramsay reçoit pour cette découverte le prix Nobel de chimie de 1904, alors que Rayleigh reçoit le prix Nobel de physique de 1904 .

L'intérêt marqué de Rayleigh pour l'optique, comme pour tous les phénomènes ondulatoires en général, le conduit à des recherches en spectroscopie. Il établit avec le mathématicien et astronome James Jeans, en utilisant pour cela la mécanique statistique, une loi théorique, connue sous le nom de loi de Rayleigh-Jeans, qui exprime la répartition de l'énergie rayonnée par le corps noir en fonction de la longueur d'onde, valable pour les grandes longueurs d'onde. En introduisant les quanta, Max Planck déterminera la loi générale quelques mois plus tard, en faisant la synthèse des travaux de Rayleigh et de Wien.

Rayleigh eut un rôle institutionnel important pour le développement de la science britannique en général, et de la physique en particulier.

Dès le congrès de 1882 de la "British Association for the Advancement of Science", il en présida la section mathématiques-physique.

Membre, dès 1876, de la "Royal Society", il en devient le secrétaire de 1885 à 1896, puis le président. Pendant quinze ans, il est conseiller de "Trinity House", organisme chargé de l'installation et de l'entretien d'installations côtières.

Il contribue grandement à la création du "National Physical Laboratory" de Teddington, dont il présida le conseil exécutif.

Il fut aussi chancelier de l'Université de Cambridge.

Ses écrits sont reconnus de très haute qualité rédactionnelle. Il a notamment laissé :

Parmi d'innombrables distinctions et titres honorifiques :

Une unité d'intensité lumineuse, le rayleigh, a porté son nom, qui reste également attaché à l'onde sismique superficielle, l'onde de Rayleigh.




</doc>
<doc id="14304" url="https://fr.wikipedia.org/wiki?curid=14304" title="Programme Voyager">
Programme Voyager

Le programme "Voyager" est un programme d'exploration robotique de l'agence spatiale américaine de la NASA dont l'objectif est d'étudier les planètes extérieures du Système solaire. Il comprend deux sondes spatiales identiques "Voyager 1" et "Voyager 2" lancées en 1977 qui ont survolé les planètes Jupiter, Saturne, Uranus, Neptune ainsi que 48 de leurs satellites. Les données collectées par les 9 instruments portés par chaque sonde en font sans doute la mission d'exploration du Système solaire la plus fructueuse sur le plan scientifique de toute l'histoire spatiale. Les sondes Voyager sont les premières à effectuer un survol d'Uranus et Neptune et les secondes à étudier Jupiter et Saturne. Voyager 1 et 2 ont permis d'obtenir des informations détaillées sur l'atmosphère de Jupiter, Saturne et Uranus. Elles ont révélé de nombreux détails sur la structure des anneaux de Saturne, permis de découvrir les anneaux de Jupiter et ont fourni les premières images détaillées des anneaux d'Uranus et de Neptune. Les sondes ont découvert en tout 33 nouvelles lunes. Elles ont révélé l'activité volcanique de Io et la structure étrange de la surface de la lune galiléenne Europe.

La NASA met sur pied en 1972 le programme Voyager pour exploiter une conjonction des planètes extérieures exceptionnelle qui doit permettre aux sondes de survoler plusieurs des planètes pratiquement sans dépense en carburant, en utilisant l'assistance gravitationnelle. Malgré les contraintes budgétaires liées à un climat économique et politique peu favorable à l'espace, la NASA après avoir renoncé à un projet plus ambitieux, parvient à construire deux engins parfaitement adaptés à ce programme complexe comme vont le prouver la longévité et la qualité du matériel scientifique récolté par les deux sondes. Voyager 1 et 2 sont dans leur catégorie des engins lourds, emportant plus de d'instrumentation scientifique à comparer à la masse totale des sondes Pioneer lancées en 1972-1973 qui ont pénétré pour la première fois dans les régions externes du système solaire et survolé Jupiter et Saturne.

Les sondes Voyager sont, en 2014, toujours en état de fonctionnement ; plusieurs de leurs instruments continuent à transmettre des informations sur le milieu environnant. . . Se déplaçant à plus de par rapport au Soleil, Voyager 1, porteur d'un message symbolique de l'Humanité, devrait être la première sonde spatiale à passer à proximité d'une autre étoile dans ans. Bien avant, vers 2020, la sonde aura cessé de fonctionner du fait de la défaillance des thermocouples des générateurs thermoélectriques à radioisotope qui lui fournissent son énergie.

Au début de l'ère spatiale, l'exploration du Système solaire se limite à l'envoi de sondes spatiales vers les planètes intérieures proches : Mars et Vénus. Mercure et les planètes extérieures du Système solaire, de Jupiter à Pluton, sont des objectifs difficiles à atteindre pour un engin spatial : pour y parvenir, celui-ci doit être lancé avec une vitesse qui nécessite un lanceur très puissant dont l'agence spatiale américaine ne dispose pas au début des années 1960. À l'époque, la conception des sondes spatiales en est à ses balbutiements et leur fiabilité est limitée. Au début des années 1960, américains comme soviétiques lancent généralement leurs sondes spatiales par paire pour accroitre la chance que l'une d'entre elles remplissent les objectifs de la mission. La durée importante du transit d'une sonde spatiale vers les planètes externes (plusieurs années) s'accompagne d'une dégradation progressive de certains organes et augmente la probabilité de panne. Par ailleurs, au fur et à mesure de l'éloignement du Soleil, la diminution du rayonnement solaire réduit l'énergie disponible et la distance limite le débit des transmissions et nécessite un fonctionnement en quasi-autonomie.

L'origine du programme Voyager remonte au milieu des années 1960. À l'époque, Michael Minovich du Jet Propulsion Laboratory (JPL), établissement de la NASA spécialisé dans l'exploration robotisée du Système solaire, attire l'attention sur le fait que la gravité très élevée de Jupiter peut être utilisée pour accélérer une sonde spatiale (mécanisme d'assistance gravitationnelle) vers les planètes les plus lointaines du Système solaire. Trois ans plus tard, Gary Flando également du JPL, constatant une conjonction unique de planètes qui doit se produire entre 1976 et 1978, met au point des trajectoires utilisant cette technique qui doivent permettre à une sonde spatiale de visiter plusieurs planètes extérieures. Une sonde lancée durant cette période pourra au choix survoler successivement soit Jupiter, Saturne, Uranus et Neptune, soit Jupiter, Uranus et Neptune, soit enfin Jupiter, Saturne et Pluton. La configuration qui permet le survol des quatre planètes gazeuses par le même engin spatial ne se reproduit que tous les 176 ans. La NASA décide de concevoir une sonde spatiale pouvant profiter de cette conjonction.

À la fin des années 1960, dans l'euphorie des succès du programme Apollo, la NASA imagine de lancer plusieurs sondes de grande taille en utilisant la fusée lunaire Saturn V. Dans cette optique, l'agence spatiale définit les caractéristiques d'une nouvelle famille de sondes dédiées à l'exploration des planètes extérieures qui est baptisée « Thermoelectric Outer Planets Spacecraft » (TOPS) ; ces sondes doivent avoir recours à des générateurs thermoélectriques à radioisotope qui fournissent l'énergie en se substituant aux panneaux solaires utilisés habituellement. Le programme Grand Tour renommé par la suite « Outer Planets Grand Tour Project » (OPGTP) est mis sur pied en 1969. Il prévoit le lancement de 4 à 5 sondes reposant sur le concept TOPS dont deux, lancées en 1976 et 1977, doivent survoler Jupiter, Saturne et Pluton tandis que deux autres, lancées en 1979, doivent survoler Jupiter, Uranus et Neptune. Le coût du programme est compris entre 750 et 900 millions de dollars auxquels il faut ajouter 106 millions US$ pour le lancement. Les postes de dépense les plus importants étaient associés au développement d'un ordinateur permettant à la sonde spatiale de fonctionner de manière autonome et baptisé STAR (Self-Test And Repair computer) et l'autre au développement de la plateforme des TOPS.

Le début des années 1970 est une période de récession économique pour les États-Unis qui se traduit notamment par une forte réduction des budgets accordés à la NASA. Par ailleurs, la compétition avec l'Union soviétique n'est plus aussi vive et ne permet pas de motiver les décideurs politiques comme l'opinion publique à investir dans le spatial. Plusieurs motifs se conjuguent pour entrainer l'annulation du programme Grand Tour. Le budget alloué à la NASA qui avait crû dans des proportions énormes au milieu des années 1960 pour le programme Apollo est en forte réduction. Au sein des programmes de la NASA, le programme Grand Tour est en concurrence avec d'autres grands projets : le grand télescope spatial (futur télescope spatial Hubble) et le programme de la navette spatiale américaine tandis que le développement du programme Viking va de dépassement en dépassement. La communauté scientifique, dont les représentants sont réunis par la NASA au mois d'août 1971, donne son appui au projet Grand Tour et la NASA décide à l'automne de soumettre un budget incluant à la fois le développement de la navette spatiale américaine et le projet Grand Tour. Mais le président Nixon, favorable au développement de la navette spatiale, n'est pas prêt à financer les deux projets. C'est à l'administrateur de la NASA de l'époque, James Fletcher, de trancher. Celui-ci décide en décembre 1971 de retirer le projet d'exploration des planètes externes de sa proposition de budget 1973 et de le remplacer par la réalisation de deux petites sondes spatiales Mariner qui seraient lancées en 1977. 

Dès juillet 1972, la NASA a lancé un projet d'exploration des planètes à faible coût baptisé "Mariner Jupiter/Saturn 1977" (MJS). Pour un tiers du prix du Grand Tour (361 millions US$ contre 1 milliard US$), ce projet doit permettre de suivre les recommandations du Space Science Board. Le nouveau programme prévoit la fabrication de deux sondes spatiales dérivées de la famille Mariner mise en œuvre pour l'exploration des planètes intérieures. Par rapport au programme Grand Tour, l'objectif scientifique est réduit au survol des deux principales planètes externes Jupiter et Saturne. Le nouveau projet est accueilli favorablement par la communauté scientifique (qui émet néanmoins le souhait que le vol des sondes spatiales pourra prolonger leur exploration au-delà de l'orbite de Saturne). Le budget est débloqué par le Sénat américain en 1973. Une enveloppe budgétaire de 250 millions US$ doit couvrir à la fois les coûts de fabrication et les coûts opérationnels. La NASA décide de confier la conception et le développement des sondes spatiales à son centre Jet Propulsion Laboratory au lieu de le sous-traiter aux sociétés Boeing, General Electric, Hughes, Martin Marietta ou North American Rockwell qui avaient travaillé sur le programme Grand Tour. Officiellement, cette mesure doit permettre de réduire les coûts mais les dirigeants de la NASA visent également à maintenir une expertise dans le domaine de la conception des sondes planétaires, Les sondes baptisées, qui portent les noms de Mariner 11 et 12, sont conçues pour une durée de vie de 4 ans suffisante pour le survol de Jupiter et de Saturne contre 10 ans pour les sondes TOPS du programme Grand Tour. 

Le projet est lancé officiellement le et la première réunion du groupe de travail scientifique chargé de fixer les objectifs détaillés de la mission a lieu en décembre 1972. La fabrication des sondes spatiales démarre en mars 1975 avec l'achèvement de la phase de conception. Les sondes à faible coût Pioneer 10 (lancée en 1972), et 11 (lancée en 1973), chargées de reconnaître le parcours, apportent des informations vitales sur la forme et l'intensité du rayonnement autour de la planète Jupiter (1000 fois plus intense que prévu) et confirment qu'il existe bien une région dégagée d'obstacles entre l'atmosphère supérieure de Saturne et l'anneau interne de la planète géante. Ces informations sont prises en compte dans la conception des Voyager et dans la sélection des instruments scientifiques. 

L'expérience acquise avec la série particulièrement réussie des sondes spatiales Mariner développées par le JPL est largement mise à profit pour le développement des sondes Voyager. Mais pour obtenir la fiabilité et les performances recherchées, les ingénieurs du JPL utilisent également des sous-systèmes des orbiters Viking. La durée de vie des batteries développées par la Commission de l'énergie atomique est portée à 10 ans à la demande de la NASA. Une enveloppe supplémentaire de 7 millions US$ est débloquée par le Congrès américain pour financer des améliorations scientifiques et technologiques dont le développement d'un ordinateur reprogrammable en vol qui jouera un rôle crucial durant la mission de Voyager 2. L'objectif officiel du programme était le survol uniquement des deux géantes gazeuses. La fenêtre de lancement des sondes spatiales est identique à celle du Grand Tour et permet donc également le survol d'Uranus et Neptune. Les ingénieurs impliqués dans la réalisation des sondes, contrevenant aux spécifications, définissent un engin aux caractéristiques très proches des sondes TOPS aptes à survoler Uranus et Neptune. Présentée officiellement comme une option en cas de succès du survol de Saturne, il ne faisait pas de doute pour les scientifiques que la mission serait prolongée.

Les objectifs scientifiques avaient été largement fixés par la communauté scientifique. Toutefois, le JPL, sans prendre en considération les attentes des scientifiques, impose l'emport de deux instruments scientifiques développés en interne : les caméras et l'expérience de radio-science. En avril 1972, la NASA lance un appel à propositions pour la sélection des autres instruments scientifiques et reçoit 200 réponses principalement de laboratoires et universités américaines. La sélection donne largement l'avantage aux grandes institutions comme le centre de vol spatial Goddard ou à des laboratoires en relation étroite avec la NASA. Chaque instrument sélectionné est conçu et développé par l'équipe scientifique dirigée par un responsable scientifique. Les 11 responsables instrumentaux forment le comité de pilotage scientifique chargé de conseiller la NASA dans le domaine scientifique. Fin 1972, Edward C. Stone, un physicien du California Institute of Technology spécialisé dans l'étude de la magnétosphère et qui avait participé au programme Grand Tour dès 1970 est nommé responsable scientifique de la mission. Son rôle est d'assurer l'interface entre les besoins des scientifiques et les contraintes techniques et budgétaires. En mars 1977, soit quelques mois avant le lancement des deux sondes spatiales, le projet "Mariner Jupiter/Saturn 1977" est rebaptisé Voyager . 

L'objectif du programme "Voyager" est de collecter des données scientifiques sur les planètes externes (Jupiter, Saturne, Uranus et Neptune) qui à l'époque sont pratiquement inexplorées : seules "Pioneer 10" et "11", des sondes légères développées pour servir d'éclaireurs aux sondes "Voyager" mais disposant de peu d'instruments, se sont jusqu'à présent approchées de Jupiter et de Saturne. L'objectif principal assigné aux deux sondes est de recueillir des données permettant de mieux connaître les deux planètes géantes, leur magnétosphère et leurs satellites naturels. Ces derniers, qui sont pour certains de la taille d'une planète, sont très mal connus. L'étude de la lune Titan, dont on sait déjà à l'époque qu'elle possède une atmosphère évoluée, est jugée aussi importante que l'exploration de Saturne, sa planète mère. Enfin, le recueil des données sur les deux autres planètes géantes du Système solaire, Uranus et Neptune, sur lesquelles très peu d'informations sont acquises du fait de leur éloignement, constitue un objectif majeur dans la mesure où l'étude de Jupiter et de Saturne a pu être menée à bien.

Les sondes Voyager 1 et 2 sont pratiquement identiques : Voyager 1 dispose d'une électronique mieux blindée car la sonde s'approche plus près de Jupiter tandis que Voyager 2 a des générateurs thermoélectriques à radioisotope plus puissants car elle doit visiter la planète la plus éloignée de la Terre.

Chacune des deux sondes spatiales Voyager a une masse de dont d'instrumentation scientifique à comparer aux de Pioneer 10. Les ordinateurs et le système de télécommunication se trouvent logés au centre de celle-ci dans un cylindre aplati de de diamètre et de de hauteur au cœur duquel se trouve le réservoir de carburant utilisé par les moteurs. Tous les autres composants de la sonde se rattachent à ce cylindre. Les instruments scientifiques qui doivent être orientés vers les planètes et lunes (ISS, IRIS et PPS) sont installés sur une plateforme située au bout d'une perche s'étendant jusqu'à environ du centre de la sonde : la plateforme est orientable selon deux degrés de liberté avec une précision de 0,1°. Les magnétomètres sont installés sur une perche de de long. Une troisième perche porte à son extrémité les générateurs thermoélectriques à radioisotope (RTG) produisant l'énergie nécessaire à la mission. Les instruments radio PRA et PWS fonctionnent quant à eux grâce à deux antennes de , perpendiculaires l'une par rapport à l'autre. Tous les instruments scientifiques sont installés de manière à être au moins à du RTG pour limiter l'incidence du rayonnement émis par la décomposition radioactive du plutonium 238.

Pour garantir le fonctionnement de la sonde durant les 5 ans de la mission, une durée exceptionnelle pour l'époque, chaque système vital est doublé : ordinateurs, senseur solaire et d'étoile, équipement radio, système de propulsion, etc. C'est ainsi que sur la sonde Voyager 1 c'est l'ordinateur principal de secours qui remplace le système d'origine tombé en panne.

Le système de propulsion est constitué par 16 petits moteurs-fusées utilisant de l'hydrazine qui, en se décomposant sur un catalyseur, fournit une poussée de 0,89 newton par moteur. Pour la première fois sur une sonde spatiale, les mêmes moteurs sont utilisés pour contrôler l'orientation et corriger la trajectoire permettant de réduire la masse du système. Seuls huit moteurs sont nécessaires : 2 pour faire pivoter la sonde sur chaque axe et 2 pour accélérer ou freiner l'engin. Les huit autres moteurs sont là en secours. Les moteurs-fusées et le réservoir, qui contient au départ d'hydrazine, sont situés dans le corps central de la sonde. Ce carburant qui permet de fournir un delta-v de s'est révélé largement suffisant, grâce à la précision de la trajectoire suivie ( d'erreur contre prévus au maximum) puisqu'il subsistait encore plus du tiers du carburant en l'an 2000 bien après l'achèvement des manœuvres de survol.

La sonde est stabilisée sur ses 3 axes : le contrôle de l'orientation de la sonde et celle de la plateforme portant les instruments est pris en charge par un ordinateur dédié l'AACS. L'orientation de la sonde est contrôlée à l'aide de deux senseurs : un senseur d'étoile qui pointe vers Canopus (Voyager 1 utilise également l'étoile Rigel sur certaines portions de son trajet) et un senseur solaire installé sur l'antenne parabolique. Lorsque l'étoile visée s'écarte du champ de vision du senseur de plus de 0,05°, les moteurs-fusées effectuent automatiquement une correction. Pour de courtes périodes (quelques jours), le contrôle de l'orientation est confié à un ensemble de gyroscopes par exemple lorsque le Soleil est masqué ou durant les corrections de trajectoire.

La sonde embarque trois ordinateurs existant chacun en deux exemplaires pour faire face à une panne :
Les données scientifiques qui ne peuvent pas être transmises directement vers la Terre sont stockées sur un enregistreur à bande magnétique à 8 pistes DTR (Digital Tape Recorder). Celui-ci peut enregistrer des informations à une vitesse de 115,2 kilobits par seconde, ce qui correspond au débit en sortie de la caméra, ou les restituer en lecture à . Lorsqu'il est utilisé simultanément en lecture et en écriture, le débit est de . Chaque piste permet d'enregistrer l'équivalent de 12 photos ; la capacité de stockage totale est équivalente à 586 mégabits.

Pour disposer de suffisamment d'énergie aux confins du Système solaire, les panneaux solaires photovoltaïques, peu efficaces à grande distance du Soleil, sont remplacés par trois générateurs thermoélectriques à radioisotope. L'énergie électrique est produite par la chaleur émise par la décroissance radioactive du plutonium 238 embarqué. Les watts de chaleur fournissent d'énergie électrique au début de la mission en 1977, distribuée sous la forme d'une tension électrique continue de . La décroissance de la radioactivité du plutonium entraine une diminution de l'énergie électrique produite de par an. Le contrôle au sol maintient la consommation de manière à disposer d'une marge de pour éviter des dysfonctionnements. Chacun des 3 générateurs a la forme d'un cylindre de de hauteur pour de diamètre.

Les communications avec la Terre sont assurées par un émetteur-récepteur radio fonctionnant à la fois en bande S () et en bande X (), relié à une antenne parabolique grand gain de de diamètre qui émet avec un angle d'ouverture de 2,3° en bande S et de 0,6° en bande X. Une antenne à faible gain est montée sur la structure portant la parabole et émet dans l'hémisphère centrée sur l'axe de la grande parabole. Le système de télécommunications est doublé pour faire face à une défaillance, Il permet de transmettre les données scientifiques recueillies avec un débit compris entre 4,8 et 115,2 kilobits par seconde en bande X et les mesures télémétriques avec un débit de 40 bits par seconde en bande S. Les instructions du contrôle de mission sur la Terre sont reçues avec un débit de 16 bits par seconde.

Avec une caméra couleur grand angle de résolution 0.64 MP (800*800) et une deuxième avec un objectif standard, les instruments de mesures scientifiques se composent de :

Voyager 2 est lancée la première le et sa jumelle Voyager 1 le 5 septembre. Construites pour durer seulement cinq ans, les sondes sont en 2010 plus de trois fois et demie plus éloignées de la Terre que Pluton. Toujours en état de fonctionnement, elles foncent vers l'héliopause, limite de l'influence magnétique du Soleil, où débute « officiellement » l'espace interstellaire.

Ces deux engins de dotés d'une douzaine d'instruments et de caméras quittaient la Terre pour un grand tour du Système solaire. La mission avait été conçue pour profiter d'un alignement planétaire exceptionnel - survenant une fois tous les 175 ans – qui permettait, avec une dépense minimale de temps et de carburant, de rendre visite aux quatre planètes gazeuses du Système solaire : Jupiter, Saturne, Uranus et Neptune. À l'origine, la NASA ne disposait pas d'un financement suffisant pour prolonger la recherche au-delà de Saturne, mais les ingénieurs américains avaient programmé pour Voyager 2 une trajectoire incluant le survol d'Uranus et de Neptune. Chaque survol rapproché d'une de ces planètes géantes donnait un coup d'accélérateur suffisant aux sondes pour les propulser au voisinage de la planète suivante. C'est ce qu'on appelle la technique de « "fronde gravitationnelle" » ou d'« "assistance gravitationnelle" ».

Durant la première phase de sa mission, Voyager 1 a survolé Jupiter le 5 mars 1979 à de la planète et Saturne le 12 novembre 1980 à une distance de . Elle a par la suite quitté le plan de l'écliptique en prenant de l'avance sur Voyager 2 et poursuivi sa route pour aller à la rencontre de l'héliopause. Le 17 février 1998, Voyager 1 est devenu l'objet le plus distant de la Terre jamais envoyé dans l'espace en battant un record établi précédemment par la sonde Pioneer 10. Elle est à plus de 18 heures-lumière de la Terre (début 2016, il fallait plus de 37 heures aux signaux pour faire l'aller-retour entre Voyager 1 et la Terre).

Voyager 2 a survolé Jupiter le 9 juillet 1979 à de la planète et Saturne le 25 août 1981 à une distance de , puis les ingénieurs de la NASA comprirent que Voyager 2 serait probablement capable de voler jusqu'à Uranus avec tous ses instruments en ordre de marche. Ce fut chose faite le 24 janvier 1986 avec un survol de la planète à , Voyager 2 réussissant à transmettre à la NASA des photos et données uniques de cette planète, de ses lunes et champs magnétiques. Après son passage à de Neptune le 25 août 1989, Voyager 2, au bout de ces 12 ans de voyage, prit à son tour une direction la faisant sortir du Système solaire.

Le programme Voyager est sans doute la mission d'exploration du Système solaire la plus fructueuse sur le plan scientifique de toute l'histoire spatiale. Les sondes Voyager ont été les premières à effectuer un survol d'Uranus et de Neptune et les secondes à étudier Jupiter et Saturne. Voyager 1 et 2 ont permis d'obtenir pour la première fois un profil détaillé des atmosphères de Jupiter, Saturne et Uranus, et ont amélioré notre compréhension de la composition de l'atmosphère de Jupiter. Les sondes Voyager ont révélé de nombreux détails sur les anneaux de Saturne notamment les pokes de l'anneau B et structure en tresse dans l'anneau F. Les ondes spatiales ont découvert les anneaux de Jupiter et deux nouveaux anneaux ont été identifiés autour d'Uranus. Les arcs (anneaux partiels) de Neptune se sont révélés être des anneaux complets composés d'un matériau particulièrement fin. Des tempêtes à grande échelle dont la Grande Tache Sombre ont été découvertes dans l'atmosphère de Neptune alors qu'on considérait que l'atmosphère de Neptune était trop froide pour produire de telles perturbations atmosphériques. Les sondes ont découvert en tout 22 nouvelles lunes orbitant autour des planètes extérieures ! trois autour de Jupiter, trois autour de Saturne, 10 autour d'Uranus et 6 autour de Neptune. Des mesures plus fines des magnétosphères de Jupiter et de Saturne ont été effectuées. Les magnétosphères d'Uranus et de Neptune ont été découvertes présentant toutes les deux un décalage important par rapport à l'axe de rotation de la planète suggérant une source très différente de celle des autres magnétosphères.

La plus grande surprise du programme a été la découverte de volcans en activité à la surface de Io, bien que ce phénomène ait été prédit peu avant son observation : pour la première fois, un tel phénomène était observé dans le système solaire ailleurs que sur Terre. Des photos de panaches de 9 volcans montant jusqu'à au-dessus de la surface ont été prises par les deux sondes. L'énergie nécessaire à l'activité de ces volcans émane d'un échauffement interne du satellite, provoqué par les effets de marée qu'engendre l'orbite elliptique du satellite autour de Jupiter, qui se perpétue du fait d'un phénomène de résonance avec les autres lunes.

Les sondes ont également découvert sur Europe, un autre satellite de Jupiter, une surface peu marquée par les cratères d'impact qui trahit un remodelage récent. Un réseau de multiples coutures, balafrant comme autant de lignes de fracture la surface, correspond, selon l'hypothèse élaborée à l'aide des données recueillies plus tard par la sonde Galileo, à une croûte de glace d'une vingtaine de kilomètres d'épaisseur recouvrant un océan souterrain. Enfin, les sondes ont découvert la présence d'une atmosphère très épaisse et très dense autour de Titan, le principal satellite de Saturne, et les geysers de Triton, la plus grosse lune de Neptune.

En effectuant le dernier survol des planètes gazeuses, les sondes Voyager ont achevé leur mission primaire. Compte tenu de la bonne santé des deux sondes spatiales, la NASA a décidé de prolonger la mission primaire par une nouvelle mission baptisée "Voyager Interstellar Mission" (VIM) destinée à collecter des données sur la région de l'espace située au-delà des planètes externes tout en restant sous l'influence du Soleil. Cette exploration sera prolongée si possible au-delà de l'héliopause c'est-à-dire de la région représentant la frontière avec l'espace interstellaire libre de toute influence du Soleil. Cette nouvelle mission commence en 1989 alors que Voyager 1 se trouve à 40 Unités Astronomiques (1 U.A. = distance Terre-Soleil soit 150 millions km) de la Terre et Voyager 2 à 31 U.A. La nouvelle mission est subdivisée en trois phases :

Dans cette dernière phase, les sondes pourront mesurer les particules et ondes interstellaires non affectées par les vents solaires, une première dans l'histoire de l'exploration spatiale. Les sondes Voyager ont encore assez d'énergie pour fonctionner jusqu'en 2020, selon les estimations des ingénieurs de la NASA. À cette date, elles seront respectivement à 20 et 16,8 milliards de kilomètres du soleil. Voyager 1 devrait passer dans la périphérie de l'étoile « AC+79 3888 » dans la constellation de la Girafe dans et Voyager 2 rendre visite à Sirius, la plus brillante des étoiles de notre ciel, dans .

Une fois franchie cette frontière, les Voyager feront partie, avec les sondes Pioneer, des tout premiers objets fabriqués par l'homme à naviguer hors de la bulle de protection du Soleil. Même si les signaux des Voyager mettent plusieurs dizaines d'heures à nous parvenir, les chercheurs espèrent bien obtenir des informations sur la densité du nuage interstellaire, sur les radiations qui le traversent et dont l'héliosphère nous protège. On ignore notamment la densité de toute une classe de particules relativement énergétiques, qui peuvent faire des dégâts sur les êtres humains - dans le cadre futuriste d'un voyage interstellaire - et sur le matériel électronique des sondes. Pour l'heure, les Voyager sont en relative bonne santé. Les astronomes comptent recevoir leurs mesures jusqu'en 2020. Aux alentours de 2025, 2030, le générateur thermoélectrique à radioisotope fonctionnant au plutonium 238, après la fourniture de près d'un demi-siècle d'énergie électrique, sera épuisé.

Voyager 1 est plus éloigné de la Terre que tout autre engin jamais lancé par l'Homme dans l'espace, et continue de s'éloigner à la vitesse de . Les deux sondes continuent à envoyer des données qui sont reçues par le Réseau d'antennes de la NASA (DSN), dans le cadre d'un projet qui a été rebaptisé Mission interstellaire Voyager. Le coût total de la mission Voyager, incluant le lancement et le suivi des sondes, s'établit aujourd'hui à 895 millions de dollars, dont une rallonge budgétaire de 30 millions accordée par la NASA en 1990 pour la poursuite de la mission.

«" Aujourd'hui, malgré leur grand âge, les deux sondes sont en mode d'alerte" » explique Rosine Lallement, directeur de recherches au Service d'aéronomie du CNRS. « "On surveille ce qu'il en sort, car on guette un changement dans les données concernant le plasma, le gaz ionisé" ». Voyager 1, la plus rapide et la plus éloignée des deux sondes, se situe actuellement à plus de 15 milliards de kilomètres et approche de la zone où le vent solaire « bute » sur le nuage de gaz interstellaire que traverse le Soleil. Les chercheurs veulent donc déterminer l'emplacement de cette zone de choc.

Les deux sondes Voyager, ainsi que Pioneer 10, sont les premiers engins conçus par l'homme à se diriger vers l'extrême frontière du Système solaire qui est englobé dans l'héliosphère. Cette dernière est une sorte d'immense bulle balayée par les particules très énergétiques émises par le Soleil. Au-delà, les petits engins rencontreront l'héliopause, la zone qui constitue la limite entre l'héliosphère et le milieu interstellaire. En théorie, les astronomes placent l'héliopause à une distance de 100 unités astronomiques par rapport au Soleil (une UA = 150 millions de kilomètres). Mais ils ignorent encore sa forme exacte ainsi que les caractéristiques précises de ce milieu.

La publication dans la revue "Science" du d'une série d'articles concordants officialise l’événement : depuis le , Voyager 1 est la première création humaine à naviguer au-delà de l'une des principales frontières du Système solaire, l'héliosphère. Cette frontière, le choc terminal, se trouve à environ 14,1 milliards de kilomètres du Soleil, soit 94 unités astronomiques. Voyager 1 doit à une chance inouïe la possibilité de témoigner de ces phénomènes. Car, dans les années 1970, ses concepteurs ignoraient tout de la direction du Soleil par rapport à la Voie lactée. De ricochet en ricochet autour des planètes visitées, le hasard a voulu que la sonde quitte le Système solaire par l'avant, vers le "nez" que forme l'héliosphère en rencontrant la résistance du milieu interstellaire.

Le , Voyager 1 a dépassé la barrière symbolique des 100 UA de distance par rapport au Soleil, soit 15 milliards de kilomètres. De son côté, Voyager 2 a franchi le choc terminal le . La sonde était alors située à environ 84 UA du Soleil. Elles poursuivent leur route à la frontière du Système solaire vers la zone que l'on appelle l'héliopause, limite de l'influence du vent solaire. Voyager 1 a dépassé officiellement Pioneer 10 le 17 février 1998 pour devenir l'objet le plus distant de la Terre jamais envoyé dans l'espace. Les sondes s'éloignent dans l'espace à des vitesses vertigineuses : par seconde () pour Voyager 1 ; () pour Voyager 2. Cette vitesse leur permet de parcourir plus de 500 millions de kilomètres par an. Elles envoient encore des données qui sont collectées par le réseau de communication avec l'espace lointain (DSN) de la NASA, dans le cadre d'un nouveau programme : la Mission Interstellaire Voyager.

La NASA confirme le 12 septembre 2013, après analyse des données recueillies par la sonde, que , à plus de 18 milliards de kilomètres du Soleil, a quitté la zone d'influence directe de ce dernier, l'héliosphère (zone de prédominance magnétique, la sonde étant toujours dans la zone de prédominance gravitationnelle de notre étoile). Elle se trouve désormais dans l'espace interstellaire.

Les deux sondes Voyager, comme les sondes Pioneer 10 (1972) et 11 (1973) qui les ont précédées, transportent, de manière symbolique, un message tentant de résumer quelques éléments clés sur l'humanité. Ces informations sont gravées sur un disque de cuivre qui est accompagné d'une cellule et d'une aiguille permettant de le lire. Les données, sélectionnées par un comité présidé par l'astrophysicien Carl Sagan, comprennent une série de 116 photos de différents lieux symboliques sur Terre, des schémas donnant la position de la Terre dans le Système solaire, une espèce de pierre de Rosette définissant le système numérique en usage ainsi que les grandeurs employées en physique ainsi que des extraits sonores comprenant 27 morceaux de musique ainsi que des enregistrements variés reflétant l'activité humaine. Les sondes approcheront pour la première fois une étoile dans ans.








</doc>
<doc id="14306" url="https://fr.wikipedia.org/wiki?curid=14306" title="Géographie de Cuba">
Géographie de Cuba

Cuba est un État situé dans les Antilles et constitué en majorité de l'île du même nom. Le pays est à au sud-ouest des Bahamas (Great Inagua), au nord de la Jamaïque, à l'est-nord-est du Mexique et au sud de la Floride.

L’île de Cuba présente une forme très allongée qui s'étend le long d’un arc convexe de km rappelant celle d’un caïman. La superficie totale du pays est de , ce qui en fait l'État le plus grand des Antilles, et qui inclut les quelque îles du pays, dont la plus grande est l'île de la Jeunesse (appelée île aux Pins jusqu'en 1976). À l'extrémité sud-est de l'île de Cuba se trouve le territoire américain de Guantánamo.

Le pays bénéficie de surfaces planes étendues et de sols favorables à l’agriculture qui ont favorisé une répartition homogène du peuplement. Toutefois, bien que près de 80 % du relief de l’île soit sous forme de plaines et de plateaux, trois chaînes de montagnes s'élèvent :

Ce petit État de , soit environ un quatre-vingt-septième du Canada, présente tout de même une importance géopolitique considérable. Situé au centre de la mer des Caraïbes, à moins de au sud de la Floride, à l’ouest d’Haïti, au nord de la Jamaïque et à l’est de la péninsule du Yucatan, Cuba est un territoire au positionnement hautement stratégique. Enviée pour sa position avantageuse, mais aussi pour ses nombreuses ressources naturelles ; faune et flore exceptionnelles, minerais – or, nickel - et terres agraires très productives - sucre, tabac, café.

D'après Aquastat, la hauteur d'eau annuelle moyenne des précipitations est de , soit pour une superficie de kilomètres carrés, un volume de précipitations annuelles de cubes ("France ").

De ce volume précipité, l'évapo-transpiration et les infiltrations consomment . Restent cubes de ressources d'eau courante produites sur le territoire du pays (en interne). Il faut ajouter à cela cubes d'eau souterraine renouvelables chaque année. Au total donc les ressources totales en eau du pays se montent à cubes en moyenne chaque année (soit 38 milliards 120 millions de m).

Chaque cubain dispose donc, bon an mal an, d'une quantité de plus ou moins d'eau, ce qui peut être considéré comme largement suffisant.

Population : (2010). 0-14 ans : 19,6 % ; 15-64 ans : 70,1 % ; + 65 ans : 10,4 %
Superficie : 
Densité : 102.3 /km
Frontières terrestres : ( avec la base américaine de Guantanamo ; cependant le terrain sur lequel se trouve la base appartient à Cuba)
Littoral : 
Extrémités d'altitude : > + 
Espérance de vie des hommes : 74,94 ans (en 2005)
Espérance de vie des femmes : 79,65 ans (en 2005)
Taux de croissance de la pop. : 0,33 % (en 2005)
Taux de natalité : (en 2005)
Taux de mortalité : (en 2005)
Taux de mortalité infantile : (en 2005), le plus bas en Amérique après le Canada
Taux de fécondité : 1,66 enfant/femme (en 2005)
Taux de migration : - 1,58 ‰ (en 2005)
Indépendance : (ancien territoire américain)
Lignes de téléphone : (en 2002)
Téléphones portables : (en 2002)
Postes de radio : 3,9 millions (en 1997)
Postes de télévision : 2,64 millions (en 1997)
Utilisateurs d'Internet : (en 2004)
Nombre de fournisseurs d'accès Internet : 4 (en 2001)
Routes : (dont goudronnés) (en 1999)
Voies ferrées : (en 2004)
Voies navigables : (en 2004)
Nombre d'aéroports : 170 (en 2004)

Pour des données plus actuelles, voir CIA The World Factbook:





</doc>
<doc id="14309" url="https://fr.wikipedia.org/wiki?curid=14309" title="Démographie de l'Amérique latine">
Démographie de l'Amérique latine

L'Amérique latine désigne les pays du continent américain où l'on parle espagnol ou portugais. Ses habitants sont les Latino-Américains.

Avant la découverte et exploration de l'Amérique par Christophe Colomb (1492), l'Amérique latine comptait environ 50 millions d'habitants. Deux foyers de civilisation principaux regroupaient l'essentiel de la population : l'empire inca et l'empire aztèque. À la fin du , il reste entre 10 et 30 millions d’indigènes. Les maladies, les massacres et l'exploitation des Amérindiens par les Européens expliquent cet effondrement démographique. En 1800, l'Amérique latine ne compte qu'une quinzaine de millions d’habitants.

Dès le , les Européens déportent des Africains en Amérique latine pour travailler dans les plantations et les mines. Ils sont remplacés au par des Asiatiques, comme au Pérou.

Depuis 1950, l'Amérique latine a augmenté légèrement sa part de la population mondiale.

Les pays d'Amérique latine sont très différemment peuplés. Ainsi, le Brésil compte plus de 200 millions d'habitants, alors que l'Uruguay compte moins de 4 millions d'habitants. 

Classement par population :

Total : environ 620 millions (en 2013)

La population latino-américaine est inégalement répartie et les densités sont très variables selon les régions. 
L'Amérique latine est principalement peuplée de métis, de descendants d'Amérindiens, d'Européens, d'Africains. Plus minoritairement on trouve également des descendants de Japonais (voir l'article de fond : Japonais au Brésil), de Chinois, d'Indiens, de Libanais et de Palestiniens.

Dans le cône Sud, au Costa Rica et à Cuba, une part très importante de la population est d'origine européenne, surtout de descendance espagnole, italienne, française, allemande...

Le catholicisme est majoritaire dans la plupart des pays d'Amérique latine.



</doc>
<doc id="14310" url="https://fr.wikipedia.org/wiki?curid=14310" title="Histoire de la physique">
Histoire de la physique

L'histoire de la physique retrace l'origine et l'évolution des courants de pensée et des connaissances en sciences physiques.

Plusieurs problématiques parallèles s'imbriquent au cours des siècles:

Durant la Préhistoire, les hommes faisaient des observations (Stonehenge ou Carnac en témoignent) et étaient amenés à reproduire des phénomènes.
C'est sur les berges des fleuves Tigre et Euphrate (Irak actuel) et du fleuve Nil (Égypte), puis plus tard en Grèce que les prémices des sciences ont vu le jour, il y a 5000 ans. Celles-ci étaient transmises par des religieux, ce qui assurait une continuité du savoir, la navigation assurant la propagation des connaissances et l'écriture, sur tablettes ou papyrus, son « stockage ».

Dans l'observation de phénomènes se reproduisant en "cycles" (diurne, lunaire ou annuel), la découverte des invariants de ces cycles constitue un début de raisonnement scientifique ; il y a là la notion que le monde obéit à des règles, et que l'on peut probablement "utiliser" ces règles.

Cette période vit l'apparition de techniques agraires, architecturales et guerrières, l'invention de la métallurgie (âge du bronze au millénaire av. J.-C., âge du fer vers 1000 av. J.-C.), le début de l'architecture et de la mécanique.

Sciences et Religion se mêlaient : les artisans faisaient des prières pendant la fabrication de leurs objets, prières qui pouvaient être un moyen de mesurer le temps lorsque la durée avait une importance dans le procédé.

Depuis l'Antiquité, on a essayé de comprendre le comportement de la matière : pourquoi les objets sans support tombent par terre, pourquoi les différents matériaux ont des propriétés différentes, et ainsi de suite. Les caractéristiques de l'univers, comme la forme de la Terre et le comportement des corps célestes comme la Lune et le Soleil étaient un autre mystère. Plusieurs théories furent proposées pour répondre à ces questions. La plupart de ces réponses étaient fausses, mais cela est inhérent à la démarche scientifique ; et de nos jours, même les théories modernes comme la mécanique quantique et la relativité sont simplement considérées comme « des théories qui n'ont pas pour le moment été contredites » (bien qu'elles soient dans leur état actuel "incompatibles" l'une avec l'autre).

Les théories physiques de l'Antiquité étaient dans une large mesure considérées d'un point de vue philosophique, et n'étaient pas toujours vérifiées par des expérimentations systématiques. Il est ici important d'avoir conscience que, dans la Grèce antique, la philosophie est née des débats et discours ("logos") issus de l'observation de la nature ("physikê" en grec). On trouve donc les étymologies de beaucoup de termes employés aujourd'hui dans les sciences : suffixe -logie (technologie, ...), et physique.

La physique était considérée dans la Grèce antique, au plus tard à l'époque des Stoïciens, mais sans doute déjà auparavant, comme une des trois branches de la philosophie. On ne la distinguait pas véritablement de la métaphysique.

Pour revenir à l'expérimentation, l'une d'entre elles jouera un rôle important : l'effet de "rame brisée" qui conduira à l'étude de la "réfraction". Néanmoins, l'idée de méthode expérimentale commença d'être élaborée de manière précise par Epicure et les sceptiques, méthode qui jouera également un rôle important dans le développement de la médecine.

Hormis pour des précurseurs comme les philosophes de l'école milésienne, Démocrite, et bien d'autres, le comportement et la nature du monde étaient expliquées par l'action de dieux. Vers -600 av. J.-C., un certain nombre de philosophes grecs (par exemple Thalès de Milet) commençaient à admettre que le monde pût être compris comme le résultat de processus naturels. Certains reprirent la contestation de la mythologie amorcée par ce même Démocrite concernant par exemple les origines de l'espèce humaine. (Ils anticipaient en cela les idées de Charles Darwin — mais cela entre dans l'histoire de la biologie plutôt que dans celle de la physique.)

Faute de matériel expérimental perfectionné (télescopes...) et d'instruments précis de mesure du temps, la vérification expérimentale de telles idées était difficile sinon impossible. Il y eut quelques exceptions : par exemple, le penseur grec Archimède décrivit correctement la statique des fluides après avoir remarqué un jour, si l'on en croit la légende, que son propre corps déplaçait un certain volume d'eau alors qu'il entrait dans son bain. Un autre exemple remarquable fut celui d'Ératosthène, qui - persuadé pour d'autres raisons, dont les "éclipses de lune", que la Terre était sphérique - parvint à calculer sa circonférence en comparant les ombres portées par des bâtons verticaux en deux points éloignés de la surface du globe. En appliquant le résultat des mêmes observations à une Terre "plate" il en eût déduit la distance du soleil, ce qui nous rappelle que "toute interprétation s'appuie nécessairement sur des présuppositions antérieures" (voir inférence bayésienne).

Des mathématiciens grecs, dont à nouveau Archimède, ont songé à calculer le volume d'objets comme les sphères et les cônes en les divisant en tranches imaginaires d'épaisseur infiniment petite ; ce qui faisait d'eux des précurseurs, de près de deux millénaires, du calcul intégral. Mais ils comprenaient mal pourquoi on ne convergeait pas ainsi vers la valeur de formula_1 en divisant la diagonale du carré en petites "marches d'escalier" successives !

On connaît mal le détail des idées anciennes en physique et leurs vérifications expérimentales. La quasi-totalité des sources directes les concernant a été perdue lors des deux grands incendies de la bibliothèque d'Alexandrie : -48 avec plus de rouleaux perdus, et 696 par le général `Amr ben al-`As qui présida à la destruction totale du fonds (hormis Aristote dont les rouleaux furent sauvés "in extremis" et clandestinement par des admirateurs de ses œuvres).

Le Moyen Âge a été réévalué depuis une trentaine d'années, par des historiens tels que Georges Duby, Jean Favier, Pierre Riché, ou Jacques Le Goff.

Au Moyen Âge précoce, à la suite des grandes invasions, l'Occident a oublié une partie de l'héritage de l'Antiquité, surtout les textes de la Grèce antique. La période 550-750 peut être qualifiée de temps obscurs, au cours desquels se conserva malgré tout, grâce à Boèce, Cassiodore, Isidore de Séville, et Bède le Vénérable, un savoir de base autour des arts libéraux. Les arts libéraux formèrent l'enseignement de base des écoles carolingiennes. Cependant la physique n'en faisait pas partie.

La civilisation arabo-musulmane conserva la mémoire de la science grecque. Les principaux progrès scientifiques au cours du Haut Moyen Âge sont d'ailleurs le fait de savants arabes (mathématiques, mécanique, médecine, astronomie) et indiens (mathématique, avec l'invention du zéro vers l'an 500).

La période de l'An mil n'est pas cette période de terreurs légendaires, image véhiculée par les historiens du , comme Jules Michelet, mais plutôt une renaissance. Un peu avant l'An mil, un certain Gerbert d'Aurillac fit un séjour en Catalogne, dont il ramena des connaissances scientifiques, qui permirent de réintroduire le quadrivium en Occident. Cette période voit ainsi le début de la mise en place d'outils mathématiques (algèbre, algorithmique, entre autres) qui seront précieux pour la suite

Le mot physique apparaît au , dans le sens de médecine, science de la nature (aujourd'hui : sciences naturelles). La physique correspondait à l'un des traités d'Aristote, qui fut traduit à partir du en Occident. Dans la philosophie d'Aristote, l'observation de la nature tient en effet une grande place. Dans le sens plus proche de l'utilisation moderne du terme, on voit des progrès dans les techniques d'architecture (chantiers des églises romanes et gothiques), de navigation. Les disciplines sont la mécanique, la métallurgie, l'hydraulique, l'orfèvrerie…

La physique en elle-même ne semble pas avoir fait encore de progrès décisifs dans cette période, hormis la mécanique.

La physique d'Aristote se révélait en fait insuffisante pour expliquer le mouvement des corps. Vers la fin du Moyen Âge fut introduite en Occident la doctrine de l'impetus afin d'expliquer le mouvement des corps physiques.
Vers la fin du , le mot physique prit le sens de science des causes naturelles (première utilisation en "1487" selon le Petit Robert), toujours dans la philosophie scolastique.

Les travaux de l'astronome polonais Copernic au ont marqué les tout débuts d'un bouleversement majeur dans les sciences qui eut des répercussions capitales en physique. Contrairement à Aristote et Ptolémée, Copernic voyait la Terre animée d'un mouvement de rotation autour du Soleil (héliocentrisme). Le philosophe des sciences Thomas Samuel Kuhn considère que cette découverte est une révolution scientifique majeure, consistant en un véritable changement de paradigme. Cette transformation est souvent appelée la révolution copernicienne. Au siècle suivant, les observations de Copernic furent confirmées par la théorie de Newton, qui révolutionna la mécanique céleste, et la mécanique en général.

Les débuts de la physique au sens moderne datent sans doute de Galilée (1564–1642), dont on peut dire qu'il fut le premier physicien dans le sens actuel : sa foi en les mathématiques pour décrire le monde et les phénomènes fut ce qui le distingua de ses prédécesseurs, même si on ne peut pas toujours dire qu'il ait été un expérimentateur très scrupuleux. Galilée perfectionna des instruments optiques pour l'astronomie, la fameuse lunette astronomique, et apporta des progrès décisifs en cinématique (mouvement uniformément accéléré).

La rigueur qui manquait encore à Galilée dans la formulation mathématique fut sans doute apportée par Descartes : coordonnées cartésiennes, travaux en optique (la loi de Descartes est en fait la loi de Snell). Le fameux "Discours de la Méthode", écrit en français, chercha à décrire une manière déductive de traiter les problèmes, beaucoup moins fondée sur l'intuition. On peut dire qu'il marque le début de la démarche des sciences dites « exactes », fondées sur les raisonnements logiques de déduction. Cette démarche fit progresser la physique dans des domaines comme la mécanique classique, l'optique, le calcul différentiel, la géométrie analytique...

Descartes s'aventura plus loin sur le plan philosophique : dans les méditations sur la philosophie première (1641), il dénonça la science aristotélicienne, qui était coupable de n'avoir pas compris le mouvement des planètes comme l'annonçaient Copernic et Galilée. L'expression aristotélicien prit alors un sens très péjoratif, pour dénoncer les errements de la scolastique alors en déclin.

Blaise Pascal (1623–1662) décrivit les phénomènes de pression atmosphérique, et fit de nombreux apports en hydrostatique et hydrodynamique. En mathématiques, il inventa les probabilités, qui eurent des applications ultérieurement en physique.

Isaac Newton (1643-1727) a formulé les « lois » qui portent son nom, qui ont permis l'essor de ce qu'on appelle la mécanique classique. En mathématique infinitésimale, il trouva un moyen de lever les indéterminations dans le calcul des tangentes ou dérivées. En 1685, il généralisa les lois de la gravitation que Robert Hooke venait de formuler et les utilisa comme base de son système du monde, où la gravitation, force d'attraction universelle, est la cause du mouvement. Son ouvrage majeur, "Principes mathématiques de la philosophie naturelle" publié en 1687, décrivit la gravitation de façon universelle et mathématique. Il permit de confirmer la théorie de l'héliocentrisme sur le plan de sa formulation mathématique (la preuve optique n'était pas encore obtenue). Les méthodes de calcul qu'il y utilise en font un précurseur du calcul vectoriel.

Leibniz (1646–1716) inventa le calcul infinitésimal à peu près au même moment que Newton, qui développa de son côté un procédé similaire avec le calcul des fluxions. Toutefois Isaac Newton n'utilise pas son calcul dans son œuvre majeure, les Principia, en 1687. Les apports de Leibniz en physique furent considérables. Citons la force vive, lointain ancêtre de l'énergie, ou la loi de conservation.

On peut dire que c'est de cette époque que le mot "physique" commence à changer de sens : de "science des causes naturelles", la physique devient la science qui étudie les propriétés générales de la matière et établit des lois qui rendent compte des phénomènes matériels : la première utilisation dans ce sens date de 1708 ("Petit Robert").

La physique du voit croître ses connaissances de manière tout à fait significative. Les domaines issus du et de la Révolution Scientifique continuent sur leur lancée, tandis que de nouveaux domaines sont explorés, tel que l'électricité.

Ce n'est qu'au que les travaux de Newton sur l'interaction gravitationnelle commencent à être vraiment diffusés sur le continent : en France, par exemple, on continuait d'expliquer le mouvement des planètes par la théorie des tourbillons de Descartes, même si un savant tel que Varignon fut acquis à la cause newtonienne très tôt, dès 1700. En effet, sur le continent, le concept d'attraction à distance était perçu comme la résurgence des qualités occultes, et donc majoritairement rejeté. Les tourbillons furent progressivement écartés à partir des années 1720, et le point de non retour fut franchi avec l'expédition de Maupertuis sur la mesure du méridien terrestre en 1738, qui permit de conclure à la véracité de la théorie de Newton sur Descartes. À la même période, Voltaire, véritable propagandiste de Newton, s'implique dans le débat et publie deux essais sur Newton : "Épître sur Newton" (1736), et "Éléments de la philosophie de Newton" (1738).

La mécanique analytique se développe au long du siècle avec Varignon, D'Alembert, Maupertuis, Lagrange et quelques autres, poursuivant ainsi l’œuvre de Jacques Bernoulli sur l'analyse mathématique (poursuivie par son frère Jean Bernoulli, et Euler), qu'il avait lui-même fondé sur la formalisation de Leibniz du calcul différentiel et intégral. Outre la gravitation, les savants s'intéressent aux systèmes à liaisons, puis appliquent le formalisme aux milieux continus, ce qui permettra à D'Alembert en 1747 de déterminer l'équation des cordes vibrantes, et à Euler en 1755 d'établir les équations générales de l'hydrodynamique, après que Daniel Bernoulli ("Hydrodynamica", 1738) et Jean Bernoulli aient apporté d'importantes contributions. 

Tandis que d'Alembert publie en 1743 son très remarqué "Traité de dynamique" dans lequel il tente de réduire toute la dynamique à la statique, Maupertuis invente le principe de moindre action, et Lagrange, en 1788, va magistralement parachever l'œuvre. C'est véritablement avec ce dernier que la mécanique devient une nouvelle branche de l'analyse mathématique.

À côté de l'avancée de la mécanique analytique, le voit se développer de manière tout à fait significative la physique expérimentale, notamment à partir des années 1730. En France, c'est Nollet qui s'impose comme le pape de cette physique, et s'investit également beaucoup dans les cours publics. En cela il est tout similaire à un Musschenbroek en Hollande, ou Desaguliers en Angleterre. Cette physique expérimentale s'intéresse ainsi à l'électricité. Gray en Angleterre comprend le rôle de ce que Desaguliers appellera après lui conducteurs et isolants. Dufay, académicien des sciences français lui rendra d'ailleurs visite, et expérimentera par lui-même ensuite. Il aura ainsi l'idée que l'électricité était composée de deux fluides, l'électricité vitrée, et la résineuse, et non d'un seul fluide comme on le pensait. C'est parce qu'on l'envisageait comme un fluide que l'on chercha à isoler dans des récipients. C'est ainsi que Musschenbroek inventa, en cherchant autre chose, la bouteille de Leyde. Benjamin Franklin donna une théorie complète de cet appareil, voyant dans la bouteille de Leyde un condensateur. Mais c'est Nollet qui composa le premier système d'ampleur d'explication des phénomènes électriques, ou plutôt électrostatiques pour employer le vocabulaire contemporain. Son système ne survivra pas à la confrontation avec le système de Franklin, notamment après le retentissement de son expérience bien connue de son cerf volant, montrant que la foudre est électrique, et bien que cette expérience n'ait que peu de rapports avec son système. À la fin du siècle, les importants travaux de Coulomb permettent de donner une mesure de la force électrique tandis que ceux de Volta permettent de créer les premières piles voltaïques.

La science des machines se développe à partir des résultats séminaux d'Antoine Parent sur les roues hydrauliques au tout début du siècle. Deparcieux, Smeaton, Borda, au milieu du siècle, puis Coulomb à la fin du siècle, apportent leurs contributions.

Les théories de la chaleur se développent à la faveur des recherches sur le ressort de l'air initiées à la fin du , par Boyle en Angleterre, et Mariotte, un peu plus tardivement en France. Ainsi, Guillaume Amontons fait d'importants travaux sur les thermomètres dans les toutes premières années du siècle, vite éclipsés par ceux de Fahrenheit, et de Réaumur. En 1741, Anders Celsius définit comme extrémités de l'échelle des températures, l'ébullition de l'eau (degré 100), et la congélation de l'eau (degré 0), échelle que Linné renverse en 1745. C'est cette échelle qui sera retenue en 1794 par la Convention quand le système métrique sera adopté. 
Du côté des théories de la chaleur elles-mêmes, on ne conceptualise pas encore la différence entre température et chaleur. Boerhaave au début du siècle, puis Black, et enfin Lavoisier à la fin du siècle, adoptent tous une conception matérielle de la chaleur. Lavoisier nomme ce fluide le "calorique", dont l'inexistence sera démontrée au .
Avec Sadi Carnot apparait la thermodynamique, initialement pour améliorer les performances des machines à vapeur. 
C'est la fin du rêve du « mouvement perpétuel » : une théorie scientifique établit maintenant qu'il n'est pas possible de tirer de l'énergie de nulle part, et que l'énergie se « dégrade ». 
Boltzmann comprend alors l'origine statistique du second principe, le seul qui fasse apparaître une distinction entre passé et futur en physique !

Une autre théorie très importante est l'électromagnétisme, unification de l'étude de l'électricité et du magnétisme. C'est James Maxwell (1831–1879) qui finira d'unifier les deux théories, et qui introduira les derniers termes dans les équations qui portent maintenant son nom et qui décrivent le comportement des champs électriques et magnétiques. 
À l'époque, une constatation est faite : les équations de Maxwell ne sont pas invariantes par les transformations de Galilée. Et une controverse fait rage : si la lumière est une onde, elle se déplace dans un milieu, puisque c'est le cas pour toutes les ondes que l'on connait. L'éther est évoqué comme hypothèse pour ces deux problèmes.

Les expériences de Michelson et Morley conduisent cependant à penser que la vitesse de la lumière est la même quelle que soit la direction, ce qui est en contradiction avec l'idée d'un éther fixe dans lequel la lumière se propagerait, sauf si on accepte l'hypothèse de la contraction des longueurs émise par Fitzgerald et Lorentz : la transformation de Lorentz, énoncée par Fitzgerald (et aussi par Voigt) en 1889 et indépendamment par Lorentz en 1892.
C'est surtout l'expérience de Kennedy-Thorndike qui donna le coup de grâce au concept d'éther.

Le début du est marqué par une succession de découvertes scientifiques qui ont complètement modifié notre vision de l'Univers et du monde, apportant en particulier avec la relativité générale et la physique quantique de nouveaux changements de paradigme.

L'ère de la mécanique classique se referma sans doute lorsque fut découverte la relativité restreinte, par Albert Einstein, (Henri Poincaré ayant partiellement pressenti cette élaboration théorique, très peu de temps avant Einstein). 
Cette théorie, en postulant que le temps pouvait être relatif, mettait un point final aux débats sur l'existence de l'éther, et permettait de constater que la mécanique de Newton n'avait qu'un domaine limité de validité.

Einstein, continuant dans cette voie, mettra au point la théorie de la relativité générale, avec l'aide de David Hilbert en utilisant un domaine tout jeune des mathématiques.

Cette théorie conduira à expliquer les constatations de Edwin Hubble, qui annonce en 1929 que les galaxies qui nous entourent s'éloignent apparemment de la nôtre.
Cette constatation conduira à l'hypothèse du commencement de l'Univers dans une grande explosion appelée ironiquement « Big Bang ».

Au début du , à la suite des travaux de Max Planck et d'Einstein démontrant l'existence du photon (quantum de lumière) se produisit la plus grande révolution conceptuelle de la physique : la naissance de la mécanique quantique.

Cette théorie mit un terme définitif à l'âge d'or de la mécanique de Newton : on considère que celle-ci ne décrit guère qu'une petite partie des phénomènes naturels, ceux qui se produisent à notre échelle, en gros.


La découverte de la radioactivité et son interprétation se produit en même temps.

Si la radioactivité est découverte par Henri Becquerel, Ernest Rutherford jouera un rôle essentiel dans la compréhension de ce phénomène : c'est lui qui comprend que plusieurs rayonnements sont à l'œuvre (il les appellera alpha et bêta) et que la radioactivité s'accompagne d'une transmutation.
Il découvre aussi que les atomes comportent un noyau, sorte de graine positive.

Avec l'informatique sont apparus dans la seconde moitié du de nouvelles possibilités de modéliser les phénomènes physiques. Les équations de différentes théories physiques peuvent être résolues à l'aide de modèles numériques - différences finies, éléments finis - afin de rendre compte des phénomènes physiques. Par exemple, les équations de Navier-Stokes peuvent être résolues numériquement pour calculer les évolutions de la vitesse et de la température d'un fluide.

Les capacités de stocker les mesures sont telles que, même si on n'a pas de modèle pour expliquer un phénomène, on est de plus en plus capable de suivre son évolution numériquement (voir météorologie par exemple).

Les outils d'informatique scientifique et technique devraient aider profondément les scientifiques et les ingénieurs à fiabiliser les méthodes expérimentales et à éliminer toutes les pseudo-hypothèses qui renaissent de façon récurrente.




</doc>
<doc id="14314" url="https://fr.wikipedia.org/wiki?curid=14314" title="Athalaric">
Athalaric

Athalaric (en gotique ), né en 516 et mort le , est un roi des Ostrogoths, petit-fils de Théodoric le Grand, auquel il succède en 526.

Athalaric n'ayant que dix ans quand il accède du trône, la régence est assurée par sa mère Amalasonte. Celle-ci tente de lui fournir une éducation de tradition romaine, sans punition corporelle et, d'après Procope de Césarée, axée notamment sur la littérature et les arts classiques. Mais les nobles goths font pression sur elle pour qu'elle les autorise à l'éduquer comme ils le désirent, selon la tradition germanique.

Le jeune roi n'a que 18 ans lorsqu'il meurt en 534, épuisé par une vie de débauche. Il semble même que son ivrognerie l'a mis dans un si piètre état qu'elle est la cause de son décès. Il laisse le trône à son beau-père Théodat, qui fait d'ailleurs emprisonner puis exécuter Amalasonte, l'année suivante.



</doc>
<doc id="14318" url="https://fr.wikipedia.org/wiki?curid=14318" title="Art vidéo">
Art vidéo

L’art vidéo naît, en tant qu'expression artistique, au début des années 1960, de la rencontre de plasticiens, d'ingénieurs et de responsables de chaînes de télé qui cherchent de nouvelles possibilités d'utilisation du médium vidéo. Même si des tentatives sont faites dès la fin des années 1950, la naissance officielle de cet art a été fixée à mars 1963, lorsque Nam June Paik expose "" à la Galerie Parnass en Wuppertal, treize téléviseurs préparés pour la distorsion d’images.

Les bobines ou cassettes magnétiques qui servaient à l'origine de support à l'enregistrement sont aujourd'hui presque complètement remplacées par des disques durs ou des cartes mémoire.

L'image produite par la caméra, enregistrée ou non, peut être restituée sur un écran nommé « moniteur ».

Issu de la télévision, l'art vidéo est apparu aux États-Unis et en Europe au début des années 1960, et a aussitôt influencé les grands courants de l'époque, de Fluxus à la performance, de l'art conceptuel au minimalisme et à l'art sociologique.

Dans les années 1960, Nam June Paik a eu le geste créateur d'un courant artistique nouveau : l'Art vidéo en disposant un gros aimant sur une télévision. Le tube cathodique réagit en créant des distorsions colorées et des images de Nixon déformées. En 1958 Wolf Vostell réalise La Chambre noire ("Das schwarze Zimmer") collection Berlinische Galerie Berlin, une installation, assemblage de matériaux et de téléviseurs, première œuvre à employer l'image électronique en tant que média artistique et expose à la Galerie Parnass de Wuppertal en 1963. Cette même année, Wolf Vostell expose à la de New York l'installation "6 TV Dé-coll/age" et réalise le vidéo "Sun in your head".

Cette nouvelle technique sera utilisée dorénavant pour enregistrer des performances et des installations. Dès 1965, Fred Forest réalise en France des œuvres vidéo sur Portapack Sony 1/2 pouce ("La cabine téléphonique"). En 1969, avec cette même technique, le groupe Video Out fondé par Paul et Carole Roussopoulos donne une parole aux oubliés des Médias.

Par la suite, l'art vidéo est devenu emblématique des recherches plastiques des années 1980, durant lesquelles les caméras portatives et les bancs de montage sont devenus accessibles à un plus large public. Bruce Nauman en est un des exemples les plus avérés, qui utilise, suivant l'exemple de Dan Graham, la mise en réseau de caméras de surveillance dans ses installations.

Aujourd'hui, la vidéo est un médium reconnu au sein de l'art contemporain.

Les perspectives et l'évolution de l'art vidéo restent sensibles aux développements technologiques et informatiques. Les avancés dans ces domaines renouvellent les possibilités du médium et semblent augurer une « nouvelle vague ».

L'interactivité avec les spectateurs, les vrais ou faux « vidéhologrammes », les « vidéo jockey », les œuvres collaboratives par internet, le vidéo mapping ou encore les visioconcerts représentent les formes d'art vidéo émergentes.

L'art vidéo est donc en forte mutation avec, notamment, l'avènement et la diffusion large des technologies logicielles et certains artistes renouvellent tant le langage que les modes de production et de diffusion de cette discipline.




</doc>
<doc id="14319" url="https://fr.wikipedia.org/wiki?curid=14319" title="Adhan">
Adhan

Adhan (en arabe: ), « appel » est un terme arabe désignant l'appel à la prière ("salat" ) et notamment un appel à la prière en groupe.

Trois mots arabes dérivent de la même racine arabe signifiant annoncer :

L'adhan peut être entendu dans tous les pays à majorité musulmane aux heures des cinq prières de la journée. Il s'agit d'une annonce publique comportant des phrases définies, sous la forme d'une récitation scandée et modulée. Ce moyen de communication publique des heures de prière a été instauré par Mahomet.

Adhan sunnite :

Adhan chiite :

La version chiite imamite est comme ceci :

La version des chiites zaydites est identique, à l'exception du fait qu'ils rejettent la parole ""J'atteste que 'Alî est le régent de Allah"". L'adhan est suivi de l"'iqama" qui reprend les mêmes formules (à une phrase près), mais marque le début effectif de la prière.

Le muezzin (celui qui fait l'appel à la prière) :

Généralement, le muezzin se place en haut d'un des minarets de la mosquée ; de plus en plus, sa voix est assistée par des haut-parleurs ; dans certaines mosquées, c'est même un enregistrement qui fait office de muezzin (bien que cela soit interdit selon l'avis de certains oulémas).

Par tradition, l'appel à la prière se fait en arabe partout dans le monde (même dans les pays non arabophones). Cependant, en Turquie, entre 1932 et 1950 il était récité en turc sur ordre de Moustapha Kemal Atatürk.




</doc>
<doc id="14327" url="https://fr.wikipedia.org/wiki?curid=14327" title="Drapeau du Mexique">
Drapeau du Mexique

Le drapeau du Mexique est le drapeau national et le pavillon national du Mexique. Ce drapeau tricolore est rectangulaire de proportions 4/7 à bandes verticales vert, blanc et rouge de même taille. En son centre, sur la bande blanche, figurent les armes du Mexique, représentant un aigle sur un figuier de Barbarie, dévorant un serpent.

Le drapeau est créé lors de la consommation de l'indépendance en 1821 ; il possède alors une apparence similaire à l'actuelle mais avec un symbolisme des couleurs différent.

Au cours de son histoire, il subit huit modifications qui concernent ses proportions, les éléments de l'écu central (présence du serpent et du laurier) et le dessin des dix éléments.

Sur les territoires contrôlés par le gouvernemement de Maximilien du Mexique le drapeau se pare de symboles impériaux, cependant le drapeau de la république mexicaine continua d'être celui de la nation dans les territoires administrés par le gouvernement légitime de Benito Juárez.

La version actuelle du drapeau date de 1968 : elle fut dessinée à l'occasion de la préparation des Jeux olympiques de Mexico. Il s'agissait alors d'éviter tout risque de confusion avec un emblème national italien. L'usage du drapeau mexicain est régi et encouragé par la loi ( de 1984).

Le drapeau est le même pour tous ses emplois militaires et civils ; quelques variantes concernant les couleurs de l'écu sont officiellement ou officieusement reconnues. Le drapeau peut en outre être décoré d'une « cravate », formée d'un ruban tricolore de mêmes couleurs que le drapeau.

Les dimensions et couleurs du drapeau, ainsi que la taille et le dessin des armes du Mexique qui y figurent, sont réglementées par la loi de 1984 sur les symboles nationaux. Le texte ne spécifie pas tous les détails de composition, en particulier la teinte exacte des bandes, la couleur et les dimensions de la plupart des éléments des armes, mais deux modèles officiels du drapeau sont déposés, l'un dans les Archives nationales de la Nation, l'autre au Musée national d'Histoire.

Le drapeau est un tricolore de bandes verticales de même dimension, sa hauteur vaut les 4/7 de sa largeur. Les couleurs sont, à partir du mât, le vert, le blanc et le rouge, mais la teinte exacte n'est pas réglementée. D'après plusieurs sites de vexillologie, le Ministère de l'intérieur conseille les couleurs indiquées dans le tableau ci-contre. Les armes sont centrées au milieu de la bande blanche et ont un diamètre des 3/4 de la bande, soit 1/4 de la largeur totale.

Les armes représentent un Aigle mexicain (au sens zoologique) vu de profil gauche, dont les ailes légèrement déployées en attitude de combat surpassent la crête de l'oiseau. Leur plumage est orienté vers le bas et touche la queue, en forme d'éventail. Il repose grâce à sa serre gauche sur un figuier de Barbarie en fleur, lequel pousse sur un rocher émergeant d'un lac (celui de Texcoco). Le volatile tient par la serre droite et le bec un serpent recourbé qu'il donne l'impression de dévorer, 32 « piquants » du cactus se ramifient sur les côtés représentent les 32 États du Mexique.
Deux branches de lauriers, reliées en bas par un ruban aux couleurs du drapeau, forment un demi-cercle inférieur. Les couleurs autres que celles du ruban ne sont pas explicitées mais une indication « quand les armes sont reproduites en couleurs naturelles » laisse supposer que c'est la manière « standard » de les dessiner.

On utilise généralement :
Les dimensions ne sont pas spécifiées. Sur les drapeaux officiels, le nopal et l'aigle occupent la majeure partie des armes ; le lac et le promontoire sont schématisés et de petite taille. Une modification récente de la loi a permis de trancher sur la représentation de l'aigle sur le revers du drapeau : elle est vue en image miroir, de profil droit et reposant sur sa serre droite. Il n'est pas précisé si les autres éléments des armes suivent cette transformation.

Les couleurs du drapeau proviennent de la bannière de l'Armée des Trois Garanties, utilisé entre 1821 et 1823. Initialement, les couleurs avaient les significations suivantes :

La signification des couleurs a changé une fois. L'une des causes est la laïcisation du pays, avec la constitution de 1857 de tendance libérale et les Lois de Réforme menées par le président Benito Juárez. Une dépêche d'agence de presse reproduite sur le site de la présidence de la République indique la symbolique actuelle suivante : 

On attribue aussi au blanc l'unité et la pureté, parfois, le lien de parenté ou le métissage au rouge, la symbolique n'étant pas définie de manière officielle. Aussi le site du groupe parlementaire du , parti conservateur de tradition catholique, indique-t-il la signification originelle « indépendance de la Nation, pureté de la religion et union du pays ».

Les espèces représentées ne sont pas précisées par la loi ni par son auteur le peintre Francisco Eppens Helguera.

À l'étranger on considère généralement qu'il s'agit d'un aigle royal car très utilisé dans l'héraldique européenne, bien qu'officiellement il n'en soit rien. Le sujet donne lieu a des polémiques dans le pays car l'ornithologue mexicain Rafael Martín del Campo a envisagé que le Caracara du Nord soit l'aigle sacré dépeint sur plusieurs codex aztèques comme le codex florentin (lire références).

Le caracara, dit « aigle mexicain » peut se percher sur des cactus, à la différence de l'aigle royal, car ses serres sont suffisamment puissantes pour qu'il ne s'y blesse pas. Le caracara a une crête (comme représenté sur les armoiries), pas l'aigle royal. L'aigle mexicain se perche sur une patte et de l'autre tient sa proie (qui peut être un serpent), l'aigle royal ne procède pas ainsi. De plus l'aire de répartition de l'aigle royal ne comprend pas le centre du Mexique où est situé le lac Texcoco.

Le serpent a été remplacé en 1917 par un serpent proche du serpent à sonnette ; auparavant il représentait un serpent d'eau du lac de Texcoco.

Le symbolisme des couleurs varie selon les auteurs mais l'interprétation principale est l'espoir (vert), l'unité (blanc) et le sang des héros (rouge). L'aigle perché sur le cactus dévorant un serpent est issu de l'interprétation erronée espagnole d'une légende aztèque et de la traduction également fausse de la phrase en náhuatl qui signifie le serpent siffle et non comme on l'a traduit le serpent est détruit : selon cette version, donnée par le moine dominicain Diego Durán, les Aztèques nomades ont fondé leur capitale Tenochtitlan — sur le même site est fondée Mexico — à l'endroit où ils ont observé ce symbole. Le lac et l'îlot, symboles aztèques également, ont été repris afin d'affirmer les origines indigènes des Mexicains, une nouvelle « race » issue du métissage. La position de l'aigle décrit la combativité et les lauriers, le succès.

Il existe variantes du drapeau autorisées. Principalement employées par les gouvernements locaux et fédéraux, elles diffèrent du drapeau standard par la couleur des armes. La première, utilisée par le président et les ministères fédéraux, possède des armes dans des teintes d'or, à l'exception du ruban tricolore, et de l' ainsi que des griffes de l'aigle de couleur argent. Les armes de la seconde, utilisée par les administrations n'ayant pas autorisation d'utiliser la première, sont entièrement d'or, y compris la montagne, le lac, les griffes et le ruban tricolore.

Le drapeau peut être décoré d'une « cravate » (), composée d'un ruban tricolore de mêmes couleurs que le drapeau. Elle est placée en haut du drapeau près du mât. Les deux extrémités pendent à des hauteurs différentes et se terminent par une frange dorée.

La marine mexicaine utilise également un drapeau spécifique comme pavillon de beaupré. De format carré, il reprend les couleurs nationales dans un ordre différent et en diagonale. Il est chargé de trois étoiles dorées et d'une ancre blanche.

Avant l'adoption du premier drapeau national, d'autres drapeaux employés durant la Guerre d'indépendance du Mexique contre l'Espagne ont eu beaucoup d'influence dans la composition du premier drapeau.
Il faut aussi rappeler que Hidalgo n'appelait pas a l'Indépendance mais se révoltait contre les espagnols favorables à Joseph Bonaparte.

José María Morelos utilise une enseigne bordée de carrés blancs et bleu ciel, une aigle couronnée sur un cactus, entouré des lettres « » (pour ses yeux et ses mains également victorieux), et un pont à trois arcs comportant les lettres VVM (« , Vive la Vierge Marie), le tout en bleu marine.

Après la mort d'Hidalgo, Ignacio López Rayón qui lui voulait l'indépendance totale du pays par rapport à l'Espagne imagina un drapeau très semblable au drapeau actuel qu'il proposa en 1811 à Zitácuaro à l'examen de la Suprema Junta Nacional Americana, celle-ci l'adopta et fixa les couleurs et leur organisation ainsi que l'aigle perchée sur le cactus.

Les insurgés ont aussi utilisé une enseigne bordée de rouge, en damier blanc et bleu ciel, au centre de laquelle est disposée l'aigle sur un cactus poussant d'une montagne émergeant d'un lac, et couronné de laurier. Cette était une enseigne de guerre.

Un des ancêtres du tricolore mexicain est celui de l'Armée des Trois Garanties de 1821 à 1823. Il s'agit d'un tricolore vert-blanc-rouge de bandes en contre-oblique comportant trois étoiles, respectivement blanche, rouge et verte dans les coins supérieur gauche, supérieur droit et inférieur droit. Au centre figure une couronne or et pourpre entourée de la mention « » (religion, indépendance et union) en majuscules noires. Il en existe plusieurs variantes utilisées par divers régiments ou compagnies. Ce drapeau n'a jamais été un emblème national ; par ailleurs, il est souvent représenté de manière erronée sans la couronne et avec trois étoiles d'or à huit branches sur la diagonale.


Quand la bannière défile devant un groupe de personnes, qui sont en uniforme militaire, celles-ci doivent présenter leurs saluts réglementaires.

Les civils présents doivent faire le salut suivant au drapeau national : debout, le civil lève son bras droit et joint sa main droite à la poitrine, sur le cœur. La main doit être ouverte et la paume de la même main dirigée vers le sol. Ce salut est appelé . Le président agissant en tant que commandant suprême des forces armées doit utiliser le salut militaire. Quand l'hymne national est joué à la télévision à l'ouverture et à la fermeture des programmes quotidiens, la bannière doit être montrée en même temps.

Les jours où le drapeau doit être hissé, ou au contraire placé en berne en signe de deuil, sont listés dans la loi de 1984 sur l'écu, le drapeau et l'hymne nationaux. Aux autres dates, le président peut, en cas d'événements d'importance exceptionnelle, demander que le drapeau soit hissé ou placé en berne.

Le jour du drapeau au Mexique se célèbre le 24 février, il a été instauré par Lázaro Cárdenas del Río en 1937 devant le monument à Vicente Guerrero, le premier à avoir prêté serment au drapeau national : ce même jour de 1821, toutes les parties combattant pour l'indépendance ont juré fidélité au drapeau après avoir uni leurs forces pour former l'Armée des Trois Garanties dans le cadre du Plan d'Iguala — signé par le Vicente Guerrero y Agustín de Iturbide — déclarant officiellement le Mexique comme pays indépendant.

Les drapeaux monumentaux (en espagnol ) sont un ensemble de drapeaux de grande taille situés sur le sol mexicain. Ils sont accrochés à un mât d'au moins de haut et mesurent au minimum sur .

Ils font partie d'un programme commencé à la fin des années 1990 par le président Ernesto Zedillo Ponce de León, puis officiellement lancé et pris en charge par le secrétariat de la défense navale en 1998. L'objectif, dans la suite de la loi de 1984, est de promouvoir le patriotisme et les symboles nationaux : aussi Zedillo indique-t-il, lors de l'inauguration du drapeau monumental de Nuevo Laredo le , que . Les drapeaux sont placés à des endroits d'importance particulière pour le pays, notamment aux villes-frontières pour démontrer la souveraineté nationale. Le président explique ainsi : 

Sont aussi concernés les endroits d'importance historique. Tout en laissant le choix des lieux d'édification des drapeaux, le programme explicite les endroits d'importance suivants :

Capitale :


D'autres drapeaux monumentaux ont été construits avec des tailles diverses : en juin 2006, le gouvernement mexicain en comptabilisait 62, dont une partie financée en dehors du programme de la défense navale, essentiellement par des collectivités locales. Les plus notables sont une douzaine de drapeaux mesurant environ x sur un mât d'une centaine de mètres, en particulier :




</doc>
<doc id="14329" url="https://fr.wikipedia.org/wiki?curid=14329" title="Intégrale de Lebesgue">
Intégrale de Lebesgue

En mathématiques, l’intégrale de Lebesgue désigne à la fois une théorie relative à l'intégration et à la mesure, et aussi le résultat de l'intégration d'une fonction à valeurs réelles définie sur formula_1 (ou sur formula_2), munis de la mesure de Lebesgue.

Généralisant l'intégrale de Riemann, l'intégrale de Lebesgue joue un rôle important en analyse, en théorie des probabilités et dans beaucoup d'autres domaines des mathématiques.

Dans les cas simples, l'intégrale d'une fonction positive formula_3 peut être vue comme l'aire comprise entre l'axe des formula_4 (l'axe horizontal) et la courbe de la fonction formula_3. En étendant cette notion, la construction de l'intégrale de Lebesgue s’applique à un ensemble plus riche de fonctions définies sur des espaces plus généraux que formula_1 ou formula_2.

Après la construction de l'intégrale de Cauchy-Riemann, l’intérêt s’est porté sur des extensions du théorème fondamental du calcul intégral :
Les études réalisées sur l'intégrale de Riemann aboutissent au théorème suivant qui est le « meilleur qu'on sache démontrer » :
Cependant, il existe des fonctions "F" dérivables sur ["a", "b"] sans que leur dérivée soit Riemann-intégrable.

L'objectif premier de l'intégrale de Lebesgue est de lever cette restriction afin de satisfaire à l'énoncé :
Par la suite, d’autres constructions d'une intégrale ont été élaborées (intégrale de Kurzweil-Henstock, Denjoy, Perron, Khintchine, ...) et elles satisfont à l'énoncé plus général

Avant les travaux d’Henri Lebesgue, la théorie de l'intégration s'appuyait sur l'intégrale de Riemann, mais celle-ci était plutôt insatisfaisante pour diverses raisons : problème de définition « efficace » des intégrales dites "impropres" (par exemple l’intégrale de Dirichlet), difficulté à établir des théorèmes de convergence…

En concevant son intégrale, Lebesgue l'a lui-même comparée à l'intégrale de Riemann : Pour comprendre cette phrase, il faut préciser que l'intégration de Riemann « parcourt » le segment et exploite au fur et à mesure la « hauteur » "y" de la fonction, alors que l'intégration de Lebesgue exploite la « taille » des ensembles de niveau "f" = "y" pour toutes les valeurs de "y". 

Cette théorie s'est avérée particulièrement féconde. Elle a permis (via la théorie des tribus) de formaliser les probabilités, de définir de nombreux espaces fonctionnels extrêmement importants et elle a marqué le début de la théorie de la mesure.

L'idée générale consiste à définir l'intégrale de fonctions simples (en l'occurrence les fonctions étagées positives), d’étendre successivement cette notion à toute fonction mesurable à valeurs positives, puis finalement à une catégorie plus riche : les fonctions mesurables.

Soit formula_8 un espace mesurable. En analyse réelle, formula_9 est l'espace euclidien formula_10; formula_11 désigne la tribu des borélien de formula_10, et formula_13 la mesure de Lebesgue. En probabilité et en statistique, formula_13 est une probabilité sur un espace probabilisable formula_15.

L'intégrale de Lebesgue des fonctions mesurables définies sur "formula_9" et à valeurs réelles est construite de la manière suivante :

Soit "formula_17" un élément de formula_11 et soit "formula_19" la "fonction indicatrice de formula_17" : c'est la fonction définie sur "formula_9" qui vaut 1 dans "formula_17" et 0 en dehors. 

La valeur attribuée à formula_23 est conforme à la mesure μ :

formula_24

Par linéarité, l’intégrale est étendue à l'espace vectoriel engendré par les fonctions indicatrices positives (une combinaison linéaire finie de fonctions indicatrices s'appelle une fonction étagée) :

formula_25

pour toute somme finie et tous coefficients formula_26 réels et positifs.

Remarquons que l’intégrale ainsi définie pour une fonction qui est une combinaison linéaire de fonctions indicatrices est indépendante du choix de la combinaison : c'est une condition essentielle à la consistance de la définition (preuve).

Soit formula_3 une fonction mesurable à valeurs positives dans formula_28. L’intégrale de Lebesgue de "formula_3" est définie comme étant la borne supérieure de formula_30 pour toute fonction étagée positive formula_31 inférieure à "formula_3" (formula_33 pour tout "formula_4"). Lorsque les formula_30 ne sont pas bornées, alors formula_36 est infinie.

Remarque : cette construction est analogue à celle des sommes inférieures de Riemann, bien qu’elle n’envisage pas de somme supérieure ; ce fait important permet d’obtenir une classe plus générale de fonctions intégrables.

Pour être plus précis, il convient encore de mentionner la mesure et le domaine d'intégration :
formula_37

L’intégrale est ainsi établie pour toute fonction définie sur "formula_9" et à valeurs positives. Cependant, afin de satisfaire des propriétés de linéarité et de convergence pour des suites, les fonctions considérées sont limitées aux fonctions "mesurables", soit celles pour lesquelles l'image réciproque de tout intervalle soit dans la tribu "formula_11".

Une telle fonction formula_3 mesurable sur l'ensemble "formula_9" et à valeurs dans formula_42 se décompose en une différence de deux fonctions positives formula_43 et formula_44. Si formula_45, alors "formula_3" est dite "intégrable au sens de Lebesgue" ou "sommable". Dans ce cas, les deux intégrales formula_47 et formula_48 sont finies et donnent un sens à la définition.

formula_49

Il est possible de vérifier que cette définition étend la notion d'intégrale de Riemann.

Les fonctions à valeurs complexes peuvent être intégrées de la même manière, en intégrant séparément la partie réelle et la partie imaginaire.

Toute notion raisonnable d'intégrale doit satisfaire les propriétés de linéarité et de monotonie. L'intégrale de Lebesgue ne fait pas exception : si "formula_3" et "formula_51" sont des fonctions intégrables et si "formula_52" et "formula_53" sont des nombres réels, alors formula_54 est intégrable et formula_55; si "formula_56", alors formula_57 (et de même en remplaçant les deux ≤ par des <, si le domaine d'intégration est de mesure non nulle), en particulier formula_58. On démontre que cette inégalité est vraie aussi pour "formula_3 "à valeurs complexes.

Deux fonctions qui diffèrent seulement sur un ensemble de mesure μ nulle (on dit alors que "formula_3" et "formula_51" sont égales µ-presque-partout) ont la même intégrale, ou plus précisément : si formula_62, alors "formula_3" est intégrable si et seulement si "formula_51" est intégrable, et dans ce cas formula_65.

Toute fonction intégrable à valeurs dans est finie presque partout, c'est-à-dire que l'ensemble des points où elle prend les valeurs formula_66 est de mesure nulle.

Comparativement à l'intégrale de Riemann, l'un des avantages essentiels de l'intégrale de Lebesgue est la facilité avec laquelle s'effectue un passage à la limite. Les trois théorèmes suivants sont parmi les plus utilisés : 





</doc>
<doc id="14336" url="https://fr.wikipedia.org/wiki?curid=14336" title="Géographie du Brésil">
Géographie du Brésil

Le Brésil est un pays d'Amérique du Sud. Cinquième pays du monde par sa superficie, il est bordé à l'est par l'océan Atlantique et s'étend vers l'intérieur du continent le long des bassins hydrographiques des fleuves Amazone et Paraná.

Son territoire peut schématiquement se diviser en deux principales zones : la moitié nord-ouest du pays se constitue du bassin de l'Amazone, couverte par la forêt équatoriale tandis que le sud-est est une région de plateaux et de montagnes, couverte de savanes et de forêts. Cette division rapide ne doit cependant pas masquer la diversité des biomes du territoire brésilien qui vont des forêts tropicales humides du bassin amazonien aux prairies inondées du Pantanal et des savanes semi-arides du Sertão aux mangroves du littoral.

Le climat est tropical sur la majorité du pays, chaud et humide. Les saisons, inversées par rapport à l'hémisphère nord (hiver en juin, juillet et août) sont peu marquées sur la majorité du territoire. En hiver les températures descendent rarement en dessous de alors qu'elles montent fréquemment à plus de en été. Seules les montagnes du sud du pays peuvent connaître exceptionnellement des températures négatives.

Avec une superficie de plus de 8,5 millions de kilomètres carrés, le Brésil occupe une grande part des côtes orientales de l'Amérique du Sud, la partie centrale du continent ainsi que quelques îles de l'océan Atlantique. Cinquième pays du monde par la superficie, il n'est dépassé que par la Russie, le Canada, la Chine et les États-Unis. Son territoire s'étend sur du Nord au Sud (5°16'20" Nord à 33°44'32" Sud de latitude) et d'Est en Ouest (34°47'30" Ouest à 73°59'32" Ouest de longitude) et couvre trois fuseaux horaires. La capitale Brasilia et les zones les plus peuplées du pays se situent dans le fuseau .

Au-delà du continent et des îles côtières, le Brésil possède également l'archipel Fernando de Noronha, situé à au nord-est de son extrémité orientale, ainsi que quelques îlots dans l'Atlantique, l'archipel des Abrolhos, l'atoll das Rocas, les rochers de Saint-Pierre et Saint-Paul et les îles de Trindade et Martim Vaz.

À l'Est, le long de l'Atlantique, le littoral brésilien s'étend sur . À l'Ouest, le Brésil partage de frontières avec, successivement dans le sens des aiguilles d'une montre du Sud au Nord, l'Uruguay, l'Argentine, le Paraguay, la Bolivie, le Pérou, la Colombie, le Venezuela, le Guyana, le Suriname et la Guyane française. Les seuls pays sud-américains ne partageant pas de frontière avec le Brésil sont le Chili et l'Équateur. Quelques portions de frontières font l'objet de discussion mais le Brésil n'entretient pas de conflit majeur à propos des frontières avec ses voisins.

Le pays est traversé à la fois par la ligne de l'équateur au Nord et par le tropique du Capricorne au Sud. La majeure partie, soit 93 %, de son territoire se situe dans l'hémisphère sud. 92 % se trouve dans la zone intertropicale et 8 %, à l'extrême Sud, dans la zone tempérée

Le Brésil est un pays au relief modeste. 40 % du territoire national se situe à moins de d'altitude, 45 % entre et et 12 % entre et . Seuls 3 % constituent les zones montagneuses, dépassant les d'altitude. Les principales formes de relief du pays sont les plaines et des plateaux.
Les plaines couvrent plus de de kilomètres carrés du territoire brésilien. Elles se divisent en trois principales zones : le bassin amazonien, le Pantanal et les plaines littorales.

La plus vaste zone de basses terres du pays se trouve dans la région Nord du pays, il s'agit de la plaine amazonienne, située entre le plateau des Guyanes au Nord et le plateau brésilien au Sud, l'océan Atlantique à l'Est et la cordillère des Andes à l'Ouest. La zone de plaine à proprement parler n'occupe qu'une partie de la région, entourées de vastes plateaux sédimentaires de faible altitude. Depuis le lit des fleuves, on observe trois zones qui se distinguent par leur altitude :

La plus particulière des plaines brésiliennes est le Pantanal, située principalement dans l'Ouest du Mato Grosso do Sul, entre le plateau central et le plateau méridional. Baignée par le Paraguay et ses affluents, cette plaine est entièrement inondée chaque année en période de crue. Elle abrite un biome très riche de prairies et savanes inondées.

Les plaines côtières forment une longue et étroite bande littorale depuis l'État de l'Amapá jusqu'au Rio Grande do Sul. Elles peuvent être localement interrompues par des avancées des plateaux en direction de la mer. Ces terres basses sont constituées de terrains du Cénozoïques et de formations actuelles.

Les plateaux occupent environ de kilomètres carrés et se répartissent en deux zones principales, séparées par des plaines : le plateau des Guyanes et le plateau brésilien.



Les principales chaînes de montagnes du pays se situent le long du littoral atlantique (serra do Mar, serra da Mantiqueira ou serra do Espinhaço notamment) et dans l'extrême Nord du pays (sur le plateau des Guyanes). Au Nord du pays, le Pico da Neblina situé à la frontière avec le Venezuela, constitue le point culminant du Brésil avec d'altitude. Sur le plateau des Guyanes, on trouve nombreuses formations caractéristiques appelées tepuys. Concernant la chaîne littoral, elle culmine au pic de la Bandeira (), à la frontière du Minas Gerais et de l'Espirito Santo.

Le Brésil possède l'un des réseaux hydrographiques les plus étendus de la planète. Le seul bassin de l'Amazone, principal fleuve mondial par le débit, représente environ 20 % du volume total des eaux douces déversées dans les océans. L'Amazone est également le second fleuve du monde par la longueur après le Nil. Le second principal cours d'eau du pays est le fleuve Paraná qui prend sa source au Brésil avant de traverser également le Paraguay et l'Argentine.

La plupart des fleuves et rivières du Brésil sont des cours d'eau de hauts-plateaux. Ces derniers, comme le rio Paraná ou le rio São Francisco, présentent de nombreuses gorges et cascades et possèdent des dénivelés importants qui permettent une exploitation hydroélectrique. Les exceptions notables à cette proposition sont l'Amazone et le Paraguay qui occupent d'immenses bassins et plaines. La quasi-totalité des cours d'eau brésiliens sont exoréiques.

Les fleuves brésiliens présentent un régime pluvial, alimentés presque exclusivement par les eaux de pluie, très abondantes dans la zone intertropicale. La plupart des cours d'eau de la région tropicale connaissent de fortes variations de débit à cause d'une saison des pluies marquée. La plupart de ces cours d'eau sont pérennes, seule la région semi-aride du Nordeste présente des cours d'eau temporaires.

Les cours d'eau brésiliens peuvent être regroupés en quatre bassins fluviaux principaux et trois bassins côtiers secondaires.

Concernant les lacs, le Brésil en possède peu. On peut les partager en deux catégories :
On peut également y ajouter les lacs artificiels, résultants de la construction de barrages sur les cours d'eau.

Bien que plus de 90 % du territoire brésilien se situe en zone tropicale, le climat du pays varie considérablement du Nord au Sud. Le Brésil comporte cinq régions climatiques différentes : équatoriale, tropicale, semi-aride, tropicale d'altitude et subtropicale.

Au Nord, les températures autour de l'Équateur sont élevées, avec des moyennes annuelles supérieures à mais n'atteignent jamais les températures extrêmes (supérieures à ) des zones dites tempérées. Les variations saisonnières y sont peu importantes. À l'autre extrémité du pays, des gelées peuvent survenir au Sud du tropique du Capricorne durant les mois d'hiver et des chutes de neige surviennent dans les zones montagneuses des États du Paraná, du Rio Grande do Sul et de Santa Catarina. Les températures dans les villes de Belo Horizonte et Brasília sont modérées (généralement comprises entre 15 et ) du fait de leur altitude avoisinant les . Rio de Janeiro, Recife ou Salvador, situées sur les côtes, connaissent un climat chaud, avec des températures moyennes autour de mais bénéficie de brises marines. Les villes du Sud, comme São Paulo, Porto Alegre et Curitiba ont un climat subtropical et les températures peuvent exceptionnellement y descendre sous les en hiver. Le sud est la région où l’occurrence de la Neige au Brésil est la plus fréquente.

Le niveau des précipitations varie fortement à travers le pays. La majeure partie du pays connaît des précipitations modérées, comprises entre et par an, principalement concentrées sur les mois d'été (de décembre à avril), au Sud de l'Équateur. La région amazonienne est très humide, avec des précipitations supérieures à par an et qui peuvent atteindre plus de dans certaines régions de l'Amazonie occidentale comme vers la ville de Belém. La région amazonienne connaît cependant une saison relativement sèche qui dure de trois à cinq mois.

Ces précipitations abondantes et régulières de la zone équatoriale contrastent avec le climat semi-aride de la région du Nordeste, où les précipitations sont rares et où se produisent de fréquentes sécheresses. Le Nordeste est la zone la plus sèche et également la plus chaude du pays. Pendant la saison sèche (de mai à novembre) les températures peuvent dépasser les . La majeure partie du Centre-Ouest du pays reçoit de à de précipitations annuelles, avec une saison sèche très marquée, alors que dans le Sud du pays les précipitations sont équitablement réparties tout au long de l'année.

Six biomes distincts se partagent le territoire brésilien :

La variété des climats, sols et d'écoulements des eaux du Brésil se constate dans les différents types de végétation rencontrés à travers le pays. Le bassin de la l'Amazone et les autres zones aux précipitations abondantes le long de la côte atlantique sont couverts d'une forêt tropicale humide. Cette forêt pluviale comprend plus de espèces différentes de flore et de faune par kilomètre carré. La forêt atlantique présente une diversité biologique encore supérieure à celle de la forêt amazonienne.

Dans le Nordeste semi-aride prédomine la caatinga, un type de végétation basse formée de petits épineux. La majeure partie du centre du pays est couverte d'une végétation de type savane, appelée cerrado et formée d'arbres éparses, de buissons et d'herbe résistantes à la sécheresse. Ce milieu constitue la principale zone de développement agricole depuis les années 1970. Dans le sud du pays, la forêt ombrophile mixte, à base de pins du Paraná (ou "araucaria"), couvre les hautes-terres tandis qu'une végétation de plaine similaire à la pampa argentine s'étend sur les basses-terres du Rio Grande do Sul. Dans le Mato Grosso, les terrains marécageux du Pantanal, couverts de grandes herbes, de plantes ligneuses et d'arbres éparses à la saison sèche, sont largement inondées durant la saison des pluies.

Le Brésil, dont le nom provient du bois de Pernambouc ("pau-brasil" en portugais) est connu depuis longtemps pour la richesse de ses forêts littorales. Celle-ci ne sont cependant plus exploitées aussi intensément à l'heure actuelle que les forêts d'Asie et d'Afrique qui n'ont commencées à s'épuiser qu'à partir des années 1980. Aujourd'hui, il ne subsiste que moins de 10 % de la forêt atlantique originelle qui a été pratiquement complètement rasée, notamment pour les besoins de l'agriculture. Elle est peu exploitée pour son bois, à l'exception des forêts d'araucaria du Sud du pays.

La situation est inverse pour ce qui concerne la forêt du bassin amazonien qui est largement exploitée pour son bois et dont 15 % avait été rasée en 1994 et une part importante abîmée par un abattage sélectif. Du fait de son hétérogénéité, avec des centaines d'espèces différentes à l'hectare, la distance entre les arbres d'intérêt économique peut être très importante. Ce type de forêt n'est donc généralement pas abattu en masse pour l'exploitation forestière mais fait l'objet d'un abattage sélectif des espèces présentant une valeur marchande. Cependant, du fait de la présence de plantes grimpantes, de la chute des arbres et de leur transport, cette exploitation cause des dégâts considérables à la forêt. Les détritus qui en résulte entraînent également un risque accru de feu de forêt, généralement rares dans les forêts pluviales.

Depuis la fin des années 1980, une déforestation rapide associée à la pratique de l'agriculture sur brûlis fait l'objet d'une attention croissante de la part de la communauté nationale et internationale. Des politiques publiques ont tenté de promouvoir des pratiques relevant du développement durable quant à l'exploitation forestière et à l'utilisation des forêts non exploitables depuis le milieu des années 1990.

Le sol tropical du Brésil produit annuellement 70 millions de tonnes de céréales, principalement du maïs et du riz, ce qui le place parmi les principaux producteurs mondiaux. Ces chiffres sont cependant principalement atteints de par l'étendue des zones cultivées plutôt que du fait de leur fertilité. Malgré les premières observations des explorateurs portugais qui vantaient l'exceptionnelle fertilité du sol, les données concernant la productivité des sols sont généralement décevantes. À une fertilité initiale consécutive au défrichement et au brûlis succède un rapide épuisement du sol, dont l'acidité et le taux d'aluminium sont souvent élevés. La température et l'humidité favorisent également la prolifération de mauvaises herbes et de nuisibles qui entraînent une perte de fertilité. Ces facteurs expliquent le mouvement généralisé vers l'Ouest des agriculteurs et la pratique d'une agriculture de défrichement et de brûlis, car la culture de nouvelles terres nécessite moins d'efforts et d'investissements que l'exploitation permanente d'un terrain. Ce schéma d'agriculture maintient bas les niveaux de technologie et de productivité et met davantage l'accent sur la quantité que sur la qualité.

Les principales zones de terres fertiles, la « terre rouge » ("terra roxa" en portugais) se situent dans les États du Paraná de São Paulo. Les terres les moins fertiles sont celles du bassin de l'Amazone, couvertes par la forêt pluviale. Les terres du Nordeste sont généralement fertiles mais souffrent d'un manque d'eau, malgré la pratique de l'irrigation.

Dans les années 1980, des investissements ont permis l'usage de l'irrigation dans le Nordeste et au Rio Grande do Sul, qui est passé d'une agriculture d'élevage extensif à la culture du riz et du soja. Les sols de la savane sont également rendus utilisable pour la culture du soja par correction d'acidité, usage de fertilisants, sélection des plants et parfois irrigation. Avec la modernisation de l'agriculture depuis les années 1970-1980, le facteur de la fertilité du sol a perdu de son importance pour la production agricole. La poussée vers de nouvelles terres à cultiver a donc perdu de sa vigueur.

Au dernier recensement datant de 2010, la population du Brésil s'élève à habitants. Le Brésil est le cinquième pays au monde pour sa population.

La population se repartit principalement sur le littoral et dans les régions Sud-Est (plus de 77 millions d'habitants) et Nord-Est (plus de 51 millions d'habitants), où se situent également les principales agglomérations du pays, São Paulo, Rio de Janeiro et Salvador. São Paulo, avec plus de 11 millions d'habitants, est la plus grande ville d'Amérique du Sud. Parallèlement, le Nord et l'Ouest du pays, avec des densités de population inférieures à 10 habitants par kilomètre carré sont très faiblement peuplés.

L'immigration a joué un grand rôle dans la formation de la population brésilienne. Les premiers peuples à s'installer sur le territoire du Brésil actuel furent des peuples originaires de Sibérie qui traversèrent le détroit de Béring aux alentours de ans pour former les populations dites indigènes au moment de l'arrivée des Européens. La seconde vague d'immigration fut celle constituée des colons portugais, depuis la reconnaissance du pays par Cabral en 1500 jusqu'à son indépendance en 1822. Cette vague fut concomitante à l'arrivée forcée d'esclaves en provenance d'Afrique, du jusqu'au milieu du . À la fin du et au début du de nombreux immigrants en provenance d'Europe s'installèrent dans le pays, encouragés par le gouvernement brésilien. Récemment, les principales sources d'immigration vers le Brésil sont les pays d'Asie et du Moyen-Orient.

Les premières richesses naturelles du Brésil sont les ressources, abondamment disponibles en surface, que sont le bois comme matériau de construction et l'eau pour son potentiel hydroélectrique. En 2007, plus de 55 % de la superficie totale du pays sont couverts de forêts. Le Brésil est par ailleurs l'un des trois principaux pays producteurs d'énergie hydroélectrique au monde avec la Chine et le Canada. En 2008, près de 80 % de l'électricité produite dans le pays est d'origine hydraulique.

Le sous-sol brésilien est riche de nombreux gisements de minéraux, parmi lesquels les plus importants sont la bauxite, l'or, le fer, le manganèse, le nickel, les phosphates, le platine ou l'uranium. Le pays compte également d'importantes réserves d'hydrocarbures, récemment découvertes, comme au large de l'État de Rio de Janeiro, qui assurent d'ores et déjà l'autosuffisance du pays vis-à-vis de sa consommation de pétrole.

Le Brésil possède deux principaux échelons de divisions administratives, les États ("estados" en portugais) et les municipalités ("municípios" en portugais). Au sein de chacune de ces divisions administratives, le pouvoir local est exercé sur le même modèle qu'au sein de l'État fédéral, avec un pouvoir exécutif, une assemblée législative et un pouvoir judiciaire spécifique.

Le Brésil est divisé en 26 États et un district fédéral, qui regroupent municipalités. Ces États possèdent une large autonomie au sein de la fédération brésilienne mais pas de souveraineté propre. Les États peuvent être regroupés en cinq régions principales. Ces dernières sont dépourvues de prérogatives politiques et n'ont pour utilité que de regrouper des États présentant une cohérence culturelle et une unité géographique.



</doc>
<doc id="14337" url="https://fr.wikipedia.org/wiki?curid=14337" title="Domaine de diffusion">
Domaine de diffusion

Un domaine de diffusion (en anglais, "broadcast domain") est une aire logique d'un réseau informatique où n'importe quel ordinateur connecté au réseau peut directement transmettre à tous les autres ordinateurs du même domaine, sans devoir passer par un routeur.

Plus spécifiquement, c'est une zone du réseau informatique composée de tous les ordinateurs et équipements de communication qui peuvent être contactés en envoyant une trame à l'adresse de diffusion de la couche liaison de données.

Généralement, les concentrateurs et commutateurs conservent le même domaine de diffusion, alors que les routeurs les divisent. L'utilisation de réseaux virtuels permet cependant de séparer virtuellement un commutateur en plusieurs domaines de diffusion.Et le routeur est un élément indispensable a la communication de deux domaines de diffusions .



</doc>
<doc id="14339" url="https://fr.wikipedia.org/wiki?curid=14339" title="Domaine de collision">
Domaine de collision

Un domaine de collision est une zone logique d'un réseau informatique où les paquets de données peuvent entrer en collision entre eux, en particulier avec le protocole de communication Ethernet.

Un domaine de collision peut être un seul segment de câble Ethernet, un seul concentrateur ou même un réseau complet de concentrateurs et de répéteurs.

Généralement, un concentrateur forme un seul domaine de collision alors qu'un commutateur ou un routeur en crée un par port, ce qui réduit les risques de collision. 

Lorsque l'Ethernet est utilisé en mode full-duplex, il n'y a plus de domaine de collision, car aucune collision n'est possible.



</doc>
<doc id="14346" url="https://fr.wikipedia.org/wiki?curid=14346" title="Région">
Région

La dénomination région peut désigner :





</doc>
<doc id="14347" url="https://fr.wikipedia.org/wiki?curid=14347" title="Régions de France">
Régions de France


</doc>
<doc id="14361" url="https://fr.wikipedia.org/wiki?curid=14361" title="Washington (district de Columbia)">
Washington (district de Columbia)

Washington, dans le district de Columbia (), souvent appelée Washington, D.C., The District, ou simplement D.C. (pour éviter la confusion avec l'État de Washington), est une ville indépendante américaine, capitale des États-Unis. Selon les dernières estimations (2013), elle compte "intra-muros" sur une superficie de ; son aire urbaine en compte environ , la septième des États-Unis. 

En tant que capitale fédérale, elle ne fait pas partie des cinquante États de l'Union et dépend directement du gouvernement fédéral. À ce titre, la ville est le siège de nombreuses institutions américaines, telles que la Maison-Blanche, résidence officielle du président ; le Capitole, siège du Congrès (constitué de ses deux chambres : celle des représentants et le Sénat), ainsi que le siège de la Banque mondiale (BM), de la Cour suprême et d'autres organismes fédéraux, comme la Réserve fédérale des États-Unis (Fed). Elle accueille en outre 176 ambassades et représentations diplomatiques.

Washington est créée à la suite de la signature du "" en 1790, qui prévoit la création d'une capitale fédérale. Elle est fondée en janvier 1791, sur les rives du fleuve Potomac, à proximité des villes de Georgetown et d'Alexandria. Nommée en hommage au premier président des États-Unis, George Washington, elle est construite "ex nihilo" selon un plan hippodamien de l'ingénieur franco-américain Pierre Charles L'Enfant. L'urbanisme diffère de la plupart des autres villes américaines car la construction de gratte-ciel y est interdite : l'architecture de Washington est marquée par une faible hauteur et un héritage de l'architecture coloniale. Peu peuplée durant la première moitié du , ce n'est qu'à la fin de la guerre de Sécession qu'elle acquiert sa légitimité en tant que capitale, devenant le symbole de l'unité retrouvée.

Située sur la côte atlantique du nord-est du pays, entre le Maryland et la Virginie, la ville se trouve à soixante kilomètres au sud de Baltimore, à deux cents kilomètres de Philadelphie et trois cents kilomètres de New York. Elle marque l'extrémité méridionale de la mégalopole américaine, appelée également BosWash. Les coordonnées géographiques de la ville correspondent au point zéro, d'où sont calculées toutes les distances routières aux États-Unis. Son climat est de type subtropical humide, avec de fortes variations de température entre l'été et l'hiver.

En tant que siège de la plupart des institutions fédérales, l'économie est fortement dépendante des activités gouvernementales, qui représentent jusqu'à 50 % de son PIB au milieu du . Aujourd'hui, l'économie est diversifiée, notamment dans l'industrie de l'armement et de l'informatique. 

La population de la ville se stabilise de nos jours autour de habitants, après avoir connu une baisse importante depuis la Seconde Guerre mondiale, essentiellement en raison du départ des Blancs pour les banlieues environnantes. Devenue une ville en majorité composée d'Afro-Américains (50,1 %), Washington comprend historiquement plusieurs ghettos et est depuis sa fondation un bastion du Parti démocrate.

La ville compte plusieurs universités, dont la prestigieuse université de Georgetown, ainsi que la Bibliothèque du Congrès, plus grande bibliothèque au monde. 

Washington dispose de services de polices dépendant de la municipalité ; ainsi que la Garde nationale du district de Columbia qui en tant que force fédérale dépend du président lui-même. Le district de Columbia ne dispose donc pas de forces autonomes comme les Polices d'État ou les Forces de défense d'État existant dans les États de l'Union. 

La ville de Washington est située au nord-est du pays, sur la rive gauche du Potomac à sa confluence avec la rivière Anacostia qui coule en aval du District. Elle se trouve entre les États de Virginie (au sud-ouest) et du Maryland (au sud-est, au nord-est et au nord-ouest).

Elle marque l'extrémité méridionale de la mégalopole américaine, appelée également BosWash.

Son territoire d'origine, en 1791, se présentait sous la forme d'un carré de de côté, positionné à cheval sur le fleuve Potomac. La rive gauche formant l'ancien comté d'Alexandria est cependant rétrocédée à la Virginie par décision du Congrès en 1846.

La partie du Potomac qui traverse Washington est entièrement comprise dans le district de Columbia et coupe également en deux la frontière entre la Virginie et le Maryland.

Les coordonnées géographiques de la ville correspondent au point zéro, d'où sont calculées toutes les distances routières aux États-Unis.

Selon le Bureau du recensement des États-Unis, la superficie de Washington est de , dont (10,16 %) sont occupés par des plans d'eau ou des cours d'eau, comme le Potomac, l'Anacostia et le Rock Creek. Il existe aussi plusieurs réservoirs artificiels : Dalecarlia Reservoir, qui traverse le coin nord-ouest du District depuis le Maryland, McMillan Reservoir près de l'université Howard et Georgetown Reservoir en amont de Georgetown. Washington compte également deux îles : Theodore Roosevelt Island et Columbia Island.

Le point culminant du district de Columbia se trouve à Tenleytown ; il s'élève à . tandis que les rives de l'Anacostia et du Potomac se situent au niveau moyen de la mer.

Le climat de Washington est typique de la façade orientale du continent. C'est un climat subtropical humide avec de notables variations entre l'été et l'hiver. Le total annuel moyen des précipitations est de . 

D'après la classification de Köppen : la température du mois le plus froid est comprise entre et (janvier avec ) et la température du mois le plus chaud est supérieure à (juillet avec ) donc c'est un climat tempéré. Les précipitations sont stables, il n'y a pas de saison sèche. C'est donc un climat tempéré chaud sans saison sèche. L'été est chaud car la température moyenne du mois le plus chaud est supérieure à (juillet avec ). 

Donc le climat de Washington est classé comme Cfa dans la classification de Köppen, soit un climat subtropical humide.

L'été tend à être très chaud et humide voire torride avec des températures élevées autour de , et des pointes fréquentes au-delà des , les orages accompagnés de pluies chaudes peuvent alors se produire mais passent très rapidement. La température la plus élevée jamais enregistrée à Washington est de le , le , le , le , le , et le . Du fait de l'humidité combinée aux hautes températures les indices de chaleur peuvent monter au-delà de rendant la chaleur suffocante. 

Le printemps et l'automne sont modérément chauds avec des températures maximales moyennes d'environ (en avril, en octobre) et des pointes à , qui ne sont pas rares. 

L'hiver, qui arrive souvent brutalement, apporte en général des températures basses (en moyenne en janvier, record : le ) et de la neige (en moyenne par an, avec des chutes parfois abondantes de plusieurs dizaines de cm), bien que des journées chaudes (plus de ) ne soient pas rares en janvier. La température moyenne annuelle à Washington est de . Les ouragans passent parfois dans la région, ils se sont généralement très affaiblis avant d'atteindre la ville : l'ouragan Isabel en septembre 2003 avait fait un mort à Washington.

Washington D.C. bénéficie d'un ensoleillement élevé avec en moyennes par an.

En janvier 2016, une tempête de neige surnommée "" s'abat sur toute la côte est des États-Unis. En trois jours (les 22, 23 et ), il est tombé près d'un mètre de neige à Washington D.C., à New York et à Philadelphie. Jamais une telle tempête n'avait autant perturbé les transports en commun, qui seront fermés dans ces trois villes. 

Le territoire de la ville est divisé en quadrants qui servent à situer un lieu par un système de coordonnées cartésiennes : Northwest (NW), Northeast (NE), Southeast (SE), et Southwest (SW). Le point origine de ce système de coordonnées est situé dans la crypte située sous la rotonde du Capitole et est marqué par une étoile incrustée dans le sol.

L'adresse d'une rue est donc toujours suivie de la mention du secteur, puisqu'il existe des coordonnées identiques dans chacun d'entre eux. De plus, au sein de chaque quadrant, les rues orientées nord-sud sont numérotées, tandis que les rues orientées est-ouest sont désignées par des lettres. Par exemple :

Washington, D.C. tient une place particulière parmi les villes américaines : son statut de capitale d'abord, mais surtout son paysage et son organisation urbaine font d'elle une ville à part. Tout d'abord, il n'existe aucun quartier de gratte-ciel si caractéristique des métropoles américaines. La hauteur des constructions a en effet été limitée par une limitant la hauteur des bâtiments à la largeur de la rue adjacente plus () et non à la hauteur du Capitole ou du Washington Monument contrairement à la croyance populaire.

Ensuite, le plan orthogonal, conçu par l'architecte et urbaniste français Pierre Charles L'Enfant, trace des axes obliques qui contrarient la structure en damier. Son projet d'urbanisme pour la ville de Washington avait d'abord été refusé, entre autres parce qu'il était jugé trop ambitieux. Puis, après avoir été oublié, il a finalement été utilisé pour organiser la capitale.

À la fin du , L'Enfant remporte le concours pour construire la capitale fédérale ("Federal City") sur les rives du Potomac. Le projet est lancé en 1791, mais ses plans ne sont que partiellement exécutés durant sa vie. Le projet lui est retiré et, par colère, il emporte ses plans avec lui. Cependant, ces derniers sont en grande partie reconstitués de mémoire par le mathématicien afro-américain Benjamin Banneker. Au tournant des s, les tenants du mouvement "City Beautiful" rêvent de réaliser des villes néoclassiques en créant un cadre harmonieux et monumental. Plusieurs villes voulurent appliquer ce concept, mais Washington, D.C. semble la plus aboutie et la plus homogène, avec ses constructions de couleur blanche.

Le paysage urbain est aéré en raison de l'absence de constructions très hautes, mais aussi grâce à de larges avenues et de nombreux parcs, dont le National Mall, , Theodore Roosevelt Island et l'Arboretum national des États-Unis. La densité du District est relativement faible par rapport à d'autres villes américaines, les bâtiments officiels et les monuments tiennent une place importante par rapport aux bâtiments destinés à l'habitat.

Il y a 34 aires protégées gérées par le National Park Service dans le district de Columbia :


Le recensement de 2000 faisait état de , de et de résidant dans la ville. La densité de population était de par km, la présence de nombreux espaces verts et de bâtiments administratifs non résidentiels expliquant ce chiffre relativement faible par rapport à New York () ou San Francisco (). L'aire métropolitaine du Grand Washington (), qui comprend les secteurs urbanisés des États voisins du Maryland et de Virginie, comprend une population totale estimée à d'habitants en 2003. La conurbation Washington-Baltimore concentre quant à elle , ce qui en fait la quatrième du pays.

Comme de nombreuses autres villes-centres américaines, le district de Columbia connaît un déclin démographique depuis la fin de la Seconde Guerre mondiale. Entre 1950 et 2000, il a perdu plus de , soit une baisse de près de 30 % en cinquante ans. Depuis 2005, il semble que cette tendance s'inverse, puisque la ville a attiré en cinq ans. Les migrations pendulaires sont particulièrement intenses à Washington : on estime en effet à le nombre de travailleurs qui viennent travailler chaque jour de la semaine, ce qui accroît de 72 % la population résidente. Enfin, étant donné la présence des et de centaines d'organisations internationales, Washington accueille un nombre important d'étrangers. La ville compte en outre une importante population étudiante, qui se répartit dans les différentes universités du district.

D'après les données de 2005, le revenu par foyer est de USD. Le taux de pauvreté est supérieur à la moyenne nationale (17,5 % de la population contre 12,5 % pour les États-Unis). Cependant, le revenu par habitant se situe nettement au-dessus de la moyenne américaine ( par habitant contre par habitant). Bien qu'un grand nombre de fonctionnaires, d'avocats et d'autres professionnels hautement qualifiés travaillent à Washington, la plupart n'y habitent pas, préférant notamment les quartiers résidentiels du nord-est de la Virginie voisine, du Maryland au nord-ouest (Bethesda, Potomac).

La répartition ethnique et les caractéristiques sociologiques des quartiers évoluent assez rapidement à Washington : au début du , les Blancs étaient largement majoritaires dans la ville, représentant 80 % de la population totale. Les familles riches ou des classes moyennes ont commencé à partir du centre-ville après la Seconde Guerre mondiale pour fuir les problèmes sociaux : dans les années 1970, Washington était surnommée "Chocolate City" (« ville chocolat »), car les Noirs comptaient pour les deux tiers de la population. Mais au début du , leur part était de 58 %.

Une partie des Afro-Américains vivant à Washington est pauvre et peu qualifiée, occupant des emplois subalternes. On peut distinguer les quartiers du nord-ouest, résidentiels à majorité blanche, des quartiers pauvres, à majorité noire du nord-est ou sud-ouest. Les quartiers du sud-est sont particulièrement touchés par la délinquance. On note par ailleurs la présence historique d'une bourgeoisie noire dans certains quartiers du nord-ouest (comme Adams Morgan, aujourd'hui plutôt "latino", ou U Street).
Par un processus de gentrification, la part des Blancs augmente et plusieurs quartiers, comme Columbia Heights ou Capitol Hill, changent rapidement. Le ghetto afro-américain d'Anacostia subit cette transformation qui passe par l'implantation d'une bourgeoisie noire et une hausse des prix de l'immobilier. La municipalité encourage ce processus, à condition de faire une place au logement social. La proportion de Latinos est plus faible que la moyenne nationale. Au sein de cette communauté, les Salvadoriens sont les plus représentés. Quant à la communauté asiatique, son dynamisme se manifeste dans le chinatown de la ville.
Selon une enquête effectuée en 2001, près d'un résident sur trois du district se réclame du christianisme. Les catholiques sont les plus nombreux.

Selon l"'American Community Survey", pour la période 2011-2015, 82,51 % de la population âgée de plus de 5 ans déclare parler l'anglais à la maison, 7,79 % déclare parler l'espagnol, 0,86 % une langue chinoise et 4,94 % une autre langue.

Créée officiellement par la Constitution des États-Unis (1787), la capitale fédérale américaine naît de rien au tout début du . Son plan est l'œuvre de Pierre Charles L'Enfant, un ingénieur militaire, fils d'un peintre de la cour de France qui propose ses services à George Washington, dont il a fait la connaissance durant la guerre d'Indépendance alors qu'il s'était engagé en 1777, à l'âge de , aux côtés des insurgés américains. Pendant la guerre anglo-américaine de 1812, les Britanniques reçoivent l'ordre de brûler les édifices publics de Washington, DC. Les Britanniques souhaitaient se venger des dommages causés à la capitale de la colonie du Haut-Canada (aujourd'hui Toronto) par les Américains après la bataille de York (1813). La destruction de la capitale des jeunes États-Unis devait démoraliser l'ennemi.

Le , le général britannique Robert Ross remporta la bataille de Bladensburg, qui lui ouvre le chemin de Washington. Cela provoque la retraite du président James Madison dans les montagnes de Virginie. La plupart des habitants de la ville s'enfuient également devant l'avancée britannique. Le 25 août, les troupes britanniques marchent sur Capitol Hill. Ne pouvant occuper la ville, Robert Ross veut la détruire. Les bâtiments du Sénat, de la Chambre des représentants et du Trésor sont détruits, de même que l'intérieur de la Bibliothèque du Congrès. Des témoins ont rapporté que l'incendie était visible depuis Baltimore. L’amiral Cockburn voulut brûler le siège du "National Intelligencer", un journal antibritannique. Mais quelques femmes l'en dissuadèrent en arguant que l'incendie risquait de se propager à leurs maisons. Les Américains brûlèrent les chantiers navals de Washington pour éviter qu'ils soient utilisés par les Britanniques. L'occupation de Washington prit fin lorsque les troupes britanniques furent envoyées contre Baltimore. La reconstruction du Capitole commença en 1815 et fut achevée quinze ans plus tard (en 1830).

La croissance de la ville est très modeste au cours des premières décennies du . C'est la guerre de Sécession (1861-1865) qui lui donne sa légitimité de capitale fédérale. Dès le début du conflit, des esclaves noirs s'enfuient des plantations des États du Sud, vers le Nord, certains d'entre eux s'installent dans des baraques à Washington. Cet exode s'amplifie avec la fin de la guerre et l'abolition de l'esclavage. Lorsque la guerre s'achève, Washington a gagné des habitants, mais aussi une place à part dans le cœur des Américains. Elle est le symbole de l'unité retrouvée.

La croissance de la ville se poursuit alors, aidée par les deux conflits mondiaux qui renforcent sa puissance nationale et internationale, et lui apportent davantage d'habitants. La population, qui atteint un sommet historique (pratiquement ) pendant la Seconde Guerre mondiale, perd ensuite des habitants au profit de la banlieue. En 1957, la majorité de la population est noire. Aujourd'hui, la proportion d'habitants noirs est stable autour de 50,1% selon le Bureau du recensement des États-Unis en 2012.

Washington, D.C. ne fait partie d'aucun des États fédérés américains (son territoire originel est pris aux États de Virginie et du Maryland). Administrativement, il dépend directement de l'État fédéral américain, et le Congrès fédéral y définit la loi. Cependant, une certaine autogestion locale est graduellement permise.

Cas unique pour une capitale fédérale moderne, les habitants de Washington DC n'ont pas de représentation dotée de droit de vote auprès du pouvoir législatif national, le Congrès des États-Unis. Ils élisent un représentant n'ayant qu'un rôle d'observateur et n'élisent personne au Sénat. Depuis 1961, ils ont cependant le droit de vote aux élections présidentielles, grâce au amendement : le district envoie trois grands électeurs. C'est pourquoi se développe au un mouvement souhaitant le remplacement du district de Columbia par un État à part entière, communément appelé "New Columbia". Bien qu'il ne soit pas représenté au vote du budget fédéral, le district paye les impôts fédéraux, une situation résumée avec amertume et humour par la formule « » (« Imposés sans représentation ») des plaques d'immatriculation du district, faisant un parallèle entre la situation actuelle du district et la situation qui perdurait avant la Révolution américaine.

Le district est le principal bastion démocrate du pays, puisque ce parti y rafle généralement plus de 85 % des voix, contre un peu moins de 10 % au Parti républicain, et cela sur les 14 élections présidentielles tenues depuis 1964, même si les 3 grands électeurs n'ont jamais été décisifs. Ce résultat peut s'expliquer par la diversité ethnique de la ville.

La ville est administrée par le maire de Washington, D.C. et le conseil du district de Columbia, élus au suffrage universel pour un mandat de quatre ans. Depuis janvier 2015, la maire est la démocrate Muriel Bowser. Le district est divisé politiquement en 8 "wards" (élisant chacun un représentant au conseil du district) et 37 "Advisory Neighborhood Commissions" (conseils de quartiers). Le district de Columbia dispose, à l'instar des procureurs généraux des États fédérés, d'un procureur général, élu pour 4 ans. L'occupant actuel de la fonction est le démocrate Karl A. Racine, en poste depuis 2015. En 1982, le conseil du district vote l'abolition de la peine de mort dans sa juridiction.

Longtemps dépendante à près de 50 % des activités gouvernementales pour son économie, la ville de Washington est désormais une ville dynamique, dans le secteur de l'armement (Northrop Grumman y a notamment des bureaux) et de l'informatique. En 2002, le gouvernement fédéral représente 27 % des emplois à Washington. De plus en plus d'entreprises s'installent dans la capitale américaine afin d'être proches des décideurs politiques auprès desquels elles peuvent faire du lobbying. Les grands employeurs non-gouvernementaux sont les principales universités et les hôpitaux, dont l'université George-Washington, l'université de Georgetown et le Washington Hospital Center. L'université Howard et la Federal National Mortgage Association (Fannie Mae) font aussi partie des cinq grands employeurs. De son côté, la Chambre de commerce du district de Columbia est la plus grande de la région. Elle offre aux entreprises locales un encadrement juridique, du réseau et de la formation. La Chambre existe depuis 79 ans et emploie .

Le National Symphony Orchestra est l'orchestre national des États-Unis. Il est en résidence au John F. Kennedy Center for the Performing Arts.

Les écoles publiques sont gérées par le "District of Columbia Public Schools" (DCPS), qui regroupe primaires, , , , d'enseignement et spéciales. Le DCPS regroupait lors de l'année scolaire 2005-2006, soit une baisse de par rapport à l'année 2003. Un nombre important a choisi de suivre les cours des écoles privées.

Plusieurs universités, "colleges", et autres institutions d'enseignement supérieur publiques ou privés se trouvent à Washington. L'université du district de Columbia est l'université publique de la ville. Le département de l'Agriculture des États-Unis propose des filières variées ayant toutes des liens avec l'agriculture. Le Département de la Défense des États-Unis gère la National Defense University à Fort Lesley J. McNair. Parmi les institutions privées, on peut citer l'université de Georgetown, laquelle a été fondée en 1789, soit avant la fondation du District : c'est la plus ancienne université catholique du pays. Les autres universités principales sont l'université Howard, l'université George-Washington, l'université catholique d'Amérique, Trinity Washington University, la American University et l'université Gallaudet.



Washington est l'une des destinations touristiques les plus populaires des États-Unis. La ville accueille un grand nombre de musées et de bâtiments remarquables. La plupart d'entre eux sont situés près du National Mall, un grand parc situé au centre de la ville dédié aux anciens dirigeants du pays, qui relie le Lincoln Memorial, à l'ouest, au Capitole à l'est. Au centre du parc se trouve le Washington Monument, un grand obélisque dédié au premier Président des États-Unis. On y trouve aussi le Jefferson Memorial, le Lincoln Memorial, le Franklin Delano Roosevelt Memorial, le National World War II Memorial, le Vietnam Veterans Memorial, le Mémorial des vétérans de la guerre de Corée, le mémorial de guerre du district de Columbia et le mémorial Albert Einstein. La Bibliothèque du Congrès est la plus grande bibliothèque du monde, avec de livres, soit trois fois les réserves de la Bibliothèque nationale de France.

La ville de Washington est aussi riche de nombreux musées, dont la plupart, situés eux aussi sur le National Mall, appartiennent à la Smithsonian Institution. Elle regroupe dix-huit musées (dont deux à New York) et d’œuvres : Anacostia Museum, galerie Arthur M. Sackler, Hirshhorn Museum and Sculpture Garden, National Air and Space Museum, musée national d'histoire américaine, National Museum of the American Indian, musée national d'art africain,
musée national d'histoire naturelle des États-Unis, National Portrait Gallery, National Postal Museum, Smithsonian American Art Museum, Renwick Gallery, et le parc zoologique national de Washington. Le National Air and Space Museum est le musée le plus visité des États-Unis. Ouvert au milieu des années 1950, il a accueilli de visiteurs en 2001. On y trouve notamment le "Spirit of St. Louis" (avion de Charles Lindbergh), et l'appareil sur lequel Orville et Wilbur Wright effectuent leur premier vol en 1903.

On compte aussi de nombreuses galeries d'art, dont la National Gallery of Art, le National Museum of Women in the Arts, la galerie d'art Corcoran of Art, et The Phillips Collection (art moderne, en 2001).

Depuis les années 1960, la ville compte par ailleurs une salle de spectacles, le John F. Kennedy Center for the Performing Arts, qui abrite une compagnie résidente d'opéra, sous la direction artistique de Plácido Domingo. La Carnegie Institution est par ailleurs une fondation qui finance la recherche scientifique, basée à Washington.

Washington est l'une des 12 villes des États-Unis qui compte des équipes sportives appartenant aux quatre principaux sports professionnels masculins et une équipe professionnelle féminine. Les Wizards de Washington (National Basketball Association), les Capitals de Washington (National Hockey League), et les Mystics de Washington (Women's National Basketball Association) jouent au Capital One Arena à Chinatown. Nationals Park, qui a ouvert en 2008 dans le Southeast D.C est la résidence des Nationals de Washington (Major League Baseball). Les D.C. United (Major League Soccer) jouent au RFK Stadium. Les Redskins de Washington (National Football League) joue tout près du FedEx Field à Landover, Maryland.

Les équipes actuelles cumulent ensemble 10 championnats professionnels: les Redskins de Washington en ont gagné 5; D.C. United en ont gagné 4 (le nombre le plus important dans l'histoire de la MLS) et les Wizards de Washington (puis les Washington Bullets) en ont gagné un seul.

D'autres équipes professionnelles et semi-professionnelles de Washington inclus: les Washington Kastles (World TeamTennis); les Washington D.C. Slayers (American National Rugby League), les Baltimore Washington Eagles (U.S. Australian Football League); les D.C. Divas (Independent Women's Football League); et le Potomac Athletic Club RFC (Rugby Super League).

Les Nationals de Washington sont les anciens Expos de Montréal.

Reconnu pour ses dîners ou déjeuners d'État, Washington (district de Colombia ) commence à devenir un lieu de plus en plus reconnu pour sa cuisine diversifiée. De plus, le nombre de restaurants est actuellement en hausse à Washington. Il faut aussi considérer les agriculteurs qui agrémentent la localité de produits frais.

Les principales autoroutes sont la Interstate 495 (Capital Beltway), la Baltimore-Washington Parkway du Maryland et les interstate highways 270, 66, 95, 395, et 295. Les autres axes routiers majeurs sont : la Whitehurst Freeway et la Anacostia Freeway dans le District de Columbia, la George Washington Parkway en Virginie, la Suitland Parkway dans le District de Columbia et dans le Maryland, la U.S. Route 50, la Clara Barton Parkway et la Virginia State Route 267 en Virginie.

La principale gare de Washington est la "Union Station" desservie notamment par la Amtrak, elle est fréquentée par par jour.

Washington D.C. possède son réseau de métro, s'entendant vers les banlieues du Maryland et de la Virginie. Ouvert en 1976, le métro comprend aujourd'hui six lignes, 91 stations et de voies. Les stations sont proches dans le centre-ville mais particulièrement éloignées en périphérie. 

Le métro est géré par la "Washington Metropolitan Area Transit Authority" (WMATA) qui opère également un vaste réseau de d'autobus. Une courte ligne de tramway est en service commercial depuis dans le nord-est de la ville.

Le district dispose d'un système de vélos en libre-service, le « "Capital Bikeshare" ». Inauguré en , il comprend et (2016) répartis sur Washington D.C., le Comté d'Arlington, la ville d'Alexandria et le Comté de Montgomery. L'entreprise canadienne PBSC Solutions Urbaines fournit les vélos et les stations associées au système (précédemment Bixi).

Les trois aéroports principaux de la ville sont l'aéroport international de Washington-Dulles, l'aéroport national Ronald Reagan, situé à Arlington en Virginie et l'aéroport international Thurgood Marshall de Baltimore-Washington. Plusieurs aéroports plus petits sont voués à l'aviation générale, dont le ' (Gaithersburg (Maryland), le ' (College Park (Maryland)), le ' et le ' (Manassas (Virginie). Depuis 2003, plusieurs de ces aéroports ont vu leur accès strictement limité par la création de la "" (ADIZ), visant à empêcher la reproduction d'attentats similaires à ceux du 11 septembre 2001 dans la capitale.

Washington a quatorze jumelages officiels selon le Bureau du Secrétaire du District de Columbia :

"Synthèses"

"Des origines à la guerre de 1812"

"Guerre civile et Reconstruction"

"Architecture"

"Urbanisme"

"Mémoire"





</doc>
<doc id="14363" url="https://fr.wikipedia.org/wiki?curid=14363" title="Mécanique newtonienne">
Mécanique newtonienne

La mécanique newtonienne est une branche de la physique. Depuis les travaux d'Albert Einstein, elle est souvent qualifiée de mécanique classique.

Avant de devenir une science à part entière, la mécanique a longtemps été une section des mathématiques.

De nombreux mathématiciens y ont apporté une contribution souvent décisive, parmi eux des grands noms tels que Euler, Cauchy, Lagrange... Jusqu'à la fin du , la mécanique a été le domaine applicatif naturel des mathématiques, le domaine dans lequel on pouvait tenter de faire entrer les faits expérimentaux dans le cadre rigoureux des mathématiques.
Inversement, certains problèmes de mécanique ont donné naissance ou orienté l'intérêt des mathématiciens vers des théories telles que la géométrie ou les équations différentielles.

Historiquement, la mécanique statique a été le premier domaine étudié par les savants. De l'Antiquité jusqu'au Moyen Âge des notions fondamentales telles que « l'équilibre », le célèbre « bras de levier » d'Archimède ou encore la notion beaucoup plus abstraite de « force » ont été étudiées. Plus tard, l'intérêt s'est porté vers la « dynamique », c'est-à-dire les phénomènes qui régissent le mouvement des solides, domaine dans lequel Galilée, pour la chute des corps, et Newton dans ses célèbres "Philosophiae Naturalis Principia Mathematica" ont apporté des contributions décisives. 

Toutefois, jusqu'à la fin du , la mécanique se séparait en deux branches : la mécanique du point d'un côté et la mécanique des fluides de l'autre. Dans le cas de la mécanique du point, les objets étudiés sont supposés implicitement indéformables et le mouvement du solide complet peut alors être décrit par le mouvement d'un de ces points remarquables : le « centre de gravité ». Il a fallu attendre le courant du pour voir apparaître les premières théories des solides "déformables" qui allaient permettre de réunir la mécanique des solides et la mécanique des fluides dans un même cadre, celui de la mécanique des milieux continus.

Parallèlement, un autre formalisme prenait naissance pour expliciter le mouvement des solides : Lagrange, dans un premier temps, puis Hamilton ont développé une approche dite analytique qui prenait comme axiome non plus l'équilibre des forces et de l'accélération mais l'existence d'un potentiel d'énergie minimal auquel obéit tout mouvement de solide. On peut démontrer que cette approche est rigoureusement équivalente à l'approche newtonienne ; elle permet toutefois de développer un formalisme radicalement différent.
Les principaux domaines de la physique ayant recours à la « mécanique analytique » sont la physique du solide et le mouvement de mécanismes complexes tels que les bras de robot.

Au début du , Einstein a développé sa célèbre théorie de la relativité et a mis en évidence les insuffisances de la mécanique telle qu'elle a été décrite par Newton. Toutefois, il s'avère que cette dernière constitue un cas particulier de la théorie de la relativité dès lors que l'on considère des vitesses relativement faibles. On a alors défini la "mécanique newtonienne", ou "mécanique classique", comme le domaine de la physique qui décrit les mouvements des corps à des vitesses faibles devant celle de la lumière (soit très inférieures à 300 000 km/s environ). Dans ce domaine, tout en étant plus simple, elle fournit des résultats très voisins de ceux de la relativité restreinte, adaptée quant à elle à tous les domaines de vitesse.

Conceptuellement, la mécanique a connu trois révolutions :

Au , les développements en mécanique classique se trouvent entre autres en théorie du chaos.

La mécanique newtonienne est classiquement découpée en domaines selon le point de vue adopté :
On distingue ainsi la cinématique du point de la cinématique du solide, …

On peut résumer ces deux types de découpage dans le tableau suivant :




</doc>
<doc id="14364" url="https://fr.wikipedia.org/wiki?curid=14364" title="Ankara">
Ankara

Ankara (anciennement appelée "Angora" et "Ancyre" durant l'Antiquité), située en Anatolie centrale, est la capitale de la Turquie depuis le et la deuxième plus grande ville du pays, après Istanbul.

C’est également la préfecture de la province du même nom. Ses habitants sont les "Ankariotes". Peuplée de plus de 5 millions d'habitants, la ville est située à d'altitude.

Connu sous le nom de "Aγκυρα" (Anküra) par les Galates, les Romains et les Phrygiens, Ankara signifie « ancre » ou « mouillage ». Selon certains mythes, Ankara est en effet l'endroit où le roi des phrygiens Midas a trouvé une ancre. Une ancre est également estampillée sur certaines pièces de monnaies anciennes, lesquelles sont exposées au musée des civilisations anatoliennes (turc : "Anadolu Medeniyetleri Müzesi").

Le nom de cette ville a été retranscrit en alphabet latin dans le monde occidental avec l'orthographe « "Ankyra" » et « "Ancyra" ».

Suite à l'arrivée des peuples turcs en Anatolie, le nom de la ville s'est transformé en "Engürü" et "Engüriye" en turc, et en "Angora" en langues occidentales. Ce n'est qu'en que l'orthographe Ankara (انقره) a commencé à être utilisée, selon divers documents officiels ottomans.

L'officialisation de cette orthographe a eu lieu suite à la demande officielle de la République turque, formulée le 28 mars 1930. À partir de cette date-là, l'office de poste turc n'a plus autorisé la livraison des courriers portant la mention « Angora » comme adresse de destinataire afin d'universaliser l'utilisation de l'orthographe « Ankara ».

Bien qu'Ankara soit en grande partie une ville nouvelle, ses origines sont très anciennes. Certains vestiges hittites découverts dans la citadelle attestent la présence d'une cité du temps de l'Empire hittite, cité qui portait le nom d’"Ankuva", mentionnée dans plusieurs inscriptions hittites.

Après les Hittites, Ankara connut la domination des Phrygiens, des Perses, d'Alexandre le Grand et enfin celle des Galates, tribus gauloises parmi lesquelles celle des Tectosages. Ceux-ci firent d'Ankara (appelé Ancyre par eux) leur capitale et construisirent une forteresse.

Des traces écrites mentionnent qu'Alexandre le Grand s'est rendu à "Anküra" en l'an 333 av. J.-C., lors de son avancée vers l'est.

Les Romains qui s'étaient emparé de la ville en 189, en laissèrent le gouvernement aux Galates jusqu'en 25 avant notre ère, date à laquelle le Royaume galate fut annexé à l'Empire romain. La ville fut promue au rang de « métropole » par Néron qui fit reconstruire ses murailles.

Durant la période byzantine, la ville connut une certaine prospérité mais les invasions des Sassanides et des Arabes au furent dévastatrices.

Tour à tour prise par les Byzantins, les croisés et les Turcs, Ankara fut, à partir de 1354, administrée par les Ottomans. En 1402, dans la plaine d'Ankara, eut lieu la grande bataille au cours de laquelle Tamerlan anéantit l'armée ottomane et fit prisonnier le sultan turc Bayezid. Mais la ville redevint ottomane en 1414.

Elle devint une ville secondaire de l'Empire ottoman, connue des Occidentaux sous le nom d’"Angora", d'où vient le nom donné aux chats, lapins et chèvres à long poil typiques de la région. Liée au système des chemins de fer ottomans à la fin du , elle restait pourtant une bourgade de habitants au début du .

Loin des zones occupées, elle est choisie par Mustafa Kemal Atatürk comme le centre de la lutte nationale et la Grande Assemblée nationale de Turquie y est inaugurée le . À la suite de la victoire des forces kémalistes, elle devint la capitale de la Turquie le , remplaçant Istanbul, la capitale historique de trois empires romain, byzantin, ottoman.

Mustafa Kemal Atatürk a choisi cette petite ville de habitants comme capitale de la nouvelle république : d'une part pour des raisons stratégiques car située au milieu du plateau anatolien, elle n'était pas aussi vulnérable aux attaques venant des côtes comme l'était Istanbul ; d'autre part pour des raisons politiques, car la République voulait couper les ponts avec l'ancien régime avec tous les symboles de l'ancienne capitale impériale, dont l'influence des milieux affairistes levantins était jugée néfaste.

Le choix d'Ankara était audacieux en raison de sa situation géographique et ses conditions climatiques. Au centre d'un plateau sec et aride, le climat y est continental, avec des étés chauds et secs, des hivers rudes.

L'urbanisation d'Ankara pour doter cette ville de bâtiments nécessaires à la fonction d'une ville-capitale devint un projet ambitieux du nouveau régime et fut confié à l'urbaniste et architecte allemand , qui remporta un concours en 1929 face à deux autres concurrents dont le Français Léon Jaussely. Obéissant à un zonage strict, le projet Jansen prévoyait un « quartier des ministères » prolongé par celui des ambassades et culminant à la résidence présidentielle. Les logements des hauts-fonctionnaires se répartissaient autour de cet ensemble, tandis que ceux des employés et des ouvriers étaient regroupé autour de la gare.

Le plan prévu par Jansen fut appliqué jusqu'en 1939. Après la Seconde Guerre mondiale, la spéculation foncière et l'exode rural, rendit impossible tout tentative de planification urbaine. La ville devint alors une importante agglomération habitée par une population qui au deux tiers vivait dans les années 1960-1970, dans des logements illégaux autoconstruits (bidonvilles).

Ankara est une ville tout à la fois moderne et ancienne puisqu'elle possède de nombreux vestiges romains et une forteresse byzantine bien conservée. Elle contient notamment un temple romain dédié à Auguste ainsi que le plus grand musée hittite au monde. Ataturk y est enterré au Anıtkabir, un mausolée grandiose achevé en 1953.

Ankara est marquée par un climat continental, l'hiver est froid avec beaucoup de neige, l'été est chaud et sec, .

La ville participe à hauteur de 9 % au PNB.

Plus de 60 % du territoire de la province d'Ankara est dévolu à l'agriculture, ce qui est bien au-dessus de la moyenne nationale.

En 2008 les exportations de la ville s'élevaient à ce qui place la ville au cinquième rang des exportations après Istanbul, Bursa, Kocaeli et Izmir. Avec un total des importations de elle se classe troisième après Istanbul et Izmir.

Parmi les entreprises internationales présentes dans la ville, on compte :

Ankara comprend en 2015 une cinquantaine de gratte-ciel. C'est la ville de Turquie qui comprend le plus de gratte-ciel après Istanbul.
Ankara est reliée à Istanbul et à la frontière bulgare par l'autoroute O4 via le tunnel du Mont Bolu mis en service en janvier 2007.

Ankara possède également une très importante gare routière, AŞTİ (en français "Terminal Interurbain d'Autobus d'Ankara").

Ankara possède une ligne de métro Batıkent-Kızılay M1 et une ligne de métro léger AŞTİ-Dikimevi « Ankaray ».

Trois autres lignes de metro sont également en cours de construction :

Un projet de tramway est à l'étude.

Le projet de LGV en Turquie consiste en trois lignes au départ d'Ankara :

La ville est desservie par l'aéroport international Esenboğa (code AITA : ANK) situé au nord de la ville.




Les Ankariotes ont une passion pour le sport, en particulier pour le football. Les principaux clubs de football d'Ankara sont : le Gençlerbirliği SK, l'Ankaragücü, l'Ankaraspor et le Hacettepe SK.

Au sein de la ligue turque de basket-ball, Ankara est représentée par deux clubs : le Türk Telekom S.K. et le .

La ville compte quatre clubs sur six évoluant dans la super ligue de Hockey turque. Le est la principale enceinte de la ville consacrée aux sports sur glace.

La ville d'Ankara est jumelée avec :






</doc>
<doc id="14367" url="https://fr.wikipedia.org/wiki?curid=14367" title="Ach (divinité)">
Ach (divinité)

Ach est une divinité libyenne, et une divinité égyptienne d'origine libyque, dieu du désert libyen du Sahara.

Au départ nommé "Ash", il fut par la suite appelé "Sha".

Connu en tant que « seigneur de la Libye », il est représenté sous forme humaine, parfois avec une tête de faucon, ou encore, en de rares occasions, avec la tête du dieu Seth.

Il a été en particulier associé aux oasis fertiles du désert dont le produit était estimé en Égypte antique. Il était le protecteur des routes où passaient les caravanes. En sa qualité de dieu de désert, il a été identifié avec le dieu Seth à l'époque dynastique, peut-être même durant l'époque archaïque, car depuis lors, il est appelé "celui d'Ombos", empruntant à Seth son aspect iconographique et lui étant complètement fusionné.

Ash, durant les premiers temps de l'histoire pharaonique, ne possédait pas de connotations négatives, personnalité qu'il adoptera en étant identifié avec Seth et en pénétrant dans le mythe osirien.

Dans la mythologie égyptienne, on le trouve au chapitre du "Livre des morts des Anciens Égyptiens".


</doc>
<doc id="14371" url="https://fr.wikipedia.org/wiki?curid=14371" title="Art contemporain">
Art contemporain

L'« art contemporain » désigne — de façon générale et globale — l'ensemble des œuvres produites depuis 1945 à nos jours, et ce quels qu'en soient le style et la pratique esthétique mais principalement dans le champ des arts plastiques. Dans cette classification, l'art contemporain succède à l'art moderne (1850-1945).

Cette désignation s'applique également aux musées, institutions, galeries, foires, salons, biennales montrant les œuvres de cette période.

On parle aussi d'art contemporain pour désigner — par convention — l'art des années 1960 et d'après. Le pop art marquerait, de ce fait, une rupture par rapport à l'art moderne. Une autre convention existe, en juillet 2010, le directeur du Centre de Recherches de Philosophie Européenne de l'Université de Kingston à Londres, "Peter Osborne" donne une conférence à la "Fondation Antonio Ratti" et lance une polémique en annonçant que « l'Art Contemporain est post-Conceptuel ». 

En France, l'expression « art contemporain » est aussi utilisée — avec un sens plus restreint — pour désigner les pratiques esthétiques et réalisations d'artistes revendiquant « une avancée dans la progression des avant-gardes » et une transgression des frontières entre les domaines artistiques (dépassant la frontière de ce que le sens commun considère comme étant de l'art, c'est-à-dire les arts plastiques, en expérimentant le théâtre, le cinéma, la vidéo, la littérature…), ou une transgression des . La distinction avec les arts classiques et moderne n'est plus alors effectuée d'après un ou des critères chronologiques mais d'après des critères paradigmatiques.

La notion de « contemporanéité » est d’abord une notion historique. Selon cette approche, la période contemporaine commencerait à partir de 1945, avec la fin de la Seconde Guerre mondiale et, par commodité, la plupart des études traitent de la période qui débute en 1945 et va jusqu'à aujourd'hui.

« Contemporanéité » signifie aussi « simultanéité ». Est contemporain ce qui est dans la même période. Le « contemporain » serait donc la manière qui se fait aujourd'hui. Appliquée à l'art, cette notion revêt une spécificité esthétique qui peut devenir polémique, puisque les acteurs n’ont pas la distance nécessaire pour effectivement apprécier les œuvres. La désignation « art contemporain » ne doit donc pas uniquement être prise de façon chronologique, car toutes les productions contemporaines n'appartiennent pas à la démarche contemporaine, ni ne se revendiquent comme telles.

De nouvelles références permettent de définir ce qu'est la méthode contemporaine. Une des premières est la transgression vis-à-vis de l'époque antérieure ; ainsi la notion d'« art contemporain » voudrait affirmer son indépendance non seulement par rapport à la notion d'arts dits « classiques », par rapport aux « beaux-arts » et à ses catégories (peinture, sculpture, etc.), mais aussi par rapport à la notion de manière « moderne ». La manière contemporaine possède donc en elle-même des exclusions. Elle s’inscrit dans la suite de l’« art moderne » et voudrait mettre, en quelque sorte, fin à celle-ci.

De surcroît, l'expression « manière contemporaine » est aujourd'hui utilisée pour des artistes encore vivants et actifs ou pouvant encore l'être, ce qui dans ce cas placerait l'origine de la méthode contemporaine dans les années 1960, avec le pop art, l'art conceptuel, Fluxus, les happenings ou l'art vidéo. C'est avec ces courants artistiques que prendrait fin la période de l'art moderne et la théorie de Clement Greenberg qui la définissait comme la recherche de la spécificité de la technique.

Dans cette recherche permanente d'une définition de la contemporanéité, la critique d'art et les institutions jouent un rôle important. Ainsi sont généralement exclues de la démarche contemporaine « labellisée » les formes d'art dont les problématiques ne reflètent pas les tendances promues par la critique « contemporaine ».

D'un point de vue géographique, à partir des grandes places artistiques médiatisées, essentiellement occidentales (Paris, Londres, New York), et avec la chute du mur de Berlin, en 1989, puis la montée en puissance de la Chine à cette même époque, la planète de l'art contemporain s'est mondialisée, l'Afrique et l'Amérique latine n'échappant pas à cette progression.

L'apparition de la photographie a exercé une influence sur de nombreux artistes dès le , tel que Degas et permis de donner naissance à l'art moderne. L'art n'a plus uniquement pour fonction importante de représenter fidèlement le réel, la photographie est mieux à même de le faire, l'art peut désormais s'essayer à d'autres formes, casser les canons de la beauté, et proposer des expérimentations nouvelles et des idées conceptuelles.

L'art contemporain a pour fondement les expérimentations de l'art moderne (début ), et notamment le désir de sortir l'art des lieux traditionnels et institutionnels. En ce sens, l'art perd peu à peu de sa fonctionnalité représentative. La création contemporaine demeure un miroir pour une réalité baignée des conflits et des prises de pouvoir qu’occasionnent ces attaques contre la rationalité. L'art reflète les crises de la société et demeure le lieu d'expression des valeurs. Les rapports de l’art à l’histoire ne s’évaluent ni qualitativement ni quantitativement, mais ils débouchent sur une conception plus institutionnelle de l'art : collectionneurs, sièges sociaux, galeries, musées, etc. pour s'ouvrir à un plus large public. Cependant, les acteurs de l'art moderne dans leur volonté d'exprimer leur opinion artistique hors des cadres institutionnels pour s'adresser au public, restent liés aux institutions ; leur démarche était de s'opposer à une idéologie (Heartfield envers le nazisme) ou au contraire de participer à la propagation d'une pensée politique.

Malgré la fin des idéologies imposées dans l'art moderne, les artistes actuels reprennent cet héritage à leur compte en exprimant leur engagement profond par rapport aux institutions. Notamment, lorsque leur sensibilité y est perturbée.

Aujourd'hui, l'art contemporain subit le déclin des idéologies du moderne (dans les années 1960, puis à partir de 1990 avec la chute du communisme). Il se fonde sur de nouveaux comportements : renouveau stylistique, brassages artistiques, origines diverses, arts technologiques (accès à la puissance mathématique des ordinateurs et ergonomie des logiciels), mode d'approche de la réalité. Les technologies ont toujours apporté des outils à l'art. Aujourd'hui, l'artiste s'en sert comme d'un instrument de médiatisation, et en invente de nouveaux. Il se base sur la culture historique, répertoriée; lit, visite, comprend, cherche, se spécialise, focalise son sujet et dépasse ce qui a été fait. Il prend position parfois, se veut démonstratif ou choquant, en tout cas il cherche la médiatisation.

L'art contemporain a pour fondement les expérimentations de l'art moderne, et revendique régulièrement la brèche ouverte par Marcel Duchamp, et d'autres qui avaient libéré la pratique de l'art des contraintes classiques de représentation.

La pensée postmoderniste a formulé la plupart des problématiques inhérentes à l'art contemporain, affranchi des courants idéologiques (communisme et capitalisme), sans toutefois empêcher des artistes engagés de critiquer les abus politiques ou idéologiques.

En France, la création des facultés d'arts plastiques constitue une base de contestation de l'enseignement académique des beaux-arts ; des matières autrefois étrangères au champ de l'enseignement de l'art, sociologie, ethnologie, esthétique et autres, orientent la recherche artistique au diapason de ses évolutions récentes.

À la recherche formelle du Beau succèdent des voies de recherche esthétiques nouvelles, dont les plus radicales, art conceptuel, minimalisme, performance, art corporel, modifient durablement la signification et la perception de l'art, qui s'oriente parfois dans des voies à première vue hermétiques aux non-initiés.

Certains courants, tels les nouveaux réalistes, la figuration libre et la trans-avant-garde, ainsi que certains francs-tireurs, ne quittent toutefois pas les médiums classiques, tout en modifiant radicalement leurs démarches créatives.

L'éclatement des types de médium (la peinture est souvent délaissée au profit d'installations, de performances ou autres) et du contenu des œuvres modifie en profondeur les réseaux de médiation d'art ; à de nouvelles galeries s'ajoutent des contextes d'exposition nouveaux et l'apparition de nouveaux médiums de diffusion.

À Paris, le Salon Comparaisons, au Musée d'art moderne de la ville de Paris, constitue dès 1954, le point de rencontre de tous les exposants de ces courants, confrontés, dans le même espace, aux peintres figuratifs et abstraits de la peinture sur chevalet.

À partir des années 1980, les arts à forte composante « technologique » font leur apparition, avec l'art vidéo, l'esthétique de la communication, l'art informatique puis, par la suite, l'art numérique, le bio-art, etc. La liste est non exhaustive et suit de très près les avancées de la recherche industrielle.

Dans les années 1990, l'art contemporain occidental a accordé son « label » à de nombreux artistes issus des pays dits « en voie de développement », à peu près absents autrefois. Les paradigmes de la globalisation et la perte des repères spatio-temporels classiques ont valorisé les modes d'approche personnels, ou les composantes biographiques, sociologiques, voire religieuses, sont valorisées au sein des démarches de travail.

La communication liée à l'internet joue un rôle de plus en plus important dans la réception et la médiation de l'art contemporain, en amont des expositions elles-mêmes, qui intègrent de plus en plus les structures de médiation étatiques. Elle donne la place à des « conseillers en art contemporain » (en anglais "The Contemporary Art Consultants"), qui conseillent gratuitement sur les valeurs à venir. Les changements survenus au sein des pays les plus développés (notamment la part grandissante du tertiaire) ont suscité un besoin de plus en plus généralisé d'art, ce qui ne rend pas la tâche des artistes, crise oblige, plus facile pour autant.

L'art contemporain, souvent obscur et provocant aux yeux du grand public, est considéré bien souvent comme l'émanation d'un art officiel. Il est cependant aujourd'hui bien plus accepté et répandu qu'auparavant ; un déferlement de travaux de qualités inégales le rend déroutant et requiert le plus souvent un investissement personnel de la part du public (voir Les théories modernes de l'art).

Cotées sur l'internet, les œuvres d'art contemporain sont aussi une manne financière potentielle, qui n'excluent pas les effets de mode au détriment des travaux réellement originaux.

En plus des médiums classiques (peinture à l'huile, pastel, sanguine, bronze, marbre, etc.), l'art contemporain est particulièrement friand de médiums nouveaux, voire de « non médiums ». Notamment, la vocation éphémère ou « en cours » de nombre d'œuvres questionne la notion même de médium, qui devient souvent un simple vecteur de médiation plutôt qu'un support stable. Cela rejoint la mutation des supports d'information entamée dans les années 1980, qui se dématérialisent progressivement au profit d'une logique de « relation » :


Certains médiums, comme la photographie — qui devient « plasticienne » (Joel-Peter Witkin) — le cinéma — qui devient « expérimental » (série des "Cremaster" de Matthew Barney) — ont acquis le statut d'art à part entière (au même titre que la peinture, la sculpture ou la musique), et constituent aujourd'hui des catégories autonomes.

La notion d'art multimédia, largement remise en cause aujourd'hui, interroge le statut d'œuvres issues d'installations, de performances souvent mêlées, tels qu'elles sont apparues dans les années 1950.

La pulsion « provocative » de l'art, si elle est loin d'être morte, n'est plus un "sine qua non" de la création.

Dans les années 1970, à la suite de mai 68 et des révoltes étudiantes dans le monde, la vertu provocatrice de l'art a été remise au goût du jour, du moins aux yeux du grand public. Le body art et la performance ont notamment mis à mal les limites extrêmes des valeurs tolérées par les sociétés occidentales. Les crucifixions de cadavres d'animaux de Hermann Nitsch, le boudin de Michel Journiac fait à partir de son propre sang, les mises en scène rituelles de Gina Pane, apparaissent toujours comme des provocations à l'encontre de l'ordre établi et visant à déstabiliser le spectateur.

La provocation en art est rarement gratuite, elle met à nu les complexes psychiques en œuvre au sein d'une société ou d'un groupe d'individu donné. Fred Forest avec son "Mètre carré artistique" et ses fausses publicités dans le journal "Le Monde" dans ses rubriques des pages économiques, dénonce la spéculation du marché de l'art en en faisant l'amalgame parodique avec le marché de l'immobilier. Hans Haacke, qui au contraire, il faut le noter, participe sans réticence à ce marché, quand il a été invité à représenter l'Allemagne au pavillon allemand de la Biennale de Venise, a cassé les dalles du pavillon pour rappeler l'origine de la fondation du pavillon, sous les nazis. Les exemples abondent en ce sens et invitent le public à essayer de connaître le contenu des œuvres, a priori opaque dans bien des cas.

Le « bon goût » n'existe pas en art contemporain, parce que l'artiste a cessé d'être un simple exécutant d'œuvres commanditées par un mécène, qui définissait son statut avant la Renaissance.

Les cinq extraits ci-dessous résument l'essentiel des critiques formulées à l'égard de l'art dit « contemporain » :

Dans le catalogue raisonné du Salon des indépendants de 1999, le président du Salon, Jean Monneret, lance un violent pamphlet contre la définition convenue de l'art contemporain, après avoir longuement critiqué les fonctionnaires qui régissent l'enseignement des arts plastiques et le choix des œuvres achetées par l'État et les collectivités locales () :
L'art contemporain ? Tous les artistes vivants font partie de l'art contemporain. Ce sont les artistes qui font l'art. Tous les artistes. Librement ! Or, l'État veut faire croire au public qu'il n'y a qu'un art digne d'intérêt, l'art dit « contemporain », c'est-à-dire l'art d'État. Comme si l'installation, la performance ou l'art inculte – pour peu que la légende qui l'accompagne relève de la logorrhée – soient, à eux seuls, la suite historique, linéaire, indiscutable de la tradition artistique. Il est vrai qu'en art dit « contemporain », moins il y a à voir, plus il y a à dire ! Dans une exposition d'art contemporain, une gaine d'aération, le matériel de secours ou le carrelage des sanitaires se confondent souvent avec les œuvres présentées. La question alors est, où est l'œuvre ? Tant l'harmonie est parfaite entre le contenant et le contenu. En réalité, l'art d'État emprunte une voie unique qui écarte arbitrairement l'art des meilleurs artistes des salons historiques. La démocratie exigerait que l'État, soucieux de l'argent du contribuable, rendît compte de la réalité contemporaine dans toute sa diversité, sans exclusion…

Dans le rapport moral de "Taylor" de juillet 2006 ( et 7), revue de la fondation du baron Taylor, le vice-président, le peintre et journaliste Philippe Lejeune, distingue la notion de beaux-arts de celle d'art contemporain.

L'art contemporain expose dans des lieux où on exposait « la peinture », ce qui entretient naturellement une confusion. Mais plutôt que de définir une nouvelle forme d'art, on lui applique les règles d'une autre discipline, comme un joueur, lassé du bridge, adapte les règles de la belote… L'art contemporain refuse toutes règles, excepté celle de l'exclusion. Vous savez qu'un slogan fameux était d'interdire tout interdit. L'art contemporain ne vit que d'ukase. N'importe quoi sauf la représentation […].

L'art contemporain se dit conceptuel, c'est-à-dire que, partant d'un concept, on arrive à procurer une sensation. 
Les Beaux-Arts se donnent un tout autre but, ont un programme bien différent. Partant de l'éprouvé, ils le confrontent à la mémoire collective pour arriver précisément à une idée, c'est-à-dire à un élément que l'on peut comparer […].

Après son procès contre le MNAM (centre Georges-Pompidou), Fred Forest écrit en dernière de couverture de son livre "Fonctionnement et dysfonctionnements de l'art contemporain" (L'Harmattan, Paris, 2000) :

Ce livre tend à révéler les limites et les contradictions d'un système qui ne peut plus perdurer sous la forme élitaire actuelle au profit d'une poignée de privilégiés, toujours les mêmes, qui bénéficient de la complaisance et de la manne publique. Lutte du pot de terre contre le pot de fer, il s'agit de la description par le menu de mon procès jusqu'en Conseil d'État contre le centre Georges-Pompidou, et à travers lui, contre les institutions publiques de l'art contemporain pour leur refus de transparence sur les acquisitions et leur manquement au respect de la loi de 78 sur la comptabilité publique. Au-delà de l'art, la démarche engagée ici se veut avant tout une démarche citoyenne posant la vraie question de l'utilisation des fonds publics, et celle de la culture dans une démocratie.

En septembre 2011, Daniel Buren dans la revue "L'Œil" constate, au cours d'un long interview, l'incapacité, la confusion et la faillite de l'expression « art contemporain » :
En règle générale, je dirais que la santé ébouriffante qu'on lui prête — biennales dans le monde entier, foires à tous les tournants et salles de ventes débordées — sont des aspects quelque peu paradoxaux d'un domaine qui, sur le plan de la pensée, est au bord de la faillite. Ce n'est plus un moment de l'histoire, mais la mode au jour le jour. "Contemporain" est un terme complètement dénué de sens, mais c'est l'une des trouvailles les plus performantes jamais trouvées afin d'annihiler dans l'œuf tout ce qu'un artiste pourrait présenter d'un tant soit peu neuf et dérangeant. […]

Dans sa conférence gesticulée « Incultures », Franck Lepage explique que le financement de l’art contemporain en Europe est le résultat « de la plus grande campagne de désinformation de l’histoire de la CIA ».

Il continue : l’art contemporain « expulse la question du sens ; il le dit lui-même » et termine en démontrant que ce mouvement ne « s’inscrit pas dans une évolution d’un art précédent, mais a été créé pour répondre à un marché. Il n’est que transgressif, mais pas subversif »



Lieux institutionnels qui ont pour mission de conserver des œuvres, ils achètent de l'art contemporain et montrent les collections ainsi réalisés. Ils réalisent aussi des expositions en empruntant des œuvres à d'autres collections publiques ou privées.



Les centres d'art contemporain ont pour objectif de présenter le travail d'artistes contemporains. Ils se différencient des musées dans le sens où ils ne conservent pas les œuvres qu'ils présentent. De ce fait, ils ne constituent pas de collections. Ils montent des expositions en fonction de leurs choix éditoriaux, propres à chaque lieu, l'objectif étant la diffusion et la promotion de l'art contemporain. On trouve de tels centres de plus ou moins grande importance dans le monde entier.




Les FRAC ou fonds régionaux d'art contemporain sont des institutions culturelles, créées en 1981, qui visent à promouvoir l'art contemporain. Leur mission est avant tout de constituer un patrimoine, de soutenir la création et de diffuser largement le fonds constitué en sensibilisant le public aux démarches artistiques contemporaines.

Chiffres à partir des ventes du octobre 2004 au 30 septembre 2005 : États-Unis 58 %, Royaume-Uni 27 %, France 3 %, Italie 2 %, Allemagne 2 %, autres 8 %

Les foires d'art contemporain sont le lieu où les grandes galeries présentent à leur clientèle internationale une sélection parmi les artistes qu'elles représentent.



Années 1980
Années 1990
Années 2000
Années 2010





</doc>
<doc id="14373" url="https://fr.wikipedia.org/wiki?curid=14373" title="Art moderne">
Art moderne

L'appellation d'art moderne désigne une période de l'histoire de l'art qui est initiée par Édouard Manet et les peintres impressionnistes dans les années 1870 et s'achève au milieu des années 1950, notamment avec la naissance du pop art. 

Précédant l'art contemporain qui commença en temps d'après guerre, l'art moderne naquit lorsque des mouvements tels que le réalisme, le symbolisme et l'art nouveau devinrent populaires. 

L'art moderne se caractérise par une rupture avec les canons de la figuration de l'art classique.

La notion de modernité (à ne pas confondre avec l'avant-garde) envahit l'art et les institutions au , mais elle émerge vers 1850 pour désigner les grands changements survenus au provenant des révolutions techniques et industrielles. La « modernité » est un mode de pensée, de vie et de création qui se veut résolument nouveau, fondé sur le changement et en réaction (comme c'est toujours le cas lors d'évolutions majeures) aux temps qui l'ont précédé.

Dans "Le Peintre de la vie moderne", Baudelaire trouve la beauté dans la rue et il la voit changeante, mobile ; chez l'artiste moderne, il salue l'aptitude à dégager du transitoire du quotidien l'éternel de la beauté. Chez Walt Whitman, on s'attache à observer l'impressionnant quotidien en perpétuel mouvement.La beauté n'est plus désormais l'apanage de l'Antique. La culture de masse et le divertissement populaire écrasent et signent la fin de l'exaltation de la morale officielle. On trouve de nouveaux sujets à traiter empreints d'une modernité toute nouvelle, notamment ceux issus de la Révolution industrielle. Ainsi "La Gare Saint-Lazare" de Monet, où l'on ne trouve guère de regard nostalgique ; c'est là la modernité véritable.

D'un point de vue institutionnel, l'émergence de la modernité ébranle l'Académie dans son pouvoir d'autoriser ou non l'entrée d'une œuvre au Salon. Les jurys des salons commencent à perdre leur crédibilité absolue pour les peintres, l'État et le public.

En 1863, lors du Salon des Refusés, Napoléon III décide de « laisser le public seul juge », et c'est un déchaînement de rires et de sarcasmes qui s'abat sur "Le Déjeuner sur l'herbe" de Manet ; cela met très nettement en évidence quelle influence le jury exerce sur l'opinion du public. En 1884, l'Académie ne dirige plus les Beaux-arts et perd ainsi en légitimité aux yeux des artistes ; cette perte d'autorité favorise l'émergence de la création dite « bohème », ainsi qu'un renouveau du marché de l'art dans lequel les galeries deviennent des acteurs de tout premier plan.

Les peintres « hors-académie » refuseront finalement d'être exposés à côté des peintres académiques. C'est la raison de la création en 1885 du Salon des indépendants, en 1890 du Salon de la Société nationale des Beaux-arts ainsi que du Salon d'automne en 1903.

Les premiers pas vers l'art moderne sont accomplis par les peintres impressionnistes, très influencés par Édouard Manet dans les années 1870. En plus de rejeter les normes dictées par l'Académie (ce qu'avaient déjà entreprit les peintres réalistes et paysagistes), ils commencent à peindre d'une manière véritablement nouvelle. L'utilisation de couleurs non-mélangées et la peinture par touches juxtaposées en sont des exemples. Ce rejet de la peinture classique ouvrira la voie à des peintres tels que Cézanne, Gauguin et Van Gogh, puis au cubisme, mouvement qui canalisera tout l'art du XXe siècle.

Notons également qu'en 1881, Octave Maus, Edmond Picard et Louis Eugène Robert fondent à Bruxelles la revue "L’Art Moderne" (1881-1914) dont la volonté est véritablement de valoriser un art dit « moderne ».

L'art moderne se caractérise aussi par la naissance de la critique d'art. En effet, au même moment, l'art devient sujet d'écriture : la critique est souvent un discours engagé sur l'œuvre. Baudelaire et Zola, écrivent des critiques engagées en faveur des peintres modernes. Goethe et Matisse écrivent sur la couleur. De nombreux artistes publient des textes ou des manifestes (dadaïsme, futurisme, surréalisme, etc.).




L'art moderne est suivi de l'art contemporain après la Seconde Guerre mondiale :


</doc>
<doc id="14375" url="https://fr.wikipedia.org/wiki?curid=14375" title="Richard Baquié">
Richard Baquié

Richard Baquié (Marseille - ), est un sculpteur français.

Sa propre histoire est liée à l'imaginaire de Marseille, sa ville natale.

La culture musicale, plastique ou cinématographique des années 1960-70 imprègne par ailleurs sa sensibilité artistique, qu'il exprime par le biais d'objets recyclés et détournés : morceaux de voiture, avion de fer blanc, qui une fois associés à des mots, des sons et des images, parlent de voyage ou d'amour. 
Ainsi mis en scène, mots et objets déclinent des fragments d'histoire personnelle tout en questionnant « l'histoire des métaphysiques quotidiennes ». 

Grave et facétieuse à la fois, l'ensemble de l'œuvre de Richard Baquié joue avec les lieux communs et les poncifs, récupère, mêle, détourne les matériaux, les objets et les mots, leurs formes, leur propriété et leur sens. 
Utilisant à plein l'association, l'assemblage, le collage et la discordance de fragments d'objets et de mots il refait une réalité et renouvelle le lien entre jeu et réalité ; la pauvreté des matériaux, leur caractère de déchets industriels révèlent un attachement à la ville, lieu de la rencontre entre la nature et l'artifice, de l'entrecroisement des cultures et des temps, donc le lieu de l'art ; tout cela constitue en soi une interprétation de l'histoire de la sculpture et du devenir de l'objet dans ce siècle, et de la culture contemporaine. 

À propos de l'œuvre de Richard Baquié on évoque bien sûr Robert Rauschenberg pour l'attitude artistique où le bricolage et la manipulation du rebut deviennent acte et pensée, pour sa matériologie ; on invoque aussi Marcel Duchamp, pour l'appropriation et le détournement, et pour ses régions plus verbales. 
Dans un entretien Baquié déclarait : « J'ai... toujours été séduit par le pouvoir des mots et le chiasme qu'ils produisent si vous les mettez sur le même plan que les images. Il s'agit, pour les mots comme pour les objets - mais n'est-ce pas la même chose ? - d'appropriation ». 

Les mots inscrits dans ses sculptures agissent comme les poncifs de la sentimentalité fleur bleue des rengaines des chansons populaires, celles dont Marcel Proust parle dans "Éloge de la mauvaise musique", et qui suscitent en chacun de nous des émotions partagées, ils ravivent les souvenirs de l'esthétique cinématographique qui fonde la plupart des réalisations de Baquié ; avec 'Le café du matin', Peter Falk dans "Les Ailes du Désir" de Wim Wenders n'est pas loin...

Dimensions : 251 x 204 x 406 cm N° d’inventaire : 992.13.1? Collection MAC Lyon



</doc>
<doc id="14377" url="https://fr.wikipedia.org/wiki?curid=14377" title="Dada">
Dada

Le mouvement dada, ou dadaïsme, est un mouvement intellectuel, littéraire et artistique du début du , qui se caractérise par une remise en cause de toutes les conventions et contraintes idéologiques, esthétiques et politiques.

Dada est issu d’une filiation expressionniste et sa véritable naissance est le "Manifeste littéraire", publié sous forme de tract, en février 1915, à Berlin, par Hugo Ball et Richard Huelsenbeck. Ceux-ci, en se déclarant « négativistes », affirment : C’est à partir de ce texte que s’esquisse la position spécifique de dada.

Dada connaît notamment une rapide diffusion internationale. Dada met en avant un esprit mutin et caustique, un jeu avec les convenances et les conventions, son rejet de la raison et de la logique, et marque, avec son extravagance notoire, sa dérision pour les traditions et son art très engagé. Proche de l'idéologie socialiste, voire anarchiste pour Tzara, ou même Hausmann, Dada se démarque à l'époque pour sa proximité avec le militantisme radical. Les artistes de dada se voulaient irrespectueux, extravagants, affichant un mépris total envers les « vieilleries » du passé. Ils cherchaient à atteindre la plus grande liberté d'expression, en utilisant tout matériau et support possible. . Ils cherchaient également une liberté du langage, qu'ils aimaient lyrique et hétéroclite.
Le déclenchement de la Première Guerre mondiale a transformé la capitale de la Suisse alémanique qu'était Zurich, en berceau d'un mouvement artistique inédit dont le « nom écrin », dada, fut trouvé dans des circonstances légendaires et controversées en février 1916. Zurich accueillait alors plusieurs artistes ayant fui les horreurs de la guerre.

Début 1916, Hugo Ball, écrivain, traducteur de littérature française (Henri Barbusse, Léon Bloy, Arthur Rimbaud) et dramaturge allemand, exilé depuis 1915, et sa compagne, Emmy Hennings, poète et danseuse, fondent le Cabaret Voltaire et en annoncent l'ouverture, dans la presse zurichoise, pour le 2 février. Ils invitent les . Il persuade Ephraïm Jan de lui louer une pièce dans l'Auberge de la Meieri, au 1 de la Spiegelstrasse, située dans le quartier mal famé de Zurich.

Hugo Ball a l'idée de mêler la tradition des cabarets parisiens de la fin du avec l'esprit du cabaret berlinois d'avant-guerre, sous la figure emblématique de Voltaire dont il admire l'opposition à la religion. Ball voulait offrir un lieu de rencontre et d'exposition aux artistes et aux intellectuels.

Quelques jours auparavant, Marcel Janco, à la recherche d'un travail, passe devant l'auberge. Il entend de la musique sortir d'une boîte de nuit et . C'était Hugo Ball. Quand ce dernier apprend que Janco est peintre, il lui offre les murs du cabaret pour exposer. Janco revient au cabaret accompagné de ses amis, Hans Arp, Sophie Taeuber et Tristan Tzara.

L'inauguration a lieu le 5 février, la salle est comble. Ball joue du piano, Hennings chante en français et en danois, Tristan Tzara récite ses poèmes en roumain. Le décor est signé Janco et Arp. Bientôt, les représentations intègrent des lectures simultanées, accompagnées de "bruitisme". Une revue est créée "Cabaret Voltaire", avec textes et dessins.

Le mot « dada » est trouvé quelques jours après. Selon Henri Béhar, ! Dans une lettre de janvier 1921 adressée à des artistes new-yorkais, Tzara explique les circonstances de l'invention du nom dont il se garde de revendiquer la paternité : 

Au cours d'un entretien accordé à "Arts magazine" (New York, décembre 1982), Marcel Janco reconnaît qu'il n'était pas présent à ce moment-là : 

En 1921, l'apparente précision du témoignage de Hans Arp paraît disqualifiée par la description ironique des circonstances : 

« Dada » apparaît pour la première fois dans l'unique numéro de la revue "Cabaret Voltaire", publiée en mai 1916.

La controverse sur la naissance du nom « dada » vient de Richard Huelsenbeck qui en a toujours revendiqué la paternité : Même si une lettre de H. Ball à R. Huelsenbeck du 28 novembre 1916 semble soutenir sa version : , la récurrente revendication de Huelsenbeck ne résiste pas au fait que, appelé par Hugo Ball, il ne soit pas arrivé à Zurich avant le 11 février 1916.

Au bout de six mois, en juillet 1916, les protagonistes du Cabaret Voltaire veulent créer une revue et une galerie. Mais Hugo Ball s'oppose à l'idée de faire de dada un mouvement artistique. Dans son manifeste, écrit à ce moment-là, il donne la primauté au mot, et hésite à parler d'art : Les dadaïstes créent tout de même une maison d'édition et une galerie. Le mouvement dérive des spectacles spontanés des cabarets à la programmation d'événements. Il converge vers la danse, probablement grâce à Sophie Taeuber. La galerie dada, ouverte en janvier 1917, se révèle un succès, mais elle ne dure que quelques semaines. Hugo Ball, finalement, voyait dans cette galerie un effort pédagogique pour réviser les traditions littéraires et artistiques. Durant cette expérience, Huelsenbeck quitte le mouvement zurichois, l'assimilant à un petit commerce artistique, pour aller relancer dada à Berlin.

À Berlin, Huelsenbeck passe quelque temps à étudier et réfléchir. Le mouvement est effectivement relancé à partir de quelques soirées au "Café des Westens", en février 1918, par des artistes tels que Huelsenbeck et Grosz. Leur posture est de se battre contre l'expressionnisme, de se présenter comme adversaires de l'art abstrait, d'aborder des sujets politiques comme la guerre (une nouveauté par rapport à l'époque zurichoise), et d'intégrer le scandale maximum dans leur démarche. Dada prend un tour nettement offensif. Le public afflue à Berlin pour voir le phénomène et des soirées dada s'organisent dans toute la ville. Les dadaïstes berlinois effectuent même une tournée en Tchécoslovaquie.

Un peu avant la fin de la guerre, des mouvements dadas sont créés dans les grandes villes allemandes : Berlin, Hanovre et Cologne. Les différents "Manifestes" parviennent à Paris, malgré la censure et le « bourrage de crâne » contre tout « germanisme ».

Courant 1917 et 1918, le mouvement s'internationalise. La revue "DADA" paraît en juillet 1917 et durera 3 ans, portée par Tristan Tzara qui explore les possibilités typographiques non conventionnelles. À Zurich, l'improvisation des débuts est remplacée par une programmation plus institutionnalisée. De nouvelles personnalités, comme Walter Serner, émergent, et une visite au Cabaret Voltaire reste un passage obligé pour tous ceux qui veulent participer à dada. Ainsi, Francis Picabia s'y présente, publie un numéro spécial de sa revue "391" (dont le nom est inspiré de la revue "291" d'Alfred Stieglitz) sur Zurich, tout en réalisant, à New York, avec Marcel Duchamp et d'autres, des événements dada, comme le salon des artistes indépendants, où est présentée (mais refusée) la "Fontaine" de Marcel Duchamp. C'est dans le numéro de mars 1920 de "391" qu'est publié le célèbre "ready-made" de Duchamp, un portrait de "La Joconde" avec moustache et barbe, se moquant ainsi du côté trop précieux de l'art. Avec Arthur Cravan, dada investit aussi le domaine du sport avec, à Madrid, un combat mémorable, dès avril 1916, pour le titre de champion du monde de boxe.

Après quatre années passées à Zurich, Tristan Tzara décide de rejoindre Paris en 1919, pour donner à l'anarchie dada un nouvel élan. Dès 1918, il avait commencé à collaborer à une des revues dadas parisiennes, "Littérature", ce qui l'avait rapproché des principaux artistes parisiens. Des ramifications du mouvement se retrouvent en Allemagne, à Cologne avec Jean Arp, Johannes Baargeld et Max Ernst, à Berlin où était revenu Richard Huelsenbeck, et à Hanovre avec Kurt Schwitters qui créait des collages à partir de déchets trouvés dans la rue.

Au moins deux œuvres, qualifiées "a posteriori" de prédadaïstes, avaient déjà sensibilisé publics et artistes parisiens à la manière dada : "Ubu roi" et le ballet "Parade". Ces œuvres donnèrent des héros aux artistes : Alfred Jarry, l'auteur du premier, et Erik Satie, compositeur du second. Elles suscitèrent auprès du public une sorte d'attente de la provocation, si porteuse pour le mouvement dada.

Dans l'après-guerre, les premières galeries dada, avec les premiers journaux et manifestes de ce mouvement apparaissent en France, en Allemagne et aux États-Unis. Contemporain du cercle de Zürich, un groupe d'amis s'est formé à New York, autour de Marcel Duchamp, Francis Picabia, Man Ray, etc., qui partage l'ambition de libérer la peinture à venir de la tyrannie de la signature de l'artiste et de . À Cologne, Hans Arp et Max Ernst organisent les premiers rassemblements dadaïstes.

À Berlin, Richard Huelsenbeck qui, en 1917, avait colporté le terme « dada » de Zürich à Berlin, et Raoul Hausmann fondent en janvier 1918 le Club Dada, groupuscule informel dépourvu de règlement, de lieu de réunion, de statuts ou même de programme. Ses membres sont les artistes George Grosz, Hannah Höch et John Heartfield, rejoints de temps en temps par Franz Jung, Walter Mehring ou Erwin Piscator.

Après quelques tournées dada à Dresde, Leipzig, Prague, Karlsbad, Hambourg et Teplitz-Schönau au printemps 1920, George Grosz, Raoul Hausmann (alias « Dadasophe ») et John Heartfield (alias « Monteurdada ») organisent la Première foire internationale Dada, première expression publique du dada berlinois ; mais cette manifestation se termine par un procès qui disperse les participants.

À Paris, bien que les premiers contacts avec les artistes locaux suscitent un enthousiasme mutuel, de nombreuses incompréhensions apparaissent. Certains défendent une tradition qu'ils disent zurichoise et refusent toute notion d'art ayant un caractère positif, voire toute notion d'art tout court, mais d'autres pensent que dada porte en lui les germes d'une nouveauté. Les discussions, souvent violentes, entraînent une scission dans le mouvement dada, le séparant d'un côté en artistes de tradition zurichoise, mouvement qui dépérira, et de l'autre côté des artistes qui se rassembleront autour de Breton et donneront le surréalisme.

Le mouvement vit au rythme des soirées et spectacles que les artistes organisent, spectacles qui cristallisent les différences de position, mais font souvent l'événement à Paris, dont notamment le festival dada, à la salle Gaveau, le 26 mai 1920. Le public, en nombre, assista à des pièces de théâtre jamais répétées, des concerts impossibles à jouer, grâce à quoi les auditeurs se mirent à crier au scandale, à envoyer tomates, œufs et côtelettes de veau sur les interprètes. Tous les dadaïstes portaient un chapeau en forme d’entonnoir, Éluard un tutu de ballerine, le reste à l'avenant. Bien que les artistes soient tous en désaccord, cette soirée leur parut être une réussite. 

Mais le monde dada ressentait une impasse dans les soirées-spectacles, inquiet de ce que le public y voie une sorte d'habitude agréable. Après presque un an de tergiversations, ils décidèrent d'organiser une excursion dada à l'église Saint-Julien-le-Pauvre, choisie parce que totalement inconnue, excursion dont les guides devaient être des célébrités dada. Dans ce choix, il n'y avait pas de connotation anticléricale, mais la volonté de dénoncer les guides suspects. Mais le public se montra absent. Alors, les dadaïstes abandonnèrent l'idée des excursions, et s'engagèrent dans le modèle de procès. 

, le procès contre Maurice Barrès, en 1921, marque la décomposition véritable des dadaïstes. La "Mise en accusation et jugement de Maurice Barrès pour crime contre la sûreté de l'esprit" n'était pas sans déplaire à Tzara, Francis Picabia, Georges Ribemont-Dessaignes, Erik Satie, ou Clément Pansaers, qui s'opposaient à l'idée d'un tribunal, et plus particulièrement d'un tribunal révolutionnaire. Tzara n'intervient que comme témoin, laissant à Breton le soin de diriger le procès. Le procès tourne rapidement en plaisanterie, ce qui n'était pas le souhait de Breton.

Le fondateur du mouvement quitte violemment la salle, aussitôt suivi par Picabia et ses amis, au moment où Aragon commence son plaidoyer, plus contre le tribunal que contre Barrès, qui fut d'ailleurs condamné à vingt années de travaux forcés.

Les artistes dada, après le procès, ne sont plus capables d'organiser des événements ensemble, tant les disputes entre eux sont vives et déplaisantes. Ils évoluent en différents clans mouvants : les dadaïstes (Tzara), les surréalistes (Breton, Soupault), ou les anti-dadaïstes qui sont aussi des anti-surréalistes (Picabia).

Au mois de juin suivant, en 1922, le Salon Dada organisé par Tzara, à Paris, est dédaigné par André Breton, et Marcel Duchamp refuse tout envoi pour cette exposition, à l'exception d'un télégramme avec les deux mots : « Pode Balle ».

La soirée dada du 6 juillet 1923 organisée par Tristan Tzara au théâtre Michel marque la rupture définitive entre dadaïstes et les futurs surréalistes (André Breton, Robert Desnos, Paul Éluard et Benjamin Péret). Face aux violentes interruptions de ces derniers : Breton, d'un coup de sa canne, casse le bras de Pierre de Massot, un journaliste (et non Tzara) appelle la police qui intervient. La soirée prévue le lendemain est annulée.

En 1924, André Breton publie le "Manifeste du surréalisme", et ce mouvement prend son envol. À partir de là, les surréalistes réinterprètent, "a posteriori", nombre d'événements dada comme étant d'ordre surréaliste. Les notions d'automatisme, de simultanéité, de hasard étant au cœur de dada comme du surréalisme naissant, ils n'ont aucune difficulté à se les approprier.

Écrivains, peintres, plasticiens, cinéastes, danseurs, photographes et même quelques musiciens, dada a traversé toutes les expressions artistiques de son temps.



















Bien qu'animé majoritairement par des artistes, Dada n'est pas comme tel un mouvement artistique. Sur les décombres de la guerre, il est davantage un état d'esprit, une réaction forte aux idées reçues. La thèse la plus importante est que l'art, d'interprétation de la réalité, devait devenir partie intégrante de la vie. En rejetant les valeurs esthétiques et artistiques en vigueur, et qu'il considérait comme désuètes, Dada a contribué à libérer les artistes de la tradition et à les encourager à explorer de nouvelles voies dont on mesure les effets plusieurs décennies plus tard, par exemple avec le surréalisme, l'expressionnisme abstrait, le Pop art, Fluxus et le Nouveau réalisme.

Après la Première Guerre mondiale, les jeunes ont besoin d'exprimer leur jubilation d'être en vie, la guerre finie et la paix retrouvée. La vie a vaincu la mort, la paix a vaincu la guerre, l'enfance et l'insouciance sont de retour et vont pouvoir s'exprimer. En 1963, Tristan Tzara a dit : 

En 1920, Tristan Tzara nomme des « présidentes dada », les plus anticonformistes possibles et à l'originalité débridée. Les « jeunes filles dada », les « dada's girls », dansent en solo avec ou sans masque, comme Sophie Taeuber. Elles font tourner les têtes et suscitent l'enthousiasme, mais aussi les huées. Une « dada dance » bien connue consiste à mettre ses bras en l'air (épaule perpendiculaire au tronc et avant-bras perpendiculaire au corps) et à sauter en même temps. Emmy Hennings, compagne de Hugo Ball, fonda avec lui le cabaret Voltaire à Zurich, dont elle devint l'âme en animant ses soirées, par la danse, le chant et la poésie.

L'Américaine Clara Tice, peintre caricaturiste et poète, horrifie la prude société américaine avec ses dessins de femmes nues accompagnées d'animaux, illustrant de manière érotique les "Fables de La Fontaine". Ses œuvres seront confisquées par la police. Une autre Américaine, Beatrice Wood, réalise aussi des œuvres à forte connotation érotique.

Valeska Gert crée ses « danses » lors de certaines soirées berlinoises. Bien loin du classique "Lac des cygnes", elles ouvrent la voie à la libération du corps des femmes et au nudisme. Renée Dunan, élevée au couvent, mais grande admiratrice du marquis de Sade, se libère, se proclame « dadaïste de la première heure », et défraie la chronique, sous divers pseudonymes, dont « Marcelle la Pompe » et « M. de Steinthal », en hommage à Stendhal et à l'écrivain aventurier Casanova de Seingalt.








</doc>
<doc id="14378" url="https://fr.wikipedia.org/wiki?curid=14378" title="Marcel Duchamp">
Marcel Duchamp

Marcel Duchamp, né à Blainville-Crevon (Seine-Maritime), le et mort à Neuilly-sur-Seine, le , est un peintre, plasticien, homme de lettres français, naturalisé américain en 1955. 

Depuis les années 1960, il est considéré par de nombreux historiens de l'art et de critiques comme l'artiste le plus important du . Déjà, André Breton le qualifiait d'. Notamment grâce à son invention des "ready-mades", son travail et son attitude artistique continuent d'exercer une influence majeure sur les différents courants de l'art contemporain. Rare artiste n'appartenant à aucun courant artistique précis, Marcel Duchamp a un style unique. Cassant les codes artistiques et esthétiques alors en vigueur, il est vu comme le précurseur et l'annonciateur de certains aspects les plus radicaux de l’évolution de l'art depuis 1945. Les protagonistes de l'art minimal, de l'art conceptuel et de l'art corporel ("body art"), dans leur inspiration, leur démarche artistique et idéologique, témoignent de l'influence déterminante de l’œuvre de Duchamp. Il aurait également été, d'après les nombreux essais qui lui sont consacrés, l'inspirateur d'autres courants artistiques dont le pop art, le néodadaïsme, l'op art et le cinétisme.

Né dans la Seine-Maritime, Henri Robert Marcel Duchamp est le fils du notaire de Blainville-Crevon, Justin Isidore Duchamp (dit « Eugène »), et de Marie Caroline Lucie, née Nicolle, musicienne accomplie. Marcel est le petit-fils d'Émile Frédéric Nicolle (1830-1894), courtier maritime et artiste, qui enseigna l'art à ses petits-enfants. Il est le troisième enfant d'une famille qui en compte sept, dont le sculpteur Raymond Duchamp-Villon (1876-1918), et les peintres Jacques Villon (Gaston Duchamp, 1875-1963) et Suzanne Duchamp (1889-1963), mariée au peintre Jean-Joseph Crotti.

Il entreprend son apprentissage de la peinture auprès de son grand-père artiste, puis de ses frères, de sa sœur et de leurs amis. Sa marraine, Julia Pillore, belle-fille de son grand-père Émile, avait épousé en 1900 le peintre Paulin Bertrand. Cette année-là, au collège, en , Marcel remporte un prix de mathématiques et exécute son premier dessin connu, "Magdeleine au piano". Durant l'été 1902, il entame ses premières toiles en s'inspirant des paysages de Blainville et ne jure que par Monet. Le soir, il apprend à jouer aux échecs en observant ses deux frères, particulièrement doués.

Il poursuit brillamment ses études à l'école Bossuet de Rouen, décrochant à quinze ans la première partie de son baccalauréat avec un de dessin. Durant l'été, il part en voyage à Jersey. L'année suivante, il décroche la deuxième partie du bac (Lettres-Philosophie) et la médaille d’excellence des « Amis des Arts ».

En octobre 1904, avec l'accord de son père, il part s'installer à Montmartre, au 71, rue Caulaincourt ; il vit chez son frère, devenu le peintre Jacques Villon. Il s’inscrit à l'académie Julian, et tiendra seulement une année, abandonnant à cause des cours théoriques. Il ne cesse de dessiner, de jouer au billard et assiste aux numéros de cabaret humoristiques.

N'ayant jamais fait d'école d'art au sens classique du terme, Marcel Duchamp est un autodidacte.

Après avoir échoué au concours d'entrée des Beaux-Arts de Paris, Marcel est appelé à faire son service militaire le 30 octobre 1905 : son livret militaire précise alors qu'il mesure , qu'il a les cheveux blonds et les yeux gris. En tant qu'ouvrier d'art, il voit son temps réduit à une année au lieu de trois : employé chez un imprimeur de Rouen, il a obtenu quelques semaines plus tôt un diplôme d'imprimeur de gravures, dans le but unique de réduire autant que possible son passage sous les drapeaux. Par ailleurs, son père part en retraite, quitte Blainville pour Rouen et emmène toute la famille au 71, rue Jeanne-d'Arc. Nommé caporal le 11 avril 1906, Marcel est libéré le 3 octobre et emménage au 65, rue Caulaincourt (Paris). Son meilleur partenaire de billard s'appelle Juan Gris.

Pour arrondir les fins de mois, Marcel, à l'imitation de Villon, tente de proposer des caricatures satiriques à des journaux comme "Le Rire" et "Le Courrier français". Après quelques refus, dix-huit dessins furent publiés entre novembre 1908 et octobre 1910. Il signe « Duchamp » et pratique un humour parfois jugé gaudriolesque. Pour la première fois, Marcel hésite entre deux carrières : humoriste ou peintre. Il propose ses dessins au Salon des Humoristes (Palais des Glaces, Paris) en mai et juin 1907, mais sans grand succès : c'est son premier contact avec le public. Entre Noël 1907 et la rentrée 1908, Marcel mène la belle vie : fêtes mémorables rue Caulaincourt, exposition de quatre nouveaux dessins au Salon des artistes humoristes (mai-juin) puis longues vacances à Veules-les-Roses. Il déménage à Neuilly-sur-Seine et y demeurera jusqu'en 1913. 

Il commence à exposer des tableaux au Salon d'automne (Grand Palais, octobre-novembre 1908), à savoir "Portrait", "Cerisier en fleurs", et "Vieux cimetière", très marqués par les impressionnistes. Au printemps 1909, il expose au Salon des indépendants (Orangerie des Tuileries) deux paysages dont l'un sera acheté : pour Marcel, c'est une première. De nouveau à Veules-les-Roses, il se met à peindre les environs et expose ses paysages au Salon d'automne pour la seconde fois. Une toile est achetée par Isadora Duncan. À la fin de l'année, il expose à la Société normande de peinture moderne organisée à Rouen par son camarade d'enfance, Pierre Dumont, qui lui présente Francis Picabia, qui exposait également. Ses deux frères, Jacques et Raymond, l'invitent souvent à les rejoindre à Puteaux au 7, rue Lemaître où ils vivent dans une sorte de communauté d'artistes où se croisent des cubistes comme Albert Gleizes, Fernand Léger, Jean Metzinger, Roger de La Fresnaye, mais aussi des poètes comme Guillaume Apollinaire (qui n'aime pas ses nus), Henri-Martin Barzun, Maurice Princet et le jeune Georges Ribemont-Dessaignes.

Après les années 1902-1910, qui sont qualifiées par Duchamp de « huit années de leçons de natation », durant lesquelles il explore toute une série de styles artistiques — impressionnisme, fauvisme, cubisme — s'ouvre une période de recherches intenses.

Entre 1910 et 1912, la manière de s'exprimer de Duchamp évolue considérablement, et passe par différentes phases. Il est d'abord très marqué par Cézanne, comme en témoigne sa toile "La Partie d'échecs", mais aussi par le fauvisme avec, par exemple, "Le Portrait du docteur Dumouchel", tout en refusant de coller au modèle. Une certaine Jeanne Marguerite Chastagnier pose pour lui et Duchamp exécute des études de nus, puis noue une relation amoureuse avec elle. Au cours de cette période, il devient également sociétaire du Salon d'Automne et ne passe plus par le jury de sélection (mais ironiquement il n'y exposera plus). En 1911, il réalise la fusion entre le symbolisme et le cubisme, entreprenant des recherches picturales sur le mouvement, très marqué par les travaux de Kupka, son voisin de Puteaux et, dans la foulée, il exécute pour ses frères "Moulin à café", sa première représentation de machine et de rouages.

C'est au début de 1911 qu'il peint une toile intitulée "Le Printemps" (ou "Jeune homme et jeune fille dans le printemps") : rétrospectivement, Arturo Schwarz y voit « la première œuvre de Duchamp qui lui soit vraiment personnelle ». Dans cette œuvre notamment, la figure de l'androgyne deviendra un thème hautement symbolique pour ses futures grandes réalisations. 

De 1911 à 1912, Duchamp élabore des dessins énigmatiques (série des "Roi et reine traversés par des nus en vitesse", "Joueurs d’échecs") et de minutieux tableaux travaillés à l’ancienne (les deux "Nu descendant un escalier", "Joueurs d’échecs", "Le Roi et la reine entourés par des nus vite", "Passage de la vierge à la mariée", "Mariée"). Il compose alors une iconographie hermétique, déconcertante de complexité, relevant d’une forme de maniérisme arcimboldesque. On a pu avancer que les peintures de cette période, à l’interprétation si problématique, et se démarquant manifestement du cubisme ou du fauvisme alors en vogue, seraient le produit d’un intérêt persistant, et certes paradoxal pour un artiste considéré comme l’apôtre de l’anti-art, pour certains maîtres du passé (Bosch, Lucas Cranach l'Ancien, Léonard, Bellange, Hogarth, Goya) ou anonymes de la Renaissance française, et surtout pour Vélasquez. Les « figures » des compositions de cette période, puisées dans le répertoire de la peinture ancienne, deviennent agencement intriqué d’objets divers, processus qui trouvera son aboutissement dans "Le Grand Verre" (1915-1923) , qui pourrait alors être lu comme la version mécaniste des "Ménines" de Vélasquez. 

Outre ce regard incisif porté sur la peinture ancienne, Duchamp revendique son grand intérêt pour des auteurs tels que Jules Laforgue, Villiers de l’Isle-Adam et Alfred Jarry, qui nourrissent également les productions de cette période. C'est de cette époque, en novembre 1911, que date "Jeune homme triste dans un train" : il y expérimente déjà les effets de la chronophotographie. C'est un poème de Laforgue qui lui aurait inspiré une composition, le "Nu descendant un escalier", qu'il entame également fin 1911, et dont la seconde version fut proposée au Salon des indépendants, le 20 mars 1912. Cette toile fut refusée par ses amis du jury : Duchamp est profondément blessé. Il dira, bien plus tard : 

Fin juin 1912, il entreprend un voyage à Munich, où il retrouve son ami le peintre allemand Max Bergmann (1884-1955), à qui il offrit en 1910, un bilboquet dédicacé. Ce voyage met Duchamp au contact de l'avant-garde munichoise, il visite les musées et les expositions temporaires, il est pris en photo par Heinrich Hoffmann et achète "Über das Geistige in der Kunst" ("Du spirituel dans l'art"), un essai signé Vassily Kandinsky. Il passe ensuite par Bâle, Dresde et Berlin. Ce nouveau contexte intellectuel, artistique et scientifique le conduit sans doute à concevoir le plan du "Grand Verre".

Il est présent au côté du groupe de la Section d'or en octobre 1912 à Paris, pour une exposition à la galerie La Boétie. Cette année, capitale, lui fait découvrir "Voyage au pays de la quatrième dimension", de Gaston de Pawlowski, par ailleurs directeur du magazine "Le Vélo", mais aussi "Impressions d'Afrique", de Raymond Roussel et les calembours étymologico-fantaisistes de Jean-Pierre Brisset, des auteurs auxquels l'artiste doit beaucoup en ce qui concerne cette période de transition : outre l'influence du mathématicien Maurice Princet, qui fréquentait les cubistes du groupe de Puteaux, Duchamp reconnut plus tard sa dette envers ces penseurs singuliers, qui lui permirent d'interpréter à sa manière certains aspects théoriques de la géométrie non euclidienne, bien qu'il se déclare ne pas être doué sur le plan scientifique.
En octobre 1912, Walter Pach met en relation Duchamp et les autres membres du Groupe de Puteaux avec Walt Kuhn et Arthur Bowen Davies, respectivement directeur et président de l'Association des peintres et sculpteur américains, qui préparent une énorme exposition devant faire le lien entre les modernistes de la fin du , la peinture américaine et l'avant-garde européenne.

De février à mai 1913, aux États-Unis, les nouvelles recherches européennes sont présentées lors de l'International Exhibition of Modern Art : l’Armory Show à New York, puis à l'Institut d'art de Chicago et enfin à Boston à la Copley Society. Durant les deux premières expositions, le "Nu descendant un escalier " provoque hilarité et scandale dans certains journaux. Cette œuvre est influencée, tout comme le futurisme, par la chronophotographie. Duchamp y présente aussi "Roi et reine entourés de nus", "Joueur d'échecs" et une esquisse de nu : il vend les trois premières œuvres. L'Armory Show ferme ses portes le 15 mars : deux jours après, Alfred Stieglitz invite Marcel Duchamp et Francis Picabia à exposer dans sa galerie appelée « 291 » : en comparaison, cet événement resta confidentiel.

En 1913, il commence à travailler à la bibliothèque Sainte-Geneviève dans le Quartier latin, ce qui lui permet d'avoir accès à une documentation nouvelle, mais aussi de « [se] dégager de toute obligation matérielle ». Duchamp ajoute : « J'ai commencé une carrière de bibliothécaire qui était une sorte d'excuse sociale. C'était vraiment une décision, à ce point de vue, très nette. Je ne cherchais pas à faire des tableaux ni à les vendre, j'avais d'ailleurs un travail devant moi qui me demandait plusieurs années, "La Mariée mise à nu par ses célibataires, même". » Afin de se perfectionner, il suit en auditeur libre les cours de l'École des chartes dès novembre 1912, où il suit particulièrement les cours de bibliographie de Charles Mortet. Ce dernier est l'un des deux conservateurs qui le soutiennent (avec Maurice Davanne, oncle de Francis Picabia) et lui permettent d'être officiellement embauché pendant les deux mois d'absence de Charles Kohler, alors malade (novembre-décembre 1913). Duchamp recommence ensuite à travailler comme bénévole (surnuméraire) de janvier 1914 à mai 1915.

Il s’écarte de la peinture, vers 1913-1915, avec les premiers "ready-mades", objets « tout faits » qu’il choisit pour leur neutralité esthétique : "Roue de bicyclette" (1913), "Porte-bouteilles" (1914), "Fontaine" (1917), un urinoir renversé sur lequel il appose la signature « R. Mutt ». Cet objet est refusé par les organisateurs de l'exposition de la Société des artistes indépendants de New York. Il a pris un article ordinaire de la vie le plus prosaïque qui soit et l'a placé de manière à ce que sa signification d’usage disparaisse sous le nouveau titre et le nouveau point de vue. En arrachant un objet manufacturé à son contexte et en le plaçant dans un nouveau contexte inhabituel, Duchamp élève ces objets au rang d’œuvres d'art par le simple choix de l'artiste. Il marque ainsi une césure profonde avec toute la tradition artistique qui l'a précédé.

Réformé en 1914 pour insuffisance cardiaque à la suite de son service militaire en 1906, il part à New York au printemps 1915 et entretient des liens avec Man Ray, Arthur Cravan, Alfred Stieglitz et Francis Picabia avec qui il fonde la revue "391". Hébergé par Walter Arensberg, qui lui fournit également un atelier, Duchamp donne des cours de français pour subvenir à ses besoins, tout en travaillant sur Le Grand Verre et en créant de nouveaux ready-mades, comme la pelle ("En avant du bras cassé"), le peigne ("Comb") sur lequel il avait tracé la phrase "Trois ou quatre gouttes de hauteur n'ont rien à faire avec la sauvagerie" ou encore "With Hidden Noise", pelote de ficelle comprimée entre deux plaques de métal. Ces propositions de Duchamp ne sont pas destinées à être vendues, mais elles influencent ses amis comme Picabia ou Man Ray.

Avec ses "objets trouvés" et ses "ready-made", ainsi que par son côté iconoclaste, Duchamp est très proche de l'esprit Dada. À ce titre, il eut un impact non négligeable sur le mouvement dadaïste, courant auquel on peut aussi rattacher "La Mariée mise à nu par ses célibataires, même" (1912-1923). En effet, il ne faut pas oublier que, si Duchamp commence les recherches du "Grand Verre" dès 1912, il ne le réalisa qu'à partir de 1915, d’où les dates énoncées précédemment. À Paris et à New York, il côtoie d'autres protagonistes du mouvement, comme Francis Picabia et Man Ray. Il refuse cependant de s'associer au Salon Dada organisé par Tristan Tzara, à Paris en 1922, souhaitant garder son indépendance et ne pas être étiqueté à un mouvement.

Duchamp se revendiquant de « l'anti-art », il est ainsi inspiré par les artistes dada rejetant les institutions artistiques dominantes tels que musées ou galeries.

Il collabore à la revue "Le Surréalisme au Service de la Révolution" (1930-1933), lancée par André Breton et éditée par José Corti.

En janvier 1938, il coorganise l’Exposition internationale du surréalisme à la Galerie des Beaux-Arts à Paris en proposant dans l'une des salles une sculpture éphémère composée de sacs de charbon suspendus au plafond. En plongeant ainsi la pièce dans la pénombre, il oblige les spectateurs à s'éclairer et à se déplacer au moyen d'une lampe de poche. Duchamp récidive en 1942 lors de l'exposition surréaliste internationale de New York où il installe un réseau de ficelles dans l'aire d'exposition, forçant à nouveau le visiteur à s'intégrer à son milieu. Ce faisant, Duchamp jette les bases du happening qui fera son apparition quelques années plus tard et qui reprend un principe similaire par ses événements et performances en direct.

Duchamp était préoccupé par le temps, la vitesse et la décomposition des mouvements. Ce qui l'a justement amené, en 1925-1926, à expérimenter une nouvelle forme d'expression cinématographique, l'« Optical cinema », avec son unique film intitulé "Anémic Cinéma". Son film présente des plaques rotatives qui deviendront plus tard, en 1935, les « rotoreliefs » (ou « machines optiques »). Proposés sous la forme de plaques tournantes sur un axe grâce à un moteur, ils associent jeux optiques, jeux de mots, et géométrie.

Au moment où il travaille sur les esquisses du "Nu descendant l'escalier" (1911-1912), il découvre les expériences protocinématographiques d'Étienne-Jules Marey, entre autres. Sa "Roue de bicyclette" (1913) peut également s'inscrire dans les prémices de ses travaux sur le mouvement poético-sculptural, ce "ready-made" est en effet considéré comme à l'origine de l'art cinétique. La phase suivante entretient un rapport entre moteurs électriques, disques transparents ou recouverts de motifs géométriques (1920-1924), invention pour laquelle il sollicite l'aide de Jacques Doucet, et qui culminera avec les « rotoreliefs », dont il déposera le brevet en 1935. Intrigué par un effet optique de deux spirales tournant sur un axe commun, l'une semblant aller vers l'avant et l'autre vers l'arrière, Duchamp fabrique un appareil pour démontrer le principe, la "Rotative plaques de verre". En 1924, il construit la "Rotative demi-sphère, optique de précision", assemblage d'un disque de tôle et d'un demi-globe de verre animé par un moteur, ainsi qu'un anneau de cuivre sur lequel était gravée la phrase : "Rrose Sélavy et moi esquivons les ecchymoses des esquimaux aux mots exquis". La première « machine optique » fut gravée sur disque rouge et reproduite en encart dans la revue "391", , en juillet 1924.

En 1926, il réalise un court-métrage expérimental intitulé "Anémic Cinéma" (, noir et blanc, durée de ), d'une durée de 7 minutes, et signé Rrose Sélavy, avec la complicité de Man Ray et du réalisateur Marc Allégret. Des disques en mouvement sont filmés, sur lesquels sont parfois inscrites des phrases — comme —, où l'absurde, l'humour noir et l'allitération sont de mise. Le film fut projeté en août 1926, en séance privée.

En revanche, il n'est pas totalement certain que l'on retrouve un jour le court-métrage qu'il réalisa avec Man Ray, "Baroness Elsa von Freytag-Loringhoven shaving her pubic hair" ("La baronne rase ses poils pubiens"), avec comme interprète la sculptrice Elsa von Freytag-Loringhoven. Ce film aurait été tourné à New York en 1921 et projeté dans le cercle des amis du mécène Walter Arensberg. Les négatifs auraient été détruits.

Par ailleurs, Duchamp entretient un rapport complice avec le cinématographe. En 1918, il apparaît comme figurant dans "Lafayette, We Come!" de Léonce Perret. En 1924, il participe au tournage d"'Entr'acte", de René Clair : dans ce court-métrage expérimental et comique, Duchamp apparaît en joueur d'échecs face à Man Ray. En 1944, il est l'« artiste » dans le film expérimental de Maya Deren, "Witch's Cradle". En 1947, il participe à la direction artistique du film "Rêves à vendre" ("Dreams That Money Can Buy") d'Hans Richter, pour un épisode sur une musique de John Cage.

Par la suite, il apparaît dans quelques films d'artistes, mais aussi des documentaires, et ce, jusqu'à la veille de sa mort :

Huile sur toile au format panorama, "Tu m’", exécutée en 1918, quatre ans après sa dernière peinture. Elle est la première œuvre de Duchamp à intégrer des objets dans sa peinture. Le tableau a été conçu afin d'entrer dans l'espace au-dessus de la bibliothèque de Katherine Dreier, sa mécène de l'époque et qui lui a commandé l'œuvre. Peinte peu avant le départ de Duchamp pour Buenos Aires, elle est vue comme « le dernier tableau de Marcel Duchamp », ou plutôt comme un abandon par l'artiste de l'huile sur toile.

Sorte de synthèse des idées de Duchamp, on y retrouve trois représentations de ready-made, une roue de bicyclette, un tire-bouchon et un porte-chapeau, peints comme des ombrages. Des lignes sont créées par la chute d'un mètre de fils d'un mètre de long. Une succession de carrés de couleur, suggérant des échantillons de peinture, traverse la toile jusqu'à une fissure. Un goupillon est enfoncé dans cette fissure réelle dans la toile du tableau qui en rejoint une seconde, peinte celle-là en trompe-l’œil et retenue avec 3 vraies épingles de sûreté. Sous la fissure peinte, on retrouve une main pointant un index et exécutée par un peintre d'enseignes que Duchamp avait embauché.

Le titre lui-même pourrait être une abréviation de "Tu m'ennuies" ou "Tu m'emmerdes", bien que Duchamp ne se soit jamais exprimé clairement sur le sujet. 

"La Mariée mise à nu par ses célibataires, même", dite "Le Grand Verre", réalisée aux États-Unis, enchâssée entre deux panneaux de verre montés sur cadre et trépieds (1915-1923, musée de Philadelphie), est l’aboutissement de plusieurs études préliminaires, constituées de notes, d'esquisses, de « peintures », remontant au début des années 1910, telles que la "Boîte de 1914" ou "Neuf moules mâliques" (1913-1914). Chez l'artiste, cette recherche (ou ce questionnement) correspond à l’obsession d’une « vraie forme » invisible, obtenue par contact et transparence, afin de synthétiser toutes ses théories, notamment l'art comme « fait mental ». Réalisée à l’huile, feuille et fil de plomb, cette étude, considérée par l'artiste comme inachevée, fut brisée lors de son transport en 1916, mais Marcel Duchamp refusa de la faire restaurer. Les critiques d'art qui découvrirent cette œuvre y virent les brisures et les considérèrent comme partie intégrante de l’œuvre jusqu'en 1959.

Dans les dernières années de sa vie, Duchamp exécuta une œuvre pour le Philadelphia Museum of Art, "Étant donnés : 1) La chute d’eau 2) le gaz d’éclairage…" (1946-1966), environnement sculptural érotique, interdit, par la volonté de l'artiste, à la vue du public avant l'année 1969 (soit un an après sa mort).

Marcel Duchamp fut aussi satrape du Collège de Pataphysique en 1953 et devint membre de l'Oulipo en 1962.

Ayant appris le jeu dès son jeune âge, Duchamp s'y consacre de plus en plus à partir de son séjour à Buenos Aires. Il devient ainsi un excellent joueur d'échecs. Champion de Haute-Normandie en 1924, il participa plusieurs fois au championnat de France et fit partie de l'équipe de France à l'Olympiade d'échecs de la Haye (1928), Hambourg (1930), Prague (1931) et Folkestone (1933).

En 1918-1919, il sculpte un jeu de pièces complet lors de son séjour à Buenos Aires.

En 1924, il dispute une partie d'échecs avec Man Ray dans le film "Entr'acte", de René Clair, scène durant laquelle des trombes d'eau s'abattent sur les joueurs et dispersent les pièces du jeu.

En 1925, il conçoit l'affiche du championnat de France d'échecs qui se déroule à Nice, du 2 au 11 septembre.

En 1932, il publie, en collaboration avec Vitaly Halberstadt, "L'opposition et les cases conjuguées sont réconciliées", un manuel qui traite des finales de rois et de pions. Marcel Duchamp en conçoit la présentation et la couverture.

Marcel Duchamp est le père d'une enfant naturelle, Yvonne, née le 6 février 1911, de Marguerite Chastagnier, son modèle. L'artiste ne découvrira l'existence de cette enfant qu'en 1922 et la rencontrera plusieurs fois entre 1966 et 1968.

En 1924, Duchamp entame une liaison avec Mary Reynolds, née Hubachek (1891-1950), qui exerça le métier de relieur d'art. Cette liaison dura plus de vingt ans.

Le , Duchamp épouse Lydie Sarazin-Levassor (1903-1988). Ils divorcent six mois plus tard, le . La rumeur colporte alors que c’est, pour Duchamp, un mariage de convenance : Lydie Sarazin-Levassor est la petite-fille d’un (autrefois) riche constructeur automobile, Émile Levassor. Le père est ravi qu'un mariage arrangé rapide de sa fille facilite sa situation. Au début de , Duchamp dit à sa femme qu’il ne peut plus supporter les devoirs du mariage et son enfermement. Moins de trois semaines plus tard, ils divorcent. Peu après son divorce, Duchamp s'affiche publiquement avec Mary Reynolds jusqu'à sa mort en 1950.

Entre 1940 et 1944, il est à New York, dans son atelier situé à Greenwich Village, vivant avec Mary, entouré d'intellectuels français en exil, dont André Breton et Robert Lebel, avec lesquels il restera très proche. En 1942, selon Serge Bramly, Duchamp se retrouve coincé dans un camp de transit à Casablanca, attendant son bateau pour les États-Unis.

En 1946, il donne son atelier parisien situé 11, rue Larrey et qu'il occupait depuis 1927, à Isabelle Waldberg.

Entre 1947 et 1951, il entretient une liaison avec la sculptrice brésilienne .

En 1954, il épouse en secondes noces Alexina Sattler, dite Teeny, la première épouse de Pierre Matisse, célèbre marchand d'art du Fuller Building de New York et fils du peintre Henri Matisse. Il devient citoyen américain en 1955.

Une grande rétrospective tenue à Pasadena en 1963 consacre le rôle de Marcel Duchamp dans l'art contemporain. L'exposition donne également lieu à des rééditions de ses "ready-mades" les plus célèbres, signés par Duchamp.

Le samedi 15 mai 1965, Duchamp organise un « dîner Rrose Sélavy » au restaurant "Victoria" à Paris, et s'entoure d'une trentaine de convives, dont Carl Reuterswärd, Jacques Fraenkel, Gabrièle Buffet-Picabia, P. R. de Zayas et Marie-Claire Dumas, tous membres de l’Association pour l'étude du mouvement dada. Au cours du dîner, il dépose dans un récipient les cendres d'un cigare et à la fin, celles du procès-verbal attestant du contenu du dit récipient baptisé "L'Urne", laquelle, véritable "ready-made" provoqué, est ensuite scellée et signée.

Le 5 juin 1968, il est longuement interviewé par Joan Bakewell pour la chaîne de télévision BBC. 

Le 2 octobre 1968, Marcel Duchamp meurt à l'âge de 81 ans à Neuilly-sur-Seine (Hauts-de-Seine).

Ses cendres sont déposées dans le caveau familial au cimetière monumental de Rouen. Une épitaphe est gravée sur sa tombe : 

En septembre 1969, le Philadelphia Museum of Art révèle au public son ultime œuvre : "Étant donnés : 1° la chute d'eau ; 2° le gaz d'éclairage…".


Marcel Duchamp a révolutionné la conception académique de l’art qui, jusqu'alors, ne jugeait la valeur d'une œuvre qu'à l'aune des efforts et du travail dispensés pour une finalité édifiante. L'hétérogénéité de ses moyens d'expression et la complexité de ses œuvres, de la peinture ("Nu descendant un escalier" en 1912), à l'installation plastique la plus hermétique ("Étant donnés…", « inachevée » en 1966), en passant par les détournements d'objets « tout fait » (un urinoir, un sèche-bouteilles, un peigne…), décrétés œuvres d'art par sa seule volonté et associés à sa constante revendication du « droit à la paresse », ne permettent de le classer dans aucun des mouvements artistiques du . Duchamp a traversé le cubisme, le futurisme, dada et le surréalisme en s'excluant lui-même de tout courant.
À travers ses œuvres, Duchamp mène une réflexion sur la notion d’Art, sur l'esthétique, préparant ainsi ce qu'est l'art conceptuel. Le pop art, fluxus et le happening ont aussi fait de fréquents emprunts aux pratiques et démarches artistiques de Duchamp. Ses rotoreliefs influenceront les tenants de l'art optique. Les écrits de Marcel Duchamp ont été publiés sous les titres "Duchamp du signe" (1958) et "Marchand du sel" (1958). Il fut également le créateur d'un personnage fictif, Rrose Sélavy, sculpteur et auteur d’aphorismes maniant la fausse contrepèterie et l’allitération.


Un grand nombre des œuvres de Marcel Duchamp sont conservées dans une salle d'exposition permanente au Philadelphia Museum of Art.

Le catalogue raisonné de l'ensemble des créations de Marcel Duchamp a été élaboré par Arturo Schwarz.



Écrits de M. D. publiés sous forme de livre, livre-objet, boîte, etc. : 












Le personnage et son œuvre inspirent dès les années 1910 un certain nombre de créateurs, cette appropriation s'exprime sous la forme de détournements et de productions originales. Les "duchampiana" n'ont pas fini d'éclore…






"Les deux premiers écrits fondateurs sont" :

"Par ordre alphabétique" :

<includeonly>Merci d'éviter les liens publicitaires et privilégier les sites francophones sans droits réservés !</includeonly>


</doc>
<doc id="14379" url="https://fr.wikipedia.org/wiki?curid=14379" title="Futurisme">
Futurisme

Le futurisme est un mouvement littéraire et artistique européen du début du (de 1909 à 1920), qui rejette la tradition esthétique et exalte le monde moderne, en particulier la civilisation urbaine, les machines et la vitesse.

Le futurisme est né en Italie autour du poète Filippo Tommaso Marinetti ("Manifeste du futurisme", 1909). Auteurs de deux manifestes en 1910, les premiers peintres du mouvement, Giacomo Balla, Umberto Boccioni, Carlo Carrà, Gino Severini, Luigi Russolo (1885-1947), empruntent à la technique divisionniste et au cubisme pour faire interférer formes, rythmes, couleurs et lumières afin d'exprimer une , une simultanéité des états d'âme et des structures multiples du monde visible.

Un mouvement Valet de Carreau a existé en Russie (appelé également cubo-futurisme) dans les années 1910-1917 (Vladimir Maïakovski, Kasimir Malevitch, Velimir Khlebnikov, Piotr Kontchalovski, Mikhaïl Matiouchine, Ilia Machkov, Aristarkh Lentoulov, Natalie Gontcharova, Vladimir Tatline, etc.).

Le futurisme prône l'amour de la vitesse (Luigi Russolo, "Dynamisme d'une automobile", 1912-1913) et de la machine en exaltant la beauté des voitures, ainsi que la nécessité de la violence pour débarrasser l’Italie du culte archéologique du passé. Marinetti est le seul à pousser ses idées jusqu’à se réclamer du social-darwinisme en exaltant . Théoricien du , Boccioni écarte les nouveaux médias technologiques, tels le cinéma et la photographie. Il stigmatise les recherches du des frères Anton Giulio Bragaglia et Arturo Bragaglia, ainsi que le cinéma abstrait des frères Arnaldo Ginna et , considérant que la main de l’artiste est l’instrument le plus apte à transmettre l’élan vital qui nourrit le monde moderne.

Plus qu'un mouvement, le futurisme devient un art de vivre et une véritable révolution anthropologique. Il touche la peinture, la sculpture, la littérature, le cinéma, la photographie, le théâtre, la mise en scène, la musique, le bruitisme, l'architecture, la danse, la typographie, les moyens de communication, et même la politique, la cuisine ou la céramique qui sera consacrée dans le dernier des manifestes futuristes de 1939.

Russolo et Pratella, à travers une théorisation de la notion de bruit, font l'apologie du son. Le bruit est en premier lieu ingérable et échappe à toute classification (par exemple, le bruit d'une usine). C'est ainsi qu'il se différencie du son, de la musique. À présent, l'analyse du bruit, ou plutôt des bruits, permet de le maîtriser. Voilà pourquoi Russolo et Pratella ont commencé à faire un classement du bruit, à chercher ses caractéristiques (chose à laquelle personne n'avait pensé auparavant). Cette nouvelle approche du phénomène sonore fait son apparition dans "L'Art des bruits" (""), manifeste contenu dans une lettre que Russolo adresse à Pratella en 1913. Cette analyse du bruit va être reprise par les dadaïstes mais avec un point de vue différent : pas de notion d'agressivité ; puis au sein de la musique contemporaine par Edgar Varèse, Pierre Schaeffer et beaucoup d'autres créateurs, et enfin réintroduite dans la musique industrielle au début des années 1980 par Vivenza, théoricien et musicien bruitiste futuriste français, à qui l'on doit la popularisation du terme « bruitisme ».

La plupart des grandes œuvres associées au mouvement futuriste sont créées . Les théories de Boccioni inspirent les futuristes jusqu’à la fin de la Première Guerre mondiale. Ensuite, les recherches futuristes sont poursuivies à travers « l’art mécanique » pendant les années 1920, puis à travers une véritable « aéro-esthétique » pendant les années 1930. En 1967, Enzo Benedetto publie le manifeste "Futurismo-oggi" qui propose de passer à la troisième étape artistique du mouvement : 

Les futuristes sont à l'origine du mouvement de la performance. Il s'agissait, à l'origine, pour les peintres d'appliquer leurs manifestes : ils associèrent alors peinture, théâtre et provocations. Ils prolongeaient leur œuvre en devenant objets d'art eux-mêmes par la gestuelle, et en développant un théâtre d'artistes-acteurs. À la suite de cela, ils approfondirent leurs manifestes, en s'inspirant du théâtre de variétés, parce que celui-ci n'avait ni traditions, ni maîtres, ni dogmes. Et, portés par leur admiration pour les machines, ils intégrèrent à leurs spectacles les notions de bruit avec la musique bruitiste, ainsi que la mécanisation de l'interprète. Ils recherchaient la continuité entre dispositif scénique et interprète, par les actions de simultanéité et de danse. Ils dénommèrent l'ensemble « théâtre synthétique ».

Le futurisme aura une influence notable sur d'autres mouvements d'avant-garde nés dans l'immédiat après-guerre, comme l'ultraïsme en Espagne et en Amérique du Sud (Rafael Barradas, Jorge Luis Borges, Guillermo de Torre) ou le formisme, en Pologne (Tytus Czyżewski, Stanisław Ignacy Witkiewicz, Auguste Zamoyski).

S’agissant des rapports entre futurisme et fascisme, une vision simpliste encore très répandue consiste à réduire l’avant-garde italienne à un mouvement entièrement soumis au régime mussolinien. En fait, Giovanni Lista a réuni les textes théoriques des futuristes italiens qui se sont réclamés du marxisme, du socialisme et du communisme. L’adhésion au fascisme fut plutôt une sorte de compromis passé avec le régime par une partie des futuristes, alors que le rôle joué par Marinetti à cette occasion mérite une étude à part. Par ailleurs, comme l’a souligné Alfred H. Barr, Jr., le directeur du Museum of Modern Art, dès 1949, la position artistique la plus représentative du mouvement mussolinien dans les années 1920 est le Novecento.

Le mouvement des futuristes possédait dès l'origine une composante politique. Marinetti accentue ses exigences pour une modification générale des valeurs sociales. Le futurisme allie des visions réformistes radicales et des visions artistiques.

Les futuristes, en se liant de manière ambiguë au régime fasciste, de 1919 à 1945, ont soulevé des réserves à leur égard, en tant que première avant-garde italienne. Ils seront aussi à l'origine du retard dans la réception de la seconde génération d'artistes futuristes.

En 1909, est publié le "Primo manifesto politico". Lors des élections de 1913, Marinetti, Boccioni, Carrà et Russolo ont établi un programme politique futuriste qui évoque la protection économique du prolétariat et qui propose l'expansion coloniale. Dans l'écrit intitulé "Che cos'è il futurismo. Nozioni elementari", daté de 1920, les buts politiques sont plus détaillés : mise en place d'une armée de volontaires, modernisation du service de sécurité public et prise en mains du gouvernement italien par des jeunes qui se sont battus sur le front.

Les futuristes avec leurs positions radicales, plus idéalistes que politiques, ont peu d'impact dans la vie politique réelle.

Mussolini, qui connaissait Marinetti depuis 1915, tire avantage de l'environnement intellectuel révolutionnaire des futuristes. À partir de sa prise de pouvoir en 1922, il s'inspire de leur volonté déterminée de renouvellement, de leur éloquence agressive et de leur bonne organisation de groupe. En 1924, Marinetti réfléchit au lien entre art et politique en Italie dans son traité "Futurisme et fascisme". Il met en valeur le rôle pionnier du futurisme et souligne les rapprochements possibles avec le fascisme. Plus tard, Mussolini prend ses distances avec le futurisme. En se rapprochant de l'Église catholique et du parti conservateur par opportunisme politique, Mussolini révèle alors une vision anti-futuriste.

Futurisme et fascisme entretiennent des liens ambivalents. Des artistes de la seconde phase futuriste, comme Enrico Prampolini, Gerardo Dottori et Mario Sironi ont décoré des salles pour les grands spectacles d'auto-représentation de l'État fasciste comme la "Mostra della Rivoluzione Fascista" de Rome en 1932. Cette relation entre futurisme et pouvoir fasciste donne lieu à des contradictions. Par exemple, Marinetti accepte en 1929 un poste à la nouvelle Reale Accademia d'Italia, alors que les futuristes ont toujours dénigré les professeurs ignorants, les qui représentent pour eux le passéisme honni.

L'architecte du régime fasciste Marcello Piacentini a fait construire des bâtiments monumentaux destinés à durer éternellement alors que l'architecte futuriste Antonio Sant'Elia prônait une élaboration de l'espace urbain à chaque génération. Mussolini, contrairement à Staline ou Hitler, cherche à s'attirer les appuis des artistes avant-gardistes. Les régimes totalitaires en Allemagne et en Russie ont violemment combattu l'art moderne en le discriminant et en tentant de le neutraliser. Les nazis n'ont d'ailleurs pas hésité à détruire des milliers d’œuvres jugées décadentes (l'art dégénéré).

Mussolini, au contraire, tolérait les courants artistiques modernes, bien qu'il ait voulu également élever à nouveau l'art antique avec sa tendance au monumental ainsi que les références à la mythologie romaine au rang d'art national.

Le fascisme, en s'appuyant sur ces nouvelles formes de la modernité picturale, montre son désir de provoquer une rupture avec le passé, mais aussi sa fascination pour la technique et la vitesse.

Le futurisme se distingue clairement de l'expressionnisme allemand ; cependant, les artistes futuristes italiens se sont retrouvés dans une position délicate, entre compromission et affirmation de leurs idéaux et leurs personnalités.




"Le Futuriste", scénario d'Olivier Cotte, dessin de Jules Stromboni, 56 pages, Casterman, 2008.



("Hylaea", "Ego-futurisme", cubo-futurisme...)



</doc>
<doc id="14381" url="https://fr.wikipedia.org/wiki?curid=14381" title="Hara-kiri">
Hara-kiri

Le , ou , est une forme rituelle de suicide masculin par éventration, apparue au Japon vers le dans la classe des samouraïs, et officiellement interdite en 1868.

En japonais, le terme 切腹 ("seppuku") est plus formel, et typiquement utilisé dans les textes écrits et officiels. Il est formé d'après la lecture "on" héritée du chinois, du caractère 切 (« couper ») qui est lu "setsu", et de 腹 (« ventre ») qui est lu "fuku". La lecture "setsu" + "fuku" donnant "seppuku".

Selon l'écrivain Christopher Ross, le terme populaire "harakiri" est utilisé dans la langue parlée japonaise, mais n'était pas utilisé dans les textes. Celui-ci est formé d'après une lecture japonaise native "kun", des mêmes caractères mais dans le sens inverse : 腹 (« ventre ») lu "hara", et 切 (« couper ») lu "kiri".

Traditionnellement, le "seppuku" était réalisé dans un temple en s'ouvrant l'abdomen à l'aide d'un "wakizashi" (sabre court) ou d'un poignard de type "tantō", ce qui libère l'âme (voir l'article "seika tanden"). La forme traditionnelle consiste en une ouverture transversale (dans la largeur), sous le nombril. Le "seppuku" comporte une version encore plus douloureuse, le "jumonji-giri", qui consiste à rajouter une coupe verticale (de haut en bas) à la coupe horizontale pour marquer sa volonté d'expiation. Il existe une version moins honorable (et moins douloureuse) dans laquelle un « ami » ("kaishakunin") coupe la tête pour une mort instantanée.

Le "seppuku" était traditionnellement utilisé en dernier recours, lorsqu'un guerrier estimait immoral un ordre de son maître et refusait de l'exécuter. C'était aussi une façon de se repentir d'un péché impardonnable, commis volontairement ou par accident. Plus près de nous, le "seppuku" subsiste encore comme une manière exceptionnelle de racheter ses fautes, mais aussi pour se laver d'un échec personnel.

Le "seppuku" étant un rituel masculin, les femmes nobles et épouses de samouraïs pratiquaient le "jigai", une forme de suicide consistant à se trancher la gorge (carotide) avec un poignard.

Le ventre est le siège de la volonté, du courage et des émotions en Asie : "Hara ookii", « vous avez un gros ventre », pourrait vexer en Occident, tandis qu'au Japon c'est un compliment qui veut dire « vous avez un grand cœur » ; à notre « parler à cœur ouvert » pour exprimer sa sincérité, correspond l'expression japonaise "Hara no watte", « à ventre ouvert » ou plus exactement « en s'ouvrant le ventre » ; "Hara no misenaï", « ne montrent pas leur ventre », signifie « cacher sa pensée », l'inverse se disant "Hara no yomeru" (« lire dans son ventre ») et signifiant qu'on peut « lire dans ses pensées », donc qu'il est honnête dans ce qu'il dit.

Le "seppuku" ou « suicide par extraction des intestins » a longtemps permis aux nobles et aux samouraïs d'exprimer leurs dernières volontés. Tout comme, en Occident, les "gentlemen" « se brûlent la cervelle » c'est-à-dire se tirent une balle dans la tête, les Japonais s'immolent par l'abdomen, siège, pour eux, de la pensée et de la conscience de soi. C'est probablement la raison pour laquelle il existe une grande variété de mots pour désigner le suicide ("jisatsu", en japonais) :

Pour être complet, il faut citer loibara", qui figure dans le manuel du parfait samouraï(le "Hagakure"). L'oibara est le suicide d'inféodation. Il se subdivise en "maebara" et "sakibara" selon que le samouraï précédait ou suivait son seigneur dans la mort.

Minamoto no Tametomo aurait été le premier homme et samouraï à pratiquer le "seppuku" honorable, en prenant exemple sur les femmes chinoises : accusées d'avoir enfanté l'enfant d'un autre homme que leur époux, elles s'ouvraient le ventre de désespoir afin de prouver leur fidélité. Minamoto no Yorimasa est le premier du "seppuku" de qui on a une description détaillée : après sa défaite à la première bataille d'Uji en 1180, Yorimasa s'est retiré dans la salle du Phénix du temple du Byōdō-in, a écrit un poème au dos de son étendard, avant de prendre son poignard et de s'ouvrir l'abdomen. Cette façon de procéder a codifié le "seppuku".

La pratique du "seppuku" est indissociable du Bushido, le code d'honneur du guerrier, qui insiste sur sa finalité propre : la mort. Celle-ci ne doit en aucun cas trahir les valeurs morales qui sont celles du samouraï ; aussi la pratique du "seppuku" est-elle codifiée très précisément. L'acte du suicide honorable ne s'effectuait "grosso modo" qu'à quatre occasions :



Hormis dans le cadre du champ de bataille, le "seppuku" accompagna le raffinement du "bushidō" et des classes dirigeantes en étoffant le rituel qui lui est encore associé. Le "seppuku" possède son propre code, qui doit être respecté scrupuleusement, tant par celui qui commet l'acte que par les personnes assistant à celui-ci. En effet, le "seppuku" n'est absolument pas une pratique solitaire, tout du moins dans le cadre du "bushidō" ; si le public est restreint et choisi, il est par contre nécessaire. Il a valeur de témoin et d'assistant de la mort du samouraï.

Le samouraï, ayant revêtu un kimono blanc, très ajusté et serré par un obi afin que les viscères ne se répandent, s'agenouillait avec un petit tabouret sous les fesses face au public, sur un "tatami". Il disposait d'un sabre court ("wakizashi") ou d'un poignard ("tantō"), d'encre, d'un pinceau, de feuilles de papier de riz et d'une tasse de saké. Après avoir écrit et lu un "waka", enveloppant le sabre court d'une des feuilles de papier de riz, il s'ouvrait l'abdomen sur sa gauche, kimono ouvert. Cette partie du ventre représente la conscience dans la tradition bouddhiste. Il remontait alors une première fois, en diagonale ; puis une seconde entaille venait couper la première. Ce "Giri no jumonji", terriblement douloureux, était la plupart du temps interrompu par le "kaishakunin", un ami du samouraï, qui le décapitait au katana en prenant soin de trancher d'un premier coup jusqu'à la trachée afin que la tête tombe sur le torse puis il coupait délicatement d'un mouvement de coupe pour que la tête ne roule trop loin du corps qui tombait alors en avant. Chaque shogun avait un "kaishakunin" officiel pour les "tsumebara" : c'était un honneur tout particulier pour un samouraï. Lorsque le "kaishakunin" était un ami proche, la décapitation était rapide et occasionnait moins de souffrances, sinon l'attente du supplicié pouvait être en rapport avec son « crime ».

L'histoire militaire du Japon est marquée par de très nombreux "seppuku" ; mais dès lors que les "bushi" perdirent de leur influence, la pratique fut contrôlée (interdiction du "junshi"), puis interdite (par le gouvernement Tokugawa à la demande de Matsudaira Nobutsuna en 1663). Les cas épars de désobéissances furent accueillis comme des actes d'autant plus braves par la population japonaise.

Essentiellement pratiqué pendant la période Edo par les guerriers, puis par les militaires japonais jusqu'à la fin de la Seconde Guerre mondiale, le seppuku est plus rare et limité que son impact sur l'imaginaire collectif ou la culture japonaise. 

À la suite de l'échec d'un coup d'État mené par sa milice privée, le Tatenokai, l'écrivain et dramaturge Yukio Mishima, dénonçant le déshonneur du Japon, passe à l'acte en pratiquant un "seppuku" par éventration (suivi d'une décapitation), dans la matinée du 25 novembre 1970. Son compagnon Masakatsu Morita s'éventre à sa suite. Yukio Mishima, devenu ultranationaliste en 1967, exaltait les valeurs traditionnelles du Japon et le défi du "bunburyōdō", la « double voie » qui unifie Lettres et Arts martiaux, l'art et l'action, l'éthique et l'esthétique. Cet acte héroïco-tragique, minutieusement mis en scène, marqua profondément les esprits, stupéfiés : par la notoriété de l'auteur, par ses idées alors tabou, mais aussi parce qu'aucun "seppuku" n'avait été pratiqué au Japon depuis l'immédiat après-guerre et que l'épisode fut retransmis à la télévision.

C'est le dernier cas célèbre de seppuku, mais il reste très particulier et se distingue par sa mise en scène et son caractère anachronique. Si la pratique du suicide rituel sous la forme du seppuku a quasiment disparu, il a profondément marqué la société japonaise contemporaine. Le taux de suicide au Japon se distingue par son ampleur : suicides pour l'année 2009, taux annuel constant pour la décennie, soit 26 suicides pour habitants (en comparaison, 9 pour au Royaume-Uni). Près d'un quart de ces suicides sont classés comme "inseki-jisatsu", ou suicide visant à effacer une faute ou une responsabilité assumée. Ils concernent des directeurs d'entreprises, des hommes politiques soupçonnés de corruption ou visés par un scandale, mais aussi les chefs d'équipes dans une entreprise ou les chefs de famille. 

Guillaume Carré, directeur du Centre de recherches Japon à l’EHESS, remarque que Même s'ils n'ont pas recours au suicide, les hommes politiques japonais tendent à démissionner lorsqu'ils doivent faire face à une faute, une accusation grave ou une menace de condamnation. Ils tendent également moins à faire appel que dans les pays occidentaux, où l'appel est souvent suspensif de la peine.





</doc>
<doc id="14383" url="https://fr.wikipedia.org/wiki?curid=14383" title="Alexandre Chevtchenko (peintre)">
Alexandre Chevtchenko (peintre)

Olexander Vasyliovytch Chevtchenko (en ); Alexandre Vassilievitch Chevtchenko (en ) ; à Kharkiv, Ukraine - à Moscou) est un artiste-peintre et sculpteur ukrainien.

De 1890 à 1898, il prend des cours particuliers de dessin à Kharkiv le peintre Dmitry Bezperchy et travaille dans un atelier de fabrication de décors de théâtre. Il s'installe à Moscou, entre à l'École d'esthétique industrielle Stroganov dont il est diplômé en 1907. La même année, il est admis à l'École de peinture, de sculpture et d'architecture, où il étudie avec Valentin Serov et K. Korovine. De 1905 à 1906, il fréquente l'atelier de E. Carrière et l'Académie Julian chez Étienne Dinet et Jean-Paul Laurens, à Paris. Fait la connaissance de Michel Larionov et de ses disciples. Sous son influence, Chevtchenko travaille dans un style néo-primitiviste, puis rayonniste. Il participe à l'organisation de ses expositions et y prend part. Il est renvoyé de l'école en 1909.

À partir de 1911, il participe aux expositions de l'Union de la jeunesse à Saint-Pétersbourg et prend part au Premier Salon de Moscou. En 1912, il participe à l'exposition la Queue d'âne (avec Natalia Gontcharova, Sergueï Bobrov, Kasimir Malevitch, Arthur Fonvizine et Vladimir Tatline), organisé par Larionov à Moscou. En 1913, il publie des œuvres théoriques : "Le Néo-primitivisme, sa théorie, ses possibilités, ses réalisations" et "Les Principes du cubisme et autres tendances dans l'art mondial de tous les temps et de tous les peuples".

Chevtchenko est collectionneur de dessins d'enfants. Il défend la spontanéité de l'art folklorique russe (du loubok et de l'art de l'enseigne peinte) et revendique les racines orientales de celui-ci. Dans son traité sur le néo-primitivisme, il écrit : « La Russie et l'Orient sont inséparablement liés depuis l'époque des invasions tatares ; l'esprit tatar, l'esprit oriental se sont enracinés dans notre vie à tel point qu'il est parfois difficile de discerner où se trouve la limite de notre nationalité et où commence l'influence orientale ». Il prend part à l'exposition la Cible en 1913, où sont présentées ses œuvres rayonnistes. Parallèlement, il participe aux expositions organisées par Mir Iskousstva (le Monde de l'art) (jusqu'en 1921). En 1913-14, il peint des œuvres cubo-futuristes. Il est convoqué par l'armée en 1914, mais ne sera mobilisé qu'en 1917. Il participe à l'exposition n°4, futuristes, rayonnistes, primitivistes en 1914.

Il rejoint la section Arts plastique (Izo) créée après la Révolution de Février-Octobre par le Commissariat populaire à l'instruction en 1917, au collège du Narkompros à Moscou, dirigé par Tatline avec Ilia Machkov, Pavel Kouznetsov, Kasimir Malevitch, Joltovski, Robert Falk, Kandinsky, Koroliov, Konionkov, Morgounov, Olga Rozanova, et Nadejda Oudaltsova. Il dirige l'atelier Histoire de l'art contemporain avec Axionov. Entre 1918 et 1920, il est membre de la commission de conservation des valeurs artistiques et historiques. Chevtchenko enseigne aux ateliers libres d'État, Vkhoutemas et Vkhouteïne. Il travaille à l'académie d'État des sciences artistiques et participe à la création du musée de la Culture artistique à Moscou.

Après la guerre, il crée son propre langage pictural. En 1919, il participe à la Exposition d'État et édite à cette occasion son manifeste "Dynamisme coloré et primitivisme tectonique" qui appelle à un retour à la peinture de chevalet, et à ses valeurs « éternelles », et en 1920, à la Exposition d'État à Moscou. Il rejoint l'Institut de culture artistique (Inkhouk) créé en mai 1920 suite à l'Izo, dirigé par Kandinsky avec Lioubov Popova, Alexandre Rodtchenko, Varvara Stepanova,Robert Falk, et Koroliov. Il travaille dans le groupe Peinture-Sculpture-Architecture fondé en mai 1919 et dirigé par Koroliov avec les architectes Krinski et Ladovski, et le peintre Rodtchenko. En 1922, il participe à la première exposition d'art russe à Berlin et à deux autres expositions du groupe Makovets, et en 1927, à l'exposition Toutes tendances à Petrograd.


</doc>
<doc id="14385" url="https://fr.wikipedia.org/wiki?curid=14385" title="Fission nucléaire">
Fission nucléaire

La fission nucléaire est le phénomène par lequel un noyau atomique lourd (c'est-à-dire, formé d'un grand nombre de nucléons comme l'uranium, le plutonium) est scindé en deux ou quelques nucléides plus légers. 

Cette réaction nucléaire s'accompagne de l'émission de neutrons (en général deux ou trois) et d'un dégagement d'énergie très important (≈ par atome fissionné, à comparer aux énergies des réactions chimiques qui sont de l'ordre de l'eV par atome ou molécule réagissant).

Le phénomène de fission nucléaire induite est décrit dès le par deux chimistes du "Kaiser-Wilhelm-Institut für Chemie" de Berlin : Otto Hahn et son jeune assistant Fritz Strassmann. La physicienne autrichienne Lise Meitner, participe aussi à cette découverte. Toutefois, étant juive, elle fuit l'Allemagne en juillet 1938 pour se réfugier en Suède. Bien qu'ayant continué à participer aux recherches par correspondance (c'est elle qui a compris les implications des résultats de l'expérience déterminante et calculé l'énergie produite), elle n'est pas citée dans la publication.

Les résultats du bombardement de noyaux d'uranium par des neutrons sont alors déjà considérés comme dignes d'intérêt et tout à fait intrigants. Les principes théoriques avaient été étudiés par Enrico Fermi et ses collègues dès 1934, ils ne furent donc correctement interprétés que plusieurs années plus tard.

Le 16 janvier 1939, Niels Bohr arrive aux États-Unis pour passer plusieurs mois à l’Université de Princeton, où il se hâte de discuter de certains problèmes théoriques avec Albert Einstein. Juste avant son départ du Danemark, deux de ses collègues, Lise Meitner et Otto Frisch, lui font part de leur hypothèse selon laquelle l’absorption d’un neutron par un noyau d’uranium provoque parfois la scission de celui-ci en deux parties approximativement égales, ainsi que la libération d’une énorme quantité d’énergie : ils nomment ce phénomène « fission nucléaire ». Cette hypothèse est fondée sur l’importante découverte de Hahn et Strassmann (publiée dans "Naturwissenschaften" au début du mois de janvier 1939) : à savoir, que le bombardement de l'uranium par des neutrons produit un isotope du baryum.

Bohr promet de garder secrète l’interprétation de Meitner et Frisch jusqu’à ce qu’ils publient un article afin de leur assurer la paternité de la découverte et de l'interprétation, mais à bord du bateau en route pour les États-Unis, il en parle avec Léon Rosenfeld, en oubliant de lui demander de respecter le secret.

Dès son arrivée, Rosenfeld en parle à tous les physiciens de Princeton. La nouvelle se répand ainsi à d'autres physiciens, tel Enrico Fermi de l’Université Columbia. Les conversations entre Fermi, John R. Dunning et G. B. Pegram débouchent, à Columbia, sur la recherche des rayonnements ionisants produits par les fragments du noyau d’uranium obtenus après cette fameuse « fission ».

Le 26 janvier 1939, se tient une conférence de physique théorique à Washington, D.C., organisée conjointement par l’Université George Washington et la Carnegie Institution de Washington. Fermi quitte New York pour participer à cette conférence avant le lancement des expériences de fission à Columbia. Bohr et Fermi discutent du problème de la fission et Fermi mentionne en particulier la possibilité que des neutrons puissent être émis durant le processus. Bien que ce ne soit qu’une hypothèse, ses conséquences c’est-à-dire la possibilité d’une réaction en chaîne paraissent évidentes. De nombreux articles à sensation sont publiés dans la presse à ce sujet. Avant la fin de la conférence à Washington, plusieurs autres expériences sont lancées pour confirmer la thèse de la fission du noyau.

Le 15 février 1939, dans la "Physical Review" quatre laboratoires publient leurs résultats (Université Columbia, Carnegie Institution de Washington, Université Johns-Hopkins, Université de Californie). Un mois plus tôt, Bohr savait que des expériences similaires avaient déjà été entreprises au laboratoire de Copenhague (Danemark) (Lettre de Frisch à la revue "Nature" datée du 16 janvier 1939 et parue dans le numéro du 18 février). Frédéric Joliot à Paris publie aussi ses premiers résultats dans les "Comptes Rendus" du 30 janvier 1939. À partir de ce moment-là, la publication d’articles sur la fission devient régulière et intense au point que, dans la "Review of Modern Physics" du 6 décembre 1939, L. A. Turner de Princeton en dénombre presque une centaine !

Il existe deux types de fissions : la fission spontanée et la fission induite. La fission neutronique est une fission induite qui peut être soit thermique (où la particule induite est un neutron thermique ou lent) soit rapide (où la particule induite est un neutron rapide). Les noyaux atomiques pouvant fissionner sont dits « fissiles » (s'ils peuvent subir une fission avec des neutrons rapides ou lents) ou « fissibles » (s'ils peuvent subir une fission rapide).

La découverte de la fission de l'uranium 235 peut être décrite par l'intermédiaire du modèle de la goutte liquide. Un noyau est constitué de nucléons : les protons et les neutrons. Ces nucléons, outre leurs masses respectives, apportent une énergie de liaison au noyau donnée par la formule de Weizsäcker ; plus l'énergie de liaison est importante plus le noyau est stable.

Donc d'après le modèle de la goutte liquide, la fission est possible si la variation de masse entre deux noyaux formula_1 issus du noyau formula_2 est positive ou nulle. Cette condition est vraie si formula_3, ce qui correspond à la région du zirconium. Au-delà du rapport formula_4, le noyau est instable et fissionne spontanément.

Actuellement, la fission induite par des projectiles de faible énergie (0 à ) a été observée pour quelques actinides, l'uranium 233, 235 et 238 et le plutonium 239 et 241.
Le phénomène de la fission spontanée est découvert en 1940 par G. N. Flerov et K. A. Petrzak en travaillant sur des noyaux d'uranium 238.

On parle de fission nucléaire spontanée lorsque le noyau se désintègre en plusieurs fragments sans absorption préalable d'un corpuscule (particule subatomique). Ce type de fission n'est possible que pour les noyaux extrêmement lourds, car l'énergie de liaison par nucléon est alors plus petite que pour les noyaux moyennement lourds nouvellement formés.

L'uranium 235 (dans une très faible proportion cependant), les plutoniums 240 et 244 et surtout le californium 254 sont par exemple des noyaux spontanément fissiles.

La fission induite a lieu lorsqu'un noyau lourd capture une autre particule (généralement un neutron) et que le noyau ainsi composé se désintègre alors en plusieurs fragments.

La fission induite de l'uranium 235 par absorption d'un neutron est la réaction de ce type la plus connue. Elle est du type :

formula_5

"X" et "Y" étant deux noyaux moyennement lourds et généralement radioactifs : on les appelle des produits de fission.

Ainsi la fission induite d'un noyau d'uranium 235 peut donner deux produits de fission, le krypton et le baryum, accompagnés de trois neutrons :

formula_6

Les fissions induites les plus couramment utilisées sont les fissions de l'uranium 235, de l'uranium 238 et du plutonium 239.

Sous l’effet d’une collision avec un neutron, le noyau de certains gros atomes, dits fissiles, a la propriété de se casser en deux. La matière fissile qui constitue le cœur des réacteurs est en général de l’uranium ou du plutonium. En absorbant un neutron, un noyau d’atome U se transforme ainsi en U, un isotope de l’uranium, dans un état excité de 6,2 Méga-électrons-volts (MeV, avec = 1,6.10 joules). Il se comporte ainsi un peu comme une goutte d'eau.

formula_7

ou bien le strontium 94 et le xénon 140 :

formula_8

Une importante quantité d’énergie est libérée lors de cette fission, de l’ordre de 202,8 MeV pour un noyau d’uranium 235. La part principale de cette énergie est constituée par l'énergie cinétique des deux atomes créés. Elle s'accompagne en général de l'émission d'un ou de plusieurs neutrons rapides (généralement 2 ou 3) qui ont une énergie cinétique moyenne de 2 MeV. Ceux-ci réagissent avec les noyaux qu'ils rencontrent et sont soit diffusés, c'est-à-dire renvoyés dans une direction différente, soit absorbés. Tant que la probabilité d'absorption reste faible, les neutrons se conservent pratiquement en nombre, mais leur énergie décroît peu à peu à chaque diffusion. Les noyaux sont d’autant plus efficaces pour ralentir les neutrons que leur masse est plus faible, plus proche de celle du neutron. C’est en particulier le cas de l'eau ordinaire (qui contient de l'hydrogène, le meilleur des modérateurs/ralentisseurs de neutrons), l'eau lourde (eau dans laquelle n'a été conservé, grâce à une séparation isotopique, que l'isotope lourd de l'hydrogène, le deutérium), le béryllium ou son oxyde la glucine, et enfin le graphite (carbone pur). Avec un modérateur efficace, les neutrons se ralentissent jusqu'à ce que leur énergie cinétique soit à peu près égale à l'énergie d'agitation thermique du milieu diffusant (0,025 eV à la température de 300 K). La plupart des fissions se produisent alors à cette énergie et le réacteur est dit à neutrons thermiques. Dans le cas contraire, le réacteur est dit à neutrons rapides.

La raison principale pour laquelle on cherche dans un réacteur thermique à ralentir les neutrons issus de fission pour les amener au niveau d'énergie (de vitesse) thermique est liée au fait que la probabilité qu'une rencontre d'un neutron thermalisé avec un atome fissile donne lieu à fission de l'atome rencontré est sensiblement 250 fois plus élevée que dans le cas où le neutron possède une énergie (une vitesse) élevée voisine de son énergie initiale.
Certaines captures de neutrons ne donnent pas lieu à la fission du noyau et l'importance relative de ces captures parasites doit être strictement limitée pour qu'une réaction en chaîne, divergente ou stationnaire, soit réalisée. Pour entretenir une réaction en chaîne, l'un des n neutrons produits à chaque fission devra à son tour être absorbé dans le combustible, les n - 1 qui restent pouvant être perdus par capture dans les autres constituants du milieu, ou par fuite en dehors du dispositif. n dépend de l'énergie des neutrons. Dans le cas des neutrons thermiques, il est égal à 2,08 pour U et Pu, à 1,8 pour l’uranium enrichi, mais à 1,36 seulement pour l'uranium naturel. Le contrôle de la réaction en chaîne est assuré par l'insertion de barres de commandes contenant des matériaux très absorbants des neutrons, généralement désignés : « absorbants mobiles de contrôle de la réactivité du cœur ». Les matériaux absorbants utilisés sont généralement le bore, le cadmium, l'argent, l'indium ainsi que d'autres non mentionnés ici.

La photofission est un type de fission nucléaire induite qui se produit lorsqu'un noyau absorbe un rayonnement gamma. Ce processus peut être utilisé pour la synthèse d'isotopes utilisés en médecine nucléaire.

Les rayons gamma de quelques dizaines de MeV peuvent induire la fission de noyaux fissiles comme les actinides uranium, plutonium et neptunium. Des expériences ont été réalisées qui montrent que la section efficace de photofission varie peu jusqu'à des énergies de photons de l'ordre du GeV.

La photofission assistée par laser a été démontrée en 2000 et elle a été proposée comme moyen de se débarrasser par transmutation des déchets nucléaires.

La photo-désintégration ou photo-transmutation est un phénomène similaire à la photofission dans lequel des photons gamma énergétiques interagissant avec des noyaux peuvent les porter dans un état excité suivit immédiatement d'une désintégration avec émission de particules subatomiques. Il a été démontré expérimentalement, qu'un laser femtoseconde délivrant des impulsions lumineuses ultracourtes (~100 fs) et ultra-intenses (~10 W/cm pouvaient produire des impulsions intenses de rayonnement gamma d'énergie comprise entre 1 et 10 MeV. De telles impulsions sont parfaitement capables de produire des désintégrations.

Lors de la fission, des neutrons rapides sont tout de suite (10 s) émis, ils sont dits neutrons instantanés (anciennement nommés neutrons prompts). Puis, après l'émission de ces neutrons instantanés, les produits de fission commencent leur décroissance radioactive. Ces décroissances radioactives vont engendrer la libération de neutrons rapides avec une latence de 13 secondes en moyenne; ces neutrons libérés juste après des désintégrations β sont appelés neutrons retardés.

La probabilité de fission d'un noyau fissile dépend de l'énergie cinétique du neutron incident ; pour des noyaux fissiles thermiquement comme l'formula_9 et le formula_10 cette probabilité augmente quand l'énergie cinétique du neutron incident diminue d'où la nécessité de modérer un réacteur nucléaire à neutrons thermiques. Ce phénomène de ralentissement des neutrons rapides issus des fissions (instantanés et retardés) s'appelle la thermalisation des neutrons, il consiste en un ralentissement par chocs élastiques successifs des neutrons avec un noyau léger (H, D, C, Be). Le béryllium métallique et le graphite sont des matériaux modérateurs solides alors que l'hydrogène et le deutérium sont principalement utilisés comme modérateur sous forme d'eau et d'eau lourde.

Le tableau suivant indique le nombre de neutrons libérés en moyenne "et par fission" par neutron thermique en fonction du noyau considéré :

On remarquera dans ce tableau que les isotopes de U et Pu fissibles par des neutrons thermiques ont tous des masses atomiques impaires : les noyaux fissibles thermiquement sont dits "Pair-Impair", même s'ils gagnent un neutron pour se fissionner.

La distribution en masse des produits de fission suit une courbe « en bosses de chameau ». On parle aussi de courbe bimodale : elle possède deux maximums. Plus de cent nucléides différents peuvent être libérés lors de la fission de l'uranium 235. Toutefois, tous ces nucléides possèdent un numéro atomique entre Z=33 et Z=59. La fission crée des noyaux de nombre de masse (nombre de nucléons) autour de A=95 (brome, krypton, zirconium) pour l'un des fragments et autour de A=139 (iode, xénon, baryum) pour l'autre.

Une répartition symétrique (A=116, 117 ou 118 pour l'uranium 235) des masses des produits de fission (0,1 % des fissions) ou une fission en trois fragments (fission ternaire, 0,005 % des fissions) sont très rares.

Chaque noyau d’uranium 235 qui subit la fission libère de l’énergie et donc de la chaleur.

L'origine de cette énergie trouve son explication dans le bilan des énergies entre le noyau initial et les deux noyaux produits : les protons d'un même noyau se repoussent vigoureusement par leurs charges électrostatiques, et ceci d'autant plus que leur nombre est élevé (énergie coulombienne), l’énergie correspondante croissant plus vite que proportionnellement au nombre de protons. La fission se traduit donc par un dégagement d'énergie, qui est principalement transmise dans les produits de fission et les neutrons sous forme d'énergie cinétique, qui se transforme rapidement en chaleur.

La chaleur produite lors de la fission de noyaux fissiles d'uranium 235 ou de plutonium 239 peut alors être utilisée pour transformer de l'eau en vapeur, permettant ainsi d'actionner une turbine pouvant produire directement de l'énergie mécanique puis par l'intermédiaire d'un alternateur, de l'électricité. C'est cette technique qui est à l'œuvre dans les réacteurs nucléaires destinés à produire de l'électricité.

Lors d'une réaction de fission nucléaire induite, l'absorption d'un neutron par un noyau fissile permet la libération de plusieurs neutrons, et chaque neutron émis peut à son tour casser un autre noyau fissile. La réaction se poursuit ainsi d'elle-même : c'est la réaction en chaîne. Cette réaction en chaîne n'a lieu que si un neutron au moins émis lors d'une fission est apte à provoquer une nouvelle fission.

Le tableau suivant indique le nombre de neutrons libérés en moyenne par neutron (thermique) capturé en fonction du noyau considéré:
Cette table diffère de la précédente par le fait qu'elle se rapporte à tous les neutrons entrés dans le noyau fissile, et pas seulement à ceux qui donnent lieu à une fission.

On voit ici pourquoi l'uranium naturel n'est pas utilisé directement dans les réacteurs : l'uranium 238 qu’il contient en grande proportion consomme trop de neutrons qui ne donnent pas lieu à une fission. Pour l'utiliser, il faut l’enrichir en uranium 235.

Dans un milieu réactif, la vitesse à laquelle se déroule cette réaction en chaîne est mesurée par le facteur de multiplication.

Les principales sections efficaces intervenants dans la modélisation de la fission en réacteur sont données ci-dessous.

Un neutron qui entre en collision avec un noyau fissile peut former avec celui-ci un noyau composé excité, ou être simplement absorbé (capture neutronique). Pour l'uranium 235, la proportion de neutrons capturés est d'environ 16 % pour des neutrons thermiques (ou neutrons lents) ; 9,1 % pour des neutrons rapides.

Dans le cas de la fission induite, la durée de vie moyenne du noyau composé est de l'ordre de 10s. Le noyau se fissionne, et les fragments se séparent à vitesse élevée : au bout de 10 s, ces fragments, distants de 10 m, émettent, nous l'avons vu, des neutrons.

Suite aux désexcitations γ, des photons γ sont émis après 10 s, alors que les fragments ont franchi 10 m. Les fragments s'arrêtent au bout de 10 s environ, après avoir franchi une distance de 50 µm (ces valeurs sont données pour un matériau de densité 1, tel que l'eau ordinaire).

L'énergie cinétique des fragments et des particules émises à la suite d'une fission finit par se transformer en énergie thermique, par l'effet des collisions et des interactions avec les atomes de la matière traversée, sauf pour ce qui concerne les neutrinos, inévitablement émis dans les désintégrations β, et qui s’échappent toujours du milieu (ils peuvent traverser la Terre sans interagir).

Le tableau suivant indique comment se répartit l'énergie libérée à la suite de la fission d'un atome d'uranium 235, induite par un neutron thermique (ces données sont des moyennes calculées sur un grand nombre de fissions).

L'énergie totale libérée lors de la fission ressort égale à 202,8 MeV dont 9,6 MeV n'est pas récupérable puisque communiquée aux neutrinos émis. 

En pratique l'énergie récupérable en réacteur de puissance, compte tenu :

Dans le cas d'une explosion nucléaire seules les énergies libérées à court terme sont à considérer pour évaluer la puissance.

Les vitesses mises en jeu ne sont pas relativistes ; les lois de la mécanique classique sont largement applicables aux particules massives émises lors du phénomène de fission.

Énergie et vitesse moyennes

Avec émis en moyenne lors d'une fission de l'uranium 235 pour une énergie de donnée dans le tableau de décomposition de l'énergie de fission l'énergie cinétique moyenne du neutron de fission ressort égale à 1,943 MeV = 3,11354×10 J

Cette énergie est cinétique, selon la relation classique : formula_11. La masse du neutron telle que donnée par le CODATA est égale à : 1,674927351×10 kg. 

On en déduit : vitesse moyenne des neutrons de fission = 

Distribution en énergie

La distribution en énergie des neutrons de fission est correctement représentée par la formule semi-empirique :

formula_12

avec :

Pour 10 MeV, N(E) ressort égal à 0,33 %.

Lors de la fission deux fragments de tailles inégales sont formés.

Fragment léger

Fragment lourd

L'énergie cinétique du fragment léger est plus élevée que celle du fragment lourd

Un calcul préliminaire grossier conduit aux résultats suivants :


En conclusion, les vitesses trouvées ne sont pas relativistes ; on peut dans une large mesure appliquer les lois de la mécanique classique aux neutrons et fragments de fission.

La majorité des fissions sont binaires générant un petit et un gros fragment :

Lors de la fission la quantité de mouvement totale initialement nulle est conservée. Le neutron incident thermalisé capturé avant la fission a une vitesse faible, en outre on peut admettre que les 2,47 neutrons émis en moyenne par fission le sont dans toutes les directions de l'espace de façon quasiment égale. Dès lors la quantité de mouvement totale des deux fragments doit être égale à zéro. <br><br>

On a donc formula_23, d'où formula_24.

Suivant le tableau de décomposition de l'énergie donné ci-dessus, l'énergie cinétique totale communiquée aux deux fragments de fission est égale à :


Autre formulation :

La vitesse mais aussi l'énergie cinétique du fragment léger (v = 14 094 km/s resp. e = 98,6 MeV) sont plus élevées que celles du fragment lourd (V = 9 665 km/s resp. E = 67,6 MeV).

Une mole d'uranium 235 pèse 235,0439299 grammes et contient N (Nombre d'Avogadro) atomes. La fission de chaque atome produit environ 193 MeV d'énergie récupérable. Donc en supposant que l'on fissionne tous les noyaux d'uranium dans un gramme d'uranium 235 - ce qui est technologiquement impossible dans l'état actuel des connaissances - l'énergie produite serait alors égale à :

1 Mégawatt.jour ⇔ 1,09 gramme d'uranium 235 fissionné

C'est-à-dire tous les atomes d'uranium 235 présents dans (1,09055 / 0,007202) = 151,42 grammes d'uranium naturel. Or :
Donc la fission de tous les atomes d'uranium 235 présents dans 1 g d'uranium naturel peut produire .

Ces résultats restent exact au avec les autres gros atomes fissiles présents ou formés dans les réacteurs de puissance tel que le plutonium 239 mis en œuvre notamment par exemple dans le combustible MOX. Ils permettent d'évaluer avec une bonne précision la consommation de matière fissile (ou fertile) dans tous les réacteurs de puissance (i. e. la masse des gros atomes fissionnés; i.e. les actinides fissionnés) et donc d'apprécier la quantité de produits de fission formés.

La fission de la totalité des atomes d'uranium 235 fissiles contenus dans une tonne d’uranium naturel, qui contient en masse 0,7202 % d’U, donne 5,7059.10 joules (= 570 600 GJ (gigajoules)) soit plus de plus d’énergie que la combustion d'une tonne d’équivalent pétrole qui dissipe 41,86 GJ (gigajoules). Toutefois étant donné que les procédés actuels ne permettent pas la fission intégrale de l'uranium 235 contenu dans l'uranium naturel on peut retenir l'ordre de grandeur de 10 000 fois plus d'énergie récupérable par tonne d'uranium naturel que par tonne d'équivalent pétrole. Cette estimation ne tient pas compte de la mise en œuvre des réacteurs rapides qui permettent de fissionner l'intégralité de l'uranium naturel extrait du sous-sol. Dans cette hypothèse la quantité d'énergie théoriquement récupérable d'une tonne d'uranium naturel se trouverait sensiblement multipliée par 1/0,7202 % soit 138,9 et de façon plus réaliste compte tenu des pertes qu'il y aurait nécessairement par un facteur 100.

Il ne suffit pas que le facteur de multiplication des neutrons soit plus grand que 1 pour que la réaction en chaîne s'entretienne : d'une part, les neutrons sont instables et peuvent se désintégrer, mais ceci joue peu, car leur temps de vie moyen est de près d'un quart d'heure, mais surtout, ils peuvent sortir du milieu où l'on essaie de faire une réaction en chaîne. Il faut qu'ils aient une collision "avant" de sortir, sinon ils ne participent plus à la réaction en chaîne. L’épaisseur moyenne du milieu fissile doit donc être assez grande pour assurer une probabilité suffisante pour les neutrons de rencontrer un noyau fissile. Ceci amène à la notion de "masse critique" de l'élément fissile, qui est une masse en dessous de laquelle on ne peut plus garder suffisamment de neutrons, quelle que soit la forme de la charge fissile, pour maintenir la réaction. Ceci explique pourquoi l'on ne peut pas avoir de mini-réacteurs nucléaires.




</doc>
<doc id="14386" url="https://fr.wikipedia.org/wiki?curid=14386" title="Corvus">
Corvus

Corvus est un genre d'oiseau qui comprend une cinquantaine d'espèces connues sous leur nom vernaculaire de corbeau, corneille, freux, choucas, etc. Le terme « corbeau » est usuellement utilisé pour désigner les espèces du genre lorsqu'on ne sait pas les identifier précisément.

Selon :




</doc>
<doc id="14389" url="https://fr.wikipedia.org/wiki?curid=14389" title="Afrique du Nord">
Afrique du Nord

Afrique du Nord est un terme collectif pour un groupe de pays méditerranéens situés dans la région la plus septentrionale du continent africain. Cette expression n'a pas de définition unique acceptée. Elle est parfois définie comme s'étendant des rives de l'Atlantique, du Maroc à l'ouest, au canal de Suez et à la mer Rouge à l'est. La définition la plus communément acceptée comprend d'Est en Ouest : l'Égypte, la Libye, la Tunisie, l'Algérie, et le Maroc. Le bureau du recensement des États-Unis définit l'Afrique du Nord comme étant l'Algérie, la Libye, l'Égypte, le Maroc et la Tunisie.

Les pays d'Afrique du Nord partagent une identité ethnique, culturelle et linguistique commune propre à cette région. L'Afrique du Nord-Ouest a été habitée par les Berbères depuis le début de l'histoire, tandis que la partie orientale de l'Afrique du Nord fut le foyer des Égyptiens anciens, lesquels entretenaient d'étroites relations avec les Berbères durant l'Antiquité. Après la conquête musulmane au , la région a subi un processus d'arabisation et d'islamisation qui a depuis redéfini son paysage culturel.

La distinction entre l'Afrique du Nord et l'Afrique subsaharienne est historiquement et écologiquement significative en raison de la barrière efficace créée par le désert du Sahara pour une grande partie de l'histoire moderne. À partir de 3500 av. J.-C., à la suite de la désertification abrupte du Sahara due aux changements graduels de l'orbite terrestre, cette barrière a séparé culturellement le Nord du reste du continent. Comme les civilisations maritimes des Phéniciens, des Grecs, des Romains, des Musulmans et d'autres facilitaient la communication et la migration à travers la mer Méditerranée, les cultures nord-africaines étaient plus étroitement liées à l'Asie du Sud-Ouest et à l'Europe qu'à l'Afrique subsaharienne. L'influence islamique dans la région est également importante, et l'Afrique du Nord est une part majeure du monde musulman.

Un nombre croissant de chercheurs ont postulé que l'Afrique du Nord, plutôt que l'Afrique de l'Est, servait de point de sortie pour les humains modernes qui ont d'abord quitté le continent lors de la migration hors d'Afrique.

L'Afrique du Nord est aussi appelée Afrique blanche. Ce terme s'oppose à celui d’« Afrique noire », désignant l'Afrique subsaharienne. Friedrich Hegel l'appelait également « Afrique européenne » alors qu'Élisée Reclus voyait dans le Nord de l'Afrique un appendice de l'arc latin.

L'expression Afrique blanche faisait référence soit, géographiquement, au nord du Sahara soit, ethniquement, aux minorités « blanches » de l’Afrique « noire » : Afrikaans au Sud, Touareg du Sahel.
Les montagnes de l'Atlas s'étendent sur une grande partie du Maroc, le nord de l'Algérie et la Tunisie, font partie du système de montagnes de pli qui traverse également une grande partie de l'Europe du Sud. Elles reculent vers le sud et l'est, devenant un paysage de steppe avant de rencontrer le désert du Sahara, qui couvre plus de 75% de la région. Les sédiments du Sahara recouvrent un ancien plateau de roche cristalline, dont certains ont plus de quatre milliards d'années.

Au sud de l'Atlas se trouve l'étendue aride et désertique du désert du Sahara, le plus grand désert de sable au monde. Par endroits, le désert est coupé par des cours d'eau irréguliers appelés wadis (ou l'oued) qui ne s'écoulent qu'après les précipitations mais sont généralement secs. Les principaux reliefs du Sahara comprennent des ergs, de grandes mers de sable qui forment parfois d'immenses dunes; la hammada, un plateau rocailleux plat sans sol ni sable; et le reg, une surface plate constituée gravier ou de petites pierres. Le Sahara couvre la partie sud du Maroc, de l'Algérie et de la Tunisie, et la majeure partie de la Libye. Seules deux régions de la Libye sont en dehors du désert : la Tripolitaine au nord-ouest et la Cyrénaïque au nord-est. La plus grande partie de l'Égypte est également désertique, à l'exception du Nil et des terres irriguées le long de ses rives. La vallée du Nil forme un fil fertile étroit qui s'étend sur toute la longueur du pays.

Les vallées abritées dans les montagnes de l'Atlas, la vallée et le delta du Nil, et la mer méditerranéenne sont les principales sources de terres agricoles fertiles. Une grande variété de cultures précieuses, y compris les céréales, le riz et le coton, et des bois tels que le cèdre et le liège, sont cultivés. Les cultures méditerranéennes typiques, telles que les olives, les figues, les dattes et les agrumes, prospèrent également dans ces régions. La vallée du Nil est particulièrement fertile, et la plupart de la population en Égypte vit près de la rivière. Ailleurs, l'irrigation est essentielle pour améliorer les rendements des cultures sur les marges du désert.

Le climat d'Afrique du Nord est influencé par la mer Méditerranée au nord, l'océan Atlantique à l'ouest, le Sahara au centre sud et dans une moindre mesure le Sahel à l'extrême sud de la zone. Avec ces influences climatiques, on peut donc citer les climats généraux d'Afrique du Nord :

Les vestiges de la présence humaine en Afrique du Nord remontent à , âge attribué aux restes de l’Atlanthrope découverts dans les sédiments du lac préhistorique Ternifine (Tighennif près de Mascara) Algérie. L’Atlanthrope, contemporain du Sinanthrope et du Pithécanthrope de Java, dont les ossements ont été retrouvés au milieu des outils de pierre taillée qu’il fabriquait, y a séjourné.

Les Berbères subsistent dans un immense territoire qui commence à l’ouest de l’Égypte. Actuellement des populations parlant le berbère habitent dans une douzaine de pays d'Afrique, de la Méditerranée au sud du Niger, de l’Atlantique au voisinage du Nil. Les autochtones de l'Afrique du Nord sont les peuples berbères et les Égyptiens. Les peuples berbères sont des peuples parlant tous des langues similaires et ayant peuplé l'Afrique du Nord depuis l'Ouest de la vallée du Nil aux îles Canaries bien avant la conquête romaine.

En 670, arrivée des Arabes sous le commandement d'Oqba Ibn Nafi. Fondation de Kairouan, première implantation de l'islam dans la région.

L'arrivée d'Idris, arrière-petit-fils d’Hassan, fils d'Ali ibn Abi Talib et Fatima, la fille de Mahomet. Il se fait reconnaître comme imam par la tribu berbère des Awraba qui l'avaient accueilli et par les quelques Arabes qui l'avaient accompagné dans son exil.

Au , début des invasions hilaliennes.

La Berbérie, du mot « berbère », terme correspondant au territoire habité par les populations berbères, autochtones d'Afrique du Nord. Donnant l'équivalent "Tamazgha" en berbère. De même, la Libye antique désignait le territoire des Libyens, ancêtre des Berbères.

Le Maghreb (de l'arabe signifiant « Le Couchant »), désigne l'Afrique du Nord, et couvre, si l'on parle de Petit Maghreb, le Maroc, l'Algérie et la Tunisie. Le Grand Maghreb compte, en plus de ces trois pays, la Libye et la Mauritanie.

Dans l'Antiquité, "Africa" désignait la région de Carthage, qui correspond à l'actuelle Tunisie, une partie du Nord-Est de l'Algérie et à la Tripolitaine. L’"Africa" a constitué plusieurs provinces de l'Empire romain. Après la conquête musulmane, le nom s'est perpétué sous la forme arabisée d"'Ifriqiya", pour ensuite servir à nommer l'ensemble du continent.

Depuis la fin des années 1980 et surtout depuis le début du , les généticiens ont travaillé sur le chromosome Y (transmis du père aux fils) et sur l'ADN mitochondrial (transmis de la mère aux enfants) qui ont la particularité d'être transmis intégralement (hors mutation). Il est donc possible de remonter aux ancêtres communs des différentes populations du globe et en particulier de ceux des populations d'Afrique du Nord. Par ailleurs, de très récentes études ont été réalisées sur un très grand nombre de gènes des chromosomes homologues ou autosomes (tous les chromosomes à l'exclusion des chromosomes X et Y).



</doc>
<doc id="14393" url="https://fr.wikipedia.org/wiki?curid=14393" title="Gottfried Wilhelm Leibniz">
Gottfried Wilhelm Leibniz

Gottfried Wilhelm Leibniz (prononcer <nowiki>[</nowiki><nowiki>]</nowiki>), né à Leipzig le et mort à Hanovre le , est un philosophe, scientifique, mathématicien, logicien, diplomate, juriste, bibliothécaire et philologue allemand qui a surtout écrit en latin, français et allemand. Esprit polymathe, personnalité importante de la période "Frühaufklärung", il occupe une place primordiale dans l'histoire de la philosophie et l'histoire des mathématiques et est souvent considéré comme le dernier « génie universel ».

Il naît en 1646 à Leipzig dans une famille protestante ; son père, Friedrich Leibnütz, est professeur de philosophie morale à l'université de la ville. Après la mort de celui-ci en 1652, Leibniz, parallèlement à son éducation supervisée par sa mère et son oncle, étudie dans la bibliothèque léguée par son père. Entre 1661 et 1667, il étudie dans les universités de Leipzig, d'Iéna et d'Altdorf et obtient des diplômes en philosophie et en droit. En 1676, il devient bibliothécaire à Hanovre. Il y mène des recherches sur des domaines très diversifiés jusqu'à sa mort en 1716.

En philosophie, Leibniz est, avec René Descartes et Baruch Spinoza, l'un des principaux représentants du rationalisme. Au principe de non-contradiction, il ajoute trois autres principes à la base de ses réflexions : le principe de raison suffisante, le principe d'identité des indiscernables et le principe de continuité. Concevant les pensées comme des combinaisons de concepts de base, il théorise la caractéristique universelle, une langue hypothétique qui permettrait d'exprimer la totalité des pensées humaines, et qui pourrait résoudre des problèmes par le calcul grâce au "calculus ratiocinator", anticipant l'informatique de près de trois siècles. En métaphysique, il invente le concept de monade. Enfin, en théologie, il établit deux preuves de l'existence de Dieu, appelées preuves "ontologique" et "cosmologique". Au contraire de Spinoza, qui pensait Dieu immanent, Leibniz le conçoit transcendant, à la manière traditionnelle des religions monothéistes. Pour concilier l'omniscience, l'omnipotence et la bienveillance de Dieu avec l'existence du mal, il invente, dans le cadre de la théodicée, terme qu'on lui doit, le concept de meilleur des mondes possibles, qui sera raillé par Voltaire dans le conte philosophique "Candide". Il aura une influence majeure sur la logique moderne développée à partir du ainsi que sur la philosophie analytique au .

En mathématiques, la contribution principale de Leibniz est l'invention du calcul infinitésimal (calcul différentiel et calcul intégral). Si la paternité de cette découverte a longtemps fait l'objet d'une controverse l'opposant à Isaac Newton, les historiens des mathématiques s'accordent aujourd'hui pour dire que les deux mathématiciens l'ont développé plus ou moins indépendamment. Il travaille également sur le système binaire comme remplaçant du système décimal, s'inspirant des vieux travaux chinois. Par ailleurs, il introduit la notation qui porte son nom et travaille également sur la topologie.

Écrivant en permanence, il lègue un immense patrimoine littéraire , conservé à la bibliothèque de Hanovre. Il est composé d'environ dont avec plus de mille correspondants différents, et n'est toujours pas entièrement publié.

Gottfried Wilhelm Leibniz naît à Leipzig le , à la fin de la Guerre de Trente Ans, dans une famille luthérienne, . Son père, Friedrich Leibnütz, est juriste et professeur de philosophie morale à l'université de la ville, sa mère, Catherina Schmuck, est la fille du professeur de droit Wilhelm Schmuck.

Son père meurt en 1652 alors que Leibniz est âgé de six ans, et son éducation est alors supervisée par sa mère et son oncle, mais le jeune Leibniz apprend également en autodidacte dans l'importante bibliothèque qu'a laissée son père. Leibniz est scolarisé à la "Nikolaischule". Bien qu'il apprenne le latin à l'école, il semble que vers l'âge de douze ans, Leibniz ait appris de lui-même le latin à un niveau avancé ainsi que le grec, semble-t-il afin de pouvoir lire les livres de la bibliothèque de son père. Parmi ces livres, il s'intéresse surtout à la métaphysique et à la théologie, aussi bien d'auteurs catholiques que protestants. Au fur et à mesure de son apprentissage, il s'estime insatisfait de la logique d'Aristote et commence à développer ses propres idées. Comme il le rappellera plus tard dans sa vie, il était là en train de retrouver sans le savoir les idées logiques derrière les preuves mathématiques rigoureuses.

En 1661, âgé de 14 ans (un âge pas exceptionnellement jeune à l'époque), Leibniz entre à l'université de Leipzig. Son enseignement concerne surtout la philosophie et très peu les mathématiques ; il étudie aussi la rhétorique, le latin, le grec et l'hébreu. Les penseurs modernes (Descartes, Galilée, Gassendi, Hobbes...) n'ayant pas encore eu d'impact sur les pays germanophones, Leibniz étudie surtout la scolastique, bien qu'on retrouve aussi des éléments de la modernité, notamment de l'humanisme de la Renaissance et des travaux de Francis Bacon.

Il est l'élève de Jakob Thomasius qui supervise son premier travail philosophique, qui lui permet d'obtenir son baccalauréat en philosophie en 1663 : . Dans son travail, il « souligne la valeur existentielle de l'individu, qui ne peut être expliqué par sa matière seule ou sa forme seule mais plutôt dans son être tout entier ». On retrouve ici les prémices de sa notion de monade.

Durant l'été 1663, il étudie quelque temps à Iéna où il a entre autres, comme professeur de mathématiques, le mathématicien et philosophe Erhard Weigel, qui amènera Leibniz à commencer à s'intéresser aux preuves de type mathématique pour des disciplines telles que la logique et la philosophie. Les idées de Weigel, comme le fait que le nombre est le concept fondamental de l'Univers, auront une influence considérable sur le jeune Leibniz.

En octobre 1663, il est de retour à Leipzig pour un doctorat en droit, qu'il obtiendra en 1665. Il obtient une maîtrise en philosophie pour une dissertation combinant philosophie et droit en étudiant les relations entre ces domaines selon des idées mathématiques, comme il a appris de Weigel.

Quelques jours après, sa mère meurt.

Après avoir obtenu un baccalauréat en droit, Leibniz se lance dans l'obtention d'une habilitation en philosophie. Son travail, la (« Dissertation sur l'art combinatoire »), est publié en 1666. Dans ce travail, Leibniz entend réduire tous les raisonnements et toutes les découvertes à une combinaison d'éléments de base, comme des nombres, des lettres, des couleurs, des sons.

Malgré sa scolarité reconnue et sa réputation croissante, le doctorat en droit lui est refusé, pour des raisons partiellement inexpliquées. Il est vrai qu'il était l'un des plus jeunes candidats et qu'il n'y avait que douze tuteurs en droit disponibles, mais il semblerait que la femme du doyen ait persuadé celui-ci de s'opposer au doctorat de Leibniz, pour une raison inexpliquée. Leibniz n'étant pas enclin à accepter un quelconque délai, il part pour l'université d'Altdorf où il devient docteur en droit en février 1667 avec sa thèse (« Des cas perplexes en droit »). Il refuse peu après un poste de professeur.

Il s’affilie à une société alchimique, peut-être rattachée à la Rose-Croix, dont il sera secrétaire pendant deux ans. La nature exacte de son obédience est encore fort discutée par les historiens.

En 1669, il devient conseiller à la Chancellerie de l'électorat de Mayence, auprès du baron Johann Christian von Boyneburg. Leibniz réside à Mayence à l’"hôtel de Boyneburg". Il prépare le projet d'une grande réforme du droit, "". Il travaille alors sur plusieurs ouvrages concernant des thèmes politiques ("Modèle de démonstrations politiques pour l’élection du roi de Pologne") ou scientifiques ("Nouvelles Hypothèses physiques", 1671).

Il est envoyé en 1672 à Paris par Boyneburg en mission diplomatique pour convaincre de porter ses conquêtes vers l'Égypte plutôt que l'Allemagne. Il y restera jusqu’en 1676. En attendant une opportunité rencontrer le gouvernement français, il peut rencontrer les grands savants de l’époque. Il est notamment en contact avec Nicolas Malebranche et Antoine Arnauld. Avec ce dernier il parle particulièrement de la réunification des Églises. À partir de l'automne 1672, il étudie les mathématiques et la physique sous l'égide de Christian Huygens. Par conseil de ce dernier, il s'intéresse aux travaux de Grégoire de Saint-Vincent. Il se consacre aux mathématiques et laisse à Paris son manuscrit sur la quadrature arithmétique du cercle (donnant sous forme d'une série alternée). Il travaille également sur ce qui sera le calcul infinitésimal. Il conçoit en 1673 une machine à calculer qui permet d'effectuer les quatre opérations, et qui inspirera bien des machines à calculer des (arithmomètre, Curta). Avant de rejoindre Hanovre, il se rend à Londres pour étudier certains écrits d’Isaac Newton ; tous deux posent les bases du calcul intégral et différentiel.

Par deux fois, en 1673 et en 1676, Leibniz se rend à Londres où il rencontre les mathématiciens et physiciens de la . Il devient lui-même "" de la le .

Par l'intermédiaire de son ami Ehrenfried Walther von Tschirnhaus, Leibniz est informé d'une grande partie des travaux de Baruch Spinoza sur l"'Éthique" (bien que Walther von Tschirnhaus ait interdiction d'en montrer une copie avancée). Fin 1676, il se rend à La Haye où il rencontre Spinoza, qui vit alors les derniers mois de sa vie, atteint de tuberculose.

En 1676, à la mort de son protecteur Boyneburg, le duc Jean-Frédéric de Brunswick-Calenberg le nomme bibliothécaire du duché de Brunswick-Lunebourg et conseiller aulique. Il reste à ce poste au service de la maison de Hanovre pendant près de . Il s’occupe aussi de mathématiques, de physique, de religion et de diplomatie.

Dans les années 1680 à 1686, il fait de nombreux voyages dans le Harz pour s'occuper de l'exploitation des mines. Leibniz a consacré l'équivalent de trois années au métier d'ingénieur des mines. Il s'occupa principalement de mettre au point des dispositifs d'extraction des eaux des mines grâce à des moulins à vent. Il entra en conflit avec les exploitants qui n'acceptaient pas ses nouvelles idées. Cela le conduisit à se poser des questions sur l'origine des fossiles, qu'il attribuait initialement à l'effet du hasard, mais dont il reconnut plus tard l'origine vivante. Son livre " ne sera publié qu'après sa mort, car les théories qu'il y développe sur l'histoire de la terre pouvaient déplaire aux autorités religieuses.

En 1683, il fonde à Leipzig le journal ". L'année suivante, il y publie son article sur le calcul différentiel . Cependant, l'article ne contient aucune démonstration, et Jacques Bernoulli l'appellera une énigme plutôt qu'une explication. Deux en plus tard Leibniz publie son article sur le calcul intégral.

En 1686, il rédige un « Court discours de métaphysique », maintenant connu comme le "Discours de métaphysique". Le Discours est généralement considéré comme sa première œuvre philosophique mûre. Il envoie un résumé du discours à Arnauld, entamant ainsi une riche correspondance qui traitera principalement de la liberté, de la causalité et de l'occasionnalisme.

En 1687, il se lance dans une "Histoire de la maison de Brunswick", pour lequel il parcourt l'Italie en quête de documentation. En 1691, il publie à Paris, dans le "Journal des savants", un "Essai de dynamique" où il introduit les termes "énergie" et "action". En 1700, il fonde à Berlin une académie qui ne sera inaugurée qu’en 1711. En 1710, il publie ses "Essais de Théodicée", résultats de discussions avec le philosophe Pierre Bayle.

Reconnu comme le plus grand intellectuel d’Europe, il est pensionné par plusieurs grandes cours (Pierre Le Grand en Russie, en Autriche qui le fait baron), et correspondant des souverains et souveraines .

La fin de la vie de Leibniz est peu réjouissante.

Il doit faire face à une controverse qui l'oppose à Isaac Newton sur la question de savoir lequel des deux a inventé le calcul infinitésimal, et se voit même accusé d'avoir volé les idées de Newton. La plupart des historiens des mathématiques s'accordent aujourd'hui à considérer que les deux mathématiciens ont développé leurs théories indépendamment l'un de l'autre : Newton a commencé à développer ses idées le premier, mais Leibniz fut le premier à publier ses travaux.

Par ailleurs, il est moqué pour l'apparence désuète que lui donnent sa perruque et ses vêtements démodés. Quand Georg Ludwig devient roi de Grande-Bretagne, la mauvaise réputation qu'il s'est acquise en Angleterre l'empêche de suivre à Londres le nouveau souverain, et il reste à Hanovre.

Peu avant sa mort, il entretient une correspondance avec Samuel Clarke, supportant Newton, à propos de physique.

Il meurt le dans la ville où il résidait depuis , dans l'indifférence générale, alors que sa pensée a révolutionné l'Europe. Personne ne se préoccupe de ses funérailles à l'exception de son secrétaire personnel. On peut néanmoins noter, un an après la mort de Leibniz, en novembre 1717, un éloge prononcée à l'Académie royale des sciences de Paris par Bernard Le Bouyer de Fontenelle.

À sa mort, George , électeur de Hanovre et roi de Grande-Bretagne, craignant la révélation de secrets, confisque le patrimoine littéraire ("Nachlass") de Leibniz, permettant ainsi sa préservation.

Leibniz ne fut jamais marié, prétendument parce qu'il n'en eut jamais le temps. Il est dit qu'il se plaignait de ne pas avoir trouvé la femme qu'il cherchait. Comme était l'usage à la cour, il portait une longue perruque noire. Fait rare pour l'époque, il attachait une grande importance à son hygiène et fréquentait régulièrement les bains, ce qui lui valut de nombreuses lettres d'admiratrices féminines.

Sur les questions religieuses, Leibniz est considéré comme étant un . Bien qu'il ait été élevé dans le protestantisme, il a appris à apprécier les bons côtés du catholicisme auprès de ses employeurs et collègues. Il n'a jamais agréé à la vision protestante du pape comme un Antéchrist.

Leibniz était un travailleur infagitable, aimant la conversation mais plus encore la lecture et la méditation solitaires, travailler la nuit ne le dérangeait pas. Il pouvait aussi bien rester à penser plusieurs jours sur la même chaise, que voyager à travers l'Europe par tous les temps. 

Souvent dépeint comme le dernier « génie universel », faisant partie des plus grands penseurs des , Leibniz écrira sur des domaines extrêmement variés, et contribuera de manière importante à la métaphysique, à l'épistémologie, à la logique et à la philosophie de la religion, mais aussi hors du champ proprement philosophique, aux mathématiques, à la physique, à la géologie, à la jurisprudence et à l'histoire. Sa pensée n'est pas groupée au sein d'un "magnum opus" mais formée d'un ensemble considérable d'essais, de travaux non publiés et de lettres.

Denis Diderot, qui pourtant s'oppose en de nombreux points aux conceptions de Leibniz, écrit à son sujet dans l"'Encyclopédie" : « peut-être jamais un homme n'a autant lu, étudié, médité et écrit que Leibniz ». Bernard Le Bouyer de Fontenelle dira lui que « pareil en quelque sorte aux Anciens qui avaient l'adresse de mener jusqu'à huit chevaux attelés de front, il mena de front toutes les sciences ».

Leibniz est classé, avec René Descartes et Baruch Spinoza, comme l'un des principaux représentants du rationalisme du début de l'Époque moderne.

La philosophie de Leibniz est indissociable de son travail mathématique ainsi que de la logique, qui assure l'unité de son système.
Les mathématiciens ont autant besoin d'être philosophes que les philosophes d'être mathématiciens.

Leibniz fut formé dans la tradition scolastique. Il fut aussi exposé à des éléments de la modernité, notamment de l'humanisme de la Renaissance et des travaux de Francis Bacon.

Son professeur à l'université de Leipzig, Jakob Thomasius, lui transmet un grand respect envers la philosophie antique et médiévale. Quant à son professeur à Iéna, Erhard Weigel, il l'amènera à considérer les preuves de type mathématique pour des disciplines telles que la logique ou la philosophie.

De la philosophie antique, il hérite notamment de l'aristotélisme (notamment la logique (syllogistique) et la théorie des catégories) et du platonisme. On retrouve chez Leibniz également une influence du christianisme orthodoxe.

Il s'inspirera beaucoup de Raymond Lulle et Athanasius Kircher pour sa thèse d'alphabet de la pensée, de combinaison des idées, et de caractéristique universelle.

Leibniz rencontre des figures majeures de la philosophie de l'époque comme Antoine Arnauld, Nicolas Malebranche (à qui il doit notamment son intérêt pour la Chine), et surtout le mathématicien et physicien néerlandais Christiaan Huygens, qui lui enseigne la philosophie, les mathématiques et la physique.

La relation de Leibniz avec les grands penseurs de l'époque lui permet d'accéder aux manuscrits impubliés de Descartes et Pascal.

Leibniz s'opposera à Spinoza et Hobbes sur l'aspect matérialiste et nécessitariste ainsi que sur leur conception de Dieu de leurs doctrines respectives.

Tout comme Spinoza, Leibniz est héritier de Descartes tout en le critiquant largement également. Spinoza et Leibniz, malgré donc un héritage commun, s'opposent aussi fortement : notamment, le premier pense Dieu immanent ("Deus sive Natura"), le second le pense transcendant. Mais Leibniz étudiera tant le spinozisme pour le critiquer et si longtemps que les commentateurs ultérieurs se demanderont dans quelle mesure cette étude finira par influencer le système leibnizien.

Leibniz s'oppose à Descartes en ce qu'il préserve les acquis de l'aristotélisme ; et affirme, contrairement à Descartes et selon une inspiration aristotélicienne, que Dieu doit respecter les principes de la logique.

Enfin, Leibniz rédigera les "Nouveaux Essais sur l'entendement humain" et les "Essais de Théodicée" en opposition à des philosophes contemporains, respectivement John Locke et Pierre Bayle.

Dans la "Monadologie", Leibniz écrit :

Cependant, on peut, au fil de ses écrits, trouver quatre autres grands principes : le principe du meilleur, le principe du prédicat inhérent au sujet, le principe d'identité des indiscernables et le principe de continuité.

Ces six principes consistent en :

La logique occupe une part importante du travail de Leibniz, bien qu'elle fut délaissée par les philosophes et les mathématiciens qui s'intéressaient chacun aux travaux de Leibniz sur leurs disciplines respectives, et ce bien que chez Leibniz ces matières forment un tout indissociable dont la logique assure la cohésion.
La Logique est pour Leibniz la Clef de la Nature
La logique que développa Leibniz en fait pour certains le plus grand logicien depuis Aristote.

Leibniz estime qu'Aristote est le . Il avait une grande admiration pour son œuvre. Cependant, il l'estimait imparfaite ; il trouvait que la logique aristotélicienne présentait des lacunes et souhaitait l'améliorer. Il s'intéressa particulièrement à la syllogistique et ses premières contributions dans ce domaine se trouvent dans le "De arte combinatoria".

La logique de Leibniz est inspiré de Raymond Lulle, qui vécut au Moyen-Âge. Celui-ci, dans les "Ars magna", avance l'idée que les concepts et les propositions peuvent être exprimées sous la forme de combinaisons. S'inspirant de Lulle, Leibniz explique dans le "De arte combinatoria" comment on pourrait, dans un premier temps constituer un « Alphabet des pensées humaines », composé de toutes les idées de base, puis découvrir de nouvelles vérités en combinant les concepts pour former des jugements de manière exhaustive et évaluer méthodiquement leur vérité.

Sur ce principe, Leibniz théorise un langage universel qu'il nomme caractéristique universelle (), qui permettrait d'exprimer les concepts sous la forme des concepts de base dont ils sont composés, et de le représenter de manière à les rendre compréhensibles par tous les lecteurs, quelle que soit leur langue maternelle. Leibniz a étudié les hiéroglyphes égyptiens et les idéogrammes chinois en raison de leur méthode pour représenter les mots, sous forme de dessins. Leibniz n'est pas le premier à théoriser ce type de langage : avant lui, le mathématicien français François Viète (), le philosophe français René Descartes et le philologue anglais George Dalgarno () avaient déjà suggéré un tel projet, notamment dans le domaine des mathématiques, mais aussi pour Viète pour la communication. Par ailleurs, le projet leibnizien inspirera les projets de langue universelle de la fin du avec l'interlingue, version non dégradée du latin créée par Giuseppe Peano, puis l'espéranto. Il inspirera aussi l'idéographie de Gottlob Frege, le langage logique loglan et le langage de programmation Prolog.

Leibniz a aussi rêvé d’une logique qui serait calcul algorithmique et donc mécaniquement décidable : le "calculus ratiocinator". Un tel calcul pourrait être effectué par des machines et ne serait donc pas sujet aux erreurs. Leibniz annonce ainsi les mêmes idées que celles qui inspireront Charles Babbage, William Stanley Jevons, Charles Sanders Peirce et son étudiant Allan Marquand au , et qui seront à la base du développement des ordinateurs après la Seconde Guerre mondiale.

Leibniz croit pouvoir inventer, pour la vérification des calculs logiques, des procédés techniques analogues à la preuve par 9 employée en Arithmétique. Aussi appelle-t-il sa Caractéristique le juge des controverses, et la considère-t-il comme un art d'infaillibilité. Il fait un tableau séduisant de ce que seront, grâce à elle, les discussions philosophiques de l'avenir. Pour résoudre une question ou terminer une controverse, les adversaires n'auront qu'à prendre la plume, en s'adjoignant au besoin un ami comme arbitre, et à dire « Calculons ! ».

Leibniz est pour beaucoup le logicien le plus important entre Aristote et les logiciens du à l'origine de la logique moderne : , George Boole, Ernst Schröder et Gottlob Frege. Pour Louis Couturat, la logique leibnizienne anticipait les principes des systèmes logiques modernes, voire les dépassait sur certains points.

Néanmoins, qui n'ont été publiées que très tardivement voire oubliées. Se pose donc la question de savoir si Leibniz a juste anticipé la logique moderne ou s'il a influencé celle-ci. Il semble que la logique du s'est effectivement inspirée de la logique leibnizienne.

Rédigée en français en 1714 et non publiée du vivant de l’auteur, la "Monadologie" représente une des dernières étapes de la pensée de Leibniz. En dépit de ressemblances apparentes avec des textes antérieurs, la "Monadologie" se distingue assez fortement d’ouvrages comme le "Discours de métaphysique "ou le "Système nouveau de la nature et de la communication des substances". La notion de substance individuelle présente dans le "Discours de métaphysique" ne doit en effet pas être confondue avec celle de monade.

Pour Leibniz, la physique a sa raison dans la métaphysique. Si la physique étudie les mouvements de la nature, quelle réalité est ce mouvement ? Et quelle cause a-t-il ? Le mouvement est relatif, c'est-à-dire qu'une chose se meut selon la perspective d’où nous la regardons. Le mouvement n’est donc pas la réalité elle-même ; la réalité est la force qui subsiste en dehors de tout mouvement et qui en est la cause : la force subsiste, le repos et le mouvement étant des différences phénoménales relatives.

Leibniz définit la force comme Cette théorie entraîne un rejet de l’atomisme ; en effet, si l’atome est une réalité absolument rigide, alors il ne peut perdre de force dans les chocs. Il faut donc que ce que l’on nomme atome soit, en réalité, composé et élastique. L’idée d’atome absolu est contradictoire :

Ainsi la force est-elle la réalité : la force est substance, et toute substance est force. La force est dans un état, et cet état se modifie suivant des lois du changement. Cette succession d’états changeants possède un ordre régulier, c’est-à-dire que chaque état a une raison ( principe de raison suffisante) : chaque état s’explique par celui qui précède, il y trouve sa raison. À cette notion de loi se rattache également l’idée d’individualité : l’individualité est pour Leibniz une série de changements, série qui se présente comme une formule : 

Toute substance se développe ainsi suivant des lois intérieures, en suivant sa propre tendance : chacune a donc sa loi propre. Ainsi, si nous connaissons la nature de l’individu, pouvons-nous en dériver tous les états changeants. Cette loi de l’individualité implique des passages à des états non seulement nouveaux, mais aussi plus parfaits.

Ce qui existe est donc pour Leibniz l’individuel ; il n’existe que des unités. Ni les mouvements, ni même les corps n’ont cette substantialité : la substance étendue cartésienne suppose en effet quelque chose d’étendu, elle est seulement un composé, un agrégat qui ne possède pas par lui-même la réalité. Ainsi, sans substance absolument simple et indivisible, n’y aurait-il aucune réalité. Leibniz nomme "monade" cette réalité. La monade est conçue selon le modèle de notre âme :

Nous faisons l’observation de nos états internes, et ces états (sensations, pensées, sentiments) sont en un perpétuel changement : notre âme est une monade, et c’est d’après son modèle que nous pouvons concevoir la réalité des choses, car il y a sans doute dans la nature d’autres monades qui nous sont analogues. Par la loi de l’analogie (loi qui se formule « tout comme ceci »), nous concevons toute existence comme n’étant qu’une différence de degré relativement à nous. Ainsi, par exemple, il y a des degrés inférieurs de conscience, des formes obscures de la vie psychique : il y a des monades à tous les degrés de clarté et d’obscurité. Il y a une continuité de toutes les existences, continuité qui trouve son fondement dans le principe de raison.

Dès lors, puisqu’il n’existe que des êtres doués de représentations plus ou moins claires, dont l’essence est dans cette activité représentative, la matière se trouve réduite à l’état de phénomène. La naissance et la mort sont également des phénomènes dans lesquels les monades s’obscurcissent ou s’éclaircissent. Ces phénomènes ont de la réalité dans la mesure où ils sont reliés par des lois, mais le monde, d’une manière générale, n’existe qu’en tant que représentation.

Ces monades, en se développant selon une loi interne, ne reçoivent aucune influence de l’extérieur : 

Ajoutons que le concept de monade a été influencé par la philosophie de Pierre Gassendi, lequel reprend la tradition atomiste incarnée par Démocrite, Épicure et Lucrèce. En effet l'atome, du grec « "" » (indivisible) est l'élément simple dont tout est composé. La différence majeure avec la monade étant que celle-ci est d'essence spirituelle, alors que l'atome est d'essence matérielle ; et donc l'âme, qui est une monade chez Leibniz, est composée d'atomes chez Lucrèce.

Dès lors, comment expliquer que tout se passe dans le monde comme si les monades s’influençaient réellement mutuellement ? Leibniz explique cette concordance par une harmonie préétablie universelle entre tous les êtres, et par un créateur commun de cette harmonie :

Si les monades semblent tenir compte les unes des autres, c’est parce que Dieu les a créées pour qu’il en soit ainsi. C’est par Dieu que les monades sont créées d’un coup par "fulguration", à l’état d’individualité qui les fait être comme de petits dieux. Chacune possède un point de vue singulier sur le monde, une vue de l’univers en miniature, et toutes ses perspectives ont ensemble une cohérence interne, tandis que Dieu possède l’infinité des points de vue qu’il crée sous la forme de ces substances individuelles. La force et la pensée intimes des monades sont donc une force et une pensée divines. Et l’harmonie est dès l’origine dans l’esprit de Dieu : elle est préétablie.

Si certains commentateurs (par exemple Alain Renaut, 1989) ont voulu voir dans l'harmonie préétablie un schème abstrait qui rétablit, seulement après coup, la communication entre les monades, monades qui seraient alors les signes d'une fragmentation du réel en unités indépendantes, cette interprétation a été rejetée par l'un des commentaires les plus importants de l'œuvre de Leibniz, celui de Dietrich Mahnke, intitulé "La synthèse de la Mathématique universelle et de la Métaphysique de l'individu" (1925). Inspirant celui de Michel Fichant, Mahnke souligne que l'harmonie universelle précède la monade : le choix de chaque monade se fait non par des volontés particulières de Dieu, mais par une volonté primitive, qui choisit l'ensemble des monades : chaque notion complète d'une monade individuée est ainsi enveloppée dans le choix primitif du monde. Aussi, .

Il ressort enfin de cette idée de la monade que l’univers n’existe pas en dehors de la monade, mais qu’il est l’ensemble de toutes les perspectives. Ces perspectives naissent de Dieu. Tous les problèmes de la philosophie sont ainsi déplacés dans la théologie.

Cette transposition pose des problèmes qui ne sont pas vraiment résolus par Leibniz :

Malebranche résumera tous ces problèmes en une formule : "Dieu ne crée pas des dieux".

Sa théorie de l’union de l’âme et du corps suit naturellement son idée de la monade. Le corps est un agrégat de monades, dont les rapports avec l’âme sont réglés dès le départ comme deux horloges que l’on aurait synchronisées. Leibniz décrit ainsi la représentation du corps (c’est-à-dire du multiple) par l’âme :

Bien que n'étant pas aussi traitée en termes de quantité que la logique, la métaphysique, la théodicée et la philosophie naturelle, l'épistémologie (ici au sens anglo-saxon du terme : étude de la connaissance) reste un thème d'important travail de la part de Leibniz. Leibniz est innéiste, et assume pleinement s'inspirer de Platon, sur la question de l'origine des idées et de la connaissance.

Le principal ouvrage de Leibniz en la matière sont les "Nouveaux Essais sur l'entendement humain", rédigés en français, commentaire de l"'Essai sur l'entendement humain" de John Locke. Les "Nouveaux essais" sont achevés en 1704. Mais la mort de Locke convainc Leibniz de reporter leur publication, ce dernier trouvant malvenu de publier une réfutation d'un homme ne pouvant se défendre. Ils ne paraîtront finalement que de manière posthume, en 1765.

Le philosophe anglais défend une position empiriste, selon laquelle toutes nos idées nous viennent de l’expérience. Leibniz, sous la forme d’un dialogue imaginaire entre Philalèthe, qui cite les passages du livre de Locke, et Théophile, qui lui oppose les arguments leibniziens, défend une position innéiste : certaines idées sont en notre esprit dès la naissance. Ce sont des idées qui sont constitutives de notre entendement même, comme celle de causalité. Les idées innées peuvent être activées par l'expérience, mais il a fallu pour cela qu’elles existent d’abord potentiellement dans notre entendement.

Leibniz s'est beaucoup intéressé à l'argument ontologique de l'existence de Dieu à partir des années 1670, et a échangé à ce sujet avec Baruch Spinoza. Il réfute l'argumentation de René Descartes dans la cinquième méditation des "Méditations métaphysiques" : Dieu a toutes les perfections, or l'existence est une perfection, donc Dieu existe. Pour Leibniz, il s'agit surtout de montrer que toutes les perfections sont compossibles, et que l'existence est une perfection. Leibniz montre la première prémisse dans son essai "Quod ens perfectissimum existit" (1676), et la seconde dans un autre court écrit de la même période.

La démonstration de Leibniz, qui a des ressemblances avec la preuve ontologique de Gödel, établie par Kurt Gödel dans les années 1970 : 

Leibniz s'est également intéressé à l'argument cosmologique. L'argument cosmologique chez Leibniz découle de son principe de raison suffisante. Chaque vérité a une raison suffisante, et la raison suffisante de l'ensemble des séries de vérités est nécessairement située hors des séries, et c'est cette raison ultime que nous appelons Dieu.

Dans les "Essais de Théodicée", Leibniz parvient à démontrer l' de Dieu, son omniscience, son omnipotence et sa bienveillance.

Le terme de « théodicée » signifie étymologiquement « justice de Dieu » (du grec (« Dieu ») et (« justice »)). Il s'agit d'un néologisme inventé par Leibniz lui-même. , le terme est généralement compris comme une , un discours se proposant de . Il est essentiel de souligner le principal enjeu de la théodicée leibnizienne. La question est d’abord : comment accorder l’existence du mal avec l’idée de la perfection générale de l’univers ? Mais, par-delà les difficultés internes à la métaphysique leibnizienne, on trouve le problème suivant : comment accorder l’idée de la responsabilité ou de la culpabilité de l’homme dans le mal avec le sentiment que cet homme agit de la seule manière dont il était possible qu’il agît. La réponse de Leibniz au conflit entre nécessité et liberté est originale.

L’exemple de Judas le traître, tel qu’il est analysé dans la du "Discours de Métaphysique", est éclairant : certes, il était prévisible de toute éternité que ce Judas-là dont Dieu a laissé l’essence venir à l’existence, pècherait comme il a péché, mais il n’empêche que c’est bien lui qui pèche. Le fait que cet être limité, imparfait (comme toute créature) entre dans le plan général de la création, et donc tire en un sens son existence de Dieu, ne le lave pas en lui-même de son imperfection. C’est bien lui qui est imparfait, de même que la roue dentée, dans une montre, n’est rien d’autre qu’une roue dentée : le fait que l’horloger l’utilise pour fabriquer une montre ne rend pas cet horloger responsable du fait que cette roue dentée n’est rien d’autre, rien de mieux qu’une roue dentée.

Le principe de raison suffisante, parfois nommé principe de « la raison déterminante » ou le « grand principe du pourquoi », est le principe fondamental qui a guidé Leibniz dans ses recherches : rien n’est sans une raison qui explique pourquoi il est, plutôt qu’il n’est pas, et pourquoi il est ainsi, plutôt qu’autrement. Leibniz ne nie pas que le mal existe. Il affirme toutefois que tous les maux ne peuvent pas être moindres : ces maux trouvent leur explication et leur justification dans l’ensemble, dans l’harmonie du tableau de l’univers. ("Théodicée", 1710 – parution en 1747).

Répondant à Pierre Bayle, il établit la démonstration suivante : si Dieu existe, il est parfait et unique. Or, si Dieu est parfait, il est « nécessairement » tout-puissant, toute bonté et toute justice, toute sagesse. Ainsi, si Dieu existe, il a, par nécessité, pu, voulu et su créer le moins imparfait de tous les mondes imparfaits ; le monde le mieux adapté aux fins suprêmes.

En 1759, dans le conte philosophique "Candide", Voltaire fait de son personnage Pangloss le prétendu porte-parole de Leibniz. En vérité, il y déforme sa doctrine : « tout est au mieux dans le meilleur des mondes possibles ». Cette formule est une mauvaise interprétation : Leibniz n'affirme nullement que le monde est parfait mais que le mal est réduit à son minimum. Toutefois, le texte de Voltaire ne s'oppose pas à Leibniz sur un plan théologique ni métaphysique : le conte de "Candide" trouve son origine dans l'opposition entre Voltaire et Rousseau, et son contenu cherche à montrer que « ce ne sont pas les raisonnements des métaphysiciens qui mettront fin à nos maux », faisant l'apologie d'une philosophie volontariste invitant les hommes à « organiser eux-mêmes la vie terrestre » et où le travail est présenté comme « source de progrès matériels et moraux qui rendront les hommes plus heureux ».

Si l'éthique constitue le seul champ traditionnel de la philosophie pour lequel Leibniz n'est généralement pas considéré comme un important contributeur, comme Spinoza, Hume ou Kant, Leibniz fut fort intéressé par ce domaine. Il est vrai que par comparaison avec sa métaphysique, la pensée éthique de Leibniz ne se distingue pas partiuclièrement par sa portée ou son originalité. Pour autant, il s'est engagé dans des débats centraux de l'éthique sur les fondements de la justice et la question de l'altruisme.

Pour Leibniz, la justice est la science du bien, c'est-à-dire qu'il y a des bases rationnelles et objectives de la justice. Il rejette la position selon laquelle la justice est le décret du plus fort, position qu'il associe à Thrasymaque qui la défend face à Socrate dans "la République" de Platon, mais également à Samuel von Pufendorf et Thomas Hobbes. En effet, appliquant cette conception, on en arrive à la conclusion que les commandements divins sont justes uniquement parce que Dieu est le plus puissant de tous les législateurs. Pour Leibniz, cela revient à rejeter la perfection de Dieu ; pour lui, Dieu agit selon la meilleure manière, et pas seulement de façon arbitraire. Dieu n'est pas parfait seulement dans son pouvoir, mais également dans sa sagesse. Le standard de justice "a priori" et éternel auquel adhère Dieu doît être la base de la théorie du droit naturel.

Leibniz définit la justice comme la charité de la personne sage. Bien que cette définition puisse paraître étrange à ceux qui sont habitués à une distinction entre justice et charité, la véritable originalité de Leibniz est sa définition de la charité et de l'amour. En effet, au se pose la question de la possibilité d'un amour désintéressé. Il semble que chaque être agisse de manière à persévérer dans l'existence, ce que Hobbes et Spinoza désignent sous le terme de à la base de leurs psychologies respectives. Selon ce point de vue, celui qui aime est celui qui voit dans cet amour un moyen d'améliorer son existence ; l'amour est alors réduit à une forme d'égoïsme, et quand bien même il serait bienveillant, il lui manquerait une composante altruiste. Pour résoudre cette incompatibilité entre l'égoïsme et l'altruisme, Leibniz définit l'amour comme le fait de prendre du plaisir au bonheur d'autrui. Ainsi, Leibniz ne nie pas le principe fondamental de la conduite de chaque individu, la recherche du plaisir et de l'intérêt personnel, mais parvient à le lier à la préoccupation, altruiste, du bien-être d'autrui. Ainsi, l'amour est défini comme la entre l'altruisme et l'intérêt personnel ; la justice est la charité de la personne sage ; et la personne sage, dit Leibniz, est celle qui aime tout.

Les travaux mathématiques de Leibniz se trouvent dans le "Journal des savants" de Paris, les "Acta Eruditorum" de Leipzig (qu'il a contribué à fonder) ainsi que dans son abondante correspondance avec Christian Huygens, les frères Jean et Jacques Bernoulli, le Marquis de L'Hôpital, Pierre Varignon

On attribue souvent à Isaac Newton et à Leibniz l'invention du calcul infinitésimal. En vérité, on retrouve dès Archimède (), les prémices de ce type de calcul. Il sera développé par la suite par Pierre de Fermat, , et René Descartes et . 

Tout le étudie l’indivisible et l’infiniment petit. Comme Newton, Leibniz domine tôt les indéterminations dans le calcul des dérivées. De plus il développe un algorithme qui est l’outil majeur pour l’analyse d’un tout et de ses parties, fondé sur l’idée que toute chose intègre des petits éléments dont les variations concourent à l’unité. Ses travaux sur ce qu’il appelait la « spécieuse supérieure » seront poursuivis par les frères Bernoulli, le marquis de l’Hospital, Euler et Lagrange.

Selon Leibniz, la symbolique mathématique n'est rien de plus qu'un échantillon concernant l'arithmétique et l'algèbre de son projet plus général de caractéristique universelle. Selon lui, le développement des mathématiques dépend avant tout de l'utilisation d'un symbolisme approprié ; ainsi considère-t-il que les progrès qu'il a fait faire aux mathématiques sont dus à ce qu'il a réussi à trouver des symboles adéquats à la représentation des quantités et de leurs relations. Le principal avantage de sa méthode de calcul infinitésimal sur celle de Newton (méthode des fluxions) est en effet son utilisation de signes plus judicieuse.

Il est à l’origine de plusieurs termes : 

Il crée également plusieurs nouvelles notations : 

On lui doit aussi une définition logique de l'égalité.

Il fait également évoluer la notation en arithmétique élémentaire : 

Leibniz s'est intéressé de près au système binaire. Il est parfois vu comme en étant l'inventeur, bien que ce ne soit pas le cas. En effet, Thomas Harriot, mathématicien et scientifique anglais, avait déjà travaillé sur des systèmes non décimaux : binaire, ternaire, quaternaire et quinaire, mais également des systèmes de base plus élevée. Selon Robert Ineichen, de l'université de Fribourg, Harriot est « probablement le premier inventeur du système binaire ». Selon Ineichen, "Mathesis biceps vetus et nova" de l'homme d'Église espagnol Juan Caramuel y Lobkowitz est la première publication connue en Europe sur les systèmes non décimaux, dont le binaire. Enfin, John Napier traite de l'arithmétique binaire dans les "Rabdologiæ" (1617) et Blaise Pascal affirme dans le "De numeris multiplicibus" (1654 / 1665) que le système décimal n'est pas obligatoire.

Leibniz cherche un remplacement au système décimal à partir de la fin du . Il découvre l'arithmétique binaire dans un livre chinois vieux de 5000 ans, le "Yi Jing" (« Classique des changements »). Il écrit un article qu'il nomme « Explication de l'arithmétique binaire, qui utilise seulement les caractères 1 et 0, avec quelques remarques sur son utilité, et sur la lumière qu'elle jette sur les anciennes figures chinoises de Fu Xi » . Son article est présent dans l"'Histoire de l’Académie royale des sciences" de 1703, ainsi qu'un compte-rendu rédigé par un contemporain, « Nouvelle Arithmétique binaire ». Reconnaissant cette manière de représenter les nombres comme un héritage très lointain du fondateur de l’Empire chinois « Fohy », Leibniz s’interroge longuement sur l’utilité des concepts qu’il vient de présenter, notamment en ce qui concerne les règles arithmétiques qu’il développe. Finalement, il semble conclure que la seule utilité qu’il voit dans tout ceci est une sorte de beauté essentielle, qui révèle la nature intrinsèque des nombres et de leurs liens mutuels.

Leibniz s’intéresse aux systèmes d’équations et pressent l’usage des déterminants. Dans son traité sur "l’art combinatoire, science générale de la forme et des formules", il développe des techniques de substitution pour la résolution d’équations. Il travaille sur la convergence des séries, le développement en série entière des fonctions comme l’exponentielle, le logarithme, les fonctions trigonométriques (1673). Il découvre la courbe brachistochrone et s’intéresse à la rectification des courbes (calcul de leur longueur). Il a étudié le "traité des coniques" de Pascal et écrit sur le sujet. Il est le premier à créer la fonction formula_4 ('). Il étudie les enveloppes de courbes et la recherche d’extremum pour une fonction (', 1684). 

Il tente aussi une incursion dans la théorie des graphes et la topologie (").

Leibniz, comme de nombreux mathématiciens de son temps, était aussi physicien. Bien qu'il soit aujourd'hui connu pour sa métaphysique et sa théorie de l'optimisme, Leibniz s'est imposé comme une des principales figures de la révolution scientifique au même titre que Galilée, Descartes, Huygens, Hooke et Newton. Leibniz est devenu très tôt mécaniste, vers 1661, alors qu'il étudiait à Leipzig, comme il le relate dans une lettre à . Cependant, une différence profonde le sépare d'Isaac Newton : si Newton considère que et cherche à prévoir les phénomènes par sa physique, Leibniz cherche à découvrir l'essence cachée des choses et du monde, sans chercher à obtenir des calculs précis à propos de phénomènes quelconques. D'ailleurs jamais il n'employa son calcul infinitésimal pour expliquer les lois de la nature. Il en est venu ainsi à reprocher à René Descartes et à Newton de ne pas savoir se passer d'un " (une raison divine cachée) dans leurs physiques, car celles-ci n'expliquaient pas tout ce qui est, ce qui est possible et ce qui n'est pas.

Leibniz, bibliothécaire à Hanovre à partir de 1676 et à Wolfenbüttel à partir de 1691, explique dans sa "Représentation à S.A.S. le duc de Wolfenbüttel pour l'encourager à l'entretien de sa Bibliothèque" comment il entendait l'exercice ses fonctions. À son mémoire il joint deux plans de classification de bibliothèque fondée sur la classification des sciences, qui devait aussi servir de base à l'Encyclopédie :

Louis Couturat, dans "La Logique de Leibniz", fait remarquer l'ordre et la distinction des trois parties de la philosophie (métaphysique, mathématique et physique), distinction fondée sur celle de leurs objets, c'est-à-dire de nos facultés de connaître : objets de l'entendement pur, de l'imagination, des sens.

Il a conçu le projet d’une encyclopédie ou « bibliothèque universelle » : 
Il importe à la félicité du genre humain que soit fondée une Encyclopédie, c’est-à-dire une collection ordonnée de vérités suffisant, autant que faire se peut, à la déduction de toutes choses utiles. 

Leibniz, dès les années 1670, a aussi une importante activité d'historien. Elle est au début liée à son intérêt pour le droit, qui le conduit à développer des travaux d'histoire du droit, et à publier, dans les années 1690, un important recueil de documents juridiques médiévaux. Elle est aussi liée à la commande que lui passe en 1685 l'électeur de Hanovre : une histoire de la maison de Brunswick. Convaincu que cette famille aristocratique a en partie des origines semblables à la maison italienne des Este, Leibniz entreprend d'importants travaux sur l'histoire de l'Europe du . Leibniz se rend alors en Italie, de 1687 à 1690, pour réunir la documentation nécessaire à son enquête. Leibniz participe ainsi aux travaux de l'époque, qui fondent, avec Jean Mabillon, Étienne Baluze ou Papebrocke, la critique historique ; il apporte des éléments importants aux questions de chronologie et de généalogie des familles souveraines d'Europe. Son travail ne sera pas achevé à son décès en 1716. Il engage au sujet de la maison des Este une polémique fameuse avec le grand savant italien Antonio Muratori.

Iréniste, Leibniz chercha la réunification des Églises chrétiennes catholique et protestant.

Il conçoit une machine arithmétique capable de multiplier, et invente pour cela la mise en mémoire du multiplicande grâce à ses fameux cylindres cannelés, utilisés jusque dans les années 1960. Après avoir construit trois premiers modèles, il en construit un quatrième plus tard, en 1690, celui-ci ayant été retrouvé en 1894 à l'université de Göttingen et est maintenant conservé à la bibliothèque Gottfried Wilhelm Leibniz à Hanovre.

Au delà de son intérêt philosophique pour le langage idéal, Leibniz pratique la linguistique en tant que science auxiliaire de l'histoire. Son objectif est d'identifier les groupes ethniques et leurs mouvements à travers le langage afin de reconstituer l'histoire avant la tradition écrite. Son intérêt se porte donc surtout sur l'étymologie.

Les écrits et lettres de Leibniz durant un demi-siècle témoignent de son intérêt fort et durable pour la Chine. Initialement, il s'intéressait surtout sur la langue chinoise : l'utilisation de ce système par les sourds-muets, l'idée qu'il s'agissait peut-être du souvenir d'un calcul oublié depuis longtemps, et la question de savoir si sa construction suivait des lois logico-mathématiques similaires à celles du projet de Leibniz de caractéristique universelle.

Nicolas Malebranche, un des premiers Européens à s'intéresser à la sinologie vers la fin de sa carrière, jouera un rôle primordial dans l'intérêt que Leibniz portera envers la Chine. En 1689, une conversation avec le jésuite élargit et renforce l'intérêt de Leibniz pour la Chine.

La psychologie a été un des principaux centres d'intérêt de Leibniz. Il apparaît comme un « précurseur sous-estimé de la psychologie ». Il s'intéresse à plusieurs thèmes faisant maintenant partie de la psychologie : l'attention et la conscience, la mémoire, l'apprentissage, la motivation, l'individualité ou encore le rôle de l'. Il a fortement influencé le fondateur de la psychologie en tant que discipline à part entière, Wilhelm Wundt, qui publiera une monographie sur Leibniz, et reprendra le terme d'aperception introduit par Leibniz.

Leibniz était un excellent joueur d’échecs ; il s'est notamment intéressé à l'aspect scientifique et logique du jeu (par opposition aux jeux qui comportent une part de hasard), et fut le premier à considérer celui-ci comme une science.

Leibniz fut un auteur très prolifique, composant environ textes, dont lettres avec plus de mille correspondants de seize pays différents. Il lègue environ manuscrites. Son œuvre est écrite majoritairement en latin (la langue des savants, langue la plus commune au ) (40 %), en français (la langue de la cour en Allemagne) (30 %) et en allemand (15 %), mais il a aussi rédigé en anglais, en italien et en néerlandais. Il parlait également couramment l'hébreu et avait quelques notions de russe et de chinois.

Il utilisa parfois les pseudonymes Caesarinus Fürstenerius et Georgius Ulicovius Lithuanus.

Sa correspondance est inscrite au registre international Mémoire du monde de l'UNESCO. Elle est dans un état de conservation exceptionnelle grâce à la confiscation opérée par George , électeur de Hanovre et roi de Grande-Bretagne qui craignait la révélation de secrets. L'édition complète de la correspondance de Leibniz est prévue pour l'année 2048.

Leibniz écrivait sur des pages in-folio qu'il séparait en deux colonnes : l'une lui servait à écrire son brouillon original, l'autre à annoter ou ajouter certains portions de texte à son brouillon. Il lui arrivait souvent d'annoter ses propres annotations. La colonne des annotations était fréquemment autant remplie que celle du texte original. Par ailleurs, son orthographe et sa ponctuation étaient très fantaisistes.

Esprit toujours en ébullition, il était tout le temps en train de noter ses idées sur le papier, stockant ses notes dans un grand placard pour les récupérer plus tard. Néanmoins, étant donné qu'il écrivait tout le temps, l'accumulation de ses brouillons l'empêchait de retrouver celui qui l'intéressait, et pour cette raison il le réécrivait ; ce qui fait qu'on a plusieurs ébauches d'un même opuscule, qui s'ils ont les mêmes idées de fond, n'ont pas le même développement et parfois même pas le même plan. Si on peut en général constater une certaine progression d'un brouillon à l'autre, les premières versions contiennent souvent des détails ou des vues manquant aux versions ultérieures. Ces répétitions entre brouillons ont toutefois un avantage : ils permettent de mettre en évidence l'évolution dans la pensée de Leibniz.

Au contraire des autres grands philosophes de son temps, Leibniz n'a pas réalisé de , ouvrage exprimant à lui seul tout le cœur de la pensée d'un auteur. Il n'écrira que deux livres, les "Essais de Théodicée" (1710) et les "Nouveaux Essais sur l'entendement humain" (1704 - publié posthumément en 1765).

Parmi ses très nombreux correspondants, Leibniz compte Baruch Spinoza, Thomas Hobbes, Antoine Arnauld, Jacques-Bénigne Bossuet, Nicolas Malebranche, Jacques Bernoulli, Pierre Bayle ou encore Samuel Clarke, mais aussi les personnalités politiques de son temps : princes, électeurs et empereurs du Saint-Empire romain germanique ou encore le tsar Pierre le Grand.

Le patrimoine ("Nachlass") de Leibniz n'est toujours pas entièrement publié. Le projet d'édition complète des écrits de Leibniz mené par la bibliothèque Gottfried Wilhelm Leibniz de Hanovre, commencé au début du , prévoit de classer son patrimoine en huit séries :

Il est à noter que l'idée de classer les opuscules et ouvrages en fonction de leur contenu ne fait l'unanimité. Ainsi Louis Couturat dans la préface de son édition des "Opuscules et fragments inédits de Leibniz" affirme que le seul classement objectif est le classement chronologique, et que tout autre classement revient à créer des divisions dans son œuvre là où il n'y en a pas, au risque d'oublier certains fragments ou de mal les classer et ainsi de fournir une vision déformée de l'œuvre. Il s'oppose également à faire des choix parmi les manuscrits ; selon lui, l'objectif de l'édition projetée est de mettre au jour l'intégralité des écrits, aux commentateurs ensuite de faire leur choix parmi les morceaux qui les intéressent.

À sa mort, Leibniz ne jouit pas d'une bonne image. Il est en effet accusé d'avoir volé à Isaac Newton les idées à la base du calcul infinitésimal. Newton et Leibniz avaient trouvé l'art de lever les indéterminations dans le calcul des tangentes ou dérivées. Mais Newton a publié tard (son procès intervient en 1713, presque 30 ans après les publications de Leibniz : 1684 et 1686) et, surtout, Newton n'a ni l’algorithme différentio-intégral fondé sur l’idée que les choses sont constituées de petits éléments, ni l’approche arithmétique nécessaire à des différentielles conçues comme « petites différences finies ».

Leibniz et son disciple Christian Wolff influenceront fortement Emmanuel Kant. Il n'est cependant pas clairement établi de quelle manière les idées leibniziennes influenceront les thèses kantiennes. Notamment, on ne sait pas vraiment si Kant, dans le commentaire qu'il fait des thèmes leibniziens, commente directement Leibniz ou ses héritiers.

Chez les Lumières, les points de vue sur Leibniz sont partagés. D'un côté, Jean-Jacques Rousseau puise une partie de son apprentissage chez Leibniz ; Denis Diderot en fait l'éloge dans l"'Encyclopédie", et malgré de nombreuses oppositions entre les deux philosophes, on retrouve des similarités notables entre les "Nouveaux Essais sur l'entendement humain" de Leibniz et les "Pensées sur l'interprétation de la nature" de Diderot. Cependant, à la même époque, la théodicée de Leibniz, et son idée de meilleur des mondes possibles, seront fortement critiquées de manière satirique par Voltaire dans son conte philosophique "Candide" à travers le personne de Pangloss.

Leibniz a également fortement influencé le neurophysiologue, psychologue et philosophe Wilhelm Wundt, connu comme le fondateur de la psychologie en tant que discipline expérimentale. Ce dernier lui consacrera une monographie en 1917.

Au , le logicien Kurt Gödel a été fortement influencé par Leibniz (ainsi que par Kant et Husserl) et a étudié de manière intensive les travaux de ce dernier entre 1943 et 1946. Il était par ailleurs persuadé qu'une conspiration était à l'origine de la suppression de certains travaux du philosophe allemand. Gödel considérait que la caractéristique universelle était réalisable.

Selon le "Mathematics Genealogy Project", Leibniz compte plus de descendants en mathématiques, dont deux étudiants : Nicolas Malebranche et Christian Wolff.

Plusieurs institutions ont été nommées en son hommage :

Par ailleurs, un prix nommé en son honneur, le prix Gottfried-Wilhelm-Leibniz, décerné chaque année depuis 1986 par la Fondation allemande pour la recherche et une des plus prestigieuses récompenses en Allemagne dans le domaine de la recherche scientifique.

En mathématiques, il a donné son nom :

En astronomie, il a donné son nom :

À Paris, il a donné son nom à la rue Leibniz et au square Leibniz dans le arrondissement.

La biscuiterie Bahlsen vend depuis 1891 des biscuits appelés « », la biscuiterie étant basée à Hanovre où le philosophe a vécu pendant 40 ans.

La maison dans laquelle il vécut de à son mort en 1716, datant de 1499, fut détruite par des bombardements aériens dans la nuit du 8 au . Une reproduction fidèle ("Leibnizhaus", « maison de Leibniz ») fut édifiée entre 1981 et 1983.

À l'occasion des 370 ans de sa naissance et du anniversaire de sa mort, année qui correspond aussi aux 10 ans du renommage de l'université de Hanovre et aux 50 ans de la société Gottfried Wilhelm Leibniz, la ville de Hanovre déclare l'année 2016 « Année de Leibniz ».

Deux monuments sont dédiés à son mémoire à Hanovre : le mémorial Leibniz, une plaque de bronze taillée pour représenter son visage, et le temple Leibniz, situé dans le parc . Par ailleurs, des mentions du philosophe peuvent être rencontrées en différents endroits de la ville.

Ernst Hähnel a réalisé une statue du philosophe à Leipzig, sa ville natale.









Traductions en français d’œuvres mathématiques : 







</doc>
<doc id="14395" url="https://fr.wikipedia.org/wiki?curid=14395" title="Amérique centrale">
Amérique centrale

L'Amérique centrale est une bande de terre reliant l'Amérique du Nord et l'Amérique du Sud.

La différence entre les frontières géographiques et les frontières administratives, ainsi que l'histoire coloniale et les ressemblances et différences culturelles dans la région font varier la définition de l'Amérique centrale selon le contexte.

Dans sa définition la plus commune, l'Amérique centrale comprend les pays suivants :

On peut dans certains cas ajouter à ces pays les Antilles.

L'Amérique centrale s'étend de l'isthme de Tehuantepec dans le sud du Mexique (le Mexique est majoritairement situé en Amérique du Nord) au nord, à l'Isthme de Darién (Panama) au sud. Elle est bordée par le Golfe du Mexique au nord, la mer des Caraïbes à l'est, et par l'océan Pacifique au sud et à l'ouest.

La cordillère néovolcanique est considérée comme la division géologique séparant l'Amérique du Nord et l'Amérique centrale.

À l'époque coloniale l'Amérique centrale était partiellement contrôlée par la Capitainerie générale du Guatemala qui recouvrait les régions aujourd'hui occupées par le Guatemala, la Belize, le Honduras, le Salvador, le Nicaragua et le Costa Rica. À l'indépendance (1821-1822), la Capitainerie devient les Provinces unies d'Amérique centrale puis la République fédérale d'Amérique centrale. Les États que l'on connaît aujourd'hui sont devenus indépendants de cette fédération dans les années 1830.

Ce passé, excluant le Panama rattaché à l'histoire colombienne et le Belize très vite colonisé par les Anglais, a permis à une identité centre-américaine de se développer dans ces pays. Il existe d'ailleurs une différence en espagnol entre la définition géographique, "« América Central »" (Amérique centrale), et la définition historique et politique, "« Centroamérica »" (Centre-Amérique).

Il existe aujourd'hui des organisations régionales résultant de ce passé, comme le marché commun centraméricain (MCCA) ou le plus récent Système d'intégration centraméricain (SICA), dont les membres fondateurs sont les cinq pays « historiques » : Guatemala, Honduras, Salvador, Nicaragua et Costa Rica.
Par simplification, on définit souvent ces cinq pays comme l'Amérique centrale ; le Belize et le Panama sont alors considérés comme caribéens (à l'instar des trois Guyane).

Mais le Panama a intégré le parlement centre-américain en 1992 et a comme projet de s'intégrer au SICA dans les prochaines années. Le Belize, lui, est déjà membre du SICA mais pas du MCCA, préférant le CARICOM. Quant au parlement centre-américain, il accueille depuis 2004 des députés de la République dominicaine (ce pays s'intégrant économiquement et politiquement de plus en plus à l'Amérique centrale). On peut donc s'apercevoir que la définition politique de l'Amérique centrale est encore très floue.


L'Amérique centrale est traversée par un système montagneux appelé « la Cordillère centrale » dont les sommets peuvent dépasser les mètres. Située à l'intersection de la Plaque caraïbe, de la Plaque nord-américaine et de la Plaque de Cocos, une chaîne volcanique longe la côte Pacifique du nord au sud de la région.

La côte caraïbe est constituée d'une forêt tropicale, qui n'est en réalité que la prolongation de l'Amazonie, très peu hospitalière. Grâce à cette forêt tropicale, l'Amérique centrale abrite 7 % de la biodiversité mondiale. La côte Pacifique, plus hospitalière car plus sèche grâce au relief la protégeant du climat caribéen, abrite quant à elle la majeure partie de la population centre-américaine.

L'espagnol est la langue officielle dans tous les pays, sauf au Belize où la langue officielle est l'anglais. L'anglais est courant sur les côtes où il y a beaucoup d'ascendance africaine, tandis que les Indiens continuent à parler leur langue maternelle.

La religion principale est le catholicisme, mais l'évangélisme est en augmentation.


</doc>
<doc id="14397" url="https://fr.wikipedia.org/wiki?curid=14397" title="Gibraltar">
Gibraltar

Gibraltar (de l'arabe « جبل طارق », « "Djebel Tariq" », « le mont de Tariq » du nom de Tariq ibn Ziyad) est un territoire britannique d'outre-mer, situé au sud de la péninsule Ibérique, en bordure du détroit de Gibraltar qui relie la Méditerranée à l'océan Atlantique. Il correspond au rocher de Gibraltar et à ses environs immédiats et est séparé de l'Espagne par une frontière de.

Gibraltar est possession du Royaume-Uni depuis 1704. Les forces armées britanniques y conservent une présence relativement importante. Bien que la majorité de sa population y soit opposée, Gibraltar est revendiqué par l'Espagne. La question de Gibraltar est une cause majeure de dissension dans les relations hispano-britanniques.

Gibraltar fait partie de l'Union européenne (dans le cadre de laquelle il bénéficie d'un statut spécial) mais pas de l'espace Schengen. Ce statut est toutefois menacé par la procédure de retrait du Royaume-Uni de l'Union européenne qui a été déclenchée le à la suite du référendum du 23 juin 2016 organisé sur l'ensemble du territoire britannique. Cependant, les résultats locaux de la consultation dénotent que 96 % des Gibraltariens souhaitent rester au sein de l'UE, tout en espèrant obtenir un statut similaire à celui octroyé à Andorre ou au Liechtenstein.

Les habitants de Gibraltar sont les Gibraltariens et les Gibraltariennes.

Le territoire de Gibraltar comporte plusieurs sites ayant été occupés par les Néandertaliens. Le site de la carrière de Forbes a d'ailleurs livré, en 1848, le premier crâne correspondant à cette espèce, lequel n'a toutefois été reconnu comme tel qu'après la découverte du site de la vallée de Néander en Allemagne, vers 1856. Le site de la grotte de Gorham a également livré des industries moustériennes qui pourraient être parmi les plus récentes.

D'après la mythologie grecque, c'est Héraclès qui a érigé les colonnes d'Hercule composées des deux promontoires séparant l'Afrique de l'Europe : le mont Calpé en Europe et djebel Musa en Afrique. Dans l'Antiquité grecque, le rocher est aussi associé à Briarée, un des Hécatonchires.

Avant la conquête musulmane, le rocher de Gibraltar était appelé mont Calpé. Au début du , dans le cadre de la conquête musulmane de l'Espagne wisigothique, le chef Tariq ibn Ziyad y établit une tête de pont en Europe, donnant son nom au rocher.

Le site est conquis, en 1309, par le royaume de Castille, puis repris par le général mérinide Abd-el-Melek en 1333 expulsant les Castillans. En 1374, les Mérinides cèdent le rocher au royaume de Grenade. Gibraltar est définitivement reconquis par Ferdinand en 1492.

Ce territoire espagnol est pris par les forces anglo-néerlandaises de l'amiral George Rooke le et sa propriété (mais pas la souveraineté) est confirmée et reconnue par l'Espagne par le traité d'Utrecht en 1713. Une tentative espagnole pour reprendre Gibraltar a lieu de 1779 à 1781, lorsque l'Espagne déclare la guerre au Royaume-Uni dans le cadre de son alliance avec la France au cours de la guerre d'indépendance américaine. Cette période, connue sous le nom de « Grand siège », dura 3 ans.

En 1805, une épidémie de fièvre jaune tue un tiers des Gibraltariens.

Au début des années 1960, le gouvernement espagnol a soulevé la « question de Gibraltar » devant le Comité des Nations unies pour la décolonisation et l'Assemblée générale a adopté les résolutions 2231 de 1966 et 2353 de 1967, qui demandent le début des pourparlers entre l'Espagne et le Royaume-Uni pour mettre fin à la situation « coloniale » de Gibraltar tout en préservant les intérêts du peuple de Gibraltar. En réponse à ces résolutions, les autorités de Gibraltar ont fait appel du droit à l'autodétermination et le Royaume-Uni a organisé un référendum en 1967 pour les Gibraltariens, dans lequel 99,64% des électeurs ont exprimé leur volonté de rester sous la souveraineté britannique. En mai 1968, afin de protester contre l'organisation quelques mois plus tôt, le , d'un référendum « d'autodétermination » sur le rocher qui avait donné une écrasante majorité pour le maintien de la souveraineté britannique, le général Franco fait fermer la frontière entre l'Espagne et le rocher, qui ne rouvrira que le à minuit.

Depuis 1985, l'Espagne revendique toujours la même position, à savoir qu'elle exige le départ des Britanniques, et que le territoire lui soit rendu, avec abrogation des accords de 1705. L'Espagne n'est pas contre un statut d'autonomie du territoire, allant jusqu'à s'inspirer du statut de Hong Kong, la colonie britannique restituée à la Chine en 1997. 

Lors d'un vote appelé Brexit en 2016, les Britanniques ont décidé par référendum de quitter l'Union européenne, 

Le territoire a une superficie de . Il possède une frontière terrestre avec l'Espagne longue de (plus courte frontière terrestre du monde), et de côtes : il y a deux côtes, la côte est ("East Side"), où se trouvent deux baies, ' et ', et la côte ouest ("West Side"), où vit la majorité de la population.

Le climat méditerranéen favorise une végétation résistante de garrigue, maquis et pinède.

Le point culminant est le rocher de Gibraltar (rocher calcaire culminant à ), réserve naturelle peuplée par des macaques berbères, les seuls singes sauvages d'Europe.

Gibraltar n'a pas de ressources naturelles exploitées ; cependant, une usine de dessalement est aujourd'hui active à l'intérieur du Rocher.

Gibraltar est un des territoires les plus densément peuplés au monde .

Plus de de plantes à fleurs poussent sur le rocher de Gibraltar. Gibraltar est l’unique endroit où l’"", une espèce de crucifères à fleurs blanches, pousse dans la nature en Europe. Cette plante originaire d’Afrique du Nord est le symbole de la réserve naturelle du rocher de Gibraltar. L'olivier et le pin sont parmi les espèces qui poussent le plus communément sur le Rocher.

La majorité du Rocher est couverte par la réserve naturelle qui est l’habitat naturel de quelque , le singe le plus célèbre de Gibraltar. Néanmoins, les spécialistes insistent sur le caractère sauvage de ces singes. Ce sont les seuls singes sauvages d’Europe. Cette espèce, dont le nom scientifique est "Macaca sylvanus", est sur la liste des espèces en danger selon la liste rouge de l'UICN.

Les autres espèces de mammifères présents sur l’île incluent les lapins, les renards et les chauves-souris. De plus, dauphins et baleines sont régulièrement présents dans la baie de Gibraltar. Les oiseaux migrateurs sont très communs ; Gibraltar est terre d’accueil des seules perdrix gambra présentes sur le continent européen. Cette richesse de la nature est menacée par le développement urbain, le tourisme et les espèces de plantes invasives. Mais aussi par les espèces d’oiseaux et de chauves-souris susceptibles de mettre en péril l’équilibre naturel de la presqu'île.

Comme pour tout territoire britannique d'outre-mer, la reine Élisabeth est le chef de l'État ; elle est représentée par le gouverneur de Gibraltar. Le Royaume-Uni a gardé les responsabilités concernant la défense, la politique étrangère, la sécurité intérieure et les questions économiques. Le rôle du gouverneur est surtout symbolique : il ne participe pas à l'administration du territoire. Le gouverneur nomme le gouvernement après les élections. Il est responsable de la défense et de la sécurité à l'intérieur de Gibraltar (la "Royal Gibraltar Police").

Le Parlement de Gibraltar est composé de 17 membres élus pour un mandat de quatre ans. Le gouvernement est responsable devant lui.

Il y a trois partis représentés au parlement : les Sociaux-démocrates de Gibraltar, le Parti travailliste-socialiste de Gibraltar et le Parti libéral de Gibraltar.

Le plus important problème est la demande permanente de l'Espagne concernant le transfert de ce territoire. Les partis politiques et une grande majorité des habitants y sont opposés.

Gibraltar est toujours sur la liste officielle des territoires à décoloniser selon l'ONU.

Gibraltar fait partie de l'Union européenne depuis 1973, conformément au traité d'adhésion du Royaume-Uni, mais y bénéficie d'un statut spécial. Gibraltar n'est en effet pas soumis à l'obligation de prélever la TVA, et n'est pas non plus membre de l'union douanière. En outre, la politique commerciale de l'Union européenne, la politique agricole commune et la politique commune de la pêche ne sont pas applicables à Gibraltar.

Avant le référendum britannique sur le retrait du Royaume-Uni de l'Union Européenne, le ministre des affaires extérieures de l'Espagne a déclaré qu'en cas de Brexit, Gilbratar perdrait l'accès au marché commun à moins qu'une solution transitoire à base de souveraineté partagée avec l'Espagne ne soit mise en œuvre. De ce fait, le succès du Brexit a été compris comme un progrès facilitant la possibilité de faire flotter le drapeau espagnol à Gibraltar.

Après l'enclenchement du Brexit, le président du Conseil européen Donald Tusk évoque la question de la sortie de Gibraltar du Royaume-Uni. Le 2 avril 2017, la première ministre Theresa May affirme qu'elle ne céderait jamais cette enclave sans la volonté de la population.

Un texte présenté par Donald Tusk prévoit notamment qu' .

Invité au Royaume-Uni en juillet 2017, le roi d'Espagne Felipe VI a appelé à une négociation et à une entente des deux royaumes sur la question de Gibraltar.

Les activités militaires ont traditionnellement dominé l'économie de Gibraltar, le chantier de construction et de maintenance navale fournissant la majeure partie de l'activité économique. Leur part dans l'économie locale a cependant diminué, passant de en 1984 à en 2004.

L'économie de Gibraltar repose sur le secteur des services, principalement ceux en lien avec la finance et le tourisme. Grâce à son taux d'imposition sur les sociétés très faible et à l'appartenance de Gibraltar à l'Union européenne, un certain nombre de banques britanniques et internationales sont installées ou ont des filiales à Gibraltar, qui est devenu un centre de finances international. Cela a valu à l'enclave britannique de figurer jusqu'en 2009 sur la liste grise des paradis fiscaux de l'OCDE. Encore aujourd'hui, l'Espagne considère Gibraltar comme un paradis fiscal.

En 2013, entreprises étaient officiellement enregistrées à Gibraltar (sur un territoire d'à peine habitants).

Beaucoup de "bookmakers" et d'opérateurs de jeu en ligne ont également déplacé leur siège à Gibraltar.

En ce qui concerne le tourisme, Gibraltar est une escale privilégiée pour les bateaux de croisière. Le rocher de Gibraltar est une attraction populaire, en particulier parmi les touristes et les résidents britanniques installés sur la côte méridionale de l'Espagne. Toutes les marchandises et les services sont vendus sans taxe sur la valeur ajoutée, ce qui explique l'implantation de plusieurs grands magasins britanniques : Marks and Spencer, BHS, Dorothy Perkins, et la chaîne de supermarchés Morrisons.

Gibraltar a un PIB de plus de de livres ( de dollars) ; avec un PIB par personne de ().

La devise est la livre de Gibraltar, qui a une parité de un pour un avec la livre sterling, laquelle a aussi cours à Gibraltar. Par ailleurs la majorité des magasins et des restaurants acceptent aussi les euros, mais avec un taux de change défavorable. On notera toutefois que la livre de Gibraltar, elle, n'a pas cours en Grande-Bretagne.

En 2016, les autorités de Gibraltar ont fait part de leur inquiétude sur une éventuelle sortie du Royaume-Uni de l'Union européenne, estimant qu'une telle sortie menacerait le secteur financier local. 96 % des habitants de Gibraltar ont voté en faveur du maintien au sein de l'Union européenne lors du référendum du 23 juin 2016, à l'inverse de la majorité du Royaume-Uni.

L'aéroport international de Gibraltar a la particularité d'avoir son unique piste traversée par la route reliant Gibraltar à l'Espagne.

Contrairement au reste du Royaume-Uni, le sens de circulation routière s'effectue à droite de la chaussée comme en Espagne.

D'après le recensement de juillet 2005, Gibraltar compte . Les origines des habitants de Gibraltar sont espagnoles, britanniques et méditerranéennes (principalement génoises et maltaises). La religion principale est le christianisme, catholique en majorité et anglican. On trouve également une grande communauté juive, une population musulmane marocaine et un certain nombre de personnes originaires du sous-continent indien.

La langue officielle est l'anglais, utilisée au gouvernement et dans les affaires. Beaucoup de gens emploient également le llanito, un mélange d'espagnol et d'anglais. L'espagnol est parlé couramment par une grande partie de la population, et est souvent utilisé dans l'administration.

Le terme "llanito" (féminin : "llanita") définit aussi une identité propre à Gibraltar et visible lors de la fête nationale de Gibraltar, en particulier sur les tee shirt portés par les jeunes et arborant des slogans comme "« »" ou "« proud to be llanito »".

Gibraltar célèbre sa fête nationale le 10 septembre, date choisie pour commémorer le référendum de 1967, premier acte d'autodétermination du peuple de Gibraltar (rejet de l'annexion par l'Espagne). C'est pour beaucoup de gens une occasion de fête, chacun s'habille en rouge et blanc, couleurs nationales. Le rassemblement politique culmine avec le lâcher de trente mille ballons rouges et blancs représentant le peuple de Gibraltar.

En 2004, Gibraltar a fêté le tricentenaire de sa conquête par les Britanniques et, pour les honorer de leurs efforts et affirmer son attachement à la base navale, a attribué la liberté de la ville à la "Royal Navy". Comme geste politique de solidarité, la quasi-totalité de la population est descendue dans la rue, habillée en rouge, blanc et bleu, se tenant par la main pour former une chaîne humaine encerclant le rocher.

Les principales fêtes à Gibraltar sont :


La fédération de football de Gibraltar, membre à part entière de l'UEFA et de la FIFA, organise un championnat de football depuis 1896. Le vainqueur du championnat est qualifié pour la Ligue des champions, tandis que le vainqueur de la coupe nationale intègre la Ligue Europa. Les clubs les plus importants du territoire sont le Lincoln FC, Manchester 62, Glacis United et le College Europa. 

En marge de cette fédération Gibraltar possède aussi depuis 118 ans une équipe nationale de football qui se limitait jusqu'en 2013 à des compétitions méconnues du grand public. Enfin en 2013 la chance lui apparaît pour un premier match officiel le temps d'une rencontre éliminatoire dans le cadre de l'Euro 2016 contre la Slovaquie. 

Jusqu'en mars 2018 la plupart des matchs officiels FIFA à domicile se disputaient à Faro au Portugal. Le 27 mars 2018 elle remportent son premier match officiel au Victoria Stadium contre la Lettonie (1-0).

Les "British Forces Gibraltar" sont chargées de la défense de ce site stratégique. La "British Army" est représentée par le "Royal Gibraltar Regiment", à l'origine une force de réserve qui a été placée sur l'établissement permanent de l'armée britannique en 1990. Le régiment comprend des soldats à plein temps et à temps partiel recrutés sur place, ainsi que des militaires de carrière britanniques en provenance d'autres régiments.

La marine royale maintient un escadron. L'escadron est responsable de la sécurité et de l'intégrité des eaux territoriales britanniques de Gibraltar (BGTW). La base est appelée Rooke par les habitants de Gibraltar en l'honneur de George Rooke qui s'est emparé du rocher au détriment de l'archiduc Charles (prétendant au trône espagnol) en 1704. Elle est une base importante pour l'OTAN, les sous-marins nucléaires britanniques et des États-Unis s'y ravitaillant fréquemment. Les bateaux de la marine espagnole ne se ravitaillent cependant pas à cet endroit.

La base de la "Royal Air Force" (RAF) à Gibraltar fait partie du régiment royal de Gibraltar. Bien que les avions ne soient pas de manière permanente postés à Gibraltar, de nombreux avions de la RAF font des visites régulières.

On pense que le rocher est une base d'écoute de ROEM pour les télécommunications en direction de l'Afrique du Nord, et en raison de son emplacement stratégique elle reste toujours une base principale pour la NSA et pour le "Government Communications Headquarters".





</doc>
<doc id="14398" url="https://fr.wikipedia.org/wiki?curid=14398" title="Himalaya">
Himalaya

L'Himalaya ( de "hima" (neige) et "ālaya" (demeure), littéralement « demeure des neiges », népalais : हिमालय, hindi : हिमालय, ), ou chaîne de l'Himalaya, est un ensemble de chaînes de montagnes s'étirant sur plus de de long et large de 250 à , qui sépare le sous-continent indien du plateau tibétain dans le Sud de l'Asie. Au sens strict, il débute à l'ouest au Nanga Parbat au Pakistan et se termine à l'est au Namche Barwa au Tibet. Cet ensemble montagneux, délimité à l'ouest par la vallée du fleuve Indus et à l'est par la vallée du fleuve Brahmapoutre, couvre une aire d'environ .

Ainsi, l'Himalaya abrite 10 des 14 sommets qui culminent à plus de d'altitude, dont le mont Everest, le plus haut de tous ; les 4 autres se situent dans le Karakoram. Ces hauts sommets ont donné lieu à de nombreuses expéditions d'alpinistes renommés et ont tous été conquis.

La limite supérieure des forêts se situe à et la limite inférieure des neiges éternelles vers .

L'Himalaya fait partie d'un ensemble montagneux plus vaste encore que l'on désigne par « Aire Hindu Kush-Himalaya » (HKH), laquelle comprend les chaînes du Karakoram, de l'Hindou Kouch et du Pamir. Ce vaste ensemble chevauche huit pays et abrite plus de 140 millions de personnes.

L'Himalaya s'étend sur plus de , depuis le Nanga Parbat, au Pakistan, à l'ouest jusqu'au Namche Barwa à l'est. Il comporte trois chaînes parallèles disposées en ordre d'altitude et d'ère géologique.

La plus jeune des trois chaînes est dite « sub-himalayenne » (collines de Shivalik) et s'élève à environ d'altitude. Elle s'est formée par l'érosion depuis la formation de l'Himalaya. Parallèle à cette chaîne se trouve celle du « Bas Himalaya » dont l'altitude varie de à . Enfin, la chaîne la plus au nord, le « Grand Himalaya », est la plus ancienne des trois. Elle s'élève à plus de d'altitude et comporte un grand nombre des plus hauts sommets du monde, dont les trois premiers sont l'Everest, le K2, et le Kangchenjunga. Au total 164 sommets dépassent l'altitude de l'Aconcagua, le point culminant de la cordillère des Andes et la plus haute montagne en dehors de l'Asie. 

L'Himalaya couvre la majeure partie du Népal et du Bhoutan et occupe le sud la région autonome pakistanaise du Baltistan. Il constitue également le relief principal des États indiens suivants : le Jammu-et-Cachemire, l'Himachal Pradesh, l'Uttarakhand, le Sikkim (célèbre pour abriter le Kangchenjunga), le Bengale-Occidental et l'Arunachal Pradesh. À la frontière du Sikkim et du Bengale-Occidental s'étend l'arête de Singalila, dont les plus hauts sommets sont le mont Sandakfu, plus haut point de l'État du Bengale-Occidental à , suivi du pic Falut, qui culmine à . L'Himalaya occupe l'extrême nord du Myanmar. Enfin, il chevauche une très petite partie du sud-est du Tibet (cependant, le plateau tibétain ne fait pas partie de l'Himalaya).

"Nota" : Les sommets au Pakistan sont du côté pakistanais de la ligne de contrôle, mais sont réclamés par l'Inde.

D'après la tectonique des plaques, l'Himalaya est le résultat de la collision de la plaque indienne et de la plaque eurasienne.

Il y a 80 millions d'années, au Crétacé supérieur, l'Inde était une île, située à au sud du continent asiatique. Se dirigeant vers le nord à la vitesse de par siècle, elle a heurté la plaque eurasienne.

La portion de l'océan Téthys, qui les séparait, a totalement disparu il y a environ 50 millions d'années. Le sommet de l'Everest est fait de calcaire marin provenant de cette mer.

La plaque indienne continue à se déplacer à la vitesse constante d'environ par année, s'enfonçant sous la plaque eurasienne et provoquant ainsi l'élévation de l'Himalaya et du plateau tibétain.

L'Inde se comporte comme un poinçon qui emboutit et déforme la lithosphère asiatique sur plus de au nord de l'Himalaya. Le Tibet est coupé par de grandes failles qui absorbent cette déformation. Sur le côté est du poinçon indien, la chaîne de l'Arakan et les îles Andaman-et-Nicobar dans l'océan Indien ont aussi été créées par le mouvement entre l'Inde et l'Eurasie.

Cette intense activité tectonique rend la région très active du point de vue sismique. D'ailleurs, des séismes historiques de magnitude 8 et plus sont documentés sur le front sud de l'Himalaya.

La chaîne de l'Himalaya possède de très nombreux glaciers dont le Siachen, le plus long avec environ. D'autres glaciers sont aussi très célèbres : le Gangotri et le Yamunotri (Uttarakhand), le Nubra, le Biafo et le Baltoro (région de Karakoram), le Zemu (Sikkim) et les glaciers de Khumbu (région de l'Everest).

Les plus hautes régions de l'Himalaya sont recouvertes de neige toute l'année malgré leur proximité avec les tropiques, et les glaciers alimentent de nombreuses rivières qui se divisent en deux grands systèmes :


Les rivières de l'est du Tibet alimentent l'Irrawaddy, principal fleuve de Birmanie, qui se jette dans la mer d'Andaman.

Le Salouen, le Mékong, le Yangzi et le fleuve Jaune sont tous originaires du plateau tibétain, mais ils ne sont pas considérés comme de vrais fleuves de l'Himalaya. Pour désigner cet ensemble de fleuves, certains géographes parlent de fleuves "péri-himalayens".

La région de l'Himalaya comprend des centaines de lacs. La plupart se situent à une altitude inférieure à , et leur taille diminue en altitude. Le plus grand lac, le Pangong t'so, longe la frontière entre l'Inde et le Tibet. Il est situé à d'altitude et mesure de long sur de large. Un des lacs se trouvant en plus haute altitude est le Gurudogmar dans le Sikkim septentrional, situé à (source : SRTM). Un autre lac important est le lac Tsongmo, près de la frontière indo-chinoise au Sikkim.

Les lacs de montagnes sont connus par les géographes sous le nom de "laquets" s'ils ont été créés par une activité glaciaire. Les « laquets » se situent principalement proches des sommets de l'Himalaya, à environ d'altitude.

La chaîne de l'Himalaya a une forte influence sur les climats du sous-continent indien et du plateau tibétain. Comme elle empêche les vents secs et glaciaux qui soufflent vers le sud d'atteindre l'Inde, le climat de tout le sud de l'Asie est bien plus chaud que celui d'autres régions situées à la même latitude. L'Himalaya forme aussi une barrière empêchant les vents de mousson en provenance du Golfe du Bengale de progresser vers le nord, ce qui explique que le versant nord de la chaîne est aride tandis que son versant sud est humide parce que plus exposé aux pluies de mousson. Enfin, l'Himalaya serait aussi un des facteurs importants dans la formation des déserts en Asie centrale, tels que les déserts de Taklamakan et de Gobi.

L'Himalaya arrête les perturbations qui viennent de l'ouest et qui sévissent en Iran durant l'hiver. Ces perturbations ne peuvent pas aller plus loin, ce qui provoque d'importantes chutes de neige dans le Cachemire et de fortes pluies dans les régions du Penjab et du Nord de l'Inde. Tout en faisant obstacle aux vents du nord, la vallée du Brahmapoutre est propice à ces vents, ce qui cause une baisse des températures dans le nord-est de l'Inde et au Bangladesh. Le Brahmapoutre subit des vents particulièrement violents pendant la mousson.

La faune et la flore de l'Himalaya varient selon le climat, les précipitations, l'altitude et le sol. Le climat tropical domine au pied des montagnes, tandis que des neiges éternelles caractérisent les plus hauts sommets. La hauteur des précipitations annuelles augmente d'ouest en est sur le front de la chaîne. Cette variété du climat, de l'altitude, des précipitations et du sol génère des communautés végétales et animales et des écosystèmes tout aussi diversifiés.

Dans la plaine indo-gangétique à la base des montagnes, plaine alluviale drainée par les réseaux fluviaux de l'Indus, du Gange et du Brahmapoutre, la végétation varie d'ouest en est selon les précipitations. La région nord-ouest se distingue par ses forêts xérophiles à épineux qui occupent les plaines du Pakistan et du Pendjab indien. Plus à l'est, les forêts humides de feuillus bordent le cours supérieur du Gange au Uttar Pradesh et celles du cours inférieur occupent le Bihar et l'ouest du Bengale. Ces forêts sont soumises aux moussons, et les feuillus qui s'y trouvent perdent leur feuillage durant la saison sèche. Les forêts tropicales semi-sempervirentes, en raison du milieu plus humide dans la vallée du Brahmapoutre, occupent les plaines de l'Assam.

Au-dessus des plaines alluviales s'étend le Teraï, zone marécageuse saisonnière composée de sols sableux et argileux. Les pluies y sont plus abondantes qu'elles ne le sont dans les plaines, et le courant des rivières qui descendent de l'Himalaya ralentit dans la zone plane du Teraï où celles-ci débordent, y déposant ainsi un limon fertile pendant la mousson, puis elles baissent en saison sèche. La nappe phréatique du Teraï est élevée, et la partie centrale de la ceinture du Teraï se compose de savane et prairies du Terraï et des Douars, mosaïque de prairies et de steppe, de forêts sempervirentes de feuillus, dont certaines des plus vastes prairies au monde. Les prairies de la ceinture du Teraï constituent l'habitat du rhinocéros indien ("Rhinoceros unicornis").

Au-dessus de la ceinture du Teraï se trouve une zone sèche connue sous le nom de Bhabhar où le sol, poreux et rocheux, est constitué de débris venant des chaînes supérieures. Le Bhabhar et la partie inférieure des chaînes du Shivalik se caractérisent par un climat subtropical. Dans cette zone subtropicale, les pinèdes, principalement constituées de pin chir "(Pinus roxburghii)", occupent l'extrémité ouest, et les forêts de feuillus, où prédomine le sal "(Shorea robusta)", occupent la partie centrale.

En moyenne altitude, les forêts tropicales laissent place aux forêts de feuillus (à l'ouest) et près de l'Assam et de l'Arunachal Pradesh. Au-dessus, et principalement à l'est, se développent des forêts de conifères et de feuillus.

Au-dessus des prés ouest-nord-ouest-est, sur les plus hauts sommets de l'Himalaya, la toundra prédomine. Les alpages sont l'habitat des léopards des neiges "(Uncia uncia)", une espèce menacée.

Le terrain accidenté de l'Himalaya fait qu'il n'y a que très peu de routes possibles pour voyager dans la montagne. Les principales routes sont :
L'Inde a entrepris et continue à entreprendre la construction de nombreuses autoroutes nationales qui devront permettre aux 6 États himalayens du pays à être connectés au reste de la nation, cela permet le progrès économique de cette région mais aussi de stopper l'isolement de certains États ou régions (Arunachal Pradesh, Ladakh, Lahaul et Spiti). .


La taille gigantesque de l'Himalaya a limité les migrations humaines entre le nord et le sud. Les différences sont notables dès que l'on compare les religions, les coutumes et les langues de la Chine et de l'Inde. Les contacts ayant été peu nombreux, les conflits ont été évités : c'est ainsi que la péninsule indienne a échappé aux conquêtes mongoles de Genghis Khan.

De nombreux lieux de l'Himalaya ont une signification religieuse dans l'hindouisme et le bouddhisme :






</doc>
<doc id="14399" url="https://fr.wikipedia.org/wiki?curid=14399" title="Mandarin (langue)">
Mandarin (langue)

Le mandarin (; , « langue des officiels », , « parlers du Nord ») est une catégorie des langues chinoises parlée dans le nord et le sud-ouest de la Chine continentale. Envisagée comme une langue, c'est celle qui compte le plus grand nombre de locuteurs dans le monde. Il s'écrit au moyen des sinogrammes et on le transcrit maintenant le plus souvent en pinyin, mais aussi en zhuyin (bopomofo).

Même s'il est maintenant enseigné à tous les Chinois, certains Chinois plus âgés ne parlent pas le mandarin mais d'autres langues chinoises, comme le cantonais. Le mandarin, que les dirigeants communistes ont désigné comme la langue véhiculaire de leur nation entière en une version standardisée (dénommée 普通話 "pǔtōnghuà", « langue commune »), était d'abord celle de communautés chinoises du nord du pays. Bien que possédant une ancienne histoire littéraire, elle ne dérive pas de la langue écrite classique littéraire et artificielle (文言 "wényán"), abandonnée en 1919 après avoir été utilisée comme langue écrite officielle et littéraire pendant plus de deux mille ans : en effet, c'est d'une langue vernaculaire parlée (白話 "báihuà", « langue simple ») que le mandarin procède. 

En français comme dans les langues européennes, le "mandarin" fait référence à deux concepts distincts :

En 1956, c'est la variante de Pékin qui est promue au rang de langue officielle. On la considère souvent comme la variante standard de cette langue. Le mandarin de Pékin possède cependant des spécificités (comme l'utilisation fréquente de la rétroflexion vocalique notée au moyen du suffixe -er) et on dit souvent que les Pékinois ont un « accent ». Le mandarin d'un Taïwanais est donc un peu différent de celui d'un Pékinois.

En dehors de la Chine d'importantes communautés chinoises partagent cette langue, qui est enseignée dans de nombreux lycées et universités de par le monde.

Comme les autres langues chinoises, c'est une langue à tons. Elle utilise quatre tonèmes, qui changent le sens du mot, haut et plat, montant, descendant légèrement puis remontant (modulé) et descendant.

Les tons sont représentés en Chine par les accents sur les voyelles des syllabes de l'écriture romanisée dite pinyin et, à Taïwan, par les mêmes accents sur les graphèmes du bopomofo. On utilise aussi le numéro du ton à la fin de la syllabe quand les contraintes techniques empêchent d'entrer ou de lire les accents.

Au quotidien, « mandarin » fait généralement référence au mandarin standard ("Putonghua"/"Guoyu"). À l'étranger, le mandarin constitue un groupe de dialectes, dont l'intelligibilité mutuelle est variable. Ce groupe de parlers est l'objet d'une reconnaissance établie chez les linguistes mais qui n'est pas nécessairement reconnue en dehors des cercles académiques.

Lorsqu'on interroge un locuteur d'un dialecte mandarin, il ne reconnaîtra pas normalement qu'il parle une variante du mandarin mais sa variante locale (dialecte du Sichuan, dialecte du nord-est, etc.), en le considérant comme différent du « mandarin standard » "(putonghua)". Il n'aura pas nécessairement conscience que les linguistes classent leur dialecte comme une forme du "mandarin" au sens linguistique ou vu de l'étranger.

Comme pour d'autres langues chinoises, il y a une controverse sur le fait que le mandarin doive être considéré comme une langue ou un dialecte.

Le terme français provient du portugais "mandarim" (du malais "mentari" ou "mantari", lui-même emprunté au sanskrit "mantrin-", signifiant « ministre ») ; c'est la traduction du chinois 官話/官话 "guānhuà", qui signifie littéralement « langue des mandarins » (magistrats de l'Empire). Le terme "guānhuà" est souvent considéré comme une appellation archaïque par les sinophones d'aujourd'hui. 

En RPC, la langue en sa version standardisée est nommée 普通話/普通话 "pǔtōnghuà", « langue commune » ou "guóyǔ" 國語/国语, « langue nationale ». À Taïwan, la langue est officiellement nommée 國語/国语 "guóyǔ". Dans les communautés chinoises à l'étranger, particulièrement dans le Sud-Est asiatique, la langue est connue comme 華語/华语 "huáyǔ", « langue chinoise » (華/华 "huá" est un terme désignant principalement la culture chinoise). Le terme "hànyǔ" 漢語/汉语, bien que semblant désigner l'ensemble des dialectes de l'ethnie Han (incluant par exemple le cantonais), est en fait utilisé lui aussi, principalement, pour désigner la langue standard : ainsi le test international d'évaluation du chinois HSK (汉语水平考试 "hànyǔ shuǐpíng kǎoshì") concerne exclusivement la langue standard, écrite et orale.

Par leur prononciation (notamment la présence ou non de consonnes finales autres que "n"), les différents dialectes peuvent être plus ou moins proches du chinois archaïque. À cet égard, "hakka" et "cantonais" sont plus proches de la langue originelle que le mandarin.

La forme standard du mandarin s'appuie sur la prononciation propre aux locuteurs de Pékin (cf. Prononciation du mandarin), sans certaines particularités phonétiques. Il existe en effet une grande diversité dans les prononciations régionales, pour deux raisons principalement. La première est que l'aire géographique où ce langage est la langue maternelle de la plupart des locuteurs est si étendue que l'on rencontre nécessairement des variations de prononciations d'une zone à l'autre. Ces différences régionales sont de même nature que celles que l'on entend dans les diverses régions francophones de France, de Belgique, de Suisse, d'Afrique, du Québec, etc. La seconde raison est que nombre de locuteurs possèdent le mandarin comme seconde langue. Ces locuteurs le "contaminent" ainsi fréquemment avec le système phonologique de leur propre langue maternelle. Le mandarin de Taïwan, par exemple, est devenu une variante relativement homogène du mandarin standard tel que défini par les autorités éducatives. 

Le mandarin est parfois encore nommé de manière informelle "pékinois" (北京話/北京话 "Beǐjīng huà", 北京方言 "Beǐjīng fāngyán", « langue régionale de Pékin », ou 京片子 "Jīng piànzi"). À Taïwan, les partisans de l'indépendance de Taïwan insistent fréquemment pour que l'on utilise le terme de "Beǐjīng huà" à la place de 國語/国语 "guóyǔ" afin de promouvoir l'idée que le taïwanais devrait être leur langue nationale.

Les langues chinoises se sont développées à partir d'une langue commune nommée "chinois archaïque", puis "chinois médiéval".

La plupart des Chinois vivant en Chine du nord, au Sichuan, et, en fait, dans un grand arc de cercle allant du nord-est (Mandchourie) au sud-ouest (Yunnan), utilisent plusieurs dialectes du mandarin comme langue maternelle. La prévalence du mandarin dans toute la Chine du nord est principalement le résultat de la géographie, en particulier les plaines du nord de la Chine. En comparaison, les zones montagneuses et fluviales de la Chine du sud ont connu une plus grande diversité linguistique. La présence du mandarin au Sichuan est largement due à une épidémie survenue au . Cette épidémie, peut-être la peste noire, ayant décimé la population de cette région, elle a permis plus tard une colonisation par les Chinois du nord de la Chine et, indirectement, explique l'implantation d'une langue du Nord dans une région méridionale.

Il n'existe pas de distinction claire de quand le chinois médiéval se termine et quand débute le mandarin lui-même; cependant, le (中原音韻), un livre de rimes datant de la dynastie Yuan, est généralement considéré comme une pierre angulaire de l'histoire du mandarin. C'est en ce livre que l'on voit pour la première fois apparaitre de nombreuses caractéristiques du mandarin, telles la disparition de la consonne finale et la réorganisation des tons du chinois médiéval.

Jusqu'au milieu du , la plupart des Chinois vivant en Chine du sud ne parlaient pas le mandarin. Cependant, malgré la mixité sociale entre membres de l'administration et gens du peuple parlant divers dialectes chinois, le mandarin pékinois était devenu la langue prédominante au moins sous la dynastie Qing, dont la langue officielle était le mandchou. Depuis le , l'Empire avait créé des académies d'« orthoépie », 正音書院/正音書院 "zhēngyīn shūyuàn", dans une tentative de rendre la prononciation conforme au standard de Pékin. Leur succès s'était avéré très limité. 

Cette situation a évolué avec la création (en RPC et à Taïwan) d'un système d'éducation d'école élémentaire dévolu à l'enseignement du mandarin. En conséquence, le mandarin est devenu la langue la plus couramment parlée par la plupart des habitants de Chine continentale et de Taïwan. À Hong Kong, cependant, la langue de l'éducation et des formalités reste le cantonais standard, bien que le mandarin standard soit de plus en plus présent.

"Voir aussi : Syllabe en mandarin"

Une erreur commune consiste à croire que le mandarin serait le "dialecte pékinois". Il est vrai que la prononciation standard et que la grammaire de la langue enseignée s'appuie principalement sur le dialecte de Pékin, mais la notion de "mandarin standard" reste un concept assez flou car il représente plutôt un ensemble de langues "fabriquées" et imposées à la population, à qui l'on demande d'oublier ses prononciations régionales habituelles. L'accent des habitants de Harbin, autrefois en zone mandchoue, serait resté celui le plus proche du mandarin actuel. De la vaste aire qui s'étend de la Mandchourie au nord-est de la Chine jusqu'au Yunnan au sud-ouest, la langue maternelle de la plupart des habitants est le mandarin (dans son sens général), mais ces langues maternelles diffèrent toutes dans la prononciation, le vocabulaire et même parfois la grammaire, de la langue enseignée. 

Spécifiquement, conformément à la langue des natifs de Pékin, la plupart des locuteurs se conforment bien à la prononciation standard des consonnes rétroflexes (notées par "zh", "ch", "sh" et "ri" en pinyin), mais ils ajoutent souvent le "-er" final ─ communément utilisé comme diminutif ─ à des mots que d'autres locuteurs laisseraient tel quel. Ce trait dialectal est nommé 兒音/儿音 "éryīn", « prononciation avec "-er" ». Il existe également de nombreux éléments lexicaux largement attestés dans la zone pékinoise mais fort rares ailleurs. En plus de toutes ces différences, comme c'est le cas pour les langues occidentales, il y a plus d'un "accent" propre à Pékin, dépendant du niveau social, d'éducation, etc. 

Ces quelques exceptions mises à part, la prononciation locale des natifs de Pékin se conforme généralement très bien à la prononciation standard. En général, les prononciations locales des natifs d'autres aires du mandarin se différencient d'autant plus qu'elles sont éloignées de la capitale. Les personnes qui vivent à Tianjin ont aussi une prononciation assez standard. Les personnes qui vivent dans le nord-est de la Chine transforment couramment les syllabes commençant par ce que le pinyin note "j" en syllabes commençant par "g" ou "k" (conformément à l'étymologie, du reste) et ont des difficultés à prononcer les sons commençant par "r". Les personnes qui vivent dans les aires plus au sud transforment souvent les consonnes rétroflexes du mandarin standard : "zh" devient "z", "ch" devient "c", "sh" devient "s" et "r" se prononcent plutôt comme "z". Cette remarque est également vraie pour le mandarin parlé à Taïwan. Dans certaines régions les locuteurs ne font pas la distinction entre "l" et "n" (principalement quand ils ont le cantonais comme langue maternelle), et dans d'autres la finale vélaire "ng" est changée en "n". 

De plus, la langue enseignée emploie de nombreux tons légers (une absence de tonème qui rend la syllabe moins distincte ; cf. "Prononciation du mandarin") pour les secondes syllabes des mots composés (consulter "Sinogramme"), alors que dans de nombreuses régions, en particulier au sud, le ton des deux syllabes est clairement marqué.

D'un point de vue officiel, il y a deux mandarins, puisque le gouvernement de Pékin se réfère à celui du continent comme étant le 普通話/普通话 "pǔtōnghuà", « langue commune », alors que le gouvernement de Taipei nomme sa langue officielle 國語/国语 "kuo-yü" (en pinyin : "guóyǔ"), « langue nationale ». Officiellement, le "pǔtōnghuà" inclut les prononciations de plusieurs régions, alors que le "kuo-yü" est basé théoriquement sur les seuls phonèmes du mandarin de Pékin. La comparaison entre des dictionnaires des deux zones montre qu'il y a quelques différences substantielles. Cependant, les deux versions du mandarin scolaire sont assez souvent différentes du mandarin tel que réellement parlé, lequel subit l'influence de variations régionales. 

De plus, toutes les variantes du mandarin ne sont pas directement mutuellement intelligibles. 

Cependant, les locuteurs éduqués vivant dans les villes du Sud-Ouest telles que Guilin et Kunming parlent un "pǔtōnghuà" assez correct en plus de leur langue maternelle.

Dans la Chine du Nord, au Sichuan, et dans d'autres aires où la "langue du Nord" est parlée, ce qu'on nommerait « variantes locales du mandarin » est en fait l'une des langues maternelles de locuteurs de ces zones. La période d'éducation de masse du mandarin n'a pas effacé ces différences régionales antérieures. Dans le Sud, l'interaction entre le mandarin et les autres langues chinoises a créé des versions locales de la "langue du Nord", qui sont assez différentes du mandarin officiel standard tant pour la prononciation que pour la grammaire. Par exemple, le mandarin parlé à Taïwan par les étudiants qui parlent taïwanais (un dialecte de min du sud) ou hakka comme langue maternelle est généralement parlé avec une grammaire et un accent qui le rendent différent du "kuo-yü" standard, donnant naissance à une version du mandarin communément nommée "mandarin de Taïwan".

Bien que le mandarin soit considéré comme le dialecte standard, parler le mandarin sans accent local ou parler le mandarin à la place du dialecte local peut faire passer le locuteur pour un étranger ou quelqu'un d"'anormal". C'est pour cette raison que la plupart des locuteurs, dirigeants politiques y compris, ne se forcent pas à parler le mandarin avec l'accent standard officiel.

Il y a plus de mots polysyllabiques en mandarin que dans toute autre langue chinoise, à l'exception du shanghaïen. Ceci est dû en partie au fait que le mandarin a subi plus de modifications dans sa prononciation au cours de l'histoire que d'autres variétés du chinois, et devait dès lors composer avec davantage d'homophones (voir notamment : Le Poète mangeur de lions dans son repaire de pierre); de nombreux mots furent créés en les composant de deux ou plusieurs sinogrammes, ou en ajoutant un affixes tel "lao-" (老), "-zi" (子), "-(e)r" (儿／兒), et "-tou" (头／頭). Il existe cependant des mots qui ont été polysyllabiques depuis le chinois archaïque, tel "húdié" (蝴蝶, papillon).

Le pronom singulier en mandarin sont wǒ (我) "Je", nǐ (你) "Tu", nín (您) "vous (singulier)", et tā (他/她/它) "Il / Elle / (Il-neutre)", avec -men(们／門) ajouté pour donner le pluriel. De plus, il existe une distinction entre le pronom pluriel de la première personne zánmen (咱(们／門), qui inclut celui qui écoute, et wǒmen (我(们／門), qui exclut celui qui écoute. Les dialectes du mandarin ont une utilisation quasi-équivalente de ces pronoms, mais pas nécessairement les autres variétés de chinois (par exemple, le Shanghaïen utilise (侬／儂) "non" "tu" et 伊 "yi" "il / elle").

D'autres morphèmes que les dialectes mandarins ont généralement en commun sont les particules d'aspect et d'ambiance, tels "-le" (了), "-zhe" (着), et "-guo" (过／過). D'autres variétés de chinois utilisent par contre d'autres mots pour ces contextes (par exemple en cantonais 咗 et ).
De par le contact avec les cultures d'Asie centrale, le mandarin inclut certains mots d'origine altaïques, qui n'existent pas en d'autres langues chinoises, tel hútong (胡同) "allée". Les variétés méridionales de chinois ont par contre intégré des mots des langues tai ou des langues austronésiennes.

Depuis que les premiers Occidentaux sont entrés en Chine et ont tenté d'apprendre le mandarin (ou, plutôt, de traduire la Bible dans une volonté d'évangélisation) est apparu le besoin d'une romanisation permettant de noter les caractères chinois. Depuis, de nombreux systèmes de transcription phonétique ont été proposés. Le premier à avoir été globalement accepté est le système dit Wade-Giles, nommé d'après ses inventeurs du . Ce système est toujours utilisé aujourd'hui, mais pas en Chine continentale. Il se rencontre surtout dans des éditions anciennes de livres occidentaux, ainsi que pour un assez grand nombre de termes chinois lexicalisés dans les langues occidentales. L'École française d'Extrême-Orient a aussi utilisé un système nommé EFEO, maintenant caduc.

Au , les linguistes chinois ont proposé de nombreux systèmes de transcription. L'un d'eux propose même un nouvel alphabet syllabique, c'est le 注音符號/注音符号 "zhǔyīnfúhào", « symboles phonétiques » (ou, de manière moins formelle, "bopomofo"). Le plus fructueux de ces systèmes est cependant le 漢語拼音/汉语拼音 "hànyǔ pīnyīn", « méthode pour épeler phonétiquement le mandarin », plus souvent nommé "pīnyīn", qui a été accepté comme système de transcription officiel pour la langue chinoise par la RPC en 1958 et ensuite par les Nations unies ainsi que par d'autres organisations internationales. Pendant les années 1950, on a même pensé en Chine, sans succès, remplacer les caractères chinois par le pīnyīn. La chose n'est en effet pas faisable, à cause des nombreux cas d'homonymies dans la langue, homonymies dues à la structure syllabique particulière du mandarin.

On retrouve cette diversité de systèmes de transcription également à Taïwan. Le gouvernement central de Taïwan a en effet adopté le 通用拼音 "tōngyòng pīnyīn" en 2002 (variante du pīnyīn de RPC) tout en permettant aux gouvernements locaux de ne pas appliquer cette décision pour préférer leur propre système de romanisation. Le bopomofo ou "zhǔyīn" est utilisé pour l'apprentissage de la prononciation des caractères et de la grammaire dans les écoles. Les efforts visant à remplacer ce système en faveur du pīnyīn ont été bloqués à cause, principalement, de désaccords sur le type de pīnyīn à utiliser en remplacement ainsi que de l'effort très important à fournir pour corriger tous les documents pédagogiques existant et re-former complètement le corps enseignant.

Parmi les autres systèmes de romanisation, on compte aussi :

Au début du , le chinois écrit était une langue originale (chinois classique, écrit), et nettement distincte de la langue parlée. À l'origine, celle-ci fut pourtant proche de la langue parlée (chinois médiéval, parlé), mais s'en écarta avec le temps, un peu l'image de la place qu'occupa le latin dans les sociétés européennes de langue romane jusqu'au . 

La langue écrite, appelée chinois classique ou littéraire, est plus concise que la langue actuelle. À l'écrit, le problème des homonymes ne se pose pas et la langue ne comporte que peu d'ambiguïtés. Par exemple, 翼 (yì, aile) n'est pas ambigu en chinois écrit, mais possède environ 75 homonymes en mandarin (parlé). 

Pour une écriture formelle, tels des documents officiels, et ainsi que pour des textes plus littéraires, le langage écrit était plus économique et plus policé, tant pour l'écriture à la main qu'en imprimerie. 

Mais pour reproduire une conversation, le chinois classique n'est pas approprié. Même la transcription à l'écrit d'un professeur tel Zhu Xi (1130-1200) s'approchait de la langue parlée. Depuis au moins les pièces de théâtre de la dynastie Yuan qui narraient les épopées des Robin des Bois chinois jusqu'aux nouvelles de la dynastie Ming, telle "Shui Hu Zhuan" (水滸傳 / 水浒传 / Shuǐhǔ Zhuàn, "Au bord de l'eau"), ou la nouvelle de la dynastie Qing "Hónglóu mèng" (紅樓夢 / 红楼梦 / Hónglóu mèng, généralement traduite par "Le Rêve dans le pavillon rouge") et au-delà, ils développèrent une littérature proche du style oral (báihùa wénxúe). En de nombreux cas, cette langue écrite s'approche du mandarin parlé. Si les prononciations ne sont pas portées par les sinogrammes, l'écrit véhicule cependant la grammaire et le style en toutes les régions de langue mandarine. Ces écrits sont généralement exprimés en mandarin standard pour les lectures formelles.

Un acteur majeur de la littérature chinoise du début du , Hu Shi, écrivit une étude approfondie de cette tradition littéraire, appelée "Báihuà wénxué shǐ" (Une histoire de la littérature vernaculaire).

Le français a emprunté relativement peu de mots au mandarin ou aux autres langues chinoises. Notons cependant les mots "Kung-fu" ("Gōngfu", 功夫), "litchi" ("lìzhī", 荔枝), "ginseng" ("rénshēn" 人参, littéralement « plante-homme »), "longane" ("lóngyǎn" 龙眼, signifiant « œil de dragon ») et "kaolin" ("gāolǐng", 高岭, signifiant « hautes (chaines de) montagnes », d'où l'on extrayait la terre ("gāolǐng tǔ", 高岭土) et la roche ("gāolǐng shí", 高岭石)).

D'autres mots gardent une forte ressemblance mais ont évolué légèrement avec les langues des peuples qui les ont apportés en France, comme "badiane" ("bājiǎo", 八角, signifiant « 8 cornes », par le persan), "tofu" ("dòufǔ", 豆腐, par le japonais) ou "soja" ("shiyu", également par l'intermédiaire du japonais) ou encore "ketchup" ("koechiap", dans le dialecte d'Amoy par le malais et l'anglais).






</doc>
<doc id="14400" url="https://fr.wikipedia.org/wiki?curid=14400" title="Mandchourie">
Mandchourie

La Mandchourie (Mandchou : , translittération ; ) est un vaste territoire au nord-est de l'Asie, dont la plus vaste extension couvre le Nord-Est de la Chine (environ ), et l'Est de la Russie sur l'océan Pacifique (environ ).

Pendant l'invasion japonaise de la Mandchourie, l'empire du Japon y crée l'« État fantoche » du Mandchoukouo (, en japonais :  ; en kyūjitai : 滿洲國), en y mettant à sa tête l'ancien empereur Qing, Puyi. Cet empire fantoche prend fin en 1945, avec l'invasion soviétique de la Mandchourie.

Le terme "Mandchourie" peut désigner différentes régions de taille variable, qui sont, de la plus petite à la plus grande :

La Mandchourie est voisine de la Mongolie à l'ouest, de la Sibérie au nord, de la Chine au sud et de la Corée à l'est.

La Mandchourie a été le berceau des peuples xianbei, khitan et jurchen. Ces derniers ont fondé plusieurs dynasties en Mandchourie comme ans d'autres régions de Chine. La Dynastie Jin (1115-1234) qui pris le pouvoir sur les Khitans, fût écrasée par les Mongols à l'époque de Gengis Khan. La plus récente et la plus célèbre fut, lors de la Dynastie des Jin postérieurs, leur prise de pouvoir sur l'ensemble de Chine au (dynastie Qing, parfois Tsing), où ils furent rebaptisés Mandchous. Il donnèrent leur nom à la région, et gouvernèrent la Chine jusqu'à sa chute en 1911, a la révolution initiée par le soulèvement de Wuchang dans l'actuelle Wuhan.

Le Nord de la province est frappée par une épidémie de peste, provenant des marmottes de novembre 1910 à mars 1911 qui fait des centaines de milliers de victimes.

De 1912 à 1931, la région est dominée par la clique de Fengtian et se trouve sous domination économique du Japon. En 1929, elle est envahie pendant la guerre sino-soviétique.

Entre 1931 et 1945, la Mandchourie a constitué l'avant-poste de l'occupation de la Chine par l'empire du Japon, qui, dans le cadre de sa politique expansionniste, l'envahit en 1931 et y installa le nouvel État du Mandchoukouo, soit « pays du peuple mandchou », considéré comme un pays indépendant du reste de la Chine. L'ancien empereur Puyi fut mis au pouvoir par les Japonais, avec le titre d'Empereur du Mandchoukouo. En 1945, l'Union soviétique attaqua les Japonais en Mandchourie, mettant un terme à l'existence du Mandchoukouo.

Depuis 1949, en République populaire de Chine, la Mandchourie ne correspond plus à aucune région administrative. En revanche, le Nord-Est ou Dongbei chinois identifie, dans le langage courant, un territoire et une culture spécifique à l'intérieur du territoire chinois.

Certains noms de famille chinois, caractérisés par leur bivalence, gardent encore les origines mandchoues de leur ascendance. La ville de Harbin (哈爾濱, ha'erbin) est un exemple de toponyme d'origine mandchoue.




</doc>
<doc id="14401" url="https://fr.wikipedia.org/wiki?curid=14401" title="Guangdong">
Guangdong

Le Guangdong () est une province administrative de la République populaire de Chine située sur la côte sud-est du pays. Peuplée de 104 millions d'habitants d'après un recensement effectué en 2010, il s'agit de la province la plus peuplée (soit 7,79 % de la population chinoise continentale) et la plus riche de Chine. 

La préfecture provinciale, Canton, est un centre économique, culturel et politique majeur de la région. Elle comprend également la ville de Shenzhen, frontalière de Hong-Kong, plus grande ZES (Zone Economique Spéciale) et cœur économique industriel et manufacturier, tournée vers le reste du monde.

Le Guangdong tire ses richesses de la mer et du commerce. Plus de 70 % de ses habitants et richesses sont concentrés dans la mégalopole du delta de la Rivière des Perles, composée principalement de Canton (Guang Zhou), Shenzhen, Dong Guan, Fo Shan, mais également de Hong Kong et de Macao, régions administratives spéciales de la République Populaire de Chine bénéficiant d'une autonomie importante et centres financiers de l'Asie orientale.

À de Pékin, le Guangdong a bénéficié des investissements massifs des Chinois d'outremer, en particulier de Hong Kong et de Taiwan, de ses infrastructures portuaires et aéroportuaires et de son ouverture historique aux échanges commerciaux. 

La province du Guangdong a triplé de population en trente ans et est l'un des principaux moteurs du développement économique contemporain de la Chine depuis l'ouverture du pays à l'économie de marché dans les années 1985-87. Elle accueille plus de usines et ateliers, dont les fameuses usines de Foxconn à Shenzhen. 

En 2013, son PIB nominal atteint 815 milliards de dollars, plaçant la province au premier rang des provinces chinoises les plus riches. Elle participe également à hauteur de 12 % des exportations totales de la Chine. 

Comme chaque région de Chine, elle présente des spécificités assez marquées. Canton, ville historique, demeure le centre de la culture cantonaise. Sa langue majoritaire, le cantonais, une des grandes familles parmi les langues Han, se distingue clairement du mandarin. Elle est très chantante et a sept intonations au lieu de quatre en 'pékinois' (mandarin). 

"Guangdong" est une forme abrégée de "Guang nan dong lu" () qui signifie « région orientale d'expansion vers le sud ». Ce terme a été créé en 997 par Song Taizong de la Dynastie Song (960 — 1279). La route Guangnan lu, se divisait alors en deux sous les noms Guang nandong lu à l'Est et Gang nanxi lu () à l'Ouest, qui donna alors son nom à l'actuelle province du Guangxi.

Le terme "Canton", lui, désigne l'actuelle préfecture de la province, également appelée Guangzhou ; dérivant du portugais "Cantão", il peut être source de confusions.

Les historiens chinois font remonter les origines de la naissance de la future province du Guangdong durant la Dynastie des Qin (221-204 av. J.-C.). Le Premier empire chinois, alors cantonné aux régions du Nord du Yangzi Jiang, poursuit alors son extension vers le Sud et fonde la Commanderie Nanhai de Panyu localisé au sud de l'actuelle capitale provinciale. Zhao Tuo, commandant militaire et général chinois, fonde le royaume de Nanyue à la chute de la Dynastie Qin en 204 av. J.-C qui se proclame roi de ce nouvel État. Cet ancien royaume qui a pour capitale Panyu comprend alors à son apogée, en plus du Guangdong, les actuelles provinces du Guangxi ainsi qu'une partie du Tonkin. Il est d'ailleurs considéré par les Vietnamiens qui désignent ce royaume par la dynastie des Triệu comme une part de leur Histoire antique ; il convient également de noter que le terme de Vietnam dérive de la prononciation vietnamienne de Nanyue, "Nam Việt."

Dès le début du avant notre ère, les relations diplomatiques entre le royaume de Nanyue et la nouvelle Dynastie Han sont rétablies, Zhao Tuo prêtant allégeance à l'Empereur Gaozu des Han dès 196 av. J.-C., entérinant par ce serment le statut d'Etat vassal de Nanyue. En 113 av. J.-C., Zhao Xing, l'un des successeurs de Zhao Tuo, souhaite réintégrer le royaume au sein de la Chine en faisant allégeance à la dynastie Han ; il est alors renversé et tué par son premier ministre Lü Jia, qui installe sur le trône Zhao Jiande, frère de Zhao Xing. L'empereur de Chine Han Wudi profite des troubles au Nanyue pour envoyer son armée y « rétablir l'ordre ». En 111 av. J.-C., le Nanyue est battu et son territoire réannexé par la Chine.

Durant la période des Trois Royaumes, le royaume Wu fait du Guangdong sa propre province sous le nom de Guang, en 226.

Les paysages du Guangdong sont variés. Les collines et les montagnes couvrent plus de la moitié du territoire, mais la population et l'activité économique, comme dans le reste de la Chine dont l'économie est très lié à l'export, se concentrent surtout dans les plaines côtières : le delta de la rivière des Perles au centre et dans une moindre mesure Chaoshan à l'est et la région de Zhanjiang, à l'ouest.

Cette plaine deltaïque très peuplée constitue le centre du Guangdong et abrite Canton, la capitale régionale qui était autrefois le siège de nombreux comptoirs des colons Européens. Elle est parcourue de multiples cours d'eau dont la rivière des Perles, le plus important des fleuves qui donne naissance au delta. Hong Kong, paradis fiscal et centre financier de la région depuis le début , se trouve à proximité. Situé dans une zone au relief assez escarpé, il est situé à l'extrémité Sud-Est du delta et entretient des liens économiques particulièrement étroits avec la région, en raison de la colonisation britannique. À l'extrémité Sud-Ouest du delta, c'est Macao, ancienne région administrative portugaise, qui joue un rôle similaire.

Le delta connaît depuis des siècles de fortes densités de population. Toutefois, pour des raisons de politique et économique, son poids relatif dans l'économie et la démographie chinoise s'est nettement renforcé au cours des années 1980 et 1990. En effet, sous l'impulsion de Deng Xiaoping, différentes zones économiques spéciales (ZES) furent créées dans le delta, pour répondre à l'hégémonie économique de ces territoires. Shenzhen à la frontière avec Hong Kong et Zhuhai à la frontière avec Macao. Ces deux villes sont devenues en deux décennies deux des principales métropoles chinoises.

Sur le plan économique, on parle d'un « grand » delta, plus étendu que celui de la géographie physique. Constitué de Hong Kong, Macao et de neuf villes préfectures : Dongguan, Foshan, Guangzhou, Huizhou, Jiangmen, Shenzhen, Zhaoqing, Zhongshan, Zhuhai. Il correspond à l'aire dans lesquels les investissements hongkongais, taïwanais (avec notamment Foxconn, qui y assemble la majorité du matériel informatique de la planète), de la Chine continentale, mais aussi étrangers sont les plus importants.

L'est du Guangdong est souvent appelé "Chaoshan" de Chaozhou et Shantou, deux des grandes villes de la région. Il possède certaines caractéristiques communes avec le delta de la rivière des perles. C'est, comme lui, une région densément peuplée et traversée de nombreux cours d'eau. Toutefois, il présente certaines particularités culturelles qui le distinguent nettement du reste de la province. Par exemple, la langue dominante n'y est pas le cantonais mais le teochew, une variante du minnan parlé dans la province adjacente du Fujian. Bien que Shantou ait été l'une des premières zones économiques spéciales chinoises, la région n'a pas connu de développement économique aussi spectaculaire que le delta de la rivière des perles.

La troisième zone de forte densité est le sud-ouest de la province, qui comprend les villes de Maoming et Zhanjiang ainsi que la péninsule de Leizhou, rattachée administrativement à Zhanjiang.

Le système d'administration territoriale est pour l'essentiel le même que dans le reste de la Chine. Au niveau immédiatement inférieur à la province, la ville-préfecture est l'unité par défaut. Le Guangdong en compte dix-neuf. Le statut de ville sous-provinciale, qui confère une plus grande autonomie que celui de ville-préfecture, est réservé aux centres urbains les plus importants, en l'occurrence Canton et Shenzhen.

La province du Guangdong est la province la plus riche de Chine. Elle contribue à environ 12 % de la richesse nationale. Le Guangdong possède trois des zones économiques spéciales de la République populaire de Chine, c'est-à-dire Shenzhen, Shantou et Zhuhai.
L'activité économique est principalement secondaire et tertiaire.

La province de Canton absorbe plus de la moitié des investissements étrangers en Chine. Les salaires sont supérieurs de deux à trois fois à la moyenne nationale chinoise.

En 2005, le PIB total a été de 479,2 milliards de yuans, et le PIB par habitant de yuans. 

En 2013, le PIB a atteint 1000 milliards de dollars, soit un doublement en 8 ans et un montant supérieur à celui de la Turquie.

La région possède aussi la place boursière de Chine, la Bourse de Shenzhen, avec une capitalisation de plus de 514 milliards de dollars. Le Guangdong a réussi à gérer sa mutation de centre industriel et commercial de la Chine vers une économie plus orientée vers les secteurs à haute valeur ajoutée et les services, du fait de l'augmentation des coûts et du niveau de vie.

Comme les autres provinces côtières, la province du Guangdong est plus densément peuplée que la moyenne chinoise et sa densité dépasse 600h/km2. 

L'extraordinaire dynamisme économique de la province encourage depuis 30 ans (1985) une immigration massive en provenance des provinces intérieures chinoises, pour alimenter sa croissance industrielle. 

Fin 2006, il y avait 80,5 millions d'habitants enregistrés, mais ce chiffre est en dessous de la population effective, beaucoup d'immigrants n'ayant pas de permis de résidence. On estime la population réelle à 112 millions d'habitants, soit une croissance moyenne de 2,5Mh/an depuis 30 ans, ce qui fait du Guangdong la province la plus peuplée de Chine, à l'exception du Si-Chuan, en intégrant la municipalité spéciale et capitale : Chongqing.

La majorité de la population est d'ethnie han, les minorités étant principalement hmongs, zhuang, li et yao.

La diaspora chinoise originaire de cette province dans les pays occidentaux dépasse les 20 millions d'habitants. Ils ont été les premiers investisseurs et l'un des puissants leviers du développement accéléré de la province.

Selon une étude de 2012, seulement 7 % de la population se revendiquait d'une religion organisée, à savoir 6,2 % de bouddhistes, 0,8 % de protestants et 0,2 % de catholiques. 93 % de la population est soit irréligieuse, soit pratique le culte des ancêtres ou de la nature.

Selon les études génétiques non officielles du virus H5N1 de la grippe aviaire, le Guangdong serait la zone d'origine de ce virus.

La prostitution s'est développée à Shenzhen. Avec un très grand nombre de jeunes filles venues seules de la campagne, Shenzhen est aussi la ville où se retrouve la plus forte concentration de « bao er nai », concubines ou « deuxièmes femmes » chinoises. Les travailleurs en provenance de Hong Kong ont commencé à entretenir des femmes lors de leur passage en Chine continentale, avant que ce phénomène ne s'étende aux Taïwanais, aux Macanais et enfin aux Chinois continentaux eux-mêmes.

On parle différentes langues dans le Guandong. La plus répandue est le cantonais, traditionnellement parlée dans le centre et l'ouest de la province. Dans la région de Chaoshan, à l'est, on parle le teochew, une variété de minnan proche des langues du Fujian voisin. 

Le hakka est également parlé dans l'est de la province, particulièrement autour de Meizhou. Avec l'arrivée massive d'émigrants venus d'autres provinces, l'usage du mandarin s'est également répandu.

A Shenzhen et à Zhuhai, deux villes nouvelles surtout peuplées de migrants de l'ensemble du pays, le mandarin est la langue la plus parlée, avec tout de même certains apports du cantonais. Dans les zones administratives spéciales de Macao on parle plutôt portugais et cantonais, tandis qu'à Hong Kong on parle plutôt anglais et cantonais, mais sur ces deux territoires, le mandarin se développe rapidement en raison des récentes rétrocessions à la Chine et du passage de nombreux touristes venus de toute la Chine continentale.

Plusieurs arts martiaux sont originaires de cette région dont le Hung gar (boxe de la famille Hong), le Choy Lee Fut (boxe des Trois Maîtres), le Mojia (boxe de la famille Mo), le Xing Yi Quan (boxe du Cœur), le Liujiaquan (boxe de la famille Liu) ou encore le célèbre Wing chun (boxe du Printemps radieux).

La cuisine cantonaise est une des plus réputées de Chine. D'une grande diversité, elle est aussi la plus célèbre à l'étranger, les immigrants venant du Guangdong y étant nombreux.



</doc>
<doc id="14403" url="https://fr.wikipedia.org/wiki?curid=14403" title="Pékin">
Pékin

Pékin (en chinois : ; pinyin : "běijīng" , littéralement « capitale du nord »), également appelée Beijing, est la capitale de la République populaire de Chine. Située dans le nord du pays, la municipalité de Pékin (北京市, abrégé en 北京), d'une superficie de , borde la province du Hebei ainsi que la municipalité de Tianjin. Pékin est considérée comme le centre politique et culturel de la Chine, tandis que Hong Kong et Shanghai dominent au niveau économique.

D'abord ville périphérique de l'empire chinois sous les Han et les Tang, elle prend de l'importance lorsque les Jurchen, qui fondent la dynastie Jin, la choisissent comme leur capitale principale en 1153. Le prince mongol Kubilai Khan en fait de même sous le nom de Dadu (« grande métropole »), enfin les Ming y transfèrent leur administration en 1421, parachevant le choix de Pékin comme capitale de la Chine. Située à proximité de la Grande Muraille, Pékin abrite des monuments célèbres comme la Cité interdite et le Temple du ciel, qui sont inscrits au patrimoine mondial. De nombreuses réalisations architecturales et structurelles ont modifié la ville à l'occasion des Jeux olympiques d'été dont elle a été l'hôte en 2008. Beijing a été choisie par le CIO pour organiser les Jeux olympiques d'hiver de 2022 et sera la première ville à avoir accueilli les deux éditions de l'évènement sportif international.

Avec 21,15 millions d'habitants en 2013, Pékin est la deuxième ville la plus peuplée de Chine après Shanghai. La zone urbaine compte quant à elle 18 millions d'habitants. Le parler pékinois forme la base du mandarin standard. D'un point de vue économique, Pékin est la troisième ville de Chine par le PIB total derrière Shanghai et Hong Kong. Elle connaît une croissance économique très rapide, nettement plus de 10 % par an dans les années 2000. Un nouveau (CBD) est en construction.

La francisation « Pékin » aurait été introduite par un jésuite français au ou et est donc antérieure au changement de prononciation (palatalisation) qui survint pendant la dynastie Qing et qui transforma le [] devant un [] en [] (notée "j" en pinyin). Cette appellation est semblable à celle qu'ont adoptée certaines autres langues occidentales : "Pechino" [pekino] en italien, "Peking" en allemand et en néerlandais, ou encore "Pequim" (prononciation semblable à celle du français) en portugais, par exemple.

La ville de Pékin est située dans le nord-est de la Chine. Sa superficie totale est de .

La ville est située à une latitude de 54′20″N et à une longitude de 23′29″E. Elle se trouve donc à la même latitude qu'Ankara, la capitale de la Turquie, ou que Valence en Espagne.

Pékin se situe à de la mer de Bohai, à l'extrémité nord-est de la plaine de la Chine du Nord. Il y a des montagnes à l'ouest et au nord de Pékin. Plus au nord encore se trouvent des régions rattachées tardivement à la Chine. C'est la raison pour laquelle la Grande Muraille de Chine, qui marquait la limite du territoire chinois vers le nord, passe à proximité de Pékin.

La grande plaine du Nord de la Chine, où se trouve Pékin, est géologiquement une zone de sédimentation constituée d'alluvions, amenées depuis des millénaires principalement par le fleuve Jaune, la rivière la plus riche en boue dans le monde, et dont les contreforts septentrionaux et méridionaux de la péninsule de Shandong atteignent la mer Jaune. Elle se compose de lœss alluviaux et de sables, apportés par les différentes rivières en provenance des montagnes de l'Ouest du pays. Cela a formé au cours du temps le delta du Nord de la Chine.

D'un point de vue climatique (étés chauds et humides et hivers froids et secs avec des tempêtes de poussières) et phytogéographique (paysage proche des caractéristiques des steppes), la région de Pékin est semblable aux paysages de collines voisins.

La région est soumise à de fréquents séismes à cause de l'activité tectonique et le lent passage de la plaque indienne sous la plaque eurasienne continentale. La vitesse de la tectonique de ces plaques est en moyenne d'environ quatre centimètres par an. Ainsi, le , s'est produit à Tangshan, à à l'est de Pékin, un des séismes les plus catastrophiques du (voir le séisme de 1976 à Tangshan). D'une magnitude de 8,2 sur l'échelle de Richter, le bilan officiel du nombre de décès de la part du gouvernement de la République populaire de Chine fait mention d'un chiffre de avec une puissance du séisme officiellement annoncée à 7,8, mais certaines estimations avancent un chiffre de près de morts. Ce séisme a également donné lieu à des dommages à Pékin et dans d'autres villes de la région.

Pékin n'est pas très éloigné de la mer, mais celle-ci se trouve à l'est, alors que les vents dominants viennent plutôt de l'ouest, comme c'est souvent le cas dans l'hémisphère Nord. C'est la raison pour laquelle le climat de Pékin est de type continental des façades orientales des continents, comme celui de New York mais de manière encore plus marquée. Les hivers sont froids et secs et les étés sont très chauds et humides avec des indices de chaleur qui peuvent atteindre ou dépasser les pendant les fortes vagues de chaleur. Les différences de températures entre les saisons sont très fortes comme le montre le record maximal qui est de et le record minimal qui est de . Il pleut surtout en été, les pluies tombent sous forme de pluies chaudes. En effet juillet est le mois le plus pluvieux avec environ 13 jours de pluie en moyenne tandis qu'on compte seulement 2,8 jours de pluie en novembre.

Les températures moyennes vont de pour le mois le plus froid à pour le mois le plus chaud, avec une moyenne annuelle de . La pluviométrie atteint en moyenne par an, les pluies estivales sont dues à la mousson et s’abattent sous forme d'averses chaudes; la ville, qui connaît un climat sec, compte tout de même environ 70 jours de pluie par an.
Début 2008, les premières dunes du désert de Gobi se trouvaient à de la capitale. Le réservoir de Guanting, qui alimente Pékin en eau, a vu son niveau baisser de moitié entre 2002 et 2007.

La capitale chinoise est confrontée à de nombreux problèmes environnementaux. Il s'agit notamment de la pollution excessive des rivières, des problèmes dans l'approvisionnement en eau potable, de la forte pollution atmosphérique, de l'insuffisance des transports publics et de l'accroissement de la circulation automobile. Depuis le début des années 1990, le gouvernement fait davantage d'efforts pour la protection de l'environnement. Il a ainsi instauré des lois favorisant le recyclage, normalisant l'évaluation d'impact environnemental, l'efficacité énergétique et monitorant la pollution atmosphérique.

Depuis le , seules les voitures personnelles répondant à la norme Euro 2 pouvaient être enregistrées à Pékin. De nombreux autobus à moteur diesel ont été remplacés par des véhicules roulant au gaz naturel. En outre, le nombre de trolleybus électriques a atteint un total de à Pékin. Pour le transport ferroviaire, des prolongations du réseau de métro ont été entreprises. La pollution de l'air dans la métropole est plus grave. La concentration élevée de particules et les émissions de dioxyde de carbone sont un problème majeur.

La qualité de l'air, selon l'OMS, reste l'une des pires au monde. Les raisons en sont les nombreuses usines et centrales électriques en périphérie de la ville, ainsi que le nombre des transports et des ménages utilisant des carburants ou combustibles polluants. L'urbanisation rapide, la forte augmentation du volume du trafic et de la concentration d'industries dans l'agglomération ont conduit à pollution élevée. Le smog, les NOx et ses sulfates y constituent une menace sérieuse pour la santé publique de plus de 400 millions de personnes en Chine du Nord, les maladies respiratoires y étant de plus en plus importantes, surtout dans la capitale.

Pour améliorer la qualité de l'air, des règles d'émission plus strictes ont été adoptées. Depuis le , toutes les voitures neuves doivent répondre à la norme d'émission Euro 4, qui est obligatoire en Europe pour les voitures neuves depuis (Euro 5 est depuis entrée en vigueur en Europe en ), mais le scandale Volkswagen a montré que de nombreux véhicules récents polluaient en situation réelle plus qu'annoncé par le fabricant et bien plus que sur les bancs d'essai.

À partir de 2008, l'ambassade américaine mesure la pollution à Pékin.

Depuis octobre 2012, le gouvernement chinois installe des stations qui mesurent la pollution de l'air à Pékin. En janvier 2013, la capitale en a 35. Pékin n'a eu aucun plan d'urgence de l'air avant celui de janvier 2013.

La concentration des particules inférieures à de diamètre a battu le record des durant 3 jours en janvier 2013. L'OMS conseille un maximum de en moyenne sur . De nombreux vols ont été annulés à cause d'un manque de visibilité. Le froid intense avait alors provoqué une augmentation importante du chauffage au bois et au charbon. Selon l'AIE, la Chine consomme la moitié du charbon mondial.<br>De plus, l'absence de vent, le nombre des véhicules à énergie fossile, et les centaines d'usines près de Pékin ont empiré ce problème de pollution de l'air.

Le nuage acide de particules aurait tué personnes en 2012 pour Pékin, Shanghai, Canton et Xi'an. Selon une étude (juin 2013) faite par l’ONG Greenpeace et des experts américains, centrée sur 196 centrales à charbon de la périphérie de Pékin, cette pollution a fait mourir près de Pékinois en 2011, et environ dans la province du Hebei.

La municipalité de Pékin exerce sa juridiction sur seize subdivisions : quatorze districts et deux "xian".

Les premières traces d'habitations humaines à Pékin ont été retrouvées dans les cavernes de la Colline de l'os de dragon, près du village de Zhoukoudian dans le district de Fangshan, où l'Homme de Pékin vivait. Des fossiles d'homo erectus de ces cavernes remonteraient à ou . Durant le paléolithique, l'homo sapiens y a également vécu il y a environ . Des cités datant du premier millénaire avant notre ère ont été découvertes à proximité de Pékin. La ville de Ji (薊 "jì"), au sud de l'actuel Pékin, fut la capitale du puissant État de Yan (燕 "yān") à l'époque des Royaumes combattants (473-221 ). Qin Shi Huang (246-210 ) se rend maître de la ville et de tout le royaume. Devenu le premier empereur de Chine en 221 , il réorganise son vaste territoire en trente-six commanderies et Ji devient le siège de l'une d'entre elles. Ji, rebaptisée Youzhou sous l'empereur Wudi conserve une certaine importance sous les Han, mais il s'agit d'une ville périphérique par rapport aux grands centres chinois, situés plus au sud. Pendant la chute des Han, la ville devient le fief du seigneur de guerre Gongsun Zan. Sous la dynastie Tang, Ji devient le siège du jiedushi Fanyang, le gouverneur militaire de la région actuelle du Hebei. La révolte d'An Lushan part de là en l'an 755.

Au , Youzhou passe sous le contrôle des Khitan, peuple d'origine nomade. Ceux-ci fondent en 947 la dynastie Liao qui régnera sur le nord de la Chine et le sud de la Mandchourie jusqu'en 1122. Ils font de Pékin une de leurs quatre capitales secondaires en 938. En 979, l'empereur Taizong tente, sans succès de reprendre la ville. À cette époque, la région de Pékin, point de passage entre la Mandchourie et les centres politiques chinois traditionnels devient un point stratégique. Certains monuments actuels comme la mosquée de Niujie et le temple de Tianning datent de l'époque Liao.

En 1125, les Jurchen, un autre peuple nomade, conquièrent l'empire Liao et fondent la dynastie Jin. En 1153, ils renomment la ville Zhongdu (« capitale du centre ») et en font leur capitale principale. Pour la première fois, Pékin est capitale d'un grand empire, mais pas de toute la Chine. La ville s'agrandit considérablement, mais en 1215, elle est pillée par les Mongols de Gengis Khan. Soixante ans plus tard, en vue de préparer la dynastie Yuan, le prince mongol Kublai Khan, maître d'une grande partie de la Chine, décide de faire de Pékin sa capitale sous le nom Dadu (« grande capitale »). Par ailleurs, elle est appelée "Cambaluc" ou "Cambuluc" dans les récits de Marco Polo. Il fait reconstruire et agrandir considérablement la ville. Son centre bouge vers le nord, à son emplacement actuel. Il est centré sur ce qui est aujourd'hui la partie septentrionale du périphérique et vers le nord s'étendait entre les et périphériques. Il existe des restes de la muraille de l'époque Yuan encore debout, et ils sont connus sous le nom de Tucheng (土城 littéralement, « le mur de terre »). La construction de Dadu s'achève en 1293. La décision de Kublai Khan a grandement accru le statut de la ville située au nord de la Chine historique.

En 1368, Zhu Yuanzhang se déclare premier empereur de la dynastie Ming, puis prend le pouvoir de la cité. Le dernier empereur Yuan est renvoyé à Shangdu et les palais de Dadu sont anéantis. La ville est alors rebaptisée Beiping et la préfecture de Shuntian est établie autour de la ville. La capitale est à cette époque Nankin, située à un millier de kilomètres au sud de Pékin.

Cependant, en 1403, l'empereur Yongle renomme la ville "Pékin" et en fait le siège du gouvernement, ce qui la met symboliquement sur un pied d'égalité avec Nankin. En 1421, il y fait transférer son administration. Yongle, entreprend des grands travaux à Pékin : il fait construire notamment la Cité interdite et le Temple du ciel. Une fois la Cité interdite établie, l'empereur prend résidence à Pékin. À partir de 1421, Pékin, également connue sous le nom de Jingshi (京师), devient la capitale officielle de la dynastie Ming et Nankin est reléguée au statut de capitale secondaire. Ce système de deux capitales (Pékin ayant une plus grande importance) perdure durant la dynastie Ming. Ainsi, 13 des 16 empereurs Ming sont enterrés dans des tombeaux majestueux près de Pékin.
Au cours du , Pékin prend essentiellement sa forme actuelle et les murs de la cité sous l'époque Ming servent de murs de protection pour la ville jusqu'à l'époque moderne, au cours de laquelle ces murs sont détruits pour construire le second boulevard périphérique. On estime que Pékin a été la plus grande ville du monde entre 1425 et 1650 puis entre 1710 et 1825. D'autres constructions notables datent de l'époque Ming dont le Temple du Ciel, construit en 1420. Tian'anmen (porte de la Paix céleste), symbole actuel de la République populaire de Chine qui l'utilise sur son emblème, est construit pour la première fois en 1420, avant d'être reconstruit au cours de l'histoire. La Place Tian'anmen a été construite en 1651 et élargie en 1958. Les Jésuites construisent la première église catholique de style roman en 1652, près de la porte Xuanwu, où le jésuite italien Matteo Ricci a vécu. On leur doit aussi l'ancien observatoire. La moderne cathédrale de l'Immaculée Conception de Pékin a été construite en 1904 sur la cathédrale originelle.

La fin des Ming se produit en 1644 quand, pendant 40 jours, l'armée paysanne de Li Zicheng s'empare de Pékin et renverse le gouvernement Ming. Quand la puissante armée mandchoue arrive aux portes de la ville, Li et ses partisans abandonnent la ville si bien que les forces mandchoues, sous la direction du prince Dorgon, capturent Pékin sans livrer de combat.

Le prince Dorgon établit la dynastie Qing comme succession directe à la dynastie Ming, et Pékin devient la capitale de la Chine. Les empereurs Qing apportent quelques modifications à la résidence impériale mais, dans l'ensemble, les constructions Ming et la disposition générale restent inchangés. À cette époque, Pékin est connue sous le nom de "Jingshi", qui correspond au nom mandchou "Gemun Hecen". Le roman classique chinois "Le Rêve dans le pavillon rouge" se déroule dans les premières années du règne Qing (fin des années 1600).

À la fin de la période Qing, Pékin est le siège des légations étrangères durant la Révolte des Boxers en 1900. Certaines structures impériales importantes sont détruites pendant les affrontements, dont l'Académie Hanlin et l'Ancien palais d'été.

La Révolution Xinhai de 1911, visant à remplacer le règne Qing par une république, avait à l'origine comme intention d'établir sa capitale à Nankin. Après que le haut fonctionnaire Yuan Shikai a forcé l'abdication de l'empereur Qing à Pékin et assuré le succès de la Révolution, les révolutionnaires à Nankin acceptent qu'Yuan soit président de la nouvelle République de Chine et que la capitale soit établie à Pékin. Yuan accroît progressivement son pouvoir et devient en 1915 le nouvel empereur de la Chine, mais décède moins d'un an après le début de son règne. La Chine passe sous le contrôle des seigneurs de guerre locaux et les factions les plus puissantes s'affrontent lors de nombreuses guerres pour prendre le contrôle de la capitale Pékin. Suivant le succès de l'expédition du Nord du Kuomintang (KMT), qui a pacifié les seigneurs de guerre du Nord, Nankin est officiellement déclarée capitale de la République de Chine en 1928. Pékin est renommée "Beiping" (北平) en juin de la même année, ce qui signifie "Paix du Nord" ou "Nord pacifié".

Le , pendant la seconde guerre sino-japonaise, la ville devint partie intégrante de l'empire nippon lors de l'expansionnisme du Japon Shōwa. Pékin devient la capitale du gouvernement collaborateur chinois, un gouvernement fantoche qui dirige les zones chinoises du nord occupées par le Japon. Le gouvernement fusionne plus tard avec le gouvernement collaborateur de Wang Jingwei basé à Nankin.

Durant son occupation, l'armée japonaise implante à Pékin l'unité de recherche bactériologique 1855, une filiale de l'unité 731, où des médecins japonais pratiquaient des expérimentations sur des cobayes humains.

Le , pendant la guerre civile chinoise, les forces communistes rentrent dans Pékin sans résistance. Le octobre de la même année, le Parti communiste chinois, sous la direction de Mao Zedong, annonce à Tian'anmen la création de la République populaire de Chine et renomme la ville en Pékin. Quelques jours plus tôt, la Conférence consultative politique du peuple chinois avait décidé que Pékin deviendrait la capitale du nouveau gouvernement.

Au moment de la fondation de la République populaire, la municipalité de Pékin est constituée de la zone urbaine et des banlieues immédiates. La zone urbaine est divisée en plusieurs petits districts à l'intérieur de ce qui est maintenant le second boulevard périphérique. Les fortifications de Pékin sont démolies pour construire le second boulevard périphérique, qui est terminé en 1981. Cette route est la première construction ayant pour but de privilégier les automobiles par rapport aux vélos.

Pendant la Révolution culturelle, les gardes rouges rentrèrent dans les logements et , censés appartenir à des catégories .

Suivant la réforme économique de Deng Xiaoping, la zone urbaine de Pékin est largement étendue. Autrefois confinée dans les second et troisième boulevards périphériques, la zone urbaine de Pékin s'étend jusqu'aux limites des actuels cinquième et sixième boulevards périphériques, avec de nombreuses anciennes zones agricoles devenues des zones résidentielles et commerciales. Selon le rapport de 2005 d'un journal, la taille des nouvelles zones développées de Pékin est une fois et demie plus importante que l'ancienne ville de Pékin.

Wangfujing et Xidan sont développées en zones de commerce florissantes, alors que Zhongguancun devient un centre majeur de l'électronique en Chine. Dans les dernières années, l'expansion de Pékin s'est heurtée à des problèmes d'urbanisation, tels que des embouteillages, l'appauvrissement de la qualité de l'air, la perte de quartiers historiques et un influx significatif de migrants venant des diverses zones rurales du pays.

Pékin a été choisi pour organiser les Jeux olympiques d'été de 2008 par le CIO, le à Moscou. À cette occasion, l'urbanisme de la ville a subi d'importantes transformations. La destruction de nombreux quartiers a, selon certaines estimations, fait déplacer 1,5 million de Pékinois. Un parc public de , baptisé « forêt olympique », a été aménagé au nord du quatrième périphérique : il a été planté de , parmi lesquels beaucoup ont été déracinés en province.

La population enregistrée dans la municipalité de Pékin est constituée des personnes possédant le "hukou" (résidence permanente) ou un permis temporaire de résidence.

En février 2010, le nombre de résidents permanents et non permanents dépassait 22 millions, dont huit à neuf millions de non permanents. De plus, de nombreux travailleurs migrants vivent dans la capitale avec d'autres permis officiels de résidence.

En 2006, la population du cœur urbain de Pékin représentait 13,33 millions d'habitants, soit 84,3 % de la population totale de la municipalité, qui s'élevait à 15,81 millions à cette époque. En appliquant ce même ratio à la population actuelle de la municipalité, la population urbaine de Pékin serait de 18,54 millions d'individus. L'expansion urbaine continue sur un rythme élevé.

Après Chongqing et avant Shanghai, Pékin est la seconde plus importante des quatre municipalités en République populaire de Chine.

La plupart des habitants de Pékin appartiennent à l'ethnie Han. Les autres ethnies minoritaires présentes sont notamment les Mandchous, les Hui, et les Mongols. Un lycée en langue tibétaine existe pour les jeunes d'origine tibétaine, dont la quasi-totalité vient expressément à Pékin depuis le Tibet pour poursuivre ses études.

Une communauté internationale importante est installée à Pékin. La plupart des expatriés sont attirés par la forte croissance des secteurs des affaires et du commerce international, et d'autres par la culture à la fois traditionnelle et moderne de la ville. Beaucoup de membres de cette communauté vivent aux alentours du CBD de Pékin, à Sanlitun et à Wudaokou. Ces dernières années ont également connu un afflux important de Coréens du sud (estimé à environ en 2009) qui vivent à Pékin essentiellement pour des raisons professionnelles ou d'études. Beaucoup d'entre eux vivent dans les quartiers de Wangjing et Wudaokou.
Ces chiffres excluent les membres en service actif dans l'Armée populaire de libération.

À l'époque de la Chine impériale, Pékin est désigné pour la première fois comme capitale de l'Empire en 1153 sous la dynastie Jin. La ville perd son statut en 1368, au détriment de Nankin. Vers 1403, l'empereur Yongle transfère à nouveau la capitale à Pékin, un statut qu'elle ne perdra que pendant la période de troubles entre 1928 et 1949, date de la fondation de la République populaire de Chine par Mao Zedong.

De nos jours, Pékin constitue le véritable centre politique de la République populaire de Chine. On y trouve les sièges du gouvernement chinois. Ainsi, le Palais de l'Assemblée du Peuple est situé à l'ouest de la place Tian'anmen. Les autres bâtiments officiels (ministères ou commissions nationales) sont disséminés dans la ville.

En tant que capitale, la ville concentre également les ambassades de la plupart des pays étrangers.

L'organisation politique de Pékin est structurée dans un système à double-partie du gouvernement, comme toutes les autres institutions gouvernantes de la République populaire de Chine.

Le maire de Pékin possède officiellement le rang le plus élevé dans le gouvernement populaire de Pékin. Depuis que Pékin est une municipalité, le maire occupe le même niveau de préséance que les gouverneurs des provinces. Cependant, dans le système à double-partie du gouvernement de la ville, son importance est moindre que le secrétaire du comité municipal de Pékin du Parti communiste chinois, qui possède le vrai pouvoir effectif.

La position de secrétaire du comité municipal de Pékin () a toujours eu sa part de prestige et d'exposition nationale. Il est maintenant d'usage qu'il fasse partie "de facto" du Bureau politique du Parti communiste chinois, le plus important organisme dirigeant du pays. À cause du statut de Pékin en tant que capitale du pays, le secrétaire est également impliqué dans les principales décisions faites au niveau national. Xie Fuzhi, qui occupa le poste de 1967 à 1972, a ainsi eu une influence significative sur le gouvernement national au cours de la révolution culturelle, ayant pu être en partie à l'origine de la montée de la violence. L'influence de Chen Xitong (secrétaire entre 1992 et 1995) a été considérée comme une menace par la clique de Shanghai, qui le força à quitter ses fonctions et à être jugé pour corruption. Pour la célébration du de la République, Jia Qinglin (secrétaire entre 1997 et 2002) présida la cérémonie. Enfin, Liu Qi, secrétaire depuis 2002, a été le président du Comité d'organisation des Jeux olympiques de Pékin et prononça un discours lors des cérémonies d'ouverture et de clôture.

Pékin est une des villes les plus développées en Chine avec l'industrie tertiaire qui compte pour 73,2 % de son PIB. Il s'agit de la première ville postindustrielle en Chine continentale. La finance constitue la plus importante activité à Pékin. À la fin de l'année 2007, 751 entreprises financières étaient présentes à Pékin et généraient 128,6 milliards RMB de revenu, ce qui représentait 11,6 % des revenus globaux de l'industrie financière dans tout le pays. et 13,8 % du PIB de Pékin, soit le pourcentage le plus élevé de toutes les villes chinoises. Pékin héberge 26 entreprises du Fortune Global 500, soit le troisième résultat derrière Tokyo et Paris.
En 2009, le PIB de Pékin est de 1,19 billion de RMB (174 milliards de $), enregistrant une croissance annuelle de 10,1 %. Son PIB par habitant était de (), soit en augmentation de 6,2 % par rapport à l'année précédente. Les secteurs primaire, secondaire et tertiaire pesaient respectivement 11,83 milliards, 274,31 milliards et 900,45 milliards de RMB. La valeur disponible urbaine par habitant était de , soit en augmentation de 8,1 % par rapport à l'année précédente. Par habitant, le revenu pur des résidents ruraux était de , soit en augmentation de 11,5 %. Les revenus des 20 % de résidents aux plus faibles revenus ont augmenté de 16,7 %, soit 11,4 % de plus que ceux des 20 % plus riches. Le coefficient d'Engel pour les résidents urbains de Pékin a atteint 31,8 % en 2005 et celui des zones rurales 32,8 %, déclinant respectivement de 4,5 et 3,9 points de pourcentage par rapport à 2004.

Les secteurs des biens immobiliers et automobiles se sont fortement accrus ces dernières années. En 2005, 28,032 millions de mètres carrés de biens immobiliers se sont vendus pour un total de 175,88 milliards de RMB. On compte en 2010 à Pekin plus de 5 millions de véhicules particuliers.

Le quartier d'affaires de Pékin se trouve dans le secteur de Guomao. Il s'agit du nouveau quartier d'affaires qui accueille des sièges régionaux d'entreprises, des centres commerciaux et des logements de luxe. La rue de la finance, dans les secteurs de Fuxingmen et Fuchengmen, est traditionnellement le centre financier de la ville. Les secteurs de Wangfujing et Xidan constituent les principaux axes commerciaux. Zhongguancun, surnommé la "Silicon Valley de la Chine", est un centre majeur en électronique et informatique, mais également en recherches pharmaceutiques. Pendant ce temps, Yizhuang, situé au sud de la zone urbaine, est devenu un nouveau centre pharmaceutique, informatique et d'ingénierie des matériaux. La ville de Pékin est également réputée comme étant un centre de marchandises contrefaites : dans les marchés partout dans la ville on peut trouver toutes les nouvelles tendances de la mode ou des DVD, souvent commercialisées pour les expatriés ou les touristes étrangers.

La principale zone industrielle est Shijingshan, située dans la périphérie occidentale de la ville. L'agriculture est réalisée à l'extérieur de la zone urbaine de Pékin, avec essentiellement des cultures de blé et de maïs. Les légumes sont également cultivés dans les régions environnantes de la zone urbaine pour pouvoir fournir la ville.

Pékin voit sa réputation augmenter de plus en plus pour ses entreprises innovantes et des start-ups en pleine croissance. Sa culture est soutenue par une importante communauté d'entreprises chinoises et étrangères. Pourtant, Shanghai est souvent considérée comme le centre économique de la Chine, un plus grand nombre d'entreprises y étant présentes, alors que Pékin représente davantage le centre de l'esprit d'entreprise chinois.

Le développement de Pékin continue sur un rythme rapide, et la vaste expansion de Pékin a créé une multitude de problèmes pour la ville. Pékin est connu pour son smog tout autant que pour ses fréquents programmes d'économie d'énergie lancés par le gouvernement. Les Pékinois mais aussi les touristes se plaignent régulièrement de la qualité de l'eau et du prix des services de base tels que l'électricité ou le gaz naturel. Pour réduire la pollution de l'air, certaines industries importantes ont été sommées de réduire leurs émissions ou de quitter la ville. Shougang, une société métallurgique, jadis plus gros employeur et pollueur de la ville, a déplacé ses activités à Tangshan dans la province voisine du Hebei.

Grâce à son statut de capitale de République populaire de Chine, Pékin attire de nombreux étudiants de tout le pays, mais également étrangers. On y trouve en effet les universités les plus réputées de Chine, voire d'Asie.

Le Lycée français international Charles-de-Gaulle de Pékin est l'école française internationale à Pékin.

L'Université de Pékin, également connue en chinois sous le nom de "Beida", est une importante université de recherche. Fondée en 1898, elle devint à partir de 1920 un centre de la pensée progressive. De nos jours, les divers classements internationaux d'universités la placent régulièrement dans les meilleures universités chinoises et asiatiques. L'université est également reconnue pour l'architecture traditionnelle de son campus.

Au cours de son histoire, l'Université de Pékin s'est imposée comme centre de la liberté intellectuelle et a formé de nombreux penseurs chinois modernes. Ainsi, elle est à l'origine de plusieurs mouvements de pensée ayant marqué la Chine, dont notamment le Mouvement du 4-Mai ou les manifestations de la place Tian'anmen.

L'Université Tsinghua est fondée en 1911 sous le nom de "Tsinghua College (清華學堂 Qīnghuá Xuétáng)", puis de "Tsinghua School" en 1912, avant d'être appelée "Université Tsinghua" en 1928. Sa devise "Engagement d'auto-discipline et social" montre que l'université est profondément tournée vers l'excellence, le bien-être de la société chinoise et le développement global.

Les classements internationaux d'universités placent régulièrement l'Université Tsinghua dans les meilleurs établissements chinois et asiatiques. De nombreuses personnalités chinoises sont sorties de cette université, dont les Prix Nobel de physique Tsung-Dao Lee et Chen Ning Yang, mais aussi le président chinois Hu Jintao ou l'écrivain Li Jianwu.

Pôle d'attraction pour les étudiants étrangers également, Pékin permet à ces derniers d'étudier la langue et la culture chinoises à l'Université des langues et des cultures de Pékin. Bien que largement orientée dans ces disciplines, l'université accueille également des étudiants chinois spécialisés dans les langues étrangères et dans d'autres domaines tels que les sciences humaines. L'université forme également des professeurs de chinois langue étrangère. Il s'agit du seul établissement de ce type en Chine.

L'École centrale de Pékin, créée le , a ouvert ses portes en septembre 2005. Il s'agit de l'École sino-française d'ingénieurs de l'université de Beihang. L'école se fonde sur le projet et le modèle du Groupe Centrale en France.

En 2005, il s'agit du projet le plus ambitieux et le plus complet de la coopération franco-chinoise en matière d’enseignement supérieur. En France, il bénéficie du soutien des ministères de l’Éducation nationale, des Affaires étrangères, de l’Industrie et de l’Ambassade de France en Chine située à Pékin.

Le groupe Total a renouvelé le 17 novembre 2009 son accord avec l’École Centrale de Paris prolongeant son soutien à l’École Centrale de Pékin pour trois nouvelles années. L’objectif consiste à encourager la formation d’ingénieurs et de managers internationaux de haut niveau en Chine.

La "ferme de Qinghe" ou "Prison numéro 1 de Pékin" est un centre de détention du laogai ouvert en 1950.

Human Rights Watch indique que depuis 2003 de nombreux citoyens chinois ont été secrètement incarcérés, sans contact avec l'extérieur, dans des centres de détention illégaux surnommés « prisons noires ». Après cette révélation de Human Rights Watch, un porte-parole du gouvernement avait réfuté la présence de prisons noires en Chine. Or une enquête sur les prisons noires de Pékin a été publiée dans un magazine chinois dépendant du groupe de presse officiel Xinhua, le sujet n'est donc plus interdit.

Trois styles architecturaux prédominent dans la ville de Pékin. D'abord, l'architecture traditionnelle de la Chine impériale, dont les édifices les plus connus sont la porte Tian'anmen (qui est reprise sur l'emblème de la République populaire de Chine), la Cité interdite ou encore le Temple du ciel. Ensuite, il existe un style sino-soviétique dont les bâtiments ont été construits entre les années 1950 et 1970, avec des structures carrées, fades et mal conçues. Enfin, depuis l'ouverture de la Chine, des bâtiments d'inspiration moderne sont apparus, notamment dans le centre d'affaires et dans la rue de la finance de Pékin.

Depuis le début du , Pékin est sujet à une incroyable croissance de nouvelles constructions, montrant différents styles d'architectes internationaux. Un mélange d'architectures ancienne et moderne est visible à l'Espace 798, qui allie le design des années 1950 et le contemporain.

Il existe de nombreux théâtres (comme le Théâtre du Peuple), et le Beijing Concert Hall pour des spectacles musicaux. Le célèbre Opéra de Pékin est composé d'un mélange spécial de différentes formes d'art : le chant, la danse, l'acrobatie, l'expression faciale, et le jeu. L'histoire s'inspire principalement d'évènements historiques ou mythologiques. Cet art ancestral possède des codes bien définis et fixes.

En revanche, le théâtre contemporain est en mutation rapide, et propose depuis quelques années des traductions en chinois de pièces de théâtre occidentales et des productions expérimentales de dramaturges locaux.

Le théâtre parlé n'est apparu qu'au cours du dans les théâtres chinois. Son origine vient du théâtre d'art populaire de Pékin, qui est né avant la Révolution culturelle, et associe un jeu européen avec un message social clair. En 1968 cette forme d'art a été interdite par Jiang Qing, la troisième épouse de Mao Zedong, après seulement quelques pièces. Le théâtre et la plupart des cinémas ont été fermés pendant environ dix ans.

Le diffuseur China National Radio (CNR) a sa propre salle de concerts à l'acoustique excellente. Cette salle est également le studio de radiodiffusion, dans lequel les nombreux concerts sont enregistrés ou retransmis en direct à l'ensemble du pays. Elle abrite un des plus grands orgues de Chine, construit en Allemagne et installé en 1999 par le facteur d'orgue Gebr Oberlinger originaire de Windesheim, en Rhénanie.

Le grand théâtre national de Chine, conçu par le français Paul Andreu et inauguré en 2008, est en verre et en titane. Ce dôme peut accueillir en trois salles.

Il existe plus d'une centaine de musées à Pékin. Si la Cité interdite abrite le plus grand musée de la capitale en regroupant de nombreuses antiquités chinoises dans les différents palais et bâtiments de la cité, il existe d'autres musées pékinois tels que le Musée national de Chine, le Musée de la capitale, le Musée d'art de Pékin, le Musée militaire de la révolution populaire chinoise, le Musée géologique de Chine, le Musée d'histoire naturelle de Pékin, le Musée paléontologique de Chine, le Rose Museum et le Musée de l'imprimerie de Chine.

En plus des musées thématiques, Pékin possède plusieurs mémoriaux dédiés à des personnalités. Le plus célèbre d'entre eux est le Mausolée de Mao Zedong sur la Place Tian'anmen, mais le Grand timonier n'est pas le seul à avoir son mémorial à Pékin : Sun Yat-Sen, Cao Xueqin, etc. ont également le leur. Les touristes peuvent également visiter d'anciennes habitations occupées par des personnalités (le prince Gong, Lu Xun, Qi Baishi, Guo Moruo, etc.)

Chaque année, des millions de touristes chinois et étrangers se rendent à Pékin pour visiter ses nombreux monuments historiques célèbres.
Longue de selon les derniers relevés, la Grande Muraille constitue l'ouvrage le plus important en termes de longueur, surface et masse jamais construit par l'homme. Sa construction interrompue puis reprise selon les dynasties s'étale sur près de vingt siècles. Ce système de fortifications, composé de murs et de tours de défenses, était principalement destiné à protéger la Chine des envahisseurs, notamment mongols.

Même si la grande majorité de l'édifice se situe loin de Pékin, il est possible de visiter quelques tronçons de la Grande Muraille qui se trouvent sur le territoire de la municipalité, à quelques dizaines de kilomètres du centre-ville. Des agences organisent chaque jour des voyages en bus vers les sites de Badaling, Mutianyu, Jinshanling ou Simatai. Ces secteurs ont été restaurés afin d'accueillir en toute sécurité les touristes, mais la grande majorité de l'édifice ne jouit pas d'autant de soins et est laissée à l'abandon.

Construite sous l'ordre de l'empereur Ming Yongle au cours du , la Cité interdite fut la résidence principale des empereurs chinois, jusqu'au début du et la proclamation de la République de Chine. Sa construction dura 14 ans et réquisitionna environ un million d'ouvriers.

Sur une superficie de , ce palais possède selon la légende , mais en réalité. Les différents bâtiments constituaient les bureaux, jardins et résidences de la cour impériale chinoise. La cité peut être divisée en deux parties : le sud, la cour extérieure, était destiné aux cérémonies et fonctions officielles publiques : le nord, la cour intérieure, était réservée aux habitations de l'empereur et de sa cour.

De nos jours, une fois rénové, le palais est devenu un musée qui conserve les trésors impériaux de la civilisation chinoise ancienne. La Cité interdite a été inscrite au patrimoine mondial de l'humanité en 1987 par l'UNESCO.

Située au sud de la Cité interdite, entre la porte de la Paix Céleste (porte Tian'anmen) et la porte Qianmen, la place Tian'anmen est, avec ses , la troisième plus grande place du monde. Au cœur de la ville, elle est entourée de monuments rappelant l'histoire de la Chine : la Cité interdite, la porte Zhengyang donnant accès à la ville impériale, le Palais de l'Assemblée du Peuple, le Monument aux Héros du Peuple, le Mausolée de Mao Zedong et le Musée historique. Elle est le lieu privilégié pour toutes les cérémonies officielles (défilé militaire de la fête nationale, etc.), mais aussi, malgré un important dispositif de sécurité, pour les contestations (manifestations de la place Tiananmen...).

Le mausolée de Mao Zedong (毛主席纪念堂 - Máo Zhǔxí Jìniàntáng) est un monument sépulcral où est exposé le corps embaumé du dirigeant chinois Mao Zedong, ancien chef du politburo du Parti communiste chinois à partir de 1943 et président du comité central du PCC de 1945 à sa mort le .

Bien que le dirigeant chinois ait souhaité lui-même être incinéré, il fut décidé peu après son décès de conserver son corps et de lui construire un tombeau monumental en plein milieu de la place Tian'anmen à l'emplacement de l'ancienne porte sud de la Chine qui datait des dynasties Ming et Qing, et qui constituait l'entrée sud de la Cité impériale avec la ville tartare.

Six jours sur sept, des milliers de personnes se pressent pour observer le corps du dirigeant dans un sarcophage de verre. Pour diminuer les temps d'attente, les visiteurs ne peuvent pas s'arrêter. Il est de plus strictement interdit d'entrer dans le mausolée avec un sac ou un appareil photo.

Le Temple du Ciel est un complexe religieux datant du . Construit sous le règne de l'empereur Ming Yongle, il est constitué de plusieurs temples entourés d'un vaste parc, dont les plus importants sont le Hall de prières pour de bonnes récoltes, la Demeure du Seigneur du Ciel (entourée par un mur des échos), la Salle de l'abstinence ou l'Autel du ciel.

Lieu de religion, le Temple du Ciel était fréquenté par l'empereur (le "Fils du Ciel") afin de montrer son respect au Ciel. Les cérémonies de sacrifice y étaient très importantes.

Lieu hautement symbolique de la ville de Pékin, le Temple du Ciel a été inscrit par l'UNESCO à la liste du patrimoine mondial en 1998.
Le Temple Zhenjue date de la dynastie Ming.

Situé au Nord-est de la partie centrale de la ville, le Temple de Yonghe est le plus important temple de bouddhisme tibétain à Pékin. Construit à la fin du , le temple est initialement la résidence officielle des eunuques de l'empereur, avant de devenir une lamaserie en 1722. Sauvé de la Révolution culturelle par Zhou Enlai, le temple est ouvert au public depuis 1981, mais reste cependant un monastère toujours en activité et il est possible d'y croiser des moines.

Les hutong sont des quartiers populaires chinois constitués de maisons basses construites selon l'architecture traditionnelle : quatre bâtiments entourant une cour intérieure carrée. Souvent habitées par de vraies familles pékinoises, ces habitations bien souvent vétustes ont tendance à être remplacées par des résidences plus hautes. De tels quartiers existent encore au sud de la porte Qianmen et au nord du lac Qianhai, notamment.

La Cité impériale est une partie de la ville qui existait pendant les dynasties Ming et Qing. Elle comprenait un ensemble de jardins, tombeaux et divers bâtiments compris entre la Cité interdite dont elle était isolée par des douves de de large, et la ville tartare du Pékin historique dont elle était séparée par des murailles percées de cinq portes.

Les tours de la cloche et du tambour sont deux tours situées au nord du Pékin historique. Ces édifices avaient pour fonction d'annoncer les heures, jusqu'en 1924, lorsque l'empereur de Chine dut quitter la Cité interdite. La tour de la cloche abrite la plus grande et lourde cloche de Chine, qui pouvait être entendue à une distance de .

Le palais du prince Gong est une "siheyuan" traditionnelle constituée de et réputée pour son ornementation et son extravagance.

Le Pont Marco Polo est situé à de la ville de Pékin et enjambe la rivière Yongding. Il tient son nom de l'évocation que Marco Polo en a faite lors de ses voyages en Chine pendant le . Il fut également le théâtre de l'incident du pont Marco Polo qui a mené à la seconde guerre sino-japonaise. L'architecture de ce pont en arc est particulièrement connue pour sa balustrade composée de 281 piliers surmontés d'autant de lions en pierre.

En plus de nombreux temples bouddhistes, la métropole chinoise compte certains édifices religieux chrétiens et musulmans. Héritages de la mission jésuite en Chine, la cathédrale de l'Immaculée Conception, Pé-Tang et l'église Saint-Joseph de Wangfujing sont les monuments catholiques les plus remarquables de Pékin. Quant à la mosquée de Niujie, il s'agit de la plus ancienne (996) et la plus grande () mosquée de Pékin.

Contrairement à l'idée largement répandue qui assimile Pékin à une mégalopole très polluée et bétonnée, Pékin possède de nombreux parcs au cœur de la ville et dans sa périphérie.

Situé au nord-ouest de la Cité interdite, le parc Beihai s'étend sur , dont 39 sont composés d'étendues d'eau. Construit depuis le , il s'agit d'un des parcs les plus anciens et le mieux entretenu, malgré le pillage des nations occidentales au . Au milieu du lac principal (Mer du nord) se trouve une pagode blanche qui domine le parc.

En périphérie de la ville, il est également possible de visiter deux anciennes résidences impériales, qui servaient de refuge à l'empereur pendant les périodes estivales, afin d'échapper aux tumultes et à l'agitation de la capitale. Il s'agit de l'ancien palais d'été et du palais d'été.

L'ancien palais d'été était l'ancienne résidence des empereurs de la dynastie Qing. Ces derniers y menaient les affaires d'État, délaissant la Cité interdite pour les cérémonies formelles. Construit et aménagé sous le règne de différents empereurs, le palais était un parc constitué de nombreux bâtiments de style chinois mais aussi européen. Ainsi, sur plus de (8 fois la surface du Vatican), les palais réunissaient la plus grande collection d'antiquités chinoises de l'époque. En 1860, les troupes franco-britanniques pillent le palais et brûlent les bâtiments. La destruction du palais a ensuite continué dans l'histoire, notamment durant la Révolution culturelle. Désormais, l'ancien palais d'été représente pour les Chinois le symbole de l'humiliation infligée par les nations occidentales durant les guerres de l'opium et la période colonialiste.
Le Palais d'été est construit non loin de l'ancien palais d'été, sous l'impulsion de l'impératrice Cixi à la fin du , en réponse à la destruction de l'ancien palais. Sur une surface de , le palais d'été comporte de nombreux palais et temples, qui représentent de constructions. Le parc est principalement dominé par la Colline de la Longévité et le Lac de Kunming. Comme autres curiosités, on y trouve notamment un bateau de marbre, une réplique des rues de la ville de Suzhou ou le Long Corridor () recouvert de plus de .

Le Parc des Bambous Pourpres est situé dans le district de Haidian, au nord-ouest de Pékin.

La cuisine pékinoise compte de nombreuses spécialités, mais Pékin est surtout connue pour trois d'entre elles : le canard laqué de Pékin, la fondue chinoise et les jiaozi. Dans la rue, il est fréquent de trouver des Pingtang hulu (), sucreries à base de cenelles enrobées d'un glaçage.

Le canard laqué de Pékin est une spécialité servie dans le monde entier. Cependant, la façon de le déguster à Pékin diffère de celle des restaurants chinois à l'étranger. Le canard est laqué puis découpé en petits morceaux. Certains restaurants haut de gamme proposent même la découpe du canard devant le client, selon ses préférences, la peau croustillante étant séparée du reste de la viande. Il est ensuite servi avec des galettes dans lesquelles on roule la viande trempée préalablement dans de la sauce et de l'oignon vert. Le plat peut également être accompagné d'un bouillon préparé à partir de la carcasse de l'animal, et d'autres plats utilisant les abats.

La fondue chinoise est un plat qui consiste à faire cuire dans de l'eau bouillante de la viande coupée en fines lamelles, du poisson, des légumes et des pâtes. Le tout est accompagné de sauces diverses. À l'origine, la marmite centrale était chauffée avec des braises de charbon, mais pour des raisons économiques, cette tradition ne perdure plus dans la plupart des restaurants. C'est un dispositif électrique qui joue maintenant ce rôle.

Les jiaozi sont les ancêtres des raviolis italiens. À l'étranger, ils sont connus sous le nom de "ravioli chinois". La pâte de jiaozi est fabriquée à partir de farine de blé et d'eau. Il existe de nombreuses variantes de la farce (viande, poisson, légumes), mais la recette la plus populaire dans le Nord de la Chine consiste à faire une farce de viande de porc hachée avec de la ciboule chinoise, de l'œuf et des assaisonnements (vin de cuisine, sauce de soja aux champignons). Les jiaozi peuvent être dégustés directement ou accompagnés de vinaigre doux. Selon les régions, il est possible de mélanger au vinaigre de la sauce soja et/ou de la sauce pimentée. Les jiaozi sont traditionnellement bouillis dans de l'eau, mais ils peuvent être frits ou sautés.

À l'occasion des Jeux olympiques d'été de 2008, à Pékin, les infrastructures sportives se sont considérablement modernisées. Le parc olympique a ainsi vu la construction d'un nouveau stade de , le Nid d'oiseau, ou encore d'un centre aquatique, appelé le Cube d'eau. Si ces nouveaux sites atypiques par leur architecture ont été nouvellement édifiés pour les principales compétitions, d'autres sites sportifs de la capitale ont été rénovés et réaménagés, tels que le stade du Centre sportif olympique de Pékin, le gymnase du centre sportif olympique de Pékin, le stade des ouvriers ou le palais des sports des ouvriers.
La ville va accueillir les Jeux olympiques d'hiver de 2022.

Pékin héberge également de nombreux clubs sportifs professionnels, parmi lesquels :

L'équipe des Beijing Olympians de l'ABA, ancienne équipe de la CBA, a conservé son nom et maintenu une liste de joueurs chinois après avoir déménagé à Maywood en Californie en 2005.

Avec la croissance de la ville due aux réformes économiques, Pékin est devenu le plus important centre de transport de la République populaire de Chine, et même de l'est de l'Asie. Autour de la ville, on compte 5 anneaux périphériques, 9 voies rapides, 11 autoroutes nationales, 7 lignes ferroviaires et un aéroport international.

Le principal aéroport de Pékin est l'aéroport international de Pékin, situé à environ au nord-est de la ville. Après les rénovations pour les Jeux olympiques d'été de 2008, l'aéroport comporte trois terminaux, dont le terminal 3, qui est le plus vaste terminal au monde. Soixante-treize millions de voyageurs sont passés par l'aéroport international de Pékin en 2010, ce qui en fait l'aéroport le plus fréquenté de Chine et le second du monde, derrière Atlanta. La plupart des vols intérieurs et les vols internationaux courts partent de l'aéroport international, qui est le hub principal pour Air China. La capitale chinoise est reliée à la plupart des grandes villes du pays par des vols intérieurs réguliers. L'aéroport est desservi par une autoroute qui le met à environ du centre de la ville. Pour les Jeux olympiques, une seconde autoroute ainsi qu'une ligne ferroviaire liée au métro ont été mises en service.

Les autres aéroports de Pékin sont Liangxiang, Nanyuan, Xijiao, Shahe et Badaling. Nanyuan sert à une seule ligne commerciale, mais ces aéroports sont principalement destinés à des usages militaires et sont moins connus du public.

Pékin est depuis longtemps un important centre ferroviaire en Chine. Des lignes ferroviaires partent en direction de toutes les plus grandes villes de Chine : Shanghai, Guangzhou, Kowloon, Harbin, Qinhuangdao, Baotou, Yuanping, Chengde, Tianjin et, depuis juillet 2006, Lhassa. En 2009, la gare de Pékin enregistrait 117 arrivées quotidiennes de trains et la gare de l'Ouest, 220. Ces deux gares sont les principaux nœuds de transport de la ville. En août 2008, la gare du Sud rouvre au public et sert de terminus à la LGV Pékin - Tianjin qui relie Pékin à Tianjin avec une vitesse de pointe de , soit la ligne commerciale ferroviaire la plus rapide du monde. La gare dessert également d'autres lignes à grande vitesse, ainsi que des lignes internationales en provenance de Mongolie, Russie, Viêt Nam et Corée du Nord.

Plusieurs autres gares urbaines absorbent le trafic régulier de voyageurs : la gare du nord de Pékin, la gare de l'est de Pékin, Fengtai et d'autres gares plus petites. Il existe également d'autres gares desservant des zones suburbaines. Les trains de voyageurs en Chine sont numérotés en fonction de leur direction par rapport à Pékin.

C'est à Pékin qu'a ouvert la première ligne de métro chinoise, en 1971. Le métro de Pékin ne comptait que deux lignes jusqu'à l'inauguration de la ligne 13 en 2002. Depuis, le métro s'est étendu jusqu'à 16 lignes et 

Depuis 2015, le prix du ticket varie en fonction de la longueur du trajet. Avant 2015, ce ticket coûtait et permettait un nombre illimité de changements, à l'exception de la ligne express de l'aéroport, qui coûte par voyage. Pékin recense environ de bus et tramways, dont trois routes de transit rapide pour les bus. Il est possible d'utiliser la carte Yikatong dans tous les transports en commun. Cette carte utilise la technologie RFID pour être détectée dans les stations de métro et les arrêts de bus.

On peut trouver des taxis enregistrés dans toute la ville, même si de nombreux taxis non officiels existent également. En juin 2008, le prix de la course dans les taxis légaux commençait à pour les 3 premiers kilomètres puis par kilomètre supplémentaire. Après , la course est majorée de 50 % sur l'ensemble des kilomètres parcourus. Entre 23 h et 5 h du matin, la course est majorée de 20 %, commençant à et le kilomètre supplémentaire. Les courses de plus de entre et sont doublement majorées de 80 % (). La plupart des taxis sont des modèles Hyundai Elantra, Hyundai Sonata, Peugeot Citroën et Volkswagen Jetta.

Si, en 2017, un réseau de stations de vélos en libre service était en place depuis plusieurs années, des nouveaux réseaux de vélos, sans bornes, attachés uniquement par leur propre cadenas, dévérouillables par internet, via un QRcode se sont mis en place. Il est ainsi possible de prendre un vélo dans les nombreuses stations en comportant des ensembles de quelques dizaines à quelques centaines, et de les déposer où l'on désire, sur n'importe quel trottoir. Du fait de leur très grand nombre, cela rend également très aisé la prise d'un vélo à n'importe quel endroit de la ville. On retrouve également les vélos de ces compagnies utilisant ce principe, entre autres à Tianjin et Nanchang. Il y a principalement quatre compagnies à Pékin que l'on distingue par les couleurs des vélos, jaunes, bleus, oranges, ou verts.

Ce nouveau service correspond à la quatrième exposition internationale de bicyclette et d’extérieur de 2017 et la fête des bicyclettes d’extérieur.

De nombreuses voies rapides sillonnent Pékin. Une des particularités du réseau routier urbain est la présence de cinq boulevards périphériques concentriques autour du centre ville.

Pékin est connecté par des autoroutes à toute la Chine en tant que partie du tronc du réseau routier national. La capitale compte cinq boulevards périphériques concentriques autour du centre ville et 11 autoroutes nationales. Les périphériques ont une forme plutôt rectangulaire que circulaire. Héritage de la Chine ancienne, la plupart des routes à Pékin sont dirigées selon les points cardinaux.

Le trafic urbain dans Pékin est dépendant de cinq boulevards périphériques (环路) qui entourent successivement la ville et dont le centre est marqué géographiquement par la Cité interdite. Le premier boulevard périphérique n'est pas officiellement défini, correspondant plus exactement aux remparts de la Cité interdite. Le second périphérique est localisé dans le centre ville de Pékin et constitue une boucle artère, saturé à longueur de la journée. Le troisième périphérique marque plus ou moins la limite entre la ville et sa banlieue, également très fréquenté. Le quatrième périphérique est plus éloigné du centre, il relie les zones résidentielles moins denses au quartier universitaire de Pékin (Université de Pékin, Université de Tsinghua) et le Parc Olympiques de Pékin. Les boulevards périphériques ressemblent de plus en plus à des autoroutes en s'éloignant de centre, les périphériques 5 et 6 étant d'ailleurs des autoroutes municipales. Les autoroutes menant au reste de la Chine sont généralement accessibles à partir du troisième boulevard périphérique, formant comme une toile d'araignée.
L'un des plus grands soucis de la circulation de Pékin réside dans ses embouteillages, apparemment omniprésents, bien que ces dernières années, des systèmes de transport intelligents aient été mis en œuvre dans de nombreux domaines pour tenter d'atténuer le phénomène. La circulation dans le centre ville est souvent engorgée, surtout aux heures de pointe. Même en dehors des heures de pointe, plusieurs routes sont toujours obstruées par le trafic. Les routes de la région urbaine périphérique et les grands axes, particulièrement près de l'avenue Chang'an, sont généralement cités comme des zones de congestion élevée.

La cause principale des problèmes de circulation à Pékin est le développement relativement faible des réseaux de transport publics. Le métro de Pékin et ses 16 lignes pour 20 millions d'habitants est régulièrement cité. En comparaison, New York dispose de 26 lignes de métro pour 8 millions de citoyens. De plus, la disposition du dessin urbain de Pékin complique davantage la situation du réseau de transport. L'application inégale des règles de circulation et l'agressivité au volant accentuent encore le problème. Les autorités de Pékin affirment que les embouteillages provenaient peut-être des Jeux olympiques d'été de 2008. Depuis 2008, la ville met en place des voies de bus qui ne peuvent être empruntées que par des bus.

L'avenue de Chang'an (littéralement Rue de la Paix éternelle) traverse le centre de Pékin en passant par la place Tian'anmen. Il s'agit de la principale route de la ville.

La ville de Pékin est jumelée ou a signé des accords de partenariat avec de nombreuses villes dans le monde :







</doc>
<doc id="14404" url="https://fr.wikipedia.org/wiki?curid=14404" title="Canton (Chine)">
Canton (Chine)

Canton (du portugais "Cantão") ou Guangzhou ( , ) est la capitale de la province du Guangdong dans le sud de la Chine. Elle a le statut administratif de ville sous-provinciale de la République populaire de Chine. Avec près de 12,7 millions d'habitants (dont résidents urbains sur un territoire de ), c'est la troisième ville la plus peuplée du pays derrière Shanghai et Pékin, et la première du Sud de la Chine. Avec les villes de Shenzhen, Foshan, Dongguan, Zhongshan, et Jiangmen, elle forme la mégalopole chinoise du delta de la Rivière des Perles, grande agglomération s'étirant sur près de et rassemblant plus de 50 millions d'habitants.
Elle a accueilli les Jeux asiatiques de 2010.

Selon la légende, Canton est la ville des chèvres descendues du ciel avec des Immortels, d'où la périphrase chinoise de « cité des Cinq Béliers » pour la désigner, béliers qui sont en fait des chèvres.

Canton, ou Guangzhou, fut à ses débuts dénommée Panyu (Chinois: 番禺; Jyutping: Pun1 Jyu4), un nom emprunté à la dénomination de deux montagnes entourant la ville actuelle, Pan et Yu.
Son histoire commence lors de la conquête de la région durant la dynastie des Qin. Panyu commença son expansion lorsque la ville devint la capitale du Royaume Nanyue (南越) en 206 av. J.-C., ce dernier incluant à l'époque une partie de ce qui constitue aujourd'hui le Vietnam.
La dynastie des Han annexa le Royaume Nanyue en -111 et Panyu devint une capitale de la province du Guangdong. En 226 , Panyu devint le siège de la préfecture de Guang (广州; Guangzhou). Son nom fut changé en "Guangzhou" (廣州) en 226.

Sous la dynastie Tang (618-907), la société chinoise s'internationalisa avec l'afflux de marchands étrangers qui fit suite au rétablissement du contrôle chinois sur les routes de la soie, après les conquêtes militaires de l'empereur Taizong (626-649). Canton, comme d'autres grandes villes telles que Chang'an ou Luoyang, ainsi que bien d'autres cités marchandes, accueillit des communautés étrangères. Originaires pour la plupart d'Asie centrale, ces dernières introduisirent de nouvelles religions ainsi que d'autres traditions culinaires, musicales et artistiques. Au , la population étrangère de la ville de Canton était estimée à personnes.

Des pirates arabes et perses mirent à sac Canton (connue d'eux sous le nom de Sin-Kalan) en 758, selon un rapport du gouvernement local du 30 octobre 758, ce qui correspondait à la journée Guisi (癸巳) du neuvième mois lunaire dans le premier année de l'ère de l'empereur Suzong Qianyuan de la dynastie Tang. Du au , il a existé à Guangzhou un quartier des étrangers, abritant notamment des habitants venus du golfe Persique issus de la mise à sac de la ville de 758.

En 1514, Canton vit arriver par la mer les Portugais. Ils furent les premiers Européens à arriver dans cette région et établirent dès 1517 un monopole sur le commerce extérieur grâce à leur comptoir commercial. Ils s'installèrent de façon permanente dans le delta de la rivière des Perles. Ils furent ensuite expulsés de Canton (Cantão en portugais), mais purent garder l'utilisation de Macao comme base commerciale, en y créant une colonie, puis une ville en 1557.
Durant un siècle entier, ils gardèrent un quasi-monopole sur le commerce extérieur de la région, jusqu'à l'arrivée des Hollandais au début du .

Après le déclin portugais, d'autres nations européennes tentèrent de s'implanter dans la région afin de commercer avec la Chine.

Les Britanniques d'abord puis les Français à partir de 1685 s'établirent à Canton avec la Compagnie française des Indes orientales.

Canton fut l'un des cinq ports ouverts par le traité de Nankin, signé en 1842. Celui-ci marquait la fin de la première guerre de l'opium.

La ville fut bombardée conjointement par les Britanniques et les Français en 1858, au cours de la seconde guerre de l'opium. Le palais du vice-roi fut à cette occasion totalement détruit.

Les Missions Étrangères de Paris y établirent un vicariat apostolique, initialement confié à Monseigneur Guillemin. Ce dernier fit construire la Cathédrale du Sacré-Cœur qui existe encore.

Les autres ports ouverts à cette occasion furent Fuzhou, Xiamen (Amoy), Ningbo et Shanghai.

L'État français commanda en 1874 au sculpteur Vital-Dubray une statue en bronze, "L'Ange funèbre", pour la décoration d'une chapelle élevée dans le cimetière chrétien de la ville, à la mémoire des soldats morts pendant l'expédition de Chine. Cette statue a figuré au Salon de 1876 ().

Au cours de l'invasion japonaise, la ville subit dès l'automne 1937 de violents bombardements stratégiques sur des objectifs civils, conduisant à une résolution de blâme de la Société des Nations à l'encontre du Japon. L'armée impériale y implanta également l'unité de recherche bactériologique 8604, une filiale de l'unité 731, où des médecins japonais pratiquaient des expérimentations sur des cobayes humains.

Elle a été l'une des premières villes à s'ouvrir aux investissements étrangers du début des années 1980. La proximité de Hong Kong a favorisé l'émergence de tout le Guangdong.

La foire internationale de Canton, qui se tient deux fois par an (avril et octobre), est l'une des plus grandes foires commerciales du monde. On y négocie aussi bien du textile que de l'électronique.

La population est passée de habitants d'après le recensement de 2001 à d'après le recensement de 2003, et en 2008.

Depuis les années 2000, la présence française se renforce dans la ville de Canton et dans la province du Guangdong, comptant plus de 350 sociétés françaises implantées principalement dans les secteurs industriels et des services, d'après le Consulat Général de France à Canton , et plus de 2000 Français expatriés.

Le secteur des vins et spiritueux prend également son essor avec la tenue du salon Interwine deux fois par an (mai et novembre), suivant la foire internationale de Canton.

Situé dans la partie centre-sud du Guangdong, Canton s'étend de 112° 57' à 114° 03' de longitude E et 22° 26' à 23° 56' de latitude nord. La ville fait partie de la mégalopole du Delta de la rivière des Perles et le centre-ville est situé à côté de la montagne Baiyun, qui est localement dénommé «le poumon de la ville (市肺). La superficie totale de l'entité administrative de la ville est de 7 434,4 km², dont 10 districts qui occupent 3 843,43 km², soit 51,7 % du total, tandis que deux districts-villes occupent le reste.
L'élévation de la préfecture augmente généralement du sud-ouest au nord-est, avec des montagnes formant l'épine dorsale de la ville, et l'océan comprenant l'avant.

La ville est située en bordure de la rivière des Perles, à une centaine de kilomètres de l'embouchure de son delta.

Le climat cantonais est à l'origine de l'appellation climat subtropical humide (dit aussi « climat chinois »), un type de climat localisé dans une partie de la Chine, du Japon, dans le sud des États-Unis, le nord de l'Argentine, l'est de l'Afrique du Sud et le sud-est de l'Australie. Il est marqué par une forte humidité avec une pluviométrie annuelle de , des hivers doux avec une température mensuelle de en janvier et des étés chauds et moites avec une température mensuelle de en juillet. Les précipitations sont abondantes toute l'année. Canton est sous l'influence de la mousson et la saison des typhons s'étend de juin à septembre. Seul l'automne, d'octobre à décembre, est lumineux.

Canton est le chef-lieu des districts suivants : Yuexiu (qui a fusionné avec Dongshan), Liwan, Haizhu, Tianhe, Baiyun, Huangpu, Fangcun, Huadu, Conghua, Zengcheng, Panyu.


La ville de Canton est, parmi les trois grandes villes chinoises actuelles, celle qui reste le plus éloignée géographiquement ; son intégration culturelle et politique est également celle qui a été la plus tardive. Les cantonais, proches de Hong Kong et plutôt influencés par l'Occident, gardent un certain sentiment d'indépendance, et .

Le climat subtropical du Guangdong inspire un mode de vie « méridional », bien différent des provinces du nord du Yangzi Jiang, et des habitudes vestimentaires très différentes : un patron chinois est souvent méconnaissable à Canton, où le short et le polo sont de mise.

La cuisine cantonaise est réputée pour son inventivité et sa variété, le riz cantonais est un plat apprécié en France.

Le cantonais est un des rares dialectes chinois qui bénéficient de caractères propres, dont l'utilisation a été popularisée par son utilisation en tant que langue officielle à Hong Kong.

Le symbole de la ville est une statue représentant cinq chèvres, que l'on trouve dans le parc Yuexiu.

La robe traditionnelle fendue très haut des deux côtés et qui a disparu lors de la période communiste est réapparue comme vêtement porté par les jeunes femmes.

Universités nationales

Universités et grandes écoles publiques 

Canton est la troisième plus grande ville de Chine continentale, derrière Shanghai et Pékin. Capitale de la province du Guangdong, la province de Chine continentale la plus riche en termes de PIB, elle contribue beaucoup à la production de richesses du pays. Guangzhou est la principale plaque tournante des produits manufacturés du delta de la Rivière des Perles, et l'une des principales agglomérations commerciales de la Chine continentale. En 2009, le PIB nominal de la ville a atteint 911,28 milliards de yuans, soit 133,5 milliards de dollars américains USD, celui par habitant étant de 89.498 yuans ou . La Foire de Canton (China Import and Export Fair), est organisée chaque année en avril et en octobre par le ministère du commerce chinois. Inaugurée au printemps de 1957, la foire est un événement majeur pour la ville. Depuis la session, l'ancien site de Liuhua Complex n'est plus utilisé pour tenir la Foire de Canton, cette dernière étant maintenant organisée au complexe de Pazhou.



Il existe plus de hôtels, restaurants et entreprises de service. 40 % du parc chinois de taxis rouges circulent à Canton.

Canton offre de nombreux parcs très étendus et magnifiquement conçus et entretenus ainsi que deux zoos, un au cœur de la ville (l'entrée arrière, moins fréquentée se trouve dans la rue Huanshidong), et l'autre à l'extérieur de la ville.


Guangzhou, l'une des cinq plus grandes agglomérations du pays, est une ville réputée dans toute la Chine pour sa gastronomie. On y trouve le CTF Finance Centre, l'une des dix plus hautes tours du monde, avec ses de hauteur. L'îlôt de Shamian (沙面), sur la rivière des Perles, conserve une remarquable architecture coloniale datant de la fin du . Le musée de la tombe des Yue du Sud présente une très belle collection d'objets archéologiques découverts en 1983 lors de travaux de voirie. Un petit musée localisé à la même adresse regroupe une étonnante collection d'oreillers de porcelaine.


Un stade omnisports, le Stade "olympique" du Guangdong, pouvant abriter spectateurs, a été inauguré le lors de l'ouverture des 9Jeux nationaux de la République populaire de Chine. En novembre 2010, ce stade a accueilli les Jeux Asiatiques.

Du au se sont déroulés à Canton, les Championnats du Monde par Équipe de Tennis de Table.

La ville possède deux clubs de football qui évoluent en Chinese Super League: 


Parmi les 98 stations de radio locales, quelques-unes sont partiellement anglophones, en FM :

Parmi les journaux et revues anglophones :

La ville sous-provinciale de Canton exerce sa juridiction sur douze subdivisions - dix districts et deux villes-districts .




</doc>
<doc id="14405" url="https://fr.wikipedia.org/wiki?curid=14405" title="Canton (homonymie)">
Canton (homonymie)

Canton peut faire référence à :

Un "canton" est une entité territoriale infra-étatique, dont le statut varie fortement selon les États : 
Les cantons de la Fédération de Bosnie-et-Herzégovine sont des subdivisions administratives qui correspondent au second niveau de l'autonomie locale dans la Fédération de Bosnie-et-Herzégovine, le premier niveau étant la municipalité.

Un canton ("township") est une division cadastrale de 10 milles sur 10 milles (100 milles carrés soit environ 259 km²), qui à l'origine a constitué le cadastre en vue de la colonisation du territoire.
Le canton () est une division administrative.

Le canton est la division administrative d'une province au Costa Rica.
Le "canton" est la division administrative immédiatement inférieure à la "province".

Un "canton" a été une division administrative de durée éphémère créée en 1873 lors de la Révolution Cantonale au temps de la Première République espagnole.

Canton français, une division administrative et une circonscription électorale en France.

Depuis le décret de l'Assemblée constituante du 22 décembre 1789 et les nombreuses modifications qui suivirent, le canton français est une subdivision administrative dont le rayon ne devait pas dépasser 1 myriamètre autour du chef-lieu, soit 10 km.

Le canton est une division administrative au Luxembourg, située au dessus de la commune.

Les cantons suisses, États de la Confédération suisse.







</doc>
<doc id="14406" url="https://fr.wikipedia.org/wiki?curid=14406" title="Europe centrale">
Europe centrale

L'Europe centrale est la région s'étendant au cœur du continent européen. Elle désigne un espace dont les contours flous et variables ne coïncident pas toujours avec les frontières des pays concernés. D'après les définitions, variant tant selon les auteurs que les époques, cinq à actuels peuvent être considérés comme centreuropéens. Au-delà de considérations strictement géographiques, l'Europe centrale désigne un ensemble partageant une trajectoire historique commune, laquelle a façonné un héritage culturel et politique singulier.

L'Europe centrale se caractérise, comme tout concept territorial, autant par ses particularités intrinsèques que par opposition à d'autres territoires. Région la plus orientale de , elle est durablement marquée au par la Réforme protestante et ses conséquences. Bien que sous l'influence des peuples de langue allemande, elle se caractérise également par une grande diversité linguistique et culturelle. Celle-ci s'explique par les dynamiques de peuplement qui ont vu s'y installer des peuples slaves, finno-ougriens, romans, baltes, germaniques, juifs et roms. Par ailleurs, cet espace a longtemps été dominé par des États supranationaux, qu’il s’agisse du Saint-Empire, de l’empire d’Autriche, de la République des Deux Nations ou dans une moindre mesure des empires russe ou ottoman. La majorité de ces peuples n'ont obtenu leur indépendance nationale qu'aux , notamment à la faveur des nombreuses recompositions géopolitiques ayant eu lieu au lendemain de la . La période d'influence soviétique voit ensuite se creuser un fossé entre les peuples centreuropéens et ceux d’Europe occidentale que la fin de la guerre froide puis l'intégration européenne comble peu à peu. De nos jours, même si les nouveaux États ont beaucoup perdu de leur cosmopolitisme, la question des minorités ethniques ou nationales est encore particulièrement prégnante, tant sur la scène politique intérieure que dans les relations de voisinage. 

Plus qu'une entité physique, l'Europe centrale est un concept géographique et culturel, une histoire partagée qui contraste avec celle des régions voisines. Elle est même pour Milan Kundera, pour Václav Havel. L'enjeu de nommer et définir cette Europe centrale est source de controverses. Souvent, la définition dépend de la nationalité et de la perspective historique de son auteur. Ainsi, parmi étudiés par Peter Jordan, seules l'Autriche et la République tchèque ont été assimilées à l'Europe centrale systématiquement.

La notion d'Europe centrale renvoie à celle de ' (littéralement Europe médiane en allemand). Celle-ci fait référence à cette partie centrale de l'Europe où d'une part dominent les empires centraux que sont l'Empire allemand et l'Empire Austro-Hongrois et où d'autre part vivent d'importantes communautés germanophones. Cette Europe située entre Allemagne et Russie et sous influence germanique n’est pas nécessairement peuplée par une majorité de germanophones. Néanmoins, parmi la mosaïque de peuples qui la compose, ceux-ci occupent une place importante et fédératrice aux côtés d’États puissants, qu’il s’agisse des différents royaumes ou principautés du Saint-Empire romain germanique, du Royaume de Prusse ou de l’Empire des Habsbourg d’Autriche. Par le pangermanisme qui la caractérise, la "Mitteleuropa" en tant que telle est devenue une notion du passé : la ('), visant à établir une hégémonie de l’Allemagne sur l’Europe, s’étant durablement effondrée en 1945.

Le concept même d'Europe centrale a perdu de sa pertinence lors de la disparition des Empires centraux à partir de 1918 puis au cours de la guerre froide. En outre, une part de l'hétérogénéité qui la caractérisait a disparu et les particularismes nationaux, tant culturels que linguistiques, ont été renforcés, et ce d'autant plus qu'au lendemain de la Seconde Guerre mondiale, de nombreux germanophones en sont expulsés. Ainsi, alors que les Allemands représentent avant guerre 29,5 % de la population des pays tchèques, ils ne représentent plus que 0,2 % de la population tchèque en 2011. Cependant, l'intégration de ces pays auparavant sous influence soviétique au sein de l'Union européenne permet de raviver et d'actualiser cette ancienne notion d'Europe centrale. L’Allemagne, pays du centre, peut dès lors (re)devenir le trait d’union entre l’ouest et l’est du continent.

L’Europe centrale n'étant pas une région aux frontières claires et reconnues, il est difficile de définir ses caractéristiques géographiques. Quelle que soit la définition retenue, elle ne présente pas un ensemble géographiquement homogène . Il est ainsi possible d’y voir plusieurs sous-régions : au nord se trouve la grande plaine européenne, de l’Elbe au golfe de Finlande, bordée par la mer Baltique ; au centre, le quadrilatère de Bohême ; au sud, les Carpates encadrent la plaine de Pannonie et le plateau de Transylvanie ; la chaîne balkanique forme enfin la limite méridionale de la région. C'est également une région éloignée de la mer, à l’exception de la mer Baltique mais qui, du fait de sa position géographique et de ses difficiles conditions de navigation, apparait comme une sorte de .

La majeure partie de l’Europe centrale connait un climat continental : les hivers y sont froids et secs, les étés chauds et humides et l’amplitude thermique y est relativement importante. Néanmoins, le nord-ouest de l’Europe centrale connait un climat océanique et les rives de l’Adriatique et l’Italie du Nord-Est possèdent un climat méditerranéen . Les Alpes sont d’ailleurs à cet égard une barrière naturelle empêchant l’extension du climat méditerranéen au nord.

Au nord, la grande plaine européenne traverse la partie septentrionale de l’Allemagne, la Pologne et les pays Baltes. Ce relief provient principalement des grandes glaciations du quaternaire qui ont aplani ces régions, formé de nombreux lacs et creusé de larges vallées ou déposé une faisant de cette région , une terre riche et fertile.

L’ouest de la République tchèque s’étend sur un ensemble géographiquement délimité que l’on appelle parfois le et correspondant au bassin de l’Elbe. D’origine hercynienne, il s’agit d’un grand plateau granitique et gneissique encadré par plusieurs chaînes montagneuses. Au sud-ouest, le massif de la Šumava, très arrosé et couvert de forêts, est dédié à l’activité agrosylvopastorale ; au nord-ouest, les monts Métallifères ('), hautes terres cristallines recelant de filons métallifères, dominent de vastes cuvettes emplies de charbons et de lignites et des plateaux volcaniques où naissent les sources thermales de Karlovy Vary ou Mariánské Lázně ; au nord, les monts des Géants (') culminent à ; enfin, à l’est, le massif tchéco-morave est de plus faible altitude et ouvre sur la Moravie. Cette région est un couloir sédimentaire menant de la vallée de l’Oder à celle de la Morava et à l’intersection desquelles se trouvent la porte de Moravie. Zone agricole, on y rencontre également des gisements de pétrole, de gaz et de lignite.

Au sud-est des pays tchèques, le bassin pannonien s’étend autour de la plaine de Pannonie, vaste bassin sédimentaire issu de l’assèchement de la mer de Pannonie du Pliocène. Il est bordé par de multiples chaînes montagneuses : les Carpates à l’est, les Alpes à l’ouest et les Alpes dinariques au sud. Les zones de peuplements hongrois correspondent peu ou prou à ce bassin pannonien, conférant à cet ensemble géographique une homogénéité culturelle. La plaine de Pannonie est issue d’importants plissements ayant exhaussé les massifs alpin et carpatique à la fin du cénozoïque.

La Transylvanie est une cuvette d'effondrement tertiaire enclavée à l’est et au sud par les Carpates. Elle est en revanche aisément reliée au bassin pannonien par les larges trouées du massif du Bihor ; celles-ci servent tant au passage des rivières qu’aux Allemands et Hongrois qui colonisent la région plusieurs siècles durant. Son sous-sol recèle d’importantes ressources minières (fer, charbon, méthane).

Les Carpates forment le principal système montagneux d’Europe centrale. Elles enserrent sur près de la plaine pannonienne, formant un arc de cercle ouest-est sur les territoires de la Slovaquie, de la Pologne, de l’Ukraine et de la Roumanie. D’une altitude plus faible que les Alpes, les Carpates comptent plusieurs massifs culminant à plus de comme les Tatras (Gerlachovský štít, , en est le point culminant), les monts de Maramureş ou les monts Bucegi. Elles comptent également un relief volcanique, notamment en Roumanie . Les Carpates n’ont jamais été une barrière naturelle et offrent un large éventail de richesses .

À l’ouest, le massif des Alpes s’étend principalement sur les territoires suisse, autrichien et slovène ; les Alpes abritent le point culminant de l’Europe centrale, qu’il s’agisse, selon la définition retenue, de la Pointe Dufour, en Suisse () ou du Großglockner en Autriche ().

Le Danube est le plus long fleuve d'Europe centrale. D’une longueur de , il prend sa source en Allemagne, dans la Forêt-Noire, et s’achève par un delta sur la mer Noire, en Roumanie. C'est d’ailleurs le deuxième fleuve d'Europe tant par sa longueur, son bassin hydrologique que son débit moyen à l’embouchure. Dans la région, il parcourt l'Allemagne, l'Autriche, la Slovaquie, la Hongrie, la Croatie puis la Serbie et arrose les capitales Vienne, Bratislava et Budapest.

L’Elbe est le plus important fleuve d’Europe centrale, s’écoulant en direction du nord via la grande plaine germano-polonaise. D’une longueur de , il prend sa source dans les monts des Géants, dans l’est de la République tchèque. La Vltava peut cependant être considérée comme le cours supérieur du fleuve , portant sa longueur totale à ; cette dernière prend sa source dans le massif de la Šumava au sud du pays et arrose Prague avant la confluence avec l’Elbe. Le fleuve traverse ensuite les Monts Métallifères avant de rejoindre la Saxe et Dresde, puis le nord de l’Allemagne et Hambourg où il se jette dans la mer du Nord.

La Vistule quant à elle s’écoule sur près de à travers la Pologne. Prenant sa source dans les Carpates occidentales, elle arrose Cracovie et Varsovie avant de se jeter dans la mer Baltique en formant un delta via le golfe de Gdańsk.

L’Europe centrale n’est pas non plus une entité historique et culturelle statique mais un concept dynamique, fruit d’une longue évolution entre les mondes russe, à l’est et germanique, à l’ouest, c'est dans cet espace de l’Europe médiane que se sont développés à partir du les peuples slaves occidentaux et méridionaux, finno-ougriens, roumains et baltes. Les germanophones y constituent cependant un groupe démographique prépondérant, , de même que les Juifs autrefois et les Tziganes. L’influence du pôle occidental, tant germanique que pontifical, se fait ressentir au niveau religieux puisque ces peuples ont développé historiquement un christianisme de rite romain. L'importance du rite grec est restreinte, puisqu'il se limite aux Roumains orthodoxes de Transylvanie, aux quelques localités serbes de la vallée du Danube, ainsi qu'aux gréco-catholiques (essentiellement ruthènes), lesquels se distinguent par leur allégeance au pape.

La question linguistique est l’une des composantes essentielles de l’Europe centrale. Les langues nationales y sont d’une grande diversité et renvoient à l’histoire complexe de la région et des Empires supranationaux qui la dominaient. Cette multitude se traduit tout d'abord par les branches linguistiques que l’on y rencontre : 
L'importance des langues minoritaires caractérise également la région et beaucoup d'entre elles comptent encore plusieurs dizaines de milliers de locuteurs au début du , comme le romani, le silésien, le sorabe ou encore l'italien et le ladin. 

Cette diversité se traduit enfin par la présence de deux alphabets, latin et cyrillique — celui-ci étant néanmoins très minoritaire, se limitant aux alphabets russe, biélorusse et rusyn. 

Historiquement, l’époque de la Renaissance voit émerger de nombreuses langues communes et vulgaires, dans des territoires plus ou moins définis, à la suite de la grammatisation systématique de langues vernaculaires. Du , de nombreux idiomes d’Europe occidentale sont officialisés puis l’édification d’une grammaire et d’une langue littéraire les fixe progressivement. En Europe centrale, ce processus sera plus tardif : au début du , la région compte, selon l’expression de Georges Weill, que les nationalistes s’efforceront d’anoblir. Certaines langues sont fixées à la même époque qu’en Europe occidentale mais ne seront relayées politiquement que beaucoup plus tard : il en va ainsi du tchèque, du polonais, du lituanien ou du hongrois. Celles-ci ont des origines anciennes ( pour le lituanien ou pour le tchèque et le polonais) et leurs grammaires remontent aux s mais ne deviennent langues nationales qu’à la fin du (en 1863 pour le hongrois) voire au (en 1920 pour le lituanien). D’autres langues centreuropéennes sont fixées plus tardivement : la priorité des mouvements nationaux est alors de systématiser leur langue vernaculaire (orthographe et grammaire). Ainsi, les premières grammaires remontent à 1757 (roumain), à 1792 (slovaque ) ou à 1820 (slovène et letton). Elles seront officialisées rapidement, au (roumain dès 1829) ou au début du (cas du letton, du slovène et du slovaque).

La langue allemande y est pendant plusieurs siècles à partir du Moyen Âge une "", une langue véhiculaire qui a influencé les langues locales ; elle est à cette époque également la langue de l’enseignement, de l’établissement des normes juridiques et de la bourgeoisie .

Si la diversité linguistique trahit la diversité ethnoculturelle, l’importante minorité juive tient une place particulièrement essentielle dans l’histoire et l’imaginaire de la région. D’une part, arrivés avec les Romains pour les premiers d’entre eux, les Juifs sont établis dans certaines parties de l'Europe centrale bien avant les Germains, les Slaves ou les Hongrois ; d’autre part, leur participation à l’histoire, à l’économie ou à la culture locales est remarquable. Mais s’ils sont depuis le Moyen Âge solidaires de ces derniers, ils en sont aussi fréquemment et leurs victimes expiatoires. Au , l’antisémitisme ne faiblit pas malgré l’émancipation de en 1867. Les mouvements de renaissance nationale ne sont pas étrangers à ce renouveau antisémite, que ce soit en Roumanie, Hongrie ou Pologne. De la fin du siècle à la Seconde guerre mondiale s’épanouit l’époque du qui marque l’explosion de l’antisémitisme et l’émergence du judaïsme moderne. Malgré les atrocités du conflit, la « rhétorique antisémite perdure » : parfois sous les traits de l’antisionisme (affaire Slánský en Tchécoslovaquie) ; parfois sous ceux de l’anticosmopolitisme (Gomułka en Pologne « engage une véritable épuration » et les deux-tiers des polonais émigrent). Les témoignages contemporains de la présence juive sont les anciens ghettos, les synagogues ou les vieux cimetières, autant de lieux touristiques majeurs dans bien des pays de la région.

Les Carpates abritaient une ancienne population autochtone de montagnards quasiment disparue, qui se divise en plusieurs communautés, largement oubliées à l'heure actuelle : les Boykos, les Lemkos et les Houtsoules. Assimilés aux Ruthènes, ils possèdent chacun leur dialecte et une culture distincte. Ils ont résisté à toute assimilation et ont été persécutés puis déportés (vers l'Union soviétique ou la Silésie notamment) par les gouvernements polonais et soviétique au lendemain de la Seconde Guerre mondiale. Quoique les chercheurs Ukrainiens considèrent ces populations slaves de souche, Paul Robert Magocsi apporte une thèse plus travaillée et complexe sur leurs origines : les Houtsoules seraient d'origine récente, issus d'un mélange de paysans et de bergers pauvres Roumains et Ukrainiens, réfugiés dans les Carpates pour fuir les guerres du . Les Ukrainiens étant plus nombreux que les Roumains, leur langue est plus proche de l'ukrainien que de toute autre et constituerait à l'origine un patois composite.

Indépendamment de la définition que l’on retient de cette région et donc des pays qui la composent, il est donc nécessaire de remarquer l’enchevêtrement entre État et nation qui la caractérise. En effet, les pays que l’on reconnait comme appartenant à cette aire géopolitique ne sont pas homogènes nationalement et leurs frontières ne recoupent pas les appartenances ethnoculturelles. De fait, l’existence de minorités nationales est une composante essentielle de cet ensemble géopolitique où cohabitent citoyenneté et nationalité. Les évolutions historiques contemporaines ont néanmoins pu atténuer ces hétérogénéités : par exemple, l’expulsion des Allemands des Sudètes entre 1945 et 1947 a renforcé l’homogénéité nationale de la République tchèque actuelle.

Les tribus Estes venues du nord de l’Oural s’établissent aux abords du golfe de Finlande au cours du III millénaire , les Finnois au nord et les Estoniens et les Lives au sud. Les Protoslaves-Baltes forment une communauté linguistique jusque vers 1400 , époque à laquelle les Baltes s’établissent à l’est de la mer Baltique et les Protoslaves entre l’Oder et le Dniepr ; les peuples germaniques quant à eux occupent à cette époque le sud de la Scandinavie et le nord de l’Allemagne, entre l’Oder et la Weser. 

Puis les Slaves migrent vers le sud et franchissent la au début de l’ère chrétienne. Les grandes invasions vont ensuite achever de structurer la démographie actuelle de l’Europe centrale : outre l’implantation des peuples germaniques, celles-ci voient l’arrivée des Hongrois. Peuple finno-ougrien issu du groupe ouralo-altaïque, les Magyars sont originaires du coude de la Volga. Agriculteurs-éleveurs, ils deviennent des pasteurs nomades organisés en clans sous l’influence du peuple turc des Khazars ; ils migrent vers l’ouest, entre Dniepr et Danube, après la poussée des peuples de la steppe d’Asie centrale. Mercenaires cavaliers, ils s’installent dans la plaine hongroise de Pannonie vers l’an 896 d’où ils organisent de fréquentes contre l’Occident jusqu’en 955. Quant aux Roumains, seul peuple latin de la région, ils sont probablement les descendants des Daces romanisés, restés sur place après l’évacuation de la Dacie par l’empereur Aurélien en 271.

Dans cet espace de l’Europe médiane se sont développés à partir du ces peuples slaves occidentaux et méridionaux, finno-ougriens, roumains, baltes et allemands. Autour de l'an mil, les peuples d’Europe centrale s’établissent en États (Duché de Bohême à la fin du ; Margraviat d'Autriche en 976 ; Duché de Pologne en 960 ; Royaume de Hongrie en 1001). Le Moyen Âge voit ces royaumes se développer avant d’être absorbés dans des ensembles plus vastes, notamment l’Empire des Habsbourg d’Autriche, l’Empire ottoman ; plus tard, la Russie tsariste de Pierre le Grand et conquiert la république de Pologne-Lituanie qui s'étendait presque jusqu'à Moscou.

Les incursions ottomanes en Europe débutent au . Les Ottomans pénètrent jusqu’en Hongrie mais sont stoppés par une coalition réunissant notamment Hongrois, Polonais et Allemands autour de Jean Hunyadi, voïvode de Transylvanie ; ils signent la paix de Szeged en 1444. Mais Jagellon, roi de Pologne et de Hongrie, rompt immédiatement la trêve et est battu à la bataille de Varna. En 1526, Soliman le Magnifique remporte face à de Hongrie la bataille de Mohács et annexe Buda : la majeure partie de la Hongrie passe sous domination ottomane pour près de ; en 1529, Vienne est assiégée, en vain ; en 1532, la Styrie est occupée. L’Empire ne cherche cependant pas à islamiser ni turquifier ses sujets mais assure au contraire leur cohabitation et leur diversité. En 1606, la entre Ottomans et Autrichiens prend fin avec la signature de la paix de Zsitvatorok qui consacre le " en Europe centrale et le coup d’arrêt des conquêtes turques dans la région. En 1683, les Ottomans font de nouveau le Siège de Vienne mais les Européens se coalisent : l’intervention du roi de Pologne Sobieski sauve la ville lors de la Bataille de Kahlenberg. Cette s’achève en 1699 avec la signature du Traité de Karlowitz : la Hongrie est rétablie dans ses frontières et, dès lors, la présence ottomane en Europe centrale prend fin.

Alors que plusieurs tentatives de réforme de l’Église ont échoué par le passé , la Réforme protestante apparait au . Sous l’égide de Martin Luther puis de Jean Calvin ou d’Ulrich Zwingli, elle marque une rupture radicale avec l’Église de Rome. Les écrits de Luther, dénonçant notamment la pratique des indulgences, se diffusent à partir de 1517. Ainsi, en 1530, la quasi-totalité des princes et des villes du Saint-Empire romain germanique adhèrent à la Réforme. Puis la paix d’Augsbourg de 1555 établit la liberté religieuse des États protestants selon la règle " : la religion du prince devient celle de ses sujets. Jusqu’en 1576, la Réforme continue de s’étendre et à cette date près des trois-quarts des sujets des Habsbourg d’Autriche sont protestants, y compris la noblesse. Mais le catholicisme regagne progressivement du terrain, tout d’abord en Bavière et dans le Bade puis en Autriche : l’archiduc Ferdinand recatholicise par la force la Styrie et la Carinthie. Son élection à la tête du Saint-Empire sous le titre de lui permet d’achever la reconquête catholique en Europe centrale : la Bohême et la Moravie réformées sont vaincues en 1620 lors de la Bataille de la Montagne Blanche. Dans le même temps, la Pologne et la Hongrie sont également reconquises par l’Église de Rome.

Au , l'Autriche est la grande puissance de l'Europe centrale. À cette époque, sous l’influence des Lumières, émergent des aspirations nationalistes qui se transformeront en luttes politiques et émancipatrices au . Le de 1848 voit les peuples d’Europe centrale réclamer en vain des libertés civiques et l'autonomie de leurs territoires : c'est ce que feront les Tchèques, les Polonais, les Croates, les Slovènes ou les Roumains ; les Hongrois réclament, pour leur part, l'indépendance et proclame la république. C’est également à cette époque que se développe l’austroslavisme en faveur d'un qui cultiverait sa richesse et sa diversité. L’un de ses plus ardents défenseurs, František Palacký, l'une des figures de la Renaissance nationale tchèque, écrit ainsi que . En 1848 se tient à Prague un congrès panslave dont les participants (tchèques, polonais, moraves, croates, serbes et slovaques) réclamant la conversion de la en un État confédéral garantissant l'égalité des droits entre les peuples . L'empereur d'Autriche refuse strictement chacune de ces revendications et le soulèvement tchèque qui fait suite à cet épisode est lui aussi écrasé.

Alors que l’Europe centrale est sous influence germanique, le marque d'ailleurs un premier tournant. Ce sont en effet les troupes russes qui en 1849 mettent fin à la révolution hongroise, au cœur même de l’Empire autrichien. Les États centreuropéens sont dorénavant sous la menace directe du grand voisin slave, l’Empire Russe devenant au détriment de l’Empire d’Autriche. Après la création en 1870 de l’Empire d’Allemagne, les peuples d'Europe centrale, qui ont toujours des pays germaniques, sont coincés entre ces deux grands Empires et l’Autriche.

Les conséquences de la Première Guerre mondiale sont l'opportunité pour ces peuples d'édifier leurs États souverains. En effet, les empires régionaux ont éclaté et les régions alors sous leur domination prennent leur indépendance. L'Empire d'Autriche a dès lors selon Milan Kundera raté l'opportunité qui lui incombait de construire une fédération centreuropéenne multinationale. Cependant, et c’est l’une des caractéristiques de l’Europe centrale contemporaine, les nouvelles frontières ne feront que peu coïncider États et nations : État théoriquement binational, la Tchécoslovaquie se révèle multinationale avec 33 % d’habitants allochtones ; la Hongrie voit deux millions de Magyars vivre en dehors de ses frontières ; Vilnius, pourtant capitale du nouvel État lituanien, compte une majorité de Polonais ou de Juifs et très peu de ressortissants nationaux.

Les régimes démocratiques apparus au lendemain de la vont bien souvent laisser place à des régimes autoritaires : Miklós Horthy à Budapest, Józef Pilsudski à Varsovie, Engelbert Dollfuß à Vienne, Konstantin Päts en Estonie ou Antanas Smetona en Lituanie. La Tchécoslovaquie fait dès lors figure d’exception en Europe centrale, ce qui ne l’empêchera pas de se voir morcelée avec l’aval des grandes puissances occidentales lors des Accords de Munich de 1938. Lors de la Seconde Guerre mondiale, la politique raciste du transforme les peuples slaves et baltes d’Europe centrale en .

Au lendemain de la guerre, les États d’Europe centrale retrouvent leur souveraineté mais le plus souvent dans de nouvelles frontières. Les modifications les plus notables sont celles de la Pologne dont les frontières se déplacent ostensiblement vers l’ouest, l’Allemagne étant amputée principalement de la Prusse orientale et de la Silésie, mais aussi de la Tchécoslovaquie qui perd la Ruthénie subcarpatique au profit de l’Ukraine soviétique. Ces changements provoquent d’importants déplacements de population : les Polonais s’établissent à l’est de la ligne Oder-Neisse dont sont chassés plusieurs millions d’Allemands tandis que les Ukrainiens des régions frontalières sont dispersés sur le reste du territoire. Mais les Allemands demeurent les principales victimes de ces déplacements forcés en Europe centrale : la présence allemande y remonte pourtant aux s et en 1937 environ d’Allemands y sont recensés . Ces bouleversements démographiques homogénéisent les territoires et conduisent à modifier durablement . L’expulsion des Allemands d’Europe centrale, dont la présence était pourtant historique, entretient une , notamment en République tchèque, Pologne et Hongrie. En 1990, Václav Havel fera d’ailleurs de ses excuses au peuple allemand sa première décision internationale.

L’Armée rouge ayant libéré la quasi-totalité des États de la région, le déclenchement de la guerre froide fait de la région un glacis en faveur de l’URSS régi par le COMECON et plus tard le Pacte de Varsovie. L'Europe centrale disparait, alors qu'à la même époque, les intellectuels concentrent leurs recherches sur le seul monde russe. Les États de la région sont dès lors ostensiblement renvoyés soit à l'Ouest, soit à l'Est. Ainsi, l'Allemagne fédérale et l'Autriche appartiennent au camp occidental (l'Autriche demeurant neutre) et les autres États se retrouvent sous influence soviétique, dont les peuples pourtant . Le concept de "" continue cependant d'intéresser au cours de la Guerre froide, notamment en Hongrie, Tchécoslovaquie et Pologne, États que Milan Kundera met en avant dans sa définition de l’Europe centrale.

Compte tenu de la multiplicité des définitions de l'Europe centrale, il est pertinent d'examiner tour à tour deux définitions opposées, l'une restrictive et l'autre extensive. 

Une définition restrictive se retrouve dans la réflexion de l'écrivain franco-tchèque Milan Kundera qui a d'une certaine manière . Rédigé en 1983, cet essai est cependant très marqué par l'histoire récente et le contexte géopolitique : la dimension allemande de la région est effacée et la Russie y apparait comme sa principale influence , alors même que le clivage entre les deux pôles de l'Europe n'a jamais été aussi fort.

L'Europe centrale y est présentée non comme un ensemble d'États, entités trop figées et trop politiques, mais . Cette définition situe en Europe centrale les pays suivants :

Pour Kundera, l'Europe centrale appartient pleinement à l'Occident et il la nomme sa . Ce sentiment d'appartenance y est très présent, plus que les peuples d'Europe de l'Ouest n'en ont conscience. Ces nations, qui se sont au lendemain de la Seconde Guerre mondiale. Le rejet du monde russe est d'ailleurs révélateur de ce sentiment d'appartenir à la partie occidentale de l'Europe. František Palacký, historien et personnalité politique tchèque du , soutenait ainsi l'Empire d'Autriche par opposition à la Russie, . Dans ses "Mémoires de Hongrie", l'écrivain antifasciste hongrois Sándor Márai évoque dès le début de son ouvrage, lorsqu'il rencontre pour la première fois un soldat russe, ce sentiment de se sentir plus proche de l'ennemi allemand, décrit comme familier et prévisible, que de ce militaire à l'allure de cosaque, dont il ne connait rien.

Le ciment de cette région, ce qui lui donne son homogénéité, se trouve également dans son histoire . Cette histoire commune est également une histoire mouvementée où les peuples sont davantage objet que sujet de leur destin, coincés entre cette double influence, germanique (du Haut Moyen Âge jusqu'au ) et russe (hégémonie tsariste en Pologne puis soviétique dans l'ensemble de la région). Les habitants des pays d'Europe centrale pourraient d'ailleurs se reconnaitre par leur contestation d'une présence trop importante d'une population soit allemande, soit russe. 

En effet, la nécessité de se battre pour survivre et pour exister caractérise ces nations, qui n'ont jamais été conquérantes ou belliqueuses car trop faibles face à leurs voisins. Elles ont de fait pour point commun un avenir incertain face aux tentations des puissances proches et ont conscience de leur vulnérabilité, de leur risque de disparaitre ; Kundera exclut par conséquent de cette Europe centrale l'Allemagne dont la tentation hégémonique a marqué l'histoire de la région, à la différence de l'Empire autrichien. Il écrit, pour résumer ce sentiment de faiblesse : .

Une forme de solidarité transparait finalement entre ces peuples à l'histoire si proche. Kundera prend l'exemple du comportement des troupes du Pacte de Varsovie lors de l'invasion de la Tchécoslovaquie en 1968 pour illustrer cet état d'esprit : .

L'homogénéité de l'Europe centrale passe enfin par une culture commune. Kundera cite notamment l'art baroque qui unira , et en particulier la musique. Mais cette culture commune passe aussi par une pluralité ethnoculturelle qui transcende et finalement unit ces États. Il explique que chacun de ces pays présentent une composition démographique multinationale, avec de nombreuses minorités ethniques, slaves et non slaves. 

La minorité juive est fondamentale dans son analyse de l'identité de l'Europe centrale : . Cette analyse est également partagée par l’écrivain serbe Danilo Kiš pour qui les Juifs constituaient le et le moteur culturel de la région. C'est d'ailleurs en Europe centrale qu'émerge le sionisme, à l'époque même où naissent les autres aspirations nationales des peuples centreuropéens : Theodor Herzl est né en Hongrie ; David Ben Gourion en Pologne. 

L'homogénéité de cet ensemble régional se trouve donc également dans l'hétérogénéité des États qui la composent. L'Europe centrale pourrait de fait se définir ainsi : . 

Le professeur Peter Jordan définit l'Europe centrale dans des frontières beaucoup plus étendues en relevant huit éléments constitutifs. Cette définition situe en Europe centrale les pays suivants : 

Les Allemands s'établissent en Europe centrale à compter du . La langue allemande y devient une langue véhiculaire de même que la langue de l’enseignement, de l’établissement des normes juridiques et de la bourgeoisie. Si l’étendue des zones de domination et de peuplement allemands s’est considérablement réduite depuis 1945, la présence historique de ces minorités a eu un effet durable, notamment dans la nature même des villes ou le paysage culturel. En outre, l’allemand est de nouveau une langue d’enseignement importante depuis la chute du , précisément dans ces anciennes régions germanisées. 

Quant à la minorité juive, celle-ci était numériquement très importante et jouait un rôle culturel et économique majeur, les Juifs formant une part essentielle de la population urbaine. Du Moyen Âge à la Seconde Guerre mondiale, les cultures juives et allemandes y vivent d’ailleurs en symbiose. Il faut toutefois noter que la présence juive est restée limitée dans les pays alpins et sur le territoire de l’Allemagne contemporaine à l'exception des grands centre urbains de Berlin, Nuremberg ou Leipzig.

Bien que les Églises aient perdu de leur influence et que les sociétés se soient sécularisées, les aires de diffusions religieuses, actuelles et passées, n’en demeurent pas moins des indicateurs importants dans la délimitation des espaces culturels. En Europe centrale vivent aujourd’hui soit des protestants à proximité de catholiques soit des catholiques dans des régions marquées par la Réforme protestante et où des traits de la culture réformée existent toujours (matérialisme, rationalisme, sobriété) . Cependant, certaines régions n’ont pas été atteintes par la Réforme protestante ; celles-ci ne sont cependant que des exceptions d’un mouvement général. 

On rencontre également dans certaines régions marginales les Églises catholiques orientales, transition entre les mondes byzantin et catholique latin traduisant un ancrage centreuropéen et non oriental. Enfin, les populations musulmanes actuelles d’Europe centrale ne proviennent pas de l’ancienne influence ottomane mais de migrations contemporaines.

Si la bourgeoisie urbaine apparait en Flandres et en Italie du Nord, ce système se développe dès le à l’est du Rhin et le long de la côte orientale de la mer Adriatique. Les villes concernées vont progressivement gagner en autonomie et être administrées par les citoyens ce qui façonnera le développement politique et socio-économique des régions alentours : les populations rurales serves sont enclines à s’installer dans ces villes et à devenir artisans ou commerçants ; de nouveaux domaines d’activités économiques émergent ; les échanges commerciaux sont accrus ; la population urbaine augmente et avec elle les classes aisées, ouvrant de nouveaux débouchés agricoles Mais la poussée des mondes ottoman et russe va freiner cet essor urbain et marquer une fracture entre l’Est et l’Ouest du continent.

Le développement de la paysannerie libre est dans une certaine mesure comparable à celui de la bourgeoisie urbaine. Les populations rurales sont rapidement affranchies et délestées de toute forme d’asservissement féodal. Elles deviendront un rouage essentiel du développement économique et de l’émergence d’une société libre et démocratique. Les pays alpins en sont le noyau originel et sa diffusion dans le reste de l’Europe centrale se fera notamment par le biais de la colonisation allemande vers l’est à partir du , qu’il s’agisse de la colonisation saxonne de Transylvanie, de la militarisation des marches autrichiennes ou du repeuplement du royaume de Hongrie après les invasions mongoles puis les guerres ottomanes.

Le développement précoce tant d’une bourgeoisie urbaine que d’une paysannerie libre constitue le substrat historique du fédéralisme contemporain que l’on rencontre notamment en Allemagne, Autriche et Suisse mais également dans le nord de l’Italie, en République tchèque ou en Slovénie. À l’inverse, les territoires polonais ou de l’ancien royaume de Hongrie sont moins marqués par cette tradition d’autonomie locale et régionale.

Cette diversité ethnoculturelle s’applique davantage aux régions méridionales et orientales de l’Europe centrale. Elle reflète directement les particularismes de l’histoire régionale et notamment l’importance qu’y ont eu les États supranationaux au sein desquels s’est diffusé le concept herdérien de la ("). Au contraire de l’Europe occidentale, l’Europe centrale se prête mal au concept d’État-nation. Les minorités nationales y bénéficient d’un droit d’existence et ont donc perduré au sein de nations culturelles différentes, au point parfois d’obtenir une protection juridique et une autonomie politique. Cependant, le sursaut nationaliste à partir de la fin du et jusqu’au lendemain de la Seconde Guerre mondiale a altéré cette réalité, entrainant parfois des violences contre les minorités ethniques voire leur destruction ou leur expulsion pures et simples.

Contrairement aux autres grandes régions européennes, l’Europe centrale n’a pas vu émerger de grandes nations maritimes . De fait, les États de la région n’ont pas été impliqués dans la division coloniale du monde et la participation tardive de l’Allemagne à ce phénomène, qui n’aura d’ailleurs que très peu de conséquences sur sa métropole, ne doit pas faire oublier ce particularisme historique. À la différence également des peuples d’Europe du Nord (tournés vers l’Atlantique nord), ottoman (tourné vers la Méditerranée et le Moyen-Orient) ou russe (véritable puissance coloniale tournée vers l’océan Pacifique, l’Asie centrale ou le Caucase), les peuples d’Europe centrale ont maintenu leurs orientations politiques et économiques dirigées vers le continent. Les conséquences contemporaines de ce positionnement historique sont d’une part des échanges commerciaux très largement infra-européens et d’autre part une très faible immigration.

Le processus d’industrialisation implique non seulement une réorganisation économique mais aussi une transformations profonde de la société, de la taille des ménages aux conditions de logement en passant par les structures politiques. Ce processus s’étend progressivement à partir de la fin du en direction de l’ouest et ce sont, aux alentours de 1820, les territoires allemands, tchèques, autrichiens et suisses qui s’industrialisent. Les autres régions d’Europe centrale ne sont touchées que durant la seconde moitié du siècle alors que l’Europe de l’Est et du Sud-Est reste très largement une aire agricole dont l’industrialisation ne commencera qu'au cours du .

Sur la base des éléments précédemment évoqués, il est possible de préciser les facteurs d'appartenance ou d'exclusion d'un pays à l'Europe centrale.

La présence de l'Allemagne au sein de l'Europe centrale élargie s'explique premièrement par la double présence des religions catholique et réformée (bien que certaines régions, comme la Bavière, n'aient pas réellement subi l'influence de la Réforme protestante). Deuxièmement, si la diversité culturelle et ethnique dans l'Allemagne contemporaine est faible, ce ne fut pas le cas jusqu'à 1945 et les minorités allemandes ont eu un rôle prédominant dans l'histoire de la région et des pays voisins. D'ailleurs, il subsiste au certaines minorités ethnico-linguistiques comme les Sorabes en Lusace. Troisièmement, l'Allemagne s'est toujours orientée vers le continent dans les domaines économique et politique, comme l'atteste d'ailleurs ses nombreuses minorités disséminées dans la région. La tentation coloniale allemande n'a commencé qu'en 1884 pour se terminer dès 1918. Quant au commerce hanséatique, il s'inscrit pour partie lui-même dans une continuité territoriale centreuropéenne, et ne concernait qu'une petite partie de l'Allemagne contemporaine. Quatrièmement, la bourgeoisie s'est rapidement développée dans les villes allemandes avant de se diffuser dans le reste de la région et avec elle une tradition politique autonome, à l'origine du fédéralisme actuel. Enfin, la minorité juive y a été pendant des siècles très importante et a contribué activement au développement de la société. À compter du milieu du , les Juifs d’Allemagne se sont progressivement émancipés et germanisés mais ne sont plus, à la fin du , qu'environ contre près de en 1933.

Noyau originel de l’immense empire supranational qu’était l’Empire des Habsbourg jusqu’en 1918, l’Autriche contemporaine possède encore sur son territoire plusieurs minorités nationales, principalement des Slovènes en Carinthie et en Styrie ; des Croates et des Hongrois au Burgenland et des Tchèques et des Slovaques à Vienne. La communauté juive autrichienne est pendant longtemps très importante et a contribué à faire de Vienne selon les mots de Walter Benjamin. Estimée à en 1938, elle ne compte cependant plus à la fin du qu’environ . En outre, l'Autriche catholique a été profondément touchée par la Réforme protestante et elle constitue enfin, avec les autres pays alpins, le cœur historique de la paysannerie libre et de l’autonomie politique locale, préfiguratrice du fédéralisme contemporain tout en ayant fait partie des premiers pays industrialisés de la région, vers 1820.

Le voblast de Hrodna est peuplé d'une importante minorité polonaise catholique, représentant en 1999 environ et jusqu'à 20 % de la population de certains districts. Historiquement, la ville de Hrodna voit s’établir des Lituaniens à compter du puis des Polonais au cours du ; elle est au un exemple de cohabitation multi-ethnique. Lors du troisième partage de la Pologne, en 1795, la ville passe sous la souveraineté de l'Empire russe. Celui-ci s’engage alors dans la russification de la région mais en 1939, Hrodna compte toujours et .

La Croatie a été jusqu'en 1918 étroitement associée à la Hongrie et à l'Autriche. Plus précisément, les royaumes de Croatie et de Slavonie furent unis à la Hongrie de 1102 à 1526 puis passèrent sous contrôle des Habsbourg. En 1797, la Dalmatie fut intégrée à son tour à l'Empire d'Autriche de même que les territoires de la République de Raguse en 1814. C'est ainsi qu'en 1914, le Royaume de Dalmatie et l'Istrie sont sous domination autrichienne et le Royaume de Croatie et de Slavonie sous influence hongroise. Cependant, la Croatie catholique n'a jamais connu d'empreinte protestante. 

Si les régions historiques de Croatie centrale et de Slavonie s'insèrent dans l'ensemble centreuropéen, il peut sembler incohérent que celles situées sur le littoral oriental de l'Adriatique ne fassent pas partie de l'Europe méridionale. En effet, dans ces régions (Istrie, Kvarner, Dalmatie), les influences vénitienne comme romaine sont palpables, de même que l'orientation politico-économique vers le large. Cependant, l'influence austro-hongroise mêlée à la culture slave a davantage marqué la région. La présence de la Croatie dans l'espace centreuropéen s'explique également par des raisons conjoncturelles, afin de la différencier de la région de crise que sont les Balkans à la fin des et au début des .

Du , l'Estonie est liée à l'État monastique des chevaliers teutoniques et abrite ainsi jusqu’à la Seconde Guerre mondiale une minorité allemande qui marquera durablement la société. Celle-ci ne représente cependant plus, au début du , que 2,5 % de la population et ces quitteront le pays à la suite du pacte germano-soviétique puis de l'annexion par l'Union soviétique (qui ordonne leur déportation). Quant à la minorité juive, peu nombreuse avant la guerre, elle est décimée lors de la Shoah et les rares survivants ne peuvent conserver le statut de . L’Estonie est également marquée par la présence d’une forte minorité russe représentant en 2006 plus de 25 % de la population et jusqu’à 78 % de la population du comté de Viru-Est.

Convertie au protestantisme sous l’influence des Suédois, l'Estonie constitue néanmoins un pont culturel avec l’Europe du Nord en raison de la proximité linguistique entre l'estonien et le finnois et d’une histoire faite de confrontation avec ses voisins Suédois et Danois.

En Alsace et en Moselle, les dialectes alémaniques d'une grande partie de la population autochtone sont l'argument principal pour affecter ces régions à l'Europe centrale, bien que celles-ci soit largement influencées par le français aujourd'hui. Historiquement, elles appartenaient jusqu'à 1648 (Sundgau), 1682 (Strasbourg) et 1737 (Moselle) au Saint-Empire romain germanique et ont été de 1871 à 1918 une partie de l'Empire allemand.
L'histoire de la Hongrie la rattache à l'Europe centrale. Sous le règne de Mathias Corvin, le pays est un immense royaume s’étendant jusqu’en Bohême et en Autriche ; puis, intégré à l’Empire d’Autriche en 1526, il gagne en autonomie à partir de 1867 et Budapest devient même l’égal de Vienne sous l’ère du dualisme austro-hongrois. Il s’agit d’un pays religieusement morcelé, avant tout catholique mais dont la minorité protestante n’est pas négligeable (11,6 % en 2011). Elle abrite en outre jusqu’en 1945 d’importantes minorités allemande et juive alors même que les magyarophones sont très présents en dehors des frontières de l’État, notamment en Roumanie et en Slovaquie voisines ; les Juifs ont activement participé à la vie politique et intellectuelle hongroise et s’ils ne sont plus que en 1990, ils étaient près de dans les années 1920.

Les territoires du Tyrol du Sud, du Trentin, du Frioul mais aussi Trieste et la province de Belluno en Vénétie ont connu une empreinte forte des cultures allemande et autrichienne. Historiquement intégrées à l'Empire d'Autriche, ces régions se caractérisent également par leur diversité ethnique (Romanches, Frioulans, Ladins, Slovènes, nombreuses enclaves germanophones) qui les rapproche en ce sens également de l'Europe centrale. 

Plus spécifiquement, le Trentin-Haut-Adige intègre la sphère d'influence germanique à partir du . La région passe progressivement sous domination habsbourgeoise et sera même intégrée au Tyrol autrichien de 1802 à 1918. Cependant, la région autour de Trente reste majoritairement de langue et de culture italiennes. À la suite de la Première Guerre mondiale, l'ensemble de la région revient à l'Italie, en dépit du principe d’autodétermination des peuples puisque les germanophones et les Ladins réclamaient l’annexion à l’Autriche ou la création d’un État indépendant. De 1922 à 1943, sous Mussolini, le Tyrol du Sud connait une période d’italianisation forcée : les toponymes et patronymes sont modifiés, le nom-même de Tyrol est interdit, l'enseignement et la pratique publique de l'Allemand sont prohibés. D'après le recensement de 2001, le Tyrol du Sud compte environ 69 % de germanophones , majoritairement en milieu rural, et 4,4 % de ladinophones.

Au sein de l'actuelle région du Frioul-Vénétie julienne, le Frioul a été brièvement administré par l'Autriche au alors que la région de Trieste l'a été jusqu'en 1919.

Liée historiquement à l'État monastique des chevaliers teutoniques du puis à la Suède et enfin à l’Empire russe du à 1918, la Lettonie a été ensuite massivement sous l’ère soviétique (1940-1991). Après avoir abrité d’importantes minorités juives et allemandes , elle est toujours en 2015 ethniquement divisée puisque 33,5 % de la population est slave, à 25,8 % russe ; les Juifs et les Allemands ne représentent quant à eux plus que 0,5 % de la population. Majoritairement protestante, la Lettonie compte cependant une minorité catholique importante en Latgale, à l’est du pays.

La Lituanie catholique est associée à la Pologne de 1386 à 1795 au sein de l’Union de Pologne-Lituanie puis de la République des Deux Nations. Elle abrite en outre d’importantes minorités nationales : sa population compte en effet 9 % de Russes, 7 % de Polonais et 1 % de Juifs. Ceux-ci ont été particulièrement touché par la Shoah puisque 87 % d’entre eux ont péri (seule la communauté polonaise a été davantage dévastée, à 93 %). Après l’indépendance en 1918, la capitale Vilnius compte d'ailleurs une majorité de Polonais ou de Juifs et sera annexée par la Pologne jusqu’à la Seconde Guerre mondiale.
La question linguistique comme l'histoire renvoient le pays vers le centre du continent : d'une part, le luxembourgeois, dialecte Franco-Mosellan, est la langue la plus parlée aux côtés de l'allemand et du français ; d'autre part, les comtes de Luxembourg ont joué un rôle de premier plan dans l'histoire du Saint-Empire romain germanique, et après son indépendance en 1815, le Luxembourg est jusqu'en 1866 membre de la Confédération germanique. Par conséquent, le Luxembourg est davantage orienté vers l'Europe centrale que les Pays-Bas ou la Belgique ; la coopération étroite avec ces pays au sein du Benelux depuis 1944 ne peut compenser complètement cette réalité.

L'histoire mouvementée de la Pologne a eu pour conséquence, entre autres, de faire coexister de nombreuses minorités sur le territoire actuel du pays. Elle a en effet été morcelée entre Prusse, Autriche et Empire russe de 1772 à 1918 et ses frontières ont sensiblement fluctué au cours du . La partie méridionale de la Pologne actuelle, la Silésie et la Galicie, sont sous souveraineté autrichienne à compter respectivement de 1526 et du premier partage de la Pologne de 1772. Pays catholique où l'influence de l'Église est importante, la Pologne est également profondément touchée par la Réforme protestante au cours du .

Les minorités présentes au sein de la Pologne contemporaine sont allemande (de ), ukrainienne (de ), biélorusse (de ) et lituanienne (environ ). Au cours du recensement polonais de 2011, sur un total de d'habitants, un peu plus de se sont d'abord définis comme silésiens, tandis que se sont considérés comme exclusivement allemands.

Les Polonais sont eux-mêmes nombreux en dehors des frontières de l’État, notamment en Biélorussie (environ , jusqu’à 20 % de la population de certains districts en 1999), en Lituanie (environ 8 % de la population), en Ukraine (environ ) et en Lettonie (2 à 3 % de la population). La Pologne est en outre jusqu’à la Seconde Guerre mondiale un important foyer de population juive. La communauté juive, qui s’élève à plus de au cours des années 1920 , ne compte cependant plus qu’environ en 1990.

La Roumanie peut être considérée à la fois comme une nation d’Europe de l'Est (notamment par sa région moldave), d’Europe du Sud-Est (notamment par sa région valaque) ou d'Europe centrale (notamment par sa région transylvaine). Mais selon les auteurs, des nuances apparaissent : par exemple seuls 6,5 % du territoire roumain, à savoir la Dobrogée, font partie de la péninsule balkanique "", limitée au nord par le Danube. 

La région historique de Transylvanie, anciennement située dans le Royaume de Hongrie et peuplée d'une importante minorité magyarophone, est considérée comme faisant culturellement partie de l'Europe centrale . De même pour le Banat et la Marmatie, régions transylvaines à cheval respectivement d'une part sur la Serbie et la Hongrie et d'autre part sur l'Ukraine . Le paysage historique et social y a été dominé par des groupes d'Europe centrale (Magyars, Saxons, Souabes…) formant en Transylvanie des villes et une paysannerie libres. La coexistence entre protestants (Saxons, Hongrois partiellement) et catholiques (Souabes, Hongrois) est une caractéristique propre à l'Europe centrale. Orthodoxes, les Roumains en revanche y étaient, asservis et même exclus de la société transylvaine depuis l’échec de la révolte de Bobâlna et la constitution de en 1438. 

Enfin, bien que la Bucovine ait été pendant des siècles intégrée à la Principauté de Moldavie, cette région fut culturellement beaucoup influencée par son appartenance à l'Empire d'Autriche de 1775 à 1918 et c'est pourquoi elle est souvent considérée comme centre-européenne. Les Allemands et la bourgeoisie juive germanisée y ont exercé une forte influence jusqu'à la Seconde Guerre mondiale. Malgré leur disparition respective à la suite de la Seconde Guerre mondiale, ce caractère multi-culturel de la Bucovine s'est perpétué. 

L'oblast de Kaliningrad correspond à l'ancienne Prusse-orientale germanique et protestante. Kaliningrad est l’ancienne résidence du Grand maitre de l’Ordre teutonique, la capitale du duché de Prusse où se fait couronner roi, la ville d’Emmanuel Kant et un lieu de résidence apprécié de la bourgeoisie berlinoise. Au lendemain de la Seconde Guerre mondiale, elle subit une véritable épuration ethnique et il ne reste officiellement aucun allemand en 1953. Plus tard, les témoignages de la présence allemande seront rasés (cimetière, citadelle). L’oblast compte néanmoins à la fin du 3,5 % de Lituaniens et environ . De fait, l'ancien paysage culturel y a été considérablement transformé. Que cette zone appartienne culturellement à l'Europe centrale s'explique principalement par le fait que l'histoire locale continue de s'insérer dans cet espace géographique, malgré la nouvelle composition de la population. Les identités régionales historiques persistent et probablement, à plus long terme, le développement des États voisins d'Europe centrale aura son effet sur la région, loin de la Russie eurasiatique.

Si la Voïvodine est aujourd'hui intégrée à la Serbie, elle appartenait jusqu'en 1918 au royaume de Hongrie. Elle a de ce fait été particulièrement influencée par la colonisation, notamment de la fin du au , par des populations d'Europe centrale (Allemands, Hongrois, Croates, Slovaques ou encore Ruthènes). Les colons de l'Europe du Sud-Est qui s'y sont installés (principalement des Serbes, des Valaques, des Bulgares) ont été socialisés dans cet environnement centreuropéen. Leur conscience régionale diffèrent de celles des autres Serbes : la Voïvodine est restée, malgré la perte d'une grande partie de la population allemande, une région multi-ethnique.

Bien que la majorité de la population soit aujourd'hui serbophone et chrétienne orthodoxe, les minorités hongroise et dans une moindre mesure slovaque, croate et roumaine sont importantes numériquement, notamment dans l'ancien Banat.

La Slovaquie a été intégrée à la sphère d’influence hongroise à compter du puis à l’Empire d’Autriche de 1526 à 1918. À majorité catholique (69 % en 2001), elle a connu une forte présence protestante au cours de la Réforme. Historiquement marquée par la présence de minorités juive et allemande (représentant à elles deux 7,1 % de la population en 1921), elle compte encore au début du une importante minorité hongroise dans le sud du pays (10 % de la population totale et jusqu’à 27,5 % dans la région de Nitra) et ruthène à l’est (0,4 % de la population totale et 2,7 % dans la région de Prešov). Les minorités magyare et ukraino-ruthène sont cependant en net recul (respectivement 21,5 % et 2,9 % de la population en 1921), signe de l’homogénéisation nationale du pays. 

Du à 1918, la Slovénie est sous domination germanique, que ce soit sous la tutelle de la Bavière, de l'Empire carolingien ou de l'Autriche. Les Slovènes habitant les provinces de Carinthie, Carniole et Styrie vivent ainsi sous la domination des Habsbourg à partir des s. 

À la différence de la Croatie et de la Serbie voisines, les élites se germanisent, mais les populations paysannes y résistent fortement et conservent leur culture et leur langue. Ce contexte explique d'ailleurs le développement autonome du slovène par rapport au serbo-croate. Après avoir subi l'influence de la Réforme protestante au , la région est recatholicisée sous le règne de l'archiduc Ferdinand d'Autriche.

En Suisse romande, l'usage du français s'oppose à toute appartenance à l'Europe centrale. Cependant, plusieurs facteurs rapprochent la Suisse dans son ensemble de l'Europe centrale : la très forte empreinte culturelle et sociale de la Confédération suisse, majoritairement germanique, depuis le ; les influences alémaniques auparavant plus fortes en Suisse romande (notamment dans les cantons de Fribourg, de Vaud et du Valais) ; l'implication dans un système fédéral autorisant une forte autonomie locale et régionale, en contraste frappant avec le jacobinisme de la France voisine ; la paysannerie libre précocement ; la pluralité linguistique et enfin la cohabitation du protestantisme (dont le calvinisme genevois) et du catholicisme.

Le pays abrite historiquement une importante minorité allemande : ceux-ci représentent 35 % de la population en 1910 mais à la suite de leur expulsion en 1945, ils ne représentent plus que 0,2 % de la population en 2011. Plusieurs autres petites minorités y sont également présentes, notamment slovaque, polonaise, silésienne et hongroise représentant 2 % de la population totale. Quant à la population juive, si celle-ci est numériquement faible dès avant la Seconde Guerre mondiale, c’est avant tout parce qu’elle a été germanisée à partir de la fin du et est largement assimilée au . Elle occupe cependant une place importante dans l’imaginaire national et international : Franz Kafka est sans doute l’écrivain le plus célèbre et le cimetière juif de Prague l’un de ses plus hauts lieux touristiques.

Si la religion majoritaire y est le culte catholique, les pays tchèques ont été profondément marqués par la Réforme protestante jusqu’en 1620, date à laquelle la Bohême et la Moravie deviennent possession héréditaire des Habsbourg d'Autriche. Elle fait également partie des pays précocement industrialisés, concomitamment avec l’Allemagne ou l’Autriche, vers 1820.

La Ruthénie subcarpatique se situe géographiquement à l'extrémité de la plaine de Pannonie et appartient à ce titre à l'Europe centrale. Mais cette région est surtout pendant un millénaire et jusqu'en 1920 sous souveraineté hongroise, avant d'être intégrée à la Tchécoslovaquie (1920-1939) puis de nouveau à la Hongrie (1939-1945). Une importante minorité hongroise (12 %) y réside toujours et la majorité des slaves autochtones, les Ruthènes, ont été influencés culturellement. Cela a conduit chez ceux-ci à l'émergence d'une conscience nationale propre et à un dialecte très distinctif. Une autre expression centreuropéenne se trouve dans l'Église Uniate, rite catholique oriental. Enfin, jusqu'à la Seconde Guerre mondiale, d'importantes minorités allemandes et juives étaient également présentes, de petites enclaves germanophones existent d'ailleurs encore à ce jour. 

Ensuite, l'appartenance de la partie ukrainienne de la Galicie à l'Europe centrale se justifie non seulement par ses siècles de longue affiliation avec le Royaume de Pologne, la République des Deux Nations puis la Pologne de l'entre-deux-guerres, mais aussi par la présence autrichienne de 1772 à 1918, à une époque où les territoires au nord et à l'est sont russes. Au cours de la période autrichienne, la domination politique et sociale de la Pologne catholique était patente, même parmi la population ruthène proche de l'Église uniate. La présence d'enclaves allemandes où furent assimilés des Juifs renforcent le caractère centreuropéen de la Galicie, malgré la forte diminution des populations non ukrainiennes aujourd'hui.

Enfin, il en va de même pour la Bucovine et la Marmatie dont il est question au sujet de la Roumanie.






</doc>
<doc id="14414" url="https://fr.wikipedia.org/wiki?curid=14414" title="Endosymbiose">
Endosymbiose

L’endosymbiose est la coopération mutuellement bénéfique entre deux organismes vivants, donc une forme de symbiose, où l'un est contenu par l'autre. L'organisme interne est appelé un endosymbiote. Cette terminologie est surtout employée au niveau cellulaire pour imager une coopération entre des micro-organismes simples, et les cellules d'organismes plus évolués qui les contiennent et dont ils favorisent le fonctionnement. L'endosymbiose se différencie de l'ectosymbiose.

On parle d'endosymbiose primaire quand un eucaryote phagocyte un procaryote vivant et d'endosymbiose secondaire lorsqu'un eucaryote phagocyte un autre eucaryote possédant déjà un endosymbionte.

Les Cnidaires (anémones de mer, coraux...) ont des zooxanthelles (Dinoflagellés) dans leurs cellules qui leur apportent des nutriments et facilitent la précipitation du carbonate de calcium (très important pour la formation des récifs coralliens).

La création des Chlorophyta, Rhodophyta et Glaucophyta résulte d'une endosymbiose primaire : capture d'une cyanobactérie par un eucaryote mitochondrial, et transformation en chloroplaste.

Il y a aussi des cellules qui contiennent des bactéries permettant de fixer l'azote atmosphérique 

On utilise aussi le terme endosymbiose pour définir un ensemble d'événements et de processus évolutifs qui ont conduit à la formation des organites (mitochondrie et chloroplaste) dans les cellules eucaryotes. La mitochondrie est le résultat de l'incorporation d'une bactérie, probablement une alpha-protéobactérie, par une cellule eucaryote primitive. Plus tard, le premier chloroplaste a été formé par l'incorporation d'une cyanobactérie. Parmi les nombreuses transformations qui ont à chaque fois affecté tant la cellule eucaryotique hôte que la cellule bactérienne endosymbiotique, les plus importantes ont été les transferts de gènes des endosymbiotes dans les cellules hôtes. À chaque fois, plus de 90 % du génome de l'endosymbiote a été transféré dans le noyau de l'hôte (toutefois, quelques gènes ont pu être perdus au cours du transfert). Ce sont ces transferts de gènes qui ont permis à la cellule hôte de contrôler complètement les nouveaux organites. En effet, ces gènes transférés codent des protéines essentielles à la maintenance et au fonctionnement des organites : ces protéines produites dans le cytoplasme cellulaire sont ensuite exportées dans l'organite concerné pour y exercer les mêmes fonctions qu'elles avaient dans la bactérie originelle.

On envisage aussi l'existence d'endosymbiotes viraux, de type rétrovirus endogène, qui s'activeraient pendant la période de gestation des mammifères et dont l'infection serait une étape cruciale dans leur évolution.




</doc>
<doc id="14415" url="https://fr.wikipedia.org/wiki?curid=14415" title="Théorie endosymbiotique">
Théorie endosymbiotique

La théorie endosymbiotique, ou hypothèse de l'endosymbiose, est l'hypothèse selon laquelle les plastes et mitochondries des cellules eucaryotes proviennent de l’incorporation (endocytose) par certaines archées, des bactéries avec lesquelles elles auraient entretenu une relation endosymbiotique.

Mitochondries et plastes sont des organites semi-autonomes de la cellule eucaryote, c'est-à-dire disposant d'un patrimoine génétique et capables de se diviser indépendamment de la cellule. Ces caractéristiques furent les premiers éléments à l'appui de la théorie endosymbiotique formulée par Andreas Schimper en 1883 et remise à l'honneur par Lynn Margulis dans les années 1960. La théorie souligne que les types de bactéries incorporées auraient auparavant développé des spécialisations opérationnelles telles que la capacité de stocker de l'énergie sous forme biochimique (mitochondries) ou de capter l'énergie lumineuse (chloroplastes). Ces facultés sont en quelque sorte partagées, transmises puis héritées d'abord via la symbiose, puis en une synthèse résultant en un organisme plus complexe.

Selon Lynn Margulis, les processus résultant en l'apparition de nouvelles formes de vie à partir de symbioses, ou plus généralement synergies, entre formes de vie existantes, sont un moteur primordial de l'évolution, en particulier de sa complexification, et à l'origine de l'émergence des cellules de tous les organismes multicellulaires, dont l'espèce humaine.

Déroulement de l'endosymbiose en série :
Une cellule procaryote ancestrale (hétérotrophe, anaérobie) va grossir ; il va y avoir une invagination de la membrane plasmique qui formera une ébauche de réticulum endoplasmique et de noyau. Cette cellule ancestrale va phagocyter une cellule procaryote et hétérotrophe mais qui est cette fois ci aérobie : c'est la première endosymbiose, elle explique l'apparition des mitochondries.
La cellule nouvellement formée est un eucaryote ancestral (hétérotrophe et aérobie) ; c'est la cellule qui a été phagocytée qui est à l'origine de la mitochondrie de cet eucaryote.

Cette nouvelle cellule va à son tour phagocyter une cellule procaryote photosynthétique (donc autotrophe) et anaérobie (par exemple une cyanobactérie) : c'est la deuxième endosymbiose, elle explique l'apparition des chloroplastes.
La cellule formée est un eucaryote photosynthétique (autotrophe) et aérobie.

On va pouvoir assister à un accroissement de la biodiversité.

Les phylogénies des gènes composant les génomes des mitochondries ou celles issues des gènes nucléaires d'origine mitochondriale (beaucoup de ces gènes sont transférés au noyau lors du processus d'endosymbiose) montrent que ces mitochondries dérivent de bactéries appartenant au phylum des "Alphaproteobacteria", plus précisément de l'ordre des rickettsiales. De nombreuses espèces de ce groupe de bactéries sont des parasites intracellulaires obligatoires pénétrant dans la cellule par endocytose. Une hypothèse controversée (car elle va à l'encontre du principe de parcimonie) suggère que les bactéries entrées dans la cellule possédaient probablement un flagelle dont elles ont perdu toute trace mais qui aurait facilité la pénétration du parasite. Les mitochondries seraient issues d'un parasitisme initial s'étant progressivement transformé en relation symbiotique.

Cette théorie est aujourd'hui largement acceptée, de nombreux faits la corroborant ayant été découverts depuis sa formulation :






</doc>
<doc id="14418" url="https://fr.wikipedia.org/wiki?curid=14418" title="Aheqet">
Aheqet

Dans la mythologie égyptienne, Aheqet est la déesse de Hirour, près d'Hermopolis Magna (l'actuel el-Achmounein) dans le nome du lièvre en Moyenne-Égypte, où elle est associée au dieu-bélier Khnoum.

Elle est représentée par une grenouille symbolisant la vie et la fécondité.


</doc>
<doc id="14421" url="https://fr.wikipedia.org/wiki?curid=14421" title="Onde">
Onde

Une onde est la propagation d'une perturbation produisant sur son passage une variation réversible des propriétés physiques locales du milieu. Elle se déplace avec une vitesse déterminée qui dépend des caractéristiques du milieu de propagation. 

Physiquement parlant, une onde est un champ, c'est-à-dire une zone de l'espace dont les propriétés sont modifiées. On affecte alors à chaque point de l'espace des grandeurs physiques scalaires ou vectorielles.

Comme tout concept unificateur, l'onde recouvre une grande variété de situations physiques très différentes.

D'autre part, la mécanique quantique a montré que les particules élémentaires pouvaient être assimilées à des ondes, et "vice versa", ce qui explique le comportement parfois ondulatoire et parfois corpusculaire de la lumière : le photon peut être considéré à la fois comme une onde et comme une particule (voir Dualité onde-particule); inversement l'onde sonore (vibration mécanique) peut être considérée comme une particule (voir phonon).

Illustrons la notion de « transport d'énergie sans transport de matière ». Dans le cas d'une onde mécanique, on observe de petits déplacements locaux et éphémères des éléments du milieu qui supportent cette onde, mais pas de transport global de ces éléments. Il en est ainsi pour une vague marine qui correspond à un mouvement approximativement elliptique des particules d'eau qui, en particulier, agite un bateau en mer. Dans ce contexte, un déplacement horizontal de matière est un courant ; or, on peut avoir une vague sans courant, voire une vague allant à contre-courant. La vague transporte horizontalement l'énergie du vent qui lui a donné naissance au large et, ce indépendamment du transport global de l'eau.

Dans les instruments de musique à corde la perturbation est apportée de différentes manières : archet (violon), marteau (piano), doigt (guitare). Sous l'effet de l'excitation appliquée transversalement, tous les éléments des cordes de ces instruments vibrent transversalement autour d'une position d'équilibre qui correspond à la corde au repos. L'énergie de vibration des cordes se transforme en son car les mouvements transverses des cordes mettent en mouvement l'air qui les baigne. Un son correspond à la propagation dans l'air d'une onde de pression de cet air. En un point de l'espace, la pression de l'air oscille autour de la valeur de sa pression au repos, elle croît et elle décroît alternativement autour de cette valeur. Dans une onde sonore le mouvement local des molécules d'air se fait dans la même direction que la propagation de l'énergie, l'onde est longitudinale. Les directions longitudinales et transverses se réfèrent à la direction de propagation de l'énergie qui est prise comme direction longitudinale.

Les ondes électromagnétiques sont des ondes qui sont transversales dans le vide ou dans des milieux homogènes. En revanche, dans des milieux particuliers, par exemple le plasma, les ondes électromagnétiques peuvent être longitudinales, transversales ou parfois les deux à la fois. L'optique est un cas particulier de propagation dans des milieux diélectriques, tandis que la propagation dans un métal correspond à un courant électrique en mode alternatif.

Le signal transmis de proche en proche peut quant à lui être illustré à l'aide des dominos: ces derniers reçoivent un signal et le transmettent en tombant sur le domino suivant.
Une file de voiture avançant au signal d'un feu vert ne constitue pas un exemple de transmission de proche en proche.

Pour que des ondes se propagent dans un milieu il faut que celui-ci soit stable: sous l'action d'une perturbation extérieure, le milieu doit développer un mécanisme de rappel le ramenant vers sa position d'équilibre. La nature et les propriétés de l'onde dépendent de la manière dont ce mécanisme agit. Ainsi, par exemple, pour les vagues, ce mécanisme de rappel est la pesanteur tendant à ramener la surface libre vers une position d'équilibre. Pour les ondes sonores, le mécanisme de rappel est la tendance d'un fluide à uniformiser sa pression. Pour les ondes de torsion (comme sur un violon joué à l'archet), le mécanisme de rappel est le couple exercé par la corde.

Soient formula_1 le déplacement de l'energie et formula_2 la vitesse de l'onde :
Exemple : Ressort à boudin. Si on déplace brutalement une spire d'un tel ressort tendu entre deux supports on voit se former une onde de compression des spires. Dans ce cas le mouvement des spires se fait dans la même direction que la propagation de l'énergie, suivant la droite que constitue l'axe de symétrie du ressort. Il s'agit d'une onde longitudinale à une dimension.
Exemples : Lorsqu'on frappe un tambour, on crée sur sa peau une onde transverse à deux dimensions, comme dans le cas de la surface de l'eau.

Lorsqu'on déplace des charges électriques, les champs magnétiques et électriques locaux varient pour s'adapter à la variation de position des charges produisant une onde électromagnétique. Cette onde est transverse et peut se propager dans les trois directions de l'espace. Dans ce cas, l'onde n'est pas un déplacement de matière.

Le cas le plus simple d'onde progressive périodique est une onde dite « monochromatique » et « unidimensionnelle »

Si l'on prend un cliché du milieu à un moment donné, on voit que les propriétés du milieu varient de manière sinusoïdale en fonction de la position. On a donc une périodicité spatiale ; la distance entre deux maxima est appelée longueur d'onde, et est notée λ. Si l'on prend des photographies successives, on voit que ce « profil » se déplace à une vitesse nommée vitesse de phase.

Si l'on se place à un endroit donné et que l'on relève l'intensité du phénomène en fonction du temps, on voit que cette intensité varie selon une loi, elle aussi sinusoïdale. Le temps qui s'écoule entre deux maxima est appelé période et est noté "T".

Une onde progressive unidimensionnelle se modélise par une fonction formula_5, d'amplitude formula_6, formula_7 étant la position dans l'espace (vecteur) et formula_8 l'instant considéré.

Une très grande famille des solutions d'équations de propagation des ondes est celle des fonctions sinusoïdales, sinus et cosinus (elles ne sont pas les seules). On montre également que tout phénomène périodique continu peut se décomposer en fonctions sinusoïdales (série de Fourier), et de manière générale toute fonction continue (transformée de Fourier). Les ondes sinusoïdales sont donc un objet d'étude simple et utile.

Dans ce cadre, une onde sinusoïdale peut s'écrire :

On appelle
La phase absolue d'une onde n'est pas mesurable. La lettre grecque formula_15, désigne la pulsation de l'onde ; on note qu'elle est donnée par la dérivée de la phase par rapport au temps :
Le vecteur k est le vecteur d'onde. Lorsque l'on se place sur un seul axe, ce vecteur est un scalaire et est appelé nombre d'onde : c'est le nombre d'oscillations que l'on dénombre sur 2formula_17 unités de longueur.

On a pour la norme du vecteur d'onde :

La pulsation s'écrit en fonction de la fréquence formula_19 :

La "vitesse de phase" vaut enfin :

Une autre écriture permet de ne faire apparaître que la période temporelle formula_22et la période spatiale formula_23

On distingue plusieurs catégories d'ondes :

Le milieu de propagation d'une onde peut être tridimensionnel (onde sonore, lumineuse, etc.), bidimensionnel (onde à la surface de l'eau), ou unidimensionnel (onde sur une corde vibrante).

Une onde peut posséder plusieurs géométries : plane, sphérique, etc. Elle peut également être progressive, stationnaire ou évanescente (voir Propagation des ondes). Elle est progressive lorsqu'elle s'éloigne de sa source. Elle s'en éloigne indéfiniment si le milieu est infini, si le milieu est borné elle peut se réfléchir sur les bords, sur la sphère (comme la Terre par exemple) les ondes peuvent revenir au point de départ en faisant un tour complet.

D'un point de vue plus formel, on distingue également les ondes scalaires qui peuvent être décrites par un nombre variable dans l'espace et dans le temps (le son dans les fluides par exemple), et les ondes vectorielles qui nécessitent un vecteur à leur description (la lumière par exemple), voire des ondes tensorielles (d'ordre 2) pour les ondes gravitationnelles de la relativité générale.

Si l'on définit les ondes comme associées à un milieu matériel, les ondes électromagnétiques sont exclues. Pour éviter de les exclure on peut définir les ondes comme des perturbations d'un milieu, au sens large, matériel ou vide. Dans ce dernier cas c'est une perturbation électromagnétique qui peut se propager dans le vide (de matière).

Une onde monochromatique est caractérisée par une pulsation formula_25 et un nombre d'onde formula_26. Ces deux quantités sont liées par la relation de dispersion. À chaque exemple d'onde mentionné ci-dessus correspond une certaine relation de dispersion.


Deux vitesses peuvent être associées à une onde : les vitesse de phase et vitesse de groupe. La première est la vitesse à laquelle se propage la phase de l'onde, tandis que la deuxième correspond à la vitesse de propagation de l'enveloppe (éventuellement déformée au cours du temps). La vitesse de groupe correspond à ce qu'on appelle la célérité de l'onde.


Pour un milieu non dispersif on a formula_33

Pour une onde progressive périodique, on a une double périodicité : à un instant donné, la grandeur considérée est spatialement périodique, et à un endroit donné, la grandeur oscille périodiquement au cours du temps. Fréquence formula_34 et période T sont liées par la relation formula_35.
Pour une onde progressive se propageant avec la célérité "c", la longueur d'onde correspondante formula_36 est alors déterminée par la relation : formula_37 où formula_36 est en m, formula_39 en hertz (Hz), et "c" en m⋅s. 
formula_36 est la période spatiale de l'onde.

La célérité des ondes dépend des propriétés du milieu. Par exemple, le son dans l'air à et à 1 bar se propage à .



De façon générale, la célérité dans un milieu dépend aussi de la fréquence de l'onde : de tels milieux sont qualifiés de dispersifs. Les autres, ceux pour lesquels la célérité est la même quelle que soit la fréquence, sont dits non-dispersifs.Par exemple, l'air est un milieu non dispersif pour nos ondes sonores !
En ce qui concerne la lumière, le phénomène de dispersion est également à l'origine de l'arc-en-ciel : les différentes couleurs se propagent différemment dans l'eau, ce qui permet de décomposer la lumière du soleil suivant ses différentes composantes. La dispersion par un prisme est également classiquement utilisée : en décomposant la lumière, on peut ainsi faire de la spectroscopie (les méthodes interférentielles donnent cependant maintenant des résultats beaucoup plus précis).

La notion d'onde monochromatique est centrale pour la compréhension du phénomène mais toutes les ondes ne sont pas monochromatiques. Considérons les ondes sonores: une onde monochromatique serait une note pure (si sa fréquence tombe juste). Une note d'instrument est composée d'une note pure (le fondamental de pulsation formula_25) plus des harmoniques (des ondes dont la pulsation est un multiple de formula_25). Si on considère une musique, la structure de l'onde est compliquée, elle est constituée d'une somme d'ondes monochromatiques. Si maintenant on considère le son d'un coup sec alors l'onde n'est plus du tout monochromatique, une représentation en paquet d'onde est beaucoup plus judicieuse.









</doc>
<doc id="14423" url="https://fr.wikipedia.org/wiki?curid=14423" title="Anty">
Anty

Dans la mythologie égyptienne Anty ("Le griffu") est un dieu faucon guerrier du nome assimilé à Seth. Il était vénéré avec la déesse Matit.

Antywy correspond à deux faucons qui représentent Horus et Seth réconciliés. Un culte leur était rendu dans le village de Qaou-el-Kebir (l'antique Tjebou) en Haute-Égypte.


</doc>
<doc id="14424" url="https://fr.wikipedia.org/wiki?curid=14424" title="Astarté">
Astarté

Astarté (du grec Ἀστάρτη) est une déesse connue dans tout le Proche-Orient, de l'âge du bronze à l'Antiquité, présentant un caractère belliqueux. Athtart (𐎓𐎘𐎚𐎗𐎚 , "‘ṯtrt", "‘Aṯtart" ou "‘Athtart") à Ougarit, Shaushka ou Shaushga chez les Hourrites, Ashtart ("‘shtrt") en langue punico-phénicienne, Ashtoret ou Ashtarot (עשתרת) en hébreu, elle est l'équivalent de la déesse mésopotamienne Ishtar (pour les babyloniens) ou Inanna (pour les sumériens). Elle fut implantée dans la mythologie égyptienne sous les . À califourchon sur son cheval, elle accompagne et protège le souverain. Elle devient la fille de Rê ou de Ptah, et est une des compagnes de Seth.

Elle semble avoir comme descendance Aphrodite en Grèce, Turan en Étrurie et Vénus à Rome sous le nom officiel de Vénus Erycine.

Elle est Tanit, chez les Carthaginois.

Tanit est une déesse d'origine cananéenne de la fertilité, présidant aux naissances et à la croissance. Elle était la déesse tutélaire de la ville de Sarepta et son culte prit de l'ampleur à Carthage où elle était nommée "Oum".

Le papyrus d'Astarté (papyrus fragmentaire) semble laisser entendre qu'Astarté est celle qui contrecarre les demandes exorbitantes de tribut que Yam (roi des dieux) demande aux autres dieux.

Astarté est une divinité sidérale constamment associée à Baal. Penê-Baal (face de Baal), Selem-Baal (Salambô, « image de Baal ») sont des épithètes qui lui sont souvent données, et ces épithètes deviennent à leur tour de véritables noms propres.
Élément féminin du couple suprême qu'elle forme avec Baal, celle-ci assume des fonctions variées : protectrice du souverain et de sa dynastie, elle protège également les marins, mais son culte est, comme pour la plupart des divinités féminines primordiales de l'antiquité (et de la proto-histoire), lié à la fertilité et à la fécondité.

Étant à la fois Vénus et la Lune, elle est considérée tour à tour comme une déesse vierge et une déesse mère. De là, dans son culte, des cérémonies et des actes symboliques qui se transformaient aisément en scènes de débauche, aboutissant à des excès sanguinaires et cruels. Comme Baal, Astarté est souvent honorée, du moins jusqu'au début du premier millénaire avant notre ère, par des sacrifices humains, surtout par des holocaustes « sacrifices » d'enfants. On retrouve dans le culte d'Aphrodite les principaux traits de celui d'Astarté. Il est même probable que le nom d'Aphrodite (« Astoret », « Aphtoret », « Aphrodite ») et celui d'Amphitrite (Amphtoret) ne soient que des altérations du nom d'Astarté.

Palé-Paphos (l'ancienne Paphos) est bâtie selon la légende vers le avant notre ère par le Phénicien Cinyras, le père de Myrrha, ou par les Syriens, selon d'autres. Les fondateurs y élevèrent, en l'honneur d'Astarté/Aphrodite, un temple connu dans tout l'Orient à l'époque d'Homère, la déesse Astarté y était adorée primitivement, sous la forme d'une pierre noire.

Dans "Zadig ou la destinée", de Voltaire, Astarté est une femme, ancienne reine de Babylone réduite à l'esclavage, qui retrouve son premier et seul amour : Zadig.

Dans "Les Lettres persanes" de Montesquieu, au sein d'un apologue sous la forme d'un récit enchâssé (lettre 67, d'Ibben à Usbek) elle apparaît comme la sœur et l'amante du Guèbre Asphéridon, convertie de force à l'Islam, mariée à un eunuque, elle s'échappe avec l'aide de son frère et après maintes péripéties, ils se retrouvent à Smyrne où ils coulent une vie maritale heureuse.

Dans "Les Chansons de Bilitis" de Pierre Louÿs, Bilitis invoque Astarté en la portant aux nues, dans "Hymne à Astarté".

Dans "Soleil et Chair" de Rimbaud, Astarté est citée comme immortelle Déesse.

Astarté est l'une des 1 038 femmes dont le nom figure sur le socle de l'œuvre contemporaine "The Dinner Party" de Judy Chicago. Elle y est associée à la "déesse Ishtar", troisième convive de l'aile I de la table.



</doc>
<doc id="14428" url="https://fr.wikipedia.org/wiki?curid=14428" title="Bénou">
Bénou

Bénou, dans la mythologie égyptienne, est l'oiseau représentant l'âme – le bâ – de Rê qui le précède dans la barque solaire. Comme Rê, l'oiseau Bénou était adoré à Héliopolis où on le trouve également lié à Atoum, le dieu du soleil couchant. Le livre des morts dit : « Je suis l'Oiseau Bénou, l'Âme/cœur de Rê, le Guide des Dieux vers la Douât ».

Il était associé à la crue du Nil, à la résurrection et au Soleil. On l'associe également à la planète Vénus, celle qui fait traverser l'oiseau Bénou. Du fait de sa relation à la création et au renouveau, il était relié au calendrier. Le temple de Bénou était réputé pour les systèmes de comptage du temps qu'il recelait.

Parmi ses titres on trouve, « celui qui est venu à l'existence par lui-même », ou « seigneur des Jubilés ».

Durant l'Ancien Empire, le Bénou était représenté sous l'apparence d'une bergeronnette printanière couronnée de l'Atef - coiffure d'Osiris - ou du disque solaire. À partir du Nouvel Empire, il prit l'apparence d'un héron cendré, parfois d'un héron pourpré. En de rares occurrences, il apparaît comme un homme à tête de héron vêtu de bleu ou de blanc et portant un long manteau transparent.

Selon le mythe, le Bénou s'était créé de lui-même à partir d'un feu consumant l'un des arbres situés dans une des enceintes du temple de Rê. D'après une autre version, il avait jailli du cœur même d'Osiris. Il vivait sur la pierre benben ou sur le saule sacré d'Héliopolis. Le mythe le plus répandu fait du Bénou un oiseau mystérieux, qui n'apparaît aux hommes que tous les cinq cents ans à Héliopolis à l'occasion de sa mort et de sa résurrection qui marque ainsi le cycle du temps.

Pour les Grecs, il devint le Phénix ("phoinix") dont le nom vient peut-être du verbe égyptien "wbn" qui signifie « briller », « étinceler » et « naître » concernant le Soleil.

Une espèce de grand héron, maintenant éteinte, se trouvait jusqu'à une époque relativement récente en péninsule arabique. Il se peut qu'elle ait été à l'origine du Bénou, et de ce fait fut appelée "Ardea bennuides".



</doc>
<doc id="14430" url="https://fr.wikipedia.org/wiki?curid=14430" title="James Ellroy">
James Ellroy

James Ellroy, de son vrai nom Lee Earle Ellroy, né le à Los Angeles, en Californie, est un écrivain et scénariste américain, spécialisé dans le roman noir et le roman policier historique.

S'affirmant comme « conservateur » et « réactionnaire », il dépeint dans son œuvre un monde particulièrement pessimiste et corrompu, dans lequel perce néanmoins la notion de rédemption, fil conducteur de nombre de ses ouvrages. Parmi ceux-ci, on peut citer la série de quatre livres sur Los Angeles dont font partie "Le Dahlia noir" et "L.A. Confidential", sa trilogie "Underworld USA" qui retrace son histoire des États-Unis de 1958 à 1973, ainsi que son récit autobiographique "Ma part d'ombre".

Plusieurs de ses romans ont été adaptés au cinéma. Il est surnommé "American Dog" ou le "Dog".

James Ellroy est né à l'hôpital du Bon Samaritain de Los Angeles le d'un père comptable (Armand Ellroy) de 50 ans et d'une mère infirmière, originaire du Wisconsin. Ses parents divorcent six ans plus tard. Sa mère obtient la garde de l'enfant et celui-ci a dix ans lorsqu'elle emménage dans un quartier populaire de Los Angeles, El Monte. James est déjà un fervent lecteur de littérature policière. À ce propos, il dira : « J'étais un lecteur vorace ».

Geneva Hilliker Ellroy (1915-1958), sa mère, est assassinée le et retrouvée par une bande de jeunes près du lycée Arroyo. L'assassin ne sera jamais arrêté. James est confié à son père et il est livré à lui-même. Il sombre peu à peu dans la délinquance. C'est à cette époque qu'il commet ses premiers cambriolages. Il fait la connaissance de Randy Rice en 1961, à qui est d'ailleurs dédié "Brown's Requiem". Ils sont deux petits voyous qui font les quatre cents coups, partageant leur goût pour les romans noirs.

James Ellroy est renvoyé du collège à 17 ans, sans diplôme. Alors que la santé de son père se dégrade, Ellroy s'engage dans l'armée en 1965 et fait ses armes en Louisiane. Le père succombe rapidement d'une crise cardiaque. Sa mort marque le début d'une lente descente aux enfers. Ellroy se fait réformer de l'armée, il retrouve son ami Randy et sombre avec lui dans la consommation d'alcool et de drogue.

Ellroy vit plus de dix ans sans domicile, parfois dans de petites chambres d'hôtel miteuses, de boulots sporadiques, de larcins, dormant dans les parcs, s'introduisant chez les gens, moins pour cambrioler (il vole des sous-vêtements féminins, de l'alcool, de l'herbe, des cartes de crédit), que pour ressentir le grand frisson, déclarera-t-il plus tard.

En 1975, un abcès au poumon ainsi qu'une double pneumonie le font renoncer aux abus d'alcool.
Il prend des amphétamines jusqu'en 1977, avant d'arrêter définitivement toutes substances toxiques. Il brise le cercle infernal dans lequel il s'est enfermé. Il devient caddie de golf à Los Angeles et commence une vie plus rangée. En 1978, il s'inspire de son expérience de caddie, de son amour pour la musique classique, pour poser la trame de fond d'un premier roman : "Brown's Requiem", publié en 1981, et écrit selon son auteur « debout, dans une chambre d'hôtel miteuse ». Il poursuit avec "Clandestin" (1982), tente de donner corps à une autre de ses obsessions, le gangstérisme juif des années trente et quarante, dans "Confessions of Bugsy Siegel", mais le livre ne verra jamais le jour.

Ses agents de l'époque, Otto Penzler de Mysterious Press et Nat Sobel, le convainquent de réécrire "American Death Trip", livre, qui donnera finalement "Lune sanglante". C'est à partir de ce moment que débute la série des "Lloyd Hopkins" (1984 - 1986), et au-delà, le commencement de sa carrière littéraire. Cette série n'est pas menée à terme (cinq opus étaient initialement prévus), James Ellroy ayant décidé d'abandonner le personnage de Lloyd Hopkins, trop encombrant à ses yeux. En réalité, les motivations de l'écrivain sont ailleurs, il s'agissait notamment d'écrire un livre sur l'affaire du Dahlia noir, avant que quelqu'un d'autre ne s'en empare.

Il publie ensuite "Un tueur sur la route", récit à la première personne du parcours d'un « serial killer ». Cet ouvrage est devenu une des références majeures des écoles de formation de policiers tant il décrit avec précision la psychologie de la majeure partie des tueurs en série.

Il se lance ensuite dans l'écriture du livre qui lui fera connaître la célébrité : "Le Dahlia noir". Ce livre est une œuvre de fiction basée sur un fait historique du Los Angeles des années quarante, à savoir l'un des meurtres les plus sadiques et médiatisés qu'ait connu la ville, celui d'une jeune starlette, Elizabeth Short. Celle-ci avait été surnommée Le Dahlia noir par un journaliste, en référence à un film de série B de l'époque : "Le Dahlia bleu". Ce film, interprété notamment par Veronica Lake, avait particulièrement marqué les esprits. L'affaire du Dahlia Noir n'a, à proprement parler, jamais été résolue. James Ellroy semble avoir utilisé ce fait divers, pour commencer à exorciser le souvenir du meurtre de sa propre mère qui a eu lieu environ 11 ans et 5 mois après celui du dahlia, Elizabeth Short ayant été assassinée en janvier 1947. En réalité, James Ellroy a découvert cette histoire dans un livre que son père lui avait offert pour ses dix ans, quelques mois avant le meurtre de sa mère, d'où la « providence », le livre s'intitulant "The Badge" de Jack Webb, lequel a été quarante ans plus tard, préfacé par Ellroy lui-même. Dans "L.A. Confidential", Jack Vincennes est inspiré de Jack Webb, flic vertueux et de droite du LAPD.

Il écrira à la suite trois autres romans ayant pour cadre la ville de Los Angeles dans les années 1940-1950 et pour thème le crime et la corruption. Il s'agit de : "Le Grand Nulle Part", "L.A. Confidential" et "White Jazz" (certains des personnages du "Quatuor" apparaissent déjà dans "Clandestin", comme Dudley L. Smith).

Toujours obsédé par l'histoire de sa mère, il va tenter de résoudre, près de 40 ans après les faits, le meurtre de sa mère avec l'aide d'un policier de L.A. à la retraite (Bill Stoner). Ce sera l'occasion pour lui de retracer le parcours de sa mère et de se réconcilier avec elle, donc avec une part de lui-même. Il en écrira le récit dans un livre autobiographique : "Ma part d'ombre".

Il se présente comme un ermite vivant en vase clos pour éviter que l'univers de ses romans, qui se passent dans les années 1940 à 1970, soit perturbé par le monde contemporain.

Après avoir fui son Los Angeles natal et vécu à New York et Kansas City, il revient vivre à Los Angeles à partir de 2006. Il se sépare à cette époque d'Helen Knode, journaliste et écrivain, à qui est d'ailleurs dédié "White Jazz".

James Ellroy est à présent l'un des auteurs de roman noir américains les plus populaires, bien que peu apprécié et peu lu dans son pays . Il a publié plus de quinze romans en trente ans. Il parle sans concession de ses années difficiles dans "Destination morgue".

En attendant le troisième et dernier volume de la trilogie "Underworld U.S.A." (publié durant l'été 2009 aux États-Unis, et en janvier 2010 en France : d'ailleurs, le titre du dernier volume n'est pas "American Madness", comme annoncé depuis plusieurs années mais "Underworld USA"), les Éditions Payot & Rivages publient en octobre 2007 deux ouvrages : un essai réactualisé sur Ellroy, "Revue Polar Spécial James Ellroy" (déjà publiée en 1992) et "Tijuana mon amour", qui contient la nouvelle "Tijuana mon amour", deux nouvelles publiées dans la version américaine de "Destination:morgue!" ainsi que des articles publiés par le magazine américain GQ entre septembre 1998 et juillet 2002.

En 2008, James Ellroy est au scénario de "Au bout de la nuit", film sorti aux États-Unis en avril 2008, avec notamment Keanu Reeves dans le rôle principal. Il avait déjà, en 2002, écrit le scénario de "Dark Blue" (de Ron Shelton, avec Kurt Russell).

Concernant les œuvres à venir et contrairement à ce qu'il avait annoncé au cours de ces dernières années de ne plus écrire sur Los Angeles, Ellroy s'attaque à un nouveau Quatuor se déroulant dans la Cité des Anges. Ces romans auront lieu pendant la Seconde Guerre mondiale, époque qu'il connaît peu, selon ses termes, et traiteront entre autres thèmes des prisons secrètes où les Japonais furent internés. Plusieurs personnages apparus dans le précédent Quatuor et dans la trilogie "Underworld USA" seront présents. Le premier roman sort mi-2014 aux États-Unis, sous le titre "Perfidia", chez William Heinemann, qui a acquis les droits pour les quatre romans.

Le style d'Ellroy s'affirme par une inventivité verbale crue et acide, dépeignant avec rudesse les recoins sombres de la société américaine. La littérature noire est un espace critique mis à profit par les auteurs pour développer des mondes ambivalents, des personnages complexes aux moralités floues. Ellroy ne déroge pas à la règle.

Ellroy emploie dans certains de ses romans (notamment dans les deux premiers de la trilogie "Underworld U.S.A" : "American Tabloïd" et de façon encore plus prononcée dans "American Death Trip") un style dépouillé à l'extrême, délibérément télégraphique, type : « Sujet verbe complément. Sujet verbe complément. » Du point de vue de l'auteur, ce style est employé « pour une raison : redéfinir le langage. Redéfinir le langage car c'est la seule façon de décrire l'extrême violence de la narration, c'est-à-dire la violence de l'Histoire, et de la même façon, la violence de la vie intérieure et extérieure des trois personnages principaux. » (interview d'Ellroy au sujet du livre "American Death Trip").

À l'instar d'un Melville retranscrivant le vocabulaire des marins de son époque et l'utilisant dans son "Moby Dick", Ellroy reprend avec une précision étonnante l'argot ("slang" en anglais) et les expressions des policiers et de la pègre des années 1950 et 1960. Sont également présents dans les livres de la trilogie "Underworld USA" l'argot des "Klansmen" (Ku-Klux-Klan) des états du sud des États-Unis, et le jargon employé par les militants du mouvement nationaliste noir américain des années 1960 (dans "Blood's a Rover", littéralement : « Le sang circule »). Cette trilogie représente un travail titanesque, enrichi de références scrupuleuses, qui revêt une dimension historique. Ellroy mêle personnages réels et personnages fictifs, sur une trame de faits historiques avérés, interprétés à sa façon. Il s'intéresse aux coulisses du pouvoir des administrations Kennedy, Johnson, puis Nixon, ainsi qu'au fonctionnement des pratiques policières du F.B.I. notamment, à travers le personnage omnipotent et diabolique que représente J. Edgar Hoover dans ces trois romans.

James Ellroy, au cours de sa carrière, s'est inspiré des pionniers du roman noir tel Raymond Chandler, auteur du "Big Sleep", auquel fait écho son "Big Nowhere".

Le fait de choisir des policiers comme personnages principaux de plusieurs de ses romans provient de la lecture des œuvres de Joseph Wambaugh.

Galerie non exhaustive des personnages les plus représentatifs de l'œuvre de James Ellroy :







En 2000, un e-book, "Breakneck Pace", a été publié en anglais, comportant quatre articles et une nouvelle, tous repris dans un des quatre premiers livres publiés en français. En 2012, Ellroy publie un autre e-book contenant uniquement la nouvelle "Shakedown".








</doc>
<doc id="14431" url="https://fr.wikipedia.org/wiki?curid=14431" title="Âqen">
Âqen

Dans la mythologie égyptienne, Âqen est un dieu du monde souterrain, de la mort et des nécropoles ; il conduisait le bateau qui emmenait les défunts dans le monde des morts. Ainsi ces derniers étaient protégés par le dieu solaire Rê pendant la périlleuse traversée.

Âqen est mentionné fréquemment dans les textes des pyramides. Ce dieu devait être réveillé par Maâ, le conducteur de la barque solaire, quand il arrivait avec son bateau, accompagné de Rê et de sa suite.

Voir aussi: Passeur (Égypte antique).


</doc>
<doc id="14432" url="https://fr.wikipedia.org/wiki?curid=14432" title="Canon (Bible)">
Canon (Bible)

Le canon biblique désigne l'ensemble des textes considérés comme sacrés ayant conduit, sur plusieurs siècles, à l'établissement de la Bible, suivant principalement les rites juifs et chrétiens.

On distingue l'établissement ou la construction des canons de la Bible hébraïque ("Tanakh"), celui de la Septante et des versions en grec, celui de la Peshitta et des versions en araméen, celui du Nouveau Testament, puis les canons des Églises. Par exemple, le canon biblique de l'Église catholique a été fixé à de l'Ancien Testament et du Nouveau Testament.

Le mot canon, qui vient du grec ancien κανών ("kanôn"), lui-même d'origine sémitique : hébreu "qaneh" (roseau, mesure, canne), akkadien "quanu", ougaritique "qn", le punique "qn"') et peut-être même sumérien "gin".
Au , le mot passe dans le milieu chrétien et désigne :
Paul de Tarse utilise le terme κανών pour désigner à la fois les limites des territoires à évangéliser qui lui sont impartis (2 Co 10,13-16) et la règle de conduite impartie aux chrétiens (Ga 6,16).

Au , le sens de ce mot est mis en rapport avec la Bible. Il s'agit alors des livres de l'Ancien Testament et du Nouveau Testament reconnus par l'Église et qui sont deux expressions nouvelles signalées :

L'idée d'un canon de la Bible hébraïque (nommée « Ancien Testament » par Justin de Naplouse pour appuyer l'appropriation de ces textes par l'Église catholique) ne s'impose qu'après le Synode de Jamnia (ou Yabnah ou Yabneh), c'est-à-dire à la fin du , après la destruction du Second Temple par les Romains. Auparavant, le concept d'une liste close (au sens de complète et définitive) 
des livres repris dans la Septante est inconcevable. En revanche, le processus de canonisation semble avoir été un processus ouvert.

Le texte massorétique actuel est contemporain de l'écriture de la Mishna, c'est-à-dire le fruit du travail des docteurs du . Ce travail de grammairiens (la vocalisation enregistre diverses prononciations possibles) se poursuit jusqu'au ; le manuscrit de Saint-Pétersbourg ("Codex Leningradensis, coté B19A") qui date du (copié au Caire en 1008-1009, d'après le colophon) et qui sert de base aux bibles d'étude en hébreu (comme la BHS - Biblia Hebraica Stuttgartensia - éditée par Rudolf Kittel), est un témoin de ce travail. Jusqu'au , la Bible de tous est le texte grec de la Septante, quoique des éditions en hébreu différentes du texte proto-massorétique aient existé, comme le montrent les rouleaux de Qumran.

Dans le "Contre Apion" (I:38-40), Flavius Josèphe donne une liste de 22 livres composant le "canon" des écritures juives. Elle comprend :

Après Jamnia, le milieu rabbinique tannaïte, le milieu qui rédige la Mishna, se vit comme l'héritier naturel de toutes les traditions antérieures, qu'elles soient saducéennes, esséniennes ou, bien évidemment, pharisiennes. Toutefois, pour le milieu de Gamaliel II, l'attitude apocalyptique des « membres du Mouvement de Jésus » selon l'expression de Jacques Schlosser (professeur à la Faculté de théologie catholique de Strasbourg), en fait un danger pour les relations avec l'occupant romain. En outre, ce sont des "minim" (sectaires), en cela qu'ils concentrent l'accès à l'alliance sur le baptême. De ce point de vue, ils se désintéressent de l'ensemble du peuple. De facto, ils sont une secte réformatrice et diviseuse comme l'étaient les Esséniens.

En outre, ils « font dire » des choses de plus en plus étranges à la Septante. Les controverses rabbiniques, enregistrées dans le Talmud montrent des discussions qui, sous prétexte d'exégèse imaginative, présentent des opinions sur la pertinence de tel ou tel texte (Traité Meguila, Traité Soferim).
On assiste donc à un retour à l'hébreu, à une méfiance envers les textes grecs qui ne s'apaisera qu'au début du .

Les témoins de cette élaboration sont nombreux. Par exemple :

La rédaction concomitante de la Mishna et des Évangiles révèle des polémiques sous-jacentes. Ce sont des rédactions concurrentes. Ces polémiques jouent un rôle non négligeable tant dans l'évolution de la pensée rabbinique autour de Gamaliel II que dans l'accouchement du système chrétien.

"(Voir l'article spécialisé Abraham Joshua Hershel)"

À partir d'un consensus établi autour d'une canonisation en 3 phases :
Albert C. Sundberg, Jr envisage, à partir de 1964, une hypothèse plus complexe.

Henri St. John Thackeray est un grammairien. Il a travaillé essentiellement sur la Septante, c'est-à-dire sur la Bible en grec. En 1921, il publie : "The Septuagint and Jewish Worship; A Study in Origins, (The Schweich Lectures of the British Academy)".


Deux thèses successives sont actuellement en voie de synthèse.

En résumé :

Vers 200 émerge l'idée d'un catalogue des livres composant le Nouveau Testament. Font alors autorité :

Outre les indices du cheminement dans la lente constitution du corpus, indiqué dans l'article Évangile, des témoins plus concrets sont donnés dans :
L'influence de Marcion fut déterminante dans la constitution d'un canon.

Selon cet ouvrage, il n'y eut jamais de "Canon Alexandrin" de la Septante, ce que confirment les études sur la construction du Talmud, telles qu'évoquées ci-dessus.

L'opportunité d'une liste close n'interroge les chrétiens qu'à partir de la toute fin du . Elle n'intéresse réellement que les Occidentaux. Le canon de l'Ancien Testament, celui des Églises latines comme celui des Églises grecques, évoluent parallèlement. Jusqu'au , on parle de canon "ouvert" et postérieurement de "canon fermé".

Toutefois Steinberg date le fragment de Muratori du et lui donne une origine orientale. Ces caractéristiques en font une liste parmi toutes les autres et lui retirent son statut de liste inaugurale. Cette conception élimine le long débat entre les Églises et attribue la fermeture du canon à une autorité ecclésiastique.

Le contenu du fragment ruine cette hypothèse sur la construction du Nouveau Testament. Le Fragment ne dit mot de l'Épître aux Hébreux fort appréciée dans les Églises orientales parce que faussement attribuée à Paul de Tarse.

Jusqu'au , la Bible de tous est la Septante, quoique des éditions en hébreu différentes du texte proto-massorétique aient existé, comme le montrent les rouleaux de Qumran. C'est elle qui donnera l'Ancien Testament des chrétiens. Le texte massorétique actuel est contemporain de l'écriture de la Mishna, c'est-à-dire le fruit du travail des docteurs du quoiqu'un texte proto-massorétique soit connu dès 150 avant l'ère commune.

Ce travail de grammairiens (la vocalisation enregistre diverses prononciations possibles) se poursuit jusqu'au ; le manuscrit de Saint-Pétersbourg ("Codex Leningradensis") qui date du et sert de base aux bibles d'étude en hébreu, est un témoin de ce travail.

Après le synode de Jamnia, le milieu rabbinique tannaïte qui a rédigé la Mishna, se vit comme l'héritier naturel de toutes les traditions antérieures, qu'elles soient saducéennes, esséniennes ou, bien évidemment, pharisiennes. Pour le milieu de Gamaliel II, les chrétiens apparaissent comme des sectaires et des hérétiques. Leur interprétation de la Septante est mise en cause. On assiste donc à une méfiance envers les textes grecs et à un retour à l'hébreu. La rédaction concomitante de la Mishna et des Évangiles révèle donc des polémiques sous-jacentes qui ont joué un rôle non négligeable tant dans l'évolution de la pensée rabbinique autour de Gamaliel II que dans l'accouchement du système chrétien.

Les tentatives de Tatien, de Marcion face à l'opposition d'Irénée et au dogmatisme d'Athanase sont clairement à l'origine du Canon.

Il précède le canon officiel. Il rejette toute référence à l'Ancien Testament et ne garde des écrits qui circulent :
Les lettres de Paul connues par Marcion sont les suivantes :

Troublé par le fait qu'on retienne 4 évangiles présentant 4 témoignages différents sur "les dits et les faits de Jésus", Tatien entreprend de les fondre en un seul récit continu et cohérent, ne retenant que ce qui leur est commun, gommant par cette sélection tout ce qui est divergent qu'il considère comme dépourvu de sens autre qu'anecdotique. Il s'inspire des 4 évangiles, canonisés depuis. La liberté avec laquelle il les utilise, semblable à celle dont usèrent les auteurs de "selon Luc" et "selon Matthieu" dans leur reprise de "selon Marc" montre qu'à l'instant où il écrit, les 4 "grands" évangiles ne sont pas encore sacralisés. Les emprunts qu'il fait à d'autres sources montrent qu'ils n'ont pas vocation à être une source exclusive. Dans un temps où triomphe l'idée de Plotin que la vérité est une et que le "dissensus" est haïssable, on ne peut concevoir que chacun des évangiles réputés canoniques avait vocation à se suffire à lui-même et non à compléter les autres. Chacun d'eux, du point de vue de leurs auteurs, se serait proposé de devenir le seul témoignage valide de la vie et de l'enseignement de Jésus qui supplanterait tous les autres. D'ailleurs, l'intention polémique est clairement marquée dans l'incipit de "l'auteur à Théophile".
Plusieurs compilations harmonisantes ont été produites. Celle de Tatien perdurera dans le corpus canonique de l'.

Pourquoi ces quatre-là et pas les autres ? Cette question vient immédiatement à l'esprit d'un lecteur du . Elle intéressait aussi les lecteurs de l'Antiquité tardive et la réponse donnée par Irénée de Lyon dans son "Adversus Hæreses" ne manquera pas d'étonner le lecteur contemporain :
L'étude des Pères de l'Église et le recueil des citations qu'ils donnent dans les écrits des montrent que les « paroles attribuées à Jésus » ne proviennent pas des évangiles tels qu'ils nous sont connus. La première hypothèse est qu'ils citent de mémoire et que celle-ci n'est pas tout à fait précise. La comparaison avec les citations de l'Ancien Testament montre moins de divergences avec les textes de la Septante. Devrait-on supposer que leur mémoire est moins fidèle pour les « dits de Jésus » que pour les textes de la Septante ? Pourtant, les hommes de l'Antiquité étaient surentraînés pour de longues récitations. On formule donc une autre hypothèse. D'autres évangiles ont été écrits qui transmettent d'autres traditions sur les « dits et les faits de Jésus ». Ils mettent à profit la même tradition orale et servent de référence dans les textes des Pères anciens.
Des ouvrages comme :
conservent des traditions sur Jésus qui ne doivent rien aux évangiles canoniques. Quelques-uns de ces textes périphériques sont couramment utilisés qui n'ont pas été conservés par la canonisation. Ainsi, Papias, évêque de Hiérapolis qui n'est connu que par "l'Histoire ecclésiastique" d'Eusèbe de Césarée, connaît des récits similaires à ceux rapportés dans l'évangile « selon Marc » et des éléments de récits qu'on retrouvera dans l'évangile « selon Matthieu ». Ces quelques indications sur les connaissances des premiers pères suffisent à invalider la théorie d'Augustin d'Hippone sur la chronologie des évangiles, telle que rapportée pour mémoire dans l'article le Problème synoptique. Papias a écrit des "Explications sur les paroles du Seigneur", perdues depuis, à l'exception de la citation de la Préface qu'en fait Eusèbe. Ces explications portent sur les récits oraux qu'il a reçus.
Selon qu'on se situe au , au , au , les hérésies ne sont pas les mêmes. Il en résulte que les livres rejetés ne sont pas les mêmes. À l'exception des "hérésies" donatiste, mélécienne et novartienne, qui traitent des désaccords sur la conduite à tenir face aux apostats et autres relaps et posent la question du "pardon", les hérésies sont majoritairement régionales et régionalement traitées jusqu'au concile de Nicée de 325.
On comprend donc qu'une liste d'hérésies qui varie avec la géographie (région) et l'histoire (le temps) conduit à des exclusions/inclusions qui relèvent de temps à autre du règlement de comptes. Jusqu'au concile de Chalcédoine, tel qui est excommunié à Rome peut être relevé à Antioche ou ailleurs et réciproquement. Deux exemples :

Tatien et Marcion, par le choix de leurs sources et leur entreprise de réécriture témoignent de la résistance à accepter plusieurs témoignages divergents. Le rôle de Marcion fut décisif, ne serait-ce que dans l'idée de clore une liste pour la dresser contre les autres sources, d'un corpus s'opposant à d'autres corpus disponibles. L'Église de Marcion, discréditée sous le nom de marcionitisme, subsistera plusieurs siècles en Asie Mineure. Pour lutter contre celle-ci, les patriarcats orientaux et occidentaux utiliseront la méthode qu'elle avait inaugurée : dresser une liste où la distinction de certains livres élevés au statut "d'écriture inspirée" renvoie les autres sources au rang de "fabulae", c'est-à-dire d'apocryphes.

Selon qu'elles viennent d'Orient et d'Occident, les listes de livres retenus ne sont pas les mêmes. Outre les réticences à la réception plurielle d'un témoignage "tétramorphe" (néologisme d'Irénée), certains livres reçus en Occident sont répudiés en Orient et réciproquement. Les Églises orientales fonctionneront longtemps avec un "canon de 22 livres" tandis que les Églises d'Occident tiendront pour un "canon de 27 livres". Orientaux comme Occidentaux utilisent cependant les mêmes critères :
Ce classement appelle quelques remarques.

Elle comporte généralement des textes dont la critique textuelle contemporaine montre qu'ils sont de rédaction contemporaine ou quasi contemporaine de ceux qui se chargent d'établir les listes. Quoique la canonisation d'un texte contemporain ne soit pas interdite, comme le montre celle du Diatessaron de Tatien dans l'Église syriaque, il semble que l'ancienneté attribuée aux textes soit un sésame. Cette deuxième liste comporte aussi des livres "nés de père inconnu" mais reçus partout. Au bout de longues tractations, certains seront inclus dans le canon. D'autres, d'usage liturgique dans certaines communautés, seront rejetés. On n'a aucune idée de ce que signifie "pseudépigraphie". Pseudépigraphe est le mot utilisé par les protestants pour designer les livres de l'Ancien Testament que les catholiques nomment « Apocryphes ».

La première liste comprend partout :
En ce qui concerne les épîtres de Paul, les listes varient. Marcion en connaissait 10, les autres listes en donnent 13, voire 14. Certaines listes furent construites autour de la symbolique du nombre 7 au prix d'acrobaties : les lettres doubles comptant pour une seule.
Les livres suivants furent toujours retardés :
Ce sont :
Quelques textes sont systématiquement ignorés en Occident qui sont appréciés en Orient et réciproquement :

Le canon se clôt à 27 livres par autorité d'Église. De ce fait, il se ferme plus tôt qu'en Orient aux synodes régionaux de Carthage de 397 et de 419. Jusqu'aux dernières années du , il exclut l'épître aux Hébreux. Cette question n'est jamais traitée dans les conciles "œcuméniques" de la fin du siècle. Cette lacune assigne donc ces conciles au rôle de tribunal et au lieu d'espace où traiter des affaires des Églises dans un projet d'unification. En dépit des décrets de Gélase, les littératures apocalyptiques autres que celle de Jean seront recopiées et tenues pour partie prenante du Nouveau Testament jusqu'au milieu du Moyen Âge ().

C'est l'usage des livres dans les communautés qui détermine le canon. Le canon démarre à 22 livres, sans épître aux Hébreux, sans lettres de Jacques, ni 2 Pierre, ni 3 Jean non plus que Jude. Au milieu du , l'œuvre de Cyprien de Carthage ne cite aucun de ces 5 livres non plus que la lettre à Philémon et, bien évidemment sans Apocalypse.

Cette opposition aux littératures apocalyptiques s'inscrit dans la lutte contre le millénarisme montaniste, attestée par Eusèbe de Césarée, puis par Grégoire de Naziance, Amphiloque d'Iconium (mort en 396) qui déclare à propos de l'Apocalypse : 
La "Lettre festale 39" d’Athanase d'Alexandrie, datée de 367, est la plus ancienne attestation d’un canon du Nouveau Testament comprenant 27 livres : 
L'école d'Antioche, avec Jean Chrysostome (347-407), Théodore de Mopsueste (393-466) s'en tient à un canon de 22 livres sans Apocalypse. Le concile "In Trullo" (692) ne règle rien.

Par ailleurs, dans sa lettre festale, Athanase recommande des livres non canoniques pour l'instruction des débutants :

En revanche il condamne les apocryphes :
Dans cette critique d'Athanase s'enracine la meilleure hypothèse actuelle concernant les manuscrits coptes de Nag Hammadi ; on peut penser qu'ils furent enterrés parce qu'une partie d'entre eux faisaient partie des livres condamnés.

Le passage de "livres sans père" à "livres absurdes et impies" s'opère lentement au cours de débats et s'exprime sous cette forme chez Eusèbe. En quelque sorte, la qualité d'hérétique remonte depuis les hommes jusque vers les livres apocryphes. Cette appréciation est savoureuse "a posteriori" quand l'exégèse a montré depuis le que même les 4 évangiles réputés canoniques sont eux-mêmes des pseudépigraphes.






</doc>
<doc id="14435" url="https://fr.wikipedia.org/wiki?curid=14435" title="Spectrométrie de masse">
Spectrométrie de masse

La spectrométrie de masse est une technique physique d'analyse permettant de détecter et d'identifier des molécules d’intérêt par mesure de leur masse, et de caractériser leur structure chimique. Son principe réside dans la séparation en phase gazeuse de molécules chargées (ions) en fonction de leur rapport masse/charge ("m/z"). Elle est utilisée dans pratiquement tous les domaines scientifiques : physique, astrophysique, chimie en phase gazeuse, chimie organique, dosages, biologie, médecine... le temps de détection est très rapide.

Le spectromètre de masse, initialement conçu par le Britannique Joseph John Thomson, comporte une source d'ionisation suivie d'un ou plusieurs analyseurs qui séparent les ions produits selon leur rapport "m/z", d'un détecteur qui compte les ions et amplifie le signal, et enfin d'un système informatique pour traiter le signal. Le résultat obtenu est un spectre de masse représentant les rapports "m/z", où m représente la masse et z la valence (ou m/q, q représentant la charge) des ions détectés selon l'axe des abscisses et l'abondance relative de ces ions selon l'axe de ordonnées.

Le spectromètre de masse se compose donc de quatre parties :


Les ionisations EI et CI, qui nécessitent un certain niveau de vide, sont préférentiellement utilisées en couplage avec la chromatographie en phase gazeuse (la CI fonctionnant à partir d'une source EI). En revanche, les deux sources à pression atmosphérique (electrospray et APCI) dites à « ionisation douce », sont principalement utilisées en couplage avec la chromatographie en phase liquide.

Des électrons émis par un filament rencontrent les molécules qui entrent dans la source : lors de la rencontre, si l'énergie cinétique des électrons est suffisante, un électron est arraché de la molécule "M", la transformant en un ion radical "M". Celui-ci peut ensuite se fragmenter suivant son énergie interne. L'EI conduit ainsi à un spectre assez fourni, avec de nombreux fragments, très riche en informations structurales.

En plus du dispositif EI ci-dessus, un gaz réactif est introduit dans la source et ionisé par impact électronique. S'ensuit une série de réactions qui donne naissance à des ions pouvant réagir avec les molécules d'analyte arrivant dans la source. Ce type de réactions ions-molécules produit principalement (en mode positif) des ions [MH], et [M+adduit+H], permettant ainsi d'accéder à la masse moléculaire de l'analyte. 
Le méthane, l'isobutane et l'ammoniac sont parmi les gaz d'ionisation chimique les plus utilisés.

Pour la détection de molécules globalement électronégatives, comportant des parties halogénées, on peut faire appel à l'ionisation chimique négative. Le principe est de charger négativement ces molécules en les bombardant d'électrons qui seront capturés par les atomes électroattracteurs. Du fait de la forte probabilité de capture de l'électron, ce type d'ionisation peut être 1000 fois plus sensible que l'ionisation chimique positive.

Elle permet d'analyser des molécules non vaporisables sous vide (grosses molécules biologiques). L'ionisation est effectuée par expulsion en phase vapeur des ions contenus dans un échantillon liquide à la suite d'un bombardement d'atomes rapides (Ar ou Xe). Les molécules ainsi ionisées n'ont pas beaucoup d'énergie interne, la fragmentation est donc faible mais l'ion moléculaire est facilement reconnaissable et la masse moléculaire est facile à déterminer.
L'échantillon est mélangé en solution à une matrice liquide non volatile (glycérol, thioglycérine, alcool m-nitrobenzylique). Un faisceau à haute énergie (de l'ordre de 4 à ) d'atomes neutres (Ar ou Xe) est envoyé sur l'échantillon et la matrice dans la chambre de collision causant ainsi les phénomènes de désorption et d'ionisation. Les ions préexistants en solution sont expulsés en phase gazeuse et accélérés vers l'analyseur.

Son principe est le suivant : à pression atmosphérique, les gouttelettes de solutés sont formées à l'extrémité d'un fin capillaire porté à un potentiel élevé. Le champ électrique intense leur confère une densité de charge importante. Sous l'effet de ce champ et grâce à l'assistance éventuelle d'un courant d'air coaxial, l'effluent liquide est transformé en nuage de fines gouttelettes (spray) chargées suivant le mode d'ionisation. Sous l'effet d'un second courant d'air chauffé, les gouttelettes s'évaporent progressivement. Leur densité de charge devenant trop importante, les gouttelettes explosent en libérant des microgouttelettes constituées de molécules protonées ou déprotonées de l'analyte, porteuses d'un nombre de charges variable.
Les ions ainsi formés sont ensuite guidés à l'aide de potentiels électriques appliqués sur deux cônes d'échantillonnage successifs faisant office de barrières avec les parties en aval maintenues sous un vide poussé (<10 Torr). Durant ce parcours à pression élevée, les ions subissent de multiples collisions avec les molécules de gaz et de solvant, ce qui complète leur désolvatation. En faisant varier les potentiels électriques appliqués dans la source il est possible de provoquer des fragmentations plus ou moins importantes.
L'avantage de cette méthode d'ionisation comme pour l'APCI est l'obtention d'ions multichargés, pour les macromolécules, polymères. Elle permet d'autre part de générer une ionisation « douce » : des ions moléculaires sont formés en majorité.

Les échantillons liquides sont directement introduits dans un nébuliseur pneumatique. Sous l'effet d'un jet d'air ou d'azote, le liquide est transformé en fin brouillard. Un chauffage assure la désolvatation des composés. Ces derniers sont ensuite ionisés chimiquement à pression atmosphérique : en général, la phase mobile vaporisée joue le rôle de gaz d'ionisation et les électrons sont obtenus à partir de décharges d'électrode couronne. L'ionisation des composés est très favorisée lors de ces techniques car la fréquence des collisions est élevée à pression atmosphérique.
L'APCI est une technique analogue à l'ionisation chimique (CI), elle fait appel à des réactions ions-molécules en phase gazeuse, mais à pression atmosphérique et conduit essentiellement à la formation d'ions [MH] ou [M-H].

Un faisceau laser pulsé est utilisé, généralement dans le domaine des ultraviolets, pour désorber et ioniser un mélange matrice/échantillon cocristallisé sur une surface métallique, la cible.
L'ionisation de l'échantillon a donc lieu soit dans la phase solide avant la désorption, soit par transfert de charge lors de collisions avec la matrice excitée après désorption. Elle conduit à la formation d'ions monochargés et multichargés de type [M+nH], avec une nette prépondérance pour les monochargés.

Le chauffage de l'échantillon désorbe des atomes qui se présentent alors sous forme ionisée sous l'effet de la chaleur. Des lentilles électromagnétiques focalisent les ions en faisceaux individualisés en fonction du ratio masse / charge. Des variations de cette technique existent sous la forme ID-TIMS (pour l'anglais "Isotope Dilution") et CA-TIMS (pour l'anglais : "Chemical Abrasion").

Les analyseurs se différencient par leur principe de mesure du rapport "m/z" des ions, qui est :

Un quadripôle (ou quadrupôle) est constitué de quatre électrodes parallèles de section hyperbolique ou cylindrique. Les électrodes opposées distantes de 2formula_1 sont reliées entre elles et soumises au même potentiel. Les électrodes adjacentes sont portées à des potentiels de même valeur, mais opposés de sorte que l'écart de potentiel soit égal à formula_2. 
Ce potentiel formula_2 résulte de la combinaison de tensions, l'une continue (U) l'autre alternative (V) de haute fréquence f : formula_4

En appliquant cette différence de potentiel entre chaque paire d'électrodes, il se crée un champ électrique quadripolaire. Un point de coordonnées (x, y, z) situé dans le champ électrique sera alors soumis au potentiel : formula_5
La trajectoire d'un ion pénétrant dans le quadripôle sera donc uniforme selon l'axe z et décrite par les équations de Mathieu selon les deux autres axes. Il est possible de définir en fonction des valeurs U et V des zones de stabilité telles que les coordonnées x et y de l'ion restent strictement inférieures à formula_1. L'une d'entre elles est exploitée en spectrométrie de masse (voir figure) (Les ions qui se trouvent dans cette zone auront donc une trajectoire stable dans le quadripole et seront détectés). En gardant constant le rapport U/V, on obtient une droite de fonctionnement de l'analyseur. Un balayage de U avec U/V constant permet l'observation successive de tous les ions dont la zone de stabilité est coupée par la droite de fonctionnement. La résolution entre ces ions est d'autant plus grande que la pente de la droite est élevée.
En l'absence de tension continue, tous les ions de rapports m/z supérieurs à celui fixé par la valeur de V appliquée auront une trajectoire stable (x et y < formula_1), le quadripôle est alors dit transparent et sert de focalisateur d'ions.

Les principaux avantages du spectromètre quadripolaire résident dans sa souplesse d'utilisation, sa résolution unitaire sur toute sa gamme de masse, sa vitesse de balayage satisfaisante, ainsi que son adaptabilité à différentes interfaces permettant le couplage avec la chromatographie gazeuse ou liquide.

Identique à l'analyseur quadripolaire mais avec 8 électrodes, cet analyseur sert uniquement à la focalisation des ions.

C'est un piège ionique où la préparation, l'analyse et la détection des ions s'effectuent dans un même espace, suivant des séquences temporelles successives.
Le piège est constitué de trois électrodes à section hyperbolique : une électrode annulaire encadrée par deux électrodes-chapeaux (d'entrée et de sortie) qui forment les calottes supérieure et inférieure du dispositif. Une tension en radiofréquence formula_8 combinée ou non à une tension continue U est appliquée entre l'électrode centrale et les deux électrodes calottes. Le champ résultant est alors tridimensionnel.
Les domaines de stabilité des ions sont à nouveau déterminés par les équations de Mathieu. Celui exploité est défini tel que lorsque les ions en sortent, leur trajectoire radiale reste stable contrairement à celle selon l'axe des z. Un balayage de l'amplitude de la radiofréquence V entraînera donc l'expulsion des ions piégés selon cet axe, vers le détecteur. Les trajectoires stables des ions, au sein du champ quadripolaire résultant sont tridimensionnelles, en forme de huit.

L'analyseur à temps de vol consiste à mesurer le temps que met un ion, accéléré préalablement par une tension, à parcourir une distance donnée. Le rapport masse sur charge est directement mesurable à partir du temps de vol.
Un analyseur à temps de vol se compose d'une zone d'accélération où est appliquée la tension accélératrice, et d'une zone appelée tube de vol, libre de champ. Les ions accélérés pénètrent dans le tube de vol libre de tout champ. La séparation des ions ne va donc dépendre que de la vitesse acquise lors de la phase d'accélération. Les ions de rapport "m/z" le plus petit parviendront au détecteur les premiers. Pour chaque groupe d'ions de même rapport "m/z", un signal est enregistré au niveau du détecteur sous la forme d'une fonction temps/intensité.
Ce mode de détection comporte cependant certaines limitations en termes de résolution : ainsi deux ions identiques, de même vitesse initiale, mais localisés à deux points différents, entreront dans le tube de vol à des vitesses et des temps différents. Celui le plus loin du détecteur à l'origine sera accéléré plus longtemps et aura donc un temps de vol plus court, d'où une dispersion en temps et en énergie. Le mode réflectron permet de pallier ce phénomène.En mode réflectron, un miroir électrostatique impose un champ électrique de direction opposée à celle du champ accélérateur initial, et donc du mouvement des ions. Ces derniers voient ainsi leur trajectoire modifiée : ils pénètrent dans le réflectron et en ressortent avec une vitesse longitudinale de sens opposé à leur vitesse initiale. Les ions les plus énergétiques arrivent les premiers au niveau du réflectron et vont y pénétrer plus profondément, ils seront donc réfléchis dans un temps plus long. De cette façon, tous les ions de même rapport "m/z" se trouvent focalisés sur un même plan, le détecteur du réflectron étant placé sur le plan de focalisation de ces ions. En outre, le réflectron permet d'allonger la distance de vol sans pour autant augmenter la taille de l'analyseur : les ions mettent plus de temps pour atteindre le détecteur, et réduisent aussi leur dispersion en temps, la résolution s'en trouve donc grandement améliorée.

 L’analyseur à résonance cyclotronique d’ion se compose d’une cellule ICR (de configuration cubique par exemple) qui comporte notamment six plaques sous tension, isolées les unes des autres. 
L’application d’un champ magnétostatique B suivant l’axe z soumet les ions à la force de Lorentz F = ez v ^ B. Leur mouvement dans le plan (xy) est alors « cyclotronique », c’est-à-dire circulaire uniforme de fréquence f= eB/(2π.m/z). Les ions sont par ailleurs confinés suivant l’axe z par un champ électrostatique imposé par les deux plaques parallèles au plan (Oxy), résultant de l’application d’une tension faible. 
Une fois piégés dans la cellule, les ions ont donc la même trajectoire mais pas la même position à un instant déterminé (a). Il convient donc de donner aux ions de même m/z un mouvement d’ensemble en les mettant en phase, par résonance cyclotronique. Pour cela, les ions m/z sont excités par un champ alternatif de fréquence correspondant à leur fréquence cyclotron : pour exciter tous les ions d’une certaine gamme de m/z, une tension contenant toutes les fréquences cyclotron correspondantes est imposée. Les ions sont alors accélérés, mis en phase et voient le rayon de leur orbite augmenter (b). 
Le courant induit par le mouvement cohérent des ions de même m/z sera mesuré sur les plaques de détection (c) : ce sera une sinusoïde amorti de fréquence cyclotronique. Le courant induit total mesuré sera donc la somme de sinusoïdes amorties des fréquences cyclotroniques correspondant aux ions de m/z excités par résonance. La fréquence cyclotron étant proportionnelle à 1/(m/z), l’inverse de la transformée de Fourier du courant obtenu permet d’aboutir au spectre de masse en m/z.

Cet analyseur a l’une des meilleures résolutions qui soient (Rs>100 000), dès lors le spectre MS a une plus grande capacité de pics, ce qui maximise la quantité d’informations pour l’analyse de mélanges complexes. Cependant, la largeur des pics étant proportionnelle à (m/z)², la résolution est meilleure aux m/z inférieures à 5000 Th. L’excellente précision du FT-ICR sur la mesure de masse (5-10 ppm) lève ou diminue les ambiguïtés sur l’identification des composés. 
La gamme de masse dépend de la valeur du champ magnétique, elle s’étend jusque 27000 Da pour un champ de 7 T. En revanche, la gamme dynamique est assez restreinte, avec 2-3 décades, car cet analyseur par confinement souffre du même défaut que le piège quadripolaire, la coexistence possible d’un nombre limité d’ions. Dès lors, les pics très minoritaires dans le spectre de masse présenteront une mesure de masse moins précise.
Le FT-ICR permet l’analyse en MS/MS dans la cellule même, avec possibilités variées d’activation des ions et donc de fragmentations sélectives.

L’orbitrap se compose d’une électrode creuse, à l’intérieur de laquelle est placée coaxialement une électrode en forme de fuseau. La forme particulière de ces deux électrodes permet l’imposition d’un champ électrostatique quadro-logarithmique avec la tension :
formula_9.

avec Rm rayon caractéristique de l’électrode centrale, k courbure du champ, et C une constante.

Le champ est en particulier quadripolaire suivant l’axe z des électrodes. Les ions sont injectés tangentiellement à l’électrode centrale et piégés autour d’elle par la force électrostatique qui compense les forces centrifuges. Le mouvement des ions se décompose alors ainsi : un mouvement circulaire autour de l’électrode centrale dans le plan (xy) et un mouvement oscillatoire de va-et-vient selon l’axe z. En particulier, les ions d’un m/z donné seront sur la même trajectoire circulaire qui oscille axialement avec une fréquence f. f est indépendante de la vitesse ou de l’énergie des ions et s’exprime comme 1/2π√(km/z). De la même façon que pour le FT-ICR, le courant induit par ces oscillations permet par une transformée de Fourier d’accéder aux m/z.

La précision des mesures de m/z est particulièrement bonne (1-2 ppm) et la résolution (jusque ) rivalise avec celle du FT-ICR, d’autant qu’étant proportionnelle à 1/√(m/z), elle diminue moins vite avec le rapport m/z que dans le cas du FT-ICR. La gamme dynamique est satisfaisante (> 3 décades). L’orbitrap est principalement utilisée en spectrométrie de masse en tandem, associée à un piège linéaire.

L'ion est éjecté dans un milieu dans lequel règne un champ magnétique uniforme perpendiculaire au plan de la trajectoire. Du fait de la force de Lorentz, la trajectoire se courbe, et le point d'impact de l'ion (donc sa déviation) permet de connaître sa masse à partir de la charge.

En effet, soit formula_10 le champ magnétique (dirigeant formula_11) de coordonnées formula_12 et formula_13 la vitesse initiale orthogonale à formula_10, elle dirige formula_15.

On a alors:
formula_16.

D'où, en écrivant la relation fondamentale de la dynamique :
formula_17.

Soit:
formula_18 où formula_19.

Posons formula_20.
On a alors formula_21.

En résolvant, formula_22.

Et donc: 
formula_23
formula_24 (à l'aide des conditions initiales).

Il s'agit bien de l'équation paramétrique d'un cercle de rayon 
formula_25.

Le spectromètre mesure ensuite les distances d'impact lorsque la particule a effectué un demi-cercle. La distance au point d'origine correspond au diamètre donc au double du rayon donné par la dernière formule. La charge de la particule permet donc d'en déduire sa masse.

Comme les analyseurs et les sources, il existe différents types de détecteurs. Ils sont tous basés sur des principes physiques différents, mais leur rôle reste le même, compter les ions. C'est une partie placée sous vide (10 - 10 Torr).


Voir aussi : Séquençage par spectrométrie de masse

La spectrométrie de masse en tandem consiste à sélectionner un ion par une première spectrométrie de masse, à le fragmenter, puis à effectuer une deuxième spectrométrie de masse sur les fragments ainsi générés. 
Elle peut être réalisée à l'aide de nombreux appareils combinant des secteurs magnétiques, électriques, quadripolaires ou des temps de vol, mais également au sein d'un même analyseur dans le cas d'une trappe d'ions.

Un triple quadripôle résulte de l'association de deux analyseurs quadripolaires en série, séparés par une cellule de collision souvent constituée d'un quadripôle plus court. Cette combinaison de quadripôles permet de travailler en MS simple ou en tandem. Pour réaliser une acquisition en MS, il suffit de n'appliquer qu'une tension alternative à l'un des analyseurs pour le rendre "transparent" comme la cellule de collision, celle-ci ne contenant alors pas de gaz.

Lors d'une acquisition en MS/MS, la cellule de collision est remplie d'un gaz inerte (argon par exemple) sous une pression relativement élevée (formula_26 torr). L'énergie cinétique de l'ion sélectionné est convertie lors de ses collisions successives en énergie interne. La dissociation de l'ion se réalisera lorsque son énergie interne sera devenue supérieure à l'énergie d'activation nécessaire à la fragmentation. Cette technique de dissociation activée par collision (CAD) peut être amplifiée en augmentant l'énergie cinétique des ions sélectionnées par application d'une différence de potentiel entre la source et la cellule de collision.
L'analyse MS/MS peut être menée selon quatre modes différents selon l'information recherchée : le mode descendant est le plus utilisé pour obtenir des informations structurales, les deux modes (ascendant et perte de neutre) sont d'un usage plus restreint et permettent de mettre en évidence des ions ayant des particularités communes. Le quatrième mode (Multiple Reaction Monitoring ou MRM), dérivé du mode descendant, est voué à la quantification.


Au sein d'un piège à ions quadripolaire (parfois appelé « trappe d'ions » en raison d'une mauvaise traduction de l'anglais "ion trap"), l'analyse en tandem se réalise dans un premier temps par sélection d'ions dont la valeur "m/z" est choisie. Ces ions piégés vont ensuite se fragmenter par collisions (acquisition d'énergie interne, excitation vibrationnelle) à l'aide d'une tension RF (radiofréquence) correspondant à leur fréquence de résonance, et les ions produits formés sont à leur tour piégés. Une éjection sélective en masse des ions produits (fragments) peut alors être réalisée en vue de leur analyse. Le gaz de collision est généralement de l'hélium présent en permanence dans le piège et a pour rôle également de focaliser les ions aux centre de l'analyseur.
L'obtention d'ions de générations supérieures est possible par simple renouvellement du processus (sélection d'un ion produit, fragmentation, sélection d'un ion produit de , fragmentation, etc.). Cette séquence est appelée formula_27, n étant le nombre de générations d'ions. Ainsi la formula_28 est la MS-MS et ainsi de suite...

Associer plusieurs types d'analyseur dans un spectromètre de masse en tandem permet de combiner les points forts des deux types d'analyseurs. 
"Article Détaillé: Spectrométrie de masse en tandem Quadripôle-Temps de vol"

Ces appareils appelés Q-TOF sont constitués d'un double quadripôle ( + cellule de collision) et d'un analyseur à temps de vol comme second analyseur. Le quadripôle procure ainsi une grande efficacité au processus MS/MS, tandis que le TOF apporte son excellente sensibilité, sa grande rapidité d'analyse et ses résolutions et précision en masse bien meilleure sur les ions produits, par rapport à une configuration triple quadripôle. Cependant ces instruments sont limités par la faible gamme dynamique du TOF.

Cette combinaison permet d'éviter les problèmes de charge d'espace associés aux pièges à ions. Le piège apporte une meilleure sensibilité et une vitesse d'analyse plus rapide. En outre, par rapport à un piège simple, cette combinaison autorise tous les modes d'acquisition MS/MS du triple quadripôle (perte de neutre et mode ascendant).

L'association d'un piège à ions et d'un TOF permet d'accéder à une analyse structurale très poussée par MS grâce au piège, mais présente aussi une grande précision en masse sur les ions précurseurs et produits pour la détermination des formules brutes, complétant ainsi l'identification. Cet appareil hybride est ainsi principalement dédié à l'identification et à l'analyse structurale.

Le but de ce genre de couplage est d'obtenir une précision en masse et une résolution, qui soient encore meilleures qu'avec un TOF comme deuxième analyseur, et permettent l'établissement de formules brutes sans ambiguïté et donc une identification facilitée. Ces appareils représentent cependant un investissement bien supérieur, comparés à un piège à ions/temps de vol.



</doc>
<doc id="14437" url="https://fr.wikipedia.org/wiki?curid=14437" title="Conducteur (physique)">
Conducteur (physique)

En physique, un conducteur est un matériau permettant des échanges d'énergie entre deux systèmes, par opposition à un isolant. On distingue les conducteurs électriques, les conducteurs thermiques et les conducteurs optiques.

En électricité, un conducteur est un matériau qui contient des porteurs de charge électrique pouvant se déplacer facilement.

Lorsque ce conducteur n'est soumis à aucun champ électrique ou, plus généralement, dans la situation décrite par la théorie de l'électrostatique, les porteurs de charge sont animés d'un mouvement aléatoire, ce qui fait qu'on n'observe aucun mouvement global d'électron ; il n'y a donc aucun courant électrique, on dit que le conducteur est en équilibre électrostatique.

Lorsqu'on lui applique un champ électrique, le mouvement des porteurs de charges devient globalement ordonné, ce qui fait qu'on observe un courant électrique.

Par extension, un conducteur est un "composant" électrique ou électronique de faible résistance, servant à véhiculer le courant d'un point à un autre.

On parle aussi de conducteur pour désigner les objets suivants : fil électrique, câble, piste, barre, strap, cordon.

Parmi les matériaux conducteurs, on peut citer les métaux, les électrolytes (ou solutions ioniques) et les plasmas. Certains solides non métalliques, tels que le graphite, sont également conducteurs. Cependant :

Un conducteur thermique est un matériau ayant une conductivité thermique élevée. Il peut etre utilisé pour :

Les meilleurs conducteurs thermiques sont les métaux et certains fluides.

Un bon conducteur électrique est souvent également un bon conducteur thermique (cas des métaux), et un bon isolant électrique est également souvent un bon isolant thermique.

Ceci vient du fait que les deux phénomènes font intervenir les phonons, les « paquets d'onde » de vibration du matériau. Pour simplifier, disons que les atomes du matériau vibrent entre eux, et que ces vibrations sont concentrées en paquets, comme des grumeaux qui se déplacent.

Le phénomène de résistance électrique est dû au freinage des électrons par les phonons. Le phénomène de conduction thermique consiste en la création de phonons et en leur déplacement, puisque la température d'un solide représente son énergie de vibration.

Il est donc logique que les deux soient liés.

Cependant on observe que le diamant, qui est un isolant électrique, est aussi un bon conducteur thermique. Ceci s'explique par le fait que la conductivité thermique est dictée par une série d'interactions entre d'une part les interactions électrons-phonons dans le cas des conducteurs électriques mais également les interactions phonons-phonons. Le diamant conduit bien la chaleur parce que ses éléments constitutifs (le carbone) sont des atomes très légers et, qui de par leurs fortes interactions, transmettent bien les vibrations à travers tout le réseau.

Une fibre optique est un fil en verre ou en plastique très fin qui a la propriété d'être un bon conducteur de la lumière et qui sert dans la transmission de données à longue distance. 


</doc>
<doc id="14439" url="https://fr.wikipedia.org/wiki?curid=14439" title="Chaligny">
Chaligny

Chaligny est une commune de l'est de la France, dans le département de Meurthe-et-Moselle, ses habitants sont les Chalinéens.

D'une superficie de 1330 ha, dont 100 ha dans la forêt de Haye, Chaligny est située sur un promontoire exposé plein sud, sur la rive droite de la Moselle, à une altitude de 290 mètres. Il se trouve à 14 km de Nancy et à 19 km de Toul.

L'existence de Chaligny est attestée vers 964 où il est connu sous le nom de "Chelineium". Son nom varie au cours des siècles pour arriver à sa forme définitive de Chaligny. Un document de 1284 signale que le village est déjà partagé en deux parties : le Mont et le Val.

Au , Chaligny est une seigneurie dépendant de l'évêque de Metz et donnée en fief aux comtes de Vaudémont. En 1345, la suzeraineté de l'évêque de Metz est transférée à l'identique au duc de Lorraine. Le 21 novembre 1562, la seigneurie de Chaligny qui appartient alors à Nicolas de Vaudémont, duc de Mercœur, est érigée en comté par le duc de Lorraine. La descendance des comtes de Chaligny se poursuit par les femmes qui quittent la Lorraine. Le comté est alors vendu à François de Vaudémont qui deviendra duc de Lorraine en 1624. À partir de ce moment, le sort de Chaligny est celui du duché de Lorraine. 

Le château-forteresse de Chaligny est détruit en 1467 par René II de Lorraine, en conflit avec Thiébaut III, seigneur de Chaligny et comte de Vaudémont. Il ne sera jamais reconstruit, mais les habitants ont utilisé les pierres et certains murs du château pour construire de nouvelles habitations. Le souterrain du château a été comblé, et personne ne connaît plus son emplacement.

La construction de l'église actuelle a été réalisée entre 1513 et 1530, sur l'emplacement de l'ancienne église détruite en même temps que le château. De l'édifice antérieur subsistent la tour du clocher et le grand portail surbaissé (le bénitier de ce portail est aujourd'hui inaccessible). L'église possède un superbe vitrail de 1520, ainsi qu'une statue de Sainte Barbe, patronne des mineurs, datant du et une superbe pietà en pierre de la même époque. Les autres statues en pierre ou en bois peint et doré datent du . Les bans de la nef sont les plus anciens et datent du avec les noms gravés au nom des premiers "locataires". Les sept premières rangées sont réservées aux hommes, et les autres aux femmes à partir de la de droite qui porte l'inde Chalignyscription "ban des femmes".

Fondée en 1913 par Jules et Henri Lévy, la filature de Chaligny emploie jusqu'à 500 ouvrières avant de connaître des difficultés dans les années 1950. Rachetée par le groupe Tricoterie Industrielle Moderne (T.I.M.) puis par le groupe Timwear, l’un des groupes français les plus importants de l’industrie textile, la "Tricoteries de Chaligny" est marquée par la bataille pour l'emploi (grève avec occupation d'usine, marche sur Nancy) menée par les tricoteuses lorsque son comité d'entreprise est averti le 11 juin 1971 de la fermeture de la filature qui emploie alors 438 personnes dont 411 femmes. L'activité productive est reprise par l'entreprise "Fra-For" qui est cependant contrainte de fermer la tricoterie en 1986. La commune de Chaligny rachète alors l’ensemble industriel et reconvertit les terrains en zone d'activité.

La démographie de Chaligny a varié en fonction de son économie, mais aussi des guerres qui ont ravagé son territoire pendant des siècles. Agglomération importante pour le début du (environ 700 habitants), la guerre la plus meurtrière de tous les temps, celle de Trente Ans, fait chuter sa population à 45 habitants. Il faut plus d'un siècle pour que Chaligny retrouve le même niveau de démographie. Ensuite, sa population croît lentement et décroît un peu pendant les guerres de 1870, 1914 (90 morts qui étaient nés à Chaligny) et 1945. En 2005, la population avoisine les 3000 habitants et devrait croître avec le récent quartier du Fond du Val (créé en 2004) et les projets de création de nouveaux lotissements. Chaligny n'a aussi presque que des résidences principales.

L'économie de Chaligny est liée à ce qui sera, pendant de nombreux siècles, sa principale activité : la culture de la vigne, apportée au par les Romains. À la fin du , plusieurs années consécutives de mauvaises récoltes, puis l'arrivée du phylloxera ont peu à peu convaincu les Chalinéens de se reconvertir dans l'industrie qui était alors en plein essor dans la région (usine de Neuves-Maisons et filatures) et assurait un revenu fixe et indépendant des conditions climatiques. L'industrialisation fait exploser la population de Chaligny et un troisième quartier est créé : les Cités. 

Le minerai de fer présent sur le territoire de Chaligny est exploité par à coups au cours des siècles. Réputé au , son exploitation est reprise en 1364 par Marie de Luxembourg qui se trouve dans une situation financière désastreuse à la mort de son époux Henri V, comte de Vaudémont. Elle exploite alors le minerai de fer et crée des forges qui disparaîtront au début du . Les mines seront encore rouvertes à la fin du , en effet René II de Lorraine, vainqueur de Charles le Téméraire, relance plusieurs mines afin de reconstruire la Lorraine. Les mines sont de nouveau exploitées aux , puis définitivement fermées en 1965.


Dans cet inventaires, 9 spécificités y sont enregistrées :

"L' instrument serait l'ancien positif de dos de l'église de Saint-Nicolas-de-Port ou proviendrait de l'abbaye cistercienne de Clairlieu, détruite à la Révolution. Il a sans doute été réalisé vers 1810 à partir d'éléments de tuyauterie plus anciens. (source base Palissy)"
"armoiries de Henri de Thierstein et de Marguerite de Neufchâtel"




</doc>
<doc id="14441" url="https://fr.wikipedia.org/wiki?curid=14441" title="Comte de Lautréamont">
Comte de Lautréamont

Isidore Lucien Ducasse, né à Montevideo (Uruguay), le , et mort dans le de Paris, le , est un poète français. Il est également connu sous le pseudonyme de comte de Lautréamont, qu’il emprunta très probablement au "Latréaumont" (1838) d’Eugène Sue et qu'il n'utilisa pourtant qu'une seule fois.

Il est l'auteur des "Chants de Maldoror", de deux fascicules, "Poésies I" et "Poésies II", ainsi que d'une correspondance habituellement publiée sous le titre de "Lettres", en appendice des œuvres précédentes. On n'a longtemps su que très peu de choses sur son auteur, mort à vingt-quatre ans, sans avoir connu le succès de son vivant. Sa vie a donc donné lieu à de nombreuses conjectures, en particulier chez les surréalistes, qui essayèrent notamment de trouver des éléments biographiques dans ses poèmes. 

Son père, François Ducasse (1809-1887), est commis-chancelier au consulat général de France à Montevideo, mais aussi un homme d'une grande culture. Isidore Ducasse naît dans un lieu indéterminé de Montevideo, . Sa mère, Jacquette Célestine Davezac, décède le 9 décembre 1847 dans des circonstances mystérieuses (elle se serait suicidée). Isidore Ducasse passe son enfance en Uruguay, pays agité par la guerre entre Manuel Oribe, soutenu par Juan Manuel de Rosas, et Fructuoso Rivera, guerre qui dure jusqu'en 1851.

En octobre 1859, il entre comme interne au lycée impérial de Tarbes, en sixième alors qu'il a treize ans et demi, ce qui n'est pas exceptionnel vu que de nombreux élèves venus des colonies ont des retards scolaires. Isidore Ducasse semble pourtant être un bon élève, qui apprend vite, car il obtient le deuxième accessit de version latine, de grammaire et de calcul, ainsi que le premier prix de dessin d'imitation. On perd sa trace entre août 1862 et octobre 1863, période durant laquelle il suit les cours de l’établissement qui deviendra le lycée Louis-Barthou à Pau, « où il est un élève des plus ternes ». À cette époque, son tuteur est un avoué tarbais, Jean Dazet. Ducasse est en amitié avec Georges Dazet (1852-1920), le fils de Jean, et qui fut le premier dédicataire de "Poésies". En août 1865, il obtient son baccalauréat ès lettres avec la mention « passable ».

Après un voyage en Uruguay en 1867, il arrive à Paris et s’installe à l’hôtel L’Union des Nations, 23 rue Notre-Dame-des-Victoires. Il entame des études supérieures dont la nature reste inconnue (concours d’entrée à l’École polytechnique, a-t-on souvent écrit). Il publie à compte d’auteur et anonymement le premier des "Chants de Maldoror" prévu en août 1868 chez l'imprimeur Gustave Balitout, Questroy et Cie, édition finalement repoussée puis publiée en dépôt en novembre 1868 en deux endroits différents : la librairie du Petit-Journal, et « au passage Européen chez Weill et Bloch ». Ce premier chant sera repris dans un recueil de poésies publié par Évariste Carrance et intitulé "Les Parfums de l'âme" à Bordeaux en 1869.

Les six chants complets seront imprimés en Belgique fin août 1869, signés « Comte de Lautréamont » par Albert Lacroix mais sans référence d'éditeur. L'ouvrage ne fut pas diffusé mais Ducasse et Lacroix restèrent en contact.

En 1870, il quitte le 32 rue Faubourg-Montmartre et habite 15 rue Vivienne. Il reprend son nom d'état civil pour publier deux fascicules intitulés "Poésies" publiés à la Librairie Gabrie située au 25 passage Verdeau, toujours dans son quartier donc, et dont une publicité paraîtra dans la "Revue populaire de Paris".

Le 24 novembre 1870, alors que le Second Empire s’effondre, il meurt à son nouveau domicile situé au 7 rue Faubourg-Montmartre. Sur son acte de décès, est écrit : « Sans autres renseignements ». Selon ses biographes, il serait mort phtisique, et vraisemblablement inhumé au cimetière du Nord (cimetière de Montmartre). Mais la destinée de sa dépouille, comme le personnage lui-même, demeure mystérieuse, et en raison de la désaffectation des concessions temporaires, comme de travaux dans le quartier, elle disparut. La dépouille aurait été ensuite déplacée de Montmartre le 20 janvier 1871 dans une concession d'un autre ossuaire, mais pas au cimetière de Pantin, comme longtemps supposé par ses biographes.

À partir de la fin des années 1970, de nouveaux documents biographiques sont retrouvés dont deux portraits photographiques présumés.

En 1874, le stock des exemplaires de l’édition originale des "Chants de Maldoror" est racheté par Jean-Baptiste Rozez, libraire-éditeur tarbais installé en Belgique, et enfin mis en vente, mais avec une nouvelle couverture. Il faut attendre 1885 pour que Max Waller, directeur de la "Jeune Belgique", en publie un extrait et en fasse découvrir les textes. Elle tombe entre les mains de Joris-Karl Huysmans, Alfred Jarry et Remy de Gourmont. Alfred Jarry rendra hommage à « cet univers pataphysique » et les surréalistes reconnaîtront le poète comme l’un de leurs plus éminents précurseurs. Huysmans s'interrogera .

Léon Bloy lui consacra en 1890 une critique admirative sous le titre , éditée dans "".

André Breton évoque Ducasse plusieurs fois dans ses Manifestes du surréalisme :  
Il dit aussi dans un entretien : .

De même, Wilfredo Lam a dessiné un projet de carte pour le Jeu de Marseille des surréalistes qui porte le nom "Lautréamont. Génie du rêve, étoile".

André Gide écrit en 1925 : 

Après 1945, Maurice Blanchot se sert de ce qu'il appelle « L'expérience de Lautréamont », et de celle du Marquis de Sade, pour tenter d'élucider « les rapports qu'entretiennent le mouvement d'écrire et le travail d'une plus grande raison » dans son essai "Lautréamont et Sade".

Certains critiques ont cherché des éléments biographiques dans l’œuvre elle-même. Ainsi, Gaston Bachelard voit dans la phrase (Les Chants de Maldoror, Chant Deuxième) la possibilité d'une surdité lors de l'enfance du poète. De même, Bachelard imagine l'esprit révolutionnaire des "Chants" commandé par et voit dans de nombreux passages la description en filigrane du rapport du maître à l'élève.

Genonceaux, troisième éditeur des "Chants de Maldoror", entreprend des recherches pour savoir qui en était l'auteur. Pour cela, il se base presque uniquement sur le témoignage de Lacroix, premier éditeur des "Chants". Il en tire la conclusion suivante : 

Aucune de ces informations, écrites vingt ans après la mort de Ducasse, n'a pu être vérifiée. Néanmoins, cette description a souvent été réutilisée, avec des variations :

"Les Chants de Maldoror", aux interprétations multiples, semble incarner une révolte adolescente où le monde de l’imaginaire paraît plus fort que la vie dite « réelle ». Ils consistent en une épopée en prose, très décalée des publications de l'époque, dont le personnage principal est Maldoror (l'origine de ce nom reste mystérieuse, mais provient sans doute d'une contraction des mots mal et "horror" (mot espagnol pour « horreur »), créature terrifiante, squelettique, armée d'un stylet et ennemie du Créateur.

Le lecteur se sent pris d'un sentiment de vertige à la lecture de Lautréamont. Il partage sa vision d'un monde en perpétuel mouvement, faisant l'expérience de la férocité, de la sauvagerie et de la perte de repères. Dans son expression, l'artiste (dont la vision si personnelle semble bouleverser des mouvements tels que le romantisme et le naturalisme littéraire) communique au lecteur un certain mépris des situations et des personnages dont il rapporte l'expérience. Sa vision de l'humanité se comprend ici très bien : « Race stupide et idiote ! Tu te repentiras de te conduire ainsi. C’est moi qui te le dis. Tu t’en repentiras, va ! tu t’en repentiras. Ma poésie ne consistera qu’à attaquer, par tous les moyens, l’homme, cette bête fauve, et le Créateur, qui n’aurait pas dû engendrer une pareille vermine. Les volumes s’entasseront sur les volumes, jusqu’à la fin de ma vie, et, cependant, l’on n’y verra que cette seule idée, toujours présente à ma conscience ! »

Il existe dès 1954 huit préfaces françaises aux "Chants de Maldoror", parfois contradictoires, et de nombreuses autres ont été publiées au cours de la seconde moitié du .

Ses "Poésies I" et "Poésie II", écrites en prose, consistent en des aphorismess exaltés ou en des réflexions sur la littérature. Il y montre notamment son mépris pour Alexandre Dumas fils : (in "Poésie I"), ou son admiration pour Byron. Il y cultive comme dans "Les Chants de Maldoror" une révolte envers l'ordre établi, réfutant tour à tour Balzac, Alexandre Dumas fils, Victor Hugo, Jean-Jacques Rousseau, George Sand, Eschyle.

La révolte et le refus de l'ordre établi, ainsi que la courte vie des deux auteurs, mettent en parallèle l'œuvre de Rimbaud et de Lautréamont, qui vécurent à la même période mais ne se croisèrent jamais.

Bien que présent dans la contre culture "underground", Lautréamont reste assez peu cité par la culture populaire, comparé à d'autres poètes français comme Rimbaud, Verlaine ou Baudelaire.









</doc>
<doc id="14445" url="https://fr.wikipedia.org/wiki?curid=14445" title="Chesmou">
Chesmou

Dans la mythologie égyptienne, Chesmou est un dieu pressoir, patron du vin, des huiles, onguents, parfums. On le retrouve surtout sur les parois des salles servant à la préparation de ces mélanges dans les temples. Il apporte ces biens aux dieux et aux humains pour les rites funéraires.

Représenté comme un lion ou un homme les bras chargés de jarres, on disait de lui qu'il remplissait ces mêmes jarres de morceaux de viande humaine. Il a le don de pouvoir se multiplier.


</doc>
<doc id="14449" url="https://fr.wikipedia.org/wiki?curid=14449" title="Loi de Coulomb">
Loi de Coulomb

En physique, il existe deux lois de Coulomb, nommées en l'honneur du physicien français Charles de Coulomb : 

</doc>
<doc id="14450" url="https://fr.wikipedia.org/wiki?curid=14450" title="DRM">
DRM

DRM peut désigner :



</doc>
<doc id="14455" url="https://fr.wikipedia.org/wiki?curid=14455" title="Gradient">
Gradient

En mathématiques, le gradient est un vecteur représentant la variation d'une fonction par rapport à la variation de ses différents paramètres, généralisant la notion de dérivée d'une fonction dans le cas de plusieurs variables. En physique et en analyse vectorielle, le gradient est une grandeur vectorielle indiquant la façon dont une grandeur physique varie dans l'espace.

Il est courant, selon la façon de noter des vecteurs, d'écrire le gradient d'une fonction formula_1 ainsi :
Souvent, en typographie, on préfère mettre un caractère en gras pour afficher son caractère vectoriel : formula_5.

Le gradient est d'une importance capitale en physique, où il fut d'abord employé. Utilisé en théorie des variations, il est aussi fondamental dans le domaine de l'optimisation ou de la résolution d'équations aux dérivées partielles. Il peut être intéressant d'en voir certains exemples avant d'en donner une définition plus mathématique.

Supposons que l'on place une poutre rectiligne entre deux murs qui n'ont pas la même température, le mur de gauche étant le plus froid. On observe que la température de la poutre n'est pas constante et qu'elle varie de façon croissante de la gauche vers la droite. À ce phénomène thermodynamique, on associe un phénomène de flux de chaleur, lui-même lié à un gradient de température, c'est-à-dire à une variation le long de la poutre de la température, cf. Conduction Thermique, loi de Fourier.

Si on part de l'extrémité gauche de la poutre avec une abscisse = 0 et qu'on atteint l'autre extrémité de la poutre pour une abscisse (la longueur de la poutre), on définit la température en un "point" qu'on écrit . La température est dite fonction de .

Entre deux points très proches, distants d'une longueur , on mesure un écart de température . Au sens usuel, le gradient (de température) est justement le rapport entre ces deux grandeurs

Au sens analytique (mathématique), on parle de gradient si cette grandeur admet une limite quand tend vers 0, limite notée


En réalité, la température de la poutre varie en fonction d'un déplacement dans l'espace. On caractérise un point de l'espace, , en fonction de ses coordonnées formula_9. De même que précédemment, on décrit la température comme fonction : .

Pour chacune de ces directions, on peut écrire une variation, dite partielle. Si, tout en étant en 3D, on ne se déplace que selon un axe, par exemple selon les ordonnées , alors on peut réécrire la même formule que précédemment sur l'accroissement de température. Cependant, pour marquer la variation, on passe par l'écriture en dérivée partielle (dite "ronde") plutôt que par la dérivée unidimensionnelle (dite droite). On écrit par exemple la variation le long de ainsi l'approximation (dite du premier ordre) :
On se déplace dans la poutre d'un point à un point tels qu'ils définissent le vecteur :
De à , la température passe de la à . En première approximation, cette variation est une fonction linéaire de formula_12 et s'exprime comme somme des variations liées à chacune des composantes de formula_13

On crée alors un vecteur appelé gradient de température
Notez que c'est bien un vecteur. Dans ce cas, on peut réécrire la relation précédente sous la forme
où "formula_17" est le produit scalaire usuel de formula_18 et le symbole formula_19 signifie que le terme qui reste est négligeable par rapport à formula_20.


Comme pour la différentielle dont il est une variante, le gradient peut être introduit avec le vocabulaire des éléments différentiels. À titre d'exemple on examine le problème de la variation de l'aire d'un rectangle.

Considérons dans le plan ( ) un rectangle de côté et .
Sa surface est égale à et dépend des coordonnées et du point M.
En suivant une démarche intuitive, on convient de noter par une très petite variation de la variable . Lorsqu'on fait subir au point un déplacement très faible, la surface va changer et on peut écrire que :

On en déduit facilement que
Une simple application numérique où et seraient des mètres et et des centimètres illustre que est négligeable par rapport aux autres grandeurs.

On peut donner un statut mathématique précis aux notations et (qui sont des formes différentielles), et à la quantité qui est alors "du second ordre". Le calcul précédent est en fait un calcul de développement limité à l'ordre 1, faisant intervenir les dérivées premières de la fonction par rapport aux deux variables.

On écrit donc :

Toutes ces égalités sont différentes façons d'écrire un produit scalaire de deux vecteurs :
où

L'intérêt de l'introduction de ces vecteurs pour exprimer la variation d'une fonction de plusieurs paramètres est de visualiser le fait que la fonction va varier le plus dans la direction du vecteur gradient et qu'elle ne va pas varier pour tout changement des paramètres dans une direction perpendiculaire au gradient.

Ceci donnera en électrostatique les courbes de même potentiel : les « équipotentielles ».

Soit un espace vectoriel euclidien et soit un ouvert de . Soit formula_29 une fonction différentiable. Soit un élément de . On note alors formula_30 la différentielle en , qui est une forme linéaire sur . On note formula_31 l'image par cette différentielle d'un vecteur de .

Il existe un vecteur tel que pour tout vecteur de , formula_32, où l'on a noté formula_33 le produit scalaire dans .

Le vecteur est appelé gradient de en , et il est noté formula_34. Il vérifie donc :

Puisque le gradient est lui-même un vecteur de , il est naturel qu'on cherche à l'exprimer dans une base orthonormée formula_36 de cet espace vectoriel. On démontre qu'il s'exprime à l'aide des dérivées partielles sous la forme
Par exemple, en dimension 3, on obtient :

Lors d'un changement de base, au travers d'un C-difféomorphisme de , l'écriture du gradient suit les règles usuelles des changements de base.

Attention, il ne faut pas confondre changement de base pour l'expression d'une fonction écrite en notations cartésiennes (canoniques) et écriture du gradient adaptée à une notation autre. Par exemple pour une fonction exprimée en coordonnées polaires on calcule l'écriture « polaire » du gradient en partant d'une fonction explicitée en fonction de l'abscisse polaire () et de l'argument () .
les vecteurs de type formula_41 sont des vecteurs propres aux coordonnées polaires

Soient formula_42 un espace de Hilbert (de dimension finie ou non), un ouvert de et une application de dans ℝ, différentiable en un point de . La différentielle formula_30 étant, par définition, une forme linéaire continue sur , il résulte alors du théorème de représentation de Riesz qu'il existe un (unique) vecteur de , noté formula_44, tel que
formula_45
Le vecteur formula_44 est appelé le "gradient de en ".

On montre que si formula_47, alors formula_1 croît strictement dans la direction formula_44, c'est-à-dire que pour tout formula_50 suffisamment petit, formula_51.

On peut encore étendre cette définition à une fonction différentiable définie sur une variété riemannienne . Le gradient de en est alors un vecteur tangent à la variété en , défini par

Enfin, si est un champ scalaire indépendant du système de coordonnées, c'est un tenseur d'ordre 0, et sa dérivée partielle est égale à sa dérivée covariante : formula_53. En coordonnées contravariantes, on calcule le champ de vecteurs appelé gradient de :

Cette formule permet, une fois établi le tenseur métrique, de calculer facilement le gradient dans un système de coordonnées quelconque.

Si une application admet un gradient en un point, alors on peut écrire ce développement limité du premier ordre
formula_56

Numériquement, il est très intéressant de faire ensuite la demi différence des 2 développements pour obtenir la valeur du gradient et on note que celui-ci ne dépend pas en fait de la valeur de la fonction au point x :formula_57. Cette formule a l'avantage de tenir compte des gradients 2 et est donc beaucoup plus précise et numériquement robuste.
L'hypothèse est bien sûr, en pratique, de connaitre les valeurs "passé et futur" de la fonction autour d'un petit voisinage du point x.

Classiquement, on sait que le gradient permet de définir la « normale aux courbes de niveau », ce qui se traduit en 2D et en 3D par des propriétés géométriques intéressantes. La propriété de tangence étant liée à la convexité/concavité, il est aussi intéressant de voir le lien qui existe entre gradient et convexité, toujours en 2D ou 3D.

On considère formula_58 continûment différentiable.
Soit une courbe définie par l'équation , où est une constante. Alors, en un point donné de cette courbe, le gradient s'il existe et n'est pas nul, donne la direction de la normale à la courbe en ce point . La droite tangente à la courbe est alors orthogonale au gradient et passe par .

Application au traitement d'image: Une image est en fait une fonction à 2 variables noté p(x,y), chaque valeur entière de x et y constitue un pixel de l'image et la valeur prise p(x,y) est appelé "niveau de gris" du pixel pour une image en "noir et blanc". Il est indispensable en pratique d'estimer "la droite tangente à la courbe" même si la fonction p n'est pas analytique (p est inconnue) et n'est peut être pas différentiable au point (pixel) d’intérêt. On calcule numériquement les 2 gradients notés gx et gy suivant x et y par exemple avec ces formules simples gx=(p(x+1,y)-p(x-1,y))/2 et gy=(p(x,y+1)-p(x,y-1))/2. Ces formules ne font appel qu'à seulement 2 pixels chacun pour le calcul et on doit supposer alors qu'il n'y a pas de bruit dans l'image.
La fonction p n'étant pas analytique et de valeur numérique connue uniquement en des points discrets (les pixels voisins), on peut utiliser diverses formules pour estimer le mieux possible (c'est l'art de l'ingénieur de gérer le cas très difficile de l'image bruitée!) ces gradients de l'image. On cite par exemple le template de Prewitt qui permet , utilisant la proximité des autres pixels de l'image (3 par 3 soit 9 pixels et tout) d'évaluer les gradients gx et gy du pixel d’intérêt situé au centre par convention du template.
Repérant dans une image donnée les pixels ayant des forts gradients, ceux-ci peuvent servir d'amers, c'est-à-dire des points particuliers reconnaissables (notés dans une carte par exemple) permettant de se situer dans l'espace, autrement dit de recaler sa navigation. Les gradients gx et gy forment une direction (c'est en fait un vecteur) et on a aussi une information angulaire : Il est possible de recaler des angles de prise de vue, très utile pour le pilotage guidage des drones aériens par exemple.

Soit une application formula_59 continûment différentiable. Soit une surface définie par l'équation , où est une constante. Alors, en un point donné de cette surface, le gradient s'il existe et n'est pas nul, donne la direction de la normale à la surface en ce point : le plan tangent à la surface est alors orthogonal au gradient et passe par .

Soit une application formula_60 (formula_61 par exemple) continûment différentiable. Si l'application formula_62 est monotone (resp. strictement monotone), alors est convexe (resp. strictement convexe). C'est-à-dire, en utilisant la caractérisation par les cordes :

Cette propriété est intéressante parce qu'elle reste valable même quand n'est pas deux fois différentiable.

Si est deux fois différentiable, le hessien est positif si et seulement si le gradient est monotone.

La monotonie telle que définie ci-dessus permet de définir une fonction croissante ou décroissante au sens usuel. Dans le premier cas, on parle de fonction convexe, dans le second de fonction concave.

Si la fonction est deux fois dérivable, la croissance de la dérivée (donc du gradient) est assurée par la positivité de la dérivée seconde (équivalent du hessien).

En analyse vectorielle, le gradient peut être combiné à d'autres opérateurs. Soit une fonction décrivant un champ scalaire, que l'on suppose de classe C par rapport à chaque paramètre, alors :



</doc>
<doc id="14459" url="https://fr.wikipedia.org/wiki?curid=14459" title="Sécurité des systèmes d'information">
Sécurité des systèmes d'information

La sécurité des systèmes d’information (SSI) ou plus simplement sécurité informatique, est l’ensemble des moyens techniques, organisationnels, juridiques et humains nécessaires à la mise en place de moyens visant à empêcher l'utilisation non-autorisée, le mauvais usage, la modification ou le détournement du système d'information. Assurer la sécurité du système d'information est une activité du management du système d'information.

Aujourd’hui, la sécurité est un enjeu majeur pour les entreprises ainsi que pour l’ensemble des acteurs qui l’entourent. Elle n'est plus confinée uniquement au rôle de l’informaticien. Sa finalité sur le long terme est de maintenir la confiance des utilisateurs et des clients. La finalité sur le moyen terme est la cohérence de l’ensemble du système d’information. Sur le court terme, l’objectif est que chacun ait accès aux informations dont il a besoin. La norme traitant des SMSI est l’ISO/CEI 27001 qui insiste sur , c'est-à-dire en français Disponibilité – Intégrité - Confidentialité.

Les responsables de systèmes d'information se préoccupent depuis longtemps de sécuriser les données. Le cas le plus répandu, et sans aucun doute précurseur en matière de sécurité de l'information, reste la sécurisation de l'information stratégique et militaire. Le Department of Defense (DoD) des États-Unis est à l'origine du TCSEC, ouvrage de référence en la matière. De même, le principe de sécurité multi-niveau trouve ses origines dans les recherches de résolution des problèmes de sécurité de l'information militaire. La défense en profondeur, tout droit sorti d'une pratique militaire ancienne, et toujours d'actualité aujourd'hui. Cette pratique consiste à sécuriser chaque sous-ensemble d'un système.

Les conséquences d'une mauvaise sécurisation peuvent concerner les organisations, mais aussi la vie privée d'une ou plusieurs personnes, notamment par la diffusion d'informations confidentielles comme leurs coordonnées bancaires, leur situation patrimoniale, leurs codes confidentiels, etc. De manière générale, la préservation des données relatives aux personnes fait l'objet d'obligations légales régies par la Loi Informatique et Libertés.

Aujourd'hui, il est généralement admis que la sécurité ne peut être garantie à 100 % et requiert donc le plus souvent la mobilisation d'une panoplie de mesures pour réduire les chances de pénétration des systèmes d'information.

La sécurité des systèmes d'information vise les objectifs suivants :
D'autres aspects peuvent aussi être considérés comme des objectifs de la sécurité des systèmes d'information, tels que :

Une fois les objectifs de la sécurisation déterminés, les risques pesant sur chacun de ces éléments peuvent être estimés en fonction des menaces. Le niveau global de sécurité des systèmes d'information est défini par le niveau de sécurité du maillon le plus faible. Les précautions et contre-mesures doivent être envisagées en fonction des vulnérabilités propres au contexte auquel le système d'information est censé apporter service et appui.

Il faut pour cela estimer :

Pour sécuriser les systèmes d'information, la démarche consiste à :

Il est important de prendre en compte les actifs ayant de la valeur en définissant un périmètre du système de management du système d’information. Il peut être orienté sur l’ensemble de l’entreprise, sur un site précis, sur un service en fonction de la stratégie de l’entreprise. Le capital intellectuel des entreprises intègre des informations sensibles, ce patrimoine informationnel doit être protégé. L’entreprise doit donc mettre en place une politique de sécurité des systèmes d’information, de sécurité des données, et des mécanismes d’identification. De plus il faut définir une politique du SMSI, qui est l’engagement de l’entreprise sur un certain nombre de points en matière de sécurité. Ces deux points forment la pierre angulaire du SMSI, dans le but d’établir la norme ISO/CEI 27001 et ainsi d’apporter la confiance aux parties prenantes.

Tenter de sécuriser un système d'information revient à essayer de se protéger contre les menaces intentionnelles et d'une manière plus générale contre tous les risques pouvant avoir une influence sur la sécurité de celui-ci, ou des informations qu'il traite.
Différentes méthodes d'analyse des risques sur le système d'information existent. Voici les méthodes d’appréciation des risques les plus courantes :

En France, la première méthode développée a été Marion. Aujourd’hui elle a été remplacée, même si certaines entreprises ont conservé ce modèle initial, par la méthode Méhari (Méthode harmonisée d'analyse des risques) développée par le CLUSIF, et par la méthode EBIOS (Expression des besoins et identification des objectifs de sécurité) développée par l'Agence nationale de la sécurité des systèmes d'information (ANSSI).

En Angleterre, Cramm est une méthode d'analyse des risques développée par l'organisation du gouvernement britannique ACTC (Agence centrale de communication et des télécommunications). C’est la méthode d'analyse des risques préférée par le gouvernement britannique, mais elle est également utilisée par beaucoup d’autre pays.

Les États-Unis utilisent OCTAVE ("Operationally Critical Threat, Asset, and Vulnerability Evaluation"), développée par l'Université de Carnegie Mellon.

À l'international, on utilise ISO/CEI 27005, qui est une norme internationale répondant point par point aux exigences de la certification ISO/CEI 27001. C’est la norme la plus récente, de plus elle est facilement applicable car pragmatique.

Même si le but de ces méthodes est identique, les termes et les expressions utilisés peuvent varier. Ceux utilisés ci-dessous sont globalement inspirés de la méthode Feros.

Paradoxalement, dans les entreprises, la définition d'indicateurs « sécurité du SI » mesurables, pertinents et permettant de définir ensuite des objectifs dans le temps raisonnables à atteindre, s'avère délicate. Pour mesurer la performance on peut désigner comme indicateurs les états d'installation d'outils ou de procédures, mais les indicateurs de résultats sont plus complexes à définir et à apprécier, par exemple ceux concernant les .

Cela consiste à faire une liste de tous les éléments importants en matière d’information au sein du périmètre SMSI. Il existe différent types d'actifs :
Pour l’identification des actifs, trois problèmes se posent :
Il est aujourd'hui indispensable de disposer de plans de sécurisation de l'activité pour en assurer la continuité et la reprise si un sinistre survient. Ces plans tentent de minimiser les pertes de données et d’accroître la réactivité en cas de sinistre majeur. Un plan de continuité d'activité efficace est quasi-transparent pour les utilisateurs, et garantie l'intégrité des données sans aucune perte d'information

C’est la personne responsable d’un bien qui en répond. Il s’agit en général de celle qui connaît le mieux la valeur et les conséquences de disponibilité, d’intégrité et de confidentialité de l’actif. Dans une entreprise c’est généralement le responsable de la sécurité des systèmes d’information qui connait le mieux les actifs de l’information.

Chaque actif recensé présente des vulnérabilités, c’est une propriété intrinsèque du bien qui l’expose à des menaces.

Les vulnérabilités précédemment identifiées exposent les biens a des menaces. La norme ISO/CEI 27001 impose l’identification des menaces pour tous les biens recensés.
Les principales menaces auxquelles un système d’information peut être confronté sont :

La norme ISO 27001 oblige l’évaluation de conséquences ; tel que : la perte de confidentialité, de disponibilité ou d’intégrité. Cela revient à donner une note en trois dimensions (confidentialité ; disponibilité et intégrité), selon des critères définis, pour chaque actif.

Quatre types de dommages peuvent affecter le système d'information d'une organisation:

Il s’agit de remettre le bien d’information dans son contexte environnemental et donc de prendre en compte les mesures qui sont déjà mises en place. ( si un fichier client est déjà chiffré, alors la vraisemblance de voir sa confidentialité compromise est limitée.) . Il est possible d’évaluer la notion de vraisemblance par une note sur une échelle de 1 à 5.

L’attribution d’une note finale reflétera le niveau de risque réel tout en tenant compte des éléments ci-dessus. La norme ISO 27001 n’impose aucune formule c’est donc à l’implémenteur de la choisir. Il peut s’agir d’une note allant de 0 à 100 ou bien d’un code couleur.

L’entreprise peut traiter les risques identifiés de 4 façons : 
Enfin, il ne faut pas oublier de prendre en compte les Risques résiduels qui persistent après la mise en place de l’ensemble des mesures de sécurité. Il faut prendre des mesures complémentaires de protection pour rendre ces risques acceptables.

L'implémentation de la norme ISO2/CEI 27001 se déroule généralement en cinq phases complémentaires:

L’étape de planification identifie les mesures à prendre dans l’organisation, mais ne permet pas de les mettre en place concrètement. Il faut les organiser, sélectionner les moyens nécessaires et définir le responsabilités en établissant un plan de traitement des risques. Cette étape relève de la gestion de projet.

De nombreux moyens techniques peuvent être mis en œuvre pour assurer une sécurité du système d'information. Il convient de choisir les moyens nécessaires, suffisants, et justes. Voici une liste non exhaustive de moyens techniques pouvant répondre à certains besoins en matière de sécurité du système d'information :

Une des nouveautés de la norme ISO/CEI 27001 est d’exiger une vérification régulière de la sécurité. Le responsable doit choisir des indicateurs qui permettent de mesurer sa fiabilité. Ils peuvent être de deux sortes :

L’information du personnel est primordiale dans la réussite d’un projet de sécurisation du SI, pour qu’il en comprenne l’utilité et sache l’appliquer. Une bonne pratique est donc de sensibiliser l’ensemble du personnel aux enjeux de la sécurité informatique pour leur organisation, de manière généraliste. Cette explication doit rappeler les engagements de l’organisation, et donner des exemples très pratiques pour éviter les incidents les plus habituels. Les employés directement concernés par la sécurité informatique doivent être formés pour qu’ils sachent utiliser correctement les outils.

La norme ISO/CEI 27001 n’impose pas seulement de mettre en place un système de sécurité, mais aussi de prouver son efficacité. Les entreprises doivent donc gérer correctement leurs ressources et développer la traçabilité.

Cette phase repose sur la théorie de ". Le principe est de prendre en compte le délai nécessaire pour qu’une attaque contre la sécurité réussisse. Pendant ce laps de temps, l’entreprise doit être capable de détecter la menace et de la contrer, avec une marge de sécurité supplémentaire.

Il doit y avoir des moyens de contrôle pour surveiller l’efficacité du SMSI ainsi que sa conformité.

Il existe des outils pour vérifier cela comme :

Les audits internes : Audit planifié longtemps en avance et faisant appel à des auditeurs.

Le contrôle interne : Contrôle en permanence au sein de l’organisation, pour vérifier que chacun appliquent les procédures aux quotidiens.

Les réexamens : Prendre du recul pour mettre en adéquation le SMSI et son environnement.

On peut s’aider de :

Après la mise en lumière de dysfonctionnement grâce à la phase Check, il est important de les analyser et de mettre en place des :



</doc>
<doc id="14461" url="https://fr.wikipedia.org/wiki?curid=14461" title="Démiurge">
Démiurge

Le démiurge, ou le créateur, est la déité responsable de la création de l'univers physique dans diverses cosmogonies. 

Le mot vient du grec "", "démiourgos", formé de « démos », signifiant « gens du commun » (soit « peuple ») et de « ergos », « travail ». Littéralement, le mot signifiait artisan ou fabricant. Au avant notre ère, Platon suppose dans son " Timée", que la cause première de l'univers et son créateur sont un bon et sage « démiurge ». Dans le douzième livre, dit « Livre lambda » Λ de la "Métaphysique", Aristote développe l'idée d'une cause motrice immobile, organisateur qui créa le monde à partir de la matière préexistante.

Les démiurges égyptiens :



</doc>
<doc id="14463" url="https://fr.wikipedia.org/wiki?curid=14463" title="Ennéade">
Ennéade

L’Ennéade ("Pésédjet", en égyptien) est le groupe des neuf divinités de la mythologie égyptienne rassemblant toutes les forces présentes dans l’univers : le démiurge Atoum, l’humidité Tefnout, l’air Shou, la terre Geb, le ciel Nout, Osiris, Isis, Seth et Nephthys.

Un des récits les plus détaillés et les plus anciens de la création porte sur le groupe de dieux appelés les « Neuf Dieux d'Héliopolis » ou « Ennéade » (du grec "ennea", neuf). Le premier était Rê-Atoum qui vint au monde sur la colline primordiale et décida la multiplicité de la création dans son cœur. Il fut à l'origine de la première distinction entre mâle et femelle : ayant pris sa semence dans sa bouche, il cracha ou éternua, créant Shou, le dieu de l'air, et Tefnout, la déesse de l'humidité. Ils explorèrent le sombre Noun et furent perdus pour Rê-Atoum qui envoya à leur recherche son œil divin, une puissance brûlante considérée comme la fille du dieu Soleil. La déesse revint avec Shou et Tefnout et les premiers êtres humains furent formés par les larmes que Rê-Atoum versa en retrouvant ses enfants.

De l'union de Shou et Tefnout naquirent Geb, le dieu de la Terre, et Nout, la déesse du Ciel. Ces derniers étaient si étroitement enlacés que rien ne pouvait circuler entre eux. Nout fut fécondée par Geb mais ses enfants ne parvenaient pas à naître. Leur père Shou, le dieu de l'Air, finit par séparer Geb et Nout. Aidé par huit êtres appelés les dieux Heh, Shou souleva la déesse du Ciel au-dessus de la terre, créant ainsi un espace où les créatures pouvaient vivre et respirer. On pensait qu'il existait un deuxième ciel sous la terre.

Les eaux primordiales continuaient à entourer le cosmos. La déesse du Ciel était parfois représentée comme une femme nue arquée au-dessus de la terre, et parfois comme une vache étoilée. Elle avalait le soleil chaque soir et était parfois accusée de vouloir avaler tous ses enfants : Nout était alors représentée comme une truie, créature connue pour dévorer ses propres petits.

Nout enfanta deux paires de jumeaux, Osiris et Isis, et Seth et Nephtys. Osiris et Isis seraient tombés amoureux dans le ventre de leur mère mais Nephtys méprisait son frère Seth. En tant qu'aîné des enfants de Geb et Nout, Osiris était destiné à régner sur l'Égypte.




</doc>
<doc id="14465" url="https://fr.wikipedia.org/wiki?curid=14465" title="Râttaouy">
Râttaouy

Râttaouy est une déesse de la mythologie égyptienne.

Elle représentait à l'origine le côté féminin du soleil, symétrique du dieu Rê. Elle devient ensuite une divinité à part entière, parèdre de Montou à Erment. Dans la triade de Médamoud elle est l'épouse de Montou et la mère de Harparê.


</doc>
<doc id="14467" url="https://fr.wikipedia.org/wiki?curid=14467" title="Triade de Médamoud">
Triade de Médamoud

La triade de Médamoud est un ensemble de trois dieux de la mythologie égyptienne de la ville antique de Médamoud. Montou y est l'époux de Râttaouy et le père de Harparê :



</doc>
<doc id="14468" url="https://fr.wikipedia.org/wiki?curid=14468" title="Harparê">
Harparê

Harparê est un dieu de la mythologie égyptienne. Dans la triade de Médamoud, il est le fils du dieu Montou et de la déesse Râttaouy.


</doc>
<doc id="14470" url="https://fr.wikipedia.org/wiki?curid=14470" title="Hededèt">
Hededèt

Dans la mythologie égyptienne, Hededèt est une déesse scorpion, essentiellement vénérée à Edfou, dont la protection était invoquée contre les animaux venimeux.

Dans les textes des sarcophages, elle est chargée de protéger la tresse de cheveux divins, en analogie avec la forme de sa queue de scorpion.

Dans le livre des morts, où elle figure avec Mafdet, elle est la personnification des cordes qu'elle utilise pour enchaîner le serpent Apophis. Dans sa lutte contre ce dernier, elle le pique avec sa queue et son poison le rend inoffensif.

Dans d'autre cas, on l'assimile aux cordes du navire de Rê.

On l'appelle également « La Lumineuse ». Associée à la déesse Selkis, elle perd peu à peu de son influence au profit de la déesse Isis.


</doc>
<doc id="14473" url="https://fr.wikipedia.org/wiki?curid=14473" title="Siemens (unité)">
Siemens (unité)

Le siemens, de symbole S, est l'unité de conductance électrique du Système international (SI), ainsi nommée en hommage à Werner von Siemens. L'admittance et la susceptance, de même dimension physique que la conductance, s'expriment aussi en siemens.

Un conducteur a une conductance d’un siemens quand sa résistance est d'un ohm. La conductance "G" et la résistance "R" d’un conducteur étant inverses l’une de l’autre ("R"∙"G" = 1), = = ou, en unités de base, = .

L’unité SI de conductance n’a été nommée siemens qu’en 1971. Auparavant son nom était le mho (ohm épelé à l'envers), et son symbole ℧ (un Ω renversé dans le sens de la hauteur), par référence à la valeur ; le terme mho avait été suggéré par William Thomson.




</doc>
<doc id="14475" url="https://fr.wikipedia.org/wiki?curid=14475" title="Unités dérivées du Système international">
Unités dérivées du Système international

Les unités dérivées font partie du Système international d'unités et sont déduites des sept unités de base :

Les colonnes « M - L - T - I - Θ (thêta) - N - J » précisent les « facteurs dimensionnels » des grandeurs dérivées, correspondant aux « expressions » dans les unités de base du Système international « kg - m - s - A - K - mol - cd » 





</doc>
<doc id="14482" url="https://fr.wikipedia.org/wiki?curid=14482" title="Jet Li">
Jet Li

Jet Li, de son vrai nom Li Lian Jie (李連杰 en chinois, Lǐ Liánjié en hànyǔ pīnyīn), né le à Pékin en Chine, est un pratiquant d'arts martiaux, acteur, producteur et champion de wushu sino-singapourien.

Il commence sa carrière à l'étranger en 1998 avec "L'Arme fatale 4", "Roméo doit mourir" en 2000 ou encore "Le Baiser mortel du dragon" (2001). Il continue également à tourner dans des films chinois. En 2010, il est à l'affiche de "" ("The Expendables").

Il pratique les arts martiaux chinois dès son plus jeune âge.

En 1971, il entre à l'école d'athlétisme Shichahai, où il intègre l'équipe sportive d'arts martiaux.

En 1975, lors des troisièmes Jeux nationaux de Chine, dans la catégorie des arts martiaux, désignant alors la lance et la boxe, il finit deuxième, puis gagne cinq fois d'affilée le titre de champion national chinois de Wushu, dans les disciplines du Chang quan (长拳), du sabre (刀术), de la lance (枪术), boxe de son choix (自选拳术), combat (对练)

Il accompagne alors certaines visites officielles chinoises à l'étranger. Après avoir participé à une démonstration sur la pelouse de la Maison-Blanche, devant le président Richard Nixon, aux États-Unis, ce dernier lui demande s'il veut devenir son garde du corps plus tard. Li Liangjie dit qu'il ne veut devenir le garde du corps de personne en particulier, qu'il préfère défendre son milliard de compatriotes.

À 16 ans, en 1979 il fait ses débuts au cinéma dans la série des "Temple Shaolin" qui est immédiatement un succès national en Chine. Artiste martial surdoué, doté d'une maîtrise technique impressionnante, perfectionniste et travailleur, il est souvent comparé, à tort ou à raison, à Bruce Lee. En effet, Jet Li apparaît comme n'étant « que » pratiquant tandis que Bruce Lee a créé son propre style, le jeet kune do, par de constantes recherches théoriques et pratiques.

Il va devenir célèbre à l'étranger en travaillant avec Tsui Hark sur la série des "Il était une fois en Chine" en 1991, où il fait la démonstration de son art du combat. Il tournera d'ailleurs une nouvelle version du film de Bruce Lee : "La Fureur de vaincre".

Repéré par Hollywood, il va se faire connaître aux États-Unis et en Europe dans un rôle de méchant dans "L'Arme fatale 4", en 1998. Il va ensuite tourner d'autres films occidentaux, notamment avec Luc Besson comme producteur et cinéaste, mais continue parallèlement à tourner en Chine, avec le réalisateur Zhang Yimou, et dans la province de Hong Kong.

Dans les années 2000, il joue dans "Danny the Dog", "The One", ", En sursis" et "Le Maître d'armes".

En 2010, il tient le rôle de "Yin Yang" dans "" ("The Expendables") aux côtés de Sylvester Stallone et Jason Statham. Il est de nouveau au casting d"'" ("The Expendables 2") et "Expendables 3".

Depuis 1999, il est marié à Nina Li Chi qu'il a rencontrée sur le tournage de The Defector avec laquelle il a deux filles : Jane (née en 2000) et Jada (née en 2003).

En 2013, il est révélé que l'acteur souffre d'une hyperthyroïdie. Il explique fin 2013 à la télévision chinoise qu'il se bat depuis 2010 contre cette maladie.





En France, Pierre-François Pistorio est la voix française régulière de Jet Li. Il y a eu également Frank Capillery qui l'a doublé à quatre reprises.







Et aussi :

Et aussi :
Li est un ambassadeur philanthrope de la Croix-Rouge chinoise depuis . Il a versé () provenant des revenus gagnés avec son film "Le Maître d'armes" à la section psychologique de la Croix Rouge.

Touché par son expérience aux Maldives durant le tsunami en 2004 où il faillit perdre une de ses filles, il crée The One Foundation, sa propre fondation à but non lucratif en .

The One Foundation, en collaboration avec la Croix rouge, soutient l'aide internationale aux victimes de grandes catastrophes, ainsi que des actions d'information ou de prévention au sujet de la santé mentale ou du suicide. Fin 2008, Li et sa fondation étaient intervenus dans sept catastrophes, incluant le tremblement de terre du Sichuan.




</doc>
<doc id="14485" url="https://fr.wikipedia.org/wiki?curid=14485" title="Suite de Cauchy">
Suite de Cauchy

En analyse mathématique, une suite de Cauchy est une suite de réels, de complexes, de points d'un espace métrique ou plus généralement d'un espace uniforme, dont les termes se rapprochent à partir d'un certain rang. Ces suites sont celles susceptibles de converger. Elles sont au centre de la définition de la complétude. Les suites de Cauchy portent le nom du mathématicien français Augustin Louis Cauchy.

Cette notion se généralise, dans un espace uniforme, par celles de filtre de Cauchy et de suite généralisée de Cauchy.

Une suite de réels ou de complexes est dite de Cauchy, ou vérifie le critère de Cauchy, lorsque les termes de la suite se rapprochent uniformément les uns des autres en l'infini au sens où :
formula_1
Cette dernière condition se réécrit classiquement à l'aide de quantificateurs universels et existentiels :
formula_2
ou encore : formula_3

L'uniformité dans la définition est importante : il ne suffit pas que la différence des termes consécutifs d'une suite tende vers 0 pour que cette suite soit de Cauchy. Par exemple, la suite des sommes partielles de la série harmonique vérifie mais n'est pas de Cauchy ni même bornée, puisqu'elle tend vers .

Une suite formula_4 dans un espace métrique est dite de Cauchy si :
formula_5
ce qui équivaut à
formula_6
ou plus synthétiquement, si
formula_7
ou encore si le diamètre de l'ensemble des termes d'indices supérieur à "n" tend vers 0 quand "n" tend vers l'infini :
formula_8
Les suites de Cauchy de réels sont donc un cas particulier de cette définition, en prenant, comme distance sur ℝ, la valeur absolue de la différence.

Les inégalités autres que ε > 0 peuvent être prises indifféremment larges ou strictes.

Intuitivement, les termes de la suite deviennent de plus en plus proches les uns des autres d'une certaine façon qui suggère que la suite doit avoir une limite dans l'espace. Les suites convergentes sont effectivement de Cauchy, mais la réciproque n'est pas vraie en toute généralité. Par exemple, certaines suites de Cauchy de rationnels convergent vers un irrationnel, donc convergent dans ℝ mais pas dans ℚ.

Exemple "(sans supposer connu le corps des réels)" : s'inspirant de la méthode de Héron, on construit une suite décroissante de rationnels positifs "x" dont les carrés tendent vers 2 : "x" = 3/2, "x" = + . La suite ("x") est de Cauchy (car convergente) et minorée par 1. On en déduit facilement que la suite de rationnels ("x") est également de Cauchy. Cependant elle n'a pas de limite rationnelle, car une telle limite ℓ devrait vérifier ℓ = 2, or la racine carrée de 2 est irrationnelle.

C'est la raison pour laquelle un espace métrique dans lequel toute suite de Cauchy converge est dit complet. L'ensemble des réels est complet, et une construction standard de cet ensemble utilise les suites de Cauchy de rationnels.


En analyse non standard, pour un espace métrique standard formula_11, il existe une définition équivalente mais pratique de la notion de suite de Cauchy.

formula_14.

En effet, si "x" est une suite de Cauchy, alors pour tout réel formula_15, il existe un entier formula_16 tel que pour tous "p", "q">"N", on a : formula_17. Si formula_18 est un réel standard, le principe de transfert permet d'imposer à formula_16 d'être un entier standard car la suite "x" est standard. Or tout entier naturel non standard est strictement plus grand que tout entier naturel standard. Donc, si "p" et "q" sont des entiers non standards, ils sont plus grands que tous les formula_16. De suite, formula_13 est strictement inférieur à tous les réels standards strictement positifs ; c'est donc un infiniment petit.

Réciproquement, supposons que pour tous entiers non standards "p" et "q", le réel formula_13 est un infiniment petit. Fixons dans un premier temps "N" un entier non standard. Tout entier plus grand que "N" est aussi non standard. Soit formula_15 un réel standard. Alors pour "p" et "q">"N", on a : formula_17. De fait, l'assertion suivante :
formula_25
est vérifiée pour tout réel standard strictement positif formula_18. Par principe de transfert, elle est vérifiée pour tout formula_15, ce qui signifie exactement que "x" est de Cauchy.

Dans un espace uniforme, une suite formula_9 est dite de Cauchy lorsque pour tout écart continu "d" sur "X", il existe un entier naturel "N" tel que pour tout formula_29, on a : formula_30.

Dans des exemples pratiques :




</doc>
<doc id="14488" url="https://fr.wikipedia.org/wiki?curid=14488" title="Cytométrie en flux">
Cytométrie en flux

La cytométrie en flux (CMF) est une technique permettant de faire défiler des particules, molécules ou cellules à grande vitesse dans le faisceau d'un laser, en les comptant et en les caractérisant. 

C'est la lumière réémise (par diffusion ou fluorescence) qui permet de classer la population suivant plusieurs critères et de les trier. 

La cytométrie en flux est définie comme l’étude précise de particules isolées ou de cellules, bactéries, etc. (vivantes ou mortes) entraînées par un flux liquide ou gazeux. C’est une technique de caractérisation individuelle, quantitative et qualitative de particules en suspension dans un liquide.

Il s'agit d'analyser les signaux optiques ou physiques émis par une particule coupant le faisceau lumineux d’un laser ou d’une lampe à arc. 
Les signaux mesurés sont essentiellement relatifs :

Ces signaux séparés par des filtres optiques sont collectés par des photomultiplicateurs (PMT), amplifiés, numérisés, traités et stockés par un ordinateur par l'intermédiaire d'une composante informatique et optique (miroir dichroïque et filtre optique).

Ce procédé d’analyse individuelle (cellule par cellule) est multiparamétrique et peut s’effectuer à la vitesse de plusieurs milliers d’événements par seconde. L’ordinateur calcule les données statistiques associées aux distributions des paramètres mesurés et les représente sous la forme d’histogrammes (un paramètre) ou de cytogrammes (deux paramètres) sur une ou plusieurs populations dont les propriétés cellulaires sont ainsi évaluées.

La fonction tri des cytomètres en flux les plus évolués permet de trier physiquement une ou deux populations cellulaires définies par leurs propriétés optiques.

Les premiers cytomètres en flux ont été inventés dans les années 1950.

C'est un des domaines d'intérêt de l'analyse biologique et plus largement de l'évaluation environnementale.
<br>On espère pouvoir un jour assurer ainsi un monitoring automatisé de la qualité de l'eau, et de ses variations par le suivi de bioindicateurs.

Les signaux optiques recueillis ont une intensité corrélée avec les propriétés particulaires.

La lumière diffusée renseigne sur la morphologie et la structure de la particule. Si la diffusion de la lumière est mesurée dans l’axe du rayon incident, l’intensité du signal peut être corrélée avec la taille et la viabilité cellulaire.

Sous un angle de 90°, la mesure correspond à la structure intracellulaire de la cellule (réfringence du cytoplasme, granulosité, morphologie, rapport nucléo-cytoplasmique).

L’utilisation simultanée de ces deux paramètres permet de distinguer, dans un sang périphérique par exemple, les plaquettes, les lymphocytes, les monocytes et les polynucléaires.

Cette mesure évolue proportionnellement au diamètre de la cellule (supposée sphérique) et à l’indice d’absorption des .

Cette fluorescence peut être spontanée, mais le plus souvent, elle est apportée à la cellule par un fluorochrome. Le fluorochrome absorbe l’énergie du laser et réémet l’énergie absorbée sous forme de photons d’une longueur d’onde plus élevée :

L'hématologie a été l’une des premières disciplines médicales à bénéficier des applications cliniques de la cytométrie en flux. Certaines de ces applications sont maintenant utilisées régulièrement pour le diagnostic ou le suivi thérapeutique de différentes affections. Ces applications concernent aussi bien l’étude fonctionnelle de cellules saines que la mise en évidence du caractère pathologique des cellules analysées.

En cancérologie, la détection de la cellule pathologique est l’application la plus développée. Cette détection repose essentiellement sur la mesure d’un contenu anormal d’ADN dans le noyau de la cellule tumorale.

L'immunologie utilise la CMF pour la détection ou l'identification des sous-types des cellules impliquées dans l'immunité. 

Le cycle cellulaire représente l’intégralité de la période de division, c’est-à-dire l’ensemble des événements biochimiques et morphologiques qui sont responsables de la prolifération cellulaire.
La CMF offre une méthodologie rapide et simple à mettre en œuvre pour l’analyse du cycle cellulaire. Elle permet de suivre la distribution des cellules dans les différentes phases du cycle en fonction de divers stimulus ou de l’ajout de certaines drogues. Elle permet aussi de voir la présence de cellules avec des contenus anormaux d’ADN.

De nombreuses études en pharmacologie font aussi appel à des techniques de CMF : mise au point ou étude de drogues antimitotiques, immunothérapie.

En océanologie, la cytométrie en flux est devenue une méthode de routine pour compter les différentes populations du picoplancton photosynthétique sur la base de la fluorescence des pigments tel que la chlorophylle. Après marquage des échantillons avec des marqueurs de l'ADN tels que le SYBR-Green, on peut aussi énumérer bactéries et virus.

D'autres recherches font appel à la CMF : l’analyse des chromosomes, la physiologie végétale (ploïdie, contenu en ADN, pour la sélection des plantes les plus résistantes)




</doc>
<doc id="14494" url="https://fr.wikipedia.org/wiki?curid=14494" title="Histoire de la Colombie">
Histoire de la Colombie

L’histoire de la Colombie commence il y a plus de . Différentes civilisations amérindiennes se développent dès cette époque, dont la plus influente est celle du peuple Chibcha. Celui-ci domine le centre du pays lorsque Christophe Colomb « découvre » l'Amérique en 1492.

Le territoire est rapidement colonisé par l'Espagne qui lui donne le nom de Nouvelle-Grenade. De nombreuses villes sont fondées dont Santafe de Bogota (l'actuelle capitale de la Colombie) en 1538. Les Amérindiens sont massacrés ou soumis au régime de l’"encomienda". Des Africains sont amenés pour servir de main-d'œuvre servile, notamment dans les mines d'or du Chocó. Devenue une partie de la vice-royauté de Nouvelle-Grenade en 1717, le pays connaît d'importants soulèvements à partir de 1810 à la faveur de l'affaiblissement de la métropole lors de la Guerre d'indépendance espagnole. Grâce à la guerre menée par le "" Simón Bolívar ces révoltes aboutissent à l'indépendance de la totalité de la vice-royauté en 1819, malgré une reconquête temporaire par la métropole.

En 1821, la Nouvelle-Grenade (dont fait alors partie le Panama), la Capitainerie générale du Venezuela et la Présidence de Quito se regroupent en une république, la République de (Grande) Colombie. Cependant, de nombreux désaccords surviennent et des volontés d'indépendance se font sentir, aboutissant à la sécession du Venezuela en 1829 et de l'Équateur l'année suivante.

La Grande Colombie devient alors la République de Nouvelle-Grenade, une république centralisée. Mais de nouvelles tensions apparaissent entre bolivaristes (centralistes catholiques) et santandéristes (fédéralistes et laïcs). De nombreuses guerres civiles découlent de ces oppositions. À partir du milieu des années 1850, le pays prend un tournant fédéral, devenant la Confédération grenadine en 1858, puis les États-Unis de Colombie en 1863. Le gouvernement central perd progressivement la quasi-totalité de ses pouvoirs et le pays en devient presque ingouvernable jusqu'à la politique de "Regeneración" du président Rafael Núñez. Celle-ci aboutit à l'abandon du fédéralisme et à l'adoption de la constitution de 1886 qui crée la République de Colombie et reste en vigueur pendant plus d'un siècle.

Les affrontements ne cessent cependant pas totalement et, en 1899, commence la guerre des Mille Jours, une guerre civile particulièrement violente qui dure trois ans et affaiblit la Colombie au point qu'elle ne peut s'opposer à l'indépendance du Panama en 1903. Cette épreuve choque durement la classe dirigeante qui s'abstient de tout nouveau conflit pendant plus de quarante ans, ce qui permet au pays de se développer économiquement. Cependant en 1948 le leader du parti libéral, Jorge Eliécer Gaitán, est assassiné à Bogota. Sa mort provoque des émeutes appelées "Bogotazo" qui dégénèrent en une guerre civile connue sous le nom de "La Violencia". Le général Gustavo Rojas Pinilla tente de mettre fin à l'anarchie en prenant le pouvoir en 1953. Après un succès mitigé, il est renversé en 1957. Le pays est alors dirigé par le Front national, une alliance entre le Parti libéral et le Parti conservateur.

Même si le calme revient peu à peu, cette confiscation du pouvoir par les deux partis principaux entraîne certaines formations politiques de gauche vers des modes de contestation non institutionnels et violents. Les Forces armées révolutionnaires de Colombie (FARC) en fournissent un exemple parmi d'autres. Cette radicalisation déclenche un nouveau conflit, baptisé conflit armé colombien, toujours en cours aujourd'hui. Depuis l'adoption en 1991 d'une nouvelle constitution qui restaure le pluralisme politique, et après l'exercice d'une politique militaire active contre les différentes guérillas, ce conflit tend néanmoins à s'apaiser et la situation à se normaliser.

L'arrivée des premières populations humaines sur le territoire colombien se fait par la côte Caraïbe et par l'est. À partir de ce moment de nombreux groupes se déplacent lentement vers l'intérieur des terres et occupent la cordillère des Andes.

De récentes datations au carbone 14 effectuées sur le site de Pubenza, dans le département de Cundinamarca, indiquent que les premiers habitants de la région sont arrivés avant .

Dans les abris rocheux d'El Abra, à l'est de Zipaquirá dans la savane de Bogota, des outils de pierre datés de (± 160 ans) ont été trouvés en 1967. Cette découverte, au centre du pays, confirme que les migrations paléoaméricaines ont atteint l'Amérique du Sud des années avant la date de fabrication de ces artefacts.

Dans la savane de Bogota se situe le site archéologique de Tequendama où ont été découverts des objets de pierre fabriqués avec soin tels des couteaux, des racloirs, des laminoirs et des pointes de projectiles. Ils furent réalisés entre -7000 av. J-C. et -3500 av. J-C. par des groupes de chasseurs spécialisés dont on possède 25 squelettes.

Au fil du temps certains peuples deviennent sédentaires tandis que les autres maintiennent leur nomadisme.

Les premiers vestiges connus d'agriculture sur le territoire colombien sont situés dans la serranía de San Jacinto, dans les actuels départements de Bolívar et Sucre, ainsi que dans son prolongement dans le département d'Atlántico où vivaient des tribus regroupées dans la zone appelée Puerto Hormiga. Il y a été réalisé des excavations qui ont mise au jour des vases et autres objets en céramique et que les tests pratiqués ont datés entre et .

À San Agustín, dans le département de Huila, ont été découvertes des traces d'établissements sédentaires datant du . Elles témoignent de l'existence d'une civilisation quasiment inconnue et disparue mystérieusement aux alentours de 1250. Elles sont conservées dans le parc archéologique de San Agustín. Ce parc regroupe trois sites d'importance : la fontaine de Lavapatas, la forêt de statues et le musée archéologique. Des sculptures monolithiques de la culture Agustín existent ailleurs, mais elles sont dans un état de conservation lamentable et techniquement irrécupérables en raison de l'action lente mais effective de l'érosion.

La culture Tierradentro est une autre culture sédentaire. Ses vestiges les plus tangibles sont les hypogées construites entre le dans le bassin supérieur du río Cauca, plus exactement dans le corregimiento de San Andres Psimbalá appartenant à la municipalité d'Inzá. Sur cette zone a été créé en 1945 le parc archéologique national de Tierradentro, devenu monument national en 1992, après décision du Conseil national des monuments, et inscrit en 1995 sur la liste du patrimoine de l'Humanité par l'UNESCO en tant que réservoir important de la culture précolombienne.

La culture Tierradentro, comme celle de San Agustín, a disparu. Les recherches effectuées indiquent néanmoins que les indiens Páez et Guambianos, les habitants autochtones de la région, sont les survivants du métissage résultant de la colonisation et de différents mouvements de populations au cours de l'Histoire colombienne.

Postérieurement, apparaissent d'autres cultures appelées « cultures dorées » en référence à leur travail de l'or.

La culture Tumaco-La Tolita s'est établie entre 600 et 400 sur le littoral Pacifique au niveau du département de Nariño et des provinces équatoriennes d'Esmeraldas et Manabí.

La culture Tolima s'est établie entre 200 et 1000 dans le département homonyme.

La culture Nariño s'est établie entre le sur les hauts plateaux de la cordillère des Andes à la frontière entre la Colombie et l'Équateur, dans ce qui est actuellement le département colombien de Nariño.

Au moment de l'arrivée de Christophe Colomb en Amérique, la côté Caraïbe est peuplée par deux grandes civilisations : les Tayronas et les Zenú. Les Tayronas sont établis dans la Sierra Nevada de Santa Marta, au nord du pays. Le territoire ancestral des Zenú est constitué par les vallées des ríos Sinú, San Jorge, Cauca et Nechi et par le littoral de la mer des Caraïbes, ce qui correspond aux actuels départements colombiens de Córdoba et de Sucre.

Dans les vallées des cordillères Occidentale et Centrale la culture Calima, apparue vers 1600 , occupe les bassins des ríos
San Juan, Dagua et Calima dans le département de Valle del Cauca, tandis que les Quimbayas sont établis dans la vallée du río Cauca, dans ce qui est aujourd'hui la zone du café, autour du département de Caldas.

La région de l'actuel département de Chocó, sur la côte Pacifique, est habitée par les Kunas autour du golfe d'Urabá. Le bassin inférieur du río Atrato l'est par les Wounaans de même que le cours du río San Juan. Les Emberás vivent quant à eux dans le bassin supérieur du río Atrato et dans la serranía del Baudó.

Le centre de l'actuelle Colombie est alors dominé par les Chibchas (ou Muiscas), qui vivent dans la savane de Bogota, au cœur de la cordillère Orientale. Ils ont formé une vaste fédération, la Confédération muisca.

Outre ces groupes importants, une myriade de petits groupes ethniques peuplent le reste du territoire. Cinq siècles plus tard, selon le recensement de 2005, la Colombie ne compte pas moins de .

C'est l'Espagnol Alonso de Ojeda qui, en 1499, aborde pour la première fois les côtes colombiennes, au cap de la Vela, dans le département actuel de La Guajira. Lors de cette expédition il est notamment accompagné du cartographe basque Juan de la Cosa et du pilote italien Amerigo Vespucci. En publiant le récit de ce voyage, Vespucci laissera son prénom à ce nouveau continent dont il sera l'un des premiers à affirmer publiquement l'existence.

Arrivent ensuite des aventuriers espagnols (les « conquistadors ») qui ont vendu leurs biens en Espagne afin de financer leur expédition. Ils sont à la recherche d’or. Rapidement les Espagnols fondent des villes : San Sebastian d'Uraba en 1509 et Santa María la Antigua del Darién en 1510, toutes deux au bord du golfe d'Urabá. Après la découverte de l'océan Pacifique par Vasco Núñez de Balboa, la ville de Panama est fondée en 1519 sur la côte Pacifique de l'isthme de Panama par Pedro Arias Dávila. En 1524, l'ancienne juridiction d'Ojeda est divisée en deux gouvernorats concédés à des gouverneurs chargés de les coloniser et de les explorer. À l'ouest du río Magdalena le bénéficiaire n'exercera jamais son mandat mais à l'est, entre le Magdalena et le cap de la Vela, Rodrigo de Bastidas fonde en 1526 la ville de Santa Marta.

En 1533, Pedro de Heredia, un des anciens gouvernants de Santa Marta, fonde Carthagène des Indes à l'ouest de l'embouchure du Magdalena. En peu de temps, dans la région du río Sinú, de nombreuses tombes de caciques sont découvertes. Signalées par des tumuli, elles se révèlent être riches en or, ce qui attire nombre de conquérants. Après le retour de Francisco Pizarro du Pérou en 1533, Carthagène devient également une escale privilégiée sur la route du Pérou.

En 1535, à la suite d'un concours de circonstances, Gonzalo Jiménez de Quesada prend le commandement de la colonie de Santa Marta, alors dans une situation critique. Il décide de monter une expédition vers l'intérieur des terres pour rejoindre le Pérou. Il rencontre à cette occasion une importante civilisation dans les hauts plateaux de la cordillère Orientale, les Chibchas. Après avoir mis en fuite le zipa de Bacatá, il fonde en août 1538 une nouvelle ville à l'emplacement de l'ancienne résidence de ce dernier, Santafe de Bogota.

Deux autres expéditions arrivent dans la région à la même époque. La première est partie du Venezuela. Elle est conduite par l'allemand Nikolaus Federmann (hispanisé en Nicolás de Federmán), successeur d'Ambrosio Alfinger comme gouverneur de la région, qui a traversé tout le bassin de l'Orénoque. La seconde vient du Pérou, conduite par Sebastián de Belalcázar, un des lieutenants de Francisco Pizarro. Après la défaite de l'Inca Atahualpa en 1533, Belalcázar a conquis la région de Quito en 1534 avant d'explorer tout le sud de l'actuelle Colombie, fondant notamment les villes de Cali en 1536 et Popayán en 1537.

En 1540, la situation politique est confuse et la Couronne peine à imposer pleinement son autorité. Sebastián de Belalcázar, Gonzalo Jiménez de Quesada et Nicolás de Federmán, les trois conquérants qui se sont rencontrés dans la région de Bogota, s'en remettent au jugement de la Couronne pour décider d'un partage des zones d'influences. Ils s'embarquent pour l'Espagne. Après un long procès, l'empereur Charles Quint décide que les nouveaux territoires dépendront du gouverneur de Santa Marta, dont Gonzalo Jiménez de Quesada n'est que le lieutenant. Sebastián de Belalcázar reçoit en compensation le titre d’"adelantado" et les terres qu'il a explorées au sud. Il fait de Popayán sa capitale. Les grands perdants du jugement sont Nicolás de Federmán et Pascual de Andagoya. Celui-ci réclamait le poste de gouverneur de Popayán. Malgré ce jugement, la situation ne s'améliore pas et les disputes entre conquérants continuent.

La plupart des problèmes sont liés à l'éloignement de l'autorité. Le seul relai entre les territoires américains et le Conseil des Indes, à Madrid, est la "Real audiencia" de Saint-Domingue, créée en 1511, aux pouvoirs flous et au domaine de compétence beaucoup trop vaste (la totalité des Indes occidentales espagnoles). En 1538 est créée une nouvelle "audiencia", la "Real audiencia de Panama", mais l'isthme, trop éloigné des autres territoires, ne remplit pas pleinement le rôle d'autorité centrale. C'est la raison pour laquelle une "" du crée la "Real audiencia de Santa Fe de Bogota". La région de Carthagène y est rattachée tandis que le sud du pays dépend de celle de Quito dès sa création le .

La "Real audiencia de Santa Fe de Bogota", représentante d'une autorité lointaine mais indiscutée, parvient à rétablir l'ordre en quelques années. La ville où elle siège devient rapidement la plus grande ville de ce qui est appelé alors le Royaume de Nouvelle-Grenade. Les "oidores" et autres fonctionnaires venus d'Espagne ne tardent pas à devenir la classe dirigeante de la colonie tandis que le rôle des premiers conquérants décline inexorablement. Dès la fin du , la plupart des "encomiendas" appartiennent à des parents ou des clients d’"oidores".

Le , le pape Pie IV créé l'archevêché de Bogota, dont l'autorité religieuse s'étend de Cuenca, au sud de Quito, jusqu'à Panama. La même année, la "Real audiencia" devient "Presidencia" avec la nomination en tant que président d'Andrés Díaz Venero de Leyva.

La Nouvelle-Grenade se caractérise par trois facteurs essentiels : la diminution rapide de la population amérindienne par l'essor précoce du métissage, les nouvelles maladies et la guerre ; l'importance économique des mines d'or exploitées par des esclaves amenés d'Afrique ; la compartimentation régionale due au relief qui rend les échanges difficiles et favorise les particularismes. Plus qu'un véritable État, la Nouvelle-Grenade est une juxtaposition de plusieurs sociétés très dissemblables qui ne communiquent que peu.

Le centre du pays, autour de Santa Fe, abrite la principale concentration de bureaucrates entourée d'une vaste région agricole peuplée d'indiens ou de métis. Dans le nord-est et le nord-ouest andins se développe une agriculture prospère basée sur la culture du tabac ou du café. La côte Caraïbe profite des échanges entre la métropole et la capitale ainsi que du commerce d'esclaves avec la région Pacifique où se trouvent les plus importantes mines d'or.

Bien que généralement connue pour sa production d'or, la société qui se met en place sous la domination espagnole est surtout centrée sur l'agriculture. Les échanges avec la métropole ou les autres colonies sont très réduits. L'économie agricole néo-grenadine est basée sur l'appropriation des terres par les espagnols et l'exploitation de la main d'œuvre rurale : amérindiens au début, puis métis ou esclaves noirs dans certaines régions après le brutal déclin de la population autochtone.

Quoique la Couronne espagnole souhaite limiter au maximum les contacts entre espagnols et les Amérindiens, ceux-ci sont enrôlés dans le système de l’"encomienda". En échange de leur évangélisation, ils payent un tribut en nature (nourriture, coton, etc.) ou en services (transport, travail dans les mines ou dans les "haciendas"). Les tribus indiennes qui résistent militairement, comme les Pijaos, sont massacrées.

La démographie de la population amérindienne à l'arrivée des espagnols est mal connue. Peu de chiffres nous sont parvenus. Les différents recensements de l'époque coloniale répondent à des besoins fiscaux et seuls les indiens des "encomiendas" sont concernés, sans qu'il soit possible de déterminer si tous les adultes sont comptabilisés ou seulement les indiens soumis au tribut, c'est-à-dire les hommes âgés de 17 à . L'historien Jaime Jaramillo Uribe donne une fourchette de à . Toutefois les chiffres concordent pour prouver un déclin brutal et général sur l'ensemble du territoire. La population indigène autour de la ville de Tunja, très importante au départ, diminue de 50 % entre 1562 et 1600 et de 84 % entre 1562 et 1636. La province de San Juan de Pasto, également très peuplée au moment de la conquête, voit son nombre de tributaires passer de à entre 1559 et 1582. Dans la zone moins densément peuplée de l'actuel Caldas, où vivent les Quimbayas, la chute démographique est encore plus marquée, passant de en 1539 à 69 en 1628. La cause de ce déclin est double. D'une part le choc microbien (grippe, rougeole et autres maladies apportées par les conquérants) ravage la population. D'autre part les mauvais traitements, le travail forcé (en particulier dans les régions minières), le confinement des indiens dans les zones les moins fertiles et le bouleversement de tous les cadres de leurs sociétés aggravent le phénomène.

À partir de 1600, lorsque la Couronne parvient à imposer une législation plus protectrice des amérindiens à travers les Lois de Burgos en 1512, les "Leyes Nuevas" en 1542, et la publication du livre "Brevísima relación de la destrucción de las Indias" par le dominicain frère Bartolomé de las Casas en 1552, le recul démographique diminue peu à peu. Mais les indiens sont alors très largement dépassés en nombre par les populations allogènes et ils ont totalement perdu leur culture. Seuls survivent les cultures amérindiennes qui ont choisi l'affrontement avec les envahisseurs comme les Pijaos. Ils résisteront plus d'un siècle. Retranchés dans une véritable forteresse naturelle au cœur de la cordillère Centrale, leur présence menace la route qui relie Santa Fe à Popayan. Ils n'hésitent pas à razzier les villes de la vallée moyenne du río Cauca. En dépit de ces luttes les indiens sont peu à peu repoussés vers les zones où ils vivent encore actuellement : les forêts du Chocó, les plus hautes cimes de la Sierra Nevada de Santa Marta ou la péninsule de Guajira, au climat désertique. En revanche ceux vivant dans les régions sauvages, très peu peuplées, des llanos ou de la région amazonienne ne seront pas inquiétés avant le , malgré la présence de missions jésuites au début du .

La pénurie de main d'œuvre constitue le principal problème économique en Nouvelle-Grenade. Les plus riches "encomiendas" se trouvent dans les zones où la population indienne est importante. Mais de nombreuses petites exploitations s'avèrent difficiles à rentabiliser et changent souvent de propriétaires bien que cela soit illégal. En effet les autochtones ne doivent en principe qu'un tribut à l’"encomendero", qui n'a aucun droit sur leurs terres, l’"encomienda" n'étant pas une propriété mais une simple concession, viagère et révocable à tout moment. Cependant les "encomiendas" sont administrées en pratique comme les fiefs du Moyen Âge européen. Elles servent à rassembler des troupes et des armes dans une place forte et elles permettent à l’"encomendero" de vivre « noblement », c'est-à-dire sans travailler de ses mains. Souvent elles sont transmises en héritage.

La Couronne modère ces usages à l'aide de plusieurs réformes à partir des années 1590. L'une d'elles établit les "corregidores de indios". Ce poste, en principe réservé à un indien, consiste à répartir la main d'œuvre indigène entre les espagnols. Il autorise son titulaire à percevoir le tribut de ses semblables et, puisque la main d'œuvre se raréfie, il lui confère un grand pouvoir. Le roi d'Espagne s'évertue par ailleurs à récupérer les "encomiendas" tombées en déshérence. À partir du , le nombre d’"encomiendas" diminue avec régularité à cause des réformes, du manque de main d'œuvre indigène et de la pression de nouveaux groupes sociaux plus dynamiques. Le système d’"encomienda" disparaît quasi totalement au cours du , remplacé par les "haciendas". Il s'agit de domaines agricoles tenus par des colons auxquels les indiens se louent comme "conciertos". Ces travailleurs disposent en outre de "resguardos", des terres, souvent de piètre qualité, réservées aux indiens.

Les métis, les noirs et les mulâtres libres, ou les blancs pauvres travaillent eux aussi comme "conciertos" dans des "haciendas". Dans quelques régions certains d'entre eux commencent à s'approprier des terres laissées en friche. Ainsi naît une classe de petits paysans indépendants particulièrement dynamique. Ils se spécialisant dans la culture du coton ou du tabac dans le Santander, ou du café dans l'Antioquia.

Dans l'ensemble l'économie agricole se révèle être arriérée et peu productive. La véritable richesse du pays demeure l'or, volé aux indiens d'abord puis exploité dans les mines par des esclaves noirs amenés d'Afrique.

La Nouvelle-Grenade, colonie secondaire par rapport au Mexique ou au Pérou, ne dispose pas d'importantes réserves d'argent. En revanche la production d'or y est importante.

Le pillage des réserves accumulées par les indiens au fil des siècles cesse vers 1560 avec leur épuisement. La production est dès lors assurée par des mines, qui sont en fait des gisements alluviaux collectés par orpaillage. Très vite, malgré les efforts de la Couronne espagnole pour empêcher l'asservissement des autochtones telles les "Leyes Nuevas" en 1542, la main d'œuvre indigène, gratuite, est épuisée par les mauvais traitements et les difficiles conditions de travail.

Les exploitants ont alors recours à des esclaves noirs ramenés d'Afrique. Carthagène des Indes, par sa situation géographique, est une étape privilégiée entre la métropole, Saint-Domingue, le Mexique et le Pérou. Elle devient un important port négrier, le seul d'Amérique avec Veracruz au Mexique jusqu'en 1615. Dans l'ensemble, cette main d'œuvre est mieux traitée, parce qu'elle coûte cher : un jeune adulte vaut jusqu'à , soit le prix de 25 vaches.

Entre 1630 et 1670, la conquête de la côte Pacifique donne accès aux mines d'or du Chocó et aux affluents du río Cauca, une zone beaucoup plus riche que le reste du pays. Les mêmes techniques d'orpaillage sont utilisées à grande échelle et la production d'or augmente sensiblement durant tout le . Les mines deviennent des exploitations rentables quoique précaires en raison de la dépendance à un approvisionnement extérieur et du besoin de prospecter toujours plus de filons pour maintenir la production, ce qui occasionne parfois des conflits.

Jusque dans les années 1580, il faut une licence pour importer des esclaves en Nouvelle-Grenade. Un "cabildo" achète les esclaves à la Couronne et les répartit entre les citoyens de sa ville. À partir de 1587, le système de l’"asiento" est adopté. Les esclaves sont achetés à des compagnies portugaises puis anglaises ou françaises qui payent au gouvernement espagnol le droit d'introduire en Amérique une certaine quantité d'esclaves chaque année. Interrompu de 1640 à 1660 à cause de la Guerre de Restauration portugaise, il atteint son apogée au début du . La contrebande permet aussi aux colons de se fournir en main d'œuvre. En 1789, le commerce d'esclaves est totalement libéralisé, mais il est alors déjà en déclin.

Les échanges avec la métropole, jusqu'au port de Cadix, se font à l'aide de convois de galions protégés par des navires de guerre. Ces voyages s'effectuent une à deux fois par an à travers la mer des Caraïbes et l'océan Atlantique infestés de flibustiers et de pirates français, hollandais ou anglais. Les affrontements sont nombreux et l'Espagne peine parfois à maintenir le contact avec ses colonies. Entre 1653 et 1659 un seul convoi parvient à Carthagène des Indes. En 1697 a lieu l'expédition de Carthagène, une attaque de la marine française, commandée par le chef d'escadre Jean-Bernard de Pointis, du port caribéen qui est pris et pillé pour un butin estimé entre 10 et 20 millions de livres. Cette expédition est ordonnée par le roi de France Louis XIV. Ce souverain recherche un succès sur les mers afin de pouvoir signer le traité de Ryswick (qui mettra un terme à la guerre de la Ligue d'Augsbourg) en position de force. Il obtient ainsi de l'Espagne la partie ouest de l'île de Saint-Dominque qui devient colonie française.

La principale voie de transport de la Nouvelle-Grenade est le río Magdalena qui relie la mer des Caraïbes à la capitale, Santa Fe de Bogota. Face aux problèmes posés par les pirates une route reliant le lac Maracaibo et Santa Fe par Tunja est mise en service. En 1650, un canal est percé reliant la baie de Carthagène des Indes et le río Magdalena. Faute d'entretien il n'est plus guère utilisé à partir du . À l'origine le trajet s'effectue à l'aide de rameurs indigènes, les "bogas". Mais à la suite de la raréfaction de cette main d'œuvre on recourt aux esclaves. Par la suite des frégates assurent une part de plus en plus importante du trafic et le système de "bogas" tombe en désuétude.

Les principaux produits importés entre Carthagène et Santa Fe sont les produits manufacturés européens (métal ou textile) et les denrées méditerranéennes impossibles à produire sur place. Vers Carthagène sont transportés principalement des produits agricoles (blé, maïs, viande, sucre, cacao, etc.) ou des produits artisanaux (sacs, corde, etc.) destinés aux villes côtières. Les produits exportés et importés par la Nouvelle-Grenade sont taxés par la Couronne au moyen de l’"almojarifazgo", un impôt représentant 7,5 % de la valeur de la marchandise. Il est perçu par la Casa de Contratación, à Séville, une institution chargée de contrôler les monopoles de commerce avec l'Empire espagnol qui perçoit également le "quinto", l'impôt sur la production d'or.

Dans le reste du pays les routes importantes sont la route transandine qui relie Ibagué, dans la vallée du rio Magdalena, à Cartago, dans celle du río Cauca, la route qui connecte Cali et le port Pacifique de Buenaventura, et la route du Pérou, via San Juan de Pasto et Popayán, si incommode que l'essentiel du trafic entre l'Espagne et le Pérou se fait par la mer via Panama.

Juridiquement le Royaume de Nouvelle-Grenade, établi en 1550, est un district dont le territoire relève de la Real audiencia de Santa Fe de Bogota. Administrativement, il est considéré comme une capitainerie générale dépendant de la vice-royauté du Pérou, fondée en 1542. Le président de la "real audiencia" dépend donc du vice-roi du Pérou à Lima. Cantonnée au départ à la seule partie septentrionale de la Nouvelle-Grenade, la juridiction de la Real Audiencia de Santafe s'étend avec le temps aux provinces limitrophes et dépasse largement le territoire néo-grenadin.

Gérer un empire grand comme un continent n'est pas chose facile et la Couronne a beaucoup de mal à imposer son autorité. Le système mis en place est centraliste et très bureaucratique et fonctionne tant bien que mal. L'administration suprême est le Conseil des Indes, à Madrid, qui ne rend compte qu'au roi. C'est sous sa tutelle que les "oidores" de la "real audiencia" rendent la justice, arbitrent les conflits entre administrés et font appliquer les décisions de la Couronne.

Le travail des fonctionnaires est contrôlé "a posteriori" au cours d'un procès, la "residencia", mené par un juge spécialisé, le juge de résidence (). Ce procès a lieu soit au terme de la mission du fonctionnaire, s'il est défini, soit en principe tous les trois ans, mais souvent après une plus longue durée et avec une périodicité irrégulière. La corruption permet souvent à un fonctionnaire d'échapper à une condamnation (pouvant aller d'une amende à la peine de mort suivant la gravité des fautes) en achetant soit les témoins du procès, qui sont ses administrés, soit le juge de résidence lui-même. L'administration est également soumise à des inspections nommées « visites ». Lors d'une « visite générale », toute la "real audiencia" est auditée par un "visitador general" venu d'Espagne. Ces inspections ont lieu de façon irrégulière. Elles deviennent plus fréquente au cours du lorsque la Couronne tente de faire passer d'importantes réformes.

La "real audiencia" de Santa Fe a autorité sur la majeure partie de l'actuel territoire colombien. La région de Popayán, au sud, dépend de celle de Quito. Le territoire, qui fait partie de la vice-royauté du Pérou, est divisé en gouvernorats, dont les gouverneurs sont nommés par le Conseil des Indes. Au-dessous, dans les agglomérations ayant le statut de "ciudad" ou de "villa", un "cabildo" représente la communauté espagnole.

L'Église joue également le rôle d'instrument de contrôle. Le pape a cédé aux autorités espagnoles le « patronage royal », c'est-à-dire le droit de nommer les prêtres et les évêques. Seuls les Jésuites dépendent directement de Rome. L'influence des autorités religieuses, centralisées par l'archevêché de Bogota, est considérable. Quasiment chaque village dispose d'au moins un couvent, franciscain, dominicain, carme ou jésuite.

La lenteur des communications entre Lima et Bogota conduit la Couronne espagnole à décider de l'établissement d'une vice-royauté de Nouvelle-Grenade en 1717. Supprimée en 1723 à cause de problèmes financiers, elle est rétablie en 1739.

En 1700, Charles II d'Espagne meurt sans successeur et les Bourbons succèdent aux Habsbourg sur le trône d'Espagne, de manière définitive après la guerre de Succession d'Espagne (1701-1714). Avec l'Espagne, les Bourbons héritent de l'immense Empire espagnol dont fait partie le Royaume de Nouvelle-Grenade. Très vite, la politique à l'égard des possessions d'outre-mer change : tandis que sous les Habsbourg les différents royaumes sont unis à la Couronne de Castille, théoriquement sur un pied d'égalité avec les royaumes européens de León ou de Grenade, les Bourbons tendent à considérer les royaumes d'outre-mer comme de simples colonies n'existant que pour être exploitées. Cette nouvelle politique se traduit par un bouleversement de l'administration et l'alourdissement brutal de la fiscalité, ce qui ne va pas sans provoquer de violentes réactions en Amérique.

L'une des premières mesures est la réunion des diverses colonies américaines en trois puis quatre grands ensembles, les vice-royautés. Le , une ' place la Real audiencia de Quito (qui est supprimée) et le Venezuela sous la tutelle de la Real audiencia de Santa Fe de Bogota, créant la vice-royauté de Nouvelle-Grenade. Le , après la guerre avec la Quadruple Alliance, Philippe V émet une autre ' qui supprime la vice-royauté en raison de difficultés économiques. Le , la vice-royauté est recréée via une nouvelle '. Ses frontières avec la vice-royauté du Pérou, l'audience de Quito (rétablie le ) et les possessions portugaises dans la forêt amazonienne sont précisées par une autre ' de Philippe V le .

Le , dans le cadre de la guerre de l'oreille de Jenkins qui oppose l'Espagne à l'Angleterre, le vice-amiral Edward Vernon détruit le port de Porto Bello, dans l'actuel Panama. Ce succès lui permet de réunir une puissante flotte qui entre mars et mai 1741 fait le siège de Carthagène des Indes. Ce dernier se solde par une défaite majeure et de lourdes pertes pour les Britanniques : 50 navires perdus, gravement endommagés ou abandonnés et des pertes humaines considérables, avec la mort de et marins, en partie due à la maladie, notamment la fièvre jaune.

Le , la province de Caracas est séparée de la vice-royauté. Le , les provinces de Maracaibo, Guayana et Cumaná sont également séparées de la vice-royauté de Nouvelle-Grenade et sont regroupées avec la province de Trinidad, dépendant de la Capitainerie générale de Saint-Domingue, et la province de Margarita, dépendant de la Couronne espagnole, pour former la Capitainerie générale du Venezuela.

Sur le plan économique et fiscal, la Couronne met fin à certains monopoles gênants et inefficaces. En 1768, la liberté de commerce est instaurée entre la Nouvelle-Grenade et le Pérou, puis avec toute l'Amérique en 1774. Le monopole du port espagnol de Cadix pour le commerce transatlantique est aboli en 1778. Dans le même temps, d'autres monopoles plus lucratifs sont créés sur le commerce de certains produits comme la poudre, le rhum ou le tabac. Mais ces réformes peinent à être appliquées et le visiteur général Juan Francisco Gutiérrez de Piñeres est envoyé en Nouvelle-Grenade en 1778 pour affirmer l'autorité de la Couronne et faire appliquer ses décisions malgré l'hostilité des producteurs locaux à leur égard.

En 1781 a lieu un important soulèvement populaire, la révolte des Comuneros, dans la région de l'actuel département de Santander, en Colombie. Les causes sous-jacentes sont surtout économiques, liées aux réformes entreprises par la Couronne espagnole, mais les idées de liberté et d'autonomie gouvernementale sont exprimées, notamment à travers l'exigence d'une représentation plus importante des créoles au sein de l'administration coloniale du pays,
ce qui laisse augurer la lutte pour se libérer du colonialisme espagnol menée au . Marchant sur Santa Fe, les protestataires négocient avec l’archevêque à Zipaquirá mais le vice-roi Manuel Antonio Flores refuse de reconnaître l'accord ainsi signé le et envoie les troupes de Carthagène mater la rébellion.

Le , une "real cédula" fait passer la côte des Mosquitos (côte est de l'actuel Nicaragua) et l'archipel de San Andrés y Providencia de la tutelle de la Capitainerie générale du Guatemala à celle de la vice-royauté de Nouvelle-Grenade, sous l'administration de la province de Carthagène des Indes.

Pendant ce temps, les guerres napoléoniennes font rage en Europe. En 1805, l'Espagne, alliée de l'Empire français, subit la rude défaite de Trafalgar et, privée de flotte, perd tout contact avec ses colonies. En 1807, le Portugal refusant d'appliquer le blocus continental, Napoléon décide d'envoyer ses troupes dans la péninsule, officiellement pour envahir le Portugal qui représente une faille notable dans son dispositif destiné à asphyxier l'Angleterre. L'invasion française de 1808 achève de déstabiliser la Couronne espagnole, déjà mise à mal par une guerre de succession entre Charles IV et son fils Ferdinand. L'empereur français en profite pour nommer son frère Joseph Bonaparte sur le trône. Ces manœuvres politiques et la guerre qui s'ensuit font vaciller l'autorité de la puissance coloniale, ce qui laisse la possibilité aux colonies d'Amérique de s'émanciper.

À la suite de la nomination de Joseph Bonaparte comme roi d'Espagne par son frère Napoléon, le peuple de Madrid se soulève contre l'occupant français le . Durement réprimé, ce soulèvement inspire d'autres villes de la péninsule et embrase l'Espagne, marquant le point de départ de la guerre d'indépendance espagnole.

La captivité du roi d'Espagne Ferdinand VII au château de Valençay pose aux Espagnols la question de la représentation qui doit remplir le vide laissé par l'absence du roi. Suivant des traditions remontant aux Habsbourgs, la souveraineté est donnée par Dieu aux "Pueblos" qui la transférent au roi au travers d'un pacte. En l'absence du roi, les "Pueblos" sont donc supposés récupérer cette souveraineté. C'est par cette fiction que chaque cité-capitale d'Espagne, et même parfois des villes secondaires, peut proclamer un gouvernement et se constituer en junte pour combattre l'invasion.

Toutefois, une Junte Centrale s'avère nécessaire pour coordonner à la fois la lutte contre les Français et le gouvernement civil. Ce sera celle de Séville. C'est alors que se pose la question épineuse de la représentation des différentes juntes péninsulaires et américaines. La junte de Séville propose 36 députés pour la péninsule et 9 députés pour l'Amérique, ce qui est jugé inacceptable par ces derniers. Peu à peu, la situation militaire devient intenable pour les espagnols. La Junte Centrale est dissoute peu avant l'occupation de la ville par les Français en janvier 1810. Elle laisse place à une Régence de cinq membres installée sur l'île de León, au large de Cadix, bientôt elle aussi dissoute.

Les cités américaines n'ont pas bougé jusque-là à l'exception de Quito qui a établi une junte le , rapidement mise au pas par les vice-rois de Nouvelle-Grenade et du Pérou. Toutefois, la menace de défaite totale des Espagnols de la péninsule les pousse elles aussi à se constituer en juntes. Caracas, où le capitaine général est déposé, montre l'exemple le , suivi par Buenos Aires le 25 mai.

En Nouvelle-Grenade, la première junte est établie à Carthagène des Indes le , suivie par Cali le 3 juillet, Pamplona le 4, Socorro le 11, Mompox le , Chocó le . C'est le , à la suite de l'épisode du "", que les habitants de Bogota instaurent leur propre junte.

Bien que considéré par l'historiographie colombienne comme le point de départ de la lutte pour l'indépendance et que ce jour du 20 juillet soit décrété fête nationale, il n'est en réalité nullement question d'indépendance. La loyauté des différentes juntes à l'égard de Ferdinand est exemplaire, même si l'aspiration à l’auto-gouvernement est ancienne. Le vice-roi Antonio José Amar y Borbón conserve même l'autorité suprême de premier délégué du roi en présidant la junte de Bogota avant d'être accusé de trahison au profit de Joseph Bonaparte et exilé.

Mais la question de la représentation reste une question délicate entre l'Amérique et la péninsule tout au long des années 1810 et 1811. Les Américains demandent toujours le même traitement que les péninsulaires dans la représentation à la Junte Centrale. Ces demandes, finalement discutées en février 1811, sont rejetées par les Espagnols, qui ne comprennent pas l'insistance des Américains à vouloir être traités en égaux et estiment avoir affaire à des rebelles. Cette incompréhension, que les Américains prennent pour du mépris, les pousse peu à peu à se radicaliser et, pour la première fois, à rejeter complètement l'autorité espagnole et à revendiquer l'indépendance.

À Bogota, la junte proclame l'indépendance de l'Espagne de l'État libre de Cundinamarca le . À Carthagène des Indes l'indépendance de la province est déclarée le . D'autres proclamations se produisent dans tout le pays et aboutissent à l'indépendance de la plupart des provinces de Nouvelle-Grenade : Tunja le , Antioquia le , Neiva le et Mariquita le .

Les provinces de Santa Marta, Riohacha et Popayán restent quant à elles fidèles à la couronne espagnole.

Un Congrès des Provinces-Unies se réunit le à Tunja et adopte l"'Acta de la Federación de las Provincias Unidas de Nueva Granada", dont les idéologues sont Camilo Torres et Miguel de Pombo. De tendance fédéraliste, cette constitution promeut le respect et la reconnaissance de l'autonomie et de la souveraineté des provinces, qui se définissent comme égales et indépendantes, autonomes dans leur mode d'administration et la collecte de certains impôts; les fonctions militaires pour la défense commune et la levée d'impôts pour financer la guerre et les relations internationales sont cédées au Congrès.

À ces idées fédéralistes s'opposent certaines factions centralistes, menées par Antonio Nariño, qui préfèrent un gouvernement central fort, plutôt qu'une alliance de provinces autonomes et faibles. En raison de ce désaccord, les représentants des provinces de Bogota (appelée Cundinamarca par ses représentants) et du Chocó refusent de signer l'Acte de Fédération.

Les provinces de Panama et de Veragua, bien qu'invitées à participer aux juntes de Quito, Santa Fe ou Carthagène afin d'adhérer au mouvement indépendantiste, refusent et restent loyales à l'Espagne.

Entre le et le , le jeune vénézuélien Simón Bolívar, qui s'est mis au service de l'armée de patriote de Carthagène des Indes après la chute des Provinces-Unies du Venezuela, libère les villes situées sur le cours du río Magdalena lors de la campagne du Magdalena. Cette campagne militaire victorieuse permet la jonction entre les patriotes de Carthagène et ceux de centre du pays et pousse Bolívar à entreprendre une campagne pour libérer le Venezuela.

Pendant ce temps, le désaccord croissant entre le gouvernement de l'État libre de Cundinamarca, centraliste, et celui des Provinces-Unies, fédéraliste, conduit à un conflit armé qui commence le , date de la première bataille (à Ventaquemada) de la première guerre civile de l'histoire de la Colombie. Nariño, leader du Cundinamarca, après quelques défaites, offre une capitulation assortie de conditions, mais les fédéralistes refusent, souhaitant une reddition inconditionnelle, ce qui prolonge la guerre. Après la défaite des centralistes à Ventaquemada, les fédéralistes avancent vers Santafé de Bogota, mais sont mis en déroute par Nariño le .

Le , la guerre entre fédéralistes et centralistes se termine après un dialogue entre Cundinamarca et les Provinces-Unies, chacune représentée par deux délégués. Ceux-ci s'accordent sur la volonté d'indépendance et l'union de leurs forces contre l'ennemi commun, l'Espagne. Le Congrès National nomme Antonio Nariño "Comandante Supremo" de l'armée pour libérer les provinces du sud, mais il est capturé et rapidement envoyé en prison en Espagne.

Le , Simón Bolívar, revenu en Nouvelle-Grenade après l'échec de la Deuxième République du Venezuela et à la tête des troupes des Provinces-Unies composées de fédéralistes et de vénézuéliens, entre dans Santafé de Bogota et force Cundinamarca à intégrer les Provinces-Unies. Le compromis trouvé est que le Cundinamarca s'engage à rejoindre la fédération en échange du déplacement du siège du Congrès des Provinces-Unies de Tunja vers Bogota, qui redevient ainsi la capitale du pays.

Après la prise de Santa Fe, Bolívar se dirige vers la côte Atlantique où il doit recevoir des armes et des fournitures de Carthagène des Indes pour prendre Santa Marta puis libérer le Venezuela. Toutefois, le gouvernement carthaginois refuse de le soutenir et Bolívar assiège la ville pendant un mois et demi. Informé de l'arrivée de Pablo Morillo au Venezuela et attaqué par les royalistes à Santa Marta, Bolívar renonce et s'embarque le pour la Jamaïque, tandis que le reste de son armée se défend du siège de Morillo, qui commence le et initie la "Reconquista".

En 1813, la situation des armées napoléoniennes en Europe est devenue intenable. Les guérillas espagnoles et portugaises, soutenues par l'Angleterre, se sont révélées indomptables tandis que la Grande Armée, parvenue jusqu'à Moscou, a été anéantie en 1812 au cours de la désastreuse retraite de Russie. En quelques semaines, de mai à juillet 1813, Joseph Bonaparte et l’armée française reculent jusqu’aux Pyrénées. Napoléon comprend sa défaite et accepte, par le traité de Valençay, le retour de l’ancien roi d’Espagne, Ferdinand VII, dans son royaume. Début 1814, la Catalogne est reconquise par les Espagnols. La guerre d’Espagne s’achève et la campagne de France qui suit mène à la chute de l'empereur français et son exil à l'île d'Elbe.

Sitôt de retour au pouvoir, Ferdinand VII entreprend de reconquérir les colonies espagnoles qui ont fait sécession. En 1815, l'Espagne envoie le plus grand corps expéditionnaire jamais envoyé à l'époque aux Amériques. Le colonel Pablo Morillo, un vétéran de la lutte espagnole contre les Français, est choisi pour la commander. L'ensemble des forces équivaut environ à et 60 bateaux.

Le siège de Carthagène des Indes initie la "Reconquista" du territoire néo-grenadin. Celle-ci est menée sur 3 fronts : Morillo depuis Carthagène, Sebastián de la Calzada depuis le Venezuela, Juan de Sámano depuis Pasto. Elle est achevée dès juin 1816 avec la défaite des patriotes lors de la bataille de la Cuchilla del Tambo.

Commence alors une campagne de répression orchestrée par Juan de Sámano (futur vice-roi de Nouvelle-Grenade) durant laquelle de nombreux patriotes sont exécutés pour trahison parmi lesquels Camilo Torres, Jorge Tadeo Lozano, Francisco José de Caldas, Manuel Rodríguez Torices, Manuel de Bernardo Álvarez, José María Carbonell, Antonio Villavicencio, Policarpa Salavarrieta, Custodio García Rovira et Joaquín Camacho. D'autres, comme Francisco de Paula Santander se réfugient dans les plaines orientales d'où ils mènent des actions de guérilla et de renseignement.

Outre cette répression sanglante qui vise à décapiter la classe dirigeante locale, les exactions de l'armée de « pacification », qui pille et tue sans contrôle, se comportant comme en terre ennemie, exaspèrent jusqu'aux "hacenderos" les plus royalistes. En moins de trois ans, loin de ramener la population néo-grenadine à des sentiments royalistes, les Espagnols creusent au contraire un fossé infranchissable de haine et d'incompréhension. Trop faibles pour expulser eux-mêmes les Espagnols, les néo-grenadins n'attendent donc plus qu'un libérateur.

C'est dans ce contexte que Simón Bolívar, de retour au Venezuela depuis la réussite de l'expédition de los Cayos à la fin de l'année 1816 et après trois ans de lutte acharnée contre Morillo et ses lieutenants, surgit du Venezuela en mai 1819 et vient porter la guerre en Nouvelle-Grenade.
Le , sur l'île de Margarita, l'autorité de Simón Bolívar sur l'ensemble de l'armée patriote a été confirmée entre autres par les chefs patriotes Santiago Mariño, Juan Bautista Arismendi, Manuel Piar, Gregor McGregor, Francisco Esteban Gómez, Manuel Valdés, Pedro María Freites et Carlos Soublette. La réussite de l'expédition de los Cayos, en décembre 1816, marque le retour de Bolívar de son exil en Jamaïque puis en Haïti. Débarqués dans l'est du Venezuela, les patriotes tentent immédiatement de percer vers l'ouest mais sont repoussés. Ils changent alors de stratégie et s'emparent de la Guyane, tandis que les royalistes commandés par Pablo Morillo tentent vainement de reconquérir l'île de Margarita.

Les patriotes s'assurent ainsi le contrôle d'une région riche en ressources naturelles et en voies de communication. Grâce aux pierres précieuses notamment, et à l'ouverture du territoire guyanais sur la mer des Caraïbes, les patriotes peuvent se procurer de l'armement (et notamment le renfort de la Légion britannique) et rétablir le contact avec l'Apure, dont José Antonio Páez contrôle les "Llaneros". Depuis la Guyane, Bolívar lance une campagne pour prendre Caracas, mais malgré d'importantes victoires il est contraint de se retirer, et est même poursuivi dans les llanos au cours de la campagne d'Apure.

Le a lieu le Congrès d'Angostura, à Angostura (aujourd'hui Ciudad Bolívar, dans l'est du Venezuela), inauguré par Simón Bolívar. Vingt-six délégués sont présents représentant le Venezuela et la Nouvelle-Grenade (aujourd'hui la Colombie). Y est projetée la création d'un vaste État indépendant sur le territoire de ce qui est encore la Vice-royauté de Nouvelle-Grenade et la Capitainerie générale du Venezuela.

Peu après, Pablo Morillo fait retraite dans ses quartiers d'hiver de Calabozo après la campagne d'Apure, pensant que le mauvais temps empêchera les patriotes de prendre une quelconque initiative. Bolívar décide alors qu'il est temps de libérer la Nouvelle-Grenade. Effectuée en plein hiver, la campagne sera très éprouvante pour les hommes.

À la tête de , il quitte Mantecal le 26 mai, franchit le río Arauca le 4 juin au niveau de Guasdualito et arrive le 11 juin à Tame où il fait la jonction avec l'armée du général Francisco de Paula Santander. Au moment de leur rencontre, les armées patriotes comptent un effectif de près de .

Afin de bénéficier de l'effet de surprise, Bolívar décide de traverser la cordillère Orientale par le páramo de Pisba, une route inhospitalière mais non surveillée par les Espagnols. Une première bataille a lieu à Paya, où le 30 juin l'avant-garde mené par Santander met en fuite les de la garnison royaliste qui se réfugient à Labranzagrande. La traversée du páramo de Pisba se révèle extrêmement difficile en raison du froid et du manque d'approvisionnement mais le 6 juillet l'armée de Bolívar arrive à Socha où elle s'accorde quatre jours de repos.

Le 11 juillet, José María Barreiro, alors en poste à Sogamoso et informé de la présence des insurgés, se porte à leur rencontre. La bataille de Gámeza, sur les rives du río Sogamoso, se solde par un résultat mitigé, les deux parties s'attribuant la victoire. Les patriotes ne parviennent pas à prendre le pont de Gámeza, mais Barreiro ne peut pas empêcher l'invasion de Tunja, porte de l'altiplano cundiboyacense. Bolívar avance en direction du marais de Vargas pour surprendre l'arrière-garde royaliste, ce qui donne lieu à l'affrontement le plus sanglant de la campagne libératrice lors de la bataille du Pantano de Vargas, près de Paipa.

Le jour de la bataille, le 25 juillet, Bolívar dispose d'environ . Les troupes patriotes attaquent les Espagnols de front, mais ceux-ci ont l'avantage du terrain et au moins , ce qui fait pencher la bataille en leur faveur. Les Espagnols sont cependant totalement désorganisés par la charge des lanciers du colonel Juan José Rondón tandis que l'infanterie gagne du terrain sur les royalistes, les forçant à battre en retraite. Le colonel James Rooke, commandant la Légion britannique, est blessé durant la bataille et meurt quelques jours plus tard.

Les deux armées, en route pour Bogota, très faiblement défendue, se rencontrent de nouveau le 7 août à Tunja, alors que l'armée royaliste traverse le pont de Boyacá. L'arrière-garde royaliste est toujours derrière, aussi le général José Antonio Anzoátegui ordonne-t-il de bloquer le passage entre les deux segments de l'armée adverse. L'arrière-garde espagnole, largement dépassée en nombre, bat en retraite. Simon Bolivar ordonne alors une attaque de flanc sur l'arrière-garde ennemie avec deux bataillons attaquant par la droite et la Légion de volontaires britanniques par la gauche. Submergés, les Espagnols battent en retraite sans direction précise et Bolivar donne l'ordre à ses lanciers d'attaquer le centre de l'infanterie royaliste, tandis qu'un escadron de cavalerie espagnol fuit la bataille. Malgré une dernière résistance et exposé à un feu nourri, le colonel Barreiro, qui commande l'arrière-garde royaliste, offre alors sa reddition. Environ prisonniers sont faits à l'issue de cette bataille qui ouvre la route de Bogota aux patriotes et assure la libération du pays.

Lorsqu'il apprend la nouvelle de la défaite de ses troupes, le vice-roi de Nouvelle-Grenade Juan de Sámano fuit Bogota et parvient à s'échapper par Carthagène des Indes. Bolívar arrive à Santafe de Bogota où il entre sans résistance le , mettant fin à la campagne libératrice de la Nouvelle-Grenade.

Avec la prise de la capitale, Bogota, et la fuite du vice-roi, la Nouvelle-Grenade est virtuellement perdue pour l'Espagne. Toutefois, les campagnes indépendantistes se poursuivent. Le sud du pays (San Juan de Pasto, Popayán) demeure aux mains des royalistes, ainsi que les ports de la mer des Caraïbes (Carthagène des Indes, Barranquilla, Santa Marta).

Bolívar charge le général vénézuélien Mariano Montilla d'attaquer les royalistes qui occupent encore les ports de la mer des Caraïbes. À partir du se déroule une campagne fluviale et navale qui libère un à un les ports caribéens et se termine par l'entrée des troupes indépendantistes à Carthagène le .

Dans le même temps, Bolívar envoie Antonio José de Sucre en mai 1821 entamer une campagne au sud pour venir en aide à la province libre de Guayaquil et libérer l'Audiencia de Quito.

De son côté, afin d'empêcher définitivement tout nouveau débarquement de troupes espagnoles sur les côtes de la mer des Caraïbes, Bolívar porte de nouveau la guerre au Venezuela dont l'ouest et le nord du pays sont toujours contrôlés par les royalistes et ce qui reste du corps expéditionnaire espagnol de Pablo Morillo. Après un armistice de six mois, la campagne débute le par la bataille de Carabobo qui se solde par une importante victoire de Bolivar sur le maréchal Miguel de la Torre, le remplaçant de Morillo, démissionnaire en décembre 1820, à la tête des troupes espagnoles.

Bolívar rejoint Sucre à Guayaquil par la terre, libérant au passage la ville de Pasto, le , lors de la bataille de Bomboná, désastre tactique pour les deux camps en présence, qui offre pourtant un avantage stratégique aux forces républicaines qui parviennent bientôt au contrôle total de l'actuel territoire colombien. La région connaît par la suite des soulèvements royalistes qui seront mâtés par les patriotes, amenant à la conclusion de ce qui sera appelé la campagne de Pasto.

Aucun renfort ne viendra d'Espagne soutenir les royalistes car à partir du , les militaires qui devaient être embarqués pour l'Amérique dans le port de Cadix se sont révoltés et ont contraint le roi Ferdinand VII à remettre en vigueur la Constitution espagnole de 1812. La France de Louis XVIII, qui intervient militairement avec l'autorisation des puissances de la Sainte-Alliance pour restaurer la monarchie absolue, ne reprend le contrôle de la situation que le après la bataille du Trocadéro. La totalité du territoire de l'ancienne Vice-royauté de Nouvelle-Grenade est alors entre les mains des républicains et la répression qui suit le retour de Ferdinand VII fait passer le problème des colonies américaines au second plan.

Sucre et Bolívar ont dès lors les coudées franches pour lancer une dernière campagne visant à libérer définitivement la vice-royauté du Pérou et du Haut-Pérou, dernier bastion espagnol en Amérique du Sud.

Dès février 1819, lors du Congrès d'Angostura, le sort des territoires libérés a été décidé. Selon le souhait de Bolívar exprimé dans sa "Lettre de Jamaïque", ceux-ci sont amenés à se regrouper au sein d'un vaste État, la République de Colombie, dont les frontières reposeraient sur le principe de l"'Uti possidetis juris" et le nom serait un hommage à Christophe Colomb.

À partir du et jusqu'au 3 octobre de la même année se réunit le Congrès de Cúcuta, assemblée constituante destinée à donner vie à ce projet. Initié par Antonio Nariño, le Congrès de Cúcuta voit la participation de Simón Bolívar, de Francisco de Paula Santander et d'autres importants personnages de l'indépendance. C'est dans le temple historique de Cúcuta qu'est adoptée la constitution de Cúcuta, acte de naissance de la Grande Colombie (alors simplement appelée « République de Colombie ») constituée de la Nouvelle-Grenade et du Venezuela. Bolívar en est désigné président et Santander vice-président.

Le la province de Panama proclame son indépendance de l'Espagne et décide de rejoindre la Grande Colombie. Elle est imitée le de la même année par la province de Veragua, qui correspond alors à la moitié occidentale de l'actuel Panama. Le , la bataille de Pichincha achève la libération de la Présidence de Quito et après la Rencontre de Guayaquil, le , celle-ci rejoint à son tour la République. Après la bataille du lac Maracaibo, le et la prise du fort de Puerto Cabello le 8 novembre de la même année par le général vénézuélien José Antonio Páez, le territoire vénézuélien (et donc celui de la Grande Colombie) est totalement débarrassé de la présence espagnole.

Le pays est "de facto" dirigé par le vice-président Francisco de Paula Santander. En effet, Bolívar continue la lutte contre l'Espagne au Pérou et en Bolivie continuant l'œuvre de l'autre héros de l'indépendance de l'Amérique du Sud espagnole, l'Argentin José de San Martín qui a proclamé l'indépendance du Pérou le . L'armée royaliste résiste jusqu'à sa défaite lors de la bataille d'Ayacucho, le , après quoi Bolívar préside le nouvel État péruvien.

Durant l'absence de Bolívar, des tensions apparaissent au sein de la Grande Colombie, immense territoire regroupant des régions fort disparates. Mises de côté lors de la lutte contre les royalistes, les divergences d'ordre idéologique qui étaient apparues lors des premières indépendances colombiennes renaissent. Les partisans de Santander plaident pour un État plus fédéral et laïc tandis que les partisans de Bolívar soutiennent l'idée initiale de Bolívar d'un état centralisé et catholique. En plus de ces désaccords, des velléités d'indépendance se font sentir, notamment au Venezuela où la révolution séparatiste, appelée "La Cosiata" et dirigée par le général José Antonio Páez, pousse les municipalités de Caracas et Valencia à ignorer l'autorité du gouvernement central et demande une réforme de la constitution de 1821.

Le , Bolívar quitte le Pérou (où il ne reviendra plus) pour la Colombie et y trouve donc une situation explosive. Un premier congrès est organisé en 1827 afin de réfléchir au futur de la constitution. Considérant qu'elle est la cause des maux de la République, celui-ci décide de convoquer une convention de tous les représentants de toutes les provinces du pays pour le dans la ville d'Ocaña. Mais la convention d'Ocaña est un échec, n'aboutissant à aucun accord. Aussi, le , Simón Bolívar adopte le décret organique qu'il a appelé « loi fondamentale » et par lequel il abolit la Constitution de Cúcuta et assume la dictature.

Face à l'impasse institutionnelle où se trouve la Grande Colombie, cette décision est plutôt bien accueillie au début, mais le gouvernement de Bolívar depuis son retour s'avère n'être qu'une suite d'improvisations qui aboutissent à rendre le "Libertador" encore plus impopulaire que Santander. Le , une tentative de coup d'État manquée aboutit à l'exécution de l'amiral Padilla et l'exil de Santander qui part pour l'Europe.

Ajoutant encore un peu plus d'instabilité, du au , la Grande Colombie est en guerre avec le Pérou, celui-ci revendiquant des territoires au sud. L'affrontement se termine sur un "statu quo ante bellum".

Le , le district du Venezuela fait officiellement sécession. Le , Bolívar convoque le Congrès Admirable afin de trouver une solution à la crise institutionnelle, mais celui-ci ne peut éviter la sécession du Venezuela. La santé de Bolívar, qui souffre de tuberculose, se détériore rapidement et le il donne sa démission. Domingo Caicedo devient président par intérim.

Le , le district de Quito déclare à son tour son indépendance et devient l'Équateur, avec à sa tête le général vénézuélien Juan José Flores.

Le , Antonio José de Sucre, que Bolívar considérait comme son successeur spirituel, est assassiné.

Une nouvelle constitution est promulguée au Venezuela le sous l'impulsion du général Paez qui devient le le premier président du Venezuela, nouveau pays dont le territoire est défini comme celui que couvrait en 1810 (avant toutes modifications) la Capitainerie générale du Venezuela.

Le , Bolívar s'éteint dans la quinta de San Pedro Alejandrino, à Santa Marta.

Ce qui reste de la Grande Colombie, correspondant au district de Nouvelle-Grenade (regroupant les actuels pays de Colombie, du Panama ainsi que la côte des Mosquitos dans l'actuel Nicaragua) se regroupe le lors de la convention d'Apulo sous la vice-présidence provisoire de Domingo Caicedo et devient le une république appelée République de Nouvelle-Grenade ().

Dès 1830, le nouveau pays est en butte aux prétentions de son voisin du sud, la nouvelle république d'Équateur, qui considère que les provinces qui appartenaient autrefois à la Real audiencia de Quito (Pasto, Popayán et Buenaventura) sont sous sa juridiction. La Nouvelle-Grenade, pour sa part, s'en tient au redécoupage de la Grande Colombie effectué en 1824 et considère ces provinces comme siennes car faisant partie de l'ancien District de Nouvelle-Grenade. La crise diplomatique débouche sur un affrontement armé entre le 7 février et le qui voit la victoire de la Nouvelle-Grenade. Malgré la signature d'un traité, les tensions diplomatiques entre les deux pays continueront jusqu'à la signature en 1916 du traité Muñoz Vernaza-Suárez, qui fixe définitivement la frontière commune.

Pendant ce temps, le la convention Grenadine fait officiellement de la Nouvelle-Grenade une république appelée République de Nouvelle-Grenade. Une nouvelle constitution est adoptée le qui établit un régime présidentiel et le général Francisco de Paula Santander, de retour d'exil, est élu président par le Congrès à titre provisoire. Santander est réélu en 1833 pour quatre ans, jusqu'au , date à laquelle son poulain le général José María Obando est battu par José Ignacio de Márquez.

La décision du Congrès de supprimer les couvents mineurs de la région de Pasto provoque le le soulèvement de la population très catholique de la région, avec le soutien des fédéralistes libéraux auxquels il sert de prétexte et du général Juan José Flores, dirigeant de l'Équateur voisin. C'est le début de la Guerre des Suprêmes. Le général Pedro Alcántara Herrán est nommé pour mater la rébellion et le à Buesaco il met en déroute la force principale des insurgés de Pasto. La réduction des dernières poches de résistance conduit à la capture de José Erazo. Ce dernier accuse le général José María Obando, probable candidat du parti d'opposition aux prochaines élections présidentielles, d'être impliqué dans l'assassinat d'Antonio José de Sucre en 1830. Obando est forcé de quitter Bogota, se dirige vers Pasto et rejoint la rébellion. La mort de Francisco de Paula Santander en mai 1840 en fait le chef de l'opposition. Il sort de Pasto et démarre une insurrection en juillet 1840. Celle-ci est matée par le gouvernement central grâce à l'aide du président équatorien Juan José Flores.

Cette intervention extérieure provoque un soulèvement général. Les chefs rebelles prononcent la sécession de leurs provinces transformées en États souverains, se donnent le titre de « chefs suprêmes » (en espagnol : "jefes supremos", d'où le nom de ce conflit), et déclarent qu'ils ne réintégreront la Nouvelle-Grenade que lorsque celle-ci sera devenue une fédération. Toutefois les insurgés libéraux ne peuvent parvenir à s'unir politiquement et militairement ce qui conduit à la déroute de José María Obando, leur unique leader ayant assez de prestige pour briguer la présidence. Ils ressortent donc de ce conflit passablement affaiblis. Le président José Ignacio de Márquez termine son mandat de manière énergique grâce à cette guerre.

Les deux généraux ayant maté la rébellion, Pedro Alcántara Herrán (chef de l'Armée) et Tomás Cipriano de Mosquera (secrétaire à la Guerre), en retirent un grand prestige et une grande influence, ce qui leur permettra d'occuper la présidence respectivement entre 1841 et 1845 et entre 1845 et 1849. Les divergences d'opinions mises en exergue par la guerre entre les bolivaristes et les santandéristes se traduisent par la constitution des deux partis qui régenteront à tour de rôle la vie politique colombienne pendant plus d'un siècle : les santandéristes fondent le parti libéral en 1848 tandis que les bolivaristes se regroupent au sein du parti conservateur en 1849.

En réponse à ce conflit, une nouvelle constitution est adoptée en 1843, faisant de la République un régime autoritaire apte à garantir l'ordre.

Le , le libéral José Hilario López arrive à la présidence. Les libéraux, après leur défaite durant la guerre des Suprêmes, ont été amnistiés par Mosquera et ont retrouvé leurs forces, poussés par les révolutions de 1848 en Europe qui reprennent leurs idées et leur donnent l'ascendant sur l'opposition conservatrice.

De vastes réformes sont engagées, notamment contre la prédominance de l'Église. Les Jésuites, revenus en 1843, sont expulsés de nouveau par le décret du . La constitution est amendée en 1851 et la plupart des réformes réclamées par l'opinion publique sont effectuées : abolition de la peine de mort pour les délits politiques, institution du jury, liberté de la presse, liberté de la navigation des fleuves de l'intérieur et des frontières, abolition de certains impôts (notamment la dîme). Cela ne va pas sans susciter de nombreuses réactions des milieux conservateurs.
Le le gouvernement décide de l'abolition de l'esclavage. Les grand propriétaires terriens et les esclavagistes se révoltent alors, soutenus par les conservateurs. Le , les conservateurs sont finalement vaincus. Les libéraux au pouvoir sortent renforcés politiquement de ces affrontements et le train de réformes engagé peut continuer, notamment par l'adoption d'une nouvelle constitution en 1853.

En 1854, une courte guerre civile éclate à la suite d'un coup d'État du général José María Melo. Les forces combinées de Pedro Alcántara Herrán, Tomás Cipriano de Mosquera et José Hilario López parviennent à vaincre les forces de Melo à Bogota le . L'acte de reddition est signé dans l'actuel parc Santander.

La structure centralisée implantée en République de Nouvelle-Grenade à la suite de l'adoption de la constitution de 1843 est rapidement secouée par les visées séparatistes de certaines régions du pays, en particulier celles qui sont loin de la capitale comme la province de Panama. En 1856, les différents gouvernements, cédant aux fortes tendances régionalistes existantes, ont divisé la République de Nouvelle-Grenade en 36 provinces, contre 16 en 1832. La réforme constitutionnelle de 1853 a introduit le fédéralisme dans le pays et le le premier état fédéral est créé : Panama. Suivent dans cette voie les États d'Antioquia le et Santander le . Afin d'éviter l'éclatement du pays, le Congrès adopte la loi du qui crée les États de Bolívar, Boyacá, Cauca, Cundinamarca et Magdalena (l'État de Tolima fut créé le par la sécession de la partie occidentale de l'État de Cundinamarca).

En 1858, un nouveau changement constitutionnel transforme la République de Nouvelle-Grenade en un État plus décentralisé nomme Confédération grenadine, amorçant là la période de fédéralisme qu'a connu le pays entre 1858 et 1886.

En 1857, les conservateurs au pouvoir à travers le président Mariano Ospina Rodríguez sont forcés de reconnaître la nouvelle organisation territoriale du pays. L'année suivante est instituée une assemblée constituante à majorité conservatrice qui rédige une nouvelle constitution en adéquation avec la nouvelle organisation. Le pays est renommé en Confédération grenadine (), le poste de vice-président est supprimé et le suffrage universel direct est adopté tandis que le président est élu pour 4 ans par le Congrès. Cette nouvelle organisation affaiblit sensiblement le pouvoir central et n'empêche pas les conflits entre les États.

Malgré cette avancée significative vers le fédéralisme prôné par les libéraux, l'intervention du gouvernement central conservateur dans les domaines de compétence des États provoque de nombreuses querelles avec les libéraux radicaux. Ceux-ci estiment que les États manquent encore d'autonomie et souhaitent l'instauration d'un État fédéral laissant un grand pouvoir aux États fédérés ainsi qu'une mise à l'écart de l'Église dans les affaires de l'État.

La guerre civile colombienne de 1860-1862 est la conséquence directe de cette opposition idéologique entre les conservateurs et les libéraux. En 1861, le général Tomás Cipriano de Mosquera (ancien président conservateur de la République de Nouvelle-Grenade entre 1845 et 1849 et devenu chef de file des libéraux) déclare la sécession de l'État du Cauca, le plus vaste des États fédérés, et la guerre au gouvernement de la Confédération grenadine afin d'augmenter le pouvoir du Cauca au sein de la confédération. Le , Mosquera prend Bogota et se déclare président provisoire.

L'un de ses premiers actes est de renommer le pays en États-Unis de Nouvelle-Grenade (), nom abandonné en novembre de la même année pour celui d'États-Unis de Colombie ().

À partir du se réunit la convention de Rionegro. Il en résulte une nouvelle constitution qui entérine le changement de nom du pays et redéfinit la répartition des pouvoirs entre le gouvernement central et les États fédérés au profit de ces derniers. La diminution du pouvoir central entraînera de nombreux heurts entre les États fédérés, certains dégénérant en guerre civile (notamment en 1876-1877).

Le , le général Mosquera laisse la place de président à Manuel Murillo Toro, libéral, ancien ministre du président José Hilario López. Son mandat est mouvementé. Le général Mosquera reste une menace, les finances du pays sont basses et la lutte contre l'Église est vive. Le , Murillo fait voter une loi bannissant les ecclésiastiques ne jurant pas fidélité à la constitution et ne soumettant pas les autres venus de l'extérieur à l'approbation du gouvernement central. L'application de cette loi est adoucie et sont autorisés à rentrer l'archevêque de Bogota et l'évêque d'Antioquia. En Antioquia, les libéraux avaient été renversés par les conservateurs et militaient pour ce retour. Dans l'État de Panama, le gouverneur, le général Santa Colonna est très hostile aux étrangers et s'en prend aux Espagnols, au consul de France, à celui des États-Unis, ainsi qu'au président Murillo. Il est déposé en mars 1865 par une révolte interne. Le président de l'État de Magdalena est déposé en juin de la même année, celui de l'État de Bolivar en novembre.

En 1865 également, durant l'absence du général Mosquera, parti négocier avec la France et l'Angleterre la garantie de la souveraineté colombienne sur l'isthme de Panama, les conservateurs tentent de prendre le contrôle de l'État du Cauca, fief du général. Le général Joaquin Cordova sort de l'État d'Antioquia et entre à Cartago (dans l'actuel département de Valle del Cauca). Des guérillas s'organisent dans les États de Tolima et Cundinamarca. Le pouvoir central déclare l'état de guerre et les insurgés sont dispersés. Le général Cordova est battu les 23 et 26 octobre 1865.

Le , le général Mosquera est élu une nouvelle fois à la présidence. Il ne prend ses fonctions que le , l'intérim étant assuré par José María Rojas Garrido. Mosquera fait adopter un décret qui ordonne le licenciement des troupes entretenues par les gouverneurs. Le gouverneur et l'assemblée de l'État de Panama déclarent ce décret nul. Mosquera envoie 500 hommes en garnison dans l'État pour le faire appliquer. Son intervention dans les troubles qui secouent les États de Santander et Antioquia le font accuser d'agissements dictatoriaux. Le , Mosquera adresse sa démission à la cour suprême, qui la refuse. En 1867, le Congrès rend aux États le pouvoir de lever des troupes.

Sur le plan extérieur, Mosquera maintient la neutralité du pays dans la guerre hispano-sud-américaine, interdisant le transit des approvisionnements et munitions par l'isthme de Panama. Il déclare les ports colombiens ouverts aux belligérants. L'État de Panama s'arroge le droit de taxer les navires qui accostent au Panama, au mépris d'une loi de 1862 et du traité passé avec la compagnie des chemins de fer, ce qui provoque des protestations, notamment des États-Unis d'Amérique, et oblige le gouvernement fédéral à intervenir. En 1866, une loi est votée par le congrès réglant les conditions dans lesquelles un canal inter-océanique pourrait être concédé. L'année suivante, les heurts entre les puissances et les gouvernements locaux continuent.

En 1867, profitant d'une guerre civile dans l'État de Magdalena, Mosquera rétablit l'article 92 de la constitution qui donne au président des pouvoirs discrétionnaires en cas de troubles. Il fait arrêter l'ancien président Murillo et obtient des députés l'approbation de ses actes. Il envoie des troupes contre le président de l'État de Magdalena, le chassant de Santa Marta sans toutefois mettre fin à la guerre civile. Mis en accusation, il opte pour un coup d'État. Le , il prononce la dissolution du congrès et déclare l'état de guerre. Il adresse un appel au peuple et envoie un message aux présidents des États les assurant de son respect pour l'autonomie des États et de son désir de paix et accusant le congrès de trahison. Les présidents des États de Magdalena et Santander le déclarent déchu. Le général Santos Acosta, chef de l'armée et président de l'État de Boyacá, renverse le président. Il le fait prisonnier le et convoque le congrès. Mosquera, accusé de mesures anticonstitutionnelles, est condamné à quatre ans d'exil. Le général Santos Gutiérrez est rappelé d'Europe et assure l'intérim du pouvoir.

Le , Santos Gutiérrez est élu président. Il fait face à plusieurs insurrections, notamment dans l'État de Panama, et en vient à bout. Deux ans plus tard, Eustorgio Salgar lui succède. Son mandat est relativement calme, ce qui permet au pays diverses avancées. L'éducation est améliorée avec la création d'écoles normales. Un traité est établi avec les États-Unis au sujet de l'isthme de Panama et du chemin de fer qui le traverse depuis 1855. En 1872, Bogota devient officiellement la capitale fédérale. Les mandats suivants de Manuel Murillo Toro (1872-1874) et Santiago Pérez de Manosalbas (1874-1876) se passent dans la même ambiance politique relativement calme et profitable.

La guerre civile colombienne de 1876-1877 vient couper net cet élan. La querelle résulte du fait que des troubles violents dans l'État de Bolívar empêchent le déroulement de l'élection présidentielle. Le congrès élit donc Aquileo Parra. Les conservateurs, dirigeant les États d'Antioquia et de Tolima, refusent de le reconnaître et recourent à la force. La lutte menée par et est remportée par les libéraux grâce à une victoire décisive du général Trujillo. Aquileo Parra reste donc à la présidence jusqu'au terme de son mandat.

Le , le général Julián Trujillo Largacha, le vainqueur de la guerre civile, est élu à la présidence. Son mandat est difficile car les troubles avaient grandement affaibli l'autorité du pouvoir central et mis à mal les finances publiques.

Le , le Français Ferdinand de Lesseps commence les travaux du canal de Panama, encore partie intégrante de la Colombie.

Le , le docteur Rafael Núñez est porté à la présidence. Libéral, il a voyagé en Europe avec le général Mosquera, ce qui lui a permis de sensiblement modifier son point de vue. Convaincu que l'anarchie faisait obstacle au développement du pays, il en vint à être partisan d'un État central fort, ce qui le rapproche des conservateurs. Il restera jusqu'à sa mort en 1894 l'homme fort du pays et sera le moteur de la période appelée la "Regeneración" (1880-1900).

Le , le docteur Francisco Javier Zaldúa est élu président sans opposant. Il sert de doublure à Rafael Núñez, la constitution interdisant à celui-ci d'effectuer plus d'un mandat consécutif. Lorsqu'il meurt, il est suppléé par José Eusebio Otálora.

Rafael Núñez est réélu à la présidence le . En janvier 1885, sept États s'insurgent. Leurs forces occupent l'embouchure du río Magdalena et les ports de Barranquilla, Panama, Colón et Buenaventura. Carthagène des Indes reste fidèle au président. Núñez, avec l'appui des États-Unis d'Amérique, entre en campagne et rétablit l'ordre à la suite d'une bataille décisive à Calamar le .

Dès lors, Núñez (libéral) prend appui sur les conservateurs, fondant et présidant le parti national. Avec le soutien du congrès, il élabore une nouvelle réforme constitutionnelle. Un conseil national de dix-huit membres est élu et investi des pouvoirs constituants. Le , une nouvelle constitution est adoptée. Celle-ci marque un changement radical en abolissant presque tous les pouvoirs des États fédérés au profit du pouvoir central. Le centralisme succède au fédéralisme. Les États souverains deviennent des départements dont les dirigeants son nommés et révoqués par le président de la nouvelle République de Colombie.

Entre 1875 et 1880, le modèle libéral politico-économique colombien est en crise : il n'y a aucune infrastructure routière nationale, ce qui maintient une séparation entre les États et le manque d'échanges commerciaux entre eux, l'agriculture est en déclin, l'exportation est lente avec une prédominance pour l'or ou le café, ce dernier représentant 50 % des exportations nationales. Il n'y a aucun processus d'industrialisation. Les conflits incessants entre les États durant la période fédéraliste ont affaibli la nation colombienne et amené la création de nouveaux courants politiques qui, à la suite de la guerre civile de 1877, unissent leurs forces dans un mouvement préférant une centralisation de l'État et son renforcement.

Ce contexte pousse le général Trujillo, élu en 1878, à se réconcilier avec l'Église en permettant le retour d'exil des ecclésiastiques chassés par le Congrès en 1877. Sa politique a peu de succès mais prépare la voie au libéral Rafael Núñez qui propose une réforme totale de l'État permettant d'éliminer le fédéralisme et d'instaurer un État central fort et prêt à entreprendre un projet économique national avec le slogan « "Regeneración o Catástrofe" ». Avec l'appui de Trujillo mais une forte opposition de son propre parti, Núñez accède à la présidence centrale en 1880, mais comme son mandat n'est que de deux ans, le temps lui manque pour faire avancer son projet de réformes sociales et économiques. Toutefois, sentant le vent tourner, certains conservateurs commencent à se rapprocher de Núñez. Il est élu pour un second mandat en 1884, cette fois avec l'appui du parti conservateur. L'année suivante, les libéraux déclarent la guerre à laquelle le président est en mesure de faire face et qui le renforce suffisamment pour convoquer une assemblée constituante qui proclame la constitution de 1886, dont il est le principal inspirateur.

Celle-ci abolit le fédéralisme, redéfinit la conception de l'État comme entité administrative dans la politique sociale et économique, proclame sa division en trois pouvoirs démocratiques (exécutif, législatif et judiciaire) et porte le mandat présidentiel à quatre ans. Les relations avec l'Église catholique, mises à mal par la politique anticléricale des libéraux radicaux, sont renouées par la signature en 1887 d'un concordat avec le Saint-Siège qui rend à l'Église le contrôle de l'éducation et reconnait le catholicisme comme religion d'État. Cela ouvre une nouvelle ère politique en Colombie dite de "Regeneración" qui est poursuivie par le président Miguel Antonio Caro durant son mandat présidentiel de 1894 à 1898.

Outre Rafael Núñez, les leaders de la " sont notamment José María Campo Serrano, Eliseo Payán, Carlos Holguín, Miguel Antonio Caro et Manuel Antonio Sanclemente. Ils sont regroupés dans un nouveau parti politique, le Parti national, qui rassemble les libéraux indépendants (modérés) et les conservateurs nationalistes. Il gouverne la Colombie en s'alliant avec les conservateurs.

L'une des conséquences de la politique de " est d'écarter totalement le parti libéral du pouvoir. Les conservateurs, alliés aux libéraux indépendants qui sont peu puissants en dehors de Nuñez, sont les grands gagnants du changement de régime. La constitution de 1886, très autoritaire, et l'adoption de la loi 61 de 1888, dite "Ley de los Caballos", leur permet d'interdire les journaux libéraux et d'emprisonner leurs opposants. Les libéraux n'ont donc plus ni députés, ni gouverneurs, ni presse et leurs principaux leaders sont soit en prison soit en exil.

Si certains libéraux restent tétanisés par la défaite politique, d'autres sont prêts à en découdre avec l'énergie du désespoir. Ainsi, dans la nuit du , le directeur de la nouvelle police nationale colombienne, le commissaire français Jean Marie Marcelin Gilibert, déjoue un complot ourdi depuis son exil à Curaçao par le général libéral Avelino Rosas Córdoba qui projetait de faire arrêter le président Miguel Antonio Caro. Le , les libéraux se soulèvent mais sont vaincus par les partisans de Rafael Reyes. Le conflit s’étend alors à l'ensemble du pays. Mais à peine deux mois après avoir commencé, la guerre civile se termine par la défaite des forces libérales lors de la bataille d'El Enciso (le ) où le général Ruiz est mis en déroute après avoir perdu plus de mille hommes. Cette victoire achève de confirmer la prééminence des conservateurs au sommet de l'État colombien.

Le parti national finit par se diviser en une branche "historique" et une branche "nationaliste" et, à l'élection présidentielle de 1904, le parti conservateur présente son propre candidat, Rafael Reyes Prieto. Mais entre temps, le chaos s'est à nouveau abattu sur le pays : la guerre civile de 1895 n'a été pour les libéraux qu'un coup d'essai avant la guerre des Mille Jours, qui commence en 1899 et embrase le pays pendant près de trois ans à une échelle inédite jusque-là dans l'histoire pourtant tourmentée de la Colombie.

Le est inauguré en Colombie par l'une des plus sanglantes guerres civiles : la guerre des Mille Jours, qui dure de 1899 à 1902 et entraîne une nouvelle défaite pour le parti libéral. Les libéraux combattent le gouvernement conservateur du président Manuel Antonio Sanclemente qu'ils accusent d'être autoritaire, de les exclure politiquement et de manquer de conciliation. C'est également une réaction de la dissidence libérale à la constitution de 1886, qui a abrogé le fédéralisme, et à l'hégémonie conservatrice qui en résulte.

La rébellion libérale commence le avec l'attaque de la ville de Bucaramanga, ce qui provoque une réaction rapide du gouvernement qui dispose d'une armée mieux équipée et supérieure en nombre. Les libéraux ne disposent de forces régulières que dans les départements de Santander et Panama. Globalement, les libéraux ne parviennent pas à obtenir le contrôle de la situation, même si le gouvernement reçoit des coups durs.

Les conservateurs, désireux de remettre de l'ordre dans le pays, sont quant à eux divisés entre « historiques » et « nationalistes ». Les premiers obtiennent la démission du président Sanclemente pour raison de santé (il a alors ) et portent au pouvoir le vice-président José Manuel Marroquín.

Dans ce conflit, interviennent également le président du Venezuela Cipriano Castro, qui soutient les troupes libérales de Rafael Uribe Uribe au Santander, le président nicaraguayen José Santos Zelaya qui soutient la rébellion libérale dans le département de Panama, le président équatorien Eloy Alfaro qui soutient la rébellion du Cauca, et la menace constante de la marine américaine envoyée par le président Theodore Roosevelt pour protéger les intérêts futurs des États-Unis dans la construction du canal de Panama dont les Américains ont repris l'idée après l'échec de la tentative française de Ferdinand de Lesseps.

Les libéraux, malgré leurs appuis étrangers, sont incapables de rivaliser avec l'armée régulière et le gouvernement. Ils sont réduits à mener une série de combats régionaux et locaux et de guérillas qui dévastent le pays et font environ , soit 3,5 % de la population du pays, une estimation toujours en discussion parmi les historiens.

Les États-Unis, dont la marine est présente dans la zone pour préserver leurs intérêts dans le futur canal interocéanique, parlemente beaucoup avec les différentes factions et le , après de conflit, est signé le traité de paix définitif à bord du navire américain USS "Wisconsin". Par ce traité, les libéraux acceptent de renoncer à la lutte armée. En échange de quoi, ils obtiennent une amnistie et la possibilité de faire paraître à nouveau leurs journaux. Néanmoins, ils demeurent exclus de la politique nationale, qui reste monopolisée par le parti conservateur.

Si personne n'est en mesure de comptabiliser le nombre définitif de morts dans les affrontements armés, les historiens s'accordent sur leur férocité et leurs conséquences désastreuses au niveau national : des destructions massives, des expropriations, des enrôlements forcés, notamment d'enfants, une inflation désastreuse et la ruine du commerce extérieur. Mais l'une des principales conséquences est la sécession du Panama en novembre 1903.

La Colombie sort de la guerre des Mille Jours passablement affaiblie. Après un siècle de guerres civiles successives, ses infrastructures sont pauvres, en particulier les transports. Ses provinces sont isolées les unes des autres, l'isthme de Panama plus que toute autre puisqu'aucune route ne le relie au reste de la Colombie et la totalité des communications se fait par mer. Lasses des querelles partisanes qui déchirent le pays et s'avèrent désastreuses pour le commerce international dont dépend l'économie panaméenne, notamment depuis la mise en service en 1855 de la ligne de chemin de fer qui traverse l'isthme, les élites panaméennes sont de plus excédées par la nouvelle politique douanière du gouvernement.

L'homme politique panaméen José Agustín Arango est l'un des premiers promoteurs d'un mouvement séparatiste. Il dirige une junte révolutionnaire qui par la suite entre en négociations avec les États-Unis. Appuyé par les dirigeants libéraux du Panama, il se rend aux États-Unis pour obtenir leur soutien au plan de conspiration.

Les dirigeants américains, et notamment le président Theodore Roosevelt, ont repris l'idée de canal interocéanique entreprise par le français Ferdinand de Lesseps et abandonnée en 1889 à la suite de la faillite de la Compagnie universelle du canal interocéanique de Panama. Contrôlant déjà le chemin de fer du Panama à travers la "Panama Canal Railway Company", les Américains ont racheté ce qui restait de la compagnie française et, via le traité Hay-Pauncefote, se sont assurés la neutralité du Royaume-Uni en promettant d'internationaliser le futur canal.

En janvier 1903, la guerre des Mille Jours terminée, le gouvernement Marroquín et le gouvernement américain signent le traité Herrán-Hay qui prévoit la concession du canal et d'une bande de terrain de de chaque côté en échange d'une indemnité de de dollars de l'époque, mais dans un sursaut nationaliste, le Congrès de la République de Colombie refuse de le ratifier. Dès lors, les États-Unis changent de politique et apportent leur soutien aux projets des indépendantistes panaméens.

La conspiration panaméenne parvient sous forme de rumeur au centre du pays et le bataillon de tirailleurs de Barranquilla est mobilisé dans l'isthme pour maintenir l'ordre dans le département. Rapidement, avec l'aide des États-Unis, le contingent de l'armée colombienne est neutralisé et le il est procédé à la déclaration de séparation qui proclame la naissance de la République du Panama, dont le premier président constitutionnel est le docteur Manuel Amador Guerrero.

La nouvelle n'est connue à Bogota que le 6 novembre par l'entremise de l'ambassadeur de Colombie à Quito. Le 13 novembre, le président américain Theodore Roosevelt s'empresse de reconnaître l'indépendance du nouveau pays et le 18 novembre, il signe avec le nouveau gouvernement le traité Hay-Bunau-Varilla pour la construction du canal qui est concédé aux États-Unis à perpétuité.

En 1921, après la mort de Roosevelt, la Colombie sera indemnisée pour la perte du Panama, pour un montant total de de l'époque.

Au sortir de la guerre des Mille Jours en 1904, la politique de " des années 1880-1890 n'a pas encore porté ses fruits et le pays est dans un état de fragilité extrême : l'insécurité est importante, l'économie est ruinée et les finances publiques sont dans un état lamentable, l'intégration des régions n'a fait que peu de progrès, même si une unification juridique et douanière a été effectuée. Cependant, les bases institutionnelles d'un régime stable sont établies, l'État a définitivement affirmé son autorité et le retour de la paix, bien que fragile, permet à la situation de s'améliorer considérablement et aux conservateurs, qui monopolisent le pouvoir pendant près de trente ans, de mener à bien de nombreuses réformes.

Une importante réforme territoriale a lieu entre 1905 et 1910, à la faveur de révisions constitutionnelles. Les huit départements colombiens, qui reprenaient les limites des anciens États souverains, sont complètement réorganisés :

Sur le plan économique, l'État tout juste restauré joue un rôle notable. Il encourage le développement des transports et protège l'économie nationale par des tarifs douaniers élevés (relevés brutalement de 70 % en 1907).

Après 1903, les travaux de construction de chemins de fer s'accélèrent. Le pays ne compte que de voies en 1906 mais ce chiffre passe à en 1922 et en 1934 (par la suite il ne dépassera pas ce chiffre). Destinées d'abord à transporter les marchandises vers l'extérieur en vue de leur exportation, les lignes ne sont pas reliées entre elles. Conscient de ce problème, le gouvernement promeut dans les années 1920 la construction d'un réseau articulé centré sur la capitale, Bogota. Les routes sont le point noir des transports colombiens, le réseau comptant officiellement en 1930 de chaussées pour automobiles et de chemins carrossables, utilisés par . En revanche, de par son relief tourmenté, la Colombie fait figure de pionnière dans le transport aérien. La première liaison aérienne commerciale du monde, entre la côte atlantique et Girardot, est mise en service en 1919 par la SCADTA (Société Colombo-Allemande de Transports Aériens), d'où les Allemands seront évincés au cours de la seconde Guerre mondiale pour donner naissance à la compagnie nationale, Avianca.

Grâce au télégraphe, au téléphone, à la TSF, à la radio, à plus de trente quotidiens, au développement des transports notamment aériens, la Colombie s'ouvre au monde et les investissements étrangers commencent à s'installer dans le pays.

À cette époque, la production et l'exportation de café explose. En 1920, avec 11,3 % de la production mondiale, la Colombie occupe le deuxième rang derrière le Brésil. La "United Fruit Company", qui a installé ses bananeraies dans la région de Santa Marta à partir de 1899, emploie en 1920 environ et représente 6 % des exportations. Quant à l'élevage, le cheptel double entre 1904 et 1930 et la Colombie exporte de la viande vers les Antilles et les États-Unis.

C'est également dans les années 1920 que commence l'exploitation des richesses pétrolières du pays. En 1922, la compagnie américaine "Standard Oil" ouvre la raffinerie de Barrancabermeja. En 1929, la Colombie exporte vingt millions de barils.

Enfin, en 1923 le système financier colombien est assaini. Une équipe d'économistes dirigée par le professeur Edwin Walter Kemmerer créé la banque centrale, la Surintendance bancaire (institution chargée de contrôler le système financier) et la "Contraloría General" (institution chargée de contrôler les dépenses de l'État).

Sur le plan démographique, le pays se transforme également. La population double entre 1880 et 1938, date à laquelle la Colombie compte , malgré une immigration extrêmement faible : moins de dix mille personnes durant toute la période. Alors qu'en 1905 seuls 10 % des Colombiens vivent en ville, ce chiffre passe à 31 % en 1938. L'alphabétisation progresse de 11,9 % en 1905 à 41,2 % en 1938.

Si le développement colombien est spectaculaire, il est à noter que c'est en grande partie parce que le pays part de très bas. Il s'accompagne en outre de déséquilibres importants, tant économiques que sociaux.

La réorganisation du système financier colombien et le versement de l'indemnité pour la perte de Panama par les États-Unis apportent dans les années 1920 un ballon d'oxygène bienvenu et provoque un afflux de capitaux nord-américains. Ainsi, environ de prêts sont consentis à la Colombie en dix ans, auxquels s'ajoutent cinquante millions d'investissements directs. Cet afflux de capitaux favorise le taux de croissance de l'économie colombienne qui passe à 5,2 % par an entre 1925 et 1929, mais se solde par un endettement massif (la dette extérieure du pays est multipliée par 8,5 entre 1923 et 1928) et une surchauffe de l'économie. Cette période d'euphorie sera par la suite connue sous le nom évocateur de .

Par ailleurs, ce développement nouveau provoque des inégalités importantes, sources de conflits sociaux souvent réprimés dans le sang. Les premières grèves notables éclatent en 1918-1919 dans les ports de la mer des Caraïbes, peu après la fin de la première Guerre mondiale. En 1919, année où le droit de grève est reconnu, quoique dans d'étroites limites, une grève des tailleurs de Bogota, qui protestent contre la décision de l'armée d'acheter ses uniformes à des compagnies étrangères, est durement réprimée avec un bilan de sept morts et quinze blessés. À cette époque, faire partie d'un syndicat est très dangereux. En 1929, seules sont reconnues mais ne jouissent d'aucune protection légale face à l'arbitraire des patrons.

Les conflits les plus durs ont lieu dans les enclaves des compagnies nord-américaines. La "Tropical Oil Company", ancêtre d’"Ecopetrol", doit ainsi faire face à deux grèves violentes et longues à Barrancabermeja en 1924 et 1927, qui se soldent par des licenciements massifs. Le a lieu le massacre des bananeraies, dans la ville de Ciénaga au nord de la Colombie, lorsqu'un régiment de l'armée colombienne ouvre le feu sur des travailleurs grévistes de la "United Fruit Company", faisant et . Ce fait divers inspirera l'écrivain Gabriel García Márquez pour un des épisodes de son chef-d'œuvre "Cent ans de solitude".

En 1904, Rafael Reyes est élu à la présidence. Contrairement à ses prédécesseurs, il est un pur conservateur et n'appartient pas au parti national, l'alliance contre nature des conservateurs et des libéraux modérés qui a soutenu la politique de "Regeneración" du président Núñez et de ses successeurs.

Toutefois, faisant preuve d'ouverture, Reyes appelle deux libéraux au gouvernement (sur un total de six ministres). Si la volonté du président de panser les plaies de la guerre des Mille Jours est probablement sincère, cette main tendue obéit aussi à des considérations purement politiciennes : élu de justesse face à un autre conservateur, Reyes a besoin de l'appui de certains libéraux pour se maintenir au pouvoir. Pour les conservateurs, cela fait de lui un traître, un nouveau Núñez qui risque de provoquer une nouvelle alternance politique, cette fois à leurs dépens.

Reyes s'occupe de relancer l'économie, dévastée par trois ans de guerre civile, mais rapidement l'action de son gouvernement se retrouve paralysée par les diverses oppositions. En décembre 1904, en violation de la constitution, Reyes suspend les activités du Congrès et en mars 1905 convoque une assemblée constituante dont il choisit les membres. Les libéraux l'appuient, voyant l'occasion de revenir au pouvoir.

En réalité, sans effectuer aucune réforme constitutionnelle, Reyes impose un régime semi-dictatorial, gouvernant avec l'appui de son assemblée de godillots, dont il prolonge le mandat jusqu'en 1910. Il supprime le poste de vice-président, trop dangereux comme l'a montré le coup d'État déguisé contre Sanclemente en 1900, et porte son propre mandat à dix ans. Il réduit drastiquement le budget du Congrès et met fin à l'inamovibilité des magistrats, tout en continuant une politique de réconciliation avec les libéraux en leur laissant des postes à tous les échelons du pouvoir. En 1906, un attentat manqué provoque une vague de répression. L'armée devient toujours plus puissante et sert loyalement les desseins du président.

Mais le népotisme du président finit par lui aliéner la plupart des notables. De plus en plus discrédité, isolé et impopulaire, Reyes commet en 1909 une erreur fatale en négociant avec les États-Unis un accord reconnaissant la perte du Panama et autorisant les navires américains à « se réfugier » dans les ports colombiens en cas de guerre. Désavoué par sa propre assemblée, Reyes préfère démissionner plutôt que de provoquer une nouvelle guerre civile.

En 1910, la coalition de libéraux et de conservateurs qui a déchu le dictateur, regroupée au sein d'un nouveau parti, le parti républicain, élit à la présidence le conservateur Carlos Eugenio Restrepo. La même année, la coalition décide de convoquer une assemblée constituante dans le but de réviser la constitution de 1886 afin d'éviter à la fois les dérives autoritaires d'un nouveau Reyes et les luttes de pouvoir au sommet de l'État dans lesquelles Sanclemente et Marroquín se sont illustrés. Ainsi, le mandat présidentiel est ramené à quatre ans et le président ne peut plus effectuer deux mandats successifs, le poste de vice-président, supprimé par Reyes, n'est pas rétabli et remplacé par un "designado", élu par les députés et les sénateurs. Le système de grands électeurs s'étant révélé trop propice aux excès et aux manipulations, le chef de l'État est élu au suffrage universel (masculin seulement). De plus, il ne peut plus nommer les magistrats de la Cour suprême sans l'approbation du Congrès, ni gouverner par décrets sans l'aval des députés. Enfin, il est inscrit dans la constitution le droit pour le Congrès de se réunir au moins une fois par an. La réforme constitutionnelle instaure également l'abolition définitive de la peine de mort en Colombie.

Le parti républicain se disloque rapidement, conservateurs et libéraux réintégrant leurs partis respectifs, et après avoir gagné les élections en 1914 le conservateur José Vicente Concha forme un gouvernement monopartisan. Concha et son successeur, Marco Fidel Suárez, maintiennent totalement les libéraux à l'écart du pouvoir, mais en 1922 le conservateur Pedro Nel Ospina n'est élu que grâce aux votes douteux des ouvriers face au libéral Benjamín Herrera. Celui-ci est arrivé en tête dans tous les départements sauf trois. Lors de l'élection suivante, écœurés par la manipulation, les libéraux ne présentent même pas de candidat face à Miguel Abadía Méndez, qui est donc élu sans opposant en 1926.

Les élections devenant sans enjeu, puisque les conservateurs semblent inamovibles, la participation aux scrutins diminue régulièrement. Avec la frustration grandissante des libéraux relégués au rang de figurants, la situation devient malsaine, la tension monte et la tentation de la violence est chaque jour plus grande. C'est à cette époque, alors que les inégalités sociales grandissantes dans la société colombienne provoquent des mouvements de protestation des travailleurs, que naissent les premiers partis à gauche du parti libéral. Un premier parti socialiste est créé en 1919, mais se rapproche très vite du parti libéral qui finit par l'absorber. Vers 1924, le marxisme fait son apparition. Un nouveau parti socialiste, le PSR, voit le jour en 1926. Il est reconnu par la troisième internationale en 1928, mais malgré un rôle notable dans les mouvements sociaux à la fin des années 1920 il s'efface progressivement au profit du parti communiste colombien.
En 1928, le massacre des bananeraies, perpétré par un régiment de l'armée colombienne qui ouvre le feu sur des travailleurs grévistes de la "United Fruit Company" près de Santa Marta provoque de vives protestations, où s'illustre un jeune orateur libéral, Jorge Eliécer Gaitán. En juin 1929, après des émeutes étudiantes qui font un mort, le maire de Bogota et trois ministres sont contraints à la démission pour fraude électorale. La situation devient si intenable que le parti conservateur se divise, et présente deux candidats à l'élection suivante. Tentant leur chance, les libéraux présentent Enrique Olaya Herrera, qui est élu en août 1930, mettant fin à l'hégémonie conservatrice.

En 1930, grâce à la division des conservateurs, les libéraux sont de retour au pouvoir en la personne d'Enrique Olaya Herrera. C'est la première fois dans l'histoire colombienne qu'une alternance politique se déroule presque sans violence.

Toutefois, le pays est dans une période de grave crise économique et sociale. Dès 1928, les investissements étrangers se sont arrêtés en raison de mesures restrictives prises par les États-Unis pour enrayer la spéculation. Avec la crise de 1929, les cours du café se sont effondrés, ainsi que ceux du pétrole et des bananes, des exportations vitales pour la Colombie. Les producteurs parviennent à réagir en augmentant les quantité produites, notamment pour le café ou l'or, et la baisse des importations venues des États-Unis ou d'Europe limite les effets de la baisse des exportations. Toutefois, les réserves de la banque centrale s'épuisent et le pays peine à rembourser la dette accumulée durant les années précédentes. Un contrôle des changes s'avère nécessaire, ainsi que l'abandon de l'étalon-or. Le peso est dévalué plusieurs fois tandis que l'inflation atteint près de 40 % au milieu des années 1930.

Le libéral très modéré Enrique Olaya Herrera gouverne à la tête d'un cabinet bipartite, ce qui a permis une transition politique sans violence mais l'empêche de prendre des mesures importantes ou d'effectuer de grandes réformes. La crise mondiale a cependant aussi des effets positifs sur l'économie colombienne : l'effacement des pays développés, occupés à se protéger de la crise puis à préparer la guerre, permet à certains secteurs ordinairement concurrencés par la production étrangère de se développer. La demande interne augmente et la production industrielle colombienne se développe. Après seulement deux années de récession, la croissance de l'industrie est en moyenne de 9,3 % par an entre 1932 et 1939. En 1932, le gouvernement colombien parvient à négocier un moratoire sur sa dette extérieure.

C'est dans ce contexte que le , le président péruvien Luis Miguel Sánchez déploie deux régiments de l'armée péruvienne à Leticia et Tarapacá, en territoire colombien, dans le but d'annexer le trapèze amazonien, ce qui déclenche une guerre entre les deux pays. Le président péruvien pense que la Colombie n'a aucune chance de se défendre car elle manque de routes et ne possède pas une marine digne de ce nom. De plus, la région amazonienne n'accueille aucune présence militaire. Mais en , la Colombie organise une réponse militaire conséquente à l'invasion péruvienne. Le premier combat aérien d'Amérique du Sud se déroule durant cette guerre entre les forces aériennes colombiennes et péruviennes.

La première attaque de la marine colombienne cible Tarapacá. La prise de la ville est une bataille sanglante. La veille, le , les forces aériennes péruviennes ont tenté de bombarder la flotte colombienne mais la plupart des bombes ont manqué leur cible. Le reste des forces péruviennes quitte la zone tandis que la flotte colombienne arrive le lendemain.

Le , après avoir passé en revue des troupes à l'hippodrome Santa Beatriz (aujourd'hui la place de la Révolution), le président péruvien Sánchez est abattu. plus tard son successeur, Oscar R. Benavides, rencontre le chef du parti libéral colombien, Alfonso López Pumarejo, pour conclure un accord et confier le sort de Leticia à une commission de la Société des Nations.
La Colombie et le Pérou se rencontrent à Rio de Janeiro, au Brésil, pour signer un traité de paix qui réaffirme le traité Salomón–Lozano définissant la frontière commune depuis 1922.

Alfonso López Pumarejo est élu président lors de l'élection de 1934 sans opposant. La domination des libéraux établie et le spectre de la crise s'éloignant, le président nouvellement élu peut lancer une série de réformes audacieuses au nom ronflant de « Révolution en marche ». Les deux réformes majeures, menées en 1936, sont une révision constitutionnelle et une réforme agraire. La première vise à garantir la liberté de culte et de conscience, la liberté d'enseignement et le droit de grève (sauf pour les fonctionnaires). De plus, elle dépouille le clergé de ses privilèges fiscaux et juridiques. La seconde est effectuée afin de mettre un terme à l'affrontement dans les campagnes entre les grands propriétaires terriens et les "aparceros", leurs ouvriers agricoles. En 1935, est également menée une réforme fiscale qui augmente l'impôt sur le revenu (créé en 1918) et le rend plus progressif. D'autre part, le gouvernement modifie sa politique sociale et se montre plus soucieux des travailleurs, s'opposant volontiers aux enclaves des compagnies nord-américains.

En menant une telle politique sociale, le parti libéral s'assure d'une base électorale solide dans les villes et s'attire la sympathie des classes laborieuses, des syndicats ouvriers (CTC) et du parti communiste colombien, fondé officiellement en 1930. En 1935, le mouvement UNIR du libéral dissident Jorge Eliécer Gaitán se rallie au parti au pouvoir. Cependant, cette politique n'est pas du goût de tous les libéraux et reçoit une franche hostilité de la part des conservateurs. Aussi, en décembre 1936, López Pumarejo annonce une pause et abandonne ses projets de législation sociale pour revenir à la politique plus classique de traitement des crises, la répression.

À cette époque, les conservateurs sont particulièrement frustrés mais n'ont pas l'intention de déclencher une nouvelle guerre civile qui signerait la mort de la constitution de 1886 qu'ils considèrent comme leur grande œuvre. Ils cherchent des modèles à suivre, en particulier en Europe, alors au bord de la Seconde Guerre mondiale. Mais si d'aucuns laissent paraître sous leur plume des propos antisémites ou des déclarations admiratives à l'égard de Mussolini ou Hitler, les principales sources d'inspiration sont les régimes cléricaux et réactionnaires mis en place par le général Franco en Espagne et par le dictateur Salazar au Portugal, qui cadrent mieux avec leurs idéaux. Un des conservateurs qui sort du lot en cette période de doute est Laureano Gómez, un modeste ingénieur originaire du Norte de Santander à la morale étroite, intransigeant et très réactionnaire. L'opposition de plus en plus farouche entre les libéraux et leurs alliés d'extrême gauche d'un côté et des conservateurs très réactionnaires de l'autre, occupant toute la sphère politique, fait que contrairement à d'autres pays d'Amérique du Sud durant la même période la Colombie ne connait pas de montée de l'extrême-droite, même si çà et là apparaissent de petits groupuscules fascistes dont le plus connu est l'ANP de Gilberto Alzate Avendaño.

En 1938, Eduardo Santos est élu à la présidence sans opposant, les conservateurs boycottant l'élection. Bien que la situation du pays soit délicate, il parvient à gouverner sans trop de problèmes. Il met fin aux tensions avec les États-Unis, que la rhétorique nationaliste et les prises de positions contre les compagnies américaines du président López Pumarejo avaient passablement agacés, et adhère au principe de « solidarité continentale » en vertu duquel toute agression contre un pays du Nouveau Monde constitue une attaque du continent entier. Les Allemands sont évincés de plusieurs sociétés qu'ils possédaient en Colombie, notamment les bières Bavaria et la compagnie aérienne SCADTA, qui devient Avianca. Après l'attaque de Pearl Harbor, en décembre 1941, la Colombie rompt ses relations diplomatiques avec les puissances de l'Axe, avant de leur déclarer la guerre le et de signer la Charte des Nations unies en 1945. Toutefois, sa participation militaire à la Seconde Guerre mondiale reste minime.

La Seconde Guerre mondiale affecte bien plus l'économie colombienne que ne l'avait fait la crise de 1929. La flotte marchande mondiale mobilisée pour le conflit et l'insécurité des eaux internationales font chuter brutalement le commerce extérieur et les exportations de café ou de bananes s'effondrent. La ' cesse sa production en Colombie en 1942 lorsqu'une nouvelle maladie, le sigatoka noir, décime ses bananeraies. Le secteur pétrolier, uniquement centré sur Barrancabermeja, stagne. De plus en plus, l'État démissionne de la gestion économique du pays, qu'il laisse aux ', les associations de producteurs.

En août 1942, Alfonso López Pumarejo est élu pour un deuxième mandat. L'espoir est grand pour les électeurs que le président reprennent la « Révolution en marche » là où il l'avait arrêtée. En 1945, un code du travail est adopté, qui limite la durée du travail, institue les congés payés et les retraites ouvrières et protège les syndicats. Mais l'État ne parvient pas à imposer cette législation. Pire, en 1946, sous la pression des ', le gouvernement revient sur la réforme agraire de 1936. Paralysé par les querelles de clans au sommet de l'État et atteint par les scandales touchant son entourage, López Pumarejo est contraint de se retirer dès juillet 1945 et de laisser un ', Alberto Lleras Camargo, finir son mandat.

L'échec de la deuxième « Révolution en marche » provoque une immense déception parmi les nombreuses victimes de la crise économique. Dépourvue d'encadrement structuré, puisque les partis de gauche et les syndicats ont été phagocytés par le parti libéral, cette importante masse trouve un porte-parole en la personne du leader libéral populiste Jorge Eliécer Gaitán qui, fort de ce soutien, se présente à l'élection présidentielle de mai 1946. Opposé au conservateur Mariano Ospina Pérez et au libéral Gabriel Turbay, Gaitán obtient 27,2 % des suffrages et termine à la troisième place, mais surtout il fait perdre le libéral Turbay et permet le retour au pouvoir des conservateurs en la personne de Mariano Ospina Pérez.

Dès la fin des élections, Gaitán lance sa campagne "" (en français : « À la reconquête du pouvoir ») pour les élections suivantes, qui doivent se tenir en 1950. Les résultats des élections législatives de mars 1947 le mettent en position de force au sein du parti libéral. En juin 1947, lors d'une séries de réunions publiques ayant pour sujet les élections municipales qui doivent se dérouler en octobre de la même année, le "leadership" de Gaitán au sein du libéralisme est ratifié. La majorité des libéraux nouvellement élus sénateurs et députés se concertent durant trois jours et élisent à l'unanimité Gaitán () du parti le 11 juin. Le , les membres libéraux du Congrès proclament Jorge Eliécer Gaitán comme étant leur candidat officiel pour les élections présidentielles de 1950.

Mais le , à 13 h 05, Jorge Eliécer Gaitán est assassiné à la sortie de son bureau. La mort violente de cet éminent dirigeant du parti libéral, alors considéré comme vainqueur probable des prochaines élections présidentielles, souvent taxé de populisme et dont la popularité effrayait autant les responsables du parti conservateur qu’une frange non marginale de sa propre faction, provoque des émeutes d’une rare violence dont l’histoire colombienne se souviendra sous le nom de "Bogotazo", prélude à une guerre civile appelée "" qui doit son nom à son caractère particulièrement violent.

Le , le leader libéral Jorge Eliécer Gaitán est assassiné par Juan Roa Sierra, qui a agi pour des motifs inconnus. L'enthousiasme populaire suscité par sa probable victoire aux élections présidentielles suivantes et l'espoir que représentait la révolution qu'il semblait vouloir mettre en œuvre pour changer la vie politique et économique colombienne sont à la mesure de la fureur incontrôlable que provoque son assassinat.

Aussitôt après le drame, la foule déchainée met à mort l'assassin puis envahit et saccage le Capitolio, où se tenait la conférence de l'Organisation des États américains. En l'absence de la police et de l'armée, les pillages se multiplient. Après s'être emparés d'une station de radio, des partisans de Gaitán appellent le président Mariano Ospina Pérez à démissionner. Ce dernier, son cabinet et les dirigeants libéraux ne parviennent pas à un accord sur les mesures à adopter et la situation ne cesse d'empirer. La violence s'étend alors à d'autres villes : Medellín, Ibagué et Barranquilla. Quand, après plusieurs jours de tueries, pillages et incendies, l'ordre est finalement rétabli par l'intervention de l'armée, le bilan de ces émeutes, appelées le "Bogotazo", s'établit à près de , des milliers de blessés et 136 édifices détruits, dont le palais historique de San Carlos, le palais de justice et le couvent dominicain.

La répression orchestrée par les conservateurs au pouvoir, réunis autour du président conservateur Laureano Gómez, élu en 1949 lors d'élections anticipées, se transforme progressivement en une véritable guerre civile opposant une droite catholique réactionnaire à une gauche libérale radicalisée par l’assassinat de son chef et l’ambiance d’intolérance politique du moment.

Ce conflit, connu sous le nom de "La Violencia", provoque la mort de près de colombiens sur une population estimée à 15 millions d’habitants (2 %). Il s’agit certainement là de l’un des plus violents conflits politiques de l’histoire du pays et d’une période excessivement traumatisante pour le peuple colombien.

La "Violencia" est à plus d’un titre une époque clé pour comprendre le développement du conflit actuel. Tout d’abord, elle provoque la renaissance de mouvements guérilleros de gauche, libéraux puis communistes. C’est de l’époque de la "Violencia" que date l’apparition des milices d’autodéfense paysanne modernes établies pour lutter contre les exactions des militaires et des groupes armés conservateurs, milices qui donneront postérieurement naissance, entre autres, aux Forces armées révolutionnaires de Colombie (FARC). Il s’agit en premier lieu de guérillas d’origine libérale dont certaines se transformeront en guérillas communistes, principalement dans les départements de Cundinamarca (Bogota) et de Tolima (Ibagué).

Le , cas unique dans l’histoire colombienne, le général Gustavo Rojas Pinilla renverse le président Laureano Gómez et prend le pouvoir par un coup d’État dans le but de faire cesser le bain de sang et de stabiliser une démocratie vacillante. Celui-ci est approuvé par une assemblée constituante de 61 délégués pour le reste de la durée du mandat présidentiel, c'est-à-dire jusqu'au .

À l'exception des partisans du président déchu, Laureano Gómez, la reprise en main du pouvoir par les militaires est bien accueillie par la classe politique. Le prestige de l'armée obtenu de sa participation à la guerre de Corée, la relative neutralité de Pinilla dans le conflit qui oppose libéraux et conservateurs, et une loi d’amnistie votée dès le permettent progressivement un retour à la normale sans que cela signifie pour autant l’arrêt total des combats.

Le , Rojas Pinilla sollicite de l'assemblée constituante, composée de , qu'elle confirme sa position à la tête du pays pour le mandat présidentiel suivant. Maintenu dans ses fonctions, Pinilla rompt avec le bipartisme qui l'a porté au pouvoir et crée ce qu'il nomme « la troisième force », qui propose une réorganisation du pays en s'appuyant sur les travailleurs, les classes moyennes et les militaires, soutenue par des principes catholiques issus de la doctrine sociale de l'Église et des idées bolivaristes. Le 25 août de la même année est approuvé un changement constitutionnel qui donne le droit de vote aux femmes. Le est annoncé officiellement la création du nouveau parti nommé "Movimiento de Acción Popular", auquel s'opposent activement les partis traditionnels.

En 1956, prenant conscience du danger de laisser Rojas Pinilla installer durablement une troisième force politique au sommet de l'État, les deux partis traditionnels acceptent de discuter et signent le 24 juillet le pacte de Benidorm dans le but de renverser le dictateur et reprendre le pouvoir. Le , Rojas Pinilla est forcé de démissionner et un gouvernement militaire provisoire dirigé par le général Gabriel París Gordillo est mis en place. En 1958, le pacte de Benidorm est soumis à un plébiscite et la population accepte l'institution du Front national, un accord de cogestion du pays entre les deux principaux partis, le parti conservateur et le parti libéral. Cet accord unique en son genre prévoit l'alternance au pouvoir entre un président libéral et un président conservateur, les ministères et les charges publiques locales se répartissant de façon égalitaire entre ces deux partis, changeant de main à chaque élection. Les partis tiers (entre autres le Parti communiste colombien, le MRL et l'ANAPO de Gustavo Rojas Pinilla fondé en 1961), ne peuvent pas présenter de candidats sous leurs propres couleurs aux élections, mais les candidats qui en sont issus ont la possibilité de se présenter sous l'étiquette de l'un des deux grands partis.

Entre 1958 et 1974 se succèdent à la présidence le libéral Alberto Lleras Camargo, le conservateur Guillermo León Valencia, le libéral Carlos Lleras Restrepo et le conservateur Misael Pastrana. Sur le plan international, déjà membre depuis 1948 de l'Organisation des États américains, la Colombie adhère à l'Association latino-américaine de libre-échange en 1960 et à la Communauté andine des Nations en 1969 via l'Accord de Carthagène.

Durant cette période d'importants investissements publics sont réalisés notamment dans le domaine de la santé, de l'éducation et des infrastructures publiques, renforçant l'unité du pays. L'État intervient de plus en plus dans l'économie, représentant jusqu'à 20 % du PIB, qui augmente en moyenne de 10,6 % par an entre 1946 et 1956, en partie imputable au haut niveau des cours du café. Différentes entités para-étatiques sont mises sur pied, dont la compagnie pétrolière nationale, Ecopetrol. Par la suite la conjoncture se retourne et la croissance économique stagne jusqu'à ce qu'un système de dévaluations graduelles du peso par rapport au dollar soit adopté en 1967, permettant à l'économie colombienne de retrouver de la compétitivité. Le PIB, sur la période 1968-1974, croît en moyenne de 6,4 % par an.

Toutefois, les inégalités sociales restent fortes et, bien que la période de guerre civile massive prenne fin, une grande partie des combattants de gauche refuse de déposer les armes. Les factions libérales acceptent le compromis alors que les socialistes se radicalisent, prennent le maquis dans le sud du pays, principalement dans les régions de Huila et Tolima et, à la suite de la révolution cubaine de 1959, se rapprochent du communisme. Des guérillas marxistes apparaissent dans des zones reculées du pays, enracinées dans les luttes agraires ou inspirées par la révolution cubaine, initiant l'actuel conflit armé colombien.

À partir de 1957 se créent des mouvements agraires d'inspiration libérale puis communiste issus des milices d’autodéfense paysanne modernes établies durant "La Violencia" pour lutter contre les exactions des militaires et des groupes armés conservateurs, principalement dans les départements de Cundinamarca (Bogota) et de Tolima (Ibagué). L’État colombien s'attaque à ces zones, dont l’éphémère « République de Marquetalia », à partir de 1964. À la suite de ces combats, se forment deux groupes de guérilla marxistes : les Forces armées révolutionnaires de Colombie (FARC) et l'Armée de libération nationale (ELN).

Le premier de ces groupes émerge en 1964 comme branche militaire du parti communiste colombien, à partir de groupes de guérillas issus de la République de Marquetalia et des autres zones d'autodéfense communistes constituées en particulier dans les départements du Tolima et du Meta. Les FARC sont menées par Manuel Marulanda Vélez et essentiellement constituées de paysans, avec un fort encadrement du parti communiste.

L'ELN est un groupe d'inspiration castriste fondé en 1965 dans le département de Santander, bénéficiant initialement du soutien des communistes au travers des syndicats des ouvriers du pétrole.

Rapidement, des tensions se font jour entre les deux groupes, reflet en Colombie des tensions entre Moscou et La Havane : tandis que les castristes, selon la théorie foquiste, croient que la guérilla peut mener à la révolution même si toutes les conditions objectives n'en sont pas réunies, les communistes « orthodoxes » jugent que dans la situation de la Colombie de la fin des années 1960, la priorité doit être donnée à l'action de masse au travers du Parti communiste et des syndicats. L'ELN obtient une importante couverture médiatique grâce à des actions à fort impact comme le dynamitage d'un train dans le département de Santander, et à la personnalité de Camilo Torres, prêtre extrêmement populaire qui rejoint l'ELN et périt rapidement lors d'un affrontement avec une patrouille militaire.

En 1967, un troisième groupe de guérilla, l'Armée populaire de libération (EPL) émerge à partir d'une scission maoïste du parti communiste colombien.

Ces groupes de guérilla ne connaissent pas d'importants succès et, au début des années 1970, sont réduits à quelques centaines d'hommes agissant dans des zones reculées du pays. Bien que jouissant de la sympathie d'une partie de la population, en particulier les étudiants, le gouvernement arrive à les contrôler avec une importante aide des États-Unis. En effet, en cette période de guerre froide, ceux-ci ne souhaitent pas un nouveau Cuba et promeuvent partout dans le monde et en particulier en Amérique la lutte contre toute tentative de coup d'état d'inspiration communiste. Ainsi, l'ELN castriste est presque anéantie en 1973 au cours de l'opération Anorí mais quelques dizaines de guérilleros échappent à l'encerclement de l'armée et continuent leur lutte armée.

Les années 1970 sont marquées par la reconstitution des structures des FARC et de l'ELN, qui reçoivent l'aide de Cuba et du Nicaragua après la révolution sandiniste de 1979 et parviennent à conserver leurs bases d'appui rurales, et par l'émergence du (M-19), une guerilla urbaine apparue à la suite des élections supposément frauduleuses du qui voient la défaite du général Rojas Pinilla.

À partir des années 1980, le conflit armé colombien prend une nouvelle dimension avec l'essor du narcotrafic et l'émergence des premiers groupes paramilitaires financés par les narcotrafiquants pour se protéger des actions des guérillas.

Carrefour géographique et seul pays d'Amérique du Sud à posséder une double façade maritime, la Colombie dispose en outre de capacités entrepreneuriales fortes, d'une diaspora en réseau et des moyens techniques nécessaires à l'élaboration et à la synthèse de drogues. La diversité de son relief ainsi que l'existence de zones reculées favorisent la culture potentielle de marijuana, de coca ou de pavot. De plus, la "Violencia" a contribué au développement de contrebandes diverses (alcool, tabac, émeraudes, précurseurs chimiques, produits manufacturés, stupéfiants…).

Entre 1974 et 1982, la Colombie est un important producteur de marijuana. La cocaïne est alors essentiellement produite au Pérou et en Bolivie et n'est que convoyée et transformée en Colombie pour ensuite prendre la route des Caraïbes ou du Mexique.

C'est à la fin des années 1970 que le cartel de Medellín de Pablo Escobar se développe. Il fait irruption sur la scène politique en 1982 lorsqu'Escobar est élu député suppléant. Écarté systématiquement à partir de 1984, Escobar entre en guerre avec le gouvernement en assassinant en 1984 le ministre de la Justice, Rodrigo Lara Bonilla. Le , Guillermo Cano Isaza, journaliste de "El Espectador", est abattu. Le , c'est le tour du candidat libéral à l'élection présidentielle, Luis Carlos Galán. Le , le cartel tente d'assassiner César Gaviria, successeur de Luis Carlos Galán, candidat à la présidentielle colombienne en faisant exploser le vol 203 d'Avianca, faisant 110 morts. Le , un attentat à la voiture piégée détruit l'immeuble du Departamento Administrativo de Seguridad. Outre le gouvernement, le cartel de Medellín est également en guerre avec son concurrent le cartel de Cali à partir du milieu des années 1980. Les attentats se multiplient alors à Bogota, Medellín et Cali. En 1991, Pablo Escobar est finalement arrêté et, en fuite, abattu deux ans plus tard. Cette mort met un terme à une décennie de conflit ouvert.

Le cartel de Cali, qui a su rester beaucoup plus discret que son concurrent, reprend alors le contrôle du trafic de drogues. Le président Ernesto Samper se voit en 1994 accusé d'avoir reçu six millions de dollars de la part du cartel de Cali pour financer sa campagne, ce qui provoque une crise politique interne et un grave incident diplomatique avec les États-Unis. Les résultats de l'enquête connue sous le nom de "Proceso 8000" montrent que de nombreuses entreprises fictives et diverses entités bancaires ont effectué plus de en faveur de personnalités politiques colombiennes. Ces faits mettent en évidence l'importance réelle du cartel de Cali et ses liens étroits avec la classe politique, ce qui conduit à son démantèlement en 1995.

À la suite de la disparition des deux principaux cartels, d'autres acteurs reprennent le trafic dans les années 1990, le ainsi que d'autres groupes plus nombreux et moins centralisés que les deux cartels originaux. Alors que les cartels de Cali et Medellín étaient totalement intégrés, contrôlant tout depuis la production jusqu'à la vente aux États-Unis ou en Europe et formant donc un quasi-duopole, ces nouveaux groupes contrôlent chacun une partie de la chaîne sans qu'il y ait de commandement commun, ce qui rend la lutte pour faire cesser le narcotrafic plus difficile. Ainsi, malgré les opérations de l'armée colombienne contre le narcotrafic, en particulier avec l'aide des États-Unis dans le cadre du Plan Colombie, la Colombie est au début des années 2000 le premier pays producteur de cocaïne au monde et domine environ 70 % du marché mondial de cette substance selon Interpol, avec une production toutefois en baisse (de en 1999 à 440 en 2003), sur un peu plus de hectares, soit un rendement d'environ de cocaïne par hectare et par an.

La transformation de la Colombie en plaque tournante du trafic international de stupéfiants donne aux acteurs du conflit armé colombien un moyen de financement puissant, pour les guérillas marxistes (FARC ou ELN) comme pour les formations paramilitaires qui apparaissent dans les années 1980 et se structurent pour devenir en 1997 les Autodefensas Unidas de Colombia, ou AUC.

En 1978, le libéral Julio César Turbay Ayala est élu à la présidence. Il a à faire face aux actions du M-19, guérilla urbaine fondée en 1974 par plusieurs membres de l'aile socialiste de l'ANAPO et certains membres des FARC. Il répond par la militarisation du pays et l'intensification de la répression.

Le président conservateur Belisario Betancur élu en 1982 entame une politique de dialogue avec les guérillas et signe les accords de La Uribe, le . Il fait voter une loi d'amnistie, légalise un organe politique des FARC, l'Union patriotique (UP), et fait passer plusieurs réformes sociales. Betancur négocie principalement avec les FARC et le M-19, multipliant les trêves et les cessez-le-feu. Mais malgré le cessez-le-feu et l'accord de La Uribe, de nombreux membres de l'Union Patriotique sont assassinés entre 1984 et 1990 et le processus de paix échoue. Cette expérience politique traumatisera les FARC, rétifs dès lors à toute négociation. Les coupables de ces assassinats seraient, selon les cas, les forces de l'ordre, des politiciens, des narcotraficants, mais aussi les paramilitaires qui commencent à émerger. Cet épisode a parfois été qualifié de génocide politique, et renforce les FARC dans leur conviction que la lutte armée est la seule voie possible vers la prise du pouvoir.

En novembre 1985, des membres du M-19 attaquent le palais de justice de Bogota et prennent en otage les juges de la Cour Suprême. Cette prise d'otage se termine par un bain de sang lorsque l'assaut est donné par l'armée, faisant près d'une centaine de morts.

Ces trois années de négociations, loin d'avoir restauré la paix, permettent aux guérillas de s'implanter plus fortement, tandis qu'apparaissent des milices d'autodéfense. L'une d'entre elles, le MAS ("Muerte a Secuestradores"), est financée par les cartels de drogue en lutte contre le M-19 à la suite de l'enlèvement en 1981 de Marta Nieves Ochoa, sœur de Jorge Luis Ochoa, un des dirigeants du cartel de Medellín. Confrontés à un ennemi commun, certains services de sécurité de l'État utilisent ces groupes paramilitaires comme supplétifs pour la « sale besogne » que l'État ne peut pas se permettre d'effectuer lui-même.

L'élection du libéral Virgilio Barco en 1986 ne change que peu de choses au conflit armé qui s'aggrave à mesure que le phénomène paramilitaire prend de l'ampleur et du fait des actions des narco-terroristes de Pablo Escobar. Ceux-ci luttent contre le gouvernement à partir de 1986 via le groupe des "Extraditables" sur le point crucial pour les trafiquants de la loi sur l'extradition des criminels vers les États-Unis.

Durant le mandat de Barco, les préoccupations du gouvernement sont la lutte contre la pauvreté, le dialogue avec les guérillas et la lutte contre le narcotrafic. Un nouveau modèle d'administration publique commence à être appliqué, avec cinq objectifs prioritaires : l'efficacité sociale des ressources publiques, la démocratisation de l'administration publique, l'efficience et la responsabilisation des institutions et des fonctionnaires, la capacité gestionnaire et administrative de l'État et le renforcement institutionnel de la Présidence de Colombie.

C'est à cette période qu'est lancée l'idée d'élire une assemblée constituante comme solution au problème des guérillas. En effet, nombreux sont ceux qui imputent au Front National et à la vieille constitution de 1886 une part de responsabilité dans le violent conflit armé qui a lieu. Favorable à cette idée, le M-19 entame des pourparlers de paix et finit par se démobiliser massivement le pour entrer en politique sous le nom AD/M-19 (Alliance Démocratique).

Il revient au successeur de Barco, le libéral César Gaviria Trujillo (1990-1994), de mener à bien ce nouveau projet de Constitution. Le 4 juillet 1991 est adoptée une nouvelle constitution particulièrement progressiste et moderne : la Colombie est déclarée (art.1). Elle supprime la notion d'état de siège, remplacé par celui d'état de commotion interne, beaucoup plus restrictif et protecteur des droits de l'homme
. En outre, elle va vers une décentralisation de l'État, les départements acquérant une relative autonomie, l'État central leur déléguant les responsabilités administratives et entérinant les élections directes des maires et gouverneurs de départements. D'autre part, elle reconnaît les droits linguistiques, culturels et politiques des minorités amérindiennes et afro-colombiennes. Enfin, elle ouvre le jeu politique à tous les partis.

Ce projet est adopté massivement par plébiscite et permet la démobilisation et l'entrée politique de l'EPL et d'autres mouvements guérilleros minoritaires (Mouvement armé Quintín Lame, PRT…). Le parti créé à la suite de l'entrée en politique du M-19 remporte 26 % des suffrages lors de l'élection pour la Constituante (et a donc largement contribué à sa rédaction) et son principal représentant, Antonio Navarro, arrive à la troisième place de l'élection présidentielle de mai 1990 (qui voit la victoire de Gaviria) devant le candidat conservateur.

Les efforts de paix du président Gaviria débouchent sur une série de négociations à Caracas (juin 1991) puis à Tlaxcala au Mexique (mars 1992) avec les FARC et l'ELN mais les négociations échouent et la situation devient tellement troublée que Gaviria déclare l'état de commotion interne durant près de neuf mois (90 jours renouvelables deux fois) et renforce les pouvoirs des militaires, tout en recentralisant le pouvoir.

Durant la même période, le président négocie avec le cartel de Medellín, affaibli par la guerre qui l'oppose à l'armée, et obtient la reddition de son chef Pablo Escobar en juin 1991 en échange de la promesse de ne pas être extradé. Incarcéré dans une luxueuse prison qu'il a lui-même fait construire à Envigado, Escobar n'en continue pas moins de diriger ses affaires depuis sa cellule. Lorsque le gouvernement menace de mettre fin à cette situation en le transférant dans une autre prison en juillet 1992, il s'évade. Pourchassé par l'armée, par ses concurrents du cartel de Cali, par des mercenaires américains, israéliens et autres alléchés par la prime de plusieurs millions de dollars US offerte par le gouvernement et les organismes anti-stupéfiants américains, et par le groupe paramilitaire terroriste "Los Pepes" apparu en 1993, Escobar fait également l'objet d'une vaste opération impliquant la plupart des agences fédérales américaines (CIA, DEA, FBI, NSA). Il finit par être abattu le dans son fief de Medellín.

Le mandat du nouveau président libéral Ernesto Samper qui débute en 1994 ne modifie pas radicalement le conflit. En effet, comme c'est le cas de tous les présidents depuis Betancur, Samper commence par vouloir négocier avec les guérillas dans le but et lance un programme social, voyant en la pauvreté et en le manque d'opportunités sociales et économiques une des racines du conflit. Mais le cycle de violence ne peut être stoppé et la méfiance réciproque entre gouvernement et guérillas ne s'estompe pas.

De fait, la marge de manœuvre de Samper est limitée par un important scandale éclatant lors de la campagne de 1994 et ayant trait au financement de sa campagne électorale par le cartel de Cali. Il débouche sur le , ce qui contraint à la démission plusieurs de ses ministres. Bien que le président Samper lui-même, jugé par l'Assemblée, soit dédouané de toute responsabilité, ce scandale le discrédite totalement et met en évidence l'importance réelle du cartel de Cali et ses liens étroits avec la classe politique, ce qui conduit à son démantèlement en 1995.

Entre 1996 et 1998, les FARC attaquent plusieurs bases militaires des départements amazoniens. Le , la base de Las Delicias, dans la municipalité de Puerto Leguízamo (Putumayo), est prise à partie par 400 guérilleros. Le , à El Billar dans la municipalité de Cartagena del Chairá (Caquetá), les FARC écrasent une unité anti-guérilla de l'armée, tuant 64 soldats et faisant prisonniers 43 militaires.

D'un autre côté, c'est sous le gouvernement de Samper que les milices paysannes CONVIVIR, créées par un décret de son prédécesseur et travaillant en étroite coopération avec les forces de l'armée, prennent leur essor, tandis que les groupes paramilitaires sont unifiés en 1997 au sein des "Autodefensas Unidas de Colombia" sous l'égide de Carlos Castaño.

Le conservateur Andrés Pastrana Arango est élu de justesse en juin 1998. Ayant rencontré personnellement le chef des FARC, Manuel Marulanda Vélez, avant son investiture, il cherche dès le début de son mandat à se concilier les faveurs des FARC et de l'ELN.

Pastrana concède le aux FARC une zone démilitarisée dans la région du río Caguán (départements de Meta et Caquetá) de . La politique de négociation dure jusqu'en 2001 à un rythme imposé par les FARC et débouche sur la libération de 300 prisonniers de la guérilla. Ces négociations prennent fin en février 2002 et la zone démilitarisée est reconquise par l'armée. Le mandat de Pastrana correspond également à une grave période de récession économique et au développement considérable du phénomène paramilitaire. Les paramilitaires sont aussi responsables, pendant la même période, de la plupart des 3 millions de réfugiés internes.

Parallèlement à la négociation avec les FARC, Andrés Pastrana renoue diplomatiquement avec Washington et obtient à l'issue de négociations secrètes le lancement en août 2000 du plan Colombie. Il s'agit d'une aide financière de de dollars initialement destinée à la lutte anti-drogue, au renforcement des capacités militaires de l'armée colombienne et à des réformes sociales, dans la droite ligne de la doctrine de la sécurité nationale et de la guerre contre-insurrectionnelle, qui combine réformes politiques et actions militaires avec le soutien des États-Unis. Les négociations avec les FARC n'auraient en réalité eu pour objet que de permettre au gouvernement de gagner du temps afin de restructurer son armée, puis de surpasser militairement la guérilla en reprenant la guerre.

C'est un candidat indépendant, issu du Parti libéral, qui gagne très largement au premier tour (avec 53 % des voix) les élections de 2002. Dès son élection, Álvaro Uribe se lance dans une politique offensive (de « sécurité démocratique ») dans le but de réduire l'emprise territoriale des guérillas. Uribe fait adopter la loi « justice et paix » de juillet 2005, offrant aux paramilitaires des Autodéfenses unies de Colombie (AUC) des conditions favorables pour leur réinsertion dans la société colombienne. Elle permet la démobilisation de plusieurs milliers de paramilitaires.

Selon la Commission colombienne des juristes, pendant le premier mandat du président Uribe (2002-2006), onze mille trois cents civils auraient été exécutés pour motif politique dont 14 % par des agents de l’État, 60 % par des paramilitaires « tolérés par l’État ». Elle souligne que, pendant cette période, . Par ailleurs, la démobilisation des paramilitaires a largement été entachée par le « scandale de la parapolitique », aboutissant en 2006 à la détention de sénateurs proches d'Uribe puis de celle d'un des ex-chef des services de renseignement, Jorge Noguera Cotes.

Malgré cela, Uribe est crédité de plus de 80 % d'opinions favorables en décembre 2003 grâce à la forte amélioration tant de la sécurité que de la situation économique (qualifiée parfois à l'extérieur de la Colombie de politique populiste). Uribe s'est fait le chantre de la lutte contre la production de drogue et les guérillas d'extrême-gauche (dans le cadre du plan Colombie puis du plan Patriote), devenant de ce fait le soutien numéro un en Amérique du Sud de l'administration Bush et l'ennemi personnel de Hugo Chávez, le président du Venezuela.

Par l'acte législatif 02 de 2004, l'article 197 de la Constitution de 1991 est modifié pour permettre la réélection du président sortant. C'est par une victoire écrasante (62 % des voix au premier tour) que le président Uribe est réélu le 28 mai 2006 pour quatre ans.

Le second mandat Uribe est marqué par une intensification de la lutte contre les FARC. Une prime donnée pour la capture ou la mort de chaque guérillero provoque un nouveau scandale qui éclate en 2008, le scandale des « "falsos positivos" » (en français : "faux-positifs") : des citoyens innocents enlevés par l'armée ou les paramilitaires sont « retrouvés » morts et présentés comme des terroristes afin de toucher la prime et de gonfler artificiellement les résultats des manœuvres militaires. En mars 2008, le bombardement d'un camp militaire en Équateur (opération "Phénix") aboutit à la mort de Raúl Reyes, de l'organisation et à une importante crise diplomatique entre la Colombie, l'Équateur et le Venezuela. En juillet 2008, quinze otages, dont la franco-colombienne Íngrid Betancourt, sont libérés lors d'une opération spéciale de l'armée colombienne.

L'opération en Équateur contre Reyes puis la découverte de documents accréditant un soutien financier du Venezuela aux FARC provoque une crise diplomatique durant l'année 2008. Par la suite, les deux présidents se rencontrent et se réconcilient officiellement. Mais en juillet 2010, quelques jours avant le départ de la présidence d'Álvaro Uribe et l'investiture de Juan Manuel Santos, éclate une crise diplomatique entre la Colombie et le Venezuela : Hugo Chávez rompt toutes relations avec la Colombie, après la présentation auprès de l'Organisation des États américains de documents (images satellites, coordonnées GPS, photos) qui visent à prouver la présence « active » de membres des FARC sur le sol vénézuélien. Accusant Álvaro Uribe de préparer une attaque aérienne contre son pays avant la fin de son second mandat, Hugo Chávez ordonne le déploiement de forces armées le long de leur frontière commune. Le président sortant colombien réfute ces accusations et déclare : .

Après le rejet par la Cour constitutionnelle d'une loi permettant à Álvaro Uribe de briguer un troisième mandat, son « dauphin » et ancien ministre de la Défense Juan Manuel Santos remporte l'élection présidentielle de 2010, avec 69,13 % des voix au second tour. Son adversaire, le candidat du Parti vert, Antanas Mockus, recueille 27,47 %.

Le , Juan Manuel Santos prête serment, devenant ainsi le président de la République de Colombie. La cérémonie d'investiture se tient sur la Place Bolívar de Bogota, en présence de invités, dont le président sortant Álvaro Uribe et 16 chefs d'État et de gouvernement, parmi lesquels le président du Brésil Luiz Inácio Lula da Silva, de l'Argentine Cristina Fernández de Kirchner, de l'Équateur Rafael Correa, du Pérou Alan García, ainsi que de la plupart des dirigeants d'Amérique centrale. Le président vénézuélien Hugo Chávez, que Santos espérait voir assister à son investiture avant la rupture des relations diplomatiques et commerciales entre les deux pays, est finalement représenté par son ministre des Affaires étrangères, Nicolás Maduro.

Sa proposition de rétablir les relations diplomatiques avec le Venezuela est accueillie favorablement par Hugo Chávez, qui lui propose aussitôt un tête-à-tête. Le 10 août, avec la médiation de Luiz Inácio Lula da Silva, une rencontre est organisée entre les deux chefs d'État dans la ville de Santa Marta. À l'issue de cet entretien, la décision de renouer les relations diplomatiques et commerciales, nécessaires à l'économie des deux pays, est annoncée. Juan Manuel Santos, après avoir serré la main de Chávez devant le portrait de Simón Bolívar, précise que le Venezuela remboursera ses dettes aux exportateurs colombiens, estimées à environ de dollars.

En matière de politique intérieure, Juan Manuel Santos souhaite faire de « la prospérité sociale » la priorité de son gouvernement, alors que 40 % de la population vit sous le seuil de pauvreté. Pour lutter contre la misère et le chômage, qui s'élève à plus de 12 % des actifs, il souhaite mettre l'accent sur la création d'emplois.

Son gouvernement démantèle peu à peu les réseaux de corruption, qui s'étaient multipliés durant la présidence Uribe, dans les secteurs de la santé, de l'éducation, de la collecte d'impôts<ref name="La Croix 7/08/2011">.</ref>. Par ailleurs, le président Santos demande pardon aux victimes des paramilitaires, fait adopter une loi visant à rendre 2,6 millions d'hectares aux trois millions d'habitants chassés par ceux-ci, et renforce les conditions de détention des officiers complices de massacres.

Le , un an après son arrivée à la tête de la Colombie, alors qu'il bénéficie d'une cote de popularité s'élevant aux alentours de 70 %, il demande aux forces armées de réviser leur stratégie pour combattre notamment les bandes criminelles et les FARC, ces dernières regagnant du terrain et multipliant les attaques soudaines et imprévues, malgré la mort de leur dirigeant militaire, Jorge Briceño Suárez, en . Juan Manuel Santos indique, le lendemain, son intention d'ouvrir un dialogue de paix avec la guérilla communiste uniquement en cas de « circonstances appropriées », parmi lesquelles la libération des otages. Le commandant en chef des FARC, Alfonso Cano, est tué par l'armée le 4 novembre 2011.

Dans la lutte historique du pays contre la drogue, Juan Manuel Santos discute la possibilité de légaliser des drogues douces comme la marijuana qui pourrait, selon lui, être un moyen d'endiguer la violence.

À la suite d'un jugement défavorable de la Cour internationale de justice sur un différend concernant la frontière maritime avec le Nicaragua. La Colombie dénonce le 28 novembre 2012 le traité américain de règlement pacifique mais la dénonciation de celui-ci ne peut entrer en vigueur avant un an.

La politique de Juan Manuel Santos dans le conflit armé au cours de la deuxième partie de son mandat, consistant à dialoguer avec la guérilla, lui vaut des critiques de l'ancien président Álvaro Uribe, lequel quitte le Parti de la U pour fonder le Centre démocratique en janvier 2013 avec son ancien viceprésident Francisco Santos et d'autres alliés proches qui étaient également au Parti de la U. L'économiste et ancien ministre des Finances d'Uribe Óscar Iván Zuluaga est leur candidat pour l'élection présidentielle de 2014. Malgré un premier tour favorable au candidat du Centre démocratique qui rafle près de 29,25 % des suffrages et devance le président sortant, Juan Manuel Santos sort vainqueur du deuxième tour et est réélu à la présidence de la République.

Le , un accord de cessez-le-feu définitif est signé entre les FARC et le gouvernement de Juan Manuel Santos. Ce jour est déclaré comme étant entre les FARC et le gouvernement. L'accord de paix est finalement signé le 24 août et est dans l'attente de validation par référendum. Le 26 septembre, le gouvernement colombien et les FARC paraphent l'accord de paix mettant fin au conflit armé qui les opposait. Toutefois, lors du référendum organisé le 2 octobre 2016, les Colombiens rejettent l'accord de paix. Le président Juan Manuel Santos assure alors que le cessez-le-feu restera en vigueur, et le chef des rebelles Rodrigo Londoño annonce qu’il reste en faveur de la paix. Après une nouvelle phase de négociations, le gouvernement et les FARC trouvent un nouvel accord modifiant largement le premier, ratifié le 29 novembre par le Sénat et le 30 par la Chambre des Représentants.

La démobilisation des FARC entraine un regain de violence dans les régions qu'ils contrôlaient autrefois, désormais sous pression des groupes paramilitaires. Une centaine de responsables associatifs ont été assassinés entre janvier et novembre 2017, auxquels il faut ajouter 27 membres démobilisés des FARC. En outre, la violence des forces de l'ordre est également dénoncée par des organisations non gouvernementales, dont en particulier la mort de sept manifestants lors d'une manifestation de paysannes réprimée par la police le 5 octobre.





</doc>
<doc id="14495" url="https://fr.wikipedia.org/wiki?curid=14495" title="Mer des Caraïbes">
Mer des Caraïbes

La mer des Caraïbes ou mer des Antilles est une mer de l'océan Atlantique, située à l'est de l'Amérique centrale et au sud-est du golfe du Mexique. Elle s'étend sur environ d'est en ouest et en moyenne deux fois moins du nord au sud et couvre une superficie de .

Le nom de cette mer trouve son origine dans celui des Caraïbes, un peuple qui habitait cette région jusqu'à l'arrivée des Espagnols au .

L'Organisation hydrographique internationale définit les limites de la mer des Caraïbes de la façon suivante :

Une ligne joignant le phare du cap Catoche () sur la côte nord-est du Yucatán, au Mexique, au phare du cap San Antonio (), à l’extrémité ouest de Cuba ; 
de là vers l'est, le long de la côte sud de Cuba, à la punta Caleta () sur la côte sud-est de cette île ;
de là, une ligne reliant la punta Caleta jusqu'à la pointe la Perle (), sur la côte nord-ouest d'Haïti ;
de là, de la pointe la Perle vers le sud et vers l'est, le long de la côte sud d'Haïti et de la République dominicaine, jusqu'au cabo Engaño (), à l'extrémité orientale de la République dominicaine;
de là, une ligne reliant le cabo Engaño vers l'est jusqu'à la punta Agujereada () sur la côte nord de Porto Rico.

Depuis la cabeza Chiquita () (Puerto Rico) vers le nord, le long du méridien de ce cap jusqu'à la ligne des fonds de 100 brasses (183 m); de là vers l'est puis vers le sud , de telle façon que toutes les îles, hauts-fonds, détroits et chenaux des Petites Antilles soient inclus dans la mer des Caraïbes jusqu'à la pointe Galera (), l'extrémité nord-est de l'île de la Trinité. Depuis la pointe Galera à travers Trinité jusqu'à la pointe Galeota (), à son extrémité sud-est ; et de là une ligne reliant la pointe Galeota vers le sud jusqu'à la punta Baja (), sur la côte orientale du Venezuela.

De la punta Baja, au Venezuela, vers l'ouest et vers le nord, le long de la côte nord de l'Amérique du Sud et la côte orientale de l'Amérique centrale, jusqu'au phare du cap Catoche (), sur la côte nord-est du Yucatán, au Mexique.

Les principaux États ou îles qui bordent la mer des Caraïbes sont :

Cette mer communique au nord-ouest avec le Golfe du Mexique par le canal du Yucatán, et avec l'océan Atlantique par le passage du Vent et le canal de la Mona au nord, directement avec cet océan à l'est et au delà des îles des Petites Antilles les plus orientales, enfin par le Columbus Channel au sud-est. Elle communique aussi "artificiellement" avec l'océan Pacifique par le canal de Panama. Le passage du Vent — nom donné à la zone située entre Cuba et Haïti — est une importante route maritime entre les États-Unis et le canal.

Sa profondeur maximale est de mètres au niveau de la fosse des Caïmans.

Les populations des Caraïbes entretiennent des relations privilégiées avec la mer des Caraïbes, qui constitue leur héritage commun, et partagent un intérêt particulier à la voir déclarée "Zone Spéciale" dans le contexte du "Développement du Tourisme durable" de l'Organisation des Nations unies (ONU).

Afin de prévenir les conséquences dévastatrices sur l'environnement côtier et marin d'un éventuel accident ou acte terroriste impliquant un chargement de matières nucléaires, les États membres de l'Association des États de la Caraïbe (AEC), se sont toujours opposés de façon véhémente au passage de chargements de déchets nucléaires par la route Canal de Panama-Mer des Caraïbes. 

Ces chargements ne représentent pas la seule menace qui pourrait affecter la mer des Caraïbes, l'une des principales voies navigables du monde. Elle est traversée chaque année par environ bateaux, qui génèrent près de d'ordures. En outre, environ bateaux de pêche circulent dans la région. Les rejets des populations sur la terre ferme, un développement touristique intensif et d'importants chargements de pétrole constituent également des risques pour l'environnement.

Le , les chefs d’État et/ou de gouvernement des pays de l'AEC, réunis sur l'île de Margarita (Venezuela), ont adopté la Déclaration de Margarita, « reconnaissant la mer des Caraïbes comme patrimoine commun de la région, et comme un actif inestimable », dans le but de « consolider une identité caribéenne propre ». Ils se sont engagés « à convertir la région de la Grande Caraïbe en "zone de coopération" », qui « consistera tout d’abord en des actions conjointes dans les domaines établis comme priorités par l’AEC, à savoir le commerce, le tourisme durable, les transports et les catastrophes naturelles ».



</doc>
<doc id="14497" url="https://fr.wikipedia.org/wiki?curid=14497" title="Mer d'Azov">
Mer d'Azov

La mer d'Azov (en , ; en , "" ; en ; en adygue "Khı Mıvt'e" ; en ou "Méotide") est une mer intracontinentale peu profonde qui s'étend sur une superficie de . Elle est bordée à l'ouest et au nord par l'Ukraine, à l'est par la Russie et au sud par la presqu'île de Crimée et la péninsule de Taman (Russie), toutes deux séparées par le détroit de Kertch qui la relie à la mer Noire. Elle porte le nom de la ville d'Azov.

L'Organisation hydrographique internationale détermine les limites de la mer d'Azov de la façon suivante : "Dans le détroit de Kertch" : une ligne joignant le mys Takil (), l'extrémité sud-est de la péninsule de Kertch (Kerchens'kyy pivostriv), en Crimée, en direction de l'est jusqu'au mys Panagiya (), l'extrémité sud-ouest de la péninsule de Taman ("Tamanskiy poluostrov").

La mer d’Azov est de fait le plus grand des limans de la mer Noire et forme l’estuaire commun de plusieurs fleuves, dont le principal est le Don. Comme pour les autres limans, ses eaux sont saumâtres et peu profondes (10 mètres en moyenne) tandis que ses rives sont généralement basses, marécageuses et couvertes de joncs et de roseaux ; d’ailleurs à l’époque de la Grèce antique, on l’appelait ἡ Μαιῶτις λίμνη : « "liman Méotide" ».

Si ce liman a pris une telle proportion, cela tient au fait qu’à la fin de la dernière glaciation le Don, les fleuves des plaines d’Ukraine (Mious, Kalmious, Molotchna) et ceux venus du Caucase (Eïa, Beïsoug, Kouban), grossis de la fonte des glaces, butèrent, au niveau du détroit de Kertch, sur les premiers contreforts de la chaîne criméo-caucasienne. La mer d’Azov est leur déversoir et leur lagune commune d’accumulation. La plupart d’entre eux forment aujourd’hui des limans secondaires ou un delta individuel qui débouche ensuite dans ce bassin commun.

L’eutrophisation d’origine agricole et urbaine est un des problèmes régionaux majeurs : les taux de nitrates en particulier ont doublé, voire triplé en mer Noire et en mer d’Azov dans les années 1980/années 1990 selon le rapport Dobris qui estime que les contrôles des activités en pleine mer sont insuffisants. D'autres problèmes sont liés à l’introduction d’espèces invasives.

Dans l’Antiquité, les habitants de ses rives sont appelés « Cimmerii » (Cimmériens soit « ceux du bout du monde ») par Hérodote et « Meoti » (Méotes) par Tacite : ils sont décrits comme de souche scythe. Sous l’Empire ottoman, on y pêchait l’esturgeon et on y produisait déjà du caviar exporté dans la glace vers la Russie ; la glace était retirée l’hiver des limans secondaires en eau douce, et conservée le reste de l’année entre des couches de paille dans de grandes glacières entourées de peupliers ombreux, auprès de pêcheries spécialisées appelées "kerhana". Les rives de la mer d’Azov sont devenues russes en 1783, provoquant la guerre russo-turque de 1787-1792.

À l’époque moderne, un canal a été creusé le long du littoral sud-ouest (canal de Pivinichno), pour assurer la circulation des bateaux jusqu’au Dniepr, très proche. On passe aussi de la mer d'Azov à la mer Caspienne par le canal Don-Volga qui relie le Don à la Volga en amont respectivement de Rostov-sur-le-Don et d’Astrakhan. D'autre part, la liaison entre la mer d'Azov et la mer Noire se fait par le détroit de Kertch, qui représente de ce fait un point éminemment stratégique, et explique qu'il était gardé par le port antique de Théodosie. Ce détroit peu profond ne peut être franchi que par le "chenal de Kertch", dans la zone portuaire du port homonyme.

Autrefois mer intérieure de l’URSS, la mer d’Azov est maintenant une mer internationale bordée par l’Ukraine et la Russie. En octobre 2003, la Russie venait de construire une digue avec une route sur le cordon littoral reliant ainsi la péninsule de Taman à l’île de Touzla. C’est alors que l'Ukraine a rappelé que depuis 1970, cette île lui appartenait, or qui contrôle l’île contrôle le trafic maritime dans le détroit de Kertch. La faible profondeur du détroit (moins de en moyenne) fait que la zone navigable par les navires se trouvent alors du côté alors ukrainien : c’est le chenal Kertch-Enikal, dans la zone portuaire de Kertch. Un accord est intervenu par la suite sur l’utilisation conjointe du détroit et sur le statut de la mer d'Azov, mais un désaccord a persisté concernant l’île de Touzla. En 2014, lors du rattachement de la République de Crimée à la Russie, l’île de Touzla est rattachée au kraï de Krasnodar, mais comme la Crimée, reste revendiquée par l’Ukraine.




</doc>
<doc id="14499" url="https://fr.wikipedia.org/wiki?curid=14499" title="Golfe du Mexique">
Golfe du Mexique

Le golfe du Mexique est un golfe de l'océan Atlantique, situé au sud-sud-est de l'Amérique du Nord. Il s'étend sur une superficie de .

L'Organisation hydrographique internationale définit les limites du golfe du Mexique de la façon suivante :

Les principaux pays qui bordent le golfe du Mexique sont :

Le golfe du Mexique communique au sud-est avec la mer des Caraïbes par le canal du Yucatán et à l'est avec l'océan Atlantique par le détroit de Floride. Sa profondeur maximale atteint à l'.


C'est une zone écologiquement très riche, et une zone de pêche importante pour les États-Unis et Cuba.

Pollution : en raison de la quantité toujours croissante d'azote et de phosphates dissous dans les eaux du golfe du Mexique, la pollution a plus que doublé depuis 1950. Selon les estimations actuelles, on trouve trois fois plus d'azote circulant dans le golfe qu'il y a . Chaque été, il y a maintenant une zone au sud du littoral de la Louisiane, plus grande que l'État américain du Massachusetts avec plus de , qui est hypoxique. Ces eaux ne transportent pas assez d'oxygène pour soutenir la vie marine.

Il y a également fréquemment des proliférations d'efflorescences algales qui tuent régulièrement (par anoxie ou par libération de toxines) les poissons et les mammifères marins et peuvent causer des problèmes respiratoires chez les humains et certains animaux domestiques lorsque "les fleurs" atteignent les rives. Cela se produit surtout sur la côte sud-ouest de la Floride, depuis les Keys jusqu'au comté de Pasco où se développe périodiquement l'une des plus grandes zones marines mortes (« "marine dead zone" ») du monde

On sait peu de choses sur l'histoire géologique du bassin du golfe du Mexique avant la fin du Trias. Certains auteurs ont postulé la présence d'un bassin dans la zone pendant la majeure partie du Paléozoïque, mais la plupart des éléments semblent indiquer que les roches du Paléozoïque ne servent pas de base sur la plupart du bassin du golfe du Mexique. Il semble également que, à la fin du Paléozoïque, la région faisait partie du supercontinent de la Pangée.

Il semble que l'actuel bassin du golfe du Mexique tire son origine de la fin du Trias, lors du clivage de la plaque nord-américaine, à l'époque où elle a commencé à se fissurer et à dériver loin des plaques de l'Afrique et de l'Amérique du Sud. La faille s'est probablement accentuée pendant le petit et le moyen Jurassique, avec la formation d'une croûte continentale « en extension » (ou « de transition ») le long de la partie centrale du bassin. Les avancées intermittentes de la mer dans l'ouest de la zone continentale, à la fin du moyen-Jurassique, a abouti à la formation d'un large dépôt salin. Il semble que le principal épisode de dérive ait eu lieu au début du Jurassique supérieur, après la formation des dépôts salins. C'est à cette période que le bloc du Yucatán se déplace vers le sud et se sépare de la plaque nord-américaine et qu'une véritable croûte océanique se forme dans la partie centrale du bassin.

Depuis la fin du jurassique supérieur, le bassin a été une zone géologiquement stable, caractérisée par la persistance de sa partie centrale, probablement en raison du refroidissement et de la sédimentation du bassin au niveau de ses limites nord et nord-ouest, principalement pendant le Cénozoïque.

À l'est, la plate-forme stable de Floride n'a pas été recouverte par la mer avant la fin du jurassique ou le début du Crétacé. La plate-forme du Yucatán était émergée jusqu'au milieu du Crétacé. Dès lors, les deux plates-formes furent submergées. Cette période géologique est caractérisée par la formation de carbonates et d'évaporites. La majorité du bassin était encerclé par des plates-formes de carbonate au crétacé inférieur et son flanc occidental était engagé dans une déformation compressive, à la fin du crétacé et au début du Tertiaire. Cet épisode compressif, l'Orogenèse laramienne, est à l'origine de la création de la Sierra Madre orientale, à l'est du Mexique.

Christophe Colomb est crédité de la découverte des Amériques, mais au cours de ses quatre voyages, aucun de ses bateaux n'a jamais atteint le golfe du Mexique. Colomb navigua plutôt dans la région des Caraïbes, autour de Cuba et Hispaniola.

La première exploration européenne du golfe est réalisée par Amerigo Vespucci, en 1497. Il suivit les lignes côtières d'Amérique centrale avant de rejoindre l'océan Atlantique par le détroit de Floride, entre la Floride et Cuba. Dans ses lettres, Vespucci décrit ce voyage et, une fois Juan de la Cosa revenu en Espagne, ils réalisèrent une carte du monde où Cuba était représentée comme une île.

En 1506, Hernán Cortés prit part à la conquête d'Hispaniola et de Cuba, ce qui lui rapporta une grande propriété ainsi que des esclaves (amérindiens) en récompense. En 1510, il accompagna Diego Velázquez de Cuéllar dans son expédition pour la conquête de Cuba. En 1518, Velázquez le plaça à la tête d'une expédition pour l'exploration et la sécurisation de l'intérieur du Mexique afin de préparer la colonisation.

En 1517, Francisco Hernández de Córdoba découvrit la péninsule du Yucatán. Ce fut la première rencontre avec une civilisation avancée aux Amériques, avec des bâtiments en dur et une organisation sociale complexe qui était comparable à celle de l'Ancien Monde. Ils avaient également des raisons de penser que ce territoire était riche en or. Tout ceci motiva le lancement de deux expéditions supplémentaires, en 1518 sous le commandement de Juan de Grijalva et en 1519 sous celui d'Hernán Cortés. Cette dernière conduisit à l'exploration espagnole, à l'invasion militaire et finalement à l'installation et la colonisation connue aujourd'hui sous le nom de conquête du Mexique. Hernández ne vécut pas assez longtemps pour voir la poursuite de son travail. Il mourut en effet en 1517 de ses blessures, de la soif extrême lors des voyages et de la déception quand il apprit que Velázquez avait privilégié Grijalva pour conduire l'expédition au Yucatán.

En 1523, naviguait jusqu'à Mexico quand son navire s'échoua le long des côtes de l'île Padre, au large du Texas, en 1554. Lorsqu'un mot de la catastrophe atteint la ville de Mexico, le vice-roi demanda à ce qu'une flotte de secours soit immédiatement envoyée et ordonna à Villafañe de retrouver le trésor des navires. Villafañe voyagea jusqu'à Pánuco où il loua un navire de transport. Il arriva en même temps que García de Escalante Alvarado (le neveu de Pedro de Alvarado), commandant de l'opération de sauvetage, le . L'équipe travailla jusqu'au 12 septembre pour tenter de retrouver le trésor. Cette perte, ainsi que le grand nombre de catastrophes maritimes dans le golfe, conduiront à l'installation d'une colonie sur la côte nord du golfe pour protéger les expéditions et accélérer les opérations de sauvetage. En conséquence, l'expédition de Tristán de Luna y Arellano fut envoyée dans la baie de Pensacola, le .

Le , Charles "Quint" accorde à Pánfilo de Narváez le droit de revendiquer les côtes du golfe, à la suite de l"'expédition de Narváez". Le contrat lui laisse un an pour rassembler une armée, quitter l'Espagne, fonder au moins deux villes pouvant accueillir chacune une centaine de personnes et construire deux forteresses de plus le long des côtes. Le , ils débarquèrent au nord de ce qui est connu aujourd'hui sous le nom de baie de Tampa. Ils voyagèrent pendant deux jours vers le sud, à la recherche d'une grande rade que le capitaine Miruelo connaissait. Au cours de ces deux jours, l'un des cinq navires restants fut perdu sur la côte sauvage, mais on ne sait rien d'autre sur cette expédition.

En 1697, Pierre Le Moyne d'Iberville s'embarqua pour la France et fut choisi par le ministre de la Marine pour mener une expédition afin de retrouver l'embouchure du fleuve Mississippi et de coloniser la Louisiane que les Anglais convoitaient. La flotte d'Iberville appareilla de Brest le . Le , Iberville atteint l'île de Santa Rosa en face de Pensacola, fondée par les Espagnols. Il navigua ensuite jusqu'à la baie de Mobile et explora l'île de "Massacre Island", rebaptisée par la suite "Dauphin Island". Il jeta l'ancre entre l'île de Cat Island et Ship Island et, le , il explora le continent, Biloxi, avec son frère Jean-Baptiste Le Moyne de Bienville. Le , il acheva la construction d'un fort sur le flanc nord-est de la baie de Biloxi, à proximité de ce qui est aujourd'hui Ocean Springs. Ce fort était connu sous le nom de Fort Maurepas ou Vieux Biloxi. Quelques jours plus tard, le 4 mai, Pierre Le Moyne repartit pour la France en laissant son jeune frère, Jean-Baptiste, comme commandant en second du commandant français.

Les côtes est, nord et nord-est du golfe s'étendent le long des États américains de Floride, d'Alabama, du Mississippi, de Louisiane et du Texas. Cette ligne côtière s'étend sur et reçoit les eaux de 33 fleuves majeurs ayant traversé 31 États. Les côtes du sud et du sud-ouest s'étendent le long des États mexicains de Tamaulipas, Veracruz, Tabasco, Campeche, Yucatán et de Quintana Roo. Au sud-est se retrouve l'île de Cuba.

Les bords du plateau continental du Yucatán et de Floride baignent dans des eaux plus fraîches et plus riches en nutriments grâce au phénomène de remontée d'eau. La croissance du plancton est ainsi stimulée dans la zone photique, ce qui attire poissons, crevettes et calmars. Le drainage des fleuves ainsi que les retombées atmosphériques en provenance des installations industrielles des villes côtières fournissent également des nutriments à la zone. De ce fait, le golfe soutient les industries de pêche américaine, mexicaine et cubaine.

Le "Gulf Stream", un courant chaud de l'océan Atlantique et l'un des plus forts courants marins connus, prend son origine dans le golfe, dans la continuité de la boucle de courant Caraïbes-Yucatán. Les autres caractéristiques de courants océaniques incluent des vortex anticycloniques qui sont générés par la boucle et qui se déplacent vers l'ouest où ils finissent par se dissiper. On trouve également un vortex cyclonique dans la baie de Campeche.

Le littoral du golfe est truffé de nombreuses petites baies et criques. De nombreux fleuves s'y jettent, et plus particulièrement le fleuve Mississippi dans le nord du golfe, ainsi que le río Grijalva et le río Usumacinta dans le sud. Les terres qui forment la côte du golfe (y compris les nombreuses barrières d'îles longues et étroites) ont une faible altitude et se caractérisent par la présence de marécages et de mangroves, ainsi que de plages de sable. Le golfe du Mexique est un excellent exemple de marge passive. Le plateau continental est relativement large à plusieurs endroits de la côte, notamment au niveau de la Floride et de la péninsule du Yucatán.
L'eau chaude du golfe peut alimenter de puissants ouragans prenant naissance dans l'Atlantique et causant de lourdes pertes humaines et matérielles, comme ce fut le cas avec l'ouragan Katrina en 2005. Dans l'océan Atlantique, un ouragan a tendance à faire remonter à la surface l'eau froide des profondeurs, ce qui diminue la probabilité qu'un autre ouragan suive dans son sillage (car une eau chaude est une condition préalable à la formation d'un ouragan). Toutefois, la faible profondeur des eaux du golfe implique une colonne d'eau relativement chaude. En conséquence, quand un cyclone passe au-dessus, même si la température de l'eau peut vite descendre, elle rebondit généralement tout aussi rapidement et peut ainsi être le berceau d'une autre tempête tropicale.

Bien que la zone du golfe soit considérée comme asismique, de légers tremblements de terre ont été enregistrés au cours de l'histoire (en général moins de 5,0 sur l'échelle de Richter). Le , un tremblement de 6,0 a été enregistré à au large des côtes de la Floride. Celui-ci n'a causé aucun dégât, mais il a été ressenti dans tout le Sud des États-Unis. Des séismes de ce genre peuvent causer des interactions entre la charge des sédiments sur le fond sous-marin et l'ajustement de la croûte terrestre. Les forages pétroliers et l'extraction de gaz pourraient être à l'origine de petits séismes.

La circulation dans le golfe du Mexique et les Caraïbes est similaire à un demi cul-de-sac. La circulation de surface forme une boucle, venant de l'Ouest de Cuba et repartant par le Sud de la Floride. Cette boucle peut, selon les périodes, pénétrer très peu dans le golfe ou au contraire profondément. Dans ce dernier cas, les courants forment des tourbillons (dans le sens des aiguilles d'une montre) et se déplaçant durant la saison vers le sud-sud-ouest. Ils perdent peu à peu leur énergie en se déplaçant. Ce cycle se reproduit tous les 6 à 11 mois.

Le plateau est surtout exploité pour le pétrole grâce à des plates-formes de forage en mer, dont la plupart sont situées à l'ouest du golfe et dans la baie de Campeche. Une autre importante activité commerciale est la pêche : vivaneau rouge, sériole, perche-tuile, espadon et mérou, mais aussi crevette et crabe. Les huîtres sont également récoltées à grande échelle dans beaucoup de baies et de bras de mer. Parmi les autres industries présentes le long des côtes, on retrouve la navigation maritime, la pétrochimie, la papeterie, la gestion d'entrepôts, des activités militaires et le tourisme.



</doc>
<doc id="14501" url="https://fr.wikipedia.org/wiki?curid=14501" title="Règle de L'Hôpital">
Règle de L'Hôpital

En mathématiques, et plus précisément en analyse, la règle de L'Hôpital (également appelée théorème de l'Hospital ou règle de Bernoulli) utilise la dérivée dans le but de déterminer les limites difficiles à calculer de la plupart des quotients. Le théorème de Stolz-Cesàro est un résultat analogue concernant des limites de suites, mais utilisant les différences finies au lieu de la dérivée.

La règle porte le nom d'un mathématicien français du , Guillaume François Antoine, marquis de L'Hôpital, qui a publié l"'Analyse des infiniment petits pour l'intelligence des lignes courbes" (1696), premier livre de calcul différentiel à avoir été écrit en français. La règle de L'Hôpital apparaît dans cet ouvrage et constitue la prop.1 de la , §163, p. 145 : l'objet de cette proposition consiste à donner la valeur d'une quantité formula_1 dépendant d'une variable formula_2 pour la valeur formula_3 de cette variable, lorsque formula_1 s'écrit comme une fraction dont le numérateur et le dénominateur s'annulent tous deux en formula_3.

L'auteur de la règle est sans doute Jean Bernoulli, car L'Hôpital payait à Bernoulli une pension de 300 francs par an pour le tenir informé des progrès du calcul infinitésimal, et pour résoudre les problèmes qu'il lui posait (comme celui de trouver la limite des formes indéterminées) ; de plus, ils avaient signé un contrat autorisant L'Hôpital à utiliser les découvertes de Bernoulli à sa guise. Quand L'Hôpital publia son livre, il reconnut ce qu'il devait à Bernoulli, et, ne voulant pas se voir attribuer son travail, publia anonymement. Bernoulli prétendit alors être l'auteur de l'ouvrage entier, ce qui fut longtemps cru, mais la règle n'en fut pas moins nommée d'après L'Hôpital, bien qu'il n'ait jamais prétendu l'avoir inventée.

Soit formula_3 réel ou égal à formula_7, tel que les fonctions réelles formula_8 et formula_9 soient définies et dérivables « au voisinage » de formula_3, la dérivée de formula_9 ne s'y annulant pas. Si nous essayons de déterminer la limite en formula_3 du quotient formula_8/formula_9, où le numérateur et le dénominateur tendent soit les deux vers zéro, soit les deux vers l'infini, alors nous pouvons dériver le numérateur et le dénominateur et déterminer la limite du quotient des dérivées. Si elle existe, la règle affirme que cette limite sera égale à la limite cherchée.

La règle, pour formula_8 et formula_9 définies (au moins) sur un intervalle d'extrémités formula_3 et formula_18, est exposée ici pour des limites à droite en formula_3 avec <math>-\infty \leq a. Elle est bien sûr transposable à gauche avec <math>b et la règle bilatérale, pour des limites épointées en un réel formula_3, se déduit de la conjonction de ces deux règles latérales.

Dans l'ouvrage de M. de l'Hôpital, la règle qui apparaît est celle communément utilisée dans le cas de deux fonctions dérivables en formula_3 et telles que le quotient formula_22 soit défini : 

La règle de l'Hôpital a été généralisée à des situations où formula_8 et formula_9 sont supposées définies et dérivables à droite de formula_3 (ou à gauche de formula_18), mais pas en formula_3 (formula_3 pouvant être réel ou infini). La première généralisation s'applique à des fonctions formula_8 et formula_9 dont la limite en formula_3 est nulle et la seconde à des fonctions formula_8 et formula_9 pour lesquelles la limite en formula_3 est infinie.

Il est en fait possible de démontrer la généralisation 2 sans utiliser l'hypothèse formula_35. Aussi seule l'hypothèse formula_36 est-elle nécessaire, ce qui permet d'étendre le domaine d'application de la règle de l'Hôpital à des cas d'indétermination autres que formula_37, entre autres si formula_8 n'admet pas de limite en formula_3.

Ces deux généralisations sont valides que formula_40 soit une limite réelle ou infinie. Leur démonstration utilise le « théorème de la moyenne de Cauchy » (cf. théorème des accroissement finis généralisé), avec plus de précaution pour la seconde.

La règle n'est utilisable qu'en cas d'indétermination. Par exemple

Dans le cas d'indétermination de la forme « 0/0 », l'énoncé simple peut souvent être utilisé, ou — comme dans la démonstration du théorème d'« intégration » terme à terme d'un développement limité — la première généralisation.

Dans le cas d'indétermination de la forme « », c'est la seconde généralisation que l'on va employer :

Parfois, il faudra utiliser plusieurs fois la règle de l'Hôpital pour parvenir au résultat :

Certaines limites, qui n'apparaissent pas comme des limites de quotients, peuvent être obtenues avec cette règle :

On remarquera que les formes généralisées ne donnent que des conditions suffisantes d'existence de la limite. Il existe donc des cas où la limite du quotient des dérivées n'existe pas et pourtant la limite du quotient des fonctions existe : 
alors que

Enfin, on prendra soin de vérifier que formula_48 est bien non nul au voisinage de formula_3, sinon la règle n'est pas applicable. Par exemple, si 
alors
donc

mais



</doc>
<doc id="14503" url="https://fr.wikipedia.org/wiki?curid=14503" title="Manifestations de la place Tian'anmen">
Manifestations de la place Tian'anmen

Les manifestations de Tian'anmen se déroulèrent entre le 15 avril 1989 et le 5 juin 1989 sur la place Tian'anmen à Pékin, la capitale de la république populaire de Chine. Elles se sont conclues par une vague de répression, parfois englobée sous l'expression de massacre de la place Tian'anmen. Cet événement politique, le plus important de l'après-révolution culturelle, prit la forme d’un mouvement d'étudiants, d'intellectuels et d'ouvriers chinois, qui dénonçaient la corruption et demandaient des réformes politiques et démocratiques. La contestation s'étendit à la plupart des grandes villes, comme Shanghai, et aboutit à Pékin à une série de grandes manifestations et de grèves de la faim organisées sur la place Tian'anmen. Après plusieurs tentatives de négociation, le gouvernement chinois instaura la loi martiale le 20 mai 1989 et fit intervenir l'armée le 4 juin 1989.

La répression du mouvement provoqua un grand nombre de victimes civiles (de quelques centaines à dix mille selon les sources), et de nombreuses arrestations dans les mois qui suivirent. Plusieurs dirigeants politiques favorables au mouvement furent limogés et placés en résidence surveillée, notamment le secrétaire général du Parti communiste chinois, Zhao Ziyang. Par la suite, un coup d'arrêt durable fut porté aux réformes politiques en république populaire de Chine. Le gouvernement expulsa les journalistes étrangers et contrôla strictement la couverture de l’évènement par la presse chinoise. À l'étranger, la répression provoqua une condamnation générale du gouvernement chinois.

En Chine, ce mouvement social, le plus important de l'après-révolution culturelle, est connu sous le nom de () ou simplement (). Cette désignation est calquée sur celle de deux autres manifestations : celle du 4 mai 1919 (nommée le ) et celle du 5 avril 1976 (le ). Cependant, le terme officiel utilisé par le gouvernement de la république populaire de Chine est (). Dans le reste du monde, il est appelé (), () ou encore (). En France, on parle également du , par analogie avec le Printemps des peuples ou avec le printemps de Prague.

L'expression « 4 juin » étant taboue et censurée, les internautes chinois en ont inventé une autre, « 35 mai », pour contourner cette censure chinoise de l'Internet.

Dans les années 1970, la jeunesse chinoise exprime sa comme lors du manifeste de Canton contre la révolution culturelle en 1974 ou lors du Printemps de Pékin en 1978 et son mur de la démocratie. Plusieurs mouvements semblables aux manifestations étudiantes de 1989 se déroulent en 1983, 1985, puis au cours de l'hiver 1986-1987. Au-delà des demandes de réformes politiques, les principales revendications portent alors sur la liberté d'association (création de syndicats étudiants indépendants) et sur la transparence (notamment sur les revenus des cadres et de leur famille).

À partir de la fin des années 1970, la République populaire de Chine est dirigée par Deng Xiaoping, qui a su placer ses fidèles à la tête du PCC et de l'État. Deng a notamment convaincu le PCC de moderniser le pays en lançant les (industrie, agriculture, sciences et technologies et défense nationale) et en ouvrant le pays aux investissements étrangers. En 1989, ce climat politique relativement ouvert encourage des professeurs de l’enseignement supérieur, des intellectuels et des étudiants à réclamer la , celle de la démocratie et du multipartisme, déjà réclamée lors du printemps de Pékin (1979). Ces intellectuels sont également influencés par la "glasnost" mise en œuvre en URSS par Mikhaïl Gorbatchev. Des étudiants dénoncent l’insécurité qui règne sur les campus, le manque de débouchés et le népotisme en faveur des enfants des membres du Parti. Des enseignants regrettent de ne pas être mieux payés. Des pétitions circulent qui réclament la libération des prisonniers politiques. Vivement réprimées à l'origine, ces idées reçoivent, vers le milieu des années 1980, un accueil plus favorable de la part des réformistes proches de Deng Xiaoping, notamment Hu Yaobang et Zhao Ziyang, secrétaire général et Premier ministre chinois jusqu'en 1987. À l'intérieur du Parti communiste chinois, deux lignes s'affrontent à la fin des années 1980. Derrière Deng Xiaoping, demandent une accélération des réformes, tant économiques que politiques. À l'opposé, et face à la montée de l'inflation provoquée par la libéralisation des prix, les adversaires traditionnels de Deng Xiaoping, notamment l'économiste Chen Yun, prônent un arrêt des réformes, voire un retour au contrôle de l'État. Jusqu'en 1986, Deng Xiaoping s'entoure principalement de réformistes, notamment Hu Yaobang et Zhao Ziyang.

Cependant, les manifestations étudiantes de 1986-1987 renforcent les partisans d'un arrêt des réformes et poussent Deng Xiaoping à limoger Hu Yaobang, alors secrétaire général du Parti, et à prendre comme Premier ministre Li Peng, un protégé de Chen Yun. L'ancien Premier ministre, Zhao Ziyang, proche de Hu, prend la tête du Parti. La direction chinoise se trouve alors divisée entre deux tendances : réformistes (avec Zhao) et conservateurs (avec Li). Les dissensions entre ces deux groupes jouent un rôle déterminant dans le mouvement de 1989. Ces divergences au sommet se retrouvent également à l'intérieur de la société. La seconde moitié des années 1980 voit une accélération de l'inflation et une augmentation du chômage, situation qui oppose des ouvriers, souhaitant un retour à l'ancien système, à plusieurs intellectuels, qui, eux, souhaitent une accélération des réformes.

L'ancien secrétaire général du Parti communiste chinois, Hu Yaobang, limogé en 1987, meurt le 15 avril 1989, des suites d'une crise cardiaque. Il est admiré pour le courage dont il a fait preuve à la fin de la révolution culturelle et le rôle qu'il a joué dans les réformes. Des manifestations spontanées ont lieu dans tout le pays et le gouvernement organise en son honneur des funérailles nationales le 22 avril. Les 16 et 17 avril, d'autres rassemblements spontanés se font jour place Tian'anmen, demandant la réhabilitation politique de Hu Yaobang. Le 18, quelques milliers d'étudiants et de civils se rendent sur la place où ils organisent un "sit-in" devant le Grand Palais du Peuple (l'assemblée nationale). C'est la première grande manifestation. Un seul journal national, le "Quotidien des Sciences et Technologies" () en rend compte le lendemain. Le 18 avril dans la soirée, quelques milliers d'étudiants tentent de pénétrer au Zhongnanhai, lieu de résidence du gouvernement. Ils sont repoussés par la police. Les campus se couvrent d’affiches réclamant la poursuite des réformes et critiquant Deng Xiaoping.

Dans la nuit du 21 au 22 avril, veille des funérailles officielles de Hu Yaobang, quelque se dirigent vers la place Tian'anmen, où ils s'installent avant qu'elle ne soit bouclée par la police. L'important rassemblement, interdit par les autorités, a lieu devant le monument aux héros du peuple. Une délégation demande à assister aux obsèques. À Pékin, ces rassemblements sont pacifiques, mais apparaissent des slogans réclamant une réforme politique, reprenant en cela ceux des manifestations de 1986-1987 qui avaient provoqué la chute de Hu Yaobang. Le 22 avril, les étudiants demandent à voir Li Peng, considéré comme le rival de Hu Yaobang. Le même jour, des manifestations dégénèrent en province à Xi'an et Changsha. À Shanghai, le 19 avril, le "" (), magazine proche des réformistes, prépare pour son numéro à paraître le 24 avril un dossier consacré à Hu Yaobang, dans lequel un article de Yan Jiaqi doit rendre compte de la manifestation du 18 avril à Pékin et demander une réévaluation du limogeage de Hu. Le 21 avril, un responsable du parti communiste de Shanghai demande à son rédacteur en chef Qin Benli de modifier ou supprimer cet article. Comme celui-ci refuse, il se tourne vers le secrétaire du Parti, Jiang Zemin, qui intervient alors pour le faire interdire. Entre temps, quelques exemplaires sont diffusés, les autres paraissant avec une page blanche. En représailles, l'éditeur en chef est limogé, et le magazine mis sous tutelle du parti communiste de Shanghai.

Le 26 avril, un éditorial du "Quotidien du Peuple" qualifie les manifestations étudiantes de , fait d'un « très petit nombre ». Toute nouvelle manifestation est interdite. Dès le soir du 26, l'agitation est forte dans les universités de la capitale, notamment à l'université de Pékin et à l'université du peuple de Chine. Les étudiants refusent la tutelle des associations universitaires qui sont entre les mains du Parti communiste chinois, fondent leur propre association autonome et se choisissent des représentants. Les jours suivants, de grandes manifestations ont lieu à Pékin. Le 27 avril, elles rassemblent quelque personnes. Le mouvement dénonce pêle-mêle la corruption, les inégalités sociales et l'absence de libertés. Il s'étend également en province et se développe lorsque les ouvriers le rejoignent afin de remettre en cause la corruption du régime et de protester contre l’inflation, le chômage et le luxe dans lequel vivent les cadres du PCC.

Le 4 mai, la manifestation commémorative du Mouvement du 4 mai se mêle à celle des étudiants et se déroule dans le calme et la bonne humeur. D’autres grandes manifestations s'organisent dans les grandes villes du pays comme Urumqi, Shanghai et Chongqing. Plus tard, le mouvement touche Hong Kong, Taïwan et les communautés de la diaspora chinoise en Amérique du Nord et en Europe. Peu après, le dirigeant soviétique Mikhaïl Gorbatchev doit effectuer à Pékin sa première visite en tant que chef d'État, ce déplacement entraîne la présence de nombreux journalistes étrangers venus couvrir le moment historique. La visite tourne court, de plus, Gorbatchev doit être escorté par des chemins détournés pour éviter qu'il ne voie les manifestations. Le 12 mai, les étudiants entament une grève de la faim illimitée sur la place Tian'anmen, grève qui finira par concerner plus de 1 000 personnes.

Les manifestations et les grèves s'étendent à certains lycées d'autres villes et de nombreux étudiants font le voyage jusqu'à Pékin. Dans l'ensemble, la manifestation de la place Tian'anmen est bien organisée, avec, chaque jour, des marches d'élèves, venus des différents lycées de Pékin, qui témoignent de leur solidarité par le boycott des cours. En chemin et une fois arrivés, ces élèves chantent "L'Internationale", l'hymne socialiste mondial. Les étudiants font même parfois preuve de surprenants gestes de respect envers le gouvernement, par exemple en aidant la police à arrêter trois hommes originaires de la province du Hunan, Yu Zhijian, Yu Dongyue et Lu Decheng, qui ont jeté de la peinture sur le portrait de Mao Zedong trônant au Nord de la place. Ces trois jeunes gens seront ensuite condamnés à des peines de prison, respectivement la perpétuité, 20 et 16 ans de réclusion. Deux d'entre eux, Yu Zhijian et Lu Decheng, seront libérés au bout de dix ans, et Yu Dongyue le sera après une détention de dix-sept ans.

Les étudiants décident d'entamer une grève de la faim. Cette décision marque un tournant décisif dans l'histoire des manifestations de 1989. La grève commence le 13 mai et comptera plus de mille participants. Cette grève assure au mouvement l'appui d'une large partie de la population. À Pékin, des manifestations de soutien, regroupant des étudiants, des ouvriers, des cadres et même parfois des policiers, ont lieu presque tous les jours, réunissant, à partir du 15 mai, plusieurs centaines de milliers de personnes. La presse nationale, encore relativement libre de couvrir les événements sans devoir propager la ligne du parti, rend compte des pourparlers qui sont tenus dans la soirée du 18 mai entre le Premier ministre Li Peng et les chefs de file étudiants. Au cours de ces entretiens, Wuer Kaixi, Wang Dan et autres accusent ouvertement le gouvernement d'être trop lent à réagir, et Li Peng est personnellement pris à partie pour son manque de sincérité dans la conduite de véritables discussions. Les pourparlers ne donnent que bien peu de résultats, mais permettent aux représentants étudiants d'apparaître à la télévision nationale chinoise.

Devant l'ampleur du mouvement, le parti communiste cherche quelle réponse lui apporter. La ligne officielle est que est le fait d'une minorité qu'il convient d'isoler du reste des étudiants. Deng, inquiet, déclare Alors que la grève de la faim se poursuit, de nombreuses organisations politiques et civiles expriment leur préoccupation envers les étudiants et la sympathie que beaucoup éprouvent pour leurs prises de position. La Croix-Rouge chinoise mobilise un important personnel pour apporter une assistance médicale aux grévistes de la faim. Quelques tentatives de négociation avec le gouvernement et la direction du parti n'apportent que peu de résultats. En raison de la visite de Mikhaïl Gorbatchev, les médias étrangers sont présents en grand nombre, leur couverture des manifestations est exhaustive et, de façon générale, favorable aux manifestants. Le Comité permanent du bureau politique du parti communiste de Chine, avec les anciens du parti (des anciens fonctionnaires du gouvernement et du parti à la retraite, mais encore influents), entretiennent d'abord l'espoir que les manifestations seront de courte durée, ou alors que des réformes cosmétiques et quelques enquêtes devraient satisfaire les protestataires. Ils veulent, si possible, éviter la violence et s'appuient dans un premier temps sur l'appareil du parti pour essayer de persuader les étudiants de retourner à leurs études. Obstacle de taille à cette action, la direction elle-même soutient bon nombre des revendications étudiantes, en particulier le souci de la corruption. Cependant, le fait qu'il existe autant de programmes que de manifestants ne permet au gouvernement ni de savoir avec qui négocier, ni sur quelles revendications discuter. La confusion et l'indécision des manifestants trouvent leur corollaire dans celles du gouvernement, ce que relaient les médias officiels.

Parmi les plus hauts dirigeants, le secrétaire général Zhao Ziyang penche fortement pour une approche en douceur, tandis que Li Peng plaide plutôt en faveur de la répression. En définitive, la décision d'intervenir par la force est prise par un groupe d'anciens du Parti, qui voient dans l'abandon du régime du parti unique un retour du chaos de la révolution culturelle. Bien que la plupart de ces personnalités n'aient pas de postes officiels, elles sont à même de contrôler l'armée. Deng Xiaoping est président de la Commission militaire centrale et, à ce titre, peut déclarer la loi martiale. Yang Shangkun le président de la république populaire de Chine, malgré le rôle symbolique de son titre depuis la constitution de 1982, est juridiquement le commandant en chef des forces armées. Les sages du parti estiment que de longues manifestations représentent une menace pour la stabilité du pays. Les manifestants sont perçus comme des partisans du « libéralisme bourgeois » qui tire les ficelles en coulisses, et certains éléments au sein du parti se voient, eux, accusés de poursuivre des ambitions personnelles.

Au début du mouvement, les médias chinois ont une occasion rare de diffuser des actualités sans censure. La plupart des médias d'actualité sont libres d'écrire et de rendre compte de ce qui se passe à leur guise, en raison de l'absence de contrôle des gouvernements centraux et locaux. Les nouvelles se propagent rapidement à travers le pays. D'après les médias chinois, les étudiants et les travailleurs de plus de 400 villes, y compris en Mongolie-Intérieure s'organisent à leur tour et commencent à protester. La population se rend également dans la capitale pour rejoindre la manifestation sur la place Tian'anmen. Les étudiants de l'université de Shanghai descendent également dans la rue pour commémorer la mort de Hu Yaobang et pour protester contre certaines des politiques prônées par les dirigeants du pays. Dans de nombreux cas, ces comités sont soutenus par le parti des universités. Jiang Zemin, alors secrétaire municipal du parti communiste, s'adresse aux manifestants et exprime sa compréhension en tant qu'ancien étudiant, lui-même agitateur avant 1949. Mais en même temps, il ne tarde pas à purger les dirigeants du parti communiste qui soutiennent les étudiants et à envoyer des forces de police pour contrôler la rue.

À Hong Kong, le , plus de se rendent à l'hippodrome de Happy Valley pour un rassemblement appelé . De nombreuses célébrités de Hong Kong y chantent et expriment leur soutien aux étudiants de Pékin. Le lendemain, de personnes, soit le quart de la population avec, à leur tête, Martin Lee, Szeto Wah et d'autres représentants, défilent à travers la ville. Partout dans le monde, notamment lorsque s'y trouve une communauté chinoise, rassemblements et protestations sont organisés. De nombreux gouvernements, comme ceux des États-Unis et du Japon, émettent des avertissements recommandant à leurs ressortissants de ne pas se rendre en république populaire de Chine.

Les dirigeants chinois sont partagés. La faction conservatrice, menée par Li Peng, mais regroupant des responsables militaires tels que Yang Shangkun, désire une mise au pas autoritaire des contestataires. Deng Xiaoping, bien qu'étant l'initiateur des réformes politiques et économiques, se range du côté des conservateurs car il craint que les contestations ne mettent un frein aux réformes. Les réformistes, autour de Zhao Ziyang, souhaitent une solution négociée et pacifique. Tout au long du mois de mai, les contacts se succèdent et l'opinion générale dans les milieux estudiantins est qu'une solution sera trouvée. Cela semble confirmé lorsque Zhao Ziyang, accompagné de Li Peng, prononce le discours suivant :

Après ce discours, chacun est persuadé de l'imminence d'une solution négociée. Les appels à l'arrêt de la grève de la faim, voire à l'évacuation de la place Tian'anmen, se multiplient chez les étudiants. Un communiqué émanant du gouvernement est prévu pour le soir, ce qui, pense-t-on, doit mettre un terme pacifique au mouvement.

Au cours de la journée du 19 mai, Zhao Ziyang, favorable à un règlement négocié du conflit, est mis en minorité par les partisans d'une ligne dure, menés par Li Peng avec le soutien de Deng Xiaoping. Ce dernier reproche à Zhao son manque de discipline à la suite du discours qu'il a fait aux étudiants. Ce même soir, Deng signe l'ordre de loi martiale. Un haut gradé de l'armée, refusant de suivre cet ordre, est défait de son rang et envoyé à l'hôpital pour « retrouver sa santé ». Huit autres généraux affirment leur opposition à la loi martiale mais ne parviennent pas à l'empêcher. Finalement, à travers les haut-parleurs de la place Tian'anmen, Yuan Mu, porte-parole du gouvernement, annonce aux étudiants la proclamation de la loi martiale.

Zhao Ziyang est immédiatement limogé et placé en résidence surveillée où il restera jusqu'à sa mort. Ses proches collaborateurs tombent en disgrâce. Autour de Li Peng se retrouvent le président de la République, Yang Shangkun, et son frère Yang Baibing, très proches de l'Armée populaire de libération. Sitôt après l'annonce, des soldats de la , chargée de la défense de Pékin, prennent position autour de la capitale. À Pékin, les étudiants demeurent sur la place et dressent des barrages aux portes de la ville. Le 20 mai, l’armée recule devant les manifestants pacifistes. Chai Ling prend la direction de la coordination étudiante autonome. Le 30 mai, une statue de la « déesse de la Démocratie », rappelant la statue de la Liberté de New York, est érigée sur la place par les étudiants de l'Académie des Beaux-Arts.

Environ militaires de 22 divisions provenant de 13 corps d'armée ont été transférés, depuis l'état de siège, dans la région de Pékin devant l'impuissance de la police armée du peuple à juguler les manifestations. Les soldats et les chars des et de l'Armée populaire de libération sont envoyés pour prendre le contrôle de la ville de Pékin. La est dirigée par le fils de Yang Shangkun. Lors d'une conférence de presse, le président américain George H. W. Bush annonce des sanctions contre la République populaire de Chine, à la suite des appels à l'action des membres du Congrès tels que le sénateur américain Jesse Helms. Le président se réfère à des renseignements qu'il a reçus, selon lesquels existent une certaine désunion dans les rangs militaires chinois et même la possibilité d'affrontements au sein de l'armée. Les rapports indiquent également que les unités 27 et 28 viennent de l'extérieur car l'Armée populaire de libération des provinces locales est considérée comme sympathisante de la protestation et de la population de la ville. Les auteurs de ces rapports apportent des éléments corroborant la thèse que la est la principale responsable des décès de civils. Après son attaque sur la place, la aurait établi des positions défensives à Pékin — non pas destinées à contrer un soulèvement civil, mais comme pour se défendre contre de possibles attaques émanant d'autres unités militaires.

Le chef de station du KGB à Pékin envoie le 4 juin au matin le rapport suivant au directeur du KGB :

À noter que les chars qui tiraient sur les soldats de la région militaire de Pékin appartenaient au d'armée. Ils se sont affrontés notamment à des blindés de la appartenant au d'armée. Alors que la rumeur se répand selon laquelle des centaines de milliers de soldats se rapprochent des quatre coins de la ville, les Pékinois envahissent les rues pour leur barrer la route, comme ils l'avaient fait deux semaines auparavant. Les gens érigent des barricades à chaque grand carrefour. Les manifestants brûlent des bus publics et les utilisent comme barrages routiers. Vers , près des immeubles de Muxidi (qui abrite les hauts fonctionnaires du parti et leurs familles), les manifestants hurlent à l'encontre des soldats et certains leur jettent des pierres. Une colonne de véhicules est incendiée alors qu'elle tente de briser les barricades. Puis les soldats commencent à tirer à balles réelles sur les manifestants. Certaines personnes sont touchées dans leurs appartements. Les combats se poursuivent dans les rues qui entourent la place, les manifestants avançant à plusieurs reprises vers l’Armée populaire de libération (APL) et construisant des barricades avec des véhicules, tandis que les chars de l'APL forcent le passage, tirant à l'aveugle. Beaucoup de blessés sont sauvés par des conducteurs de rickshaw qui se sont aventurés dans le "no man's land" séparant les soldats et la foule, et conduisent les blessés dans des hôpitaux. Après l'attaque, la couverture télévisée montre en direct de nombreuses personnes portant un brassard noir en signe de protestation, la foule occupant les boulevards, ou encore s'attarde sur des véhicules ou des barricades encore fumantes. En quelques occasions, des officiers sont extraits des chars, puis battus, voire tués par les manifestants.

Pendant ce temps, l'APL établit systématiquement des postes de contrôle autour de la ville, poursuivant les manifestants et fermant l'accès du quartier universitaire. Sur la place elle-même, un débat s'instaure entre ceux, y compris Han Dongfang, qui veulent se retirer pacifiquement, et ceux qui, comme Chai Ling, souhaitent rester sur la place. Vers , l'armée atteint la place Tian'anmen et attend les ordres du gouvernement. Les soldats ont pour consigne de ne pas ouvrir le feu, mais aussi d'évacuer la place avant — sans exception ou retard. Ils font une dernière offre d'amnistie, valable si les quelques milliers d'étudiants restants se retirent. Vers , les chefs de file étudiants soumettent la question à un vote : quitter la place, ou rester et en subir les conséquences. Les transports de troupes blindés sillonnent les routes, tirant vers l'avant et sur les côtés. Des affrontements (tirs d'artillerie notamment) opposent aussi, selon le général Eyraud, ancien attaché militaire en Chine, la et la . Cela conforte l'idée que les divisions de la société chinoise n'épargnent pas l'armée. La reporter de la BBC Kate Adie parle de « tirs à l'aveugle » sur la place. Le journaliste Charlie Cole, témoin oculaire des événements, voit lui aussi des soldats chinois tirer dans la foule avec des fusils d'assaut de type 56 près d'un blindé venant d'être incendié, son équipage tué, de nombreux civils sont atteints. Les étudiants cherchant refuge dans des autobus en sont extraits par des groupes de soldats et battus à coups de matraque. Même ceux qui tentent de quitter la place sont assiégés et battus. Les meneurs, dont certains ont tenté d'ériger des barricades de fortune devant les blindés, déclarent avoir « supplié » les étudiants de ne pas utiliser d'armes (comme des cocktails Molotov) contre les soldats. Entre-temps, de nombreux étudiants, semble-t-il, hurlent : Vers quatre ou cinq heures le matin du 4 juin, Charlie Cole déclare avoir vu des chars investissant la place, broyant indifféremment véhicules et personnes. À le 4 juin, la place est vidée. Le matin du 5 juin, des manifestants tentent de pénétrer sur la place qui reste interdite et sont abattus par les soldats leur tirant dans le dos lorsqu'ils prennent la fuite. Ces faits se répètent à plusieurs reprises. Selon Alan Donald, ambassadeur du Royaume-Uni à Pékin, les blindés ont . Dans les jours qui suivent, l'armée occupe Pékin, des affrontements sporadiques ont encore lieu la nuit. Le mouvement étudiant est également réprimé en province et une purge sévère est menée dans tout le pays.

La répression est immortalisée dans les médias occidentaux par des séquences vidéo et des photographies devenues célèbres, telle celle de « l'homme de Tian'anmen » ou « Tank Man ». C'est un homme seul, vêtu d'une chemise blanche, debout devant une colonne de chars qui tente de quitter la place. Prise le 5 juin, alors que la colonne approche d'une intersection sur l'avenue Chang'an (avenue de la Paix éternelle), la séquence montre l'homme sans arme au beau milieu de la rue, arrêtant la progression des blindés. Comme le conducteur de char tente de le contourner, « Tank Man » se déplace selon sa trajectoire, continue de défier la colonne pendant quelques instants, puis grimpe sur la tourelle du char de tête afin de parler aux soldats. Après son retour à sa position initiale, l'homme est tiré sur le côté par un groupe de personnes, dont l'identité divise les témoins oculaires. Témoin de ce face-à-face, Jan Wong est convaincue que ce groupe est constitué de citoyens voulant l'aider à fuir, tandis que le journaliste Charlie Cole estime que « Tank Man » a probablement été exécuté après avoir été enlevé par la police secrète, hypothèse s'appuyant sur le fait que jamais le gouvernement chinois ne pourra le présenter pour faire taire les protestations. Le magazine "Time" l'appelle le « rebelle inconnu » ; l'homme est plus tard cité parmi les 100 personnes les plus influentes du . Le "tabloïd" britannique "Sunday Express" rapporte qu'il s'agirait d'un étudiant de 19 ans du nom de Wang Weilin, mais la véracité de cette affirmation est discutable. Dans un discours prononcé devant le Club du Président en 1999, Bruce Herschensohn — ancien assistant spécial du président Richard Nixon — a indiqué qu'il aurait été exécuté 14 jours plus tard. Dans "Le Blues de la Chine rouge : ma Longue Marche de Mao à maintenant", Jan Wong écrit que l'homme est toujours vivant et se cache en Chine continentale. La dernière déclaration officielle du gouvernement de la RPC sur « Tank Man » vient de Jiang Zemin lors d'une entretien de 1990 avec Barbara Walters. Interrogé sur son sort, Jiang a répondu que, selon lui, le jeune homme n'a pas été tué. Après la vague de coercition à Pékin du 4 juin, les manifestations se poursuivent dans une grande partie du pays pendant plusieurs jours. Hong Kong est également touchée, la population arbore à nouveau la couleur noire en signe de protestation. D'autres manifestations sont signalées à Guangzhou ou, sur une plus grande échelle, à Shanghai, associées à une grève générale. On manifeste également à l'étranger, où le brassard noir est de rigueur. Toutefois, le gouvernement reprend rapidement le contrôle. S'ensuit une purge politique au cours de laquelle des fonctionnaires ayant organisé ou toléré les manifestations sont démis de leurs fonctions, et les dirigeants étudiants emprisonnés. Selon Amnesty International, au moins 300 personnes ont été tuées le 5 juin dans la ville de Chengdu. À Chengdu, les troupes utilisent contre les civils des grenades assourdissantes, des matraques, des couteaux et des aiguillons électriques destinés au bétail. Les hôpitaux ont ordre de ne pas accepter les étudiants et, la seconde nuit, le service ambulancier est arrêté par la police.

L'explication officielle donnée par le gouvernement est que la majorité des manifestants étaient des criminels et des voyous, sans lien avec les étudiants, et que l’armée est intervenue pour sauver le socialisme en Chine. Selon d'autres sources, ce sont en majorité de jeunes étudiants qui ont participé au mouvement. Le fait qu'un nombre important d'étudiants aient été arrêtés dans les jours suivant les évènements du 4 juin semble corroborer cette dernière thèse. Selon le gouvernement, le seul endroit où les étudiants étaient majoritaires en 1989 était la place Tian'anmen, où étaient braquées toutes les caméras accourues pour filmer l'arrivée de Gorbatchev. Dans toutes les autres villes, Changsha, Xi'an, Taiyuan, Urumqi, etc., ce sont des ouvriers, des chômeurs, des lycéens, des travailleurs migrants, des voleurs, des anonymes qui ont « conduit » le mouvement. Les étudiants de Pékin n'étaient que la minorité que les gouvernants ont tenté de récupérer par la négociation.

Le nombre de morts et de blessés demeure incertain en raison des grandes divergences entre les différentes estimations. Selon Nicholas D. Kristof du "New York Times", si des Pékinois soupçonnent les troupes d'avoir brûlé de nombreux corps pour détruire toute preuve des massacres, il n'y a cependant aucun indice permettant de dire que cela s'est produit. Certaines des premières estimations sont fondées sur des rapports de la Croix-Rouge chinoise qui font état d'un chiffre de . Cependant, cet organisme dément avoir jamais fourni un tel chiffre. Selon un rapport de Frontline de PBS, ce chiffre a rapidement été écarté sous la pression du gouvernement, qui, lui, avance les chiffres de , dont des soldats, et de .

Selon Nicholas D. Kristof, . Le gouvernement soutient qu'il n'y a pas eu de victimes sur la place Tian'anmen proprement dite, bien que les vidéos prises à l'époque aient enregistré des coups de feu. Le Comité central du Parti communiste chinois et le Conseil d'État font valoir que les statistiques de base sont les suivantes : . . Yuan Mu, le porte-parole du Conseil d'État, indique qu'un total de 23 personnes sont mortes, pour la plupart des étudiants, avec un certain nombre d'autres personnes qu'il qualifie de « voyous ». Pour Chen Xitong, maire de Pékin, deux cents civils et plusieurs dizaines de soldats sont morts. D'autres sources font état de et blessés. En mai 2007, le membre de la Conférence consultative politique du peuple chinois en provenance de Hong Kong, Chang Ka-mun, précise qu'entre 300 et 600 personnes ont été tuées sur la place Tian'anmen. Il ajoute qu'.

Selon Jay Mathews, qui était le premier chef de bureau du "Washington Post" à Pékin, .

Dans son bilan du massacre, l'ambassadeur américain James Lilley note que les diplomates du département d'État américain ont vu les troupes ouvrir le feu sur des gens désarmés. Ces derniers, se fondant sur les visites effectuées dans les hôpitaux à la périphérie de Pékin, avancent le chiffre de plusieurs centaines de morts. Se focaliser sur les décès de la place Tian'anmen ne donne pas, en soi, une image exacte du carnage et de leur nombre global, des civils ayant été visés par des tirs dans les rues adjacentes. En outre, selon leur propre témoignage, des étudiants auraient été victimes de tirs après avoir quitté la place, en particulier dans la zone proche de la salle de concert de Pékin.

Estimations du nombre de décès provenant de différentes sources, par ordre décroissant :

À l'étranger, l'intervention militaire est sévèrement critiquée. Quelques mesures de rétorsion sont prises, la principale étant un embargo sur les ventes d'armes à la Chine — toujours en vigueur — de l'ONU. La CEE Les États-Unis décident de mettre un terme à la coopération militaire et de renseignement avec Pékin et ferment deux stations d'écoute le long de la frontière russe. La France décide de geler ses relations avec la Chine. Les marchés boursiers en Asie réagissent à la baisse.

À titre officieux, devant la violence de la répression des services de sécurité chinois, la CIA réagit avec l'opération "Yellow Bird", sur ordre de George H. W. Bush : en coordination avec la DGSE et le SIS, elle réussit à faire exfiltrer nombre de dissidents politiques chinois. Dans les six mois qui suivent la répression, grâce à des agents postés en Chine, à Hong Kong et à Macao, elle procure des refuges et des moyens d'évasion. Ainsi « disparaissent » les dissidents Li Lu, l'un des principaux organisateurs et représentants du mouvement estudiantin, et Wuer Kaixi, représentant étudiant d'origine ouïghoure, puis Wan Runnan et Yan Jiaqi. Il est estimé que des centaines de dissidents seront ainsi exfiltrés vers Hong Kong, et entre 200 et 250 personnes au total seront sauvées lors de cette opération. Alors que la condamnation est quasi unanime en Occident, certains pays, notamment en Asie, passent quasiment sous silence les événements. Le gouvernement indien ordonne à la télévision de consacrer une couverture minimale des manifestations pour ne pas compromettre ses relations avec la Chine, tout en faisant preuve d'une sorte d'empathie politique envers les événements. La Corée du Nord, Cuba, la Tchécoslovaquie et l'Allemagne de l'Est, entre autres, soutiennent le gouvernement chinois et dénoncent les manifestations. Les étudiants chinois de la diaspora chinoise manifestent dans plusieurs villes d'Europe, d'Amérique, du Moyen-Orient et d'Asie.

En France, François Mitterrand déclara . Lors du 14 juillet 1989, à l'occasion du bicentenaire de la Révolution, à l'initiative de Jack Lang organisateur de la manifestation, plusieurs étudiants chinois exfiltrés avec "Yellow Bird", assistent au défilé de Jean-Paul Goude. Ainsi Wuer Kaixi, un des représentants étudiants des manifestations de la place Tian'anmen, explique : . Par ailleurs des étudiants chinois en France étaient en début de cortège, le front ceint d’un tissu blanc en signe de deuil, un vélo à la main, entourant un tambour géant.
En 1992, le gouvernement chinois annonce 780 arrestations à la suite des événements alors qu'Amnesty International estime leur nombre à plusieurs milliers. Selon l'organisation Asia Watch, entre dix à trente mille personnes auraient été emprisonnées en Chine. En revanche, les étudiants – dont beaucoup sont issus de milieux relativement aisés et disposent de relations – reçoivent des peines beaucoup plus légères. Wang Dan, chef de file étudiant qui a complété la liste des personnes recherchées, passe sept ans en prison. Bon nombre des étudiants et du personnel universitaire impliqués sont définitivement stigmatisés politiquement, certains ne pourront jamais retrouver un emploi. D'autres parviennent cependant à s'échapper à l'étranger grâce à l'opération Yellow Bird basée à Hong Kong.

Pendant les quelques jours suivant les événements de Pékin, certains protestataires moins en vue organisent des actions dans d'autres villes. Des cérémonies commémoratives sont tenues, dès leur retour en cours, par des universitaires et des étudiants qui ont été les témoins des tueries de Pékin. À la prestigieuse université Jiao-tong de Shanghai, par exemple, le secrétaire du parti organise une cérémonie commémorative publique, pour laquelle les élèves ingénieurs fabriquent une grande gerbe de fleurs métalliques. Cependant, ces commémorations sont interdites les années suivantes et leurs organisateurs démis de leurs fonctions.

Pendant et après la manifestation, les autorités tentent d'arrêter et de poursuivre en justice les chefs de file étudiants du Mouvement démocratique chinois, notamment Wang Dan, Chai Ling, Zhao Changqing et Wu'erkaixi. Wang Dan est arrêté, condamné et envoyé en prison, avant d'être libéré pour raison médicale et d'émigrer aux États-Unis. Figure moins éminente des événements, Zhao est relâché après six mois de prison. Il sera cependant de nouveau incarcéré pour avoir continué à adresser des pétitions en faveur d'une réforme politique. Wuer Kaixi s'échappe à Taïwan. Il se marie et devient commentateur politique à la radio nationale taïwanaise. Chai Ling s'échappe en France puis aux États-Unis. Dans un discours public donné à l'université du Michigan en novembre 2007, Wang Dan commente la situation actuelle des anciens chefs de file étudiants. Chai Ling, qui a monté une entreprise hi-tech aux États-Unis, a été autorisé à revenir en Chine et à y faire des affaires. Li Lu est devenu banquier d'investissement à Wall Street et a créé sa propre firme. Wang Dan envisage une carrière universitaire après avoir obtenu son Philosophiæ doctor (PHd) à l'université Harvard, tout en désirant retourner en Chine si cela lui est permis. Yu Dongyue, un journaliste chinois, est condamné à 20 ans de prison, pour avoir jeté de l'encre sur un portrait géant de Mao Zedong le 23 mai 1989. Il sera libéré en février 2006.

Les dirigeants du parti expulsent Zhao Ziyang du Comité permanent du bureau politique du Parti communiste chinois (CPBP), pour son opposition à la loi martiale. Zhao est assigné en résidence surveillée jusqu'à sa mort. Hu Qili, l'autre membre du CPBP qui s'est opposé à la loi martiale mais qui s'est abstenu de voter, est également exclu du comité. Il est cependant autorisé à demeurer membre du parti et, après un « changement d'opinion », il est nommé vice-ministre de la Construction mécanique et de l'Industrie électronique. Le dirigeant réformiste Wan Li aurait également placé en résidence surveillée dès sa descente d'avion à l'aéroport international de Pékin, à son retour d'un voyage abrégé à l'étranger pour, motif officiel, « raisons médicales ». Lorsque Li Wan est libéré de son assignation à résidence après avoir enfin « changé d'avis », comme Qiao Shi, il est muté sur un autre poste de rang égal, mais avec un simple rôle de représentation. Plusieurs ambassadeurs chinois à l'étranger demandent l'asile politique.

Les séquelles des événements permettent à Jiang Zemin, alors maire de Shanghai, de devenir secrétaire général du Parti communiste chinois. Ses prises de position catégoriques à Shanghai (interdiction des publications à tendance réformiste et prévention de la violence meurtrière) lui valent le soutien d'anciens du parti à Pékin. Les membres du gouvernement préparent un livre blanc présentant le point de vue officiel sur les manifestations. Une source gouvernementale anonyme exfiltre ce document à l'étranger, et il est publié en sous le nom de "Documents de Tian'anmen". Il comporte une citation de l'aîné du PCC, Wang Zhen, faisant allusion à la réaction officielle face aux manifestations.

Les dissensions dans l'armée ont conduit au moins une dizaine de généraux en cour martiale. officiers ont fait l'objet d'une enquête et au moins 111 ont été punis ainsi que hommes du rang qui avaient refusé de participer à la répression.

Pour s'être montrés plutôt favorables aux mouvements des étudiants, la plupart des dirigeants des médias d'État sont licenciés. Deux animateurs ayant couvert les événements du 4 juin au journal de 19h à la Télévision centrale de Chine sont démis de leurs fonctions. Le motif invoqué est qu'ils ont fait montre de leurs émotions lors de l'émission. Wu Xiaoyong, fils d'un membre du Comité central du Parti communiste chinois, ancien ministre des Affaires étrangères et vice-Premier ministre de Wu Xueqian, est renvoyé du département en anglais de la Radio Chine Internationale. Les rédacteurs et autres collaborateurs du "Quotidien du Peuple", le journal du Parti communiste chinois, y compris son directeur Qian Liren et son rédacteur en chef Tan Wenrui, sont démis de leurs fonctions en raison de reportages jugés trop favorables aux étudiants. Plusieurs éditeurs sont arrêtés, dont Wu Xuecan, responsable d'une édition non autorisée d"'Extra", qui est condamné à quatre ans d'emprisonnement.

Rob Gifford, journaliste de la National Public Radio, déclare qu'une grande partie des libertés politiques et d'expression ayant été octroyées après Mao et avant Tiananmen ont été remises en question après les événements. Par exemple, certains des auteurs du film "Rivière Elegy" (He Shang) sont arrêtés, et des écrivains sont obligés de fuir la Chine continentale. Gifford conclut que a interdit et interdit toujours « l'indépendance de l'esprit », qui selon la pensée officielle, conduirait à la remise en cause du système politique. Il ajoute que les personnes nées après 1970 sont « proches de la dépolitisation complète », tandis que des intellectuels plus âgés ne se préoccupent plus du changement politique, mais se concentrent plutôt sur les réformes économiques.

Les protestations de la Place Tian'anmen ont considérablement nui à la réputation de la république populaire de Chine en Occident. Les médias occidentaux, invités à couvrir la visite de Mikhaïl Gorbatchev en mai, se sont trouvés dans une situation privilégiée pour couvrir l'action militaire, par exemple sur les ondes de la BBC et de CNN. Les manifestants ont saisi cette occasion, créant des panneaux et des banderoles à l'adresse du public des télévisions internationales, rédigés en français et en anglais. Cette couverture médiatique a été facilitée par l'acuité des conflits qui ont régné au sein du gouvernement chinois sur la façon dont il convenait de répondre aux manifestations. Ainsi, à la suite des tergiversations, l'interruption des images diffusées s'est trouvée différée au lieu d'être interrompue dans l'instant.

En fin de compte, lors de la répression, tous les réseaux internationaux se sont trouvés contraints de mettre fin aux émissions en provenance de Pékin, la transmission satellitaire ayant été fermée par les autorités. Les radiodiffuseurs ont tenté de contourner ces ordres en correspondant par voie téléphonique. Ainsi certaines images clandestines sont rapidement sorties du pays, y compris celle de l'« homme de Tian'anmen ». Le seul réseau qui s'est montré capable d'enregistrer des images au cours de la nuit est celui de la Radio Télévision espagnole (TVE).

Le correspondant de CBS Richard Roth et son cameraman ont été emprisonnés pendant la répression. Roth a été placé en détention alors qu'il était en train de correspondre depuis la place via un téléphone mobile. La retransmission permet de l'entendre crier à plusieurs reprises d'une voix rauque quelque chose comme « Oh, non ! Oh, non ! », avant que la communication ne soit interrompue. Il a été ensuite libéré, souffrant d'une légère blessure au visage reçue lors d'une altercation avec des policiers chinois qui tentaient de lui confisquer son téléphone.

Tout au long ses années 1990 et du , ces reportages ternissent durablement l'image de la république populaire de Chine auprès de l'opinion mondiale, et l'image de la Chine réformatrice et alliée privilégiée contre l'URSS s'efface devant celle d'un régime autoritaire et répressif. Par voie de conséquence, les étudiants chinois séjournant en Occident se voient privilégiés. Presque aussitôt après la répression, les États-Unis et la Communauté économique européenne imposent un embargo sur les ventes d'armes. Et les manifestations de Tian'anmen sont désormais fréquemment invoquées pour s'opposer à la libéralisation du commerce avec la Chine continentale, et la "Blue Team" américaine en veut pour preuve que le gouvernement de la république populaire de Chine a toujours représenté une menace pour la paix mondiale et les intérêts américains.

En Chine, pendant ce temps, les médias d'État sont contraints de mettre l'accent sur les soldats qui ont trouvé la mort, n'hésitant pas à masquer pour ce faire de nombreuses images à la télévision. Chez les étudiants chinois résidant à l'étranger, les manifestations de la Place Tian'anmen ont conduit à la création de services d'actualité sur Internet, tels que "China News Digest" et l'organisation non gouvernementale "China Support Network". Au lendemain des événements, des organisations comme l'Alliance pour la démocratie en Chine et la Fédération indépendante des étudiants et lettrés chinois ont vu le jour, encore que ces structures aient perdu beaucoup de leur impact politique après la mi-1990.

Les manifestations de la place Tian'anmen ont réduit l'espoir d'une prochaine libéralisation politique des pays communistes, idée ayant gagné du terrain au cours des années 1980. De nombreuses réformes démocratiques proposées pendant ces années-là se sont vues balayées. Bien que la situation ait depuis évolué, notamment en ce qui concerne les libertés individuelles, les discussions sur les changements structurels du gouvernement de la république populaire de Chine et sur le rôle du Parti communiste chinois restent largement taboues. Contrairement aux attentes de l'Occident concernant un effondrement du système politique chinois au profit d'un régime démocratique, le Parti communiste chinois n'a pas relâché sa mainmise sur le pays, et le mouvement étudiant de Tian'anmen est resté sans suite.

À Hong Kong, les manifestations de la place Tian'anmen ont pu faire craindre que la Chine ne renonce à honorer ses engagements (« un pays, deux systèmes ») après la rétrocession de 1997. Le dernier gouverneur, Chris Patten, a cherché à élargir le droit constitutionnel du Conseil Législatif de Hong Kong, ce qui a conduit à des frictions avec la Chine. À partir de 1989 à Hong Kong, de nombreuses veillées aux chandelles ont été tenues par des dizaines de milliers de personnes, même après le transfert du pouvoir vers la RPC. Les manifestations ont également marqué un tournant dans les conventions régissant la vie politique chinoise. Auparavant, en vertu de la constitution de 1982, le Président avait un rôle essentiellement symbolique. Le pouvoir était réparti entre le président, le Premier ministre et le secrétaire général du Parti communiste chinois, postes tous destinés à des personnes différentes afin d'éviter les excès de la dictature de l'ère Mao Zedong. Toutefois, après que Yang Shangkun a fait usage de ses « pouvoirs de réserve » en mobilisant l'armée, la présidence a bénéficié d'un réel pouvoir. Par la suite, c'est une seule et même personne qui a occupé les postes de président et de secrétaire général du Parti, et, à ces deux titres, exercé le pouvoir exécutif.

En 1989, ni l'armée chinoise ni la police de Pékin n'avaient d'équipements anti-émeute, balles en caoutchouc et gaz lacrymogènes pourtant utilisés depuis longtemps dans les pays occidentaux. Après le massacre, la police anti-émeute des villes chinoises a été équipée de matériel non létal pour faire face à ce genre de confrontation. La reprise en main de la population a été menée avec une particulière diligence. Deng Xiaoping, silencieux pendant toute la durée des événements, s'exprime le 9 juin en un discours dans lequel il résume la position officielle du parti. Pendant les douze mois qui suivent, des commissions d'enquête sont créées pour interroger tous ceux qui ont pris part aux manifestations, ce qui marque la fin définitive des mouvements étudiants des années 1980.

Dès la fin de l'été, une série de campagnes de propagande est lancée autour de thèmes patriotiques, notamment le personnage de Lei Feng, et les Quatre Principes Cardinaux (Voie Socialiste, Dictature du Prolétariat, Marxisme-Léninisme Pensée Mao Tsé Toung, prééminence du parti communiste). Les médias qui se sont montrés favorables aux étudiants ou à Zhao Ziyang sont mis au pas. L'idée de réforme politique ou de démocratisation, envisagée jusque-là par certains éléments du Parti, est abandonnée.

Les événements de Tian'anmen ont eu un impact économique d'envergure sur la Chine. Les emprunts étrangers ont été suspendus par la Banque mondiale, la Banque asiatique de développement et les gouvernements. Les recettes touristiques sont passées de 2,2 à de dollars américains. Les engagements concernant des investissements à l'étranger ont été annulés et le budget de la défense accru de 8,6 % en 1986 à 15,5 % en 1990, renversant la tendance des dix dernières années. Le Premier ministre chinois Li Peng s'est rendu au Conseil de sécurité des Nations unies le , et a fait valoir que les sanctions économiques et l'embargo sur la vente d'armes à la Chine représentaient une violation de sa souveraineté.

Au lendemain des manifestations, certains membres du gouvernement chinois ont essayé de freiner les réformes conduisant à une libéralisation du marché qu'avait amorcées Deng Xiaoping, et de rétablir les contrôles administratifs sur toutes les transactions. Toutefois, ces tentatives se sont heurtées à la résistance des gouverneurs de province avant de s'effondrer au début des années 1990, à la suite de l'implosion de l'URSS et du voyage de Deng Xiaoping dans le sud du pays. La poursuite de la réforme économique a conduit à la croissance des années 1990, qui a permis au gouvernement de remonter sa cote de popularité. Les dirigeants responsables de la répression semblent avoir été progressivement remplacés, sans avoir, pour autant, été inquiétés .

Les figures de proue de 1989 se sont avéreés incapables de susciter un mouvement ou une idéologie cohérente et durable au-delà du milieu des années 1990. . Un certain nombre étaient socialistes. Bien des organisations pro-démocratiques (comme la FDC à Paris), créées au lendemain des événements, se sont effondrées en raison de querelles intestines et aussi, selon un rapport des services de renseignements canadiens, à cause de l'action des services secrets chinois, bien implantés dans la diaspora. Plusieurs militants démocrates résidant à l'étranger étaient en faveur de la limitation du commerce avec la Chine continentale, ce qui les a sensiblement compromis tant en Chine que parmi la communauté chinoise d'outre-mer. Un certain nombre d'ONG basées aux États-Unis continuent d'exiger des réformes démocratiques en Chine et à protester sans relâche contre les violations des droits de l'homme. Un des plus anciens, et aussi le plus éminent d'entre eux, le "China Support Network", a été fondé en 1989 par un groupe d'Américains et de Chinois militants en réponse à la répression de Tian'anmen.

Contrairement à la révolution culturelle, à propos de laquelle les Chinois peuvent facilement trouver livres, magazines ou sites web autorisés, le sujet des événements de Tian'anmen reste interdit par le gouvernement et n'est généralement pas traité par les médias. Des moteurs de recherche tels que Google et Yahoo ont dû, pour s'installer en Chine, adapter leurs programmes afin que soit barrée toute requête dérangeante. La simple mention de ces sujets sur des sites web ou des blogs chinois peut en entraîner la fermeture.

Les médias officiels considèrent que la répression militaire était nécessaire au maintien de l'ordre public. Comme les événements sont absents des programmes scolaires, les jeunes nés après eux ne connaissent son existence que par des rumeurs, ce qu'en disent les familles ou encore les médias étrangers. Les rares ouvrages sur le sujet écrits par des historiens chinois ont été publiés dans la région spéciale de Hong Kong (autonome jusqu'en 1997), et sont difficilement accessibles. Les sources occidentales sur le sujet ne sont pas diffusées en Chine. Chaque année, un grand rassemblement est organisé à Victoria Park, Hong Kong, en mémoire des victimes, et pour réclamer une inflexion de la position officielle. En 2008, la veillée a été couverte par la presse chinoise, mais a été détournée de son objet et utilisée pour illustrer un sujet concernant les victimes du tremblement de terre du Sichuan.

Des pétitions sont régulièrement lancées, notamment à l'initiative du Jiang Yanyong et des Mères de Tiananmen, organisation fondée par l'une des mères des victimes tuées en 1989, afin d'obtenir explications et dédommagements, ainsi que le droit de recevoir des dons en provenance de l'étranger. La place Tian'anmen est étroitement surveillée à chaque anniversaire du 4 juin pour éviter toute commémoration.

Après le remaniement gouvernemental de la république populaire de Chine de 2004, plusieurs membres du cabinet ont fait état de Tian'anmen. En octobre 2004, pendant sa visite en France, le président Hu Jintao a réitéré la position officielle, à savoir que . Il a insisté sur le fait que ce point de vue gouvernemental ne serait sujet à aucune modification.

En mars 2004, le Premier ministre Wen Jiabao a déclaré lors d'une conférence de presse, que, durant les années 1990, une tempête politique sévère s'est abattue sur la RPC, alors qu'implosait l'URSS et que des changements radicaux affectaient l'Europe de l'Est. Il a ajouté que le Comité central communiste a réussi à stabiliser la politique d'ouverture et a protégé le .

En 2009, pour le vingtième anniversaire de l'événement, la population chinoise a fait savoir qu'elle désirait s'entretenir ouvertement des événements et a réclamé l'ouverture d'une enquête<ref name="LM 2009/03/23">.</ref>. La réponse du gouvernement chinois a été de bloquer, les jours précédant l'anniversaire, l'accès aux réseaux sociaux tels que Twitter et Flickr, de même que celui du fournisseur Hotmail. Dans les aéroports, les marchands de journaux ont systématiquement retiré de l'"Economist" l'article commentant l'anniversaire du 4 juin. Zhang Shijun, ancien soldat qui avait 18 ans en 1989, a été arrêté après avoir publié une lettre ouverte à Hu Jintao, dans laquelle il demandait que s'ouvre une discussion publique sur le problème. Les gouvernements des régions administratives spéciales de Hong Kong et Macao ont refusé le retour des étudiants compromis dans les manifestations. Le , plusieurs employés d'une chaîne de télévision de Guangzhou ont été suspendus après avoir autorisé la diffusion de dix secondes d'une vidéo portant sur l'Homme de Tian'anmen et sur des veillées à la bougie tenues à Hong Kong.

L'explication officielle, fournie par Deng Xiaoping quelques jours après le 4 juin et inlassablement reprise depuis, est qu'un petit nombre d'émeutiers, pour l'essentiel des repris de justice et des chômeurs mécontents, avaient attaqué les soldats venus mettre de l'ordre sur la place Tian'anmen, et que l'armée avait dû se défendre. Selon cette thèse, il n'y a pas eu de morts sur la place et les victimes, de toute façon, n'étaient pas des étudiants. Le mouvement étudiant d'avril et mai est, pour sa part, qualifié de « trouble politique ».

En mai 2009, les mémoires posthumes de Zhao Ziyang sont publiés. Deng Xiaoping y est désigné comme le principal responsable de la répression.

En 2014, plusieurs personnalités, dont Pu Zhiqiang, Xu Youyu, Tang Jingling et la blogueuse dissidente Liu Do, sont inculpés de , (passible de cinq ans de prison), pour avoir célébré le vingt-cinquième anniversaire des manifestations.

En 2016, à l'occasion de l'anniversaire du 4 juin 1989, une dizaine de parents de victimes ont pu se rendre au cimetière mais sous contrôle des forces de l'ordre. Zhang Xianling, dont le fils de 19 ans a été abattu, précise : . L'ONG Human Rights in China a diffusé une lettre ouverte des Mères de Tiananmen : . Ding Zilin est de nouveau sous résidence surveillée avec sa ligne téléphonique coupée et un accès à son domicile contrôlé. À Taiwan, le parlement de la république de Chine a commémoré pour la les événements .

À la suite des manifestations, les instances gouvernementales interdisent les films et les livres sujets à controverse et réduisent de nombreux journaux au silence. En une année, 12 % de la presse écrite, 8 % des maisons d'édition, 13 % des périodiques de sciences sociales et plus de 150 films sont interdits ou fermés. Le gouvernement annonce également une saisie de 32 millions de livres de contrebande et de 2,4 millions de vidéos et cassettes audio.

Actuellement, en raison d'une mesure de censure émanant du gouvernement chinois et incluant la censure de l'Internet, les médias d'actualité ne sont pas autorisés à faire état des actions ou des événements concernant les manifestations. Les sites consacrés aux manifestations sont bloqués, du moins dans la Chine continentale. Une recherche Internet concernant les événements de 1989 ne donne aucun résultat ; en effet, seuls, les sites du "Quotidien du Peuple" ou autres médias étroitement contrôlés s'avèrent disponibles, et ils ne présentent que la version officielle des faits.

En janvier 2006, Google accepte de censurer son site en Chine, Google.cn, et supprime certaines informations relatives au massacre et à divers sujets tels que l'indépendance du Tibet, le Falun Gong et le statut politique de Taïwan. Lorsque les internautes effectuent des recherches sur les sujets censurés, le message suivant s'affiche en chinois en bas de page : .

En 2006, le programme américain "Frontine" sur PBS diffuse un extrait vidéo filmé à l'intérieur de l'université de Pékin, dont de nombreux étudiants ont en leur temps participé aux manifestations de 1989. Une photo de l'homme de Tian'anmen est montrée à quatre étudiants, mais aucun d'entre eux n'a pu identifier ce qui s’y passe. Certains ont répondu qu'il s'agissait d'un défilé militaire ou d'une œuvre artistique.

Le , le chef pro-Pékin de l'Alliance démocratique pour l'amélioration de Hong Kong, Ma Lik, s'est vu critiqué pour avoir déclaré qu'il « n'y a pas eu de massacre » pendant les manifestations, pas plus que de « tirs intentionnels et sans discernement ». Il avait ajouté que Hong Kong « n'était pas assez mature » et que la faute en était à l'influence que les médias étrangers exerçaient à propos de l'interprétation des événements de Tian'anmen, la ville montrant ainsi son manque de patriotisme et son peu de sens de l'identité nationale. Il en concluait qu'elle ne serait donc « pas prête pour la démocratie avant 2022 ». Ces remarques ont été vivement condamnées par le public. Plus tard, Ma Lik a reconnu qu'il s'était sans doute montré « téméraire et frivole » en proférant de tels propos, mais n'en a pas moins insisté sur le fait qu'à, Tien'anmen, il ne s'était pas agi d'un massacre. 

Le , jour de l'anniversaire du massacre, une lecture, « rendant hommage aux mères des victimes du 4 juin », est publiée par le journal "Chengdu Evening News". Cette parution entraîne le licenciement par le gouvernement chinois de trois éditeurs. Le secrétaire du bureau qui a approuvé cette publication n'aurait, selon les sources officielles, jamais entendu parler de la répression militaire du 4 juin, et aurait déclaré que la date en question était celle d'une catastrophe minière.

À la fin d'avril 2009, l'accès Internet aux événements de Tian'anmen, y compris les vidéos, les bulletins d'actualité et Wikipédia, a été pour la première fois censuré en Chine continentale pour les médias de langue anglaise. À cette occasion, les articles concernés ont à nouveau été censurés, principalement sur la version chinoise de Google, encore que certaines vidéos sont restées visibles. D'autre part, lors du des manifestations, des policiers en civil, équipés de parapluies, ont rendu impossible tout tournage de la place, en passant et repassant devant les caméras des journalistes postés à proximité.

En 2013, le sinologue Renaud de Spens considère qu'il n'existe plus d'internautes non informés de ces manifestations. Malgré « l’amnésie officielle », les Chinois multiplient les contournements concernant le « 35 mai » avec, par exemple, des montages photos ou des jeux de cartes.

L'embargo de l'Union européenne et les États-Unis sur les ventes d'armes à la république populaire de Chine mis en place à la suite de la répression est toujours en vigueur. La Chine appelle à une levée de l'interdiction depuis de nombreuses années, soutenue en cela par certains membres du Conseil de l'Union européenne dont le nombre varie selon les circonstances. Début 2004, la France prend l'initiative d'un mouvement au sein de l'Union européenne pour lever l'interdiction. L'ancien chancelier allemand Gerhard Schröder a publiquement ajouté sa voix à celle de l'ancien président français Jacques Chirac pour que l'embargo soit levé.

L'embargo a été l'un des sujets du sommet RPC-UE aux Pays-Bas entre le 7 et 9 décembre 2004. Dans la période qui a précédé le sommet, la RPC s'est efforcé d'accroître la pression sur le Conseil européen en faisant valoir que l'embargo pouvait altérer les relations qu'elle entretenait avec l'Union européenne. Le vice-ministre des Affaires étrangères chinois, Zhang Yesui, a qualifié l'interdiction de « dépassée » et a affirmé à la presse : . Finalement, le Conseil de l'UE n'a pas cédé. Le porte-parole européen François le Bail a déclaré qu'il existait encore des incertitudes quant à l'engagement de la RPC en faveur des droits de l'homme. Dans le même temps, l'UE a déclaré vouloir travailler avec la Chine pour parvenir à une levée de l'interdiction.

Jacques Chirac s'est engagé à lever l'interdiction pour le milieu de l'année 2005. Cependant, la loi antisécession que la RPC vote en mars 2005 accroît les tensions. Plusieurs membres de l'UE changent d'avis. Le Congrès américain menace l'UE de restrictions dans le transfert de technologie militaire en cas de levée. Le Conseil européen ne parvient pas à un consensus et, bien que la France et l'Allemagne aient œuvré contre l'interdiction, celle-ci est maintenue.

La Grande-Bretagne prend la charge de la présidence de l'Union européenne en juillet 2005, rendant impossible la levée de l'embargo pendant cette période. En effet, ce pays a toujours émis de sérieuses réserves sur le sujet, notamment afin de préserver la qualité des relations entre l'UE et les États-Unis. D'autre part, l'échec de la Constitution européenne et le désaccord qui en a suivi sur le budget européen et la politique agricole commune ont supplanté en importance la question de l'embargo. La Grande-Bretagne voulant profiter de sa présidence pour faire pression pour une réforme globale de l'UE, -la levée de l'interdiction en devient d'autant plus secondaire. L'élection de José Manuel Barroso comme président de la Commission européenne rend elle aussi une éventuelle levée des sanctions plus difficile. Lors d'une réunion avec les dirigeants chinois tenue à la mi-juillet 2005, Barroso déclare que le médiocre bilan de la Chine sur le plan des droits de l'homme justifie que le processus d'une modification de l'interdiction de ventes d'armes à la Chine soit mis en veilleuse.

De plus, certains changements politiques affectent la position de l'Union européenne sur le sujet. Schröder perd les élections fédérales allemandes de 2005 contre Angela Merkel, qui devient chancelière le . Cette dernière déclare son opposition à une levée de l'interdiction. Jacques Chirac ne se porte pas candidat à la présidentielle de 2007 ; son successeur, Nicolas Sarkozy, est lui aussi partisan de la levée de l'embargo. Pourtant, la politique étrangère de la France sur ce sujet reste inchangée. En outre, le Parlement européen s'y est toujours opposé. Bien que son accord ne soit théoriquement pas nécessaire, certaines voix se font entendre pour rappeler qu'il reflète mieux la volonté du peuple européen car ses membres sont directement élus, alors que le Conseil de l'UE est constitué de membres issus des différents États. L'opposition du parlement européen se manifeste par une série de résolutions dont la teneur ne varie guère :

L'embargo sur les armes a limité les options de la Chine dans sa recherche de matériel militaire. Elle s'est adressée à l'ancien bloc soviétique avec qui elle avait une relation tendue à la suite de la rupture sino-soviétique. Les autres fournisseurs incluaient dans un premier temps Israël et l'Afrique du Sud, mais la pression américaine a restreint leur coopération.

Bien que la responsabilité du gouvernement chinois n'ait jamais été reconnue, un a été effectué à la mère d'une des victimes en avril 2006. Il s'agit là du premier cas publié de dédommagement. Le versement, (environ ), a été qualifié d'assistance contrainte, donnée à Tang Deying dont le fils Zhou Guocong est mort à 15 ans lors d'une garde à vue à Chengdu le 6 juin 1989, deux jours après que l'armée chinoise eut dispersé les manifestants de Tiananmen. Ce geste a été salué par de nombreux activistes chinois, mais est considéré par d'autres comme destiné à garantir la stabilité sociale sans pour autant annoncer de changement dans la position officielle du Parti.

Le 21 novembre 2008, la Convention contre la torture de l'Organisation des Nations unies exhorte la Chine à présenter des excuses, à libérer les dissidents encore emprisonnés et à diligenter une enquête sur les événements survenus en marge des manifestations.


Certaines références aux événements se retrouvent dans de nombreuses paroles et couvertures d'albums, que ce soit à des fins politiques ou non. Le groupe de rock britannique The Cure, pendant un concert à Rome le 4 juin 1989, a dédié son dernier rappel , à . Le chanteur Robert Smith a complété la chanson, avec des paroles improvisées, sur une personne qui a un fusil dans la gorge et qui est exhorté à répondre « Oui » à la question « Est-ce que tu m'aimes ? », mais qui refuse finalement de le faire. L'enregistrement de cette version de 15 minutes est connu sous le nom de .

La même année, Joan Baez a écrit et enregistré son hymne folk pour commémorer la révolte démocratique. Le single sur le thème de l'histoire de Billy Joel , sorti fin 1989, mentionne l'événement au vers « la Chine sous la loi martiale ».

La chanson du groupe canadien de musique industrielle Skinny Puppy est une référence à la révolte et au massacre.

Le groupe de rock progressif Marillion a écrit une chanson intitulée . La chanson apparaît dans l'album en septembre 1989.

Le groupe américain de rock et folk "The Hooters" a fait référence à l'événement dans sa chanson (de l'album , enregistré en 1989), qui est une version mise à jour de la chanson folk des années 1960. Le troisième couplet commence par : , qui pourrait être traduit par : .

Le groupe System of a Down a fait référence à l'événement dans les premières lignes de la chanson : ()

L'inspiration du titre "Shiny Happy People" par R.E.M. provient d'un poster intitulé « Shiny Happy People Holding Hands » "(traduction: des gens joyeux et étincelants se tenant par la main)" de la propagande chinoise édité juste après le massacre.

Le groupe de thrash metal Slayer a sorti la chanson dans son album des années 1990 intitulé . Ce titre est inspiré des événements de la place Tian'anmen. La chanson contient les vers suivants : (). La même année, un autre groupe de thrash metal, Testament a sorti la chanson pour protester contre le massacre pékinois (même si l'assaut de la place Tian'anmen a eu lieu le 3 juin et non en mai) sur son album . Dans ce titre, se lit : (soit : ).

En 1990, le groupe corse I Muvrini dédie à ces évènements la chanson ""Trà more è campà"" (""Entre vivre et mourir"") sur scène lors de sa tournée d'été. Celle-ci reste un temps inédite malgré la sortie de l'album live ""... in core"" et d'une VHS éditée par FR3 sur cette tournée, ""I Muvrini... In Giru"". Elle paraît sur l'album ""À voce rivolta"" en 1991. En 1991, Johnny Hallyday sur son album "Ça ne change pas un homme" chante également une chanson qui se nomme , écrite par Ysa Shandy Et Jacques Cardona.

Le groupe britannique anarchiste de pop Chumbawamba a sorti une chanson appelée (Place Tian'anmen) dans son album . Les paroles sont construites autour du fait que l'Armée populaire de libération a commis des assassinats. L'Homme de Tiananmen y est également mentionné (, traduisible par ).

Sinéad O'Connor, dans son album de 1990 , a fait référence à la tuerie dans la chanson avec ces paroles : ().

Le groupe de rock britannique Siouxsie and the Banshees a enregistré la chanson pour son album en 1991. Il y est question d'une personne témoin du massacre qui retourne sur la place Tian'anmen et se souvient de la terrible émotion qu'elle y a ressentie.

Roger Waters a visé le massacre dans la chanson en 1992 dans l'album . En 1996, Nevermore a sorti la piste intitulée sur son album .

En 2006, le chanteur chinois de folk Li Zhi a écrit une chanson intitulée , dans laquelle sont audibles le sifflement des balles, la sirène des ambulances et la voix de Ding, l'une des Mères de Tiananmen. En 2007 Hed PE a écrit une chanson intitulée dans son album .

Calogero a également écrit une chanson intitulée en 2003.

Le groupe portugais Kalashnikov possède dans son répertoire une chanson intitulée . Le chœur de la chanson entonne ().

Le groupe italien CCCP Fedeli alla linea a inclus la chanson dans son album de 1990 .

Le groupe français Les Wriggles a fait référence à cet événement dans leur chanson « N'importn'awak » : « T'as pas balancé des chars sur la place Tien an Men » de l'album « Le Best Of » sorti en 2006.

En 2009, le groupe indi pop de Hong Kong My little airport a écrit après la déclaration de Tsang selon laquelle le massacre de la place Tian'anmen est insignifiant au regard du pouvoir économique actuel de la Chine. Les paroles disent : .

Le groupe de punk Rancid fait référence à la place Tian'anmen dans sa chanson , dont voici un extrait : (). La chanson reflète les enjeux de la censure des médias et de l'absence de libertés démocratiques en Chine.

Le groupe australien de hip-hop Hilltop Hoods mentionne la place Tian'anmen dans une de ses chansons : ().

Alors que le massacre des manifestants de la place Tian'anmen est à son comble, s'ouvrent à Paris les internationaux de France de tennis 1989. Le tournoi est gagné par un Américain d'origine chinoise, Michael Chang, qui, à 17 ans, devient le plus jeune joueur à remporter un tournoi du Grand Chelem. Le mémorable quatrième set de la victoire sur le numéro un mondial Ivan Lendl a lieu le 5 juin 1989. Chang a déclaré que sa motivation était d'autant plus forte que le massacre se poursuivait :







</doc>
<doc id="14508" url="https://fr.wikipedia.org/wiki?curid=14508" title="Géographie de la Colombie">
Géographie de la Colombie

La Colombie est un pays situé dans le coin nord-ouest de l'Amérique du Sud. Dans le sens des aiguilles d'une montre, en commençant par le nord, il est entouré par la mer des Caraïbes (mer bordière de l'océan Atlantique nord), le Venezuela, le Brésil, le Pérou, l'Équateur, l'océan Pacifique nord et le Panama, qui le relie à l'Amérique centrale. Bogota en est la capitale.

Ce pays occupe une superficie de dont de terre. La Colombie possède aussi quelques îles : Malpelo, Gorgona, Roncador Cay, Serrana Bank, Seranilla Bank, San Andrés et Providencia.

La Colombie comptait un peu plus de (en 2005).

La Colombie est un pays du nord-ouest de l’Amérique du Sud. Les pays limitrophes sont le Venezuela à l’est, le Brésil au sud-est, le Pérou et l’Équateur au sud-ouest et le Panama au nord-ouest. À l'ouest, le pays possède une large façade sur l'océan Pacifique nord, tandis qu'au nord, il s'ouvre largement sur la mer des Caraïbes, mer bordière de l'Atlantique nord. Il est le seul pays d’Amérique du Sud à posséder des côtes sur deux océans, sur la mer des Caraïbes et sur l’océan Pacifique. Le pays possède de nombreuses îles et archipels, dont l’archipel de San Andrés et Providencia, au large des côtes atlantiques du Nicaragua, situé en Amérique centrale. La Colombie a une superficie totale de , elle est dotée d’un relief d’une grande diversité.

Le territoire colombien est divisé en plusieurs régions physiques bien différentes avec des caractéristiques propres.






La Colombie a presque partout un réseau hydrographique riche, et parfois très riche (à l'exception de la zone steppique de La Guajira): cela est dû à l'abondance de la pluviosité moyenne. Le pays se trouve au centre d'une vaste zone parmi les plus arrosées de la planète (On recueillerait d'eau par an à Lloro, sur la côte atlantique) et s'étendant sur l'Amérique centrale depuis le Yucatan mexicain, et les régions nord de l'Amérique du Sud jusqu'aux bouches de l'Amazone. De ce fait et de par son relief, le pays constitue ainsi un énorme château d'eau.

D'après Aquastat, la hauteur d'eau annuelle moyenne des précipitations est de , soit pour une superficie de , un volume de précipitations annuelles de (près de douze fois le chiffre de l'Allemagne qui est de ).

De ce volume précipité, l'évapo-transpiration et les infiltrations consomment plus ou moins 29 % - ce qui est fort peu - soit . Restent pas moins de de ressources d'eau superficielle produites annuellement sur le territoire du pays (en interne).

À ces ressources de produites en interne, il faut ajouter quelque d'eau produits à l'étranger et qui font partie des ressources utilisables du pays, une fois la frontière franchie. Il s'agit du débit apporté de l'Équateur par diverses rivières. Compte tenu de ce petit apport, les ressources totales en eau du pays se montent annuellement à quelque ( de m), soit pour une population estimée à d'habitants en 2008, environ d'eau par habitant, ce qui doit être considéré comme extrêmement élevé.

Il faut ajouter qu'une énorme quantité d'eau quitte annuellement le territoire à destination de ses voisins : , et ce à raison de annuellement en direction du bassin de l'Amazone (territoires du Brésil et du Pérou) et de cubes par an vers le Venezuela, au profit avant tout de l'Orénoque, mais aussi du bassin du lac Maracaibo (río Catatumbo).

Le fleuve principal du pays est le Río Magdalena qui coule du sud vers le nord entre les chaînes de montagnes centrales et orientales. Il traverse la quasi-totalité du pays et se jette dans la mer des Caraïbes.
Son affluent principal, le Río Cauca est tout aussi important, son bassin comprenant notamment les grands cités de Medellín et de Cali.

Le Río Atrato, long de , est une importante voie navigable sur plus de . Son bassin versant a une surface de .

C'est dans la région pacifique que l'on trouve le réseau hydrographique le plus dense. La pluviosité de la région est en effet la plus importante du pays et l'une des plus élevées du monde.

Ainsi, dans toute la zone du Pacifique, on a des valeurs d'écoulement situées entre et . (à l'exception du bassin du Río Patía). Les bassins fluviaux ayant le plus fort écoulement correspondent à celui du Río San Juan avec , celui du Río Baudó avec , et celui de l'Atrato avec . Pour le bassin du Río Patía situé au sud de la zone et dont une partie importante du bassin est située dans la zone andine, les valeurs moyennes d'écoulement étaient de dans la partie haute et dans la partie basse du bassin.

Le Río San Juan est autre fleuve important de cette région. Long de , il a un petit bassin versant d'à peine kilomètres carrés (moins que celui de l'Oise en France) ; mais il roule autant d'eau que le Rhin en fin de parcours.

L'étendue totale du bassin de l'Orénoque est de . Il a une longueur de dont navigables. Il délimite la frontière avec le Venezuela sur .

Le Río Arauca a plus ou moins de long, dont 510 sont navigables. Il détermine la frontière avec le Venezuela sur . La superficie colombienne de son bassin est de .

Le Río Meta est l'affluent colombien le plus important de l'Orénoque. Il a une longueur de , dont 900 sont navigables. Il a une grande importance pour le commerce avec le Venezuela via le cours de l'Orénoque. Son bassin versant a une surface de .

Le Río Vichada a plus ou moins de long, dont 450 sont navigables. Son bassin versant a une surface de .

Le Río Guaviare est l'affluent colombien le plus long et le plus abondant de l'Orénoque. Il a une longueur de , dont 620 seulement sont navigables pour de petites embarcations (il présente en effet des rapides). Son cours d'orientation ouest-est détermine grosso modo la limite entre la région des llanos au nord et celle de la forêt amazonienne au sud. La superficie de son bassin versant est de .
Son important débit de plus de /s est plus élevé que celui du Danube.

On y trouve également les "surales", qui s'étendent sur . Il s'agit de formations paysagères créées par des vers de terre géants.

L'Amazone est le fleuve le plus important au monde; il est aussi le plus long et celui qui comporte le plus important réseau navigable de la planète (non moins de ). La Colombie possède une fenêtre de de large sur la rive nord du fleuve, y compris un port fluvial, Leticia, cela au niveau du trapèze amazonien, dans le département d'Amazonas.

Citons les principaux affluents de l'Amazone coulant en territoire colombien.

Le Río Negro ou Guainía a plus de de long et se jette dans l'Amazone près de Manaus au Brésil. Là, son débit est énorme (plus de /s, plus de dix fois le volume du Nil et presque autant que le fleuve Congo, second gros débit de la planète). Il a donné son nom au département de Guainía.

Le Río Vaupés a environ de long et est formé de la réunion des Ríos Unilla et Itilla. Il est navigable sur tout son parcours et constitue l'affluent principal du Río Guainía

Le Río Caquetá a de long dont en Colombie et navigables (parfois entrecoupés de rapides). Il naît dans les Andes au niveau du massif colombien. Au Brésil, on lui donne le nom de Rio Japurá. Il a des affluents importants comme le Río Apaporís, le Río Caguán et le Río Orteguaza.

Le Río Putumayo, qui donne lui aussi son nom à un département colombien, est surtout une rivière frontalière. Il constitue partiellement la frontière avec l'Équateur et presque totalement avec le Pérou. Né dans le nœud de los Pastos, il a une longueur approximative de , dont non moins de sont navigables. Il parcourt en Colombie et le reste au Brésil.

C'est un petit bassin formé de plusieurs cours d'eau dont les eaux coulent vers le lac Maracaíbo au Venezuela, et donc vers la mer Caraïbe. On distingue :

Le río Catatumbo (partie colombienne du bassin : )

Le río Zulia (partie colombienne : )

Le río Sardinata ()

Autres rivières mineures ()

Selon la Constitution de 1991, la Colombie est divisée en 32 départements et un unique , Bogota. L'échelon inférieur est constitué d'approximativement dont font partie le et les districts spéciaux de Barranquilla, Cartagena, Santa Marta et Buenaventura.

Le tableau réduit ci-dessous focalise sur les 13 plus fortes augmentations de la population des villes principales de Colombie, durant les trois dernières décennies :

La Colombie est le pays avec le plus d’espèces différentes au monde après Madagascar et le Brésil. Et le premier pays quant à la diversité d’oiseaux avec plus de dont les plus fréquents sont les condors, les vautours, les toucans, les perroquets, les cigognes et les colibris. Cela est dû à la diversité de la topographie et aux différents climats présents dont le climat tropical humide. On compte également quelque de papillons, plusieurs sortes de reptiles, de batraciens et de poissons tropicaux. Quant aux mammifères, comme dans la plupart des pays d’Amérique du Sud, sont présents de grands mammifères tels que le jaguar, le puma, le tapir, le pécari, le paresseux, le tatou ainsi que plusieurs espèces de singes et de cerfs.

Pour ce qui est de la flore on dénombre environ de plantes, dont la moitié serait endémique, et de fleurs dont environ ; elle est considérée comme la fleur nationale. Le gouvernement colombien protège cette biodiversité exceptionnelle dans plus de nationaux et douze réserves naturelles pour un total de 9 millions d’hectares.

Les aires protégées de Colombie sont gérées par le "Sistema Nacional de Áreas Protegidas" ou SINAP (en français Système National de Zones Protégées). En 2008, la Colombie comptait 58 parcs nationaux naturels couvrant environ et représentant plus de 10 % de la superficie du pays.




</doc>
<doc id="14510" url="https://fr.wikipedia.org/wiki?curid=14510" title="Farad">
Farad

Le farad (symbole : F), tiré du nom du physicien Michael Faraday, est l'unité dérivée de capacité électrique du Système international (SI).

Un farad est la capacité d'un conducteur électrique isolé pour laquelle une addition de provoque une augmentation de son potentiel de (aspect électrostatique). Cette charge électrique composée de représente en fait une charge électrique de . (Le coulomb est aussi le nombre d'électrons traversant chaque seconde la section d'un conducteur parcouru par un courant de (aspect électrodynamique)).

Il faut considérer tout conducteur comme un « réservoir » à électrons, susceptible d'être plus ou moins rempli à l'aide d'un contact électrique avec un générateur d'électrons ou vidé avec un récepteur d'électrons. 

Cette capacité attribuée au conducteur électrique ne dépend que de la forme du conducteur. Par exemple, en considérant la Terre comme une sphère conductrice de de diamètre, on trouve une capacité de ~ (~).

Le composant électronique appelé « condensateur » utilise cette propriété mais en associant deux conducteurs (ou plus), chacun des conducteurs exerçant son « influence », si possible totale, sur l'autre conducteur. C'est sous cette condition d'influence électrostatique d'un conducteur sur l'autre que l'on fabrique les condensateurs utilisés en électronique.

En unités de base SI :

formula_1

Cette unité est en pratique très grande. On utilise usuellement ses sous-multiples, microfarad (symbole : µF), nanofarad (symbole : nF) et picofarad (symbole : pF).

Depuis quelques années, on peut trouver sur le marché des composants électroniques : des « super-condensateurs » d'une capacité variant entre un et mille farads. Ces condensateurs ont une tension de service assez faible, de l'ordre de . La mise en série et parallèle de nombreux de ces « super-cap » permet d'obtenir un genre de batterie susceptible de stocker assez d'énergie pour une utilisation dans les transports (récupération de l'énergie de freinage). Cela peut être une alternative aux accumulateurs dans certaines applications.


</doc>
<doc id="14512" url="https://fr.wikipedia.org/wiki?curid=14512" title="Henry (unité)">
Henry (unité)

Le henry (symbole : H) est l’unité dérivée d’inductance du Système international (SI), du nom du physicien américain Joseph Henry.

L’inductance d’un circuit est de si un courant parcourant ce circuit en variant uniformément à raison de produit à ses bornes une force électromotrice de .

En unités de base SI : 



</doc>
<doc id="14514" url="https://fr.wikipedia.org/wiki?curid=14514" title="Radian">
Radian

Le radian (symbole : rad) est l'unité dérivée du Système international qui mesure les angles plans. Bien que le mot « "radian" » ait été inventé au cours des années 1870 par Thomas Muir, les mathématiciens mesuraient depuis longtemps les angles en prenant pour unité le report sur la circonférence de la longueur du rayon.

Considérons un secteur angulaire, formé de deux droites concourantes distinctes, et un cercle de rayon "r" tracé dans un plan contenant ces deux droites, dont le centre est le point d'intersection des droites. Alors, la valeur de l'angle en radians est le rapport entre la longueur "L" de l'arc de cercle intercepté par les droites et le rayon "r".

Un angle d'un radian intercepte sur la circonférence de ce cercle un arc d'une longueur égale au rayon. Un cercle complet représente un angle de 2π radians, appelé "angle plein".

L'utilisation des radians est impérative lorsque l'on dérive ou intègre une fonction trigonométrique : en effet, l'angle pouvant se retrouver en facteur, seule la valeur en radians a un sens. De ce fait, le calcul des fonctions trigonométriques par une série de Taylor suppose l'expression des angles en radians, tout comme l'application de la formule d'Euler, qui l'a posée en spécifiant que les angles devaient être mesurés par la longueur en rayons de l'arc qu'ils interceptent, plus d'un siècle avant l'invention du terme "radian".


Il n'y a aucune formule de ce genre avec les valeurs en grades et degrés.

Dans le domaine de la topographie, où on traite d'angles faibles, on utilise le "mil angulaire", une unité pratique, définie comme l'angle qu'intercepte une longueur de à une distance de . Elle sert, par exemple, à déterminer la distance d'une mire de hauteur connue par la mesure de sa taille apparente. Dans les conditions où elle sert, cette unité s'identifie avec un "milliradian".

Par conséquent,
Les formules de conversion entre les degrés et les radians sont :

Les formules de conversion entre les grades et les radians sont :


</doc>
<doc id="14515" url="https://fr.wikipedia.org/wiki?curid=14515" title="Stéradian">
Stéradian

Le stéradian (symbole : sr) est l'unité dérivée du Système international pour la mesure d'angles solides. Son nom est partiellement dérivé du grec ancien στερεός ("stereos") « solide, dur, cubique ».

Sa définition française officielle est : 

Autrement dit, un angle solide d'un stéradian délimite sur la sphère unité à partir du centre de cette sphère une surface d'aire 1. Pour une sphère complète, l'angle solide vaut donc 4π stéradians, la surface d'une sphère complète de rayon "r" valant . 

Le stéradian est une unité sans dimension.

Le stéradian fut, à partir de 1960, avec le radian une unité SI supplémentaire, mais cette catégorie fut retirée du Système international en 1995.



Le lumen est l'unité de flux lumineux correspondant au flux émis par une source d'une intensité lumineuse de 1 candela contenu dans un angle solide de 1 stéradian.

Expressions contenant le stéradian :

et

Avec :




</doc>
<doc id="14519" url="https://fr.wikipedia.org/wiki?curid=14519" title="Kingston (Ontario)">
Kingston (Ontario)

Kingston est une municipalité du Canada, située en Ontario. Au recensement de 2011, la région métropolitaine comptait .

Anciennement nommé Fort Frontenac, Kingston a été la première capitale du Canada de 1841 à 1844.

Bien que principalement anglophone, Kingston a été désignée région bilingue par le gouvernement provincial en 2009, ce qui assure aux francophones l'accès aux services dans leur langue.

Kingston est située à la jonction du fleuve Saint-Laurent, du canal Rideau et du lac Ontario. La ville se trouve à de Toronto par l'autoroute 401 (l'autoroute Macdonald-Cartier), à de Montréal et à d'Ottawa. 

Kingston constitue le terminus sud du canal Rideau, voie maritime mise en service pour relier le lac Ontario à la rivière des Outaouais.

Le chemin de fer Canadien National y passe.

L'ancienne municipalité de Kingston est traversée par la rivière Cataraqui à l'est et est bordée par la crique Cataraqui à l'ouest. 

Kingston fait partie de la circonscription électorale de Kingston et les Îles.

La région métropolitaine compte kilomètres carrés.

Kingston est une destination touristique populaire, entre autres parce qu'elle est située dans la région des Mille-Îles. Elle est surnommée la « ville du calcaire » (« "limestone city" ») en raison des nombreux bâtiments historiques faits à partir de la pierre locale.

Fondée en 1673, la ville compte de nombreux édifices historiques. À cause de son emplacement stratégique, Kingston est un lieu militaire d'importance. On y trouve notamment le Fort Henry, site patrimonial national. La base des Forces canadiennes de Kingston abrite aujourd'hui des unités de la force terrestre, l'École des communications et de l'électronique des Forces canadiennes, le Musée des communications des Forces canadiennes et le Collège militaire royal du Canada.

La ville est accessible par voie aérienne, avec l’aéroport Norman Rogers (CYGK), fondé en 1940, et qui accueille plus de par année. On peut également s'y rendre par train, avec Via Rail, et plusieurs marinas permettent de s'y rendre par voie maritime.

En plus de nombreux musées, Kingston abrite l'université Queen's, le Collège militaire royal du Canada ainsi que le St. Lawrence College. L'une des plus anciennes stations de radio du monde, CFRC, fait partie de l’université Queen's et tire son nom des « Célèbres champions de rugby du Canada » (« Canada’s Famous Rugby Champions »). 

Le centre-ville y est animé et accueille plusieurs festivals d’importance chaque été, dont le festival Buskers (amuseurs de rue), le Limestone City Jazz Festival et le Kingston Blues Festival. De très nombreux hôtels et restaurants côtoient les commerces des principales rues du quartier historique : Princess, Brock, Queen, Ontario, King. Tout juste derrière l'hôtel de ville, on trouve le marché de Kingston, le plus vieux en Ontario, où les marchands convergent chaque fin de semaine et où est installée une patinoire publique en hiver. 

La ville a accueilli les compétitions de voile pour les Jeux olympiques d'été en 1976. Kingston est célèbre pour ses conditions de voile exceptionnelles, et au mois d'août chaque année, des amateurs de voile de partout dans le monde s'y donnent rendez-vous pour le CORK (Canadian Olympic-training Regatta, Kingston). Il compte une équipe de hockey sur glace, les Frontenacs de Kingston.

Kingston compte plusieurs personnalités populaires canadiennes dans le domaine de la musique, notamment les Tragically Hip, Sarah Harmer, Bryan Adams, Hugh Dillon des Headstones et David Usher (autrefois de Moist).

Kingston reçoit régulièrement des mentions pour sa qualité de vie. En 2011, le magazine MoneySense classait la ville en quatrième position sur la liste des meilleurs endroits où vivre au Canada.

La ville est le siège d'un évêché, l'Archidiocèse de Kingston.

En 1673, le gouverneur de la Nouvelle-France Louis de Frontenac fait construire un fort à l'emplacement actuel de la ville, nommé fort Cataraqui (anciennes orthographes : Cataracoui, Kataracouy) et renommé ensuite Fort Frontenac. Cavelier de la Salle en est le premier commandant et fait doubler la superficie du fort. L'endroit abritait en 1677 une quarantaine de Français, dont une douzaine de familles de colons.

En 1758, lors de la guerre de Sept Ans, le fort est pris et détruit par les Britanniques. La bataille de Fort Frontenac oppose une force de 150 hommes, du côté français, à une armée de anglais. La ville est rétablie en 1784 comme camp de réfugiés pour les loyalistes britanniques fuyant la révolution américaine afin de se maintenir dans l'Empire.

La nation Mohawk des Six Nations Iroquois de New York (dirigée par Molly Brant) formait également une partie significative de la population locale à la fin du . La communauté qui s’appelle maintenant Cataraqui, du nom amérindien original « Kateracoui » des Mississaugas, se trouve à l'ouest de Kingston.

Kingston sert alors de base pour la flotte navale britannique de l’est de la Région des Grands Lacs, qui livrait une féroce concurrence à la flotte américaine basée à Sackets Harbor (New York) pour le contrôle du lac Ontario. Après la guerre, la Grande-Bretagne construit le Fort Henry et une série de tours Martello pour protéger l'entrée du canal Rideau contre une invasion américaine.

Lors de la proclamation de l'Acte d'Union en 1840, Kingston est choisie comme future capitale du Canada uni. La première Assemblée législative de la province du Canada y siège du 14 juin au 18 septembre 1841. Toutefois, dès le 8 septembre 1842, l'Assemblée déclare la ville impropre à servir de siège au gouvernement et choisit alors Montréal comme capitale, où le gouvernement s'installe de 1844 à 1849, pour ensuite déménager à Toronto (1849-1851), puis à Québec (1851-1859) et enfin à Ottawa. La Confédération sera votée en 1867.

Kingston est la ville d'adoption du premier Premier ministre du Canada, Sir John A. Macdonald, qui y est enterré.

Kingston reçoit sa charte de ville le 18 mai 1846.

La population des districts les plus fertiles de l'Ontario, à l'ouest de Kingston quadruple entre 1838 et 1851 et les surfaces cultivées augmentent encore plus. La région est d'abord pénalisée quand le marché du blé s'effondre en 1834-1835 lors d'une crise de surproduction amplifiée par la spéculation: le boisseau se vend 35 cents, sous son coût de production (40 à 50 cents), et trois fois moins que quelques années avant. Le prix de la terre est divisé par quatre, la dépression et les mauvaises récoltes ravagent de nombreuses régions nouvellement peuplées dans les années 1830. Le Québec, dont la production a aussi baissé, doit s'approvisionner en Europe et l'Ontario exporte ensuite vers Etats-Unis quand ses récoltes rebondissent en 1838, en profitant de la navigation toute l'année sur le Lac Ontario. Cette évolution conduit l'Angleterre à réduire les taxes sur le blé canadien en 1842 et les Québécois à creuser le canal de Lachine, qui permet d’éviter les Rapides de Lachine, zone-clé de la voie maritime du Saint-Laurent. Cette voie d'exportation des blés est cependant bloquée par les glaces l'hiver, période où va servir le silo élévateur à grain inventé en 1842 à Buffalo (New York) par Joseph Dart. 

Aux , Kingston était un port important des grands lacs et un centre de construction navale et de locomotives. Cette industrie lourde s'étant éteinte dans la deuxième moitié du , les emplois y sont désormais principalement dans les secteurs gouvernementaux, notamment dans le domaine correctionnel, éducatif, militaire et tertiaire. On trouve de plus à Kingston plusieurs sites industriels d'importance, dont DuPont et Bombardier.






</doc>
