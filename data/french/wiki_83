<doc id="15445" url="https://fr.wikipedia.org/wiki?curid=15445" title="Procruste">
Procruste

Les procrustes (Procrustes), forment un sous-genre d'insectes coléoptères du genre "Carabus" ; on peut en trouver dans toute l'Europe. Ce sont des prédateurs qui se nourrissent d'autres coléoptères, chenilles, limaces, escargots et fruits mûrs. Ils vivent sous les cailloux, sous les bois morts ou sous les feuilles dans les forêts humides. Lorsqu'ils sont dérangés, ils dégagent par l'anus une substance à l'odeur pestilentielle (acide butyrique), qui compense l'absence d'ailes et leur donne le temps de s'échapper.




</doc>
<doc id="15447" url="https://fr.wikipedia.org/wiki?curid=15447" title="Taxe générale sur les activités polluantes">
Taxe générale sur les activités polluantes

En France, la taxe générale sur les activités polluantes (TGAP) est un impôt qui s'applique à diverses activités polluantes. Elle a été instituée par la loi de finance 1999 et est entrée en application le janvier 2000. Elle a permis de remplacer/fusionner diverses taxes parafiscales sur la pollution atmosphérique, les déchets ménagers et industriels spéciaux, les huiles de base et les nuisances sonores dues au décollage des aéronefs.

Elle est proportionnelle au degré de pollution engendré par toute activité (production de déchets industriels et ménagers, pollution atmosphérique, nuisances sonores, etc.). Chaque année, le montant de cette taxe est révisée. La loi de finance 2018 a supprimé les composantes spécifiques aux . Il ne reste plus que les composantes , , , et ainsi que celle sur les qui est à part.

Elle a été introduite par la loi de finances pour 1999 et est opérationnelle depuis janvier 2000.

La TGAP sur les produits phyto-sanitaires a été remplacée par une redevance sur les pollutions diffuses perçue par les Agences de l’eau. La TGAP frappe cependant les produits antiparasitaires.

Cette taxe sur les activités polluantes doit permettre de mieux appliquer le principe pollueur-payeur. En effet, elle conduit à différencier, dans le montant de la taxe, les ressources nécessaires pour financer les dommages causés à l'environnement par une activité polluante. . La TGAP émet un signal-prix qui doit dissuader les pratiques polluantes.

Les personnes favorables à la TGAP considèrent qu'elle constitue une modernisation et une simplification de la fiscalité écologique.

La composante de la TGAP est due par tout exploitant d'une installation de stockage de déchets ou d’une installation de traitement thermique de déchets (incinérateur) soumise à autorisation en application de la législation sur les installations classées pour la protection de l'environnement. Le fait générateur de la taxe est la réception de déchets par l’exploitant de l’installation.

Cette composante a pour objectif de limiter le développement de ce type d'installations et d’encourager les comportements vertueux, c’est-à-dire privilégier dans l’ordre la prévention des déchets, la préparation en vue de la réutilisation, le recyclage, toute autre valorisation, notamment énergétique, l’élimination des déchets, en cohérence avec la hiérarchie des modes de traitement des déchets prévue par le code de l'environnement.

Dans le système actuel, les réductions de taux de cette composante liée aux déchets non dangereux ont pour objectif d’inciter les exploitants d'installations de stockage de déchets non dangereux et d’incinérateurs de déchets non dangereux à exploiter des installations présentant des performances environnementales et de valorisation les plus élevées conformément aux objectifs inscrits à l’article 46 de la loi Grenelle I.

Via la loi de finance 2018, le gouvernement a révisé les règles de calcul des réfactions dont bénéficient les installations les plus performantes, en attendant la réforme annoncée de cette composante.

La composante de la TGAP est due par les installations classées pour la protection de l'environnement soumises à autorisation qui émettent des substances participant à la pollution atmosphérique (oxydes de soufre et autres composés soufrés, acide chlorhydrique, oxydes d'azote et autres composés oxygénés de l'azote, poussières totales en suspension, arsenic, sélénium, mercure, benzène, hydrocarbures aromatiques polycycliques, plomb, zinc, chrome, cuivre, nickel, cadmium, vanadium, hydrocarbures non méthaniques, solvants et autres composés organiques volatils), dans des quantités supérieures aux seuils indiqués sur une année.

Prévue par l'article 266 quindecies du code des douanes, la composante de la TGAP a été instaurée en 2005. Elle vise à favoriser l'incorporation de biocarburants dans les supercarburants et gazole mis à la consommation en France. Cette taxe est distincte des autres composantes TGAP et fait l'objet d'une déclaration qui lui est spécifique. Le taux de cette taxe, qui augmente progressivement chaque année, est diminué à proportion des volumes de biocarburant incorporés dans ces carburants.

La composante de la TGAP, spécifiquement relative aux installations classées pour la protection de l'environnement (ICPE), était composée de :

Après plusieurs tentatives, le gouvernement a réussi à abroger cette composante via la loi de finance 2018.

Le produit de la taxe s'élevait globalement à 726 millions d'euros en 2015, répartis entre l'Etat (277 M€) et l'agence de l'environnement et de la maîtrise de l'énergie (449 M€).

La TGAP n'est pas forcément toujours lisible, par exemple dans le cas des produits phytopharmaceutiques. En effet, la TGAP est payée par les firmes phytosanitaires détentrices de ces produits. Selon les entreprises, ce montant est imputé sur leur marge bénéficiaire pour rester en conformité avec les prix du marché, ou bien elle entraîne une augmentation des prix qui est soit répartie sur l'ensemble de la gamme, soit répercutée sur les produits ayant un classement toxicologique. Les négociants fixent ensuite leurs propres barèmes de prix avant de vendre aux agriculteurs, ce qui contribue à brouiller le signal-prix.



</doc>
<doc id="15448" url="https://fr.wikipedia.org/wiki?curid=15448" title="Vignette automobile">
Vignette automobile

La vignette automobile est un impôt annuel sur les véhicules en circulation sur toutes routes ou sur certaines seulement (autoroute), qui se traduit par l'obligation d'acheter et d'apposer une figurine fiscale spéciale, ou « vignette », sur le pare-brise de chaque véhicule assujetti.

En Autriche, une vignette valable dix jours (9€), deux mois (25,20€) ou un an (87,30€) autorise la circulation sur autoroute.

La vignette automobile française fut instituée en 1956 afin de financer les retraites et supprimée en juin 1981 pour les motocycles et en 2001 pour tous les autres véhicules.

En Suisse une vignette autoroutière annuelle de coûtant autorise la circulation sur les autoroutes suisses, elle institue en outre un impôt direct sur le transit étranger et l'exploitation suisse d'un véhicule poids-lourds, la Redevance poids lourds liée aux prestations (RPLP). En 2013, le peuple suisse a refusé par référendum l'augmentation de la vignette de 40 FS à 100 FS. Ce système pourrait être remplacée par un enregistrement électronique de la plaque d'immatriculation.

Pour les véhicules à moteur d'un poids inférieur à , les autoroutes tchèques (en 2016 seules certaines autoroutes sont concernées) sont sujettes à des frais d'accès sous la forme d'une vignette de péage temporelle ("dálniční známka" ou "dálniční kupón"), en 2016 valide dix jours (310 CZK), un mois (440 CZK) et une année (1500 CZK). En outre elle institue un impôt direct sur l'usage des véhicules professionnels.

Les exemptions sont les suivantes:

À partir du janvier 2007 un nouveau système de péage électronique c'est-à-dire un péage à distance pour les véhicules qui excèdent a été introduit pour les autoroutes et certaines routes de première classe ("silnice první třídy"), au total . Depuis le janvier 2010, cela s'applique aussi aux véhicules de plus de .

Un débat public est en cours sur la mise en place du péage électronique pour tous les véhicules et pour toutes les voitures.




</doc>
<doc id="15450" url="https://fr.wikipedia.org/wiki?curid=15450" title="Alimentation">
Alimentation

L’alimentation désigne, par définition, l'action de s'alimenter. Elle relève donc de la nourriture et par conséquent des aliments qui permettent à un organisme de fonctionner, de survivre. Elle caractérise aussi la manière de s'alimenter, qui s'intéresse davantage au domaine social et éthique.

Les réactions chimiques exothermiques nécessaires à la vie sont dépendantes d'apports en nutriments. Chez les organismes supérieurs ceux-ci sont soit synthétisés par photosynthèse (végétaux), soit puisés dans des composés organiques (animaux et champignons). Il existe d'autres sources énergétiques pour les micro-organismes : par exemple, certaines archées puisent leur énergie en produisant du méthane ou en oxydant des composés sulfurés.

Les végétaux sont des organismes autotrophes. Ils sont capables de synthétiser les composants organiques à partir de sels minéraux et d'énergie solaire grâce à la fonction chlorophyllienne.

Les animaux sont des organismes hétérotrophes. Ils sont dépendants d'une ou plusieurs autres espèces pour leur nourriture. Les aliments sont transformés en nutriments par la digestion. Le régime alimentaire, qu'il soit zoophage ou herbivore, a une influence prépondérante sur le comportement des animaux. Il détermine notamment leur statut de prédateur ou de proie dans le réseau trophique. Ils peuvent avoir une pratique alimentaire omnivore ou plus spécifique insectivore, piscivore, charognard, saprophage, herbivore…

Comme les autres animaux, l'homme est dépendant de son environnement pour assurer ses besoins primaires en nourriture. L'étude des besoins humains en nourriture, que ce soit en quantité (obésité ou sous-alimentation) ou en qualité (malnutrition) est la nutrition.
Les nutriments sont des molécules produites lors de la digestion des aliments consommés. Les protéines, les lipides et les glucides sont les trois grands groupes de nutriments qui permettent à l’organisme de se construire, de se renouveler, et d'apporter l'énergie nécessaire au métabolisme. Néanmoins, on peut les scinder en deux groupes : les nutriments essentiels et ceux qui ne le sont pas. En effet, les protéines et les lipides sont dits essentiels car notre corps est incapable des les fabriquer et il faut donc les acheminer par l'alimentation, contrairement aux glucides qui peuvent être synthétisés à partir d'autres nutriments

Les protéines sont les nutriments qui constituent notre enveloppe, autrement dit les muscles, les os, la peau, les cheveux ou encore les ongles. En outre, elles sont composées d'acides aminés qui, une fois libérés pendant la digestion, vont être utilisés par l'organisme pour produire ses propres protéines. 

De plus, elles sont indispensables à certains processus physiologiques comme la réponse immunitaire (les anticorps) ou encore la production d'hormones. Elles sont aussi l’unique source d'azote de l'organisme.

Les lipides sont les nutriments les plus énergétiques. Ils sont les constituants de la membrane de nos cellules (bicouche de phospholipides) et assurent donc leur bon fonctionnement, et celui des organes. On peut ajouter à cela que les lipides ont un rôle essentiel dans le transport de certaines protéines et hormones dans le sang, ainsi que d'un bon nombre de vitamines. Pour les hormones, ils ne font pas que les transporter, mais ils participent aussi à l'élaboration de certaines d'entre elles.

Les glucides, contrairement aux protéines et aux lipides, ne sont pas essentiels, et peuvent être produits à partir d'autres nutriments. Les glucides sont utilisés sous la forme de glucose. Ce glucose va être utilisé par toutes les cellules, qu'elles soient musculaires ou nerveuses, notamment les cellules du cerveau. Il peut aussi être dans une moindre mesure, transformé en glycogène pour servir de réserve d’énergie instantané pour les muscles par exemple.

L'eau est un solvant polaire de référence qui dissout de nombreux composés comme le sel et le sucre. La plupart des aliments contiennent de l'eau de manière naturelle. C'est un nutriment essentiel qui permet à de nombreuses réactions d'avoir lieu, de sorte qu'il est indispensable au fonctionnement des organismes vivants. Il permet également le transport des nutriments et l'hydratation des tissus de l'organisme. L'organisme humain contient en moyenne 60 % d'eau. Les humains sont capables de vivre sans manger pendant plusieurs semaines mais ne peuvent vivre sans apport d'eau pendant plus que quelques jours.

Les apports nutritionnels conseillés sont les quantités que l'on doit ingérer en une journée. Ils diffèrent selon l'âge, le sexe et le mode de vie.




</doc>
<doc id="15453" url="https://fr.wikipedia.org/wiki?curid=15453" title="Malbouffe">
Malbouffe

La malbouffe désigne par dérision ou réprobation une nourriture et un régime alimentaire jugés néfastes sur le plan diététique, en raison notamment d'une haute teneur en énergie - principalement des calories vides, due aux graisses et au sucre, et d'une faible valeur nutritive. La nourriture de fast-food, les snacks (frites, chips, biscuits) et sodas en sont des archétypes. Une telle alimentation peut favoriser l'obésité, le diabète, les maladies cardiovasculaires, certains cancers, des dépressions, etc.

Certains appellent aussi "malbouffe" la consommation de préparations alimentaires qui ont tendance à employer dans leur composition toujours plus d'additifs (stabilisants, épaississants, raffermissant, agent de texture, agent de charge, agent de rétention d'eau, exhausteurs de goûts, arômes, etc.) et toujours moins de produits de base. Une partie de la recette peut ainsi être dénuée de toute valeur nutritive, mais la préparation aura un aspect attractif. La surconsommation de la malbouffe peut entraîner la malnutrition.

La définition du terme "malbouffe" a été étendue à une critique plus globale dénonçant un modèle productiviste et la société de consommation.

Le néologisme "malbouffe" a été formé par Stella et Joël de Rosnay par agglutination d'un adverbe et d'un substantif, ce que la syntaxe du français ne permet généralement pas puisque ce sont les adjectifs qui qualifient les noms.

Le risque de dépression a été corroboré par une étude espagnole de janvier 2011 qui a porté sur et a analysé leur alimentation durant six ans : les résultats suggèrent un risque de dépression « 48 % plus élevé » pour les sujets ayant consommé des graisses saturées par rapport aux sujets se nourrissant d'une autre manière.

Un lien a été constaté entre l'obésité, les maladies cardiaques et l'inflammation du cerveau chez la souris mâle et non chez la femelle. Après avoir exploré ce phénomène, des chercheurs ont publié une étude (en 2014 dans la revue scientifique américaine "Cell Reports" spécialisée dans la biologie cellulaire), concluant que chez des souris de laboratoire des deux sexes ayant subi un régime riche en matières grasses tel que décrit par le vocable "malbouffe" ( dans l'article), les cerveaux des souris mâles sont effectivement devenus nettement plus sensibles aux lésions inflammatoires que ceux des souris femelles. Les auteurs estiment que les œstrogènes spontanément produits par les femelles auraient un effet protecteur. En outre les souris mâles exposées à ce régime alimentaire étaient plus enclines à l'intolérance au glucose et à des altérations de la fonction cardiaque. Ceci laisse craindre que des effets similaires soient possibles chez l'humain. Cette étude pointe la responsabilité des acides palmitiques comme cause de l'inflammation cérébrale chez les mâles, mais il a aussi été montré qu'un régime riche en sucre peut causer une inflammation de l'hypothalamus chez le rat de laboratoire.

Une étude réalisée par l'Institut de recherche Scripps sur des rats en 2008 suggère que la consommation de malbouffe modifie l'activité cérébrale d'une manière similaire aux drogues addictives comme la cocaïne et l'héroïne. Après plusieurs semaines avec accès illimité à de la malbouffe, les centres de plaisir des cerveaux des rat sont devenus désensibilisés, nécessitant plus de nourriture pour le même plaisir ; après que la malbouffe a été remplacée par une alimentation saine, les rats se sont affamés pendant deux semaines plutôt que de manger des aliments sains.

Une étude américaine sur des écoliers entre 10 et 14 ans publiée en décembre 2014 met en évidence un lien entre consommation de malbouffe et résultats scolaires.

Une étude iranienne publiée en mai 2014 montre un lien entre la consommation de malbouffe et la santé mentale des enfants et adolescents iraniens : les étudiants qui consommaient quotidiennement des boissons sucrées, de la nourriture de fast food ou des snacks salés avaient davantage de risques d'avoir une faible estime d'eux-mêmes, d'être agressifs, anxieux, insomniaques et désorientés.

Un des opposants déclaré à la malbouffe le plus marquant est l'altermondialiste député européen José Bové, ancien porte-parole du troisième syndicat agricole français : Confédération paysanne. Celui-ci tire sa légitimité de son activité d'éleveur de brebis sur le causse du Larzac mais surtout de ses actions militantes mettant l'accent sur l'importance de l'autosuffisance alimentaire et la préservation de l'environnement. Pour les filières d'exploitations agricoles spécialisées dans l'élevage bovin ayant adopté le système intensif comme moyen de production et fournisseurs des chaînes de , cette légitimité est mise en doute.

À la suite de Jamie Oliver, des chefs cuisiniers français médiatisés comme Cyril Lignac ont décidé depuis les années 1990 de réagir et de faire de l'éducation culinaire et de l'éducation au goût dans les écoles, la "Semaine du Goût" a été créée.
Des agriculteurs, des associations et mouvements de consommateurs et des diététiciens sont également en première ligne, notamment pour veiller à l'alimentation des jeunes et faire évoluer la publicité et la législation française.
Autres opposants publics à la malbouffe, mais moins médiatisés, les mouvements pour la promotion des bons produits, du goût et du patrimoine culinaire, tel le mouvement , qui a pris naissance en Italie.




</doc>
<doc id="15455" url="https://fr.wikipedia.org/wiki?curid=15455" title="Imposition en France">
Imposition en France

L’imposition en France regroupe l'ensemble des impôts, taxes, redevances, contributions et cotisations sociales auxquels les administrations publiques françaises soumettent les personnes physiques et morales françaises ou vivant en France. Le total des impositions de toutes natures et des cotisations sociales représente 45,8 % du produit intérieur brut (PIB) en 2006. Pour une économie de marché, ce niveau est élevé par rapport aux niveaux des pays développés comparables : l'imposition moyenne des trente pays membres de l'OCDE représente 35,9 % du PIB en 2005 (inférieure en moyenne de de PIB). 

La France est ainsi décrite comme une « championne de la pression fiscale dans le monde » avec, en 2014, le second taux de prélèvements obligatoires le plus élevé dans le monde.

L'administration française utilise la notion de prélèvements obligatoires, définie par l'OCDE, qui représentaient 44,2 % du PIB en 2006. De ce champ sont exclues des cotisations sociales (même obligatoires) qui ne constituent pas une recette pour les administrations publiques (cotisations sociales dites volontaires, versés à d'autres organismes que les administrations publiques). Le Conseil des prélèvements obligatoires a souligné les limites de cette mesure dans un rapport de mars 2008. Les diverses formes d'imposition en France revêtent une grande diversité, ce qui rend plus complexe l'effort de définition et de catégorisation.

Les impositions n’ont pas toutes un caractère fiscal. Ainsi les redevances pour services rendus, prélevées à l’occasion de l’utilisation d’un service, échappent au droit fiscal. Les cotisations sociales relèvent du droit de la Sécurité sociale.

La notion de prélèvements obligatoires, bien que considérée par les spécialistes comme encore incomplète, englobe un champ plus large au sein des recettes des administrations publiques et est utilisée pour comparer le poids des États dans l’économie.

Historiquement, la plupart des impôts ont été établis en nature, soit en parts de récolte (dîme, champart, etc.), soit en travaux (corvées, service militaire). Progressivement, chacun de ces impôts a été remplacé par une contribution en numéraire, plus pratique aussi bien pour l'autorité que pour le contribuable. 

La taille, au est l’un des plus anciens impôts prélevés par la monarchie française. Elle a remplacé le fouage.

Sous l’Ancien Régime, la collecte des impôts était affermée, c’est-à-dire que l’État confiait cette tâche à des entrepreneurs spécialisés, les fermiers généraux, qui lui avançaient le montant de l’impôt à percevoir pour se rembourser ensuite sur les imposables. Ce système était commode pour l'État (la recette était connue d'avance et il se déchargeait de l'impopularité des collecteurs d'impôts) et pour les fermiers généraux (bien rémunérés). Le peuple y voyait surtout une source d'injustice et d'excès dans la collecte, mais cette critique doit être relativisée : 
En entamant sa régence, Philippe d'Orléans, conscient du problème, adresse le une « "Lettre à MM. les intendants commissaires départis dans les provinces" », dans laquelle il déclare que sa préoccupation majeure est le poids excessif des différentes taxes et annonce son intention d'établir un système d'imposition plus juste et plus égalitaire.

La Révolution française mérite bien son nom en matière fiscale. La ferme générale est abolie, les fermiers généraux guillotinés, les impôts uniformisés sur le territoire, une véritable administration fiscale mise en place. Le parlement, au nom du peuple, prend le contrôle des impôts, détruit tous les statuts et privilèges fiscaux, rêve d'une égalité contributive "proportionnelle" (qui ne sera jamais véritablement mise en place) et formalise cette prise de pouvoir dans la Déclaration des droits de l'homme et du citoyen de 1789, article 13 : 

Au , les impôts évoluent peu. Sont levés principalement des impôts sur le patrimoine (taxes foncières), sur l'activité (la patente, ancêtre de la taxe professionnelle), et beaucoup de taxes indirectes lors des échanges de biens (succession, achat immobilier, enregistrement de valeurs mobilières, etc.). Au tournant du , on commence à discuter de la mise en place d'un impôt sur le revenu, mis en place finalement en 1914 et 1917. En 1943, on abolit enfin la douane intérieure (l'octroi). 

Enfin, dernière innovation notable sur le plan technique, la TVA est introduite progressivement à partir de 1954, en France d'abord, puis sur son exemple plus largement dans le monde. Adoptée partout en Europe, elle sera unanimement considérée comme la meilleure base pour alimenter les caisses de l'Union européenne. 

Le système fiscal français se retrouve actuellement controversé : avec le développement de l'Union Européenne et la mondialisation, la concurrence fiscale s'est fortement accrue. Il devient nécessaire de prendre en compte les possibilités nouvelles d'évitement (pratique légale d'expatriation fiscale et de fraude fiscale), sans pour autant reporter une charge excessive sur l'assiette fiscale qui ne peut se délocaliser. La concurrence fiscale tend en effet à augmenter l'impôt sur la consommation et les importations et à diminuer celui qui frappe les valeurs mobilières ou le travail (délocalisables).

L'impôt constitue un prélèvement obligatoire effectué par voie d’autorité par l'État et les administrations territoriales sur les ressources des personnes résidentes (c'est-à-dire vivant sur leur territoire ou y possédant des intérêts) pour être affecté aux services d'utilité générale.

La taxe est un prélèvement assorti d’une contrepartie, c'est-à-dire l'utilisation d'un service ou ouvrage public. Mais cette contrepartie reste secondaire dans sa définition, ce qui la distingue de la redevance. Ainsi, et d’une part, il ne peut exister aucune proportionnalité entre la somme réclamée et le service rendu. D’autre part, la taxe est exigible même si le redevable ne fait aucune utilisation du service rendu.

Les impôts et les taxes relèvent des mentionnées à l’article 34 de la Constitution, en vertu duquel le législateur a compétence exclusive pour déterminer leur assiette, taux et procédure de recouvrement. On peut ainsi décrire le champ fiscal comme l'ensemble de tous les impôts, droits ou taxes qui relèvent de l'article 34 et donc de la compétence législative. La jurisprudence du Conseil Constitutionnel joue un rôle important dans la définition de ce champ.

Par exception, les taxes peuvent être éventuellement perçues au profit de personnes privées chargées d’une mission de service public.

La redevance est la recette prélevée à l’occasion d’un service rendu à l’usager. Au contraire de la taxe, la redevance n’est perçue que si l’usager tire un avantage effectif du service et si une certaine proportionnalité existe entre la somme réclamée et le service rendu.
À ce titre, elle fait partie des recettes non fiscales des administrations et est instituée, en ce qui concerne l’État, par voie réglementaire (article 37 de la Constitution). La loi organique relative aux lois de finances (LOLF) prévoit cependant à son article 4 que le décret instaurant la redevance doit faire l’objet 

Cette catégorie de prélèvement a été supprimée par la LOLF à compter du janvier 2004. Les taxes parafiscales avait été définies par un avis du Conseil d’État comme les prélèvements obligatoires, recevant une affectation déterminée, institués par voie d'autorité, généralement dans un but d'ordre économique, professionnel ou social. L'article 4 de l'ordonnance du 2 janvier 1959 précisait qu’elles ne pouvaient être perçues qu’au profit .

Établies par voie réglementaire, elles permettaient ainsi de financer l’action publique dans un domaine sectoriel, au moyen d’un organisme, privé ou public, chargé d’une mission de service public.

Après leur suppression, elles ont été fréquemment remplacées par des taxes fiscales ordinaires.

La cotisation de sécurité sociale se distingue de l’impôt par le fait qu’elle a une contrepartie et qu’elle est affectée au financement de la protection sociale. Depuis la réforme du système de financement de la sécurité sociale par l'État, qui s'est traduite par une loi organique encadrant le vote annuel des lois de financement de la Sécurité sociale, les recettes prévisionnelles de la Sécurité sociale font l’objet d’un vote au Parlement (mais non d'une autorisation). Les cotisations sociales restent établies et recouvrées dans les conditions fixées par les organismes de Sécurité sociale.

Inversement, tous les prélèvements affectés au financement de la protection sociale ne sont pas des cotisations. En particulier, la CSG fait partie des impositions de toutes natures, dont la compétence relève du législateur.

La définition des prélèvements obligatoires par l'OCDE est plus large que le champ fiscal : elle désigne les . D'après le Conseil des prélèvements obligatoires, trois critères sont cumulativement nécessaires à cette qualification :


Les cotisations sociales sont explicitement incluses par l'OCDE dans ses statistiques sur les prélèvements obligatoires, à condition qu'elles soient versées à des administrations publiques ou assimilées et bien qu'elles soient perçues dans un but déterminé (la protection sociale) et qu'elles soient assorties de contreparties indirectes (prestations sociales ou couverture d'un risque). Certaines cotisations, même obligatoires, en sont exclues lorsqu'elles sont versées à des organismes privés qui ne sont pas contrôlés par les pouvoirs publics.

Les prélèvements obligatoires comprennent donc les impôts et taxes, mais aussi certaines recettes non fiscales de l’État (comme le produit versé par la Française des jeux) et les cotisations sociales effectives. Certains taxes en sont exclues car elles correspondent à la rémunération d’un service précis, leur montant étant en rapport avec ce dernier : l’opération est alors traitée en achat de service marchand.

Ainsi, contrairement aux apparences, la notion de prélèvements obligatoires ne recoupe pas entièrement la distinction entre taxe et redevance. Par exemple, la taxe d’enlèvement des ordures ménagères, prélevée avec la taxe foncière sur le bâti, est considérée comme une taxe par le Conseil d’État mais n’est pas incluse dans les prélèvements obligatoires.

En France, le poids des prélèvements obligatoires atteignait 44,5 % du PIB en 2010 contre 40,2 % en moyenne dans les pays de la Zone Euro et jusqu'à 27,2 % en Corée du Sud (en 2001). Le taux global de prélèvement social et fiscal sur le salaire moyen atteignait en 2005 71,3 % du salaire brut, soit le taux le plus élevé de l'OCDE. Le niveau des cotisations sociales est également élevé (16,1 % du PIB).

Les principaux impôts sont, en milliards d'euros :
La suppression de l'imposition forfaitaire annuelle des sociétés (IFA) est entrée en vigueur depuis le janvier 2014. Jusqu'au 31 décembre 2013, l'IFA était due par les personnes morales soumises à l'impôt sur les sociétés qui réalisaient un chiffre d'affaires hors taxes, majoré des produits financiers, supérieur à 15 millions d'euros.

Le niveau de prélèvements obligatoires est important en France.

En 2009, l'impôt sur les sociétés, par exemple, y est le plus élevé d'Europe (38 %) devant l'Allemagne (30 %). Certains estiment même que la France aurait la pression fiscale la plus lourde du monde ou qu'elle serait le pays le moins accueillant en termes de fiscalité. Selon une étude du cabinet d'audit PricewaterhouseCoopers et de la Banque mondiale, la France qui avait le taux d'imposition sur les entreprises de taille moyenne le plus élevé en Europe en 2013, se situe, en 2014, au deuxième rang -derrière l'Italie, avec un taux de 62,7 % de leur résultat commercial. La France est largement au-dessus de la moyenne européenne (40,6 %). En ce qui concerne les prélèvements basés sur les salaires, la France maintient toujours sa dernière place en Europe.

En réalité, si la France a un taux de prélèvement obligatoire supérieur à la moyenne de l'UE (environ cinq points au-dessus) et de l'OCDE (environ dix points au-dessus), celui-ci n'était, d'après l'OCDE, que le en 2005.

D'après le rapport annuel de la Commission européenne, la France a (avec l'Italie) le d'imposition le plus élevé en Europe (derrière le Danemark, la Suède, la Belgique, la Finlande et l'Autriche).

En 2017, selon les prévisions du ministère de l'Économie, personnes privées et entreprises paieront plus de milliards € de prélèvements, les impôts, taxes et l'ensemble des cotisations sociales, ayant augmenté de près de 95 Mds€ de 2012 à 2017 sous le mandat de François Hollande (près de 50 Mds€ hors inflation), après une augmentation de 95 Mds€ de 2007 à 2012 sous le mandat de Nicolas Sarkozy .

Le nombre très élevé des impôts et taxes (214 taxes différentes en 2006) et leur complexité rendent le système fiscal français très difficile à gérer. Les coûts de gestion d'un certain nombre de taxes peuvent être supérieurs à ce qu'elles rapportent. Un rapport de l'Inspection générale des finances (IGF) de 2014, commandé par le gouvernement français, a identifié 192 « petites taxes », dont le rendement est inférieur à 150 millions d'euros par an.

La France dépense 53 % du PIB en dépenses publiques dont 30 % pour des transferts et 23 % pour la fourniture de biens et services publics
. Selon l'Insee, la fiscalité réduit le niveau de vie du quintile supérieur de 22 % et augmente celui du quintile inférieur de 40 %.



</doc>
<doc id="15456" url="https://fr.wikipedia.org/wiki?curid=15456" title="Aliment biologique">
Aliment biologique

Un aliment biologique est un aliment produit suivant les principes de l'agriculture biologique.
En France, le label Agriculture biologique peut s'appliquer aux aliments issus de produits respectant les standards de l'agriculture biologique, et transformés selon des méthodes elles aussi standardisées.

Il existe une tolérance de 5 % pour les ingrédients comme le sel marin qui, sans être des aliments biologiques "stricto sensu", sont des produits naturels sans élément chimique de synthèse rajouté par l’homme.

Sur le plan de la valeur nutritionnelle, un rapport de 2003 de l'Agence française de sécurité sanitaire des aliments (Afssa) trouve et observe que . Cette équivalence nutritionnelle (en vitamines, minéraux, acides gras, protéines...) est confirmée par une étude de 2012.
Une méta-analyse de 343 publications scientifiques réalisée en 2014 par dix-huit chercheurs européens a toutefois montré l'existence de différences nutritives substantielles en faveur des aliments biologiques. Ces différences ne portent pas sur la teneur des aliments en nutriments mais sur la présence de substances toxiques telles que cadmium et pesticides, et sur la teneur en antioxydants. Leurs effets sur la santé restent à déterminer. Selon une étude de l'Autorité européenne de sécurité des aliments (EFSA) en 2015, il est « peu probable » que l'exposition alimentaire à des résidus de pesticides ait « des effets à long terme sur la santé des consommateurs ».

Par ailleurs, une méta-analyse de l'université de Newcastle upon Tyne conclut que le lait et la viande biologiques contiennent sensiblement plus d'acides gras oméga-3, de sels minéraux et d'antioxydants essentiels que leurs homologues conventionnels.

Les qualités organoleptiques d'un aliment biologique sont difficiles à évaluer. L'INRA conclut à une absence de différence significative de ces qualités entre l'agriculture biologique et conventionnelle.

L'épidémie de gastro-entérite et de syndrome hémolytique et urémique de 2011 en Europe a été causée par des graines germées produites dans une ferme biologique en Allemagne mais le lien épidémique reste pour l'heure inexpliqué.

Si un produit, conventionnel ou biologique, contient plus de 0,9 % d'OGM, il doit être étiqueté. En dessous de cette valeur, aucune indication au consommateur n'est requise. Chaque État membre reste toutefois libre de renforcer sa législation sur la labellisation des produits « bio » sur son territoire.

Les graines germées biologiques sont obtenues en n'utilisant pas de pesticides et en excluant les OGM. Les graines déjà germées sont majoritairement produites en hydroponie par des entreprises spécialisées et vendues en grandes surfaces.

L'association UFC-Que choisir a relevé prix dans magasins et montré que le panier d'articles biologiques vendus sous marque de distributeur (MDD) coûtaient 57 % de plus que l'équivalent en MDD classiques ; selon Cécile Lepers de Synabio .

En 2010, les approvisionnent directement les réseaux spécialisés (La Vie claire, Biocoop, Naturalia, Croc'Nature). Les hypermarchés se fournissent presque exclusivement à l'étranger auprès d'un : de 8 à 10 % des lots de produits biologiques contrôlés contiennent des résidus phytosanitaires interdits dans leur production, en particulier dans les arrivages d'Italie et d'Espagne.

En 2015, la vente de produits bio a augmenté de 14,7 % pour atteindre d’euros en France.




</doc>
<doc id="15466" url="https://fr.wikipedia.org/wiki?curid=15466" title="Fleuve Jaune">
Fleuve Jaune

Le fleuve Jaune () est le deuxième plus long fleuve de Chine après le Yangzi Jiang. Long de , il se jette dans la mer de Bohai, dans la mer Jaune.

Son nom lui vient de sa couleur boueuse liée à sa forte turbidité car il charrie de grandes quantités d'alluvions (lœss, limons) qui fertilisent la grande plaine du Nord de la Chine.

En 1938, le Kuomintang détruit des digues retenant le fleuve dans le but de ralentir l'avancée de l'armée japonaise, ce qui provoque de graves inondations et cause au moins morts parmi la population locale.

Le fleuve Jaune ou Huang He (), s'écrit également en hanyu pinyin "Huánghé", en tibétain , "", littéralement « le fleuve du paon »).

Le fleuve prend sa source dans les monts Kunlun (province du Qinghai) et se dirige vers l'est à travers le plateau tibétain dans lequel il a creusé de profondes gorges. Après Lanzhou (province du Gansu), le fleuve parcourt une vaste boucle dans le plateau désertique de l'Ordos, en Mongolie-Intérieure. Il traverse notamment Kaifeng, Wuhai, Baotou, Jinan (capitale du Shandong) et se jette finalement dans la mer de Bohai sous la forme d'un delta.

Le fleuve Jaune est réputé pour ses crues désastreuses, au cours desquelles il a plusieurs fois changé de cours, avec parfois un parcours alternatif beaucoup plus méridional passant par le lac Hongze.

Troublant le cours du fleuve Jaune, les chutes de Hukou (bec de bouilloire) ont le deuxième plus gros débit de Chine. En été, leur volume peut être multiplié par sept, émettant le bruit de bouillonnement auquel elles doivent leur nom.

Le fleuve Jaune a subi un certain nombre d'aménagements, dont des aménagements hydroélectriques, on peut ainsi citer notamment le barrage de Lijiaxia, le barrage de Longyangxia, le barrage de Xiaolangdi, le barrage de Laxiwa, le barrage de Wanjiazhai, le barrage de Liujiaxia ou encore le barrage de Sanmenxia.

Depuis le milieu des années 1980 le niveau de pollution, qui était déjà élevé, a encore été multiplié par deux.

La pollution, par les métaux lourds et métalloïdes notamment, (abondamment retrouvés dans les sédiments de l'estuaire) provient de la concentration d'usines de l'industrie chimique et pharmaceutique installées le long du fleuve et de ses affluents, notamment à Shizuishan, actuellement considérée comme l'une des villes les plus polluées du monde.

Par suite d'un essor économique brutal, des prélèvements d'eau importants sur le fleuve Jaune liés à la prolifération d'exploitations agricoles, de villes, et d'usines, provoquent l'asséchement du fleuve. 
La prélèvement d'eau représente en effet 70 % du débit total moyen à long terme du fleuve Jaune. La période durant laquelle le fleuve s'assèche avant d'atteindre la mer ne cesse de s'allonger d'année en année - à peu près 200 jours en 1997. Cette situation pousse les autorités à pomper l'eau de la nappe phréatique à une vitesse qui dépasse la recharge de la nappe, de sorte que son niveau baisse inexorablement. Ce phénomène est l'un des problèmes de pénurie d'eau les plus sensibles de la planète, du fait que le fleuve draine un immense bassin céréalier qui alimente une population très nombreuse. Il ne s'agit que de l'un des nombreux problèmes d'utilisation non durable de l'eau que l'on rencontre aujourd'hui dans le monde.

Le fleuve Jaune est un exemple extrême d'un cours d'eau ayant virtuellement perdu toutes ses fonctions écosystémiques et naturelles en raison de la gravité des altérations anthropiques portées au régime hydrologique et à l'écosystème fluvial.




</doc>
<doc id="15467" url="https://fr.wikipedia.org/wiki?curid=15467" title="Édouard IV">
Édouard IV

Édouard IV d'Angleterre ( – ) est roi d'Angleterre de 1461 à 1483. Il prend la succession d'Henri VI le à la suite de la victoire de Towton. Il est le premier roi d'Angleterre issu de la maison d'York. La première partie de son règne s'avère troublée par la guerre des Deux-Roses, mais, une fois la menace de la maison de Lancastre éliminée à la suite de la bataille de Tewkesbury, l'Angleterre connaît la paix jusqu'à sa mort soudaine. Son règne est brièvement interrompu par un retour de Henri VI entre le et le .

Édouard est le quatrième enfant de Richard Plantagenêt, comte de Rutland, de March, d'Ulster et de Cambridge, duc d'York († 1460) et de Cécile Neville († 1495). Il naît à Rouen, alors sous contrôle anglais, le . Il est l'aîné des quatre fils de Richard qui atteignent l'âge adulte. Les prétentions de son père à la couronne d'Angleterre, et la santé mentale inégale du roi Henri VI forment le facteur déclenchant de l'escalade du conflit connu sous le nom de guerre des Deux-Roses. Après la défaite des Yorkistes à Ludford Bridge, en octobre 1459, Édouard se réfugie à Calais avec le comte de Salisbury. Ils déjouent les tentatives des Lancastre de reprendre la ville et regagnent l'Angleterre au début de l'été 1460. Édouard commande un des trois corps de l'armée yorkiste lors de la victoire de Northampton, le . Richard d'York se fait alors reconnaître par le Parlement comme le successeur d'Henri VI par l'Acte d'Accord du 24 octobre.

Quand Richard est vaincu et tué par les Lancastre à Wakefield, le , Édouard hérite de tous ses titres (sauf celui de comte de Rutland) et devient le chef de la maison d'York, revendiquant directement la couronne. Après avoir obtenu le soutien de son cousin, Richard Neville, fils du comte de Salisbury, il remporte sa première bataille à Mortimer's Cross le . Il entre alors dans Londres, tenue par Neville, où, après avoir été acclamé par une foule en liesse, il se fait couronner hâtivement roi d'Angleterre le 4 mars. Dès le lendemain, il part à la tête de son armée affronter celle des Lancastre et, le , il remporte la décisive bataille de Towton, où l'armée des Lancastre est anéantie. Édouard IV est alors un jeune homme de 18 ans, avenant, grand () et musclé, charismatique revêtu de son armure et doué pour les armes ; en comparaison son rival est un homme frêle et mentalement instable perçu comme une marionnette de sa femme. Henri VI reste chez lui à York pendant la bataille, alors que le nombre de morts est égal à au moins 1 % de la population anglaise de l'époque, et qu'Édouard combat héroïquement en première ligne pour inspirer ses troupes et les mener sur le terrain. 

De retour à Londres, il se fait couronner officiellement le 28 juin.

Malgré la résistance des partisans des Lancastre au nord de l'Angleterre, la mainmise d'Édouard IV sur le royaume n'est pas remise en cause, d'autant qu'Henri VI est finalement capturé en 1465 et enfermé à la tour de Londres. Au début de son règne, Richard Neville, comte de Warwick, s'avère tout-puissant et possède la haute main sur la politique du royaume. Mais Édouard s'aliène Neville quand, en 1464, il se marie secrètement à Élisabeth Woodville (1437 – 1492), la veuve d'un sympathisant de la maison de Lancastre, alors que Neville projetait de l'unir à Bonne de Savoie, belle-sœur du roi Louis XI. Dès lors, l'influence de Neville sur le roi commence à décroître au profit de la famille d'Élisabeth Woodville, et notamment de son père Richard Woodville. Son ressentiment, renforcé par le refus d'Édouard de laisser ses frères Georges et Richard se marier avec les deux filles de Neville Isabelle et Anne, ainsi que par la préférence d'Édouard d'une alliance avec la Bourgogne plutôt qu'avec la France, le pousse à comploter avec Georges, duc de Clarence, le frère cadet d'Édouard.
Neville et Clarence lèvent une armée qui bat celle d'Édouard (mais sans lui pour la mener) à Edgecote Moor le . Édouard est alors fait prisonnier, Neville fait exécuter le père d'Élisabeth Woodville et tente de gouverner au nom du roi, en espérant faire monter sur le trône Georges, l'héritier présomptif d'Édouard (qui n'a pas encore de fils), et qui vient d'épouser Isabelle Neville. Cependant, une grande partie de la noblesse du pays est hostile à cette idée, et le deuxième frère d'Édouard, Richard, duc de Gloucester, lève à son tour une armée et fait libérer son frère. Édouard, plutôt que de faire exécuter Neville et son frère Georges, cherche à se réconcilier avec eux. Mais ils se rebellent à nouveau et sont forcés de fuir en France quand Édouard bat leur armée lors de la bataille de Losecoat Field, le . Accueillis à la Cour du roi Louis XI, ils concluent une alliance avec Marguerite d'Anjou, épouse d'Henri VI, et Neville accepte de restaurer celui-ci sur le trône en échange d'un soutien français à son projet d'invasion, qu'il mène à bien au mois d'octobre 1470. La libération de Henry Percy, dont le père lancastrien est mort à Towton, et son rétablissement en tant que comte de Northumberland, entraîne la défection de John Neville, qui espérait conserver le titre, récompense accordée par Édouard IV après ses victoires pour York. John se rallie à son frère Richard Neville et le rejoint à la tête d'une forte armée. Voyant que la situation militaire est intenable, Édouard disperse ses troupes et s'enfuit en Bourgogne avec son frère Richard de Gloucester pendant qu'Henri VI est rétabli sur le trône d'Angleterre par Neville.

Édouard est accueilli par son beau-frère, Charles "le Téméraire", qui est malgré tout réticent à lui apporter son aide pour reconquérir le trône. Mais l'alliance entre Neville et la France et la menace d'une invasion le poussent à changer d'avis ; Charles fournit à Édouard de l'argent et des troupes. Édouard débarque à Ravenspurn, sur la côte du Yorkshire, le à la tête de forces relativement modestes. Il traverse les terres d'Henry Percy, qui fait semblant de croire qu'Édouard désire simplement rétablir ses droits sur son duché. La ville d'York lui ferme ses portes et il marche alors vers le sud en obtenant du soutien et en rassemblant des troupes sur sa route. Son frère Georges (qui voit ses droits dynastiques réduits à néant avec le rétablissement d'Henri VI) change alors à nouveau de camp et le rejoint. Édouard entre dans Londres sans résistance, faisant à nouveau prisonnier Henri VI, et triomphe de l'armée de Neville lors de la bataille de Barnet, où Richard et John Neville eux-mêmes sont tués, le . Puis il bat l'armée de Marguerite d'Anjou à la bataille de Tewkesbury, le , où Édouard de Westminster, le fils d'Henri VI est exécuté. Quelques jours plus tard, Henri VI meurt à son tour soudainement, Édouard ayant sans doute donné l'ordre de le tuer afin d'éliminer définitivement la menace des Lancastre. Le cousin de Warwick, Thomas Neville, qui attaque par le sud-est et fait le siège de Londres, est capturé à Southampton.

Toute opposition à Édouard IV est dès lors éliminée à l'intérieur du pays et il peut se consacrer aux affaires extérieures. En 1475, il monte une expédition militaire en France à partir de Calais dans le but de reprendre les possessions anglaises en France, perdues sous le règne d'Henri VI. Conscient du faible potentiel de son armée, essentiellement constituée d'archers sans expérience guerrière, et devant l'absence de soutien militaire de Charles "le Téméraire", il préfère accepter les offres généreuses du roi de France Louis XI et le traité de Picquigny, signé le , met officiellement fin à la guerre de Cent Ans. 

La rivalité constante entre les deux frères d'Édouard, désormais mariés aux deux filles de Neville, concernant l'héritage de leur père, trouble le monarque et, en février 1478, Georges est accusé de comploter contre Édouard et, convaincu de trahison, est exécuté en privé (noyé dans une barrique de malvoisie selon la tradition populaire). Richard capte alors l'héritage du comte de Warwick.

Édouard soutient les prétentions d'Alexandre Stuart au trône d'Écosse et, en 1482, charge son frère Richard de mener une invasion de ce pays. Richard s'empare d'Édimbourg mais quitte la ville peu après en abandonnant Alexandre, se satisfaisant d'avoir ramené la ville de Berwick-upon-Tweed dans le giron de l'Angleterre. 

Néanmoins, la santé d'Édouard IV commence à décliner et il tombe gravement malade en mars 1483. Il a cependant le temps de faire rajouter quelques codicilles à son testament, le plus important étant celui où il nomme son frère Richard comme Protecteur du royaume après sa mort. Il meurt le et est enterré dans la chapelle Saint-Georges, au château de Windsor. Son fils, Édouard V, âgé de douze ans, lui succède sur le trône. La cause précise de la mort d'Édouard IV n'est pas connue avec exactitude, la pneumonie, la typhoïde ou même un empoisonnement faisant partie des principales hypothèses. On peut aussi attribuer sa mort à son style de vie peu sain car, devenu inactif, il avait pris beaucoup d'embonpoint au cours des années précédant sa mort.

Le fils aîné d'Édouard IV, connu sous le nom d'Édouard V, lui succède. Le conseil de régence dirigé par Richard, lord protecteur du royaume et tuteur du jeune roi se saisit d'un possible cas de bigamie du roi décédé. Il fut établi qu'Édouard IV aurait promis le mariage à Éléonore Talbot en 1461 et celle-ci, décédée en 1468, était encore vivante lors du mariage d'Édouard avec Élisabeth Woodville. Robert Stillington, évêque de Bath et Wells, affirma avoir célébré la cérémonie ; le mariage d'Édouard IV avec Élisabeth est par conséquent invalidé et tous ses enfants reconnus illégitimes. Édouard V est déposé le et enfermé à la tour de Londres en compagnie de son frère cadet, Richard de Shrewsbury ; son titre lui est cependant conservé. Richard, duc de Gloucester, est couronné sous le nom de Richard III. Les deux enfants n'ont plus été revus en vie après l'été 1483 ; ce qu'il leur advint, mort naturelle ou violente, reste l'un des plus grands mystères de la couronne d'Angleterre ainsi que le sujet de nombreux débats.

Édouard IV, de belle allure et au physique impressionnant (sa taille, estimée à , en fait le plus grand monarque britannique à ce jour), était un chef militaire redouté et extrêmement compétent, doté d'un grand flair. Il réussit à détruire la maison de Lancastre par une série de victoires spectaculaires et ne fut jamais vaincu sur le champ de bataille. En dépit de ses quelques revers politiques, souvent provoqués par son grand rival, le roi Louis XI, il fut un souverain populaire et capable. Bien que manquant de prévoyance et ayant commis à l'occasion des erreurs de jugement, il possédait une compréhension troublante de la plupart de ses sujets les plus importants, et la grande majorité de ceux qui l'ont servi lui restèrent indéfectiblement loyaux jusqu'à sa mort, y compris dans le rang de ses anciens ennemis lancastriens.

Sur le plan intérieur, le règne d'Édouard IV vit la restauration de l'ordre en Angleterre (le "moto" d'Édouard étant d'ailleurs "modus et ordo", « la méthode et l'ordre »), et la piraterie et le banditisme, qui avaient pris beaucoup d'importance sous le règne d'Henri VI, décrurent considérablement. Édouard fut aussi un homme d'affaires perspicace qui investit avec succès dans plusieurs corporations de la "City" de Londres. 

Néanmoins, en dépit de son génie militaire et administratif, la dynastie d'Édouard IV ne lui survécut qu'à peine deux ans. Mais par sa fille Élisabeth d'York, mère de Henri VIII, ses descendants ont continué à occuper le trône d'Angleterre. Il fut l'un des rares membres masculins de sa famille à mourir de cause naturelle. En effet, son père Richard et son frère Edmond furent tués à la bataille de Wakefield ; son grand-père, Richard de Conisburgh, et son frère Georges furent exécutés pour trahison ; ses deux fils furent emprisonnés et disparurent (probablement tués) l'année de sa propre mort ; son frère Richard fut tué lors de la célèbre bataille de Bosworth qui l'opposa à Henri Tudor.

De son mariage avec Élisabeth Woodville (1437 – 1492) naissent dix enfants :

Il eut également de nombreuses maîtresses, la plus célèbre de toutes étant Jane Shore, et il est rapporté qu'il eut plusieurs enfants illégitimes, dont le plus connu reste Arthur Plantagenêt, qui fut une célèbre figure de la Cour durant le règne d'Henri VIII.





</doc>
<doc id="15468" url="https://fr.wikipedia.org/wiki?curid=15468" title="Alès">
Alès

Alès (prononcer ) est une commune française située dans le département du Gard, en région Occitanie. Elle est considérée comme la « capitale » des Cévennes.

Forte de (2014) et d'une densité de , Alès est la seule commune du département à dépasser une densité de . Par sa population, elle est la deuxième commune du Gard et la treizième d'Occitanie. Ses habitants sont appelés les "Alésiens" et "Alésiennes".

Située à au nord-nord-ouest de Nîmes, la ville d'Alès est édifiée dans une boucle du Gardon d'Alès dans la plaine, au pied des Cévennes. La cité cévenole constitue une bonne base de départ pour la découverte des Cévennes. La ville subit une extension géographique vers le sud.

Le climat à Alès est méditerranéen, c’est-à-dire de type "Csa" selon la classification de Köppen-Geiger. Les saisons sont bien marquées, les hivers sont doux et pluvieux et les étés sont chauds et secs. 

Alès, étant à la porte des Cévennes, souffre en automne (octobre/novembre) d'épisodes cévenols, ce sont de très violents orages causant de grandes inondations. En quelques heures, des centaines de millimètres d'eau peuvent tomber, soit l'équivalent de plusieurs mois de pluie. Cependant, la ville a pu se doter d'infrastructures suffisamment sûres pour éviter des dégâts gravissimes ou mortels.

Le climat de la region d'Alès est mesuré depuis 2014 à l'aide des relevés de la station météorologique de Saint-Hilaire-de-Brethmas qui se situe dans l'agglomération du Grand Alès.


Le réseau, baptisé NTecC (Nouveau Transport en commun Cévenol) s'étend sur 62 communes du bassin alésien, et est divisé en 3 zones. La gare routière, située juste à côté de la gare SNCF en centre-ville, constitue le nœud du réseau urbain et suburbain. De nombreuses lignes départementales desservent aussi Alès.



Le nom d’Alès est attesté sous la forme "Alesto" (sans date) à l'époque mérovingienne, ensuite sous la forme latinisée "Alestum" en 1120, puis "Alest" en 1190 et 1344, "Alez" ou "Allès" en 1435, "Alais" à partir de 1694. En 1926, la graphie du nom de la ville est fixée. Sous l'impulsion du professeur Artigues, "Alais" devient donc Alès. À la fin des années 1980, la municipalité essaya de renommer la ville "Alès-en-Cévennes" afin de bénéficier des retombées d'images positives liées aux Cévennes. Albert Dauzat et Charles Rostaing considèrent le radical "Al-" comme une racine pré-latine obscure. Ils identifient un suffixe pré-latin "-estum". Ils rapprochent ce nom d’Alles-sur-Dordogne ("Alas" 1228, "Alès" jusqu'au ). 

Les habitants d'Alès se nomment les "Alésiens" et les "Alésiennes".

Les fouilles sur la colline de l'Ermitage ont permis de mettre au jour des vestiges d'habitats gaulois du , dont une mosaïque de l'époque de Jules César (première moitié du ). Ses dimensions () et la qualité de ses décors permettent de situer Alès comme un oppidum tirant profit de sa situation à la frontière de la Gaule indépendante et de la province romaine de Gaule transalpine pour établir un commerce fructueux.
Un premier état de sol avec de la chaux a été retrouvé sous la mosaïque, datant de quelques années auparavant, ce qui laisse à penser qu'un "premier" état mosaïqué a existé.

Alès était une cité sur la voie Regordane entre Le Puy et Saint-Gilles.

La famille d'Anduze puis sa descendante Narbonne Pelet était suzeraine d'Alais. On retrouve Raymond Pelet, coseigneur d'Alais, participant à la première croisade.

En 1629, Louis XIII assiège la ville, alors haut-lieu de la résistance protestante, qui capitule après neuf jours. Le dimanche 17 juin 1629 au matin, Alès se rend, les quelque hommes présents en ses murs ne purent rien devant l'armée du roi. Louis XIII fait son entrée à la tête de ses troupes par la porte de la Roque, accompagné par Richelieu en habit militaire. Les huguenots furent autorisés par le roi à partir pour Anduze contre la promesse expresse de ne plus porter les armes contre le roi. Le , Richelieu accorda aux protestants la paix d'Alès ou l'Édit de grâce. Cet édit, qui leur retirait les places fortes mais leur confirmait les garanties religieuses de l'édit de Nantes, a été signé par Richelieu au camp de Lédignan. Louis XIII aurait logé à l'auberge du Coq Hardi, dans la Grand'Rue. Cette rue, aujourd'hui disparue comme tout le quartier, se situait au bas de l'actuelle rue Jules-Cazot. On peut voir le blason au restaurant du Coq Hardi, rue Mandajors.

Un fort de type Vauban, à l'instar de la citadelle de Montpellier, fut bâti après la révocation de l'édit de Nantes sur un point haut de la vieille ville, à l'emplacement des anciens châteaux des seigneurs afin d'y installer une garnison au milieu de la zone tenue par les protestants. Il a abrité un temps une maison d'arrêt. Dans les premières années du éclata la révolte populaire dite « des Camisards ». En 1694 a été créé, sur ordre de Louis XIV, l'évêché d'Alès, dont les titulaires les plus actifs furent Charles de Bannes d'Avéjan et Jean-Louis du Buisson de Beauteville. Le dernier évêque, Louis-François de Bausset, abandonna son poste pendant la Révolution et l'évêché fut supprimé peu après, en 1790.

Alès fut l'un des berceaux des charbonnages des Cévennes, à l'époque de Pierre-François Tubeuf et des premiers entrepreneurs du charbon français. Le charbon de terre est exploité depuis au moins le . La pénurie de bois qui survient au stimule son exploitation. Le charbon est utilisé pour la production de chaux qui nécessite la cuisson de roche calcaire. Le charbon permet aussi de produire de l'acier. Ces exploitations étaient alors artisanales et indépendantes.

En 1773, l'entrepreneur Pierre-Francois Tubeuf obtient la concession exclusive des mines dans toute la région des Basses-Cévennes. Il fait creuser de nouveaux puits plus profonds et plus sophistiqués : systèmes de ventilation et de drainage. En 1788 Tubeuf crée la verrerie de Rochebelle et confie la gestion à l'abbé Bérard.
Tubeuf entre en conflit avec les propriétaires terriens, et finalement, il est chassé en 1786. La concession dite de Rochebelle et Cendras est toutefois renouvelée à sa veuve et ses enfants en 1802.

1828 : cession à Bérard pour sa société d'exploration de mines qui est en train de créer les forges et fonderies de Tamaris, puis création de la société civile de Rochebelle et Trélys.

1834 : absorption par la "Cie des Fonderies et Forges d'Alais" qui exploite principalement pour l'usage de ses usines.

À partir du milieu du et jusqu'au milieu du , l'histoire de la ville est intimement liée à l'extraction du charbon. Elle va devenir un important centre industriel de la région surtout à partir de 1840, date à laquelle Alès est relié par la ligne de chemin de fer Beaucaire-La Grand-Combe (une des premières en France) grâce à Paulin Talabot. D'autres lignes furent ensuite créées pour transporter le charbon, notamment la ligne Alès-Bessèges. La ville d'Alès est alors le pôle principal du bassin houiller des Cévennes.

Le , une ordonnance royale institua à Alès une école pratique destinée à former des maîtres-ouvriers-mineurs. Ce n'est qu'en novembre 1845 que la première promotion fut installée dans les locaux du collège d'Alès. Cet établissement est aujourd'hui une école d'ingénieurs réputée, l'école des Mines d'Alès.

1873 : modification du nom en "Cie des Mines, Fonderies et Forges d'Alais".

1878 : séparation difficile des activités et création avec des capitaux lyonnais de la S.A. des "Houillères de Rochebelle" qui renouvelle les installations, creuse de nouveaux puits de mine etc. Nationalisation en 1946 au sein des "Houillères du Bassin des Cévennes" (secteur sud). Concentration progressive sur le siège modernisé de Ladrecht (puits Fontanes et Destival).

Le site de Rochebelle, dans la commune, sur la rive droite du Gardon, a cessé son activité en 1968, celui de Ladrecht en 1985.

Du 5 mai 1980 au 10 juin 1981, une grève des mineurs de Ladrecht, fut la plus longue d'Europe avec occupation du fond (13 mois). Une grande peinture symbolique en solidarité avec les mineurs a été réalisée en 1981 sur le mur de soutènement en béton du puits Fontanes.

Aujourd'hui, si le chevalement métallique de Fontanes sur l'ancienne mine de Ladrecht a pu être sauvegardé dans le cadre de la Communauté de Communes du Grand Alès, si la molette du puits Destival a trouvé une place sur un rond-point de Saint-Martin-de-Valgalgues, le chevalement béton du puits Destival, très dégradé, présentait un danger pour les personnes qui travaillent sur le site (chutes de blocs de béton). Aussi, après consultation des collectivités, les autorités ont décidé de le démolir. Au cours de la démolition, le bâtiment voisin affecté à la collecte des déchets de la Communauté de communes a d'ailleurs été très sérieusement endommagé.

Il était cependant important de maintenir sur ce lieu, le souvenir de l'histoire industrielle et sociale ancrée dans la mémoire collective des populations du bassin minier d'Alès et de sa région.

Au nord-ouest de la ville, aux portes des habitations, s'élève le mont Ricateau (du nom d'un ancien directeur des houillères locales), crassier de l'ancien site minier de Rochebelle. Depuis un incendie de forêt (24 juillet 2004), ce terril est entré en combustion souterraine.

En juin 1865, Jean-Baptiste Dumas fait appel à son ancien élève, Louis Pasteur pour venir étudier une maladie inconnue qui décime les élevages de vers à soie. Louis Pasteur arrive à Alès le 7 juin 1865 et s'installe à la magnanerie de Pont de Gisquet sur la route qui mène à Saint-Jean-du-Pin. Après quatre années de recherche, il découvre comment identifier les papillons malades et permet ainsi leur éradication avant que tout l'élevage ne soit infesté. Il sauve ainsi en partie l'industrie de la soie dans les Cévennes. Mais elle déclinera à cause de la concurrence asiatique, amplifiée par l'ouverture du Canal de Suez.

Dans le cadre de la reconversion du bassin minier gardois, la Manufacture française de pianos (MFP) s'installa en 1973 à Alès. Elle a fabriqué des instruments sous la marque "Rameau", "Gaveau", "Érard", puis "Pleyel" en 1997. En 2007, Pleyel a définitivement fermé son implantation alésienne (43 salariés).

La ville est libérée par la DB le 21 août 1944.

Le 28 octobre 1948, lors de la grande grève des mineurs, réprimée sur ordre du ministre socialiste Jules Moch qui envoie des blindés en Lorraine, les mineurs de la région d'Alès sont en grève. Lors d'une manifestation, un maçon solidaire, Max Chaptal, tente de franchir un barrage sur un pont. Il est abattu d'une rafale de mitrailleuse tirée d'un char. Les chars tirent au canon sur plusieurs barrages des grévistes. C'est à ce moment-là que naît le slogan CRS-SS. Un quai du centre-ville porte son nom en mémoire de cet évènement.

À la fin de l'année 1956 et durant les années 1960-70, sous les mandats de Paul Béchard et Roger Roucaute, une grande partie du centre historique d'Alès remontant à la période médiévale, en mauvais état général, située à l'ouest et au nord de la cathédrale en direction du Gardon, fut entièrement rasée pour laisser place à une architecture typique des « grands ensembles » des années 1960 de type ZUP et barres HLM. L'ancien lycée Jean-Baptiste Dumas, édifié à la fin du , sur le même modèle que celui du lycée Daudet de Nîmes, et auquel on accédait par une rotonde d'angle surmontée d'une horloge fut également démoli. Son espace abrite aujourd'hui le théâtre ("Le Cratère") et la médiathèque. L'ancien théâtre à l'italienne, installé au sein de l'ancienne église des Cordeliers donnant sur la place de l'Hôtel de ville, fut encore démoli dans les années 1960. Le bâtiment de la "gare du Rhône" du début du , ancienne ligne reliant Alès à Bagnols-sur-Cèze, désaffecté, disparut...

Lors de cette période furent détruits: l'ancienne maison consulaire ; l'ancienne auberge du Coq Hardi dont la façade avait été certes remaniée en 1898 dans le « style troubadour » avec tour arborant mâchicoulis et créneaux ; de l'autre côté de la rue, une maison dont l'ornementation des arcades « en pointe » au rez-de-chaussée et les fenêtres à croisée de meneaux des étages faisait la transition entre le gothique flamboyant et la Renaissance datait aussi du milieu du et ne manquait pas de compléter cet ensemble fort pittoresque. Dans le quartier de la rue Soubeyranne l'ancien couvent des Dominicains avec son cloître à voûtes d’arêtes, ses escaliers à balustres, la chapelle de la Présentation surmontée d'un clocher pointu en tuiles d'écailles vernissées à pans coupés, l'ancien hôtel des « Ours de Mandajors » d'époque Louis XV aux riches décors intérieurs, la place du Marché -de forme rectangulaire- à proximité des quais du Gardon et dont les rez-de-chaussée des maisons comportaient soixante arcades (cette place dont l'ordonnancement n'était pas sans rappeler celles de Sommières ou d'Uzès était prolongée d'une rue arborant le même type d'architecture), la « maison des Appeaux » la « maison Ollier » pourtant inscrite à l'inventaire des monuments historiques en 1955 arborait, pour sa part, une remarquable façade d'époque Louis XV richement ornée de sculptures et balcons ouvragés, la place de l'Abbaye qui comportait encore des vestiges de l'ancienne abbaye Sainte-Claire, etc. Signalons enfin de nombreuses rues et passages étroits, parfois couverts, des venelles, avec des arches de soutènement comme à Sommières.

Alès s'est actuellement lancée dans un projet de rénovation de son centre-ville avec pour objectif un développement durable à travers la réalisation d'un écoquartier.

Liste des maires depuis la Libération :

Alès est l'une des deux sous-préfectures du Gard, avec Le Vigan. L'arrondissement d'Alès comprend douze cantons.

La commune d'Alès est divisée en trois cantons dont elle est le chef-lieu :

Alès est le siège d'un tribunal de grande instance.




La répartition de la population de la commune par tranches d'âge est, en 2010, la suivante :
La population de la commune est relativement âgée. Le taux de personnes d'un âge supérieur à 60 ans (30,1 %) est en effet supérieur au taux national (22,7 %) et au taux départemental (25,4 %).

À l'instar des répartitions nationale et départementale, la population féminine de la commune est supérieure à la population masculine. Le taux (53,6 %) est supérieur de plus de deux points au taux national (51,6 %).






Unité ayant été stationnée à Alès :


Alès est le siège de la Chambre de commerce et d'industrie d'Alès Cévennes. Elle gère l'aérodrome d'Alès Cévennes et le centre de formation des apprentis.

Trois foires traditionnelles ont lieu chaque année les 17 janvier, 27 avril et 24 août. Ces dates sont reportées au jour suivant si elles correspondent à un dimanche ou à un jour férié.


La commune fait partie de la zone de production de l'olive de Nîmes.

En octobre 2015, l'association L214 diffuse une vidéo montée à partir de plusieurs heures de rushs filmés en caméra cachée dans l'abattoir municipal d'Alès avec un commentaire d'Hélène de Fougerolles. On y voit l'abattage dans une grande souffrance de chevaux, cochons et bovins ainsi que de mauvaises conditions d'hygiène. Les images reprises par de nombreux médias poussent le maire Max Roustan à fermer à titre conservatoire l'abattoir et le parquet à ouvrir une enquête pour cruauté envers les animaux. L'abattoir municipal abattait pour le commerce hallal, qui n'impose pas que la bête soit étourdie avant d'être abattue, 30 à 40 % des animaux.

Alès accueille le siège de l'association Nature et progrès.






Dans son roman "Le Petit Chose", Alphonse Daudet a utilisé son expérience de surveillant pendant deux ans dans une des écoles de la ville d'Alès.









Ce blason est directement hérité de la famille noble du marquis Bérard de Montalet de Saint-Pierre (son château est le château de Potelières, au nord d'Alès), grande famille nobiliaire du Languedoc, qui fut maire d'Alès ("Nobiliaire de Provence", de René Borricand ; "Histoire de la noblesse du Comtat Venaissin", de Pithon-Curt).





</doc>
<doc id="15469" url="https://fr.wikipedia.org/wiki?curid=15469" title="Le Canard enchaîné">
Le Canard enchaîné

Le Canard enchaîné est un hebdomadaire satirique français, paraissant le mercredi. Fondé le par Jeanne Maréchal et Maurice Maréchal, aidés par Henri-Paul Deyvaux-Gassier, c’est l’un des plus anciens titres de la presse française actuelle, notamment le plus ancien titre de presse satirique encore actif. Depuis les années 1960, c'est aussi un journal d'investigation qui révèle nombre d'affaires scandaleuses.

Pour l’historien Laurent Martin, ce journal, très attaché à la protection des sources d'information des journalistes, représente « une forme alternative de presse qui n’a guère d’équivalents en France et dans le monde ».

Son nom fait malicieusement allusion au quotidien "L'Homme libre" édité par Georges Clemenceau, qui critiquait ouvertement le gouvernement de l’époque. Ce journal (en français familier, ce « canard ») doit alors subir la censure de la guerre, et son nom est changé en "L’Homme enchaîné". S’inspirant de ce titre, les deux journalistes Maurice et Jeanne Maréchal aidés par le dessinateur H.-P. Gassier décident d’appeler leur propre journal "Le Canard enchaîné", dont le premier numéro paraît le 10 septembre 1915. 

La première série, faite avec des moyens limités, se termine au cinquième numéro. Le journal renaît cependant le 5 juillet 1916, point de départ de la série actuelle. Le titre du journal a connu une variante : "Le Canard déchaîné", du au .

Les deux canards de la manchette du journal (chacun dans une des oreilles du titre du journal) et les canetons qui s'ébattent dans les pages sont l'œuvre du dessinateur Henri Guilac, un des premiers collaborateurs du journal.

"Le Canard enchaîné" est au format « quotidien », composé de pages de par . Deux feuilles libres forment les huit pages de chaque numéro. L'impression est en bichromie, en noir et rouge écarlate, sur la première et la dernière page ; en monochrome noir sinon. À titre exceptionnel le 18 septembre 2013, la première page du numéro 4847 a été en trichromie (noir, rouge et jaune).

Grâce à des frais de gestion limités et stables, et étant indépendant de revenus publicitaires, ce journal est un des rares en France dont le prix n'a pas augmenté depuis 1991 (et même diminué : il était à 8 francs avant le passage à la monnaie européenne, soit 1,22 €).

En Suisse, le journal est vendu en 2017 au prix de 2,60 francs (suisses). sont écoulés chaque semaine en Suisse romande sans compter les lecteurs romands achetant l'hebdomadaire en France voisine. Ces derniers sont estimés à .

"Le Canard enchaîné" a pour sous-titre "Journal satirique paraissant le mercredi" (parfois modifié, par exemple en "Journal satirique paraissant exceptionnellement le mardi" lorsque la publication est avancée d'un jour si le mercredi est férié), et pour slogan « La liberté de la presse ne s’use que quand on ne s’en sert pas », allusion à l’inusable slogan de la pile Wonder : « La pile Wonder ne s’use que si l’on s’en sert », qui résume assez bien la ligne éditoriale de l’hebdomadaire : dénoncer tous les scandales publics (politiques, économiques, judiciaires, etc.) survenant en France mais aussi dans les autres pays. Sa devise, inventée par H.-P. Gassier en 1915, est : « Tu auras mes plumes, tu n’auras pas ma peau ». "Le Canard enchaîné" n'accepte pas de publicité, cherchant à éviter l'influence des annonceurs sur le contenu de ses informations dans ses colonnes. De plus, il ne cache pas l'état des finances du journal ainsi que leurs provenances, et publie son bilan financier dans le journal chaque année.

La stabilité du cadre rédactionnel du journal est l’une de ses caractéristiques.

L’hebdomadaire adhère à la charte de Munich, qui assure la protection des sources d'information des journalistes.

Les journalistes du "Canard" tirent leurs informations de plusieurs sources :

D’après la rédaction, les informations sont vérifiées et recoupées. Parmi les informateurs, seuls ceux qui sont journalistes sont rémunérés. 

Du fait de ses investigations régulières touchant aux domaines politique et économique, le "Canard" est l'objet de nombreuses attaques en justice. Cependant, fort de ses dossiers solidement montés, vérifiés juridiquement, et de témoins, il perd rarement les procès qui lui sont intentés. 

Antimilitariste, on y voit communément une nette sensibilité de gauche. Certains voient en lui, dès ses origines, une gauche anarchiste, voire une droite anarchisante. Il refusera aussi le titre de journal communiste sans renoncer pour autant ni à son indépendance ni à son esprit critique. Il professe un anticléricalisme de bon aloi. Il applaudit quand la gauche arrive au pouvoir (Cartel des gauches en 1924, Front populaire en 1936, Pierre Mendès France, François Mitterrand en 1981) mais avec méfiance et circonspection. Les partis de gauche se sont toujours méfiés de lui. Maurice Thorez, dans un comité central du PCF, fustige « l’esprit blagueur du "Canard" qui conduit à douter de tout » ; Guy Mollet à la SFIO le poursuit lui aussi de sa vindicte.

Depuis toujours, "Le Canard enchaîné" est considéré comme un journal politiquement indépendant. Ses partisans disent que, même s’il garde une sensibilité de gauche, il n’hésite pas à dénoncer toutes les dérives des politiques quel que soit leur bord politique. Farouchement attaché à son indépendance éditoriale et à son aspect critique, le journal refuse les annonceurs. Il reste l’un des derniers journaux d’investigation en France. Il ne se réfère pas à l’AFP, contrairement à la majorité des quotidiens. "Le Canard" est connu pour renifler les scoops et n'hésite pas, d'après ses partisans, à publier les scandales quelles que soient leur nature et l'orientation politique des personnes impliquées. Ses partisans disent qu'à ce titre, il est craint, lu et informé par l’ensemble de l’échiquier politique, et n’éprouve pas plus de compassion envers une défaite d’un parti de gauche ou de droite, qui plus est si c’est un extrême. André Escaro, dessinateur du "Canard enchaîné", a déclaré à cet égard : « la tendance actuelle du "Canard", c’est l’objectivité. Ni gauche, ni droite ».

Sans recette publicitaire ni subvention publique ou privée, "Le Canard" ne vit que de ses ventes et affiche pourtant une belle santé financière : en 2016, il a réalisé 24 millions de chiffre d'affaires et deux millions d’euros de bénéfices après impôt. Il refuse d’accueillir dans ses huit pages la moindre publicité, ce qui en fait un cas rare dans la presse hebdomadaire française. En refusant la « manne publicitaire », il est « le seul journal qui renseigne le public sur l’influence nocive de la publicité dans les médias », selon le Groupe Marcuse (Mouvement Autonome de Réflexion Critique à l’Usage des Survivants de l'Économie). Ses statuts (SA Les Éditions Maréchal) le préservent de toute intervention extérieure (cela depuis une tentative de prise en main par le groupe Hachette, en 1953), puisque seuls sont actionnaires ceux qui y travaillent, ainsi que les fondateurs (les titres du journal sont incessibles et sans valeur).

Depuis 1974, "Le Canard enchaîné" est propriétaire de ses murs au 173 rue Saint-Honoré.

Sa « bonne santé financière » lui a permis de passer à la photocomposition en 1982, puis en publication assistée par ordinateur en 1996. Chaque année les bénéfices sont mis « en réserve » pour assurer l’indépendance financière. Ces réserves, trois fois plus importantes que le chiffre d’affaires annuel, sont placées sur un compte non rémunéré ; la réserve totale est estimée en 2016 à une centaine de millions d'euros. Les 65 salariés du journal (chiffre en 2014) sont parmi les mieux payés de toute la presse française. En contrepartie, les rédacteurs ne peuvent ni jouer en bourse, ni faire des piges ailleurs, ni accepter de cadeau ou d'honneur, notamment les décorations officielles. 

"Le Canard enchaîné" emploie une trentaine de journalistes régulièrement. L'écart des salaires est d'un rapport de 1 à 4. L'un d'eux estime qu'il gagne 4 500 € net par mois, primes comprises.

L’hebdomadaire est imprimé le mardi en début d’après-midi.

Il est souvent sévère, parfois cruel, y compris avec ses amis. Il n’est cependant pas vindicatif. Ainsi, le capitaine Nusillard, chef de la censure de 1916 à 1918, est devenu par la suite un fidèle abonné du journal, jusqu’à sa mort à 95 ans, en 1955.

De même, le général de Gaulle une fois devenu président de la République avait pour habitude de demander ce que le « volatile » disait de lui.

Jean Egen, dans "Messieurs du Canard", puis Vincent Nouzille, dans un article du "Nouvel Économiste" en 1993, distingueront « deux clans de journalistes historiquement opposés, les dionysiaques ou buveurs de vin (tradition du juliénas), rois de la satire, et les apolliniens ou buveurs d’eau, preux chevaliers de l’information ». Yvan Audouard dira les choses plus simplement pour employer le vocabulaire de la profession en séparant « chroniqueurs » et journalistes d’information.


Anciens directeurs :

Ancien rédacteur en chef :

Entré au Canard enchaîné en 1971, Claude Angeli devient successivement chef des informations, rédacteur en chef adjoint et enfin, rédacteur en chef (en 1991).
Il laisse sa place à Louis-Marie Horeau en mars 2012, mais continue de participer à la rédaction du journal.

Il arrive que le "Canard" publie anonymement un article rédigé par un ou plusieurs journalistes ou une personne extérieure au journal. L'article paraît alors sous le nom de Jérôme Canard. S'il s'agit d'articles à sujet scientifique ou environnemental, ils sont attribués au professeur Canardeau. 

Anciens rédacteurs :

Les dessinateurs du "Canard" :

Anciens dessinateurs :

Les comptes financiers du "Canard" sont publiés chaque année à partir du dernier mercredi du mois d'août dans l'hebdomadaire, avec le détail de la diffusion du journal.

Le "Canard enchaîné" a été vendu à exemplaire lors de la Libération en 1944, mais tombe à en 1953. 

Après avoir augmenté fortement en 2007 et 2008, les ventes ont baissé (de 5,7 % en 2012, de 16 % en 2013, de 2,5 % en 2014), l'hebdomadaire résistant un peu mieux que le reste de la presse française malgré son absence assumée d'internet (son petit site qui met uniquement en ligne ses unes, permet de réserver le nom de domaine, plusieurs fois usurpé, et un compte Twitter poste les gros titres le mardi, veille de parution). Les recettes ont ainsi baissé à 24,4 millions d'euros en 2014, mais les bénéfices du journal ont augmenté de 20 %, à 2,4 millions. Pour l'année 2016, le journal se vend en moyenne à exemplaires ( par abonnement), ce qui constitue une baisse de 8,6 %.

Diffusion payée annuelle totale (France et étranger) du "Canard enchaîné" :

Le journal a plusieurs fois révélé des affaires politiques et/ou financières. Elles lui permettent de faire des ventes exceptionnelles, jusqu'à d'exemplaires pour l'affaire Maurice Papon en 1981.

À la suite de l'attentat du 7 janvier 2015 contre le journal "Charlie Hebdo", la rédaction du "Canard enchaîné" indique dans son édition du 14 janvier avoir reçu des menaces le lendemain de l'attaque. À cette occasion, le journal rend hommage à Cabu, dessinateur aux deux journaux.

Le ton employé, humoristique, est celui de la satire et de l’ironie, d’où les nombreuses antiphrases dans les pages du journal ("Le Canard enchaîné" reprend les termes et les arguments de son adversaire, semble le défendre, mais c'est pour mieux en montrer les limites ou l'absurdité de la position). Les jeux de mots sont réservés aux titres des articles. Le "Canard" cherche à être de connivence avec le lecteur « moyen », ce qui explique, malgré un style assez soutenu, l’emploi de formules issues de la langue du peuple et l’usage de surnoms moqueurs envers des personnalités qu’il critique. C’est ainsi qu’au cours de son existence, on lui doit non seulement des diminutifs de politiciens (« Chichi », « L'Ex »), mais aussi certaines expressions entrées dans le langage populaire, comme « minute Papillon », les « étranges lucarnes » ou enfin « "Bla bla bla" » ; onomatopée lancée par le Canard sous la plume de Pierre Bénard le 27 février 1946 (Mon ami Paul Gordeaux, lorsqu'on lui présente un reportage où il y a plus de mauvaise littérature que d'informations, dit en repoussant le papier : « Tout ça, c'est du bla bla bla ! »)

Le "Canard enchaîné" titre - logiquement - sur un fait d’actualité (national ou international) et ses manchettes comportent toujours un jeu de mot. Exemples :

En , Karl Laske avec le journaliste Laurent Valdiguié publient un essai contre "Le Canard enchaîné" intitulé "Le vrai Canard", qui entend dénoncer le travail, les liens avec des personnalités politiques et l’opacité des finances de cet hebdomadaire. Pascale Santi du quotidien "Le Monde" parle de « livre à charge ». Pour "L'Express", il s'agit d'un travail « copieux et minutieux ».

En 2013, Jean-Yves Viollier, longtemps collaborateur du journal, publie "Un délicieux canard laquais", « roman satirique » qui, de manière à peine voilée, dénonce le manque d'indépendance du "Canard enchaîné" vis-à-vis des partis politiques au pouvoir. Il lui reproche également des pratiques salariales et des pratiques sociales peu exemplaires en dépit de bénéfices importants et « un décalage entre les idées professées et les pratiques à l’intérieur du journal [...] vertigineux ».

Tentatives de diversification : elles ont été rares et ont presque toujours concerné l’édition de presse.

Dans la Presse :


Internet : 





Certains journaux et sites d'Internet actuels ou passés plagient en reprenant le nom du journal sous forme de variante mais sans toujours respecter les caractéristiques du journal et les droits d'auteurs.





</doc>
<doc id="15472" url="https://fr.wikipedia.org/wiki?curid=15472" title="Média">
Média

Le terme média désigne tout moyen de diffusion : 
permettant la communication, soit de façon unilatérale (transmission d'un message), soit de façon multi-latérale par un échange d'informations.

Au sein de cet ensemble, l'expression médias de masse (de l'anglais ) caractérise un sous-ensemble important : les médias qui ont acquis une diffusion à grande échelle pour répondre rapidement à une demande d'information d'un public vaste, complétée dans de nombreux cas par une demande de distraction. La plupart des entreprises dites de média emploient des journalistes et des animateurs de divertissement. Ils recueillent dans un premier temps des informations auprès de sources d'information, en leur assurant la protection des sources d'information, ce qui leur permet d'acquérir une audience, et valorisent, dans un second temps, leur audience par la vente d'espaces publicitaires. À côté de ce modèle dominant, les chaînes de téléachat et les périodiques ne diffusant que des petites annonces et publicités sont aussi considérés comme des médias.

Dans les pays industrialisés, où les médias se sont largement développés, ils sont majoritairement détenus par de grands groupes industriels dont les dirigeants, proches du pouvoir politique, sont régulièrement critiqués pour instrumentaliser l'information à des fins partisanes plus ou moins reconnues (thèse de la « fabrication du consentement »). Mais l'avènement d'internet, des TIC signe celui des médias alternatifs (blogs, réseaux sociaux...). L'information n'est plus alors forcément soumise aux règles déontologiques, notamment celle de la vérification par les faits, la multiplication et l'ampleur des hoax inaugurant selon certains une nouvelle « ère » : l'ère post-vérité.

En latin, ' est le pluriel de ' (milieu, intermédiaire). Le mot français est issu de l’anglais "", mot anglais lui-même formé sur l'usage italien "media", venant aussi de la langue latine. La notion d'intermédiaire a aussi une origine grecque, médiation développée par de nombreux philosophes notamment Socrate puis Bergson et nouvellement Francis Balle.

L'écriture du terme "media" prête à discussion. Faut-il rajouter un "s" comme marque du pluriel sur un substantif déjà au pluriel ? 

Le terme ' est maintenant rarement employé selon son orthographe latine, « Médias » désigne plusieurs supports et « Média » un support unique. Ces termes consacrés par l'usage commencent à se trouver dans la plupart des dictionnaires francophones. Le Grand dictionnaire terminologique et FranceTerme recommandent eux aussi « média » pour l’anglais '.

Les médias sont des outils de communication. Le choix d'un média dépend évidemment du type de communication recherché :

Selon ses caractéristiques techniques propres, l'usage d'un média de masse est davantage approprié à un certain type de communication : par exemple, le "média de type Presse Écrite" ("Le Monde", "Le Figaro", etc.) semble plus adapté pour communiquer de manière unilatérale, les "médias de type Réseaux sociaux" (Facebook, Twitter, Snapchat, Instagram, etc.) semblent plus pertinents pour communiquer de façon multilatérale.

Selon le critère de « "mise à disposition du public" » employé par les juristes français, on distingue :


L’apparition d’internet dans les années 1990 a démultiplié les sources d’information de presse en ligne.La presse écrite a en effet souhaité s’inscrire dans cette nouvelle modernité en créant des versions en ligne de ses journaux mais les médias en ligne ne sont pas les seules sources présentant l’actualité sur le web, on compte également les infomédiaires, les blogs et les sites natifs de l’internet. 

Ces différentes sources présentent des disparités dans les modes de traitement de l’actualité et dans leurs énonciations éditoriales qui sont marquées notamment dans les articles traitant de l’actualité politique, thème plus ou moins enclin d’être sujet à controverse. On constate une hiérarchie dans le traitement de l’actualité sur le web étant donné que tous les sites d’information n’ont pas les mêmes façons de montrer leur point de vue sur les questions traitées. Chaque site d’actualité en ligne se construit une identité propre qui découle des plus ou moins grandes restrictions qui sont faites aux auteurs et qui se traduit par différents procédés :
Les stratégies énonciatives et discursives mises en place par les auteurs des articles sont les suivantes (non exhaustif):


Les médias sont souvent qualifiés de "quatrième pouvoir", par allusion aux trois pouvoirs constitutionnels, dans le processus de la formation de l'opinion publique et dans l'influence que la révélation de ces faits peut avoir dans les prises de position des citoyens. Les faits, analyses ou commentaires qu'ils rapportent sont porteurs de sens, par exemple dans le domaine de la politique, de l'économie ou de la culture. Le choix des faits rapportés appartient aux responsables nommés par les propriétaires de ces médias d'où la revendication par les syndicats de journalistes pour obtenir l'indépendance des rédactions. Le SNJ, le SNJ-CGT, FO, la CFTC, et l'USJ CFDT ont rédigé à l'automne 2007 la pétition nationale pour l'indépendance des rédactions, dans le sillage du combat mené par les journalistes des quotidiens économiques "Les Échos" et "La Tribune", en 2007. Ils demandent que la ligne éditoriale respecte la Charte de Munich, adoptée par la Fédération européenne des journalistes et référence européenne concernant la déontologie du journalisme, un texte qui distingue dix devoirs et cinq droits, en reprenant les principes de la Charte des devoirs professionnels des journalistes français.

En France, en cas de désaccord avec la ligne éditoriale, le journaliste peut en théorie demander l'application de la clause de conscience, supervisée par la commission arbitrale, l'une des cinq grandes commissions qui cogèrent la profession, en vertu du paritarisme. En pratique, la clause de conscience est très difficile à obtenir, la loi n'étant pas assez précise.

L'influence des médias - à condition de choisir les messages et les supports pertinents - est généralement conçue et adressée vers celui qui achète (le consommateur-acheteur). Comme l’indique le sociologue D. W. Smythe, l’audience est ce que produisent les mass-media. Cependant, d'autres cibles indirectes sont régulièrement visées :

L'annonceur désigne l'émetteur d'information qui passe commande à un support pour réaliser et/ou diffuser un message en direction d'une cible. 
Pour cet annonceur, la politique de communication est l'un des 4 piliers fondamentaux de son marketing mix. 

Les informations peuvent être élaborées :

Compte tenu de leur efficacité, mais aussi de leur coût, les données médias et leur analyse sont au cœur des choix d’investissement en communication (environnement produit, positionnement, stratégie des concurrents, choix des supports, risques pour le client, impact sur les consommateurs, etc.). Les études médias, réalisées à partir de mesures d'impact et d'audience (audimat). 

L'étude des médias ne néglige pas l'analyse qualitative :

Le plan média d'un annonceur ("media planning", en anglais) désigne le choix des supports, ainsi que le calendrier de mise en œuvre des médias.

Promoteurs et porteurs de la culture de masse, les médias, écrits d'abord puis audiovisuels (radios, télévisions), ont été et restent encore des acteurs incontournables dans la diffusion de la culture et dans la structuration des marchés culturels, en particulier des produits culturels. Pour ces derniers, aucune offre de quelque importance ne peut exister sans plan-médias et sans médiatisation réussie. Le « diktat » des médias peut être décisif dans certains cas et nécessite une intervention régulatrice des pouvoirs publics (par exemple les quotas de production de phonogrammes de langue française au Québec, ou d'œuvres audiovisuelles d'origine européenne sur les télévisions françaises).

La plupart des grands groupes opérant dans les industries culturelles sont également leaders dans le secteur des médias écrits, audiovisuels et d'Internet : AOL Time Warner, Lagardère, Bertelsmann, Sony, etc. (quand ces médias sont utilisés conjointement, on parle alors de "médias multiplateformes").

Ces conglomérats financiers que l'on peut qualifier de « médiatico-culturels », ayant grandi par croissance externe ou fusion, sont présents sur les principaux marchés des produits culturels éditoriaux (livres, phonogrammes, vidéogrammes, presse écrite, jeux vidéo…) et des offres médiatiques. Leur stratégie dans le domaine des médias doit en revanche tenir compte de deux contraintes majeures : les réglementations publiques, qui dans de nombreux pays contrôlent leur concentration (respect de l'information…) et la barrière linguistique, frein « naturel » au développement de certains marchés comme la presse, le livre et tous les contenus linguistiques. Néanmoins, cet obstacle est de moins en moins fort, en raison de la prédominance de l'anglais. Les groupes médiatico-culturels (le plus souvent classés dans le secteur de la communication) sont ainsi les acteurs majeurs de la concentration financière et de la concentration de l'offre, allant à l'encontre de la diversité culturelle et de la diversité linguistique.

Si les médias ont été des acteurs clés de la constitution des « majors » dans les différents secteurs qui se sont structurés autour d'oligopoles à frange (cinéma, musique enregistrée…), ils sont aujourd'hui eux-mêmes menacés par le développement d'Internet et de nouveaux acteurs liés quant à eux aux offres et aux pratiques sur le Web (Google, Yahoo, Facebook, Twitter, MyMajorCompany…). Ainsi, dans le secteur de la musique enregistrée, les deux piliers de la concentration, d'une part le couple star/major et, d'autre part, les réseaux professionnels coopératifs associant publishing, scène, médias écrits et audiovisuels, sont considérablement mis à mal par le développement d'Internet. L'évolution rapide des usages sociaux qui en a résulté (ce que Bernard Stiegler appelle la consom'action) va à l'encontre de l'exposition traditionnelle des produits et du modèle économique de la marchandisation à grande échelle sur lequel reposait jusqu'à présent le système médiatico-culturel.

Dans de nombreux pays, le secteur des médias relève également du champ culturel, en particulier pour l'intervention publique ; par exemple en France avec un ministère de la Culture et de la communication ou au Royaume-Uni avec le "Department for Culture, Media and Sport" (DCMS) créé par le gouvernement de Blair en 1996.

Les nouveaux médias permettent l'hyperchoix (décrit par Alvin Toffler dans "Le Choc du futur") et sont hyper-spécialisés, au détriment de ceux qui sont généralistes. Ainsi, on a eu une baisse de 15 % des ventes de journaux généralistes en 15 ans, et une augmentation de 15 % de la vente de magazines. (2)
Les utilisateurs de média choisissent désormais ce qu'ils regardent et quand est-ce qu'ils le regardent.
On peut s'inquiéter de cet effet « œillère » qui limite de plus en plus l'ouverture d'esprit du public ou se réjouir de cette opulence de diversité.

La théorie de l'hyperchoix reste critiquable, notamment avec le concept de « circularité de l'information » de Pierre Bourdieu qu'il décrit dans son livre "Sur la télévision". Ainsi, il indique que les médias traitent, dans un grand nombre, des mêmes sujets, aux mêmes moments, et ceux-ci influencés le plus souvent par les médias dominants ("Le Monde" aura plus d'impact que le "Midi libre"). On n'est bien sûr pas surpris de savoir que les médias ont toujours eu le pouvoir de persuader l'opinion publique depuis ces médias dominants. On voit aussi que certaines médias en particulier tendraient à distraire le public de certains problèmes, crises et changements gouvernementaux. 

Les médias de masse sont notamment influencés, voire profondément renouvelés, par l’époque de numérisation croissante présente. 
Déjà en 1984 le théoricien Alan Kay définissait ainsi l’ordinateur comme le « premier méta-medium », en ce qu’il « est un medium qui peut simuler dynamiquement les détails de toute autre medium » et, en tant que tel, « il a des degrés de liberté de représentation et d’expression jamais encore atteints »: effectivement l’ordinateur aujourd’hui, par exemple, résume dans soi-même plusieurs fonctions de médiation qu’auparavant appartenaient à différents media spécifiques : il est télévision, agenda, courrier, machine à écrire, etc. etc. etc.
Cette capacité des media numériques à remédier par une programmation digitale toutes les médiations antérieures, en le reconfigurant, a été également souligné par le philosophe Vilém Flusser, qui désigne celle du numérique comme une phase de superposition de toutes les précédentes que l’histoire de la culture humaine a vu passer. 

Une fois posée l’hypothèse d’une numérisation des média quasiment ubiquitaire à l’époque contemporaine nous pouvons énoncer quelqu’une des principales caractéristiques de cette situation. 

En premier lieu, et comme les "Software Studies" le remarquent, il y a une croissante densité et obscurité de nos machines, qui se font toujours plus accessibles et simples au niveau de leurs interfaces graphiques, et pourtant toujours plus insondables dans leur fonctionnement profond, jusqu’au paradoxe des "algorithmes auto-apprenants" dont l’intelligence supère celle de leurs ingénieurs ou, dans les termes de Bernard Stiegler, d’une hyper-industrialisation qui entraine une progressive exclusion de la force de travail intellectuel humaine. 
Certains auteurs ont entrainé à cet égard la notion de gouvernementalité algorithmique. 

Les méta-média du numérique opèrent aussi ce que Yves Citton propose de nommer une « premédiation » : dans leur complexité vouée à l’autorégulation, les médias numériques s’évadent d’une certaine façon de l’intelligence humaine et ils tendent à pre-médier, voire à anticiper ou bien à fournir des catégories préétablies de ce qu’ils nous proposent. Cela est évident dans le cas du ciblage commerciale effectué par les algorithmes sur la base des données personnelles, mais tout de même dans le cas de la contestée fiabilité de l’information, qui est souvent politiquement et économiquement conditionnée ou le résultat d’un calcul algorithmique, comme dans le cas des tableaux de bord de Facebook. 
Plus en général la question de la pré-médiation entraine notamment des dangers au niveau socio-politique, et particulièrement pour ce qui regarde les effets de lock-in – le phénomène pour lequel plus une plateforme compte des participants, plus les données qu’elle génère sont nombreuses et ses algorithmes sont puissants plus, du coup, elle offre des services efficaces, écrasant la concurrence en une tendance monopolistique - ou bien la ci-dite "vectorialisation", à savoir la monopolisation de l’information opérée par une classe dominante à travers le contrôle des vecteurs par lesquels l’information est abstraite que McKenzie Wark revendique dans son « Hacker Manifesto ». Cela pourrait nous emmener à l’horizon d’une croissante asymétrie du rapport au medium entre l’individu et le programme (et celui qui gère le programme), jusqu’au perspectives catastrophiques d’une société numérique basée sur la surveillance et sur la manipulation perpétuelle où il ne reste pas beaucoup d’espace à l’intelligence et à l’individualité humaines. 

Une autre et essentielle caractéristique des méta-media numériques est l’inter connectivité : désormais tous les outils – et non pas seulement les Smartphones et les ordinateurs, depuis l’avènement de l’internet des objets, sont connectés, s’envoyant constamment des données entre eux qui enregistrent nos préférences, nos activités, nos déplacements, nos compagnies, etc etc, dans un grand réseau virtuel mondial que certains comparent à un « cerveau collectif mondial ». 

Dans le danger d’une croissante standardisation et uniformisation des pratiques et des produits médiatiques, ou encore d’une colonisation commerciale du milieu numérique où le monopole des big data appartiendrait à un nombre très restreint de colosses capitalistes, plusieurs auteurs soulignent l’importance de développer une conscience majeure des enjeux juridico-politiques que l’ère du numérique entraine conjointement à un effort de réglementation, et affirment l’indispensabilité de préserver l’hétérogénéité au sein de l’espace numérique partagé. Dans ce contexte les actions du hacktivisme s’inscrivent dans une perspective de lutte et de contestation politique, et d’une particulière éthique de revendication des droits personnels que le numérique met en danger.



</doc>
<doc id="15474" url="https://fr.wikipedia.org/wiki?curid=15474" title="Histoire des États-Unis de 1776 à 1865">
Histoire des États-Unis de 1776 à 1865

La période de la fin du au milieu du est fondamentale pour comprendre le pays : la guerre d'indépendance des États-Unis, l'industrialisation et la guerre de Sécession ont marqué et préparé l'ascension de la puissance américaine.

Les États-Unis d'Amérique sont fondés en 1776 à partir des colonies britanniques sur la côte Atlantique de l'Amérique du Nord. Dès 1775, la frustration provoquée par diverses pratiques de la Couronne britannique en matière d'impôts, conduit à la révolte des colons du Massachusetts.

L'année suivante, en juin, la Virginie est le premier territoire qui déclare l'indépendance, sous l'impulsion de Thomas Jefferson. Celui-ci participe en juillet au Congrès continental qui se réunit à Philadelphie, et prépare la Déclaration d'indépendance des États-Unis d'Amérique, document fondateur des États-Unis.

En 1777, les représentants des colonies rédigent les Articles de la Confédération qui comptent parmi les textes fondateurs du pays. La victoire américaine de Saratoga incite la France de Louis XVI à entrer en guerre aux côtés des "insurgents".

Avec l'aide de leurs alliés européens et après la bataille de Yorktown menée par George Washington (1781), les Américains sortent finalement vainqueurs de la guerre d'indépendance contre la Grande-Bretagne. La paix et la reconnaissance du nouveau pays sont scellées par le traité de Paris en 1783. Des discussions s'engagent alors pour établir la nature et l'organisation politique de la nouvelle nation. Le problème de l'extension des États-Unis vers l'ouest, au-delà des Appalaches, commence à se poser avec acuité.

On ne peut établir le nombre de victimes de la guerre d'indépendance avec certitude. Dans le contexte de la fin du , il est cependant certain que les épidémies (variole…) firent plus de ravages que les opérations militaires elles-mêmes. L'historien John Whiteclay Chambers a donné les chiffres de américains morts et à la suite des batailles ("The Oxford Companion to American Military History", Oxford University Press, 1999). La fin de la guerre eut d'autre conséquences humaines : 
les colons loyalistes, restés fidèles au roi de Grande-Bretagne, durent s'exiler au Canada, où la province du Nouveau-Brunswick fut fondée pour les accueillir. Enfin, sur le plan économique, le tout nouveau gouvernement dut faire face à l'inflation ainsi qu'au remboursement des dettes causées par la guerre.

Jusqu'en 1789, les États-Unis sont gouvernés par les Articles de la Confédération. Ce régime est très souple, car chaque État jouit d'un très grand pouvoir dans de nombreux domaines, notamment en matière de politique fiscale et commerciale, la seule institution fédérale du pays étant le Congrès. Les treize États fédérés sont différents et certains contestent leurs frontières. Les difficultés rencontrées sont surpassées par l'adoption de la Constitution. Celle-ci a été adoptée par les différents États fédérés entre 1787 et 1790. C'est l'une des plus anciennes de l'Histoire après la constitution corse de 1755. Elle applique les idées des philosophes des Lumières :

George Washington, qui commanda les troupes des insurgés pendant la guerre d'indépendance, est le premier président élu (1789-1797). Le Congrès, d'abord réuni au Federal Hall New York, adopte les premières lois définissant le mode de gouvernement. En 1791, les dix premiers amendements sont inscrits dans la Constitution. Malgré le désir de Washington de demeurer isolationniste, qui transparaît dans son discours d'adieu, les États-Unis ont une histoire diplomatique riche.

Bien que la constitution ne reconnaisse pas l'existence de partis politiques, les désaccords sur le texte font émerger deux « factions » : 

La constitution américaine donne naissance à une fédération de treize États : chacun de ses États garde des prérogatives particulières en matière d'éducation et de justice. Chaque État possède ses assemblées, ses cours de justice et son gouvernement dirigé par un gouverneur. Le gouvernement central ou fédéral exerce sa souveraineté sur l'armée, la monnaie commune et les relations extérieures. Cette organisation fédérale est toujours en place aujourd'hui.

Les Républicains occupèrent la présidence de 1801 à 1825. En 1808, la traite des esclaves est officiellement abolie sur le sol américain. Le pays s'engage dans la conquête de l'Ouest par la colonisation, l'achat ou la guerre. En 1803, Napoléon vend d'immenses territoires appelés Louisiane française aux États-Unis : cet achat permet le doublement de la superficie des États-Unis. L'année suivante, le président Thomas Jefferson envoie l'expédition Lewis et Clark reconnaître ces nouveaux espaces en remontant le Missouri.

En 1812, éclate une guerre contre le Royaume-Uni qui dure jusqu'en 1815. Appelé aussi la seconde guerre d'indépendance, elle est causée par la volonté anglaise d'interdire le commerce entre les États-Unis et la France et le blocus britannique le long des côtes américaines. Madison veut faire respecter les droits de neutres.
En 1814, les forces britanniques et canadiennes reçoivent l'ordre de brûler les édifices publics de Washington DC. La ville comptait alors environ. Les Britanniques souhaitaient se venger de la destruction de la capitale du Haut-Canada (aujourd'hui Toronto) par les Américains après la bataille de York (1813). La destruction de la capitale des jeunes États-Unis devait démoraliser l'ennemi. Les Américains dirigés par le général Andrew Jackson, battent un corps expéditionnaire anglais à La Nouvelle-Orléans le 8 janvier 1815. Le traité de Gand signé quelques mois plus tôt permettait un "statu quo ante bellum".

En 1820, l'entrée d'un nouvel État, le Missouri, provoque une crise dans la fédération. Pour la première fois, les États esclavagistes risquent de devenir majoritaires. Après plusieurs mois de négociations entre les États, un compromis est trouvé. Il fixe une ligne territoriale qui sépare la fédération entre Nord et Sud. Au nord, l'esclavage est interdit, au sud, il est autorisé. Pour prévenir toute discorde future, les entrées de nouveaux États devront se faire par paire, l'entrée d'un État esclavagiste devant être accompagnée de celle d'un État libre .

James Monroe occupe la présidence de 1816 à 1825. En 1819, l'Espagne cède la Floride aux États-Unis.
En 1823, au cours de son deuxième mandat, il présente une nouvelle conception de politique internationale. Les États-Unis s'interdisent de se mêler des affaires européennes mais, en retour, demandent aux puissances européennes de s'abstenir de toute intervention dans les affaires du continent américain. De plus, ils considéreraient comme inamicale à leur égard, toute action européenne contre un gouvernement américain ayant proclamé son indépendance. Cette déclaration porte en elle le panaméricanisme et la légitimation de l'hégémonie américaine.

C’est sous la présidence d’Andrew Jackson que le système des partis politiques américains tel qu’il existe encore voit vraiment le jour. Ses mandats sont marqués par le clientélisme et le populisme. C’est lui aussi qui proposa l’Indian Removal Act le , ordonnant la déportation des Amérindiens vivant dans les territoires compris entre les treize États fondateurs et le Mississippi, vers un territoire situé au-delà de ce fleuve. Elle concernait d'Amérique.
La présidence Jackson est également marquée par une crise institutionnelle grave entre le Gouvernement fédéral et un État, la Caroline du sud. cette crise connue sous le nom de crise de l'annulation ("nullification" en américain) est l'occasion de réaffirmer la forme fédérale du système américain et de redéfinir la place des États.

Le , le traité de Córdoba permet au Mexique de proclamer l'indépendance à l'égard de l'Espagne. En 1835, les Mexicains prennent Alamo. À la suite d'une révolution, le Texas proclame son indépendance le , par la Bataille de San Jacinto, acquise sous la conduite de Sam Houston qui profita des troubles rencontrés par le régime militaire d'Antonio López de Santa Anna. S'engagea alors un conflit avec les États-Unis après le raid de Zachary Taylor. Le Mexique sortit vaincu et dut signer le traité de Guadeloupe Hidalgo (2 février 1848) qui entérina la perte de la moitié de son territoire (notamment la Californie et le Texas).


Les capitaux nécessaires au décollage industriel des États-Unis proviennent essentiellement du dynamisme commercial du pays. Les ressources naturelles en charbon (Pennsylvanie), en fer et en cuivre (autour du Lac Supérieur), en bois, le potentiel hydraulique, permettent également le développement industriel du Nord-Est (la "Manufacturing Belt"). Pittsburgh en Pennsylvanie acquiert rapidement le surnom de "Ville de l'acier". Les ateliers puis les usines se développent à partir des années 1810, avec la Révolution industrielle. C'est l'industrie textile qui entraîne une bonne partie des autres secteurs de production. La croissance démographique est un moteur de la croissance économique : la population américaine est multipliée par quatre entre le début du et 1860. L'industrie américaine ne manque pas de main d'œuvre : entre 1840 et 1860, le pays attire des centaines de milliers d'immigrants. Les Irlandais fuient la grande famine et de nombreux Allemands quittent leur pays à la suite notamment de l'échec des révolutions de 1848-1849. Durant la décennie 1851-1860, la part des Allemands dans le flux des immigrants est de 40%, dont 220 000 pour la seule année 1854. Au moment du déclenchement de la guerre civile, trois millions d'Américains sont d'origine allemande et ils s'engagent en très grande majorité dans l'armée de l'Union pendant la guerre de Sécession. Ils fournissent un apport décisif à la victoire finale du Nord.

L'optimisme du peuple américain constitue une composante importante pour expliquer l'ascension fulgurante du pays. L'esprit pionnier est porté par le droit au bonheur, exprimé dans la déclaration d'indépendance de 1776.

La construction des premières voies ferrées stimule la demande en acier et prépare la conquête de l'Ouest. Ainsi, le chemin de fer de Baltimore et de l'Ohio sont en service dès 1830. En 1855, le pays compte de lignes

Le canal Érié (1817-1824) permet de relier l'Hudson au lac Érié, établissant une voie fluviale entre l'océan Atlantique et les Grands Lacs. Le canal fait la prospérité de New York et de Buffalo. Les Grands Lacs offrent une voie d'eau qui relie l'intérieur du continent à l'océan Atlantique par le fleuve Saint-Laurent : la ville de Détroit (Michigan) se développe rapidement. L'ouverture du canal Illinois-Michigan en 1848 permit aux bateaux circulant sur les Grands Lacs de rejoindre le Mississippi en passant par Chicago : la ville connut dès lors une forte croissance démographique (entre 1840 et 1860, sa population est multipliée par 20) et économique et devint le débouché des Grandes Plaines céréalières. La voie fluviale du Mississippi voit passer des bateaux à vapeur et la ville de Saint-Louis profite de sa position de confluence. La Nouvelle-Orléans (Louisiane) tire avantage de sa situation au débouché du grand fleuve : vers 1840, elle atteint , ce qui en fait la quatrième ville des États-Unis. Cependant, d'une manière générale, le pays reste majoritairement rural (15 % de citadins en 1850).

Dès 1864, les premiers navires à vapeur transatlantiques relient l'Amérique du Nord à l'Europe de l'Ouest.
L'Américain Samuel Morse invente un télégraphe pratique et efficace, qui permet, dans les années 1860 d'envoyer des messages de l'autre côté de l'Atlantique. Il est aussi à l'origine du code morse.

Cette époque est marquée par d'intenses changements sociaux. Des grèves et des émeutes éclatent dans les villes, comme à Baltimore (Maryland) en 1835 ou à New York en 1849. Des polices urbaines sont créées pour ramener l'ordre. La contestation ouvrière est particulièrement intense au moment de la crise de 1837. En 1842, la loi martiale est proclamée à Providence. En 1860, une grève générale s'étend à toute la Nouvelle-Angleterre.
L'immigration irlandaise et allemande, particulièrement importante dans les années 1840-1850, provoque un afflux de catholiques. Les protestants se sentent menacés et manifestent leur hostilité dans la presse et dans la rue. Ils font pression pour interdire la vente d'alcool. Si la période "ante-bellum" est marquée par une brève vague nativiste, celle des "Know-Nothings" qui culmine en 1854 et décline rapidement, un autre mouvement aura une influence plus durable : il s'agit du Ku Klux Klan, fondé en 1864 dans le Tennessee.
Dans les années 1820, les premières organisations féministes et autres mouvements dit des "suffragettes" ont vu le jour aux États-Unis : La "Female Anti-slavery Society" dénonçait l'esclavage ; l"'American Female Moral Reform Society" voulait lutter contre la prostitution et l'alcoolisme. Une cinquantaine d'années plus tard, les féministes américaines revendiquèrent l'égalité des droits civiques dans le pays. En 1869, l'État du Wyoming autorise le suffrage féminin.
Dans le domaine religieux, les mouvements chrétiens hétérodoxes se multiplient aux États-Unis : unitarisme, transcendantalisme, spiritualisme, mormons (qui s'installent en Utah à partir de 1847), … Les communautés égalitaires et utopiques se développent également : colonies Amana en Iowa, Shakers à Pleasant Hill.

La culture américaine se distingue de plus en plus de la culture européenne ; les écrivains sont de mieux en mieux connus en Europe et traitent de sujets véritablement américains : Washington Irving (1783-1859) écrit une biographie de George Washington. Herman Melville (1819-1891) publie Moby Dick en 1851. James Fenimore Cooper (1789-1850) connut le succès grâce à ses romans sur les Amérindiens ("le dernier des Mohicans", "la Prairie" et "le Tueur de daim"). 
En peinture, l'originalité américaine se manifeste dans les représentations de paysages (Thomas Cole). L'architecture reste très influencée par l'Europe, avec quelques adaptations à l'environnement américain. Il faut attendre la naissance des gratte-ciel, à la fin du pour voir une architecture vraiment américaine.

La révolution des transports a préparé la conquête de l'ouest. Les colons américains empruntent les pistes de l'Oregon ("Oregon Trail") ou de Californie, dans des charriots bâchés, immortalisés par la littérature et plus tard par le cinéma (westerns). La pénétration des Américains suit la piste de Santa Fe, qui dès le début du est parcourue par des liaisons régulières sur . Dans les années 1830, le développement du commerce conduit les Américains à changer de route : ils préfèrent emprunter le raccourci de la Cimarron plutôt que de se risquer dans le passage montagneux de Raton Pass. À Santa Fe, les Américains vendent des armes et de la pacotille ; ils remportent avec eux des peaux de bisons achetées aux "commancheros" et des blocs d'argent de l'Arizona. En 1858, les lignes de diligences assurent des liaisons régulières entre San Francisco et Saint-Louis. Les pistes sont progressivement désertées avec le développement des liaisons ferroviaires, surtout après l'achèvement du premier chemin de fer transcontinental le 10 mai 1869. Les cow-boys mènent les milliers de bœufs vers les gares d'où ils seront acheminés vers les abattoirs de Chicago. En 1875, le Kansas est relié à Santa Fe par le train ; en 1885, cette dernière est connectée avec la Californie. Avec la révolution de l'automobile au , l'Ouest attire de plus en plus les touristes.

La maîtrise du territoire américain passe aussi par la mise en place du Pony Express, le premier service postal qui allait du Missouri à la côte ouest (1860-1861). Le courrier était alors acheminé à dos de cheval. Mais en 1861, le télégraphe transcontinental permet une liaison instantanée entre les deux extrémités du pays.

Durant le , le pays étend largement son territoire à travers deux acquisitions majeures. En 1803, la taille du pays double avec la vente de la Louisiane par Napoléon Bonaparte. L'expédition Lewis et Clark explore rapidement les territoires dans le nord-ouest, du Mississippi au Pacifique. En 1812, les États-Unis ouvrent les hostilités, et restaurent les conditions d'avant-guerre. Le territoire de la nation continue de s'étendre par l'annexion du Texas qui mène à la Guerre américano-mexicaine, dans laquelle les États-Unis obtiennent du Mexique des territoires au sud-ouest, du Texas à la Californie (traité de Guadalupe Hidalgo, 1848). Le territoire de l'Oregon est acheté au Royaume-Uni en 1846, l'Alaska à la Russie en 1867, et le royaume de Hawaii est annexé en 1898, définissant le territoire actuel des États-Unis (50 états fédérés).
L"'expansion vers l'ouest" par des actes officiels du gouvernement des États-Unis est accompagnée par le mouvement vers l'ouest (et vers le nord, dans le cas de la Nouvelle-Angleterre) des colons au-delà de La Frontière.

En 1842-1846, l'ouverture de la piste de l'Oregon puis le traité avec le Royaume-Uni (Traité de l'Oregon) provoqua l'afflux massif de nouveaux colons. Ce traité règle le contentieux qui opposait les deux pays sur le tracé de la frontière des territoires du nord-ouest. La limite est fixée au nord. Le territoire de l'Oregon est officiellement organisé en 1848. L'Oregon est érigé en état le .

La conquête de l'ouest est aussi rendue possible par la spoliation des indiens de leurs terres : l'Indian Removal Act déporte les Indiens de l'Est du Mississippi à l'Ouest du Mississippi. Les massacres et les conflits entre colons et indigènes sont fréquents.

Enfin, l'extension américaine est alimentée par l'idéologie de la Destinée manifeste à partir de 1845 : selon cette idéologie, la nation américaine avait pour mission divine de répandre la démocratie vers l'Ouest et de former un territoire continental pour sa nation. L'Ouest servit aussi de refuge aux mormons qui s'installèrent en Utah à partir de 1847.

En Europe, la mode des bonnets en peau de castor stimule le commerce des fourrures. Daniel Boone est l'un de ces trappeurs qui démarrent la colonisation du Kentucky. Ce schéma est poursuivi à travers l'ouest alors que les hommes font commerce de la fourrure avec les Indiens, et explorent le pays. Combattants et chasseurs habiles, ces "hommes des montagnes" trappent le castor en petits groupes à travers les montagnes Rocheuses. Après le déclin du commerce des fourrures, ils établissent des postes de commerce à travers l'Ouest (Fort Robidoux en 1837 ; Fort Bridger en 1841…), continuant les échanges avec les Indiens ou les Mexicains, et aidant les colons dans leurs migrations vers les régions de l'ouest : Utah, Oregon et Californie. 

En 1811, le financier new-yorkais John Jacob Astor établit Fort Astoria, le premier campement blanc de l'Oregon, sur la côte Pacifique. Son intention était de fonder un réseau de postes de traite des fourrures. Quelques années plus tard, John McLoughlin, construit Fort Vancouver en 1825. 

Dans la deuxième moitié du , des filons d'or et d'argent sont trouvés dans l'ouest : 

L'immigration liée à la ruée vers l'or provoque la naissance de véritables villes-champignons : San Francisco passe de en 1848 à en 1850. À côté de créations durables (Denver, Boulder), d'autres cités sont désertées une fois les filons épuisés (villes fantômes : Virginia City dans le Nevada par exemple). Les villes pionnières forment des univers masculins et souvent violents.

La faim de terre des paysans poussa également la frontière vers l'ouest.
Dépressions économiques dans l'Est de 1818, 1837, 1839 et 1841 



Les États du nord-est des États-Unis suppriment rapidement l'esclavage à la fin du XVIII et au début du . La traite négrière est officiellement abandonnée en 1808. Pendant l´importation d´esclaves, les Africains de même ethnie sont séparés, on leur donne des noms anglo-saxons, ils sont convertis de force au protestantisme.

En 1860, près de 3 millions de Noirs vivent dans le sud, réduits majoritairement à l'état d'esclaves. Les églises baptiste et méthodiste se détachent progressivement du contrôle des Blancs et s'organisent en communautés d'entraide. Les esclaves affranchis qui gagnent bien leur vie, essaient alors d’acheter la liberté des membres de leurs familles. Les esclaves commencent à travailler à l’âge de 12 ans, effectuant des journées de 17 à 20 heures par jour. Beaucoup meurent au bout de 5 ans, de malnutrition ou de maladie (notamment de dysenterie). Certains s’enfuient avec succès et gagnent le nord, d'autres sont mutilés quand ils sont rattrapés. Enfin certains se révoltent (Révolte de Nat Turner). Des enfants métis naissent également des unions sexuelles consenties ou non entre les maîtres et les esclaves. Ces enfants métis sont parfois éduqués (un « plaçage ») à l'européenne et deviennent eux-mêmes, parfois, propriétaire d'esclaves à l'âge adulte. D'autres moins chanceux restent des esclaves (la récolte d’enfant). 

À partir de 1808 (abolition de la traite négrière), le nombre d’esclaves diminue et leur prix augmente sur le marché aux esclaves. 

En dépit de l'invention d'une machine à séparer les graines du coton par Eli Whitney, ce sont les esclaves des plantations qui sont utilisés pour la récolte de cette culture d'autant plus que la demande est forte, stimulée par l'Europe occidentale et la Grande-Bretagne en particulier. 

Malgré tout, seule une petite minorité de Blancs dispose d'esclaves : sur 6 millions de Blancs dans les États du Sud en 1850, des esclaves.

Les idées de la révolution américaine, les soulèvements d'esclaves et la révolution haïtienne font craindre chez certains planteurs une insurrection générale de la population noire. En 1831, l'esclave Nat Turner, conduit une révolte dans le comté de Southampton en Virginie (51 blancs sont tués en une journée). Elle est finalement écrasée et son chef est exécuté. 

Le compromis du Missouri (1820) consacre la règle de la parité dans l'admission des nouveaux États dans l'Union : au nord du , ces nouveaux États doivent interdire l'esclavage et il doit y avoir le même nombre d’États abolitionnistes qu’esclavagistes. Lorsque le Missouri esclavagiste est créé on crée un nouvel état abolitionniste au nord : le Maine (détaché du Massachusetts).

L'acte Kansas-Nebraska en 1854 est une des origines de la guerre de Sécession. La constitution américaine interdisait l’esclavage au nord du mais lors de la création du Kansas, ses habitants veulent eux-mêmes choisir par référendum si on doit pratiquer l’esclavage ou pas. Il y a alors des affrontements entre esclavagistes et abolitionnistes et de nombreux avocats dont un certain Lincoln, ancien politicien, s’intéressent à cette affaire et portent plainte. Lincoln fonde plus tard le parti républicain et propose d’abolir l’esclavage.

La guerre de Sécession s'enracine dans les différences de développement et d'économie entre le nord et le sud : le nord s'industrialise et s'urbanise, accueille les immigrants européens et impose des taxes sur les produits britanniques. Les États du sud profitent au contraire des importations britanniques de coton et du système esclavagiste.
En réaction à l'élection du républicain Abraham Lincoln en 1860, la plupart des États du Sud font sécession de l'union et forment les États confédérés d'Amérique. Lincoln promet de les remettre dans l’Union, par la force s'il le faut : l’Union a priorité sur l’esclavage. La Guerre civile américaine s'ensuit, elle s'élève donc plus contre la sécession que pour la libération des esclaves.
Le commandement du Sud, suivi par des politiques économiques d'exploitation dans les territoires conquis après la guerre cause une amertume tenace parmi les Sudistes envers le gouvernement des États-Unis. Cet échec du gouvernement fédéral à réunir le pays contribua à son échec pour plusieurs décennies à faire mettre en application les "Droits civiques" des anciens esclaves afro-américains dans le Sud.

La guerre commence le , lorsque les confédérés bombardent et prennent le Fort Sumter en Caroline du Sud. L’armée américaine est minuscule (), confinée à l’ouest dans des guerres contre les Indiens. L’Union et les confédérés sont obligés de lancer un appel aux volontaires. Les officiers de l’armée américaine se contentant juste de former et encadrer ceux-ci. L'année 1862 est marquée par les défaites de l'Union à l'est mais aussi par les succès du général Grant sur le fleuve Mississippi (reddition de La Nouvelle-Orléans). En juillet 1863, la victoire nordiste de Gettysburg (Pennsylvanie) porte un coup d'arrêt important à l'avancée des Sudistes. Le nombre de soldats sudistes mobilisés est tel que l’écrasante majorité des esclaves laissés sans surveillance se sont enfuis, Lincoln en profite alors pour lancer la proclamation d’Émancipation c’est-à-dire à interdire officiellement l’esclavage. La guerre change de données, cela devient aussi une guerre contre l’esclavage. Ceci augmente le nombre de volontaires nordistes, prêt à se battre pour un bel idéal et les esclaves enfuis sont aussi engagés comme soldats. Le , Atlanta est prise par le général William Tecumseh Sherman. Après la reddition de Robert Lee en avril 1865, les armées du sud cessèrent rapidement le combat.





</doc>
<doc id="15480" url="https://fr.wikipedia.org/wiki?curid=15480" title="Cemex">
Cemex

Cemex (acronyme de "", ) est une entreprise de matériaux de construction ayant son siège au Mexique. Comme ses concurrents directs, Cemex est actif dans le ciment, le béton (un dérivé du ciment) et les granulats. À la différence de ses concurrents cependant, le béton représente une part aussi importante de son chiffre d'affaires que le ciment (40 %). L'entreprise détient une part de marché volumineuse dans plusieurs pays comme au Vénézuela avec 50 % ou même en France avec 19 % de marché. Cemex se situe derrière Lafarge et Holcim pour la production de ciment, mais occupe le premier rang mondial pour celle de béton.

Implanté dans différentes régions du monde, Cemex est particulièrement présent au Mexique, aux États-Unis et en Europe. Cemex emploie près de en 2007. Cemex est présent dans l'indice IPC de la Bourse du Mexique. Son siège social est situé à Monterrey au Mexique.

Cemex voit le jour avec l'ouverture de Cementos Hidalgo, en 1906. Cementos Portland Monterrey est fondée en 1920, et en 1931, les deux sociétés fusionnent, pour devenir Cementos Mexicanos, soit Cemex. 

Dans les années 1960, Cemex grandit en devenant acquéreur d'autres sites de production à travers le Mexique. En 1976, la société est cotée à la Bourse du Mexique, et cette même année, devient le premier producteur de ciment du Mexique avec l'acquisition de trois sites de Cementos Guadalajara.
En 1982, la société développe sa production outre-mer, doublant ses exportations. 

Plusieurs acquisitions de sociétés de ciment mexicaines sont réalisées entre 1987 et 1989, ce qui fait de Cemex une des dix sociétés les plus importantes au niveau mondial dans le ciment. En 1992, Cemex entame sa croissance internationale avec l'acquisition des deux plus grandes sociétés de ciment espagnoles. C'est au tour de la plus grande société du Venezuela, Vencemos, d'entrer dans le giron du groupe en 1994, et d'autres acquisitions ont lieu la même année aux États-Unis et au Panama. En 1995, Cemex acquiert une société de ciment dans la République dominicaine.

Le , Cemex finalise l'acquisition pour de dollars du groupe basé à Londres, RMC Group, ce qui fait de Cemex le leader mondial de la production de béton prêt à l'emploi. Cette acquisition augmente sa couverture des marchés européens. Avec cette acquisition, la société espère voir sa production annuelle de ciment augmenter de de tonnes, et elle pourrait voir ses ventes annuelles atteindre , très près du leader mondial, Lafarge qui pour sa part a un volume de chiffre d'affaires de .

En octobre 2006, Cemex lance une offre d'acquisition sur Rinker Group, cimentier australien très présent aux États-Unis, pour dans un premier temps 12,8 milliards de dollars avant de l'augmenter à 14,2 milliards de dollars. Cette offre d'acquisition réussit malgré les réserves des autorités de la concurrence américains, qui demandent la vente de 39 unités de productions en Floride et en Arizona.

Le , dans le cadre de son plan de nationalisation de l'industrie du ciment (après le pétrole et les télécommunications), le président vénézuélien, Hugo Chávez, a exproprié la filiale locale de Cemex (qui détient près de 50 % du marché vénézuélien), après que l’entreprise a refusé l’indemnisation de de dollars proposée par le gouvernement de Caracas. En effet, le cimentier mexicain réclame de dollars. Cemex a annoncé qu’elle allait présenter une demande d’arbitrage international, jugeant la mesure illégale. L’expropriation de Cemex devait permettre à l’État vénézuélien de mettre la main sur 90 % de l’industrie du ciment du pays, après un accord de cession de leurs filiales conclu, également le 19 août, avec le français Lafarge et le suisse Holcim.

En août 2016, Cemex annonce la vente de certains de ses actifs aux États-Unis au Grupo Cementos de Chihuahua pour 306 millions de dollars.



</doc>
<doc id="15485" url="https://fr.wikipedia.org/wiki?curid=15485" title="Steve Wozniak">
Steve Wozniak

Stephen Gary Wozniak, dit Steve Wozniak, né le à San José, aussi appelé Woz, est un informaticien, professeur d'informatique et électronicien américain. 

Il est cofondateur de la société Apple Computer avec Steve Jobs et Ronald Wayne, et concepteur des premiers Apple (dont Apple I, Apple II, Apple III, Lisa et divers périphériques), et est un des pionniers de l'industrie micro-informatique.

Wozniak a toujours aimé les projets qui exigent une profonde réflexion. Son père, ingénieur chez Lockheed, lui apprend les rudiments des mathématiques et de l'électronique. À , il construit son propre équipement de radioamateur. À , il est élu président du club d'électronique de son établissement scolaire, et gagne le premier prix à une pour une calculatrice utilisant des transistors. En outre, au même âge, Wozniak gagne le premier prix d'un concours de création de machines à additionner et soustraire, la base de tout son travail ultérieur.

Steve Wozniak fait la connaissance de Steve Jobs en 1970 grâce à son voisin Bill Fernandez, alors camarade de classe de Jobs à la Homestead High School. Ils partagent la même passion de l'électronique, ils deviennent amis et réalisent ensemble de nombreux canulars. En octobre 1971, les deux Steve mettent la main sur un article du magazine "Esquire" qui explique comment fabriquer une blue box, un appareil qui permet de passer des appels longue distance de façon entièrement gratuite en fraudant donc les compagnies téléphoniques, et plus précisément AT&T. Ils décident alors d'en monter et de les vendre pour l'unité, pour un total de environ. Selon Steve Jobs, cette expérience est à l'origine d'Apple.

En , Steve Wozniak est embauché par Hewlett-Packard dans le département des produits avancés, qui produit des calculatrices, où il est rapidement rejoint par Bill Fernandez. Il tente alors de rejoindre la division ordinateur de HP, en vain. Steve Jobs est employé par Atari pour développer des jeux vidéo, tâche dans laquelle il est aidé par Wozniak hors de son temps de travail.

Steve Wozniak rapporte dans son autobiographie "iWoz", que c'est Steve Jobs qui eut l’idée de vendre un ordinateur sous la forme d'un circuit imprimé pré-assemblé. Bien que d'abord sceptique, Wozniak est convaincu par la suite par Jobs que même si cela est un échec, ils pourront toujours raconter à leurs petits enfants qu'ils avaient eu leur propre société. Pour rassembler des fonds, Wozniak vend sa calculatrice programmable HP-65, Jobs son Volkswagen Combi et ils en obtiennent pour assembler leur prototype. Sur un processeur MOS Technology 6502 qu'il découvre en septembre 1975, il écrit un interpréteur BASIC émulé sur une machine HP. Le circuit de l’Apple I est entièrement conçu par Steve Wozniak ; bien que sommaire, il impressionne les membres du Homebrew Computer Club, un club de Palo Alto réunissant des passionnés d'informatique. Contrairement à d'autres machines admirées par le groupe comme l'Altair 8800, l'Apple I est capable d'affichage graphique sur un écran. Le travail commence dans la chambre de Jobs à Los Altos puis lorsque la pièce devient trop exiguë, ils transfèrent leur atelier de montage dans le garage de la famille Jobs. L’appartement de Wozniak à San José est lui rempli de moniteurs, d'appareils électroniques et quelques jeux vidéo développés par Wozniak.

Le , Jobs et Wozniak forment leur société, Apple Computer. Wozniak quitte son travail chez Hewlett-Packard au mois de mai et devient vice-président responsable de la recherche et du développement. Jobs et Wozniak placent leurs ordinateurs au magasin « Byte Shop », un revendeur local, pour , soit pièce, et revendu . Fin 1976, grâce à un investissement de de Mike Markkula, la société engrange près d'un million de dollars avec de nouvelles ventes.
Steve Wozniak se concentre maintenant à plein temps à son amélioration et lui ajoute de nouvelles fonctionnalités. Sa nouvelle machine doit conserver les caractéristiques les plus importantes de l' : simplicité et rentabilité. Wozniak ajoute le graphisme haute résolution dans l'Apple II qui peut maintenant afficher des images aussi bien que des lettres.

En 1978, il conçoit un lecteur de disquette peu coûteux et Randy Wigginton et lui écrivent un système d'exploitation de base. En plus de son don pour le matériel, Wozniak écrit la majeure partie des logiciels qui tournent sur la machine. Il programme un interpréteur BASIC, un jeu de casse-briques (qui est l'occasion d'ajouter du son à l'Apple), le code pour commander le lecteur de disquettes, et plus encore. Côté logiciel, l' est également rendu plus attrayant pour un utilisateur professionnel par l'apparition du fameux tableur VisiCalc de Dan Bricklin et Bob Frankston. Le , Apple entre en bourse et fait de Jobs et Wozniak des millionnaires avec respectivement d'actions chacun, introduites à .

Ses travaux pour Apple sont arrêtés après un accident d'avion en février 1981, à la suite duquel Steve Wozniak souffre d'amnésies pendant quelques semaines. Wozniak devient moins enthousiaste dans son travail pour Apple. Il se marie avec Candice Clark, retourne à l'université sous le nom de « Rocky Clark » pour obtenir en 1986 ses diplômes en informatique et en électrotechnique.

En 1983, il revient chez Apple d'une manière assez originale : il rentre dans l'un des bâtiments de l'unité Apple et demande tout simplement s'il peut faire quelque chose. Il découvre alors le projet Apple IIgs, avec son . Cependant, à cause de problèmes externes et internes, il quitte Apple le , après la création de la société ; il touche d'Apple un salaire symbolique d'environ par an. Jobs quitte aussi Apple à la suite d'une lutte pour le pouvoir à la tête de la société. Wozniak sponsorise alors des actions caritatives dans le domaine de l'éducation, ce qui ne l'empêche nullement d'acheter les nouveaux produits Apple pour les étudier et les mettre à la disposition des écoles.

Bien qu'ayant cessé d'y travailler, Steve Wozniak reste un fan revendiqué d'Apple. Il continue à faire des déclarations publiques sur l'entreprise : il a par exemple exprimé son approbation pour Tim Cook mais a critiqué certains choix techniques sur l'iPhone.

Wozniak met un point d'honneur à acheter chaque nouveau modèle d'iPhone en s'intégrant à la file d'attente du jour de lancement plutôt que de le demander directement à Apple, afin de profiter de l'occasion pour rencontrer d'autres fans de la marque.

Il poursuit ses activités dans le domaine de l'informatique avec l'aide d’anciens collaborateurs débauchés d'Apple.

En 1985, il fonde , société créant des télécommandes universelles vendue en 1988, le coût de ces appareils entièrement programmables étant supérieur aux autres télécommandes du marché.

En 2001, il fonde ("WoZ", comme diminutif de Wozniak), créant un localisateur GPS pour retrouver des objets "via" un ordinateur. La société et les brevets sont vendus en 2006 à ZonTrak.

En 2006, il fonde , un holding pour acquérir des sociétés de technologies pour les développer. Ce holding rachète Jazz Semiconductor Inc. puis prend son nom pour devenir Jazz Technologies, qui sera finalement absorbée par Tower Semiconductor en septembre 2008.

En février 2009, il rejoint Fusion-io, une compagnie de serveurs informatiques et de stockage de données dont il devient le "chief scientist".

En 2014, Il devient professeur associé à l'université technologique de Sydney.

Il est marié à sa quatrième femme, Janet Hill, depuis 2008, et a trois enfants de ses précédents mariages.

En septembre 2000, Steve Wozniak entre au National Inventors Hall of Fame (musée des inventeurs américains).

En 2014, il obtient le statut de résident permanent en Australie.







</doc>
<doc id="15488" url="https://fr.wikipedia.org/wiki?curid=15488" title="Jérôme Pétion de Villeneuve">
Jérôme Pétion de Villeneuve

Jérôme Pétion de Villeneuve, né à Chartres le , mort dans la commune de Saint-Magne-de-Castillon le , est un avocat et un révolutionnaire français, maire de Paris de 1791 à 1792.

Fils de Jérôme Pétion, avocat au bailliage de Chartres, subdélégué de l'intendant pour le bailliage et juge présidial à Chartres, et de Marie-Élisabeth Le Tellier, il fait ses études chez les Oratoriens de Vendôme puis à 18 ans chez un procureur à Paris avant de s'inscrire au barreau de Chartres en 1778. Il essaie de se faire un nom en littérature, concourant à divers prix et publiant plusieurs mémoires : "Moyens proposés pour prévenir l'infanticide" (1781), "Les Lois civiles et l'administration de la justice ramenées à un ordre simple et uniforme, ou Réflexions morales, politiques, etc., etc., sur la manière de rendre la justice en France avec le plus de célérité et le moins de frais possible" (1782) — interdit par la justice —, "Essai sur le mariage considéré sous des rapports naturels, moraux et politiques, ou Moyens de faciliter et d'encourager les mariages en France" (1785), ses autres écrits étant consacrés à la réunion de l'Assemblée des notables et des États généraux. Il est également membre actif de la Société de Amis des Noirs.

Élu le premier député du tiers état du bailliage de Chartres aux États généraux avec 164 voix sur 190 votants, il siège parmi le petit groupe des patriotes avancés de l’Assemblée constituante avec François Buzot et Maximilien de Robespierre, dont il est l'ami et partage les combats démocratiques : lutte contre le veto royal, les deux chambres proposées par les Monarchiens, le suffrage censitaire (s'il ne défend pas le suffrage universel, il exige l'éligibilité de tous les citoyens actifs). Il devient l'un des chefs de file des Jacobins. Membre du comité de révision, il est adjoint en au comité de constitution, avant d'être élu secrétaire puis président de l'Assemblée.

Lors de la fuite de la famille royale et son arrestation à Varennes en juin 1791, alors qu'il vient d'être nommé président du tribunal criminel de Paris (fonction qu'il n'exercera pas), il est chargé, avec Barnave et le comte de Latour-Maubourg, de la ramener à Paris. Il a laissé un témoignage de cet épisode, dans lequel il prétend que « si nous eussions été seuls, elle (Madame Élisabeth) se serait abandonnée dans mes bras aux mouvements de la nature ». Par la suite, il se prononce en faveur de la suspension, voire de la déchéance, de Louis XVI.

Le , lors de la clôture des séances de l'Assemblée, il bénéficie avec Robespierre d'une ovation de la foule parisienne. 

Intimement lié à Madame de Genlis, il l'accompagne jusqu'à Londres quand celle-ci y conduit trois élèves, parmi lesquelles Adélaïde d'Orléans, en octobre-novembre 1791.

Le , il est élu maire de Paris face à La Fayette avec voix sur votants, avec l'appui de la Cour, opposée à La Fayette, selon certains avis. Le 20 juin 1792, il tente d'empêcher les manifestants d’envahir le palais des Tuileries et des appartements royaux, mais il est accusé par le roi et le directoire du département d'avoir favorisé l'émeute et facilité, par son absence de réaction, l'invasion des Tuileries. Le 6 juillet, il est suspendu de ses fonctions par le département et remplacé par Philibert Borie, mais cette mesure accroît sa popularité ; les sections s'arment pour réclamer son retour, et il est le héros des célébrations du . L'Assemblée législative décide alors de le rétablir dans ses fonctions. Le , il est chargé de porter l'adresse des commissaires des 48 sections exigeant la déchéance du roi. En revanche, il ne participe pas à la journée du 10 août 1792.

Il est confirmé dans ses fonctions de maire par la commune insurrectionnelle, mais perd tout pouvoir face aux sections révolutionnaires. Il ne s'oppose pas aux visites domiciliaires et reste totalement passif lors des massacres de Septembre. Le 6 septembre, il vient rendre compte devant l'Assemblée des événements.

Élu le 5 septembre député d'Eure-et-Loir à la Convention, le sur 9 avec 274 voix sur 354 votants, il démissionne de ses fonctions de maire et devient le premier président de l'assemblée lors de l'ouverture de la session, le .

À cette époque, il se heurte à Robespierre, avec lequel il rompt au début de novembre, et s’allie aux Girondins. Lors du procès de Louis XVI, il vote l'appel au peuple et la mort avec sursis. Au printemps 1793, il entre en conflit avec la Commune de Paris, qui échappe aux Girondins après la démission de Chambon, accélérant la rupture entre Girondins et Montagnards. Toutefois, il vote contre la mise en accusation de Marat.
Après l'insurrection du 2 juin 1793, il est décrété d'arrestation, mais réussit à s'évader le 24 juin et rejoint Caen avec Guadet, où il tente de soulever la Normandie contre la Convention. Après la bataille de Brécourt en , il passe dans le Finistère, d'où il s'embarque pour la Gironde (Bordeaux était entré en insurrection contre la Convention) avec Buzot et Barbaroux, avec lesquels il vit caché à Saint-Émilion, près de Bordeaux, pendant dix mois. Quand Salle et Guadet sont arrêtés dans la maison du père de Guadet, se croyant menacé, il quitte son asile, chez le perruquier Troquart (chez qui il s'était réfugié depuis le 20 janvier), en pleine nuit avec Buzot et Barbaroux. Toutefois, un berger les aperçoit dans un bois de pins. Barbaroux se tire un coup de pistolet, mais il se manque et se fait prendre (il est guillotiné le 25 juin). De leur côté, Pétion et Buzot s'enfoncent dans un champ de blés et se tuent d'un coup de pistolet à Saint-Magne-de-Castillon. On retrouve leurs cadavres, à moitié dévorés par les loups, quelques jours plus tard.

Avant cette ultime fuite, Pétion avait laissé à Madame Bouquey le manuscrit de ses "mémoires" et son testament politique.

Son nom a été donné à la rue Pétion, à Paris.





</doc>
<doc id="15490" url="https://fr.wikipedia.org/wiki?curid=15490" title="Nudité">
Nudité

La nudité désigne l'état d'une partie ou de la totalité d'un corps humain qui n'est pas recouverte d'un vêtement. 

Dans d'autres contextes, la nudité renvoie à un corps considéré comme insuffisamment recouvert.

L'usage public de la nudité peut être associé à de l'exhibitionnisme et condamné en tant que tel, il est aussi revendiqué comme une libéralisation des mœurs

La pratique en commun de la nudité se développe à travers le naturisme qui la considère comme un mode de vie alternatif naturel. 

Il peut aussi être fait usage de la nudité comme un acte protestataire ou de revendication.

En zoologie, la nudité désigne l'absence de fourrure. Considérant l'espèce humaine, c'est l'approche éthologique que développe Desmond Morris dans "Le Singe nu".

Dans les beaux-arts en Europe, la représentation du corps nu est un exercice fondamental dans l'enseignement classique et un thème artistique fréquent à certaines époques.

Comme celles de la pudeur, les conceptions de la nudité ont varié dans le temps et dans l'espace. De nombreuses sociétés humaines perçoivent la nudité comme dangereuse.

En zone froide et tempérée, le vêtement est d'abord un élément de protection contre le froid, comme il peut être une protection contre le soleil dans les déserts. Il est aussi porteur de divers marqueurs sociaux relatifs au genre (quand les hommes et les femmes s'habillent différemment), à l'emploi (par exemple, l'uniforme), à la position sociale (par l'exhibition de sa valeur), à l'adhésion à des valeurs (par l'élégance dans un style ou code vestimentaire).

En zone tropicale le caractère social et distinctif peut s'exprimer sans vêtements par des peintures corporelles et des tatouages, ainsi que par divers accessoires, et ce qui est pour d'autres une "nudité" est normal ou parfaitement toléré. Cependant, les missionnaires et administrateurs américains et européens ont fait reculer la nudité des adultes, puis des enfants sur presque toute la planète.

Les Grecs de l'Antiquité valorisaient la nudité masculine dans certains contextes : l'adjectif γύμνος ("gymnos"), dont est dérivé notre "gymnaste", signifiait "nu". À d'autres époques, pour des motifs exprimés souvent en termes religieux, elle est mal admise voire strictement interdite (ère victorienne au Royaume-Uni, États-Unis). Dans l'art, elle est souvent valorisée des époques classiques à l'époque moderne (peinture, sculpture, puis photographie, dès le ), et ce, même si elle n'est pas tolérée par ailleurs : 

De nos jours, la nudité n'est considérée comme normale ou tolérable que dans des moments particuliers de la vie (la toilette, l'accouchement/naissance, toilette mortuaire, morgue/autopsie, les examens médicaux et gynécologique notamment, vacances estivales, et seul ou dans l'intimité (devant le miroir).

Hors de ces contextes, la nudité totale, parce qu'elle ne cache pas les organes génitaux, est souvent assimilée à une invite à la sexualité. Or la sexualité est elle-même très codifiée au sein de tout groupement humain. La plupart des sociétés ont des lois déterminant des interdictions ou des obligations vestimentaires, parfois explicitement en lien avec le contrôle de la reproduction de ses membres.

La nudité en public provoque un trouble d'autant plus intense qu'elle est rare. Dans les milieux ou sociétés les plus pudiques, la nudité est une transgression qui pourra être interprétée comme une invite à la fornication. 

Dans les sociétés à vêtement, celui-ci définit la personnalité sociale ; la nudité marque l'absence de position et le degré le plus bas de l'échelle, exprimé par de nombreux proverbes et expressions comme « n'avoir qu'une main devant et l'autre derrière ».

Le vêtement ayant nécessairement un coût, puisque généralement produit par un spécialiste, la nudité, associée à d'autres signes de pauvreté (comme l'absence de soins cosmétiques, notamment des cheveux et de la barbe, les maladies de peau) est perçue comme liée à la pauvreté ou comme un attribut de l'indigent.

Dans une telle société, dépouiller une autre personne de ses vêtements, tandis que ceux qui le font restent vêtus, est une humiliation. De nombreux châtiments incluent la nudité forcée, depuis l'Antiquité romaine et le Moyen Âge. Les Romains ôtaient à titre infamant tout vêtement aux condamnés à mort par crucifixion. Dans la France de l'Ancien Régime, les deux peines maximales, l'écartèlement et la mort sur la roue, étaient accompagnées de nudité publique. La pendaison s'exécutait avec le condamné .

À une époque plus moderne, la mise à nu fait souvent partie des humiliations du bizutage.

On mentionnera l'existence, à diverses périodes et dans plusieurs pays d'Europe (Pays-Bas, Bohême, Savoie, Pologne, Grande-Bretagne) d'Adamites ou Adamiens qui s'inspirant de la pureté primitive du paradis terrestre pratiquaient la nudité pour l'exercice de leur culte dans leurs temples. Certains d'entre eux allaient même dans les rues pour proclamer l'observation des lois de la nature. 

En Inde, il faut également citer l'existence actuelle de sadhus hindous nus vivant seuls ou en communautés ou encore des moines jaïns digambara (vêtus de ciel) pratiquant le détachement complet du monde, l'ascétisme et la non-violence absolue. Ils vont nus par les routes avec pour seuls biens un balai pour ôter de leur chemin les petites bêtes qu'ils pourraient écraser en marchant et un seau pour leurs ablutions. Ils recueillent dans leurs mains jointes la boisson et la nourriture que leur donnent pour vivre les laïcs. Pendant la mousson, ils restent dans des locaux mis à leur disposition par ces mêmes laïcs où ils méditent et donnent des sermons sur la non-violence et le détachement du monde.

En 2008, dans certaines associations ou sectes, les candidats à l'admission doivent être nus pour recevoir l'initiation considérée comme une nouvelle naissance.

Inversement, celui qui se dispense volontairement et publiquement de vêtement dans la sphère publique montre qu'il refuse une valeur de son groupe.


Tous ces motifs peuvent se méler souvent. Les FEMEN utilisent la transgression qu'est encore la nudité pour obtenir une exposition médiatique en faveur d'une cause, tout en tenant un discours critique sur les valeurs liées à l'obligation de couvrir tout ou partie du corps des femmes. Dès l'action effectuée, son interprétation dépend de ses commentateurs.

Selon Norbert Elias, qui affirme que les sentiments de pudeur et la prohibition de la nudité sont corrélatifs d'un « processus de civilisation », au Moyen Âge, en Europe, des familles entières se rendaient aux bains dans le plus simple appareil. L'ethnologue Hans-Peter Duerr a depuis contesté cette thèse, examinant la documentation sur la nudité, pour conclure à l'inverse de Norbert Elias que les descriptions de nudité de cette époque ne constatent pas un état de faits commun, mais condamnent des actions considérées comme abusives.

Aux siècles de la réforme protestante, la répression de la nudité s'intensifie, mais n'a pas interdit la perpétuation et même le développement de l'art du nu, en peinture ou dans la sculpture dans les zones catholiques.

La nudité est souvent drapée d'une dimension christique qui lui sert pour partie d'alibi, et qui se surajoute à la vision presque exclusivement esthétique de la nudité héritée de la Grèce antique, dont les conceptions de la beauté et de l'Homme sont en vogue à la Renaissance puis aux périodes classiques.

Les élites aristocratiques, bien que toujours vêtues en public, apprécient et forment la clientèle d'un art ouvertement érotique développé depuis la Venise du Titien jusqu'aux productions de l'académisme français du en passant par la peinture de cour de l'époque de Louis XV de France.

Un renversement se produit en Europe au , peut-être encouragé par la mécanisation de l'industrie textile et l'influence croissante du discours hygiéniste qui conduisent les classes aisées, et à leur suite les classes moyennes émergentes, à voir dans la nudité ce signe de l'infamie paysanne évoqué ci-dessus. Ces mêmes classes s'engagent aussi dans de nouvelles pratiques corporelles, aujourd'hui objet d'étude de la sociologie du corps qui vont finalement les conduire à une rapide libération, celui de la femme en particulier, essentiellement à partir de mai 1968, avant que la popularisation du sport accompagne dans la seconde moitié du l'émergence d'un véritable culte du corps valorisant la nudité et son insertion dans un environnement sain, objectif indirect de certains naturismes. Dans les années 1970 à 1990, le culte du bronzage semble avoir à nouveau encouragé la nudité. Le bronzage est un signe que chacun se doit de ramener de vacances comme s'il s'agissait de prouver sa capacité à voyager ou à prendre des vacances. De nombreux auteurs tiennent à ce sujet pour révélatrice de la modification de la perception de la nudité dans l'évolution du maillot de bain, qui devient de plus en plus échancré, moulant et diaphane.

En France, pendant longtemps, les jeunes conscrits devaient passer entièrement nus devant le conseil de révision en mairie puis, à partir des années 1960, dans un centre d'incorporation, à l'occasion des « 3 jours ». Cet examen permettait de juger s'ils étaient de santé et de robustesse convenables à l'exercice des armes. Il a disparu avec la suppression progressive de la conscription obligatoire entre 1997 et 2001.

Dans les sociétés occidentales, le fait de montrer le sein en public y compris devant des enfants pour une femme en allaitement est parfaitement admis même s'il peut provoquer de la gène chez certaines personnes ou chez la mère elle-même. L'allaitement naturel, même s'il est peu pratiqué, est très valorisé. Toutefois en Amérique du Nord, il arrive que cette attitude soit jugée « "inappropriate" », mais les tribunaux sanctionnent le fait de demander à une femme de s'abstenir d'allaiter dans des lieux publics. Des condamnations de 2000 $can et 3500 $can ont été prononcées par le Tribunal des droits de la personne du Québec pour le fait de demander à une femme de cesser d'allaiter au sein dans un lieu public. 

Parmi les ambassadeurs de la dénudation, l'enfant a toujours historiquement obtenu le premier la licence de la nudité, dont sur les plages. Certains voient dans la nudité une forme de "regreso ad uterum", retour symbolique dans l'utérus là où d'autres voient l'expression naïve et/ou jouissive d'une liberté permise par le franchissement d'un interdit. Les travaux du chercheur sont intervenus avant les scandales récents liés à la pédophilie.

Les représentations humaines incluent en général les attributs des personnages représentés ; dans les sociétés sans vêtements, ils sont représentés ainsi.

D'une façon plus paradoxale, les sociétés occidentales chrétiennes, peu tolérantes à l'égard de la nudité publique, l'ont abondamment représentée, d'abord avec des significations négatives de souffrance et de sacrifice (Crucifix avec le Christ nu depuis le ), reprenant des représentations existant à partir de l'époque hellénistique (Marsyas), puis, à la Renaissance, avec une valorisation de la figure humaine, qui se poursuivra d'une façon discontinue jusqu'à l'époque contemporaine. Les représentations s'intéressent, en peinture, d'abord aux hommes, pour ne plus concerner presque exclusivement que les femmes à partir du .

En sculpture, le produit encore des nus masculins (par exemple, Bourdelle) dans une proportion considérable.

Mode de vie quotidien de nombreux peuples, la nudité est un acte social qui diffère selon les cultures et les contextes. 

Dans la société occidentale, la nudité totale peut avoir un usage codifié et se pratiquer dans des contextes précis, comme les lieux privés, les espaces de loisir naturistes, les plages naturistes, les Spas…

Le mouvement décrit plus haut n'autorise pas tout d'un point de vue socio-culturel. Comme le signale Jean-Claude Kaufmann dans son ouvrage "Corps de femmes, regards d'hommes", la pratique des seins nus sur les plages apparaît inconcevable à ses plus ferventes supportrices quelques mètres en arrière, aux limites de la ville et de la civilisation. La nudité reste ainsi circonscrite à des espaces bien délimités, ce qu'a bien observé Francine Barthe-Deloizy dans sa "Géographie de la nudité".

Ainsi, si le vêtement cesse progressivement d'être un indicateur de rang social pour indiquer davantage l'appartenance à un groupe ou à une tranche d'âge, la nudité demeure le fait de lieux où prend place une inversion passagère des règles sociales et elle ne s'épanouit plus ou moins qu'à la marge de la vie normale ; par exemple, pendant les carnavals, la nuit ou sur le littoral, à mi-chemin entre terre et mer.

Par ailleurs, certaines zones du corps restent difficiles à montrer. Par exemple, au Japon, l'exposition des poils pubiens au cinéma était assimilée à un acte pornographique jusqu'à la fin des années 1990. 

Le naturisme, de même que la nudité simple, pratiqués en espaces publics, ne font pas en France l'objet de sanctions pénales. En effet, seule l'agression sexuelle est visée par le code pénal, soit une « atteinte sexuelle commise avec violence, contrainte, menace ou surprise ». Ainsi, en droit, le code pénal français (art 222-32) punit le délit d'exhibition sexuelle jusqu'à un an de prison et euros d'amende. En revanche, la nudité pratiquée décemment, d'un point de vue naturiste, sans geste de nature sexuelle, ne peut en France faire l'objet d'une répression légale, même en-dehors des espaces officiellement autorisés (même en-dehors des plages ou des centres naturistes).

L'outrage à la pudeur, concept trop subjectif, n'existe plus dans le code pénal depuis 1992. Si tout de même il y a procès, à la suite d'une plainte transmise au procureur qui engage une suite, le tribunal pourra juger si la nudité avait un caractère sexuellement provoquant ou non, eu égard à la jurisprudence qui, en cas de nudité simple, est favorable à la relaxe. Il en va du bon sens. Ainsi, être simplement nu chez soi, même visible de la rue ou de voisins, sans volonté de choquer, reste parfaitement légal. De même, les manifestations de personnes nues dans les rues font généralement l'objet de non-lieu. Si des arrêtés ou des règlements municipaux peuvent interdire d'être plus ou moins nu dans l'espace communal, d'un point de vue juridique ils n'ont pas force de loi donc sont contestables. La nudité est donc, en pratique, difficilement punissable, sauf à exagérer ou à s'insérer dans des espaces trop peuplés de gens habillés.

Le fait de se dénuder ou « dénudation » semble un acte plus délicat à envisager, du fait de similitudes apparentes avec une pratique exhibitionniste. Ainsi, à l'entrée des parcs naturistes allemands, où la nudité est par ailleurs très bien vécue, il existe pourtant des cabines pour se changer à l'abri du regard de tous. Dans les commerces des pays occidentaux, on trouve des cabines d'essayage, dont l'existence peut surprendre par rapport à ce qui se fait sur les plages (après tout, l'essayage d'un article ne demande dans le pire des cas que de paraître en sous-vêtements devant quelques clients). Cela renvoie à une habitude culturelle qui vise à préserver du regard celles et ceux qui ne veulent pas être vus ; il ne s'agit pas d'interdire d'être vu dénudé mais de pouvoir ne pas l'être.

Les publicitaires jouent des aspects contradictoires de la nudité, en utilisant les corps féminins offerts à la vue de tous via l'image publicitaire ou filmée d'une manière souvent inspirée de leur présentation artistique, mais qui suscite la contestation de certains groupes jugeant certaines images dégradantes.

En outre, la nudité ne favorisant pas l'activité du secteur textile et du commerce des vêtements, elle ne participerait pas à une part généralement substantielle des échanges au sein de l'ensemble humain considéré, qu'il s'agisse d'échanges rituels ou économiques.

Face au marché de l'habit, il existe un marché utilisant la nudité allant de la à la pornographie la plus crue, marché que l'on sait inspirer les médias.

Dans le domaine du spectacle, la dénudation progressive constitue le genre du striptease.




</doc>
<doc id="15491" url="https://fr.wikipedia.org/wiki?curid=15491" title="Maillot de bain">
Maillot de bain

Le maillot de bain (ou le costume de bain en Suisse et au Québec) est un vêtement destiné à cacher certaines parties du corps lors de la pratique de la natation, de la baignade, de la détente au bord de l'eau (plage, bronzage…) ou, plus généralement, lors de toute activité de plein air. 

Dans l'Antiquité romaine, les bains publics sont très prisés et l'on s'y baigne nu. 

Au Moyen Âge, les eaux thermales et les bains de mer sont jugés malsains pour la santé, accusés de répandre la peste notamment, et leurs bienfaits ne sont redécouverts qu'au . On se baignait alors en chemise.

À la fin du , les femmes se baignent en corset et pantalon bouffant. Les hommes, eux, portent un costume qui s'arrête aux mollets et à manches longues car il est inconvenant de montrer le torse. Vers 1900, la femme porte une robe légère qui s'arrête au genou sur une culotte bouffante de la même étoffe.

Au début des bains de mer au , le costume de bain est codifié par le corps médical et les hygiénistes qui préconisent un costume bouffant en laine ce qui gagne en confort et un bonnet sur la tête. Le dénudement progressif des femmes et des hommes n'est pas du goût de la norme de l'époque. En Australie, le 20 octobre 1907, un arrêté oblige les hommes à porter un costume de baignade plus pudique. Les hommes doivent porter une "swimming robe", une sorte de jupe large en plus de leur uniforme afin de cacher le membre masculin qui était trop visible lorsqu'on portait un maillot de bain. 

Avec l'engouement pour la natation, les maillots de bains pour homme laissent la place au Topper ou moule-tout, les bras deviennent visibles mais pas les torses au risque d'une amende. Une championne de natation d'origine australienne, Annette Kellerman, crée son propre maillot de bain une pièce, plus pratique et adapté à la natation. Dans les années 1920, Coco Chanel lance la mode du teint hâlé (bronzage), ce qui permet de dénuder bras, jambes et épaules. En 1932, le slip Tarzan révolutionne le maillot et permet aux hommes de découvrir leur torse. 

En 1946 apparaît le bikini qui ne s'impose vraiment que dans les années 1960. Chez les hommes, le "trunk", une sorte de caleçon court sur les cuisses avec une ceinture s'impose aussi. Puis jusqu'à la fin des années 1970, la ceinture du maillot descend sous la taille et le bikini devient monokini. Les tendances suivantes sont une culotte de plus en plus mince et la disparition du haut.

Dans les années 1980, l'influence du surf favorise le port de caleçons longs chez les hommes qui supplantent durant une vingtaine d'années l'utilisation du classique slip de bain, issu de la mode unisexe. Le maillot de forme "boxer" est lui aussi devenu prépondérant (en tout cas en piscines françaises où le short est interdit), par le maintien anatomique qu'il procure, la zone couverte plus grande, une image contemporaine, une liberté de mouvement et l'effet de mode. 

Dès la fin du apparaît en Europe ce qui constituera le fondement du mouvement naturiste qui prône, entre autres pratiques de vie saine et équilibrée, la baignade sans aucun vêtement. Le vêtement — notamment le maillot de bain — est considéré à la fois comme une entrave, impropre aux activités de plein air, et a fortiori aquatiques, et comme un objet d'érotisation, incompatible avec des relations sociales quotidiennes apaisées. Le naturisme considère le vêtement comme un indicateur social (de richesse, de statut…) ; son absence permet de ne plus voir que les personnes en lieu et place de ce qu'elles prétendent être, en l'absence de toute érotisation dans le cas du maillot de bain.

Depuis les années 2010 se développe doucement une tendance à employer des tenues de bain plus couvrantes en toute circonstances, une-pièce chez la femme ou "jammer" chez l'homme, par exemple. Augmentation du nombre de cancer de la peau, frilosité personnelle dans une eau fraîche, refus de la sexualisation par des tenues trop courtes ou moulantes, malaise avec son corps mais nécessité de se baigner, préceptes religieux… tous ces facteurs poussent de plus en plus de gens à se couvrir plus, voire à se baigner habillés.

L'eau, la transpiration et la chaleur favorisent les macérations et le développement de germes, cette macération entraîne des irritations et des mycoses qui se développent facilement sous un tissu humide. Il est donc conseillé de ne pas garder un maillot humide lors du rhabillage.

À l'exception des shorts de bain, les maillots de bain reprennent en général la forme peu couvrante et moulante des sous-vêtements, moyennant quelques aménagements : 
Les shorts et caleçons de bain voient leurs poches équipées d'un œillet dans un coin inférieur extérieur, pour l'évacuation de l'eau. Les caleçons de bain, malgré leur nom, comportent un filet intérieur en forme de slip, pour le confort du porteur. Les shorts de bain ("boardshorts") se portent généralement nu avec un vrai sous-vêtement.

Leur composition diffère radicalement. Les maillots ne sont pas faits de coton (matière absorbante), mais de nylon ou élasthanne, matières synthétiques. La composition-type est souvent la suivante : 
Le grammage (quantité de matière au cm²) et le denier (densité de tissage) peuvent varier par rapport aux sous-vêtements. Ce dernier point est important : plus le tissage est dense, moins l'eau va s'y accrocher durant la nage, et moins le maillot retiendra l'eau une fois sorti du bassin. Un tissage dense contribue aussi, partiellement, à protéger des rayons ultraviolets. 

Par ailleurs, les maillots de bain doivent répondre à des besoins spécifiques : 

Concernant l'entretien, il est conseillé de le rincer à l'eau claire (non chlorée ni salée) une fois rentré chez soi, de l'essorer, et de le suspendre. En réalité, ces conseils valent pour n'importe quel pièce textile "humide", y compris un coupe-vent après une pluie par exemple. En effet, une stagnation d'eau serait l'assurance de voir se développer des champignons ou bactéries, visibles par une sorte de « nuage » ou « mouton (blanc) » que forment leurs colonies, et parfois remarqué via l'odeur dégagée. 

Ils sont lavables en machine à laver, mais rarement au-delà de à cause de leur composition essentiellement synthétique (le Lycra pourrait fondre ou se déformer sous l'effet d'une eau trop chaude). Pour la même raison, il porte la mention « Tenir éloigné du feu » sur l'étiquette, il ne faut pas le repasser, et éviter de le faire sécher dans un sèche-linge. Il est conseillé de le laver à part, c'est-à-dire isolé dans un filet de lavage, pour éviter que le frottement dans le tambour avec d'autres éléments plus résistants (jeans) ou dur (bouton de jeans) ne les abîme.

Speedo est l’équipementier historique en natation. La marque australienne a été créée en 1910 par un jeune immigré écossais de 22 ans. La pratique grandissante de la natation dans l’après-guerre ouvre un marché toujours plus vaste et plus concurrentiel. Fondée en 1952 en Californie, O’neill domine le marché du surf. Arena, équipementier français créé en 1973 par Horst Dassler (fils du fondateur de Adidas), tente de rivaliser avec speedo. Tyr (Dieu de la victoire dans la mythologie nordique), équipementier américain, est né lui en 1985.

Le marché continue de croître dans le monde et ne semble pas connaître la crise même en Europe. Des niches de marché apparaissent au début des années 2000, avec de nombreuses nouvelles marques, notamment Funky trunks, AussieBum et Andrew Christian. Celles-ci veulent renouveler le style du maillot de bain sportif en le rendant plus original et ciblent principalement la communauté homosexuelle.

En 2008, Speedo affirme son rôle de leader en créant des combinaisons qui feront polémique lors des Jeux olympiques de Pékin. Arena et Adidas suivent la marche mais les combinaisons sont définitivement interdites par la FINA en 2010.

Speedo, désormais basée en Angleterre, c’est, en 2010, 400 millions d’euros de chiffre d’affaires, faisant de la marque le leader du vêtement sportif de natation. En 2010, Arena, basée désormais en Italie, représentait 107 millions de CA.

Les équipementiers sportifs non spécialisés, comme Adidas, Nabaiji (marque Décathlon pour les articles de Natation), Nike, Reebok, Puma, Asics sont également très présents sur le marché. Comme pour les autres grandes marques de sport, les équipementiers s’arrachent les stars de la discipline pour vendre leurs produits. Ainsi Speedo s’est longtemps offert les services de Michael Phelps pour représenter sa marque tandis que Florent Manaudou représente la marque aujourd’hui en France. Arena a réussi à s’attribuer Alexander Popov, Alain Bernard et César Cielo. Nabaiji s’offre les services de Yannick Agnel, et Matthew Mitcham a été l’ambassadeur de la marque Funky Trunks.

Le 21 mai 2015, la Startup Spinali Design à Mulhouse (France) invente et commercialise les premiers maillots de bain connectés au monde. Il s'agit d'un maillot relié à un capteur pour mesurer le taux d'UV et ainsi prévenir les coups de soleil.

Le marché du loisir et de la détente est lui beaucoup plus diversifié. De nombreuses marques de vêtements créent leurs maillots de bain.



Par ailleurs, la culotte du maillot de bain féminin peut se décliner en différentes formes :


 et certaines populations africaines ou arabes ne portent en général pas de maillots de bain « occidentaux », peu couvrants ou moulants. Elle se baignent avec leurs vêtements habituels.

Le bain habillé est aussi l'objet, dans le monde occidental, d'une sous-culture appelée "".



</doc>
<doc id="15492" url="https://fr.wikipedia.org/wiki?curid=15492" title="Constante de Brun">
Constante de Brun

En mathématiques, la constante de Brun des nombres premiers jumeaux (ou plus simplement constante de Brun) est la somme de la série des inverses des nombres premiers jumeaux, c’est-à-dire des couples de nombres premiers distants de 2.

Cette constante tire son nom du mathématicien Viggo Brun qui démontra en 1919 que cette série est convergente : voir l'article « Théorème de Brun ».

Soit formula_1 la suite des couples de nombres premiers jumeaux. Les premiers termes de cette suite sont formula_2, formula_3, formula_4, etc.

Soit formula_5 la suite des sommes partielles des inverses des formula_6 premiers termes de la suite précédente : formula_7. La série correspondante converge vers la constante de Brun, notée formula_8 :

À la différence de la série des inverses de tous les nombres premiers qui, elle, diverge, cette série est convergente. Une divergence de la série aurait permis de prouver la conjecture des nombres premiers jumeaux ; dans la mesure où elle est convergente, cette conjecture n'est toujours pas prouvée.

Une première estimation de la constante de Brun a été effectuée par Shanks et Wrench en 1974 à l'aide des premiers jumeaux jusqu'à 2 millions. R.P. Brent calcula en 1976 tous les nombres premiers jumeaux jusqu'à 10 et améliora le résultat.

Une meilleure estimation de la constante de Brun a été réalisée par Thomas Nicely en 1994 par une méthode heuristique en calculant les nombres premiers jumeaux jusqu'à 10 (pour l'anecdote, T. Nicely a mis en évidence à cette occasion le bug de la division du Pentium). Il a par la suite amélioré cette approximation en utilisant les jumeaux jusqu'à 1,6 et a mis à jour cette approximation au fil des années. En septembre 2006, il donnait l'estimation suivante :

La meilleure estimation de l'écriture décimale de la constante de Brun a été réalisée en 2002 par Pascal Sebah et Patrick Demichel en utilisant tous les nombres premiers jumeaux jusqu'à 10 :

La suite des chiffres de la constante de Brun en écriture décimale est référencée dans l'OEIS comme .

L’irrationalité de la constante de Brun démontrerait la conjecture des nombres premiers jumeaux. En effet, s'il y a un nombre fini de nombres premiers jumeaux alors la constante de Brun est rationnelle en tant que somme finie de rationnels, donc si elle est irrationnelle alors par contraposée c'est qu'il y a un nombre infini de nombres premiers jumeaux.
Il existe aussi une constante de Brun pour les quadruplets de nombres premiers. Un "quadruplet de premiers" est un couple constitué de jumeaux premiers, séparés d'une distance de 4 (la plus courte distance possible) soit formula_10. Les premiers quadruplets de premiers sont (5, 7, 11, 13), (11, 13, 17, 19), (101, 103, 107, 109). La constante de Brun pour les quadruplets de premiers, notée "B", est la somme des inverses de tous les nombres premiers des quadruplets :

avec la valeur : 




</doc>
<doc id="15494" url="https://fr.wikipedia.org/wiki?curid=15494" title="Empire moghol">
Empire moghol

L'Empire moghol (, ; , ) est fondé en Inde par Babur, le descendant de Tamerlan, en 1526, lorsqu'il défait Ibrahim Lodi, le dernier sultan de Delhi à la bataille de Pânipat.

Le nom « "Moghol" » est dérivé du nom de la zone d'origine des Timourides, ces steppes d'Asie centrale autrefois conquises par Genghis Khan et connues par la suite sous le nom de « "Moghulistan" » : « terre des Mongols ». Bien que les premiers Moghols aient parlé la langue tchaghataï, et conservé des coutumes turco-mongoles, ils avaient pour l'essentiel été « persanisés ». Ils introduisirent donc la littérature et la culture persanes en Inde, jetant les bases d'une culture indo-persane.

L'Empire moghol marque l'apogée de l'expansion musulmane en Inde. En grande partie reconquis par Sher Shâh Sûrî, puis à nouveau perdu pendant le règne d'Humâyûn, il se développe considérablement sous Akbar, et son essor se poursuit jusqu'à la fin du règne d'Aurangzeb. Après la disparition de ce dernier, en 1707, l'Empire entame un lent et continu déclin, tout en conservant un certain pouvoir pendant encore 150 ans. En 1739, il est défait par une armée venue de Perse sous la conduite de Nâdir Shâh. En 1756, une armée menée par Ahmad Shâh pille à nouveau Delhi, tandis que l'empire devient un espace d'affrontements entre les Européens (les Britanniques agrandissent leurs possessions et envahissent le Bengale à l'issue de la guerre de Sept Ans). Après la révolte des cipayes (1857-1858), les Britanniques exilent le dernier empereur moghol, resté jusqu'à cette date, le souverain en titre de l'Inde.

Les Moghols employaient le système du "", dans lequel un officier était appointé pour lever le revenu de la terre. L'empereur accordait des revenus au "mansabdar" en échange de la disponibilité de soldats en temps de guerre. Le nombre de soldats promis était fonction de la taille de la terre accordée par l'empereur. Le "mansab" était révocable et non héréditaire, ce qui donnait un grand contrôle aux empereurs.

L'Empire moghol était à dominance islamique. Quand Bâbur fonda l'Empire, il insista plus sur son héritage turc que sur sa religion. Sous le règne d'Akbar, la "jizya", l'impôt sur les non-musulmans, traditionnel dans le monde à dominance islamique, est abandonné, et le calendrier musulman lunaire laisse place à un calendrier solaire, plus utile pour l'agriculture. Cependant, l'importance de l'islam changera selon les empereurs (Aurangzeb fut ainsi un dirigeant musulman très rigoureux, qui rétablit la "jizya"). L'aire d'influence du droit hindou déclina, alors que les nouveaux convertis à l'islam vivaient sous le régime du droit musulman. Les juridictions impériales appliquaient aux sujets hindous le droit hindou. Dans le même temps, le droit se fractionna selon les territoires. Selon le système politico-juridique de l'islam, les sujets hindous, sikhs, etc., avaient le droit de maintenir leurs coutumes et d'obéir à leur propre système juridique, tant qu'ils payaient la "jizya". En échange, ils étaient exemptés de service militaire ; toutefois, ils ne devaient pas faire de prosélytisme.

L'organisation politique et juridique de l'Empire moghol était loin de se cantonner au respect de la "charia" : . Le rôle des "oulémas"-"soufis" (les deux étant alors indissociables), recrutés parmi les classes supérieures musulmanes (les "ashraf", les étrangers ou réputés tels) reste limité : leur fonction étatique se restreint . En tant que soufis, ils légitiment les souverains moghols, assurant les populations hindoues que ceux-ci étaient bénis ; la confrérie soufie Chishtiyya, très indianisée, joue à cet égard un rôle important. Les gouvernants, eux, étaient plutôt d'origine turco-mongole ou afghane.
De classe noble, les oulémas-soufis ne s'intéressaient guère aux basses castes. Pour celles-ci, les experts religieux étaient les "fakirs", affiliés à des ordres soufis hétérodoxes ("be-shar"'). Jusqu'en 1818, les oulémas s'intéressent peu à la conversion des basses castes.

De plus, l'apostasie, selon le droit hindou, conduisait à la renonciation envers tout droit à l'héritage, ce qui handicapait lourdement les conversions à l'islam. De façon générale, les empereurs moghols, du moins jusqu'à Jahângîr (1569-1627), montraient une tolérance religieuse importante, ce qui a fait l'objet de critiques de la part des jésuites.

Empreint de syncrétisme, l'empereur Akbar (1542-1605) va jusqu'à promouvoir la "Tauhid-i Ilahi" (divin monothéisme), ce qui conduit certains à le tenir pour apostat. Pour Gaborieau (1989), il accapare plutôt la fonction de soufi, tout comme Jahângîr prendra celle d'ouléma. Akbar finit par se déclarer . Par ailleurs, il supprime la "jizya", prohibe les conversions forcées et la circoncision sans consentement avant l'âge de 12 ans, et décourage les mariages précoces.

Sous le règne moghol, un certain nombre de musulmans se convertirent à l'hindouisme, ainsi qu'au sikhisme. Gurû Arjan et son successeur, Gurû Hargobind ( et ), parvinrent à convertir bon nombre de musulmans, suscitant la colère de Jahângîr (1569-1627). Dans son autobiographie, Jahângîr indique que les lieux de pèlerinage hindous de Mathura et Kangra attiraient un nombre important de musulmans.

En ce qui concerne l'organisation juridique, les Moghols mirent en place le système des "zamindar", qui fut repris plus tard par les Britanniques. Ils renforcèrent le droit hindou, y compris contre les violations commises par des Européens. Toutefois, plusieurs tentatives furent prises pour interdire la "satî" (immolation par le feu) : le second empereur moghol, Humâyûn (1508-1556), l'interdit avant de se rétracter, suivi par Aurangzeb en 1663.

L'Empire moghol éclata en 1707 et se fragmenta sous les invasions musulmanes (Iraniens et Afghans) et hindoues (Marathes). On assista, pendant le et le , à une période d'expansion économique et de renouveau du soufisme, ainsi que de la pensée politique et juridique. L"'ijtihâd" (interprétation) est rouvert, avec un intérêt marqué pour Gazâlî () et Ibn Tamiyya (), apparenté à l'école juridique hanbalite. Les échanges avec La Mecque et les écoles du Yémen se multiplièrent (, réformateur religieux, fut l'un des nombreux pèlerins-étudiants à faire le "hajj").

Les Grands Moghols sont les six premiers empereurs de cette dynastie, Bâbur (1526-1530), Humâyûn (1530-1556), Akbar (1556-1605), Jahângîr (1605-1627), Shâh Jahân (1627-1658) et Aurangzeb (1658-1707).

En 1526, Bâbur défait les Lodi et tue Ibrahim Lodi lors de la première bataille de Panipat. Cet événement marque la fondation de l’Empire moghol et le début du règne de Bâbur. En 1529, celui-ci vainc le Bengale à Gaghra. Pendant son règne, il est un excellent administrateur. Il meurt d'une longue maladie en 1530. Fin lettré, il aimait la musique, composait des poèmes et dicta ses mémoires, le "Bâbur Nâmâ", chronique de sa vie et de ses proches entre 1494 et 1529, probablement le premier texte autobiographique du monde islamique, écrit en turc tchaghataï.

Sa dynastie a régné sur l'Inde jusqu'au .

En 1530, Humâyûn succède à Bâbur. Il hérite d'un empire que son père n'a pas eu le temps d'organiser, et se trouve pris en tenailles entre deux généraux en pleine ascension : Bahadur Shah au Goujerat, et Sher Shâh Sûrî dans le Bihar. En 1531, Diu est bombardée par la flotte portugaise, puis conquise et fortifiée par eux. Il fonde une ville nouvelle à Delhi. En 1534, Sher Shah Suri est victorieux au Bengale. Humâyûn le rattrape, et l'assiège pendant six mois, au , en 1537. Mais Sher Shah lui ayant échappé, Humâyûn, plutôt que de le poursuivre, décide de s'emparer du Bengale. Sher Shah lui coupe la route de retour et le défait, le 26 juin 1539, à la . Humâyûn est obligé de s'enfuir pour Āgrā, accompagné de seuls quelques fidèles. Il perd une nouvelle bataille contre les Afghans, à Kanauj, en 1540 ; et s'enfuit au Pendjab, puis dans le Sind, s'exilant d'abord en Afghanistan, puis, en 1544, en Perse. En 1554, il entre à Peshawar ; en 1555, il occupe Lahore, puis Dîpalpur. La même année, la bataille de Macchiwara, contre les Afghans, consacre sa victoire. En juillet, Humâyûn entre finalement dans Delhi : il a retrouvé son trône, après quinze ans d'exil.

Humâyûn rapporte de son exil en Perse un art d’essence impériale ainsi que le persan comme langue officielle, qui sera parlé à la cour jusqu’en 1857. À la même époque, le hindî parlé par le peuple se teinte de connotations perso-arabiques. Il apparaît sous cette forme dans les camps militaires (en turc "urdû") des sultanats du Dekkan sous le nom hindustânî ou urdû.

En 1556, Akbar succède à son père. Il est alors âgé de quatorze ans, et son tuteur Bairam Khân va assurer sa régence. Grâce à son aide et à celle de ses troupes, Akbar remporte, la même année, la bataille de Pânipat sur les Afghans du Bihar. En 1560, Akbar s'empare du Mâlvâ. Il épouse la princesse hindoue d'Amber en 1562. Il supprime la "jizya" en 1564. L'année suivante, les chefs musulmans du Dekkan défont et détruisent, à la bataille de Talikota, le royaume de Vijayanâgara. Lors de la chute de Chittor, en 1568, Râjputs sont massacrés. Akbar agrandit son empire en faisant la conquête du Goujerat en 1573, du Bengale en 1576, du Sind en 1590, de l'Orissa en 1592, et du Balouchistan en 1594. En 1585, au décès de son frère Hakîm, roi de Kaboul, il hérite du Cachemire. Il se lance ensuite à la conquête du Sud de l'Inde.

En 1571, l'empereur fonde Fatehpur-Sikrî et en fait sa capitale. En 1581, Akbar promulgue la "Dîn-i-Ilâhî", religion des lumières sous entendant par là une , un syncrétisme unifiant le Coran, la Bible et les textes hindous. 1604 est l'année de la compilation de l"'Âdi Granth", livre saint des sikhs, par Gurû Arjun Dev. Les dernières années du règne d'Akbar sont marquées par les rébellions fréquentes de son fils Salim, le futur empereur Jahângîr. Il meurt à Āgrā le de dysenterie. Un superbe mausolée en marbre blanc et grès rouge élevé par son fils à , au nord-ouest de la ville, recueille sa dépouille. Sa tombe sera profanée par les Jâts, des agriculteurs révoltés, et ses restes dispersés.

En 1605, Jahangir succède à son père. Sous son règne, l'Empire reste en état de guerre, de façon à continuer son expansion. L'ennemi le plus sérieux de Jahângîr est , le râna du Mewâr, qui capitule finalement en 1613 devant les forces de Khurram, le futur Shâh Jahân. Au nord-est, les Moghols affrontent les Âhoms, dont la tactique de guérilla les met en difficulté. En Inde du Nord, sous le commandement de Khurram, ils défont le râja de Kângrâ en 1615. Dans le Dekkan, ses victoires permettent de consolider l'Empire. L'art, la littérature, et l'architecture prospèrent durant son règne, il commence ses mémoires, le "" et fait construire des jardins à Srinagar.

En 1627, Shâh Jahân succède à son père puis, en 1628, est proclamé empereur. En 1631, à la suite du décès de Mumtaz Mahal, l'épouse de Shah Jahan, la construction du Taj Mahal est entreprise.

Entre 1630 et 1632 s'est produite une des pires famines qu’ait connues l’Inde, touchant la région de Deccan et du Gujarat, qui a pu être due à un retard de la mousson et aurait entraîné la mort de près de 2 millions d’Indiens.

Les Moghols envahissent Bîjâpur en 1632, puis, l'année suivante, s'emparent de Daulatabad. En 1635, Shâh Jahân bat les Bundelâ et s'empare de la forteresse d'Orchhâ. En 1646, le chef marathe Shivaji Bhonsla capture Torna, près de Poona ; puis , en 1656. Les Moghols attaquent Hyderâbâd et Golkonda. En 1657, Aurangzeb s'empare de Bîjâpur, Bîdâr et , mais Shivaji Bhonsla se livre à des raids sur Ahmadnâgar et .

En 1658, Aurangzeb, nommé vice-roi du Dekkan dès 1636, emprisonne son père Shah Jahan dans le fort rouge d'Āgrā et prend le pouvoir. Il étend les limites de l'Empire aussi bien à l'est, en soumettant l'Assam et en s'emparant du port de Chittagong, qu'à l'ouest, où il exercera un certain contrôle de l'Afghanistan, et au sud du Dekkan, où les États de Tanjore et de Tiruchirapalli deviendront ses tributaires. Mais son empire ne connaît pas la paix. En 1669, Aurangzeb adopte, en rupture avec ses prédécesseurs, une politique de prohibition de la religion hindoue et de destruction des temples hindous, rétablissant la "jizya" en 1679. Les révoltes dues à son intransigeance religieuse se succèdent sans fin : Jâts de Mathurâ, Bundelâ, Patiala, sikhs conduits par le gourou Gobind Singh, Marathes fédérés par Shivaji… Tous ceux-ci se consacrent à construire l'Empire marathe, s'opposant au pouvoir moghol. En 1707, avec le décès d'Aurangzeb, disparaît le dernier Grand Moghol.

Les autres souverains de cette dynastie, appelés simplement « Moghols », sont :

Les Portugais sont les premiers à s'installer en Inde, ils y fondent les Indes portugaises à partir de 1510. En 1578, Antonio Cabral est ambassadeur des Portugais auprès d'Akbar. Les jésuites de Goa sont invités par Akbar et le visitent à Fatehpur-Sikri (1580). En 1597, Philippe II d'Espagne se nomme roi de Ceylan. Trois ans plus tard, en 1600, Élisabeth I d'Angleterre accorde une charte à la Compagnie anglaise des Indes orientales, geste suivi par les Hollandais qui fondent la Compagnie hollandaise des Indes orientales en 1602. En 1603, , le représentant de la Compagnie anglaise des Indes orientales arrive à Āgrā mais n'obtient pas de concession avant 1608.

"Les grands moghols entre monuments et sultans" de Romain Dezwarte aux éditions Amalthée sur le site http://romaindezwarte.com/accueil_026.htm.


</doc>
<doc id="15495" url="https://fr.wikipedia.org/wiki?curid=15495" title="Studio Ghibli">
Studio Ghibli

Le est un studio d'animation japonais fondé par Hayao Miyazaki et Isao Takahata en 1985. Il produit des "anime" (films d'animation japonais), longs-métrages et courts-métrages, ainsi que des téléfilms, des séries d'animation et des jeux vidéo, dans une moindre mesure. Le studio est connu principalement pour ses longs-métrages d'animation destinés à un large public et dont plusieurs ont remporté des succès auprès de la critique et du public. Le logo du studio est un totoro, une créature mise en scène dans le film "Mon voisin Totoro" en 1988.

Le nom du studio provient du mot que les Italiens utilisaient pendant la Seconde Guerre mondiale pour désigner l'un de leurs avions de reconnaissance, le "Caproni Ca.309" "Ghibli". Hayao Miyazaki, grand amateur d'aviation, décide de choisir ce nom. Pour lui, le studio Ghibli se doit de jouer un rôle d'éclaireur dans le secteur de l'animation japonaise, et d'y faire souffler un vent de nouveauté.

Le nom italien se prononce avec un « g » dur (), alors que le nom japonais se prononce avec un « g » mou () donnant la prononciation . Les Occidentaux ont tendance à utiliser la prononciation issue de l'italien. La prononciation avec un « g » dur a cependant été utilisée par le studio au Japon pour les titres « anglicisés » des courts-métrages "Ghiblies" et "Ghiblies Episode 2", prononcés .

Le studio est créé en juin 1985 par Hayao Miyazaki et Isao Takahata, et par la compagnie Tokuma Shoten, éditrice du magazine sur l'animation, Animage. En pratique, l'équipe existait déjà lors de la création du film "Nausicaä de la vallée du vent", en 1983.

Le studio se concentre sur les longs métrages d'animation, dans un pays où les "anime" et les OAV sont favorisées.

Dans les premières années, seuls les deux réalisateurs à l'origine de la création du studio réalisent leurs films, mais peu à peu, ils laissent la chance à des auteurs plus jeunes, comme Tomomi Mochizuki et Yoshifumi Kondō. Ce dernier, considéré comme le successeur de Miyazaki, meurt en janvier 1998. Miyazaki, qui pensait prendre sa retraite, revient alors sur sa décision et poursuit sa carrière.

Le , The Walt Disney Company obtient l'exclusivité des droits de distribution à l'étranger des films du studio Ghibli. À l'origine, sa filiale Buena Vista Distribution avait choisi de distribuer en France un film du studio Ghibli tous les six mois, et de ne les sortir en DVD qu'après leur exploitation en salle. Mais les plannings ont parfois changé et leur sortie au cinéma a pu être espacée de plus d'un an. De plus, Buena Vista France décide de sortir plusieurs films directement en DVD. Aux États-Unis, les films antérieurs à 1997 ont tous été diffusés directement en DVD. Certains sont actuellement introuvables en édition DVD française. Le , le porte-parole de la compagnie new-yorkaise GKIDS annonce avoir obtenu les droits de distribution nord-américains pour "La Colline aux coquelicots", long-métrage sorti en 2011 au Japon.

Une rumeur se diffuse le 3 août 2014 sur des sites anglophones et est reprise en France, annonçant l'arrêt de la production de longs-métrages. Cependant, elle semble infondée et basée sur une erreur de traduction d'une interview de Toshio Suzuki, le producteur. Suzuki évoque une « pause », une « reconstruction » et une « restructuration », ce qui pourrait signifier une réorganisation et un recentrage des activités du studio.



Il s'agit ici des dates de sorties japonaises. "Nausicaä de la vallée du vent", sorti en 1984, ne fait pas partie de cette liste car ce film est réalisé avant la création du studio, et ce, même si le studio Ghibli s'y réfère comme faisant partie de leur catalogue.


Les jeux auxquels le studio ou l'un de ses membres a participé :





</doc>
<doc id="15498" url="https://fr.wikipedia.org/wiki?curid=15498" title="Babur">
Babur

Babur (), parfois orthographié Baber, né le à Andijan et mort le à Agra, est un prince timouride de l'Inde et le fondateur de l'Empire moghol.

Son nom est Zahir ud-din Muhammad, mais il reçoit le surnom de Babur, signifiant « tigre ». Descendant de Tamerlan par Miran Shah et de Gengis Khan par sa mère. Son père, Omar Sheikh Mirza (1456-1495), est un turco-mongol roi de Ferghana, une partie du Turkestan, maintenant en Ouzbékistan.

Omar meurt le , et à 12 ans, Babur hérite du trône. Une tentative de renversement par ses oncles échoue et aussitôt son trône assuré, il réfléchit à étendre son territoire. 

En 1497, il attaque et prend Samarcande, sur laquelle il pense avoir un droit légitime héréditaire en tant que descendant de Tamerlan. Une rébellion parmi ses nobles s'empare de son royaume. En route pour le reconquérir, ses troupes l'abandonnent et il reperd Samarcande. Il reprend ses territoires perdus, mais en est finalement chassé en 1501 par son ennemi principal, Muhammad Shaybani, le khan des Uzbek. Pendant trois années, il erre, tentant en vain de récupérer ses possessions perdues, puis en 1504, rassemblant quelques troupes fidèles, il traverse l'Hindu-Kush enneigé, prend la ville forte de Kaboul et se retrouve à la tête d'un riche royaume. 

De nouveau, après la mort de Shaibani en 1510, Babur réclame ses possessions originelles, et reçoit l'aide déterminante du turkmène Ismail Safavi, et en 1511 fait une entrée triomphale dans Samarcande. Mais en 1512 il est à nouveau défait par les Uzbek et retourne difficilement à Kaboul en 1514.

Il semble maintenant avoir perdu tout espoir de récupérer la Ferghana, et comme il redoute aussi une invasion des Uzbeks à l'ouest, il se tourne vers l'Inde et en particulier le Pendjab qu'il considère comme son héritage légitime par Tamerlan. Plusieurs incursions préliminaires avaient été déjà faites, quand en 1521 une occasion se présente pour une expédition plus sérieuse. Ibrahim Lodi, sultan de Delhi, est détesté de tous, même par les nobles afghans, et Babur s'allie avec un rebelle, Alam Khan. Il rassemble ses forces, et quelques pièces d'artillerie et marche sur l'Inde. Ibrahim, avec et de nombreux éléphants avance contre lui. La grande bataille a lieu à Panipat le , Ibrahim est massacré et son armée mise en déroute. Babur se proclame alors "Padshah Ghazi", empereur de l'Inde, puis avec l'aide de son fils Humayun s'empare immédiatement d'Agra. Mais, un autre ennemi redoutable l'attend, Rana Sangha de Chittorgarh qui a rassemblé contre lui une énorme armée de . Son cas paraît désespéré, il fait le vœu de renoncer au vin, qu'il consomme sans mesure. À Kanwaha, le 10 ou , il remporte une grande victoire, tandis que son fils pacifie la vallée du Gange, et devient alors le maître absolu de l'Inde du nord.

Il passe la fin de sa vie à organiser son nouvel empire et à embellir Agra, sa capitale. En octobre 1530, son fils aîné et préféré Humayun tombe malade. Alors que tous les médecins s'accordent à annoncer sa mort prochaine, c'est Babur qui meurt, anéanti à l'annonce de la maladie de son fils . Selon la légende, il aurait donné sa vie pour sauver celle de celui qu'il désigne comme son successeur. Il décède le durant sa quarante-huitième année et est enterré à Kaboul. Humayun lui succède alors.

Fin lettré, il aime la musique, compose des poèmes et dicte ses mémoires, le "Babur Nama", chronique de sa vie et de ses proches entre 1494 et 1529, probablement le premier texte autobiographique du monde islamique, écrit en turc tchaghataï.

Sa dynastie a régné sur l'Inde jusqu'au .

De son père, Omar Sheikh Mirza, fils d'Abu Saïd Mirza, arrière-petit-fils et successeur de Tamerlan assassiné en 1469, dont il hérite une bonne partie de la personnalité, Babur nous a laissé ce portrait émouvant de précision :

« C'était un homme corpulent et de petite taille, à la barbe clairsemée et au teint coloré. Il portait sa tunique très serrée et comme, pour en nouer les cordons, il avait coutume de contracter son ventre, il arrivait souvent qu'en lui rendant la liberté les cordons se rompissent. Il ne faisait qu'un seul tour avec son turban alors qu'en ces temps-là il était de coutume d'en faire quatre ; en outre, il n'y faisait pas de pli et en laissait pendre les bouts. L'été, à moins qu'il ne fût au Conseil, il ne portait la plupart du temps que le bonnet mongol. Il appartenait au rite hanéfite et avait des opinions très orthodoxes. Il ne négligeait aucune des cinq prières quotidiennes et s'acquitta toute sa vie de ses devoirs religieux. Il passait une partie de son temps à lire et à méditer le Coran. Il était disciple de Khadja Ubaydullah et aimait converser avec lui. Celui-ci, de son côté, l'appelait son fils. Ses lectures favorites était le "khamsa", les "mesnevi", les livres d'histoire et surtout le Shah Nameh. Il avait une disposition naturelle pour la poésie, mais ne s'était pas appliqué à cultiver cet art.

C'était un prince doué d'une grande générosité : elle était chez lui la qualité dominante. D'un bon naturel, subtil, éloquent, il n'en était pas moins brave. En deux occasions, il marcha seul en avant de tous ses "nöker" et fit au sabre des prodiges de valeur... Il était d'une force moyenne dans le maniement de l'arc mais il avait une vigueur extraordinaire dans les bras de telle sorte qu'il n'était pas de lutteur qui ne fût renversé sous ses coups... C'était un agréable compagnon. À l'occasion, il récitait fort joliment des vers. C'était un homme unique en son genre. Il jouait beaucoup, surtout au tric-trac et parfois même aux dés. »

Sa mère, Kutlug Nigar Khanim, était une des cinq filles de Yunus Khan, prince de Tachkent descendant de Gengis Khan à la onzième génération par son fils Tchagataï, fondateur du khanat qui porte son nom. Par ses origines autant que par son milieu, Babur était donc un authentique Timouride. 

Babur reçoit plusieurs précepteurs aux compétences inégales, mais dont deux khodjas le marquent plus particulièrement : Ubaydallah, qui lui donne son nom et lui inculque la compassion pour les pauvres, vertu qu'il pratiqua toute sa vie et Mevlana-i-Kadi, issu d'une prestigieuse lignée, et que son élève admire pour sa sainteté et son courage.

Il pratique toutes les activités aristocratiques de son temps : équitation, tir à l'arc, escrime, natation. 

Sa langue est le turc tchagataï, rameau oriental du turc commun, la plus importante après l'ottoman. Les "Mémoires" qu'il dicte lui-même passent pour le chef-d'œuvre littéraire de cette langue. Il maîtrise le persan, alors langue vernaculaire de toute l'Asie orientale, jusqu'à composer des poèmes de très bonne facture. Il ignore vraisemblablement le mongol (malgré ses origines maternelles) de même que l'arabe, devenu déjà très minoritaire à cette époque dans la région.

Sa ville natale, bien que de taille provinciale, subit le rayonnement de la prestigieuse Samarcande qu'il rêve de conquérir sans succès durant toute sa vie.

La mort accidentelle de son père en 1494 lui permet de poser sa candidature à la succession au trône du Ferghana dans une Asie centrale dépourvue de règle de succession et déchirée par les rivalités des princes locaux, turcs ou mongols.

De l'union avec la sultane bégum Aisha (Khodjent, mars 1500), fille de Sultan Ahmed Mirza et de la bégum Qataq (1484 - v. 1531)

De l'union avec Zainab Sultan Begum (Kaboul, 1504), fille de Sultan Mahmud Mirza et de Khwanzada Begum Termizi, morte de la petite vérole en 1507 : aucune descendance

De l'union avec Maham Begum (Herat, 1506), parente de Sheikh Ahmed Jami (morte à Agra le )

De l'union avec Masuma Sultan Begum (Kaboul, 1507), fille de Sultan Ahmed Mirza et de Habiba Sultan Begum Arghun (morte en couches à Kaboul vers 1509/1510)

De l'union avec Gulrukh Begum Taghay Begchik (1508), sœur de Sultan Ali Mirza Taghay Begchik et de Yadgar Taghai (morte avant 1545)

De l'union avec Dildar Agha Begum (1510/1514), morte après 1550:

Bibi Mubaraika Begum (Kehraj le 30 janvier 1519), fille de Malik Shah Mansur Yusufzai, morte après 1556

Babur a rédigé lui-même en turc tchaghataï.




</doc>
<doc id="15499" url="https://fr.wikipedia.org/wiki?curid=15499" title="Complexité">
Complexité

La complexité est une notion utilisée en philosophie, épistémologie (par exemple par Anthony Wilden ou Edgar Morin), en physique, en biologie (par exemple par Henri Atlan), en théorie de l'évolution (par exemple Pierre Teilhard de Chardin), en écologie, en sociologie, en ingénierie, en informatique ou en sciences de l’information. La définition connaît des nuances importantes selon ces différents domaines.

Une notion de complexité est définie en Théorie algorithmique de l'information.

La théorie de la complexité des algorithmes étudie formellement la difficulté intrinsèque des problèmes algorithmiques.
Elle définit des classes de complexité ( P, NP) pour classer les problèmes algorithmiques.

La théorie de la complexité de Kolmogorov définit la complexité d’un objet fini par la taille du plus petit programme informatique (au sens théorique) qui permet de produire cet objet. Ainsi, un texte compressible a une faible complexité et contient peu d’informations. C’est d’ailleurs pourquoi les utilitaires de compression généralistes ne peuvent pas comprimer des fichiers totalement aléatoires (opération « par nature » impossible), mais uniquement des fichiers dont on sait à l’avance qu’ils comportent une certaine redondance qui se traduit par des corrélations.


Intuitivement, un système est complexe lorsque beaucoup de ramifications le composent (donc il n'est pas forcément compliqué, puisqu'en le décomposant il peut être simple à comprendre). Deux critères permettent de caractériser plus finement cette notion : le nombre et l’indépendance des parties.

La conception occidentale de la complexité qui émerge par étape chez les systèmes vivants et mène au progrès est une illusion liée en grande partie à une vision très anthropocentrée du monde vivant, qui s’accompagne de biais épistémiques tels que le macrobiocentrisme (ignorance du monde microbien au profit des macro-organismes) et l’essentialisme (modèle des plans d'organisation idéaux). Cette conception, imprégnée de la chaîne des êtres d'Aristote, est transposée dans un contexte évolutionniste au , et est aujourd'hui encore prégnante.

Selon cette conception occidentale, deux grands principes semblent intervenir de manière répétitive : la « juxtaposition » d’entités identiques, puis leur « intégration » dans des entités plus complexes, dont elles constituent alors des parties (concept épistémologique de Georges Chapouthier).

La systématique phylogénétique a réfuté cette conception occidentale en remettant sur le devant de la scène l'idée d'une évolution en mosaïque : un organisme n'est pas le reflet d'un plan idéel, mais une mosaïque unique de caractères qui est le fruit de la contingence de son histoire évolutive. La complexité et le progrès sont des notions subjectives qui n'ont rien à voir avec l'évolution biologique : .

Un système complexe est composé d’un grand nombre de parties. Avec ce seul critère, tous les systèmes matériels seraient complexes sauf les particules, les atomes, les petits ions et les petites molécules. Mais un système peut avoir un grand nombre de parties sans avoir un mouvement très compliqué, si toutes les parties bougent de la même façon par exemple. Le critère de l’indépendance des parties est destiné à exclure ces cas. Mais il est difficile à définir précisément.

Tant qu’on considère un solide comme un corps parfaitement rigide, ses parties ne sont pas indépendantes les unes des autres. Quelques nombres, quelques variables d’état suffisent pour caractériser complètement l’état de du solide : position du centre d'inertie, vitesse de , vitesse de rotation. Le mouvement de chacune des parties est complètement déterminé par ces nombres. En revanche, si on étudie les vibrations du solide, les mouvements peuvent être beaucoup plus compliqués, parce que chaque partie peut avoir un mouvement différent des autres. Il en va de même pour un fluide. Pour décrire ces mouvements il faut beaucoup plus de variables d’état, un nombre infini en théorie. Dire ici que les parties sont indépendantes, ce n’est pas dire qu’elles n’interagissent pas avec les autres mais seulement que la connaissance de l’état d’une partie ne fournit pas ou peu d’informations sur l’état des autres parties.

Il y a une part de subjectivité et d'ambiguïté dans l’appréciation de l’indépendance des parties : un système mal connu peut sembler tout aussi bien complexe, car inexplicable, que très simple, en se contentant d'explications superficielles.

Une entreprise, une administration, ... sont des systèmes sociaux complexes dans la mesure où se regroupent des valeurs différentes, des systèmes de pensées, des objectifs, des référentiels... différents dans lesquels les relations inter-personnelles, les techniques, les pratiques managériales sont imbriquées au profit d'un objectif métier, à vocation économique ou non. Dans toute organisation humaine, l'ordre est nécessaire, sous toute forme possible, pour faire co-habiter des systèmes de pensée individuels dans une organisation cohérente, et ce dans le temps. Sans ordre (objectifs collectifs ou individuels, notations, ressources humaines, ambiance, hiérarchie, intrapreneuriat, etc.) le système social ne tiendrait pas ( sociale), et passerait du simple, vers le compliqué, puis le complexe et parfois dans le chaos, irréversible.

Les systèmes simples sont des objets d’études privilégiés. Ce sont des systèmes que l’on peut caractériser lors d’une expérience et les résultats sont reproductibles. Cet intérêt de la simplicité explique en partie pourquoi on trouve dans tous les livres et les laboratoires de physique les mêmes géométries simples (cercle, sphère, cylindre...).

On peut dire qu’en première approximation « "les systèmes complexes sont tous les systèmes : la complexité est la règle, la simplicité l’exception." »

Appréhender la complexité concerne plusieurs domaines de connaissances, et rendre compte de la complexité du monde semble un objectif valide pour les chercheurs. Edgar Morin, sociologue et philosophe, propose dans « Introduction à la complexité » une approche de la complexité.
On peut noter la capacité qu'a la complexité de remettre tout en question. Elle est l'entremêlement de plusieurs paramètres qui s'influencent les uns les autres. Or on a souvent isolé des définitions sans les mettre en relation les unes les autres ce qui a ralenti le processus de compréhension de la complexité des systèmes étudiés.

La théorie générale des systèmes est parfois appelée systémique.

La n'est pas la répétition à l'identique, mais le déploiement d'une multitude de versions différentes d'un même schéma ou motif (en anglais ").

Alors, il est possible de modéliser la complexité en termes de redondance fonctionnelle, comme le restaurant chinois où plusieurs fonctions sont effectuées en un même endroit d'une structure.

Pour la complication, le modèle serait la redondance structurelle d'une usine où une même fonction est exécutée en plusieurs endroits différents d'une structure.

1 - La redondance structurelle désigne des structures différentes pour exécuter une même fonction, comme le double circuit de freinage d'une voiture automobile ou plusieurs ateliers différents ou usines différentes pour fabriquer une même pièce ou un même engin. La redondance structurelle caractérise la « complication ». La redondance structurelle s'illustre avec le double circuit de freinage pour plus de sécurité dans des véhicules automobiles modernes et avec les multiples circuits de commande électrique, hydraulique et pneumatique des engins de guerre pour les ramener au bercail avec leur équipage après des dégâts du combat.

2 - La redondance fonctionnelle est celle de la multiplicité de fonctions différentes exécutées en un point d'une structure, comme un atelier d'artisan qui exécute différentes opérations sur différents matériaux. La redondance fonctionnelle caractérise la « complexité » et condition de l'auto-organisation chez Henri Atlan. C'est la « variété » chez le neuropsychiatre Ross W. Ashby passé à la cybernétique.

La complication est de l’ordre de la redondance structurelle d’une configuration avec ("cum") beaucoup de plis (latin : "plico", "are", "atum" : plier). La complication, multiplication, duplication et réplication sont de la même série des plis et plissements. C'est la multiplicité des circuits de commande pour effectuer une même fonction.

La complexité est une configuration avec ("cum") un nœud ("plexus") d’entrelacements d’enchevêtrements. Alors, la complexité est de l’ordre de la redondance fonctionnelle, comme un restaurant qui présente un menu de 40 plats différents. Une machine à bois combinée d'artisan qui scie, rabote, perce, et tutti quanti est représentative de cette complexité, comme une perceuse électrique d'amateur avec une multiplicité d'accessoires pour différentes fonctions.

Dans le monde réel, une partie de la complexité provient de l'irrationalité des acteurs (et de leurs décisions) ainsi que de la multitude d'impacts dès que l'on considère un système ouvert. Dans le monde virtuel, des difficultés spécifiques apparaissent : l'identification des entités virtuelles, leurs définitions, leurs rôles, les règles que les humains leur appliquent, les processus d'authentification... Des critères de régulation s'appliquent sur les univers cibles et sur les manipulateurs / concepteurs.





</doc>
<doc id="15501" url="https://fr.wikipedia.org/wiki?curid=15501" title="CAN">
CAN

Le can est la tranche ou l'épaisseur d'une pièce relativement longue et étroite telle qu'une planche, c'est-à-dire la face la moins large de la pièce de bois.

CAN est un sigle qui peut signifier :

CAN est un code qui peut signifier :


Can peut faire référence à :

Can est une abréviation qui peut signifier :




</doc>
<doc id="15502" url="https://fr.wikipedia.org/wiki?curid=15502" title="Tapestry (DHT)">
Tapestry (DHT)

Tapestry (de l'anglais : "tapisserie") est un réseau de recouvrement de type table de hachage distribuée pour les réseaux pair à pair (P2P).


</doc>
<doc id="15503" url="https://fr.wikipedia.org/wiki?curid=15503" title="Information">
Information

L’information est un concept. Au sens étymologique, "l'information" est ce qui donne une "forme" à l'esprit. Elle vient du verbe latin "informare", qui signifie « donner forme à » ou « se former une idée de ».

L'information désigne à la fois le message à communiquer et les symboles utilisés pour l'écrire ; elle utilise un code de signes porteurs de sens tels qu'un alphabet de lettres, une base de chiffres, des idéogrammes ou pictogrammes. Hors contexte, elle représente le véhicule des données comme dans la théorie de l'information et, hors support, elle représente un facteur d'organisation. On touche là à un sens fondamental, où l'information est liée à un projet. Il peut être construit, comme un programme informatique, ou auto-construit, comme la matière.

Le projet de fonder une « science de l'information et de la documentation » spécifique s'est affirmé sous l'impulsion d'acteurs comme Pierre Larousse (1817-1875), Melvil Dewey (1851-1931), Paul Otlet (1868-1944), Jean Meyriat (1921- 2010). Le point de départ en a été de dissocier l'information, construction sociale et intellectuelle, de l'ensemble des objets matériels qui, en circulant, la conditionnent sans la définir. 

On doit aux spécialistes de cette science d'avoir posé que l'information ne circule pas (elle n'est pas un objet), mais qu'elle se redéfinit sans cesse (elle est une relation et une action). Ce projet est lié, dès la fin du , au développement d'une recherche à visée industrielle et au rêve d'un savoir planétaire. Mais plutôt que tout assimiler par l'idée d'un « système d'information » (idée plus récente dont le succès est dû aux développements informatiques), ces auteurs distinguent méthodiquement entre le support, le document, l'information et le savoir : effort de distinction qu'il faut redécouvrir aujourd'hui (Yves Jeanneret).

Le mot information est parfois utilisé pour théoriser des choses pratiques relevant en réalité de la perception : un individu a faim parce que son estomac l'a informé de son besoin. La chaleur d'une flamme l'informe du risque de brûlure. Il est informé de la visite prochaine d'un ami. L'information peut être parlée ou écrite et consiste à « savoir ce qui se passe », qu'il s'agisse de l'état du monde ou dans la vie d'un interlocuteur, ce qu'on n'a ni vu, ni entendu directement.

Pendant des siècles la rareté de l'information, et la difficulté de sa transmission étaient telles , explique le chercheur Dominique Wolton.

Inversement, dans un message reliant deux êtres humains, l'information n'est qu'une toute petite partie de la communication, d'où la fréquence des malentendus, selon Irène Lautier, directrice de la Faculté des Sciences du sport de l'Université Lille II.

Selon Dominique Wolton, le mot « information » est , puis et du , avant d'être repris dans l'informatique, pour parler de d'une entreprise. Le développement d'Internet a multiplié les communications sous forme de blogs et de courrier électronique, riches en commentaires, où la part d'information est dès le départ modeste et plus faible que dans les « systèmes d'information » des entreprises. Pour informer un ami d'une visite, il est plus efficace de lui téléphoner que de lui envoyer un mail.

Une définition pratique et efficace (dans le domaine des systèmes d’information par exemple), est de définir l'information comme étant une « connaissance pouvant avoir un effet » (dérivé de Shannon et Weaver cas 3 : les problèmes « influents »). 

Cette connaissance doit être portée par un support et mise en présence d'une entité (un être humain ou un dispositif) et que cette entité fasse quelque chose à partir de cette information. 

On a donc (Connaissance, support, communication, entité, action), on sait travailler sur les aspects support et communication depuis Shannon, l'identification de la connaissance peut-être caractérisée par le couple (entité, action).

Exemple du bulletin météo: l'information « bulletin météo » sur la côte normande devra d'abord être créé (par Météo France par exemple) ensuite communiquée à un média (la radio...) qui va diffuser ce bulletin à un moment donné de la journée. Ce bulletin sera diffusé au hasard de la zone de réception de cette radio, on comprend bien que l'audition de ce bulletin entrainera une action, action qui sera différente suivant que l'auditeur habite la Normandie ou la Provence, qu'il est citadin ou agriculteur...

Une information n'existe en pratique que par l'action qu'elle va susciter. Cette action peut être soit anticipée soit constatée et servir de point de départ à une analyse complète de la chaine informationnelle.

Les progrès technologiques ont dopé la communication, par la rotative et le chemin de fer au , puis les ondes hertziennes, le satellite et Internet. L'imprimerie et le train réduisant à une nuit la durée séparant la production et la consommation de l'information, la presse écrite diffuse des contenus informatifs beaucoup plus importants: quotidiens de 32 pages puis 64 pages, profitant de coûts moins élevés. La croissance économique, la colonisation puis la décolonisation, le développement boursier, génèrent une demande accrue d'information, essentiellement quantitative.

L'audiovisuel et Internet ont encore abaissé les coûts de diffusion mais pour des contenus informatifs plus restreints : le nombre de mots d'un journal télévisé est celui d'une page seulement de journal écrit, et Twitter se limite à des messages de 140 signes. L'information et la communication, sœurs solidaires, sont devenues des sœurs ennemies, luttant pour s'approprier un espace de contenu restreint, surtout quand les médias touchent un public très large. 

L'opposition information / communication s'est installée dans tous les domaines, y compris des disciplines jugées austères comme la finance. Anne Guimard, chercheuse titulaire d'un doctorat en finance internationale, a ainsi établi en 1998 que , réflexion qui amène à une position plus prudente sur la notion historique d'information financière, forcément imparfaite, pour parler de . Par sa subjectivité, la communication financière ne pourrait donc jouer un rôle qu'au niveau de la circulation de connaissances, et non au moment de la circulation d'informations, concept jugé plus exigeant. Cette évolution est significative d'une demande accrue d'information, au plan cette fois plus qualitatif. Elle inclut un souci d'objectivité qui inspire le titre d'une revue financière, "Le Pour et le Contre", emblématique de l'histoire de la presse économique et financière.

Le journalisme ne s'est que très progressivement adapté à ces nouvelles données. Au milieu des années 1990 émerge d'abord le paradigme de « journalisme de communication », promu en 1996 par les universitaires québecois Jean Charon et Jean de Bonville. Fournisseur de médias et , il adopte les mimiques du « journalisme citoyen », sur le plan de l'hyper-subjectivité, non seulement assumée mais affichée, quitte à se confondre avec les commentaires laissés par les internautes sous les articles ou sur les blogs.

D'autres estiment que cette accumulation de commentaires, mais surtout de communications qui viennent parfois « souiller » la qualité de l'information ouvre au contraire au journalisme un boulevard, pour assumer son rôle très particulier de sélection et de validation des données, afin d'en faire des informations. En recoupant et questionnant les sources officielles d'information, en recourant au besoin à la protection des sources d'information des journalistes, il devient capable de transformer de la pure communication en information et devenir ainsi le centre producteur de l'information. La déontologie demande en particulier aux médias de . La liberté d'accès aux documents administratifs et informations classifiées, prévue aux États-Unis par le "Freedom of Information Act", est renforcée lorsqu'une source interne peut orienter le journaliste, en étant protégée par l'anonymat. Ce sont alors des pans entiers de données publiques qui sont susceptibles de se transformer en informations utiles, susceptibles de valoriser, par la comparaison, d'autres stocks d'information plus accessibles, voire de favoriser le travail des chercheurs dans les pays où la liberté d'accès aux documents administratifs n'existe guère.

On qualifie d'information toute donnée pertinente que le système nerveux central est capable d'interpréter pour se construire une représentation du monde et pour interagir correctement avec lui. L'information, dans ce sens, est basée sur des stimuli sensoriels véhiculés par les nerfs, qui aboutissent à différentes formes de perception.

Dans le contexte de l’administration publique, on considère comme « information » toute donnée pertinente dont la collecte, le traitement, l’interprétation et l’utilisation concourent à la réalisation d’une mission gouvernementale, régionale, et départementale. Certaines de ces données sont des données publiques, c'est notamment le cas de la plupart des données environnementales en Europe dans le cadre de la Convention d'Aarhus. 

La transposition en droit français de la directive de l'Union européenne concernant la réutilisation des informations du secteur public a précisé que les informations publiques .

Les informations d'autorité sont appelées à être gérées dans des registres de métadonnées. Les autorités publiques sont responsables du processus d'attribution de certificats électroniques, utilisant les critères communs. Dans l'Union européenne, la directive INSPIRE demande que l'on gère les informations géographiques à des fins d'utilisation publique (gouvernements, collectivités locales...). En France, le référentiel général d'interopérabilité d'ADELE doit gérer à terme des métadonnées.

Selon la théorie de l'information, des données contiennent de l'information quand celles-ci ne sont que peu compressibles et qu'elles sont complexes. En effet, l'information contenue dans un message composé d'une seule lettre se répétant un grand nombre de fois tel que « AAAAAAAAA... » est quasiment nulle (on parle alors de faible néguentropie).

Kolmogorov a tenté de définir le contenu d'information d'une donnée par la taille du plus petit programme permettant de la fabriquer. Ainsi, le nombre pi aurait une complexité moyenne malgré son nombre infini de chiffres, le programme informatique permettant d'en construire la suite (infinie) de nombres tenant sur une seule page.

La conception la plus répandue de l'information est liée au couple « message + récepteur », le dernier possédant des "implicites" valorisant le message (et, de fait, tout message est incompréhensible sans ces implicites supposés ; ainsi un message en chinois pour qui ne comprend pas le chinois).

Ainsi, la phrase « Médor est un chien » contient plus d'information que « Médor est un quadrupède », bien que la seconde contienne plus de lettres. La différence est à mettre au compte de la connaissance d'un dictionnaire implicite et faisant partie du contexte, qui nous permet de savoir qu'un chien est nécessairement - sauf amputation - un quadrupède, l'inverse n'étant pas vrai.

Les notions de quantité d'information, d'entropie et d'information mutuelle font l'objet d'une discipline spécialisée, initiée par Claude Shannon.

La théorie de la décision ne considère comme « information » que ce qui est de nature à entraîner ou modifier une décision. Dans le cas contraire, il s'agit d'un simple bruit. On pense souvent que l'information peut être définie comme une donnée réductrice d'incertitude. Dans bien des cas, pourtant, avec la mondialisation et le développement des réseaux internationaux, une information juste peut remettre en cause une décision déjà prise. Il existe aussi des informations fausses ("hoaxes"), biaisées ou présentées de manière telle que les destinataires ont tendance à prendre de mauvaises décisions.

Il est donc vital de s'assurer de la pertinence des informations, et d'organiser des circuits d'informations tels que les informations disponibles soient bien traitées pour être distribuées aux bonnes personnes, au bon moment. C'est l'objet de l'intelligence économique. Une bonne méthode d'intelligence économique doit prendre en compte les informations issues du contexte de l'entreprise. Il est de coutume de vérifier les sources de l'information et si possible en croiser plusieurs.

L'information — souvent assimilée à la néguentropie — est un facteur d'organisation qui s'oppose à la tendance naturelle au désordre et au chaos — souvent assimilés à l'entropie —, même si des controverses persistent encore entre les spécialistes à propos de toutes ces assimilations. Un organisme vivant, comme le corps humain, ne peut rester organisé que par les informations qui le lient. Toute rupture d'information (nerveuse, chimique, etc.) entraîne la dégénérescence d'une partie ou de l'ensemble.

L'information est immatérielle. Elle peut être consignée directement ou pas sur un support matériel qui prend alors la valeur de document. L'information toutefois est indépendante du support : elle existe indépendamment de lui.

Le support d'information est l'objet matériel sur lequel sont représentées les informations ou les données. Le support d'information est la composante matérielle d'un document.

On distingue différents supports d'information :

Le papier est le support dit « physique » des livres, des périodiques, des fiches, des affiches, des documents administratifs imprimés (bons de commande, bons de livraison, factures...).

Dans l'économie moderne, il reste un support important.

Les supports électroniques sont ceux des bases de données, des systèmes de gestion électronique des documents, des systèmes de gestion de contenu, de la gestion des connaissances, etc. Bien que les informations de ces supports soient immatérielles, il ne faut toutes fois pas oublier qu'il y a également une infrastructure physique.

Le processus qui permet de faire passer des informations d'un support papier à un support électronique est souvent appelé numérisation (l'appellation dématérialisation est abusive car le nouveau support d'information est également matériel). Il a pris une importance considérable dans les économies modernes, en raison de l'informatisation croissante des entreprises et des administrations. C'est la raison pour laquelle on parle quelquefois d'économie numérique.

L'impression de document vers des fichiers, au lieu d'imprimer sur du papier avec son imprimante pour les documents dont l'utilité d'en avoir une copie papier n'est pas nécessaire. Il suffit de sélectionner « Imprimer dans un fichier » ou lors de la sélection de l'imprimante (Création de fichiers dématérialisés d'impression).

Les supports électroniques facilitent la diffusion et la dissémination de l'information. Les services 2.0 sont interopérables. Cela signifie qu'une information publiée sur un support est désormais très facilement reproductible sur d'autres, grâce notamment aux flux RSS, qui tiennent le rôle de langage commun. De plus, les sites sont généralement pourvus de fonctions de partage sur d'autres supports tels que Facebook, Twitter, Google+... fonctions connues sous le terme de « "Share this!" ».

Il existe d'autres supports d'information, notamment les supports photographiques.

La source d'une information peut être auditive, visuelle ou sous forme d'une vidéo. L'enregistrement peut être le fait d'une opération manuelle (caméra par exemple) ou automatique (vidéo surveillance par exemple).

Le stockage et le transport historiquement limités à la transmission orale et écrite sont, depuis l’avènement du numérique, très divers tel qu'un enregistrement audio, vidéo ou une télédiffusion. La capture, le stockage et la diffusion des informations se font de manière plus aisée.

La diffusion de l'information peut se faire au travers d'organes publics ou privés tel que les journaux, les magazines, la radio, la télévision mais aussi à travers d'internet via des sites internet ou les réseaux sociaux

De nombreuses entreprises ou administrations considèrent que le passage du support papier à un autre support, notamment électronique, comporte des avantages sur le plan du développement durable. La diminution de la quantité de papier qui serait obtenue par la « dématérialisation » permettrait de diminuer la consommation de bois donc la déforestation, et parallèlement la quantité de vieux papiers qui peuvent être incinérés (s'il ne sont pas recyclés) donc la génération de gaz à effet de serre.

Mais il n'est pas évident que la dématérialisation diminue la consommation de papier et la dématérialisation entraîne la consommation de ressources non renouvelables (métaux et énergie utilisés dans la fabrication des équipements électroniques, énergie nécessaire au fonctionnement des équipements électroniques), qui peuvent être perdues si les déchets électroniques ne sont pas recyclés. D'autre part, la dématérialisation s'accompagne généralement d'une augmentation des flux des biens matériels produits associés aux flux de gestion, donc d'une diminution du capital naturel.

Le bilan global sur le plan environnemental n'est pas facile à établir. de nouvelles informations sont générées chaque jour, soit huit fois plus que l'information contenue dans toutes les bibliothèques américaines.

Un certain nombre de philosophes de la seconde moitié du ont traité de la question de l'information. On peut mentionner notamment l'œuvre du philosophe français Gilbert Simondon, qui traite de la question de l'information à de nombreuses reprises dans "L'Individuation à la lumière des notions de forme et d'information" ou dans "Communication et Information." Un aspect important de la définition que Simondon donne de l'information dans ces ouvrages est l'indépendance de l'information à l'égard de toute notion d'émetteur : la notion d'information pour Simondon ne s'applique donc pas uniquement à des ensembles organisés de signes produits par un émetteur intelligent, mais à toute structure dynamique susceptible de contenir un facteur d'organisation dans le système qui la reçoit. 

L'information est également un élément important de la philosophie du philosophe français Michel Serres.




</doc>
<doc id="15506" url="https://fr.wikipedia.org/wiki?curid=15506" title="Goniomètre">
Goniomètre

Un goniomètre est un appareil ou un capteur servant à mesurer les angles.

Le goniomètre a été inventé vers 1780 par le minéralogiste français Arnould Carangeot (1742-1806).

En optique, le goniomètre est utilisé pour déterminer la déviation d'un rayon lumineux par un dispositif optique (par exemple un prisme).

Le goniomètre comporte une partie fixe, sur laquelle est montée une partie mobile portant une lunette de visée. On peut avoir deux configurations :
Le goniomètre comporte en général une règle graduée en degrés, le rapporteur, et éventuellement un vernier pour améliorer la précision.

En radiocristallographie, le goniomètre est la partie du diffractomètre qui sert à déterminer les angles. Les mouvements sont motorisés.

Dans la majeure partie des cas, les angles sont déterminés par les ordres donnés aux moteurs (moteurs pas à pas) : lors de l'initialisation, l'appareil établit son zéro (par rapport à un point de référence, par exemple une encoche sur le goniomètre) ; l'angle correspondant au zéro du moteur est déterminé par une procédure d'alignement.

Dans le cas d'une mesure à haute résolution, il devient très long de stabiliser la position exacte des moteurs (la boucle de rétroaction génère des oscillations qui se réduisent au fur et à mesure). Dans ce cas, il est plus intéressant (gain de temps) de laisser le moteur se placer approximativement, puis de mesurer l'angle (mesure automatique, par exemple à l'aide d'un capteur optique).

Dans le cas le plus général, on a un goniomètre à deux cercles, c'est-à-dire que l'on détermine :
Le terme de « cercle » désigne en fait une motorisation permettant un mouvement circulaire, le terme plus exact serait « montage à deux axes motorisés ».

Dans ce montage Bragg-Brentano, l'échantillon a une orientation fixe par rapport au vecteur de diffraction (bissectrice entre le faisceau incident et le faisceau détecté). On adjoint parfois un dispositif permettant de faire tourner l'échantillon autour de son axe, appelé "spinner", mais ce dispositif n'est pas considéré comme un cercle supplémentaire mais comme une manière de balayer complètement un échantillon supposé homogène (le faisceau a la forme d'un trait et n'éclaire qu'une portion réduite de l'échantillon).

On distingue deux configurations (on suppose ici une mesure en configuration Bragg-Brentano) :

Dans certains cas, on s'intéresse à l'anisotropie de l'échantillon ; c'est par exemple le cas de la texture (orientation cristalline préférentielle), de la mesure des contraintes, ou de la détermination de la structure cristalline à partir d'un monocristal. Le faisceau incident a ici une forme ponctuelle, il éclaire un petit disque sur l'échantillon.

Dans ce cas, il faut pouvoir orienter l'échantillon dans toutes les directions de l'espace, ce qui suppose trois axes de rotation, auquel s'ajoute la position du détecteur ; on a donc quatre axes motorisés, le dispositif est dit à « quatre cercles ».

Dans le cas d'un échantillon polycristallin, le dispositif s'appelle un « berceau d'Euler » "(Euler craddle)", par comparaison aux angles d'Euler. Ce berceau d'Euler peut être centré ou excentré, il peut être ouvert ou fermé ; les berceaux ouverts et excentrés peuvent accueillir des échantillons plus volumineux, mais ils sont plus compliqués à réaliser.

L'échantillon est mis en place sur une platine motorisée ; celle-ci peut bouger selon les trois axes ("x","y","z") pour permettre de positionner le centre de l'échantillon au point de référence. Dans tous les cas, le tube est fixe, et dans la position de référence, le plan de l'échantillon est vertical (le détecteur se déplace selon un cercle horizontal).

Dans le cas d'un échantillon monocristallin, celui-ci est collé sur une « tête d'épingle » orientable.

Dans la photographie ci-contre, le goniomètre est le matériel en blanc à droite: il sert à manipuler par rotation (très précise) ; un microcristal pur d'une molécule dont on veut connaître la structure dans le faisceau de rayon X monochromatique (tube effilé du haut) est placé au bout de l'aiguille au centre.
Une caméra CCD spéciale rayons X (à gauche avec des lettres rouges) recueille numériquement la position et l'intensité des taches de diffractions.

Puisque la position des taches de diffraction est repérée par la caméra, celle-ci n'est pas orientable ; on a donc un goniomètre à trois cercles.
Une caméra vidéo (tube noir en haut à gauche) aide pour un premier positionnement et centrage du cristal dans le faisceau de rayons X.

Ces mesures traitées par ordinateur permettent par transformée de Fourier de reconstituer l'image du cristal et surtout de la molécule de base qui le compose.

Remarque : on a utilisé cet instrument pour illustrer les modèles sciences, physique car les rayons X ont eu un rôle déterminant dans l'évolution des sciences.

La radiogoniométrie permet à un récepteur radio muni d'un goniomètre de repérer la direction (gisement en navigation) d'un émetteur fixe : balise, émetteur illégal ou hostile, ou d'un émetteur mobile : "radiotracking".

Les premiers radiophares pour la navigation maritime ont été mis en place en 1911 à la sortie de la rade de Brest pour ce qui sera plus tard le rail d'Ouessant. Ils sont maintenant obsolètes avec le GPS et ont arrêté d'émettre.

Pour la navigation aérienne, la première balise française ADF date de 1925 à Orly. Elles disparaissent également progressivement.




</doc>
<doc id="15512" url="https://fr.wikipedia.org/wiki?curid=15512" title="Dynastie Chola">
Dynastie Chola

Les Chola sont une dynastie très ancienne du sud de l'Inde, mentionnée dans le "Mahābhārata", et qui a donné son nom à la côte de Coromandel (d'après "Chola mandalam", « le pays des Chola ») au Tamil Nadu. On sait peu de choses des premiers Chola, dont la tradition et la littérature nous ont transmis quelques noms et dates approximatives :


La suite se perd dans la confusion. Puis les Chola reviennent sur le devant de la scène au .



La dynastie entre en décadence et le royaume Chola de nouveau réduit à la zone originelle d'Uraiyur sera absorbé par le royaume de Vijayanâgara au .

Les Chola connaissent leur apogée sous Rajaraja Chola I et Rajendra Choladeva. C'est aussi sous leurs règnes que l'Inde connaît la seule période de puissance maritime de son histoire.

Les Chola ont développé un art caractéristique dans le domaine de l'architecture et du bronze à la cire perdue, ainsi que des fresques dans les temples.



</doc>
<doc id="15513" url="https://fr.wikipedia.org/wiki?curid=15513" title="Axiome">
Axiome

Un axiome (du grec ancien /"axioma", « considéré comme digne, convenable, évident en soi » — lui-même dérivé de ("axios"), « digne ») désigne une proposition indémontrable utilisée comme fondement d’un raisonnement ou d’une théorie mathématique.

Pour Euclide et certains philosophes grecs de l’Antiquité, un axiome était une affirmation qu'ils considéraient comme évidente et qui n'avait nul besoin de preuve. Théophraste définit ainsi l’axiome : c’est une formule qui concerne en partie les choses de même sorte, s’il y a analogie de l’une à l’autre, en partie toutes les choses indistinctement.

En épistémologie (branche de la philosophie des sciences), un axiome est une vérité évidente en soi sur laquelle une autre connaissance peut se reposer, autrement dit peut être construite. Précisons que tous les épistémologues n'admettent pas que les axiomes, dans ce sens du terme, existent. Dans certains courants philosophiques, comme l'objectivisme, le mot "axiome" a une connotation particulière. Un énoncé est axiomatique s'il est impossible de le nier sans se contredire. Exemple : « Il existe une vérité absolue » ou « Le langage existe » sont des axiomes.

En mathématiques, le mot "axiome" désignait une proposition qui est évidente en soi dans la tradition mathématique des "Éléments" d’Euclide. L’axiome est utilisé désormais, en logique mathématique, pour désigner une vérité première, à l'intérieur d'une théorie. L'ensemble des axiomes d'une théorie est appelé axiomatique ou théorie axiomatique. Cette axiomatique doit être non contradictoire ; c'est sa seule contrainte. Cette axiomatique définit la théorie ; ce qui signifie que l'axiome ne peut être remis en cause à l'intérieur de cette théorie, on dit alors que cette théorie est cohérente, ou consistante ou non-contradictoire. Un axiome représente donc plutôt un point de départ dans un système de logique et il peut être choisi arbitrairement. La pertinence d'une théorie dépend de la pertinence de ses axiomes et de son interprétation. En réalité, c'est de la non cohérence de son interprétation que vient la réfutation de la théorie non contradictoire et, par voie de conséquence, de son axiomatique.
L'axiome est donc à la logique mathématique, ce qu'est le postulat à la physique théorique.

Des axiomes servent de base élémentaire pour tout système de logique formelle.
Par exemple, on peut définir une arithmétique simple, comprenant un ensemble de « nombres » et une loi de composition, +, interne à cet ensemble, en posant (en s'inspirant un peu de Peano) :


Beaucoup de théorèmes peuvent être démontrés à partir de ces axiomes.

En utilisant ces axiomes, et en définissant les mots usuels 1, 2, 3, et ainsi de suite pour désigner les successeurs de 0 : succ(0), succ(succ(0)), succ(succ(succ(0))) respectivement, nous pouvons démontrer ce qui suit :

et

Tout résultat que nous pouvons déduire des axiomes n'a pas besoin d'être un axiome. Toute affirmation qui ne peut être déduite des axiomes et dont la négation ne peut pas non plus se déduire de ces mêmes axiomes peut être ajoutée comme axiome pour modifier l'expressivité de la théorie.

Probablement le plus ancien et aussi le plus célèbre système d'axiomes est celui des 5 postulats d'Euclide. Ceux-ci s'avérèrent être assez incomplets, et beaucoup plus d'axiomes sont nécessaires pour caractériser complètement la géométrie d'Euclide (Hilbert en a utilisé 26 dans son axiomatique de la géométrie euclidienne).

Le cinquième postulat (par un point en dehors d'une droite, il passe exactement une parallèle à cette droite) a été suspecté d'être une conséquence des 4 premiers pendant presque deux millénaires. Finalement, le cinquième postulat s'est avéré être indépendant des quatre premiers. En effet, nous pouvons supposer qu'aucune parallèle ne passe par un point situé en dehors d'une droite, ou qu'il existe une unique parallèle, ou encore qu'il en existe une infinité. Chacun de ces choix nous donne différentes formes alternatives de géométrie, dans lesquelles les mesures des angles intérieurs d'un triangle s'ajoutent pour donner une valeur inférieure, égale ou supérieure à la mesure de l'angle formé par une droite (angle plat). Ces géométries sont connues en tant que géométries elliptique, euclidienne et hyperbolique respectivement.
La relativité générale affirme que la masse donne à l'espace une courbure, c'est-à-dire que l'espace physique n'est pas euclidien.

Au, les théorèmes d'incomplétude de Gödel énoncent qu'aucune liste explicite d'axiomes suffisante pour démontrer quelques théorèmes très élémentaires sur les entiers (par exemple l'arithmétique de Robinson) ne peut être à la fois complète (chaque proposition peut être démontrée ou réfutée à l'intérieur du système) et consistante (aucune proposition ne peut être à la fois démontrée et réfutée).

Robert Blanché, "L’Axiomatique" — 1955, éd. P.U.F. coll. Quadrige, 112 p.

 "Metamath" axioms page


</doc>
<doc id="15514" url="https://fr.wikipedia.org/wiki?curid=15514" title="Édouard V">
Édouard V

Édouard V, né le à Westminster et mort probablement en à Londres, est roi d'Angleterre pendant deux mois seulement en 1483. Avant de régner, il est comte de March et de Pembroke, duc de Cornouailles et prince de Galles.

Fils du roi Édouard IV et d'Élisabeth Woodville, il a pour frère Richard de Shrewsbury et pour sœur Élisabeth d'York, épouse du roi Henri VII Tudor.

Son court règne est dominé par l’influence de son oncle Richard, duc de Gloucester, qui lui succède sous le nom de Richard III. Édouard disparaît, ainsi que son jeune frère Richard, après avoir été enfermé (prétendument pour sa sécurité) à la Tour de Londres. On a accusé Richard III d’avoir ordonné leurs meurtres, sans que les contemporains ou les historiens ne puissent déterminer ce qui leur est arrivé.

Édouard V est, avec Mathilde l'Emperesse, Jeanne Grey et Édouard VIII, l’un des monarques anglais ayant régné après 1066 à n’avoir pas été couronné. Si, comme c’est probable, il est mort avant son quinzième anniversaire, il serait le souverain d’Angleterre mort le plus jeune (son petit-neveu, Édouard VI, est mort à quinze ans).

Édouard naît dans le sanctuaire de l’abbaye de Westminster, sanctuaire où sa mère a trouvé refuge pour échapper aux Lancastre qui viennent d'évincer du pouvoir son père, le roi Édouard IV d'Angleterre, pendant la guerre des Deux-Roses. En , après la restauration de son père sur le trône, il est fait prince de Galles et assiste désormais au côté de ses parents aux cérémonies officielles.

Édouard IV conclut une alliance en 1480 avec le duc de Bretagne François II, et tous deux décident de fiancer leurs héritiers, Édouard (10 ans) et Anne (4 ans), promettant de les marier quand ils auraient atteint leur majorité. La Bretagne aurait été l’apanage de leur deuxième né, le premier ayant été prince de Galles. Ces projets s’évanouissent avec la disparition d'Édouard V.

Son père, voulant qu'Édouard apprenne l'art de régner, l'envoie dans la petite ville de Ludlow, près du Pays de Galles. Le prince s'y trouve quand il apprend la mort soudaine du roi. Il hérite du trône le 9 avril 1483, à 12 ans, mais il n'apprend la nouvelle de son avènement que le 14 avril. Son oncle paternel Richard de Gloucester est nommé Lord Protecteur jusqu'à son couronnement qui est prévu pour le 4 mai. Accompagné de son oncle maternel Anthony Woodville, de son demi-frère Richard Grey et du chambellan Thomas Vaughan, Édouard se dirige vers Londres. Le 29 avril, ils sont rejoints par Gloucester, qui fait arrêter Woodville, Grey et Vaughan le lendemain. Gloucester et le duc de Buckingham Henry Stafford escorte Édouard jusqu'à Londres ; Richard est nommé Lord Protecteur le 10 mai, tandis que le couronnement de son neveu est prévu le 22 juin. Pendant ce temps, la mère d'Édouard se réfugie à nouveau à Westminster, avec ses autres enfants. Pour sa propre sécurité, Édouard est installé à la Tour de Londres le 19 mai. Après négociation entre son oncle et sa mère, son frère Richard de Shrewsbury l'y rejoint le 16 juin. Gloucester repousse par la suite la date du couronnement.

L'évêque de Bath et Wells, Robert Stillington, affirme le 22 juin qu'Édouard IV a précédemment contracté une promesse de mariage secrète avec Éléonore Talbot en 1461, avant de convoler trois ans plus tard en 1464, cette fois-ci en justes noces, avec Élisabeth Woodville. Or, au moment du mariage, Éléonore est encore vivante. Le conseil de régence conclut à un cas de bigamie, invalidant le second mariage et la légitimité de tous les enfants nés de celui-ci. Édouard V et Shrewsbury sont donc déclarés illégitimes et révoqués de la succession au trône le . Gloucester s'empare le lendemain du pouvoir sous le nom de Richard III.

Les jeunes princes Édouard et Richard n’apparaissent plus en public après avoir été emmenés à la Tour et déchus de leurs légitimité. Leur destin reste un des grands mystères de l’histoire, et de nombreux livres ont été écrits sur le sujet. La thèse la plus probable est qu’ils ont été assassinés ; les principaux bénéficiaires de leur disparition sont leur oncle, le roi Richard, et Henri Tudor, prétendant lancastrien qui monte sur le trône sous le nom d'Henri VII en 1485, après avoir battu Richard et rallié la famille des disparus.

Un manuscrit rédigé en 1483 par l'ecclésiastique italien Dominique Mancini, qui a assisté à sa prise de pouvoir controversée, décrit les conditions du renversement et de l'emprisonnement du jeune roi : en juin 1483, des hommes en armes du futur Richard III tiennent Londres, la capitale. L'oncle du roi fait éliminer William Hastings, un ami loyal, fidèle parmi les fidèles de la Maison d'York car il sait qu'il n'acceptera jamais la destitution du jeune Édouard V. Il va donc l'éliminer en le convoquant avec d'autres à la Tour de Londres. Le sort du jeune Édouard V et de son petit frère Richard de Shrewsbury, tous deux enfermés à la Tour de Londres est scellé. , explique Dominique Mancini. .

En 1502, un chevalier anglais du nom de James Tyrrell, fidèle lieutenant de Richard III, confessa les avoir étouffés sous des matelas. Mais ses aveux, obtenus sous la torture, sont sujets à caution pour les historiens. 

Si les princes ont été tués, le secret a été bien gardé ; à l’inverse, on n’a aucune preuve de leur survie ou de leur exil du pays. Quand, en 1495, Perkin Warbeck affirme être le prince Richard, William Stanley (le frère cadet du beau-père du roi Henri VII, Thomas Stanley) qui, en dépit de ses sympathies yorkistes s’était opposé à Richard III en faveur d’Henri pendant la bataille de Bosworth, affirme que, si le jeune homme était vraiment le prince, il ne combattrait pas contre lui, démontrant ainsi que certains Yorkistes n’avaient pas abandonné tout espoir d’une hypothétique survie d’un des princes.

En 1674, des ouvriers qui travaillent à la Tour de Londres trouvent une boîte qui contient deux petits squelettes humains. Ils les jettent aux ordures, mais quelques jours ou quelques semaines après, quelqu’un s'avise qu'il peut s'agir des restes des princes, aussi les rassemble-t-on dans une urne, enterrée à Westminster sur l’ordre de Charles II. 

En 1933, les os sont examinés puis replacés dans leur tombe sous l’abbaye. Les experts ne s’accordent pas sur l’âge que les enfants pouvaient avoir, ni si c’étaient des garçons ou des filles. Il apparaît en effet qu'un des squelettes est plus gros que l’autre, et beaucoup d’os manquent, y compris une partie de la mâchoire du plus petit et les dents du plus grand. L’Église d'Angleterre refuse encore aujourd'hui les analyses ADN.


</doc>
<doc id="15517" url="https://fr.wikipedia.org/wiki?curid=15517" title="Musée de Cluny">
Musée de Cluny

Le musée de Cluny, de son nom officiel Musée national du Moyen Âge - Thermes et hôtel de Cluny, est situé dans le de Paris, au cœur du Quartier latin, dans un hôtel particulier du : l'hôtel de Cluny. Il possède l'une des plus importantes collections mondiales d'objets et d'œuvres d'art de l'époque médiévale et les thermes de Cluny, qui y sont contigus, en font également partie.

Les bâtiments accueillaient les abbés de l'ordre de Cluny en Bourgogne dès le . 

À la fin du , le bâtiment construit par Jean III de Bourbon a été agrandi par Jacques d'Amboise, abbé de Cluny (1485-1510). Les armes d'Amboise, « trois pals alternés d'or et de gueules » ornent les lucarnes ouvragées de la façade.

L'hôtel accueille les abbés de Cluny et quelques dignitaires importants.

La jeune Marie d'Angleterre y est enfermée pendant 40 jours en 1515 pour s'assurer qu'elle ne porte pas d'héritier à la mort de son mari le roi Louis XII de France, ainsi la couronne passe à son cousin, le futur roi François. Jacques V d'Écosse est également dans l'hôtel de Cluny en 1537 pour son mariage stratégique avec la fille de François, Madeleine de France. 

À partir du , l'hôtel sert de nonciature aux légats du pape. Le nonce y réside alors avec sa maison qui se compose d'une vingtaine de personnes dont deux secrétaires.

Au , Nicolas-Léger Moutard, l'imprimeur-libraire de la reine de 1774 à 1792, installe ses presses dans la chapelle, et son adresse est rue des Mathurins, Hôtel de Cluni. 

À la Révolution, l'hôtel est vendu comme bien national et subit des transformations et des agressions jusqu'à son acquisition par l'État en 1843.

L'hôtel de Cluny est partagé entre plusieurs propriétaires ou locataires particuliers comme les astronomes Joseph-Nicolas Delisle (1688-1768) et ses élèves Joseph Jérôme Lefrançois de Lalande (1732-1807) et Charles Messier (1730-1817) qui transforment la tour en observatoire. 

En 1833, Alexandre Du Sommerard conseiller-maître à la Cour des comptes et amateur passionné par le Moyen Âge s'y installe, et loue quelques pièces à un imprimeur pour y organiser sa collection d'objets.


En 1843, la collection est rachetée par l'État, qui nomme son fils Edmond Du Sommerard premier directeur du Musée des Thermes et de l'Hôtel de Cluny. Les bâtiments sont restaurés par l'architecte Albert Lenoir, fils d'Alexandre Lenoir, qui confie au ferronnier d'art Pierre François Marie Boulanger la réalisation des pentures et serrures des portails ainsi que deux bouteroues en fer forgé (aujourd'hui disparues). L'hôtel est classé monument historique en 1846, et les thermes gallo-romains avec les collections lapidaires ont été cédés à l’État par la ville de Paris, le 1er janvier 1843. L'hôtel est classé en 1846 et les thermes en 1862.

L'hôtel est aujourd'hui le plus ancien témoin de l'architecture des hôtels particuliers construits à Paris entre cour et jardin. Il est de style gothique flamboyant selon un plan en U, d'un corps de logis prolongé par deux petites ailes en équerre délimitant une cour intérieure trapézoïdale.

Le musée accroît ses collections et la réorganisation de sa muséographie permet la création du musée national de la Renaissance à Écouen en 1977. L'opportunité sera également offerte aux autres musées et châteaux d'enrichir leurs séries par le moyen de dépôts.

La vocation de l'établissement est confirmé en 1992 par sa nouvelle appellation de Musée national du Moyen Âge.
Un projet de rénovation du musée a été confié à l'architecte Bernard Desmoulin, désigné en 2014 parmi 5 finalistes. Il permettra de doter le musée de l’ensemble des équipements nécessaires à un musée moderne en améliorant l'accueil et l'accessibilité du public ainsi que le parcours muséographique ; tandis que les maçonneries et enduits des thermes gallo-romains seront restaurés par l'architecte en chef des monuments historiques Paul Barnoud. Les travaux d'un montant total de 21,5 millions d'euros, entrepris en mars 2016 pour 2 ans, prévoient une extension de sur une emprise de , appuyée sur le bâtiment du de Paul Boeswillwald et accessible par une passerelle surplombant les vestiges antiques, qui abritera l’accueil-billetterie, une librairie-boutique, des vestiaires et des sanitaires. Le musée sera également pourvu d'un espace pédagogique, d'équipements de régie des œuvres et d'une salle polyvalente de présentations temporaires et sa muséographie sera entièrement repensée afin d’offrir un parcours de visite chronologique et thématique plus cohérent.

Le musée s'étend sur (dont d'exposition). Il rassemble quelque et objets (dont sont exposés) datant d'une période allant de la Gaule romaine jusqu'au et embrassant une aire géographique qui comprend l'Europe mais aussi l'Orient byzantin et musulman ainsi que le Maghreb.

Consacré au Moyen Âge, le musée abrite néanmoins de nombreuses sculptures antérieures à cette période. Il conserve notamment plusieurs œuvres témoignant de l'histoire antique de Lutèce. Le plus célèbre exemple en est le Pilier des Nautes, plus ancien monument daté de Paris. Offert par les bateliers de la ville (les nautes) à l'empereur Tibère (14-37), il a été découvert sous le chœur de Notre-Dame de Paris au . Un autre pilier monumental, dit pilier de Saint-Landry, découvert sur l'île de la Cité au , a été sculpté au . D'autres éléments antiques sont sans lien avec l'histoire parisienne : ainsi d'une statue achetée par le musée au comme une statue de Julien d'origine parisienne, mais en réalité représentant un prêtre de Sérapis et produite en Italie sous l'empereur Hadrien. S'y ajoute une paire de têtes de lions en cristal de roche, sculptées vers la fin de la période antique, qui ornaient peut-être un trône impérial ou consulaire. Enfin, quatre chapiteaux corinthiens produits entre le et le proviendraient des combles de l'abbatiale de Saint-Denis. 

A ces sculptures antiques s'ajoutent plusieurs éléments d'ivoire tardo-antiques ou protobyzantins : un feuillet de diptyque romain du , le diptyque des Nicomaque et des Symmaque, mais aussi le célèbre groupe d'Ariane entourée par un satyre et des putti, sans doute originaire de Byzance au , et un feuillet de diptyque consulaire d'Aréobindus, produit à Constantinople en 506. S'y est ajouté en 2014 l'ivoire dit de Trébizonde, une plaque issue d'un feuillet de diptyque représentant le Christ trônant entre les apôtres Pierre et Paul, également d'origine constantinopolitaine et produit au . Enfin, le musée de Cluny possède un coffret byzantin à scènes mythologiques, produit vers l'an mil, à l'époque où les empereurs de la dynastie macédonienne règnent à Constantinople.

L'ivoire occidental du haut Moyen Âge est représenté notamment par une plaque de reliure carolingienne représentant un apôtre et par une plaque d'inspiration byzantine produite dans l'empire germanique en 982-983, représentant le Christ couronnant l'empereur Otton II et son épouse l'impératrice Théophano. 

La collection de sculptures romanes du musée national du Moyen Âge comprend également plusieurs œuvres monumentales liées à l'histoire de Paris. Les éléments les plus importants sont une série de douze chapiteaux provenant de l'abbatiale de Saint-Germain des Prés, sculptés au début du , ainsi que quatre chapiteaux provenant de l'ancienne église Sainte-Geneviève de Paris, réalisés vers 1100-1110. D'autres objets témoignent de l'élaboration de la sculpture protogothique en Île-de-France vers le milieu du : trois têtes de statues-colonnes de la façade occidentale de Saint-Denis, représentant la reine de Saba, Moïse et un prophète, produites vers 1137-1140, ainsi qu'une colonnette à décor de rinceaux habités provenant du même portail ; un chapiteau double provenant du cloître de cette même abbaye, sculpté vers 1140-1145 et représentant deux sirènes-oiseaux affrontées ; enfin deux statues-colonnes provenant du portail Sainte-Anne de la cathédrale Notre-Dame de Paris, créés autour de 1150, représentant saint Pierre et saint Marcel.

Mais les collections de sculpture romane du musée de Cluny proviennent également d'autres régions et pays. La Catalogne est bien représentée, notamment par une série de huit chapiteaux provenant de l'abbaye de Sant Pere de Rodes, dont un qui représente l'histoire de Noé et un autre qui représente l'histoire d'Abraham, et par une statue de sainte femme en bois, produite dans la vallée de Boï vers 1120-1140. Le musée abrite également un Christ auvergnat en bois de la seconde moitié du .

A ces sculptures monumentales s'ajoutent de petits objets sculptés sur ivoire d'éléphant ou de morse, dans diverses régions d'Europe : une reine d'un jeu d'échecs de la fin du ; une plaque représentant les douze tribus d'Israël sous les traits des fils de Jacob, acquise en 2012 ; une défense d'éléphant sculptée en Sicile à la fin du représentant l'Ascension, et un crosseron en ivoire de morse à décor de rinceaux habités du milieu du . 

Comme pour les époques précédentes, une part importante des collections des XIIIe et XIVe siècles du musée de Cluny est composée d'objets originaires de Paris ou de l'Île-de-France. De Notre-Dame de Paris proviennent ainsi un élément du linteau du portail central, représentant la Résurrection des Morts, produit au cours du deuxième quart du , ainsi qu'une statue d'Adam qui ornait autrefois le portail du transept sud de la cathédrale, sculpté dans le troisième quart du . Autre bâtiment important, la Sainte-Chapelle a donné au musée quatre des apôtres du collège apostolique qui ornaient la chapelle haute, dont saint Jean. Ces statues ont été créées entre 1243 et 1248, pendant la construction de l'édifice. D'autres apôtres, réalisés dans les années 1320, proviennent quant à eux de l'église de l'hôpital Saint-Jacques aux Pèlerins. Parmi les édifices d'Île-de-France dont des éléments sont aujourd'hui conservés au musée, il faut citer la priorale Saint-Louis de Poissy, avec trois statues d'anges portant les insignes de la Passion du Christ, et celle de Pierre d'Alençon, fils de Louis IX. 

La Picardie, quant à elle, a donné au musée de Cluny un retable représentant diverses scènes du Nouveau Testament et de la vie de saint Germer, provenant de l'abbaye Saint-Germer de Fly et sculpté dans les années 1260.

Plusieurs sculptures de cette période proviennent d'Italie : ainsi, deux statues de la Vierge et de saint Jean, des années 1220-1230, proviennent de la cathédrale de Prato, où ils formaient autrefois un groupe de Calvaire avec une statue de Christ ; un ange d'Annonciation sculpté par le florentin Nino Pisano dans le troisième quart du ; et un buste-reliquaire de sainte Mabille, une des légendaires onze mille vierges qui accompagnaient sainte Ursule, sculpté à Sienne à la même époque. 

La sculpture de petite taille est également représentée, surtout par des ivoires nombreux. Outre des diptyques ou triptyques à décor religieux, comme le triptyque de Saint-Sulpice du Tarn ou la valve de miroir dite de l'Assemblée, le musée de Cluny abrite des objets à décor profane de production parisienne, comme un coffret à scènes courtoises figurant le siège du château d'amour, produit dans le premier quart du , ou une valve de boîte à miroir représentant Tristan et Iseut, sortie des ateliers parisiens du second quart du .

Des sculptures romanes et gothiques, en pierre ou en bois, du au début du s, provenant par exemple de la cathédrale Notre-Dame de Paris mais aussi d'Allemagne, des Flandres d'Espagne ou d'Italie, ainsi que d'autres éléments architecturaux (chapiteaux romans et gothiques, portail de la chapelle de la Vierge de Saint-Germain-des-Prés).

Le musée de Cluny possède la plus riche collection de vitraux en France (plus de 230 panneaux, médaillons ou fragments de vitraux couvrant une période du XII° jusqu'au début du ). De 2000 à la fin de l'année 2004, grâce au soutien de la Fondation d'entreprise Gaz de France, cette collection a bénéficié d'une exceptionnelle campagne de restauration.
Le musée de Cluny abrite notamment un ensemble important de vitraux issus de la Sainte Chapelle.

Le musée national du Moyen Âge a la chance de posséder l'un des plus beaux rassemblements d'œuvres d'orfèvrerie et d'émaillerie du Moyen Age. Ces objets, en or, en argent, ou encore en cuivre, souvent émaillés ou rehaussés de pierreries, formaient le trésor de riches abbayes et des grands princes de l'Occident.

La collection des ivoires du musée est avec celle du musée du Louvre l'une des deux principales collections parisiennes. Elle s'étend de la fin de l'Antiquité à la fin du Moyen Âge. Elle comprend des objets religieux mais aussi des objets civils : coffrets, miroirs, peignes, gravoirs. Plusieurs exemplaires sont du , mais le plus grand nombre appartient au .

Le musée de Cluny conserve une importante collection de tapisseries à caractère profane et religieux. Parmi les pièces majeures de ses collections se trouvent l'emblématique tapisserie de "La Dame à la licorne", la "Légende de saint Étienne" ou bien la tapisserie de "La Vie seigneuriale".


En 2000, un jardin d'inspiration médiévale a été aménagé le long du boulevard Saint-Germain.
Elisabeth Taburet-Delahaye, conservateur général du patrimoine, est directrice du musée de Cluny depuis novembre 2005.

En 2006, le mécénat de CNP Assurances a permis l'acquisition d'une châsse limousine de l'Adoration des mages, classée bien d'intérêt patrimonial majeur. L'année suivante, la générosité de Groupama SA a permis l'acquisition d'un coffret gothique d'ivoire également classé bien d'intérêt patrimonial majeur.
Mr Michel David-Weill a été le principal mécène du jardin d'inspiration médiévale qui a ouvert ses portes en 2000.

Le musée accueille en moyenne deux expositions temporaires par an. Les chiffres de fréquentation prennent en compte les collections permanentes et les expositions.


Entre le janvier et le 30 juin 2008, l'établissement a participé à l'expérimentation du ministère de la Culture quant à la gratuité des expositions permanentes de certains musées français.

La société des Amis du musée a été créée en 1992 et soutient les activités du musée, les opérations de mécénat et possède une infolettre: "Millefleurs". Elle compte 600 adhérents, en 2011.

Le musée de Cluny est membre de la Fédération des sites clunisiens.


Chaque premier dimanche du mois, le musée de Cluny est gratuit pour tous. Certains premiers dimanches du mois, quatre à six fois dans l'année, de 13h30 à 17h30, des étudiants de l’École du Louvre, des universités et des écoles spécialisées accueillent les visiteurs et commentent des œuvres du musée.

Ces après-midis dominicaux placés sous le signe de la jeunesse et de la médiation existent depuis plusieurs années et recueillent un franc succès : une moyenne de visiteurs se déplacent et profitent du travail et du dynamisme de ces médiateurs en herbe, futurs professionnels et parfois déjà spécialistes.

Cette opération réunit vingt à trente étudiants, qui à l'issue d'un travail de recherche documentaire s'initient à l'art de la médiation. Postés dans les salles, seuls ou en binôme, ces jeunes vont au devant des visiteurs pour leur livrer les clés de lecture des œuvres phares, parfois atypiques et souvent mal connues.

En 2012, à l'occasion d'un partenariat avec l'université de Paris-Dauphine, vingt étudiants ont été formés par les conservateurs du musée afin de présenter les cinq thèmes suivants :

Plus tôt dans l'année, dans le cadre des Journées européennes des Métiers d'Art, tandis que vingt autres étudiants médiateurs évoquaient les collections sous l'angle des techniques de création, six élèves de l'ENSAAMA (l’École nationale supérieure des arts appliqués et métiers d'art à Paris), futurs peintres-verriers, reconstituaient un atelier vitrail dans la cour du musée. À partir d'une œuvre de la Sainte-Chapelle exposée dans une salle du musée, les élèves expliquaient les différentes étapes de fabrication du vitrail (du calibrage au montage en passant par la peinture).
"Un dimanche avec des étudiants" donne aux visiteurs l'occasion de venir librement au musée et de profiter de présentations sympathiques et didactiques.




Ce site est desservi par la station de métro Cluny - La Sorbonne.


</doc>
<doc id="15518" url="https://fr.wikipedia.org/wiki?curid=15518" title="Verrières-le-Buisson">
Verrières-le-Buisson

Verrières-le-Buisson ( ) est une commune française située à quatorze kilomètres au sud-ouest de Paris dans le département de l’Essonne en région Île-de-France.
Située à la frontière avec les Hauts-de-Seine et la première couronne parisienne dont elle est proche sociologiquement, Verrières-le-Buisson qui était déjà plébiscitée dès le par les rois de France pour leurs chasses en forêt est aujourd’hui encore connue des Parisiens pour sa forêt de Verrières, poumon vert aux portes de la capitale et sa vallée de la Bièvre au caractère rural. Elle est aussi célèbre dans le milieu de l’horticulture et la botanique pour avoir été le site choisi par la famille Vilmorin, fondateur de la compagnie Vilmorin de graines. Cette riche famille a laissé à la ville son arboretum, devenu réserve naturelle régionale, qui lui permet aujourd’hui encore, malgré une urbanisation importante durant les années 1960 de revendiquer le titre de « Ville Arboretum ». Riche de six châteaux et demeures et de nombreux lotissements pavillonnaires, elle cultive son côté « village » en pleine agglomération parisienne.

Ses habitants sont appelés les "Verriérois".

Verrières-le-Buisson est située en Île-de-France, à l’extrême nord du département de l’Essonne qui est totalement intégré à l’agglomération parisienne, au cœur de ce qui était l’ancien pays et aujourd’hui la région naturelle du Hurepoix. Son territoire prend approximativement la forme d’un triangle dont la pointe serait orientée vers l’est et la base à l’ouest, il occupe une superficie totale de neuf cent quatre-vingt-onze hectares, dont 54 % sont encore considérés comme espace rural, couvert par l’importante forêt de Verrières qui occupe cinq cent cinquante hectares gérés par l’Office national des forêts. L’Institut national de l'information géographique et forestière donne les coordonnées géographiques 48°44'34" Nord et 02°16'08" Est au point central de ce territoire. L’espace urbain est concentré sur la moitié est du territoire et séparé d’écarts implantés au sud en bordure de rivière. La commune est ainsi implantée sur les rives de trois cours d’eau qui forment des frontières naturelles, la Bièvre au sud et à l’est, la Sygrie à l’ouest et le ruisseau des Godets au nord-est, tous deux affluents de la rivière. Elle est aussi bordée par deux axes routiers majeurs, l’autoroute A86 au nord et la route nationale 118 à l’ouest, ainsi que par l’ancienne ligne de Sceaux, aujourd’hui empruntée par la ligne B du RER d'Île-de-France à l’est et la ligne de Grande Ceinture empruntée par la ligne C du RER d'Île-de-France au sud. Ces deux lignes ferroviaires sont accessibles dans la commune par la gare de Massy - Verrières et la gare d'Igny, situées chacune dans les communes voisines. En souterrain, l’extrême est du territoire est traversé par la tranchée de la LGV Atlantique, aujourd’hui recouverte par la coulée verte du sud parisien. Positionnée sur le versant nord de la vallée de la Bièvre et sur l’extrémité sud du plateau de Villacoublay, la commune occupe un terrain relativement pentu dont le point culminant à cent soixante-quatorze mètres d’altitude est le deuxième plus haut du département. L’urbanisation et le lotissement relativement récents de la commune ont organisé le territoire en plusieurs quartiers pavillonnaires et résidentiels reprenant les noms des anciennes propriétés ou lieux-dits locaux.

La commune est aujourd’hui située à quatorze kilomètres au sud-ouest de Paris-Notre-Dame, point zéro des routes de France, dix-sept kilomètres au nord-ouest du chef-lieu départemental Évry, quatre kilomètres au nord-est de Palaiseau, vingt et un kilomètres au nord-ouest de Corbeil-Essonnes, trente-cinq kilomètres au nord-est d’Étampes, onze kilomètres au nord de Montlhéry, dix-sept kilomètres au nord d’Arpajon, vingt-neuf kilomètres au nord-ouest de La Ferté-Alais, trente kilomètres au nord-est de Dourdan et quarante et un kilomètres au nord-ouest de Milly-la-Forêt. Elle est aussi située à seulement deux kilomètres de la sous-préfecture des Hauts-de-Seine Antony et douze kilomètres au sud-est du chef-lieu des Yvelines Versailles.

Le territoire de Verrières-le-Buisson s’étend dans un triangle formé par trois cours d’eau qui marquent approximativement les limites communales. 

Au sud coule la Bièvre, qui comprend deux bras :



À l’extrême ouest du territoire, à quelques dizaines de mètres de la frontière, coule la Sygrie, affluent de la Bièvre, qui descend depuis le plateau de Villacoublay à travers la forêt de Verrières, elle alimente le petit lac de l’Abbaye aux Bois placé à l’intersection des frontières entre Verrières-le-Buisson, Bièvres et Châtenay-Malabry. 

Au nord-est, la frontière avec Antony est matérialisée par le cours du ru des Godets, affluent de la rive gauche de la Bièvre qui rejoint la rivière dans le parc Heller. Il alimente un petit étang dans le quartier de la Noisette. Dans le quartier du parc subsiste un lac artificiel d’agrément. Dans la forêt, quatre petites mares sont disposées en bordure des allées tracées au , dont la mare à Chalot sur la route de la Châtaigneraie, d’autres mares recueillent les eaux de ruissellement à Vaupéreux, un petit étang est alimenté par la rivière au lieu-dit Le Salvert.

Verrières-le-Buisson est implantée à l’extrémité sud-est du plateau de Villacoublay et sur le versant nord de la vallée de la Bièvre qui y forme une boucle de l’ouest au nord-est. Le territoire communal s’étage entre une altitude maximale de cent soixante-quatorze mètres au nord-ouest au carrefour de l’Obélisque dans la forêt et un point bas à cinquante-deux mètres à l’extrême est sur le cours de la rivière dans le parc du Breuil. Le territoire s’étage vers l’est en pente relativement douce puisque trois kilomètres séparent le point culminant du point le plus bas. La déclivité est plus relativement importante sur le versant sud, resté boisé, puisque le point bas en bord de Bièvre à Vaupéreux est situé à soixante-seize mètres d’altitude, soit cent mètres plus bas que l’obélisque située à seulement deux kilomètres de distance. Caractéristique du bassin parisien, le sous-sol est composé de couches successives de sable de Fontainebleau et de meulière, de marne gypseuse reposant sur du calcaire, strates mises au jour lors des travaux de creusement de la tranchée de la LGV Atlantique.

Verrières-le-Buisson dispose d’un territoire relativement étendu, à la limite de deux départements. Du sud-ouest au sud-est, le cours de la Bièvre matérialise la frontière avec Igny puis Massy, elle se poursuit à l’est avec Antony, limite matérialisée par la rue Marius Hue puis en suivant le cours du ruisseau des Godets à travers le parc de la Noisette pour rejoindre l’avenue d’Estienne d’Orves. Au nord se trouve la commune de Châtenay-Malabry, séparée par la rue des Grillons et la rue Jean-Baptiste Clément jusqu’à suivre la lisière de la forêt par le chemin de la Bordure, le chemin de la Porte des Bois, et la route des Vaches. Au nord-ouest et à l’ouest se trouve la commune de Bièvres, séparée par le tracé de la route nationale 118.

Verrières-le-Buisson, située en Île-de-France, bénéficie d’un climat océanique dégradé. En moyenne annuelle, la température relevée s’établit à avec une moyenne maximale de et une moyenne minimale de . La température réelle maximale intervient en juillet avec et la réelle minimale en janvier avec . Elle se distingue de Paris par un écart constant négatif de deux degrés celsius, qui s’explique notamment par la différence de densité urbaine entre la capitale et sa banlieue. L’influence du climat continental engendre des records extrêmes avec relevés le et enregistrés le . L’ensoleillement est comparable aux régions du nord de la Loire avec heures en moyenne sur l’année, et les précipitations sont également réparties avec une moyenne de cinquante millimètres par mois et un total de de pluie sur l’année. Le record de précipitations a été établi le avec tombés en vingt-quatre heures.

Le territoire de Verrières-le-Buisson est pour sa majeure partie occupé par la vaste forêt domaniale, préservée des infrastructures. La commune est cependant correctement desservie, de façon indirecte par les réseaux de transport. Au nord, l’autoroute A86 fait une courte incursion, la commune est ainsi accessible par l'échangeur numéro 28 situé dans la commune voisine de Châtenay-Malabry. À l’ouest, suivant le val de la Sygrie, la route nationale 118 fait elle aussi un bref passage sur le territoire communal, l’échangeur 6a situé à Bièvres dessert alors le hameau de Vaupéreux. Au sud, la vallée de la Bièvre accueille le tracé de la route départementale 60 qui marque, comme la rivière, la frontière avec Massy.

Les infrastructures ferroviaires utilisent aussi le relief pour se frayer un passage. Ainsi, le territoire est traversé dans sa partie est, en souterrain par la LGV Atlantique avant son arrivée depuis Paris en gare de Massy TGV. Hors du territoire, la ligne B du RER d'Île-de-France, qui emprunte la ligne de Sceaux, passe à proximité du Parc du Breuil et la ligne C, qui emprunte la ligne de Grande Ceinture, forme une boucle venant de Bièvres et se dirigeant vers Antony. Implantée à Massy, la gare de Massy - Verrières est dédiée à la desserte du centre-ville tandis qu’à l’ouest, la gare d'Igny est utilisée par les habitants des hameaux d’Amblainvilliers et Vaupéreux.

Les réseaux d’autobus complètent l’offre de transport en commun avec cinq arrêts sur la ligne Noctilien N63 assurant la continuité de service nocturne du réseau RER, neuf arrêts sur la ligne 196 du réseau Ratp et onze stations sur la ligne de bus RATP 294, la ligne 8 du réseau de bus Paladin intercommunal et quatre arrêts sur la ligne Vélizy-Antony du réseau Phébus.

La commune est en outre implantée à seulement neuf kilomètres à l’ouest de l’aéroport Paris-Orly et onze kilomètres à l’est de l’aéroport de Toussus-le-Noble dédié à l’aviation légère et d’affaires. Elle est enfin située à trente-six kilomètres au sud-ouest de l’aéroport Paris-Charles-de-Gaulle.

La commune de Verrières-le-Buisson est composée de deux espaces distincts d’habitat, le bourg à l’est et l’écart au sud-ouest, constitué des hameaux d’Amblainvilliers, Le Salvert, Marienthal et Vaupéreux. Les quartiers créés par les lotissements successifs empruntent pour la plupart le nom des anciennes propriétés ou lieux-dits avec d’ouest en est : les Rinsolles, le Moulin de Grais, le Trésor, le Moulin Migneaux, les Dauphines, les Cœurs, le Parc, les Graviers, la Ferme-Saint-Fiacre, la Noisette et le Tombeau de Molé. Les résidences ont suivi le même principe avec la dénomination du Clos de Verrières en référence au parc du château de la famille d'Estienne d'Orves, le Parc occupant l’ancienne propriété des Cambacérès. L’ancienne caserne du bois de Verrières, occupée par le centre national de la recherche scientifique est aujourd’hui une sorte d’enclave urbanisée dans le massif forestier. L’Insee découpe la commune en neuf îlots regroupés pour l'information statistique soit Morte rivière-les Prés Bouchards, les Pierres beurrés, Hôtel de Ville, la Tournelle-Clos de Verrières, les Gros Chênes-les Godets-le Grand Clos, les résidences de la Poste et du Bois, les Prés hauts, la zac de Vaupépins et le Bois de Verrières-Vaupéreux.

Le nom fut cité une première fois au dans un acte de propriété de l’abbaye de Saint-Germain-des-Prés. "Verdrariæ" au siècle, "Vedzariæ" en 1027, le nom évolua vers "Vitreriæ" au siècle, "Verrarias" en 1236, "Voerrières" au début du pour trouver sa forme actuelle au .

En 1793, la commune fut créée sous le simple nom de Verrieres, l’ajout de l’accent grave et l’adjonction de « le-Buisson » intervint en 1801 en référence à l’importante forêt communale, conformément à la première mention faite au temps de Louis XIV.

L’hypothèse qui rapprocherait le nom de la commune d’une activité d’artisanat verrier local est peu probable puisqu’aucune trace ou notoriété ne subsiste.

L’étymologie du nom de la commune remonte très certainement à la présence dès le bas Moyen Âge d’une "villa rustica" sur le territoire de l’actuel centre-ville appelée "Villa Vedrarias", probablement du nom de son fondateur.

La découverte dans le bois de Verrières de vestiges d’ateliers du Paléolithique et du Néolithique confirme avec certitude la présence humaine sur le territoire dès cette époque. Plus à l’est, à la frontière avec Bièvres en bordure de la Sygrie furent découverts les restes d’une "villa rustica" gallo-romaine.

En 543, le roi Childebert fit don de la "Villa Vedrarias" à la nouvelle abbaye de Saint-Germain-des-Prés.

La première mention écrite de Verrières-le-Buisson daterait de l’an 806. Une "Villa Vedrarias" était alors attachée à la seigneurie d’Antony, dont le domaine relevait de l’abbaye de Saint-Germain-des-Prés. Cent cinquante-six ménages vivaient sur le terroir dont trois cents hectares étaient des terres labourables, quarante hectares étaient considérés comme des prés, et trente-cinq hectares étaient plantés de vignes. Les textes du Moyen Âge mentionnent trois moulins sur la Bièvre. De l’amont de la rivière à son aval, ces moulins étaient aux lieux-dits d’Amblainvilliers, de Grès (Grais) et de Migneaux.

Verrières-le-Buisson dépendit d’Antony jusqu’à la fin du : en 1177 elle fut érigée en paroisse par le pape Alexandre III à la suite de l’édification de son église, placée sous le patronage de Sainte-Anne. L’emprise des moines était totale sur les moindres faits et gestes des Verriérois. Cependant en 1248, Thomas de Mauléon, abbé de Saint-Germain, affranchit du servage les habitants de son domaine d’Antony et de Verrières-le-Buisson en échange d’un lourd tribut.

L’histoire du village de Verrières-le-Buisson suivit les aléas de l’histoire de l’Île-de-France. La guerre de Cent Ans lui valut plusieurs pillages et destructions en 1358 lorsqu’elle fut occupée par les Anglais, 1411 et 1417. En 1358, Amblainvillers devait être un lieu très important. En effet en octobre 1358 les garnisons anglaises, qui se trouvaient autour de Paris, allèrent, disent les chroniqueurs de Saint-Denis, . Paris envoya des troupes pour la reprendre, mais ce fut sans succès. Elle fut par la suite achetée par les Anglais et abattue. En 1360, le roi Jean le Bon fit démanteler la place forte de Massy-Verrières. Les guerres de religion occasionnèrent les mêmes méfaits. En 1562 l’église fut incendiée par les troupes de Condé.

La forêt, mentionnée dès les origines de Verrières-le-Buisson, était aussi en grande partie propriété de l’abbaye. En 1630, Louis XIII y fit percer deux routes, l’une d’ouest en est de Villacoublay à Verrières-le-Buisson et l’autre du nord au sud, de Châtenay-Malabry à Amblainvilliers. Elle séduisit aussi Louis XIV qui s’y rendait pour la chasse. Il en fit l’acquisition. En 1682, elle rejoignit le domaine royal et demeure aujourd’hui forêt domaniale.

Un dénombrement des habitants de la paroisse effectué en 1725 recensait à Verrières-le-Buisson cent cinquante-trois feux, soit environ six-cent quatre-vingt-dix habitants. En 1790, le nombre de ceux-ci était de deux cent deux feux, et de neuf cent treize habitants. Trente-deux d’entre eux signèrent en 1789 le cahier des doléances, plaintes et remontrances des habitants de la paroisse de Verrières-le-Buisson. Ce cahier, pour sa partie locale, listait quelques griefs et demandes, tels pour éviter les dégradations des animaux sur les récoltes, la suppression des barrières d’octroi grevant la circulation entre Verrières-le-Buisson et la route de Paris à Orléans.

En 1815, à la tête de la cavalerie, le général Exelmans fit mouvement en bordure du bois de Verrières contre les troupes alliées de la Septième Coalition qui menaçaient Paris et sortit vainqueur de l'affrontement le .

En 1802, la collection de pommes de terre d’Antoine Parmentier fut transportée chez son ami Philippe de Vilmorin. En 1815 aussi eut lieu le premier achat de terres agricoles par l’entreprise grainetière Vilmorin-Andrieux. Le domaine s’agrandit et la famille Lévêque de Vilmorin s’installa à Verrières-le-Buisson. Aux bâtiments résidentiels qu’elle fit construire, s’ajoutèrent de grands édifices d’exploitation, dont l’horloge réglait le travail quotidien des ouvriers agricoles et des employés des services d’expérimentation. La société Vilmorin-Andrieux fut, jusqu’aux années 1950 le plus important employeur local. La famille consolida son statut social par la prise de responsabilités au sein de la commune : trois maires de Verrières, en sont issus. Durant la première moitié du vingtième siècle les terrains « Vilmorin », des champs d’exploitation et d’expérimentation formèrent frontière entre les proches communes du département de la Seine (Châtenay-Malabry, Antony) et préserva le bourg rural de l’urbanisation. Ces terrains furent vendus en 1964.

En 1821, l’église bénéficia de nombreux travaux de réfection, puis en 1857, le cimetière fut déplacé. Un autre événement d’importance intervint en 1854. Le chemin de fer de Paris à Sceaux fut prolongé entre Bourg-la-Reine et Orsay. Originellement appelée gare de Massy, la station qui desservait Verrières-le-Buisson devint gare de Massy-Verrières en 1900. La gare des voyageurs jouxtait une gare de marchandises située sur le chemin de fer de la grande ceinture. Un service de voitures à cheval menait les voyageurs de la gare jusqu’au centre-ville.

Après la guerre de 1870-1871, les autorités politiques et militaires décidèrent de construire un dispositif de défense autour de Paris. En 1875, grâce au don du duc de Cambacérès, un nouveau clocher fut élevé. Entre 1875 et 1879 un ensemble de six forts fut bâti, desservis par des routes militaires. L’ensemble couvrait près du dixième de la superficie totale du bois de Verrières. En arc de cercle autour d’un réduit central, cinq batteries furent construites : batterie des Gâtines, d’Igny, de Bièvres, de la Châtaigneraie, du Terrier. Munis d’une garnison, ils ne furent cependant d’aucune utilité militaire ni en 1914, ni en 1940. Tous furent déclassés en 1946 et la plupart, envahis par la végétation, devinrent des terrains d’aventure et de jeu pour les promeneurs. Toutefois deux de ces équipements furent repris par des organismes civils. L’un d’entre eux, le fort des Gâtines avait été utilisé durant la Seconde Guerre mondiale par l’armée allemande pour des essais de propulseurs et du stockage de matériels. Après 1945, il servit aux sociétés aéronautiques françaises pour y expérimenter des matériels. L’usine Sud-Aviation, puis SNIAS, dépendante du centre de recherches de Châtillon succéda à l’entreprise Vilmorin-Andrieux comme principal employeur local. Le réduit est quant à lui utilisé par des services du centre national de la recherche scientifique jusqu’à ce jour.

L’évolution de la commune de Verrières-le-Buisson fut celle de toute la région parisienne. Les champs, les vergers et terres de maraîchage, les grandes propriétés ont fait place aux résidences d’une population dont l’emploi est très majoritairement hors de la commune. Depuis les lendemains de la Première Guerre mondiale, les lotissements se sont succédé. Des zones de pavillons jouxtaient un habitat de petits immeubles collectifs jusqu’en 1964. Durant les deux décennies suivantes, la vente de vastes propriétés (Parc du château d’Estienne d’Orves et champs de la société Vilmorin) et la construction de grands ensembles immobiliers, avec des tours élevées, ne fut pas sans conséquence sur l’aspect visuel de la petite ville. Depuis lors, les municipalités se sont attachées à préserver l’espace urbain de l’envahissement de nouvelles constructions massives et à rénover l’ancien tissu villageois en lui gardant certains aspects des anciens villages d’Île-de-France. Les événements de l’histoire nationale ont une répercussion au niveau local.

La Première Guerre mondiale mobilisa, ici comme ailleurs, les hommes en âge de porter les armes. Inauguré en 1922, le monument aux morts de Verrières-le-Buisson porte, gravés contre l’oubli, les noms des quatre-vingt-cinq Verriérois morts entre 1914 et 1918.

En 1936, ici comme ailleurs, le Front populaire fut une période d’espoir pour une partie des « classes laborieuses ». Durant les grèves de 1936, les ouvriers travaillant aux nombreux chantiers de construction firent parfois grève sur le tas. Les élections législatives de mai 1936 avaient eu pour résultat de désigner un député communiste sur la circonscription de Versailles sud. À Verrières-le-Buisson même, bien que devancé par le candidat de droite, le futur élu, Jean Duclos, frère du dirigeant national du PCF Jacques Duclos rassemblait au second tour du scrutin plus de 44 % des suffrages. Son électorat était constitué de nombreux ouvriers travaillant dans les usines de la banlieue sud-ouest de Paris, et particulièrement par les terrassiers et autre manœuvres des métiers du bâtiment des multiples chantiers ouverts du fait de l’urbanisation. Souvent d’origine bretonne, déracinés et durs au mal, jeunes, ceux-ci trouvèrent localement à Verrières-le-Buisson et à Igny dans le syndicalisme et le parti communiste, des structures de socialisation. À celles déjà énoncées s’ajoutait une association, relativement importante à Verrières-le-Buisson, celle des « Bretons émancipés », dirigée par un ouvrier terrassier-mineur, Eugène Le Foulgocq. Après la guerre de 1939-1945, le groupe des Bretons de Verrières-le-Buisson fut l’une des plus importantes « sections » de l’association des Bretons d’Île-de-France.

La Seconde Guerre mondiale eut des conséquences certaines pour la population. Les événements militaires de 1939-1940 puis les combats en 1943-1945 pour la libération du territoire entraînèrent la mort de douze Verriérois. Meurtriers furent en 1944 les bombardements par l’aviation alliée des infrastructures ferroviaires de la gare de triage de Massy-Palaiseau : huit Verriérois y furent tués. Six autres sont morts en déportation. La défaite militaire entraîna vers les camps de prisonniers en Allemagne plus de deux cents hommes. La résistance à l’envahisseur est symbolisée à Verrières par le combat et la mort sous les balles allemandes le d’Honoré d'Estienne d'Orves, natif de Verrières-le-Buisson. Les combats de la Libération furent fatals au jeune neveu de celui-ci, David Regnier, tué le .

Difficile à évaluer, l’action résistante à Verrières-le-Buisson, où des troupes allemandes stationnèrent jusqu’en 1942, fut multiforme : hébergement d’israélites, diffusion de la presse clandestine, établissement de faux-papiers, sabotages opérés dans la région. Quatre Verriérois se distinguèrent durant cette période trouble par leur humanité en aidant des Juifs : Olivier et Roger de Vilmorin, Camille et Germain Lecureur qui reçurent tous les quatre le titre de Juste parmi les nations par le comité pour Yad Vashem. Une des actions les plus notables consista le en une manifestation préparée et menée par les organisations se situant dans la mouvance du Parti communiste. Selon les témoignages, une petite foule forte de soixante à quatre-vingts personnes, encadrée par les FFI, se réunit ce jour-là au cimetière de Verrières-le-Buisson : la tombe d’Honoré d'Estienne d'Orves fut fleurie et des drapeaux tricolores furent déployés par les participants qui manifestèrent dans quelques rues avant de se disperser. À la fin du mois d’août 1944, la municipalité accueillit en son sein, les représentants de la résistance active dont les président et vice-président du comité local de libération, tous deux membres du Parti communiste français Louis Voyer et Marcel Giraud. Les élections municipales d’avril 1945 donnèrent la victoire à ceux-ci, qui avaient constitué une très large coalition politique. Cette municipalité à direction communiste, épisode isolé dans l’histoire locale, fut battue en octobre 1947.

À partir de 1956 furent élevés les premiers logements HLM puis en 1962 fut entreprise la construction du vaste grand ensemble du Clos, comprenant quatre cent quarante six logements et trois tours de quinze étages. En 1972 fut vendue la dernière ferme d’Amblainvilliers. Entre 1961 et 1986, six écoles furent élevées pour répondre aux besoins des nouvelles familles s’installant dans la commune. En 1975, la ville se dota d’un centre culturel dans les anciens communs du château Vilmorin et d’une salle des fêtes à proximité du vieux colombier. En 1975 toujours, la commune fit l’acquisition de l’arboretum municipal. Le , la commune fut placée sous le feu des projecteurs à l’occasion des obsèques de l’ancien ministre de la Culture André Malraux.

La commune fait partie de l'arrondissement de Palaiseau du département de l'Essonne. Pour l'élection des députés, elle fait partie de la cinquième circonscription de l'Essonne.

La commune, initialement rattachée au canton de Jouy, en 1793, a ensuite fait partie du canton de Palaiseau jusqu'en 1967, année où il a été scindé pour permettre la création du canton de Bièvres, auquel la commune a été rattaché jusqu'en 2015.

Pendant toute son existence, les électeurs de ce canton ont élu conseiller général les maires de Verrières : Jean Simonin, Bernard Mantienne puis Thomas Joly.

Dans le cadre du redécoupage cantonal de 2014 en France, la commune fait désormais partie du canton de Gif-sur-Yvette.

L’organisation juridictionnelle rattache les justiciables Verriérois au tribunal d’instance de Palaiseau, au conseil de prud’hommes de Longjumeau et au tribunaux de grande instance et de commerce d’Évry tous dépendants de la cour d'appel de Paris.

La commune fut membre de 2004 à 2015 de la communauté d'agglomération des Hauts-de-Bièvre qui regroupait sept communes dont deux seulement dans le département de l’Essonne, et qui était compétente en matière de collecte et traitement des ordures ménagères, de gestion de l'eau, de gestion des réseaux de transport en commun, de développement économique et social, l’aménagement du territoire et la gestion des équipements publics d’intérêts communautaires Cette intercommunalité a été dissoute le , compte tenu de la création de la Métropole du Grand Paris le .

La commune adhère depuis à la communauté d'agglomération Communauté Paris-Saclay qui regroupe vingt-sept communes. Elle lui a transféré les compétences de collecte et traitement des ordures ménagères, la gestion de l'eau, la gestion des réseaux de transport en commun, le développement économique et social, l’aménagement du territoire et la gestion des équipements publics d’intérêts communautaires.

La commune adhère également au syndicat intercommunal pour le gaz et l'électricité en Île-de-France (SIGEIF), au syndicat d’aménagement de la vallée de la Bièvre (SIAVB), au syndicat mixte de l’Yvette et de la Bièvre (SIEVYB), au syndicat intercommunal pour l’enfance inadaptée (SIEI), au syndicat intercommunal pour l’aménagement du plateau de Saclay et les vallées de l’Yvette et de la Bièvre, au syndicat intercommunal d’étude, d’aménagement et de protection de la vallée de la Bièvre, au syndicat mixte d’études et de réalisation de la Coulée verte du sud parisien, au syndicat mixte de restauration avec le département de l’Essonne et au syndicat intercommunal pour la création et le fonctionnement d’un centre de montagne.

Maire de 1983 à 2013, réélu au premier tour lors des élections municipales de 2008, Bernard Mantienne fut sénateur du au 30 septembre de la même année (non réélu) et se situe dans la tradition des maires de Verrières-le-Buisson depuis 1947 : les municipalités sont élues sous l’étiquette de « l’Union et de l’Action locale », mais les listes de leurs adversaires électoraux se situent elles-mêmes à gauche.

Thomas Joly a été élu maire de Verrières-le-Buisson en janvier 2013, à la suite de la démission de Bernard Mantienne, lui-même maire depuis 1983. Lors des élections municipales de 2014, la liste Union pour Verrières, conduite par Thomas Joly, a été élu au premier tour de scrutin avec 64,94 % des voix.

Thomas Joly, conseiller général de 2001 à 2015, est aujourd’hui le suppléant de Michel Bournat, conseiller départemental du canton de Gif-sur-Yvette avec Laure Darcos.

Dans la communauté d’agglomération des Hauts-de-Bièvre, Thomas Joly était vice-président chargé du développement durable, de l’environnement, de l’assainissement et des eaux pluviales. Au sein de la nouvelle Communauté Paris-Saclay créée au 1er janvier 2016, il est vice-président chargé de l’hydrologie, l'eau potable, le milieu aquatique et l'assainissement.

La commune de Verrières-le-Buisson est intégrée au canton de Gif-sur-Yvette représenté par les conseillers départementaux Michel Bournat et Laure Darcos (UMP), canton intégré à la cinquième circonscription de l'Essonne représentée par la députée Maud Olivier (PS). Le maire actuel est Thomas Joly (DVD), il préside le conseil municipal composé de trente-trois élus dont vingt-huit de la majorité Union pour Verrières (UPV), quatre de l’opposition socialiste et un de l’opposition communiste. Il est assisté par neuf adjoints au maire et huit conseillers municipaux délégués54. L’Insee attribue à la commune le code 91 3 03 64555. La commune de Verrières-le-Buisson est enregistrée au répertoire des entreprises sous le code SIREN 219 106 457. Son activité est enregistrée sous le code APE 8411Z56.

La commune adhère à la communauté d'agglomération Communauté Paris-Saclay qui regroupe vingt-sept communes. Elle lui a transféré les compétences de collecte et traitement des ordures ménagères, la gestion des réseaux de transport en commun, le développement économique et social, l’aménagement du territoire et la gestion des équipements publics d’intérêts communautaires. La commune adhère aussi au syndicat intercommunal pour le gaz et l'électricité en Île-de-France (SIGEIF), au syndicat d’aménagement de la vallée de la Bièvre (SIAVB), au syndicat mixte de l’Yvette et de la Bièvre (SIEVYB), au syndicat intercommunal pour l’enfance inadaptée (SIEI), au syndicat intercommunal pour l’aménagement du plateau de Saclay et les vallées de l’Yvette et de la Bièvre, au syndicat intercommunal d’étude, d’aménagement et de protection de la vallée de la Bièvre, au syndicat mixte d’études et de réalisation de la Coulée verte du sud parisien, au syndicat mixte de restauration avec le département de l’Essonne et au syndicat intercommunal pour la création et le fonctionnement d’un centre de montagne. Elle s’est en outre dotée d’un office de tourisme. Depuis 2011, la commune est récompensée par cinq @ dans le cadre du concours Ville Internet

Résultats des deuxièmes tours des élections présidentielles :

Résultats des deuxièmes tours des élections législatives :

Résultats des deux meilleurs scores des élections européennes :

Résultats des deux meilleurs scores communaux des élections régionales :

Résultats des seconds tours :

Résultats des seconds tours des élections municipales :


Trente-deux maires se sont succédé à la tête de la commune de Verrières-le-Buisson depuis sa création en 1790 :

En 2015, la commune disposait d’un budget de 30 733 000 € dont 22 607 000 € de budget de fonctionnement et 8 126 000 € d’investissement, financés pour 45,51 % par les impôts locaux avec des taux fixés à 17,62 % pour la taxe d'habitation, 21,20 % et 57,99 % pour la taxe foncière sur le bâti et le non-bâti, la même année l’endettement communal s’élevait à 12 061 000 €.

Au 1er janvier 2015, la commune disposait sur son territoire de mille cent quatre-vingt onze logements sociaux répartis entre neuf bailleurs sociaux, soit 18,78 % du total du parc de logement communal.

Après avoir été récompensée de quatre @ dans le cadre du concours Ville Internet en 2011, la ville a reçu en 2016 pour la cinquième année consécutive cinq @, pour la dématérialisation poussée des inscriptions aux services de la ville, l'accès au wi-fi à la mairie et dans les médiathèques, l'application pour smartphones "Allô voirie" permettant de signaler des anomalies aux services techniques. La ville a également mis à disposition d'une association de femmes du Burkina Faso six ordinateurs configurés pour Internet.

Verrières-le-Buisson a développé des associations de jumelage avec:
Lors du premier recensement intervenu en 1794 , Verrières-le-Buisson comptait mille cinquante-quatre habitants, chiffre relativement stable jusqu’au recensement de 1821 où elle dépassait à peine les mille âmes avant de reprendre une lente progression pour dépasser mille cent cinquante personnes en 1846. En 1851 intervint une nouvelle chute, la commune perdant presque un dixième de sa population avant une nouvelle ascension jusqu’à la perte de soixante habitants au sortir de la guerre franco-prussienne de 1870 et l’occupation prussienne. La progression reprit, avec un bond à plus de mille quatre cents personnes en 1886 grâce à l’ouverture de la ligne de Sceaux, la commune comptant plus de mille cinq cents habitants en 1901, elle poursuivit son expansion malgré les deux conflits mondiaux pour dénombrer en 1946 trois mille cinq cent quatorze habitants. Implantée en banlieue parisienne, elle connut un développement comparable aux autres villes du secteur, répondant au besoin pressant de logements, elle connut une explosion démographique pour atteindre onze mille quatre cents habitants trente ans plus tard et plus de quinze mille dès 1990. Le recensement organisé en 2006 a permis de dénombrer quinze mille huit cent quarante-huit résidents, en légère régression. L’immigration ne représente qu’une faible part de cette évolution puisqu’en 1999, seulement 4,2 % des Verriérois étaient de nationalité étrangère avec une répartition de 1,1 % de Portugais, 0,4 % de Tunisiens et Algériens, 0,3 % de Marocains, 0,2 % d’Italiens, 0,1 % d’Espagnols et de Turcs.

L’analyse de la pyramide des âges de Verrières-le-Buisson établie en 2006 comparée à celle du département montre une relativement forte disparité de répartition de la population, statistiquement plus âgée dans la commune avec des taux presque deux fois supérieurs pour les deux tranches d’âges les plus élevées, un fort déficit de population d’adolescents et jeunes adultes et un déficit moins prononcé de personnes entre trente et quarante-quatre ans, plus marqué encore pour les femmes que pour les hommes. Cette situation ne grève cependant pas la représentation des jeunes enfants, comparable à celle enregistrée dans le reste du département. En 1999, 32,4 % de la population avait moins de vingt-cinq ans.

La culture à Verrières-le-Buisson est accessible grâce à la médiathèque André Malraux en centre-ville et son annexe de La Potinière qui totalisent plus de soixante-cinq mille documents sur divers supports. À proximité directe se trouve le conservatoire de musique à rayonnement intercommunal Charles Koechlin agréé depuis 1993. S’ajoutent le centre culturel Le Colombier qui sert de salle de conférence, de théâtre et de salle de cinéma classée « Art et Essai ». Le musée André Malraux retrace l’histoire locale.

Verrières-le-Buisson dispose de plusieurs installations sportives disséminées sur l’ensemble du territoire. La plus importante est le stade Robert Desnos équipé de douze courts de tennis, d’une piste d'athlétisme et d’un terrain d’honneur engazonné. Il est complété par le stade des Justices qui dispose d’un terrain de football et d’une piste d’athlétisme. Les deux gymnases Jean Mermoz et de la Vallée à la Dame servent de salles polyvalentes, le parc de la Noisette dispose d’un terrain de football, un centre équestre a été aménagé à proximité de Bièvres ainsi qu’un practice, une piste de bicross et un terrain de golf de six trous. Les plateaux libres d’évolution d’Estienne d’Orves, de Breuillet, de l’Hexagone, de la Tournelle, des Gros Chênes et du Poulinat permettent la pratique du football, du basket-ball, du handball.

L’association TUVB (Trait d’Union Verrières-le-Buisson) est la principale organisation sportive de la commune. Elle rassemble diverses disciplines dont les arts martiaux, l’athlétisme, la danse, l’escrime, lefootball, la gymnastique, le handball, l’escalade, la randonnée pédestre, le tennis de table ou le yoga. L’association organise en outre différentes manifestations autour du handisport.
Les établissements scolaires de Verrières-le-Buisson sont rattachés à l’académie de Versailles. Elle dispose sur son territoire des écoles maternelles du Bois Loriot, du Clos Fleuri, des Gros Chênes et des Prés-Bouchard, des écoles élémentaires Paul Fort - David Régnier et Honoré d'Estienne d'Orves. La poursuite d’étude se fait ensuite au collège Jean Moulin. Les élèves vont ensuite dans l’un des lycées de la commune voisine de Massy. S’ajoutent à ces établissements publics deux écoles privées, l’école primaire catholique Notre-Dame de l’Assomption et l’école libre Rudolf Steiner appliquant la pédagogie Steiner-Waldorf. Les jeunes enfants sont accueillis dans plusieurs structures municipales ou familiales, dont les crèches La Vaudonnière, Louise de Vilmorin, La Pouponnière et Saint-Fiacre. Un centre de loisirs accueille les enfants en dehors des périodes scolaires.

Verrières-le-Buisson ne dispose d’aucun hôpital ou clinique sur son territoire, les urgences et pathologies sont traitées par le centre hospitalier privé Jacques Cartier de Massy. Elle regroupe cependant quatre structures d’accueil des personnes âgées avec les résidences du Bois et de la Fontaine et les établissements d’hébergement pour personnes âgées dépendantes Paul Gauguin et Léon Maugé. Un centre de protection maternelle et infantile est implanté dans la commune. Vingt-neuf médecins et douze chirurgiens-dentistes exercent dans la commune

Village devenue petite ville, Verrières-le-Buisson accueille aujourd’hui une agence postale, seule représentation des services publics dans la commune. Une étude de notaire est implantée en centre-ville. La sécurité est assurée par le centre de secours de Massy et le commissariat de police de Palaiseau. L’organisation juridictionnelle rattache les justiciables Verriérois au tribunal d’instance de Palaiseau, au conseil de prud’hommes de Longjumeau et au tribunaux de grande instance et de commerce d’Évry tous dépendants de la cour d'appel de Paris…

La ville s’est dotée d’un office de tourisme.

La paroisse catholique de la commune est rattachée au secteur paroissial de Massy-Verrières et au diocèse d'Évry-Corbeil-Essonnes, elle dispose de l’église Notre-Dame-de-l’Assomption et de la chapelle Saint-Augustin de Grais. Les sœurs missionnaires de Notre-Dame d'Afrique disposent à Verrières-le-Buisson d’une maison de retraite équipée de la chapelle des Sœurs Blanches, ouverte au public. L’association judaïque AIVB dispose d’une salle de prière.

La commune est située dans le bassin d’émission des chaînes de télévision France 3 Paris Île-de-France Centre, IDF1 et Téléssonne intégré à Télif. L’hebdomadaire "Le Républicain" relate les informations locales dans son édition Nord-Essonne comme la station de radio EFM.

Verrières-le-Buisson est intégrée par l’Insee à la zone d’emploi de Boulogne-Billancourt qui rassemblait en 2006 habitants, les Verriérois comptant pour 1,82 % du total. Dans cette zone d’emploi, Verrières-le-Buisson se caractérise par son côté fortement résidentiel, aucune des grandes structures n’étant présentes sur son territoire, la commune ne comptait ainsi en 2007 que six cent quatre-vingt-une entreprises immatriculées dont 64 % évoluaient dans le secteur des services, elle ne dénombrait la même année que quatre-vingt-neuf créations d’entreprise, l’ensemble employant trois mille six cent trente personnes. En 2000, quatre exploitations agricoles étaient encore en activité sur un total de cinq hectares cultivés, exclusivement consacrés au maraîchage, elles occupaient ainsi neuf personnes. Les entreprises de la commune sont principalement groupées dans les zones d’activités des Gardes et des Petits Buissons. Depuis , la commune est au cœur de l’opération d'Intérêt National de Massy Palaiseau Saclay Versailles Saint-Quentin-en-Yvelines. Un marché se tient les mercredis et samedis.

La population active était évaluée à sept mille trois cent cinquante sept personnes, soit le double des emplois disponibles dans la commune, 5,8 % de la population était au chômage, ainsi 84 % des actifs travaillaient dans une autre commune et même 62 % dans un autre département, donnant à la commune des airs de « cité-dortoir ». La population verriéroise est cependant relativement privilégiée puisque 87,8 % des actifs étaient salariés et près de 80 % disposaient d’un contrat à durée indéterminée ou étaient titulaires de la fonction publique. Si la catégorie socioprofessionnelle majoritaire des emplois était en 2006 celle des professions intermédiaires, la majeure partie de la population globale relevait de la catégorie des cadres pour 25,9 % des quinze ans et plus, suivie de près par les retraités (24,4 %). Les revenus qui en découlent permettent à la commune de disposer de 76,4 % de sa population assujettie à l’impôt avec un revenu net imposable moyen fixé à euros en 2006. Le revenu fiscal médian par ménage était en 2007 de euros, ce qui plaçait Verrières-le-Buisson au cinquante-septième rang parmi les communes de plus de cinquante ménages en métropole et au troisième rang départemental. Plus de 69 % de la population était propriétaire de son logement, une maison individuelle dans 54 % des cas.

Près de 55 % du territoire municipal ont conservé un caractère dit rural, en grande partie occupés par la vaste forêt de Verrières qui couvre cinq cent cinquante hectares constitués de chênes, châtaigniers, frênes, charmes et bouleaux. Elle est gérée par l’Office national des forêts et recensée par le Conseil général au titre des espaces naturels sensibles. Au sud de ce massif subsiste la plaine d’Amblainvilliers, consacrée à l’agriculture maraîchère, elle est incluse dans une zone soumise au droit de préemption départemental. À l’extrême sud, les bords de Bièvre sont eux aussi classés au titre des zones humides sensibles. La commune dispose aussi de deux arboretum, l’arboretum municipal et celui d’origine, l’arboretum Vilmorin qui totalisent à eux deux 5,5 hectares. Le premier est classé réserve naturelle régionale depuis 2004. La commune est bordée au nord par le parc de la Noisette et à l’est par le parc Heller et le parc du Breuil, constitutifs de la coulée verte du sud parisien et situés sur le territoire de la commune voisine d’Antony. Elle dispose de plusieurs squares avec le square des Muses, le square Louise de Vilmorin, le square des Roses, le square des Bégonias. La commune est par ailleurs traversée par les sentiers de grande randonnée GR 11 qui ceinture l’Île-de-France et GR 655 qui correspond au chemin du pèlerinage de Saint-Jacques-de-Compostelle par la "Via Turonensis".
Une partie de la Réserve naturelle régionale du Bassin de la Bièvre se trouve également sur la commune.
Le patrimoine architectural de Verrières-le-Buisson est relativement varié des diverses époques d’occupation du site et bénéficie d’une politique de conservation et de classement importante.

Différents personnages publics sont nés, décédés ou ont vécu à Verrières-le-Buisson :






</doc>
<doc id="15521" url="https://fr.wikipedia.org/wiki?curid=15521" title="Conjecture de Goldbach">
Conjecture de Goldbach

La conjecture de Goldbach est l'assertion mathématique non démontrée qui s’énonce comme suit :

Formulée en 1742 par Christian Goldbach, c’est l’un des plus vieux problèmes non résolus de la théorie des nombres et des mathématiques. Il partage avec l'hypothèse de Riemann et la conjecture des nombres premiers jumeaux le numéro 8 des problèmes de Hilbert, énoncés par celui-ci en 1900.

La figure ci-contre montre les solutions de l’équation 2N = p + q représentées par des ronds, où 2N est un nombre pair entre 4 et 50, et p et q sont deux nombres premiers ː les nombres 2N sont représentés par les lignes horizontales et les nombres premiers p et q sont représentés par les lignes rouges et bleues. La conjecture de Goldbach correspond au fait qu’aussi loin qu’on prolonge la figure vers le bas, toute ligne horizontale grise contiendra au moins un rond :

La conjecture de Goldbach est un cas particulier d’une conjecture liée à l’hypothèse H de Schinzel.

Le 7 juin 1742, le mathématicien prussien Christian Goldbach écrit au mathématicien suisse Leonhard Euler une lettre à la fin de laquelle il propose la conjecture suivante :

Dans sa réponse datée du 30 juin 1742, Euler rappelle à Goldbach que cet énoncé découle d'un énoncé antérieur que Goldbach lui avait déjà communiqué :

Selon une version plus faible de la conjecture, tout nombre impair supérieur ou égal à 9 est somme de trois nombres premiers.

La majorité des mathématiciens pense que la conjecture de Goldbach est vraie, en se basant surtout sur des considérations statistiques axées sur la répartition probabiliste des nombres premiers : plus le nombre est grand, plus il y a de manières disponibles pour le représenter sous forme de somme de deux ou trois autres nombres, et la plus « compatible » devient celle pour qui au moins une de ces représentations est constituée entièrement de nombres premiers.

Une version très grossière de l'argument probabiliste heuristique (pour la forme forte de la conjecture de Goldbach) est la suivante. Le théorème des nombres premiers affirme qu'un entier sélectionné aléatoirement d'une manière brute possède formula_1 chance d'être premier. Ainsi, si est un grand entier pair et , un nombre compris entre 3 et , alors on peut s'attendre à ce que la probabilité que et soient tous deux premiers soit égale à formula_2. Cet argument heuristique n'est pas rigoureux pour de nombreuses raisons ; par exemple, on suppose que les événements que et soient premiers sont statistiquement indépendants l'un de l'autre. Si l'on poursuit quand même ce raisonnement heuristique, on peut estimer que le nombre total de manières d'écrire un grand nombre entier pair comme la somme de deux nombres premiers impairs vaut environ
Puisque cette quantité tend vers l'infini lorsque augmente, on peut s'attendre à ce que tout entier pair suffisamment grand non seulement possède au moins une représentation sous forme de somme de deux nombres premiers, mais en fait en possède beaucoup.

L'argument heuristique ci-dessus est en fait quelque peu imprécis, car il ignore certaines corrélations entre les probabilités que et soient premiers. Par exemple, si est impair alors aussi, et si est pair alors aussi, or les nombres premiers sont tous impairs à part 2. De même, si est divisible par 3 et si est déjà un nombre premier distinct de 3, alors est aussi premier avec 3 donc sa probabilité d'être premier est légèrement supérieure à celle d'un entier quelconque. En poursuivant ce type d'analyse avec plus de soin, Hardy et Littlewood conjecturèrent en 1923 (c'est une partie de la célèbre "conjecture des -uplets premiers de Hardy-Littlewood") que pour tout , le nombre de représentations d'un grand entier sous la forme de somme de premiers formula_4 avec formula_5 devrait être équivalent à
où le produit porte sur tous les nombres premiers , et formula_6 est le nombre de solutions de l’équation formula_7 en arithmétique modulaire, soumise aux contraintes formula_8. Cette formule asymptotique a été démontrée pour à partir du travail de Vinogradov, mais est encore à l'état de conjecture pour . Dans ce dernier cas, l'expression ci-dessus est nulle lorsque est impair, et lorsque est pair elle se simplifie en

où formula_9 est la constante des nombres premiers jumeaux

Cette formule asymptotique est quelquefois appelée "conjecture étendue de Goldbach". La conjecture forte de Goldbach est en fait très similaire à celle des nombres premiers jumeaux, et les deux conjectures sont présumées de difficultés comparables.

Dans le cadre de recherches en vue de démontrer la conjecture de Goldbach, plusieurs théoriciens des nombres ont abouti à des théorèmes plus faibles que la conjecture. Le tableau suivant présente quelques étapes significatives de ces recherches. La mention f indique les théorèmes en rapport avec la conjecture faible de Goldbach, « tout nombre impair supérieur ou égal à 9 est somme de trois nombres premiers impairs. » :

En 2014, les vérifications numériques publiées conduisent aux conclusions suivantes :





</doc>
<doc id="15524" url="https://fr.wikipedia.org/wiki?curid=15524" title="Richard Cœur de Lion">
Richard Cœur de Lion

Richard naît probablement au palais de Beaumont en Angleterre. Troisième fils d’ d’Angleterre (l’aîné, appelé Guillaume, né en 1153, est mort à l’âge de trois ans) et d'Aliénor d'Aquitaine, Richard n’est pas destiné à succéder à son père. Il est cependant le fils préféré de sa mère (qui avait eu deux filles de son premier époux, le roi de France) et, lorsque ses parents se séparent, il devient son héritier à la couronne d’Aquitaine en 1168, puis au titre de comte de Poitiers.

En janvier 1169, il est fiancé à Adèle de France (fille du roi de France le jeune). Son père, , la fit venir en Angleterre pour prendre possession des terres constituant sa dot (comté d'Aumale et comté d'Eu), mais, dès qu'elle fut nubile, il aurait abusé d'elle, en aurait fait sa maîtresse et retarda le mariage. Par le traité de paix signé le 30 septembre 1174 à Montlouis entre Tours et Amboise, le roi renouvela à la promesse du mariage entre Adèle et son fils Richard, mais il ne s'y tint pas, et en 1177, le pape  intervint pour le sommer, sous peine d'excommunication, de procéder au mariage convenu. Le Berry devait être la dot de l'épousée. Henri renouvela sa promesse en décembre 1183 puis à l'époque du Carême de 1186, mais ne tint toujours pas sa promesse. Entre temps Adèle aurait donné la vie à un fils, la rumeur voulant qu'il soit l'enfant d'.

Après la mort du roi  Plantagenêt, le 6 juillet 1189, son fils et successeur Richard fit venir Adèle à Rouen en février 1190, mais en 1191, il avertit le roi de France Philippe-Auguste qu'il ne saurait prendre sa sœur comme femme à cause du déshonneur dont il l'accusait.

Comme les autres enfants légitimes d’ Plantagenêt, Richard montre peu de respect pour son père et manque de clairvoyance à long terme ainsi que du sens des responsabilités.

En 1170, son frère Henri « le Jeune » est couronné roi d’Angleterre, avant la mort de son père. Il est ainsi dénommé pour le différencier de son père, puisqu’il ne règne pas encore. Vers 1170, Richard reçoit le comté de Poitiers et le duché d'Aquitaine, lors de cérémonies d'investiture à Saint-Hilaire de Poitiers, puis à Limoges. En 1173, Richard rejoint ses frères de Bretagne, époux de Constance de Bretagne, et Henri le Jeune dans leur révolte contre leur père. Déjà dotés de fiefs par leur père, ils espèrent le remplacer effectivement au pouvoir, poussés en cela par leur mère. . Finalement, il refuse un combat face-à-face, et lui demande son pardon. En 1174, Richard renouvelle ses vœux de soumission à son père.

Après son échec, Richard va mater les nobles mécontents d’Aquitaine, spécialement en Gascogne. Il fonde Marmande en 1182, s’y installe et construit de nombreux châteaux forts dans les environs (Soumensac). Il se taille une affreuse réputation de cruauté, avec de nombreuses accusations de viols et de meurtres. Les rebelles espèrent détrôner Richard et appellent ses frères à l’aide. a peur que cette guerre entre ses trois fils ne conduise à la destruction de son royaume, et il lance son armée à son aide. Le , Henri le Jeune meurt, et son père est toujours sur son trône.

Richard a une raison majeure de s’opposer à son père. Ce dernier a pris comme maîtresse la princesse Adèle, fille du roi , alors qu’elle lui était promise. Cela rend aux yeux de l’Église le mariage avec Richard techniquement impossible. Mais Henri, voulant éviter un incident diplomatique, ne confesse pas son erreur de conduite. Quant à Richard, il ne renonce au mariage qu’en 1191.

Très absent de son royaume d’Angleterre, Richard préfère se consacrer à ses possessions françaises et à la croisade en Terre sainte. 

Peu après son accession au trône (1189), il décide de se joindre à la troisième croisade, inspirée par la perte de Jérusalem, prise par Saladin. Richard Cœur de Lion craint que Philippe Auguste, n’usurpe ses territoires en son absence. Le roi de France a les mêmes craintes vis-à-vis de son rival anglais, aussi les deux rois partent ensemble pour la Palestine. Ils s'engagent à défendre les territoires l'un de l'autre pendant qu'ils seront à la croisade.

Richard est accusé de faire peu pour l’Angleterre, se contentant d’épuiser les ressources du royaume en empruntant pour financer ses expéditions en Terre sainte. Il relève également les taxes, et dépense la majeure partie du trésor de son père. Il rassemble et emprunte autant d’argent qu’il le peut, libérant par exemple le roi d’Écosse de son hommage en échange de dix mille marcs, et vendant nombre de charges officielles et autres droits sur des terres. Par ailleurs, c’est grâce aux réformes importantes de son père en matière de législation et de justice qu’il lui sera possible de quitter l’Angleterre pendant une longue période.

En 1190, Richard part finalement pour la troisième croisade avec son ami le seigneur de Sablé et futur Grand-Maitre templier, Robert de Sablé (qui passa dix-neuf ans à sa cour). Il s'embarque avec Philippe Auguste à Marseille, laissant Hugues, évêque de Durham, et Guillaume de Mandeville comme régents. Guillaume de Mandeville, qui meurt rapidement, est remplacé par Guillaume Longchamp. Mécontent de cette décision, le frère de Richard, Jean, se met à manigancer contre Guillaume.

Pendant l'été 1190, Richard décide de débarquer près de Naples tandis que Philippe Auguste gagne directement Messine le 16 septembre. De la région de Naples, il gagne Messine par voie terrestre en passant par Amalfi, Salerne et Mileto, où il est agressé par des gens du cru. Selon Roger de Hoveden, Richard s'était écarté de sa suite et avait molesté un paysan ; aussitôt, tous les habitants du village l'attaquent et il ne doit sa survie qu'à la rapidité de sa fuite.

En septembre 1190, Richard et Philippe sont en Sicile. En 1189, le roi de Sicile est mort. Son héritière, sa tante Constance, future reine de Sicile, est mariée à l’empereur . Mais immédiatement après la mort de Guillaume, son cousin Tancrède de Lecce se rebelle, prend le contrôle de l’île, et début 1190, est couronné roi de Sicile. Il est préféré par le peuple, et par le pape, mais il est en conflit avec les nobles de l’île. L’arrivée de Richard accentue les difficultés. Tancrède a emprisonné la veuve de Guillaume, la reine Jeanne, la sœur de Richard, et ne lui donne pas l’argent qu'elle a hérité selon la volonté du défunt. Richard réclame la libération de sa sœur et la remise de son héritage. Pendant ce temps, la présence de deux armées étrangères cause des troubles parmi la population, exaspérée notamment par le comportement des soldats envers les femmes. En octobre, la population de Messine se révolte, demandant que les étrangers quittent l’île. Une rixe éclate le 3 octobre entre des soldats et des habitants de la ville, « ramas de Grecs et de ribauds, gens issus de sarrasins » qui conspuaient les pèlerins tout en les traitant de « chiens puants ». Richard attaque Messine et la prend le 4 octobre 1190. Après l’avoir pillée et brûlée, Richard y établit son camp. Il y reste jusqu’en mars 1191, quand Tancrède accepte finalement un traité. Celui-ci est signé, toujours en mars, par Richard, Philippe et Tancrède. En voici les termes :

Le traité ébranle les relations entre l’Angleterre et le Saint-Empire romain germanique, et cause la révolte de Jean sans Terre, qui espère être proclamé héritier à la place de son neveu. Bien que sa révolte échoue, Jean continue dès lors de comploter contre son frère.

Richard et Philippe reprennent la mer. En avril, Richard s'arrête sur l’île byzantine de Rhodes pour éviter une tempête. Il la quitte en mai, mais une nouvelle tempête amène sa flotte à Chypre, où trois de ses navires s'échouent. L'attitude hostile du prince Isaac Doukas Comnène, qui régnait sur Chypre après s'être détaché de l'empire byzantin en 1184, provoque, le 6 mai 1191, le débarquement de la flotte de Richard dans le port de Lemesos (aujourd'hui Limassol). Il tente de s'entendre avec le Grec pour le ravitaillement d'Acre, mais devant la perfidie de ce dernier (Isaac était en fait de mèche avec Saladin), Richard entreprend la conquête de l'île. Les quelques catholiques romains de l’île se joignent à Richard, ainsi que ses nobles, révoltés par les sept années du joug tyrannique d’Isaac.

Après avoir été défait à Kolossi (à l'ouest de Limassol), Isaac réorganise sa défense à Trémithoussia, sur la route menant à la capitale Nicosie, où se livre une bataille décisive le 21 mai 1191. Isaac est vaincu et fait prisonnier par Richard, qui devient le nouveau maître de Chypre. Il pille l’île et massacre ceux qui tentent de lui résister. Pendant ce temps, la promise de Richard, Bérengère de Navarre, première-née du roi de Navarre, l’a enfin rejoint sur sa route vers la Terre sainte. Leur mariage est célébré à Limassol, le 12 mai 1191. La sœur de Richard, Jeanne, l’a suivi depuis la Sicile et assiste à la cérémonie. Le mariage ne produit pas d’héritier, et les opinions divergent sur l’entente entre les époux. La malheureuse Bérengère ne reverra l’Angleterre qu’après la mort de Richard.

Cette conquête de Chypre allait avoir un impact très important sur l'Orient latin. D'un côté, l'île, pleine de ressources, allait constituer un centre de ravitaillement assuré pour l'Orient latin (et notamment pour Acre encore assiégée) et une escale sûre pour les armadas italiennes (maîtresses de la mer) et les autres croisades. D'un autre côté, elle allait participer au déclin de l'Orient latin en attirant les colons et barons syriens : entre les terres pleines de richesse de l'île et celles sans cesse exposées au danger de la Palestine, le choix était évident pour nombre de chevaliers, d'autant plus que le clan des Lusignan, futurs maîtres de Chypre, n'hésitait pas à multiplier les offres de terres et autres baronnies.

Avant de partir pour Acre et pour seulement d'argent, Richard vend l'île de Chypre à son ami Robert de Sablé, le grand-maître de l'ordre du Temple. Les Templiers y installeront pendant quelques années leur première base en Orient avant de la vendre à Guy de Lusignan. Richard, avec presque toute son armée, quitte Chypre pour la Terre sainte au début de juin. En son absence, Chypre doit être gouvernée par Richard Kamvill.

Richard arrive à Acre en juin 1191 avec son ami le grand-maître de l'ordre du Temple Robert de Sablé, deux mois après Philippe Auguste. La ville, assiégée depuis deux ans par les Francs (eux-mêmes encerclés par l'armée de Saladin), commence à être à bout. L'arrivée du roi Richard, à la fois fabuleux combattant et tacticien, amène la chute d'Acre en juillet 1191. C'est lors de cette victoire que Richard va s'illustrer sombrement en massacrant musulmans, parce que Saladin tardait à lui remettre une relique de la Vraie Croix, chrétiens ainsi qu'une rançon convenue (20 août 1191, après le départ de Philippe Auguste). Après cet acte de barbarie qui va renforcer le jihad et rendre entre autres les futures négociations très difficiles (notamment pour la restitution de Jérusalem), Richard part conquérir le littoral avec Robert de Sablé et ses Templiers, mais il reste le seul chef de toute l'armée franco-anglaise (le roi de France est parti avec sa propre maison, laissant toutes ses troupes sous la houlette du duc de Bourgogne). Richard a aussi tout fait pour imposer comme roi de Jérusalem Guy de Lusignan (celui-ci étant originaire du Poitou, et donc son vassal) au détriment de l'énergique Conrad de Montferrat, sauveur de Tyr en pleine débâcle franque et soutenu ardemment par tous les barons syriens.

Lors de leur conquête du littoral sud, Richard, Robert et leurs troupes sont harcelés sans cesse par les troupes de Saladin. Les croisés ne tombent néanmoins pas dans le piège de la poursuite et restent solidement groupés. Cependant, Saladin, ayant reçu des renforts turcomans, engage la bataille d'Arsouf dans une position stratégique très favorable : les croisés étant encerclés, adossés à la mer. Richard ne perd pas son calme et tente une habile manœuvre d'encerclement pour écraser totalement l'armée adverse. Mais un hospitalier et un chevalier anglais chargent pour la gloire, entraînant avec eux quelques autres chevaliers. Richard doit alors charger avec toute la cavalerie pour éviter une désorganisation possiblement fatale, et après de durs combats, la victoire est remportée par Richard. Celle-ci n'est cependant pas complète et ne conduit qu'à disperser et repousser l'armée ennemie, Richard n'ayant pu réaliser le mouvement tournant qui lui aurait permis une victoire décisive. Saladin détruit alors des places fortes (Jaffa notamment) avant l'arrivée des croisés. Le littoral conquis et certaines places fortes reconstruites (Jaffa, Ascalon…), Richard part vers Jérusalem en plein hiver. Mais il renonce finalement au siège, sous l'insistance notamment des barons syriens : la saison était mauvaise et ces derniers savaient qu'ils ne pourraient tenir Jérusalem une fois tous les croisés repartis. Le roi revient par la suite à deux reprises, mais il renonce bien qu'il estime toujours que la ville est à portée de main car son armée est affaiblie, alors que celle de Saladin est toujours plus grande et plus forte. Il est vrai qu'il vient également de recevoir de graves nouvelles d'Angleterre et il ne pense plus qu'à rejoindre son royaume. 

Le 5 juillet 1192, Richard commence à se replier pour regagner la côte. Voyant une occasion de se venger de la défaite d'Arsouf, Saladin contre-attaque et, le 27 juillet, met le siège devant la ville de Jaffa, qui avait servi de base d'opérations pour Richard au cours de sa marche à l'intérieur des terres en direction de Jérusalem. Il prend la ville basse, mais pas la citadelle qui résiste. Mis au courant, Richard quitte alors sa flotte, rassemble rapidement une petite armée, et se précipite vers la ville. La bataille de Jaffa s'engage. Battu à deux reprises par Richard, les 1 et 5 août, Saladin est contraint de se replier vers Jérusalem.

Richard finit par embarquer le 9 octobre 1192, après avoir bâclé la paix avec Saladin (celui-ci, conscient des difficultés de Richard, tergiversait intelligemment) et mis à la tête d'Acre son neveu, le comte de Champagne (Conrad de Montferrat avait été assassiné par la secte des Assassins, et Guy de Lusignan dit « Sa Simplesse », devenu trop embarrassant pour les croisés, fut nommé à la tête du Royaume de Chypre).

À la suite des manœuvres du roi français Philippe, le duc de Babenberg capture Richard sur son chemin de retour, près de Vienne, à l’automne 1192. Richard l’a en effet publiquement insulté durant la croisade. Emprisonné à Dürnstein, il est ensuite livré à l’empereur qui réclame une rançon de cent cinquante mille marcs d’argent, équivalant à deux années de recettes du royaume d’Angleterre. Bien que les conditions de sa captivité ne soient pas strictes, il est frustré par l’impossibilité de voyager librement. De cet emprisonnement est tirée la légende de Blondel.

L’empereur le libère en février 1194 contre un premier versement de cent mille marcs d’argent que sa mère, Aliénor d'Aquitaine, réussit à rassembler péniblement. L’empereur lui extorque également un serment d’allégeance de la couronne d’Angleterre à l’Empire avec le devoir de payer un tribut de cinq mille livres sterling par an. Philippe Auguste aurait fait prévenir Jean sans Terre que « le diable est lâché ».

Le 20 mars 1194, Richard débarque au port de Sandwich et retrouve l'Angleterre. Durant son absence, son frère Jean fut près de conquérir le trône. Richard lui reprend une à une les forteresses, le château de Nottingham est le dernier à tomber, puis il décide de rentrer en France, Philippe Auguste ayant tenté de s'emparer de la Normandie en son absence.

Richard débarque à Harfleur le 13 mai et prend le chemin pour Verneuil sur Avre assiégée par Philippe Auguste. Auparavant, Jean qui voit son frère arriver si tôt en Normandie se rallie à son frère à Lisieux. Richard campe à l'Aigle, le roi de France Philippe se sentant menacé profite des fêtes de la Pentecôte (29 mai) pour fuir, sacrifiant son arrière-garde. Dés lors, le but de Richard est de reprendre le contrôle des forteresses objet du traité signé en janvier entre Philippe et Jean, ou d'en empêcher la prise, car tous les gouverneurs n'ont pas accepté les clauses de ce traité. Il descend sur l'Anjou.

Philippe se venge de la trahison de Jean en brûlant Évreux. Il réalise un peu tard le dessein du roi d'Angleterre quand celui-ci a repris la place forte de Loches. Fin juin, Philippe prend le château de Fréteval et tourne son Ost sur la forteresse de Vendôme. Richard campe alors à moins d'une lieue et fait dire à Philippe qu'il l'attend. Profitant de la nuit, Philippe lève le camp et suit péniblement la rive gauche du Loir avec son armée. Complètement désorganisée, celle-ci est cueillie au petit matin à quelques kilomètres de Fréteval. Philippe, qui s'était éloigné de l'itinéraire pour se reposer dans un châtelet sur une île du Loir, parviendra à fuir avec une poignée d'hommes, mais ses sceaux royaux, son trésor et ses chartes feront partie du butin récupéré par Richard.
Après son départ en mai 1194, il ne retournera pas en Angleterre. En janvier 1196, Richard assiège Gaillon dont Lambert Cadoc est le châtelain. Lambert Cadoc repère Richard du haut de la tour et le vise avec son arbalète : le trait atteint le roi au genou et tue son cheval. Ironiquement, c'est Richard lui-même qui a recruté Lambert Cadoc, avec d'autres mercenaires, dans le Pays de Galles, pour combattre le roi de France ; mais une partie de ces Gallois, dont Lambert Cadoc, poussés par leur haine des Normands et des Saxons, ont fait défection et rejoint l'autre camp.

Durant plusieurs années de guerre, Richard parvient à redresser la situation et à défendre efficacement la Normandie. Il fait construire à cet effet une série de châteaux dont le célèbre Château-Gaillard près des Andelys, sur la rive droite de la Seine, mais aussi la forteresse d’Arques-la-Bataille, ainsi que les châteaux de Radepont dans la vallée de l’Andelle, Montfort-sur-Risle dans la vallée de la Risle, Orival sur la Roche Fouet surplombant la Seine en amont de Rouen au-dessus d’Elbeuf, et fait améliorer le château de Moulineaux surplombant la Seine en aval de Rouen. Après une courte trêve, la guerre reprend à l'automne 1196. Richard envahit le Vexin. Il bat une première fois Philippe Auguste en septembre 1198 entre Gamaches et Vernon, puis une deuxième fois le 27 septembre lors de la bataille de Gisors. Cependant, le pape lui impose une trêve qui profite à Philippe Auguste.

Le , Richard assiège le château de Châlus-Chabrol, possession du vicomte de Limoges, dit Boson. Le 26, le roi est atteint par un carreau d'arbalète. L'auteur du tir n'est pas identifié avec certitude à cause des divergences entre les récits des chroniqueurs. Roger de Hoveden accuse le chevalier du Quercy Bertrand de Gourdon, mais Mathieu Paris et Raoul de Dicet évoquent un petit noble local Pierre Basile, à moins que ce ne soit Jean Sabroz ou Dudo. La flèche est retirée mais la gangrène s'installe. Richard meurt le , onze jours après sa blessure.

Son corps est enterré en l’abbaye de Fontevraud (située non loin de Saumur), son cœur embaumé est enfermé dans un reliquaire et enterré dans un tombeau surmonté d'un gisant à son effigie en la cathédrale de Rouen, et ses entrailles sont déposées en l'église (actuellement ruinée) du château de Châlus-Chabrol. Cette partition du corps ("", « division du corps » en cœur, entrailles et ossements) avec des sépultures multiples est une pratique initiée au milieu du par les chevaliers et souverains du Royaume d'Angleterre et du Saint-Empire romain germanique morts en croisade ou loin de leur lieu de sépulture choisi.

Selon Roger de Hoveden, Philippe de Cognac, fils illégitime supposé de Richard, aurait vengé la mort de son père en assassinant Adémar de Limoges.

En mai 1199, Jean succède à Richard sur le trône d’Angleterre. Cependant les barons d'Anjou, du Maine et de Touraine le rejettent au début, lui préférant Arthur de Bretagne, neveu de Richard et Jean, dont les droits sont juridiquement meilleurs que les siens.

Richard est très respecté par son plus grand rival militaire, Saladin, ainsi que par l’empereur Henri, mais il est également haï par nombre de ses anciens amis, en particulier le roi Philippe Auguste.

Il se soucie peu de sa propre sécurité : la blessure reçue lors du siège de Châlus, qui aura raison de lui, ne se serait pas produite s’il avait été correctement protégé par une armure ; par la suite, l'infection aurait pu être évitée. Un incident très similaire s’était déjà produit dix ans auparavant, lorsque, combattant contre son père, il avait rencontré, désarmé, Guillaume le Maréchal, et avait dû le supplier pour avoir la vie sauve.

Richard est un mécène et protecteur des troubadours et trouvères de son entourage il est également poète. Il est lui-même intéressé par l'écriture et la musique, et on lui attribue deux poèmes qui nous sont parvenus. Le premier est un sirventès, "Dalfin je us voill desrenier", le second est une complainte, "Ja nuns hons pris".

La légende de Robin des Bois "(Robin Hood)", d'abord située sous le règne d' (vers 1322), est déplacée dans le temps par des écrivains anglais à partir du dans le but de la rattacher au règne de . Cependant, il n'y a pas de certitude historique sur Robin, qui peut avoir vécu au , au . C'est donc bien plus tard qu’est établi un lien entre les deux hommes, en affirmant que le but poursuivi par Robin est de restaurer Richard sur le trône usurpé par le prince Jean lors de la captivité de Richard, entre 1192 et 1194, alors qu'en réalité Richard n'avait guère plus de soutien populaire en Angleterre que son frère Jean.

L’amitié entre Philippe Auguste et Richard, qui se connaissaient depuis l'enfance, a parfois été assimilée à une relation homosexuelle, notamment par l'historien britannique John Harvey, en 1948. Pour l'historien britannique John Gillingham, biographe de Richard Cœur de Lion, cette idée d'un roi homosexuel, apparue au , s'appuie sur des interprétations anachroniques des éléments qui nous sont connus. Pour lui, la sexualité exacte de Richard ne peut être connue avec certitude. Toutefois, pour l'historien William E. Burgwinkle, le fait qu'il n'y ait pas de preuves formelles de son homosexualité ne signifie pas pour autant qu'il faille conclure qu'il était forcément hétérosexuel.

Certains chroniqueurs du , comme notamment Benoît de Peterborough, parlent d'« amour » entre les deux jeunes hommes qu'étaient alors Richard et Philippe Auguste, et soulignent qu'ils partageaient le même lit. Ce lien très fort unissant les deux hommes est définitivement brisé peu après et se transforme en haine.

Quoi qu'il en soit, ses contemporains supposaient qu'il était hétérosexuel. L'historien Jean Flori n'adhère pas à la thèse d'un roi homosexuel. Pour lui, conclure à une relation homosexuelle relève d'une interprétation trop « moderne » du terme « amour » et il ajoute que partager le même lit . Toutefois, sur la base des récits des pénitences de roi Richard en 1191 et 1195 pour des péchés de sodomie et de bougrerie, Jean Flori conclut à la probabilité d'une bisexualité. Pour l'historien William E. Burgwinkle, il n'y a rien dans les chroniques contemporaines pour affirmer qu'en dehors de la forte affection qu'il avait à l'égard de Philippe Auguste, Richard ait été épris de quiconque, homme ou femme.

À , sous la pression de sa mère, Richard épouse Bérengère de Navarre. Ils se voient très rarement, et ce mariage est avant tout un mariage de convenance. D'après le chroniqueur contemporain Roger de Hoveden, après l'avertissement d'un ermite, et étant tombé subitement malade, Richard fait pénitence pour s'être éloigné de sa femme, et se réconcilie charnellement avec elle. Il ne montre toutefois aucune volonté visible de concevoir un héritier.

Le chroniqueur contemporain Benoît de Peterborough accuse aussi Richard de viols sur des femmes du peuple. Pour Burgwinkle, un viol n'est pas l'indication d'un désir sexuel pour les femmes, mais un désir de contrôle, et dans le cas de Richard, certainement un contrôle politique. Sa conclusion est qu'affirmer que Richard Cœur de Lion était hétérosexuel est illusoire.

Richard a, avec une maîtresse inconnue, un fils illégitime, Philippe de Cognac. Ce dernier épouse Amélie de Cognac († 1199), fille d'Itier, seigneur de Cognac, Villebois et Jarnac. Philippe de Cognac venge son père en assassinant, en 1199, de Limoges.





</doc>
<doc id="15526" url="https://fr.wikipedia.org/wiki?curid=15526" title="Châlus">
Châlus

Châlus est une commune française située dans la Haute-Vienne, en région Nouvelle-Aquitaine. Localisée au sud-ouest de Limoges et au nord-est de Périgueux, elle appartient au Limousin historique. Elle est connue pour être le lieu où le roi d'Angleterre Richard Cœur de Lion fut mortellement blessé en 1199.

Sa position dans les monts de Châlus, au carrefour naturel de routes anciennes, se traduit par les influences mêlées du Limousin, du Périgord et de la Charente limousine dans l'hydrographie, le climat, le relief ou encore les styles architecturaux. Ce caractère de frontière a orienté un développement fondé sur les échanges, avec des foires au Moyen Âge, et une histoire agitée par les sièges de ses châteaux.

Marquée par l'activité agricole et l'exploitation du châtaignier, son économie a vu l'industrie se développer avec le chemin de fer, jusqu'à la contraction de sa population dans le dernier quart du .

L'installation récente de populations rurbaines ou britanniques permet une stabilisation démographique autour de . Axé sur le tourisme et le développement durable, le renouveau de la commune et de ses environs, illustré par exemple par la création du parc naturel régional Périgord-Limousin, intègre les atouts traditionnels du territoire, tels que la forêt et le bois, mais aussi le développement de services médico-sociaux, éducatifs et sportifs.

Constituant un pôle de services intermédiaires dont la promotion est portée par des rendez-vous épisodiques tels que la félibrée ou, en 2009, le Tour du Limousin, Châlus doit sa renommée à l'aura de personnalités dont le souvenir y est attaché, de Richard Cœur de Lion à Pierre Desproges en passant par Georges-Emmanuel Clancier ou Lawrence d'Arabie.

Châlus est au centre du pays des Feuillardiers, région naturelle constituée d'un ensemble de collines boisées, bordée à l'est par le pays Arédien, au nord par la vallée de la Vienne, à l'ouest par la Charente limousine et au sud par le Périgord vert. Châlus est limitrophe de cinq autres communes.

Située à au sud-ouest de Limoges et à au nord-est de Périgueux (29 et respectivement en distances orthodromiques), Châlus est la ville principale des monts de Châlus, aire géographique d'une altitude maximale de qui constitue les premiers contreforts occidentaux du Massif central avec, plus au nord, les monts de Blond.

Le territoire communal est situé sur un sous-sol de roches métamorphiques, très dur, particulièrement résistant à l'érosion, correspondant au socle cristallin du Massif central, et constitué de gneiss, largement utilisé dans le bâti traditionnel. Il offre un relief assez doux, entre d'altitude, fait de vallonnements et de fortes collines boisées de taillis de châtaigniers, caractéristiques du paysage.

Toutefois, si au nord de la Tardoire, l'activité agricole et l'élevage dominent le bocage limousin traditionnel, ils sont, au sud, plus imbriqués avec la forêt, où la présence de monts offre des points de vue panoramiques, comme celui sur Châlus depuis Lageyrat.

La géologie châlusienne inclut des massifs de serpentinite, reliques du fond d'un océan disparu au cours de l'édification de la chaîne hercynienne au carbonifère (-350 à -290 millions d'années). Sur cette roche ultramafique et riche en métaux lourds se développe une végétation originale, comme sur la lande de la Martinie. Les sols bruns acides sont, de manière générale, pauvres et peu fertiles.

La sismicité est faible, mais non nulle. Si aucun séisme de magnitude supérieure à 3 n'est survenu depuis 1979, la commune se trouve dans l'aire macrosismique de neuf séismes recensés depuis 1925. Pour deux d'entre eux, la commune est comprise dans l'aire pléisoséiste. C'est le cas pour le séisme du d'une intensité épicentrale de III sur l'échelle MSK64 et pour celui du qui fut d'une intensité épicentrale et ressentie dans la commune de V à VI (l'épicentre de ce dernier peut être localisé entre Châlus et Gorre, par 45° 41' de latitude nord et 0° 59' de longitude est).

Le milieu naturel châlusien est soumis à l'influence d'un climat océanique humide, avec des précipitations assez abondantes, et des températures sans excès, que l'altitude et l'exposition contribuent à moduler.

Le territoire de Châlus est à cheval sur les bassins hydrographiques de la Loire, de la Charente et de la Dordogne. Les fortes précipitations liées à un climat océanique humide et à un sol cristallin imperméable ont induit un réseau hydrographique dense qui modèle fortement le paysage. Les cours d'eau, souvent bordés de ripisylves, maintiennent des corridors écologiques qui serpentent dans des vallons humides et présentent un fort intérêt paysager.
L'omniprésence de l'eau sur la commune, riche en sources, serves, puits, lavoirs et fontaines à dévotion, est renforcée par la présence d'un grand nombre d'étangs. Les eaux souterraines, concernées par le schéma directeur d'aménagement et de gestion des eaux (SDAGE) du bassin Adour-Garonne, sont, comme l'ensemble des eaux souterraines de la communauté de commune, de bonne qualité physico-chimique, bien que faiblement minéralisées et acides.

Le cours d'eau principal, la Tardoire, est une rivière classée en seconde catégorie piscicole sur son cours supérieur. Elle appartient au bassin de la Charente, dont elle forme l'extrémité la plus orientale. La vallée de la Tardoire constitue, comme la lande de la Martinie, une zone naturelle d'intérêt écologique, faunistique et floristique (ZNIEFF), avec la présence notamment de la loutre, du râle d'eau, du cincle plongeur ou du busard Saint-Martin. Elle prend sa source sur la commune de Pageas, à la sortie d'un étang sous le hameau du Mazaubert, puis s'encaisse pour franchir l'ancien moulin entre les châteaux de Châlus Chabrol et de Châlus Maulmont. En aval, la Tardoire perd peu à peu son eau pour alimenter le système de gouffres et de résurgences du karst de La Rochefoucauld, puis ressort, associée à d'autres eaux souterraines dont celles du Bandiat, aux sources de la Touvre. En cas de crue, la Tardoire peut conserver assez d'eau pour constituer un affluent de la Bonnieure. La commune est parsemée de ruisseaux naturels, tels le ruisseau du Lac, qui prend sa source à proximité du lieu-dit « Chareilles » et rejoint la Dronne via les étangs de Maison Neuve (commune de Dournazac) ou le ruisseau des Maisons, qui constitue un site majeur du patrimoine naturel, notamment en raison des populations d'écrevisses à pattes blanches d'intérêt européen qu'il abrite. De multiples rigoles artificielles, de très faible importance, créées pour drainer les vallées humides et amender la terre, participent également au système hydraulique du territoire.

Le territoire communal compte 60 étangs ; la superficie du plus petit correspond à et celle du plus étendu est supérieure à . Certains d'entre eux alimentaient autrefois des moulins. Les plus récents, qui sont aussi les plus nombreux, sont directement liés au développement d'une société de loisirs. Ils sont, le plus souvent, construits par obstruction d'une petite vallée, ce qui a réduit la surface des zones humides et modifié l'aspect du paysage en le remodelant de façon importante, avec une influence possible sur le climat.

La richesse hydrographique du territoire s'accompagne de nombreux petits ouvrages bâtis : ponts, moulins, lavoirs, abreuvoirs, fontaines, puits. La Tardoire est franchie par une dizaine de ponts, dont le plus important est un petit viaduc à trois arches, dit "les trois ponts".

Châlus est accessible de Limoges () et de Périgueux () par la RN 21, de Nontron (), par la D 707 puis la D 85, et enfin la D 6 bis en Haute-Vienne, de Saint-Yrieix () par la D901, de Rochechouart () également par la D 901. En 2004, le trafic moyen journalier recensait au sud de Châlus et au nord ; en avril 2007, les départementales 901 et 6b débouchant sur Châlus connaissaient un trafic relativement important avec environ par jour. Trois lignes de la RDTHV relient la ville à Limoges : la desservant Isle, Aixe-sur-Vienne, Flavignac, Châlus, Dournazac et La Chapelle-Montbrandeix, ainsi que la , desservant Isle, Aixe-sur-Vienne, Séreilhac, Pageas et Châlus son terminus, et enfin la ligne 60 avec un arrêt au pont. La , fonctionne en période scolaire avec un arrêt place Salvador-Allende.

Les trains Intercités desservent Limoges par la gare des Bénédictins. Ils sont accessibles en TER Limousin par la gare de Bussière-Galant, distante de Châlus de , avec cinq allers-retours en semaine, sur la ligne Limoges - Périgueux, ou par celle de Nexon, à , avec douze allers-retours en semaine. L'aéroport international le plus proche est l'aéroport de Limoges-Bellegarde à . En avion de tourisme, la liaison peut s'effectuer à partir de l'aérodrome Maryse-Bastié de Saint-Junien, distant de également.

L'agglomération s'inscrit dans deux entités paysagères distinctes avec, au nord, le bocage limousin dominé par l'élevage et les prairies permanentes et, au sud, le massif des Feuillardiers, constitué d'un plateau au relief ondulé et au chevelu hydrographique dense où s'imbriquent parcelles agricoles et forestières. Son origine est à rechercher des deux côtés de la vallée de la Tardoire, dans l'urbanisation de promontoires rocheux posés en vis-à-vis, dont le développement réalise un tissu urbain continu. Zone frontière de contact et d'échange entre différentes influences, Châlus est le lieu de rencontre de deux types d'architecture vernaculaire : celle du pays Arédien, plus fréquente au sud de la commune, avec ses toits de tuiles plates anciennes, et celle du pays de Limoges, avec ses couvertures en pentes douces de tuiles canal rouge brique. Si, au , la construction de maisons de maître dans les hameaux, et de maisons bourgeoises en ville n'a pas remis en cause la trame urbaine historique, celle-ci est désormais affectée par l'habitat pavillonnaire contemporain, regroupé en lotissements aux franges de la zone agglomérée ou bâti isolément, et par mitage, dans les hameaux.

Le parc de logements, constitué majoritairement de bâtiments anciens, s'élève, en 2006, à . Selon une étude réalisée de 2003 à 2005, la superficie moyenne des parcelles construites s'élève à dans le bourg, et en zone non agglomérée. Les résidences secondaires, au nombre de 123, représentent 11,60 % de l'ensemble des logements. Le statut de propriétaire est largement dominant (en 2006, 24,5 % des logements étaient occupés par des locataires), ce qui s'explique notamment par l'omniprésence de l'habitat individuel (93,5 % des résidences principales en 2007). Les logements sociaux sont peu développés : l'office départemental HLM de la Haute-Vienne (ODHAC) en possède 31, et la commune un seul. Si, en 2006, 156 logements vacants étaient référencés, l'offre locative reste insuffisante pour répondre à la demande, tirée dans le bourg par la présence des commerces et services, malgré les onze logements remis sur le marché locatif entre 2000 et 2003 après rénovation réalisée dans le cadre de l'« Opération programmée d'amélioration de l'habitat des Feuillardiers ».

Le bourg est collecté par un réseau d'assainissement collectif de type séparatif dans ses parties les plus récentes (l'Abbaye, la Ville Haute, le Chêne Vert, la Malatie, les Places), et par un réseau de type unitaire dans ses parties les plus anciennes (le Nid, le Bosfranc, la Vieille Ville, la Cité des Granges) relié à la station d'épuration, qui est située à proximité de la chapelle Séchaud. Tous les autres hameaux et les maisons isolées sont soumis à l'obligation de disposer d'un assainissement autonome, bien que certains terrains soient peu adaptés à cette technique. Le réseau électrique appartient au Syndicat d'électricité de Haute-Vienne. Géré par ERDF, il dessert l'ensemble des zones urbanisées.

Le plan local d'urbanisme, élaboré par la communauté de communes, fixe, parmi ses priorités, le développement de l'habitat par densification des zones urbanisées, en continuité avec le tissu urbain ancien afin d'éviter les phénomènes de mitage. L'éclatement du bourg et des hameaux se poursuit cependant avec la tendance à la rurbanisation, liée à l'influence du bassin d'emploi de Limoges et qui se traduit par d'importants flux quotidiens d'habitants (un comptage de l'observatoire mis en place en 2003 par la communauté de communes sur Châlus et Flavignac a révélé que 44 % des demandeurs de logement travaillent dans l'agglomération de Limoges). Quoique le Limousin constitue la région française où le prix au mètre carré est le meilleur marché, la hausse des prix des terrains à bâtir à proximité immédiate de Limoges incite les ménages à s'éloigner de la capitale régionale et constitue un potentiel de développement pour la commune.

Marqués par la coupure de la Tardoire et un relief vigoureux, les quartiers de Châlus se partagent entre le promontoire situé sur la rive droite de la Tardoire, le promontoire situé sur sa rive gauche, et les extensions plus récentes de la zone agglomérée.

"La Ville haute", construite sur les faces est et sud-est du promontoire de Châlus Chabrol avec lequel elle se confond, est le quartier le plus ancien. Aujourd'hui en connexion urbaine avec le bourg de Châlus, "La Ville haute" constituait autrefois une agglomération propre, qui eut ses seigneurs (les Bourbons Châlus, propriétaires du château de 1530 à 1994), sa propre église (les paroissiens de Châlus-Bas allaient à l'église de Lageyrat), et conserve sa place publique, la place du Canton. Cette dernière reçoit l'ancienne route d'Oradour, une voie menant aux moulins et étang de la Tardoire (la rue Mardochée) et la rue Chabrol, la plus vieille de toute la ville, et qui mène aux Cars.

À la différence de "La Ville haute", qui constitue un seul quartier, la ville basse, ou "Bas-Châlus", ou encore "Le bourg", comprend plusieurs quartiers historiques, qui s'articulent entre la rive gauche de la Tardoire et son moulin, une route menant à Nontron, via Dournazac (actuelles rue et place du Marché) et une autre menant autrefois à la route royale de Limoges à Périgueux (rue Salardine). Son cœur historique, le quartier du "Fort", est bâti dans l'ancienne enceinte de la forteresse Maulmont (rue Gourdon, ses maisons s'appuient sur ce qui en fut les murailles). Les ruelles étroites et sinueuses de ce quartier, plongées dans l'ombre de la tour Maulmont furent, selon ses évocations dans "Quadrille sur la tour" et "L'Enfant double", le terrain de jeux d'enfant de l'écrivain poète Georges-Emmanuel Clancier. "Le Quartier noir", entre le "Fort" et le cours de la Tardoire, renforcé par le tracé de l'actuelle route d'Oradour, abrita sur les berges de l'étang de la Fabrique, la dernière forge de Châlus. Le quartier de "la Place du Marché", qui va de la place de la fontaine à la route du Châtaignier, était le lieu des anciennes halles. Sa partie basse, rebaptisée récemment « rue du Marché », était autrefois le marché aux cochons. "Le Pont", sous lequel coule la Tardoire, est situé au carrefour des routes de Rochechouart à Saint-Yrieix et de Limoges à Périgueux. "Le Champ de foire" date de 1833, année au cours de laquelle, pour la première fois, ce lieu fut mis à disposition des marchands de bestiaux par la municipalité pour accueillir les foires de la Saint-Michel et de la Saint-Georges, qui se tenaient traditionnellement sur les anciennes terres de l'abbaye de l'Abeille.

Les noms de ces quartiers anciens restent des repères usuels, alors que ceux des rues ne sont d'usage courant que pour les plus anciennes, comme Salardine ou Mardochée.

Des quartiers plus récents complètent la zone agglomérée. Ils s'étendent, de part et d'autre des deux pôles historiques, aux lieux et sur les terres d'anciens villages, rattrapés par l'urbanisation. C'est le cas, par exemple, des villages des "Mettes", des "Granges", des "Places", du "Nid", du "Bosfranc", qui constituaient au une seigneurie (Jean de Brie en était seigneur en 1451) ou de "La Tranchardie", ancienne seigneurie de la paroisse de Lageyrat dont le titulaire était, en 1587, Jacques des Champs, conseiller et secrétaire du roi de Navarre, trésorier et receveur général du Limousin et Périgord.

La construction, au , de la nouvelle route d'Oradour, qui aboutit en ville au quartier du "Pont", et la postérité de l'axe routier Limoges - Périgueux, excentré par rapport au "bourg" sont à l'origine de la transformation de quartiers, qui, tels "La Ville haute" puis "Le Fort", très marchands au , sont exclus des zones de passage. Les quartiers commerçants, qui n'offrent que très peu de parkings et des rues étroites, se réduisent aujourd'hui à la "rue Salardine", à la "rue Nationale" et à la partie haute de la "place du Marché", dénommée "place de la Fontaine".

Les hameaux, appelés « villages » en Limousin, se présentent traditionnellement sous la forme du regroupement serré de quelques habitations intergénérationnelles, d'une ou deux granges et d'un puits, auxquels est souvent adjoint un séchoir à châtaignes appelé "clédier". Ces bâtiments sont posés sans recherche de parallélisme, sans rue ni organisation structurée apparente, mais autour ou à proximité d'un espace public partagé : le "coudert". Livré aux animaux de basse-cour (cochons, volailles), ce dernier fait également usage de « place publique », de lieu de sociabilité du village.

Si, à l'exception de ceux qui sont situés le long des routes principales, les villages présentent les caractéristiques d'un habitat rural dispersé, ils s'organisent en fait le long d'anciens axes de circulation, aujourd'hui peu usités. Ainsi, "les Pièces", "le Lac", et "la Plagne" sont sur l'ancien itinéraire qui menait à l'abbaye de Thavaud (commune de Dournazac), ruinée par les guerres de religions. "La Grande Vergne", "la Petite Vergne" et "la Gratte", qui apparaissent aujourd'hui en marge de la route Châlus-Dournazac, sont d'anciennes étapes d'une voie reliant Châlus Chabrol au château de Montbrun (commune de Dournazac). "Fontvieille" et "les Jarosses" sont des étapes d'un itinéraire médiéval reliant l'ancienne paroisse de "Lageyrat" à "Latterie" (commune de Dournazac). Selon la même démonstration, "la Besse", qui était le lieu d'un pont en bois sur la Tardoire, et "les Courrières", aujourd'hui isolées, sont à rattacher à un ancien itinéraire Châlus-Lageyrat. Enfin, "Loriol", isolé dans les bois, était, comme "les Gannes", à proximité du grand chemin d'Oradour, avant que la route actuelle, qui contourne le promontoire de Châlus Chabrol, n'ait été ouverte au milieu du .

Certains villages, tels "les Maisons", ne donnent pas directement sur la voie principale et ne sont accessibles que par un chemin à usage privatif. Cette configuration en retrait de l'axe routier, maintenant une certaine distance entre le village et la route, visait à prévenir les villageois de l'insécurité qui régnait sur les chemins limousins durant la majeure partie de l'époque médiévale. Pour la même raison, d'autres hameaux, dont "Puy Gris", "le Roulle" ou "le Puy de Lageyrat", sont construits, malgré leur exposition aux vents, sur les lignes de crête que suivaient préférentiellement les vieux chemins (les "pouges").

Parmi les hameaux notables, "le Châtaignier" est un village où un trésor monétaire a été fortuitement découvert en 1963-64. "Le Mazaubrun" est une ancienne seigneurie, qui présente la particularité d'avoir conservé trois de ses mottes féodales. Le hameau des "Quatre-Vents" est, à , le lieu-dit le plus élevé de la commune, à égalité parfaite avec la borne du Bois de Piolet qui marque la limite entre Châlus et Dournazac.

Depuis la Révolution française, du fait d'une évolution territoriale qui lui fut systématiquement favorable, Châlus s'est enrichi de . En 1790, date de création du canton de Châlus, la commune de "Lageyrat" a fusionné avec celle de Châlus (la paroisse de Lageyrat, dite paroisse Saint-Étienne, dont Châlus-bas dépendait depuis 1498, subit le même sort, en 1806). En 1959, "la Borie", "l'Age", "Landrevie", "Bouchetort", "le Mazaubrun", "Chareilles" et "la Petite Jaline", détachés de la commune de Pageas, sont rattachés à Châlus. En 1966, à la demande de leurs habitants, ce sont "Chanteloube", "la Grande Vergne", "la Petite Vergne", "le Bos", "Fantaisie", "la Gratte", "Gouhaud", "la Gareille", "le Lac" et "le Petit Lac" qui sont soustraits du territoire de Dournazac et rattachés à la commune.

Depuis la fin du , les villages de la commune bénéficient d'un phénomène de rurbanisation, lié à l'établissement de populations d'origine anglo-saxonne ou autochtone, et travaillant sur les bassins d'emploi d'Aixe et de Limoges.

Châlus porte le nom de "Chasluç" en limousin, un dialecte de l'occitan. Localement, en patois châlusien, le nom de la ville se prononce « Chèlu », comme l'illustre peut-être déjà la mention portée sur un dessin de 1700, représentant le château de Châlus en 1460.

La première mention de Châlus apparaît dans la "Vita Brevior" de saint Waast, rédigée au , lequel serait né en un lieu appelé "Leucus", qui pourrait être Châlus, alors issu de "Castrum Leucus". Ensuite, on trouve les formes "Castel Lucius" et "Castelluccio" citées dans deux chartes du cartulaire de l'abbaye de Beaulieu de 885.

Les érudits des siècles antérieurs au utilisent des faits historiques, plus ou moins avérés, pour en déduire l'étymologie de Châlus. Ainsi, Jourdain de la Fayardie, archéologue des monuments antiques de Périgueux attribue vers 1750 la fondation de Châlus, comme celle d'un lieu-dit "Châlus" situé près de Montpont en Dordogne, à Lucius Munatius Plancus. Il se base en effet sur la latinisation médiévale artificielle "Castel Lucius".

D'autres développent leurs hypothèses à partir du nom de Châlus Chabrol, tout en ne tenant compte également que de la forme ancienne "Castel Lucius", complétée d'une hypothétique forme ancienne "Capreolus" pour expliquer Chabrol. Ces deux mots mis côte-à-côte contiendraient le nom d'un romain, Lucius Capreolus, proconsul d'Aquitaine sous Auguste (et petit-fils du proconsul Duratius) et Châlus Chabrol aurait été anciennement le "Castrum Lucius Capreolus"
. Ce dernier terme latin a par ailleurs donné le terme occitan limousin "chabrol" « chevreuil », à l'origine du patronyme Chabrol. Cette croyance était renforcée par une légende, selon laquelle les terres de Châlus recèlent un trésor, constitué d'une collection de statues en or grandeur nature représentant la famille de Lucius Capréolus, et qui aurait été la cause du siège de Châlus par Richard Cœur de Lion. Les quilles du blason de la ville, représentant le proconsul romain Capréolus et sa famille, reprennent cette légende. Pour d'autres, l'élément "Chabrol" correspond au nom commun chèvre (chevreuil), du fait que le château est posé sur un site escarpé et qu'un chemin de chèvres y menait... ou que seules les chèvres pouvaient y monter. Ces spéculations anciennes sont remises en cause au moins à partir de 1854.

Châlus est une contraction de "Chastelus". Ce toponyme correspond à un type occitan, issu du gallo-roman méridional "castelluciu", composé apparent des éléments "castellu", château, et du suffixe "uciu", analysé par Auguste Longnon, Albert Dauzat et Charles Rostaing qui citent le bas latin "castellucium", dérivé de "castellum" « fort » avec le suffixe "-ucium".

Le nom du premier château de Châlus est attaché à celui du chevalier Bernard Chabrol qui le construit au , sur la base de vestiges plus anciens, et sur demande du vicomte de Limoges. De même Châlus Maulmont vient de Géraud de Maulmont, qui fait construire ce château en 1275, en même temps qu'il agrandit Chalucet.

L'omniprésence de l'eau sur le territoire communal se traduit dans la toponymie de nombreux lieux-dits, comme l'illustrent Fonvieille, issu de l'occitan "font viélha" « vieille source », la Ribière de "ribièra" « terrain près d'un cours d'eau, d'une zone humide », Les Courrières directement issues de "courrièra", « rigole d'écoulement, ravine » ou Buas, qui est un féminin pluriel, peut-être dérivé du francique "buka" signifiant « cruche, conduite d'eau, lavoir ».

Les mégalithes retrouvés sur la butte de Châlus Chabrol confirment une occupation humaine du promontoire de la Ville Haute dès le néolithique.

À l'est du bourg, sur le plateau du lieu-dit les Quatre-Vents, à cheval sur les bassins hydrographiques de la Loire, de la Charente et de la Dordogne, un important carrefour de six grands chemins protohistoriques a été identifié. Ses voies principales menaient, au sud-ouest, "via" Lageyrat, vers Cassinomagus (Chassenon) ; au nord, par le Tuquet de la Garde où un raccordement se faisait avec une voie venant du Haut Châlus, vers le Jutland (pays de l'ambre) ; au sud, par le village de la Petite-Jaligne, vers l'Espagne et, au nord, par le village de la Garenne, vers Limoges.

L'époque gallo-romaine a également laissé des tessons de poterie et des tesselles de mosaïque trouvés en 1949 à Lageyrat, ainsi qu'une voie romaine qui reliait Vésone (Périgueux) à Augustoritum (Limoges) et comportait une station "Fines" (frontière), située entre Firbeix et Châlus

Des armes, caractéristiques de l'époque mérovingienne ont été découvertes sur le site à proximité de la base ouest du château par le commandant Teillard lors de sa campagne de fouilles de 1926.

C'est au Moyen Âge, période au cours de laquelle Châlus connaît quatre sièges, que l'histoire locale est la plus riche, du fait de sa position stratégique entre le Limousin et l'Aquitaine et de la lutte pour le contrôle de ces territoires à laquelle se livrent alors les rois de France et les ducs d'Aquitaine, également rois d'Angleterre.

Châlus-Chabrol est érigé au , sur l'initiative des vicomtes de Limoges, afin de contrôler l'itinéraire de Limoges vers le Périgord, détournant ainsi la voie qui menait de Bourges à Bordeaux et passait alors par Lastours. La création d'une abbaye dépendant des augustins de Limoges à proximité du château de Châlus Chabrol, alliée à la fréquentation du nouvel itinéraire Limoges -Périgueux "via" Châlus et Aixe (qui reprenait en grande partie un itinéraire antique), entraînent le développement du bourg castral (Châlus haut). Les moines organisent des foires, dont la Saint-Georges et la Saint-Michel, qui se tiennent encore en 2009 à Châlus, et qui furent un temps parmi les plus réputées de France pour le commerce de chevaux.

En 1193, Châlus connaît son premier siège. Le château, comme d'autres places limousines, est pris et pillé par des soldats brabançons, en guerre contre Sébrand Chabot, l'évêque de Limoges.

En 1199, lors du second siège de Châlus Chabrol, Richard Cœur de Lion meurt. C'est un événement historique de premier plan pour la politique européenne, qui va permettre au capétien Philippe Auguste d'accroître considérablement le territoire du domaine royal, posant les fondements du futur territoire national.

Châlus connaît son troisième siège en 1265. Mené par Bozon de Bourdeilles, qui conteste à Adémar de Maulmont ses droits sur la place, il aboutit à l'occupation de Châlus par Bozon et à l'exécution d'Adémar de Maulmont.

En 1280, le fils d'Adémar, Géraud de Maulmont, chanoine de Limoges et chapelain du roi, récupère la terre et la juridiction de Châlus Chabrol qu'il reçoit en fief d'Arthur de Bretagne et de Marie de Limoges, en reconnaissance du service rendu par son jugement arbitral de 1276, favorable à la vicomtesse, par lequel il réglait les droits respectifs de celle-ci et de la ville de Limoges. Après avoir pris possession de Châlus en armes, accompagné de plusieurs gens de guerre en raison d'un différend avec Aymard, comte de Rochechouart (Aimery , dans la lignée des vicomtes de Rochechouart), relatif à la justice du bourg d'Oradour, revendiquée par l'un et l'autre, Géraud de Maulmont fait construire, face à Châlus Chabrol, un second château : Châlus Maulmont.

En 1307, une contestation entre les héritiers de Géraud de Maulmont offre l'occasion à Philippe le Bel de se rendre acquéreur des châteaux de Châlus. Traitant par échange avec Guillaume de Chanac, exécuteur testamentaire, il acquiert le comté de Bourdeilles, les châtellenies de Châlus Chabrol et de Chalusset, donnant en place aux héritiers Maulmont les seigneuries de Châteauneuf dont le château de Tournoël en Auvergne et de Moret dans ce qui est alors le diocèse de Sens. La validité de cet échange est affectée par la violation de l'acte de donation du comté de Bourdeilles établi en 1283 entre les religieux de Brantôme et Géraud de Maulmont. Une clause de cet acte de donation de 1283 (mentionné par Bernard de Maulmont, abbé de Brantôme et frère de Géraud, en août 1294) prévoyait le gré et l'autorisation de l'abbé et du couvent pour transférer Bourdeilles en des mains plus puissantes, ce qui ne fut pas respecté lors de ces échanges. Le rattachement de Châlus à la France est donc irrégulier au regard du droit féodal (les recours sont toutefois prescrits).

En 1406, Châlus connaît son quatrième siège. Comme Brantôme, la ville est alors prise par des troupes françaises, conduites par Guillaume Le Bouteiller, en campagne contre les Anglais en Guyenne et au Limousin.

 Lors des guerres de religions, en 1569, l'armée de Coligny (qui compte dans ses rangs le futur Henri alors âgé de et son (futur) écuyer, Agrippa d'Aubigné), se regroupe avec les mercenaires du duc de Deux-Ponts, Wolfgang de Bavière et occupe Châlus et ses environs, avec . Les deux châteaux, le bourg et les environs de Châlus hébergent alors les de l'armée protestante regroupée. À 30 kilomètres de là, en avant de Saint-Yrieix campent les troupes royales, à peu près aussi nombreuses, dirigées par le duc d'Anjou. Les deux armées s'affrontent le à la Roche l'Abeille. Coligny fait prisonnier le condottiere Philippe Strozzi, met en déroute l'armée royale et s'ouvre ainsi la voie du Périgord.

Après cinq années de répit, les guerres entre seigneurs, nobles huguenots et catholiques, reprennent. Elles vont durer encore deux décennies. C'est dans ce contexte, qu'en 1592, Châlus connaît un cinquième siège, mené par Chamberet, gouverneur du Limousin, qui, avec le comte de Busset, sieur de Châlus, et d'autres nobles, assiègent Châlus, bombardent, avec le canon de Limoges
, son fort défendu par le capitaine Labesse, et s'en rendent maîtres. La ville basse, au prix de meurtres perpétrés dans l'église, est prise par les troupes du vicomte d'Aubeterre, et les sieurs de Lavauguyon, de Palissand et d'Oradour, sollicités par le comte de Busset.

En 1594, les paysans, lassés de ces guerres intestines entre nobles catholiques et protestants, de la destruction des récoltes, des arrestations arbitraires et de l'insécurité, se révoltent et prennent les armes. Cette révolte paysanne, à mettre en parallèle avec les Jacqueries des croquants, est sévèrement réprimée par les hommes du gouverneur du Limousin.

Selon l'état des paroisses, en 1688, Châlus Haut et Châlus Bas sont encore un lieu d'étape pour la maréchaussée de la vice-sénéchaussée de Limoges. La ville est décrite comme « bien foulée de gens de guerre », et ses « habitants sont fort fatigués » et « ruinés par le moyen des gens de guerre ».

Au , Châlus se développe grâce à l'élevage bovin et à ses foires. La ville devient un lieu de rencontre dont la renommée dépasse celle du canton, avec des effets sociaux induits, tels la transformation des cafés et auberges en tripots. Le phénomène devient si important qu'il conduit, en 1845, au recrutement par le conseil municipal d'un commissaire de police pour remédier aux désordres entraînés par « "la passion du jeu, qui a valu à Châlus une triste célébrité" ».

Durant la Première Guerre mondiale, en 1917, des troupes américaines stationnent à Châlus et entretiennent des contacts avec la population. La tradition rapporte que les soldats américains dynamitèrent le rocher de Richard Cœur de Lion afin d'en ramener une portion aux États-Unis. Elle rapporte également qu'une réfugiée alsacienne provoqua un scandale public en adressant à celui qui venait d'attenter à sa réputation : « Ose une fois répéter que tu m'as vu me faire biquer par un Américain ! ».

Au cours de la Seconde Guerre mondiale, en juin 1944 alors que les activités de la Résistance s'intensifient, le délégué militaire interdépartemental des Francs-tireurs et partisans, le commandant, puis lieutenant-colonel commandant interrégional adjoint des Forces françaises de l'intérieur, Louis Godefroy, alias Rivière, s'installe à Châlus. Le 12 juillet, un combat implique le maquis Bir-Hacheim et notamment Roger River. Le 16 juillet, le capitaine Jacques Nancy et les de sa section spéciale de sabotage stoppent un train blindé en provoquant la destruction du viaduc de chemin de fer.

En 1994, la tour de Châlus Maulmont s'effondre partiellement. La même année, le château de Châlus Chabrol quitte le patrimoine familial des Bourbon-Châlus, qui le détenaient depuis 1530.
L'électorat de la commune est marqué, à l'image du Limousin, par une domination de la gauche socialiste et l'influence communiste. Ce recouvrement idéologique traduit une superposition anthropologique des structures familiales de type souche et de type communautaire, correspondant dans le domaine agraire, à la juxtaposition de la propriété paysanne et du métayage, selon l'analyse développée par Emmanuel Todd. Châlus appartenant à l'espace déchristianisé du centre
, la droite laïque a, traditionnellement, une audience relativement limitée.

Les résultats électoraux de l'élection présidentielle de 2007 illustrent bien l'ancrage à gauche de l'électorat. Au premier tour, totalisant 32,49 % des suffrages, contre 25,87 % seulement au niveau national, Ségolène Royal se positionne devant Nicolas Sarkozy lequel rassemble localement 24,58 % des électeurs, contre 31,18 % en moyenne nationale. Lors du second tour, Nicolas Sarkozy, élu président de la République avec 53,06 % des suffrages nationaux, en recueille 42,75 % sur Châlus. Son opposante, Ségolène Royal, qui totalise quant à elle 46,94 % des voix au niveau national en obtient 57,25 % à Châlus. L'ancrage à gauche s'est également exprimé en 2002 lorsque, au premier tour de l'élection présidentielle, Jacques Chirac arrive en tête (23,24 %), tout juste suivi de Lionel Jospin (22,88 %). Du fait des résultats nationaux de Lionel Jospin, le second tour, qui oppose dans un duel électoral imprévu Jacques Chirac à Jean-Marie Le Pen (lequel n'a pas dépassé les 10 % à Châlus au premier tour) se traduit localement par un fort recul de l'abstention (15,47 % le jour du scrutin, contre 21,4 % au premier tour) et une mobilisation extrêmement importante de l'électorat en faveur de Jacques Chirac (88,11 % des bulletins exprimés).

Lors des scrutins concernant l'Europe, les Châlusiens votent conformément aux résultats nationaux, en les amplifiant légèrement. Ainsi, lors du référendum du 20 septembre 1992 pour l'adoption du traité de Maastricht, les Châlusiens votent « OUI » à 52,47 % (contre 51,04 % de « OUI » au niveau national) et lors du référendum sur la Constitution européenne du 29 mai 2005, ils votent « NON » à 59,86 %, soit plus fortement que l'ensemble du corps électoral français, qui s'est prononcé pour le « NON » à 54,68 % seulement.

Les élections européennes de 2009, dont les résultats doivent être appréciés à l'aune d'une abstention record (49,93 %), restent en conformité avec la tradition électorale châlusienne et donnent 29,19 % à la liste du parti socialiste, 24,42 % à la liste UMP, 9,68 % à la liste Front de gauche, 9,06 % à la liste Europe Écologie, 7,07 % à la liste du NPA et 5,99 % au MoDem. Les autres voix se partagent entre la Liste Écologiste indépendante (3,99 %), la liste Libertas (3,84 %), et les autres listes (dont le FN et LO), qui recueillent toutes moins de 3 %.

Lors des cantonales de 2008 (canton de Châlus), qui connaissent un taux d'abstention de 27 %, le Châlusien Jean-Claude Peyronnet, candidat du parti socialiste, est élu dès le premier tour. Il obtient 63,51 % (63,09 % sur la commune), face aux deux autres candidats : Jacques Maisongrande du parti communiste (20,78 % et 22,89 % sur la commune) et Marie-Louise Couade du Front national (15,70 % et 14,02 % sur la commune).

Les élections municipales sont traditionnellement, et depuis les années 1970, favorables aux listes agréées par le parti socialiste, allié au parti communiste, au point que dans les années 1980, la droite ne présente plus de liste. En 2008, le scrutin porte cependant une nouvelle équipe, sans étiquette, à la mairie.

Châlus est située dans le département de la Haute-Vienne, en région Nouvelle-Aquitaine et dans l'arrondissement de Limoges. De 1790 à 2015, elle est le chef-lieu du canton de Châlus. Pour les élections départementales de mars 2015, le nombre de cantons du département est divisé par deux, passant de 42 à 21. Le canton de Châlus disparait et la commune est alors rattachée au canton de Saint-Yrieix-la-Perche.

La commune de Châlus a d'abord fait partie de la communauté de communes du pays de Châlus. Fin 2001, cette dernière est remplacée par la communauté de communes des monts de Châlus.

Au , la communauté de communes des monts de Châlus est dissoute et ses communes sont désormais rattachées à la communauté de communes Pays de Nexon-Monts de Châlus.

Châlus relève du « Pays d'ouest Limousin », échelon de coopération entre collectivités locales, issu de la loi d'orientation pour l'aménagement et le développement du territoire du , complétée par la loi du dite loi Voynet. Il regroupe , répartis sur 46 communes et six communautés de communes : Feuillardiers, Monts de Châlus, Pays de la Météorite, Val de Vienne, Vallée de la Gorre et Vienne-Glane.

Châlus est située, pour l'intégralité de son territoire communal, dans le parc naturel régional Périgord-Limousin, établissement public créé en 1998 pour protéger et mettre en valeur un grand espace rural de sur et qui réunit (plus un « territoire associé », les lacs de Haute-Charente), deux départements (Dordogne et Haute-Vienne), et anciennement deux régions, l'Aquitaine et le Limousin, fusionnées en une seule en 2016 : Nouvelle-Aquitaine.

Selon ses deux principes fondamentaux et , le parc a pour vocation de protéger et valoriser le patrimoine naturel, culturel et humain de son territoire en mettant en œuvre une politique innovante d'aménagement et de développement économique, social et culturel.

Ses actions ont également pour but la valorisation des ressources locales dans une perspective de développement durable, l'amélioration de la qualité de l'eau et des hydrosystèmes à l'échelle des trois têtes de bassins versants du Périgord-Limousin, la préservation de la biodiversité et la lutte contre le réchauffement climatique.

Le siège de cet établissement public, qui s'attache à dynamiser l'identité et les liens sociaux du Périgord-Limousin, est situé au château du Mas-Nadaud à Pageas.

Six maires ont été élus à Châlus depuis 1945 :

De 1530 et jusqu'à la Révolution, Châlus était administrée depuis le château de Châlus Chabrol par les comtes de Bourbon-Châlus. La première municipalité date de 1792. Depuis 1945, deux mandatures successives ne sont pas arrivées à leur terme : 1971-1977 et 1977-1983. Robert Dolier est décédé en cours de mandat en 1975 et son adjoint, André Mazière, élu pour finir la mandature en cours (1971 - 1977) et réélu pour la mandature suivante (1977 - 1983), décède en 1981, également en cours de mandat. Pierre Charissou est élu par élections complémentaires des 15 et 22 février 1981 pour finir la mandature.

Le terrain de football porte le nom de stade Robert-Dolier. Le nom d'André Besse a été donné à l'ancienne avenue du champ de foire. Antoine Hallary, Jacques Garebeuf et François Romain ont chacun une rue à leur nom.

Située dans l'académie de Limoges, la ville administre une école maternelle de 50 élèves, ainsi qu'une école élémentaire de 55 élèves. Le département gère un collège de 260 élèves, situé à proximité immédiate.

La garderie périscolaire municipale peut accueillir 30 enfants et 12 assistantes maternelles opèrent sur la commune, qui dispose également d'un centre de loisirs sans hébergement.

Les trois établissements scolaires sont regroupés au sein du « groupe scolaire Pierre-Desproges ». Le collège entretient des relations d'échanges d'élèves avec la Staatliche Realschule de Roth (Moyenne-Franconie, Allemagne) depuis 1991. Outre l'allemand, l'anglais et l'espagnol, l'occitan y est enseigné. Les résultats au diplôme national du brevet ont fluctué de 81,4 % en 2003 à 79,6 % en 2007

Fin 2009, une quarantaine de structures agissent dans les secteurs de l'action sociale, de la culture, du sport, ou des loisirs et s'impliquent dans la vie associative, jugée particulièrement dynamique.

Un club de tarot organise un festival annuel, doté d'un prix du conseil général et d'un prix de la commune.

L'académie cyclopédique s'efforce de promouvoir la culture régionale et l'esprit châlusien, celui de Pierre Desproges. Elle organise, à Paris et localement, des animations et événements culturels, tels qu'une évocation de l'histoire cycliste de Châlus, présentée à Paris, à la Maison du Limousin, dans l'exposition "Limousin terre de cyclisme", un concours de construction de catapultes à fromage mou, et des soirées cabaret au bar restaurant concert « Le Lawrence d'Arabie ».

Depuis 2007, le festival « Bouge Ton Zinc », qui se déroule dans l'ensemble des monts de Châlus, a pour objet l'organisation de fêtes et concerts dans les bistrots. Il affiche à ce titre, et avec le soutien actif du monde associatif, une programmation éclectique de groupes de pop-rock-jazz et de spectacle vivant.

Ce dynamisme associatif est présent de longue date sur la commune puisque dès 1957, un festival départemental donna lieu à la frappe du seul exemple connu de création numismatique spécifique à Châlus. Cette vitalité s'exprime également par l'organisation d'événements ponctuels tels les manifestations de la célébration du huitième centenaire de la mort de Richard d'Angleterre en 1999, l'accueil de la félibrée (qui s'est déroulée pour la seconde fois à Châlus en 2007) ou celui du Tour cycliste du Limousin ainsi qu'à l'occasion de la fête patronale, qui se tient le troisième week-end de juillet, et se conclut par un feu d'artifice le dimanche soir. L'esprit festif, particulièrement en période estivale, génère de multiples manifestations du Comité des fêtes, dont une course de voitures à pédalier, ou « Le retour du roi Richard ».

Châlus bénéficie des équipements administratifs traditionnels d'un ancien chef-lieu de canton, tels que trésorerie, brigade de gendarmerie et bureau de poste.

Les locaux mis à la disposition des associations et des habitants sont une salle des fêtes polyvalente ( assises), la salle de l'ancienne école de Lageyrat (), la salle de l'ancienne gare et un "Mille clubs" (modèle « DC 333 » conçu en 1968 par la société De Coene), dont l'aspect a été modifié par des opérations d'entretien et de mise aux normes, mais dont l'intérêt patrimonial s'accroît avec la disparition de ces structures.

La liste des équipements présents sur la commune est complétée par une bibliothèque municipale, intégrée au réseau de bibliothèques de la communauté de communes des monts de Châlus, un centre de secours et de lutte contre les incendies, deux cimetières (l'un en ville, l'autre au village de Lageyrat), une déchèterie éclairée par électricité photovoltaïque, un atelier technique et un dépôt de la Direction départementale de l'Équipement et de l'Agriculture.

L'ensemble du territoire de la commune est desservi par l'ADSL. Toutefois, les villages et hameaux éloignés de plus de des centraux sont affectés par une réduction des performances de l'internet haut débit.

Un centre de soins infirmiers de la Croix-Rouge française assurant un service de soins à domicile, ainsi qu'un centre du Secours catholique sont présents sur la commune. Une pharmacie et plusieurs professionnels libéraux de santé complètent l'équipement médical local.

Le centre hospitalier le plus proche est le centre Jacques-Boutard à Saint-Yrieix-la-Perche, le centre de convalescence et de réadaptation est celui de "La Chesnaie" à Verneuil-sur-Vienne, le centre hospitalier universitaire, celui de Limoges.

Pour répondre aux problématiques du vieillissement de la population, renforcé par l'allongement de la durée de la vie, Châlus dispose, avec l'Association de Coordination des actions en faveur des personnes âgées du canton de Châlus (ACAFPA), d'un réseau gérontologique permettant de coordonner la prise en charge des personnes âgées à domicile. Ce réseau local, intégré au Centre local d'information et de coordination (CLIC) du val de Vienne et des monts de Châlus dont la mission est de développer la collaboration en matière d'intervention en faveur des personnes âgées, compte parmi les plus anciens et a servi d'exemple à de nombreuses structures de coordination gérontologique.

Depuis 1970, Châlus dispose d'une maison de retraite médicalisée de 123 places, la "Résidence Le Nid", qui est également établissement d'hébergement pour personnes âgées dépendantes (EHPAD).

Au bas du village de vacances "La Sapinière", qui compte , la commune dispose d'un Parc des sports. Il comprend un terrain de football avec tribunes et vestiaires, un gymnase, un tennis, un mini-golf, et une piscine (creusée par des prisonniers allemands et inaugurée en 1946), dotée de trois bassins et d'un solarium. Ces équipements sportifs ou de loisir sont complétés par quatre terrains de pétanque et deux terrains de boule lyonnaise, situés sur le boulodrome de l'ancien champ de foire.

Les associations sportives, de football, de gymnastique, de basket-ball (Mont Châlus Basket Ball), de judo, de boule, de tennis ou de pétanque bénéficient d'un parc des sports, d'une salle omnisports et d'un boulodrome. La Gaule Châlusienne regroupe les amateurs de pêche.

Si aucune rédaction ou agence locale de presse écrite n'est installée sur la commune, des correspondants relaient les informations locales pour trois journaux de la presse quotidienne régionale : "L'Écho du Centre", "Le Populaire du Centre" et "La Montagne". Trois publications sont éditées à Châlus : le "Bulletin municipal", le bulletin paroissial "En Veillée" édité depuis 1946 et, depuis 2001, le "Bulletin de l'association Histoire et archéologie du Pays de Châlus".

Les radios locales captées sur la commune sont "RTF", "Kaolin FM", "Radio Vassivière" et "Radio PAC". Depuis l'interdiction de "Radio Coulgens" en 1996 et les déboires de "Radio Diffusion charentaise (RDC)" qui avait pris son relais, "RTL" est la seule radio à être diffusée en modulation de fréquence depuis l'antenne de TDF située sur le territoire communal.

Bénéficiant de la présence, sur la commune voisine des Cars, d'un émetteur de télévision de forte puissance diffusant les programmes nationaux ainsi que le décrochage local de France 3 Limousin Poitou-Charentes, la télévision numérique terrestre est disponible sur la commune depuis 2010.

Le site Internet de la communauté de communes des monts de Châlus a son siège et sa rédaction à Châlus.

La commune de Châlus relève de la paroisse catholique Saint-Joseph des feuillardiers, qui est une subdivision du diocèse de Limoges, lequel relève de la province ecclésiastique de Poitiers. La paroisse Saint-Joseph des feuillardiers regroupe sept communes et neuf clochers, dont deux sont situés sur la commune : celui de Notre-Dame-de-l'Assomption dans le bourg, et celui de Saint-Étienne de Lageyrat, dont la sainte patronne est sainte Quitterie.

Fin 2009, en l'absence de prêtre résidant à Châlus, l'animateur de l'équipe pastorale, responsable de paroisse, est un laïc.

Une communauté d'ursulines, dite « ursulines de Chavagnes », réside au presbytère, précédemment occupé par des pères jésuites, où elle anime un lieu source et de prière.

L'église du Haut-Châlus, incluse dans la propriété du château de Châlus-Chabrol et qui recèle les entrailles de Richard Cœur de Lion, est aujourd'hui en ruines. La chapelle Séchaud, n'est qu'exceptionnellement un lieu où la messe est célébrée. Un bras reliquaire étant conservé au presbytère, tout comme une statue de sainte Quitterie, des ostensions pourraient être organisées à Châlus.

Le culte des « Bonnes fontaines », autrefois particulièrement développé, de nature religieuse et préexistant aux cultes chrétiens, semble conserver quelques adeptes, sans que la part relevant du folklore ou de la superstition puisse être établie.

Les Témoins de Jéhovah disposent d'un local à Puybos.

L'activité économique de Châlus se caractérise par la présence de deux activités traditionnelles, la transformation du bois de châtaignier et l'élevage.

Le travail du bois de châtaignier, « arbre à pain » ou « arbre du pauvre » introduit massivement en Limousin au , est à l'origine d'un métier spécifiquement local, qui apparaît vers 1850 : le feuillardier. Ces ouvriers du monde rural, parfois saisonniers, travaillent sur des chantiers d'exploitation de taillis pour des propriétaires forestiers ou des marchands de bois. Travaillant en forêt, dans des loges-ateliers qu'ils construisent eux-mêmes, ils coupent les jeunes barres de châtaigniers qui poussent en « cépée », c'est-à-dire en couronne autour de ce qui aurait pu être le tronc (le cep) de l'arbre s'il n'avait été systématiquement rabattu. Ces tiges, appelées « feuillards » car trop jeunes pour donner des châtaignes et donnant juste des feuilles, sont écorcées ou non selon l'ouvrage définitif, puis coupées en deux dans le sens de la longueur. Les feuillards ainsi travaillés servent à la confection de cercles de barrique, de panier à crustacés, de piquets (dont carrassones et échalas pour les vignes) ou des lattes. Œuvrant en extérieur, sans outillage mécanique, le feuillardier passe beaucoup de temps à entretenir les taillis, préparer les nouvelles cépées, à tailler, à ranger et à porter, tout en étant payé à la pièce ou au mille feuillards produits. Ces rudes conditions de travail et de rémunération ont généré, au début du , d'importants mouvements sociaux, comparables à ceux des ouvriers de la porcelaine, bien que le syndicat des feuillardiers de Châlus, possédant une forte personnalité, n'était pas toujours en accord avec les décisions des autres sections syndicales. Si le métier de feuillardiers a pratiquement disparu, la transformation du bois de châtaignier reste un secteur économique important à Châlus, où se tient tous les ans le seul salon de France entièrement et exclusivement consacré à la promotion du bois de châtaignier. Baptisé « Châtaignier en projet(s) » et organisé par le parc naturel régional Périgord-Limousin et la ville de Châlus, ce salon, qui vise à valoriser et moderniser l'image du produit en châtaignier, se veut être un rendez-vous pour toute la filière.

L'élevage est l'autre activité économique traditionnelle de Châlus dont la situation de carrefour de routes et de frontière entre régions différenciées par la géographie physique et humaine, lui permit, au moins depuis le , de jouer un rôle commercial important avec la tenue de foires et marchés renommés qui constituèrent l'élément majeur de son développement économique jusqu'à la fin du .

C'est à ces foires et marchés, que Châlus doit le rôle de petite capitale économique qu'elle connut sous l'Ancien Régime, rôle mis en évidence par les différentes unités de mesure propres à Châlus, et dont les valeurs étaient en usage dans des aires d'influence aux contours variables, dans les monts de Châlus ou au-delà. La setérée de Châlus, unité de mesure de superficie valait . Elle fut utilisée jusqu'au milieu du à Châlus, Marval, Pensol, La Chapelle-Montbrandeix, Milhaguet, Boubon, Saint-Léonard, etc. Elle se divisait en deux héminées, l'héminée en deux quartes, la quarte en quatre coupées. À partir de 1750, la setérée de (divisée en 50 perches de 20 pieds de côté) s'y substitue jusqu'à la généralisation du système métrique. La pinte de Châlus, unité de mesure de capacité de matière liquide, contenait . Le setier de Châlus, unité de mesure de capacité de matière sèche, valait de grain.

Le déclin des foires à chevaux au , puis l'évolution plus récente du commerce de bétail a entraîné la fin des foires à bestiaux. Plus récemment encore, la construction de deux supermarchés a réduit le poids relatif des marchés.

Au début du , Châlus est un pôle de services intermédiaires, dont le nombre d'établissements actifs s'élève, au , à 155. Ces établissements sont répartis, pour 7,1 % dans l'industrie, 7,1 % dans la construction, 25,8 % dans le commerce et 60,0 % dans les services.

La fonction industrielle est axée sur l'appareillage électrique d'installation, la transformation du bois-ameublement, le bâtiment et l'exploitation du bois de châtaignier. L'usine de construction électrique du groupe Legrand est le premier employeur. Elle est spécialisée notamment dans la réalisation des corps de cartouches fusibles en cordiérite et emploie . L'essentiel des terrains de la zone économique de Fontanilles, qui regroupe cinq établissements et , ayant été vendu, une réflexion, menée dans le cadre de la Communauté de communes des monts de Châlus et visant à créer un second parc d'activités, est en cours en 2009.

L'activité agricole reste importante, bien qu'entre 1988 et 2000 le nombre d'exploitations agricoles soit passé de 68 à 47 (de 27 à 19 pour les professionnelles). La surface agricole utile atteint , pour 53 unités de travail (dont ). Le cheptel bovin dépasse et sur 10 sont de race limousine. Les exploitations ont dans l'ensemble une orientation bovin-viande au nord de la commune, le sud étant plutôt inclus dans un système agro-forestier avec une zone de polyculture-élevage, orientation bovin traditionnel.

Châlus est classée en zone de revitalisation rurale. Elle bénéficie à ce titre des mesures fiscales favorisant son attractivité et le développement de son économie. Elle est par ailleurs classée dans les communes touristiques ouvrant droit aux réductions d'impôt pour investissements locatifs dans le secteur du tourisme, qui peuvent atteindre sur .

Les projets communaux reposent en premier lieu sur les atouts touristiques, dont les pouvoirs publics s'efforcent d'organiser l'offre selon une exigence de qualité. L'aménagement d'un pôle touristique multimodal autour de la rénovation de l'ancienne gare et la réhabilitation d'une ancienne auberge en centre-ville destinée à accueillir un espace culturel sont en gestation. Un réaménagement du centre-ville, incluant modification du plan de circulation, réfection des trottoirs et amélioration de l'accessibilité pour les personnes à mobilité réduite, est en cours de programmation, de même que la requalification de la RN 21 (première tranche de travaux prévue en 2009-2010). Un site Internet, consacré à la commune, chargé de promouvoir l'économie locale et les activités touristiques, est en projet.

La fiscalité locale a été caractérisée par une augmentation régulière des taxes prélevées par la commune. La taxe d'habitation a progressé de 10,48 % en 2001 à 11,03 % en 2006, et à 11,14 % en 2009. Le taux communal de la taxe foncière sur les propriétés bâties est passé de 17,81 % à 17,99 % entre 2006 et 2009.

En 2007, le revenu fiscal médian par ménage était de , ce qui plaçait Châlus au rang parmi les communes de plus de 50 ménages en métropole et 38,3 % des foyers fiscaux étaient imposés (contre et 51,7 % en Haute-Vienne).

La taxe professionnelle, unifiée dans la communauté de communes, s'élevait à 13,91 % en 2006 et à 14,08 % en 2009.

Les postes clés des comptes de la ville de Châlus s'écartent peu des moyennes des communes de 500 à appartenant à un groupement fiscalisé.

Châlus, qui connaît un taux de chômage de 6,9 % selon le recensement de 2006, contre 8,8 % en 1999, offre de multiples emplois, principalement dans la santé et l'action sociale (maison de retraite, service de maintien à domicile des personnes âgées, professionnels de santé...), le bâtiment, les transports, et les services (dont le tourisme).

L'emploi à Châlus se caractérise cependant par la présence de deux secteurs particulièrement dynamiques localement : la filière bois (dans les monts de Châlus, la forêt couvre environ ), et l'élevage bovin.

Les banques et les activités immobilières, avec l'arrivée de nouvelles populations (Anglo-saxons et élargissement urbain de Limoges) sont en plein essor en 2009 et l'industrie est principalement représentée par une unité du groupe Legrand.
Structure des emplois à Châlus, selon le recensement de 1999

Châlus, chef-lieu de canton et pôle d'emplois, concentre, selon les estimations SIRENE d', 45 % des emplois de la communauté de communes des monts de Châlus.

Châlus Chabrol, un château fort du , surplombe la ville. Son enceinte comprend les vestiges de Notre-Dame du Haut-Châlus, église des où furent ensevelies les entrailles de Richard d'Angleterre.

Châlus Maulmont, est un château fort du , également appelé « le fort ». On en découvre d'importants vestiges en centre-ville. 

Châlus Chabrol et Châlus Maulmont sont classés monuments historiques. L'ensemble constitué par le promontoire du château de Châlus Chabrol en ville haute et les abords de la tour de Châlus Maulmont en ville basse est un site inscrit.

Les mottes castrales du Mazaubrun sont inscrites à l'inventaire des Monuments historiques depuis 1983. Elles constituent un bel exemple de castrum à mottes multiples, déclassé assez tôt en simple arrière-fief, perceptible dans les sources écrites à compter du comme simple repaire.

L'église Notre-Dame-de-l'Assomption abrite cloches, statues et tableau classés ou inscrits monuments historiques et provenant de l'ancienne église paroissiale de la Nativité-de-la-Très-Sainte-Vierge, dont la cloche des pénitents gris de 1718.

L'église Saint-Étienne de Lageyrat, distante de quatre kilomètres du bourg, date du et constituait l'église paroissiale de Châlus bas jusqu'à la Révolution. Son cimetière conserve des pierres tombales en granite sculpté des , dont l'une est dénommée tombeau de sainte Quitterie. Elle fut reconstruite à la fin du et détruite pendant les guerres de religion. Propriété de la commune, elle est inscrite à l'inventaire des monuments historiques depuis 1975.

La chapelle Notre-Dame de Seichaud, édifiée en 1473 par une demoiselle de Maulmont, reconstruite en 1707, est la seule des huit anciennes chapelles construites du au qui n'a pas disparu (la chapelle Saint-Roch, démolie pour la construction d'un pont de chemin de fer a été remplacée par un petit oratoire).

Les bonnes fontaines ("lé bounei foun" en occitan) constituent un patrimoine emblématique de la Haute-Vienne, qui en recèle plus de 120. Leur culte, antérieur au christianisme, discret et sobre, « parallèle et insoumis », relié à la déchristianisation marquée du Limousin, en dépit de relations complexes avec l'Église et le clergé, a suscité la confrontation avec les institutions religieuse et médicale. Elles font toujours l'objet de rituels thérapeutiques en fonction de bienfaits ou de qualités thérapeutiques qui leur sont attribués par la coutume. Ainsi, la fontaine Seichaud favorise le mariage (elle fait marier dans l'année les jeunes filles qui la sautent sept fois à pieds joints), la guérison des fièvres et des maux de tête. La fontaine Saint-Roch offre la pluie ; les fontaines Sainte-Marguerite et Sainte-Quitterie de Lageyrat sont « bonnes » pour les maux de tête et de dents, tout en favorisant également les mariages.

La Fonquebure, source magique qui guérit les maux de tête, aurait, selon la légende, une première source souterraine au nord de la commune, dans le Bois du Roy, avant de ressurgir dans un pré à Chandos (commune de Champsac). La fontaine du centre-ville a vu son bassin transformé en Font Crimosana par les porcelaines de Yann Fayaud en 2007.

Le cimetière contient des monuments funéraires remarquables dont les tombes de Martial Dumas, médecin de Napoléon ou de Joseph, dit Paul, Patier, historien du passé de Châlus, ornées, pour les plus anciennes de plaques de porcelaine, à l'exemple de celle de Léon et Julien Nicolas, victimes de l'accident du métro parisien du 10 août 1903.

Le monument aux morts, de type classico-pacifiste, sculpté par Henri Coutheillas, est composé sur un plan de l'architecte Élie Berteau, d'un obélisque en granite et d'une statue représentant une bergère recueillie, revêtue d'une mante, cape traditionnelle appelée « limousine ». La "mère Milan", habitant la ville haute, mère du premier enfant de Châlus mort à la guerre de 1914-1918, servit de modèle au sculpteur. Inauguré le dimanche , ce monument était entouré d'une grille dotée de fortes pointes jusqu'au milieu du . La grille fut retirée après que Pierre Chaminade, dévalant l'avenue du Champ-de-foire à vélo, se fut empalé sur cette ferronnerie.

Les puits de Flayat, Lageyrat, Puy Lageyrat, les Pluviaux, la Ribière, le Châtaignier, la Villehaute, tout comme les "clédiers" (séchoirs à châtaignes) de la Ribière, la Besse, Lageyrat, la Brouille, la Faye, le Mazaubrun, les croix et lavoirs constituent également un petit patrimoine bâti remarquable.

Le Rocher de Richard Cœur de Lion, site inscrit en 1944, est une roche qui émerge des herbes dans les prés de Maumont, au bas du bourg. Stationnant à Châlus durant la guerre de 1914-1918, des troupes américaines l'auraient dynamité afin d'en ramener un morceau aux États-Unis. Jouant la carte des "provinces pittoresques" et du sensationnel, les éditeurs de cartes postales du début du n'hésitaient pas à présenter ce rocher comme étant le lieu où Richard Cœur de Lion aurait été enterré.

Le plus gros séquoia géant ("Sequoiadendron giganteum") d'Europe, d'une circonférence de , se trouve dans un jardin privé. Depuis le passage de la tempête Martin qui s'abattit sur Châlus à partir de le , la cime de ce séquoia exceptionnel, qui conserve la circonférence de tronc la plus importante d'Europe, fut arrachée sur environ .

L'association « Histoire et archéologie du Pays de Châlus », créée par Maurice Robert et Gabriel Fontanille, reprenant le travail de Paul Patier et présidée par Andrée Delage, s'attache à la valorisation du patrimoine historique, bâti et culturel, du Haut Limousin.

L'association « Vie Lageyrat » contribue à la conservation, la valorisation et l'animation du patrimoine et du site de Lageyrat. Elle rassemble plus d'une centaine d'adhérents qui organisent une fête, l'avant dernier week-end de mai, avec un marché gastronomique, artisanal et floral, une brocante, une exposition dans l'église, un déjeuner et diverses autres animations.

Ces événements ponctuels peuvent également s'appuyer sur des amateurs éclairés, dont certains ont constitué de vraies collections, mises en scène à l'occasion d'expositions ou de journées d'animation publiques. Ainsi, un Châlusien passionné a rassemblé plusieurs centaines de postes de radio et de télévision (collection Belair), un autre plusieurs milliers de pipes, un autre encore différents accessoires et matériels de lutte contre les incendies : seaux, casques, haches, épées, grenades extinctrices, pompes ainsi que des véhicules anciens, dont trois Laffly (collection Vignéras).

Châlus constitue le cadre ou la référence géographique de romans et d'essais, tels que "Des femmes qui tombent" de Pierre Desproges, ou "Quadrille sur la tour" de Georges-Emmanuel Clancier. Elle est également citée dans "La Terre aux loups" de Robert Margerit, ainsi que dans le tome sept, "Quand un roi perd la France", des "Rois maudits" de Maurice Druon ou dans le "Richard Cœur de Lion" de Walter Scott.

Châlus est par ailleurs source d'inspiration pour Théodore Agrippa d'Aubigné qui, dans "Les Aventures du baron de Faeneste", met en scène un dialogue entre Henri et un personnage imaginaire dénommé « Châlus de Limousin ». Dans "Une ville de garnison", Alfred Assollant imagine un certain Bertrand de Presles, comte de Châlus, en compagnon de Godefroy de Bouillon lors de la première croisade, montant le premier sur les remparts d'Antioche, qui semble inspiré par le personnage de Gouffier de Lastours. Châlus fut également source d'inspiration pour Philippe Ébly qui, dans le tome , "Celui qui revenait de loin", de la série fantastique "Les Conquérants de l'impossible", fait apparaître pour la première fois le troisième protagoniste de la série sous le nom de Thibaut, duc de Châlus. Ce personnage pourrait avoir contribué à inspirer celui du comte de Montmirail, interprété par Jean Reno dans "Les Visiteurs". Enfin, le siège de Châlus a fourni à Walter Scott pour "Ivanhoé" le canevas du siège du château de Front-de-Bœuf.

Par deux fois, en 1976 et 2010, le cinéma hollywoodien évoque Châlus. Le film "La Rose et la Flèche" (1976), avec Sean Connery et Audrey Hepburn, s'ouvre sur le siège de Châlus par Richard Cœur de Lion, joué par Richard Harris. De même, les premières minutes du "Robin des Bois" de Ridley Scott, avec Russell Crowe et Cate Blanchett, qui fait l'ouverture du festival de Cannes 2010, reconstituent la bataille de Châlus

En 2014, Châlus sert de cadre à un épisode de la saison 6 de la série télévisée "Un village français" tourné dans la maison Moins, une bâtisse de 1827.

La création d'une poste à Châlus remonterait à Louis XI avec l'établissement d'un relais aux Granges, sur la route royale (actuelle RN21) de Limoges à Périgueux. Entre 1610 et 1632, Pierre, dit Pascaud, et Martial de Villoutreys en sont les maîtres. Au début du , le nombre de chevaux de poste en service au relais des Granges reste conséquent et varie de 10 à 19. À la fin du siècle, et jusqu'au milieu du , le bureau de poste, limité au transport du courrier, connaît de nombreux emplacements. Après avoir été situé en de multiples endroits, puis en bas de la place du Marché (dans une maison construite en 1826 par la famille Forgeront), il est actuellement place Cardaillac, au lieu de l'ancienne mairie, elle-même construite au lieu de l'ancienne église.

Émis en France depuis le janvier 1849, le timbre-poste est utilisé à Châlus dès le , comme le montre la plus ancienne enveloppe, destinée à un banquier, affranchie localement avec un Cérès noir, qui ait été conservée. Le fait est notable car, jusqu'au 1854, le timbre-poste est peu utilisé, l'ancien système de port payé par le destinataire restant en usage. Ce n'est qu'à partir de 1854, quand la Poste différencie les tarifs du courrier prépayé (affranchi de port) et de la lettre en port à percevoir, que son utilisation se généralise.

Le , la ville de Châlus héberge la Journée du timbre, ce qui est l'occasion d'une émission premier jour.

En 1999, la Poste édite un timbre-poste commémorant le de la mort de Richard Cœur de Lion, et organise une nouvelle émission premier jour à Châlus. Dans le cadre d'une manifestation philatélique de promotion, un bureau de poste temporaire est ouvert au château de Châlus-Chabrol, les vendredi 9 et samedi . Précédée d'une autre vente anticipée à Fontevraud les samedi 10 et dimanche , la mise en vente officielle de ce timbre dédié au roi Richard d'Angleterre est fixée au , avec vente générale à partir du lundi 12 avril 1999.

Le timbre, réalisé à partir de la photographie d'un détail de l"'Historia Anglorus", Bridgeman-Giraudon, British Library, est gravé par Claude Jumelet, également auteur du timbre commémorant le millième anniversaire du baptême de Clovis et sur lequel figure son catéchiste, saint Waast, qui est originaire de la région de Châlus. Il est imprimé en taille-douce sur rotative à par feuille. D'une valeur faciale de 3 FRF, ce qui correspondait à l'affranchissement d'une lettre simple (lettre de poids, zone 1), il fut vendu à environ d'exemplaires et retiré de la vente le . Format : , dentelure : 13, couleurs : rouge, vert, bleu, bistre et beige.

La cuisine châlusienne est limousine mais déjà fortement influencée par la proximité du Périgord vert.

Les principaux plats qui la caractérisent sont le pâté de pommes de terre et le pâté de viande, ce dernier étant également appelé tourtière. L'enchaud est une spécialité à base de poitrine de porc, roulée et fumée. Les desserts traditionnels sont la flognarde et le clafoutis. Depuis quelques années, le Burgou, un gâteau à la châtaigne baptisé du nom du bandit d'honneur actif entre Bandiat et Tardoire vers 1835 et devenu héros régional emblématique, est élaboré et commercialisé par les pâtissiers locaux.

La cuisine châlusienne familiale utilise les ressources locales : viande de porc, de bœuf, d'agneau et de mouton. Les champignons sont cuisinés sous toutes leurs formes, qu'il s'agisse de cèpes (en patois châlusien, est nécessairement un cèpe), de girolles, de coulemelles (appelées « Filleuls » dans les monts de Châlus) ou de trompettes de la mort. La châtaigne, qu'elle soit blanchie, bouillie ou grillée, est également très présente, comme mets principal ou comme base de préparations (boudins aux châtaignes, etc.) La pomme du Limousin, produite notamment dans les monts de Châlus, est la seule variété, en France, à bénéficier d'une AOC. La soupe traditionnelle est la bréjaude. Composée de lard, de pommes de terre et de raves, il est d'usage de la finir avec un peu de vin. La cuisine familiale châlusienne est aussi faite du produit des rivières (écrevisses, truites, vairons), des et des étangs (carpes, brochets).

La cornue est une spécialité boulangère préparée pour les Rameaux, le dimanche précédant Pâques. Il est d'usage à Châlus que le parrain l'offre à son filleul, en signe d'espoir en la « virilité » de ce dernier. En effet, la forme en Y de cette brioche, censée représenter la Sainte Trinité, rappelle également la forme d'un sexe d'homme. À tel point qu'au , l'évêque de Limoges aurait demandé aux pâtissiers de moraliser leur gâteau des Rameaux, en en modifiant quelque peu la forme. La coutume limousine de la cornue semble également se maintenir, avec quelques variantes (existence d'une cornue « femelle ») dans la Charente limousine voisine. La spécialité sucrée reste les "Craquelins de Châlus", de forme ronde et dont la couleur rouge provient du cumin qui intervient dans sa fabrication.

Une limonade fut, pendant plusieurs générations et jusque dans les années 1970, produite peut-être à partir de l'eau de la Fonquebure sous la marque "Limonade Mémé". La recette de cette limonade s'est perdue avec le décès de Mémé Deléron. La bière Chevalier de Maulmont, brassée par la brasserie Duplessi, permettait en 2005 de financer la restauration du château de Châlus-Maulmont.

Châlus, située au cœur d'une aire touristique, historique et culturelle posée aux confins du Limousin, du Périgord vert et de la Charente limousine, est une station verte de vacances. L'office du tourisme des monts de Châlus y présente l'offre touristique dans l'ensemble de la communauté de communes et édite chaque année un guide touristique, ainsi qu'une sélection de gîtes ruraux. Située à sa proximité immédiate, la Maison du Châtaignier inclut un espace muséographique interactif entièrement consacré au châtaignier et aux possibilités gastronomiques offertes par son fruit, la châtaigne. Elle offre une présentation du métier de feuillardier, de même qu'un espace boutique avec une exposition vente de produits de fabrication artisanale en bois de châtaignier et de produits de la ferme, à base de châtaigne. La Voie verte des Hauts de Tardoire, unique voie verte de la région Limousin, offre un itinéraire sécurisé de Châlus à Oradour-sur-Vayres qu'il est possible de suivre à pied, en fauteuil roulant, à vélo ou en roller.
Le chemin « las girondelas » ("les girolles") est exclusivement pédestre. Ses de promenade en pleine nature limousine peuvent être parcourus en , ou réduits à une variante de .
En période estivale, un circuit de vélorail sur une voie de chemin de fer désaffectée permet, au départ de Bussière-Galant, une promenade de deux heures jusqu'à l'aire de retournement de la Tranchardie, ou, sur réservation, de deux heures trente jusqu'à la gare de Châlus.

La ville de Châlus est située sur deux routes touristiques : la route Richard Cœur de Lion et le chemin de Compostelle ("Via Lemovicensis").

Les armes de Châlus sont blasonnées "de sinople à un arc de gueules cordé de sable, avec une flèche aussi de sable, accompagné de neuf quilles d'or posées en orle et soutenu d'une boule de sable". Il s'agit d'armes récentes, du type « armes par allusion ». La devise de Châlus est que l'on peut traduire par . L'hymne des Châlusiens est "Lo Turlututu". Selon un usage très ancien, un Châlusien pénétrant dans un lieu, hors de Châlus, siffle les trois premières mesures du Turlututu. Les Châlusiens présents se font connaître en sifflant la mesure suivante. Cet usage semble toujours en vigueur, voire plus usité que par le passé du fait de la dispersion géographique des familles originaires de Châlus.




Géographie

Histoire

Politique et administration

Patrimoine civil

Patrimoine religieux


</doc>
<doc id="15527" url="https://fr.wikipedia.org/wiki?curid=15527" title="Touques">
Touques

Touques est une commune française, située dans le département du Calvados en région Normandie, peuplée de . Elle fait partie de la communauté de communes Cœur Côte Fleurie.

Touques se situe au nord-est du département du Calvados, sur le bord de la Touques, juste avant Deauville et Trouville-sur-Mer qui lui sont limitrophes.

Le nom de la localité est attesté sous la forme "Touqua" vers 1350. 

Selon Charles Rostaing, ce toponyme, lié au fleuve côtier qui traverse le territoire, serait d'origine pré-latine, "tosca" (taillis au milieu de défrichements) et signifierait « réserve de bois entre défrichements ». 

S'il ne cite pas Touques, René Lepelley évoque pour un toponyme apparenté, "Touquettes", l'ancien français "toche", « petit morceau de forêt non défriché ».

Le gentilé est "Touquais".

Des fragments de céramiques datant du ont été retrouvés lors des travaux sur le parvis de l'église Saint-Pierre.

Sa situation privilégiée, sur l'estuaire de la Touques, lui a permis aussi loin que l'on puisse remonter dans le temps de confirmer la prédominance de ce qui fut son caractère politique, maritime et économique jusqu'au début du où le développement de Trouville puis Deauville amena à la construction d'une ligne de chemin de fer qui détourna le cours de la Touques devenue de moins en moins praticable pour les gabarres de par son ensablement.

En 1096, Guillaume II le Roux s'y embarque pour aller se faire sacrer roi d'Angleterre. Guillaume le Conquérant, devenu roi d'Angleterre, y débarque pour venir inspecter son duché normand. Le 1417, Henri V d'Angleterre, y débarque pour reprendre le château de Bonneville situé sur la commune voisine de Bonneville-sur-Touques

Un des grands talmudistes du Moyen Âge, , vécut à Touques dans la seconde moitié du (il est entré dans les archives juives sous cette appellation, ce qui semble indiquer que le nom «Touques» était déjà en usage). 

Le , une importante inondation affecte le bourg.

Sous l'Ancien Régime, Touques est formée de deux paroisses, Saint-Pierre (), qui dépend du bailliage de Honfleur, et Saint-Thomas (), qui dépend du bailliage d'Auge. Le ruisseau des Ouïes les sépare. Touques devient chef-lieu de canton en 1790, lequel comprend les communes de Saint-Arnoult, Benerville, Cricquebœuf, Daubeuf, Deauville, Englesqueville, Hennequeville, Tourgéville, Trouville, Vauville et Villerville. Elle perd ce titre en 1878. En 1827, elle absorbe Daubeuf ( en 1821), au nord-est de son territoire.

Touques connaît un regain de dynamisme depuis les années 1970, sous la mandature de Charles Roffé, avec la construction de nombreux lotissements à caractère social, aménagement d'une importante zone commerciale et d'aménagements sportifs.

Le , une importante inondation due à deux gros orages successifs dans la même journée cause de graves dégâts dans le bourg.

Le , se tient une rencontre prémonitoire de la réunification de la Normandie (2016), entre les présidents respectifs des conseils régionaux de Basse-Normandie et Haute-Normandie pour développer la coopération entre les deux instances.



Le conseil municipal est composé de vingt-sept membres dont le maire et huit adjoints.





Les disciplines suivantes sont pratiquées localement : basket-ball, tennis, athlétisme, tir à l'arc, gymnastique et football.









</doc>
<doc id="15530" url="https://fr.wikipedia.org/wiki?curid=15530" title="Fractale">
Fractale

Une figure fractale est un objet mathématique, telle une courbe ou une surface, dont la structure est invariante par changement d'échelle.

L'adjectif « fractal », à partir duquel l'usage a imposé le substantif une fractale pour désigner une figure ou une équation de géométrie fractale, est un néologisme créé par Benoît Mandelbrot en 1974 à partir de la racine latine "", qui signifie « brisé », « irrégulier », et de la désinence "-al" présente dans les adjectifs "naval" et "banal" (pluriels : navals, banals, fractals). De nombreux phénomènes naturels – comme le tracé des lignes de côtes ou l'aspect du chou romanesco – possèdent des formes fractales approximatives.

Les fractales sont définies de manière paradoxale, à l'image des poupées russes qui renferment une figurine identique à l'échelle près : « les objets fractals peuvent être envisagés comme des structures gigognes en tout point – et pas seulement en un certain nombre de points, les attracteurs de la structure gigogne classique. Cette conception "hologigogne" (gigogne en tout point) des fractales implique cette définition tautologique : un objet fractal est un objet dont chaque élément est aussi un objet fractal (similaire) .

Employé en tant qu'adjectif, le terme peut désigner une appellation « générique » (notamment d'un point de vue sémiotique, par signes équivalents).

C'est cette généricité (cf. une « déterritorialisation ») qui est prise en compte dans la Théorie du Rhizome (cf. « French Theory ») à portée socio-politique ; (afin de montrer la possibilité d'une organisation horizontale, où chaque élément est virtuellement efficient, plutôt qu'une disposition pyramidale par exemple, verticalement rigide et sans potentiel fractal).

Un objet fractal possède au moins l'une des caractéristiques suivantes :

Les figures fractales n'ont pas à satisfaire toutes les propriétés mentionnées ci-dessus pour servir de modèles. Il leur suffit de réaliser des approximations convenables de ce qui intéresse dans un domaine de validité donné (le livre fondateur de Mandelbrot "Les Objets fractals" en donne une grande variété d'exemples). La taille des alvéoles du poumon, par exemple, taille à partir de laquelle celui-ci cesse de se subdiviser de façon fractale, est liée à la taille du libre parcours moyen de la molécule d'oxygène à température du corps.

La dimension utilisée est celle de Hausdorff, et on observe qu'elle correspond à une caractéristique nouvelle des surfaces irrégulières. On connait les plages de validité des dimensions de Hausdorff observées sur Terre pour les montagnes, les nuages, etc.

Des exemples de figures fractales sont fournis par les ensembles de Julia, Fatou et de Mandelbrot, la fractale de Lyapunov, l'ensemble de Cantor, le tapis de Sierpinski, le triangle de Sierpinski, la courbe de Peano ou le flocon de Koch. Les figures fractales peuvent être des fractales déterministes ou stochastiques. Elles apparaissent souvent dans l'étude des systèmes chaotiques.

Les figures fractales peuvent être réparties en trois grandes catégories :

De toutes ces figures fractales, seules celles construites par des systèmes de fonctions itérées affichent habituellement la propriété d'autosimilitude, signifiant que leur complexité est invariante par changement d'échelle.

Les fractales aléatoires sont les plus utilisées dans la pratique, et peuvent servir à décrire de nombreux objets extrêmement irréguliers du monde réel. Les exemples incluent des nuages, les montagnes, les turbulences de liquide, les lignes des côtes et les arbres. Les techniques fractales ont aussi été utilisées dans la compression fractale d'images, de même que dans beaucoup de disciplines scientifiques.

La dimension d'une ligne droite, d'un cercle et d'une courbe régulière est de 1. Une fois fixés une origine et un sens, chaque point de la courbe peut être déterminé par un nombre, qui définit la distance entre l'origine et le point. Le nombre est pris négativement s'il faut se déplacer dans le sens opposé à celui choisi au départ.

La dimension d'une figure simple dans le plan est de 2. Une fois un repère défini, chaque point de la figure peut être déterminé par deux nombres. La dimension d'un corps simple dans l'espace est de 3.

Une figure telle qu'une fractale n'est pas simple. Sa dimension n'est plus aussi facile à définir et n'est plus forcément entière. La dimension fractale, plus complexe, s'exprime à l'aide de la dimension de Hausdorff.
Quand la fractale est formée de répliques d'elle-même en plus petit, sa dimension fractale peut se calculer comme suit :

formula_1

où la fractale de départ est formée de formula_2 exemplaires dont la taille a été réduite d'un facteur formula_3 (pour homothétie).

Quelques exemples :
formula_6
formula_9
formula_12

Une liste beaucoup plus longue se trouve sous : Liste de fractales par dimension de Hausdorff.

Des formes fractales approximatives sont facilement observables dans la nature. Ces objets ont une structure autosimilaire sur une échelle étendue, mais finie : les nuages, les flocons de neige, les montagnes, les réseaux de rivières, le chou-fleur ou le brocoli, et les vaisseaux sanguins.

Les arbres et les fougères sont de nature fractale et peuvent être modélisés par ordinateur à l'aide d'algorithmes récursifs comme les L-Systems. La nature récursive est évidente dans ces exemples ; la branche d'un arbre ou la fronde d'une fougère sont des répliques miniatures de l'ensemble : pas identiques, mais de forme similaire.

La surface d'une montagne peut être modélisée sur ordinateur en utilisant une fractale : prenons un triangle dans un espace tridimensionnel dont nous connectons les milieux de chaque côté par des segments, il en résulte quatre triangles. Les points centraux sont ensuite déplacés aléatoirement vers le haut ou le bas, dans un rayon défini. La procédure est répétée, diminuant le rayon de moitié à chaque itération. La nature récursive de l'algorithme garantit que le tout est statistiquement similaire à chaque détail.

Enfin, certains astrophysiciens ont remarqué des similitudes dans la répartition de la matière dans l'Univers à six échelles différentes. Les effondrements successifs de nuages interstellaires, dus à la gravité, seraient à l'origine de cette structure (partiellement) fractale. Ce point de vue a donné naissance au modèle de l'univers fractal, décrivant un univers fondé sur les fractales.
Les domaines d'application des fractales sont très nombreux, on peut citer en particulier :
Tous ces domaines - et bien d'autres - peuvent bénéficier de la description et d'une modélisation en termes fractals des phénomènes associés.

Le modèle commence tout particulièrement à se développer en finance, où l'approche fractale de Mandelbrot se prête aux marchés volatils. Des sociétés utilisent un modèle identifiant les répétitions mathématiques afin de prévoir certains mouvements de prix à court-terme. Cette approche systématique est basée sur la volatilité et l'accélération des échanges de titres afin de valider les tendances. 
Une anticipation des variations est ainsi immédiatement inscrite sur le modèle : si la variation est d'ampleur suffisante, elle permet de prendre par exemple une position short sur le marché.

Surface spécifique de Blaine : la finesse de broyage d'un ciment est exprimée en termes de surface spécifique (cm²/g) et mesurée par la méthode de Blaine, dite de perméabilité à l'air, utilisant la loi de Darcy, et la loi de Kozeny-Carman qui établit que la traversée d'un lit de granules par un fluide est affectée par la surface spécifique des granules.

Ainsi, en calculant la durée que met un gaz sous pression à traverser un volume donné de granules, on en déduit la surface des granules. Plus le broyage est fin, plus la surface calculée est importante.

Cette expérience se produisant dans un volume déterminé, on peut imaginer obtenir une surface développée infinie en broyant toujours plus finement le ciment. Il s'agit là d'une utilisation industrielle d'un modèle expliqué par les mathématiques fractales (un objet de dimension formula_2 de mesure finie, borné par une frontière de dimension formula_14, de mesure tendant vers l'infini).






</doc>
<doc id="15532" url="https://fr.wikipedia.org/wiki?curid=15532" title="Hack">
Hack

Le hack est une manipulation d'un système, de l'anglais , tailler, couper quelque chose à l'aide d'un outil. Par analogie, séparer des blocs logiques, retirer de l'étude tout ce qui n'est pas nécessaire, et regrouper des données dispersées permet de retrouver une cohérence, tout en permettant d'être mieux compris dans son fonctionnement.

La légalité de ce « palier » du "hack" est sujette à débat, notamment par le statut indéfini de la légalité de certaines méthodes de lecture des données (notamment les Packet sniffers).

Le terme de "hack" est très employé par les internautes et les médias d'information, mais dans des significations qui tendent vers un abus de langage. C'est pourquoi il est primordial de différencier l'étymologie de la méthode de hack des applications possibles, qui peuvent former alors des domaines plus spécifiques.

Le terme le plus employé pour désigner quelqu'un utilisant cette méthode est hacker, toutefois, et pour éviter tout débat autour de l'emploi du terme, l'expression acteur du hack (quelqu'un se servant de la "méthode de hack" à différentes fins) sera utilisée dans cet article.

En programmation, le "hack" est une solution rapide et bricolée pour contourner un problème, quel qu'il soit. Il peut s'agir d'une limitation du langage de programmation lui-même, ou d'une conception imparfaite de la part du programmeur. Dans ce cas, plutôt que de réécrire une grosse section du code source, le hacker peut choisir de le cracker, plus rapide à mettre en œuvre mais moins propre et pouvant mener à des problèmes ultérieurs.
Cracker des logiciels sert également à enlever la protection de certains qui demandent une clé d'activation payante. Les crackers, après avoir « analysé » le logiciel en question, créent un autre logiciel appelé "Keygen" signifiant générateur de clé, qui génère des clés d'activations et/ou des numéros de séries, permettant ainsi de se servir du logiciel sans payer. Cette méthode est illégale et interdite en France et dans de très nombreux autres pays.

La signification la plus usitée de l'application de la "méthode de hack" est la modification arbitraire et visible du contenu d'un site Internet - la page d'accueil la plupart du temps, en raison du fait que c'est la page la plus visitée sur un site. Les motivations des "acteurs du hack" (hackers) sont diverses, on distingue les chapeaux blancs et les chapeaux noirs, mais il y en a principalement trois :


Cette application de l"'acteur du hack" a pour terme équivalent pirate informatique qui, lui aussi, amène beaucoup de débats.

Le terme de "hack" a alors pour définition l'action visant à pénétrer sans autorisation dans un réseau, câblé ou non. C'est surtout grâce à la démocratisation des réseaux sans fil que le terme de "hack" resurgit dans toute sa splendeur. Le principe est le même que pour une attaque d'un site Internet : accéder à un domaine privé sans autorisation, et être capable ou non de modifier tout contenu derrière cette barrière.

La grande différence du "hack" d'un réseau sans fil est la popularisation des outils permettant une "casse" rapide et sans connaissance nécessaire de la sécurité du réseau. L'auteur de telles pratiques est alors considéré comme étant un script kiddie.

L'application du "hack" dans l'analyse de logiciels a amené la création et le développement du monde du cracking. Cette application consiste à analyser le fonctionnement d'une protection pour la contourner ou la leurrer. La différenciation entre "hack" et "crack" est beaucoup plus nette chez les internautes qu'il y a quelques années, où "hack" était LE mot passe-partout. Le Crack est une copie quasi-conforme du fichier exécutable original (fournit par le développeur du logiciel), sauf qu'un pirate en a supprimé des composants (pour éviter une détection de disque original par exemple). Le principe pour les contrevenants est simple, il suffit de remplacer le fichier exécutable original par celui piraté, et le logiciel pourra ensuite se lancer sans demander de clé d'activation ou vérifier la présence du disque dans le lecteur. Ce principe de contournement se généralise depuis plusieurs années, surtout dans le domaine des jeux vidéo, et pour les systèmes d'exploitation propriétaires.

L'application de la "méthode de hack" est à double tranchant : il est à la fois la preuve d'une faiblesse, d'une faille mais aussi le localisateur de cette faiblesse à combler et à protéger davantage. La place laissée aux systèmes informatiques fait que suivant son importance, toute faiblesse permettrait une exploitation potentielle, et peut amener à la destruction des données, ce qui serait catastrophique à certaines échelles d'importance. C'est pourquoi de plus en plus de propriétaires de produits (sites Internet, logiciels...) invitent les acteurs du "hack" à trouver les faiblesses pouvant exister, et à faire en sorte que le créateur du produit puisse les corriger.



</doc>
<doc id="15538" url="https://fr.wikipedia.org/wiki?curid=15538" title="Bug de la division du Pentium">
Bug de la division du Pentium

Le bug de la division du Pentium est un bug informatique ayant affecté le microprocesseur Pentium du fabricant Intel peu après son lancement en 1994 : une erreur était introduite lors de certaines opérations de division.

En , le professeur Thomas Nicely de l'université de Lynchburg dévoile un dysfonctionnement dans l'unité de calcul en virgule flottante du "Pentium" lors de calculs sur la constante de Brun . Il s'est rendu compte que certaines opérations de division renvoient toujours une valeur erronée par excès sur ce processeur. Ces erreurs dans les divisions sont rapidement confirmées par d'autres personnes.

Ce bug devient très vite notoire et est surnommé le « bug FDIV du Pentium » (FDIV est l'instruction de division en virgule flottante des microprocesseurs x86). D'autres ont mis en évidence des problèmes de division dont le résultat retourné par le Pentium était au-dessus de la valeur réelle jusqu'à pour 10000. L'erreur provenait de l'initialisation incomplète (dans le silicium) d'une table de valeurs servant à un nouvel algorithme de division, plus rapide.

La présence du bug peut être vérifiée via l'opération qui suit, à effectuer dans une application qui utilise de manière native les nombres en virgule flottante, y compris la calculatrice de Windows : 

Ce problème s'est produit seulement sur quelques modèles du processeur Pentium. Tous les processeurs de famille Pentium ayant une fréquence d'horloge de plus de et plus récents sont exempts de ce bug.

Ces constatations ont alimenté une vive polémique. Intel a d'abord nié le problème. Plus tard, Intel a clamé l'insignifiance des défauts de ses microprocesseurs, voulant rassurer les utilisateurs et a refusé de remplacer systématiquement les microprocesseurs défectueux. Cependant, si une personne pouvait montrer qu'elle avait été affectée par le dysfonctionnement, alors Intel remplacerait son processeur.

Bien que des évaluations effectuées par des organismes indépendants eussent montré le peu d'importance des conséquences du bug et son effet négligeable dans la plupart des utilisations, la communication nonchalante d'Intel a provoqué une grande colère publique, et le "bug" a trouvé un large écho dans la presse nationale américaine. Des compagnies comme IBM (dont le clone du Pentium « 586 » concurrençait au même moment la gamme des Pentium d'Intel) ont joint leur voix pour exprimer leur colère. Finalement, Intel a décidé de remplacer tous les processeurs Pentium défectueux, ce qui aurait pu représenter un coût énorme pour la compagnie. Toutefois, seule une petite fraction des possesseurs de processeurs défectueux a demandé l'échange.



</doc>
<doc id="15541" url="https://fr.wikipedia.org/wiki?curid=15541" title="D (lettre)">
D (lettre)

D est la quatrième lettre de l'alphabet latin. Son équivalent dans l'alphabet cyrillique est Д.
La lettre D tire probablement son origine de l'alphabet protosinaïtique, du graphème représentant un poisson ou de celui représentant une porte. Le graphème a ensuite évolué dans les alphabets phénicien, grec, étrusque et romain, tout en conservant sa prononciation codice_1.






</doc>
<doc id="15542" url="https://fr.wikipedia.org/wiki?curid=15542" title="Alain (philosophe)">
Alain (philosophe)

Alain, de son vrai nom Émile-Auguste Chartier, né le à Mortagne-au-Perche (Orne) et mort le au Vésinet (Yvelines), est un philosophe, journaliste, essayiste et professeur de philosophie français. Il est rationaliste, individualiste et critique.

L'auteur utilisa différents pseudonymes entre 1893 et 1914. Il signe « Criton » sept « Dialogues » adressés à la très universitaire "Revue de métaphysique et de morale" (dans laquelle il signe, par ailleurs, plusieurs articles de son vrai nom) ; il signe « Quart d'œil », ou encore « Philibert », ses pamphlets dans "La Démocratie rouennaise", journal éphémère destiné à soutenir la campagne du député Ricard à Rouen ; enfin « Alain » ses chroniques dans "La Dépêche de Lorient" (jusqu'en 1903) puis dans "La Dépêche de Rouen et de Normandie" de 1903 à 1914.

L'adjectif dérivé de son nom est "alinien".

Émile-Auguste Chartier est né le , à Mortagne-au-Perche, rue de la Comédie, au domicile de ses parents, Étienne Chartier, vétérinaire et Juliette-Clémence Chaline. Ses grands-parents maternels Pierre-Léopold Chaline et Louise-Ernestine Bigot sont des commerçants de Mortagne connus et très présents dans la vie communale. Alain a également pour cousin l’abbé Chaline, grâce à qui le sujet de la religion aura une place toute particulière dans son étude et sa réflexion philosophique. Il tient fondamentalement une grande part de son radicalisme de son père et de son grand-père.

En 1881, il entre au lycée d'Alençon où il passe cinq ans. À cette époque, ses auteurs préférés sont Homère, Platon, René Descartes, Honoré de Balzac et Stendhal. Il lit le grec ancien mieux que le latin.

Se destinant d'abord à l’École polytechnique, il opte finalement pour une préparation littéraire qu'il effectue comme externe au lycée Michelet de Vanves à partir de 1886. Là, il fait la rencontre décisive du philosophe Jules Lagneau, qu'il reconnaît comme son maître, et qui l’oriente vers la philosophie.

Après l'École normale supérieure, il est reçu troisième à l'agrégation de philosophie en 1892 puis est nommé professeur successivement aux lycées Joseph-Loth à Pontivy, Dupuy de Lôme à Lorient, à Rouen (lycée Corneille de 1900 à 1902) et à Paris (lycée Condorcet) puis à Vanves (lycée Michelet). Il s'engage politiquement du côté républicain et radical, donnant des conférences pour soutenir la politique laïque de la République. En 1902, après l'échec du candidat Louis Ricard dont il organise la campagne à Rouen, il se retire du militantisme politique, se consacrant aux universités populaires qui se sont créées à la suite de l'affaire Dreyfus et à l'écriture. À partir de 1903, il publie (dans "La Dépêche de Rouen et de Normandie") des chroniques hebdomadaires qu'il intitule « Propos du dimanche », puis « Propos du lundi », avant de passer à la forme du Propos quotidien. Plus de de ces « Propos » paraîtront de février 1906 à septembre 1914. Devenu professeur de khâgne au lycée Henri-IV en 1909, il exerce une influence profonde sur ses élèves (Simone Weil, Raymond Aron, Georges Canguilhem, André Maurois, Julien Gracq, etc.). Alain a également enseigné à partir de 1906 au Collège Sévigné, à Paris.

À l'approche de la guerre, Alain milite dans ses "Propos" pour la paix en Europe et refuse la perspective d'un conflit avec l'Allemagne dont il pressent qu'il serait d'une violence inédite. Lorsque la guerre est déclarée, sans renier ses idées, il devance l'appel et s'engage, fidèle à un serment prononcé en 1888 lorsque la loi de l'époque permettait aux enseignants d'être dispensés de service militaire. Acceptant le bénéfice de la dispense, il avait juré de s'engager si une guerre survenait, ne supportant pas l'idée de demeurer à l'arrière quand les « meilleurs » sont envoyés au massacre.

Brigadier au d'artillerie, il refuse toutes les propositions de promotion à un grade supérieur. Le 23 mai 1916, il se broie le pied dans un rayon de roue de chariot lors d'un transport de munitions vers Verdun. Après quelques semaines d'hospitalisation et de retour infructueux au front, il est affecté pour quelques mois au service de météorologie, puis il est démobilisé le .

Ayant vu de près les atrocités de la Grande Guerre, il publie en 1921 son célèbre pamphlet "Mars ou la guerre jugée". Sur le plan politique, il s’engage aux côtés du mouvement radical en faveur d'une république libérale strictement contrôlée par le peuple. En 1927, il signe la pétition (parue le 15 avril dans la revue "Europe") contre la loi sur l’organisation générale de la nation pour le temps de guerre, qui abroge toute indépendance intellectuelle et toute liberté d’opinion. Son nom côtoie ceux de Lucien Descaves, Louis Guilloux, Henry Poulaille, Jules Romains, Séverine… et ceux des jeunes normaliens Raymond Aron et Jean-Paul Sartre. Jusqu'à la fin des années 1930, son œuvre sera guidée par la lutte pour le pacifisme et contre la montée des fascistes. La rédaction des "Propos" reprend, mais sous forme de revue, de 1921 à 1936, avec une interruption de 1924 à 1927, où ils sont accueillis par la revue "Émancipation "de Charles Gide. En 1934, il est cofondateur du Comité de vigilance des intellectuels antifascistes (CVIA), dirigé par Paul Rivet et Paul Langevin. En 1936, alors qu'il est depuis longtemps atteint de crises régulières de rhumatismes qui l'immobilisent, une attaque cérébrale le condamne au fauteuil roulant. Il participe néanmoins, mais de loin, aux travaux du "Comité de Vigilance des Intellectuels antifascistes", milite ardemment pour la paix, rassemble les deux volumes de "Propos" qu'il intitulera "Convulsions de la Force" et "Échec de la Force", soutient un moment les efforts pacifistes de Giono, même si, partisan de toujours de la guerre défensive, il désapprouve toute idée de désarmement. Il soutient en revanche les accords de Munich, heurté par les appels à l'Union sacrée des bellicistes en France dans lesquels il semble retrouver la censure des opinions dissidentes et pacifistes qui ont puissamment contribué au développement de la Première Guerre mondiale. Anti-fasciste convaincu, il semble ne pas mesurer la puissance réelle et la dimension spécifique de l'hitlérisme, considérant la France comme la puissance dominante dans le rapport de force international. Il signe, en septembre 1939, le tract « Paix immédiate » du militant anarchiste Louis Lecoin. À partir de 1937, à l'instigation de sa compagne après des semaines d'impuissance à écrire, Alain se consacre pour l'essentiel à l'écriture privée de son "Journal". Sont publiés également plusieurs recueils thématiques rassemblant ses "Propos", de même qu'il poursuit sa collaboration à la "Nouvelle Revue française", y compris après que Drieu La Rochelle en aura pris la direction sous l'Occupation nazie.

L'entrée en guerre et la débâcle sont pour lui un effondrement. Il est cosignataire d'un tract pacifiste "Paix immédiate" que Louis Lecoin fait imprimer clandestinement - car la guerre est déclarée - et distribuer. Alain n'évite une peine de prison qu'en prétendant que Lecoin l'a abusé. Ensuite il ne prend aucune position publique pendant la guerre et l'on ne peut restituer son opinion qu'à travers le style heurté, lapidaire et volontiers paradoxal de son "Journal". En 1940, il accepte la défaite et ne souhaite pas la poursuite des hostilités. Dans son "Journal", le 23 juillet 1940, Il va jusqu'à souhaiter la victoire allemande plutôt que celle "du genre De Gaulle". La collaboration pétainiste lui semble un moindre mal, dans la continuité de son engagement pacifiste. En 1943, il est sollicité pour apporter son patronage à la Ligue de pensée française, de René Château, initiative qui ne semble pas s'être concrétisée.
Très affaibli, pratiquement coupé du monde et de la guerre que même ses amis évitent d'évoquer devant lui, il connaît de 1940 à 1942 des années très sombres d'un point de vue moral comme physique. Il perd en 1941 sa compagne, amie de cœur et fidèle collaboratrice, Marie-Monique Morre-Lambelin, et en 1944 son ancien élève et plus proche disciple, Jean Prévost, tué dans le Vercors. Son "Journal (1937-1950)" porte néanmoins la marque de la renaissance de son activité littéraire à partir de 1943. C'est pour l'essentiel la relecture des grandes œuvres qui le ramène à l'écriture. Il y avoue sa part d'ombre de ne pouvoir se débarrasser d'un antisémitisme latent. Cet aspect est d'ailleurs régulièrement mis en place publique. Il rédigera encore, en 1947, les "Lettres à Sergio Solmi sur la philosophie de Kant" ainsi que les "Souvenirs sans égards", divers articles et préfaces et l'ébauche d'un "Marx" en 1950. En mai 1950, il reçoit le Grand Prix National des Lettres. Il meurt le et est enterré au cimetière du Père-Lachaise (division 94).

Trois associations contribuent aujourd'hui à faire connaître et à diffuser son œuvre en se chargeant de la réédition et de la publication de ses textes inédits : l"'Institut Alain" est dirigé par l'administrateur littéraire de son œuvre, "l'Association des Amis d'Alain" et "l'Association des Amis du Musée Alain et de Mortagne".

Alain met au point à partir de 1906 le genre littéraire qui le caractérise, les « Propos ». Ce sont de courts articles, inspirés par l'actualité et les événements de la vie de tous les jours, au style concis et aux formules frappantes, qui couvrent presque tous les domaines. Cette forme appréciée du grand public a cependant pu détourner certains critiques d'une étude approfondie de son œuvre philosophique. Beaucoup de "Propos" sont parus dans la revue "Libres Propos" (1921-1924 et 1927-1935) fondée par un disciple d'Alain, Michel Alexandre. Certains ont été publiés, dans les années trente, dans la revue hebdomadaire "L'École libératrice" éditée par le Syndicat national des instituteurs.

Il s'inspira de Platon, Descartes, Kant et Auguste Comte — mais il se réclama surtout de Jules Lagneau, dont il prit les conseils à la lettre, sans jamais devenir véritablement son disciple. Lagneau fut son premier professeur de philosophie au lycée de Vanves (actuel lycée Michelet). Il n'oublia jamais, toute sa vie durant, celui qu'il appela « le seul Grand Homme que j'aie jamais connu », et dont la rencontre fut pour Alain aussi décisive que celle de Platon avec Socrate :

Le but de sa philosophie est d'apprendre à réfléchir et à penser rationnellement en évitant les préjugés. Humaniste cartésien, il est un « éveilleur d'esprit », passionné de liberté, qui ne propose pas un système ou une école philosophique mais apprend à se méfier des idées toutes faites. Pour lui, la capacité de jugement que donne la perception doit être en prise directe avec la réalité du monde et non bâtie à partir d'un système théorique.

Alain perd la foi au collège sans en ressentir de crise spirituelle. Bien qu'il ne croie pas en Dieu et soit anticlérical, il respecte l'esprit de la religion. Il est même attiré par les phénomènes religieux qu'il analyse de façon très lucide. Dans "Propos sur la religion" et "Propos sur le bonheur" il fait transparaître, un peu comme chez Auguste Comte, une certaine fascination pour l'Évangile et pour le catholicisme, dont il aime la dimension universelle.
Profondément athée, il critique le côté irrationnel de la croyance religieuse. Ainsi, dans "Les Saisons de l'esprit", il affirme : Il dénonce la croyance sans preuve : Il pointe du doigt le manque d'humanisme des monothéismes en particulier.

Alain y explique que ce qu'il a ressenti le plus vivement dans la guerre, c'est l'esclavage. Il s'insurge contre le mépris des officiers pour les hommes de troupe lorsqu'ils . Il ne supporte pas l'idée de cette tuerie organisée, de ce traitement que l'Homme inflige à l'Homme.

Il se révolte quand il assiste à la mise au point d'une énorme machine destinée à tenir les hommes dans l'obéissance et explique pourquoi, soldat, il n'a jamais voulu d'autres galons que ceux de brigadier.


La bibliographie des œuvres d’Alain est considérable. Outre 3083 "Propos d’un Normand" et plus de 1800 "Libres propos", Alain a écrit une cinquantaine de volumes ou articles, sans compter des dizaines de volumes reprenant un choix de propos. On trouvera au Tome II d’Olivier Reboul [voir plus bas] une bibliographie complète des œuvres d’Alain ainsi que les principales études (jusqu’en 1968). La thèse de Reboul sur "Les passions selon Alain" reste considérée comme la meilleure introduction à Alain.

Le lecteur d’aujourd’hui trouvera l’essentiel de l’œuvre d’Alain dans les quatre volumes de La Pléiade. Alain fut longtemps le seul philosophe français du publié dans les éditions de La Pléiade avant la publication, en 2015, des "Œuvres" de Michel Foucault.





</doc>
<doc id="15545" url="https://fr.wikipedia.org/wiki?curid=15545" title="Aragon (communauté autonome)">
Aragon (communauté autonome)

LAragon ("Aragón" en castillan et aragonais, "Aragó" en catalan) est une communauté autonome située dans le nord de l'Espagne. Elle est composée de trois provinces : la province de Huesca, la province de Saragosse et la province de Teruel. Elle est bordée au nord par la France, à l'est par la Catalogne et la Communauté valencienne, au sud par la Castille-La Manche, à l'ouest par la Castille-et-León et la Navarre.

L'Aragon tient son nom de deux petites rivières pyrénéennes, l'Aragon et l'Aragon Subordan. Le petit comté qui s'établit à Jaca au prit le nom de ces rivières, avant de connaître une expansion exceptionnelle au cours des siècles suivants.

D'une superficie de , l'Aragon représente 9,43 % de la superficie totale de l'Espagne, ce qui la place au quatrième rang des communautés autonomes espagnoles par la superficie, après la Castille-et-León, l'Andalousie et la Castille-La Manche. Elle est divisée en 3 provinces :

Elle se situe au nord-est de la péninsule ibérique, entre les latitudes des et nord.

L'Aragon est bordé :

L'orographie de l'Aragon est marquée par l'axe central que forme la vallée de l'Èbre, bordé au nord par le piémont des Pyrénées méridionales, et au sud par le piémont des mont Ibériques. C'est d'ailleurs en Aragon que l'on trouve les sommets les plus élevés de ces deux systèmes montagneux, le pic d'Aneto et le Moncayo.

Les Pyrénées aragonaises occupent la majeure partie de la province de Huesca, au nord de l'Aragon. On distingue trois grandes unités :

Dans les hautes Pyrénées, la région axiale ("Pirineo Axial") est formée des zones les plus anciennes : granites, quartzites, schistes et calcaires anciens. C'est également là que l'on trouve les sommets les plus élevés de toute la chaîne des Pyrénées : le pic d'Aneto (), le pic de la Maladeta () et le pic Perdiguère (). La région des Pré-Pyrénées Intérieures ("Prepirineo interior") est composée de roches calcaires plus modernes. On retrouve des sommets élevés, comme le mont Perdu (), la Collarada () et la Tendeñera ().

Les principales vallées pyrénéennes, formées par les rivières qui les traversent, sont la vallée d'Ansó (rivière Veral), la vallée d'Hecho (Aragon Subordan), la vallée de Canfranc (Aragon), la vallée de Tena (Gállego) et la vallée d'Ainsa-Benasque (Ara, Cinca et Ésera).

La Dépression intra-pyrénéenne est une dépression orographique, dont l'altitude oscille entre 600 et . Le canal de Berdún en est l'exemple le plus frappant. Il s'étend depuis Jaca jusqu'à Yesa, en Navarre, et est parcourue par l'Aragon. Cette dépression longitudinale est limitée au nord par les Pré-Pyrénées Intérieures, Leyre et Orba, et au sud par les Montagnes Extérieures, la Peña Oroel ()et le San Juan de la Peña (). Son altitude oscille entre 600 et .

Les Montagnes extérieures correspondent au piémont de la province de Huesca et sont l'ensemble montagneux le plus méridional des Pyrénées, principalement formé de calcaires. Les sommets y atteignent des altitudes moins élevées, entre et . On y trouve cependant des reliefs réputés pour leur beauté, tels que la sierra de Guara, qui culmine au Tozal de Guara () et les Mallos de Riglos.

Le système ibérique recouvre en partie les provinces de Saragosse et de Teruel, au sud de l'Aragon. C'est un ensemble de "sierras" sans unité structurelle claire, que l'on peut diviser en deux zones :

Bien que le climat de l'Aragon appartienne au domaine continental, il est tempéré par des interférences avec le climat méditerranéen. La topographie irrégulière donne lieu à une grande variété de microclimats. De la haute montagne dans les Pyrénées centrales au nord, avec des neiges perpétuelles et des glaciers, à la steppe semi-désertique, comme les Monegros, en passant par des zones de climat continental, comme la région de Teruel-Daroca. Cette dernière région est d'ailleurs réputée la plus froide d'Espagne : le village de Calamancha a enregistré le 17 décembre 1963 un record de .

Les caractéristiques principales du climat de l'Aragon sont :

Les températures moyennes dépendent de l'altitude. Dans la vallée de l'Ébre, les hivers sont relativement doux, bien que la sensation de froid soit renforcée par les vents du "cierzo", tandis que les températures estivales peuvent atteindre les . Dans les régions de montagne, les hivers sont plus longs et les températures inférieures de à celles qui sont enregistrées dans la vallée.

L'Aragon est partagé entre trois bassins hydrographiques :

L'Aragon est partagée transversalement par l'Èbre, qui est le fleuve au débit le plus puissant d'Espagne. La plus grande partie des rivières d'Aragon sont des affluents de l'Èbre :

Près de la frontière avec la Catalogne, le lac de retenue du barrage de Mequinenza a reçu le nom de « mer d'Aragon ». Ce vaste lac a effectivement une superficie de et une longueur de .

Un élément caractéristique de l'hydrographie est l'abondance des petits lacs de montagnes, appelés "ibones" en Aragon. Ces lacs, remarquables pour leur beauté et leur pittoresque ont été formés lors de la dernière glaciation. Ils se trouvent pour la plupart à des altitudes supérieures à .

Afin de lutter contre les effets de la sécheresse et améliorer l'irrigation, plusieurs canaux ont été creusés en Aragon à la fin du et au cours du principalement. Le plus ancien et le plus important reste le canal impérial d'Aragon, construit à la fin du , parallèlement au cours de l'Èbre, en amont de Saragosse, entre Fontellas (Navarre) et Fuentes de Ebro (Saragosse).

Les autres canaux importants sont le canal d'Aragon et Catalogne et le canal de Bardenas, construit au début du entre Yesa et le Gállego. Le dernier tronçon est, à l'heure actuelle, encore à l'étude.

Depuis la réforme territoriale de 1833, l'Aragon est divisé en trois provinces que sont la province de Huesca, la province de Saragosse et la province de Teruel. La capitale de chacune d'entre elles se trouve dans la ville du même nom.

Chaque province est divisée en comarques, au nombre de 10 dans chacune des provinces de Huesca et de Teruel, et de 13 dans la province de Saragosse. Chaque comarque est ensuite divisée en commune.

La communauté autonome d'Aragon comprend 1 parc national et 4 parcs naturels, ainsi que divers espaces naturels protégés.






Les témoignages les plus anciens de vie humaine en Aragon remontent à l'époque des glaciations, au Pléistocène, il y a environ . Ces populations ont laissé des témoignages d'artisanat acheuléen. On a retrouvé des bifaces de silex et des hachereaux de quartzite. Au paléolithique supérieur apparaissent deux nouvelles cultures : le solutréen et le magdalénien. Les restes de l'épipaléolithique, entre le et le millénaire, sont concentrés dans le Bas-Aragon, en occupant l'époque entre le et le millénaire. On trouve des objets de la période néolithique, de la première moitié du millénaire, dans les Sierras Exteriores de la région de Huesca et dans le Bas-Aragon.

L'âge du bronze est présent encore dans la province de Huesca par deux noyaux mégalithiques importants : le piémont pyrénéen des Sierras Exteriores et les hautes vallées pyrénéennes. Les dernières périodes de l'âge du bronze final, vers , sont caractérisées par la culture des champs d'urnes. Il s'agit de populations indo-européennes, originaires du centre de l'Europe, qui se mêlent à des populations méditerranéennes. Ils incinèrent leurs morts et placent les cendres dans des urnes funéraires. Des exemples existent dans la grotte du Maure à Olvena, la Masada del Ratón à Fraga et le Cabezo de Monleón à Caspe. Un essor de la métallurgie se caractérise par l'augmentation des moules de fonte qui sont trouvés dans les lieux habités.

L'âge du fer est mieux documenté. L'activité commerciale, en particulier avec les Phéniciens, les Étrusques et les Grecs, se développe et soutient la métallurgie du fer. Les outils et l'armement se modernisent et se perfectionnent. Au coexistent en Aragon six groupes distincts, appartenant aux groupes ibère, celtique et aquitain : les Vascons, les Suessétanes, les Sédétanes, les Iacétanes, les Ilergetes et les Celtibères citérieurs. Ce sont tous des groupes ibérisés, sédentaires, installés dans des villages fixes. Les exemples les plus remarquables se trouvent à Cabezo de Monleón à Caspe, Puntal à Fraga, Roquizal del Rullo et Loma de los Brunos. Le système social est basé sur le groupe familial, constitué autour de quatre générations. Les activités économiques sont principalement l'agriculture et l'élevage. Le pouvoir est exercé par un roi, entouré de la population masculine qui se réunit en assemblée.

Les Romains arrivent au et progressent facilement vers l'intérieur de l'Hispanie. Dans le premier découpage territorial de l'Hispanie, l'Aragon actuel est inclus dans l'Hispanie citérieure. Au , elle est rattachée à la province de Tarraconaise. La romanisation de la région passe par la fondation de cités nouvelles ou la refondation de cités celtibères : Caesaraugusta (Saragosse), Osca (Huesca) ou Bilbilis (Calatayud).

En 197 , Sempronius Tuditanus, préteur d'Hispanie citérieure, doit faire face à un soulèvement général qui provoque la défaite de l'armée romaine et la mort du préteur. Le Sénat envoie le consul Caton et une armée de . Pourtant, les peuples de la région, excepté les Ilergetes qui négocient leur reddition avec Caton, poursuivent le combat. La rébellion se diffuse à l'ensemble de la péninsule, ce qui entraîne des pertes élevées pour l'armée romaine, dont la moitié des effectifs est tuée en 188 Acidinus Manlius, préteur la Citérieure, affronte les Celtibères à Calagurris en 184 , tandis que Terentius Varrone bat les Suessétanes et s'empare de leur capitale, Corbio.

Au , l'Aragon est le théâtre de la guerre civile romaine, lorsque le gouverneur Quintus Sertorius, du parti marianiste, se réfugie à Osca.

Au milieu du commence le déclin de l'Empire romain. Entre 264 et 266, les Francs et les Alamans, deux peuples germaniques, traversent les Pyrénées et atteignent Tarazona, qu'ils saccagent. Des groupes de brigands, appelés bagaudes, se livrent au pillage et dévastent la vallée de l'Èbre au .

En 408, l’invasion des Vandales, des Suèves et des Alains bouleverse la péninsule ibérique, mais la Tarraconaise reste un réduit romain. En 459, Majorien est le dernier empereur qui vient en Espagne, pour maintenir la Tarraconaise et la Carthaginoise dans l’Empire romain et préparer une offensive contre les Vandales d’Afrique, qui échoue. Après lui, les rois Wisigoths prennent définitivement le contrôle des provinces espagnoles. Le sort de l'Aragon est alors celui du royaume des Wisigoths, qui perdure jusqu'en 711, date de la conquête de la péninsule par les Arabes.

Le nom d'« Aragon » apparait pour la première fois au haut Moyen Âge en 828, lorsqu'un petit comté franc, centré sur la ville de Jaca, prend le nom de la rivière qui le traverse, l'Aragon, et de son affluent, l'Aragon Subordán. Ce comté d'Aragon, durant la première moitié du , reste dans l'orbite carolingienne, qui lui est relié par la vallée d'Hecho et le col du Somport. Le monastère de San Pedro de Siresa, fondé à cette époque, est placé sous l'obédience bénédictine : son importance s’accroît et en fait le centre culturel du comté.

Au cours du , l'influence carolingienne recule au profit des voisins ibérique : le roi de Pampelune, Íñigo Arista, s'entremet dans les guerres de succession du comté, tandis que le comte Galíndez marie sa fille Sancha au wali de Huesca, Mohammed al-Tawil. L'expansion du royaume de Navarre vers le sud gêne cependant considérablement les progrès du petit comté, en lui coupant les routes de la reconquête. La mort de Aznárez sans fils légitime provoque le partage de ses terres : la Sobrarbe passe à sa fille Toda, qui a épousé Bernard, comte de Ribagorce, tandis que l'Aragon proprement dit tombe dans la dépendance du roi de Pampelune qui a épousé Endregoto Galíndez.

L'Aragon est alors considéré comme une seigneurie particulière, « terre des seigneurs aragonais », dirigée par un comte obéissant au roi de Pampelune. Le premier d'entre eux est justement un fils illégitime du comte défunt. Peu à peu, le comté d'Aragon se développe sur le plan culturel : le monastère de San Juan de la Peña, fondé par des religieux qui avaient quitté Saragosse, occupée par les Maures, devient un foyer de culture chrétienne tourné vers l'idéal de reconquête et la réintroduction du rite wisigoth dans la liturgie. En 922, les évêques d'Aragon, parfois appelés « évêque de Jaca » ou « de Huesca », s'installent dans la vallée de Borau. Ils prennent leur résidence dans plusieurs monastères majeurs, tels que San Juan, San Pedro ou San Adrián de Sasabe. Sanche le Grand donne en 1015 les territoires de l'Aragon à son fils illégitime Ramire. Son père partage en 1135 ses États entre ses quatre fils : Ramire hérite de l'Aragon, dont il devient le premier roi. En 1043, son frère Gonzalo de Sobrarbe et Ribagorce, roi de Sobrarbe et Ribagorce est assassiné, et c'est lui qui hérite de son royaume.

Le jeune royaume d'Aragon continue à s'étendre au cours du . Il intègre d'abord la région des Cinco Villas. En 1076, à la mort de « le Noble », roi de Navarre, l'Aragon arrondit ses frontières en s'emparant des territoires orientaux du royaume de Navarre, tandis que la Castille s'empare de l'ouest de ce royaume. Sous les règnes de Sanche et de Pierre, le royaume poursuit son expansion vers le sud : la ville de Huesca, prise en 1096, devient la nouvelle capitale du royaume, tandis que des forteresses sont construites à El Castellar et Juslibol, afin de surveiller les musulmans de Saragosse.

Alphonse « le Batailleur », roi à partir de 1104, poursuit la politique de conquêtes : il s'empare des terres basses de la vallée de l'Èbre : Ejea, Valtierra, Calatayud, Tudela et même Saragosse, capitale d'une puissante taïfa. À sa mort, juste après la bataille de Fraga, en 1134, les nobles aragonais élisent son frère, , dit « le Moine », car il avait choisi la vie religieuse. Afin d'assumer la continuité dynastique, il épouse Agnès de Poitiers. En 1137, sa fille, Pétronille, épouse Raimond-, comte de Barcelone. Cette union, qui donne naissance à l'entité de la couronne d'Aragon se renforce considérablement, et conduit à la conquête des royaumes de Majorque et de Valence. La puissance aragonaise se déploie en Méditerranée, et le roi d'Aragon s'empare également de la Sicile et de Naples.

La couronne d'Aragon subit cependant une grave crise en 1412, à la suite de la mort du roi « l'Humain » sans descendance. Le compromis de Caspe conduit à l'élection de Ferdinand de Antequera par la noblesse aragonaise. Ce noble d'origine castillane, de la famille des Trastamare, est également descendant du roi aragonais par sa mère, Éléonore d'Aragon. Dans ce vaste ensemble, l'Aragon est alors un royaume qui possède ses Cortes propres, un droit particulier et une députation royale propre. L'union de et d'Isabelle de Castille, en 1469, à Valladolid, provoque l'union des deux principaux royaumes de la péninsule, à la base de la création de l'Espagne moderne.

L'histoire de l'Espagne est marquéee, à l'époque moderne, par le conflit entre les institutions monarchiques espagnoles, qui tendent à la centralisation, et les institutions médiévales locales, qui tendent à la conservation des particularismes et des privilèges locaux. Ce conflit éclate une première fois en 1592, à la suite des troubles que connait l'Aragon entre 1590 et 1591. Aux Cortes de Tarazona, décide de remodeler les institutions aragonaises, même s'il ne les supprime pas : le roi choisit le vice-roi (même s'il n'est pas aragonais) et le justicier d'Aragon, la députation du royaume perd le contrôle des impôts, la surveillance du territoire et la nomination des représentants des villes, la cour de justice passe sous le contrôle du roi.

Le est une période de décadence pour les institutions aragonaises. Mais il est également une période de travail historique intense qui débouche sur une importante littérature historiographique et juridique du royaume. Afin de soutenir cet effort sont créées en 1601 les archives du royaume d'Aragon, tandis que le poste de chroniqueur d'Aragon prend de l'importance, avec des hommes comme Jerónimo Zurita. Des chroniques particulières se multiplient : "Información de los sucesos de Aragón de 1590 y 1591" et les "Alteraciones populares de Zaragoza del año 1591" des frères Argensola. De la même manière, une "Historia de las cosas sucedidas en este Reyno" d'Antonio de Herrera est condamnée à être brûlée par la députation.

Durant la guerre de Succession, l'Aragon prend le parti de l'héritier habsbourg, l'archiduc Charles d'Autriche, contre l'héritier désigné, de Bourbon. Après la bataille d'Almanza, en 1707, abolit les droits aragonais et adopte diverses mesures : ces transformations, qui débouchent sur les décrets de Nueva Planta, transforment l'Aragon en simple province du royaume.

Au cours des , l'histoire de l'Aragon ne se distingue pas vraiment de celle du reste de l'Espagne. L'occupation française et la guerre d'Indépendance provoquent des destructions importantes en Aragon. Saragosse, assiégée par deux fois, en 1808 et en 1809, est complètement ruinée. Plus tard, les guerres carlistes, au , trouvent un écho en Aragon. Les carlistes, à la recherche de partisans, proposent le rétablissement des libertés forales aragonaises.

D'un point de vue administratif, l'Aragon est découpé en 1822 en quatre provinces : Saragosse, Huesca, Teruel et Calatayud. Cette dernière est supprimée après la réorganisation administrative de 1833. Cette perte d'importance traduit l'exode rural massif, qui voit l'émigration des paysans aragonais vers les centres urbains de Saragosse, Huesca, Teruel et Calatayud, mais aussi vers les grandes villes voisines, comme Madrid et Barcelone.

Au début du , l'Aragon reste une des régions les plus pauvres d'Espagne. À ce titre, elle devient un des points principaux pour la relance économique initiée sous la dictature de Primo de Rivera. L'anarcho-syndicalisme s'y développe cependant considérablement, au point d'en faire un des bastions des syndicats de la CNT et de la FAI. À la différence d'autres régions d'implantation de l'anarchisme, comme la Catalogne, il s'agit d'un anarchisme paysan, où la question de la réforme agraire reste prédominante. À ce titre, la mise en place de la république en 1931 est largement soutenue dans les villes comme dans les campagnes. En juin 1936 est présenté devant les Cortes espagnoles un avant-projet du statut d'autonomie d'Aragon, sur le modèle des statuts basque et catalan, qui sera la base des revendications autonomistes postérieures, à la fin du .

Le déclenchement de la guerre d'Espagne, à la suite de la tentative de coup d'État militaire, en juillet 1936, empêche cependant la poursuite de ce projet d'autonomie. Dès les premiers jours de la guerre, l'Aragon se retrouve coupé en deux : la moitié occidentale, avec les capitales provinciales de Saragosse et Téruel, tombe entre les mains des nationalistes. Sous l'influence de milices populaires anarchistes et communistes, l'Aragon est, en 1936 et 1937, le cadre d'une des tentatives de gestion anarchiste originale, dans le cadre du Conseil régional de défense d'Aragon. Entre 1936 et 1939, plusieurs des batailles les plus importantes ont pour théâtre les provinces aragonaises : Belchite, Téruel et enfin l'Èbre. À la suite de l'offensive d'Aragon, en 1939, c'est l'ensemble de l'Aragon qui tombe sous l'autorité franquiste.

Durant les années 1960, l'Aragon souffre d'un exode rural et d'un déclin démographique important dans les zones rurales. Afin de redynamiser la région, Saragosse bénéficie d'un plan de développement dans le cadre des pôles de développement nationaux ("Polos de Desarrollo").

Dans le cadre de la transition démocratique, l'Aragon devient, en 1978, une communauté autonome. Le sentiment régionaliste se développe et se rend visible sur la scène politique, en particulier lors de la manifestation du 23 avril 1978, qui réunit plus de personnes dans les rues de Saragosse. Le 10 août 1982, la loi organique sur le statut d'autonomie de l'Aragon, votée par les Cortes Generales, est promulguée par le roi et le président du gouvernement. Le 7 mai 1992, une commission spéciale des Cortes d'Aragon élabore un texte qui vise à réformer le statut d'autonomie. Il entre en vigueur la même année, après l'approbation des Cortes d'Aragon et les Cortes Generales. En 1996, une nouvelle réforme élargit les compétences de la communauté. Ces changements poussent à une révision complète, qui débouche sur un nouveau statut, approuvé à la majorité en 2007.

Dans les années 1990, l'Aragon commence à profiter de la croissance économique du « miracle espagnol ». Les infrastructures sont considérablement améliorées : construction de la voie grande vitesse qui relie Madrid à la frontière française par Madrid-Calatayud-Saragosse-Barcelone, de l'autoroute « Mudéjar », des aéroports de Saragosse et Huesca-Pyrénées. De grands projets de technopoles se développent, comme le parc technologique Walqa, près de Huesca. Enfin, la ville de Saragosse a accueilli, en 2008, une exposition internationale. Pour ce qui est du divertissement, le projet de Gran Scala est un des plus importants en cours.

Le blason actuel de l'Aragon se compose de quatre quartiers et est confirmé pour la première fois par un témoignage écrit en 1499. Ce blason, remis au goût du jour au , après avoir été oublié, est confirmé comme le blason officiel par l'Académie royale d’histoire en 1921.

Le premier quartier est une reproduction du blason de Sobrarbe, qui apparaît à la fin du et commémore, selon la tradition, le légendaire royaume de Sobrarbe. Le second quartier, qui représente la croix d'Íñigo Arista, est un ajout du roi aragonais le Cérémonieux : s'appuyant sur une interprétation anachronique qui fait de cette croix le symbole de la religion chrétienne des premiers rois asturiens, navarrais et aragonais, il l'ajoute au blason des rois d'Aragon. Le troisième quartier est une croix d'Alcoraz, c'est-à-dire une croix de saint Georges cantonnée de quatre têtes de Maures, confirmée la première fois sur un sceau de d'Aragon, datant de 1281, et rappelant, selon la légende, la bataille au cours de laquelle Pierre et son fils, le futur le Batailleur, s'emparèrent de la ville de Huesca. Le quatrième quartier, appelé les « barres d'Aragon » ou « enseigne royale d'Aragon », est le plus ancien des emblèmes héraldiques d'Aragon, remontant au moins à la deuxième moitié du "(voir son origine légendaire sous Guifred le Velu)." Ces « barres » sont d'ailleurs visibles dans le troisième quartier du blason de l'Espagne.

Le drapeau actuel a été approuvé en 1984, par l'article 3 du statut d'autonomie d'Aragon. Il reprend les quatre « barres d'Aragon » disposées horizontalement. Sur le côté gauche a été ajouté le blason de l'Aragon.

L'hymne d'Aragon a été officialisé en 1989. Sur une musique du compositeur aragonais Antón García Abril, il combine l'ancienne tradition musicale aragonaise, avec des éléments populaires, dans une conception moderne. Les paroles furent écrites par les poètes aragonais Ildefonso Manuel Gil, Ángel Guinda, Rosendo Tello et Manuel Vilas : elles s'efforcent de souligner les valeurs de liberté, justice, raison, vérité, accueil…

La Journée de l'Aragon est célébrée le 23 avril et commémore saint Georges, patron du royaume d'Aragon depuis le . Ce jour férié est confirmé par l'article 3 du statut d'autonomie d'Aragon de 1984. Cette journée est l'occasion de festivités officielles, comme la remise du prix Aragon par le gouvernement aragonais ou encore la composition d'un tapis de fleurs représentant le drapeau aragonais, place d'Aragon à Saragosse.

Dans la plus grande partie de l'Aragon, la langue utilisée couramment reste le castillan, qui est langue officielle de la communauté autonome, tout comme de l'État espagnol. Dans la partie nord de l'Aragon, on parle l’aragonais tandis que dans la partie orientale, appelée la Frange d'Aragon, est parlé le catalan.

Le statut d'autonomie ne reconnait aucun caractère officiel aux langues aragonaise et catalane en Aragon. Cependant, la Loi sur le patrimoine culturel d'Aragon, en 1999, a reconnu leur particularité et renforcé leur protection. Après l'approbation de la Loi sur les langues d'Aragon de 2009, et avec le soutien du président Marcelino Iglesias, l'aragonais et le catalan ont été reconnues comme langues propres à l'Aragon, mais pas comme langue officielle. Ainsi, les testaments et les contrats de mariage peuvent légalement être rédigés dans n'importe laquelle des trois langues en usage dans la communauté.

Le castillan est aujourd'hui encore la seule langue officielle en Aragon. Le dialecte local, appelé « castillan aragonais », possède ses propres caractéristiques. La plupart de celles-ci sont tout simplement dérivées de la langue aragonaise, en particulier dans l'intonation et le vocabulaire. Le castillan de la Frange d'Aragon est en revanche marqué par des catalanismes plus nombreux.

Au Moyen Âge, la langue vernaculaire traditionnellement parlée dans la majorité du territoire était l’aragonais. Celui-ci a néanmoins connu à partir du un fort processus de castillanisation et il subsiste essentiellement dans les zones rurales et septentrionales, ainsi que de façon résiduelle, par l'influence qu'il a exercée sur le castillan. L'aragonais est considéré par l'Union européenne comme une langue minoritaire en danger de disparition : 

Le bénasquais, parlé dans la vallée de Bénasque, est un dialecte de transition entre catalan et aragonais.

Dans la Frange d'Aragon, située dans la partie orientale de la région, la langue traditionnelle est une variante de catalan occidental, dont l'usage est partiellement conservé dans la vie quotidienne. Cette langue locale subit cependant la normalisation rapide et croissante du catalan par la télévision et la radio.

Les cultures maraîchères de la vallée de l'Èbre ont permis le développement de légumes et de fruits largement utilisés dans la cuisine locale, comme l'oignon des Sources de l'Èbre. Le cardon, lors des fêtes de Noël, est préparé avec une sauce à base d'amandes et de pignons. La bourrache de Saragosse sert à la fabrication de "crespillo" de bourrache, très répandu dans la région du Somontano de Barbastro. Parmi les fruits, le plus réputé est la pêche, qui bénéficie d'une DOC dans le Bas-Aragon, sous le nom de pêche de Calanda. Les châtaignes de Huesca sont également réputées.

L'agneau de lait d'Aragon est également une spécialité qui s'appuie sur la tradition ovine de la région. Il est protégé par une DOC particulière. Il est généralement préparé en rôti. L'agneau, comme le poulet, peut être accompagné d'une sauce au "chilindrón" ("cordero" ou "pollo al chilindrón"), à base de tomates, de poivrons rouges et d'ail. Le poulet à la "pepitoria" ("pollo en pepitoria") est cuisiné à partir des jus de la viande de poulet mélangés à du jaune d'œuf dur et des amandes en poudre.

La charcuterie aragonaise possède également plusieurs spécialités, telles que le boudin au riz ("morcilla de arroz"), la saucisse de Graus ("longaniza de Graus") et la boutifarre ("butifarra"). Mais la plus connue des spécialités reste le jambon de Teruel.

Parmi les plats aragonais les plus réputés, on retrouve les "migas de pastor", un plat d'origine paysanne, sorte de ragoût de pain dur frit avec des lardons, du chorizo, du poivron, de l'oignon et de l'ail. On le sert traditionnellement avec des œufs frits. La "chireta" est une sorte de "haggis", élaborée à partir de tripe d'agneau ("chireta" signifie « peau retournée » en aragonais) cousue et fourrée de riz, auquel on ajoute les ris, les poumons et le cœur de l'agneau : l'ensemble est cuit bouilli.

Quoique l'Aragon soit éloigné de la mer, plusieurs spécialités locales se préparent à partir de poisson. La morue à l'ail "arriero" ("bacalao al ajoarriero") est élaboré avec de la morue salée, poêlée avec de la tomate et de l'ail. La sardine rancie ("sardina rancia"), souvent utilisée en tapa, est une sardine qui a macéré en salaison. Les poissons de fleuves comme la truite peuvent être accommodés à l'aragonaise ("truchas a la aragonesa") ou à la mode de Teruel ("truchas a la turolense").

Parmi les fromages, le plus connu est le "queso" de Tronchón, fabriqué sur les hauteurs du Maestrazgo, à Tronchón. On retrouve également des fromages réputés à Alcañiz, Samper de Calanda, Hecho, Biescas, El Burgo de Ebro ou Gistaín.

Les desserts sont généralement simplement élaborés. C'est à Catalayud que sont confectionnés les desserts de "Frutas de Aragón", préparés à partir de fruits macérés et cuits dans le sirop, puis couverts de chocolat, afin de leur donner une apparence de bonbon. Les fruits les plus utilisés sont la pomme, la poire, la pastèque, l'abricot, la cerise, la figue, la prune et l'orange. Le "guirlache", similaire au tourron, est composé à partir d'amandes et de caramel. Le pavé du Pilar ("adoquín del Pilar") est un caramel de grande taille, d'environ , emballé d'une image de la Vierge du Pilar sur fond blanc, tandis que l'intérieur contient les paroles d'une chanson populaire aragonaise. Les galettes du cœur ("tortas de alma"), sont fabriquées dans la province de Teruel. Ce sont des petites tourtes de pâte fourrées aux cheveux d'ange et parfumées à l'anis ou au moscatel. Il existe d'autres pâtisseries traditionnelles comme la coca, la tresse d'Almudévar ("trenza de Almudévar"), les nœuds de Jaca ("lazos de Jaca").

Enfin, plusieurs vins aragonais bénéficient d'une DOC : les vins de Somontano, de Campo de Borja, de Cariñena et de Calatayud. L'huile d'olive du Bas-Aragon et de la Sierra de Moncayo est également protégée par une appellation.

Selon l'article 11 du Statut d'autonomie d'Aragon, les quatre institutions qui ont un pouvoir politique sont les Cortes d'Aragon, la Présidence d'Aragon, la Députation générale d'Aragon et le Justicier d'Aragon.

Le parlement aragonais, ou Cortes d'Aragon, possède le pouvoir législatif. Les représentent le peuple aragonais : pour la province de Huesca, pour la province de Teruel et pour la province de Saragosse. Ils choisissent parmi leurs membres le Président d'Aragon, le Bureau et la Députation permanente.

Les députés sont chargés du vote des lois et du budget. Ils contrôlent l'action de la Députation générale.

Les principaux partis présents sont le PP de Aragón, le PSOE-Aragón, Podemos, Ciudadanos, le PAR, le CHA et IUA. Le siège des Cortes se trouve depuis 1986 dans le palais de la Aljafería, à Saragosse.

Le président d'Aragon est le socialiste Javier Lambán.

Le siège de la Présidence se trouve dans le bâtiment Pignatelli, l'ancienne Real Casa de la Misericordia de Saragosse.

La Députation générale d'Aragon ou gouvernement d'Aragon ("Diputación General de Aragón") est l'instance exécutive de la communauté autonome. Il comprend l'Assemblée et le président de la Députation générale.

La Députation actuelle a été créée en 1983, après approbation du statut d'autonomie. Son siège se trouve dans la Real Casa de la Misericordia, à Saragosse.

Le Justicier d'Aragon ("Justicia de Aragón") est une institution d'origine médiévale, apparue dans le royaume d'Aragon au , afin d'agir comme médiateur entre les nobles et le roi. Réapparu en 1982, après l'approbation du nouveau statut, il est chargé de défendre les droits et les libertés des citoyens contre les éventuels abus de l'administration de la communauté autonome, à l'instar du Défenseur des droits en France. Son activité judiciaire reste cependant limitée, dans la mesure où il ne peut prononcer un jugement ni prendre aucune mesure coercitive. Il peut diffuser des recommandations et des informations auprès de l'administration.

Il est élu par au moins 60 % des députés des Cortes d'Aragon, pour une durée de 5 ans.

Son siège se trouve dans le palais Armijo, à Saragosse.

L'Aragon compte aujourd'hui deux aéroports :

Il existe également plusieurs aérodromes :

La communauté autonome est chargée de l'entretien de toutes les routes de la Députation générale d'Aragon, des routes des trois députations provinciales et des communes aragonaises. Cela représente quelque , dont la moitié environ appartiennent à la Députation générale, à l'État et aux députations provinciales.

La Députation générale a entrepris un gros effort de rénovation des routes dans les années 1990 et 2000. Elle a ainsi entrepris la construction de la première autoroute à péage appartenant à une communauté autonome, entre El Burgo de Ebro et Villafranca de Ebro. Le but était de relier , , et , afin de former la cinquième rocade ou "Quinto Cinturón" (Z-50) autour de Saragosse.

La LGV Madrid-Saragosse-Lérida traverse la communauté autonome depuis 2003. En Aragon, les trains grande vitesse AVE s'arrêtent aux gares de Calatayud et Saragosse-Delicias. Depuis 2008, la ligne a été complétée vers Barcelone et Perpignan. Des projets d'extension sont prévus en direction de Huesca (gare de Plana de Uesca), bien que le maintien de la grande vitesse ne soit pas possible sur cette section.

Parallèlement existe un projet de rénovation de la ligne Saragosse-Teruel, afin de l'inclure dans le grand projet de LGV Cantabrie-Méditerranée, entre Santander et Valence. Les travaux impliquent le changement de l'écartement des voies, l'électrification complète de la ligne et son dédoublement.

Une originalité du réseau ferroviaire aragonais reste la gare internationale de Canfranc, vaste gare inaugurée en 1928 sur la ligne Pau - Canfranc. À la suite d'un accident ferroviaire en 1970, la gare vit son activité, déjà faible, s'arrêter presque complètement.

Le PIB de l'Aragon représente environ 3% du PIB total de l'Espagne. Le PIB par habitant était, en 2008, de , ce qui place l'Aragon au , au-dessus de la moyenne de l'Espagne et de l'Union européenne.

L'économie traditionnelle de l'Aragon appartient au secteur primaire, où prédominent les cultures de céréales et de fourrage, complétées par un important élevage ovin. Les produits aragonais les plus connus restent l'agneau de lait d'Aragon, les vins du Somontano, le jambon de Teruel, l'huile d'olive du bas-Aragon, la pêche de Calanda et l'amande. Les appellations d'origine se développent, afin de garantir la qualité des produits. Cette économie a connu de profonds bouleversements au cours du , qui a vu l'essor des secteurs industriel et tertiaire 

L'entreprise Opel (Groupe PSA) possède une usine près de la ville de Saragosse, à Figueruelas. Il existe d'autres entreprises importantes dans les domaines de l'énergie, comme l'électricien Endesa qui possède une centrale thermique à Teruel, de la papeterie, avec la SAICA implantée à Saragosse et Burgo de Ebro et ICT Ibérica, également à Burgo de Ebro, ou du bois, avec Cella. Mais c'est la ville de Saragosse qui a le plus bénéficié du développement de la région, et concentre aujourd'hui des entreprises diverses, comme Pikolín, Sabeco, Inditex, BSH ou les Chocolates Lacasa.

Le complexe PLAZA, près de l'aéroport de Saragosse, permet à la ville de devenir un centre important pour la logistique et le transport de marchandises. Le parc technologique Walqa, près de Huesca, est également un important technopôle, qui concentre plus de 60 entreprises dans les domaines de l'information, des biotechnologies et des énergies renouvelables. Le tourisme, en particulier tourné vers le sport, bénéficie de conditions favorables en Aragon. Les stations de ski pyrénéennes comme Aramón Formigal et Candanchú profitent de l'amélioration des infrastructures, avec l'autoroute Saragosse-Somport. Le tourisme culturel bénéficie également du rayonnement de l'art mudéjar, très présent à Huesca, Saragosse et surtout Teruel, qui a reçu la protection de l'UNESCO au titre de patrimoine mondial de l'humanité sous l'intitulé d'art mudéjar d'Aragon.

Selon le recensement de 1991, l'Aragon comptait habitants, soit 3,10 % de la population espagnole totale. Le recensement de 1996 a dénombré habitants, soit un recul de plus de habitants. Aujourd'hui, selon le recensement de 2010, ce chiffre est de habitants. Mais la population aragonaise ne représente actuellement pas plus de 2,86 % de la population totale de l'Espagne.

La proportion d'étrangers était, en 2006, de 8,25 % de la population totale de la communauté, ce qui reste proche de la moyenne nationale (9,27 %)

La population est inégalement répartie, environ 50,12 % des Aragonais, soit personnes, habitent à Saragosse, seule ville de la communauté qui dépassent les . Cette concentration de la population aragonaise dans la capitale est relativement récente, dans la mesure où, en 1950, la capitale ne pesait que 24 % de la population de la communauté. Conséquence de l'exode rural, le peuplement du territoire aragonais est extrêmement faible. Avec une densité de , l'Aragon se place au quatrième rang des communautés à la densité de population la plus faible d'Espagne, après la Castille-La Manche, l'Estrémadure et la Castille-et-León.




</doc>
<doc id="15546" url="https://fr.wikipedia.org/wiki?curid=15546" title="Saragosse (homonymie)">
Saragosse (homonymie)

Saragosse désigne notamment :




</doc>
<doc id="15547" url="https://fr.wikipedia.org/wiki?curid=15547" title="Zaragoza">
Zaragoza



</doc>
<doc id="15548" url="https://fr.wikipedia.org/wiki?curid=15548" title="Choucroute">
Choucroute

La choucroute (de l'allemand : "Sauerkraut" , par l'alsacien : "Sürkrüt", du chinois : 酸菜) est un plat qui se consomme traditionnellement, avec des variantes locales : en Allemagne, Autriche, Belgique, Bosnie, Bulgarie, France (plus particulièrement en Alsace, où elle est emblématique de la cuisine locale), Hongrie, au Luxembourg, en Pologne, aux Pays-Bas, République tchèque, Roumanie, Russie, Serbie, Slovaquie, Suisse, dans le sud du Brésil, au Chili, aux États-Unis, en République populaire de Chine (et aussi, plus généralement, mais non de manière exclusive, par des populations issues des vagues d'immigration allemandes et germaniques, ainsi, par exemple, en Namibie). 

Au Chili, la choucroute fait partie du traditionnel "completo chileno". En Chine, elle est consommée dans la province du Heilongjiang (Mandchourie) . En Italie, dans la région du Trentin-Haut-Adige ou Trentin-Tyrol du Sud, elle bénéficie depuis 1999 de l'appellation « Produits agroalimentaires traditionnels » (PAT), appellation italienne qui n'est pas reconnue au niveau européen.

C'est un mets composé de chou coupé finement et soumis à lacto-fermentation dans une saumure, généralement accompagné de garniture.

L'origine du mot est à rapporter à "Sauerkraut" en allemand : littéralement « chou aigre », altéré en « chou » et « croute ». 

En France, il dérive du dialecte alsacien.

Ce mode de préparation du chou viendrait de Chine, où, selon la légende, il aurait été inventé au avant notre ère par les constructeurs de la Grande Muraille pour résister au froid.
Si la grande muraille était d'abord destinée à se protéger des hordes venues du nord, ou Huns, considérés par certains avec les Xiongnu comme les ancêtres des Mongols. Il est probable que ce soit Attila et les Huns qui auraient, après avoir échoué à conquérir la Chine, porté ensuite leurs conquêtes vers l'ouest, passant par la Bavière et l'Autriche avant d'atteindre l'Alsace en 451. Ils iront même jusqu'à Orléans avant d'être repoussés par les Romains et les Wisigoths, alliés. C'est la date probable à laquelle cette préparation du chou est apparue dans ces régions, qui utilisaient aussi la lacto-fermentation pour la conservation d'autres légumes, notamment du navet (navet salé).

La choucroute reste le principal plat de la province du Heilongjiang dans l’extrême Nord-Est de la Chine. Le Baechu gimchi, un plat de choux fermenté pimenté, de la Corée voisine, et ses variantes composées de différents légumes, appelés plus généralement kimchi, sont aussi très connus.

En France, les premières références à la cuisson du chou ainsi préparé datent du , des textes du en attestent la présence à la table des monastères. Au , on le trouve sous l'amusant nom de « "Kompostkrut" » (chou compost), et au siècle suivant il se généralise en Alsace, dans une partie de la Lorraine et dans le Bade-Wurtemberg voisin.

En France, ce n'est qu'au que la choucroute désignera le plat de chou cuit avec son accompagnement. Le chou fermenté est généralement cuit dans du vin blanc mais peut aussi l'être dans le cidre, la bière ou le champagne. D'autres variantes, plus récentes, remplacent la viande et charcuterie par un assortiment de poissons, nommée « choucroute de la mer », ou des saucisses de soja « choucroute végétarienne ».

Le chou est débarrassé de ses feuilles externes et de son trognon, puis les feuilles restantes sont laissées entières (en Roumanie) ou coupées en fine julienne sur un coupe-chou, rabot à lame multiple destiné à cet usage.

Il est ensuite disposé par couches de vingt centimètres d'épaisseur séparées par des couches de sel, environ 2,5 % à 3 % du poids des légumes, dans un haut tonneau de bois ou de grès. Une planche de bois ajustée permet de fermer le récipient de manière à isoler le chou de l'air, une pierre de lester le couvercle et comprimer le tout.

Les bactéries nécessaires à la fermentation sont naturellement présentes dans le chou. Au début, "Leuconostoc mesenteroides" commence son œuvre, puis est tué par ses propres sécrétions d'acide lactique lorsque la concentration de ce dernier atteint 0,25 % à 0,3 %. "Lactobacillus plantarum" et "Lactobacillus cucumeris", pour l'essentiel, prennent le relais et amèneront la teneur totale en acide lactique à environ 2,5 %.

La durée totale du processus de fermentation est d'environ 6 à 8 semaines, selon la quantité de sel utilisée.

Industriellement, la fermentation se fait plutôt dans des cuves en ciment ou en plastique, et un brassage journalier avec un ajout de vinaigre au vin blanc permet d'accélérer le processus, qui ne met alors qu'environ deux semaines.

En fonction de la quantité de sel ajoutée, la choucroute se conserve plus d'une année sans problèmes.

La choucroute d'Alsace : le terme « choucroute » est une adaptation populaire et phonétique du mot alsacien "« Sürkrüt »" (Sür = aigre et Krüt = chou).

La choucroute d'Alsace est un légume transformé, obtenu par fermentation lactique de feuilles de choux préalablement découpées en lanières, et mises en cuves de fermentation en y ajoutant le sel nécessaire à la conservation du produit.

L'Alsace assure à elle seule entre et de choucroute par an, soit environ 70 % de la production nationale (statistiques 2012).

Dans le Bas-Rhin, la culture du chou est localisée autour de la ville de Krautergersheim : c'est dans cette localité, capitale de la choucroute, que sont produits 25 % de la production nationale ; même le jus de choucroute y est récupéré, afin d'en faire du biogaz. 

Le Haut-Rhin compte encore quelques producteurs de choucroute: on les retrouve notamment autour de la région de Colmar, à Wickerschwihr et Holtzwihr.

L’arrêté du 8 octobre 2012 paru au "Journal officiel" de la République française du 18/10/2012 a reconnu l’homologation du cahier des charges de l’Indication Géographique Protégée « Choucroute d’Alsace » et a marqué l’entrée en application d’une Protection Nationale Transitoire (PNT). Aujourd’hui, la demande d’IGP est toujours en cours d’instruction européenne. 

L'Aube, avec 20 % de la production nationale, est en 2009 le deuxième département producteur de chou à choucroute. Une fête de la choucroute y a lieu tous les ans à Brienne-le-Château. Viennent ensuite la Sarthe et le Nord-Pas-de-Calais.

La choucroute, facile à conserver et riche en vitamine C, est un repère dans l'évolution alimentaire, tant elle améliora la nutrition et la santé des populations, l'hiver. Elle contribua, de façon non négligeable, au développement économique en aidant à lutter contre le scorbut, dont les marins étaient souvent victimes durant les longs voyages maritimes

En accompagnement et en tenant compte de sa teneur en sel, la choucroute est particulièrement diététique et facilite le transit intestinal.

En 2007, la consommation annuelle moyenne de choucroute est estimée à par personne.

Dans la région liégeoise, il est de coutume de manger une choucroute en famille le jour de l'an. On place alors une pièce de monnaie sous l'assiette, dans sa main ou dans sa poche. Ce symbole est censé apporter prospérité tout du long de l'année.






</doc>
<doc id="15552" url="https://fr.wikipedia.org/wiki?curid=15552" title="Kalpana Chawla">
Kalpana Chawla

Kalpana Chawla, née le (sa date de naissance a été ensuite modifiée en juillet 1961 pour qu'elle soit admise plus tôt à l'école) et morte le , est une astronaute américaine d'origine indienne, spécialiste de mission pour la navette spatiale. Elle est morte lors de la rentrée dans l'atmosphère de la navette spatiale Columbia.

Kalpana Chawla, dite "K.C.", est née à Karnal, dans l'État de l'Haryana en Inde. Son intérêt pour le vol fut inspiré par J. R. D. Tata, le premier pilote de l'Inde.

Kalpana Chawla étudie la construction aéronautique à l'Institut de technologie du Pendjab en 1982. Elle part ensuite aux États-Unis pour obtenir une maîtrise de sciences en technologie aérospatiale à l'université du Texas (1984). Le Chawla obtient un doctorat en technologie aérospatiale à l'université du Colorado en 1988. La même année, elle commence à travailler pour la NASA au centre de recherches d'Ames.

Kalpana Chawla devient citoyenne américaine en avril 1991 et épouse Jean-Pierre Harrison, un instructeur de vol indépendant. Elle était détentrice de multiples licences de vol.

Elle meurt lorsque la navette spatiale Columbia se désintégre lors du retour dans l'atmosphère terrestre, le février 2003. Les six autres membres de l'équipage sont également tués durant cet accident.

Le Chawla intégra le programme d'astronaute de la NASA en 1994 et fut sélectionnée pour voler en 1996. La première mission de Kalpana Chawla dans l'espace commença le , comme membre de l'équipage de 6 astronautes qui effectua le vol STS-87 sur la navette spatiale Columbia. Kalpana Chawla est ainsi la première femme d'origine indienne à voler dans l'espace et le deuxième astronaute indien après le cosmonaute Rakesh Sharma qui participa en 1984 à un vol sur un vaisseau soviétique. Lors de sa première mission, Kalpana Chawla parcourut près de 10 millions de km au cours de 252 orbites autour de la Terre, comptabilisant plus de 375 heures dans l'espace. Lors du vol STS-87, elle était responsable du déploiement d'un satellite dont le dysfonctionnement obligea deux autres astronautes à faire une sortie extra-véhiculaire. Après cinq mois d'enquête, la NASA pointa du doigt les équipes de vol et de contrôle au sol et la dégagea de toute responsabilité.

Après avoir été choisie pour un deuxième vol, Kalpana Chawla vécut au centre spatial Lyndon B. Johnson de Houston au Texas, suivant une formation approfondie. Cette mission fut retardée en juillet 2002 lorsque des ingénieurs de la NASA identifièrent trois fissures dans le circuit d'alimentation en hydrogène du second moteur de la navette. Six mois plus tard, la navette fut déclarée opérationnelle et partit pour la mission funeste STS-107.





</doc>
<doc id="15558" url="https://fr.wikipedia.org/wiki?curid=15558" title="Vignoble d'Alsace">
Vignoble d'Alsace

Le vignoble d'Alsace est une région viticole française. Il s'étire en une étroite bande sur presque toute la longueur de la région Alsace, entre le massif des Vosges et la plaine du Rhin.

Les vins produits sont essentiellement des blancs (sous les appellations alsace et alsace grand cru), des mousseux (appellation crémant d'Alsace), ainsi que quelques rosés et rouges (appellation alsace). Le vignoble produit également une eau-de-vie, le marc d'Alsace. La réputation de la production vinicole alsacienne s'appuie sur des vins parfois puissants en termes d'arômes, de sucre et d'alcool, notamment le gewurztraminer, le riesling et le pinot gris.
Les débuts de la viticulture en Alsace sont difficiles à dater. Si des sources archéologiques récentes la font remonter à la période romaine, les historiens plus anciens la limitent au haut Moyen Âge. La région fait partie, de la fin du jusqu'à la crise du, de la province de Germanie supérieure où se trouvent stationnées d'importantes forces militaires. La présence de ces garnisons, tout particulièrement celles composées d'un camp légionnaire situé le long du Rhin, nécessite l'importation de vin en provenance d'Hispanie puis de Narbonnaise. Ces besoins ont stimulé la naissance de la viticulture, notamment dans la vallée de la Moselle (province de Belgique) dont la production est exportée à "CCAA" (Cologne, capitale de la province de Germanie inférieure) et jusqu'en Bretagne.

Les fouilles archéologiques menés depuis 1998 à Biesheim et Kunheim ont mis au jour des raisins datés par leur contexte du Haut-Empire. Étant donné la romanisation particulièrement lente de la province de Germanie supérieure et la faible densité de population, la petite production locale ne peut subvenir au ravitaillement des troupes y stationnant, d'où le maintien des importations.

À partir du début du , la province est en partie conquise par les Alamans, qui traversent régulièrement le Rhin pendant toute la période du Bas-Empire romain pour piller les villes et les campagnes. Au , l'Alsace fait partie du royaume des Alamans, jusqu'à sa conquête par les Francs.

La viticulture ne connait un nouvel essor que sous l'influence des ordres monastiques au plus tard pendant la période carolingienne. La plus ancienne source littéraire mentionnant la viticulture en Alsace date du début du , attestant l'existence d'une production vinicole dans plus de 160 lieux.

Au Moyen Âge, les vins d'Alsace ou « vin d'Aussey » étaient réputés. Ils s'exportaient vers les pays nordiques par l'Ill puis au-delà par le Rhin.

Au , la zone de production s'étendait sur une surface deux fois plus grande que le vignoble actuel. De nombreux bâtiments, encore conservés aujourd'hui et datant du début de la Renaissance, attestent de cette période florissante. De cette époque date aussi la première tentative d'établissement d'une sorte d'appellation d'origine contrôlée : une association de vignerons de Riquewihr décida alors de la date officielle de début des vendanges, et définit les cépages à planter.

La guerre de Trente Ans mit fin à cette période faste et apporta dans la contrée la guerre, les pillages, la famine et la peste. Pratiquement tous les vignobles furent détruits. Après la fin de la guerre, la viticulture se reconstruisit, et la superficie plantée remonta jusqu'à en 1828.
En conséquence de la défaite française lors de la guerre de 1870-1871, la République française cède une partie de son territoire à l'Empire allemand, ce qui fait que de 1871 à 1918 l'Alsace fait partie de l'Empire allemand avec la Moselle sous le nom de "". Pendant cette période, le pays était la plus grande région viticole allemande. Le volume de production est privilégié au détriment de la qualité. De plus, avec les ravages causés par le phylloxéra et le mildiou, le développement des transports ferroviaires bon marché et de la consommation croissante de bière, le vignoble se rétrécit à une superficie de , dont dans l'actuelle appellation alsace.

En , l'Alsace est occupée par l'armée française, puis cédée à la France par le traité de Versailles le 28 juin 1919. En raison du maintien du droit local (correspondant aux lois françaises antérieures à 1871 et aux lois allemandes de 1871 à 1918), l'Alsace a un statut à part au sein des vignobles français, car la loi allemande du 7 avril 1909 sur les vins y est appliquée jusqu'à la fin de la Seconde Guerre mondiale. La situation évolue par l'ordonnance du , qui définit une appellation d'origine « vins d'Alsace » ou « alsace », encadrée tardivement comme appellation d'origine contrôlée par un décret du , après négociation avec le comité interprofessionnel du vin d'Alsace (CIVA), créé pour l'occasion (décret du ).
Le décret du fait apparaître les AOC de vins de cépage.
S'y sont rajoutées les appellations alsace grand cru (décret du ) et crémant d'Alsace (décret du ).

Les efforts sont depuis plutôt orientés vers la production de vins de meilleure qualité, la communication commençant à insister sur la notion de terroir. Allant dans ce sens, le décret de 2011 prévoit onze dénominations géographiques au sein de l'appellation alsace, tandis que les géographiques de l'appellation alsace grand cru deviennent autant d'appellations partageant le même cahier des charges.

Le vignoble s'étend sur toute la longueur de l'Alsace, le long d'un axe orienté du nord-nord-est au sud-sud-ouest. Les extrémités sont au nord à Wissembourg (dans le département du Bas-Rhin) sur la frontière franco-allemande (le vignoble se poursuit dans le Palatinat rhénan) et au sud à Leimbach près de Thann (département du Haut-Rhin). L'ensemble forme une mince bande de plus d'une centaine de kilomètres de long pour une largeur allant de . L'ensemble de la zone de production est parcourue, sur une longueur de , par la route des vins d'Alsace.

Il s'agit d'un vignoble de piedmont, à cheval sur les collines sous-vosgiennes (les contreforts orientaux des Vosges) et la plaine du Rhin. Les vignes s'y développent entre environ d'altitude (point le plus bas autour de Dambach-la-Ville, en plaine d'Alsace) et (limite supérieure de la culture viticole en Alsace à Osenbach, d'altitude en haut du Rangen). La protection des Vosges entraine une semi-aridité, l'exposition majoritaire vers l'est favorise la maturité du raisin tandis que les pentes assurent le drainage.

La route des vins est l'une des plus ancienne route des vins de France traversant le vignoble sur . C'est un lieu de rassemblement où les villages organisent des fêtes du vin et des vendanges.

Seules 67 des alsaciennes productrices sont sur le trajet de la route des vins d'Alsace telle que définie en (date de son inauguration). Cet itinéraire touristique passe à proximité de plus de trois cents domaines viticoles et 48 des , traversant les départements du Bas-Rhin et du Haut-Rhin, depuis Marlenheim au nord jusqu'à Thann au sud.

Colmar accueille une école viticole et un institut (l’institut viticole Oberlin), Rouffach un lycée viticole, tous trois œuvrant à l'amélioration des pratiques viticoles en Alsace.

La plaine d'Alsace occupe la partie sud du fossé rhénan, né d'un effondrement durant l'Oligocène et le Miocène (33 à d'années). Le vignoble est établi sur le piémont du massif des Vosges, sur la zone de fracture. Cette localisation explique la variété des sous-sols et leur succession en véritable mosaïque : calcaires, granites, schistes, gneiss ou grès. Généralement, le haut des pentes des collines sous-vosgiennes est constitué des roches anciennes, plutoniques et métamorphiques tels que du granite, du gneiss ou de l'ardoise. Les parcelles de vignes y sont très pentues, montant jusqu'à d'altitude (à Osenbach). Le bas des coteaux est formé des couches de calcaires ou de marne recouvertes par du lœss, où le relief est moins accentué. Les différentes appellations alsace grand cru sont toutes localisées sur ces pentes.

Enfin, la plaine est composée d'une épaisse couche d'alluvions déposées par le Rhin (limon et graviers), c'est une zone beaucoup plus fertile que les deux premières, avec une importante nappe phréatique à moins de cinq mètres de profondeur. Les appellations alsace et crémant d'Alsace y sont pour l'essentiel produit sur ces sols.

À l'ouest, les Vosges protègent du vent et de la pluie la région de production des vins d'Alsace. Les vents d'ouest dominants perdent leur humidité sur le versant occidental des Vosges et parviennent sous forme de foehn, secs et chauds, dans la plaine d'Alsace. La quantité moyenne de précipitations est la plus faible de tous les vignobles français.

De ce fait, le climat est plus tempéré (avec une température annuelle moyenne plus haute de ) que ce qui serait attendu à cette latitude. Le climat est continental et sec avec des printemps chauds, des étés secs et ensoleillés, de longs automnes et des hivers froids.
La station météo de Strasbourg ( d'altitude) se trouve à l'extrémité nord de l'aire d'appellation, mais au bord du Rhin. Ses valeurs climatiques de 1961 à 1990 sont :
La station météo de Colmar ( d'altitude) se trouve au milieu de l'aire d'appellation, mais en plaine. Ses valeurs climatiques de 1961 à 1990 sont :
La station météo de l'aéroport de Basel-Mulhouse-Freiburg ( d'altitude) se trouve à l'extrémité sud de l'aire d'appellation, encore une fois en plaine. Ses valeurs climatiques de 1961 à 1990 sont :

La surface du vignoble est de en 2013, soit une taille modeste en comparaison des principaux vignobles français. Ce chiffre est à peu près stable autour de depuis 2008, après des décennies de croissance. La surface plantée était selon le recensement agricole de 2000 de , à raison de de vignes (AOC+VDT) dans le Haut-Rhin et dans le Bas-Rhin en 2000, y compris les vignes à raisin de table (quantité négligeable en Alsace), mais sans compter les pépinières et les vignes-mères de porte-greffes. En 2012, les de vignes se répartissent à raison de dans le Haut-Rhin et de dans le Bas-Rhin.

L'influence allemande a, au cours des siècles, entraîné la mise en place d'une viticulture très différente de celle des autres régions viticoles françaises. Elle est, encore aujourd'hui, remarquable par les cépages utilisés et les méthodes de production.

Les principaux cépages sont aussi cultivés en Allemagne : riesling B, gewurztraminer Rs et sylvaner B. On utilise aussi le pinot gris G (anciennement connu sous le nom de « tokay d'Alsace », mais cette dénomination n'est plus autorisée), le muscat blanc à petits grains B, le muscat rose à petits grains Rs, le muscat ottonel B et le pinot blanc B (ou klevner, à ne pas confondre avec le klevener de Heiligenstein Rs). Le pinot noir N est le seul cépage rouge ou rosé de la région. Il est à la base des dénominations pinot noir, rouge d'Ottrott, rouge du Stephansberg, etc. L'edelzwicker, tout comme le gentil est un assemblage de plusieurs cépages. Le crémant d'Alsace est un vin blanc effervescent à base de pinot blanc et de pinot gris, vinifié depuis le selon la méthode champenoise. Sont également utilisés l'auxerrois B, le chardonnay B (qui n'est produit que pour la fabrication du crémant), le riesling B et le pinot noir N (production du blanc de noir). Une petite production concerne le vin de paille et le vin de glace.

Le riesling B ( en 2009, en 2012) est le cépage le plus caractéristique d'Alsace. À la différence de la variété allemande, il peut donner des vins franchement secs, qui vieillissent bien, comme des demi-secs (moelleux) de vendanges tardives.

Le pinot blanc B et l'auxerrois ( ensemble en 2009, respectivement et en 2012), aussi appelé klevner, donnent des vins blancs secs et frais. Une grande partie de la production est destinée à la production du vin mousseux commercialisé sous le nom de crémant d'Alsace.

Le gewurztraminer Rs ( en 2009, en 2012) occupe une surface croissante. Il a un caractère très marqué et peut, les bonnes années, donner des vins amples et généreux. Ce cépage n'est autorisé en France que dans les trois départements du Haut-Rhin, du Bas-Rhin et de la Moselle.

Le pinot gris G ( en 2009, en 2012), aussi appelé autrefois « tokay d'Alsace », est moins abondant, mais les surfaces plantées sont en augmentation. Le lien avec la variété hongroise du tokay est assez difficile à établir et le nom n'est plus utilisé officiellement pour éviter la confusion.

Le pinot noir N ( en 2009, en 2012) est l'unique raisin rouge d'Alsace, utilisé pour faire des vins rosés et des vins rouges plus ou moins colorés.

Le sylvaner B ( en 2009, en 2012) abonde dans les zones les moins prestigieuses de la région. Il donne des vins frais et simples. Les surfaces plantées en sylvaner sont en réduction constante depuis des décennies. À noter qu'il est le protagoniste des premières pages du roman de Julio Cortázar, "62 Modelo para armar".

Les muscats ( en 2009), c'est-à-dire du muscat blanc à petits grains B, du muscat rose à petits grains Rs et du muscat Ottonel B, produisent un vin au fruité très caractéristique mais sec, contrairement aux vins de muscat méridionaux.

Le chardonnay B (), le chasselas B ( en 2009) et le savagnin Rs ( en 2009), ce dernier étant un cousin du gewurztraminer appelé localement klevener de Heiligenstein, sont devenus confidentiels. Le chasselas est surtout consommé comme raisin de table et n'est que très rarement vinifié. La roussanne est un cépage par quelques jeunes vignerons novateurs. Ces vins issus de roussanne ne ressemblent pas aux autres vins d'Alsace, on peut les comparer à des vins de la vallée du Rhône (saint-péray).

La limite de rendement de l'appellation alsace était de cent hectolitres par hectare en 1945, tous cépages confondus, auquel se rajoute à partir de 1974 un plafond limite de classement (PLC, un volume de réserve fixé annuellement par l'INAO) de + 20 % (soit un rendement plafond de par hectare).

Depuis les années 1990, le rendement annuel à l'hectare autorisé dans l'appellation alsace est passé à 80 hectolitres par hectare, avec un plafond de + 10 % (soit un rendement plafond de par hectare). Les rendements pour le crémant sont de par hectare, avec un butoir à par hectare. Les conditions de production sont plus drastiques pour les appellations alsace grand cru, dont le rendement a été limité à par hectare, avec butoir à par hectare.

Le rendement réellement pratiqué en 2009 est en moyenne de par hectare pour l'ensemble des trois appellations alsaciennes. Ces rendements sont supérieurs à ceux pratiqués dans les autres vignobles français, où la moyenne pour l'ensemble des AOC est d'environ par hectare en 2009.

Une des principales particularités des vins d'Alsace est d'être dans leur très grande majorité des mono-cépages, les volumes de vins d'assemblage se limitant à l'edelzwicker (les cahiers des charges de l'altenberg-de-bergheim et du kaefferkopf l'autorisent depuis peu pour ces deux alsaces grands crus). En comptant les différentes appellations, dénominations de cépage, dénominations géographiques, couleurs et mentions, le vignoble d'Alsace peut produire différents.

Le total de la production viticole alsacienne varie chaque année en fonction des conditions climatiques. Par exemple, les trois dernières mauvaises récoltes (en termes de volume) correspondent à la canicule de 2003 qui en plus de la sécheresse a grillé les raisins (record avec à Colmar le 13 août 2003 ; le ban des vendanges est levé dès le 25 août 2003 pour le crémant et le 8 septembre pour l'alsace), au dur hiver 2009-2010 ( à Colmar le 19 décembre 2009) et au manque d'ensoleillement de l'été 2010 qui a retardé la maturité (ban levé le 13 septembre 2010 pour le crémant et seulement le 27 pour l'alsace) et au printemps 2013 trop frais qui a retardé la floraison (levée du ban le 19 septembre 2013 pour le crémant, le 30 pour l'alsace et le 7 octobre pour le riesling et le gewurztraminer).

En général pour le vin d'Alsace, la vinification se fait en blanc, en utilisant les méthodes traditionnelles. Les vins vieillissent entre six et douze mois dans de grands fûts, (foudres de chêne) ou des cuves en inox. Dans la vinification en rosé ou en rouge, le raisin n’est pas pressé immédiatement à son arrivée en cave.

À l'arrivée au chai, le raisin est foulé et pressé pour séparer le moût du marc de raisin. Les pressoirs pneumatiques remplacent progressivement les pressoirs horizontaux à plateau. Le moût est mis en cuve en stabulation pour le dépôt des bourbes. Le soutirage du jus clair est le débourbage. Les bourbes peuvent être filtrées pour donner aussi un bon vin. La fermentation alcoolique débute sous l'action de levures indigènes ou de levures sélectionnées introduites lors du levurage. Cette opération transforme le sucre du raisin en éthanol. La maîtrise de la température de fermentation par un système de réfrigération permet d'exprimer le potentiel aromatique du produit.

La fermentation achevée, le vin est soutiré afin d'éliminer les lies. La fermentation malolactique n'est généralement pas réalisée, bloquée par un sulfitage du vin. Ce dernier peut être stocké en cuve pour le préparer à l'embouteillage ou élevé en barrique ou foudres de bois de chêne. Le vin est soutiré, filtré et stabilisé avant le conditionnement exclusivement en bouteilles.

La coloration du moût nécessite une macération du grain de raisin dans le jus ; en effet, le pinot noir est un cépage rouge à jus blanc. Seule la pellicule comporte les anthocyanes colorantes. Dans le cas du vin rosé, la macération ne dure que quelques heures. Elle est interrompue dès que la couleur désirée est atteinte. La suite de la vinification se fait de la même manière que pour la vinification en blanc.

Dans le cas du vin rouge, la macération dure le temps de la fermentation alcoolique. Outre la couleur, elle permet de solubiliser les tanins. Le pressurage intervient à ce moment-là pour séparer le vin du marc de raisin. Le vin subit alors la fermentation malolactique. Elle transforme l'acide malique à deux groupes carboxyle, en acide lactique qui n'en comporte qu'un. L'opération conduit à une désacidification naturelle du vin ; elle arrondit le vin, le rend plus souple et moins âpre.

L'appellation couvre en 2009 (75,2 % du vignoble) sur lesquels ont été produits de vins (74,4 % de la production de l'ensemble du vignoble). L'AOC alsace mentionne habituellement le nom du cépage ou celui d'edelzwicker comme « dénomination de cépage » selon l'INAO. L'étiquette peut également mentionner un lieu-dit. L'edelzwicker (« coupage noble ») est un assemblage de cépages réalisé selon l'inspiration du viticulteur ; il est souvent à base de sylvaner. Les différentes dénominations de cépage sont :

Dans les cas du gewurztraminer, du muscat, du pinot gris et du riesling, il existe des mentions correspondant à des vins moelleux voire liquoreux : les « vendanges tardives » et les « sélections de grains nobles ».

En 2009, l'appellation alsace grand cru couvre (5,4 % de la surface du vignoble) sur lesquels ont été produits de vins (4,1 % de la production de l'ensemble du vignoble). L'AOC alsace grand cru a été créée en 1975 mais les crus n'ont été définis qu'en 1983, suivis par en 1992 et un dernier en 2007. Il existe délimités pouvant bénéficier chacun d'une appellation grand cru, les dénominations étant devenues des appellations en 2011.

Seuls six cépages sont autorisés à l'origine dans les AOC alsace grand cru : le riesling B, le gewurztraminer Rs, le pinot gris G et les muscats (muscat blanc à petits grains B, muscat rose à petits grains Rs et muscat ottonel B). Toutefois, le décret du 21 mars 2005 autorise l’utilisation du cépage sylvaner B dans le grand cru Zotzenberg. Le pinot blanc B, le pinot noir N et le chasselas B sont également autorisés dans les vins d’assemblage de l’AOC alsace grand cru Altenberg de Bergheim. Le décret du 12 janvier 2007 autorise également les vins d’assemblage dans l'alsace grand cru Kaefferkopf.

L'appellation couvre en 2009 (19,4 % du vignoble), sur lesquels ont été produits de vins (21,5 % de la production de l'ensemble du vignoble). L'AOC crémant d'Alsace regroupe des vins effervescents à base de pinot blanc B, pinot noir N, pinot gris G, riesling B ou chardonnay B élaborés sur une méthode traditionnelle comme en Champagne. Ils sont blancs, parfois rosés. L'appellation date de 1976.

Depuis 1984, les vins d'appellation d'origine contrôlée alsace et alsace grand cru peuvent être déclarés et présentés avec l'une des mentions vendanges tardives ou sélection de grains nobles s'ils correspondent à des conditions strictes (vendanges manuelles, teneurs en sucre minimales, vins issus uniquement des cépages gewurztraminer, pinot gris, riesling et muscat).

Vendanges tardives ( en allemand) indique que la vendange s'est faite au moment de la maturation optimale du raisin (pas forcément plus tard que la récolte normale), certaines baies pouvant se montrer atteintes de la pourriture noble ou botrytis. La dénomination s'applique aux principaux cépages, gewurztraminer, pinot gris, riesling ou muscat : ce sont alors des vins demi-secs. 
L'indication sélection de grains nobles s'applique aux vins faits à partir de raisins atteint de pourriture noble. Ceux-ci sont produits les années chaudes : ce sont des vins doux et capiteux qui peuvent vieillir longtemps.

Les étiquettes des vins d'Alsace sont plus simples que les autres étiquettes françaises. Elles font apparaître le cépage et le nom du propriétaire et, souvent, le nom de la vigne et du village, surtout dans le cas d'un grand cru.

La vente des vins d'Alsace en fûts ou autres caisses-outres est interdite, seule la commercialisation en bouteilles est autorisée. Celles-ci, hautes et élancées, sont désignées sous le nom de flûtes à cause de leur forme.

D'après le CIVA (le Conseil interprofessionnel des vins d'Alsace), la production annuelle en 2010 est de d'hectolitres ( de bouteilles dont 90 % de blancs) réalisée par de raisins, la commercialisation est faite par coopératives (38 %), (42 %) et indépendants (20 %), la distribution se fait à 80 % par les circuits alimentaires (grandes et moyennes surfaces, commerces traditionnels, magasins spécialisés et ventes directes), 20 % en restauration. Le vignoble d'Alsace représente 18 % de la production française de vins blancs AOC hors effervescents, 31 % des vins blancs AOC consommés à domicile hors effervescents en France, 30 % du marché des mousseux AOC (hors champagne) consommés à domicile sont les crémants d’Alsace. Le marché français représente 75 % des ventes, l'export se ventile en Europe (77 %), États-Unis (6 %), Canada (6 %) et Asie (4 %).




</doc>
<doc id="15564" url="https://fr.wikipedia.org/wiki?curid=15564" title="Diffractomètre">
Diffractomètre

Le diffractomètre est un appareil permettant de mesurer la diffraction d'un rayonnement sur une cible. Le terme est utilisé pour la diffractométrie de rayons X et la diffraction de neutrons.

Les premiers diffractomètres utilisaient une pellicule argentique qui était impressionnée par des rayons X. C'étaient parfois juste un tube, un porte-échantillon et un porte-film posés sur une table (les dangers des rayons X étaient sous-estimés à l'époque), parfois mis dans une « boîte ». Il portait de ce fait le nom de « chambre », les Britanniques parlant de « "camera" ».

Les rayonnements utilisés dans un diffractomètre ont une longueur d'onde de l'ordre de (), ce qui est du même ordre de grandeur que les distances interatomiques dans les matériaux solides.

La première source de rayons X fut la désintégration radioactive. Cette source est encore parfois utilisée en spectrométrie de fluorescence X, mais plus en diffraction.

En général, les rayons X sont produits par freinage des électrons. On utilise en général des tubes à rayons X, dispositifs de petite taille (environ 50 cm de long pour une dizaine de cm de diamètre, plus pour les tubes à anode tournante). Dans la plupart des cas, on modifie le spectre du tube afin de s'approcher des conditions monochromatiques :

Les diffractomètres sont également placés dans des lignes de faisceau synchrotron. Le rayonnement synchrotron permet d'avoir des rayons X monochromatiques et parfaitement collimatés, ce qui permet des mesures très précises. Cependant, un synchrotron est une installation de plusieurs centaines de mètres de diamètre et de coût de structure faramineux, ce qui réserve son utilisation aux cas vraiment nécessaires.

Les neutrons peuvent être produits dans deux types de source : 
Les neutrons obtenus sont ralentis dans de l'eau lourde afin d'atteindre une longueur d'onde de l'ordre de . Comme pour les rayons X, il est possible d'obtenir un faisceau monochromatique à l'aide d'un monochromateur.

La chambre de Laue est le dispositif le plus simple pour faire un cliché de diffraction, mais il n'est adapté qu'aux monocristaux.

Il consiste en une source de rayonnement (tube de rayons X, réacteur) émettant sur un spectre large (spectre polychromatique), un porte-échantillon, et un support de film photographique. Le film photographique est masqué par un papier afin de ne pas être voilé par la lumière ; les rayonnements seuls traversent le papier et impressionnent le film.

Le cliché obtenu permet de déterminer les paramètres de maille du cristal ainsi que l'orientation du réseau par rapport à la face analysée. Il est similaire au cliché de diffraction obtenu en microscopie électronique en transmission.

Lorsque l'on veut faire des mesures plus précises, on utilise un diffractomètre muni d'un goniomètre à trois cercles permettant d'orienter le monocristal, le film étant remplacé par un détecteur à deux dimensions (type caméra CCD ou chambre à fils), voir plus bas. On peut ainsi acquérir plusieurs clichés de Laue de manière automatisée.

La chambre de Debye-Scherrer est le dispositif le plus simple permettant de faire de la diffraction sur poudre ou sur échantillon polycristallin.

Il se compose d'une source monochromatique de rayonnement, d'un porte-échantillon et d'un film en forme de bande qui entoure le dispositif. Le rayon incident est diffracté sous la forme de cônes, qui laissent des traces en forme de cercle sur la bande.

On voit parfois le terme « caméra de Debye-Scherrer », mais il semble que ce soit un anglicisme, il est en effet peu utilisé en français. Le terme est toutefois correct sur le plan étymologique, le mot latin "camera" signifiant « chambre », et l'analogie avec la caméra de cinéma est pertinente (chambre noire servant à impressionner un film photographique), bien que dans le cas de la chambre de Debye-Scherrer il n'y ait pas de mouvement.

Ce dispositif est très simple et peu coûteux, mais s'il permet de localiser aisément la position des pics (rayon de l'arc de cercle sur la bande), la trace photographique rend peu précise l'estimation de l'intensité (niveau de gris) et la largeur du pic (largeur de l'arc).

Les autres sources d'incertitude sont :

Initialement, le dépouillement des données était fait manuellement, la position des arcs étant repérée avec une règle. La numérisation des films (avec un scanneur) permet un traitement informatique du diffractogramme.

On trouve également des chambres Debye-Scherrer où le film est remplacé par une série de détecteurs placés en arc de cercle autour de l'échantillon, offrant une résolution de l'ordre du centième de degré. Ce dispositif permet une acquisition directe sur ordinateur, avec une mesure précise des intensités (nombre de coups reçus par chaque détecteur).

Ce dispositif a été de fait quasiment systématiquement remplacé par un diffractomètre de poudre « mécanisé » (avec un détecteur ponctuel mobile monté sur un goniomètre à deux cercles). Ces diffractomètres à goniomètre sont prévus pour une géométrie Bragg-Brentano, mais ils peuvent être utilisés en géométrie Debye-Scherrer, par exemple lorsque l'on a peu de produit : la poudre est introduite dans un capillaire, on travaille avec un faisceau parallèle, et le détecteur fait le tour de l'échantillon.


Les chambres de Seemann-Bohlin sont particulièrement adaptées à l’emploi d’un cristal monochromateur pour focaliser le faisceau primaire et pour exciter l’échantillon avec un rayonnement monochromatique. Ces chambres, dites de Guinier, existent en différentes versions : symétrique, asymétrique, juxtaposée, échantillon en réflexion ou en transmission. Elles sont surtout utilisées lorsqu’une précision élevée de la position des pics et une haute résolution sont exigées.



Pour améliorer la précision des mesures et obtenir des raies de diffraction plus intenses, on utilise des montages à pseudo-focalisation du type Seemann-Bohlin.

Un diffractomètre de poudres est un diffractomètre à bras mobiles. Les premiers modèles étaient mus par des manivelles, puis sont venus les bras motorisés ; les diffractomètres modernes sont entièrement automatisés et commandés par ordinateur.

Dans le cas général, l'appareil possède un goniomètre « à deux cercles », c'est-à-dire ne permettant de faire varier que deux angles : l'angle d'incidence du rayonnement sur l'échantillon γ, et l'angle de déviation 2θ. Ceci peut être réalisé par deux montages, dits « θ-2θ » (thêta-deux thêta) et « θ-θ » (thêta-thêta). Dans les deux cas, le détecteur est mobile, c'est sa position qui détermine la déviation 2θ ; la différence est dans la détermination de l'incidence γ :

Les diffractomètres de ce type sont les plus polyvalents, on peut en effet faire varier la géométrie et faire :

La géométrie de Bragg-Brentano consiste à avoir une focalisation approchée du rayonnement incident (parfois appelée « parafocalisation », en anglais "parafocussing").

L'idée est d'éclairer l'échantillon avec un faisceau divergent, ce qui permet d'avoir plus d'intensité qu'avec un faisceau fin. Ce faisant, on introduit une erreur angulaire, le faisceau incident ne frappant pas l'échantillon avec le même angle. Ce défaut est corrigé de deux manières :

Comme il s'agit d'une méthode sur poudre, on travaille avec une source monochromatique et un détecteur ponctuel. On peut remplacer le détecteur ponctuel par un détecteur linéaire ou à deux dimensions, afin d'accélérer la mesure. Cependant, on n'est plus strictement en géométrie Bragg-Brentano, même si les résultats sont similaires.

Les diffractomètres de poudre peuvent s'utiliser avec une autre géométrie que la géométrie de Bragg-Brentano.

Les mesures en incidence rasante se font à incidence γ fixe, et en faisant varier 2θ. On fait en général des mesures pour plusieurs valeurs de γ. Pour éviter que le faisceau incident passe par-dessus l'échantillon et frappe directement le détecteur aux faibles angles, on utilise un faisceau fin et on peut placer un « couteau » (écran métallique) au-dessus de l'échantillon.

L'absorption du rayonnement dépend du trajet dans l'échantillon (loi de Beer-Lambert). Au-delà d'une certaine distance "d" parcourue, les rayons sont trop absorbés et ne contribuent quasiment pas au signal ; cette distance "d" choisie par convention est celle donnant 90 % du signal.

Le rayon incident parcourt une distance "x" valant "e"/sin(γ) pour atteindre une profondeur "e", et une distance "x" valant "e"/sin(2θ-γ) pour ressortir et frapper le détecteur. La couche d'atomes située à une profondeur "e" contribue donc de manière significative au signal uniquement si formula_1, soit
Dans le cas d'un échantillon bicouche, l'angle d'incidence γ à partir duquel on peut détecter un pic du substrat permet de déterminer l'épaisseur de la couche située au-dessus.

Les mesures en bercement ou en balancement ("rocking curves" en anglais), consistent à faire varier l'angle d'incidence γ tout en maintenant la déviation 2θ constante. En raison de la défocalisation, il faut travailler avec un faisceau fin.
On fait en général plusieurs mesures sur un intervalle de γ donné, mais en faisant varier 2θ entre chaque mesure.

Ces mesures en général sont utilisées pour déterminer l'orientation d'une couche épitaxiée ; par exemple, dans l'industrie des semi-conducteurs, on fait croître une couche cristalline sur un monocristal de silicium. On effectue des mesures pour une plage de 2θ couvrant un pic du substrat et un pic de la couche. Les deux pics sont maximaux pour des valeurs de γ différentes, et ceci donne la désorientation entre le substrat et la couche.

Une géométrie en faisceau parallèle permet de s'affranchir de la forme de l'échantillon. En effet, en faisceau divergent, la surface de l'échantillon doit être tangente au cercle de focalisation pour que l'on puisse faire l'hypothèse que tous les rayons frappant le détecteur subissent la même déviation. Si le faisceau est parallèle, alors la déviation ne dépend que de la direction du détecteur.

On utilise pour cela un système diffractant courbé (ce n'est donc pas à proprement parler un miroir), et dont la courbe est un arc de parabole. Le centre du tube (la ligne de l'anti-cathode sur laquelle se projettent les électrons) est placée au foyer de cette parabole. L'alignement du miroir est sans doute l'opération qui conditionne le plus la qualité de la mesure.

Cette méthode a été développée par H. Göbel, le système diffractant porte donc le nom de « miroir de Göbel » (ou « miroir de Goebel », voir l'article "Umlaut").

Le miroir de Göbel n'est utile qu'avec un monochromateur arrière. Sinon, la technique ne présente aucun avantage.

Ce système est par exemple utilisé lorsque l'on dispose d'extrêmement peu de matière. La poudre est introduite dans un capillaire (tube de verre très fin), et on réalise un balayage avec le détecteur (c'est en fait en quelque sorte la méthode de Debye-Scherrer mais avec un détecteur électronique au lieu d'un film photographique). Le faisceau parallèle peut également être utilisé pour une mesure sur une pièce non plane (courbe, rugueuse), voir pour une mesure non destructrice (on place une pièce entière, par exemple un objet d'art, dans l'appareil).

Le miroir est un multicouche de synthèse. La principale limitation de sa durée de vie est l'oxydation des couches, en particulier par l'ozone que peut produire la haute tension des tubes à rayons X. Pour éviter ceci, les miroirs de Göbel sont sous atmosphère inerte, dans un boîtier muni de fenêtres transparentes aux rayons X.

Dans la configuration Bragg-Brentano, le faisceau incident a une divergence radiale, la configuration permettant la focalisation approchée. C'est donc une bande rectangulaire de l'échantillon qui est éclairée. La divergence radiale est limitée par une fente rectangulaire située entre le tube et l'échantillon, appelée « fente primaire », « fente avant » ou « fente de divergence ». Une autre fente se trouve devant le détecteur, elle limite le volume que « voit » le détecteur à la seule zone irradiée de l'échantillon ; cette fente porte le nom de « fente secondaire », « fente arrière » ou « fente anti-diffusion ». Ces fentes déterminent l'intensité qui atteint le détecteur ainsi que le bruit de fond.

Le faisceau incident a également une divergence axiale. On essaie en général de limiter cette divergence axiale par des « fentes de Soller », parfois appelées « collimateurs » : il s'agit de lames de cuivre parallèles, qui absorbent les rayons qui ne sont pas parallèles aux lames. La divergence est limitée à quelques degrés (en général, entre 0,1 et 5°). Plus la divergence est étroite, plus les pics de diffraction sont étroits, mais plus l'intensité est faible. Sans fente de Soller, on a des pics larges et dissymétriques.

Dans le cas le plus simple, le porte-échantillon est une simple pièce passive soit fixe (montage θ-θ), soit motorisée (montage θ-2θ). Il permet en général de faire tourner l'échantillon dans son plan "(spinner)" ; en effet, comme seule une petite portion de l'échantillon est éclairée (un rectangle étroit), le fait de faire tourner l'échantillon permet de balayer un disque, le signal collecté représente donc une plus grande surface d'échantillon. Ceci permet d'englober plus de cristallites, et donc d'avoir une meilleure représentation statistique.

Le porte-échantillon peut également être un passeur : on charge plusieurs échantillons, et ceux-ci sont mesurés successivement, ce qui permet de mesurer plusieurs échantillons sans avoir besoin d'intervenir pour les changer (par exemple mesure de nuit). Dans certains cas, le passeur est distinct du porte-échantillon, il amène l'échantillon au porte-échantillon ; on peut par exemple avoir une mesure automatisée avec un échantillon provenant d'une chaîne de production par une bande convoyeuse.

Pour certaines mesures, notamment de texture ou de contraintes, il est nécessaire de faire varier la position de l'échantillon sous le faisceau (le faisceau est alors ponctuel). On utilise pour cela un goniomètre à trois cercles ou « berceau d'Euler » :
À ceci se rajoute la position 2θ du détecteur, on parle donc de « montage à quatre cercles ».

Le porte-échantillon peut aussi faire varier la position de l'échantillon selon les axes "x", "y" et/ou "z".

L'appareillage comporte un goniomètre pour manipuler le monocristal dans le faisceau incident sous tous les angles (montage à quatre cercles).
La rotation du cristal dans le diffractomètre a pour but de générer une onde issue des plans réticulaires en phase avec l'onde incidente à ce même plan réticulaire.

Cette technique est en général utilisée pour déterminer la structure cristalline.

Elle se fait sur le CCD qui est une matrice de cellules qui captent l'information lumineuse sous forme de pixels et qui n'utilise pas de plaque photographique. Des photons isolés sont enregistrés électroniquement et répartis à l'aide d'un microprocesseur le long d'une série de pixels qui, assemblés en rangées, forment alors une image qui peut être numériquement travaillée par ordinateur.

Il y existe plusieurs types de diffractomètres, selon le domaine de recherche (science des matériaux, diffraction des poudres, sciences de la vie, biologie structurale, etc.) et selon le type de structure : en effet, il faut distinguer les diffractomètres dédiés aux laboratoires équipés d’une source à rayons X, et ceux dédiés aux synchrotrons, qui utilisent des sources de lumière beaucoup plus puissantes.

En laboratoire, les diffractomètres proposés par les industriels sont usuellement des solutions complètes, c’est-à-dire comportant un diffractomètre, une source de rayons X, un vidéo-microscope et un détecteur à rayons X en un seul ensemble sécurisé. Il existe de nombreux fabricants pour ce type d’équipement, on peut citer, par exemple, Bruker, Rigaku, ou encore Thermo Fisher Scientific, mais il en existe bien d’autres.

En synchrotron, les diffractomètres sont disponibles indépendamment d’autres équipements, à la différence des diffractomètres de laboratoires. Les fabricants de diffractomètres pour synchrotrons sont aussi bien moins nombreux, les diffractomètres dédiés aux synchrotrons étant bien plus complexes et le nombre de lignes de lumière à équiper étant bien moindre par rapport aux laboratoires.

Parmi les fabricants, on peut citer Huber Diffraktionstechnik, une entreprise allemande dont les diffractomètres appliqués aux sciences des matériaux sont parmi les plus répandus. En biologie structurale, les diffractomètres commercialisés par Arinax, une entreprise française, sont les plus répandus.

On notera néanmoins que de nombreux diffractomètres, en synchrotrons, sont  conçus et assemblés par les équipes techniques des synchrotrons eux-mêmes, ce qui n’est que très rarement le cas en laboratoire.




</doc>
<doc id="15571" url="https://fr.wikipedia.org/wiki?curid=15571" title="Fitra">
Fitra

La fitra ( [fiṭra], "état de nature ; naturel") est un terme arabe qui fait référence à la nature originelle de l'être humain selon l'islam.

La fitra serait « L’attitude naturelle par laquelle nous irions vers Dieu » ou "instinct". En d'autres termes, il y aurait quelque chose en nous qui nous attirerait vers le transcendant. Dieu aurait créé l'homme avec une question fondamentale qui est : « Quel est le sens profond et premier de l'existence ? » La réponse à cette question aurait été oubliée par l'homme. Cette question serait un cri du cœur vers l'Absolu ("Al-Qayyum", un des noms de Dieu en Islam).

Selon le cadre de pensée islamique, la réponse à cette question du sens de la vie ne pourrait être trouvée que dans un cadre spirituel (pas nécessairement religieux cependant, par exemple le fait d'aider les pauvres toute sa vie). La connaissance de Dieu serait le sommet de l'accomplissement de la fitra perdue, laquelle est supposée être une réalisation spirituelle totale.

Selon un hadith, ce principe englobe également une composante purement physique, qui est le plus bas degré sur l'échelle des valeurs de la fitra (le plus haut étant la connaissance de Dieu, et les degrés intermédiaires étant tous d'ordre spirituels, tels la prière de la nuit, le jeûne volontaire, la méditation sur les écrits coraniques, etc.). La fitra contient 10 actes qui doivent être effectués au minimum tous les quarante jours : il est obligatoire selon ce dogme, par exemple, de ne pas laisse sa moustache pousser plus de quarante jours. Ces actes se justifieraient par la nécessite d'être propre ce qui permettrait de se rapprocher de la pureté et donc d'Allah 



</doc>
<doc id="15576" url="https://fr.wikipedia.org/wiki?curid=15576" title="Fêtes et jours fériés en Allemagne">
Fêtes et jours fériés en Allemagne

Les fêtes et jours fériés en Allemagne peuvent varier en fonction du considéré, mis à part le Jour de l'Unité allemande qui est la fête nationale.

La saison des carnavals (Fastnacht/Karneval/Fasching) commence le 11 novembre (soit 40 jours avant Noël) et termine la veille du mercredi des Cendres (soit le premier jour du Carême). Les carnavals animent des grandes villes comme Düsseldorf, Munich ou Mayence. Cependant, le carnaval le plus important est celui de Cologne. La semaine avant le début du Carême marque souvent l'apogée des festivités. Le grand cortège du « Lundi des Roses » (Rosenmontag) constitue le point fort du carnaval, avant le défilé du Mardi gras et le grand bal qui clôturent la semaine.

Pâques est riche en traditions en Allemagne. C'est là que le lièvre de Pâques (Osterhase) apporte pour la première fois des friandises et cadeaux le dimanche de Pâques. Cette tradition sera ensuite perpétuée dans les pays germaniques et frontaliers.

Les Allemands décorent leurs maisons et les villages avec des œufs vidés et peints, parfois accrochés à des arbres (Osterbaum ou Osterstrauch). Dans certaines communes de Bavière, ce sont les fontaines qui sont décorées pour devenir des Osterbrunnen. Les Allemands organisent également des marchés de Pâques (Ostermärkte). L'un des plus anciens est celui de Nuremberg.

Le jour de l’Unité allemande ("Tag der Deutschen Einheit") est la fête nationale allemande et elle est célébrée depuis 1990 le 3 octobre, jour anniversaire de la réunification du pays. C’est en Allemagne le seul jour férié en application du droit fédéral, tous les autres sont fixés par les droits régionaux.

Avant 1990, la fête nationale de la République fédérale était célébrée le 17 juin, et celle de la République démocratique allemande était le jour de la République, célébré le 7 octobre.
Beaucoup de villes bavaroises organisent des fêtes de la bière, la plus connue étant celle de Munich appelée Oktoberfest qui a lieu depuis 1810. Avec six millions de visiteurs, c'est la plus grande fête populaire du monde qui commence par un défilé de plus de huit mille personnes portant le costume traditionnel. La fête de la bière dure maintenant 16 jours complets et se termine traditionnellement toujours le d'octobre.

Nikolaus (Saint Nicolas en France) accompagné par le Knecht Ruprecht, descend du ciel dans une luge chargée de petites gourmandises et de cadeaux. Le soir du 5 décembre, les enfants placent leurs chaussures nettoyées dans un endroit particulier. Le matin du 6 décembre, ils vont très vite voir s'il y a des cadeaux et des friandises dans leurs chaussures. C'est le début des fêtes de fin d'année.

Dans la région de Hanovre et en Westphalie, on l'appelle aussi Klas ou Bullerklas ; c'est à lui que les enfants adressent leurs prières, se réjouissant de petits présents qui les attendent le 6 décembre.

Noël (Weihnachten) est la fête la plus importante. Dès le premier dimanche de l'Avent, les calendriers de l'Avent et les marchés de Noël (Weihnachtsmärkte) animent les places des villes. Les plus réputés sont ceux de Nuremberg, Munich, Essen et Heidelberg. Aux étals des cabanes de bois, on peut acheter des décorations, des cadeaux, des spécialités, comme des gâteaux secs (Plätzchen) ou du pain d'épice (Lebkuchen) et bien sûr boire du vin chaud aromatisé à la cannelle (Glühwein).


</doc>
<doc id="15584" url="https://fr.wikipedia.org/wiki?curid=15584" title="Touaregs">
Touaregs

Les Touaregs, qui se nomment eux-mêmes les Kel Tamasheq (en berbère : ⴾⵍ ⵜⵎⵛⵈ "Kel Tamaceq") sont des habitants du Sahara central et de ses bordures (Algérie, Libye, Niger, Mali, Mauritanie et Burkina Faso). Ils parlent une langue berbère, le "tamasheq", et utilisent un alphabet appelé tifinagh (prononcer en français "tifinar").

Souvent nomades, leur sédentarisation s'accélère depuis la seconde moitié du . Ils sont confrontés à des formes d’assimilation culturelle et linguistique (acculturation) et à une marginalisation économique et politique qui les ont conduits à la lutte armée dans les années 1990. Beaucoup ont abandonné le nomadisme pour se fixer dans les grandes villes en bordure du Sahara, comme Tamanrasset en Algérie ou Agadez au Niger, ou les capitales des États sahéliens (Bamako, Niamey).

Pour se qualifier, les Touaregs n'utilisent pas le mot « touareg », un exonyme qui leur a été attribué, mais se désignent soit en tant que « Kel Tamasheq », qui signifie « ceux de la langue tamasheq », soit en tant que "Imuhagh", "Imajaghen" ou "Imushagh" (sing. "amajagh"), termes employés pour désigner les « nobles », ou les « hommes libres ». 

Les Touaregs se désignent aussi sous le nom de « Kel Tagelmust », signifiant « ceux du tagelmust », en référence au tagelmust, sorte de voile que les hommes touaregs portent sur la tête, ou encore « Kel tefinagh », qui signifie « les gens des tifinagh », en référence au tifinagh, l'écriture qu'ils utilisent. 

Tamahaq, Tamajaq et Tamachaq sont des variations dialectales du mot Tamazight.

Il existe plusieurs hypothèses concernant l'origine du mot « Touareg », qui n'est attesté qu'à partir du . Selon Léon l'Africain, explorateur d’Afrique du nord au , il semblerait que « Touareg » dérive du nom de la région de "Targa" (qui signifie « rigole » ou « vallée » en berbère), dans le Fezzan en Libye, dont selon lui, nombre de groupes touaregs seraient originaires.

À l’époque coloniale, les Français ont utilisé et popularisé la dénomination "Touareg" comme le pluriel de "targui" (féminin "targuia"). Cette pratique est aujourd'hui le plus souvent abandonnée et on l'accorde désormais selon les règles du français (Touareg/Touaregs/Touarègue). Il fut également utilisé le synonyme "tamahek". 

Pour Adolphe Hanoteau, le terme par lequel les Touaregs dénomment leur écriture « "tifinagh" », proviendrait d'après lui de la même racine phonétique que le terme désignant phéniciens/puniques. Néanmoins, l'étymologie du terme peut probablement être d'origine berbère, comme le défend J.G. Février : « …faut-il supposer que les Numides auraient demandé aux Carthaginois seulement l'idée d'un alphabet consonantique, mais auraient emprunté ailleurs ou forgé les signes eux-mêmes? ». 

Selon une hypothèse assez répandue, le terme composé des mots berbères "tifin" qui signifie « trouvaille » ou « découverte » et de "nagh", adjectif possessif qui signifie « notre ».

Souvent appelés les « hommes bleus », d’après la couleur de leur chèche (teint avec de l’indigo, il se décolore sur la peau avec le temps), les Touaregs ont été l'objet de nombreuses représentations, en particulier chez les Occidentaux. Auparavant, l'indigo dominait au sud, dans les palmeraies de la vallée du Draâ. Aujourd'hui, cette culture a été abandonnée. Les toiles bleues sont importées directement de France, de Belgique ou d'Espagne.

Le mythe du Touareg apparaît avec l’ouvrage d’Henri Duveyrier "Les Touaregs du Nord" en 1864 : berbère de race blanche peu islamisé, guerrier farouche avec son bouclier de peau d'antilope qui a macéré dans du lait aigre, appartenant à une société féodale basée sur le matriarcat, dont le nomadisme est assimilé à la liberté, la sagesse et la simplicité, c'est un « seigneur du désert » mystérieux par sa tenue, son voile.

Répartis et divisés en plusieurs confédérations et tribus, un million et demi de Touaregs vivent dans cinq pays africains. À l’intérieur de ce territoire, les "Kel Tamasheq" se sont longtemps joués des limites des États. Ceux-ci ont pourtant réussi à leur inculquer les normes de la douane et des passeports.

Ce territoire, appelé "tinariwen" (les déserts), est, comme son nom l’indique, découpé en plusieurs terres. De ces nombreux déserts, il y a le désert proprement dit : le Ténéré. Les autres terres sont plus ou moins arides, plates et montagneuses, parmi lesquels on peut citer celles qui font l’objet d’un article ici : Adrar, Azawagh, Hoggar, Tanezruft, Tassili n'Ajjer, Tawat (Touat), Tadmaït, le désert Libyque ou encore Tibesti.

Au Maroc, les touaregs contrôlaient le commerce caravanier entre le Maroc et le Niger. Accompagnés de leurs esclaves, les haratins


</doc>
<doc id="15591" url="https://fr.wikipedia.org/wiki?curid=15591" title="CDU">
CDU

CDU est un sigle qui peut désigner :

un parti ou une coalition politique

autre

CDU est un code qui peut désigner :

</doc>
<doc id="15595" url="https://fr.wikipedia.org/wiki?curid=15595" title="Jana Gana Mana">
Jana Gana Mana

Jana Gana Mana (hindi : ; bengali : ) est l'hymne national de la République d'Inde, adopté par l'Assemblée constituante, le . Il est la première strophe d'un chant écrit et composé par Rabindranath Tagore en 1911 (également auteur de l'hymne bangladais).


</doc>
<doc id="15597" url="https://fr.wikipedia.org/wiki?curid=15597" title="Amar Shonar Bangla">
Amar Shonar Bangla

Amar Shonar Bangla est l'hymne national du Bangladesh, adopté lors de l'indépendance en 1971. La musique et les paroles ont été composées par Rabindranath Tagore (également auteur de l'hymne indien).

Texte en bengali :

Translittération :

Mon Bengale doré


</doc>
<doc id="15598" url="https://fr.wikipedia.org/wiki?curid=15598" title="Conjecture de Poincaré">
Conjecture de Poincaré

La conjecture de Poincaré était une conjecture mathématique du domaine de la topologie algébrique portant sur la caractérisation d'une variété particulière, la sphère de dimension trois ; elle fut démontrée en 2003 par le Russe Grigori Perelman.

Elle faisait jusqu'alors partie des problèmes de Smale et des sept « problèmes du prix du millénaire » recensés et mis à prix en 2000 par l'Institut de mathématiques Clay. En 2006, cette démonstration a été validée par l'attribution d'une médaille Fields à Grigori Perelman (qui l'a refusée) ; de plus, en mars 2010, l'institut Clay a officiellement décerné le prix correspondant à Perelman, prix qu'il a également refusé, en raison d'un « désaccord avec les décisions de la communauté mathématique ».

La conjecture fut formulée pour la première fois par Henri Poincaré en 1904, et s'énonce ainsi :

Poincaré ajouta, avec beaucoup de clairvoyance, un commentaire : .

Précisément, la question est de savoir si toute variété de dimension 3 fermée, simplement connexe et sans bord, est homéomorphe à une sphère. Plus vulgairement, il s'agit de déterminer si « un objet à trois dimensions » donné possédant les mêmes propriétés que celles d'une sphère 3D (dont notamment toutes les boucles peuvent être « resserrées » en un point) est bien seulement une déformation d'une sphère tridimensionnelle (la sphère ordinaire — surface dans l'espace ordinaire — possède seulement deux dimensions).

Ni la sphère ni un autre espace tridimensionnel dépourvu de frontière autre que formula_1 (l'espace ordinaire) ne peuvent être "dessinés" proprement comme objets dans l'espace ordinaire à trois dimensions. C'est l'une des raisons pour lesquelles il est difficile de "visualiser" mentalement le contenu de la conjecture.

Vers la fin de l'année 2002, des publications sur arXiv de Grigori Perelman, de l'Institut de mathématiques Steklov de Saint-Pétersbourg, laissent penser qu'il pourrait avoir trouvé une preuve de la « conjecture de géométrisation » (voir ci-dessous), mettant en œuvre un programme décrit plus tôt par Richard S. Hamilton. En 2003, il publia un deuxième rapport et donna une série de conférences aux États-Unis. En 2006, un consensus d'experts a conclu que le travail récent de Perelman en 2003 résolvait ce problème, près d'un siècle après son premier énoncé. Cette reconnaissance a été annoncée officiellement lors du congrès international des mathématiciens le 22 août 2006 à Madrid au cours duquel la médaille Fields lui a été décernée conjointement avec trois autres mathématiciens. Cependant Perelman a refusé la médaille, et laissé entendre qu'il refuserait également le prix Clay. Ce prix lui a été décerné le 18 mars 2010, prix accompagné d'une récompense d'un million de dollars, et il l'a effectivement refusé. D'après Aleksandr Zabrovsky, qui prétend avoir obtenu de lui une interview, il aurait déclaré au journal "Komsomolskaïa Pravda" le 29 avril 2011 :
Mais cette affirmation de Zabrovsky est controversée, plusieurs journalistes niant l'authenticité de cette interview.

Si la conjecture a induit une longue liste de preuves incorrectes, certaines d'entre elles ont toutefois mené à une meilleure compréhension de la topologie en petites dimensions.

Sa résolution est liée au problème de classification des variétés de dimension 3. Une classification des variétés de dimension 3 est généralement considérée comme la production d'une liste de toutes les variétés de dimension 3 à un homéomorphisme près (sans répétition).

Une telle classification est équivalente à un algorithme de reconnaissance, qui pourrait vérifier si deux variétés de dimension 3 sont homéomorphes ou pas.

On peut ainsi considérer la conjecture de Poincaré comme un cas particulier de la conjecture de géométrisation de Thurston.
Cette dernière conjecture, une fois prouvée (ce qu'a fait Perelman en 2003), achève la question de la classification des variétés de dimension 3.

Les seules parties de la conjecture de géométrisation qu'il restait à démontrer après sa formulation par Thurston vers 1980, étaient appelées la conjecture d'« hyperbolisation » et la conjecture d'« elliptisation ».

La conjecture d'« elliptisation » déclare que toute variété de dimension 3 fermée ayant un groupe fondamental fini a une géométrie sphérique, c'est-à-dire est couverte par la 3-sphère. La conjecture de Poincaré correspond au cas où le groupe fondamental est trivial.

Des conjectures analogues à celles de Poincaré dans des dimensions autres que 3 peuvent également être formulées :
La conjecture de Poincaré donnée précédemment apparaît comme le cas particulier "n" = 3.

La difficulté de la basse dimension en topologie est accentuée par le fait que tous les résultats analogues avaient été prouvés :
alors que la version à trois dimensions originale de la conjecture de Poincaré demeurait sans solution.



</doc>
<doc id="15600" url="https://fr.wikipedia.org/wiki?curid=15600" title="Fred (auteur)">
Fred (auteur)

Fred, de son vrai nom Frédéric Othon Théodore Aristidès (né le à Paris et mort le à Paris), est un auteur de bande dessinée français. Ses œuvres les plus connues sont "Le Petit Cirque", "L'Histoire du corbac aux baskets" et la série "Philémon". Grand prix de la ville d'Angoulême en 1980 et en 1994, il fait partie des rares auteurs à avoir obtenu ces deux hautes distinctions de la bande dessinée francophone.

Fred naît le à Paris. Il aime à raconter qu'en 1917, alors que sa grand-mère fuyait la guerre en Grèce avec ses enfants, elle s'arrêta à plusieurs reprises pour boire des coups avec ses amis, et de ce fait manqua son train qui explosa sur une mine, ne laissant aucun survivant : « "C'est ainsi que ma grand-mère et ses dix enfants - parmi lesquels une petite fille de dix ans qui allait devenir une femme puis ma mère - ont été sauvés par le hasard et la musique, le sens de la fête et de l'amitié. Sinon je ne serais plus là" », déclare Fred.

Enfant, il se passionne pour Oliver Twist, Shéhérazade, Oscar Wilde, Edgar Allan Poe, Robinson Crusoé, Cadichon, Jack l'Éventreur, autant de références qui ornent son œuvre à plusieurs reprises. Il découvre également la bande dessinée avec "Le Journal de Mickey", mais il a une véritable révélation lorsqu'il découvre chez l'éditeur du journal "Robinson" des planches abandonnées de Mandrake le Magicien et de Popeye le marin. Il rêve aussi devant des images d'Epinal. Fred dessine beaucoup dans les marges de ses cahiers. Il dessine avec fébrilité, y compris sur les tranches et dans les perforations des feuilles. En 1946, à 15 ans, il débute par des dessins d'humour dans "OK". Il publie sa première BD, "Les joies de l'alpinisme", dans le courrier des lecteurs d'un journal pour enfants puis, étudiant au quartier latin, participe à plusieurs publications aujourd'hui très recherchées comme "Quartier Latin", "Zéro", "Hebdo Latin" ou "Baladin de Paris" dont il est le rédacteur en chef. Mais il publie également des dessins pour des revues plus connues, comme "Ici Paris", "Paris Match", "Paris-Presse", "le Rire", "le Hérisson", "France Dimanche", "France-Soir", "Punch" et "The New Yorker".

Il fait alors la connaissance de François Cavanna (rencontré à "Ici-Paris"), Roland Topor, Wolinski, Reiser, Cabu, Gébé et du professeur Choron (qui vendait par colportage "Quartier Latin") avec qui il fonde en 1960 "Hara-Kiri", le journal bête et méchant, dont il fera de nombreuses couvertures mais également des dessins humoristiques et des contes (il en sera ensuite le directeur artistique). C'est également l'occasion pour lui de revenir à la bande dessinée avec "Tarsinge l'homme zan", "le Manu manu", "les Petits métiers" et surtout "Le Petit cirque". C'est donc là qu'il produit le début de son œuvre et qu'il créé déjà plusieurs personnages et histoires qu'il reprendra par la suite (comme le Manu-Manu, mais aussi les petits métiers, on en trouvera de nombreux dans "Philémon" et dans ses autres albums Dargaud). Fred en gardera aussi un esprit assez mordant, souvent noir, mais également une critique de l'esprit bourgeois étriqué (symbolisé par l'homme au cigare : attiré par l'argent, à l'opposé de l'artiste, en faveur de l'autorité et n'aimant pas la différence), esprit bourgeois que Fred stigmatise dans toute son œuvre.

En 1966, "Hara-Kiri" cesse de publier. Fred va d'abord proposer quinze planches à "Spirou", qui les refuse. Il tente alors sa chance au journal "Pilote" où René Goscinny accepte de le publier. C'est dans le numéro 300 que paraît, au rythme de deux planches par semaine (ce qui se voit assez bien à la lecture), "Le mystère de la clairière aux trois hiboux", qui met pour la première fois le personnage de Philémon en scène. Les lecteurs du journal écrivent alors pour dire que leur petite sœur dessine mieux et qu'ils ne comprennent rien à l'histoire. Fred fait alors des scénarios pour les autres (comme plus tard pour Alexis, avec qui il publie "Time is Money"). Il a alors l'idée d'envoyer Philémon sur les lettres de l'Océan Atlantique. Il y a deux hypothèses quant à la façon dont il eut cet éclair de génie, la première veut que Fred ait eu cette idée alors qu'il prenait son bain, s'interrogeant sur l'endroit où l'on va quand on est aspiré par le tourbillon de la baignoire qui se vide. L'autre veut que c'est en vacances qu'il ait eu cette idée : alors que son fils de dix ans Éric lui réclamait une histoire, il se met à l'imaginer en se servant des objets qui l'entourent, notamment une bouteille (qui sert pour le SOS), une maquette de bateau et un abat-jour (qui devient une Lampe naufrageuse). Goscinny accepte que Fred dessine cette histoire, quinze Philémon seront alors publiés jusqu'en 1987. C'est la série-phare de l'auteur qui compose la plus grande partie de son œuvre.

Fred, refusant de se laisser avaler par un personnage à succès, publie parallèlement d'autres histoires dans "Y a plus d'saison", "Ca va ça vient", "Hum!", "le Fond de l'air est frais", mais aussi des histoires complètes comme "Cythère l'apprentie sorcière" ou "Magic palace hotel". En 1983, il publie "La Magique lanterne magique" dans le but de venir en aide aux éditions Pellerin qui publient des images d'Épinal — une façon de les remercier. Il publie un portfolio, "Manège", et le journal de Jules Renard, qu'il adapte en bande dessinée, auteur chez qui on retrouve le même esprit un peu misanthrope et le même intérêt poétique pour la nature.

Parallèlement à ces publications, Fred fait plusieurs rencontres importantes, notamment avec Jacques Dutronc en 1970, pour qui il écrit plusieurs chansons, la plus connue étant « Le Fond de l'air est frais ». Ils feront ensuite deux livres disques pour enfants : "La voiture du clair de lune" et "Le Sceptre". Il rencontre également Terry Gilliam, alors fauché et errant dans Paris ; Goscinny demande à Fred d'écrire un scénario pour lui, publié dans "Pilote" sous la forme d'un récit de six pages. Le succès venu, Gilliam cherchera à joindre Fred, malheureusement occupé à faire de la plongée sous-marine aux Maldives. En 1991, il écrit des scénarios pour des courts-métrages réalisés par Daniel Vigne ("le Retour de Martin Guerre"), Jacques Rouffio et Gérard Zingg entre autres. Puis il écrit pour le long-métrage "L'Autobus de la haine" que Gérard Zingg désirait réaliser, mais ce projet n'a pas trouvé de producteur.

Fred fait partie du groupe des H.A. (Humoristes Associés) avec Avoine, Barbe, Blachon, Bridenne, Laville, Loup, Mose, Napo, Nicoulaud, Sabatier, Serre, Siné, Soulas, Trez. Ils éditent ensemble plusieurs albums.

En 1988, Fred a participé à l'édition d'un album souvenir sur Jacques Brel (illustration, en 4 pages, de la chanson « Les Bourgeois »).

Après avoir cessé la bande dessinée, il fait une grave dépression qui le conduit à l'hôpital psychiatrique. Pour guérir, il doit mettre un terme à sa retraite et reprendre son activité. Inspiré par son séjour à l'asile et par les nombreux psychiatres qu'il a rencontrés, il publie en 1993 "L'Histoire du corback aux baskets", qui obtient l' à Angoulême en 1994. Il publie ensuite plusieurs récits complets comme "L'Histoire du conteur électrique" et "L'Histoire de la dernière image", ainsi qu'une anthologie de ses meilleurs gags : "Fredissimo".

Après avoir longtemps vécu à Puiseux-le-Hauberger, Fred s'installe dans une maison de retraite à Domont. En 2011, il fait l'objet d'une large exposition rétrospective à la Galerie Martel, à l'occasion de la sortie de "Fred, L'Histoire d'un conteur éclectique", de Marie-Ange Guillaume. Fin 2011, il subit une intervention chirurgicale cardiaque. En janvier 2012, il est présent au Festival d'Angoulême, où il visite l'exposition qui lui est consacrée et donne une interview publique, où il avoue avoir envie de terminer le dernier album de "Philémon", dont les premières pages sont déjà dessinées. Cet album intitulé "Le Train où vont les choses" sort le 22 février 2013, et est annoncé comme le dernier de la série. Fred meurt le 2 avril suivant.








</doc>
<doc id="15601" url="https://fr.wikipedia.org/wiki?curid=15601" title="Fréquence d'apparition des lettres en français">
Fréquence d'apparition des lettres en français

Le calcul de la fréquence des lettres dans une langue est difficile et soumis à interprétation. On compte la fréquence des lettres d’un texte arbitrairement long, mais un certain nombre de paramètres influencent les résultats :


Si ces paramètres ont un impact spectaculaire sur les symboles les moins fréquents (la fréquence du œ varie entre 0,002 % et 0,09 % pour trois textes pris au hasard), elle est également sensible même pour les lettres les plus fréquentes (l’ordre de fréquence des lettres A, S, I, T et N, qui sont les plus fréquentes à part E, fluctue d’un texte à l’autre).

La fréquence des lettres dans un texte diffère de celle de la liste des mots d’un dictionnaire. En effet, très peu de mots apparaissent au pluriel dans un dictionnaire, ce qui conduit la lettre "s" à y être moins fréquente. De plus, les lettres accentuées "à" et "ù" apparaissent dans un nombre très limité de mots, mais dont certains sont d'usage fréquent ("à", "où"), ce qui contribue à modifier la fréquence relative de ces lettres.

Le corpus de textes littéraires disponible sur le Net (par exemple sur le site de l’Association des bibliophiles universels (ABU)) permet à tout un chacun de se livrer en quelques minutes aux analyses de fréquence de lettres chez l’auteur de son choix.

Le corpus de Wikipédia en français, en 2008, a été segmenté en mots par le laboratoire CLLE-ERSS qui a ensuite recensé les occurrences de ces derniers, permettant ainsi le calcul de la fréquence des caractères.

Diagramme comparatif de la fréquence des lettres dans 11 langues. 



</doc>
<doc id="15606" url="https://fr.wikipedia.org/wiki?curid=15606" title="Oliver Cromwell">
Oliver Cromwell

Oliver Cromwell (né à Huntingdon, le – mort à Londres, le ) est un militaire et homme politique anglais, resté dans les mémoires pour avoir pris part à l'établissement d'un "Commonwealth" républicain en Angleterre (ainsi qu'en Irlande et en Écosse), puis pour en être devenu le Lord Protecteur. Il est également l'un des commandants de la "New Model Army" — ou « Nouvelle Armée idéale » —, vainqueur des royalistes lors de la Première Révolution anglaise. Après la mise à mort du roi Charles en 1649, il se hisse à un rôle de premier plan au sein de l'éphémère "Commonwealth" d'Angleterre, conquérant l'Irlande et l'Écosse, et règne en tant que Lord Protecteur de 1653 jusqu'à sa mort, causée par la malaria, en 1658.

Cromwell naît dans les rangs de la "gentry" et demeure relativement inconnu jusqu'à ce qu'il reçoive en héritage le patrimoine de son oncle. En même temps que ce retournement du sort, il se convertit à une forme de puritanisme et fréquente une secte protestante considérant que la Réforme n'était pas encore achevée. Il en fait une partie essentielle de sa discipline de vie et de son univers mental. Il est alors élu au Parlement pour Cambridge au cours des "Short" et "Long Parliaments", puis est impliqué dans la guerre civile anglaise aux côtés des "Roundheads", littéralement « Têtes rondes », ou parti parlementaire, en opposition aux royalistes.

Soldat compétent, surnommé "Old Ironsides", il est promu de simple chef d'une troupe de cavalerie à commandant de l'armée entière. Cromwell se trouve aussi parmi les signataires de l'arrêt de mort prononcé contre le roi Charles en 1649, et membre du "Rump Parliament" (« Parlement croupion »), qui siège de 1649 à 1653. Ce même parlement envoie Cromwell conquérir l'Irlande, ce qu'il fait de 1649 à 1650, pour se tourner ensuite contre l'armée écossaise de 1650 à 1651. Le , se sentant suffisamment maître de la situation, Cromwell dissout par force le parlement, et établit pour un court laps de temps le "Barebone's Parliament", également nommé « Assemblée des Saints », en raison de la stricte doctrine puritaine qu'il se donne pour mission d'établir, et ce jusqu'à ce qu'il soit fait Lord Protecteur d'Angleterre, du pays de Galles, d'Écosse et d'Irlande le 16 décembre de la même année. À sa mort, il est d'abord enterré à l'abbaye de Westminster, mais lorsque les royalistes reviennent au pouvoir, ils déterrent son corps, l'enchaînent et le décapitent.

Cromwell est l'une des figures les plus controversées de l'histoire des îles Britanniques. Alors que certains historiens voient en lui un héros de la liberté, tels Thomas Carlyle ou Samuel Rawson Gardiner, d'autres en font un tyran, dictateur régicide, ainsi que le qualifient David Hume et . Au sein de la population, les sentiments exprimés sont tout aussi mitigés et passionnés, puisque pour les uns, il s'agit de l'un des plus grands héros nationaux de la patrie anglaise, alors que pour d'autres ses mesures prises contre les catholiques irlandais étaient presque génocidaires ; il est donc généralement détesté en Irlande.

Il y a peu de sources relatant les quarante premières années de sa vie. Il naît à la maison Cromwell à Huntingdon, le , fils de Robert Cromwell (v. 1560-1617) et d'Elizabeth Steward († 1654). Son grand-père était également une figure marquante, fait chevalier sous Élisabeth, et ayant siégé à la Chambre des communes en tant que chevalier pour le comté de Huntingdonshire.

Malgré cette ascendance, les Cromwell n'étaient alors que des membres de la "gentry". Le patrimoine de Robert Cromwell se limitait à une maison à Huntingdon et à un lopin de terre dans les environs, le tout ne générant au plus que 300 livres de revenu par an, les plaçant ainsi dans la tranche inférieure de la "gentry".

De ses jeunes années, nous trouvons encore dans les archives de l'établissement des preuves du passage du jeune Oliver Cromwell, vers 1610, à la "Huntingdon Grammar School", à la suite de quoi il étudie au "Sidney Sussex College" à Cambridge, alors une institution nouvellement créée professant une stricte doctrine puritaine. Il doit cependant la quitter dès 1617 sans avoir obtenu de diplôme, son père étant décédé. Plusieurs biographes notent qu'il doit fréquenter ensuite la "Lincoln's Inn", une des "Inns of Court", écoles de droit de Londres. Cependant, nous ne retrouvons plus dans les archives de la "Lincoln's Inn" de traces de son passage. La solution à cette énigme diverge selon les biographes. Selon Antonia Fraser, il est très vraisemblable qu'il ait tout de même fréquenté cette institution, alors que son grand-père, son père et deux de ses oncles l'ont fait avant lui, et qu'il y enverra de même son fils Richard en 1647. Au contraire, avance que le jeune Cromwell dut demeurer à Huntingdon alors que sa mère veuve avait à charge ses sept sœurs non mariées.

C'est en 1620 qu'il épouse Élizabeth Bourchier, le 22 août à l'église "St Giles-without-Cripplegate", celle-ci se situant à Londres, ce qui est, faisons-le remarquer, un indice de plus suggérant que Cromwell a bel et bien fréquenté l'une des "Inns of Court" de la capitale. Le père d'Élizabeth Bourchier, "Sir" James Bourchier, est un marchand de cuir londonien qui possède un important domaine foncier dans l'Essex et entretient des liens nombreux avec les membres de la "gentry" puritaine locale. Il entre également en contact, grâce à ce mariage, avec Oliver St-John et d'autres membres influents de la bourgeoisie londonienne, ainsi qu'avec les comtes de Warwick et de Holland. Ces liens avec des personnalités importantes de la capitale joueront un rôle crucial dans le futur rôle que tiendra Cromwell.

Le couple Cromwell a neuf enfants, dont Richard Cromwell qui succédera à son père en tant que Lord Protecteur du "Commonwealth", et Henry Cromwell, qui deviendra "Lord Deputy" d'Irlande.

Il obtient un siège au Parlement en 1628. L'écrivain et député "Sir" Philip Warwick dressa un portrait peu flatteur d'Oliver Cromwell : 

Lorsque le Parlement est dissous en 1629, il retourne gérer la fortune paternelle. Député de l'université de Cambridge au Long Parlement (1640), il s'y fait remarquer par ses déclamations contre le papisme et la royauté. Lorsque la guerre civile commence, en janvier 1642, il est convaincu que c'est le signe de Dieu pour la lutte contre l'épiscopalisme et la monarchie détachée des affaires puritaines.

Il vit comme fermier-gentilhomme, membre de la "gentry" jusqu'au début de la première guerre civile anglaise en 1642 quand il mène ses ouvriers (en fait une armée recrutée par ses soins) au service du Parlement. Il se signale par son habileté et sa bravoure, mais aussi par ses actes de cruauté. Après son service militaire, il devient un homme politique remarqué, et il est le seul apparemment capable de gouverner après la mort du roi Charles.

Les relations supposées entre Cromwell et la franc-maçonnerie ont donné naissance à des hypothèses jugées minoritaires et fantaisistes.

À l'été 1642, il lève à ses frais (il a hérité en 1638 d'une riche propriété) une troupe de cavalerie organisée selon des principes démocratiques (officiers élus par la troupe, discussions idéologiques…) : les "Ironsides" (« côtes de fer »). En 1643, le Parlement le promeut de capitaine à colonel, de manière inexplicable. Sous les ordres de Lord Thomas Fairfax, il s'illustre à la bataille de Marston Moor le et à celle de Newbury en octobre. Le Parlement le nomme lieutenant-général de cavalerie.

En 1645, le Parlement le charge de réorganiser l'armée sur le modèle de ses propres troupes (c'est la "New Model Army"). Il bat les royalistes à la bataille de Naseby le 14 juin de la même année.

Le , le roi se rend aux Écossais, qui le livrent au Parlement anglais le .

L'armée parlementaire est divisée en deux camps : les Indépendants constitués par les officiers, et les Niveleurs composés par la troupe. Ceux-ci prônent un régime égalitaire. Cromwell est d'abord conquis par leurs idées. En 1648, Charles s'enfuit sur l'île de Wight, mais il est bientôt ramené à Londres. Le Parlement étant peu enclin à juger son souverain légal, Cromwell organise la purge dans ses rangs. Le procès a lieu du 20 au 27 janvier 1649, et Charles est décapité à la hache le 30 janvier.
C'est le général en chef de ses armées et un de ses plus proches conseillers, Edward Whalley, qui signe l'arrêt de mort de Charles .

Une des opérations de siège les plus réussies de la "New Model Army" est le siège de Drogheda de 1649, dans le cadre de la conquête cromwellienne de l'Irlande catholique.

Le , Cromwell proclame la République, ou "Commonwealth". Mais les relations se détériorent entre le Parlement croupion, parlement à chambre unique, et l'armée ; Cromwell intervient et fait chasser les parlementaires par des soldats et institue un nouveau Conseil d'État dont il est partie prenante ainsi qu'un nouveau Parlement, mais dont les membres sont cette fois-ci nommés par le Conseil d'État. Ce Conseil ainsi que le Conseil des officiers, redoutant l'anarchie latente, nomme Cromwell Lord Protecteur de la république d'Angleterre, d'Écosse et d'Irlande en 1653.

Ses pouvoirs sont normalement contrebalancés par le Conseil et le Parlement, mais le Conseil lui est acquis et le Parlement est dissous dès le 20 avril 1653 : 

Un plaisantin fait placer un écriteau sur la porte de la salle des séances où il est écrit : « Chambre non meublée à louer ».

Cromwell impose ainsi un despotisme puritain, fait régner l'austérité, et pratique une certaine tolérance religieuse, sauf en ce qui concerne les catholiques. Les séries de massacres commis par ses troupes durant la répression de la révolte de l'Irlande sont ainsi encore très présentes dans la mémoire collective.

À l'initiative de Manasse ben Israel, il abolit en 1656 le décret de 1290 qui avait expulsé la communauté juive d'Angleterre.

En 1656, il convoque un nouveau Parlement car il a besoin de subsides pour mener la guerre contre l'Espagne en Jamaïque, et le dissout dix jours plus tard.

Une troisième session est ouverte en 1658. Ce Parlement, fortement épuré, lui accorde les subsides et lui demande de devenir roi et de rétablir la royauté ; sous la pression de ses officiers, Cromwell refuse, mais conserve le droit de désigner son successeur ; il désignera Richard Cromwell, son fils, avant de dissoudre une dernière fois l'Assemblée, le 4 février de la même année : 

Dès lors, Cromwell règne en souverain absolu. Du reste, il enlève la Jamaïque aux Espagnols et abaisse la marine hollandaise ; il achève la réduction de l'Irlande et de l'Écosse.

Cromwell, affecté par la mort de sa fille Betty un mois plus tôt, s'éteint à Londres le , victime d'une septicémie due à une infection urinaire, facilitée par la malaria. 

Son fils Richard Cromwell lui succède mais pour très peu de temps car le général George Monck, gouverneur de l'Écosse, craint que la nation ne sombre dans le chaos, et cherche à rétablir la monarchie. En , Monck et son armée marchent sur Londres, et avec le soutien populaire, forcent le Parlement à se dissoudre.

Charles II rentre alors à Londres où il va se faire couronner le . Pour venger la mort de son père, il fait juger les régicides, et exhumer le corps de Cromwell de l'abbaye de Westminster et le soumet, avec les dépouilles de son beau-fils Henry Ireton et du juge John Bradshaw, au rituel d'exécution "post mortem" le 30 janvier 1661, date anniversaire de l'exécution de Charles. Son corps est jeté dans un puits et sa tête exposée sur un pieu devant l'abbaye de Westminster jusqu'en 1685. Après trois siècles de vicissitudes, elle sera inhumée au Sidney Sussex College de Cambridge, le .

La période qui suit le couronnement de Charles II est appelée la Restauration.

À l'éclatement de la guerre civile anglaise, la flotte, de trente-cinq navires, se range du côté du Parlement et s'accroît alors très rapidement jusqu'à parvenir à cent deux bâtiments en 1652. Les tactiques et l'armement évoluent et le combat en ligne de file, laquelle est alors divisée en trois parties — ou escadres —, commandés respectivement par un "admiral", un "vice admiral et un "rear admiral", est introduit. Lors de la guerre de Hollande, sous le commandement d'amiraux tel que Robert Blake, elle se révèle un magnifique outil de combat. Quand Charles II monte sur le trône en avril 1661, l'effectif est de 154 vaisseaux. Le roi change le nom de la flotte en Royal Navy et désigne Samuel Pepys à la tête du Navy Board, où il organise la création de l'amirauté. Suivent deux guerres contre la Hollande en 1664 et 1674 ; Pepys est finalement écarté en 1688, lors de la déposition de Jacques II.

En 1655, l'amiral William Penn échoue dans sa tentative de prise de contrôle de la colonie espagnole d'Hispaniola mais parvient à s'emparer de la Jamaïque, dont il fait une importante base pour les corsaires de toute nationalité et l'attaque des navires espagnols. Cromwell espère ainsi prolonger la guerre des Hollandais contre l'Espagne qui s'est achevée en 1648.

Ses successeurs de la dynastie Stuart vont au contraire faire la guerre aux Hollandais, coupables de soutenir le trafic du tabac au détriment de la croissance du sucre. La première guerre, en 1664, revient à inverser les alliances de la période élisabéthaine, lorsque les Chiens de Mer anglais combattaient aux côtés des corsaires huguenots et des gueux de mer hollandais contre l'ennemi commun : la monarchie espagnole, première puissance européenne à la tête de son empire et championne du catholicisme.

Auparavant, les forces maritimes de Cromwell, dopées par un important effort de construction navale, ont fait le blocus de l'île de la Barbade, dirigée par des catholiques, puis imposé à l'île des taxes élevées et un monopole d'exportation, qui freine l'essor alors très rapide de cette colonie, où le sucre vient de s'implanter.








</doc>
<doc id="15607" url="https://fr.wikipedia.org/wiki?curid=15607" title="Liste des présidents du Nicaragua">
Liste des présidents du Nicaragua

La fonction de président de la République du Nicaragua fut créée par Constitution de 1854. De 1825 jusqu'à la Constitution de 1838, le Nicaragua fait partie de la République fédérale d'Amérique centrale et est dirigé localement par un chef de l'État "(Jefe del Estado)". Après la dissolution de la Fédération en 1838 jusqu'en 1854 la fonction est assurée par Directeur suprême "(Supremo Director)".

La liste des présidents de la République du Nicaragua depuis l'indépendance le est la suivante :




</doc>
<doc id="15618" url="https://fr.wikipedia.org/wiki?curid=15618" title="Gnuplot">
Gnuplot

Gnuplot est un logiciel qui sert à produire des représentations graphiques en deux ou trois dimensions de fonctions numériques ou de données. Le programme fonctionne sur de nombreux ordinateurs et systèmes d'exploitation (Linux, Windows, OS/2, VMS...) et peut envoyer les graphiques à l'écran ou dans des fichiers dans de nombreux formats.
Gnuplot utilise également l'algorithme de Levenberg-Marquardt pour ajuster les paramètres d'une fonction numériques sur des données expérimentales.

Le programme est distribué sous une licence de logiciel libre qui permet de copier et de modifier le code source du programme. Les versions modifiées du programme ne peuvent être distribuées que sous forme de fichiers correctifs.
Le programme n'a aucun raccordement avec le projet GNU et n'utilise pas la licence de copyleft GPL.

Le programme peut être utilisé interactivement, et est accompagné d'une aide en ligne. L'utilisateur entre en ligne de commande des instructions qui ont pour effet de produire un tracé. Il est aussi possible d'écrire des scripts gnuplot qui, lorsqu'ils sont exécutés, génèrent un graphique.

Gnuplot est utilisé comme moteur de traçage d'Octave et de Maxima.

Gnuplot fonctionne en interne en faisant abstraction du dispositif final de rendu. Ceci est implémenté via le concept de « terminal », que l'utilisateur peut spécifier par une commande.

Par défaut, et quelle que soit la plateforme, le rendu sera fait via une fenêtre utilisant la bibliothèque de fenêtrage standard du système d'exploitation et permettant une utilisation interactive à la souris (orientation de la vue pour les graphes en 3D notamment).

De nombreux terminaux sont disponibles (plus d'une trentaine) parmi lesquels SVG, PNG, PostScript, PDF, JPEG.
La liste complète dépend de la version et des options de compilation utilisée, et peut être obtenue via la commande codice_1.
On précisera le terminal souhaité via la commande

On pourra préciser la taille du rendu (en pixels) en ajoutant une option codice_2, par exemple:

D'autres options sont possibles, mais dépendent du type de terminal.

En cas de sortie dans un fichier, il faut spécifier pour chaque plot le nom du fichier voulu avec la commande codice_3, par exemple:

Pour exécuter le script :

La commande "multiplot" permet d'insérer plusieurs graphiques dans une feuille.


</doc>
<doc id="15621" url="https://fr.wikipedia.org/wiki?curid=15621" title="Liste des communes de la province de Saragosse">
Liste des communes de la province de Saragosse

Liste des 292 communes de la province de Saragosse, dans la communauté autonome d'Aragon (Espagne).


</doc>
<doc id="15622" url="https://fr.wikipedia.org/wiki?curid=15622" title="Intel P5">
Intel P5

L'architecture Intel P5 est à la base des microprocesseurs Pentium, lancé en mars 1993 en tant que premier processeur x86 superscalaire. Il s'agit pour Intel de la de processeurs x86. Il succède au dernier processeur de la série 80x86, l'Intel 80486. Il fut présenté pour la première fois le . Le Pentium MMX est une évolution mineure du Pentium. 

Elle sera suivie par l'architecture Intel P6, avec la sortie des premiers Pentium Pro en novembre 1995.


Les premières puces Pentium offraient juste deux fois la vitesse d’exécution d’un processeur Intel 80486 par cycle. Le plus rapide des Intel 80486 allait presque à la même vitesse qu’un Pentium de première génération, et quelques am486 d'AMD étaient pratiquement égaux aux Pentium 75. Le fait était coutumier d’Intel, dont déjà la version d’entrée de gamme du Intel 80386SX était moins rapide (mais bien plus riche en fonctionnalités) que les derniers hauts de gamme de son Intel 80286.

Les premiers Pentium sont sortis aux fréquences d’horloge de 66 et 60 MHz. Les versions ultérieures à 75, 90, 100, 120, 133, 150, 166, 200 et 233 mégahertz sont petit à petit devenues disponibles. Des overdrives pour Pentium sont sortis aux fréquences de 63 et de comme option de mise à niveau pour des ordinateurs de classe 80486. 

Le premier microprocesseur Pentium avait le nom de code interne P5, et était un microprocesseur superscalaire canalisé dans l’ordre. Il fut suivi du P54C, une version plus compacte qui était prête pour un fonctionnement en biprocesseur et gravée en 0,6 µm au lieu de 0,8 pour la première version.

Dans les premiers Pentium, un problème dans le code de l’unité de calcul en virgule flottante sur la division fut découvert en 1994, connu sous le nom de bug de la division du Pentium. Ces premiers exemplaires de processeurs Pentium sont également connus pour leur fragilité et la production relativement élevée de chaleur.

En 1997, Intel présenta une évolution mineure de son Pentium, appelée Pentium MMX (core P55C gravé en 0,35 µm pour certains), qui reposait sur le même cœur Pentium mais auquel avait été adjoint davantage de mémoire cache ( contre ) et 57 nouvelles instructions vectorielles afin de rendre plus rapides les applications multimédia. Ce processeur fut décliné dans des fréquences allant de à en version "normale" ou "lowpower". Il utilisait le Socket 7 pour la connexion avec la carte mère. 


</doc>
<doc id="15623" url="https://fr.wikipedia.org/wiki?curid=15623" title="Steve Ballmer">
Steve Ballmer

Steven Anthony Ballmer, né le à Détroit aux États-Unis, est un chef d'entreprise américain. Il fait la connaissance de Bill Gates à l'Université Harvard et entre chez Microsoft en 1980. Ballmer est CEO de l'entreprise de 2000 à 2014, date à laquelle il cède son poste à Satya Nadella. Depuis le , il est officiellement le nouveau propriétaire des Clippers, une franchise de basket-ball de la NBA basée à Los Angeles.

Steve Ballmer est né le , d'un père suisse (comptable chez Ford Motor Co) et d'une mère originaire de Pinsk (aujourd'hui en Biélorussie). Il grandit à Farmington Hills dans le Michigan et étudie les mathématiques et l'économie à l'Université Harvard, où il fait la connaissance de Bill Gates.

De 1977 à 1979, il a été employé par Procter & Gamble en tant qu'assistant chef de produits (), avant d'entrer à la Stanford Graduate School of Business. En 1980, Bill Gates le persuade d'abandonner ses études et de le rejoindre chez Microsoft, la société de logiciels de micro-informatique qu'il a fondée en 1975 avec Paul Allen.

En juillet 1998, il devient président de la société, puis son directeur exécutif en janvier 2000, remplaçant ainsi le cofondateur Bill Gates. Depuis 1998, il est notamment à l'origine du développement de la Xbox.

En 2014, son patrimoine était évalué par "Forbes" à , ce qui en fait le le plus riche du monde.

Le 17 février 2011, Steve Ballmer reçoit le titre de chevalier de la Légion d'honneur des mains du président de la République française Nicolas Sarkozy.

Le 23 août 2013, âgé de 57 ans, Steve Ballmer émet un communiqué interne au sein de Microsoft pour annoncer sa retraite après 33 ans d'activités chez Microsoft. En février 2014, le conseil de direction, dont fait partie le cofondateur de la société, Bill Gates, nomme Satya Nadella pour le remplacer.

Le 19 août 2014, Ballmer annonce qu'il quitte son poste au sein du conseil d'administration de Microsoft.

En 2016 il devient le conseiller d'Arnold Schwarzenegger dans l'émission de télévision "The Celebrity Apprentice".

En 2001, il a décrit la licence libre GPL (licence du système d'exploitation Linux), comme un cancer qui contamine la propriété intellectuelle dès qu'il la touche : . Il avait auparavant, en 2000, déclaré que Linux présentait les caractéristiques du communisme.

Steve Ballmer est réputé pour exprimer son enthousiasme sans retenue. Plusieurs vidéos le montrant en train de bondir sur la scène d'une conférence au rythme d'une chanson de Gloria Estefan ou de haranguer les développeurs informatiques sont devenues virales et ont été parodiées par les internautes. En 1991, après une conférence au Japon, il a dû se faire opérer des cordes vocales.

En avril 2007, Ballmer déclare 




</doc>
<doc id="15624" url="https://fr.wikipedia.org/wiki?curid=15624" title="Volga">
Volga

La Volga ( ; en , en ) est le plus grand fleuve d'Europe. Avec ses affluents, il draine plus d'un tiers de la surface de la Russie européenne. La Volga prend sa source dans les collines de Valdaï à d'altitude entre Moscou et Saint-Pétersbourg avant de se jeter dans la mer Caspienne après un long parcours de . Le fleuve est navigable sur presque toute sa longueur grâce à d'énormes aménagements réalisés pour l'essentiel durant la seconde moitié du . Son bassin versant, d'une superficie de , rassemble une mosaïque de peuples. La vallée de la Volga concentre depuis la Seconde Guerre mondiale une part importante des activités industrielles de la Russie. La Volga joue également un grand rôle dans l'imaginaire russe et a inspiré de nombreux romans, tableaux et chansons, telle que "Les Bateliers de la Volga."

La Volga prend sa source dans les collines de Valdaï, au nord ouest de Moscou et à environ au sud-est de Saint-Pétersbourg. Après avoir quitté ces collines, le cours d'eau atteint Rjev et se dirige vers le nord-est. À partir de là, de petits navires de marchandises peuvent circuler. Plus loin, il arrose la ville de Tver (ancienne Kalinine) qui fut fondée en 1135 et se situait sur la route reliant Moscou à Saint-Pétersbourg. La Volga traverse le lac de retenue du barrage d'Ivankovo (réservoir d'Ivankovo) jusqu'à Doubna, où elle est rejointe par le canal de Moscou. Le réservoir de Doubna a été construit pour alimenter Moscou. Après Kimry, le fleuve atteint le lac de retenue du barrage d'Ouglitch (réservoir d'Ouglitch). Ensuite le fleuve se dirige vers le nord jusqu'au lac de retenue du barrage de Rybinsk (réservoir de Rybinsk), qui est le plus ancien construit sur le fleuve. Dans ce lac se jettent deux affluents rejoignant la Volga ainsi que la voie navigable Volga-Baltique.

En aval du barrage, on trouve la ville de Rybinsk (autrefois rebaptisée Andropov) qui est le grand port de transbordement du cours supérieur de la Volga. Après le passage de l'écluse à double bassin, celle-ci coule ensuite vers le sud-est et atteint, après , Iaroslavl, une des plus anciennes villes de la Russie centrale, fondée au . Les industries qui y sont installées déversent la majeure partie de leurs eaux usées dans le fleuve sans les avoir retraitées. Environ en aval se trouve Kostroma fondée en 1152, à la confluence du fleuve avec la Kostroma. En aval de Kinechma, on trouve un nouveau lac de retenue (réservoir de Gorki) : c'est un plan d'eau de de long créé par le barrage de Nijni Novgorod. À Nijni Novgorod, l'Oka, un affluent droit, rejoint la Volga. Plus loin sur le territoire de la république des Maris, se trouve le barrage de Tcheboksary. Dans les années 1980, lors de sa construction, des dizaines de milliers de Maris durent être déplacés pour faire place au lac de retenue (réservoir de Tcheboksary). En aval du barrage se trouvent les villes de Tcheboksary et Novotcheboksarsk. Kazan, capitale du Tatarstan, est située sur le cours du fleuve, plus à l'est, là où le cours d'eau incline son cours vers le sud. La ville se situe au début du réservoir de Kouïbychev, lac de retenue long de créé par le barrage de Samara : avec ses de superficie, il s'agit du plus grand lac de retenue d'Europe. La Kama rejoint la Volga en se jetant dans ce lac. Sur les bords du lac se trouvent les villes d'Oulianovsk et Togliatti. La Volga forme une boucle presque fermée dans laquelle se situe la ville de Samara (autrefois Kouïbychev) qui compte plus d'un million d'habitants. La Samara, un affluent gauche, débouche à cet endroit dans le fleuve. La ville de Syzran se trouve sur la fin de la boucle.

Le lac de retenue de Saratov, qui commence à cet endroit est créé par le barrage de Saratov construit près la ville de Balakovo. L'Irguiz se jette dans la Volga au niveau de cette ville industrielle. Le peuple des Allemands de la Volga vivait entre Balakovo et Saratov avant d'être déporté au Kazakhstan et en Sibérie après la Seconde Guerre mondiale. Les villes de Engels et Marks situées sur la rive gauche rappellent cette époque. Le fleuve a conservé intact son aspect d'autrefois uniquement sur cette partie de son cours. Les formes caractéristiques du paysage constitué de prairies et de collines à l'ouest et d'une rive plate à l'est sont encore perceptibles entre Kazan et Volgograd, même si les lacs de retenues ont en partie noyé les anciennes rives. Mais ce n'est qu'entre Balakovo et Marks que la Volga est dans son état originel.

En face de la ville d'Engels se trouve la ville de Saratov, centre universitaire de . Le lac de retenue du barrage de Volgograd (réservoir de Volgograd), long de commence à hauteur de cette ville. La ville de Kamychine se trouve sur les rives de ce lac. En aval du barrage, se trouvent les villes de Volgograd (autrefois Tsaritsyne puis Stalingrad) et de Voljski. Volgograd s'étale sur le long de la rive ouest. Près de Svetly, commence le canal Volga-Don qui permet d'atteindre la mer Noire. Il a été construit pour l'essentiel par des déportés entre 1950 et 1957. Près de Voljski se détache un défluent de la Volga qui va suivre son propre cours jusqu'à la mer Caspienne. La Volga effectue une courbe prononcée vers le sud-est pour aller se jeter dans la mer Caspienne. La ville d'Astrakhan (autrefois Itil) se situe au début du delta formé par le fleuve. Une partie du delta est protégée par la réserve naturelle d'Astrakhan, car la région est un lieu de transit pour les oiseaux migrateurs. Les deux bras les plus importants du delta de la Volga sont le Bakhtemir et le Tabola. Plus à l'est, l'Akhtouba se jette dans le plus grand lac du monde (la mer Caspienne).

La Volga est alimentée pour 60 % par les eaux provenant de la fonte des neiges, à 30 % par les eaux souterraines et à 10 % par les eaux de pluie. La Volga possède un régime peu pondéré. En effet la moitié des eaux que roule le fleuve dans l'année s'écoulent en l'espace de six semaines de la fin avril à début juin au moment du dégel qui débute dans le sud du bassin versant pour se propager rapidement vers le nord ensuite. La cote (hauteur d'eau) du fleuve est soumise à d'importante fluctuations annuelles. Elle atteint à Tver, juste en amont du point de confluence avec la Kama et à Astrakhan mais la construction de réservoirs sur le cours du fleuve et de ses affluents a permis de réduire considérablement ces fluctuations.

Le débit moyen inter annuel ou module du fleuve est de /s à Tver; de /s à Iaroslavl, de /s à Nijni Novgorod, de /s à Samara et de /s à Volgograd. Après Volgograd, le fleuve ne reçoit plus de tributaires significatifs et l'évaporation entraine une diminution de son débit de 2 %. Le débit du fleuve pouvait autrefois atteindre au maximum /s après le point de confluence avec la Kama et /s à Volgograd, une partie des eaux se déversant dans les plaines inondables alentours. La lame d'eau écoulée annuellement dans le bassin versant est de à Volgograd pour un total des précipitations reçues de .

Avant la création des réservoirs, la Volga déversait en une année à son embouchure de tonnes de sédiments et 40 à de minéraux dissous.

Les eaux de la Volga atteignent une température de à en juillet et elles sont libres de glace par an à Astrakhan.

Les populations indigènes du cours supérieur de la Volga sont les Finnois Meryas qui sont aujourd'hui assimilés par les Russes. D'autres groupes finnois, comme les Maris et les Mordves résident le long du cours moyen de la Volga. Les populations turques sont apparues vers 600 et ont absorbé certains groupes finnois et indo-européens installés sur le cours moyen et inférieur du fleuve : par la suite, ils devinrent les Tchouvaches chrétiens et les Tatars musulmans ainsi que des Nogaïs aujourd'hui réinstallés au Daghestan. Les mongols bouddhistes Kalmouks colonisèrent la Volga au .

La région de la Volga héberge également quelques descendants d'Allemands de la Volga qui avaient été incités par Catherine II à s'installer sur ces terres pour les cultiver et les coloniser et également pour créer une région tampon contre les attaques des hordes mongoles de l'est. Les Allemands vinrent en grand nombre. Sous le régime soviétique, une partie de la région devint la République socialiste soviétique des Allemands de la Volga. Pendant la Seconde Guerre mondiale, Staline dissout la république : ses habitants furent en majorité déportés par familles entières dans d'autres régions de l'URSS (surtout le Kazakhstan et la Kirghizie) pour empêcher des actes de collaboration avec les occupants allemands et pour punir cette ethnie. Beaucoup émigrèrent en Allemagne à partir des années 1990.

La Volga était connue par les anciens Grecs sous le nom de fleuve "Rha". Dans le folklore russe, la Volga est connue sous le nom de « Mère Volga » en raison de son importance. Le fleuve constitua durant plusieurs siècles la frontière orientale de la Russie.

Au Haut Moyen Âge, des tribus slaves s'établirent sur son cours supérieur, tandis que des Bulgares s'établissaient sur son cours moyen (les Bulgares de la Volga, du au ) et les Khazars sur son cours inférieur. 

Ces derniers établirent à Itil, près du delta de la Volga, la capitale d'un « Empire » éphémère (-) qui s'étendit de Kiev à l'Oural, au détriment des Slaves orientaux et des Bulgares de la Volga. Ils sont surtout connus pour s'être convertis au judaïsme, avant d'être vaincus par les armées du Grand-Duc de Kiev Sviatoslav en 965. 

C'est durant cette période que la Volga devint une voie commerciale majeure à l'est de l'Europe (route commerciale de la Volga). Contrôlée par les Mongols de la Horde d'or en aval de Nijni Novgorod au , elle fut disputée au par les khanats d'Astrakhan et de Kazan. Aux , la Volga sur laquelle se trouvait la capitale de la Horde d'or joua un rôle prépondérant dans les conquêtes des Cosaques qui la firent passer sous le contrôle de Moscou. Après la prise de Kazan par Ivan le Terrible en 1552 puis celle d'Astrakhan en 1556, l'ensemble du cours du fleuve passa sous le contrôle de l'empire russe. Pour assoir son emprise sur la région de nombreux kremlins furent édifiés presque tous sur la rive droite plus escarpée. Parmi ceux-ci, certains sont devenues de grandes agglomérations : Saratov fondéee en 1590, Tsaritsyne (aujourd'hui Volgograd) en 1589, Simbirsk (aujourd'hui Oulianovsk) en 1648, Samara en 1648. Le peuplement de la région fut assuré par des colons russes, par des Cosaques et par des Allemands fuyant leur terre natale surpeuplée et attirés par l'offre d'installation de la reine Catherine II (1767). La Volga devenait un axe de communication facilitant l'expansion russe en Sibérie et sur la Caspienne, notamment sous Stenka Razine. À cette époque, la région de la basse Volga était principalement occupée par des populations turco-mongoles et finnoises.

Au , le chemin de fer consolida la prééminence des villes édifiées le long du fleuve. Les activités de ces centres urbains portaient sur le commerce, la minoterie, la conserverie de poisson, la construction navale et la maintenance du matériel ferroviaire. Mais la région resta globalement en marge de la révolution industrielle jusque dans les années 1930, date à laquelle furent construits un premier combinat métallurgique et une usine de tracteurs (à Stalingrad).
Durant la Seconde Guerre mondiale, la Volga fut une ligne de défense précieuse pour l'Armée rouge après les défaites de l'été 1942. La sanglante bataille de Stalingrad (aujourd'hui Volgograd) située sur le saillant est que dessine la Volga, permit aux Soviétiques de stopper l'avancée Allemande et de reprendre l'offensive.

Ce n'est qu'après la Seconde Guerre mondiale que la région se développa réellement : plus de (machine-outil, automobile) furent construites dans les principales agglomérations. De gigantesques travaux d'aménagements furent entrepris sur la Volga et son affluent, la Kama, pour en faire des artères de communication permanentes, produire de l'électricité et irriguer les terres peu arrosées situées le long du cours inférieur.
La mise en exploitation après la Seconde Guerre mondiale de gisements de pétrole et de gaz importants tout au long du bassin ( de tonnes de pétrole et de mètres cubes produits au cours de l'année 2001) ont favorisé la création d'une importante industrie pétrochimique dynamique même si les gisements ont tendance aujourd'hui à s'épuiser.

La partie centrale du bassin du fleuve est relativement fertile, quoique les précipitations soient très irrégulières d'une année sur l'autre. Par contre, les tentatives d'irrigation des terres situées plus au sud n'ont pas donné les résultats espérés. De plus, une partie des terres cultivables situées au bord de la mer Caspienne ont été submergées dans les années 1980 à la suite de la remontée du niveau de la mer Caspienne qui a pris les spécialistes au dépourvu.

Le bassin de la Volga est riche en ressources minières telles que la potasse et le sel. Le delta de la Volga ainsi que les abords de la mer Caspienne sont riches en poissons. Astrakhan, située sur le delta de la Volga, est le centre de l'industrie du caviar - « Caviar Volga » est d'ailleurs le nom de l'importateur français qui détient le monopole de la diffusion du caviar iranien dans le monde de 1921 à 1979 grâce à un accord avec l'Union des républiques socialistes soviétiques puis, dès 1956, avec le Chah d'Iran.

"(source)"

Plusieurs canaux mettent en communication Moscou avec la mer Blanche, la mer Baltique, la mer d'Azov, la mer Caspienne et la mer Noire. Cet ensemble de liaisons fluviales, dont la Volga constitue la pièce maîtresse, forme le système des Cinq-Mers. Il structure les échanges commerciaux de matières pondéreuses (bois, sel, céréales) en Russie occidentale et facilite l'approvisionnement de la capitale. 

Après la Seconde Guerre mondiale, un plan d'aménagement de la Volga imaginé dans les années 1920 est mis à exécution. Il s'agit d'abord de rendre navigable le fleuve soumis à de fortes variations de débit associées à une pente extrêmement faible ( de dénivelé sur l'ensemble du cours) avec des changements importants de niveau en fonction de la saison (jusqu'à ). Les deux autres objectifs sont de produire de l'électricité et d'irriguer les terres peu arrosées situées sur le cours inférieur.

Une dizaine de grands barrages sont édifiés sur le cours de la Volga et de ses affluents la Kama et l'Oufa créant de gigantesques lacs de retenue. L'ensemble est appelé « cascade Volga-Kama ». Les ouvrages construits ont assagi le fleuve et garantissent désormais en toute saison (quand le fleuve n'est pas pris par les glaces) une profondeur supérieure à . En contrepartie, plus de de terres ont été noyées ainsi que des centaines de villages et quelques villes. Les centrales électriques produisent par an. En revanche, le programme d'irrigation est un échec car il pâtit de la désorganisation de l'administration russe et de problèmes de remontée de sel sur des terres trop irriguées.

Barrages hydroélectriques construits sur la Volga (surface du lac de retenue, volume, production électrique, date de construction) :

L'appellation russe peut être rapprochée des mots slaves désignant le caractère « mouillé », « humide » ("влага", "волога"). Ce nom devint en français et en anglais "Volga" et en allemand "Wolga". Le nom pourrait également avoir des origines finnoises.

Les populations turques vivant au bord du fleuve l'appellent "Itil" ou "Atil". Attila le Hun pourrait tenir son nom du fleuve. Aujourd'hui dans les langues apparentées au turc, la Volga est connue sous le nom de "İdel" (Идел) en tatar, "Атăл" (Atăl) en tchouvache et "İdil" en turc. En langue mari le fleuve est appelé "Юл" (Jul) utilisant la même racine

Si on remonte encore plus loin dans le temps, les Scythes donnaient au fleuve le nom de "Rha" qui peut être associé à l'ancien mot sanscrit "Rasah" désignant une rivière sacrée. Cette origine est conservée dans le nom donné par les Mordves au fleuve : Рав (Raw).

La Kama est le plus important des affluents de la Volga. Plusieurs indices prouvent que la Volga dans son cours inférieur devrait être renommée la Kama. À la confluence, les débits moyens de la Volga et de la Kama sont respectivement de et /s. La superficie des bassins de leurs cours supérieur est respectivement de et . La Volga reçoit un nombre de cours d'eau inférieur ( contre ). La vallée fluviale de la Kama est plus ancienne que celle de la Volga. Dans la première moitié de l'ère quaternaire, à l'époque du maximum glaciaire, la Volga n'existait pas dans sa forme actuelle et la Kama alimentait la mer Caspienne. À l'époque, le cours supérieur de la Volga se jetait dans le Don qui était alors le fleuve le plus important d'Europe. Le cours inférieur de la Volga emprunte en fait celui de l'ancienne Kama. Si on s'en tient aux paramètres hydrologiques, il est clair que la Volga inférieure devrait en fait s'appeler la Kama. Mais le rôle historique joué par le cours supérieur de la Volga ainsi que son importance économique contemporaine expliquent la dénomination retenue. Il existe d'autres exemples analogues par exemple : le Mississippi et le Missouri ; la Seine et l'Yonne ; l'Ob et l'Irtych, l'Ienisseï et l'Angara, et d'autres.

"(de la source à l'embouchure)"


"(source)"




</doc>
<doc id="15625" url="https://fr.wikipedia.org/wiki?curid=15625" title="Frank Zappa">
Frank Zappa

Frank Vincent Zappa, né le à Baltimore et mort le à Los Angeles, est un musicien, guitariste, auteur-compositeur, interprète, ingénieur du son, producteur, satiriste et réalisateur américain. Ses travaux ont trait à plusieurs genres distincts : rock, jazz et musique classique, ainsi qu'un lien à la musique concrète. Zappa a aussi occasionnellement été réalisateur de films et de vidéos de musique, et concepteur de pochettes d'albums qu'il a produit par ailleurs en totalité. Tout au long de sa carrière, il a sorti plus de soixante albums qu'il a enregistrés avec les Mothers of Invention ou, pour une bonne partie, sous son propre nom. Dès sa jeunesse, il s'est intéressé aux compositeurs classiques du , notamment Edgard Varèse, Igor Stravinsky, Anton Webern, et au rhythm and blues des années 1950. Il s'est essayé à la composition de musique classique au lycée, tout en jouant de la batterie dans des groupes de rhythm and blues. Il s'est finalement orienté vers la guitare, restée son instrument de prédilection pour la plus grande partie de sa carrière.

Auteur-compositeur-interprète autodidacte, Frank Zappa s'est ouvert à diverses influences musicales, sa musique faite d'expérimentations dans de multiples styles musicaux, s'avère difficile à classifier dans un genre distinct. Les morceaux de son premier album avec les Mothers of Invention, "Freak Out!", paru en 1966, semblent être du rock conventionnel tout en s'en distinguant par des improvisations collectives et des collages sonores réalisés en studio. Les albums subséquents de Zappa affirment son approche éclectique et expérimentale de la musique, s'essayant à plusieurs genres et s'écartant des sentiers conventionnels du rock, du jazz ou de la musique classique. Les paroles de Zappa, souvent teintées d'un humour décapant, parfois graveleux et absurde, révèlent sa vision iconoclaste des pratiques, structures et hiérarchies sociales établies. Sur un ton satirique, Zappa a âprement critiqué le système éducatif et les institutions religieuses et s'est imposé comme un défenseur assidu et passionné de la liberté d'expression, de l'autodidaxie, de l'engagement politique et de l'abolition de la censure.

Les travaux de Zappa, artiste prolifique, ont souvent été reçus très favorablement par la critique. Il a aussi connu le succès commercial, particulièrement en Europe, bien qu'il ait travaillé comme artiste indépendant pour une grande partie de sa carrière. Zappa est fréquemment cité comme source d'influence majeure par plusieurs musiciens et compositeurs contemporains. Il a aussi lancé la carrière solo de musiciens membres quelque temps de ses différents groupes. Il a été, à titre posthume, intronisé au Rock and Roll Hall of Fame en 1995 et a reçu un Grammy Award rendant hommage à l'ensemble de son œuvre, en 1997. Zappa est mort à (en 1993) des suites d'un cancer de la prostate. En 2002, la revue "Rolling Stone" l'a classé dans sa liste des cent plus grands artistes de tous les temps, et en 2011 de la liste des cent meilleurs guitaristes. 

Depuis 2006, son fils Dweezil Zappa, guitariste, tourne dans le monde entier avec un groupe consacré aux interprétations sur scène du répertoire de son père. 

Aîné de quatre enfants, Frank naît à Baltimore (Maryland) dans une famille d'origine sicilienne-libanaise par son père, Francis Vincent Zappa, et franco-italienne par sa mère, Rose Marie Colimore. Il grandit en Californie, écoutant divers compositeurs d'avant-garde, comme son préféré Edgard Varèse, qu'il considère alors comme ou Igor Stravinski, et en s'intéressant aux groupes locaux de rhythm and blues.

Il intègre différents groupes en tant que batteur. Entamant une carrière d'auteur de chansons, Zappa rejoint un groupe local de R&B en tant que guitariste. Peu de temps après, il rebaptise le groupe "The Mothers", diminutif de "Motherfuckers", ce qui ne plaît évidemment pas à la maison de disques. Le groupe prend alors le nom de The Mothers of Invention.

Les "Mothers" épaulés par le producteur Tom Wilson sortent le double album "Freak Out!" (1966), mélange de R&B et de collages sonores expérimentaux. Mais l’année suivante Tom Wilson néglige la production de l’album "Absolutely Free". Zappa, voyant que son producteur est plus occupé au téléphone que dans la cabine d'enregistrement, lui propose de produire lui-même l'album, habitude qu'il gardera jusqu'à la fin de sa carrière. Zappa enregistre également "We're Only in It for the Money", satire grinçante du flower power mais aussi du mode de vie traditionnel américain ; la couverture pastiche celle de "Sgt. Pepper's Lonely Hearts Club Band" des Beatles, remplaçant les fleurs par des légumes.

Dans la foulée de "We're Only in It for the Money", il sort aux États-Unis, en , son premier album solo : "Lumpy Gravy", commercialisé en mai. Cet album, signé « Francis Vincent Zappa », est un collage de musique contemporaine (enregistrée en trois jours avec le ) et dialogues, réutilisés dans son dernier album, "Civilization, Phaze III".

Après plusieurs albums avec "The Mothers", dont "Cruising With Ruben & The Jets", au parfum de musique doo-wop, ou encore l'album-concept "Uncle Meat", Zappa sort "Hot Rats" un album solo instrumental à l'écriture ciselée, où apparaît son jeu de guitare influencé par le jazz, ainsi qu'un album de concert en public enregistré au "Fillmore East" (avec la participation de John Lennon et Yoko Ono).

Le , alors qu’il se produit avec son groupe au Casino de Montreux au bord du lac Léman, en Suisse, le feu prend au plafond de la salle, allumé par une fusée de détresse tirée par un des spectateurs. « Quelqu'un dans le public avait lancé un cocktail Molotov ou une chandelle romaine vers le plafond en guise de feu d'artifice, explique Zappa. Le revêtement en rotin a commencé à s'embraser. à étaient entassés dans la salle, bien au-delà de la capacité d'accueil. Dehors, pas mal d'autres essayaient d'entrer par tous les moyens, aussi les organisateurs avaient-ils astucieusement condamné les sorties de secours. Quand l'incendie a débuté, la foule n'avait que deux issues : la porte de devant, minuscule, ou les grandes baies vitrées côté scène ». Le Casino ainsi que le matériel des Mothers sont intégralement détruits, mais Zappa parvient à faire sortir tout le public sans incident grave et dans le calme. « J'ai fait une annonce du genre : "Gardez votre calme. Nous allons devoir vider les lieux. Il y a le feu, aussi je vous invite à foutre le camp." C'est surprenant, mais c'est ainsi : comment des gens qui ne parlent que le français peuvent-ils comprendre tout ce qu'on leur dit dans une autre langue, dès lors qu'il s'agit de vie ou de mort ? Ils ont commencé à évacuer par-devant ». Le groupe Deep Purple, qui enregistre au même moment l'album "Machine Head" dans le studio mobile des Stones immortalise l'événement dans son morceau "Smoke on the Water". On peut entendre cet événement sur le bootleg "Swiss Cheese/Fire!" édité officiellement en 1992 dans le coffret "Beat the Boots II".

Peu après, le , Zappa est précipité dans la fosse d’orchestre par Trevor Howell, un spectateur, lors d’un concert donné au Rainbow Theatre de Londres. L'agresseur se justifie tant par la qualité de la prestation, trop médiocre à son goût, que par l'insistance supposée du compositeur-guitariste à regarder sa petite amie. Frank Zappa souffre de plusieurs fractures, d’un traumatisme crânien, de blessures au dos, au cou, ainsi que d’un écrasement du larynx. Pendant plus d'un an, Zappa reste en chaise roulante, dans l'incapacité de jouer en concert et gardera plusieurs séquelles de l'accident :

« J’ai fini par me remettre, mais ma jambe est restée un poil plus courte que l’autre, d’où ces années de douleurs chroniques dans le dos. Durant ma saison en fauteuil roulant, j’ai refusé interviews et photos, je voulais juste faire de la musique, et j’ai quand même pu réaliser trois albums : "Waka/Jawaka", "Just Another Band From L.A." et "The Grand Wazoo" ».

En 1972, sortent donc deux albums de jazz avec un orchestre big-band : "Waka/Jawaka" et "The Grand Wazoo". Face aux coûts de fonctionnement du grand orchestre et de l'échec commercial, Zappa décide d'évoluer vers un style de composition plus accessible. Les résultats sont "Over-Nite Sensation", "Apostrophe", "Roxy & Elsewhere" et "One Size Fits All", avec une nouvelle version des Mothers, comprenant George Duke (claviers), Napoleon Murphy Brock (saxophone et chant), Ruth Underwood (percussions), Chester Thompson (batterie), Tom Fowler (basse), considéré comme le meilleur groupe l'ayant accompagné. Un album entier de la série "live" en six volumes "You Can't Do That On Stage Anymore" est extrait de cette période faste. C'est aussi l'ultime déclinaison des Mothers of Invention. Après un dernier disque en public enregistré en 1975 avec son vieux complice Captain Beefheart, "Bongo Fury", Frank Zappa arrête définitivement The Mothers of Invention, et ne publie désormais plus que sous son propre nom.

En 1977 Frank Zappa produit "Läther", un coffret à huit faces (quatre disques) (seuls 300 coffrets de 4 LP seront distribués aux radios) qui doit représenter son travail d’orchestration en studio, sur scène. Mais la Warner qui devait le distribuer, refuse de le publier. Le contenu apparaît pourtant éparpillé sur quatre albums différents : "Zappa in New York", "Studio Tan", "Sleep Dirt" et "Orchestral Favorites". D’autres bouts sont aussi présents sur "Shut Up 'n Play Yer Guitar" et "Zoot Allures". Le contenu de ce disque « perdu » (jusqu’en 1996), sera commercialisé tel qu’il fut conçu au départ, par sa famille, sous la forme d'un coffret CD, trois ans après son décès.

En décembre 1977, sur les ondes de la radio de Pasadena KROQ radio, Zappa diffuse "Läther" dans son intégralité, déclarant au micro : « Ici Frank Zappa, je suis votre disc-jockey temporaire, prenez votre petit appareil à cassette et enregistrez cet album qui ne sera peut-être jamais disponible pour le grand public. »

Zappa attaque la Warner, qui a refusé de le payer pour tout ce matériel, publié un peu n'importe comment, et crée son propre label, "Zappa Records", distribué par Mercury/Phonogram. Il publie en 1979 "Sheik Yerbouti" (album basé sur des enregistrements "live" de sa tournée européenne 1978), qui marque le début d’une excellente période en termes de réussite commerciale, et contient un titre qui se classe 1 en Norvège et en Suède : "Bobby Brown". Dans le groupe qui l'accompagne alors, le batteur Terry Bozzio, le guitariste Adrian Belew, et le claviériste Tommy Mars se coulent parfaitement dans l'esprit et la technicité de sa musique.

Dans la foulée, l'« "American composer" » (« "compositeur américain" »), comme il aime se définir, et qui avoue dans son autobiographie "Zappa par Zappa" n'avoir jamais été capable de jouer de la guitare et de chanter en même temps, sort l'opéra-rock en trois actes "Joe's Garage", interprété par un nouveau groupe - le chanteur Ike Willis, le batteur Vinnie Colaiuta, le bassiste Arthur Barrow et le guitariste Warren Cucurullo) - où tous les genres musicaux du rock (du reggae au disco en passant par le punk, la pop ou le rythm'n'blues) sont abordés à la sauce Zappa. Il y brocarde notamment l'Église de scientologie, ici « church of appliantology » (dont il change le nom du fondateur L. Ron Hubbard en "L. Ron Hoover"). On y trouve aussi la phrase-manifeste "Music is the Best" (la musique est la meilleure des choses). Ce sera un de ses plus grands succès commerciaux.

À partir du début des années 1980, Zappa explore les liens entre la musique qu'il a toujours jouée et la musique savante, en enregistrant notamment deux disques avec l'Orchestre symphonique de Londres. Le , Pierre Boulez et l'Ensemble intercontemporain jouent trois pièces de Zappa qui feront partie de l'album "" qui sort à la fin de la même année.

Une grande partie du travail ultérieur de Zappa sera influencée par son utilisation du synclavier comme outil de scène ou de composition, ainsi que par sa maîtrise des techniques de studio pour produire des effets sonores singuliers. Il est l'inventeur de la xenochronie, technique de studio utilisée sur de nombreux albums. Son propos devenu également plus explicitement politique se moque des télévangélistes et du Parti républicain américain.

Au début des années 1990, Zappa consacre presque toute son énergie à des travaux orchestraux et de synclavier. Fin 1991, sa fille aînée Moon Unit révèle à la presse le cancer de la prostate de son père. La maladie l'emporte le , à l'âge de . Pour sa dernière tournée en 1988 accompagnée d'une formation rock, il exige de ses 12 musiciens de connaître plus de 100 compositions, la plupart tirées de son propre répertoire. Le dernier concert de cette tournée et donc la dernière prestation scénique de Zappa avec un groupe, a lieu le 9 juin 1988 à Gênes en Italie. Alors que le groupe doit poursuivre sa tournée aux États-Unis, Zappa est contraint de tout arrêter. Le groupe explose en raison de l'animosité développée par plusieurs musiciens envers le bassiste Scott Thunes, au point qu'ils finissent par refuser de monter sur scène avec lui. L'ultime tournée de Frank Zappa est donc écourtée. Celle-ci est cependant immortalisée dans les albums "The Best Band You Never Heard in Your Life" (des morceaux aux textes « politiques », et des reprises de musiques de films principalement), "Make a Jazz Noise Here" (principalement de la musique instrumentale et expérimentale), "Broadway the Hard Way" (de nouvelles chansons), ainsi que sur quelques plages de "You Can't Do That on Stage Anymore, Vol. 6".

"You Can't Do That On Stage Anymore" ("tu ne peux plus faire cela sur scène désormais") sera la dernière production importante de sa vie, un projet majeur qu'il parvient tout juste à mener à bien, les volumes 5 et 6 étant publiés en 1992. Il compile sur six doubles CD (et près de 13 heures d'écoute) trois décennies de prestations scéniques, mêlant (parfois dans la même chanson) tous ses différents groupes et toutes les époques sans aucun ordre chronologique. C'est une plongée vertigineuse dans ce qu'il appelait "the conceptual continuity", la continuité conceptuelle qui définit la cohérence globale de son œuvre. Très tôt, Frank Zappa avait entrepris d'enregistrer tous ses concerts : les bandes, qui servaient souvent de base à ses albums live ou studio, étant stockées dans "The Vault" (la chambre-forte), un endroit mythique d'où la famille Zappa continue à sortir régulièrement des albums. Le 17 septembre 1992, l'Ensemble Modern interprète sous sa direction et celle de Peter Rundel son œuvre « classique » "The Yellow Shark" à Francfort. Une forme de consécration pour le compositeur américain.

Quelque temps avant sa mort, Zappa s'était occupé de la politique culturelle tchèque, à la demande de Václav Havel ; les deux hommes avaient une profonde estime mutuelle.

Après un mariage éphémère avec Kathryn J. Sherman (de 1960 à 1964), Zappa épouse Adelaide Gail Sloatman, avec laquelle il a eu quatre enfants : Moon, Dweezil, Ahmet et Diva.
Ses deux fils, Ahmet Zappa et Dweezil Zappa, également musiciens, ont formé ensemble le groupe Z. Depuis 2006, Dweezil organise et dirige fréquemment les tournées "Zappa Plays Zappa", présentant exclusivement des morceaux composés par son père.

La musique de Zappa est très hétérogène, allant du doo-wop à la musique contemporaine, parfois dans une même composition. Les influences en sont multiples, Zappa ayant pu être réduit à ses influences. Le fait est que, si elles sont parfois reconnaissables, elles sont cependant synthétisées dans un art unique et très personnel. Une phrase de Zappa se reconnaît instantanément (sauf, et cela arrive régulièrement, quand il ne veut pas que ce soit ainsi).

On peut essayer de distinguer les styles chez Zappa, pour mieux montrer comment ils s'entremêlent. Avant tout, la musique classique, celle du essentiellement (Zappa n'aimait pas la musique classique des siècles précédents, considérant que les compositeurs n'étaient que des esclaves au service des mécènes. Il aimait seulement Bach) : il dit avoir reçu le plus grand choc musical de sa vie dans ses jeunes années avec "Ionisation" de Edgar Varèse et "Le Sacre du printemps" de Igor Stravinski.

Le plus gros apport de la musique contemporaine dans l'œuvre de Zappa se situe au niveau rythmique : l'utilisation de mesures asymétriques et de polyrythmies.

Pour les premières, on peut citer le très classique "Pound for a Brown" (sur "Zappa in New York", par exemple), dont la rythmique écrite en 7/8 (caractéristique de la musique de l'Europe de l'Est — voir Mesures asymétriques) fut utilisée à de nombreuses reprises par Zappa, dans des morceaux comme "Catholic Girls", "Flower Punk" ou "Mother People". Le morceau "Keep It Greasey" (sur l'album "Joe's Garage") comporte toute une section en 19/16 (la mesure se décompose en quatre noires plus trois double-croches). Le rock progressif utilisait déjà beaucoup ce genre de mesures.

Les polyrythmes sont la superposition de divisions différentes d'un même temps, ou d'un même groupe de temps. Ainsi, en binaire, le temps se divise en 2, 4, 8, 16, etc. En ternaire, en 3, 6, 12, etc. Cela est totalement conventionnel, et la musique (jusqu'à la fin du au moins) repose là-dessus pour la musique dite « savante » ; la musique populaire ne divise guère autrement. Mais on peut vouloir jouer cinq, ou sept, etc., notes sur un même temps, et de manière régulière (c'est-à-dire en divisant le temps par cinq ou sept). Zappa le fait abondamment. C'est même l'une des marques de fabrique de ses mélodies. L'une de ses plus célèbres compositions, la "Black Page", fait une très grande utilisation des polyrythmes. Cela peut atteindre une redoutable complexité. Exemple : "Get Whitey" (sur l'album "The Yellow Shark") : la rythmique de base est en 9/4 ; elle peut donc se diviser en 18 croches, ou 36 doubles-croches, etc. À un moment, la mesure se divise en 23 croches (c'est donc du 23/8) et la mélodie se répand en doubles croches pointées principalement, ce qui augmente la complexité rythmique du morceau. Ce n'est pas pour rien que Zappa utilisait son Synclavier, qui pouvait jouer tout et n'importe quoi. En fait, à ce niveau-là, c'est comme si la mélodie se jouait à un "tempo" très différent de la rythmique.

On trouve des œuvres, chez Zappa, qui relèvent d'une esthétique venue tout droit de la musique contemporaine. Par exemple, la très boulézienne "Girl in the Magnesium Dress" (sur "" ou "The Yellow Shark"), ou des pièces comme "The Return of the Son of Monster Magnet" (album "Freak Out!"). D'autres s'apparentent à la musique de Stravinski (par exemple "G-Spot Tornado" sur "Jazz from Hell" ou sur "The Yellow Shark"), à Webern, etc. Mais ses meilleures compositions sont celles où il ne s'apparente à personne : les sus-cités "Black Page" et "Get Whitey", par exemple. D'une manière générale, Zappa compose à partir d'un fond très jazz-rock sur lequel se détachent des mélodies beaucoup plus complexes. Le fond sera par exemple une pentatonique sur un rythme en 4/4 tandis que la mélodie sera polyrythmique et polytonale — une alchimie caractéristique de son style.

Mais Zappa donne aussi dans le rock le plus simple, très souvent de manière parodique. L'album "Sheik Yerbouti" est principalement constitué de ce genre de musique. On y évoque des plombiers, l'idée que les cœurs brisés sont pour les « trouducs » ("Broken Hearts Are for Assholes"), des princesses juives, la barbichette, etc. Que des choses très importantes, servies par une musique entre le hard-rock et le blues, sans jamais perdre l'occasion de placer une mélodie avant-gardiste. De même, l'album "Joe's Garage" combine les genres, avec des morceaux disco, reggae, funk, rock, etc., avec beaucoup d'humour et de dérision.

Les morceaux de Zappa ne sont jamais vraiment achevés. Les concerts sont toujours l'occasion de nouveaux arrangements. De fait, Zappa ne joue jamais deux fois le même morceau. Par exemple, pour la "Black Page" sur "Zappa in New York", on trouve une première version avec solo de batterie, ajouts de percussions, puis un orchestre réduit ; sur le même album, on trouve la seconde version, qui comporte une rythmique qu'on pourrait dire "disco-funk" et des arrangements beaucoup plus grandiloquents ; sur "Make a Jazz Noise Here", on peut entendre la version "new age", très lente, menée par des cuivres langoureux, des rythmes reggae-ska, qui finit par reprendre à toute allure. De surcroît, Zappa avait mis au point tout un langage gestuel lui permettant d'indiquer, à n'importe quel moment, un changement d'interprétation quelconque : tel geste signifiait qu'il fallait jouer en reggae, ou en hard rock, etc. Par exemple, s'il tournait un doigt à droite et derrière sa tête comme s'il tripotait une dreadlocks, le groupe derrière lui jouait de façon reggae ; s'il faisait de même avec ses deux mains, le groupe jouait du ska ; s'il mettait ses deux mains à l'entrejambe et qu'il mimait une grosse paire de testicules, les musiciens savaient qu'ils devaient jouer du heavy metal. Zappa pouvait donc modifier sa composition au moment même où le groupe la jouait sur scène.

Tout ceci nécessitait d'avoir d'excellents musiciens. Et là encore, Zappa fut loin d'être en reste. En 1969, il renvoya tous ses musiciens (les Mothers of Invention d'origine), parce qu'il avait de gros problèmes financiers à l'époque, ou parce que ces musiciens n'étaient plus assez bons pour jouer sa musique, qui se complexifiait toujours plus. Il employa de nombreux batteurs : Aynsley Dunbar, Chester Thompson (accompagné de Ralph Humphrey dans la série de concerts de fin 1973 notamment au Roxy), Terry Bozzio, Vinnie Colaiuta, Chad Wackerman. En fait, Zappa fut au rock ce que Miles Davis fut au jazz un formidable révélateur de talents : comme pour Miles Davis, chaque nouveau groupe a été un nouveau style, une nouvelle source de compositions et d'arrangements.

En 1994 l'astéroïde 3834 est nommé (3834) Zappafrank en son honneur grâce au professeur Marsden.
L'année suivante Zappa entre au "Rock and Roll Hall of Fame", introduit par Lou Reed. Comme Reed, Zappa avait reçu l'hommage du président tchécoslovaque Václav Havel, pour son influence dans les pays de l'Est pendant l'oppression soviétique :

"Avant 1989, il était admiré en tant que symbole de démocratie et liberté par beaucoup de gens en Tchécoslovaquie".

Un buste du musicien est visible à Prague (République tchèque).
En 1995, on installe au centre de Vilnius, capitale de la Lituanie, une statue de Zappa réalisée par Konstantinas Bogdanas, un sculpteur lituanien renommé pour ses portraits de Lénine. Un autre buste de Zappa est également visible à Bad Doberan dans le Nord-Est de l'Allemagne, où se déroulent chaque année les Zappanales.

La "Frank-Zappa-Strasse" est inaugurée le 28 juillet 2007 dans les faubourgs de l'ancien Berlin-Est.

En 2012, la classe de cycle spécialisé en musiques actuelles du conservatoire Darius Milhaud à Aix en Provence, lui rend hommage avec un projet intitulé ""Gong Shô, Zappa, pas à pas"". Sous la direction de Thierry Riboulet, le spectacle audio - vidéo revisite des classiques du compositeur, essentiellement publiés dans les années 1970-80, regroupant des titres tels que "The slime, Broken hearts are for assholes, Bobby Brown, Dancing fool, Don't eat the yellow snow, Oh No, Peaches en Regalia, Muffin Man..."

En 2014, les conservatoires musicaux de Nantes, St Nazaire et La Roche Sur Yon lui rendent hommage avec "le projet Zappa" regroupant plusieurs morceaux tels que "Uncle Meat", "20 Small Cigars", "Take Your Clothes Off When You Dance", "Inca Road"...

Frank Zappa a créé le label Straight Records, sur lequel ont été produits ces albums :









</doc>
<doc id="15630" url="https://fr.wikipedia.org/wiki?curid=15630" title="Grenade (pays)">
Grenade (pays)

La Grenade (anglais : ) est un pays des Antilles. Sa capitale est Saint-Georges.

Cet État insulaire de la mer des Caraïbes comprend l'île de la Grenade, l'île Ronde, l'île de Carriacou et l'île de Petite Martinique, toutes situées dans la partie méridionale de l'archipel des Grenadines. En y incluant les îles désertes, le pays possède une superficie de . En 2015, on comptait Grenadiens. La langue officielle est l'anglais.

L'île de la Grenade est située à moins de au nord des côtes du Venezuela et de Trinité-et-Tobago. L'île de Carriacou est à quelques kilomètres au sud de l'île d'Union de Saint-Vincent-et-les-Grenadines.

Peuplée par les Caraïbes avant l'arrivée des Européens, la Grenade est d'abord une colonie du royaume de France de 1649 à 1763. À la suite de la guerre de Sept Ans, elle est léguée au royaume de Grande-Bretagne par le traité de Paris. Reconquise par la France durant la Révolution américaine, elle redevient britannique grâce au traité de Versailles de 1783. Le pays accède à son indépendance du Royaume-Uni le . La Grenade devient le Gouvernement révolutionnaire populaire de la Grenade, un État communiste, de 1979 jusqu'à l'invasion américaine de 1983. En 2004, l'ouragan Ivan cause d'importants dommages dans le pays.

La Grenade est surnommée « l'île aux épices » ("Island of Spice") pour sa cannelle, ses clous de girofle, son curcuma et surtout le macis et la noix de muscade.

La Grenade est membre de l'Alliance bolivarienne pour les Amériques (ALBA) depuis le .

La Grenade est un pays des Antilles. La Grenade est située à au sud-sud-ouest de l'île Saint-Vincent (Saint-Vincent-et-les-Grenadines), à au nord-ouest de l'île de Tobago (Trinité-et-Tobago) et à de la punta Mejillones, sur la côte nord-est du Venezuela. D'une superficie de , ce pays compte environ habitants (2012) et est composé de l'île principale, la Grenade, et de quelques îles parmi les Grenadines, Carriacou, Petite Martinique et l'île Ronde. Saint-Georges est la capitale de la Grenade.

La Grenade est située à au nord du Venezuela.

Le mont Sainte-Catherine est le point culminant avec . Son littoral mesure de long.

Avant l'arrivée de Christophe Colomb, en 1492, l'île était habitée par les Caraïbes. Christophe Colomb baptisa cette île "Concepción". Une compagnie fondée par le cardinal français Richelieu acheta l'île aux Anglais en 1650. Grenade resta sous domination française jusqu'en 1762. Grenade devint officiellement britannique en 1763 par le traité de Paris qui met fin à la guerre de Sept Ans. Les Français se réemparèrent de l'île en 1779, mais les Britanniques la reprirent peu après. La paix fut rétablie lors de la signature par les deux camps du traité de Versailles en 1783. Provoquée par Victor Hugues une révolte pro-française éclata en 1795 mais fut matée par les troupes britanniques. De 1958 à 1962, la Grenade devint une province de la Fédération des Indes occidentales qui éclata rapidement.

L'île accéda à l'indépendance le , devenant un royaume du "Commonwealth", avec Eric Gairy comme Premier ministre. Mais le gouvernement de celui-ci devint progressivement autoritaire, se lie aux dictatures militaires chilienne et sud-coréenne et s’appuie sur des groupes de miliciens semblables aux Tontons macoutes d’Haïti, le Mangoose Gang, pour assassiner des adversaires politiques. Il se bâtit une fortune considérable en accumulant les propriétés d’hôtels et de restaurants. 

L'opposition se rassemble principalement au sein du New Jewel Movement (NJM) dirigé par Maurice Bishop (dont le père a lui-même été assassiné par le régime). Devant l’impossibilité de manifester légalement, celle-ci commence à organiser une branche militaire, l'armée révolutionnaire du peuple. Lorsque les dirigeants du mouvement apprennent qu'Eric Gairy s’apprête à les faire assassiner, ils choisissent d’opérer un coup d’État : le 13 mars 1979, un groupe de militants s'empare de l'unique caserne de la Grenade et désarment les soldats qui n'opposent que très peu de résistance.

Le NJM constitue un Gouvernement révolutionnaire du peuple présidé par Maurice Bishop, qui exprime son objectif : « Nous sommes un petit pays, nous sommes un pays pauvre, avec une population de descendant d'esclaves africains, nous faisons partie du tiers-monde exploité et, définitivement, notre défi est de chercher la création d'un nouvel ordre international qui mette l’économie au service du peuple et de la justice sociale ». Le nouveau gouvernement inquiète les États-Unis, qui avaient précédemment soutenu Eric Gairy, et dont l’ambassadeur avertit : « Le gouvernement des États-Unis verrait avec déplaisir toute inclinaison de la part des Grenadins à développer des liens plus étroits avec Cuba. »

Le régime s’emploie en particulier à développer des politiques sociales : un Centre pour l'éducation populaire est créé pour coordonner les initiatives du gouvernement en matière d'éducation, notamment des campagnes d'alphabétisation. L'apprentissage du créole de la Grenade est autorisé à l'école. Néanmoins, la tendance du gouvernement de Bishop à marginaliser le rôle de l’Église dans l'éducation contribue à la dégradation des relations avec le clergé. Dans le secteur de la santé, les consultations médicales sont rendues gratuites avec l'aide de Cuba qui fournit des médecins, du lait est distribué aux femmes enceintes et aux enfants. En économie, les autorités mettent en place un système de prêts financiers et de matériel à l'attention des agriculteurs, et des coopératives agricoles sont mises en place pour développer l'activité. Le gouvernement de Bishop s'emploie également à développer les infrastructures, notamment en construisant de nouvelles routes et en modernisant le réseau électrique. Enfin, le gouvernement s'attaque aux cultures de marijuana pour favoriser l'agriculture vivrière et faire baisser la violence.

Á l'international, la Grenade est de plus en plus isolée. Le Royaume-Uni suspend ses aides économiques et les États-Unis usent de leur influence pour bloquer les prêts du Fonds monétaire international et de la Banque mondiale. La situation se dégrade également sur le plan intérieur : le 19 juin 1980, une bombe explose pendant un meeting au cours duquel Bishop devait intervenir. L'engin fait trois morts et vingt-cinq blessés. Bishop accuse ouvertement « l’impérialisme américain et ses agents locaux ». La responsabilité réelle de la CIA est cependant incertaine ; si elle avait en effet imaginé des opérations de déstabilisation, l’administration Carter y était opposée. En 1983, Bishop se rend finalement à Washington pour essayer de "négocier la paix". Au sein du gouvernement socialiste, des dissensions opposent une faction pro-soviétique et les partisans de Bishop. Le voyage à Washington de celui-ci est désavoué par le comité central du parti qui le destitue.le 14 octobre 1983 et le remplace par une direction collégiale. Le 19 octobre, une grève générale est déclenchée par les partisans de Bishop qui conduit à l'arrestation de ce dernier. Alors que les manifestants tentent de franchir les barrages pour le libérer, Il est assassiné par l'armée le .

Six jours après la prise de pouvoir par l'armée en , la Grenade est envahie par une coalition menée par les États-Unis. Cette intervention est demandée par l'Organisation des États de la Caraïbe orientale (OECO). La requête est rédigée à Washington. L'opération est le plus grand déploiement américain depuis la guerre du Viêt Nam. La guerre est rapide et la coalition américaine ( soldats américains et 300 hommes d'Antigua, la Barbade, la Dominique, la Jamaïque, Sainte-Lucie et Saint-Vincent, qui n'ont pas participé aux combats) vient rapidement à bout des forces grenadiennes ( soldats, assistés par 784 Cubains - pour la plupart des ouvriers qui participaient aux travaux de construction d'un aéroport - et quelques instructeurs provenant d'URSS et d'autres pays communistes). Après la chute du PRG, des élections sont tenues en 1984, et voient la victoire du Nouveau Parti national.


Le programme Patrimoine mondial (UNESCO, 1971) a inscrit dans sa liste du Patrimoine mondial (au 17/01/2016) : liste du patrimoine mondial à la Grenade.

La Grenade est divisé en six paroisses (') et une dépendance (').


L'agriculture représente environ 24 % du produit national brut (PNB).

La noix de muscade, qui orne le drapeau national, a fait la fortune de l'archipel : jusqu'en 2004, la Grenade en était le deuxième producteur mondial derrière l'Indonésie et l'ensemble de ses épices faisait vivre plus de exploitants. Mais cette année-là, l'ouragan Ivan, dit « le terrible » a ravagé 60 % des plantations. Si bien que la noix de la Grenade ne devrait pas retrouver son rang avant 2012, le temps que les milliers de muscadiers replantés arrivent à maturité.

Le , l'ouragan Ivan a dévasté la Grenade. 90 % des habitations ou immeubles ont été détruits. Plus de 90 % des bateaux ancrés régulièrement ou réfugiés à la Grenade pour échapper à Ivan ont été coulés ou endommagés. Ivan, cyclone de force 5 (« catastrophique », maximum sur l'échelle de Saffir-Simpson) a fait 37 morts, 500 blessés et laissé personnes sans abri. Il fut l'ouragan le plus redoutable ayant frappé les Caraïbes en un demi-siècle. Le , la Commission européenne a accordé une aide de 1,5 million d'euros en faveur des victimes de la Grenade.

La Grenade utilise comme sept autres pays de la région la même banque centrale et la même devise.

La plupart des habitants sont d'ascendance africaine. Les indigènes, Caraïbes et Arawaks, ne constituent qu'une minorité. Environ 50 % des habitants ont moins de 30 ans (2000).

L'anglais est la langue nationale, mais quelques personnes connaissent encore le créole à base lexicale française proche de celui de la Martinique.

La population de Grenade est estimée à habitants en 2015. Sa densité est de 316 /km. Elle est composée à 24,35 % de personnes de 0 à 14 ans, à 66 % de personnes de 15-64 ans et de 9,62 % de personnes de 65 ans ou plus. L'espérance de vie des hommes est 71,5 ans et celle des femmes est de 76,9 ans. La même année, le taux de croissance de la population est 0,48 %, avec un taux de natalité de , un taux de mortalité de , un taux de mortalité infantile de , un taux de fécondité de 2,06 enfants/femme et un taux de migration de .

Selon le Pew Research Center, en 2010, 96,6 % des habitants de la Grenade sont chrétiens, principalement catholiques (51,9 %) et dans une bien moindre mesure protestants (43,4 %). De plus, 1,3 % de la population pratiquent une religion populaire.

Tout comme les autres îles caribéennes le principal événement culturel de la Grenade est le carnaval qui se déroule tous les ans au mois d'août. Localement appelé "Spice Mas" le carnaval dure deux jours. Durant les festivités les Grenadins défilent vêtus de costumes très colorés faisant référence à l'héritage africain, britannique et français de l'île. La fête est très populaire et la majorité de la population y participe. L'île de Carriacou organise également son propre carnaval.

La Grenade remporte son premier titre olympique le grâce à Kirani James, qui obtient à 19 ans la médaille d'or au 400 mètres homme des Jeux olympiques de Londres.

La Grenade a pour codes : 



</doc>
<doc id="15631" url="https://fr.wikipedia.org/wiki?curid=15631" title="Conjecture d'Euler">
Conjecture d'Euler

La conjecture d'Euler est une conjecture mathématique de théorie des nombres, réfutée, mais qui a été originellement proposée par le mathématicien suisse Leonhard Euler en 1772, et qui s'énonce de la façon suivante :Pour tout entier "n" strictement supérieur à 2, la somme de "n "– 1 puissances "n"-ièmes n'est pas une puissance "n"-ième.

En d'autres termes, et de manière plus formelle :formula_1

Euler percevait cet énoncé comme une généralisation de la conjecture de Fermat, à savoir que pour tout entier "n" strictement supérieur à 2, la somme de deux puissances "n"-ièmes n'est pas une puissance "n"-ième. Les deux énoncés coïncident pour "n "= 3. Euler ajouta que 

La conjecture d'Euler fut infirmée par L. J. Lander et T. R. Parkin en 1966 grâce au contre-exemple suivant :

En 1988, Noam Elkies trouva même une méthode pour construire des contre-exemples lorsque "n" = 4. Son plus simple contre-exemple fut le suivant :

Par la suite, Roger Frye trouva le plus petit contre-exemple possible pour "n" = 4 en utilisant, avec un ordinateur, des techniques suggérées par Elkies :

Aucun contre-exemple pour "n" > 5 n'est actuellement connu.

En 1967, Lander, Parkin et ont conjecturé que si et , il n'existe pas d'entiers strictement positifs " "tels que
formula_5
Cela impliquerait en particulier que
formula_6




</doc>
<doc id="15634" url="https://fr.wikipedia.org/wiki?curid=15634" title="Conjecture de Syracuse">
Conjecture de Syracuse

En mathématiques, on appelle suite de Syracuse une suite d'entiers naturels définie de la manière suivante :

On part d'un nombre entier plus grand que zéro ; s’il est pair, on le divise par 2 ; s’il est impair, on le multiplie par 3 et on ajoute 1. En répétant l’opération, on obtient une suite d'entiers positifs dont chacun ne dépend que de son prédécesseur.

Par exemple, à partir de 14, on construit la suite des nombres : 14, 7, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1, 4, 2… C'est ce qu'on appelle la suite de Syracuse du nombre 14.

Après que le nombre 1 a été atteint, la suite des valeurs (1,4,2,1,4,2…) se répète indéfiniment en un cycle de longueur 3, appelé cycle trivial.

Si l'on était parti d'un autre entier, en lui appliquant les mêmes règles, on aurait obtenu une suite de nombres différente. A priori, il serait possible que la suite de Syracuse de certaines valeurs de départ n'atteigne jamais la valeur 1, soit qu'elle aboutisse à un cycle différent du cycle trivial, soit qu'elle diverge vers l'infini. Or, on n'a jamais trouvé d'exemple de suite obtenue suivant les règles données qui n'aboutisse pas à 1 et, par suite, au cycle trivial.

La conjecture de Syracuse, encore appelée conjecture de Collatz, conjecture d'Ulam, conjecture tchèque ou problème 3"x" + 1, est l'hypothèse mathématique selon laquelle la suite de Syracuse de n'importe quel entier strictement positif atteint 1.

En dépit de la simplicité de son énoncé, cette conjecture défie depuis de nombreuses années les mathématiciens. Paul Erdős a dit à propos de la conjecture de Syracuse : .

Dès 1928, Lothar Collatz s'intéressait aux itérations dans les nombres entiers, qu'il représentait au moyen de graphes et d'hypergraphes. Il inventa alors le problème 3x+1, et le présentait souvent ensuite dans ses séminaires. En 1952, lors d'une visite à Hambourg, Collatz expliqua son problème à Helmut Hasse. Ce dernier le diffusa en Amérique à l'université de Syracuse : la suite de Collatz prit alors le nom de « suite de Syracuse ». Entre temps, le mathématicien polonais Stanislas Ulam le répand dans le Laboratoire national de Los Alamos. Dans les années 1960, le problème est repris par le mathématicien Shizuo Kakutani qui le diffuse dans les universités Yale et Chicago.

Cette conjecture mobilisa tant les mathématiciens durant les années 1960, en pleine guerre froide, qu'une plaisanterie courut selon laquelle ce problème faisait partie d'un complot soviétique visant à ralentir la recherche américaine.

La suite de Syracuse d'un nombre entier est définie par récurrence, de la manière suivante :

La conjecture affirme que pour tout , il existe un indice tel que . 

L'observation graphique de la suite pour et pour montre que la suite peut s'élever assez haut avant de retomber. Les graphiques font penser à la chute chaotique d'un grêlon ou bien à la trajectoire d'une feuille emportée par le vent. De cette observation est né tout un vocabulaire imagé : on parlera du vol de la suite.

On définit alors : 

On peut donner de nombreuses formulations équivalentes au problème de Syracuse.
La conjecture de Syracuse est équivalente aux propositions suivantes :

Par exemple, on remarque que si formula_3 est impair dans la formule ci-dessus, formula_4 est nécessairement pair et donc, le pas suivant de la suite doit être une division par deux ; on peut définir une nouvelle version compressée de la suite de Syracuse en combinant ces deux pas de la façon suivante :formula_5

La nouvelle suite est une suite extraite de la version de base, et la conjecture dit que cette suite aboutit toujours au cycle (1,2,1…). 

On peut aussi partir d'un algorithme inverse :

formula_6

Au lieu de prouver que la suite directe, partant de n'importe quel entier naturel non nul, mène toujours à 1, on essaye de démontrer que l'algorithme inverse, partant de 1, est capable de générer tous les nombres entiers naturels non nuls.

Il existe aussi une version compressée de l'algorithme inverse :

formula_7

Ces algorithmes inverses peuvent être représentés par des arbres, dont la racine est 1. Si la conjecture est vraie, ces arbres recouvrent tous les entiers naturels non nuls.

Il existe des arguments heuristiques et statistiques de nature à motiver la conjecture. Considérons par exemple une itération de la suite de Syracuse compressée sur un nombre "v" pris aléatoirement dans un intervalle assez grand. Si "v" est pair, il est multiplié par (1/2), tandis qu'un nombre impair se trouve multiplié par (3/2) environ. Dans les deux cas, on vérifie que la parité du résultat est indépendante de celle de "v". Un raisonnement heuristique consiste à supposer que ce raisonnement probabiliste est valable pour n'importe quel terme de la suite compressée. Bien que ce ne soit pas rigoureux (les termes de la suite ne sont pas aléatoires), certaines observations expérimentales tendent à le confirmer. Ainsi, le modèle obtenu en appliquant cette hypothèse prédit convenablement le temps de vol en altitude de la suite. Avec cette heuristique, on peut dire que statistiquement, l'effet de deux opérations consécutives de la suite revient à multiplier le nombre de départ par (3/4), ou encore que l'opération de Syracuse est contractante, en moyenne, dans un rapport approximativement égal à la racine carrée de (3/4) = 0,866…

Ce rapport nettement inférieur à l'unité suggère fortement que les éléments successifs d'une suite de Syracuse ne peuvent croître indéfiniment. Il n'existe aucune preuve rigoureuse de cette affirmation (et même si l'on parvenait à rendre rigoureux cet argument probabiliste, cela ne permettrait pas encore de conclure, un événement de probabilité infinitésimale n'étant pas pour autant impossible). Également, l'argument ici esquissé n'exclut nullement l'existence de cycles non triviaux. 

Concernant la répartition des nombres qui satisfont à l'hypothèse de Syracuse, par des méthodes élaborées de programmation linéaire on arrive à montrer que, pour formula_8 suffisamment grand, le nombre d'entiers inférieurs à formula_8 qui satisfont l'hypothèse de Syracuse est au moins formula_10 pour certaine constante formula_11. En 2002, I. Krasikov et J. Lagarias obtinrent formula_12 .

Une voie d'exploration intéressante consiste en l'étude systématique du comportement de la suite de Syracuse à l'aide d'ordinateurs, pour des nombres de départ de plus en plus grands. On a ainsi vérifié la conjecture pour tout "N < 1,25×2". La grandeur de ce nombre, de l'ordre de six milliards de milliards, est de nature à renforcer notre croyance en la véracité de la conjecture de Syracuse. Il convient cependant de comprendre qu'aussi loin que l'on poursuive le calcul, il ne peut directement fournir une démonstration de cette conjecture ; le calcul pourrait éventuellement, au contraire, rencontrer un contre-exemple, qui démontrerait la fausseté de la conjecture. Cette approche présente aussi l'intérêt de fournir des résultats numériques utilisables par les théoriciens pour compléter leurs démonstrations. Par exemple, en utilisant la borne N ci-dessus avec un théorèmesur la longueur des cycles de la suite de Syracuse, on peut conclure qu'à part le cycle trivial (1,4,2,1…) il n'existe aucun cycle de longueur inférieure à 17 milliards. 

Les résultats numériques permettent de chercher des corrélations entre le nombre de départ N et la durée de vol, ou le record d'altitude. On a ainsi observé que si les records d'altitude pouvaient être très élevés, la durée du vol était en comparaison plus modeste. Une observation sur les nombres déjà étudiés semble indiquer que l'altitude maximale est majorée par φ(N).N, où φ(N) pourrait être soit une constante, soit une fonction lentement croissante. Le temps de vol est plus erratique mais semble majoré par un multiple du logarithme de N. Les expériences numériques suggèrent ainsi de nouvelles conjectures auxquelles les théoriciens peuvent s'attaquer.

En revanche, la recherche théorique est seule en mesure d'apporter des lumières concernant l'existence de trajectoires infinies : il a été démontré que l'ensemble des nombres appartenant à une telle trajectoire aurait une densité asymptotique nulle ; pour rester dans l'image du vol, on pourrait dire que le grêlon, pour ne pas retomber jusqu'au sol, doit acquérir et maintenir une haute « vitesse de libération ». Si la conjecture est vraie, alors un tel vol infini est impossible.

La relative faiblesse des résultats obtenus en dépit de l'application acharnée de méthodes mathématiques puissantes par des esprits brillants a conduit certains chercheurs à se demander si la conjecture de Syracuse est un problème indécidable. En 1972, John Conway a établi l'indécidabilité algorithmique pour une famille de problèmes qui généralise de manière naturelle le problème 3x+1 (voir l'article sur le langage de programmation exotique FRACTRAN). Ce résultat implique qu'il y a dans la famille considérée des problèmes individuels qui sont indécidables (il est en fait même possible, en théorie sinon en pratique, d'en expliciter un), mais ne résout pas la décidabilité du problème de Syracuse en particulier.





</doc>
<doc id="15636" url="https://fr.wikipedia.org/wiki?curid=15636" title="Liste des souverains de Ceylan">
Liste des souverains de Ceylan

Voici la liste des souverains de Ceylan.

Les sources principales de cette liste de rois proviennent de deux livres mythiques du Bouddhisme Theravada, le Mahavamsa et le Dipavamsa. Ces livres religieux ont souvent été remis en cause pendant la guerre civile, parce que les cingalais s'en servaient pour prouver leur présence sur l'île depuis l'antiquité; alors que les tamouls, d'une grande majorité de confession hindouïste, rejetait ces livres provenant d'une autre religion.

Aussi, ces livres présentent régulièrement des aberrations, comme par exemple dans le Mahavamsa :
- Le premier roi du Sri Lanka, le Prince Vijaya, serait le petit-fils d'un lion. Néanmoins, les traces de l’existence du Roi Vijaya sont retranscrite dans les écrits de voyage du moine chinois Xuanzang, et des peintures représentant son couronnement ont été retrouvé dans les grottes d'Ajantâ en Inde.
- L'armée de Vijaya a du faire face à une armée d'esprits, les Yaksha.

La chronologie de la liste ci-dessous est basée sur le système traditionnel sri lankais, basé sur le Calendrier bouddhiste, celui-ci commence sur l'an -543 ou -544.

De plus, ce calendrier étant luni-solaire, les mois durent 29 à 30 jours, ce qui revient à une année à 354 jours, en opposition avec les calendriers solaires contenant 365,25 jours. Pour corriger ce décalage, ce calendrier rajoute 11 jours tous les 57 ans, et 7 mois de 30 jours tous les 19 ans.

Due à ces différences de calendrier, plusieurs dates ne sont pas précises, et les dates après l'an 1548 sont synchrones.





























Dynastie parallèle fondée par un frère de Bhuvanaikabâhu VII



En 1796, les Britanniques prennent le contrôle de toute l'île, et mettent fin à 2 millénaires de monarchie.





</doc>
<doc id="15640" url="https://fr.wikipedia.org/wiki?curid=15640" title="IRM">
IRM

IRM est un sigle pouvant faire référence à :

IRM est aussi un code qui correspond :

IRM est le titre d'un album de Charlotte Gainsbourg, sorti en 2009.


</doc>
<doc id="15645" url="https://fr.wikipedia.org/wiki?curid=15645" title="Énantiomérie">
Énantiomérie

L’énantiomérie est une propriété de certaines molécules stéréoisomères, dont deux des isomères sont l'image l'un de l'autre dans un miroir plan, mais ne sont pas superposables. Une molécule ayant deux énantiomères est dite chirale. En revanche si une molécule est identique à sa propre image dans un miroir, elle est dite achirale. La chiralité peut être due :

Dans le cas d'un centre stéréogène, la configuration autour de ce centre est indiquée par les lettres "R" ou "S", selon les règles de la nomenclature Cahn-Ingold-Prelog. Dans le cas d'une chiralité de type hélicoïdale, la est souvent utilisée.

Chimiquement, deux énantiomères ont des réactivités identiques avec d'autres molécules non chirales. Ils ont les mêmes propriétés physiques et un pouvoir rotatoire opposé.

Au niveau biologique, les deux énantiomères d'une molécule, un médicament par exemple, peuvent avoir des effets physiologiques différents, voire antagoniques. Cela s'explique par le fait que les systèmes biologiques dépendent directement de la forme de la molécule. Ils sont eux-mêmes énantiopurs et interagissent différemment avec les deux énantiomères d'un centre chiral externe, où les interactions sont diastéréomériques. 

Les relations entre les activités biologiques de chaque stéréoisomère pur et celles de leurs mélanges sont souvent très complexes et leur analyse nécessite des études approfondies et détaillées. Cependant, il arrive que deux énantiomères aient des activités similaires au niveau biologique. 

Un exemple tragique d'effets différents de deux deux énantiomères est celui de la thalidomide. Cette substance utilisée dans différents médicaments possède en effet deux énantiomères dont l'un a des effets sédatifs et anti-nauséux (notamment chez la personne enceinte), tandis que l'autre a des effets tératogènes. L'utilisation de la thalidomide a donné lieu à un important scandale sanitaire au début des années 1960. On dénombre en effet entre et .

L'analyse et la séparation des énantiomères (qui forment la structure spatiale et fonctionnelle de notre environnement biotique et abiotique) sont capitales pour l'avancée des recherches dans la plupart des domaines scientifiques. 

Près des 2/3 des molécules biologiquement actives chirales issues de synthèse classique (non énantiosélective) proviennent de dédoublements (séparation d'énantiomères), qui représente l'une des principales voies d'accès aux composés énantiomériquement purs. La production des produits énantiopurs représentait aux États-Unis, en 1995, la somme colossale de près de de dollars.

Pour ces molécules, on appelle dans le vocabulaire pharmaceutique « eutomère » l'énantiomère le plus actif quant à l'effet recherché, l'autre étant appelé « distomère ». Ce dernier peut être moins actif, inactif, ou avoir un effet totalement différent, éventuellement indésirable. Dans le meilleur des cas c'est une charge que le foie devra métaboliser en plus du principe actif. Il arrive parfois que chaque énantiomère ait un intérêt pharmaceutique : par exemple le propoxyphène-(R) est un analgésique, commercialisé sous le nom de Darvon, et son énantiomère-(S) est un antitussif, vendu sous le nom en miroir de Novrad.

Il existe trois sortes de nomenclature permettant de différencier les énantiomères : .
Les règles apparaissent à la page Chiralité.

Pour une molécule donnée, il existe au maximum 2 isomères optiques pour un composé avec n centres stéréogènes, car il faut également tenir compte du fait que l'on puisse, lors de la recherche d'isomères optiques, trouver deux, trois, voire quatre fois le même stéréoisomère.

Le premier exemple de résolution chirale (séparation d'énantiomères) est celui de Louis Pasteur qui, en 1848, isola les deux énantiomères de l'acide tartrique par tri manuel de cristaux énantiomorphes.

De nouvelles techniques et méthodes effectuant le dédoublement des racémates sont depuis apparues 

Ces méthodes font appel aux diastéréoisomères, préparés à partir de racémiques par formation de sels ou par dérivation avec des composés énantiopurs, puis séparés par cristallisation ou chromatographie, ou par transformations stéréosélectives. 

Plusieurs méthodes chromatographiques sont utilisées pour la séparation chirale d'une large variété de composés. Dans ce processus, les positions de l'équilibre entre les états liés et non liés sont différentes pour les deux énantiomères. Ceci est la base de la séparation.

L'utilisation d'une colonne à phase stationnaire chirale ou d'additifs chiraux dans la phase mobile est une voie plus « élégante » de séparation des énantiomères que par synthèse de composés diastéréoisomères à l'aide d'un réactif optiquement pur. Parmi les approches permettant l'obtention de substances optiquement pures, la chromatographie en phase supercritique (SFC) est de loin la méthode la plus utilisée pour la discrimination des énantiomères. Les cyclodextrines, notamment, sont des phases stationnaires chirales utilisées aussi en séparation énantiomérique par d'autres méthodes telles que l'électrophorèse capillaire, la CPG et l'HPLC. Elles sont aussi employées en résonance magnétique nucléaire (RMN) comme auxiliaires chiraux pour la détermination d'excès énantiomérique. La formation des composés d'inclusion et ses applications en séparation chirale sont mises à profit dans le domaine, mais aussi dans les industries chimiques et agroalimentaires (cas du menthol ou de la mélisse).

Ces méthodes consistent à utiliser des enzymes qui sont des composés qui catalysent des transformations stéréospécifiques. Par exemple pour séparer les deux énantiomères du 1,1'-bi-2-naphtol, une méthode consiste à le faire réagir avec du chlorure de pentanoyle, le chlorure de l'acide pentanoïque (CH(CH)COCl), pour former le di-ester. L'enzyme cholestérol estérase est alors introduite sous forme de poudre acétonique de pancréas bovin qui est capable d'hydrolyser le di-ester ("S") mais pas le di-ester ("R"). Le dipropanoate (R) est hydrolysé dans une seconde étape avec le méthoxyde de sodium (CHONa).




</doc>
<doc id="15646" url="https://fr.wikipedia.org/wiki?curid=15646" title="Chromatographie en phase liquide">
Chromatographie en phase liquide

La chromatographie en phase liquide (CPL) ou "liquid chromatography" (LC) est une technique d'analyse quantitative, qualitative et séparative principalement utilisée dans le domaine de la chimie analytique comme outil scientifique majeur mais aussi dans des domaines variés tels que la chimie organique et la biochimie. Elle recouvre la chromatographie sur couche mince (CCM), la chromatographie sur papier, la chromatographie en phase liquide en colonne ouverte ou à basse pression, et la chromatographie en phase liquide à haute performance (HPLC).
Ce type de chromatographie repose sur la séparation de composés entraînés par un liquide ("phase mobile") à travers un solide divisé ("phase stationnaire") qui est soit placé dans un tube ("colonne chromatographique") , soit fixé sur une surface inerte.
La séparation s'opère suivant les interactions chimiques ou physiques des analytes avec la phase mobile ainsi qu'avec la phase stationnaire. 

Ils sont classés ici selon les interactions des analytes avec la phase stationnaire.

Dans cette chromatographie, la phase stationnaire consiste en une matière solide à grand pouvoir d'adsorption, tel que l'oxyde d'aluminium, les silicates de magnésium, les gels de silice. Les composants sont simplement plus ou moins retenus à la surface de la phase stationnaire par adsorption physique. C'est une technique qui prend en compte la polarité des composants.

Dans cette chromatographie les analytes sont séparés en fonction de leur affinité avec les phases stationnaire et mobile. L'affinité dépend de la polarité des analytes et des phases. En mode normal la phase stationnaire est polaire, en mode inverse elle est apolaire. Il y a deux types de chromatographie de partage :

La phase solide est une résine insoluble munie de groupes fonctionnels capable de se dissocier. Ce sont, habituellement, des groupes "acide sulfonique" (SOH) pour les échangeurs de cations et "ammonium quaternaire" (N(R)) pour les échangeurs d'anions.

Appelée aussi "chromatographie à perméation de gel", cette technique consiste en séparer les composants selon leur dimension moléculaire. La phase stationnaire est composée d'un matériau poreux (petites particules de silice ou de polymères), les molécules dont le diamètre est supérieur à celui des pores ne peuvent pénétrer et ne sont pas retenues. La durée de séjour dans la colonne augmente lorsque la taille des analytes diminue.

La chromatographie de paires d’ions (en anglais "ion pair chromatography") est utilisée pour séparer et analyser des ions. Ces ions forment une paires d’ions à l’aide d’un contre-ion qui possède une ou des chaînes alkyles. Par la présence de ces chaînes alkyles, le contre-ion a une affinité avec les molécules hydrophobes. Ces contre-ions sont généralement du tétraalkylammonium pour des analytes à charge négative (acides) ou de l’alkylsufonate pour des analytes à charge positive (bases). La longueur de chaîne l’alkyle est importante en chromatographie de paires d’ions. Elles influencent le ratio de contre-ions dans la phase stationnaire versus la phase mobile. La concentration en contre-ions est plus importante si la chaîne alkyle est plus longue, ceci peut être expliqué par le fait que le caractère hydrophobe du contre-ion et de la paire d’ions est plus grand lorsque la chaîne alkyle est longue, donc le contre-ion se liera plus facilement à la phase stationnaire .
Il existe donc deux types de chromatographie de paires d’ions : 

La phase stationnaire(ou solide) est composée de silice greffée par des chaînes alkyles. La phase stationnaire est alors apolaire, ce qui ne retient aucunement les ions qui ne possèdent pas de zone apolaire et c’est pourquoi la présence de contre-ions apolaire est nécessaire pour la rétention de l’analyte. Par contre, il est possible que l’analyte possède une chaîne alkyle, ce qui permet à l’analyte à être retenu, mais pour augmenter leur rétention il est avantageux d’ajouter le contre-ion, puisque le contre-ion peut avoir une meilleure affinité avec la phase stationnaire, ce qui permet une meilleure séparation.

La phase mobile est généralement composée d’un mélange d’eau (solvant A) et d’acétonitrile ou de méthanol (solvant B). La phase mobile contient aussi le contre-ion utilisé. Le pourcentage volumique en acétonitrile ou en méthanol dans la phase mobile (%B) est importante, parce qu’elle influence la solubilité du contre-ion. Plus la concentration du solvant B (acétonitrile ou méthanol) est élevé, plus le contre-ion sera présent dans la phase mobile, donc il sera moins présent dans la phase stationnaire. En addition, la longueur de la chaîne carbonée fait augmenter la concentration de celui-ci dans la phase stationnaire, donc plus la longueur de la chaîne est grande moins le contre-ion sera présent dans la phase mobile. De plus, le type de chromatographie doit être aussi tamponné. En effet, la préparation de la phase mobile doit être à pH contrôlé.

La concentration du contre-ion a une influence directe sur le facteur de rétention k du soluté. Plus la concentration du contre-ion augmente, plus le facteur de rétention "k" augmente. L’agencement de la molécule a une influence sur la rétention, plus la chaîne alkyle est substituée et plus le caractère hydrophobe de la molécule est important et donc la rétention augmente. La longueur de la chaine carbonée agit aussi sur le facteur de rétention. Le facteur k peut être modifié en agissant sur la composition de la phase mobile, c’est-à-dire en agissant directement sur la fraction volumique du contre ion dans le solvant. 

Le pH permet aux molécules d’être complètement ionisées, ce qui fait que le pH est un facteur très important pour effectuer une chromatographie de paires d’ions. En ce qui concerne les acides, le pH de la solution doit être supérieur ou égale au pKA+2 du couple A-/HA et cela permet à cette espèce d’être à 99% sous forme d’anion. Tandis que pour les bases le pH doit être inférieur ou égale au pKA-2 du couple HB+/B (dans cette section B représente une base), ce qui fait un ratio de 99:1 de HB+ par rapport à B. Pour ce faire l’éluant est tamponné à l’aide d’un acide ou d’une base qui ne réagit pas avec la silice ou l’analyte.

En chromatographie de paires d’ions, des ions secondaires peuvent se former lors de l’augmentation de la force ionique et donc réduit la formation des paires d’ions que l’on veut former. On peut en conclure que la rétention diminue avec l’augmentation de la force ionique.

 Un avantage de cette technique est qu’il est possible d’analyser des espèces neutres en même temps que des espèces ioniques puisque la méthode expérimentale de cette chromatographie est similaire à celle de la chromatographie liquide inverse. Cette technique permet d’augmenter le temps de rétention pour les molécules ioniques, donc il est possible d’avoir une meilleure résolution entre deux molécules, surtout lorsqu’il est possible d’en avoir une seule ionique. Un des inconvénients majeurs est que la silice greffée ne peut pas être utilisé à un pH supérieur à 7,5, donc cela détermine la limite de la chromatographie par paires d’ions.

Dans le cas de la CLHP, une (élution isocratique) ou plusieurs (élution par gradient) pompes sont utilisées pour la circulation de la phase dite "mobile", c'est-à-dire le liquide circulant dans le système chromatographique. Des tubes en acier inoxydable, en Teflon, en PEEK ou en silice fondue permettent de relier la ou les pompes à l'injecteur chromatographique.

La phase mobile est souvent composée de plusieurs solvants (méthanol, acétonitrile, eau...) et de sels (tampons, réactif ionique...). Ces solvants doivent être dégazés (par barbotage de gaz neutre dans les réservoirs de phase mobile ou par dégazeurs en ligne) afin d'en retirer l'air dissous qui pourrait former des bulles. Celles-ci peuvent gêner la progression du liquide dans les tubes (mauvais débits) et créer des faux pics ou artéfacts au niveau du détecteur. Dans une élution avec deux pompes, un mélangeur est aussi nécessaire afin d'obtenir une phase mobile homogène.

Après l'injecteur, est placée une colonne chromatographique (cylindre rempli par la phase stationnaire) qui permet la séparation. La colonne est suivie d'un détecteur chromatographique (spectroscopie UV-visible, barrette de diode, fluorimètre, réfractomètre, chimique, ...). Un ordinateur complète le plus souvent ce dispositif, pour la commande du système chromatographique, ainsi que l'acquisition et le traitement des données.

L'analyse LC met en œuvre plusieurs étapes :

En CLHP, l'opérateur ayant une solution à analyser, la prépare dans un mélange similaire à celui circulant dans le système. Il introduit une faible quantité de ce mélange dans une boucle d'injection afin d'éviter les phénomènes de Band broadening, puis commence l'acquisition. La boucle est alors reliée dans l'injecteur au reste du système, provoquant le passage des molécules jusqu'en tête de colonne chromatographique. Cette colonne, choisie parmi la très large gamme commerciale, est remplie d'une phase stationnaire, qui permettra de séparer les molécules chimiques en fonction de certaines de leurs propriétés respectives (taille, polarité, hydrophilie, affinité, contenu en métaux...). Les molécules sortiront ainsi de la colonne à différents temps appelés "temps de rétention", suivant leurs interactions avec la phase stationnaire et la phase mobile, et seront détectées, par le détecteur, là aussi, en fonction de certaines de leurs propriétés.

De nos jours, ces techniques simples sont utilisées en relation avec des appareils de détection et de reconnaissance des molécules plus puissants (MS (spectrométrie de masse), RMN (Résonance magnétique nucléaire) entre autres).



</doc>
<doc id="15647" url="https://fr.wikipedia.org/wiki?curid=15647" title="In Nomine Satanis - Magna Veritas">
In Nomine Satanis - Magna Veritas

In Nomine Satanis - Magna Veritas (INS - MV) est un jeu de rôle français fantastique et humoristique publié en 1990. Dans "In Nomine Satanis", les joueurs incarnent un groupe de démons, chacun aux ordres d'un prince-démon. Dans "Magna Veritas", ils incarnent un groupe d'anges, chacun aux ordres d'un archange. Dans les deux cas, ils sont incarnés dans des corps humains de nos jours, et doivent faire attention à ne pas se faire remarquer par les humains. L'ambiance est généralement à prendre au second degré.

"INS/MV" a connu quatre éditions ; la dernière est sortie en juin 2003. La quatrième édition se présente sous la forme d'un fourreau en carton rouge illustré contenant trois livres ; l'un contient les règles, les deux autres sont voués au background et aux scénarios pour les anges et pour les démons. Ce jeu proposé par Croc (même si l'idée originelle ne provient pas de lui mais d'un ancien groupe d'amis) et Mathias Twardowski est édité par Siroz, une marque d'Asmodée. Il a été traduit en allemand, espagnol et polonais, et a vu une adaptation américaine nommée "In Nomine". Cette adaptation a subi de nombreuses modifications par rapport à l'originale, et certains rôlistes la voient comme une version édulcorée.

Après 17 ans d'existence (un âge exceptionnel pour un jeu de rôle de création française), Asmodée annonce l'arrêt des publications d'INS/MV. En novembre 2006, le supplément "On ferme !", qui clôt les nombreuses intrigues encore en suspens, termine l'édition du jeu.

À noter qu'un supplément « posthume » mais néanmoins officiel, "INS/MV Apéro", fournit une version remaniée et allégée des règles de la quatrième édition pour des parties rapides.

En 2011, Croc annonce sur plusieurs forum de jeux qu'une cinquième édition "est en préparation et devrait sortir courant 2012". La sortie est aujourd'hui planifiée pour 2015 par le biais d'un financement participatif, chez l'éditeur Raise Dead Éditions, créé dans le but de proposer des rééditions des jeux de Croc.

Par défaut, les personnages-joueurs jouent chacun un ange ou un démon. Ceux-ci sont incarnés dans des corps humains de nos jours. Les anges s'incarnent dans le corps d'un humain consentant, et les démons dans le corps d'un humain qui vient de décéder. La seule chose qui, extérieurement, les différencie d'un humain normal est leurs différents pouvoirs. Ils possèdent aussi souvent une ou plusieurs limitations ou blâmes, qui sont des manifestations physiques ou psychiques de leur nature surnaturelle. Par exemple, un démon pourrait ainsi avoir une queue qui pousse entre les fesses, tandis qu'un ange pourrait voir interdit tout contact avec une personne du sexe opposé.

Chaque ange est au service d'un archange, parmi une vingtaine différents. De même, chaque démon est au service d'un prince-démon, parmi une trentaine différents. Chaque supérieur octroie à ses serviteurs des pouvoirs spécifiques, et lui donne un certain genre. Par exemple, Laurent, Archange de l'Epée, donne souvent aux anges à son service des capacités de combat et de commandement. Ses anges auront souvent une apparence paramilitaire et auront tendance à voter à droite. Au contraire, Novalis, Archange des Fleurs, accorde à ses anges des pouvoirs permettant de calmer les humains. Ces anges-là seront souvent habillés en hippies et proclameront des idées telles que la paix, l'amour. Les mêmes différences existent parmi les démons. Dans la première édition, il y avait une seule "vraie" religion, défendue par les forces du Bien : le catholicisme. Puis des archanges et des princes-démons musulmans sont apparus. Il arrive que les archanges musulmans ne s'entendent pas parfaitement avec leurs homologues chrétiens... 

Cependant chaque ange ou démon est unique et rien ne l'oblige à coller totalement à son supérieur.

Chaque ange ou démon dispose de pouvoirs surnaturels tels que "jets de flammes" ou "télépathie". Ces pouvoirs sont néanmoins à utiliser avec parcimonie, tout d'abord car on doit dépenser des "points de pouvoir", et ensuite car les humains ne doivent jamais suspecter la présence sur Terre d'êtres surnaturels.

Les suppléments "Berserker" et "Mindstorm" pour la première édition, puis "Les Petites apocalypses" pour la quatrième, proposent de jouer des membres de la Troisième Force plutôt que des anges ou des démons. La Troisième Force est composée de héros païens réincarnés, d'humains dotés de pouvoirs psioniques, d'humains pratiquant la sorcellerie, d'anges ou démons renégats, et de diverses créatures magiques, bref de tous les êtres surnaturels qui n'appartiennent ni aux forces du Bien ni à celles du Mal.

"INS/MV" se déroule dans le monde que nous connaissons, mais avec l'ajout de créatures surnaturelles cachées parmi les humains. Plusieurs événements de notre histoire réelle sont, dans "INS/MV", liés aux machinations des différentes factions du grand jeu. Peu décrit dans les livres de base de la première édition, l'univers d"'INS/MV" et son histoire ont été développés au fur et à mesure, en particulier dans le supplément "Heaven & Hell".

Au-delà de l'univers que nous connaissons, l'univers est composé de différents plans parallèles ou marches intermédiaires. Elles sont généralement décrites par les auteurs du jeu comme les étages d'un gratte-ciel. Dans "New World Order" apparaissent les ley lines, des sortes de câbles qui relient les marches entre elles, mais ces ley lines sont de moins en moins apparues dans des suppléments ultérieurs.

Tout en haut de l'immeuble, il y a la marche du Paradis. Tout en bas se trouve l'Enfer. Au rez-de-chaussée, il y a le Purgatoire, à égale distance du Paradis et de l'Enfer, et à l'entresol se situe la marche terrestre. Une autre marche importante est la marche des rêves et des cauchemars ou MRC, qui a tendance à se déplacer. 

Il existe aussi des marches moins importantes, comme les marches des différents panthéons païens (Asgard pour les dieux Vikings, Tír na nÓg pour les Celtes, New Olympus pour les Gréco-Romains, et Héliopolis pour les Égyptiens) ou bien la marche des fées. Certaines créatures très puissantes, surtout le prince-démon Beleth et l'archange Blandine, ont aménagé quelques marches en univers de poche. Le plus connu est la marche du Gothic Horror, un monde créé par Beleth en s'inspirant des romans d'horreur gothique.

L'univers d"'INS/MV" a été créé par Dieu il y a plusieurs milliards d'années. Dieu a ensuite créé Yves, le premier archange de puissance, puis le Paradis et les autres anges de puissance, qui étaient les futurs archanges et princes-démons. Il a enfin créé les anges, puis s'est reposé.

À l'apparition des dinosaures, Dieu envoya les anges de puissance Dominique et Andromalius les évangéliser et leur fournit un prophète nommé Denver, que les deux frères ont fait se crucifier pour impressionner les autres dinosaures. Mais les dinosaures étaient trop stupides pour être convertis, et Dieu a choisi de les détruire pour effacer ce fiasco.

Mais les premiers hommes ont fasciné plusieurs anges, surtout Samaël alias Lucifer. Ce charismatique ange de puissance y voyait une espèce libre, dotée d'une grande intelligence. Son seul défaut, c'était qu'elle était particulièrement fragile. Il eut alors une idée : permettre aux archanges, qui étaient forts mais qui n'avaient aucune liberté, de se reproduire avec les humains pour les rendre résistants et donc parfaits. Il soumit cette idée à Dieu lors d'un grand conseil rassemblant tous les premiers-nés. Mais sa proposition fut violemment rejetée par Dieu, ce qui l'ébranla fortement ; c'était en effet la première fois que Dieu lui refusait quelque chose.

Il décida donc de passer outre et de descendre sur Terre sans l'aval de Dieu avec d'autres anges qui avaient adhéré à ses idées. De leurs unions avec les humains naquirent une race de géants, les nephilim. Mais Dieu n'allait pas laisser passer cela. Il réunit un second conseil extraordinaire et demanda à Samaël de s'excuser. Celui-ci refusa et une guerre éclata dans la Cité éternelle. D'un côté Samaël et ses suivants, de l'autre les armées de Dieu. Au milieu de la bataille, Dieu projeta Samaël à travers les marches, accompagné de ceux qui l'avaient soutenu.

Et ils tombèrent jusqu'à la dernière marche, blessés par la chute et la distance qui les séparait de la puissance divine qui les avait créés. Ils décidèrent de changer de nom pour marquer ce passage à une nouvelle existence. Samaël se fit alors appeler Satan. Il construisit dans cette marche l'Enfer et la cité de Dis en sept ans là où Dieu avait mis sept jours à créer l'univers.

Commença alors une guerre, qui dure encore aujourd'hui, où les forces du Bien et celles du Mal s'affrontent pour conquérir l'âme de l'Homme.

Vers l'an -6000, Dieu a fait une expérience, en créant le Jardin d'Éden, un lieu protégé du danger et de l'influence de la société humaine, et en y plaçant un couple d'humains dont il avait modifié les gênes pour leur donner des pouvoirs. Il voulait voir ce que donnaient des humains qui ne seraient pas influencés par la société. Mais l'expérience tourna court quand Satan fit succomber Ève à la tentation. Dieu relâcha alors le couple parmi les autres hommes, avec lesquels ils se mélangèrent. Les descendants d'Adam et Ève ont conservé une partie de leurs pouvoirs et sont maintenant appelés les psis.

La guerre entre Enfer et Paradis continuait, de façon assez frontale : épées contre épées, etc. Mais Jésus, un ange de puissance qui avait toujours été le favori de Dieu, s'incarna sur Terre au dans le corps d'un nourrisson, afin d'apporter le message divin aux hommes. Cette tentative, qui finit avec sa crucifixion eut beaucoup plus de succès que les précédentes. Elle donna aussi une nouvelle idée à Dieu : rendre la guerre contre l'Enfer plus discrète et réglementée. Ce conflit prit le nom de « Grand Jeu ». Les grandes mesures qui apparurent furent, entre autres, l'instauration du principe de discrétion, qui veut que l'existence des anges et démons soit cachée aux humains, et l'incarnation des anges et des démons dans des corps humains.

Cette dernière phase du Grand Jeu vit plusieurs événements importants. Les dieux païens étaient apparus pendant l'antiquité, formés par les rêves des humains ou, selon le supplément "Sur la Terre comme au Ciel", par des psis qui avaient récupéré des morceaux de la pomme du Jardin d'Éden. Mais la montée en puissance du christianisme, ainsi que les combats musclés entre démons et païens, ont porté des coups sévères aux panthéons païens qui ont perdu l'essentiel de leur puissance depuis. Dans le même temps, les fées et les dragons, des créatures d'origine inconnue, furent exterminées par l'archange Georges, qui fut mis à la retraite pour cette raison.

L'essor de l'Islam au est interprété, dans "INS/MV", par le départ de trois anges puissants, Eli, Hassan et Khalid, qui, menés par l'archange Gabriel, voulaient réformer la chrétienté en croyant avoir le feu vert de Dieu. Au lieu de cela, Gabriel a disparu et les trois nouveaux archanges se sont retrouvés en conflit ouvert avec la chrétienté, conflit dont l'apogée fut un duel entre Khalid et l'archange Laurent à la bataille de Poitiers. L'enfer a, de son côté, infiltré cette religion en y dédiant deux nouveaux princes-démons, Dajjâl et Majûj.

INS/MV est, selon ses auteurs, fait pour être joué avec humour et un certain second degré. Cet humour permet au jeu de ne pas être toujours politiquement correct. Une partie de cet humour vient de ce que le jeu exploite un événement de l'histoire réelle pour en faire une base de scénario. Que se passerait-il par exemple si un ange particulièrement crétin et fanatique réagissait violemment à la victoire d'un "transsexuel déicide" au concours Eurovision de la chanson ? Et si un prince-démon musulman était spécialisé dans le détournement d'avions ? Les grands de ce monde sont-ils manipulés? Par un ou plusieurs camps ?

Malgré le thème du jeu, les auteurs tentent d'éviter de tomber dans le manichéisme. Ainsi certains anges méprisent les humains, tandis que certains démons peuvent s'attacher à eux. Certains skinheads fanatisés, enrôlés comme force de frappe par les forces du Bien, ne sont pas forcément de bonne compagnie. Les différents archanges et princes-démons n'étant pas d'accord sur la meilleure façon de faire le Bien ou le Mal, les luttes internes (violences ou magouilles) sont fréquentes dans les deux camps.

Dès la première édition, le jeu INS/MV a employé un système de jeu unique. Pour résoudre une action, on emploie la "Table Unique Multiple". Ce tableau à double entrée donne le nombre à obtenir pour réussir l'action, en fonction de la compétence du personnage et de la difficulté de l'action. Ensuite on lance un "dé 666", composé de trois dés à six faces, qui forment à eux trois un nombre à trois chiffres. Les chiffres des centaines et des dizaines établissent l'échec ou la réussite de l'action, tandis que le chiffre des unités donne l'ampleur de la réussite ou de l'échec.

Il existe deux résultats spéciaux : un "111" représente une intervention de Dieu, et est donc une réussite critique pour un ange et un échec critique pour un démon. Inversement, un "666", le nombre de la bête, représente une intervention de Satan, et est donc une réussite critique pour un démon et un échec critique pour un ange. Ces critiques ont souvent un effet humoristique.

La quatrième édition a transformé la Table Unique Multiple en "Ligne Unique Multiple" (surnommée "la belle LN") mais son emploi est très similaire.

Seule la version des règles dénommée INS Apero s'écarte des règles historiques. Il conserve néanmoins le principe du lancer de trois dés à six faces. C'est le plus petit dé qui détermine le résultat final. Les interventions divine et satanique sont elles aussi conservées.

La V5 possède aussi son propre système. On conserve toujours un triple lancer de D6 mais à présent, on ne conserve que les dés inférieurs à la caractéristique associée au test. Une réussite pour les test faciles, deux pour les moyens et trois pour les difficiles. Les 111 et 666 sont toujours des échecs/réussites critiques bien que Dieu et Satan semblent absents.





En novembre 2006, Olivier Fanton, l'un des auteurs du jeu et notamment du livre de règles de la , met en ligne gratuitement sur son site une version plus simple des règles, appelée "INS/MV Apéro".

Pour réussir une action, on ajoute le plus petit résultat de trois d6 au score de la caractéristique, du talent ou du pouvoir testé. Il faut faire plus que la difficulté ou que le résultat de l'adversaire.
Avec ce principe, la Table unique multiple et la Ligne unique multiple des éditions précédentes sont délaissées mais le d666 est toujours utilisé.

On note aussi une simplification au niveau des pouvoirs, chacun coutant un point pour être lancé, les attaques infligeant « niveau » point de dégâts et les défenses réduisant « niveau » point de dégâts.

Bien que le livre de base couvre la création de personnage et toutes les mécaniques de jeu (jets de caractéristique, combat etc), "INS/MV Apéro" ne se destine pas aux nouveaux joueurs car les pouvoirs ainsi que les supérieurs (Archanges et Princes-Démons) ne sont pas explicités et qu'il ne comporte aucun élément sur l'histoire et l'univers du jeu.
On peut cependant placer cette version "Apéro" lors de la quatrième édition, car la liste des supérieurs correspond à celle-ci, avant les évènements des derniers suppléments tels que "Fire & Ice", "Jésus reviens !", "Les Petites Apocalypses" ou "La Bible à Dudule".

Après plus de 7 ans, une cinquième édition du jeu a été annoncée par Croc sur divers forums de jeux de société ou de jeux de rôles tel que Casus NO ou Tric Trac. Début 2015, des anciens de Siroz, Jeux Descartes et Asmodée créent une nouvelle structure, Raise Dead Édition, dont "In Nomine Satanis/Magna Veritas" sera la première publication.

Après 4 ans de travail, deux parties en avant-première de "INS/MV" 5 ont été jouées lors de l'Asmoday 2011 (évènement promotionnel de l'éditeur), la V5 a vu le jour automne 2015.

Bien que le principe de base reste le même (des Anges et des Démons qui complotent et se battent sur Terre à l'insu des humains), les règles sont complètement remaniées et l'univers totalement remis à zéro. La hiérarchie n'existe plus et seul huit archanges et huit princes démons sont jouables. Les regles, simplifiées pour un jeu plus rapide et aisé, tiennent dans un livre unique qui fait la part belle aux nouvelles mais ne donne aucun élément d'information sur le background du jeu, en lien avec la ligne de conduite actuelle : vous êtes seuls et sans soutien.
Les extensions sortent sous un format défini, le "Faits Divins", sorte de magazine à scandales détourné.




</doc>
<doc id="15649" url="https://fr.wikipedia.org/wiki?curid=15649" title="GPC">
GPC

GPC est un sigle qui peut signifier :

</doc>
<doc id="15658" url="https://fr.wikipedia.org/wiki?curid=15658" title="Gustaaf Willem baron van Imhoff">
Gustaaf Willem baron van Imhoff

Gustaaf Willem baron van Imhoff (né le à Leer - mort le à Batavia) fut gouverneur du Ceylan néerlandais puis des Indes Néerlandaises (l'Indonésie actuelle) pour la Compagnie néerlandaise des Indes orientales (VOC).

Il était issue d'une famille noble de Frise orientale. Son père était Wilhelm Heinrich Freiherr von Imhoff de la ville de Leer, en Allemagne, à quelques kilomètres de la frontière actuelle avec les Pays-Bas.

Il entra au service de la Compagnie en 1725 à Batavia (l'actuelle Jakarta) et obtint plusieurs promotions avant de devenir gouverneur de la colonie de la Compagnie à Ceylan en succédant à Jan Macaré le .

Il mit un terme à la situation chaotique sur l'île. Il établit une relation constructive avec le roi de Kandy Vira Narendra Sinha. Parmi les gouverneurs néerlandais, van Imhoff fut l'un des plus attachés au progrès. Par exemple, il introduisit les noix de coco et la presse sur l'île.

Le roi Narendra était marié avec une princesse de Madurai, et son fils Sri Vijaya Rajsimha qui lui succéda à sa mort le était considéré plutôt comme un (Tamoul) que comme un Cinghalais (l'ethnie principale). Imhoff s'inquiétait au sujet de cette succession parce que des contacts plus étroits de l'île avec le sud de l'Inde pouvaient menacer le monopole commercial de la compagnie. Dans ses lettres, il exprime sa surprise de constater que les Sinhala acceptent un tel roi, . Aussi il voit dans cette situation une occasion. Il propose aux XVII Messieurs, les dirigeants de la compagnie, de chercher à diviser le royaume, mais les XVII rejettent la proposition : une guerre serait trop chère.

Malgré la production d'épices qui était très profitable, la colonie était toujours en déficit parce que les profits étaient attribués à la compagnie en général, pas à la colonie. Cette pratique évitait aux gouverneurs la tentation d'un trop grand faste, comme on avait pu l'observer à Goa.

Le 12 mars 1740, Willem Maurits Bruyninck le remplaça comme gouverneur et Imhoff regagna Batavia, où il découvrit une situation très pénible. Le Gouverneur-Général Vackenier trouvait la population chinoises des environs de la ville trop grande. Il essaya de les envoyer à Ceylan et en Afrique du Sud, mais une rumeur prétendant qu'ils allaient être jetés en pleine mer déclencha une insurrection. Vackenier la réprima par un massacre qui fit environ cinq mille victimes et Imhoff contesta sa politique brutale. Il fut arrêté et renvoyé en Hollande. Là, les XVII Messieurs le nommèrent Gouverneur-Général en remplacement de Valckenier.

En route vers Batavia, Imhoff visita Le Cap en Afrique au Sud, où il
découvrit que les citoyens néerlandais pénétraient de plus en plus à l'intérieur du pays et perdaient contact avec la compagnie. Il proposa d'améliorer l'éducation et le travail de l'église protestante.

Au mois de mai 1743, il prit ses fonctions à Batavia, qu'il retrouvait en pleine guerre. Les princes de Java avait tiré profit du chaos pour lancer une guerre contre la compagnie. Imhoff réussit à rétablir la paix et commença ses réformes. Il créa une école latine, les premières postes aux Indes néerlandaises, un hôpital et un journal. Il fonda Buitenzorg (Bogor) et supprima le trafic d'opium. Il fit en 1746 une tournée d'inspection de tout le territoire de Java et décida de réformes institutionnelles.

Malheureusement, il y eut aussi des catastrophes. Un navire, le "Hofwegen", fut frappé par la foudre et explosa dans le port de Batavia avec entre autres d'argent. La perte fut énorme, six cent mille florins.

La politique progressiste d'Imhoff lui attira beaucoup d'ennemis, surtout lorsque, par son manque de diplomatie et de respect pour les coutumes locales, la colonie fut entraînée dans la Troisième Guerre de succession javanaise. Mis dans une position intenable par ses ennemis, il voulut démissionner mais la VOC ne le lui permit pas. Il dut ainsi rester en poste jusqu'à sa mort en 1750, et constater que le plus gros de son travail avait été vain.




</doc>
<doc id="15661" url="https://fr.wikipedia.org/wiki?curid=15661" title="Cuisine hongroise">
Cuisine hongroise

La cuisine hongroise fait référence à une tradition gastronomique originaire de Hongrie, partagée par les habitants du pays et les minorités magyares vivant en Slovaquie, Ukraine, Roumanie et Serbie. Utilisant les mêmes ingrédients que la plupart des cuisines d'Europe centrale (chou et de nombreuses variétés de tubercules, bœuf, porc, volaille), elle se distingue par une forte influence orientale (turque et balkanique) et l'utilisation privilégiée de poudre de paprika, sous forme de légume ou poivron. Elle est également inspiratrice de nombreux plats de la cuisine juive ashkénaze.

De ces ingrédients sont préparés de nombreux plats de viande épicés (pörkölt, paprikás, fasírt), des spécialités de saucisses (saucisses de Debrecen, de Gyula), des soupes paysannes ( goulash, bableves) ou de pêcheurs (halászlé), des légumes marinés, farcis (töltött káposzta) ou macérés (salades de chou, cornichons lacto-fermentés, etc.). Outre le paprika, la spécificité de la cuisine hongroise est due à la qualité des bêtes à viande disponibles dans la plaine hongroise tel que le bœuf gris de Hongrie ou le porc laineux mangalitsa. Les variétés de blé donnent également au pays une vraie tradition de pâtes aux œufs de type nokedli, tarhonya, etc. Si la pâtisserie hongroise bénéficie de l'influence autrichienne (dobos torta), les desserts sont moins réputés. On trouve néanmoins en Hongrie de nombreuses variétés de crêpes de type "Palatschinten" (crêpes épaisses) comme le palacsinta de Hortobágy ou le Gundel palacsinta. La charcuterie à base de porc est variée (téliszalámi, petits salés, saucissons au paprika) tandis qu'il existe peu de spécialités de fromage (camemberts et fromages à pâte molle).

Le petit-déjeuner hongrois est à dominante salée : de la charcuterie est dégustée avec tomate et poivron dans des petits pains (zsemle et kifli), avec des fruits et une boisson chaude. Le déjeuner commence avec une soupe, se poursuit sur un plat en viande accompagné de pâtes et une salade de chou ou de cornichon macéré et s'achève sur un produit sucré. Le dîner peut ressembler au petit-déjeuner ou se limiter à une simple sandwich. Les déjeuners sont arrosés de vin rouge produit dans la région du Balaton ou dans les massifs autour d'Eger ; les apéritifs de vins blancs liquoreux de type Tokaji.




</doc>
<doc id="15663" url="https://fr.wikipedia.org/wiki?curid=15663" title="Daniel Balavoine">
Daniel Balavoine

Daniel Balavoine est un auteur-compositeur-interprète français, né le à Alençon (Orne) et mort dans un accident d'hélicoptère le , aux environs de Gourma-Rharous (Mali), en marge du Paris-Dakar.

Porté par sa très haute tessiture et sa grande étendue vocale, il connait le succès en 1978 et 1979 avec son titre "Le Chanteur" et son rôle de Johnny Rockfort dans l'opéra-rock "Starmania" de Michel Berger et Luc Plamondon. Issu de divers groupes de rock progressif, Daniel Balavoine s'inscrit dès ses débuts de compositeur dans la mouvance inspirée par le rock et la pop anglaise, compatible avec sa voix androgyne. À l'exception de son ami Michel Berger et sans dénigrer pour autant la tradition littéraire française, il revendique des influences exclusivement anglo-saxonnes, notamment Genesis et Queen. Dans les dernières années de sa vie, passionné par la production sonore et les percussions, il évolue vers une pop rock expérimentale dont il est en France l'un des pionniers et l'un des rares représentants populaires.

Réputé pour ses textes engagés comme pour sa dimension sociale et ses prises de position médiatiques, il n'hésite pas à interpeller les médias ou le monde politique dans des interventions restées célèbres. Durant les années 1985-1986 à la suite des grandes famines éthiopiennes, il s'engage personnellement en faveur de l'Afrique par le biais du Rallye Dakar et devient l'un des premiers artistes français à s’investir personnellement dans l'humanitaire. Au cours d'une opération destinée à acheminer des pompes à eau aux populations locales maliennes, il est tué dans le crash d'un hélicoptère avec les quatre autres passagers. À l'annonce de l'accident, le choc est décuplé puisqu'il est alors avec Jean-Jacques Goldman, son rival mais néanmoins ami, le plus gros vendeur de disques en France.

En dépit de sa courte carrière due à une mort prématurée, Daniel Balavoine a écrit et composé plus d'une centaine de titres et demeure aujourd'hui encore l'un des artistes francophones les plus populaires, fort de près de 20 millions d'albums vendus et de tubes comme "Tous les cris les SOS", "Mon fils ma bataille", "La vie ne m'apprend rien" ou encore "L'Aziza". En 2005 il figure sur la liste des 100 français les plus célèbres établie par sondage BVA ; il y est classé dix-neuvième. À l'instar de Jean-Jacques Goldman, sa ligne mélodique inspirera de manière profonde la chanson française des années 1990 et du début des années 2000.

Daniel Balavoine vit ses premières années au 85, rue de Bretagne à Alençon, où il naît le . Issu d'une famille originaire des Landes et du Pays basque, il est le benjamin d'une famille de six enfants. Il a deux sœurs : Marie-Françoise (née en 1940) et Claire (née en 1943) et trois frères : Bernard (né en 1944), Guy (né en 1946) et Yves (né en 1948). Son frère Xavier meurt d'une méningite foudroyante un an plus tôt, si bien que Daniel pensera être un bébé de remplacement et aura des rapports complexes avec sa famille, jugeant indécents les artistes qui s'épanchent sur leur vie personnelle.

Son père Émile est ingénieur en urbanisme et travaille pour le ministère de la reconstruction. Sa mère Élisabeth Lamagdeleine est antiquaire, issue d'une famille du Sud-Ouest de la France. Ils se séparent alors que Daniel a six ans, les enfants restant chez le père. Il passe la majorité de sa jeunesse dans le Sud-Ouest, Bordeaux, Biarritz puis Pau. En 1959, Daniel entre en pension à la suite de la mutation de son père en Algérie à Tizi Ouzou. Il apprécie peu le pensionnat qui lui fait perdre le goût de la religion et provoque chez lui un profond rejet de la discipline qui y règne. Vers 11 ans, il entend dans l'établissement "She Loves You" des Beatles ce qui - il le confiera plus tard - lui donne goût à la musique.

Lycéen à Pau, Balavoine est un élève doué, surtout en littérature. Il s'implique de très près dans la révolte étudiante de mai 68 et s'imagine alors faire une carrière politique. Mais la fin du mouvement le déçoit, et il décide de se lancer dans la musique.

Après trois mois de terminale, il quitte son établissement en décembre 1969 afin de se consacrer à la musique.

Il débute chanteur de bal et se produit à Pau, notamment dans le quartier du Hédas, au Chaudron (actuellement Gusto), en interprétant Bob Dylan. Intégrant successivement les éphémères groupes de rock "Réveil", "Shake's" puis "Purple Eruption", il acquiert une petite notoriété locale.

En 1971 il décide de monter à Paris avec ses amis une première fois. Mais de retour à Pau, il est contacté par le groupe Présence dont le chanteur vient de partir. De nouveau sur Paris, il passe une audition au cours de laquelle un autre jeune chanteur, du nom de Laurent Voulzy, concourt. Balavoine est retenu et commence à côtoyer les studios. Un premier 45 tours oscillant entre hard rock et slow sort chez Vogue : il ne s'en vendra que 247 exemplaires. Malgré l'échec de ce disque, Présence se produit un peu partout en France. Entre temps, il se mariera avec une jeune polonaise rencontrée au Gibus où elle est caissière, Dominique Shroo, mais ils se séparent en 1974 et divorcent en 1979. Il évoque leur relation dans la chanson "Couleurs d'automne" de son premier album "De vous à elle en passant par moi".

En 1972, le groupe signe chez Warner Bros et Balavoine le quitte.

Pour assurer le quotidien, Balavoine trouve un emploi de disquaire mais ne renonce pas pour autant à la musique. En 1973 la maison de disques Vogue le rappelle et l'encourage à entamer une carrière solo. Le 45 tours "Viens vite" sort mais obtient à peine plus de succès qu'à l'époque de Présence. Il gardera un mauvais souvenir de cette période en raison des exigences du directeur artistique. Daniel quitte Vogue et, accompagné de son frère Guy, devient choriste. La même année, ils sont engagés dans l'opéra-rock "La Révolution française" de Claude-Michel Schönberg.

À la même période, Patrick Juvet prépare son passage à l'Olympia et recherche un choriste avec une haute tessiture. Contacté par sa productrice, Daniel est engagé et entame avec l'artiste une tournée au cours de l'année 1974. Daniel Balavoine lui compose une chanson "Couleurs d'automne" pour son prochain album intitulé "Chrysalide" ; Patrick Juvet, généreux, la lui laisse chanter. Le disque sort chez Barclay. C'est d'ailleurs pendant cet enregistrement que Daniel fait la connaissance d'Andy Scott, ingénieur du son, qui ne le quittera plus. Séduit par la voix de Balavoine, Léo Missir, vice-président et directeur artistique de Barclay, lui fait signer sur le champ un contrat de trois albums. Leur collaboration durera bien au-delà.

Le premier 33 tours de Daniel Balavoine sort en mars 1975 et s'intitule "De vous à elle en passant par moi", enregistré de nuit au Studio Hoche qu'il libère lui et son équipe au matin pour le début des séances de neuf heures. Aucun titre ne se démarque clairement : seul "Evelyne et moi", unique extrait à paraître en single, passe timidement en radio. L'album ne rencontre pas le succès ( exemplaires vendus). En 1982, en évoquant ce premier album dans l'émission "Aujourd'hui la vie", Balavoine admet que ', ajoutant que sa '. Il affirme que les ' vu qu'il parlait de lui et de ses fiancées et que ça lui '. Attristé par l'échec de "De vous à elle en passant par moi", Balavoine ne reprendra jamais les titres de l'album en concert, pas plus que le single suivant, "Vienne la pluie", sorti la même année, qui passe également inaperçu et qui connaît des problèmes en raison de sa pochette, reprenant sans autorisation la peinture "Les Vacances de Hegel" de René Magritte.

Peu avant, il croise la route de Catherine Ferry dont il tombe amoureux. Il devient par ailleurs le pygmalion de la jeune femme. Elle est choisie pour représenter la France à l'Eurovision 1976 lors de la sélection nationale française avec la chanson "Un, deux, trois" écrite par Jean-Paul Cara et composée par Tony Rallo. Les frères Balavoine chantent les chœurs bien que Daniel n'aime pas la chanson et font partie des choristes qui accompagnent la chanteuse lors de sa prestation au Concours Eurovision de la chanson à La Haye le 3 avril 1976. Un temps favorite, la chanson se classera deuxième au terme du vote final. Daniel écrira ensuite la majeure partie des futures chansons de Catherine Ferry, dont les titres "Bonjour, bonjour" en 1982 et "Vivre avec la musique" en 1984.

Au cours d'un voyage en Pologne en accompagnant Catherine Ferry, avec qui il est en couple à l'époque, Balavoine, heurté par le climat politique ambiant, imagine un album-concept autour du mur de Berlin, qu'il enregistre avec ses propres musiciens et son ami ingénieur du son, Andy Scott, bénéficiant de moyens qu'aurait obtenu un chanteur déjà célèbre. Intitulé "Les Aventures de Simon et Gunther...", le disque, mêlant rock progressif et musique classique, sort en et bénéficie d'une promotion plus grande que sur l'album précédent. Malgré le succès d'estime obtenu, les ventes de cet ovni paru en pleine période disco restent faibles (seulement écoulés) et Eddie Barclay s'impatiente des résultats du chanteur et fait savoir à Léo Missir que le prochain album sera décisif. Parallèlement, Balavoine est choriste sur le premier album d'Alain Bashung, "Roman-photos".

Entre-temps, Michel Berger, qui est en passe d'achever la composition de l'opéra-rock "Starmania", cherche un chanteur pour interpréter le rôle de "Johnny Rockfort". Impressionné par une prestation de Balavoine qui interprète à la télévision "Lady Marlène" (l'unique titre du dernier album ayant réussi à percer), il l'embauche. France Gall, alors compagne de Michel Berger, témoigne : 
Dès lors débute entre eux une grande et fraternelle amitié.

En sort l'album studio de "Starmania", dont, de nombreux titres deviennent en quelques semaines des hits. Balavoine y interprète "Quand on arrive en ville", "Banlieue nord" et le "SOS d'un terrien en détresse", composé et taillé sur mesure à sa voix. Le disque demeure une des meilleures ventes françaises de l'Histoire, cumulant plus de deux millions d'unités vendues. L'œuvre, plus tard adaptée en anglais, est tout aussi bien accueillie à l'étranger.

En parallèle — et après un 45 tours encore peu rentable, "Je suis bien", sorti en , bien que lui permettant de bénéficier de l'interpréter à plusieurs reprises à la télévision — Daniel Balavoine enregistre son troisième album "Le Chanteur" avec le groupe Clin d'œil, dans les bacs quelques semaines avant la sortie de Starmania. Clin d'œil participera aussi aux deux albums suivants. La chanson "Le Chanteur" qui donne son titre à l'album, obtient un succès fulgurant et se vend à plus de exemplaires. Avec ce titre (devenu un standard de son répertoire et qui demeure, aujourd'hui encore, une de ses plus célèbres chansons), Balavoine, lucide et amer, chante les ambitions et les craintes d'un artiste en devenir. Il évoque la fulgurance du succès d'un nouveau venu dans le monde de la chanson, , qui adulé du public et reconnu par les médias donne , puis passe au terme d'une longue carrière du statut d'idole à celui de vieux chanteur jugé ringard par la jeune génération () et s'achève, après l'abandon de toute illusion et le désamour du public, par . "Les Oiseaux" et "Lucie" seront également extraits du même album.

Cette double réussite, quasi simultanée, fait passer Daniel Balavoine de chanteur méconnu à vedette en devenir, ce qui, par la même occasion, lui permet de renouveler sereinement son contrat chez Barclay.

Du 10 avril au 3 , "Starmania" est joué au Palais des congrès de Paris, où personnes au total assistent au spectacle. La distribution, outre Daniel, se compose de France Gall, Diane Dufresne, Étienne Chicot, Fabienne Thibeault, Nanette Workman pour ne citer qu'eux. Balavoine marque profondément cette production et cette participation accroit davantage sa notoriété en lui donnant une image de rebelle, voyou et tendre à la fois.

Fort de cette expérience, il enregistre son quatrième album "Face amour / Face amère", qui sort en et comprend notamment "Love Linda", dédié à sa nouvelle compagne Linda Lecomte, "Rougeagèvre", "Ces petits riens" (une douce balade pop) et "Me laisse pas m'en aller", dont la construction musicale rappelle celle du "Chanteur". Sans réel tube, le disque est moyennement accueilli par le public, tout en étant salué par la critique qui lui décerne le prix Raoul-Breton. À Lille au théâtre Sébastopol, au mois de novembre, il donne le premier concert à son nom.

Balavoine se produit à l'Olympia du 31 janvier au , où par soir viennent le voir, obtenant un accueil favorable des critiques professionnels. Toujours en ce début d'année 1980, il apparait dans le film "Alors... Heureux ?" jouant le rôle d'un brancardier homosexuel, et pour lequel il compose également la musique du film.

Il fait aussi sensation le , lors d'un débat au journal de midi sur Antenne 2 au cours duquel il prend à partie François Mitterrand, alors premier secrétaire du Parti socialiste et par la même occasion les journalistes présents sur le plateau, les accusant d'ignorer les problèmes de la jeunesse dans un monologue resté célèbre. Les médias l'érigent alors en porte-parole de cette même jeunesse, un rôle qu'il réfute et dont il désirera toujours se défaire estimant que ce n'était pas du tout son intention. Créant la polémique, il devient désormais un invité incontournable des émissions-débats, devenant un « bon client » aux yeux des médias. Après cette intervention, il est catalogué comme chanteur engagé dans l'esprit du grand public.

En bon ami, il soutient à l'époque la candidature de Coluche à l'élection présidentielle de 1981. Après le retrait de ce dernier, François Mitterrand lui demande de se joindre à sa campagne. Balavoine, sensible aux idées de gauche, chante dans la première partie de ses meetings pendant quelques semaines avant de se rétracter, refusant ce qu'il estime être une récupération politique. Il déclarera plus tard : 

En , il revient avec l'album "Un autre monde", disque contenant "Mon fils ma bataille" (inspiré du divorce de son guitariste et ami Colin Swinburne), "Je ne suis pas un héros" (initialement écrit pour l'album "À partir de maintenant" de Johnny Hallyday), "La vie ne m'apprend rien". Ces tubes deviennent des incontournables de son répertoire, tout comme, dans une moindre mesure, "Lipstick Polychrome". L'album rencontre un énorme succès commercial, avec exemplaires vendus

Fort du succès de ses nouvelles chansons, Daniel réinvestit la scène de l'Olympia du 10 au 14 mars 1981. Il fait salle comble et enregistre son premier album en public, "Balavoine sur scène" qui parait en . La Chine est très présente dans ce spectacle. Il entame ensuite une grande tournée et participe, le 22 octobre, au concert "100 artistes pour les prisonniers d'opinions", au profit d'Amnesty International.

Parallèlement, Daniel fait ses débuts de présentateur à la télévision sur Antenne 2. En compagnie de Joëlle Mogensen (alors ex-chanteuse du groupe Il était une fois), il présente, le , un nouveau concept d'émission de variétés baptisé "Tout nouveau, tout beau". L'aventure tournera court et s'arrêtera à ce premier numéro.

Durant l'hiver 1981, il part à Ibiza enregistrer un sixième 33 tours avec de nouveaux musiciens, dont le batteur américain Joe Hammer. À 30 ans, Balavoine veut entamer un nouveau virage musical, plus rock, plus électronique, s'écartant de plus en plus de l'acoustique. En avril sort "Vendeurs de larmes" porté par la chanson "Vivre ou survivre", qui devient très vite un tube. "Dieu que l'amour est triste", "Soulève-moi" et le titre éponyme de l'album sont aussi notables. Ce disque rencontre un grand succès public et obtient le prix Diamant de la chanson française.

Estimant que ses productions sont maintenant dignes de concerts plus imposants, il investit la plus grande salle de spectacle parisienne de l'époque, le Palais des sports, où il joue à guichets fermés du 9 au . Les moyens mis en œuvre sont importants et Balavoine offre au public un grand spectacle. Séduit par l'acoustique du lieu ainsi que son ambiance, il restera fidèle à cette salle.

Balavoine se voit également proposer un second rôle au cinéma dans le film "Qu'est-ce qui fait craquer les filles..." (1982).

Passionné de sports mécaniques, Balavoine participe en janvier au Paris-Dakar. Tombé en panne à la première étape, il suit la caravane en touriste et découvre l'Afrique. Électrochoc pour Daniel Balavoine qui prend violemment conscience de la famine et de la pauvreté du continent. Revenant avec des images dures, il déclare : .

Durant l'été, il part en Écosse composer son septième album "Loin des yeux de l'Occident". Sorti en et réputé être son album le plus engagé, les textes évoquent les femmes du tiers-monde avec "Pour la femme veuve qui s'éveille", la torture avec "Frappe avec ta tête", la drogue avec "Poisson dans la cage", les dictatures d'Amérique du Sud avec '. Notons également : "Partir avant les miens", dont le texte à l'annonce de sa mort sonnera comme étrangement prémonitoire. Musicalement, le disque, inspiré par Peter Gabriel, mêle sonorités électroniques et ambiances ' avec l'emploi de percussions africaines. Toutefois, l'album se vend moins bien que les précédents ( exemplaires).

Durant l'année, Balavoine participe au conte musical "Abbacadabra" avec Frida du groupe ABBA, avec laquelle il enregistre le single "Belle".

Pendant trois semaines, à 18 h 30, il tient une chronique quotidienne de 2 minutes 30 sur une éphémère radio "95.2". Il réagit à l'actualité en rédigeant des billets d'humeurs. En , il préfigure les Restos du Cœur dans une de ses chroniques en émettant l'idée d'une grande . font comprendre au chanteur qu'il n'a pas à se mêler de tels sujets. L'idée sera reprise par Coluche, à l'origine des Restos du cœur. Selon Fabien Lecœuvre : 

Le chanteur est l'invité de l'émission d'information "7 sur 7" le , jour de l'attentat du Drakkar au Liban où son frère Yves — militaire — est basé. Il lance sous le coup de l'émotion : ; phrase adressée à tous ceux qui souhaitent à la jeunesse . Il poursuit avec véhémence et colère dans une diatribe profondément antipolitique et antimilitariste. Son propos fait scandale et deux semaines plus tard, il s'explique publiquement dans une émission de Michel Drucker, ce qui n'empêche pas l'annulation de certains de ses concerts du fait de manifestations d'anciens combattants, notamment à Avignon.

Balavoine entreprend une tournée marathon à travers la France durant l'hiver-printemps 1984. Le 2 avril, il fait une halte au Printemps de Bourges.

Le , naît son fils Jérémie. Daniel a rencontré sa mère Corinne pendant l'enregistrement de "Vendeurs de larmes". Dans l'émoi et à titre promotionnel pour sa rentrée parisienne, il compose un 45 tours inédit "Dieu que c'est beau" illustrant d'une manière métaphorique l'accouchement avec des références omniprésentes à la Genèse. Frida Lyngstad, du groupe Abba, est l'une de ses choristes sur cette chanson ; il lui compose d'ailleurs le titre "The Face" pour son album "Shine" (1984). "Dieu que c'est Beau" est le premier titre de Balavoine à entrer au Top 50, nouvellement créé.

Sa tournée se clôture au Palais des sports du 21 au 30 septembre, où est enregistré le double album live "Balavoine au Palais des sports". Daniel Balavoine présente au public un spectacle qui utilise les faisceaux Vari-Lite et la technologie HF (sans fil). Le décor est très dépouillé, Balavoine privilégiant largement la lumière et le rendu sonore, qu'il désire irréprochable. La totalité des chansons a été réorchestrée soit dans des ambiances techno-world soit dans un rock très prononcé.

Durant l'année, il compose et écrit l'album "Vivre avec la Musique" pour Catherine Ferry, où il expérimente pour la première fois l'échantillonneur Fairlight CMI qu'il vient d'acquérir pour un prix exorbitant.

Le , Balavoine se lance dans son deuxième Paris-Dakar comme copilote de Jean-Luc Roy à bord d'un Toyota. Ils arriveront à Dakar trentième.

Il devient arrangeur musical et ouvre une « cellule artistique » destinée à promouvoir le son reconnaissable de ses albums et sa technique de production réputée « raffinée » chez d'autres artistes. Admirative de Balavoine, Jeanne Mas restera sa première et dernière cliente. Le chanteur lui réalise deux titres : "Cœur en stéréo" et "Oh Mama".

L'année 1985 marque l'entrée du showbiz dans le monde de l'humanitaire. Les artistes du monde entier se mobilisent pour l'Éthiopie qui subit alors une famine effroyable. À l'initiative de Bob Geldof qui a créé Band Aid l'année passée, un concert planétaire est donnée le au Wembley Stadium qui est marqué par des performances scéniques, comme celle de Queen. Une délégation française, composée de Michel Berger, France Gall, Jean-Jacques Goldman et Daniel Balavoine, est présente. Attristé que contrairement à plein d'autres pays il n'y ait pas eu de concert solidaire en France à cette occasion, le groupe décide d'en organiser un. Ce sera le concert des "Chanteurs sans frontières", coorganisé par Renaud à La Courneuve le . Daniel Balavoine y chante en duo "Je marche seul" avec Jean-Jacques Goldman et "Il jouait du piano debout" avec France Gall. Le concert en plein air, dont le prix des places fut jugé trop onéreux, avec seulement spectateurs est considéré comme un échec, mais le disque "SOS Éthiopie" se vend bien. Balavoine qualifie le concert de .

Durant l'été, Balavoine retourne en Écosse pour enregistrer son huitième album studio. "Sauver l'amour" paraît en . Le 33 tours est également diffusé en CD (format d'écoute encore rarissime à cette époque), ce qui, en bon amateur de nouvelle technologie, fait le bonheur de Daniel Balavoine. L'album est marqué musicalement par l'utilisation de l'échantillonneur Fairlight CMI, permettant une large gamme de sonorités nouvelles et encore inédites en France où l'appareil est peu utilisé.

Sur les neuf chansons que compte l'album, quatre deviennent des tubes : "L'Aziza", en hommage à sa femme juive-marocaine Corinne, le plus grand succès de l'album dont les ventes en single dépassent le million d'exemplaires et lui vaut d'être classé du Top 50 un mois après sa mort tragique, "Sauver l'amour" ( au Top 50), "Aimer est plus fort que d'être aimé" (non classé au Top 50, mais succès radiophonique) et l'hymne de la solitude "Tous les cris les SOS". La quasi-totalité des titres traitent d'un problème politique ou social : une jeunesse incomprise pour "Petite Angèle", le sujet grave des enfants soldats avec "Petit homme mort au combat", la rupture avec "Ne parle pas de malheur" et la sécheresse (et "a fortiori" la famine en Éthiopie) avec "Un enfant assis attend la pluie" qui clos l'album. Après sa mort, on apprendra que l'artiste avait cédé en secret tous les droits de cette dernière chanson au profit de l'Afrique. Toute la fin de l'année 1985 est consacrée à la promotion du disque. de l'album sont vendus (et ), ce qui en fait la meilleure vente toutes catégories confondues du chanteur.

Il participe à plusieurs manifestations parmi lesquelles, les premières Victoires de la musique, le 23 novembre, qu'il préside pendant une partie en remettant un prix à Jean Michel Jarre et au groupe Téléphone. Le 7 décembre, il reçoit le prix de la chanson anti-raciste pour "L'Aziza" des mains de Harlem Désir au nom de SOS Racisme. Militant de la première heure au sein de cette association, il était inscrit comme militant de base au comité de Colombes, son lieu de résidence. Quelques jours plus tard, le 14 décembre, il participe au lancement officiel des Restaurants du cœur par son ami Coluche. Balavoine en est le premier parrain(ce même mois, il passera son dernier Noël en famille).

Par sa volonté d'être sur tous les fronts, le chanteur se voit extrêmement médiatisé à cette période.

Le représentant en France de , Lionel Rotcage, l'encourage ainsi que Michel Berger, France Gall et Richard Berry à s'investir dans l'opération Action Écoles qui consiste à créer des comités d'élèves dans tous les établissements scolaires de France afin de lever des fonds et de financer des projets précis sur le continent africain.

Parmi ces projets, Daniel Balavoine se voit confier la responsabilité de l'opération "Pompes à eaux pour l'Afrique", qui l'amène à repartir sur le Paris-Dakar, non pas en tant que concurrent, mais comme ambassadeur des "Paris du cœur" (une action humanitaire visant à installer des pompes à eaux dans des villages africains, en profitant de la logistique du rallye). Il supervise, avec l'aide du créateur et directeur de la course Thierry Sabine, ce programme en prenant appui sur le rallye. À l'aide d'une caméra et d'un appareil photo, il réalise un reportage au fur et à mesure de ses arrêts dans le but de le présenter sur le plateau de "Champs-Élysées" peu après son retour (25 janvier). Parallèlement, il rédige des chroniques quotidiennes pour Europe 1. Il part donc le 6 janvier 1986 de Tamanrasset pour rejoindre l'équipe qui se trouve au Rallye Dakar.

Ainsi, le , on le voit assistant à l'installation d'une pompe à eau solaire dans un village voisin d'Agadez. C'est probablement sa dernière apparition télévisée, bien qu'il existe un court film amateur tourné quelques heures avant sa mort.

Le 12 janvier, deux jours avant sa mort, il sauve la vie de la pilote Catherine Caly, alors gravement blessée, en l'évacuant d'urgence à bord de son avion. , lui aurait-il dit. Il rejoint ensuite à Niamey le Rallye Dakar le 13 janvier 1986 pour la journée de repos.

Présent lors du Paris-Dakar 1986 en tant qu'ambassadeur de l'action humanitaire des "Paris du Cœur" (Action Ecoles), Daniel Balavoine traite une bonne partie de la journée du 14 janvier avec le gouverneur de Gao, dont les autorités bloquent une partie du convoi acheminant les pompes à eaux. Le matin dans le petit avion qui l'emmenait de Niamey (Niger) à Gao (Mali), il donnait sa dernière interview filmée, volée au détour d'une conversation. Vêtu d'un sweat blanc et apparaissant très fatigué il renouvelait sa confiance en son opération humanitaire au terme d'un échange bref. Avec Thierry Sabine présent à ses côtés ils donnent en fin d'après-midi le coup d'envoi d'un match de football entre l'équipe de Gao et celle de Mopti organisée dans le cadre du Paris-Dakar. La cérémonie s'éternise et le jour décline. Cette journée est décrite par tous les protagonistes comme l'une des pires de l'épreuve, avec un fort vent de sable fluctuant tout au long de la journée. Thierry Sabine doit rejoindre par hélicoptère le bivouac de Gourma-Rharous, arrivée de l'étape à 250 km du site. Daniel Balavoine n'est pas prévu à bord. Plusieurs journalistes présent pour la couverture du rallye et prévus à bord ont ce jour-là échappé à la mort. Patrick Poivre d'Arvor, Yann Arthus-Bertrand, Jean-Luc Roy ou encore Patrick Chêne se seraient trouvés embarqués si deux avions en provenance de Bamako ne s'étaient pas posés par hasard sur le tarmac de Gao. Tous choisirent de s'y disperser. Nathalie Odent et Jean-Paul Le Fur, journaliste au Journal du Dimanche et technicien radio RTL les remplacent dans l'hélicoptère. Jean-Luc Roy, sur la proposition de Thierry Sabine auprès duquel Balavoine réclamait de temps à autre un baptême de l'air en hélicoptère, cédera sa place au dernier moment au chanteur qui finira, après quelques hésitations, par monter à bord pressé par le temps. 

À 17 h 15, l'appareil décolle. Le pilote François-Xavier Bagnoud commence par suivre le fleuve Niger (un repère plat et simple) afin de limiter tout risque. Une heure plus tard, ils se posent une première fois à Gossi pour donner le coup d'envoi de la deuxième épreuve chronométrée et repartent au coucher du soleil bien que l'hélicoptère ne soit pas équipé pour voler de nuit. Vers 19 h, François-Xavier Bagnoud, n'y voyant plus rien décide d'atterrir 22 km avant l'arrivée. Les conditions sont exécrables, la nuit est tombée et le vent de sable remonte en puissance. Sabine appelle par radio le bivouac et demande qu'on leur envoie un véhicule pour terminer le parcours. Il sort de l'hélicoptère et croise un concurrent immatriculée 198. D'un ton calme et rassurant, il réitère sa demande d'aide au pilote Pierre Lartigue et au copilote Bernard Giroux. Claude Brasseur, témoin de leur ultime arrêt, décrira pourtant Thierry Sabine très énervé à l'idée de rester immobile sous l'autorité de son pilote.

De manière inexplicable, ils redécolleront quelques instants plus tard en prenant en chasse le 4x4 de Charles Belvèze et de son coéquipier Jacquie Giraud, se guidant à partir des feux rouges arrière du véhicule. Les deux témoins décriront l'appareil comme volant en rase-motte à une dizaine de mètres au-dessus d'eux à très haute vitesse. Le terrain réputé vicieux, ce dernier accroche, après que le 4x4 ait viré sur la gauche pour la contourner, le sommet d'une dune de 30 mètres incapable d'apprécier la déclivité progressive du terrain. Rapidement déstabilisé, l'hélicoptère bascule vers l'avant et se désintègre sur près de 150 mètres après plusieurs loopings, s'éclatant entre temps contre un ou plusieurs acacias. Il est alors 19 h 20 ; l'accident se produit à seulement huit kilomètres et cinq minutes de vol du bivouac de Gourma-Rharous (approximativement 16° 49′ 52″ N, 1° 52′ 23″ O), en plein désert malien. Les cinq passagers meurent sur le coup.

Si l'accident en lui-même, même si mal compris faute de témoins, reste a priori lié aux conditions météorologique difficiles, la raison de leur dernier décollage semble irrationnelle et demeure à ce jour inexpliquée. Durant longtemps, la seule et unique réponse qui ait été avancée est la thèse d'une blessure se fondant sur la découverte de gazes à l'endroit de leur arrêt. Morsure de serpent, piqûre de scorpion ou tout autre traumatisme suffisamment grave pour s'envoler en urgence et ainsi arriver le plus vite possible à destination, et ce malgré le danger. Depuis quelques années un coup de sang de Thierry Sabine est de plus en plus évoqué par ceux qui l'ont connu et étaient sur place à l'époque. Il était de notoriété publique que le jeune pilote, fatigué du rythme qu'impliquait le Dakar, était en froid avec Thierry Sabine, peu enclin aux règles de sécurité et dont le charisme et le goût pour l'aventure étaient parfois jugés écrasants.

Le corps de Daniel Balavoine est, dans les jours qui suivent, rapatrié en France pour y être inhumé. Son cercueil est exposé un temps au public au funérarium du mont Valérien à Nanterre. Ses obsèques furent célébrées le à Biarritz, où il repose désormais, au cimetière de Ranquine.

La mort de Daniel Balavoine intervient à un moment charnière où le chanteur bouillonne de projets et rêve d'entamer une carrière internationale. Son seul succès francophone ne lui suffit plus, il désire s'exporter outre-Manche et créer un groupe.

Voulant se remettre en cause et repartir de zéro, il était convenu que, dès , Balavoine aille s'installer à Londres. Son introduction sur le marché du disque anglais se serait réalisée par l'intermédiaire de l'ex-chanteur de Genesis, Peter Gabriel avec qui Daniel Balavoine était en pourparler en vue d'une collaboration artistique et de Peter Hammill, membre fondateur de Van der Graaf Generator. Là-bas était prévue l'admission du chanteur dans un groupe où il n'occuperait pas forcément la place de chanteur ou de leader. Entièrement anglo-saxonne et réservée au marché britannique, du moins dans un premier temps, cette nouvelle production nommée "" (), chantée en anglais, aurait été pour lui non seulement un moyen de convaincre les critiques rocks que sa musique était digne de la Grande-Bretagne mais aussi de renouer avec ses débuts. L'équipe aurait été la même que pour l'enregistrement de "Sauver l'amour", composée donc, outre Balavoine, du batteur Joseph Hammer, du guitariste John Wooloff et du claviériste Matt Clifford (plus tard claviériste des Rolling Stones), le tout accompagné d'Andy Scott à la réalisation. Un 45 tours à titre expérimental serait sorti au cours de l'année 1986, puis selon le succès un premier album en anglais vers fin 1987.

En parallèle, Balavoine voulait continuer sa carrière française, mais de manière moins intense que la décennie écoulée. Sa salle fétiche, le palais des Sports, devait à nouveau l'accueillir pour trois semaines de concerts, une durée exceptionnelle, dès la fin . Il n'était d'ailleurs pas exclu que la formation anglaise s'occupe de la première partie du spectacle en interprétant des inédits. Le spectacle aurait inauguré une tournée qui se serait étendue de la France aux Pays-Bas, en passant par l'Allemagne jusqu'en mars 1987. Elle aurait rejoint celle de Jeanne Mas au palais des Sports de Lyon où les deux artistes envisageaient de donner un spectacle en commun.

Le chanteur, estimant que son métier n'est pas une fin en soi, disait vouloir mettre un terme à sa carrière autour de la quarantaine pour pouvoir commencer autre chose — politique, production, cinéma, écriture — sans savoir encore. Dans une interview en février 1984 sur Europe 1, il déclarait être très intéressé par l'écriture d'un roman. Certaines personnes de son entourage affirment qu'il aurait quand même continué la musique.

En à peine huit ans de succès (1978-1986), Balavoine laisse près d'une vingtaine de tubes. Nombre d'artistes ont interprété ultérieurement des chansons de son répertoire, tels que Florent Pagny, Liane Foly, Léna Ka, Jeanne Mas,Nicole Rieu, Pascal Obispo, Patrick Fiori, la troupe des Enfoirés, Marie Denise Pelletier ou Grégory Lemarchal pour ne citer qu'eux.

Daniel Balavoine a vendu près de 20 millions de disques et est de ceux dont la carrière posthume est autant prolifique sinon plus que celle menée de leur vivant. 
Il est fréquemment diffusé sur les ondes (en 2003, il a été l'artiste le plus diffusé à la radio, en moyenne une fois par heure) et souvent repris à la télévision.

Il jouit encore aujourd'hui d'une grande popularité, en témoignent les ventes de ses principales compilations : "L'Essentiel" (paru en 1995) vendu à exemplaires et "Balavoine sans frontières" (paru en 2005) atteignant les copies. Ses actions humanitaires et prises de positions sont unanimement saluées. Son univers particulier fut boudé durant un temps par la nouvelle génération avant qu'une nouvelle scène hétéroclite ne commence à le saluer ou à s'en réclamer : de rappeurs comme Soprano et Youssoupha à Justice ou Mickaël Miro en passant par Christine and the Queens et dernièrement Fishbach ou encore BB Brunes.

Quatre jours après sa mort, Jean-Jacques Goldman lui a rendu hommage en direct dans "Champs-Élysées" en lui dédiant sa chanson "Confidentiel", dont les paroles reflètent son état d'âme vis-à-vis du disparu.

Alors qu'elle remporte le concours « Tremplin de la musique du Festival de Wallonie » en 1986, Lara Fabian décide de faire figurer sur la face A de son premier 45 tours la chanson écrite et composée en hommage à Daniel Balavoine par Marc Lerchs "L'Aziza est en pleurs". Remarquée par Claude Rappé de RTL, elle sera sélectionnée par le producteur Hubert Terheggen pour représenter le Luxembourg à l'Eurovision 1988.

Michel Berger a écrit et composé pour France Gall la chanson "Évidemment" (sur l'album "Babacar", en 1987), en hommage à Daniel Balavoine. Il lui a également fréquemment dédié sa chanson "La Minute de silence" lors de concerts. Michel Berger écrira sur son dernier disque "Double jeu", la chanson "La lettre" en hommage à Daniel Balavoine et sa compagne, Corinne.

Lors de sa tournée 1986-1987, Jeanne Mas interprète "Lucie" dans son tour de chant. Elle choisira de reprendre systématiquement une chanson de Daniel Balavoine lors de ses tournées en France.

En décembre 1987, Julie Pietri rend à son tour hommage au chanteur lors de ses concerts à l'Olympia, en interprétant "La vie ne m'apprend rien".

Dans son album "Rocktambule" (1988), Catherine Lara inclut sa chanson "I.E.O.", écrite à partir de titres et paroles de chansons de Daniel Balavoine.

De même, Francis Cabrel enregistre sur son album "Sarbacane" (1989) la chanson "Dormir debout" dans laquelle il rend hommage à et .

En 1990, Johnny Hallyday inscrit pour la première fois à son répertoire "Je ne suis pas un héros", qu'il dédie lors de son tour de chant à Daniel Balavoine. Sortie en single, cette version live devient un tube et cela malgré la censure qui l'interdit de radio et de télévision durant la Guerre du Golfe. (voir album live "Dans la chaleur de Bercy").

En 1997, les Enfoirés reprendront "Sauver l'amour", puis en 2004 "Tous les cris les SOS" comme hymnes officiels.

En 1999, Liane Foly inclut une reprise de "La vie ne m'apprend rien" sur son album "Acoustique".

En 2000, une sélection d'artistes composée de David Hallyday, Florent Pagny, Francis Cabrel, Hélène Segara, Jean-Louis Aubert, Khaled, Liane Foly, Marc Lavoine, Roch Voisine et Stephan Eicher reprennent ses chansons sur l'album "Balavoine hommages...".

En 2004, la troupe des Enfoirés fait de "Tous les cris les SOS" son hymne de l'année.

Le 17 avril 2004, l'astéroïde (214081) Balavoine a été nommé en sa mémoire.

En 2005, dans l'attente du vingtième anniversaire de sa mort, la Star Académy reprend "Je ne suis pas un héros" et lui rend hommage sur un album de reprises "Star Academy chante Daniel Balavoine".

En 2010, le rappeur Soprano lui rend aussi hommage dans sa chanson "Hiro" en affirmant vouloir remonter le temps pour « boycotter » son décollage.

Marc Lavoine a pour sa part interprété "Sauver l'amour" en duo avec Joana Balavoine (née le ), fille de l'artiste disparu, lors de l'émission "Daniel Balavoine, Évidemment" diffusée en juin 2011.

En 2015, le rappeur Youssoupha revisite le court titre "Pour faire un disque" sorti en 1982.

En 2016, à l'occasion des trente ans de la mort du chanteur ce sont Bessa, Cats on Trees, Christophe, Damien Loretta, Emmanuel Moire, Florent Pagny, Jenifer Bartoli, Josef Salvat, Marina Kaye, Nolwenn Leroy, Ours, Raphael, Shy'm, Zaho, Zaz et Christine and the Queens qui lui rendent hommage sur l'album "Balavoine(s)". Bien qu'ayant obtenu un succès commercial, cet album hommage est très critiqué.

En 2017, Mathieu Chedid, -M- de son nom d'artiste, rend hommage au chanteur en interprétant lors de sa tournée Lamomali, album au accents profondément inspirés du Mali le titre "Sauver l'amour" accompagné de l'artiste malienne Fatoumata Diawara. Cette reprise chantée en cœur par le public du festival Francofolies sera présente sur l'album live "Lamomali Airlines" sorti en novembre 2017.

Son fils Jérémie Balavoine est devenu producteur de spectacles. Sa fille Joana est chanteuse du groupe de musique "Gentle Republic", avec Alexandre Mazarguil, dans lequel elle interprète en anglais des chansons aux fortes résonances des années 1980. Pour la première fois, Joana Balavoine parle de son père dans un documentaire-événement qui lui est consacré "J’me présente, je m’appelle Daniel" en 2016. Sa dernière compagne et mère de ses deux enfants, Corinne Barcessat (Coco) est aujourd'hui mariée au réalisateur de télévision Serge Khalfon.

Son écriture, engagée par les sujets traités, brosse le portrait de facettes sensibles de la société : célébrité, divorce, enfance, argent et réussite sociale, travail, guerres, drogue, torture, politique, amour, tolérance et racisme, drames humanitaires, vie et mort Il inclut dans une grande majorité de ses chansons la notion d'espoir au sein d'un environnement désespérant : "Vivre ou survivre" et "Tous les cris les SOS" illustrent bien cette idée, autant textuellement que musicalement. Balavoine est fréquemment montré comme appartenant à une certaine mouvance romantique.

, résumait Daniel Balavoine.

Durant toute sa carrière, il n'a de cesse de blâmer les critiques rock qui, à son sens, censurent son statut de « rockeur » et ne reconnaissent pas à part entière son travail, ou tout simplement ne considèrent pas sa musique comme étant du rock. Cette quête permanente de reconnaissance artistique fut plus ou moins récompensée en 1984, année où l'émission "Les Enfants du rock" lui consacre un portrait. Il gardera toutefois une profonde amertume envers cette presse spécialisée. C'est d'ailleurs une des raisons pour lesquelles il voulait partir en Angleterre, avec l'ambition de fonder un groupe de rock qui lui aurait assuré une légitimité à long terme.

Grand détracteur de la catégorie « variétés », du moins dans le sens péjoratif qu'on lui donne, il essaie, à la moindre interview et par tous les moyens, d'échapper à cet étau, à son goût hautement réducteur. Balavoine définit la musique comme prioritaire sur les textes, sans pour autant les dénigrer, se distinguant ainsi du modèle français de tradition plutôt littéraire ne voulant en aucun cas être comparé à des poètes tels que Jacques Brel, Léo Ferré ou Georges Brassens. Il désire faire la synthèse entre la musicalité rock anglaise et la langue française à laquelle il reste viscéralement attaché (il chante en 1978 "Le français est une langue qui résonne"), déplorant le diktat sur les marchés du disque d'une mondialisation linguistique anglo-saxonne : 

Daniel Balavoine est l'un des rares chanteurs français à avoir introduit des instrumentaux dans ses albums studios : "Correspondances" (dans l'album "Les Aventures de Simon et Gunther..." en 1979), "Un autre monde" (dans l'album "éponyme" en 1980) et "La danse" (dans "Vendeurs de larmes" en 1982).

Issu de la nouvelle scène française émergeant au milieu des années 1970, à savoir les Michel Berger, Alain Souchon, Francis Cabrel, Laurent Voulzy, Renaud ou Jean-Jacques Goldman, il se distingue par sa volonté de mettre en avant l'instrumentation électronique, et d'utiliser principalement les synthétiseurs (dans la deuxième moitié de sa carrière).

Il n'hésitait pas à critiquer une majorité d'artistes français "établis", qu'il accusait alors de faire de la musique de , pas assez en rapport avec les attentes de la jeunesse tendant à se tourner davantage vers la musique anglo-saxonne.

Il prend pour modèle essentiellement le groupe Genesis et ses membres : Phil Collins mais surtout Peter Gabriel, détenteur d'un univers bien particulier, idole du chanteur. Une collaboration entre les deux artistes avait même été envisagée. 
Balavoine était enthousiaste face à l'arrivée des nouvelles technologies (le CD naissant et l'informatique) motivé par la perpétuelle recherche de sons nouveaux. C'est dans cette optique d'innovation qu'il s'essaye même à la "" avec "Pour la femme veuve qui s'éveille" dont découle l'album "Loin des yeux de l'Occident".

On note que l'achat du Fairlight CMI marque un tournant décisif dans sa carrière. Grâce à ce matériel, il est l'un des premiers à avoir expérimenté le concept du home studio : l'informatisation de la musique lui permet de composer et travailler chez lui. L'échantillonneur Fairlight, permettant d'enregistrer des sons réels puis de les échantillonner pour pouvoir ensuite les jouer, lui octroie un éventail presque infini de possibilités musicales. En découlent des airs inédits, telle l'intro de "Tous les cris les SOS" matérialisée par un vrai sifflement de train mêlé à des taiko japonais. Les percussions ainsi que les effets synthétiques (synthèse proche de l'orgue ou du violon) occupent un rôle qui ne cessera de croître, devenant ainsi priorité sur "Sauver l'amour". "Sauver l'amour" ne peut pas être non plus réduit à un album de « laboratoire », album dont certains morceaux seraient d'ailleurs qualifiés d'électro-pop aujourd'hui, le solo de guitare de "L'Aziza" joué en une prise au retour du Live Aid par John Woolloff est un parfait contre-exemple et révèle que certains titres requièrent toujours beaucoup de spontanéité.

Compositeur avant d'être auteur, Balavoine passe la majeure partie de son temps à élaborer ses musiques. Les textes sont écrits rapidement et toujours au dernier moment, à l'instar du "Chanteur". Balavoine n'est pas musicien de formation : par conséquent il travaille à l'oreille, ne sachant pas écrire la mélodie.

Sa voix reste néanmoins sa principale caractéristique. Puissante et assez singulière, on la reconnait par son timbre haut perché et parfois volontairement éraillé. On lui décerne la plupart du temps une amplitude de près de trois octaves, généralement représentative de la montée effectuée sur le SOS d'un terrien en détresse du "la" 1 au "fa" 4 qui couvre aussi bien les graves que les aigus. Sa tonalité naturellement plus haute que la normale, aurait tendance à l'oreille, à majorer son étendue vocale. Il n'utilise que peu la voix de tête (essentiellement sur Lucie, le Chanteur et SOS d'un terrien en détresse) et reste la majeure partie du temps en voix de poitrine, qui lui suffit pour chanter haut. Il interprète la plupart de ses chansons dans une tessiture et un registre rares de haute-contre avec cependant plus de puissance. Il atteint le "ré" 4 en voix de poitrine sur Tous les cris les SOS, et même furtivement le "do" 5 dans cette même chanson.




L'« Association Daniel-Balavoine », loi 1901, a été créée en mars 1986 par les amis et la famille pour répondre à l'appel de ceux qui souhaitaient continuer l'action de Daniel Balavoine et Thierry Sabine en Afrique de l'Ouest. Son but principal est de fournir des motopompes d'irrigation pour la culture du riz au Sénégal, en Mauritanie et au Mali (tracé du Paris-Dakar). Ce matériel est destiné aux coopératives villageoises pour leur permettre d'atteindre l'auto-suffisance alimentaire. L'association est apolitique, sans position religieuse, et se veut ouverte à tous.



Afin de célébrer le trentième anniversaire de sa disparition, des émissions hommage lui sont consacrées par différentes chaînes :

Plusieurs stations de radiodiffusion consacrent la journée du 14 janvier 2016 à cette commémoration :





</doc>
<doc id="15664" url="https://fr.wikipedia.org/wiki?curid=15664" title="Groupe abélien">
Groupe abélien

Un groupe abélien (du nom de Niels Abel), ou groupe commutatif, est un groupe dont la loi de composition interne est commutative. Vu autrement, un groupe commutatif peut aussi être défini comme un module sur l'anneau commutatif ℤ des entiers relatifs ; l'étude des groupes abéliens apparaît alors comme un cas particulier de la théorie des modules.

On sait classifier de façon simple et explicite les groupes abéliens de type fini à isomorphisme près, et en particulier décrire les groupes abéliens finis.

On dit qu'un groupe formula_1 est abélien, ou commutatif, lorsque la loi de composition interne du groupe est commutative, c'est-à-dire lorsque :

pour tous formula_2

La loi d'un groupe commutatif est parfois notée additivement, c'est-à-dire par le signe +. Quand cette convention est adoptée, l'élément neutre est noté 0, le symétrique d'un élément "x" du groupe est noté –"x" et, pour tout entier relatif "n", on note :


Pour "x" élément d'un groupe abélien noté additivement et "n" entier relatif, on a défini plus haut l'élément "nx" du groupe. Le groupe apparaît ainsi comme un module sur l'anneau ℤ des entiers. Réciproquement, tout ℤ-module s'obtient de cette façon.

Ce procédé permet de concevoir la théorie des groupes commutatifs comme un cas particulier de la théorie des modules ; en sens opposé certains résultats énoncés dans le cadre des groupes commutatifs peuvent être généralisés à des classes de modules plus larges, notamment la classe des modules sur un anneau principal. Ainsi un recyclage de la preuve du théorème de structure des groupes abéliens de type fini permet de prouver un théorème analogue valable sur un anneau principal quelconque, lui-même applicable à de tout autres questions -notamment la classification à similitude près des matrices à coefficients dans un corps commutatif.

On appelle groupe abélien libre un groupe abélien qui est libre "en tant que" ℤ"-module" (et non pas en tant que groupe), c'est-à-dire qui possède une base.

Comme les espaces vectoriels, les groupes abéliens libres sont classifiés (à isomorphisme près) par leur rang, défini comme le cardinal d'une base, et tout sous-groupe d'un groupe abélien libre est lui-même abélien libre. Tout groupe abélien est donc isomorphe au quotient d'un groupe abélien libre par un sous-groupe abélien libre.

Ce sont, par définition, les groupes abéliens qui possèdent une partie génératrice finie : ainsi notamment les groupes abéliens finis et les réseaux d'un espace euclidien.

Les produits finis, les quotients, mais aussi les sous-groupes des groupes abéliens de type fini sont eux-mêmes de type fini. Un théorème de structure des groupes abéliens de type fini permet d'expliciter la liste complète de ces groupes à isomorphisme près ; il montre notamment que tout groupe abélien de type fini est un produit fini de groupes cycliques. En particulier, un groupe abélien de type fini qui n'a aucun élément d'ordre fini (hormis le neutre) est abélien libre.

Un groupe abélien "G" est dit divisible lorsque pour tout entier "n" > 0, "G" = "nG". Les archétypes en sont le groupe additif ℚ des nombres rationnels et les "p"-groupes de Prüfer. Un théorème de structure des groupes abéliens divisibles montre que tout groupe divisible est somme directe (finie ou infinie) de copies de ces modèles.

La catégorie de tous les groupes abéliens est le prototype d'une catégorie abélienne.

, étudiante de Tarski, a démontré en 1955 que la théorie du premier ordre des groupes abéliens est décidable (contrairement à la théorie du premier ordre des groupes).




</doc>
<doc id="15670" url="https://fr.wikipedia.org/wiki?curid=15670" title="FFT">
FFT

FFT peut faire référence à 



</doc>
<doc id="15678" url="https://fr.wikipedia.org/wiki?curid=15678" title="AbiWord">
AbiWord

AbiWord est un logiciel de traitement de texte pour les plates-formes Unix, Windows et BeOS lancé en 2002 et distribué sous licence GNU GPL v2.0. 

AbiWord était à l'origine un produit de la société SourceGear Corporation, mais il a été entièrement confié à une équipe de développeurs volontaires.

Il y a plusieurs filtres d'import/export tels que le format RTF, le HTML, le format de MS Word (.DOC) et celui de LaTeX (le TEX) ainsi que le format OpenDocument (.odt) qui est un format ISO depuis 2006. Le format d'AbiWord utilise la norme XML (fichier .abw), comme l'OpenDocument ou les nouveaux formats de MS Office.

AbiWord dispose d'un plugin de connexion à Wikipédia.

Plus rapide et plus léger que ses homologues, eux aussi libres, OpenOffice.org Writer et LibreOffice Writer, ce traitement de texte est cependant moins complet.


Pour les plates-formes officiellement supportées, la version 1.0 n'avait pas la possibilité de faire des tableaux, ce qui a été implémenté sur la version 2.0 à cause de la forte demande.



</doc>
<doc id="15679" url="https://fr.wikipedia.org/wiki?curid=15679" title="GTK+">
GTK+

GTK+ ("The GIMP Toolkit") est un ensemble de bibliothèques logicielles, c'est-à-dire un ensemble de fonctions permettant de réaliser des interfaces graphiques. Cette bibliothèque a été développée originellement pour les besoins du logiciel de traitement d'images GIMP. GTK+ est maintenant utilisé dans de nombreux projets, dont les environnements de bureau GNOME, Xfce, Lxde et ROX.

GTK+ est un projet libre (licence GNU LGPL 2.1) et multiplate-forme.

GTK+ est écrit en langage C et utilise pourtant le paradigme de la programmation orientée objet. Il est également possible d'utiliser GTK+ dans de nombreux autres langages de programmation: C++ (avec gtkmm), C# et Visual Basic (Gtk#), F# (Gtk#), Java (), JavaScript, Perl, Python, Vala, Ada, D, Fortran, Haskell, OCaml, , Ruby (), Rust, etc.

GTK+ est l'interface de différents environnements de bureau comme GNOME, Xfce ou encore ROX ce qui permet une intégration parfaite. Il s'intègre également dans d'autres environnements de bureau GNU/Linux grâce à un moteur de thème qui mime l'interface initiale. Il en va de même sur Windows et Mac OS X.

Parmi ces moteurs de thèmes, on retrouve Luna (Windows XP), Motif, Qt ou NeXTSTEP. Mais aussi des moteurs originaux comme Industrial par Novell ou Bluecurve par Red Hat.

GTK+2 a succédé à GTK+1.2, marquant une rupture de compatibilité. Ainsi, les applications basées sur GTK+1.2 et souhaitant utiliser GTK+2 ont dû être adaptées.

La bibliothèque intègre un nouveau système de rendu du texte utilisant Pango, un nouveau moteur de thème, une meilleure accessibilité en utilisant ATK (Accessibility Toolkit), prend en charge complètement Unicode en utilisant l'UTF-8 et une API plus flexible.

Quelques évolutions notables :

Sortie le 10 février 2011, GTK+ 3.0 est une version majeure qui rompt la compatibilité avec la série 2.xx (pour faciliter la transition, les deux versions peuvent être installées en parallèle). GTK+ 3.0 constitue notamment l'aboutissement du projet Ridley qui est un travail de longue haleine consistant à consolider dans GTK+ les fonctions préposées dans des bibliothèques éparses dont la maintenance n'est pas correctement assurée. Par ailleurs cette version offre une meilleure intégration de Cairo, une moindre dépendance à X11 (GTK+ 3 peut s'interfacer également avec Win32, Quartz, Wayland et HTML5/Broadway), l'utilisation de XInput2 ainsi qu'un système de thèmes basé sur le langage CSS.

Quelques évolutions notables :

Outre les applications au cœur de GNOME 3, les logiciels suivants sont compatibles GTK+ 3 : gThumb 3.0.0, Shotwell 0.12, Liferea 1.10, Pitivi 0.91, Synaptic 0.83, Subtitle Editor 0.50.0, LibreOffice 5.0.0, Eclipse 4.4, la version GNU/Linux de Firefox 46…

Xfce 4.12 et MATE 1.12 sont en grande partie portés sur GTK+3, avec la version 4.14 du premier qui achèverait le port. Thunderbird 47 serait basé sur GTK+3.

En février 2018, lors du GTK+ hackfest, a été lancé la nouvelle roadmap du développement de la version 4




</doc>
<doc id="15681" url="https://fr.wikipedia.org/wiki?curid=15681" title="Adam Smith">
Adam Smith

Adam Smith ( - ) est un philosophe et économiste écossais des Lumières. Il reste dans l’histoire comme le père des sciences économiques modernes, dont l'œuvre principale, publiée en 1776, "La Richesse des nations", est un des textes fondateurs du libéralisme économique. Professeur de philosophie morale à l'université de Glasgow, il consacre dix années de sa vie à ce texte qui inspire les grands économistes suivants, ceux que Karl Marx appellera les « classiques » et qui poseront les grands principes du libéralisme économique.

La plupart des économistes considèrent Smith comme « le père de l’économie politique » ; pourtant, certains, comme Joseph Schumpeter ou Murray Rothbard, l’ont défini comme un auteur mineur, considérant que son œuvre comportait peu d’idées originales et que ces dernières étaient pour beaucoup fausses.

Adam Smith est né le à Kirkcaldy. Dès sa naissance, Adam Smith est orphelin de père. Ce dernier, contrôleur des douanes, meurt deux mois avant la naissance de son fils. À l’âge de quatre ans, Adam Smith est enlevé par des bohémiens, qui, prenant peur en voyant l’oncle du jeune garçon les poursuivre, l’abandonnent sur la route où il sera retrouvé.

Élève particulièrement doué dès son enfance, bien que distrait, Adam Smith part étudier à Glasgow à l’âge de quatorze ans et y reste de 1737 à 1740. Il y reçoit, entre autres, l’enseignement de Francis Hutcheson, le prédécesseur d’Adam Smith à la chaire de philosophie morale. Smith sera très influencé par Hutcheson. Ayant obtenu une bourse, destinée en partie à former le clergé anglican écossais (le statut de cette bourse à l'époque de Smith n'est pas très établi), il part étudier à l’université d’Oxford. Il ne se plait guère dans cette université. Plus tard dans son livre la Richesse des Nations, il écrit : . Il choisit lui-même ses lectures, un choix qui lui vaut d’être menacé d’expulsion de l’université lorsqu’on découvre dans sa chambre le "Traité de la nature humaine" du philosophe David Hume, lecture jugée inconvenante à l’époque.

Choisissant une carrière universitaire, Smith obtient à l’âge de vingt-sept ans la chaire de logique à l’université de Glasgow et plus tard celle de philosophie morale. Le corps enseignant apprécie peu ce nouveau venu qui sourit pendant les services religieux et qui est de plus un ami déclaré de David Hume. Pourtant Smith devient relativement connu à Glasgow, où il participe à des cercles intellectuels, joue au whist le soir… Il est apprécié de ses étudiants : ses manières et son allure peu commune lui valent d’être imité, et on voit même de petits bustes de lui dans certaines librairies de la ville. Ses fréquents hochements de tête et sa diction maladroite dérivaient d’une maladie nerveuse dont il souffrit tout au long de sa vie.

Au-delà de son excentricité, la célébrité d’Adam Smith provient aussi de son travail et de la parution en 1759 de la "Théorie des sentiments moraux", œuvre de philosophie qui le fait connaître en Grande-Bretagne et même en Europe. Dans ce livre, il énonce les causes de l'immédiateté et de l'universalité des jugements moraux. Smith affirme que l’individu partage les sentiments d'autrui par un mécanisme de sympathie. Smith étend ce point de vue en évoquant un hypothétique spectateur impartial avec lequel nous serions en permanence en situation de sympathie. On discute vite des thèses de ce livre un peu partout, et plus particulièrement en Allemagne.

Adam Smith, alors qu’il était professeur de logique, a écrit d’autres ouvrages qui ne seront publiés qu’après sa mort. Un des plus connus est son "Histoire de l’astronomie". L’histoire de l’astronomie à proprement parler ne représente qu’une petite partie de l’ouvrage, et s’arrête à Descartes, car en fait Smith s’intéresse davantage aux origines de la philosophie. Selon Smith, l’esprit prend plaisir à découvrir les ressemblances entre les objets et les observations, et c’est par ce procédé qu’il parvient à combiner des idées et à les classifier. Dans la succession des phénomènes constatés, l’esprit recherche des explications plausibles. Lorsque les sens constatent une succession qui rompt avec l’accoutumance de l’imagination, l’esprit est surpris, et c’est cette surprise qui l’excite et le pousse vers la recherche de nouvelles explications.

La philosophie, en exposant les chaînes invisibles qui lient tous ces objets isolés, s’efforce de mettre l’ordre dans ce chaos d’apparences discordantes, d’apaiser le tumulte de l’imagination, et de lui rendre, en s’occupant des grandes révolutions de l’univers, ce calme et cette tranquillité qui lui plaisent et qui sont assortis à sa nature. » Adam Smith, "Histoire de l’Astronomie"

Les convictions religieuses d’Adam Smith ne sont pas connues avec précision, et il est souvent considéré comme un déiste à l’image de Voltaire qu’il admirait. Ronald Coase a critiqué cette thèse et note que, bien que Smith fasse référence à un « grand architecte de l’univers », à la Nature, ou encore à la fameuse « main invisible », il ne parle que très rarement de Dieu, et surtout il explique que les merveilles de la nature attisent la curiosité des hommes, et que la superstition est la façon la plus immédiate de satisfaire cette curiosité, mais qu’à terme, elle laisse la place à des explications plus usuelles et donc plus satisfaisantes que celles de l’intervention des dieux.
L’ouvrage de Smith est remarqué par Charles Townshend, homme politique important et chancelier de l’Échiquier de 1766 à sa mort un an plus tard. Ce dernier avait épousé en 1754 lady Caroline Campbell, veuve de lord Dalkeith, duc de Buccleuch, avec lequel elle a déjà deux fils. Townshend cherche un tuteur pour le fils aîné de son épouse qui, comme tous les jeunes aristocrates anglais de l’époque, doit faire un Grand Tour, et propose à Smith d’accompagner celui-ci dans son périple.

Smith et son élève quittent la Grande-Bretagne pour la France en 1764. Ils restent dix-huit mois à Toulouse, ville dont la société lui semble ennuyeuse. Ils séjournent ensuite dans le sud de la France puis vont à Genève. Là il rencontre et enthousiasme Voltaire, ainsi qu’une marquise dont il doit repousser les avances. Pendant ce long séjour dans le Sud-Ouest de la France et en Provence, Smith s’ennuie et entame la rédaction d’un traité d’économie, sujet sur lequel il avait été amené à dispenser des cours à Glasgow. Après leur sejour à Genève, Smith et son élève arrivent à Paris. C’est là qu’il rencontre l’économiste le plus important de l’époque, le médecin de Madame de Pompadour, François Quesnay. Quesnay avait fondé une école de pensée économique, la physiocratie, en rupture avec les idées mercantilistes du temps. Les physiocrates prônent que l’économie doit être régie par un ordre naturel : par le laissez-faire et le laissez-passer. Ils affirment que la richesse ne vient pas des métaux précieux, mais toujours du seul travail de la terre et que cette richesse extraite des sols circule ensuite parmi différentes classes stériles (les commerçants, les nobles, les industriels). Adam Smith est intéressé par les idées libérales des physiocrates, mais ne comprend pas le culte qu’ils vouent à l’agriculture. Ayant vécu à Glasgow, il a conscience de l’importance économique de l’industrie.

En 1766, le voyage de Smith et de son protégé s’achève, le frère de ce dernier ayant été assassiné dans les rues de Paris. Smith rentre à Londres, puis à Kirkcaldy. Il ne se rend que rarement à Londres pour participer aux débats de son temps. Il y rencontre Benjamin Franklin dont l’influence lui fera dire que les colonies américaines sont une nation qui « deviendra très probablement la plus grande et la plus formidable qui soit jamais au monde ». Comme lui, Adam Smith a rencontré au sein de la Lunar Society une génération d'entrepreneurs anglais et écossais dont les inventions vont provoquer dans le dernier quart du siècle une vague de confiance dans la croissance économique et la capacité des entreprises à innover.

En 1776, après y avoir consacré plusieurs années, Smith publie son traité d’économie politique, celui qui va faire sa renommée et qu’il intitule "Recherches sur la nature et les causes de la richesse des nations" (titre souvent abrégé en "Richesse des nations").

En 1778, il devient commissaire aux douanes à Édimbourg, ce qui lui assure une retraite confortable. Il passe les douze dernières années de sa vie en célibataire, vivant avec sa mère (jusqu’à la mort de celle-ci à quatre-vingt-dix ans).

À la fin de sa vie, il devient recteur de l’université de Glasgow, et voit son œuvre traduite en espagnol, allemand, danois, italien et français. Le premier ministre Pitt le Jeune lui déclare un jour : « Nous sommes tous vos élèves. »

Smith meurt le 17 juillet 1790 à l’âge de soixante-sept ans, dans une relative indifférence vu les troubles révolutionnaires qui agitent alors la France et menacent la campagne anglaise. Il est enterré simplement à Canongate, on peut lire sur la pierre tombale : .

Bien que connu de son vivant pour ses œuvres de philosophie, la postérité a surtout retenu son talent d’économiste. Les sciences économiques l’ont très rapidement élevé au rang de fondateur. Le courant libéral, autant économique que politique, en a fait un de ses auteurs de référence. Qu’y a-t-il dans "La richesse des nations" qui justifie une telle postérité ? Paradoxalement, Adam Smith n’a apporté presque aucune idée nouvelle à la philosophie et à l’économie dans son ouvrage. La plupart de ces idées ont déjà été approchées par des philosophes et des économistes comme François Quesnay, John Locke, William Petty, David Hume (avec qui il entretenait des relations amicales), Turgot ou encore Richard Cantillon. La "Richesse des nations" mentionne plus d’une centaine d’auteurs auxquels sont empruntées les différentes analyses.

Ce qui donne toute sa valeur à l’œuvre de Smith n’est donc pas son originalité, mais la synthèse de la plupart des idées économiques pertinentes de son temps. La plupart des auteurs qui l’ont précédé ont développé des idées brillantes, mais distinctes de tout système global cohérent, et souvent associées à d’autres conceptions économiques beaucoup moins pertinentes (comme la stérilité de l’industrie chez les physiocrates). Smith corrige les erreurs "a posteriori" évidentes des auteurs qui l’ont précédé, il approfondit leurs idées et les lie entre elles pour tisser une compilation cohérente. Son mode de pensée repose souvent sur le principe suivant : pour Smith ce qui est sage pour le chef de famille ne peut pas être une folie dans la gestion d’un empire.

Dans la "Théorie des sentiments moraux" (publié en 1759), il tente de décrire les principes de la nature humaine pour comprendre comment ils suscitent la création d’institutions communes et un comportement social.

Smith s’interroge sur l’origine de la capacité qu’ont les individus de porter des jugements moraux sur les autres mais aussi sur leur propre attitude. Smith commence par affirmer, contre les théories de l'égoïsme et de l'intérêt, le caractère désintéressé de certains de nos jugements. Selon lui, chacun de nous a en lui-même un , capable de se placer à distance de ses propres passions et intérêts, afin de se constituer en de soi-même, capable de témoigner son approbation ou sa désapprobation morale à l'égard de ses propres actes, et dont nous ne pouvons ignorer le jugement. Certains voient dans cette thèse une anticipation du concept de surmoi (lequel est pourtant une instance inconsciente).

Dans la "Théorie des sentiments moraux", la sympathie au sens d’empathie, de capacité de comprendre un autre en se mettant en quelque sorte à sa place, occupe une place centrale. Pour Smith, l’homme dans ses actions doit tenir compte du point de vue des spectateurs réels ou du spectateur impartial, dans le cadre d’un double processus de sympathie. D’une part, les spectateurs s’identifient à l’acteur et arrivent à comprendre les motifs de son action; d’autre part, l’acteur s’identifie aux spectateurs qui le contemplent et perçoit leurs sentiments à son égard. Il résulte de ce double processus de décentrement « un champ de connaissances communes à l’acteur et aux spectateurs qui engendrent l’ensemble du système des règles (dont celles de justice) qui permettent la maîtrise des passions ». Le problème est que ce double décentrement n’est pas facilement accessible à tous. Aussi, Diatkine suggère-t-il que c’est parce que Smith avait conscience de ces difficultés qu’il a écrit la "Richesse des nations" où, dans le domaine économique, le marché, d’une certaine façon, se substitue au spectateur impartial, ou du moins oblige les acteurs économiques à tenir compte les uns des autres.

Avant Smith, les économistes avaient proposé deux grandes définitions de la richesse. Smith reprend, dans le Livre IV de la "Richesse des Nations", une critique des mercantilistes que Schumpeter qualifiera d'« inintelligente », à savoir que la richesse est définie par la possession de métaux et de pierres précieuses, car ce sont eux qui permettent de financer les guerres, ce sont eux qui ont une valeur durable dans le temps et reconnue partout. Il s’agit d’une richesse essentiellement princière. « Jamais les mercantilistes n'ont soutenu cela », souligne Schumpeter. Pour les physiocrates, la production agricole est la seule source de richesse, les autres activités n’étant vouées qu’à la transformation de cette richesse première.

Pour Smith, la richesse de la nation, c’est l’ensemble des produits qui agrémentent la vie de la nation tout entière, c’est-à-dire de toutes les classes et de toutes leurs consommations. L’or et la monnaie ne constituent donc plus la richesse, elles n’ont en elles-mêmes aucune autre utilité que celle d’intermédiaire de l’échange. Adam Smith rejoint donc la vision de la monnaie proposée par Aristote dans l’Antiquité. Pour lui, l'origine de la richesse est le travail des hommes. Il pose ainsi les bases de la doctrine de la valeur travail, qui sera pleinement théorisée au siècle suivant par David Ricardo.

Cette richesse, comment est-elle produite, et comment peut-on l’accroître ? En tentant de répondre à cette question, Smith propose une analyse de la croissance économique. Analysant l’économie de son temps, il distingue trois grandes causes de l’enrichissement de la nation : la division du travail, l’accumulation du capital, et la taille du marché.

La division du travail consiste en une répartition toujours plus spécialisée du processus de production de sorte que chaque travailleur peut devenir spécialiste de l’étape de la production à laquelle il se consacre, accroissant donc l’efficacité de son travail, sa productivité.

Ce qui permet la division du travail, c’est l’échange. Les hommes se répartissent les tâches pour survivre, puis s’échangent les fruits de leur travail. Plus les échanges s’accroissent, plus les hommes sont à même de se consacrer à une tâche particulière et d’espérer des autres la satisfaction de leurs autres besoins.

Il existe toutefois un obstacle à la division du travail, c’est la taille du marché. Plus les hommes sont nombreux, plus ils peuvent se diviser les tâches. Si le marché n’est pas assez grand, le surplus de production permis par une division du travail toujours accrue ne trouvera pas acheteur.

Par ailleurs, la division du travail n’a pas que des avantages. Smith note qu’elle peut avoir des effets désastreux sur l’intellect des ouvriers qui sont abrutis par la répétition de gestes d’une simplicité toujours plus grande. Il invite donc l’État à faire quelque chose pour qu’il en soit autrement, peut-être à mettre en place un système éducatif. Ce faisant, Adam Smith approche la notion d’externalité que développeront plus tard les économistes et qui justifiera en partie l’intervention de l’État.

Pour illustrer ce principe de division du travail, Adam Smith a employé l'exemple d'une manufacture d'épingles, probablement repris à Henri-Louis Duhamel du Monceau, ou bien en se référant à l'article « épingles » de l'encyclopédie de Diderot et d'Alembert (1755) dont on sait que nombre d'articles s'inspirent directement de la "Description des Arts et Métiers".

La notion de « main invisible » est susceptible d'une double interprétation suivant que l'on suppose qu'il y a une discontinuité dans l'œuvre de Smith entre la "Théorie des sentiments moraux" et la "Richesse des nations" (approche dite parfois leibnizienne) ou non. Les analystes de Smith ont longtemps débattu sur une éventuelle opposition entre les thèses exposées dans ces deux ouvrages. Ce débat est connu depuis Joseph Schumpeter comme . D’un côté, la "Théorie des sentiments moraux" donne une explication morale au fonctionnement harmonieux de la société, centrée sur le concept de « sympathie », tandis que la "Richesse des nations" l’explique par un mécanisme économique reposant sur l'intérêt personnel. De multiples interprétations ont été données de ce problème. Si, au , on tendait à considérer ces deux ouvrages comme contradictoires, les chercheurs de nos jours soulignent en général la continuité de la pensée de Smith.

Cette approche est celle du libéralisme classique et aurait été diffusée . Dans cette version, la « main invisible » serait une métaphore par laquelle Smith signifierait que les marchés sont autorégulateurs et conduiraient à l'harmonie sociale.

Selon cette interprétation, comme dans la "Théorie des sentiments moraux", Smith se demanderait dans la "Richesse des nations" comment survit une communauté où chaque individu se préoccupe avant tout de son intérêt personnel. Toutefois, il avancerait une explication nouvelle et différente de celle proposée dans son ouvrage précédent.

En fait, les actions des individus seraient coordonnées et rendues complémentaires par le marché et ce qu’il appelle la « main invisible ». Selon Smith, les « lois » du marché, associées à la recherche de l'intérêt personnel des agents économiques, conduiraient à un résultat inattendu : l’harmonie sociale. La confrontation des intérêts individuels mène naturellement à la concurrence, et cette dernière amène les individus à produire ce dont la société a besoin. En effet la forte demande provoque l’envolée des prix, cette dernière amène donc naturellement les producteurs avides de profits à produire le bien recherché. La recherche de l'intérêt personnel d’un individu seul peut être nuisible, mais la confrontation des intérêts personnels mène à l’intérêt général. Si un producteur tente d’abuser de sa position et fait monter les prix, des dizaines de concurrents tout aussi avides de profit en profiteront pour conquérir le marché en vendant moins cher. La main invisible oriente donc le travail vers l’usage le plus utile à la société car c’est aussi celui qui est le plus rentable. Elle règle avec justesse aussi bien les prix, que les revenus et les quantités produites.

Adam Smith avancerait donc l’idée d’un marché « autorégulateur » que n’auraient pas eu les physiocrates. Paradoxalement ce mécanisme, paradigme du libéralisme économique, est très contraignant pour l’individu qui se voit imposer aussi bien son activité que sa rémunération. Il ne s’agit pas de faire ce que l’on veut, car le non-respect des recommandations du marché mène à la ruine. En fait, « l’individu est conduit par une main invisible à remplir une fin qui n’entre nullement dans ses intentions ».

L’idée que l’économie puisse être régulée par des mécanismes amoraux n’est pas nouvelle. Bernard Mandeville l’avait déjà fait remarquer dans sa "Fable des Abeilles", où il expliquait comment les vices privés, c’est-à-dire la consommation de richesses, se révélaient être des vertus collectives, susceptibles de stimuler l’activité économique.

Mais cette vision est contestée de nos jours. Tout d'abord, pour Heilbroner, Adam Smith n'est pas l’apôtre d’un capitalisme sauvage. Le principe du marché tel qu’il le décrit s’applique à l’économie artisanale de son époque. Il en a conscience et dénonce les industriels qui par les ententes et les monopoles tentent de contourner la loi du marché à leur seul profit. Ce n’est donc pas l’État qui menace le plus l’économie de marché mais plutôt les industriels, et il revient à l’autorité souveraine de s’assurer du respect des règles du marché. Noam Chomsky émet une double critique de cette version de la main invisible : d'une part, il souligne l'absence de toute référence à la "Théorie des sentiments moraux", ce qui pour lui tend à montrer que nous sommes censés vénérer Adam Smith mais non le lire, et d'autre part, partant du passage où Smith traite de la « main invisible » dans la "Richesse des nations", il met en exergue que chez Smith, « à égalité de profit ou à peu près », l'homme, guidé par son propre intérêt et une plus grande sûreté dans ses investissements, choisira le succès de l'industrie nationale et sera de la sorte conduit par une main invisible à servir l'intérêt public, ce qui n'était pas son but, réflexion qui lui semble aller à l'encontre de la théorie du libre-échange global soutenue par le courant économique libéral, mais aussi un très grand nombre d'économistes.

Dans cette approche, au contraire, par rapport à David Hume, Leibniz ou Malebranche, . La conséquence en est que l'ordre physique, c'est-à-dire l'ordre de la richesse matérielle ne se confond pas avec l'ordre moral entendu chez Smith comme harmonie ou bonheur intérieur. D'où alors que la main invisible dans l'approche dichotomique conduit automatiquement et facilement à l'harmonie, ici, l'harmonisation doit porter à la fois sur le monde physique de la richesse matérielle et sur le monde intérieur. Il en découle l'impossibilité de réduire l'être humain à un simple mécanisme qui répond aux stimuli de l'intérêt, et la nécessité au contraire à ce qu'il utilise au mieux ses sentiments et sa raison.

Toutefois, Smith s'inscrit dans la tradition de Newton où le monde reste au-delà de ce que la raison peut concevoir. Elle ne permet pas, comme chez Malebranche, de concevoir ce que Dieu aurait pu concevoir de meilleur. Malgré tout, l'homme partant des observations de l'existant peut d'une certaine façon le rendre meilleur. Pour Michaël Biziou, l’intervention du gouvernement et de la loi chez Smith se trouvent justifiées par le fait que son libéralisme prône le « perfectionnement intentionnel d’un ordre sub-optimal non intentionnel ». Pour cet auteur, ceux qui soutiennent la thèse d’une autorégulation optimale du marché confondent deux idées distinctes : l’idée des conséquences inattendues et celle du « cours naturel des choses », c’est-à-dire qu’ils ne distinguent pas « naturel » au sens de non intentionnel, du « naturel » de « cours naturel des choses » qui lui se réfère à un idéal.

Si donc chez Smith la notion de main invisible traduit bien l'existence de conséquences inattendues, celles-ci ne sont pas forcément favorables. Par contre, connaître si les conséquences sont positives ou négatives sert à nourrir la faculté de juger des hommes dont l'usage contribue à leur bonheur intérieur ou moral. Alors que dans la tradition du libéralisme classique, la main invisible est d'une certaine façon organique, ici, elle s'inscrit dans un processus plus réflexif et plus politique qui, sur bien des points, la rapproche des problématiques sociales libérales.

Grâce aux lois du marché, Smith décrit ensuite une dynamique économique qui doit conduire la société vers l’opulence. Faisant la louange de l’épargne, qui n’est que la manifestation de la frugalité et du renoncement au bien-être immédiat afin que survive et prospère l’industrie, Smith voit dans l’accumulation du capital, c’est-à-dire l’investissement en machines, l’occasion de décupler la productivité et d’accroître la division du travail.

Pour Adam Smith, l’accumulation des machines implique une augmentation des besoins en main-d’œuvre, et donc une montée des salaires. Mais, selon lui, la loi du marché gouverne aussi la démographie. La hausse des salaires permet aux pauvres de faire vivre leurs enfants et donc d’accroître à terme la main-d’œuvre disponible, provoquant alors une baisse des salaires vers leur niveau antérieur, et permettant que s’accroissent de nouveau le profit et donc l’accumulation. Entre-temps, la production s’est accrue, la mortalité infantile a régressé. À notre époque, l’idée que la démographie est régulée par le marché peut sembler naïve, mais Smith note qu’au , « il n’est pas rare, dans les Highlands d’Écosse, qu'une mère ayant engendré vingt enfants n’en conserve que deux vivants ».

Il semble alors que la régulation de la société par le marché mène à l’accroissement des richesses, et à un retour régulier des salaires vers le minimum vital. Smith parle ainsi d'un « salaire de subsistance » qui permet d'assurer la satisfaction des besoins physiologiques de l'être humain, ainsi que ceux de sa descendance, laquelle est nécessaire pour fournir la main-d'œuvre future. Est-ce à dire que les niveaux de vie ne peuvent progresser ? Non, car l’accumulation tire toujours les salaires vers le haut, de sorte que la notion même de « minimum vital », considérée comme une variable sociologique (et non comme un phénomène biologique), évolue vers le haut. Pourquoi ? Parce que, la population s’accroissant, le capital s’accumulant, la division du travail s’approfondissant, la production (et donc la richesse) par habitant doit augmenter.

Adam Smith constate d'abord que, en Angleterre, « les bons effets naturels du commerce des colonies, aidés de plusieurs autres causes ont surmonté en grande partie les mauvais effets du monopole. Ces causes, à ce qu'il semble, sont la liberté d'exporter, franches de droit, presque toutes les marchandises qui sont le produit de l'industrie nationale à presque tous les pays étrangers, et la liberté illimitée de les transporter d'un endroit de notre pays à l'autre, sans être obligé de rendre compte à aucun bureau public, sans avoir à essuyer des questions ou des examens d'aucune espèce ».

Par ailleurs, la thèse de Smith sur le commerce international se fonde sur une évidence "a priori" : il est prudent « de ne jamais essayer de faire chez soi la chose qui coûtera moins à acheter qu’à faire. »

Smith reprend en fait une critique du mercantilisme entamée par David Hume en 1752. Hume pensait que les excédents commerciaux, en accroissant la quantité de monnaie sur le territoire, provoquaient une hausse des prix et donc une baisse de la compétitivité induisant un déficit commercial, de sorte que les balances commerciales s’ajustaient naturellement, et qu’il était inutile de poursuivre l’excédent.

La démonstration formelle des avantages du libre-échange est différente chez Smith. Elle repose sur la notion d’avantage absolu. Si une première nation est meilleure dans la production d’un premier bien, tandis qu’une seconde est meilleure dans la production d’un second bien, alors chacune d’entre elles a intérêt à se spécialiser dans sa production de prédilection et à échanger les fruits de son travail.

Quelques années avant la parution du renommé "Recherches sur la nature et les causes de la richesse des nations" (1776), Adam Smith avait été témoin de l'éclatement d'une bulle financière qui avait décimé le système bancaire d'Édimbourg : sur trente banques, seules trois avaient survécu. Pour lui, livrée aux seules forces du marché, la finance faisait courir de graves dangers à la société.

Adam Smith stipule donc expressément que la logique d'un marché libre et concurrentiel ne doit pas s'étendre à la sphère financière. D'où une nécessaire exception financière au principe de la liberté d'entreprendre et de commercer, et la nécessité d'un cadre réglementaire strict : .

Dans le livre V de la "Richesse des nations", Adam Smith définit enfin les fonctions d’un État gardien de l’intérêt général (et non de l’intérêt du prince). Il s’agit d’abord des fonctions dites régaliennes (police, armée, justice). L’État doit protéger les citoyens contre les injustices et les violences venant du dedans comme du dehors.

L’analyse du droit public de Smith s’inscrit dans la logique de Grotius, Pufendorf et Hobbes, mais Adam Smith opère dans ses cours à Glasgow (1762-1763) une rupture nette dans sa définition des fonctions de la « police », c’est-à-dire la protection et la régulation de l’ordre intérieur. Or, à l’époque, la régulation de l’ordre intérieur est étroitement liée à l’abondance et au prix des vivres ; garantir l'ordre public, c'est garantir l'approvisionnement en vivres. La police impliquerait donc l’intervention économique, ce à quoi s’oppose Smith dans ses cours à Glasgow en expliquant que l’intervention économique est contre-productive vu qu’elle nuit à l’opulence des denrées.
Adam Smith définit donc les devoirs régaliens dans leur sens moderne : la protection des libertés individuelles fondamentales contre les agressions du dedans et du dehors. Pour autant, Smith ne refuse pas à l’État toute intervention économique.<br> 
" "Dans le système de la liberté naturelle , le souverain n'a que trois devoirs à remplir; trois devoirs d'une haute importance, mais clairs, simples et à la portée d'une intelligence ordinaire.<br>
"Le premier, c'est le devoir de défendre la société de tout acte de violence ou d'invasion de la part des autres sociétés indépendantes."<br>
"Le deuxième, c'est le devoir de protéger autant qu'il est possible chaque membre de la société contre l'injustice ou l'oppression de tout autre membre, ou bien le devoir d'établir une administration exacte de la justice."<br>
"Et le troisième, c'est le devoir d'ériger et d'entretenir certains ouvrages publics et certaines institutions que l'intérêt privé d'un particulier ou de quelques particuliers ne pourrait jamais les porter à ériger ou à entretenir, parce que jamais le profit n'en rembourserait la dépense à un particulier ou à quelques particuliers, quoiqu'à l'égard d'une grande société ce profit fasse beaucoup plus que rembourser les dépenses." "

Avec ces « devoirs », Smith justifie clairement un certain interventionnisme de l’État dans la vie économique. Il définit aussi ce que la science économique appellera plus tard le « bien commun ». Selon Smith, le marché ne peut pas prendre en charge toutes les activités économiques, car certaines ne sont rentables pour aucune entreprise, et pourtant elles profitent largement à la société dans son ensemble. Ces activités doivent alors être prises en charge par l’État. Il s’agit surtout des grandes infrastructures, mais l’analyse peut s’étendre aux services publics.

On peut aussi ajouter la fourniture d'une éducation aux pauvres. 

Dans un article publié en 1927, Jacob Viner, professeur d'économie à l'université de Chicago, écrivait ainsi qu'« Adam Smith n'était pas un avocat doctrinaire du laisser-faire », laissant beaucoup de place à l'intervention gouvernementale, tenant compte des circonstances pour décider si une politique libérale est bonne ou mauvaise. Il soulignait : « Les avocats modernes du laisser-faire qui s'opposent à la participation du gouvernement dans les affaires parce qu'elle constituerait un empiètement sur un champ réservé par la nature à l'entreprise privée ne peuvent trouver d'appui à cet argument dans la Richesse des nations » (Viner, 1927: 227).

À travers la "Richesse des nations", Adam Smith prend de nombreuses positions sur les débats politiques de son temps et tente, à la lumière de l’économie, de contribuer à l’idéal des "Lumières" du .

Sur la question de l’esclavage, il explique que le travail des esclaves est en fait bien plus coûteux que celui des hommes libres, motivés par l’appât du gain et guidés par les forces du marché. « L’expérience de tous les temps et de toutes les nations, écrit Adam Smith, s’accorde, je crois, pour démontrer que l’ouvrage fait par des esclaves, quoiqu’il paraisse ne coûter que les frais de leur subsistance, est au bout du compte le plus cher de tous. »

C’est dans une logique semblable qu’il s’attaque au colonialisme, entreprise coûteuse d’exploitation.

Ce [les colonies] sont tout au plus des dépendances accessoires, une espèce de cortège que l’empire traîne à sa suite pour la magnificence et la parade.

Il consacre une centaine de pages à dénoncer le système économique mercantiliste qui dicte jusque-là la politique des grandes nations.

Adam Smith n’épargne pas non plus l’aristocratie terrienne. La critique des propriétaires fonciers oisifs, les rentiers, sera surtout l’œuvre de David Ricardo, mais dès 1776 Smith faisait remarquer : 

Adam Smith n’a pas fait naître le libéralisme économique. Déjà Montesquieu écrivait en 1748 dans "De l'esprit des lois": « "Il se trouve que chacun va au bien commun, croyant aller à ses intérêts particuliers". » Puis le physiocrate Vincent de Gournay avait demandé aux gouvernants de « "laisser faire les hommes" » et de « "laisser passer les marchandises" », mais il ne s’agissait alors que de dénoncer le système des corporations et d’encourager la libre circulation des grains dans les provinces d’un unique royaume. Et Turgot écrivait en 1759 dans l'Éloge de Vincent de Gournay : « "L’intérêt particulier abandonné à lui-même produira plus sûrement le bien général que les opérations du gouvernement, toujours fautives et nécessairement dirigées par une théorie vague et incertaine" ». On considère néanmoins que c’est Adam Smith qui, en faisant de l’initiative privée et égoïste le moteur de l’économie et le ciment de la société, achève d’énoncer le dogme libéral.

Sur le plan intellectuel, l’influence la plus directe d’Adam Smith se manifeste dans l’inspiration que trouvent dans la "Richesse des nations" les économistes des décennies suivantes. Parmi eux se réclament de Smith des auteurs dont la célébrité deviendra presque aussi grande comme Thomas Malthus, David Ricardo et John Stuart Mill en Angleterre, Jean-Baptiste Say et Frédéric Bastiat en France. Ces auteurs libéraux donnent une impulsion sans antécédents à la science économique en discutant dans leurs ouvrages les avis de celui qu’ils nomment le Smith. Karl Marx, lui-même admirateur d’Adam Smith, les qualifie de « classiques », bien que ses propres travaux, fondés sur la méthode « scientifique » et rigoureuse des classiques, l’amènent à prôner une doctrine, le communisme, opposée au libéralisme.

Le plus étonnant est de retrouver dans la "Richesse des nations" nombre de petites phrases qui semblent annoncer les grandes idées économiques des siècles futurs. Quelques exemples :

Au début des années 1980, les « théoriciens de l’offre » avancèrent l’idée que des taux de prélèvements obligatoires trop élevés, en décourageant l’activité, peuvent finalement engendrer des recettes fiscales inférieures à celle d’un impôt plus modéré. Cette théorie modélisée par la courbe de Laffer, popularisée par la célèbre formule « trop d’impôt tue l’impôt » et qui motiva une partie de la politique économique de Ronald Reagan n’avait rien de nouveau. En 1776, Smith écrivait déjà :

L’impôt peut entraver l’industrie du peuple et le détourner de s’adonner à de certaines branches de commerce ou de travail, qui fourniraient de l’occupation et des moyens de subsistance à beaucoup de monde. Ainsi, tandis que d’un côté il oblige le peuple à payer, de l’autre il diminue ou peut-être anéantit quelques-unes des sources qui pourraient le mettre plus aisément dans le cas de le faire.

À la fin du , le sociologue américain Thorstein Veblen critique les postulats économiques sur le comportement du consommateur. Pour lui, le consommateur accroît souvent sa consommation d’un bien quand son prix augmente, et ce par effet de snobisme dans un objectif de démonstration sociale. Mais Smith l’avait écrit cent cinquante ans plus tôt :

Pour la plupart des riches, le principal plaisir qu’ils tirent de la richesse consiste à en faire étalage et à leurs yeux leur richesse est incomplète tant qu’ils ne paraissent pas posséder ces marques décisives de l’opulence que nul ne peut posséder sauf eux-mêmes.

Mais plus généralement c’est le concept du marché, comme mécanisme de base de la société tout entière qui devint le sujet de prédilection des économistes qui depuis lors s’intéressent à ses imperfections, à ses incapacités, et à son inexistence relative dans l’économie réelle où les situations de monopoles sont courantes.

Si nombre d’économistes admirent Smith, c’est peut-être parce que nombre de courants peuvent y voir le père de leurs idées. Les libéraux le saluent comme celui qui a mis en lumière l’importance du marché comme mode de régulation automatique de la société, ceux recommandant une intervention modérée de l’État peuvent pourtant rappeler que Smith en a aussi souligné les imperfections éventuelles et a appelé la puissance publique à les corriger. Bien qu’à l’opposé des idées politiques de Smith, Karl Marx lui-même s’en inspire en développant toute une doctrine fondée sur la théorie classique de la valeur.

Pour autant, l’œuvre de Smith n’est pas exempte d’imperfections et la science économique a su se placer en rupture avec certains de ses postulats. La théorie de l’avantage absolu s’est révélée être un argument relativement faible en faveur du libre-échange, inférieur aux analyses de David Hume sur la balance des paiements qui l’avaient précédée, mais surtout à la théorie de l’avantage comparatif avancée par David Ricardo en 1817 dans "Des principes de l'économie politique et de l'impôt". Dans le monde de Smith, deux pays n’avaient avantage à échanger que lorsque chacun d’entre eux disposait d’un avantage sur l’autre dans une production donnée. Aucun argument n’était présenté pour les pays "a priori" désavantagés. Ce sera donc la démonstration de Ricardo selon laquelle même le pays le moins compétitif du monde trouve intérêt au commerce international qui sera retenu comme argument principal du courant libre-échangiste.

De même la théorie de la « valeur travail » développée par Smith et adoptée par la plupart des classiques anglo-saxons et les marxistes, en opposition avec la conception subjective de Démocrite, des scolastiques et des classiques français (Turgot, Say, Condillac), a été abandonnée par la science économique néoclassique à partir de la fin du . Toute l’analyse microéconomique repose sur l’idée que la valeur d’un bien est fondée sur l’utilité que nous apporte la consommation d’une unité supplémentaire de celui-ci, c’est-à-dire sur son utilité marginale. Or Smith avait écarté l’utilité comme facteur de valeur des produits au profit du travail nécessaire à leur production.

Enfin Adam Smith n’a semble-t-il compris que partiellement les grandes transformations économiques qu’allait apporter la Révolution industrielle. On est étonné de son postulat selon lequel l’achat de machine accroît le besoin de main-d’œuvre car on a depuis tendance à postuler le contraire. L’idée selon laquelle les individus sont guidés par leur intérêt individuel peut aussi sembler en contradiction avec la société industrielle du où les rapports socio-économiques sont moins le fait des individus isolés que des classes sociales auxquelles ils disent s'identifier : la bourgeoisie et le prolétariat. Pour Karl Polanyi, qui critique le paradigme emprunté à Smith du « sauvage adonné au roc », « les idées d'Adam Smith sur la psychologie économique du premier homme étaient aussi fausses que celles de Rousseau sur la psychologie politique du sauvage ».

Murray Rothbard, économiste de l'école autrichienne d'économie et théoricien de l'anarcho-capitalisme, voit de façon plus dure dans l'importance supposée de Smith un . Il fait plutôt remonter l'origine de l'économie moderne à Richard Cantillon.

Dans la sphère politique et industrielle, les admirateurs de Smith sont nombreux. Dix ans après la parution de la "Richesse des nations", les gouvernements français et britannique signent en 1786 le Traité d'Eden qui instaure un certain libre-échange entre les deux pays. Déséquilibré car accordant plus d'avantages à la Grande-Bretagne industrielle qu'à la France, réduite à exporter des produits primaires, il sera remis en cause par la Révolution française et il faudra attendre 1860 pour qu'un traité de libre-échange soit signé entre la France et la Grande-Bretagne.

Aux États-Unis, le secrétaire d’État au Trésor, Alexander Hamilton espère fonder une nation industrieuse. Son célèbre "Rapport sur les manufactures" repose en grande partie sur une lecture critique des thèses de Smith, s’en inspirant largement mais critiquant son laissez-faire jugé excessif et souhaitant protéger l’industrie américaine balbutiante du libre-échange.

En Angleterre, l’idée selon laquelle la recherche du profit individuel se fait au profit de la nation tout entière devient le dogme de la bourgeoisie capitaliste, qui y trouve une justification. De cette façon, les idées de Smith ont été profondément détournées. Le concept de la main invisible, qui devint si chère aux défenseurs de l’entrepreneuriat capitaliste, ne s’appliquait qu’à l’économie essentiellement artisanale de l’époque d’Adam Smith, qui se méfiait lui-même des industriels et de leurs manigances visant à établir des ententes et des monopoles afin de s’affranchir des contraintes du marché et d’imposer leurs prix. Bien que caricaturée, l’analyse smithienne du marché permit une longue et progressive transition des législations économiques, notamment en Angleterre, qui furent favorables à la Révolution industrielle et à la libre-entreprise.

Quelle étendue peut-on prêter à l’influence d’Adam Smith sur le monde ? L’économiste britannique John Maynard Keynes écrit au :

Qu’elles soient justes ou erronées, les idées des théoriciens de l’économie et de la politique exercent une puissance supérieure à celle qu’on leur prête communément. En fait, ce sont elles qui mènent le monde ou peu s’en faut. Tel pragmatique déclaré, qui se croit libre de toute influence théorique, suit en fait aveuglément un économiste défunt. Tel maniaque de l’autorité, qui entend des voix, ne tire en fait sa frénésie que d’un docte barbouilleur de papier des années précédentes. Je suis certain qu’on s’exagère l’influence des intérêts acquis par rapport à l’emprise progressive des idées.

Si on en croit Keynes, il ne semble donc pas exagéré de prétendre qu’Adam Smith et ses idées ont modelé le monde qui les a suivis. .

Le personnage célèbre d'Adam Smith et son concept de « main invisible » ont inspiré de multiples fois des œuvres audiovisuelles modernes.

Il est par exemple possible de citer le cas du personnage Adam Smith, truand dans la série Le Transporteur, joué par l'acteur Don Tripe, et avec une référence explicite à la main invisible dans le titre de la version française mais la version anglophone est nommée "give a hand".

"Publiées à titre posthume"

En anglais :



Articles en français :





</doc>
<doc id="15685" url="https://fr.wikipedia.org/wiki?curid=15685" title="Internet Engineering Task Force">
Internet Engineering Task Force

L’, abrégée IETF, littéralement traduit de l'anglais en « Détachement d'ingénierie d'Internet » est un groupe informel, international, ouvert à tout individu, qui participe à l'élaboration des standards Internet. L'IETF produit la plupart des nouveaux standards d'Internet.

L’IETF est un groupe informel, sans statut, sans membre, sans adhésion. Le travail technique est accompli dans une centaine de groupes de travail. En fait, un groupe est généralement constitué d'une liste de courrier électronique. L'IETF tient trois réunions par année.

Les groupes de travail sont répartis dans une dizaine de domaines d'intérêt, chaque domaine ayant un ou deux directeurs. Ces directeurs de domaine nomment le ou les directeurs de chaque nouveau groupe de travail. Les directeurs de domaine font partie de l' (IESG). L’ (IAB) se charge de l'orientation à long terme d'Internet, et donc des activités données à l’IETF. L’IESG et l’IAB sont chapeautés par l' (ISoc).

Le but du groupe est généralement la rédaction d'un ou plusieurs (RFC), nom donné aux documents de spécification à la base d’Internet.




</doc>
<doc id="15688" url="https://fr.wikipedia.org/wiki?curid=15688" title="Transformation de Fourier rapide">
Transformation de Fourier rapide

La transformation de Fourier rapide (sigle anglais : "FFT" ou "") est un algorithme de calcul de la transformation de Fourier discrète (TFD).

Sa complexité varie en O("n" log "n") avec le nombre "n" de points, alors que la complexité de l’algorithme « naïf » s'exprime en O("n"). Ainsi, pour "n" = , le temps de calcul de l'algorithme rapide peut être 100 fois plus court que le calcul utilisant la formule de définition de la TFD.

C'est en 1965 que James Cooley et John Tukey publient l’article qui « lance » définitivement l'adoption massive de cette méthode en traitement du signal et dans les télécommunications. On a découvert par la suite que l'algorithme avait déjà été imaginé par Carl Friedrich Gauss en 1805, et adapté à plusieurs reprises (notamment par Lanczos en 1942) sous des formes différentes.

Cet algorithme est couramment utilisé en traitement numérique du signal pour transformer des données discrètes du domaine temporel dans le domaine fréquentiel, en particulier dans les analyseurs de spectre. Son efficacité permet de réaliser des filtrages en modifiant le spectre et en utilisant la transformation inverse (filtre à réponse impulsionnelle finie). Il est également à la base des algorithmes de multiplication rapide (Schönhage et Strassen, 1971), et des techniques de compression numérique ayant mené au format d'image JPEG (1991).

Soient "x", ..., "x" des nombres complexes. La transformée de Fourier discrète est définie par la formule suivante :

ou en notation matricielle :

formula_2

Évaluer ces sommes directement coûte ("n" – 1) produits complexes et "n"("n" – 1) sommes complexes alors que seuls ("n"/2)(log("n") – 2) produits et "n" log("n") sommes sont nécessaires avec la version rapide. En général, de tels algorithmes dépendent de la factorisation de "n" mais contrairement à une idée répandue, il y a des transformées de Fourier rapides de complexité O("n" log "n") pour tous les "n", même les "n" qui sont des nombres premiers.

Comme la transformée de Fourier inverse discrète est équivalente à la transformée de Fourier discrète, à un signe et facteur 1/"n" près, il est possible de générer la transformation inverse de la même manière pour la version rapide.

Remarque : on peut reconnaître ici une matrice de Vandermonde en la matrice "n"×"n".

Il s'agit d'un algorithme fréquemment utilisé pour calculer la transformation de Fourier discrète. Il se base sur une approche de type « diviser pour régner » par le biais d'une récursion. Celle-ci subdivise une transformation de Fourier discrète d'une taille composite "n" = "n""n" en plusieurs transformées de Fourier discrètes de tailles inférieures "n" et "n". Cet algorithme nécessite O("n") multiplications par des racines d'unité, plus communément appelés "facteurs de rotation".

C'est en 1965 que James Cooley et John Tukey publient cette méthode mais il a été découvert par la suite que l'algorithme avait déjà été inventé par Carl Friedrich Gauss en 1805 et adapté à plusieurs reprises sous des formes différentes.

L'utilisation la plus classique de l'algorithme de Cooley-Tukey est une division de la transformation en deux parties de taille identique "n"/ 2 et ceci à chaque étape. Cette contrainte limite les tailles possibles, puisque celles-ci doivent être des puissances de deux. Toutefois, une factorisation reste possible (principe déjà connu de Gauss). En général, les mises en code essaient d'éviter une récursion pour des questions de performance. Il est aussi possible de mélanger plusieurs types d'algorithme lors des subdivisions.

Il existe d'autres algorithmes qui permettent de calculer la transformée de Fourier discrète. Pour une taille "n" = "n""n", avec des nombres premiers entre eux "n" et "n", il est possible d'utiliser l'algorithme PFA (Good-Thomas) basé sur le théorème des restes chinois. Le PFA est similaire à celui de Cooley-Tukey.

L'algorithme de Rader-Brenner est aussi une variante de Cooley-Tukey avec des "facteurs de rotation" purement imaginaires qui améliorent les performances en réduisant le nombre de multiplications mais au détriment de la stabilité numérique et une augmentation du nombre d'additions. Les algorithmes qui procèdent aussi par des factorisations successives sont et l'algorithme QFT. Les versions originales travaillent sur des fenêtres dont la taille est une puissance de 2 mais il est possible de les adapter pour une taille quelconque.
L'algorithme de Bruun considère la transformée de Fourier rapide comme une factorisation récursive du polynôme "z" – 1 en des polynômes à coefficients réels de la forme "z" – 1 et "z" + "az" + 1.

L'algorithme de Winograd factorise "z" – 1 en un polynôme cyclotomique, dont les coefficients sont souvent –1, 0 ou 1, ce qui réduit le nombre de multiplications. On peut voir cet algorithme comme la version optimale en termes de multiplications. Winograd a montré que la transformée de Fourier discrète peut être calculée avec seulement O("n") multiplications, et ce minorant est atteint pour les tailles qui sont des puissances de 2. Toutefois, des additions supplémentaires sont nécessaires, ce qui peut être pénalisant sur les processeurs modernes comportant des unités arithmétiques performantes.

L' est quant à lui destiné aux fenêtres dont la taille est un nombre premier. Il profite de l'existence d'une génératrice pour le groupe multiplicatif modulo "n". La transformation discrète dont la taille est un nombre premier s'exprime ainsi comme une convolution cyclique de taille "n" – 1. On peut ensuite la calculer par une paire de transformation de Fourier rapide.

Finalement, un autre algorithme destiné aux transformations avec des tailles qui sont des nombres premiers est due à Leo Bluestein, en 1968. On l'appelle plus souvent l'. Ici encore, la transformation est vue comme une convolution dont la taille est identique à la fenêtre originale. On utilise à cet effet l'identité "jk" = –("j – k")/2 + "j"/2 + "k"/2.

Dans beaucoup d'applications, les données en entrée de la transformation discrète de Fourier sont uniquement des nombres réels. Dans ce cas, les sorties satisfont la symétrie suivante :

et des algorithmes efficaces ont été conçus pour cette situation, par exemple celui de Sorensen en 1987. Une approche possible consiste à prendre un algorithme classique comme celui de Cooley-Tukey et à enlever les parties inutiles dans le calcul. Cela se traduit par un gain de 50 % en mémoire et en vitesse de calcul. Alternativement, il est possible d'exprimer une transformation discrète sur des nombres réels (avec une taille paire) en une transformation avec des nombres complexes mais dont la taille a été divisée par deux (les parties imaginaires sont les éléments impairs et les parties réelles sont les éléments pairs) suivie d'un décodage dont la complexité est de l'ordre de O("n") opérations.

On pensait que les transformations avec des nombres réels pouvaient être plus efficacement calculées via une mais il a été prouvé par la suite qu'une transformation de Fourier discrète modifiée pouvait être plus efficace que la même transformation de Hartley. L'algorithme de Bruun était un candidat pour ces transformations mais il n'a pas eu la popularité escomptée.

Il existe encore d'autres variantes pour les cas où les données sont symétriques (c’est-à-dire des fonctions paires ou impaires) avec un gain supplémentaire de 50%. Dans ce cas, on utilise une transformée en cosinus discrète.

Tous les algorithmes proposés ci-dessus calculent la transformée sans aucune erreur, de par leur nature analytique. Toutefois, il existe des algorithmes qui peuvent s'accommoder d'une marge d'erreur pour accélérer les calculs. En 1999, Edelman proposent une approximation à la transformée de Fourier rapide. Cette version est destinée à une mise en œuvre en parallèle. Une approximation basée sur les ondelettes est proposée en 1996 par Guo et Burrus et tient compte de la répartition dans les entrées/sorties. Un autre algorithme a encore été proposé par Shentov en 1995. Seul l'algorithme de Edelman fonctionne bien avec n'importe quel type de données, il profite de la redondance dans la matrice de Fourier plutôt que de la redondance dans les données initiales.

Toutefois, même les algorithmes décrits de manière analytique présentent des erreurs lorsqu'ils sont codés avec des virgules flottantes dont la précision est limitée. L'erreur est cependant limitée. Une borne supérieure d'erreur relative pour Cooley-Tukey est donnée par formula_3 alors qu'elle est de formula_4 pour la formulation triviale de la transformée de Fourier discrète. Le terme formula_5 représente ici la précision relative en virgule flottante. En fait, l'erreur quadratique moyenne est encore plus limitée avec seulement formula_6 pour Cooley-Tukey et formula_7
pour la version triviale. Il ne faut malgré tout pas oublier que la stabilité peut être perturbée par les différents facteurs de rotation qui interviennent dans les calculs. Un manque de précision sur les fonctions trigonométriques peut fortement augmenter l'erreur. L'algorithme de Rader est par exemple nettement moins stable que celui de Cooley-Tukey en cas d'erreurs prononcées.

Avec une arithmétique en virgule fixe, les erreurs s'accumulent encore plus vite. Avec Cooley-Tukey, l'augmentation de l'erreur quadratique moyenne est de l'ordre de formula_7. De plus, il faut tenir compte de la magnitude des variables lors des différentes étapes de l'algorithme.

Il est possible de vérifier la validité de l'algorithme grâce à une procédure qui vise à déterminer la linéarité et d'autres caractéristiques de la transformation sur des entrées aléatoires.



</doc>
<doc id="15689" url="https://fr.wikipedia.org/wiki?curid=15689" title="Hypoténuse">
Hypoténuse

Dans un triangle rectangle, le côté opposé à l'angle droit est appelé hypoténuse de ce triangle rectangle. Le théorème de Pythagore, parfois appelé "théorème de l'hypoténuse", affirme que dans un triangle rectangle, la longueur de l'hypoténuse égale la racine carrée de la somme des carrés des longueurs des deux autres côtés, appelée parfois somme pythagoricienne de ces deux longueurs. L'hypoténuse d'un triangle rectangle est un diamètre du cercle circonscrit à celui-ci (voir angle inscrit dans un demi-cercle).

Ce mot (féminin) vient du latin "hypotenusa", lui-même transcrit du grec ancien ὑποτείνουσα, "hupoteinousa", du préfixe "hupo-" « sous », et "teino", "teinein" «  tendre  ». "Hypoténuse" signifie donc littéralement « celle qui sous-tend », c'est-à-dire « (le côté) se tendant sous ... ». 
Platon, avant Euclide, a utilisé (dans le "Timée") ce terme pour désigner le côté du triangle rectangle qui semble être « tendu » par le secteur angulaire de l'angle droit.


</doc>
<doc id="15691" url="https://fr.wikipedia.org/wiki?curid=15691" title="Tsugaru shamisen">
Tsugaru shamisen

Le parfois transcrit tsugaru jamisen ou tsugaru jabisen est un style de musique japonaise folklorique joué sur plusieurs variantes régionales du : , et . Plus rythmé que le shamisen classique, il est originaire de la région de Tsugaru, actuelle préfecture d' au nord de , l'île principale du Japon.

L'histoire veut que le style ait été d'abord pratiqué par des mendiants, souvent aveugles, appelés péjorativement et effectuant le (jouer à la porte d'une maison jusqu'à avoir obtenu de l'argent ou de la nourriture).
Selon une croyance, l'un d'eux, appelé , originaire de dans la région de Tsugaru, aurait été le fondateur du style. Bien qu'il soit reconnu maintenant qu'il ne peut avoir été le seul fondateur, la légende aura toutefois donné un film d'animation, "Nitaboh", racontant le destin tragique et grandiose de ce dernier, réalisé par les studios de WAO corporation, également groupe d'éducation.

Ce style de musique est structuré par des pièces traditionnelles tels que le "Jonkara Bushi", "Jongara Bushi", "Nikata" ou "Aiya Bushi" (pour en citer des célèbres), ces dernières ne correspondent cependant pas à notre vision de la musique traditionnelle, elles comportent une partie fixe et une partie variable qui est toujours improvisée par le musicien. Ainsi le tsugaru shamisen est un style qui se prête facilement à l'improvisation.
Ce style est le plus populaire des musiques jouées au shamisen au Japon et connaît depuis quelques années une réinvention par des artistes modernes tels que , les , et , qui mêlent le shamisen à des instruments plus occidentaux tels que la basse, la batterie et le piano.

Toutefois, les puristes diront que ces artistes ne jouent pas à strictement parler du "tsugaru shamisen". Ils reprennent cependant toutes les techniques qui lui sont propres.

Le musicien américain Kevin Kmetz du groupe Estradasphere est le premier occidental à acquérir une réelle maîtrise du shamisen dans ce répertoire là et entend créer le shamisen californien, il est d'ailleurs le personnage principal d'un documentaire appelé "The Birth of California Shamisen" retraçant comment il en est venu à être le premier étranger à recevoir le prix "Daijo Kazuo" du championnat national de "tsugaru shamisen" de Kanagi.




</doc>
<doc id="15698" url="https://fr.wikipedia.org/wiki?curid=15698" title="Liste des cantons de la Manche">
Liste des cantons de la Manche

Le département de la Manche comptait 52 cantons avant 2015. Avec le redécoupage cantonal de 2014, le nombre de cantons est ramené à 27.

Dans la poursuite de la réforme territoriale engagée en 2010, l'Assemblée nationale adopte définitivement le la réforme du mode de scrutin pour les élections départementales destinée à garantir la parité hommes/femmes. Les lois (loi organique 2013-402 et loi 2013-403) sont promulguées le . Un nouveau découpage territorial est défini par décret du 25 février 2014 pour le département de la Manche. Celui-ci entre en vigueur lors du premier renouvellement général des assemblées départementales suivant la publication du décret, soit en mars 2015. Les conseillers départementaux sont élus au scrutin majoritaire binominal mixte. Les électeurs de chaque canton éliront au Conseil départemental, nouvelle appellation des Conseils généraux, deux membres de sexe différent, qui se présenteront en binôme de candidats. Les conseillers départementaux seront élus pour au scrutin binominal majoritaire à deux tours, l'accès au second tour nécessitant 10 % des inscrits au . En outre la totalité des conseillers départementaux est renouvelée.

Ce nouveau mode de scrutin nécessite un redécoupage des cantons dont le nombre est divisé par deux avec arrondi à l'unité impaire supérieure si ce nombre n'est pas entier impair et avec des conditions de seuils minimaux. Dans la Manche le nombre de cantons passe ainsi de 52 à 27.

Les critères du remodelage cantonal sont les suivants : le territoire de chaque canton doit être défini sur des bases essentiellement démographiques, le territoire de chaque canton doit être continu et les communes de moins de sont entièrement comprises dans le même canton. Il n’est fait référence, ni aux limites des arrondissements, ni à celles des circonscriptions législatives.

Conformément à de multiples décisions du Conseil constitutionnel depuis 1985 et notamment sa décision DC du 9 décembre 2010, il est admis que le principe d’égalité des électeurs au regard des critères démographiques est respecté lorsque le ratio conseiller/habitant de la circonscription est compris dans une fourchette de 20 % de part et d'autre du ratio moyen conseiller/habitant du département. Pour le département de la Manche, la population de référence est la population légale en vigueur au janvier 2013, à savoir la population millésimée 2010, soit . Avec 27 cantons la population moyenne par conseiller départemental est de . Ainsi la population de chaque nouveau canton doit-elle être comprise entre et pour respecter le principe de l'égalité citoyenne au vu des critères démographiques.

Dans le précédent découpage (2010) l'écart de population était de un à dix entre le canton le moins peuplé (Juvigny-le-Tertre avec habitants) et le canton le plus peuplé (Équeurdreville-Hainneville avec habitants).


Contrairement à l'ancien découpage où chaque canton était inclus à l'intérieur d'un seul arrondissement, le nouveau découpage territorial s'affranchit des limites des arrondissements. Certains cantons peuvent être composés de communes appartenant à des arrondissements différents. Dans le département de la Manche, c'est le cas de cinq cantons (Agon-Coutainville, Bréhal, Carentan, Saint-Lô-1 et Villedieu-les-Poêles).

Le tableau suivant présente la répartition par arrondissement :

District d'Avranches

Canton d'Avranches - Canton de Ducey - Canton de Granville - Canton de La Haye-Pesnel - Canton de Saint-James - Canton de Pontorson - Canton de Sartilly - Canton de Tirepied - Canton de Villedieu-les-Poêles

District de Carentan

Canton de Carentan - Canton de La Haye-du-Puits - Canton de Lessay - Canton de Périers - Canton de Pont-l'Abbé ou Canton de Picauville - Canton de Prétot - Canton de Sainteny - Canton de Sainte-Marie-du-Mont - Canton de Sainte-Mère-Église - Canton de Montmartin-en-Graignes

District de Cherbourg

Canton de Beaumont-Hague - Canton de Cherbourg - Canton de Digosville - Canton de Martinvast - Canton des Pieux - Canton de Saint-Pierre-Église - Sainte Croix ou Sainte-Croix-dans-la-Hayne (lire "Hague")

District de Coutances

Canton de Blainville - Canton de Bréhal - Canton de Cérences - Canton de Cerisy-la-Salle - Canton de Coutances - Canton de Créances - Canton de Gavray - Canton de Montmartin-sur-Mer - Canton de Saint-Denis-le-Gast - Canton de Saint-Sauveur-Lendelin

District de Mortain

Canton de Barenton - Canton de Brécey - Canton d'Isigny-le-Buat - Canton de Juvigny-le-Tertre - Canton de Mortain - Canton de Saint-Pois - Canton de Saint-Hilaire-du-Harcouët - Canton de Sourdeval - Canton du Teilleul

District de Saint-Lô

Canton de Saint-Lô - Canton de Canisy - Canton d'Esglandes - Canton de Marigny - Canton de Percy - Canton de Saint-Clair-sur-l'Elle - Canton de Saint-Jean-des-Baisants - Canton de Tessy-sur-Vire - Canton de Torigni-sur-Vire

District de Valognes

Canton de Barneville - Canton de Bricquebec - Canton de Lestre - Canton de Montebourg - Canton de Quettehou - Canton de Saint-Sauveur-le-Vicomte - Canton de Sauxemesnil - Canton de Surtainville - Canton de Valognes

De 1790 à 1795, le département de la Manche comptait 7 districts.

Créés en 1790, les cantons furent tous supprimés, par la Convention en , puis rétablis par le directoire en .

Les arrondissements sont créés en 1800 : arrondissement d'Avranches, arrondissement de Mortain, arrondissement de Valognes, arrondissement de Coutances et arrondissement de Saint-Lô.

En 1801, les cantons sont modifiés (certains sont supprimés). Ils correspondent globalement aux cantons d'aujourd'hui.

L'arrondissement de Cherbourg est créé en 1811 à partir de six cantons de l'arrondissement de Valognes.

En 1926, l'arrondissement de Mortain et l'arrondissement de Valognes sont supprimés et les autres arrondissements sont modifiés en conséquence. D'autres modifications interviennent dans les années 1950 et 1960.

Les cantons de la Manche ont été plusieurs fois redécoupés. Les modifications les plus récentes ont été effectuées par les décrets suivants :
Liste des 52 anciens cantons du département de la Manche, par arrondissement :

(16 cantons - sous-préfecture : Avranches) :canton d'Avranches - canton de Barenton - canton de Brécey - canton de Ducey - canton de Granville - canton de La Haye-Pesnel - canton d'Isigny-le-Buat - canton de Juvigny-le-Tertre - canton de Mortain - canton de Pontorson - canton de Saint-Hilaire-du-Harcouët - canton de Saint-James - canton de Saint-Pois - canton de Sartilly - canton de Sourdeval - canton du Teilleul

(15 cantons - sous-préfecture : Cherbourg-Octeville) :canton de Barneville-Carteret - canton de Beaumont-Hague - canton de Bricquebec - canton de Cherbourg-Octeville-Nord-Ouest - canton de Cherbourg-Octeville-Sud-Est - canton de Cherbourg-Octeville-Sud-Ouest - canton d'Équeurdreville-Hainneville - canton de Montebourg - canton des Pieux - canton de Quettehou - canton de Sainte-Mère-Église - canton de Saint-Pierre-Église - canton de Saint-Sauveur-le-Vicomte - canton de Tourlaville - canton de Valognes

(10 cantons - sous-préfecture : Coutances) :canton de Bréhal - canton de Cerisy-la-Salle - canton de Coutances - canton de Gavray - canton de La Haye-du-Puits - canton de Lessay - canton de Montmartin-sur-Mer - canton de Périers - canton de Saint-Malo-de-la-Lande - canton de Saint-Sauveur-Lendelin

(11 cantons - préfecture : Saint-Lô) :canton de Canisy - canton de Carentan - canton de Marigny - canton de Percy - canton de Saint-Clair-sur-l'Elle - canton de Saint-Jean-de-Daye - canton de Saint-Lô-Est - canton de Saint-Lô-Ouest - canton de Tessy-sur-Vire - canton de Torigni-sur-Vire - canton de Villedieu-les-Poêles

Il n'y a pas d'homonymies pour les cantons de Marigny et de Percy, bien qu'il en existe une pour chacune des communes chefs-lieux.

Au total, 59 cantons ont disparu :




</doc>
<doc id="15707" url="https://fr.wikipedia.org/wiki?curid=15707" title="Comatrice">
Comatrice

En algèbre linéaire, la comatrice d'une matrice carrée "A" est une matrice introduite par une généralisation du calcul de l'inverse de "A". Elle a une importance considérable pour l'étude des déterminants. Ses éléments sont appelés cofacteurs de "A", et ils permettent d'étudier les variations de la fonction déterminant.

La comatrice est aussi appelée matrice des cofacteurs.

Le déterminant pour les matrices est naturellement "défini" comme une fonction sur les "n" vecteurs colonnes de la matrice. Il est cependant légitime de le considérer aussi comme une fonction qui aux "n" coefficients de la matrice associe un scalaire.

Quand on « gèle » tous les coefficients de la matrice à l'exception d'un seul, le déterminant est une fonction affine du coefficient variable. L'expression de cette fonction affine est simple à obtenir comme cas particulier de la propriété de "n"-linéarité ; elle fait intervenir un déterminant de taille "n" – 1, appelé cofacteur du coefficient variable.

Ces considérations permettent d'établir une formule de récurrence ramenant le calcul d'un déterminant de taille "n", à celui de "n" déterminants de taille "n" – 1 : c'est la formule de Laplace.

Soit "A" une matrice carrée de taille "n". On observe l'effet d'une modification d'un des coefficients de la matrice, les autres restant inchangés. Pour cela on choisit donc deux indices "i" pour la ligne et "j" pour la colonne, et on note "A"("x") la matrice dont les coefficients sont les mêmes que ceux de "A", sauf le terme d'indice "i, j", qui vaut "a + x". On écrit la formule de linéarité pour la "j"-ième colonne 
Le déterminant noté Cof est appelé cofacteur d'indice "i, j" de la matrice "A". Il admet les interprétations suivantes :

Dans la pratique, on calcule les cofacteurs de la façon suivante : on appelle "M"("i, j") le déterminant de la sous-matrice déduite de "M" en ayant enlevé la ligne "i" et la colonne "j" (on parle de mineur pour un tel déterminant). Alors le cofacteur est (–1) fois "M"("i, j").
Les cofacteurs sont des cas spéciaux de mineurs.

Si "n" > 1 et "A" est une matrice carrée de taille "n" alors on peut calculer son déterminant en fonction des coefficients d'une seule colonne et des cofacteurs correspondants. Cette formule, dite formule de Laplace, permet ainsi de ramener le calcul du déterminant à "n" calculs de déterminants de taille "n" – 1.


On introduit la comatrice de "A", matrice constituée des cofacteurs de "A". On peut généraliser les formules de développement du déterminant par rapport aux lignes ou colonnes


</doc>
<doc id="15708" url="https://fr.wikipedia.org/wiki?curid=15708" title="AccorHotels">
AccorHotels

AccorHotels est le premier groupe hôtelier en France et le sixième au niveau mondial. Le groupe français, est présent dans 95 pays. AccorHotels compte plus de et sous enseignes répartis sur les cinq continents. Sa capacité totale en nombre de chambres est de dont 26 % sont situées en France, 23 % en Europe Centrale, du Nord et de l'Est hors France, 13 % en Amérique du Nord, Amérique Latine et Caraïbes, 12 % en Méditerranée, Afrique et Moyen-Orient, et 26 % en Asie Pacifique. AccorHotels a son siège à Issy-les-Moulineaux.

Le Groupe propose un portefeuille de marques allant du luxe (Raffles, Fairmont, Sofitel, onefinestay, MGallery by Sofitel, Grand Mercure, Novotel, The Sebel, Pullman, swissôtel) à l’économique (Jo&Joe, ibis, ibis Styles, ibis budget, adagio access et hotelF1) en passant par le milieu de gamme (Mercure, Mama Shelter, Adagio).

En 1967, Paul Dubrule et Gérard Pélisson fondent la SIEH (Société d'investissement et d'exploitation hôteliers) et appliquent le modèle américain de Holiday Inn pour ouvrir leur premier Novotel la même année à Lille suivant les principes de Bernardo Trujillo.

En 1974 est lancée la marque Ibis avec l’ouverture du premier Ibis à Bordeaux. La même année, la SIEH rachète la marque Courtepaille.

En 1975, la SIEH rachète la marque Mercure et, en 1980, le groupe reprend le groupe Sofitel se composant à l'époque de 43 hôtels et de 2 centres de thalassothérapie. La SIEH prend le contrôle de Jacques Borel International, alors leader de la restauration collective, de la restauration de concession et leader mondial de l'émission de tickets restaurant en 1982.

En 1983, le Groupe Novotel SIEH - Jacques Borel International change de nom et devient le Groupe Accor.

Le groupe Accor crée en 1985 la marque Formule 1, mettant en place un nouveau concept d'hôtellerie basé sur une réduction des coûts de la construction à la gestion. La même année, Accor entre dans le capital du groupe Lenôtre à hauteur de 46 %.

Accor lance un nouveau concept avec les hôtels Formule 1 en 1985 avant de reprendre son expansion internationale avec la reprise de Motel 6 aux États-Unis en 1990. Cette acquisition permet au groupe de devenir le leader mondial de l’hôtellerie. 1991 et 1997 marquent une diversification du groupe avec l’acquisition respective de la Compagnie internationale des wagons-lits et du tourisme ainsi que de la SPIC qui devient Accor Casinos ainsi que la nomination de Jean-Marc Espalioux à la tête du groupe.
Dès lors le groupe continue son développement en reprenant différentes enseignes comme Red Roof Inns et les enseignes très haut de gamme Westin demeures Hôtels et libertel du Groupe CGIS (1999), et en lançant accorhotels.com et Suitehotel en Europe. Le groupe prend également une participation de 30 % du Club Méditerranée en 2005.

Durant l'été 2005, Jean-Marc Espalioux, quitte la présidence du directoire. Après de nombreux rebondissements, Gilles Pélisson, neveu de Gérard, est nommé directeur général du groupe Accor. Serge Weinberg, ancien du Groupe PPR est nommé Président du Conseil d’administration.

En , le groupe change de mode de direction, en adoptant un régime de conseil d’administration au lieu de celui de directoire et conseil de surveillance. Gilles Pélisson devient directeur général du groupe Accor et Serge Weinberg président du conseil d'administration.

En 2007, Accor cède de plusieurs activités non stratégiques comme sa participation dans le Club Méditerranée, mais aussi Red Roof Inn, de la restauration collective en Italie, Go voyages), en parallèle Accor Services acquiert Kadéos. Toujours en 2007, Accord met en place des nouvelles chaînes Pullman, MGallery et All Seasons. Accor lance, encore en 2007, Adagio City Aparthotel, une nouvelle marque de résidences urbaines, en collaboration avec le groupe Pierre & Vacances (coentreprise).

En février 2009, Gilles Pélisson, directeur général, est nommé président du conseil d’administration. Accor Services et MasterCard Europe concluent une alliance stratégique dans les services prépayés : PrePay Solutions, détenue à hauteur de 67 % par Accor Services. En 2009, la marque SuiteHotel est intégrée au réseau Novotel, sous le nom Suite-Novotel.

Le , le conseil d'administration d'Accor s'est prononcé à l'unanimité moins une voix en faveur du projet de scission des activités d'hôtellerie et de services du groupe. 
Les fondateurs d’Accor, Paul Dubrule et Gérard Pélisson, ont défendu ce projet de scission. Lors de ce conseil d’administration, Jacques Stern est nommé directeur général délégué d'Accor, chargé d'Accor Services, devenue Edenred.

Le conseil d’administration d'Accor a approuvé le les modalités de la séparation de l’hôtellerie et des services. Réuni le 1, le conseil d’administration a validé le traité d'apport-scission qui précise les modalités de mise en œuvre de la séparation, et qui a été accepté par l’assemblée générale des actionnaires du . 88,49 % des actionnaires ont voté en faveur de la scission.

En 2010, Accor cède la Compagnie des Wagons-Lits.

Le , le conseil d’administration d'Accor met fin au mandat de Gilles Pélisson à la suite de divergences stratégiques. Il nomme Denis Hennequin, jusqu'alors PDG de McDonald's Europe, directeur général exécutif à compter du . Denis Hennequin devient PDG d'Accor le .

Avec son arrivée, Accor poursuit son désendettement, son recentrage sur les activités d’hôtellerie, avec plusieurs cessions notamment celles du traiteur de luxe Lenôtre à Sodexo, ou de sa participation dans le groupe Lucien Barrière). Accor poursuit son développement international, avec la signature le d’un contrat de franchise concernant 24 hôtels et avec Jupiter Hotels, nouveau propriétaire du réseau d’hôtels Jarvis. Ce contrat s’inscrit dans la volonté d’Accor de détenir un réseau de 300 hôtels au Royaume-Uni d’ici 2015.

Le , le PDG présente un plan stratégique procédant notamment au regroupement de ses marques du segment économique sous la bannière d'Ibis : Etap Hotel devient Ibis Budget et All Seasons devient Ibis Styles.

En 2012, Accor cède Motel 6 et Studio 6.

Denis Hennequin quitte le groupe en . Durant une période de transition allant d’avril à août 2013, Yann Caillère exerce la fonction de directeur général. 
En , Sébastien Bazin est nommé président-directeur général, et Yann Caillère quitte le groupe.

En novembre 2013, Sébastien Bazin a annoncé une redéfinition du modèle économique autour des deux pôles stratégiques : HotelServices, opérateur et franchiseur, et HotelInvest, propriétaire et investisseur. Le Groupe est organisé selon une logique géographique avec cinq grandes zones : France ; Europe du Nord, Centrale et de l’Est ; Méditerranée, Moyen-Orient, Afrique ; Asie-Pacifique ; Amériques.

Le , le Groupe annonce un plan d’investissement de 225 millions d’euros sur 5 ans pour accélérer sa transformation digitale ainsi que l’acquisition de la start-up française Wipolo qui propose des solutions mobiles et web de gestion de voyage.

Le , Accor annonce le rachat des murs de 97 hôtels en Europe (), à travers HotelInvest, pour d'euros . En octobre 2014, Accor a confié la gestion de ses activités en Europe centrale à . En décembre 2014, Accor entre en alliance avec Huazhu (China Lodging), rassemblant plus de et acquiert une participation de 35 % dans Mama Shelter, élargissant ainsi son offre avec une marque contemporaine « lifestyle » particulièrement performante et attractive en matière de restauration.

Accor accélère sa stratégie digitale avec la reprise de Fastbooking en avril 2015, société française spécialisée dans les services digitaux aux hôteliers.

En juin 2015, Accor devient AccorHotels. En décembre 2015, AccorHotels a annoncé le rachat pour d'euros des murs de que le groupe exploite déjà dans divers pays européens, ce qui représente au total . AccorHotels va entre autres acheter à Axa Investments Manager un portefeuille composé de en franque exploités sous le nom de Ibis budget, Novotel et Mercure, pour une valeur de d'euros. En décembre 2015, AccorHotels annonce l'acquisition pour de dollars de FRHI, qui possède les marques Fairmont, Raffles et Swissôtel, notamment par une augmentation de capital qui voit la Qatar Investment Authority et Al-Walid ben Talal avoir respectivement 10,5 % et 5,8 % du nouvel ensemble. A l'issue de cette opération, le véhicule d'investissements du Qatar, Qatar Investment Authority devient le premier actionnaire du groupe avec 10,8 % du capital.

En avril 2016, bousculé par Airbnb, AccorHotels rachète pour 148 millions d’euros la start-up londonienne Onefinestay, un site de partage d’appartements luxueux et légaliste.

Suite au vote des actionnaires lors de l’assemblée générale en juillet 2016, AccorHotels annonce le rachat définitif de FRHI Hotels and Resorts (FRHI) et de ses marques de luxe, Fairmont, Raffles et Swissôtel. Cette acquisition positionne AccorHotels parmi les leaders mondiaux de l’hôtellerie de luxe, en renforçant sa présence en Amérique du Nord, marché le plus influent au monde sur ce segment.

En février, le groupe rentre ainsi au capital de Squarebreak à hauteur de 49 %, d’Oasis Collections à hauteur de 30 % puis poursuit avec l’acquisition de onefinestay, pionnier de la location de résidences de luxe, et de John Paul, leader mondial des services de conciergerie.

En novembre 2016, AccorHotels annonce l'acquisition pour 35 millions d’euros d'une participation de 30 % dans la chaîne hôtelière allemande 25hours Hotels, et devient ainsi partenaire stratégique du développement de la marque à l’international.

Le , AccorHotels et Rixos Hotels annoncent la signature d'un partenariat stratégique par lequel AccorHotels détiendra une participation de 50 % dans la nouvelle structure cogérant les hôtels. Cet accord permet à 15 des hôtels de Rixos d'intégrer le groupe AccorHotels, 5 hôtels changeront de nom au profit d'une marque AccorHotels et les deux hôtels en construction prévus avant fin 2018 seront aussi intégrés à la nouvelle structure. Cet accord permet à AccorHotels de se renforcer dans le luxe en Europe de l'Est, en Asie et au Moyen-Orient, en complément de ses marques Fairmont, Pullman et Raffles.

En avril 2017, Accor annonce qu'il vend 62 hôtels à bas coût à Adoma (ex-Sonacotra) qui compte les transformer en structures d’hébergement d'urgence. La fermeture des 62 hôtels est assortie de départs volontaires, portant sur 393 emplois. En octobre 2017, Accor annonce lancer une offre d'acquisition de l'entreprise australienne Mantra pour 780 millions d'euros. En février 2018, AccorHotels annonce la vente de 55 % de AccorInvest pour 4,4 milliards d'euros.

Premier groupe hôtelier européen, AccorHotels est présent sur les cinq continents, dans 95 pays avec représentant plus de .

Le groupe AccorHotels détient un portefeuille de 26 marques :

Composition du conseil d'administration:
(*) : administrateur indépendant

Composition du comité exécutif :

Ces données sont indiquées en millions d'euros et incluent Accor Services jusqu'en 2009.
Il y a des franchises au groupe AccorHotels, soit 960 hôtels, 63 % de leur part hôtelière en France.


En mars 2017, la Ministre du travail Myriam El Khomri annonce transmettre au Défenseur des droits un rapport datant de décembre 2016, et pointant le à l'embauche par le groupe AccorHotels. L'enquête de testing menée en amont par la Direction de l'animation de la recherche, des études et des statistiques a révélé des dysfonctionnements, et les réponses proposées ensuite par le groupe n'ont pas été jugées satisfaisantes par le cabinet Vigeo Eiris. Le groupe réfute les conclusions de la Ministre.


</doc>
<doc id="15710" url="https://fr.wikipedia.org/wiki?curid=15710" title="Vauban (homonymie)">
Vauban (homonymie)






</doc>
<doc id="15713" url="https://fr.wikipedia.org/wiki?curid=15713" title="Accélération">
Accélération

L'accélération est une grandeur physique vectorielle, appelée de façon plus précise « vecteur accélération », utilisée en cinématique pour représenter la modification affectant la vitesse d'un mouvement en fonction du temps. La norme (l'intensité) de ce vecteur est appelée simplement « accélération » sans autre qualificatif.

Dans le langage courant, l'accélération s'oppose à la décélération et indique l'augmentation de la vitesse ou de la fréquence d'évolution d'un processus quelconque, par exemple l'accélération de la fréquence cardiaque ou celle d'une suite de situations.

De même que la vitesse décrit la modification de la position d'un objet au cours du temps, l'accélération décrit la « modification de la vitesse au cours du temps » (ce que les mathématiques formalisent par la notion de dérivée). Dans la vie courante, on distingue trois cas que le physicien regroupe sous le seul concept d'accélération :
Lorsque l'on est soi-même soumis à une accélération, on ressent un effort : effort qui nous plaque contre le siège lorsque la voiture accélère (va plus vite), effort qui nous tire vers le pare-brise lorsque la voiture freine, effort qui nous tire sur le côté lorsque la voiture tourne (force centrifuge). Nous ressentons cet effort de manière similaire au poids. Le rapport entre l'accélération et l'effort est le domaine de la dynamique ; mais l'accélération est une notion de cinématique, c'est-à-dire qu'elle se définit uniquement à partir du mouvement, sans faire intervenir les efforts.

Dans les unités internationales, la vitesse s'exprime en mètres par seconde (m/s). L'accélération est donc la « variation, par seconde, des mètres par seconde », soit des « (mètres par seconde) par seconde », (m/s)/s ; que l'on appelle « mètres par seconde au carré » (m/s). On exprime ainsi souvent cette grandeur en « nombre de "g" », par analogie avec la pesanteur. Par rapport à l'unité internationale d'accélération, le « mètre par seconde au carré » (m/s), on a = .

Pour se faire une idée de l'accélération linéique, il peut être utile de penser en termes de « + "x" km/h par seconde », sachant que, par rapport aux unités internationales,
Par exemple, si une voiture passe de 0 à en , elle a une accélération de ()/() = = = .

À l'inverse, lors d'un choc frontal, une voiture roulant à s'arrête en environ , ce qui représente une variation de vitesse de ()/() = = = .

On parle souvent de l'accélération due à un changement de direction dans le cas des manèges à sensation, comme les montagnes russes. C'est ainsi que l'on peut lire que dans certains manèges, on subit une accélération allant jusqu'à .

La notion d'accélération est formalisée par Pierre Varignon le 20 janvier 1700, comme un écart infiniment petit de vitesse d"v" pendant un temps infiniment petit d"t" mis pour modifier cette vitesse. Réitérant l'approche qu'il avait utilisée deux ans plus tôt pour définir la notion de vitesse, il utilise le formalisme du calcul différentiel mis au point quelques années plus tôt par Gottfried Wilhelm Leibniz (Isaac Newton ayant développé le formalisme du calcul des fluxions).

On se place dans un référentiel (R) donné. Considérons un point matériel M de vecteur position formula_1 et de vecteur vitesse formula_2. Laccélération moyenne entre les instants "t" et "t" est le vecteur défini par :
La norme de l'accélération s'exprime en mètre par seconde au carré (m⋅s, m/s).

Si le référentiel et le point matériel sont définis sans ambiguïté, on allège couramment la notation

Avec les mêmes notations, on définit laccélération instantanée comme étant la dérivée du vecteur vitesse :

Comme le vecteur vitesse est lui-même la dérivée du vecteur position formula_1 du point matériel M, il en résulte que formula_7 est la dérivée seconde de formula_1 :

Physiquement, le vecteur accélération décrit la variation du vecteur vitesse. Ce dernier pouvant à la fois varier en valeur et en direction, la notion physique d'accélération est plus large que celle employé dans le langage courant, où celle-ci désigne uniquement une variation de la valeur de la vitesse. Du point de vue cinématique, un véhicule effectuant un virage à vitesse constante (en valeur) possède bien une accélération. Il est possible de montrer que celle-ci est normale au vecteur vitesse et dirigée vers le centre de courbure du virage (cf. expression intrinsèque de formula_7).

Tout comme le vecteur position et le vecteur vitesse, le vecteur accélération par rapport à un référentiel donné peut s'exprimer dans les différents systèmes de coordonnées : cartésiennes, cylindro-polaires, et sphériques. Il est important de souligner que le choix du système de coordonnées est indépendant de celui du "référentiel" : le "même" vecteur accélération pourra donc s'exprimer différemment selon le système de coordonnées choisi.



Dans un repère de Frenet il est possible de décomposer l'accélération en deux composantes :

Il est possible de démontrer l'expression suivante :

où "s"("t") est l'abscisse curviligne du point matériel et R est le rayon de courbure de la trajectoire au point considéré : c'est le rayon du cercle dit "osculateur" en ce point. Ce cercle osculateur est le cercle tangent à la trajectoire en ce point qui se rapproche le plus de cette trajectoire autour de ce point.

Dans le cas du mouvement rectiligne, le rayon de courbure R tend vers l'infini, et donc l'accélération normale est évidemment nulle.

Dans le cas d'un mouvement circulaire le rayon de courbure R est constant et correspond au rayon de la trajectoire. Si le mouvement est en plus uniforme, la composante tangentielle est nulle, et l'accélération est purement normale.

Un solide, indéformable ou déformable, peut être décrit comme un ensemble de points ; on note Σ le domaine spatial (volume) occupé par le solide, et formula_20 la fonction de masse volumique en un point M. On peut définir un vecteur accélération en chaque point, et ainsi un champ de vecteurs accélération formula_21.

Dans le cas d'un "solide indéformable", si l'on connaît l'accélération en un point A et le vecteur vitesse angulaire formula_22 du solide, on peut déterminer l'accélération en tout point B par la « loi de distribution des accélérations dans un solide indéformable », ou formule de Rivals :
Ceci montre que le champ des accélérations n'est pas un torseur.

Toutefois, à partir de ce champ, on peut définir le moment dynamique par rapport à un point A du solide
Ce moment dynamique est un champ équiprojectif (dans tous les cas, même si le solide est déformable), c'est donc un torseur, appelé « torseur dynamique ». Sa résultante est la quantité d'accélération :

Les lois de mouvement d'un corps sont la détermination de la position en fonction du temps formula_26, de la vitesse instantanée en fonction du temps formula_27 et de l'accélération instantanée en fonction du temps formula_28, les trois grandeurs étant des grandeurs vectorielles. Comme nous l'avons vu précédemment, le passage d'une grandeur à l'autre se fait par dérivation ou bien résolution d'une équation différentielle (ou, dans les cas simples, intégration). Ceci est le domaine de la cinématique.

Si formula_29 alors formula_30 et le mouvement du point matériel est rectiligne et uniforme dans (R).

On peut simplifier l'étude en posant l'axe "x" comme étant l'axe du vecteur vitesse, si celui-ci est non nul.

Le mouvement du point matériel est alors complètement décrit par la seule donnée de "x"("t"), et l'on a les équations de mouvement :

où "x" est l'abscisse initiale : "x"="x"("t"=0). Notons que si formula_32, alors le point est immobile dans le référentiel.

Si la direction et la valeur de formula_7 sont constantes, le mouvement est dit uniformément accéléré. On note

Si formula_35 et formula_7 sont colinéaires, alors le mouvement est rectiligne (MRUA : mouvement rectiligne uniformément accéléré). On peut simplifier l'étude en posant l'axe "x" comme étant l'axe commun de l'accélération et du vecteur vitesse. Le mouvement du point matériel est alors complètement décrit par la seule donnée de "x"("t"), et l'on peut exprimer l'accélération comme étant un scalaire :
On établit facilement que

où

De ceci, on peut également déduire la formule suivante :

Par exemple, afin de déterminer la hauteur d'un pont, on lâche une pierre depuis le haut du pont. Si celle-ci met formula_44 secondes pour atteindre le sol, quelle est la hauteur du pont ?

Sachant que l'accélération vaut formula_45 et formula_46 (lâcher sans vitesse initiale), la réponse est :
On a choisi arbitrairement formula_48.

Autre exemple : une voiture a un mouvement rectiligne uniformément accéléré, l'accélération valant . Quelle distance a-t-elle parcouru lorsqu'elle atteint la vitesse de , départ arrêté ?

On a :
donc, la distance formula_51 parcourue vaut :

Dans le cas le plus général, la trajectoire d'un point matériel en mouvement uniformément accéléré est plane et correspond à un arc de parabole.

Le cas typique est celui de la chute libre d'un corps dans le champ de pesanteur, lorsque l'on néglige le frottement de l'air. Il est important de souligner que la constance de formula_7 ne préjuge en rien de la forme de la trajectoire, qui dépend en fait des conditions initiales.

Si nous considérons que :
alors les lois de mouvement sont :
voir la démonstration sur l'article "Trajectoire parabolique". On en déduit que
qui est l'équation d'une parabole si α ≠ π/2 + "k"π. Si α ≡ π/2 mod(π), on se retrouve dans le cas précédent du MRUA d'axe "z".

Lorsque la droite portant le vecteur accélération passe toujours par un même point, on parle de mouvement à accélération centrale. Un cas particulier important de ce type de mouvement, où la force causant l'accélération est de type newtonien, est donné par le mouvement képlérien, qui décrit le mouvement des planètes autour du Soleil.

Un cas particulier simple est celui du mouvement circulaire uniforme : le point matériel est soumis à une accélération centripète valant (voir la section "Expression dans un repère de Frenet" ci-dessus) :
où R est le rayon de la trajectoire et ω est la vitesse angulaire.

Par exemple, une voiture roulant à une vitesse uniforme de () sur un rond-point de diamètre de (R = ) subit une accélération valant

Le vecteur accélération dépend du référentiel choisi pour l'étude du mouvement. Le mouvement par rapport à un référentiel donné (R), il est possible de déterminer sa nature par rapport à un autre référentiel (R'), en mouvement par rapport à "(R)", et donc la relation entre le vecteur accélération d'un point matériel "M" par rapport à "(R)", noté formula_59, et celui du même point par rapport à "(R')", noté formula_59.

Cette relation est parfois nommée la "loi de composition des accélérations", et il est possible de montrer qu'elle se met sous la forme suivante:

avec:
formula_63 étant le vecteur rotation instantané du référentiel "(R')" par rapport au référentiel "(R)", et formula_64 le vecteur position du point "M" dans le repère d'origine "O"' associé au référentiel "(R')".

Le vecteur position de "M" dans "(R)" est donné par formula_67, par suite il vient pour le vecteur vitesse du point matériel dans "(R)":

Par ailleurs formula_70 est le vecteur position de "M" dans "(R')" qui s'écrit dans la base du repère d'espace associé à ce référentiel: formula_71, par suite: formula_72.

Le vecteur accélération de "M" dans "(R)" s'obtient en dérivant le vecteur vitesse formula_73 par rapport au temps, dans ce référentiel:
or il vient aussitôt:
et
Finalement, on obtient la formule précédente.
Le référentiel terrestre étant non-galiléen, l'accélération de Coriolis joue un rôle important dans l'interprétation de beaucoup de phénomènes à la surface de la Terre. Par exemple le mouvement des masses d'air et des cyclones, la déviation de la trajectoire des projectiles à grande portée, le changement du plan de mouvement d'un pendule tel que montré par Foucault dans son expérience de 1851 au Panthéon de Paris, ainsi que la légère déviation vers l'est lors de la chute libre.

L'étude des causes de l'accélération s'appelle la dynamique.

L'accélération étant une variation du vecteur vitesse par rapport à un référentiel (R) au cours du temps, les causes de l'accélération sont les phénomènes faisant varier le vecteur vitesse. Ces phénomènes sont appelés des forces, et sont définies, en mécanique newtonienne, par le principe fondamental de la dynamique ( loi de Newton) :
où "m" est la masse du corps.

Il faut distinguer deux types de forces :
Les forces d'inertie sont simplement un artefact de calcul provenant des lois de composition des mouvements.

L'accélération, en tant que vecteur, n'est qu'un descriptif du mouvement. L'accélération, en tant que phénomène, est simplement un état dynamique (état dans lequel le vecteur vitesse varie). D'un point de vue causal, on ne peut donc pas à proprement parler de conséquences de l'accélération, mais plutôt de conséquences des interactions provoquant cet état accéléré.

Considérons le cas d'un solide suivant un mouvement de translation linéique uniformément accélérée, sous l'effet d'une action de contact ou sous l'effet d'une action volumique, à l'équilibre (l'accélération est la même pour toutes les parties). Prenons un modèle simple de solide déformable : il est composé de deux solides indéformables de masse respective "m" et "m", reliées par un ressort de masse négligeable.

Dans le cas d'une action de contact, le solide est poussé par une force formula_78, ce qui crée une accélération formula_7 d'intensité F/("m" + "m") (figure du haut). Si l'on isole le solide 2 (figure du milieu), il a également une accélération d'intensité "a" ; cela signifie qu'il subit de la part du ressort une force d'intensité F = "m""a", soit
Isolons le ressort (figure du bas) ; il subit une force formula_81 de la part du solide 2 (principe des actions réciproques). Sa masse étant négligeable, la résultante des forces qui s'exercent sur lui est nulle, il est donc en compression sous l'effet d'un couple de forces formula_82.

Cette accélération produit donc, par effet d'inertie, une déformation du solide, ici une compression. Si à l'inverse formula_78 était une force de traction s'exerçant sur le solide 2, le ressort serait en traction.

Si l'on se place dans un modèle de solide continu, défini par une fonction de masse volumique ρ(M) sur un domaine spatial Σ. L'accélération au point M vaut formula_21 ; soit un petit volume dV autour de M, ce volume est donc soumis à des forces dont la résultante vaut
Si le champ d'accélération est uniforme, on retrouve une forme similaire à l'action du poids. Cela explique qu'une accélération est ressentie de la même manière que la gravité.

L'étude de cette déformation et de ses conséquences est similaire à la statique.

Considérons maintenant que ce solide est accéléré par une action volumique. L'ensemble est soumis à une force globale formula_78, et chaque partie est soumise à une force volumique propre formula_87 et formula_88. Supposons que la force soit proportionnelle à la masse, ce qui est par exemple le cas du poids. Si l'on isole l'ensemble {solide 1, ressort, solide 2}, il est soumis à la seule force volumique :
(résultat classique de la chute libre sans résistance de l'air). Si maintenant on isole le solide 2 seul, il est soumis à l'action de sa force volumique propre, formula_88, et à l'action du ressort, formula_92, on a :
Donc, le ressort n'est pas comprimé ni étiré, le solide n'est pas déformé.

Si la force volumique n'est pas proportionnelle à la masse (cas d'une force électromagnétique par exemple), il va y avoir une déformation.

Comme énoncé plus haut, l'accélération est une grandeur cinématique, c'est-à-dire qu'elle décrit le mouvement. On a deux situations :
L'accélération peut enfin être mesurée par des accéléromètres.

Au voisinage de la Terre, tout corps doté d'une masse subit dans le référentiel terrestre une force appelée "poids". Pour l'essentiel, celle-ci correspond à la force de gravitation exercée par la Terre sur le corps, ce qui fait que le poids et la force de gravitation sont souvent confondus. À ceci s'ajoutent deux effets, celui de la rotation sur lui-même de la Terre, dépendant donc de la latitude du lieu, et dans une bien moins grande mesure l'influence des forces de gravitation exercées par les autres astres (termes de marée). Cette notion se généralise sans difficulté à un astre quelconque, au voisinage de celui-ci et dans un référentiel qui lui est lié.

Le poids s'exprime sous la forme du produit de la masse du corps par une accélération formula_95, appelée "pesanteur", soit
La valeur de formula_95 dépend du lieu considéré : la pesanteur constitue donc un champ d'accélération, qui peut être considéré comme uniforme au voisinage d'un lieu donné, pour de faibles variations d'altitude.

La direction de formula_98 en un lieu donné de la surface de la Terre correspond par définition à la verticale de ce lieu. Cette propriété est utilisée par le fil à plomb. Le sens de formula_98 est par définition, le "bas". À la surface de la Terre la valeur de moyenne de "g" est :

Dans le cas d'une masse qui n'est soumise qu'à cette seule force, lors du mouvement qui par définition est appelé la chute libre, et du fait de l'identité de la masse grave et de la masse inerte, tous les corps en chute libre, quelles que soient leurs masses, subissent (en un lieu donné) la même accélération. Par suite, si deux corps de masses différentes, par exemple une plume et une masselotte de plomb, sont lâchés au même moment de la même hauteur, ils arriveront à terre au même moment, à condition de s'abstraire de la résistance de l'air. En pratique cette expérience devra être faite dans un tube où le vide a été fait, ou sur un astre pratiquement dépourvu d'atmosphère comme la Lune.

Par suite, et bien qu'en toute rigueur la pesanteur en tant que champ d'accélération corresponde à une notion "cinématique", elle possède un lien direct avec la notion "dynamique" de poids, et tout se passe « comme si » un corps laissé « libre » dans ce champ de pesanteur « acquiert » l'accélération formula_95.

À partir du constat que masse grave et masse inerte ne peuvent être distinguées fonctionnellement, la relativité générale postule, sous le nom de principe d'équivalence, que la force de gravitation ne se distingue pas "localement" (c'est-à-dire si l'on considère uniquement un point) d'une accélération. Il est important sur le plan conceptuel de connaître cette équivalence, beaucoup de physiciens utilisant pour cette raison, en abrégé, le terme "accélération" pour désigner indifféremment une modification de vitesse ou la présence dans un champ de gravité, même en l'absence apparente (dans l'espace 3D) de mouvement.

Tout comme le vecteur accélération est la dérivée du vecteur vitesse par rapport au temps, on peut définir la dérivée de l'accélération par rapport au temps. Il s'agit du vecteur d'à-coup, parfois désigné sous le terme anglais de "jerk", qui permet ainsi de quantifier les variations d'accélération et qui est utilisé dans un certain nombre de domaines.

L'à-coup en jerks est donc la dérivée seconde de la vitesse et dérivée troisième de la distance parcourue.

Ceux-ci sont décrits notamment sur l'article décrivant l'accélération de la pesanteur terrestre, de , utilisée aussi en tant qu'unité de mesure d'accélération : 

Le génie mécanique consiste à concevoir et fabriquer des machines, c'est-à-dire des systèmes effectuant des mouvements. Une partie importante est le dimensionnement, c'est-à-dire le choix des actionneurs (vérins, moteurs) et des pièces supportant les efforts. Si les masses mises en mouvement et/ou les accélérations sont importantes, les effets dynamiques — les efforts nécessaires pour créer les accélérations, ou bien les efforts résultant des accélérations — ne sont pas négligeables. La détermination de l'accélération instantanée au cours d'un mouvement est donc capitale pour que les pièces résistent, et pour déterminer la consommation d'énergie du système.

Le ballet des robots autour d'une caisse automobile en cours d'assemblage, c'est impressionnant. Une usine d'automobiles consomme autant qu'une ville moyenne, et les robots y contribuent largement. C'est pourquoi Siemens et Volkswagen se sont attelés au problème, en visant les causes de surconsommation : les nombreuses accélérations et décélérations des bras robots, à chaque changement de direction. Les partenaires ont donc développé un logiciel de simulation qui crée des trajectoires moins abruptes pour la même tâche à réaliser. Et montré en laboratoire que l'on pouvait gagner jusqu'à 50 % d'énergie !
Dans de nombreux cas, le cahier de charges se résume à « amener un objet d'un point A à un point B en une durée "t" », la durée "t" étant parfois exprimée comme une cadence (effectuer le mouvement "n" fois par heure). La conception consiste à :

L'accélération joue donc un rôle capital :

Le terme est aussi utilisé en mathématiques, par exemple l'accélération de la convergence d'une suite (par des procédés comme le Delta-2 d'Aitken) signifie que l'écart entre la valeur des éléments de la suite et sa limite est plus petit que pour la suite initiale à un rang "n" donné.



</doc>
<doc id="15715" url="https://fr.wikipedia.org/wiki?curid=15715" title="Delta-2">
Delta-2

Delta-2 est un procédé d'accélération de la convergence de suites en analyse numérique, popularisé par le mathématicien Alexander Aitken en 1926. C'est l'un des algorithmes d'accélération de la convergence les plus populaires du fait de sa simplicité et de son efficacité. Une première forme de cet algorithme a été utilisée par Seki Kōwa (fin du ) pour calculer une approximation de formula_1 par la méthode des polygones d'Archimède.

Soit une suite formula_2 convergente vers une limite que l'on souhaite déterminer, le procédé Delta-2 de Aitken associe à cette suite une autre suite définie par :

C'est de la première écriture que le procédé tire son nom.
Sous certaines conditions, la suite "Ax" converge plus vite que la suite initiale "x", ce qui permet d'estimer la limite de la suite avec une meilleure précision et/ou en effectuant moins de calculs.

C'est un algorithme numériquement peu stable : il convient de calculer la suite "x" ainsi que "Ax" avec un nombre important de chiffres significatifs. Certaines écritures de l'algorithme propagent moins les erreurs d'arrondi, par exemple :

La suite "Ax" étant elle-même une suite numérique, il est possible de lui appliquer le Delta-2, et ainsi de suite : c'est ce qu'on appelle une application itérée du Delta-2.

Le Delta-2 est un algorithme non linéaire d'accélération de la convergence. Mais il vérifie la propriété :

Le Delta-2 détermine une estimation de la limite de la suite "x" en partant de l'hypothèse que celle-ci vérifie l'équation aux différences suivante :

En résolvant cette équation aux différences, les suites (dont le Delta-2 détermine de manière immédiate la limite) sont de la forme :

Il est à noter que même si la suite "x" diverge, c'est-à-dire si |λ| > 1, le Delta-2 converge vers « l'anti-limite » de la suite.
Le théorème de convergence pour le procédé de Aitken est :

alors Ax converge vers formula_8 plus vite que x.
Le Delta-2 est donc particulièrement bien adapté aux suites à convergence linéaires (dont l'écart avec leur limite se comporte à l'infini comme une suite géométrique).

Le Delta-2 est un cas particulier de certaines transformations plus générales :

Le Delta-2 peut être utilisé pour accélérer la convergence des séries en extrayant une suite numérique d'après leur somme partielle.

La précision obtenue par le Delta-2 avec seulement 9 termes, serait obtenue en sommant plus de 4000 termes de la suite non accélérée.

La convergence d'un procédé itératif de point fixe du type formula_11 peut être accéléré de plusieurs manières :


Cette deuxième stratégie, appliquée systématiquement toutes les 3 itérations, est appelé procédé de Aitken-Steffensen. Il permet la plupart des cas de transformer une convergence (ou divergence) linéaire en convergence quadratique, et une convergence quadratique en super-quadratique. Le procédé de Aitken-Steffensen remplace l'itération d'origine formula_11 par

L'équation (appelée équation de Kepler, liée au calcul d'orbites en astronomie)

où "x" est l'inconnue ("M" et "a" étant connus), peut être résolue par exemple par l'itération :

D'après le théorème du point fixe, cette suite converge vers la solution de l'équation de départ, si "a" < 1. Mais cette suite sera d'autant plus lente à converger que "a" sera proche de 1 (cas fréquemment rencontré en pratique, car typique des orbites des comètes). Il sera intéressant dans ce cas d'accélérer la convergence avec le Delta-2 ou le procédé d'Aitken-Steffensen.

Par exemple, pour "a" = 0,9 et "M" = 0,01 (solution x = ...), on obtient :
Les colonnes des Delta-2 ont été décalés vers le bas pour mettre sur une même ligne les itérés de base nécessaires à leur calcul, et ainsi mieux visualiser le gain apporté par l'accélération de la convergence vis-à-vis des itérations de base.
On constate une nette accélération de la convergence de la suite initiale par le Delta-2. Les applications itérées du Delta-2 l'accélèrent encore davantage, mais le résultat le plus spectaculaire est obtenu par la méthode de Steffensen (les nombres en gras montrent l'application du Delta-2 toutes les 3 itérations). Pour obtenir la même précision que le Delta-2 après 12 itérations, il aurait fallu itérer 50 fois la formule de base, et l'itérer 300 fois pour être équivalent à la méthode de Steffensen.


Lorsque l'itération de base a une convergence quadratique (par exemple avec la méthode de Newton), le Delta-2 ou la méthode de Steffensen, quoique accélérant la convergence, présente moins d'intérêt pratique. Le calcul d'une itération de base supplémentaire permet souvent d'obtenir le même résultat que la valeur accélérée.

La valeur de formula_16 peut être calculé par la méthode de Héron, en partant d'une valeur initiale "x" et la suite récurrente (à convergence quadratique) :

En partant de "x" = 1 :

On constate certes un gain en précision en accélérant la convergence, mais l'itérée de base suivante est du même ordre de précision, pour un moindre coût en calcul.


Ce procédé est notamment utilisé pour accélérer l'algorithme de décomposition de domaine de type Schwarz (additifs et multiplicatifs). En effet, on peut remarquer que sous certaines conditions, les coefficients de Fourier liés aux solutions itérées obtenus ont une convergence purement linéaire. Par ce principe, on peut réduire le nombre total d'itérations de l'algorithme à 3 ou 5 itérations pour des problèmes 1D ou 2D (respectivement).

Claude Brezinski, "Algorithmes d'accélération de la convergence : étude numérique", éditions Technip, 1978, 



</doc>
<doc id="15716" url="https://fr.wikipedia.org/wiki?curid=15716" title="Méridien">
Méridien


En chacun de leurs points, tous les méridiens sont perpendiculaires à tous les parallèles. Par ailleurs, ils ont tous la même longueur égale à . Ce sont des demi-ellipses et, comme géodésiques, ce sont également les plus courtes distances entre deux de leurs points.

Par convention, il existe sur Terre 360 méridiens séparés par un degré d'arc.

Au niveau de l'équateur, la distance entre deux méridiens est égale à 1/360 partie de la longueur de l'équateur, soit approximativement. En s'éloignant de l'équateur, cet écart diminue. Il est proportionnel au 1/360 partie de l'équateur multiplié par le cosinus de la latitude. Ainsi, à de latitude, la distance entre deux méridiens est égale à multiplié par le cosinus de , soit 0,707, ce qui fait approximativement. À de latitude, l'écart entre deux méridiens passe à , le cosinus de cette latitude étant égal à 0,5. Aux pôles géographiques, la distance entre les méridiens est nulle puisqu'ils y convergent (cos 90° = 0).

Un fuseau horaire est une portion de la surface du globe, limitée par deux méridiens que séparent 15° de longitude. Puisqu'un jour solaire fait , il y a horaires qui se répartissent sur 360°. Au niveau de l'équateur chaque fuseau horaire a une largeur de divisé par 24, soit approximativement . Cette largeur diminue jusqu'à tendre vers zéro au niveau des pôles.

Le mille nautique a été défini comme la 1/60 partie d'un degré d'un arc de méridien ; il équivaut en moyenne à .

Si les latitudes peuvent être mesurées à partir de l'équateur, il n'existe pas de référence naturelle équivalente pour fixer l'origine des longitudes. Il est donc nécessaire de définir un méridien d'origine, où les points ont par définition une longitude égale à zéro.

Actuellement, le méridien d'origine pour la plupart des systèmes géodésiques est voisin du méridien de Greenwich qui passe par l'observatoire de Greenwich, en Angleterre. Jusqu'au début du , différents pays utilisèrent d'autres méridiens d'origine comme le méridien de Paris en France (02° 20' 14,025" E), le méridien de Berlin en Allemagne (13° 24' E), le méridien de Tolède en Espagne ou le méridien d'Uppsala en Suède. 

En France, le roi Louis XIII décréta par ordonnance en 1634 que le premier méridien serait celui dit de l'Île de Fer (aujourd'hui île d'El Hierro dans l'archipel des îles Canaries), arbitrairement situé à 20°00'00" à l'ouest du méridien de Paris. Cette localisation permettait d'obtenir une longitude positive pour toutes les terres européennes et a été longtemps suivie par plusieurs autres pays.

Choisir un méridien d'origine de longitude 0° implique l'existence d'un antiméridien, situé à l'opposé sur le globe. La ligne de changement de date suit cet antiméridien sur la majeure partie de sa longueur.

La première définition du mètre a été édictée par le décret de l'Assemblée Nationale du 30 mars 1793. Il représentait le dix-millionième de la longueur du quart du méridien terrestre de l'époque, qui était considéré comme faisant le tour de la Terre. Cette longueur est d'abord approximative car la référence doit encore être mesurée. Jean-Baptiste Joseph Delambre et Pierre Méchain s'attèlent à la mesure de la distance entre Dunkerque et Barcelone, et après la publication de leur rapport, le mètre étalon est définitivement fixé par la loi du (10 décembre 1799) :

ART . 
La fixation provisoire de la longueur du mètre, à trois pieds onze lignes quarante-quatre centièmes, ordonnée par les lois des août 1793 et 18 germinal an III, demeure révoquée et comme non avenue. Ladite longueur, formant la dix-millionième partie de l'arc du méridien terrestre compris entre le pôle nord et l'équateur, est définitivement fixée, dans son rapport avec les anciennes mesures, à trois pieds onze lignes deux cent quatre-vingt-seize millièmes.

C'est un méridien particulier passant par les pôles magnétiques.

Certaines frontières entre pays ou régions ont été déterminées par des méridiens, bien que le cas soit moins fréquent que pour les parallèles. En partant vers l'est depuis le méridien de Greenwhich, on peut noter :




</doc>
<doc id="15717" url="https://fr.wikipedia.org/wiki?curid=15717" title="Gaz">
Gaz

Un gaz est un ensemble d'atomes ou de molécules très faiblement liés et quasi indépendants. Dans l’état gazeux, la matière n'a pas de forme propre ni de volume propre : un gaz tend à occuper tout le volume disponible. Cette phase constitue l'un des quatre états dans lequel peut se trouver un corps pur, les autres étant les phases solide, liquide et plasma (ce dernier, proche de l'état gazeux, s'en distingue par sa conduction électrique). Le passage de l'état liquide à l'état gazeux est appelé vaporisation. On qualifie alors le corps de "vapeur" (par exemple la vapeur d'eau).

À basse pression, les gaz réels ont des propriétés semblables qui sont relativement bien décrites par le modèle du gaz parfait. La masse volumique d'un corps pur atteint son minimum à l'état gazeux. Elle décroît sous l'effet d'une baisse de pression (loi de Gay-Lussac et loi de Charles) ou d'une hausse de la température (on parle de dilatation des gaz). Les mouvements chaotiques des molécules qui composent le corps le rendent informe et lui permettent d'occuper entièrement l'espace clos qui le contient. Une propriété remarquable des gaz parfaits, valable approximativement pour les gaz réels, est que, dans les mêmes conditions de température et de pression, un volume donné contient toujours le même nombre de molécules quelle que soit la composition du gaz (loi d'Avogadro).

Au tout début du , un chimiste flamand, Jean-Baptiste Van Helmont, utilisa le mot « "gas" » par rapprochement avec le mot « chaos » (en néerlandais « ch » et « g » se prononcent de la même façon) venant du grec το χαος-χαους qui désigne l'espace immense et ténébreux qui existait avant l'origine des choses (dans la mythologie). En effet, il voulait introduire une notion de vide. Peu après, les français écrivirent « gas » avec un z : gaz. Ce n'est qu'à la fin du que le mot prit son sens moderne.

Les gaz sont miscibles entre eux : on parle de "mixage" pour l'action de mélanger et, de "mélange gazeux" pour l'état mélangé. Exemple : l'air sec, épuré de son dioxyde de carbone, est un mélange composé principalement de 78 % de diazote (), de 21 % de dioxygène () et de 1 % d'argon (Ar).

Un gaz peut se dissoudre dans l'eau (loi de Henry), ou d'autres liquides (comme le sang). Par exemple la pression d'oxygène dans le sang artériel PaO2 est de , et la pression du dioxyde de carbone PaCO2 est de . Les gaz dissous dans le sang peuvent créer des embolies gazeuses en cas de décompression rapide lors d'une plongée sous-marine .

Un gaz peut même se dissoudre (faiblement) dans un métal (adsorption, désorption).

La combustion des gaz oxydables est très importante en chimie, en chimie organique et, donc dans la vie courante.

Des transformations d'état, les "transitions de phase", affectent les gaz. 

Le passage direct de l'état solide à l'état gazeux est appelé "sublimation" (par exemple, le dioxyde de carbone , ou neige carbonique) ; la transformation inverse s'appelle "déposition", "condensation solide" ou encore "sublimation inverse".

Quand un liquide passe à l'état gazeux, il y a "vaporisation" (soit par évaporation, soit par ébullition). L'inverse s'appelle la "liquéfaction".

En chimie : gaz halogènes, gaz rares, gaz naturel

En physique : gaz parfait, gaz réel, ionisation des gaz, théorie cinétique des gaz

Pour les applications technologiques : compression des gaz, Histoire de la liquéfaction des gaz, machine à vapeur, moteur à gaz, moteur à combustion interne

En relation avec les phénomènes atmosphériques : air, atmosphère, effet de serre, gaz à effet de serre, ozone, couche d'ozone oxyde d'azote









</doc>
<doc id="15718" url="https://fr.wikipedia.org/wiki?curid=15718" title="Small Computer System Interface">
Small Computer System Interface

Le standard décrit les spécifications mécaniques, électriques et fonctionnelles du bus.


Ce bus diffère des autres en ce qu'il déporte la complexité vers le périphérique lui-même. Ainsi, les commandes envoyées au périphérique peuvent être complexes, le périphérique devant alors (éventuellement) les décomposer en sous-tâches plus simples, ce qui est avantageux si l'on travaille avec des systèmes d'exploitation multitâche.

Cette interface est donc plus rapide, plus universelle et plus complexe que l'interface E-IDE dont le principal inconvénient est d'accaparer un pourcentage non négligeable du processeur, ce qui constitue un handicap quand de nombreux flux de données sont simultanément ouverts.

Plus « intelligente » et moins dépendante de l'unité centrale, l'interface SCSI peut gérer des périphériques internes et externes très variés, tels que disques durs, scanners, graveurs, unités de sauvegardes, etc.

La norme SCSI-2 précise que le bus peut relier entre eux :


avec des périphériques tels que :


La norme ne restreint pas l'utilisation du bus à l'interconnexion d'un ordinateur avec des périphériques, elle l'élargit au contraire à des interconnexions entre ordinateurs, ou pour partager des périphériques entre ordinateurs.

La norme SCSI-3 est plus généraliste. On se référera à la page du comité technique pour en avoir le détail.

Le SCSI-3 présente comme énorme changement l'apparition d'un bus série, dans une technologie jusqu'à présent exclusivement parallèle. Il apporte aussi quelques nouveautés et améliorations dans l'interface parallèle.

La fréquence du bus est doublée. On passe donc de 40 à . Les périphériques SE ne sont plus du tout compatibles avec ces fréquences à cause des phénomènes de réverbération.

L'interface Ultra 160 utilise le LVD, elle n'est absolument plus compatible avec SCSI-1 et 2. L'Ultra 160 apporte de lourdes modifications dans la gestion du transfert de données.




L'interface 320 apporte des modifications supplémentaires par rapport à l'ultra160, ce qui permet d'augmenter encore la fréquence de travail à et d'augmenter les débits utiles.





Avec l'augmentation des fréquences de transfert, les décalages entre les signaux et leur sensibilité au bruit et aux capacités parasites deviennent problématiques et causent des restrictions dans la longueur des câbles. On passe donc sur des bus série (un seul fil) qui évite les problèmes de courants induits.

La réflexion sur des interfaces séries fut commencée avant la mise au point de l'Ultra 160 et 320. Mais les débits offerts sont tels que ces technologies restent tout à fait viables. L'objectif de l'interface série réside dans le fait d'empaqueter les commandes et données SCSI, afin de les transférer via un seul fil, tout en conservant la compatibilité SCSI (afin de conserver l'avantage, notamment, de la possibilité de stockage des commandes, très utile en fonctions multi-tâches).
On retrouve de nombreux avantages dans ces technologies, on peut citer notamment :

On peut citer comme technologies séries utilisant les commandes SCSI : 

La norme SCSI-2 de 1994 est une amélioration du SCSI-1. Certains points ont été améliorés ou rendus obligatoires. Théoriquement SCSI-1 et SCSI-2 ont une compatibilité descendante. 
On peut noter que l'utilisation des bits de parité a été rendue obligatoire avec le SCSI-2.

On utilise des transferts synchrones de haut débit, ce qui permet des taux de transfert de sur un câblage , et de 20 ou si on est sur du 16 ou (avec une fréquence de ).

On a la possibilité de travailler avec des bus plus larges de 16 ou , ce qui permet des débits plus importants. On utilisait un câble A (50 broches) pour les transmissions sur , le SCSI-2 avait prévu un câble B (68 broches) pour les bus plus larges. Mais il n'a pas rencontré de réel succès, on lui préfère le câble P (68 broches également) défini dans le SCSI-3. Pour le , le câble P doit être utilisé avec un câble Q (68 broches lui aussi).

Le SCSI-1 ne permettait d'envoyer les commandes qu'une à une. Le SCSI-2 permet d'envoyer jusqu'à 256 commandes à un périphérique. Elles seront stockées et traitées dans l'ordre optimal par le périphérique. Ceci permet d'augmenter les performances de travail du périphérique et prend un intérêt fort quand on travaille avec des systèmes d'exploitation multi-tâche (Linux, MS-Windows NT etc.) qui peuvent être amenés à faire plusieurs requêtes simultanément à un périphérique (plusieurs accès en lecture sur un disque dur par exemple).






</doc>
<doc id="15719" url="https://fr.wikipedia.org/wiki?curid=15719" title="Programme Apollo">
Programme Apollo

Le programme "Apollo" est le programme spatial de la NASA mené durant la période 1961 – 1975 qui a permis aux États-Unis d'envoyer pour la première fois des hommes sur la Lune. Il fut lancé par John F. Kennedy le , essentiellement pour reconquérir le prestige américain mis à mal par les succès de l'astronautique soviétique, à une époque où la guerre froide entre les deux superpuissances battait son plein.

Le programme avait pour objectif de poser un homme sur la Lune avant la fin de la décennie. Le , cet objectif était atteint par deux des trois membres d'équipage de la mission , Neil Armstrong et Buzz Aldrin. Cinq autres missions se sont posées par la suite sur d'autres sites lunaires et y ont séjourné jusqu'à trois jours. Ces expéditions ont permis de rapporter de roche lunaire et de mettre en place plusieurs batteries d'instruments scientifiques. Les astronautes ont effectué des observations "in situ" au cours d'excursions sur le sol lunaire d'une durée pouvant atteindre huit heures, assistés à partir par un véhicule tout-terrain, le rover lunaire.

Aucun vol orbital américain n'avait encore été réalisé en mai 1961. Pour remplir l'objectif fixé par le président, la NASA lança plusieurs programmes destinés à préparer les futures expéditions lunaires : le programme "Gemini" pour mettre au point les techniques de vol spatial et des programmes de reconnaissance (programme "Surveyor", "Ranger"…) pour, entre autres, cartographier les zones d'atterrissage et déterminer la consistance du sol lunaire. Pour atteindre la Lune, les responsables finirent par se rallier à la méthode audacieuse du rendez-vous en orbite lunaire, qui nécessitait de disposer de deux vaisseaux spatiaux dont le module lunaire destiné à l'atterrissage sur la Lune. La fusée géante de , capable de placer en orbite basse , fut développée pour lancer les véhicules de l'expédition lunaire. Le programme drainera un budget considérable ( milliards de dollars US actuels) et mobilisera jusqu'à . Deux accidents graves sont survenus au cours du projet : l'incendie au sol du vaisseau spatial dont l'équipage périt brûlé et qui entraîna un report de près de deux ans du calendrier et l'explosion d'un réservoir à oxygène du vaisseau spatial dont l'équipage survécut en utilisant le module lunaire comme vaisseau de secours.

Les missions lunaires ont permis d'avoir une meilleure connaissance de notre satellite naturel. Le programme "Apollo" a favorisé la diffusion d'innovations dans le domaine des sciences des matériaux et a contribué à l'essor de l'informatique ainsi que des méthodes de gestion de projet et de test. Les photos de la Terre, monde multicolore isolé dans un espace hostile, ainsi que celles de la Lune, monde gris et mort, ont favorisé une prise de conscience mondiale sur le caractère exceptionnel et fragile de notre planète. Le programme est à l'origine d'une scission dans la communauté scientifique et parmi les décideurs entre partisans d'une exploration robotique jugée plus efficace et ceux pour qui l'exploration humaine a une forte valeur symbolique, qui justifie son surcoût.

Durant les années 1950, la guerre froide bat son plein entre les États-Unis et l'Union soviétique, les deux superpuissances de l'époque. Celle-ci se traduit par des affrontements militaires indirects (guerre de Corée), et une course aux armements qui porte notamment sur le développement de missiles intercontinentaux porteurs de têtes militaires nucléaires capables d'atteindre le territoire national de l'adversaire. Les deux pays développent ces fusées en s'appuyant largement sur les travaux et l'expertise de savants et techniciens allemands qui ont mis au point le premier engin de ce type lors de la Seconde Guerre mondiale, la fusée V2. L'Union soviétique prend une certaine avance en réussissant le premier tir d'un missile intercontinental, la R-7 Semiorka, ancêtre direct de la fusée Soyouz. Cette fusée de est particulièrement puissante car elle doit emporter une bombe A pesant . Les missiles américains à longue portée, développés plus tardivement, car conçus pour lancer des bombes H techniquement plus avancées et beaucoup plus légères (), sont de taille plus réduite et sont encore en phase de mise au point à la fin des années 1950.

En juillet 1955, les États-Unis et l'URSS annoncent, chacun de leur côté, qu'ils lanceront un satellite artificiel dans le cadre des travaux scientifiques prévus pour l'Année géophysique internationale (juillet 1957—décembre 1958).
Début 1956, le concepteur de la Semiorka, Sergueï Korolev, réussit à convaincre les dirigeants soviétiques d'utiliser son missile comme lanceur spatial.
À la surprise générale, le , l'Union soviétique est la première à placer en orbite le satellite Spoutnik 1. L'opinion internationale est fascinée par cet événement qui semble présager le début d'une nouvelle ère technique et scientifique. C'est un choc pour les responsables et l'opinion publique américains, jusqu'alors persuadés de leur supériorité technique. Les dirigeants soviétiques, d'abord surpris par l'impact de ce lancement, ne tardent pas à comprendre le prestige international que le régime peut retirer des succès de sa politique spatiale ; ils décident de se lancer dans un programme ambitieux.

À la même époque, le programme Vanguard, pendant américain du programme spatial russe lancé tardivement et trop ambitieux, enchaîne les échecs. L'équipe de Wernher von Braun parvient finalement à lancer le premier satellite américain, Explorer 1, le grâce au lanceur improvisé à partir d'un missile balistique Redstone. Mais la petite taille de la charge utile comparée à celle de Spoutnik semble confirmer l'avance soviétique. Bien que réticent à investir massivement dans le spatial civil, le président américain Dwight D. Eisenhower décide le de la création d'une agence spatiale civile, la NASA, qui doit permettre de fédérer les efforts américains pour mieux contrer les réussites soviétiques : la course à l'espace est lancée. La même année voit le début du programme Mercury qui doit permettre la mise en orbite des premières missions habitées américaines.

Mais les Soviétiques, qui disposent d'une avance importante et d'une fusée fiable pouvant emporter une grosse charge utile, continuent au cours des années suivantes de multiplier les premières : premier être vivant placé en orbite avec la chienne Laïka (Spoutnik 2), premier satellite à échapper à l'attraction terrestre (Luna 1), premier satellite à s'écraser sur la Lune (Luna 2), première photo de la face cachée de la Lune (Luna 3), premier être vivant à revenir vivant après un séjour dans l'espace (les chiens Belka et Strelka de Spoutnik 5), premier survol de Vénus (Venera 1).

Lorsqu'il arrive au pouvoir en janvier 1961, le président américain John F. Kennedy est, comme son prédécesseur, peu enclin à donner des moyens importants au programme spatial civil. Mais le lancement du premier homme dans l'espace par les Soviétiques (Youri Gagarine, ) le convainc de la nécessité de disposer d'un programme spatial ambitieux pour récupérer le prestige international perdu. L'échec du débarquement de la baie des Cochons () destiné à renverser le régime de Fidel Castro installé à Cuba, qui écorne un peu plus l'image des États-Unis auprès des autres nations, contribue également sans doute à son changement de position.

John Kennedy demande à son vice-président Lyndon B. Johnson de lui désigner un objectif qui permettrait aux États-Unis de reprendre le leadership à l'Union soviétique. Parmi les pistes évoquées figurent la création d'un laboratoire spatial dans l'espace et un simple survol lunaire. Le vice-président, qui est un ardent supporter du programme spatial, lui répond que la recherche et l'industrie américaine ont la capacité d'envoyer une mission habitée sur la Lune et lui recommande de retenir cet objectif. Le , le président annonce devant le Congrès des États-Unis, lors du "Special Message to the Congress on Urgent National Needs", le lancement d'un programme qui doit amener des astronautes américains sur le sol lunaire « avant la fin de la décennie ». Il confirme sa décision dans un autre discours resté célèbre, « "we choose to go to the Moon" », le .

La proposition du président reçoit un soutien enthousiaste des élus de tous les horizons politiques ainsi que de l'opinion publique, traumatisés par les succès de l'astronautique soviétique. Le premier budget du nouveau programme baptisé "Apollo" — nom choisi par Abe Silverstein à l'époque directeur des vols spatiaux habités — est voté à l'unanimité par le Sénat américain. Les fonds alloués à la NASA vont passer de de dollars à de dollars en 1966, année de son budget le plus conséquent (environ ). La NASA, grâce aux qualités manœuvrières de son administrateur James E. Webb, un vieux routier de la politique, put obtenir chaque année les fonds qu'elle souhaitait jusqu'au débarquement sur la Lune, même lorsque le soutien des élus commença à faiblir après 1963. James Webb sut en particulier s'assurer un appui solide auprès du président Lyndon B. Johnson qui avait succédé au président Kennedy assassiné en 1963.
Dès 1959 des études sont lancées au sein de l'agence spatiale américaine dans une perspective à long terme, sur la manière de poser un engin habité sur la Lune. Trois scénarios principaux se dégagent :

Lorsque le président américain John Kennedy donne à la NASA, en 1961, l'objectif de faire atterrir des hommes sur la Lune avant la fin de la décennie, l'évaluation de ces trois méthodes est encore peu avancée. L'agence spatiale manque d'éléments : elle n'a pas encore réalisé un seul véritable vol spatial habité (le premier vol orbital de la capsule Mercury n'a lieu qu'en septembre 1961). L'agence spatiale ne peut évaluer l'ampleur des difficultés soulevées par les rendez-vous entre engins spatiaux et elle ne maîtrise pas l'aptitude des astronautes à supporter de longs séjours dans l'espace et à y travailler ; ses lanceurs ont essuyé par ailleurs une série d'échecs qui l'incite à la prudence dans ses choix techniques.

Aussi, bien que le choix de la méthode conditionne les caractéristiques des véhicules spatiaux et des lanceurs à développer et que tout retard pris dans cette décision pèse sur l'échéance, la NASA va mettre plus d'un an, passé en études et en débats, avant que le scénario du LOR soit finalement retenu.

Au début de cette phase d'étude, la technique du rendez-vous en orbite lunaire (LOR) est la solution qui a le moins d'appui malgré les démonstrations détaillées de John C. Houbolt du Centre de Recherche de Langley, son plus ardent défenseur. Aux yeux de beaucoup de spécialistes et responsables de la NASA, le rendez-vous entre module lunaire et module de commande autour de la lune paraît instinctivement trop risqué : si les modules n'arrivent pas à se rejoindre en orbite lunaire, les astronautes occupant le module lunaire n'ont pas le recours de freiner leur engin pour se laisser redescendre vers la Terre contrairement aux autres scénarios ; ils sont alors condamnés à tourner indéfiniment autour de la Lune. Les avantages du LOR, en particulier le gain sur la masse à placer en orbite, ne sont pas appréciés à leur juste mesure. Toutefois, au fur et à mesure que les autres scénarios sont approfondis, le LOR gagne en crédibilité. Les partisans du vol direct — Max Faget et ses hommes du Centre des Vols Habités se rendent compte de la difficulté de faire atterrir un vaisseau complet sur le sol lunaire accidenté et aux caractéristiques incertaines. Wernher von Braun, qui dirige l'équipe du Centre de vol spatial Marshall qui doit développer le lanceur et est partisan d'un rendez-vous orbital terrestre, finit lui-même par être convaincu que le LOR est le seul scénario qui permettra de respecter l'échéance fixée par le président Kennedy.
Au début de , alors que les principaux responsables de la NASA se sont tous convertis au LOR, ce scénario se heurte au veto de Jerome B. Wiesner, conseiller scientifique du président Kennedy. Le choix du LOR est finalement entériné le . Dès , onze sociétés aérospatiales américaines sont sollicitées pour la construction du module lunaire sur la base d'un cahier des charges sommaire.

Le , soit vingt jours avant le lancement du programme "Apollo", l'astronaute Alan Shepard effectue le premier vol spatial américain (mission Mercury 3). En fait, il s'agit d'un simple vol suborbital car la fusée Mercury-Redstone utilisée (il n'y a pas d'autre lanceur disponible) n'a pas une puissance suffisante pour placer en orbite la petite capsule spatiale Mercury d'une masse un peu supérieure à une tonne. Le programme lunaire nécessite de pouvoir placer en orbite basse une charge utile de . Le changement d'échelle qui en résulte est particulièrement important : la NASA va passer de la fusée de qui a lancé Alan Shepard aux de qui nécessitera de développer des moteurs d'une puissance aujourd'hui inégalée ainsi que des technologies nouvelles comme l'utilisation de l'hydrogène liquide.

Les effectifs affectés au programme spatial civil vont croître en proportion. , le nombre d'employés de la NASA passe . Pour accueillir ses nouveaux effectifs et disposer d'installations adaptées au programme lunaire, la NASA crée trois nouveaux centres entièrement affectés au programme "Apollo" aux périmètres précisément délimités :

Le Manned Spacecraft Center (MSC), édifié près de Houston au Texas, est destiné à la conception et la qualification des vaisseaux spatiaux (module lunaire et CSM), l'entraînement des astronautes et le suivi des missions à partir de leur décollage. Parmi les installations présentes sur le site, on trouve le centre de contrôle des missions, les simulateurs de vol et des équipements destinés à simuler les conditions spatiales et utilisés pour tester les livraisons des industriels. Le centre est dirigé par Robert Gilruth, ancien ingénieur de la NACA, qui joue un rôle de premier plan pour l'activité des vols habités américains depuis 1958. Contrairement aux deux autres établissements créés pour le programme "Apollo", le MSC est activé dès le programme "Gemini". Il emploie dont de sociétés aérospatiales.

Le Centre de vol spatial Marshall (George C. Marshall Space Flight Center ou MSFC) est une ancienne installation de l'Armée de Terre (Redstone Arsenal) située près de Huntsville dans l'Alabama transférée à la NASA avec les spécialistes en majorité allemands de missiles balistiques dirigés par Wernher von Braun qui y travaillaient. Von Braun en restera le responsable jusqu'en 1970. Le centre est spécialisé dans la conception et la qualification des lanceurs de la famille Saturn. On y trouve des bancs d'essais, des bureaux d'étude et des installations d'assemblage. Les premiers exemplaires de la fusée y sont construits avant que le reste de la production soit confié à l'industrie. Il emploiera jusqu'à .

Le Centre spatial Kennedy (KSC), situé sur l'île Meritt en Floride, est le site d'où sont lancées les fusées géantes du programme "Apollo". La NASA qui a besoin d'installations à l'échelle de la fusée met en construction cette nouvelle base de lancement qui jouxte celle de Cape Canaveral appartenant à l'Armée de l'Air américaine et d'où sont parties, jusqu'alors, toutes les missions habitées et les sondes spatiales de l'agence spatiale. Le centre effectue la qualification de la fusée assemblée (« all up ») et contrôle les opérations sur le lanceur jusqu'à son décollage. Il emploie environ . Au cœur du centre spatial, le complexe de lancement 39 comporte deux aires de lancement et un immense bâtiment d'assemblage, le VAB (hauteur ), dans lequel plusieurs fusées peuvent être préparées en parallèle. Plusieurs plates-formes de lancement mobiles permettent de transporter la fusée Saturn assemblée jusqu'au site de lancement. Le premier lancement depuis le nouveau terrain est celui en 1967. Jusqu'en 2011, le complexe était utilisé pour lancer la navette spatiale américaine.

D'autres établissements de la NASA, jouent un rôle moins direct ou ne consacrent qu'une partie de leur activité au programme "Apollo". En 1961, le Centre spatial John C. Stennis est édifié dans l'État du Mississippi. Le nouveau centre dispose de bancs d'essais utilisés pour tester les moteurs-fusées développés pour le programme. L'Ames Research Center est un centre de recherche ancien (1939) situé en Californie dont les souffleries sont utilisées pour mettre au point la forme de la capsule Apollo en vue de sa rentrée dans l'atmosphère terrestre. Le Langley Research Center (1914), situé à Hampton (Virginie) abrite également de nombreuses souffleries. Il a servi de siège au MSC et continue, par la suite, à abriter certains simulateurs du programme. Le Jet Propulsion Laboratory (1936), près de Los Angeles (Californie), est spécialisé dans le développement des sondes spatiales. C'est dans ce centre que sont conçues les familles de sondes spatiales qui vont permettre de reconnaître l'environnement lunaire (programme "Surveyor").

Les principales entreprises de l'astronautique sont fortement impliquées dans le programme qui se traduit par un accroissement considérable des effectifs — le personnel affecté aux projets de la NASA passe durant cette période — et la construction d'établissements de grande taille. La société californienne North American, avionneur célèbre pour avoir construit les B-25 et le chasseur Mustang durant la Seconde Guerre mondiale, va jouer un rôle central dans le programme. L'arrêt et l'échec de plusieurs projets aéronautiques ont conduit son président à miser sur le développement de l'astronautique. La société s'est déjà distinguée dans le domaine en produisant l'avion fusée X-15. Pour le programme "Apollo", la société fournit pratiquement tous les composants sensibles hormis le module lunaire qui est confié à la société Grumman implantée à Bethpage, Long Island (État de New York). La division moteur Rocketdyne de North American fabrique les deux principaux moteurs-fusées les J-2 et F-1 dans l'usine de Canoga Park, tandis que sa division Espace construit le deuxième étage de la à Seal Beach et le module de commande et de service Apollo à Downey. L'incendie du vaisseau et de nombreux problèmes rencontrés dans le développement du programme entraîneront la fusion de North American avec la société Rockwell Standard Corporation ; le nouveau groupe développera dans les la navette spatiale américaine avant d'être absorbé par Boeing. La société McDonnell Douglas construit le troisième étage de la à Huntington Beach en Californie tandis que le premier étage est construit dans l'établissement de Michoud (Louisiane) de la NASA par la société Chrysler. Parmi les fournisseurs de premier plan figure le laboratoire des instruments du Massachusetts Institute of Technology (MIT) qui conçoit le système de pilotage et de navigation des deux vaisseaux habités Apollo.

Le projet "Apollo" a constitué un défi sans précédent sur le plan de la technique et de l'organisation : il fallait mettre au point un lanceur spatial dont le gigantisme générait des problèmes jamais rencontrés jusque-là, deux nouveaux moteurs innovants par leur puissance (F-1) ou leur technologie (J-2), des vaisseaux spatiaux d'une grande complexité avec une exigence de fiabilité élevée (probabilité de perte de l'équipage inférieure à 0,1 %) et un calendrier très tendu (huit ans entre le démarrage du programme "Apollo" et la date butoir fixée par le président Kennedy pour le premier atterrissage sur la Lune d'une mission habitée). Le programme a connu de nombreux déboires durant la phase de développement qui ont tous été résolus grâce à la mise à disposition de ressources financières exceptionnelles avec un point culminant (5,5 % du budget fédéral alloué à la NASA), mais également une mobilisation des acteurs à tous les niveaux et la mise au point de méthodes organisationnelles (planification, gestion de crises, gestion de projet) qui ont fait école par la suite dans le monde de l'entreprise.

La mise au point du moteur F-1, d'architecture conventionnelle mais d'une puissance exceptionnelle ( d'ergols brûlés par seconde) fut très longue à cause de problèmes d'instabilité au niveau de la chambre de combustion qui ne furent résolus qu'en combinant études empiriques (comme l'utilisation de petites charges explosives dans la chambre de combustion) et travaux de recherche fondamentale. Le deuxième étage de la fusée , qui constituait déjà un tour de force technique du fait de la taille de son réservoir d'hydrogène, eut beaucoup de mal à faire face à la cure d'amaigrissement imposée par l'augmentation de la charge utile au fur et à mesure de son développement.
Mais les difficultés les plus importantes touchèrent les deux modules habités du programme : le CSM et le module lunaire Apollo. Le lancement du développement du module lunaire avait pris un an de retard à cause des atermoiements sur le scénario du débarquement lunaire. Il s'agissait d'un engin entièrement nouveau pour lequel aucune expérience antérieure ne pouvait être utilisée, par ailleurs très complexe du fait de son rôle. Les problèmes multiples — masse nettement supérieure aux prévisions initiales, difficulté de mise au point des logiciels indispensables à la mission, qualité déficiente, motorisation — entraînèrent des retards tellement importants qu'ils mirent à un moment en danger la tenue de l'échéance du programme tout entier.

Les tests prennent une importance considérable dans le cadre du programme puisqu'ils représentent près de 50 % de la charge de travail totale. L'avancée de l'informatique permet pour la première fois dans un programme astronautique, de dérouler automatiquement la séquence des tests et l'enregistrement des mesures de centaines de paramètres ( pour un étage de la fusée ) ce qui permet aux ingénieurs de se concentrer sur l'interprétation des résultats et réduit la durée des phases de qualification. Chaque étage de la fusée subit ainsi quatre séquences de test : un test sur le site du constructeur, deux sur le site du MSFC, avec et sans mise à feu avec des séquences de test par sous-système puis répétition du compte à rebours et un test d'intégration enfin au centre spatial Kennedy une fois la fusée assemblée.

Le premier groupe de sept astronautes sélectionnés pour le programme Mercury avait été recruté parmi les pilotes d'essais militaires ayant un diplôme de niveau minimum licence dans des domaines touchant à l'ingénierie, âgés de moins de et satisfaisant une batterie de critères physiques et psychologiques. Les vagues de recrutement effectuées ( du ), 1963 ( du ) ( du ) utilisent les mêmes critères de sélection en abaissant l'âge puis , diminuant l'exigence en nombre d'heures de vol et élargissant la gamme des diplômes acceptés. En parallèle, deux groupes d'astronautes scientifiques détenteurs d'un doctorat sont recrutés () () dont un seul volera.

Les astronautes passent beaucoup de temps dans les simulateurs du CSM et du module lunaire mais reçoivent également, entre autres, des cours d'astronomie pour la navigation astronomique, de géologie pour les préparer à l'identification des roches lunaires et de photographie. Ils passent de nombreuses heures de vol sur des avions d'entraînement à réaction T-38 pour maintenir leur compétence de pilote (trois astronautes du se tueront en s'entraînant sur T-38). Ils sont impliqués très en amont dans le processus de conception et de mise au point des vaisseaux habités. Enfin, on leur demande de consacrer une partie de leur temps à des tâches de relations publiques qui se traduisent par des tournées dans les entreprises qui participent au projet. Deke Slayton joue un rôle officieux mais effectif de chef des astronautes en sélectionnant les équipages de chaque mission et défendant le point de vue des astronautes durant l'élaboration du projet et des missions.

Les véhicules spatiaux Apollo sont initialement conçus pour donner une autonomie complète à l'équipage en cas de coupure des communications avec le centre de contrôle à Terre. Cette autonomie procurée par les programmes du système de navigation et de pilotage sera dans les faits fortement réduite lorsque les procédures suivies par les missions "Apollo" seront figées : c'est le contrôle au sol à Houston qui fournira les principaux paramètres tels que la position du vaisseau spatial ainsi que le vecteur de la poussée avant chaque allumage des moteurs. Houston dispose au moment des premiers vols vers la Lune de moyens de calcul plus puissants et, grâce à la télémesure, connaît parfaitement la position des vaisseaux et leur trajectoire. Une fois une phase de vol engagée, c'est toutefois à l'ordinateur de bord d'appliquer les corrections nécessaires en se basant sur ses capteurs et ses capacités de calcul. Par ailleurs, l'ordinateur joue un rôle essentiel pour le contrôle des moteurs (fonction autopilote) et gère de nombreux sous-systèmes, ce qui lui vaut le surnom de quatrième homme de l'équipage. Sans l'ordinateur, les astronautes n'auraient pu poser le module lunaire sur la Lune car lui seul pouvait optimiser suffisamment la consommation de carburant pour se contenter des faibles marges disponibles.

La NASA est, dès le lancement du projet, très sensible aux problèmes de fiabilité. L'envoi d'astronautes sur le sol lunaire est une entreprise beaucoup plus risquée que les vols spatiaux autour de la Terre. Pour les missions en orbite terrestre, en cas d'incident grave, le retour est assuré relativement facilement par une brève poussée des rétrofusées. Par contre, une fois que le vaisseau a quitté l'orbite terrestre, un retour des astronautes sur Terre nécessite que les principaux sous-systèmes ne connaissent aucune défaillance. De manière assez empirique, la NASA avait déterminé que les composants du vaisseau devaient permettre d'atteindre une probabilité de succès de mission de 99 % tandis que la probabilité de perte de l'équipage devait être inférieure à 0,1 % en ne tenant pas compte des micro-météorites et des rayons cosmiques dont les effets étaient mal connus à l'époque. L'architecture des sous-systèmes et la qualité des composants élémentaires des véhicules et du lanceur devaient donc respecter ces objectifs.

Des choix techniques garantissant une grande fiabilité sont retenus sur le module lunaire comme sur le module de commande et de service. Les ergols liquides utilisés par les moteurs sont hypergoliques, c'est-à-dire qu'ils s'enflamment spontanément quand ils sont mis en contact et ne sont pas à la merci d'un système d'allumage défaillant. Leur mise sous pression est effectuée classiquement grâce à de l'hélium supprimant le recours à une fragile turbopompe. Pour parvenir au taux de fiabilité visé sur les autres sous-systèmes, la NASA envisage d'abord de donner aux astronautes la possibilité de réparer les composants défaillants. Mais ce choix suppose de former les astronautes à des systèmes nombreux et complexes, d'emporter des outils et des pièces de rechange et de rendre accessibles les composants à réparer, ce qui les rend vulnérables à l'humidité et à la contamination. La NASA renonce à cette solution en 1964 et décide d'intégrer dans la conception du vaisseau des solutions de contournement permettant de pallier toute anomalie affectant un sous-système critique.

En cas de panne, des systèmes de secours prennent le relais dans un mode plus ou moins dégradé. Ainsi, le système de navigation du module lunaire (ordinateur et système inertiel) est doublé par un système de secours développé par un autre constructeur pour éviter qu'une même faille logicielle mette en panne les deux systèmes. Les quatre groupes de moteurs de contrôle d'attitude sont regroupés par paires indépendantes, chacune d'entre elles pouvant couvrir le besoin en mode dégradé. Le système de régulation thermique est doublé. Les circuits d'alimentation électrique sont également doublés. L'antenne de télécommunications en bande S peut être remplacée par deux antennes plus petites en cas de défaillance. Il n'y a néanmoins pas de parade à une panne de moteur : seuls des tests poussés avec un maximum de réalisme peuvent permettre d'atteindre le taux de fiabilité attendu. Des solutions techniques conservatrices mais éprouvées sont dans certains cas retenues. C'est le cas de l'énergie électrique sur le module lunaire (choix des batteries), des systèmes pyrotechniques (choix de systèmes existants standardisés et éprouvés) ainsi que l'électronique de bord (les circuits intégrés, bien qu'acceptés dans les ordinateurs, ne sont pas retenus pour le reste de l'électronique).

Selon Neil Armstrong, les responsables du projet avaient calculé qu'il y aurait environ à chaque mission "Apollo" (fusée, CSM et LEM), chiffre extrapolé du nombre de composants et du taux de fiabilité exigé des constructeurs. Il y en aura en fait en moyenne 150, ce qu'Armstrong attribue à l'implication exceptionnellement forte des personnes ayant travaillé sur le projet.

Depuis Spoutnik 1, les dirigeants de l'Union Soviétique et les responsables du programme spatial soviétique avaient toujours fait en sorte de maintenir leur avance sur le programme américain. Il ne faisait aucun doute dans l'esprit des dirigeants américains comme dans celui de l'opinion publique que l'URSS allait lancer son propre programme de vol habité vers la Lune et tenter de réussir avant les États-Unis pour conserver le prestige associé à leur domination durant la première phase de la course à l'espace. Néanmoins, après une déclaration publique d'un dirigeant soviétique semblant relever le défi, aucune information officielle ne filtrera plus sur l'existence d'un programme lunaire habité soviétique au point de susciter le doute sur son existence chez certains représentants du congrès américain qui commencèrent, pour cette raison, à contester le budget alloué au programme "Apollo" à compter de 1963. Cependant, pour les dirigeants de la NASA, la menace d'une réussite soviétique exerça une pression constante sur le calendrier du programme "Apollo" : la décision de lancer la mission circumlunaire , alors que le vaisseau spatial Apollo n'était pas complètement qualifié, constituait une certaine prise de risque, qui avait été largement motivée par la crainte de se faire devancer par les Soviétiques. Certains indices contribuèrent par la suite à diminuer la pression sur les décideurs de la NASA dans la dernière ligne droite qui précéda le lancement . Au cours des années 1970, aucune information ne filtra sur la réalité du programme soviétique et dans l'atmosphère de désenchantement qui suivit la fin du programme "Apollo", le célèbre journaliste américain Walter Cronkite annonça gravement à son public que l'argent dépensé pour celui-ci avait été gaspillé, car . Ce n'est qu'avec la glasnost à la fin des années 1980 que commenceront à paraître quelques informations sur le sujet et il fallut attendre la chute de l'URSS pour que la réalité du programme lunaire soviétique soit reconnue par les dirigeants russes.

À compter du début des années 1960, le programme spatial habité soviétique, si performant jusque-là, tourne à la confusion. Sergueï Korolev, à l'origine des succès les plus éclatants de l'astronautique soviétique, commence à concevoir à cette époque la fusée géante N-1 pour laquelle il réclame le développement de moteurs cryogéniques performants (c'est-à-dire utilisant de l'hydrogène comme ceux en cours de développement chez les Américains) mais se heurte au refus de Valentin Glouchko qui possède un monopole sur la fabrication des moteurs-fusées. Aucun programme lunaire n'est lancé car les responsables soviétiques sont persuadés que la NASA court à l'échec. Le premier secrétaire du PCUS Nikita Khrouchtchev demande en à son protégé Vladimir Tchelomeï, rival de Korolev, de développer un lanceur, le Proton et un vaisseau LK-1 (LK pour "Lounnyï korabl"' - Лунный корабль - vaisseau lunaire) en vue d'un vol habité circumlunaire. Korolev riposte en proposant une mission de débarquement lunaire basée sur un vaisseau concurrent, le Soyouz (Союз), apte à des rendez-vous en orbite et un module d'atterrissage L3. Constatant les progrès américains, Khrouchtchev décide finalement le , avec trois ans de retard, de lancer les équipes soviétiques dans la course à la Lune : les programmes Proton (Прото́н) / Zond (Зонд, « sonde ») de survol de la Lune par une sonde inhabitée et N1-L3 de débarquement d’un cosmonaute sur la Lune de Korolev reçoivent alors le feu vert du Politburo. Toutefois, le limogeage de Khrouchtchev, remplacé par Léonid Brejnev à la tête du Parti communiste de l'URSS en octobre de la même année, se traduit par de nouveaux atermoiements et des problèmes dans la répartition des ressources budgétaires entre les deux programmes.

Gravement handicapé par la mort de Korolev en 1966 et par l'insuffisance des moyens financiers, le développement de la rencontre des problèmes majeurs (, ) qui conduisent à son abandon le . C'est la fin des ambitions lunaires de l'URSS. Le lanceur Proton comme le vaisseau Soyouz après des débuts laborieux jouent aujourd'hui un rôle central dans le programme spatial russe.

Les principaux composants du programme "Apollo" sont la famille de lanceurs Saturn ainsi que les deux vaisseaux habités : le CSM et le module lunaire. Pour le séjour sur la Lune, un véhicule est développé ainsi qu'un ensemble d'instruments scientifiques, l'ALSEP.

Trois types de lanceurs sont développés dans le cadre du programme "Apollo" : qui va permettre de confirmer la maîtrise du mélange LOX/LH2, utilisé pour les premiers tests du vaisseau Apollo en orbite terrestre et enfin, le lanceur lourd dont les performances exceptionnelles et jamais dépassées depuis, permettront les missions lunaires.

Les débuts de la famille de lanceurs Saturn sont antérieurs au programme "Apollo" et à la création de la NASA. Début 1957, le Département de la Défense (DOD) américain identifie un besoin pour un lanceur lourd permettant de placer en orbite des satellites de reconnaissance et de télécommunications pesant jusqu'à . À cette époque, les lanceurs américains les plus puissants en cours de développement peuvent tout au plus lancer en orbite basse car ils dérivent de missiles balistiques beaucoup plus légers que leurs homologues soviétiques. En 1957, Wernher von Braun et son équipe d'ingénieurs, venus comme lui d'Allemagne, travaillent à la mise au point des missiles intercontinentaux Redstone et Jupiter au sein de l'Army Ballistic Missile Agency (ABMA), un service de l'Armée de Terre situé à Huntsville (Alabama). Cette dernière lui demande de concevoir un lanceur permettant de répondre à la demande du DOD. Von Braun propose un engin, qu'il baptise Super-Jupiter, dont le premier étage, constitué de huit étages Redstone regroupés en fagot autour d'un étage Jupiter, fournit les de poussée nécessaires pour lancer les satellites lourds. La course à l'espace, qui débute à la fin de 1957, décide le DOD, après examen de projets concurrents, à financer en le développement de ce nouveau premier étage rebaptisé puis finalement Saturn (la planète située au-delà de Jupiter). Le lanceur utilise, à la demande du DOD, huit moteurs-fusées H-1 simple évolution du propulseur utilisé sur la fusée Jupiter, ce qui doit permettre une mise en service rapide.

Durant l'été 1958, la NASA, qui vient tout juste d'être créée, identifie le lanceur comme un composant clé de son programme spatial. Mais au début de 1959, le Département de la Défense décide d'arrêter ce programme coûteux dont les objectifs sont désormais couverts par d'autres lanceurs en développement. La NASA obtient le transfert en son sein du projet et des équipes de von Braun ; celui-ci est effectif au et la nouvelle entité de la NASA prend le nom de Centre de vol spatial Marshall (George C. Marshall Space Flight Center MSFC).

La question des étages supérieurs du lanceur était jusque-là restée en suspens : l'utilisation d'étages de fusée existants, trop peu puissants et d'un diamètre trop faible, n'était pas satisfaisante. Fin 1959, un comité de la NASA travaille sur l'architecture des futurs lanceurs de la NASA. Son animateur, Abe Silverstein, responsable du centre de recherche Lewis et partisan de la propulsion par des moteurs utilisant le couple hydrogène/oxygène en cours d'expérimentation sur la fusée Atlas-Centaur, réussit à convaincre un von Braun réticent d'en doter les étages supérieurs de la fusée Saturn. Le comité identifie dans son rapport final six configurations de lanceur de puissance croissante (codés A1 à C3) permettant de répondre aux objectifs de la NASA tout en procédant à une mise au point progressive du modèle le plus puissant. Le centre Marshall étudie en parallèle à l'époque un lanceur hors normes capable d'envoyer une mission vers la Lune : cette fusée baptisée Nova, est dotée d'un premier étage fournissant de poussée et est capable de lancer sur une trajectoire interplanétaire.

Lorsque le président Kennedy accède au pouvoir au début de 1961, les configurations du lanceur Saturn sont toujours en cours de discussion, reflétant l'incertitude sur les missions futures du lanceur. Toutefois, dès juillet 1960, Rocketdyne, sélectionné par la NASA, avait démarré les études sur le moteur J-2 consommant hydrogène et oxygène et d'une poussée de retenu pour propulser les étages supérieurs. Le même motoriste travaillait depuis 1956, initialement à la demande de l'armée de l'Air, sur l'énorme moteur F-1 ( de poussée) retenu pour le premier étage. Fin 1961, la configuration du lanceur lourd (C-5 futurs ) est figée : le premier étage est propulsé par cinq F-1, le deuxième étage par cinq J-2 et le troisième par un J-2. L'énorme lanceur peut placer jusque en orbite basse et envoyer vers la Lune. Deux modèles moins puissants doivent être utilisés durant la première phase du projet :
Fin 1962, le choix du scénario du rendez-vous en orbite lunaire (LOR) confirme le rôle du lanceurs et entraîne l'arrêt des études sur le lanceur Nova.

Le véhicule spatial Apollo (ou module de commande et de service abrégé en CSM) transporte les astronautes à l'aller et au retour. Pesant plus de , il est pratiquement dix fois plus lourd que le vaisseau Gemini. La masse supplémentaire () est en grande partie représentée par le moteur et les ergols qui fournissent un delta-v de permettant au vaisseau de s'insérer en orbite lunaire puis de quitter cette orbite. Le vaisseau Apollo reprend une disposition inaugurée avec le vaisseau Gemini : un module de commande (CM) abrite l'équipage et un module de service (SM) contient le moteur de propulsion principal, l'essentiel des sources d'énergie ainsi que l’équipement nécessaire à la survie des astronautes. Le module de service est largué juste avant l'atterrissage.

Le module de commande Apollo est la partie dans laquelle les trois astronautes séjournent durant la mission, sauf lorsque deux d'entre eux descendent sur la Lune au moyen du module lunaire. Pesant et de forme conique, sa structure externe comporte une double paroi : une enceinte constituée de tôles et nid d'abeilles à base d'aluminium qui renferme la zone pressurisée et un bouclier thermique qui recouvre la première paroi et dont l'épaisseur varie en fonction de l'exposition durant la rentrée atmosphérique. Le bouclier thermique est réalisé avec un matériau composite constitué de fibres de silice et microbilles de résine, dans une matrice de résine époxy. Ce matériau est inséré dans un nid d'abeille en acier.

L'espace pressurisé représente un volume de . Les astronautes sont installés sur trois couchettes côte à côte parallèles au fond du cône et suspendues à des poutrelles partant du plancher et du plafond (la pointe du cône). En position allongée, les astronautes ont en face d'eux, suspendu au plafond, un panneau de commandes large de deux mètres et haut de un mètre présentant les principaux interrupteurs et voyants de contrôles. Les cadrans sont répartis en fonction du rôle de chaque membre d'équipage. Sur les parois latérales se trouvent des baies réservées à la navigation, d'autres panneaux de commande ainsi que des zones de stockage de nourriture et de déchets. Pour la navigation et le pilotage, les astronautes utilisent un télescope et un ordinateur qui exploite les données fournies par une centrale inertielle.

Le vaisseau dispose de deux écoutilles : l'une située à la pointe du cône comporte un tunnel et est utilisée pour passer dans le module lunaire lorsque celui-ci est amarré au vaisseau Apollo. L'autre placée sur la paroi latérale est utilisée à Terre pour pénétrer dans le vaisseau et dans l'espace pour les sorties extra véhiculaires (le vide est alors effectué dans la cabine car il n'y a pas de sas). Les astronautes disposent par ailleurs de cinq hublots pour effectuer des observations et réaliser les manœuvres de rendez-vous avec le module lunaire. Le module de commande dépend pour les principales manœuvres comme pour l'énergie et le support-vie du module de service. Il dispose de quatre grappes de petits moteurs d'orientation permettant les manœuvres lors de la rentrée. Celles-ci s'effectuent en orientant le module en roulis, la capsule ayant une incidence voisine de par rapport à son axe de symétrie. Cette incidence est obtenue par balourd statique de construction.
Le module de service (SM ou en anglais) est un cylindre d'aluminium non pressurisé de de long et de diamètre pesant . Il est accouplé à la base du module de commande et la longue tuyère du moteur-fusée principal de de poussée en dépasse de . Le module est organisé autour d'un cylindre central qui contient les réservoirs d'hélium servant à pressuriser les réservoirs d'ergols principaux ainsi que la partie haute du moteur principal. Autour de cette partie centrale, l'espace est découpé en six secteurs en forme de parts de gâteau. Quatre de ces secteurs abritent les réservoirs d'ergols (). Un secteur contient trois piles à combustible qui fournissent la puissance électrique et en sous-produit l'eau ainsi que les réservoirs d'hydrogène et d'oxygène qui les alimentent. L'oxygène est également utilisé pour renouveler l'atmosphère de la cabine. Un secteur reçoit des équipements qui ont varié en fonction des missions : appareils scientifiques, petit satellite, caméras, réservoir d'oxygène supplémentaire. Le module de service contient également les radiateurs qui dissipent l'excédent de chaleur du système électrique et qui régulent la température de la cabine. Quatre grappes de petits moteurs de contrôles d'attitude sont disposées sur le pourtour du cylindre. Une antenne comportant cinq petites paraboles, assurant les communications à grande distance, est déployée une fois le vaisseau lancé.

La tour de sauvetage est un dispositif destiné à éloigner le vaisseau spatial du lanceur si celui-ci subit une défaillance durant les premières phases du vol. Le recours à des sièges éjectables, utilisé sur le vaisseau spatial Gemini, est exclu compte tenu du diamètre de la boule de feu que créerait l'explosion de la fusée . La tour de sauvetage est constituée d'un propulseur à poudre situé au bout d'un treillis métallique lui-même perché au sommet du vaisseau Apollo. En cas d'incident, le moteur-fusée de la tour arrache le vaisseau de la fusée tandis qu'un petit propulseur l'écarte de la trajectoire de la fusée. La tour est alors larguée et le vaisseau entame sa descente en suivant une séquence similaire à celle d'un retour sur Terre. Si le lancement se déroule sans problème, la tour est éjectée lorsque le deuxième étage de la fusée Saturn est mis à feu.

Le module lunaire comporte deux étages : un étage de descente permet d'atterrir sur la Lune et sert par ailleurs de plate-forme de lancement au deuxième étage, l'étage de remontée, qui ramène les astronautes au vaisseau Apollo en orbite à la fin de leur séjour sur la Lune. La structure du module lunaire est, pour l'essentiel, réalisée avec un alliage d'aluminium choisi pour sa légèreté. Les pièces sont généralement soudées entre elles mais parfois également rivetées.

Le corps de l'étage de descente, qui pèse plus de , a la forme d'une boîte octogonale d'un diamètre de et d'une hauteur de . Sa structure, constituée de deux paires de panneaux parallèles assemblés en croix, délimite cinq compartiments carrés (dont un central) et quatre compartiments triangulaires. La fonction principale de l'étage de descente est d'amener le LEM sur la Lune. À cet effet, l'étage dispose d'un moteur fusée à la fois orientable et à poussée variable. La modulation de la poussée permet d'optimiser la trajectoire de descente mais surtout de poser en douceur le LEM qui s'est fortement allégé en consommant ses ergols. Le comburant, du peroxyde d'azote (), et le carburant, de l'aérozine 50 (), sont stockés dans quatre réservoirs placés dans les compartiments carrés situés aux quatre coins de la structure. Le moteur se trouve dans le compartiment carré central. Le deuxième rôle de l'étage de descente est de transporter tous les équipements et consommables qui peuvent être abandonnés sur la Lune à la fin du séjour, ce qui permet de limiter le poids de l'étage de remontée.

L'étage de remontée pèse environ . Sa forme complexe, qui résulte d'une optimisation de l'espace occupé, lui donne l'allure d'une tête d'insecte. Il est essentiellement composé de la cabine pressurisée qui héberge deux astronautes dans un volume de et du moteur de remontée avec ses réservoirs d'ergols. La partie avant de la cabine pressurisée occupe la plus grande partie d'un cylindre de de diamètre et de de profondeur. C'est là que se tient l'équipage lorsqu'il n'est pas en excursion sur la Lune. Le pilote (à gauche face à l'avant) et le commandant de bord sont debout, tenus par des harnais qui les maintiennent en place en impesanteur et durant les phases d'accélération. Sur la cloison avant, chaque astronaute a devant lui un petit hublot triangulaire () incliné vers le bas, qui lui permet d'observer le sol lunaire avec un bon angle de vision, ainsi que les principales commandes de vol et cadrans de contrôle regroupés par panneaux généralement dédiés à un sous-système. Les commandes et contrôles communs sont placés entre les deux astronautes (par exemple la console d'accès à l'ordinateur de navigation), certaines commandes sont doublées (commandes pilotant l'orientation et la poussée des moteurs), les autres commandes sont réparties en fonction des tâches assignées à chaque astronaute. Les panneaux de commandes et coupe-circuit se prolongent sur les parois latérales situées de part et d'autre des astronautes.

Le pilote a au-dessus de sa tête un petit hublot () qui lui permet de contrôler la manœuvre de rendez-vous avec le module de commande. L'arrière de la cabine pressurisée est beaucoup plus exigu ( pour de haut) : son plancher est plus haut de et, de plus, encombré par un capot recouvrant le sommet du moteur de remontée. Les parois latérales sont occupées par les rangements et à gauche, par une partie du système de contrôle environnemental. Au plafond se trouve l'écoutille utilisée pour passer dans le Module de Commande derrière laquelle se trouve un tunnel court ( de diamètre pour de long) comportant un système de verrouillage utilisé pour solidariser les deux vaisseaux. Les forces en jeu au moment de l'accostage qui pourraient déformer le tunnel sont amorties par des poutres qui les répercutent sur toute la structure.

Le LEM ne dispose pas de sas, qui aurait ajouté trop de poids. Pour descendre sur le sol lunaire, les astronautes font le vide dans la cabine et, à leur retour, ils pressurisent la cabine avec les réserves d'oxygène. Pour descendre, ils se glissent dans l'écoutille : celle-ci donne sur une petite plate-forme horizontale qui débouche sur l'échelle dont les barreaux sont situés de part et d'autre d'une des jambes de l'étage de descente.

Pour remplir la mission lunaire, la NASA dut concevoir plusieurs instruments scientifiques, équipements et véhicules destinés à être mis en œuvre sur le sol lunaire. Les principaux développements sont :

Les six missions lunaires "Apollo" ont été programmées pour que le module lunaire atterrisse au tout début du jour lunaire (qui dure terrestres). Les astronautes bénéficient ainsi d'une lumière rasante pour le repérage du terrain à l'atterrissage (entre 10 et 15° d'élévation au-dessus de l'horizon selon les missions) et de températures relativement modérées : la température au sol passe progressivement à entre le lever du Soleil et le moment où le Soleil culmine au bout de terrestres. Compte tenu de ces conditions, pour chaque lieu d'atterrissage, la fenêtre de lancement de la fusée Saturn était réduite à un jour par mois pour un site donné.

Le site retenu est toujours situé sur la face visible de la Terre pour que les communications entre le vaisseau et la Terre ne soient pas interrompues ; il n'est pas trop éloigné de la bande équatoriale de la Lune pour limiter la consommation de carburant que nécessiterait un déport du vaisseau vers des latitudes plus élevées.

La fusée décolle systématiquement depuis le du centre spatial Kennedy. Le lancement des de la fusée est particulièrement spectaculaire : les cinq moteurs du premier étage sont allumés simultanément consommant de carburant chaque seconde puis la fusée, qui est retenue par des pinces, est lâchée dès que les ordinateurs ont vérifié que la poussée des moteurs a atteint sa puissance nominale. La fusée s'élève d'abord très lentement, mettant près de dix secondes à se dégager de la tour de lancement. La séparation du premier étage S1-C intervient deux minutes et demie après le lancement à une altitude de alors que la fusée a atteint une vitesse de Mach 8 ( soit environ ). Peu après, les moteurs-fusées du deuxième étage S-II s'allument : la jupe inter-étages se détache et la tour de sauvetage est éjectée car le vaisseau spatial est suffisamment haut pour pouvoir retomber sans son aide en cas d'interruption de la mission. Le deuxième étage est à son tour largué alors que la fusée atteint une vitesse de (soit environ ) et une altitude de . Le troisième étage S-IVB est alors mis à contribution durant pour placer l'ensemble de la fusée restante sur une orbite circulaire de onze minutes et demie après le décollage.

Une fois placés en orbite basse, les vaisseaux Apollo (LEM et Module de Commande et de Service) ainsi que le troisième étage de la fusée effectuent une orbite et demi autour de la Terre puis le moteur du troisième étage est rallumé pour injecter l'ensemble sur une orbite de transfert vers la Lune (TransLunar Injection - TLI). L'injection se traduit par une augmentation de la vitesse de (). Environ une demi-heure après la fin de la poussée, le Module de Commande et de Service (CSM) se détache du reste du train spatial puis pivote de 180° pour venir repêcher le LEM dans son carénage. Après avoir vérifié l'arrimage des deux vaisseaux et pressurisé le LEM, les astronautes déclenchent par pyrotechnie la détente de ressorts situés dans le carénage du LEM : ceux-ci écartent le LEM et le CSM du troisième étage de la fusée Saturn à une vitesse d'environ . Le troisième étage va alors entamer une trajectoire divergente qui, selon les missions le place en orbite autour du Soleil ou l'envoie s'écraser sur la Lune.

Durant le trajet de vers la Lune, des corrections peuvent être apportées à la trajectoire du CSM et du LEM pour optimiser la consommation finale de propergols. Initialement, le déroulement d’une mission "Apollo" prévoyait une quantité relativement importante de carburant pour ces manœuvres. À l'usage, à peine 5 % de cette quantité sera consommée grâce à la précision de la navigation. Le train spatial est mis en rotation lente pour limiter l'échauffement des vaisseaux en réduisant la durée de l'exposition continue au Soleil.

Une fois arrivé à proximité de la Lune, le moteur du CSM est allumé pour placer les vaisseaux en orbite en les freinant. Si ce freinage n'est pas réalisé, la trajectoire permet aux vaisseaux de revenir se placer en orbite terrestre après avoir fait le tour de la Lune sans utiliser leurs moteurs. Cette disposition sauvera d'ailleurs la mission . Un peu plus tard, le moteur du CSM est utilisé une deuxième fois pour placer les deux vaisseaux sur une orbite circulaire de d'altitude.

La descente sur la Lune repose en grande partie sur le système de guidage, navigation et contrôle (PGNCS : "Primary Guidance and Control System") piloté par l'ordinateur embarqué (LGC). Celui-ci va d'une part, déterminer périodiquement la position et la trajectoire réelle du vaisseau en utilisant d'abord la centrale inertielle puis le radar d'atterrissage (fonction de navigation), et d'autre part, calculer la trajectoire à suivre en utilisant ses programmes et piloter, en fonction de tous ces éléments, la poussée et l'orientation des moteurs (fonction de guidage). Le pilote du LEM peut toutefois corriger l’altitude en cours à tout moment et, dans la dernière phase, reprendre complètement la main sur les commandes des moteurs. Mais seul le système de navigation et de pilotage permet, en optimisant trajectoire et consommation des ressources, de poser le LEM avant d'avoir épuisé tout le carburant.

Cette phase est désignée par l'acronyme DOI ("Descent Orbit Insertion") dans la terminologie de la NASA.

L'objectif de cette phase est d'abaisser l'altitude du LEM de à au-dessus du sol lunaire. À cet effet, son orbite circulaire est transformée en une orbite elliptique de par . Cette phase permet de réduire la distance à parcourir jusqu’au sol lunaire à un faible coût en propergols (elle ne nécessite qu'une brève impulsion du moteur). La limite des a été retenue pour éviter que la trajectoire finale ne s'approche trop du relief.

Deux des trois astronautes de l'équipage prennent place dans le Module Lunaire pour descendre sur la Lune. Ils initialisent le système de navigation avant d'entamer la descente vers la Lune. Le LEM et le CSM se séparent avant que le moteur ne soit mis en marche (jusqu’à ). Le changement d'orbite est initié lorsque le vaisseau spatial se situe aux antipodes (à une demi-orbite) du point où démarrera la phase suivante. Une fois que la distance entre le LEM et le module de commande est suffisante (une centaine de mètres), une petite accélération est d’abord imprimée par les moteurs contrôlant l'attitude pour plaquer le carburant du moteur de descente contre les vannes de distribution puis le moteur de descente est allumé brièvement pour freiner le LEM d'environ ().

À partir , pour économiser les propergols de l'étage de descente, c'est le moteur du Module de Commande et de Service qui est sollicité pour abaisser l'orbite. Le CSM accompagne donc le LEM dans son orbite elliptique et s'en sépare avant que la descente propulsée ne démarre.

Cette phase est caractérisée par une action continue du moteur de descente. Elle démarre lorsque le LEM a atteint le point le plus bas de son orbite elliptique. Elle se décompose elle-même en trois phases : la phase de freinage, la phase d'approche et la phase d'atterrissage.

La phase de freinage vise à réduire la vitesse du vaisseau de la manière la plus efficace possible : celle-ci va passer de () à (). Le moteur est allumé à 10 % de sa puissance durant , le temps que le moteur s'aligne grâce à son cardan sur le centre de gravité du vaisseau, puis il est poussé au maximum de sa puissance. Le module lunaire qui au début de la trajectoire est pratiquement parallèle au sol va progressivement s'incliner tandis que sa vitesse de descente nulle au départ augmente jusqu'à en fin de phase. Lorsque le LEM se trouve à une altitude inférieure à 12-, le radar d'atterrissage accroche le sol et se met à fournir des informations (altitude, vitesse de déplacement) qui vont permettre de vérifier que la trajectoire est correcte : jusqu'alors celle-ci était extrapolée uniquement à partir de l'accélération mesurée par la centrale à inertie. Une différence trop importante entre les données fournies par le radar et la trajectoire visée ou le non fonctionnement du radar sont des motifs d'interruption de la mission.

La phase d'approche démarre à du site visé alors que LEM est à une altitude de . Elle doit permettre au pilote de repérer la zone d'atterrissage et de choisir le lieu précis (dégagé) où il souhaite atterrir. Son point de départ est désigné sous le terme de « porte haute » (« "high gate" »), expression empruntée à l'aéronautique.

Le module lunaire est progressivement redressé en position verticale fournissant au pilote une meilleure vision du terrain. Celui-ci peut ainsi localiser le point d'atterrissage auquel conduit la trajectoire grâce à une échelle gravée sur son hublot graduée en degrés ("Landing Point Designator", LPD) : l'ordinateur fournit à la demande l'angle sous lequel l'astronaute peut voir le lieu d'atterrissage sur cette échelle. Si celui-ci juge que le terrain n'est pas propice à un atterrissage ou qu'il ne correspond pas au lieu prévu, il peut alors corriger l'angle d'approche en agissant sur les commandes de vol par incrément de 0,5° dans le sens vertical ou 2° en latéral.

Lorsque le module lunaire est descendu à une altitude de ce qui le place théoriquement à une distance de du lieu visé (point désigné sous le terme de "low gate"), démarre la phase d'atterrissage. Si la trajectoire a été convenablement suivie, les vitesses horizontale et verticale sont respectivement alors de et . La procédure prévoit que le pilote prenne la main pour amener le module lunaire au sol mais il peut, s'il le souhaite, laisser faire l'ordinateur de bord qui dispose d'un programme de pilotage pour cette dernière partie du vol. En prenant en compte les différents aléas (phase de repérage allongée de deux minutes, modification de la cible de dernière minute de pour éviter un relief, mauvaise combustion finale, jauge de propergol pessimiste), le pilote dispose d'une marge de pour poser le LEM avant l'épuisement des ergols. La dernière partie de la phase est un vol stationnaire à la manière d'un hélicoptère qui permet à la fois d'annuler toutes les composantes de vitesse mais également de mieux repérer les lieux. Des sondes situées sous les semelles du train d'atterrissage prennent contact avec le sol lunaire lorsque l'altitude est inférieure à et transmettent l'information au pilote. Celui-ci doit alors couper le moteur de descente pour éviter que le LEM ne rebondisse ou ne se renverse (la tuyère touche presque le sol).

Le séjour sur la Lune est rythmé par les sorties extra-véhiculaires : une unique sortie pour mais jusqu’à trois sorties pour les dernières missions. Avant chaque sortie, les astronautes doivent faire le plein en eau et oxygène de leur système de survie portable puis enfiler leur tenue. Ils font ensuite le vide avant d’ouvrir l’écoutille qui donne accès à l’échelle.

Les outils et les instruments scientifiques sont sortis des baies de stockage de l’étage de descente puis sont déployés non loin du LEM ou à plus grande distance. À partir , les astronautes disposent d’une brouette puis dans le cadre des vols suivants du rover lunaire qui leur permet de s’éloigner d’une dizaine de kilomètres du LEM en transportant de lourdes charges. Le rover occupe une baie entière du module lunaire ; il est stocké en position repliée sur une palette que les astronautes abaissent pour libérer le véhicule. Le rover est déployé par un système de ressorts et de câbles agissant via des poulies et actionnés par les astronautes.

Avant de quitter la Lune, les échantillons géologiques placés dans des conteneurs sont hissés jusqu’à l’étage de remontée grâce à un palan. Le matériel qui n’est plus nécessaire (survie portable, appareils photos, etc.) est abandonné pour alléger au maximum l’étage de remontée.

La phase de remontée doit permettre au LEM de rejoindre le module de commande resté en orbite. Cet objectif est atteint en deux temps : l'étage du LEM décolle du sol lunaire pour se mettre en orbite basse puis à l'aide de poussées ponctuelles du moteur-fusée, il rejoint le module de commande.

Avant le décollage, la position précise du LEM au sol est entrée dans l'ordinateur afin de déterminer la meilleure trajectoire. L'instant du départ est calculé de manière à optimiser la trajectoire de rendez-vous avec le module de Commande. L'étage de descente reste au sol et sert de plate-forme de lancement. La séparation des deux étages est déclenchée avant le décollage par de petites charges pyrotechniques qui sectionnent les quatre points solidarisant les deux étages ainsi que les câbles et tuyauteries.

Le Module Lunaire suit d'abord une trajectoire verticale jusqu'à une altitude d'environ pour se dégager du relief lunaire puis s'incline progressivement pour rejoindre finalement à l'horizontale le périlune (point bas) d'une orbite elliptique de sur .

Un rendez-vous en orbite lunaire est alors effectué entre le CSM (piloté par le troisième membre d'équipage, le seul de la mission à ne pas aller sur la Lune) et le LEM en orbite lunaire. Après que les pierres lunaires ont été transférées, le LEM est libéré et lancé sur une trajectoire qui l'amènera à s'écraser sur la Lune. Le vaisseau spatial peut alors entamer son retour vers la Terre. et resteront en orbite une journée de plus pour réaliser des expériences scientifiques et larguer un petit satellite scientifique de .

Pour quitter l'orbite lunaire et placer le vaisseau spatial sur la trajectoire de retour vers la Terre, le moteur du module de commande et de service est sollicité durant deux minutes et demie après avoir soigneusement orienté le vaisseau ; il fournit un delta-v d'environ qui doit permettre au vaisseau de rejoindre l'orbite terrestre. C'est l'un des moments critiques de la mission car une défaillance du moteur ou une mauvaise précision dans l'orientation condamnerait les astronautes. Le moteur est allumé alors que le vaisseau se situe sur la face située à l'opposé de la Terre de manière à ce que la nouvelle trajectoire, une orbite de transfert fortement elliptique, frôle la surface de la Terre à d'altitude dans la position qu'elle occupera à l'arrivée du vaisseau. Le trajet de retour dure environ trois jours mais peut être un peu raccourci en optant pour une trajectoire plus tendue. Peu après l'injection sur le trajet de retour ("trans-Earth Injection", TEI), une sortie extravéhiculaire est effectuée pour récupérer les films photographiques des caméras placés dans le module de service qui doit être largué avant l'entrée dans l'atmosphère terrestre.

De petites corrections sont effectuées au cours du trajet pour optimiser l'angle d'entrée dans l'atmosphère et le point de chute. Au fur et à mesure que le vaisseau se rapproche de la Terre, la vitesse du vaisseau, qui était tombée à à la limite de l'influence des champs de gravité de la Terre et de la Lune, s'accroît jusqu'à atteindre lorsque le vaisseau pénètre dans les couches denses de l'atmosphère ; celles-ci font sentir leur influence à compter de d'altitude. Peu avant de pénétrer dans l'atmosphère, le module de service du vaisseau est largué au moyen de systèmes pyrotechniques, emportant avec lui le moteur principal et la majorité des réserves d'oxygène et d'électricité. La rentrée dans l'atmosphère se fait sous un angle très précis fixé à 6,5° avec une tolérance de 1°. Si l'angle de pénétration est trop important, le bouclier thermique qui est porté normalement à une température de durant la rentrée dans l'atmosphère, subit une température supérieure à celle pour laquelle il est conçu et la décélération est plus importante ; ces deux phénomènes pouvant entraîner la mort de l'équipage. Avec un angle inférieur, le vaisseau spatial peut rebondir sur la couche atmosphérique et repartir sur une longue trajectoire elliptique condamnant son équipage incapable de manœuvrer et ne disposant que de très peu de réserves d'air.

Après une phase de décélération qui atteint , le vaisseau a perdu sa vitesse horizontale et descend pratiquement à la verticale. À d'altitude, la protection située à l'extrémité conique du vaisseau est éjectée et deux petits parachutes se déploient pour stabiliser la cabine et faire chuter sa vitesse à . À , trois petits parachutes pilotes sont déployés latéralement par des mortiers pour extraire les trois parachutes principaux en évitant qu'ils s'emmêlent. Le vaisseau percute la surface de l'océan à une vitesse de (soit environ ). Les parachutes sont immédiatement largués et trois ballonnets se gonflent de manière à éviter que le vaisseau reste la pointe sous l'eau. Une flottille comprenant un porte-avions ou un porte-hélicoptères est positionnée à l'avance sur la zone où doit amerrir le module de commande. Des avions sont chargés de localiser le point de chute tandis que des hélicoptères amènent sur place des plongeurs qui, montés sur des embarcations légères, récupèrent les astronautes et placent des élingues sur le vaisseau pour qu'il puisse être hissé sur le pont du porte-aéronefs.

Aucun vol orbital américain n'avait encore eu lieu au lancement du programme "Apollo". Le seul vol du programme Mercury — ce programme avait débuté — avait eu lieu trois semaines avant le discours du président Kennedy et fut un simple vol balistique faute de disposer d'une fusée suffisamment puissante. Il fallut attendre la mission du pour que John Glenn devienne le premier astronaute américain à boucler une orbite autour de la Terre. Trois autres vols habités eurent lieu et .

À l'issue du programme Mercury, des aspects importants du vol spatial, qui devaient être mis en application pour les vols lunaires, n'étaient toujours pas maîtrisés alors qu'il n'était pas possible de les tester au sol. Les dirigeants de la NASA lancèrent un programme destiné à acquérir ces techniques sans attendre la mise au point du vaisseau très sophistiqué de la mission lunaire : le programme "Gemini" devait remplir trois objectifs :
Le vaisseau spatial Gemini, qui devait initialement être une simple version améliorée de la capsule Mercury, se transforma au fur et à mesure de sa conception en un vaisseau complètement différent de (contre environ 1 tonne pour le vaisseau Mercury), capable de voler avec deux astronautes durant deux semaines. Le vaisseau était lancé par une fusée , missile de l'armée de l'air américaine reconverti en lanceur. Le programme rencontra des problèmes de mise au point. Le lanceur souffrait d'effet pogo, les piles à combustible utilisées pour la première fois fuyaient et la tentative de mise au point d'une aile volante pour faire atterrir la capsule sur le sol ferme échoua. Tous ces déboires gonflèrent le coût du programme de de dollars à un milliard de dollars. Toutefois, fin 1963, tout était rentré dans l'ordre et deux vols sans équipage purent avoir lieu et au . Le premier vol habité emporta les astronautes Virgil Grissom et John Young le . Au cours de la mission suivante, l'astronaute Edward White réalisa la première sortie dans l'espace américaine. Huit autres missions, émaillées d'incidents sans conséquence, s'échelonnèrent jusqu'en : elles permirent de mettre au point les techniques de rendez-vous spatial et d'amarrage, de réaliser des vols de longue durée ( resta près de 14 jours en orbite) et d'effectuer de nombreuses autres expériences.

Parallèlement au programme "Apollo", la NASA lance plusieurs programmes pour affiner sa connaissance du milieu spatial et du terrain lunaire. Ces informations sont nécessaires pour la conception des engins spatiaux et préparer les atterrissages. En 1965, trois satellites Pegasus sont placés en orbite par une fusée pour évaluer le danger représenté par les micrométéorites ; les résultats seront utilisés pour dimensionner la protection des vaisseaux Apollo. Les sondes Ranger (1961–1965), après une longue série d'échecs, ramènent à compter de fin 1964, une série de photos de bonne qualité de la surface lunaire qui permettent d'identifier des sites propices à l'atterrissage.

Le programme Lunar Orbiter, composé de cinq sondes qui sont placées en orbite autour de la Lune en 1966–1967, complète ce travail : une couverture photographique de 99 % du sol lunaire est réalisée, la fréquence des micrométéorites dans la banlieue lunaire est déterminée et l'intensité du rayonnement cosmique est mesurée. Le programme permet également de valider le fonctionnement du réseau de télémesure. Les mesures effectuées indiquent que le champ gravitationnel lunaire est beaucoup moins homogène que celui de la Terre rendant dangereuses les orbites à basse altitude. Le phénomène, sous-estimé par la suite, réduira à l'altitude de l'orbite du LEM dont l'équipage était endormi, alors que la limite de sécurité avait été fixée à pour disposer d'une marge suffisante par rapport aux reliefs. Le , la sonde "Surveyor 1" effectue le premier atterrissage en douceur sur la Lune fournissant des informations précieuses et rassurantes sur la consistance du sol lunaire (le sol est relativement ferme) ce qui permet de dimensionner le train d'atterrissage du module lunaire.
La fusée (ou ) avait été conçue alors que le cahier des charges du programme lunaire n'était pas encore figé. Sa capacité d'emport s'avéra finalement trop faible même pour remplir les objectifs des premières phases du programme. Néanmoins, dix des douze fusées commandées furent construites et lancées entre le et le , dont six avec l'ensemble des étages. Aucun des composants de cette fusée ne fut réutilisé dans la suite du programme. Après cinq vols consacrés à la mise au point de la fusée (missions SA-1, SA-2, SA-3, SA-4, SA-5), fut utilisée pour lancer deux maquettes du vaisseau Apollo (missions "A-101", "A-102") et placer trois satellites Pegasus en orbite (missions A-103, A-104, A-105).

Les vols de la fusée Saturn IB permirent la mise au point du troisième étage de la fusée (l'étage IVB dont le moteur consommait du dihydrogène liquide) et d'effectuer les premiers tests du vaisseau spatial Apollo :

Le , alors que l'équipage du premier vol habité (initialement "AS-204") qui doit décoller un mois plus tard effectue une répétition au sol en conditions réelles, un incendie se déclare dans le vaisseau Apollo (CSM) dans lequel les trois astronautes se trouvent sanglés sur leurs couchettes. Les flammes font rage dans l'atmosphère confinée et composée uniquement d'oxygène. Virgil Grissom, Edward White et Roger Chaffee décèdent asphyxiés sans être parvenus à ouvrir l'écoutille dont le mécanisme complexe ne permettait pas une ouverture rapide. Le vaisseau avait rencontré de nombreux problèmes de mise au point avant l'accident. Le déclenchement de l'incendie sera attribué, sans être clairement identifié, à un court-circuit dû à un fil électrique dénudé. L'enquête révèle l'utilisation de nombreux matériaux inflammables dans la cabine et beaucoup de négligences dans le câblage électrique et la plomberie. Le déclenchement et l'extension de l'incendie avait été favorisé par l'atmosphère d'oxygène pur (dépourvue d'azote) donc extrêmement inflammable, une solution qui était déjà celle des vaisseaux Mercury et Gemini.

De nombreuses modifications furent apportées pour que la cabine du vaisseau offre une meilleure résistance au feu. L'écoutille fut modifiée pour pouvoir être ouverte en moins de dix secondes. Une atmosphère d'azote et d'oxygène était utilisée durant la première phase du vol. L'ensemble du programme "Apollo" subit une revue qui entraîna la modification de nombreux composants. Les exigences de qualité et les procédures de test furent renforcées. Tout le programme subit un décalage de accroissant la pression sur les équipes : la fin de la décennie approchait. Par ailleurs, tout le monde s'inquiétait de l'avancement du programme soviétique, même si aucune information officielle ne filtrait de l'Union soviétique.

Les déboires du vaisseau spatial Apollo permirent au programme de développement de la fusée géante de rattraper son retard. Celle-ci avait en effet rencontré de nombreux problèmes touchant en particulier le deuxième étage (le S-II qui est encore aujourd'hui le plus gros étage à hydrogène jamais conçu) : excès de poids, phénomènes de vibration (effet pogo), etc.




Le premier vol habité n'a lieu qu'en mais les missions destinées à valider le fonctionnement des différents composants du programme et à effectuer une répétition presque complète d'une mission lunaire, se succèdent rapidement. Quatre missions préparatoires se déroulent sans anomalie majeure sur une période de sept mois.

Les sept missions suivantes lancées ont toutes pour objectifs de poser un équipage en différents points de la Lune, présentant un intérêt géologique. est la première mission à remplir l'objectif fixé par le président Kennedy. est une mission sans histoire, contrairement à qui, à la suite d'une explosion dans le module de service, frôle la catastrophe et doit renoncer à se poser sur la Lune. La NASA a modifié le modèle de module lunaire emporté par les missions à partir pour répondre aux attentes des scientifiques : le séjour sur la Lune est prolongé grâce à des réserves de consommables plus importantes. Le module lunaire plus lourd transporte le rover lunaire qui accroît le rayon d'action des astronautes durant leurs sorties.


La NASA se préoccupe de la suite à donner au programme "Apollo". En 1965, l'agence crée une structure affectée aux missions postérieures à celles déjà planifiées regroupées sous l'appellation Apollo Applications Program (AAP). La NASA propose plusieurs types de mission dont le lancement en orbite d'une station spatiale, des séjours prolongés sur la Lune mettant en œuvre plusieurs nouveaux modules dérivés du LEM, une mission habitée vers Mars, le survol de Vénus par une mission habitée, etc. Mais les objectifs scientifiques trop vagues ne réussissent pas à convaincre le Congrès américain beaucoup moins motivé par les programmes spatiaux « post-"Apollo" ». Par ailleurs, les priorités des États-Unis ont changé : les dispositifs sociaux mis en place par le président Lyndon Johnson dans le cadre de sa guerre contre la pauvreté (Medicare et Medicaid) et surtout un conflit vietnamien qui s'envenime prélèvent une part croissante du budget. Ce dernier ne consacre aucun fonds à l'AAP pour les . Les budgets votés par la suite ne permettront de financer que le lancement de la station spatiale Skylab réalisée en utilisant un troisième étage de la fusée .

En 1970, le programme "Apollo" lui-même est touché par les réductions budgétaires : la dernière mission planifiée () est annulée tandis que les vols restants sont étalés jusqu'en 1974. La NASA doit se préparer à se séparer de ses employés et sous-traitants () tandis que l'on annonce l'arrêt définitif de la fabrication de la fusée qui ne survivra donc pas au programme. Un projet de mission habité vers Mars (pour un coût compris entre trois et cinq fois celui du programme "Apollo") proposé par un comité d'experts sollicité par le nouveau président républicain Richard Nixon ne reçoit aucun appui ni dans la communauté des scientifiques ni dans l'opinion publique et est rejeté par le Congrès sans débat. Le 20 septembre 1970, le responsable de la NASA, démissionnaire, annonce que les contraintes budgétaires nécessitent de supprimer deux nouvelles missions et .

L'annulation des missions laisse trois fusées inutilisées dont l'une permettra néanmoins de lancer la station spatiale Skylab. Les deux restantes sont aujourd'hui exposées au Johnson Space Center et au centre spatial Kennedy. La station spatiale Skylab est occupée successivement par trois équipages lancés par des fusées et utilisant des vaisseaux . Une fusée fut utilisée pour le lancement de la mission "Apollo-Soyouz" qui emportait un vaisseau spatial . Ce sera la dernière mission à utiliser du matériel développé dans le cadre du programme "Apollo". Le coût du programme est évalué à de dollars (équivalent à de dollars, ).

L'objectif fixé au programme "Apollo" par le président Kennedy est rempli au-delà de toute espérance. L'astronautique américaine a su développer dans un temps record un lanceur d'une puissance inimaginable dix ans auparavant, maîtriser complètement le recours à l'hydrogène pour sa propulsion et réaliser ce qui paraissait, peu de temps auparavant, relever de la science-fiction : amener l'homme sur un autre astre. Malgré le saut technologique, le taux de réussite des lancements des fusées Saturn a été de 100 % et tous les équipages ont pu être ramenés à Terre. Aux yeux du monde entier le programme "Apollo" est une démonstration magistrale du savoir-faire américain et de sa supériorité sur l'astronautique soviétique qui au même moment accumule les échecs. Pour beaucoup d'Américains cette victoire démontre la supériorité de la société américaine même si cette foi dans leur système est fortement ébranlée à la même époque par l'ampleur de la contestation étudiante liée à la guerre du Viêt Nam et l'agitation sociale qui touche en particulier la minorité noire dans les grandes villes liée avec le mouvement des droits civiques.

Le programme "Apollo", lorsqu'il est lancé, répond à des considérations de politique extérieure : l'architecture des missions et la conception des véhicules sont définies sans se soucier de leur pertinence et de leur pérennité du point de vue de la recherche scientifique. Celle-ci est intégrée dans le projet tardivement et avec beaucoup de difficultés. Absorbés par les défis techniques à relever, la NASA et le MSC — ce dernier était particulièrement concerné puisque chargé de la conception des vaisseaux habités et de l'entraînement des astronautes — ont du mal à consacrer des forces à la prise en compte des besoins scientifiques. Enfin, membres de la NASA et scientifiques (ceux-ci étant représentés notamment par le National Academy of Sciences et le Space Science Board) tâtonnèrent longtemps pour mettre au point un mode de travail constructif, chacun voulant assumer la conduite des projets. Après avoir lancé les premières études en 1962, le Space Science Board définit au cours de les points clés à traiter pour les quinze prochaines années dans le domaine de la recherche lunaire. Ce document servira de cahier des charges pour la conception des expériences scientifiques à mettre en œuvre au cours des missions "Apollo".

Pour mener des recherches scientifiques sur le terrain, il valait mieux disposer de scientifiques entraînés comme astronautes que de pilotes — le vivier dans lequel avait puisé jusque-là la NASA — formés à la géologie. En 1965, malgré les réticences d'une partie du management, la NASA recrute six scientifiques. Seuls deux d'entre eux étaient des pilotes vétérans et les autres durent suivre une formation de pilote de chasseur à réaction. Début 1966, le MSC, après avoir été plusieurs fois relancé par la direction de la NASA, mit en place une structure destinée aux expériences scientifiques permettant d'amorcer le processus de développement des instruments embarqués. Seul le géologue Schmitt aura l'occasion d'aller sur la Lune.

Les missions "Apollo" ont permis de collecter en tout de roches lunaires dans six régions différentes de notre satellite (à comparer aux ramenés sur Terre par les missions soviétiques robotisées du programme Luna à la même époque). Ces roches sont conservées d'abord dans un bâtiment construit à cet effet au Centre spatial de Houston, le Lunar Receiving Laboratory remplacé depuis 1979 par le Lunar Sample Laboratory Facility. Une organisation est mise en place pour la fourniture de petits échantillons de roches aux scientifiques du monde entier qui en font la demande. Un institut consacré aux sciences planétaires, le Lunar and Planetary Institute, est créé à la même époque à Houston pour faciliter la coopération internationale et centraliser les résultats des études menées. Par ailleurs de nombreuses données scientifiques ont été collectées au cours des missions : mesures effectuées par les astronautes durant leur séjour sur le sol lunaire, photographies prises depuis l'orbite lunaire, relevés effectués par les instruments logés dans une des baies du module de service à partir de la mission . Enfin, les stations scientifiques ALSEP, comportant de trois à huit instruments et déposées sur le sol lunaire durant les sorties extravéhiculaires, ont transmis leurs mesures aux stations terrestres jusqu'à l'épuisement de leur source d'énergie radioactive en septembre 1977. Les réflecteurs laser qui faisaient partie des ALSEP mais n'ont pas besoin d'une source d'énergie, car complètement passifs, sont encore utilisés de nos jours pour mesurer les variations de distance entre la Terre et la Lune.

Contre toute attente les roches lunaires ramenées comme les observations et les mesures effectuées n'ont pas permis de trancher entre les différents scénarios de formation de la Lune : produit de la collision entre un astre vagabond et la Terre (thèse aujourd'hui privilégiée), capture d'un astre par la Terre, formation en parallèle, etc. En effet, l'interprétation de données issues d'un milieu extraterrestre s'est avérée beaucoup plus difficile que ce que les scientifiques avaient imaginé, car nécessitant entre autres, un gros effort de recherche interdisciplinaire. Les échantillons de roche collectées indiquent une géologie complexe aussi les scientifiques estiment que la Lune est, dans ce domaine, en grande partie inexplorée malgré les six expéditions "Apollo". Les données collectées par les quatre sismomètres ont permis d'esquisser une modélisation de la structure interne de la Lune : une croûte de d'épaisseur surmontant une couche homogène et de nature différente de d'épaisseur avec en profondeur un cœur à moitié fondu () constitué sans doute de silicates. Les altimètres laser ont confirmé que le centre de gravité de la Lune ne coïncidait pas avec son centre géométrique. Les données géologiques et géochimiques recueillies ont été par contre beaucoup plus difficiles à interpréter et n'ont permis de tirer que des conclusions générales : les échantillons reflètent une composition chimique différente de celle de la Terre avec une proportion plus faible des éléments les plus volatils et plus d'éléments radioactifs que la moyenne cosmique. Trois types de roche semblent prédominer : des basaltes riches en fer dans les mers, des plagioclases ou anorthosites riches en aluminium dans les zones situées en altitude et des basaltes riches en uranium et en thorium avec des concentrations importantes de potassium, terres rares et phosphore (basaltes « KREEP »). Mais pour certains scientifiques de cette époque, ces roches ne reflètent pas la composition du sol de la Lune primordiale sans doute enseveli par le bombardement constant subi par celle-ci depuis plusieurs milliards d'années.

L'impact du programme "Apollo" et des programmes spatiaux américains contemporains sur l'évolution technologique est indirect et porte sur des domaines bien précis. Il est difficile de distinguer la contribution du programme de celle des projets militaires (missile balistique) qui le précèdent ou l'accompagnent. Si les technologies concernées peuvent être clairement identifiées, il est beaucoup moins facile de mesurer précisément l'incidence du programme spatial sur les progrès constatés.

L'industrie métallurgique, qui doit répondre à des exigences particulièrement sévères (allègement, absence de défaut) et aux contraintes de l'environnement spatial (vide entraînant la sublimation des métaux, vibration, chaleur), crée de nouvelles techniques de soudure, dont le soudage par explosion, pour obtenir des pièces sans défaut. Le recours à l'usinage chimique, qui deviendra plus tard un procédé essentiel pour la fabrication des composants électroniques, est fréquent. Il a fallu mettre au point de nouveaux alliages et recourir à des matériaux composites. Les instruments de mesure installés dans les engins spatiaux ont dû satisfaire des exigences de précision, fiabilité et rapidité beaucoup plus élevées que la norme. L'instrumentation biomédicale est née de la nécessité de contrôler l'état de santé des astronautes en vol. Enfin, les projets de la NASA des ont permis d'affiner les techniques de calcul de la fiabilité et de mettre au point un grand nombre de techniques de gestion de projet : PERT, WBS, gestion de la valeur acquise, revue technique, contrôle qualité.

Le programme "Apollo" a contribué à l'essor de l'informatique : le développement des programmes de navigation et de pilotage des vaisseaux Apollo voit apparaître la scission entre matériel et logiciel. Les méthodes de programmation et de test sont également en partie nées des exigences de fiabilité et de la complexité des logiciels développés pour le programme. Enfin, le projet lance l'utilisation des circuits intégrés qui ont fait leur apparition en 1961. La NASA achète au début du programme 60 % de la production mondiale pour les besoins des ordinateurs des vaisseaux Apollo.

L'ère spatiale débute en plein âge d'or d'une science-fiction américaine inspirée par les réalisations techniques nées de la Seconde Guerre mondiale et incarnée par des écrivains comme Isaac Asimov, Robert Heinlein, Arthur C. Clarke. Leurs œuvres dressent en images saisissantes et crédibles, le portrait d'une civilisation terrestre et plus particulièrement américaine qui s'est étendue aux planètes voisines ou aux étoiles. Des ingénieurs comme le futur concepteur de la fusée Wernher von Braun (ce dernier à travers ses contacts avec Walt Disney) contribuent également à populariser l'idée de l'exploration de l'espace par l'homme. Lorsque le programme "Apollo" est lancé, la rhétorique sous-jacente de la littérature de fiction spatiale (nouvelle frontière, conquête de l'espace) est reprise dans le discours de responsables politiques et de ceux l'agence spatiale. Aiguillés par la NASA, des magazines comme "Life", la télévision américaine en pleine expansion, transforment la course à l'espace et le programme "Apollo" en particulier, en un feuilleton haletant, suivi avec passion par les Américains et dont les astronautes sont les héros. Le film "2001, l'Odyssée de l'espace", réalisé en collaboration étroite avec les spécialistes de l'industrie spatiale et qui sort en 1968, reflète l'idée que se font beaucoup d'un futur spatial qui semble désormais à portée de main.

Lorsque les astronautes effectuent le voyage initial vers la Lune, donnant à des millions de téléspectateurs pour la première fois la possibilité d'apercevoir leur planète plongée dans l'espace, ils sont sans doute nombreux à partager le sentiment qui inspire au poète Archibald MacLeish ce texte intitulé (« Passagers solidaires de la Terre, frères dans le froid éternel ») qui fut imprimé le jour de Noël à la Une du New York Times :

Les photos de la Terre prises depuis l'espace lointain par les équipages du programme "Apollo" frapperont les esprits à l'époque. La plus célèbre de ces photos est La Bille bleue prise par les astronautes . D'autres photos, comme celles montrant un lever de Terre au-dessus d'un sol lunaire dépourvu de couleurs ou celles mettant en évidence la minceur de la couche atmosphérique ont fait prendre conscience du caractère unique et fragile de notre planète, le vaisseau Terre. Ces images ont sans doute contribué à l'expansion des mouvements écologiques au cours des décennies suivantes.

Le , de téléspectateurs, soit un cinquième de la population mondiale de l'époque, assistent en direct à la télévision aux premiers pas de Neil Armstrong et Buzz Aldrin. Si presque tout le monde s'accorde sur le fait qu'il s'agit d'un évènement marquant, il y a toutefois des voix pour s'élever contre le gaspillage d'argent comme certains représentants de la communauté noire américaine, à l'époque en pleine ébullition. L'écrivain de science-fiction Ray Bradbury, qui participe à un débat à la télévision à Londres, durant lequel il se heurte aux critiques émanant, entre autres, de l'activiste politique irlandaise Bernadette Devlin, s'insurge .

Le mot de Neil Armstrong, , fut immédiatement repris et adapté tandis que l'expression « Si on a pu envoyer des hommes sur la Lune, alors on devrait pouvoir… » devint une phrase passe-partout. Mais l'intérêt pour le programme spatial faiblit rapidement. Le déroulement de la mission , pourtant filmé en couleurs contrairement à , fut beaucoup moins suivi. Les commentaires très techniques, hors de portée de l'Américain moyen, l'absence de péripéties banalisaient l'évènement. Il fallut l'accident , qui replaçait l'homme au cœur de la mission, pour raviver l'intérêt du public.

Plusieurs films et de nombreux documentaires ont pris pour sujet le programme "Apollo". On peut citer notamment :


Au début des années 1970, alors que le programme "Apollo" touche à sa fin, certains décideurs politiques envisagent l'arrêt des vols habités trop coûteux et aux retombées limitées. La fin de la guerre froide et l'effondrement du programme spatial soviétique a privé le projet habité américain d'une grande partie de ses justifications. Mais Richard Nixon ne veut pas être celui qui a arrêté les missions habitées auxquelles se rattache encore malgré tout une part de prestige. Par ailleurs, si l'opinion publique et la communauté scientifique s'accordent sur la nécessité de réduire le budget spatial en particulier consacré aux vols habités, le président n'est pas insensible au lobbying de l'industrie et aux considérations électorales : la Californie qui concentre une grande partie des emplois de l'astronautique — les effectifs employés par l'industrie aérospatiale en Californie passent à — est un enjeu important pour les élections à venir. En partie pour répondre aux critiques sur le coût du programme "Apollo", la NASA a élaboré à cette époque son projet de navette spatiale qui doit permettre d'abaisser de manière significative le prix du kilogramme placé en orbite par rapport aux lanceurs non réutilisables. Le président Nixon donne son feu vert au programme de la navette spatiale mais celle-ci devra s'inscrire par la suite dans un cadre budgétaire spatial civil en décroissance constante : les sommes allouées à la NASA passent progressivement de 1,7 % du budget total de l'État fédéral à 0,7 % , son point le plus bas. Les espoirs suscités par la navette spatiale seront déçus : on estime , alors que le programme de la navette est en voie d'achèvement, que chaque vol de la navette spatiale américaine revient à de dollars en intégrant les coûts de développement : un coût non concurrentiel par rapport à celui d'un lanceur classique. La souplesse opérationnelle n'est pas non plus au rendez-vous : la cadence de lancement atteint 5 % de celle prévue initialement.

La communauté scientifique américaine tire un bilan négatif du programme "Apollo". Les retombées scientifiques du programme sont limitées au regard des sommes investies et la part du programme spatial consacrée à la science (satellites scientifiques, sondes spatiales) a diminué durant les années "Apollo". Le phénomène se répètera d'ailleurs au cours des décennies suivantes, les programmes scientifiques de la NASA étant régulièrement victimes soit des dépassements budgétaires des programmes spatiaux habités soit d'arbitrages en leur défaveur. Aussi, l'Académie des Sciences américaine demande à l'époque que l'activité spatiale soit recentrée sur des thèmes scientifiques et ses applications dans le domaine de la météorologie, l'agriculture, l'hydrologie, l'océanographie, etc. Elle s'oppose également au développement de la navette spatiale. La communauté scientifique est aujourd'hui dans son ensemble toujours peu favorable aux missions habitées au-delà de l'orbite basse : en 2004, à la suite de la relance des missions habitées vers la Lune et Mars, le comité chargé du financement de l'astrophysique au sein de l'American Physical Society, s'inquiétait de l'importance des fonds monopolisés par ce type de mission aux objectifs mal cernés au détriment de projets, comme les télescopes spatiaux, qui avaient largement prouvé leur intérêt scientifique.

Après les progrès fulgurants des années 1960 dont le débarquement lunaire constitue l'acmé, le vol spatial habité, contrairement à toutes les prédictions de l'époque, s'est replié durant ses cinquante dernières années sur l'orbite terrestre basse. L'astronaute Gene Cernan, dans son autobiographie publiée en 1999, écrit « Tout se passe comme si le programme "Apollo" avait vu le jour avant son heure, comme si le président Kennedy avait été chercher une décennie au cœur du et qu'il avait réussi à l'insérer au début des ». Pour l'historien américain J.R. McNeill, l'aventure du programme "Apollo" et de l'exploration spatiale en général pourrait être une impasse condamnée à devenir dans le futur une simple note de bas de page de l'histoire de la civilisation, à moins que des découvertes ne relancent son intérêt ou que renaisse une course au prestige entre des nations disposant de moyens financiers suffisants.

À l'époque du débarquement sur la Lune, il existait déjà une petite minorité d'incrédules qui se recrutait aux États-Unis dans les classes sociales les plus défavorisées, coupées de toute connaissance scientifique, et les minorités. L'audience de la thèse du moon hoax (canular lunaire) s'élargit dans les lorsqu'un climat de défiance vis-à-vis des institutions s'installe chez beaucoup d'Américains dans le sillage du scandale du Watergate et de la guerre du Viêt Nam : c'est à cette époque, symbolisée dans les médias par le film "Les Trois Jours du Condor", qu'est tourné "Capricorn One" (1978) qui raconte l'histoire d'un faux débarquement sur Mars mis en scène par la NASA. En 2001, l'émission « Théorie du complot : avons-nous atterri sur la Lune ? », basée sur des pseudo témoignages scientifiques et diffusée sur la chaine de télévision Fox rencontre un succès d'audience qui témoigne surtout de l'absence de culture scientifique de ses auditeurs. Malgré ses incohérences évidentes, la théorie du faux débarquement sur la Lune continue à trouver des partisans pour les raisons déjà citées mais sans doute également parce que l'événement est si éloigné de toute expérience personnelle, qu'il dégage pour beaucoup un sentiment d'irréalité.

La stagnation du programme spatial habité américain après les succès du programme "Apollo" suscite un intense sentiment de frustration chez beaucoup de passionnés d'astronautique. Au moment même où le programme "Apollo" subit un coup d'arrêt à la fin des années 1960, naissent des associations militant pour un programme spatial habité ambitieux prolongeant l'effort spatial engagé. Selon T.E. Dark, l'apparition de ces mouvements est à mettre en relation avec la crise que subit à la fin des l'idée de progrès, une croyance au cœur de la société américaine. L'apparition du mouvement écologique, un scepticisme naissant vis-à-vis des bienfaits de la croissance économique et la crainte d'un déclin culturel américain expliquent principalement cette crise. Promouvoir le programme spatial était un moyen de faire revivre l'idée de progrès sous une autre forme.

L'association la plus connue à l'époque, la L5 Society, préconise la colonisation de l'espace par la création de gigantesques habitats spatiaux au point de Lagrange L5. Elle reçoit l'attention du Congrès américain ainsi que de la NASA. Mais le concept d'habitats spatiaux géants ne dépassera jamais le stade de l'étude théorique, car il nécessite de lancer un million de tonnes en orbite autour de la Terre en six ou dix ans, un objectif qui ne pouvait être atteint que si le coût de la mise en orbite était abaissé à le kg comme envisagé par l'étude de Gerard K. O'Neill et la NASA en 1975-1977. La L5 Society disparait en 1987, victime des désillusions nées de la crise de l'énergie et des déboires de la navette spatiale américaine. , est fondée la Mars Society qui milite pour la colonisation de Mars. Son créateur, Robert Zubrin, rédige plusieurs ouvrages très documentés sur les moyens de mener une mission habitée sur Mars. The Planetary Society est une association plus ancienne, née en 1980, dont le fondateur le plus connu est Carl Sagan, qui a un ancrage international et compte plus de . Plus réaliste, elle milite surtout pour l'exploration du système solaire mais a tout de même apporté son soutien au programme de mission habitée vers la « planète rouge » de la Mars Society.

Depuis la mission habitée de 1972, plus aucun astronaute ne s'est éloigné de plus de quelques centaines de kilomètres de la Terre. Le , pour le de l'atterrissage , le président des États-Unis George H. W. Bush lance un programme spatial ambitieux sur , le Space Exploration Initiative (SEI), qui doit permettre l'installation d'une base permanente sur la Lune. Mais son coût, l'absence de soutien dans l'opinion publique et les fortes réticences du Congrès font capoter le projet. En 2004, son fils, le président George W. Bush, rend public les objectifs à long terme qu'il souhaite assigner au programme spatial américain alors que l'accident de la navette spatiale Columbia vient de clouer au sol une flotte de navettes spatiales vieillissantes et que le sort de la station spatiale internationale, dont l'achèvement approche, est en suspens. Le projet présidentiel Vision for Space Exploration veut replacer l'Homme au cœur de l'exploration spatiale : le retour d'astronautes sur la Lune est programmé pour une série de missions destinées à préparer une éventuelle présence permanente de l'homme sur le sol lunaire et mettre au point le matériel nécessaire à de futures missions habitées sur Mars fixées à une échéance beaucoup plus lointaine. Cette fois ci, l'opinion comme le Congrès sont favorables au projet : le programme Constellation est alors mis sur pied par la NASA pour répondre aux attentes présidentielles. Il prévoit la construction de deux types de lanceur Ares I et Ares V ainsi que, de manière similaire au programme "Apollo", deux vaisseaux habités Altair et Orion. La NASA utilise, en les adaptant, des moteurs-fusées développés pour la fusée , les propulseurs à poudre de la navette spatiale ainsi que de nombreuses installations au sol remontant à l'époque du programme "Apollo". Mais le programme prend du retard et se heurte à un problème de financement qui selon les plans initiaux, doit s'effectuer sans augmentation substantielle du budget global de la NASA. À la suite de son investiture, le président américain Barack Obama fait expertiser le programme "Constellation" par la commission Augustine, créée à cet effet le . Celle-ci conclut qu'il manque trois milliards de dollars par an pour atteindre les objectifs fixés mais confirme l'intérêt d'une seconde exploration humaine de la Lune comme étape intermédiaire avant une mission habitée vers Mars. Début , le président Obama annonce l'annulation du programme "Constellation" qui est confirmée par la suite.






</doc>
<doc id="15720" url="https://fr.wikipedia.org/wiki?curid=15720" title="Relativité générale">
Relativité générale

La relativité générale est une théorie relativiste de la gravitation, c'est-à-dire qu'elle décrit l'influence sur le mouvement des astres de la présence de matière et, plus généralement d'énergie, en tenant compte des principes de la relativité restreinte. La relativité générale englobe et supplante la théorie de la gravitation universelle d'Isaac Newton qui en représente la limite aux petites vitesses (comparées à la vitesse de la lumière) et aux champs gravitationnels faibles.

Elle est principalement l'œuvre d'Albert Einstein, dont elle est considérée comme la réalisation majeure, qu'il a élaborée entre 1907 et 1915. Le 25 novembre 1915, il soumet son manuscrit de la théorie de la relativité générale à la section de mathématique et de physique de l'Académie royale des sciences de Prusse, qui la publie le 2 décembre. 

Les noms de Marcel Grossmann et de David Hilbert lui sont également associés, le premier ayant aidé Einstein à se familiariser avec les outils mathématiques nécessaires à la compréhension de la théorie (la géométrie différentielle), le second ayant franchi conjointement avec Einstein les dernières étapes menant à la finalisation de la théorie après que ce dernier lui en eut présenté les idées générales dans le courant de l'année 1915.

La relativité générale est fondée sur des concepts radicalement différents de ceux de la gravitation newtonienne. Elle énonce notamment que la gravitation n'est pas une force, mais la manifestation de la courbure de l'espace (en fait de l'espace-temps), courbure elle-même produite par la distribution de l'énergie, sous forme de masse ou d'énergie cinétique, qui diffère suivant le référentiel de l'observateur. Cette théorie relativiste de la gravitation prédit des effets absents de la théorie newtonienne mais vérifiés, comme l'expansion de l'Univers, les ondes gravitationnelles et les trous noirs. Elle ne permet pas de déterminer certaines constantes ou certains aspects de l'univers (notamment son évolution, s'il est fini ou non, etc.) : des observations sont nécessaires pour préciser des paramètres ou faire des choix entre plusieurs possibilités laissées par la théorie.

Aucun des nombreux tests expérimentaux effectués n'a pu la mettre en défaut. Toutefois, des questions restent sans réponse : principalement sur le plan théorique, comment la relativité générale et la physique quantique peuvent être unies pour produire une théorie complète et cohérente de gravité quantique ; et sur le plan des observations astronomiques ou cosmologiques, comment concilier certaines mesures avec les prévisions de la théorie (matière noire, énergie sombre).

Une analogie permettant une visualisation de la relativité consiste à représenter l'espace-temps en dimension 2 comme une nappe tendue se déformant sous le poids des objets que l'on y met. Si la nappe est bien tendue et sans corps dessus, une bille légère que l'on fait rouler dessus passe en ligne droite. Si on y place une boule lourde au centre, la nappe est déformée et la bille légère ne va plus en ligne droite, et même peut tomber vers la boule lourde donnant l’illusion que la bille légère est attirée par la bille lourde alors que cette attraction est le résultat indirect de la forme de la « nappe » qui s’applique aux masses en tout lieu de celle-ci.

Cette analogie semble supposer une source externe de gravitation (qui donnerait du poids à la boule déformant la nappe), mais il faut plutôt considérer que c'est la gravitation exercée par la boule elle-même qui déforme l'espace-temps alentour en le contractant vers elle, voire en lui transmettant une partie de sa dynamique (vitesse de déplacement, rotation sur elle-même).

L'espace-temps n'est pas à deux dimensions, mais à quatre (trois d'espace et une de temps) et toutes les quatre sont déformées par la présence d'une masse.

La théorie de la gravitation universelle proposée par Newton à la fin du se fonde sur la notion de force par une action à distance, c'est-à-dire le fait que la force exercée par un corps (par exemple le Soleil) sur un autre (la Terre) est déterminée par leur position relative à un instant donné, et ce quelle que soit la distance les séparant, et cette force s'exerçant de manière instantanée. Ce caractère instantané est incompatible avec les principes de la relativité restreinte suivant lesquels aucune information ne peut se propager plus vite que la vitesse de la lumière dans le vide. Ceci amène Einstein dès 1907 à réfléchir à une théorie de la gravitation qui soit compatible avec la relativité restreinte. Le résultat de sa quête est la théorie de la relativité générale.

Au , Galilée affirme (en argumentant notamment au sujet du mouvement des navires) que les lois de la physique sont les mêmes dans des référentiels en translation rectiligne et uniforme les uns par rapport aux autres. C'est le principe de relativité galiléenne.

Il utilisera aussi l'additivité des vitesses, dont une conséquence est que n'importe quelle vitesse peut être atteinte, le tout n'étant qu'une question de moyens. Si une balle roule à dans un train (et dans le sens de la marche) qui va lui-même à par rapport au sol, alors la balle va à par rapport au sol.

Dans sa mécanique, Isaac Newton présupposait que les corps étaient dotés d’une vitesse absolue, autrement dit qu’ils étaient soit « réellement » au repos, soit « réellement » en mouvement. Il remarqua aussi que ces vitesses absolues étaient non mesurables autrement que relativement aux vitesses des autres corps (de la même manière, la position d’un corps n’était mesurable que relativement à celle d’un autre corps, etc.). En conséquence, toutes les lois de la mécanique newtonienne devaient opérer à l’identique quel que soit le corps considéré et quel que soit son mouvement.

Cependant, Newton pensait que sa théorie ne pouvait avoir de sens sans l’existence d’un référentiel fixe absolu dans lequel la vitesse de tout corps pourrait être mesurée, même si celui-ci ne pouvait être détecté.

En fait, il est possible en pratique de bâtir une mécanique newtonienne sans cette hypothèse : la théorie résultante (nommée d’ailleurs relativité galiléenne) n’a d’ailleurs pas d’intérêt opérationnel particulier et ne doit pas être confondue avec la relativité d'Einstein qui implique "en plus" la constance de la vitesse de la lumière dans tous les référentiels et "en moins" l’hypothèse galiléenne que les vitesses relatives s’additionnent (ces deux postulats sont en effet mutuellement incompatibles).

Au , le physicien écossais James Clerk Maxwell formula un ensemble d’équations, les équations du champ électromagnétique, qui conduisait à prédire la propagation d'ondes électromagnétiques de vitesse formula_1 dans un milieu électrostatique de constante formula_2 et magnétostatique de constante formula_3. Cette vitesse phénoménalement élevée, même dans un milieu raréfié comme l'air, avait la même valeur que la vitesse de propagation de la lumière. Il proposa que la lumière ne soit rien d'autre qu'une onde électromagnétique.

Les théories corpusculaires de la lumière semblaient compatibles avec le principe de relativité de Galilée ainsi que la théorie de Maxwell qui penchait en faveur de l'existence d'un éther luminifère envisagé par Huygens. Mesurer la vitesse du système solaire par rapport à ce milieu élastique fut l'objet des expériences d’interférométrie menées par Michelson et Morley. Leurs expériences ont démontré que le vent apparent d'éther était nul, quelle que soit la période de l'année. Supposer que l'éther était constamment accroché à la Terre aurait été une remise en cause trop grave du principe de relativité de Galilée. D'autre part, l'éther présentait l'inconvénient d'être à la fois impalpable et très "rigide" puisque capable de propager les ondes à une vitesse phénoménale.

Il fallut attendre Albert Einstein en 1905 pour remettre en cause radicalement la notion d'éther, porter au plus haut le principe de relativité de Galilée en postulant que les équations de Maxwell obéissent elles-mêmes à ce principe, et en tirer les conséquences révolutionnaires dans un article resté célèbre : "De l’électrodynamique des corps en mouvement".

C'est la naissance de la relativité restreinte :

En écrivant l'expression de l'énergie cinétique d'un corps de masse formula_5 de la manière la plus simple respectant le principe de relativité, Einstein a fait apparaître une énergie au repos : E = m.c qui sera mesurée par la suite dans les phénomènes de fusion et de fission nucléaires (mais qui se manifeste aussi dans les réactions chimiques ainsi que dans tout échange énergétique, même si ce n'est pas encore directement détectable).

La "théorie de la relativité restreinte" (1905) modifiait les équations utilisées pour comparer les mesures de longueur et de durée faites dans différents référentiels en mouvement les uns par rapport aux autres. Cela eut pour conséquence que la physique ne pouvait plus traiter le temps et l’espace séparément, mais seulement comme un espace à quatre dimensions, appelé l'espace-temps de Minkowski.

En effet, lors de mouvements à des vitesses non négligeables devant formula_4 (vitesse de la lumière dans le vide), temps et espace s'altèrent de façon liée, un peu comme deux coordonnées d'un point en géométrie analytique s'altèrent de façon liée lorsqu’on pivote les axes du repère.

Par exemple, en géométrie euclidienne habituelle la distance formula_7 entre deux points de coordonnées formula_8 et formula_9 vérifie formula_10 (avec formula_11, etc.), mais dans l'espace de Minkowski deux points sont repérés par les coordonnées formula_12 et formula_13, où formula_14 et formula_15 sont les coordonnées de temps, et la « distance », alors notée formula_16, entre ces points vérifie formula_17. Ce calcul donne une « distance » nulle entre deux points du parcours d'un rayon lumineux. Il donne aussi toutes les mesures de longueurs matérielles, des intervalles de temps, des vitesses en relativité restreinte, qui suscitent toujours l'étonnement.

L'espace-temps de Minkowski étant néanmoins de courbure nulle (c'est-à-dire plat) on le qualifie d'espace "pseudo euclidien".

Tel devait être, pour Einstein, l'espace sans gravitation (et sans accélération pour l'observateur). La gravitation newtonienne, se propageant instantanément, n'est pas compatible avec l'existence d'une vitesse limite : Einstein se mit donc en quête d'une nouvelle théorie de la gravitation.

Il admit l'égalité entre la masse gravitationnelle et la masse inertielle comme hypothèse, la fameuse formule formula_18 autorisant alors à utiliser l'énergie totale d'un corps en lieu et place de sa masse. Ce sera fait grâce à l'outil mathématique nommé tenseur énergie.

Expert en expériences de pensée, il imagina un disque en rotation regardé par un expérimentateur placé en son centre et tournant avec : comme pour Huygens, il y a une force centrifuge au niveau du périmètre qui est perçue comme une force gravitationnelle (car la masse gravifique et la masse inerte sont égales par hypothèse). De plus, en voulant rester dans le cadre de la relativité restreinte, il conclut que l'observateur doit constater la réduction du périmètre mais pas du rayon : ce n'est pas possible dans un espace plat. Conclusion : la gravitation oblige à utiliser une géométrie non euclidienne.

Einstein imagina un expérimentateur enfermé dans un ascenseur aux parois opaques, subissant une montée à accélération constante : l'ascenseur d'Einstein dans lequel il est impossible pour une personne de savoir s'il y a accélération constante ou bien attraction gravitationnelle constante (car la masse gravifique et la masse inerte sont égales par hypothèse). Conclusion : équivalence "locale" entre mouvement accéléré et gravitation, ce qui devait se retrouver dans les équations "différentielles" de la nouvelle théorie. C'est son principe d'équivalence.

Enfin, Einstein voulait trouver une expression des lois de la nature (à l'époque : dynamique, gravitation et électromagnétisme) qui soit inchangée quel que soit le référentiel (accéléré ou galiléen, etc.) : c'est la relativité galiléenne généralisée à tous les repères (on nomme cela la covariance).

La grande difficulté étant de mettre ces principes sous forme mathématique, il en discuta avec David Hilbert qui, d'abord dubitatif, faillit lui ravir la vedette en trouvant la théorie en même temps que lui (voir : Controverse sur la paternité de la relativité).
La "relativité générale" ajouta à la relativité restreinte que la présence de matière pouvait déformer localement l’espace-temps lui-même (et non pas seulement les trajectoires), de telle manière que des trajectoires dites géodésiques — c'est-à-dire intuitivement de longueur minimale — à travers l’espace-temps ont des propriétés de courbure dans l’espace et le temps. Le calcul de la « distance » dans cet espace-temps courbe est plus compliqué qu'en relativité restreinte, en fait la formule de la « distance » est créée par la formule de la courbure, et vice-versa.

Les géodésiques sont les trajectoires vérifiant le principe de moindre action, suivies par les particules test (c'est-à-dire dont l'influence sur le champ de gravitation dans lequel elles se déplacent est négligeable, ce qui est le cas par exemple d'un satellite artificiel autour de la Terre ou bien d'un photon passant à côté du Soleil mais pas d'une étoile orbitant autour d'une autre dans un système binaire oscillant rapidement), elles ont donc une importance pratique très importante pour la compréhension intuitive d'un espace courbe.


La lumière suit les géodésiques (des lignes d'espace-temps) qui sont déformées aux abords d'un corps massif par effet de la gravitation. Par conséquent, et contrairement aux prévisions newtoniennes, la trajectoire de la lumière peut être fortement infléchie en présence d'un corps massif (par exemple une planète particulièrement massive). Deux rayons issus d'un même corps présent d'un côté d'un astre massif, et dirigés dans des directions différentes, peuvent se rejoindre du côté opposé de l'astre et créer une image dédoublée, une sorte de mirage d'origine gravitationnelle.

De tels phénomènes sont observés depuis de nombreuses années et pourraient servir à la détection de la matière noire présente dans l'univers.

À la suite de la découverte de la métrique de Schwarzschild (1916), il est apparu dans les équations que pour toute masse sphérique il existe une distance au centre (le rayon de Schwarzschild) où des phénomènes particuliers se manifestent, si la masse est de rayon inférieur : pour un observateur un peu éloigné, les corps s'approchant de ce rayon semblent s'immobiliser, ses horloges s'arrêter et ceci pour l'éternité ; de plus, mis à part les phénomènes gravitationnels, nulle information ne semble pouvoir venir de cette masse centrale, pas même la lumière, et la masse centrale elle-même n'est décelable que par ses effets gravitationnels.

Toutefois, ce rayon de Schwarzschild n'apparut d'abord que comme une possible singularité topologique de l'espace-temps, une absurdité qui marquait une limite de la théorie, ce qui ne satisfaisait pas Einstein. Entre 1938 (Georges Lemaître) et 1939 (Robert Oppenheimer) est émise l'hypothèse que c'était un phénomène réaliste, nommé "collapse gravitationnel". Dans les années 1960, la nature de ce phénomène a été précisée : il a été compris que le rayon de Schwarzschild n'est pas une singularité de l'espace-temps, mais seulement une singularité de la métrique utilisée due à la courbure de l'espace alors que la métrique est construite comme si l'espace était plat. Les phénomènes décrits par la métrique de Schwarzschild restent valables pour l'observateur éloigné, la métrique de Kruskal-Szekeres (1960) a permis de comprendre comment se fait le passage du rayon de Schwarzschild pour le voyageur.

Depuis, différents types de trous noirs ont été mis en évidence (avec ou sans charge ou moment cinétique), leur dynamique a été étudiée en détail, l'hypothèse de leur évaporation a été précisément formulée, et la notion, très hypothétique, de trou de ver a été avancée. L'observation et la détection des trous noirs est toujours l'objet de travaux intenses, mais de nombreux trous noirs (stellaires, intermédiaires et supermassifs) ont été détectés au-delà de tout doute raisonnable.

En considérant un champ de gravitation faible, la métrique formula_19 s'écarte peu de la métrique formula_20 de l'espace de Minkowski : formula_21.
Avec la condition de petitesse de formula_22 et en ajoutant une condition de jauge, le tenseur de Ricci peut prendre la forme simple formula_23, où formula_24 est le d'alembertien.

Dans le vide, l'équation d'Einstein s'écrit formula_25, ce qui est une équation d'onde. La gravitation peut donc, dans ces conditions, être considérée comme une onde.

On peut de même considérer la gravitation comme une perturbation ondulatoire par rapport à une métrique quelconque "non perturbée", c'est-à-dire dans un espace-temps courbe et stationnaire, et on peut aussi considérer des "ondes gravitationnelles de forte intensité", et étudier le rayonnement énergétique de ces ondes (en utilisant le tenseur énergie-impulsion).

La détection de telles ondes est l'objet d'intenses recherches internationales, cependant, la petitesse des énergies mises en jeu les rend difficilement perceptibles. Les premières détections furent indirectes : en 1974, une perte d'énergie a été observée dans un pulsar binaire (PSR 1913+16) et a été interprétée comme due à l'émission d'ondes gravitationnelles ; par la suite, de nombreuses observations plus précises n'ont fait que confirmer le modèle théorique ; on trouvera un exposé plus détaillé de ces observations dans la section correspondante de l'article "Pulsar binaire".

Le 14 septembre 2015, les chercheurs du LIGO ont détecté des ondes gravitationnelles de l'événement GW150914 : la coalescence de deux trous noirs. Ce fut annoncé le 11 février 2016 lors d'une conférence de la National Science Foundation à Washington. Le résultat est publié le jour-même dans la revue "Physical Review Letter". Ce serait aussi , affirme Thibault Damour, physicien théoricien français.

La physique quantique permet d'émettre l'hypothèse qu'à cette onde est associée une particule responsable de l'interaction gravitationnelle : le graviton, de masse nulle car se déplaçant à la vitesse de la lumière dans le vide.

L'hypothèse de l'homogénéité et l'isotropie, qui constitue le principe cosmologique et qui est en accord avec les observations sur une grande échelle, implique que l'on peut choisir un temps universel tel que la métrique de l'espace soit la même à tout instant, pour tous les points et dans toutes les directions, ce qui est compatible avec la théorie du Big Bang qui prévaut actuellement.

À partir des équations d'Einstein, plusieurs modèles d'Univers sont possibles. En 1915, Einstein concevait l'Univers comme stationnaire, ce que les observations cosmologiques ont contredit. Plus tard Alexandre Friedmann et Georges Lemaître ont proposé des modèles non stationnaires : la métrique de Friedmann-Lemaître-Robertson-Walker montre que trois modèles homogènes et isotropes de l'Univers sont possibles suivant la valeur d'un paramètre dans la métrique : espace plat (en moyenne), à courbure positive (univers dit "fermé" : de volume fini), ou à courbure négative (univers dit "ouvert" : de volume infini).
D'autres modèles cosmologiques, plus "exotiques", sont compatibles avec les équations de la relativité générale. Par exemple : l'Univers de de Sitter correspondant en physique à un univers homogène, isotrope, vide de matière et ayant une constante cosmologique positive ; l'univers mixmaster qui est un univers vide de matière, homogène mais anisotrope, dont le taux d'expansion diffère dans les trois directions d'espace ; l'Univers de Gödel qui ne respecte pas le principe de causalité.

Le micro-satellite Microscope, de 300 kg, lancé en avril 2016, porte deux masses en platine et titane qui ont accompli l'équivalent d'une chute de 85 millions de km. La mission, prévue jusqu'à fin 2018, confirme en novembre 2017 la validité du principe d'équivalence.

Le mouvement d'une masse d'épreuve (très petite) soumise uniquement à la gravitation des masses environnantes est en fait un mouvement inertiel dans un espace-temps courbé par ces masses (la courbure observée dépend aussi du référentiel de l'observateur). La ligne d'univers tracée dans cet espace-temps courbe est une géodésique pour une métrique obéissant aux équations non linéaires d'Einstein qui relient la courbure de l'espace-temps (vu depuis le référentiel choisi) et la présence de masses.

L’idée centrale de la relativité est que l’on ne peut pas parler de quantités telles que la vitesse ou l’accélération sans avoir auparavant choisi un cadre de référence, un référentiel. Tout mouvement, tout événement est alors décrit relativement à ce référentiel de l"'observateur".

La relativité restreinte postule que ce référentiel doit être inertiel et peut être étendu indéfiniment dans l’espace et dans le temps.

Dans le but de ne privilégier aucun type de référentiels en particulier dans l'écriture des lois de la nature (principe de covariance générale), la relativité générale traite en plus les référentiels non inertiels, c'est-à-dire dans lesquels un corps "libre de toute contrainte" ne suit pas un mouvement rectiligne et uniforme. Dès lors, tout système de coordonnées est a priori admissible et, généralement, ses limites se révèlent à l'usage.

En physique classique, un exemple de référentiel non inertiel est celui d'un véhicule qui nous transporte et qui suit un virage : la force centrifuge que l’on ressent contrarie le mouvement inertiel des corps par rapport au véhicule. Un autre exemple est le référentiel lié à la terre, qui du fait de la rotation terrestre voit se manifester la force de Coriolis bien mise en valeur par le pendule de Foucault. Une "force centrifuge" est dite "fictive" car elle n'est qu'une manifestation de l'inertie (premier principe de Newton), et non pas due à l'application d'une force.

En relativité générale, il est admis que l’on ne peut définir un référentiel que localement et sur une période finie. Cette limitation est une nécessité car elle s'impose dans plusieurs cas :

Parce qu’il n’a jamais été possible de mettre en évidence le moindre écart entre la "masse d’inertie" (résistance d’un corps à l’accélération) et la "masse pesante" (qui détermine son poids dans un champ de gravité), le "principe d'équivalence" en relativité générale postule qu’il n’y a pas lieu de distinguer "localement" un mouvement de chute libre dans un champ gravitationnel constant, d’un mouvement uniformément accéléré en l’absence de champ gravitationnel : la gravitation est (localement) équivalente au choix d'un référentiel accéléré pour l'observateur (accélération constante ou variable) par rapport à un référentiel inertiel ; elle n'est donc localement qu'un effet relativiste.

Ce résultat n’est que "local", c’est-à-dire valable pour un espace restreint, « petit ». Dans un volume plus important et avec des accéléromètres sensibles, on distinguera au contraire très bien un champ de gravité (forces concourantes), une simple accélération (forces parallèles) et un effet centrifuge (forces divergentes). Mais dans un volume quasi-ponctuel, aucune mesure ne peut faire la distinction.

Cette équivalence est utilisée dans le cadre de l’entraînement des astronautes : ceux-ci montent dans des avions effectuant un vol parabolique, simulant ainsi un peu plus d'une quinzaine de secondes la « chute libre » d’un corps satellisé (mais pour ce dernier la chute libre peut durer indéfiniment, puisque sa trajectoire est une boucle).

En chaque point de l'espace-temps il existe un référentiel localement inertiel : un référentiel en chute libre (dans le champ de gravitation, s'il y en a) dans lequel tous les corps chutent simultanément au référentiel, si bien qu'ils ne paraissent subir aucune gravitation par rapport à ce référentiel. Par hypothèse un tel référentiel décrit un espace de Minkowski, localement. Ainsi le choix d'un référentiel fait-il disparaître, localement, les effets de la gravitation, ou bien il en crée ; mais ces effets ne sont que locaux.

En chaque point de l'espace-temps, la gravitation peut être décrite comme le choix pour l'observateur d'un référentiel non inertiel dans un espace plan. La métrique dans ce référentiel est la métrique dans un référentiel inertiel au même point mais exprimée avec les coordonnées du référentiel non-inertiel (ce qui peut donner des formules laborieuses). Les coefficients formula_26 de cette expression quantifient la différence entre une métrique de référentiel inertiel et le référentiel de l'observateur : elles contiennent toutes les informations nécessaires pour passer d'un référentiel à l'autre, ainsi la gravitation ne dépend que de la métrique du référentiel de l'observateur.

Le temps propre formula_27 du référentiel inertiel (Minkowskien) donne sa métrique et vérifie formula_28, où formula_29 sont les coordonnées dans le référentiel de l'observateur et formula_30 les coordonnées dans un référentiel inertiel au même point. En posant formula_31, avec la convention d'Einstein, on peut écrire formula_32.

Le principe d'équivalence permettant d'affirmer que localement le champ de gravitation est équivalent à un choix de référentiel, et que l'on peut annuler (toujours localement et momentanément) les effets de la gravitation en choisissant un référentiel inertiel. La géodésique suivie par un corps est particulièrement simple dans cette théorie : c'est la courbe suivie par ce corps quand il se déplace sur la ligne droite d'un tel référentiel inertiel, mais vu depuis le référentiel de l'observateur. En général, à chaque instant du mouvement, le référentiel inertiel local est à redéfinir, et donc les géodésiques aussi, là est la complexité : les géodésiques sont des solutions d'équations différentielles définies dans le référentiel de l'observateur.

Comme dans le cas d'un espace plat où le référentiel de l'observateur est en rotation autour d'un axe, par rapport à un référentiel inertiel, l'observateur perçoit comme "courbés" les mouvements rectilignes uniformes du référentiel inertiel.

Il faut prendre garde au fait qu'à chaque instant, un nouveau référentiel inertiel peut être utilisé et qu'il est rare qu'un seul accompagne le corps en mouvement dans le référentiel de l'observateur : ça ne se rencontre que pour des situations purement académiques. Même dans un tel cas, il ne faut pas croire pour autant que si deux mobiles suivent la même ligne droite dans un référentiel inertiel, ils sembleront se suivre dans un référentiel non-inertiel : si le référentiel de l'observateur n'est pas inertiel, deux corps ayant des vitesses initiales différentes se déplacent sur des géodésiques différentes.
La dérivée covariante étant la dérivée le long des géodésiques, considérées comme des tangentes à la trajectoire, on comprend qu'ici elle soit indépendante du référentiel de l'observateur, et que ses calculs soient un peu laborieux car ils incluent un changement de référentiel pour passer de celui de l'observateur à un référentiel inertiel, différent à chaque instant car un référentiel n'est que localement et provisoirement inertiel. La dérivée covariante d'un quadri-vecteur est la dérivée le long de la géodésique qui relie deux positions successives (et infiniment proches) de ce vecteur.

La dérivée covariante d'un quadri-vecteur dans le référentiel quelconque est notée formula_33, où formula_34 est le temps propre lié au quadri-vecteur. Le principe de correspondance consiste alors à considérer que là où il y a une égalité du type formula_35, en physique classique, ou formula_36 en relativité restreinte, on peut écrire formula_37 en relativité générale, à condition que le membre de droite de l'égalité ait aussi son équivalent dans cette théorie. Cela est rendu possible parce que, finalement, il s'agit de la même chose exprimée de manières différentes : des dérivations le long d'axes rectilignes de référentiels inertiels.

Dans le cas où, par rapport au référentiel inertiel, le quadri-vecteur est constant au cours du temps propre formula_27 (mouvement inertiel), on a formula_39.

Supposons que dans un référentiel quelconque soit exercée une force relativiste, sous la forme d'un quadri-vecteur formula_40, sur le corps observé. Par changement de référentiel, on peut considérer cette force dans un référentiel d'inertie local par un quadri-vecteur formula_41.

Du principe fondamental de la dynamique, formula_42, en physique classique, on tire par le principe de correspondance formula_43 en relativité restreinte, puis enfin formula_44, équation de la dynamique relativiste en présence d'un champ de gravitation.

L'équation d'Einstein est l'expression mathématique de la Relativité Générale et plus généralement de toute la physique de la gravitation. Il s'agit d'une formule fondamentale, qui ne peut être dérivée d'une théorie sous-jacente.

Sa forme générale signifie :

Cette équation exprime et concentre les idées principales d'Einstein gouvernant la relativité générale : le principe d'équivalence amène à affirmer que la gravitation n'est pas une véritable force. S'il n'existe aucune force pour dévier ou accélérer la trajectoire des objets, c'est que c'est l'espace-temps lui-même qui est déformé et la théorie de la gravitation doit se manifester sous forme d'une courbure de l'espace-temps. Les objets suivent des géodésiques, qui peuvent être considérées comme l'équivalent des lignes droites pour cet espace-temps courbé. L'utilisation du formalisme des tenseurs rend l'expression de cette loi indépendante des référentiels et est donc conforme au principe de relativité.

Cette équation est locale : elle indique la manière avec laquelle l'espace-temps se courbe en un "point" de l'espace-temps en fonction de la densité de matière qui s'y trouve et, réciproquement, la disposition ou l'évolution de la matière en un point en fonction de la courbure à ce point. L'espace-temps agit sur la matière, qui elle-même agit sur l'espace-temps. Cette rétroaction se traduit par une non-linéarité des équations d'Einstein, qui sont de ce fait extrêmement difficiles à résoudre de manière exacte. Le caractère local de l'équation a pour conséquence que selon la relativité générale, il n'existe pas d'action instantanée à distance : la matière courbe localement l'espace-temps, ce qui perturbe l'espace-temps un peu plus loin et ainsi de suite. Les perturbations gravitationnelles se propagent ainsi à la vitesse de la lumière.

Cette équation se traduit par un ensemble complexe d'équations différentielles d'un tenseur métrique formula_45. Néanmoins l'expression de cette équation reste concise et élégante, et est considérée par beaucoup de physiciens comme étant une des formules les plus importantes et les plus belles de la physique.

Ses solutions, qui sont des métriques de l'espace-temps, permettent de définir des modèles cosmologiques formalisant l'évolution à grande échelle de l'univers, de modéliser les propriétés d'objets astronomiques comme les trous noirs, ou de prédire l'existence d'ondes gravitationnelles. Elle incorpore bien entendu la loi universelle de la gravitation de Newton comme approximation dans le cas de champ gravitationnel faible.

Plus précisément, l'équation d'Einstein s'exprime sous la forme globale suivante :

avec formula_46 qui est le tenseur d'Einstein qui représente la courbure de l'espace-temps en un point, et formula_47 qui est le tenseur énergie-impulsion représentant la contribution de toute la matière (et énergie) à la densité d'énergie en ce point du champ gravitationnel. Mais ce tenseur ne tient pas compte de l'énergie éventuellement présente dans le champ gravitationnel lui-même.

formula_48 est un simple facteur dimensionnel, permettant d'exprimer l'équation dans les unités usuelles et de faire correspondre l'équation à la réalité physique et à la valeur observée de la constante gravitationnelle.

La manière la plus naturelle de représenter la courbure par un tenseur serait d'utiliser un tenseur de Riemann, qui est la façon la plus courante d'exprimer la courbure des variétés riemanniennes, l'espace-temps étant parfaitement représenté par une variété pseudo-riemannienne. Mais ce tenseur est d'ordre 4 (à 4 indices), alors que le tenseur énergie-impulsion est d'ordre 2 : 2 indices sont en effet suffisants pour décrire "toutes" les propriétés dynamiques de l'énergie et la matière, et construire un tenseur énergie-impulsion d'ordre 4 n'aurait aucun sens physique.

Il est donc nécessaire de construire un tenseur spécial représentant la courbure, ayant un sens physique et qui puisse être identifié au tenseur énergie-impulsion. C'est tout le travail qu'effectue Einstein entre 1913 et 1915, pour aboutir au tenseur d'Einstein, et à la formulation exacte de l'équation d'Einstein.

Le tenseur énergie-impulsion représente la contribution de toute la matière (et de tous les champs "non gravitationnels") à la densité d'énergie en un point.

Le tenseur énergie-impulsion possède une dérivée covariante nulle, et une dérivée covariante étant une « dérivée le long des géodésiques », cela traduit qu'un objet suivant une géodésique conserve son énergie.

Toutefois, la dérivée covariante nulle du tenseur énergie-impulsion ne traduit pas la conservation de l'énergie-impulsion du corps en présence de gravitation, ni « la conservation de quoi que ce soit », ce qui se comprend en remarquant que dans un référentiel non inertiel un corps initialement au repos peut acquérir de la vitesse sans pour autant changer de masse, ce qui correspond à une acquisition d'énergie cinétique : la loi de conservation de l'énergie d'un corps reste valable uniquement dans les référentiels inertiels.

Ce tenseur ne prend pas en compte l'énergie éventuellement présente dans le champ gravitationnel lui-même, quand celui-ci est dynamique (présence d'ondes gravitationnelles par exemple), cette expression ne représente pas la conservation "globale" de l'énergie. La conservation de l'énergie en présence d'un champ gravitationnel dynamique est un sujet délicat et non encore complètement résolu en relativité générale.

Le tenseur d'Einstein est donc un tenseur qui, dans l'équation d'Einstein, représente la courbure et possède une signification physique, c'est-à-dire d'ordre 2, symétrique, possédant une dérivée covariante nulle, et qui permet de retrouver la loi de gravitation de Newton comme approximation avec des champs gravitationnels faibles et vitesses en jeu très inférieures à celle de la lumière.

Il existe un moyen de construire un tenseur d'ordre 2 à partir d'un tenseur d'ordre 4 : effectuer une contraction du tenseur selon deux indices. Une telle contraction du tenseur de Riemann donne un tenseur connu sous le nom de tenseur de Ricci, noté formula_49.

Pour construire une équation physique, le tenseur de Ricci possède une propriété intéressante : il permet de retrouver l'accélération à partir de l'état de repos d'une sphère de particules entourant une masse ponctuelle. En mécanique newtonienne, cette même accélération est calculée à partir de l'équation de Poisson formula_50, formula_51 étant le potentiel gravitationnel et formula_52 la densité de masse. Le tenseur de Ricci formula_49 et le terme gauche de l'équation de Poisson possédant tous les deux des dérivées secondes de la métrique et ayant une même signification physique, il serait naturel de poser :

formula_47 étant le tenseur représentant la densité de masse, et cette équation a été effectivement proposée en 1913 par Einstein. Ce tenseur est en effet d'ordre 2 et symétrique, mais il s'avère que sa dérivée covariante n'est pas nulle. En fait, en utilisant les identités de Bianchi sur le tenseur de Riemann, on trouve que c'est le tenseur formula_56 qui possède une dérivée covariante nulle. Einstein ne connaissait pas les identités de Bianchi, et trouve le tenseur d'Einstein, après deux ans d'intense efforts, aidé par le mathématicien Marcel Grossmann :

formula_57 est la courbure scalaire, qui est elle-même une contraction du tenseur de Ricci, et formula_45 est le tenseur métrique, solution des équations d'Einstein. Si le tenseur de Riemann donne la courbure d'une variété en un point, selon un plan défini par un couple de vecteurs, le tenseur de Ricci représente la moyenne des courbures selon tous les plans contenant un vecteur donné, tandis que le tenseur d'Einstein représente la moyenne des courbures selon tous les plans orthogonaux à ce vecteur.

Il a été démontré que le tenseur d'Einstein est le seul tenseur pouvant être mathématiquement construit qui possède toutes les propriétés voulues : ordre 2, qui possède des dérivées secondes de la métrique, de dérivée covariante nulle et qui s'annule en espace plat (permettant de retrouver Newton)

David Hilbert a aussi justifié cette équation par le principe de moindre action dès 1915.

Étant donné le tenseur d'Einstein, la formulation complète et exacte de l'équation d'Einstein en découle directement :

avec formula_59, et (i,j) allant de 1 à 4 (pour les 4 dimensions de l'espace-temps).

Éclatée en équations différentielles, cette expression tensorielle se traduit par dix équations aux dérivées partielles non-linéaires. Sur ces dix équations, quatre dépendent du choix du référentiel, ce qui laisse six équations à résoudre pour déterminer la métrique.

Il est important de noter que l'ajout d'une constante au tenseur d'Einstein ne change pas ses caractéristiques physiques : sa dérivée covariante reste nulle et les lois de Newton sont toujours retrouvées aux limites. L’équation du champ peut donc contenir un paramètre « supplémentaire » appelé la "constante cosmologique" formula_60 qui a été introduite à l’origine par Einstein pour qu’un univers statique (c’est-à-dire un univers qui n’est ni en expansion, ni en contraction) soit solution de son équation.

Les équations d'Einstein s'écrivent alors :

Cet effort se solda par un échec pour deux raisons : d'un point de vue théorique, l’univers statique décrit par cette théorie est instable ; et de plus les observations de l’astronome Edwin Hubble dix ans plus tard démontrèrent que l’Univers était en fait en expansion. Donc formula_60 fut abandonnée, mais récemment, des techniques astronomiques ont montré qu’une valeur non nulle de ce paramètre permet d'expliquer certaines observations, notamment l'énergie sombre.

Il est possible de reformuler les équations d'Einstein de manière, rigoureusement équivalente, à isoler le tenseur de Ricci :

Dans le vide où il n'existe aucune énergie ni matière, formula_62. Il devient alors apparent que l'équation d'Einstein se résume à :

quand la constante cosmologique est nulle. Un espace vide dont le tenseur de Ricci s'annule est nommé un espace « Ricci-plat ». "Cela ne signifie pas que l'espace-temps est plat en l'absence de toute matière ou énergie" : la courbure de l'espace est représentée par le tenseur de Riemann, pas par le tenseur de Ricci.
Le fait que le tenseur de Ricci représente une courbure "moyenne" implique que, dans le vide (au point où est faite la mesure : absence d'énergie courbant l'espace), l'espace soit "en moyenne" plat (courbure moyenne nulle) mais courbé dans chaque direction du fait que plus ou moins loin des présences d'énergies (des masses en mouvement) courbent l'espace en le mettant sous tension un peu comme une nappe tirée à ses coins. Par ailleurs, la forme globale de l'univers impose des courbures dans les différentes directions, bien que dans le vide la courbure moyenne reste nulle : diverses formes d'univers sont possibles, aucune n'est certaine à ce jour.

Si on considère le tenseur de Ricci comme la "source" du champ gravitationnel, le champ gravitationnel lui-même est représenté par le tenseur de Riemann, auquel au soustrait le tenseur de Ricci pour ne laisser que les degrés de liberté qui ne sont pas issus de la source elle-même. Le tenseur obtenu est le tenseur de Weyl formula_63, qui a les mêmes propriétés que le tenseur de Riemann, mais qui représente réellement le champ gravitationnel : formula_64. C'est l'annulation de ce tenseur qui est la condition pour la platitude conforme de l'espace-temps.

Le tenseur de Weyl représente les forces de marée dues à la gravitation. Une sphère de particules soumise au tenseur de Weyl, par l'influence d'une masse en dehors de la sphère, subit une déformation "qui ne change pas son volume", contrairement à l'influence du tenseur de Ricci. Les ondes gravitationnelles sont décrites, dans le vide, par le tenseur de Weyl.

Le tenseur densité-impulsion amène à définir le concept de masse en relativité générale de manière légèrement différente que dans le cas des lois Newtoniennes. En reprenant l'expression de l'équation d'Einstein qui isole le tenseur de Ricci : formula_65, et en identifiant celui-ci à l'accélération initiale, et à l'équation de Poisson, on trouve une masse gravitationnelle active équivalente:

au lieu de formula_66 dans le cas Newtonien. Les valeurs formula_67 sont les valeurs de la "pression" sur les trois axes spatiaux orthogonaux, et la constante gravitationnelle contribue à la masse gravitationnelle active.

Dans les conditions normales, les contributions de la pression à la masse gravitationnelle active est très faible, et la constante cosmologique négligeable. Mais la pression peut jouer un rôle considérable dans des conditions extrêmes notamment lors de l'effondrement gravitationnel d'étoiles massives, où la pression - au lieu de s'opposer à l'effondrement gravitationnel comme on pourrait s'y attendre - accroît la tendance à l'effondrement en augmentant la masse gravitationnelle active.

Il existe des situations physiques où l'énergie peut être échangée entre des systèmes gravitationnels et non-gravitationnels. Par exemple, quand un corps massif orbite autour d'un autre corps massif, il y a émission d'ondes gravitationnelles qui emportent une certaine énergie du système. Cette perte est absolument négligeable dans les ordres de grandeurs classiques (par exemple, l'énergie dégagée par unité de temps sous forme d'ondes gravitationnelles par l'orbite de Jupiter autour du soleil correspond à 40 watts). Mais dans des circonstances où les ordres de grandeurs sont très élevés, comme pour le pulsar binaire PSR B1913+16, l'énergie emportée a des effets importants et mesurables, qui permettent d'ailleurs de valider avec succès la théorie de la relativité générale.

La théorie de la relativité générale ne donne pas une représentation immédiate et évidente de ce phénomène. Le tenseur énergie-impulsion ne donne que l'énergie d'un corps ou d'un champ non gravitationnel en un point, sans tenir compte de l'énergie du champ de gravitation en ce point. L'énergie des ondes gravitationnelles n'est donc pas représentée par ce tenseur, et sa dérivée covariante nulle ne représente pas la conservation globale de l'énergie. Pour représenter une énergie du système « corps-champ de gravitation » se conservant, Einstein a exprimé l'énergie du champ par d'un « pseudo-tenseur » qui s'annule pour un choix de référentiel "en chute libre" (inertiel) au point considéré : l'énergie du champ de gravitation n'existe qu'en fonction du référentiel choisi. Ce « pseudo-tenseur », tiré du tenseur de Ricci, exprime aussi l'auto-corrélation du champ sur lui-même, ce qui explique sa formulation assez compliquée. En particulier, l'énergie émise sous forme d'ondes gravitationnelles s'exprime à l'aide de ce « pseudo-tenseur ».

Ces échanges ont aussi été étudiés et modélisés par Hermann Bondi et Rainer Sachs pour un type d'espace-temps particulier, l', qui représente des systèmes gravitationnels considérés comme isolés du reste de l'univers, ce qui est approximativement vrai pour des systèmes comme des pulsars binaires.

Mais la compréhension de la conservation globale de l'énergie en présence d'un champ gravitationnel dynamique reste un sujet délicat et non encore complètement résolu en relativité générale.











Accessibles au niveau du premier cycle universitaire.





</doc>
