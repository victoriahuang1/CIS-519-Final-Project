<doc id="1982" url="https://es.wikipedia.org/wiki?curid=1982" title="Nicaragua">
Nicaragua

Nicaragua, oficialmente República de Nicaragua, es un país de América ubicado en el istmo centroamericano. Su capital es Managua. Nicaragua está compuesta por 15 departamentos y 2 regiones autónomas. Son órganos de gobierno: el Poder Legislativo, el Poder Ejecutivo, el Poder Judicial y el Poder Electoral. En separación de poderes existe autonomía en cada uno de estos.

La República de Nicaragua está ubicada en el hemisferio norte, entre la línea ecuatorial y el trópico de Cáncer aproximadamente entre los 11° y los 15° de latitud Norte y respecto al meridiano de Greenwich, entre los 83° y los 88° de longitud Oeste.

El territorio de Nicaragua tiene una superficie aproximada de 129 494 km², limita al norte con Honduras, al sur con Costa Rica, al oeste con el océano Pacífico y al este con el mar Caribe. En cuanto a límites marítimos, en el océano Pacífico colinda con El Salvador, Honduras y Costa Rica; mientras que en el mar Caribe colinda con Honduras, Colombia y Costa Rica.

El pueblo nicaragüense es de naturaleza multiétnica y el español es la lengua oficial, aunque también son reconocidas las lenguas de los pueblos indígenas originarios como el Inglés criollo nicaragüense, misquito, Sumu o Sumo, Garífuna y Rama.

Habitado por pueblos precolombinos, la costa del Océano Pacífico y parte de la región central del actual territorio de Nicaragua fue conquistado por España en el siglo XVI, donde fue establecida la Provincia de Nicaragua, que perteneció al Imperio español (1502-1821), luego al Primer Imperio Mexicano (1821-1823), a las Provincias Unidas del Centro de América (1823-1824), y a la República Federal de Centroamérica (1824–1838), emerge como país independiente en 1838, bajo el nombre de "Estado de Nicaragua" y se empieza a llamar República de Nicaragua, desde 1854.

Respecto a la integración de la llamada Costa de Mosquitos (la antigua Provincia de Taguzgalpa) en la República de Nicaragua, en 1860 se firmó el tratado de Managua entre Nicaragua y el Reino Unido de Gran Bretaña e Irlanda, por lo cual este renunció a su protectorado misquito y reconoció la soberanía de Nicaragua; mientras que Nicaragua reconoció los derechos de autonomía de los misquitos. Así nació la "Reserva Mosquitia". Un año después de firmado el Tratado de Managua, en Bluefields se reunieron 51 Witas (alcaldes) y aprobaron la Constitución de la Reserva, inspirada por el cónsul británico y que establecía de manera general, leyes inglesas. La soberanía de Nicaragua fue en realidad una formalidad, hasta que en 1894 la Mosquitia fue reincorporada oficial y concretamente a Nicaragua durante el gobierno de José Santos Zelaya, mediante la llamada Reincorporación de la Mosquitia efectuada por Rigoberto Cabezas, quien debió hacer frente a un intento de restablecer su dominación por parte de los británicos, entre julio y agosto de ese mismo año. Mediante el tratado Altamirano-Harrison del 19 de abril de 1905, Gran Bretaña reconoció la soberanía absoluta de Nicaragua sobre la costa de Mosquitos, lo que significaba abolir la "Reserva Mosquitia", a cambio de garantizar a los nativos exención de impuestos y del servicio militar y garantizarles vivir en sus aldeas y territorios ancestrales según sus costumbres propias.

Nicaragua es un país y tropical, en su interior alberga también dos grandes lagos: el Lago Xolotlán y el Lago Cocibolca o "Gran lago de Nicaragua".

Tras décadas de intervención y fuerte influencia extranjera, mediante la Revolución nicaragüense, se instauró una Junta de Gobierno de Reconstrucción Nacional (1979-1985) constituida como junta de gobierno transitoria encargada del poder ejecutivo y un Consejo de Estado encargado del poder legislativo con participación de representantes de los ámbitos político, social, comunal y religioso.

En 1984 se realizan las primeras elecciones populares conforme a la nueva Ley electoral. La Junta de Gobierno de Reconstrucción Nacional entrega el poder al nuevo Presidente elegido: Daniel Ortega Saavedra. Así La Junta transitoria queda disuelta.

Durante el gobierno del Frente Sandinista de Liberación Nacional (FSLN) el país sufrió un prolongado conflicto civil fomentado con la intervención de los Estados Unidos de América bajo la administración del presidente Ronald Reagan, el gobierno estadounidense por medio de la CIA; formó y entrenó en secreto a grupos de rebeldes anticomunistas conocidos como Contras, financiando una guerra desautorizada por el Congreso y llegando a bloquear económicamente a Nicaragua. La Unión Soviética y países como Cuba, Francia y Libia también intervinieron en el conflicto a través de cooperación militar, económica, financiera y médica. Dicho conflicto motivó la demanda del gobierno de Nicaragua contra el gobierno de Estados Unidos ante la Corte Internacional de Justicia de La Haya, en el conocido caso Nicaragua contra Estados Unidos, cuya sentencia favorable a Nicaragua obligaba al gobierno de Estados Unidos a indemnizar a la República de Nicaragua, deuda que luego fue perdonada al gobierno de Estados Unidos por el gobierno nicaragüense de la presidenta Violeta Barrios de Chamorro.

Los conflictos económicos y de guerra culminaron luego de las elecciones populares del 25 de febrero de 1990, cuando Violeta Chamorro derrotó a Daniel Ortega con 54.7 % de los votos contra 40.8 %.

Según el IDH, a partir del año 1995, Nicaragua ha venido mejorando su nivel de vida.

La determinación del significado del nombre de Nicaragua es un poco inexacto, sin embargo sintetizando los hallazgos de los investigadores Nicaragua significa El Reino de los que habitan junto a grandes depósitos de agua. También Generalmente se acepta que se debe a Nicarao, señor de los niquiranos (nahuas), cuyo señorío a la llegada de los conquistadores españoles abarcaba desde el istmo de Rivas e isla de Ometepe hasta Nicoya en la actual Costa Rica. Se cuenta de un diálogo entre Nicarao y Gil González Dávila, durante el cual el jefe indígena asombró al español con sus preguntas y respuestas a temas de filosofía y astronomía. 

Por lo menos unos 13 000 años antes de nuestra era, aparecieron en Nicaragua los primeros seres humanos, procedentes del hemisferio Norte; también se conoce de emigraciones originarias del Sur. Se radicaron a orillas de ríos, lagunas, lagos y mares; transcurridos los siglos el único testimonio que dejaron de su cultura son sus huellas en la loseta volcánica de Acahualinca.

De esos migrantes aseveran que el núcleo original perteneció los primeros pobladores lenmichies, luego desplazados de la costa del Océano Pacífico por el gran grupo de origen mangue llamados dirianes o chorotegas, de quienes descienden los habitantes de la zona oriental del Pacífico: Managua (Imabite); Masaya (Nindiri, Catarina, Niquinohomo); Granada (Xalteva) y Carazo (Diriamba, Jinotepe). Además en León (Sutiava o Sutiaba).

En la costa del mar Caribe nicaragüense, en la zona llamada se localiza el "conchero" (cúmulo de valvas) conocido como "Angie", donde se encuentran los vestigios de presencia humana, más antiguos conocidos, datados en 8 mil años.

Se sabe de asentamientos indígenas en la región de la costa del Océano Pacífico nicaragüense que datan del 6000 a. C. El yacimiento de Acahualinca (entre el 232 y el 8 a. C.) es posterior, asimismo se conocen otras evidencias arqueológicas, principalmente artículos de cerámica y estatuarios de piedra volcánica, como los hallados en la isla de Zapatera.

La mayoría de investigaciones coinciden en el origen náhuatl del nombre de Nicaragua, pero los autores no se ponen de acuerdo en cuál puede ser su traducción:

Los nicaraos emigraron hacia esta área desde regiones norteñas después de la caída de Teotihuacán, ya que así lo aconsejaron sus líderes religiosos. Según la tradición, debían viajar hacia el sur hasta que encontraran un lago con dos volcanes que se levantaran de las aguas, es decir, cuando llegaran a Ometépetl (Ometepe), la isla volcánica más grande del mundo en medio de un lago de agua dulce.

Además de los chorotegas, nahoas y marribios que habitaban en la franja del Pacífico, estaban los matagalpas que habitaban las cordilleras montañosas del centro de Nicaragua, y los ulwa-sumo, miskitos y ramas que habitaban las riberas de los grandes ríos que desembocan en el mar Caribe.
Siempre ha habido una confusión gramatical entre Ulúa y Ulwa, que son dos grupos diferentes, los Ulúa hablaban el matagalpa-populuca. Los ulwas forman parte de los mayangnas y hablan el sumo o parrastra. Es posible que existiera algún contacto a nivel del departamento de Matagalpa, los primeros al oeste, entre pinares, los segundos al este era gente selvática. El límite entre ambos era Yasica al norte y Olama al sur.

El 21 de abril de 1524, en el actual territorio de Nicaragua, fue fundada la ciudad de Granada y el 19 de junio de 1524 la ciudad de León. Ambas fueron fundadas por Francisco Hernández de Córdoba, enviado por Pedro Arias de Avila, entonces gobernador de Castilla de Oro, en el actual territorio de Panamá. En 1528, la Corona española erigió la Provincia de Nicaragua, y se solicitó establecer si el territorio de la villa de Bruselas (actualmente en territorio de Costa Rica), pertenecía a la Provincia de Nicaragua (la nueva circunscripción), o si permanecía bajo la autoridad de Castilla del Oro.

Una Real Cédula del 21 de abril de 1529 resolvió el conflicto a favor de la Provincia de Nicaragua, cuando ya la villa de Bruselas había dejado de existir. Posteriormente la Provincia de Nicaragua pasó a depender de la Audiencia de Panamá hasta 1543 que pasa a depender de la Audiencia de Guatemala.

En 1554, con la conquista del Reino de Nicoya se crea la Alcaldía Mayor o Corregimiento de la provincia de Nicoya, puertos de Chira y Paro. La Intendencia de León fue creada por Real Cédula del 23 de diciembre de 1786, con la unión de la Alcaldía Mayor de Nicoya y la Gobernación de Nicaragua. Formando parte de la Capitanía General de Guatemala, dependiente del Virreinato de la Nueva España.

En 1812, las Cortes de Cádiz erigieron la provincia de Nicaragua y Costa Rica (separada de la provincia de Guatemala), y con cabecera en la ciudad de León. Esta provincia duró hasta 1814, año en que se restableció el reino de Guatemala. En 1820, al restablecerse el régimen constitucional, resurgió la provincia de Nicaragua y Costa Rica, que estaba dividida en siete partidos:

A mediados del siglo XVI, se desarrolló en el noreste de la actual Honduras la nación de los zambos mosquitos, surgida de la mezcla entre los indígenas que la habitaban y los esclavos sobrevivientes del naufragio de un barco negrero que se hundió en el litoral. Los británicos establecieron amistosas relaciones con ellos y surgió así la reserva Misquita o «Mosquitia», una especie de Protectorado británico que duró hasta fines de siglo XIX.

En 1630, se estableció el primer contacto comercial entre los británicos y los misquitos en la zona del cabo Gracias a Dios Entre ellos estaba el pirata neerlandés Abraham Blauvelt quien se estableció en la bahía de Bluefields llamada así en honor a él. Poco a poco los ingleses se asentaron en la región, hasta que el 16 de abril de 1740 los misquitos, amparados por la protección de Gran Bretaña, ceden sus territorios, estableciendo el dominio colonial británico.

En 1774, Bluefields se convirtió en la capital de la Mosquitia, donde los británicos instalaron a un rey mosco para consolidar su dominio. Los británicos se retiraron en 1787 pero la Mosquitia siguió siendo gobernada por los reyes moscos, fieles a la corona británica.

En 1803, por intermedio de la Real Orden del 20 de noviembre, el rey de España ordenó segregar de la antigua Capitanía General de Guatemala, la Costa de Mosquitos como las islas de San Andrés y agregarlas al Virreinato de Nueva Granada.

Posteriormente la Costa de Mosquitos fue restituida a la Capitanía General de Guatemala, mediante una Real Orden del 13 de noviembre de 1806, enviada al Capitán General de Guatemala, expresando lo siguiente:

En 1894, las tropas nicaragüenses al mando de Rigoberto Cabezas ocuparon la Costa de Mosquitos, que fue organizada como el departamento de Zelaya, dividido a fines del siglo XX en dos regiones (Región Autónoma del Atlántico Norte y la Región Autónoma del Atlántico Sur).

Nicaragua formaba parte de la española Capitanía General de Guatemala, que comprendía los territorios desde Costa Rica hasta la actual Chiapas (en México). En Sudamérica, y durante cierto periodo en México, los mestizos y criollos americanos (españoles nacidos en el Nuevo Mundo) iniciaron sangrientas guerras contra la Corona hasta conseguir su independencia. Pero en Centroamérica la situación fue diferente.

Con España fuera, Nicaragua y toda Centroamérica decidió anexarse al naciente Imperio mexicano, pero este duró muy pocos años. Entonces los pequeños países del istmo decidieron formar la Federación de Estados Centroamericanos, la cual se disolvió debido a los intereses particulares de los líderes de cada una de las provincias. Fue entonces que el 30 de abril de 1838, Nicaragua ingresó en la historia como una república independiente.

La independencia de Nicaragua ocurrió durante septiembre de 1821, al observar como otras regiones españolas ganaban la guerra de la independencia, los líderes nicaragüenses comenzaron un proceso de negociación, al redactar un acta de independencia que fue reconocida por los jefes de la Corona. Entre las personas que promovieron la independencia centroamericana destacaron dos nicaragüenses: el presbítero Tomás Ruiz Romero y el jurisconsulto Miguel Larreynaga, recordado por su efigie en una emisión de los billetes de diez córdobas.

Varias fueron las causas que llevaron a esta antigua región española a decidir su separación: El ejemplo de independencia de la corona británica del norte, la ilustración francesa que trajo nuevos ideales, y el fuerte control y carga de impuestos por la corona española y su progresivo debilitamiento.

La independencia trajo consigo un enfrentamiento por el poder entre las ciudades de León y Granada y sus respectivos partidos políticos (los democráticos o liberales en León y los legitimistas o conservadores en Granada). El mayor beneficio fue que dejaron de pagar a la corona española impuesto alguno.

Posteriormente se da la anexión al Primer Imperio mexicano gobernado por Agustín de Iturbide decretada el 5 de enero de 1822. Iturbide fue obligado a renunciar en México, lo cual aprovechó el Congreso de las Provincias para reunirse en Guatemala el 1 de julio de 1823 y declarar la separación de México. En esa misma reunión también se aprobó la abolición de la esclavitud, convirtiendo a las Provincias Unidas del Centro de América en una de las primeras naciones del continente americano en abolir la esclavitud, junto con Chile en 1823, México en 1829 y Argentina en 1853, mucho antes que países como Estados Unidos (1865) y Brasil (1888).

Desde 1823, Nicaragua junto a los otros cuatro países centroamericanos formaron una federación llamada Provincias Unidas de Centroamérica, con un gobierno general residente en Guatemala y otro particular en la capital de cada provincia, siendo su primer presidente Manuel de Arce y vicepresidente Mariano de Beltranena. Los países centroamericanos no estaban de acuerdo con el sistema de gobierno de Arce ya que disolvió el congreso, el cual no lo apoyaba.

Finalmente tras años de conflictos civiles provocados por las diferencias entre los gobiernos federales y provinciales y las luchas de poder en las provincias se da la separación de la federación el 30 de abril de 1838 cuando Nicaragua la abandona, siendo el primer país en hacerlo, seguido ese mismo año por Costa Rica y Honduras.

Nicaragua tuvo una convulsa vida política durante la primera mitad del siglo XIX. Al ser Nicaragua el puente entre los dos océanos que fue utilizado para el desplazamiento de pasajeros de la ruta del tránsito propiedad de Cornelius Vanderbilt, ruta por la que circulaban los aventureros, comerciantes y emigrantes que viajaban desde el Atlántico de Estados Unidos, hasta California en donde, hacia 1848-49 se habían descubierto yacimientos de oro, la convierten en un punto estratégico e importante en Centroamérica.

En 1854, los generales liberales Castellón y Jérez contratan a través de Vanderbilt los servicios de Byron Cole, en calidad de mercenario. Posteriormente Cole le cede el contrato a William Walker. Este, amparado bajo la doctrina Monroe, se proclama presidente de Nicaragua e intenta hacer de la nación centroamericana un nuevo miembro de los Estados Unidos. Los filibusteros fueron derrotados en la Guerra Nacional que contó con la participación de todos los países centroamericanos, y que en lo que respecta a los nicaragüenses tuvo su episodio más glorioso en la batalla de San Jacinto.

Al concluir el conflicto, Nicaragua se hallaba gravemente debilitada económicamente, la ciudad de Granada había sido incendiada casi en su totalidad y se mantenía la rivalidad entre los liberales de León y los conservadores granadinos.

A partir de 1858 se inició, bajo predominio conservador, una etapa de recuperación económica e institucional, que constituye uno de los períodos más sobresalientes de la historia de Nicaragua conocido como "Primera República Conservadora" o los "Treinta años conservadores".

La economía, el desarrollo cultural y social, este último en menor medida debido a la desigualdad de clases, convirtieron al país en el más estable y rico de toda Centroamérica y en una de las mejores economías del continente americano, con un sólido régimen constitucional y una administración proba y austera de las finanzas públicas.

Todo esto provocó una nueva oleada de inmigrantes provenientes de Europa, principalmente de Alemania e Italia, lo que hizo florecer aún más la economía, mientras El Salvador, Honduras y Guatemala se mantenían en conflictos armados y en Costa Rica se daba una época de golpes militares.

Durante esta época se sucedieron en el poder Tomás Martínez Guerrero (1858-1867), Fernando Guzmán Solórzano (1867-1871), Vicente Cuadra y Ruy Lugo (1871-1875), Pedro Joaquín Chamorro y Alfaro (1875-1879), Joaquín Zavala Solís (1879-1883), Adán Cárdenas del Castillo (1883-1887), Evaristo Carazo Aranda (1887-1889) y Roberto Sacasa y Sarria (1889-1893).

Durante el gobierno Chamorro ocurre el Caso Eisenstuck (o Incidente Eisenstuck, en alemán Eisenstuck-Affäre), un conflicto diplomático entre el Imperio alemán y el gobierno nicaragüense, en que el puerto de Corinto fue ocupado por tres corbetas de la Marina Imperial alemana. En 1885, Nicaragua se unió a Costa Rica y El Salvador en una alianza militar para hacer frente a las pretensiones del Presidente de Guatemala Justo Rufino Barrios, apoyadas por el Presidente de Honduras Luis Bográn, de restablecer por la fuerza la unidad política centroamericana; pero las tropas nicaragüenses no tuvieron ocasión de entrar en combate, ya que Barrios murió en la batalla de Chalchuapa, poco después de haber invadido El Salvador.

Nicaragua exporta principalmente café (un 64,9 %) y metales preciosos con un 13,8 %. En total el porcentaje de exportación de estos dos productos era de 78,7 % en 1913. Por tanto, Nicaragua dependía principalmente de la exportación de café.
Los principales compradores de las exportaciones nicaragüenses era Estados Unidos, seguido por Alemania. Estados Unidos aumenta sus importaciones durante los años 1907 a 1918, mientras que Gran Bretaña, Francia y Alemania las disminuyen. Su principal socio comercial era Estados Unidos, ya que contenía una alta concentración de exportaciones (en 1917 llegó a obtener un 85 % de las exportaciones de Nicaragua).

El período de los treinta y cinco años de gobiernos conservadores concluyó con la llamada Revolución Liberal del 11 de julio de 1893, cuando fue derrocado el Presidente Roberto Sacasa y Sarria y ascendieron al poder los liberales encabezados por el Doctor y General José Santos Zelaya López.

Zelaya aglutinó a la naciente burguesía criolla en torno a su persona e implantó un régimen dictatorial que le permitió perpetuarse en el poder hasta 1909, haciendo uso del destierro y la represión en contra de sus adversarios. Esto a la postre dio inicio a una etapa de inestabilidad política. No obstante, en términos económicos, durante su gobierno se continuó con el desarrollo del país sufragado por la amplia solvencia y excedentes económicos existentes, permitiéndole a Zelaya ampliar su influencia en Centroamérica.

En 1907 a Nicaragua le fue impuesta una guerra por los gobiernos de Honduras y El Salvador. El triunfo de las tropas nicaragüenses sobre un ejército combinado de hondureños y salvadoreños en la llamada batalla de Namasigüe y la posterior entrada en Tegucigalpa ocasionaron la rendición del general Manuel Bonilla en la isla de Amapala y la caída de su gobierno.

Durante la presidencia de Zelaya se promulgo una nueva Constitución conocida como "La Libérrima" que declaraba el estado laico (separación entre el Estado y la Iglesia católica), la obligatoriedad de la educación primaria, la secularización de los cementerios y la despenalización del aborto, entre otras medidas consideradas como avanzadas para su época. Otro logro importante fue la fundación de la primera Academia Militar de Nicaragua, fundada el 11 de julio de 1904, que contó entre sus organizadores e instructores a militares provenientes de Alemania y Chile. Entre estos se destacó el coronel Carlos Uebersezig, quien se desempeñó en el cargo de instructor hasta 1909. Otros alemanes fueron los coroneles Carlos von Grafenhvost y Enrique Berew. Entre los chilenos estaban Joaquín Ortiz y Erwin Keife.

Zelaya fue derrocado por la intervención directa del gobierno de los Estados Unidos de América mediante la llamada "Nota Knox". Se inició nuevamente la guerra civil entre los liberales que mantenían el poder y los conservadoras quienes solicitaron la ayuda de los marines estadounidenses que ocuparon Nicaragua y colocaron en la presidencia del país a Adolfo Díaz. Contra está ocupación se destacó el General Benjamín Zeledón muerto el 4 de octubre de 1912 luego de la batalla de La Barranca, Masaya en donde las fuerzas liberales sitiadas fueron derrotadas por los fuerzas conservadoras y estadounidenses.

Durante el principio del siglo XX, el país se caracterizó por la inestabilidad política e intervenciones armadas de Estados Unidos en 1912 y el período entre 1927 a 1933.

Además, durante este tiempo, surgen algunas discrepancias con Colombia por problemas territoriales, ya que con ese país no se había definido claramente los derechos sobre la Costa de Mosquitos a quienes se les vendieron (cedieron) estos territorios. El 24 de marzo de 1928 se firma el tratado Esguerra-Bárcenas, en el cual, Colombia reconoció la propiedad y soberanía de Nicaragua sobre las islas Mangle y la Costa de Mosquitos desde el cabo Gracias a Dios y hasta el río San Juan (como consecuencia de la segregación de Panamá) y Nicaragua reconoció a su vez la soberanía y propiedad de Colombia sobre el Archipiélago de San Andrés, Providencia y Santa Catalina. En 1930 se realizó el Acta de Canje de dicho Tratado.

El 4 de febrero de 1980, la entonces Junta de Gobierno de Reconstrucción Nacional declaró unilateralmente la nulidad del Tratado Esguerra-Bárcenas, demandando ante la CIJ con el resultado de la validación plena del tratado y la reiteración de la soberanía colombiana sobre las islas de San Andrés, Providencia y Santa Catalina, el 13 de diciembre de 2007. Pero no sobre las 200 millas náuticas de zona económica exclusiva de Nicaragua.

Uno de los personajes importantes de la primera mitad del siglo XX fue Augusto Nicolás Calderón Sandino, mejor conocido como Augusto C. Sandino, general de origen campesino, que cuando liberales y conservadores llegan al pacto del Espino Negro continuó la lucha contra la intervención estadounidense. La última entrevista que diera el general Sandino fue el 3 de febrero de 1933 a Adolfo Calero Orozco (1899-1980), periodista de "La Prensa", un día después de suscribir con el presidente Juan Bautista Sacasa los "Convenios de Paz", los cuales implicaron la disolución de su Ejército y, en la práctica, la firma de su sentencia de muerte. El asesinato de Augusto C. Sandino se ordenó a las siete de la noche en la oficina del jefe director de la Guardia Nacional y se ejecutó aproximadamente a las 23:00 en un predio de barrio Larreynaga, entonces periférico de la Vieja Managua, el 21 de febrero de 1934.

Desde 1936 a 1979, Nicaragua vive una era marcada por la sucesión en el poder de distintos dictadores, pertenecientes a la familia Somoza.

Desde su Independencia, hasta la Revolución de 1979 Nicaragua estuvo muy influida por tres poderosas familias: Sacasa, Chamorro y Somoza.

El nuevo auge económico en los años cincuenta y sesenta coexiste con la inestabilidad política. El crecimiento económico de esos años provocó un gran desarrollo de la capital Managua. Sin embargo, el violentísimo terremoto del 23 de diciembre de 1972 provocó la destrucción de la ciudad y la muerte de más de 10 000 personas. Lo que vino después fue la corrupción del gobierno somocista en el manejo de la ayuda internacional.

La dictadura de la familia Somoza, apoyados militarmente por Estados Unidos, gobernaron el país durante varias décadas, hasta el triunfo de la Revolución Popular Sandinista.

Pese a la corta duración que tuvo el conflicto armado, los continuos bombardeos en las ciudades provocaron la muerte de más de 50 000 personas. El pueblo nicaragüense con la vanguardia de «los Muchachos» del FSLN logra derrocar a Somoza el 19 de julio de 1979. El FSLN, apoyado por México, Cuba, la Unión Soviética y los países del Bloque Socialista, realizó cambios sociales, expropiando propiedades de la clase alta del país en general en una clara visión para instaurar el socialismo. Hacia el año 1981, gracias al apoyo de la URSS, el Ejército Popular Sandinista se había convertido en la fuerza militar más poderosa en la historia de Centroamérica.

Sin embargo, la etapa sandinista se tradujo en la continuación del conflicto Este-Oeste entre las dos superpotencias de la Guerra Fría. Se formaron los contras armados y financiados por el Gobierno de Estados Unidos, incluso tras la victoria electoral del sandinismo en 1984. Muchos nicaragüenses emigraron a Estados Unidos, Canadá, México, Guatemala, Honduras, Costa Rica, países occidentales de Europa y Australia durante la guerra civil; escapando de la persecución política, el Servicio Militar Patriótico y el estado económico del país.

En febrero de 1990, se celebraron elecciones generales bajo la supervisión de varios observadores internacionales. Violeta Barrios de Chamorro, candidata antisandinista de la Unión Nacional Opositora, ganó las elecciones. Violeta Barrios de Chamorro inició un programa de reconstrucción nacional que estableció la reforma monetaria, la reducción del ejército y la desmovilización de la contra. Gracias a estas reformas la altísima tasa de inflación disminuyó; el crecimiento económico comenzó a ser positivo, las exportaciones crecieron y el país comenzó a reconstruirse, aunque el desempleo se agudizó por los miles de combatientes que se reintegraron a la vida civil. Se privatizó la Banca, las Minas, el transporte, la salud, la educación. Este modelo de gobierno facilitó un auge de la empresa privada, a costa de la explotación de los obreros y la generación de una gran masa de excluidos que accedían precariamente a la alimentación, vivienda, educación, deportes, salud.

En 1996 se celebraron nuevas elecciones en las que ganó Arnoldo Alemán, candidato del Partido Liberal Constitucionalista. Durante los meses de septiembre y octubre de 1998 trascendieron, a través de distintos medios de comunicación y de la oposición, tanto sandinista como liberal disidente, las presuntas prácticas de nepotismo en las altas instancias del Estado por parte de familiares y allegados al presidente de la República.
Todas las acusaciones pasaron a segundo plano cuando a finales de octubre de 1998 se produjo el paso del Huracán Mitch por el territorio nicaragüense. Solo en Nicaragua murieron casi 4000 personas, 5000 resultaron desaparecidas y más de un millón de personas resultaron damnificadas. A todo ello se le unieron cuantiosos daños materiales y económicos que devastaron aún más la ya de por si maltratada economía nicaragüense.
Posteriormente al desastre, y en parte a consecuencia del mismo, el país tuvo que hacer frente a una grave crisis política y social en 1999. Esto se produjo por la depuración, iniciada por el gobierno de Arnoldo Alemán, de los sectores vinculados al sandinismo en el Ejército de Nicaragua. A ello se unieron las protestas de estudiantes y trabajadores en demanda de sus reivindicaciones.

En las elecciones legislativas y presidenciales celebradas el 4 de noviembre de 2001, la victoria fue para Enrique Bolaños del Partido Liberal Constitucionalista.

En el año 2006 se celebraron nuevas elecciones, las cuales fueron ganadas por el candidato del Frente Sandinista de Liberación Nacional, Daniel Ortega Saavedra.

En noviembre de 2008 se celebraron elecciones municipales. Con observación electoral de más de 150 observadores internacionales, entre ellos los representantes del Protocolo de Tikal compuesta de miembros de América Central y América del Sur, el Protocolo Suramericano de Quito, y el consejo latinoamericano de expertos electorales (CCELA), que arrojaron un balance oficial de 105 alcaldías para los sandinistas, frente a sólo 41 para los dos partidos opositores (ALN y PLC).

En 2017, según el índice de Brecha Global de Género del Foro Económico Mundial, Nicaragua es el país con mayor equidad de género de América Latina.

Nicaragua no contaba con ave nacional por decreto, el presidente Enrique Bolaños Geyer en 2004 dijo que iba a lanzar el decreto que no incluiría al ave "Eumomota superciliosa" (guardabarranco) ya que es el ave nacional de El Salvador por lo que se pondría al "Momotus momota" (barranquero) como ave nacional, pero no se lanzó el decreto. El 15 de junio de 2012 fue declarado de forma oficial ave nacional.

Nicaragua se divide en 15 departamentos y 2 regiones autónomas, los hoy en día sólo tienen propósitos meramente administrativos. No tienen autoridades, ni propias ni delegadas del poder central. Los departamentos se dividen a su vez en municipios regidos por un alcalde y un concejo municipal.

En 1987, se han creado dos "regiones autónomas" a partir del antiguo departamento de Zelaya, las de Atlántico Norte y Atlántico Sur, las cuales son regidas por un gobernador Regional y un Concejo regional. La reforma a la Constitución Política de Nicaragua del 2014 modifica el nombre de las regiones por Costa Caribe en lugar de Costa Atlántica. Estas regiones autónomas están pobladas básicamente por poblaciones indígenas y su gobierno comunitario se rige por las normas propias de estas culturas.

Nicaragua es una república constituida por cuatro poderes: el Ejecutivo, el Legislativo, el Judicial y el Electoral. El poder ejecutivo es ejercido por el presidente, quien es elegido para un período de 5 años mediante sufragio universal. El poder legislativo está radicado en la Asamblea Nacional (unicameral), formada por 92 diputados electos por 5 años. Una Corte Suprema de Justicia integrada por 16 magistrados es la cual se encarga de vigilar el sistema judicial. Las contiendas electorales son responsabilidad del Consejo Supremo Electoral. Administrativamente, Nicaragua está dividida en 153 municipios circunscritos, en 15 departamentos y 2 regiones autónomas.

Los partidos políticos principales son (orden alfabético):

La Asamblea Nacional de Nicaragua es el órgano que ejerce el poder legislativo en Nicaragua. Está integrada por 92 diputados que son electos junto a sus suplentes para un período de cinco años mediante el voto universal, igual, directo, libre y secreto. Del total de diputados 70 son electos de acuerdo a las circunscripciones departamentales y regiones autónomas, mientras que el resto tendrán carácter nacional.

La Constitución de Nicaragua dispone que el presidente y vicepresidente de la República ocuparán los cargos de diputados propietario y suplente, respectivamente, una vez hayan culminado su período constitucional, también harán lo mismo los candidatos a presidente y vicepresidente que hubiesen obtenido el segundo lugar.

La Asamblea Nacional es constituida el 9 de enero del año posterior a la elección. Todos los diputados gozan de la inmunidad parlamentaria en el ejercicio de sus funciones como diputado.
Anteriormente a la Revolución Sandinista, el poder legislativo era llamado congreso y su sede se encontraba en el Palacio Nacional de Nicaragua, actual Palacio de la Cultura.

La República de Nicaragua es un país ubicado en el centro geográfico del istmo centroamericano. Limita al norte con Honduras, al sur con Costa Rica, al oeste con el océano Pacífico y al este con el mar Caribe. Por razones administrativas, Nicaragua se divide en 15 departamentos y 2 regiones autónomas. Estos, a la vez, se dividen en municipios, que actualmente son 153.

En Nicaragua se encuentran desde sabanas, hasta montañas vírgenes con especies autóctonas, y goza de tener uno de los lagos más grandes del mundo, con especies exóticas como el tiburón de agua dulce; mesetas aún despobladas con clima primaveral todo el año en el centro y pacífico del país, incluyendo zonas frías; playas aún vírgenes e impresionantes, donde actualmente se está asentando una oleada de nuevos turistas provenientes principalmente de Honduras y El Salvador, aprovechando además los bajos costos de los terrenos; volcanes activos; islas impresionantes y también poco exploradas aún como Ometepe, Zapatera, las Isletas de Granada o Corn Island, entre otras.

La Zona del Pacífico del país se caracteriza por ser la región volcánica y lacustre de Nicaragua, en ella se extienden la cordillera Centroamericana y la más elevada y ríspida cordillera Volcánica. El primer volcán es el Cosigüina, ubicado en la península homónima, dentro del golfo de Fonseca (muy popular entre turistas y autóctonos por ser en realidad una caldera sumergida de un gran cráter). Le sigue la cadena volcánica de los Marrabios o Maribios, que termina con el Momotombito; un islote en el lago Xolotlán. Hay también otros volcanes, como el Masaya o el Maderas y Concepción, formando estos dos últimos la isla de Ometepe en el lago Cocibolca (también conocido como el lago de Nicaragua). Esta zona goza de la presencia de otro gran lago: el lago de Managua.

Compuesta por los departamentos Rivas, Granada, Carazo, Masaya, Managua, León y Chinandega.

La Zona Central del país da fuente a otro gran río, el río Escondido, que se alimenta de la unión de los ríos Siquia, Mico y Rama. A lo largo de esta región se desplaza la cordillera de Amerrisque o Chontaleña. En el norte de esta, presenta regiones secas como Nueva Segovia y montañosas y húmedas como Jinotega y Matagalpa. Estas zonas sirven de fuente a dos grandes ríos: el río Coco o Segovia y el río Grande de Matagalpa. Nueva Segovia presenta las cordilleras de Dipilto y Jalapa, que sirven de frontera con Honduras, mientras que Jinotega a la cordillera de Isabelia y Matagalpa a la cordillera Dariense.
La Zona Central se divide en los departamentos de Madriz, Nueva Segovia, Boaco, Jinotega , Esteli, Matagalpa y Chontales, también se dice de Río San Juan pero pertenece a la Región Central y la Región del Caribe.

La zona del Caribe del país es una gran planicie cubierta de grandes bosques y enormes ríos corren por sus tierras. Entre los principales ríos de esta región que desembocan en el mar de las Antillas están: el Segovia o Coco, el Wawa, el Kukalaya, el Prinzapolka, el Bambana, el Grande de Matagalpa, el Kurinwás, el Escondido (y sus afluentes Siquia, Mico y Rama), el Punta Gorda y el San Juan. En la parte norte de esta zona se encuentra parte de la cordillera Isabelia y Dariense y hacia el sur un ramal de la del Amerrisque o Chontaleña. Como nota adicional en la zona Caribe se encuentra la selva de Bosawás, la segunda selva más grande del continente y hogar de una rica biodiversidad.

Nicaragua es un país de grandes lagos y abundantes ríos. Se pueden diferenciar tres vertientes, la del Caribe, la del Pacífico y la interna. Los ríos de la vertiente del Pacífico son cortos y en general con sistemas de drenaje estructurados por corrientes efímeras o intermitentes, con un régimen irregular y caudales de estiaje muy reducidos; sin embargo, en el período lluvioso se pueden producir grandes crecidas, con inundaciones severas en las partes bajas de sus cuencas.

Sus principales ríos son: el Negro, Estero Real, El Viejo, Atoya, El Tesorero, El Releajo, Posoltega, Telica, Chiquito, Izapa, Tamarindo, Soledad, Masachapa, Amalia, Las Lajas, Ochomogo, Grande y Brito. La vertiente del Caribe acoge a los ríos más largos y caudalosos, muchos de ellos con posibilidad de navegación. Los más importantes son el río Coco, que hace frontera con Honduras, el río San Juan, que hace frontera con Costa Rica, Tuma, Siquia e Indio.

Nicaragua se localiza en el centro del continente americano, esta privilegiada localización provoca que el país albergue una gran biodiversidad. En el país se localizan la mayoría de especies del Neártico y de la Región Neotropical, con la excepción de las especies de altas latitudes.

Este conjunto de factores junto con el clima y las ligeras variaciones altitudinales permiten que el país de cobijo a 248 especies de y , 183 especies de mamíferos, 705 especies de aves, 640 especies de peces y unas 5796 especies de plantas. Todas estas especies se distribuyen en los diferentes biomas del país: selvas umbrófilas, selvas tropófilas, bosques de coníferas, sabanas y matorrales.

El ave nacional de Nicaragua es el Guardabarranco. La región de las grandes selvas se localiza en la costa oriental del país. Se da la selva lluviosa en el Río San Juan y en las regiones autónomas RAAN y RAAS. Este bioma agrupa a la mayor biodiversidad del país y se encuentra protegida en gran parte por la Reserva Biológica Indio Maíz en el sur y por la Reserva de Bosawás en el noreste de Jinotega. La reserva de Bosawás tiene una gran biodiversidad representada por el jaguar, el puma, el danto, la guacamaya y el águila harpía; además forma un gran corredor con los bosques del sur de Honduras que representan unas 2,4 millones de hectáreas, consideradas los pulmones de América Central y la segunda selva umbrófila en tamaño de las Américas (Para más información ver Áreas protegidas de Nicaragua).

En general la fauna que compone a las selvas lluviosas del país son el jaguar, el danto, diversos tipos de monos, la guacamaya, el quetzal, el águila harpía, las serpientes y los cocodrilos.

La selva tropófila se da en la zona del Pacífico y en algunos puntos del norte y el Caribe del país. En estos bosques se da una estación seca durante el invierno, sin embargo llueve mucho durante la estación húmeda. Estos bosques albergan pumas, venados, monos y diversas especies de reptiles.

El bosque tropical de coníferas se da en la RAAN. Se caracteriza por la presencia de diversos árboles típicos del Neártico, como el pino. También se dan algunas especies de mamíferos como los venados y los coyotes.

Las sabanas se dan en todo el país y su vegetación varía según la región. Así en la RAAN hay sabanas cubiertas de pinos y en Rivas hay sabanas con especies propias de las selvas. La fauna de las sabanas se compone de venados, coyotes y pecarís; sin embargo, la mayoría de sabanas del país han sido convertidas en terrenos de cultivo y pastoreo.

Nicaragua al ubicarse en la Zona Intertropical posee un clima tropical con variaciones dependiendo del relieve y la altitud; Además incluye los vientos alisios del Océano Pacífico y el Mar Caribe. El clima de la costa Pacífica es cálido durante todo el año y muy árido con un periodo estival muy seco y una estación de lluvias y alta humedad desde a mediados de mayo hasta principio de noviembre pero, con cortos periodos de calor y sequedad entre junio y julio.

La costa Caribe presenta un clima muy húmedo durante todo el año con fuertes vientos alisios entre diciembre y febrero. La lluvia es muy intensa y a veces se generan inundaciones, este clima se clasifica entre tropical marítimo a tropical muy húmedo.

La zona del lago presenta un clima Tropical con estación seca entre noviembre y abril y lluvias moderadas entre mayo a octubre. La temperatura suele ser elevada y la media ronda todo el año entre los 33 grados celsius.

La zona montañosa presenta un clima Templado.

Durante la gran depresión de 1929, Nicaragua creció más rápidamente que el resto de países. También durante los años 1932 a 1935, crece más que el resto. Esta es la época que Nicaragua negocia, hasta firmar la independencia.

Entre los años 1960 y 1980, Nicaragua crece más despacio que el resto de países. A partir de estos años, todos los demás países crecen, mientras que Nicaragua decrece.

Aunque en relación al PIB la inversión es alta, en términos por habitante Nicaragua ha tenido desde 1994 la menor inversión de América Latina.
Es el país centroamericano con menor productividad, y desde finales de los años setenta la brecha de productividad con el resto de la región ha aumentado.

Aun logrando en forma sostenida tasas de crecimiento anual del orden del 6,7 %, el PIB por habitante en el 2031 sería menor al promedio actual del resto de Centroamérica.

Desde el año 1951 y durante casi 26 años la economía nicaragüense experimentó tasas de crecimiento sostenidas por encima del 6 % en términos reales, con estabilidad de precios y sin perder la paridad cambiaria del córdoba con relación al dólar, y sin caer en los excesos del modelo de sustitución de importaciones y de crecimiento hacia adentro, tan popular en la mayoría de los países latinoamericanos. A pesar de tasas de crecimiento demográfico del 2,9 % durante los años cincuenta, 2,5 % durante los sesenta, y 3,5 % en los setenta, entre 1950 y 1977 el PIB per cápita de los nicaragüenses experimentó un crecimiento promedio del 3,1 %, igual al de Costa Rica, y muy por encima del de países como El Salvador (2,1 %), Guatemala (1,9 %) y Honduras (1,1 %). Más aún, según cifras de la CEPAL y el Banco Mundial, el porcentaje de la población rural sobre la línea de la pobreza saltó del 9 % en 1960, a 30 % en 1977, mientras el porcentaje de la población urbana que dio ese mismo salto entre 1960 y 1977, fue del 36 % al 60 %.

Analizando el PIB per cápita a principios del siglo XX América Latina experimentó un importante crecimiento económico gracias al impulso que le dieron las exportaciones, aunque tuvo gran inestabilidad justo en el periodo antes de la Primera Guerra Mundial por la crisis que asolo a todo el mundo. Esta exportación se basó sobre todo en la explotación de recursos naturales.

En Nicaragua los recursos naturales son principalmente agrícolas, ya que los depósitos de material volcánico han enriquecido muchísimo su suelo, haciendo que el país sea extremadamente fértil. Por tanto es un país en el que existen gran variedad de cultivos. De esta manera, los principales productos de exportación en esta década fueron el café y los metales preciosos, concentrando casi el 80 % de todas las exportaciones.

Los mayores socios comerciales eran Estados Unidos, Francia, Alemania y Reino Unido, concentrando casi el 100 % de todas las exportaciones. Por tanto, una característica importante es el predominio de Europa occidental, sobre todo de Reino Unido y Francia, hasta la Primera Guerra Mundial, ya que este equilibrio fue desplazándose gradualmente hacia Estados Unidos.
Por tanto la conclusión que podemos sacar, es que Nicaragua era muy sensible a la coyuntura económica mundial ya que resumiendo exportaba dos bienes a cuatro países, tenía una situación muy peligrosa.

El periodo de después de la Segunda Guerra Mundial fue la semilla de la nueva época, en la que se dio inicio a la industrialización por sustitución de importaciones.

Para empezar y observar los efectos de este proceso debería de observarse la disminución del peso de las exportaciones en el PIB del país. Pero esto no fue así, al contrario cada vez el porcentaje de las exportaciones sobre el PIB es mayor.
Los efectos de esta política también podrían observarse analizando el peso de las importaciones de productos intermedios, de capital o de consumo. Podemos ver como durante estos años la importación de bienes intermedios ha sido mucho mayor que los demás, pero ha sido bastante inestable, con periodos que ha disminuido y periodos, sobre todo los últimos en los que ha aumentado, llegando a ocupar hasta un 60 % del total. Los bienes de capital han sido los que menor porcentaje han tenido, con gran disminución en la última época, suponiendo solo un 10 %. Los bienes de consumo han sido el intermedio de estos dos, siendo más cercana a los bienes de capital.

Con la nueva política de impulso hacia la industrialización uno de los objetivos que se marcaban era la de sustituir la importación de productos terminados para importar productos intermedios y acabarlos en el país. Observando la evolución de estos tipos de productos podemos ver un progreso contrario: en los primeros 10 años las importaciones de productos intermedios disminuyo mientras aumentaron las importaciones de productos de consumo y de capital, pero en la segunda década analizada la entrada de productos intermedios aumento junto con los bienes de consumo, mientras disminuyeron los bienes de capital.

Por tanto podemos deducir que en la primera década no tuvo gran repercusión la sustitución de importaciones ya que se introducción gran cantidad de productos acabados. Después de los años setenta hubo mayor porcentaje de productos intermedios, lo cual nos indica que se producían más productos terminados dentro. Aunque el aumento de la entrada de bienes de consumo indica que no se producía lo suficiente para satisfacer la demanda de los nicaragüenses.

Los ingresos siempre fueron menores que los gastos, exceptuando un par de años, siendo cada vez mayor, llegando a porcentajes tan sorprendentes como un 7 % del PIB.
Esto se debió al gran aumento del gasto público por la ampliación de responsabilidades que asumió el Estado en esta nueva política, que no pudo compensarse con un aumento similar de los ingresos. Como el desarrollo de infraestructuras, creación de bancos, mayor papel en la provisión de la educación, salud y vivienda.

Al final del siglo XX, América Latina estuvo marcada por la gran deuda externa que tuvo que afrontar. Aunque siempre ha estado endeudada con los países más ricos, la gran crisis de pagos comenzó hacia los años setenta, cuando aumentaron los precios del petróleo y empezó a llegar a los bancos de los países ricos mucho dinero, enriqueciéndose de tal manera que concedieron préstamos sin asegurarse que serían devueltos.

Es en los años ochenta cuando comienza la verdadera crisis financiera de Nicaragua. Este país, al igual que sus vecinos latinoamericanos, experimenta una caída dramática de los precios del mercado mundial para sus principales exportaciones. Ello trajo como consecuencia, junto con unas altas tasas de interés, un rápido deterioro económico. Por otro lado, dada la situación de guerra en la que se encontraba el país, la situación se volvió extrema, ya que era necesario obtener recursos económicos para satisfacer las necesidades básicas de la población que se financiaron a través del creciente gasto del estado, el subsidio del precio de los alimentos y un intercambio sobrevalorado de la moneda. Esto dio lugar a una hiperinflación incontrolada, un déficit crónico de la balanza de pagos y un aumento considerable de la deuda externa. Vemos que ya para 1980 Nicaragua tenía una deuda externa que le suponía el total de su PIB y en diez años aumentó hasta el 1200 % del PIB, siendo esta imposible de pagar.

Después de que los Estados Unidos impusieran un embargo comercial en 1985, la tasa de inflación de Nicaragua se levantó dramáticamente. El índice de 1985 según publicaciones anuales del 220 %, triplicó el año siguiente y se elevó súbitamente más al 13 000 % en 1988, la tarifa más alta para cualquier país en el hemisferio occidental en ese año. Desde el final de la guerra hace casi dos décadas, más de 350 empresas del Estado fueron privatizadas, reduciendo la inflación a partir de 13 500 % a 9,6 %, y cortando la deuda exterior por la mitad.

El córdoba fue introducido el 20 de marzo de 1912, reemplazando de esta forma al peso nicaragüense. Promulgada la Ley de Conversión Monetaria, los Billetes del Tesoro fueron cambiados gradualmente por la nueva moneda que tenía un tipo de cambio de paridad de 5 córdobas = 1 libra esterlina. El 13 de noviembre de 1931, el córdoba empezó a cotizarse a un tipo de paridad de 1,10 córdobas = 1 dólar estadounidense. Luego de sucesivas devaluaciones, el córdoba empezó a cotizarse a un tipo de paridad estable de 7 córdobas = 1 dólar estadounidense entre 1946 y abril de 1979.

El córdoba fue llamado así en conmemoración del segundo apellido del conquistador español, natural de Córdoba, Capitán Francisco Hernández de Córdoba, fundador de las ciudades de Santiago de Granada y de León Santiago de los Caballeros. Santiago de Managua es la capital de Nicaragua.

En 1987, el gobierno introdujo el nuevo córdoba (o formalmente llamado «córdoba revaluado») con valor de 1000 antiguos córdobas. Nicaragua abre los años noventa bajo la administración presidencial de Violeta Barrios de Chamorro, y el Plan del Gobierno de Salvación Nacional dentro de la estabilización y ajuste estructural, incluye la emisión del «córdoba oro» (formalmente llamado «córdoba») que a partir del 13 de agosto de 1990, pasa a convertirse en un nuevo medio circulante, expresado en la misma moneda Córdoba, con paridad al dólar estadounidense. El primer nuevo facial añadido al actual cono monetario metálico, comprendido entre los 5 centavos y los 5 córdobas, fue el de 10 córdobas, la emisión de esta moneda se produjo por primera vez el 16 de junio de 2008.

También existen monedas que circulan a nivel nacional, las de 1 y 5 córdobas (la moneda de 10 córdobas salió de circulación debido a que estas se deterioraban muy fácilmente); las otras monedas de 5, 10 y 25 centavos sólo son aceptadas en los bancos.

Asimismo circula el dólar estadounidense por todo el país.



Además, a comienzos del año 2009, el gobierno ruso se interesó por crear la planta procesadora de chocolate más grande de Europa Oriental y, según los encargados del proyecto, el cacao será producido en Nicaragua; para lograr el objetivo el país deberá producir más de 50 000 toneladas anuales de cacao, esto lo convertirá en el mayor productor de cacao en América Central y el noveno mayor a nivel mundial.





El turismo en Nicaragua está creciendo, ya que actualmente tiene la segunda industria más grande de la nación, durante los 9 años pasados el turismo ha crecido el 90 % por toda la nación en un índice del 10 % anualmente. Se espera que Nicaragua que ha visto crecimiento positivo en este 2009, crezca aún más en el año 2015 gracias a que el gobierno actual está impulsando el rubro de una manera ordenada y a gran escala. Solo en el 2009 el sector turístico en Nicaragua creció un 9,8 % en relación a años anteriores.
Cada año cerca de 200 000 estadounidenses visitan Nicaragua y en el 2010 el turismo creció un 9 % llegando así a la cifra récord de 1 millón de turistas, sobre todo gente del negocio, turistas, y parientes que visitan a sus familias. La mayoría de los turistas que visitan Nicaragua son de los Estados Unidos, Centroamérica, Sudamérica, y Europa. Según el ministerio del turismo de Nicaragua (INTUR), la ciudad colonial de Granada es el punto preferido para los turistas. También, las ciudades de Chichigalpa, León, Masaya, Rivas, las playas de San Juan del Sur, la isla de Ometepe, el volcán Mombacho, las Islas del Maíz (Corn Island y Little Corn Island), y otras, son atracciones turísticas principales. Además, el ecoturismo y el practicar surf atraen a muchos turistas a Nicaragua.

Las atracciones principales en Nicaragua para los turistas son las playas, rutas escénicas, la arquitectura de ciudades tales como Granada, León y más recientemente el eco y agro turismo en la zona norte donde se encuentra La Ruta del Café de Matagalpa - Jinotega - Esteli - Madriz - Nueva Segovia.

La actual población nicaragüense es multiétnica, y se divide en todos los grupos raciales así como todas sus posibles mezclas, principalmente con una gran mayoría de mestizos a lo largo de todo el territorio. De este modo, se han realizado varios estudios genéticos para analizar la estructura mitocondrial de la población del país, en los que los resultados demuestran una formación étnica trihíbrida mestiza, con algunas variaciones regionales, por ejemplo: según el estudio «Genomic Components in America's demography», publicado en 2017 en Japón, un nicaragüense promedio presenta una composición de entre el 58% y el 62% de genes europeos, casi que exclusivamente españoles; 28% de herencia indígena de diversas etnias mesoamericanas y un 14% proveniente de África. Otro estudio publicado en la revista "Genetics and Molecular Biology", realizado en diferentes países de America Latina, mostró también una composición triple, en la que los nicaraguenses en general tienen un 69% de herencia europea, seguida en segundo lugar por la africana en un 20% y en último lugar la amerindia en un 11%. Finalmente, tomando en cuenta el cromosoma Y junto con diversos Y-SNPs, permiten clasificar la población nicaragüense dentro del acervo genético euroasiático, en particular, el grupo aportado principalmente por emigrantes españoles resultó ser el mayoritario (43,63%) mientras que los grupos nativo americano y africano también se observaron ambos con una frecuencia del 15,33%.

El análisis del ADN mitocondrial el cual es importante en este estudio dado que este no forma parte de la información genética del núcleo y que es aportado exclusivamente por la madre a todos los hijos (varones y mujeres) y no por el padre, muestra por este método que el componente nativo americano del ADN de la actual población mestiza de Nicaragua alcanza un 88,95%. Lo anterior sugiere que la base de la población nicaragüense se ha compuesto de una predominante participación paterna caucásica, principalmente española, con mujeres en su mayoría amerindias. Similares hallazgos y valores de composición en el mestizaje se han encontrado en diversos estudios realizados en poblaciones latinoamericanos. Cabe señalar que en el país también existen poblaciones más o menos puras que no se incluyeron en este estudio, como son los de origen caucásico que predominan en el norte del país, por su parte la población mestiza que es la inmensa mayoría predomina en el centro, sur y regiones del norte del país, y el grupo de afrodescendientes y nativos americanos que habitan en las costas que son muy poco habitadas.

El primer censo de Nicaragua se realizó en 1778, cuando su población apenas sobrepasaba los 100 000 habitantes. El último censo realizado en 1995 arrojó una población de casi cinco millones de habitantes.

Según datos oficiales del Instituto Nicaragüense de Estadísticas y Censos en el censo de julio de 1906 se contabilizaron finalmente 501 849 personas y para mayo de 1950 eran 1 049 611. El último censo realizado en el año 2005 arroja un total de 5 142 098 habitantes, muy por debajo de las estimaciones y a expensas de la reducción de la tasa de fecundidad, para una densidad de 42,7 habitantes por kilómetro cuadrado. La mayoría de la población nicaragüense (69 %) es principalmente de origen mestizo (mezcla de españoles, amerindios o africanos y en menor grado asiáticos). Corresponde el 5 % a grupos étnicos indígenas siendo los más numeroso el Miskito, Mestizo de la Costa Caribe, Chorotega Nahua-Mangue y Creol. Se estiman que la población de blancos descendientes europeos es cerca al 17 % (la principal fuente de inmigración fueron españoles peninsulares, siguiendo la inmigración alemana y en menor proporción italiana, francesa, asiática, inglesa y de otros países de Europa Oriental). A mediados y finales del siglo XIX e inicios del siglo XX se incentivó la inmigración principalmente alemanes y franceses, otorgándoles terrenos para cultivos principalmente en las zonas de Estelí, Jinotega, Matagalpa, Managua-El Crucero, Carazo, Nueva Segovia y Madriz. Actualmente en departamentos de la zona Norte de Nicaragua (Estelí, Matagalpa, Jinotega) predominan descendientes de italianos, alemanes y en menor proporción de ingleses, alcanzando tasas de hasta 93 % de blancos. La población nicaragüense de origen africano (zambos, mulatos y afrodescendientes) corresponde al 9 % de la población, y habitan principalmente en las regiones caribeñas del país (donde la población es muy escasa y reducida). La mayoría de la población nicaragüense reside en la región occidental del país en los departamentos de Managua, Granada y León. Los extranjeros residentes en el país al momento de dicho censo sumaban el 0,6 % del total de la población nacional

La mayoría de la población afronicaragüense reside en la costa del Caribe del país, que también es la región más vasta y despoblada y son en su mayoría descendientes de antiguos esclavos provenientes finalmente de Jamaica cuando la región era un protectorado británico y conservan una rica cultura autóctona. De antaño los costeños han refutado la incapacidad que tiene el resto de los nicaragüenses (del Pacífico) para entender su identidad cultural, y aunque desde 1987 el Caribe cuenta con un sistema territorial diferente (RAAN y RAAS) muchos sectores consideran que siguen olvidados por el estado central y que no se ha dado todavía una reincorporación jurídica, política, económica, religiosa y cultural de la Costa Caribe al resto de Nicaragua.

Hay comunidades de sirios, armenios, palestinos, judía, y libaneses en Nicaragua con una población total de cerca de 30 000. Hay también una comunidad asiática de personas provenientes de Corea del Sur, de Japón, de Taiwán y de China. Estiman a la población china nicaragüense de aproximadamente 12 000. Los chinos llegaron en los fines del siglo XIX, el segundo censo de la nación (en 1920) reveló a 400 personas de nacionalidad china. Estas minorías hablan español mientras que mantienen sus idiomas ancestrales también.

La población del país crece a un ritmo de un 1,8 % anual (uno de los más altos del Hemisferio). Este alto crecimiento se debe a una alta natalidad situada en un 24/1000 y a una mortalidad baja de 4,5/1000 que dejarían un crecimiento natural de 2,03 % anual; sin embargo la tasa neta de migración es negativamente alta, de tal forma que el crecimiento poblacional desciende a un 1,8 %.

Debido a los altos índices de pobreza y desempleo, muchos nicaragüenses han decidido emigrar a países como México, Canadá, Guatemala, Panamá y El Salvador, no obstante los principales países de destino para los nicaragüenses son Estados Unidos, Costa Rica y España. La emigración de nicaragüenses al exterior ha aumentado, a tal grado, que se estima que uno de cada seis nicaragüenses vive en el exterior. Las cifras más aceptadas indican que hay casi un millón de nicaragüenses en el exterior.

De conformidad con el Artículo 11 de la Constitución de la República de Nicaragua, el idioma oficial del país es el español. Una de las características más sobresalientes del castellano nicaragüense es la aspiración de la /s/ posvocálica como en muchas regiones de España e Hispanoamérica.

También en Nicaragua, como en Argentina, Bolivia, Colombia, Costa Rica, Chiapas de Mexico, El Salvador, Guatemala, Honduras, Paraguay, Uruguay, Venezuela se utiliza el voseo; y así como en la región rioplatense, el uso del pronombre "voseo" es parte de la norma culta y el uso del tuteo es casi inexistente.

Debido a la colonización británica de la Costa Atlántica, el inglés es común al lado de lenguas naturales como miskito, rama y sumo y otras autóctonas sumando una veintena sin catalogar. También, debido a la cercanía de Estados Unidos y su influencia en el estilo de vida "nica", es muy común encontrar personas bilingües en las principales ciudades como Managua, León, Granada, San Juan del Sur y Estelí, aunque también como parte de la apertura de la industria recreativa en estos sitios.

La denominación religiosa más seguida en Nicaragua es el catolicismo con 4 997 431 adeptos, lo que representa el 81 % de la población. Un segundo grupo religioso es el protestantismo que abarca un 8 % de la población y se encuentra dividido en varios grupos. Por su parte el 7 % de los nicaragüenses declara no seguir ninguna religión y el 4 % dicen seguir otra religión.

La religión es una parte importante de la cultura de Nicaragua y se reconoce en la Constitución. La libertad religiosa, que ha sido garantizada desde 1939, y la tolerancia religiosa las promueve tanto el gobierno nicaragüense como la Constitución. Nicaragua no tiene religión oficial. Las declaraciones de la Iglesia católica sobre temas nacionales se siguen de cerca. Se recurre a su autoridad en ocasiones estatales importantes. También se recurre a su mediación entre partes contendientes en momentos de crisis política.

La denominación más grande y tradicionalmente la religión de la mayoría es católica. El número de católicos practicantes ha disminuido paulatinamente desde los años sesenta, donde el 96 % de la población se declaraba católica. Mientras que los miembros evangélicos protestantes y la población que se declara sin religión ha crecido rápidamente en número desde los años noventa. También hay comunidades anglicanas y moravas en la costa del Caribe.
El catolicismo llegó a Nicaragua en el siglo XVI con la conquista española y se mantuvo hasta 1939. El Protestantismo y otras confesiones cristianas llegaron a Nicaragua durante el siglo XIX, pero solo ganó muchos seguidores en la Costa Caribe durante el siglo XX.

Debido a la presencia inglesa en la Costa de los Mosquitos o Mosquitia (Costa Caribe), la mayoría de los costeños son cristianos protestantes en su mayoría anglicanos. Ellos pertenecen a seis diferentes pueblos indígenas y comunidades étnicas: * mestizos (idioma español),

La religiosidad popular gira en torno a los santos, que son percibidos como intercesores (pero no mediadores) entre los seres humanos y Dios. La mayoría de las localidades, desde la capital Managua hasta las pequeñas comunidades rurales, rinden honor a «santos patronos», conforme al Calendario romano de la Iglesia católica, con fiestas religiosas solemnes y populares. En muchas comunidades, una rica tradición ha crecido en torno a las celebraciones de los santos patronos, sin duda una de las más importantes expresiones de fe del país y de más relevancia folklórica es la celebración del Tope de los Santos. Este constituye en el encuentro de las imágenes de Santiago, San Marcos y San Sebastián que se realiza tres veces al año en el departamento de Carazo el primer tope se realiza en enero con motivo de las fiestas de san Sebastián santo patrono de la ciudad de Diriamba, en ellas participan bailes tradicionales de la zona tales como El Gueguense, El Toro Huaco, el Viejo y la Vieja, el Gigante, entre otros. El segundo tope se realiza en el mes de abril con motivo de las fiestas de san Marcos Evangelista en la ciudad homonima San Marcos (Nicaragua), en ellas participan bailes típicos como la Vaquita de San Marcos y se reparten comidas y bebidas típicas como el picadillo y la chicha de maíz. El tercer tope se realiza en el mes de julio con motivo de las fiestas de Santiago Apóstol en la ciudad de Jinotepe, en estas fiestas participan bailes típicos de la zona como los Diablitos. También resaltan las festividades de Santo Domingo de Guzmán en Managua del 1 al 10 de agosto, muestra representativa del sincretismo religioso.

Los puntos culminantes del calendario religioso para las masas son la Semana Santa en León;La Purísima durante el 7 y 8 de diciembre, cuando se erigen elaborados altares dedicados a la Virgen María en los hogares, iglesias, centro comerciales y plazas ; y la Navidad y Año Nuevo.

"La gritería" es una fiesta religiosa popular nicaragüense en honor a la Purísima e Inmaculada Concepción de María. Esta fiesta religiosa se celebra en todos los pueblos y ciudades de Nicaragua (y en los lugares donde la colonia nicaragüense es importante como en Estados Unidos (particularmente en la ciudad de Miami), Costa Rica y El Salvador teniendo especial relevancia en El Viejo y León de donde es originaria.

Se celebra la noche del 7 de diciembre, víspera de la fiesta católica de la Inmaculada Concepción de María, devotos recorren las calles y visitan diferentes altares en honor a la Virgen María, en templos y casas particulares, realizando rezos, cánticos y quemando pólvora (cohetes y juegos pirotécnicos). A la vez que se grita ""¿Quién causa tanta alegría?"" y se responde ""La Concepción de María"". Los habitantes de las casas reciben a los devotos con un "brindis", llamado popularmente "gorra".

La tasa de alfabetización es de un 78,0 %, por tanto el analfabetismo de la población está entre uno de las más bajos del continente y del mundo. El Ministerio de Educación desarrolla programas para reducir el nivel de analfabetismo y elevar el nivel de educación de los que tienen un nivel básico.

Nicaragua es producto de la herencia de las culturas nahoas, chorotegas, sutiabas, lenmichies, chibchas, afrocaribeñas y europeas (principalmente hispana), que aportaron el cultivo del arte, música, baile, alfarería, cestería y la gastronomía. La cultura nicaragüense refleja la mezcla predominante de la herencia indígena americana y española. Poco se conservó definitivamente de esta última, aunque se encuentran vestigios de la misma.

Nicaragua es famosa por su gran número de fiestas y tradiciones. Gran parte de las celebraciones giran en torno a la religión católica, implantada durante la colonia española.

El colorido, la comida y bebida, la pólvora, la música, los bailes típicos, los desfiles hípicos, las corridas de toros, los promesantes y los actos religiosos, forman parte de estas fiestas que pueden extenderse por varios días, constituyen la esencia de la cultura popular nicaragüense. La fiesta religiosa más popular de todo el país es La Purísima o La gritería, dedicada a la Inmaculada Concepción de la Virgen María. Consiste en una celebración donde se crean altares con imágenes religiosas de la Virgen en los cuales la gente llega a cantar para obtener algo de lo se obsequian como: dulces típicos (gofio, enchiladas, leche burra, cajeta de leche, cajeta de coco) y frutas como la caña de azúcar y limones dulces. La fiesta de santo Domingo de Guzmán que empieza el 1 de agosto con la Bajada de Minguito y finaliza con su retorno el 10 de agosto, es otro acto religioso masivo que atrae incluso a nicaragüenses residentes en otro países.

Las Fiestas de san Sebastián en Diriamba (19, 20, 26, 27 de enero), las fiestas de Santiago Apóstol en Jinotepe y las fiestas de San Marcos Evangelista en San Marcos (Nicaragua), son una de las más representativas del país pues en esta se da el Tope de los Santos, el encuentro de las imágenes de Santiago, san Marcos y san Sebastián, estas fiestas patronales son una de las más coloridas pues el pueblo, demuestra su idiosincrasia con el colorido de los bailes y trajes típicos de la región. Podrá apreciar el baile de Los Diablitos, El Guegüense, El Toro Guaco, El Gigante, La Vaquita, el Baile de las Inditas y muchos más. También se celebra a San Sebastián en la ciudad de Acoyapa, departamento de Chontales.

Las fiestas patronales de san Sebastián de Diriamba están por encima de todas las fiestas patronales en Nicaragua En ellas los nicaragüenses expresan sus más auténticas conexiones con sus raíces indígenas y españolas. Muchos de los bailes, canciones y costumbres son verdaderas tradiciones que se remontan a cientos de años cuando los primeros españoles arribaron a Nicaragua. Las fiestas no son un acto de nostalgia, pero si la integración de rituales pre-colombinos con el catolicismo y su historia es tan fascinante como sus colores, costumbres y música. Un día antes de su fiesta, el día 19 de enero, se celebra una misa y luego la imagen de San Sebastián sale de su basílica para dirigirse al poblado de Dolores, que está ubicado entre Jinotepe y Diriamba. Ahí se encuentra con sus amigos, san Marcos Evangelista (patrono de la ciudad del mismo nombre) y Santiago apóstol (patrono de Jinotepe). Este encuentro es conocido como El Tope de los Santos.

Las fiestas patronales en el municipio de San Marcos (Nicaragua) se celebran el 24 y 25 de abril en homenaje al patrono San Marcos evangelista, al cual se debe el nombre de la ciudad. Su imagen fue encontrada en las pilas de Sapasmapa, donde se iba a traer el agua. En estas fiestas locales se acostumbran los bailes folklóricos como: El Gueguense, El Toro Huaco, Las Inditas y La vaquita. El día 24, la víspera de la fiesta del santo, se realiza el famoso “Tope de los santos” en donde san marcos se reúne con San Sebastián patrono de Diriamba, Santiago patrono de Jinotepe y de reciente añadidura con la Virgen de Montserrat, patrona de La Concepción (Masaya) este se da por motivo de añejos enfrentamientos entre pobladores de san marcos y la concepción.

La demanda de Santiago en Jinotepe es una de las más significativas pues en esta el pueblo hace la peregrinación más larga del país, esta inicia el 29 de junio y concluye el 12 de julio, esta es conocida como la demanda mayor, esto porque hay más peregrinaciones a diferentes sitios. El 24 de julio se realiza el Tope de los Santos con las imágenes de san Sebastián (patrono de Diriamba) y san Marcos (patrono de la ciudad del mismo nombre).

Santiago Apóstol, San Sebastián Mártir y San Marcos Evangelista son por excelencia los patronos del departamento de Carazo.

Cada domingo en Nicaragua hay un desfile en las diferentes ciudades del país. Diriamba ostenta el título de ser la cuna de las Hípicas de Nicaragua, la cuna del fútbol nacional y la cuna de la comedia danzante del güegüense o macho ratón (declarado Patrimonio Intangible de la Humanidad).

Las fiestas patronales constituyen la cara y el corazón de Nicaragua, pues en estas se ve reflejado la idiosincrasia del pueblo, el fervor y el amor a su patria.
La música vernácula y autóctona nicaragüense es una de las más ricas de la región centroamericana, razón por la cual se afirma que «si México es la guitarra de América, Nicaragua es una de sus cuerdas». Pueden señalarse a destacados autores y recoliadores de la misma como Camilo Zapata, Erwin Krüger, Los Bisturices Armónicos, Los Soñadores de Saraguasca, Carlos Mejía Godoy y su hermano Luis Enrique Mejía Godoy, Los de Palacagüina, Otto de la Rocha, entre otros.

La música nicaragüense (son nica, polca y mazurca segoviana, el jamaquello y la música vernácula en general) muestran gran influencia española, alemana y francesa.

El violín de talalate es una instrumento musical derivado del violín clásico y a la vez es único de Nicaragua por sus componentes y sonido, usado por ello para sonar la música vernácula, principalmente polcas y mazurcas, lo que lo hacen un verdadero símbolo patrio como instrumento musical nacional autóctono.

Existen también otros ritmos vinculados con la conquista española, como las melodías del "Toro guaco" y "El güegüense" o "Macho ratón" (obra maestra del Patrimonio Oral e Inmaterial de la Humanidad).

La marimba, de origen africano, es un instrumento musical común a todos los países de Centroamérica y México. Es muy utilizada en Jinotepe, Masaya y en los llamados "Pueblos Blancos" (Catarina, Diriá, Diriomo, Niquinohomo) y en su variante nica, conocida como marimba de arco, que es uno de los instrumentos más populares del folclore de las regiones pacífico y central del país. En muchas ocasiones se toca acompañada de guitarras y maracas.

En cuanto a la región de la Costa Caribe, esta se caracteriza por una música propia de tipo afro caribeña, denominada Palo de Mayo, que con un ritmo bien intenso rinde homenaje a la fertilidad de la mujer y de la naturaleza como garante de la continuidad de la vida.

En los últimos años se ha desarrollado también la música popular con exponentes en diversos géneros, quienes han alcanzado popularidad internacional:

El mayor representante de la poesía nacional es Rubén Darío, quien aportó grandes innovaciones en la métrica y el estilo poético, y fue llamado el “padre del modernismo” y ”el príncipe de las letras castellanas".

Otros poetas y escritores con reconocimiento mundial son

En la pintura han destacado artistas como

En la cinematografía se destacan los cineastas

La educación primaria brinda atención básica a los niños de seis o siete años a los doce años de edad y a los que se encuentran en situación de extraedad hasta los 15 años. Comprende 6 grados escolares divididos en dos ciclos: educación fundamental (primeros cuatro años) y segundo ciclo (5.º y 6.º grado).La educación primaria es obligatoria y gratuita.

La educación secundaria brinda atención educativa a jóvenes y adultos preparándolos para continuar sus estudios a nivel superior o participar eficientemente en la vida del trabajo. Comprende dos niveles: el ciclo básico (3 años de duración, diploma de curso
básico) y el ciclo diversificado (dos años, bachillerato en humanidades o ciencias). La educación técnica secundaria ofrece un programa de tres años de duración a los jóvenes de 15 a 18 años para el título de técnico medio así como para los estudios de formación docente.

La educación superior comprende las (públicas y privadas), los centros de educación técnica superior (institutos politécnicos y tecnológicos) y los centros de investigación y de capacitación. La educación técnica superior ofrece programas de 2 a 3 años de duración para el título de técnico superior. El título de licenciado requiere normalmente 4 a 5 años de estudios (6 años en el caso de medicina). Los programas de maestría requieren 2 años adicionales de estudios después de la licenciatura.

En la Actualidad existen muchos centros de educación superior en Nicaragua, en su mayoría privados, pero existen universidades públicas que reciben el 6% constitucional el cual es disfrutado por el estudiantino que acceda a estas universidades mediante exámenes de admisión los cuales comprenden 2 pruebas (Lengua y Literatura y Matemática Básica) además de una prueba psicología de nivel de aprendizaje, esto equivale al 60% el 40% restante es obtenido por las calificaciones de 10.º y 11.º grado de la educación secundaria. El 6% constitucional es administrado por el centro universitario y por la Unión Nacional de Estudiantes de Nicaragua (UNEN).

En 2013, el índice de seguridad ciudadana "Índice de Ley y Orden de 2013" (Law and Order Index 2013) elaborado por la firma Gallup, posicionó a Nicaragua como el país más seguro de Latinoamérica. Este informe toma en cuenta la confianza en la Policía local. Michael Shifter, presidente del centro de estudios Diálogo Interamericano con sede en Washington, dijo a la agencia EFE, que en Nicaragua, a pesar de ser uno de los países más pobres de la región, las autoridades locales son bastante ""respetadas por mantener el orden"".

Según el Índice de Paz Global (GPI 2014), del Institute got Economics and Pieace (IEP), publicado en 2015, Nicaragua es el sexto país más seguro Latinoamérica y el Caribe ubicándose en la posición número 58 en dicho índice, que evalúa los gastos militares, relaciones con países vecinos, cantidad de homicidios, crimen organizado y respeto por los derechos humanos.

De acuerdo al Programa de las Naciones Unidas para el Desarrollo, Nicaragua es el país más seguro de Centroamérica con una tasa de homicidios de 8,7 por cada 100 mil habitantes, solamente por detrás de países latinoamericanos como Chile (2 por cada 100 000), Argentina (5,8 por cada 100 000), Uruguay (6,1 por cada 100 000), y por delante de Costa Rica (8,9 por cada 100 000) y Perú (9 por cada 100 000).

Por el contrario, los países vecinos del llamado ""triángulo del norte"", una de las zonas más violentas de América, registran por cada 100 000 habitantes:

Este informe analiza en profundidad el fenómeno de la seguridad ciudadana, estudia experiencias exitosas y propone recomendaciones concretas para mejorar las políticas públicas. Pablo Mandeville, representante Residente del Programa de las Naciones Unidas para el Desarrollo (PNUD), afirmó:

El plato principal típico nicaragüense es el gallo pinto, una mezcla elaborada de arroz y frijoles. Originaria de los esclavos africanos que migraron a la costa Caribe e hicieron esta mezcla por falta de variedad de alimentos.

Hay diferencias entre la cocina tradicional de la región del Pacífico y la de la costa del Caribe. Mientras que los principales platillos de la costa sur en el Pacífico se basan en carne de cerdo y res, frutas, verduras y el maíz blanco, la cocina de la costa norte en el Caribe hace amplio uso de los mariscos y el coco, como por ejemplo en la elaboración del gallo pinto con leche de coco, también conocido como "Rice and Beans"".

Como en muchos otros países centroamericanos, el maíz es una de las bases de la alimentación y se cultiva en el territorio desde hace milenios; se utiliza en muchos platos extensamente consumidos, tales como el nacatamal
, el Yoltamal y el indio viejo. Además de usarse como "bastimento" en la forma de tortillas cocidas en comales, es un ingrediente para bebidas tales como pinolillo y la chicha así como en los dulces, rosquillas y los postres típicos.

Los vegetales y las frutas locales han estado en uso desde periodos prehispánicos. Su influencia perdura hoy en día en la cocina de Nicaragua. Muchos de los platos de Nicaragua incluyen las frutas y los vegetales tales como
aguacate,
ayote,
caimito,
chilote,
coyolito,
elote,
granada,
granadilla,
grosella,
guaba,
guayaba,
icaco,
jocote,
mango,
mamón,
nancite,
papaya,
pipián,
plátano,
quequisque,
tamarindo,
yuca y
zapote,
además de hierbas como
culantro,
orégano y
achiote.

El nacatamal es una comida típica nicaragüense hecha de maíz, tiene apariencia de tamal, lleva carne de cerdo o pollo, arroz, papas en rodajas, y en algunas ocasiones incluye pasas, aceitunas, tomate, etc.

También se puede destacar las rosquillas con café.

El Instituto Nicaragüense de Deportes es la institución encargada de impulsar, normar, coordinar, promover y fomentar la práctica de las actividades deportivas, de educación física y recreación en todo el país, así como la construcción y mantenimiento de la infraestructura necesaria para tales fines, lo mismo para la organización y buen funcionamiento de asociaciones y federaciones deportivas y recreativas, con el apoyo de la comunidad nacional e internacional.

El béisbol es el deporte más popular en Nicaragua y su equipo nacional goza de una tradición fuerte en el ámbito del béisbol aficionado mundial con varios subcampeonatos conquistados.

El béisbol nicaragüense cuenta con jugadores que han logrado ser parte de las Ligas Mayores pero el más notable es Dennis Martínez, el primer jugador del béisbol de Nicaragua en las Grandes Ligas. Él se convirtió en el primer lanzador latino que lanzó un juego perfecto, el décimo tercero en la historia de las Ligas Mayores, contra el equipo Los Angeles Dodgers el 27 de julio de 1991.

La FENIBA (Federación Nicaragüense de Béisbol Aficionado) es la entidad rectora y organiza desde el año 1970 el Campeonato Nacional de Béisbol de Primera División que actualmente lleva el nombre de «Comandante Germán Pomares Ordóñez» con la participación de equipos representativos de los 15 departamentos y 2 regiones autónomas del país. Con jugadores de estos equipos se conforma la Selección nacional de Béisbol que representa al país en las competiciones internacionales más importantes organizadas por la IBAF y la COPABE.

Desde hace unos años, un grupo de empresarios ha organizado la llamada Liga Nicaragüense de Béisbol Profesional (LNBP) de categoría Doble A, en la cual participan equipos conformados por jugadores profesionales, tanto nacionales como extranjeros, que provienen del sistema de Ligas Menores de los Estados Unidos de América o de las ligas profesionales de República Dominicana, Puerto Rico y Venezuela.

El boxeo es el segundo deporte popular en Nicaragua. El país ha tenido varios campeones del mundo en distintas categorías de peso reconocidos por los principales organismos boxísticos como la AMB, el CMB, la OMB y la FIB. El deportista nicaragüense más famoso de la historia es el boxeador Alexis Argüello, triple campeón mundial en diferentes categorías, reconocido como una leyenda del boxeo latinoamericano y mundial. En 2015 el nicaragüense Román González, fue reconocido como el mejor boxeador "" del mundo.

Recientemente, el fútbol ha ganado cierta masificación, especialmente entre la población más joven. El estadio Nacional Dennis Martínez ha servido como lugar para el béisbol y el fútbol, pero el primer estadio nacional de este deporte en Managua está actualmente en construcción.

En la Liga de Primera División los equipos con más tradición y arrastre popular son Diriangén FC (Diriamba), Real Estelí FC (Estelí) y CD Walter Ferreti (Managua).

Por primera vez en su historia, la selección nicaragüense de fútbol, tras una victoria 2:0 sobre su similar de Guatemala en la Copa de Naciones de la UNCAF en 2009, clasificó a la Copa de Oro de la CONCACAFque se celebró en los Estados Unidos de América en ese mismo año. En la fase de grupos, Nicaragua se enfrentó a las selecciones de México, Panamá y Guadalupe.

Durante el verano del año 2015, Juan Barrera se ha convertido en el primer jugador nicaragüense en firmar por un equipo europeo desde un equipo de la liga local.

El surf en Nicaragua está pasando por un momento de auge y aparentemente tiene un horizonte muy a largo plazo. La historia data desde 1970 en una playa llamada "Popoyo", donde la gente que volaba desde Costa Rica podía apreciar la bella playa y sus grandes olas, un reducido grupo local de personas se mostró interesado en visitar la playa y realizar surf en la misma, pero el estado remoto de la playa hacía el acceso a la misma muy difícil y costoso, por lo que la gente usualmente acampaba en la costa de la playa. Luego en los 80s, a pesar del contexto político por el que pasaba el país, aún había una pequeña afluencia de turistas dispuestos a explorar el país. Personas de renombre como George Greenough y Adrian Cojin, famoso por su aventura en motocicleta desde California hasta Suramérica en 1987.

A inicios de 1990 el ahora llamado INTUR (en ese entonces Ministerio de Turismo) empezó a promover Nicaragua como un gran destino para surfistas en todo el mundo. En 1992 una revista de surf hizo un viaje a Montelimar pero las personas en el viaje terminaron en un bote en la playa Manzanillo, ya que Montelimar no reunía las condiciones climáticas para surf, las olas son apenas de 1 metro.

En 1992 un repentino desastre natural destruyó la costa de Popoyo, un tsunami que causó la muerte de aproximadamente 300 personas. Esto hizo que Popoyo perdiera su atractivo temporalmente, pues la playa y las olas seguían siendo perfectas para el surf. A medido de los 90s, surfistas provenientes de Managua y también de áreas aledañas a Popoyo. Gradualmente Poypo volvía a atraer extranjeros, fue así como personas provenientes de Costa Rica y Miami, Florida empezaban a comprar terrenos en la costa, ahí surge el campamento de surf en Popoyo en 1999.

Actualmente, Popoyo sigue siendo un gran destino para el surf pero este deporte se ha extendido a lo largo de la costa del Pacífico. Las playas más populares para surfear son: San Juan del Sur, Marsella, Maderas, Tola, Gigante, Colorado, Playgrounds, Astillero, Aschunchillo, Santana, Jiquiliste, y Playa Hermosa. Todas las playas cuentan con hostales, hospedajes, hoteles desde 2 hasta 5 estrellas, pueblos asentados, entre otras atracciones además del surf.

Nicaragua ha sido sede de campeonatos como:

Todos los eventos promovidos por el INTUR, ISA, entre otros patrocinadores.

El fútbol americano nicaragüense también ha empezado a dar luz en este país. Existen cinco equipos que batallan en diversos campos de la ciudad de Managua. Existe una liga llamada LUFAN (Liga Universitaria de Fútbol Americano Nicaragüense) en la cual participan los Guerreros de Nicaragua, Ave María Knights, Los Lobos de UCC, Jaguares de la UAM, Santos de UNAN y recientemente se está hablando del ingreso de un sexto equipo del American College. Se juega una liga anual que dura de septiembre a diciembre, y se realizan partidos de fogueo y pequeños torneos entre enero y mayo. La liga tiene cobertura periodística por los principales diarios de circulación nacional.

Símbolos patrios de Nicaragua Descripción y significado de los símbolos patrios de Nicaragua



</doc>
<doc id="1983" url="https://es.wikipedia.org/wiki?curid=1983" title="Newton (unidad)">
Newton (unidad)

En física, un newton (símbolo: N) es la unidad de medida de la fuerza en el Sistema Internacional de Unidades, nombrada de esa forma por las aportaciones de Isaac Newton a la física, especialmente a la mecánica clásica. Es una unidad derivada del Sistema Internacional que se compone de las unidades básicas:

En 1946, la VIII Conferencia General de Pesos y Medidas (CGPM), resolución 2, normalizó la unidad de fuerza del sistema MKS de unidades como la fuerza necesaria para proporcionar una aceleración de 1 m/s a un objeto de 1 kg de masa. La IX CGPM, de 1948, adoptó el nombre de "newton" en su resolución 7.

En la tabla que sigue se relacionan los múltiplos y submúltiplos del newton en el Sistema Internacional de Unidades.





</doc>
<doc id="1984" url="https://es.wikipedia.org/wiki?curid=1984" title="Neptuno (planeta)">
Neptuno (planeta)

Neptuno es el octavo planeta en distancia respecto al Sol y el más lejano del sistema solar. Forma parte de los denominados planetas exteriores o gigantes gaseosos, y es el primero que fue descubierto gracias a predicciones matemáticas. Su nombre fue puesto en honor al dios romano del mar —Neptuno—, y es el cuarto planeta en diámetro y el tercero más grande en masa. Su masa es diecisiete veces la de la Tierra y ligeramente mayor que la de su planeta «gemelo» Urano, que tiene quince masas terrestres y no es tan denso. En promedio, Neptuno orbita el Sol a una distancia de 30,1 ua. Su símbolo astronómico es ♆, una versión estilizada del tridente del dios Neptuno.

Tras el descubrimiento de Urano, se observó que las órbitas de Urano, Saturno y Júpiter no se comportaban tal como predecían las leyes de Kepler y de Newton. Adams y Le Verrier, de forma independiente, calcularon la posición de un hipotético planeta, Neptuno, que finalmente fue encontrado por Galle, el 23 de septiembre de 1846, a menos de un grado de la posición calculada por Le Verrier. Más tarde se advirtió que Galileo ya había observado Neptuno en 1612, pero lo había confundido con una estrella.

Neptuno es un planeta dinámico, con manchas que recuerdan las tempestades de Júpiter. La más grande, la Gran Mancha Oscura, tenía un tamaño similar al de la Tierra, pero en 1994 desapareció y se ha formado otra. Los vientos más fuertes de cualquier planeta del sistema solar se encuentran en Neptuno.

Neptuno tiene una composición bastante similar a del planeta Urano, y ambos tienen composiciones que difieren mucho de los demás gigantes gaseosos, Júpiter y Saturno. La atmósfera de Neptuno, como las de Júpiter y de Saturno, se compone principalmente de hidrógeno y helio, junto con vestigios de hidrocarburos y posiblemente nitrógeno. Contiene una mayor proporción de hielos, tales como agua (), amoníaco () y metano (). Los científicos muchas veces categorizan Urano y Neptuno como gigantes helados para enfatizar la distinción entre estos y los gigantes de gas Júpiter y Saturno. El interior de Neptuno, como el de Urano, está compuesto principalmente de hielos y roca. Los rastros de metano en las regiones periféricas exteriores contribuyen para el aspecto azul vívido de este planeta.

Neptuno es ligeramente más pequeño que Urano, pero más denso.

Los dibujos de Galileo muestran que el planeta Neptuno fue observado por primera vez el 28 de diciembre de 1612, y nuevamente el 27 de enero de 1613; en ambas ocasiones, Galileo confundió Neptuno con una estrella cercana a Júpiter en el cielo nocturno.

En 1821, Alexis Bouvard publicó en sus tablas astronómicas la órbita de Urano. Las observaciones revelaron perturbaciones sustanciales, que llevaron a Bouvard a lanzar la hipótesis de que la órbita de Urano debía estar siendo perturbada por algún otro cuerpo. En 1843, John Couch Adams calculó la órbita de un octavo planeta en función de las anomalías observadas en la órbita de Urano. Envió sus cálculos a "sir" George Airy, el Astrónomo Real, quien pidió más información. Adams comenzó a redactar una respuesta, pero nunca llegó a enviarla. Urbain Le Verrier, el matemático codescubridor de Neptuno, en 1846, independientemente de Adams, publicó sus propios cálculos. En el mismo año, John Herschel comenzó a abogar por el enfoque matemático y persuadió a James Challis para buscar el planeta propuesto por Le Verrier. Después de muchas dilaciones, Challis empezó su búsqueda, reacio, en julio de 1846. Sin embargo, en el ínterin, Le Verrier había convencido a Johann Gottfried Galle para buscar el planeta. Neptuno fue descubierto esa misma noche, el 23 de septiembre de 1846, donde Le Verrier había predicho que se encontraría. Challis más tarde se dio cuenta de que había observado previamente el planeta dos veces en agosto, sin advertirlo.

A raíz del descubrimiento, hubo mucha rivalidad nacionalista entre los franceses y los británicos sobre quién tenía prioridad y merecía crédito por el descubrimiento. Finalmente surgió un consenso internacional sobre que tanto Le Verrier como Adams conjuntamente lo merecían. Sin embargo, la cuestión está siendo revaluada por los historiadores con el redescubrimiento, en 1998, de los "Documentos de Neptuno" (documentos históricos del Observatorio Real de Greenwich), que al parecer habían sido objeto de apropiación indebida por el astrónomo Olin Eggen durante casi tres décadas y sólo redescubiertos inmediatamente después de su muerte. Después de la revisión de los documentos, algunos historiadores indican que Adams no merece crédito en igualdad con Le Verrier.

Poco después de su descubrimiento, Neptuno fue llamado, simplemente, «el planeta que le sigue a Urano» o «el planeta de Le Verrier». La primera sugerencia de un nombre provenía de Galle, quien propuso el nombre de "Janus". En Inglaterra, Challis presentó el nombre de "Océano". En Francia, Le Verrier propuso que el nuevo planeta se llamara "Le Verrier", una sugerencia que no fue bien recibida fuera de Francia.

Mientras tanto, en ocasiones separadas e independientes, Adams propuso cambiar el nombre de Urano por el de "Georgia", mientras que Le Verrier sugirió "Neptuno" para el nuevo planeta. Struve salió en favor de ese nombre el 29 de diciembre de 1846, en la Academia de Ciencias de San Petersburgo. En la mitología romana, Neptuno era el dios del mar, identificado con el griego Poseidón. La demanda de un nombre mitológico parecía estar en consonancia con la nomenclatura de los otros planetas, los cuales todos recibieron nombres de deidades romanas.

El nombre del planeta se traduce literalmente como "estrella del rey del mar" en chino, coreano, japonés y vietnamita (海王星 en caracteres chinos, 해왕성 en coreano).

En la India, el nombre que se da al planeta es Varuna (devanagari: वरुण), el dios del mar en la mitología hindú/védica, el equivalente de Poseidón/Neptuno en la mitología grecorromana.

Desde su descubrimiento hasta 1930, Neptuno fue el planeta conocido más lejano. Con el descubrimiento de Plutón en 1930, Neptuno se convirtió en el penúltimo planeta, salvo durante 20 años entre 1979 y 1999 cuando Plutón cayó dentro de su órbita. No obstante, el descubrimiento del cinturón de Kuiper en 1992 llevó a muchos astrónomos a debatir si Plutón debía considerarse un planeta en su propio derecho o parte de la estructura más grande del cinturón. En 2006, la Unión Astronómica Internacional definió la palabra "planeta" por primera vez, reclasificando a Plutón como un «planeta enano» y haciendo de nuevo a Neptuno el último de los planetas del sistema solar.

El 12 de julio de 2011, al cabo de casi 165 años terrestres, Neptuno alcanzó a finalizar su primera órbita completa alrededor del Sol desde su descubrimiento en 1846, en lo que constituye un año en términos de su propia traslación.

La estructura interna de Neptuno se parece a la de Urano: un núcleo rocoso cubierto por una costra helada, oculto bajo una atmósfera gruesa y espesa. Los dos tercios interiores de Neptuno se componen de una mezcla de roca fundida, agua, amoníaco líquido y metano. El tercio exterior es una mezcla de gas caliente compuesto de hidrógeno, helio, agua y metano.

Al igual que Urano y a diferencia de Júpiter y de Saturno, la composición de la estructura interna de Neptuno se cree que está formada por capas distintas. La capa superior está formada por nubes de hidrógeno, helio y metano, que se transforman de gas en hielo a medida que aumenta la profundidad. El manto rodea un núcleo compacto de roca y hielo.

Su atmósfera comprende aproximadamente 5 % a 10 % de su masa y se probablemente se extiende entre la superficie del planeta hacia profundidades correspondientes a entre 10 % y 20 % de la distancia hacia el núcleo. A esas profundidades, la atmósfera alcanza presiones de aproximadamente 10 GPa, o alrededor de 100 000 veces mayor que la de la atmósfera de la Tierra. Las concentraciones de metano, amoníaco y agua son crecientes desde las regiones exteriores hacia las regiones inferiores de la atmósfera.

Este manto que rodea al núcleo rocoso de Neptuno, es una región extremadamente densa y caliente, se cree que en su interior pueden llegar a alcanzarse temperaturas de 1700 ℃ a 4700 ℃. Se trata de un fluido de gran conductividad eléctrica es una especie de océano de agua y amoníaco.

A 7000 km de profundidad, las condiciones generan la descomposición del metano en cristales de diamante que se precipitan en dirección al núcleo.

Al orbitar tan lejos del Sol, Neptuno recibe muy poco calor. Su temperatura en la superficie es de –218 °C (55 K). Sin embargo, el planeta parece tener una fuente interna de calor. Se piensa que puede ser un remanente del calor producido por la concreción de materia durante la creación del mismo, que ahora irradia calor lentamente hacia el espacio. Esta fuente de calor interno produce potentísimos sistemas climáticos en torno al planeta, como la Gran Mancha Oscura que la sonda "Voyager 2" descubrió a su paso por el sistema de Neptuno en 1989.

Otra de las teorías apunta a que en las profundidades de Neptuno se dan las condiciones idóneas para que los átomos de carbono se combinen en cristales, liberando calor en el proceso. Esta hipótesis plantea pues la posibilidad de que en Neptuno lluevan literalmente los diamantes.

El color de Neptuno difiere del de Urano debido a la cantidad de helio contenido en su atmósfera, que es ligeramente mayor. Debido a esto, Neptuno absorbe más luz roja del Sol que su planeta vecino, por tanto refleja un azul mucho más intenso.

La atmósfera de Neptuno tiene una estructura de bandas similar a la encontrada en los otros gigantes gaseosos. En este planeta se producen fenómenos como huracanes gigantes, con un diámetro igual al de la Tierra, y otras formaciones de nubes, incluyendo algunos extensos, y muy bellos cirros, encima (50 km) de las nubes principales. De este modo Neptuno tiene un sistema de nubes muy activo, posiblemente más activo que el de Júpiter. La velocidad del viento en la atmósfera de Neptuno, es de hasta 2000 km/h, siendo la mayor del sistema solar y se cree que se alimentan del flujo de calor interno.

A grandes altitudes, la atmósfera de Neptuno es el 80 % de hidrógeno y 19 % de helio. Una pequeña cantidad de metano también está presente. Hay prominentes bandas de absorción de metano en longitudes de onda superiores a 600 nm, en la porción roja e infrarroja del espectro. Al igual que con Urano, esta absorción de la luz roja por el metano atmosférico es parte de lo que le da su color azul a Neptuno, aunque el azul vívido de Neptuno es diferente del color azul cian de Urano. Dado que el contenido de metano atmosférico de Neptuno es similar a la de Urano, se cree que algunos constituyentes atmosféricos desconocidos contribuyen al color de Neptuno.
La atmósfera de Neptuno se subdivide en dos regiones principales: la región inferior (troposfera), donde la temperatura disminuye con la altitud, y la región superior (estratosfera), donde la temperatura aumenta con la altitud. El límite entre las dos, la tropopausa neptuniana, se encuentra a una presión de 10 kilopascales (0,1 bares). La estratosfera luego da paso a la termosfera a una presión inferior, entre 1 y 10Pa (10 a 10 microbares). Más arriba, la "termosfera" transiciona gradualmente a la exosfera.

Los modelos sugieren que la troposfera de Neptuno está dividida por nubes en bandas de diferentes composiciones en función de la altitud. Las nubes de nivel superior se encuentran a presiones por debajo de un bar, donde la temperatura es adecuada para el metano se condense. Para presiones de entre uno y cinco bares (100 y 500 kPa), se cree que se formen nubes de amoníaco y sulfuro de hidrógeno. Por encima de una presión de cinco bares, las nubes pueden consistir en amoníaco, sulfuro de amonio, sulfuro de hidrógeno y agua. Nubes más profundas de hielo de agua se creen encontrar a presiones de alrededor de 50 bares (5 MPa), donde la temperatura llega a 273 K (0 °C). Debajo, se cree que se encontran nubes de amoniaco y sulfuro de hidrógeno.

Se han observado nubes de gran altitud en Neptuno que proyectan sus sombras en la capa opaca de nubes abajo. También hay bandas de nubes de gran altitud que envuelven alrededor del planeta en latitudes constantes. Estas bandas circunferenciales tienen anchuras de 50 a 150 km y están aproximadamente entre los 50 y 110 km por encima de la capa de nubes. Estas altitudes corresponden a la capa donde se producen los fenómenos meteorológicos y climáticos, en la troposfera. Estos fenómenos no se producen en mayores altitudes, que corresponden a la estratosfera y a la termosfera. Neptuno posee un manto helado de mayor tamaño que Urano.

Los espectros electromagnéticos de Neptuno sugieren que la baja estratosfera es brumosa debido a la condensación de productos de la fotólisis ultravioleta del metano, tales como el etano () y el acetileno (). La estratosfera tiene también pequeñas cantidades de monóxido de carbono () y cianuro de hidrógeno (). La estratosfera de Neptuno es más caliente que la de Urano, debido a la elevada concentración de hidrocarburos. La abundancia de metano, etano y acetileno en el ecuador de Neptuno es entre 10 y 100 veces mayor que en los polos.

Por razones que permanecen oscuras, la termosfera del planeta tiene una temperatura anormalmente alta de alrededor de 750 K. El planeta está demasiado lejos del Sol para que este calor se genere por la radiación ultravioleta. Uno de los candidatos para un mecanismo de calentamiento es la interacción atmosférica con iones en el campo magnético del planeta. Otras explicaciones posibles para esta ocurrencia son ondas de gravedad desde el interior que se disipan en la atmósfera. La termosfera contiene vestigios de dióxido de carbono () y agua, que pueden haber sido depositados a partir de fuentes externas, como los meteoritos o polvo cósmico.

El campo magnético de Neptuno, como el de Urano, está bastante inclinado, 47 grados respecto al eje de rotación y desplazado al menos 0,55 radios (unos ) del centro físico. Comparando los campos magnéticos de los planetas, los investigadores piensan que la extrema orientación podría ser característica de los flujos en el interior del planeta y no el resultado de la inclinación del propio planeta o de cualquier posible inversión de los campos en ambos planetas. Este campo puede ser generado por movimientos convectivos fluidos en una cáscara esférica delgada de líquidos conductores eléctricos (probablemente una combinación de amoníaco, metano y agua) que resulta en una acción de dinamo.

El dipolo del campo magnético, en el ecuador magnético de Neptuno, es de unos 14 microteslas (0,14 G). El momento dipolar magnético de Neptuno es aproximadamente (14 μT·"R", donde "R" es el radio de Neptuno). El campo magnético de Neptuno tiene una geometría compleja, que incluye contribuciones relativamente grandes de componentes no dipolares, incluyendo un momento cuadrupolar que puede exceder la fuerza del momento dipolar. Por el contrario, la Tierra, Júpiter y Saturno sólo tienen momentos cuadrupolares relativamente pequeños, y sus campos están menos inclinados con respecto al eje polar. El gran momento cuadrupolar de Neptuno puede ser el resultado del desplazamiento en relación al centro del planeta y de las limitaciones geométricas del dinamo generador del campo magnético.

El arco de choque de Neptuno, donde la magnetósfera empieza a frenar el viento solar, se produce a una distancia de 34,9 veces el radio del planeta. La magnetopausa, donde la presión de la magnetósfera contrarresta el viento solar, se encuentra a una distancia de entre 23 y 26,5 veces el radio de Neptuno. La cola de la magnetosfera se extiende por lo menos hasta 72 radios de Neptuno, y probablemente mucho más lejos.

La meteorología de Neptuno se caracteriza por sistemas de tormentas muy dinámicos, con vientos que alcanzan velocidades de casi 600 m/s (2200 km/h), casi llegando a velocidades de flujo supersónico. Más típicamente, mediante el seguimiento del movimiento de las nubes persistentes, se ha demostrado que las velocidades del viento varían de 20 m/s en la dirección este hasta 325 m/s hacia el oeste. En la parte superior de las nubes, la velocidad de los vientos predominantes oscila entre 400 m/s a lo largo del ecuador y 250 m/s en los polos. La mayoría de los vientos en Neptuno se mueve en una dirección opuesta a la rotación del planeta. El patrón general de vientos muestra una rotación adelante en latitudes altas contra la rotación regresiva en latitudes más bajas. Se piensa que la diferencia en la dirección de flujo se debe a un "efecto pelicular" y no se debe a ningún proceso atmosférico más profundo. A los 70° S de latitud, un chorro de alta velocidad viaja a una velocidad de 300 m/s.

Neptuno se diferencia de Urano en su nivel típico de la actividad meteorológica. Voyager 2 observó fenómenos meteorológicos en Neptuno durante su sobrevuelo en 1989, pero no observó fenómenos comparables en Urano durante su sobrevuelo en 1986.

En 2007, se descubrió que la troposfera superior del polo sur de Neptuno era aproximadamente 10 K más caliente que el resto del planeta, que tiene un promedio de aproximadamente 73 K (–200 ℃). La diferencia de temperatura es suficiente para que el metano, que en otras partes se congela en la troposfera, escape a la estratosfera cerca del polo. Esta región más caliente se debe a la inclinación del eje de Neptuno, que ha expuesto el polo sur al Sol durante el último cuarto del año de Neptuno, o unos 40 años terrestres. Como Neptuno se mueve lentamente hacia el lado opuesto del Sol, el polo sur se oscurecerá y el polo norte se iluminará, haciendo que la liberación de metano cambie al polo norte.

Debido a los cambios estacionales, se ha observado que las bandas de nubes en el hemisferio sur de Neptuno aumentaron en tamaño y albedo. Esta tendencia se ha visto por primera vez en 1980 y se espera que dure hasta cerca de 2020. El largo periodo orbital hace que las estaciones en Neptuno duren cuarenta años.

La nave Voyager 2, fue lanzada 16 días antes que su gemela, la Voyager 1. La trayectoria que siguió fue más lenta que la de su compañera, para poder explorar no solo Júpiter y Saturno, sino proseguir la misión hasta Urano e incluso Neptuno. Para poder alcanzar los cuatro planetas, el Voyager 2 requería un lanzamiento que le diera todo el empuje del que fuera capaz el cohete "Titán III". Y mientras que el cohete que expulsó al Voyager 1 no logró un buen lanzamiento, el del Voyager 2 funcionó a la perfección. De haberse usado el primer cohete para el Voyager 2, la nave no habría llegado a Urano y Neptuno. Por fortuna el Voyager 2 tuvo el mejor cohete.

Al llegar Voyager 2 a Neptuno, el 25 de agosto de 1989 a las 3:56 hora de Greenwich, ciento cuarenta y tres años después de su descubrimiento, poco sabíamos acerca de este planeta. El más lejano de los cuatro "planetas gigantes" está treinta veces más alejado del Sol que la Tierra y tarda 165 años en darle una vuelta al Sol. Su diámetro es unas cuatro veces más grande que el de nuestro planeta. Se le conocían dos lunas, entre ellas Tritón uno de los objetos más interesantes del sistema solar, y se sospechaba que podría tener anillos. Los datos recabados en unas cuantas horas por el Voyager 2 nos dieron más información que cerca de un siglo y medio de observaciones astronómicas desde la Tierra.

Para sorpresa de los científicos, el Voyager 2 reveló una gran mancha oscura, similar a la mancha roja de Júpiter. Se trata de un gigantesco huracán con vientos de dos mil kilómetros por hora, los más violentos en nuestro sistema solar. En la Tierra la energía que produce los vientos es suministrada por el Sol. En el caso de Neptuno, actualmente el planeta más alejado del Sol, la temperatura en la parte superior de la capa de nubes es de 210 °C bajo cero, por lo que la energía solar es insuficiente para dar lugar a los vientos observados por el Voyager 2. Al parecer el planeta sigue el proceso de contracción a partir del cual se formó, proceso que proporciona la energía suficiente para generar estos poderosos vientos. Sin embargo, la estructura general de los vientos en Neptuno no ha podido ser comprendida por los científicos.

Algunas observaciones desde la Tierra habían proporcionado evidencia de anillos alrededor de Neptuno. Esta evidencia no era concluyente ya que parecía que más que anillos se trataba de pedazos de anillos, como delgados arcos de materia girando alrededor de Neptuno. Voyager 2 encontró cuatro anillos completos, dos de ellos delgados y los otros dos anchos. Los anillos delgados se hallan cerca de la órbita de dos satélites que se cree son responsables de su estabilidad, y por ello se les denomina "lunas pastoras". Los dos anillos más anchos están formados por material sumamente opaco que refleja aproximadamente un diez milésimo de la luz que incide sobre ellos, haciendo imposible su detección desde la Tierra. La justificación en que los anillos contienen una gran cantidad de polvo, sólo puede explicarse si en la vecindad de Neptuno se albergara una importante cantidad de meteoritos, mayor que en las zonas más internas del sistema solar.

Durante más de un siglo sólo se conoció una luna de Neptuno, llamada Tritón. En 1949 Gerard Kuiper descubrió un segundo satélite Nereida, el cual gira muy alejado del planeta. Como sucedió en los encuentros anteriores de las naves Voyager con otros planetas, Neptuno tenía más satélites "escondidos". Voyager 2 descubrió seis nuevas lunas, entre ellas Despoina y Galatea, las dos lunas pastoras mencionadas anteriormente. Proteus, la mayor de las "nuevas lunas", tiene una superficie completamente cubierta de cráteres, el mayor de ellos con un tamaño de casi la mitad del de Proteus mismo. A pesar de estos hallazgos, Tritón, la luna mayor de Neptuno, y la que se conoce desde hace más de un siglo, sigue siendo la más interesante. Tritón es un objeto único en el sistema solar que bien merece un relato aparte.

En la actualidad, se conocen catorce satélites de Neptuno. El mayor de ellos es Tritón, que posee más del 99,5 % de la masa en órbita alrededor de Neptuno en sus 2700 km de diámetro. Se destaca, no sólo por su gran tamaño, sino también por poseer una órbita retrógrada, algo excepcional dentro de los grandes satélites. En su superficie se han encontrado géiseres de nitrógeno. Posee forma esférica, mientras los demás satélites de Neptuno tienen una forma irregular.

Tritón es considerado un objeto del Cinturón de Kuiper capturado por la gravedad de Neptuno. Por su tamaño y aspecto debe ser muy parecido a Plutón, hoy reclasificado como un planeta enano, el cual también es un objeto del Cinturón de Kuiper. Nereida, con 340 km de diámetro, tiene la órbita más excéntrica de todos los satélites del sistema solar, su distancia a Neptuno varía entre 1 353 600 y 9 623 700 kilómetros.

Antes de la llegada de la sonda espacial Voyager 2 en 1989, sólo se conocían estos dos satélites gracias a las observaciones desde la Tierra: Tritón y Nereida. El Voyager 2 descubrió otros seis más: Náyade, Talasa, Despina, Galatea, Larisa y Proteo. Estos seis satélites son los más próximos al planeta y poseen una órbita más interior que la de Tritón. La mayoría de los satélites descubiertos miden menos de 200 km de diámetro y podrían ser restos de la luna anterior que fue destruida o desintegrada durante la captura de Tritón. Proteo es el de mayor tamaño con 400 km de diámetro.

Después de eso, se han descubierto cinco pequeñas lunas más (mediante sondeos telescópicos) entre 2002 y 2003, situadas en órbitas lejanas al planeta, las cuales han recibido los nombres de Halímedes, Sao, Laomedeia, Psámate y Neso. Todas ellas poseen órbitas con elevada inclinación y tres tienen una órbita retrógada. Ambas características, iguales a las de Tritón, hacen suponer que su origen también fue el de objetos del Cinturón de Kuiper capturados por la gravedad de Neptuno.

El 16 de julio de 2013 se anunció el descubrimiento de la luna número 14, nombrada provisionalmente 'S/2004 N 1' a la espera de ponerle un nombre definitivo.

Es el satélite más grande de Neptuno, y el más frío del sistema solar que haya sido observado por una Sonda (–235º). La capa Polar de Tritón tiene géiseres que arrojan nieve de nitrógeno.

Fue descubierto por William Lassell el 10 de octubre de 1846, y debe su nombre al dios Tritón de la mitología griega. Tiene un diámetro de 2707 km, lo cual lo convierte en el satélite más grande de Neptuno y el séptimo del sistema solar, además de ser la única luna de gran tamaño que posee una órbita retrógrada, es decir, una órbita cuya dirección es contraria a la rotación del planeta. A causa de esta órbita retrógrada y a su composición, similar a la de Plutón, se considera que Tritón fue capturado del Cinturón de Kuiper por la fuerza gravitacional de Neptuno.

Tritón se compone de una corteza de nitrógeno congelado sobre un manto de hielo el cual se cree cubre un núcleo sólido de roca y metal. Es de los pocos satélites del sistema solar del que se conoce que es geológicamente activo. Debido a esta actividad, su superficie es relativamente joven, y revela una compleja historia geológica a partir de misteriosos e intrincados terrenos criovolcánicos y tectónicos. Tras el paso de la sonda espacial "Voyager 2" por sus cercanías, unas enigmáticas imágenes revelaron lo que parecían ser géiseres de nitrógeno líquido emanados desde su superficie helada. Este descubrimiento cambió el concepto clásico de vulcanismo ya que, hasta entonces, se suponía que los cuerpos gélidos no deberían estar geológicamente activos.

Tritón posee una tenue atmósfera de nitrógeno con pequeñas cantidades de metano. La sonda "Voyager 2" consiguió observar una fina capa de nubes que se forman en los polos y están compuestas por hielo de nitrógeno; existe también niebla fotoquímica hasta una altura de 30 km que está compuesta por varios hidrocarburos, semejantes a los encontrados en Titán.

La temperatura en la superficie es de –235 grados Celsius, aún más baja que la temperatura media de Plutón (cerca de –229 °C), de hecho es la temperatura más baja jamás medida en el sistema solar.

Neptuno posee un sistema de anillos tenue, que guarda más semejanzas con el sistema de Júpiter que con los complejos anillos presentes en los planetas Urano y Saturno. Estos anillos están formados por partículas de hielo y silicatos además de compuestos orgánicos, producidos por la radiación de la magnetosfera, por lo que su color es muy oscuro. Los tres anillos principales son el estrecho y más exterior anillo Adams, a 63 000 km del centro de Neptuno, el anillo Le Verrier, a 53 000 km, y el anillo Galle, el más ancho de los tres, a 42 000 km. Además de estos definidos anillos existe una lámina de material extremadamente tenue que se extiende desde el anillo Le Verrier hasta el Galle y probablemente más al interior hacia Neptuno.

El primero de estos anillos fue descubierto en 1968, aunque el resultado de estas observaciones no fue publicado hasta 1977, cuando se detectaron los anillos de Urano. Pero fue la sonda espacial "Voyager 2" la que confirmó la existencia de los anillos a su paso por Neptuno en 1989. Las imágenes tomadas por la "Voyager 2" en 1989 mostraron asimismo un gran número de anillos delgados, desde el más externo, que contiene cinco prominentes arcos, llamados Coraje, Libertad, Igualdad 1, Igualdad 2 y Fraternidad. Estos arcos podrían formarse por la influencia gravitacional de Galatea, uno de los satélites de Neptuno.

Se piensa que los anillos de Neptuno, al igual que los de Urano, son relativamente jóvenes. Es probable que su edad sea significativamente menor que la del sistema solar. De igual modo, ambos están probablemente originados por la fragmentación y posterior colisión de los restos de uno o varios satélites interiores de Neptuno. Estos fragmentos actúan como fuentes de polvo y material de los anillos. A este respecto los anillos de Neptuno son similares a las bandas de polvo observadas por la "Voyager 2" entre los anillos principales de Urano.

Las últimas observaciones realizadas desde la Tierra evidencian que los anillos de Neptuno son mucho más inestables de lo que se creía, algunas partes se han deteriorado dramáticamente. Entre 2002 y 2003, Imke de Pater de la Universidad de California, Berkeley, y sus colegas utilizaron el telescopio Keck de 10 metros de Hawái para volver a mirar al anillo. Han analizado ya las imágenes y han encontrado que todos los arcos parecen haber sufrido una desintegración, mientras que uno en especial, llamado Libertad, se ha desvanecido considerablemente desde las observaciones de la Voyager. Si esta tendencia continua, Libertad habrá desaparecido dentro de 100 años.

Los resultados sugieren que sea lo que sea que está causando el deterioro de los arcos, está actuando más rápido que cualquier mecanismo que pudiera regenerarlos, ya que el sistema parece no estar en equilibrio.

Este planeta requiere algo de búsqueda. Para localizarlo hay que valerse de cartas de ubicación específicas o de software capaz de mostrar a Neptuno junto con el fondo de estrellas. Puede encontrarse con binoculares si se sabe dónde buscar. Al igual que Júpiter y Saturno se trata de un planeta gaseoso, pero al estar mucho más alejado del Sol y de la Tierra su brillo no es muy alto y sus características atmosféricas no son apreciables con telescopios de aficionado.

La mejor época para observar Neptuno es en las proximidades de la oposición. No obstante, puede observarse con mayor o menor dificultad desde unos meses antes hasta unos meses después. Para saber si es visible o no en un momento determinado, puede utilizarse un planisferio para determinar si la constelación de Capricornio se halla sobre el horizonte.

Finalmente, cabe destacar que, debido a la posición de Neptuno con respecto a la Tierra, los observadores del hemisferio Sur están favorecidos, ya que en el Norte el planeta está muy bajo sobre el horizonte.

Neptuno es invisible a simple vista, y su tamaño aparente es tan pequeño que si se observa con pocos aumentos —lo cual es necesario cuando se está buscando un objeto— es tan diminuto que parece una estrella. Por este motivo, para poder localizarlo es necesario el uso de uno de los dos métodos que se han descrito en la sección de cielo profundo:





</doc>
<doc id="1985" url="https://es.wikipedia.org/wiki?curid=1985" title="Netscape Communications Corporation">
Netscape Communications Corporation

Netscape Communications Corporation es una empresa de software famosa por ser la creadora del navegador web Netscape Navigator. Fue comprada por AOL en 1999.

La compañía fue fundada como Mosaic Communications Corporation el 4 de abril de 1994 por Marc Andreessen y Jim Clark. Fue una de las primeras compañías en trabajar con la naciente World Wide Web. Lanzó un navegador llamado Mosaic Netscape 0.9 el 13 de octubre de 1994. Este navegador fue posteriormente renombrado como Netscape Navigator.
La compañía cambió de nombre a "Netscape Communications Corporation" el 14 de noviembre de 1994.

Microsoft lanzó la versión 1.0 de Internet Explorer (IE) como parte del Pack Plus de Windows 95, según Spyglass (el desarrollador de Internet Explorer), este no fue tomado de Netscape como comúnmente se cree, pero había una parte de Mosaic en él.

Después de esto, Microsoft lanzó sucesivamente una serie de IE, y tanto Netscape como Internet Explorer fueron agregando nuevas funcionalidades, aunque éstas no siempre funcionaban correctamente.

Esto fue conocido como la guerra de navegadores, en la que ambas compañías destinaban gran cantidad de recursos en sus navegadores para que uno fuera mejor que otro, pero Internet Explorer empezó a llevar la delantera debido a las grandes cantidades de dinero invertidas en él y la decisión de incluir el navegador por defecto en Microsoft Windows. En tanto, los usuarios empezaron a reclamar por la gran cantidad de errores y problemas que estos experimentaban debido a la gran rapidez de su desarrollo, por lo que la nueva prioridad fue hacer que los navegadores funcionaran bien, en vez de agregarles nuevas funcionalidades.

En enero de 1998, cuando Netscape empezó el proyecto de código abierto Mozilla. Netscape, sabiendo que Internet Explorer era de lejos el Navegador más usado, publicó el código fuente de Netscape, con la esperanza de que se convirtiera en un popular proyecto de código abierto. Este código fue puesto bajo la Licencia Pública Netscape, la cual es similar a la GNU General Publical License, para el Communicator 4.5 Netscape se enfocó en que pudiera enviar correos electrónicos y fuera funcional para las empresas.

America Online (AOL) anunció el 24 de noviembre que adquiriría Netscape Communications en 4.200 millones de US$, aunque dicen que AOL estaba más interesado en otras propiedades de Netscape más que en el navegador en sí.

El 14 de noviembre de 2000, AOL lanzó Netscape 6.0 basado en Mozilla 0.6 (La versión 5 fue saltada). Desafortunadamente, Mozilla 0.6 estaba lejos todavía de ser estable, por lo que el efecto de Netscape 6.0 fue el alejar más aún a los usuarios de la marca Netscape. No fue hasta agosto de 2001 cuando Netscape 6.1 apareció basado en Mozilla 0.9.2 que era bastante más robusto y casi un año después llegó el Netscape 7.0 (unos días después de haber sido lanzado Netscape Communicator 4.8, mostrando que los esfuerzos de los desarrolladores de Netscape seguían divididos).

Después del caso en el que Microsoft fue hallado culpable de abuso de poder de monopolio y fue sentenciado a pagar 750 millones de US$ a AOL y a compartir algunas tecnologías, incluyendo dejar a AOL licenciar y distribuir Internet Explorer gratis por 7 años. Esto fue considerada como la "Muerte de Netscape".

El 15 de julio de 2003 AOL se deshizo de la marca Netscape, sacó el logo de su edificio y despidió a la mayoría de los programadores.

En la actualidad Netscape es sólo una marca dentro de AOL, que es usada para brindar Internet a poco costo. AOL contrató a una empresa canadiense para lanzar Netscape 8.0 basado en Mozilla Firefox.

Tom Drapeau, director de la compañía, anunció que a partir del 1 de febrero de 2008, Netscape dejaría de recibir actualizaciones. El 28 de enero se anunció que se extendería por un mes más el soporte y desarrollo. La historia de Netscape y Netscape Communications Corporation finaliza con el lanzamiento de la versión 9.0.0.6, el 20 de febrero de 2008 (aunque oficialmente finaliza el 1 de marzo de 2008)

Algunas personas piensan que esta estrategia fue para opacar a Microsoft y brindar apoyo a la Fundación Mozilla.

La línea inicial de productos Netscape:


Otros productos Netscape:



</doc>
<doc id="1987" url="https://es.wikipedia.org/wiki?curid=1987" title="Nivel de dominio de las proteínas">
Nivel de dominio de las proteínas

Nivel de dominio de las proteínas, se define como una unidad compacta, de características globulares, que suele comprender entre 30-150 aminoácidos y se considera que esta conformación está determinada por la secuencia de aminoácidos.

Es una ordenación de fragmentos de estructura secundaria en una estructura terciaria y se estabiliza por enlaces de hidrógeno entre cadenas.


</doc>
<doc id="1988" url="https://es.wikipedia.org/wiki?curid=1988" title="Neutrón (juego)">
Neutrón (juego)

Neutrón un juego abstracto de dos personas. Requiere un tablero de 5x5, y 5 fichas para cada jugador, llamadas Electrones, blancas y negras. Además hay una ficha roja, el Neutrón, compartida por ambos jugadores.

Blanco mueve primero, y siguen jugando alternadamente. En su turno el jugador debe mover siempre dos fichas, en este orden estricto:
Tanto el Neutrón como las demás fichas, llamadas Electrones, pueden ser movidas, en cualquier dirección (horizontal, vertical o diagonal), y es obligatorio desplazarlas lo más posible en la dirección elegida, pero sin ir a ocupar ni saltar por encima de una casilla ya ocupada. Es decir, que después de elegida una dirección de desplazamiento, la ficha debe ser movida todo lo posible en tal dirección, hasta quedar su paso bloqueado por otra ficha cualquiera o por el borde del tablero.

En su turno, el jugador puede elegir una dirección de desplazamiento para el Neutrón y otra dirección para su ficha. Tanto el Neutrón como la ficha propia deben moverse al menos una casilla.
No hay capturas.

Gana el primero que consigue llevar el Neutrón a cualquier casilla libre de su línea de partida.
Un jugador pierde si se ve forzado a llevar el Neutrón hacia una casilla de la línea de partida adversaria. También pierde si la situación está bloqueada y en su turno no puede mover el Neutrón o, si después de mover el Neutrón, no puede mover ninguna de sus fichas.

"Comienza el turno de las Blancas. Ganan llevando el Neutrón a su línea de partida"


</doc>
<doc id="1989" url="https://es.wikipedia.org/wiki?curid=1989" title="Neurología">
Neurología

La neurología (del griego clásico νεῦρον, «nervio» y del sufijo -λογία, «estudio de») es la especialidad médica que trata los trastornos del sistema nervioso. Específicamente se ocupa de la prevención, diagnóstico, tratamiento y rehabilitación de todas las enfermedades que involucran al sistema nervioso central, sistema nervioso periférico y el sistema nervioso autónomo. Existen gran número de enfermedades neurológicas, las cuales pueden afectar el sistema nervioso central (cerebro y espina dorsal), el sistema nervioso periférico, o el sistema nervioso autónomo.

Thomas Willis fue un médico inglés, figura esencial en la historia de la anatomía, la fisiología y la neurología, fue pionero en sus investigaciones neuroanatómicas. En 1662 fue uno de los fundadores de la Royal Society. En su obra "Cerebri Anatome", Willis subrayó la importancia del estudio comparativo de la estructura del cerebro, determinando las semejanzas entre el cerebro del ser humano y el de otros mamíferos, así como entre el cerebro de los pájaros y los peces. Su más notable descubrimiento fue el Círculo de Willis un círculo de arterias en la base del cerebro. 
En 1667 publicó "Pathologicae cerebri, et nervosi generis specimen" un importante trabajo en la patología y neurofisiología del cerebro. En este, el desarrolla una nueva teoría de la causa de la epilepsia y de otras enfermedades convulsivas y contribuyo al desarrollo de la psiquiatría.

Jean-Martin Charcot es conocido como el fundador de la neurología moderna, puso en evidencia la relación existente entre las lesiones de ciertas partes del cerebro y la afectación de las habilidades motrices. Nombró y fue el primero en describir la esclerosis múltiple, resumiendo reportes previos, adicionando sus propias observaciones clínicas y patológicas. También observó cambios cognoscitivos, describiendo a sus pacientes como si sufrieran una «marcada debilitación de la memoria» y «concepciones que se forman lentamente». Investigó las funciones de diferentes partes del cerebro y el papel que tienen las arterias en la hemorragia cerebral. Entre 1868 y 1881 los estudios de Charcot fueron un punto de referencia en el entendimiento de la enfermedad de Parkinson. Entre otros avances el realizó la distinción entre rigidez, debilidad y bradicinesia.

Fundó la escuela de neurología del Hôpital de la Salpêtrière, donde impartió clases,de las que recoge una muestra importante en su obra (en tres volúmenes) "Leçons sur les maladies du système nerveux faites à la Salpêtrière" que fueron publicadas entre 1885 y 1887. Freud fue uno de sus alumnos, así como Joseph Babinski, Gilles de la Tourette, Gilbert Ballet y Jean Leguirec inventor del método Benedicte. Médicos de muchos países acudieron a trabajar con él y recibir sus lecciones. Fueron relevantes sus investigaciones sobre la histeria.

Edward Flatau fue un neurólogo y psiquiatra polaco, cofundador de la moderna neurología de Polonia, autoridad en la fisiología y la patología de la meningitis. Cofundador de las revistas médicas "Neurologia Polska" y "Warszawskie Czasopismo Lekarskie". Estableció el principio de la localización de las fibras largas en la médula espinal en 1893, y con Sterling (1911) publicó un documento de principios en espasmo de torsión progresiva en los niños y sugirieron que la enfermedad tenía un componente genético y en 1912 escribió un libro fundamental sobre la migraña.

En 1894 publicó el "Atlas del Cerebro Humano" "y el trayecto del nervio-fibras", se basan en fotografías de larga exposición de las secciones del cerebro frescos (hasta 10 minutos para plana y 30 minutos para superficies irregulares, por medio de pequeños diafragmas). Estos estudios se llevaron a cabo en Berlín con el profesor Emanuel Mendel.


El objetivo del método clínico en la neurología es servir como base para el tratamiento o la prevención de alguna enfermedad neurológica. En la mayoría de los casos el método consiste en cinco etapas, las cuales son:

El método precedente para el diagnóstico de las enfermedades neurológicas puede verse resumido en el diagrama colocado en esta sección. Este enfoque sistemático permite identificar de manera confiable la localización y a menudo el diagnostico preciso de la enfermedad. Cabe recordar que no siempre es necesario plantear de esta forma la solución a un problema clínico, ya que algunas enfermedades neurológicas tienen cuadros clínicos muy característicos.

Durante un examen neurológico, el neurólogo revisa la historia médica del paciente, con especial atención a sus condiciones recientes. Después le realiza un test neurológico. Normalmente, este test mide el estado mental, funciones de los nervios craneales (incluyendo la visión), fuerza, coordinación, reflejos y sensaciones. Esta información ayuda al neurólogo a determinar si el problema se halla en el sistema nervioso y su localización clínica. La localización de la patología es la clave del proceso por el cual los neurólogos desarrollan sus diferentes diagnósticos. Pueden ser necesarios estudios posteriores para confirmar el diagnóstico, y finalmente una guía y terapia apropiada.

La exploración neurológica se inicia con la exploración del paciente en tanto se practica el interrogatorio. La manera en que el paciente cuenta su enfermedad puede manifestar confusión o incoherencia del pensamiento, trastornos de la memoria o del juicio e incluso dificultades para comprender o expresar ideas.El resto de la exploración neurológica debe efectuarse como la última parte de la exploración física general a partir de, como ya se mencionó, la exploración de nervios craneales, cuello y tronco hasta terminar con las pruebas de las funciones motora, refleja y sensitiva de las extremidades superiores e inferiores.

Dicha exploración debe modificarse según el estado del paciente. Desde luego muchas partes de la exploración no pueden efectuarse en el paciente comatoso; niños pequeños y lactantes o pacientes con padecimientos psiquiátricos necesitan explorarse de maneras especiales.









Los neurólogos son responsables del diagnóstico, tratamiento y manejo de todas las condiciones mencionadas arriba. Cuando la intervención quirúrgica es requerida, el neurólogo puede referirse al paciente como "neuropaciente". En algunos países, algunas responsabilidades legales de un neurólogo pueden incluir efectuar un diagnóstico de muerte cerebral si el paciente fallece. Suelen tratar personas con enfermedades congénitas si la mayor parte de manifestaciones son neurológicas. Las punciones lumbares también pueden ser realizadas por estos profesionales. Algunos neurólogos desarrollan un interés a sub-campos en particular como las enfermedades cerebrovasculares, los trastornos del movimiento, epilepsia, cefaleas, neurología de la conducta y demencias, trastornos del sueño, control de dolor crónico, esclerosis múltiple o enfermedades neuromusculares.

Hay superposición de otras especialidades, variando de país en país e incluso en un área geográfica local. El traumatismo craneoencefálico (ETC) agudo es más comúnmente tratado por neurocirujanos, mientras que secuelas de traumas craneoencefálicos pueden ser tratados por neurólogos o especialistas en rehabilitación médica. Aunque los casos de accidente cerebro vascular (ACV) han sido tradicionalmente tratados por médicos internistas u hospitalarios, el surgimiento de neurología vascular y neurólogos intervencionistas han creado una demanda para especialistas en ACV.

La organización de JHACO centro certificado en accidentes cerebro vasculares ha incrementado el papel de los neurólogos en el tratamiento de accidentes cerebro vasculares en muchos centros de atención primaria, así como en hospitales de tercer nivel. Algunos casos de enfermedades infecciosas del sistema nervioso son tratados por especialistas en enfermedades infecciosas. La mayoría de los casos de dolor de cabeza son diagnosticados y tratados principalmente por médicos generales, al menos los casos menos severos. Del mismo modo, la mayoría de los casos de ciática y otras radiculopatías mecánicas son atendidos por médicos generales, aunque pueden ser enviados a neurólogos o cirujanos (neurocirujanos o cirujanos ortopédicos). Los trastornos del sueño generalmente son tratados en unidades multidisciplinares en las que participan neurólogos, neumólogos y psiquiatras. Una parálisis cerebral es inicialmente atendida por pediatras, pero el tratamiento puede ser transferido a un neurólogo de adultos después de que el paciente alcanza una cierta edad. 

Los neuropsicólogos clínicos son usualmente consultados para realizar una evaluación funcional del comportamiento y funciones cognitivas superiores, relacionada con la asistencia en diagnósticos diferenciales, la planificación de estrategias de rehabilitación, el registro de fuerzas y debilidades cognitivas, y la medición de cambios en el tiempo (por ejemplo, para identificar anomalías de envejecimiento o llevando el progreso de una demencia).

En algunos países como Estados Unidos y Alemania, los neurólogos se pueden especializar en neurofisiología clínica, en electroencefalografía, o en el estudio de la conducción nerviosa, en Electromiografías y potenciales evocados. En otros países, es una especialidad independiente (por ejemplo en el Reino Unido y Suecia).

A pesar de que las enfermedades mentales son consideradas por algunos de ser desórdenes neurológicos afectando el sistema nervioso central, tradicionalmente se las clasifica por separado, y son tratadas por psiquiatras. En el año 2002, en una reseña del "American Journal of Psychiatry", el profesor Joseph B. Martin, decano de Harvard Medical School y neurólogo de profesión, escribió que: «la división en dos categorías es arbitraria, a menudo influenciada por creencias más que por observaciones científicas verificables. Y el hecho de que el cerebro y la mente sean uno solo, hace que esta división sea solamente artificial de todas formas». Esta perspectiva ha propiciado un progresivo acercamiento entre ambas especialidades en las últimas dos décadas, que finalmente se materializó en 2004 con el reconocimiento, en EEUU, de la subespecialidad en 'Neurología de la conducta y Neuropsiquiatría'. Actualmente, los médicos de esta subespecialidad se encargan del estudio, diagnóstico y tratamiento de las alteraciones de la conducta y los trastornos mentales atribuibles a enfermedades neurológicas. 

Las enfermedades neurológicas a menudo tienen manifestaciones psiquiátricas, como por ejemplo psicosis, depresión, manía y ansiedad. Estos síndromes neuropsiquiátricos son relativamente habituales en pacientes con ictus, enfermedad de Huntington, Parkinsonismos, enfermedad de Alzheimer, enfermedad por cuerpos de Lewy, enfermedad de Pick, encefalitis infecciosas, encefalitis autoinmunes, así como en algunos tipos de epilepsia, por nombrar solo algunas.

De todos los cambios vinculados con la edad tienen una enorme importancia los que tiene el sistema nervioso, algunos signos neurológicos del envejecimiento son: los signos neurooftalmológicos, pérdida de la audición perceptiva progresiva, disminución del sentido del olfato y menor extensión del gusto, reducción de la velocidad y magnitud de actividad motora, tiempo de reacción lento, trastornos de coordinación y agilidad, reducción de la fuerza muscular y adelgazamiento de los músculos, cambios de los reflejos tendinosos y finalmente trastornos del sentido de vibración en los dedos de los pies y en tobillos.
El emergente campo de la neurología cosmética señala el potencial de terapias para mejorar cuestiones como la eficacia laboral, la atención en la escuela, y una mayor felicidad en la vida personal. A pesar de todo, este campo ha dado también lugar a preguntas acerca de la neuroética o la psicofarmacología.






</doc>
<doc id="1991" url="https://es.wikipedia.org/wiki?curid=1991" title="Najadaceae">
Najadaceae

Najadaceae es una familia de liliopsidas del orden Najadales.

En algunos sistemas está incluida en la familia Hydrocharitaceae.

La familia de Najadáceas es una familia de plantas monocotiledóneas. En la clasificación tradicional (1981) que incluye 50 especies del género de las Najas.

Ellas son acuáticas herbáceas, sumergidas en las regiones frías a tropicales.

En la clasificación filogenética APG II (2003) y la clasificación filogenética APG III (2009) esta familia no existe: las plantas de esta familia se incorporan a las hydrocharitáceas.






</doc>
<doc id="1993" url="https://es.wikipedia.org/wiki?curid=1993" title="Noctiluca">
Noctiluca

La noctiluca (del latín "nox, noctis", noche + "lūcēre", brillar) es un organismo unicelular marino que la biología incluye dentro del género de los protistas dinoflagelados, dentro de la clase Noctiluciphyceae y el orden de los Noctilucales. 

Posee dos flagelos heterocontos en el sulcus y el cíngulo. Las células que componen a este protozoo son vesiculosas, frecuentemente vacuolizadas, y tanto los flagelos como los surcos son rudimentarios. Presenta asimismo un tentáculo móvil que usa para capturar presas.
En ocasiones presenta adheridas algas simbióticas. Estas algas tienen una enzima que, cuando reacciona con oxígeno, provoca un destello de luz bioluminiscente, de la que el organismo recibe su nombre.

"Noctiluca scintillans" está relacionado simbióticamente a "Pedinomonas noctilucae", un alga verde Pedinophyceae, la cual puede situarse internamente o estar adherida externamente.


</doc>
<doc id="1996" url="https://es.wikipedia.org/wiki?curid=1996" title="Narduroides salzmannii">
Narduroides salzmannii

Narduroides es un género monotípico de planta herbácea, perteneciente a la familia de las poáceas. Su única especie: Narduroides salzmannii (Boiss.) Rouy, es originaria de la región del Mediterráneo.

Son plantas anuales. Hojas con vaina de márgenes libres; lígula membranosa, entera, a veces lacerada; limbo al principio plano, después convoluto y filiforme. Inflorescencia en racimo espiciforme, rara vez ramificado en su base. Espiguillas comprimidas lateralmente, cortamente pedunculadas, con 4-6 flores hermafroditas; raquilla ciliada, desarticulándose en la madurez. Glumas 2; subiguales, más cortas que las flores, oblongas u oblongo-lanceoladas, agudas, coriáceas, con margen escarioso estrecho, glabras; la inferior con 1-3 nervios; la superior con 3-5 nervios. Lema oblonga u oblongo-lanceolada, papirácea, con dorso redondeado, 5 nervios poco marcados y margen escarioso estrecho. Pálea membranosa con 2 quillas. Lodícula lanceoladas, bilobadas. Androceo con 3 estambres. Ovario glabro. Cariopsis linear o fusiforme, trígona, glabra.

"Narduroides salzmannii" fue descrito por (Boiss.) Rouy y publicado en "Fl. France (Rouy & Foucaud)" 14: 301. 1913 
El nombre del género deriva de "Nardus", otro género de la misma familia.
El número de cromosomas es de: x = 7. 2n = 14. 2 ploidias.





</doc>
<doc id="1997" url="https://es.wikipedia.org/wiki?curid=1997" title="Nardus">
Nardus

Nardus es un género de gramíneas europeas de la familia de las poáceas. Antiguamente se incluían más especies, pero en la actualidad solamente se acepta "Nardus stricta". 



</doc>
<doc id="1999" url="https://es.wikipedia.org/wiki?curid=1999" title="Nibble">
Nibble

Nibble, Cuado o Cuarteto es el conjunto de cuatro dígitos binarios ("bits") o medio octeto.

Su interés se debe a que cada cifra en hexadecimal (0, 1, 2..., 9, A, B, C, D, E, F) se puede representar con un cuarteto, puesto que 2 elevado a la 4 es 16 (2=16). También el cuarteto es la base del sistema de codificación BCD.

A continuación se muestra la correspondencia entre las dieciséis cifras hexadecimales y sus correspondientes representaciones binarias en forma de cuarteto ( = hexadecimal, = octal, = decimal):

De acuerdo con la anterior correspondencia, es posible codificar números decimales o hexadecimales en BCD según se muestra en los siguientes ejemplos:




Un "byte" completo está representado por dos dígitos hexadecimales, por tanto, es común visualizar un "byte" de información como dos "nibbles". El "nibble" a menudo se llama semiocteto o cuarteto en un contexto de redes o telecomunicaciones. En inglés hay un juego de palabras gastronómico con "nibble" (que significa mordisqueo), en comparación con "bite"/"byte" (bocado) y "bit" (trozo pequeño).

También podemos encontrar aplicaciones binarias interesantes como el "Tratado Sobre las Células Binarias" creado por el español Pedro Luis Asensio Álvarez, que trata sobre las propiedades, evoluciones genéticas, relaciones externas y creaciones espontáneas de estos números o "bits" en un medio tecnológico creado por el hombre.

El "nibble" se utiliza para describir la cantidad de memoria utilizada para almacenar un dígito de un número almacenado en BCD en una mainframe de IBM. Esta técnica se utiliza para reducir los requisitos de espacio, haciendo la computación más rápida y la depuración más sencilla. Un "byte" de 8 "bits" es dividido en mitades y cada "nibble" se utiliza para almacenar un dígito. El último "nibble" de la variable se reserva para el signo. Así una variable que puede almacenar más de nueve dígitos se "empaquetaría" en 5 "bytes". Fácil de depurar resultaban los números que son legibles en un hex dump, donde dos números hexadecimales se utilizan para representar el valor de un "byte", ya que 16×16 = 2 = 256.

Históricamente, ha habido casos donde el término ""nybble"" se ha utilizado para un conjunto de "bits" inferior a 8, pero no necesariamente 4. En la línea Apple II, muchos de los drivers de control de disco se implementaron en software. La escritura de datos en disco se hizo convirtiendo páginas de 256 "bytes" en conjuntos de 5 "bits", o después en "nibbles" de 6 "bits". Los datos cargados del disco necesitaban lo contrario. Hay que notar que el término "byte" también tiene esta ambigüedad, a la vez, "byte" significa un conjunto de "bits" pero no necesariamente 8.

Hoy, los términos ""byte"" y ""nibble"" generalmente se refieren a colecciones de 8 y 4 "bits" respectivamente y no se utilizan a menudo para otros tamaños. El "nibble" se usa también cuando aparecen los primeros microprocesadores a principios de los años 1970, ya que dichos dispositivos trabajaban con microinstrucciones las cuales estaban constituidas por grupos de 4 "bits". Sin embargo, cuando llega la comercialización de los microprocesadores, éstos ya pueden trabajar con grupos de 8 "bits" y es así como inicia la popularidad del "byte" en el ámbito de los sistemas digitales y de la informática. En algunos lenguajes, un "nibble" es llamado un "tetrade" —del griego "tetra" ("cuatro")—. Esta utilización refleja el número de "bits" —cuatro— en medio "byte" (considerando 1 "byte" = 8 "bits").





</doc>
<doc id="2000" url="https://es.wikipedia.org/wiki?curid=2000" title="Navegador web">
Navegador web

Un navegador web (en inglés, web browser) es un software, aplicación o programa que permite el acceso a la Web, interpretando la información de distintos tipos de archivos y sitios web para que estos puedan ser visualizados.

La funcionalidad básica de un navegador web es permitir la visualización de documentos de texto, posiblemente con recursos multimedia incrustados. Además, permite visitar páginas web y hacer actividades en ella, es decir, enlazar un sitio con otro, imprimir, enviar y recibir correo, entre otras funcionalidades más.

Los documentos que se muestran en un navegador pueden estar ubicados en la computadora donde está el usuario y también pueden estar en cualquier otro dispositivo conectado en la computadora del usuario o a través de Internet, y que tenga los recursos necesarios para la transmisión de los documentos (un "software" servidor web).

Tales documentos, comúnmente denominados páginas web, poseen hiperenlaces o hipervínculos que enlazan una porción de texto o una imagen a otro documento, normalmente relacionado con el texto o la imagen.

El seguimiento de enlaces de una página a otra, ubicada en cualquier computadora conectada a Internet, se llama "navegación", de donde se origina el nombre navegador (aplicado tanto para el programa como para la persona que lo utiliza, a la cual también se le llama "cibernauta"). Por otro lado, "hojeador" es una traducción literal del original en inglés, "browser", aunque su uso es minoritario.

El primer navegador fue desarrollado por Tim Berners-Lee, en la CERN, a finales de 1990 y principios de 1991; el navegador web llamado WorldWideWeb era bastante sofisticado y gráfico, pero solo funcionaba en estaciones NeXT.

El navegador Mosaic, que funcionaba inicialmente en entornos Unix sobre XFree86 (X11), fue el primero que se extendió debido a que pronto el National Center for Supercomputing Applications (NCSA) preparó versiones para Windows y Macintosh.

Sin embargo, Netscape Navigator al poco tiempo entró en el mercado y rápidamente superó en capacidades y velocidad al Mosaic. Este navegador tuvo la ventaja de funcionar en casi todos los sistemas Unix, y también en entornos Windows.

Internet Explorer (anteriormente Spyglass Mosaic) fue la apuesta tardía de Microsoft para entrar en el mercado y consiguió desbancar al Netscape Navigator entre los usuarios de Windows, debido a la integración del navegador con el sistema operativo y al hecho de que era gratuito, mientras que Netscape tenía costo, llegando a poseer cerca del 95% de la cuota de mercado. Netscape Communications Corporation liberó el código fuente de su navegador, naciendo así el proyecto Mozilla. 

Finalmente Mozilla (Mozilla Application Suite) fue reescrito desde cero tras decidirse a desarrollar y usar como base un nuevo conjunto de "widgets" multiplataforma basado en "Extensible Markup Language" (XML) llamado XUL y esto hizo que tardara bastante más en aparecer de lo previsto inicialmente, apareciendo una versión 1.0 de gran calidad y para muchísimas plataformas a la vez el 5 de junio de 2002.

El 7 de enero de 2003, Apple lanzó al mercado el navegador web Safari. Este navegador se hace con casi la totalidad del mercado de las microcomputadoras Mac, debido a su velocidad y gran cantidad de actualizaciones. Asimismo, también entra al mercado del sistema operativo Windows.

A finales de 2004 aparece en el mercado Mozilla Firefox, una rama de desarrollo de Mozilla que pretende hacerse con parte del mercado de Internet Explorer. Se trata de un navegador más ligero que su hermano mayor.

El 2 de septiembre de 2008, Google Chrome aparece en el mercado. Es el navegador web desarrollado por Google y compilado con base en componentes de código abierto como el motor de renderizado de WebKit y su estructura de desarrollo de aplicaciones ("framework"). Está disponible gratuitamente bajo condiciones de servicio específicas. El nombre del navegador deriva del término usado para el marco de la interfaz gráfica de usuario ("chrome"). En diciembre de 2011, Chrome superó a Internet Explorer 8.0 como el navegador más utilizado a nivel mundial.

El 29 de julio de 2015, Microsoft lanza Microsoft Edge como sucesor de Internet Explorer. Es una versión mejorada, modernizada y distinta de Internet Explorer con una línea de desarrollo independiente. El navegador se encuentra disponible para iOS, Android 4.4+ y Windows 10 (PC, Mobile, Xbox One, HoloLens). Tiene varias funciones únicas, como lectura de ebooks integrada, función para agregar notas web con Windows Ink y "Continuar en PC", una herramienta en la que se puede continuar la navegación web y la sincronización entre el PC y el teléfono.

La comunicación entre el servidor web y el navegador se realiza mediante el protocolo de comunicaciones "Hypertext Transfer Protocol" (HTTP), aunque la mayoría de los navegadores soportan otros protocolos como "File Transfer Protocol" (FTP), Gopher, y "Hypertext Transfer Protocol Secure" (HTTPS, una versión cifrada de HTTP basada en "Secure Socket Layer" —SSL— o Capa de Conexión Segura).

La función principal del navegador es descargar documentos HTML y mostrarlos en pantalla. En la actualidad, no solamente descargan este tipo de documentos sino que muestran con el documento sus imágenes, sonidos e incluso vídeos en transmisión en diferentes formatos y protocolos. Además, permiten almacenar la información en el disco o crear marcadores ("bookmarks") de las páginas más visitadas.

Algunos de los navegadores web más populares se incluyen en lo que se denomina una "suite" de internet o paquete de Internet. Estos paquetes de Internet disponen de varios programas integrados para leer noticias de Usenet y correo electrónico mediante los protocolos "Network News Transport Protocol" (NNTP), "Internet Message Access Protocol" (IMAP) y "Post Office Protocol" (POP).

Los primeros navegadores web solo soportaban una versión muy simple de HTML. El rápido desarrollo de los navegadores web propietarios condujo al desarrollo de dialectos no estándares de HTML y a problemas de interoperabilidad en la web. Los más modernos (como Chrome, Amaya, Firefox, Netscape, Opera e Internet Explorer 9.0) soportan los estándares HTML y XHTML (comenzando con HTML 4.01, los cuales deberían visualizarse de la misma manera en todos ellos).

Los estándares web son un conjunto de recomendaciones dadas por el World Wide Web Consortium' (W3C) y otras organizaciones internacionales acerca de cómo crear e interpretar documentos basados en la web. Su objetivo es crear una web que trabaje mejor para todos, con sitios accesibles a más personas y que funcionen en cualquier dispositivo de acceso a Internet.

Existe una lista detallada de navegadores, motores de renderización y otros temas asociados en la .



Listado de los primeros navegadores con interfaz gráfica de usuario (GUI) que ya no están en desarrollo:





</doc>
<doc id="2002" url="https://es.wikipedia.org/wiki?curid=2002" title="Número">
Número

Un número, en ciencia, es una abstracción que representa una cantidad o una magnitud. En matemáticas un número puede representar una cantidad métrica o más generalmente un elemento de un sistema numérico o un número ordinal que representará una posición dentro de un orden de una serie determinada. Los números complejos son usados como una herramienta útil para resolver problemas algebraicos y que algebraicamente son un mero añadido a los números reales que a su vez ampliaron el concepto de número ordinal. Sobre todo, un número real resuelve el problema de comparación de dos medidas: tanto si son conmensurables o inconmensurables. Ejemplo: el lado de un cuadrado es conmensurable con su perímetro, pero el lado del cuadrado con la diagonal del mismo son inconmensurables.

También, en sentido amplio, indica el carácter gráfico que sirve para representarlo; dicho signo gráfico de un número recibe propiamente la denominación de numeral o cifra. El que se escribe con un solo guarismo se llama dígito.

El concepto de número incluye abstracciones tales como números fraccionarios, negativos, irracionales, trascendentales, complejos y también números de tipo más abstracto como los números hipercomplejos que generalizan el concepto de número complejo o los números hiperreales, los superreales y los surreales que incluyen a los números reales como subconjunto.

Los números más conocidos son los números naturales. Denotados mediante formula_1, son conceptualmente los más simples y los que se usan para contar unidades discretas. Estos, conjuntamente con los números negativos, conforman el conjunto de los enteros, denotados mediante formula_2 (del alemán "Zahlen" 'números'). Los números negativos permiten representar formalmente deudas, y permiten generalizar la resta de cualesquiera dos números naturales.

Otro tipo de números ampliamente usados son números fraccionarios, y tanto cantidades inferiores a una unidad, como números mixtos (un conjunto de unidades más una parte inferior a la unidad). Los números fraccionarios pueden ser expresados siempre como cocientes de enteros. El conjunto de todos los números fraccionarios es el conjunto de los números racionales (que usualmente se define para que incluya tanto a los racionales positivos, como a los racionales negativos y el cero). Este conjunto de números se designa como formula_3.

Los números racionales permiten resolver gran cantidad de problemas prácticos, pero desde los antiguos griegos se conoce que ciertas relaciones geométricas (la diagonal de un cuadrado de lado unidad) son números no enteros que tampoco son racionales. Igualmente, la solución numérica de una ecuación polinómica cuyos coeficientes son números racionales, usualmente es un número no racional. Puede demostrarse que cualquier número irracional puede representarse como una sucesión de Cauchy de números racionales que se aproximan a un límite numérico. El conjunto de todos los números racionales y los irracionales (obtenidos como límites de sucesiones de Cauchy de números racionales) es el conjunto de los números reales formula_4. Durante un tiempo se pensó que toda magnitud física existente podía ser expresada en términos de números reales exclusivamente. Entre los reales, existen números que no son soluciones de una ecuación polinomial o algebraica, que reciben el nombre de transcendentales. Ejemplos famosos de estos números son el número π (Pi) y el número e (este último base de los logaritmos naturales), los cuales están relacionados entre sí por la identidad de Euler.

Uno de los problemas de los números reales es que no forman un cuerpo algebraicamente cerrado, por lo que ciertos problemas no tienen solución planteados en términos de números reales. Esa es una de las razones por las cuales se introdujeron los números complejos formula_5, que son el mínimo cuerpo algebraicamente cerrado que contiene a los números reales. Además algunas aplicaciones prácticas así como en las formulaciones estándar de la mecánica cuántica se considera útil introducir los números complejos. Al parecer la estructura matemática de los números complejos refleja estructuras existentes en problemas físicos, por lo que en física teórica y en diversas aplicaciones los números complejos se usan en pie de igualdad con los números reales, a pesar de que inicialmente fueron considerados únicamente como un artificio matemático sin relación con la realidad física. Todos los conjuntos de números formula_6 fueron de alguna manera "descubiertos" o sugeridos en conexión con problemas planteados en problemas físicos o en el seno de la matemática elemental y todos ellos parecen tener importantes conexiones con la realidad física.

Fuera de los números reales y complejos, claramente conectados con problemas de las ciencias naturales, existen otros tipos de números que generalizan aún más y extienden el concepto de número de una manera más abstracta y responden más a creaciones deliberadas de matemáticos. La mayoría de estas generalizaciones del concepto de número se usan sólo en matemáticas, aunque algunos de ellos han encontrado aplicaciones para resolver ciertos problemas físicos. Entre ellos están los números hipercomplejos que incluyen a los cuaterniones útiles para representar rotaciones en un espacio de tres dimensiones, y generalizaciones de estos como octoniones y los sedeniones.

A un nivel un poco más abstracto también se han ideado conjuntos de números capaces de tratar con cantidades infinitas e infinitesimales como los hiperreales y los transfinitos. 

La teoría de los números trata básicamente de las propiedades de los números naturales y los enteros, mientras que las operaciones del álgebra y el cálculo permiten definir la mayor parte de los sistemas numéricos, entre los cuales están:

En álgebra abstracta y análisis matemático un sistema numérico se caracteriza por una: 


Otra propiedad interesante de muchos conjuntos numéricos es que son representables mediante diagramas de Hasse, diagramas de Euler y diagramas de Venn, pudiéndose tomar una combinación de ambos en un diagrama de Euler-Venn con la forma característica de cuadrilátero y además pudiéndose representar internamente un diagrama de Hasse (es una recta). Tanto históricamente como conceptualmente, los diversos conjuntos numéricos, desde el más simple de los números naturales, hasta extensiones trascentes de los números reales y complejos, elaboradas mediante la teoría de modelos durante el siglo XX, se construyen desde una estructura más simple hasta otra más compleja.

El estudio de ciertas propiedades que cumplen los números ha producido una enorme cantidad de tipos de números, la mayoría sin un interés matemático específico. A continuación se indican algunos:

Una vez entendido el problema de la naturaleza y la clasificación de los números, surge otro, más práctico, pero que condiciona todo lo que se va a hacer con ellos: la manera de escribirlos. El sistema que se ha impuesto universalmente es la numeración posicional, gracias al invento del cero, con una base constante. 

Más formalmente, en "The concept of number", el matemático Frege realiza una definición de «número», la cual fue tomada como referencia por muchos matemáticos (entre ellos Russell, cocreador de "principia mathematica"):

Véase también que Frege, tanto como cualquier otro matemático, se ven inhabilitados para definir al número como la expresión de una cantidad, porque la simbología matemática no hace referencia necesaria a la numerabilidad, y el hecho de «cantidad» referiría a algo numerable, mientras que números se adoptan para definir la cardinalidad de, por ejemplo, los elementos que se encuentran en el intervalo abierto (0, 1), que contiene innumerables elementos (el continuo).

Peano, antes de establecer sus cinco proposiciones sobre los números naturales, explicita que supone sabida una definición (quizás debido a su «obviedad») de las palabras o conceptos "cero", "sucesor" y "número". De esta manera postula:

Sin embargo, si uno define el concepto "cero" como el número 100, y el concepto "número" como "los números mayores a 100", entonces las cinco proposiciones mencionadas anteriormente aplican, no a la idea que Peano habría querido comunicar, sino a su formalización.

La definición de número se encuentra por ende no totalmente formalizada, aunque se encuentre un acuerdo mayoritario en adoptar la definición enunciada por Frege.

Cognitivamente el concepto de número está asociado a la habilidad de contar y comparar cual de dos conjuntos de entidades similares tiene mayor cantidad de elementos. Las primeras sociedades humanas se toparon muy pronto con el problema de determinar cual de dos conjuntos era "mayor" que otro, o de conocer con precisión cuantos elementos formaban una colección de cosas. Esos problemas podían ser resueltos simplemente contando. La habilidad de contar del ser humano, no es un fenómeno simple, aunque la mayoría de culturas tienen sistemas de cuenta que llegan como mínimo a centenares, algunos pueblos con una cultura material simple, sólo disponen de términos para los números 1, 2 y 3 y usualmente usan el término "muchos" para cantidades mayores, aunque cuando es necesario usan recursivamente expresiones traducibles como "3 más 3 y otros 3" cuando es necesario.

El conteo se debió iniciar mediante el uso de objetos físicos (tales como montones de piedras) y de marcas de cuenta, como las encontradas en huesos tallados: el de Lebombo, con 29 muescas grabadas en un hueso de babuino, tiene unos 37.000 años de antigüedad y otro hueso de lobo encontrado en la antigua Checoslovaquia, con 57 marcas dispuestas en cinco grupos de 11 y dos sueltas, se ha estimado en unos 30.000 años de antigüedad. Ambos casos constituyen una de las más antiguas marcas de cuenta conocidas habiéndose sugerido que pudieran estar relacionadas con registros de fases lunares. En cuanto al origen ordinal algunas teorías lo sitúan en rituales religiosos. Los sistemas numerales de la mayoría de familias lingüísticas reflejan que la operación de contar estuvo asociado al conteo de dedos (razón por la cual los sistemas de base decimal y vigesimal son los más abundantes), aunque están testimoniado el empleo de otras bases numéricas además de 10 y 20.

El paso hacia los símbolos numerales, al igual que la escritura, se ha asociado a la aparición de sociedades complejas con instituciones centralizadas constituyendo artificios burocráticos de contabilidad en registros impositivos y de propiedades. Su origen estaría en primitivos símbolos con diferentes formas para el recuento de diferentes tipos de bienes como los que se han encontrado en Mesopotamia inscritos en tablillas de arcilla que a su vez habían venido a sustituir progresivamente el conteo de diferentes bienes mediante fichas de arcilla (constatadas al menos desde el 8000 a. C.) Los símbolos numerales más antiguos encontrados se sitúan en las civilizaciones mesopotámicas usándose como sistema de numeración ya no solo para la contabilidad o el comercio sino también para la agrimensura o la astronomía como, por ejemplo, registros de movimientos planetarios.

En conjunto, desde hace 5.000 años la mayoría de las civilizaciones han contado como lo hacemos hoy aunque la forma de escribir los números (si bien todos representan con exactitud los naturales) ha sido muy diversa. Básicamente la podemos clasificar en tres categorías:

En este papiro adquirido por Henry Rhind en 1858 cuyo contenido data del 2000 al 1800 a. C. además del sistema de numeración antes descrito nos encontramos con su tratamiento de las fracciones. No consideran las fracciones en general, solo las fracciones unitarias (inversas de los naturales 1/20) que se representan con un signo oval encima del número, la fracción 2/3 que se representa con un signo especial y en algunos casos fracciones del tipo formula_7. Hay tablas de descomposición de formula_8 desde n=1 hasta n=101, como por ejemplo formula_9 o formula_10, no sabemos por qué no utilizaban formula_11 pero parece que trataban de utilizar fracciones unitarias menores que formula_12.

Al ser un sistema sumativo la notación es: 1+1/2+1/4 . La operación fundamental es la suma y nuestras multiplicaciones y divisiones se hacían por "duplicaciones" y "mediaciones", por ejemplo 69x19=69x(16+2+1), donde 16 representa 4 duplicaciones y 2 una duplicación.

En las tablillas cuneiformes de la dinastía Hammurabi (1800-1600 a. C.) aparece el sistema posicional, antes referido, extendido a las fracciones, pero XXX vale para formula_13, formula_14 ó formula_15 con una representación basada en la interpretación del problema.

Para calcular recurrían, como nosotros antes de disponer de máquinas, a las numerosas tablas que disponían: De multiplicar, de inversos, de cuadrados y cubos, de raíces cuadradas y cúbicas, de potencias sucesivas de un número dado no fijo, etc. Por ejemplo para calcular formula_16, tomaban su mejor aproximación entera formula_17, y calculaban formula_18 (una mayor y otra menor) y entonces formula_19 es mejor aproximación, procediendo igual obtenemos formula_20 y formula_21 obteniendo en la tablilla Yale-7289 2=1;24,51,10 (en base decimal 1,414222) como valor de formula_22 partiendo de formula_23 (véase algoritmo babilónico).

Realizaban las operaciones de forma parecida a hoy, la división multiplicando por el inverso (para lo que utilizan sus tablas de inversos). En la tabla de inversos faltan los de 7 y 11 que tienen una expresión sexagesimal infinitamente larga. Sí están 1/59=;1,1,1 (nuestro 1/9=0,111...) y 1/61=;0,59,0,59 (nuestro 1/11=0,0909...) pero no se percataron del desarrollo periódico.

Las circunstancias y la fecha de este descubrimiento son inciertas, aunque se atribuye a la escuela pitagórica (se utiliza el Teorema de Pitágoras). Aristóteles menciona una demostración de la inconmensurabilidad de la diagonal de un cuadrado con respecto a su lado basada en la distinción entre lo par y lo impar. La reconstrucción que realiza C. Boyer es:

Sean d:diagonal, s:lado y d/s racional que podremos escribirlo como formula_24 con p y q primos entre sí. Por el teorema de Pitágoras tenemos que formula_25 , formula_26, entonces formula_27 y por tanto formula_28 debe ser par y también p, y por tanto q impar. Al ser p par tenemos formula_29, entonces formula_30 y formula_31, entonces formula_32 es par y q también, entonces q es par e impar con lo que tenemos una contradicción.

La teoría pitagórica de "todo es número" quedó seriamente dañada.

El problema lo resolvería Eudoxo de Cnido (408-355 a. C.) tal como nos indica Euclides en el libro V de "Los elementos". Para ello estableció el Axioma de Arquímedes: "Dos magnitudes tienen una razón si se puede encontrar un múltiplo de una de ellas que supere a la otra" (excluye el 0). Después en la Definición-5 da la famosa formulación de Eudoxo: "Dos magnitudes están en la misma razón formula_33 si dados dos números naturales cualesquiera m y n, si formula_34 entonces formula_35 (definición que intercambiando el 2º y 3º términos equivale a nuestro procedimiento actual).

En el libro de J.P. Colette se hace la observación de que esta definición está muy próxima a la de número real que dará Dedekind en el siglo XIX, divide las fracciones en las formula_36 tales que formula_37 y las que no.

En cualquier sistema de numeración posicional surge el problema de la falta de unidades de determinado orden. Por ejemplo, en el sistema babilónico el número formula_38 escrito en base 60 puede ser formula_39 o formula_40. A veces, se utilizaba la posición vacía para evitar este problema 3 _ 2; pero los escribas debían tener mucho cuidado para no equivocarse.

Hacia el siglo III a. C., en Grecia, se comenzó a representar la nada mediante una "o" que significa "oudos" 'vacío', y que no dio origen al concepto de cero como existe hoy en día. La idea del cero como concepto matemático parece haber surgido en la India mucho antes que en ningún otro lugar. La única notación ordinal del viejo mundo fue la sumeria, donde el cero se representaba por un vacío.

En América, la primera expresión conocida del sistema de numeración vigesimal prehispánico data del siglo III a. C. Se trata de una estela olmeca tardía, la cual ya contaba tanto con el concepto de "orden" como el de "cero". Los mayas inventaron cuatro signos para el cero; los principales eran: el corte de un caracol para el cero matemático, y una flor para el cero calendárico (que implicaba no la ausencia de cantidad, sino el cumplimiento de un ciclo).

Brahmagupta, en el 628 de nuestra era, considera las dos raíces de las ecuaciones cuadráticas, aunque una de ellas sea negativa o irracional. De hecho en su obra es la primera vez que aparece sistematizada la aritmética (+, -, *, / , potencias y raíces) de los números positivos, negativos y el cero, que él llamaba "los bienes", "las deudas" y "la nada". Así, por ejemplo, para el cociente, establece:

"Positivo dividido por positivo, o negativo dividido por negativo, es afirmativo. Cifra dividido por cifra es nada (0/0=0). Positivo dividido por negativo es negativo. Negativo dividido por afirmativo es negativo. Positivo o negativo dividido por cifra es una fracción que la tiene por denominador (a/0=¿?)"

No solo utilizó los negativos en los cálculos, sino que los consideró como entidades aisladas, sin hacer referencia a la geometría. Todo esto se consiguió gracias a su despreocupación por el rigor y la fundamentación lógica, y su mezcla de lo práctico con lo formal.

Sin embargo el tratamiento que hicieron de los negativos cayó en el vacío, y fue necesario que transcurrieran varios siglos (hasta el Renacimiento) para que fuese recuperado.

Al parecer los chinos también poseían la idea de número negativo, y estaban acostumbrados a calcular con ellos utilizando varillas negras para los negativos y rojas para los positivos.

Varios autores del siglo XIII contribuyeron a esta difusión, destacamos a: Alexandre de Villedieu (1225), Sacrobosco (circa 1195, o 1200-1256) y sobre todo Leonardo de Pisa (1180-1250). Este último, conocido como Fibonacci, viajó por Oriente y aprendió de los árabes el sistema posicional hindú. Escribió un libro, "El Liber abaci", que trata en el capítulo I la numeración posicional, en los cuatro siguientes las operaciones elementales, en los capítulos VI y VII las fracciones: comunes, sexagesimales y unitarias (¡no usa los decimales, principal ventaja del sistema!), y en el capítulo XIV los radicales cuadrados y cúbicos. También contiene el problema de los conejos que da la serie: formula_41 con formula_42.

No aparecen los números negativos, que tampoco consideraron los árabes, debido a la identificación de número con magnitud (¡obstáculo que duraría siglos!). A pesar de la ventaja de sus algoritmos de cálculo, se desataría por diversas causas una lucha encarnizada entre abacistas y algoristas, hasta el triunfo final de estos últimos.

Pietro Antonio Cataldi (1548-1626), aunque con ejemplos numéricos, desarrolla una raíz cuadrada en fracciones continuas como hoy:
Queremos calcular formula_43 y sea formula_16 el mayor número cuyo cuadrado es menor que formula_43 y formula_46, tenemos: formula_47 que con su notación escribía: n=a&b/2.a.&b/2.a... Así 18=4&2/8.&2/8, que da las aproximaciones 4+(1/4), 4+(8/33)...

Siendo así los números irracionales aceptados con toda normalidad, pues se les podía aproximar fácilmente mediante números racionales.

Los números complejos eran en pocos casos aceptados como raíces o soluciones de ecuaciones (M. Stifel (1487-1567), S. Stevin (1548-1620)) y por casi ninguno como coeficientes). Estos números se llamaron inicialmente "ficticii" 'ficticios' (el término "imaginario" usado actualmente es reminiscente de estas reticencias a considerarlos números respetables). A pesar de esto G. Cardano (1501-1576) conoce la regla de los signos y R. Bombelli (1526-1573) las reglas aditivas a través de "haberes" y "débitos", pero se consideran manipulaciones formales para resolver ecuaciones, sin entidad al no provenir de la medida o el conteo.

Cardano en la resolución del problema "dividir 10 en dos partes tales que su producto valga 40" obtiene como soluciones formula_48 (en su notación 5p:Rm:15) y formula_49 (en su notación 5m:Rm:15), soluciones que consideró meras manipulaciones ""sutiles, pero inútiles"".

En la resolución de ecuaciones cúbicas con la fórmula de Cardano-Tartaglia, aunque las raíces sean reales, aparecen en los pasos intermedios raíces de números negativos. En esta situación Bombelli dice en su "Álgebra" que tuvo lo que llamó ""una idea loca"", esta era que los radicales podían tener la misma relación que los radicandos y operar con ellos, tratando de eliminarlos después. En un texto posterior en 20 años utiliza p.d.m. formula_50 para formula_51 y m.d.m. formula_52 para formula_53 dando las reglas para operar con estos símbolos añadiendo que siempre que aparece una de estas expresiones aparece también su conjugada, como en las ecuaciones de 2º grado que resuelve correctamente. Da un método para calcular formula_54.

Aunque se encuentra un uso más que casual de las fracciones decimales en la Arabia medieval y en la Europa Renacentista, y ya en 1579 Vieta (1540-1603) proclamaba su apoyo a éstas frente a las sexagesimales, y las aceptaban los matemáticos que se dedicaban a la investigación, su uso se generalizó con la obra que Simón Stevin publicó en 1585 "De Thiende (La Disme)". En su definición 1ª dice que la Disme es un especie de aritmética que permite efectuar todas las cuentas y medidas utilizando únicamente números naturales. En las siguientes define nuestra parte entera: "cualquier número que vaya el primero se dice comienzo y su signo es (0), (1ª posición decimal 1/10). El siguiente se dice primera y su signo es (1) (segunda posición decimal 1/100). El siguiente se dice segunda (2)". Es decir, los números decimales que escribe: 0,375 como 3(1)7(2)5(3), ó 372,43 como 372(0)4(1)3(2). Añade que "no se utiliza ningún número roto (fracciones), y el número de los signos, exceptuando el 0, no excede nunca a 9".

Esta notación la simplificó Jost Burgüi (1552-1632) eliminando la mención al orden de las cifras y sustituyéndolo por un "." en la parte superior de las unidades 372·43, poco después Magín (1555-1617) usó el "." entre las unidades y las décimas: 372.43, uso que se generalizaría al aparecer en la "Constructio" de Napier(1550-1617) de 1619. La "," también fue usada a comienzos del siglo XVII por el holandés Willerbrod Snellius: 372,43.

Su antecedente es un método de demostración, llamado inducción completa, por aplicación reiterada de un mismo silogismo que se extiende indefinidamente y que usó Maurolyco (1494-1575) para demostrar que la suma de los primeros formula_55 números naturales impares es el cuadrado del formula_55-ésimo término, es decir formula_57. Pascal (1623-1662) usó el método de inducción matemática, en su formulación abstracta, tal y como lo conocemos hoy para probar propiedades relativas al triángulo numérico que lleva su nombre. La demostración por inducción consta siempre de dos partes: el paso base y el paso inductivo, los cuales se describen a continuación en notación moderna:

Si formula_58 es un subconjunto de los números naturales (denotado por formula_59) donde cada elemento formula_55 cumple la propiedad formula_61 y se tiene que:

entonces formula_67, es decir que todos los números naturales formula_55 tienen la propiedad formula_61.

De manera intuitiva se entiende la inducción como un efecto dominó. Suponiendo que se tiene una fila infinita de fichas de dominó, el paso base equivale a tirar la primera ficha; por otro lado, el paso inductivo equivale a demostrar que si alguna ficha se cae, entonces la ficha siguiente también se caerá. La conclusión es que se pueden tirar todas las fichas de esa fila.

Esta interpretación suele ser atribuida a Gauss (1777-1855) que hizo su tesis doctoral sobre el teorema fundamental del álgebra, enunciado por primera vez por Harriot y Girard en 1631, con intentos de demostración realizados por D’Alembert, Euler y Lagrange, demostrando que las pruebas anteriores eran falsas y dando una demostración correcta primero para el caso de coeficientes, y después de complejos. También trabajó con los números enteros complejos que adoptan la forma formula_70, con formula_71 y formula_72 enteros. Este símbolo formula_73 para formula_74 fue introducido por primera vez por Euler en 1777 y difundido por Gauss en su obra “"Disquisitiones arithmeticae"” de 1801.

La representación gráfica de los números complejos había sido descubierta ya por Caspar Wessel (1745-1818) pero pasó desapercibida, y así el plano de los números complejos se llama “"plano de Gauss"” a pesar de no publicar sus ideas hasta 30 años después.

Desde la época de Girard (mitad siglo XVII) se conocía que los números reales se pueden representar en correspondencia con los puntos de una recta. Al identificar ahora los complejos con los puntos del plano los matemáticos se sentirán cómodos con estos números, "ver es creer".

La distinción entre números irracionales algebraicos y trascendentes data del siglo XVIII, en la época en que Euler demostró que formula_75 y formula_76 son irracionales y Lambert que lo es π. Los trabajos de Legendre sobre la hipótesis de que π podía no ser raíz de una ecuación algebraica con coeficientes racionales, señalaron el camino para distinguir distintos tipos de irracionales. Euler ya hacía esta distinción en 1744 pero habría que esperar casi un siglo para que se estableciera claramente la existencia de los irracionales trascendentes en los trabajos de Liouville, Hermite y Lindeman.

Liouville (1809-1882) demostró en 1844 que todos los números de la forma formula_77 (p.e. 0,101001...) son trascendentes.

Hermite (1822-1901) en una memoria “"Sobre la función exponencial"” de 1873 demostró la trascendencia de formula_75 probando de una forma muy sofisticada que la ecuación: formula_79 no puede existir.

Lindeman (1852-1939) en la memoria “"Sobre el número formula_75"” de 1882 prueba que el número e no puede satisfacer la ecuación: formula_81 con formula_82 y formula_83 algebraicos, por tanto la ecuación formula_84 no tiene solución para x algebraico, pero haciendo formula_85 tenemos formula_86, entonces formula_87 no puede ser algebraico y como i lo es entonces π es trascendente.

El problema 7 de Hilbert (1862-1943) que plantea si formula_88, con a algebraico distinto de cero y de uno, y b irracional algebraico, es trascendente fue resuelto afirmativamente por Gelfond (1906-1968) en 1934. Pero no se sabe si son trascendentes o no: formula_89,formula_90, formula_91, ... Sin embargo e y 1/e sí que son trascendentes.

Hasta mediados del siglo XIX los matemáticos se contentaban con una comprensión intuitiva de los números y sus sencillas propiedades no son establecidas lógicamente hasta el siglo XIX. La introducción del rigor en el análisis puso de manifiesto la falta de claridad y la imprecisión del sistema de los números reales, y exigía su estructuración lógica sobre bases aritméticas.

Bolzano había hecho un intento de construir los números reales basándose en sucesiones de números racionales, pero su teoría pasó desapercibida y no se publicó hasta 1962. Hamilton hizo un intento, haciendo referencia a la magnitud tiempo, a partir de particiones de números racionales:

Pero en el mismo año 1872 cinco matemáticos, un francés y cuatro alemanes, publicaron sus trabajos sobre la aritmetización de los números reales:






La construcción de obtención de los números complejos a partir de los números reales, y su conexión con el grupo de transformaciones afines en el plano sugirió a algunos matemáticos otras generalizaciones similares conocidas como números hipercomplejos. En todas estas generalizaciones los números complejos son un subconjunto de estos nuevos sistemas numéricos, aunque estas generalizaciones tienen la estructura matemática de álgebra sobre un cuerpo, pero en ellos la operación de multiplicación no es conmutativa.

La teoría de conjuntos sugirió muchas y variadas formas de extender los números naturales y los números reales de formas diferentes a como los números complejos extendían al conjunto de los números reales. El intento de capturar la idea de conjunto con un número no finito de elementos llevó a la aritmética de números transfinitos que generalizan a los naturales, pero no a los números enteros. Los números transfinitos fueron introducidos por Georg Cantor hacia 1873.

Los números hiperreales usados en el análisis no estándar generalizan a los reales pero no a los números complejos (aunque admiten una complejificación que generalizaría también a los números complejos). Aunque parece los números hiperreales no proporcionan resultados matemáticos interesantes que vayan más allá de los obtenibles en el análisis real, algunas demostraciones y pruebas matemáticas parecen más simples en el formalismo de los números hiperreales, por lo que no están exentos de importancia práctica.


Los números como expresión de cantidades aparecen en todas las culturas humanas. Incluso los grupos humanos con culturas materiales más simples disponen en su lengua de alguna manera para expresar cantidades en forma numérica, al menos hasta cierto número, mediante palabras que designa a estos números (palabras numerales). El advenimiento de la escritura también comportó la búsqueda de sistemas de representación gráfica para los números, estos sistemas van desde sistemas muy simples basados en rayas a sistemas elaborados que permiten expresar números elevados.

Una de las formas más frecuentes de representar números por escrito consiste en un "conjunto finito de símbolos" o dígitos, que adecuadamente combinados permiten formar cifras que funcionan como representaciones de números (cuando una secuencia específica de signos se emplea para representar un número se la llama numeral, aunque una cifra también puede representar simplemente un código identificativo).

Tanto las lenguas naturales como la mayor parte de sistemas de representación de números mediante cifras, usan un inventario finito de unidades para expresar una cantidad mucho mayor de números. Una manera importante de lograr eso es el uso de una base aritmética en esos sistemas un número se expresa en general mediante suma o multiplicación de números. Los sistemas puramente aritméticos recurren a bases donde cada signo recibe una interpretación diferente según su posición. Así en el siguiente numeral arábigo (base 10):

El <8> por estar en última posición representa unidades, el <6> representa decenas, el <5> centenas, el <3> millares y el <1> decenas de millares. Es decir, ese numeral representara el número:

Muchas lenguas del mundo usan una base decimal, igual que el sistema arábigo, aunque también es frecuente que las lenguas usen sistemas vigesimales (base 20). De hecho la idea de usar un número finito de dígitos o signos para representar números arbitrariamente grandes funciona para cualquier base "b", donde b es un número entero mayor o igual que 2. Los ordenadores frecuentemente usan para sus operaciones la base binaria ("b" = 2), y para ciertos usos también se emplea la base octal ("b" = 8 ) o hexadecimal ("b" = 16). La base coincide con el número de signos primarios, si un sistema posicional tiene "b" símbolos primarios que designaremos por formula_96, el numeral:

Designará al número:

Las lenguas naturales usan nombres o numerales para los números frecuentemente basados en el contaje mediante dedos, razón por la cual la mayoría de las lenguas usan sistemas de numeración en base 10 (dedos de las manos) o base 20 (dedos de manos y pies), aunque también existen algunos sistemas exóticos que emplean otras bases.



</doc>
<doc id="2006" url="https://es.wikipedia.org/wiki?curid=2006" title="Número racional">
Número racional

Número racional es todo número que puede representarse como el cociente de dos números enteros o, más precisamente, un entero y un natural positivo; es decir, una fracción común formula_1 con numerador formula_2 y denominador formula_3 distinto de cero. El término «racional» alude a una fracción o parte de un todo. El conjunto de los números racionales se denota por Q (o bien formula_4, en negrita de pizarra) que deriva de «cociente» ("Quotient" en varios idiomas europeos). Este conjunto de números incluye a los números enteros (formula_5), y es un subconjunto de los números reales (formula_6).

La escritura decimal de un número racional es, o bien un número decimal finito, o bien periódico. Esto es cierto no solo para números escritos en base 10 (sistema decimal); también lo es en base binaria, hexadecimal o cualquier otra base entera. Recíprocamente, todo número que admite una expansión finita o periódica (en cualquier base entera) es un número racional.

Un número real que no es racional se llama número irracional; la expresión decimal de los números irracionales, a diferencia de los racionales, es infinita "aperiódica".

En sentido estricto, número racional es el conjunto de todas las fracciones equivalentes a una dada; de todas ellas, se toma como "representante canónico" de dicho número racional a la fracción irreducible. Las fracciones equivalentes entre sí –número racional– son una clase de equivalencia, resultado de la aplicación de una relación de equivalencia sobre formula_5.

Los egipcios calculaban la resolución de problemas prácticos utilizando fracciones cuyos denominadores son enteros positivos; son los primeros números racionales utilizados para representar las «partes de un entero», por medio del concepto de "recíproco de un número entero".

Los matemáticos de la antigua Grecia consideraban que dos magnitudes eran "conmensurables" si era posible encontrar una tercera tal que las dos primeras fueran múltiplos de la última, es decir, era posible encontrar una "unidad" común para la que las dos magnitudes tuvieran una medida entera. El principio pitagórico de que todo número es un cociente de enteros, expresaba en esta forma que cualesquiera dos magnitudes deben ser conmensurables, luego números racionales.

Etimológicamente, el hecho de que estos números se llamen racionales corresponde a que son la razón de dos números enteros, palabra cuya raíz proviene del latín "ratio", y esta a su vez del griego λόγος (razón), que es como llamaban los matemáticos de la antigua Grecia a estos números. La notación formula_4 empleada para nombrar el conjunto de los números racionales proviene de la palabra italiana "quoziente", derivada del trabajo de Giuseppe Peano en 1895.

Cualquier entero "n" se puede expresar como el número racional "n"/1 debido a eso se escribe frecuentemente formula_9 (técnicamente, se dice que los racionales contienen un subanillo isomorfo al anillo de los números enteros).

Cuando ambos denominadores son positivos:

Si cualquiera de los denominadores es negativo, las fracciones primero deben convertirse en otras equivalentes con denominadores positivos, siguiendo las ecuaciones:
y

A las operaciones de suma, resta, multiplicación y división de fracciones se les llama operaciones racionales.

Se define la suma o adición de dos números racionales a la operación que a todo par de números racionales le hace corresponder su suma :

La operación que a todo par de números racionales le hace corresponder su diferencia se llama resta o diferencia y se la considera "operación inversa" de la suma.

La multiplicación o producto de dos números racionales:

Se define la división o cociente de dos racionales "r" entre "s" distinto de 0, al producto formula_19. En otra notación,

Es una operación totalmente definida, pero se asume que es una operación inversa de la multiplicación que resuelve la ecuación "s"·"x"="r", "s"≠0.

Los inversos aditivo y multiplicativo existen en los números racionales:

Todo número real admite una representación decimal ilimitada, esta representación es única si se excluyen secuencias infinitas de "9" (como por ejemplo el 0,9 periódico).
Utilizando la representación decimal, todo número racional puede expresarse como un número decimal finito (exacto) o periódico y viceversa. De esta manera, el "valor decimal" de un número racional, es simplemente el resultado de dividir el numerador entre el denominador.

Los números racionales se caracterizan por tener una escritura decimal que solo puede ser de tres tipos:


De la misma manera se aplica la representación de un número racional en un sistema de numeración posicional en bases distintas de diez.

En un sistema de numeración posicional de base racional, las fracciones irreducibles cuyo denominador contiene factores primos distintos de aquellos que factorizan la base no tienen representación finita.

Por ejemplo, en base 10, un racional tendrá un desarrollo finito si y solo si el denominador de su fracción irreducible es de la forma formula_25 (formula_26 y formula_27 enteros), así como en base duodecimal es infinita y recurrente la representación de todas aquellas fracciones cuyo denominador contiene factores primos distintos de 2 y 3.

El conjunto de los números racionales puede construirse a partir del conjunto de fracciones cuyo numerador y cuyo denominador son números enteros. El conjunto de los números racionales no es directamente identificable con el conjunto de fracciones, porque a veces un número racional puede representarse por más de una fracción, por ejemplo:

Para poder definir los números racionales debe definirse cuando dos fracciones diferentes son equivalentes y por tanto representan el mismo número racional.

Formalmente cada número racional puede representarse como la clase de equivalencia de un par ordenado de enteros ("a","b"), con "b"≠0, con la siguiente relación de equivalencia:

donde el espacio de equivalencia de clases es el espacio cociente formula_29. Las operaciones de suma y multiplicación se definen como

Se verifica que las dos operaciones definidas son compatibles con la relación de equivalencia, indicando de manera que formula_4 se puede definir como el conjunto cociente formula_29, con la relación de equivalencia descrita antes.

Téngase en cuenta que las operaciones definidas no son más que la formalización de las operaciones habituales entre fracciones:

Se denota como [("a","b")] a la clase de equivalencias que corresponde con las distintas representaciones de un mismo número racional formula_34, con "k"≠0, en forma de fracción. Es decir :

Se toma como representante canónico el par ("a","b") tal que mcd("a","b")= 1. Cualquier otro par se puede usar en el caso de operaciones. Por ejemplo, formula_36 es la clase de equivalencia del número racional formula_37.

Con las operaciones anteriores, formula_4 es un cuerpo, donde la clase (0,1) desempeña el papel de cero, y la clase (1,1) de uno. El elemento opuesto de la clase ("a","b") es la clase (-"a","b"). Además, si "a"≠0, la clase ("a","b") es distinta de cero, luego ("a","b") es invertible (inverso multiplicativo) y su inverso corresponde a la clase ("b","a").

También se puede definir una orden total en formula_4 de la siguiente manera:

El conjunto de los números racionales puede también construirse como el cuerpo de cocientes de los números enteros, esto es,

El conjunto de los números racionales formula_4 equipado con las operaciones de suma y producto cumple las propiedades conmutativa, asociativa y distributiva, es decir:

Existen los elementos neutros para la suma y producto. Para la suma, el "cero", denotado por 0, ya que formula_46 para cualquier formula_47. Para el producto es el 1, que puede ser representado por formula_48, con "n" distinto de 0, ya que formula_49.

Posee elementos simétricos para las operaciones de suma y producto. Así, el elemento simétrico respecto de la suma para cualquier número racional formula_50 es formula_51, llamado "elemento opuesto", puesto que formula_52. Lo mismo ocurre en el caso del elemento simétrico respecto del producto, para todo número racional formula_53, distinto de 0, existe formula_54, llamado "inverso multiplicativo" tal que formula_55.

El conjunto formula_56, con las operaciones de adición y multiplicación definidas más arriba, conforma un cuerpo conmutativo, el cuerpo de cocientes de los enteros formula_57.

Los racionales son el menor cuerpo con característica nula. Cualquier otro cuerpo de característica nula contiene una copia de formula_56.

La clausura algebraica de formula_56, es el conjunto de los números algebraicos.

Los racionales forman un dominio de factorización única ya que todo racional diferente de cero puede descomponerse en la forma: formula_60 donde formula_61 son números enteros primos, formula_62 (siendo algunos de ellos negativos si "q" no es entero) y formula_63. Por ejemplo formula_64.

El conjunto de los números racionales es numerable, es decir que existe una biyección entre formula_65 y formula_56 (tienen la misma cantidad de elementos). El conjunto de los números reales no es numerable (la parte "no-denombrable" de los reales, la constituyen los números irracionales).


Sea formula_27 un número primo y para todo entero no nulo formula_72, sea formula_73 donde formula_74 es la mayor potencia de formula_75 que divide a formula_72.

Si formula_77 y para cada número racional formula_78 , formula_79 entonces la función multiplicativa formula_80 define una métrica sobre formula_56.

El espacio métrico formula_82 no es completo, su completitud es el cuerpo de los números p-ádicos formula_83. El teorema de Ostrowski asegura que todo valor absoluto no-trivial sobre formula_56 es equivalente ya sea al valor absoluto usual, o al valor absoluto "p"-ádico.



</doc>
<doc id="2010" url="https://es.wikipedia.org/wiki?curid=2010" title="Número irracional">
Número irracional

En matemáticas, un número irracional es un número que no puede ser expresado como una fracción , donde y sean enteros y sea diferente de cero. Es cualquier número real que no es racional, y su expresión decimal no es ni exacta ni periódica.

Un "decimal infinito" (es decir, con infinitas cifras) "aperiódico", como = 2,645751311064591 no puede representar un número racional. A tales números se les nombra "números reales o irracionales". Esta denominación significa la imposibilidad de representar dicho número como "razón" de dos números enteros. El número pi (formula_1), número e y el número áureo (formula_2) son otros ejemplos de números irracionales.

Dado que en la práctica de medir la longitud de un segmento de recta solo puede producir como resultado un número fraccionario, en un inicio, los griegos identificaron los números con las longitudes de los segmentos de recta.
Al identificar del modo mencionado, surge la necesidad de considerar una clase de números más amplia que la de los números fraccionarios. Se atribuye a Pitágoras de Samos (580- 500a. C.) y su escuela el descubrimiento de la existencia de segmentos de recta "inconmensurables" con respecto a un segmento que se toma como unidad en un sistema de medición. Pues, existen segmentos de recta cuya longitud medida en este sistema no es un número fraccionario.

Por ejemplo, en un cuadrado, la diagonal de este es inconmensurable con respecto a sus lados. Este hecho ocasionó una convulsión en el mundo científico antiguo. Provocó una ruptura entre la geometría y la aritmética de aquella época, ya que esta última, por entonces, se sustentaba en la "teoría de la proporcionalidad", la cual solo se aplica a magnitudes conmensurables.

Intentaron salvar el obstáculo distinguiendo entre el concepto de número y el de longitud de un segmento de recta, y tomaron estos últimos como elementos básicos para sus cálculos. De tal modo, a los segmentos inconmensurables con respecto a la unidad tomada como patrón de medida les asignaron un nuevo tipo de magnitud: "los números irracionales", los cuales por largo tiempo no se reconocieron como verdaderos números.

No existe una notación universal para indicarlos, como formula_3, que es generalmente aceptada. Las razones son que el conjunto de Números Irracionales no constituyen alguna estructura algebraica, como sí lo son los naturales (formula_4), los enteros (formula_5), los racionales (formula_6), los reales (formula_7) y los complejos (formula_8), por un lado, y que la formula_3 es tan apropiada para designar al conjunto de Números Irracionales como al conjunto de Números Imaginarios Puros, lo cual puede crear confusión. Fuera de ello,
Tras distinguir los números componentes de la recta real en tres categorías (no excluyentes): (naturales, enteros y racionales), podría parecer que ha terminado la clasificación de los números, pero aún quedan "huecos" por rellenar en la recta de los números reales. Los números irracionales son los elementos de dicha recta que cubren los vacíos que dejan los números racionales. Debe notarse que aquí se está entendiendo como "recta real" el conjunto de las clases de equivalencia de sucesiones de Cauchy de números racionales. Puede demostrarse que el límite de algunas de esas sucesiones (de hecho la mayor parte de ellas), no es un número racional, por lo que si no se consideraran racionales existirían "huecos" en el conjunto de límites.

Los números irracionales son los elementos de la recta real que no pueden expresarse mediante el cociente de dos enteros y se caracterizan por poseer infinitas cifras decimales aperiódicas. De este modo, puede definirse al número irracional como una fracción decimal aperiódica infinita. En general, toda expresión en números decimales es solo una aproximación en números racionales al número irracional referido, por ejemplo, el número racional 1,4142135 es solo una aproximación a 7 cifras decimales del número irracional raíz cuadrada de 2, el cual posee infinitas cifras decimales no periódicas.

Entonces, se dice con toda propiedad que el número es "aproximadamente" igual a 1,4142135 en 7 decimales, o bien es "igual" a 1,4142135… donde los tres puntos hacen referencia a los infinitos decimales que hacen falta y que jamás terminaríamos de escribir. Debido a ello, los números irracionales más conocidos son identificados mediante símbolos especiales; los tres principales son los siguientes:

Los números irracionales se clasifican en dos tipos:

Los números irracionales no son numerables, es decir, no pueden ponerse en biyección con el conjunto de los números naturales. Por extensión, los números reales tampoco son contables ya que incluyen el conjunto de los irracionales.





</doc>
<doc id="2014" url="https://es.wikipedia.org/wiki?curid=2014" title="Neurolepis">
Neurolepis

Neurolepis, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Sudamérica.



</doc>
<doc id="2015" url="https://es.wikipedia.org/wiki?curid=2015" title="Nastus">
Nastus

Nastus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Malasia y Nueva Guinea.



</doc>
<doc id="2019" url="https://es.wikipedia.org/wiki?curid=2019" title="Números pares e impares">
Números pares e impares

El diccionario de la RAE define número par como ""número <mark>entero que es exactamente divisible entre dos</mark>"<mark>"</mark>.

En matemáticas, un número par es un número entero que se puede escribir de la forma: 2"k" (es decir, divisible de manera entera entre 2), donde "k" es un entero (los números pares son los múltiplos del número 2). Los números enteros que no son pares, se llaman números impares (o "menores"), y se pueden escribir como 2"k"+1.

Los números pares son:

y los impares:

La paridad de un número entero se refiere a su atributo de ser par o impar. Comparativamente, dos números son «de la misma paridad» si al dividirlos entre 2, el resto es el mismo, por ejemplo: "2" y "4", o "3" y "7"; son «de la misma paridad». Por el contrario los números "23" y "44" son «de distinta paridad».

Esta se complementa por una fácil fórmula:
par + par = par | par + impar = impar | 
impar + impar = par

Si la base de numeración utilizada es un número par (por ejemplo, base 10 o base 8), podremos reconocer un número par si su último dígito también es par. Por ejemplo, el siguiente número en base 10:

es par ya que su último dígito: 6, también es par. Lo mismo sucede con el siguiente número en base 6:

Si la base del sistema de numeración es impar (3, 5, etc), el número será par si el número de dígitos con cifra impar es par, en cualquier otro caso el número será impar. Por ejemplo, en base 3:

es impar, dado que el uno es la única cifra impar, mientras que:

Como el 3 y el 1 son impares, hay un número par de cifras impares y el número es par.

El cero es un número par, cumple con la definición así como con todas las propiedades de los números pares.




En el libro 7 de los Elementos de Euclides (definiciones 8 a 10) vienen definidas unas clases de números que, aunque hoy en desuso, han sido citadas de forma recurrente en libros históricos de matemáticas.

Observaciones:

Algunas fuentes, tales como "Dorado contador. Aritmética especulativa y práctica" (1794) y el más reciente "Enjambre matemático", utilizan otra definición para los números parmente pares: no se trata de los que son productos de dos pares, sino de los que "sólo" se pueden expresar como producto de dos pares (exceptuando, por supuesto, el producto de sí mismos por uno). Según esta definición, los números parmente pares son exactamente las potencias de 2. Asimismo, definen el número parmente impar como el múltiplo de una potencia de 2 por un número impar e introducen el concepto, ausente en la obra de Euclides, de número imparmente par como un número que es doble de un número impar. La definición del número imparmente impar no sufre variación.

El libro "Llave aritmética y algebrayca" utiliza las primeras definiciones y explica el caso de que haya números que son simultáneamente parmente pares y parmente impares. Esta definición, además, queda reforzada en la proposición 32 del libro 9 de los Elementos, que explica así: «Cada uno de los números (que es continuamente) duplicado a partir de una díada es solamente un (número)
parmente par».

Sea el conjunto de los pares formula_14 = {0, 2, 4, 6, 8, 10...2"n"..., "n" cualquier natural}.
el elemento a es "primo" en 2Z si no existe un elemento de 2Z que lo divida.
Por ejemplo 6, 10, pues no hay elemento de 2Z que lo dividan parmente.

Fuera de los primos en sentido par, los otros números tienen más de dos divisores
48 y 32 tienen como divisores comunes 2, 4, 8, 16 no, porque no divide parmente a 48

El mayor de los divisores comunes de dos elementos de formula_14 se llama "máximo común divisor"



</doc>
<doc id="2021" url="https://es.wikipedia.org/wiki?curid=2021" title="Número complejo">
Número complejo

Los números complejos son una extensión de los números reales y forman el mínimo cuerpo algebraicamente cerrado. El conjunto de los números complejos se designa con la notación formula_1, siendo formula_2 el conjunto de los números reales se cumple que formula_3 (formula_2 está estrictamente contenido en formula_1). Los números complejos incluyen todas las raíces de los polinomios, a diferencia de los reales. Todo número complejo puede representarse como la suma de un número real y un número imaginario (que es un múltiplo real de la unidad imaginaria, que se indica con la letra i), o en forma polar.

Los números complejos son la herramienta de trabajo del álgebra, análisis, así como de ramas de las matemáticas puras y aplicadas como variable compleja, ecuaciones diferenciales, facilitación de cálculo de integrales, en aerodinámica, hidrodinámica y electromagnetismo entre otras de gran importancia. Además los números complejos se utilizan por doquier en matemáticas, en muchos campos de la física (notoriamente en la mecánica cuántica) y en ingeniería, especialmente en la electrónica y las telecomunicaciones, por su utilidad para representar las ondas electromagnéticas y la corriente eléctrica.

En matemáticas, estos números constituyen un cuerpo y, en general, se consideran como puntos del plano: el plano complejo. Este cuerpo contiene a los números reales y los imaginarios puros. Una propiedad importante que caracteriza a los números complejos es el teorema fundamental del álgebra —pero que se demuestra aún en un curso de variable compleja—, que afirma que cualquier ecuación algebraica de grado "n" tiene exactamente "n" soluciones complejas. Los análogos del cálculo diferencial e integral con números complejos reciben el nombre de variable compleja o análisis complejo.

La primera referencia conocida a raíces cuadradas de números negativos proviene del trabajo de los matemáticos griegos, como Herón de Alejandría en el siglo I antes de Cristo, como resultado de una imposible sección de una pirámide. 

Los complejos se hicieron más patentes en el Siglo XVI, cuando la búsqueda de fórmulas que dieran las raíces exactas de los polinomios de grados 2 y 3 fueron encontradas por matemáticos italianos como Tartaglia, Cardano. Originalmente, los números complejos fueron propuestos en 1545, por el matemático italiano, Girolamo Cardano (1501-1576), en un tratado epitómico que versaba sobre la solución de las ecuaciones cúbicas y cuárticas, con el título de "Ars magna". El término "imaginario" para estas cantidades fue acuñado por Descartes en el Siglo XVII y está en desuso.

Las cantidades «ficticias» de Cardano cayeron en un mar de indiferencia por la mayoría de los miembros de la comunidad matemática. Fueron Caspar Wessel en 1799 y Jean-Robert Argand en 1806, con la propuesta del plano complejo y la representación de la unidad imaginaria "i", mediante el punto (0,1) del eje vertical quienes sentaron las bases de estos números. El matemático alemán Carl Friedrich Gauss (1777-1855), fue quien les dio nombre, los definió rigurosamente y los utilizó en la demostración original del teorema fundamental del álgebra, que afirma que todo polinomio que no sea constante, posee al menos un cero. La implementación más formal, con pares de números reales fue dada en el Siglo XIX.

Los números complejos ligados a las funciones analíticas o de variable compleja, permiten extender el concepto del cálculo al plano complejo. El cálculo de variable compleja posee diversas propiedades notables que conllevan propiedades que pueden usarse para obtener diversos resultados útiles en matemática aplicada.

Se define cada número complejo "z" como un par ordenado de números reales: "z" = ("a", "b"). A su vez el primer elemento "a" se define como parte real de "z", se denota formula_6; el segundo elemento "b" se define como parte imaginaria de "z", se denota formula_7. Luego en el conjunto ℂ de los números complejos, se definen tres operaciones y la relación de igualdad:

A partir de estas operaciones podemos deducir otras como las siguientes:

Al número formula_14 se denomina número complejo real y como entre el conjunto de estos y el conjunto ℝ de los números reales se establece un isomorfismo , se asume que todo número real es un número complejo. Al número complejo formula_15 se denomina número imaginario puro. Puesto que
formula_16 se dice que un número complejo es la suma de un número real con un número imaginario puro. 

Se define un número complejo especial, sobre todo en el álgebra, de suma relevancia, el número "i" ( "j" en física), llamado unidad imaginaria, definido como 

Que satisface la siguiente igualdad:

Tomando en cuenta que formula_19, cabe la identificación 

El valor absoluto, "módulo" o "magnitud" de un número complejo "z" viene dado por la siguiente expresión:

Si pensamos en las coordenadas cartesianas del número complejo "z" como algún punto en el plano; podemos ver, por el teorema de Pitágoras, que el valor absoluto de un número complejo coincide con la distancia euclídea desde el origen del plano a dicho punto.

Si el complejo está escrito en forma exponencial "z" = "r e", entonces |"z"| = "r". Se puede expresar en forma trigonométrica como "z" = "r" (cosφ + isenφ), donde cosφ + isenφ = "e" es la conocida fórmula de Euler. 

Podemos comprobar con facilidad estas cuatro importantes propiedades del valor absoluto

para cualquier complejo "z" y "w".

Por definición, la función distancia queda como sigue "d"("z", "w") = |"z" - "w"| y nos provee de un espacio métrico con los complejos gracias al que se puede hablar de límites y continuidad. La suma, la resta, la multiplicación y la división de complejos son operaciones continuas. Si no se dice lo contrario, se asume que ésta es la métrica usada en los números complejos.

El "argumento principal" o "fase" de un número complejo genérico formula_25 (siendo "x"=Re("z") e "y"=Im("z")) es el ángulo formula_26 que forman el eje de abscisas "OX" y el vector "OM", con M("x","y"). Viene dado por la siguiente expresión:

donde atan2(y,x) es la función arcotangente definida para los cuatro cuadrantes:

O también: formula_28 Siendo:

la función signo.

El argumento tiene periodicidad 2π, con lo que formula_30 siendo formula_31 cualquier número entero. El ángulo Arg "z" es el valor principal de arg "z" que verifica las condiciones -π < Arg "z" <= π descritas antes.

Dos binomios se llaman conjugados si solo difieren en su signo central. De esta manera, el "conjugado" de un complejo "z" (denotado como formula_32 o formula_33) es un nuevo número complejo, definido así:

Se observa que ambos difieren en el signo de la parte imaginaria. Con este número se cumplen las propiedades:

Esta última fórmula es el método elegido para calcular el inverso de un número complejo si viene dado en coordenadas rectangulares.
Un número complejo se representa en forma binomial como: 

La parte real del número complejo y la parte imaginaria, se pueden expresar de varias maneras, como se muestra a continuación:

En esta representación, formula_45 es el módulo del número complejo y el ángulo formula_46 es el argumento del número complejo.

Despejandose "a" y "b" en las expresiones anteriores y, utilizando la representación binomial, resulta:
Sacando factor común "r":

Frecuentemente, esta expresión se abrevia convenientemente de la siguiente manera:

la cual solo contiene las abreviaturas de las razones trigonométricas coseno, la unidad imaginaria y la razón seno del argumento respectivamente.

Según esta expresión, puede observarse que para definir un número complejo tanto de esta forma como con la representación binomial se requieren dos parámetros, que pueden ser parte real e imaginaria o bien módulo y argumento, respectivamente.

Según la Fórmula de Euler:

No obstante, el ángulo formula_53 no está unívocamente determinado por "z", pues pueden existir infinitos números complejos que tienen el mismo valor representado en el plano, que se diferencian por el número de revoluciones, ya sean de sentido antihorario (positivas) u horario (negativas) las cuales se representan por números enteros formula_54, como implica la fórmula de Euler:

Por esto, generalmente formula_53 está restringido al intervalo [-π, π) y a éste formula_53 restringido se le llama "argumento principal" de "z" y se denota φ=Arg("z"). Con este convenio, las coordenadas están unívocamente determinadas por "z".

La multiplicación de números complejos es especialmente sencilla con la notación polar:

División:

Potenciación:

En el anillo de las matrices de segundo orden sobre el campo de números reales, se puede hallar un subconjunto que es isomorfo al cuerpo de los números complejos. Pues, se establece una correspondencia entre cada número complejo "a"+"b"i con la matriz

De tal manera se obtiene una correspondencia biunívoca. La suma y el producto de dos de esta matrices tiene de nuevo esta forma, y la suma y producto de números complejos corresponde a la suma y producto de tales matrices. En particular la matriz formula_63 cumple el rol de unidad imaginaria.

El concepto de plano complejo permite interpretar geométricamente los números complejos. La suma de números complejos se puede relacionar con la suma con vectores, y la multiplicación de números complejos puede expresarse simplemente usando coordenadas polares, donde la magnitud del producto es el producto de las magnitudes de los términos, y el ángulo contado desde el eje real del producto es la suma de los ángulos de los términos pudiendo ser vista como la transformación del vector que rota y cambia su tamaño simultáneamente.

Multiplicar cualquier complejo por "i" corresponde con una rotación de 90º en dirección contraria a las agujas del reloj. Asimismo el que (-1)·(-1)=+1 puede ser entendido geométricamente como la combinación de dos rotaciones de 180º ("i" al cuadrado = -1), dando como resultado un cambio de signo al completar una vuelta.

Los diagramas de Argand se usan frecuentemente para mostrar las posiciones de los polos y los ceros de una función en el plano complejo.

El análisis complejo, la teoría de las funciones complejas, es una de las áreas más ricas de la matemática, que encuentra aplicación en muchas otras áreas de la matemática así como en física, electrónica y muchos otros campos.

El conjunto ℂ de los números complejos satisface las leyes de la axiomática que define un cuerpo:

Si identificamos el número real "a" con el complejo ("a", 0), el cuerpo de los números reales R aparece como un subcuerpo de C. Más aún, C forma un espacio vectorial de dimensión 2 sobre los reales. Los complejos no pueden ser ordenados como, por ejemplo, los números reales, por lo que C no puede ser convertido de ninguna manera en un cuerpo ordenado. 

El conjunto ℂ con la adición de números complejos y considerando como escalares los números reales, se puede definir ℂ como un espacio vectorial. Esto es:

Una "raíz" o un "cero" del polinomio "p" es un complejo "z" tal que "p"("z")=0. Un resultado importante de esta definición es que todas las ecuaciones polinómicas (algebraicas) de grado "n" tienen exactamente "n" soluciones en el "cuerpo de los números complejos", esto es, tiene exactamente "n" complejos "z" que cumplen la igualdad "p"("z")=0, contados con sus respectivas multiplicidades. A esto se lo conoce como Teorema Fundamental del Álgebra, y demuestra que los complejos son un cuerpo algebraicamente cerrado; por esto los matemáticos consideran a los números complejos unos números más "naturales" que los números reales a la hora de resolver ecuaciones.

También se cumple que si "z" es una raíz de un polinomio "p" con coeficientes reales, entonces el complejo conjugado de "z" también es una raíz de "p".

Al estudio de las funciones de variable compleja se lo conoce como el Análisis complejo. Tiene una gran cantidad de usos como herramienta de matemáticas aplicadas así como en otras ramas de las matemáticas. El análisis complejo provee algunas importantes herramientas para la demostración de teoremas incluso en teoría de números; mientras que las funciones reales de variable real, necesitan de un plano cartesiano para ser representadas; las funciones de variable compleja necesitan un espacio de cuatro dimensiones, lo que las hace especialmente difíciles de representar. Se suelen utilizar ilustraciones coloreadas en un espacio de tres dimensiones para sugerir la cuarta coordenada o animaciones en 3D para representar las cuatro.

En ecuaciones diferenciales, cuando se estudian las soluciones de las ecuaciones diferenciales lineales con coeficientes constantes, es habitual encontrar primero las raíces (en general complejas) formula_65 del polinomio característico, lo que permite expresar la solución general del sistema en términos de funciones de base de la forma: formula_66.

Muchos objetos fractales, como el conjunto de Mandelbrot, pueden obtenerse a partir de propiedades de convergencia de una sucesión de números complejos. El análisis del dominio de convergencia revela que dichos conjuntos pueden tener una enorme complejidad autosimilar.

Los números complejos se usan en ingeniería electrónica y en otros campos para una descripción adecuada de las señales periódicas variables "(ver Análisis de Fourier)". En una expresión del tipo formula_67 podemos pensar en formula_68 como la amplitud y en formula_69 como la fase de una onda sinusoidal de una frecuencia dada. Cuando representamos una corriente o un voltaje de corriente alterna (y por tanto con comportamiento sinusoidal) como la parte real de una función de variable compleja de la forma formula_70 donde ω representa la frecuencia angular y el número complejo "z" nos da la fase y la amplitud, el tratamiento de todas las fórmulas que rigen las resistencias, capacidades e inductores pueden ser unificadas introduciendo resistencias imaginarias para las dos últimas (ver redes eléctricas). Ingenieros eléctricos y físicos usan la letra "j" para la unidad imaginaria en vez de "i" que está típicamente destinada a la intensidad de corriente.

El campo complejo es igualmente importante en mecánica cuántica cuya matemática subyacente utiliza Espacios de Hilbert de dimensión infinita sobre C (ℂ).

En la relatividad especial y la relatividad general, algunas fórmulas para la métrica del espacio-tiempo son mucho más simples si tomamos el tiempo como una variable imaginaria.




</doc>
<doc id="2022" url="https://es.wikipedia.org/wiki?curid=2022" title="Número real">
Número real

En matemáticas, el conjunto de los números reales (denotado por ) incluye tanto a los números racionales (positivos, negativos y el cero) como a los números irracionales; y en otro enfoque, trascendentes y algebraicos. Los irracionales y los trascendentes (1970) no se pueden expresar mediante una fracción de dos enteros con denominador no nulo; tienen infinitas cifras decimales aperiódicas, tales como: √5, , el número real 2, cuya trascendencia fue enunciada por Euler en el siglo XVIII.

Los números reales pueden ser descritos y construidos de varias formas, algunas simples aunque carentes del rigor necesario para los propósitos formales de matemáticas y otras más complejas pero con el rigor necesario para el trabajo matemático formal.

Durante los siglos XVI y XVII el cálculo avanzó mucho aunque carecía de una base rigurosa, puesto que en el momento prescindían del rigor y fundamento lógico, tan exigente en los enfoques teóricos de la actualidad, y se usaban expresiones como «pequeño», «límite», «se acerca» sin una definición precisa. Esto llevó a una serie de paradojas y problemas lógicos que hicieron evidente la necesidad de crear una base rigurosa para la matemática, la cual consistió de definiciones formales y rigurosas (aunque ciertamente técnicas) del concepto de número real. En una sección posterior se describirán dos de las definiciones precisas más usuales actualmente: clases de equivalencia de sucesiones de Cauchy de números racionales y cortaduras de Dedekind.

Los egipcios dieron origen por primera vez a las fracciones comunes alrededor del año 1000 a. C.; alrededor del 500 a. C. un grupo de matemáticos griegos liderados por Pitágoras se dio cuenta de la necesidad de los números irracionales. Los números negativos fueron ideados por matemáticos indios cerca del 600, posiblemente reinventados en China poco después, pero no se utilizaron en Europa hasta el siglo XVII, si bien a finales del XVIII Leonhard Euler descartó las soluciones negativas de las ecuaciones porque las consideraba irreales. En ese siglo, en el cálculo se utilizaban números reales sin una definición precisa, cosa que finalmente sucedió con la definición rigurosa hecha por Georg Cantor en 1871.

En realidad, el estudio riguroso de la construcción total de los números reales exige tener amplios antecedentes de teoría de conjuntos y lógica matemática. Fue lograda la construcción y sistematización de los números reales en el siglo XIX por dos grandes matemáticos europeos utilizando vías distintas: la teoría de conjuntos de Georg Cantor (encajamientos sucesivos, cardinales finitos e infinitos), por un lado, y el análisis matemático de Richard Dedekind (vecindades, entornos y cortaduras de Dedekind). Ambos matemáticos lograron la sistematización de los números reales en la historia, no de manera espontánea, sino utilizando todos los avances previos en la materia: desde la antigua Grecia y pasando por matemáticos como Descartes, Newton, Leibniz, Euler, Lagrange, Gauss, Riemann, Cauchy y Weierstrass.

Se sabe que los egipcios y babilónicos hacían uso de fracciones (números racionales) en la resolución de problemas prácticos. Sin embargo, fue con el desarrollo de la matemática griega cuando se consideró el aspecto filosófico de número. Los pitagóricos descubrieron que las relaciones armónicas entre las notas musicales correspondían a cocientes de números enteros, lo que les inspiró a buscar proporciones numéricas en todas las demás cosas, y lo expresaron con la máxima «"todo es número"».

En la matemática griega, dos magnitudes son "conmensurables" si es posible encontrar una tercera tal que las primeras dos sean múltiplos de la última, es decir, es posible encontrar una "unidad" común para la que las dos magnitudes tengan una medida entera. El principio pitagórico de que todo número es un cociente de enteros, expresaba en esta forma que cualesquiera dos magnitudes deben ser conmensurables.

Sin embargo, el ambicioso proyecto pitagórico se tambaleó ante el problema de medir la diagonal de un cuadrado, o la hipotenusa de un triángulo rectángulo, pues no es conmensurable respecto de los catetos. En notación moderna, un triángulo rectángulo cuyos catetos miden 1, tiene una hipotenusa que mide raíz cuadrada de dos, formula_1:

Surgió entonces un dilema, ya que de acuerdo al principio pitagórico: todo número era racional, mas la hipotenusa de un triángulo rectángulo isósceles no era conmensurable con los catetos, lo cual implicó que en adelante las magnitudes geométricas y las cantidades numéricas tendrían que tratarse por separado, hecho que tuvo consecuencias en el desarrollo de la matemática durante los dos milenios siguientes.

Los griegos desarrollaron una geometría basada en comparaciones (proporciones) de segmentos sin hacer referencia a valores numéricos, usando diversas teorías para manejar el caso de medidas inconmensurables, como la teoría de proporciones de Eudoxo. Así, los números irracionales permanecieron a partir de entonces excluidos de la aritmética puesto que sólo podían ser tratados mediante el método de infinitas aproximaciones. Por ejemplo, los pitagóricos encontraron (en notación moderna) que si es una aproximación a √2 entonces = + 2 y = + son tales que es una aproximación más precisa. Repitiendo el proceso nuevamente se obtienen mayores números que dan una mejor aproximación.
Dado que las longitudes que expresan los números irracionales podían ser obtenidas mediante procesos geométricos sencillos pero, aritméticamente, sólo mediante procesos de infinitas aproximaciones, originó que durante 2000 años la teoría de los números reales fuese esencialmente geométrica, identificando los números reales con los puntos de una línea recta.

Nuevos avances en el concepto de número real esperaron hasta los siglos XVI y XVII, con el desarrollo de la notación algebraica, lo que permitió la manipulación y operación de cantidades sin hacer referencia a segmentos y longitudes. Por ejemplo, se encontraron fórmulas para resolver ecuaciones de segundo y tercer grado de forma mecánica mediante algoritmos, los cuales incluían raíces e incluso, en ocasiones, «números no reales» (lo que ahora conocemos como números complejos). Sin embargo, no existía aún un concepto formal de número y se seguía dando primacía a la geometría como fundamento de toda la matemática. Incluso con el desarrollo de la geometría analítica este punto de vista se mantenía vigente, pues Descartes rechazaba la idea que la geometría pudiera fundamentarse en números, puesto que para él la nueva área era simplemente una herramienta para resolver problemas geométricos.

Posteriormente, la invención del cálculo abrió un período de grandes avances matemáticos, con nuevos y poderosos métodos que permitieron por vez primera atacar los problemas relacionados con lo infinito mediante el concepto de límite. Así, un número irracional pudo ser entendido como el límite de una suma infinita de números racionales (por ejemplo, su expansión decimal). Como muestra, el número puede estudiarse de forma algebraica (sin apelar a la intuición geométrica) mediante la serie:

entre muchas otras expresiones similares. Para entonces, el concepto intuitivo de número real era ya el moderno, identificando sin problema un segmento con la medida de su longitud (racional o no). El cálculo abrió el paso al análisis matemático, que estudia conceptos como continuidad, convergencia, etc. Pero el análisis no contaba con definiciones rigurosas y muchas de las demostraciones apelaban aún a la intuición geométrica. Esto conllevó a una serie de paradojas e imprecisiones.

Los números reales se expresan con decimales que tienen una secuencia infinita de dígitos a la derecha de la coma decimal, como por ejemplo 324,8232. Frecuentemente también se sub representan con tres puntos consecutivos al final (324,823211247…), lo que significaría que aún faltan más dígitos decimales, pero que se consideran sin importancia.

Las medidas en las ciencias físicas son siempre una aproximación a un número real. No sólo es más conciso escribirlos con forma de fracción decimal (es decir, números racionales que pueden ser escritos como proporciones, con un denominador exacto) sino que, en cualquier caso, cunde íntegramente el concepto y significado del número real. En el análisis matemático los números reales son objeto principal de estudio. Puede decirse que los números reales son la herramienta de trabajo de las matemáticas de la continuidad, como el cálculo y el análisis matemático, mientras que los números enteros lo son de las matemáticas discretas, en las que está ausente la continuidad.

Se dice que un número real es recursivo si sus dígitos se pueden expresar por un algoritmo recursivo. Un número no-recursivo es aquél que es imposible de especificar explícitamente. Aun así, la escuela rusa de constructivismo supone que todos los números reales son recursivos.

Los ordenadores sólo pueden aproximarse a los números reales por números racionales; de todas maneras, algunos programas de ordenador pueden tratar un número real de manera exacta usando su definición algebraica (por ejemplo, "formula_2") en vez de su respectiva aproximación decimal.

Los matemáticos usan el símbolo formula_3 (o, de otra forma, formula_4, la letra "R" en negrita) para representar el conjunto de todos los números reales. La notación matemática formula_5 se refiere a un espacio de formula_6 dimensiones de los números reales; por ejemplo, un valor formula_7 consiste de tres números reales y determina un lugar en un espacio de tres dimensiones.

En matemática, la palabra "real" se usa como adjetivo, con el significado de que el campo subyacente es el campo de los números reales. Por ejemplo, "matriz real", "función real", y "Álgebra de Lie real".

Un número real puede ser un "número racional" o un "número irracional". Los números racionales son aquellos que pueden expresarse como el cociente de dos números enteros, tal como 3/4, -21/3, 5, 0, 1/2, mientras que los irracionales son todos los demás. Los números racionales también pueden describirse como aquellos cuya representación decimal es eventualmente periódica, mientras que los irracionales tienen una expansión decimal aperiódica:
El conjunto de los números racionales se designa mediante formula_9 .

Otra forma de clasificar los números reales es en "algebraicos" y "trascendentes". Un número es algebraico si existe un polinomio de coeficientes racionales que lo tiene por raíz y es trascendente en caso contrario. Obviamente, todos los números racionales son algebraicos: si formula_10 es un número racional, con "p" entero y "q" natural, entonces es raíz de la ecuación "qx"="p". Sin embargo, no todos los números algebraicos son racionales.
El conjunto de los números algebraicos se designa mediante formula_14.

Un número real se dice computable si tiene una complejidad de Kolmogórov finita, es decir, si puede escribirse un programa informático de extensión finita que genere los dígitos de dicho número. Si un número real no es computable se dice irreductible. Una definición de número irreductible es:

El conjunto de números reales computables se designa por formula_15. Obviamente los racionales y los algebraicos son números computables. De hecho se tiene la siguiente inclusión:

Además se tiene que todos estos conjuntos son numerables:

Esto implica que el conjunto de todos los números computables es un conjunto de medida nula.

Fue propuesto por el matemático alemán David Hilbert. En textos actuales de cálculo y análisis matemático aparecen enunciados equivalentes al de Hilbert.
Existen diferentes formas de construir el conjunto de los números reales a partir de axiomas, siendo la caracterización más común, el conocido como "método directo" que introduce el sistema (ℝ, +., ≤), donde los elementos de ℝ se llaman "números reales", + y. son dos operaciones en ℝ, ≤ es una relación de orden en ℝ. Se presenta una variante axiomática, mediante las siguientes tres propiedades:

Las primeras dos condiciones definen el concepto de "campo ordenado", mientras que la tercera propiedad es de naturaleza topológica y es la que diferencia al conjunto de los números reales de todos los demás campos ordenados. Hay que hacer notar que, en principio pueden existir diferentes conjuntos que satisfagan las mismas condiciones y que podrían ser diferentes al conjunto de los números reales, pero un teorema establece que si eso sucediera, ambas estructuras serían esencialmente la misma.

En vista de lo anterior podemos hablar de "el" conjunto de los números reales (y no de "un" conjunto de números reales) y estableciendo su unicidad se puede usar el símbolo ℝ para representarlo.

Al enunciar la tercera propiedad en ocasiones se especifica que ℝ es completo en el sentido de Dedekind, pues existen otros axiomas que se pueden usar y que, asumiendo las primeras dos condiciones, todos son lógicamente equivalentes. Algunos de estos son:

Cada una de las primeras dos propiedades mencionadas al inicio de la sección corresponden a su vez a otra serie de axiomas, de modo que si se hace un desglose, puede caracterizarse el conjunto de los números reales como un conjunto que satisfaga la siguiente lista de axiomas.


Los axiomas del 1 al 15 corresponden a la estructura más general de cuerpo ordenado.
El último axioma es el que distingue formula_59 de otros cuerpos ordenados como formula_63. Debe señalarse que los axiomas 1 a 15 no constituyen una teoría categórica ya que puede demostrarse que admiten al menos un modelo no estándar diferente de los números reales, que es precisamente el modelo en el que se basa la construcción de los números hiperreales

Consideramos los números decimales como los conocemos intuitivamente. Sabemos que formula_64, es decir, el número π se expresa como el número entero 3 y una secuencia infinita de "dígitos" 1, 4, 1, 5, 9, 2, etc.

Un número decimal se expresa entonces como formula_65 donde formula_66 es un número entero y cada formula_67 es un elemento del conjunto formula_68. Además, consideramos que no existen las colas de 9.

Al conjunto de todos los números decimales donde formula_66 es un número entero positivo se le denota por formula_70 y se le llama el conjunto de los números "reales positivos".

Al conjunto de todos los números decimales donde formula_66 es un número entero negativo se le denota por formula_72 y se le llama el conjunto de los números "reales negativos".

Al número decimal formula_73 se le llama "cero".

Al conjunto formula_74 se le denota por formula_75 y se le llama conjunto de "números reales".

Se define la relación de orden total de los números decimales como

Hay valores que no se pueden expresar como números racionales, tal es el caso de formula_1. Sin embargo es claro que se puede aproximar formula_1 con números racionales tanto como se desee. Podemos entonces partir al conjunto de los números racionales en dos subconjuntos formula_94 y formula_95 de manera que en el conjunto formula_94 se encuentran todos los números racionales formula_97 y en formula_95 todos los números racionales tales que formula_99.

Una "cortadura de dedekind" es un par ordenado formula_100 que hace precisamente esto. Conceptualmente, la cortadura es el "espacio" que hay entre formula_94 y formula_95. De esta manera es posible definir a formula_1 como formula_100 tal que formula_105 y formula_106.

Es posible demostrar que formula_95 queda unívocamente definido por formula_94, de esta manera la cortadura formula_100 se reduce simplemente a formula_94.

También es demostrable que el conjunto de todas las cortaduras cumple con los axiomas de los números reales, de esta manera formula_75 es el conjunto de todas las cortaduras de Dedekind. Esta es la primera construcción formal de los números reales bajo la teoría de conjuntos.

Las sucesiones de Cauchy retoman la idea de aproximar con números racionales un número real. Tómese por ejemplo, la igualdad.

Es claro que esta sumatoria opera sólo con los números racionales de la forma:

sin embargo el resultado final es el número irracional formula_114. Cada vez que se añade un término, la expresión se aproxima más y más a formula_114.

Las sucesiones de Cauchy generalizan este concepto para definir a los números reales. Primero se define que una "sucesión de números racionales" es una función se denota simplemente por formula_116.

Una "sucesión de Cauchy" es una sucesión de números racionales donde sus elementos cada vez son menos diferentes. Más formalmente, se define una "sucesión de Cauchy" como una sucesión de números racionales tales que para todo formula_117 existe un formula_118 tal que para todo formula_119 se cumple formula_120.

De esta manera es posible definir al número real formula_121 como la sucesión de números racionales:

Sea Γ el conjunto de las sucesiones de Cauchy en Q. Sea la relación ρ siguiente, definida entre las sucesiones de Cauchy de Q, (x) y (y):




Sean a > 0 y b números reales cualesquiera, existe un número natural n tal que na > b; esto expresa a su vez que la sucesión b/n tiende a cero.

Con números reales pueden realizarse todo tipo de operaciones básicas con diversas excepciones importantes:


Estas restricciones tienen repercusiones en otras áreas de las matemáticas como el cálculo: existen asíntotas verticales en los lugares donde el denominador de una función racional tiende a cero, es decir, en aquellos valores de la variable en los que se presentaría una división entre cero, o no existe gráfica real en aquellos valores de la variable en que resulten números negativos para raíces de orden par, por mencionar un ejemplo de construcción de gráficas en geometría analítica.




</doc>
<doc id="2028" url="https://es.wikipedia.org/wiki?curid=2028" title="Netscape Navigator">
Netscape Navigator

Netscape Navigator es un navegador web, el primer producto comercial de la compañía Netscape Communications creada por Marc Andreessen (uno de los autores de Mosaic) cuando se encontraba en el "National Center for Supercomputing Applications" (NCSA: Centro Nacional de Aplicaciones para Supercomputadoras) de la Universidad de Illinois en Urbana-Champaign.

Netscape fue el primer navegador comercial.

Netscape anunció el 13 de octubre de 1994 que lanzaría un navegador disponible de forma gratuita para todos sus usuarios no comerciales, y que las versiones beta 1.0 y beta 1.1 se podrán descargar en noviembre de 1994 y marzo de 1995. La versión 1.0 final estuvo disponible en diciembre de 1994. Netscape hizo gratuita la disponibilidad de su software porque tenía en sus políticas la noción de que el software para Internet no debía tener coste. 
En 1997, el Netscape Navigator 2.0 fue el primer navegador en incluir un lenguaje de "script" en las páginas web, al introducir JavaScript en su versión 2. Originalmente, apenas servía para algo más que para validar formularios, pero rápidamente se fue expandiendo.

Al añadirle capacidades para leer y enviar mensajes, tanto de correo electrónico como de "netnews", aparece la versión Communicator. El editor de páginas Netscape Composer, introducido en la "'versión 3", da lugar a la denominación "Gold" para las distribuciones que lo incluyen.

Fue muy criticado por los partidarios de los estándares en Internet por introducir en el HTML gran cantidad de extensiones propietarias (o "netscapismos"), es decir, creadas por sus autores, sin respetar las recomendaciones del "World Wide Web Consortium", lo que dañaba la compatibilidad de las páginas entre navegadores y al objetivo de llegar a la web semántica. Entre las extensiones propietarias introducidas por Netscape destacan los "frames" y los "layers".

La versión 4 introdujo las hojas de estilo en cascada (CSS) y HTML dinámico a través de JavaScript y una extensión propietaria de HTML llamada "layers". Por desgracia, esta versión estaba plagada de "bugs", y su implementación del HTML dinámico era inferior a la del Internet Explorer 4. Esto, unido a la integración de Internet Explorer en Microsoft Windows, llevó a la llamada “guerra de navegadores” entre ambas compañías, que introdujeron abundantes extensiones propias e incompatibles entre sí a HTML y JavaScript. Esto obligó a muchos a crear dos versiones de sus páginas, una para cada navegador.

El resultado de esta ‘guerra’ fue la victoria del Internet Explorer, que consiguió una cuota del 98% en el uso de navegadores, y la posterior desaparición de Netscape Navigator. Esta victoria se debió, fundamentalmente, a la inclusión de Internet Explorer como un componente más de Microsoft Windows, lo que hacía que la inmensa mayoría de los usuarios lo tuvieran aunque no lo hubieran instalado como tal, y no se molestaran en buscar otro.

La versión 5 estuvo en desarrollo durante años, pero la dificultad de modificar el código fuente para permitir la modificación de las páginas tras su carga, unida a las progresivas pérdidas económicas de la empresa, hizo que nunca saliera al mercado. Así, Netscape perdió la guerra de los navegadores en favor de Internet Explorer, que ya iba por la versión 5. Finalmente, su código fue liberado, con el fin de que la comunidad de desarrolladores de software libre pudiera contribuir a terminarlo. Esto dio lugar a la Fundación Mozilla, que reescribió casi todo el código, creando el navegador Mozilla Application Suite.

Las versiones 6 y 7 se basaron en el código del proyecto Mozilla. En la actualidad, al haber abandonado Netscape el desarrollo de su navegador, se puede considerar a Mozilla Navigator como su sucesor.

En marzo de 1997, Netscape liberó la mayoría del código de Netscape Communicator y lo puso bajo la licencia libre. El proyecto se llamó Mozilla. Se estimó que completar el código fuente (los elementos con "copyright" propietario tuvieron que ser eliminados) en una nueva versión de navegador, podría llevar un año, y de esta forma se decidió que la próxima versión del navegador Netscape, "versión 5.0", se basaría en esta. Netscape asignó sus ingenieros de desarrollo de su navegador para que ayudaran en el proyecto.

Después de un año, era evidente que el desarrollo de Mozilla no era tan veloz, por lo que Netscape reasignó algunos de sus ingenieros a la versión Netscape Communicator 4.5. Esto tuvo el efecto de redirigir parte de los esfuerzos en una línea muerta, mientras el navegador de Microsoft, Internet Explorer 5.0, estaba todavía desarrollándose. Los ingenieros de Mozilla decidieron tirar el código de Communicator y empezar desde cero. La primera versión pública de Mozilla, dos años más tarde, no tuvo mucha aceptación ya que muchas computadoras de nivel medio eran demasiado lentos para ejecutar un navegador que utilizaba su propia interfaz gráfica de usuario y personalizable con el lenguaje "Extensible Markup Language" (XML).

Se evitó la versión 5 porque Microsoft Internet Explorer 5.0 estaba disponible desde hacía un año y medio. Había planes para liberar una versión 5.0 basada en el código 4.x, pero esta idea fue desechada y se utilizaron todos los recursos para trabajar en la versión de Mozilla Netscape 6.0, en lo que algunos empleados de Netscape todavía consideran uno de los mayores errores en la historia de la empresa.

Con bastante publicidad, la empresa AOL como nueva dueña de Netscape, liberó Netscape 6 el 14 de noviembre de 2000, basado en el código de la versión anterior de Mozilla. El producto fue una decepción colosal: era enorme, lento, inestable y visualmente no atractivo (para la gran mayoría). Nada de esto fue una sorpresa, ya que el núcleo de Mozilla no estaba cerca de estar disponible como nueva versión por sí mismo, y era muy inestable.

Netscape 6.1 y Netscape 6.2, liberados en 2001, solucionaron los problemas de estabilidad, pero eran demasiado grandes y lentos, y no mejoraron la mala reputación de Netscape 6, por lo que fueron ignorados de forma generalizada por el mercado.

En 2002, AOL liberó Netscape 7: basado en el núcleo de Mozilla 1.0, más estable y notablemente más rápido, tenía varios extras como el "AOL Instant Messenger" integrado, ICQ y Radio@Netscape. El mercado respondió que era esencialmente una versión re-empaquetada de Mozilla con una serie de herramientas integradas que permitían acceder a los servicios gestionados por AOL, por lo que fue ignorado nuevamente. La competencia entre las alternativas no-Microsoft maduras y competentes como el navegador Opera y la distribución de Mozilla fue otro factor decisivo. La versión Netscape 7.1 (basada en Mozilla 1.4) fue también ignorada.

En la plataforma Windows, el navegador Netscape ha sido irrelevante durante bastantes años. Todavía hay algunos usuarios de versiones recientes, pero la mayoría son personas que no están dispuestas, o no pueden, cambiar de navegador desde las versiones 4.x, ya que normalmente los navegadores más recientes requieren máquinas con mayor potencia de cálculo para un rendimiento aceptable. En otras plataformas, que no tienen la posibilidad de instalar Internet Explorer, como GNU/Linux, Netscape mantuvo su posición como navegador dominante durante más tiempo. Únicamente en los últimos años, la aparición de otras alternativas como Mozilla y Konqueror han supuesto un incremento de la competencia.

AOL anunció el 14 de julio de 2003 que iba a retirar a todo el personal de desarrollo que trabajaba en la versión de Netscape de Mozilla. Combinado con el acuerdo entre Microsoft y AOL para utilizar la versión de Internet Explorer en las futuras versiones de software, marcó el final de Netscape como entidad y lo relegó a poco más de una nota histórica. El nombre de marca Netscape como proveedor de servicios de Internet con llamada telefónica.

Netscape 7.2 se lanzó el 17 de agosto de 2004; AOL afirmó no haber continuado con la división del navegador Netscape.

En mayo de 2005 se publicó una nueva versión, Netscape 8.0, basada en Mozilla Firefox, pero ofreciendo también el motor de Internet Explorer para visualizar ciertas páginas.

En octubre de 2007 se lanzó la versión Netscape 9.0, que además de otras funcionalidades, permite la integración de los "plugins" de Firefox 2.

AOL canceló el soporte para Netscape a partir del 1 de marzo de 2008. Esto significa que a partir de esa fecha no se producirán parches de seguridad o nuevas versiones del navegador.

Inicialmente se había anunciado que el día 1 de febrero de 2008 se finalizaría el soporte técnico y desarrollo del navegador, pero se extendió la fecha hasta el 1 de marzo para crear un "plugin" que permitiría migrar a los usuarios de Netscape 9.0.x y 8.x a una versión especial de Flock, o a Mozilla Firefox. Fue así que el 20 de febrero se lanzó la última versión de Netscape Navigator, la 9.0.0.6, cerrando una larga historia en Internet.

Algunos usuarios, aprovechando el código de Mozilla Firefox, han intentado revivir a Netscape Navigator. Entre estos proyectos se encuentran Netscape Reloaded y Netstep. Ellos agregan funcionalidad, herramientas y aspectos similares a las usadas por Netscape mediante extensiones.




</doc>
<doc id="2029" url="https://es.wikipedia.org/wiki?curid=2029" title="Friedrich Nietzsche">
Friedrich Nietzsche

Friedrich Wilhelm Nietzsche (; Röcken, -Weimar, ) fue un filósofo, poeta, músico y filólogo alemán, considerado uno de los pensadores contemporáneos más influyentes del siglo XIX.

Realizó una crítica exhaustiva de la cultura, la religión y la filosofía occidental, mediante la genealogía de los conceptos que las integran, basada en el análisis de las actitudes morales (positivas y negativas) hacia la vida. Este trabajo afectó profundamente a generaciones posteriores de teólogos, antropólogos, filósofos, sociólogos, psicólogos, politólogos, historiadores, poetas, novelistas y dramaturgos.

Meditó sobre las consecuencias del triunfo del secularismo de la Ilustración, expresada en su observación «Dios ha muerto», de una manera que determinó la agenda de muchos de los intelectuales más célebres después de su muerte.

Si bien hay quienes sostienen que la característica definitoria de Nietzsche no es tanto la temática que trataba sino el estilo y la sutileza con que lo hacía, fue un autor que introdujo, como ningún otro, una cosmovisión que ha reorganizado el pensamiento del siglo XX, en autores tales como Martin Heidegger, Michel Foucault, Jacques Derrida, Gilles Deleuze, Georges Bataille, Gianni Vattimo o Michel Onfray, entre otros.

Nietzsche recibió amplio reconocimiento durante la segunda mitad del siglo XX como una figura significativa en la filosofía contemporánea. Su influencia fue particularmente notoria en los filósofos existencialistas, críticos, fenomenológicos, postestructuralistas y posmodernos, y en la sociología de Max Weber. Es considerado uno de los tres «maestros de la sospecha» (según la conocida expresión de Paul Ricoeur), junto a Karl Marx y Sigmund Freud.

Friedrich Nietzsche nació el 15 de octubre de 1844 en Röcken, un pequeño pueblo de Sajonia-Anhalt, cerca de Leipzig. Su nombre proviene del rey Federico Guillermo IV de Prusia, en cuyo cuadragésimo noveno cumpleaños nació. Sus padres fueron Carl Ludwig Nietzsche (1813-1849), pastor luterano y preceptor privado en el ducado alemán de Sajonia-Altenburgo en Turingia, y Franziska Oehler (1826-1897). Su hermana Elisabeth Förster-Nietzsche nació en 1846, seguida por su hermano Ludwig Joseph en 1848. Tras la muerte del padre en 1849 y del hermano menor en 1850 la familia se trasladó a Naumburgo, donde vivió con su abuela materna y las hermanas solteras del padre bajo la protección de Bemhard Dächsel, un magistrado local. 

Después de la muerte de su abuela en 1856, la familia pudo permitirse tener casa propia. Durante este tiempo el joven Nietzsche asistió a un colegio de niños para luego trasladarse a un colegio privado, la prestigiosa escuela Pforta, donde se hizo amigo de Gustav Krug y Wilhelm Pinder, dos estudiantes pertenecientes a familias acomodadas. Escribe su primer "tratado" filosófico titulado "Sobre el origen del mal". En 1854 comenzó a asistir al Domgymnasium en Naumburgo, pero, habiendo demostrado un talento especial para la música y el lenguaje, fue admitido en la reconocida Schulpforta, donde continuó sus estudios desde 1858 hasta 1864. Aquí se hizo amigo de Paul Deussen y Carl von Gersdorff. También encontró tiempo para la escritura de poemas y composiciones musicales. En Schulpforta, Nietzsche recibió una importante educación literaria, en especial en el estudio de los clásicos griegos y romanos, y por primera vez experimentó la carencia de su vida familiar en un pequeño pueblo de ambiente cristiano. Durante este período se encontró bajo la influencia del poeta Ernst Ortlepp.

Después de su graduación en 1864, Nietzsche comenzó sus estudios en teología y filología clásica en la Universidad de Bonn. Por un breve período fue miembro de la Burschenschaft Frankonia junto a Deussen. Para disgusto de su madre, abandonó sus estudios de teología tras un semestre y comenzó los de filología con el profesor Friedrich Wilhelm Ritschl. Al año siguiente siguió al maestro a la Universidad de Leipzig. Allí entablaría una íntima amistad con el estudiante Erwin Rohde. Los primeros escritos sobre filología de Nietzsche serían publicados un poco más tarde.

En 1865 se familiarizó con la obra de Arthur Schopenhauer. Al año siguiente leyó "Geschichte des Materialismus" ("Historia del materialismo"), de Friedrich Albert Lange. Ambas experiencias le resultaron muy estimulantes desde el punto de vista filosófico y, en consecuencia, comenzó a adentrarse en esta disciplina, superando su interés por la filología. En 1865, cuando todavía era estudiante, Nietzsche visitó Colonia, donde unos amigos lo llevaron a un prostíbulo. Los detalles, e incluso la posibilidad, de esta visita fueron largamente discutidos, pero ahora se acepta que en esa oportunidad contrajo sífilis. En 1867 realizó un año de servicio militar voluntario con la división de artillería prusiana de Naumburgo. En marzo de 1868 sufrió un accidente ecuestre que lo excluyó del servicio militar y le permitió volver a dedicarse al estudio. Ese mismo año conoció a Richard Wagner, personaje fundamental en su desarrollo.

Gracias a Ritschl, Nietzsche recibió una oferta extraordinaria de la Universidad de Basilea para ejercer como profesor de filología clásica antes de licenciarse, siendo así el profesor más joven de la universidad. En su trabajo filológico durante esa época cabe reseñar el descubrimiento de que el ritmo en la métrica poética de los antiguos dependía únicamente de la duración de las sílabas a diferencia de la métrica moderna basada en la acentuación.

En 1869 la Universidad de Leipzig le concedió el doctorado sin examen ni disertación en mérito a la calidad de sus investigaciones. Inmediatamente la Universidad de Basilea lo nombró profesor de filología clásica y al año siguiente fue ascendido a profesor honorario.

Después de trasladarse a Basilea, Nietzsche renunció a su ciudadanía alemana, manteniéndose durante el resto de su vida oficialmente sin nacionalidad alguna. Sin embargo en agosto de 1870 obtuvo un permiso para servir en el bando prusiano durante la guerra franco-prusiana pero sólo como sanitario ya que la neutral Suiza le impidió reclutarse como combatiente. Su paso por la milicia fue tan sólo de un mes, pero vivió múltiples experiencias. Allí fue testigo de los efectos traumáticos de la batalla. Contrajo difteria y disentería, enfermedades que le arruinaron la salud de por vida.

De vuelta a Basilea, Nietzsche fue testigo del establecimiento del Imperio alemán y el auge de Otto von Bismarck, a quien veía con escepticismo. En la universidad pronunció su discurso inaugural, "Sobre la personalidad de Homero". En esta época conoció a Franz Overbeck, un profesor de Teología, cuya amistad conservó durante el resto de su vida. El historiador Jacob Burckhardt, a cuyas clases magistrales Nietzsche asistía frecuentemente, se convirtió en otro colega influyente. También durante este período leerá la obra del filósofo Max Stirner, cuya influencia será notable en él.

Nietzsche había conocido ya a Richard Wagner en Leipzig en 1868, y (algo después) a la esposa de Wagner, Cósima. Admiraba a ambos profundamente y, durante su estancia en Basilea, fue un asiduo invitado en la casa de los Wagner en Tribschen. Estos lo introdujeron en su círculo más íntimo y le agradecieron la atención que dio al principio al Festival de Bayreuth. En 1870 regaló a Cósima Wagner por su cumpleaños el manuscrito de la primera versión de "El origen de la tragedia".

En 1872, Nietzsche publicó su primer libro, "El nacimiento de la tragedia en el espíritu de la música". Sin embargo el trabajo, en el cual siguió un preciso método filológico para estructurar toda su especulación filosófica radicalmente novedosa, no fue bien recibido entre sus colegas filólogos, incluido su profesor Ritschl. En el polémico panfleto "Para una filología del futuro", Ulrich von Wilamowitz-Moellendorff criticó duramente el libro, lo que contribuyó, sin embargo, a aumentar su polémica notoriedad en los círculos filológicos y universitarios de Alemania. En respuesta, Rohde, por la fecha profesor en Kiel, y el mismo Wagner salieron públicamente en defensa de Nietzsche. Estos hechos remarcaron el aislamiento creciente que sentía dentro de la comunidad filológica, y por ello el filósofo intentó (infructuosamente) ganar la cátedra de Filosofía en Basilea.

Entre 1873 y 1876, publicó separadamente cuatro grandes ensayos, "David Strauss, el confesor y el escritor", "Sobre la utilidad y el perjuicio de la Historia para la vida", "Schopenhauer como educador", y "Richard Wagner en Bayreuth" (estos cuatro fueron más tarde recogidos y titulados, conjuntamente, "Consideraciones intempestivas"). Los cuatro ensayos compartían la orientación de una crítica general a la actualidad cultural alemana, en un intento por cambiar su rumbo, que Nietzsche preveía como esencialmente falso y equivocado. Comenzando en 1873, además, también acumuló notas que fueron publicadas más tarde como "La filosofía en la época trágica de los griegos".

Durante este periodo, en el círculo de los Wagner, Nietzsche conoció a Malwida von Meysenbug y Hans von Bülow, y también comenzó una amistad con Paul Rée, quien después de 1876 le influyó en la atenuación del pesimismo de sus primeros escritos. Sin embargo, debido a su decepción respecto al «fenómeno Wagner», y en concreto al Festival de Bayreuth de 1876, donde la banalidad de los actos y la vileza del público le repelieron, fue cada vez más insalvable la distancia del filósofo hacia este mundo.

En 1879, después de un declive de salud, se vio forzado a abandonar su puesto como profesor. Desde su juventud, Nietzsche había padecido frecuentes momentos de debilidad generalizada, con épocas de carencia visual que rozaba la ceguera, fuertes migrañas y violentos ataques estomacales. Estas condiciones persistentes se agravaron quizá con su accidente a caballo en 1868 y las enfermedades de 1870, y continuaron afectándolo durante sus años en Basilea, forzándolo a tomar vacaciones cada vez más largas, hasta que le fue prácticamente imposible retomar el trabajo.

Con la publicación de "Humano, demasiado humano" en 1878, un libro de aforismos sobre múltiples temas, desde la metafísica hasta la moralidad y de la religión al sexo, la distancia de Nietzsche respecto a la filosofía de Wagner y Schopenhauer fue evidente. También su amistad con Deussen y Rohde se enfrió.

Durante sus primeros años en Basilea se cocinó la ambivalente amistad de Nietzsche con Wagner, y aprovechó toda oportunidad para visitar a Richard y a su esposa Cósima. Nietzsche apreciaba a Wagner como un brillante apóstol catedrático, pero la explotación de motivos artísticos cristianos cada vez más acentuada, junto con su chovinismo y antisemitismo excederían lo que Nietzsche podría soportar.

La composición de Parsifal, que Wagner concebiría más como un "auto litúrgico" para el Viernes Santo que como una ópera, ofendió profundamente la sensibilidad de Nietzsche. Aunque la gigantesca obra no sería estrenada hasta 1882, ya en 1878 la brecha entre los dos sería ineludible y definitiva.

Conducido por su enfermedad a encontrar climas más templados, Nietzsche viajó frecuentemente y vivió hasta 1889 como un autor independiente en diferentes ciudades. Estuvo muchos veranos en Sils Maria, cerca de St. Moritz, en la Engandina (extremo este de Suiza), y muchos otoños en las ciudades italianas de Génova, Rapallo y Turín, y la ciudad francesa de Niza. Ocasionalmente volvía a Naumburgo a visitar a su familia, y especialmente durante este período, él y su hermana tuvieron repetidos episodios de conflicto y reconciliación. Vivía de su pensión de profesor retirado de la Universidad de Basilea, pero también recibía ayuda de amigos.

Un antiguo estudiante suyo, Peter Gast (seudónimo de Johann Heinrich Köselitz), llegó a ser su secretario privado. Hasta el final de su vida, Gast y Overbeck se mantuvieron como amigos en los que confiar. Malwida von Meysenbug mantuvo una conducta maternal incluso fuera del círculo de Wagner. Pronto Nietzsche contactó con el crítico musical Carl Fuchs.

Nietzsche se encontraba en el principio de su mayor período productivo. A partir de "Humano, demasiado humano" en 1878, Nietzsche publicaría un libro (o su mayor parte) por año hasta 1888, su último año de escritura, durante el cual completó cinco. En 1879, Nietzsche publicó "Opiniones y máximas mezcladas", lo que sugirió el aforismo de "Humano, demasiado humano".

En 1881 Nietzsche publicó "Aurora. Reflexiones sobre los prejuicios morales", y en 1882 la primera parte de "La gaya ciencia". Ese año también conoció a Lou Andreas-Salomé a través de Malwida von Meysenbug y Paul Rée. Nietzsche y Salomé pasaron el verano juntos en Tautenburg, a menudo con la hermana de Nietzsche, Elisabeth. Sin embargo, la visión que de Nietzsche tenía Salomé era más la de un amigo y compañero de discusiones lleno de genialidad, que el de una posible pareja. Él se enamoró de ella lo cual provocó una situación ambigua e incómoda entre los tres amigos, puesto que Rée a su vez se interesaba por Lou. Cuando Nietzsche le pidió que se casara con él, Salomé lo rechazó. Las relaciones de Nietzsche con Salomé y Rée se rompieron en el otoño de 1882-1883, en parte por las intrigas llevadas a cabo por su hermana Elisabeth. En paralelo a esta historia, Lou Salomé de vez en cuando mantenía correspondencia con Freud, introduciéndolo en el pensamiento de Nietzsche. En el proceso de aparición de nuevos síntomas de su enfermedad, aislado tras las discusiones con su hermana y su madre, y acosado por pensamientos suicidas, se marchó a Rapallo, donde en solo diez días, anticipados por dieciocho meses de incubación, escribió la primera parte de "Así habló Zaratustra".

Después de varias críticas filosóficas contra Schopenhauer y Wagner, Nietzsche mantuvo a pocos amigos. Ahora, bajo la impronta personalísima del "Zaratustra" sobre sus obras posteriores, su escritura resultó todavía más «intempestiva» y se lo leyó (poco) sólo en la medida en que pareciera adecuarse a las convenciones morales o intelectuales del momento. Nietzsche reconoció la situación y se obstinó en su soledad («las siete soledades»), incluso aunque a veces pareciera no resignarse a ella. Abandonó su plan a medio plazo de convertirse en un poeta público y reconocido, y siguió padeciendo los problemas consabidos con sus libros. Estos eran tan buenos como poco vendidos. En 1885, editó únicamente cuarenta copias de la cuarta parte de "Así habló Zaratustra", y solo una pequeña parte fue distribuida entre sus amigos más allegados.

En 1886, editó "Más allá del bien y del mal". Con este libro y con la aparición entre 1886 y 1887 de segundas ediciones de sus trabajos tempranos ("El nacimiento de la tragedia", "Humano, demasiado humano", y "La gaya ciencia"), vio completado su trabajo y se esperanzó con que una oleada de lectores apreciara sus escritos. De hecho, el interés por Nietzsche aumentó en esta época, aunque esto fue apenas percibido por él.

Durante estos años, Nietzsche conoció a Meta von Salis, Carl Spitteler, y también a Gottfried Keller. En 1886, su hermana Elisabeth se casó con el antisemita Bernhard Förster y viajó con él a Paraguay para fundar una colonia alemana, un plan al que Nietzsche contestó con ironía. A través de la correspondencia se puede observar que la relación de Nietzsche con su hermana continuó por el camino que siempre había seguido de conflicto y reconciliación, pero no la volvería a ver en persona hasta después de su colapso.

Nietzsche continuaba teniendo ataques frecuentes de enfermedad, lo que le imposibilitó para el trabajo continuo. En 1887, Nietzsche rápidamente escribió su polémica "Genealogía de la moral". También intercambiaba correspondencia con Hippolyte Taine, y después también con Georg Brandes, quien al comienzo de 1888 desarrolló en Copenhague la primera lectura pública de la obra filosófica de Nietzsche y su estudio.

En el mismo año Nietzsche escribió cinco libros basados en sus voluminosas notas, fruto de largo trabajo continuado, que en un principio pensaba reunir bajo el título de "La voluntad de poder". Su salud pareció mejorar y aquel verano estuvo de buen humor. Pero hacia finales de 1888, sus escritos y cartas empezaron a revelar una sobreestimación patológica de su estatus y destino. Sobrevaloraba la respuesta creciente a sus escritos, sobre todo por la reciente polémica respecto a "El caso Wagner".

Hay que tener en cuenta que en 1867, Nietzsche fue tratado por una infección sifilítica que finalmente desembocó en la crisis mental de enero de 1889, fin efectivo de la vida de Nietzsche aunque viviría, en silencio y perdido en sí mismo, hasta 1900. La sífilis era el sida de su tiempo, y cuando leemos a Nietzsche, especialmente su obra tardía, deberíamos tener bien presente el hecho de su enfermedad.

De octubre a noviembre de 1888, Nietzsche trabaja en la obra "Ecce homo (Cómo se llega a ser lo que se es)", que no verá la luz hasta el año 1908 en una versión en la que el capítulo «Por qué soy tan sabio» no aparece, siendo sustituido por otro capítulo escrito anteriormente que el propio autor descartó.

El 3 de enero de 1889 Nietzsche sufrió un colapso mental. Ese día fue detenido tras, al parecer, haber provocado algún tipo de desorden público, por las calles de Turín. Lo que pasó exactamente es desconocido. La versión más extendida sobre lo sucedido dice que Nietzsche caminaba por la Piazza Carlo Alberto, cuando un repentino alboroto que causó un cochero al castigar a su caballo llamó su atención. Nietzsche corrió hacia él y lanzó sus brazos rodeando el cuello del caballo para protegerlo, desvaneciéndose acto seguido contra el suelo. En los días siguientes, escribió breves cartas para algunos amigos, incluidos Cósima Wagner y Jacob Burckhardt, en las que mostraba signos de demencia y megalomanía.

A su colega Burckhardt escribió: «He tenido Caiphas puestos. Además, el año pasado fui crucificado por los doctores alemanes de una manera muy drástica. Wilhelm, Bismarck, y todos los antisemitas abolidos». El 6 de enero de 1889, Burckhardt mostró la carta a Overbeck. El siguiente día Overbeck recibió una carta reveladora semejante, y decidió que Nietzsche debería volver a Basilea. Overbeck viajó a Turín y trajo a Nietzsche a una clínica psiquiátrica en Basilea.

Por ese tiempo, Nietzsche estaba enteramente sumergido en la locura, y su madre Franziska decidió llevarlo a una clínica en Jena bajo la dirección de Otto Binswanger. Desde noviembre de 1889 a febrero de 1890, Julius Langben intentó curar a Nietzsche, sentenciando que los métodos del doctor eran ineficaces para curar su condición. Langbehn asumió más y más control sobre Nietzsche. En marzo de 1890, Franziska sacó a Nietzsche de la clínica, y en mayo de 1890 lo llevó a su casa en Naumburgo.

Durante este proceso, Overbeck y Gast contemplaban la idea de qué hacer con el trabajo no publicado de Nietzsche. En enero de 1889 se pusieron a planear la salida de "El ocaso de los ídolos, o cómo se filosofa a martillazos", por esa época ya impreso y atado. En febrero, ordenaron una edición privada de 50 copias de "Nietzsche contra Wagner", pero el editor C. G. Nauman en secreto imprimió 100. Overbeck y Gast decidieron publicar con reservas "El Anticristo" y "Ecce homo" debido a su contenido más radical.

En 1893, Elisabeth Nietzsche volvió de Paraguay después del suicidio de su marido. Leyó y estudió los trabajos de Nietzsche, y pieza por pieza tomó control sobre ellos y su publicación. Overbeck fue paulatinamente relegado al ostracismo, y Gast finalmente cooperó. Después de la muerte de Franziska en 1897, Nietzsche vivió en Weimar, donde fue cuidado por Elisabeth, quien permitió a la gente visitar a su poco comunicativo hermano. El 25 de agosto de 1900, Nietzsche murió después de contraer neumonía. Por deseo de Elisabeth, fue inhumado junto a su padre en la iglesia de Röcken.

La causa del hundimiento de Nietzsche ha sido un tema de especulación y origen incierto. Un frecuente y temprano diagnóstico era una infección de sífilis, sin embargo, algunos de los síntomas de Nietzsche eran inconsistentes. Otro diagnóstico posible es un meningioma derecho retroorbital, un tipo de cáncer cerebral. En su libro "La lucha contra el demonio", Stefan Zweig presenta una psicobiografía sobre Nietzsche en que sitúa la etiología de su locura desde un ángulo puramente psicogénico.

Hay una controversia sobre si Nietzsche abogaba por un único punto de vista de comprensión filosófica. Muchos cargan contra Nietzsche por la contradicción de sus pensamientos e ideas.

Una tesis alternativa en la contradicción de los escritos de Nietzsche es el de la perspectiva, o la idea de que Nietzsche usaba múltiples puntos de vista en su trabajo como un medio para retar al lector a considerar varias facetas de un tema. Si uno acepta su tesis, la variedad y número de perspectivas sirven como una afirmación de la riqueza de la filosofía. Esto no quiere decir que Nietzsche viera todas las ideas como igualmente válidas. Tenía aspectos en los que no estaba de acuerdo con respecto a otros filósofos como Kant. Tampoco está claro dónde se posicionaba Nietzsche en cada tema. De cualquier modo, si uno mantiene los elementos en conflicto de sus escritos como algo intencionado o no, hay pocas dudas de que sus ideas siguen siendo influyentes.

Algunos filósofos han designado al estilo aforístico de Nietzsche como el responsable de estas aparentes contradicciones en su pensamiento, llegando a decir por ejemplo que «hay tantos Nietzsches como lectores». Esta afirmación resulta excesivamente cómoda ya que sólo pretende facilitar la explicación de las contradicciones sin intentar desentrañar su sentido final.

La filosofía de Nietzsche se halla atravesada esencialmente por la herencia de la cosmología clásica, en particular por los conceptos de la cosmogonía griega. Esto es, la identificación del carácter más humano del hombre en relación con el vínculo que guarda con sus dioses. Hablamos de la dualidad de lo apolíneo contra lo dionisíaco. Nietzsche, aunque no descarta por completo la regencia de lo apolíneo en la vida como ha sido heredada, particularmente desde la modernidad, se inclina por resaltar y adoptar una postura en esta línea de lo dionisíaco. En ello consiste precisamente su crítica a la sociedad contemporánea y éste será el hilo conductor que permea de forma constante su obra y su vida.

Para Nietzsche, la sociedad occidental se encuentra sumida en un profundo nihilismo que ha de superar si no quiere ver su fin. El nihilismo (que tiene distintas formas) es un advenimiento de unas repetidas frustraciones en la búsqueda de significado, o más precisamente, «la desvalorización de los valores supremos». El nihilismo en Nietzsche se refiere al proceso histórico que surge en el reconocimiento de un valor sumo y termina en la asunción o reconocimiento de múltiples cosas valorables, al volverse inoperante lo que antes se mostraba como lo supremo. El nihilismo acontece en nuestro tiempo como manifestación de la ausencia de una medida única y, al mismo tiempo, como la proliferación de múltiples medidas que, en cada caso, pueden aparecer como válidas. Nietzsche ve en el despliegue del nihilismo toda fundación de cultura europea, la que surge como destino necesario de este proceso. La visión religiosa del mundo había sufrido ya un gran número de cambios por perspectivas contrarias, cayendo en el escepticismo filosófico, y en las teorías científicas evolucionistas y heliocéntricas modernas, lo que no hace más que confirmar la desvalorización de los valores supremos. A lo ya señalado, hemos de sumar una creciente presencia de lo democrático, la que se muestra como la afirmación de una individualidad independiente de Dios y acreedora de la igualdad, de la medianía. La democracia aparece, a los ojos de Nietzsche, como un momento del despliegue del nihilismo igualmente negador de la vida que los que la antecedieron. Ambas manifestaciones del nihilismo se muestran a Nietzsche como negaciones de la vida, al negar u olvidar dimensiones de la misma que, a su parecer, aparecen como constitutivas de ella e inalienables a lo que él considera vida. Estas dimensiones negadas de la vida se muestran en ámbitos tan determinantes como el constante darse del devenir y las diferencias entre los hombres.

Nietzsche ve esta condición intelectual como un nuevo reto para la cultura europea, lo que se ha extendido, asimismo, más allá de un pequeño punto de no-retorno. Nietzsche conceptualiza esto con su famosa frase, «Dios ha muerto», que aparece en "La gaya ciencia" y en "Así habló Zaratustra". Esta frase fue dada también por Hegel veinte años antes de que Nietzsche naciera. Este aforismo, por una parte, señala el fin de eso que antes aparecía como lo imperante, y por otra, indica un terreno fértil, un terreno inexplorado, en el cual el propio Nietzsche es un colono. A partir de la frase «Dios ha muerto», Nietzsche se refiere tanto a la ceguera del pasado en tanto incapacidad de ver esto, como a la asunción de una nueva posibilidad de relacionarse con lo que es, posibilidad dada por la asunción de dicha muerte.

Nietzsche trata esta frase más que como una mera declaración provocativa, casi como una revelación, como si representase el potencial de nihilismo que arrastra el alzamiento y el progreso, en el contexto de un concepto absurdo y sin significado.

Según Nietzsche, el hombre europeo descendiente de los hiperbóreos ha de asumir la gran e inevitable consecuencia de la muerte en la sociedad occidental de Dios, del Dios judeocristiano, el vengativo y cruel Yahvé. La consecuencia de la muerte de Dios es que los valores vigentes en la sociedad occidental se vienen abajo ellos solos, según el nihilismo, o no se vienen abajo sino que los hombres los destruimos. Según Nietzsche la superación del nihilismo se producirá cuando el Übermensch imponga unos nuevos valores de acuerdo a la moral de señores, destruyendo los valores de la moral de esclavos. Resumiendo, destruimos los valores de los hombres para poner en su lugar los valores del Übermensch, que ocupará el lugar de Dios.

Nietzsche pensaba que había dos clases de hombres: los señores y los siervos, que han dado distinto sentido a la moral. Para los señores, el binomio «bien-mal» equivale a «noble-despreciable». Desprecian como malo todo aquello que es fruto de la cobardía, el temor, la compasión, todo lo que es débil y disminuye el impulso vital. Aprecian como bueno, en cambio, todo lo superior y altivo, fuerte y dominador. La moral de los señores se basa en la fe en sí mismos, el orgullo propio.

Por el contrario, la moral de los siervos nace de los oprimidos y débiles, y comienza por condenar los valores y las cualidades de los poderosos. Una vez denigrado el poderío, el dominio, la gloria de los señores, el esclavo procede a decretar como «buenas» las cualidades de los débiles: la compasión, el servicio —propios del cristianismo—, la paciencia, la humildad. Los siervos inventan una moral que haga más llevadera su condición de esclavos. Como tienen que obedecer a los señores, los siervos dicen que la obediencia es buena y que el orgullo es malo. Como los esclavos son débiles promueven valores como la mansedumbre y la misericordia; por el contrario, critican el egoísmo y la fuerza.

La crítica de Nietzsche a la moral tradicional se centraba en la tipología de moral de «amo» y de «esclavo» y en la descripción de la dinámica que generan; esta dinámica o dialéctica debe ser conocida por los «espíritus libres» para conducir a la humanidad a su superación: una sucesión de continuas superaciones —la moral deja de ser algo cerrado para ser visto como una dinámica de morales yuxtapuestas y reconocibles en la dinámica de las lenguas. Examinando la etimología de las palabras alemanas "gut" («bueno»), "schlecht" («malo») y "böse" («malvado»), Nietzsche sostuvo que la distinción entre el bien y el mal fue originalmente descriptiva, o sea, una referencia amoral a aquellos que eran privilegiados (los amos), en contraste con los que eran inferiores (los esclavos). El contraste bueno/malvado surge cuando los esclavos se vengan "convirtiendo los atributos de la supremacía en vicios". Si los favorecidos (los «buenos») eran poderosos, se decía que los sumisos heredarían la Tierra. El orgullo se volvió pecado, mientras que la caridad, humildad y obediencia reemplazaron a la competencia, el orgullo y la autonomía. La insistencia en la absolutidad ("Absolutheit") es esencial tanto en la ética religiosa como filosófica y fue clave para el triunfo de la moral de esclavo mediante la presunción de ser la única moral verdadera.

La voluntad de poder ("der Wille zur Macht") es un concepto altamente controvertido en la filosofía nietzscheana, generando intenso debate e interpretaciones varias, algunas de las cuales, como la notoria interpretación dada por los intelectuales nazis, fueron intentos deliberados de justificación de tácticas políticas.

Una manera de abordar este concepto es por medio de la crítica nietzscheana a la teoría de la evolución de Darwin. Nietzsche veía en los instintos una fuerza que iba más allá del sólo impulso a sobrevivir, protegerse y reproducirse de todos los seres vivos, de sólo ser esto la vida se estancaría. La supervivencia era una de las consecuencias de un deseo aún mayor, impulso hacia una supravivencia, un deseo perpetuo de todo ser vivo por ir más allá de todos, el todo y hasta más allá de sí mismo, más allá de la muerte. Este impulso irracional o deseo perpetuo por expandirse impreso en cada ser es lo único que da sentido a la existencia, paradójicamente «razón de ser» y es la fuerza principal dentro de la visión trágica o dionisíaca de Nietzsche.

Las teorías posteriores de Sigmund Freud respecto al inconsciente probablemente fueron inspiradas en gran parte por los conceptos de lo Dionisíaco y la voluntad de poder, las cuales Freud relacionó a los instintos sexuales primitivos, por encima de cualquier otro instinto, y su represión y control excesivo por el consciente o parte Apolínea del ser como generadores de la histeria y otras dolencias.

La idea del eterno retorno ha sido tratada como un concepto basilar para Nietzsche por muchos, aunque no por todos los intérpretes.

Nietzsche encuentra la idea en los trabajos de Heinrich Heine, quien especulaba que llegaría el día en el que la persona volvería a nacer con el mismo proceso de él mismo, y con el mismo en todas las demás personas. Nietzsche expandió este concepto para formar su teoría, la cual resaltó en "La gaya ciencia" y desarrolló en "Así habló Zaratustra". En las lecturas de Nietzsche sobre Schopenhauer, le saltó la idea del eterno retorno. Schopenhauer sentenciaba que una persona que se afirmara en la vida incondicionalmente lo haría incluso si todo lo que le había pasado le ocurriera de nuevo de forma repetida.

En unas pocas ocasiones en sus notas, Nietzsche discurre la posibilidad del eterno retorno como verdad cosmológica (véase el libro de Arthur Danto "Nietzsche como filósofo" para un análisis en detalle de estos esfuerzos), pero en los trabajos que él preparó para publicar está tratado como el método más vanguardista de afirmación de la vida. Según Nietzsche, requeriría un sincero "Amor fati" («Amor al destino»), no simplemente para sobrellevar, sino para desear la ocurrencia del eterno retorno de todos los eventos exactamente como ocurrieron, todo el dolor y la alegría, lo embarazoso y la gloria, esta repetición, más de emociones y sentimientos que de hechos, es lo que configuraría el tipo y la raza universal y global del por venir, no como una raza de las ya existentes, sino como una posibilidad abierta del hombre inacabado como especie genética y lingüística que debe ser perfilada por el eterno retorno de la superación de sus previos pensamientos y hechos.

Nietzsche menciona la idea de lo «horrible y paralizante», y también mantiene que la carga de esta idea es el peso más pesado imaginable ("Das schwerste Gewicht"). El deseo del eterno retorno de todos los eventos marcaría la afirmación de la vida definitiva.

Según algunos intérpretes, el eterno retorno es más que el mero concepto intelectual o reto, refleja una "Kōan", o característica psicológica que ocupa la estimulación consciente etérea, una transformación de consciencia conocida como "metanoia".

Alexander Nehamas escribió en "Nietzsche: vida como literatura" que hay tres maneras de ver el eterno retorno: (a) Mi vida volverá del mismo modo. Esto es una aproximación fatalista a la idea; (b) Mi vida puede ocurrir del mismo modo. Esta segunda visión es una aserción condicional de cosmología, pero falla al captar lo que Nietzsche se refiere en "La gaya ciencia"; (c) Es mi vida por re-ocurrir, entonces podría re-ocurrir sólo en idéntico modo. Nehamas muestra que esta interpretación es totalmente independiente de la física y no presupone la verdad de la cosmología. La interpretación de Nehamas es que los individuos se constituyen ellos mismos a través de las acciones y la única manera de mantenerse a ellos mismos como son es vivir en una reocurrencia de acciones pasadas.

El eterno retorno cumple pues dos funciones en la filosofía de Nietzsche. La primera es remarcar el amor a la vida. Los cristianos postulan un paraíso, Platón el mundo de las ideas. Nietzsche dice que después está otra vez la tierra, el mundo: porque no hay nada más. Por otro lado cumple una función ética. Quien acepta el eterno retorno, se previene y acepta sus actos. Con el dolor que puedan contraer, con el placer que puedan conllevar: no hay lugar para el arrepentimiento.

Extrapolando ideas del darwinismo Nietzsche considera que el ser humano ("Mensch") es un ser incompleto, pues todo animal da lugar a algo superior. Es un puente entre el simio y el "Übermensch" (término que ha sido traducido con frecuencia, aunque no con excesiva fortuna, como 'superhombre' o 'suprahombre', existiendo autores que prefieren su traducción como 'ultrahombre'). El hombre es, por tanto, algo que debe ser saltado, superado. El "Übermensch" es aquel ser que tiene una moral de nobles, es un noble, y acepta la voluntad de poder: es un hombre legislador, él crea sus propias normas, morales y de todo tipo, además es un hombre que somete las cosas a su voluntad, es un hombre vital: ama la vida y este mundo. Además es un ser que acepta el eterno retorno, pues cuando toma una decisión realmente la quiere tomar, y no se arrepiente de sus actos. Sabe que la vida es en parte dolor y en parte placer, pero no reniega de ello.

Desarrollando la idea del nihilismo, Nietzsche escribió "Así habló Zaratustra", introduciendo en él el concepto del primer hombre creador de valores, no como un proyecto, sino como un antiproyecto, la ausencia de proyecto alguno. En dicho libro Zaratustra se refiere a las «tres transformaciones del espíritu», el que se transforma figurada y sucesivamente en camello, león y finalmente niño. Este estado amoral y de creación de nuevos valores puede interpretarse como el inicio del camino hacia el ideal del "Übermensch": «Inocencia es el niño, y olvido, un nuevo comienzo, un juego, una rueda que se mueve por sí misma, un primer movimiento, un santo decir sí. Sí, hermanos míos, para el juego del crear se precisa un santo decir sí: el espíritu quiere ahora su voluntad, el retirado del mundo conquista ahora su mundo».

Hay controversia sobre qué o a quién consideraba Nietzsche como «Übermensch». No sólo hay cierta base para pensar que Nietzsche era escéptico sobre la identidad individual y la noción de sujeto, sino que habría un ejemplo concreto del Ultrahombre como algo nuclear. Las interpretaciones modernas de Nietzsche, especialmente después del trabajo de Walter Kaufmann, sugieren que la visión de Nietzsche sobre el "Übermensch" está más en línea con el concepto de hombre renacentista, como Goethe o Da Vinci.

Normalmente se traduce como «superhombre»; sin embargo esta traducción es errónea ya que el prefijo alemán "über" significa 'superior' como adjetivo, o 'sobre' (como el "over" inglés). Además "Mensch" significa 'humano', 'persona', esto es, 'hombre' en términos de especie, y no de sexo. En castellano puede dar lugar a equívocos si se lo lee con mala intención. Por lo tanto, la traducción más correcta al castellano sería 'suprahumano' o 'sobrehumano', pero en el uso más convencional sería 'suprahombre', o bien, 'ultrahombre', tal como el filósofo Vattimo ha sugerido.

Siempre debe recordarse que el concepto se contrapone a cualquier término sexista y al del «último hombre», el que presenciará el gran mediodía que representa el último paso de superación del hombre moral y septentrional, y la etapa final del nihilismo. Es en este sentido en que debe entenderse al super-hombre como uno de los objetivos nietzscheanos, y no como una «calidad» a la que se pueda acceder, o una «categoría» que se pueda obtener.

En su libro "El Anticristo, maldición sobre el cristianismo" (1888), Nietzsche escribe sobre cómo la cristiandad se ha convertido en una ideología establecida por instituciones como la Iglesia, y cómo las iglesias han fallado a la hora de representar la vida de Jesús, es importante destacar que Nietzsche vivió en una sociedad protestante y su repulsa hacia el cristianismo se forjó a partir del conocimiento de dicha doctrina. Es importante, para él, distinguir entre la religión de la cristiandad y la persona de Jesús. Nietzsche explicó la religión cristiana como si fuera representado por iglesias e instituciones a las que llamaba su «transvaloración» (del alemán "Umwertung") de los valores instintivos saludables. Transvaloración es el proceso por el cual el significado de un concepto o ideología puede ser puesto al revés de lo expresado por su etimología. Fue más allá del pensamiento de los agnósticos o ateos de la Ilustración, quienes sentían que la Cristiandad era simplemente falsa. Él afirmaba que ha podido ser deliberadamente infundida como una religión subversiva (como un arma psicológica subversiva) dentro del Imperio Romano por el apóstol Pablo como una forma de cobrar venganza por la destrucción romana de Jerusalén y su templo durante la Primera guerra judeo-romana.

Nietzsche contrasta a los cristianos con Jesús, a quien admiraba de gran modo. Nietzsche argumenta que Jesús transcendió las influencias morales de su tiempo creando su propio sistema de valores. Jesús representaba un paso hacia el "Übermensch". Al final, Nietzsche clama sin embargo: en contraste con el suprahombre, quien abraza la vida, Jesús negaba la realeza en favor de su «Reino de Dios». La negación de Jesús para defenderse a sí mismo, y su muerte, eran consecuencias lógicas de su desajuste de sistema de ideas.

Nietzsche entonces analizó la historia de la cristiandad, descubriendo una distorsión progresiva de modo grotesco de las enseñanzas de Jesús. Él critica a los primeros cristianos por convertir a Jesús en un mártir y la vida de Jesús dentro de la historia de la salvación de la humanidad como motivo para dominar a las masas, encontrando a los apóstoles cobardes, vulgares y resentidos. Argumenta que las sucesivas generaciones malentendieron la vida de Jesús, mientras la influencia de la cristiandad crecía. En el siglo XIX, Nietzsche concluye que la cristiandad se ha vuelto tan mundana al punto de hacerse una parodia de sí misma, una total manipulación de sus enseñanzas y su «buena nueva». Es por esto que concluyó en una de sus frases más célebres: «El último cristiano murió en la cruz», considerando que Pablo de Tarso y los primeros cristianos (los «anticristianos») solo hicieron negocio con su figura a través de su Iglesia y nadie siguió realmente ni aspiró jamás a aceptar la doctrina de Cristo.

Nietzsche aborda la ética desde diferentes perspectivas. En términos de hoy en día, podemos decir que sus obras tocan los ámbitos de la metaética, la ética normativa, y la ética descriptiva.

En lo referente a la metaética, Nietzsche puede ser clasificado quizá como un escéptico moral. Esto es en la medida en que afirma que todas las sentencias éticas son falsas, porque cualquier tipo de correspondencia entre sentencias morales y hechos es ilusoria y mendaz. Esta afirmación forma parte de aquella otra más general según la cual no existe una verdad universal, pues ninguna corresponde a la realidad más que de una forma aparente. En realidad, las afirmaciones éticas, como todas las afirmaciones, son meras interpretaciones como mínimo siempre parciales sobrepuestas a la realidad, fundamentalmente ininterpretable.

A veces, Nietzsche puede parecer tener opiniones muy definidas en lo que es moral e inmoral. Hay que notar, no obstante, que las opiniones morales de Nietzsche se pueden explicar sin atribuirle la afirmación de que son "ciertas". Según Nietzsche, no necesitamos descartar una afirmación simplemente porque sea falsa. Al contrario, a menudo afirma que la falsedad es esencial para la vida. Curiosamente, en sus discusiones figuradas con Wagner en "El caso Wagner" menciona la "mentira deshonesta", como opuesta a la "mentira honesta". Posteriormente menciona a Platón como referente sobre esta última. Esto debería dar una idea de los múltiples niveles interpretativos de su obra, a menudo aparentemente paradójicos si no se toman las debidas cautelas hermenéuticas.

En la disyuntiva entre ética normativa y ética descriptiva distingue entre la "moral de señor" y la "moral de esclavo". Aunque reconoce que es muy difícil encontrar un ejemplo real de alguien que mantenga una u otra moral pura sin algún tipo de yuxtaposición (de hecho era consciente de estar haciendo historia al vislumbrar «genealógicamente» esta distinción), las presenta, a lo largo de la historia y actualmente en tanto que pulsiones humanas atemporales, una en contraste de la otra. Algunos de estos contrastes de una moral frente a la otra son:


Estas ideas fueron elaboradas en su libro "La genealogía de la moral", en el cual además introdujo el concepto clave del "resentimiento" como base de la moral del esclavo.

También es conocido como hemos dicho por su frase «Dios ha muerto», mientras en la creencia popular se cree que es Nietzsche de donde procede esta frase, es puesta en verdad en boca de un personaje, un hombre loco, en "La gaya ciencia". Fue más adelante dicha por el Zaratustra de Nietzsche. Estas frases malinterpretadas no proclaman una muerte física, sino un final natural a la creencia de dios. Está altamente malentendido como una declaración de regocijo, cuando es descrito como un lamento trágico por el personaje de Zaratustra.

«Dios ha muerto» es más una observación que una declaración. Nietzsche no dio argumentos para el ateísmo, sino meramente observó que, para todos los efectos prácticos, sus contemporáneos vivían como si Dios estuviera muerto. Nietzsche creía que esta muerte minaba los fundamentos de la moral y que acabaría por desembocar en el más completo nihilismo y relativismo moral. Para evitar esto, él creía en la revaluación de los fundamentos de la moral para comprender mejor los motivos y orígenes subyacentes de los primeros. De esta manera los individuos podrían decidir por sí mismos si un valor moral es obsoleto o está desviado por imposiciones culturales o quieren realmente tomar ese valor como cierto.

Si bien es fácil ver un aire político en los escritos de Nietzsche, su trabajo no fue de ningún modo pensado para ser un panfleto político. La influencia que Nietzsche ejerció sobre la política de la «nueva derecha» fue realmente extensa. Afirmó que el poder de un sistema es signo de falta de integridad, no propuso un sistema de gobierno específico como solución, y nunca se vinculó a sí mismo con movimientos de masas, organizaciones sociales o partidos políticos. En este sentido, Nietzsche casi podría ser llamado un pensador anti-político. Walter Kaufmann enfatiza la visión de que el poderoso individualismo expresado en sus escritos sería desastroso si se practicara en las bases reales de los políticos. Escritores posteriores, guiados por la izquierda intelectual francesa, han propuesto maneras de usar la teoría nietzscheana en lo que se ha llegado a conocer como «políticas de diferencias», en especial formulando teorías sobre resistencia política y sobre diferencias sexuales y morales.

Revisando ampliamente los escritos de Kauffmann y otros, el espectro del nazismo ha sido hoy en día casi extinto de sus escritos. Nietzsche a menudo se refería como «el rebaño» a los participantes de los movimientos de masas que comparten una psicología común de la masa. Valoraba el individualismo y el lenguaje como obra común que nos construye y era en especial opuesto al altruismo, pero consideraba sus obras como regalos a la humanidad. Despreciaba al Estado moderno, Nietzsche también habló negativamente de demócratas y socialistas y dejó claro que sólo ciertos individuos podían romper la moral del rebaño. Pero son sus propias palabras las que deberían alejar cualquier sospecha de simpatía con el nazismo:

Al pueblo se refería como «perro de fuego». En "Zaratustra" desarrolla esta idea como fuerzas dinámicas de las que hay que tomar partido en el desarrollo histórico. El perro de fuego representa los ideales populares por diferenciarse de otros pueblos. En «De viejas y nuevas tablas», desarrolla también la idea de cómo ciertos valores morales acaban por ser institucionalizados en normas de domesticación y a eso llaman nacionalismo... ¡domesticar a favor del Estado al perro de fuego que cometió esos desmembramientos de cabeza y dio su apoyo popular a Napoleón! Sólo el individuo alienado de las masas puede comprender su situación con respecto al resto.

Los comentarios de Nietzsche sobre las mujeres han provocado una gran polémica. El hecho de que Nietzsche ridiculizara a la humanidad en general no le salva de la carga del sexismo. Algunas de sus afirmaciones sobre las mujeres parecían prefigurar la crítica del post-feminismo contra las versiones primerizas del feminismo, particularmente aquellas que afirman que el feminismo ortodoxo discrimina a las propias mujeres en función de su posición social privilegiada. En este contexto, el pensamiento de Nietzsche ha sido relacionado con el opúsculo de Schopenhauer «Sobre las mujeres» (Parerga y paralipómena), habiendo sido muy probablemente influenciado por él en algún grado.

De todos modos, Nietzsche en su libro "Más allá del bien y del mal" muestra un carácter misógino similar, en muchos aspectos, al de Schopenhauer. Ambos hablan del sexo femenino como de un "segundo papel", y sus comentarios tratan a la mujer hasta como un animal incluso haciendo apología de los tratos que se le daban a ellas en la antigüedad. Habla también, Nietzsche, del progreso del feminismo como una degeneración en la historia, principalmente en lo tratante a la igualdad de derechos a los cuales se muestra en contra.

Los escritos de Nietzsche han sido interpretados de diversas maneras, e incluso existen casos en los que Nietzsche es citado para sustentar visiones contradictorias.

Por ejemplo, Nietzsche era popular entre el ala izquierdista de la Alemania de 1890, pero unas décadas después, durante la Primera Guerra Mundial, muchos le vieron como la raíz del ala derecha del militarismo alemán. Tengamos en cuenta que es más factible que la derecha acepte las máximas nietzscheanas anticompasivas, belicosas y aristocráticas, en tanto las doctrinas igualitarias como el comunismo —con la excepción de la belicosidad y fórmulas anticompasivas aplicadas en el régimen comunista soviético— y la democracia fueron despreciadas por él. Otro ejemplo se establece en la época del «Caso Dreyfus». La derecha antisemita francesa elevó la acusación a judíos e intelectuales de izquierdas que defendían a Alfred Dreyfus de ser nietzscheanos. Los conservadores alemanes quisieron censurar los trabajos de Nietzsche ante el peligro de subversión en 1894-1895, mientras que la Alemania nazi lo utilizó como excusa intelectual para promover su idea de la resurrección de la cultura alemana y de la identidad nacional. Muchos alemanes leyeron "Así habló Zaratustra" y se vieron influenciados por el llamamiento de Nietzsche del individualismo ilimitado y al desarrollo de la propia personalidad. Así durante el final del Siglo XIX y el comienzo del Siglo XX las ideas de Nietzsche estaban comúnmente asociadas con el movimiento anarquista y parece que tuvieron una influencia dentro de este, particularmente en Francia y Estados Unidos (ver también Anarquismo y Friedrich Nietzsche).

Durante el "interbellum", muchos fragmentos del trabajo de Nietzsche fueron apropiados por los nazis, principalmente por Alfred Bäumler en "La voluntad de poder". Durante el periodo de dominio nazi, las obras de Nietzsche fueron muy estudiadas en los colegios y universidades alemanas. Los nazis creyeron ver en Nietzsche a uno de los padres fundadores. Incorporaron la ideología y el pensamiento sobre el poder dentro de su propia filosofía política. Expresiones como "La voluntad de poder" fueron relacionadas con el nazismo y proclamadas como paradigma del movimiento. Sin embargo, existen muy pocas, si acaso alguna, similitudes entre Nietzsche y el nazismo. En múltiples pasajes a lo largo de sus obras, Nietzsche defiende ardorosamente a los judíos, y expresa su rabia contra la lenta pero imparable corriente antisemita en Alemania, personificada dolorosamente en su propia familia a través de la figura de su hermana, que adoptó fervientemente el ideario racista, influenciada por su marido, para el cual no escatimó el filósofo todo tipo de improperios en muchas de sus cartas.

Uno de los más importantes estudiosos de Nietzsche fue el reconocido filósofo alemán Martin Heidegger. Éste fue durante unos meses Rector de la Universidad de Friburgo —renunció mucho antes de terminar su período—, donde realiza su famoso, por lo polémico, «Discurso de rectorado», en el cual aparecen ideas nacionalistas, que algunos, han interpretado como un discurso en favor del nuevo "Führer", por ese entonces, Adolf Hitler.





</doc>
<doc id="2031" url="https://es.wikipedia.org/wiki?curid=2031" title="Neurofisiología">
Neurofisiología

La Neurofisiología es la rama de la fisiología que estudia el sistema nervioso.

En cualquier acción o conducta de todo organismo está presente el sistema nervioso. Cualquier cambio en su desarrollo es resultado de modificaciones funcionales de dicho sistema.
La neurofisiología se ocupa de desvelar cómo funciona este complicado sistema y cómo produce la variedad de modelos de conductas que manifiestan los organismos. Sin embargo, a pesar de los avances producidos en la investigación, sobre todo en los aspectos bioquímicos y eléctricos, se tiene la convicción de que es mucho más lo que se desconoce.


La neurofisiología elemental trata de estudiar el comportamiento de neuronas o grupos de neuronas aisladas. Los hechos establecidos por la neurofisiología elemental pueden ser aprovechados por la teoría matemática de redes neuronales para construir modelos matemáticos que permitan identificar fenómenos neurofisiológicos como la memoria y el aprendizaje.
Los principales hechos establecidos por la neurofisiología elemental tenidos en cuenta en la construcción de modelos de redes neuronales son:



</doc>
<doc id="2032" url="https://es.wikipedia.org/wiki?curid=2032" title="Neuroanatomía">
Neuroanatomía

La neuroanatomía es el estudio de la estructura y la organización del sistema nervioso.
Se llama neuroanatomía comparada a la ciencia que analiza y compara los sistemas nerviosos de las diferentes especies. Desde los sistemas más simples hasta el de los mamíferos y el hombre.

El primer registro escrito conocido de un estudio de la anatomía del cerebro humano es egipcio, el papiro de Edwin Smith. El siguiente desarrollo importante en neuroanatomía fue de unos mil años más tarde, cuando el griego Alcmeón determinó que el cerebro y no el corazón, como se creía, gobierna al cuerpo y recibe información de los sentidos. Uno de los fundadores de la neuroanatomía moderna fue el descubridor de la neurona, el español Santiago Ramón y Cajal, premio Nobel de medicina en 1906.

El sistema nervioso de los vertebrados está constituido por el cerebro y la médula espinal (el sistema nervioso central o SNC) y por las rutas de los nervios que se conectan con el resto del cuerpo (el sistema nervioso periférico o SNP). 
El sistema nervioso central (SNC) consiste en el cerebro, la retina, y la médula espinal, mientras que el sistema nervioso periférico (SNP) se compone de todos los nervios fuera del sistema nervioso central que lo conectan con el resto del cuerpo. 

El sistema nervioso central está compuesto de las regiones del cerebro, tales como, por ejemplo, el hipocampo que es crítico para la formación de las memorias. 
El sistema nervioso también contiene los nervios, que son haces de fibras que se originan en el cerebro y la médula espinal, y se ramifican varias veces para inervar a cada parte del cuerpo. Los nervios están constituidos principalmente de los axones de las neuronas, junto con una variedad de membranas que recubren los fascículos nerviosos.

El cerebro y la médula espinal están exteriormente protegidos por las estructuras óseas que son el cráneo y la columna vertebral. Interiormente son envueltos por tres membranas: la duramadre, la aracnoides y la piamadre. Además están bañados por el líquido cefalorraquídeo que completa los espacios vacíos y actúa como amortiguador de golpes, entre otras funciones.

Con el fin de precisar las ubicaciones anatómicas se hacen frecuentes referencias a detalles notorios del cerebro como las cisuras y se utilizan planos de orientación o planos de sección que generalmente son "sagital", "transversal" o "coronal" u horizontal. 

El SNC está constituido anatómicamente por él:

El SNP está constituido por:

El SNP se subdivide en el somático y el sistema nervioso autónomo. 
El sistema nervioso autónomo también tiene dos subdivisiones, el simpático (SNS) y el parasimpático (SNPS), que son importantes para la regulación del cuerpo en las funciones básicas del organismo, tales como el ritmo cardíaco, la respiración, la digestión, el control de temperatura, etc
El SNS prepara al cuerpo para actuar en una emergencia y el SNPS dispone al cuerpo conservar y restablecer energía.
Mucho de lo aprendido procede de observar cómo las "lesiones" de áreas específicas del cerebro afectan al comportamiento u otras funciones.
Nuevos recursos han ido mejorando las posibilidades de observar la situación y los aspectos del funcionamiento cerebral en personas vivas y sanas. La tomografía computada, la resonancia magnética y los emisores de positrones (PET) son creadores de imágenes sin “invadir” a la persona observada. 
Este último, con el auxilio de productos apropiados inyectados, permite observar el grado de actividad de cada zona cerebral en diferentes circunstancias. Así se logra determinar con mayor precisión las zonas involucradas en el razonamiento, la memoria, las emociones como el amor, el miedo, etc., y se conocen los trayectos que realizan los estímulos nerviosos que participan.

Se sitúa dentro del conducto rodeada por las tres meninges y el líquido cefalorraquídeo. La arquitectura de la médula espinal es aproximadamente cilíndrica, y comienza por arriba en el agujero occipital en el cráneo, a donde se continúa con el bulbo raquídeo, y termina por debajo de la región lumbar en forma de huso en el cono medular, desde cuyo vértice se conforma desciende una prolongación piamádrica, formando al Filo Terminal o "Filum Terminalis".

A lo largo del trayecto de la médula espinal se localizan 31 pares de nervios espinales unidos por raíces anteriores o motríces, y raíces posteriores o sensitivas.

La estructura de la médula espinal está compuesta en su porción céntrica por la sustancia gris, y en su periferia por la sustancia blanca.

En un corte transversal se puede observar a la sustancia gris formar una silueta similar al de una mariposa, con sus cordones grises anteriores y posteriores unidas por la comisura gris. La sustancia blanca se divide en cordones blancos anteriores, laterales y posteriores. 

La arquitectura de la médula espinal cambia de acuerdo a su posición. 

Se sitúa en la cavidad craneana y se continúa con la médula espinal a través del agujero occipital. Está rodeado por tres meninges. El encéfalo se divide en tres partes principales, estas son:


La base celular del sistema nervioso se compone de neuronas, células gliales, y matriz extracelular. Existen neuronas y células gliales de muchos tipos. Las neuronas son las células de procesamiento de información del sistema nervioso: generan la sensación de nuestro entorno, producen nuestros pensamientos y provocan nuestros movimientos. Se comunican entre sí por medio de señales eléctricas que recorren sus prolongaciones: los axones y las dentritas; las uniones interneuronales se llaman sinapsis y son estructuras complejas. Las células gliales mantienen la homeostasis, la producción de mielina, y brindan apoyo y protección a las neuronas del cerebro. Algunas células gliales (astrocitos) incluso pueden propagar las ondas de calcio intercelular por largas distancias en respuesta a la estimulación y liberar “gliotransmisores” en respuesta a cambios en la concentración de calcio. La matriz extracelular proporciona también apoyo a nivel molecular para las células del cerebro.

Estos recursos se utilizan en muestras obtenidas en biopsias, necropsias y en animales. 
La tinción es una técnica utilizada para mejorar el contraste creando características particulares en las imágenes microscópicas.
En histoquímica utiliza el conocimiento acerca de las propiedades bioquímicas de reacción de los componentes químicos del cerebro, especialmente de las enzimas.
La inmunocitoquímica es un caso especial de histoquímica que utiliza anticuerpos selectivos contra una variedad de epítopos químicas del sistema nervioso. Logra teñir selectivamente tipos particulares de células, fascículos axonales, neuropiles, procesos gliales o vasos sanguíneos, o ciertas proteínas específicas intracitoplasmáticas o intranucleares y otras moléculas inmunogenéticas. 
También se recurre a otras técnicas más complejas como la hibridación in situ que usa sondas de ARN, a marcadores codificados genéticamente y a ciertos virus que pueden replicarse en las células cerebrales y en las sinapsis.
Es muy útil la microscopía de electrones en serie (microscopio electrónico).



</doc>
<doc id="2033" url="https://es.wikipedia.org/wiki?curid=2033" title="Nuevo Testamento">
Nuevo Testamento

El Nuevo Testamento es la parte de la Biblia cristiana compuesta por un conjunto canónico de libros y cartas escritas después de la muerte de Jesús de Nazaret, que la tradición apostólica hizo discernir a la Iglesia, apartando otros textos considerados apócrifos (griego: από 'lejos', κρυφος 'oculto'; latín: apócryphus). Se le designa como Nuevo Testamento desde Tertuliano en la Iglesia cristiana. Al contrario con el Tanaj hebreo, llamado por los cristianos Antiguo Testamento, los judíos (a excepción de los llamados judíos mesiánicos), no tienen el Nuevo Testamento en común con los cristianos.

El uso del término «testamento» proviene del vocablo hebreo "berith" ('alianza, pacto, convenio o disposiciones entre dos contratantes'), a través del griego "diatheké", y del latín "testamentum". Algunos autores presentan los nombres Antiguo y Nuevo Testamento con que se designa las dos grandes secciones en que se divide la Biblia cristiana como el resultado de un error de interpretación de la palabra "diatheké", que significa: 'deseo' o 'voluntad', y también 'acuerdo’ o 'convenio'. Con este criterio "diatheké" en griego haría referencia al antiguo y al nuevo convenio de Dios con los hombres más que a las Escrituras mismas.

Según otros autores, el término «testamento» proviene de la traducción de la Vulgata y del paso del concepto hebreo al griego, y sería el resultado de una búsqueda consciente. Los traductores de la Septuaginta habrían querido evitar que al hablar del "berith" (la alianza entre Dios e Israel) se entendiera que era un pacto entre iguales. Por eso no usaron el término griego "syntheké" (que se traduce por 'alianza'), sino que escogieron "diatheké", que se traduce por 'testamento' o 'voluntad', que es la obligación de uno solo con respecto a otro que solo recibe beneficios. De esta forma destacaron más la disparidad entre las partes (es decir, entre Dios y los hombres). Luego, esa es una de las acepciones de la palabra "testamentum", y de la castellana «testamento» (no entendida solo como última voluntad "ex mortis", como en el uso coloquial). De allí que las versiones latinas, como la de Jerónimo de Estridón, y la mayoría de las versiones de la Biblia cristiana siguen utilizando el término «testamento» en lugar de «alianza» para referirse al Antiguo Testamento (alianza del Sinaí) y al Nuevo Testamento (alianza en la sangre de Cristo).

Aun conviniendo que tales conceptos no hacen referencia a las colecciones de escritos sagrados, sino a relaciones entre la divinidad y los seres humanos en la historia religiosa, la mayoría de los eruditos simplemente se remiten al uso popular y coloquial de estos conceptos para referirse a los textos sagrados del canon hebreo y griego cristiano. 

Las versiones más antiguas de textos del llamado Nuevo Testamento, que se conservan, están escritas en el griego denominado koiné, la lengua franca en el Mediterráneo Oriental en época romana. La mayoría de los especialistas cree que éste fue el idioma en que originalmente se redactaron, aunque algunos libros puedan haberse escrito primero en idioma hebreo o arameo, la lengua semita hablada por Jesús y su entorno. Aún hoy existen textos manuscritos fechados como desde el siglo V (cercanos a los más antiguos manuscritos griegos completos) en arameo como la Peshita siríaca, la Harclense y la Curetoniana, pero la mayoría de los estudiosos los consideran traducciones del griego.

La composición del Nuevo Testamento canónico se fijó poco a poco en los primeros siglos del nuevo movimiento. La lista más antigua se supone redactada hacia el año 170.

La lista actual fue publicada originalmente por Atanasio de Alejandría en 370 y consagrada como canónica en el Tercer Concilio de Cartago de 397. Sin embargo, las disputas sobre la composición del canon no cesaron. Martín Lutero cuestionó la pertinencia de incluir la Epístola de Santiago, la Epístola de Judas, la Epístola a los Hebreos y el Apocalipsis de Juan o Libro de la Revelación; aunque finalmente, a diferencia de los deuterocanónicos del Antiguo Testamento, no fueron nunca rechazados. Sin embargo, la canonización de 2 Pedro, 2 Juan, 3 Juan, Santiago y Judas, así como de Hebreos y Apocalipsis, sigue siendo tema de debate.

El Nuevo Testamento comprende los cuatro Evangelios canónicos, los Hechos de los Apóstoles, las epístolas de Pablo de Tarso, siete epístolas de diversa atribución y el Apocalipsis, como se puede observar en el esquema que se encuentra a continuación.

Comprende, en total, 27 libros en el canon de la Iglesia católica, aceptado por la mayoría de las Iglesias de la Reforma. La Iglesia Siria solo acepta 22 libros en su canon. Libros como 1 y 2 de Clemente, el libro de la Alianza, el Octateuco y otros, han sido motivo de disputas, y se encuentran canonizados por parte de otras iglesias Católicas Ortodoxas

Según Robert W. Funk, fundador del "Jesus Seminar" (‘seminario de Jesús’), existen muchas variantes en los distintos manuscritos griegos del Nuevo Testamento que han llegado hasta la actualidad; algunas son variantes menores sin trascendencia, pero también hay cambios significativos. Él asegura:

Los textos maestros se clasifican según criterio en "texto mayoritario recibido" o "Receptus" y "Texto Crítico". El primero prioriza las variaciones mayoritarias y tradicionales sin importar su antigüedad, se basa en la compilación iniciada por Erasmo. El segundo prioriza las lecturas más antiguas según criterio de jerarquía temporal, basándose en los textos más antiguos encontrados, aun recientemente, como el códice Sinaítico (costumbre seguida en las obras críticas de textos clásicos seculares). La vigésima séptima edición Nestlé-Aland es el texto maestro refinado más reciente y base para las traducciones vernáculas modernas.

Los manuscritos completos más antiguos del Nuevo Testamento son los códices pergaminos Sinaítico y Alejandrino, pero en cuanto a papiros, de data anterior existen cerca de cien papiros fragmentados (algunos caben en la palma de una mano).

El papiro Rylands (P) es el más antiguo de los manuscritos que se han encontrado de los cuatro evangelios canónicos. Se descubrió en el desierto de Egipto. Se publicó en 1935. Contiene algunos versículos del capítulo 18 del evangelio de Juan (Jn 18,31-33.37-38). Según el estudio grafológico es anterior al año 150 (suele datarse hacia 125-130 d. C).

Fue encontrado en una tienda de antigüedades en Luxor (Egipto) a finales del siglo XIX. Fue adquirido por un sacerdote llamado Charles Bousfield Huleatt, quien tras su muerte donó el papiro al Magdalen College de Oxford, donde pasó a denominarse Gr 17. (suele datarse de 200 d. C)

Se trata de papiros descubiertos por M. Martin Bodmer. Del conjunto de cuatro papiros Bodmer (P66, P72, P73, P74) que se conservan en la Biblioteca de Cologny, en Ginebra, destaca el P66. Encontrado en Egipto y datado hacia el año 200, contiene catorce capítulos del evangelio de Juan.

Por su parte, los papiros Bodmer 14 y 15, conocidos como P75, fueron descubiertos también en Egipto en 1956 y están datados del año 175 al 225 d. C. Contienen cerca de la mitad de los Evangelios de Lucas y de Juan, a saber:
P75 constituye el manuscrito más antiguo que mantiene unidos a dos Evangelios. Esto fue interpretado por diferentes escrituristas como una demostración de que, para las primeras comunidades cristianas, los Evangelios formaban una unidad. Pertenecieron a la Fundación Bodmer de Cologny (Ginebra). En 2007, fueron donados a la Biblioteca Apostólica Vaticana donde se conservan actualmente.

Son tres papiros (P45, P46 y P47) escritos antes del año 250 d. C. Contienen fragmentos de las epístolas de Pablo, del Apocalipsis y de los evangelios.

Data de mediados del siglo IV.

De mediados del siglo IV.

Del siglo V

Del siglo V.

Del siglo V. Solo contiene los Evangelios y los Hechos de los Apóstoles. El texto de los Hechos difiere algo de otras versiones.

Del siglo V. Solo contiene los Evangelios.



Se descubre el códice sinaítico (K. Tischendorf, 1859). Los códices "Sinaiticus" y "Vaticanus" dan lugar a los textos actuales.

En el año 397 el papa Siricio convoca el tercer concilio de Cartago donde se impone la vulgata (traducción de la Biblia al latín vulgar realizada por San Jerónimo del 382-405) y finalmente se edita el Nuevo Testamento.

Por siglos la Biblia fue el libro de mayor distribución en España, habiendo disponibles copias manuscritas en latín y, por varios siglos, hasta en la lengua gótica. Diversas historias bíblicas, salterios (o salmos), glosarios, relatos morales y obras similares se convirtieron en libros de mayor venta de la época. Copistas adiestrados reprodujeron concienzudamente exquisitos manuscritos bíblicos. Aunque a 20 escribas les tomaba todo un año producir un solo manuscrito de primera clase, muchas Biblias latinas y millares de comentarios sobre la Biblia latina circulaban en España para el siglo XV.

Cuando el idioma español empezó a desarrollarse, surgió interés en tener la Biblia en el lenguaje vernáculo. Para el siglo XII la Biblia se tradujo al romance o español antiguo, el lenguaje que hablaba la gente común.

Posteriormente la disidencia entre valdenses, lolardos y husitas hizo que por precaución a la herejía, la Iglesia prohibiera la traducción de la Biblia en lengua romance (Concilio de Toulouse, Francia, 1229). Por los siguientes doscientos años la única Biblia católica oficial publicada en España —aparte de la Vulgata latina— fue la Políglota complutense, la primera Biblia políglota, patrocinada por el cardenal Cisneros. Sólo se imprimieron 600 ejemplares. Contenía el texto bíblico en hebreo, arameo, griego y latín.

A principios del siglo XVI Francisco de Enzinas, hijo de un rico terrateniente español, empezó a traducir el Nuevo Testamento al español mientras todavía era un joven estudiante. Luego consiguió que se imprimiera su traducción en los Países Bajos, y en 1544 trató de obtener la autorización real para distribuirla en España, la cual le fue rechazada y terminó acusado ante la inquisición. Pocos años más tarde se imprimió una edición revisada de esa traducción en Venecia, Italia, la que Julián Hernández introdujo secretamente en Sevilla, siendo prendido y posteriormente ejecutado por herejía.

Sólo posteriormente se empezó a traducir la Biblia entera a lengua vernácula castellana con la Obra de Casiodoro de Reina (Biblia del Oso 1568-1569), por parte del protestantismo, y Felipe Scío de San Miguel (1790) y Félix Torres Amat (1823) en el catolicismo.




</doc>
<doc id="2034" url="https://es.wikipedia.org/wiki?curid=2034" title="Naturaleza">
Naturaleza

La naturaleza, en su sentido más amplio, es equivalente al mundo natural, mundo material o universo material. El término hace referencia a los fenómenos del mundo físico, y también a la vida en general. Por lo general, no incluye los objetos artificiales ni la intervención humana, a menos que se la califique de manera que haga referencia a ello, por ejemplo con expresiones como «naturaleza humana» o «la totalidad de la naturaleza». La naturaleza también se encuentra diferenciada de lo sobrenatural. Se extiende desde el mundo subatómico al galáctico.

La palabra «naturaleza» procede del latín "natura" que significa «perteneciente o relativo a la naturaleza o conforme a la cualidad o propiedad de las cosas», «carácter natural». 

La «naturaleza» es la dinámica y la armonía del conjunto de los seres vivos y la materia inerte en su extensa diversidad en todas sus variedades y combinaciones a través del tiempo y el espacio, de las actividades climáticas, sísmicas, volcánicas, geológicas, geográficas y atmosféricas.

El concepto de naturaleza como un todo —el universo físico— es un concepto más reciente que adquirió un uso cada vez más amplio con el desarrollo del método científico moderno en los últimos siglos.

Dentro de los diversos usos actuales de esta palabra, «naturaleza» puede hacer referencia al dominio general de diversos tipos de seres vivos, como plantas y animales, y en algunos casos a los procesos asociados con objetos inanimados —la forma en que existen los diversos tipos particulares de cosas y sus espontáneos cambios—, así como el tiempo atmosférico, la geología de la Tierra y la materia y energía que poseen todos estos entes. A menudo, se considera que significa «entorno natural»: animales salvajes, rocas, bosques, playas, y en general todas las cosas que no han sido alteradas sustancialmente por el ser humano, o que persisten a pesar de la intervención humana. Este concepto más tradicional de las cosas naturales implica una distinción entre lo natural y lo artificial (entendido esto último como algo hecho por una mente o una conciencia humana).

La Tierra es el quinto mayor planeta del sistema solar y el tercero en orden de distancia al Sol. Es el mayor de los planetas telúricos o interiores y el único lugar del universo en el que se sabe que existe vida.

Los rasgos más prominentes del clima de la Tierra son sus dos grandes regiones polares, dos zonas templadas relativamente estrechas y una amplia región ecuatorial, tropical y subtropical. Los patrones de precipitación varían enormemente dependiendo del lugar, desde varios metros de agua al año a menos de un milímetro. Aproximadamente el 70 por ciento de la superficie terrestre está cubierta por océanos de agua salada. El resto consiste en continentes e islas, situándose la mayor parte de la Tierra habitable en el hemisferio norte.

La Tierra ha evolucionado mediante procesos geológicos y biológicos que han dejado vestigios de las condiciones originales. La superficie externa se halla fragmentada en varias placas tectónicas que se van desplazando muy lentamente a medida que avanza el tiempo geológico (si bien al menos varias veces en la historia han cambiado de posición relativamente rápido). El interior del planeta permanece activo, con una gruesa capa de materiales fundidos y un núcleo rico en hierro que genera un potente campo magnético. Las condiciones atmosféricas han variado significativamente de las condiciones originales por la presencia de formas de vida, que crean un equilibrio ecológico que estabiliza las condiciones de la superficie. A pesar de las grandes variaciones regionales del clima por la latitud y otros factores geográficos, el clima global medio a largo plazo está regulado con bastante precisión, y las variaciones de un grado o dos en la temperatura global media han tenido efectos muy importantes en el equilibrio ecológico y en la geografía de la Tierra.
Basándose en las pruebas disponibles, los científicos han recabado información detallada acerca del pasado del planeta. Se cree que la Tierra se formó hace aproximadamente 4550 millones de años a partir de la nebulosa protosolar, junto con el Sol y otros planetas. La Luna se formó relativamente poco después (aproximadamente 20 millones de años más tarde, hace 4530 millones de años). Al principio fundida, la capa exterior del planeta se enfrió, dando lugar a la corteza sólida. Las emisiones de gases y la actividad volcánica formaron la atmósfera primordial. La condensación del vapor de agua, junto con el hielo de los cometas que en aquella época impactaban con la Tierra, crearon los océanos. Se cree que la química altamente energética produjo una molécula que se autoduplicó hace aproximadamente 4000 millones de años.

Los continentes se formaron, se separaron y se volvieron a unir durante cientos de millones de años, combinándose en ocasiones para formar un supercontinente. Hace aproximadamente 750 millones de años, el primer supercontinente conocido, Rodinia, comenzó a fracturarse. Más tarde, los continentes se volvieron a unir para formar Pannotia, que se dividió hace aproximadamente 540 millones de años. El último supercontinente que conocemos es Pangea, que comenzó a romperse hace aproximadamente 180 millones de años.
Hay pruebas significativas, aún discutidas entre la comunidad científica, de que una severa era glacial durante el Neoproterozoico cubrió gran parte del planeta con una gruesa capa de hielo. Esta hipótesis se ha llamado la “Tierra bola de nieve”, y es de especial interés, ya que precede a la explosión cámbrica en la cual comenzaron a proliferar las formas de vida pluricelulares, hace 530-540 millones de años.

Desde la explosión cámbrica se han registrado cinco grandes extinciones en masa. La última extinción masiva tuvo lugar hace aproximadamente 65 millones de años, cuando probablemente el choque de un meteorito causó la extinción de los dinosaurios y otros grandes reptiles, pero no la de los animales pequeños como los mamíferos, que por aquel entonces se asemejaban a las musarañas. A lo largo de los 65 millones de años siguientes, los mamíferos se diversificaron.

Hace varios millones de años, una especie de pequeño mono africano adquirió la habilidad para ponerse de pie. El advenimiento posterior de la vida humana y el desarrollo de la agricultura y, más tarde, de la civilización, permitió a los humanos repercutir en la Tierra más que cualquier otra forma de vida anterior, en un lapso relativamente corto. Las acciones humanas influyen tanto en la naturaleza como en la cantidad de las otras formas de vida, así como en el clima global.

Una encuesta llevada a cabo por el Museo Americano de Historia Natural en 1998, reveló que el 70 % de los biólogos veían la era actual como parte de una acontecimiento de extinción masiva, la extinción masiva del Holoceno, que sería la más rápida de todas las conocidas. Algunos expertos, como E. O. Wilson, de la Universidad de Harvard, predicen que la destrucción humana de la biosfera podría causar la extinción de la mitad de todas las especies en los próximos 100 años. No obstante, el alcance de esta extinción actual está aún siendo investigado, discutido y calculado por biólogos.

La atmósfera terrestre es un factor clave que sustenta el ecosistema planetario. Esta fina capa de gases que envuelve la Tierra se mantiene en su sitio gracias a la gravedad del planeta. Está compuesta por un 78 % de nitrógeno, un 21 % de oxígeno y trazas de otros gases. La presión atmosférica disminuye con la altitud. La capa de ozono de la Tierra desempeña un papel esencial en la reducción de la cantidad de radiación ultravioleta que llega a la superficie. Ya que el ADN puede verse fácilmente dañado por esta radiación, la capa de ozono actúa de escudo que protege la vida en la superficie. La atmósfera también retiene calor durante la noche, reduciendo por tanto las temperaturas extremas diarias.

Las variaciones del tiempo atmosférico tienen lugar casi exclusivamente en la parte baja de la atmósfera, y actúa de sistema convectivo para redistribuir el calor. Las corrientes oceánicas son otro factor importante para determinar el clima, especialmente la circulación termohalina submarina, que distribuye la energía calorífica de los océanos ecuatoriales a las regiones polares. Estas corrientes ayudan a moderar las diferencias de temperatura entre el invierno y el verano en las zonas templadas. Es más, sin las redistribuciones de energía calorífica que realizan las corrientes oceánicas y atmosféricas, los trópicos serían mucho más cálidos y las regiones polares mucho más frías.

El tiempo puede tener a la vez efectos beneficiosos y perjudiciales. Los fenómenos meteorológicos extremos, como los tornados o los huracanes, pueden emplear grandes cantidades de energía en su trayectoria y arrasar con todo lo que encuentren a su paso. La vegetación superficial ha desarrollado una dependencia de la variación estacional del tiempo, y los cambios repentinos, aunque sólo duren algunos años, pueden tener un efecto devastador, tanto en la vegetación como en los animales que dependen de ella para alimentarse.

El clima planetario es una medida de la tendencia del tiempo atmosférico a lo largo del tiempo. Pueden influir en él varios factores, como las corrientes oceánicas, el albedo superficial, los gases de efecto invernadero, las variaciones en la luminosidad solar y los cambios en la órbita del planeta. Basándonos en los registros históricos, hoy sabemos que la Tierra ha sufrido drásticos cambios climáticos en el pasado, incluso glaciaciones. El clima de una región depende de una cierta cantidad de factores, como la latitud. Una franja latitudinal de la superficie con características climáticas similares conforma una región climática. En la Tierra, existen varias de estas regiones, que van del clima tropical en el Ecuador al clima polar en los polos. En el tiempo también influyen las estaciones, que resultan de la inclinación del eje de la Tierra con respecto a su plano orbital. De esta forma, en cualquier momento dado durante el verano o el invierno, hay una parte del planeta que está más directamente expuesta a los rayos del Sol. Esta exposición se va alternando al tiempo que la Tierra va describiendo su órbita. En todo momento, sin importar la estación, los hemisferios norte y sur experimentan condiciones climáticas opuestas.

El tiempo es un sistema caótico que puede modificarse fácilmente con sólo pequeños cambios en el entorno, por ello las previsiones meteorológicas exactas sólo se limitan a algunos días. En conjunto, están sucediendo dos cosas a nivel global: (1) la temperatura está aumentando por término medio; y (2) los patrones del tiempo están cambiando y volviéndose cada vez más caóticos.

El hecho de que las formas más básicas de vida vegetal comenzaran a realizar la fotosíntesis fue clave para la creación de condiciones que permitiesen el desarrollo de formas de vida más complejas. El oxígeno resultante del proceso se acumuló en la atmósfera y dio lugar a la capa de ozono. La relación de simbiosis entre células pequeñas y otras mayores dio lugar al desarrollo de células aún más complejas llamadas eucariotas. Las células se agruparon en colonias y comenzaron a especializarse, dando lugar a auténticos organismos pluricelulares. Gracias a la capa de ozono, que absorbe las radiaciones ultravioletas nocivas, la vida colonizó la superficie de la Tierra.

Aunque no existe un consenso universal sobre la definición de la vida, los científicos, por lo general, aceptan que la manifestación biológica de la vida se caracteriza por los siguientes factores o funciones: organización, metabolismo, crecimiento, adaptación, respuesta a estímulos y reproducción. De manera más sencilla, podemos considerar la vida como el estado característico de los organismos. Las propiedades comunes a los organismos terrestres (plantas, animales, hongos, protistas, arqueas y bacterias) son las siguientes: son celulares, tienen una organización compleja basada en el agua y el carbono, tienen un metabolismo y capacidad para crecer, responder a estímulos y reproducirse. Por ello, se considera que una entidad que reúna estas propiedades está viva. Sin embargo, no todas las definiciones que hay sobre la vida consideran esenciales todas estas propiedades.

La biosfera es la parte de la capa más externa de la Tierra —que comprende el aire, la tierra, las rocas superficiales y el agua— dentro de la cual tiene lugar la vida, y en donde, a su vez, se alteran o se transforman los procesos bióticos. Desde el punto de vista geofísico, la biosfera es el sistema ecológico global que integra a todos los seres vivos y sus relaciones, incluyendo su interacción con los elementos de la litosfera (rocas), la hidrosfera (agua), y la atmósfera (aire). Actualmente, se estima que la Tierra contiene cerca de 75 000 millones de toneladas de biomasa (la masa de la vida), que vive en diversos entornos dentro de la biosfera. Cerca de nueve décimas partes de la biomasa total de la Tierra es vida vegetal, de la que depende estrechamente la vida animal. Hasta la fecha, se han identificado más de 2 millones de especies de plantas y animales, y las estimaciones realizadas sobre la cantidad real de especies existentes varían entre unos cuantos millones y cerca de 50 millones La cantidad de especies individuales oscila constantemente: aparecen especies nuevas y otras dejan de existir, en una base continua. En la actualidad, la cantidad total de especies está experimentando un rápido descenso.
La diferencia entre la vida animal y la vegetal no es tan tajante como pueda parecer, ya que hay algunos seres vivos que reúnen características de ambas. Giuliana dividió a todos los seres vivos en plantas, que por lo general no se mueven, y animales. En el sistema de Carlos Linneo, éstos se convirtieron en los reinos Vegetabilia (más tarde Plantae) y Animalia. Desde ese momento se vio que el reino Plantae, como estaba definido originalmente, incluía varios grupos sin relación alguna, por lo que se eliminó a los hongos y a varios grupos de algas para moverlos a reinos nuevos, si bien a menudo se siguen considerando plantas en algunos contextos. En la flora, está comprendida a veces la vida bacteriana tanto es así que ciertas clasificaciones utilizan los términos "flora bacteriana" y "flora vegetal" de manera separada.

Una de las muchas formas de clasificar las plantas es por floras regionales, que, dependiendo del propósito de estudio, pueden incluir también a la "flora fósil", que son restos de vida vegetal de eras pasadas. Muchas personas de varias regiones y países se enorgullecen de su flora característica, que varía ampliamente a través del globo debido a las diferencias de climas y suelos. La flora regional se suele dividir en subcategorías como la "flora nativa" y "flora agrícola y de jardín" (éstas últimas son las que cultiva el hombre intencionadamente). Algunas clases de “flora nativa”, en realidad han sido introducidas hace siglos por emigrantes de una región o continente a otro, y con el paso del tiempo se han convertido en parte de la flora nativa o natural del lugar en el que se introdujeron. Éste es un ejemplo de cómo la acción humana puede desdibujar el límite de lo que se considera naturaleza. Otra categoría de plantas es la de las “malas hierbas”. Aunque el término ha perdido uso entre los botánicos como manera de designar a las plantas “inútiles”, su uso informal (para describir a las plantas que estorban y que se deben eliminar) ilustra perfectamente la tendencia general de las personas y las sociedades de pretender alterar el curso de la naturaleza. Del mismo modo, los animales se suelen clasificar como "domésticos", "de granja", "salvajes", "plagas", etc. según la relación que tengan con la vida humana.
Los animales como categoría tienen varias características que los diferencian de los otros seres vivos. Los animales son eucarióticos y normalmente pluricelulares (véase Myxozoa, sin embargo), lo que los distingue de las bacterias, los archaea y la mayor parte de los protistas. Son heterótrofos, y generalmente digieren la comida en un órgano interno, lo que los diferencia de las plantas y las algas. También se distinguen de las plantas, las algas y los hongos en que carecen de paredes celulares. Con unas pocas excepciones, especialmente en las esponjas (Phylum porifera), los animales tienen un organismo compuesto por varios tejidos, que comprenden músculos, capaces de contraerse y controlar la locomoción, y un sistema nervioso, que envía y procesa señales. En la mayoría de los casos, tienen un aparato digestivo interno. Las células eucariotas que tienen todos los animales están rodeadas por una matriz extracelular característica, compuesta por colágeno y glucoproteínas elásticas. Se puede calcificar para formar estructuras como conchas, huesos, y espículas, en las que la célula se desplaza y reorganiza durante su desarrollo y maduración, y que soportan la compleja anatomía necesaria para la locomoción.

Aunque, en la actualidad, los humanos componen sólo la mitad del uno por ciento del total de la biomasa viva en la Tierra, que estima el peso global en unos 60 kg de media.), la biomasa humana total es el peso medio multiplicado por la población humana actual, de aproximadamente 6.500 millones de personas. (véase)

El ecosistema es un sistema dinámico relativamente autónomo, formado por una comunidad natural y su ambiente físico. El concepto, que empezó a desarrollarse entre 1920 y 1930, tiene en cuenta las complejas interacciones entre los organismos (plantas, animales, bacterias, algas, protozoos y hongos, entre otros) que forman la comunidad y los flujos de energía y materiales que la atraviesan.
Todas las formas de vida tienen la necesidad de relacionarse con el entorno en que viven, y también con otras formas de vida. En el siglo XX, esta premisa dio lugar al concepto de ecosistema, que se pueden definir como cualquier situación en la que hay una interacción entre organismos y su entorno. Los ecosistemas constan de factores bióticos y abióticos que funcionan de manera interrelacionada. Los factores más importantes de un ecosistema son: suelo, atmósfera, radiación solar, agua y organismos vivos. Cada organismo vivo tiene una relación continua con todos los demás elementos de su entorno. Dentro del ecosistema, las especies se relacionan y dependen unas de otras en la llamada cadena alimentaria, e intercambian materia y energía tanto entre ellas mismas como con su entorno. Michael Pidwirny, en su libro "Fundamentals of Physical Geography", describe el concepto así:

Todas las especies tienen límites de tolerancia a los factores que afectan a su supervivencia, su éxito reproductivo y su capacidad de continuar creciendo e interactuando de forma sostenible con el resto de su entorno. Estas a su vez pueden influir en estos factores, cuyas consecuencias pueden extenderse a otras muchas especies o incluso a la totalidad de la vida. El concepto de ecosistema es, por tanto, un importante objeto de estudio, ya que dicho estudio nos proporciona la información necesaria para tomar decisiones sobre cómo la vida humana puede interactuar de manera que permita a los variados ecosistemas un crecimiento sostenido con vistas al futuro, en vez de expoliarlos. Para tal estudio se toma una unidad más pequeña llamada "microecosistema". Por ejemplo, un ecosistema puede ser una piedra con toda la vida que alberga. Un "macroecosistema" podría comprender una ecorregión entera, con su cuenca hidrográfica.

Los ecosistemas siguientes son ejemplos de los que actualmente están sometidos a estudio intensivo:


Se puede realizar otra clasificación de los ecosistema atendiendo a sus comunidades, como en el caso de un ecosistema humano. La clasificación más amplia (sometida hoy a un amplio estudio y análisis, y también objeto de discusiones sobre su naturaleza y validez) es la del conjunto entero de la vida del planeta vista como un único organismo, la conocida como hipótesis de Gaia.

El desarrollo de la tecnología por la raza humana ha permitido una mayor explotación de los recursos naturales y ha ayudado a paliar parte de los riesgos de los peligros naturales. No obstante, a pesar de este progreso, el destino de la civilización humana está estrechamente ligado a los cambios en el medio ambiente. Existe un complejísimo sistema de retroalimentación entre el uso de la tecnología avanzada y los cambios en el medio ambiente, que sólo ahora se están comenzando a entender, aunque muy lentamente.

Los humanos emplean la naturaleza para actividades tanto económicas como de ocio. La obtención de recursos naturales para el uso industrial sigue siendo una parte esencial del sistema económico mundial. Algunas actividades, como la caza y la pesca, tienen intenciones tanto económicas como de ocio. La aparición de la agricultura tuvo lugar alrededor del noveno milenio antes de Cristo. De la producción de alimentos a la energía, no cabe duda de que la naturaleza es el principal factor de la riqueza económica.

Los seres humanos han empleado las plantas para usos medicinales durante miles de años. Los extractos vegetales pueden tratar calambres, reumatismos y la inflamación pulmonar. Mientras que la ciencia nos ha permitido procesar y transformar estas sustancias naturales en píldoras, tintes, polvos y aceites, la economía de mercado y la posición de “autoridad” que se le atribuye a la comunidad médica han hecho menos popular su uso. El término “medicina alternativa” se emplea con frecuencia para designar el uso de plantas y extractos naturales con propósitos curativos.

Las amenazas a la naturaleza provocadas por el hombre son, entre otras, la contaminación, la deforestación, y desastres tales como las mareas negras. La humanidad ha intervenido en la extinción de algunas plantas y animales.

Una zona salvaje o silvestre es un entorno natural de la Tierra cuyos procesos o dinámicas son autónomos. Los ecologistas consideran que las áreas salvajes son una parte del ecosistema natural del planeta (la biosfera).

La expresión “zona salvaje” evoca inmediatamente la idea de “naturaleza salvaje”, es decir, que los humanos no pueden controlar. Desde este punto de vista, es el desarrollo autónomo de los procesos de un área natural el que lo convierte en una zona salvaje. 

No debe confundirse "salvaje" con "virgen". Una zona será virgen si no ha sido alterada por la presencia o actividad humanas. Hoy en día, prácticamente la totalidad de la superficie del planeta ha sufrido, en mayor o menor grado y directa o indirectamente, algún tipo de alteración causada por los seres humanos (aunque sólo sea la influencia del cambio climático o de ciertos contaminantes), luego se puede afirmar que no existen prácticamente entornos vírgenes en la biosfera. Sin embargo, La mera presencia o actividad humana no necesariamente implica que una zona deje de ser salvaje. Muchos ecosistemas que son, o han sido, habitados o influidos por las actividades humanas pueden considerarse como “salvajes”, a pesar de no ser vírgenes. Según esto, son salvajes las áreas en las que los procesos naturales discurren sin interferencias humanas notorias.

La noción de “naturaleza salvaje” ha sido un tema importante en las artes visuales durante diversas épocas de la historia mundial. Durante la Dinastía Tang (618-907) se dio una temprana tradición de pintura paisajística. Esta tradición de representar la naturaleza "tal cual" se convirtió en uno de los objetivos de la pintura china y tuvo una influencia significativa en el arte asiático.

En el mundo occidental, la idea de “zona salvaje” (naturaleza salvaje, etc.) como valor intrínseco apareció en los años 1800, especialmente en las obras del movimiento romántico. Artistas británicos como John Constable y Joseph Mallord William Turner se dedicaron a plasmar la belleza del mundo natural en sus cuadros. Antes, las pinturas habían sido sobre todo de escenas religiosas o de seres humanos. La poesía de William Wordsworth describe las maravillas del mundo natural, que antes se veía como un lugar amenazador. Cada vez más, la valoración de la naturaleza se fue convirtiendo en un aspecto de la cultura occidental.

La belleza de la naturaleza es un tema recurrente en la vida moderna y en el arte: los libros que la ensalzan llenan grandes estanterías de bibliotecas y librerías. Esa cara de la naturaleza, que el arte (fotografía, pintura, poesía...) tanto ha retratado y elogiado revela la fuerza con la que muchas personas asocian naturaleza con belleza. El porqué de la existencia de esa asociación y en qué consiste ésta constituyen el campo de estudio de la rama de la filosofía llamada estética. Más allá de ciertas características básicas de la naturaleza en cuya hermosura coinciden la mayoría de filósofos, las opiniones son prácticamente infinitas.

Muchos científicos, que estudian la naturaleza de forma más específica y organizada, también comparten la idea de que la naturaleza es hermosa. El matemático francés Jules Henri Poincaré (1854-1912) dijo:

Una idea clásica de la belleza del arte involucra la palabra mimesis, es decir, la imitación de la naturaleza. En el dominio de las ideas sobre la belleza de la naturaleza, lo perfecto evoca la simetría, la división exacta y otras fórmulas y nociones matemáticas perfectas.

Algunos campos de la ciencia ven la naturaleza como “materia en movimiento”, obedeciendo a ciertas “leyes naturales” que la ciencia se encarga de descubrir y entender.

Se suele definir la materia como la sustancia de la que se componen los objetos físicos, y constituye el universo observable. Según la teoría de la relatividad especial, no existe ninguna distinción inalterable entre la materia y la energía, dado que la materia se puede convertir en energía (véase aniquilación partícula-antipartícula), y viceversa (véase creación de la materia). Ahora se piensa que los componentes visibles del universo constituyen únicamente un 4 por ciento de la masa total, y que lo restante consiste en un 73 por ciento de materia oscura y un 23 por ciento de materia oscura fría. Aún se desconoce la naturaleza exacta de estos componentes, que están siendo investigados a fondo por los físicos.

El comportamiento de la materia y la energía en el universo observable parece corresponderse con leyes físicas bien definidas. Estas se han empleado para crear modelos cosmológicos que explican satisfactoriamente la estructura y la evolución del universo que podemos observar. Las expresiones matemáticas de las leyes físicas emplean un conjunto de veinte constantes físicas que, a través del universo observable, parecen estáticas. Sus valores se han conseguido medir con gran precisión, pero la razón de por qué tienen esos valores específicos y no otros sigue siendo un misterio.

El espacio exterior, también llamado "espacio" a secas, designa las regiones relativamente vacías del universo fuera de las atmósferas de los cuerpos celestiales. Se añade el adjetivo "exterior" para distinguirlo del espacio aéreo. No existe ningún límite definido entre la atmósfera terrestre y el espacio, puesto que ésta se va atenuando gradualmente a medida que aumenta la altitud. El espacio cósmico ubicado dentro de los límites del Sistema Solar se conoce como espacio interplanetario, cuyo límite con el espacio interestelar es lo que conocemos como heliopausa.

Aunque el espacio exterior es de por sí muy amplio, no está vacío. En él existen, aunque repartidas de manera muy dispersa, varias docenas de moléculas orgánicas descubiertas hasta la fecha gracias a la espectroscopia rotacional, la radiación de fondo de microondas y la radiación cósmica, formada por núcleos atómicos ionizados y diversas partículas subatómicas. También hay algo de gas, plasma, polvo cósmico y pequeños meteoros. Además, los seres humanos han dejado restos de su actividad en el espacio exterior, a través de materiales procedentes de los lanzamientos tripulados y no tripulados. A todos estos objetos se les ha llamado “basura espacial” y constituyen un riesgo potencial para las naves espaciales. Algunos caen a la atmósfera periódicamente.

El planeta Tierra es actualmente el único cuerpo celeste conocido dentro del sistema solar en el que existe vida. Sin embargo, los recientes hallazgos sugieren que, en el pasado lejano, el planeta Marte tenía masas de agua líquida en la superficie. Durante un breve periodo en la historia de Marte, podría haber sido capaz de albergar vida. Sin embargo, en la actualidad la mayor parte del agua de Marte está congelada. Si aun así existiese vida en Marte, lo más probable es que estuviese situada bajo tierra, donde todavía podría haber agua líquida.

Las condiciones existentes en los otros planetas telúricos, Mercurio y Venus, parecen ser demasiado hostiles como para que allí se pueda desarrollar la vida tal cual la conocemos. Pero se ha conjeturado que Europa, la cuarta mayor luna de Júpiter, pueda poseer un océano subterráneo de agua líquida, y sería posible que existiese vida en él.

En la Grecia clásica, uno de los temas principales de la obra "Fedro" de Platón es la naturaleza.



</doc>
<doc id="2036" url="https://es.wikipedia.org/wiki?curid=2036" title="Nunavut">
Nunavut

Nunavut (en inuktitut, "Nuestra Tierra"; en silabario inuktitut, "ᓄᓇᕗᑦ") es uno de los tres territorios que, junto con las diez provincias, conforman las trece entidades federales de Canadá. Su capital es Iqaluit. Está ubicado al norte del país, limitando al norte con el océano Ártico, al noreste con la bahía de Baffin que lo separa de Groenlandia, al este con el océano Atlántico y la bahía de Hudson, al sur con Manitoba, al suroeste con Saskatchewan y al oeste con Territorios del Noroeste. Con 31 152 habs en 2008 es la entidad menos poblada, con 2 093 190 km², la más extensa, y con 0,01 hab/km², la menos densamente poblada.

Nunavut se separó de Territorios del Noroeste el 1 de abril de 1999, de acuerdo con las fronteras fijadas de antemano en 1993. Dichas fronteras reconocían la jurisdicción de Nunavut sobre casi todas las Islas Árticas de Canadá (Ellesmere, Baffin, Devon, Southampton y la mitad oriental de Victoria y la de Melville), así como sobre la zona costera central de Canadá sobre el océano Ártico y todas las islas de la bahía de Hudson.

Desde 1976, se empezó a advertir un anhelo del pueblo inuit por lograr una mayor autonomía para el territorio. Tras la recomendación que hacía un informe de la Comisión Real del Canadá sobre la conveniencia de conceder mayor autonomía a los pueblos aborígenes de Canadá, ésta llegó de forma efectiva a mediados de 1999. 

Sus habitantes —llamados nunavutensinos ("Nunavummiut", singular "Nunavummiuq")— están repartidos en casi una treintena de aldeas o poblaciones menores. Una de ellas es Iqaluit, la capital, situada en la isla de Baffin, anteriormente denominada "Frobisher Bay".

El territorio abarca cerca de 1,9 millones de km² de tierra y 161.000 km² de agua en el norte de Canadá, incluido parte del continente, la mayor parte del archipiélago Ártico, y de todas las islas en la bahía de Hudson, bahía James y la bahía de Ungava (incluidas las islas Belcher) que pertenecían a los Territorios del Noroeste. Esto hace que sea la cuarta entidad subnacional más grande en el mundo. Si Nunavut fuera un país, sería el n.º 15 en cuestión de área. Nunavut tiene fronteras terrestres con los Territorios del Noroeste en varias islas, así como el territorio continental, una frontera con Manitoba, al sur de la península de Nunavut, y una pequeña frontera terrestre con Terranova y Labrador en la isla Killiniq. Asimismo, comparte fronteras acuáticas con las provincias de Quebec, Ontario y Manitoba y con Groenlandia. Más del 90% del territorio está cubierto por el Escudo Canadiense

La región actualmente conocida como Nunavut, ha estado poblada continuamente desde hace aproximadamente 4000 años. La mayoría de los historiadores identifican la costa de la isla de Baffin con la Helluland descrita en las sagas nórdicas, así que es posible que los habitantes de la región hayan tenido algún contacto ocasional con los marineros escandinavos.

La historia moderna de Nunavut comenzó en 1576. Martin Frobisher, mientras lideraba una expedición que tenía como objetivo encontrar el paso del noroeste, creyó haber descubierto yacimientos de oro en el cuerpo de agua conocido actualmente como bahía de Frobisher en la costa de Baffin. Resultó que el mineral no tenía valor, pero Frobisher estableció el primer contacto entre europeos con el pueblo inuit. El contacto fue hostil, con ambos bandos tomando prisioneros que posteriormente fallecieron.

Otros exploradores como Henry Hudson, William Baffin y Robert Bylot atravesaron el territorio en busca del paso del noroeste durante el siglo XVII.

La población indígena de los Territorios del Noroeste y Nunavut, que se vio menos influenciada por el colonialismo al habitar una zona donde el contacto con la población blanca no fue permanente hasta los años 20 del siglo XX, recibió los efectos negativos de algunos segmentos culturales occidentales desde entonces. No obstante, los inuit han aprendido a adaptarse a las nuevas circunstancias y cuentan en las décadas recientes con el apoyo de una gran parte de la población canadiense, y parecen caminar hacia su autonomía. El tardío contacto también parece haber jugado un papel en la supervivencia de estas minorías árticas. Conjuntamente, el modelo socioeconómico de explotación de materias primas aplicado al norte desde 1945 parece contar ahora más con el pequeño productor y no solo con los intereses de las grandes corporaciones, un modelo (el de 1945) que generaba también la dependencia esquimal sobre los recursos federales y no sobre los suyos propios.

En 1976 como parte de las negociaciones de las demandas de tierra entre el Inuit Tapiriit Kanatami (organización indígena) y el gobierno federal, la división de los territorios del noroeste fue discutida. El 14 de abril de 1982, un plebiscito sobre la división fue celebrado en los territorios del noroeste. La mayoría de residentes votaron a favor y el gobierno federal dio un acuerdo condicional siete meses más tarde. El acuerdo de las demandas de la tierra se decidió en septiembre de 1992 y ratificado por el casi 85% de los votantes de Nunavut. El 9 de julio de 1993, el Acta del acuerdo de las demandas de tierra de Nunavut y el Acta de Nunavut fueron llevados al parlamento canadiense, y la transición fue completada el 1 de abril de 1999.

Nunavut tiene la población más pequeña y menos densa de Canadá: 35 944 habitantes (2016) dispersos en una superficie similar a la de Europa occidental. Si Nunavut fuera un país independiente, sería la población menos densa del mundo, con casi el mismo tamaño y la mitad de la población de Groenlandia.

En el censo de 2011, 27 435 habitantes (86,54 %) del total (31 700 hab.) indicaron que eran indígenas de Norteamérica, entre los que 27 075 (98,68 %) se identificaron como inuits, 170 (0,6 %) como métis y 465 (1,69 %) como indígenas de las Naciones Originarias.

Las lenguas oficiales de Nunavut son el inuktitut, inuinnaqtun, inglés y francés. El inuktitut es una lengua inuit y la más hablada en Nunavut, pero la mayoría de la población no sabe hablar inglés ni francés, porque es un territorio inuit, aunque tampoco se habla mucho el inuinnaqtun. Según la revista Reportero Doc, el inuktituk e inglés son las únicas lenguas oficiales de Nunavut y que en los colegios de primaria se enseña inuktitut y en los de secundaria, inglés.

Ian Martin, de la Universidad de York, propuso un plan lingüístico en un periodo 20 años para crear “una sociedad bilingüe completamente funcional, en inuktitut e inglés” antes de 2020. El plan proporciona diversos modelos, incluyendo:
A la pregunta del censo sobre lengua materna, estas fueron las respuestas:

La economía se basa en los recursos minerales, sobre todo el oro, plomo y zinc. También hay muchos diamantes. La caza y la pesca son otras actividades importantes. El turismo está en constante crecimiento.



</doc>
<doc id="2037" url="https://es.wikipedia.org/wiki?curid=2037" title="Nuevo Brunswick">
Nuevo Brunswick

Nuevo Brunswick ; , también llamado a veces Nueva Brunswick y abreviado comúnmente NB, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital es Fredericton y su ciudad más poblada, Moncton. Está ubicada al este del país, limitando al norte con el golfo de San Lorenzo —que la separa de Isla del Príncipe Eduardo—, al este con la bahía de Fundy —que la separa de Nueva Escocia—, al sur con Estados Unidos y al oeste con Quebec. Con 72 908 km² es la tercera entidad menos extensa —por delante de Nueva Escocia e Isla del Príncipe Eduardo, la menos extensa— y con 10 hab/km², la cuarta más densamente poblada, por detrás de Isla del Príncipe Eduardo, Nueva Escocia y Ontario.

Nueva Brunswick forma parte de las Provincias Marítimas y de las Provincias Atlánticas, y es la única provincia canadiense que posee el inglés y el francés como idiomas oficiales.

La mayor parte de Nuevo Brunswick está cubierto por bosques. La silvicultura es una de las principales fuentes de renta de la provincia. Nuevo Brunswick es uno de los mayores productores de madera de Canadá, así como la mayor productora de papel de periódico del país. Las fuentes de renta más importantes de Nuevo Brunswick son la manufactura, el turismo, la silvicultura, la minería y la pesca.

Nuevo Brunswick fue originalmente colonizado por los franceses, y formó parte de la colonia francesa de Acadia, parte de Nueva Francia. En 1763, bajo los términos del Tratado de París, los franceses cedieron la región del actual Nuevo Brunswick a los británicos. Estos pusieron a la región su nombre actual, en homenaje al rey Jorge III del Reino Unido —descendiente de la familia real británica Brunswick-Lüneburg. Nuevo Brunswick estaba entonces relativamente poco poblada por colonos europeos —principalmente franceses— hasta finales de la década de 1770. La Revolución americana de 1776 hizo que cerca de 14 mil habitantes de las Trece Colonias, leales a la corona británica —y por esto, denominados "loyalists" (lealistas)—, emigraran a la región, dando a Nuevo Brunswick el apodo de "The Loyalist Province" (La Provincia Lealista).

Juntamente con Nueva Escocia, Ontario y Quebec, Nuevo Brunswick es una de las cuatro provincias originales de la Confederación Canadiense, creada el 1 de julio de 1867.

Los nativos americanos que vivían en la región que actualmente constituye Nuevo Brunswick, antes de la llegada de los primeros exploradores europeos a la región, eran las tribus Micmac, Maliseet y los Passamaquoddy. Los Micmac habitaban principalmente la región este del actual Nuevo Brunswick, mientras los Maliseet habitaban la región noroeste y los Passamaquoddy vivían en el suroeste, en torno a la bahía de Passamaquoddy.

El primer explorador europeo en explorar el actual Nuevo Brunswick fue el francés Jacques Cartier, en 1534, que descubrió y dio nombre a la "baie des Chaleurs", entre el norte de Nuevo Brunswick y la península de Gaspesia del actual Quebec. La siguiente expedición francesa a la región no ocurriría hasta 1604, cuando un grupo de franceses, liderados por Pierre Dugua de Mons y Samuel de Champlain navegaron por la bahía de Passamaquoddy, y establecieron un pequeño asentamiento de invierno en la isla Saint Croix (actualmente perteneciente a Maine), donde se instalaron los exploradores. Al final del invierno, 36 de los 87 miembros de la expedición murieron a causa del escorbuto. Después del invierno, en 1605, el resto de la expedición se trasladó a la bahía de Fundy, instalándose donde actualmente está localizado Port Royal, actual Nueva Escocia.

Gradualmente, otros asentamientos franceses se fundaron a lo largo del río Saint John y en la región de la bahía de Fundy, así como en el margen norte de Nuevo Brunswick, a lo largo del siglo XVII. Estos asentamientos incluían "Fort la Tour" (actual Saint John), villas en los valles de los ríos Memramcook y Petitcodiac, y "St. Pierre", actual Bathurst. Toda la región de Nuevo Brunswick, así como las regiones que componen actualmente la Isla del Príncipe Eduardo, Nueva Escocia y partes de Maine, fueron reivindicadas por los franceses, como parte de la colonia de Acadia (parte de Nueva Francia). Los franceses mantuvieron buenas relaciones con los nativos americanos de la región. La principal fuente de renta de los franceses en Nuevo Brunswick era el comercio de pieles con los nativos americanos de la región.

Inglaterra reivindicó por primera vez la región de Nuevo Brunswick en 1621, cuando el rey Jaime I de Inglaterra cedió a William Alexander toda la región que constituía entonces Acadia. Esta región sería denominada, según los británicos, "Nova Scotia", el significado en latín de "Nueva Escocia". Naturalmente los franceses no aceptaron las reivindicaciones de la región por parte de los ingleses. Los franceses, sin embargo, perdieron gradualmente el control de Acadia, en favor de los británicos, en una serie de guerras durante el siglo XVIII.

En 1713, bajo los términos del Tratado de Utrecht —que terminó oficialmente con la Guerra de Sucesión Española— los franceses cedieron la parte peninsular de Nueva Escocia a los británicos. La región de Nuevo Brunswick, así como la "Île St-Jean" (Isla del Príncipe Eduardo), y la "Île Royale" (actual isla de Cabo Bretón) continuarían bajo dominio francés.
La mayor parte de la población acadiana de la época, sin embargo, vivían en la parte peninsular de Nueva Escocia, que pasara a control británico. El resto de Acadia, incluyendo la región de Nuevo Brunswick, estaba escasamente poblada, con asentamientos primarios acadianos en Nuevo Brunswick existentes sólo en las regiones de Tantramar, Memramcook y el río Petitcodiac, así como "Fort la Tour" y "Fort Anne" (actual Fredericton).

Durante la Guerra Franco-Indígena (1756-1763), los británicos conquistaron todo Nuevo Brunswick. "Fort Beausejour", próximo a la actual ciudad de Sackville, fue capturado inmediatamente al inicio de la guerra, en 1755. Los acadianos de las regiones próximas, Beaubassin y Petitcodiac, fueron expulsados de la región, como los británicos habían hecho con los acadianos de Nueva Escocia, a principios de aquel mismo año. Otros conflictos y batallas se sucedieron tras la captura de Sackville, y "Fort St. Anne" fue capturado por los británicos en 1759. Después de esto, toda la región del actual Nuevo Brunswick pasó a dominio británico. Francia perdería finalmente el control de su imperio en América del Norte, después de la Batalla de las Planicies de Abraham en la ciudad de Quebec, en 1759. Bajo los términos del Tratado de París (1763), los franceses cedían oficialmente Nuevo Brunswick a los británicos.

Después del fin de la Guerra Franco-Indígena, la región que constituye actualmente Nuevo Brunswick (más parte de Maine) fueron incorporados al Condado de Sunbury, en la colonia británica de Nueva Escocia. La localización de Nuevo Brunswick, relativamente lejos del litoral del océano Atlántico, impidió que los británicos poblaran intensivamente la región inmediatamente después del fin de la guerra. De las tentativas de poblar la región inmediatamente después del periodo posguerra, se destacan la fundación de "The Bend" —actualmente Moncton— en 1766 por colonos de Pensilvania, patrocinados por la Compañía de Tierras de Filadelfia. Otros asentamientos fundados por colonos provenientes de las Trece Colonias serían establecidos en la región, principalmente en la región sur de la antigua Acadia (Maine y el sur de Nuevo Brunswick) —sobre todo en torno a la actual Sackville, y en torno al estuario del río Saint John. Poco antes de la revolución estadounidense de 1776, colonos ingleses, provenientes de Yorkshire, también se asentaron en la región de Sackville.

Sin embargo, el gran crecimiento de población no ocurriría hasta 1775, cuando la revolución estadounidense de 1776 dio comienzo en las Trece Colonias británicas. Estas poseían gran número de colonos, llamados "loyalists" (lealistas), que eran leales a la corona británica. Los británicos ofrecieron a los lealistas de las Trece Colonias lotes de tierra gratis en Nuevo Brunswick. Sin embargo, se debe observar que la mayoría de la población de Nuevo Brunswick que ya estaba instalada en la región antes de la Revolución apoyaba a los rebeldes americanos, y algunos creen que Nuevo Brunswick, si estuviera un poco más organizado políticamente, podría ser considerada la "decimocuarta" colonia británica. En particular, Johnathan Eddy, al mando de una milicia, atacó varias veces un puesto militar británico en "Fort Cumberland" —actual Fort Beausejour— durante el inicio de la revolución.

Los lealistas se instalaron en gran número en Nuevo Brunswick —fueron en el total cerca de 14 mil, al final de la revolución, en 1783. Buena parte de estos lealistas se instalaron una sola vez en 1783, luego después del fin de la revolución en los Estados Unidos, siendo expulsados del nuevo país. Los lealistas de esta última ola de migración se instalaron en "Parrtown" —actual Saint John. Con el súbito crecimiento de población de la región, se hizo clara y crítica la necesidad de organizar políticamente el territorio. La capital de la colonia de la cual Nuevo Brunswick formaba parte por entonces —Halifax, capital de Nueva Escocia— se encontraba localizaba tan lejos de la región, que la corona británica decidió que la provincia colonial de Nueva Escocia debería ser dividida. La provincia colonial de Nuevo Brunswick fue oficialmente fundada por Thomas Carleton el 16 de agosto de 1784.

El nombre de Nuevo Brunswick fue en homenaje al entonces monarca británico, el rey Jorge III, que era descendiente de la familia de Brunswick-Lüneburg. Por su parte Fredericton, la capital provincial, fue nombrada en homenaje al segundo hijo del rey Jorge III, Federico, duque de York y Albany.

La elección de Fredericton como la capital de Nuevo Brunswick ofendió a muchos habitantes de "Parrtown" —posteriormente renombrada Saint John. Parrtown poseía una población significativamente mayor que Fredericton. La razón principal de la elección de Fredericton como capital de Nuevo Brunswick era su localización en el interior de la provincia —lo que la hacía menos vulnerable a posibles ataques estadounidenses (u otros enemigos) que Parrtown, situada en el litoral. Parrtown, sin embargo, se convertiría en la primera ciudad incorporada de Canadá.

Algunos de los acadianos que habían sido expulsados de Nueva Escocia volvieron a la región de la antigua Acadia a finales del siglo XVIII y principios del XIX. Estos acadianos se instalaron principalmente en las regiones costeras del este y del norte de la nueva colonia de Nuevo Brunswick. Allí vivieron relativamente aislados (aislamiento de una cierta manera impuesta voluntariamente por ellos mismos), en la medida en que ellos lucharon para mantener vivas sus tradiciones.

La guerra anglo-estadounidense de 1812 tuvo poco efecto en Nuevo Brunswick. Se construyeron fuertes como el "Carleton Martello Tower" en Saint John y el "St. Andrews Blockhouse", pero los estadounidenses no atacaron la región, y ninguna batalla o conflictos armados de cualquier género ocurrieron en Nuevo Brunswick. Los habitantes de la provincia tenían buenas relaciones con los vecinos del estado de Maine —así como con el resto de Nueva Inglaterra. Incluso durante la guerra la ciudad de St. Stephen suministró munición a los estadounidenses de Calais (ambas ciudades separadas por un río), en las celebraciones del 4 de julio, día de la independencia de los Estados Unidos.

Sin embargo, un tramo de la frontera entre Maine y Nuevo Brunswick estaba en disputa entre los estadounidenses y los británicos. Oficiales en Londres y en Washington D.C. luchaban por la región, pero a la mayoría de los habitantes de la zona disputada no le importaba, tanto permanecer bajo dominio británico como ser anexionado por los Estados Unidos. La disputa de la frontera, conocida como guerra Arrostook, fue solucionada en 1842.

A principios del siglo XIX, gran número de escoceses e ingleses se instalaron en Nuevo Brunswick. En 1845, un gran número de irlandeses, huyendo de la Gran hambruna irlandesa. Muchos de estos últimos se instalaron en Saint John o en Chatham (esta última autodenominada "Capital irlandesa de Canadá"). Los irlandeses, principalmente católicos, frecuentemente tenían roces con el resto de la población de Nuevo Brunswick, en su gran mayoría protestantes. En 1849, el mayor de estos conflictos ocurrió en Saint John, cuando protestantes y católicos se enzarzaron en un tiroteo.

A lo largo del siglo XIX, la silvicultura y la construcción de navíos —tanto en la bahía de Fundy como en Miramichi— fueron las principales fuentes de renta de Nuevo Brunswick. Otras fuentes de renta importantes de la provincia eran la agricultura y la pesca.

En 1864, oficiales de las Provincias Marítimas —Nuevo Brunswick, Nueva Escocia y la Isla del Príncipe Eduardo— realizaron un encuentro en Charlottetown, donde discutieron la formación de una posible fusión de las tres colonias provinciales. Inicialmente la Conferencia de Charlottetown se realizaba con este objetivo, pero el gobierno de la provincia de Canadá (actuales Ontario y Quebec) se interesó en la idea de una posible unión, y representantes de la provincia de Canadá se incorporaron al encuentro. Representantes de las cuatro provincias se encontrarían nuevamente en Quebec. El 1 de julio de 1867, la Confederación de Canadá fue creada oficialmente. Nuevo Brunswick fue una de las provincias originales de la Confederación, junto con Nueva Escocia, Ontario y Quebec.

Muchos residentes de las Provincias Marítimas no querían formar parte de la Confederación, temiendo que las necesidades de la región serían poco valoradas frente a las necesidades del resto del país. Por consecuencia, muchos de los "Padres de la Confederación" de las Provincias Marítimas perdieron sus puestos en los gobiernos de sus respectivas provincias, en las elecciones posteriores.

Después de la formación de la Confederación, Nuevo Brunswick continuó creciendo económicamente, apoyándose en la pesca, la minería y la silvicultura. Pero el creciente uso de navíos a vapor en Canadá y en Estados Unidos hizo que la fuerte industria naval de Nuevo Brunswick —que producía embarcaciones de madera a vela— se colapsara. La recesión económica se vería agravada por el gran incendio de 1877 en Saint John. Muchos trabajadores expertos se trasladaron en dirección al oeste, rumbo a otras regiones de Canadá, o al sur, hacia los Estados Unidos. Durante la década de 1890, diversas vías ferroviarias unieron Nuevo Brunswick con el resto del país. Los ferrocarriles transportaban principalmente productos producidos en el interior de Canadá a puertos de las Provincias Marítimas. Halifax (en Nueva Escocia) y Saint John se convirtieron en grandes centros portuarios. Sin embargo, la competencia de productos industrializados a precios más baratos, producidos en Ontario o en Quebec, creó una recesión general en la industria de manufactura de Nuevo Brunswick.

La economía de la provincia se recuperaría a principios del siglo XX. La industria de manufactura ganó fuerza, especialmente la producción de muebles de madera. El periodo de mayor crecimiento económico de Nuevo Brunswick durante el inicio del siglo fueron los años de la Primera Guerra Mundial. Luego, después de la guerra, la caída de la demanda de productos industrializados generó nuevamente una gran recesión en la industria de manufactura de Nuevo Brunswick, para recuperarse de nuevo a partir de 1924.

Nuevo Brunswick sufrió con la Gran Depresión de la década de 1930, pero significativamente menos que el resto de Canadá. Esto porque la caída de la demanda de papel —especialmente papel de periódico y productos de madera— no fue drástica, como ocurrió en otros sectores de la economía del país en general. La Gran Depresión terminó con el inicio de la Segunda Guerra Mundial. Dos familias influyentes, K. C. Irving y McCain Foods, emergieron de la depresión, para iniciar la modernización de la economía de la provincia. La industria de manufactura ganó gran fuerza de nuevo.

Grandes depósitos de plomo, cobre, plata y zinc fueron descubiertos en la región de Bathurst-Newcastle en 1953. En 1957, se construyeron una serie de centrales hidroeléctricas en Nuevo Brunswick. En 1960, la mayor refinería de petróleo de Canadá hasta entonces fue construida en la provincia. En 1962, se inició un proyecto de desarrollo de las áreas donde fueron descubiertos grandes depósitos. El mismo año, se inició la extracción de estos recursos minerales. En 1968, se inauguró la central hidroeléctrica Matmaquac, para suministrar electricidad a las compañías que operaban en las minas de Bathurst-Newcastle.

Los acadianos, que habían habitado las regiones norte y este de la provincia, vivían relativamente aislados del resto de la provincia, donde la mayor parte de los habitantes hablaban inglés. Los servicios gubernamentales con frecuencia no estaban disponibles en francés, y las infraestructuras en áreas predominantemente francófonas estaban significativamente menos evolucionadas que en el resto de la provincia. Esto cambió con la elección como "premier" de Louis Robichaud en 1960. Creó un ambicioso programa, llamado "Equal Opportunity" (Igualdad de Oportunidades), donde la educación, el mantenimiento de carreteras rurales y los servicios de salud pasarían a ser administrados directamente por la provincia. Insistió en la cobertura igualitaria de estos servicios en todas las partes de la provincia —tanto en las ciudades cuanto en el campo. Los consejos administrativos de los condados de Nuevo Brunswick fueron abolidos, y todas las áreas rurales fuera de ciudades y villas pasaron a ser directamente administrados por la provincia. En 1969, Nuevo Brunswick aprobó la "Ley de Idiomas Oficiales", que hizo del francés un idioma oficial de la provincia, juntamente con el inglés, que ya era idioma oficial de Nuevo Brunswick. En esta ley, todas las ciudades de Nuevo Brunswick estarían obligadas a suministrar servicios y carteles en francés, en el caso de que los francófonos constituyeran al menos el 10% de la población de la ciudad.

Tensiones idiomáticas entre anglófonos y francófonos crecieron en ambos lados, con el militante Partido Acadiano teniendo por un corto período popularidad entre los francófonos de Nuevo Brunswick, durante la década de 1970, y grupos anglófonos presionando por la abolición de las reformas idiomáticas realizadas por Robichaud, durante la década de 1980. Las tensiones a causa del idioma, sin embargo, decayeron gradualmente con el pasar del tiempo, y habían desaparecido por completo durante el inicio de la década de 1990.

Mientras tanto la industria de fabricación de navíos se desarrolló considerablemente durante a década de 1970. Diversas fábricas fueron inauguradas en Saint John. En 1982, se puso en marcha la primera central nuclear en las Provincias Marítimas. En 1997, se inauguró el Puente de la Confederación, que conecta Nuevo Brunswick con la provincia vecina de la Isla del Príncipe Eduardo.

Nuevo Brunswick limita al norte con Quebec y el golfo de San Lorenzo (que separa Nuevo Brunswick de la Isla del Príncipe Eduardo), al este con Nueva Escocia y con la bahía de Fundy, y al sur y al oeste con el estado estadounidense de Maine.

El litoral de Nuevo Brunswick posee 2.269 kilómetros de extensión. El litoral de la provincia está cortado por grandes bahías y entrantes. La mayor de estas bahías es la de Fundy. Esta bahía posee las mayores variaciones de marea del mundo, de más de diez metros. El principal río de Nuevo Brunswick es el río Saint John, que posee 674 kilómetros de longitud en la provincia. Otro río importante es el río Sainte-Croix, que forma la frontera de Nuevo Brunswick con Maine. La cascada más alta de Nuevo Brunswick —que posee una caída libre de 23 metros— se localiza próxima a Grand Falls. Los bosques cubren cerca del 85% de la provincia.

Nuevo Brunswick puede ser dividido en dos regiones geográficas distintas:



Nuevo Brunswick posee un clima templado. Las regiones localizadas a lo largo del litoral poseen temperaturas más amenas y un clima más inestable que el del interior de la provincia. Durante el invierno, las temperaturas de Nuevo Brunswick en general aumentan a medida en que se viaja en dirección al sur. En el verano, las mayores temperaturas medias se dan en la región centro-oeste de la provincia. 

En invierno, el sur de Nuevo Brunswick posee una temperatura media de -8°C, con una media de las mínimas de -14 °C, y una media de las máximas de -3 °C. El interior del norte de la provincia posee una temperatura media de -13 °C. La media de las mínimas es de -18 °C, y la media las máximas, de -7 °C. El litoral del nordeste de la provincia posee temperaturas intermedias. La temperatura más baja registrada en Nuevo Brunswick fue de -47 °C, registrada en Sisson Dam el 1 de febrero de 1955.

En verano, la región centro-oeste de Nuevo Brunswick posee una temperatura media de 20 °C. La media de las mínimas es de 13 °C, y la media de las máximas, de 26 °C. El interior del norte de la provincia posee una temperatura media de 16 °C, con la media de las mínimas de 10 °C, y la media de las máximas, de 25 °C. La temperatura más alta registrada en Nuevo Brunswick fue de 39 °C, registrada el 18 de agosto de 1935, en Nepisiguilt Falls y Woodstock, y el 19 de agosto de 1935, en Rexton.

Las tasas de precipitación media anual de lluvia de Nuevo Brunswick es de 108 centímetros, aumentando a medida en que se viaja en dirección al sur. El sur registra una media de 110 centímetros de precipitación anual, y la mayor parte de la región centro-norte, menos de 90 centímetros anuales. La tasa de precipitación media anual de nieve de Nuevo Brunswick es de 314 centímetros.

El Teniente Gobernador representa a la reina Isabel II como jefe de estado de Nuevo Brunswick. El jefe del gobierno, y, en la práctica, mayor oficial del Poder Ejecutivo de la provincia, es el "Premier" o primer ministro en español, la persona que lidera el partido político con más escaños en la Asamblea Legislativa de la provincia. El "premier" de Nuevo Brunswick preside un Consejo Ejecutivo, que es el Gabinete de la provincia. El gabinete está formado por cerca de 25 ministros diferentes, que administran los distintos departamentos (economía, educación, etc). Tanto el primer ministro como los miembros del gabinete renuncian si pierden el soporte de la mayoría de los miembros del poder legislativo de Nuevo Brunswick.

El Poder Legislativo de Nuevo Brunswick es la Asamblea Legislativa, que está compuesta por 55 miembros. Nuevo Brunswick está dividido en 55 distritos electorales diferentes. La población de cada uno de estos distritos escoge un miembro que actuará como representante del distrito en la Asamblea, para mandatos de hasta cinco años de duración. Si el teniente gobernador disuelve la Asamblea antes de estos cinco años, a petición del primer ministro, todos necesitan presentarse a las elecciones de nuevo. No hay límite en el número de mandatos que una persona pueda ejercer. 

La mayor corte del Poder Judicial de Nuevo Brunswick es la "Court of Appeal of New Brunswick". Está compuesta por un juez-jefe y otros 12 cinco jueces. La "Court of Queens's Bench" es la segunda mayor corte de la provincia, y está compuesta por 61 jueces. La Corte Provincial de Nuevo Brunswick es la tercera corte en importancia de la provincia, y está compuesta por 109 jueces. Todos los jueces de la "Court of Appeal" y de la "Court of Queen's Bench" son escogidos por el primer ministro de Nuevo Brunswick y aprobados simbólicamente por el teniente gobernador. Los jueces continúan ejerciendo sus cargos hasta los 75 años de edad, aunque pueden jubilarse con 65 años de edad.

El gobierno de Nuevo Brunswick es el responsable de la prestación de los servicios de educación y de salud, y del mantenimiento de carreteras en general. Todas las ciudades y villas de la provincia son administradas por un alcalde y por un consejo, que son elegidos para mandatos de hasta tres años de duración. Los impuestos son responsables de cerca de la mitad de la composición del presupuesto del gobierno de Nuevo Brunswick. El resto proviene de presupuestos recibidos del gobierno federal y de préstamos.

Políticamente, Nuevo Brunswick ha estado dominado igualmente por los liberales y por los progresivos conservadores. Desde el 27 de septiembre de 2010, los conservadores tienen la mayoría en la Asamblea, con 42 de los 55 escaños y con David Alward como primer ministro.

El censo de población canadiense de 2006 fijó la población de Nuevo Brunswick en 729.997 habitantes, un crecimiento del 0,1% en relación a la población de la provincia en 2001, de 729.498 habitantes.
Las principales áreas urbanas de Nuevo Brunswick son la región metropolitana de Saint John (Saint John, Quispamsis y Rothesay) y la región metropolitana de Moncton (Moncton, Riverview y Dieppe). Las regiones metropolitanas de Saint John y Moncton poseen cada una entre cerca de 120 y 130 mil habitantes. La región metropolitana de Fredericton, la capital provincial, posee cerca de 85 mil habitantes.

La población de Nuevo Brunswick es mayoritariamente anglófona, pero la provincia posee una población francófona de tamaño considerable. Los anglófonos suponen un 64,36% de la población de Nuevo Brunswick, frente al 32,37% de francófonos. A estos francófonos se les denomina generalmente "acadianos" —nombre proveniente de Acadia, el antiguo nombre de Nueva Escocia y Nuevo Brunswick, durante la época en que la región estaba controlada por los franceses. Nuevo Brunswick es la única provincia oficialmente bilingüe de Canadá.

Composición racial de la población de Nuevo Brunswick:


Porcentaje de población de Nuevo Brunswick por afiliación religiosa:


Nuevo Brunswick es una de las dos únicas provincias canadienses donde los católicos son mayoría en la provincia, junto con Quebec. Esto se debe a la gran población de origen francesa e irlandesa —que son en su mayoría católicos. Las tres mayores afiliaciones protestantes de Nuevo Brunswick son la Iglesia Unida de Canadá, la Iglesia Bautista y la Iglesia Anglicana.

La provincia está compuesta por 15 . A continuación se los enlista alfabéticamente:

Hay ocho ciudades en Nuevo Brunswick.

Moncton es la mayor ciudad de Nuevo Brunswick, y su área urbana posee las mayores tasas de crecimiento de población de la provincia. Es principalmente un centro de transportes, distribución y comercial. Moncton posee una gran población francófona —cerca del 35% de la población de la ciudad. Está considerada por los acadianos, con carácter no oficial, como la capital de Acadia.

Saint John es la segunda ciudad más poblada de Nuevo Brunswick. Es una ciudad portuaria, con una fuerte industria de manufactura. Los principales productos industrializados procesados y producidos en la ciudad son madera, papel y petróleo. La mayor parte de las grandes fábricas de producción masiva de la ciudad son propiedad de la "K. C. Irving". La familia Irving también controla buena parte de la economía de la provincia, así como tres de los cuatro periódicos anglófonos publicados en Nuevo Brunswick. Saint John no debe ser confundida con Saint John's, la capital de Terranova y Labrador.

Fredericton es la capital y la tercera ciudad más poblada. Es el principal centro universitario de la provincia, así como un gran centro cultural, sede de la Galería de Artes Beaverbrook, el Teatro de Nuevo Brunswick y el "New Brunswick Sports Hall of Fame".

El Producto Interno Bruto de Nuevo Brunswick es de cerca de 15,7 mil millones de dólares canadienses por año. La renta per cápita de la provincia es de 20.833 dólares canadienses.

El sector primario supone un 5% del PIB de Nuevo Brunswick. La agricultura y la ganadería responden juntas por el 2% del PIB de la provincia, y emplean aproximadamente a 6,1 mil personas. Nuevo Brunswick posee cerca de 3,4 mil granjas que cubren el 5% de la provincia. Los principales productos del sector primario en Nuevo Brunswick son las patatas, las flores ornamentales y la carne y la leche bovina. La silvicultura aporta un 2% del PIB de la provincia, empleando a cerca de 7 mil personas. La pesca supone cerca del 1% del PIB, y emplea a cerca de 3 mil personas. El valor anual de la pesca capturada en la provincia es de aproximadamente 175 millones de dólares canadienses.

El sector secundario aporta el 25% del PIB de Nuevo Brunswick. La industria de manufactura aporta el 14% del PIB de la provincia y emplea aproximadamente a 41 mil personas. El sector de la construcción supone el 5% del PIB de la provincia y emplea a cerca de 19,6 mil personas. La minería aporta el 2% del PIB y emplea aproximadamente a 3 mil personas. Los principales recursos naturales extraídos en Nuevo Brunswick son el plomo, el cobre, la plata, el zinc, el cadmio, el bismuto, el oro y el carbón.

El sector terciario supone el por 70% del PIB de Nuevo Brunswick. Los servicios suponen el 22% del PIB de la provincia y emplean a cerca de 127,3 mil personas. Los servicios financieros e inmobiliarios emplean aproximadamente a 12,7 mil personas y suponen más del 22% del PIB de Nuevo Brunswick. El comercio al por mayor y al por menor responde por un 11% del PIB de la provincia y emplea aproximadamente a 55,1 mil personas. Transportes y telecomunicaciones suponen el por 10% del PIB y emplean aproximadamente a 32,2 mil personas y los servicios gubernamentales el 10% del PIB de la provincia, empleando aproximadamente a 22,9 mil personas. Los servicios públicos responden por el 4% del PIB de la provincia y emplean aproximadamente a 4,3 mil personas.

Cerca del 30% de la electricidad generada en Nuevo Brunswick está producida por la central nuclear de Point Lepreau, el 35% es generada en centrales termoeléctricas a carbón o a petróleo, y el 15% en centrales hidroeléctricas. El otro 20% se genera en centrales localizadas fuera de Nuevo Brunswick, pero administradas por la provincia. Cerca de la mitad de la electricidad generada en Point Lapreau es exportada a los Estados Unidos. Nuevo Brunswick también exporta electricidad a la Isla del Príncipe Eduardo.

Durante el siglo XVIII, la educación se impartía en los hogares o en escuelas privadas. En 1816, Nuevo Brunswick creó un sistema de escuelas públicas, donde existiría al menos una escuela en cada condado de la entonces colonia británica. Sin embargo, presupuestos insuficientes por parte del gobierno de Nuevo Brunswick forzaron a muchas de estas escuelas a cobrar por la prestación de la educación. Fue en 1871 cuando la provincia implementó el sistema de distritos escolares, dando a estas divisiones administrativas el poder de cobrar impuestos con fines educativos. En 1967, Nuevo Brunswick pasó a aportar todos los presupuestos necesarios para su sistema escolar público. Los distritos escolares, sin embargo, no fueron extinguidos, perdiendo solamente su poder de cobrar impuestos.

Actualmente, es el Ministerio de Educación de Nuevo Brunswick el responsable de dictar reglas y patrones de las escuelas de la provincia. No existen ya los distritos escolares en Nuevo Brunswick y las escuelas son administradas directamente por la provincia. La atención escolar es obligatoria para todos los niños y adolescentes con más de siete años de edad, hasta la conclusión de la enseñanza secundaria o hasta los dieciocho años de edad.

Durante el curso 2004/2005, las escuelas públicas de la provincia atendieron a 117.205 estudiantes, empleando a 7.509 profesores. El sistema de escuelas públicas de la provincia invirtió 1.013,6 millones de dólares canadienses, y el gasto de las escuelas públicas por estudiante fue de 8.653 dólares canadienses.

Nuevo Brunswick posee actualmente cinco sistemas de bibliotecas públicas. La biblioteca provincial, localizada en Fredericton, suministra parte de los presupuestos necesarios para el mantenimiento de estas bibliotecas públicas. La primera institución de enseñanza superior de Nuevo Brunswick, la Universidad de Nuevo Brunswick, en Fredericton, fue fundada en 1785.

Nuevo Brunswick posee cerca de mil kilómetros de vías férreas y 955 kilómetros de vías públicas. Saint John es el principal centro de transportes en general de Nuevo Brunswick, y un gran centro portuario, aeroportuario y ferroviario canadiense. Es uno de los pocos centros portuarios del este canadiense que opera todo el año.

Los primeros periódicos publicados en Nuevo Brunswick fueron el "The Royal Gazette" y el "The New Brunswick Advertiser", que fueron publicados en 1785. Actualmente se publican en la provincia cerca de 25 periódicos, de los cuales cinco son diarios.

La primera estación de radio de Nuevo Brunswick fue fundada en 1923, en Fredericton. La primera estación de televisión de la provincia fue fundada en 1954, en Saint John. Actualmente, Nuevo Brunswick posee 31 estaciones de radio —de las cuales 11 estaciones son de radio AM y 20 estaciones son de FM— y tres estaciones de televisión.





</doc>
<doc id="2038" url="https://es.wikipedia.org/wiki?curid=2038" title="Nueva Escocia">
Nueva Escocia

Nueva Escocia (en inglés: "Nova Scotia", nombre de origen latino; en francés: "Nouvelle-Écosse"; en gaélico escocés: "Alba Nuadh") y abreviada comúnmente NS, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital y ciudad más poblada es Halifax. Ubicada en el extremo este del país, está formada por la península homónima y la isla de Cabo Bretón en la extremidad norte de esta. La península está rodeada por el océano Atlántico, salvo por el istmo de Chignecto —que la une a Nuevo Brunswick— y el estrecho de Northumberland —que la separa de Isla del Príncipe Eduardo. Con 55 284 km² es la segunda entidad menos extensa —por delante de Isla del Príncipe Eduardo— y con 17 hab/km², la segunda más densamente poblada, por detrás de Isla del Príncipe Eduardo.

Forma parte de las Provincias Marítimas. Su capital es un puerto muy importante de Norteamérica. La pesca y el turismo son vitales para la economía de la provincia.

Aunque el explorador Juan Caboto la visitó en 1497 por cuenta de la Corona de Inglaterra, Nueva Escocia fue colonizada por primera vez por el reino de Francia. Samuel de Champlain y De Monts fundaron una colonia en una isla en la desembocadura del río Sainte-Croix en 1604. Al sufrir falta de agua potable en la isla ese invierno, al año siguiente (1605) la colonia fue trasladada a Port Royal, cerca de Annapolis Royal.

En los años 1620, el rey Carlos VI de Escocia y I de Inglaterra envió una tropa de escoceses para fundar en el lugar una colonia con el nombre de "Nova Scotia", como homenaje a sus orígenes escoceses. Para ello fundó el impuesto o "baronetage" de Nueva Escocia: aquellos que deseasen obtener el título nobiliario de "baronet" quedaban obligados al pago de una cierta suma de dinero que serviría para la fundación de la colonia, además de recibir en la misma una concesión de tierras. Durante la Guerra de los Nueve Años o de la Gran Alianza contra Francia, fue tomada por británicos, pero en los tratados firmados al final de la misma, se volvió a ceder a Francia: Tratado de Rijswijk 20 de septiembre de 1697. Fruto del tratado los colonos escoceses debieron abandonarlo, el "baronetage" de Nueva Escocia perdió su valor, pasando a ser una mera categoría nobiliaria.
El territorio fue capturado por fuerzas británicas durante la Guerra de la reina Ana, que es como se conoce el conflicto de Guerra de Sucesión Española en el escenario Norteamericano. La titularidad inglesa fue ratificada por el Tratado de Utrecht (1713). Francia retendría la posesión de la Île St Jean (Isla del Príncipe Eduardo) e "Île Royale" (Isla de Cabo Bretón), en la que establecieron la fortaleza de Louisbourg, que se construyó para vigilar las vías marítimas que se dirigen al río San Lorenzo. 

La fortaleza de Louisbourg sería en 1745, en el curso de la Guerra de Sucesión Austriaca (1740 - 1748), conocida como "Guerra del rey Jorge" en su escenario americano. El tratado de Aix-la-Chapelle o Tratado de Aquisgrán (1748) que puso fin a dicho conflicto, estipuló la devolución a Francia de la fortaleza de Louisbourg. 

Louisbourg sería nuevamente tomada (Batalla de Louisbourg, junio-julio de 1758) por una tropa mixta de soldados del Ejército británico y habitantes de las colonias americanas, durante la Guerra Franco-india, que es como se conoce al frente norteamericano de la Guerra de los siete años. Una vez en manos inglesas, (antes incluso de la Batalla de las Llanuras de Abraham, que abriría paso a la conquista del Quebec), los Británicos destruyeron la fortaleza de Louisbourg con explosivos para evitar que pudiera volver a ser usada por los franceses si la retomaban fruto de algún nuevo tratado de paz. 

Quedaría ratificada la posesión inglesa por el Tratado de París (1763) al recibir Gran Bretaña todos los territorios franceses en el Canadá.

La presencia de los acadianos, francófonos y de religión católica en el territorio de la futura colonia británica planteaba a los británicos un problema cara a la colonización del territorio. En 1750 un alto número de colonos de religión protestante, en su mayor parte de origen alemán, fueron atraídos a Nueva Escocia, estableciéndose en la costa sur. La colonia seguía sin embargo siendo mayoritariamente acadiana. Pero a partir de 1755, los británicos decidieron deportar a los acadianos a sus otras colonias americanas, a Francia, al Reino Unido o a Luisiana, lugar donde muchos de ellos se establecieron contribuyendo a forjar la cultura cajún.

Tras la Deportación de los acadianos, las tierras acadianas fueron entregadas a colonos americanos procedentes de Nueva Inglaterra. Unos 8.000 de ellos, llamados «planters» se establecieron en la colonia entre 1759 y 1774, entre ellos el bisabuelo de Robert Laird Borden. Una nueva inmigración escocesa cuyo destino fue la isla de Cabo Bretón, en las postrimerías del siglo XVIII y a principios del siglo XIX restableció la antigua presencia escocesa en la región.

En 1784 la porción continental del noroeste de la colonia fue separada del resto, pasando a constituir la colonia de Nuevo Brunswick.
En 1848 Nueva Escocia se convirtió en la primera colonia del Imperio británico en alcanzar el «self-government» o autogobierno, en que el gobernador británico quedaba obligado a aceptar las decisiones tomadas por una Asamblea Legislativa y por unos ministros electos por la misma.

En la isla se encuentran enterrado muchos de los fallecidos en el naufragio del RMS Titanic.

Nueva Escocia se convirtió, al entrar en la Confederación Canadiense, en una de las cuatro provincias fundadoras de Canadá, junto con Nuevo Brunswick, Quebec ("Canadá Este") y Ontario ("Canadá Oeste"). 

A pesar de su nombre, quedan escasísimos habitantes en la región que sigan hablando el gaélico escocés, aunque la música celta sigue gozando de gran popularidad en la isla de Cabo Bretón. Sigue habiendo actualmente una pequeña presencia acadiana en la localidad de Clare (al oeste de la provincia).

La provincia está dividida en 18 condados.

Los 10 condados más poblados de la provincia:

La economía de Nueva Escocia se basa actualmente en el sector servicios y el sector industrial, aunque sigue manteniendo presencia el sector primario.

En el sector primario, por lo que respecta a la agricultura, destaca la producción de fruta, especialmente manzanas, y patatas. En la ganadería tiene presencia la avicultura y el ganado porcino, a lo que se une una cabaña bovina generadora de productos lácteos.

También existe una activa industria de tipo forestal, dedicada a la explotación de los bosques del territorio.

Por otro lado, es igualmente importante la pesca de langostas, bivalvos (destacando las vieiras) o bacalao, especialmente. 

Posee igualmente una activa industria, relacionada con las actividades pesqueras y con la industria alimentaria en general, pero también industria papelera, de equipos de transporte.

El turismo ha adquirido una creciente importancia a lo largo de la segunda mitad del siglo XX.





</doc>
<doc id="2040" url="https://es.wikipedia.org/wiki?curid=2040" title="Nenúfar">
Nenúfar

El término nenúfar se aplica, en general, a plantas acuáticas con flores que crecen en lagos, lagunas, charcas, pantanos o arroyos de corriente lenta, estando usualmente enraizadas en el fondo. Los "nenúfares" pertenecen a las familias Nymphaeaceae, Cabombaceae del orden Nymphaeales; la familia Nelumbonaceae del orden Proteales y también a los géneros Nymphoides de la familia Menyanthaceae del orden Asterales y el género Hydrocleys de la familia Alismataceae del orden Alismatales. Véase cada una de estas tres familias o uno de estos dos géneros para datos más específicos.
Las hojas de los nenúfares comunes pueden ser de dos tipos:

Los antiguos egipcios veneraban los nenúfares del Nilo, a los que solían llamar “lotos” (no confundir con el género lotus). Es frecuente el motivo del “loto” en los capiteles de las columnas (forma lotiforme) de los templos egipcios. Florece en la noche y se cierra por la mañana, esto simbolizaba la separación de deidades y era un motivo asociado a sus creencias sobre la muerte y el más allá. El reciente descubrimiento de las propiedades psicodélicas del loto azul egipcio es muy probable que hubiesen sido conocidas por los egipcios y explica su papel ceremonial que puede verse en multitud de representaciones. Restos de ambos tipos de nenúfares se han encontrado en la tumba de Ramsés II.

Una placa siria de terracota del siglo  a. C. al  a. C. muestra a la diosa Asera con dos flores de loto. Un panel de marfil del siglo  a. C. al siglo  a. C. muestra al dios Horus sentado en una flor de loto, flanqueada por dos querubines.

El pintor francés Claude Monet es famoso por sus pinturas de nenúfares.

Muchos de los nenúfares familiares de los jardines acuáticos son híbridos.

Los nenúfares de jardín provienen del género botánico "Nymphaea" aunque su nombre en español deriva de otra planta de parecidas características conocida como "Nuphar".

Los nenúfares se desarrollan a expensas de un tallo carnoso (rizoma) que vive entre los materiales acumulados en el fondo de charcas y cursos estancados de aguas poco profundas. Las hojas tienen un buen tamaño y forma casi circular con una profunda escotadura que llega hasta la inserción del pecíolo con el limbo (parte plana). Estas hojas, al igual que las flores, son flotantes y nacen directamente del rizoma, al que se unen por largos pecíolos. Las flores de buen tamaño incluso muy grandes, se visten con multitud de pétalos imbricados formando una especie de cuenco en cuyo centro se encuentran los estambres y pistilos. La amplia gama de colores de la flor incluye el blanco puro, marfil, crema, rosa, rojo, carmesí, cobrizo y amarillo en distintas tonalidades según variedades. En situaciones apropiadas la emisión de flores es continua de mayo a septiembre. La profundidad de plantación necesaria para los diferentes tipos de nenúfares oscila entre 20 cm y el metro, mientras que la superficie de extensión foliar va de 0,5 a 1,5 metros cuadrados.

tas


</doc>
<doc id="2041" url="https://es.wikipedia.org/wiki?curid=2041" title="Numerología">
Numerología

La numerología es una práctica adivinatoria que utiliza los números. Es un conjunto de creencias o tradiciones que pretende establecer una relación mística entre los números, los seres vivos y las fuerzas físicas o espirituales. Su estudio fue popular entre los primeros matemáticos, pero no se la considera ya disciplina matemática. La comunidad científica hace tiempo que relegó la numerología a la categoría de pseudociencia o superstición, al igual que la astrología con respecto a la astronomía, o la alquimia, aunque esta última tuvo carácter de protociencia con respecto a la química.

En numerología, se dice que los números son uno de los conceptos humanos más perfectos y elevados. Según los que la practican, la numerología es la disciplina que pretende investigar la «vibración secreta» de ese código y enseñan a utilizar los números en su beneficio, por medio del estudio de su influencia sobre personas, animales, cosas y eventos.

En el año 530 a. C., Pitágoras, filósofo griego, desarrolló en forma metódica una relación entre los planetas y su «vibración numérica». La denominó «música de las esferas». Mediante su método de numerología afirmó que las palabras tienen un sonido que vibra en consonancia con la frecuencia de los números como una faceta más de la armonía del universo y las leyes de la naturaleza.

Según los numerólogos, los números son mucho más que una forma de medir o cuantificar lo que existe a nuestro alrededor. Pitágoras creía que el universo debe ser visto como un todo armonioso, donde todo emite un sonido o vibración. Los números del 1 al 9 están asociados a características específicas, que juntas abarcan toda la experiencia de la vida.

El sistema numérico por excelencia en numerología es el decimal, siendo excepción la escuela caldea de numerología, que utiliza el sistema octal.

Existen varias escuelas de numerología, entre ellas:







</doc>
<doc id="2046" url="https://es.wikipedia.org/wiki?curid=2046" title="Nirvana (espiritualidad)">
Nirvana (espiritualidad)

En la filosofía shramánica, nirvana es el estado de liberación tanto del sufrimiento (dukkha) como del ciclo de renacimientos. 

Es un concepto importante en el hinduismo, jainismo y budismo y suele alcanzarse mediante diferentes prácticas y técnicas espirituales.

Nirvana es una palabra del sánscrito que hace referencia a un estado que puede alcanzarse a través de la meditación y la iluminación, y que consiste en la liberación de los deseos, la conciencia individual y la reencarnación.

Nirvana significa literalmente "apagado", como en una vela.

En otros idiomas se dice:

En el contexto religioso, este término pasa a aplicarse en las religiones en India como el hinduismo, budismo, jainismo, para así indicar un estado de cese de la actividad mental corriente y que significará una liberación espiritual, el estado de felicidad supremo.
Dependiendo de cada contexto religioso, el nirvana tiene diferentes implicaciones.
Las dos religiones más importantes respecto a su influencia en Occidente son la hinduista y la budista (fundada por el Buda Gautama).

En todas estas religiones, la palabra nirvana tiene connotaciones de quietud y paz.
La persona que experimenta el nirvana se compara con un fuego apagado cuando su provisión de combustible se ha extinguido.
En todas ellas también este combustible sería la falsa idea del Yo, que causa (y es causada por) el deseo, la necesidad, la conciencia, el nacimiento, la muerte, la codicia, el odio, la confusión, la ignorancia.
Entonces el nirvana no sería un sitio ni un estado, sino una verdad absoluta que debe ser experimentada.

Según sus practicantes, la experiencia del nirvana es posible mediante:


Cada uno de estos senderos considera que es el único que permite alcanzar el nirvana y considera que los demás senderos son seudorreligiosos y dirigidos por maestros o gurús falsos.

El nirvana es el estado transcendente libre de sufrimiento y de la existencia fenoménica individual; es la experiencia religiosa más identificada con el budismo.
La palabra procede de un verbo que significa "enfriarse" o "apagarse", como el final de una vela.
La connotación es que sólo en el nirvana están extinguidas las llamas del odio, el apego y la ignorancia.
En estado de nirvana se rompe el ciclo de la transmigración, que de otra manera sería eterno.
Su naturaleza ha sido muy debatida por el pensamiento occidental, algunos de cuyos investigadores sostienen que implica una total aniquilación aunque otros lo interpretan como beatitud eterna.
Ambos puntos de vista son problemáticos en ocasiones, ya que el nirvana es indescriptible y sólo puede conocerse desde su experiencia.

En el hinduismo se habla de la unión con el uno absoluto (Brahman), por tanto aunque el nirvana apunta a un mismo suceso de paz interior, no se debe considerar exactamente con las mismas consecuencias que en el budismo, ya que de hecho el budismo redefinió el concepto de nirvana según sus propios postulados.
Cada una por tanto tiene su propio marco religioso.

El hinduismo utiliza el término nirvana en su contexto de "" (liberación del "samsara" o del ciclo de nacimientos y muertes repetidos), en el que el alma o "ātmān" se fundirá con la divinidad o lo absoluto.
Esta liberación es por tanto una fusión del alma con la divinidad.

A su vez dentro del hinduismo este concepto de liberación es concebido de manera diferente por los distintos credos "(dárśanas)" hindúes.
Los vaishnavas (vishnuistas, o devotos del dios Vishnú) consideran que "" no implica la fusión monista del alma dentro de Dios, sino la aceptación del alma para servirlo.
Por eso en el vaishnavismo no se desea realmente abandonar la reencarnación, sino servir a Dios, aunque sea sufriendo en este mundo lejos de él.

Siddhartha Gautama se refería al nirvana de la siguiente manera:
Como no se puede definir el nirvana con palabras, se lo suele delimitar por lo que no es:


Buda Gautama redefinió la consecución del nirvana presente en el hinduismo mediante un proceso de meditación en el que se analiza el cuerpo y la mente como carentes de una individualidad intrínseca.
En ese proceso existe un vacío de individualidad "(śūnyatā)" de todo lo presente en el cuerpo y mente del sujeto.
Esta falta de una individualidad es también común en todos los fenómenos del universo.

Al igual que en el hinduismo, la realización del nirvana budista implica la liberación definitiva del sufrimiento de la existencia o de los diferentes estados de reencarnación a los que todos los seres están sujetos.
Pero en el budismo esta idea será llevada hasta sus últimas consecuencias.
La diferencia en el contexto hinduista es que esto ocurre por la unión a un absoluto (Brahman) a semejanza de lo que expone la mística de las religiones teístas occidentales.

La afirmación de que el budismo considera el nirvana como lo opuesto al "samsāra" (el mundo tal como lo vivimos ahora) no es correcta desde el punto de vista de la doctrina budista, toda vez que dioses y hombres están sujetos al "karma" y Buda expresó la liberación final de dioses y hombres en medio del mundo de los fenómenos.
Por lo tanto, se distanció de ese estado de absorción en la divinidad o unión a un absoluto como vía de liberación definitiva tal como estaba presente en el hinduismo.

En el jainismo se refiere a la liberación de las ataduras del karma. Cuando un ser humano como un Tirthankara se libera de sus karmas finaliza su experiencia en el mundo logrando el nirvāṇa. 
Técnicamente, el final del período de vida es llamado nirvana en tanto que ha acabado la existencia terrenal y ha alcanzado la liberación. El Moksa sería entonces la liberación que sigue al nirvana. Así tendríamos un primer paso, el nirvana, que realiza el Arhat y que solo después y mediante el Moksa pasa a convertirse en siddha, el liberado.

Los jainas celebran el Diwali como el día en que Mahavira logró su nirvana. El Kalpasutra narra detalladamente el nirvana de Mahavira.



</doc>
<doc id="2051" url="https://es.wikipedia.org/wiki?curid=2051" title="Ojo humano">
Ojo humano

En el ser humano, el ojo es un órgano que detecta la luz y es la base del sentido de la vista. Su función consiste básicamente en transformar la energía lumínica en señales eléctricas que son enviadas al cerebro a través del nervio óptico. Funciona de forma muy similar al de la mayoría de los vertebrados y algunos moluscos; posee una lente llamada cristalino, que es ajustable según la distancia; un "diafragma", que se llama pupila, cuyo diámetro está regulado por el iris, y un tejido sensible a la luz, que es la retina. La luz penetra a través de la pupila, atraviesa el cristalino y se proyecta sobre la retina, donde se transforma, gracias a unas células llamadas fotorreceptoras, en impulsos nerviosos que se trasladan, a través del nervio óptico, al cerebro.

Su forma es aproximadamente esférica, mide 2,5 cm de diámetro y está lleno de un gel transparente llamado humor vítreo que rellena el espacio comprendido entre la retina y el cristalino.

En la porción anterior del ojo se encuentran dos pequeños espacios: la cámara anterior que está situada entre la córnea y el iris, y la cámara posterior que se ubica entre el iris y el cristalino. Estas cámaras están llenas de un líquido que se llama humor acuoso, cuyo nivel de presión (presión intraocular) es muy importante para el correcto funcionamiento del ojo.

Para que los rayos de luz que penetran en el ojo se puedan enfocar en la retina, se deben refractar. La cantidad de refracción requerida depende de la distancia del objeto al observador. Un objeto distante requerirá menos refracción que uno más cercano. La mayor parte de la refracción ocurre en la córnea, que tiene una curvatura fija. Otra parte de la refracción requerida se da en el cristalino. El cristalino puede cambiar de forma, aumentando o disminuyendo así su capacidad de refracción. Al envejecer, el ser humano va perdiendo esta capacidad de ajustar el enfoque, deficiencia conocida como presbicia o vista cansada.

El órgano de la visión está compuesto por los párpados, los globos oculares, el aparato lagrimal y los músculos oculares externos. El globo ocular mide unos 25 mm de diámetro y se mantiene en su posición gracias a los músculos extraoculares. La visión binocular, con la participación de ambos ojos, permite apreciar las imágenes en tres dimensiones.

La pared del ojo está formada por tres capas:

El ojo se forma por la fusión de varias estructuras que proceden de tejidos embrionarios distintos. La retina es un derivado del prosencéfalo (cerebro anterior) y por tanto forma parte del sistema nervioso central, mientras que la córnea y el cristalino proceden del ectodermo superficial.

Los primeros signos del futuro ojo se observan de forma muy temprana en el embrión, pues son visibles a finales de la tercera semana o principios de la cuarta, aproximadamente en el día 22. La retina se forma a partir de dos vesículas ópticas que nacen directamente de la porción anterior del cerebro primitivo, llamada prosencéfalo, al que está conectada mediante los tallos ópticos. Estas dos vesículas se van aproximando poco a poco a la superficie y sufren una invaginación en la parte anterior, pasando de ser esféricas a tener forma de copa, dando origen al cáliz óptico que tiene doble pared por el plegamiento sufrido. La pared interna que recubre el interior del cáliz óptico, dará lugar a la retina, mientras que la pared externa formará la lámina de células epiteliales ricas en melanina.

El ectodermo superficial que entra en contacto con la parte anterior del cáliz óptico sufre un espesamiento, formando la placa cristalina, que se invagina y da origen a la vesícula cristalina, la cual es el germen del futuro cristalino. A partir de la quinta semana del desarrollo, la vesícula cristalina pierde contacto con el ectodermo superficial y se dispone cubriendo el orificio del cáliz óptico. Cuando la vesícula cristalina se separa, esta misma zona del ectodermo se espesa de nuevo, para formar la córnea.

La parte anterior del globo ocular está cubierta por la córnea, una estructura transparente y resistente que carece de vasos sanguíneos.

Alrededor de la córnea está la conjuntiva. Por detrás de la córnea se halla la cámara anterior, limitada por el iris y la pupila. Detrás del iris y la pupila se encuentra la cámara posterior, el cuerpo ciliar y el cristalino.

La cámara anterior y la cámara posterior son dos pequeños espacios separados por el iris y conectados por la pupila que están llenos de un líquido transparente, el humor acuoso. El humor acuoso humedece el cristalino, garantiza su nutrición y contribuye a mantener la forma de la porción anterior del ojo.

El iris está formado por dos músculos que controlan la dilatación y la contracción de la pupila. El color del iris depende de la transparencia del estoma y de la cantidad de pigmento que contiene. Cuando el pigmento es escaso, los ojos son azules, mientras que cuando hay una cantidad mayor se aprecian matices verdes o castaños.

El cristalino es la lente del ojo, está sostenido por unas fibras conjuntivas muy finas llamadas ligamento suspensorio del cristalino que a su vez se unen al músculo ciliar. El cristalino se forma a lo largo de la tercera o cuarta semana de embarazo. Es blando y elástico en los niños, pero se endurece con el paso de los años.
El cuerpo ciliar se extiende entre la ora serrata y el iris, y es responsable de la producción del humor acuoso y del cambio de forma del cristalino necesario para lograr la correcta acomodación (enfoque). Está formado por dos estructuras, el músculo ciliar y los procesos ciliares.

Detrás del cristalino se encuentra el humor vítreo. El humor vítreo es un gel transparente que ocupa la mayor parte del interior del ojo y contribuye a que este mantenga su forma. Está en contacto directo con la retina, que es la túnica más interna del ojo. La retina es sensible a los estímulos luminosos y está conectada con el cerebro mediante las fibras del nervio óptico.

En la retina se pueden diferenciar varias partes, la más importante es la mácula, que es la zona con mayor agudeza visual. En el centro de la mácula se encuentra la fóvea que es un área muy pequeña, formando una depresión, extremadamente sensible a la luz. La fóvea es el área de la retina donde se enfocan los rayos luminosos y se encuentra especialmente capacitada para la visión aguda y detallada. Cualquier daño en la fóvea tiene importantes consecuencias en la capacidad visual.

Otra zona importante es la papila óptica que es el lugar por donde sale de la retina el nervio óptico. En la papila no existen células sensibles a la luz por lo que se conoce también como punto ciego.

La ora serrata es la porción más anterior y periférica de la retina, por la que ésta entra en contacto con el cuerpo ciliar.

El ojo recibe los estímulos luminosos procedentes del entorno. La luz atraviesa los medios transparentes y la lente del ojo, formando una imagen invertida sobre la retina. En la retina, células especializadas transforman la imagen en impulsos nerviosos. Estos llegan a través del nervio óptico hasta la región posterior del cerebro. El cerebro interpreta las señales mediante un complejo mecanismo en el que intervienen millones de neuronas.

El iris es un diafragma circular que regula la cantidad de luz que ingresa en el ojo, mediante el músculo constrictor del iris o músculo esfínter de la pupila y el músculo dilatador de la pupila o radial. Presenta un orificio central de unos 3 mm de diámetro, la pupila. Ésta se adapta a la intensidad de la luz. Si la luz es intensa, la pupila se contrae (miosis), si la luz es escasa, la pupila se dilata (midriasis).

La constricción del iris es involuntaria y está controlada de forma automática por el sistema nervioso parasimpático, la dilatación también es involuntaria, pero depende del sistema nervioso simpático.

La córnea es la estructura hemisférica y transparente localizada en la parte anterior del ojo que permite el paso de la luz y protege al iris. El cristalino está detrás de la córnea, tiene forma biconvexa y es la lente u objetivo del ojo. Cuando un rayo de luz pasa de una sustancia transparente a otra, su trayectoria se desvía: este fenómeno se conoce con el nombre de refracción. La luz se refracta en la córnea y el cristalino y se proyecta sobre la retina.

Los rayos de luz que penetran en el ojo deben enfocarse exactamente sobre la retina para que la imagen obtenida sea nítida. Ello requiere un ajuste que ocurre de forma muy similar tanto en el ojo humano como en el resto de los animales vertebrados.
El proceso mediante el cual los rayos luminosos procedentes tanto de objetos cercanos como lejanos se enfocan con exactitud sobre la retina se llama acomodación.
El mecanismo de la acomodación exige la contracción del músculo ciliar que está unido al cristalino mediante el ligamento suspensorio.

Si el músculo ciliar se contrae, el cristalino se hace más esférico y aumenta su poder de refracción, lo cual permite enfocar la luz procedente de objetos cercanos.
Cuando el músculo ciliar se relaja, el cristalino se hace menos esférico, disminuye su poder de refracción, lo cual nos permite ver con nitidez objetos lejanos.

En la retina están las células visuales, por lo que se la puede comparar a una película fotosensible. Estas células son capaces de captar la luz visible que es solo una pequeña parte del espectro electromagnético, la comprendida entre los 400 nanómetros de la luz violeta y los 750 nanómetros de la luz roja.

La luz que incide en la retina desencadena una serie de fenómenos químicos y eléctricos que finalmente se traducen en impulsos nerviosos que son enviados hacia el cerebro por el nervio óptico.

Las células sensoriales de la retina reaccionan de forma distinta a la luz y los colores. Los bastones se activan en la oscuridad, y sólo permiten distinguir el negro, el blanco y los distintos grises. Los conos, hacen posible la visión de los colores.

En el ojo humano hay tres tipos de conos, sensibles a luz de color rojo, verde, y azul. Cada uno de ellos absorbe la radiación de una determinada porción del espectro gracias a que poseen unos pigmentos llamados opsinas.
Las opsinas son unas moléculas que están formadas por una proteína y un derivado de la vitamina A. La eritropsina tiene mayor sensibilidad para las longitudes de onda largas de alrededor de 560 nm (luz roja), la cloropsina para longitudes de onda medias de unos 530 nm (luz verde) y por último la cianopsina con mayor sensibilidad para las longitudes de onda pequeñas de unos 430 nm (luz azul).
Mediante las diferentes intensidades de las señales producidas por los tres tipos de conos, podemos distinguir todos los colores que forman el espectro de luz visible.

Los conos están concentrados en el centro de la retina, mientras que los bastones abundan más en la periferia de la misma. Cada cono está conectado individualmente con el centro visual del cerebro, lo que en la práctica permite distinguir a una distancia de 10 metros dos puntos luminosos separados por sólo un milímetro. Cada ojo humano dispone de 7 millones de conos y 125 millones de bastones.

La musculatura extrínseca está formada por seis músculos que se insertan por una parte en la órbita y del otro lado en la capa más externa del ojo, la esclerótica. Estos músculos son los que permiten mover el ojo en cualquier dirección sin necesidad de cambiar la posición de la cabeza, tal como ocurre por ejemplo cuando seguimos con la vista un objeto en movimiento.

Los nervios ópticos de ambos ojos se entrecruzan antes de entrar en el encéfalo, formando el quiasma óptico. Luego se prolongan por las cintillas ópticas hacia la zona media del cerebro. Finalmente estos impulsos alcanzan los centros visuales de los lóbulos occipitales.

Cuando los impulsos nerviosos llegan a los lóbulos occipitales del cerebro, la información debe ser procesada. El cerebro procesa la información visual de forma particular.
Los diferentes aspectos de una imagen son decodificados por diferentes partes del mismo.

La forma de un objeto es procesada por una vía, mientras el color y el movimiento lo son por otras vías diferentes. De esta forma, el daño de una zona concreta del cerebro, puede producir ciertas manifestaciones características, como ocurre en la agnosia (imposibilidad de nombrar y reconocer un objeto común) que se produce cuando se lesiona un área específica de asociación visual que se encuentra en el hemisferio cerebral izquierdo.

Las órbitas son dos cavidades óseas, simétricas y profundas con forma de pirámide cuyo vértice apunta hacia atrás, tienen la función de proteger al ojo. Están situadas a ambos lados de la nariz, en el límite del cráneo con la cara. Constan de cuatro paredes: superior, inferior, interna y externa y un vértice donde se encuentra el agujero óptico que es la principal comunicación de la órbita con el interior del cráneo.

Dentro de la órbita se encuentra el ojo y una serie de estructuras anexas que son imprescindibles para el funcionamiento adecuado de este órgano. A continuación se enumeran:

Las razones más comunes de consulta con relación al ojo son: pérdida de agudeza visual, dolor, cuerpo extraño, cefalea, irritación del ojo (ojo rojo), otros síntomas variables (secreciones, ardor, prurito, fotofobia, etc.) y trastornos anatómicos.

Incluye el estudio de la agudeza visual, la capacidad para distinguir colores, el sentido luminoso, es decir la medida de la intensidad de luz necesaria para distinguir un objeto y el estudio del campo visual que se realiza mediante una prueba llamada campimetría.

Para explorar la agudeza visual, el paciente debe leer varias filas de letras de tamaño decreciente (test de Snellen). Si la visión es normal, se pueden leer todas las filas a una distancia de 6 metros.
Para corregir el déficit de visión se pueden utilizar cristales de distinto tipo: cóncavos y convexos. Los cristales cóncavos, corrigen la miopía y los convexos se utilizan para la presbicia y la hipermetropía.

Para examinar la visión cromática o visión de colores, el médico presenta al paciente varias láminas con un dibujo en color sobre un fondo de otro color. Si se distinguen con normalidad todos los colores, se pueden apreciar los dibujos que hay sobre el fondo. La acromatopsia total impide distinguir cualquier color: la visión es exclusivamente en blanco y negro. Es más frecuente la acromatopsia parcial como ocurre en el daltonismo.

Incluye una inspección general de la cara, los párpados, observando su aspecto y posición, la región lagrimal, la superficie interna de los párpados (conjuntiva palpebral), eversión de los párpados en busca de cuerpos extraños allí alojados. También el examen de la movilidad ocular y los reflejos pupilares, como el reflejo fotomotor que consiste en el cierre inmediato de la pupila tras iluminar el ojo con una luz directa.

Mediante diferentes dispositivos de iluminación y una lente de aumento, se visualizan en detalle las estructuras de la porción anterior del ojo, es decir la conjuntiva, la córnea, el humor acuoso, el iris, el cristalino y la pupila.

Para explorar el fondo de ojo, el médico se sirve de un oftalmoscopio e instila en el ojo una sustancia que dilata las pupilas. De esta forma puede observar las porciones internas del órgano, la retina y sus vasos sanguíneos, la papila óptica, la coroides y el humor vítreo, así como detectar diversas enfermedades, como un desprendimiento de retina o signos de hipertensión arterial o diabetes que a veces se reflejan en la retina.

En este examen pueden visualizarse múltiples anomalías, algunas de las más usuales son las hemorragias en la retina y la presencia de exudados de diferentes tipos. Muchas enfermedades no oculares dan manifestaciones características que son detectables mediante esta exploración.

Se llama ceguera a una pérdida total o muy severa de la capacidad visual. Una persona ciega es incapaz de percibir la forma de los objetos, aunque puede conservar una mínima función que le permita distinguir entre luz y oscuridad.

El concepto de ceguera legal es distinto al anterior, pues se utiliza para diferentes cuestiones legales relacionadas con indemnizaciones, prestaciones sociales o afiliación a organizaciones de ciegos. La ceguera legal no tiene una definición única, pues depende de la legislación de cada país. En los países occidentales, generalmente se considera legalmente ciego a aquel individuo que tiene una agudeza visual menor de 0.1 (1 es la normalidad) o un campo visual muy disminuido, inferior a 10 grados.

Por lo tanto, contrariamente a lo que muchos creen, una persona con ceguera legal puede conservar un resto visual que le permita realizar algunas actividades de la vida diaria sin necesidad de ayuda.

Según los datos de la OMS, en el mundo existen 45 millones de personas ciegas, la mayoría de las cuales viven en países en vías de desarrollo. A nivel mundial las principales causas son: catarata (48 %), glaucoma (12 %), degeneración macular asociada a la edad (9 %), opacidades de la córnea (5 %), retinopatía diabética (5 %), diferentes trastornos agrupados como ceguera en la infancia (3.9 %) y tracoma (3,6 %). Muchas de estas enfermedades son perfectamente tratables, por lo que en los países desarrollados las causas principales son: Retinopatía diabética, degeneración macular asociada a la edad, glaucoma y accidentes.

La miopía es un defecto del ojo en el que el punto focal se forma delante de la retina, en lugar de en la misma retina como sería normal.

Esta anomalía ocasiona dificultad para ver de lejos. El sujeto verá mal todo aquel objeto situado a partir de una cierta distancia.

La causa más frecuente de miopía es un aumento en el diámetro anteroposterior del globo ocular. También puede ser debida a un aumento de la capacidad de refracción del cristalino o al aumento en la curvatura de la córnea como ocurre en el queratocono. Se trata mediante el uso de gafas correctoras, lentillas, con una intervención quirúrgica con láser (LASIK, PRK) o con la colocación de lentes intraoculares.

La hipermetropía es un defecto del ojo, en el cual los rayos de luz que inciden en el mismo procedentes del infinito, forman el foco en un punto situado detrás de la retina. Se trata por lo tanto de un defecto refractivo inverso al de la miopía.

A diferencia de la miopía no es progresiva y tampoco suele producir complicaciones. Los niños afectados de hipermetropía no suelen presentar déficit de agudeza visual, sino dolor de cabeza o cansancio relacionados con el esfuerzo continuado de acomodación que debe realizar el músculo ciliar para lograr un correcto enfoque. En los adultos suele existir déficit de visión cercana y con el paso de los años se puede afectar la lejana. Se trata mediante el uso de gafas correctoras.

Es un defecto de refracción que se produce debido a que existe diferente capacidad de refracción entre dos meridianos oculares y en consecuencia los objetos se ven desenfocados. Generalmente está originado por una curvatura irregular en la zona anterior de la córnea, de tal forma que la refracción del meridiano vertical es diferente a la del horizontal. Se trata mediante la utilización de gafas con lentes correctoras.

La presbicia también llamada "vista cansada", comienza alrededor de los 40 años y alcanza su máxima evolución después de los 60. Consiste en la pérdida progresiva y gradual de la elasticidad del cristalino que se manifiesta por dificultad para ver con claridad los objetos cercanos. Una persona con presbicia necesita alejar un texto más de 33 cm de los ojos para poder leer, a esa distancia muchos caracteres no se distinguen con claridad.

Para garantizar una buena visión de los objetos cercanos, el cristalino debe cambiar de forma y hacerse más esférico para aumentar su poder de refracción, cuando ya no puede hacerlo, la visión cercana se hace borrosa, sin embargo, la visión de lejos sigue siendo buena.

Puede corregirse con el uso de lentes oftálmicas, que realizan el trabajo de convergencia de las imágenes tal como lo hacían antes los ojos.
Cuando existe otro problema de visión añadido, como la miopía, pueden utilizarse lentes bifocales o multifocales que permiten ver de manera correcta a diferentes distancias, por ejemplo para ver bien un monitor y un texto que está más próximo.

El daltonismo es un defecto del ojo. La persona que lo padece, presenta dificultad para distinguir el rojo y el verde, aunque hay casos en que también es difícil diferenciar otros colores. Cuando el defecto consiste en la imposibilidad de distinguir todos los colores, no es daltonismo sino otro trastorno más grave que se llama acromatopsia.

El daltonismo es mucho más corriente en el hombre que en la mujer y es hereditario. No suele causar otros trastornos, aunque constituye un problema en algunas profesiones que exigen una correcta visión de los colores.

La catarata es una opacidad del cristalino (la lente del ojo) que pierde su transparencia habitual. Como consecuencia la luz penetra con dificultad en el ojo, lo cual ocasiona pérdida de visión progresiva, que puede llegar a ser total, si no se realiza el tratamiento adecuado. Este consiste en una intervención quirúrgica mediante la cual se extirpa el cristalino y se coloca en su lugar una lente intraocular.

La catarata es generalmente degenerativa y aparece muy frecuentemente en personas de más de 50 años, aunque existen formas más raras que son congénitas (presentes en el nacimiento), algunas de las cuales se deben a que la madre sufrió una rubéola durante el embarazo, en este caso se denomina catarata rubeólica.

Según los datos de la Organización Mundial de la Salud, la catarata es la responsable del 48 % de los casos de ceguera en todo el mundo, lo cual supone 18 millones de personas.

Conjuntivitis es la inflamación de la conjuntiva (membrana mucosa que recubre el interior de los párpados de los vertebrados y se extiende a la parte anterior del ojo). Puede estar originada por muchas causas, entre las cuales la más frecuente es la infecciosa; pueden estar involucrados diferentes virus y bacterias. También existen conjuntivitis de origen alérgico, tóxicas por sustancias irritantes y actínicas por exposición a la luz o radiación ultravioleta.

Todos los casos presentan unas manifestaciones comunes: enrojecimiento, fotofobia y lagrimeo. Sin embargo otros síntomas dependen de la causa, secreciones matutinas en las bacterianas, ganglios aumentados de tamaño en las víricas, prurito estacional en las alérgicas, etc. La duración del cuadro es variable según el origen.

En general se trata de procesos benignos, aunque algunas formas pueden conducir a complicaciones como la queratitis (inflamación de la córnea) que a veces son graves.

El glaucoma es una enfermedad ocular causada por la elevación de la presión intraocular del ojo. La presión intraocular está determinada por el equilibrio entre la producción y reabsorción del humor acuoso. Si el canal por donde se drena el humor acuoso se obstruye, el líquido no se elimina y la presión intraocular aumenta en exceso.

El glaucoma es una afección que puede ser grave. Si no se trata a tiempo, puede generar la pérdida de la visión. Hay muchos medicamentos contraindicados cuando se padece glaucoma.




</doc>
<doc id="2052" url="https://es.wikipedia.org/wiki?curid=2052" title="Modelo OSI">
Modelo OSI

El modelo de interconexión de sistemas abiertos (ISO/IEC 7498-1), más conocido como “modelo OSI”, (en inglés, "Open System Interconnection") es un modelo de referencia para los protocolos de la red de arquitectura en capas, creado en el año 1980 por la Organización Internacional de Normalización (ISO, "International Organization for Standardization"). Se ha publicado desde 1983 por la Unión Internacional de Telecomunicaciones (UIT) y, desde 1984, la Organización Internacional de Normalización (ISO) también lo publicó con estándar. Su desarrollo comenzó en 1977.

A principios de 1980 el desarrollo de redes originó desorden en muchos sentidos. Se produjo un enorme crecimiento en la cantidad y tamaño de las redes. A medida que las empresas tomaron conciencia de las ventajas de usar tecnologías de conexión, las redes se agregaban o expandían a casi la misma velocidad a la que se introducían las nuevas tecnologías de red.

Para mediados de 1980, estas empresas comenzaron a sufrir las consecuencias de la rápida expansión. De la misma forma en que las personas que no hablan un mismo idioma tienen dificultades para comunicarse, las redes que utilizaban diferentes especificaciones e implementaciones no podían intercambiar información. El mismo problema surgía con las empresas que desarrollaban tecnologías de conexiones propietarias. Una tecnología es llamada «propietaria» cuando su implementación, (ya sea de software o hardware) está sujeta a un copyright. Esto supone que una empresa controla esta tecnología y las empresas que quieran utilizarla en sus sistemas tienen que pagar derechos por su uso. Las tecnologías de conexión que respetaban reglas propietarias en forma estricta no podían comunicarse con tecnologías que usaban reglas propietarias diferentes e incluso con las que usen reglas de conexión copyleft.

Para enfrentar el problema de incompatibilidad de redes, la ISO investigó modelos de conexión como la red de "Digital Equipment Corporation" (DECnet), la Arquitectura de Sistemas de Red ("Systems Network Architecture", SNA) y TCP/IP, a fin de encontrar un conjunto de reglas aplicables de forma general a todas las redes. Con base en esta investigación, la ISO desarrolló un modelo de red que ayuda a los fabricantes a crear redes que sean compatibles con otras redes.

Es un estándar desarrollado en 1980 por la ISO, una federación global de organizaciones que representa aproximadamente a 130 países. El núcleo de este estándar es el modelo de referencia OSI, una normativa formada por siete capas que define las diferentes fases por las que deben pasar los datos para viajar de un dispositivo a otro sobre una red de comunicaciones.

Siguiendo el esquema de este modelo se crearon numerosos protocolos. El advenimiento de protocolos más flexibles donde las capas no están tan desmarcadas y la correspondencia con los niveles no era tan clara puso a este esquema en un segundo plano. Sin embargo se usa en la enseñanza como una manera de mostrar cómo puede estructurarse una «pila» de protocolos de comunicaciones.

El modelo especifica el protocolo que debe usarse en cada capa, y suele hablarse de modelo de referencia ya que se usa como una gran herramienta para la enseñanza de comunicación de redes.

Se trata de una normativa estandarizada útil debido a la existencia de muchas tecnologías, fabricantes y compañías dentro del mundo de las comunicaciones, y al estar en continua expansión, se tuvo que crear un método para que todos pudieran entenderse de algún modo, incluso cuando las tecnologías no coincidieran. De este modo, no importa la localización geográfica o el lenguaje utilizado. Todo el mundo debe atenerse a unas normas mínimas para poder comunicarse entre sí. Esto es sobre todo importante cuando hablamos de la red de redes, es decir, Internet.

Este modelo está dividido en siete (7) capas o niveles:

Es la primera capa del Modelo OSI. Es la que se encarga de la topología de red y de las conexiones globales de la computadora hacia la red, se refiere tanto al medio físico como a la forma en la que se transmite la información.

Sus principales funciones se pueden resumir como:

Esta capa se ocupa del direccionamiento físico, del acceso al medio, de la detección de errores, de la distribución ordenada de tramas y del control del flujo. 

Es uno de los aspectos más importantes que revisar en el momento de conectar dos ordenadores, ya que está entre la capa 1 y 3 como parte esencial para la creación de sus protocolos básicos (MAC, IP), para regular la forma de la conexión entre computadoras así determinando el paso de tramas (unidad de medida de la información en esta capa, que no es más que la segmentación de los datos trasladándolos por medio de paquetes), verificando su integridad, y corrigiendo errores.

Por lo cual es importante mantener una excelente adecuación al medio físico (los más usados son el cable UTP, par trenzado o de 8 hilos), con el medio de red que redirecciona las conexiones mediante un router.

Dadas estas situaciones cabe recalcar que el dispositivo que usa la capa de enlace es el Switch que se encarga de recibir los datos del router y enviar cada uno de estos a sus respectivos destinatarios (servidor -> computador cliente o algún otro dispositivo que reciba información como teléfonos móviles, tabletas y diferentes dispositivos con acceso a la red, etc.), dada esta situación se determina como el medio que se encarga de la corrección de errores, manejo de tramas, protocolización de datos (se llaman protocolos a las reglas que debe seguir cualquier capa del modelo OSI).

Se encarga de identificar el enrutamiento existente entre una o más redes. Las unidades de datos se denominan paquetes, y se pueden clasificar en protocolos enrutables y protocolos de enrutamiento.


El objetivo de la capa de red es hacer que los datos lleguen desde el origen al destino, aun cuando ambos no estén conectados directamente. Los dispositivos que facilitan tal tarea se denominan encaminadores o enrutadores, aunque es más frecuente encontrarlo con el nombre en inglés "routers".
Los routers trabajan en esta capa, aunque pueden actuar como switch de nivel 2 en determinados casos, dependiendo de la función que se le asigne.
Los firewalls actúan sobre esta capa principalmente, para descartar direcciones de máquinas.

En este nivel se realiza el direccionamiento lógico y la determinación de la ruta de los datos hasta su receptor final.

Capa encargada de efectuar el transporte de los datos (que se encuentran dentro del paquete) de la máquina origen a la de destino, independizándolo del tipo de red física que esté utilizando.
La PDU de la capa 4 se llama Segmento o Datagrama, dependiendo de si corresponde a TCP o UDP.
Sus protocolos son TCP y UDP; el primero orientado a conexión y el otro sin conexión.
Trabajan, por lo tanto, con puertos lógicos y junto con la capa red dan forma a los conocidos como Sockets IP:Puerto (ejemplo: 191.16.200.54:80).

Esta capa es la que se encarga de mantener y controlar el enlace establecido entre dos computadores que están transmitiendo datos de cualquier índole. Por lo tanto, el servicio provisto por esta capa es la capacidad de asegurar que, dada una sesión establecida entre dos máquinas, la misma se pueda efectuar para las operaciones definidas de principio a fin, reanudándolas en caso de interrupción. En muchos casos, los servicios de la capa de sesión son parcial o totalmente prescindibles.

El objetivo es encargarse de la representación de la información, de manera que aunque distintos equipos puedan tener diferentes representaciones internas de caracteres, los datos lleguen de manera reconocible.

Esta capa es la primera en trabajar más el contenido de la comunicación que el cómo se establece la misma. En ella se tratan aspectos tales como la semántica y la sintaxis de los datos transmitidos, ya que distintas computadoras pueden tener diferentes formas de manejarlas.

Esta capa también permite cifrar los datos y comprimirlos. Por lo tanto, podría decirse que esta capa actúa como un traductor.

Ofrece a las aplicaciones la posibilidad de acceder a los servicios de las demás capas y define los protocolos que utilizan las aplicaciones para intercambiar datos, como correo electrónico (Post Office Protocol y SMTP), gestores de bases de datos y servidor de ficheros (FTP). Hay tantos protocolos como aplicaciones distintas y puesto que continuamente se desarrollan nuevas aplicaciones el número de protocolos crece sin parar.

Cabe aclarar que el usuario normalmente no interactúa directamente con el nivel de aplicación. Suele interactuar con programas que a su vez interactúan con el nivel de aplicación pero ocultando la complejidad subyacente.

A fin de facilitar el aprendizaje y memorización de los nombres de las capas que componen el modelo; una regla sencilla consiste en memorizarlas como una sigla nemotécnica: FERTSPA, que en inglés sonaría como "First Spa", primer spa en castellano, el cual se define de la siguiente manera:

El intercambio de información entre dos capas OSI consiste en que cada capa en el sistema fuente le agrega información de control a los datos, y cada capa en el sistema de destino analiza y quita la información de control de los datos como sigue:

Si una computadora (A) desea enviar datos a otra (B), en primer término los datos deben empaquetarse a través de un proceso denominado encapsulamiento, es decir, a medida que los datos se desplazan a través de las capas del modelo OSI, reciben encabezados, información final y otros tipos de información.

La unidad de datos de protocolo (N-PDU) es la información intercambiada entre entidades pares, es decir, dos entidades pertenecientes a la misma capa pero en dos sistemas diferentes, utilizando una conexión codice_1. Está compuesta por:

La Unidad de Datos de Interfaz (N-IDU): es la información transferida entre dos niveles adyacentes, es decir, dos capas contiguas. Está compuesta por:

La capa de aplicación recibe el mensaje del usuario y le añade una cabecera constituyendo así la PDU de la capa de aplicación. La PDU se transfiere a la capa de aplicación del modo destino, este elimina la cabecera y entrega el mensaje al usuario.

Para ello ha sido necesario todo este proceso:

Otros datos reciben una serie de nombres y formatos específicos en función de la capa en la que se encuentren, debido a como se describió anteriormente la adhesión de una serie de encabezados e información final.
Los formatos de información son los que muestra el gráfico:


En determinadas situaciones es necesario realizar una serie de operaciones sobre las PDU para facilitar su transporte, debido a que son demasiado grandes o bien porque son demasiado pequeñas y estaríamos desaprovechando la capacidad del enlace.

El bloqueo hace corresponder varias codice_11 en una codice_12.

El desbloqueo identifica varias codice_11 que están contenidas en una codice_12.

La concatenación es una codice_15 que realiza el codice_16 y que hace corresponder varias codice_17 en una sola codice_18.

La separación identifica varias codice_17 que están contenidas en una sola codice_18.

Las redes permiten la comunicación entre computadoras y otros dispositivos "inteligentes" como tabletas y teléfonos, pero también son el principal medio por el que estos dispositivos son infectados con virus o son atacados para robar información. Los entornos de red seguros son una necesidad cada vez mayor. El modelo OSI facilita la clasificación de los diferentes ataques conocidos y las acciones que permiten evitarlos o al menos mitigar sus consecuencias.




</doc>
<doc id="2054" url="https://es.wikipedia.org/wiki?curid=2054" title="Oceanía">
Oceanía

Oceanía es un continente insular de la Tierra constituido por la plataforma continental de Australia, las islas de Nueva Guinea, Nueva Zelanda y los archipiélagos coralinos y volcánicos de Melanesia, Micronesia y Polinesia. Un sector de los expertos considera que Insulindia también forma parte de Oceanía. Todas estas islas están distribuidas por el océano Pacífico. Con una extensión de 9 008 458 km², se trata del continente más pequeño del planeta tierra.

En otros modelos continentales, por ejemplo en los de habla inglesa, se usa Australia (continente) en lugar de Oceanía, pero en este caso su definición no incluye las , así como en otros modelos se utiliza el término de Oceanía para designar el conjunto de todas las islas del Océano Pacífico.

El término fue acuñado por el geógrafo francés Conrad Malte-Brun en 1812 como "Océanie", proveniente de "océan" (océano en francés) el cual, a su vez, deriva del griego antiguo "Ōkeanós" (Ώκεανός), combinado con el sufijo en latín -ia , basado en su cognado del griego antiguo -ία, -εια que se usa para designar sustantivos femeninos abstractos. El significado de su nombre se basa en el hecho que su territorio está compuesto por miles de pequeñas islas esparcidas en el océano más grande del planeta.

Los primeros pobladores humanos de Oceanía procedían del sureste de 
Asia. De ellos descienden los actuales papúes y nativos australianos. A esta primera oleada humana siguió la de los austronesios, también de origen asiático, que se extenderían hacia el este hasta la Isla de Pascua. Tanto la migración pre-austronesia como la posterior inmigración austronesia se dieron en oleadas diferentes que tardaron varios milenios en completarse. Hace 18 mil años Nueva Guinea y Australia formaba una única masa de tierra poblada por seres humanos, posteriormente la subida del nivel del mar aisló a las poblaciones en tres grupos: Nueva Guinea, Australia y Tasmania (además de algunas pocas islas menores). Dichas poblaciones evolucionaron separadamente bajo condiciones ecológicas divergentes y desarrollaron patrones culturales independientes. Por otra parte la presencia austronesia en Oceanía está testimoniada arqueológicamente ya en el milenio II a. C., cuando ocupaba básicamente regiones dentro de Melanesia, aunque las últimas islas importantes en ser colonizadas fueron alcanzadas durante el primer milenio d. C.

En el 950 d. C. el Imperio Tu'i Tonga dominó la mayoría de las islas de Oceanía, en sus comienzos los reyes lograron deshacerse del dominio extranjero y consolidó el poder del imperio en lo que hoy es Tonga. Cerca al año 1200 comenzó su expansión que se dio hasta, aproximadamente el 1500. El imperio conquistó lo que hoy en día se conoce como Fiyi, partes de Samoa y otras islas de la polinesia como las Islas Cook y Niue. La gran habilidad para construir canoas y el buen sistema aplicado a las invasiones facilitó que Tu'i Tonga se estableciera en más islas aún.

Cercano al año 1500 se desataron muchos problemas en la realeza del imperio que debilitó su figura en las colonias, que consiguieron mucha autonomía de la corona real y el poder central. En 1799 fue asesinado Tuku'aho, el rey que poseía el poder en ese momento, lo que desató una terrible guerra civil. Ya con la presencia europea la guerra civil terminó de devastar a los dos bandos, dejando al imperio diezmado en manos de la corona británica.

Los españoles fueron los primeros en cruzar el océano Pacífico y en llegar a las islas de Oceanía. La expedición de Fernando de Magallanes descubrió las Marianas en 1521 y otras islas del Pacífico. Tras la muerte de Magallanes en Filipinas, Juan Sebastian Elcano tomó el mando de la expedición, que acabaría circunnavegando el mundo. Poco después exploraron la región los portugueses: En 1525 descubrieron las Carolinas y, al año siguiente, Nueva Guinea. Entre 1525 y 1527 varias expediciones españolas descubrieron las Islas Marshall y las Islas del Almirantazgo y en 1568 las Islas Tuvalu, las Islas Salomón y la Isla de Wake. En 1595 otra expedición española descubrió las Marquesas y las Cook. En 1606, la expedición española de Quirós descubrió las Islas Pitcairn y las Nuevas Hebridas, cuya isla principal bautizaron con el nombre de "La Austrialia del Espíritu Santo", creyendo que habían llegado a la Terra Australis. A pesar de encontrarse en las Nuevas Hebridas, el nombre "Australia" ha perdurado hasta nuestros días para referirse a esa gran isla. Los neerlandeses recorrieron en 1642 el litoral de Australia y descubrieron Tasmania, las islas Tonga, Fiyi y Bismark. Mientras, durante dos siglos y medio, la ruta española del Galeón de Manila recorrió el Pacífico en ambas direcciones, uniendo los puertos de Acapulco y Manila entre 1565 y 1815.

En el siglo XVIII británicos y franceses se sumaron a la exploración de la Oceanía. Entre 1764 y 1770, los británicos recorrieron Tahití, Samoa, Salomón y Nuevas Hébridas. Entre 1772 y 1774, navegantes españoles llegaron a Tahití y descubrieron varias islas del archipiélago de las Tuamotu. Entre 1768 y 1779, navegantes ingleses también llegaron a las islas de la Sociedad, a Nueva Zelanda, las Marquesas, Nuevas Hébridas y Hawái. Los franceses exploraron las islas paralelamente a los británicos. Todos estos viajes determinaron el posterior reparto de Oceanía entre Gran Bretaña y Francia, así como España que llevaba varios siglos en Filipinas y las Marianas.

En 1831, Jules Dumont d'Urville dividió las islas de Oceanía en Melanesia, Micronesia, Insulindia y Polinesia, las cuales conjuntamente con Australia conforman la división tradicional.

A finales del siglo XIX y comienzos del XX, comenzaron los deseos de independencia en las colonias británicas, Australia y Nueva Zelanda, en 1901 y en 1907, respectivamente, abrieron el camino a los demás países hacia la independencia.

Los países más débiles y pobres solo pudieron declararse independientes durante la segunda mitad del siglo XX. En 1962, Samoa declaró su independencia de Nueva Zelanda, que la había ocupado años atrás; luego siguieron Nauru en 1968, Fiyi y Tonga en 1970, las Islas Salomón y Tuvalu en 1978, los Estados Federados de Micronesia y Kiribati en 1979 (aunque reconocida en 1990 para Micronesia), Vanuatu en 1980, las Islas Marshall en 1990 y Palaos en 1994 los siguieron en el proceso de libertad.

Estas naciones formaron el Foro de las Islas del Pacífico para intentar ayudar a países que aún están bajo el mandato de potencias, como Guam, en poder de los Estados Unidos, y Nueva Caledonia y Polinesia Francesa, ambas en poder de Francia.

El término Oceanía cubre una región macrogeográfica situada entre Asia y América, con Australia continental como la masa principal del continente, seguida por las mucho menores y cercanas islas de Nueva Guinea, Tasmania y Nueva Zelanda, a las que se suman unas 25 000 pequeñas islas dispersas en el Pacífico.

Los territorios de Oceanía se extienden desde el sureste de Asia por el océano Pacífico hacia América. Con su extensión de 9 008 458 km² es el continente más pequeño del mundo. Está bañada por los océanos Índico y Pacífico, con un total de 25 760 km de costas y posee la , Nueva Guinea, con 785 753 km². El clima es fuertemente influenciado por corrientes oceánicas, incluyendo El Niño, el cual causa sequías periódicas, y el sistema estacional tropical de baja presión, que produce ciclones en el norte de Australia.

La región desértica o semiárida es la de mayor extensión: un 40% de su territorio está cubierto por dunas de arena. Oceanía es el continente más seco, más plano, con los terrenos de mayor antigüedad y los menos fértiles. Curiosamente, la montaña más alta del continente, el Monte Jaya (4884 m), no se halla en Australia, sino que se encuentra en la isla de Nueva Guinea, perteneciendo a Indonesia. El Monte Kosciuszko, con 2228 m, es la principal elevación de Oceanía continental.

Los puntos geográficos extremos de Oceanía son los siguientes:


Oceanía esta compuesto por 14 naciones independientes, 14 dependencias (de países como Estados Unidos, Reino Unido, Francia, Nueva Zelanda y Australia) y 5 territorios integrados en otras naciones no oceánicas como Estados Unidos, Chile e Indonesia. Desde la llegada de los colonizadores europeos, Oceanía estuvo dividida en una serie de territorios dependientes, los que comenzaron a alcanzar su autonomía solo a partir de mediados del siglo XX, a excepción de Australia y Nueva Zelanda, que lo hicieron en 1901 y 1907 respectivamente.

Los estados de Oceanía se hallan plenamente integrados en la ONU siendo Australia y Nueva Zelanda países fundadores de dicha organización. De las dependencias seis de ellas (Tokelau, Polinesia Francesa, Samoa Americana, Pitcairn, Nueva Caledonia y Guam) están incluidas en la lista del Comité de Descolonización de la ONU.

En materia económica 8 estados son miembros de la Organización Mundial del Comercio (Australia, Fiyi, Nueva Zelanda, Papúa Nueva Guinea, Samoa, Islas Salomón, Tonga y Vanuatu) mientras que 6 estados no forman parte de la organización (Kiribati, Islas Marshall, Estados Federados de Micronesia, Nauru, Palau y Tuvalu). Así mismo, la totalidad del continente se incluye en el Fondo Monetario Internacional.

En materia de justicia y seguridad tan solo 8 países oceánicos están integrados en la INTERPOL (Australia, Fiyi, Nauru, Nueva Zelanda, Islas Marshall, Samoa, Papúa Nueva Guinea, Tonga). En el caso de la Justicia internacional seis países no han firmado ni ratificado el Estatuto de Roma de la Corte Penal Internacional. Mientras que las Islas Salomón han firmado que aún no lo han ratificado. En el resto de países acepta la jurisdicción del Corte Penal Internacional para juzgar casos de crímenes contra la humanidad.

Son tres estados oceánicos (Fiyi, Papúa Nueva Guinea y Vanuatu) los que están adscritos al Movimiento de Países No Alineados.

El peso de las relaciones internacionales en la zona lo llevan Australia y Nueva Zelanda, es por ello que en la mayoría de las organizaciones transcontinentales sea ambas naciones miembros. Así, Australia (1971) y Nueva Zelanda (1973) esta presentes en la Organización para la Cooperación y el Desarrollo Económicos (1960), en el Plan Colombo (1950) para el desarrollo local junto a Fiyi y Papúa Nueva Guinea. La Asociación ribereña del Océano Índico para la cooperación regional (1995) de cooperación entre países asiáticos, africanos y Australia. Y finalmente, en el Foro de Cooperación Económica Asia-Pacífico (1989) junto con Papúa Nueva Guinea, que entró en 1994.

En 1975 se creó Estados de África, del Caribe y del Pacífico (ACP) para, a través de varios acuerdos (el más reciente Acuerdo de Cotonú del año 2000) luchar contra la pobreza junto a la Unión Europea que trabaja por medio del Fondo Europeo de Desarrollo. Forman parte de esta organización todos los estados oceánicos salvo Australia y Nueva Zelanda, además de los territorios libres asociados de las Islas Cook y Niue. 

A nivel regional el Foro de las Islas del Pacífico es la principal organización. Los miembros plenos son los 14 países independientes además de 2 estados asociados libremente a Nueva Zelanda: las Islas Cook y Niue; y 2 dependencias de Franacia: Nueva Caledonia y Polinesia Francesa. Una dependencia como miembro asociado, Tokelau, y también admite como observadores a los países en proceso de descolonización: Samoa Americana, Guam, Wallis y Futuna, Islas Marianas del Norte y un país asiático, Timor Oriental.

Creó la figura de los «dialogue partners» (Canadá, China, la Unión Europea, Francia, Gran Bretaña, Japón, Corea del Sur, Malasia, Filipinas, Estados Unidos y Tailandia) y mantiene también reuniones separadas de sus ministros de asuntos económicos.

Uno de sus objetivos principales es promover la integración de los territorios de la región, pero también la búsqueda de soluciones para problemas comunes, tales como la seguridad, la pesca o el medio ambiente. La Declaración de Biketawa, firmada en octubre de 2000 pertenecientes al PIF, en donde se preveían mecanismos para que sus miembros intervinieran en los asuntos internos de otros «en tiempos de crisis» fue un paso crucial en el proceso de integración, que ha servido para allanar el envío de la RAMSI y para legitimar su éxito.

Existen otras organizaciones como el Grupo Melanesio Punta de Lanza (1986) que incluye 4 estados (Fiyi, Papúa Nueva Guinea, Islas Salomón y Vanuatu) además de dos partidos políticos pro independencia de sus respectivos territorios, el Movimiento Papúa Libre (Papúa Occidental de Indonesia) y el Frente Socialista de Liberación Nacional Canaco de Nueva Caledonia (colectividad sui generis de Francia). También hay dos organizaciones formadas por todos los estados independientes, dependientes y sus metrópolis (Estados Unidos, Reino Unido y Francia). La primera preocupada por el cambio climático como el Programa de Medio Ambiente Regional del Pacífico (1993) y la segunda la Comunidad del Pacífico (1947) con objetivos científicos y tecnológicos.

Finalmente debemos mencionar la organización militar más importante de la región, el ANZUS (1951), acuerdo firmado entre Australia, Nueva Zelanda y Estados Unidos. El establecimiento de una alianza de éste tipo en el sur del Pacífico respondía a una dinámica de bipolaridad en la que Estados Unidos quería garantizar una zona de influencia más allá del territorio en el cual es capaz de influir, y cuya presencia, cercana a la de la Unión Soviética, actuaba como disuasivo de un posible ataque nuclear.

Datos de superficie y población consultados en  actualizados 1 junio de 2016.

Son territorios dependientes de otra potencia en materias como política exterior, defensa o relaciones comerciales. Algunos de estos territorios están incluidos en el Comité de descolonización de la ONU como Samoa Americana, la Polinesia francesa, Guam, Nueva Caledonia, Islas Pitcairn y Tokelau. Los territorios dependientes de los estados europeos (Reino Unido y Francia) son países y territorios de ultramar (o PTU) son las dependencias y territorios de ultramar de los Estados miembros de la Unión Europea que no forman parte de la Unión, sino que tiene un estatuto de asociados a los Estados miembros desde el Tratado de Lisboa.

Datos de superficie y población consultados en  actualizados 1 junio de 2016.

Datos de superficie y población consultados en  actualizados 1 junio de 2016.

La definición exacta de qué territorios pertenecen al continente es muy variada:














Son pocos los países de Oceanía que gozan de libertad de expresión y sufragio universal. Solo Australia y Nueva Zelanda poseen gobiernos democráticos que pueden mantenerse a lo largo de los años, a pesar de que en Samoa, Vanuatu y Tonga los gobiernos también se encuentran bastantes consolidados.

En los demás países independientes o con deseos de serlo se viven momentos de irregularidad política, Fiyi sufrió un golpe de estado en 2006 y por esa razón fue expulsado de la Mancomunidad de Naciones, en Nueva Caledonia y, en menor medida, en la Polinesia Francesa se sufren tensiones por los deseos de la población nativa de declarar la independencia de Francia, Papúa Nueva Guinea posee un gobierno nacional muy débil, amenazado constantemente. Algo parecido ocurre en Islas Salomón.

Otros países no han tenido más elección que "someterse" a un país más poderoso, debido a que no pueden mantenerse económicamente de forma autónoma. Niue, Islas Cook y Tokelau firmaron un tratado de libre asociación con Nueva Zelanda. La Polinesia Francesa, Wallis y Futuna y Nueva Caledonia son estados dependientes de Francia. En la Micronesia la situación de los estados es muy mala. Todos poseen economías débiles y por lo tanto están muy influenciados por Estados Unidos, que domina la mayoría de los países de la región. Porque aunque no los domine políticamente, posee mucho poder sobre la economía de estos países en vías de desarrollo.

El peso de Oceanía en la economía mundial es muy escaso, apenas aporta tan solo el 1 % de la producción total.

Australia y Nueva Zelanda tienen una economía diversificada y muy desarrollada. Aunque hoy en día la mayor parte de la población trabaja en los servicios, el sector primario sigue siendo clave y proporciona una buena parte de las exportaciones.

Ambos países concentran el 40 % del ovino mundial, son los principales productores de lana y aportan más de un tercio de la producción mundial.

En Australia la actividad industrial ha experimentado un fuerte crecimiento en las últimas décadas, principalmente la industria pesada y la industria química; en su mayor parte, gracias a los importantes yacimientos mineros.
Por su parte, Nueva Zelanda posee numerosos lagos, utilizados para la producción de energía hidroeléctrica, lo que ha favorecido el desarrollo de diversas industrias básicas.

Dos tercios de la producción de Australia y Nueva Zelanda es insertada en los mercados asiáticos.

En los demás países del Pacífico, consiste en una economía rudimentaria y de autoabastecimiento.
En las islas volcánicas se practica la agricultura. En estas islas se hallan distintas especies tropicales.

El producto más importante que se exporta es la palmera cocotera, hay también ananás, arroz, bananas, caña de azúcar y la llamada «fruta del árbol del pan».

Otra actividad importante es la minera, hay reservas de oro en Papúa Nueva Guinea y níquel y hierro en Nueva Caledonia. En el océano Pacífico se hallan nódulos polimetálicos, que en algunas zonas son trabajados para la obtención de metales.

Una fuente de ingresos importantes es el turismo. Tahití y Fiyi son algunos países que subsisten principalmente con la industria del turismo. Es explotada por grandes industrias que construyen hoteles muy exóticos y consiguen cruceros y aviones para atraer al turismo mundial.

La pesca es también una actividad importante, especialmente en los países pequeños, como Wallis y Futuna, Nauru, Niue y las Islas Marshall.

Esta región es la menos poblada del mundo (con excepción de la Antártida) con aproximadamente 34 300 000 habitantes en el año 2010, esta cifra ha aumentado considerablemente debido a la alta natalidad y la baja mortalidad de Oceanía. La tasa de natalidad oceánica es de 21 % y la tasa de mortalidad del 9 %. La esperanza de vida promedio es de 70 años.

La densidad de población subió de 2,8 habitantes por km cuadrado a 3,4 habitantes por km cuadrado.

La mayoría de la población se concentra en Australia, Nueva Zelanda y Papúa Nueva Guinea, 92,1 % de la población de Oceanía. El resto de la población se divide en los demás países insulares del continente de Micronesia, Melanesia y Polinesia.

La población es heterogénea, gran parte de la población se concentra en grupos étnicos nativos de la Polinesia, Micronesia y Melanesia. Otra gran parte de las personas que viven en el continente son descendientes de los primeros colonizadores europeos, principalmente de ascendencias británica, alemana, neerlandesa, francesa y una pequeña parte desciende de españoles. Otro grupo étnico es el asiático, que a pesar de representar un bajo porcentaje del total, es el tercer grupo étnico más común de Oceanía. Esto se podría explicar debido a la gran cantidad de inmigrantes asiáticos, especialmente de Indochina, que recibe el continente desde hace ya muchos años.

En Nueva Zelanda, el censo de 2006, determinó que el 67,6 % de la población neozelandesa es étnicamente europea, mientras que tan solo el 14,6 % era maorí (un grupo nativo de Oceanía, el principal de Nueva Zelanda) y que el 9,2 % era asiático. En Australia los nativos representan solo 2,2 % de la población total australiana, el porcentaje más bajo de nativos oceánicos de los países del continente.

En otros países como Papúa Nueva Guinea, Vanuatu, las Islas Salomón, Fiyi, Samoa y Tonga, la mayoría de la población es descendente de tribus nativas de Micronesia, Melanesia y Polinesia, mientras que los descendentes de asiáticos y europeos representan una pequeña parte de la población total de estos pequeños países. Aunque la cantidad de personas relacionadas con la etnia asiática sigue creciendo, la etnia europea sigue siendo la segunda con más presencia en los países más pequeños de Oceanía.

Por número de personas las cuatro lenguas con mayor número de hablantes nativos en Oceanía son el inglés, el tok pisin, el francés y el hindi de Fiyi, las cuatro son lenguas con origen alóctono (autóctono de la región). Las lenguas nativas con mayor número de hablantes son el samoano, el fiyiano (austronesios) y el enga (papú).

La lengua más utilizada es el inglés, seguido del tok pisin (criollo) y del francés.

En algunas islas principalmente pertenecientes a la soberanía chilena, como en la Isla de Pascua y Juan Fernández, se habla el español. Minoritariamente se habla también en las islas estadounidenses de Guam y las Islas Marianas del Norte, y ha influido notoriamente en el idioma chamorro, hablado por los indígenas de ambos países. Existen también otras lenguas criollas locales de influencia española, que son habladas en Micronesia y Palaos, ambos países que forman parte del archipiélago de las Carolinas.

En Oceanía se hablan más de 1500 lenguas, cuya clasificación presenta aún bastantes dudas (especialmente en lo referente a las lenguas de origen pre-austronesio). A grandes rasgos se pueden diferenciar tres grupos:


Las primeras poblaciones de Australia y Nueva Guinea proceden de las primeras migraciones de la humanidad (proceso que se había iniciado en África). Cuando los primeros seres humanos poblaron esos territorios ambos formaban parte de una única masa de tierra, llamada Sahul, que incluía también a Tasmania. Estos hecho llevaron a Joseph Greenberg a especular sobre un origen común de las lenguas de estos territorios, que se denomina hipótesis indopacífica, que incluiría además el tasmanio (ya extinguido) y las lenguas andamanesas. Sin embargo, la enorme diversidad de estas lenguas y la escasa evidencia disponible para dichas hipótesis hacen que los dos últimos grupos sólo se consideren agrupaciones geográficas útiles, pero no grupos lingüísticos filogenéticos genuinos.

Las lenguas austronsias de Oceanía fueron divididas inicialmente según un criterio geográfico: Melanesia, Polinesia, Micronesia y Nueva Zelanda, sin embargo, estas divisiones no representan agrupaciones lingüísticas adecuadas (ver lenguas oceánicas). Las lenguas polinesias, de Fiyi y las lenguas micronesias parecen formar un grupo filogenético dentro de las lenguas oceánicas centro-orientales, mientras que las lenguas de Melanesia y otras áreas forman parte de diferentes familias oceánicas y por tanto no forman ningún grupo filogenético válido. Dentro de las lenguas polinesias se encuentran las lenguas de la isla de Pascua (rapanui) o Hawái (hawaiano) hasta Nueva Zelanda (maorí). El parentesco de estas lenguas polinesias ya fue detectado en los primeros viajes del capitán Cook.

Las lenguas no austronésicas de Nueva Guinea, llamadas lenguas papúes, sólo fueron razonablemente conocidas a partir del siglo XX. Su clasificación fue altamente controversial hasta los trabajos de Stephen Wurm (1975) y Malcolm Ross (2005). Esos trabajos sugieren que las lenguas papúes no forman una familia lingüística, sino varias familias altamente diversas. La mayor de estas familias está formada por las lenguas trans-neoguineanas que incluye centenares de lenguas. A este grupo pertenece el kate, que fue lengua franca de varios grupos antes de la expansión del tok pisin y el dani, lengua conocida por ser una de las pocas del mundo con solo dos términos para designar colores.

En cuanto a las lenguas de Australia, de las aproximadamente 750 que se hablaban en la isla antes de la llegada de los europeos, quedan actualmente unas 200, muchas de ellas con los últimos hablantes.

En muchas regiones de Oceanía, las lenguas autóctonas no han resistido la presión de la colonización y es actualmente la zona del mundo donde más lenguas autóctonas desaparecen. El samoano, lengua oficial de Samoa hablada por más 300 mil personas, es una de las pocas excepciones. Un caso curioso es la lengua llamada "beach-la-mar", criollo de base léxica inglesa, francesa, española e indígena. Esta lengua se utiliza como lengua puente del Pacífico no francófono y tiene, incluso, un diccionario y una literatura.

Algunas palabras procedentes de las lenguas de Oceanía han tenido una gran difusión a través del inglés. Entre estas podemos citar "ukelele" (del hawaiano), "tabú" y "tatuaje" (del tóngico) y kiwi (del maorí). De las lenguas australianas nos ha llegado la palabra "bumerang", que es originariamente el nombre de un grupo étnico local, así como algunos nombres de animales como "dingo", "koala" y "canguro".

En Oceanía la población varía dependiendo de las distintas regiones y países. En Australia y Nueva Zelanda la mayor parte de la población es adulta, superando ampliamente a la población joven. En cambio, en Fiyi, Kiribati, Papúa Nueva Guinea, Vanuatu y las colonias pertenecientes a Francia, al Reino Unido y a Estados Unidos, la mayor parte de la población está compuesta por jóvenes.

Por otra parte, en Papúa Nueva Guinea se ve una mayor cantidad de población adulta, pero con un envejecimiento mucho menor que en los otros países del continente.

Las Islas Marshall, Nauru y Tuvalu no fueron incluidos en el último informe sobre desarrollo humano del PNUD. Sin embargo sí fueron calculados en el año 2008, marcando los siguientes índices:

El 42,7 % de la población es protestante, el 24,7 % es católica, tan solo el 2,2 % pertenecen a la Iglesia ortodoxa y el 14,8 % profesan otras denominaciones cristianas (En total, el 86,6 % del continente es cristiano). Hay bajos porcentajes de nativos hinduistas (1,10 %), a pesar de que en Fiyi es la segunda religión más popular después del cristianismo, budistas (0,8 %), musulmanes (0,8 %) y de religiones tradicionales (0,8 %). El 13,1 % restante profesa otras religiones.

En resumen, 24 451 000 oceánicos son cristianos, 345 000 hinduistas, 266 000 budistas, 248 000 musulmanes, 259 000 de religiones tradicionales y 3 891 000 nativos pertenecen a otras religiones.

El arte tradicional de Oceanía tiene un sentido mágico-simbólico, originado por la preocupación religiosa y manifestado en ídolos, máscaras, armas, tatuajes y adornos. Los polinesios hacen llamativos tatuajes corporales; es más evolucionado el arte de los maoríes de Nueva Zelanda, con su arquitectura en madera, de una decoración muy rica, y grandes máscaras labradas; también llaman la atención sus figurillas de jade (tikis). En la Isla de Pascua son famosas las gigantescas estatuas de medio cuerpo, de piedra volcánica, alguna de hasta 15m de altura. Los melanesios decoran con figuras humanas y de animales las proas de sus piraguas y realizan máscaras de danza; en Nueva Guinea destacan las macabras estatuas de antepasados y la talla y adorno de cráneos de difuntos. En el arte de los micronesios resalta la elaboración de esteras.

Los dos deportes más populares son el rugby y el fútbol, aunque también el críquet, el culturismo, el béisbol, el baloncesto, el squash, el surf, la natación y algunos deportes locales, jugados por nativos, son también deportes practicados por los pobladores de Oceanía.

El rugby es el deporte más popular en Fiyi, Nueva Zelanda, Samoa, y Tonga, y goza también de buena popularidad en Australia (donde es el tercer deporte más popular, detrás del críquet y el fútbol australiano respectivamente) y Papúa Nueva Guinea (donde el deporte más popular es el rugby a 13, una variedad del rugby tradicional).

El torneo continental oceánico de rugby es la Copa del Pacífico, que se disputa desde 1975 y que incluye a todos los seleccionados de Oceanía y a equipos alternativos neozelandeses y australianos. Las primeras 4 ediciones (1974, 1977, 1986 y 1988) fueron ganadas por el seleccionado maorí de Nueva Zelanda, los siguientes dos campeonatos (1990 y 1992) quedaron para Samoa. Las ediciones de 1994 y 2006 fueron ganadas por el combinado tongano. Nueva Zelanda XIII en 1997, las Islas Cook en 2004 y Papúa Nueva Guinea en 2009 ostentan un solo título.

Nueva Zelanda y Australia son las selecciones más importantes de Oceanía, compiten a nivel internacional en todas las ediciones de la Copa Mundial de Rugby y el Torneo de las Tres Naciones. Nueva Zelanda consiguió el título mundial tres veces (1987 , 2011 y 2015) y el Torneo de las Tres Naciones en 9 ocasiones, mientras que Australia obtuvo el campeonato del mundo 2 veces (1991 y 1999), y el Torneo de las Tres Naciones en dos oportunidades. Estos dos países envían equipos alternativos a participar de los torneos continentales para poder mantener a los jugadores principales para los dos torneos más importantes a nivel mundial de rugby.

Fiyi, Tonga y Samoa son también selecciones importantes a nivel internacional, ya que compiten con frecuencia en la Copa Mundial de Rugby y en otros torneos de rugby union. Estos tres seleccionados se enfrentan cada año en la Pacific Nations Cup, el torneo sufrió cambios continuos de participantes, llegando a participar la selección junior de Nueva Zelanda, el elenco de maoríes neozelandeses y la selección alternativa de Australia, a pesar de esto, desde 2010 logró su forma actual, los tres seleccionados del Pacífico más Japón. Solo una vez una de las tres selecciones oceánicas pudo conquistar el título, lo hizo Samoa en 2010, ya que Nueva Zelanda Junior ganó las ediciones 2006, 2007 y 2009, Maoríes de Nueva Zelanda se quedó con el torneo celebrado en 2008 y Japón ganó el campeonato de 2011.

En rango de jerarquía, detrás de Fiyi, Samoa y Tonga aparecen los combinados de Papúa Nueva Guinea y las Islas Cook que tienen el gran logro de haber conseguido un título en la Copa del Pacífico. Juegan en prácticamente todas las ediciones de dicha copa, aunque nunca ninguno de los dos seleccionados llegó a jugar una Copa Mundial u otro torneo de rugby union.

Samoa Americana es otra selección de Oceanía de buen nivel, a pesar de ello, nunca llegó a disputar una Copa Mundial, aunque si jugó en tres ediciones de la Copa del Pacífico (1988, 1992 y 1994) sin poder lograr nunca un título. Niue representa otro seleccionado que nunca ha podido alzarse con títulos pero que si posee un cierto reconocimiento a nivel continental.

El fútbol no es tan practicado por los pobladores de Oceanía como el rugby, pero es el deporte más popular en Kiribati, Salomón, Tuvalu y Vanuatu. Como sucede en el rugby, las selecciones de y son las de mayor nivel, mientras que otras selecciones importantes oceánicas son , las , , y . La Confederación de Fútbol de Oceanía (comúnmente abreviada "OFC") es el máximo ente futbolístico de Oceanía, posee 11 miembros, las selecciones ya nombradas (exceptuando a Australia que en 2006 se adhirió a la AFC) y las , , , y . Además de 3 selecciones asociadas (miembros de la OFC, pero no de la FIFA), , y . y las fueron antiguos miembros asociados, pero hoy se encuentran en la AFC buscando su lugar en la FIFA. también es miembro de la AFC y de la FIFA, pero por ciertos problemas con la Federación Internacional de Fútbol Asociado no ha participado en las últimas dos eliminatorias asiáticas rumbo al Mundial.

El máximo torneo continental a nivel selecciones es la Copa de las Naciones de la OFC que se disputa desde 1973, edición que ganó Nueva Zelanda. El combinado neozelandés repitió esta hazaña tres veces más, en 1998, 2002 y 2008. Australia ganó los torneos disputados en 1980, 1996, 2000 y 2004. Estas dos son las únicas selecciones que han podido conquistar más de dos títulos en el campeonato. Si exceptuamos a Australia y Nueva Zelanda, sólo Tahití pudo lograr un campeonato (2012).

Por otro lado, en el Fútbol femenino, al igual que en fútbol masculino, Australia y Nueva Zelanda son las mejores selecciones del continente, goleando a todas la selecciones en todos los torneos (exceptuando los partidos entre sí). El Campeonato Femenino de la OFC, es la máxima competición a nivel continental (última edición en 2010), en la cual la selección neozelandesa es la más ganadora del certamen con 4 títulos, le siguen Australia y Taiwán. Ahora, sin Australia ni Taiwán, Nueva Zelanda, práctimente no tiene rival en la OFC, puesto a que logra goleadas increíbles (14-0, 10-0, 11-0 a Vanuatu, Islas Cook y Papúa Nueva Guinea, respectivamente en 2010), aunque en los mundiales, Nueva Zelanda no hace buenos papeles. Otra selección importante en la OFC es Papúa Nueva Guinea que gana con superioridad al resto de los países, aunque es goleada por Nueva Zelanda.

A nivel internacional la OFC es la confederación más débil de las seis asociaciones miembros de la FIFA. Australia disputó 3 mundiales (en el último, Sudáfrica 2010 ya era miembro de la AFC). Se clasificó siendo miembro de la OFC a los dos mundiales que se disputaron en Alemania, 1974 y 2006. Solo ganó un partido y en 1974 no pudo marcar goles. Nueva Zelanda, por su parte, jugó los mundiales de España 1982 y Sudáfrica 2010, en 1982 fue goleado en sus tres partidos, pero en 2010 fue la única selección que no perdió ningún partido, empatando en sus tres partidos en la fase de grupos. Solo una vez una selección oceánica superó la fase de grupos, lo hizo Australia en 2006 aunque fue eliminada en octavos de final a manos de la selección italiana, que días después obtendría el título mundial.

A nivel de clubes, todos los países cuentan con ligas semiprofesionales, además de sus respectivas copas. Australia y Nueva Zelanda, además de la liga oficial, poseen múltiples campeonatos regionales. El nivel de la A-League australiana crece año tras año, mientras que la ASB Premiership neozelandesa trata de ganar relevancia mundial. La Liga Nacional de Fútbol de Fiyi, la Primera División de Vanuatu, la S-League de Islas Salomón y la Tahiti Division Federale son ligas que están avanzando en nivel futbolístico. El campeonato de clubes a nivel continental es la Liga de Campeones de la OFC en la que solo una vez un equipo fuera de Australia y Nueva Zelanda logró un título, el Hekari United de Papúa Nueva Guinea. El campeón del torneo se clasifica para la Copa Mundial de Clubes de la FIFA. El mejor puesto alcanzado por un equipo de Oceanía en este torneo fue el tercer lugar logrando por Auckland City FC en la edición 2014.



</doc>
<doc id="2055" url="https://es.wikipedia.org/wiki?curid=2055" title="Onagraceae">
Onagraceae

Onagraceae (onagráceas, en español) es una familia de plantas generalmente herbáceas.
Tienen hojas simples, sin estípulas, alternas u opuestas. La familia se caracteriza por flores de 4 sépalos y pétalos en algunos géneros (por ejemplo, las fucsias), los sépalos son tan coloreados como los pétalos, por lo que da la impresión de que tienen doble número de éstos, son hermafroditas, actinomorfas o ligeramente cigomorfas, habitualmente tetrámeras (en la península) o dímeras, ínferas, con 2-4 carpelos y con un hipanto tubular, androceo con 8 (o 4+4) estambres. Fruto en cápsula, en baya, o seco indehiscente, más o menos alargado; es característica la presencia de un penacho de pelos en la semilla. 

Esta familia incluye unas 650 especies de hierbas, arbustos y árboles en 20 ó 24 géneros repartidos ampliamente por todos los continentes, abarcando desde las regiones boreales hasta las tropicales.


</doc>
<doc id="2057" url="https://es.wikipedia.org/wiki?curid=2057" title="Oxalidaceae">
Oxalidaceae

Las oxalidáceas (Oxalidaceae) son una familia de plantas herbáceas o raramente leñosas. Hojas alternas, compuestas, a menudo trifoliadas con peciolos largos. Flores hermafroditas, actinomorfas, diclamideas, pentámeras, diplostemonas, monadelfos en la base, gineceo supero, pentacarpelar, sincárpico, con estilos libres. Flores solitarias o en cimas. Frutos en cápsula loculicida o en baya, semillas con arilo carnoso. Unas 950 especies de las regiones cálidas y templadas, arvenses. 




</doc>
<doc id="2058" url="https://es.wikipedia.org/wiki?curid=2058" title="Oceanografía">
Oceanografía

La oceanografía es un campo de la ciencia que estudia los mares y océanos y todo lo que se relaciona con ellos, es decir, la estructura, composición y dinámica de dichos cuerpos de agua, incluyendo desde los procesos físicos, como las corrientes y las mareas, hasta los geológicos, como la sedimentación o la expansión del fondo oceánico, o los biológicos. La misma ciencia es llamada también en español con expresiones como ciencias del mar, oceanología y ciencias marinas. Se divide en muchas ramas, en relación con sus contenidos específicos, como oceanografía física, oceanografía química, oceanografía geológica, u oceanografía biológica.

La palabra "oceanografía" (del griego ωκεανός, "océano" y γραφειν, "describir" o "representar gráficamente") fue acuñada por primera vez en el año 1584, del francés "océanographie", pero tuvo una vida corta. En el año 1880 retorna al alemán como "Oceanographie". En esa misma época surgen correlativamente en otras lenguas "oceanography", en inglés; "oceanografía", en español. En la lengua portuguesa, la palabra oceanografía aparece al final del siglo XIX.

La formación de la palabra es basada en el vocablo "geografía" y responde al origen científico del cual proviene la disciplina. Sobre el modelo de la palabra "geología" se encuentra "oceanologia", registrada por primera vez en la lengua inglesa - "oceanology" - en 1864. Aunque algunos la definen más completa por "oceanología", la forma que ha ganado más popularidad es "oceanografía".

Existen cuatro ramas principales de la oceanografía: oceanografía biológica, oceanografía física, oceanografía geológica y oceanografía química.

La Oceanografía Biológica, que no es lo mismo que la Biología marina, estudia todos los organismos marinos y su relación con el medio ambiente.

Estudia los procesos físicos que ocurren en el mar, tales como la mezcla (difusión molecular y turbulenta de las propiedades del agua de mar), las corrientes, las mareas y el oleaje.

Estudia los procesos geológicos que afectan a los océanos.

Estudia la composición química del agua de mar. De los componentes disueltos y particulados, de sus interacciones y efectos en la hidrósfera, biósfera y atmósfera.





</doc>
<doc id="2059" url="https://es.wikipedia.org/wiki?curid=2059" title="Oleorresina">
Oleorresina

La oleorresina son extractos semisólidos compuestos de una resina en solución en un aceite escencial o graso, obtenido por la evaporación del solvente(s) utilizado para su producción. Las oleorresinas naturales son conocidas como bálsamos.

En contraste a los aceites esenciales obtenidos, por destilación por vapor, las oleorresinas abundan en compuestos más pesados, menos volátiles y lipofílicos, como las resinas, ceras, grasas y aceites grasos. Las "gomoleorresinas" (oleo-goma resinas, gomarresinas) ocurren principalmente como bálsamos crudos, y también contienen polisacáridos solubles en agua.

Las oleorresinas son preparadas a partir de especias, como por ejemplo: albahaca, capsicum (pimentón), cardamomo, semillas de apio, corteza canela, clavo de olor, fenogreco, bálsamo de abeto, jengibre, pomarrosa, ládano, macis, mayorana, nuez moscada, perejil, pimienta (blanca/negra), pimenta dioica, romero, salvia, ajedrea (de verano/invierno), tomillo, cúrcuma, vanilla y hierbas de la costa oeste de India. Los solventes utilizados no son acuosos y pueden tener enlaces polares (alcoholes) o apolares (hidrocarburos, dióxido de carbono).

Las oleorresinas son similares "concretos" utilizados en perfumería, obtenidos especialmente de flores, y también son similares a los "resinoides", también utilizados en perfumería, los cuales son preparados de las secreciones animales.

La mayoría de las oleorresinas son utilizadas como sabores para los perfumes, algunos son utilizados medicinalmente (ej. aceite de hachís, aerosol de pimienta)


</doc>
<doc id="2061" url="https://es.wikipedia.org/wiki?curid=2061" title="Ocio">
Ocio

Comúnmente se llama ocio al tiempo libre que se dedica a actividades que no son ni trabajo ni tareas domésticas esenciales, y que pueden ser consideradas como recreativas. Es un tiempo recreativo que se usa a discreción. Es diferente al tiempo dedicado a actividades obligatorias o esenciales, como comer, dormir, hacer tareas vinculadas a cierta necesidad, etc. Las actividades de ocio se hacen en el tiempo libre, y no por obligación. 

Según el científico Rommel Masaco el Ecuatoriano nacido en Nueva Loja, Sucumbios nos dice Que «El ocio es un conjunto de ocupaciones a las que el individuo puede entregarse de manera completamente voluntaria tras haberse liberado de sus obligaciones profesionales, familiares, y sociales, para descansar, para divertirse, y sentirse relajado para desarrollar su información o su formación desinteresada, o para participar voluntariamente en la vida social de su comunidad».

La distinción entre las actividades de ocio y las obligatorias no es estricta, y depende de cada persona; así estudiar, cocinar o hacer música, puede ser ocio para unos y trabajo para otros, pues pueden realizarse por placer como por su utilidad a largo plazo y/o eventual ganancia económica.

El ocio se puede emplear en actividades motivadoras y productivas. Por otro lado, el ocio en la Antigua Grecia era considerado el tiempo dedicado, principalmente por filósofos, para reflexionar sobre la vida, las ciencias y la política.

" Ocio: Toda actividad que el individuo desarrolla de manera libre, improductiva, que causa placer en el individuo y que no produce un desgaste neuromotriz"(según un punto de vista desde el turismo)
Utilizando como criterio la participación de las personas en el ocio, podemos distinguir dos tipos de ocio:

El Dr Manuel Cuenca habla sobre las dimensiones y direccionalidad del ocio dentro del ocio humanista. Partiendo de la premisa que el ocio es una experiencia que beneficia el desarrollo, entonces se vuelve relevante comprender qué tipo de ocio se practica y si realmente permite una mejora en la persona.

Las direccionalidades se dividen en positivas y negativas.
Negativo cuando la experiencia perjudica al sujeto o su entorno. En ella se identifican dos tipos:
Positivo si tiene una vivencia gratificante de las experiencias. Igualmente se divide en dos:
Y de este último ocio se derivan 5 dimensiones descritas por Cuenca:
"La vivencia de ocio es, o debiera serlo, una vivencia integral, relacionada con el sentido de la vida y los valores de cada uno, coherente con todos ellos".

Desde una perspectiva más actual, de acuerdo con Gomes e Elizalde (2012), el ocio no es un fenómeno aislado y se manifiesta en diferentes contextos según los sentidos y significados producidos/reproducidos culturalmente por las personas en sus relaciones con el mundo. El ocio participa de la compleja trama histórico-social que caracteriza la vida en sociedad, y es uno de los hilos tejidos en la red humana de significados, símbolos y significaciones.

En la vida cotidiana, el ocio constituye relaciones dialógicas con otros campos además del trabajo: la educación, la política, la economía, el lenguaje, la salud, el arte, la ciencia y la naturaleza, entre otras dimensiones de la vida, siendo parte integrante y constitutiva de cada sociedad (Gimes, 2010).

De este modo, para los autores Gomes y Elizalde el ocio es entendido como una necesidad humana y dimensión de la cultura caracterizada por la vivencia lúdica de manifestaciones culturales en el tiempo/espacio social. Así, el ocio se constituye en la articulación de tres elementos fundamentales: la ludicidad, las manifestaciones culturales y el tiempo/espacio social. Juntos, estos elementos configuran las condiciones materiales y simbólicas, subjetivas y objetivas que pueden – o no – hacer del ocio un potente aliado en el proceso de transformación de nuestras sociedades, convirtiéndolas en más humanas e inclusivas.

Las manifestaciones culturales que constituyen el ocio son prácticas sociales experimentadas como disfrute de la cultura, tales como: fiestas, juegos, paseos, viajes, música, poesía, graffiti y murales, pintura, escultura, danza, vivencias y expresiones corporales, juegos electrónicos y experiencias virtuales, fotografía, teatro, actividades comunitarias, ferias con nuevas modalidades de intercambio, actividades recreativas y deportivas, festivales y eventos artísticos, variadas modalidades de educación popular local, espacios de conversación y debate etc.

Desde esta perspectiva re-significada, el ocio puede generar una vivencia de apertura marcada por una actitud que rompa y transgreda con lo permitido y con lo lícito, mostrándose muchas veces al borde de lo socialmente adecuado y aceptado. Justamente a esto se debe uno de los grandes temores, así como peligros, que representa el ocio para el mantenimiento del status quo. De aquí surge, en parte, el intento de acallar y prohibir la disrupción, contracorriente, alteridad e innovación subversiva, y todo aquello que puede expresar un ocio polémico, caótico, contra-hegemónico y catalizador (Elizalde, 2010).

Según Gomes y Elizalde (2013), en los estudios sobre el ocio difundidos en Occidente es posible verificar que las raíces de este abordaje generalmente son localizadas en la Grecia clásica o en la modernidad europea. Estas dos interpretaciones son divergentes en términos de ocurrencia histórica del ocio y generan intensos debates académicos: para algunos, la existencia del ocio es observada desde las sociedades griegas, y para otros el ocio es un fenómeno específico de las sociedades modernas, urbanas e industrializadas.

Independientemente del contexto histórico y de las características consideradas, el desarrollo teórico sobre el tema desde finales del siglo XIX posibilitó la sistematización de los conocimientos sobre el ocio, una palabra que hoy - según algunos estudiosos - corresponde a los términos leisure en inglés, loisir en francés y lazer en portugués la doris.

Para algunos autores el ocio y al vocablo romano otium. Recuperando el significado de skholé, esta palabra representaba una posibilidad de abstención de las actividades ligadas a la mera subsistencia. Implicaba, necesariamente, las condiciones de paz, reflexión, prosperidad y libertad de tener que realizar las tareas serviles y vinculadas a las necesidades de la vida productiva. Como dependía de ciertas condiciones educacionales, políticas y socioeconómicas, skholé constituía un privilegio reservado a una pequeña parcela de los hombres libres. Para Aristóteles, las personas tenían que aprender a desear el reposo filosófico, pues, es por medio de él que se tornaría posible alcanzar virtudes. De esta forma, en su sentido griego, skholé era vinculada a la posibilidad de descanso y reposo, condición propicia por el distintivo característico de los privilegiados: la abstención de la necesidad de ejercer el trabajo útil o productivo y la posibilidad de dedicación a la contemplación, a la meditación y a la reflexión filosófica.

Como destaca Munné, el otium romano era estratificado socialmente: estaba asociado, en el caso de las elites intelectuales, a la meditación y a la contemplación. Era el otium con dignidad. Por eso, en lo que concierne a las personas comunes, otium significaba descanso y diversión proporcionados por los grandes espectáculos. Esta estrategia hacía referencia a la tradicional expresión “pan y circo” y tenía como finalidad despolitizar al pueblo, reduciéndolo a la condición de mero espectador, evidenciando así el potencial muchas veces alienante, de las formas de entretenimiento masivo.

La conexión que los romanos hicieron entre el otium y el negotium es interesante de comprender. El negotium, palabra latina que originó el término negocio, fue entendido como ocupación y actividad. De esta forma, el trabajo (negocio y comercio) también representaba la negación del otium. Para tener una visión más clara sobre la forma de entender el ocio y el trabajo en la antigüedad greco-romana es importante recordar que, etimológicamente, la palabra trabajo deriva del término latín tripalium, que significaba un instrumento de tortura con el que se obligaba a los esclavos a realizar determinadas tareas. Así, en la visión clásica greco-romana el ocio era mucho más valorizado que el trabajo, algo distinto a lo que ocurrió posteriormente.

En esta perspectiva, desde el siglo XIX el ocio está muy vinculado a las categorías trabajo y tiempo libre – concebidas desde una perspectiva sociológica. Por eso, la sociología es una importante área (pero no la única) que fundamenta las teorías y análisis desarrollados sobre la temática, principalmente por autores de Europa y de los Estados Unidos. Para muchos estudiosos, entre los cuales se destaca Dumazedier (1976), el ocio surgió en la modernidad europea en el siglo 21 como fruto de la revolución industrial acontecida, en los principales centros urbanos de Europa, sobre todo en Inglaterra. Para él, el ocio se contrapone al trabajo y corresponde a una liberación periódica del trabajo al fin del día, de la semana, del año y de la vida, cuando se alcanza la jubilación.

Independiente de que la ocurrencia histórica del ocio sea ubicada en la Grecia clásica o en la modernidad europea, es posible observar que Europa, con sus prácticas e instituciones, es considerada como imprescindible y determinante para el “surgimiento” del ocio en todos los rincones del mundo, incluso en Latinoamérica. Así, se perpetúa la idea de que existe una historia única y universal del ocio, que ubica Europa en una posición central, destacada y que debe ser tratada como válida para todo el mundo.

Ambas interpretaciones colaboran con el mantenimiento de una lógica evolutiva y lineal que define los tiempos, las historias, las culturas y las prácticas de todas las realidades, de todos los pueblos que, a su vez, deben anhelar el modelo occidental – urbano, industrial y capitalista – como el ideal a ser alcanzado para acceder al supuesto progreso. Las evidencias de que disponemos hasta el momento indican que los primeros conceptos elaborados sobre el ocio fueron producidos en este contexto. Pero un concepto no es el fenómeno, es solamente una representación de la realidad que pretende expresar. De esta manera, lo que “surgió” en Europa en el siglo XIX fue el concepto de ocio tal como lo entendemos actualmente en Occidente, y no la realidad que este pretende representar.

De acuerdo con Gomes y Elizalde (2012), desde el siglo XX estas dos distintas interpretaciones sobre el origen del ocio han generado profundas polémicas cuando se busca retomar la historia de este fenómeno. En general, ambas son ampliamente utilizadas en las teorías sobre el ocio que orientan y fundamentan los estudios sobre esa temática en varias partes del mundo, ejerciendo influencias significativas sobre los conocimientos difundidos en los distintos países de Latinoamérica.

Esas interpretaciones aun cuando son dotadas de lógicas propias, se refieren a realidades específicas pertinentes cuando se trata de Europa, por ejemplo, pero son inadecuadas e insuficientes para discutir el ocio y la recreación en Latinoamérica. Esta región posee otras singularidades y otros marcos históricos, culturales, sociales, políticos y económicos. Todo esto demanda otras interpretaciones, abordajes, reflexiones y re-significaciones, así como la sistematización de otros saberes que sean capaces de dialogar críticamente con las realidades latinoamericanas.

Como plantea Escobar, para hablar de América Latina es necesario considerar los lugares y realidades locales, obviamente sin perder de vista el contexto más amplio. De este modo, los análisis sobre los conceptos y teorías de ocio y recreación no pueden ser universales y globalizantes (Gomes, 2010).

Además de esto, las dos interpretaciones sobre un supuesto origen del ocio, destacadas previamente, son producciones teóricas que refuerzan el mito de la centralidad de Europa como referente privilegiado para la constitución del mundo, y sobre todo del llamado mundo occidental. De este modo, excluyen la decisiva participación de otras realidades en un juego que envuelve, de manera desigual, varios componentes, dentro de los cuales están los pueblos y culturas de otros continentes, tales como América Latina, África y Asia. (Gomes y Elizalde, 2012).




</doc>
<doc id="2062" url="https://es.wikipedia.org/wiki?curid=2062" title="Orchidaceae">
Orchidaceae

Las orquídeas u orquidáceas (nombre científico Orchidaceae) son una familia de plantas monocotiledóneas que se distinguen por la complejidad de sus flores y por sus interacciones ecológicas con los agentes polinizadores y con los hongos con los que forman micorrizas.

La familia comprende aproximadamente 25 000 especies (algunas fuentes informan de 30 000), por lo que resulta ser una de las familias con mayor riqueza específica entre las angiospermas. A esta diversidad natural se le suman 60 000 híbridos y variedades producidas por los floricultores.

Las orquídeas pueden ser reconocidas por sus flores de simetría fuertemente bilateral, en las que la pieza media del verticilo interno de tépalos —llamada labelo— está profundamente modificada, y el o los estambres están fusionados al estilo, al menos en la base.

Las orquídeas constituyen un grupo de plantas de morfología extremadamente diversa. Su tamaño varía desde unos pocos milímetros de longitud (ciertas especies de los géneros "Bulbophyllum" y "Platystele") hasta gigantescas agregaciones que pueden pesar varios cientos de kilogramos (algunas especies de "Grammatophyllum") o longitudes de hasta 13,4 m (como "Sobralia altissima"). Del mismo modo, varía el tamaño de sus flores, desde las diminutas del género "Platystele" —menores de 1 mm— pasando por las grandes flores de 15 a 20 cm de diámetro en muchas especies de los géneros "Paphiopedilum", "Phragmipedium" y "Cattleya", hasta los 76 cm de las flores de "Phragmipedium caudatum". La fragancia de sus flores no es menos variable, desde el delicado aroma de "Cattleya" hasta el repulsivo hedor de las flores de ciertas especies de "Bulbophyllum".

Se encuentran en la mayor parte del mundo, excepto en las regiones de clima desértico o polar, si bien son especialmente abundantes en la zona intertropical, donde crecen la mayoría de las especies de flores más vistosas.

La familia ha sido reconocida por los sistemas clásicos de clasificación de plantas, como el sistema de Cronquist, así como por los más modernos, como el sistema de clasificación APG II y el sistema de clasificación APG III.

Las orquídeas son plantas herbáceas, perennes —raramente anuales—, terrestres o epífitas, ocasionalmente trepadoras. Unas pocas especies carecen de clorofila, y son micoheterotróficas.
Con respecto a las orquídeas epífitas, se dice que pueden llegar a ser eternas. De hecho, en la naturaleza, su supervivencia está ligada a la vida del árbol que las sostiene. Se conocen plantas recolectadas a mediados del siglo XIX que todavía están creciendo y floreciendo en muchas colecciones.

Los tallos son rizomas o cormos en las especies terrestres. En las especies epífitas, en cambio, las hojas se hallan engrosadas en la base formando pseudobulbos que sirven para almacenar agua y nutrientes y que, por lo general, están recubiertos por las vainas foliares membranosas que se secan con la edad.

Existen dos tipos básicos de crecimiento dentro de la familia: el tipo simpodial, que origina tallos múltiples, y el tipo monopodial, que origina un solo tallo. El tipo simpodial de crecimiento es el más común dentro de la familia. La mayoría de estas orquídeas presentan pseudobulbos que funcionan como reservorios de agua y nutrientes. La planta sostiene los pseudobulbos casi verticalmente y el crecimiento y desarrollo posterior de nuevos tallos se produce horizontalmente, entre los pseudobulbos preexistentes. Cada nuevo pseudobulbo se origina en la base de los anteriores y, con su crecimiento, origina nuevas hojas y raíces. Las hojas originadas en cada pseudobulbo pueden durar muchos años, proveyendo nutrientes para toda la planta, hasta que se tornan marrones y mueren. Aun sin hojas, cada pseudobulbo continúa sosteniendo el crecimiento y suministrando la energía necesaria para el crecimiento del resto de la planta y para la floración. Algunos ejemplos de orquídeas con este tipo de crecimiento son los géneros "Cattleya", "Dendrobium" y "Oncidium". Las orquídeas con crecimiento monopodial, a diferencia de las anteriores, presentan un solo tallo principal que crece erecto e indefinidamente desde el centro de la planta. Normalmente, el tallo va creciendo hacia arriba y se originan raíces en los nudos, las cuales crecen hacia abajo. La planta, conforme va creciendo, pierde las hojas inferiores a medida que se forman nuevas hojas en el extremo superior. Algunas especies de orquídeas con este tipo de crecimiento son aquellas pertenecientes a los géneros "Ascocentrum", "Phalaenopsis" y "Vanda".

Las orquídeas terrestres a veces presentan raíces tuberosas. En las orquídeas epífitas, en cambio, las raíces son aéreas y están muy desarrolladas, cuelgan de los árboles y son verdes y gruesas. Las raíces de las epífitas tienen una doble función, son las estructuras que se encargan de captar los nutrientes que la planta necesita y funcionan, además, como elementos de fijación. Las raíces en este tipo de orquídeas típicamente poseen una epidermis esponjosa, formado por muchas capas de células muertas a la madurez y con paredes celulares engrosadas, llamada velamen. El velamen constituye una vaina esponjosa y blanquecina que rodea por completo a la raíz. Si el tiempo está seco, sus células están llenas de aire; pero cuando llueve se llenan de agua.
Según algunos autores el velamen es un tejido que absorbe agua, según otros nunca se ha observado el paso de agua del velamen al córtex de la raíz. Su función principal parece ser la de protección mecánica, además de impedir la excesiva pérdida de agua de la raíz en períodos de deficiencia hídrica. Además, cuando el velamen se llena de agua se vuelve transparente permitiendo a la luz alcanzar el tejido verde de las raíces y, por ende, facilita la fotosíntesis.

Del rizoma o de los tallos aéreos nacen las hojas, las cuales son simples y de margen entero, generalmente alternas, espiraladas, dísticas o verticiladas, muchas veces plicadas, basales o a lo largo del tallo, a veces reducidas a vainas o a escamas, usualmente con venación paralela y envainadoras en la base. Pueden presentar pecíolo o ser sésiles y no presentan estípulas. Las especies adaptadas a períodos de sequía tienen hojas carnosas que cumplen la función de reserva de agua en épocas de escasez.

Aún siendo una familia cuyas flores tienen un aspecto muy diferente entre géneros, su estructura es homogénea. Como en otras monocotiledóneas, el periantio es trímero. Está formado por tres piezas externas llamadas sépalos, dos laterales y uno dorsal, y tres elementos internos llamados pétalos, uno de ellos modificado en un labio o labelo de mayor tamaño y color más intenso que los demás. Esta modificación, junto con el fenómeno de resupinación o torsión que lo sitúa en posición inferior, cumple la función de atraer algún animal que es su polinizador. Hay variaciones estructurales que facilitan la polinización por una determinada especie de insecto, pájaro o murciélago. Algunos autores clasifican el perianto de las orquídeas como un perigonio, formado por seis tépalos dispuestos en dos verticilos.

Las diferentes piezas del perianto pueden estar separadas entre sí o fusionadas en la base.

Los sépalos, o tépalos externos, son usualmente petaloideos (similares a pétalos), imbricados. A veces los dos sépalos laterales se encuentran fusionados en un solo elemento llamado «sinsépalo». Los pétalos, o tépalos internos, están siempre separados, a veces presentan puntos, manchas y colores muy variados. El llamado «labelo» es el pétalo medio, es de tamaño mayor que los dos pétalos laterales y su forma es extremadamente variable. Es la pieza más compleja y, en cierto modo, un órgano característico de las orquídeas. Puede ser lobulado, y entonces se dice que existe un lóbulo central y dos laterales ("Orchis", "Dactylorhiza"). En otras oportunidades, como en "Epipactis", se diferencian transversalmente dos partes que se denominan «hipoquilo» la basal y «epiquilo» la distal. Puede tener áreas brillantes, crestas, quillas u otras protuberancias que se suelen denominar como «callo» o «callus». También es frecuente que desarrolle un espolón dirigido hacia atrás o hacia abajo en donde se aloja un nectario. Este espolón puede ser largo y fino ("Gymnadenia", "Orchis"), o como un saco redondeado ("Coeloglossum viride"). También hay especies en que el espolón no tiene néctar o puede haber nectarios no incluidos en el espolón.

El androceo está usualmente formado por uno o dos estambres (a veces tres), si es uno solo deriva del estambre medio del verticilo externo ancestral y usualmente con dos estaminodios vestigiales derivados de los estambres laterales de un verticilo interno ancestral. En algunas subfamilias, como en Apostasioideae o Cypripedioideae, hay dos o tres estambres fértiles. Cuando son dos, han derivado de los dos estambres laterales del verticilo interno ancestral, y cuando son tres, se han originado de los dos laterales del verticilo interno y del estambre medio del verticilo externo. El androceo se halla fusionado al estilo y al estigma, los cuales se hallan altamente modificados, formando una estructura conocida como «columna», «ginostemo» o «ginostegio». Las tecas de las anteras se disponen en la porción del ginostemo denominada «clinandro» o «androclino». El polen es granular, en tétradas o aglutinado en grupos de dos a ocho masas suaves o duras llamadas polinias. Estas polinias presentan un apéndice filiforme —llamado «caudícula»— que se une con una masa pegajosa —«retináculo» o «viscidium»— sobre el «rostelo», estructura derivada del estigma con forma de lóbulo alargado y que se sitúa sobre la porción receptiva del estigma. El conjunto de polinios, caudículas y retináculos se denomina «polinario», el cual es la unidad de transporte del polen durante la polinización. Las anteras son de dehiscencia longitudinal y su conectivo muchas veces se halla modificado en un «opérculo» que cubre la antera hasta la polinización.

El gineceo está formado por tres carpelos fusionados entre sí, con el ovario ínfero, que puede presentar un lóculo o tres, y numerosos óvulos (hasta millones) de placentación usualmente parietal, pero ocasionalmente de placentación axilar.

Las orquídeas son, en general, productoras de néctar, sustancia que utilizan como recompensa a los polinizadores. Los nectarios son variables en posición y tipo. Por ejemplo, se encuentran en el espolón del labelo, o en los ápices de los sépalos, o en las paredes internas del gineceo. Las especies que no producen néctar son autógamas o apomícticas, es decir, no necesitan de polinizadores para producir semillas.

Las orquídeas llevan sus flores de diversos modos. Aun dentro del mismo género, las diferentes especies pueden tener distintos modos de disponer las flores en inflorescencias, las cuales son indeterminadas y, a veces, reducidas a una única flor, terminal o axilar.
La mayoría de las orquídeas tienen inflorescencias que llevan dos o más flores, las que usualmente nacen de un eje floral más o menos alargado que comprende un tallo denominado "pedúnculo" y una porción que lleva las flores, llamada "raquis". En la mayoría de las especies las flores se disponen en un racimo erecto y alargado, con las flores arregladas en una espiral laxa alrededor del raquis (como, por ejemplo, en "Cymbidium)". En esos racimos las flores individuales se enlazan con el eje floral a través de un corto tallito llamado pedicelo. Puede ser que las flores se articulen con el raquis directamente, sin pedicelo, y —en ese caso— la inflorescencia se denomina espiga, como puede observarse en los géneros "Peristylus" y "Neuwiedia".

Un grupo de orquídeas pertenecientes al género "Bulbophyllum", bastante espectacular por su floración, presenta el raquis tan contraído que todas las flores parecen salir del mismo punto, como en una umbela. Algunas otras orquídeas "(Oncidium, Renanthera"), finalmente, presentan inflorescencias ramificadas que se denominan panículas.

El fruto es una cápsula loculícida, que se abre mediante tres o seis ranuras longitudinales (a veces una sola); en raras ocasiones, el fruto de las orquídeas es una baya.

Las semillas son diminutas y numerosas. El tegumento es crustoso o membranoso, sin fitomelaninas, con sólo la capa externa persistente y los tejidos internos colapsados. Las semillas son muchas veces membranosas y aladas, los que les permite ser dispersadas por el viento. El embrión es muy pequeño y no se halla acompañado por endosperma, ya que este tejido aborta muy temprano en el desarrollo embrionario.

La palabra "orquídea" deriva del griego ὄρχις ("órjis" ‘testículo’) e ἰδέα ("idéa" ‘forma’). El vocablo hace referencia a la forma de los tubérculos de las especies del género "Orchis", orquídeas de hábito terrestre cuyos tubérculos dobles parecen testículos, como puede apreciarse en la imagen de la derecha. El vocablo se atestigua por primera vez en los manuscritos de la obra "De causis plantarum" del filósofo griego Teofrasto, que datan aproximadamente del año 375 antes de Cristo.

Fueron conocidas y apreciadas por los seres humanos desde la Antigüedad. Existen escritos chinos de 1500 años de antigüedad donde se hace referencia al cultivo de las orquídeas. En la antigua Grecia se le atribuían propiedades curativas y afrodisíacas. Los aztecas utilizaban una orquídea —la vainilla— para enriquecer una bebida espesa hecha a base de cacao, destinada a los nobles y a los guerreros y era conocida con el nombre de "xocoatl".

En Europa, el interés por ellas se despertó hacia 1731 cuando floreció la primera orquídea tropical del Nuevo Mundo, "Bletia purpurea" (sin. "Bletia verecunda"), en la colección del almirante inglés Charles Wager quien la obtuvo del Jardín Botánico de Chelsea. Desde ese momento, se suscitó un interés sin igual por la adquisición y cultivo de orquídeas exóticas, en particular por los miembros de las clases sociales más acomodadas, quienes debían construir un orquideario como una obligación acorde con su estatus. De hecho, cuando una orquídea florecía en tales colecciones, el evento daba lugar a grandes fiestas y la noticia cubría las primeras planas de la prensa. Para satisfacer este consumo de orquídeas raras y exóticas, durante muchos años los recolectores profesionales provenientes en su mayoría de Francia e Inglaterra se dedicaron a saquear sin misericordia los bosques americanos, poniendo a muchas especies en peligro de extinción. A principios del siglo XX, no obstante, la era de la denominada «orquideomanía» llegaba a su fin. El costo para calefaccionar los invernaderos en los que se debían cultivar estas plantas era extremadamente alto y la carestía energética —agudizada por la primera guerra mundial— dificultó el mantenimiento de los orquidarios privados. Con la depresión de 1929, el cultivo de orquídeas a gran escala definitivamente pasó a manos de empresarios comerciales.

Las orquídeas conforman la familia más grande de las plantas con flores, con alrededor de 20 000 especies divididas en unos 800 géneros distribuidos por todo el mundo. Son una familia cosmopolita, que se halla distribuida desde dentro del círculo polar ártico hasta Tierra del Fuego y las islas al sur de Australia. Se hallan ausentes solamente en los desiertos verdaderos y en los polos. Son más diversas en las regiones tropicales, donde frecuentemente son epifitas. No obstante, la mayoría de las especies se encuentran en los trópicos y subtrópicos, desde el nivel del mar hasta los 5000 msnm, en casi todos los ambientes. En algunos ecosistemas son el elemento dominante, particularmente en hábitats deficientes en nutrientes. Solamente existen dos ambientes en la tierra donde no prosperan estas plantas, los polos y los desiertos de arena. Son más diversas en las regiones tropicales, donde frecuentemente son epifitas.
La mayor cantidad de especies se distribuyen en las regiones tropicales, particularmente en áreas montañosas, las cuales representan barreras naturales y aíslan a las diversas poblaciones de plantas, lo que ocasiona la formación de un elevado número de endemismos. Algunas áreas con una marcada predominancia de orquídeas son las islas y el área continental del sudeste asiático y la región montañosa de Colombia y Ecuador. El tercer sitio con un gran número de especies es la masa atlántica brasilera con, aproximadamente, 1500 especies descritas. Otras áreas importantes son las montañas del sur del Himalaya en la India y China, las montañas de América Central y el sudeste africano, notablemente la isla de Madagascar.

Colombia es el país que presenta la mayor riqueza de especies, llegando a totalizar 4270 taxones de orquídeas registrados, seguido por Ecuador con 3549, Nueva Guinea con 2717 y Brasil con 2590. México, Indonesia, Madagascar, Venezuela y Costa Rica son también países con un elevado número de especies.

Su capacidad para adaptarse es notable, ya que pueden crecer tanto a nivel del mar como en los páramos elevados. Muchas viven sobre los árboles (epifitas), otras lo hacen sobre las rocas (litófitas), otras sobre la tierra y algunas especies se desarrollan incluso en ambientes subterráneos. A pesar de lo que mucha gente cree, no son parásitas, ya que no se alimentan del árbol donde viven, sino que lo usan como medio de soporte y como vehículo para alcanzar la luz del sol. Algunas sólo miden unos pocos centímetros y otras pueden tener el porte de un árbol. Sus flores pueden ser tan diminutas que resulta imposible observarlas a simple vista, mientras que otras llaman poderosamente la atención.

Por lo general, las orquídeas florecen una sola vez al año, siempre por la misma época, la cual está determinada por factores ambientales tales como la disminución o elevación de la temperatura, el incremento de las horas de luz, los cambios de estación y las variaciones en la humedad ambiental. Las flores pueden permanecer abiertas desde un día (el caso de "Sobralia") hasta más de tres meses (como en "Paphiopedilum" y "Phalaenopsis"). Los híbridos artificiales pueden florecer dos o más veces al año.

El 97 % de las especies de orquídeas necesitan de un polinizador para que se lleve a cabo la transferencia de los granos de polen de una planta a los pistilos de otro individuo y, por ende, para que se produzca la fecundación y la formación de las semillas. Se debe tener en cuenta que el polen de las orquídeas se halla agrupado en masas compactas llamadas polinias (singular: polinario), de tal modo que por sí solo, o por acción del viento, el polen no se puede dispersar de una flor a otra por lo que los polinizadores son imprescindibles para asegurar su reproducción sexual.
Estos polinizadores son muy variados y, según cuál sea la especie en cuestión, pueden ser moscas, mosquitos, abejas, avispas, coleópteros y aves (especialmente colibríes).

La zoofilia que caracteriza a las orquídeas presupone que los animales polinizadores visiten las flores de manera regular y se detengan en ellas el tiempo suficiente; que las anteras y el estigma sean rozados o tocados con cierta frecuencia y que el primero quede adherido a los visitantes de modo tan perfecto que pueda llegar con la debida seguridad a los estigmas de otras flores. El resultado de la zoofilia depende esencialmente de que los animales puedan reconocer las flores desde una cierta distancia y de que se vean compelidos a visitar durante un cierto tiempo las flores de la misma especie. Las flores zoófilas, entonces, deben poseer "productos atractivos" (cebos, como el polen y el néctar), "medios de reclamo" (tales como olores y colores) y, además, "polen viscoso o adherente".

Muchas especies de orquídeas recompensan a los polinizadores con alimento (como por ejemplo, néctar, pelos alimenticios o aceites) y otros compuestos, tales como ceras, resinas y fragancias. Estas recompensas, a su vez, refuerzan la conducta de los polinizadores. No obstante, la especialización en un solo tipo de polinizador para asegurar una transferencia más eficiente de polen, determinó una creciente especialización morfológica y estructural en las flores de las orquídeas para garantizar la atracción de una sola especie de insecto.

Por esa razón, las flores de las orquídeas son de formas extremadamente variadas y pueden atraer a una amplia variedad de insectos (abejas, avispas, moscas, mariposas, polillas) así como a pájaros, murciélagos o sapos para la polinización. Algunas atraen visitantes generalistas, pero muchas están bastante especializadas, atrayendo sólo a una o unas pocas especies como polinizadores. Polen, néctar, o fragancias florales pueden ser empleadas como recompensadores de la polinización, mientras que algunas flores (por ejemplo "Cypripedium") manipulan a sus polinizadores y no proveen ninguna recompensa, y algunas especies de "Ophrys" y "Cryptostylis" mimetizan la forma y el olor de las hembras de abejas, avispas, o moscas, y son polinizadas cuando los machos tratan de aparearse con la flor (fenómeno llamado pseudocopulación).

Generalmente, el labelo funciona como una plataforma de aterrizaje y provee señales visuales o táctiles que orientan al polinizador. La polinia se adjunta al cuerpo del polinizador, y muchas veces es depositada en el estigma (usualmente una depresión en la parte de abajo de la columna) de la siguiente flor visitada. El género "Coryanthes" tiene un labelo como un bolsillo que se llena con un fluido secretado por la columna, una abeja que cae en este fluido debe viajar a través de un túnel, forzando la deposición del polinario en su cuerpo. La transferencia de polen dentro de la polinia es una aparente adaptación para asegurar la fertilización de muchos del tremendo número de óvulos. En algunas especies la polinización es un evento bastante poco común, y las flores pueden permanecer funcionales y vistosas por muchos días. El marchitamiento del perianto ocurre rápidamente solo después de la fertilización. "Angraecum sesquipedale", una orquídea de Madagascar, también es conocida por su biología de la polinización. Esta especie presenta un espolón de 20 a 35 cm de largo, y es polinizada por una mariposa esfíngida, "Xanthopan morganii praedicta" con una probóscide de esa longitud, un hecho que Charles Darwin había predicho antes del descubrimiento de tal polinizador.

En la mayoría de las especies las pequeñas semillas, que son como polvo, son dispersadas por el viento y requieren nutrientes provistos por un hongo micorrícico para poder germinar. Algunos miembros de Cypripedioideae y Vanilloideae poseen frutos carnosos que fermentan "in situ" liberando compuestos fragantes (por ejemplo la vainillina) que atraen a pájaros y mamíferos, que actúan como agentes de dispersión.

Estas semillas están formadas por un embrión constituido por pocas células (entre 100 y 200), cubiertas por una testa muy dura. El número de semillas puede variar de 13 000 a 4 000 000 por cápsula. El rango de peso de una semilla de orquídea varía de 0,3 a 14 µg y miden de 0,25 a 1,2 mm de largo y 0,009 a 0,27 mm de ancho. Estas semillas no poseen endosperma y consisten de un pequeño embrión suspendido dentro de una membrana, comúnmente transparente, aunque en ocasiones pigmentada. Las formas de las semillas pueden ser muy variables, existiendo elípticas, filiformes, fusiformes, redondas, globulares o prominentemente aladas. Todas estas características aparentemente maximizan la fecundidad y la efectividad en la dispersión por el viento de las semillas de orquídeas.
La germinación de estas semillas tiene lugar por medio de un proceso que es diferente al de la mayor parte de las angiospermas, porque los embriones de orquídeas son, desde un punto de vista anatómico y estructural, extremadamente reducidos y simples. Los embriones de orquídeas germinan y crecen hasta producir una masa de células llamada «protocormo». Estos protocormos, con sus «rizoides» (estructuras en forma de raíces) pueden o no de inmediato comenzar a fotosintetizar. No obstante, para que el protocormo sobreviva, se desarrolle y se transforme en retoño, primero debe establecer una relación simbiótica con un hongo.

El papel que desempeña el hongo es el de suministrar azúcares al protocormo (especialmente a aquellos que no poseen clorofila). El hongo obtiene el azúcar de secciones del substrato (suelo u otro objeto sólido que sirva de organismo huésped a la planta) de la orquídea, es decir, la corteza de un árbol o del suelo. El protocormo, a su vez, provee al hongo con ciertas vitaminas y un hábitat donde vivir. El hongo vive en área del protocormo y del substrato. Con el tiempo, el joven retoño comenzará a producir sus propios nutrientes y la simbiosis no será más necesaria.

Se han sugerido muchos orígenes posibles para las orquídeas, no obstante, la familia de las hipoxidáceas (o plantas similares a ellas, ya extintas) parecen ser sus progenitores más probables. A pesar de ser la familia de angiospermas más diversa sobre la tierra, las orquídeas no poseen un registro fósil adecuado por lo que muchos aspectos de su historia evolutiva permanecen oscuros. No obstante, en 2007 se ha informado el hallazgo en la República Dominicana del polinario de una orquídea (la que fue denominada "Meliorchis caribea") preservado en ámbar y adherido al mesoescutelo de una especie extinta de abeja "(Proplebeia dominicana"). Ese fósil proviene del Mioceno, aproximadamente 15 a 20 millones de años atrás. Este descubrimiento constituye no solo el primer fósil de orquídea descubierto sino también el primer antecedente fósil de las interacciones entre las plantas y sus polinizadores. Asimismo, este descubrimiento sumado a análisis cladísticos sobre datos de la morfología, indican que el ancestro más reciente de las orquídeas existentes vivió en el Cretácico superior, entre 76 a 84 millones de años atrás.
La monofilia de las orquídeas está sustentada tanto por la morfología como por los análisis de secuencias de ADN (Dressler 1981, 1993, Dressler y Chase 1995, Burns-Balogh y Funk 1986, Judd "et al." 1993, Chase "et al." 2000, Fay "et al." 2000, Freudenstein "et al." 2004). Asimismo, las relaciones filogenéticas dentro de la familia, motivo de activas investigaciones en las últimas décadas que todavía continúan, han sido dilucidadas mediante análisis cladísticos de la morfología y de secuencias conservadas del ADN (Dressler 1983, 1993, Chase 1986, 1988, Chase y Hills 1992, Chase y Palmer 1992, Cameron "et al." 1999, Kores "et al." 2000, Whitten "et al." 2000, Salazar "et al." 2003, Burns-Balogh y Funk 1986, Cameron 2006, Dressler 1986, 1993, Judd "et al." 1993, Dressler y Chase 1995, Cameron "et al." 1999, Freudenstein y Rasmussen 1999, Cameron y Chase 2000, Freudenstein "et al." 2000, 2004, Molvray "et al." 2000, van den Berg "et al." 2005).

La filogenia de las orquídeas se halla suficientemente aclarada en la actualidad, lo que permite la reconstrucción de los estados ancestrales y el análisis de la evolución de varios caracteres adaptativos novedosos, los que incluyen los síndromes de polinización altamente especializados, la colonización de hábitats epifíticos y la presencia de metabolismo ácido de las crasuláceas. El metabolismo ácido de las crasuláceas (conocido como CAM, acrónimo inglés para "Crassulacean Acid Metabolism") es una ruta fotosintética, muy distribuida taxonómicamente, la cual ha evolucionado en plantas que habitan ambientes con limitaciones de agua y de dióxido de carbono, los cuales incluyen el dosel de los bosques tropicales con disponiblidad hídrica estacional o intermitente. La fotosíntesis C3 es el estado ancestral de la familia y el metabolismo CAM ha evolucionado al menos diez veces de modo independiente, con varias reversiones al estado original. Un gran evento de radiación adaptativa hacia el metabolismo CAM ocurrió dentro de Epidendroideae, el clado con mayor riqueza de especies epífitas de todos los grupos de plantas conocidos, el cual estuvo ligado a la rápida evolución de una gran cantidad de especies durante el período Terciario. De hecho, se ha demostrado que existe una asociación muy estrecha entre el metabolismo CAM y el hábito epifítico, caracteres que habrían evolucionado paralelamente hace unos 65 millones de años, en correspondencia con la progresiva aridificación y reducción de la concentración de dióxido de carbono en la atmósfera durante el Terciario. Aparentemente, la riqueza de especies en las orquídeas está ligada a la colonización de hábitats epifíticos, y la capacidad para hacerlo estuvo relacionada con la adquisición del metabolismo CAM, como un medio de llevar a cabo la fotosíntesis con bajo consumo de agua. No obstante, el cambio del hábito de crecimiento terrestre al hábito epifítico no solo requiere del metabolismo CAM, sino también de la presencia de varios otros atributos adaptativos. Así la presencia de raíces finas, pequeñas y trepadoras es esencial para la adhesión a un sustrato con escasa estabilidad, como las ramas de los árboles. La suculencia y las raíces con velamen se requieren para soportar los períodos prolongados de deficiencia hídrica al estar fijadas a sustratos con escasa o nula capacidad de retención de agua. Finalmente, la densidad poblacional de los organismos epifíticos es en general muy baja, por lo que requieren de sistemas de polinización altamente especializados para lograr la transferencia eficiente del polen entre plantas diferentes. Todas estas adaptaciones morfológicas y fisiológicas se han desarrollado en las orquídeas en múltiples ocasiones, lo que ha determinado la gran riqueza de especies de esta familia y que casi el 70 % de las mismas sean epífitas.

Los géneros "Apostasía" y "Neuwiedia" (pertenecientes a la subfamilia Apostasioideae) son considerados hermanas del resto de los miembros de la familia (Dressler 1993, Judd "et al." 1993, Dressler y Chase 1995, Neyland y Urbatsch 1996, Cameron "et al." 1999, Freudenstein y Rasmussen 1999). Estos dos géneros, y especialmente "Neuwiedia", han retenido muchos caracteres ancestrales, como por ejemplo la presencia de dos ("Apostasia") o tres ("Neuwiedia") estambres en sus flores, los que están sólo ligeramente fusionados al estilo y los granos de polen, independientes entre sí y no pegajosos. Las restantes orquídeas, en cambio, presentan polen pegajoso o con los granos de polen fusionados entre sí en el momento en el que son liberados de los estambres. Dentro del grupo de orquídeas con polen pegajoso, las subfamilias Cypripedioideae y Vanilloideae son los clados basales. La primera de ellas (que incluye, por ejemplo, a "Cypripedium" y "Paphiopedilum") es claramente monofilética y sus miembros comparten algunos caracteres exclusivos, como su labelo en forma de saco (con la forma de una zapatilla) y la antera media modificada en un estaminodio con forma de escudo y dos estambres funcionales. Vanilloideae (que contiene por ejemplo a "Vanilla", "Pogonia" y "Cleistes") se distingue porque sus flores tienen sólo un estambre funcional y tampoco presentan polinias.

Las restantes subfamilias poseen un solo estambre funcional, los granos de polen se encuentran agrupados formando polinias y el filamento del estambre se encuentra completamente fusionado con el estilo (Dahlgren "et al." 1985, Burns-Balogh y Funk 1986, Judd "et al." 1993). Este clado, que incluye a todas las especies con polen agrupado en polinias, tiene flores con solo un estambre funcional (se dicen monandras) y los dos estambres laterales están transformados en esbeltos estaminodios o faltan completamente).

Los análisis de morfología (Freudenstein y Rasmussen 1999) y algunos análisis moleculares (Cameron "et al." 1999, Molvray "et al." 2000) indican que las orquídeas monandras son monofiléticas, No obstante, otros análisis moleculares (Cameron 2006, Cameron y Chase 2000, Freudenstein "et al." 2004), sostienen que la reducción del número de estambres funcionales ha ocurrido en dos oportunidades durante la evolución de la familia.
Entre las orquídeas monandras con polinia se reconocen dos grandes subfamilias, Epidendroideae y Orchidoideae (incluyendo Spiranthoideae). Los miembros de Epidendroideae comparten la apomorfía de presentar una antera picuda e incumbente (es decir, la antera se halla curvada sobre el ápice de la columna), mientras que los integrantes de Orchidoideae comparten las apomorfías de un ápice de la antera agudo, tallos suaves y hojas convolutas.
El árbol filogenético de las subfamilias es el que sigue (Judd "et al." 2007, modificado de Cameron "et al." 1999, Kocyan "et al." 2004):

Algunos autores, como por ejemplo Dahlgren "et al." (1985), reconocieron tres familias de orquídeas basándose en el número de anteras del androceo: Apostasiaceae, con dos o tres anteras sólo parcialmente fusionadas al gineceo; Cypripediaceae, con dos anteras fusionadas al gineceo y Orchidaceae, la familia más rica en cantidad de especies, las cuales presentan una única antera fusionada al gineceo. No obstante, todas las evidencias moleculares hasta la fecha muestran que Orchidaceae definida o circunscripta de ese modo sería polifilética. Los datos morfológicos y moleculares indican, en cambio, que Orchidaceae debería definirse en forma amplia, por lo que una nueva clasificación de la familia que se corresponde con la filogenia conocida fue publicada por Chase y colaboradores en 2003, en la que se reconocen cinco subfamilias, las que se describen a continuación:

Las orquídeas apostasioides se consideran el grupo de orquídeas más primitivo. Presentan dos o tres estambres en sus flores, las cuales son «regulares» y se parecen a las del género "Hypoxis" (de la familia Hypoxidaceae). Las hojas se disponen en forma espiralada en los tallos, son plegadas, resupinadas (salvo en "Apostasia"). El saco embrionario es bispórico, del tipo "Allium". El número cromosómico básico es x= 24. Incluye solo dos géneros ("Apostasia" y "Neuwiedia") y aproximadamente 16 especies.

Sinonimia: Apostasiaceae Lindley, Neuwiediaceae Reveal & Hoogland.

Este segundo grupo de orquídeas representan un linaje independiente, con categoría taxonómica de subfamilia: las cipripedióideas. También retienen características primitivas, tales como la presencia de dos estambres en las flores. Comprende cinco géneros: "Cypripedium", "Mexipedium, Paphiopedilum, Phragmipedium" y "Selenipedium" y cerca de 150 especies, las cuales se distribuyen en cinco tribus monotípicas.
Están ampliamente distribuidas en Eurasia y a través de América.

Conocidas popularmente como «zapatillas de dama» debido a la abultada forma de zapatilla de su labelo que funciona como atrapa insectos, ya que el insecto es forzado a pasar con la espalda por el estaminodio, con lo que se recolectan o depositan los polinia.
En estas orquídeas, dos anteras fértiles se disponen a cada lado de la columna. El estambre central es estéril y está curiosamente modificado como un escudo que impide el acceso directo de los polinizadores desde del frente de la flor a la parte central. Los otros dos estambres están escondidos detrás de este estaminodio. El labelo saculiforme ha evolucionado como una trampa para los polinizadores. Las paredes internas del labelo son muy resbalosas pero una escalera de pelos yace en el interior de la pared dorsal. Este conduce bajo el estigma ventral a una de las dos salidas en la base del labelo a cada lado de la columna.

Sinonimia: Cypripediaceae Lindley.

Las orquídeas vanilóideas son un pequeño grupo que incluye a "Vanilla", un género de aproximadamente 70 especies de lianas. Comprende 15 géneros y 180 especies que se distribuyen en la franja tropical y subtropical húmeda del globo y en los Estados Unidos de América.

Esta subfamilia incluye en su mayoría orquídeas terrestres con tubérculos o rizomas carnosos. El género tipo "Orchis" y las "orquídeas abeja" "(Ophrys", que se denominan así porque su labelo parece el abdomen de una abeja) pertenecen a este grupo. Comprende 208 géneros y 3630 especies distribuidas en todo el mundo, excepto en los desiertos más secos, en el círculo polar Ártico y en la Antártida. Los miembros representativos de Orchidoideae incluyen a "Cynorkis, Diuris, Goodyera, Habenaria, Orchis, Platanthera, Spiranthes, "y" Zeuxine".

Más de 500 géneros y cerca de 20 000 especies distribuidas en las mismas regiones de Orchidoideae, si bien incluyen algunas especies subterráneas del desierto australiano. Epidendroideae contiene numerosas epífitas tropicales, entre los géneros representativos se incluyen "Bulbophyllum, Catasetum, Dendrobium, Epidendrum, Encyclia, Maxillaria, Oncidium, Pleurothallis" y "Vanda". La delimitación de los géneros en este grupo es notoriamente problemática, y los géneros más numerosos no son monofiléticos. La mayoría son epífitas tropicales (normalmente con pseudobulbos), pero algunas son terrestres e incluso unas pocas saprofitas.

Tradicionalmente las orquídeas han sido utilizadas por distintos pueblos con fines ornamentales y medicinales. Los chinos fueron los primeros en cultivarlas desde, aproximadamente, el año 500 a. C. Más tarde, en el siglo V, los griegos las empleaban como plantas medicinales. En América, los aztecas las utilizaban como plantas medicinales, especias, alimenticias y ornamentales. Una de las orquídeas empleadas por este pueblo fue la popular vainilla («tlilxóchitl» en náhuatl, nombre científico, "Vanilla planifolia"), usada para aromatizar el chocolate, y llevada a Europa por los conquistadores españoles a principios del siglo XVI y desde ahí a regiones tropicales como Madagascar. Este país se ha convertido en el primer productor del mundo de esta especia, utilizada como saborizante y aromatizante en todo el mundo.

A pesar de la gran diversidad de la familia, pocas orquídeas son cultivadas por otra razón que no sea la belleza de sus flores. Además del ya mencionado cultivo de "Vanilla" para producir vanillina, algunas pocas especies se utilizan para la producción de aromatizantes del té "(Jumellea") o del tabaco "(Vanilla"). En Turquía se utilizan los tubérculos de "Anacamptis morio" para la preparación de una bebida típica caliente que se bebe en los días fríos del invierno conocida como salep.

El cultivo de las orquídeas por la belleza de sus flores evolucionó lentamente desde un simple pasatiempo hasta la explotación comercial. Las primeras orquídeas ornamentales llegaron a Europa, procedentes del Nuevo Mundo, en 1731. Sin embargo, no fue sino hasta 1821 cuando se inició su cultivo comercial en invernaderos cerca de Londres. Para 1913 se inauguró en Singapur la compañía «Sun Kee» para producir y comercializar flores cortadas de orquídeas. Actualmente, en Estados Unidos, Inglaterra, Francia, Taiwán, Japón, China, Tailandia, Australia, Hawái y Singapur se ha profundizado el interés por el cultivo y la explotación de orquídeas, con dos objetivos definidos. El primero es el de la producción de flor cortada para abastecer el mercado internacional de floricultura. El segundo objetivo es el de producir y comercializar plantas de diferentes tamaños, en particular las que se hallan cerca de la floración, para abastecer de plantas ornamentales el mercado interno de cada país.

Tailandia es uno de los países más especializados en la producción de flores de orquídeas para abastecer la demanda de las principales ciudades alrededor del mundo, con un monto de exportaciones de 40 millones de dólares para el año 2001.

Entre los géneros de orquídeas más comúnmente cultivados para flor de corte o como plantas ornamentales se destacan "Cattleya", "Dendrobium", "Epidendrum", "Paphiopedilum", "Phalaenopsis", "Vanda", "Brassia", "Cymbidium", "Laelia", "Miltonia", "Oncidium", "Encyclia" y "Coelogyne". No obstante, la mayor proporción de cultivares actuales de orquídeas (los que se cuentan por más de 100 000) han surgido a través de hibridaciones artificiales entre dos o más especies, muchas veces de distintos géneros.

El método más simple de multiplicación, a menudo utilizado por los coleccionistas y por los comerciantes de pequeña escala, es la división del tallo. En varias especies de orquídeas, como las pertenecientes al género "Dendrobium", el pseudobulbo es largo y articulado, está formado por muchos nudos en los cuales se desarrollan hijuelos. Desde la base de estos hijuelos se desarrollan raíces. Para multiplicar este tipo de orquídeas, entonces, solo se deben cortar los hijuelos enraizados, separarlos de la planta madre y trasplantarlos a otro recipiente. Las especies de orquídeas de mayor importancia comercial, tales como "Cattleya", "Laelia", "Miltonia" y "Odontoglossum", pueden propagarse por división del rizoma en secciones, las que deben llevar de tres a cuatro pseudobulbos.
Los denominados «bulbos traseros», aquellos que ya han perdido el follaje, se usan comúnmente para propagar clones de "Cymbidium". Estos bulbos se remueven de la planta y se colocan en otro recipiente con un sustrato adecuado para que formen raíces.

Luz sí, pero no sol directo, la temperatura entre 18 y 25 °C., nunca inferior a 16 °C. pues moriría.

El riego debe ser una vez a la semana, se coloca la maceta en un plato y se llena el éste de agua, después de un rato hay que quitarlo, pues las raíces se pudrirán.

Se abona una vez al mes, siguiendo las mismas instrucciones que para el riego, es decir, diluyes el abono en el agua del plato y al rato cuando haya absorbido toda la humedad que necesita lo retiras.

Para conseguir una mayor y mejor floración: cuando las flores se secan, hay que cortar por encima de la tercera yema (nodo), y en pocos meses volverá a brotar con más vigor.

La maceta, como en todas las plantas, se cambia cuando empiezan a asomar por debajo las raíces, esa es señal de que ya no le queda tierra, ni sitio para las raíces.

Debido a la gran cantidad de semillas que se producen en cada fruto y a la posibilidad de cultivar los meristemas "in vitro", las orquídeas también pueden ser multiplicadas a gran escala.

Las semillas de las orquídeas son muy pequeñas y las que se hallan en un solo fruto pueden generar miles de nuevas plantas, cada una con características diferente de la otra. No obstante, las semillas contienen escasas reservas y no pueden germinar con sus propios recursos. De hecho, en la naturaleza deben asociarse a un hongo durante la germinación, el cual le provee los nutrientes que requiere para su crecimiento y desarrollo. Por esta razón, la manera más simple —si bien la menos eficiente— de multiplicar orquídeas a través de semillas consiste en esparcir las semillas sobre y alrededor de las raíces de orquídeas cultivadas en maceta y asegurarse de que tengan humedad constante en el sustrato. Las semillas germinan en unas semanas y crecen muy lentamente, de manera que una planta obtenida de este modo florece por primera vez cuando alcanza de cinco a diez años. Este proceso se denomina «germinación simbiótica» y, hasta 1922, era el único método de propagación de orquídeas a través de semillas. En ese año Lewis Knudson de la Universidad Cornell publicó un trabajo en el que describía un método artificial para hacer germinar a las orquídeas sin la participación de un hongo. Este método, llamado de «germinación asimbiótica», hace uso de técnicas de micropropagación para lograr la germinación y establecimiento de las plántulas en un medio de cultivo artificial y bajo condiciones estériles.

La reproducción a través del cultivo in vitro de meristemas, o clonación, es más eficiente y consiste en quitar la punta de la raíz o el extremo de un brote, situarlo en un medio de cultivo adecuado bajo condiciones estériles. Bajo la influencia de los fitohormona los meristemas se convierten en una masa de tejido indiferenciado, capaces de dar lugar a nuevas plántulas. Las plántulas así obtenidas se separan unas de otras y se cultivan en tubos de ensayo independientes. Las plantas son clones perfectos de la planta original, por lo que éste es el método más aplicable a la propagación masiva de una variedad particular o de híbridos estériles.






</doc>
<doc id="2063" url="https://es.wikipedia.org/wiki?curid=2063" title="Ontogenia">
Ontogenia

La ontogenia (también llamada morfogénesis u «ontogénesis») describe el desarrollo de un organismo, desde la fecundación de un cigoto durante reproducción sexual hasta su senescencia, pasando por la forma adulta. La ontogenia es estudiada por la biología del desarrollo. «La ontogenia es la historia del cambio estructural de una unidad sin que ésta pierda su organización. Este continuo cambio estructural se da en la unidad, en cada momento, o como un cambio desencadenado por interacciones provenientes del medio donde se encuentre o como resultado de su dinámica interna».

El desarrollo animal u ontogenia cumple dos funciones principales:

La fecundación es la unión de dos gametos con la consiguiente formación de un cigoto. Los gametos pueden ser iguales (isogametos) o distintos (anisogametos: espermatozoide y óvulo). El proceso central de la fecundación es la cariogamia, es decir, la fusión de los núcleos de los gametos (pronúcleos).

La activación es el conjunto de fenómenos que tienen lugar en el cigoto y que determinan que éste empiece a segmentarse (dividirse por mitosis).

La embriogénesis es el conjunto de procesos ontogenéticos que abarca desde que el cigoto comienza a segmentarse hasta que se consuma la organogénesis. La embriogénesis incluye las siguientes fases: segmentación, blastulación gastrulación y organogénesis.





En el cigoto existe una región del citoplasma (plasma germinal) que da lugar a las células precursoras de los gametos. Dichas células precursoras se denominan células germinales. Todas las demás células se conocen como células somáticas. Las células germinales migran hacia las gónadas, donde acaban diferenciándose en gametos. Esta diferenciación que se conoce como gametogénesis se produce en general cuando el animal está físicamente maduro.

La embriogénesis culmina con la formación de un embrión que, seguidamente, puede pasar por fases ontogenéticas diversas (feto, larva, pupa, juvenil) hasta llegar a adulto.

El ciclo vital de las especies animales se completa con la reproducción, el envejecimiento (senectud) y la muerte.

La segmentación del cigoto depende en gran manera de la distribución del vitelo (material de reserva) en el óvulo (huevo) y, por tanto en el propio cigoto (óvulo fecundado o huevo). Al margen de ello, la cantidad de vitelo está correlacionada con la duración de la embriogénesis. Si existe poco vitelo, el embrión o bien se convierte pronto en una larva capaz de alimentarse por sí misma, o bien ha de recibir un aporte de nutrientes por parte de la madre. Si existe gran cantidad de vitelo, el embrión se convierte en un individuo juvenil a base de alimentarse exclusivamente del vitelo.

Existen numerosos términos que describen la condición del huevo en función de la cantidad y de la disposición del vitelo:


Según afecte a la totalidad o solamente a una parte del cigoto, se distingue entre segmentación total y segmentación parcial.

La segmentación total (holoblástica) se da en cigotos formados a partir de huevos alecitos, oligolecitos y mesolecitos. El cigoto se divide por completo en dos blastomeros que, luego, dan lugar a más blastómeros.
La segmentación parcial (meroblástica) se da en cigotos formados a partir de huevos centrolecitos y telolecitos. El cigoto no se divide por completo; solamente se divide el núcleo celular. Los núcleos resultantes se rodean de membranas, formándose blastómeros. El vitelo permanece indiviso.

En la segmentación total se distinguen distintas modalidades en función del tamaño y de la disposición de los blastómeros.



En la segmentación parcial se distinguen distintas modalidades según se distribuya el vitelo en el óvulo a partir del que se forma el cigoto.

Segmentación parcial de los cigotos formados a partir de huevos telolecitos: segmentación discoidal.
En la segmentación discoidal, el cigoto no se divide por completo; sólo se divide el núcleo celular. Los dos núcleos resultantes se rodean de sendas membranas celulares. Se forman así dos pequeños blastómeros que se siguen dividiendo, mientras que la parte que contien el vitelo permanece indivisa. Los blastómeros ocupan el polo animal, formando un disco (blastodermo o blastodisco) que queda situado sobre la gran masa no segmentada de vitelo. Esta masa de vitelo constituye el saco vitelino. 

Segmentación parcial de los cigotos formados a partir de huevos centrolecitos: segmentación periféfica.
En la segmentación periférica, el núcleo celular se divide varias veces. Los núcleos resultantes migran hacia la periferia, donde cada uno se rodea de una membrana, formándose un blastómero. Así, los blastómeros ocupan la periferia (blastodermo periférico) y rodean el vitelo, indiviso, que ocupa una posición central. Uno o varios núcleos migran hacia uno de los polos para formar un conjunto de blastómeros que se conoce como plasma polar. Estos blastómeros del plasma polar son los precursores de las células germinales. 

Las distintas modalidades de segmentación no están necesariamente correlacionadas con la posición filogenética de los animales. Es frecuente que las especies correspondientes a un determinado grupo zoológico presenten la misma modalidad de segmentación. Sin embargo, también pueden presentarse modalidades distintas dentro de un mismo grupo. Al margen de ello, existen variantes propias de determinados grupos animales que no se corresponden con ninguno de los modelos de segmentación expuestos.

La segmentación del cigoto concluye con la formación de la blástula. El proceso de formación de la blástula se denomina blastulación.
Con frecuencia se describe la blástula como un estado embrionario constituido por una esfera de blastómeros (blastodermo) que rodea una cavidad central (blastocele), llena de líquido blastocélico. Sin embargo, esta descripción corresponde sólo a un determinado tipo de blástula.
Otras blástulas difieren notablemente de este modelo.

Principales tipos de blástula:





La gastrulación consiste en el conjunto de procesos morfogenéticos que se producen a partir del estadio de blástula y que conducen a la formación de las hojas blastodérmicas u hojas germinativas. La gastrulación difiere notablemente de unos grupos zoológicos a otros. Incluso puede diferir entre los representantes de un mismo grupo.





Otras modalidades de gastrulación, menos frecuentes, que se asemejan en mayor o menor grado a la gastrulación por inmigración son las siguientes: involución, separación, ingresión polar, proliferación y cavitación.

La idea de que la ontogenia recapitula la filogenia, esto es, que el desarrollo de un organismo refleje exactamente el desarrollo evolutivo de la especie, está hoy desacreditada. No obstante, se pueden observar algunas conexiones entre ontogenia y filogenia, dadas por la evolución, de esta forma la ontogenia se utiliza en cladística como guía para reconstruir la historia evolutiva y las relaciones filogenéticas entre clados.



</doc>
<doc id="2065" url="https://es.wikipedia.org/wiki?curid=2065" title="Opegrapha">
Opegrapha

Líquenes formados por la asociación de un ascomiceto con fitobionte, presentan apotecios lirelinos, no situados en una desgarradura, con reborde propio o paratecio, córtex ausente o muy reducido, paráfisis ramificadas.


</doc>
<doc id="2066" url="https://es.wikipedia.org/wiki?curid=2066" title="Olivares">
Olivares

Olivares es un municipio español de la provincia de Sevilla, Andalucía, España. Se encuentra dentro de la comarca del Aljarafe. Está a orillas del río Agrio, afluente del río Guadiamar.

Se encuentra situada a una altitud de 169 metros y a 16 kilómetros de la capital de provincia, Sevilla. 

El número de habitantes de 2007 a 2016 fue de:

Tras la conquista romana de la provincia Bética por Turculus se fundó donde actualmente se encuentra Olivares una villa romana llamada Estercolines o Estercolinas. Dentro del término municipal está montículo conocido como cerro de la Cabeza, donde debió de haber una ciudad romana de relativa importancia construida en los tiempos de César Augusto. El comercio y la comunicación con otras culturas se realizaba a través del río "Maenoba", hoy conocido como Guadiamar. También dentro del término existen restos de un acueducto romano desde el que se llevaba agua desde la desaparecida ciudad de Tejada hasta Itálica.

De la época musulmana se conserva una torre defensiva del siglo XII junto a la carretera Olivares-Gerena, conocida como torre de San Antonio, por ser ese el nombre de la finca donde está. Es una torre mocha (sin almenas) de tres pisos de planta cuadrada, con ventanas en los cuatro muros en el tercer piso.

En el siglo XIII, las tierras donde se encuentra este municipio fueron donadas por el rey Fernando III a los infantes Manuel y Fadrique. En 1356 estos terrenos figuran como propiedad de Álvaro Pérez de Guzmán con el nombre de Estercolinas. Estercolinas y el vecino Heliche figuran en 1484 como del Guzmán que era duque de Medina-Sidonia. El cuarto hijo de este duque fue Pedro de Guzmán, nacido en Sevilla en 1503. Sirvió a a Carlos I en los combates de Alemania, Flandes, Austria y Túnez. El 15 de octubre de 1535 Carlos I nombró a Pedro de Guzmán conde de Olivares. Tras un pleito con su hermano, Juan Alonso de Guzmán, fundó su mayorazgo en Estercolinas, y cambió el nombre al lugar por Olivares. En 1538 Pedro de Guzmán compró las villas de Heliche, Castilleja de Alcántara y Castilleja de la Cuesta. 

En 1539 Pedro se casó con Francisca Ribera Niño y, aunque vivían en Madrid, tenían varias casas en la provincia de Sevilla. A mediados del siglo XVI, el I conde de Olivares construyó su palacio en el pueblo. Este palacio es de estilo renacentista. Subsisten la portada principal, de mármol, el patio principal con columnas y el escudo en la fachada.

En Olivares había una ermita dedicada a la Virgen del Álamo, que era la patrona del pueblo, y que puede datar del siglo XIV (aunque una leyenda dice que fue encontrada en 1247 en el hueco de un álamo). Desde 1653 esta Virgen se encuentra en una capilla en el lado izquierdo del presbiterio de la colegiata de Santa María de las Nieves.

Enrique de Guzmán y Ribera, II conde de Olivares, fue embajador de España en Roma, y en 1590 recibió una bula del papa Gregorio XIII para crear una capilla en Olivares, que fue dotada de doce capellanes y un capellán mayor.

El III conde de Olivares y I duque de Sanlúcar la Mayor, Gaspar de Guzmán y Pimentel, fue valido del rey Felipe IV. Heredó el condado en 1607. En 1623 le fue concedida una bula del papa Urbano VII que elevaba el rango de la capilla a colegiata. El encargado de la colegiata pasó a ser un abad mayor mitrado, que tenía autoridad canónica en Olivares, Heliche, Albaida del Aljarafe, Sanlúcar la Mayor, Castilleja de Guzmán y parte de Castilleja de la Cuesta.

El cercano poblado llamado Heliche fue despoblado en 1817 y su parroquia, la de San Benito, subsistió hasta 1843.

Posee 2.884 ha de cultivos herbáceos, de las cuales 61 ha son de trigo y 1.305 de girasoles. Hay 854 ha de cultivos leñosos, de las cuales 646 ha son de olivares de aceituna de mesa.

Cerca hay una estación de tren de la línea de cercanías C-5, la estación de Villanueva del Ariscal-Olivares.

Desde el año 2002 se celebra en Olivares una feria del barroco, con trajes y tenderetes inspirados en los siglos XVII y XVIII.





</doc>
<doc id="2067" url="https://es.wikipedia.org/wiki?curid=2067" title="Ornitología">
Ornitología

La ornitología (del griego "ὄρνις - ὄρνιθος", ""ornis" - "ornithos"", "pájaro" y λόγος ""logos"", "estudio o ciencia") es la rama de la zoología que se dedica al estudio de las aves. Numerosos aspectos de la ornitología difieren de las disciplinas relacionadas, debido en parte a la alta visibilidad y el atractivo estético de las aves. Una de las diferencias más notables es la importancia y cantidad de estudios llevados a cabo por aficionados que trabajan dentro de los parámetros de la metodología científica.

La ciencia de la ornitología tiene una larga historia, y el estudio de las aves ha ayudado a desarrollar numerosos conceptos claves en evolución, comportamiento y ecología, como los de especie; procesos de especiación; instinto; aprendizaje; nicho ecológico; biogeografía insular; filogeografía; y conservación. Mientras que en sus comienzos la ornitología se ocupaba principalmente de la descripción y distribución de las especies, los ornitólogos de hoy en día buscan respuestas a cuestiones muy específicas, a menudo usando a las aves como modelos para probar hipótesis o predicciones basadas en teorías. La mayor parte de las teoría biológicas modernas se aplican indiferentemente entre los distintos grupos taxonómicos, y por lo tanto el número de científicos profesionales que se identifican a si mismos como ornitólogos se ha reducido. El abanico de herramientas y técnicas que se usan en la ornitología es muy amplio, y constantemente se realizan innovaciones.

La historia de la ornitología refleja en buena medida las tendencias de lo ocurrido en la historia de la biología. Estas tendencias incluyen el paso de las meras descripciones a la identificación de modelos, y posteriormente hacia el estudio de los procesos que producen esos modelos.

Los humanos han observado a las aves desde el comienzo de los tiempos; algunos dibujos de la Edad de Piedra, están entre las muestras más antiguas del interés del hombre en las aves. En esa época las aves quizás fueron una importante fuente de comida, y los huesos de hasta ochenta especies se han encontrado en excavaciones de asentamientos de la Edad de Piedra.

Culturas de todo el mundo tienen ricos vocabularios referidos a las aves. Los nombres tradicionales de las aves están a menudo basados en un conocimiento detallado de su comportamiento, siendo muchos nombres onomatopéyicos, y estando otros muchos todavía en uso. El saber popular puede también involucrar el uso de las aves en la medicina tradicional, y el conocimiento de estas prácticas son transmitidas como tradición oral. La caza de aves silvestres, así como su domesticación también debe haber requerido un considerable conocimiento de sus hábitos. La cría de aves de corral y la cetrería se han practicado desde tiempos pretéritos en muchas partes del mundo. La incubación artificial de aves de corral se practicaba en China hacia el 246 a. C. y en Egipto en torno al 400 a. C. Los egipcios también representaron a las aves en sus jeroglíficos, muchos de los cuales, aunque simplificados, permiten la identificación de la especie.

Los primeros registros escritos proveen una valiosa información sobre las antiguas distribuciones de las especies. Por ejemplo, los escritos de Jenofonte mencionan la abundancia de avestruces en Asiria; esta subespecie de Asia menor está extinta, y la distribución del avestruz restringida a África. Otros antiguos escritos contienen cuidadosas y detalladas descripciones de la vida de las aves, como en los "Vedas" (1500-800 a. C.) donde se incluye la primera referencia a parasitismo de puesta, por parte del koel común ("Eudynamys scolopacea"). Al igual que en la literatura, en las pinturas de las antiguas civilizaciones de China, Japón, Persia e India también se demuestra un gran conocimiento de las aves, con detalladas y muy precisas ilustraciones de diferentes especies.

Aristóteles en el 350 a. C. en su obra "Historia Animalium" escribió sobre los hábitos de la migración de las aves, su muda, incubación y duración de sus vidas. El, sin embargo, introdujo y propago numerosos mitos, como la idea de que las golondrinas hibernaban a pesar de que había notado que las grullas comunes migraban desde la estepas de Escitia hacia la desembocadura del Nilo. La idea de la hibernación de las golondrinas llegó a estar tan bien establecida, que en 1878, Elliott Coues, pudo listar hasta 182 publicaciones de ese momento que daban por supuesto la hibernación de las golondrinas, mientras que muy pocas publicaban evidencias que contradijeran la teoría. Parecidos errores existieron en lo referente a la cría de la barnacla cariblanca. Sus nidos no habían sido vistos nunca y se creó que crecían por la transformación de los crustáceos del orden Pedunculata, una idea que se convirtió en frecuente en tono al siglo XI, y mencionada por el obispo Giraldus Cambrensis en su obra "Topographia Hiberniae" (1187).

El origen de la cetrería se localizan en Mesopotamia, con sus primeros registros datados en el reino de Sargón II (722–705 a. C.). La cetrería hizo su entrada en Europa solo después del 400 d. C. a través de las invasiones de hunos y alanos provenientes del este. Federico II de Alemania (1194 – 1250) aprendió sobre la cetrería árabe durante las guerras en la región, y consiguió un tratado árabe de cetrería de Moamín. Logró que esta obra se tradujera al latín y también llevó a cabo experimentos con las aves de su colección privada de animales. Cegando a unos buitres y poniéndoles comida cerca, dedujo que encontraban su alimento gracias a su vista y no por el olfato. También desarrolló métodos para mantener y entrenar halcones. Los estudios que llevó a cabo durante cerca de 30 años, fueron publicados en 1240 bajo el nombre de "De arte venandi cum avibus" ("El arte de cazar con aves"), obra que es considerada uno de los primeros estudios sobre el comportamiento de las aves.

Numerosos eruditos alemanes y franceses compilaron los viejos trabajos y realizaron nuevos descubrimientos sobre las aves. Entre estos se incluye Guillaume Rondelet que escribió acerca de sus observaciones en el Mediterráneo; y Pierre Belon que describió los peces y aves que había visto en Francia y el Levante mediterráneo. Su obra "L'Histoire de la nature des oyseaux" contiene descripciones de cerca de doscientas especies. Su comparación entre el esqueleto de los humanos y de las aves es considerada un hito en la evolución de la anatomía comparada. Volcher Coiter (1534-1576), un anatomista holandés, hizo estudios detallados de la estructura interna de las aves y realizó una clasificación de las aves, "De Diferentiis Avium" (en torno a 1572), que se basaba en criterios de estructura y hábitos. Konrad Gesner escribió las obras "Vogelbuch" e "Icones avium omnium" alrededor de 1557. Como Gesner, Ulisse Aldrovandi, un naturalista, publicó entre 1599 y 1603 una obra de 14 volúmenes sobre historia natural, de los que tres de ellos eran sobre aves. Su "Ornithologiae" sola tiene más de 2.000 páginas e incluye aspectos como la cría de gallinas y otras aves de corral. La obra de William Turner "Historia Avium" ("Historia de las Aves") publicada en Colonia en 1544 fue uno de los primeros trabajos ornitológicos ingleses. Advirtió lo frecuente de los milanos reales en las ciudades inglesas, donde arrebataban la comida de las manos de los niños. Trató creencias populares como la de los pescadores que creían que las águilas pescadoras acababan con sus bancos de peces, por lo que buscaban matarlas mezclando en sus cebos la carne de las águilas.

En el siglo XVI Francis Willughby (1635-1672) y John Ray (1627-1705) realizaron los primeros grandes sistemas de clasificación de las aves basadas en sus funciones y morfología en vez de su forma o comportamiento. "Ornithologiae libri tres" (1676) de Willughby y completada por Ray, se considera en ocasiones el comienzo de la ornitología científica. Ray también publicó otra obra, "Ornithologia", que fue publicada póstumamente en 1713 bajo el nombre de "Synopsis methodica avium et piscium". La primera lista de aves inglesas, "Pinax Rerum Naturalium Britannicarum", fue escrita por Christopher Merrett en 1667, sin embargo para muchos (incluyendo a Ray) no tenía mucho valor.

Hacia el final del siglo XVIII, Mathurin Jacques Brisson (1723-1806) y Georges Louis Leclerc (1707-1788) realizaron nuevos trabajos sobre aves. Brssion publicó una obra, "Ornithologie", de seis volúmenes en 1760 y Leclerc incluyó nueve volúmenes sobre aves ("Histoire naturelle des oiseaux" (1770-1785)) en su trabajo "Histoire naturelle générale et particulière" (1749-1804). Coenraad Jacob Temminck (1778 - 1858) patrocinó a François Le Vaillant (1753-1824) para que recolectara especímenes de aves en África, lo que al final resultó en la publicación de "Histoire naturelle des oiseaux d'Afrique" (1796-1808), de seis volúmenes de Le Vaillant.
Louis Jean Pierre Vieillot (1748-1831) pasó diez años estudiando las aves norteamericanas y escribió la "Histoire naturelle des oiseaux de l'Amerique septentrionale". Vieillot fue pionero en el uso de la historia natural y los hábitos en la clasificación.

La ornitología emerge como una ciencia especializada recién en la era victoriana—con la proliferación de las armas de fuego, del concepto de historia natural, y las colecciones de objetos naturales como huevos de aves y pieles.Esta especialización dio lugar a la formación en Gran Bretaña de la British Ornithologists' Union en 1858. En 1859 los miembros formaron su revista "The Ibis". La surgencia súbita en el interés por la ornitología se debió también a la colonización. Cien años después, en 1959, R. E. Moreau observó que la ornitología en este periodo se preocupaba de las distribuciones geográficas de varias especies de aves.
Los coleccionistas de aves de la era victoriana observaron las variaciones en las formas de las aves y sus hábitos a lo largo de las regiones, notaron la especialización local y la variación en especies de amplia distribución. Las colecciones de museos y los coleccionistas privados crecieron con contribuciones de varias partes del mundo. La denominación de especies con el sistema binominal y la organización de aves en grupos basados en sus similitudes se volvió el trabajo principal de los especialistas de museos. Las variaciones en las aves de amplia distribución a lo largo de regiones geográficas causó la introducción de denominaciones trinominales.
La búsqueda de patrones en las variaciones de las aves fue intentada por muchos. Los primeros ornitólogos como William Swainson siguieron el sistema quinario y este fue remplazado por "mapas" más complejos de afinidades en trabajos por Hugh Edwin Strickland y Alfred Russel Wallace
Se cree que los pinzones de las Galápagos fueron de una influencia especial en el desarrollo de la teoría de la evolución de Charles Darwin. Su contemporáneo Alfred Russel Wallace también notó estas variaciones y las separaciones geográficas entre las diferentes formas que dieron lugar al estudio de la biogeografía. Wallace fue influenciado por el trabajo de Philip Lutley Sclater sobre los patrones de distribución de las aves.

Para Darwin, el problema fue cómo las especies surgieron de un ancestro común, pero él no intentó encontrar reglas de delimitación de especies. El problema de las especies, fue abordado por el ornitólogo Ernst Mayr. Mayr fue capaz de demostrar que el aislamiento geográfico y la acumulación de diferencias genéticas dio lugar a la división de especies.

Los primeros ornitólogos se preocupaban con asuntos de identificación de especies. Sólo las sistemática se consideraba como verdadera ciencia y los estudios de campo eran tenidos por inferiores a lo largo de buena parte del siglo XIX. En 1901 Robert Ridgway escribió en la introducción de "The Birds of North and Middle America" que:

Esta idea inicial de que el estudio de las "aves vivientes" era meramente recreación se mantuvo dominante hasta que las teorías ecológicas se hicieron el foco predominante de los estudios ornitológicos. El estudio de las aves en sus hábitats fue avanzado particularmente en Alemania con las estaciones de anillamiento de aves establecidas ya en 1903. Hacia la década de 1920 la revista "Journal für Ornithologie" incluyó muchos trabajos sobre comportamiento, ecología, anatomía y fisiología, muchos escritos por Erwin Stresemann. Stresemann. cambió la política editorial de la revista, dirigida tanto a la unificación de los estudios de campo y de laboratorio, como a un cambio del lugar de investigación, de los museos a las universidades. La ornitología en los Estados Unidos continuó siendo dominada por estudios de museo de variaciones morfológicas, identidad y distribución geográfica de especies, hasta que fue influenciada por el estudiante de Stresemann, Ernst Mayr. En Gran Bretaña, algunos de los primeros trabajos ornitológicos que usaron la palabra ecología aparecieron en 1915. "The Ibis" sin embargo resistió la introducción de estos nuevos métodos de estudio y recién en 1943 publicó trabajos sobre ecología. El trabajo de David Lack sobre ecología poblacional fue pionero. Enfoques más nuevos se introdujeron para el estudio de la ecología y el comportamiento y estos no fueron bien aceptados. Por ejemplo, Claud Ticehurst escribió:

Los estudios de David Lack sobre ecología poblacional buscaron encontrar el proceso involucrado en la regulación de la población basado en la evolución de tamaños de nidada óptimos. Él concluyó que la población estaba regulada primariamente por controles dependientes de densidad y también sugirió que la selección natural produce rasgos de historia de vida que maximizan la adaptación de individuos. Otros como Wynne-Edwards interpretaron la regulación de la población como un mecanismo que ayudaba a la "especie" envés de a los individuos. Esto llevó a un debate amplio y a veces enconado sobre que constituía la "unidad de selección". Lack también fue pionero en el uso de muchos instrumentos nuevos para la investigación ornitológica, incluida la idea de usar radar para estudiar la migración de las aves.

Las aves fueron también usadas en estudios de la hipótesis de nichos y el principio de exclusión competitiva de Georgii Gause. Robert MacArthur hizo trabajos sobre la partición de recursos y la estructuración de comunidades de aves a través de la competición. Los patrones de biodiversidad también se convirtieron en un tópico de interés. E. O. Wilson y Robert MacArthur fueron pioneros en trabajos sobre la relación del número de especies con el área y su aplicación en el estudio de la biogeografía insular. Estos estudios llevaron al desarrollo de la disciplina de la ecología del paisaje.

John Hurrell Crook estudió el comportamiento de las aves acuáticas y demostró el vínculo entre las condiciones ecológicas, el comportamiento y los sistemas sociales.Se introdujeron principios de la economía al estudio de la biología por J. L. Brown. Esto llevó al estudio del comportamiento con el uso de análisis costo-beneficio. El creciente interés en la sociobiología también dio lugar a una surgencia de estudios en esta área.
El estudio del comportamiento de impronta en patos y gansos por Konrad Lorenz y los estudios de instintos en gaviotas argenteas por Nicolaas Tinbergen, dieron lugar al establecimiento del campo de la etología. El estudio del aprendizaje se volvió un área de interés y el estudio del canto de las aves ha sido un modelo para estudios de neuro-etología. El rol de las hormonas y la fisiología en el control del comportamiento ha sido ayudado también por aves como modelos. Estas aves han ayudado en el estudio de ciclos circadianos y estacionales. Los estudios sobre la migración han intentado responder las interrogantes sobre la evolución de la evolución, la orientación y la navegación.
El crecimiento de la genética y el surgimiento de la biología molecular dio lugar a la aplicación de la visión de la evolución centrada en genes para explicar fenómenos en aves. estudios de grupos familiares y el altruismo, tal como el de los ayudantes en el nido, se volvió de interés particular. La idea de adaptación inclusiva fue usado para interpretar observaciones sobre el comportamiento y la historia de vida y las aves fueron modelos ampliamente usadas para examinar hipótesis basadas en teorías postuladas por W. D. Hamilton y otros.
Las nuevas herramientas de la biología molecular cambiaron el estudio de la sistemática de las aves. La sistemática cambió de ser basada en fenotipo a basarse en genotipo. Charles Sibley y Jon Edward Ahlquist fueron pioneros en el uso de técnicas como la hibridación ADN-ADN aplicadas al estudio de relaciones evolutivas las que resultaron en lo que es llamado taxonomía de Sibley-Ahlquist. Esta tecnología inicial ha sido remplazada por otras más nuevas basadas en análisis de secuencias de ADN nuclear y mitocóndrico y enfoques de filogenética molecular con métodos estadísticos cladísticos que hacen uso de alineamiento de secuencias, construcción de árboles filogenéticos y calibración de relojes moleculares para inferir relaciones evolutivas. Las técnicas moleculares se usan también ampliamente en estudios de biología de poblaciones y ecología.

El uso de prismáticos y telescopios para la observación de las aves comenzó hacia 1820 y 1830 de la mano de pioneros como J. Dovaston (quien también fue pionero en el uso de comederos de aves), pero no fue hasta 1880 que los manuales de instrucción comenzaron a insistir en el uso de ests herramientas.

Otro de los mayores cambios, fue el crecimiento de la publicación de las guías de campo para la identificación de las aves. Las primeras guías eran grandes y pesadas; y estaban centradas principalmente en la identificación de especies en mano. Una de las primeras guías de nueva generación fue la realizada por Florence Merriam en 1887, titulada "Hints to Audubon Workers:Fifty Birds and How to Know Them" ("Pistas para los trabajadores de Audubon: cincuenta ave y como conocerlas").

El interés y la popularidad del pajareo creció en muchas partes del mundo, y se tomó conciencia de que existía la oportunidad para los aficionados de contribuir a la biología profesional. Ya en 1916, Julian Huxley, escribió un artículo en "The Auk" acerca de las tensiones entre aficionados y profesionales del estudio de las aves, y de la posibilidad de que los aficionados podían proveer de una gran cantidad de datos a los científicos.

Se fueron creando organizaciones en muchos países, y crecieron rápidamente en número. Algunas de las más notables fueron la Royal Society for the Protection of Birds (RSPB) creada en 1889 en el Reino Unido y la Audubon Society creada en 1885 en EEUU. Aunque alguna de estas organizaciones se centran en la conservación, otras realizan estudios científicos de gran calado, como por ejemplo la realización de atlas de distribución de especies.

Los instrumentos y las técnicas de ornitología son variados y nuevos inventos y enfoques son incorporados rápidamente. Las técnicas pueden ser ampliamente divididas entre las categorías de aquellas que son aplicables a especímenes y aquellas que son usadas en el campo, sin embargo la clasificación es aproximada y muchas técnicas de análisis son usables en ambos, el laboratorio y el campo o pueden requerir una combinación de técnicas de campo y de laboratorio.

Los enfoques más tempranos para el estudio de las aves involucraron la colección de huevos, una práctica conocida como oología. Mientras la colecta se volvió un pasatiempo para muchos aficionados, las etiquetas asociadas con estas colectas tempranas de huevos carecieron de confiabilidad para su uso en estudios serios de la reproducción de aves. Con el objetivo de preservar los huevos, se les realizaba un pequeño hueco y se extraía su contenido. Esta técnica se volvió estándar con la invención del taladro de soplado alrededor de 1830 La colecta de huevos ya no es popular; sin embargo las colecciones de museos históricas han sido de valor en la determinación de los efectos de pesticidas como el DDT sobre la fisiología.

El uso de pieles de aves para documentar especies ha sido una parte estándar de la ornitología sistemática. Las pieles de aves se preparan reteniendo los huesos claves de las alas, patas y cráneo junto con la piel y las plumas. En el pasado, se las trataba con arsénico para prevenir el ataque de hongos e insectos (mayormente derméstidos). El arsénico, por ser tóxico, fue remplazado por bórax. Los colectores aficionados Sportsmen se familiarizaron con estas técnicas de disección de pieles y comenzaron a enviar sus pieles a los museos, algunos desde localidades distantes. Esto dio lugar a la formación de gigantescas colecciones pieles de aves en museos de Europa y Norteamérica. Se formaron también muchas colecciones privadas. Estas se convirtieron en referencias para la comparación de especies y los ornitólogos en estos museos pudieron comparar especies de diferentes localidades, a menudo de lugares que ellos mismos nunca habían visitado. La morfometría de estas pieles, en particular la longitud de tarso, pico, cola y ala se volvieron importantes en las descripciones de especies de aves. Estas colecciones de pieles han sido utilizadas en tiempos más recientes para estudios sobre filogenética molecular mediante la extracción de ADN antiguo. La importancia de los especímenes tipo en la descripción de especies hace de las colecciones de pieles un recurso vital para la ornitología sistemática. Sin embargo, con el surgimiento de las técnicas moleculares, se ha vuelto posible establecer el estatus taxonómico de nuevos descubrimientos, como por ejemplo los de "Laniarius liberatus" (que ya no es una especie válida) y "Liocichla bugunorum", usando muestras de sangre, ADN y plumas como material holotipo.
Otros métodos de preservación incluyen el almacenamiento de especímenes en alcohol. Tales especímenes húmedos tienen valor especial en estudios fisiológicos y anatómicos, aparte de proveer ADN de mejor calidad para los estudios moleculares. El secado por congelación de especímenes es otra técnica que tiene la ventaja de preservar el contenido estomacal y la anatomía, aunque tiende a encoger las muestras lo que las hace menos confiables para la morfometría.

El estudio de aves en el campo fue ayudado enormemente por las mejoras en la óptica. La fotografía hizo posible documentar aves en el campo con gran precisión. Los teleobjetivos de alto poder hoy le permiten a los observadores detectar diferencias morfológicas mínimas que antes sólo podían detectarse con el espécimen en la mano.

La captura y marcado de aves permite estudios detallados de historia natural. Las técnicas para la captura de aves son variadas e incluyen el uso de liga de aves (con sustancias pegajosas) para las que se posan, la red japonesa para las aves de bosques, la red de cañón para bandadas en áreas abiertas, la trampa "bal-chatri" para rapaces, el señuelo y la trampa de embudo para aves acuáticas.

El ave en mano puede ser examinada y las mediciones pueden ser hechas incluyendo longitudes estándares y peso. La muda de las plumas y la osificación del cráneo proveen indicaciones de la edad y la salud. El sexo puede ser determinado por examen de la anatomía en algunas especies sin dimorfismo sexual. Las muestras de sangre pueden ser extraídas para determinar las condiciones hormonales en estudios de fisiología, identificar marcadores de ADN para análisis genéticos y de las relaciones de parentesco en estudios de biología de la reproducción y filogeografía. La sangre también puede usarse para hallar patógenos y virus transmitidos por artrópodos. Los ectoparásitos se pueden colectar para estudios de coevolución y zoonosis En muchas especies crípticas, las mediciones ( como las longitudes relativas de las plumas de alas en las currucas) son vitales para identificar la especie.

Las aves capturadas son a menudo marcadas para su reconocimiento posterior. Los anillos o bandas provee identificaciones duraderas pero requieren la captura para que la información que portan pueda ser leída. Las marcas identificables en el campo como las bandas de colores, etiquetas alares, y las pinturas permiten estudios a corto plazo donde se requiere la identificación de individuos. La técnica de marcaje y recaptura hace posible estudios demográficos. El anillado ha sido usado tradicionalmente en estudios de migración En tiempos recientes los transmisores satelitales proveen la posibilidad de hacer un seguimiento de las aves durante la migración casi en tiempo real.
Las técnicas para la estimación de la densidad de población incluyen conteo puntual, transecto y mapeo territorial. Las observaciones se hacen en el campo usando protocolos cuidadosamente diseñados y los datos pueden ser analizados para estimar la diversidad de aves, la abundancia relativa o la densidad poblacional absoluta. Estos métodos pueden usarse repetidamente por largos periodos de tiempo para monitorear cambios en el ambiente.La trampa fotográfica se ha considerado un instrumento útil en la detección y documentación de especies elusivas, predadores de nidos, y en el análisis cuantitativo de frugivoría, dispersión de semillas y comportamiento.

Muchos aspectos de la biología de las aves son difíciles de estudiar en el campo. Entre estos se incluyen los cambios de comportamientos y fisiológicos que requieren un acceso de larga duración al ave. Las muestras de sangre o plumas tomadas sin daño durante estudios de campo pueden ser estudiadas en el laboratorio. Por ejemplo, la variación en la relación entre isótopos de hidrógeno en las diferentes latitudes hace posible establecer aproximadamente el origen de aves migratorias con el uso de análisis con espectrómetro de masas en muestras de plumas. Estas técnicas pueden usarse en combinación con otras técnicas como el anillado.
La primera vacuna atenuada desarrollada por Luis Pasteur fue para el cólera aviar y fue probada en gallinas en 1878. Las gallinas continúan usándose como modelo para muchos estudios en inmunología de animales no-mamíferos.
Estudios de la conducta de aves incluyen el uso de aves amansadas y entrenadas en cautiverio. Los estudios de la inteligencia de las aves y el aprendizaje del canto se han basado ampliamente en laboratorios. Los investigadores de campo hacen uso de un amplio rango de técnicas como el uso de búhos imitados para sonsacar un comportamiento "mobbing", los muñecos de machos o el uso de grabaciones de llamados para inducir comportamientos territoriales y por lo tanto establecer los límites de los territorios de las aves.
Estudios de la migración de las aves que incluyen aspectos de navegación, orientación, y fisiología son realizados a menudo con aves cautivas en jaulas especiales para registrar sus actividades. El embudo de Emlen, por ejemplo, usa una jaula con almohadillas entintadas en el centro y un suelo cónico donde las patas imprimen marcas que pueden contarse para identificar la dirección hacia la cual el ave intenta volar. EL embudo puede tener un techo transparente y se pueden controlar los estímulos visuales como la dirección de la luz solar usando espejos o las posiciones de las estrellas simuladas en un planetario.
El genoma completo de la gallina doméstica ("Gallus gallus") fue secuenciado en 2004 y luego en 2008 también fue secuenciado el genoma del pinzón cebra ("Taeniopygia guttata").Tales proyectos de secuenciación completa de genomas permiten el estudio de los procesos evolutivos involucrados en la especiación.La asociaciones entre la expresiones de genes y comportamientos pueden ser estudiadas usando genes candidatos. Se ha encontrado que las variaciones en el comportamiento explorador del herrerillo mayor ("Parus major") están ligadas a un gen ortólogo del gen humano Drd4 (receptor de dopamina D4) es cual se conoce que está asociado al comportamiento de búsqueda de novedades. El rol de la expresión de genes en diferencias de desarrollo y en variaciones morfológicas han sido estudiadas en los pinzones de Darwin. Se ha mostrado que la diferencia en la expresión de "Bmp4" está asociada con cambios en el crecimiento y forma del pico.
Desde hace mucho la gallina ha sido un organismo modelo para el estudio de la biología del desarrollo en vertebrados. Dado que el embrión es rápidamente accesible, su desarrollo puede ser fácilmente seguido (a diferencia del ratón). Esto también permite el uso de la electroporación para el estudio del efecto de la adición o silenciamiento de un gen. Otras herramientas para la perturbación de su constitución genética son las células madre embrionarias y vectores virales.

Con el crecimiento del interés en las aves, ha sido posible usar un gran número de personas para trabajar en proyectos ornitológicos colaborativos que cubren amplias escalas geográficas. Estos proyectos de ciencia ciudadana incluyen proyectos de amplitud nacional tales como en Estados Unidos el "Conteo de Aves de Navidad",el "Conteo de Aves del Patio", la "Encuesta de Aves Reproductoras" de Norteamérica, la EPOQ canadiense, o los proyectos regionales como el "Censo de Aves Acuáticas de Asia". Estos proyectos ayudan a identificar la distribución de las aves, sus densidades de población y los cambios con el tiempo, fechas de partida y llegada de las migraciones, la estacionalidad reproductiva e incluso la genética poblacional. Los estudios de migración con uso de anillamiento de aves o su marcaje con color a menudo involucra la cooperación de personas y organizaciones en diferentes países.

Las aves silvestres se implican en muchas actividades humanas mientras que las aves domésticas son importantes como fuente de huevos, carne, plumas y otros productos. La ornitología aplicada y económica tiene por objeto el reducir el efecto nocivo de las aves problemáticas y aumentar el aprovechamiento de las especies beneficiosas.

Se conoce bien el rol de algunas especies de aves como plagas, en particular en la agricultura. Las aves granívoras como las queleas en África están entre las aves más numerosas en el mundo y bandadas alimentándose pueden causar devastaciones. Muchas aves insectívoras son también apreciadas como beneficiosas para la agricultura. Muchos de los primeros estudios realizados sobre los beneficios y daños causados por las aves en los campos se hicieron mediante el análisis de contenidos estomacales y la observación de la conducta de alimentación. Estudios modernos dirigidos al manejo de las aves en relación a la agricultura hacen uso de un amplio espectro de principios de la ecología. La acuicultura intensiva ha puesto a los humanos en conflicto con las aves pescadoras como los cormoranes.
Las grandes bandadas de palomas y estorninos en las ciudades son considerados a menudo como una molestia y constantemente se innovan técnicas para reducir sus poblaciones o sus impactos. Las aves son también de importancia médica y se ha reconocido ampliamente el rol que tienen como portadoras de enfermedades humanas como la encefalitis japonesa, el virus del Nilo occidental y el H5N1. El choque de aves y el daño que causan a la aviación son de importancia particularmente grande, debido a las consecuencias fatales y el nivel de pérdidas económicas causadas. Se ha estimado que el negocio de las aerolíneas incurre mundialmente en daños de 1.200 millones cada año.
Muchas especies de aves han sido llevadas a la extinción por actividades humanas. La conservación de las aves requiere conocimientos especializados en aspectos de biología, ecología y puede requerir el uso de enfoques localmente muy específicos. Los ornitólogos contribuyen a la biología de la conservación mediante el estudio de la ecología de las aves silvestres y la identificación de las amenazas claves y de las vías para mejorar la supervivencia de las especies. Las especies bajo amenaza crítica tales como el Cóndor Californiano han debido ser capturados y criados en cautiverio. Tal medidas de conservación ex situ pueden permitir luego la reintroducción de la especie a su medio natural.




</doc>
<doc id="2068" url="https://es.wikipedia.org/wiki?curid=2068" title="Oreomunnea">
Oreomunnea

Oreomunnea es un género de árboles perteneciente a la familia Juglandaceae. Es nativa del sur de México y América Central, donde se encuentran en las selvas de montaña.
Son grandes árboles que alcanzan los 35 m de altura, con hojas pinnadas con cuatro hasta ocho foliolos; las hojas están dispuestas en pares opuestos. El fruto es una pequeña nuez con alrededor de 1 cm de diámetro, con un ala tri lobulada.


</doc>
<doc id="2071" url="https://es.wikipedia.org/wiki?curid=2071" title="Obesidad">
Obesidad

La obesidad es una enfermedad crónica de origen multifactorial prevenible que se caracteriza por acumulación excesiva de grasa o hipertrofia general del tejido adiposo en el cuerpo; es decir, cuando la reserva natural de energía de los humanos y otros mamíferos —almacenada en forma de grasa corporal— se incrementa hasta un punto en que pone en riesgo la salud o la vida. El sobrepeso y la obesidad son el quinto factor principal de riesgo de defunción humana en el mundo. Cada año fallecen por lo menos 2,8 millones de personas adultas como consecuencia del sobrepeso o la obesidad.

La Organización Mundial de la Salud (OMS) define como obesidad cuando el índice de masa corporal (IMC, cociente entre el peso y la estatura de un individuo al cuadrado) es igual o superior a 30 kg/m². También se considera signo de obesidad un perímetro abdominal en hombres mayor o igual a 102 cm y en mujeres mayor o igual a 88 cm. (Ver: diagnóstico de la obesidad).

La obesidad forma parte del síndrome metabólico, y es un factor de riesgo conocido, es decir, es una indicación de la predisposición a varias enfermedades, particularmente enfermedades cardiovasculares, diabetes mellitus tipo 2, apnea del sueño, ictus y osteoartritis, así como para algunas formas de cáncer, padecimientos dermatológicos y gastrointestinales. (Ver: Efecto sobre la salud).

Aunque la obesidad es una condición clínica individual, se ha convertido en un serio problema de salud pública que va en aumento:

Según el origen de la obesidad, esta se clasifica en los siguientes tipos:

La obesidad infantil es uno de los problemas de salud pública más graves del siglo XXI. El problema es mundial y está afectando progresivamente a muchos países de bajos y medianos ingresos, sobre todo en el medio urbano. La prevalencia ha aumentado a un ritmo alarmante. Se calcula que en 2010 había 42 millones de niños con sobrepeso en todo el mundo, de los que cerca de 35 millones viven en países en desarrollo.

Los niños obesos y con sobrepeso tienden a seguir siendo obesos en la edad adulta y tienen más probabilidades de padecer a edades más tempranas enfermedades no transmisibles como la diabetes y las enfermedades cardiovasculares. El sobrepeso, la obesidad y las enfermedades conexas son en gran medida prevenibles. Por consiguiente hay que dar una gran prioridad a la prevención de la obesidad infantil.

Cada año, como mínimo 2,8 millones de adultos fallecen por las consecuencias sobre la salud del sobrepeso o la obesidad. Asimismo, son responsables de entre el 7% y el 41% de ciertos tipos de cáncer, el 23% de los casos de cardiopatía isquémica y el 44% de los casos de diabetes, la cual afecta a actualmente a 347 millones de personas en todo el mundo.

En el Reino Unido, la encuesta de salud para Inglaterra predijo que más de 12 millones de adultos y un millón de niños serían obesos en 2010 si no se tomaban acciones.

En EUA la obesidad es un problema de salud pública por su prevalencia, costos y carga en los servicios sanitariosy las agencias del gobierno así como la medicina privada han advertido durante años acerca de los efectos adversos para la salud asociados con el sobrepeso y la obesidad. A pesar de las advertencias, el problema es cada vez peor y en los Estados unidos, la prevalencia de sobrepeso y obesidad hace de la obesidad un importante problema de salud pública. En 2004, el CDC reportó que el 66,3 % de los adultos en los Estados Unidos tenía sobrepeso u obesidad. La causa en la mayoría de los casos es el estilo de vida sedentaria; aproximadamente el 40 % de los adultos en Estados Unidos no participan en ninguna actividad física durante su tiempo de ocio y menos de un tercio de los adultos se ocupan de la cantidad de actividad física recomendada. Los Estados Unidos tiene en la tasa más alta de obesidad en el mundo desarrollado. Desde 1980 al 2002 la obesidad se ha duplicado en adultos y la prevalencia de sobrepeso se ha vuelto crítica en niños y adolescentes. Las estadísticas muestran un rápido crecimiento de la epidemia de obesidad en los Estados Unidos entre 1985 y 2004 y de 2003 a 2004, "en los niños y adolescentes en edades comprendidas entre 2 y 19 años, 17,1 % tuvieron sobrepeso... y el 32,2 % de los adultos de 20 años y mayores fueron obesos". Este repentino aumento en la prevalencia de obesidad es atribuido a factores del medio ambiente y de la población más que a un comportamiento individual y biológico debido al aumento rápido y continuo en el número de individuos con sobrepeso y obesidad.

En China, el ingreso promedio se incrementó debido al boom económico, la población de China ha iniciado recientemente un estilo de vida más sedentario y al mismo tiempo empezó a consumir alimentos más ricos en calorías. Desde 1991 al 2004 el porcentaje de adultos con sobrepeso u obesidad se incrementó desde el 12,9 al 27,3 %.

En México, de acuerdo con la Encuesta Nacional de Salud y Nutrición 2012 (ENSANUT2012), el sobrepeso y la obesidad afectan a 7 de cada 10 adultos mexicanos. La prevalencia combinada de sobrepeso u obesidad es de 73 % para las mujeres y 69.4 % para los hombres de edad adulta. Los niños en edad escolar (ambos sexos), de 5 a 11 años, presentaron una prevalencia nacional combinada de sobrepeso y obesidad en 2012 de 34.4 %, 19.8 % para sobrepeso y 14.6 % para obesidad. El 35 % de los adolescentes de entre 12 y 19 años presentan sobrepeso u obesidad. Uno de cada cinco adolescentes tiene sobrepeso y uno de cada diez presenta obesidad. La prevalencia nacional combinada de sobrepeso y obesidad en adolescentes fue de alrededor de 35.8 % para el sexo femenino y 34.1 % en el sexo masculino. En menores de cinco años ha aumentado entre 1988 y 2012, pasando de 7.8 a 9.7 %, respectivamente. El principal aumento de la prevalencia combinada de sobrepeso y obesidad se observa en la región norte del país, con 12 %. La Ciudad de México tuvo 39.9 % de sobrepeso y 33.9 % de obesidad y la zona sur de México presentó 39.6 % de sobrepeso y 31.6 % de obesidad. La región norte del país tuvo una prevalencia de sobrepeso del 35.9 % y de obesidad del 37.2 %.

Las causas de la obesidad son múltiples, e incluyen factores tales como la herencia genética; el comportamiento del sistema nervioso, endocrino y metabólico; y el tipo o estilo de vida que se lleve. Para entre los factores que pueden causar obesidad puede ser atribuido un 30 % a los factores genéticos, 40 % a los factores no heredables y 30 % a los factores meramente sociales, es decir, la relación entre factores genéticos y ambientales son del 30 % y 70 % respectivamente. Los mecanismos para que estos factores causen exceso de grasa corporal son:


Si se ingiere mayor cantidad de energía de la necesaria esta se acumula en forma de grasa. Si se consume más energía de la disponible se utiliza la grasa como energía. Por lo que la obesidad se produce por exceso de energía, como resultado de las alteraciones en el equilibrio de entrada/salida de energía. Como consecuencia se pueden producir diversas complicaciones, como son la hipertensión arterial, la diabetes mellitus y las enfermedades coronarias.

La herencia tiene un papel importante, tanto que de padres obesos el riesgo de sufrir obesidad para un niño es 10 veces superior a lo normal. En parte es debido a tendencias metabólicas de acumulación de grasa, pero en parte se debe a que los hábitos culturales alimentarios y sedentarios contribuyen a repetir los patrones de obesidad de padres a hijos.

Otra parte de los obesos lo son por enfermedades hormonales o endocrinas, y pueden ser solucionados mediante un correcto diagnóstico y tratamiento especializado.

La mayoría de los investigadores han concluido que la combinación de un consumo excesivo de nutrientes y el estilo de vida sedentaria son la principal causa de la rápida aceleración de la obesidad en la sociedad occidental en el último cuarto del siglo XX.

A pesar de la amplia disponibilidad información nutricional en escuelas, consultorios, Internet y tiendas de comestibles, es evidente que el exceso en el consumo continúa siendo un problema sustancial. Por ejemplo, la confianza en la comida rápida rica en energía, se ha triplicado entre 1977 y 1995, y el consumo de calorías se ha cuadruplicado en el mismo periodo.

Sin embargo, el consumo de alimento por sí mismo es insuficiente para explicar el incremento fenomenal en los niveles de obesidad en el mundo industrializado durante los años recientes. Un incremento en el estilo de vida sedentaria también tiene un rol significativo en los niveles actuales elevados de esta enfermedad.

Cuestiones sobre el estilo de vida, menos establecido, que pueden influir sobre la obesidad incluyen al estrés mental y el sueño insuficiente.

Como con muchas condiciones médicas, el desbalance calórico que resulta en obesidad frecuentemente se desarrolla a partir de la combinación de factores genéticos y ambientales. El polimorfismo en varios genes que controlan el apetito, el metabolismo y la integración de adipoquina, predisponen a la obesidad, pero la condición requiere la disponibilidad de suficientes calorías y posiblemente otros factores para desarrollarse completamente. Varias condiciones genéticas que tienen como rasgo la obesidad, han sido identificadas (tales como el síndrome de Prader-Willi, el síndrome de Bardet-Biedl, síndrome MOMO, mutaciones en los receptores de leptina y melanocortina), pero mutaciones sencillas en locus solo han sido encontradas en el 5 % de los individuos obesos. Si bien se piensa que una larga proporción los genes causantes están todavía sin identificar, para la mayoría que la obesidad es probablemente el resultado de interacciones entre múltiples genes donde factores no genéticos también son probablemente importantes.

Un estudio de 2007 identificó bastantes mutaciones comunes en el gen FTO; los heterocigotos tuvieron un riesgo de obesidad 30 % mayor, mientras que los homocigotos tuvieron un incremento en el riesgo de un 70 %. Gracias a otro estudio GWAS realizado en 2015, se han podido identificar más de 100 variantes genéticas implicadas en la modulación del IMC y el Índice cintura/cadera. Estos parámetros, proporcionan información sobre el peso corporal y la distribución de la grasa, aspectos íntimamente relacionados con la obesidad y sus efectos fisiopatológicos. Asimismo, el conocimiento de estos polimorfismos, proporciona información sobre los mecanismos biológicos que subyacen de la relación entre edad/sexo y tamaño/forma del cuerpo, facilitando el diagnóstico y favoreciendo un tratamiento de la obesidad de manera mucho más personalizado. Por otro lado, identifica loci (locus) genéticos que contribuyen a las diferencias que existen en el dimorfismo sexual entre hombres y mujeres 

A nivel poblacional, la hipótesis del gen ahorrador, que postula que ciertos grupos étnicos pueden ser más propensos a la obesidad que otros y la habilidad de tomar ventaja de raros períodos de abundancia y usar esta abundancia para almacenar energía eficientemente, pueden haber sido una ventaja evolutiva, en tiempos cuando la comida era escasa. Individuos con reservas adiposas mayores, tenían más posibilidades de sobrevivir la hambruna. Esta tendencia a almacenar grasas es probablemente una inadaptación en una sociedad con un abastecimiento estable de alimentos.

Aproximadamente de un 2 % a un 3 % de las causas de obesidad son enfermedades endocrinas como el hipotiroidismo, síndrome de Cushing, hipogonadismo, lesiones hipotalámicas o deficiencia de la hormona de crecimiento.

La enfermedad celíaca y la sensibilidad al gluten no celíaca no tratadas, que frecuentemente cursan sin síntomas digestivos y en la mayoría de los casos permanecen sin diagnosticar, son una causa poco conocida de obesidad tanto en niños como en adultos. Más de la mitad de los adultos presentan obesidad en el momento de ser diagnosticados de enfermedad celíaca y solo el 15% está por debajo de su peso normal. Estas tasas son algo inferiores en los niños. Evidencias recientes demuestran que en algunos casos la persistencia de ciertas complicaciones de la enfermedad celíaca, que no remiten a pesar de seguir una dieta sin gluten, predispone al sobrepeso y la obesidad. Entre ellas se incluyen los trastornos de la vesícula biliar, la insuficiencia pancreática exocrina, el aumento de la permeabilidad intestinal, el sobrecrecimiento bacteriano intestinal, la hígado graso no alcohólico, la intolerancia a la lactosa y la alergia a la leche.

También ciertas enfermedades mentales pueden predisponer a la obesidad o incrementar el riesgo de obesidad como los trastornos alimentarios tales como bulimia nerviosa y el consumo compulsivo de comida o la adicción a los alimentos. Dejar de fumar es una causa conocida de ganancia de peso moderada, pues la nicotina suprime el apetito. Ciertos tratamientos médicos con (esteroides, antipsicóticos atípicos y algunas drogas para la fertilidad) pueden causar ganancia de peso.

Aparte del hecho de que corrigiendo estas situaciones se puede mejorar la obesidad, la presencia de un incremento en el peso corporal puede complicar el manejo de otras enfermedades.

Flier resume los muchos posibles mecanismos fisiopatológicos involucrados en el desarrollo y mantenimiento de la obesidad.

Este campo de investigación ha sido casi inalcanzable hasta el descubrimiento de las leptinas en 1994, gracias al cual se dilucidado muchos otros mecanismos hormonales que participan en la regulación del apetito y consumo de alimentos, así como en los patrones de almacenamiento en el tejido adiposo y en el desarrollo de resistencia a la insulina.

Desde el descubrimiento de las leptinas, han sido estudiados otros mediadores como las ghrelinas, orexinas, PYY 3-36, colecistoquinina, adiponectina y las adipoquinas que son mediadores producidos por el tejido adiposo; se piensa que su acción se modifica con muchas enfermedades relacionadas con la obesidad.

Las leptinas y ghrelinas son consideradas complementarias en su influencia sobre el apetito, las ghrelinas producidas por el estómago, modulan el control del apetito a corto plazo (para comer cuando el estómago está vacío y para parar con el estómago está lleno). La leptina es producida por el tejido adiposo para señalizar las reservas de grasa almacenadas en el organismo y mediar el control del apetito a largo plazo (para comer más cuando las reservas de grasa están bajas y menos al de las reservas de grasa son altas). Aunque la administración de leptinas puede ser efectiva en un pequeño grupo de sujetos obesos quienes son deficientes de leptina, muchos más individuos obesos parecen ser resistentes a la leptina. Esta resistencia explica en parte porqué la administración de leptinas no ha mostrado ser eficiente en suprimir el apetito en la mayoría de los sujetos obesos.

Mientras que la leptina y la ghrelina son producidas periféricamente, su control del apetito es a través de sus acciones sobre sistema nervioso central. En particular, estas y otras hormonas relacionadas con el apetito, actúan sobre el hipotálamo, una región del cerebro, central en la regulación del consumo de alimentos y el gasto de energía. Hay varios círculos dentro del hipotálamo, que contribuyen con este rol de integración del apetito, siendo la vía de la melanocortina la mejor comprendida.

El circuito comienza en el núcleo arcuato del hipotálamo, que tiene salidas al hipotálamo lateral (HL) y ventromedial (HVM), los centros de la alimentación y la saciedad en el cerebro respectivamente.

El núcleo arcuato contiene dos grupos distintos de neuronas.
El primer grupo coexpresa neuropéptido Y (NPY) y el péptido relacionado agouti (AgRP) y recibe señales estimulatorias del hipotálamo lateral y señales inhibitorias del hipotálamo ventromedial. El segundo grupo coexpresa proopiomelanocortina (POMC) y transcritos regulados por cocaína y anfetamina (CART) y recibe señales estimulatorias del hipotálamo ventromedial y señales inhibitorias del hipotálamo lateral.

Consecuentemente, las neuronas NPY/AgRP estimulan la alimentación e inhiben la saciedad, mientras que las neuronas POMC/CART, estimula la saciedad e inhiben la alimentación. Ambos grupos de neuronas del núcleo arcuato son reguladas en parte por la leptina. La leptina inhibe el grupo NPY/AgRP, mientras que estimula el grupo POMC/CART. Por lo tanto una deficiencia en la señalización por leptina, vía deficiencia de leptina o resistencia a la leptina, conduce a una sobrealimentación y puede dar cuenta por algunas formas de obesidad genética y adquirida.

El rol de las bacterias y arqueas que colonizan el tracto digestivo en el desarrollo de la obesidad ha comenzado a ser recientemente objeto de investigación. Las bacterias participan en la digestión (especialmente de ácidos grasos y polisacáridos) y alteraciones en la proporción 10 cintas pueden explicar por qué ciertas personas son más propensas a ganar peso que otras.

En el tracto digestivo humano, las bacterias generalmente son miembros del filo de los bacteroides o de los firmicutes. En la gente obesa, existe una abundancia relativa de firmicutes (los cuales causan una absorción de energía relativamente alta), lo cual es restaurado por la pérdida de peso. A partir de estos resultados no se puede concluir aún si este desbalance es la causa de la obesidad o es un efecto. Microorganismos que se especula que se asocia con la obesidad incluyen la arquea "Methanobrevibacter smithii".

Algunos cofactores de la obesidad, son resistentes a la teoría de que la epidemia es un nuevo fenómeno. En particular, un cofactor de clase que aparece de manera coherente a través de muchos estudios. Comparando el patrimonio neto, con el índice de masa corporal, un estudio de 2004 encontró que en Estados Unidos, los sujetos obesos son la mitad de ricos que los delgados.

Cuando se compararon diferenciales en el ingreso, la inequidad persistió, los sujetos delgados fueron por herencia más ricos que los obesos. Una tasa mayor de un bajo nivel de educación y tendencias a depender de comidas rápidas baratas es visto como una razón por la cual estos resultados son tan diferentes. Otro estudio encontró que mujeres quienes se casaban dentro de un estatus más alto son de forma predecible más delgadas que las mujeres quienes se casan dentro de un estatus más bajo.

Un estudio de 2007, de 32.500 niños de la cohorte original del estudio Framingham, seguidos por 32 años indicaron que el IMC cambia en amigos, hermanos o esposos sin importar la distancia geográfica. La asociación fue más fuerte entre amigos mutuos y menor entre hermanos y esposos (aunque estas diferencias no fueron estadísticamente significativas). Los autores concluyeron a partir de estos resultados que la aceptación de la masa corporal juega un papel importante en los cambios de la talla corporal.

Mientras frecuentemente podría parecer obvio por qué un cierto individuo engorda, es más difícil entender por qué el peso promedio de cierta sociedad ha estado recientemente aumentando. Mientras que las causas genéticas son centrales para comprender la obesidad, estas no pueden explicar completamente por qué una cultura en gorda más que otra.

Esto es más notable de Estados Unidos. En los años justo después de la Segunda Guerra Mundial hasta 1960 el peso promedio por persona se incrementó, pero pocos fueron obesos. En las dos y media décadas desde 1980, el crecimiento en la tasa de obesidad se aceleró marcadamente y esta cada vez más convirtiéndose en un problema de salud pública.

Existe un número de teorías para explicar la causa de este cambio desde 1980. La más creíble es la combinación de varios factores.








La menopausia produce cambios en la distribución de la grasa corporal y en la oxidación del tejido adiposo. El aumento de masa grasa abdominal y visceral de la postmenopausia se acompaña con aumento de la capacidad antioxidante a causa del cambio hormonal mientras que la edad no tiene influencia. Sin embargo, la capacidad antioxidante tiene una correlación lineal con la edad, pero no con la masa grasa troncular.

En mujeres inicialmente premenopáusicas que fueron seguidas durante 4 años a lo largo de la transición menopáusica, se comunicó un aumento de grasa subcutánea abdominal asociado con la edad, mientras que la menopausia se acompaña de un incremento en la masa grasa corporal total y en la masa grasa visceral.
El estudio estadounidense SWAN relaciona el incremento de la grasa visceral durante la menopausia con los cambios en la testosterona biodisponible.

El exceso de peso corporal (sobrepeso y obesidad) produce mayor alteración en el Índice de Kupperman, metabolismo, sueño y calidad de vida.
Las mujeres menopáusicas obesas tienen, además, mayor prevalencia de problemas con su sexualidad, relacionados consigo mismas y con factores relacionados con sus parejas.

La OMS señala que «El sobrepeso y la obesidad son el quinto factor principal de riesgo de defunción en el mundo. Cada año fallecen por lo menos 2,8 millones de personas adultas como consecuencia del sobrepeso o la obesidad. Además, el 44 % de la carga de diabetes, el 23 % de la carga de cardiopatías isquémicas y entre el 7 y el 41 % de la carga de algunos cánceres son atribuibles al sobrepeso y la obesidad».

Un gran número de condiciones médicas han sido asociadas con la obesidad y las consecuencias sobre la salud son el resultado de un incremento de la grasa corporal: (artrosis, apnea del sueño, (diabetes, cáncer, enfermedades cardiovasculares, esteatosis hepática no alcohólica).
La mortalidad está incrementada en la obesidad, con un IMC mayor de 32 están asociado con un doble riesgo de muerte.
Existen alteraciones en la respuesta del organismo a la insulina con (resistencia a la insulina), un estado pro inflamatorio y una tendencia incrementada a la trombosis (estado pro trombótico).

La asociación con otras enfermedades puede ser dependiente o independiente de la distribución del tejido adiposo. La obesidad central (u obesidad caracterizada por un radio cintura cadera alto), es un factor de riesgo importante para el síndrome metabólico, el cúmulo de un número de enfermedades y factores de riesgo que predisponen fuertemente para la enfermedad cardiovascular. Estos son diabetes mellitustipo dos, hipertensión arterial, niveles altos de colesterol y de triglicéridosen la sangre (hiperlipidemiacombinada).

Además del síndrome metabólico, la obesidad es también correlacionada con una variedad de otras complicaciones. Pero algunas de estas dolencias no ha sido establecido claramente hasta qué punto son causadas directamente por la obesidad como tal o si tienen otra causa (tal como sedentarismo) que también causa obesidad.


Mientras que ser gravemente obeso tiene muchas complicaciones de salud, quienes tienen sobrepeso también enfrentan un pequeño incremento en la mortalidad o morbilidad. Por otra parte algunos estudios han encontrado que la osteoporosis ocurre menos en personas ligeramente obesas sugiriendo que la acumulación de grasa sobre todo visceral, que se mide con la circunferencia abdominal, es un factor protector para la mineralización ósea.

En forma práctica, la obesidad puede ser diagnosticada típicamente en términos de salud midiendo el índice de masa corporal (IMC), pero también en términos de su distribución de la grasa mediante la circunferencia de la cintura o la medida del índice cintura/cadera. Además, la presencia de obesidad necesita ser considerada en el contexto de otros factores de riesgo y comorbilidades asociadas (otras condiciones médicas que podrían influir en el riesgo de complicaciones).

El índice de masa corporal es un método simple y ampliamente usado para estimar la proporción de grasa corporal.
El IMC fue desarrollado por el estadístico y antropometrista belga Adolphe Quetelet. Este es calculado dividiendo el peso del sujeto (en kilogramos) por el cuadrado de su altura (en metros), por lo tanto es expresado en kg / m².

Los organismos gubernamentales en EUA determinan el sobrepeso y la obesidad usando el índice de masa corporal (IMC), utilizando el peso y altura para determinar la grasa corporal. Un IMC entre 25 y 29,9 es considerado sobrepeso y cualquier valor sobre 30 es obesidad. Individuos con un IMC por encima de 30 incrementan el riesgo de varios peligros para la salud.

La OMS (Organización Mundial de la Salud) establece una definición comúnmente en uso con los siguientes valores, acordados en 1997, publicados en 2000 y ajustados en el 2010:


En un marco clínico, los médicos toman en cuenta la raza, la etnia, la masa muscular, edad, sexo y otros factores que pueden afectar a la interpretación del índice de masa corporal. El IMC sobreestima la grasa corporal en personas muy musculosas, y por otra parte la grasa corporal puede ser subestimada en personas que han perdido masa corporal (muchos ancianos).
La obesidad leve como es definida según el IMC, no es un factor de riesgo cardiovascular y por lo tanto el IMC no puede ser usado como un único predictor clínico y epidemiológico de la salud cardiovascular.

El IMC no tiene en cuenta las diferencias entre los tejido adiposo y tejido magro; tampoco distingue entre las diferentes formas de adiposidad, algunas de las cuales pueden estar asociadas de forma más estrecha con el riesgo cardiovascular.

El mejor conocimiento de la biología del tejido adiposo ha mostrado que la obesidad central (obesidad tipo masculina o tipo manzana) tiene una mayor relación con la enfermedad cardiovascular, que el IMC aislado.

La circunferencia de cintura absoluta (>102 cm en hombres y >88 cm en mujeres) o el índice cintura-cadera (>0,9 para hombres y >0,85 para mujeres) son usados como medidas de obesidad central.

En una cohorte de casi 15.000 sujetos del estudio National Health and Nutrition Examination Survey (NHANES) III, la circunferencias cintura explicó significativamente mejor que el IMC los factores de riesgo para la salud relacionados con la obesidad cuando el síndrome metabólico fue tomado como medida.

Una vía alternativa para determinar la obesidad es medir el porcentaje de grasa corporal. Médicos y científicos generalmente están de acuerdo en que un hombre con más del 25 % de grasa corporal y una mujer con más de 30 % de grasa corporal son obesos.

Sin embargo, es difícil medir la grasa corporal de forma precisa. El método más aceptado ha sido el de pesar a las personas bajo el agua, pero la pesada bajo el agua es un procedimiento limitado a laboratorios con equipo especial. Los métodos más simples para medir la grasa corporal son el método de los pliegues cutáneos, en el cual un pellizco de piel es medido exactamente para determinar el grosor de la capa de grasa subcutánea; o el análisis de impedancia bioeléctrica, usualmente llevado a cabo por especialistas clínicos. Su uso rutinario es desaconsejado.
Otras medidas de grasa corporal incluyen la tomografía computarizada, la resonancia magnética y la absorciometría de rayos x de energía dual.

La presencia de factores de riesgo y enfermedad asociados con la obesidad también son usados para establecer un diagnóstico clínico. La coronariopatía, la diabetes tipo 2 y la apnea del sueño son factores de riesgo que constituyen un peligro para la vida que podría indicar un tratamiento clínico para la obesidad.
Hábito tabáquico, hipertensión, edad e historia familiar son otros factores de riesgo que podrían indicar tratamiento.

Es necesario tratar adecuadamente las enfermedades subyacentes, si existen. A partir de aquí depende de buscar el equilibrio, mediante ajustes en la dieta. La dieta debe ser adecuada a la actividad necesaria, por ello una dieta muy intensiva en personas muy activas es contraproducente. Debe de tenderse a realizar dietas más suaves y mantenidas. Una vez alcanzado el peso ideal, lo ideal es mantenerlo con un adecuado programa de ejercicios y alimentación que sobre todo permitan no volver a recuperar la grasa y el peso perdido.

El principal tratamiento dietético para la obesidad es reducir la grasa corporal comiendo menos calorías y ejercitándose más. El efecto colateral beneficioso del ejercicio es que incrementa la fuerza de los músculos, los tendones y los ligamentos, lo cual ayuda a prevenir lesiones provenientes de accidentes y actividad vigorosa. Los programas de dieta y ejercicios producen una pérdida de peso promedio de aproximadamente 8 % del total de la masa corporal (excluyendo los sujetos que abandonaron el programa). No todos los que hacen dieta están satisfechos con estos resultados, pero una pérdida de masa corporal tan pequeña como 5 % puede representar grandes beneficios en la salud.

Mucho más difícil que reducir la grasa corporal es tratar de mantenerla. Entre el 80 y el 90 % de aquellos que bajan un 10 % de su masa corporal o más a través de una dieta vuelven a recuperar todo el peso en un período de dos y cinco años. El organismo tiene sistemas que mantienen su homeostasis a cierto nivel, incluyendo el peso corporal. Por lo tanto, mantener el peso perdido generalmente requiere que hacer ejercicio y comer adecuadamente sea una parte permanente del estilo de vida de las personas. Ciertos nutrientes, tales como la fenilalanina, son supresores naturales del apetito, lo cual permite restablecer el nivel adecuado del peso corporal.

En una guía de práctica clínica del colegio americano de médicos, se hacen las siguientes cinco recomendaciones:

Una guía para la práctica clínica por la US Preventive Services Task Force (USPSTF), concluyó que la evidencia es insuficiente para hacer una recomendar a favor o en contra del consejo rutinario sobre conducta para promover una dieta saludable en pacientes no seleccionados en establecimientos de atención primaria, sin embargo este consejo intensivo acerca de la conducta dietaria está recomendado en aquellos pacientes con hiperlipidemia y otros factores de riesgo conocidos para enfermedades cardiovasculares y enfermedades crónicas relacionadas. La asesoría puede ser llevada a cabo por clínicos de atención primaria o por referencia a otros especialistas tales como nutricionistas o dietistas.

El ejercicio requiere energía (calorías). Las calorías son almacenadas en la grasa corporal. Durante el ejercicio aeróbico prolongado el organismo consume inicialmente sus reservas de grasa a fin de proveer energía. Los músculos más grandes en el organismo son los músculos de las piernas y naturalmente estos queman la mayoría de las calorías, lo cual hace que el caminar, correr y montar en bicicleta estén entre las formas más efectivas de ejercicio para reducir la grasa corporal.

Un metaanálisis de ensayos aleatorios controlados realizado por la International Cochrane Collaboration, encontró que "el ejercicio combinado con dieta resulta en una mayor reducción de peso que la dieta aislada".

En general, el tratamiento dietético de la obesidad se basa en reducir la ingesta de alimentos. Se han propuesto varios abordajes dietéticos, algunos de los cuales se han comparado mediante ensayos aleatorios controlados:

Un estudio en el que se compararon durante 6 meses las dietas Atkins, de la Zona, Weight Watchers y Ornish encontró los siguientes resultados:


Un meta-análisis estudios al azar controlados concluyó que "comparando con el tratamiento usual, el asesoramiento dietético produce una modesta pérdida de peso que disminuye con el tiempo".

Muchos estudios se han enfocado en dietas que reducen las calorías vía dietas bajas en carbohidratos (la dieta Atkins, la dieta de la Zona) vs. dieta baja en grasas (la dieta LEARN, la dieta Ornish). El Nurses' Health Study, un estudio observacional por cohortes, encontró que las dietas baja en carbohidratos basadas en fuentes vegetales de grácil proteína está asociadas con menos coronariopatía.

Un meta-análisis de estudios aleatorios controlados por el International Cochrane Collaboration realizado en el 2002 concluyó que las dietas en las que se restringen las grasas no son mejores que las dietas en las que se restringen las calorías, en alcanzar una pérdida de peso a largo plazo en personas con sobrepeso u obesidad.

Un metaanálisis más reciente que incluyó estudios controlados publicados después de la revisión de Cochrane, encontró que "las dietas bajas en carbohidratos, en las que no se restringe la energía parecen ser al menos tan efectiva como en las dietas bajas en grasa con restricción de la energía en indios y una pérdida de peso hasta por un año. Sin embargo, cambios potencialmente favorables en los niveles de triglicéridos y HDL colesterol deben ser pesados contra cambios potencialmente desfavorables en el nivel de LDL colesterol, cuando se usen dietas bajas en carbohidrato para inducir una pérdida de peso".

El estudio "Women's Health Initiative Randomized Controlled Dietary Modification Trial" encontró que una dieta con un total de 20 % de la energía proveniente de la energía y un incremento en el consumo de vegetales y frutas hasta de al menos 5 raciones diarias y granos de hasta al menos 6 raciones diarias resultó en: no hubo reducción en la enfermedad cardiovascular, hubo una reducción no significativa del cáncer de mama invasivo y no hubo reducción en el cáncer colorectal.

Recientes estudios aleatorios controlados adicionales han encontrado que: una comparación de las dietas Atkins, de la Zona, Ornish y LEARN en mujeres premenopausicas, encontró los mayores beneficios a partir de la dieta Atkins.

Para la elección de la dieta de una persona específica se puede tener en cuenta la medición de la secreción individual de insulina. En adultos jóvenes "la reducción de la carga glicémica (carbohidratos), puede no ser especialmente importante para alcanzar la pérdida de peso entre individuos con una alta secreción de insulina".
Esto es coherente con estudios previos de pacientes diabéticos en los cuales dietas bajas en carbohidratos fueron más beneficiosas.

"El factor Índice glicémico es una clasificación de los alimentos ricos en carbohidratos basada en su efecto total sobre los niveles plasmáticos de glucosa. Alimentos con un índice glucémico bajo, tales como las lentejas, proveen una fuente de glucosa más constante y lenta al torrente sanguíneo, por lo tanto estimulan menos la liberación de insulina que los alimentos con índice glicémico alto, tales como el pan blanco".

La carga glucémica es "el producto matemático del índice glicémico y de la cantidad de carbohidratos".

Un estudio aleatorio controlado, que comparó cuatro dietas que variaban en la cantidad de carbohidratos y el índice glicémico, encontró resultados complicados:


En las dietas 2 y 3 perdieron la mayor cantidad de peso y masa grasa; sin embargo, las lipoproteínas de baja densidad cayeron en la dieta dos y aumentaron en la dieta tres. Por lo tanto los autores concluyeron que las dietas altas en carbohidratos de bajo índice glicémico fueron las más favorables.

Un meta-análisis realizado por Cochrane Collaboration concluyó que las dietas de bajo índice glicémico o bajas cargas y se indica conducen a más pérdida de peso y mejor perfil lipídico. Sin embargo, las dietas de índice glicémico bajo y carga y cínica baja fueron agrupadas juntas y no se trató de separar el efecto de la carga versus el índice.

El tratamiento farmacológico de la obesidad tiene un papel coadyuvante y normalmente se justifica en pacientes con un IMC igual o mayor a 30 Kg/m o en pacientes con factores de riesgo (diabetes o dislipidemias) con un IMC igual o mayor a 27 kg/m. 
Generalmente los fármacos utilizados se dividen en tres grandes grupos:

La medicación más comúnmente prescrita para la obesidad resistente al ejercicio/dieta es el orlistat (Xenical, el cual reduce la sesión intestinal de grasas inhibiendo la lipasa pancreática) y sibutramina (reductil, Meridia, un anorexígeno supresor del apetito). La pérdida de peso con estas drogas es modesta y a largo plazo la pérdida promedio de peso con el orlistat es de 2,9 kg, con la sibutramina 4,2 kg y con el rimonabant 4,7 kg. El orlistat y el rimonabant llevan a una reducción en la incidencia de diabetes, y todas las drogas tienen algún efecto sobre las lipoproteínas (diferentes formas de colesterol).

Sin embargo, existe poca información sobre las complicaciones a largo plazo de la obesidad, tales como los infartos. Todas las drogas tienen efectos secundarios y contraindicaciones potenciales. Comúnmente las drogas para pérdida de peso se usan por un período determinado y se descontinuan o se cambian por otro agente si no se obtiene el beneficio esperado, tal como una pérdida de peso menor de 5 % del total del peso corporal en un periodo de 12 semanas en el caso del orlistat.

Un meta-análisis de estudios controlados al azar realizado por International Cochrane Collaboration, concluyó que en pacientes diabéticos la fluoxetina, el orlistat y la sibutramina, podrían conseguir una significativa aunque modesta pérdida de peso entre 12-57 semanas, con beneficios a largo plazo sobre la salud no muy claros.

La obesidad también puede influir sobre la elección de las drogas para el tratamiento de la diabetes. La metformina puede conducir a una leve reducción de peso (en oposición a las sulfonilureas e insulina) y ha sido demostrado que reduce el riesgo de enfermedad cardiovascular en los diabéticos tipo dos obesos. Las tiazolidinedionas, pueden causar una ligera ganancia de peso, pero disminuyen la "patológica" grasa abdominal y pueden por lo tanto ser usadas en diabéticos con obesidad central.

La cirugía bariátrica (o "cirugía para pérdida de peso") es el conjunto de las intervenciones quirúrgicas usadas en el tratamiento de la obesidad mórbida, es decir, normalmente es indicada para pacientes con un IMC igual o mayor a 40 Kg/m o en pacientes con factores de riesgo o asociaciones comórbidas con un IMC igual o mayor a 35 Kg/m. Como toda intervención quirúrgica pueden producirse a complicaciones y la cirugía bariátrica las tiene frecuentes, por lo que debe ser considerada como el último recurso cuando la modificación dietética y el tratamiento farmacológico no han sido exitosos. El resultado de la cirugía bariátrica depende de varios mecanismos, la propuesta más común es la reducción de volumen del estómago (por ejemplo con una cinta gástrica ajustable), produciendo así una sensación de saciedad temprana y reducción de la ingesta, mientras otros procedimientos (como el bypass gástrico) también reducen la longitud del tracto digestivo con la que la comida entra en contacto, reduciendo directamente la absorción. La cirugía en la que se emplea la cinta o banda es reversible mientras que las operaciones en las que se acortan el estómago o intestino no lo son. Algunos procedimientos pueden ser realizados laparoscópicamente.

Dos grandes estudios han demostrado una relación mortalidad/beneficio a partir de la cirugía bariátrica con una marcada disminución en el riesgo de sufrir diabetes mellitus, enfermedades cardiovasculares y cáncer. La pérdida de peso fue mayor en los primeros meses después de la cirugía, pero el beneficio se mantuvo a largo plazo. En uno de los estudios hubo un incremento inexplicable en las muertes por accidentes y suicidios que no pesó más que el beneficio en términos de prevención de enfermedad. La cirugía bypass gástrico fue aproximadamente dos veces más efectiva que el procedimiento de la banda gástrica ajustable.

Un estudio realizado a personas mayores de cuarenta años de edad por el "Framinghan Heart Study" de 1948 a 1990 reveló que en aquellos pacientes con sobrepeso (IMC de 24 a 29.9 kg/m) no fumadores tuvieron una esperanza de vida menor a la media de 3,3 años para las mujeres y 3,1 años para los hombres. En pacientes obesos (IMC mayor a 30 kg/m) no fumadores obtuvieron 7,1 años menos en las mujeres y 5,8 años menos en los hombres. Los pacientes obesos fumadores tuvieron una esperanza de vida menor a la media de los fumadores no obesos de 7,2 años para las mujeres y 6,7 años para los hombres y en comparación a la media de los que no fumaban y eran de peso normal fue una diferencia de 13,3 años para las mujeres y 13,7 para los hombres.

La obesidad se puede prevenir y tratar buscando el equilibrio en la ingesta de calorías con una dieta balanceada teniendo en cuenta los aportes calóricos de los alimentos. Se sabe que cada 250 gramos de grasa equivalen a 2250  kilocalorías, y cada gramo de grasa equivale a 9 kcal. Si existe un exceso de grasa corporal, se debe calcular la energía (medida en calorías) que representan y disminuirla en la ingesta alimentaria durante un período adecuado.

Un método se basa en estimar el aporte de energía de la dieta (energía de metabolización) a partir de su contenido en macronutrientes (y de etanol, en el caso de incluir bebidas alcohólicas). Esta energía de metabolización se calcula a partir de los factores de Atwater, que solo son válidos para la dieta y no para alimentos particulares. Estos factores se recogen en la tabla siguiente:

Así, una dieta diaria que aporte un total de 100,6 g de proteínas, 93,0 g de grasa y 215,5 g de carbohidratos, proporcionará una energía de, aproximadamente, 2101 kcal.

En cuanto a alimentos, en la tabla siguiente se recogen algunos factores de Atwater que permiten estimar la energía que aportarían tras su metabolización:

También se puede conocer la energía que aportarían los alimentos a través de un dispositivo denominado "bomba calorimétrica". Con este sistema se calculan los valores de energía que habitualmente se recogen en la mayoría de las tablas de composición de alimentos. En la tabla siguiente se reflejan algunos ejemplos:

La palabra «obeso» proviene del latín "obēsus", que significa ‘corpulento, gordo o regordete’. "Ēsus" es el participio pasado de "edere" (‘comer’), con el prefijo "ob" agregado a este. En latín clásico, este verbo se encuentra solamente en la forma de participio pasado.

En varias culturas humanas, la obesidad estuvo asociada con atractivo físico, fuerza y fertilidad. Algunos de los primeros artefactos culturales conocidos, como las figuritas de Venus, son estatuas tamaño bolsillo representando una figura femenina obesa. Aunque su significado cultural no está registrado, su amplio uso por todas las culturas prehistóricas mediterráneas y europeas sugiere un rol central para la forma femenina obesa y el uso en rituales mágicos sugiere la aprobación cultural de (y quizás la reverencia por) esta forma corporal. Esto es más probable se deba a su habilidad para lidiar fácilmente con niños y sobrevivía las hambrunas.

La obesidad fue considerada un símbolo de riqueza y estrato social en culturas propensas a la escasez de comida o hambrunas. Esto fue visto también de la misma manera en el período moderno temprano en las culturas europeas, pero cuando la seguridad alimentaria fue realizada, sirvió más como una muestra visible de "lujuria por la vida", apetito e inmersión en el reino del erótico. Este fue especialmente el caso en las artes visuales, tales como las pinturas de Rubens (1577-1640), cuya representación regular de mujeres obesas nos dio el término descriptivo de "rubenesca".

La obesidad también puede ser vista como un símbolo dentro de un sistema de prestigio. "El tipo de comida, la cantidad y la manera en la cual está servida están entre los criterios importantes de clase social. En la mayoría de las sociedades tribales, inclusive aquellas con un sistema social altamente estratificado, todo el mundo-la realeza y los plebeyos-, comían la misma clase de alimentos y si hubo una hambruna todo el mundo estuvo hambriento. Con la siempre creciente diversidad de elementos, la comida se ha convertido no solamente en un asunto de estatus social, sino también una marca de la personalidad y el gusto individual".

En las culturas occidentales modernas, la forma del cuerpo obeso es ampliamente considerado no atractivo y muchos estereotipos negativos están comúnmente asociados con la gente obesa. Los niños, adolescentes y adultos obesos también pueden enfrentar un pesado estigma social. Los niños obesos son frecuentemente el blanco de amenazas y son con frecuencia rechazados por sus compañeros. Aunque las tasas de obesidad se están incrementando entre todas clases sociales en el mundo occidental, la obesidad es frecuente vista como un signo de estatus socioeconómico bajo.

La mayoría de las personas ha experimentado pensamientos negativos acerca de su imagen corporal, y algunos de ellos toman medidas drásticas para tratar de cambiar su forma, incluyendo la dieta, el uso de medicamentos inclusive la cirugía. No todas las culturas contemporáneas desaprueban la obesidad. Existen muchas culturas las cuales tradicionalmente aprueban más (en diversos grados) la obesidad, incluyendo algunas culturas africanas, árabes hindúes y en las islas del pacífico. Especialmente en décadas recientes, la obesidad ha comenzado a ser vista más como una condición médica en la cultura occidental moderna inclusive tiene referida como una epidemia.

Recientemente ha emergido un pequeño pero creciente movimiento de aceptación a la gordura que busca cuestionar la discriminación basada en el peso. Los grupos de apoyo y aceptación de la obesidad, han iniciado un litigio para defender los derechos de las personas obesas y para prevenir su exclusión social. Autores dentro de este movimiento argumentan que el estigma social alrededor de la obesidad está fundado en la ansiedad cultural y que la preocupación pública sobre los riesgos de salud asociados con la obesidad son inapropiadamente usados como una racionalización de este estigma.

Varios estereotipos de personas obesas ha encontrado su vía dentro de expresión de la cultura popular. Un estereotipo común es el carácter de la persona obesa, quien tiene una personalidad cálida y fiable, sin embargo es igualmente común el estereotipo del matón vicioso y obeso (tal como Dudley Dursley de la serie de libros de Harry Potter, Nelson Muntz de Los Simpsons). La glotonería y la obesidad son comúnmente representadas juntas en trabajos de ficción. En los dibujos animados, la obesidad es frecuentemente usada como efecto cómico, con personajes de dibujos animados gordos (tales como Piggy, Porky Pigy Tummi Gummi) teniendo que escurrirse a través de espacios angostos quedando frecuentemente atascados o inclusive explotando.

Un ejemplo más inusual de humor relacionado con la obesidad es Bustopher Jones, del poema de T. S. Eliot. Bustopher Jones: The Cat About Town que figura en su libro "Old Possum's Book of Practical Cats", así como en el musical "Cats", quien se hizo famoso por ser un visitante regular de muchos clubes de caballeros. Debido a sus constantes almuerzos en el club, él es extraordinariamente gordo, siendo descrito por los otros como "un 25 libras... y él está ganando peso cada día". Otro personaje popular es Garfield, un gato de dibujos animados, es también obesidad para humor. Cuando su dueño, John, lo puso a dieta, en vez de perder peso, Garfield disminuyó la velocidad de ganancia de peso.

Es discutible que esta representación en la cultura popular suma y mantiene los estereotipos comúnmente percibidos, dañando la autoestima de las personas obesas. Por otro lado, la obesidad es frecuentemente asociada con características positivas tales como el del humor (el estereotipo del gordo alegre como Santa Claus) y algunas personas son más atraídas sexualmente por personas obesas que por personas delgadas.

Además del incremento en enfermedad y mortalidad existen otras implicaciones para la actual tendencia mundial a la obesidad. Entre estas están:

Las respuestas en salud pública y política a la obesidad buscan entender y corregir los factores ambientales responsable por cambios en la prevalencia de sobrepeso y obesidad en una población. La vecindad y el sobrepeso son actualmente ante todo problemas políticos en los Estados Unidos. Las soluciones políticas y de salud pública buscan cambiar los actores del medio ambiente que promueven las calorías densas, el consumo de alimentos bajos en nutrientes y que inhibe la actividad física.

En los Estados Unidos, la política se ha enfocado ante todo en el control de la obesidad en la niñez la cual tiene las implicaciones más serias en salud pública a largo plazo. Los esfuerzos han sido dirigidos a escuelas clave. Existen esfuerzos en proceso para reformar el programa Federal de reembolso de comidas, limitar el marketing de alimentos a los niños y prohibir o limitar el acceso a bebidas endulzadas con azúcar. En Europa, la política se ha enfocado en limitar el marketing a los niños. Ha habido un enfoque en nivel internacional sobre la política relacionada con el azúcar y el rol de las políticas agrícolas en la producción de alimentos que producen sobrepeso y obesidad en la población. Para confrontar la actividad física, los esfuerzos se han dirigido a examinar la zonificación y el acceso parques y rutas seguras en las ciudades.

En el Reino Unido, un reporte del 2004 por el Real Colegio de Médicos, la Facultad de Salud Pública y el Real Colegio de Pediatría Salud Infantil titulado "Almacenando problemas", seguido por un reporte del Comité de Salud de la Cámara de los Comunes, sobre el acto de la obesidad sobre la salud y la sociedad en el Reino Unido y posibles acercamientos al problema. En el 2006, el Instituto nacional para la salud y la excelencia clínica (National Institute for Health and Clinical Excellence), publicó una guía sobre el diagnóstico y manejo de la obesidad así como las implicaciones políticas para las organizaciones no asistenciales tales como los Ayuntamientos. Un reporte del año 2007 producido por Sir Derek Wanless para la Fundación del Rey, advirtió que a menos que acciones adicionales sean tomadas, la obesidad tienen la capacidad para paralizar el Servicio Nacional de Salud desde el punto de vista financiero.




</doc>
<doc id="2073" url="https://es.wikipedia.org/wiki?curid=2073" title="Oreochloa">
Oreochloa

Oreochloa es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Eurasia.

Algunos autores lo incluyen en el género "Sesleria".
El género fue descrito por Heinrich Friedrich Link y publicado en "Hortus Regius Botanicus Berolinensis" 1: 44. 1827. 



</doc>
<doc id="2075" url="https://es.wikipedia.org/wiki?curid=2075" title="Oryzopsis">
Oryzopsis

Oryzopsis es un género de plantas herbáceas, perteneciente a la familia de las poáceas. Es originario de Norteamérica.
El nombre del género es una combinación de "Oryza" (género de la misma familia) y del término griego "opsis" (apariencia), aludiendo a una similitud en los dos géneros. 





</doc>
<doc id="2077" url="https://es.wikipedia.org/wiki?curid=2077" title="OpenGL">
OpenGL

OpenGL (Open Graphics Library) es una especificación estándar que define una API multilenguaje y multiplataforma para escribir aplicaciones que produzcan gráficos 2D y 3D. La interfaz consiste en más de 250 funciones diferentes que pueden usarse para dibujar escenas tridimensionales complejas a partir de primitivas geométricas simples, tales como puntos, líneas y triángulos. Fue desarrollada originalmente por Silicon Graphics Inc. (SGI) en 1992 y se usa ampliamente en CAD, realidad virtual, representación científica, visualización de información y simulación de vuelo. También se usa en desarrollo de videojuegos, donde compite con Direct3D en plataformas Microsoft Windows.

Fundamentalmente OpenGL es una especificación, es decir, un documento que describe un conjunto de funciones y el comportamiento exacto que deben tener. Partiendo de ella, los fabricantes de hardware crean implementaciones, que son bibliotecas de funciones que se ajustan a los requisitos de la especificación, utilizando aceleración hardware cuando es posible. Dichas implementaciones deben superar unos tests de conformidad para que sus fabricantes puedan calificar su implementación como conforme a OpenGL y para poder usar el logotipo oficial de OpenGL.

Hay implementaciones eficientes de OpenGL para Mac OS, Microsoft Windows, GNU/Linux, varias plataformas Unix y PlayStation 4. Existen también varias implementaciones en software que permiten ejecutar aplicaciones que dependen de OpenGL sin soporte de aceleración hardware. Es destacable la biblioteca de software libre / código abierto Mesa 3D, una API de gráficos sin aceleración hardware y completamente compatible con OpenGL. Sin embargo, para evitar los costes de la licencia requerida para ser denominada formalmente como una implementación de OpenGL, afirma ser simplemente una API "muy similar".

La especificación OpenGL era revisada por el OpenGL Architecture Review Board (ARB), fundado en 1992. El ARB estaba formado por un conjunto de empresas interesadas en la creación de una API consistente y ampliamente disponible. Microsoft, uno de los miembros fundadores, abandonó el proyecto en 2003.

El 21 de septiembre de 2006 se anunció que el control de OpenGL pasaría del ARB al Grupo Khronos. Con ello se intentaba mejorar el marketing de OpenGL y eliminar las barreras entre el desarrollo de OpenGL y OpenGL ES. ARB se convirtió dentro de Khronos en el OpenGL ARB Working Group. El subgrupo de Khronos que gestiona la especificación de OpenGL se denomina OpenGL ARB Working Group. Para una relación de los miembros que componen el OpenGL ARB Working Group, véase el apartado Miembros del Grupo Khronos. El gran número de empresas con variados intereses que han pasado tanto por el antiguo ARB como por el grupo actual han hecho de OpenGL una API de propósito general con un amplio rango de posibilidades.

Mark Segal y Kurt Akeley fueron los autores de la especificación original de OpenGL. Chris Frazier fue el editor de la versión 1.1. Jon Leech ha editado las versiones desde 1.2 hasta la presente 3.0.

OpenGL tiene dos propósitos esenciales:


El funcionamiento básico de OpenGL consiste en aceptar primitivas tales como puntos, líneas y polígonos, y convertirlas en píxeles. Este proceso es realizado por una "pipeline" gráfica conocida como "Máquina de estados de OpenGL". La mayor parte de los comandos de OpenGL bien emiten primitivas a la pipeline gráfica o bien configuran cómo la pipeline procesa dichas primitivas. Hasta la aparición de la versión 2.0 cada etapa de la pipeline ejecutaba una función prefijada, resultando poco configurable. A partir de la versión 2.0 algunas etapas son programables usando un lenguaje de programación llamado GLSL.

OpenGL es una API basada en procedimientos de bajo nivel que requiere que el programador dicte los pasos exactos necesarios para renderizar una escena. Esto contrasta con las APIs descriptivas, donde un programador sólo debe describir la escena y puede dejar que la biblioteca controle los detalles para representarla. El diseño de bajo nivel de OpenGL requiere que los programadores conozcan en profundidad la pipeline gráfica, a cambio de darles libertad para implementar algoritmos gráficos novedosos.

OpenGL ha influido en el desarrollo de las tarjetas gráficas, promocionando un nivel básico de funcionalidad que actualmente es común en el hardware comercial; algunas de esas contribuciones son:


Una descripción somera del proceso en la pipeline gráfica podría ser:

Muchas tarjetas gráficas actuales proporcionan una funcionalidad superior a la básica aquí expuesta, pero las nuevas características generalmente son mejoras de esta pipeline básica más que cambios revolucionarios de ella.

Nota: Cuidado, este ejemplo es únicamente válido con OpenGL 2.1 y versiones anteriores. Hace uso intensivo de funciones actualmente anticuadas.

Primero, limpiamos el buffer de color para empezar en un "canvas" negro:

Se establece la matriz "modelview", que controla la posición de la cámara respecto a las primitivas que renderizamos. La retrasamos 3 unidades en el eje "Z", dejándola apuntando hacia el origen:
La matriz "projection" controla la perspectiva aplicada a las primitivas; se utiliza de forma similar a la anterior:

Por último, se dibuja un polígono (un cuadrado verde orientado en el plano "XY"):

En los años 1980 el desarrollo de software que fuese compatible con un amplio rango de hardware gráfico era un verdadero reto para los desarrolladores. Había que tratar con interfaces muy diferentes y escribir drivers específicos para cada tipo de hardware, resultando muy costoso; por ello, se subcontrataban equipos de programadores para agilizar el desarrollo. Dado que cada equipo trabajaba por separado en sus interfaces, se producía mucho código redundante. Además, era un proceso caro, por lo que varios grupos innovadores aceptaron el reto de encontrar un método mejor.

Al principio de los años 1990 SGI era un grupo de referencia en gráficos 3D para estaciones de trabajo. Suya era la API IRIS GL, considerada puntera en el campo y estándar de facto, llegando a eclipsar a PHIGS, basada en estándares abiertos. IRIS GL se consideraba más fácil de usar y, lo más importante, soportaba renderizado en "modo inmediato". Además, PHIGS, aparte de su mayor dificultad, fue considerada inferior a IRIS GL respecto a funcionalidad y capacidad.

La competencia de SGI (Sun Microsystems, Hewlett-Packard e IBM, entre otros) fue capaz de introducir en el mercado hardware 3D compatible con el estándar PHIGS mediante extensiones. Esto fue reduciendo la cuota de mercado de SGI conforme iban entrando diferentes proveedores en el mercado. Por todo ello, en un intento de fortalecer su influencia en el mercado, SGI decidió convertir el estándar IRIS GL en un estándar abierto.

SGI observó que la API IRIS GL no podía ser abierta debido a conflictos de licencias y patentes; también contenía funciones no relevantes para los gráficos 3D como APIs para ventanas, teclado o ratón (en parte, porque fue desarrollada antes de la aparición del X Window System o de los sistemas NeWS de Sun). Además, mientras iba madurando el soporte del mercado para el nuevo estándar, se pretendía mantener los antiguos clientes mediante bibliotecas añadidas como Iris Inventor o Iris Performer.

El resultado de todo lo anterior fue el lanzamiento del estándar OpenGL.

Algunos de los logros que se consiguieron fueron:
Con la variedad de hardware gráfico existente, lograr que todos "hablasen" el mismo lenguaje obtuvo un efecto importante, ofreciendo a los desarrolladores de software una plataforma de alto nivel sobre la que trabajar.

En 1992, SGI lideró la creación del OpenGL Architecture Review Board (OpenGL ARB), grupo de empresas que mantendría y extendería la especificación OpenGL en los años siguientes. OpenGL evolucionó desde IRIS GL, superando su problema de dependencia del hardware al ofrecer emulación software para aquellas características no soportadas por el hardware del que se dispusiese. Así, las aplicaciones podían utilizar gráficos avanzados en sistemas relativamente poco potentes.

En 1994 SGI barajó la posibilidad de lanzar un producto denominado OpenGL++, el cual incluía elementos como una API de "scene-graph" (basada presumiblemente en la tecnología de Performer). Dicha especificación fue divulgada entre unos pocos grupos interesados, pero nunca apareció finalmente como producto.

En 1995 Microsoft lanzó Direct3D, que se convertiría en el principal competidor de OpenGL. El 17 de diciembre de 1997 Microsoft y SGI iniciaron el proyecto Fahrenheit, esfuerzo cooperativo con el objetivo de unificar las interfaces de OpenGL y Direct3D (y añadir también una API "scene-graph"). En 1998 se uniría al proyecto Hewlett-Packard. Pese a tener un principio prometedor en estandarizar las APIs de gráficos 3D, debido a restricciones financieras en SGI y la falta general de apoyo por parte de la industria, fue finalmente abandonado en 1999.

En la GDC de 2015, Khronos Group anunció la API sucesora de OpenGL, llamada Vulkan. Inicialmente, fue presentada por Khronos como "la iniciativa OpenGL de próxima generación", pero luego el nombre fue descartado, quedando Vulkan como definitivo. Vulkan está basado en Mantle, otra API de la empresa AMD, cuyo código fue cedido a Khronos con la intención de generar un estándar abierto similar a OpenGL, pero de bajo nivel.

Publicada en enero de 1992.
La primera especificación de OpenGL fue publicada por Mark Segal y Kurt Akeley.

Publicada en enero de 1997.
OpenGL 1.1 se enfocó en el soporte de texturas y formatos de textura sobre hardware de GPU.
Tarjetas gráficas soportadas: todas
Publicada el 16 de marzo de 1998.
OpenGL 1.2 se enfocó en el soporte de texturas de volumen, píxeles empaquetados, reescalado normal, muestreo de texturas clamped/edge y procesamiento de imágenes.
Tarjetas gráficas soportadas: Rage 128, Rage 128 GL, Rage XL/XC, Rage 128 Pro, Rage Fury MAXX, y todas las tarjetas posteriores.

Publicada el 14 de octubre de 1998
OpenGL 1.2.1 fue un lanzamiento menor publicado después de OpenGL 1.2 (16 de marzo de 1998) el cual añadió multi-textura, o unidades de textura, al canal de renderizado. Esto permitió texturas múltiples que son combinadas por píxel durante la rasterización. 
Tarjetas gráficas soportadas: Radeon, Radeon Mobility, Radeon 7500 Mobility, Radeon 8500, Radeon 9000, Radeon 9200, Radeon 9600, Radeon 9800, GeForce 3, GeForce 4Ti, GeForce FX, y todas las tarjetas posteriores

Publicada el 14 de agosto de 2001.
OpenGL 1.3 añadió soporte para textura cubemap, múltiples texturas, multi-muestreo y operaciones de combinación de unidades de textura (añadir, combinar, dot3, border clamp).
Tarjetas gráficas soportadas: Radeon 32/36, Radeon 64/7200, Radeon 7000, Radeo AIW, Radeon 7500, Radeon IGP 320M, Radeon IGP 345M, ES1000, Radeon 8500, Radeon 9000/Pro, Radeon 9100/9200/9250 (Pro & IGP), GeForce 3, GeForce 4Ti, GeForce FX, y todas las tarjetas posteriores.

Publicada el 24 de julio de 2002.
OpenGL 1.4 añadió soporte de sombreado por hardware, coordenadas niebla, generación automática de mipmaps, y modos de textura adicionales.
Tarjetas gráficas soportadas: Quadro DCC, Quadro4 380 XGL, Quadro4 500XGL, 550XGL, Quadro4 700XGL, 750XGL, 900XGL, 980XGL, y todas las tarjetas posteriores.

Publicada el 29 de julio de 2003.
OpenGL 1.5 añadió soporte para objetos de búfer de vértice (VBOs), consultas de oclusión, y amplió las funciones de sombreado.
Tarjetas gráficas soportadas: Radeon X800, Radeon 9600, Radeon 9700, Radeon 9800, GeForce FX, y todas las tarjetas posteriores.

Publicada el 7 de septiembre de 2004.
OpenGL 2.0 añadió soporte para un lenguaje ensamblador basado en GPU verdadero, llamado ARB (diseñado por el Architecture Review Board), que se convertiría en el estándar para vertex y fragment shaders. Las tarjetas publicadas con OpenGL 2.0 fueron las primeras en ofrecer shaders programables por el usuario.
Tarjetas soportadas: Radeon 9650, Radeon 9500, Radeon 9500/9550/9600/9700/9800 (Pro, SE, XT), Radeon X1050, Radeon Xpress 200 / 1100, Radeon X300, Radeon X550, Radeon X600/Pro, Radeon X700, Radeon X800 (VE, SE, GT, Pro), Radeon X850, Radeon Xpress 1250, Radeon X1200, Radeon X1250, Radeon 2100, Radeon X1300, X1550, X1600, X1650, X1800, X1900, X1950 (Pro, XT, GT), GeForce 6800, Quadro 600, Qaudro FX 500, Quadro FX 700, Quadro FX 1000, FX 2000, FX 3000, Quadro FX 1400, Quadro FX 1500, Quadro FX 3450, Quadro FX 3500, Quadro FX 4500X2, Quadro FX4500 SDI, y todas las tarjetas posteriores.

OpenGL 2.0 fue concebido por 3Dlabs para abordar las preocupaciones de que OpenGL estaba estancado y carecía de una dirección fuerte. 3Dlabs propuso una serie de importantes adiciones a la norma. La mayoría de estas fueron, en ese momento, rechazadas por el ARB o de otra manera nunca llegaron a realizarse en la forma que 3Dlabs propuso. Sin embargo, su propuesta de un lenguaje de sombreado de estilo C se completó con el tiempo, resultando en la formulación actual del GLSL (OpenGL Shading Language, también slang).Al igual que los lenguajes de sombreado estilo-ensamblador que trataba de sustituir, permite al programador sustituir los fixed-function vertex y el fragment pipe con shaders, aunque esta vez escritos en un lenguaje tipo C de alto nivel.

El diseño de GLSL se destacó por hacer relativamente pocas concesiones a las limitaciones del hardware entonces disponible, lo que recordaba a la tradición anterior de OpenGL estableciendo un objetivo ambicioso, con visión de futuro para los aceleradores 3D en lugar de simplemente seguir el estado de hardware disponible actualmente. La última especificación OpenGL 2.0 incluye soporte para GLSL.

El 2 de agosto de 2006 se publicó OpenGL 2.1. Siendo completamente compatible con las versiones anteriores, aporta además nuevas características como:


La versión OpenGL 3.0 fue publicada el 11 de agosto de 2008. Es compatible hacia atrás con todas las versiones anteriores de OpenGL, aunque introduce un nuevo mecanismo para despreciar ("deprecate" en inglés) funcionalidad obsoleta y así poder simplificar la API en versiones futuras.

Las principales novedades son:

Sólo el hardware a nivel de DirectX 10 es capaz de ejecutar OpenGL 3.0.

La versión 3.1 (Longs Peak Reloaded) fue publicada el 24 de marzo de 2009, y presenta una serie de características para hacer la API más conveniente de utilizar, además de las características orientadas al rendimiento:


Con la liberación de la especificación OpenGL 3.1, también fue publicada una extensión de compatibilidad que permite a los desarrolladores acceder a la funcionalidad de OpenGL 1.X/2.X eliminada en OpenGL 3.1. En particular, se mantiene funcionalidad "legacy" para una amplia línea de soporte.

Funcionalidad heredada eliminada incluye:


La versión 3.2 fue publicada el 3 de agosto de 2009. Incluye las siguientes características:


Publicada el 11 de marzo de 2010

OpenGL 3.3, simultáneamente lanzado con OpenGL 4.0 y complementada por un conjunto de nuevas extensiones ARB, porta tanta funcionalidad como es posible desde la especificación OpenGL 4.0 para su uso en la generación anterior de hardware GPU. Incluye GLSL 3.30.

Publicada el 11 de marzo de 2010
Tarjetas compatibles: Radeon HD serie 5000, nVidia GTX serie 400;

Características:


Anunciado el 26 de julio de 2010 
Tarjetas soportadas: Nvidia GeForce 400 series, Nvidia GeForce 500 series, ATI Radeon HD 5000 series, AMD Radeon HD 6000 Series

Esta nueva versión añade estas características adicionales a la especificación, muchas de las cuales ayudan a ponerla en consonancia con las de Direct3D 11:

Publicado el 8 de agosto de 2011 
Tarjetas soportadas: Nvidia GeForce 400 series, Nvidia GeForce 500 series, ATI Radeon HD 5000 series, AMD Radeon HD 6000 Series, ATI Radeon HD 7000 series


Publicado el 6 de agosto de 2012
Tarjetas Soportadas: Nvidia GeForce 400 series, Nvidia GeForce 500 series, Nvidia GeForce 600 series

Publicado el 22 de julio de 2013

Publicado el 11 de agosto de 2014

Tarjetas Soportadas: Nvidia GeForce 400 series y nuevas, también Tegra K1 y Tegra X1.


La popularidad de OpenGL se debe en parte a su detallada documentación oficial. El OpenGL ARB ha publicado una serie de manuales actualizados conforme la API iba evolucionando. Son fácilmente reconocibles (y conocidos) por el color de sus tapas:





Para OpenGL 2.0 y posteriores:


El estándar OpenGL permite a los fabricantes añadir nuevas funcionalidades adicionales mediante "extensiones" conforme aparecen nuevas tecnologías. Dichas extensiones pueden introducir nuevas funciones y constantes, y suavizar o incluso eliminar restricciones en funciones ya existentes. Cada fabricante dispone de una abreviatura que le identifica en el nombre de sus nuevas funciones o constantes. Por ejemplo, la abreviatura de NVIDIA ("NV") aparece en la definición de su función "glCombinerParameterfvNV()" y su constante "GL_NORMAL_MAP_NV".

Es posible que varios fabricantes se pongan de acuerdo en implementar la misma funcionalidad extendida. En ese caso, se usa la abreviatura "EXT". Incluso puede ocurrir que el ARB adopte la extensión, convirtiéndose así en estándar y utilizando la abreviatura "ARB" en sus nombres. La primera extensión "ARB" fue "GL_ARB_multitexture", presentada en la versión 1.2.1. Siguiendo el camino marcado por la extensión, el "multitexturing" no es ya una extensión opcional, sino que entró a formar parte del núcleo de OpenGL desde la versión 1.3.

Antes de usar una extensión, los programas deben comprobar su disponibilidad y, después, acceder a las nuevas funcionalidades ofrecidas. Este proceso es dependiente de la plataforma, pero bibliotecas como GLEW y GLEE lo simplifican.

Las especificaciones para la mayor parte de las extensiones pueden encontrarse en el registro oficial de extensiones.

Se han programado varias bibliotecas externas que añaden características no disponibles en el propio OpenGL. Algunas de ellas son:




Para enfatizar las características multilenguaje y multiplataforma de OpenGL, se han desarrollado varios "bindings" en muchos lenguajes. Algunos de los lenguajes para los que están disponibles dichos "bindings" son:



En 2008, algunos de los miembros del Grupo Khronos son:

Para una lista completa y actualizada de los miembros del proyecto, véanse las listas de miembros, contribuyentes y académicos del Grupo Khronos.






</doc>
<doc id="2082" url="https://es.wikipedia.org/wiki?curid=2082" title="Otachyrium">
Otachyrium

Otachyrium es un género de planta con flor, perteneciente a la familia de las poáceas. Es originario de Sudamérica. Comprende 11 especies descritas y de estas solo 8 aceptadas.

El género fue descrito por Christian Gottfried Daniel Nees von Esenbeck y publicado en "Flora Brasiliensis seu Enumeratio Plantarum" 2(1): 271–272. 1829. La especie tipo es: "Otachyrium junceum" Nees. 

A continuación se brinda un listado de las especies del género "Otachyrium" aceptadas hasta abril de 2014, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos.



</doc>
<doc id="2085" url="https://es.wikipedia.org/wiki?curid=2085" title="Orcuttia">
Orcuttia

Orcuttia es un género de planta con flor, perteneciente a la familia de las poáceas. Es originario de California y México.

El género fue descrito por George Vasey y publicado en "Bulletin of the Torrey Botanical Club" 13: 219. 1886. La especie tipo es: "Orcuttia californica" 
El nombre del género fue otorgado en honor de Charles Russell Orcutt, eminente botánico, malacólogo y naturalista estadounidense.



</doc>
<doc id="2086" url="https://es.wikipedia.org/wiki?curid=2086" title="Oplismenus">
Oplismenus

Oplismenopsis es un género de planta con flor, perteneciente a la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo. Comprende 136 especies descritas y de estas solo 7 aceptadas.
Son planta anuales o perennes; con tallos ramificados, decumbentes y enraizando; plantas hermafroditas. Vainas redondeadas; lígula una membrana ciliada; láminas lanceoladas a ovadas, aplanadas. Inflorescencias terminales y axilares, panículas delgadas de racimos cortos, espiciformes, unilaterales, las espiguillas en 2 o 4 hileras a lo largo de los lados inferiores del raquis; espiguillas pareadas, más o menos comprimidas lateralmente, biconvexas, con 2 flósculos; desarticulación por debajo de las glumas y por debajo del flósculo superior; glumas subiguales, más cortas que la espiguilla, herbáceas, 3–5-nervias, carinadas, aristadas; flósculo inferior estéril; lema inferior envolviendo al flósculo superior; pálea inferior ausente o pequeña y hialina; flósculo superior bisexual, comprimido dorsalmente; lema superior más corta que la lema inferior, coriácea; lodículas 2; estambres 3; estilos 2. Fruto una cariopsis; embrión ca 1/2 la longitud de la cariopsis, hilo ca 2/5 la longitud de la cariopsis, linear-oblongo.

El género fue descrito por (Retz.) P.Beauv. y publicado en "Essai d'une Nouvelle Agrostographie" 54,169. 1812. La especie tipo es: "Oplismenus africanus" P. Beauv.
El nombre del género deriva del griego "hoplismenos" (armados), aludiendo a las barbas.

A continuación se brinda un listado de las especies del género "Oplismenus" aceptadas hasta abril de 2014, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos.



</doc>
<doc id="2087" url="https://es.wikipedia.org/wiki?curid=2087" title="Olyra">
Olyra

Olyra, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de África y América tropical.




</doc>
<doc id="2095" url="https://es.wikipedia.org/wiki?curid=2095" title="Ontología">
Ontología

La ontología (del griego οντος 'del ente', genitivo del participio del verbo εἰμί 'ser, estar'; y λóγος 'ciencia, estudio, teoría') es una rama de la metafísica que estudia lo que hay. Intenta responder preguntas generales como: ¿Qué es la materia? ¿Qué es un proceso? ¿Qué es el espacio-tiempo? ¿Hay propiedades emergentes? ¿Se ajustan todos los eventos a alguna(s) ley(es)? ¿Hay especies naturales? ¿Qué hace real a un objeto? ¿Hay causas finales? ¿Es real el azar?

Muchas preguntas tradicionales de la filosofía pueden ser entendidas como preguntas de ontología: ¿Dios existe? ¿Existen entidades mentales, como ideas y pensamientos? ¿Existen entidades abstractas, como los números? ¿Existen los universales?

Además, la ontología estudia la manera en que se relacionan las entidades que existen. Por ejemplo, la relación entre un universal (rojo) y un particular que "lo tiene" (esta manzana), o la relación entre un acto (Sócrates bebió la cicuta) y sus participantes (Sócrates y la cicuta).

Los discípulos de Aristóteles utilizaron el término metafísica por primera vez (literalmente quiere decir "después de la física") para referirse a lo que su maestro describió como "filosofía primera", posteriormente conocida como ontología. La ontología es la investigación del ser en tanto que es, o del ser en general, más allá de cualquier cosa en particular que es o existe. Algunos filósofos, sobre todo de la escuela de Platón, sostienen que todos los sustantivos se refieren a entidades existentes. Otros afirman que los sustantivos no siempre nombran entidades, sino que ofrecen una forma de referencia a una colección de objetos o sucesos. En este sentido, la mente, en lugar de referirse a una entidad, se refiere a una colección de sucesos mentales experimentados por una persona.

Al parecer el primero en usar la expresión “ontología" en sentido filosófico fue el filósofo alemán Jacob Lorhard en su obra "Ogdoas Scholastica" (1606) seguido de Rodolfo Goclenio en su obra "Lexicon philosophicum", ("Léxico Filosófico", en idioma castellano), en el año 1613 con caracteres griegos. Se afirma allí que la ontología es la filosofía del ente.

Después de diversos usos y su paso a caracteres latinos, el matemático y filósofo alemán Gottfried Leibniz usó la expresión en su libro "Introductio ad Encyclopaediam arcanam" (1683) y la define como “ciencia de lo que es y de la nada, del ente y del no ente, de las cosas y de sus modos, de la sustancia y del accidente”. 

Ya como término técnico, es hallada en la obra "Ontologia sive de ente in genere" de Jean Le Clerc publicada en 1692 y el filósofo alemán Christian Wolff la populariza definiéndola como “ciencia del ente en general, en cuanto que ente”. Afirma que usa un método demostrativo o deductivo y analiza los predicados que corresponden al ente en cuanto ente. Todos estos sentidos contribuyeron a identificarla en la práctica con la metafísica.

El problema central de la ontología fue presentado muy elocuentemente por Willard van Orman Quine en su artículo «Sobre lo que hay»:

En general, cada uno de estos "casos particulares" presenta un problema distinto. Desde la segunda mitad del siglo XX, el naturalismo imperante ha determinado que los debates metafísicos sean principalmente acerca de la existencia o no de todo aquello que parece entrar en conflicto con la descripción del mundo provista por las teorías científicas más exitosas. Esto se refleja en la elección de algunos de los casos que se mencionan a continuación:

Dada la acepción cada vez más restringida que la ontología iba tomando, dentro de la Neoescolástica quedó como una investigación de las propiedades estáticas, y en algunos casos las propiedades trascendentales. De ahí que Kant pueda afirmar –trasladando esta noción a su propia filosofía–, que la ontología es el estudio de los conceptos a priori que residen en el entendimiento y tienen su uso en la experiencia, llevando la noción hacia un sentido más inmanente.

Según Husserl la ontología es una ciencia de las esencias que puede ser formal o material. La primera se dedica a las esencias formales, es decir, a las propiedades de todas las esencias. Las ontologías materiales tratan de esencias materiales y se restringen según los modos de sus objetos. Por tanto, son llamadas también “ontologías regionales”. Obviamente la ontología formal abarca todas las materiales e incluso las del ser.

Heidegger, quien estudiaría con Husserl en sus inicios, retoma la pregunta por el ser presente en la Metafísica aristotélica, realizando una crítica a la ontología de la tradición como "onto-teología", e intentando acercarse al ser por medio del ente que existe, el Ser-ahí, el cual podría entenderse como el ser humano. Desarrolla así una ontología originaria llamada “analítica de la existencia” que se encarga de descubrir “la constitución del ser de la existencia”. La ontología se refiere entonces a las condiciones de posibilidad de las existencias o al ser mismo en su apertura originaria. 

Además, insiste en diferenciar la metafísica de la ontología, alegando que son radicalmente distintas, pues la primera confunde ser con ente; mientras que la segunda, parte precisamente del hecho de que son diferentes.

Partiendo de una crítica de la noción de ontología como metafísica y con ella de toda la escolástica, Hartmann afirma que la ontología es en realidad la crítica que permite descubrir los límites de la metafísica y qué contenidos pueden ser considerados racionales o inteligibles.





</doc>
<doc id="2097" url="https://es.wikipedia.org/wiki?curid=2097" title="Oro">
Oro

El oro es un elemento químico de número atómico 79, que está ubicado en el grupo 11 de la tabla periódica. Es un metal precioso blando de color amarillo. Su símbolo es Au (del latín "aurum", ‘brillante amanecer’).

Es un metal de transición blando, brillante, amarillo, pesado, maleable y dúctil. El oro no reacciona con la mayoría de los productos químicos, pero es sensible y soluble al cianuro, al mercurio, al agua regia, al cloro y a la lejía. Este metal se encuentra normalmente en estado puro, en forma de pepitas y depósitos aluviales. Es un elemento que se crea gracias a las condiciones extremas en el núcleo colapsante de las supernovas. Cuando la reacción de una fusión nuclear cesa, las capas superiores de la estrella se desploman sobre el núcleo estelar, comprimiendo y calentando la materia hasta el punto de que los núcleos más ligeros, como por ejemplo el hierro, se fusionan para dar lugar a los metales más pesados (uranio, oro, etc.). Un estudio sugiere que el oro del planeta provino de la colisión de estrellas de neutrones. Otras teorías apuntan a que el oro se forma de gases y líquidos que se elevan desde la estructura interna de la Tierra, los cuales se trasladan a la superficie a través de fallas de la corteza terrestre. Sin embargo, las presiones y temperaturas que se dan en el interior de la Tierra no son suficientes como para dar lugar a la fusión nuclear de la cual surge el oro.

El oro es uno de los metales tradicionalmente empleados para acuñar monedas; se utiliza en la joyería, la industria y la electrónica por su resistencia a la corrosión. Se ha empleado como símbolo de pureza, valor, realeza, etc. El principal objetivo de los alquimistas era producir oro partiendo de otras sustancias como el plomo. Actualmente está comprobado químicamente que es imposible convertir metales inferiores en oro, de modo que la cantidad de oro que existe en el mundo es constante.

En heráldica, representa todo poder económico y es símbolo de vanidad.


El oro ha tenido mucha referencia en sentido figurado en el habla y cultura populares, por ejemplo:

El oro ha sido conocido y utilizado por los artesanos desde el Calcolítico. Artefactos de oro fabricados desde el , como los provenientes de la necrópolis de Varna (primer oro trabajado del mundo), han sido encontrados en los Balcanes. Otros artefactos de oro como los sombreros de oro y el disco de Nebra aparecieron en Europa Central desde el en la Edad del Bronce. El oro se conoce desde la prehistoria. En el Antiguo Egipto, el faraón Dyer (3000 a. C.), llevaba en su título un jeroglífico referente al metal, y también se menciona varias veces en el Antiguo Testamento. Se ha considerado uno de los metales más preciosos a lo largo de la Historia, y como "valor patrón" se ha empleado profusamente, acuñado en monedas.

En la antigüedad algunos creían que ingerir sus alimentos diarios servidos en platos de oro podría prolongar su tiempo de vida y retardar el envejecimiento. También durante la gran peste negra en Europa algunos alquimistas pensaron que podrían curar a los enfermos haciéndoles ingerir oro finamente pulverizado.

El oro es sumamente inactivo. Es inalterable por el aire, el calor, la humedad y la mayoría de los agentes químicos, aunque se disuelve en mezclas que contienen cloruros, bromuros o yoduro. También se disuelve en otras mezclas oxidantes, en cianuros alcalinos y en agua regia, una mezcla de ácido nítrico y ácido clorhídrico, una vez disuelto en agua regia, se obtiene ácido cloroáurico, que se puede transformar en oro metal con disulfito de sodio. El oro se vuelve soluble al estar expuesto al cianuro.

El oro exhibe un color amarillo en bruto. Es considerado como el metal más maleable y dúctil que se conoce. Una onza (31,10 g) de oro puede moldearse en una lámina que cubra 28 m². Como es un metal blando, son frecuentes las aleaciones con otros metales con el fin de proporcionarle dureza.

Además, es un buen conductor del calor y de la electricidad, y no le afecta el aire ni la mayoría de los agentes químicos. Tiene una alta resistencia a la alteración química por parte del calor, la humedad y la mayoría de los agentes corrosivos, y así está bien adaptado a su uso en la acuñación de monedas y en la joyería.

Se trata de un metal muy denso, con un alto punto de fusión y una alta afinidad electrónica. Sus estados de oxidación más importantes son 1+ y 3+. También se encuentra en el estado de oxidación 2+, así como en estados de oxidación superiores, pero es menos frecuente. La estabilidad de especies y compuestos de oro con estado de oxidación III, frente a sus homólogos de grupo, hay que razonarla considerando los efectos relativistas sobre los orbitales 5d del oro.

La química del oro es más diversa que la de la plata, su vecino inmediato de grupo: seis estados de oxidación exhibe –I a III y V. El oro –I y V no tiene contrapartida en la química de la plata. Los efectos relativistas, contracción del orbital 6s, hacen al oro diferente con relación a los elementos más ligeros de su grupo: formación de interacciones Au-Au en complejos polinucleares. Las diferencias entre Ag y Au hay que buscarlas en los efectos relativistas que se ejercen sobre los electrones 5d y 6s del oro. El radio covalente de la tríada de su grupo sigue la tendencia Cu < Ag > Au; el oro tiene un radio covalente ligeramente menor o igual al de la plata en compuestos similares, lo que podemos asignar al fenómeno conocido como “contracción relativista + contracción lantánida”.

Electrones solvatados en amoniaco líquido reducen al oro a Au. En la serie de compuestos MAu (M: Na, K, Rb, Cs) se debilita el carácter metálico desde Na a Cs. El CsAu es un semiconductor con estructura CsCl y se describe mejor como compuesto iónico: CsAu. Hay que resaltar los compuestos iónicos del oro del tipo RbAu y CsAu con estructura tipo CsCl (8:8), ya que se alcanza la configuración tipo pseudogás noble del Hg (de 6s a 6s²) para el ion Au (contracción lantánida + contracción relativista máxima en los elementos Au y Hg). El subnivel 6s se acerca mucho más al núcleo y simultáneamente el 6p se separa por su expansión relativista. Con esto se justifica el comportamiento noble de estos metales. La afinidad electrónica del Au, –222,7 kJ mol, es comparable a la del yodo con –295,3 kJ mol. Recientemente se han caracterizado óxidos (M)AuO(M = Rb, Cs) que también exhiben propiedades semiconductoras.

El oro sólo tiene un isótopo estable,Au, el cual es también su único isótopo de origen natural. 36 radioisótopos han sido sintetizados variando en masa atómica entre 169 y 205. El más estable de éstos es Au con un periodo de semidesintegración de 186,1 días. Au es también el único isótopo que se desintegra por captura electrónica. El menos estable es Au, el cual se desintegra por emisión de protones con un periodo de semidesintegración de 30 µs. La mayoría de radioisótopos del oro con masas atómicas por debajo de 197 se desintegran por alguna combinación de emisión de protones, desintegración α y desintegración β+. Las excepciones son Au, el cual se desintegra por captura electrónica, y Au, el cual tiene un camino de desintegración β- menor. Todos los radioisótopos del oro con masas atómicas por encima de 197 se desintegran por desintegración β-.

Por lo menos 32 isómeros nucleares han sido también caracterizados, variando en masa atómica entre 170 y 200. Dentro de este rango, sólo Au, Au, Au, Au y Au no tienen isómeros. El isómero más estable del oro es Au con un periodo de semidesintegración de 2,27 días. El isómero menos estable del oro es Au con un periodo de semidesintegración de sólo 7 ns. Au tiene tres caminos de desintegración: desintegración β+, transición isomérica y desintegración alfa. Ningún otro isómero o isótopo del oro tiene tres caminos de desintegración.

No existe evidencia del estado de oxidación IV, pero si para el Au(V) en el fluoruro AuF (rojo oscuro, d>60C, inestable, polimérico y diamagnético;su estructura consiste en octaedros AuF unidos por los vértices, generando un polímero monodimensional) y en el anión complejo [AuF] (oxidante fuerte, el más fuerte de las especies metálicas [MF],donde tenemos una configuración de bajo espín d).

El oro forma bastantes complejos pero pocos compuestos sencillos. No se ha aislado un óxido con Au(I), pero si el AuO que contiene Au y Au, pero el estado I solo es estable en estado sólido o en forma de complejos estables como el anión lineal [Au(CN)], ya que en disolución se desproporciona en oro y oro(III).

El óxido AuO se obtiene, como precipitado amorfo, AuO.nHO, de color marrón, en medio alcalino a partir del halurocomplejo planocuadrado [AuCl]. El AuO cristalino, polímero monodimensional, se obtiene mejor por vía hidrotermal y su estructura se genera con grupos planocuadrados [AuO] unidos por vértices; es poco estable, como es de esperar, y descompone en Au y O a 150 °C.

La cloración de polvo de oro a 200 °C da moléculas diméricas planas de AuCl, rojo (d>160 °C), que es el reactivo de partida para preparar muchos compuestos de oro; cuando se calienta a 160 °C produce el AuCl. Se conocen los tres monohaluros AuX (X = Cl, Br, I) cuya estructura se define por cadenas en zig-zag...X-Au-X..., con puentes angulares Au-X-Au (72º-90º).

El ion dicianoaurato [Au(CN)] de gran importancia metalúrgica se forma con facilidad cuando se hace reaccionar oro con disoluciones de cianuros en presencia de aire o agua oxigenada.
El Au(III) es d e isoelectrónico con Pt(II), teniendo sus complejos preferencia por la geometría plana cuadrada. La disolución de oro en agua regia o de AuO en ácido clorhídrico concentrado nos da el ion tetracloroaurato(III), [AuCl], que se usa como “oro líquido” para decorar cerámicas y vidrios, ya que cuando se calienta deja una película de oro. La evaporación de estas disoluciones producen cristales amarillos de (HO)[AuCl].3HO; las disoluciones acuosas de esta sal generan un medio fuertemente ácido. Este anión tetracloroaurato(III),[AuCl], se hidroliza fácilmente a [AuClOH].

El “tricloruro de oro” (AuCl) y el “ácido cloroáurico” ((HO)[AuCl].3HO) son algunos de los compuestos más comunes de oro.

También existen otros aniones planocuadrados del tipo [AuX], siendo X: F,Cl, Br, I, CN, SCN y NO; este último es uno de los pocos ejemplos auténticos donde el ion nitrato actúa como ligando monodentado, al igual que en los complejos equivalentes de Pd(II) y Pt(II).

Por otro lado se conocen cationes complejos con amoniaco, aminas, piridina y con ligandos quelatos como etilendiamina:
[Au(NH)] y [AuCl(py)]. En el complejo [Au Cl (en)] aparece una coordinación rara para el Au(III) en un entorno octaédrico distorsionado.

La mayoría de los compuestos que se cree que contienen oro(II) en realidad son compuestos de valencia mixta, como el dicloruro de oro que en realidad es el tetrámero (Au)(Au)Cl donde aparece Au(III) planocuadrado y Au(I) lineal y su color oscuro se origina por la transferencia de carga entre ambos centros metálicos.

También forma cúmulos de oro (compuestos "clúster"), aspecto desconocido en la química del cobre, su homólogo de grupo más ligero. En este tipo de compuestos hay enlaces entre los átomos de oro que están favorecidos por los efectos relativistas. A algunos de estos compuestos se les denomina “oro líquido”. El clúster trimetálico más voluminoso caracterizado por difracción de rayos-X corresponde al macroanión,[(PhP) AuAgPtCl], en cuya formación juega un rol importante el oro. Éste contiene 25 átomos de elementos vecinos del bloque d y sin participación de metales ligeros de la primera serie de transición: 12Au + 12Ag + 1Pt. Esta clase de clúster queda definida estructuralmente por dos icosaedros AuAg unidos por un vértice común de oro, situándose en el centro de un icosaedro un átomo de platino y en el segundo el atómo central es de oro.

De la producción mundial de oro el 70% se utiliza en joyería, el 20% en reservas e inversiones y solo al 10% se le da usos industriales.

El oro puro o de 24kt es demasiado blando para ser usado normalmente y se endurece aleándolo con plata y/o cobre, con lo cual podrá tener distintos tonos de color o matices. El oro y sus muchas aleaciones se emplean bastante en joyería, en relación con el intercambio monetario (para la fabricación de monedas y como patrón monetario), como mercancía, en medicina, en alimentos y bebidas, en la industria, en electrónica y en química comercial.

El oro se conoce y se aprecia desde tiempos remotos, no solamente por su belleza y resistencia a la corrosión, sino también por ser más fácil de trabajar que otros metales y menos costosa su extracción. Debido a su relativa rareza, comenzó a usarse como moneda de cambio y como referencia en las transacciones monetarias internacionales. Hoy por hoy, los países emplean reservas de oro puro en lingotes que dan cuenta de su riqueza, véase patrón oro.

En joyería fina se denomina oro alto o de 18kt aquél que tiene 18 partes de oro y 6 de otro metal o metales (75 % en oro), oro medio o de 14kt al que tiene 14 partes de oro y 10 de otros metales (58,33 % en oro) y oro bajo o de 10kt al que tiene 10 partes de oro por 14 de otros metales (41,67 % en oro). En joyería, el oro de 18kt es muy brillante y vistoso, pero es caro y poco resistente; el oro medio es el de más amplio uso en joyería, ya que es menos caro que el oro de 18kt y más resistente, y el oro de 10kt es el más simple. Debido a su buena conductividad eléctrica y resistencia a la corrosión, así como una buena combinación de propiedades químicas y físicas, se comenzó a emplear a finales del siglo XX como metal en la industria.

En joyería se utilizan diferentes aleaciones de oro alto para obtener diferentes colores, a saber:

Cabe mencionar que el color que se obtiene, excepto en oro blanco, es predominantemente amarillo, es decir, el “oro verde” no es verde, sino amarillo con una tonalidad verdosa.

El oro no es un elemento esencial para ningún ser vivo. Sin embargo, en la antigüedad algunos creían que ingerir sus alimentos diarios servidos en platos de oro podría prolongar su tiempo de vida y retardar el envejecimiento. También durante la gran peste negra en Europa algunos alquimistas pensaron que podrían curar a los enfermos haciéndoles ingerir oro finamente pulverizado. Todo esto son solo supersticiones.

En la actualidad se le ha dado algunos usos terapéuticos: algunos tiolatos (o parecidos) de oro (I) se emplean como antiinflamatorios en el tratamiento de la artritis reumatoide y otras enfermedades reumáticas. No se conoce bien el funcionamiento de estas sales de oro. El uso de oro en medicina es conocido como crisoterapia.

La mayoría de estos compuestos son poco solubles y es necesario inyectarlos. Algunos son más solubles y se pueden administrar por vía oral. Este tratamiento suele presentar bastantes efectos secundarios, generalmente leves, pero es la principal causa de que los pacientes lo abandonen.

El cuerpo humano no absorbe bien este metal, pero sus compuestos pueden ser tóxicos. Hasta el 50 % de pacientes con artrosis tratados con medicamentos que contenían oro han sufrido daños hepáticos y renales.



Los principales países exportadores del Oro a nivel mundial son Suiza, Reino Unido y Hong Kong. 

Debido a que es relativamente inerte, se suele encontrar como metal, a veces como pepitas grandes, pero generalmente se encuentra en pequeñas inclusiones en algunos minerales, vetas de cuarzo, pizarra, rocas metamórficas y depósitos aluviales originados de estas fuentes. El oro está ampliamente distribuido y a menudo se encuentra asociado a los minerales cuarzo y pirita, y se combina con teluro en los minerales calaverita, silvanita y otros. Los romanos extraían mucho oro de las minas españolas, pero hoy en día muchas de las minas de este país están agotadas.

El oro se extrae por lixiviación con cianuro. El uso del cianuro facilita la oxidación del oro formándose Au (CN) en la disolución. Para separar el oro se vuelve a reducir empleando, por ejemplo, cinc. Se ha intentado reemplazar el cianuro por algún otro ligando debido a los problemas medioambientales que genera, pero o no son rentables o también son tóxicos. En la actualidad hay miles de comunidades en todo el mundo en lucha contra compañías mineras por la defensa de sus formas de vida tradicionales y contra los impactos sociales, económicos y medioambientales que la actividad minera de extracción de oro por lixiviación con cianuro genera en su entorno.

Hay una gran cantidad de oro en los mares y océanos, siendo su concentración de entre 0,1 µg/kg y 2 µg/kg, pero en este caso no hay ningún método rentable para obtenerlo.

El oro puede encontrarse en la naturaleza en los ríos. Algunas piedras de los ríos contienen pepitas de oro en su interior. La fuerza del agua separa las pepitas de la roca y las divide en partículas minúsculas que se depositan en el fondo del cauce.

Los buscadores de oro localizan estas partículas de oro de los ríos mediante la técnica del bateo. El utensilio utilizado es la batea, un recipiente con forma de sartén. La batea se llena con arena y agua del río y se va moviendo provocando que los materiales de mayor peso, como el oro, sean depositados en el fondo y la arena superficial se desprenda.

Así pues, el bateo de oro es una técnica de separación de mezclas heterogéneas.

La producción mundial de oro durante el 2014 alcanzó un total de 2860 toneladas métricas de oro fino. El principal país productor fue China, seguido por Australia y Rusia.

El método de ensayo a fuego consiste en producir una fusión de la muestra usando reactivos fundentes adecuados para obtener dos fases líquidas: una escoria constituida principalmente por silicatos complejos y una fase metálica constituida por plomo, el cual colecta los metales nobles de interés (Au y Ag). Los dos líquidos se separan en dos fases debido a su respectiva inmiscibilidad y gran diferencia de densidad, éstos solidifican al enfriar. El plomo sólido (con los metales nobles colectados) es separado de la escoria como un régulo. Este régulo de plomo obtenido es oxidado en caliente en copela de magnesita y absorbido por ella, quedando en su superficie el botón de oro y plata, elementos que se determinan posteriormente por método gravimétrico (por peso) o mediante espectroscopia de absorción atómica.

Algunos medicamentos como el tiosulfato de oro, la aurotioglucosa, el tiomalato de sodio y oro (miocrisine), etc.; pueden provocar un cuadro de intoxicación por oro. Produciendo efectos adversos como exantemas cutáneos, erupciones papulosas, herpes simple y dermatitis exfoliativa grave. En el sistema digestivo, estos fármacos pueden causar salivación, gusto metálico, náuseas, vómito y diarrea, apareciendo hepatosis y nefritis. En el sistema nervioso puede aparecer anemia aplástica, granulocitopenia y púrpura trombocitopénica. El tratamiento consiste en suspender la medicación, administrar dimercaprol por vía intramuscular y tratar los síntomas.




</doc>
<doc id="2099" url="https://es.wikipedia.org/wiki?curid=2099" title="Orgánico">
Orgánico

Orgánico/a, del griego όργανον (órgnon), hace referencia a varios artículos:





Cuando el adjetivo calificativo «orgánico» alude a lo que tiene vida, es porque están compuestos por carbono () e hidrógeno (). La denominación «orgánica» de tal rama de la química es por virtud de que estos elementos, junto con el oxígeno () y el nitrógeno (), son integrantes esenciales de los seres vivientes. Constituyen el famoso . Por lo tanto su connotación sinónima es sólo parcial. En realidad es un hipónimo.


</doc>
<doc id="2100" url="https://es.wikipedia.org/wiki?curid=2100" title="Ontario">
Ontario

Ontario (pronunciado en inglés //, en francés // y en español //; abreviado con frecuencia "ON" u "ONT") es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. En ella se localizan la mayor ciudad canadiense, Toronto, y Ottawa, la capital. Está ubicada al centro-este del país, limitando al norte con la bahía de Hudson, al este con Quebec, al sur con los Grandes Lagos y el río Niágara que la separan de Estados Unidos, y al oeste con Manitoba. Con 12 891 787 habs. en 2008 —más de un tercio de la población del país— es la entidad más poblada, con 1 076 395 km², la cuarta más extensa —por detrás de Nunavut, Quebec y Territorios del Noroeste— y con 12 hab/km², la tercera más densamente poblada, por detrás de Isla del Príncipe Eduardo y Nueva Escocia. La región sur de Ontario alberga al punto más meridional de todo Canadá.

La principal fuente de ingresos de Ontario es la industria. El valor de los productos industriales producidos en Ontario es mayor que la suma del valor total de los productos industriales fabricados en todas las otras provincias y territorios de Canadá. La fuerza de su industria manufacturera le valió el apodo de "Manufacturing Heartland of Canada" (Corazón Industrial de Canadá).La provincia se destaca principalmente por su fuerte industria automotriz —la más competitiva de todo el continente americano a excepción de Míchigan de los Estados Unidos. Otras fuentes importantes de ingresos son el turismo y la prestación de servicios financieros e inmobiliarios.

El origen de su nombre deriva del lago del mismo nombre, el lago Ontario, nombre dado por los iroqueses, que significa «lago hermoso» o «aguas brillantes». Ontario fue colonizado inicialmente por los franceses, pasando a formar parte de la colonia francesa de Canadá, una de las provincias coloniales de Nueva Francia, que entonces incluía la región sur de las actuales provincias canadienses de Ontario y de Quebec.

En 1763, el Reino de Gran Bretaña anexó Canadá. En tres décadas, los anglófonos se convirtieron en mayoría en el suroeste de la colonia, motivo por el cual el Reino Unido decidió dividir la colonia en dos en 1791. Ambas divisiones fueron reunidas nuevamente en 1840, en una única provincia de Canadá. Con la independencia de Canadá, el 1 de julio de 1867, la provincia de Canadá fue definitivamente separada en dos, en las actuales provincias de Ontario y de Quebec. En sus inicios una potencia agraria, Ontario pasó a ser un gran centro industrial a comienzos del siglo XX, y se convirtió en el principal centro económico del país durante las décadas de 1960 y de 1970.

En agosto de 2006, residían en la provincia 12.792.619 ontarienses, lo que representa aproximadamente el 37,9% de la población total canadiense, repartidos por un área de 1.076.395 km².

Antes de la llegada de los primeros exploradores europeos, la región que actualmente constituye la provincia de Ontario estaba habitada por diversas tribus nativas americanas, pertenecientes a tres familias.Los chippewa vivían al norte y al noreste del lago Superior, y cazaban y recolectaban frutas para su sustentación. Los hurones vivían en la región del lago Hurón y del lago Ontario, y vivían principalmente de la agricultura. Tanto los chippewas como los hurones temían a los iroqueses, una familia nativa americana compuesta por seis tribus aliadas entre sí, de carácter nómada y altamente agresivo, que constantemente los atacaban.

El francés Étienne Brûlé fue el primer europeo en explorar la región, haciéndolo en 1613, por orden de Samuel de Champlain, el fundador del Quebec. Ese año, Brûlé alcanzó la margen sur del río Ottawa, en la región donde actualmente se localiza la capital canadiense, Ottawa. En 1615, Brûlé había alcanzado el lago Hurón. Brûlé y Champlain observaron que la región era abundante en animales como los castores, cuya piel era muy apreciada en el continente europeo. Los cazadores franceses comenzaron a cazar animales de la región a partir de la década de 1620, al mismo tiempo en que los comerciantes franceses pasaron a comercializar con los hurones pieles de animales. Durante la década de 1630, otros exploradores franceses exploraron la región del sur de los Grandes Lagos. La región que actualmente constituye el sur de Ontario pasó a formar parte de la colonia francesa de Nueva Francia.

Los misioneros franceses —acompañados de algunas familias francesas— fundaron algunas villas a lo largo de la región, tales como el "Fort Sainte Marie", donde están localizadas actualmente las ciudades de Sault Ste. Marie, Ontario y Sault Ste. Marie, Míchigan.El principal objetivo de los misioneros era convertir a los nativos de la región, como los hurones, al cristianismo, así como que asimilaran la cultura europea. Sin embargo, los ataques iroqueses forzaron a estos misioneros y a los colonos a abandonar estas villas. Los franceses continuarían explorando a lo largo de la década de 1610 la región del norte de los Grandes Lagos.

La expansión de Nueva Francia —que hasta la década de 1620 estaba limitada la región que actualmente constituye las provincias canadienses de Quebec, Nuevo Brunswick y Nueva Escocia— en dirección al noroeste, al oeste y al sur alarmó al Reino Unido, lo que hizo que los británicos crearan la Compañía de la Bahía de Hudson en 1670. Los británicos se aliaron eventualmente con los iroqueses. Ambos atacarían constantemente a los villorrios y a los comerciantes franceses de toda Nueva Francia. En 1754 comenzó la guerra entre los franceses y los británicos. Los franceses perdieron la guerra. En el Tratado de París (1763), Francia cedía todas las colonias francesas localizadas al norte de los Grandes Lagos —las colonias de Acadia (actuales Nueva Brunswick y Nueva Escocia) y de Canadá —que constituía lo que actualmente es el sur de las provincias de Ontario y de Quebec.

Hasta entonces, los únicos villorrios franceses en lo que actualmente es Ontario estaban localizados donde hoy están las ciudades de Niagara Falls, Kingston y Windsor. Hasta 1784, el crecimiento demográfico de la región de Ontario, aún parte de la colonia inglesa de Canadá, era muy pequeño. A partir de 1784, con el fin de la Revolución Americana de 1776, cerca de 10 mil colonos americanos, leales a la Corona británica, emigraron hacia el sur de la colonia de Canadá. Luego, el número de anglófonos en el sur de Canadá era mayor que el número de francófonos. Estos colonos recibieron de los británicos tierras, refugio, comida, ropas y otras ayudas.

En 1791, el Reino Unido dividió la colonia de Canadá en dos, Canadá Inferior (el actual Quebec) y Canadá Superior (el actual Ontario). Ambas estaban divididas por el río Ottawa. Niagara-on-the-Lake fue elegida capital de la recién creada colonia. El Reino Unido sería el encargado de escoger al nuevo Teniente Gobernador. El primer Teniente Gobernador de Canadá Superior fue John Graves Simcoe. Simcoe construyó varias carreteras a lo largo de Canadá Superior, y promovió el mayor poblamiento de la colonia. Simcoe eventualmente decidió cambiar la capital de la colonia, Niagara-on-the-Lake, a York, actual Toronto. En 1797, todos los puestos gubernamentales habían efectuado su transferencia de Niagara a York.

La población de Canadá Superior comenzó a crecer gradualmente. Muchos de estos colonos eran inmigrantes europeos (mayoritariamente ingleses y escoceses) que habían llegado recientemente a Estados Unidos, mientras que muchos otros eran americanos. Varios de estos colonos vinieron a Canadá Superior en grupos y a su propia suerte. A otros tantos los traían compañías especializadas. Estas compañías eran dueñas de granjas en la colonia, y estos colonos eran traídos como mano de obra. Algunos de los colonos americanos más ricos vinieron al Canadá Superior por las tierras. Hubo incluso el caso de una villa en Pensilvania, cuya población emigró por completo a Canadá Superior, instalándose en lo que es actualmente la ciudad de Waterloo.

En 1812, se inició la guerra de 1812. Los Estados Unidos de América invadieron Canadá Superior, y tomaron y quemaron su capital, York. En 1814, las tropas británicas, junto con la milicia canadiense, expulsaron a los estadounidenses de la colonia. La guerra acabó en 1815, en "statu quo". La población de Canadá Superior y de Canadá Inferior comenzó a desarrollar sentimientos anti-estadounidenses, tales como un sentimiento antidemocrático (Estados Unidos, en aquella época, era el único país del mundo que había adoptado la democracia como forma de gobierno). Este sentimiento antidemocrático tuvo un gran peso en 1837, cuando tuvo lugar la Rebelión de Canadá Superior. Durante la década de 1830, la población de Canadá Inferior comenzó a sentirse molesta por el inmenso poder que los británicos tenían en la región —los británicos elegían al Teniente Gobernador de la colonia, y éste tenía un gran poder en la región. La rebelión fue liderada por William Lyon Mackenzie. Esta rebelión pedía mayores poderes para el gobierno colonial, aunque no ganó popularidad entre la población local, por ser vista como "un ataque de la democracia a la monarquía". Esta rebelión fue rápidamente reducida, no por tropas británicas, sino por una milicia canadiense. Mackenzie huyó a Estados Unidos, mientras que otros líderes de la rebelión fueron ejecutados.

En 1840, el Reino Unido decidió unir Canadá Superior y Canadá Inferior en una única colonia, la colonia del Canadá. En 1841, se efectuó esta fusión. Su objetivo era forzar una asimilación cultural de los francófonos por parte de los anglófonos. Alarmada por la guerra, los británicos cedieron a la nueva colonia el derecho de formar un gobierno basado en el parlamentarismo, que tendría poderes sobre asuntos relacionados exclusivamente con Canadá. Canadá Superior y Canadá Inferior tendrían el mismo número de escaños en la Asamblea Legislativa.

Entre la década de 1820 y la década de 1850, la región de Ontario recibió un gran número de inmigrantes ingleses e irlandeses. La población anglófona de la colonia de Canadá creció rápidamente, y, en la década de 1850, ya había sobrepasado en número a la población francófona, generando una crisis política y social entre la población anglófona, que se sentía menospreciada por el hecho de los francófonos tuviesen el mismo número de escaños en la Asamblea, aun teniendo una población menor, y entre la población francófona, que temía una posible asimilación de la cultura anglófona.

En 1864, políticos de la colonia de Canadá se reunieron con políticos de las colonias británicas de Isla del Príncipe Eduardo, Nuevo Brunswick, Nueva Escocia y Terranova y Labrador, en tres encuentros diferentes. Los políticos de Canadá propusieron a las otras colonias británicas la formación de una Confederación. De estas colonias, Nuevo Brunswick y Nueva Escocia aceptaron la propuesta de Canadá. El 1 de julio de 1867, se crea la Confederación canadiense. La ex-colonia de Canadá fue dividida en dos: Ontario y Quebec. Estas dos, más Nuevo Brunswick y Nueva Escocia, fueron los cuatro miembros fundadores de Canadá.

En 1868 se crea el escudo y lema de Ontario. Como curiosidad decir que el lema ("Ut incepit fidelis sic permanent") fue añadido al escudo por Sir Henry William Stisted, Primer Gobernador de Ontario; quien fuera gran amigo del General José de Bascarán y Federic (XVII Señor de Olvera). En una de sus visitas a este, Sir Stisted observó el citado lema en el escudo heráldico que presidía el salón de la casa del General Bascarán y tras pensar que representaba a la perfección los sentimientos de los ontareños le solicitó a su amigo la pertinente autorización para incluirlo en el escudo de la ciudad canadiense. De ahí que el lema de Ontario sea el mismo que el del Señorío de Olvera.
El juez Oliver Mowat, segundo gobernador de Ontario, luchó en el Parlamento de Canadá por mayores derechos y poderes para los gobiernos provinciales. Asumió el gobierno de Ontario en 1872, gobernando hasta 1896.

La población y la economía de Ontario crecieron lentamente en sus dos primeras décadas como provincia. A pesar de que la agricultura se hubiese fortalecido en la región, y de que se hubieran desarrollado algunas industrias, muchas personas dejaron Ontario —así como Canadá— y marcharon a Estados Unidos, en busca de mejores salarios y condiciones de vida.

Finalmente, la agricultura de Ontario, gracias al empleo de modernas prácticas agro-ganaderas (en aquella época), se convierte en la mayor fuente de ingresos de la provincia hasta la década de 1910. En 1883, se descubre la mayor mina de aluminio y de zinc del mundo (de aquella época), en Sudbury. Estas minas permanecieron intactas durante nueve años, hasta que fuese descubierto un proceso barato y eficiente para separar el aluminio del zinc. La minería de estos minerales se inició en 1892, e inmediatamente convirtió en una de las principales fuentes de ingresos de la provincia.

La economía de Ontario pasó a desarrollarse rápidamente desde comienzos del siglo XX. Siguieron descubriéndose varias minas, en especial de oro y plata. Al mismo tiempo, se crearon fábricas y centrales hidroeléctricas, estimulando así el crecimiento demográfico de la provincia. La industria maderera también se hizo importante. Con el inicio de la Primera Guerra Mundial, en 1914, en la cual Canadá participó activamente, la economía de Ontario creció rápidamente, con la construcción de varias fábricas en diversas ciudades. Al final de la guerra, en 1918, estas fábricas, que anteriormente fabricaban armas y materiales militares, pasaron paulatinamente a fabricar automóviles y equipamientos de comunicación tales como radios y teléfonos. Este crecimiento económico, estimulado también por el descubrimiento de minas de hierro en el norte de la provincia, atrajeron a numerosos inmigrantes; finlandeses, noruegos y quebequeses emigraron en gran número hacia Ontario. En esta época, Ontario —anteriormente una pequeña franja de tierra que se extendía por el este del lago Hurón hasta el Quebec— se había expandido hasta llegar a sus límites actuales.

La Gran Depresión puso fin a este crecimiento económico. El problema del desempleo pasó a ser un gran problema —las tasas de desempleo llegaron a un máximo del 30%. Varias empresas quebraron, muchas fábricas y tiendas cerraron, mientras que otras empresas y tiendas comenzaron a despedir trabajadores para recortar costes. Las granjas acumularon grandes deudas. A pesar de esto, el crecimiento demográfico de Ontario creció de la misma manera, a causa de los emigrantes venidos de otras partes de Canadá, con la esperanza de encontrar empleo en una de las grandes ciudades de la provincia, y por la llegada de judíos alemanes a partir de 1933, cuando el régimen nazi de Adolf Hitler subió al poder en Alemania. Esta depresión terminó en 1939, con el inicio de la Segunda Guerra Mundial, cuando Ontario volvió a conocer un gran crecimiento económico.

Con el fin de la Segunda Guerra Mundial en 1945, Ontario recibió muchos inmigrantes de varios países europeos, que estaban arruinados a causa de la guerra. Un gran número de ingleses, alemanes, escoceses, polacos y neerlandeses emigraron a Canadá. Entre 1945 y 1970, la población de la provincia aumentó de 4,5 millones a más de 7 millones de habitantes. Esta época también fue de gran desarrollo económico, el mayor de toda la historia de Ontario. En tan sólo cinco años, entre 1945 y 1950, la producción industrial de la provincia se duplicó, y se duplicaría otra vez más entre 1950 y 1960.

En 1945, se construye la primera central nuclear canadiense, en 1952 se encuentra la mayor mina de uranio del mundo en Elliot Lake, en 1960 se inaugura el primer acelerador de partículas del país, en la década de 1950 se construyen varios gasoductos, y en 1960, Hamilton se convierte en el mayor centro siderúgico de América del Norte, sobrepasando a Pittsburgh. En 1962, se inaugura en Rolphton la primera central nuclear para generación de electricidad para uso comercial. En 1967, se construye una nueva central nuclear en Darlington, y en 1971, se inaugura otra más en Pickering. Todos estos eventos ocurrieron en Ontario, entre las décadas de 1940 y 1970.

En 1965, los gobiernos canadiense y americano suscribieron un tratado de libre comercio para los automóviles en general. Esto benefició a Ontario, que entonces ya era un gran centro industrial automovilístico. Este gran crecimiento económico convirtió gradualmente a Toronto en el principal centro financiero e industrial de Canadá. Paulatinamente, las empresas anteriormente radicadas en Montreal comenzaron a transferir sus sedes a Toronto. Además de eso, la aprobación de la Ley 101 en 1977 - que convertía en obligatorio el uso del francés en todas las empresas con más de 50 operarios instaladas en el Quebec - hizo que varias instituciones financieras se mudaran de Montreal a Toronto. La bolsa de valores de Toronto pasó a ser la única oficial para las transacciones internacionales en 1999, sustituyendo a la de Montreal.

En 1972, el gobierno de Ontario comenzó a cubrir los servicios hospitalarios para los ancianos y los pobres. En tres años, esta cobertura se extendió a todos los habitantes de la provincia. En la década de 1970, Ontario se convirtió en un centro turístico cada vez más conocido mundialmente, haciendo del turismo una fuente de ingresos cada vez más importante en la economía de la provincia. Durante la década de 1970, y hasta el comienzo de la década de 1980, Canadá pasó por una gran recesión económica. Los efectos de esta recesión tuvieron menos efectos en Ontario que en el resto del país gracias a la diversidad y a la fuerza de su economía.

Sin embargo, Ontario enfrentó serios problemas durante la década de 1980 y los primeros años de la década de 1990, cuando el déficit provincial y las deudas de la provincia crecieron drásticamente, disminuyendo el crecimiento de la economía de Ontario. En 1995, Michael Harris se convirtió en gobernador de Ontario. Harris recortó gastos provinciales en el área de salud, educación y bienestar social, así como recortes en los presupuestos destinados a las ciudades. Harris también disminuyó el impuesto sobre la renta de la provincia, en una tentativa de crear puestos de empleo. Estas medidas surtieron efecto, y la economía de Ontario volvió a crecer.

En 1997, el gobierno de Ontario decidió fusionar la ciudad de Toronto con otras 5 ciudades vecinas, en una única Ciudad de Toronto. Este cambio ocurrió en 1998. En 1999, el gobierno de la provincia efectuó fusiones semejantes en Ottawa, Greater Sudbury y Hamilton (tales fusiones tuvieron efecto en 2001). En 2003, la economía de la provincia entró de nuevo en declive, con la amenaza de la neumonía asiática que contagió a centenares de habitantes en Toronto, y mató a 44 personas. Sólo a partir de 2005 la economía de Ontario volvió de nuevo a crecer.

Ontario limita al norte con la bahía de Hudson y la bahía de James, al este con Quebec, al oeste con Manitoba y al sur con los Estados americanos de Minnesota, Míchigan, Ohio, Pensilvania y Nueva York. La larga frontera entre Ontario y Estados Unidos está delimitada en gran parte por obstáculos naturales como lagos y ríos. La serie de estos obstáculos naturales comienza en el "Lake of the Woods", pasa por los Grandes Lagos (Superior, Hurón, Erie y Ontario), y termina en el río San Lorenzo.

Ontario posee vastos bosques boreales, que cubren aproximadamente dos quintos de la provincia —466 mil km² de 1.076 mil km².

Podemos dividir la provincia en cuatro grandes regiones geográficas:


El litoral de Ontario posee 3.840 kilómetros, a lo largo de los lagos Superior, Hurón, Erie y Ontario. Contando todas las regiones bañadas por los Grandes Lagos —bahías, estuarios e islas a lo largo del litoral de la provincia con los Grandes Lagos— este número aumenta a 8.452. La mayor isla del mundo en estar totalmente localizada dentro de un continente es la Isla Manitoulin, localizada en el lago Hurón, con 2.765 km² de área. Gran parte de la provincia está cubierta por ríos y lagos. En total, los cuerpos de agua cubren aproximadamente un 14,7% de la provincia, o lo que es lo mismo, un sexto de Ontario. La provincia posee más de 250.000 lagos, y más de 100.000 kilómetros de ríos.

Los Grandes Lagos cubren cerca de la mitad la superficie total de los aproximadamente 177.390 km² de aguas interiores. Precisamente, han sido el río San Lorenzo y los Grandes Lagos los que han atraído a exploradores, comerciantes, soldados y colonos hacia el corazón del continente. Más recientemente, los numerosos lagos y ríos de Ontario han permitido la explotación de la energía hidroeléctrica y el desarrollo de una mayor industrialización.

Las abundantes lluvias alimentan los cursos de agua de la provincia de Ontario (en la mayoría de las regiones de la provincia es precipitación de nieve). Las precipitaciones son bastante regulares en el sur y el centro, en donde las variaciones entre el invierno y el verano o entre la primavera y el otoño no son particularmente destacables. No obstante, las precipitaciones invernales y primaverales son menos abundantes en el norte y el noroeste.

La cuenca de los Grandes Lagos drena la mayor parte de las aguas de la mitad sur de la provincia a lo largo de la frontera sur, lo que representa un caudal anual medio de 5.700 m³/s de agua hacia el río Niágara.

Al contrario que los ríos que conectan los Grandes Lagos, y cuyo volumen de agua no experimenta grandes variaciones de un mes a otro, los ríos interiores aumentan el suyo durante la época de deshielo, con el consiguiente riesgo de inundaciones.

Ontario posee en su mayor parte un clima templado, si bien las regiones en el extremo norte de la provincia poseen un clima semi-polar. La presencia de los Grandes Lagos suavizan los inviernos a lo largo del litoral de los mismos. La temperatura media baja a la medida en que aumenta la latitud. El sur de Ontario en general posee veranos cálidos e inviernos fríos. En el norte de la provincia hace frío durante casi todo el año.

Las temperaturas medias del sur de la provincia, en invierno, son de -8°C, con mínimas entre -42 °C y 1 °C, y máximas entre -35 °C y 12 °C. La media de las máximas es de -1 °C, y la media de las mínimas es de -8 °C. En verano, el sur de la provincia registra máximas de hasta 38 °C, y mínimas de hasta 9 °C. La media de las máximas es de 26 °C, y de las mínimas, de 15 °C. En el extremo norte de la provincia, la temperatura media en invierno es de -25 °C, y, en verano, de 7 °C. La mayor temperatura registrada fue de 42 °C, medida en Atikokan, los días 11 y 12 de julio de 1936, y en Fort Frances, el 13 de julio de 1936. La menor temperatura registrada fue de -58 °C, en Iroquois Falls, el 23 de enero de 1935.

Las tasas de precipitación media anual de lluvia varían entre 60 y 70 centímetros en el norte de la provincia, y entre 80 y 90 centímetros en el sur. En invierno, en el sur de la provincia, nieva de media cada 2 días. Las tasas de precipitación media anual de nieve varían entre 123 centímetros en el extremo norte hasta 267 centímetros en el sur de Ontario.

El clima relativamente templado del sur de la provincia permite el desarrollo de una amplia variedad de plantas, tanto nativas como procedentes de Europa. 

Muchas especies de aves migratorias atraviesan Ontario cada año: Point Pelee es el punto de encuentro de las mariposas monarca en su migración anual. En la localidad de Aylmer suelen hacer una parada los 60.000 cisnes de la tundra que emigran al Ártico todos los años.

Las especies acuáticas más comunes en los ríos y lagos de la provincia son el lucio norteamericano y la trucha. En el norte viven caribúes, alces, bueyes almizcleros, castores, águilas y lobos. Los osos polares viven en el extremo norte, a lo largo de la bahía de Hudson.

Ottawa, la capital de Canadá, se localiza en Ontario, en el extremo oriental de la provincia, en la frontera de Ontario con Quebec. La capital de Ontario es Toronto.

El mayor oficial de Ontario, en teoría, es el Teniente Gobernador ("Lieutenant Governor"). El Teniente Gobernador representa al jefe de estado de Canadá, actualmente, la Reina Isabel II, y es elegido por el Primer Ministro de Canadá, junto con el Gobernador de la provincia.Sin embargo, el Teniente Gobernador no posee ningún poder teórico en la política de la provincia. En la práctica, el líder de Ontario es el Gobernador "(Premier)". Desde el inicio de la historia de Ontario como provincia de Canadá, el título oficial de este Gobernador era "Premier". En 1906, este título fue cambiado a "Prime-Minister", primer ministro. En 1972, el primer ministro provincial de Ontario decidió volver a llamar a este título "Premier".

Las elecciones provinciales tienen lugar generalmente cada cinco años, aunque en ocasiones, especialmente cuando el partido político en el poder no mantenga suficiente apoyo popular o político, puedan ocurrir antes de este plazo —caso de que el Teniente Gobernador, indicado por el Gobernador, así lo desee. Ontario está dividido en 103 distritos electorales. Durante las elecciones, los electores de cada distrito —que deben tener más de 18 años y ser ciudadanos canadienses para poder votar— votan a un representante. El vencedor de las elecciones en un distrito electoral dado representará a dicho distrito en la Asamblea Legislativa de la provincia. El Gobernador de Ontario será el líder del partido político que, al final de las elecciones, posea más miembros en la Asamblea Legislativa.
El poder legislativo de Ontario es la Asamblea Legislativa, que tiene el poder de crear y aprobar las leyes provinciales. Está compuesta por 103 miembros, cada uno representante de cada uno de los 103 distritos electorales de la provincia. El período de oficio máximo de los miembros de la Asamblea, así como también del Gobernador, es de 5 años. Antes de las elecciones, la Asamblea se disuelve. Todos los miembros de la Asamblea, incluyendo el Gobernador, pueden participar en las elecciones cuantas veces quieran.

En el año fiscal de 2006, el 75% de todos los ingresos presupuestarios del gobierno de Ontario provenían de los impuestos provinciales, tales como el impuesto sobre la renta o impuestos sobre el valor añadido. Lo restante viene de presupuestos recibidos del gobierno federal y de préstamos.

Ontario posee dos niveles básicos de subdivisiones políticas, llamadas regiones administrativas o divisiones de censo. Las municipalidades regionales, los condados y los distritos son subdivisiones que agrupan varios a municipios. Los habitantes de un municipio dado dentro de estas subdivisiones mencionadas más arriba reciben servicios gubernamentales tanto del municipio como de estas subdivisiones —excepto en el caso de los distritos, donde son las ciudades o la provincia de Ontario las que proporcionan todos los servicios públicos. Los habitantes de municipalidades-independientes, que no forman parte de ninguna de las subdivisiones mencionadas arriba, reciben servicios sólo de dicha municipalidad, y no del municipio, en caso de que la municipalidad en cuestión agrupe a más de una villa o ciudad. La mayoría de estas municipalidades, sin embargo, están compuestas por una única ciudad, y por lo tanto pueden ser consideradas también como una ciudad propiamente dicha.

En 1996, el número de municipios de la provincia era de 815 y el número de municipalidades regionales, de 13. Desde 1996, la provincia de Ontario ha fusionado varias de estos municipios y municipalidades entre sí. El número de municipios fue reducido a 447 y el número de municipalidades regionales a ocho. Además de eso, se crearon cuatro ciudades independientes, resultantes de la fusión de varios municipios en una única gran ciudad: Toronto, Ottawa, Sudbury y Hamilton. También se añadieron dos nuevos condados. La mitad de todos los municipios de Ontario posee menos de cinco mil habitantes. La mayor parte del norte de la provincia, por estar tan escasamente poblada, no está organizada en subdivisiones tales como condados o municipalidades regionales.

Los condados y las municipalidades regionales proporcionan servicios regionales tales como vigilancia policial, vivienda y educación, para las ciudades y las villas vecinas que son demasiado pequeñas para acarrear con los costes de estos servicios.

La política de Ontario se ha caracterizado siempre por su sistema tripartito. En las últimas décadas, el Partido Liberal de Ontario, el Partido Progresista Conservador de Ontario y el Nuevo Partido Democrático de Ontario han gobernado la provincia al menos una vez.

Actualmente Ontario está bajo un gobierno liberal encabezado por el "Premier" Dalton McGuinty.

En el campo federal, Ontario es conocida por ser la provincia que ofrece más apoyo al Partido Liberal de Canadá. La mayoría de los 101 escaños actuales del partido en la Cámara de los Comunes de Canadá provienen de Ontario. Dado que Ontario cuenta con más escaños que cualquier otra provincia de Canadá, ganar votos en esta provincia es crucial para cualquier partido que aspire ganar unas elecciones federales.

Ontario es la provincia más poblada de Canadá. Más del 80% de la población de Ontario vive en ciudades, y esta tasa está aumentando. Esta provincia posee más grandes ciudades que cualquier otra provincia canadiense.

El censo nacional canadiense de 2001 estimó la población de Ontario en 11.410.046 habitantes, un crecimiento del 6% sobre la estimación del censo de 1996, de 10.753.573 habitantes. Más del 92% de la población de la provincia vive en una estrecha franja que va de Windsor hasta Ottawa. Esta región comprende sólo un 12% del área de Ontario. La región metropolitana de Toronto concentra, sola, 5,6 millones de habitantes, y la región metropolitana de Ottawa posee otros 1,1 millones.

"Fuente: Statistics Canada"

Composición racial de la población de Ontario:

Los mayores grupos étnicos que componen la población de Ontario son los ingleses, escoceses, irlandeses, franceses, alemanes, italianos, chinos.

Ontario posee aproximadamente 66 mil nativos indígenas. Un 45% de ellos vive en una de las 186 reservas indígenas administradas por la provincia, que cubren un total de más de 700 mil hectáreas. Otros 150 mil habitantes de la provincia poseen ascendencia indígena.

En 2001, el 71,6% de los habitantes de Ontario tenía como lengua materna el inglés. Entre el resto de la población, el 4,4% hablaba francés como lengua materna y el 23,7% tenía otra lengua materna.

El inglés es la única lengua oficial, aunque los francófonos de Ontario desempeñan un papel esencial en la vida cultural de la provincia y conforman la mayor minoría lingüística. El gobierno provincial proporciona servicios en francés en las regiones donde la población francófona es lo suficientemente alta, como es el caso de la ciudad de Ottawa, donde el francés y el inglés son cooficiales. Toronto tiene más hablantes de italiano que cualquier otra ciudad fuera de Italia.

Los principales grupos religiosos de Ontario son:



Ontario es una de las subdivisiones nacionales más ricas y prósperas económicamente de América del Norte, gracias a su economía fuerte y variada, a su población en gradual crecimiento y a la existencia de mano de obra cualificada. El producto interior bruto de Ontario en 2003 fue de 538.386 millones de dólares canadienses (39,3% de Canadá) y la renta per cápita, de 33.428 dólares. Por su parte, la tasa de desempleo se situaba en el 6,6%. La economía de Ontario se beneficia de su proximidad a los grandes centros de consumo de Estados Unidos. La provincia canadiense está próxima a varias grandes ciudades americanas, mercados en potencia para los productos canadienses.



La industria constructora emplea aproximadamente a 325 mil personas y es responsable de aproximadamente un 4,5% del PIB de la provincia. Y la minería, anteriormente una de las principales fuentes de ingresos de la provincia, entró progresivamente en declive con la diversificación de la economía de Ontario y con la creciente modernización en esta área en las últimas décadas —actualmente, la minería corresponde a sólo un 1% del PIB de Ontario, empleando a cerca de 35,2 mil personas. La provincia posee grandes reservas de níquel —un octavo del níquel del mundo es producido en Ontario— cobalto, cobre, oro, plata y zinc.


En otra época el sector dominante, la agricultura ocupa hoy a un pequeño porcentaje de la población. La cantidad de granjas ha disminuido de 68.633 en 1991 a 59.728 en 2001,aunque han aumentado en tamaño medio y muchas otras se están mecanizando. Las granjas de ganado, los graneros y las lecherías eran los tipos más comunes según el censo de 2001. La industria del cultivo de fruta, uva y verdura se localiza principalmente en la península de Niágara y a lo largo del lago Erie, donde también están situadas las granjas de tabaco. La producción de tabaco ha disminuido notablemente, lo que ha conducido a un aumento de nuevas alternativas de cultivos que están ganando una gran popularidad, como las avellanas o el ginseng. La Massey Ferguson Ltd., una de las mayores empresas fabricantes de herramientas agrícolas del mundo, surgió en Ontario, lo que pone de relieve la importancia que tuvo antaño la agricultura en la economía de la provincia.

Los bosques cubren 700 millones de hectáreas de la superficie de la provincia (el 65%), de los cuales sólo un tercio está calificado como explotable. La mayor parte (90%) pertenece a la provincia, lo que significa que las compañías madereras deben obtener una autorización del gobierno antes de comenzar cualquier actividad de explotación. En 2001, los beneficios provenientes de esta industria ascendieron a 18.000 millones de dólares. Más de 90% de la producción de papel y pulpa de papel se destina al mercado americano.

La antaño próspera industria pesquera de Ontario ha conocido una debacle considerable. Esto es debido, entre otros factores, a las capturas excesivas y al deterioro de la calidad del agua del lago Erie.

A causa de este declive, este sector tiene una contribución muy pequeña a la economía provincial, aunque todavía es una importante fuente de ingresos en las comunidades del norte. La modesta industria de la pesca comercial de Ontario ha sido víctima de la contaminación del medio hídrico, que también afecta a la pesca deportiva, una actividad muy popular en los ríos y lagos de la provincia, con 814.887 practicantes habituales en 2000.

Ontario ha sido desde siempre la provincia industrial por excelencia de Canadá. Ya lo era en la época de la Confederación, y esta tendencia ha favorecido después el posterior desarrollo industrial de la provincia, gracias a su eficiente red de transportes, abundantes recursos naturales y la proximidad al mercado estadounidense. El valor total de los productos fabricados en Ontario en 2005 fue de 300 millones de dólares canadienses, lo que supone el 51% de los productos elaborados de Canadá. En Toronto se encuentran las sedes de una gran cantidad de compañías canadienses del sector industrial. Además, el hecho de que la provincia se encuentre próxima a los principales centros de la industria automovilística estadounidense (caso de Detroit, por ejemplo) también ha favorecido la implantación de fábricas allí.

El Área Metropolitana de Toronto es la zona industrialmente más dinámica, con la mitad de todas las industrias manufactureras de la provincia, seguida de Hamilton, Windsor, St. Catharines-Niagara y London. A finales de los años 70, Ottawa fue perfilándose como centro industrial de la alta tecnología de Canadá, al estilo del Silicon Valley californiano. La provincia cuenta cerca del 60% de las industrias de tecnología punta de Canadá.

El desarrollo de la industria minera está estrechamente ligado a la consolidación de Toronto como centro financiero de Ontario y de Canadá. El níquel estimuló la prosperidad de la región de Sudbury. A principios de siglo, los yacimientos de plata, plomo y cinc atraen a los buscadores a la localidad de Cobalt, y el oro contribuye a estimular la actividad económica de la provincia (y, en cierta medida, del país) durante los años 30. En los años 50, el descubrimiento de un filón de uranio excepcionalmente rico en Elliot Lake impulsa de nuevo la economía de Ontario.

Las minas han desempeñado desde siempre un rol fundamental en la economía de la provincia, aunque ha conocido épocas de crisis en los años 80 y comienzo de los 90, cuando el mercado internacional registró una bajada en todos los sectores mineros. A pesar de todo, en 2005, el valor de toda la producción minera en Ontario ascendía a 7.220 millones de dólares, de la cual los minerales metálicos representaban el 66 por ciento y los minerales no metálicos, el 34 por ciento. Aquel mismo año, la provincia produjo el 36% de los minerales metálicos y el 23% de los minerales no metálicos de todo Canadá. Siguiendo en 2005, los cinco minerales de más valor extraídos en la provincia fueron el níquel (2.116 millones), el oro (1.227 millones), el cobre (797 millones), los metales del grupo del platino (328 millones) y el cinc (183 millones). Combinados, representan el 97% del valor total de la producción de minerales metálicos de Ontario.

Desde siempre, Ontario ha tenido que importar energía. En tiempos de los primeros colonos, la madera de los bosques cubría las necesidades de combustible, pero debido al rápido crecimiento urbano e industrial, se tuvo que recurrir a importar carbón de las minas de los estados de Ohio, Pensilvania y Virginia Occidental, ya que era mejor y menos caro que el que se extraía en Nueva Escocia. En las proximidades de la bahía de James, Ontario posee yacimientos de carbón, aunque su explotación no parece rentable. Por lo que respecta al petróleo y al gas natural, la provincia lleva ventaja: se han venido explotando sus yacimientos petrolíferos desde finales de la década de 1850. Por otra parte, el gas natural ha sido descubierto algo después, y durante mucho tiempo Ontario fue el primer productor de estos productos en Canadá. No obstante, esta aportación en la actualidad no representan más que una pequeña parte de la producción global de energía. En la década de 1890, Canadá comenzó a desarrollar su potencial hidroeléctrico a gran escala con la construcción de generadores y líneas de transmisión en Niagara Falls, Ontario.
En 2004, la energía nuclear representaba casi la mitad de la producción eléctrica de Ontario. La Central Nuclear de Bruce, en Tiverton, fue inaugurada en 1967, y es la primera central de generación de energía nuclear de Canadá, pasando a estar completamente operativa en 1969. En 1997, Ontario Hydro autorizó el cierre y revisión general de 7 de sus 19 reactores porque consideraba que la compañía no tenía ni dinero ni personal para gestionarlos de manera segura.

Ontario es la región líder en refinado de petróleo de todo Canadá, contando con siete refinerías. La provincia es autosuficiente en lo concerniente a productos petrolíferos, y los exporta a otras provincias de Canadá y estados de Estados Unidos. El gas natural es el combustible esencial para todos los sectores de la economía provincial excepto para el transporte. Se utiliza en los sistemas de calefacción doméstica, comercial e industrial. La industria se está interesando por el gas natural para reducir las emisiones de gases de efecto invernadero.

La Bay Street de Toronto constituye el corazón del sector financiero de Canadá, al estilo de la Wall Street de Nueva York. No en vano, la mayoría de las sedes sociales de los grandes bancos canadienses y de muchas grandes empresas encuentran en Toronto. La Toronto Stock Exchange es la mayor bolsa de valores del país. El First Canadian Place, poblado de oficinas de abogados, de contables y administradores, es el rascacielos más alto en el país (290 m). Por su parte, la Torre CN, de 533 m de alto, otro edificio comercial, es la estructura no sostenida por cables en tierra firme más alta del mundo. Toronto acoge las sedes de grandes empresas de seguros. Otras ciudades de Ontario, como Kitchener-Waterloo, y en especial London, albergan también varias sedes de compañías de seguros.

En 2005, los bancos canadienses gestionaban cerca de 3.644 sucursales en Ontario, lo que representa el 43% de todas las sucursales bancarias de Canadá. Además, aproximadamente el 55,4% de los empleos de Canadá relacionados con la banca se encuentran en Ontario. El número de sucursales demuestra claramente la preferencia de los habitantes de Ontario por el Canadian Imperial Bank of Commerce (CIBC), que cuenta con una larga presencia en la provincia.

En 2005, el valor las exportaciones totales de Ontario sumaban 200.700 millones de dólares canadienses, y las importaciones otros 228.500 millones. Los Estados Unidos son el mercado de exportación principal de Ontario (88,9 por ciento de todas las exportaciones) y el principal proveedor de productos importados (72,5 por ciento de todas las importaciones). Otros mercados de exportación son el Reino Unido, México, China y Japón. Los principales mercados de importación son México, China, Japón, y Alemania.

La fuerte densidad de población del sur de Ontario lo convierte en la región más activa de Canadá (en términos económicos) en lo que respecta a supermercados, distribuidores de vehículos de motor, tiendas de productos generales y estaciones de servicio. La proximidad de Ontario a los grandes mercados de Estados Unidos permite que los productos generados en la provincia no se encuentren muy lejos de gran parte de los consumidores estadounidenses.

El nivel de imposición en Canadá sale beneficiado si lo comparamos con el de otros países desarrollados. Canadá posee un régimen completo de seguridad social, así como de sistemas de enseñanza y salud pública reputados por su eficiencia. Aun con toda la carga de estos servicios públicos subvencionados por el Estado, los impuestos de las sociedades y los impuestos profesionales siguen siendo competitivos comparados con los de Estados Unidos y con la media de los países del G-8. 

La tasa de impuestos de las sociedades establecidas en Ontario es por lo general del 36,12%. El impuesto de las ventas al por menor es del 8% y se aplica a la mayoría de los productos y a algunos servicios. Numerosos productos están exentos, en particular los alimentos, las prendas de vestir para niños y la energía, así como el material y la maquinaria para la industria y la investigación.

En 2003, una familia media de Ontario tenía unos ingresos medios de 81.437 dólares canadienses. Esa misma familia pagó de media unos 39.071 dólares en materia de impuestos.

Poco queda de las formas de arte autóctonas, aunque los primeros habitantes de Ontario dejaron detrás de sí considerables vestigios culturales, desde los Serpent Mounds, cerca de Peterborough, a otras obras más modernas y más perfeccionadas de escultura y alfarería. Más tarde, los colonos trajeron su propio patrimonio cultural, inspirado en el modelo europeo. Las formas de mediados del siglo XIX, plasmadas en obras de arte contemporáneas, aún gozan de una cierta popularidad. En general, los artistas de Ontario siguen los estilos internacionales, ya sea en literatura, en arte o en arquitectura. Los esfuerzos artísticos y culturales se ven apoyados por diversas subvenciones gubernamentales federales o provinciales, que ofrecen, entre otros, organismos como el Consejo de las Artes de Ontario (Ontario Arts Council), fundado en 1963, que concede subvenciones a particulares y a organizaciones de arte.

El gobierno de la provincia subraya el hecho de que el arte crea empleos: la documentación del Consejo de las Artes le recuerda al contribuyente que cada dólar de subvención en las orquestas genera directamente casi 7 dólares en salarios, cotizaciones y gastos de explotación.

Ontario cuenta con orquestas sinfónicas en Toronto (la Orquesta Sinfónica de Toronto, la más importante de Canadá), Ottawa, Hamilton y Kitchener-Waterloo. Todos los años tiene lugar un gran festival shakespeariano: el Festival de Stratford, instituido en 1953. Dos de los museos más importantes de la provincia, la Galería de Arte de Ontario y el Real Museo de Ontario se encuentran en Toronto. Esta ciudad es un destacado centro cultural, y sus producciones teatrales tienen fama mundial, como El Fantasma de la Ópera, Miss Saigón y, más recientemente, Mamma Mia!. Más de 100 compañías profesionales representan obras de teatro, cabaret, ópera, y danza en Toronto. También acoge el mayor festival de cine de Norteamérica, el Festival Internacional de Cine de Toronto, que tiene lugar en septiembre.
El Rogers Centre de Toronto (antiguo nombre: "SkyDome") el primer estadio del mundo con una cubierta completamente retráctil, y es la casa de los Toronto Blue Jays, un equipo de béisbol que en 1992 se convirtió en el primer equipo canadiense en ganar la World Series. El hockey femenino ha crecido en popularidad y es muy practicado en Ontario. La National Women's Hockey League cuenta con cinco equipos provenientes de esta provincia.

El autódromo de Mosport Park ha recibido a numerosas categorías mundiales y norteamericanas de automovilismo y motociclismo de velocidad, tales como la Fórmula 1, el Campeonato Mundial de Motociclismo, el Campeonato Mundial de Resistencia, el Campeonato Nacional del USAC, la American Le Mans Series y la NASCAR Canada Series. El Gran Premio de Toronto es una carrera de automovilismo de velocidad de la categoría de monoplazas Champ Car desde 1986 hasta 2007 y la IndyCar Series desde 2009. Es la tercera carrera callejera más antigua de América del Norte.

Ir en motonieve por los 50.000 kilómetros de pistas de la provincia (el mayor sistema de pistas de motonieves del mundo) es una actividad invernal muy popular.

A continuación se detallan los principales equipos deportivos de Ontario y las ligas en las que juegan:

Las primeras escuelas en ser construidas en lo que es actualmente Ontario fueron inauguradas durante la década de 1780. Estas escuelas —"common schools"— enseñaban sólo hasta lo que constituye actualmente la educación básica o elemental. En 1807, una ley obligó a la entonces colonia británica de Canadá Superior a construir una escuela secundaria —"grammar school"— en cada uno de los ocho distritos de la colonia. La colonia dio a las ciudades y a las villas donde estaban situadas tales escuelas la responsabilidad de administración. Muchas de estas ciudades y villas cobraban por la enseñanza.

Durante la década de 1870, el sistema escolar público de Ontario adquirió el formato de hoy día —organización entre "elementary schools" (de 1º a 8º curso) y "high schools" (de 9º a 12º curso). Cada ciudad —o, en regiones menos densamente pobladas, distritos educativos, que comprende un gran área y diversas villas de alrededor— está servida por un distrito escolar. Todas las instituciones de educación de Ontario deben seguir patrones dictados por la provincia, como los libros de texto a usar, y la prohibición de cobrar por la enseñanza, por ejemplo. Además de las escuelas públicas administradas por los municipios, existen también escuelas adminstradas por la Iglesia católica y varias escuelas privadas. La educación es obligatoria para todos los niños y adolescentes con más de seis años de edad, hasta la conclusión de la educación secundaria o hasta los dieciséis años de edad.

En 1999, las escuelas públicas de la provincia atendieron a cerca de 2.038 millones de estudiantes, y empleando aproximadamente a 110 mil profesores. Por su parte, las escuelas privadas atendieron a cerca de 90,6 mil estudiantes, y empleando aproximadamente a 7,1 mil profesores. El sistema de escuelas públicas de la provincia utilizó cerca de 17.108 millones de dólares canadienses, y el gasto de las escuelas públicas por estudiante es aproximadamente de 8 mil dólares canadienses.

Tanto las escuelas públicas como las escuelas católicas son mantenidas a través de impuestos municipales y de subvenciones que ofrece el gobierno de Ontario. La mayor parte de las escuelas existentes en la provincia enseñan en inglés, si bien hay algunas, localizadas en ciudades que poseen una notable población francófona, que lo hacen en francés.

En noviembre de 1997, los sindicatos de profesores de Ontario convocaron una huelga que duró dos semanas. Fue la huelga de profesores más larga de Norteamérica.

La primera biblioteca pública de Ontario fue construida en Niagara-on-the-Lake, en 1800. Este número había aumentado hasta 60 en el año de la independencia de Canadá, 1867. Actualmente, existen centenares de bibliotecas públicas a lo largo de la provincia, gestionadas por el gobierno provincial, los municipios o instituciones educativas. Además de eso, la Biblioteca Nacional de Canadá está localizada en la provincia, en Ottawa.

La Toronto Public Library (Biblioteca Pública de Toronto) es el mayor sistema de bibliotecas públicas de Canadá y el segundo más dinámico (por cantidad de visitas) del mundo después de la Biblioteca Pública de Hong Kong. Consta de 99 bibliotecas y cuenta con un patrimonio de 11 millones de materiales, entre libros, CD y vídeos.

La Universidad de Toronto es la mayor universidad de Canadá, y una de las más renombradas del país. Fue fundada en 1827, como "King's College". En 1850, el nombre de la institución cambió al nombre actual. Es conocida internacionalmente principalmente por sus programas en el área de la medicina, el derecho y los idiomas en general. Es la universidad que recibe más presupuestos del gobierno provincial y nacional, y una de las que tiene un mayor presupuesto del mundo.

Aparte de la Universidad de Toronto, Ontario posee otras 27 universidades y facultades. La Universidad de Waterloo, en Waterloo, es conocida por su programa de ingeniería. La Universidad de Queen, en Kingston, y la Universidad McMaster, en Hamilton, son conocidas por sus programas de medicina. La Universidad de Guelph es reconocida por su programa de investigación.

Los ríos, lagos y vías de agua han desempeñado un papel esencial a lo largo de la historia de Ontario. Los primeros exploradores europeos en explorar la región —en su mayoría franceses— exploraron la región siguiendo los ríos y los lagos existentes, como el río San Lorenzo, el río Ottawa y los Grandes Lagos, por ejemplo. Seguían estos cuerpos de agua por tierra, recorriendo el litoral del cuerpo de agua en cuestión, o por vías hídricas, a través de canoas o barcos.

Actualmente, durante la estación de navegación, cuando las aguas del río San Lorenzo no están cubiertas de hielo, entre abril y diciembre, varios barcos circulan entre el océano Atlántico y los Grandes Lagos. Por la provincia se extiende un sistema de canales artificiales, que posee 869 kilómetros de extensión. Durante la estación de hielo —de enero hasta marzo— las aguas del río San Lorenzo se vuelven peligrosas para la navegación de barcos, y ésta se interrumpe hasta el inicio de la estación de navegación.

Ontario posee cerca de 72 mil kilómetros de vías públicas, la mayor parte de ellas pavimentadas. La región más densamente cubierta por carreteras es el sur de la provincia. Entre las incontables carreteras de Ontario, la más frecuentada es la Highway 401, que se inicia en Windsor, pasa por London, Oakville, Mississauga, Toronto, Pickering, Oshawa y Kingston, extendiéndose hasta la frontera con la provincia del Quebec. Esta carretera es la carretera con más tráfico del mundo, especialmente en el tramo que pasa por la región metropolitana de Toronto.

Ontario posee 13.351 kilómetros de vías férreas, lo que corresponde a un cuarto de la red ferroviaria canadiense. La mayor parte de la red ferroviaria de Ontario se extiende por el sur de la provincia —ésta es la región más densamente cubierta por vías férreas por kilómetro cuadrado de todo el país. Las principales compañías ferroviarias que operan en la provincia son la Canadian National Railway, la Canadian Pacific Railway y la VIA Rail. GO Transit atiende a unos 195.000 pasajeros al día, transportándolos entre Toronto y las ciudades vecinas, y extendiéndose hasta Hamilton y Oshawa.

El Aeropuerto Internacional Lester B. Pearson, localizado en Mississauga, es el aeropuerto más dinámico de Canadá. Atiende a cerca de 29 millones de pasajeros por año, y es el principal centro aeroportuario del país. Otros aeropuertos importantes de la provincia son el Aeropuerto Internacional Ottawa Macdonald-Cartier y el Aeropuerto Internacional John C. Munro, en Hamilton, que también es un importante centro de la aviación de carga y de correo.

Las ciudades de Ontario cuentan cada una al menos con un periódico en inglés, y ocurre que estos diarios pertenecen casi siempre a la misma empresa. La excepción es Toronto, con tres diarios diferentes. En esta ciudad se publica la gran mayoría de las principales revistas del país (Maclean's, Canadian Business y Saturday Night) y en donde se ubican las sedes social de las grandes empresas editoriales del país (McClelland and Stewart y la editorial de la Universidad de Toronto). International Thomson, una editorial multinacional, también tiene su sede en Toronto y es la mayor compañía de medios de comunicación de Canadá.

El primer periódico publicado en lo que actualmente constituye la provincia de Ontario, el "Upper Canada Gazette", fue publicado en 1793, en la antigua Newark (actual Niagara-on-the-Lake). Cuatro años después, el periódico pasaría a ser publicado en York (actual Toronto), habiendo sido publicado hasta 1849. Actualmente, se publican en la provincia cerca de 450 periódicos, de los cuales cerca de 50 son diarios. La mayoría de estos periódicos se publican en inglés, aunque otros tantos se publican en chino, en francés y en italiano. El periódico de mayor circulación diaria en Canadá es el "Toronto Star" de Toronto.

Los principales estudios de la red anglófona de radiodifusión Canadian Broadcasting Corporation y la red privada CTV se encuentran en Toronto. Además de los medios de comunicación anglófonos, Ontario cuenta con tres cadenas de televisión en francés, así como numerosos repetidores y cadenas de radio, sin contar las cadenas que emiten en otras lenguas. La red de televisión pública de la provincia, TVOntario, emite principalmente en inglés, aunque dedica un canal —TFO— específicamente para la comunidad francófona de Ontario. La mayor parte de la provincia no sólo capta la televisión canadiense: también se pueden ver las retransmisiones de las grandes compañías de televisión de Estados Unidos, como la NBC, la ABC, la CBS o la FOX. Así pues, el sur de Ontario disfruta de uno de los repertorios más amplios de emisiones televisadas del mundo.

La primera cadena de radio de Ontario fue inaugurada en Hamilton en 1922. La primera cadena de televisión comenzó a retransmitir en 1952, en Toronto. Actualmente, la provincia posee cerca de 170 cadenas de radio y 30 de televisión.

Desde 1990, Telemundo tiene 3 estaciones locales en Toronto/Ottawa, Kingston/Windsor y Mississauga/Hamilton. A igual con Univisión.

El Ministerio de la Salud y de los Cuidados a largo plazo de Ontario (llamado en inglés "Ministry of Health and Long-Term Care" y en francés "Ministère de la Santé et des Soins de longue durée") se encarga de la administración del sistema sanitario de la provincia y de la prestación de servicios a la población de Ontario por medio de diversos programas, como seguros de enfermedad, programas de medicamentos, cuidados a los enfermos mentales, cuidados a largo plazo, cuidados a domicilio, servicios de salud comunitaria y de salud pública, promoción de la salud y prevención de enfermedades. También regula los hospitales y las casas de reposo, administra los centros psiquiátricos y laboratorios médicos y coordina los servicios de urgencias.

La Ontario Hospital Association (OHA), fundada en 1924, representa a 159 hospitales públicos de la provincia.

En la primavera de 2003, Ontario se vio gravemente afectada por una epidemia de síndrome respiratorio agudo severo, más conocido como neumonía asiática, en los hospitales de la provincia. Las autoridades sanitarias competentes ordenaron la puesta en cuarentena de miles de personas. En total, se dieron 44 muertes y 375 casos de infección en dos oleadas.





</doc>
<doc id="2104" url="https://es.wikipedia.org/wiki?curid=2104" title="Ovario">
Ovario

El ovario (lat. "ovum", huevo; gr. "ooforon") es la gónada u órgano reproductor femenino productor y secretor de hormonas sexuales y óvulos. Son estructuras pares con forma de almendra, con medidas de 1x2x3 cm en la mujer fértil (aunque varía durante el ciclo), y un peso de unos 6 a 7 gramos, de color blanco grisáceo, fijados a ambos lados del útero por los ligamentos uteroováricos y a la pared pelviana por los infundíbulos pelvianos. Su equivalente masculino serían los testículos.

El ovario posee medidas de sujeción para fijarlo en una posición que son: 


Las hormonas que produce el ovario son los estrógenos, quienes son los responsables del crecimiento del endometrio durante la fase proliferativa del ciclo menstrual, la progesterona, que es la hormona que evita el desprendimiento del endometrio rico en glucógeno durante la fase secretora del ciclo menstrual y la inhibina, que impide la secreción de la FSH desde la hipófisis. Con ayuda de estas hormonas el óvulo acabará implantándose en el endometrio. También en el ovario se producen cantidades insignificantes de Testosterona.
Referencia: Embriología Clínica, Keith Moore, 8.ª edición.

La "oforectomía" es el proceso quirúrgico que consiste en la extirpación de uno o los dos ovarios. Se denomina entonces ooforectomía uni o bilateral. Esta operación se puede realizar a través del abdomen por cirugía laparoscópica o bien por cirugía convencional. Cuando es de ambos ovarios deja a la mujer imposibilitada de producir óvulos y hormonas entrando ésta en menopausia de origen quirúrgico. En los casos en la que la paciente es portadora de un tumor ovárico no canceroso se saca sólo el ovario afectado pudiendo el ovario restante suplir todas las funciones. En caso de quistes ováricos benignos, generalmente se extirpa sólo el quiste.

La irrigación del ovario está dada por la artería gonadal o arteria ovárica (siendo la arteria testicular para el hombre) rama directa de la aorta abdominal, que pasan a los ovarios a tráves de los ligamentos suspensorios, esta arteria se anastomosan con la segunda fuente de irrigación del ovario, las ramificaciones ováricas de las arterias uterinas, que se originan en las arterias ilíacas internas.



</doc>
<doc id="2107" url="https://es.wikipedia.org/wiki?curid=2107" title="Ornithorhynchidae">
Ornithorhynchidae

Los ornitorrínquidos (Ornithorhynchidae) son una de las dos familias de las posibles monotremas que en la actualidad tienen especies vivas, sin embargo los taquiglósidos no se parecen a los contemporáneos ornitorrínquidos, se especula que el ornitorrinco es un "ave" con cuerpo masivo junto con aletas en forma de alerones.


"Monotramatum sudamericanum" está estrechamente relacionado con "Obdurodon sp.", formando parte de este género para algunos autores y siendo clasificado como "Obdurodon sudamericanum", sin embargo las demás es especies inciertamente pueden ser del orden "Monotremata".

Los géneros, "Steropodon" y "Teinolophos" podrían pertenecer a esta familia, aunque los expertos aseguran que sus fósiles son demasiado antiguos y los clasifican en Steropodontidae.


</doc>
<doc id="2108" url="https://es.wikipedia.org/wiki?curid=2108" title="Olimpo">
Olimpo

El monte Olimpo (en griego Όλυμπος, transliterado como "Ólympos", «el luminoso») es la montaña más alta de Grecia y segunda de los Balcanes (tras el Musala de Bulgaria, 2925 m), con 2919 m de altitud. Situado entre las regiones griegas de Tesalia y Macedonia, es reserva natural griega desde 1938 y patrimonio natural de la Unión Europea desde 1981, en su categoría de reserva de la biosfera.

El pico más alto es el "Mitikas" (2919 m), el más alto de Grecia, y el segundo, el pico "Eskolio" (2912 m). El monte Olimpo es rico en vegetación, especialmente endémica.

Para la mitología griega, el Olimpo era el hogar de los dioses olímpicos, los principales dioses del panteón griego, presididos por Zeus. Los griegos creían que en él había construido mansiones de cristal en las que moraban los dioses.

Como ocurre con otros aspectos y elementos de la mitología, el número e identidad de los dioses que habitaban ese Olimpo (el llamado «Concilio de los dioses») es impreciso de acuerdo con la tradición. Parece que su número era doce, siendo este un posible listado original: 

La tradición fue agregando algunos que fueron reemplazando a otros para que el número de dioses olímpicos quedara estable en doce. Zeus, Hera, Poseidón, Ares, Hermes, Hefesto, Afrodita, Atenea, Apolo y Artemisa son siempre considerados dioses olímpicos. Hestia, Deméter, Dioniso, Hades, Perséfone, Eros, Hebe, Asclepio, Pan y Heracles, después de ser divinizado, son los dioses variables que completaban la docena. 

De todos los dioses, solo Hestia, Deméter, Hera, Hades, Poseidón y Zeus eran hijos de Crono y Rea.

Se puede incluir en la lista a Hades, pero no posee trono en el Olimpo, ya que, a pesar de ser uno de los dioses más importantes, su morada en el mundo subterráneo de los muertos hacía su relación con los olímpicos más delicada. Hestia fue uno de los doce Olímpicos durante mucho tiempo, aunque terminó cediendo su lugar a Dionisio. Perséfone pasaba la tercera parte del año en el inframundo (provocando así el invierno) y se le permitía volver al Olimpo durante los restantes meses para que pudiera estar con su madre, Deméter.

Como en la antigua Grecia, la palabra "olimpo" significa, en español, lo más alto entre lo más alto.

Hay hasta 18 montañas más con el mismo nombre, incluyendo varias en las islas griegas, Chipre, Asia Menor, Nueva Zelanda, Tennessee, Utah y Washington. También se da este nombre a un volcán del planeta Marte (Olimpo).



</doc>
<doc id="2114" url="https://es.wikipedia.org/wiki?curid=2114" title="Procesador">
Procesador

El término "Procesador" puede referirse a los siguientes artículos:




</doc>
<doc id="2117" url="https://es.wikipedia.org/wiki?curid=2117" title="Programa">
Programa

Según el contexto, programa puede adoptar distintos significados:





</doc>
<doc id="2118" url="https://es.wikipedia.org/wiki?curid=2118" title="Perianto">
Perianto

El perianto (del griego "perí", alrededor y "anthós", flor) es una estructura floral que corresponde a la envoltura que rodea a los órganos sexuales; constituye la parte no reproductiva de la flor. 

Está formada por dos tipos de piezas: 


</doc>
<doc id="2122" url="https://es.wikipedia.org/wiki?curid=2122" title="Pintura (material)">
Pintura (material)

"Este artículo trata sobre la naturaleza de los materiales, así como sus aplicaciones en construcción e ingeniería. La parte artística de pintura y sus técnicas se describen mejor en el artículo Pintura."

La pintura es un producto fluido que, aplicado sobre una superficie en capas relativamente delgadas, se transforma al cabo del tiempo en una capa sólida que se adhiere a dicha superficie, de tal forma que recubre, protege y decora el elemento sobre el que se ha aplicado.

En tiempos antiguos la pintura era hecha a base de pigmento.

Existen diferentes tipos de pinturas, como son:

barnices, esmaltes, lacas, colorantes, entonadores y selladores entre otros; cada uno con unas propiedades físicas y químicas que deben tenerse en cuenta a la hora de elegir el producto adecuado, ya sea por el tipo de superficie a aplicar, el carácter estético o las inclemencias a la que va a estar sometido.

Las más comunes son las siguientes:

Es el tipo de pintura más utilizado para paredes interiores. Es una pintura permeable, porosa, de aspecto mate. No se puede lavar, ni colocar en zonas expuestas a la lluvia ni condensaciones de agua.

Es una pintura de la cual se pueden limpiar las manchas que pueda recibir. 
Se usa en ambientes, comedores, dormitorios, etc. No conviene usarla en ambientes donde se produce vapor, como baños o cocinas, pues debido a que genera una capa impermeable no permite el pasaje de los vapores, por esa razón es común que se formen ampollas en su superficie. En estos recintos conviene usar pinturas de diferente composición y más permeables que permitan el pasaje de los gases. Se aplica principalmente sobre revoques de yeso o cemento y derivados.

Para aplicarlo sobre otros materiales como metal o madera, es necesaria un tratamiento especial llamado imprimación, aunque la durabilidad no es buena, y para los acabados, tiene cierta tendencia a dejar las marcas de la herramienta usada para su aplicación. Para estos sustratos hay pinturas específicas que se conocen como esmalte sintético.

También se le conoce como «pintura de emulsión» o «pintura de caucho» (principalmente en Venezuela). Otra característica que la distingue es el hecho de ser soluble en agua, por lo cual no precisa solventes sintéticos como el thinner.

Se utiliza tanto para el interior como para el exterior, y tanto para paredes y techos como para muebles, puertas, ventanas, metales, etc. Ofrece resistencia al agua, pierde brillo si está expuesto al sol, es fácilmente lavable, buena resistencia al frote, secado lento, especialmente a bajas temperaturas, y buena extensibilidad.

Este es el tipo de pintura que mejor conserva el brillo, incluso a la intemperie. El acabado es liso, con aspecto mate, satinado o brillante. Se utiliza mucho para proteger superficies de metal y de madera, tanto en el exterior como interior. A diferencia del esmalte graso esta se seca con mayor rapidez. 

Es de aspecto mate y relativamente resistente al desgaste y a la erosión provocados por la lluvia, viento, etc. Se utiliza en el exterior, en superficies que deben ser rugosas para que se adhiera sin problemas. Se compran en polvo y se mezclan con agua, es importante aplicarlo justo después de mezclarlo con agua, ya que se endurecen rápidamente. Este tipo de pinturas cementicias ha sido superado ampliamente desde hace unos años por pinturas específicas para exteriores, entre las que podemos encontrar las pinturas de piso, etc. Éstas, más modernas, presentan mucho mayor resistencia a los agentes atmosféricos y su acabado es muy superior que las cementicias. No obstante, aún se siguen usando las derivadas del cemento blanco por su bajo costo comparado con las mencionadas. En climas tropicales y sub tropicales, en caso de usar pinturas cementicias, es necesario repintar todos los años luego de la temporada de lluvias.

La gran ventaja de esta pintura, además de su bajo costo, es que debido a su alcalinidad tiende a destruir la materia orgánica, por lo tanto es útil para pintar habitaciones de casas abandonadas o que no se han usado por tiempo donde existe la presencia de insectos. Es antiséptica. No es adecuada para el exterior, pues, el agua de lluvia tiende a eliminarla aunque se le agreguen aditivos comúnmente llamados fijadores. El proceso de carbonatación, es decir de formación de la capa sólida, se da exclusivamente en presencia del dióxido de carbono del aire. Demora en fijarse los días lluviosos o de mucha humedad. Presenta también la gran ventaja adicional de permitir el pasaje de los vapores por eso es apta para ser usada en baños y cocinas, pues permite la "respiración" del paramento, disminuyendo así la posibilidad de formación de hongos (pues éstos se producen en ambientes anaeróbicos, es decir sin presencia de aire). Esa condición también hace que este tipo de pintura no se ampolle. De todas formas es una pintura de baja calidad, esto se nota por su aspecto y en particular porque al recostarse queda en parte adherida a la ropa. Existen pinturas llamadas para cielorasos, más económicas que la plásticas que son específicas para baños y cocinas y ofrecen un aspecto más agradable, pero, no tienen la propiedad antiséptica de las pinturas a la cal. El aspecto es mate. No se debe emplear sobre yesos, maderas o metales. Hay que tener cuidado al usar este tipo de pintura, ya que es corrosiva, y puede quemar las manos.

La superficie queda totalmente lisa y brillante. Es un tipo de pintura muy popular, sobre todo para pintar muebles, puertas, etc. Hay que saber utilizar bien esta técnica, ya que se dan varias capas de productos distintos y pueden surgir problemas de adherencia entre ellas, si no se aplican correctamente. A diferencia de los barnices, se usan para interiores.

Para lograr un aspecto diferente, existen pinturas especiales que imitan el mármol o el estuco, o que semejan acabados antiguos, rústicos o multicolor.

El vinilo se encuentra presente en la pintura acrílica o vinilica, tiene la misma función que el aceite en la pintura de óleo. Es un medio que permite al pigmento adherirse a las superficies. Es incoloro y es soluble en agua. Tiene menor tiempo de secado que la pintura óleo, y mayor resistencia a la intemperie, aunque todavía no se ha determinado su durabilidad frente al óleo.

Todas las pinturas se componen a su vez de una serie de subproductos:

Estos recubrimientos tienen las siguientes propiedades en grados variables, dependiendo de la composición del recubrimiento: buen flujo y nivelación; proporción de aspersión y grosor de película satisfactorios; secado rápido, alta impermeabilidad, buena adhesión, flexibilidad y dureza, resistencia a la abrasión y durabilidad.

También se refiere en primer lugar a las sustancias empleadas para dar color y que suelen ser una mezcla de un pigmento con un aglutinante que es la sustancia que se le adhiere para que la pintura se fije al material en el que se va a trabajar, también se le agrega un líquido según la consistencia deseada. También existen pinturas que no requieren un aglutinante, como por ejemplo: los pasteles, carboncillos, grafitos, etc. Por extensión se denominan así también algunas obras realizadas con dichos materiales.

Existen multitud de técnicas válidas para la realización de pinturas, así como de soportes y motivaciones. Las técnicas se pueden diferenciar en grasas y acuosas. Los soportes en fijos o inmuebles (parietales o murales) y móviles (pintura de caballete).



</doc>
<doc id="2125" url="https://es.wikipedia.org/wiki?curid=2125" title="Infracción de derechos de autor">
Infracción de derechos de autor

Una infracción de derechos de autor, infracción de "copyright o violación de "copyright es un uso no autorizado o prohibido de obras cubiertas por las leyes de derechos de autor, como el derecho de copia, de reproducción o el de hacer obras derivadas.

También es habitual el uso del término "piratería", a menudo de forma peyorativa, para referirse a las copias de obras sin el consentimiento del titular de los derechos de autor.
El informático Richard Stallman y el experto en propiedad intelectual, Eduardo Samán, entre otros, argumentan que el uso de la expresión "piratería" para referir a las copias no autorizadas es una exageración que pretende equiparar el acto de compartir con la violencia de los piratas de barcos, criminalizando a los usuarios. La Free Software Foundation incluye esta acepción del término en su nómina de expresiones a evitar en materia de derechos de autor.

Los alcances de la protección de las obras a nivel internacional están regidos por el Convenio de Berna, que establece un plazo mínimo de 50 años a partir de la muerte del autor. La forma en que debe tratar la legislación estas infracciones es un tema que genera polémica en muchos países del mundo.

A un año de ingresar a la Organización de Cooperación y Desarrollo Económico (OCDE), y según señaló Business Software Alliance (BSA, asociación que agrupa a las principales empresas de software en Chile y el resto del mundo), Chile continúa como el miembro con la tasa más alta de copias no autorizadas de software. Sin embargo, dicho estudio es criticado en cuanto a la exactitud de sus mediciones, apelando a la rigurosidad y metodologías aplicadas al Global Software Piracy Study.

Según un estudio de la consultora International Data Corporation (IDC), la tasa de infracción en materia de software en Chile alcanza el 64%. Según el estudio, sólo el 25% de las empresas chilenas tienen una política formal para el uso de softwares con licencia, lo que corresponde al porcentaje más bajo entre los países encuestados. Esto contrasta con lo que dicen las compañías, donde el 56% dice tener algún tipo de protocolo básico, de acuerdo a la información entregada por los gerentes de tecnología de las firmas consultadas.

En cuanto a legislaciones, Chile cuenta con la Ley Nº 17.336, sobre Propiedad Intelectual, de 2 de octubre de 1970, y sus modificaciones posteriores que regulan el derecho de autor.

Esta ley ampara los derechos de los autores chilenos y extranjeros domiciliados en Chile. Establece, asimismo, que los autores extranjeros no domiciliados en el país gozan de la protección que les sea reconocida por las convenciones internacionales que Chile ha suscrito y ratificado.

Chile también integra con regularidad la "Priority Watch List" estadounidense, debido a la recomendación que ha efectuado la IIPA (International Intelectual Property Alliance), frente al que consideran un alto índice de infracciones que mantiene el país. Debido a obligaciones de carácter legal, adquiridas voluntariamente mediante el Tratado de Libre Comercio con Estados Unidos (TLC). El impacto de pertenecer a esta lista, significa sufrir en su prestigio comercial; pérdida de oportunidades de negocio con Estados Unidos y con otras naciones desarrolladas; y que empresas exportadoras chilenas podrían transformarse en potenciales target de las nuevas leyes norteamericanas de competencia desleal, que apuntan primordialmente a las empresas foráneas que exportan a Estados Unidos y que no tienen licenciado el software que utilizan en sus procesos productivos.

A pesar de la necesidad de requerir la autorización del autor o del titular de los derechos de autor para la explotación de la obra, existen excepciones contempladas en la Ley de Propiedad Intelectual ecuatoriana. Las mismas se encuentran especificadas en el Art. 83.

La ley española que regula los derechos de autor contempla como excepción la copia privada, es decir, autoriza a los particulares la copia o reproducción de una obra protegida para hacer un uso privado de la misma, siempre que haya tenido acceso legítimo al original copiado. No en vano, la Constitución, norma jerárquicamente superior, establece el derecho de todos a la cultura.

Según datos extraídos del informe anual del Instituto de Cinematografía y de las Artes Audiovisuales del Ministerio de Cultura, en 2008 se vendieron en torno a nueve millones de entradas menos, 39 salas de cine fueron cerradas, ocasionando la desaparición de 156 pantallas de cine.

La situación ha cambiado frente al bache de los años 2005-2008, y los espectadores comenzaron a acudir con más frecuencia a las salas. De acuerdo con la consultora Nielsen EDI, en España, en 2009 los cines españoles batieron récords de recaudación, superando al registro más alto anterior, del año 2004. Como causas se indicaron lo atractivo de los estrenos y a las innovaciones técnicas; el informe no relacionó la evolución de la taquilla ni de los espectadores con la evolución de la infracción de copyright.

Durante años sucesivos, España continúa integrando la Lista 301 o "Priority Watchlist". Este informe dedica a España 17 páginas en las que indica una serie de requerimientos y sugerencias a las autoridades españolas para corregir las infracciones, que califican como "fuera de control". Asimismo alaba el anteproyecto de Ley de Economía Sostenible (la conocida como "Ley Sinde" por la que un órgano administrativo podrá ordenar el cierre o bloque sitios web de enlaces, previa autorización expréss de un juez de la Audiencia). Entre las sugerencias recogidas en la Lista 301 se pueden ver diferentes actos, tales como aumentar el personal para investigar las actividades de Internet, en el Ministerio de Interior, la Guardia Civil y la Policía Nacional, permitir que los dueños de los derechos puedan obtener la información necesaria para emprender acciones civiles, tomar las acciones necesarias para asegurarse que los modchips (chips utilizados para liberar diversas consolas para que sean capaces de ejecutar copias no autorizadas y homebrew) y dispositivos similares sean ilegales, desarrollar una campaña de publicidad efectiva, entre muchas otras.

Estados Unidos es el principal país en cuanto a la persecución a los infractores de derechos de autor, con una legislación muy agresiva al respecto. Allí se elabora anualmente la "Priority Watchlist", un informe redactado por las principales asociaciones de productores y editores y que se remite al Departamento de Comercio de EE. UU. para presionar a los países que, bajo su óptica, no respetan lo suficiente el derecho de autor en ese país. Los productos relacionados directa o indirectamente con la propiedad intelectual representan alrededor del 35% del PBI de EEUU.

 México se encontraría entre los once países donde las infracciones al derecho de autor se dan con mayor fuerza, afectando a la economía de Estados Unidos. Esta afirmación ya había sido planteada mucho antes, por lo que bajo presión de organismos internacionales y de los Estados Unidos, el presidente Vicente Fox lanzó el programa más ambicioso contra la venta de música y películas reproducidos sin autorización en México, llamada la "guerra contra la piratería", su primer movimiento fue El Acuerdo Nacional contra la Piratería, que no solo se preocupaba por las infracciones relacionadas con el cine y la música; si no también del vestido, el software y autores en general.
Este acuerdo planteaba que para su éxito debían participar las tres órdenes de gobierno (Federal, Estatal y Municipal), los poderes que sustentan al Estado (Legislativo, Ejecutivo y Judicial) y por supuesto, las Organizaciones Protectoras de Derechos de autor interesadas en la solución que este nuevo acuerdo prometía cumplir.

El derecho penal mexicano sólo trata las violaciones más graves del ordenamiento jurídico, y en el marco del derecho de autor, generalmente sólo se sancionan penalmente las conductas que supongan la copia o el plagio de las obras protegidas, donde concurran dos circunstancias: el ánimo de lucro y el perjuicio a terceros, donde el beneficio obtenido posea especial trascendencia económica. Esto último, en muchos casos, supone una actividad altamente especializada, que busca la comercialización de los productos copiados o plagiados, y se define en actos tales como la exposición de las copias en comercios, catálogos de venta, y otros. Considerar estos derechos como una forma de propiedad (y no como un derecho de uso) facilita la criminalización de la copia no autorizada. Permite además a las grandes multinacionales que controlan estos derechos una equiparación con otros delitos de mayor gravedad como el robo, es por esto, que El Acuerdo Nacional Contra la Piratería hace modificaciones a las penas legales para quienes no cumplan la ley en cuanto a las infracciones de derecho de autor. La ley establece que a quien incumpla en las leyes, la privación de la libertad será de 3 a 10 años, y una sanción que va de 2.000 a 20.000 días de multa, todo esto con la finalidad de reducir los usuarios infractores. Durante el último año de la administración de Fox, más de 8,700 operativos fueron realizados en el país para decomisar mercancía y detener presuntos vendedores de copias no autorizadas Al final del sexenio de Felipe Calderón se habrían registrado alrededor de 123.440.367 artículos en infracción; por otro lado, Enrique Peña Nieto ha tenido el sexenio con más bajo resguardo según el Informe Especial 301 de EU. Sin embargo, según el antropólogo José Carlos G. Aguiar estas políticas parecerían ser más efectivas para criminalizar el comercio informal, que para el control efectivo de venta de copias no autorizadas en los mercados populares y espacio público.

En relación a la industria musical, para la mayoría de músicos su verdadera fuente de ingresos está en la actuación en vivo, no en la venta de discos. Por tanto, para algunos, la disponibilidad del material de los músicos favorece la afluencia de público a sus conciertos. Uno de los medios que favorece esa disponibilidad del material hoy en día es el uso de "software" P2P que permite a sus usuarios compartir ficheros a través de Internet, si bien muchos esperan que los músicos comiencen a abandonar el concepto de disco grabado para ofrecer su material de formas alternativas (como, por ejemplo, descargas a través de FTP o similares), pudiendo fijar precios por pieza/canción o grupo de piezas mucho más bajos que los actuales precios de CD.

Sin embargo, la mayoría de las grandes compañías, y asociaciones de autores, e intérpretes "best-sellers", no están de acuerdo con este punto de vista y aluden a la pérdida de puestos de trabajos que se producirá en la industria del sector debido a esta actividad. Además defienden el derecho de los autores a recibir compensación económica por la utilización de su obra, por un tiempo indeterminado, criticando las actuales limitaciones temporales, arguyendo que "el dinero, las propiedades, las casas, los negocios, las empresas, los cuadros, los muebles y las zapaterías se heredan hasta el infinito, generación tras generación, y eso nadie lo discute ni a nadie le parece mal (...). Sólo los herederos de los artistas “viven del cuento”, cuando justamente éstos ni siquiera han comprado lo que poseen, sino que lo han creado e inventado."

Aunque las cifras sobre copias no autorizadas son cuestionadas por su validez, conglomerados de empresas del sector han realizado estudios que afirman que la media mundial de falsificación para el año 2006 se situaba en 35%, Sin embargo, existen grandes variaciones de este guarismo dependiendo de la región. Vietnam es el país con las cifras más altas: el 97% del software utilizado es ilegal, mientras que en China se mantiene en un 94%.

En Argentina algunos afirman que alrededor del 70% de los DVD que se venden son copias ilegales, mientras que el 75% del software en uso es falsificado.
Mientras que en toda Latinoamérica se calcula en un 66%.

Según un estudio elaborado por International Data Corporation publicado por la Business Software Alliance, las infracciones de derechos de autor generan pérdidas, y las mismas ascenderían a 58 700 millones USD para el año 2010, un 14,2% más que en 2009. En Argentina, se afirma que estas supuestas pérdidas llegaron a los 681 millones USD para el período 2005-2010.

La Motion Pictures Association of America (MPAA) publicó un detallado informe titulado "El costo de la piratería" ("The Cost of Movie Piracy"), donde se afirmaba que durante el año 2005 las descargas y ventas ilegales de películas provocaron una pérdida teórica de 18 000 millones USD a la industria del cine. También se señala que los principales afectados por estas prácticas son las grandes productoras. Según estos datos, estas "perderían" alrededor de 6 100 millones USD. El resto de las presuntas pérdidas, unos 11 900 millones, corresponderían al entramado de distribuidores, exhibidores y otras pequeñas productoras.

Por otra parte, un estudio realizado por el gobierno suizo concluyó que la infracción de derechos de autor no genera pérdidas ni menores ingresos a la industria, además de considerar legal la descarga de material protegido.

Los derechos de autor son un sistema que data del siglo XVIII, sin embargo mucho antes de esto y desde los orígenes de la humanidad ha existido La cultura libre, que es una corriente de pensamiento que promueve la libertad en la distribución y modificación de trabajos creativos basándose en el principio del contenido libre para distribuir o modificar trabajos y obras creativas, usando Internet así como otros medios. Para esto comparten y distribuyen obras en dominio público, además de crear obras artísticas con licencias copyleft y creative commons y en entornos de programas de computo utilizan licencias libres como GPL o apache.

De esta forma mucha de la información, libros, música, películas y programas de computo que se comparte en la red ya sea en redes de pares o archivos alojados en la red son completamente legales y se fomenta su distribución y redistribución en forma libre y gratuita ya que ese es su objetivo y en estos intercambios no se viola ningún derecho de autor porque no existen.

Al utilizar obras en dominio público es imposible infrigir derechos de autor porque no existen, ya que estas pueden ser utilizadas libremente y se pueden hacer obras derivadas o lucrarse con estas, tal es el caso de las películas que hace Disney basadas en obras bajo dominio público que produce y vende con licencia de derechos de autor, pasando a ganar billones de dólares basándose en obras que originalmente pertenecen al dominio público.




</doc>
<doc id="2127" url="https://es.wikipedia.org/wiki?curid=2127" title="Psicología">
Psicología

La psicología (también sicología, de uso menos frecuente) (literalmente «estudio o tratado del alma»; del griego clásico ψυχή, transliterado "psykhé", «psique», «alma», «actividad mental», y λογία, "logía", «tratado» o «estudio») es, a la vez, una profesión, una disciplina académica y una ciencia que trata el estudio y el análisis de la conducta y los procesos mentales de los individuos y de grupos humanos en distintas situaciones, cuyo campo de estudio abarca todos los aspectos de la experiencia humana y lo hace para fines tanto de investigación como docentes y laborales, entre otros. Existen diversas perspectivas psicológicas, cada una con sus propias teorías y metodologías, y en comparativa pueden coincidir, influirse, solaparse o incluso ser contradictorias e incompatibles; esta variedad da pie a múltiples acepciones y abordajes. Algunos enfoques —como en el humanismo— consideran que el método científico no es adecuado para investigar la conducta; otros tales como el conductismo lo emplean para comportamientos observables que pueden ser objetivamente medidos.

Por medio de sus diversos enfoques, la psicología explora conceptos como la percepción, la atención, la motivación, la emoción, el funcionamiento del cerebro, la inteligencia, el pensamiento, la personalidad, las relaciones personales, la conciencia y la inconsciencia. La psicología emplea métodos empíricos cuantitativos y cualitativos de investigación para analizar el comportamiento. También se pueden encontrar, especialmente en el ámbito clínico o de consultoría, otro tipo de métodos cualitativos y mixtos. Mientras que el conocimiento psicológico es empleado frecuentemente en la evaluación o tratamiento de las psicopatologías, en las últimas décadas los psicólogos también están siendo empleados en los departamentos de recursos humanos de las organizaciones, en áreas relacionadas con el desarrollo infantil y del envejecimiento, los deportes, los medios de comunicación, el mundo del derecho y las ciencias forenses. Aunque la mayor parte de los psicólogos están involucrados profesionalmente en actividades terapéuticas (clínica, consultoría, educación), una parte también se dedica a la investigación, desde las universidades, sobre un amplio rango de temas relacionados con el comportamiento y el pensamiento humano.

El vocablo griego ψυχή "(psykhé)" significa «alma», «mente», «aliento», «vida», «viento frío», «soplo helado» y era representado simbólicamente con una mariposa, mientras que -λογία "(-logia)" describe al «habla» o el «discurso», «tratado», «doctrina», etc.; por tanto, psicología significa literalmente «estudio del alma» y denota al «estudio de la mente».

La palabra "psicología" fue utilizada por primera vez en lengua latina por el poeta y humanista cristiano Marko Marulić, en su libro "Psichiologia de ratione animae humanae" a finales del siglo XV o a comienzos del XVI, y también se cita la obra de un autor alemán, Rudolf Göckel, que publicó el texto "Psychologia hoc est de hominis perfectione, anima, ortu" (Marburg, 1590).

El término se difundió a través de la Reforma protestante en Alemania y los escritos de Philippe Melanchthon, y también se encuentra el término en francés, por ejemplo en el texto "Psichologie ou traicté de l'apparition des esprits", de Noël Taillepied (1588). En cuanto a la lengua inglesa, la primera referencia conocida de "psychology" apareció en la obra de Steven Blankaart, en 1694.

El término no ganó popularidad en el ámbito ilustrado sino hasta el uso del mismo a cargo del filósofo alemán Christian Wolff, quien lo usó en sus obras "Psychologia empirica" (1732) y "Psychologia rationalis" (1734).

Las distintas escuelas, teorías y sistemas psicológicos han enfocado sus esfuerzos en diversas áreas, existiendo desde los enfoques que se centran exclusivamente en la conducta observable (conductismo), pasando por los que se ocupan de los procesos internos tales como el pensamiento, el razonamiento, la memoria, etc. (como el cognitivismo) o las orientaciones que ponen el acento en las relaciones humanas y el pensamiento humanista de la posmodernidad y en la comunicación basándose en la teoría de sistemas, hasta los sistemas psicológicos que focalizan en los procesos inconscientes (como el psicoanálisis o la psicología analítica). El alcance de las teorías abarca áreas o campos que van desde el estudio del desarrollo infantil de la psicología evolutiva hasta cómo los seres humanos sienten, perciben o piensan; cómo aprenden a adaptarse al medio que les rodea o resuelven conflictos.

Para algunos autores, como los de la corriente académica anglosajona del "Behavioural sciences", el ámbito de investigación y acción de la psicología científica es exclusivamente el comportamiento humano, distinguiendo solo tres áreas: ciencia de la conducta, ciencia cognitiva y neurociencia.

Como disciplina científica, registra las interacciones de la personalidad en tres dimensiones: cognitiva, afectiva y del comportamiento. Es materia de controversia si acaso otras dimensiones (como la moral, social y espiritual, incluyendo las creencias religiosas) de la experiencia humana forman o no parte del ámbito de la psicología, como asimismo, en qué medida el abordaje de tales aspectos puede ser considerado científico.

En cuanto a la metodología utilizada, la psicología ha discurrido tradicionalmente por dos opciones de investigación:


Los psicólogos suelen estar organizados localmente en colegios profesionales y también en asociaciones científicas, que pueden ser de carácter local, nacional, continental y mundial. En el caso de los colegios profesionales, estos cumplen una función normativa, ya que en muchos países se exige al psicólogo poseer una autorización para ejercer su profesión, a lo que se denomina indistintamente licencia, colegiatura o registro, entre otras formas. No existe un colegio profesional internacional; cuando un psicólogo necesita ejercer su actividad profesional en un país diferente a aquel en el que ha obtenido su titulación, debe revalidar su título y obtener una nueva licencia.

La Unión Internacional de la Ciencia Psicológica (IUPSyS, por sus siglas en inglés) es la entidad que representa a la psicología en el mundo, congregando a los comités nacionales que representan a las Asociaciones de Psicólogos de cada país. Una de las asociaciones de psicólogos más importantes es la Asociación Psicológica Estadounidense (APA, que ha publicado normas para la elaboración y publicación de trabajos científicos ampliamente difundidas y utilizadas en varios ámbitos de la ciencia. En América Latina, destaca la Sociedad Interamericana de Psicología (SIP). En el 2002, se fundó la Unión Latinoamericana de Entidades de Psicología (ULAPSI), con el propósito de generar una comunidad científica y profesional de los psicólogos de esta región, a fin de generar alternativas conceptuales y prácticas que correspondan a las grandes necesidades y a la diversidad cultural de estos países; pretende una psicología con compromiso social y combatir el tradicional colonialismo científico para dialogar de manera crítica con los conocidos psicólogos europeos, asiáticos y norteamericanos.

Las siguientes son las principales escuelas o tendencias en la historia de la psicología:


El psicoanálisis es un método de exploración que, creado por el neurólogo austríaco Sigmund Freud, tiene como objetivo la investigación y el tratamiento de los problemas emocionales desde el punto de vista: de la infancia de la persona, de la interpretación de los sueños, de los actos fallidos y de la técnica de asociación libre, entre otras.

Freud complementó la "psicología de la consciencia" de Wilhelm Wundt con su "psicología del inconsciente". Contrariamente a los anteriores enfoques, centrados en la investigación de laboratorios, el psicoanálisis no intenta ser una ciencia pura. Su interés no recayó en la acumulación de conocimientos sobre la mente normal, si no en la aplicación inmediata de una nueva manera de tratar a individuos que manifestaban un comportamiento anormal. Extrajo mucho más de sus datos de observación clínica que de la experimentación controlada en el laboratorio. Freud creía que poderosos impulsos biológicos, principalmente de naturaleza sexual, influían en el comportamiento humano. Opinaba que estas tendencias eran inconscientes y que creaban conflictos entre el individuo y las normas sociales.

La psicología conductista norteamericana se forjó como una disciplina naturalista con inspiración en la física (en oposición a la psicología fundada por Wundt, quien en 1879 creó el primer laboratorio en Alemania); se caracteriza por recoger hechos sobre la conducta observada objetivamente, y a organizarlos sistemáticamente, elaborando teorías para su descripción, sin interesarse demasiado por su explicación. Estas teorías conductistas se basan en el método científico, y procuran conocer las condiciones que determinan el comportamiento de cualquier animal, siguiendo el esquema causa-efecto, y permiten en ocasiones la predicción del comportamiento y la posibilidad de intervenir en ellas. Es una psicología que se orienta más hacía la producción tecnológica.

Uno de los defensores más importantes del conductismo fue Burrhus Frederic Skinner, quien escribió diversos trabajos con gran controversia acerca de diferentes técnicas psicológicas para la modificación del comportamiento. Una de sus principales técnicas fue el condicionamiento operante, forma de aprendizaje a consecuencia de estímulos reforzadores del ambiente. El fin de las teorías de Skinner era crear una sociedad en completa armonía.

La mayor parte de los estudios se realizan en seres humanos. No obstante, es habitual que la psicología experimental realice estudios del comportamiento animal, tanto como un tema de estudio en sí mismo (cognición animal, etología), como para establecer medios de comparación entre especies (psicología comparada), punto que a menudo resulta controvertido, por las limitaciones evidentes derivadas de la extrapolación de los datos obtenidos de una especie a otra. La tecnología computacional es otra de las metodologías utilizadas para elaborar modelos de conducta y realizar verificaciones y predicciones.

La psicología cognitiva es una escuela de la psicología que se encarga del estudio de la cognición, es decir, de los procesos mentales implicados en el conocimiento. Se define a sí misma como heredera de la ciencia fundada por Wundt (Leipzig, 1879) y está enfocada en el problema de la mente y en los procesos mentales. Tiene como objeto de estudio los mecanismos de elaboración del conocimiento, desde la percepción, la memoria y el aprendizaje, hasta la formación de conceptos y razonamiento lógico. Lo «cognitivo» se refiere al acto de conocimiento, en sus acciones de almacenar, recuperar, reconocer, comprender, organizar y usar la información recibida a través de los sentidos. Metodológicamente, más que en la experimentación (como el conductismo), se ha apoyado en modelos, también computacionales e informáticos, para llegar a la explicación de los diversos procesos cognitivos que son de su interés. La investigación cognitivista en los campos del juicio y de la toma de decisiones han tenido un gran impacto en otras disciplinas como la economía (véase Daniel Kahneman, 2006).

La psicología humanista es una corriente dentro de la psicología que surge en la década de los sesenta del siglo XX. Esta escuela enfatiza la experiencia no verbal y los estados alterados de conciencia como medio de realizar nuestro pleno potencial humano. Surge como reacción al conductismo y al psicoanálisis y se propone la consideración global de la persona, basándose en la acentuación en sus aspectos existenciales (la libertad, el conocimiento, la responsabilidad, la historicidad). Critica el posicionamiento de la psicología como una ciencia natural, porque este reduciría al ser humano solo a variables cuantificables y critica además, en el caso del psicoanálisis y el conductismo, la excesiva focalización en los aspectos negativos y patológicos de las personas. Uno de los teóricos humanistas más importantes, Abraham Maslow, denominó a este movimiento «la tercera fuerza», por tratarse de una propuesta crítica, pero a la vez integradora de las dos teorías (aparentemente opuestas) de la psicología de la época: el conductismo y el psicoanálisis.

La psicobiología o biopsicología es un sistema psicológico, que considera que la psicología es: el estudio científico de la conducta y de la mente (si existe), de los animales dotados de un sistema nervioso que los capacite por lo menos para percibir y aprender; considera que los animales capaces de percibir y aprender son: a) los mamíferos (incluyendo el ser humano), y b) las aves; se considera predominantemente una ciencia biológica y secundariamente una ciencia social, y se basa en el materialismo como filosofía. (Bunge y Ardila, 2002; Gadenne, 2006). La psicobiología incorpora los objetivos del conductismo y va más allá; la psicobiología no se limita a describir la conducta, sino que la intenta explicar en términos neurobiológicos. El fin último de la psicobiología es la construcción de teorías, tanto generales como específicas, capaces de explicar y predecir hechos conductuales y mentales en términos biológicos.

Este sistema fue fundado por Wundt. Se le denomina estructuralismo por la finalidad con que fue creado, ya que sus miembros estaban preocupados por el descubrimiento de la «estructura». Los estructuralistas emplearon el método experimental, optando por la introspección para relatar tan objetivamente como sea posible, la experiencia consciente durante el proceso de captar y juzgar los estímulos. Descubrieron que los procesos conscientes consisten fundamentalmente en tres elementos: sensaciones, imágenes y sentimientos.

El asociacionismo constituye un principio psicológico que afirma que todo lo conocemos por medio de los sentidos, y surge la pregunta siguiente: «entonces, ¿de dónde vienen las ideas complejas, que no son directamente sentidas?». La respuesta a esta pregunta nos proporciona el primer principio de la Asociación: «Las ideas complejas provienen de la asociación de otras más simples.»

El surgimiento (en Alemania) de la Gestalt, como teoría psicológica, completa el panorama de la psicología centroeuropea, junto al estructuralismo, el funcionalismo, que nacieron hacia finales del siglo XIX y principios del siglo XX, y particularmente, junto al psicoanálisis.

Con fuerte acento en el idealismo trascendental kantiano, la Gestalt referirá la organización de la percepción en el sujeto a un marco estructurador de lo real a priori, esto es, independientemente de la experiencia.

La noción de Gestalt es introducida por Christian Von Ehrenfels en 1890, como «forma», «estructura» (eso significa, justamente, la palabra "Gestalt" en alemán), al descubrir que una misma melodía podría ser tocada sobre distintas notas, al tiempo que las mismas notas en distinto orden daban lugar a una tonada distinta.
Siendo que la tonada se da a la percepción, sucede que la totalidad estructural, o sea, la forma, la pone el sujeto.

De acuerdo con Kurt Koffka (1935), la aplicación de Gestalt significa «determinar que partes de naturaleza pertenecen a todos funcionales, para descubrir su posición en ellos, su grado de independencia relativa y la articulación de grandes todos en sub-todos»
La fórmula fundamental de la teoría Gestalt, puede ser expresada de la siguiente forma: «Hay todos cuyo comportamiento no está destinado por sus elementos individuales, sino donde los procesos parte se encuentran determinados por la naturaleza intrínseca del todo». Es la esperanza de la teoría Gestalt el determinar la naturaleza de tales todos.

Como su nombre indica, es una corriente enfocada a la función de la mente y no tanto a su estructura. Es decir, cómo interactuamos como individuos con nuestro entorno y cómo nos desenvolvemos en el medio. Un ejemplo que ilustra esta corriente es la función del corazón. Tácitamente la importancia de este órgano radica en bombear la sangre a todo el cuerpo para que funcione correctamente, no importando así si es de metal o de plástico.

La psicología básica es la parte de la psicología que tiene como función fundamental la recopilación y organización estructurada de conocimientos nuevos acerca de los fundamentos de actuación de los procesos psicológicos básicos, como la percepción, la atención, la memoria, el lenguaje, el aprendizaje, el razonamiento y la resolución de problemas. Por otra parte, la psicología aplicada (ver más adelante), busca solucionar problemas prácticos por medio de la aplicación y la transformación a diferentes contextos, de los conocimientos generados por la psicología básica.

La psicología, por abordar al individuo humano, constituye un campo de estudio intermedio entre «lo biológico» y «lo social». Lo biológico se presenta como substrato del sistema psíquico. Progresivamente, y en la medida que la comprensión del funcionamiento del cerebro y la mente han avanzado, los aportes de la neurobiología se han ido incorporando a la investigación psicológica a través de la neuropsicología y las neurociencias cognitivas, Teoría de las Ciencias Humanas.

Tradicionalmente, estas funciones han sido estudiadas por la Psicología cognitiva, y se han planteado para cada uno diferentes modelos que explican sus mecanismos a la base. Pero, al menos en su definición, se puede describir lo siguiente:







El aprendizaje es un metaproceso psicológico en el que se ven implicados el lenguaje, el pensamiento, la memoria, la atención, etc. Es para la psicología una de las principales áreas de estudio y aplicación, al responder a uno de los llamados conceptos centrales de la disciplina: la generación de cambio en los sistemas individuales y colectivos. Esta define procesos de aprendizaje conductual y procesos de aprendizaje cognitivo, según impliquen un cambio en la conducta o un cambio en el pensamiento.

La psicología del aprendizaje se ocupa del estudio de los procesos que producen cambios relativamente permanentes en el comportamiento del individuo (aprendizaje). Es una de las áreas más desarrolladas y su estudio ha permitido elucidar algunos de los procesos fundamentales involucrados en el aprendizaje como proceso completo:


Básicamente existen dos teorías que explican el aprendizaje tanto humano como animal: el conductismo y el constructivismo (ver constructivismo), también conocido como cognoscitivismo. Se diferencian en las suposiciones iniciales que consideran como ciertas y que utilizan como base de sus teorías. En el conductismo, se consideran dos principios:


Los constructivistas, en cambio, niegan ambos principios e incluyen los factores cognitivos, socio-culturales y emocionales
como determinantes de las conductas. Entre ellos se destacan los piagetianos (seguidores de las enseñanzas de Jean Piaget), quienes hablan del principio de asimilación-acomodación como determinante del aprendizaje, según el cual cada individuo asimila un nuevo conocimiento según su estructura cognitiva acomodándolo a los conocimientos previos, eso explicaría porqué distintas personas aprenden diferentes cosas a partir de los mismos estímulos.

La psicología del aprendizaje cobra una gran importancia en la educación. Docentes y pedagogos deben considerar aspectos tan importantes como la motivación, los intereses, las expectativas y necesidades de los estudiantes.

Tiene como finalidad el estudio psicológico de las diferentes etapas de crecimiento y desarrollo del ser humano, como lo manifestó Arnold Gesell. Busca comprender la manera en que las personas perciben, entienden y actúan en el mundo y cómo todo eso va cambiando de acuerdo a la edad (ya sea por maduración o por aprendizaje). A esta materia también se le conoce con el nombre de «psicología del ciclo vital», ya que estudia los cambios psicológicos a lo largo de toda la vida de las personas. Ese sería, por tanto, el objeto de estudio de la psicología del desarrollo.

La psicología del desarrollo está interesada en explicar los cambios que tienen lugar en las personas con el paso del tiempo, es decir, con la edad. Dentro de esta área el foco de atención puede centrarse en el desarrollo físico, intelectual o cognitivo, emocional, sexual, social, moral.

Siguiendo a Erik Erikson, esos cambios que se dan en las personas a lo largo de la vida pueden ser explicados a través de unos factores que se encuentran enfrentados por parejas: la continuidad versus discontinuidad, la herencia versus el ambiente, y la normatividad versus la ideografía. También el contexto en el que se desarrollan los sujetos nos permite comprender mejor su evolución; así, es necesario destacar el contexto histórico, el socio-económico, el cultural e incluso, el étnico, por citar los más importantes. Finalmente, el desarrollo debe ser entendido como un proceso continuo, global y dotado de una gran flexibilidad.

A lo largo del último siglo han sido varias las corrientes y los modelos teóricos que han aportado sus descubrimientos e investigaciones para explicar el fenómeno del cambio. En general, cada uno de estos modelos tiene sus propias explicaciones, a veces contradictorias, a las que se presentan desde otras teorías. Esa diversidad de paradigmas explicativos enriquece la comprensión del fenómeno del desarrollo. Entre los más significativos de estos modelos es necesario citar el psicoanálisis, la psicología genética de Jean Piaget, el modelo sociocultural de Lev Vygotski, las teorías del aprendizaje, el modelo del procesamiento de la información, y más recientemente, el modelo ecológico y el etológico.

Los investigadores que estudian niños utilizan una serie de métodos únicos de indagación para comprometerlos en tareas experimentales prediseñadas. Estas tareas a menudo semejan juegos y actividades que resulten entretenidas para los niños, y al mismo tiempo útiles desde un punto de vista científico. Además del estudio del comportamiento de niños, los psicólogos del desarrollo también estudian a individuos en otras etapas vitales, y principalmente, los momentos en que se producen las transiciones entre una etapa y otra (por ejemplo, la pubertad, o la adolescencia tardía).

La psicopatología es la rama de la psicología que describe los eventos que se presentan en la conducta visible o no explícita en diversos trastornos de la conducta y los trastornos mentales, el desarrollo y las consecuencias de estos comportamientos y condiciones psíquicas, tanto desde una visión fenomenológica-clasificatoria, como circunscrita a una teoría o corriente particular.

Es el campo de la psicología que estudia los fenómenos de la creación y de la percepción artística, desde un punto de vista psicológico. En colaboración con la estética y la crítica del arte, utiliza teorías y métodos psicológicos para el análisis de los fenómenos y las producciones artísticas. La investigación se desarrolla en varias direcciones: análisis del proceso creativo, de los productos artísticos, de las relaciones entre el artista y la obra, y entre la obra y el usuario. La psicología del arte utiliza los resultados de la investigación psicológica base, incluidas las técnicas experimentales, los resultados comparativos y las investigaciones clínicas; aborda las áreas de estudio que se refieren a los procesos cognoscitivos como la imaginación, la memoria, el lenguaje y la creatividad. Aportes como los de Gustav Theodor Fechner, Sigmund Freud, la escuela de la Gestalt (dentro de la que destaca el desarrollo de Rudolph Arnheim), Lev Vygotski y Howard Gardner han sido cruciales en el desarrollo de esta disciplina.

Durante el siglo XX, los psicólogos, al igual que los expertos en otros campos de la ciencia, se preocuparon por extender las concepciones ya existentes, especialmente en medicina, sobre los tipos de contextura física y sus relaciones con disposiciones comportamentales. A partir de este conocimiento se diseñaron varios modelos de factores de la personalidad y pruebas para determinar el conjunto de rasgos que caracterizaban a una persona. Hoy en día, la personalidad se entiende como un conjunto organizado de rasgos, es decir comportamientos relativamente permanentes y estables en el tiempo, que caracterizan a un individuo.

El estudio de la personalidad sigue estando de actualidad y se configura alrededor de tres modelos válidos: el clínico, el correlacional y el experimental. El modelo clínico da prioridad al estudio a profundidad de los individuos. El modelo correlacional busca explorar diferencias individuales mediante estudios de tipo encuesta en grandes muestras de población. El modelo experimental busca establecer relaciones causa-efecto a partir de la manipulación de variables. Si bien existen diferentes posiciones respecto al nivel de cientificidad de cada modelo, en la actualidad cada uno de ellos agrupa un conjunto de teorías de gran utilidad para el trabajo aplicado del psicólogo.

Uno de los modelos predominantes es el llamado modelo de cinco factores de la personalidad: neuroticismo, extraversión, agradabilidad, apertura y conciencia.

La psicología aplicada o profesional agrupa a las distintas vertientes de la psicología que tienen aplicación directa en la solución de problemas y optimización de procesos humanos con fines profesionales (de allí deriva su denominación como psicología profesional).

Muchos de los conocimientos de la psicología aplicada provienen de la psicología básica, sin embargo cabe señalar que la aplicación profesional genera constantemente nuevo conocimiento de orden conceptual y/o procedimental que muchas veces alcanza independencia del conocimiento básico que le dio origen.

Las vertientes más conocidas en el rubro de la psicología aplicada son la clínica, la educativa, la organizacional y la comunitaria (muchas veces denominada "social" o "social-comunitaria"); pero también existen otras ramas de creciente desarrollo.

Se ocupa de la investigación de las funciones mentales de las personas que padecen sufrimiento, no solo derivado por un trastorno mental sino también trastornos de orientación del desarrollo de las potencialidades humanas. Puede usar como apoyo las diversas pruebas psicológicas que se han creado, pero teniendo en cuenta que jamás una prueba reemplaza a la fuente del conocimiento, que es la entrevista.

La psicología educativa es el área de la psicología que se dedica al estudio de los fenómenos del aprendizaje y técnicas para mejorar la enseñanza humana dentro de los centros educativos; comprende el análisis de las formas de aprender y de enseñar.

Mediante el estudio de la psicología educativa se busca conocer los factores que han intervenido en el desenvolvimiento de las potencialidades o aquellos que las dificultan.

Es el estudio del comportamiento de los niños desde el nacimiento hasta la adolescencia, que incluye sus características físicas, cognitivas, motoras, lingüísticas, perceptivas, sociales y emocionales.

Los psicólogos infantiles intentan explicar las semejanzas y las diferencias entre los niños, así como su comportamiento y desarrollo. También desarrollan métodos para tratar problemas sociales, emocionales y de aprendizaje, aplicando terapias en consultas privadas y en escuelas, hospitales y otras instituciones.

Las dos cuestiones críticas para los psicólogos infantiles son: primero, determinar cómo las variables ambientales (el comportamiento de los padres, por ejemplo) y las características biológicas (como las predisposiciones genéticas) interactúan e influyen en el comportamiento; y segundo, entender cómo los distintos cambios en el comportamiento se interrelacionan.

La psicología social investiga la interacción de los seres humanos, sobre todo en grupos y situaciones sociales, y subraya la influencia de las situaciones sociales en la conducta humana. La psicología social trata de comprender el mundo social, a la vez que se interesa por la interacción humana desde tres puntos de vista: psicológico, social y simbólico. Muchos procesos sociales implican relaciones entre personas, o la vinculación de la gente a la sociedad y a sus instituciones, o la presencia simbólica de la sociedad en la mente del individuo. El conocimiento psicosocial se aplica en áreas como las formas de atracción interpersonal, relaciones internacionales, discriminación de grupos minoritarios, publicidad, prejuicios, fanatismo, etcétera. La importancia de la matriz social en la explicación de la conducta humana exige un examen de las nociones de socialización y cultura humana, así como del pensamiento social: percepción (conocimiento de las personas), atribución (conocer las causas de la conducta propia y ajena) y cognición (conocimiento de la «realidad social»).

La psicología del trabajo y de las organizaciones, a veces también llamada psicología laboral o psicología organizacional, deriva de lo que inicialmente se llamó psicología industrial (y aún se le sigue llamando así, sobre todo en el ámbito de lo académico). Sin embargo, la posterior incorporación de nuevos elementos, provenientes del área de estudio de la psicología social y aplicados a las organizaciones, marca una diferencia que no sólo es terminológica, sino también conceptual. Mientras la psicología organizacional enfatiza en un enfoque sistémico o estructural, poniendo el acento en las relaciones y procesos de la dinámica de la organización, a la vez que opera con una idea de organización más amplia, que incluye a las instituciones no laborales o empresariales (escuelas, hospitales, etcétera), la aproximación al tema de la psicología del trabajo o laboral se ocupa de todos los aspectos psicológicos del trabajo humano (tales como la ergonomía, el análisis de puestos de trabajo, o la selección de personal), pero poniendo énfasis en el comportamiento individual, en la manera en que el individuo actúa en su contexto laboral, en el carácter de su relación individual con la organización empresarial en la que trabaja.

La denominación «psicología del trabajo y de las organizaciones» aspira a englobar ambos enfoques, y tiene por objeto el estudio y la optimización del comportamiento del ser humano en las organizaciones, fundamentalmente en contextos laborales, profesionales y empresariales (industriales o no), pero también en otros ámbitos institucionales. Esta área de la psicología constituye, junto a la psicología clínica y la psicología de la educación, uno de los tres grandes ámbitos de aplicación de esta ciencia del comportamiento humano.

Trabajan con los pobladores de una comunidad urbana o rural para el estudio de sus recursos humanos y materiales, facilitando que satisfagan necesidades vitales como salud, educación, vivienda, salubridad, alimentación, trabajo, deporte, recreación y otros.

El conjunto de contribuciones científicas, educativas y profesionales que las diferentes disciplinas psicológicas hacen a la promoción y mantenimiento de la salud, a la prevención y tratamiento en la especialidad, a la identificación de los correlatos etiológicos y diagnósticos de la salud, la enfermedad y las disfunciones relacionadas.

Se dedica al diseño de intervenciones en poblaciones que han sufrido desastres, ya sea en los momentos recientes o los mediatos, para aminorar las secuelas emocionales.

Comprende un amplio rango de prácticas que involucran principalmente evaluaciones de capacidad de los acusados, informes a jueces, abogados y testimonio en juzgados sobre temas determinados. Entre ellos está la psicología criminal, consistente en estimar un perfil psicológico de un individuo hipotético, que facilite la aprehensión de cualquier criminal, tomando en cuenta aspectos, conductas y evidencias del sospechoso, se le conoce como psicología criminal.

La Asociación Estadounidense de Psicología (APA) define a la psicología del deporte como «el estudio científico de los factores psicológicos que se asocian con la participación y el desempeño en el deporte». Sus objetivos principales son apoyar a los atletas a aumentar su desempeño y comprender el papel del deporte en la salud.

El término "psicólogo" tiene dos acepciones generales, por un lado es una persona que tiene un título profesional en Psicología y que ejerce la práctica de la misma, para esto debe poseer el grado académico de "Licenciado/Graduado en Psicología" y haberse colegiado en el "Colegio de Psicólogos" de la jurisdicción donde ejerce. Cabe agregar en todo caso que no en todos los países la colegiatura es obligatoria, sino voluntaria. Esto viene determinado por las leyes particulares de cada país. Asimismo, en otros países como en Chile algunas escuelas de psicología ofrecen al estudiante la opción de recibir solo el «título profesional» de psicólogo acreditado por una práctica profesional, y no necesariamente el «grado académico» de licenciado en psicología, que implica para su acreditación la elaboración de una tesis de grado.

En otro sentido, se entiende como psicólogo a toda persona que estudia el comportamiento humano en sus diferentes ámbitos desde un enfoque científico. De ahí que personajes tan importantes como Sigmund Freud, Carl Jung, Carl Rogers, Alfred Adler, Jean Piaget, Wilhem Wundt o Eric Berne, que provienen de áreas tan dispares como la medicina, la biología y la física, sean considerados como los padres de la psicología y que se les reconozca, dentro del gremio, su estatus como psicólogos.

En casi todos los países del mundo existen facultades o escuelas de Psicología en las principales universidades tanto públicas como privadas. En las universidades que no poseen una facultad de psicología, esta carrera suele estar adscrita a las facultades de ciencias sociales, humanidades y ciencias humanas, dependiendo del país, de la institución y de la orientación de la formación.

El estudio de la psicología está especialmente difundido en Europa y Norteamérica; en América Latina está en amplio crecimiento, encontrándose especialmente desarrollada en Sudamérica, donde países como Argentina, Chile y Brasil son reconocidos en todo el mundo por sus aportes a la teoría, especialmente en el área del Psicoanálisis. Otra área de estudio desarrollada en América Latina es la psicología social y su aplicación comunitaria, donde países como El Salvador, Puerto Rico, Venezuela y México han dado varios de los teóricos más importantes en este campo.

Aunque cada programa de instrucción en psicología varía según la institución que lo imparte, en líneas generales los psicólogos deben tener formación en:





A estos aspectos se les suma la formación en ciencias básicas y en ciencias aplicadas, de acuerdo con la estructuración y los objetivos de cada centro de estudios profesionales que imparte la carrera.

La psicología tiene un terreno amplio de aplicaciones, tantas como hechos humanos hay. Los psicólogos frecuentemente optan por la especialización en un área de su preferencia (más del 60 por ciento de ellos se dedican a la clínica), o a aquella que represente mayores retribuciones laborales, o un mayor campo de trabajo (industrial-organizacional). Actualmente, la tendencia va más hacia la integración interdisciplinaria de los diferentes campos y con carreras afines, en pos de una comprensión de la complejidad del individuo, de su existencia y de su vida psíquica que permita estudiar, investigar, teorizar, e intervenir de una forma más adecuada, más efectiva, y más real, en los problemas que aquejan a la humanidad en su eterno devenir por la experiencia del sí mismo y de los otros.

La psicología y la psiquiatría pueden ser confundidas debido a que una de las ramas de la psicología, la psicología clínica, aborda el fenómeno de la salud mental al igual que la psiquiatría. La psicoterapia psiquiátrica también ha difuminado todavía más los límites entre psiquiatría y psicología. Las diferencias fundamentales radican en la formación recibida y el uso de medicamentos para el tratamiento.

Diccionarios como el "Diccionario de la lengua española" de la Real Academia Española recogen otros significados del término "psicología", además de los ya desarrollados en este artículo, que no se abordan centralmente en él o bien que no se mencionan de manera explícita:




</doc>
<doc id="2128" url="https://es.wikipedia.org/wiki?curid=2128" title="Película (desambiguación)">
Película (desambiguación)

Película generalmente se refiere a la obra de arte cinematográfica. Además, película —o su plural, películas— puede referirse a:


</doc>
<doc id="2130" url="https://es.wikipedia.org/wiki?curid=2130" title="Pirata (desambiguación)">
Pirata (desambiguación)

La palabra «pirata» puede referirse a:


La palabra «piratas» (el plural de «pirata») puede referirse a:


</doc>
<doc id="2134" url="https://es.wikipedia.org/wiki?curid=2134" title="Pecado">
Pecado

Pecado (latín "peccātum") es la transgresión voluntaria y con conocimiento de un precepto moral o religioso. 
En Teología moral se lo considera «un acto malo, o la omisión culpable de un acto bueno obligatorio». Por extensión, se denomina pecado a todo aquello que se aparta de lo recto y justo, o que falta a lo que es debido.

Para los griegos pecado se decía "hamartia": ‘fallo de la meta, no dar en el blanco’. Los escritores griegos solían utilizar la forma verbal hamartánō con respecto al lancero que erraba su blanco y, por implicación, aludía al concepto de vivir al margen de un código moral o intelectual tenido por meta ideal, debido a una actitud errónea, consciente o inconscientemente. En tal caso la hamartia o pecado suele ser una "desmesura" o hybris de algo que realizado armoniosamente es correcto.

En hebreo la palabra común para "pecado" es "jattáʼth", חטא que también significa “errar” en el sentido de no alcanzar una meta, camino, objetivo o blanco exacto. En se utiliza la forma verbal jatáʼ en una frase negativa para referirse a los benjamitas como ‘personas que podían tirar piedras con honda a un cabello y no erraban’ (véase también ). Igualmente se aplica a desviarse de metas morales, como en , que dice que el que halla sabiduría piadosa halla vida, pero ‘el que no alcanza (heb. jatáʼ) la sabiduría le está haciendo violencia a su alma’, pues la lleva a la muerte. En Arameo la palabra para "pecado" es khata.

El concepto religioso aún vigente de pecado como ‘delito moral’ alude a la trasgresión voluntaria de normas o preceptos religiosos. Dado que existen innumerables normas de este tipo, existen innumerables pecados, a los cuales se les asigna mayor, menor o ningún castigo según las distintas creencias.

En los estados confesionales, que tienen una "religión oficial", puede estar penado con la privación de libertad, e incluso de la vida, y en entornos culturalmente pobres, aun en sociedades modernas, se suelen achacar los problemas o accidentes físicos a la comisión de pecados.

La tradición judeocristiana, cuya fuente fundamental es la Biblia, ha entendido el pecado, en términos generales, como el alejamiento del hombre de la voluntad de Dios.

De acuerdo al Tanaj o Antiguo Testamento, esta voluntad está representada por la Ley (Torah), preceptos y estatutos dados por Dios al pueblo de Israel, y registrados en los libros sagrados. 

Aún hoy, para el judaísmo no existe un pecado genérico a manera de naturaleza subyacente en los actos de los hombres, sino solo transgresiones objetivas y concretas (no pensamientos o intenciones del corazón) que se cometen voluntariamente. En cambio, de acuerdo con el Nuevo Testamento, y la tradición del cristianismo, existe una naturaleza pecaminosa en el ser humano, heredada de la primera transgresión de Adán y Eva. Esta naturaleza pecaminosa del hombre afecta tanto sus actos como sus pensamientos, y no se puede superar con el solo esfuerzo de seguir la Ley de Dios, por lo tanto, solo mediante la sangre de Jesucristo este pecado genérico del hombre, y las culpas individuales, son expiadas. Esta expiación se hace válida para la persona mediante la fe en Jesucristo y la regeneración espiritual por medio del nuevo nacimiento mencionado en el Evangelio de Juan 3:3-8, y 1ª Pedro 1:3. Así puede vencerse esta naturaleza, y por ende, anular su efecto condenatorio final, que no su efecto sobre la vida del creyente.

Las distintas corrientes del cristianismo han elaborado de distinta forma la doctrina que sustenta esta concepción del hombre en lucha permanente contra el pecado, como naturaleza propia, y la victoria sobre él.

La Biblia y la tradición eclesiástica definen y se refieren a las diferentes clases de pecados:

El pecado en general, consiste en una transgresión libre y deliberada de la Ley de Dios. Por leve que sea, es pecado cualquier desviación de los mandatos divinos. La naturaleza esencial del pecado es la rebelión contra Dios, y es pecaminoso cualquier acto en el cual la voluntad humana se opone a la voluntad divina conocida ya sea por un mandamiento revelado o por la conciencia sembrada por Dios en cada ser humano. El pecado se ha clasificado de diferentes formas:

De acuerdo a lo señalado en el Catecismo católico, el pecado es "una falta contra la razón, la verdad, la conciencia recta; es faltar al amor verdadero para con Dios y para con el prójimo, a causa de un apego perverso a ciertos bienes. Hiere la naturaleza del hombre y atenta contra la solidaridad humana. Ha sido definido como ‘una palabra, un acto o un deseo contrarios a la ley eterna’ (S. Agustín, Faust. 22, 27; S. Tomás de A., s. th., 1-2, 71, 6) )" "

Agustín de Hipona define que hay pecado «cuando la soberbia personal ama una parte del todo haciendo de ella un falso todo». José María Cabodevilla señala al respecto:

El pecado se considera "una ofensa a Dios: ‘Contra ti, contra ti solo he pecado, lo malo a tus ojos cometí’ ('). El pecado se levanta contra el amor que Dios nos tiene y aparta de El nuestros corazones. Como el primer pecado, es una desobediencia, una rebelión contra Dios por el deseo de hacerse ‘como dioses’, pretendiendo conocer y determinar el bien y el mal ('). El pecado es así ‘amor de sí hasta el desprecio de Dios’ (S. Agustín, civ, 1, 14, 28). Por esta exaltación orgullosa de sí, el pecado es diametralmente opuesto a la obediencia de Jesús que realiza la salvación (cf Flp 2, 6-9)" 

No obstante ello, se asume que en la Pasión, la misericordia de Cristo vence al pecado. "En ella, es donde este manifiesta mejor su violencia y su multiplicidad: incredulidad, rechazo y burlas por parte de los jefes y del pueblo, debilidad de Pilato y crueldad de los soldados, traición de Judas tan dura a Jesús, negaciones de Pedro y abandono de los discípulos. Sin embargo, en la hora misma de las tinieblas y del príncipe de este mundo (""), el sacrificio de Cristo se convierte secretamente en la fuente de la que brotará inagotable el perdón de nuestros pecados". 

El pecado imperdonable es aquel que, según la Biblia, se comete en contra del Espíritu Santo.

Cabe especificar, que el pecado imperdonable, es aquel que hicieron los fariseos al Espíritu Santo. La blasfemia contra el Espíritu Santo (pecado imperdonable: Los Fariseos clamaban que el Señor estaba poseído por el demonio “Beelzebú” (Mateo 12:24) Ahora, notemos que en Marcos 3:29-30, Jesús es muy específico acerca de lo que ellos cometieron exactamente: “la blasfemia contra el Espíritu Santo”.

En la Fe Bahá'í, los seres humanos son considerados naturalmente buenos (perfectos), fundamentalmente seres espirituales. Los seres humanos fueron creados por el amor inconmensurable de Dios. Sin embargo, las enseñanzas bahá'ís comparar el corazón humano a un espejo que, si se apartó de la luz del sol (es decir, Dios), es incapaz de recibir el amor de Dios.

El budismo no reconoce la idea detrás de pecado, sino que cree en el principio del karma, por lo que el sufrimiento es la consecuencia inevitable de la codicia, la ira y la ignorancia (conocido como los Tres venenos). Si bien no hay equivalente directo del concepto judeocristiano de pecado, el de "maldad" si es reconocido en el budismo. El concepto de la ética budista es consecuencialista en la naturaleza y no se basa en deberes para con una divinidad.

En el hinduismo, el término pecado (papa en sánscrito) se utiliza a menudo para describir las acciones que crean karma negativo por violar los códigos morales y éticos, que automáticamente trae consecuencias negativas. Esto es diferente del concepto de pecado en las religiones judeocristianas en el sentido de que "papá" no es un crimen en contra de la voluntad de Dios, sino en contra (1) Dharma, o el orden moral, y (2) el orden propio de uno.

Los musulmanes ven el pecado (dhanb, thanb ذنب) como algo que va en contra de los mandamientos de Dios (Allah). El Islam enseña que el pecado es un acto y no un estado del ser. El Corán enseña que "el alma es ciertamente propensa al mal, a menos que el Señor le conceda su misericordia" y que incluso los profetas no absolverse de la culpa. Se cree que Iblís (Satanás) tiene un papel importante en la humanidad tentadora hacia el pecado.
En el Islam, hay varios grados de pecado:
sayyia, khatia: errores (Suras 7:168; 17:31; 40:45; 48:2 47:19)
itada, Junah, dhanb: inmoralidad (Suras 2:190,229; 17:17 33:55)
haram: transgresiones (Suras 5:04; 6:146)
ITHM, dhulam, fujur, su, fasad, Fisk, kufr: la maldad y depravación (suras 2:99, 205, 4:50, 112, 123, 136; 12:79; 38:62; 82:14)
shirk: atribuir un socio a Dios (Sura 4:48)
Uno puede arrepentirse sinceramente a Dios por los pecados cometidos y buscar el perdón, como se dice en el Corán: "¡Señor! Perdónanos nuestros pecados, quite de nosotros nuestras iniquidades, y toma para ti a nuestras almas en compañía de los justos". (Al-Imran.193 / 3.193).
"Oye a mis esclavos que se rebelaron desesperadamente contra sus almas, no de la misericordia de Dios, en verdad Él perdona todos los pecados, ciertamente Él es el Indulgente, el Misericordioso" (al-Zumar)

Si bien todo pecado es personal, porque es un acto de libertad de un hombre en particular, y no propiamente de un grupo o comunidad, es al mismo tiempo social: "en virtud de una solidaridad humana tan misteriosa e imperceptible como real y concreta, el pecado de cada uno repercute en cierta manera en los demás." Por ello mismo la Iglesia, cuando habla de situaciones de pecado o denuncia como pecados sociales determinadas situaciones o comportamientos colectivos de grupos sociales más o menos amplios, o hasta de enteras naciones y bloques de naciones, sabe y proclama que estos casos de pecado social son el fruto, la acumulación y la concentración de muchos pecados personales.
Las verdaderas responsabilidades son de las personas» "".

Algunos pecados, en particular, constituyen por su objeto mismo una agresión directa al prójimo. Estos pecados se califican como pecados sociales. "Así se considera como social todo pecado cometido contra la justicia en las relaciones entre persona y persona, entre la persona y la comunidad, y entre la comunidad y la persona. 
Es social todo pecado contra los derechos de la persona humana, comenzando por el derecho a la vida, o contra la integridad física de alguien; todo pecado contra la libertad de los demás, especialmente contra la libertad de creer en Dios y adorarlo; todo pecado contra la dignidad y el honor del prójimo. Es social todo pecado contra el bien común y contra sus exigencias, en toda la amplia esfera de los derechos y deberes de los ciudadanos. En fin, es social el pecado que se refiere a las relaciones entre las distintas comunidades humanas." 





</doc>
<doc id="2135" url="https://es.wikipedia.org/wiki?curid=2135" title="Pecados capitales">
Pecados capitales

Los siete pecados capitales son una clasificación de los vicios mencionados en las primeras enseñanzas del cristianismo para educar a sus seguidores acerca de la moral cristiana.

El término «capital» (de "caput", "capitis", "cabeza", en latín) no se refiere a la magnitud del pecado sino a que da origen a muchos otros pecados, de acuerdo a santo Tomás de Aquino (II-II:153:4).

La identificación y definición de los pecados capitales a través de su historia ha sido un proceso fluido y ―como es común con muchos aspectos de la religión― con el tiempo ha evolucionado la idea de lo que envuelve cada uno de estos pecados. Ha contribuido a estas variaciones el hecho de que no se hace referencia a ellos de una manera coherente o codificada en la "Biblia" y por tanto se han consultado otros trabajos tradicionales (literarios o eclesiásticos) para conseguir definiciones precisas de los pecados capitales.

Al principio del cristianismo, todos los escritores religiosos
―Cipriano de Cartago,
Juan Casiano,
Columbano de Luxeuil,
Alcuino de York―
enumeraban ocho pecados capitales.

El número siete fue dado por el papa Gregorio Magno y se mantuvo por la mayoría de los teólogos de la Edad Media.

Se sabe que el santo africano Cipriano de Cartago (f. 258) ―en "De Mort". (IV)― escribió acerca de ocho pecados principales.

El monje Evagrio Póntico (345-399) escribió en griego "Sobre los ocho vicios malvados", una lista de ocho vicios o pasiones malvadas ("logismoi" en griego) fuentes de toda palabra, pensamiento o acto impropio, contra los que sus compañeros monjes debían guardarse en especial. Dividió los ocho vicios en dos categorías:

En el siglo V, san Juan Casiano (ca. 360-435) ―en su "De institutis coenobiorum" (V, coll. 5, «de octo principalibus vitiis»)― actualizó y difundió la lista de Evagrio.

Columbano de Lexehuil (540-615) ―en su "Instructio de octo vitiis principalibus" en "Bibl. max. vet. patr." (XII, 23)― y Alcuino de York (735-804) ―en su "De virtut. et vitiis", XXVII y siguientes)― continuaron la idea de ocho pecados capitales.

En el siglo VI, el papa romano san Gregorio Magno ("circa" 540-604) ―en su "Lib. mor. en Job" (XXXI, XVII)― revisó los trabajos de Evagrio y Casiano para confeccionar una lista propia definitiva con distinto orden y reduciendo los vicios a siete (consideró que la tristeza era una forma de pereza).


San Buenaventura de Fidanza (1218-1274) enumeró los mismos.

Santo Tomás de Aquino (1225-1274) respetó esa misma lista, con otro orden:

El poeta Dante Alighieri (1265-1321) utilizó el mismo orden del papa Gregorio Magno en «El Purgatorio», la segunda parte del poema "La Divina Comedia" (c. 1308-1321). La teología de "La Divina Comedia", casi ha sido la mejor fuente conocida desde el Renacimiento (siglos XV y XVI).

Muchas interpretaciones y versiones posteriores, especialmente derivaciones conservadoras del protestantismo y del movimiento cristiano pentecostal han postulado temibles consecuencias para aquellos que cometan estos pecados como un tormento eterno en el infierno, en vez de la posible absolución a través de la penitencia en el purgatorio.

La lujuria (en latín, , ‘abundancia’, ‘exuberancia’) es usualmente considerada como el pecado producido por los pensamientos excesivos de naturaleza sexual, o un deseo sexual desordenado e incontrolable.

En la actualidad se considera lujuria a la compulsión sexual o adicción a las relaciones sexuales. También entran en esta categoría el adulterio y la violación.

A lo largo de la historia, diversas religiones han condenado o desalentado en mayor medida o menor medida la lujuria.

Dante Alighieri consideraba que lujuria era el amor hacia cualquier persona, lo que pondría a Dios en segundo lugar. Según otro autor la lujuria son los pensamientos posesivos sobre otra persona.

Por otra parte, el "Diccionario de la Real Academia Española de la Lengua" ("DRAE", XXII edición, 2012) define el significado y uso apropiado de la palabra «lujuria» de dos maneras: Como un «Vicio consistente en el uso ilícito o en el apetito desordenado de los deleites carnales». O como el «Exceso o demasía en algunas cosas». De tal manera que es prudente considerar, además, que la lujuria inicia donde ha terminado la temperancia.

 Actualmente la gula (en latín, ) se identifica con la glotonería, el consumo excesivo de comida y bebida. En cambio en el pasado cualquier forma de exceso podía caer bajo la definición de este pecado. Marcado por el consumo excesivo de manera irracional o innecesaria, la gula también incluye ciertas formas de comportamiento destructivo. De esta manera el abuso de sustancias o las borracheras pueden ser vistos como ejemplos de gula. En "La Divina Comedia" de Alighieri, los penitentes en el Purgatorio eran obligados a pararse entre dos árboles, incapaces de alcanzar y comer las frutas que colgaban de las ramas de estos y por consecuencia se les describía como personas hambrientas.

La avaricia (en latín, ) es —como la lujuria y la gula—, un pecado de exceso. Sin embargo, la avaricia (vista por la Iglesia) aplica sólo a la adquisición de riquezas en particular. Santo Tomás de Aquino escribió que la avaricia es «un pecado contra Dios, al igual que todos los pecados mortales, en lo que el hombre condena las cosas eternas por las cosas temporales». En el Purgatorio de Dante, los penitentes eran obligados a arrodillarse en una piedra y recitar los ejemplos de avaricia y sus virtudes opuestas. «Avaricia» es un término que describe muchos otros ejemplos de pecados. Estos incluyen deslealtad, traición deliberada, especialmente para el beneficio personal, como en el caso de dejarse sobornar. Búsqueda y acumulación de objetos, robo y asalto, especialmente con violencia, los engaños o la manipulación de la autoridad son todas acciones que pueden ser inspiradas por la avaricia. Tales actos pueden incluir la simonía.

La pereza (en latín, ) es el más «metafísico» de los pecados capitales, en cuanto está referido a la incapacidad de aceptar y hacerse cargo de la existencia de uno mismo. Es también el que más problemas causa en su denominación. La simple «pereza», más aún el «ocio», no parecen constituir una falta. Hemos preferido, por esto, el concepto de «acidia» o «acedía». Tomado en sentido propio es una «tristeza de ánimo» que aparta al creyente de las obligaciones espirituales o divinas, a causa de los obstáculos y dificultades que en ellas se encuentran. Bajo el nombre de cosas espirituales y divinas se entiende todo lo que Dios nos prescribe para la consecución de la eterna salud (la salvación), como la práctica de las virtudes cristianas, la observación de los preceptos divinos, de los deberes de cada uno, los ejercicios de piedad y de religión. Concebir pues tristeza por tales cosas, abrigar voluntariamente, en el corazón, desgano, aversión y disgusto por ellas, es pecado capital.
Tomada en sentido estricto es pecado mortal en cuanto se opone directamente a la caridad que nos debemos a nosotros mismos y al amor que debemos a Dios. De esta manera, si deliberadamente y con pleno consentimiento de la voluntad, nos entristecemos o sentimos desgana de las cosas a las que estamos obligados; por ejemplo, al perdón de las injurias, a la privación de los placeres carnales, entre otras; la acidia es pecado grave porque se opone directamente a la caridad de Dios y de nosotros mismos.

Considerada en orden a los efectos que produce, si la acidia es tal que hace olvidar el bien necesario e indispensable a la salud eterna, descuidar notablemente las obligaciones y deberes o si llega a hacernos desear que no haya otra vida para vivir entregados impunemente a las pasiones, es sin duda pecado mortal.

La ira (en latín, ) puede ser descrita como un sentimiento no ordenado, ni controlado, de odio y enfado. Estos sentimientos se pueden manifestar como una negación vehemente de la verdad, tanto hacia los demás y hacia uno mismo, impaciencia con los procedimientos de la ley y el deseo de venganza fuera del trabajo del sistema judicial (llevando a hacer justicia por sus propias manos), fanatismo en creencias políticas y religiosas, generalmente deseando hacer mal a otros. Una definición moderna también incluiría odio e intolerancia hacia otros por razones como raza o religión, llevando a la discriminación. Las transgresiones derivadas de la ira están entre las más serias, incluyendo homicidio, asalto, discriminación y en casos extremos, genocidio.

La ira es el único pecado que no necesariamente se relaciona con el egoísmo y el interés personal (aunque uno puede tener ira por egoísmo). Dante describe a la ira como «amor por la justicia pervertido a venganza y resentimiento».

Como la avaricia, la envidia (en latín, ) se caracteriza por un deseo insaciable, sin embargo, difieren por dos grandes razones: Primero, la avaricia está más asociada con bienes materiales, mientras que la envidia puede ser más general; segundo, aquellos que cometen el pecado de la envidia desean algo que alguien más tiene, y que perciben que a ellos les hace falta, y por consiguiente desean el mal al prójimo, y se sienten bien con el mal ajeno.

Dante Alighieri define esto como «amor por los propios bienes pervertido al deseo de privar a otros de los suyos». En el purgatorio de Dante, el castigo para los envidiosos era el de cerrar sus ojos y coserlos, porque habían recibido placer al ver a otros caer.

En casi todas las listas de pecados, la soberbia (en latín, ) es considerado el original y más serio de los pecados capitales, y de hecho, es la principal fuente de la que derivan los otros. Es identificado como un deseo por ser más importante o atractivo que los demás, fallando en halagar a los otros.

En "El paraíso perdido" de John Milton, dice que este pecado es cometido por Lucifer al querer ser igual que Dios.

Genéricamente se define como la sobrevaloración del Yo respecto de otros por superar, alcanzar o superponerse a un obstáculo, situación o bien en alcanzar un estatus elevado e infravalorar al contexto. También se puede definir la soberbia como la creencia de que todo lo que uno hace o dice es superior, y que se es capaz de superar todo lo que digan o hagan los demás. También se puede tomar la soberbia como la confianza exclusiva en las cosas vanas y vacías (vanidad) y en la opinión de uno mismo exaltada a un nivel crítico y desmesurado (prepotencia).

Soberbia (del latín "superbia") y orgullo (del francés "orgueil"), son propiamente sinónimos aun cuando coloquialmente se les atribuye connotaciones particulares cuyos matices las diferencian. Otros sinónimos son: altivez, arrogancia, vanidad, etc. Como antónimos tenemos: humildad, modestia, sencillez, etc. El principal matiz que las distingue está en que el orgullo es disimulable, e incluso apreciado, cuando surge de causas nobles o virtudes, mientras que a la soberbia se la concreta con el deseo de ser preferido a otros, basándose en la satisfacción de la propia vanidad, del Yo o ego. Por ejemplo, una persona Soberbia jamás se "rebajaría" a pedir perdón, o ayuda, etc.

Existen muchos tipos de soberbia, como la "vanagloria" o "cenodoxia", también denominada en las traducciones de la Biblia como "vanidad", que consiste en el engreimiento de gloriarse de bienes materiales o espirituales que se poseen o creen poseer, deseando ser visto, considerado, admirado, estimado, honrado, alabado e incluso halagado por los demás hombres, cuando la consideración y la gloria que se buscan son humanas exclusivamente. La cenodoxia engendra además otros pecados, como la filargiria o amor al dinero (codicia) y la filargía o amor al poder.

El poeta hispanolatino Aurelio Prudencio (348-410) ya utilizó personificaciones alegóricas de los vicios y virtudes en combate en su poema "Psychomachia". Muchos sermones se inspiraron en los pecados capitales durante la Edad Media, así como no pocos poemas alegóricos. En el siglo XIV pueden encontrarse en el "Libro de Buen Amor" de Juan Ruiz, el arcipreste de Hita (1284-1351) y, también, dentro del "Rimado de Palacio" del canciller de Castilla Pero López de Ayala, en forma de exposición previa o examen de conciencia de la confesión católica de los mismos. Ya en el siglo XV, la "Mesa de los pecados capitales" (1485, pintura al óleo sobre tabla), del pintor Hieronymus Bosch, refleja una consolidada iconografía de los mismos.

Posteriormente, el género literario teatral del auto sacramental (siglos XVI, XVII y primera mitad del siglo XVIII) llevado a su perfección por Pedro Calderón de la Barca, testimonia la popularidad de estas alegorías hasta pasada la mitad del siglo XVIII, cuando se prohibió en España representar este tipo de piezas teatrales (1765).

La Iglesia católica reconoce siete virtudes que forman parte del catecismo; "(que corresponden a cada pecado capital)".

En 1589, Peter Binsfeld, basándose libremente en fuentes anteriores, asoció cada pecado con un demonio que tentaba a la gente por medios asociados al pecado. Su clasificación de los demonios es la siguiente:


Según Binsfeld, también existían otros demonios que incitaban a pecar, como los íncubos (fantasmas masculinos que tenían relaciones sexuales con mujeres durmientes) y los súcubos (fantasmas femeninos que tenían relaciones sexuales con varones durmientes), que incitaban a la lujuria.




</doc>
<doc id="2139" url="https://es.wikipedia.org/wiki?curid=2139" title="Protón">
Protón

En física, el protón (del griego πρῶτον, "prōton" 'primero') es una partícula subatómica con una carga eléctrica elemental positiva 1 (1,6 × 10 C), igual en valor absoluto y de signo contrario a la del electrón, y una masa 1836 veces superior a la de un electrón.

Básicamente , se ve el protón como estable, con un límite inferior en su vida media de unos 10 años, aunque algunas teorías predicen que el protón puede desintegrarse en otras partículas. Originalmente se pensó que el protón era una partícula elemental, pero desde la década de 1970 existe una evidencia sólida de que es una partícula compuesta. Para la cromodinámica cuántica el protón es una partícula formada por la unión estable de tres quarks.

El protón y el neutrón, en conjunto, se conocen como nucleones, ya que conforman el núcleo de los átomos. En un átomo, el número de protones en el núcleo determina las propiedades químicas del átomo y qué elemento químico es. El núcleo del isótopo más común del átomo de hidrógeno (también el átomo estable más simple posible) está formado por un único protón. Al tener igual carga, los protones se repelen entre sí. Sin embargo, pueden estar agrupados por la acción de la fuerza nuclear fuerte, que a ciertas distancias es superior a la repulsión de la fuerza electromagnética. No obstante, cuando el átomo es grande (como los átomos de uranio), la repulsión electromagnética puede desintegrarlo progresivamente.

Generalmente se le acredita a Ernest Rutherford el descubrimiento del protón. En el año 1918 Rutherford descubrió que cuando se disparan partículas alfa contra un gas de nitrógeno, sus detectores de centelleo muestran los signos de núcleos de hidrógeno. Rutherford determinó que el único sitio del cual podían provenir estos núcleos era del nitrógeno y que por tanto el nitrógeno debía contener núcleos de hidrógeno. Por estas razones Rutherford sugirió que el núcleo de hidrógeno, del que en la época se sabía que su número atómico era 1, debía ser una partícula fundamental.

Antes que Rutherford, en 1886, Eugene Goldstein había observado rayos catódicos compuestos por iones cargados positivamente. Después del descubrimiento del electrón por J.J. Thomson, Goldstein sugirió que, puesto que el átomo era eléctricamente neutro, el mismo debía contener partículas cargadas positivamente. Goldstein usó los rayos canales y pudo calcular la razón carga/masa. Encontró que dichas razones cambiaban cuando variaban los gases que usaba en el tubo de rayos catódicos. Lo que Goldstein creía que eran protones resultaron ser iones positivos. Sin embargo, sus trabajos fueron largamente ignorados por la comunidad de físicos.

Las últimas observaciones experimentales, ponen el radio del protón en 8,4184 × 10 m.

Los protones no se consideran partículas elementales, sino partículas compuestas por tres partículas elementales de espín 1/2: dos quarks arriba y un quark abajo, las cuales también están unidas por la fuerza nuclear fuerte mediada por gluones. La masa de estos tres quarks sólo supone un 1% de la masa del protón. El resto proviene del cómputo de la energía de enlace al considerar el mar de gluones y los pares quark-antiquark que los rodean. La evidencia de que el protón no era una partícula elemental sino compuesta proviene de experimentos realizados durante los años 1970 que dieron lugar al modelo de partones, después reformulado dentro de la cromodinámica cuántica.

En cuanto a su clasificación, los protones son partículas de espín 1/2, por lo tanto fermiones (partículas de espín semientero). Al experimentar la interacción nuclear fuerte decimos que son hadrones, y dentro del conjunto de hadrones, bariones, que es como se designa a los hadrones que a su vez son fermiones.

Al ser los protones los bariones más ligeros, la conservación del número bariónico nos llevaría a conjeturar su estabilidad. De hecho, la desintegración espontánea de los protones libres nunca ha sido observada. Sin embargo, algunas teorías que no conservan el número bariónico, entre las que se encuentran las teorías de la gran unificación, predicen procesos del tipo:
donde un protón se desintegraría, hipotéticamente, en un positrón y en un pión neutro; o en un muon y un pión neutro.

Distintos montajes experimentales buscaron estas hipotéticas desintegraciones sin éxito en enormes cámaras subterráneas llenas de agua. El detector de partículas Super-Kamiokande en Japón, aunque no encontró ninguno de estos sucesos, estableció experimentalmente límites inferiores a la vida media de un protón del orden de 10 años.

El "antiprotón" es la antipartícula del protón. Se conoce también como protón negativo. Se diferencia del protón en que su carga es negativa y en que no forma parte de los núcleos atómicos. El antiprotón es estable en el vacío y no se desintegra espontáneamente. Sin embargo, cuando un antiprotón colisiona con un protón, ambas partículas se transforman en mesones, cuya vida media es extremadamente breve (véase Radiactividad). Si bien la existencia de esta partícula elemental se postuló por primera vez en la década de 1930, el antiprotón no se identificó hasta 1955, en el Laboratorio de Radiación de la Universidad de California, por Emilio Segre y Owen Chamberlain, razón por la cual se les concedió el en 1959.

En química, el número de protones del núcleo de un átomo se conoce como número atómico ( Z ), y determina el elemento químico al que pertenece el átomo. Por ejemplo, el número atómico del cloro es 17, de modo que todo átomo de cloro tiene 17 protones y todos los átomos con 17 protones son átomos de cloro. Las propiedades químicas de cada átomo se determinan por el número de electrones, lo que para los átomos neutros es igual a la cantidad de protones para que la carga total sea cero. Por ejemplo, un átomo de cloro neutro tiene 17 protones y 17 electrones, mientras que un ion de cloro Cl tiene 17 protones y 18 electrones, por lo que resulta una carga total de -1. Todos los átomos de un elemento dado no son necesariamente idénticos, ya que el número de neutrones puede variar para formar los diferentes isótopos, y los niveles de energía pueden variar en la formación de diferentes isómeros nucleares.

En física y química, el término "protón" puede referirse al catión de hidrógeno (H). En este contexto, un emisor de protones es un ácido, y un receptor de protones una base. Esta especie, H, es inestable en disolución, por lo que siempre se encuentra unida a otros átomos. En soluciones acuosas forma el ion hidronio u oxonio (HO), donde el protón está unido de forma covalente a una molécula de agua. En este caso se dice que se encuentra hidratado, pero también pueden existir especies de hidratación superior.

Los protones tienen un espín intrínseco. Esta propiedad se aprovecha en la espectroscopia de resonancia magnética nuclear (RMN). En esta técnica, a una sustancia se le aplica un campo magnético para detectar la corteza alrededor de los protones en los núcleos de esta sustancia, que proporcionan las nubes de electrones colindantes. Puede usarse posteriormente esta información para reconstruir la estructura molecular de una molécula bajo estudio; éste sigue siendo llamado un protón en cualquier tipo de enlace que se quiera establecer.


</doc>
<doc id="2140" url="https://es.wikipedia.org/wiki?curid=2140" title="Platino">
Platino

El platino es un elemento químico de número atómico 78, situado en el grupo 10 de la tabla periódica de los elementos. Su símbolo es Pt. Se trata de un metal de transición blanco grisáceo, precioso, pesado, maleable y dúctil. Es resistente a la corrosión y se encuentra en distintos minerales, frecuentemente junto con níquel y cobre; también se puede encontrar como metal. Se emplea en joyería, equipamiento de laboratorio, contactos eléctricos, empastes y catalizadores de automóviles.

El platino fue descubierto en América, en la provincia de Esmeraldas, Ecuador, por el español Antonio de Ulloa, siendo llevado por primera vez a Europa en el año 1735. El nombre del elemento se relaciona a su parecido con la plata, con la cual se lo confundió en un primer momento. 
En 1822, el platino fue encontrado también en los montes Urales (Rusia), y más tarde en Colombia,
Canadá y Sudáfrica.

El platino se utiliza en múltiples y esenciales aplicaciones, mientras que nuevos usos para el platino se desarrollan constantemente.










Cuando está puro, es de color blanco grisáceo, maleable y dúctil. Es resistente a la corrosión y no se disuelve en la mayoría de los ácidos, aunque es posible disolverlo usando agua regia dando como resultado el ácido cloroplatínico. Es atacado lentamente por el ácido clorhídrico (HCl) en presencia de aire. Se denomina "grupo del platino" a los elementos rutenio, osmio, rodio, iridio, paladio y platino. Estos elementos son bastante utilizados como catalizadores.

El platino es relativamente resistente al ataque químico, tiene buenas propiedades físicas a temperaturas altas, y también buenas propiedades eléctricas. Esto ha hecho que se utilice en distintas aplicaciones industriales. Por ejemplo, se puede emplear como electrodo, en contactos electrónicos, etc. El platino no se oxida con el aire, pero puede reaccionar, dependiendo de las condiciones, con cianuros, halógenos, azufre, plomo, silicio y otros elementos, así como con algunos óxidos básicos fundidos y ozono.

Actualmente, Sudáfrica cuenta con las reservas de platino más grandes del mundo (más del 70% del total mundial), por lo que se ha convertido en su mayor productor y exportador. Rusia y Canadá cuentan con modestas reservas de este metal y Estados Unidos cuenta con una producción mínima a pesar de sus yacimientos (casi la mitad de los yacimientos canadienses). Solo entre Sudáfrica y Rusia se genera el 90% de la producción mundial de platino.

Se halla en minas de rocas ígneas en gránulos muy pequeños. La producción mundial de platino, estimada en unas 16 toneladas anuales, se reparte principalmente entre Colombia, Estados Unidos, Sudáfrica, Canadá y los países de la antigua URSS.

Normalmente se encuentra en estado metálico aleado con otros metales de su grupo en forma de pepitas y de escamas y asociado a los minerales de níquel, cobre y cromo fundamentalmente.

Se ha llegado a encontrar una pepita de unos 9,5 kg con casi un 80% de riqueza en platino y el resto distribuido en metales como iridio, paladio, rodio, osmio, rutenio, oro, etc.

En la naturaleza, generalmente forma parte de los Metales del Grupo del Platino y se encuentra junto a otros metales como el oro, el níquel o el cobre. Los Metales del Grupo del Platino (MGP) son Platino (Pt), Paladio (Pd), Rodio (Rh), Rutenio(Ru), Iridio (Ir) y Osmio (Os). Platino y Paladio son los más importantes del grupo.

El platino como metal no es muy peligroso, pero sus sales pueden causar varios efectos como:

Finalmente, un peligro del platino es que este puede causar la potenciación de toxicidad de otros productos químicos peligrosos en el cuerpo humano, como es el selenio.




</doc>
<doc id="2141" url="https://es.wikipedia.org/wiki?curid=2141" title="Planeta">
Planeta

Un planeta es, según la definición adoptada por la Unión Astronómica Internacional, un cuerpo celeste que: 

Según la definición, el sistema solar consta de ocho planetas: Mercurio, Venus, Tierra, Marte, Júpiter, Saturno, Urano y Neptuno. En cambio Plutón, que hasta 2006 se consideraba un planeta, ha pasado a clasificarse como planeta enano, junto a Ceres, también considerado planeta durante algún tiempo, ya que era un referente en la ley de Titius-Bode, y más recientemente considerado como asteroide y Eris, un objeto transneptuniano similar a Plutón. Ciertamente, desde los años setenta existía un amplio debate sobre el concepto de planeta a la luz de los nuevos datos referentes al tamaño de Plutón (menor de lo calculado en un principio), un debate que aumentó en los años siguientes al descubrirse nuevos objetos que podían tener tamaños similares. De esta manera, esta nueva definición de planeta introduce el concepto de planeta enano, que incluye a Ceres, Plutón, Haumea, Sedna, Makemake y Eris; y tiene la diferencia de definición en (3), ya que no ha despejado la zona local de su órbita y no es un satélite de otro cuerpo.

Los cuerpos que giran en torno a otras estrellas se denominan generalmente planetas extrasolares o exoplanetas. Las condiciones que han de cumplir para ser considerados como tales son las mismas que señala la definición de planeta para el sistema solar, si bien giran en torno a sus respectivas estrellas. Incluyen además una condición más en cuanto al límite superior de su tamaño, que no ha de exceder las 13 masas jovianas y que constituye el umbral de masa que impide la fusión nuclear de deuterio.

Etimológicamente, la palabra "planeta" proviene del latín "planeta", que a su vez deriva del griego "πλανήτης" ('planētēs' «vagabundo, errante»). Esto se debe a que en la antigüedad, siguiendo la teoría geocéntrica de Ptolomeo, se creía que en torno a la Tierra, la cual era considerada el centro del cosmos, giraban el Sol y "las cinco errantes" o los cinco "planetas errantes" (Mercurio, Venus, Marte, Júpiter y Saturno), llamadas así por obstinarse a desobedecer la ley del círculo. Es decir, se les consideraba "errantes" debido a que, aparentemente y a simple vista, no trazaban ningún círculo alrededor de la Tierra, a diferencia del Sol.

Hoy en día, según la Real Academia Española, podemos ver la palabra "planeta" definida así:

El problema de una definición correcta llegó a un punto crítico en los años 2000. Sin embargo, esta no es la primera vez que se identifica un sistema de este tipo. En el 2004, Gael Chauvin descubrió un objeto de unas 5 veces la masa de Júpiter orbitando alrededor de la enana marrón 2M1207. La distancia proyectada es de unas 55 unidades astronómicas.

La Unión Astronómica Internacional, organismo responsable de resolver los asuntos de la nomenclatura astronómica, se reunió en agosto de 2006 dentro de su XXVI Asamblea General en Praga. Aquí, tras largas discusiones y varias propuestas, se adoptó finalmente que un planeta es:

Además, propone el término planeta enano para los cuerpos que cumplan las condiciones (a) y (b), pero no (c) y no sean satélites. Este es el caso de Plutón, Ceres y Eris (conocido antes como 2003 UB). Con posterioridad también se han añadido a la lista de planetas enanos Makemake y Haumea. Por último, el resto de los objetos del sistema solar, excepto los satélites, pueden considerarse cuerpos menores del sistema solar.

No se sabe con certeza como se forman los planetas. La teoría predominante es que lo hacen durante el colapso de una nebulosa en un delgado disco de gas y polvo. En el centro se forma una protoestrella rodeada de un disco protoplanetario en rotación. 
Mediante la acreción (un proceso de coalescencia por colisión), las partículas de gas y polvo del disco acumulan sin interrupción masa para formar objetos cada vez más grandes. Estas acumulaciones de masa, conocidas como planetesimales, aceleran el proceso de acreción por la atracción gravitatoria de materiales adicionales y se vuelven cada vez más densas hasta que colapsan bajo la gravedad para formar protoplanetas. Después de que un planeta alcanza una masa algo mayor que la de Marte, comienza a reunir una atmósfera extensa  que incrementa la tasa de captura de planetesimales por medio de la resistencia atmosférica. En función del modo de acreción de sólidos y gases, el resultado será un planeta gigante, un gigante de hielo o un planeta terrestre.

Los planetas del sistema solar se clasifican conforme a dos criterios: su estructura y su movimiento aparente.



La teoría geocéntrica clasificaba a los planetas según su elongación:


Suelen tener grandes atmósferas compuestas por helio e hidrógeno, con componentes de otras sustancias como agua, metano o amoníaco.
Las configuraciones de un planeta exterior son:


Los planetas interiores y exteriores, parten de un lugar de referencia que no es la Tierra: Es el cinturón de asteroides.
Los planetas: Mercurio, Venus, La Tierra y Marte son internos.
Los planetas: Júpiter, Saturno, Urano y Neptuno son exteriores.

El año 1781 Herschel descubrió Urano, y en 1846 Johann Gottfried Galle y Urbain Le Verrier descubrieron Neptuno basándose en las perturbaciones gravitacionales ejercidas sobre Urano. Finalmente, en el año 1930 Clyde Tombaugh descubrió Plutón, clasificado a partir de agosto de 2006 como planeta enano. En los años 1970 se pudo descubrir un satélite orbitando Plutón, de nombre Caronte.

Anteriormente se consideraba planeta cualquier cuerpo que tuviera una masa entre 13 masas de Júpiter y la masa de Plutón, aunque esta definición era muy vaga. Con el descubrimiento de cuerpos cada vez mayores en el cinturón de Kuiper se puso en entredicho la catalogación de Plutón como planeta. Habiéndose descubierto varios candidatos a planeta más allá de la órbita de Neptuno, la Unión Astronómica Internacional tuvo que decidir si los incluía en el listado oficial de planetas. Puesto que se estima que aún faltan cientos de objetos nuevos por descubrir, y la UAI no deseaba que el listado se hiciera inacabable, se tomó la decisión de incluirlos en una categoría nueva, la de planeta enano. La UAI además tomó una postura oficial respecto a la definición de planeta, que ha de permitir la correcta clasificación de futuros descubrimientos.

Desde 1988 el descubrimiento de Gamma Cephei Ab, confirmó una serie de descubrimientos que se han hecho de planetas en órbita alrededor de estrellas distintas del Sol. Hasta octubre de 2011 se habían descubierto 567 sistemas planetarios que contienen un total de 692 cuerpos. La mayoría de ellos tienen masas que son comparables o mayores que Júpiter. Entre las excepciones se incluyen una serie de planetas descubiertos en órbita alrededor de los restos quemados de estrellas llamados púlsares, como PSR B1257 +12, los planetas en órbita alrededor de las estrellas: Mu Arae, 55 Cancri y GJ 436, que son aproximadamente del tamaño de Neptuno, y un sistema planetario que contiene al menos dos planetas en órbita alrededor de Gliese 876.

No está nada claro si los grandes planetas recién descubiertos se parecen a los gigantes gaseosos en el sistema solar o si son de un tipo de gas distinto aún no confirmado, como el amoníaco o el carbono. En particular, algunos de los planetas recién descubiertos, conocidos como jupiteres calientes, orbitan muy cerca de sus estrellas padre, en órbitas casi circulares, por lo que reciben mucho más la radiación estelar que los gigantes de gas en el sistema solar, lo que hace preguntarse si son absolutamente el mismo tipo de planeta. También existe una clase de jupiteres calientes que orbitan tan cerca de su estrella que sus atmósferas son lentamente arrancadas: los planetas Chthonianos.

Para una observación más detallada de planetas extrasolares será requerida una nueva generación de instrumentos, incluidos los telescopios espaciales. En la actualidad, la nave espacial CoRoT está a la búsqueda de variaciones de luminosidad estelar debido al tránsito de planetas. Varios proyectos han propuesto también la creación de un conjunto de telescopios espaciales para la búsqueda de planetas extrasolares con masas comparables a la de la Tierra. Estos incluyen el proyecto de la NASA Kepler Mission, Terrestrial Planet Finder, y programas de la Misión Espacial de Interferometría, el Darwin de la ESA, el CNES y la PEGASE. The New Worlds Misión es un dispositivo oculto que puede trabajar en conjunto con el telescopio espacial James Webb. Sin embargo, la financiación de algunos de estos proyectos sigue siendo incierto. La frecuencia de ocurrencia de tales planetas terrestres es una de las variables en la ecuación de Drake, que estima el número de planetas con seres inteligentes, con civilizaciones con las que comunicarnos nuestra galaxia. [41]

Varias simulaciones por ordenador de evolución estelar y formación de los sistemas planetarios han sugerido que algunos objetos de masa planetaria habrían sido expulsados al espacio interestelar. Algunos científicos han argumentado que esos objetos encontrados vagando en el espacio deben ser clasificados como "planetas". Sin embargo, otros han sugerido que podrían ser estrellas de baja masa. La definición de la UAI sobre planetas extrasolares no toma posición sobre la cuestión.

En 2005, los astrónomos anunciaron el descubrimiento de Cha 110913-773444, la enana marrón más pequeña encontrada hasta la fecha, con solo siete veces la masa de Júpiter. Ya que no se encuentran en órbita alrededor de una estrella de detonación, es una sub-enana marrón, de acuerdo con la definición de la UAI. Sin embargo, algunos astrónomos creen que debería ser denominada como planeta. Durante un breve tiempo en 2006, los astrónomos creían que habían encontrado un sistema binario de objetos, Oph 162225-240515, que los descubridores describen como "planemos", u "objetos de masa planetaria". Sin embargo, los últimos análisis de los objetos ha determinado que sus masas son mayores que 13 veces la de Júpiter; que es el tope de masa que debe tener un planeta para que en su núcleo no se produzcan combustiones termonucleares, es decir, para que no sea una estrella.

El nombre en castellano de los planetas del sistema solar, corresponde al nombre de algunas divinidades de las mitologías romana o griega:


En diferentes culturas los días de la semana provienen de los nombres de los dioses asociados con cada uno de estos astros. El lunes por la Luna, el martes por Marte, el miércoles por Mercurio, el jueves por Júpiter, el viernes por Venus, excepto sábado (por el Sabbath) y domingo por la resurrección de Jesucristo: "die dómini" (‘día del Señor’ en latín). En inglés aún se conserva la denominación "Saturday" (día de Saturno) para el sábado, y "Sunday" (día del Sol) para el domingo. Los satélites mayores de los diferentes planetas reciben su nombre de personajes mitológicos, excepto los satélites de Urano, cuyos nombres conmemoran personajes de obras clásicas de teatro. Otros cuerpos menores del sistema solar reciben su nombre de diversas fuentes: mitológicas (Plutón, Sedna, Eris, Varuna o Ceres), de sus descubridores (cometas como el Halley) o de códigos alfanuméricos relacionados con su descubrimiento.

La siguiente tabla muestra una comparación entre las medidas de la Tierra, los demás planetas del sistema solar y el Sol. 



</doc>
<doc id="2142" url="https://es.wikipedia.org/wiki?curid=2142" title="Puerto Rico">
Puerto Rico

Puerto Rico, oficialmente Estado Libre Asociado de Puerto Rico, es un territorio no incorporado estadounidense con estatus de autogobierno. Se localiza en América, al noreste del Caribe, al este de la isla La Española y al oeste de las islas Vírgenes. Su costa oeste se sitúa a aproximadamente 1536 kilómetros (960 millas) al sureste de la costa de Florida, la más cercana de la zona continental de Estados Unidos. El archipiélago de Puerto Rico incluye la isla principal de Puerto Rico (8 896 km²) - la más pequeña de las Antillas Mayores - y un número de cayos e islas más pequeñas; de las cuales las más grandes son Vieques (135 km²), Mona (55 km²) y Culebra (30 km²). Es una isla con clima tropical y, a pesar de su tamaño, posee diversidad de ecosistemas: bosques secos y lluviosos, zona cárstica, áreas montañosas, ecosistemas costeros y marinos, lagos, etc.

Puerto Rico fue un territorio ultramar de la corona española desde la llegada de Cristóbal Colón en 1493 hasta la promulgación de la Carta Autonómica de Puerto Rico en 1897, siendo provincia española de 1897 hasta la guerra hispano-estadounidense de 1898. Cuatro siglos de administración española dieron lugar a una cultura hispanoamericana, siendo la lengua española y el catolicismo sus elementos más distinguibles. Los españoles construyeron numerosos , y otros edificios de uso público, comercial y residencial, así como puertos, y carreteras. Durante más de tres siglos, Puerto Rico estuvo comunicada con la península ibérica por medio de convoyes de las Flotas de Indias que unían Cádiz y San Juan una vez al año.

Los puertorriqueños son ciudadanos estadounidenses desde 1917, cuando el Congreso de los Estados Unidos aprobó la Ley Jones. Aunque su relación con Estados Unidos es similar a la de un estado de la Unión y se le permitió la redacción de una Constitución para el manejo de asuntos internos, está sujeto a los poderes plenos del Congreso estadounidense mediante la Cláusula Territorial. Esto significa que el poder de ejercer su soberanía recae en el Congreso de los Estados Unidos y los poderes existentes en la isla, al no gozar de protección en la Constitución estadounidense, son revocables. Los puertorriqueños no pueden votar en las elecciones presidenciales de los Estados Unidos, a menos que dispongan de residencia oficial en alguno de los cincuenta estados o en el Distrito de Columbia. Si es así, pueden trasladarse a su lugar de residencia y votar presencialmente o utilizar el procedimiento de voto a distancia ("ballot absentee"). Por otro lado, a pesar de la condición jurídica puertorriqueña, algunas personalidades a nivel internacional se han referido a Puerto Rico como nación.

El nombre actual de «Puerto Rico» alude a las riquezas que partían del puerto de San Juan Bautista hacia España. Cristóbal Colón lo bautizó con el nombre de San Juan Bautista. Los nativos de la tribu taína llamaban a la isla "Borikén", que significa «Tierra de Nuestro Altísimo y Bravo Señor», el cual evolucionó al nombre de Borínquen, nombre que todavía se utiliza en referencia a Puerto Rico. De allí surge el gentilicio «boricua». Los españoles denominaron a la capital Puerto Rico. Al pasar los años, se intercambiaron los nombres de manera que «Puerto Rico» pasó a ser San Juan, y San Juan Bautista pasó a ser Puerto Rico. En la actualidad, la capital es San Juan.

La historia de Puerto Rico comenzó con el asentamiento del pueblo indígena ostionoide en el archipiélago de Puerto Rico entre los años 3000 y 2000 a. C. Otras tribus, como la de los indios arahuaco y saladoide, poblaron la isla entre los años 430 a. C. y 1000 d. C. En el momento de la llegada de Cristóbal Colón al Nuevo Mundo en 1492, la cultura indígena dominante era la de los taínos.

Cristóbal Colón llegó a la isla de Puerto Rico el 19 de noviembre de 1493, en su segundo viaje de exploración. Algunos historiadores son de la opinión de que ya Martín Alonso Pinzón había llegado a la isla en 1492 durante el tiempo que estuvo separado de Colón. Los taínos, habitantes nativos de la Isla, llamaban a ésta «Boriquén», origen del nombre «Borínquen», término que guarda cierta semejanza acústica con el nombre original, y que ha proporcionado el aún existente «boricua». Según los historiadores, este nombre «Boriquén» se deriva del vocablo «buruquena», nombre de un pequeño crustáceo endémico del Caribe Puertorriqueño.

Según algunos historiadores, los taínos constituían una cultura pacífica y hospitalaria, que contrasta con datos históricos por Scarrano, Waguenheim, y otros historiadores que describen una cultura hospitalaria pero cautelosa. Estos les entregaron a los españoles regalos de oro, metal que para ellos tenía un valor simplemente decorativo, como un collar de caracoles, mientras que para los habitantes de Europa, Asia y África era y sigue siendo muy preciado.

Existe la teoría de que ese comportamiento se debía a la creencia de que los españoles eran dioses por el color de su piel; pero la opinión moderna lo descarta como mito. En realidad lo que se desprende de los escritos de los colonizadores es la referencia a que fueron tratados como dioses por los taínos, lo cual es un enfoque propio del colonizador, pero no es un indicador objetivo de lo que los taínos realmente pensaban sobre ellos. Hay que recordar que en ese momento no existían buenos traductores españoles capaces de profundizar en una conversación con los taínos y que los que existían se dejaron llevar por sus impresiones.

Otro incidente que vale la pena examinar es la muerte de Diego Salcedo, un colonizador que mantuvo esclavizado a un grupo de taínos. Estos se rebelaron contra él por su trato cruel y lo ahogaron en un río. Muchas personas creen que el acto se llevó a cabo para verificar su condición de dios, pero los académicos difieren. Un hecho utilizado para rebatir esta presunción es que en 1492 se construyó en la actual República Dominicana el Fortín de Navidad con los restos de la embarcación Santa María. Cuando regresaron los españoles en 1493 encontraron que el fortín había sido destruido por el fuego y que los taínos habían matado a todos los colonizadores residentes en él. Los expertos en el tema son de la opinión de que la muerte de Salcedo fue un acto premeditado del Cacique Agüeybaná, que representó el inicio de la rebelión indígena contra los colonizadores en las Antillas.

En 1508 Juan Ponce de León colonizó la isla y fundó el poblado de Caparra. Ponce de León fue recibido por el cacique Agüeybaná y, rápidamente, tomó control de la isla, en contraste con el intento fallido de Vicente Yáñez Pinzón, quien fue declarado capitán general y corregidor y se limitó a desembarcar animales domésticos en el oeste de la isla. Después de la muerte de Cristóbal Colón, quien había sido nombrado «Gobernador de las Indias» por la corona española, este título le fue negado a su hijo Diego Colón y nombró a Juan Ponce de León como primer gobernador oficial de la Puerto Rico, proclamándose la Capitanía General de Puerto Rico en 1582.

Bajo el sistema de la encomienda, equivalente al sistema feudal europeo, se forzó a muchos taínos a abandonar sus aldeas para vivir en las haciendas. Muchos taínos murieron debido a que carecían de inmunidad contra las enfermedades traídas por los europeos, tales como el sarampión o la viruela. Los pocos taínos que sobrevivieron fueron liberados cuando Fray Bartolomé de las Casas, sacerdote español, convenció a los Reyes Católicos de que eliminaran la encomienda. Para llenar el vacío dejado por los vasallos liberados, los comerciantes comenzaron a traer a Puerto Rico esclavos africanos negros. Los africanos, en su mayoría, fueron establecidos en la zona oriental de la Isla, en pueblos como Vieques, Loíza y Ponce. Debido a esta mezcla de razas que de igual manera ocurrió en Santo Domingo y Cuba, los boriqueños modernos describen a Puerto Rico como un país con ciudadanos con un mestizaje producto de tres razas (española, africana y taína), aún siendo la española la predominante.

Durante siglos, el Imperio británico disputó al español el dominio de esta isla. Puerto Rico fue posesión colonial de España durante más de 400 años. El movimiento conocido como Grito de Lares fue una insurrección armada liderada por Manuel Rojas que tuvo lugar el 23 de septiembre de 1868, coincidiendo con los sucesos de la Gloriosa en la península. Controlado el alzamiento con cierta rapidez, la isla vivió varias reformas políticas hasta finales del siglo XIX. La lucha por la autonomía llegó casi a alcanzar su propósito el 25 de noviembre de 1897 cuando se aprobó la Carta Autonómica que concedía un amplísimo auto-gobierno a la isla.

Los Estados Unidos entraron en la historia puertorriqueña al entrar en guerra con España y ocupar la Isla el 25 de julio de 1898 durante la Guerra hispano-estadounidense. El 10 de diciembre de 1898 se firmó el Tratado de París, por el que Puerto Rico y el resto de los territorios coloniales (Cuba y Filipinas) del Imperio español se cedieron a los Estados Unidos, el 11 de abril de 1899.

En 1900, la Ley Foraker creó un gobierno civil que reemplazó al gobierno militar de ocupación. Puerto Rico fue administrado por el Departamento del Interior de los Estados Unidos, y el gobernador era nombrado por el presidente de los Estados Unidos. Este tipo de gobierno se basó en un modelo republicano, con tres ramas: el Poder Ejecutivo (Gobernador), el Poder Legislativo (Asamblea Legislativa) y el Poder Judicial (Tribunal General de Justicia). Cabe mencionar que la Asamblea Legislativa constaba de dos Cámaras: por un lado, el Consejo Ejecutivo constituido por los Secretarios del Gobernador; y, por el otro, una Cámara de Delegados compuesta de treinta y cinco miembros elegidos cada dos años por los electores capacitados. Un dato importante es la creación del cargo de Comisionado Residente, representante de la Isla en el Congreso de los Estados Unidos, pero sin derecho a votar en decisión alguna de dicho cuerpo.

En 1917, con la Ley Jones, se le otorgó a los puertorriqueños la ciudadanía estadounidense, se eliminó el Consejo Ejecutivo como Cámara Legislativa y se dividió a sus funcionarios para formar distintos Departamentos Independientes bajo el Poder Ejecutivo. Estos fueron: el Departamento de Justicia, liderado por el Procurador General; el Departamento de Hacienda, liderado por el Tesorero; el Departamento del Interior, dirigido por el Comisionado del Interior; el Departamento de Instrucción, liderado por el Comisionado de Instrucción; el Departamento de Agricultura y Comercio, dirigido por el Comisionado de Agricultura y Comercio; el Departamento del Trabajo, dirigido por el Comisionado del Trabajo; y el Departamento de Salud, liderado por el Comisionado de Salud.

En sustitución del Consejo Ejecutivo se creó el Senado de Puerto Rico, que se compondría de diecinueve miembros elegidos por los electores capacitados y sirviendo por períodos de cuatro años. Además a éstos, se añaden siete distritos senatoriales representados por dos senadores, más cinco senadores electos por acumulación. Este Senado ejercería todos los poderes y funciones puramente legislativos que hasta ese momento había ejercido el Consejo Ejecutivo, incluyendo la confirmación del nombramiento de Gobernador.

En 1922 la Corte Suprema de los Estados Unidos, en el caso Balzac v. Porto Rico, 258 U.S. 298 (U.S. 1922), interpretó que la Ley Jones no expresaba que Puerto Rico fuese un territorio incorporado, frase que describe a aquellos territorios en proceso de incorporación e integración a Estados Unidos como un estado adicional de ese país. Sin embargo, en Consejo de Salud v. Rullan, 586 F.Supp. 2d 22 (D.P.R. 2008), el juez federal del distrito de Puerto Rico Gustavo Gelpi dijo "Let it be clear. The court today is in no way attempting to override the 'Insular Cases' as applied to the U.S. territories - only the Supreme Court can. The court, rather, today holds that in the particular case of Puerto Rico, a monumental constitutional evolution based on continued and repeated congressional annexation has taken place. Given the same, the territory has evolved from an unincorporated to an incorporated one". («Que quede claro. La corte, hoy, de ninguna manera está tratando de anular los 'Casos Insulares' tal y como se aplican a los territorios de EE.UU. Solo la Corte Suprema de los Estados Unidos puede hacerlo. Esta corte, más bien, mantiene hoy que, en el caso particular de Puerto Rico, ha tenido lugar una gran evolución constitucional basada en una anexión continua y repetida por parte del Congreso. Debido a ello, el territorio ha evolucionado de no incorporado a incorporado».

En 1946 la presión para conceder poderes negados hasta entonces durante casi medio siglo a los puertorriqueños comenzó a dar resultados con el nombramiento por parte del presidente Truman del Comisionado Residente Jesús T. Piñero Jiménez para el puesto de Gobernador de Puerto Rico. Se convirtió así Jesús T. Piñero en el primer puertorriqueño que ocupó en propiedad el más alto puesto político en toda la historia de la Isla. En 1947 el Congreso aprobó la ley que les permite a los puertorriqueños elegir a su gobernante mediante voto electoral por un término de cuatro años.

En 1948, Luis Muñoz Marín, fundador del Partido Popular Democrático e hijo de Luis Muñoz Rivera, ganó las primeras elecciones para gobernador en la historia de Puerto Rico. El 3 de julio de 1950 fue aprobada por el Congreso de los Estados Unidos la Ley Pública 600, que permite a la Asamblea Legislativa formar una Asamblea Constituyente para la creación de la Constitución de Puerto Rico, sujeta a posterior aprobación por parte del Presidente de los Estados Unidos y el Congreso. Esta ley deja intacta la Ley Jones y la bautiza como Ley de Relaciones Federales, eliminando sólo las disposiciones que serían incluidas en el momento en que la Constitución de Puerto Rico entrase en vigor. El 30 de octubre de 1950 tuvo lugar la Insurrección Nacionalista, en respuesta al proyecto del «Estado Libre Asociado». Blanca Canales proclamó la República de Puerto Rico en el Grito de Jayuya y se dieron combates en diferentes puntos del País. El pueblo de Jayuya fue bombardeado desde el aire, hubo matanzas en Utuado y La Fortaleza, residencia del Gobernador, fue atacada a tiros. En 1954, para dejar claro que la insurrección independentista no era un problema interno de los puertorriqueños, como decía el gobierno estadounidense, los nacionalistas Lolita Lebrón, Rafael Cancel Miranda, Irving Flores y Andrés Figueroa Cordero protestaron en el Congreso estadounidense, Lolita dando tiros al aire a la Casa Blair. Todos los atacantes fueron arrestados, incluyendo a Pedro Albizu Campos y cumplieron largas condenas en cárceles federales por no disculparse por haber realizado dicho acto.

Los opositores al Estado Libre Asociado y muchos académicos reclaman que el mayor efecto de esta ley fue cambiar el nombre de la ley que regía a Puerto Rico y perpetuar la alegada relación subordinada, puesto que erróneamente se piensa que en el año 1952 es cuando se obtiene la elección del gobernador por voto popular y el sistema de gobierno republicano, cosas otorgadas por las leyes anteriormente reseñadas. Los defensores del Estado Libre Asociado reclaman que se dejó de ser colonia por medio de un «pacto bilateral», por haberse definido la relación de Estados Unidos con Puerto Rico como una «"in a nature of a compact"» asociación, término no definido bajo el Derecho Internacional.

En 1952 Muñoz Marín indujo a Puerto Rico a obtener el estatus de Estado Libre Asociado, bajo la Constitución del mismo, que es la situación política actual en la Isla. Sin embargo, este cambio en el estatus territorial no significa que a Puerto Rico no le continúe aplicando la cláusula territorial de la Constitución de los EE.UU..

El inglés y el español han sido los idiomas oficiales de Puerto Rico, apenas desde la firma de la Ley del 5 de enero de 1993, aunque todavía predomina el uso del español.

En septiembre de 2015 fue aprobado el Proyecto del Senado 1177, que declara el español como el primer idioma oficial y el inglés como el segundo idioma oficial del Gobierno, establece su utilización en los poderes ejecutivo, legislativo y judicial y deroga la Ley 1-1993, que establecía la oficialidad de ambos idiomas al mismo nivel. 

Las peculiaridades del idioma español de Puerto Rico se deben a fuertes influencias de otros idiomas: a la posible influencia de la lengua nativa de los taínos se sumó posteriormente la aportada por fuertes corrientes de inmigración canaria, corsa y catalana, y al aporte de las lenguas africanas. Posteriormente, el idioma inglés ha hecho sentir su fuerte influencia a partir de la ocupación estadounidense desde principios del siglo XX, causada por la influencia de la administración, del comercio casi exclusivo con los Estados Unidos, de la presencia de fuerzas militares estadounidenses en la isla y de la gran cantidad de puertorriqueños que residen en suelo estadounidense.

El inglés se enseña como segunda lengua, aunque se ha estimado que sólo un 10 a 20 por ciento de los residentes de la isla domina el inglés "muy bien":

Está dividido administrativamente en setenta y ocho municipios; cada municipio elige un alcalde y una "Legislatura Municipal" por un término de cuatro años. Las ciudades principales son San Juan (capital), Bayamón, Carolina, Ponce, Caguas, Guaynabo, Arecibo, Toa Baja, Mayagüez y Trujillo Alto, todos ellos con más de 75 000 habitantes. Puerto Rico posee dos islas municipio, Vieques y Culebra, que están localizadas al este de la isla grande.

Los municipios son:

Puerto Rico es un territorio no incorporado de Estados Unidos. Esto significa que Puerto Rico pertenece a Estados Unidos, pero no forma parte de ellos. Según los Casos insulares resueltos por la Suprema Corte de Justicia de los Estados Unidos, los derechos constitucionales no son extendidos automáticamente a todos los territorios bajo el control estadounidense. Los territorios y sus ciudadanos tienen derecho a la protección de la Constitución de Estados Unidos, pese pocas excepciones, como los estados incorporados que forman "parte íntegra" de la nación.

La relación del gobierno de Puerto Rico con el gobierno federal de Estados Unidos es para muchos comparable a la relación del gobierno federal estadounidense con sus estados. Todo lo relacionado a la moneda, la defensa, las relaciones exteriores y la mayor parte del comercio entre estados cae bajo la jurisdicción del gobierno federal. El gobierno de Puerto Rico tiene autonomía fiscal y el derecho de cobrar impuestos locales. Los puertorriqueños son ciudadanos de los Estados Unidos con todos los derechos y deberes que confiere esa ciudadanía, contribuyen al seguro social estadounidense, pero como las elecciones presidenciales sólo se celebran en estados y territorios incorporados, los residentes de Puerto Rico no participan en éstas, a menos que tengan residencia legal en un estado o territorio incorporado.

El Comisionado Residente es el único representante del gobierno local en el Congreso de Estados Unidos. El Comisionado Residente tiene derecho a voz pero no a voto en el Congreso de Estados Unidos, excepto cuando el mismo Congreso le concede voto en el "comité conjunto". Cuando esto ocurre, el Comisionado Residente puede votar, pero sólo cuando su voto no sea determinante en el tema.

El gobierno del Estado Libre Asociado de Puerto Rico está dividido en tres ramas: la Rama Ejecutiva, la Rama Legislativa (dividida en la Cámara de Representantes y el Senado) y la Rama Judicial.

La Rama Ejecutiva está representada y dirigida por el Gobernador. El Gobernador es electo por voto directo en una elección general cada cuatro años y designa, con el consejo y consentimiento del Senado, a los miembros de su gabinete, el cual está formado por los secretarios de los quince departamentos.

El poder legislativo de la Isla recae en la Asamblea Legislativa, una legislatura bicameral compuesta del Senado y de la Cámara de Representantes. El Senado cuenta con veintisiete miembros en total – dos por cada distrito electoral y once por acumulación basados en la proporción de la población. La Cámara de Representantes cuenta con 51 miembros en total – uno para cada distrito electoral y once por acumulación. En caso que el Gobernador y la Asamblea Legislativa sean del mismo partido y en ésta estén dos tercios o más de los legisladores, se le otorga hasta un máximo constitucional de nueve puestos en el Senado y diecisiete en la Cámara de Representantes adicionales a los partidos de minoría.

En 2005 hubo un referéndum en el que participó solo el 22.6 % (553 955), de los electores inscritos para votar (2 453 292) y de ellos el 83 % (464 010) de los electores votaron por que se convierta esta Asamblea en unicameral, y en enero de 2007 el Senado aprobó un proyecto de ley para iniciar este proceso.

El Poder Judicial es la rama de Gobierno responsable del cumplimiento de la Constitución y la administración de la Justicia. Dirigido por el Tribunal Supremo de Puerto Rico, el sistema judicial está compuesto por tres instancias. El Tribunal de Primera Instancia (TPI) está dividido en la Sala Superior y la Sala Municipal (con diferentes áreas de competencia). El TPI tiene trece distritos judiciales (San Juan, Bayamón, Carolina, Caguas, Arecibo, Utuado, Aguadilla, Mayagüez, Ponce, Aibonito, Guayama, Humacao y Fajardo). La parte insatisfecha con las decisiones del TPI puede solicitar una apelación a la segunda instancia, conocida como Tribunal de Apelaciones, que se constituye por paneles. La última instancia es el Tribunal Supremo, el cual es el único tribunal constitucional. El Tribunal Supremo está integrado por el Juez Presidente y seis Jueces Asociados. Estos son nombrados por el Gobernador con el consejo y consentimiento del Senado. Dichos nombramientos son de por vida, hasta la edad del retiro obligatorio de setenta (70) años. El número de jueces sólo podrá ser variado por ley, a solicitud del propio Tribunal Supremo.

En Puerto Rico existen cuatro partidos políticos principales: el Partido Popular Democrático (PPD), el Partido Nuevo Progresista (PNP), el Partido Independentista Puertorriqueño (PIP) y el Partido del Pueblo Trabajador (PPT). Todos los oficiales electos en Puerto Rico sirven por un período de cuatro años. Existen también varios grupos políticos dedicados a la lucha por la independencia, entre ellos el Movimiento Socialista de Trabajadores de Puerto Rico, fundado en 1982 mediante la fusión del Movimiento Socialista Popular y el Partido Socialista Revolucionario, posteriormente Liga Internacionalista de los Trabajadores; el Partido Nacionalista de Puerto Rico, que no cree en la participación en las elecciones mientras Puerto Rico sea una colonia, y el Movimiento Independentista Nacional Hostosiano, movimiento que resulta de la fusión del Congreso Nacional Hostosiano y del Nuevo Movimiento Independentista Puertorriqueño. Igualmente el Movimiento al Socialismo (MAS) que fue fundado en el 2008 producto de la fusión del Partido Revolucionario de los Trabajadores (PRT-Macheteros), la Juventud de Izquierda Revolucionaria (JIR), el Taller de Formación Política (TFP) y el Proyecto de Trabajo Político (PTP).

El debate sobre el estatus político de Puerto Rico ha sido continuo en muchas esferas locales, federales (Estados Unidos) e internacionales (Naciones Unidas). En 2007, un comité de trabajo de Casa Blanca concluyó que Puerto Rico continúa totalmente sujeto a la autoridad del Congreso de EE.UU. bajo las cláusulas territoriales. El Partido Popular Democrático, fundador del "Estado Libre Asociado", protesta esta opinión de la Casa Blanca.

Sin embargo, las restricciones legales relacionadas al estatus político de Puerto Rico no se transfieren al ciudadano, ya que limitan sólo al territorio. De esta manera, cualquier ciudadano de Estados Unidos, aún los nacidos en Puerto Rico, pueden votar por el presidente y el congreso si no residen en Puerto Rico; ningún ciudadano podrá votar por cargos electivos federales desde el territorio comprendido por esta isla. Por esta razón varias personas defienden el argumento de que Estados Unidos sigue tratando a Puerto Rico como una colonia.

En octubre de 2011, el gobernador Luis Fortuño estableció el 12 de agosto de 2012 para celebrar la primera parte de un plebiscito sobre el estatus de dos pasos. Si una segunda votación es necesaria, se llevará a cabo en el mismo día de las elecciones generales el 6 de noviembre de 2012, agregó.

Actualmente, el proyecto de ley está bajo evaluación de la Asamblea Legislativa de Puerto Rico. Donde fue enmendado para hacer ambas preguntas en una misma papeleta el 6 de noviembre de 2012. El No al estatus territorial (colonial) actual ganó la consulta mientras que la segunda pregunta la estadidad obtuvo la mayoría. La opción del No al "statu quo", Estado Libre Asociado Colonial, obtendría cerca del 54 % del favor del pueblo. La estadidad ganó con más del 61 % de los votos contados, lo cual ha provocado controversia por la presencia de una cantidad grande de papeletas en blanco e inválidas. Sin embargo, éstas se descartan para calcular qué alternativa ganó, ya que no se consideran votos bajo el Código Electoral vigente.

El 11 de junio de 2017, un nuevo plebiscito no vinculante fue realizado, obteniendo la victoria, con un 97 % de los votos, la opción que ofrecía la anexión a Estados Unidos. La opción que proponía la independencia total del Ex-estado libre asociado a Estados Unidos, sólo logró un 1,5 % de respaldo y el resultado para los que proponían mantener el estatus actual fue de 1,32 %. En la consulta solo participó un 22 % de los 2 260 804 electores registrados; teniendo en consideración que las listas están alteradas por la decisión federal sobre el asunto de mantener los electores activos aunque no han participado en los eventos electorales previos.

La Ley 600 (P.L. 81-600), que fue aprobada por el Congreso de Estados Unidos, autorizó al pueblo de Puerto Rico a desarrollar su propia Constitución. Esta ley le otorgó al pueblo el control de las actividades de gobierno interno. Sin embargo, esta ley dejó intactos todos los artículos bajo la Ley Jones y la Ley Foraker, al igual que el Tratado de París.

Después que la Asamblea Constituyente redactara la Constitución, el pueblo la ratificó mediante un referéndum. El Congreso de los Estados Unidos, siguiendo el procedimiento requerido por la Ley de Relaciones Federales, aprobó la Constitución, la cual entró en vigor el 28 de julio de 1952.

La incluye una moderna Carta de Derechos que sigue la tradición de la Carta de Derechos Humanos de las Naciones Unidas. De los veinte artículos originales, sin embargo, uno fue enmendado de acuerdo con la orden del Congreso de limitar la educación secundaria gratuita, y otro artículo fue eliminado por el Congreso sin la aprobación de los puertorriqueños. La forma republicana de gobierno imita la Constitución de los Estados Unidos. Un gobernador dirige la rama ejecutiva mientras dos cámaras legislativas, el Senado y la Cámara de Representantes, componen la rama legislativa. El Tribunal Supremo de Puerto Rico es el último tribunal de apelaciones en la mayoría de los casos judiciales, pero sus decisiones pueden ser recurridas ante la Corte Suprema de los Estados Unidos.

Tan sólo en 1993 el Undécimo Circuito del Tribunal de Circuito de Apelaciones de los Estados Unidos determinó que la decisión del Congreso de permitir un gobierno interno en Puerto Rico no invalidó la de la jurisdicción de la Cláusula Territorial de la Constitución de los Estados Unidos. El tribunal concluyó que no ha habido ninguna alteración fundamental en las relaciones de Puerto Rico con los Estados Unidos; Puerto Rico continúa siendo constitucionalmente un territorio no incorporado, sin soberanía separada. El tribunal estableció que "el Congreso puede eliminar unilateralmente la Constitución de Puerto Rico o la Ley de Relaciones Federales y reemplazarlas con cualquier ley o regulación que considere oportuna. A pesar de la aprobación de la Ley de Relaciones Federales y de la Constitución de Puerto Rico, los tribunales de Puerto Rico continúan obteniendo toda su autoridad del Congreso de los Estados Unidos."

No obstante, la mayoría de los observadores políticos locales e internacionales está de acuerdo en que la condición política de Puerto Rico es extremadamente estable, y que ningún miembro del Congreso estadounidense tiene la más mínima intención de tratar de modificar unilateralmente la "Magna Carta" que rige las vidas de más de cuatro millones de ciudadanos y residentes de la Isla.

El gobierno está compuesto por la rama ejecutiva, judicial y legislativa. Esta última consiste de dos cámaras: la Cámara del Senado y la Cámara de Representantes. La rama legislativa al estar compuesta por la Cámara de Representantes y el Senado es un sistema bicameral (dos cámaras). La bicameralidad fue originada en Inglaterra en el siglo XIII. Fue establecida ya que era indispensable reconocer la división de las clases socio-económicas. Se tenía una cámara en representación de la nobleza y clero y otra cámara en representación a los burgueses y los caballeros. Ya que había dos cámaras que cumplían con las necesidades de las diferentes clases sociales del país, existía un equilibrio social, el cual le era muy conveniente al reino británico.

La bicameralidad fue adoptada por los Estados Unidos de América en el siglo XVIII aunque con unos cambios. Las cámaras no representarían los niveles sociales, sino que una cámara (Senado) representaría a los estados y otra (Representantes) representaría los representantes de números similares de población. Antes de que los Estados Unidos adoptara la bicameralidad, ésta fue adoptada por Puerto Rico a finales del dominio español bajo la Carta Autonómica. Según la Ley Jones y más luego la Constitución de Puerto Rico, el bicameralismo se estableció para tener el beneficio de un doble examen a las medidas tomadas por el poder legislativo, para evitar disputas y bajo la idea de que trabajo doble afina el mejor criterio legislativo (Informe de la Comisión de la Rama Legislativa, 4 Diario De Sesiones de la Convención Constituyente 2579 (1961)). Otra razón es que este sistema bicameral evitaría tropiezos políticos. Finalmente, y la más preponderante de todas, se quería evitar conflicto cuando se redactara y se enviará la Constitución de Puerto Rico al Congreso de los Estados Unidos (Luis Pérez Bonilla, Conveniencia de una asamblea legislativa unicameral para Puerto Rico, LIV Rev. Jur. U.P.R. 711, 723 (1985)).

Actualmente el gobierno de Puerto Rico tiene en su poder legislativo la cámara del Senado y la cámara de Representantes. Desde que se implantó el sistema bicameral, se ha estado estudiando el mismo a fondo. Las ventajas presentadas por el gobierno puertorriqueño son las siguientes: la cámara nivela el control de los otros dos cuerpos del gobierno (Rama Judicial y Rama Ejecutiva) y así se evitan los excesos. Al tener dos cámaras se permite establecer diversos esquemas representativos y al tener tantas personas se “reduce” el error sistemático. Hace ya un tiempo funcionarios del gobierno puertorriqueño han presentado el sistema unicameral ante el pueblo ciudadano.

Las ventajas, después de mucha consideración, se han argumentado y las mismas le han dado auge a la posibilidad del cambio. Las ventajas de la unicameralidad son: un solo cuerpo legislativo facilita que se llegue a un consenso general, economiza tiempo y recursos económicos ya que la realidad de gobierno de Puerto Rico es que la rama legislativa es sumamente numerosa lo cual equivale a muchos gastos. Continuando, la concentración de un solo cuerpo legislativo permite localizar y maximizar los recursos económicos de investigación, se genera un sentido de responsabilidad ya que solo hay un solo cuerpo legislativo y finalmente el análisis de otras constituciones del mundo lleva a la conclusión de que en realidad ha tenido éxito este sistema cameral.

Se ha rechazado la unicameralidad ya que se ha querido imitar el sistema de los Estados Unidos y porque en realidad no es conveniente para los integrantes del poder legislativo que se reduzca el tamaño del mismo porque resultaría en reducción de escaños. El 17 de marzo de 2003, el Honorable Luis Raúl Torres Cruz expresó que "la unicameralidad cumple con algunos de los objetivos que tiene la legislatura: reducir gastos, mejorar la calidad del trabajo legislativo y mejorar el balance entre los poderes del Estado, en particular por el fortalecimiento de una legislatura unicameral frente al poder ejecutivo". Se ha presentado una propuesta para enmendar la Constitución de Puerto Rico para cambiar su poder legislativo a una sola cámara ya que el sistema bicameral se ha visto defectuoso. En Puerto Rico en las últimas décadas se ha revelado una gran deficiencia del mismo ya que el pueblo ha elegido al gobierno con brechas mucho más amplias (mucha diferencia) y esto ha desembocado en una abrumadora mayoría que ocupa el poder legislativo llevando el poder a una dictadura de la mayoría lo cual es totalmente antidemocrático. Con estas deficiencias el Partido Independentista de Puerto Rico (más que cualquier otro) ha pedido que se haga un referéndum para que el pueblo decida si quiere continuar con la bicameralidad, la cual para muchos ha presentado defectos crasos.

En las siguientes fechas se han hecho referéndums para saber el sentir del pueblo respecto la bicameralidad o unicameralidad: 23 de septiembre de 2004, 25 de agosto de 2005 y 10 de julio de 2007. El referéndum bajo la Ley Núm. 477, mejor conocida como la Ley del Referéndum sobre el Sistema Cameral de la Asamblea Legislativa, establece que si el pueblo de Puerto Rico expresa su voluntad a favor de una propuesta por más de un 50 por ciento se debe validar la votación.

Ante el referéndum del 25 de agosto de 2005, el Dr. Luis Roberto Piñero González II, Presidente de Independentistas Pro Unicameralidad, compareció ante el pueblo puertorriqueño, dando un mensaje por escrito el cual establecía su posición ante la unicameralidad como la mejor opción para el poder legislativo: “El pasado 10 de julio de 2005 el electorado puertorriqueño se expresó en el referéndum, contundentemente a favor de sustituir el actual sistema legislativo bicameral por uno unicameral. Según los resultados del referéndum sobre el Sistema Cameral de 2005, la opción uno (1) que representa los votos a favor de que se cambie la Asamblea Legislativa a una sola cámara (unicameralidad) recibió el 83,8 por ciento de los votos emitidos”.

La Comisión Estatal de Elecciones certificó que luego del referéndum del 10 de julio de 2005 se favoreció el Sistema Unicameral. Todavía está bajo análisis y debate la decisión del electorado ya que significa que se deben preparar unas votaciones para que el pueblo escoja si quiere enmendar la Constitución y establecer la unicameralidad o no.

Actualmente, la isla cuenta con cuatro formaciones políticas reconocidas para los comicios electorales: el Partido Popular Democrático, que defiende el Estado Libre Asociado y la Libre Asociación como opción política; el Partido Nuevo Progresista, que promueve la integración plena como estado 51 de la Unión Americana; el Partido Independentista Puertorriqueño (PIP), que promulga la independencia y el Partido del Pueblo Trabajador sin planteamientos particulares acerca del estatus político de la Isla. En Puerto Rico también tienen presencia los dos partidos nacionales de Estados Unidos: el Partido Republicano de los Estados Unidos y el Partido Demócrata de los Estados Unidos, que promueven las primarias de esos partidos en Puerto Rico y colaboran en la recaudación de fondos.

Por otra parte el Partido Nuevo Progresista surgió como una ruptura dentro del Partido Republicano local. Tiene como ideología el conseguir la estadidad para Puerto Rico. En la actualidad cuenta con el respaldo del 47 % del voto popular. El mismo se ha destacado por grandes reformas en el sistema de transporte público y salud las cuales aún se encuentran en controversia debido al alto coste y a la deficiencia de los servicios de salud.

El Partido Popular Democrático se destaca por ser el partido activo más fuerte y antiguo de Puerto Rico. Fue fundado por disidentes del Partido Liberal. Aunque en un principio su filosofía política defendía la independencia, posteriormente cambió al autonomismo al entender que esta opción daba mayores beneficios a la población de la Isla sin la necesidad de integrarse como Estado en EE.UU. En la actualidad representa al 48 % de la población de la Isla.

El Partido Independentista Puertorriqueño es también uno de los más antiguos. Surgió cuando el Partido Popular comenzó a defender el autonomismo, entonces parte de sus miembros fundaron el Partido Independentista que, como su nombre indica, promueve la independencia para Puerto Rico. Aunque en los años 50 lograron un 20 % del apoyo del pueblo, su apoyo ha disminuido al grado de que perdió su franquicia en elecciones recientes incluyendo las elecciones del 2004, 2008, 2012 y 2016 . Actualmente sólo cuenta con el 2.5 % del apoyo del pueblo.

Puerto Rico se compone de rocas volcánicas (revisar) y plutónicas de los períodos Cretácico y Eoceno cubiertas por rocas sedimentarias del Oligoceno y recientes. La mayoría de las cuevas aparecen en el área kárstica del norte en las rocas del Oligoceno y recientes. Las rocas más antiguas de la isla tienen alrededor de 190 millones de años y están localizadas en sierra Bermeja, al suroeste. Estas rocas representan parte de la corteza oceánica y podrían haberse trasladado desde el océano Pacífico hasta su lugar actual en el Caribe. Puerto Rico se halla en la zona de contacto entre las placas tectónicas del Caribe y de Norteamérica. Esto quiere decir que la isla actualmente está siendo deformada por los esfuerzos creados en dicha zona. Dichos esfuerzos pueden causar terremotos y maremotos. Estos eventos sísmicos, acompañados de deslizamientos de tierras, representan algunos de los más peligrosos desastres geológicos en la isla y en el noreste del Caribe. Uno de los más graves fue el terremoto de san Fermín de 1918, llamado así por ocurrir en el natalicio del santo católico Fermín de Uzès.

Puerto Rico tiene un clima tropical con una temperatura promedio mínima de y la máxima de . La precipitación promedio es de al año.

Puerto Rico utiliza la hora estándar del Atlántico todo el año; esto es, UTC-04:00. El horario de verano no se usa en el archipiélago porque no hay mucha diferencia entre las puestas y salidas del sol a lo largo del año. La puesta de sol varía entre las 17:40 en invierno y las 19:10 en verano, mientras que la salida del sol varía entre las 7:00 en invierno y las 5:30 en verano.

La Economía de Puerto Rico es la más competitiva y, en términos nominales, la primera y más grande de la región Centroamericana y del Caribe y una de las más grandes de Latinoamérica pese a su tamaño. Según el Banco Mundial es una economía de alto ingreso no perteneciente a la OCDE, lo cual la convierte en la única nación de América Latina en alcanzar un elevado nivel de industrialización y bienestar económico. No obstante, de ser comparado con los Estados de los Estados Unidos, Puerto Rico sería el territorio que registraría mayores niveles de pobreza y menor productividad. En 2010, la renta per cápita de Puerto Rico ascendió a 24.229 $ (podría aumentar ligeramente en próximas revisiones por la pronunciada caída de la población desde 2005), mientras que el Estado de Mississippi sobrepasaba los 30.000 dólares con 32.967 dólares. En la actualidad Puerto Rico tiene una deuda pública de 72.204.000.000 $ (equivalente al 103% del PIB), un déficit gubernamental del 2.500.000.000 $.

A mediados del siglo XX la economía puertorriqueña se orientaba hacia la producción agrícola, especialmente al cultivo de la caña de azúcar. Sin embargo, había una gran inversión en la infraestructura pública. Los programas de incentivos federales han logrado transformar la actividad económica en los dos últimos cuartos de siglo. Desde los años 1960, se han establecido en el archipiélago numerosas empresas multinacionales de diferentes industrias como la farmacéutica, electrónica, textil, petroquímica, y más recientemente biotecnológica. Hoy en día, la manufactura y la industria de servicios (incluyendo el turismo) han reemplazado a la agricultura como principal productor de ingresos, cuya cuota de participación en la economía es inferior al 2%. Igualmente, el ganado y la producción de artículos lácteos reemplazaron a la industria azucarera como sector principal de la agricultura. La economía se desaceleró entre 2001 y 2003 por la recesión que experimentaba la economía estadounidense por el estallido de la burbuja tecnológica en el año 2000. En 2004 se produjo una efímera recuperación ya que, nuevamente, Puerto Rico entraría en un periodo de recesión durante 2006 y éste se ha extendido hasta 2012, el año en que se proyecta la depresión económica.

Las previsiones económicas apuntan a una leve mejoría en el comportamiento de la economía puertorriqueña en el año fiscal 2012 debido, fundamentalmente, a un mejor comportamiento de la economía global y a un plan de rescate aprobado por el Presidente Obama. Dicho plan incluyó una inyección económica de más de cinco mil millones de dólares para Puerto Rico.

Los líderes de la isla intentaron desarrollar Puerto Rico por medio de la industria ligera, alta en mano de obra pero baja en capital. Este intento falló con la recuperación de los mercados europeos después de la Segunda Guerra Mundial. El gobierno de la década de los 60 vio cómo el país se sumía en una bancarrota económica e intentó rescatar la economía por medio de la inversión en la industria petroquímica. Con la subida de los precios del petróleo realizada por la Organización de Países Productores de Petróleo, la industria petroquímica del País se vio sumida en una segunda crisis, lo que provocó que se revisara el modelo económico desarrollado hasta entonces. Los gobernantes lanzaron una tercera alternativa que era la extensión de contribuciones de las corporaciones privadas por medio de la sección 936 del Código de Rentas Internas. En 2005 venció el plazo dado a las empresas que se habían acogido al Código de Rentas Internas de los Estados Unidos, sección 936. Hasta el presente no se cuenta con un programa de desarrollo económico coherente que resuelva el hueco que dejó el cierre de la 936. Sin embargo, algunos grupos políticos han planteado que la crisis existente en Puerto Rico sólo se puede resolver por medio de un desarrollo integral de la economía que envuelva la autosuficiencia agrícola junto con el desarrollo de industrias de alta tecnología pero que contribuyan a la economía del país por medio de las contribuciones.

El gobierno de Aníbal Acevedo Vilá introdujo cambios en los sistemas de impuestos para normalizar la carga y distribuirla más equitativamente a todos los sectores de la economía del país. Ejemplo de eso es la reciente creación de un Impuesto sobre las Ventas y Uso (IVU) o «"sales tax"» que fluctuó durante los primeros meses después de ser establecido entre el 5,5% y el 7% (un 5,5% estatal y hasta un 1,5% municipal) sobre las compras y los servicios, pero que finalmente en 2007 fue unificado a 7% en todo el territorio. El IVU fue establecido con el fin de intentar aliviar los serios problemas fiscales que afectan a la Isla y evitar así una degradación en la escala de devaluación de los bonos de Puerto Rico, lo que de haber acontecido hubiera encarecido la financiación de los proyectos públicos. Este impuesto se equilibró con la eliminación del arbitrio del 6,6% que se cobraba en el punto de importación. Esto fue porque dicho sistema de arbitrios no era del todo fiable y era de conocimiento público que no percibía las cantidades que deberían haber entrado al erario, en su mayor parte por falta de personal para llevar a cabo inspecciones de carga y el tiempo que se requería para estas inspecciones.

Otra razón por la cual se estableció el nuevo impuesto a la venta es para reducir de manera drástica la tan mencionada "economía subterránea", cuyo monto llegó a ser estimado por el Banco de Gubernamental de Fomento igual al de la economía legal. Al requerirse el registro de todo comerciante para legalizar el cobro del IVU, se intenta reducir la evasión contributiva. También se han instituido otros cambios, tales como el alza de los servicios de electricidad y agua para lograr reducir los subsidios que se les daba a las agencias cuasi-gubernamentales que los administran bajo monopolio legal. Nuevamente la lógica es que estos servicios deben ser financiados a base del consumo en vez de subsidiarlo con fondos públicos, lo cual afectaba aún más el desbalance de la carga contributiva hacia la clase asalariada.


Según el censo de Estados Unidos del año 2010, la población total de Puerto Rico era de 3 725 789 habitantes. A su vez, la población de origen puertorriqueño en los cincuenta estados y el distrito de Columbia de EE.UU. era de 4 623 716 millones de personas. El 93.8 % de la población de Puerto Rico es urbana y tan solo el 6.2 % es rural. La densidad demográfica supera los 407,15 hab/km², lo que convierte a la isla como la más densamente poblada de las Antillas Mayores; de igual forma, posee una de las mayores aglomeraciones humanas del mundo. Las zonas más densamente pobladas son las costas y el área metropolitana de San Juan, donde la densidad alcanza los 1983,45 hab./km².

La esperanza de vida es de 82,67 años para las mujeres y 74,6 para los hombres, con un promedio de 78,54 años. El 27 % de la población en Puerto Rico es extranjera. Las nacionalidades cubana y dominicana son las más abundantes, seguido por venezolanos, haitianos, mexicanos, españoles, franceses, italianos, chinos, filipinos y alemanes.

Cifras:
Según el censo de Estados Unidos, la población de origen español es la que más abunda en Puerto Rico, con un 70,5 % de la población. Los afrocaribeños se encuentran especialmente en los municipios de Loíza y Río Grande. Los mulatos y mestizos se encuentran en toda la Isla, pero abundan más en el centro y norte. Los blancos se encuentran en toda la Isla también, pero abundan más en el oeste y en el área metropolitana. Los habitantes asiáticos son muy pocos en general. También aparecen mezcladas otras etnias y culturas.

Un estudio usando ADN mitocondrial encontró que la población de Puerto Rico tiene un alto componente genético taíno (aborigen puertorriqueño) y guanche (aborigen canario, especialmente de los guanches de la isla de Tenerife).

Puerto Rico cuenta con una de las infraestructuras más modernas del Caribe y América Latina. Sus ciudades principales, San Juan, Bayamón, Caguas, Guaynabo, Carolina, Ponce, Cayey, Arecibo y Mayagüez cuentan con modernos edificios, y con grandes fábricas de distintas compañías. San Juan es la metrópoli del Caribe, con grandes y modernos edificios, San Juan ocupa el lugar 71 como ciudad de mayor calidad de vida en el mundo y la de mejor calidad de vida de Latinoamérica, además es una una de las ciudades más modernas de América Latina. Sin embargo, a pesar de tener una infraestructura moderna , el patrón de desarrollo sufre de falta de planificación, lo cual afecta al medio ambiente, debido a no proveer la protección de los recursos naturales de la Isla. Algunos estudios demuestran que si el patrón de desarrollo continúa, en menos de 70 años la isla será una isla-ciudad. La Isla también cuenta con un sistema ferroviario metropolitano muy moderno llamado Tren Urbano, el cual está concentrado en el área metropolitana de San Juan, recorre desde San Juan hasta el municipio de Bayamón y se encuentra en vías de expansión en los próximos años, con tres líneas adicionales, una de las cuales llegará hasta el Aeropuerto Internacional. El sistema del Tren Urbano cuenta con dependencias modernas. Sus estaciones están equipadas con los más modernos sistemas electrónicos.
Además de que en la Ciudad de Mayagüez se encuentra el estadio de béisbol más moderno y tecnológico del Caribe con una capacidad de 13,000 espectadores. En donde en el Municipio de Rincón existe la única planta de energía nuclear en todo el Caribe. En la ciudad de Río Grande se encuentra el bosque del Caribe el Yunque. tambien en la Municipalidad de San Juan se encuentra el Coliseo de Puerto Rico siendo el más moderno, tecnológico, avanzado y grande de todo el Caribe con una capacidad de 20,000 espectadores teniendo un aspecto parecido al American Airlines Arena de Miami. Teniendo en cuenta que la Ciudad de San Juan es su Capital Puerto Rico tiene una variada y estable infraestructura en diferentes municipalidades además de que cada vez que Puerto Rico es sede de algún evento deportivo Puerto Rico invierte unas sumas de miles de millones de dólares que ningún país del Caribe o América Latina haya hecho alguna vez.

Hay veintiún aeropuertos, tres con vuelos internacionales: San Juan, Ponce y Aguadilla. El aeropuerto de la Base Naval Roosevelt Roads en Ceiba fue cerrado cuando la Marina abandonó sus operaciones allí, pero la propiedad reabrió ofreciendo sus servicio como el punto de trasbordo de carga aérea más grande del Caribe. Esto también le concede una vida útil indefinida al Aeropuerto Internacional Luis Muñoz Marín, ya que sus operaciones de carga se espera sean trasladadas a Ceiba Y cuenta con otro Aeropuerto Internacional en la Ciudad de Mayagüez llamado Aeropuerto Eugenio María de Hostos.
El metro de San Juan, Tren Urbano, recorre algunos de los puntos principales del área metropolitana de la capital. La Autoridad Metropolitana de Autobuses (AMA) opera autobuses por el área metropolitana que incluye San Juan, Carolina, Guaynabo y Bayamón. Operadores de transportes públicos de diversos tipos y tamaños cubren la totalidad de la Isla en rutas reguladas por la Comisión de Servicio Público. Ésta también regula la gran cantidad de taxis que operan a través de toda la Isla. Sin embargo todos estos sistemas de transporte público no están muy bien integrados, acarreando una gran pérdida de tiempo el movilizarse mediante ellos. Por lo cual la mayoría de los ciudadanos se ven forzados a usar su propio automóvil para desplazarse. 

La isla también cuenta con una red de puertos que pueden ser utilizados por todo tipo de embarcación privada y comercial, incluyendo los cruceros de pasajeros más grandes del mundo. Actualmente se está construyendo un nuevo puerto en el sur de la isla con el nombre de Rafael Santiago (antiguo alcalde de la ciudad de Ponce). Se espera que este puerto sirva como punta de lanza para adelantar el desarrollo económico de la isla.

La privatización de la salud ha disminuido la garantía y la calidad de los servicios debido a los altos costos en los servicios médicos y de farmacia. A pesar de la gran magnitud de industrias farmacéuticas estadounidenses, los medicamentos se venden a unos costos sumamente caros que obligan a los ciudadanos a pagar pólizas privadas, que también son costosos. Aunque existe un plan médico público, denominado "La Reforma", es limitado a personas de escasos ingresos.

Los altos costos en los medicamentos se debe a la aplicación de la Ley de Cabotaje, la cual establece que a los productos hechos en el país se le deben sumar los costos de importación.

La educación hasta el nivel secundario es gratuita y está garantizada constitucionalmente. Hay alrededor de 1523 escuelas públicas y el Departamento de Educación de Puerto Rico contrata a alrededor de 42 000 maestros. El Departamento se divide en regiones educativas, que a su vez se dividen en distritos escolares. Estos aportan sus servicios a cientos de miles de estudiantes y son la principal institución educativa del País. El idioma de instrucción es el español, pero el inglés es asignatura obligatoria en todos los grados. Departamento de Educación del Estado Libre Asociado de Puerto Rico opera la mayoría de las escuelas públicas del País.

Dentro del Departamento de Educación existe la Unidad de Escuelas Especializadas, entre ellas:
Existen 47 universidades: 39 privadas —13 de ellas con fines de lucro— y ocho públicas, las cuales representan 117 unidades académicas en toda la Isla. La Universidad de Puerto Rico es la más grande del País y sus once unidades componen el sistema público. Incluye el Recinto de Ciencias Médicas, del cual se ha graduado un porcentaje importante de los médicos. El 9,6 % de los recaudos estatales se destinan a pagar la universidad pública.

Entre las universidades privadas se encuentran:

El sistema educativo de Puerto Rico está integrado al sistema estadounidense. Los primeros cuatro o cinco años de estudios universitarios son denominados como bachillerato ("bachelor's degree"), en lugar de licenciatura, como se le conoce en Latinoamérica y España. Le siguen los grados de maestría y doctorado.

El Consejo de Educación Superior es el ente que licencia todas las instituciones universitarias públicas y privadas que interesen operar en la Isla. En términos de acreditación, (tal como se conoce en los Estados Unidos, más de la mitad de las instituciones de educación superior en Puerto Rico están acreditadas por la Middle States Commission on Higher Education. También hay varios programas académicos acreditados por entidades especializadas reconocidas por el Departamento de Educación de los EE.UU. como acreditadoras profesionales. Algunas de éstas son el American Board of Engineering and Technology ABET y la American Psychological Association [APA].

La música oriunda de Puerto Rico representa la convergencia de diferentes corrientes culturales; tales como la taína, la española y la canaria, la corsa y la africana. Con esta mezcla de ritmos, instrumentos y melodías se desarrolló lo que representa la identidad musical puertorriqueña. Los instrumentos característicos de esta música son el güiro, las maracas, el cuatro, la guitarra y los tambores africanos. Entre los primeros músicos profesionales, se destacó la gente negra y los criollos mulatos.

"Una gran parte de esta música folklórica es parte de la herencia del jíbaro, con su origen en la región española de Canarias. Eventualmente, esta se mezcló con otras músicas, importadas o nativas de la parte latina del Nuevo Mundo". 
En la actualidad, la isla cuenta con diferentes ritmos folclóricos culturales, como la bomba y la plena. En la música jíbara o trova destacan los diferentes seises y aguinaldos, y en la música clásica, la danza puertorriqueña. Actualmente, sus ritmos con auge internacional son la salsa y el reggaetón, los cuales tienen raíces extranjeras. La salsa evolucionó de ritmos mayormente reconocidos en Cuba, y el reggaeton por su parte es una fusión con el "hip-hop" y su antecesor, el reggae en español, y que en la actualidad se ha fusionado con todo tipo de ritmos, como por ejemplo la bachata de la República Dominicana.

El arte refleja influencias de su trasfondo étnico. Una forma de trabajo artesanal llamada talla de santos es el resultado de una larga evolución católica de representar los santos mediante esculturas con el propósito de convertir indígenas al cristianismo. Los santos son hechos de maderas nativas, barro y piedra. Luego de esculpir las efigies, algunas sencillas otras con mayor detalle, son pintadas con vivos colores. Los santos varían en tamaño, los más pequeños son de aproximadamente ocho pulgadas de alto y los más grandes hasta de veinte pulgadas. Tradicionalmente, los santos son vistos como mensajeros entre el cielo y la tierra por lo que ocupan espacios llamados altares en las casas. En estos altares las personas les piden ayuda, favores especiales y/o protección.

Muy populares también son las caretas de los vejigantes que son lucidas en los carnavales. Máscaras similares que representan los espíritus diabólicos son utilizadas también en España y África. Los españoles utilizaban estas máscaras para asustar los cristianos separados de la iglesia para que regresen. En las tribus africanas utilizaban las máscaras como protección de los espíritus malignos que representan. Basado en los orígenes históricos las caretas puertorriqueñas siempre tienen cuernos y colmillos. Generalmente son creadas con papier-maché, cáscara del coco y alambre. El rojo y blanco son los colores típicos de las caretas pero la paleta de colores se ha expandido para incluir una amplia variedad de formas y patrones.

Una expresión de la artesanía puertorriqueña es el mundillo que viene de la tradición e influencia europea y católica. El mundillo es un encaje hecho a mano utilizado para adornar los cuellos de las camisas, los trajes de boda y de bautismos. Es muy conocido en los pueblos del noroeste de la isla especialmente Moca, conocida como la Capital del Mundillo. La obra Mundillo Nuestro del Maestro Antonio Martorell, uno de los artistas puertorriqueños más reconocidos a nivel mundial, se exhibe en el Museo de Arte de Puerto Rico y representa el esfuerzo coordinado del artista y varias mundillistas de Moca y otros pueblos. Es una enorme representación artística de un mapa mundial en hilo elaborado utilizando las técnicas del mundillo. Esta obra es parte del proyecto de exhibición colectiva de arte a nivel mundial llamada Google Art Project.

En Puerto Rico, la Navidad Boricua comienza en noviembre el día después del Día de Los Santos y se incorpora la celebración del Día de Acción de Gracias donde se conmemora la llegada de los peregrinos ingleses a las Américas; en Navidad, el 25 de diciembre, y el Día de Reyes, el 6 de enero, se reparten regalos a los niños (y adultos); y finaliza la temporada navideña 8 días después del Día de Reyes con las octavitas. El fin de la Navidad termina con las fiestas de la Calle San Sebastián en el Viejo San Juan.

Hay diez fiestas navideñas solemnes en Puerto Rico: las Misas de Aguinaldos, Nochebuena, la Misa de Gallo, el Día de Pascuas (Día de Navidad), Despedida de Año, Año Nuevo, Día de Reyes, las Fiestas de la Calle San Sebastián, las octavas y octavitas, y los aguinaldos (parrandas, trullas o asaltos).

En Puerto Rico, se observan todas las fiestas nacionales de los Estados Unidos por ser un territorio no incorporado estadounidense, o mejor dicho, una colonia.

En Puerto Rico, los deportes más populares son el baloncesto, el béisbol y el boxeo; mientras el fútbol gana mucha popularidad en las últimas décadas. Puerto Rico también se ha destacado a nivel mundial en otros deportes como: atletismo, voleibol, tenis, golf, softbol, judo, lucha olímpica, entre otros.

Algunos de los atletas más destacados que tiene y ha tenido la Isla son:

Baloncesto: José Juan Barea, Carlos Arroyo, José Ortiz, Raymond Dalmau, Juan Vicéns, Elías Ayuso, Eddie Casiano, entre muchos otros.

Béisbol: Roberto Clemente, Roberto Alomar, Orlando Cepeda, Iván Rodríguez, Yadier Molina, Carlos Beltrán, Carlos Correa, Carlos Delgado, Edgar Martínez, Juan González, Bernie Williams, entre muchos otros.

Boxeo: Miguel Cotto, Wilfredo Gómez, Wilfred Benitez, Hector Camacho, Felix Trinidad, Wilfredo Vázquez, Edwin Rosario, Iván Calderón, Carlos Ortiz, Alfredo Escalera, Sixto Escobar, entre muchos otros.

Voleibol (hombres): Héctor Soto, Luis Rodríguez, Víctor Rivera, Ozzie Antonetti, Gregory Berríos, entre otros.

Voleibol (mujeres): Áurea Cruz, Karina Ocasio, Sheila Ocasio, Jetzabel Del Valle, Eva Cruz.

Tenis: Mónica Puig. Oro olímpico en individuales en los Juegos Olímpicos de Río de Janeiro 2016, el primero en la historia de Puerto Rico.

Golf: Chi-Chi Rodríguez

Lucha Olímpica: Jaime Espinal

Atletismo: Javier Culson






</doc>
<doc id="2143" url="https://es.wikipedia.org/wiki?curid=2143" title="Premio Miguel de Cervantes">
Premio Miguel de Cervantes

El Premio de Literatura en Lengua Castellana Miguel de Cervantes, conocido también como Premio Cervantes o Premio Miguel de Cervantes, es un premio de literatura en lengua española concedido anualmente por el Ministerio de Cultura de España a propuesta de la Asociación de Academias de la Lengua Española.

Fue instituido en 1976 y está considerado como el galardón literario más importante en lengua castellana pese a no ser el de mayor monto. Está destinado a distinguir la obra global de un autor en lengua castellana cuya contribución al patrimonio cultural hispánico haya sido decisiva.

Está dotado con 125 000 euros y toma su nombre de Miguel de Cervantes Saavedra, autor de la que se considera la máxima obra de la literatura castellana, "Don Quijote de la Mancha".

Su primera edición tuvo lugar en el año 1976. El Premio Cervantes no puede ser dividido, declarado desierto o ser concedido a título póstumo, según las normas que se establecieron después de que en la edición de 1979 el jurado decidiera conceder el premio «ex aequo» al español Gerardo Diego y al argentino Jorge Luis Borges.

Los candidatos al Premio Miguel de Cervantes son propuestos por el pleno de la Real Academia Española, por las Academias de la Lengua de los países de habla hispana y por los ganadores en pasadas ediciones.

El jurado estuvo integrado por el director de la Real Academia Española, el director de una Academia de la Lengua de Hispanoamérica, que va cambiando cada año, el premiado en la edición anterior y seis personalidades del mundo académico, literario o universitario, hispanoamericanos, «de reconocido prestigio».

Desde la edición del año 2008, la composición del jurado sigue un nuevo modelo que supone una mayor proporción de miembros designados por entidades de carácter electivo: los dos últimos galardonados con el propio Premio Cervantes; un miembro de la Real Academia Española; un miembro de una de las Academias Iberoamericanas de la lengua española; cuatro personalidades del mundo académico, universitario y literario, de reconocido prestigio, propuestos, respectivamente, por la Conferencia de Rectores de las Universidades Españolas, la Unión de Universidades de América Latina, el director del Instituto Cervantes y el ministro de Cultura de España; dos miembros elegidos entre representantes de suplementos culturales de diarios, propuestos, respectivamente, por la Federación de Asociaciones de Periodistas de España y la Sociedad Interamericana de Prensa; y uno a propuesta de la Asociación Internacional de Hispanistas, de nacionalidad no española ni iberoamericana.

Se falla a finales de año y se entrega el 23 de abril del siguiente, coincidiendo con la fecha en que se conmemora la muerte de Miguel de Cervantes. Se celebra en la Universidad de Alcalá de Henares. El rey de España, Felipe VI, preside la entrega de este galardón en el Paraninfo de la Universidad de Alcalá. En este acto solemne, el rey, el ministro de Cultura español y el autor galardonado pronuncian sendos discursos en los que se glosan la vida y producción literaria del premiado, la obra de Cervantes y los autores clásicos de nuestra lengua, así como sobre el estado del idioma.

Los últimos galardonados con el Premio de Literatura en Lengua Castellana Miguel de Cervantes son Fernando del Paso (2015), Eduardo Mendoza (2016) y Sergio Ramirez (2017).




</doc>
<doc id="2144" url="https://es.wikipedia.org/wiki?curid=2144" title="Premio Planeta">
Premio Planeta

El Premio Planeta de novela es un premio literario comercial otorgado desde 1952 por la editorial Planeta a la mejor obra inédita. Fue creado por el fundador de la editorial José Manuel Lara Hernández. Este premio no debe confundirse con los que otorgan las filiales de Planeta en algunos países latinoamericanos, como por ejemplo el Premio Planeta Argentina.

Es uno de los premios literarios mejor dotados del mundo, sólo por detrás del Premio Nobel de Literatura, con 601.000 € para el ganador y 150.250 € para el finalista. Se falla cada 15 de octubre, festividad de Santa Teresa, onomástica de la esposa del fundador, María Teresa Bosch.

En los últimos años su credibilidad se ha puesto en tela de juicio desde muchos ángulos. La cuestión ha llegado al extremo de que escritores como Miguel Delibes o Ernesto Sabato han renunciado a participar al mismo (denunciando ambos que les habían ofrecido ganar la edición de 1994).

En 2005 un tribunal argentino condena a pagar 10.000 pesos a Gustavo Nielsen por haberlo perjudicado, después de encontrar que hubo fraude en la entrega de la versión argentina del premio Planeta, entregado por la empresa editora Espasa Calpe Argentina, que forma parte del Grupo Planeta. El premio había sido entregado a Ricardo Piglia en 1997.

El nombre de los autores de las novelas ganadoras se conoce días antes de su promulgación, con lo cual ha decaído el prestigio literario del galardón.





</doc>
<doc id="2145" url="https://es.wikipedia.org/wiki?curid=2145" title="Perú">
Perú

Perú (en quechua y en aimara: "Piruw"), oficialmente la República del Perú, es un país soberano del oeste de América del Sur. El océano Pacífico bordea su costa y limita con Ecuador y Colombia al norte, Brasil al este, y Bolivia y Chile al sureste. Su territorio se compone de diversos paisajes: los valles, las mesetas y las altas cumbres de los Andes se despliegan al oeste hacia la costa desértica y al este hacia la Amazonia. Es uno de los países con mayor diversidad biológica y mayores recursos minerales del mundo.

El Antiguo Perú fue una región de sucesivas civilizaciones desde el surgimiento de Caral-Supe en el 3200 a. C. El Imperio incaico fue el último Estado autóctono o indígena, el cual dominó gran parte del occidente sudamericano hacia el siglo . Con el siguiente siglo advino la Conquista del incario, tras la cual el territorio se configuró como un virreinato del Imperio español articulado en torno a la explotación de plata y oro con trabajo forzado de indígenas y de esclavos africanos en minas y haciendas. Las reformas borbónicas del siglo suscitaron diversos levantamientos contra la autoridad colonial, cuyo máximo exponente fue la rebelión de Túpac Amaru II.

Con la ocupación de España y la promulgación de la constitución de 1812, se difundieron ideas de autonomía política en la América española. La Independencia se proclamó formalmente en 1821, y fue saldada en la batalla de Ayacucho tres años después. El país se mantuvo en recesión y bajo el caudillismo militar hasta la bonanza y declive de la era del Guano, que culminó poco antes de la Guerra del Pacífico. En la posguerra, se cimentó una política oligárquica que prevaleció hasta el fin del Oncenio. Los sucesivos gobiernos democráticos fueron constantemente interrumpidos por golpes de Estado.

En 1968, se impuso una dictadura militar que introdujo diversas y profundas reformas de corte nacionalista. El gobierno democrático y representativo fue restablecido en 1980, así también se dieron inicio un sangriento conflicto armado entre los grupos terroristas de Sendero Luminoso y el MRTA y el Estado en la sierra sur así como la crisis inflacionaria de fines de la década. En los años 1990 se implementó un modelo neoliberal, cuyas bases continúan vigentes. A inicios del siglo , el país experimentó un importante crecimiento económico y reducción de la pobreza, aun soportando una fuerte desigualdad y una renta per cápita por debajo de la media mundial. Es considerado un país en vías de desarrollo. Entre sus principales actividades económicas se incluyen la agricultura, la minería, la pesca, la construcción y el comercio.

La cultura peruana es diversa como resultado del intenso mestizaje originado en la colonia. A ello se une la posterior influencia de migraciones decimonónicas procedentes de China, Japón y Europa. El idioma principal y más hablado es el español, aunque un número significativo de peruanos habla diversas lenguas nativas, siendo la más extendida el quechua sureño. Políticamente, el país está organizado como una república presidencialista con un sistema multipartidista estructurado bajo los principios de separación de poderes y descentralización. Administrativamente, se divide en veinticuatro departamentos y la provincia constitucional del Callao.

Existen muchas versiones sobre el origen etimológico del nombre Perú; he aquí las más conocidas.

La palabra «Perú» derivaría de Virú. Los primeros españoles que llegaron al país le preguntaron a unos nativos como llamaban ellos el lugar, a lo que respondieron «Virú» (antigua cultura pre-inca, del río Virú, al norte del Perú). Los españoles entendieron el nombre como «Perú» y de allí proviene el nombre. Así, cuando Francisco Pizarro exploró las regiones más meridionales en 1525, estas fueron designadas Virú o Perú. La Corona española le dio al nombre un estado legal en 1529 con la Capitulación de Toledo, la cual designó al entonces reciente confrontado Imperio incaico como la provincia del Perú. Bajo el mandato español, el país adoptó la denominación de Virreinato del Perú que se convertiría, a su vez, en República del Perú al momento de la independencia del dominio español.

Según el historiador Raúl Porras Barrenechea, el nombre «Perú» no fue conocido por los incas, sino que fue impuesto en los primeros años de la conquista por los exploradores españoles. Estos lo tomaron del nombre de un cacique llamado «Biru», quien vivió cerca del Golfo de San Miguel en Panamá, donde gobernaba una pequeña región de la costa panameña al sur del golfo a inicios del siglo . Con el tiempo, los españoles empezaron a llamar Perú no solo a esa pequeña región, sino a todo el gran país situado más al sur. Los tesoros encontrados en la tierra de los incas terminaron por convertir el nombre de Perú en sinónimo de riqueza.

A partir de las primeras exploraciones, Vasco Núñez de Balboa recibió las primeras noticias sobre un lejano país donde se bebía y comía en vasijas de oro; dichos indicios eran muy vagos para conjeturar la existencia del Imperio incaico. Posteriormente Balboa, acompañado de Francisco Pizarro, después de descubrir el Mar del Sur, alcanzó el golfo de San Miguel, donde recibió noticias más convincentes sobre la existencia del país buscado. El viajero Badajoz, desviándose de la ruta de Balboa, se dirigió al oeste y descubrió nuevas tierras, donde arrebató unas joyas y objetos de oro a sus habitantes aborígenes.

Del mismo modo, el licenciado Gaspar de Espinosa conquistó la provincia de «Peruquete», nombre que algunos historiadores consideran que dio origen al nombre «Perú». Según el cronista Gonzalo Fernández de Oviedo, «después de la ejecución de Balboa en Darién, no se hablaba de otra cosa, sino de la rica y lejana provincia de Perú»; dice también Oviedo que en el mapa de Andagoya, el río Cartagena llevaba el nombre «Pirú». Casi por el mismo tiempo (1519), Pascual de Andagoya emprendió un viaje hacia Levante y, al llegar a la provincia llamada Chochama, recogió noticias más concretas sobre el Imperio incaico: llegó a otra provincia llamada Virú o Birú donde también corría un río del mismo nombre. He aquí como relata Andagoya su viaje:

Sus restos arqueológicos más antiguos son muy posteriores al primer poblamiento de América. Corresponden al XI milenio a. C., datación hallada en la Cueva del Guitarrero (departamento de Áncash), en la sierra nor-central del país. A fines de la última glaciación, los primeros pobladores comenzaron el lento proceso de domesticación de la biota local (véase: revolución neolítica) y a reunirse en tribus y aldeas para formar eventualmente aillus. Se han encontrado vestigios del origen de la agricultura americana en la cuenca media del río Zaña, en Nanchoc (departamento de Cajamarca) de hace nueve mil años (7600 a. C.).

Hacia el IV milenio a. C., las comunidades aldeanas de la costa iniciaron una jerarquización que se superpuso a la organización tribal. Aparecieron entonces los primeros indicios de arquitectura organizada, con edificios públicos y ceremoniales. A comienzos del III milenio a. C., surgió en el complejo de Caral, la civilización más antigua del continente, centro de una extensa red de intercambio comercial que iba desde Ecuador hasta la selva del Perú, de la cual participaba con la producción extensiva del algodón y con una jefatura ligada al culto ceremonial.

Caral es coetánea a las civilizaciones de China, Egipto, India y Mesopotamia; tratándose de una zona que puede considerarse como cuna de la civilización del mundo por su antigüedad (c. 5000 años). Más antiguo parece ser el complejo de Sechín Bajo, en el valle de Casma (Áncash), donde se han hallado restos de una edificación de 5500 años de antigüedad, que sería la más antigua del Perú y América. Posteriormente, se difundió en la costa norte la cultura Cupisnique, que tuvo apogeo entre los años 1500 a. C. y 1000 a. C. A finales de este período, la cultura Chavín ejerció enorme influencia cultural sobre las demás hasta su decadencia. Los petroglifos y canales de Cumbemayo, a media hora de la ciudad de Cajamarca, constituyen una obra maestra de ingeniería hidráulica.

Se trata de unos bloques tallados por los que discurre agua en una suave pendiente, que incluye túneles y codos en zigzag para aminorar la velocidad de la corriente. Los bloques de piedra ubicados al inicio del recorrido tienen diversos planos tallados y pulidos. Uno de estos bloques, en forma de cono trunco, es conocido tradicionalmente como «piedra de los sacrificios». En el seno de las culturas Moche al norte y Nazca al sur, se desarrollaron los primeros estados con milicias permanentes, vinculadas a las piezas de arte cerámico mejor valoradas del Antiguo Perú.

En el extremo sur, entre tanto, surgió Tiahuanaco como cultura dominante del Altiplano. Más tarde, la cultura wari desarrolló el modelo clásico del Estado Andino con el surgimiento de las ciudades de corte imperial, modelo que se expandió por el norte hacia el siglo . A partir del siglo , tras el abandono de Huari, se erigieron nuevos Estados centralizadores de alcance regional a lo largo de la cordillera de los Andes, tales como Lambayeque, Chimú y Chincha, periodo conocido como el Intermedio Tardío o de los Estados regionales.

De entre estos señoríos destaca el de los incas, que hacia el siglo se anexionó todos los pueblos andinos entre los ríos Maule y Ancasmayo, con una extensión de dos millones de km², hoy ubicada en los territorios del sur de Colombia, el oeste de Ecuador, Perú, Bolivia, el norte Chile y el noroeste de Argentina, conformando lo que se conoce como el Imperio incaico. Su capital fue el Cuzco, ubicada en la sierra sur peruana. Además de su poderío militar, destacó en arquitectura, con magníficas estructuras como la ciudadela de Machu Picchu.

En el año 1532, el Imperio incaico o Tahuantisuyo sucumbió ante la conquista española que llevó a cabo Francisco Pizarro. El conquistador encontró al imperio debilitado a causa de una guerra civil iniciada en 1529 entre Huáscar y Atahualpa, los dos hermanos pretendientes al trono imperial. En noviembre de 1532, Pizarro capturó a Atahualpa y, en julio de 1533, lo mandó ejecutar bajo el cargo de haber ordenado la muerte de su hermano Huáscar. Doblegando la oposición, relativamente débil de algunos generales incas, se dio inicio al dominio español que estableció sobre el territorio del antiguo Imperio incaico, el virreinato más poderoso que España tuvo en ultramar.

Tras el asesinato de Atahualpa los familiares de Huáscar se unirían a Francisco Pizarro junto con miles de hombres de etnias opositoras a los incas, así fue recibido con honores Pizarro en el Cusco y la ciudad fue ocupada sin mediar batalla, luego el conquistador fundó la ciudad de Lima. Al poco tiempo se suscitó la guerra civil entre los conquistadores por el repartimiento de las encomiendas del nuevo territorio. En 1542, se estableció el Virreinato del Perú, que en un comienzo abarcó "de iure" un espacio geográfico desde lo que hoy es Panamá hasta el extremo sur del continente.

El nuevo orden provocó un nuevo levantamiento conocido como la rebelión de los encomenderos. En la década de 1570, el virrey Francisco de Toledo reorganizó el territorio pacificando el país de las guerras intestinas y culminando con la resistencia incaica. El Imperio español significó para el Perú una profunda transformación social y económica. Se implantó un sistema mercantilista, sostenido por la minería del oro y de la plata, principalmente, de Potosí, el monopolio comercial y la explotación de la mano de obra indígena bajo el trabajo forzoso o mita.

A partir de fines del siglo e inicios del , la recaudación de la Corona se vio lentamente socavada por el declive de la minería y la consecuente diversificación económica, así como por el contrabando comercial. En este contexto, fueron impuestas las reformas borbónicas, las cuales restaron poder político a la élite limeña y afectaron económicamente al comercio interno, lo que produjo diversos levantamientos de los cuales el de mayor repercusión fue la rebelión del descendiente de los incas Túpac Amaru II; esta última llegó a poner en peligro el gobierno virreinal en el Cusco, pero al tomar tintes raciales contra criollos indistintamente, precipitó su derrota.

Tras la muerte de Túpac Amaru, la cultura indígena fue férreamente reprimida por las autoridades borbónicas y atrasaron los proyectos emancipatorios dado el temor a nuevas asonadas contra la élite peninsular y criolla. No cabe duda que el Cusco era la ciudad principal de todo el Tahuantinsuyo. Al tomarla los españoles, mermó significativamente la resistencia inca, no solo porque allí se encontraba toda la organización del imperio, sino por el significado que tenía para los ejércitos incas ver su capital tomada y dominada por los españoles.

En el siglo , tuvieron lugar varios levantamientos indígenas en reacción a los abusos de los corregidores españoles, la falta de justicia, la demora en los reclamos, y el cobro indebido de los tributos, donde destacan personajes como Juan Santos Atahualpa, Túpac Amaru II y Túpac Katari. La rebelión de Túpac Amaru II fue el levantamiento de mayor repercusión social y política de esta época. El 4 de noviembre de 1780, Túpac Amaru II consiguió preparar un movimiento revolucionario que puso en peligro el poder de la monarquía. Esa noche tomó preso al corregidor Antonio Arriaga, a quien lo obligó a entregar los fondos reales y luego lo mandó ejecutar como castigo de sus crueldades.

Luego, logró organizar un considerable ejército de indígenas; en el Cusco los corregidores cercanos se reunieron y organizaron igualmente un ejército que partió en la búsqueda de Túpac Amaru. Ambos ejércitos se encontraron en el pueblo de Sangarará, librándose una brutal y sangrienta batalla de la que Túpac Amaru II salió triunfador. En el Cusco, el 18 de mayo de 1781, fue sometido a un juicio y condenado a morir junto con los demás cabecillas de la rebelión. Primero intentaron descuartizarlo, donde sus extremidades fueron atadas a cuatro caballos, pero al fracasar, lo mandaron decapitar. Los levantamientos indígenas fueron controlados por la monarquía española, pero estas influenciaron a futuras luchas independentistas.

En el siglo surgió la Expedición Libertadora del Perú encabezada por el general argentino José de San Martín con la misión de independizar al Perú. El 20 de agosto de 1820, partió de Valparaíso, con destino al Perú, llegando así a la bahía de Paracas después de dos semanas de navegación. A los pocos días, hubo conversaciones en Miraflores (25 de septiembre) entre representantes de San Martín y el virrey Joaquín de la Pezuela, I Marqués de Viluma para buscar la independencia de manera pacífica, pero estas fracasaron.

El general San Martín posteriormente se comunicó con el intendente de Trujillo José Bernardo de Tagle, IV Marqués de Torre Tagle quien había llegado a la ciudad ese mismo año, mediante una carta fechada el 20 de noviembre de 1820, invitándolo a unirse a la causa emancipadora. Bernardo de Tagle se sumó a la causa patriota proclamando la Independencia de Trujillo el 29 de diciembre de 1820. El virrey Pezuela renunció a su cargo, siendo nombrado como nuevo virrey el general José de la Serna, I Conde de los Andes.

La Serna propuso a San Martín nuevos arreglos pacíficos en las Conferencias de Punchauca, las cuales no se llegó a dar ningún acuerdo. Ante esta situación, el virrey decidió evacuar Lima por temor a ser expuesto al ataque de San Martín, quién logró ocupar la ciudad con un batallón de patriotas. Los actos de declaración, proclamación y jura de la independencia del Perú se llevaron a cabo en la ciudad de Lima, entre los meses de julio y agosto de 1821. El primero de ellos, constituido por la firma del acta que contenía la declaración de independencia, fue realizado por el Cabildo de Lima el 15 de julio de ese año.

La proclamación fue llevada a cabo el 28 de julio de 1821, cuando el líder de la Expedición Libertadora del Perú, el general José de San Martín proclamó desde cuatro plazas públicas la independencia del Perú. A partir del 29 del mismo mes, se realizó la juramentación por el pueblo, organizado en sus diversas instituciones. El 3 de agosto de 1821, abrigando un plan monárquico, José de San Martín asumió "el mando político y militar de los departamentos libres del Perú" bajo el título de Protector. El 27 de diciembre de 1821, convocó a la ciudadanía con el fin de que eligiera libremente un Congreso Constituyente con el exclusivo objeto de establecer la forma de gobierno y dar la Constitución más conveniente. El primer Congreso de la República del Perú se reunió el 20 de septiembre de 1822. Más tarde, en 1824, el general venezolano Simón Bolívar tras sus victorias en las batallas de Junín y Ayacucho, el 6 de agosto y 9 de diciembre de 1824 respectivamente, aceptó la capitulación de las tropas realistas afincadas en la sierra sur, terminando con el Virreinato del Perú.

Una vez proclamada la independencia, San Martín, asumió el mando político militar de los departamentos libres del Perú, bajo el título de Protector, según decreto dado el 3 de agosto de 1821. Las obras del Protectorado contribuyeron con la creación de la Biblioteca Nacional (a favor del conocimiento), la aprobación del Himno Nacional, y la abolición de la mita (a favor de los indígenas). El 27 de diciembre de 1821, San Martín creó tres ministerios: Ministerio de Estado y Relaciones Exteriores, comprometiendo a Juan García del Río; Ministerio de Guerra y Marina, a Bernardo de Monteagudo; y Ministerio de Hacienda, a Hipólito Unanue.

Durante el Protectorado, el 7 de abril de 1822, la división de Domingo Tristán y Moscoso que viajó a Pisco, sufrió una desastrosa derrota del bando realista tras la batalla de Ica, perdiendo muchos soldados y gran parte de su armamento. Con el objetivo de acelerar la independencia total del Perú en la sierra sur, San Martín viajó a Guayaquil a fin de ponerse de acuerdo con Simón Bolívar, para pedirle ayuda militar, pero al terminar la conferencia, no se llegó a ningún acuerdo, y San Martín se retiró de Guayaquil con la decisión de abandonar al Perú. Entregó el poder ejecutivo a tres de sus miembros, que conformaron un cuerpo colegiado denominado Suprema Junta Gubernativa del Perú y cuya cabeza era el general José de La Mar.

La Junta Gubernativa quiso finalizar la Guerra de la Independencia por cuenta propia y organizó la Primera Campaña de Intermedios, que culminó en fracaso. Luego, los oficiales del Ejército se sublevaron en el llamado motín de Balconcillo y con un golpe de Estado, destituyeron a la Junta y el 28 de febrero de 1823 nombraron como Presidente del Perú a José de la Riva Agüero. Riva Agüero quiso también derrotar a los españoles, que aún resistían en el centro y sur del Perú, y organizó una Segunda Campaña de Intermedios, la misma que igualmente culminó en fracaso.

Luego tuvo una abierta disputa con el Congreso y se trasladó a Trujillo, donde instaló su gobierno, mientras que en Lima, el Congreso nombró como nuevo Presidente a José Bernardo de Tagle. El Congreso, vista la crítica situación, acordó llamar a Bolívar y a su Ejército Libertador. Tras reunificar el mando del país, Bolívar instaló su cuartel general en Trujillo y organizó la campaña final de la Independencia, contando con la ayuda decisiva de los peruanos, tanto en soldados, dinero, abastecimientos y recursos de toda índole. Tras las batallas de Junín y Ayacucho, el 6 de agosto y 9 de diciembre de 1824 respectivamente, se logró derrotar y expulsar definitivamente del Perú a las tropas realistas.

Es solo con la primera elección de Ramón Castilla en 1845 que la República Peruana encontró una relativa paz interior y pudo organizar su vida política y económica. Le correspondió a Castilla abolir definitivamente la esclavitud y la pena de muerte. Estableció políticas de promoción de extracción y exportación de fertilizantes naturales (guano de islas) que iniciarían una era de prosperidad en el país. Los primeros ferrocarriles y el alumbrado a gas llegaron al Perú en este período. Durante su segundo gobierno promulgó la Constitución de 1856 (Liberal) y la Constitución de 1860 (Conservadora), reorganizó los servicios postales y la carrera pública.

En 1864 una expedición española ocupó las Islas Chincha (productoras de guano) y desató un incidente internacional de grandes consecuencias en la política interna peruana, que llevó a un golpe de estado contra el presidente Juan Antonio Pezet, el gobierno de Mariano Ignacio Prado y la declaratoria de guerra a España. Tras el combate del Callao del 2 de mayo de 1866, la Armada Española se retiró del Perú. El gobierno de José Balta y Montero fue pródigo en obras de infraestructura (construcción del Ferrocarril Central) aunque en él se percibieron ya las primeras muestras de exceso de gastos del gobierno.

En las postrimerías de su gobierno, la elección, por primera vez, de un presidente civil, Manuel Pardo y Lavalle, llevó a una insurrección militar que terminó en el asesinato de Balta y la furibunda reacción de la población de Lima (que ejecutó a los usurpadores), así terminó lo que Jorge Basadre llamó "Primer Militarismo". Pardo y Lavalle implementó importantes reformas de tipo liberal en la organización del estado. Sin embargo la principal fuente de recursos del estado, el guano, sobreexplotado, se empezó a agotar y resultó inevitable una crisis económica que el sucesor de Pardo, el ya anciano Mariano Ignacio Prado tuvo que afrontar, en medio de una virtual bancarrota del Estado.

Para 1859 habían muerto unos 41 000 peruanos en las constantes guerras civiles que sacudieron el país desde 1829. Gracias al dinero de la venta del guano, el Perú empezó a modernizarse con distintas obras públicas como los ferrocarriles; creció la burocracia civil y militar; los indios dejaron de pagar tributo y los esclavos alcanzaron su libertad; empezó la política de migraciones de alemanes, austriacos, irlandeses e italianos.

El 5 de abril de 1879, Chile declaró la guerra al Perú, desatando la Guerra del Pacífico. El "casus belli" fue el enfrentamiento entre Bolivia y Chile por un problema de impuestos en el cual el Perú se vio comprometido por el Tratado de Alianza Defensiva firmado con Bolivia en 1873. Sin embargo, la historiografía peruana es unánime al sostener que la causa profunda de esta guerra fue la ambición de Chile de apoderarse de los territorios salitreros y guaneros del sur del Perú. En una primera etapa de la guerra, la campaña naval, la marina peruana repelió el ataque chileno hasta el 8 de octubre de 1879, día en el que se libró el combate naval de Angamos, en donde la armada chilena con sus buques "Cochrane", "Blanco Encalada", "Loa" y "Covadonga" acorraló al monitor "Huáscar", el principal buque de la marina peruana comandado por el Almirante AP Miguel Grau Seminario, quien murió en la refriega y se convirtió desde entonces en el mayor héroe del Perú.

Luego de vencer a la escuadra peruana, Chile dio inicio a la campaña terrestre de la guerra. Esta comenzó con el desembarco de Pisagua y se desarrolló durante cuatro años (incluyendo la ocupación de Lima), hasta que luego del Grito de Montán, el gobierno de Miguel Iglesias, firmó el Tratado de Ancón que puso fin a la guerra, a pesar de la oposición del gobierno de Lizardo Montero y la resistencia en la sierra peruana comandada por Andrés Avelino Cáceres, el cual vislumbraba el cercano agotamiento de las fuerzas chilenas para derrotarlas.

Tras la guerra, se inició un período de «Reconstrucción Nacional» que, aunque de relativa calma, no conoció la reactivación económica ni la paz política hasta 1895 con la presidencia de Nicolás de Piérola. Con el gobierno de Piérola, se materializó una política pluto-aristocrática con unas clases alta y media que vivían acomodadamente al auspicio de los grandes capitales estadounidenses y un pueblo llano con diversas carencias, frente a las cuales reclamaron, principalmente ante las malas condiciones laborales.

Esta época, conocida como la República Aristocrática, concluyó con la asunción de Augusto Leguía, quien permaneció en el poder durante once años —el "Oncenio"— con una política paternalista hacia los indígenas, la creación de una momentánea bonanza, la manipulación del orden jurídico y la amedrentación de la oposición. El Oncenio de Leguía, terminó en 1930 con el popular pronunciamiento de Luis Miguel Sánchez Cerro, que inició un período de gobiernos militares y de irrupción de movimientos populares –como la Alianza Popular Revolucionaria Americana o el Partido Comunista Peruano– en el escenario político.

Al final de este tercer militarismo se sucedieron presidentes democráticos interrumpidos primero por el "Ochenio" de Manuel A. Odría y un breve golpe militar para continuar con la sucesión presidencial. Hacia los años 1950 se inició el éxodo rural, principalmente desde la sierra hacia las urbes de la costa, en busca de mejores condiciones de vida y educación para sus hijos. Gradualmente, durante los años 1960 la crisis política se hizo patente, lo que propició en 1968 la llamada "Revolución de la Fuerza Armada", la toma del poder político por parte de las Fuerzas Armadas del Perú al comando del general Juan Velasco Alvarado con un mensaje antiimperialista, especialmente anti-estadounidense, y antioligarca.

Se instauró un régimen de corte estatista que impulsó varias y profundas reformas de diversos resultados. Hacia fines de los años 1970, el gobierno militar con todas las reformas producidas, se encontró frente al descalabro económico, aún pese a que se había dado un cambio de mando en la cúpula militar y que la presidencia había sido asumida por el general Francisco Morales Bermúdez en el año 1975. A pesar de esto, se dio el fin de la revolución y se retornó a la democracia. Se redactó una nueva constitución mediante una Asamblea Constituyente en 1979 y se convocó a elecciones en 1980.

Durante la década de 1980, el Perú enfrentó una fuerte crisis económica y social, debido al descontrol del gasto fiscal, una considerable deuda externa y la creciente inflación junto con un conflicto armado interno, propiciado por la insurrección de los grupos terroristas Sendero Luminoso y el Movimiento Revolucionario Túpac Amaru de inspiración comunista, que pretendían tomar el poder mediante la lucha armada. El terrorismo obtuvo una respuesta represiva de las Fuerzas Armadas, la Policía primero y el Ejército después. Los combates entre ambos bandos provocaron la muerte de cerca de 70 000 personas entre combatientes, campesinos y habitantes de las ciudades.

La crisis entró en su fase más crítica a finales de la década, durante el primer gobierno de Alan García, cuando el país sufrió una fuerte crisis económica debido al descontrol del gasto fiscal y la consiguiente hiperinflación que llegó a un máximo de 7,649 % en 1990, mientras que Sendero Luminoso incursionó en las grandes ciudades del país, iniciando la fase más dura del conflicto armado interno.

El primer gobierno de Alan García terminó en medio de una creciente impopularidad. En las elecciones de 1990, se dio un reñido balotaje entre el escritor liberal Mario Vargas Llosa y Alberto Fujimori, quien ganó la presidencia. Desde el inicio de su mandato encontró una fuerte oposición en el Congreso por parte de la Alianza Popular Revolucionaria Americana y del Frente Democrático. En su primer año, aplicó una política de choque a la cual se había negado durante su campaña electoral, que se hizo conocido como el "fujishock". Eventualmente, implementó una serie de reformas de corte neoliberal, alineándose al Consenso de Washington. Paralelamente, el asesor presidencial Vladimiro Montesinos fue nombrado jefe del Servicio de Inteligencia Nacional del Perú, posición desde la cual dirigió la cleptocracia en la que derivó el gobierno de Fujimori.

La madrugada del 5 de abril de 1992, Fujimori desató una crisis constitucional cuando disolvió el Congreso de la República y restringió la libertad de prensa con apoyo de las fuerzas armadas. Posteriormente, convocó a la Asamblea Constituyente que produjo una nueva constitución política promulgada en el año 1993. Fujimori se mantuvo como presidente tras la promulgación de la constitución y logró ser reelegido en 1995, aunque no consiguió solucionar la larga recesión económica que afectaba al país. El 9 de abril de 2000, tras unas cuestionadas elecciones, Alberto Fujimori logró un tercer mandato. La oposición, conformada por los diversos partidos políticos y organizaciones civiles de diversa índole, intentó evitar la juramentación del tercer periodo presidencial de Fujimori pero no lo logró.

Seis semanas después, el 14 de septiembre, se difundieron filmaciones donde se mostraba claramente el soborno de algunos Congresistas de la oposición y empresarios para que favorezcan al Gobierno, lo que precipitó la caída del régimen. Fujimori abandonó el país solicitando permiso para participar en la cumbre del Foro de Cooperación Económica Asia-Pacífico para luego dirigirse a Japón, país del cual era ciudadano y desde el cual renunció por fax y donde se refugió. El Congreso no aceptó la renuncia y lo destituyó, inhabilitándolo para ejercer todo cargo político por 10 años.

El 22 de noviembre de 2000 el entonces Presidente del Congreso, Valentín Paniagua, fue investido como nuevo Presidente de la República ante la renuncia de los dos vicepresidentes. El gobierno de transición se orientó a la organización de nuevas elecciones y a una profunda campaña de moralización del aparato público y las fuerzas militares que habían caído bajo la influencia del sistema. El Presidente firmó contratos de explotación para los yacimientos de gas de Camisea, y convocó a una polémica Comisión de la Verdad para investigar la lucha contra el terrorismo de los últimos años.

En las elecciones del 8 de abril de 2001, Alejandro Toledo fue declarado como nuevo Presidente de la República. Estas se caracterizan también por el retorno de Alan García y su muy sorpresivo segundo lugar en la contienda electoral. La paradoja del gobierno de Toledo es que gozó de baja popularidad, envuelto en acusaciones de corrupción de la más variada índole, mientras la economía peruana logró superar la recesión y tuvo un gran crecimiento especialmente en la capital, la sierra central y la costa norte. En este período se inició la negociación de un Tratado de Libre Comercio con los Estados Unidos el cual en su momento no era visto con buenos ojos por los campesinos del país porque temían que tuviera un efecto negativo sobre sus economías.

En las elecciones del 9 de abril y 4 de junio de 2006, en medio de un ambiente de incertidumbre por el futuro de la democracia, fue reelegido Presidente Alan García, (con un discurso y perfil más moderado y reivindicador pese a su primer gobierno) frente al exmilitar Ollanta Humala. En las elecciones de 2011, Humala pasó a segunda vuelta junto con Keiko Fujimori, hija del expresidente Alberto Fujimori, preso por delitos de lesa humanidad. Humala ganó en la primera vuelta dejando a Keiko Fujimori en empate técnico ante el economista y candidato liberal, Pedro Pablo Kuczynski. En la segunda vuelta, el nacionalista Ollanta Humala fue elegido Presidente, por un margen de 2 % de ventaja. En las elecciones generales del 2016, el economista Pedro Pablo Kuczynski fue electo Presidente luego de vencer a Keiko Fujimori con un margen muy ajustado.

El 15 de diciembre 2017 el Congreso del Perú admitió un pedido de vacancia presidencial el cual no alcanzó el mínimo de 87 votos necesarios para ser aprobado. Días después Kuczynski le concedió un indulto humanitario y derecho de gracia al expresidente Alberto Fujimori, quien cumplía una condena de 25 años por crímenes contra los derechos humanos. El 20 de marzo de 2018, a dos días de un segundo pedido de vacancia presidencial decidió renunciar a la presidencia, ocupando su lugar el vicepresidente Martín Vizcarra.

El Perú es una república unitaria, representativa, descentralizada, presidencialista con un sistema multipartidista. El gobierno se estructura según el principio de separación de poderes, estos son el poder ejecutivo, el poder legislativo y el poder judicial. Además, la Constitución establece diez organismos denominados «constitucionalmente autónomos», de funciones específicas e independientes de los tres poderes del Estado. Dichos organismos son: el Tribunal Constitucional, el Ministerio Público, la Defensoría del Pueblo, la Contraloría General de la República, el Consejo Nacional de la Magistratura, la Superintendencia de Banca, Seguros y AFP, el Jurado Nacional de Elecciones, la Oficina Nacional de Procesos Electorales, el Registro Nacional de Identificación y Estado Civil y el Banco Central de Reserva. El gobierno peruano es directamente elegido, el voto es obligatorio para todos los ciudadanos entre los 18 y 70 años.

Según la actual constitución, el Presidente de la República es el jefe de estado y el jefe de gobierno, es elegido cada cinco años y no puede cumplir mandatos consecutivos. El Presidente designa al Consejo de Ministros, que está compuesto por los jefes de las carteras sectoriales, y por un Presidente del Consejo, quien podrá ocupar una cartera sectorial o solamente desempeñarse en el cargo presidencial.

El Presidente de la República es el jefe del poder ejecutivo, y no comparte esta prerrogativa con el Presidente del Consejo de Ministros ni ninguna otra autoridad. El Presidente no tiene responsabilidad política sobre sus decisiones de gobierno. En el Jefe de Estado reside exclusivamente la defensa nacional, llevada a cabo por las Fuerzas Armadas. Para coordinar su accionar, el país se halla subdividido en veinticuatro departamentos y una provincia constitucional. El actual jefe de estado y de gobierno es Martín Vizcarra Cornejo.

El Consejo de Ministros es el órgano encargado de la dirección y la gestión de los servicios públicos del Estado. Está presidido por el Presidente del Consejo de Ministros, cargo desingnado por el Presidente del República y está conformado por cada uno de los Ministros de Estado, quienes tienen a su cargo las carteras sectoriales del gobierno. El Presidente del Consejo de Ministros podrá o no tener una cartera a su cargo y su función fundamental es refrendar los actos de los demás ministros y representar al Consejo de Ministros frente al Congreso. Además, es el portavoz oficial del gobierno frente a la sociedad.

En el país, al cargo de Presidente del Consejo de Ministros suele llamársele coloquialmente «Primer Ministro» o «Premier», de manera indistinta, aunque sus funciones difieran claramente de las de un primer ministro, puesto que no tiene capacidad de decisión política en ausencia de la aprobación del Presidente de la República. Las sesiones del Consejo de Ministros también son presididas por el Presidente de la República. Los Ministros de Estado tienen responsabilidad política sobre sus decisiones de gobierno, mientras que el Presidente del Consejo de Ministros tiene responsabilidad sobre cada una de las decisiones de todo el gabinete ministerial. El actual Presidente del Consejo de Ministros es César Villanueva.

El poder legislativo del estado peruano reside en el Congreso de la República, el cual es unicameral y consta de 130 miembros elegidos por un período de cinco años. Los proyectos de ley pueden ser propuestos por el poder ejecutivo o legislativo; se convierten en ley luego de ser aprobadas por el Congreso y promulgadas por el Presidente.

Actualmente el Congreso está compuesto por Fuerza Popular (59 escaños), Peruanos Por el Kambio (15 escaños), Frente Amplio (10 escaños), Nuevo Perú (10 escaños), Alianza para el Progreso (8 escaños), Acción Popular (5 escaños), Partido Aprista (5 escaños) y los No Agrupados (18 escaños). La facultad de interpretar la Constitución en materias específicas reside en el Tribunal Constitucional, que se compone de siete miembros elegidos por el Congreso de la República por un periodo de cinco años también. El actual Presidente del Congreso de la República es Luis Galarreta.

El poder judicial es un organismo autónomo de la República del Perú constituido por una organización jerárquica de instituciones, que ejercen la Jurisdicción, que en teoría emana del pueblo, no obstante no es elegido directa ni indirectamente. Al darse la Independencia, José de San Martín creó la «Cámara de Apelaciones», por decreto del 12 de febrero de 1821, con una jurisdicción que alcanzó los territorios de los actuales departamentos de Cajamarca, Piura, Lambayeque, Amazonas, entonces conocido como Chachapoyas y de Huamachuco, que era como entonces se conocía a la actual provincia de Sánchez Carrión, con sede en la ciudad de Trujillo, con el objetivo de reemplazar a la Real Audiencia.

El poder judicial está encabezado por el presidente Duberlí Rodríguez y por la Corte Suprema de Justicia que tiene competencia en todo el territorio. El segundo nivel jerárquico lo forman las Cortes Superiores de Justicia con competencia en todo un Distrito Judicial. El tercer nivel es formado por los Juzgados de Primera Instancia cuya competencia es, aproximadamente, provincial. Luego, se encuentran los Juzgados de Paz Letrados, con competencia distrital. Y finalmente los Juzgados de Paz (no letrados), encargados de resolver asuntos judiciales sencillos.

La defensa del país está a cargo de las Fuerzas Armadas de la República del Perú, que, según el artículo 165 de la Constitución Nacional, tienen como finalidad primordial garantizar la independencia, la soberanía y la integridad territorial de la República. Las fuerzas armadas se hallan bajo la autoridad del Presidente de la República por medio del Ministerio de Defensa y coordinados por el Comando Conjunto de las Fuerzas Armadas.

El Comando Conjunto tiene subordinados a los Comandos Operacionales y Comandos Especiales, con los cuales realiza las operaciones militares que se requieran para la defensa y el cumplimiento de las tareas que disponga el poder ejecutivo. Las fuerzas armadas están compuestas por la Fuerza Aérea, el Ejército y la Marina de Guerra, siendo los dos últimos los componentes más antiguos de las Fuerzas Armadas.

El Ejército está formado por la Jefatura de Estado Mayor, dos Órganos de Control, dos Órganos de Apoyo, cinco Regiones Militares y seis Comandancias. Hasta el año 2001, contaba con 120 658 miembros, además de 26 570 reservistas. La Fuerza Aérea fue creada oficialmente el 20 de mayo de 1929 con el nombre de Cuerpo de Aviación del Perú. Tiene como función principal la defensa aérea del país, además, participa en campañas de apoyo social a poblaciones de difícil acceso, organiza puentes aéreos en caso de desastres y participa en misiones de paz internacional. Cuenta con cuatro alas aéreas ubicadas en las ciudades de Piura, Callao, Arequipa e Iquitos.

La Marina de Guerra se encarga de la defensa marítima, fluvial y lacustre del país. Está integrada por 26 000 marinos, el personal naval se divide en tres estamentos: personal superior, personal subalterno y personal de marinería. Se considera a la Policía Nacional dentro de las fuerzas armadas aunque en realidad se trata de un organismo distinto con una misión civil diferente, sin embargo, su actuación y preparación en función a más de dos décadas de narcoterrorismo le ha dado en el caso del Perú, un carácter extremadamente militar, con importantes fuerzas de ataque terrestres, acuáticas y aéreas.

El Ministerio de Relaciones Exteriores o Cancillería es el organismo encargado de formular, ejecutar y evaluar la política exterior del país. La Cancillería administra las misiones diplomáticas en otras naciones y representaciones ante organismos multilaterales. La política exterior peruana está basada principalmente en promover la cultura de la paz, la democracia y el desarrollo, respetando los principios y normas del derecho internacional, en un marco de diálogo interinstitucional.

El país tradicionalmente ha tenido fuertes vínculos políticos y culturales con sus países cercanos, así como también con los Estados Unidos, con quien mantiene relaciones diplomáticas desde comienzos del siglo con el nombramiento de Joel Roberts como agente residente para el Virreinato. En 1824 Estados Unidos nombró su primer cónsul en Lima, William Tudor quien se convirtió en el único representante de sus intereses en el territorio peruano hasta 1827.

Otro de las estados con los que el gobierno peruano mantiene fuertes lazos de amistad es Japón. Las relaciones políticas con esta nación se inicieron el 21 de agosto de 1873 con la firma del Tratado de Paz, Amistad, Comercio y Navegación, de esta forma Perú se convirtió en el primer país de América Latina en establecer relaciones diplomáticas con los japoneses. Durante la Segunda Guerra Mundial, el país estuvo del lado de los aliados, le declaró la guerra a Alemania y permitió que los Estados Unidos construyera un aeropuerto en la ciudad de Talara.

Perú es un de la Organización de las Naciones Unidas desde el 31 de octubre de 1945. Ha formado parte de su Consejo de Seguridad en cinco ocasiones: en los periodos 1955-1956, 1973-1974, 1984-1985, 2006-2007, 2018-2019. El abogado y diplomático peruano Javier Pérez de Cuéllar fue Secretario General de las Naciones Unidas entre 1982 y 1991. En el campo de la integración regional, es miembro pleno de la Organización de los Estados Americanos, la Comunidad Andina, la Unasur y estado asociado del Mercosur.

Ha hecho aportes con personal militar, policial u observador para las en Abyei (UNISFA), América Central (ONUCA), Burundi (ONUB), Chipre (UNFICYP), Congo (MONUSCO), Costa de Marfil (UNOCI), El Salvador (ONUSAL), Egipto e Israel (UNEF II), Etiopía y Eritrea (UNMEE), Haití (MINUSTAH), Irán e Irak (UNIIMOG), Líbano (UNOGIL), Liberia (UNMIL), Namibia (UNTAG), República Centroafricana (MINUSCA), Sahara Occidental (MINURSO), Sudán (UNMIS), Sudán del Sur (UNMISS) y Timor Oriental (UNMISET).

Las regiones y los departamentos son las divisiones administrativas mayores del país de acuerdo con la constitución vigente. La división departamental procede desde la Independencia como seguimiento de las intendencias virreinales. El grado de autonomía de las mismas ha sido fluctuante en la historia. En el año 2002, fueron creados veinticinco gobiernos regionales como entes autónomos destinados a administrar los veinticuatro departamentos y la provincia del Callao así como dirigir un proceso de conformación de regiones, a la fecha en su fase inicial; a la vez que se dotó a la provincia de Lima de independencia del gobierno regional de su departamento. Los gobiernos regionales se componen de un gobernador y un consejo, los cuales son electos por votación directa y sirven por un período de cuatro años. Son jurisdicciones con gobierno regional propio los veinticuatro departamentos y la provincia siguientes:

Las (196 provincias al 2015) son los términos municipales del país, dirigidos por ayuntamientos conocidos como Municipalidades Provinciales. Estas, a su vez, se encuentran subdivididas en distritos, los cuales suman 1869, encontrándose dirigidos a su vez por Municipalidades Distritales. La ley permite la conformación de Municipalidades de Centros Poblados, que dirigen el gobierno municipal de una población alejada de la capital del distrito por petición de sus pobladores. A los principales mandos políticos de los gobiernos Municipales, elegidos mediante voto popular cada cuatro años, se les denomina Alcaldes Provinciales o Alcaldes Distritales.

El país se encuentra en la zona intertropical de Sudamérica comprendida entre la Línea del Ecuador y el Trópico de Capricornio. Cubre un área de 1 285 215 km², lo que lo convierte en el en tamaño de la Tierra y el tercero de América del Sur. Limita al norte con Ecuador y Colombia, al este con Brasil, al sureste con Bolivia, al sur con Chile y al oeste con el océano Pacífico. Posee una enorme multiplicidad de paisajes debido a sus condiciones geográficas, lo que a su vez le da una gran diversidad de recursos naturales. La constitución expresa que el mar territorial se extiende hasta las 200 millas náuticas.

El territorio peruano se encuentra determinado por la interacción de dos placas tectónicas: la Sudamericana al este, donde se halla todo su territorio continental, y la de Nazca debajo del océano Pacífico. Ambas comparten un límite convergente de subducción, es decir, la placa de Nazca se desplaza bajo la Sudamericana paralela a la costa occidental sudamericana, a una velocidad promedio de 7-8 cm/año.

Producto de esta subducción, se formó hacia el jurásico la fosa de Perú-Chile así como la elevación de la cordillera de los Andes. La cordillera ha sufrido un importante proceso de erosión eólica y aluvial; a consecuencia de la cual la región andina tiene una superficie bastante escarpada. Al este de la cordillera, se depositaron sedimentos producidos por la erosión andina donde antes se encontraba una vasta porción de mar; allí se formó la actual llanura amazónica.

La cordillera de los Andes divide al país en tres regiones fisiográficas mayores: costa, sierra y selva. La costa peruana es una franja desértica y llana que corre paralela al litoral, su ancho alcanza un máximo de 140 km en el desierto de Sechura. Desde la latitud 6°S hasta la frontera con Chile se extiende el sector peruano del desierto del Pacífico el cual se encuentra atravesado por valles originados por ríos cortos de régimen estacional. A lo largo de la costa se pueden encontrar pampas cubiertas de arena que forman los desiertos del país, tales como el de Sechura (Piura) y el de Pisco (Ica).

La sierra está conformada por un . Estas montañas corren alineadas en cadenas paralelas: tres en el norte, tres en el centro y dos en el sur. Los andes del norte confluyen con los del centro en el nudo de Pasco, mientras que los del centro confluyen con los del sur en el nudo de Vilcanota a la altura del Cuzco. Los andes del norte son más bajos y más húmedos que el promedio, en ellos se encuentra el abra de Porculla, que con 2145 msnm es el punto más bajo de la cordillera andina. Los andes del centro son los más altos y empinados, es aquí donde se encuentra el pico más alto del país, el nevado Huascarán, con 6768 msnm. Los andes del sur son de mayor espesor que los del norte y centro. En este sector se encuentra la meseta del Collao, también conocido como altiplano.

La selva, ubicada hacia el este, es una vasta región llana cubierta por vegetación. Constituye casi el 60 % de la superficie del país. Se aprecian dos regiones distintas: selva alta y selva baja. La selva alta se ubica en todo el flanco oriental de los andes. Su altura varía entre los 800 y 3500 msnm. Abarca desde la zona fronteriza septentrional hasta el extremo sur del país. El relieve de esta zona es variado, al ser la salida de las fuertes pendientes los andes y el ingreso a la región plana y natural de la selva.

La selva baja o bosque tropical amazónico se ubica entre los 80 y los 800 msnm, en esta zona se encuentran los ríos más extensos y navegables como es el caso del Amazonas, que pasa por la ciudad de Iquitos. La forma del relieve es llana y destaca la presencia de la cordillera de Contamana, ubicada en la margen izquierda del río Yavarí. Su punto más alto alcanza los 780 msnm.

El país cuenta con cincuenta y cuatro cuencas hidrográficas, cincuenta y dos de las cuales son pequeñas cuencas costeras que vierten sus aguas al océano Pacífico. Las otras dos son la cuenca del Amazonas, que desemboca en el océano Atlántico, y la cuenca endorreica del lago Titicaca, ambas delimitadas por la cordillera de los Andes. En la segunda de estas cuencas nace también el gigante río Amazonas que, con sus 6872 km, es el río más largo y caudaloso del mundo. Su vertiente ocupa el 75 % del territorio peruano. El Perú contiene el 4 % del agua dulce del planeta.

La mayoría de drenan desde los Andes y hacia una de las tres vertientes hidrográficas del país. Los procedentes de los Andes que desembocan en el océano Pacífico son de corto recorrido, torrentosos y de régimen variable según la intensidad de las lluvias que se producen en la sierra. Las cuencas que desembocan en el Titicaca, para luego seguir su camino en otros ríos y desembocar en un océano, tienen características muy similares a las de la vertiente del Pacífico. Este es el lago más alto del mundo (3808 msnm) y el segundo más extenso de Sudamérica (8300 km² de área total).

Los ríos de la vertiente del Atlántico nacen también en la cordillera de los Andes, hasta llegar al río Amazonas, que a su vez desemboca luego en el océano Atlántico. Son más largos, mucho más caudalosos y su curso tiene una pendiente menor una vez que salen de la sierra. Los ríos más largos del Perú son de la cuenca amazónica: el Ucayali, el Marañón, el Putumayo, el Yavarí, el Huallaga, el Urubamba, el Mantaro y el Amazonas. Los ríos que desembocan en el lago Titicaca son por lo general cortos y tienen gran caudal.

A diferencia de otros países ecuatoriales, el Perú no presenta un clima exclusivamente tropical; la influencia de los Andes y la corriente de Humboldt conceden una gran diversidad climática al territorio peruano. La costa central y sur del país presentan un clima subtropical árido o desértico, con una temperatura promedio de 18 °C y precipitaciones anuales de 150 mm, por acción del mar frío de Humboldt. En cambio, la costa norte posee un clima árido tropical, debido al mar tropical, con una temperatura promedio por encima de los 24 °C y lluvias durante el verano. Cuando hay ocurrencia del fenómeno de El Niño, la temperatura promedio de toda la costa se eleva (con máximas mayores a 30 °C) y las lluvias se incrementan de manera significativa en la costa norte y central.

En la sierra se observan los siguientes climas: clima templado sub-húmedo, en áreas entre los 1000 y los 3000 msnm, con temperaturas alrededor de los 20 °C y precipitaciones entre los 500 y 1200 mm al año; clima frío entre los 3000 y 4000 msnm, con temperaturas anuales promedio de 12 °C y heladas durante el invierno; clima frígido o de puna, en áreas entre los 4000 y 5000 msnm, con una temperatura promedio de 6 °C y precipitaciones anuales de 700 mm; y clima de nieve o gélido en zonas por encima de los 5000 msnm, con temperaturas debajo de los 0 °C y nevadas. En la selva hay dos tipos de clima: clima semitropical muy húmedo en la selva alta, con precipitaciones mayores a los 2000 mm al año y temperaturas promedio alrededor de los 22 °C; y el clima tropical húmedo en la selva baja, con precipitaciones que oscilan los 2000 mm al año y temperaturas promedio de 27 °C.
Los antiguos habitantes de los Andes ya poseían un conocimiento geográfico importante sobre el suelo que habitaban. Este conocimiento se dio gracias a la interacción que experimentaron con su medio en el proceso de producción de sus medios de existencia. Estos hombres llegaron a identificar diversos pisos ecológicos a los cuales les dieron distintos nombres. Con la llegada de los españoles a territorio americano, a la división hecha por los antiguos pobladores andinos se impuso una nueva en la que se dividía el territorio peruano en tres grandes regiones: costa, sierra y selva.

En las primeras décadas del siglo , se volvió a plantear la existencia de diversas regiones altitudinales al interior del país, criticando la división simplista dada por los conquistadores españoles. Posteriormente gracias al esfuerzo de diferentes estudiosos nacionales y extranjeros como: Pedro Paulet, José de la Riva Agüero, entre otros, se fueron acumulando estudios geográficos modernos sobre el Perú. Estos estudios fueron sintetizados y expuestos años más tarde en la tesis sobre las "Ocho Regiones Naturales del Perú" (1943) postulada por Javier Pulgar Vidal. De acuerdo con Vidal, las regiones naturales del país son las siguientes, de oeste a este: Chala, Yunga, Quechua, Suni, Puna, Janca, Rupa-Rupa y Omagua.

El accidentado relieve y particular historia natural del Perú ha causado que éste sea considerado uno de los diecisiete países megadiversos, con una gran variedad de ecosistemas y, consecuentemente, de flora y fauna. El país presenta en su territorio seis biomas terrestres diferentes, dos biomas marinos y tres biomas de agua dulce. A lo largo de la mayor parte de la costa se extiende el desierto del Pacífico, mientras que en la costa norte y valles interandinos del río Marañón y algunos afluentes, se extiende el bosque seco ecuatorial, un tipo de ecosistema similar a una sabana tropical que proviene de la convergencia de afluentes amazónicos, andinos y del bosque tropical del Pacífico.

En las desembocaduras de los ríos Tumbes y Piura se extienden los manglares y subiendo a los Andes se extiende el bioma de matorral montano. Según el Fondo Mundial para la Naturaleza, los ecosistemas correspondientes son la puna seca, la puna húmeda y el páramo. El bioma más extendido del país (59 % del territorio) así como el más biodiverso se encuentra al oriente: la selva amazónica peruana. Ésta se subdivide en selva baja y selva alta. Los ecosistemas que en esta región destacan son bosque de neblina (al norte de los departamentos de Piura y Cajamarca) y una pequeña porción de sabana de palmeras en el extremo oriental del país, en el departamento de Madre de Dios. En cuanto al mar peruano, dos corrientes marinas que discurren en sentido contrario caracterizan sendos ecosistemas.

De la latitud 6° S hacia el norte se presenta la corriente de El Niño con una temperatura que oscila entre los 22 °C y 27 °C. Esta choca con la corriente peruana o de Humboldt con temperaturas que oscilan entre los 13 °C y 19 °C. Aunque las dos corrientes brindan recursos innumerables, es la corriente de Humboldt la de mayor importancia debido a que ella presenta abundancia de plancton y se encuentra en la zona de amplitud del zócalo continental, la cual favorece a una mayor productividad y cantidad de recursos marinos, tal es el caso de la anchoveta y la consecuente producción masiva de harina de pescado. La flor nacional es la cantuta y el árbol más representativo del país es el árbol de la quina. En cuanto a fauna, las especies más emblemáticas son la vicuña y el gallito de las rocas.

En los últimos años la economía peruana ha tenido un nivel de crecimiento notable respecto a otras economías del mundo, solo comparable al de China. Según la revista AméricaEconomía y el Fondo Monetario Internacional, el país tuvo en el año 2008 la segunda inflación más baja del mundo después de Francia y por lo tanto una de las economías en este sentido más sólidas de la región. Tiene un índice de desarrollo humano alto, con una puntuación de 0,740 en 2015 que lo ubica en el .

De acuerdo con estimaciones del FMI la renta per cápita se encuentra por encima de los 12 000 dólares, ocupando el . La Comisión Económica para América Latina y el Caribe estimó que en el año 2012 la economía peruana crecería un 5,9 %, aunque su enorme dependencia de la exportación de metales y minerales y la importación de alimentos hace que la economía sea muy dependiente de la fluctuación de los precios a nivel global.

Para los próximos años está previsto un menor crecimiento así como riesgos inflacionarios debido a la posible devaluación de los precios de las materias primas dada la evolución de la crísis en los países desarrollados, cuyo menor crecimiento podría afectar negativamente a las economías de países —como Perú— que abastecen con materia prima a sus industrias, incluso contando con China como primer socio comercial. En marzo de 2018 se estableció el en S/ 930.00, el equivalente a US$ 290.00 aproximadamente. Es el cuarto mejor país emergente más prometedor para los inversores, según el ranking elaborado por la revista Bloomberg Markets. La inflación en el año 2014 fue la más más baja de la región con un 3,22 %.

Según el directorio ejecutivo del Fondo Monetario Internacional el país se ha convertido en una de las economías de crecimiento más pujante y más estables de América Latina. El 23 de octubre de 2013, la entidad calificadora de riesgos Fitch Group elevó la calificación de crédito del Perú al nivel de BBB+. En julio de 2014, la agencia Moody's también elevó la calificación crediticia del país de Baa2 a A3 debido a las expectativas del crecimiento de la economía, el fortalecimiento de su desempeño fiscal y su potencial de expansión.

Acuerdos comerciales del Perú.
La agricultura ha sido la actividad económica tradicional del Perú prehispánico, donde se cultivó de forma intensa productos como el maíz y la papa. Los pobladores prehispánicos se adaptaron a las condiciones del ambiente y debido a carencia de espacios abiertos se crearon sistemas de terrazas (andenes) convirtiendo las limitaciones de la pendiente en ventajas en el uso del espacio. También se domesticaron animales como la alpaca, la llama y el cuy. Esta actividad respondía a una visión teocrática, panteísta y premoderna del mundo, donde el trabajo colectivo realizado por las familias (aillu) permitió el desarrollo de las actividades agropecuarias como base de la economía andina. Los principales productos agrícolas peruanos son: papa, arroz, maíz, camote, maca, trigo, quinua, café, así como también las frutas: manzana, pera, uva, durazno, plátano y las verduras: habas, cebollas, tomate, ajos.

Luego de más de veinte años de haber sido descubierto, el yacimiento de gas natural ubicado en Camisea, departamento del Cuzco, empezó a ser explotado y su producción está por ahora destinada principalmente al consumo interno y a la sierra peruana; y el excedente es vendido al exterior. Este gas de Camisea llegó a Lima en agosto de 2004. La explotación gasífera, junto con la minería, son los sectores con mayor potencial de inversiones por la calidad y abundancia de recursos.

El país tiene una expectante posición competitiva en la minería mundial, manteniendo el liderazgo minero en Latinoamérica y una sólida historia y trayectoria minera. En el mercado latinoamericano, es el mayor productor de oro, cinc, plomo y estaño; registrando una producción anual de 164 toneladas métricas y reservas estimadas en 2 762 000 toneladas. Asimismo, es el segundo productor de plata y de cobre, además de producir otros importantes productos metálicos y no metálicos.

La mina de Yanacocha es la principal fuente de extracción de oro en el Perú. Es considerada la mayor mina aurífera de Sudamérica y la segunda más grande a nivel mundial. En el año 2005 se produjeron 3 333 088 onzas del preciado metal. Un indicador del crecimiento minero, lo podemos observar en las exportaciones mineras, habiendo crecido de US$ 1447 millones de 1990 a US$ 3600 millones en el año 2002.

La explotación de los recursos marinos como anchoveta, corvina, lenguado, bonito, perico y jurel es vital para la economía peruana. De la anchoveta, por ejemplo, se hace la harina de pescado, de la cual el país es el mayor productor mundial. Gran parte de lo producido se destina para el mercado interno, en especial de las zonas costeras.

El Perú se situaba en 2011, en agroindustria, como el primer productor mundial de harina de pescado, segundo productor mundial de espárragos, séptimo productor mundial de maíz, cuarto productor mundial de alcachofas, sexto productor mundial de café; en minería como el tercer productor mundial de plata, de cobre y de cinc, cuarto productor mundial de plomo y de estaño, quinto productor mundial de oro, además de contar con grandes yacimientos de hierro, estaño, manganeso; además de petróleo y gas natural.

Es además, el primer productor mundial de lana de alpaca, y el más importante exportador de prendas textiles de algodón en América Latina y por su riqueza natural es un excelente lugar para el desarrollo de la industria de los polímeros a nivel mundial. El país se encuentra en una etapa de crecimiento económico y se espera a la luz de los acuerdos y tratados firmados en áreas de libre comercio, se constituya como una de las naciones de Sudamérica más atractivas para desarrollar negocios.

Una de las actividades económicas más recientes y de gran potencial es la explotación de los recursos forestales (cedro, roble y caoba, principalmente) que aporta una gran cantidad de ingresos para la población de la selva. Se espera que la deforestación sea controlada y con grandes inversiones en reforestación. El Instituto Nacional de Recursos Naturales (organismo del Estado Peruano), es el encargado de dar las normas necesarias y controlar dichos proyectos generando importantes fuentes de divisas para el país.

En cuanto al desarrollo industrial se puede mencionar una gran variedad de empresas dedicadas al consumo interno y a la exportación. Hoy en día el país produce y exporta carrocerías para buses de dos pisos, maquinaria para la minería, grupos electrógenos, equipos de bombeo, tuberías, herramientas y diferentes productos metalmecánicos. También productos químicos como ácidos y detergentes, productos plásticos, productos textiles, productos de papel y de cuero, productos agro-industriales y alimenticios. La gran riqueza de recursos mineros (es un país polimetálico), recursos vegetales (inmensa variedad de plantas debido a su rica biodiversidad) y recursos animales (ganadería, pesquería), hace que el Perú tenga un gran potencial para la industrialización extensiva en un futuro muy cercano.

Los principales productos que Perú exportaba en el periodo de 1880-1914 eran el azúcar, que venía a representar un 30 % aproximadamente del total de productos exportados; la plata, representando un 18 %; el cobre 20 % y por último, el algodón con un 26 %. El país dependía alrededor del 50 % de las exportaciones. Es a partir de 1920 cuando se comenzó a exportar petróleo. Según el Ministerio de Comercio Exterior y Turismo, en el año 2008, las exportaciones crecieron un 11,2 %, comercializándose más de 5000 productos diferentes, alcanzándose el monto de 31,236 millones de dólares.

Se estima que el 62,1 % de las exportaciones corresponden al sector minero. Las principales exportaciones son el cobre, oro, cinc, textiles y productos pesqueros; sus principales socios comerciales son Estados Unidos, China, Brasil y Chile. Los principales destinos de exportación de productos tradicionales y no tradicionales entre enero y septiembre de 2011, fueron en orden de importancia por importadores, China, Estados Unidos, Suiza, Canadá, Japón, Chile, Alemania, Corea del Sur, España e Italia. El ritmo de crecimiento de las exportaciones no tradicionales con valor agregado fue del 32 % en 2011 en comparación con el año anterior.

En los últimos años, se ha observado un proceso de industrialización de los productos agrícolas (agroindustria) y de diversificación de exportaciones. El número de empresas exportadoras para el año 2011 se incrementó a 8200. Según la revista The Economist, es el sexto país con mayor crecimiento económico en el mundo, y según el Banco Mundial el quinto país con el mayor crecimiento exportador. En el período 2006-2012 el número de empresas exportadoras se incrementó de 6505 a 8135 lo que representó un crecimiento del 25 %. Sin embargo durante el año 2012 en medio de un enfriamiento económico 2465 empresas dejaron de registrar envíos, y las exportaciones cayeron un 2 % respecto al año 2011. Según Juan Varilias, expresidente de la Asociación de Exportadores cada año 2500 empresas exportadoras abandonan el mercado debido a la falta de una política adecuada para el sector y a problemas con la infraestructura del país.

Durante el año 2012, la entrada de inversión extranjera en el país registró una tasa de crecimiento elevada, con una variación del 49 % respecto al año anterior. Con un ingreso de inversión extranjera de 12 240 millones de dólares. equivalente al 5,9 % de su PIB el país se constituyó como el quinto receptor en América Latina, después de Brasil, Chile, Colombia y México. Replicando el patrón de los últimos años, la reinversión de utilidades (8263 millones de dólares) fue el componente predominante de la inversión en 2012, seguido por aportes de capital (4637 millones de dólares), mientras que el flujo de préstamos de las casas matrices fue levemente negativo.

La elevada rentabilidad de la inversión extranjera de empresas en el Perú, principalmente en la minería, explica estos procesos en que una parte considerable de la ampliación de la capacidad productiva se financia reinvirtiendo utilidades. No hay datos oficiales sobre la distribución de la inversión por sectores de destino, sin embargo, varias informaciones permiten estimar que el sector minero sería el principal receptor, seguido por la ampliación de la infraestructura eléctrica y de comunicaciones y el sector financiero. Según el Ministerio de Energía y Minas, las inversiones en el sector, la gran mayoría relacionadas con empresas extranjeras, habrían alcanzado los 8549 millones de dólares en 2012.

Hasta junio de 2017, las reservas internacionales netas del Perú alcanzaban los 63 256 millones de dólares. En cuanto a las reservas oficiales de oro, hasta el año 2010 el país ocupaba el sexto lugar en América Latina y el puesto 53.º en el mundo, con 34,7 toneladas, el equivalente al 4 % de sus reservas internacionales.

El turismo constituye la tercera industria más grande de la nación, detrás de la pesca y la minería. El turismo se dirige mayoritariamente hacia los monumentos arqueológicos, pues cuenta con más de cien mil sitios arqueológicos. De acuerdo con un estudio del gobierno peruano, el índice de satisfacción de los turistas después de visitar el Perú es del 94 %. Es la industria de más rápido crecimiento en el país, creció anualmente a un ritmo del 25 % en los últimos cinco años, siendo la tasa de crecimiento más alto que cualquier otro país en América del Sur.

El turismo tiene un impacto del 7 % del PBI del Perú, es regulado y estimulado por la Comisión de Promoción del Perú para la Exportación y el Turismo del Ministerio de Comercio Exterior y Turismo. Los países más populares de origen de los turistas son Chile, Estados Unidos, Ecuador, Colombia, Costa Rica, Bolivia, México, Venezuela, Reino Unido y China. El turismo emplea al 11 % de la población económicamente activa del país (484 000 empleos directos y 340 000 indirectos), la mayor parte en hostelería y en el transporte.

Los lugares más visitados por los turistas son las ciudades de Lima y su centro histórico, Cuzco que se caracteriza por su arquitectura incaica y colonial pero sus principales atractivos son el Valle Sagrado de los Incas y Machu Picchu, Arequipa por el centro histórico, también por el Valle del Colca y finalmente Puno por el lago Titicaca. El principal circuito turístico del país es el circuito sur, que engloba ciudades como; Ica, Nazca, Paracas, Arequipa, Chivay, Puno, Cuzco, Ayacucho y Puerto Maldonado, con atractivos arquitectónicos, culturales y naturales. La segunda ruta en importancia es la del Callejón de Huaylas, en el departamento de Áncash, sede del turismo de aventura y principal punto de referencia de la cocina novoandina.

Perú tiene muchas otras rutas turísticas. Entre éstas se encuentran las del valle del río Mantaro, con la ciudad de Huancayo como uno de sus ejes, y el Valle de Tarma como otro eje que a su vez es la entrada a la selva central. La costa central sur (departamento de Ica y provincia de Cañete) y la ciudad norteña de Trujillo donde se encuentra Chan Chan la ciudadela de adobe más grande del mundo, el tradicional balneario de Huanchaco y las Huacas del Sol y de la Luna pertenecientes a la cultura Chimú. Según el Ministerio de Comercio Exterior y Turismo la visita de turistas extranjeros aumentó en 7 % durante el año 2015 y habría generado US$ 3500 millones en divisas para el país.

La red vial del Perú está compuesta por más de 140 000 km de carreteras, organizada en tres grandes grupos: las carreteras longitudinales, las carreteras de penetración y las carreteras de enlace. Conectan a todas las capitales de departamento y la mayoría de las capitales de provincia, permitiendo que cualquier ciudadano se pueda movilizar con su vehículo a los principales centros urbanos del país, adonde llegan también un gran número de líneas de buses interprovinciales.

El transporte ferrioviario es limitado y básicamente utilizado para transportar minerales que se trasladan desde los centros de producción hasta los centros de exportación ubicados en diferentes puertos. En la ciudad de Lima se encuentra una antigua estación de ferrocarril llamada Estación de Desamparados. Su uso es exclusivamente administrativo, aunque eventualmente ofrece servicios de carga y transporte de pasajeros desde Lima hacia la sierra central. Asimismo, desde el 2010, el transporte ferroviario metropolitano de pasajeros viene tomando una gran relevancia con la construcción del Metro de Lima el cual cuenta con una línea completada y una segunda en plena etapa de construcción, se tiene planificada la construcción de una red de seis líneas.

El transporte aéreo se encuentra bien desarrollado y sirve a las veintiún ciudades más importantes con vuelos regulares en aviones de diferente tamaño. Algunas poblaciones alejadas, especialmente de la selva cuentan con aeródromos para la recepción de avionetas. El Aeropuerto Internacional Jorge Chávez es el principal terminal aéreo del país. Está ubicado en la provincia constitucional del Callao. Es el aeropuerto más importante, pues concentra la gran mayoría de vuelos internacionales y nacionales del país, sirviendo a más de 19 000 000 pasajeros por año.

Además del Aeropuerto Jorge Chávez hay otros once terminales aéreos funcionando como internacionales: el Aeropuerto Rodríguez Ballón en Arequipa, el Aeropuerto José A. Quiñones en Chiclayo, el Aeropuerto Alejandro Velasco Astete en Cuzco, el Aeropuerto Francisco Secada Vignetta en Iquitos, el Aeropuerto Inca Manco Cápac en Juliaca, el Aeropuerto Guillermo Concha Iberico en Piura, el Aeropuerto David Abensur Rengifo en Pucallpa, el Aeropuerto Padre Aldamiz en Puerto Maldonado, el Aeropuerto Carlos Ciriani Santa Rosa en Tacna, el Aeropuerto Víctor Montes Arias en Talara y el Aeropuerto Carlos Martínez de Pinillos en Trujillo.

En el país existen varios puertos localizados a lo largo de sus 3070,5 km de costa en el océano Pacífico, en el lago Titicaca y en la cuenca amazónica que por naturaleza propia cuenta con ríos navegables que hacen posible el transporte fluvial de carga y pasajeros. Los puertos del país se clasifican según el tipo de categoría: los puertos mayores utilizados para el comercio nacional e internacional, los puertos menores que se utilizan solo para exportar y la caleta que es el lugar habilitado u ocasional de embarque y desembarque de mercadería. El Callao es el principal puerto marítimo del país. Concentra el 90 % del transporte marítimo tanto mercante como militar ya que en su territorio se extiende el terminal marítimo y la Base Naval de la Marina de Guerra del Perú.

Si bien el transporte civil marítimo no ofrece servicios comerciales con regularidad, varios cruceros anclan en el Callao periódicamente. En Lima también se encuentra un pequeño puerto en el distrito de Lurín cuyo tránsito sobre todo se debe a los barcos petroleros de la refinería de Conchán que se encuentra cerca. Otros principales puertos marítimos son: Paita, Salaverry, Chimbote, San Martín, Matarani e Ilo.

En el país la libertad de expresión y la libertad de prensa están amparadas por la Constitución Nacional. Según un estudio realizado en 2017 por la organización Reporteros Sin Fronteras, Perú es el octavo país de América Latina con la mayor libertad de prensa. Las comunicaciones del país se encuentran reguladas dentro de las funciones del Ministerio de Transportes y Comunicaciones. Los medios de comunicación masiva más utilizados son la prensa escrita, la radio y la televisión.

El primer diario peruano fue la "Gaceta de Lima", que circuló por primera vez en el año de 1715. El "Diario Oficial El Peruano", fundado el 22 de octubre de 1825 por Simón Bolívar es actualmente el diario de circulación más antiguo del país y de América. Lima es sede de los principales y mayores diarios de circulación nacional, entre los que destacan: "Depor", "Diario Correo", "El Comercio", "El Bocón", "Expreso", "La Razón", "La República", "Líbero", "Perú.21", "Todo Sport" y "Trome".

La primera emisora de radio del país se llamó OAX, fue inaugurada el 20 de junio de 1925 por el entonces presidente Augusto Leguía. Desde la capital peruana emiten varias emisoras de tipo AM y FM con alcance local, nacional e internacional. De acuerdo con una encuesta realizada por la Compañía Peruana de Estudios de Mercado y Opinión Pública S. A. C. en 2017, las emisoras de radio con mayor audiencia a nivel nacional son: Radio Programas del Perú, Moda, Karibeña, Ritmo Romántica, La Zona, Onda Cero, Panamericana, Nueva Q, La Kalle y Radio Felicidad.

En 1939 se realizó la primera demostración experimental de televisión en el país al transmitirse una película y un programa artístico desde el Colegio Nacional Nuestra Señora de Guadalupe. Luego se realizó otra prueba, esta vez desde el Gran Hotel Bolívar el 28 de mayo de 1954. Finalmente el 17 de enero de 1958, inició sus emisiones el canal estatal, con la transmisión de un documental técnico. Los canales de televisión nacionales más importantes son: América Televisión, ATV, La Tele, Latina Televisión, NexTV, Panamericana Televisión, RBC Televisión y TV Perú.

La entidad estatal encargada de regular y supervisar el mercado de servicios públicos de telecomunicaciones en el país es el Organismo Supervisor de Inversión Privada en Telecomunicaciones (OSIPTEL). Perú cuenta con un sistema de telecomunicaciones que cubre la mayor parte de su territorio. Hasta septiembre de 2017 existían 3 101 053 líneas de telefonía fija y 38 023 587 abonados a telefonía móvil. El código de dominio de nivel superior geográfico en internet es .pe; el cual es administrado por la Red Científica Peruana desde 1991. Existen más de 102 500 páginas web registradas con dominio peruano. De acuerdo con el Informe Técnico de Estadísticas de las Tecnologías de Información y Comunicación en los Hogares realizado por el Instituto Nacional de Estadística e Informática durante el primer trimestre de 2017, el 38,4 % de los hogares del país poseen al menos una computadora y el 33,1 % tiene acceso a internet. El informe también señala que el 51,7 % de la población de 6 y más años de edad hace uso de internet.

El sector eléctrico ha experimentado notables mejoras en los últimos años. La cantidad de hogares con alumbrado eléctrico creció del 82 % en 2007 al 94,2 % en 2016, a la vez que mejoró la calidad y la eficacia de la prestación del servicio. La capacidad actual de generación de electricidad está dividida de manera uniforme entre las fuentes de energía térmica y energía hidroeléctrica. El Sistema Eléctrico Interconectado Nacional abastece al 85 % de la población conectada, con varios sistemas aislados que cubren el resto del país.

Hasta el año 2015, Perú tenía una capacidad instalada de 12 251 MW, de la cual el 63 % correspondía a la generación térmica, el 34 % a la generación hidroeléctrica y un 3 % de otras fuentes de energía renovable. La instalación hidroeléctrica más grande del país es la del complejo del Mantaro con una potencia nominal de 1008 MW, operada por la compañía estatal Electroperú. Según el Ministerio de Energía y Minas del Perú entre los años 2004 y 2014, la producción de electricidad pasó de 6016 GWh a 11 284 GWh, con lo cual acumuló un aumento de 88 % y un promedio anual de 6,5 %.

Con una población de 31 826 018 habitantes según estimaciones y proyecciones del Instituto Nacional de Estadística e Informática hasta el año 2017, el Perú es el quinto país más poblado de Sudamérica. Su densidad poblacional es de 24,76 habitantes por km² y su tasa de crecimiento anual es de 1,07 %. El 55,9 % de la población peruana vive en la costa, el 29,6 % en la sierra, y el 14,5 % en la selva.

La población económicamente activa equivale al 53,11 % del total de la población, es decir 16 903 700 habitantes. Las mayores ciudades se encuentran en la costa, como Sullana, Piura, Chiclayo, Trujillo, Chimbote, Lima e Ica. En la sierra destacan las ciudades de Arequipa, Cusco, Huancayo, Cajamarca y Juliaca. Finalmente, en la selva es Iquitos la más importante, seguida de Pucallpa, Tarapoto, Moyobamba y Tingo María.

Las áreas metropolitanas se han formado a partir del crecimiento urbano de las ciudades peruanas más pobladas y están formadas por la integración de dos o más municipios. Por Ley 27795 de Demarcación y Organización Territorial, se consideran metrópolis peruanas a las ciudades que comprenden a más de 500 001 habitantes y cuentan con Plan de Acondicionamiento y Plan de Desarrollo Metropolitano, estas son: Lima-Callao, Trujillo, Arequipa, y Chiclayo.

El Perú es una nación multiétnica formada por la combinación de diferentes grupos a lo largo de cinco siglos. En la actualidad se observa una relativa mayoría mestiza, seguida de un importante porcentaje de amerindios. Las poblaciones indígenas habitaron el territorio peruano por varios milenios antes de la conquista española en el siglo ; principalmente debido a enfermedades infecciosas su población disminuyó de un estimado de 9 millones en la década de 1520 a alrededor de 600 000 en 1620.

Durante el virreinato, españoles y africanos llegaron en gran número, mezclándose ampliamente entre ellos y con la población nativa, principalmente en la costa (la sierra y la selva mantuvieron una mayoría indígena muy poco mestizada). Después de la independencia hubo una gradual inmigración europea desde España, Italia, Inglaterra, Francia, los Balcanes y Alemania. Los chinos llegaron en la década de 1850 como reemplazo de los trabajadores esclavos y desde entonces han pasado a ser una importante influencia en la sociedad peruana. Otros grupos de inmigrantes incluyen árabes y japoneses.

En la actualidad se observa que coexisten un conjunto de minorías étnicas, en primer término lo conforma el segmento amerindio con un 45 %; principalmente de la etnia quechua; luego el segmento mestizo con alrededor del 37 % fundamentalmente descendientes de la mezcla de sangre española y quechua; seguidamente la población blanca con 15 %; y la población negra junto con el segmento asiático de origen chino y japonés con el 3 %. En las distintas etapas de la historia del Perú la composición étnica ha ido variando, observándose un continuo retroceso de la proporción amerindia debido a múltiples factores socio económicos, socio culturales, controles de natalidad, alta tasas de mortandad, exclusión, entre otros. El país tiende a un mestizaje generalizado lento de todos los segmentos étnicos iniciado desde los inicios de la etapa colonial hasta nuestros días.

Al respecto de estudios científicos para determinar el perfil genético peruano, se obtienen los siguientes aportes étnicos, lo cual entrega un panorama de la composición del individuo peruano:

En las últimas décadas las cifras de emigración peruana han mostrado un marcado crecimiento y actualmente más del 10 % de los peruanos se encuentra residiendo fuera del país. Este movimiento migratorio se ha visto acentuado a partir del año 2000, la cifra oficial de emigrantes peruanos es de 2 444 634 desde 1990 hasta el año 2011, esto sin considerar a la población descendiente, y a la población flotante ilegal que esencialmente se encuentra en países limítrofes. Se estima que en los últimos 82 años, más de 3,5 millones de peruanos emigraron del país. Con respecto a los principales países de destino de los emigrantes peruanos entre 1990 y 2011, estos fueron: Estados Unidos (31,5 %), España (16 %), Argentina (14,3 %), Italia (10,1 %), Chile (8,8 %), Japón (4,1 %) y Venezuela (3,8 %). El 75 % de emigrantes peruanos tiene entre 19 y 49 años, con una ligera mayoría de mujeres. En su mayor parte, la emigración peruana es una migración de carácter laboral.

El panorama lingüístico del Perú es bastante complejo. Se estima que, a inicios del siglo , en el país se habla un conjunto grande y heterogéneo de una cincuentena de lenguas vernáculas. La gran mayoría de estas lenguas son indígenas, aunque la lengua más extendida es el español, la lengua materna del 83,9 % de los habitantes. Este idioma coexiste con varias lenguas nativas, de las cuales la más importante es el quechua, hablada por el 13,2 % de la población, el 1,8 % aimara y el 0,9 % habla otra lengua nativa. En las zonas urbanas del país, especialmente en la región costera, predomina el monolingüismo del español; mientras que en muchas zonas rurales del país, particularmente en la amazonía, dominan las poblaciones multilingües.

Según Peter Landerman los jesuitas tradujeron fragmentos del canon cristiano a unas ciento cincuenta lenguas indígenas de la amazonía peruana, de las cuales en la actualidad sobreviven solo unas sesenta. Las lenguas nativas se hablan, sobre todo, en los andes centrales y en la selva amazónica. Un número considerable de las lenguas andinas septentrionales se hablaban en la costa norte y los andes septentrionales, pero se extinguieron durante el siglo . Las únicas lenguas nativas andinas en actual uso son el quechua, el aimara, el jacaru y el cauqui; mientras que la región amazónica alberga una mayor variedad de lenguas, siendo las más habladas el asháninca y el aguaruna.

La llegada de los conquistadores españoles al Perú significó la introducción de la religión católica en esta zona poblada de aborígenes de diversas etnias, los cuales seguían religiones animistas y politeístas, lo que produjo un sincretismo religioso. Mediante un proceso largo de adoctrinamiento y prácticas entre los pobladores prehispánicos, los frailes españoles hicieron de la evangelización su tarea más importante. La ciudad de Lima, capital del Virreinato del Perú, se convirtió en el siglo en una ciudad de vida monástica donde surgieron santos como Rosa de Lima (patrona de los católicos en Lima, en la Policía Nacional del Perú, en la República del Perú, en el continente americano y en las Filipinas) y Martín de Porres.

La capital peruana es sede de la Arquidiócesis de Lima, la cual fue establecida en 1541 como Diócesis y en 1547 como Arquidiócesis. Es una de las más antiguas de América. Actualmente la Arquidiócesis de Lima está a cargo del cardenal Juan Luis Cipriani. En el país la religión mayoritaria es el catolicismo. Según el XI Censo Nacional de Población y VI de Vivienda, el 81,3 % de los ciudadanos mayores de doce años declaró ser católico, mientras que el 12,5 % profesa la religión evangélica, el 3,3 % pertenecen a otras religiones y el 2,9 % no especifican ninguna afiliación religiosa.

Una de las manifestaciones religiosas católicas más prominentes es la procesión del Señor de los Milagros, cuya imagen que data de la época virreinal sale en procesión por las calles de Lima en el mes de octubre de cada año. Esta imagen recibió homenajes del Papa Juan Pablo II (quien la llamó la "cuaresma limeña") y del Papa Benedicto XVI, es también considerada por L'Osservatore Romano desde 1993, como la manifestación de fe más multitudinaria que hay en el mundo. El Señor de Los Milagros fue nombrado Patrón de la ciudad por el Cabildo de Lima en 1715 y Patrono del Perú en 2010. En el país como en el resto de América Latina hay además una gran cantidad de devociones a la cruz así como muchas advocaciones marianas como la Virgen de Chapi, la Virgen de Candelaria, la Virgen del Carmen, la Virgen de la Puerta, entre otras. El Perú cuenta con cuarenta y cinco jurisdicciones eclesiásticas, entre ellas, siete arquidiócesis.

En el país los ciudadanos cuentan con un sistema de salud mixto (público y privado). El Ministerio de Salud es el responsable de proteger la dignidad personal, promover la salud, prevenir las enfermedades y garantizar la atención integral de todos los habitantes, mientras que el Instituto Nacional de Salud se encarga de la investigación, desarrollo y transferencia tecnológica. El porcentaje del gasto en salud correspondiente al PBI fue de un 5,1 % en 2010. De acuerdo con un informe realizado por la Organización Mundial de la Salud en el año 2000, el sistema médico peruano se ubicaba en el puesto 115 a nivel mundial.

Según la Organización Panamericana de la Salud la esperanza de vida para los hombres es de 71,7 años, mientras que para las mujeres es de 75,1 años. La mortalidad infantil es de dieciocho por cada mil nacimientos, habiéndose reducido 76 % desde el año 1990 a 2011. Las principales causas de muerte de los peruanos son la neoplasia, la influenza y la neumonía, las , las enfermedades isquémicas del corazón y las enfermedades cerebrovasculares. Según los Censos de Población y Vivienda de 2007, el 42,3 % de la población cuenta con algún tipo de seguro de salud, es decir, 11 598 698 personas, a pesar de eso el 57,7 % de la población no cuenta con ningún tipo de seguro.

Los resultados obtenidos en los censos también señalan que hombres y mujeres acceden casi con el mismo porcentaje a un seguro de salud. Así, el 42,1 % de los hombres, es decir, 5 732 970, y el 42,5 % de las mujeres, que equivale a 5 865 728 personas cuentan con algún seguro de salud. En cuanto al tipo de seguro al cual se encuentra afiliada la población, del total de personas que manifestaron poseer algún seguro de salud, el 18,4 % están protegidas por el Seguro Integral de Salud, el 17,4 % acceden únicamente al seguro social EsSalud, mientras que el 5,9 % se encuentra afiliada a compañías privadas de seguros.

En el Perú, la educación está bajo la jurisdicción del Ministerio de Educación, el cual está a cargo de formular, implementar y supervisar la política nacional de educación. De acuerdo a la Constitución Política del Perú, la educación es obligatoria y gratuita en las escuelas públicas para los niveles de inicial, primaria y secundaria. Es también gratuita en las universidades públicas para los estudiantes que tengan un satisfactorio rendimiento académico y superen los exámenes de admisión.

La educación se divide en diferentes niveles: La educación inicial, corresponde al período entre los cero y los cinco años de edad, y está a cargo de las cunas que tienen la finalidad de brindar a los niños las estimulaciones requeridas para su desarrollo integral y los jardines que ofrecen actividades técnico-pedagógicas. La educación primaria se inicia con el primer ciclo, conformado por el primer y segundo grado. La edad de ingreso para los niños es de seis años. Este nivel empieza en el primer grado y termina en el sexto grado de primaria.

La educación secundaria consta de cinco años, de primero al quinto año. Luego viene la educación superior que puede ser técnico productiva, tecnológica o universitaria. Para ingresar a las universidades es indispensable dar un examen de admisión, aunque la dificultad de éste depende de la exigencia de la universidad. La primera universidad del país es la Universidad Nacional Mayor de San Marcos, la más antigua del continente americano, fundada el 12 de mayo de 1551; le siguen en antigüedad la Universidad Nacional de San Cristóbal de Huamanga de 1677, la Universidad Nacional de San Antonio Abad del Cusco de 1692, la Universidad Nacional de Trujillo de 1824, la Universidad Nacional de San Agustín de 1828, la Universidad Nacional de Ingeniería de 1876, la Universidad Nacional Agraria La Molina de 1902, la Universidad Nacional del Centro del Perú de 1959, la Universidad Nacional de Cajamarca de 1962, la Universidad Nacional Federico Villarreal de 1963, entre ; todas ellas universidades públicas.

Por el lado de las universidades privadas, las más antiguas son la Pontificia Universidad Católica del Perú de 1917 y la Universidad Peruana Cayetano Heredia de 1961. De acuerdo con los resultados obtenidos en el censo de 2007, el 87,73 % de los peruanos de tres o más años de edad es alfabeta. En cuanto al nivel de educación alcanzado, el 38,2 % de las personas tiene educación secundaria, mientras que el 31,3 % ha cursado la educación superior. El promedio de años de estudio es de 9 años.

La cultura peruana tiene sus raíces principales en las tradiciones amerindias y españolas, aunque también ha sido influida por diversos grupos étnicos de África, Asia y Europa. La tradición artística peruana se remonta a la elaborada cerámica, textilería, orfebrería y escultura de las civilizaciones del Antiguo Perú. Los incas mantuvieron esos oficios e hicieron grandes logros arquitectónicos incluyendo la construcción de Machu Picchu.

El barroco predominó en el arte virreinal, aunque modificado por las tradiciones autóctonas. Durante este período, el arte se concentró mayormente en temas religiosos; las numerosas iglesias de la época y las pinturas de la escuela cuzqueña son muestra de ello. Las artes se estancaron después de la independencia hasta la aparición del indigenismo en la primera mitad del siglo . Desde la década de 1950 el arte peruano ha sido ecléctico e influido tanto por corrientes internacionales como locales.

La arquitectura peruana es la arquitectura realizada en cualquier época en lo que se conoce hoy en día como Perú, así como la arquitectura realizada por arquitectos peruanos en todo el mundo. Su diversidad y larga historia comprende desde el Antiguo Perú, el Imperio inca y el Virreinato, hasta la actualidad. La arquitectura virreinal peruana, desarrollada en el virreinato entre los siglo y , se caracterizó por la importación y adaptación de los estilos arquitectónicos europeos a la realidad peruana, produciendo como resultado una arquitectura original.

El uso de sistemas constructivos como la quincha, las ornamentaciones de iconografía andina y soluciones con formas inéditas confieren a la arquitectura virreinal peruana una identidad propia. Dos de los ejemplos más conocidos del Renacimiento son la Catedral del Cuzco y la Iglesia de Santa Clara, también en el Cuzco. Tras este periodo, la mezcla cultural alcanzó su más rica expresión en el estilo barroco.

Algunos ejemplos de este periodo son la Basílica y convento de San Francisco de Lima, la Catedral de Cajamarca, o la fachada de la Universidad Nacional de San Antonio Abad del Cusco y, sobre el conjunto, las iglesias de San Agustín, Santo Domingo y San Francisco, en Arequipa. Las guerras de independencia dejaron un vacío creativo que el neoclasicismo de inspiración francesa rellenó. El siglo se caracterizó por el eclecticismo, en contraposición al funcionalismo constructivo. El ejemplo más considerable es la Plaza San Martín de Lima.

La literatura peruana tuvo su primer vestigio en el "taki", término quechua que engloba literatura, danza y música. En los tiempos del virreinato, la literatura fue, básicamente, imitación de la literatura española de la época. Destaca en primer lugar, el Inca Garcilaso de la Vega con sus "Comentarios reales de los incas". Más tarde, destacaron Juan de Espinosa Medrano en la literatura quechua y Juan del Valle y Caviedes, el mismo Espinosa y Pedro Peralta y Barnuevo en la literatura castellana. También en esta época apareció la obra dramática anónima "Ollantay".

A partir de la época republicana fueron varios los exponentes de la literatura nacional como Felipe Pardo y Aliaga, Manuel Ascencio Segura, pero el mayor literato del siglo fue Ricardo Palma con sus célebres "Tradiciones peruanas", creando con ellas un nuevo género literario, una especie de cuentos, caracterizadas por ficcionalizar la realidad. En poesía resaltan en el siglo Mariano Melgar, José Santos Chocano y José María Eguren y en el siglo César Vallejo. En la narrativa destacan Ciro Alegría, José María Arguedas, Julio Ramón Ribeyro, Alfredo Bryce Echenique, y el Premio Nobel Mario Vargas Llosa.

La literatura del Perú, así como todas las manifestaciones culturales y artísticas, han pasado por varias etapas, en las cuales fue influenciada por movimientos o corrientes nacionales e internacionales. Los acontecimientos trascendentales de la historia, sirvieron de inspiración a los artistas que plasmaron en su obra el sentir de la época. Se distinguen varios movimientos, de acuerdo con cada época, sus ideas y filosofía.

La pintura en el Perú tiene su origen más remoto en el arte rupestre, destacando las cuevas de Toquepala y Lauricocha, cuya antigüedad se fecha en unos 10 000 años. En el Antiguo Perú, el arte se plasmó principalmente en la cerámica, distinguiéndose en ello, las culturas Nazca, Moche, Chimú, Tiahuanaco y Wari.

La pintura, como representación artística sobre lienzo o fresco, se inició durante la época virreinal. La pintura colonial, tuvo tres grandes influencias: la italiana, muy intensa durante el siglo y principios del xvii; la influencia flamenca, que se dio desde el principio y su importancia fue creciendo hasta ser muy fuerte en el siglo ; y la española que se manifestó con mayor fuerza durante el período barroco de los siglo y , especialmente a través de la escuela sevillana. Durante la primera mitad del siglo la pintura cuzqueña recibió la influencia del maestro italiano Bernardo Bitti quien dejó allí varios discípulos como Pedro de Vargas y Gregorio Gamarra quienes fueron continuadores del manierismo.

Sin embargo, la segunda mitad de este siglo presentó características totalmente diferentes debido en parte a la influencia de los dibujos y grabados flamencos como los de Marten de Vos y Jean van Halbeck respectivamente, así como de la pintura de Francisco de Zurbarán. La escuela de pintura cuzqueña se caracterizó por su originalidad y su gran valor artístico, los que pueden ser vistos como resultado de la confluencia de dos corrientes poderosas: la tradición artística occidental, por un lado, y el afán de los pintores indios y mestizos de expresar su realidad y su visión del mundo, por el otro. El indigenismo fue una de las corrientes más importantes en la pintura peruana. Sus mayores exponentes fueron Mario Urteaga Alvarado y José Sabogal, entre los discípulos de este último figuran Camilo Blas, Julia Codesido, Enrique Camino Brent, Cota Carvallo, Pedro Azabache Bustamante y Eladio Ruiz.

La música peruana es producto de la fusión a través de muchos siglos. Existen muchos géneros de música peruana: clásica, andina, criolla, amazónica, entre otros. Estas se clasifican en música y danzas de la costa, sierra y amazonía. La música criolla tradicional de la costa es muy variada debido a que justamente esta es la región donde mayor mestizaje hubo y actualmente hay, conocida como "música criolla" dentro de la cual se encuentran las danzas afroperuanas. De la costa central básicamente Lima; sobresale la música de los callejones de la "Lima de Antaño" y el mundialmente conocido vals peruano (cultivado en otros países sobre todo en Argentina, dentro de los aficionados al tango).

De la capital también es originaria la salerosa zamacueca o marinera limeña (madre del resto de cuecas y zambas); dentro de lo cual existen variantes y extensiones como el canto de Jarana y la resbalosa (como la fuga de ésta). La costa sur-central Cañete, Chincha, Ica y Nazca; ofrecen el culto a la música afroperuana. Entre los géneros más destacados están el festejo, el landó, el toro mata y el panalivio. De los departamentos de La Libertad y Lambayeque es oriunda la reconocida marinera norteña; que es tocada en banda, tambores y trompetas. Esta versión a diferencia de la anterior no es de salón, sino es muy vistosa y alegre, motivo de festivales que atraen mucho incluso cuando se presentan los famosos campeonatos del caballo peruano de paso.

Más al norte, de Piura y Tumbes vienen la cumanana (de influencia mulata y afroperuana), el "agitanado" emotivo piurano tondero y el triste que muchas veces va acompañado dentro de la expresión propia del norte del Perú "Triste con fuga de Tondero". Las regiones de la sierra sur como Huancavelica, Ayacucho, Apurímac, Cuzco y Puno se caracterizan por el huayno (y también la zona norte del altiplano boliviano). De la región del Cusco procede la muliza, "el cóndor pasa…" y de Arequipa lo más destacado es el género musical wititi del distrito de Tapay en el Valle del Colca, el "mestizo" Yaraví Arequipeño, dentro de los cuales destacan el conocido "Melgar" y "La Partida". La sierra central como Cerro de Pasco, Áncash y Junín es famosa por su alegre huaylas. Versiones típicas de este género son el "Pío Pío" y el "Huaylas Macho".

Dentro de las fiestas tradicionales andinas, la más conocida es el Inti Raymi que, en Sacsayhuamán, en las afueras del Cusco, rememora ceremonias y rituales de la época del Imperio incaico rindiendo homenaje al Inti (dios Sol de los incas), se lleva a cabo el 24 de junio de cada año. Entre los intérpretes de música criolla y afroperuana más reconocidos se encuentran: Arturo Cavero, Augusto Polo Campos, Cecilia Bracamonte, Chabuca Granda, Eva Ayllón, Felipe Pinglo Alva, Lucha Reyes, Lucho Barrios, Lucho Garland, Lucila Campos, Óscar Avilés y las ganadoras del Grammy Latino Susana Baca y Tania Libertad.

De la música folclórica sobresalen: Alicia Delgado, Dina Páucar, Flor Pucarina, Muñequita Sally, Pastorita Huaracina, Picaflor de los Andes, Rosita de Espinar, Saywa y Damaris (ganadora de la competencia folclórica del Festival de Viña del Mar. De la música folclórica amazónica destacan: Los Shapis, Ruth Karina, Rossy War, entre otros. En el ámbito operístico, uno de los más reconocidos es Juan Diego Flórez.

El país también cuenta con algunos cantantes de rock y pop de gran aceptación a nivel tanto nacional como internacional tales como: Anna Carina, Jean Paul Strauss, Leslie Shaw, Raúl Romero, Gian Marco y Pedro Suárez-Vértiz, ganadores de premios como Grammy Latino y Orgullosamente Latino, a nivel de rock grupos como Libido, TK, Zen entre otros. Perú también es el país que vio nacer a Los Saicos, considerada como la primera banda de garage rock y proto-punk del mundo.

La primera función de un filme (usando el cinematógrafo de los hermanos Lumière) se realizó en febrero de 1897 en la Confitería Jardín Estrasburgo (hoy Club de la Unión), en la ciudad de Lima. Un mes antes, se habían proyectado imágenes en movimiento con el vitascopio inventado por Thomas Alva Edison. El público que presenció en un inicio, las proyecciones del vitascopio y del cinematógrafo fue de la aristocracia y las imágenes que observaron eran de paisajes de otros países (en 1899 se tomaron las primeras imágenes del Perú).

Históricamente, el cine del país comenzó en Iquitos una ciudad septentrional y escenario principal de la fiebre del caucho en la amazonía peruana. La industria cauchera benefició la presencia de cineastas extranjeros en la ciudad, y el interés cinematográfico en años posteriores. Antonio Wong Rengifo es el pionero más importante del cine de Iquitos. En Lima, la primera película peruana con sonido (con música sincronizada y algunas secuencias de diálogo) fue "Resaca" de Alberto Santana, que fue estrenada en 1934. Esta fue seguida de otra película sonora titulada "Cosas de la vida" también en 1934. La primera película completamente con sonido y diálogos fue "Buscando olvido" de 1936.

Hasta mayo de 2015, los diez habían sido: "Asu mare 2", "Asu mare", "A los 40", "La fuga del Chacal", "Cementerio general", "Pantaleón y las visitadoras", "Secreto Matusita", "No se lo digas a nadie", "Viejos amigos" y "". Una de las películas peruanas más galardonada internacionalmente es "La teta asustada" que obtuvo el en el Festival Internacional de Cine de Berlín, mientras que su protagonista Magaly Solier ganó el premio a la mejor actriz en los festivales de cine de Gramado, Guadalajara, Montreal y Lima.

Asimismo, "Caídos del cielo" ganó el y el Grand Prix des Amériques en 1990. El filme "Espejismo" fue la primera cinta peruana en ser nominada al , mientras que la cinta "La teta asustada" se convirtió en el primer filme peruano en ser nominado al .

Entre los directores de cine, han destacado Francisco José Lombardi, dos veces ganador del premio al del Festival Internacional de Cine de San Sebastián por "La ciudad y los perros" en 1985 y por "Bajo la piel" en 1996, Armando Robles Godoy ganador del Premio ACE, Josué Méndez, Luis Llosa, Augusto Tamayo San Román, Javier Corcuera, Claudia Llosa, Salvador del Solar, entre otros. En el país se realizan diversos festivales de cine como el Festival de Cine de Lima, Festival de Cine Lima Independiente, Festival de Cine Europeo, Festival de cine Al Este de Lima, Cinesuyo, Festival Nacional e Internacional de Cortometrajes e Inkafest.

Son grupos de teatro conocidos, entre otros: "Yuyachkani" y "Cuatrotablas". El grupo "Integro" fusiona danza y teatro de manera interdisciplinaria. Desde hace varios años en la época de Todos los Santos (fines de octubre y comienzos de noviembre) se representa en el Cementerio Presbítero Matías Maestro de Lima la obra "Don Juan Tenorio" de José Zorrilla, un clásico de la literatura escrita en castellano. 

La historieta o cómic peruano no ha sido especialmente prolífica, ya que el país ha sido mayormente un consumidor de revistas extranjeras. Suele citarse el "Primer nueva corónica y buen gobierno" (hacia 1615) de Felipe Guamán Poma de Ayala como ejemplo de antigua historieta, aunque la mayoría de los estudiosos del medio lo consideran un producto cultural de la modernidad industrial y política occidental que surgió en paralelo a la evolución de la prensa escrita como primer medio de comunicación de masas, y buscan la primera historieta entre las reproducidas en ella. En el caso del Perú, esto supone remontarse hasta 1873, fecha en que Dumontel firmó la historieta "Fragata sospechosa a la vista", como parte de la serie titulada "Lima a las diez de la noche" para el semanario "Don Quijote".

La ciencia y la tecnología peruana tiene sus orígenes en la civilización incaica, quienes se destacaron en el campo de las matemáticas principalmente por su capacidad de cálculo en el ámbito económico. Los quipus y yupanas fueron señal de la importancia que tuvo la matemática en la administración incaica. Esto dotó a los incas una aritmética sencilla pero efectiva, para fines contables, basada en el sistema decimal; conocieron el cero, y dominaron la suma, la resta, la multiplicación y la división. Durante las primeras décadas del siglo , se comenzaron a crear institutos destinados a la promoción y difusión de la actividad científica y tecnológica en el país.

Uno de los principales organismos de investigación científica del Perú es la Academia Nacional de Ciencias Exactas, Físicas y Naturales. También existen otros institutos de investigación científica como el Centro Internacional de la Papa, la Sociedad Química del Perú, el Instituto Nacional de Investigación y Capacitación de Telecomunicaciones, el Instituto de Investigación Científica de Arqueología Peruana, el Instituto de Investigaciones de la Amazonía Peruana entre otros. El país cuenta con una estación de investigación científica establecida en la Antártida llamada Base Machu Picchu y observatorios astronómicos como Jicamarca, el Morro Solar y Chanquillo (el observatorio solar más antiguo de América).

En materia nuclear Perú cuenta con la Central Nuclear Óscar Miró Quesada de la Guerra, cuyo reactor es usado únicamente para la investigación. Entre las funciones más importantes de esta planta, figura la producción de radioisótopos y gammagrafías, que facilitan hacer diagnósticos médicos, así como una mayor precisión en el estudio de los tejidos del cuerpo humano. Según Scopus, una base de datos bibliográfica de resúmenes y citas de artículos de revistas científicas, Perú se posiciona en el lugar número 58 del mundo en materia de publicaciones científicas y séptimo entre los países de América Latina.

Algunos científicos peruanos que han destacado durante su carrera son: Alberto Barton descubridor del agente etiológico de la enfermedad de Carrión, Daniel Alcides Carrión que se infectó él mismo con la bacteria "bartonella bacilliformis" para contraer la enfermedad de Carrión y estudiar su desarrollo y evolución en el infectado, Julio César Tello considerado el padre de la arqueología peruana, Pedro Ruiz Gallo uno de los precursores de la aeronáutica moderna, Pedro Paulet considerado por Wernher von Braun como el padre de la astronáutica moderna, Ronald Woodman ganador del premio Appleton y Carlos Noriega el primer peruano en viajar al espacio.

La cocina peruana es considerada la más variada del mundo, tiene el récord Guiness a la mayor variedad y diversidad de platos típicos en el mundo (491); entre tanto, se ha registrado más de dos mil diferentes tan solo en la costa y más de doscientos cincuenta tradicionales a nivel nacional. La formación de la gastronomía peruana refleja el mestizaje que a lo largo de los siglos ha modelado la cultura peruana.

La primera fusión se produjo durante la colonia con los insumos y técnicas precolombinas sumado a la cocina española y las costumbres culinarias de la cultura africanas, posteriormente, se vio influenciada por la gastronomía francesa, cantonesa, japonesa e italiana, y con la expansión a la selva, la gastronomía amazónica se transformó dentro de este mismo crisol. Entre los estilos culinarios del Perú, cabe mencionar la cocina criolla (norteña y limeña), la gastronomía marina, la cocina andina, el chifa y la cocina amazónica.

Los platos más representativos son el cebiche en la costa, la pachamanca en la sierra y el juane en la selva. En el ámbito de las bebidas, destaca entre los espirituosos el pisco, un brandy de uva originario con el cual se prepara el pisco sour, cóctel de bandera preparado en base al pisco. La chicha de jora, una bebida de origen precolombino, hecha de maíz. Es un licor tradicional y extendido de la sierra y es, además, la bebida tradicional de la Fiesta de San Juan, celebrada en toda la selva peruana.

En la selva, se prepara el masato, licor de origen indígena, hecho de yuca fermentada. La selva posee gran variedad de refrescos hechos de frutas amazónicas, entre éstos se encuentran la aguajina, bebida hecha del aguaje, moriche o burití ("Mauritia flexuosa") y el refresco de camu-camu ("Myrciaria dubia"), fruta amazónica que concentra la mayor cantidad de vitamina C. La Inca Kola, de origen nacional, es la gaseosa más vendida en el país, incluso por encima de las multinacionales Coca-Cola o Pepsi.

En los últimos años del siglo e inicios del la cocina peruana empezó a expandirse fuera de sus fronteras. En la IV Cumbre Internacional de Gastronomía Madrid Fusión 2006, realizada del 17 al 19 de enero, la ciudad de Lima fue declarada capital gastronómica de América Latina. La gastronomía local está registrada como un producto bandera del Perú. En diciembre 2016, el país fue distinguido por quinta ocasión consecutiva con el World Travel Awards en la categoría de mejor destino culinario del mundo. Asimismo, la restauracion peruana acumula cada vez mas reconocimientos internacionales, como por ejemplo la mas reciente edicion de la lista Worlds 50 Best Restaurants (publicada por la revista Restaurant), incluye a dos restaurantes peruanos entre los diez mejores del mundo.

El patrimonio cultural inmaterial del Perú está compuesto por diversas manifestaciones culturales como arte, artesanía, danzas, bailes, festividades, gastronomía, música y rituales. Hasta enero de 2018, el país cuenta con doscientos cuarenta y tres expresiones folclóricas consideradas como patrimonio cultural de la nación. Algunas de estas son: la marinera, el pisco, el caballo de paso, el cajón peruano, la pachamanca, el cebiche, la fiesta del Tata Pancho, la quena, la , el sicuri, el pincullo, la tunantada, el shapish y el Señor de los Milagros.

Perú también cuenta con sitios específicos de importancia cultural o natural que han sido incluidos en la lista de Patrimonio de la Humanidad de la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura de acuerdo con la Convención sobre la Protección del Patrimonio Mundial Cultural y Natural creada en 1972. El país ratificó esta convención el 24 de febrero de 1982, haciendo que sus sitios históricos sean elegibles para su inclusión en la lista.

Desde el año 2014 cuenta con doce sitios considerados como Patrimonio de la Humanidad, ocho son lugares de interés cultural (la ciudad del Cuzco, el sitio arqueológico de Chavín, la zona arqueológica de Chan Chan, el centro histórico de Lima, las líneas y geoglifos de Nazca y Pampas de Jumana, el centro histórico de la ciudad de Arequipa, la ciudad sagrada de Caral-Supe y Qhapaq Ñan, sistema vial andino), dos son bienes naturales (el parque nacional Huascarán y el parque nacional del Manu) y dos mixtos (el santuario histórico de Machu Picchu y el parque nacional del Río Abiseo). 

En el año 2001 la Unesco inició un programa denominado . Ese mismo año el patrimonio oral y manifestaciones culturales del pueblo zápara fue proclamado como integrante de la lista de obras maestras. Posteriormente en 2005, el arte textil de Taquile también fue incluido de dicha lista. Este programa concluyó en 2006 con la entrada en vigor de la Convención para la Salvaguardia del Patrimonio Cultural Inmaterial y las obras maestras pasaron a formar parte de la .

A esta nueva lista se añadieron siete elementos más del país: la danza de las tijeras, la huaconada, danza ritual de Mito, eshuva, rezos cantados de la etnia Huachipaeri, la peregrinación al santuario del Señor de Quyllurit'i, los conocimientos, técnicas y rituales vinculados a la renovación anual del puente Q’eswachaka, la festividad en honor a la Virgen de la Candelaria, la danza del wititi del valle del Colca y el sistema tradicional de Jueces de Agua de Corongo. El artículo 18 de la convención estipula que el comité intergubernamental selecciona programas, proyectos y actividades de salvaguardia del patrimonio cultural inmaterial que reflejen mejor los principios y objetivos de la convención. Uno de esos proyectos corresponde al país bajo el título de "salvaguarda del patrimonio cultural inmaterial de las comunidades aymaras de Bolivia, Chile y Perú", seleccionado en 2009.

La práctica del deporte en el territorio peruano se remonta al Antiguo Perú. Con la llegada de los españoles a este territorio, la práctica del deporte cambió radicalmente. Más tarde, ésta fue influenciada por la ideología estadounidense de la educación física ligada a la comercialización. El deporte en el país se encuentra dividido en varias federaciones deportivas (una por cada práctica deportiva) que se encuentran bajo la tutela del máximo ente estatal para regular su práctica, el Instituto Peruano del Deporte. Este organismo es el encargado de recibir el presupuesto que el gobierno asigna al área, a fin de dividirlo entre todas las federaciones y organismos afines a la práctica deportiva.

El historial peruano en los Juegos Olímpicos es muy escaso; pese a ello, es uno de los primeros países sudamericanos en ganar una medalla de oro en los Juegos Olímpicos. Aconteció en los Juegos Olímpicos de Londres 1948, cuando ganó su primera y única medalla de oro en la disciplina de tiro, modalidad de pistola libre, con el tirador Edwin Vásquez Cam. Este deporte ha logrado tres de las cuatro medallas olímpicas del Perú: En 1948, en 1984 con Francisco Boza y en 1992 con Juan Giha, estos dos últimos de plata. La otra medalla de plata lograda por el país en los Juegos Olímpicos corresponde a la disciplina del voleibol, cuando en 1988 en Seúl, el seleccionado peruano cayó por 3-2 ante la Unión Soviética en la final.

El fútbol, el deporte más popular en el mundo, también es el de mayor práctica en el país. El Campeonato Descentralizado es el torneo de clubes más importante de la nación. La selección masculina ha tenido algunas actuaciones importantes en la escena mundial. Participó en la fase final de la Copa Mundial de Fútbol en cuatro ocasiones, actualmente clasificado para la edición del 2018. Asimismo, han sido campeones de la Copa América en dos ocasiones (1939 y 1975). A nivel de clubes, sobresalen Universitario de Deportes con el subcampeonato de la Copa Libertadores de América en 1972 y Sporting Cristal también con el subcampeonato en 1997. Los únicos clubes peruanos con títulos internacionales son Cienciano, que obtuvo la Copa Sudamericana 2003 y la Recopa Sudamericana 2004, y Universitario campeón de la Copa Libertadores Sub-20 de 2011.

Otro de los deportes con un gran número de seguidores es el voleibol. La selección femenina ha sido ganadora en doce ocasiones del Campeonato Sudamericano y ha obtenido medallas de plata y bronce en el Campeonato Mundial y en los Juegos Panamericanos. Otra disciplina deportiva en la que el Perú ha destacado internacionalmente es el surf, el país posee seis títulos mundiales (tres a nivel individual con Felipe Pomar, Sofía Mulánovich y Analí Gómez y tres en equipos en el ISA World Surfing Games), además cuenta también con dos títulos mundiales de Piccolo Clemente en la modalidad de longboard y uno de César Bauer en la modalidad de bodyboard. El tenis también ha registrado importantes logros con Alex Olmedo campeón de los abiertos de Australia y Wimbledon y Luis Horna ganador del .

En el ajedrez sobresalen el GMI Julio Granda y el GMI Emilio Córdova; el primero de ellos ganó el Campeonato Mundial Infantil a la edad de 13 años y el segundo obtuvo la norma de Gran Maestro Internacional a los 16 años, convirtiéndose en el GMI más joven del país y de Sudamérica en alcanzar esa norma. En este deporte también destacan los hermanos Deysi y Jorge Cori Tello ambos campeones mundiales juveniles. En la clase optimist de vela, es el único país que ha logrado conseguir el título del Campeonato Sudamericano de Vela en seis ocasiones consecutivas. El principal exponente de la clase optimist es Sinclair Jones, quien en el año 2009 se consagró campeón mundial en la categoría individual.

En el sunfish el velerista más destacado es Alexander Zimmerman campeón mundial en 2012 y 2013, mientras que en el windsurf el más sobresaliente es Sebastian Aguirre Roda campeón mundial del Formula Experience en 2009. En motonáutica Paloma Noceda ha sido campeona mundial en dos oportunidades. El jinete Edgar Prado fue ganador del Derby de Kentucky y es miembro del Salón de la Fama de la Hípica. En cuanto a los deportes de combate, Perú ha obtenido campeonatos mundiales en el boxeo con Kina Malpartida, Linda Lecca y Alberto Rossel, en muay thai con Alexander Chávez, Antonina y Valentina Shevchenko y en kick boxing con Miguel Sarria.





</doc>
