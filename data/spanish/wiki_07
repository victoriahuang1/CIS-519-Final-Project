<doc id="1094" url="https://es.wikipedia.org/wiki?curid=1094" title="Egipto">
Egipto

Egipto, oficialmente la República Árabe de Egipto (en árabe: جمهوريّة مصرالعربيّة "Ŷumhūriyyat Miṣr Al-ʿArabiyyah", pronunciado en dialecto egipcio: [Maṣr]), es un país soberano de África en la parte más occidental del Máshrek. Es un , está ubicado mayoritariamente en el extremo noreste de África mientras que en Asia, se encuentra en la península del Sinaí. Limita con Sudán al sur, con Libia al oeste y con el Estado de Palestina e Israel al noreste. Al norte limita con el mar Mediterráneo y al sureste con el mar Rojo.

La mayor parte de su superficie la integra el desierto del Sahara. El río Nilo cruza el desierto de norte a sur, formando un estrecho valle y un gran delta en su desembocadura en el Mediterráneo. Estas tierras fértiles se hallan densamente pobladas, concentrando . Casi la mitad de los egipcios viven en áreas urbanas, sobre todo en los centros densamente poblados de El Cairo, su capital, y Alejandría.

Egipto fue cuna de la antigua civilización egipcia, que junto con la mesopotámica fueron el origen de la actual cultura Occidental, influyendo decisivamente en la historia de la humanidad. Los restos de esta civilización jalonan el país como las pirámides y la gran esfinge o la ciudad meridional de Lúxor que contiene un gran número de restos antiguos, tales como el templo de Karnak y el Valle de los Reyes. Egipto es actualmente un centro político y cultural importante del Oriente Próximo y se le considera una potencia regional. Su actual forma de gobierno es la república semipresidencialista. Entre 2013 y 2014 estuvo bajo gobierno interino, formado tras el golpe de Estado de 2013 que derrocó al primer presidente democrático del país, Mohamed Morsi.

El antiguo nombre del país, Kemet "(km.t)", o ‘tierra negra’, deriva de los fértiles limos negros depositados por las inundaciones del Nilo, distintos de la ‘tierra roja’ "(dsr.t)" del desierto. El nombre se transformó en "kīmi" y "kīmə" en la etapa copta de la lengua egipcia, y fue traducido al primitivo griego como Χημεία (Jemía).

Miṣr, el nombre oficial árabe (مصر) de Egipto es de origen semítico y significa "estrecho". El nombre hebreo para Egipto es מִצְרַיִם "(mitzráyim)", que significa literalmente ‘dos estrechos’, por una referencia a la separación histórica en el Alto y Bajo Egipto. Miṣr significaba originalmente ‘metrópoli’, ‘civilización’ y también ‘país’ o ‘tierra fronteriza’. El nombre مصر deriva de la raíz semítica صار (ṣr), que indica angostura. Algunos dicen que la etimología de la palabra hebrea מַצֵר "(metzar)" deriva de la raíz צור (ṣr, صار) y el prefijo מֵ "(me)". מַצֵר también es escrita מֵיצַר "(meytzar)". Otros dicen que deriva de מֵי "(mey)", agua, y צֵר "(tzar)", angosto.

El nombre en español, Egipto, proviene del latín Aegyptus, derivado a su vez de la palabra griega Αίγυπτος (Aigyptos). El término fue adoptado en copto como Gyptios, y pasó al árabe como Qubt. Se ha sugerido que la palabra es una corrupción de la frase egipcia "ḥwt-k3-ptḥ", que significa ‘casa del espíritu (ka) de Ptah’, el nombre de un templo al dios Ptah en Menfis. Según Estrabón, el término griego Aigyptos significaba ‘más allá del Egeo’ (Aἰγαίου ὑπτίως, "Aegaeon uptiōs"). 

La Biblia hace referencia a Egipto y sus habitantes más de 700 veces. A Egipto por lo general se le llama Mizraim (Mits·rá·yim) en las Escrituras Hebreas, seguramente debido a la importancia o preponderancia de los descendientes de ese hijo de Cam en dicha región. (Gé 10:6.) En algunos salmos se le denomina “la tierra de Cam”. (Sl 105:23, 27; 106:21, 22.)

La riqueza que aportaba el fértil limo tras las inundaciones anuales del río Nilo, junto a la ausencia de poderosos pueblos por su aislamiento, debido a que el valle del Nilo está situado entre dos amplias zonas desérticas, permitieron el desarrollo de una de las primeras y más deslumbrantes civilizaciones en la historia de la humanidad.

Los primeros pobladores de Egipto, alcanzaron las riberas del Nilo, por entonces un conglomerado de marismas y foco de paludismo, escapando de la desertización del Sahara. Las primeras comunidades hicieron habitable el país, y se estructuraron en regiones llamadas nomos. Pasado el tiempo y tras épocas de acuerdos y disputas los nomos se agruparon en dos proto-naciones, denominadas el Alto y el Bajo Egipto alrededor del año 4000 a. C. Egipto se unifica alrededor del año 3100 a. C., desde el faraón Menes (Narmer en su nombre egipcio).

La historia del Antiguo Egipto se divide en tres imperios con períodos intermedios de conflictos internos y dominación por gobernantes extranjeros. El Imperio Antiguo se caracterizó por el florecimiento de las artes y la construcción de inmensas pirámides . Durante el Imperio Medio (2050-1800 a. C.), tras una etapa de descentralización, Egipto conoció un período de esplendor en su economía. En el Imperio Nuevo (1567-1085 a. C.) la monarquía egipcia alcanzó su edad dorada conquistando a los pueblos vecinos y expandiendo sus dominios bajo la dirección de los faraones de la dinastía XVIII. La última dinastía fue derrocada por los persas en el año 341 a. C., quienes a su vez fueron sustituidos por gobernantes griegos y romanos, periodo que comenzó hacia el año 30 a. C. como resultado de la derrota de Cleopatra y Marco Antonio en la batalla de Actium, que trajo siete siglos de paz relativa y estabilidad económica. Desde mediados del siglo IV, Egipto formó parte del Imperio Oriental, que se convirtió en el Imperio bizantino.

En el 640, se produce la invasión árabe, que asume el gobierno del país a pesar de las revueltas de los pobladores de entonces, los cristianos coptos en el 725. Los arabes introdujeron el islamismo y el idioma árabe en el siglo VII y gobernaron los siguientes seis siglos, con una interrupción de los Tuluníes, que declaron la independencia de Egipto del califato abasi y la mantuvieron 37 años. A finales del siglo X, durante un breve tiempo los Fatimies se hicieron con el gobierno. Vendrá a continuación la época de Saladino que supondrá un renacimiento cultural y económico favorecido por el espíritu de la Jihad, guerra santa en respuesta a las cruzadas cristianas. Entre 1250 y 1517, los Mamelucos, que eran parte de una casta militar local, tomaron el control del gobierno alrededor del año 1250, derrotaron a los mongoles en su avance imparable por Asia, pero fueron incapaces de impedir la ocupación del país y el control del gobierno por parte de los turcos otomanos en 1517.
Bajo el gobierno otomano, Egipto quedó relegado a una posición marginal dentro del gran Imperio otomano. Aunque los Mamelucos recuperaron el poder por un breve periodo, en 1798 el ejército de Napoleón ocupó el país. Tampoco duró mucho la ocupación francesa, que apenas dejó huella aunque supuso el comienzo de los estudios egiptológicos sobre la cultura antigua.
Tras la salida de las tropas francesas, hubo una serie de guerras civiles entre otomanos, mamelucos y mercenarios albaneses, hasta que en 1805 Egipto consiguió la independencia, siendo nombrado sultán Kavalali Mehmet Alí Pasha (Kavalali Mehmed Ali Pasha), más conocido como Mehmet Alí, quien había llegado al país como virrey o valí para reconquistarlo en nombre del Imperio Turco, y que llevaría una política exterior pro-occidental emprendiendo una serie de reformas que combinaban estrategias tradicionales de centralización del poder con la importación de modelos europeos para la creación de nuevas estructuras militares, educativas, industriales y agrícolas, incluyendo planes de regadío, que fueron continuadas y ampliadas por su nieto y sucesor Ismail Pachá, el primer Jedive.

Tras la apertura del canal de Suez en 1869, Egipto se convirtió en un importante centro de comunicaciones, pero cayó a su vez en una fuerte deuda. Los británicos tomaron el control del gobierno en forma de concesiones hacia 1904, que fue fuertemente protestado declarándose de nuevo la independencia en 1925, con una nueva constitución y un régimen parlamentario. Sad Zaghlul fue elegido como primer ministro de Egipto en 1924 y en 1936 el llamado tratado Anglo-Egipcio le dio por finalizado.

Las continuas injerencias británicas mantenían una inestabilidad política hasta que en 1952 un golpe de estado forzó al rey Faruk I a abdicar y llevó al gobierno al coronel Gamal Abdel Nasser, como Presidente del nuevo gobierno. Nasser declaró la titularidad pública del Canal de Suez lo que supuso una importante mejora para la Tesorería egipcia, aunque para ello tuvo que enfrentarse militarmente en 1956 a las tropas conjuntas francesas, inglesas e israelíes que intentaron derrocar al gobierno sin conseguirlo (Crisis de Suez). Esta victoria militar colocó a Nasser a la cabeza de los líderes de Oriente Medio y como ejemplo a seguir por el mundo árabe para desembarazarse de las injerencias extranjeras. Entre 1958 y 1961 Egipto, durante la presidencia de Nasser, formó parte, junto con Siria, de la República Árabe Unida. La derrota de las fuerzas árabes por Israel en 1967 durante la Guerra de los Seis Días, privó a Egipto de la península del Sinaí y de la franja de Gaza.

Tras la guerra con Israel, guerra del Yom Kippur de 1973, a lo que siguió la firma en 1978 del acuerdo de Camp David (por el sucesor de Nasser, Anwar el-Sadat), Egipto recuperó el Sinaí. Este tratado fue repudiado por el mundo árabe, y sus consecuencias fueron la expulsión de Egipto de la Liga árabe y el ascenso del fundamentalismo islámico en el país después de la revolución iraní.

En 1981 Sadat fue asesinado y le sucedió Hosni Mubarak, quien mantuvo las políticas de su predecesor. Una política interior adecuada ha conseguido vencer al fundamentalismo, pese a algunos atentados contra turistas extranjeros para dañar la fuente principal de ingresos del país: el turismo. Tras la Cumbre de Amán en 1987, Egipto inicia la recuperación de sus anteriores relaciones con los países árabes, especialmente con Arabia Saudí, lo que trae consigo la rehabilitación de Mubarak y su gobierno ante los ojos del resto de dirigentes políticos árabes. Desde entonces, Egipto aprovechó su prestigio para mediar entre Israel y los árabes conocidos como palestinos desde la fundación de la Organización para la Liberación de Palestina en 1964, y en 1993 apoyó la firma de los acuerdos que llevaron al inicio de la autonomía palestina, defendiendo la formación de un futuro Estado Palestino.

En 2003 se lanzó el movimiento egipcio para el cambio, conocido popularmente como Kifaya, para buscar una vuelta a la democracia y a mayores libertades civiles. Sin embargo, no fue hasta febrero de 2011 cuando se consiguió derrocar al dictador Hosni Mubarak (que llevaba 30 años en el poder) mediante dos semanas de manifestaciones. El foco principal y permanente de la rebelión fue la famosa y representativa "Midan Tahrir" (Plaza de la Liberación), en el centro de El Cairo, donde se congregaban a diario varios cientos de miles de manifestantes. El 3 de julio de 2013, el ejército dio un nuevo golpe de Estado, bajo petición del pueblo debido a la gran corrupción del Presidente Mohamed Morsi y los Hermanos Musulmanes. Más tarde incluso el ejército reveló los complotes que los Hermanos Musulmanes llevaban a cabo contra el país y su intento de vender gran parte de las tierras de Sinai a Israel y Hamas. Actualmente está encerrado junto con los demás de su partido en espera a ser condenados por Traición Suprema y comunicación con partes extranjeras facilitándoles información confidencial del país.

Actualmente la República Árabe de Egipto es una república democrática parlamentaria cuyo presidente, como jefe de Estado y comandante supremo de las fuerzas armadas del país, representa al poder ejecutivo elegido por elecciones populares para un período de cuatro años. Se puede volver a votar al mismo presidente únicamente una vez más

Aunque aparentemente el poder se organiza bajo un sistema multipartidista, en la práctica durante más de cincuenta años el presidente se ha elegido en elecciones con un solo candidato. Egipto también celebra elecciones parlamentarias multipartidistas de manera regular.
En febrero de 2005 el presidente Hosni Mubarak anunció la reforma de la ley para la elección presidencial, de manera que en las elecciones de 2010 habría varios candidatos, por primera vez desde 1952 y se limita el mandato a siete años con solo dos legislaturas. En 2007 se celebró un referéndum en el que se aprobó aumentar los poderes presidenciales.

En las elecciones del 28 de noviembre de 2010, Hosni Mubarak volvió a arrasar en la primera vuelta electoral dejando fuera a los Hermanos Musulmanes, principal grupo de oposición islamista. Sin embargo, parece evidente que hubo numerosas irregularidades en la votación. Así lo denunciaron diversos medios de prensa y entes internacionales.
En junio de 2012, hubo elecciones presidenciales por primera vez desde la deposición de Mubarak. Resultó electo el candidato por los Hermanos Musulmanes, Mohamed Morsi, el 24 de junio de 2012. Asumió el cargo el 30 de junio de 2012.

Con motivo de las Elecciones presidenciales de Egipto de 2014 y dado el gran apoyo popular con el que contaba, Abdelfatah Al-Sisi dimitió de todos sus cargos militares y se presentó como candidato. La Comisión Electoral egipcia anunció en abril que Al Sisi logró registrar 188930 firmas válidas para su participación (siendo solamente 25 000 necesarias). Su único rival que logró superar el mínimo fue el izquierdista Hamdin Sabahi, líder del partido Corriente Popular, habiendo logrado 31555 avales. Así, tras el segundo golpe de Estado llevado a cabo bajo petición del pueblo, y aunque el Presidente Abdelfatah Al-Sisi, como ministro de Defensa entonces, rehusaba presentarse a las elecciones presidenciales, finalmente accedió a hacerlo tras la constante exigencia del pueblo para que se presentara. Es el actual presidente del país desde el 8 de junio de 2014, siendo así el noveno presidente desde la declaración de la república en el país el 18 de junio de 1953 (hace 63 años).

El gobierno provisional, respaldado por la junta militar surgida del triunfo del Golpe de Estado en Egipto de 2013, someterá a referéndum en las primeras semanas de 2014 una nueva Constitución, como alternativa a la Constitución "islamista" del presidente derrocado Mohamed Morsi. Según el análisis que ha hecho del proyecto la profesora de la Universidad Autónoma de Madrid, Luz Gómez García, en el mismo, entre otras cosas, se mantienen los poderes que el ejército ya tenía en la época de Hosni Mubarak —no es casual que este haya alabado el proyecto— e impide participar en la política egipcia a los Hermanos Musulmanes, declarados a finales de 2013 como "organización terrorista" por las nuevas autoridades egipcias.

Egipto está dividido en 27 gobernaciones o provincias ("muhafazah"; en singular "muhafazat").El triángulo de Hala´ib ubicado en territorio egipcio está bajo administración sudanesa mientras que el triángulo de Bir Tawil sería parte de Egipto según el gobierno sudanés estos territorios en disputa están ubicados al sureste de Egipto y al noreste de Sudán.

Egipto se encuentra en el extremo noreste del continente africano, posee costas sobre el mar Mediterráneo y el mar Rojo. Limita al oeste con Libia, al sur con Sudán, al norte con el Mediterráneo y al este con el mar Rojo e Israel. Su territorio abarca 1 001 450 km² de superficie, que a efectos comparativos corresponde a la mitad de la de México o el doble que España. Está ocupado en su inmensa mayoría por el desierto del Sáhara, y surcado por un único río, el Nilo, que riega la única tierra fértil del país y que ha sido la principal fuente de riqueza y ha permitido el desarrollo de varias culturas a lo largo de la milenaria historia de Egipto. Desemboca en el Mediterráneo formando un delta de unos 200 km de extensión en dirección norte-sur y entre Alejandría y Damieta en dirección este-oeste.

El clima es desértico en la mayoría del territorio, con escasez de lluvias (aunque en los últimos años la humedad ha aumentado considerablemente en El Cairo), con noches frías y días muy calurosos. En la costa norte, a lo largo del delta, posee clima mediterráneo, con una media de lluvia de 18 mm. Por lo inhóspito del territorio la población se asienta principalmente a orillas del Nilo, aunque también son importantes algunas localidades mediterráneas y del mar Rojo. En Egipto se encuentra el canal de Suez, que conecta el mar Mediterráneo con el Rojo, y separa la parte principal del territorio egipcio de la Península del Sinaí, que limita al este con Israel.

El gobierno egipcio mantiene 21 Parques Naturales con una superficie total de 53 000 km², el 5 % del territorio nacional. El mayor de ellos, el Parque Nacional de Elba, al sur, con distintos ecosistemas: manglares del mar Rojo, 22 islas, arrecifes de coral, dunas costeras, pantanos salados costeros, llanuras desérticas costeras y la zona de montañas: Jabal Elba de 1437 m de altitud, Jabal Ebruq y Al Daeeb.

A través de Egipto cruza el río Nilo, que es el segundo del mundo en longitud, con 6497 km de largo, después del río Amazonas (6800 km). Su curso a través de Egipto es de 1.550 kilómetros, y la zona del Delta del Nilo posee 24 000 km². El Nilo entra en Egipto, cerca de Wadi Halfa por su frontera sur. Fluye a través del desierto fertilizando un valle de 1,5 a 2 km de ancho hasta Asuán. En Asuán, cruza las últimas cataratas y fluye a través del valle, que se extiende de 5 a 20 km, hasta El Cairo, situado a unos 700 km. Recorre otros 300 km hasta el mar irrigando el amplio delta del Nilo, ramificándose en varios brazos por terrenos pantanosos. El delta posee una costa con lagunas de 250 km de largo.

El Valle y el delta del Nilo están cubiertos de tierra muy fértil, generada por los limos depositados por el río durante miles de años en una gruesa capa de 10 a 12 m. Cada año, de agosto a octubre, se elevaba el nivel del Nilo, y el río vertía sus aguas inundando el valle y el delta. Después de retirarse las aguas, dejaba atrás el limo, que restauraba y fertilizaba el suelo. Tras la construcción de la gran presa de Asuán, el caudal es estable durante todo el año. En el territorio de Egipto, el Nilo no recibe afluentes permanentes. El clima que prevalece sobre el valle es muy cálido y desértico. Solo la costa tiene frecuentes lluvias. El período de vegetación, en general, no se interrumpe, y las plantas crecen durante todo el año. Estas condiciones naturales han hecho del valle del río Nilo el oasis más grande del mundo.

Además de tierra y agua de mar, Egipto está dotado de importantes sales minerales. La península del Sinaí y la costa poseen yacimientos de petróleo. En esta costa se encuentran algunas zonas de fosfatos. El oeste del delta, en la costa mediterránea posee sal de roca.

La vegetación de Egipto se limita a la zona del Delta, el valle del Nilo y los oasis del desierto. El más extendido es el árbol de coco. Otras especies de árboles autóctonos son la acacia, el Tamaris y el karob. Los árboles que proceden de otros continentes son el ciprés, el eucalipto, la mimosa, y varios árboles frutales. Los suelos aluviales de Egipto, especialmente en el Delta, son aptos para el cultivo de diversas plantas y frutas, incluidas las uvas, todo tipo de verduras, flores como el loto, el jazmín y la rosa. En las zonas desérticas, con frecuencia cada vez mayor, crecen arbustos y hierba para el ganado. El papiro, antes presente a lo largo del Nilo, ahora se encuentra en el extremo sur de Egipto.

Debido al clima del desierto de Egipto la fauna local es poco variada. Hay gacelas en el desierto, así como zorros, hienas, hipopótamos y jabalíes que habitan en diferentes áreas, principalmente en el delta y las montañas a lo largo del mar Rojo. Existen varias especies de reptiles . Los cocodrilos, antes vivían en el Bajo Egipto, ahora, en su mayoría, viven en la zona sur del Alto Egipto. Hay flamencos, águilas, buitres, pelicanos y más de 493 especies conocidas. Hay muchos insectos y escorpiones que viven en zonas desérticas. En los lagos y el Nilo, hay cerca de 70 especies de peces.

Egipto se encuentra en la zona subtropical. El clima está caracterizado por veranos cálidos y secos e inviernos templados y estables, es decir; período cálido de mayo a septiembre y frío de noviembre a marzo. La temperatura más alta en ambos períodos es causada por los vientos del norte. En las zonas costeras el rango de temperatura media máxima es de 37 °C y la mínima de 14 °C. Las grandes variaciones de temperatura son las incidencias más comunes en el desierto, con máximas diarias de 46 °C y mínimas de 6 °C durante la noche. Durante el invierno la temperatura por la noche cae a 0 °C. Las zonas con mayor humedad se encuentran a lo largo de la costa mediterránea, y el promedio de las precipitaciones es de 200 mm al año, mientras que el promedio de las lluvias en El Cairo, es de solo 26 mm por año; en las áreas naturales caen tormentas cada pocos años. La precipitación disminuye en dirección al sur, mientras que la temperatura aumenta. El Kamsin (viento tormentoso del desierto, seco y cálido) se produce en abril y mayo y alcanza velocidades de hasta 150 km/h.

La práctica totalidad del país corresponde al bioma de desierto. WWF divide el territorio de Egipto en nueve ecorregiones:

Egipto es predominantemente un país agrícola; y uno de los cultivos de mayor importancia es el algodón, aparte de la actividad agrícola de subsistencia, pues alrededor de 40 % de la fuerza laboral se dedica a las actividades agrícolas o ganaderas. La economía de Egipto se socializó tras la promulgación de una serie de leyes a comienzos de 1961. El patrón de propiedad de la tierra fue muy alterado por el Decreto de Reforma Agraria de 1952, que limitaba las explotaciones individuales a unas 80 hectáreas, cifra revisada en 1961 a cerca de 40 hectáreas, y revisada de nuevo a unas 20 hectáreas en 1969.

Las reformas copiadas del régimen soviético en la materia agrícola dadas en el período 1952-1961 y la construcción con la ayuda comunista de la presa de Asuán, han provocado una revolución agrícola que ha aumentado la producción, y las tierras requisadas por el gobierno se distribuyeron entre los campesinos "(fellahin)", pero aún hasta hoy siguen existiendo grandes diferencias económicas entre la clase media y los agricultores. Los programas gubernamentales han ampliado las zonas de cultivo mediante la regeneración, el regadío (sobre todo desde la terminación de la presa de Asuán, en 1970), y la utilización de tecnología avanzada, como equipos mecanizados y fertilizantes químicos han hecho aumentar la producción agrícola precedente; pero a su vez estos avances han desencadenado múltiples problemas, sobre todo medioambientales: Al abonarse con productos químicos y no por las crecidas del río, se está afectando el equilibrio biológico de la zona, produciéndose una salinización del suelo y apareciendo nuevas clases de insectos y parásitos.

El rendimiento de las tierras agrícolas de Egipto está entre los más altos del mundo. Egipto es uno de los principales productores mundiales de productos básicos de algodón; la producción anual de fibra de algodón era de unas 300 000 toneladas métricas, a principios de 1990. El clima cálido y la abundancia de agua permiten hasta tres cosechas al año, dando abundantes cosechas agrícolas. En los años 1990 el valor estimado anual de producción en millones de toneladas métricas, como arroz (3,9), tomates (4,7), trigo (4,6), maíz (5,2), caña de azúcar (3,1), bananas (2,5), patatas (1,8), y naranjas (1,7). También se cultiva una amplia variedad de otras frutas y hortalizas.

La principal industria ganadera de Egipto es la cría de animales de carga. El ganado a principios del decenio de 1990 incluía unos 3 millones de cabezas de ganado vacuno, 3 millones de búfalos, 4,4 millones de ovejas, 4,8 millones de cabras, 1,6 millones de asnos, y 40 millones de aves de corral.

Egipto posee importantes yacimientos de petróleo y gas, pero la industria más explotada es el turismo, ya que las pirámides y reliquias de esta civilización milenaria atraen a muchas personas todos los años. Es una de las economías más estables de la región, con un PIB por habitante de 4274 dólares (datos de OMS para 2004).
La unidad monetaria es la libra egipcia, que se divide en 100 piastras; circula con los siguientes valores:

En diferentes momentos de su historia, Egipto permitió la circulación de monedas extranjeras en su territorio, sobre todo las piezas de 8 reales españoles. Tan populares fueron estas monedas, que durante los siglos XVIII y XIX en el Gran Bazar del Cairo tenían cotización oficial por 20 "qirsh" o piastras. El primero que permitió la circulación legal de monedas extranjeras en este territorio fue el sultán Selim III. De esta manera se estampó un resello que llevaba la palabra “MISR” (Egipto) sobre piezas de reales de a ocho del rey Carlos III y Carlos IV. Con esta contramarca también se conocen monedas de otras cecas hispanoamericanas, talers de María Teresa de Austria y algunas piezas de 5 francos franceses que quedaron en Egipto después de las guerras napoleónicas (1798 – 1802). Durante el dominio de los Mamelucos también fueron marcadas diversas monedas, y más tarde en el siglo XIX se contramarcaron con fecha y ceca “MISR”. Durante el siglo XX en el Gran Bazar se acuñaron piezas de 2 y 8 reales con diferentes fechas (1920) para circular por valor de 20 y 3 piastras (2 reales). En Egipto los reales españoles eran conocidos por el nombre de “Abu Mafta”, ya que creían que las columnas de Plus Ultra eran dos cañones.

Durante los últimos 40 años, el gobierno egipcio ha adoptado estrategias que van de una economía de orden soviético a una economía de mercado, con varias variantes entre ambas, predominando por último las tendencias socialistas moderadas intentado hacer prosperar al país. Hay un sector público fuerte cuya ineficacia intenta combatir el Gobierno.

Las industrias más productivas son textil, fertilizantes y productos de caucho y cemento. Hay algo de industria pesada y varias plantas de ensamblaje de automóviles.

Los socios comerciales principales del país son EE. UU y algunos de los países de la Unión Europea (Alemania, Francia, Italia y el Reino Unido). Los cambios radicales en el anterior bloque soviético, que era el mercado principal de Egipto, han tenido un gran impacto en la economía, aunque después el país se convirtió en el segundo país en recibir ayuda de Estados Unidos, tras Israel; entre 1994 y el 2004 Egipto recibió unos 2000 millones de USD por año de ayuda de Estados Unidos.

Egipto tenía en 1990 serios desequilibrios económicos tanto internos como externos: una estructura industrial organizada por Nasser de titularidad pública, sobredimensionada, obsoleta y de muy baja productividad. Un sector agrario rígidamente controlado por el estado con precios intervenidos y deficitarios. Por último, un sector exterior deficitario y basado en las exportaciones de productos energéticos, las remesas de emigrantes, los ingresos del canal de Suez y el turismo, todo ello había sostenido el desarrollo en la década de 1970, pero era sensible al nuevo terrorismo de los integristas islámicos. Asimismo, el déficit público era prácticamente insostenible y generador de inflación y el país apenas podía hacer frente a la situación surgida tras la explosión de la crisis de la deuda en los años ochenta, que tan seriamente afectó a casi todos los países en vías de desarrollo. En 1991, el gobierno elaboró un programa y propuso varias medidas:


El turismo es una de las principales fuentes de ingreso de divisas de Egipto, tanto por los turistas en sí mismos como por las importantes inversiones realizadas por cadenas internacionales de hoteles.
Por la naturaleza de la actividad turística, genera un número muy importante de puestos de trabajo, los cuales incluyen personal de: Agencias de turismo, Hoteles, fabricación y comercialización de artesanías, transportes, entre otras.
Se pueden identificar tres zonas principales donde se localiza la actividad turística:


En 2008 esta rama de la economía, junto con la pesca, constituyó un 13,4 % del PIB. Antes de la industrialización, la mayoría de los productos exportados eran agrícolas, pero ese número se reduce significativamente después de 1998 a solo el 6 %. Los productos agrícolas más importantes son el algodón, cereales, frutas, hortalizas y forraje. Área de la tierra cultivable es considerablemente más pequeño, pero muy fructífero. Ocupa el espacio alrededor de todo el valle y el delta del Nilo Occidental. La pesca es un sector económico importante. Grandes cantidades de pescado se encuentra en el río Nilo, el mar Rojo y el Mediterráneo.

Los servicios y productos industriales (minería, manufactura y construcción) componían el 37,6 % del PIB de 2008. Los principales productos son los textiles, productos químicos, metales y los productos derivados del petróleo. La nueva política económica ha conducido a la creación de empresas privadas para la producción de automóviles, la electrónica y la medicina. La mayoría de estas fábricas se concentran alrededor del centro de las dos mayores urbes: El Cairo y Alejandría y en la zona industrial a lo largo del Canal de Suez.

El petróleo es el producto más importante y una gran e importante fuente de ingresos. El Gobierno en la década de 80 alentó la producción de gas natural para abastecer a los consumidores de energía doméstica. El gas natural comenzó a exportarse en los 90. Los principales campos de petróleo y gas están ubicados en el mar Rojo y el desierto de Libia. En cuanto a otras riquezas minerales, Egipto tiene abundantes menas de fosfatos, sal, caliza y mineral de hierro.

Egipto produce la energía suficiente para satisfacer las necesidades de todos los consumidores locales. Las principales fuentes de energía son de origen hidroeléctrico, y se basan en su mayoría cerca de Asuán. Las cantidades de petróleo y gas natural también surten cerca de la mitad de los requerimientos energéticos de los consumidores.

El canal de Suez es un canal artificial a nivel del mar, considerado el centro de transporte marítimo más importante en el Oriente Medio, que conecta el mar Mediterráneo con el mar Rojo. Abierto en noviembre de 1869 después de 10 años de trabajo, permite el transporte en barco entre Europa y Asia sin tener que rodear África. El término norte es Port Said y el término sur es Port Tawfiq en la ciudad de Suez. Ismailia se encuentra en su lado oeste, a 3km del punto medio.

El canal tenía 193.30km de longitud, 24 m de profundidad y 205m de ancho en 2010. Se compone de un canal de acceso norte de 22km, el canal propiamente dicho de 162,25km, y el canal de acceso sur de 9km. El canal es un único carril con lugares de paso en el "Ballah By-Pass" y el Gran Lago Amargo. No contiene esclusas, el agua del mar fluye libremente por el canal. En general, el canal al norte del lago Amargo fluye al norte en invierno y al sur en verano. La parte sur de los lagos cambian con la marea de Suez.

El 26 de agosto de 2014 se realizó una propuesta para abrir un Nuevo canal de Suez. Los trabajos en el Nuevo canal de Suez se completaron en julio de 2015. El canal fue inaugurado oficialmente con una ceremonia a la que asistieron diferentes líderes internacionales el 6 de agosto de 2015, de acuerdo con el presupuesto presentado para el proyecto.

El suministro de agua potable aumentó en Egipto entre los años 1990 y 2000 del 89% al 100% en las áreas urbanas y del 39% al 93% en las áreas rurales, a pesar del rápido crecimiento de la población. En este período, Egipto consiguió erradicar la costumbre de defecar en letrinas en las áreas rurales e invirtió en las infraestructuras necesarias para hacerlo. El acceso a fuentes de agua potable en Egipto ahora es prácticamente universal con una estimación del 99%. Alrededor de la mitad de la población está conectada a sistemas de recogida de aguas residuales.

Debido a la baja cobertura de recogida de basuras, alrededor de entre 30 a 120 niños mueren cada año a causa de enfermedades virales tales como la diarrea, el dengue y la malaria.


Egipto tiene dos compañías aéreas para vuelos internos: Egyptair y Air Sinai. Las distancias son cortas y los billetes asequibles. Es frecuente la cancelación de vuelos por distintos motivos.
En la actualidad hay 20 aeropuertos, el más importante el Aeropuerto Internacional de El Cairo, donde se realizan 190 000 vuelos con más de 13 millones de pasajeros.

Egyptair vuela diariamente entre El Cairo y Alejandría, Luxor, Assuán, Abu Simbel y Hurgada; dos veces por semana a los oasis de Jarga, y realiza unos 300 vuelos semanales conectando Egipto con las principales ciudades del mundo. Air Sinaí vuela desde El Cairo a El Arish Sharm el Sheik, Monasterio de Santa Catalina y Tel Aviv.


Hay ocho puertos con tráfico internacional, siendo el de Alejandría el principal, junto a los de Dammietta, Port Said, Suez y algunos otros en el mar Rojo.

Por las aguas del río Nilo navegan no menos de 60 cruceros. Además de los cruceros-restaurantes, hay cruceros de cinco días y cuatro noches (entre Luxor y Assuán, de tres, cuatro y cinco estrellas) y cruceros de tres días (a través del lago Nasser). En junio estas embarcaciones van al varadero de El Cairo para su reparación y vuelven a Luxor en septiembre. Las falucas son barcos veleros muy comunes en el río.


La red ferroviaria es de las más antiguas, con 9826 km de vías que conectan el 75 % de las ciudades de todo el país. Los trenes egipcios son confortables, puntuales, rápidos y baratos. Unen El Cairo con el valle del Nilo, el delta y las ciudades del canal. Hay cuatro tipos de servicio: primera, segunda, tercera clase y Wagon-Lits (coche cama con dirección a Luxor y Assuán). Se puede reservar billete en agencias de viaje o en la propia estación. Las estaciones tienen ventanillas especiales para cada clase de billete.

Los taxistas egipcios tienen fama de temerarios al volante, y los contadores se utilizan raramente, por lo que es necesario indicar el destino, pactar un precio, y pagar al llegar. Los servicios de taxis se encuentran normalmente en las estaciones de Peugeot, y no arrancan hasta que no han llenado todos sus asientos. Viajan tanto dentro de la ciudad como a cualquier punto de Egipto, incluidos los oasis. La mayoría intenta situarse en la plaza de Ramsés, plaza de Tharir y en el aeropuerto de El Cairo, para recoger turistas.

Egipto tiene una red de autobuses que recorre todo el país. Son baratos, y se modificó el sistema para garantizar a cada viajero su asiento. Hay autobuses urbanos en las ciudades grandes, como El Cairo y Alejandría.

El metro de El Cairo es limpio, cómodo y recorre todo el centro de El Cairo con las paradas a intervalos de medio kilómetro. Las estaciones de metro están indicadas por una señal octogonal negra con una M roja. Casi todo el recorrido discurre a lo largo del Nilo, por la llamada Corniche.

En las ciudades el tráfico está congestionado, especialmente en El Cairo, donde es un problema fundamental. En carretera hay pocas limitaciones, y la tranquilidad es total, aunque abundan los controles.

La red viaria consta de 50 300 km, entre autopistas y carreteras asfaltadas. La más importante es el cinturón que une El Cairo con Alejandría, donde se concentra el 70 % del movimiento de vehículos. El gobierno tiene previsto la construcción de una gran autopista que una El Cairo y Assiut a lo largo de la orilla este del Nilo y de carreteras que conecten El Cairo con Jordania, Israel y los Territorios Palestinos.

Las carreteras desde El Cairo a Alejandría, Port Said, Ismailía y Suez, son todas de cuatro carriles, y la mayoría de las que cruzan el desierto uniendo las principales ciudades están pavimentadas excepto las carreteras en dirección a Hurgada y Alto Egipto, que siguen siendo muy peligrosas, especialmente de noche. En total, la red viaria alcanza los 50 300 km. Las reparaciones no son caras y es muy fácil encontrar un mecánico. Hay agencias de alquiler de coches en los principales hoteles.



Las redes de comunicaciones son modernas: teléfono, internet, telégrafo, télex y servicios del fax están disponibles. Al enviar un mensaje a Egipto, los télex y el fax tienden a ser más fiable que los telégrafos, porque los cables no siempre se entregan. Las compañías de mensajería privada reparten en la mayoría de las ciudades egipcias. El servicio egipcio de correos varía en fiabilidad: el correo de la superficie es muy lento, por lo que se suele usar el aéreo para comunicaciones internacionales. Dentro de Egipto, el servicio del correo urgente proporcionado por la Organización Postal Nacional egipcia es considerado fiable.

Egipto es el país árabe más poblado, con más de 90.200.000 habitantes (2016), 15 000 000 de los cuales residen en El Cairo.
Otra ciudad notablemente poblada es Alejandría, junto al delta del Nilo. Cerca del 98 % de la población se concentra a lo largo del Nilo, cuyas fértiles riberas representan el 3,5 % de la superficie. La densidad de la población en las dos orillas de El Nilo es una de las más altas del mundo y su crecimiento es considerado uno de los graves problemas del país.

Los egipcios son un pueblo bastante homogéneo. Las influencias mediterránea (tales como griegos e italianos) y árabes aparecen en el norte, y poblaciones de nubios en el sur. Se han propuesto diferentes teorías sobre los orígenes de los egipcios, sin embargo, ninguna es concluyente y más ampliamente aceptada es que la sociedad egipcia fue el resultado de una mezcla de gente asiática y africana oriental que se trasladó al valle del Nilo después de la Era del Hielo. La mayor parte de la moderna sociedad egipcia es heterogénea pero mantiene los lazos culturales con la sociedad egipcia antigua, la cual ha sido siempre considerada rural y la más populosa comparada con las demografías vecinas. El pueblo egipcio hablaba solamente cinco idiomas de la familia afroasiática (previamente conocidas como hamito-semíticas).

En Egipto conviven más de 34 grupos étnicos.

Los egipcios son en su mayoría descendientes de los antiguos egipcios, la población que se asentó en el noreste de África. Cerca de 4000 jinetes árabes islámicos entraron en Egipto. Los inmigrantes árabes comenzaron a mezclarse con la población local, surgiendo matrimonios entre las comunidades árabe y autóctona. También hay descendientes de otros pueblos invasores, como los romanos, griegos y turcos.

Los grupos indígenas nubios viven en el norte de Sudán y el sur de Egipto. Muchos pueblos nubios quedaron inundados por el lago Naser, cerca de Asuán, tras lo cual sus habitantes se trasladaron a Asuán y a El Cairo. El gobierno no los reconoce como una minoría étnica. Hay otras minorías étnicas en Egipto, como los beduinos árabes de la península del Sinaí, del desierto árabe, y la población bereber del oasis de Siwa. Un pequeño número de griegos, italianos, judíos y otras minorías cristianas se mezclan con la población musulmana local.

Egipto tiene una población de 500 000 a 3 000 000 de refugiados y solicitantes de asilo. Hay alrededor de 70 000 refugiados palestinos y 150 000 refugiados iraquíes. El mayor número de refugiados proviene de Sudán, y se estima entre 2 y 5 millones.


Si bien Egipto tuvo sus propias lenguas que evolucionaron durante los periodos egipcio antiguo y egipto antiguo clásico, y posteriormente el copto, estas tres lenguas fueron reemplazadas en este último periodo por su actual idioma oficial, el Árabe egipcio, idioma que se ha mantenido como oficial desde la edad media, moderna y contemporánea. La versión egipcia de la lengua árabe (Masri) es dominante en el mundo árabe, gracias a la excepcional importancia que Egipto tiene en los medios de comunicación y la educación en este idioma.

El árabe egipcio ha adoptado elementos de la lengua egipcia desde tiempos pre-islámicos, así como del Turco, Francés e Inglés.

En la región nubia es hablado el idioma nubio antiguo. La lengua bereber se utiliza en varios asentamientos en los oasis del desierto occidental. Los cristianos coptos utilizan el idioma copto para servir a la liturgia. En las escuelas egipcias se enseña el inglés y el francés.

La religión oficial en Egipto es el islamismo suní, al que pertenece el 85 % de la población.<ref name="The world factbook/Egypt/"></ref><ref name="U.S.Dept of State/Egypt"></ref><ref name="FCO/Egypt/"></ref><ref name="LOOKLEX Encyclopedia/Egypt/Religions&Peoples"></ref> El segundo grupo religioso más grande son cristianos coptos, que representan el 10 % de la población total. Un 1 % corresponde a otras minorías religiosas cristianas, como son los cristianos armenios, católicos y protestantes.

En Egipto también vivían judíos, aunque en pequeño número de gran importancia económica. Estos abandonaron Egipto después de 1956, cuando las fuerzas armadas de Israel, Francia y Gran Bretaña atacaron el país.

A principios de los años ochenta perteneció a los soldados de los grupos islámicos y de la Jihad Islámica. En 1992 comenzó una campaña de violencia armada, centrado en El Cairo y el Alto Egipto, cuyo objetivo era establecer un gobierno basado en la estricta ley islámica. Las víctimas de la violencia fueron principalmente fieles de la Iglesia Copta, funcionarios gubernamentales y turistas. Organización de Derechos Humanos determinó que el gobierno egipcio ejerció la discriminación contra la Iglesia copta. Las leyes relativas a la construcción de iglesias y la práctica abierta de la religión han disminuido recientemente, pero el trabajo de construcción importante en las iglesias aún requiere permiso del gobierno.

Hay dos clases principales. Los primeros son la élite, con educación de influencia occidental, de clase alta y media. Al segundo grupo, que es mucho más humilde, pertenecen los agricultores, la población urbana y la clase obrera. Existen enormes diferencias en el estilo de vida, hábitos, alimentación, vestimenta, etc. En 1970 el gobierno ha introducido políticas económicas liberales conocida como la "puerta abierta". Esta política es más demanda por el primer grupo, porque conecta con la cultura y el capital extranjero.

En el pasado, las mujeres de las clases bajas trabajaban en los campos con sus maridos, a fin de mantener a su familia, mientras que las mujeres de las clases más altas se mantenían en las casas, porque sus maridos mantenían a la familia. Hoy en día, muchas mujeres trabajan fuera del hogar, y usan pañuelos cubriéndose la cabeza para recordar que son musulmanas.

Los platos más comunes en la cocina egipcia son molojeya (una hierba tradicional local preparada como una sopa)[mahshi] kushari (pasta con la cebolla y varias hierbas), frutas y hortalizas frescas. El té o el café es el complemento alimenticio usual. Los egipcios ricos, además, en su gastronomía suelen incluir platos europeos, principalmente de la cocina francesa.

El rápido crecimiento demográfico ha saturado el sistema educativo. Las aulas están repletas, desde las escuelas primarias hasta las universidades, aunque las escuelas carecen de material adecuado para realizar un buen trabajo de educación. Muchos niños asisten a la escuela de forma irregular, o no asisten porque tiene que trabajar. Se estima, en 2005, que el 71,4 % de la población sabe escribir, aunque repartido en 83 % de hombres y 59,4 % de mujeres.

El informe de 2006 sobre la salud en el mundo publicado por la OMS, arroja los siguientes datos:

En las principales ciudades del país se encuentran médicos con un buen nivel, algunos de ellos con formación en el extranjero y que hablan francés e inglés. Por lo que se refiere al tratamiento en los hospitales, el mismo es aceptable para tratamientos de dolencias e infecciones leves. En casos graves y en aquellos que requieran cirugía, lo más recomendable es viajar al extranjero, ya que los equipamientos de los hospitales son bastante deficientes. Es común que los hospitales y médicos exijan el pago en efectivo por adelantado si no existe el respaldo de una compañía aseguradora y los gastos médicos suelen ser, para los extranjeros, muy onerosos. Asimismo es recomendable que dicho seguro médico incluya la repatriación para casos de urgencia.

En los barcos turísticos que navegan por el Nilo, no suele haber médico a bordo, aunque sí suelen disponer de un botiquín para primeros auxilios en los que se pueden encontrar remedios para los males menores más comunes. En la ruta turística del Nilo, solamente en Luxor y Asuán se encuentran hospitales con limitadas garantías.

Hay enfermedades contagiosas:

Más del 90% de la población femenina sufre ablación de sus genitales, según la encuesta del Ministerio de Sanidad (2015). El sondeo de 2015, realizado por varias instituciones nacionales y extranjeras para el Ministerio egipcio de Sanidad, muestra también que esta práctica está más extendida entre las mujeres procedentes del medio rural (95%) que del medio urbano (86%). Más de la mitad de las mujeres fueron mutiladas cuando tenían entre siete y diez años, según la encuesta en Egipto, donde esta práctica es una tradición arraigada tanto entre musulmanes como cristianos.

Los egipcios construyeron monumentos y complejos funerarios para sus faraones y grandes templos, con obeliscos en los cuales grabaron los títulos y alabanzas del faraón, con pinturas representando la vida divina o terrenal de este. También esculpieron grandes estatuas pétreas representando a dioses y faraones, y pequeñas piezas de orfebrería, con metales y piedras preciosas, y labores de artesanía realizadas en piedra, fayenza o delicadamente talladas en madera. Desarrollaron su propio sistema de escritura, los jeroglíficos, con sus variantes: la escritura hierática y posteriormente la demótica, simplificando su grafía. El egipcio fue de los primeros pueblos en entrar en la Historia, dejando a la posteridad tratados de medicina, matemáticas y relatos mitológicos e históricos, escritos en papiros o grabados en piedra o madera.
Durante el período faraónico, la cultura egipcia mantuvo sus características fundamentales hasta la época de dominación romana, influyendo culturalmente en todo el Mediterráneo occidental. Los últimos sacerdotes de Isis, en la isla de File, mantuvieron su culto hasta que fue prohibido por el emperador romano Justiniano I, en el año 535 de la era común. Alejandría, capital de la Dinastía Ptolemaica –sede de la célebre Biblioteca–, fue durante siglos el más importante centro cultural del Mediterráneo y preferente lugar de estancia y estudio de muchos grandes pensadores de la antigüedad.

Egipto cristiano: la Iglesia copta fue fundada en Egipto en el siglo I. Su nombre deriva de la palabra griega (egipcio), trasformado en "gipt" y después en "qibt", de donde derivó la respectiva voz árabe. Así pues, la palabra copto significa simplemente ‘egipcio’. El cristianismo impuesto por los emperadores romanos sustituyó las creencias anteriores hasta la época de la dominación islámica. Sus patriarcas ejercieron notable influencia sobre el resto de la cristiandad. Las manifestaciones artísticas de este período egipcio se denominan arte copto. El idioma copto es la lengua descendiente de la hablada en el Antiguo Egipto. Dejó de usarse en el siglo XVI, aunque se sigue utilizando como lengua litúrgica. Tiene un alfabeto propio.

Tras la invasión árabe, la cultura egipcia se ha diluido en la árabe: ello supone el fin de la escultura y de la pintura, pero un gran desarrollo de la literatura y de la protección a las ciencias: Maimónides vivió en Egipto como refugiado al ser desterrado de Córdoba.

El arte islámico importado se desarrolló con influencias locales, sobre todo a partir de los Fatimíes, y ha creado conjuntos arquitectónicos de gran belleza, que se pueden ver en El Cairo, en la necrópolis de Asuán, las casas y mezquitas de Rosetta, etc.

Los adornos de madera, metal, y cristal de roca diferencian la arquitectura egipcia del resto de la islámica. Bajo los mamelucos se desarrollaron alminares de fustes superpuestos y cúpulas decoradas con gallones, y aparecieron edificios diferentes: mezquitas funerarias y madrasas. De esta etapa son la mezquita de Baybars (circa 1269) o la madrasa del sultán Hasan (circa 1360). Especialistas en vidrio esmaltado hicieron lámparas que se vendieron por todo el mundo. La llegada de los otomanos trajo la imposición de los modelos de Estambul.

A finales del siglo XX, el Estado construyó una gran biblioteca para recordar la de Alejandría.

La música ha formado parte de la vida egipcia desde la antigüedad, aunque no queda ningún escrito sobre ella, se le supone tradición oral.
Entre los distintos instrumentos, se conocen el sistro, el menat, etc. Durante la dinastía lágida surge el órgano hidráulico y la flauta. En 1930 se creó en El Cairo el Instituto de Música Oriental, que protege un gran número de compositores que coordinan la música tradicional con la de origen europeo. Sus principales exponentes son: Uum Kulthum, Farid Al Atrash, George Abdo, Mohammad Abdel Wahab, Abdel Halim Hafez, y los más actuales Amr Diab, Hakim, Ehab Tawfik, entre otros.

La primera obra de teatro árabe moderno se llevó a cabo en El Cairo, en el año 1870. La película apareció en la década de 1930 en Egipto, y desde entonces está en constante crecimiento. El Cairo es considerado el "Hollywood del Medio Oriente", que se celebra cada año el Festival Internacional de Cine. La industria del cine egipcio es considerado el más grande en el mundo árabe. En Alejandría se formó un núcleo de productores que crearon las bases del cine egipcio: dramas y actualidad, que en los años treinta se trasladó a El Cairo.

La primera película egipcia fue "Laila" (1927), producida e interpretada por la actriz Aziza Amir. El cine sonoro llegó en 1932, y el estreno de la primera película fue un fracaso, debido a errores técnicos. Hubo que esperar a 1936, con el estreno de "Wedad". Los géneros del cine egipcio moderno son variados, musicales, cine realista, con una enseñanza cinematográfica que es la mejor del Oriente medio, aunque con medios técnicos pobres.

La industria de los medios de comunicación de Egipto ha florecido, con más de treinta canales por satélite y más de un centenar de imágenes producidas cada año.

Los medios de comunicación egipcios son muy influyentes en todo el mundo árabe, atribuidos a grandes audiencias y cada vez más libres del control gubernamental. La libertad de los medios de comunicación está garantizada en la constitución; Sin embargo, muchas leyes aún restringen este derecho.

Egipto se considera a menudo el hogar de la danza del vientre. La danza del vientre egipcia tiene dos estilos principales - raqs baladi y raqs sharqi. También hay numerosas danzas folklóricas y de carácter que pueden formar parte del repertorio de bailarinas de estilo belga, así como la moderna danza callejera shaabi que comparte.

En cuanto a sus alimentos típicos existe una gama de entrantes fríos de procedencia oriental que se sirven en numerosas escudillas de pequeño tamaño, entre las que se encuentran:
Otros platos típicos son:


Todos estos platos se sirven acompañados de "pilau", arroz con verduras.

Los postres preferidos por los egipcios son:
Las bebidas típicas egipcias son:
La mayor parte de la población egipcia profesa el islamismo y no consume bebidas alcohólicas, pero existe una importante minoría copta (cristiana) que mantiene la milenaria tradición de su elaboración, cultivo y consumo. Entre las bebidas alcohólicas destacan: "ersoos", licor de fuertes sabor y olor; "zahlab", considerada la "bebida de los dioses" ya que esta hecha de una planta parecida a la Jamaica con alcohol, que solo crecía alrededor del valle de los reyes; "yasoon", con sabor a anís. Entre los vinos destacan: "Chateu Giniclis", tinto. Una buena variedad de blancos: "Rubi d’Egyte", rosado. No son de excelente calidad pero resultan aceptables.

Las comidas de los turistas se acompañan normalmente con agua. Las autoridades recomiendan que sea agua mineral y que la botella se abra en presencia del turista. También recomiendan beber la cerveza local "Stella" (o cervezas de importación).

El fútbol es el deporte más popular en Egipto. A nivel de clubes, destacan el Al-Ahly y el Zamalek, dos de los clubes más exitosos a nivel local e internacional. El Al-Ahly fue elegido como el mejor club africano del siglo XX, además de ser el que más títulos internacionales posee, con 19 trofeos.

La selección nacional es conocida por el apodo de "faraones". Es además la selección más fuerte de su continente, ya que ha sido vencedora de la Copa Africana de Naciones en siete veces, siendo la que más veces la ha ganado.

El baloncesto es otro deporte que también le ha dado éxitos al país, donde la selección local ha logrado ganar cinco veces el Afrobasket.





</doc>
<doc id="1095" url="https://es.wikipedia.org/wiki?curid=1095" title="Ethernet">
Ethernet

Ethernet (pronunciado /ˈiːθərnɛt/ en inglés) es un estándar de redes de área local para computadores con acceso al medio por detección de la onda portadora y con detección de colisiones (CSMA/CD). Su nombre viene del concepto físico de "ether". Ethernet define las características de cableado y señalización de nivel físico y los formatos de tramas de datos del nivel de enlace de datos del modelo OSI.

Ethernet se tomó como base para la redacción del estándar internacional IEEE 802.3, siendo usualmente tomados como sinónimos. Se diferencian en uno de los campos de la trama de datos. Sin embargo, las tramas Ethernet e IEEE 802.3 pueden coexistir en la misma red.

En 1970, mientras Norman Abramson montaba la gran red ALOHA en Hawái, un estudiante recién graduado en el MIT llamado Robert Metcalfe se encontraba realizando sus estudios de doctorado en la Universidad de Harvard trabajando para ARPANET, que era el tema de investigación candente en aquellos días. En un viaje a Washington, Metcalfe estuvo en casa de Steve Crocker (el inventor de los RFC de Internet) donde este lo dejó dormir en el sofá. Para poder conciliar el sueño Metcalfe empezó a leer una revista científica donde encontró un artículo de Norm Abramson acerca de la red Aloha. Metcalfe pensó cómo se podía mejorar el protocolo utilizado por Abramson, y escribió un artículo describiendo un protocolo que mejoraba sustancialmente el rendimiento de Aloha. Ese artículo se convertiría en su tesis doctoral, que presentó en 1973. La idea básica era muy simple: las estaciones antes de transmitir deberían detectar si el canal ya estaba en uso (es decir si ya había 'portadora'), en cuyo caso esperarían a que la estación activa terminara. Además, cada estación mientras transmitiera estaría continuamente vigilando el medio físico por si se producía alguna colisión, en cuyo caso se pararía y retransmitiría más tarde. Este protocolo MAC recibiría más tarde la denominación Acceso Múltiple con Detección de Portadora y Detección de Colisiones, o más brevemente CSMA/CD ("Carrier Sense Multiple Access / Collision Detection").

En 1972 Metcalfe se mudó a California para trabajar en el Centro de Investigación de Xerox en Palo Alto llamado Xerox PARC (Palo Alto Research Center). Allí se estaba diseñando lo que se consideraba la 'oficina del futuro' y Metcalfe encontró un ambiente perfecto para desarrollar sus inquietudes. Se estaban probando unas computadoras denominadas "Alto", que ya disponían de capacidades gráficas y ratón y fueron consideradas los primeros ordenadores personales. También se estaban fabricando las primeras impresoras láser. Se quería conectar las computadoras entre sí para compartir ficheros y las impresoras. La comunicación tenía que ser de muy alta velocidad, del orden de megabits por segundo, ya que la cantidad de información a enviar a las impresoras era enorme (tenían una resolución y velocidad comparables a una impresora láser actual). Estas ideas que hoy parecen obvias eran completamente revolucionarias en 1973.

A Metcalfe, el especialista en comunicaciones del equipo con 27 años de edad, se le encomendó la tarea de diseñar y construir la red que uniera todo aquello. Contaba para ello con la ayuda de un estudiante de doctorado de Stanford llamado David Boggs. Las primeras experiencias de la red, que denominaron 'Alto Aloha Network', las llevaron a cabo en 1972. Fueron mejorando gradualmente el prototipo hasta que el 22 de mayo de 1973 Metcalfe escribió un memorándum interno en el que informaba de la nueva red. Para evitar que se pudiera pensar que solamente servía para conectar computadoras "Alto" cambió el nombre de la red por el de Ethernet, que hacía referencia a la teoría de la física hoy ya abandonada según la cual las ondas electromagnéticas viajaban por un fluido denominado éter que se suponía llenaba todo el espacio (para Metcalfe el 'éter' era el cable coaxial por el que iba la señal). Las dos computadoras "Alto" utilizadas para las primeras pruebas de Ethernet fueron rebautizadas con los nombres "Michelson" y "Morley", en alusión a los dos físicos que demostraron en 1887 la inexistencia del éter mediante el famoso experimento de Michelson y Morley.

La red de 1973 ya tenía todas las características esenciales de la Ethernet actual. Empleaba CSMA/CD para minimizar la probabilidad de colisión, y en caso de que esta se produjera se ponía en marcha un mecanismo denominado retroceso exponencial binario para reducir gradualmente la ‘agresividad’ del emisor, con lo que este se adaptaba a situaciones de muy diverso nivel de tráfico. Tenía topología de bus y funcionaba a 2,94 Mb/s sobre un segmento de cable coaxial de 1,6 km de longitud. Las direcciones eran de 8 bits y el CRC de las tramas de 16 bits. El protocolo utilizado al nivel de red era el PUP (Parc Universal Packet) que luego evolucionaría hasta convertirse en el que luego fue XNS (Xerox Network System), antecesor a su vez de IPX (Netware de Novell).

En vez de utilizar el cable coaxial de 75 ohms de las redes de televisión por cable se optó por emplear cable de 50 ohms que producía menos reflexiones de la señal, a las cuales Ethernet era muy sensible por transmitir la señal en banda base (es decir sin modulación). Cada empalme del cable y cada 'pincho' vampiro (transceiver) instalado producía la reflexión de una parte de la señal transmitida. En la práctica el número máximo de 'pinchos' vampiro, y por tanto el número máximo de estaciones en un segmento de cable coaxial, venía limitado por la máxima intensidad de señal reflejada tolerable.

En 1975 Metcalfe y Boggs describieron Ethernet en un artículo que enviaron a Communications of the ACM (Association for Computing Machinery), publicado en 1976. En él ya describían el uso de repetidores para aumentar el alcance de la red. En 1977 Metcalfe, Boggs y otros dos ingenieros de Xerox recibieron una patente por la tecnología básica de Ethernet, y en 1978 Metcalfe y Boggs recibieron otra por el repetidor. En esta época todo el sistema Ethernet era propiedad de Xerox.

Conviene destacar que David Boggs construyó en el año 1975 durante su estancia en Xerox PARC el primer router y el primer servidor de nombres de Internet.

Ethernet se tomó como base para la redacción del estándar internacional IEEE 802.3, siendo usualmente tomados como sinónimos. Se diferencian en uno de los campos de la trama de datos. Sin embargo, las tramas originales Ethernet e IEEE 802.3 pueden coexistir en la misma red.

Los estándares de este grupo no reflejan necesariamente lo que se usa en la práctica, aunque a diferencia de otros grupos este suele estar cerca de la realidad.

La primera versión del IEEE 802.3 fue un intento de estandarizar ethernet aunque hubo un campo de la cabecera que se definió de forma diferente, posteriormente ha habido ampliaciones sucesivas al estándar que cubrieron las ampliaciones de velocidad (Fast Ethernet, Gigabit Ethernet y el de 10 Gigabits), redes virtuales, hubs, conmutadores y distintos tipos de medios, tanto de fibra óptica como de cables de cobre (tanto par trenzado como coaxial).

La trama es lo que se conoce también por el nombre de "frame". 


Hace ya mucho tiempo que Ethernet consiguió situarse como el principal protocolo del nivel de enlace. Ethernet 10Base2 consiguió, ya en la década de los 90s, una gran aceptación en el sector. Hoy por hoy, 10Base2 se considera como una "tecnología de legado" respecto a 100BaseT. Hoy los fabricantes ya han desarrollado adaptadores capaces de trabajar tanto con la tecnología 10baseT como la 100BaseT y esto ayuda a una mejor adaptación y transición.

Las tecnologías Ethernet que existen se diferencian en estos conceptos entre ellos:

A continuación se especifican los anteriores conceptos en las tecnologías más importantes:

Los elementos de una red Ethernet son: tarjeta de red, repetidores, concentradores, puentes, los conmutadores, los nodos de red y el medio de interconexión. Los nodos de red pueden clasificarse en dos grandes grupos: equipo terminal de datos (DTE) y equipo de comunicación de datos (DCE).

Los DTE son dispositivos de red que generan el destino de los datos: los PC, las estaciones de trabajo, los servidores de archivos, los servidores de impresión; todos son parte del grupo de las estaciones finales. Los DCE son los dispositivos de red intermediarios que reciben y retransmiten las tramas dentro de la red; pueden ser: conmutadores (switch), routers, concentradores (hub), repetidores o interfaces de comunicación. Por ejemplo: un módem o una tarjeta de interfaz.



Ethernet se planteó en un principio como un protocolo destinado a cubrir las necesidades de las redes de área local (LAN).

A partir de 2001, Ethernet alcanzó los 10 Gbit/s lo que dio mucha más popularidad a la tecnología. Dentro del sector se planteaba a ATM como la total encargada de los niveles superiores de la red, pero el estándar 802.3ae (Ethernet Gigabit 10) se ha situado en una buena posición para extenderse al nivel WAN.



</doc>
<doc id="1098" url="https://es.wikipedia.org/wiki?curid=1098" title="Erupciones históricas de Tenerife">
Erupciones históricas de Tenerife

Relación de las erupciones de las cuales se tiene registro histórico en la Isla de Tenerife:



</doc>
<doc id="1100" url="https://es.wikipedia.org/wiki?curid=1100" title="Escalada">
Escalada

La escalada, en montañismo, es una actividad que consiste en realizar ascensos sobre paredes de fuerte pendiente, valiéndose de la fuerza física y mental propia. Se considera escalada todo ascenso ya sea fácil, difícil o imposible de realizar (según el estado físico de la persona) con las extremidades inferiores (pies y piernas; en algunos casos también se podría llegar a utilizar la rodilla, por si hubiera alguna pared al lado) y las extremidades superiores (brazos y manos). En la escalada hay alturas que implican un peligro considerable y con el objetivo de tener seguridad se utiliza equipo de protección.

En origen, la escalada aparece como una actividad derivada del montañismo. Entonces se consideraba solo como un medio de entrenamiento para los recorridos de montaña. Fue en el siglo XIX cuando la actividad nació en Alemania del Este (Dresde) y en Inglaterra (el distrito de los Lagos).

A lo largo de un siglo, el material evolucionó al ritmo de las actuaciones de los escaladores y a la inversa. Las vías de dificultades crecientes aparecieron con los tiempos: 1913, nivel 5 ; 1917, nivel 6 ; 1970, nivel 7 ; 1983, nivel 8 ; 1991, nivel 9... La existencia de rocódromos a partir de los años 1960 dio un auténtico empuje a la evolución de la disciplina.

La escalada se considera, a menudo, como un deporte de riesgo, aunque conviene distinguir diferentes prácticas. Habitualmente, se practica con un equipo que permite evolucionar con seguridad, pero existe una práctica más extrema llamada "solo integral", donde el escalador evoluciona sin ninguna seguridad. Esta práctica en particular ha sido popularizada por las películas de Jean-Paul Janssen, "La vie au bout des doigts" ("La vida en la punta de los dedos", 1982) y "Opéra Vertical", en las que Patrick Edlinger evoluciona en solitario en sitios como los faros de Buoux y las Gargantas de Verdon.

Y al ser la escalada una disciplina sin normas escritas, se pueden diferenciar los tipos de escalada según su filosofía o ética:


De cada uno de los medios en que se escale depende las técnicas y el equipo a emplearse. El equipo y técnicas difieren mucho entre la escalada en hielo y la escalada en roca. En cambio, no hay mucha diferencia de técnica básica entre la escalada en roca y la de rocódromo, por lo que el rocódromo se utiliza muchas veces como entrenamiento. Sin embargo, la escalada en roca exige muchos más recursos físicos, técnicos y de equipo que la de rocódromo.

Se emplean únicamente las manos y los pies como elementos de progresión. El casco es un elemento recomendable. Suelen utilizarse los denominados pies de gato. Son un tipo de calzado que se adapta muy bien a los pies. Su suela es lo suficientemente gruesa para que no se perfore con ningún objeto, y está fabricada en goma cocida, lo que proporciona adherencia, siempre que la roca no esté húmeda. Por esta razón, no conviene escalar en ciertos lugares por la mañana, debido al rocío que humedece la pared. En esta modalidad de escalada libre está "prohibido" descansar colgándose de los seguros entre las reuniones, y si el escalador se cae tiene que repetir el largo desde el principio.

Escalada alpina. Es la escalada en alta montaña. Requiere ser un escalador experto, debido a las complicaciones que podrían darse, como la capacidad física, falta de seguros fijos, roca no fiable, condiciones meteorológicas, descenso complicado, etc.

Escalada en hielo. Se realiza en las paredes en que se forman cascadas de hielo. Es una de las más peligrosas. Se progresa con herramientas específicas: piolets y crampones, y para asegurarse se usan los tornillos de hielo.

Escalada mixta (roca y hielo). 

Dentro de la "escalada libre", se incluirían la escalada deportiva y la escalada clásica, siempre y cuando en esta última no exista ningún tramo de la vía ascendido con técnicas de escalada artificial.

La escalada clásica (o tradicional) persigue hacerse de la manera tradicional alpina, es decir, subir una vía por la que el primero de la cordada va instalando los seguros, ya sea en anclajes naturales (árboles, puentes de roca, puntas de roca) o en anclajes artificiales recuperables (clavos, nudos empotrados, fisureros, friends...).Generalmente, las fijaciones para escalada clásica se instalan en grietas (mayor sencillez), como los "friends", fisureros, pitones... Ocasionalmente, se colocan seguros que ofrecen mejores garantías, fundamentalmente por permitir una tracción multidireccional: tacos de expansión autoperforantes -conocidos popularmente como SPITS-. Si bien requieren un tiempo de instalación mucho mayor (hay que perforar manualmente un agujero de unos 3 cm de profundidad en la roca compacta, usando la propia cabeza dentada del taco como broca y el martillo de escalador como percutor), ofrecen una resistencia mayor y, en combinación con un conjunto de conectores (chapa o anilla de anclaje + mosquetón) conforman un anclaje artificial con mayor eficacia para detener una caída que las fijaciones para fisuras. El taco en sí no es recuperable, a diferencia de las fijaciones para fisuras, aunque sí lo es la chapa o anilla que lleva para unirse al mosquetón. Retirada ésta (chapa o anilla), en pared solo queda el orificio de la rosca hembra del taco.
Generalmente, en la escalada clásica se evita instalar anclajes de expansión (como Spits y Parabolts), aunque se ven a menudo en pasajes delicados o difícilmente protegibles de forma muy natural.

Estilo de escalada que, como sistema de seguridad, utiliza anclajes previamente fijados a la pared mediante sistemas mecánicos -"de expansión"- o químicos -"resinas epoxi"- colocados estratégicamente a lo largo de la vía, lo que permite ampliar las posibilidades de escalada a las placas de roca compacta carentes de aristas o fisuras. Estos anclajes ("chapas") sirven para asegurar a los escaladores de modo más polivalente que un "friend" o un "fisurero," lo que permite concentrarse mucho más en la técnica o en algunos pasos difíciles. La escalada deportiva se caracteriza por reducir notablemente el riesgo del escalador, a cambio de aumentar el nivel de dificultad (el grado de la vía). Generalmente, esta modalidad busca zonas relativamente accesibles y con paredes no necesariamente muy altas, en las que se equipan vías marcadas de diferentes grados de dificultad. Los grados de dificultad en la escalada deportiva se miden desde 5.6 (principiante) hasta el 5.15 (profesional). Por lo general, antes de equiparse, estas vías se "limpian" de maleza y de piedras sueltas o susceptibles de romperse, para ganar en la seguridad del escalador deportivo. La escalada de esta modalidad suele buscar la dificultad por sí misma, y la belleza de movimientos.

El tipo de escalada "deportivo" es idéntico al desarrollado en rocódromos, salvo que estos últimos utilizan "presas artificiales" para conformar los agarres que la roca provee de modo natural. Las presas están hechas de resinas sintéticas, con buena adherencia e imitando formas naturales según la dificultad que se quiera lograr, aunque tienen el inconveniente de gastarse paulatinamente, volviéndose lisas. Este problema se acentúa si no se utiliza una zapatilla apropiada. Se suelen aducir motivos éticos para prohibir o censurar la alteración del medio natural con el fin de facilitar la ascensión. Por tanto, en caso de no tener suficiente nivel para escalar determinada vía, se recomienda buscar otra de menor nivel en lugar de alterarla artificialmente. 

La escalada deportiva surgió de la evolución de la escalada tradicional, buscando forzar el encadenamiento de las vías en estilo totalmente libre sin ningún tipo de apoyo artificial, de ahí su carácter deportivo. Corrientes éticas y filosóficas de aquellos orígenes que ayudan a comprender como se desarrolló su evolución fueron el Rotpunkt y el Freeclimbing. Este tipo de escalada será incluida como deporte olímpico a partir de Tokio 2020.

La escalada de grandes paredes o "big wall" suele durar varios días, por lo que se tienen que subir hamacas para dormir, víveres, etc. Para este tipo de escaladas se usan técnicas de escalada artificial, aunque últimamente se están realizando grandes y largas escaladas íntegramente en libre. Se precisa de alimento para uno o dos días y el mínimo material, ya que su peso dificultará aún más la ascensión de la vía.

En la escalada artificial se emplean todo tipo de material como fisureros y pitones para ayudar a subir y no solo como protección; es decir, el material puede usarse también para progresar. En ausencia de presas naturales, se colocan fijaciones (del tipo adecuado a la carga y condiciones de la roca) a las que se sujetan estribos escalonados, que servirán al escalador para ir ascendiendo. Es un tipo de escalada lento y laborioso, donde además se precisa usar mucho material. Constituye la única forma de alcanzar determinados lugares, siendo muy usado -por ejemplo- por los espeleólogos para explorar ventanas colgadas en paredes y techos de las cuevas.

Solo integral (también se conoce por escalada natural). La famosa escalada sin cuerda ni seguros ni ningún tipo de protección que pueda salvar al escalador si comete un error y se cae.
En casi todos los casos en los que el escalador o escaladora realiza un solo integral, lo hace en vías que conoce bien. Además, para este tipo de ascensiones habitualmente se escogen rutas muy por debajo del nivel de dificultad del escalador en cuestión, a pesar de lo espectacular que pueden parecer al profano. De esta manera se minimiza en lo posible el riesgo de caída, supeditado más a una rotura de la roca o un resbalón inesperado que a la dificultad técnica que la vía pueda plantear. Lógicamente, sigue siendo una práctica desaconsejada, por la posibilidad de que cualquier imprevisto tenga un desenlace fatal. Pero descarga mucha adrenalina.

En la actualidad, podemos diferenciar una gran variedad de tipos de escalada. Sin embargo, ninguna vertiente de la escalada posee un grado de peligrosidad tan elevado como el que ofrece la escalada en solo, ya que la primera y principal característica de esta vertiente es la de escalar en altura sin cuerda alguna ni ningún otro tipo de seguridad adicional. El escalador que escale en solo, debe tener una forma física y una técnica excelentes; y además debe aguantar la presión psicológica de conciencia de la dualidad entre la vida (llegar a la cima) y la muerte (caída mortal). Por lo general, la mayoría de los que escalan en solo, suelen basarse en el principio de progresión para disminuir ligeramente los riesgos, de manera que suelen hacer algún o algunos intentos con cuerda o línea de vida antes de ascender en solo. Esto ayuda al escalador a conocer el manejo y desarrollo de la técnica que requerirà la vía en cuestión y le permite conocer el grado de esfuerzo y concentración así como la voluntad que va a tener que desarrollar para completar la vía y alcanzar la cima. A pesar de todas las precauciones que se puedan tomar, la escalada en solo se considera uno de los deportes más peligrosos, ya que el escalador se juega la vida en cada ascenso. 

Se denomina escalada en solitario a escalar autoasegurado con una cuerda, pero sin compañero. Existen distintas técnicas para autoasegurarse, desde la clásica de los nudos (en la que el escalador va atándose a nudos a medida que progresa), hasta los modernos aparatos de autoseguro (Silent Partner, Soloist, Soloaid). La técnica consiste en fijar un cabo de la cuerda en la base de la vía (ya sea a un anclaje natural, como un árbol o puente de roca; ya sea a un anclaje de expansión, si la vía está equipada), y subir instalando seguros por los que pasamos la cuerda, que está unida al escalador mediante los nudos o los aparatos mencionados.
Esta modalidad requiere del doble de tiempo para escalar, puesto que obliga a descender en rapel para recuperar la cuerda (fijada abajo) y los seguros, y volver a subir el tramo para comenzar el siguiente.

Bulder, del inglés "Boulder": escalada en bloque. Es una forma de solo integral en la que el escalador nunca sube bastante alto como para que una caída pueda suponerle problemas graves. Es decir, se sube un bloque de unos pocos metros, por lo general con la caída asegurada con una colchoneta (crash pad) que evite golpes o un compañero atento a la caída. El Boulders se puede hacer sobre roca o sobre una superficie artificial de madera tipo plywood, a la cual se le abren huecos con un barreno. Para sujetar las presas se usa un tipo de rosca llamada peanut, que ayuda a que la presa no se mueva a los lados. Los Boulders también pueden ser de materiales plásticos y de roca pura. Lo principal es que no sean muy altos, para caer suavemente en la colchoneta.

Una de las últimas tendencias del búlder es el psicobloc, que se realiza en acantilados que tienen paredes con el desplome suficiente como para no golpearse en una de las habituales caídas con algún saliente de roca. Aquí la protección pasiva es el agua.
Pese a parecer una práctica segura, la altura de algunos acantilados hace que no sea raro ver muñecas, tobillos y costillas rotas por el golpe contra el agua. Esto sin considerar la cantidad de medusas que se pueden ver en algunos de los lugares más habituales de psicobloc, como Mallorca.

La técnica de progresión, que es común a todos los tipos de escalada, es el siguiente:

El primero de la cordada sube haciendo uso de "agarres" o "presas" y "apoyos" naturales, para agarre de manos y apoyos de pies, respectivamente, y va colocando los seguros -caso de la escalada clásica- o anclándose a ellos -caso de la escalada deportiva-. Según coloca o se ancla a cada fijación preferentemente al nivel de su cintura (cuanto más alto se coloque mayor será la posible caída) y pasa la cuerda con cuyo chicote va atado por uno de los mosquetones enlazados por una cinta que unirá la cuerda a la fijación (el conjunto de dos mosquetones unidos por una cinta se conoce como "cinta exprés"). 

Mientras tanto, el segundo de la cordada asegura al primero fijando su cuerda anclándola, mediante un mosquetón y un dispositivo de freno, en la base de la cordada o en un lugar intermedio de reunión, estrangulando la cuerda y bloqueándola en caso de caída. En el caso de una caída, el último punto de anclaje la detendrá. La energía de la caída la absorben los elementos de la cadena de seguridad, tales como la elasticidad de la cuerda, las cintas que la conecten a las fijaciones, el dispositivo de freno (si es dinámico), los arneses de los escaladores y, en último caso, sus cuerpos.

El segundo de la cordada sube asegurado desde arriba por el primero, usando la misma cuerda, pero expuesto a una caída de una altura mucho menor. En la escalada clásica, y si el segundo es el último que sube, debe retirar las fijaciones que sean recuperables ("friends", clavos, fisureros, cintas en anclajes naturales...) y los elementos posibles en las fijaciones artificiales (como las chapas o anillas de conexión en los tacos autoperforantes).

Una vez alcanzado el final de la escalada, se pueden usar varias técnicas para el descenso. En escalada de varios largos, y si no se puede descender a pie por una ruta alternativa, se deberá usar la técnica de rapel. Si la vía es de un solo largo, el escalador se podrá descolgar desde la reunión, pudiendo dejar la cuerda colocada para que el segundo escale en tope-rope (con la cuerda por arriba).

El equipo dependerá del tipo de escalada. Si es escalada deportiva, se necesita arnés, zapatos para escalada (pie de gato), mosquetones, cintas exprés o anillas, sistemas de frenado o seguro (ATC, grigri, reverso, etc.), cuerda dinámica, puño ascensor, y algo muy importante que muchos escaladores han olvidado: casco. 
Para escalada artificial y/o escalada interior o clásica, se requiere además de diversos materiales (fisureros -también llamados empotradores, stoppers o nueces-, friends, etc.), según la ruta que se desea subir.
La mayoría de los escaladores usa magnesio contra el sudor, aunque en determinados lugares protegidos (como parques naturales, etc) está expresamente prohibido por las autoridades porque mancha temporalmente la roca.

Para escalar, siempre se utilizan una serie de elementos para la seguridad: arnés, cintas exprés, mosquetones (normales o de seguridad), cuerda dinámica, magnesio, pies de gato, cinta larga, grigri, casco etc. Es muy importante llevar el material adecuado para cada tipo de escalada, teniendo en cuenta el tipo de roca, la graduación del sector donde se vaya a escalar y el estado de los anclajes existentes, verificar el grado de oxidación, etc. Hay que llevar siempre algo más de material, para posibles emergencias.

En escalada de rocódromo necesitaremos el material mínimo: arnés, cuerda, pies de gato, cintas exprés, dispositivo de freno (preferiblemente uno automático o semiautomático, tipo gri-gri, etc). Para la escalada deportiva en vías equipadas con anclajes fijos necesitaremos poco más: es habitual un cabo para usarlo de autoseguro en las reuniones y algo que muchos escaladores han olvidado: casco. Para escalada artificial y/o escalada clásica se requiere además de diversos materiales (fisureros, friends, empotradores, uñas, plomos, etc.) variando mucho en función de la ruta elegida (tipo de roca, tipo de emplazamientos para anclajes, ética determinada de la zona...).

Podemos clasificar el equipo de escalada 

Podemos diferenciar entre 2 tipos de fijaciones: las recuperables (empleadas sobre todo en escalada clásica, alpina y BigWall) y las no recuperables, empleadas especialmente en deportiva.

Las fijaciones usadas en la técnica deportiva pueden ser los tacos autoperforantes comentados en el apartado de escalada clásica, pero el uso cada vez más asequible de potentes taladros autónomos permite instalar fijaciones más profundas (al no ser necesario abrir el agujero a mano) que ofrecen más garantías. Es el caso de los pernos de expansión, conocidos como "parabolts", y de los pernos químicos. 

En los "parabolts", se trata de un tornillo roscado de hasta 15 cm de longitud, a lo largo del cual se intercala una o varias cuñas tronco-cónicas que se expanden contra una camisa exterior y ésta, a su vez, contra las paredes del agujero (similar a como sucede con un taco de expansión autoperforante). En el extremo roscado del tornillo que aflora de la roca se coloca la chapa o anilla de conexión, siendo posible utilizar el punto de anclaje al instante de haberlo colocado, motivo por el cual ha ganado adeptos en los terrenos de exploración donde es factible llevar un taladro autónomo en el equipo, como determinadas campañas espeleológicas.

Los pernos químicos se adhieren a la roca mediante un adhesivo, generalmente a base de resinas epoxi: se taladra el agujero en el cual, convenientemente limpio, se introduce la resina (existe variedad de formas de aplicación, como pistola de inyección o cápsulas pre-dosificadas) y luego el perno: básicamente una varilla con corrugas en el cuerpo -que se agarran a la resina- terminada en una argolla para el mosquetón. El perno, también llamado tensor, suele ser de materiales muy durables, como acero bicromatado o inoxidable.

Este sistema de instalación precisa de un tiempo de fraguado tras su colocación antes de poder ser usado, que varía según el ligante usado y las condiciones climatológicas. Asimismo, es el que ofrece mayor durabilidad y resistencia del anclaje, y puede ser colocado en multitud de rocas, incluso en rocas blandas que no permitirían el uso de anclajes de expansión. Es considerado hoy día el mejor tipo de anclaje sobre roca, con el inconveniente de la necesidad de un tiempo de fraguado previo a la utilización.

"" Graduación de dificultad.

La dificultad de una escalada se puede graduar utilizando distintos sistemas métricos. Estos sistemas varían según la región (francés, yosemite, inglés..) o el tipo de escalada (libre, artificial, en hielo, psicobloc). En España el sistema más habitual para la escalada en roca es la mezcla de la graduación UIAA y la francesa. Para las vías de menor dificultad se emplea el sistema UIAA (números romanos del I al V con + ó - para afinar más), para saltar después a la graduación francesa (6,7,8,9 con subíndices a, b o c y un + o - para ajustar más aún).




</doc>
<doc id="1101" url="https://es.wikipedia.org/wiki?curid=1101" title="Espacio vectorial">
Espacio vectorial

En álgebra abstracta, un espacio vectorial es una estructura algebraica creada a partir de un conjunto no vacío, una operación interna (llamada "suma", definida para los elementos del conjunto) y una operación externa (llamada "producto por un escalar", definida entre dicho conjunto y otro conjunto, con estructura de cuerpo), con 8 propiedades fundamentales.

A los elementos de un espacio vectorial se les llama vectores y a los elementos del cuerpo, escalares.

Históricamente, las primeras ideas que condujeron a los espacios vectoriales modernos se remontan al siglo XVII: geometría analítica, matrices y sistemas de ecuaciones lineales. 

Los espacios vectoriales se derivan de la geometría afín a través de la introducción de coordenadas en el plano o el espacio tridimensional. Alrededor de 1636, los matemáticos franceses Descartes y Fermat fundaron las bases de la geometría analítica mediante la vinculación de las soluciones de una ecuación con dos variables a la determinación de una curva plana. Para lograr una solución geométrica sin usar coordenadas, Bernhard Bolzano introdujo en 1804 ciertas operaciones sobre puntos, líneas y planos, que son predecesores de los vectores. Este trabajo hizo uso del concepto de coordenadas baricéntricas de August Ferdinand Möbius de 1827. 

La primera formulación moderna y axiomática se debe a Giuseppe Peano, a finales del siglo XIX. Los siguientes avances en la teoría de espacios vectoriales provienen del análisis funcional, principalmente de espacios de funciones. Los problemas de Análisis funcional requerían resolver problemas sobre la convergencia. Esto se hizo dotando a los espacios vectoriales de una adecuada topología, permitiendo tener en cuenta cuestiones de proximidad y continuidad. Estos espacios vectoriales topológicos, en particular los espacios de Banach y los espacios de Hilbert tienen una teoría más rica y elaborada.

El origen de la definición de los vectores es la definición de Giusto Bellavitis de bipoint, que es un segmento orientado, uno de cuyos extremos es el origen y el otro un objetivo. Los vectores se reconsideraron con la presentación de los números complejos de Argand y Hamilton y la creación de los cuaterniones por este último (Hamilton fue además el que inventó el nombre de vector). Son elementos de R y R; el tratamiento mediante combinaciones lineales se remonta a Laguerre en 1867, quien también definió los sistemas de ecuaciones lineales.

En 1857, Cayley introdujo la notación matricial que permite una armonización y simplificación de las aplicaciones lineales. Casi al mismo tiempo, Grassmann estudió el cálculo baricéntrico iniciado por Möbius. Previó conjuntos de objetos abstractos dotados de operaciones. En su trabajo, los conceptos de independencia lineal y dimensión, así como de producto escalar están presentes. En realidad el trabajo de Grassmann de 1844 supera el marco de los espacios vectoriales, ya que teniendo en cuenta la multiplicación, también, lo llevó a lo que hoy en día se llaman álgebras. El matemático italiano Peano dio la primera definición moderna de espacios vectoriales y aplicaciones lineales en 1888.

Un desarrollo importante de los espacios vectoriales se debe a la construcción de los espacios de funciones por Henri Lebesgue. Esto más tarde fue formalizado por Banach en su tesis doctoral de 1920 y por Hilbert. En este momento, el álgebra y el nuevo campo del análisis funcional empezaron a interactuar, en particular con conceptos clave tales como los espacios de funciones p-integrables y los espacios de Hilbert. También en este tiempo, los primeros estudios sobre espacios vectoriales de infinitas dimensiones se realizaron.

Los espacios vectoriales tienen aplicaciones en otras ramas de la matemática, la ciencia y la ingeniería. Se utilizan en métodos como las series de Fourier, que se utiliza en las rutinas modernas de compresión de imágenes y sonido, o proporcionan el marco para resolver ecuaciones en derivadas parciales. Además, los espacios vectoriales proporcionan una forma abstracta libre de coordenadas de tratar con objetos geométricos y físicos, tales como tensores, que a su vez permiten estudiar las propiedades locales de variedades mediante técnicas de linealización.

Dado un espacio vectorial formula_1 sobre un cuerpo formula_2, se distinguen.

Los elementos de formula_1 como:

Los elementos de formula_2 como:
Un espacio vectorial sobre un cuerpo formula_2 (como el cuerpo de los números reales o los números complejos) es un conjunto formula_10 no vacío, dotado de dos operaciones para las cuales será cerrado:

operación interna tal que:

y la operación producto por un escalar:

operación externa tal que:

La denominación de las dos operaciones no condiciona la definición de espacio vectorial por lo que es habitual encontrar traducciones de obras en las que se utiliza "multiplicación" para el "producto" y "adición" para la "suma", usando las distinciones propias de la aritmética.

Para demostrar que un conjunto formula_32 es un espacio vectorial:





 = \mathit{1} \\

Si formula_43 formula_44


Notación

Observación

Se quiere probar que formula_61 es un espacio vectorial sobre formula_62

Si formula_61 juega el papel de formula_64 y formula_62 el de formula_2:

Los elementos:

son, de forma genérica:

es decir, pares de números reales. Por claridad se conserva la denominación del vector, en este caso u, en sus coordenadas, añadiendo el subíndice x o y para denominar su componente en el eje x o y respectivamente

En formula_10 se define la operación suma:

donde:

y la suma de u y v sería:

donde:

esto implica que la suma de vectores es interna y bien definida.

La operación interna suma tiene las propiedades:

1) La propiedad conmutativa, es decir:

2) La propiedad asociativa:

3) tiene elemento neutro formula_87:

4) tenga elemento opuesto:

La operación producto por un escalar:

El producto de a y u será:

donde:

esto implica que la multiplicación de vector por escalar es externa y aun así está bien definida.

5) tenga la propiedad asociativa:

Esto es:

6) formula_101 sea elemento neutro en el producto:

Que resulta:

Que tiene la propiedad distributiva:

7) distributiva por la izquierda:

En este caso tenemos:

8) distributiva por la derecha:

Que en este caso tenemos:

Queda demostrado que es espacio vectorial.

Todo cuerpo es un espacio vectorial sobre él mismo, usando como producto por escalar el producto del cuerpo.


Todo cuerpo es un espacio vectorial sobre su subcuerpo, usando como producto por escalar el producto del cuerpo.


El espacio vectorial más conocido notado como formula_126, donde "n">0 es un entero, tiene como elementos "n"-tuplas, es decir, sucesiones finitas de formula_125 de longitud "n" con las operaciones:

Las sucesiones infinitas de formula_128 son espacios vectoriales con las operaciones:

El espacio de las matrices formula_129, formula_130, sobre formula_128, con las operaciones:

También son espacios vectoriales cualquier agrupación de elementos de formula_125 en las cuales se defina las operaciones suma y producto entre estas agrupaciones, elemento a elemento, similar al de matrices formula_129, así por ejemplo tenemos las cajas formula_136 sobre formula_125 que aparecen en el desarrollo de Taylor de orden 3 de una función genérica.

El conjunto formula_138 de las aplicaciones formula_139, formula_128 un cuerpo y formula_141 un conjunto, también forman espacios vectoriales mediante la suma y la multiplicación habitual:

formula_143

El espacio vectorial "K"[x] formado por funciones polinómicas, veámoslo:

Las series de potencias son similares, salvo que se permiten infinitos términos distintos de cero.

Las funciones trigonométricas forman espacios vectoriales con las siguientes operaciones:

formula_163 o equivalentemente formula_164 simplificado como formula_165

Un sistema de ecuaciones lineales homogéneas( ecuaciones lineales en las que formula_166 es siempre una solución, es decir, formula_167) posee soluciones que forman un espacio vectorial, se puede ver en sus dos operaciones:

También que las ecuaciones en sí, filas de la matriz formula_172 notadas como una matriz formula_173, es decir, formula_174, son un espacio vectorial, como se puede ver en sus dos operaciones:

Sea formula_32 un espacio vectorial sobre formula_125, y formula_181 no vacío, formula_182 es un subespacio vectorial de formula_32 si:

formula_182 hereda las operaciones de formula_32 como aplicaciones bien definidas, es decir que no escapan de formula_182, y como consecuencia tenemos que formula_182 es un espacio vectorial sobre formula_125.

Con cualquier subconjunto de elementos seleccionados en los espacios vectoriales anteriores, no vacío, se pueden generar subespacios vectoriales, para ello seria útil introducir nuevos conceptos que facilitarán el trabajo sobre estos nuevos espacios vectoriales.

Para detallar el comportamiento interno de todos los espacios vectoriales de modo general es necesario exponer una serie de herramientas cronológicamente vinculadas entre ellas, con las cuales es posible construir resultados válidos en cualquier estructura que sea espacio vectorial. 

Dado un espacio vectorial formula_191, diremos que un vector "u" es combinación lineal de los vectores de formula_192 si existen escalares formula_193 tales que

Notaremos como formula_194 el conjunto resultante de todas las combinaciones lineales de los vectores de formula_195.

Dado formula_191 un espacio vectorial y formula_197 un conjunto de vectores, el conjunto formula_198 es el subespacio vectorial más pequeño contenido en formula_191 y que contiene a formula_200.

Diremos que un conjunto formula_203 de vectores es linealmente independiente si el vector 0 no se puede expresar como combinación lineal no nula de los vectores de formula_200, es decir:

Diremos que un conjunto formula_200 de vectores es linealmente dependiente si no es linealmente independiente.

formula_207 son linealmente dependientes formula_208

Las "bases" revelan la estructura de los espacios vectoriales de una manera concisa. Una base es el menor conjunto (finito o infinito) "B" = {v} de vectores que generan todo el espacio. Esto significa que cualquier vector v puede ser expresado como una suma (llamada "combinación lineal") de elementos de la base
donde los "a" son escalares y v ("k" = 1, ..., "n") elementos de la base "B". La minimalidad, por otro lado, se hace formal por el concepto de independencia lineal. Un conjunto de vectores se dice que es linealmente independiente si ninguno de sus elementos puede ser expresado como una combinación lineal de los restantes. Equivalentemente, una ecuación 
solo se consigue si todos los escalares "a", ..., "a" son iguales a cero. Por definición de la base cada vector puede ser expresado como una suma finita de los elementos de la base. Debido a la independencia lineal este tipo de representación es única. Los espacios vectoriales a veces se introducen desde este punto de vista.

Dado un sistema de generadores, diremos que es una base si son linealmente independientes.

Todo sistema de generadores tiene una base.

Toda base de un espacio vectorial puede ser cambiada parcialmente por vectores linealmente independientes.

Todo espacio vectorial tiene una base. Este hecho se basa en el lema de Zorn, una formulación equivalente del axioma de elección. Habida cuenta de los otros axiomas de la teoría de conjuntos de Zermelo-Fraenkel, la existencia de bases es equivalente al axioma de elección. El ultrafilter lemma, que es más débil que el axioma de elección, implica que todas las bases de un espacio vectorial tienen el mismo "tamaño", es decir, cardinalidad. Si el espacio es generado por un número finito de vectores, todo lo anterior puede demostrarse sin necesidad de acudir a la teoría de conjuntos.

Dado un espacio vectorial sobre formula_220:

Dado un espacio vectorial formula_191 y un subespacio formula_222, tenemos que:



Dado dos subespacios vectoriales formula_230, la intersección es subespacio vectorial contenido en estos y lo notaremos como:

La unión de subespacios vectoriales no es en general un subespacio vectorial.

Dado dos subespacios vectoriales formula_232, la suma es un subespacio vectorial que contiene a estos y la notaremos como:

Si F y G son subespacios vectoriales de E, su suma F+G es el subespacio vectorial de E más pequeño que contiene a F y a G.

Dado dos subespacios vectoriales formula_232 de dimensión finita, tenemos el resultado siguiente:

Dados dos subespacios vectoriales formula_232, diremos que formula_237 es una "suma directa" si formula_238 y lo notaremos como:

Cuando formula_240 y formula_241 están en suma directa, cada vector de formula_242 se expresa de forma única como suma de un vector de formula_240 y otro vector de formula_241.

Dado un espacio vectorial formula_245 y un subespacio vectorial formula_246.

Dados formula_247 diremos que están relacionados módulo formula_248 si formula_249.


Llamaremos conjunto cociente o espacio cociente al conjunto de las clases de equivalencia anterior:

El espacio formula_254 es un espacio vectorial con las operaciones siguientes:

Además de lo expuesto en los ejemplos anteriores, hay una serie de construcciones que nos proporcionan espacios vectoriales a partir de otros. Además de las definiciones concretas que figuran a continuación, también se caracterizan por propiedades universales, que determina un objeto "X" especificando las aplicaciones lineales de "X" a cualquier otro espacio vectorial.

Dado dos espacios vectoriales formula_257 sobre un mismo cuerpo formula_125, llamaremos suma directa al espacio vectorial formula_259formula_260, veamos que están bien definidas las dos operaciones:

Desde el punto de vista del álgebra lineal, los espacios vectoriales se comprenden completamente en la medida en que cualquier espacio vectorial se caracteriza, salvo isomorfismos, por su dimensión. Sin embargo, los espacios vectoriales "ad hoc" no ofrecen un marco para hacer frente a la cuestión fundamental para el análisis de si una sucesión de funciones converge a otra función. Asimismo, el álgebra lineal no está adaptada "per se" para hacer frente a series infinitas, ya que la suma solo permite un número finito de términos para sumar. Las necesidades del análisis funcional requieren considerar nuevas estructuras.

Un espacio vectorial es normado si está dotado de una norma.

Un espacio métrico es un espacio vectorial dotado de una aplicación distancia.

Toda distancia inducida por la norma es una distancia.

Dada una topología formula_266 sobre un espacio vectorial formula_267 donde los puntos sean cerrados y las dos operaciones del espacio vectorial sean continuas respecto dichas topología, diremos que:

Un espacio de Banach es un espacio normado y completo.

Un espacio prehilbertiano es un par formula_271, donde formula_191 es un espacio vectorial y formula_273 es un producto a escalar.

Un espacio de Hilbert es un espacio prehilbertiano completo por la norma definida por el producto escalar.

Son aplicaciones entre espacios vectoriales que mantienen la estructura de los espacios vectoriales, es decir, conservan las dos operaciones y las propiedades de estas de uno a otro de dichos espacios.

Dado dos espacios vectoriales formula_191 y formula_138, sobre un mismo cuerpo, diremos que una aplicación formula_276 es lineal si:






</doc>
<doc id="1102" url="https://es.wikipedia.org/wiki?curid=1102" title="Epaminondas (juego)">
Epaminondas (juego)

Epaminondas es un juego abstracto creado por Robert Abbott en 1975. Es una versión ampliada y mejorada del juego 'Crossings' publicado en 'A Gamut of Games', por Sid Sackson. Es jugado por dos jugadores en un tablero de 12x14 cm. Cada jugador dispone de 28 piezas de color diferente a las del contrario.

El concepto de claridad aplicado a un juego abstracto significa la facilidad con que los jugadores pueden ver cómo va la partida, cuáles son las posiciones fuertes, dónde existen debilidades, qué piezas están amenazadas y, en general, la transparencia con que se manifiesta la estructura del propio juego. Según su autor, esta es la mayor virtud (y no la única) del juego Epaminondas, llamada así en honor del famoso general tebano a quien se atribuye la invención de la formación militar denominada falange.

La siguiente figura muestra la colocación inicial de las fichas.

Los jugadores alternan sus turnos para jugar.

Hay dos posibilidades básicas de movimiento: o mover una ficha sola como el rey en el ajedrez (es decir, a una cualquiera de las ocho casillas adyacentes que esté desocupada), o mover dos o más fichas a la vez, siempre que constituyan una falange.

Una falange es un alineamiento de fichas del mismo bando, contiguas, situadas en una misma línea horizontal, vertical o diagonal; puede desplazarse en esa misma línea de formación (hacia adelante o hacia atrás) tantas casillas como fichas contiene, como máximo. Cuando una falange se mueve, las fichas que la forman deben desplazarse manteniendo sus posiciones relativas, una tras otra, siempre en la dirección original de la falange y sin poder pasar sobre ninguna casilla ocupada. Puede moverse solo parte de una falange, pero nunca más casillas que fichas de la misma se desplazan.

Si en su movimiento la primera ficha de una falange llega a una casilla ocupada por una pieza enemiga, se detiene en ella inmediatamente y la ficha enemiga es capturada y retirada del tablero. Si esta ficha contraria fuera la primera de una falange enemiga de menor longitud que la atacante y situada en la misma línea de movimiento, sería capturada la falange completa. 

Una falange no puede capturar falanges enemigas de longitud igual o mayor a ella misma; por tanto, una ficha sola (que puede ser considerada como una falange mínima) no puede en ningún caso capturar.

Una misma ficha puede pertenecer a la vez a varias falanges.

El objetivo del juego es llegar a tener en la última fila del tablero (que es la primera del enemigo) más fichas propias que las que el contrario tenga en nuestra primera fila al comienzo de un turno propio.


</doc>
<doc id="1103" url="https://es.wikipedia.org/wiki?curid=1103" title="Epistemología jurídica">
Epistemología jurídica

La epistemología jurídica entra en la reflexión sobre el conocimiento del derecho, se trata de dilucidar si este conocimiento es posible, qué forma o estructura ha de tener, cuáles son sus maneras de presentarse en las sociedades, etc. El conocimiento se ha definido como la relación que el hombre establece con la realidad para producir en el alma el objeto cognitivo (Demócrito, 460- Larroyo, 1972 y Gonzáles de Ibarra Juan de Dios 1997)

Una epistemología es un método de conocer, es un método de conocimiento; si queremos sistematizar un conocimiento sobre el derecho debemos sistematizar el método de obtenerlo; esta cuestión es importante porque ha marcado a lo largo de la historia los diferentes modelos de conocimiento sobre el derecho, dicho de otra manera, el derecho ha tenido diferentes epistemologías a lo largo de la historia, las más importantes han sido el iusnaturalismo (derecho natural) y el iuspositivismo (derecho positivo). El derecho natural es el primer modelo espistemológico y tiene su desarrollo desde los griegos hasta el nacimiento del mecanicismo a finales del siglo XVII o comienzos del XIX, el derecho positivo sigue el modelo epistemológico científico. El primer modelo es un modelo metafísico y por ello presta mucha atención al derecho ideal, mientras que el segundo es un modelo físico y hace mucho hincapié en la medición y valoración de los hechos relacionados con el derecho.



</doc>
<doc id="1104" url="https://es.wikipedia.org/wiki?curid=1104" title="Eric S. Raymond">
Eric S. Raymond

Eric Steven Raymond (nacido el 4 de diciembre de 1957), también conocido como ESR, es el autor de La catedral y el bazar, (""The Cathedral & the Bazaar"", en inglés) y el responsable actual del " Jargon File " (también conocido como "The New Hacker's Dictionary"). Si bien con el " Jargon File " obtuvo fama como historiador de la cultura hacker, se convirtió después de 1997 en una figura líder en el Movimiento del Open Source y el Código abierto. Hoy día es uno de sus personajes más famosos y controvertidos.

Raymond es un neopagano, un confeso anarcocapitalista, y un defensor del derecho a poseer y utilizar armas de fuego. Tiene un gran interés en la ciencia ficción. Es músico amateur y cinturón negro de taekwondo.

Nacido en Boston, Massachusetts en 1957, sufre una leve parálisis cerebral congénita, Raymond vivió en tres continentes antes de establecerse en Pensilvania en 1971. Su compromiso con la cultura hacker empieza en 1976, y escribió su primer proyecto de código abierto en 1982.

Fue el coordinador del cliente de correo electrónico Fetchmail. También colaboró con los modos de edición de Emacs y coescribió porciones de la biblioteca GNU ncurses. Ha escrito una implementación en C del lenguaje de programación de parodia INTERCAL.

Es suyo el aforismo "Con los suficientes ojos, todos los errores son fáciles de encontrar". Reconoce a Linus Torvalds la inspiración de esta cita, que denomina como "Ley de Linus". La fuente principal de esta es el libro La catedral y el bazar, el cual se considera su obra más importante. Además, ESR frecuentemente escribe ensayos, muchos de tema político, que pueden encontrarse a la red. Se lo conoce más por su estilo ávido y persuasivo al escribir, que como programador.

Tras 1997, se convirtió en uno de los principales teorizadores del movimiento del código abierto y uno de los fundadores del Open Source Initiative. Tomó el papel de embajador del código abierto en la prensa, los negocios y en la cultura de masas.

Por un tiempo fue un polémico bloggero, hasta 2006 en que dejó de hacerlo, retomándolo en 2008, citando problemas judiciales como causa de su silencio.

De entre sus éxitos, hace falta destacar su contribución en la liberación del código de Netscape para acontecer el proyecto Mozilla en 1998. Se le reconoce haber llevado el código abierto a los círculos de Wall Street de una forma más efectiva que anteriores partidarios.

La figura de Eric ha estado envuelta en distintas controversias:

Se ha hecho famoso inicialmente por la adopción del Jargon File. Desde entonces, muchos hackers se han sentido insatisfechos por el control centralizado a las aportaciones del proyecto, algunas adiciones y ediciones que ha hecho, y la supresión de ciertos términos por haber sido datados (algo no común en los proyectos de diccionarios históricos). Aquellos que apoyan a Raymond argumentan que nadie ha hecho ningún caso para hacer una bifurcación del proyecto y convertirse en coordinador de esa nueva versión.

Los críticos acusan a Raymond de secuestrar el movimiento del software libre para su propia promoción personal. Se dice que a menudo ha puesto pegas a otros líderes y oradores del movimiento. Su desacuerdo con Richard Stallman y la postura de la Free Software Foundation con respecto a la ética del software libre en favor de una visión más mercantil, ha exacerbado las tensiones preexistentes a la comunidad. Incrementó la fricción haciendo una charla en Microsoft, y se dice que aceptó stock options a cambio de dar credibilidad a VANO Software.

También hubo malestar entre Raymond y los desarrolladores del núcleo Linux, después de que se rechazara la incorporación de CML2, una configuración del kernel alternativa que había desarrollado.

Además, su temperamento ha provocado tensiones con otros partidarios del código abierto, por ejemplo con Bruce Perens. Este hizo públicos en las listas de correo de Debian unos mensajes que recibió de Raymond que le hacían temer por su integridad física.

Raymond afirma que es un desarrollador principal de Linux, cosa que le ha hecho recibir muchas críticas, porque ningún código suyo ha sido aceptado nunca al núcleo Linux. Su mayor contribución en código ha sido en los proyectos fetchmail, ncurses y a los modos de edición de Emacs. Esta carencia de credenciales, provocó una respuesta a Richard Stallman al ensayo "Calla y enséñales el código". Raymond respondió a estas críticas en su ensayo "¡Toma mi trabajo, por favor!", donde argumenta que si alguien está cualificado y dispuesto a representar el código abierto en cualquier parte del mundo, él lo seguirá.

Durante el verano del 2003, Raymond expuso sus opiniones políticas en su blog: la diferencia de cociente intelectual, el terrorismo y la guerra de Irak en su blog; provocando un alud de críticas. También ha sido acusado de haber modificado el Jargon File para poder reflejar sus propias opiniones sobre la guerra.

También ha expresado la opinión de que, a diferencia de los Estados Unidos de América, Europa se colapsará en un futuro próximo por los problemas relacionados con la inmigración, especialmente la musulmana.





</doc>
<doc id="1111" url="https://es.wikipedia.org/wiki?curid=1111" title="Escudo">
Escudo

Un escudo es el arma defensiva activa más antigua utilizada para protegerse de las armas ofensivas y para un ataque.Se conoce al menos desde la época sumeria (III milenio a. C., en Mesopotamia) y será utilizada en Occidente hasta el siglo XVII, cuando las armas de fuego individuales se generalizaron, quedando así obsoleto. Comúnmente se embraza en el brazo izquierdo y ayuda a cubrir el cuerpo de los embates sin impedir la utilización del brazo derecho para contraatacar. El escudo ha sido usado por casi todas las culturas humanas para la defensa en la lucha, tanto a distancia como cuerpo a cuerpo, por su versatilidad para cubrir al luchador de las agresiones con armas arrojadas o blandidas. 

Conoció grandes modificaciones tanto en los materiales como en su forma, ya sea a través de los tiempos o por regiones geográficas, adaptándose a los cambios tecnológicos o tácticas para asegurar la máxima protección a los combatientes. Cada vez que una nueva arma de potencial letal más importante era introducida, el escudo se espesaba o la calidad de sus materiales crecía, hasta que la pólvora, que lanzaba proyectiles perforantes a gran distancia, convirtieron su uso inútil en el campo de batalla. En numerosas regiones del globo donde el sistema tribal aún persiste (Oceanía, África, etc.), los escudos eran utilizados a comienzos del siglo XX.

A partir del siglo XX, el escudo reencuentra una utilización en el seno de numerosas fuerzas de policía en la lucha antidisturbios, en la que sirve de protección contra los lanzamientos, y también como apoyo para rechazar a los manifestantes (llevado habitualmente por los policías en primera línea). Está realizado con material plástico, en general transparente, a fin de permitir la visión y simultáneamente la protección de la cara.

Otra versión moderna es usada también por fuerzas especiales o de elite particularmente para asedio y control de situaciones de toma de rehenes. Generalmente están realizados en acero reforzado y cerámica.

Cualquier objeto que permite oponer al adversario una superficie detrás de la cual se encuentra protección, puede ser llamada escudo con toda propiedad, y a veces era de «fortuna», asegurando un protección mínima con un coste mínimo. Así, las milicias helvecias disponían en los primeros tiempos de simples hatillos de paja. los escudos a cambiado con las acontecimiento y guerras historicistas

La madera prevaleció, como armazón, durante toda la Historia para su confección. Podía ser fabricado de diferentes maneras según la clase de protección del combatiente, de un simple trenzado de mimbre, ligero y resistente a la perforación como en la pelta tracia o como en numerosos modelos africanos, con una estructura gruesa de piezas formadas y unidas, como el aspis koile del hoplita; o bien podía estar hecho de una única pieza de madera esculpida como en Oceanía. En los equipamientos de los ejércitos organizados estaba recubierto, al menos, en su cara externa, de un segundo material que le confería una mejor resistencia a la penetración y le permitía guardar su integridad durante los golpes: los materiales cambian conforme modifican las tácticas de guerra

En el Imperio bizantino prevaleció el escudo ovalado. En Occidente, y a partir del siglo X, fue bastante común el de forma de almendra, atribuido a los normandos, con la punta inferior aguda para clavarlo en el suelo al hacer alto las tropas. A finales del siglo XIII hasta el siglo XVI tiende a la forma triangular equilátera. comerciar con escudos en todos los lugares del planeta.

De ordinario, los escudos se recubrían de piel y se pintaban con emblemas o signos particulares que dieron fundamento a los blasones. En el siglo XVI se emplearon rodelas metálicas con relieves e incrustaciones de gran lujo para torneos de gala, mientras que algunas divisiones de tropas de infantería las usaban de hierro o de madera recubierta con piel solo en los sitios de ciudades enemigas, perdiendo luego toda su importancia el escudo defensivo transformado exclusivamente en heráldico.

En la cultura occidental muy especialmente, el escudo ha servido de soporte para elementos identificadores del individuo que lo portaba, con la composición del escudo de armas con sus blasones, dando lugar al arte de la Heráldica.

Los escudos actuales pueden cubrir todo el cuerpo de un policía contra el impacto de balas y otros objetos pesados que se les arrojen. Comúnmente son transparentes, y también se utilizan unos parecidos a las rodelas. En algunos países asiáticos, los policías antimotines emplean escudos redondos de fibras vegetales muy resistentes.

Los escudos antiguos son:



El escudo medieval estaba principalmente constituido de:




</doc>
<doc id="1112" url="https://es.wikipedia.org/wiki?curid=1112" title="Enlazador">
Enlazador

Un enlazador (en inglés, "linker") es un programa que toma los objetos generados en los primeros pasos del proceso de compilación, la información de todos los recursos necesarios (biblioteca), quita aquellos recursos que no necesita, y enlaza el código objeto con su(s) biblioteca(s) con lo que finalmente produce un fichero ejecutable o una biblioteca.
En el caso de los programas enlazados dinámicamente, el enlace entre el programa ejecutable y las bibliotecas se realiza en tiempo de carga o ejecución del programa.


</doc>
<doc id="1113" url="https://es.wikipedia.org/wiki?curid=1113" title="Etiología">
Etiología

La etiología (αἰτιολογία) es la ciencia centrada en el estudio de la causalidad de la enfermedad. En medicina (patogénesis) se refiere al origen de la enfermedad. La palabra se usa en filosofía, biología, derecho penal, física, y psicología para referirse a las causas de los fenómenos.

Desde los tiempos de Hipócrates a los médicos se les enseña a comenzar las historias clínicas preguntando al paciente:
El médico hace partícipe al paciente, para que exprese la causa, si la sabe, de sus males.

A lo largo de la historia de la medicina, los médicos discutieron si la causa de una enfermedad era un único factor o si era el resultado de un conjunto de factores que actuaban simultáneamente. En el siglo XIX estos dos puntos de vista los representaron respectivamente Pasteur y Bernard. 

Bernard hizo hincapié en los factores ambientales, externos e internos. Y defendió la idea de la enfermedad producida por una pérdida del equilibrio interno (homeostasis) que suponía, por lo general, la concurrencia de un gran número de factores.

Pasteur centró sus esfuerzos en esclarecer el papel desempeñado por las bacterias en la aparición de una enfermedad, relacionando diferentes enfermedades con determinados microbios. Pasteur demostró la correlación que existe entre las bacterias y determinadas enfermedades, y por ello sus teorías tuvieron un impacto decisivo. 

La postura de Pasteur y sus seguidores predominó en la discusión y, como resultado, la teoría de los gérmenes -según la cual cada enfermedad era causada por un microbio específico- fue rápidamente aceptada por los profesionales de la medicina.

El concepto de etiología científica lo formuló el médico Robert Koch, quien enumeró una serie de postulados de Koch para probar si un microbio determinado causaba una enfermedad específica.

Los adelantos en el campo de la biología del siglo XIX se acompañaron del desarrollo de la tecnología médica. Se inventaron nuevos instrumentos de diagnóstico médico, entre ellos el estetoscopio y los aparatos para tomar la presión sanguínea, y la tecnología quirúrgica se volvió más sofisticada.

Ya bien entrado el siglo XX, se reconoce que la causa de las enfermedades es múltiple donde interaccionan los determinantes de la salud que son el medio ambiente, el agente y el huésped.

La etiología en el campo de la medicina se refiere principalmente al estudio de las causas de las enfermedades 

Los tres elementos necesarios para que se desarrolle una enfermedad son:

Estos tres "elementos" por sí solos no "causan" un problema. Es la concurrencia de los tres, en tiempo y espacio, lo que da como resultado una enfermedad. 
Cuando se conoce la causa o causas de una enfermedad, facilita la investigación de un tratamiento específico, o en su defecto un tratamiento para mejorar la calidad de vida del paciente.

Se considera que hay cuatro tipos básicos de factores que influyen en las causas de las enfermedades:

Según su etiopatogenia (según la causa y la fisiopatología consecuente) las enfermedades se pueden clasificar en: 





Actualmente, varias de las condiciones de salud que originan los diferentes tipos de enfermedades están codificadas en la Clasificación internacional de enfermedades, décima versión. Dicha clasificación se basa en una amplia variedad de signos, síntomas, hallazgos anormales, denuncias, circunstancias sociales y causas externas que producen daños y/o enfermedad. 



</doc>
<doc id="1117" url="https://es.wikipedia.org/wiki?curid=1117" title="Exégesis">
Exégesis

La exégesis (del griego ἐξήγησις [ek’se:ge.sis], de ἐξηγέομαι [ek.se:’ge.o.mai], ‘explicar’) "significado literal=extraer" es un concepto que involucra una interpretación crítica y completa de un texto, especialmente religioso, como el "Antiguo" y el "Nuevo Testamento" de la "Biblia", el "Talmud", el "Midrash", el "Corán", etc. Un exégeta es un individuo que practica esta disciplina, y la forma adjetiva es exegético.

La palabra "exégesis" significa ‘extraer el significado de un texto dado’. La exégesis suele ser contrastada con la eiségesis, que significa ‘insertar las interpretaciones personales en un texto dado’. En general, la exégesis presupone un intento de ver el texto objetivamente, mientras que la eiségesis implica una visión más subjetiva.

La exégesis tradicional requiere lo siguiente:

A pesar de que la utilización más extendida del término "exégesis" es para la interpretación de los textos sagrados judeocristianos, existe también el análisis de textos de otras religiones, como los del islam, e incluso de libros no religiosos.

En el campo jurídico la exégesis es uno de los métodos de hermenéutica jurídica que tuvieron su auge con el "Código napoleónico".

Básicamente la exégesis pretende limitar la acción del juez, pues luego de la revolución francesa se considera que todos los hombres son iguales. El juez en la monarquía era un instrumento importante de poder; por lo tanto estaba en la capacidad de interpretar las normas a su gusto. Desde la revolución francesa, y a través de la Declaración de los Derechos del Hombre y del Ciudadano, se considera que la ley es la emanación de la voluntad general (concepto de Rousseau). Dada la igualdad de los individuos, el juez no debía interpretar la ley pues esto sería darle más importancia a la voluntad particular del juez sobre la voluntad general.

Finalmente, la exégesis consiste en hacer una paráfrasis directa del texto; es tomar casi textualmente lo que dice la ley sin capacidad de salirse de esta.

La exégesis y el conceptualismo hicieron parte del formalismo jurídico de principios del siglo XIX.

Este método llegó a Latinoamérica a través del "Código civil" chileno realizado por el venezolano Andrés Bello (inspirado en el "Código napoleónico", en los tratados de los juristas Domat y Pothier, y en la tradición romana clásica), que luego fue fuente de inspiración para otros países, entre ellos Colombia, Nicaragua Y Venezuela.




</doc>
<doc id="1120" url="https://es.wikipedia.org/wiki?curid=1120" title="Evangelio">
Evangelio

Según la fe cristiana, el Evangelio (del latín "evangelĭum", y este del griego εὐαγγέλιον ["euangelion"], «buena noticia», propiamente de las palabras εὐ, «bien», y -αγγέλιον, «mensaje») es la narración de la vida y palabras de Jesús, es decir la "buena nueva" del cumplimiento de la promesa hecha por Dios a Abraham, Isaac y Jacob de que redimiría a su descendencia del pecado por medio de la muerte de su Hijo unigénito Jesucristo, quien moriría en expiación por el pecado de toda la Humanidad y resucitaría al tercer día para dar arrepentimiento y perdón de los pecados a todo aquel que crea en él. David profetizó que Jesús resucitaría al tercer día sin ver corrupción; David murió y su cuerpo vio corrupción y su tumba está en el monte Sion, pero Jesús resucitó al tercer día cumpliendo la profecía de su resurrección y su tumba está vacía y es conocida como el Santo Sepulcro. Este es el evangelio que predicaban los primeros discípulos de Jesús.

En un sentido más general, el término "evangelio" puede referirse a "los evangelios", que son escritos de los primeros cristianos que recogen las primigenias predicaciones de los discípulos de Jesús de Nazaret. Siendo el núcleo central de su mensaje la muerte y resurrección de Jesús. Son cuatro los evangelios contenidos en el Nuevo Testamento de la Biblia cristiana, llamados evangelios canónicos, reconocidos como parte de la Revelación por las diferentes confesiones cristianas. Son conocidos con el nombre de sus autores: Mateo, Marcos, Lucas y Juan.

La mayoría de los expertos consideran que estos cuatro evangelios fueron escritos entre los años 65 y 100 d. C., aunque otros expertos proponen fechas más tempranas.

Existen otros escritos, conocidos como evangelios apócrifos, no reconocidos como canónicos por las iglesias cristianas actuales, de manera que estos evangelios apócrifos no son aceptados como fidedignos, ni como textos inspirados por la divinidad. Pero sí fueron considerados «escritura» por algunas de las facciones en que se dividió el cristianismo durante los primeros siglos de su historia, especialmente por la corriente gnóstica, que fue la que aportó la mayor parte de estos textos, y por comunidades cristianas que conservaron una ligazón más estrecha con la tradición judía de la que surgió el cristianismo. Este último es el caso del evangelio de los hebreos y el evangelio secreto de Marcos, que diversos autores (como Morton Smith) datan como contemporáneos de los evangelios canónicos y aun como fuente de algunos de estos. Debido a este tipo de debates, hay autores que prefieren hablar de «evangelios extracanónicos», en vez de «apócrifos», para evitar un término que implica a priori la falsedad de los textos. El evangelio de Tomás es incluso datado por algunos expertos en el año 50 dC, hipótesis que lo convertiría en el más antiguo conocido.

La palabra «evangelio» es empleada por primera vez en los escritos de las primeras comunidades cristianas por Pablo de Tarso, en la primera carta a los corintios, redactada probablemente en el año 57: 

El Evangelio es el relato de vida y enseñanzas de Jesús. También habla del amor que Dios muestra a la humanidad mandando a su único Hijo Jesucristo a redimir el mundo. Es así que muere por nuestros pecados; es sepultado y al tercer día resucita de entre los muertos conforme él mismo lo había predicho. Se aparece a sus doce apóstoles (además de otras personas), durante cuarenta días. Con su muerte se restauran los lazos de amor quebrados desde la desobediencia de los primeros padres y se abren las puertas del cielo (que hasta ese momento se encontraban cerradas) en beneficio de todos aquellos que sigan su palabra, esto es "El amor a Dios por sobre todas las cosas y el amor al prójimo como a sí mismo".
Con el mismo "sentido" aparece la palabra en el evangelio de Mateo y en el evangelio de Marcos. Posiblemente esta palabra sea la traducción al griego de una expresión aramea empleada en su predicación por Jesús de Nazaret, pero no existen datos concluyentes. En total, la expresión «evangelio» es usada en 76 ocasiones en el Nuevo Testamento. Es significativo que sesenta de ellas tengan lugar en las cartas de Pablo, y que no exista ninguna mención del término en el evangelio de Juan y en el Evangelio de Lucas, aunque sí aparece en los Hechos de los Apóstoles, atribuidos a Lucas. El número de menciones de cada término es el siguiente:

Se ha especulado sobre si las comunidades cristianas helenísticas adoptaron el término «evangelio» a partir del culto al emperador. Existe en Priene una inscripción, fechada en el año 9 a. C., en que aparece esta palabra con un sentido muy similar al que después le darían los cristianos. En cualquier caso, la palabra había sido frecuentemente utilizada en la literatura anterior en lengua griega, incluyendo la primera traducción de la Biblia a este idioma, conocida como Biblia de los Setenta.

Del elevado número de evangelios escritos en la Antigüedad, solo cuatro fueron aceptados por la Iglesia y considerados canónicos. Establecer como canónicos estos cuatro evangelios fue una preocupación central de Ireneo de Lyon, hacia el año 185. En su obra más importante, "Adversus haereses", Ireneo criticó con dureza tanto a las comunidades cristianas que hacían uso de un solo evangelio, el de Mateo, como a los que aceptaban varios de los que hoy son considerados como evangelios apócrifos, como la secta gnóstica de los valentinianos. Ireneo afirmó que los cuatro evangelios por él defendidos eran los cuatro pilares de la Iglesia. «No es posible que puedan ser ni más ni menos de cuatro», declaró, presentando como lógica la analogía con los cuatro puntos cardinales, o los cuatro vientos (1.11.18). Para ilustrar su punto de vista, utilizó una imagen, tomada de Ezequiel 1, del trono de Dios flanqueado por cuatro criaturas con rostros de diferentes animales (hombre, león, toro, águila), que están en el origen de los símbolos de los cuatro evangelistas en la iconografía cristiana.

Tres de los evangelios canónicos, Marcos, Mateo y Lucas, presentan entre sí importantes similitudes. Por la semejanza que guardan entre sí se denominan sinópticos desde que, en 1776, el estudioso J. J. Griesbach los publicó por primera vez en una tabla de tres columnas, en las que podían abarcarse globalmente de una sola mirada ("synopsis", «vista conjunta»), para mejor destacar sus coincidencias. 

La historia del desarrollo de los evangelios es confusa, existiendo varias teorías acerca de su composición, como se expone a continuación. Los análisis de los estudiosos se han centrado en lo que se llama el problema sinóptico, es decir, las relaciones literarias existentes entre los tres evangelios sinópticos, Mateo, Lucas y Marcos. 

La teoría que ha obtenido el mayor consenso es la «teoría de las dos fuentes». 

Las diferencias y semejanzas entre los evangelios sinópticos se han explicado de diferentes formas. Una de las teorías no comprobadas, es la llamada «teoría de las dos fuentes». Según esta teoría, Marcos sería el evangelio más antiguo de los tres, y que habría sido utilizado como fuente por Mateo y Lucas, lo que puede explicar la gran cantidad de material común a los tres sinópticos, sin embargo, dado que los evangelios fueron escritos en tiempo y lugares diferentes, no habría sustento en ello. Entre Lucas y Mateo se han observado coincidencias que no aparecen en Marcos y que se han atribuido a una hipotética fuente Q (del alemán "Quelle", fuente) o protoevangelio Q, que consistiría básicamente en una serie de "logia" («dichos», es decir, «enseñanzas» de Jesús), sin elementos narrativos. El descubrimiento en Nag Hammadi del evangelio de Tomás, recopilación de dichos atribuidos a Jesús, contribuye a consolidar la hipótesis de la existencia de la fuente Q.

La existencia de Q fue defendida por los teólogos protestantes Weisse ("Die evangelische Geschichte kritisch und philosopisch bearbeitet", 1838), y Holtzmann ("Die Synoptischen Evangelien", 1863), y desarrollada posteriormente por Wernle ("Die synoptische Frage", 1899), Streeter ("The Four Gospels: A Study of Origins, treating of the manuscript tradition, sources, authorship, & dates", 1924), quien llegó a postular cuatro fuentes (Marcos, Q, y otras dos, que denominó M y L) y J. Schmid ("Matthäus und Lukas", 1930). Aunque para Dibelius y Bornkann pudo tratarse de una tradición oral, lo más probable es que se tratase de una fuente escrita, dada la coincidencia a menudo literal entre los evangelios de Mateo y Lucas. También se ha considerado probable que el protoevangelio Q fuera redactado en arameo, y traducido posteriormente al griego.

Si bien la fuente Q es una hipótesis de los eruditos para intentar explicar el problema sinóptico, esta colección de dichos de Jesús —también conocido modernamente como Logia— era de lectura y estudio cotidiano en la iglesia primitiva y Lucas la menciona en Hechos de los Apóstoles como “Las Palabras del Señor”. De tal forma la hipótesis de Q y de Logia adquiere sustancia.

Existen otras hipótesis que prescinden de la existencia de una fuente Q. De estas, algunas afirman la prioridad temporal de Mateo y otras consideran que Marcos fue el primer evangelio. Las más destacadas son las siguientes:





Juan es sin duda el último de los evangelios canónicos, de fecha bastante más tardía que los sinópticos. En él, los milagros no son presentados como tales sino como «signos», es decir, gestos que tienen una significación más profunda: revelar la gloria de Jesús (ver Rivas, L. H., "El Evangelio de Juan"). La hipótesis elaborada por Rudolf Bultmann ("Das Evangelium des Johannes", 1941) postula que el autor de este evangelio tuvo a su disposición una fuente, oral o escrita, sobre los «signos» de Cristo, independiente de los evangelios sinópticos, que ha sido denominada "Evangelio de los Signos", cuya existencia es meramente hipotética.

Tradicionalmente se atribuye la autoría de los evangelios a Mateo, apóstol de Jesús, a Marcos discípulo de Pedro, a Lucas, médico de origen sirio discípulo de Pablo de Tarso y a Juan, apóstol de Jesús. Sin embargo, hasta hoy no ha sido determinada aún la autoría real de cada evangelio. 

En el seno de la Iglesia Católica, el Concilio Vaticano II en su Constitución Dei Verbum señaló que «la Iglesia siempre ha defendido y defiende que los cuatro evangelios tienen origen apostólico. Pues lo que los Apóstoles predicaron por mandato de Cristo, luego, bajo la inspiración del Espíritu Santo, ellos y los varones apostólicos nos lo transmitieron por escrito, fundamento de la fe, es decir, el evangelio en cuatro redacciones, según Mateo, Marcos, Lucas y Juan».

No hay información acerca de las fechas exactas en que fueron redactados. La mayoría de los expertos considera que los evangelios canónicos fueron redactados en la segunda mitad del siglo I d. C., alrededor de medio siglo después de la desaparición de Jesús de Nazaret, aunque muchos expertos consideran que fueron redactados antes de la destrucción del Templo de Jerusalén (p. ej. J.A.T. Robinson en su libro "Redating the New Testament", J. Carrón García y J. M. García Pérez en su obra "¿Cuándo fueron escritos los evangelios?", entre otros).

También existe una minoría que propone que los evangelios fueron redactados tras la destrucción definitiva de Jerusalén durante el reinado de Adriano.

Raymond E. Brown, en su libro "An Introduction to the New Testament", considera que las fechas más aceptadas son:


Estas fechas están basadas en el análisis de los textos y su relación con otras fuentes.

En cuanto a la información que nos proporciona la arqueología, dejando aparte el papiro 7Q5 del que no se conoce el contexto, el manuscrito más antiguo de los evangelios canónicos es el llamado papiro P52, el cual contiene una breve sección del evangelio de Juan (Juan 18: 31-33,37-38). Según los papirólogos, y sobre la base del estilo adriánico de escritura, dataría de la primera mitad del siglo II, aunque no existe consenso total acerca de la fecha exacta. De todos modos, el lapso que separa la fecha de redacción tentativa del manuscrito original de Juan respecto de la del papiro P52, considerado la copia sobreviviente más antigua, es extraordinariamente breve, si se compara con la de otros manuscritos de la antigüedad preservados. Y esto se constata —en menor grado— en todos los evangelios cuyas copias más antiguas guardan menos de un siglo de diferencia respecto de la fecha estimada de redacción de sus originales.

María de Jesús de Ágreda (1602-1665), abadesa del convento de las Madres Concepcionistas de Ágreda, Soria, venerable de la Iglesia Católica, por revelación privada dio a conocer que Mateo el Evangelista habría escrito estando en Judea en lengua hebrea, el año cuarenta y dos del nacimiento de Jesucristo, a nueve años de su resurrección. Marcos el Evangelista lo habría hecho cuatro años más tarde, es decir, en el año cuarenta y seis, también en lengua hebrea, en Palestina. Lucas el Evangelista habría escrito en lengua griega en Acaya, Grecia; lo habría hecho dos años más tarde, es decir, a quince años de la muerte y resurrección de Jesús de Nazaret, y Juan el Evangelista a veinticinco años, en el año cincuenta y ocho estando en Asia Menor, Anatolia, Turquía. En cualquier caso, no se conserva ningún escrito neotestamentario redactado en arameo, sino que todos los que se conservan están en griego koiné.

La «armonización» fue un recurso utilizado cuando se buscaba la forma de «forzar» textos de los evangelios que parecen contradecirse o que no están totalmente de acuerdo entre sí, para que parezca que expresan lo mismo. De allí el nombre de «problema armónico», con el que se refería la dificultad para reunir los cuatro relatos evangélicos en uno solo.

Uno de los ejemplos más famosos fue el «Diatéssaron», nombre griego que se podría traducir como «formado por cuatro». Se trata de una obra griega escrita entre los años 165 y 170 por el autor sirio Taciano, que consiste en un solo evangelio compuesto con elementos tomados de los cuatro evangelios canónicos, y posiblemente también de alguna fuente apócrifa. Taciano eliminó las repeticiones y armonizó los textos para ocultar las posibles discrepancias que se encuentran en los evangelios.

Esa obra tuvo mucha popularidad en la Iglesia de lengua aramea, hasta llegar a convertirse en el evangelio de las Iglesias de Siria. Efrén de Siria (306-373) escribió un comentario al Diatéssaron que se conserva en la actualidad. Pero por las armonizaciones y omisiones, la obra de Taciano no refleja fielmente el texto de los evangelios. Por otra parte, al mostrar un evangelio «único», no permite ver el mensaje propio que ofrece cada uno de los evangelistas. Por esa razón, se ordenó en el siglo V que se volvieran a leer los evangelios por separado.

El «concordismo» fue otro recurso que se utilizó cuando ciertos textos bíblicos en general, que reflejan conceptos científicos de épocas en las que las ciencias estaban mucho menos desarrolladas, son presentados de manera forzada para que expresen lo mismo que dice la ciencia en la actualidad.

Estos recursos, utilizados en otros tiempos con cierta frecuencia hasta llegar a ser populares, han sido dejados totalmente de lado en la actualidad. Los evangelios recogen las predicaciones apostólicas que se desarrollaron a partir de la persona de Jesús de Nazaret, y su finalidad se vincula al anuncio de la salvación, no a la proclamación de verdades científicas en general. Esto no impide que los evangelios puedan ser analizados además como cualquier material antiguo (crítica histórico-literaria, crítica textual, etc.), pero el objetivo de su redacción se sitúa en otro plano.










</doc>
<doc id="1122" url="https://es.wikipedia.org/wiki?curid=1122" title="Estado">
Estado

El Estado es la organización política, dotada de atribuciones soberanas e independiente, que integra la población de un país. Hace referencia a la organización social política, coactiva, coercitiva y económica, conformada por un conjunto de instituciones, que tienen la atribución de regular la vida en sociedad.

Como término polisémico, designa también a todo aquel país soberano, reconocido como tal en el orden internacional, así como al conjunto de atribuciones y órganos de gobierno de dicho país.

Todo Estado está dotado de territorio, población y soberanía.

El concepto de Estado difiere según los autores, pero algunos de ellos definen el Estado como el conjunto de instituciones que poseen la autoridad y potestad para establecer las normas que regulan una sociedad, teniendo soberanía interna y externa sobre un territorio determinado. Max Weber, en 1919, define Estado moderno como una ""asociación de dominación con carácter institucional que ha tratado, con éxito, de monopolizar dentro de un territorio la violencia física legítima como medio de dominación y que, con este fin, ha reunido todos los medios materiales en manos de sus dirigentes y ha expropiado a todos los seres humanos que antes disponían de ellos por derecho propio, sustituyéndolos con sus propias jerarquías supremas”". Por ello se hallan dentro del Estado instituciones tales como las fuerzas armadas, la administración pública, los tribunales y la policía, asumiendo pues el Estado las funciones de defensa, gobernación, justicia, seguridad y otras, como las relaciones exteriores.

Probablemente la definición más clásica de Estado, fue la citada por el jurista alemán Hermann Heller que define al Estado como una ""unidad de dominación, independiente en lo exterior e interior, que actúa de modo continuo, con medios de poder propios, y claramente delimitado en lo personal y territorial"". Además, el autor define que sólo se puede hablar de Estado como una construcción propia de las monarquías absolutas ("ver monarquía absoluta") del siglo xv, de la Edad Moderna. "No hay Estado en la Edad Antigua", señala el autor.
Asimismo, como evolución del concepto se ha desarrollado el "Estado de Derecho" por el que se incluyen dentro de la organización estatal aquellas resultantes del imperio de la ley y la división de poderes (ejecutivo, legislativo y judicial) y otras funciones, como la emisión de moneda propia. 













En los Diálogos de Platón, se narra la estructura del Estado ideal, pero es Maquiavelo quien introdujo la palabra Estado en su célebre obra "El Príncipe": usando el término de la lengua italiana "«Stato»", evolución de la palabra "«Status»" del idioma latín.
Si bien puede considerarse que el deseo de mandar es innato, el ser humano ha civilizado el instinto de dominación, transformándolo en la autoridad. Y ha creado el Estado para legitimarla.

Las sociedades humanas, desde que se tiene noticia, se han organizado políticamente. Tal organización puede llamarse Estado, en tanto y en cuanto corresponde a la agregación de personas y territorio en torno a una autoridad, no siendo, sin embargo, acertado entender la noción de estado como única y permanente a través de la historia.

De una manera general, entonces, puede definírsele como la organización en la que confluyen tres elementos, la autoridad, la población y el territorio. Pero, esta noción ambigua obliga a dejar constancia de que si bien el Estado ha existido desde la antigüedad, sólo puede ser definido con precisión teniendo en cuenta el momento histórico.

Del estado de la Antigüedad no es predicable la noción de legitimidad, por cuanto surgía del hecho de que un determinado jefe (rey, tirano, príncipe) se apoderase de cierto territorio, muchas veces mal determinado, sin importar el sentimiento de vinculación de la población, generalmente invocando una investidura divina y contando con la lealtad de jefes y jefezuelos regionales. Así fueron los imperios de la antigüedad, el egipcio y el persa, entre ellos.

La civilización griega aportó una nueva noción de estado. Dado que la forma de organización política que la caracterizó correspondía a la ciudad, la polis, se acordaba a la población una participación vinculante, más allá del sentimiento religioso y sin poderes señoriales intermedios. Además, estando cada ciudad dotada de un pequeño territorio, su defensa concernía a todos los ciudadanos, que se ocupaban de lo que hoy se llama el interés nacional. 

En el régimen feudal prevalecieron los vínculos de orden personal, desapareciendo tanto la delimitación estricta del territorio como la noción de interés general. El poder central era legítimo pero débil y los jefes locales fuertes, al punto que éstos ejercían atributos propios del príncipe, como administrar justicia, recaudar impuestos, acuñar moneda y reclutar ejércitos. 

Y, finalmente, el estado moderno incorpora a la legitimidad, heredada del feudal, la noción de soberanía, un concepto revolucionario, tal como señala Jacques Huntzinger, quien atribuye el paso histórico de una sociedad desagregada y desmigajada, pero cimentada en la religión, a una sociedad de estados organizados e independientes unos de otros. 

Pero, este estado moderno, surgido de la aspiración de los reyes a desembarazarse de los lazos feudales y de la jerarquía eclesiástica, el estado – nación, la unión de un poder central, un territorio y una población alrededor del concepto revolucionario de la soberanía, habría de conocer dos formas, dos definiciones diferentes, la primera, el estado principesco y la segunda, el estado democrático.

El estado principesco, se caracterizó por el poder personal ejercido uniformemente sobre un territorio estrictamente delimitado. El príncipe era el soberano, con atribuciones internas y externas. Dentro de su territorio, cobraba impuestos y producía leyes de carácter general, aplicadas coercitivamente, mediante el monopolio de la fuerza pública. Internacionalmente, representaba y obligaba a su Estado. 

Y el estado democrático, surgido de las revoluciones inglesa, norteamericana y francesa, trasladó la soberanía del príncipe a la nación. Sus poderes fueron asumidos por organismos surgidos de consultas a la población, mediante reglas de juego previa y claramente definidas. Y al igual que en las polis griegas, el sentimiento patriótico se desarrolló y con él los de pertenencia, civismo e interés nacional. 

Sea que se practique la democracia o sólo se adhiera verbalmente a ella, el proceso histórico descrito ha llevado a la extensión del estado - nación como forma política. Los principios desarrollados en Europa y Norteamérica se propagaron con la descolonización producida durante el siglo XX y así, tal como afirma Huntzinger, se “ha llegado a universalizar el modelo de estado – nación de tal modo que el planeta, ahora, se encuentra poblado de estados.”



Existen distintas formas de organización de un Estado, pudiendo abarcar desde concepciones "centralistas" a las "federalistas" o las "autonomistas", en las que el Estado permite a las federaciones, regiones o a otras organizaciones menores al Estado, el ejercicio de competencias que le son propias pero formando un único Estado, (lo que sucede por ejemplo en Suiza, Alemania, EE. UU.)

No todos los Estados actuales surgieron de la misma manera; tampoco siguieron de una evolución, un camino inexorable y único. Esto es así porque los Estados son construcciones históricas de cada sociedad. En algunos casos surgieron tempranamente, como por ejemplo el Estado Nacional inglés. En otros casos, lo hicieron más tardíamente, como el Estado Nacional alemán. 

Los Estados pueden ser examinados dinámicamente usando el concepto de estatidad, aportado por Oscar Oszlak. Desde este punto de vista, ellos van adquiriendo con el paso del tiempo ciertos atributos hasta convertirse en organizaciones que cumplen la definición de Estado.

Estas características de estatidad enunciadas en un orden arbitrario, en el sentido de que cada Estado puede adquirir estas características no necesariamente en la secuencia indicada, son las siguientes:


Así, todos los territorios atraviesan un largo proceso hasta alcanzar esa calidad de Estado pleno. Que solo será tal en la medida que ese Estado haya logrado con éxito todos estos requisitos. Requisitos que son mínimos y necesarios para hablar de un verdadero Estado Nacional.

Todo esto hace que el Estado sea una de las más importantes formas de organización social en el mundo. Ya que en cada país y en gran parte de las sociedades se postula la existencia real o ficticia de un Estado, aunque la creación de entes supra-estatales como la Unión Europea, ha modificado el concepto tradicional de Estado, pues este delega gran parte de sus competencias esenciales en las superiores instancias europeas (económicas, fiscales, legislativas, defensa, diplomacia, ...) mermándose así la soberanía original de los Estados.

Otros grupos sociales que se consideran en la actualidad como Estados no son tales por tener tan mermadas sus capacidades y funciones en favor de otras formas de organización social.





El Poder muestra dos facetas distintas aquí en sentido "estricto" y "legitimo" en la otra cara.
En el primero es conocido como Poder estricto cuando es aludido en el sentido de fuerza coactiva, o sea aplicación pura de la fuerza. Mientras que en el segundo se lo concibe cuando es fruto del reconocimiento de los dominados. De este modo el pueblo reconoce como autoridad a una institución por excelencia y le delega su poder.



Una primera y clásica clasificación de los Estados hace referencia a la "centralización y descentralización" del Poder, diferenciándose entre "Estados unitarios" y "Estados de estructura compleja", siendo estos últimos, generalmente, las federaciones y las confederaciones, así como otros tipos intermedios.

El Derecho Internacional da también otra clasificación de los Estados según su "capacidad de obrar" en las relaciones internacionales:

El reconocimiento es un acto discrecional que emana de la predisposición de los sujetos preexistentes. Este acto tiene efectos jurídicos, siendo considerados ambos sujetos internacionales, el reconocedor y el reconocido, de igual a igual puesto que se crea un vínculo entre los dos.

Hoy en día la doctrina aceptada para el reconocimiento de los Estados es la doctrina Estrada, pragmática en tanto en cuanto un sujeto no sea molesto para la sociedad internacional no va a tener dificultad para ser reconocido. Se entiende que si un sujeto reconoce a otro se va a producir contactos entre ambos, por lo que en el momento que se inician los trámites para el establecimiento de relaciones diplomáticas se supone que existe un reconocimiento internacional mutuo. Sin embargo, la ruptura de estas relaciones diplomáticas no supone la pérdida del reconocimiento. Igualmente, una simple declaración formal también es válida para reconocer a otro Estado pese a no iniciar relaciones diplomáticas.

En el ámbito normativo, hay propuestas que apuntan a necesidad de mayor integración con la creación de un Estado global, entendido como un marco político planetario con poder coercitivo y capacidad para regular las relaciones interestatales y los focos de poder extrapolíticos, con capacidad ejecutiva, legislativa y judicial capaz de imponerse a los Estados nacionales en determinados ámbitos que no pueden ser abordados desde la óptica de la soberanía nacional (medio ambiente, terrorismo, paraísos fiscales...)

El Estado es una de las instituciones que perdura sin una evolución importante en su estructura y funcionamiento, con excepción de su crecimiento. El Estado moderno fue creado con la revolución industrial, pero el mundo y la dinámica de la sociedad ha cambiado mucho desde del siglo XIX. Por ejemplo, mientras las empresas modernas, que fueron creadas durante la revolución industrial, cambian ágilmente su dinámica cada vez que el mercado lo demanda, los Estados no cambian sus leyes de la misma forma como la sociedad lo demande (véase: cálculo económico).

El enfoque crítico difiere además entre el institucionalismo y el clasismo como factor determinante de la naturaleza del Estado. Algunas concepciones como el anarquismo consideran conveniente la total desaparición de los Estados, en favor del ejercicio soberano de la libertad individual a través de asociaciones y organizaciones libres. Otras concepciones aceptan la existencia del Estado, con mayor o menor autoridad o potestad, pero difieren en cuanto cual debiera ser su forma de organización y el alcance de sus facultades: 

El anarquismo sostiene que el Estado es la estructura de poder que pretende tener el monopolio del uso de la fuerza sobre un territorio y su población, y que es reconocido como tal por los estados vecinos. Los elementos más aparentes que señalan el poder del estado son:

Se le critica la falsa ostentación de la seguridad, defensa, protección social y justicia de la población; ejerciendo en realidad un gobierno obligatorio y violentando la soberanía individual y la no coacción. Los anarquistas señalan que el Estado es una institución represora para mantener un orden económico y de poder concreto vinculado al poder público. Le atribuyen al Estado buena parte de los males que aquejan a la humanidad contemporánea como la pobreza, crisis económicas, las guerras, la injusticia social, etc.

Unas palabras que identifican plenamente lo que es para los anarquistas el Estado desde la perspectiva de Bakunin, uno de los teóricos del anarquismo moderno:

“Quien dice ‘Estado’, dice necesariamente ‘Guerra’. El Estado procura (y debe procurar) ser fuerte, más fuerte que sus vecinos; de lo contrario, será un juguete en manos de ellos. Se ve obligado a debilitar, a empobrecer a los otros Estados para imponerles su ley, su política, sus tratados comerciales, con objeto de enriquecerse a su costa. La lucha por la supremacía, que está en la base de la organización económica burguesa, es también la base de su organización política”.

Por su parte los marxistas afirman que cualquier Estado tiene un carácter de clase, y que no es más que el aparato armado y administrativo que ejerce los intereses de la clase social dominante. Por tanto aspiran a la conquista del poder político por parte de la clase trabajadora, la destrucción del Estado "burgués" y la construcción de un necesario Estado obrero como paso de transición hacia el socialismo y el comunismo, una sociedad donde a largo plazo no habrá Estado por haberse superado las contradicciones y luchas entre las clases sociales. Se discute sobre la viabilidad de la eliminación de las condiciones de la existencia burguesa, supuesto para el paso de la sociedad enajenada a la comunista.

Desde el liberalismo se aboga por la reducción del papel del Estado al mínimo necesario (Estado mínimo), desde un sentido civil para el respeto de las libertades básicas, es decir el Estado debería encargarse de la seguridad (ejército y policía para garantizar las libertades ciudadanas) y de la justicia (poder judicial independiente del poder político). En ningún caso el Estado debe servir para ejercer la coacción de quitar a unos individuos para dar a otros, y deben ser los agentes privados los que regulen el mercado a través del sistema de precios, asignando a cada cosa el valor que realmente tiene."
Bastiat expuso dos formas posibles de entender el Estado: Un estado que hace mucho pero debe tomar mucho, o bien un estado que hace poco pero también toma poco de sus ciudadanos. La tercera posibilidad de un estado que hace mucho por sus ciudadanos pero les pide poco a cambio (tercera vía) es, según Bastiat, una invención de algunos políticos irresponsables.

Las ideologías integristas defienden la concepción del Estado supeditada a la religión que profesan.

En defensa del bien común de la totalidad de la población que engloba el Estado o de la pervivencia del mismo, se utiliza frecuentemente la llamada "razón de Estado", término acuñado por Nicolás Maquiavelo, por la que dicho Estado, perjudica o afecta de una u otra forma a personas o grupos de personas, en pro del resto de individuos que lo conforman, generalmente obviando las propias normas legales o morales que lo rigen. Tal es el argumento esgrimido, por ejemplo, en ciertos asesinatos selectivos o en ciertos casos de terrorismo de Estado.




</doc>
<doc id="1124" url="https://es.wikipedia.org/wiki?curid=1124" title="Espectáculo">
Espectáculo

Según la Real Academia la palabra espectáculo hace referencia a una función o diversión pública celebrada en un cine, en un circo o en otro edificio o lugar en que se congrega la gente para presenciarla y a cualquier cosa que se ofrece a la vista o a la contemplación intelectual y es capaz de atraer la atención y mover el ánimo infundiéndole deleite, asombro, dolor u otros afectos más o menos vivos o nobles.



</doc>
<doc id="1126" url="https://es.wikipedia.org/wiki?curid=1126" title="Enfermería">
Enfermería

La enfermería (del latín "in-", «negación»; "firmus, firma, firmum", «firme, resistente, fuerte»; y "-eria", «actividad, establecimiento» o «actividad, establecimiento [relacionado] con los no firmes, no fuertes [enfermos]») es la ciencia que se dedica al cuidado y atención de enfermos y heridos, así como a otras tareas sanitarias, siguiendo pautas clínicas. La enfermería forma parte de las conocidas como ciencias de la salud. La enfermería abarca la atención autónoma y en colaboración dispensada a personas de todas las edades, familias, grupos y comunidades, enfermos o no, y en todas circunstancias. Comprende la promoción de la salud, la prevención de enfermedades y la atención dispensada a enfermos, discapacitados y personas en situación terminal.

Según el Consejo Internacional de Enfermería, esta se define del siguiente modo:
La Asociación Norteamericana de Enfermeros declara desde 1987, en un documento denominado «Nursing: A Social Policy Statement», a la enfermería como: «El diagnóstico y tratamiento de las respuestas humanas ante problemas de salud reales o potenciales».
La primera Teoría de enfermería nace con Florence Nightingale, a partir de allí aparecen nuevos modelos, cada uno de los cuales aporta una filosofía de entender la enfermería y el cuidado. Las enfermeras comenzaron a centrar su atención en la adquisición de conocimientos técnicos que les eran delegados, y con la publicación del libro «Notas de Enfermería» de Florence Nightingale en 1859 se sentó la base de la enfermería profesional.


El profesional de enfermería es tanto de nivel técnico (enfermero auxiliar, enfermero técnico superior) como de nivel universitario (enfermero diplomado, licenciado o graduado) y se dedica a los cuidados de enfermería de individuos de todas las edades, familias, grupos y comunidades.

En España, por ley los enfermeros diplomados o graduados son los responsables de la dirección, evaluación y prestación de los cuidados de enfermería orientados a la promoción, mantenimiento y recuperación de la salud, así como a la prevención de enfermedades y discapacidades.

Todos los enfermeros diplomados o graduados están capacitados para realizar las funciones de enfermería asistencial, administrativa, docente e investigadora. También existe la figura del llamado enfermero supervisor, cuya función es supervisar y organizar el trabajo y entorno físico de trabajo de todos los profesionales que existen en la unidad a su cargo. Los enfermeros tienen funciones independientes (las relativas al cuidado) y dependientes o delegadas por el médico (administración de medicación, vendajes especiales y técnicas invasivas como la venopunción, básicamente).

La profesión de enfermería ha recibido diferentes nomenclaturas a lo largo de su historia en España. Hace años, se conocían como practicantes. Tras la creación de escuelas para la formación de ayudantes técnicos sanitarios, entre los años 1950 y 1970, se acuñó el término ATS (Ayudante Técnico Sanitario). En 1977, se crearon las Escuelas Universitarias de Enfermería, donde se forman los profesionales con una titulación universitaria de diplomatura, y pasan a denominarse D.U.E. (Diplomado Universitario en Enfermería). En la actualidad, con la aplicación del Plan Bolonia en las universidades españolas, se comienza a hablar de "enfermeros graduados".

Por otra parte, los enfermeros auxiliares son conocidos como "técnicos en cuidados auxiliares de enfermería", "técnicos auxiliares de enfermería" o "auxiliares de enfermería", obtienen su título tras dos cursos académicos de preparación —no universitarios. Tienen formación profesional de grado medio.

Cronología de los Técnicos en Cuidados Auxiliares de Enfermería:








Enfermería, al estudiar la biología, psicología y socioantropología del ser humano, tiene a su disposición diversas y numerosas especialidades. Enfermería tiene especialidades exclusivas para profesionales de enfermería, y también tiene disponibles otras especialidades de carácter interdisciplinario.



Contrariamente a la percepción de algunos, los enfermeros profesionales son un campo exclusivamente dominado por hombres durante gran parte de la historia de la humanidad. Cuando la primera escuela de enfermería del mundo fue abierta en India en el , debido a creencias religiosas, solo los hombres fueron considerados lo suficientemente "puros" para ser enfermeros.

La enfermería fue principalmente ejercida por hombres durante el Imperio bizantino. En la antigua Roma el término "nosocomial" significaba "hospital en sí", procedente de nosocomi, el hombre que proporcionaba cuidados enfermeros en la antigua Roma y diagnosticaba enfermedades a sus pacientes.

Según indica Colliere, el origen de las prácticas de cuidados está ligado a las intervenciones maternales que aseguraban la continuidad de la vida y de la especie. La alimentación, como necesidad básica que implica suplencia y ayuda (por parte de la madre o sustituta) en los primeros estadios evolutivos del hombre, es considerada como la práctica de cuidados más antigua.

Desde la época de Homero y de Sócrates existe constancia de que se tenía en cuenta que el hecho de autocuidarse desde la perspectiva de la limpieza mantendría la vida y la prosperidad en una persona.

Febe (60 d. C.) es la única mujer a la que se cita como diaconisa en el Nuevo Testamento (Romanos, 16, 1-2). Atendía a los pobres en sus hogares y con el tiempo se convirtió esta labor en parte primordial del trabajo de las diaconisas. No obstante, no se la relaciona con la enfermería.

El cristianismo y su organización tuvo vínculos históricos importantes con las prácticas de cuidados de enfermería desde los monasterios a través de las órdenes religiosas, así como desde la conquista de Tierra Santa, con las cruzadas. Como consecuencia del pensamiento medieval relacionado con la Reconquista de Santos Lugares, surgió un movimiento organizado, que cristalizó con el fenómeno histórico de las cruzadas, las cuales dieron lugar a la aparición de tres tipos de figuras: el guerrero, el religioso y el enfermero. La demanda de hospitales y sanitarios en las rutas seguidas por los cruzados propició la aparición de las Órdenes Militares dedicadas a la enfermería: los caballeros de la Orden de San Juan de Jerusalén, los caballeros Teutónicos y los caballeros de la Orden de San Lázaro de Jerusalén. En España, la primera institución destinada a acoger enfermos fue el Hospital del Obispo Masona, en Mérida, en el siglo VI, según Domínguez Alcón y el "Diccionario Eclesiástico" de España.

Entre los hospitales medievales donde se desarrollaban actividades de enfermería, se encuentran El Hôtel-Dieu de París y Lyon, el Santo Spirito de Roma, el Hospital de la Seo de Tortosa, el Hospital de Mérida, y el Hospital d'en Clapers de Valencia, de los cuales, según datos recogidos por Domínguez Alcón, los dos primeros perduran en la actualidad.

El llamado movimiento "Beguino", constituido por «mujeres santas» que cuidaban enfermos, se diferencia dentro del entramado histórico-cristiano-caritativo ligado a los cuidados de enfermería fundamentalmente en que no asume los votos preceptivos de las órdenes religiosas.

Las denominaciones de las personas encargadas de proporcionar cuidados de enfermería han variado a lo largo de la historia en función de la época y el contexto donde estos se desarrollaban (hospitales, leproserías, órdenes militares, órdenes religiosas y ámbitos domésticos): "macipa", "mossa", "clavera", "donado", "donada", "hospitaler", "hospitalera"y "enfermero".

Según la historiografía estudiada hasta ahora, los administradores o procuradores de los hospitales eran varones, salvo en el Hospital del Rey de Burgos.

Hasta el año 1500, la escasa atención en cuanto a la reglamentación de los cuidados de enfermería, practicados en ámbitos domésticos, propició una variedad de grupos que ejercían estas actividades fuera de los ámbitos institucionales: nodrizas (didas), parteras o comadronas, grupos dedicados al cuidado a domicilio y grupos dedicados a otras prácticas sanadoras.

En el siglo XVI, la Reforma Protestante tuvo graves consecuencias para los cuidados de salud, debido a la supresión de las instituciones de caridad. La filosofía protestante indica que «no son necesarias las obras de caridad para obtener la salvación». Esto se traduce en un abandono de la consideración del cuidado de enfermería que continuaba existiendo en el ámbito católico.

Entre los años 1500 y 1860, la enfermería tuvo su peor momento, debido a que la idea predominante era que la enfermería constituía más una ocupación religiosa que intelectual, por lo que su progreso científico se consideraba innecesario. Además, tras la Reforma Protestante se produjo una desmotivación religiosa para dedicarse al cuidado de enfermos entre las personas laicas y una relegación a antiguas pacientes, presas y otras personas de los estratos más bajos de la sociedad de la actividad de aplicar cuidados. M. Patricia Donahue denominó a este período la «época oscura de la enfermería».

Los avances en otras ciencias, como el invento del microscopio, proporcionaron a todas las hoy llamadas ciencias de la salud, incluida la enfermería, la posibilidad de procurar a las personas un mayor nivel de bienestar.

El Instituto de Diaconisas de Kaiserwerth, creado en 1836 por el pastor protestante Theodor Fliedner (1800-1864), supuso para la enfermería el inicio de una formación reglada, para enfermeras. Este hecho, acaecido en el ámbito protestante, puede suponer en un análisis superficial una contradicción; sin embargo, el propio caos y desorganización de los cuidados de enfermería protestantes fue lo que exigió una reglamentación formal y específica para ejercer la profesión.

Según Eileen Donahue Robinson, el libro "Notas sobre la enfermería" ("Notes on Nursing"), publicado por Florence Nightingale en 1859 —tras sus experiencias en la guerra de Crimea—, supuso «un texto de crucial influencia sobre la enfermería moderna». En 1860 se inauguró la "Nightingale Training School for Nurses" («Escuela Nightingale de Formación para Enfermeras»), la cual constituyó una institución educativa independiente financiada por la "Fundación Nightingale". La originalidad del proyecto fue considerar que debían ser las propias enfermeras las que formasen a las estudiantes de enfermería mediante programas específicos de formación y haciendo hincapié tanto en las intervenciones de enfermería hospitalarias como extrahospitalarias, para el mantenimiento y promoción de la salud tanto del individuo como de las familias. Nigthingale, reformadora del concepto de enfermería, le dio una nueva directriz a la ciencia del cuidado del ser humano, además de diferenciar lo que era medicina de enfermería desde el punto de vista de que la enfermería situaba al paciente en las mejores condiciones para que la naturaleza actuase sobre él en un ambiente limpio libre de agentes patógenos.

En Estados Unidos, según Donahue, el primer texto sobre enfermería se publicó en 1885 por la señora Clara Weeks Shaw, y la primera revista nacional sobre enfermería, "The Trained Nurse and Hospital Review", apareció en 1888. Según Donahue, Lilian Wald fue la precursora de lo que hoy se entiende como Enfermería Comunitaria, por medio de un proyecto que comenzó en Nueva York en 1893 como una organización filantrópica, y que constituiría la base para el posterior desarrollo de la Salud Pública en dicho país. En España no se puede hablar de un origen específico de la Enfermería de Salud Pública, ya que las ideas anglosajonas no tuvieron mucho eco entre las enfermeras españolas, hasta que en 1933 se crearon las 50 primeras plazas de enfermeras visitadoras y sanitarias. Posteriormente, Mrs. Benford Fenwick fundaría el "Consejo Internacional de Enfermeras", la más antigua de todas las organizaciones internacionales para trabajadores profesionales. En 1922, en la Universidad de Indiana, se fundó la Sigma Theta Tau, una organización que promueve la investigación y dirección de Enfermería. Sus miembros son seleccionados de acuerdo con sus logros académicos y calidad profesional, y entre ellos figuran estudiantes, estudiantes graduados en Programas de Enfermería y dirigentes de Enfermería Comunitaria.

A principios del siglo XX, en los Estados Unidos se admitía, por lo general, que la legislación sobre la aprobación estatal para la Enfermería elevaría a las personas que la practicaban a un nivel profesional mediante el establecimiento de unas normas educativas mínimas para las escuelas de Enfermería. Sin embargo, a medida que la demanda de enfermeros crecía, se establecieron más escuelas de Enfermería de distinta calidad, circunstancia que hizo poco por mejorar el nivel de la profesión.

En la segunda guerra mundial, la enfermería adquirió mayor importancia y relieve. En los últimos días de la guerra un artículo de Bixler y Bixler en la revista "Am. J. of Nursing" valoraba la enfermería como una profesión. Los siete criterios para una profesión identificados por estos autores eran aplicables a la enfermería de la forma en que se practicaba en ese momento y justificaban la consideración de la enfermería como profesión. Bixler y Bixler revisaron sus criterios y el nivel profesional de la enfermería 14 años después y observaron que ambos continuaban siendo válidos.

Hasta la década de 1950 no se empezó a plantear en serio la necesidad de desarrollar, articular y contrastar una teoría global de enfermería, y casi un siglo después de Nightingale comenzaron a aparecer en la literatura estadounidense nuevos aportes sobre la definición de la profesión y sus funciones:

En 1955, Virginia Henderson publicó: 

En 1958, Dorothea Orem escribió: «la enfermería es un servicio humano cuyo aspecto esencial es atender a la necesidad personal de realizar actividades de autocuidado de forma continua para el mantenimiento de la salud o la recuperación tras la enfermedad o la lesión». En su definición incluía a las personas como parte importante de su propia recuperación y al enfermero como facilitador de su autonomía.

También en 1958, Ami Francis Brown, en su libro "Enfermería Medicoquirúrgica", insistía en «la asistencia y el cuidado de enfermería al paciente como función central de la profesión».

En 1962, Gertrud B. Ujhely afirmaba que el cuidado es el «apoyo que se da al paciente frente a la enfermedad», y que la razón de ser de la enfermería es «sostener al paciente durante su lucha contra la enfermedad», con la relación interpersonal como factor fundamental del cuidado.

En 1964, Lydia E. Hall consideraba las funciones de enfermería extendidas en tres círculos: cuerpo-cuidados, enfermedad-curación y persona-instrospección, compartidos en diferentes grados con otros profesionales. Sostenía que los cuidados de enfermería eran más necesarios cuanta menor atención médica se recibía y que la atención que realizaban los enfermeros aceleraba la recuperación.

Hall indentificó los siguientes cinco criterios de actitud con la profesionalidad:


También en 1964, Hildegard Peplau planteaba que lo realmente profesional en la enfermería era la relación enfermero-paciente en el aspecto psicodinámico de los cuidados. Consideraba el cuidado «un proceso educativo que tiende al desarrollo y crecimiento personal», con las relaciones interpersonales y la labor educativa como elementos básicos. Su principal aporte fue destacar la labor comunicativa de la enfermería e identificar funciones relacionadas con la asistencia en la educación para la salud y la docencia en el ejercicio de formación de nuevos profesionales.

En 1970, Martha Rogers postulaba que el modelo conceptual de enfermería se construye alrededor del proceso vital del ser humano, y que los conocimientos deben ser aplicados en la práctica de los cuidados. Concebía la enfermería como arte o ciencia, identificando una única base de conocimientos procedente de la investigación científica y el análisis lógico que puede trasladarse a la práctica. Estableció la importancia de la investigación que perdura hasta la actualidad. Para Rogers, el mantenimiento y la promoción de la salud deben llegar a ser las primeras funciones del enfermero y las considera aún más importantes que el tratamiento de las enfermedades. También explicitaba la necesidad de tener en cuenta la promoción y la prevención en la definición de las funciones de la profesión.

Callista Roy (1970) suponía que el hombre es un ser biopsicosocial que vive dentro de un entorno, que junto con la personalidad influye en él, provocando el desarrollo de formas de adaptación. La atención del enfermero sería necesaria cuando dichas respuestas fuesen ineficaces. Peplau, Rogers y Roy se engloban en los llamados modelos de interrelación, que son los más recientes y avanzados.

También en 1970, Beverly Witter Du Gas publicó el "Tratado de enfermería práctica", donde se indica que «el cuidado constituye el papel de la enfermería», y que el proceso de atención consta de una serie de pasos realizados por el enfermero para planear y cumplir la función de «cuidar». El proceso de atención de enfermería aporta a la profesión un método científico para la realización de sus funciones.

A inicios de la década de 1980, Rosa M. Alberdi expuso que el enfermero tiene la función de ocuparse de las necesidades de salud del paciente o de los grupos sociales. En esta definición aparece por primera vez la atención a grupos sociales por parte del personal de enfermería.

En 1986, Yyer, Tapatich y Renocchi-Losey planteaban que «la enfermería es un arte que sabe cuidar al paciente mientras dura la enfermedad, y también está orientada a ayudar al ser humano a alcanzar el máximo de salud a lo largo de su ciclo vital». Consideraban la realización de un plan de cuidados como eje director de la acción enfermera.

A finales de los años 1980, María Consuelo Castrillón consideraba que la práctica de enfermería está conformada por tres funciones básicas realizadas en ámbitos sociales diferentes: cuidar la salud, administrar el cuidado de enfermería y los servicios de salud y educar para la salud.

En España, el 4 de diciembre de 1953 se unificaron en ATS (Asistente Técnico Sanitario) los estudios de auxiliares sanitarios siguiendo el modelo de especialidades médicas con el objeto de proporcionar mayor formación posbásica a los profesiones de "matronas", "practicantes" y "enfermeros", de modo que las matronas pasaron a ser una especialidad de ATS (BOE del 12 de febrero de 1957, Decreto de enero de 1957. Para fisioterapia, BOE del 23 de agosto, Real Decreto del 26 de julio de 1957). En 1977 (Decreto 2128), se transformaron en España las enseñanzas conducentes al título de ATS por las de DUE (Diplomado Universitario en Enfermería). Este hecho histórico supuso el reconocimiento por parte de la Institución Universitaria de la Enfermería como disciplina en proceso de construcción y como profesión de carácter universitario con todo lo que ello implica: reconocimiento científico y académico de la antigua actividad del cuidado de enfermería, crecimiento doctrinal y la posibilidad futura de acceder a todos los grados académicos (licenciatura y doctorado).

En la actualidad, en Estados Unidos se ofrecen dos programas de doctorado en enfermería: el doctorado académico y el doctorado en ciencias de la enfermería. Esto supone la consecución del máximo grado académico para la enfermería en el contexto estadounidense. Asimismo, este «doble doctorado» supone exigencias académicas que configuran, sin duda, el conocimiento de enfermería y la identidad profesional. Para pertenecer a la Academia Norteamericana de Enfermería ("American Academy of Nursing"), es necesario haber realizado trabajos de investigación inéditos que supongan un aumento del corpus de conocimientos de enfermería. Este hecho es análogo para todas las disciplinas científicas así como para sus respectivas academias. En España, con el programa de estudios resultante del Proceso de Bolonia, la enfermería ha alcanzado su máximo desarrollo, pues es posible obtener el doctorado en enfermería, que facilita la labor de investigación y consecuentemente el desarrollo de la profesión.



</doc>
<doc id="1127" url="https://es.wikipedia.org/wiki?curid=1127" title="Enfermedad de Alzheimer">
Enfermedad de Alzheimer

La enfermedad de Alzheimer (EA), también denominada demencia senil de tipo Alzheimer (DSTA) o simplemente alzhéimer, es una enfermedad neurodegenerativa que se manifiesta como deterioro cognitivo y trastornos conductuales. Se caracteriza en su forma típica por una pérdida de la memoria inmediata y de otras capacidades mentales (tales como las capacidades cognitivas superiores), a medida que mueren las células nerviosas (neuronas) y se atrofian diferentes zonas del cerebro. La enfermedad suele tener una duración media aproximada después del diagnóstico de 10 años, aunque esto puede variar en proporción directa con la severidad de la enfermedad al momento del diagnóstico.

La enfermedad de Alzheimer es la forma más común de demencia, es incurable y terminal, y aparece con mayor frecuencia en personas mayores de 65 años de edad.
Aunque también en raros casos puede ser desarrollada desde los 40 años. Los síntomas de la enfermedad como una entidad nosológica definida fueron identificados por Emil Kraepelin,
mientras que la neuropatología característica fue observada por primera vez por Alois Alzheimer en 1906.
Así pues, el descubrimiento de la enfermedad fue obra de ambos psiquiatras, que trabajaban en el mismo laboratorio. Sin embargo, dada la gran importancia que Kraepelin daba a encontrar la base neuropatológica de los desórdenes psiquiátricos, decidió nombrar a la enfermedad Alzheimer en honor a su compañero.

Por lo general, el síntoma inicial es la inhabilidad de adquirir nuevos recuerdos, pero suele confundirse con actitudes relacionadas con la vejez o el estrés.
Ante la sospecha de alzheimer, el diagnóstico se realiza con evaluaciones de conductas cognitivas, así como neuroimágenes, si están disponibles.
A medida que progresa la enfermedad, aparecen confusión mental, irritabilidad y agresión, cambios del humor, trastornos del lenguaje, pérdida de la memoria de corto plazo y una predisposición a aislarse a medida que declinan los sentidos del paciente.
Gradualmente se pierden las funciones biológicas, que finalmente conllevan a la muerte.
El pronóstico para cada individuo es difícil de determinar. El promedio general es de 7 años,
menos del 3% de los pacientes viven más de 14 años después del diagnóstico.

La causa de la enfermedad de alzheimer permanece desconocida, aunque las últimas investigaciones parecen indicar que están implicados procesos de tipo priónico. Las investigaciones suelen asociar la enfermedad a la aparición de placas seniles y ovillos neurofibrilares. Los tratamientos actuales ofrecen moderados beneficios sintomáticos, pero no hay tratamiento que retrase o detenga el progreso de la enfermedad. No obstante, casos preliminares de asociación de demencia por Alzheimer con la enfermedad celíaca mostraron la mejoría con el seguimiento de una dieta sin gluten.

Para la prevención del alzheimer, se han sugerido un número variado de hábitos conductuales, pero no hay evidencias publicadas que destaquen los beneficios de esas recomendaciones, incluyendo la estimulación mental y la dieta equilibrada.
El papel que juega el cuidador del sujeto con alzheimer es fundamental,
aun cuando las presiones y la demanda física de esos cuidados pueden llegar a ser una gran carga personal.

El Día Internacional del Alzheimer se celebra el 21 de septiembre, fecha elegida por la OMS y la Federación Internacional de Alzheimer, en la cual se celebran actividades en diversos países para concienciar y ayudar a prevenir la enfermedad.
La Organización Mundial de la Salud (OMS), realizó en 2015 su Primera Conferencia Ministerial de la OMS sobre la Acción Mundial contra la Demencia.

Médicos griegos y romanos asociaron a la vejez con la demencia. Pero no fue hasta 1901 cuando el psiquiatra alemán Alois Alzheimer identificó el primer caso de lo que se conoce hoy como enfermedad de Alzheimer, en una mujer de 51 años de edad, esta mujer se llamaba Auguste Deter. El investigador hizo seguimiento de su paciente hasta su muerte en 1906, fue entonces cuando pudo observar el cerebro. Después de este momento fue cuando por primera vez se reportó el caso públicamente.

Tras la muerte de la mujer, Alzheimer le examinó el cerebro al microscopio. Anotó las alteraciones de las "neurofibrillas", elementos del citoesqueleto teñidos con una solución de plata.

Durante los siguientes cinco años, la literatura médica reportó al menos once casos similares, algunos de ellos utilizando ya el término «enfermedad de Alzheimer». La enfermedad fue categorizada por primera vez por Emil Kraepelin después de la supresión de algunos elementos clínicos concomitantes como delirios y alucinaciones, así como características histológicas irrelevantes para la enfermedad, como los cambios arterioscleróticos, los cuales figuraban en el informe original sobre "Auguste D".
En la octava edición de su libro de texto de Psiquiatría, publicado en 1910, incluyó a la enfermedad de Alzheimer, denominada también por Kraepelin «demencia presenil», como un subtipo de demencia senil.

Durante la mayor parte del siglo XX, el diagnóstico del alzheimer era reservado para las personas entre las edades de 45 y 65 años con síntomas de demencia. La terminología ha cambiado desde 1977, cuando, en una conferencia sobre alzheimer, se llegó a la conclusión de que las manifestaciones clínicas y patológicas de la demencia presenil y senil eran casi idénticas, aunque los autores también agregaron que ello no descartaba la posibilidad de que tuviesen causas diferentes.
Esto, a la larga, conllevó a que se haga el diagnóstico del alzheimer independientemente de la edad.
El término demencia senil del tipo Alzheimer fue empleado durante un tiempo para describir el trastorno en aquellos mayores de 65 años, mientras que la enfermedad clásica de Alzheimer se reservaba para los de edades menores. Finalmente, el término enfermedad de Alzheimer fue aprobado oficialmente en la nomenclatura médica para describir a individuos de todas las edades con un patrón de síntomas: característica, curso de la enfermedad y neuropatología comunes.

La incidencia en estudios de cohortes muestra tasas entre 10 y 15 nuevos casos cada mil personas al año para la aparición de cualquier forma de demencia y entre 5 a 8 para la aparición del alzheimer.
Es decir, la mitad de todos los casos nuevos de demencia cada año son pacientes con alzheimer. También hay diferencias de incidencia dependiendo del sexo, ya que se aprecia un riesgo mayor de padecer la enfermedad en las mujeres, en particular entre la población mayor de 85 años.

La prevalencia es el porcentaje de una población dada con una enfermedad. La edad avanzada es el principal factor de riesgo para sufrir alzheimer: mayor frecuencia a mayor edad. En los Estados Unidos, la prevalencia del alzheimer fue de un 1,6 % en el año 2000, tanto en la población general como en la comprendida entre los 65 y 74 años. Se apreció un aumento del 19 % en el grupo de los 75-84 años y del 42 % en el mayor de 84 años de edad;
sin embargo, las tasas de prevalencia en las regiones menos desarrolladas del mundo son inferiores. La Organización Mundial de la Salud estimó que en 2005 el 0,379 % de las personas a nivel mundial tenían demencia y que la prevalencia aumentaría a un 0,441 % en 2015 y a un 0,556 % en 2030.
Por otro lado, para el año 2010 la Alzheimer's Disease International ha estimado una prevalencia de demencia del 4,7 % a nivel mundial para personas con 60 años o más,
representando por cierto cifras al alza respecto a varios estudios publicados con anterioridad (10 % superiores a las estimadas para The Lancet en 2005).
Otro estudio estimó que en el año 2006, un 0,4 % de la población mundial (entre 0,17–0,89 %; valor absoluto aproximadamente 26,6 millones con un rango entre 11,4–59,4 millones) se vio afectada por alzhéimer y que la prevalencia triplicaría para el año 2050.
En 2015 la Primera Conferencia Ministerial de la OMS sobre la Acción Mundial contra la Demencia.
estimó en 47.5 millones el número de casos en el mundo.

Las causas del alzheimer no han sido descubiertas completamente. Existen tres principales hipótesis para explicar el fenómeno: el déficit de la acetilcolina, la acumulación de amiloide o tau y los trastornos metabólicos.

La más antigua de ellas, y en la que se basan la mayoría de los tratamientos disponibles en el presente, es la hipótesis colinérgica, la cual sugiere que el alzheimer se debe a una reducción en la síntesis del neurotransmisor acetilcolina. Esta hipótesis no ha mantenido apoyo global por razón de que los medicamentos que tratan una deficiencia colinérgica tienen reducida efectividad en la prevención o cura del alzheimer, aunque se ha propuesto que los efectos de la acetilcolina dan inicio a una acumulación a tan grandes escalas que conlleva a la neuroinflamación generalizada que deja de ser tratable simplemente promoviendo la síntesis del neurotransmisor.

Algunas investigaciones recientes han relacionado la demencia, incluyendo la enfermedad de Alzheimer, con desórdenes metabólicos, particularmente con la hiperglicemia y la resistencia a la insulina. La expresión de receptores de la insulina ha sido demostrada en las neuronas del sistema nervioso central, preferentemente en las del hipocampo. En estas neuronas, cuando la insulina se une a su receptor celular, se promueve la activación de cascadas de señalización intracelular que conducen al cambio de la expresión de los genes relacionados con los procesos de plasticidad sináptica y de las enzimas relacionadas con el despeje de la misma insulina y del beta-amiloide. Estas enzimas degradantes de insulina promueven la disminución de la toxicidad debida al amiloide en modelos animales.

En esencia, Alzheimer puede ser considerado como una forma de diabetes de cerebro que tiene elementos tanto de resistencia a la insulina como de deficiencia de insulina. Para consolidar este concepto, se ha propuesto que Alzheimer sea conocida como "diabetes tipo 3".
El Alzheimer está asociado con una progresiva resistencia a la insulina cerebral en ausencia de DM2, de resistencia a la insulina periférica o de obesidad. Estudios post mortem demostraron que molecularmente, bioquímicamente así como la transducción de señales anormales en el Alzheimer eran virtualmente idénticas a lo que ocurría en la diabetes mellitus tipo I y II. Al administrar localmente drogas prodiabéticas, como la streptozotocina, estas generan daño cognitivo, con deficiencia espacial y de memoria así como neurodegeneración típica de Alzheimer, pero no generan diabetes mellitus.

A pesar de la polémica existente en torno al papel que tiene el aluminio como factor de riesgo para la enfermedad de Alzheimer, en los últimos años los estudios científicos han revelado que este metal podría estar relacionado con el desarrollo de la enfermedad. Los resultados muestran que el aluminio se asocia a varios procesos neurofisiológicos que provocan la característica degeneración del Alzheimer. Sin embargo, algunas personas que han estado crónicamente expuestas al aluminio, a través de alimentos o agua, no han mostrado ningún síntoma de la enfermedad. La probable explicación es que su intestino mantiene la función de barrera protectora, que evita el paso de sustancias tóxicas a la sangre y las consecuentes reacciones.

Se han documentado casos de asociación de demencia por Alzheimer con el consumo de gluten y la mejoría con el seguimiento de una dieta sin gluten.

Otra hipótesis propuesta en 1991,
se ha relacionado con el acumulo anómalo de la proteína beta-amiloide (también llamada amiloide Aβ) y tau en el cerebro de los pacientes con alzheimer.
En una minoría de pacientes, la enfermedad se produce por la aparición de mutaciones en los genes PSEN1, PSEN2 y en el gen de la APP, localizado en el cromosoma 21. En este último caso la enfermedad aparece clásicamente en personas con el síndrome de Down (trisomía en el cromosoma 21), casi universalmente en los 40 años de vida y se transmite de padres a hijos (por lo que existen, habitualmente, antecedentes familiares de alzheimer en los pacientes que desarrollan la enfermedad en edades precoces). Esa relación en el cromosoma 21, y la tan elevada frecuencia de aparición de la enfermedad en las trisomías de ese cromosoma, hacen que la teoría sea muy evidente.

Para poder hablar de las presenilinas, debemos recordar que el alzheimer está caracterizado por depósitos amiloideos en el cerebro (como apoya la segunda teoría de este artículo).
Su componente principal es el péptido beta-amiloide de 42 aminoácidos (βA42), en cuyo proceso de producción es fundamental la participación de la γ-secretasa, la cual depende a su vez de las presenilinas (PSEN).

De esta manera se instituye un nuevo grupo de moléculas implicadas en la génesis de la enfermedad del Alzheimer y fundamental para su comprensión. Además son de notable actualidad debido a que su descubrimiento es relativamente reciente y a las posibilidades que ofrecen como dianas terapéuticas.
Para comprender qué son estas moléculas, debemos señalar que se trata de un grupo de sustancias peptídicas producidas principalmente en el cerebro.
Hay dos tipos, PSEN 1 y PSEN 2, con una estructura similar. La función principal que desempeñan ambas PSEN consiste en el procesamiento proteolítico de numerosas proteínas de membrana de tipo 1, entre ellas la APP, formando parte de la γ secretasa; de ahí la importancia de las PSEN en la enfermedad de Alzheimer, ya que a través de la regulación de la γ secretasa determinan la forma de Aβ que se genera y por tanto su acumulación en el tejido cerebral.
El alzheimer de inicio temprano se ha relacionado con mutaciones en el cromosoma 21, que contiene el gen de la PPA, y los cromosomas 14 y 1, que codifican para PSEN1 y PSEN2, respectivamente. Estas mutaciones tienen como resultado, entre otros efectos, el aumento de la concentración de βA. Mientras que el alzheimer de inicio tardío se relaciona con mutaciones en el gen de la apolipoproteina E.
El gen que codifica la PSEN1, del que se conocen 177 mutaciones distintas, es el responsable de la aparición del alzheimer de inicio tan temprano como a los 23 años. La mutación de la PSEN2 es la causante de menos del 1% de los casos de alzheimer autosómicos dominantes, influyendo más en estos portadores los factores ambientales.
La revisión de diferentes artículos nos ha conducido a la conclusión de que existe una relación entre las PSEN y el alzheimer. Actualmente el avance en las técnicas de secuenciación del genoma ha aportado gran cantidad de información sobre las PSEN, su función, la localización en nuestros genes, la implicación de éstas en la formación de βA, etc. No obstante, hoy día aún se observan lagunas en cuanto a los mecanismos moleculares en los que están implicadas las PSEN.

Otro gran factor de riesgo genético es la presencia del gen de la "APOE4" (apolipoproteína relacionada con la hiperlipoproteinemia y la hipercolesterolemia familiar), el cual tiende a producir una acumulación amiloide en el cerebro antes de que aparezcan los primeros síntomas del alzheimer. Por ende, la deposición del amiloide Aβ tiende a preceder la clínica del alzheimer.
Otras evidencias parten de los hallazgos en ratones genéticamente modificados, los cuales sólo expresan un gen humano mutado, el de la "APP", el cual invariablemente les causa el desarrollo de placas amiloides fibrilares. Se descubrió una vacuna experimental que causaba la eliminación de estas placas pero no tenía efecto sobre la demencia.

Los depósitos de las placas no tienen correlación con la pérdida neuronal.
Esta observación apoya la hipótesis "tau", la cual defiende que es esta proteína la que da inicio a la cascada de trastornos de la enfermedad de Alzheimer. De acuerdo a este modelo, las tau hiperfosforiladas adoptan formas anómalas, distribuyéndose en largas hileras. Eventualmente forman ovillos de neurofibrillas dentro de los cuerpos de las células nerviosas.
Cuando esto ocurre, los microtúbulos se desintegran, colapsando el sistema de transporte de la neurona. Ello puede dar inicio a las primeras disfunciones en la comunicación bioquímica entre una neurona y la otra y conllevar la muerte de estas células.

Según un trabajo realizado por un equipo de científicos de la Universidad de Cambridge, en Reino Unido cuyos resultados se publican en Brain, la proteína tau, causante de la muerte de las células nerviosas, se disemina por todo el cerebro en la enfermedad de Alzheimer y, por lo tanto, bloquear su propagación puede evitar que la enfermedad aflore.

Se considera que los síntomas del Alzheimer están causados por la acumulación en el cerebro de dos proteínas anómalas: la proteína beta amiloide y la proteína tau. Se cree que la beta amiloide se produce primero, fomentando la aparición y la diseminación de tau, y que es esta última la que destruye las células nerviosas, mermando la memoria y las funciones cognitivas.

Hasta hace unos años solo era posible observar la acumulación de estas proteínas mediante el examen de los cerebros de los pacientes post mortem. Sin embargo, los recientes desarrollos en la tomografía por emisión de positrones (PET) han permitido a los científicos comenzar a visualizar su acumulación en pacientes que vivos.

La forma en que tau se presenta en todo el cerebro ha sido tema de especulación entre los científicos y se han propuesto tres hipótesis:


Los avances en el escaneo PET permiten actualmente hacer comparaciones entre estas hipótesis. 

Los científicos analizaron las conexiones funcionales dentro de los cerebros de los pacientes de Alzheimer y lo compararon con los niveles de tau. Sus hallazgos respaldan la idea de la propagación transneuronal, es decir, que tau comienza en un lugar y se propaga. Al mismo tiempo enconrtraron que no se cumplían las predicciones para las últimas dos hipótesis.

Según Thomas Cope, el primer autor del estudio, la propagación transneuronal es la correcta, las áreas del cerebro que están más conectadas tienen la mayor acumulación de la proteína tau anómala y la transmitirán a sus conexiones. En la enfermedad de Alzheimer, la región cerebral más común para tau que aparece primero es la región de la memoria, en el área de la corteza entorrinal, que está al lado del hipocampo. Los primeros síntomas en el Alzheimer tienden a ser problemas de memoria y el estudio de Cope sugiere que la tau luego se propaga por el cerebro, infectando y destruyendo las células nerviosas a medida que avanza, lo que hace que los síntomas del paciente empeoren progresivamente.

Esta confirmación es importante porque indica que se puede ralentizar o incluso detener la progresión de la enfermedad de Alzheimer mediante el desarrollo de fármacos para evitar que tau se mueva a lo largo de las neuronas.

La enfermedad de Alzheimer se caracteriza por la pérdida de neuronas y sinapsis en la corteza cerebral y en ciertas regiones subcorticales. Esta pérdida resulta en una atrofia de las regiones afectadas, incluyendo una degeneración en el lóbulo temporal y parietal y partes de la corteza frontal y la circunvolución cingulada.

Las placas son depósitos densos, insolubles, de la proteína beta-amiloide y de material celular que se localizan fuera y alrededor de las neuronas. Estas continúan creciendo hasta formar fibras entretejidas dentro de la célula nerviosa, los llamados ovillos. Es probable que muchos individuos, en su vejez, desarrollen estas placas y ovillos como parte del proceso normal de envejecimiento. Sin embargo, los pacientes con alzhéimer tienen un mayor número en lugares específicos del cerebro, como el lóbulo temporal.

La enfermedad de Alzheimer se ha definido como una enfermedad que desdobla proteínas o proteopatía, debido a la acumulación de proteínas Aβ y tau, anormalmente dobladas, en el cerebro.
Las placas neuríticas están constituidas por pequeños péptidos de 39–43 aminoácidos de longitud, llamados "beta-amiloides" (abreviados A-beta o Aβ). El beta-amiloide es un fragmento que proviene de una proteína de mayor tamaño conocida como "Proteína Precursora de Amiloide" (APP, por sus siglas en inglés). Esta proteína es indispensable para el crecimiento de las neuronas, para su supervivencia y su reparación postdaño.
En la enfermedad de Alzheimer, un proceso aún desconocido es el responsable de que la APP sea dividida en varios fragmentos de menor tamaño por enzimas que catalizan un proceso de proteolisis.
Uno de estos fragmentos es la fibra del beta-amiloide, el cual se agrupa y deposita fuera de las neuronas en formaciones microscópicamente densas conocidas como placas seniles.

La enfermedad de Alzheimer se considera, debido a la agregación anormal de la proteína tau, como una "tauopatía", . Las neuronas sanas están compuestas por citoesqueleto, una estructura intracelular de soporte, parcialmente hechas de microtúbulos. Estos microtúbulos actúan como rieles que guían los nutrientes y otras moléculas desde el cuerpo neuronal hasta los extremos de los axones y viceversa. Cada proteína tau estabiliza los microtúbulos cuando es fosforilada y por esa asociación se le denomina "proteína asociada al microtúbulo". En el alzheimer, la tau debido a cambios químicos que resultan en su hiperfosforilación, se une con otras hebras tau creando ovillos de neurofibrillas y, de esta manera, desintegra el sistema de transporte de la neurona.

No se ha explicado por completo cómo la producción y agregación de los péptidos Aβ (beta Amiloides) juegan un rol en el alzheimer.
La fórmula tradicional de la hipótesis amiloide apunta a la acumulación de los péptidos Aβ como el evento principal que conlleva la degeneración neuronal. La acumulación de las fibras amiloides, que parece ser la forma anómala de la proteína responsable de la perturbación de la homeostasis del ion calcio intracelular, induce la muerte celular programada, llamada apoptosis.
Se sabe también que la Aβ se acumula selectivamente en las mitocondrias de las células cerebrales afectadas en el alzhéimer y que es capaz de inhibir ciertas funciones enzimáticas, así como alterar la utilización de la glucosa por las neuronas.

Varios mecanismos inflamatorios y la intervención de las citoquinas pueden también jugar un papel en la patología de la enfermedad de Alzheimer. La inflamación es el marcador general de daño en los tejidos en cualquier enfermedad y puede ser secundario al daño producido por el alzhéimer, o bien, la expresión de una respuesta inmunológica.

La gran mayoría de los pacientes de esta enfermedad, tienen o han tenido algún familiar con alzheimer. También hay que decir que en una pequeña proporción de los pacientes, el Alzheimer es debido a una generación autosómica dominante, haciendo que la enfermedad aparezca de forma temprana. En menos de un 10% de los casos, el alzheimer aparece antes de los 60 años de edad como consecuencia de mutaciones autosómicas dominantes, representando, apenas, un 0,01% de todos los casos.
Estas mutaciones se han descubierto en tres genes distintos: el gen de la proteína precursora de amiloide (la APP) y los genes de las presenilinas 1 y 2.Si bien la forma de aparición temprana de la enfermedad de Alzheimer ocurre por mutaciones en tres genes básicos, la forma más común no se ha podido explicar con un modelo puramente genético. La presencia del gen de la apolipoproteína E es el factor de riesgo genético más importante para padecer Alzheimer, pero no permite explicar todos los casos de la enfermedad.

En 1987, se descubrió la relación de la enfermedad de Alzheimer con el cromosoma 21. Esto fue importante porque la mayoría de los afectados por el "síndrome de Down" o trisomía del cromosoma 21, padecen lesiones neuropatológicas similares a las del Alzheimer. Dentro del cromosoma 21 encontramos el gen PPA. John Hardy y sus colaboradores en 1991 afirmaron que este gen estaba implicado en la Enfermedad de Alzheimer en un reducido número de familias. Sin embargo, se considera que de entre 5-10% de los familiares con la enfermedad precoz la padecen debido a una mutación de este gen.
Las investigaciones dentro de este gen se han centrado en el péptido Ab (todas las mutaciones se encuentran alrededor de este péptido).
Las mutaciones producían un aumento de las concentraciones del péptido Ab. Esto llevó a la formación de la hipótesis de "cascada amieloide" en los años 90.
La "cascada amieloide" consiste en que la gran producción de Ab llevaría a la formación de depósitos en formas de placas seniles. Estas placas seniles serían nocivas para las células que producirían ovillos neurofibrilares, la muerte celular y la demencia.
Más tarde se vio en un grupo amplio de familias el ligamiento de la enfermedad del Alzheimer con el cromosoma 14. Pero esto llevó a una cadena de errores y con ello unas conclusiones erróneas.
Rudy Tanzi y Peter St George-Hyslop en 1995, mediante las técnicas de clonaje descubrieron otro gen S182 o Presenilin-1 (PS1). Este gen se encuentra entre los dominios 9 y 8 de transmembrana (con dos regiones hidrofílicas) y se le han encontrado más de 30 mutaciones.
Este gen interviene en procesos de apoptosis y es fundamental durante el desarrollo.
La mayoría de las mutaciones del gen Presenilin-1 (PS1) provocan un cambio en la estructura primaria. La PS1 y la enfermedad del Alzheimer no tienen una clara relación, pero hay que destacar que los pacientes que tuvieron mutaciones que aumentan Ab en el plasma.
Poco más tarde se descubrió un nuevo gen que se denomina presenilina-2 (PS2) y también provoca el ascenso en la concentración de Ab, aunque las mutaciones observadas son de menor cantidad que los otros genes (PPA y PS1).
La PS2 está formada por 8-9 dominios transmembrana.

La mayoría de las mutaciones en el gen de la APP y en los de las presenilinas, aumentan la producción de una pequeña proteína llamada beta-amiloide (Abeta 2), la cual es el principal componente de las placas seniles.

Aunque la mayoría de los casos de Alzheimer no se deben a una herencia familiar, ciertos genes actúan como factores de riesgo. Un ejemplo es la transmisión familiar del alelo e4 del gen de la apolipoproteína E. Este gen se considera un factor de riesgo para la aparición de Alzheimer esporádico en fases tardías, produciendo un 50% de los casos Alzheimer.Además de éste, alrededor de 400 genes han sido también investigados por su relación con el Alzheimer esporádico en fase tardía.
Así pues, los genetistas coinciden en que hay más genes que actúan como factores de riesgo, aunque también afirman que existen otros que tienen ciertos efectos protectores que conllevan a retrasar la edad de la aparición del Alzheimer. Un ejemplo es la alteración en el gen de la reelina, que contribuye a aumentar el riesgo de aparición del alzhéimer en mujeres.

Los primeros síntomas se confunden, con frecuencia, con la vejez o estrés en el paciente. Una evaluación neuropsicológica detallada es capaz de revelar leves dificultades cognitivas hasta 8 años antes de que la persona cumpla los criterios de diagnóstico.
Estos signos precoces pueden tener un efecto sobre las actividades de la vida diaria.
La deficiencia más notable es la pérdida de memoria, manifestada como la dificultad de recordar hechos recientemente aprendidos y una inhabilidad para adquirir nueva información.
Dificultades leves en las funciones ejecutivas —atención, planificación, flexibilidad y razonamiento abstracto— o trastornos en la memoria semántica —el recordar el significado de las cosas y la interrelación entre los conceptos— pueden también ser síntomas en las fases iniciales del alzheimer.
Puede aparecer apatía, siendo uno de los síntomas neuropsiquiátricos persistentes a lo largo de la enfermedad.
La fase preclínica de la enfermedad es denominada por algunos "deterioro cognitivo leve", pero aún existe debate sobre si el término corresponde a una entidad diagnóstica independiente o si, efectivamente, es la primera etapa de la enfermedad.

Los síntomas en esta fase inicial van desde una simple e insignificante, pero a veces recurrente, pérdida de memoria (como la dificultad en orientarse uno mismo en lugares como calles al estar conduciendo el automóvil), hasta una constante y más persuasiva pérdida de la memoria conocida como memoria a corto plazo, presentando dificultades al interactuar en áreas de índole familiar como el vecindario donde el individuo habita.

Además de la recurrente pérdida de la memoria, una pequeña porción de los pacientes presenta dificultades para el lenguaje, el reconocimiento de las percepciones —agnosia— o en la ejecución de movimientos —apraxia— con mayor prominencia que los trastornos de la memoria.
El alzheimer no afecta las capacidades de la memoria de la misma forma. La memoria a largo plazo o memorias episódicas, así como la memoria semántica o de los hechos aprendidos y la memoria implícita, que es la "memoria del cuerpo" sobre cómo realizar las acciones (tales como sostener el tenedor para comer), se afectan en menor grado que las capacidades para aprender nuevos hechos o el crear nuevos recuerdos.

Los problemas del lenguaje se caracterizan, principalmente, por reducción del vocabulario y disminución en la fluidez de las palabras, lo que conlleva a un empobrecimiento general del lenguaje hablado y escrito. El paciente con alzheimer suele ser capaz de comunicar adecuadamente las ideas básicas.
También aparece torpeza al realizar tareas motoras finas, tales como escribir, dibujar o vestirse, así como ciertas dificultades de coordinación y de planificación.
El paciente mantiene su autonomía y sólo necesita supervisión cuando se trata de tareas complejas.

En esta etapa es frecuente que la persona se desoriente en la calle y llegue a perderse, por lo que se recomienda tomar precauciones:

Conforme avanza la enfermedad, los pacientes pueden realizar tareas con cierta independencia (como usar el baño), pero requerirán asistencia para tareas más complejas (p. ej. ir al banco, pagar cuentas, etc.). Paulatinamente llega la pérdida de aptitudes, como las de reconocer objetos y personas. Además, pueden manifestarse cambios de conducta como, por ejemplo, arranques violentos incluso en personas que jamás han presentado este tipo de comportamiento.

Los problemas del lenguaje son cada vez más evidentes debido a una inhabilidad para recordar el vocabulario, lo que produce frecuentes sustituciones de palabras erróneas, una condición llamada parafasia. Las capacidades para leer y escribir empeoran progresivamente.
Las secuencias motoras complejas se vuelven menos coordinadas, reduciendo la habilidad de la persona para hacer sus actividades rutinarias.
Durante esta fase, también empeoran los trastornos de la memoria y el paciente empieza a dejar de reconocer a sus familiares y seres más cercanos.
La memoria a largo plazo, que hasta ese momento permanecía intacta, se deteriora.
En esta etapa se vuelven más notorios los cambios en la conducta. Las manifestaciones neuropsiquiátricas más comunes son las distracciones, el desvarío y los episodios de confusión al final del día (agravados por la fatiga, la poca luz o la oscuridad),así como la irritabilidad y la labilidad emocional, que incluyen llantos o risas inapropiadas, agresión no premeditada e incluso resistencia a las personas a cargo de sus cuidados. En el 30% aproximadamente de los pacientes aparecen ilusiones en el reconocimiento de personas. También puede aparecer la incontinencia urinaria.
Estos síntomas estresan a los familiares y a las personas al cuidado del paciente y pueden verse reducidos si se le traslada a un centro de cuidados a largo plazo.

La enfermedad trae deterioro de la masa muscular, perdiéndose la movilidad, lo que lleva al enfermo a un estado de encamamiento,
la incapacidad de alimentarse a sí mismo,
junto a la incontinencia, en aquellos casos en que la muerte no haya llegado aún por causas externas (infecciones por úlceras o neumonía, por ejemplo).
El lenguaje se torna severamente desorganizado, llegándose a perder completamente. A pesar de ello, se conserva la capacidad de recibir y enviar señales emocionales.
Los pacientes no podrán realizar ni las tareas más sencillas por sí mismos y requerirán constante supervisión, quedando así completamente dependientes. Puede aún estar presente cierta agresividad, aunque es más frecuente ver extrema apatía y agotamiento.

El diagnóstico se basa primero en la historia y la observación clínicas, del profesional de la salud y la que es referida por los familiares, basada en las características neurológicas y psicológicas, así como en la ausencia de condiciones alternativas: un diagnóstico de exclusión.
Luego durante unas semanas o meses se realizan pruebas de memoria y de funcionamiento o evaluación intelectual. También se efectúan análisis de sangre y escáner para descartar diagnósticos alternativos. 
No existe un test "pre mortem" para diagnosticar concluyentemente el alzheimer. Se ha conseguido aproximar la certeza del diagnóstico a un 85%, pero el definitivo debe hacerse con pruebas histológicas sobre tejido cerebral, generalmente obtenidas en la autopsia (McKhann 1984) .
Las pruebas de imagen cerebral —Tomografía axial computarizada (TAC), Resonancia magnética nuclear (RMN), tomografía por emisión de positrones (TEP) o la tomografía computarizada por emisión de fotón único— pueden mostrar diferentes signos de que existe una demencia, pero no especifican de cuál demencia se trata.
Por tanto, el diagnóstico de la enfermedad de Alzheimer se basa tanto en la presencia de ciertas características neurológicas y neuropsicológicas, como en la ausencia de un diagnóstico alternativo y se apoya en el escáner cerebral para detectar signos de demencia. Actualmente se están desarrollando nuevas técnicas de diagnóstico basadas en el procesamiento de señales electroencefalográficas.

Una vez identificada, la expectativa promedio de vida de los pacientes que viven con la enfermedad de Alzheimer es aproximadamente de 7 a 10 años, aunque se conocen casos en los que se llega antes a la etapa terminal, entre 4 y 5 años; también existe el otro extremo, donde pueden sobrevivir hasta 21 años.

La "Asociación del Alzheimer" es el organismo que ha establecido los criterios diagnósticos más comúnmente usados, registrados en los "Criterios NINCDS-ADRDA del Alzheimer".
Estas pautas requieren que la presencia de un trastorno cognitivo y la sospecha de un síndrome demencial sean confirmadas con una evaluación neuropsicológica con vistas a categorizar el diagnóstico de Alzheimer en dos: posible o probable. La confirmación histológica, que incluye un examen microscópico del tejido cerebral, se precisa para el diagnóstico definitivo del Alzheimer. Estos criterios incluyen que la presencia de un trastorno cognitivo y la sospecha de un síndrome demencial sean confirmados por evaluaciones neuropsicológicas para distinguir entre un diagnóstico posible o uno probable de la enfermedad de Alzheimer. Se ha mostrado fiabilidad y validez estadística entre los criterios diagnósticos y la confirmación histológica definitiva.
Son ocho los dominios cognitivos que con más frecuencia se dañan en el alzhéimer: la memoria, el lenguaje, la percepción, la atención, las habilidades constructivas y de orientación, la resolución de problemas y las capacidades funcionales. Estos parámetros son equivalentes a los evaluados en los Criterios NINCDS-ADRDA publicados por la Asociación Americana de Psiquiatría.

Las evaluaciones neuropsicológicas, inclusive el examen minimental, son ampliamente usadas para evaluar los trastornos cognitivos necesarios para el diagnóstico de EA. Otra serie de exámenes más comprensivos son necesarios para una mayor fiabilidad en los resultados, especialmente en las fases iniciales de la enfermedad.
El examen neurológico en los inicios del alzhéimer es crucial para el diagnóstico diferencial del alzheimer y otras enfermedades. 
Las entrevistas a familiares también sirven para evaluar la enfermedad. Los cuidadores pueden proveer información y detalles importantes sobre las habilidades rutinarias, así como la disminución en el tiempo de la función mental del paciente.
El punto de vista de la persona a cargo del paciente es de especial importancia debido a que el paciente, por lo general, no está al tanto de sus propias deficiencias.
Muchas veces, los familiares tienen desafíos en la detección de los síntomas y signos iniciales de la demencia y puede que no comuniquen la información de manera acertada al profesional de salud especializado.

Los exámenes adicionales pueden proporcionar información de algunos elementos de la enfermedad y tienden a ser usados para descartar otros diagnósticos. Los exámenes de sangre pueden identificar otras causas de demencia que no sea el alzheimer, que pueden ser, en pocos casos, enfermedades reversibles.
El examen psicológico para la depresión sería de valor, puesto que la depresión puede aparecer de manera concomitante con el alzhéimer, o bien ser la causa de los trastornos cognitivos.

En los casos en que estén disponibles imágenes neurológicas especializadas, como la TEP o la tomografía de fotón único, pueden servir para confirmar el diagnóstico del alzheimer junto con las evaluaciones del estatus mental del individuo.
La capacidad de una tomografía computarizada por emisión de fotón único, para distinguir entre el alzheimer y otras posibles causas en alguien que ya fue diagnosticado de demencia, parece ser superior a los intentos de diagnóstico mediante exámenes mentales y la historia del paciente.
Una nueva técnica, conocida como PiB PET, se ha desarrollado para tomar imágenes, directamente y de forma clara, de los depósitos beta-amiloides "in vivo", con el uso de un radiofármaco que se une selectivamente a los depósitos Aβ.
Otro marcado objetivo reciente de la enfermedad de Alzheimer es el análisis del líquido cefalorraquídeo en busca de amiloides beta o proteínas tau.
Ambos avances de la imagen médica han derivado en propuestas para cambiar los criterios diagnósticos.

Actualmente la enfermedad de Alzheimer es incurable y terminal. 
El tratamiento del Alzheimer se sustenta en dos pilares complementarios: el tratamiento no farmacológico y el tratamiento farmacológico.

Se ha probado la eficacia de fármacos anticolinesterásicos que tienen una acción inhibidora de la colinesterasa, la enzima encargada de descomponer la acetilcolina (neurotransmisor que falta en la enfermedad de Alzheimer y que incide sustancialmente en la memoria y otras funciones cognitivas). Se han incorporado al tratamiento de la enfermedad nuevos fármacos que intervienen en la regulación de la neurotransmisión glutaminérgica. Con todo esto se ha mejorado el comportamiento del enfermo en cuanto a la apatía, la iniciativa, la capacidad funcional y las alucinaciones, mejorando su calidad de vida. Sin embargo, es preciso remarcar que en la actualidad (2008) la mejoría obtenida con dichos fármacos es discreta, es decir, no se ha conseguido alterar el curso de la demencia subyacente.

El primer fármaco anticolinesterásico comercializado fue la tacrina, que hoy ha dejado de emplearse por su hepatotoxicidad. En 2008, en Europa y Norteamérica existían 4 fármacos disponibles, tres de ellos son inhibidores de la acetilcolinesterasa: donepezilo (comercializado como "Aricept"),
rivastigmina (comercializado como "Exelon" o "Prometax")
incluyendo el parche de Exelon,
y galantamina (comercializado como "Reminyl").
Los tres presentan un perfil de eficacia similar con parecidos efectos secundarios. Estos últimos suelen ser alteraciones gastrointestinales, anorexia y trastornos del ritmo cardíaco. El cuarto medicamento es un antagonista de los receptores NMDA, la memantina. Ninguno de los cuatro se indica para retardar o detener el progreso de la enfermedad.

La reducción en la actividad de las neuronas colinérgicas es una de las características reconocidas de la enfermedad de Alzheimer.
Los inhibidores de la acetilcolinesterasa se emplean para reducir la tasa de degradación de la acetilcolina, manteniendo así concentraciones adecuadas del neurotransmisor en el cerebro y deteniendo su pérdida causada por la muerte de las neuronas colinérgicas.
Existen evidencias de que estos medicamentos tienen eficacia en las etapas leves y moderadas de la enfermedad,aunque un poco menos de que sean útiles en la fase avanzada. Sólo el donepezilo se ha aprobado para este estado de la demencia.
El uso de estos fármacos en los trastornos cognitivos leves no ha mostrado ser capaz de retardar la aparición del alzhéimer.
Los efectos adversos más comunes incluyen náuseas y vómitos, ambos ligados al exceso colinérgico que de ellos deriva. Estos efectos aparecen entre un 10 y un 20% aproximadamente de los tratados y tienen severidad leve a moderada. Entre los efectos secundarios menos frecuentes figuran calambres musculares, disminución de la frecuencia cardíaca, disminución del apetito y del peso corporal y un incremento en la producción de jugo gástrico.

La memantina es un fármaco con un mecanismo de acción diferente, que está indicado en las fases moderadas y avanzadas de la enfermedad. Su mecanismo de acción teórico se basa en antagonizar los receptores NMDA glutaminérgicos, usado en un principio como un agente antigripal. El glutamato es un neurotransmisor excitatorio del sistema nervioso central. Al parecer, un exceso de estimulación glutaminérgica podría producir o inducir una serie de reacciones intraneuronales de carácter tóxico, causando la muerte celular por un proceso llamado excitotoxicidad, que consiste en una sobreestimulación de los receptores del glutamato. Esta excitotoxicidad no sólo ocurre en pacientes con alzheimer, sino también en otras enfermedades neurodegenerativas, como la enfermedad de Parkinson y la esclerosis múltiple.
Los ensayos clínicos han demostrado una eficacia moderada en estos pacientes y un perfil de efectos secundarios aceptable. En 2005 se aprobó también su indicación en fases moderadas de la enfermedad, pero los efectos en las fases iniciales son aún desconocidos.
Los efectos adversos de la memantina son infrecuentes y leves e incluyen alucinaciones, confusión, mareos, dolor de cabeza y fatiga.
La combinación de memantina y donepezilo ha mostrado ser estadísticamente significativa pero marginalmente exitosa desde el punto de vista clínico.

Además existen fármacos que mejoran algunos de los síntomas que produce esta enfermedad, entre los que se encuentran ansiolíticos, hipnóticos, neurolépticos y antidepresivos. Los fármacos antipsicóticos se indican para reducir la agresión y la psicosis en pacientes con alzhéimer que tienen problemas de conducta, pero se usan con moderación y no de forma rutinaria por razón de los serios efectos secundarios, como eventos cerebrovasculares, trastornos extrapiramidales y una reducción cognitiva.

El avance de la enfermedad puede ser más rápido o más lento en función del entorno de la persona con alzheimer. No es una situación fácil y la familia tendrá que hacer grandes esfuerzos para ofrecerle a la persona con alzheimer un entorno lo más favorable posible.
Aceleradores de la enfermedad. Se consideran aceleradores las siguientes situaciones: Estrés familiar. Cambios bruscos en las rutinas diarias. Cambio a un domicilio nuevo y desconocido (como son las residencias de mayores). -(falta cita)
Retardadores de la enfermedad. Se consideran retardadores las situaciones nombradas a continuación: Ambiente familiar feliz. Hacer ejercicio. Socializar con los amigos u otras personas.

Existen ciertas evidencias de que la estimulación de las capacidades cognitivas ayuda a ralentizar la pérdida de estas funciones y habilidades. Esta estimulación consiste en trabajar aquellas áreas que aún conserva el paciente, de forma que el entrenamiento permita compensar las pérdidas que el paciente está sufriendo con la enfermedad.

Las intervenciones psicosociales se usan conjuntamente con el tratamiento farmacológico y se clasifican en abordajes orientados al comportamiento, las emociones, lo cognitivo y la estimulación. Las investigaciones sobre la efectividad de estas intervenciones aún no se encuentran disponibles y, de hecho, rara vez son específicas al alzhéimer, enfocándose en la demencia en general.

Las intervenciones en el área del comportamiento intentan identificar y reducir los antecedentes y consecuencias de los problemas de la conducta. Este abordaje no ha mostrado éxito en mejorar el funcionamiento general del paciente, en especial en relación con su entorno, pero ha podido ayudar a reducir ciertos problemas específicos del comportamiento, como la incontinencia urinaria.
Siguen faltando datos de calidad sobre la efectividad de estas técnicas en otros problemas como las deambulaciones del paciente.

Las intervenciones orientadas a las emociones comprenden la terapia de validación, la terapia de reminiscencia, la psicoterapia de apoyo, la integración sensorial (también denominada "snoezelen") y la terapia de presencia estimuladora. La psicoterapia de apoyo ha tenido poco estudio científico formal, pero algunos especialistas la encuentran de utilidad en pacientes con trastornos leves. La terapia de reminiscencia incluye la discusión de experiencias del pasado de manera individual o en grupo, muchas veces con la ayuda de fotografías, objetos del hogar, música y grabaciones u otras pertenencias del pasado. En esta terapia, igualmente, no hay muchos estudios de calidad sobre su efectividad, aunque puede resultar beneficiosa para la reestructuración cognitiva y el humor.
El tratamiento con presencias estimuladas se basa en las "teorías de la adherencia" e implica escuchar voces grabadas de los familiares y seres más cercanos del paciente con alzheimer. Las evidencias preliminares indican que dichas actividades reducen la ansiedad y los comportamientos desafiantes.

Finalmente, la terapia de validación se basa en la aceptación de la realidad y la experiencia personal de otras personas, mientras que la integración sensorial se basa en ejercicios guiados que estimulan los sentidos. Aún no hay suficientes evidencias que apoyen el uso de estas terapias en pacientes con alzhéimer.

La finalidad de las terapias cognitivo-conductuales, que incluyen la orientación y la rehabilitación cognitiva, es reducir las distorsiones cognitivas. La orientación hacia la realidad consiste en presentar información acerca de la época, el lugar o la persona, con el fin de aliviar su entendimiento acerca de sus alrededores y el lugar que ellos desempeñan en dichos sitios. Por otro lado, el entrenamiento cognitivo intenta mejorar las capacidades debilitadas al ejercitar las habilidades mentales del paciente. Ambos ejercicios han mostrado cierta efectividad en el mejoramiento de las capacidades cognitivas.
Sin embargo, en algunos estudios, estos efectos fueron transitorios y en otros tenían un efecto negativo, pues añadían frustración al paciente, según los reportes.

Los tratamientos orientados a la estimulación incluyen la arteterapia, la musicoterapia y las terapias asistidas por mascotas, el ejercicio físico y cualquier actividad recreacional. La estimulación tiene apoyo modesto al ser aplicada con la intención de mejorar la conducta, el humor y, en menor grado, el funcionamiento del paciente. Si bien son efectos importantes, el principal beneficio reportado entre las terapias de estimulación es el mejoramiento en las rutinas de la vida diaria del paciente.

Debido a que el alzhéimer no tiene cura, con el tiempo el paciente cae en un estado de imposibilidad de autosuficiencia para cuidar de sí mismo, por lo que los cuidados por terceros son una medida vital para esa deficiencia y deben ser abordados cuidadosamente durante el curso de la enfermedad.

En las fases tempranas y moderadas, las modificaciones al ambiente donde vive el paciente y a su estilo de vida, pueden darle seguridad y reducir las cargas al cuidador.
Algunos ejemplos de dichas modificaciones son la adherencia a rutinas simplificadas, como son la colocación de candados, el uso de una pulsera con el número de teléfono del cuidador (o soluciones más avanzadas como un localizador por GPS), el etiquetado de los objetos del hogar y el uso de utensilios modificados para la vida diaria. Puede llegar el punto en que el paciente no sea capaz de alimentarse a sí mismo, de modo que debe empezar a ingerir sus alimentos en porciones más pequeñas o en dietas no sólidas con la ayuda de otras personas.
Cuando aparezca una dificultad para tragar, puede que sea indicado el uso de sondas gástricas. En tales casos, la efectividad médica y ética de tener que continuar alimentando al paciente son consideraciones importantes que deben tomar los cuidadores y los familiares del individuo.
Las restricciones físicas rara vez están indicadas en cualquier fase de la enfermedad, aunque hay situaciones en que son necesarias para prevenir que el paciente con alzheimer se dañe a sí mismo o a terceros.

A medida que progresa la enfermedad, pueden aparecer distintas manifestaciones médicas, como, las enfermedades orales y dentales, úlceras de presión, desnutrición, problemas de higiene o infecciones respiratorias, urinarias, dermatológicas u oculares, entre otras. El manejo cuidadoso del paciente puede prevenir dichos problemas, pero si llegan a producirse, deben ser tratados bajo supervisión médica. Durante las etapas finales de la enfermedad, el tratamiento se centra en mantener la calidad de vida hasta el fallecimiento.

Igualmente se están realizando experimentos con vacunas, basados en la idea de que si el sistema inmune puede ser entrenado para reconocer y atacar la placa beta-amiloide, podría revertirse la deposición de amiloide y parar la enfermedad. Los resultados iniciales en animales fueron prometedores. Sin embargo, cuando las primeras vacunas se probaron en seres humanos en 2002, se produjo inflamación cerebral, (meningoencefalitis), en una pequeña proporción de los participantes en el estudio, por lo que se detuvieron las pruebas. Se continuó estudiando a los participantes y se observó una mejora en la lentitud del progreso de la enfermedad. Recientemente se ha descubierto que la inflamación cerebral estaba producida por una serie de péptidos que se incluían con la vacuna AN-179, por lo que se está investigando la creación de una vacuna que no tenga dichos péptidos en su composición.
Se está probando una vacuna la ABvac40, como preventiva contra el alzhéimer desde el 2014. Su objetivo, es detener la producción de placas amiloides. La vacuna produciría anticuerpos encargados de eliminar los beta amiloides 40 y 42, que son los causantes de la neurodegeneración cerebral. Los ensayos de la vacuna se realizarán sobre un total de 24 personas: 16 pacientes diagnosticados y en estadio leve y ocho pacientes que reciben placebo. De acreditarse su inocuidad, la vacuna no estará en el mercado antes del 2018. 

En marzo de 2015 se publicó en "Science-Translational Medicine" una aproximación completamente nueva al tema alzheimer, que ha sido probada en ratones.
La misma utiliza una manera particular de aplicar ultrasonido, dentro del tejido gris cerebral. Estas ondas de sonido resultaron capaces de abrir gentilmente la barrera hematoencefálica, que separa al cerebro de la sangre, y estimularon a las células de del Río Hortega o microglía. Estas células microgliales, una vez activadas, resultaron capaces de ir desintegrando y eliminar las aglutinaciones beta-amiloideas del Alzheimer. Los autores de la investigación informaron haber observado la restauración completa de las memorias en el 75% de los ratones en los que ensayaron. Hallaron que los ratones así tratados desplegaron mejoras de la memoria en tres pruebas específicas. El equipo científico planea iniciar pruebas con animales de laboratorio superiores, como ovejas y simios, y espera ser autorizado a poner en marcha ensayos sobre seres humanos en el 2017.

Por su parte, en las aproximaciones clínicas clásicas (farmacológicas), un estudio de 2014 afirmaba que en ratones el antidepresivo citalopram detuvo el crecimiento de las placas beta amiloides de la enfermedad de Alzheimer existentes y redujo la formación de nuevas placas en un 78%. En un segundo experimento, los científicos administraron una dosis única de citalopram a 23 personas de entre 18 y 50 años que no estaban cognitivamente deterioradas ni padecían depresión. Cuando obtuvieron muestras de líquido cefalorraquídeo a las 24 horas, observaron una reducción del 37% en la producción de la proteína beta-amiloide.

Si esta enfermedad está relacionada con la resistencia a la insulina, se presentan múltiples alternativas terapéuticas. Se está evaluando actualmente el uso de medicamentos empleados en el tratamiento de la diabetes. Estudios recientes muestran que la administración de insulina por vía intranasal mejora la función cognitiva de pacientes normales y con alzhéimer.
Una revisión sistemática de los ensayos clínicos hasta ahora desarrollados muestra resultados esperanzadores. Por otra parte, se ha propuesto el empleo de técnicas de inducción enzimática, con enzimas activas por la insulina.

Otra de las áreas de investigación es la medicina regenerativa. Se trata de inyectar en el cerebro del paciente células madre embrionarias o adultas para intentar detener el deterioro cognitivo. Ya se han hecho experimentos en humanos con resultados positivos.

La estimulación cerebral intenta normalizar la actividad, con un dispositivo llamado neuroestimulador, similar a un marcapasos cardíaco. El dispositivo forma parte de un tratamiento llamado estimulación cerebral profunda (ECP), que involucra la liberación de impulsos eléctricos para regular la actividad cerebral. La investigación, llevada a cabo en la Escuela de Medicina Johns Hopkins, forma parte de un proyecto más amplio iniciado en Canadá, donde ya se implantó el marcapasos a seis pacientes con la enfermedad. El tratamiento logró que los pacientes -todos con formas moderadas de alzheimer- mostraran un incremento en la actividad neuronal durante 13 meses.
La terapia de estimulación cerebral profunda se ha utilizado con personas que sufren la enfermedad de Parkinson. Ahora, la terapia podría ser una alternativa para revertir el deterioro cognitivo de las personas con alzheimer.
Esta neurocirugía funcional, busca reparar, modular o corregir un déficit en un sistema o red neurológica determinada. Lo que ocurre con el alzheimer es que se altera la química cerebral y esto conduce a una actividad eléctrica anormal que puede expresarse en temblores, deterioro cognitivo o trastornos psiquiátricos. La aplicación para el alzheimer todavía está en sus primeras etapas.

Los estudios globales sobre las diferentes medidas que se pueden tomar para prevenir o retardar la aparición de la enfermedad de Alzheimer han tenido resultados contradictorios y no se ha comprobado aún una relación causal entre los factores de riesgo y la enfermedad, ni se han atribuido a efectos secundarios específicos. Por el momento, no parece haber medidas definitivas para prevenir la aparición del alzheimer.

Varios estudios epidemiológicos han propuesto diversas relaciones entre ciertos factores modificables, tales como la dieta, los riesgos cardiovasculares, productos farmacéuticos o las actividades intelectuales entre otros, y la probabilidad de que en una población aparezca el alzhéimer. Por ahora se necesitan más investigaciones y ensayos clínicos para comprobar si estos factores ayudan a prevenirla.

La dieta mediterránea se ha asociado con un menor riesgo de desarrollar la enfermedad de Alzheimer, por su papel en la prevención del desarrollo de enfermedades cardiovasculares y por sus efectos antiinflamatorios y antioxidantes.

La curcumina del curry ha mostrado en estudios del 2001 y 2007 cierta eficacia en la prevención de daño cerebral en modelos de ratón.

Similares propiedades se comunicaron en 2010 y 2012 para ensayos en ratones de la "Withania somnifera" (ashwagandha, ginseng indio).
A pesar de que los riesgos cardiovasculares, como la hipercolesterolemia, hipertensión arterial, la diabetes y el tabaquismo, están asociados a un mayor riesgo de desarrollo y progresión del alzheimer,
las estatinas, que son medicamentos que disminuyen la concentración de colesterol en el plasma sanguíneo, no han sido efectivas en la prevención o mejoramiento del alzheimer.
Sin embargo, en algunos individuos, el uso a largo plazo de los antiinflamatorios no esteroideos (AINEs) está vinculado con una reducción de la probabilidad de padecerla.
Otros fármacos y terapias, como el reemplazo de hormonas en las mujeres, han dejado de ser aconsejadas como medidas preventivas del alzheimer.
Se incluye también un reporte en 2007 que concluyó la falta de evidencias significativas y la presencia de inconsistencias en el uso de ginkgo biloba para mejorar los trastornos cognitivos.

Hay diferentes actividades intelectuales, como el jugar ajedrez, Go, la lectura, el completar crucigramas o las interacciones sociales frecuentes, que parecen retardar la aparición y reducir la gravedad del alzheimer.
El hablar varios idiomas también parece estar vinculado a la aparición tardía de la enfermedad.

Otros estudios han demostrado que hay un aumento en el riesgo de la aparición del alzheimer con la exposición a campos magnéticos,
la ingestión de metales, en particular de aluminio,
o la exposición a ciertos solventes.
La calidad de algunos de estos estudios ha sido criticada,
y otros estudios han concluido que no hay una relación entre estos factores ambientales y la aparición del alzhéimer.





</doc>
<doc id="1128" url="https://es.wikipedia.org/wiki?curid=1128" title="Enfermedad de Bright">
Enfermedad de Bright

La enfermedad de Bright se clasifica históricamente como una enfermedad renal, que se describiría en la medicina moderna como una Nefritis degenerativa aguda o crónica, especialmente parenquimatosa. Sin embargo, el término ha dejado de ser utilizado, clasificándose ahora las enfermedades renales según su etiología.

La enfermedad de Bright contiene un grupo de trastornos que pertenecen al grupo de enfermedades no supurativas o degenerativas que se caracterizan por la presencia de proteínas—principalmente albúmina—y sangre en la orina. En algunas ocasiones también aparece edema (inflamación debida a acumulación de líquido en los tejidos), retención de orina e hipertensión arterial.

Esta enfermedad se detecta por la presencia de albúmina en la orina y va frecuentemente acompañada de edema.

Los síntomas son generalmente graves. Dolor de espalda, vómitos y fiebre son indicadores comunes de un ataque. El edema, que puede fluctuar entre una ligera hinchazón de la cara hasta una acumulación de fluido suficiente para dilatar todo el cuerpo y, en ocasiones, limita gravemente la respiración, facilitado por la presencia de anemia y de acidosis metabólica, es una afección muy común. La cantidad de orina se reduce, adquiere un color oscuro, ahumado o sanguinolento, muestra en los análisis la presencia de gran cantidad de albúmina y al microscopio células sanguíneas en abundancia.

Este estado de inflamación aguda puede limitar seriamente las actividades diarias y, si no se diagnostica, conllevar a una de las formas crónicas de la enfermedad de Bright. Sin embargo, en muchos casos se reduce la inflamación debido a un aumento de micción mediante la utilización de diuréticos de asa y la desaparición de la albúmina y otros subproductos, a lo que acompaña, normalmente, la recuperación.


</doc>
<doc id="1129" url="https://es.wikipedia.org/wiki?curid=1129" title="Enfermedad de Parkinson">
Enfermedad de Parkinson

La enfermedad de Parkinson (EP), también denominada mal de Parkinson, parkinsonismo idiopático, parálisis agitante o simplemente párkinson, es una enfermedad neurodegenerativa crónica caracterizada por bradicinesia (movimiento lento), rigidez (aumento del tono muscular) y temblor.

La enfermedad de Parkinson se clasifica con frecuencia como un trastorno del movimiento, sin embargo, también desencadena alteraciones en la función cognitiva, depresión, dolor y alteraciones en la función del sistema nervioso autónomo.

Esta enfermedad representa el segundo trastorno neurodegenerativo por su frecuencia, situándose por detrás de la enfermedad de Alzheimer. Está extendida por todo el mundo y afecta tanto al sexo masculino como al femenino, siendo frecuente que aparezca a partir del sexto decenio de vida. Además de esta variedad tardía, existe otra versión precoz que se manifiesta en edades inferiores a los cuarenta años.

La enfermedad de Parkinson aumenta su severidad con el tiempo, como consecuencia de la destrucción progresiva, por causas que todavía se desconocen, de las neuronas pigmentadas de la sustancia negra.

En 1997 la Organización Mundial de la Salud estableció que el 11 de abril se celebraría el Día mundial del párkinson, con el objetivo de acrecentar la concienciación de las necesidades de las personas aquejadas de esta dolencia. Se estableció esta fecha pues corresponde al nacimiento de James Parkinson, el médico británico que describió por primera vez la «parálisis agitante», término que él mismo acuñó.

La enfermedad de Parkinson se clasifica en estadios clínicos según el grado de afectación.

Hay varias escalas de evaluación que se pueden utilizar como herramientas para determinar la progresión de la enfermedad. Los criterios para evaluar la enfermedad de Parkinson se centran en la severidad de las alteraciones motoras y en el grado de deterioro en las actividades diarias de una persona.

Las escalas de evaluación de uso general, como la de Hoehn y Yahr, se centran en las alteraciones motoras. Estas alteraciones se evalúan según su severidad en una escala del 1 a 5. En esta escala, dependiendo de las dificultades de una persona para realizar sus actividades, se asigna un puntaje de 1 y 2 (leve a moderado) en la etapa temprana del cuadro, puntaje de 2 y 3 (moderado a severo) en la etapa media y un puntaje de 4 y 5 (severo a invalidante) en la etapa más avanzada de la enfermedad.

La Escala de evaluación de la enfermedad de Parkinson (UPDRS) es más completa que la escala de Hoehn y de Yahr. Toma en cuenta la alteración para la realización de las actividades diarias, el comportamiento, el humor, las complicaciones cognoscitivos y los efectos del tratamiento respecto de las alteraciones motoras.

En 1817, James Parkinson, médico inglés, describió un síndrome que denominó "Parálisis Agitans", el cual fue posteriormente denominado como enfermedad de Parkinson por Jean-Martin Charcot.

Globalmente, la incidencia anual de la enfermedad de Parkinson es de dieciocho nuevos casos por cada cien mil habitantes, pero la alta esperanza de vida que suelen presentar los pacientes hace que la prevalencia de la enfermedad en la población sea cuantitativamente mayor que la incidencia, registrándose unos ciento sesenta y cuatro casos por cada cien mil habitantes. Según los estudios auspiciados por el grupo de estudio del Europarkinson, la prevalencia de la enfermedad de Parkinson en el continente europeo es de 1,43% en las personas que superan los sesenta años de edad, aunque se han hecho estimaciones en estados como España o Reino Unido, que exponen que cerca de ciento veinte mil habitantes se ven afectados por esta enfermedad en sendos países. En América del Norte la cifra se dispara hasta el millón de pacientes aquejados de esta enfermedad, estando afectada un 1% de la población que supera los 65 años.

En edades tempranas, concretamente antes de los cuarenta años, la enfermedad de Parkinson es excepcional y su prevalencia es menor del 1/100000. La incidencia de esta enfermedad empieza a aumentar a partir de los cincuenta años y no se estabiliza hasta los ochenta, si bien este hecho puede ser resultado de un sesgo de selección.

Varios estudios han puesto al descubierto una prevalencia acentuada de la enfermedad de Parkinson en el medio rural, especialmente entre los varones. Esto puede deberse a que la vida en el campo incluye en algunas ocasiones, diferentes exposiciones ambientales de riesgo, como contaminación en el agua de los pozos, uso de pesticidas e insecticidas.

Los estudios sobre la mortalidad en la enfermedad de Parkinson se encuentran limitados por la escasez de precisión de los certificados de defunción, así como por la confusión diagnóstica entre el párkinson idiopático y otros tipos de trastornos neurodegenerativos. Con todo ello, puede establecerse que las tasas de mortalidad son bajas para cualquier estrato de edad y que la edad de la muerte de los pacientes ha ido desplazándose hasta edades más avanzadas, por un progresivo aumento de la esperanza de vida. Además, todo parece indicar que el tratamiento con levodopa reduce el riesgo de muerte de los pacientes, especialmente durante los primeros años de la enfermedad. De hecho, y en efecto la mortalidad estandarizada de la la enfermedad de Parkinson se situaba en 2,9 antes de haberse producido la introducción de la levodopa, pues tras la aparición del fármaco la cifra experimentó un colosal descenso que la dejó en 1,3, proporcionándole a los pacientes una esperanza de vida que rozaba la normalidad. Sin embargo, una revisión sistemática del efecto de levodopa en el cambio de la esperanza de vida demostró que la mejora que se había producido a consecuencia del tratamiento farmacológico era menor, con una estimación de la mortalidad estandarizada de 2,1.

Cuando se sobreviene la muerte en los pacientes aquejados de enfermedad de Parkinson, esta suele ser debida a una infección intercurrente, generalmente torácica, o a un traumatismo producido en alguna de las caídas ocasionadas por la inestabilidad postural. Cabe destacar, que los pacientes con enfermedad de Parkinson tienen una menor probabilidad de fallecer a consecuencia de cáncer o de enfermedades cardiovasculares que la población general. 

Actualmente se desconoce la causa exacta de la enfermedad de Parkinson, pero todo parece indicar que se trata de una combinación de ciertos factores ambientales, genéticos, el daño oxidativo y el proceso normal de envejecimiento, con un probable papel fundamental de la conexión intestino-cerebro. Se ha documentado la asociación del parkinsonismo con la enfermedad celíaca no diagnosticada y la mejoría con la retirada del gluten de la dieta. Los síntomas neurológicos pueden ser la única manifestación de la sensibilidad al gluten, en ausencia de síntomas digestivos o de otro tipo.

Aunque los estudios epidemiológicos muestran que uno de los factores de riesgo de mayor preponderancia son los antecedentes familiares, las teorías etiológicas tóxico-ambientales han ido tomando cada vez mayor importancia en desmedro de las teorías genéticas.

Evidencias actuales apoyan la hipótesis de que la enfermedad de Parkinson comienza en el intestino y se propaga a través de los sistemas nerviosos simpático y parasimpático hasta la sustancia negra y el sistema nervioso central.

Estudios realizados hasta la fecha han encontrado un riesgo superior de desarrollar la enfermedad de Parkinson entre el personal expuesto profesionalmente a ciertos plaguicidas, fundamentalmente insecticidas y herbicidas. Otros factores se han relacionado con un mayor riesgo de desarrollar la enfermedad de Parkinson, tales como el consumo de agua de pozo, la agricultura y la vida rural, si bien no se ha podido determinar si guardan relación con la exposición a los plaguicidas o si se trata de factores de riesgo independientes.

La enfermedad de Parkinson se caracteriza por la pérdida o degeneración de las neuronas dopaminérgicas en la sustancia negra y la formación de cuerpos de Lewy en dichas neuronas.

La alteración de la alfa-sinucleína y su acumulación en los cuerpos de Lewi tiene una mayor extensión y afecta otras zonas y sistemas neuronales, como el colinérgico, el noradrenérgico y el serotoninérgico.

El diagnóstico de la enfermedad de Parkinson puede realizarse en aquellos individuos que presenten al menos dos de cuatro signos cardinales:
El temblor en reposo está presente en aproximadamente 85 % de los casos con enfermedad de Parkinson. La ausencia de expresión facial, disminución del parpadeo y del movimiento de los brazos al caminar completan el cuadro clínico.

Muchos de estos síntomas son comunes en los ancianos y pueden ser causados por otras afecciones. En pacientes con algunos de estos síntomas parkinsonianos, y con ausencia de temblores, presente en el 15% de pacientes con párkinson, pueden sospecharse otras patologías del sistema nervioso, tales como las hidrocefalias. Concretamente, la hidrocefalia normotensiva también aparece en ancianos, deteriora las funciones del sistema nervioso, llevando a la demencia, y se presenta con síntomas parecidos a los del párkinson, sin aparición de temblores. La prueba diagnóstica para confirmar o descartar la hidrocefalia normotensiva es un TAC.


No todos los síntomas aparecen en todos los pacientes y la evolución y progresión de la enfermedad es muy variable según los casos.

El tipo de temblor que aparece en pacientes con enfermedad de Parkinson consiste en una especie de agitación que aparece cuando el paciente está en reposo pero que disminuye cuando el paciente está realizando alguna actividad o durante el sueño.

La enfermedad puede aparecer con una ligera contracción en la cual el temblor suele afectar al brazo, la mano o los dedos conocido como «movimiento de hacer píldoras» o «movimiento de contar monedas» que se caracteriza por un movimiento de desplazamiento hacia adelante y atrás de los dedos pulgar e índice. Los síntomas de temblor afectan inicialmente un solo lado del cuerpo.

La pérdida del equilibrio puede hacer que el paciente se caiga y producir lesiones. Esta dificultad y la pérdida de la capacidad de mantener la postura se ven afectadas principalmente en la marcha, al girar y al permanecer de pie. También al intentar levantarse o al inclinarse adelante. Es por eso que se recomienda usar un andador o un bastón.

La bradicinesia o lentitud en los movimientos hace que el paciente tenga que esforzar el doble para realizar sus tareas cotidianas porque se ven afectados, sobre todo, los movimientos de precisión como abrocharse los botones o escribir. Cuando la enfermedad avanza puede tener dificultades para levantarse de la silla, darse vuelta en la cama y tiene que caminar lentamente. Suele aparecer una «congelación» durante un breve período de tiempo cuando está caminando.

Como se trata de un trastorno progresivo los síntomas empeoran gradualmente con el tiempo. En general los síntomas se ven agravados por el estrés y las situaciones emocionales que causan ansiedad. la parte psicológica es muy importante. Los síntomas suelen mejorar con el descanso, el sueño y se utilizan técnica de relajación o cualquier estrategia para controlar el estrés y la ansiedad.


A veces los pacientes refieren dolor en las piernas por calambres, frío, ardor o sensación de entumecimiento y dolor de cabeza (cefalea) o dolor de cintura (lumbar).

Las dificultades para dormir se deben a la ansiedad, el dolor o la rigidez muscular. Es fundamental que el paciente duerma bien y realice un buen descanso porque el sueño reparador disminuye los efectos sintomáticos parkinsonianos. El cansancio es un estado de agotamiento físico y mental muy común en pacientes parkinsonianos. Puede ser consecuencia de los medicamentos, de la depresión o del esfuerzo extra necesario para realizar las tareas cotidianas y enfrentar los síntomas de la enfermedad. Esto puede ser mejorado con la medicación adecuada si se identifica cual es la causa que lo provoca.

La depresión puede ser causada por la enfermedad o por una reacción a la misma. Algunos pacientes se deprimen cuando les dan el diagnóstico. Los signos de depresión incluyen alteraciones del sueño, de la memoria, del apetito, del interés en la vida social o sexual, pérdida de energía o motivación para ciertas cosas y un concepto negativo de sí mismo. Al paciente le cuesta aceptar su estado y se enoja por sus limitaciones.

La ansiedad aparece ante cualquier situación estresante, por no poder realizar las tareas cotidianas como el paciente estaba acostumbrado o por tener que hablar en público. La ansiedad puede llegar incluso a provocar mayor inestabilidad, dificultad para respirar y sudoración excesiva. Para evitar que esto suceda son de gran ayuda las técnicas de relajación.

Entre las alteraciones cognitivas suelen aparecer dificultades en la concentración, la memoria, el pensamiento enlentecido, la capacidad para planificar tareas complejas o para realizar varias tareas a la vez.

La contención emocional de las personas que rodean al paciente es fundamental y un componente clave en la atención del parkinsoniano pues le proporciona numerosos beneficios.

La confusión y las alucinaciones que pueden aparecer son efectos secundarios de la medicación parkinsoniana y no de la enfermedad misma.

La disfunción autonómica se acompaña de diversas manifestaciones: hipotensión ortostática, estreñimiento, urgencia miccional, sudoración excesiva, seborrea. La hipotensión ortostática puede ser ocasionada tanto por la denervación simpática del corazón como por efecto colateral de la terapia dopaminomimética.

La depresión afecta a aproximadamente el 50% de los pacientes con enfermedad de Parkinson y puede presentarse en cualquier momento de evolución de la enfermedad, sin embargo se debe tener en cuenta que puede ser agravada por la administración de agentes antiparkinsonianos y psicotrópicos; otras causas de depresión refractaria al tratamiento incluyen: hipotiroidismo, hipogonadismo, déficit de vitamina B12.

Los síntomas psicóticos (más que una genuina psicosis se trata de la semiología de una demencia) afectan a 6-45% de los pacientes, en etapas tempranas incluyen alucinaciones visuales, aunque la depresión y la demencia son los principales desencadenantes de la psicosis, también lo es la administración de agentes dopaminérgicos, anticolinérgicos, amantadina, selegilina.

El diagnóstico de la enfermedad de Parkinson está basado en la clínica, puesto que no se ha identificado ningún marcador biológico de esta enfermedad. Por ello, el diagnóstico de la misma se apoya en la detección de la característica tríada rigidez-temblor-bradicinesia y en la ausencia de síntomas atípicos, aunque también tiene importancia la exclusión de otros posibles trastornos por medio de técnicas de imagen cerebral o de analíticas sanguíneas.

El diagnóstico puede llegar a revestir una gran complejidad. Esta dificultad en la diagnosis es corriente que aparezca en los primeros estadios de la enfermedad, cuando los síntomas que el paciente presenta pueden ser atribuidos a otros trastornos. Consecuencia directa de este hecho es la elaboración de diagnósticos erróneos.

Es importante dentro de la semiología de la enfermedad de Parkinson, realizar un exhaustivo interrogatorio para averiguar otras posibles causas que diferencien a la enfermedad de Parkinson con otros posibles síndromes extrapiramidales, ya que de inicio no existe una diferencia clara en el diagnóstico por las características clínicas que son compartidas por otros trastornos del movimiento.

No existe ninguna prueba de laboratorio o estudio radiológico que permita diagnosticar la enfermedad, aunque algunas empresas de diagnósticos genéticos sí que ofrecen test para la secuenciación de los genes SPARK1, SPARK2 y SPARK4 altamente relacionados con la enfermedad, aunque la detección de mutaciones en estos genes no determina terminantemente el futuro desarrollo de la enfermedad en el individuo. Este tipo de pruebas están dirigidas a familias con alta incidencia de la enfermedad de Parkinson y que los enfermos en su gran mayoría presentaran alguna mutación concreta en alguno de estos genes SPARK. En estos casos se podría secuenciar en alguno de sus descendientes el gen en el cual se presenta la mutación familiar, aunque aun así, la existencia o no de la mutación no asegura la presencia de la enfermedad. Con todo esto ni siquiera es recomendable realizar este tipo de secuenciaciones si no se ha presentado previamente ningún síntoma de la enfermedad, al ser una enfermedad grave y actualmente sin cura, los pacientes rara vez prefieren no saber su futuro con respecto al párkinson.

También es frecuente que se realicen evaluaciones analíticas sanguíneas con el objetivo de descartar otros posibles trastornos, como el hipotiroidismo, una disfunción hepática o patologías autoinmunes. Por otra parte, las técnicas de imagen cerebral, como son la resonancia magnética, la tomografía por emisión de positrones o la tomografía por emisión de fotón único, son eficaces a la hora de excluir otras dolencias que desencadenen síntomas parecidos a los de la enfermedad de Parkinson, tales como un accidente cerebrovascular o un tumor cerebral.

Resulta habitual que los facultativos formulen preguntas al paciente con las que pretenden dilucidar si este consumió alguna clase de estupefaciente o si estuvo expuesto a virus o toxinas medioambientales, para así determinar si un factor específico pudo haber sido la causa de un parkinsonismo. Es objeto de observación la actividad muscular del paciente durante un periodo de tiempo, pues con el avance de la enfermedad los trastornos motores específicos se vuelven más evidentes.

Un indicativo diagnóstico suele ser la prueba terapéutica, que consiste en la aplicación de terapia farmacológica con Levodopa (que es considerado el fármaco de elección en el tratamiento de enfermedad de Parkinson) por al menos 30 días observando de cerca la evolución del paciente. Se considera prueba Positiva si responde radicalmente al tratamiento con Levodopa y se considera negativa si no existe respuesta en absoluto. La prueba terapéutica con Levodopa suele ser confirmatoria si se sospecha la enfermedad; sin embargo si la prueba resulta negativa el médico tendrá que seguir investigando otras probables causas del trastorno o realizar estudios de mayor profundidad como los marcadores genéticos.

El tratamiento de la enfermedad de Parkinson consiste en mejorar, o al menos mantener o prolongar la funcionalidad del enfermo durante el mayor tiempo posible. En la actualidad, el tratamiento puede ser de tres tipos: farmacológico, quirúrgico y rehabilitador.

Muchos de los síntomas característicos de la enfermedad de Parkinson son debidos a una deficiencia de dopamina en el cerebro, pero el suministro de este neurotransmisor al paciente con el objetivo de reponer las reservas agotadas no resulta eficaz, puesto que la dopamina no puede pasar del torrente sanguíneo al cerebro. Por ello, los fármacos que se emplean en el tratamiento de la enfermedad de Parkinson (fármacos anti-parkinsonianos) usan otras vías para restituir de forma temporal la dopamina en el citado órgano o bien, imitan las acciones de la misma.

Pese al optimismo reinante en un principio, ninguno de los fármacos usados en el tratamiento de la enfermedad de Parkinson actúa sobre la progresión de la enfermedad. En la actualidad, los fármacos más usados son levodopa y varios agonistas de dopamina, aunque también tienen cierta relevancia otros como la selegilina (inhibidor de la MAO-B), la amantadina (liberador de dopamina) o la benzatropina (antagonista del receptor muscarínico de la acetilcolina).

La levodopa, un fármaco oral que combina con carbidopa o benseracida, lográndose con esto una reducción en las dosis necesarias y un amortiguamiento de los efectos secundarios periféricos. La estructura de la levodopa permite que esta penetre en el cerebro, donde se sobreviene la transformación en dopamina. En torno a un 80% de los pacientes tratados con levodopa manifiesta una mejoría inicial, sobre todo en lo referido a rigidez e hipocinesia, mientras que un 20% de las personas llega a recuperar por completo la función motora.

La efectividad de los agonistas de la dopamina sobre el control de los síntomas, especialmente sobre la bradicinesia y la rigidez, es sensiblemente menor que la de la levodopa, pero esto queda en parte compensado por una vida media más larga y una menor incidencia de desarrollo de fenómeno «encendido-apagado» y discinesias. Con la excepción de la cabergolina, el resto pueden usarse en monoterapia o asociados a levodopa. La utilización de estos fármacos se está extendiendo cada vez más como tratamiento único en los estadios tempranos de la enfermedad de Parkinson, siempre y cuando no se presente un predominio de temblor, con la finalidad de retrasar lo máximo posible la introducción de levodopa.

La bromocriptina, un derivado de los alcaloides del "Claviceps purpurea", es un potente agonista de la dopamina en el sistema nervioso central. Inhibidor de la adenohipófisis, fue usado inicialmente para tratar afecciones como la galactorrea o la ginecomastia, pero con posterioridad fue constatada su eficacia en la enfermedad de Parkinson. Su acción se prolonga más en el tiempo que la de la levodopa, de modo que no es necesario administrarla con tanta frecuencia. Se esperaba que la bromocriptina fuese eficaz en aquellos pacientes que dejasen de responder a levodopa por pérdida de neuronas dopaminérgicas, pero este hecho todavía no ha sido confirmado. Entre sus efectos adversos sobresalen las náuseas y vómitos, pero también se pueden presentar otros tales como congestión nasal, cefalea, visión borrosa o arritmias.

Otros agonistas dopaminérgicos son la lisurida, cuyos efectos adversos son parecidos a los de la bromocriptina, su administración es parenteral y actualmente no está aprobada para el tratamiento de la enfermedad de Parkinson en EUA, solo en Europa; la pergolida, que es el más potente y uno de los que más vida media presenta, sin embargo este medicamento fue retirado en marzo de 2007 del mercado estadounidense por su asociación con valvulopatías cardiacas; el pramipexol, un compuesto no ergolínico que produce efectos clínicos de importancia sobre el temblor y la depresión; el ropirinol, que al igual que el anterior es un compuesto no ergolínico, pero a diferencia de este puede causar crisis de sueño; y la cabergolina, que es un derivado ergolínico, con una larga semivida de eliminación que permite administración única diaria. Cabe destacar que los tres últimos agonistas de los receptores de dopamina son los que más recientemente se han introducido en el panorama farmacológico.

La selegilina es un inhibidor de la MAO selectivo para la MAO-B, que es la predominante en las zonas del sistema nervioso central que tienen dopamina. Con la inhibición de la MAO-B se consigue proteger a la dopamina de la degradación intraneuronal, así que en un principio este fármaco fue utilizado como un complemento de levodopa.

Tras descubrirse la participación de la MAO-B en la neurotoxicidad, se planteó la posibilidad de que la selegilina podría tener efecto neuroprotector retrasando la progresión de la enfermedad.

El descubrimiento accidental en 1969 de que la amantadina resultaba beneficiosa en la enfermedad de Pakinson, propició que esta dejase de ser usada únicamente como un fármaco antiviral, que era para lo que había sido concebida. Aunque los científicos no conocen con exactitud cómo actúa, han sido propuestos numerosos posibles mecanismos de acción partiendo de pruebas neuroquímicas que indican que incrementa la liberación de dopamina, inhibe la recaptación de aminas o ejerce una acción directa sobre los receptores de dopamina. Con todo ello, estudios recientes han sacado a la luz que inhibe la acción del glutamato, una sustancia química cerebral que provoca la generación de radicales libres.

Además de no ser tan eficaz como la levodopa o la bromocriptina, la acción de la amantidina se ve disminuida con el transcurso del tiempo. En contraposición a esto, sus efectos secundarios son cualitativamente similares a los de la levodopa, pero ostensiblemente menos importantes.

Actualmente se utiliza la amantadina asociada a Levodopa para logar controlar los trastornos motores, especialmente la discinesia y prolongar la vida útil de la Levodopa.

Anula la señal de cerebro que causa los temblores mediante la aplicación de una pequeña corriente eléctrica, a través de electrodos en el exterior de la cabeza de un paciente. Por lo que no conlleva los riesgos asociados con la estimulación profunda del cerebro. El TACS, funciona mediante la colocación de dos almohadillas de electrodos en el paciente, una cerca de la base del cuello y otra en la cabeza, por encima de la corteza motora (la parte del cerebro implicada en el control de los temblores). La corriente alterna que aplican los electrodos se hace que coincida con la señal oscilante de los temblores, de manera que la cancele, y se suprima el temblor físico. El estudio preliminar se ha llevado a cabo con 15 personas con la enfermedad de Parkinson en el Hospital John Radcliffe de Oxford. Los investigadores demostraron una reducción del 50% en los temblores en reposo entre los pacientes.

La estimulación magnética transcraneana o transcraneal es una técnica basada en la estimulación del cerebro mediante pulsos magnéticos generados por un dispositivo. Las evidencias demuestran que mejora la función de las extremidades superiores a corto plazo, y la marcha y los síntomas motores generales de la enfermedad de Parkinson a corto y largo plazo. No obstante, son necesarios más estudios de investigación que permitan desarrollar protocolos terapéuticos óptimos para la aplicación de esta técnica.

A mediados del siglo XX, la neurocirugía era el método que con más frecuencia se utilizaba para tratar el temblor y la rigidez característica de los pacientes aquejados de la enfermedad de Parkinson, pero el problema se hallaba en que no siempre se tenía éxito en las intervenciones quirúrgicas y en las complicaciones de gravedad que solían surgir. Con este panorama, el uso de la cirugía se vio reducido a partir de 1967 con la introducción en el mercado de la levodopa, un tratamiento alternativo que proporcionaba más seguridad y eficacia. Pero con el avance tecnológico experimentado en estos últimos años, se han logrado conseguir novedosas técnicas de imagen cerebral que han permitido mejorar la precisión quirúrgica, recuperando la neurocirugía su popularidad como tratamiento para algunas personas con enfermedad de Parkinson que por diversos motivos, ya no responden al tratamiento con fármacos.

Los estudios realizados en las últimas décadas han dado lugar a grandes mejoras en las técnicas quirúrgicas, por lo que la cirugía de nuevo se está utilizando en las personas con enfermedad de Parkinson avanzada para quienes la terapia farmacológica ya no es suficiente.
La cirugía para la EP se pueden dividir en dos grandes grupos: la estimulación cerebral lesional y la estimulación cerebral profunda ( ECP). Los ámbitos de actuación de la ECP o lesiones incluyen el tálamo, el globo pálido o el núcleo subtalámico.

La estimulación cerebral profunda (ECP) es el tratamiento quirúrgico más utilizado, desarrollado en la década de 1980 por Alim -Louis Benabid y otros. Se trata de la implantación de un dispositivo médico llamado marcapasos cerebral, que envía impulsos eléctricos a partes específicas del cerebro. La Estimulación cerebral profunda (ECP) se recomienda para personas que tienen enfermedad de Parkinson con fluctuaciones motoras y temblor no controlado con los fármacos, o para aquellos que son intolerantes a la medicación, siempre y cuando no tengan problemas neuropsiquiátricos graves.

Otro tratamiento quirúrgico menos común es la provocación de manera intencionada de lesiones para suprimir la hiperactividad de las áreas subcorticales específicas. Por ejemplo, la palidotomía implica la destrucción quirúrgica del globo pálido para controlar la discinesia.

Fue la enfermedad de Parkinson la primera enfermedad neurodegenerativa en la que se intentó realizar un trasplante nervioso en 1982, siendo este un hecho que alcanzó una notable repercusión mediática.

Es importante que los pacientes realicen ejercicio de manos, pero más importante es que un logopeda trabaje con el paciente el máximo tiempo posible, pues debe corregir la disfagia, el manejo de objetos, la hipofonía, la ansiedad, la micrografía y demás aspectos del lenguaje que solo este profesional puede hacer.

Si con el tratamiento farmacológico se consigue que los pacientes mejoren en cuanto a los síntomas motores se refiere, no sucede lo mismo con el equilibrio, pues este va empeorando a lo largo del transcurso de la enfermedad. De hecho, se han llevado a cabo varios estudios que demostraron que no se experimentan cambios en el equilibrio global en pacientes con enfermedad de Parkinson en relación con la administración del tratamiento farmacológico.

En los últimos años se han realizado múltiples estudios con el fin de identificar factores exógenos que pudieran modificar el riesgo de desarrollar la enfermedad de Parkinson. Mediante estudios retrospectivos de casos y controles se ha intentado relacionar el consumo regular de antiinflamatorios no esteroides y ciertas vitaminas con un menor riesgo de contraer la enfermedad pero los resultados obtenidos son contradictorios y no es posible inferir que el consumo de esos fármacos reduzca el riesgo. La asociación más firme en este momento es la mayor incidencia de enfermedad de Parkinson entre no fumadores: existe una relación entre la alteración de los niveles de dopamina producida por el tabaco y una disminución del riesgo de contraer párkinson pero los mecanismos de esa relación aún no han sido determinados.

En diversos estudios llevados a cabo hace poco en los que no solo se investigó la relación de la enfermedad de Parkinson con el tabaco sino también con el café se confirmó que el consumo de ambos disminuye el riesgo de padecer esa enfermedad porque una serie de receptores y sustancias, como la dopamina mencionada anteriormente, podrían proteger a las neuronas relacionadas con esa afección. No obstante, se necesitan más estudios acerca de ese tema para verificar dicha teoría. Además, el autor de una publicación sostiene que pensar que fumar es bueno es un autoengaño y una incongruencia. Por ejemplo, hay un mito basado en estudios que plantean que la incidencia de enfermedad de Parkinson disminuye en los pacientes fumadores cuando la realidad es que el hecho de que haya menos fumadores con enfermedad de Parkinson se debe en gran parte a que las personas que fuman viven menos y la incidencia de la enfermedad de Parkinson aumenta a edad avanzada (cuando los fumadores habitualmente han muerto de cáncer o enfermedad cardiovascular).

Algunos trabajos sugieren una relación entre el consumo de lácteos y la enfermedad de Parkinson.

En años recientes, la investigación sobre la enfermedad de Parkinson ha avanzado y actualmente existe un mejor conocimiento de la enfermedad. Esto está facilitando el desarrollo de herramientas más precisas para el diagnóstico, el cual actualmente sigue basándose en los signos clínicos, y nuevos tratamientos, si bien hasta la fecha la levodopa continúa siendo el tratamiento más eficaz.

En mayo y junio de 2016 se dieron a conocer varios descubrimientos importantes realizados en Estados Unidos. Por un lado investigadores de la Universidad Northwestern en Chicago descubrieron una nueva causa de la enfermedad de Parkinson relacionada con las mutaciones en un gen llamado TMEM230. Días después investigadores de la Escuela de Medicina de la Universidad de Pittsburgh, en Estados Unidos descubrieron la causa por la que la proteína alfa-sinucleína relacionada con el párkinson - un constituyente principal de los cuerpos de Lewy que son el sello patológico de la enfermedad de Parkinson- es tóxica para las neuronas en el cerebro.

La enfermedad de Parkinson presenta relaciones genéticas con numerosos rasgos y características de los seres humanos, lo cual puede servir de ayuda para el entendimiento de la patología. Por ejemplo, en un trabajo publicado por la revista Nature en el año 2016, se observó una correlación genética positiva con el volumen intracraneal. 






</doc>
<doc id="1130" url="https://es.wikipedia.org/wiki?curid=1130" title="Ecumenismo">
Ecumenismo

Ecumenismo es la tendencia o movimiento que busca la restauración de la unidad de los cristianos, es decir, la unidad de las distintas confesiones religiosas cristianas «históricas», separadas desde los grandes cismas. Del griego antiguo «οἰκουμένη» ("oikoumenē", aunque se pronuncia "ikuméni", “tierra habitada”). Si bien el término «"oikoumenē"» se utilizó desde los tiempos del Imperio Romano para expresar la totalidad de las tierras conquistadas, el mundo como unidad, en la actualidad la palabra «ecumenismo» tiene una significación eminentemente religiosa, y es usada para aludir a los movimientos existentes en el seno del cristianismo cuyo propósito consiste en la unificación de las distintas denominaciones cristianas que se hallan separadas por cuestiones de doctrina, de historia, de tradición o de práctica.

El ecumenismo es diferente del diálogo interreligioso; este último consiste en la búsqueda de cooperación entre diferentes religiones (tanto las religiones abrahámicas —judaísmo, cristianismo e islam— como otras).

En el sentir de numerosas personalidades cristianas del último siglo, el ecumenismo constituye un camino de superación de las divisiones entre los cristianos, en orden al cumplimiento del mandato de Cristo: «[...] que todos sean uno [...]» (Juan 17, 21).

Entre las muchas personalidades relevantes que tienen o tuvieron influencia en el desarrollo de la conciencia ecuménica se encuentran Robert Gardiner, el teólogo Yves Congar, el hermano Roger Schutz —fundador de la Comunidad ecuménica de Taizé—, Chiara Lubich —fundadora del Movimiento de los Focolares—, el patriarca Atenágoras I, los papas Juan XXIII, Pablo VI y Juan Pablo II, y el arzobispo de Canterbury Rowan Williams.

El término «ecumenismo» proviene del latín, «"œcumenicus"» y del griego, «οικουμενικός» ("oikoumenikós") y éste a su vez de «οἰκουμένη» ("oikoumenē"), y significa “lugar o tierra poblada como un todo”. El término ya era usado en el Imperio Romano para referirse a la totalidad de las tierras conquistadas. Sin embargo, en la literatura de la época romana el término tenía un significado político-imperial que superaba el sentido geográfico: implicaba «el mundo como unidad administrativa, el Imperio Romano».

Los romanos eran llamados "señores del «"oikoumenē"»" (Plutarco, "Tiberius Gracchus" 9, 6). Polibio escribió: "todas las partes del mundo habitado («"oikoumenē"») han venido a estar bajo el dominio de Roma" (Polibio, "Historias" 3,1,4). De la misma forma lo usó Dion Casio ("Historia Romana" 37,1,2; 43,14,16; 43,21,2) y Flavio Josefo, entre muchos otros. Flavio Josefo escribió que el rey Agripa dijo: "En el mundo habitable («"oikoumenē"») todos son romanos" ("La guerra de los judíos" 2, 388).

En los evangelios, el término «"oikoumenē"» es poco utilizado como tal. Por ejemplo, en Lucas 2,1 se señala: "Sucedió que por aquellos días salió un edicto de César Augusto ordenando que se empadronase todo el mundo («"oikoumenē"»)". También, el diablo tienta a Jesús ofreciéndole "todos los reinos de la tierra («"oikoumenē"»)" (Lucas 4, 5).

El significado de «"oikoumenē"» comenzó a tornarse decididamente positivo cuando Constantino I el Grande convocó el primer Concilio ecuménico de cristianos en Nicea, en 325, con la participación de obispos de todo el «"oikoumenē"». Así se creó un vínculo entre el concepto de universalidad de la Iglesia (es decir, sin exclusiones) y el término "ecuménico" («"oikoumenē"»).

El movimiento ecuménico estuvo marcado por diversos hitos. Entre ellos se pueden mencionar los siguientes:

Esta etapa coincidió con la historia del «Consejo Mundial de Iglesias» (CMI). Su estatuto, fijado provisionalmente en Utrech en 1938, a causa de la Segunda Guerra Mundial, no fue adoptado hasta la asamblea de Ámsterdam, en 1948. El consejo se definió, no como una «super Iglesia» o como una «Iglesia mundial», sino como una «comunidad de Iglesias que reconocen a Cristo como Dios y Salvador». Desde su fundación se han establecido 7 asambleas generales: Ámsterdam (1948); Evanston (1954); Nueva Delhi (1961); Upsala (1968); Nairobi (1968); Vancouver (1983) y Canberra (1991).

En cuanto a la Iglesia católica, el papa Juan XXIII produjo un cambio de rumbo con la creación del "Secretariado para la promoción de la unidad de los cristianos", una comisión preparatoria al Concilio Vaticano II que más tarde recibiría el nombre de Consejo Pontificio para la Unidad de los Cristianos. El 6 de junio de 1960, Juan XXIII designó al cardenal Augustin Bea como primer presidente del recién creado Secretariado.
El Secretariado participó en 1961 de la conferencia de Nueva Delhi y fue el responsable de la redacción de diferentes borradores de documentos críticos durante el Concilio Vaticano II, entre ellos el del decreto "Unitatis redintegratio" sobre el ecumenismo.

Las últimas palabras pronunciadas por Juan XXIII en su lecho de muerte exteriorizaron su compromiso ecuménico:

La Iglesia católica, a través del Concilio Vaticano II, estableció, entre otros puntos los siguientes:
El nuevo rumbo se profundizó con el papa Pablo VI, quien peregrinó a Tierra Santa del 4 al 6 de enero de 1964, en el primer viaje de un papa por el mundo. Como resultado de aquel acercamiento histórico, en una , Pablo VI y Atenágoras I, guías espirituales de los cristianos católicos y ortodoxos del mundo respectivamente, decidieron «[...] cancelar de la memoria de la Iglesia la sentencia de excomunión que había sido pronunciada [...]» en ocasión del Cisma de Oriente o Gran Cisma de 1054.

El 25 de mayo de 1995, Juan Pablo II publicó la carta encíclica "Ut unum sint" (del latín, "Que sean uno"), en la cual se instó a la unión de las iglesias cristianas mediante la fraternidad y la solidaridad al servicio de la humanidad. Ya el 10 de noviembre de 1994, en su carta apostólica "Tertio Millennio Adveniente" dirigida al episcopado, al clero y a los fieles con motivo de la preparación del jubileo del año 2000, Juan Pablo II instó a analizar el curso de los últimos diez siglos y señaló la falta de unidad de los cristianos entre «los pecados que exigen mayor compromiso de penitencia y de conversión», al tiempo que lo calificaba como «un problema crucial para el testimonio evangélico en el mundo».

El 31 de octubre de 1999 en Augsburgo, Alemania, se firmó la "Declaración conjunta sobre la doctrina de la justificación", por parte del cardenal Edward Cassidy en nombre de la Iglesia católica, y el obispo Christian Krause de la Federación Luterana Mundial. Joseph A. Fitzmyer, quien trabajó durante casi tres décadas en el diálogo ecuménico luterano-católico, proporcionó una contribución esencial para la elaboración de esta declaración. El documento representó un paso importante para zanjar las divisiones entre ambas denominaciones cristianas que llevaban 482 años, desde que el mismo día del año 1517, Martín Lutero clavó sus noventa y cinco tesis en la puerta de la iglesia del castillo en Wittenberg, en Alemania.

En el 2004 se fundó la comunidad religioso-ecuménica de los Misioneros y Misioneras del Amor Sacramentado, basada en la creación de proyectos sociales que promueven el amor y el servicio, en atención a diversas obras solidarias en la comunidad, sumado a la presencia de oratorios que invitan a todos a la oración universal y no el debate religioso.

En febrero del 2016, el papa Francisco y el patriarca de Moscú y de todas las Rusias Cirilo I de Moscú, firman una Declaración conjunta reunidos en Cuba, en este encuentro histórico, dichos líderes se abrazaron después de casi mil años de separación de sus iglesias.
En abril de ese año Francisco y los patriarcas Bartolomé I y Jerónimo II de Atenas, arzobispo de Atenas y de toda Grecia, firmaron una declaración ecuménica conjunta para manifestar su preocupación por la situación trágica de los numerosos refugiados, emigrantes y demandantes de asilo, que han llegado a Europa huyendo de situaciones de conflicto. El 31 de octubre del 2016, en el marco de su viaje apostólico a Lund (Suecia) con ocasión de la conmemoración luterano-católica por el quingentésimo aniversario de la Reforma iniciada por Martín Lutero, el papa Francisco participó en una ceremonia ecuménica y firmó junto a Munib Younan, presidente de la Federación Luterana Mundial, una declaración conjunta.

Una de las personas que más ha contribuido a la promoción de la idea del ecumenismo en el siglo XX, especialmente entre los jóvenes, fue el hermano Roger Schutz, fundador de la ecuménica Comunidad de Taizé. Su visión de la unidad cristiana deriva de la creencia de que Jesús no vino para iniciar una nueva religión, sino para revelar el amor de Dios y reconciliar a la gente entre sí. Por lo tanto, según el pensamiento de Roger Schutz, los cristianos pueden ser reconciliados unos con otros mediante la oración en común, que permite la entrada del Espíritu Santo en el corazón de la acción. En 1972, los jóvenes mostraron la importancia que brindan al mensaje ecuménico de Taizé, tal como se señaló en el periódico francés "Le Monde":

Un panorama general, basado en las apreciaciones de René Berthier, permite señalar los puntos siguientes referidos al estado de situación del ecumenismo hoy.

Anualmente, se celebra la Semana de Oración por la Unidad de los cristianos, que tradicionalmente se hace del 18 al 25 de enero, entre las festividades de la confesión de san Pedro, y la conversión de san Pablo. En otros lugares, se celebra en torno a la fiesta de Pentecostes.

Entre las personalidades reconocidas por su carácter ecuménico y sus aportes decisivos al ecumenismo se pueden citar:





</doc>
<doc id="1137" url="https://es.wikipedia.org/wiki?curid=1137" title="Extremadura">
Extremadura

Extremadura es una comunidad autónoma situada en la zona suroeste de la península ibérica. Está compuesta por las dos provincias más extensas de España: Cáceres y Badajoz. Limita al norte con las provincias de Salamanca, Ávila (Castilla y León), al sur con Huelva, Sevilla y Córdoba (Andalucía); al este, con Toledo y Ciudad Real (Castilla-La Mancha) y al oeste, con Portugal. Su capital es Mérida (antigua Augusta Emerita), ciudad reconocida por el Estatuto de Autonomía como sede de la Junta de Extremadura. 

La población total de Extremadura a 1 de enero de 2017 era de 1 079 920 habitantes según INE. Tiene varias denominaciones de origen tales como: Ribera del Guadiana en vinos; Dehesa de Extremadura en jamón; torta del Casar, queso de la Serena y queso de Ibores en quesos; aceite Gata-Hurdes, aceite Monterrubio en aceite de oliva y otras materias como el pimentón de la Vera, la ternera de Extremadura, el cordero de Extremadura, la miel Villuercas-Ibores o las cerezas del Valle del Jerte. El clima de su territorio es cálido en el sur y templado, e incluso frío, en el norte. Tiene una gran belleza medioambiental, sobre todo en el norte de la comunidad, y de un gran Patrimonio Histórico. Cuenta así mismo con un importante sector turístico, concentrado en las ciudades de Mérida, Cáceres, Plasencia, Badajoz, Trujillo, Garganta la Olla, Cuacos de Yuste, Guadalupe o Hervás, y en comarcas como el Valle del Jerte, el Valle del Ambroz o La Vera. El pico más alto de la región es el Calvitero, situado en el noreste de la provincia de Cáceres, en el Valle del Jerte, con 2405 msnm. Por Extremadura pasan dos de los ríos más importantes de la península ibérica: el Tajo, y el Guadiana. Gracias a ellos se produce una agricultura de calidad, con productos como pimentón, tomate, tabaco y arroz.

El Reino de León y el Reino de Castilla conquistaron la Taifa de Badajoz entre los siglos XII y XIII. Tras la formación de la Corona de Castilla por la unión de ambos reinos en 1230, la provincia de Extremadura se creó en 1371.

Extremadura es cuna de los más famosos conquistadores del Nuevo Mundo: Francisco Pizarro y Hernán Cortés, conquistadores de los imperios incaico y azteca, respectivamente, y Pedro de Valdivia, conquistador de Chile. Otros muchos e importantes conquistadores también nacieron en Extremadura.

El Día de Extremadura se celebra el 8 de septiembre, que coincide con la fiesta católica de la Virgen de Guadalupe.
Sobre los orígenes del nombre de Extremadura hay varias hipótesis:


No se debe confundir con la antigua provincia portuguesa de Estremadura, aunque el origen etimológico sea el mismo.

La prehistoria humana en Extremadura tiene su inicio cuando grupos de cazadores recorrieron las cuencas de los ríos más importantes para encontrar medios de supervivencia, allá por el paleolítico inferior y medio. De estos periodos existen abundantes restos como piedras de cazadores, talladas en piedra, que se corresponden con los periodos achelense y musteriense. Sin embargo, los restos de la época en la que apareció el homo sapiens sapiens son bastante escasos si bien alguno de ellos son de gran calidad e interés como son los encontrados en la Cueva de Maltravieso.

Las pruebas de presencia humana más antiguas del actual territorio de Extremadura datan del periodo Paleolítico Inferior. En los yacimientos —en su mayoría superficiales— se han hallado herramientas toscas de cuarcita y, en menor medida, de granito, pero no se han encontrado restos de cadáveres humanos. La técnica usada para construir las herramientas consistía en golpear la piedra con un percutor de piedra o cuerna hasta conseguir filos, puntas, muescas, hachas, picos, etc. Los restos más antiguos se corresponden con la fase media del periodo achelense, hace unos 700 000 años. Los yacimientos más antiguos están cerca de donde hay piedra adecuada para tallar y construir las herramientas y útiles. Además se encuentran cerca de los ríos y de los grandes afluentes. Las áreas de más concentración de yacimientos del periodo achelense sonen los alrededores de Mérida en el río Guadiana, río Zújar, pantano de Valdecañas, río Alagón, Jerte y "El Sartalejo". Los instrumentos más destacados de esta época son el bifaz, el hendidor y el pico triédrico.

Se han encontrado muy pocos restos en esta región y todos ellos son del periodo Musteriense. Se construyeron con una técnica mediante la cual calculaban el tamaño del instrumento antes de extraer de la piedra matriz un fragmento adecuado al instrumento que pretendían fabricar. Los útiles más característicos eran las raederas, denticulados y puntas. Todos ellos son menos pesados y menos toscos ya que fueron construidos con una tecnología más avanzada que los del Paleolítico Inferior. Los lugares donde se encontraron yacimientos del periodo musteriense se corresponden con los del periodo achelense, es decir, cerca de los ríos. Sin embargo, también se han hallado restos en zonas bajas y medias de sierras en Badajoz lo que da a entender que estos habitantes tuvieron una mayor capacidad de extensión territorial, una mayor adaptación para habitar ciertos lugares y conseguir caza, alimento y trabajo en ellos por parte de los habitantes de ese periodo.

Durante esta era aparece el "Homo sapiens sapiens" —el hombre actual— hace unos 50 000 años. En esta época fueron hechos los grabados y pinturas de la cueva de Maltravieso, santuario del arte cuaternario, y de las Minas de Castañar de Ibor. Todas son de estilo Magdaleniense. En la cueva de Maltravieso, se encuentran grabados de la silueta de una cierva, varios triángulos y otras figuras geométricas. Sobre todo se han encontrado más de 30 manos pintadas en negativo y, la mayoría de ellas, sin dedo meñique. No se han encontrado restos que sugieran que fuera habitada durante esta época, aunque sí de épocas posteriores, por lo que se puede deducir que era un lugar sagrado, no de habitación. Los restos encontrados se agrupan en tres tipos diferenciados: los óseos, los líticos y las hechas con hastas de animales. Destacan las hachas encontradas en el yacimiento de «Cabezo de Galisteo».

Aunque son muy pocos los datos que se conocen sobre el Epipaleolítico en la actual región de Extremadura, el Neolítico aportó la eclosión del fenómeno megalítico así como datos que aportaban conocimientos acerca de algunas modificaciones en la subsistencia de las comunidades humanas que habitaban la región. Las más importantes son la introducción de la ganadería y la agricultura, que se incorporaron a las actividades de caza y recolección ya existentes. En cuanto a la tecnología se refiere, la incorporación más importante es la de la cerámica que permitía el almacenamiento de los excedentes agrícolas.

Los estudios más recientes consideran que el Neolítico en Extremadura comenzó en la transición del V al IV milenio a. C. Se superó así el concepto de Neolítico Tardío que algunos autores habían empleado, creyendo que la aparición de la agricultura habría sido mucho más tardía en esta zona de España. Los yacimientos más representativos del Neolítico Antiguo son la cueva de la Charneca en Oliva de Mérida, el Cerro de la Horca en Plasenzuela, la Cueva de Boquique en Plasencia, la cueva de El Conejar en Cáceres y Los Barruecos en Malpartida de Cáceres. De este último yacimiento proceden las evidencias agrícolas más antiguas de la región, que fueron datadas a finales del VI milenio a. C. Los indicios de domesticación animal son débiles pero puede suponerse que la domesticación animal es contemporánea a la introducción de la agricultura. En estos yacimientos se han encontrado cerámicas decoradas, sobre todo la variedad conocida como «boquique», por haberse documentado por primera vez en esta cueva de Plasencia.

A partir del Neolítico Medio, a comienzos del siglo V a. C., se produjo la proliferación del megalitismo en la región. Existen pocos poblados conocidos de esta época, tan solo algunos datos del yacimiento de Los Barruecos. El fenómeno megalítico es, en cambio, bien conocido pues existen grandes concentraciones de dólmenes en diversas comarcas de la región. Conjuntos de este tipo de sepulcros megalíticos pueden encontrarse en Valencia de Alcántara, Cedillo, Santiago de Alcántara o Barcarrota además de otros ejemplares aislados de gran interés como el gran «dolmen de Lácara». Este fenómeno tuvo una gran perduración en el tiempo, perdurando hasta los inicios de la Edad del Bronce. Los enterramientos de esta fase solían caracterizarse por microlitos de sílex, cerámicas lisas y algunos ídolos placa.

El Neolítico Final es mejor conocido en las márgenes del Guadiana, con yacimientos como los de Araya o El Lobo, entre otros a los que añadiríamos el de Los Caños de Zafra recientemente. Se desarrolla a partir del 3500 a. C. y sentará las bases para la aparición del Calcolítico, a partir del III milenio a. C. Estos poblados tienen una verdadera vocación agrícola y ganadera. Su situación, próxima a tierras fértiles, suele ser en suaves lomas próximas a cauces de ríos. Las cerámicas se caracterizan por ser prácticamente lisas, con escasas decoraciones y formas simples. La cerámica más indicativa es la «cazuela carenada», que aparece corrientemente en los yacimientos de todo el Suroeste peninsular, demostrando la integración de Extremadura dentro de una dinámica cultural común caracterizada por el incremento demográfico y el afianzamiento, cada vez más claro, de la agricultura y la ganadería.

Durante el Calcolítico o Edad de Cobre, las comunidades humanas prehistóricas realizan avances en la explotación agropecuaria del medio, se desarrolla la metalurgia con el inicio de la transformación del cobre hacia el III milenio a.C en Castillejo. Se produce un desarrollo de la complejidad social tanto estructural como ideológicamente: hay desigualdad de roles y de bienes.

Entre los pueblos prerromanos más importantes que habitaron Extremadura se encontraron los vettones ("Vettoni"), que habitaron las actuales provincias de Cáceres (norte) y Salamanca, la provincia de Ávila y parte de la de Toledo. Los lusitanos ("Lusitani") (los más arquetípicos de Extremadura), que se extendían por casi la totalidad de la actual Extremadura y centro de Portugal, pueblos pastores dedicados al pillaje y la guerra; cabe destacar la imagen del líder lusitano Viriato y su resistencia férrea frente a los romanos. Situados al sur, próximos al Guadalquivir, se encontraban los célticos ("Celtici"), eran principalmente urbanos y ofrecieron poca resistencia a las tropas romanas, por lo que no fueron obstáculo para el avance de estas.

La tierra de esta confederación lusitana vivió una romanización completa y profunda. El grado de romanización alcanzado y la extensión de la provincia Ulterior aconsejaban un gobierno aparte, formándose la Lusitania en provincia aparte en tiempos de Augusto (s. II a. C.). La provincia de "Lusitania" acogía gran parte de Extremadura, y Portugal central.

Se construyeron numerosas vías de comunicación (calzadas), grandes urbes, destacando Augusta Emerita, fundada en el 25 a. C., ciudad muy significativa en el Imperio romano y capital de Lusitania, una de las provincias en que se dividió definitivamente la Península Ibérica. Un aspecto importantísimo fue la adopción de la lengua del Imperio, base de todos las futuras lenguas romances peninsulares.
La capital de la provincia de Lusitania, Emerita Augusta, se convirtió pronto en una ciudad rica y brillante, que en nada tenía que envidiar a las otras dos capitales de provincia hispanas, Tarraco y Corduba. Tenía una amplia y cuidada red de comunicaciones que la cruzaban para enlazarla con las restantes capitales de provincia y con otras ciudades; así, la Ruta de la Plata unía Asturias con Emérita y con Itálica; otras rutas conducían a Corduba; otras a Olisipo, a Conimbriga, pasando por el famoso puente de Alcántara. Mérida canalizó el comercio y la vida de la provincia hacia Roma, norte de África y Grecia. No cabe duda que se alcanzó un alto grado de bienestar. Esto lo demuestra el circo de Mérida, capaz de acoger a 30 000 espectadores. Se estima que su población llegó a superar los 50 000 habitantes en época romana. Fue la 9ª ciudad más importante de su época en todo el Imperio romano, incluso más que Atenas.

Vespasiano dio otro paso en la romanización al conceder el derecho de ciudadanía romana a todos los habitantes de la península ibérica, facilitando de este modo que los hispanos pudieran acceder a un cargo público. En el siglo III d. C. comenzaron los problemas. Bandas germánicas, constituidas por bárbaros, saquearon la provincia a su paso. Ello aconsejó fortificar las ciudades; de este tiempo datan las murallas de Mérida, Coria y Cáceres. El temido peligro llegaría en el s. V, dejando a la provincia abandonada y en ruinas. La ciudad de Norba Caesarina se extinguió. Otras, como Augustobriga, Cáparra y Iulipa cayeron en el olvido, a pesar de quedar en pie formidables monumentos. La Lusitania fue invadida primero por los alanos y después por los suevos. Con ellos entramos en época visigoda.

Con la llegada de los sarracenos. la Lusitania visigótica pasa a ser una Cora (división territorial) siendo Mérida su capital hasta la caída del Califato de Córdoba, cuando se constituye el Reino Taifa de Badajoz. En Extremadura se conservan numerosas huellas del periodo musulmán de más de 500 años en la zona, hasta 1248. Por destacar algunos de los existentes se puede citar la Alcazaba de Mérida siendo la primera alcazaba de la Península Ibérica, los restos de la fortaleza de Alange, la Alcazaba de Badajoz, el Aljibe de Cáceres, el castillo de Trujillo, y en Galisteo las murallas de la época almohade a base de piedras de río. En 1031 se crea el Reino de Taifas de Badajoz que recuerda geográficamente y es el mismo territorio en extensión que la Cora (división territorial) de Mérida. La Cora (división territorial) de Mérida fue una de las más extensas y poderosas de la península, llegando a tener una extensión mayor al área actual de la región extremeña.

Durante el período de la Reconquista los reinos de Portugal, León y Castilla conquistaron territorios de lo que hoy conocemos como Extremadura. El Reino de Portugal, bajo el mandato del Rey Alfonso I de Portugal y con la ayuda del guerrero Geraldo Geraldes, conocido como Geraldo «sem Pavor»), disputó con el Reino de León varios territorios del antiguo Reino de Taifas de Badajoz. La parte occidental del Reino Taifas de Badajoz fue reconquistada por Enrique de Borgoña, el cual recibió el condado portucalense (Oporto y tierras circundantes), con el título de «Conde de Portus Cale». Este condado se convertiría en un reino independiente años después y comenzaría su expansión hacia el sur hasta llegar a Faro.

El Reino de León reconquistó parte del territorio. El 17 de enero de 1213 Alfonso IX conquistó Alcántara. A esta ciudad la convirtió en la sede de la «Orden Militar de San Julián de Pereiro», posteriormente llamada Orden de Alcántara. En 1229 Alfonso IX tomó Cáceres tras varios intentos fallidos previos, siendo el primero el de Fernando II en 1169. El 19 de marzo de 1230 Alfonso IX conquistó Badajoz. También ese año llevó a cabo la conquista de Mérida —muy importante para los monarcas leoneses por ser sede episcopal de un obispado visigodo, lo cual lo encadenaba a la antigua tradición eclesiástica mozárabe—. El 25 de enero de 1233 un ejército encabezado por Fernán Ruiz conquistó la villa de Trujillo a los almohades. A esta región del Reino de León se la conoce como "Extremadura leonesa" desde las «Cortes de Benavente de 1202», que dividieron el Reino de León en cuatro regiones: León, Galicia, Asturias y Extremadura (leonesa). Desde 1230, con la conquista de Badajoz, como capital de un antiguo reino, se le concedieron fueros y privilegios de un extenso territorio, denominado también como Reino de Badajoz; apareciendo, desde la conquista de la ciudad, en las intitulaciones reales. En 1258 incluía los concejos de Badajoz, Cáceres, Ciudad Rodrigo, Galisteo, Granadilla, Jerez de los Caballeros, Montemayor y Salvatierra de Tormes.
Extremadura castellana

Por su parte, el Reino de Castilla también avanzó en la reconquista y en el año 1186 el rey Alfonso VIII fundó la ciudad de Plasencia sobre un asentamiento anterior para así garantizar y asegurar la posesión de Gredos y del Valle del Jerte. Se estableció la Vía de la Plata como frontera entre los reinos de León y Castilla. En este reino existió la región conocida como "Extremadura", "Extremaduras" o "Extremaduras de Castilla" y comprendía un amplio territorio, muy superior al actual, abarcando desde el río Ebro hasta el Sistema Central. Esta zona incluía cuarenta comunidades de villa y tierra, las vicarías de Serón y Monteagudo y las villas episcopales de las mitras de Osma, Segovia y Ávila. Además pertenecían a la región los territorios de los obispados de Ávila, Segovia, Sigüenza y Plasencia situados al sur del Sistema Central.

Con la unión de los reinos de León y Castilla en la Corona de Castilla, se unieron ambas regiones. En las «Cortes de Toro de 1371», Extremadura fue reconocida como región administrativa, y se denominó Provincia de Extremadura en las Cortes de Segovia de 1390. Es de resaltar que durante esta época convivieron pacíficamente islam, judaísmo y cristianismo, llamadas las tres culturas, hasta que los Reyes Católicos, después de finalizar la Reconquista decretaron para sus vasallos la conversión obligatoria al cristianismo de todo individuo judío o musulmán o la expulsión de los que no aceptaran la nueva doctrina oficial. En el siglo XIV se produjo un hecho relevante para la religiosodad del pueblo extremeño que fue, según ellos, la aparición de la Virgen de Guadalupe.

Un rasgo característico de la región fue la emigración masiva a América. Muchos de los emigrantes fueron hombres en busca de fortuna y fama que España ya no podía ofrecer tras la caída del Reino nazarí de Granada en 1492, el mismo año que se descubrió América. Entre los conquistadores que llegaron a América, destacan varios extremeños como Hernán Cortés, conquistador de México; Alonso Valiente, secretario de Hernán Cortés, que además contribuyó en la conquista de San Juan Bautista (Puerto Rico), Nueva Galicia, Honduras y contribuyó a descubrir el Canal viejo de Bahama; Francisco Pizarro quien anexionó los territorios Incaicos a la Monarquía Hispánica, Ñuflo de Chaves explorador y conquistador español del Paraguay y la zona suroriental de la actual Bolivia, fundador de la ciudad a la que le dio el nombre de su tierra natal Santa Cruz de la Sierra en Bolivia y Pedro de Valdivia, conquistador de Chile que bautizó como Nueva Extremadura, cuya capital fue Santiago de Nueva Extremadura.

Desde 1528, Trujillo fue la única capital del territorio, que tenía según el Censo de Pecheros de Carlos I, 48 789 vecinos pecheros, el 6,75 % de la población de la Corona de Castilla. El Censo de los Millones reconoce en 1591 la provincia de Trujillo como una de las provincias de España a la que pertenecían la mayoría de localidades de la actual Extremadura. El resto estaban en la Provincia de Salamanca y la Provincia de León de la Orden de Santiago. Esta provincia no contaba con derecho a voto en las Cortes de Castilla, dependiendo a nivel administrativo de la de Salamanca.

Uno de los acontecimientos determinantes de la historia moderna de Extremadura se produjo en 1580 con la unión de los Imperios de España y Portugal. Las dos superpotencias de la época se unieron bajo una misma corona. Extremadura está a similar distancia entre Madrid y Lisboa, las capitales de los dos Imperios, por lo que ciudades como Badajoz vivieron una época de esplendor, que quedó truncada con la Guerra de Restauración portuguesa que supuso la definitiva separación de ambos Reinos y que marcó la decadencia de Extremadura en los siglos posteriores.

La guerra de 1640 fue el inicio de una sucesión trágica de guerras devastadoras para Extremadura que no acabó hasta la finalización de las guerras napoleónicas, a principios del siglo XIX. La guerra menos referida en los libros escolares españoles, la llamada Guerra de Restauración portuguesa —"Guerra da Restauração", en portugués— mantenida con Portugal desde 1640 hasta 1668, transformó a Extremadura de una manera determinante y marcó su destino hasta tiempos muy recientes. La prepotencia de la nobleza española trató a Portugal, su vasto imperio, su singular cultura y su importancia naval y comercial, como un territorio más de un imperio por otra parte difícilmente gobernable en muchos aspectos, por lo complejo y extenso, durante el periodo en el que Portugal formó parte de la Monarquía Hispánica —1580 a 1640—, desde el reinado de Felipe II, hasta el de Felipe IV.

Analizada desde la perspectiva de sus consecuencias, especialmente para Extremadura, fue sin duda una de los peores servicios hechos a la historia de España, por unos gobernantes que les falto la altura de miras para entender el poder y la influencia que podría haber alcanzado aquel imperio, si esa unión dinástica hubiera tenido más éxito que el que tuvo. La guerra con Portugal transformó las ciudades y los pueblos extremeños de una manera notable. Se produjo una gran despoblación y un gran abandono de tierras de labor. Las continuas escaramuzas por la frontera y el asentamiento casi durante treinta años de los soldados en las poblaciones extremeñas provocó una crisis que se acrecentó tras el final de la guerra, al convertirse este territorio de nuevo en la «Extremadura». Otra vez territorio de frontera, con un imperio muy poderoso como vecino y con una gran carga de recelo tras el largo período de hostilidades.
En 1653 se pusieron a la venta dos votos en las Cortes. Uno lo compró Galicia y otro, por iniciativa de la ciudad de Plasencia, lo compraría Extremadura, por valor de 80 000 ducados. Las ciudades de Plasencia, Badajoz, Mérida y Trujillo y las villas de Cáceres y Alcántara se unieron para comprar dicho voto.

No habían pasado treinta y cinco años del final de la guerra con Portugal y España se ve envuelta en la Guerra de Sucesión Española (1702-1713), que acaba de arruinar Extremadura, con la práctica destrucción de Badajoz a manos austriacas y la destrucción de los pueblos del valle del Tajo y del Guadiana. A efectos transfronterizos, es una nueva guerra con Portugal, que viene a abrir aún más la brecha que separa ambos países. Buena prueba de ello es la destrucción por parte de los españoles, de Puente Ajuda en 1709, cuyas ruinas han sido durante siglos, la expresión material de desencuentro ibérico.

Durante la Guerra de la Independencia Española (1808-1814), Extremadura registra un nuevo periodo de convulsiones y penurias al estar situada en la encrucijada estratégica por la que pugnan las tropas ocupantes francesas y las nacionales, ayudadas por el ejército inglés al mando del duque de Wellington. Durante este periodo, la guerra y las hambrunas contribuyen aún más a la despoblación de la región. A modo de ejemplo, durante el verano 1809 se produce en la localidad de Hoyos la ejecución de Juan Álvarez de Castro, obispo de Coria a manos de las tropas francesas mandadas por el mariscal Soult.

En 1810, los franceses dividieron la provincia brevemente en las prefecturas de Cáceres y Mérida, antecedentes de las actuales provincias. En 1822 se produjo la división definitiva en provincia de Cáceres y provincia de Badajoz. La reforma administrativa de 1833 impulsada por Javier de Burgos fijó definitivamente las capitales provinciales, no sin ciertas resistencias por parte de Plasencia y Mérida.

La segunda mitad del siglo XX estuvo marcado por la sangría demográfica en la región. Se calcula que más de 800 000 personas abandonaron Extremadura para buscar una mayor prosperidad en otras regiones españolas, como País Vasco, Madrid o Cataluña y en otros países como Francia, Alemania u Holanda.

Desde los años 1980 han ocurrido, entre otros, los siguientes hechos en Extremadura:


La bandera de Extremadura, según determina el artículo 4-1 del Estatuto de Autonomía está formada por tres franjas horizontales iguales: la superior, de color verde, la central blanca, y la inferior, negra. Estos colores tienen una explicación histórica: el color verde era el color emblemático de la venera de la Orden de Alcántara, cuyos territorios y encomiendas se extendieron por gran parte de las provincias de Badajoz y Cáceres. El color blanco era utilizado en el pendón real de los monarcas leoneses que reconquistaron la región incorporándola al Reino de León. El color negro se tomó del estandarte de los reyes aftásidas de Badajoz, que crearon un gran reino musulmán sobre la mayor parte de Extremadura, en el siglo XI, y aportando un esplendor literario y cultural como nunca antes fue conocido.

El escudo de Extremadura es descrito en el título I de la Ley 4/1985, de 3 de junio, «del escudo, la bandera y del Día de Extremadura».

El Escudo de Extremadura debe figurar en:


Las medidas del escudo estarán en proporción 5/6 por lo que se refiere a la relación altura-anchura.
La superficie de Extremadura es de 41.633 km² lo que la sitúa como la 5.ª comunidad autónoma de España por superficie. Sus dos provincias son las de mayor superficie en España.

Extremadura reparte su territorio entre dos grandes cuencas hidrográficas, la del Tajo (Cáceres) y la del Guadiana (Badajoz) y tres cadenas montañosas paralelas: el sistema Central, las sierras Centrales Extremeñas y Sierra Morena. En la mayor parte de la región aflora el zócalo paleozoico aunque existen depresiones interiores más o menos grandes que acumulan arcillas y arenas del Terciario. La omnipresencia del granito y la pizarra obliga a los ríos a encajarse profundamente en el terreno. Las sierras interiores tienen un claro carácter apalachense, que es el tipo de relieve que predomina en las montañas de Extremadura.

A pesar de la aparente homogeneidad de su geografía Extremadura posee gran variedad ecológica. Las mayores elevaciones se encuentran en el sistema Central: Calvitero (2.404 m), El torreón (2.401 m), Canchal de Ballesteros (2.342 m), El Turmal (2.338), La Nijarra (2.214) todos ellos en el Valle del Jerte, Peludillo (2.250 m), Alto del Horco (2.162 m), Mesas Altas (2.070 m) y Peña Negra (1.637 m). En Las Villuercas se alcanzan los 1.601 m.

La mayor parte de las rocas del sistema Central se formaron durante el Carbonífero, en el seno de una antigua orogenia, la orogenia varisca o hercínica, posteriormente desmantelada durante el Pérmico y el Mesozoico. El relieve actual corresponde a la orogenia alpina. Se trata de un conjunto de fallas y bloques elevados y hundidos. En Extremadura se desarrollan las sierras y valles de la vertiente suroccidental: sierra de Gata, Las Hurdes, Montes de Tras la Sierra-Valle del Jerte, La Vera y la depresión del Tajo, con los valles del Tiétar, Alagón y Arrago. En este conjunto distinguimos cinco paisajes con personalidad propia: Gata, desde la sierra de Malvana en la frontera con Portugal hasta Las Hurdes. Las Hurdes, entre Puerto Viejo y el Alagón. El Alagón, entre Riomalo y el Puerto de Baños. El valle del Jerte, entre la sierra de Candelario y la sierra de Tormantos-Gredos. Y La Vera, entre la sierra de Tormantos y el Tiétar; es la vertiente sur de la sierra de Gredos.

Sobre el valle del Tajo se asientan una serie de cuencas sedimentarias, topográficamente más deprimidas que la penillanura y recubiertas por sedimentos por los ríos de la región. La más occidental es la de la vega de Moraleja, a los pies de la sierra de Gata y regado por el río Arrago a la altura de embalse de Borbollón. La vega de Coria-Galisteo se encuentra a continuación, sobre el río Alagón. Hacia el nordeste encontramos las vegas de Granadilla, hoy ocupadas por el embalse de Gabriel y Galán. Por último encontramos la cuenca del valle del Tiétar y Campo Arañuelo, la más grande, limitada por el escalón de La Vera y el propio Tajo, al sur de Gredos.

En el centro de la región aparece la penillanura, el zócalo paleozoico que es el soporte de todo el relieve. Se trata de una región llana, suavemente ondulada pero con los ríos profundamente encajados. En la penillanura central distinguimos dos sectores: los Llanos del Salor, al oeste sobre el curso del Tajo, y las Tierras de Cáceres y Trujillo en el centro a la izquierda del Tajo. Aparecen todos los tipos de formas de relieve sobre rocas metamórficas: berrocales, bolos, torres, rocas caballeras, tors, dorso de ballena, etc.
Las Sierras Centrales Extremeñas son, en realidad, las estribaciones más occidentales de los Montes de Toledo. Hacen de divisoria entre el Tajo y el Guadiana. Se trata de antiguos pliegues que fueron recubiertos por sedimentos y más tarde exhumados de nuevo, por lo que forman un típico relieve apalachense. Distinguimos tres conjuntos: Las Villuercas, Montánchez y San Pedro. Las Villuercas están formados por una serie de sierras de dirección noroeste-sureste y que llegan hasta Monfragüe en el Tajo. Su límite oriental es la sierra de Altamira que hace de frontera con Toledo. Montánchez se sitúa en el centro de la región entre las sierras de Guadalupe y San Pedro. La Sierra de San Pedro es la más occidental. Está formada por multitud de pequeñas sierras paralelas de altitudes similares. Montánchez y San Pedro tienen una dirección general de este a oeste.

Sobre el valle del Guadiana se asientan una serie de depresiones recubiertas de sedimentos, pero que tienen mayor continuidad y extensión que en el Tajo. Las Vegas del Guadiana, en torno a Mérida, en las que se distinguen la Vega Alta, en torno a Don Benito y la Vega Baja, entre Mérida y Badajoz. Hacia Portugal aparece de nuevo la penillanura, el Guadiana adopta una dirección norte-sur y las vegas se prologan por los Llanos de Olivenza.

La penillanura vuelve a cobrar protagonismo en el sur de la región. Vuelve a ser una región llana, suavemente ondulada pero con los ríos profundamente encajados, pero con pequeñas depresiones colmatadas por arcillas y arenas, y pequeñas sierras de tipo apalachense. Se distinguen tres comarcas: Tierra de Barros, un sector ligeramente deprimido recubierto de arcillas en torno a Almendralejo; La Serena, entre el río Zújar y el río Guadamez, un amplio glacis que pone en contacto la penillanura extremeña con la manchega y el valle de Alcudia; y Sierra Morena, una flexión de la penillanura que da paso al valle del Guadalquivir, en donde resaltan múltiples sierras de escasa altitud.

Al norte de la comunidad se alzan las sierras del sistema Central, con la sierra de Gredos, sierra de Béjar donde Extremadura alcanza su mayor altitud en el Calvitero con 2405 m y la sierra de Gata que la separan de la meseta norte castellana. En el centro encontramos, de este a oeste, la sierra de las Villuercas, la sierra de Montánchez y la sierra de San Pedro, que forman parte de los Montes de Toledo. Al sur se eleva Sierra Morena que separa Extremadura de Andalucía.

Extremadura reparte sus aguas entre dos grandes cuencas hidrográficas, la del Tajo y la del Guadiana, se estructura en torno a dos ríos que nacen fuera de la región.

El río Tajo es el que estructura Cáceres. Nace en los Montes Universales, Teruel, y desemboca en Lisboa. Entra en Cáceres tras pasar por El Puente del Arzobispo en Toledo y forma frontera entre Toledo y Cáceres hasta llegar a la cola del embalse de Valdecañas. El río se encaja profundamente en la penillanura lo que facilita la construcción de embalses. En la actualidad desde que se hace extremeño se encuentra, prácticamente, embalsado hasta Alcántara. Debido a este profundo encajamiento no se han asentado en sus orillas grandes poblaciones. Aguas abajo hace de frontera con Portugal y abandona definitivamente España tras el embalse de Cedillo. En Extremadura el Tajo recibe alguno de sus principales afluentes. Los principales afluentes por la derecha son:



Los principales afluentes por la izquierda son de mucha menor entidad, ya que nacen en las Sierras Centrales Extremeñas. Los principales son el río Gualija, el río Ibor, el río Almonte y el río Salor. De todos ellos solo el Almonte tiene una cuenca hidrográfica de cierta entidad. Recoge las aguas de las Tierra de Cáceres y recibe por la izquierda afluentes como el río Tozo y el río Tamuja. Se trata de un río encajado en la penillanura. El embalse de Alcántara ejerce su influencia hasta su curso medio.

El río Guadiana es el que estructura Badajoz. Nace en los manantiales de Pinilla, en Albacete y desemboca en un gran estuario en Ayamonte, Huelva, haciendo frontera con Portugal. Entra en Badajoz por el Estrecho de las Hoces, en la sierra de La Umbría, y a su salida se encuentra ya embalsado. Discurre por las Vegas Altas y por la Tierras de Mérida - Vegas Bajas del Guadiana, por lo que en sus orillas encontramos importantes poblaciones, como Villanueva de la Serena, Don Benito, Mérida y Badajoz. Tras pasar Badajoz hace de frontera entre España y Portugal y hasta que abandona definitivamente Extremadura después de regar los Llanos de Olivenza. Los afluentes del Guadiana son mucho más numerosos, pero más cortos y menos caudalosos.

La vertiente meridional de Sierra Morena entrega sus aguas al río Guadalquivir. En Extremadura se encuentran las cabeceras de algunos de sus afluentes como el río Bencébar y el río Viar.

Todos los ríos extremeños son ríos mediterráneos con un fuerte estiaje en verano, un máximo en primavera, un máximo secundario en otoño y un mínimo secundario en invierno. Son ríos de alimentación pluvionival. Una de las características más destacables de los ríos extremeños es que a lo largo de la mayor parte de su curso encontramos numerosos embalses. Frecuentemente la cola de uno se encuentra a poca distancia de la presa de otro. Son embalses tanto para regadío como para producción hidroeléctrica. Los canales para regadío son muy son modernos ya que la mayoría aparecen en los años de implantación del Plan Badajoz. Extremadura no es tierra de lagos, los pocos que existen son de carácter endorreico y muy pequeños, sin embargo en las numerosas dehesas de Extremadura existen innumerables charcas artificiales, que forman humedales más o menos grandes excavados en diversas partes de la dehesa para retener el agua de lluvia, y que hoy en día se han convertido en zonas húmedas de importancia.

El clima dominante en Extremadura es el mediterráneo, pero suavizado por la advección de masas de aire marítimo procedentes del Atlántico. Los centros de acción principales son el frente polar, que descarga sus masas de aire húmedas y el anticiclón de las Azores. En invierno a la región le alcanzan los efectos de los anticiclones térmicos que aparecen sobre La Mancha, que dan a la región un tiempo seco y frío, en esta situación son frecuentes las nieblas en el valle del Tajo y del Guadiana. No obstante, el murallón del sistema Central dificulta la entrada de la mayoría de los ciclones cargados de lluvia que atraviesan la península debido al efecto barrera, mientras que el efecto foehn proporciona a la región vientos secos y cálidos, que pueden llegar a ser fuertes. Los días nublados son escasos, aunque hay grandes diferencias entre las montañas, del sistema Central y el resto de la región. La insolación sobrepasa las 2600 horas. Las situaciones de gota fría en otoño son raras, ya que la región se encuentra relativamente lejos de las principales masas de agua. Cuando se producen está asociadas a gotas frías de mayor radio situadas sobre el golfo de Cádiz. La mayoría de las lluvias entran en la región por el suroeste. La orografía influye decisivamente en el clima de algunas partes de la región, creando microclimas muy húmedos en las sierras del norte, particularmente en las comarcas de La Sierra de Gata, Valle del Ambroz, Hurdes, Valle del Jerte y la Vera, donde las precipitaciones son muy abundantes.

Las precipitaciones son escasas en casi toda la región excepto el norte. La mayor parte de ella recoge menos de 600 mm anuales, y en el centro del valle del Guadiana no se alcanzan los 400 mm. En la sierra de Guadalupe alcanzan los 1.000 mm, pero donde más lluvias caen son en las montañas del sistema Central, donde se superan los 1.000 mm. El máximo se alcanza en la vertiente sur de la sierra de Gredos (Valle del Jerte, Ambroz y La Vera), donde se superan los 1.500 mm. Una de las características más notables, sobre todo en las regiones más secas es la irregularidad interanual. La época más lluviosa del año es la primavera, seguida del otoño. Son las épocas en las que llegan las masa de aire polar marítimo que trae el frente polar. El anticiclón de las Azores predomina en verano y aleja las lluvias. Encontramos tres, y hasta cuatro, meses de aridez en casi toda la región. A medida que ascendemos por las montañas los meses de aridez se reducen y en las montañas más altas quedan reducido a dos.

Las temperaturas presentan un patrón muy acusado de norte a sur. Las temperaturas medias anuales más frías se dan en el ángulo noroeste del sistema Central donde se sitúan en torno a los 13 ºC. Aumentan progresivamente a medida que nos desplazamos hacia el sur. En resto del norte de Cáceres tiene unas medias anuales en torno a los 15 °C y el sur sobre los 16 °C. Badajoz tiene unas medias anuales en torno a 17 °C, que desciende ligeramente en Sierra Morena. Las temperaturas más altas se alcanzan en el centro del valle del Guadiana, donde se superan los 17 °C de media anual. El mes más frío es enero y el más caluroso agosto, pero salvo en las montañas del Sistema Central en ningún mes se alcanzan temperaturas medias bajo cero. No obstante, en todos los sistemas montañosos las mínimas absolutas sí pueden estar por debajo de cero, por lo se dan heladas esporádicas. El verano llega a ser muy caluroso en toda superando las medias los 25 °C, e incluso llegando a los 40 °C las máximas absolutas.

Con estas características de precipitaciones y temperaturas que encontramos en Extremadura el balance hídrico es claramente negativo, con un mínimo muy acusado en verano y un largo periodo de recarga que no garantiza la total recuperación de los acuíferos en los años de sequía.

El contraste que introducen en la región las montañas dan a la comunidad autónoma de Extremadura una cierta variedad ecológica, aunque la mayor parte de la región pertenece al ámbito del bosque mediterráneo. Esta ha sido una región intensamente explotada desde tiempos de la Prehistoria en la que, no obstante, existen zonas menos explotadas. Sin embargo, el modelo de explotación del bosque, la dehesa, ha alcanzado tal nivel de equilibrio ecológico que permite al mismo tiempo la explotación del medio natural y el desarrollo de la vida salvaje. La dehesa es un modo de explotación del bosque en el que se arrancan las especies competidoras de aquellas que explotamos agrícolamente. Aparece, así, el estrato arbóreo, con encinas y alcornoques, y el prado, con hierba para que paste el ganado. También se intercalan explotaciones agrícolas. Se trata de un sistema de explotación que se remonta, al menos, a la época romana.

El piso basal domina en la mayor parte de la región en él aparece el bosque mediterráneo. La vegetación típica es xerófila, ya que tiene que soportar la aridez estival. La especie dominante es la encina. El sotobosque es leñoso, espinoso y aromático, con especies perennifolias como el lentisco y el aladierno. En el cortejo florístico aparecen especies como la sabina, el madroño, el romero, el tomillo, las jaras, etc. En las zonas más húmedas aparece el roble como especie dominante. Es muy importante el bosque galería, en el que aparecen especies frondosas como el álamo, el chopo o el olmo, que encontramos en los márgenes de los ríos y las charcas.

En el piso montano aparece el roble como especie dominante, y es el piso más alto de la mayor parte de las montañas de la región. Esta zona ha sufrido la presión antrópica, por lo que encontramos especies de repoblación, principalmente de pinos alóctonos de rápido crecimiento.

El piso subalpino solo aparece en el Sistema Central. Aquí aparece el roble y el haya. En el piso alpino, que solo se da en el entorno de la sierra de Gredos (Valle del Jerte, Ambroz y La Vera) aparece la pradera alpina. Este piso ha sido utilizado para pasto de verano al menos desde la Edad Media y hasta mediados del siglo XX.

Extremadura es una de las regiones europeas que cuenta con el sistema natural menos degradado del continente, pese a ello el número y nivel de protección de estos espacios es claramente insuficiente. No obstante, Extremadura posee un Parque nacional, dos Parques Naturales, una Reserva Natural, un Paisaje Protegido, un Geoparque, cuatro monumentos naturales y numerosas ZEPAs, o Zonas especiales de protección de las aves.
El 17 de septiembre de 2011 las comarcas de Villuercas, Ibores y Jara fueron incluidas en la red mundial de Geoparques de la mano de la UNESCO. Geoparque Villuercas-Ibores-Jara es el 5º Geoparque de España. Su singularidad geológica (ligada a la formación de los Montes Apalaches de EE. UU.) y natural hacen de estas comarcas un destino turístico de interés regional.

El 3 de marzo de 2007 el Consejo de Ministros aprobó declarar Monfragüe como Parque nacional, convirtiéndolo en el parque nº 14 de estas características en España. Anualmente recibe más de 80.000 visitas.

Extremadura cuenta con dos Parques Naturales declarados y gestionados por la Junta de Extremadura, que son el Parque Natural de Cornalvo, en Badajoz y el Parque de Tajo Internacional, entre Cáceres y Portugal.






Desde el nacimiento de la comunidad autónoma de Extremadura hasta el año 2008 no existió una división comarcal oficial en Extremadura. El Estatuto de Autonomía preveía la posible división de Extremadura en comarcas a través de una ley, pero no fue hasta 2008 cuando, como consecuencia de la crisis económica y la necesidad de racionalización del gasto público, la Junta de Extremadura impulsó un proceso de comarcalización basado en la creación de mancomunidades integrales. Desde entonces, todos los municipios de Extremadura pertenecen a una, y solo a una, mancomunidad integral. Extremadura se divide en 33 mancomunidades integrales: 15 en la provincia de Badajoz y 18 en la provincia de Cáceres. Todos los municipios, a excepción de Badajoz, Cáceres, Mérida, Plasencia y Navalmoral de la Mata, pertenecen a alguna de las 33 mancomunidades en las que se ha dividido la región. 




Además pueden existir zonas naturales consideradas popularmente en ocasiones como comarcas pero que no se encuentran reconocidas oficialmente: Valle del Ambroz, Campo Arañuelo, Valle del Jerte, Las Hurdes, Las Villuercas, Los Ibores, La Jara cacereña, la Sierra de Gata, y Trasierra - Tierras de Granadilla.

Al margen de la división mancomunal, que es la única oficial en toda Extremadura, la Diputación de Badajoz ha dividido tradicionalmente su provincia en comarcas, aunque estas nunca han sido instituciones oficiales.

Extremadura se organiza territorialmente en 388 municipios, de los cuales, 223 se encuentran en Cáceres y los 165 restantes, en Badajoz. Posee el 4,77% de los municipios totales que integran el territorio español (8124). Las dos provincias poseen un gran número de municipios. La provincia de Cáceres es una de las provincias españolas con mayor número de ayuntamientos y se sitúa claramente por encima de la media española, cifrada en unos 163 municipios por provincia. (Burgos cuenta con el mayor número de términos municipales con 371 ayuntamientos, y Las Palmas es la provincia que tiene menos con 34). Badajoz supera ligeramente la media española, aunque se la puede considerar en ella.

El Estatuto de Autonomía de Extremadura dispone que la Comunidad Autónoma tiene competencia para fijar las demarcaciones de los órganos jurisdiccionales en Extremadura y su localización de acuerdo con lo que establezca la Ley Orgánica del Poder Judicial de España, legislación que atribuye a las Comunidades Autónomas la determinación de la capitalidad de los partidos judiciales. Existen veintiún partidos judiciales en Extremadura, los cuales están encabezados por las siguientes localidades:





En otro tiempo existieron también los partidos de Fuente de Cantos, Puebla de Alcocer, Jarandilla de la Vera, Serradilla, Gata, Granadilla, Alcántara, Garrovillas y Montánchez.

La superficie media de los municipios extremeños es de 131,92 km² en Badajoz y 89,09 km² en Cáceres, un promedio bajo el que se esconden grandes oscilaciones. Los cinco términos municipales más grandes son Cáceres, con 1.750 km²; Badajoz, con 1440,37 km²; Mérida, con 865,61 km²; Jerez de los Caballeros, con 740,55 km²; y Alburquerque, con 723,23 km².

Los tres primeros son también los más poblados de Extremadura. Badajoz es el 43º municipio más poblado de España y el único que sobrepasa los 100 000 habitantes en la Comunidad, aunque Cáceres está cercano a esa cifra.


Con un censo de 911.433 electores, los votantes fueron 650.774 (71,40%) y 260.659 las abstenciones (28,6%). La coalición PSOE-Socialistas Independientes de Extremadura ganó las elecciones, aunque por mayoría simple. El PP perdió su mayoría simple anterior pasando a ser la segunda fuerza más votada, mientras que la coalición Ganemos Extremadura-IU-Los Verdes quedó fuera de la Asamblea, perdiendo los tres escaños de IU en la legislatura anterior. A cambio, entraron por primera vez en la Asamblea Podemos y Ciudadanos-Partido de la Ciudadanía. Habiendo pactado el apoyo de Podemos, y con la abstención de PP y Ciudadanos, el candidato socialista Guillermo Fernández Vara obtuvo la investidura como presidente de la Junta.

Aparte, se contabilizaron 8.561 (1,34%) votos en blanco.

 
Fueros vigentes propios de Extremadura son el Fuero de Baylío (siglo XIII), reconocidos en su Estatuto de Autonomía (el resto, como el de Badajoz, actualmente no están vigentes).

Las primeras instituciones de las que se tenga constancia son la Capitanía General y el Real Ejército de Extremadura (principios del siglo XVII), conformadas dentro de la antigua Provincia de Extremadura (con independencia jurídica en 1653, aunque ya existía previamente una concepción geográfica y cultural de la misma), conformándose formalmente en 1785, con su reconocimiento de facto con la creación de la Real Audiencia de Extremadura (1790); cuya existencia real y unitaria proyecta una particular historia y cultura compartidas, cuyos orígenes más remotos se remontan al siglo XII en la "Estremadura leonesa" como entidad territorial dentro de la Corona de León (extendiéndose a Badajoz), posteriormente dentro de la Corona castellano-leonesa y más tarde integrada en la Monarquía Hispánica. 

Las Extremaduras alcanzarían su independencia administrativa en las Cortes de Segovia de 1390.

Sus orígenes etimológicos se remontan a la Reconquista.

El pensador y médico Antonio Elviro es considerado el padre del regionalismo extremeño, y en lingüística extremeña las obras de Luis Chamizo y José María Gabriel y Galán; anteriormente de Diego Sánchez de Badajoz en el siglo XVI.

La población de Extremadura es de 1.072.884 habitantes (1 de julio de 2017), fuente INE, por tanto, representa el 2,3% de la población española (46.549.045). Posee una densidad demográfica de 25'77 h/km, muy inferior a la media de España. La provincia más poblada es Badajoz, con 691.715 habitantes, con una densidad de población de 31,78 hab/km² y, su superficie, 21.766 km², es la provincia más extensa de España. En Cáceres viven 413.766 habitantes, con una densidad de población de 20,83 hab/km² y, una superficie de 19.868 km², es la segunda provincia más extensa de España después de Badajoz. La población de Extremadura está muy irregularmente repartida. Badajoz acumula 148.334 habitantes, y es la única ciudad de la comunidad que supera los 100.000 habitantes. Solo tres poblaciones tienen más de 50.000 habitantes: Badajoz, Cáceres y Mérida, una supera los 40.000: Plasencia y otras nueve con más de 10.000: Don Benito, Almendralejo, Villanueva de la Serena, Montijo, Zafra, Navalmoral de la Mata, Villafranca de los Barros, Coria y Olivenza.

De los 383 municipios 195 no llegan a los 1.000 habitantes. Solo hay 3 municipios que no llegan a los 100 habitantes. La población extremeña tiene un carácter notablemente rural. Solo el 27.49% de la población vive en las tres ciudades de más de 50.000 habitantes (Badajoz, Cáceres y Mérida, y el 48'56% en las ciudades de más de 10.000, aunque la mayoría de los pueblos son medianamente grandes, entre 1.000 y 10.000 habitantes. Las zonas más densamente pobladas son las de Badajoz, Mérida, Plasencia, Jaraíz de la Vera y Talayuela, aunque también Cáceres, cuya densidad está un poco distorsionada debido a que es el municipio más extenso de España. Son densidades de unos 50 h/km. Los ejes Plasencia–Cáceres–Mérida–Almendralejo–Zafra y Badajoz–Mérida–Don Benito–Villanueva de la Serena son los más poblados de la región, con densidades en torno a los 40 h/km. El este de la región y la comarca de los Llanos de Olivenza y en Valencia de Alcántara, las densidades no superan los 20 h/km. Así pues, la mayor parte del territorio de la región tiene un fuerte carácter rural.

A partir del alarde realizado en septiembre de 1502 por orden de Isabel I de Castilla, se estimó una población de 70.000 vecinos y 350.000 habitantes. La población extremeña, según el censo de 1591 de las provincias de la Corona de Castilla, había ascendido a unos 540.000 habitantes y suponía el 8% del total de España. No se volvió a realizar un nuevo censo fidedigno en España hasta el año 1717, año en que contaba con 326.358 habitantes.

Desde esta época, se produjo un aumento de la población más o menos constante hasta los años 1960, en el siglo XX (1.379.072 habitantes en 1960), a partir de la cual comenzó un descenso vertiginoso de la población debido a la emigración a otros países y regiones más prósperas de España. Casi un millón de extremeños se vieron obligados a abandonar su tierra natal a lo largo del siglo XX. Un fenómeno que se vio acentuado a partir de la década de los sesenta debido al fuerte crecimiento de la población y a la imposibilidad de encontrar trabajo en la región. Entre 1950 y 1977 salieron de Extremadura 645.000 habitantes, es decir, el 45% de su población a mediados de siglo. La mayor parte de ellos tenía entre 20 y 40 años. Este éxodo de miles de jóvenes contribuyó al desarrollo de otras regiones a la par que se perpetuó por más tiempo la pobreza y el subdesarrollo de la comunidad extremeña.

Muchos de ellos emigraron a otras regiones peninsulares, pues de hecho, todavía en 1987, 729.532 extremeños vivían en distintas Comunidades Autónomas españolas, la mayoría en Madrid, Cataluña y el País Vasco por este orden. Sin embargo, otros muchos tuvieron que marchar a otros países europeos, sobre todo a Francia, Alemania, Suiza, Holanda y Bélgica. Esto provocó un estancamiento de la población que todavía en el 2006 era inferior a la que tenía la región en 1930.

A lo largo del siglo XX Extremadura ha ido aumentando su población a un ritmo muy inferior que el conjunto de España, por lo que su peso relativo ha ido descendiendo continuamente. En realidad se pueden distinguir dos períodos, la primera mitad del siglo, donde las tasas de crecimiento están parejas, y la segunda mitad del siglo XX, cuando la tasa de crecimiento de Extremadura cae precipitadamente. No obstante las capitales de provincia, y Mérida, han ganado población, mientras que el resto de la provincia lo ha perdido. Sobre todo a partir de 1960. En algunas comarcas la pérdida ha sido tan grande que han llegado a convertirse en despoblados, con densidades demográficas inferiores a 5 h/km. Las tasas de natalidad han sido inferiores a la media española y las de mortalidad un poco superiores debido al envejecimiento de la población. A este proceso hay que añadir la existencia de movimientos migratorios.

Las tasas de natalidad y mortalidad han seguido el ciclo general de la transición demográfica del conjunto de España. No obstante, la natalidad, desde los años 60, se sitúa por debajo de la media española, debido a la emigración, que afecta a la población en edad reproductora. A partir de entonces el envejecimiento ha hecho subir un poco la tasa de mortalidad. En las comarcas más despobladas el índice de masculinidad es elevadísimo por lo que sus habitantes tienen grandes dificultades para contraer matrimonio.

En Extremadura la estructura urbana es muy laxa. No existen grandes ciudades. Badajoz es el centro urbano más poblado y sin embargo su área de influencia no alcanza a toda la región, salvo para algunos servicios, debido a la fuerte influencia de otros núcleos de población. Junto con Badajoz, también es núcleo de máximo nivel Cáceres: quinto nivel.

El cuarto nivel está formado por siete capitales comarcales: Mérida, Plasencia, Don Benito, Almendralejo, Zafra, Navalmoral de la Mata, Trujillo y Miajadas. Tienen una gran cantidad de servicios centralizados pero estos dos niveles son insuficientes para la región. El este de la región y el norte dependen, en buena medida de centros extrarregionales: Ciudad Rodrigo, Béjar o El Barco de Ávila en Castilla y León; Talavera de la Reina o Ciudad Real en Castilla-La Mancha: y Córdoba o Sevilla en Andalucía.

En el tercer nivel se encuentran poblaciones con bastante población pero cuyo nivel de servicios no ha superado ciertos niveles debido a la cercanía de núcleos mayores, más algunos pueblos con poca población que han conseguido un nivel notable de servicios por estar lejos de los grandes centros urbanos: Villanueva de la Serena, Coria, Olivenza, Jerez de los Caballeros, Talayuela, Azuaga, Jaraíz de la Vera, Castuera, Valencia de Alcántara, Fregenal de la Sierra, Casar de Cáceres, Logrosán, Montánchez, Gata, Nuñomoral, Alcántara y Almendral.

En un segundo nivel estarían los núcleos de población que han conseguido atraer unos pocos servicios centrales extendiéndolos así por gran parte de la región: Montijo, Moraleja, Arroyo de la Luz, Cabeza del Buey, Oliva de la Frontera, Llerena, Montehermoso, Fuente de Cantos, Malpartida de Cáceres, Hervás, Herrera del Duque, Barcarrota, Talarrubias, Torrejoncillo, Aliseda, Cabezuela del Valle, Zorita. Por debajo están los núcleos rurales.

Como podemos ver en Extremadura los lugares centrales que prestan servicios están muy mal distribuidos y no cubren eficazmente toda la región. A medida que mejoran las comunicaciones estas diferencias tienen menor importancia, pero grandes áreas de la región están muy mal comunicadas.

El poblamiento rural extremeño presenta una tendencia muy fuerte al núcleo concentrado. Muchos son los factores que favorecen esta concentración: baja productividad de la tierra por hectárea, factores históricos y sociales en los que el modo de explotación de la dehesa, por medio del dominio directo y la gran propiedad explica la existencia de grandes pueblos concentrados en los que viven gran número de jornaleros. No debemos olvidar que los núcleos concentrados de las montañas se explican por la dificultad de encontrar asentamientos adecuados. A pesar de este carácter concentrado, los pueblos al norte del Tajo son muy pequeños. El tamaño aumenta entre el Tajo y el Guadiana, tanto más grandes cuanto más al sur, debido a la mayor presencia de la gran propiedad. Si bien el uso de la cal en fachadas es habitual en la mayor parte de la región, el sur de Badajoz es la tierra de los pueblos blancos por excelencia. En estas comarcas los pueblos se organizan en torno a una gran plaza porticada. Tienen calles que tienden a ser rectas, y tienen en torno al pueblo una corona de pequeñas huertas de propiedad de los vecinos del pueblo, fundamentales en el pasado para completar la dieta de los jornaleros.

El carácter extensivo de la agricultura, reforzado por la política con actos como los del Plan Badajoz, el Plan de Empleo Rural y las ayudas de la UE ha logrado fijar población en los pueblos, pero con pocas perspectivas de crecimiento. No obstante, en los últimos años, gracias a los avances de la tecnología, la productividad de la tierra ha aumentado y se comienza a notar menos el peso de la gran propiedad. La gran propiedad ha hecho surgir un tipo de casa rural muy extendido: el cortijo. Se trata de una casa con varias edificaciones en torno a un patio que albergan diversas funciones: vivienda, cuadra, almacén de alimentos, etc.

Los municipios de Extremadura que poseen más de 7.000 habitantes son 20 (INE, 1 de enero de 2017):

En el territorio extremeño hay 31.388 extranjeros, según el INE a 1 de enero de 2017, de los cuales 18.639 viven en la provincia de Badajoz y los 12.749 restantes en la de Cáceres. La comunidad inmigrante más numerosa es rumana con 8.615 personas, seguida por la marroquí con 7.202 personas, y después la portuguesa con 3.305 personas. Los chinos suman 1.644 y los brasileños 1.371. Entre los naturales del África subsahariana que viven en Extremadura, la comunidad más numerosa es la de los senegaleses con 193 miembros. En lo que respecta a las personas procedentes de América Latina, salvo Brasil, el resto de nacionalidades han pasado en los últimos años a ser apenas destacables, ya que la población colombiana, por ejemplo, pasó de 1.725 en el año 2009 a apenas 873 personas en el año 2017 en toda la región.

En Extremadura la única lengua reconocida como oficial es el castellano, que además es el idioma materno y corriente de más del 97% de la población. No obstante en su territorio se habla minoritariamente otras lenguas iberorromances:

 
En Extremadura están presentes numerosas confesiones religiosas. La mayor parte de los extremeños pertenecen a alguna religión cristiana, desde el catolicismo, que es la que más fieles congrega, a las confesiones evangélicas y anglicanas, además, existen en Extremadura Testigos de Jehová y miembros de La Iglesia de Jesucristo de los Santos de los Últimos Días (mormones). No obstante, también hay en la región personas judías y musulmanes, estos últimos con una presencia notable en la Comunidad, que se estima en torno a los 20 000 fieles al Corán.

Según el Barómetro Autonómico publicado por el CIS (Centro de Investigaciones Sociológicas) en 2012, la afiliación religiosa en Extremadura es:


Ante la pregunta: "¿Con qué frecuencia asiste Ud. a misa u otros oficios religiosos, sin contar las ocasiones relacionadas con ceremonias de tipo social, por ejemplo, bodas, comuniones o funerales?" Las respuestas fueron:
Destacan las devociones a:

El mayor peso en la economía de Extremadura corresponde al sector servicios (57%). La construcción y las pequeñas y medianas empresas son la base de una economía que está desarrollando un comercio incipiente con las tierras vecinas de Portugal y que mantiene un alto grado de terciarización debido al auge que el turismo medioambiental y cultural está produciendo en los ámbitos rurales, tradicionalmente agrícolas, de su territorio.
Extremadura goza aún en nuestros días de un crecimiento económico superior al de la media española, sin duda partiendo de un retraso económico histórico pero descubriendo y desarrollando nuevas posibilidades de mercado en el sector turístico, del comercio y agroalimentario, principalmente. El proyecto de instalar una refinería de petróleo en el sur de la región ha originado una polémica de nivel regional. La región tiene más de 400.000 afiliados a la Seguridad Social, según los datos de 2007. En Extremadura existen alrededor de 8.000 industrias, la mayoría son pequeñas y medianas empresas. Los principales subsectores son la energía, agroindustria, corcho, piedra ornamental, maquinaria y textil. En materia energética, el desarrollo de embalses y saltos de agua ha dado paso a una estable explotación de los recursos hidroeléctricos y a una producción de energía mayor que las necesidades de consumo de la propia región.

Extremadura es una región que produce más energía eléctrica de la que consume. En el año 2012, su generación neta fue de 18 506 Gwh, mientras que su consumo fue de 4 244 Gwh, un 5,4 % inferior al año 2011.

En ese año 2012 la capacidad instalada en la comunidad era de 4 386 MW en régimen ordinario (hidráulica y nuclear) y 1 245 MW en régimen especial, que incluye 539 MW en solar fotovoltaica y 649 MW en solar termoeléctrica. Dentro del régimen ordinario destacan la central nuclear de Almaraz y las centrales hidroeléctricas de Cedillo, José María de Oriol, Gabriel y Galán, Torrejón, Valdecañas y Cíjara.

Las carreteras de Extremadura tienen diferentes titularidades. Existen, al menos, cuatro grandes administraciones titulares de carreteras en la Comunidad Autónoma de Extremadura: el Ministerio de Fomento, la Junta de Extremadura, la Diputación de Badajoz y la Diputación de Cáceres.

Las autovías del Estado que pasan por Extremadura son:

Las autovías autonómicas de la comunidad autónoma extremeña son:

Además, existen otras redes de carreteras gestionadas por los Ayuntamientos en los términos municipales de su competencia.

En el transporte público de la región, destacan los autobuses sobre cualquier otro medio de transporte público. En la región operan varias empresas para el transporte de viajeros de unas localidades a otras, tales como LEDA o CEVESA. En las principales ciudades, como Badajoz, Cáceres, Mérida y Plasencia, existen líneas urbanas de autobús.

En cuanto al ferrocarril, las ciudades de Extremadura no cuentan con redes de metro, tren de cercanías ni tranvía. Las únicas líneas de tren son las líneas que unen la región con otros lugares de España y Portugal, que últimamente se encuentran deterioradas. Se han cancelado las obras para la alta velocidad, con estaciones en Navalmoral de la Mata, Plasencia, Cáceres, Mérida y Badajoz. y en su lugar, se piensan implantar vías convencionales rentables con una capacidad de 200km/h y se quiere poner el Talgo para el 21 de junio de 2013. De todas formas, hoy en día, Extremadura cuenta con varios trayectos de Regional e Intercity.

En la región se distribuyen los principales diarios nacionales: "El Mundo", "El País", "ABC", "La Razón", "La Vanguardia", "El Periódico"... También se distribuyen las principales revistas sobre todo tipo de temas, por ejemplo: "Cuore", "Lecturas", "El Jueves", "Jara y Sedal"...
A nivel autonómico existen el diario "HOY" perteneciente a "Vocento" que se centra más a la provincia de Badajoz y "El Periódico de Extremadura" perteneciente al "Grupo Zeta" que se centra más el provincia de Cáceres. Ambos diarios tienen sedes en las principales ciudades de Extremadura.
A nivel local el periódico más importante de la región es "La Crónica de Badajoz" que se distribuye en dicha ciudad. Aparte también existen pequeños periódicos y revistas comarcales y locales de menor importancia que se reparten de forma gratuita o pagando en los quioscos.

En la capital extremeña, Mérida se encuentra la sede principal en la región de la "RTVE" desde la que emite "RNE". Aparte existen sedes más pequeñas de esta institución en Badajoz, Cáceres y Plasencia. Desde estos puntos emite a nivel regional "RNE" el boletín territorial "Crónica de Extremadura", de lunes a viernes.
En diferentes puntos de la geografía extremeña hay sedes de las principales radios privadas nacionales por donde emiten a nivel regional. Son, por ejemplo: "Los 40 Principales", "esRadio", "COPE", "Cadena SER", "ABC Punto Radio",
"Cadena 100", "Cadena Dial", "Europa FM", "Onda Cero"...

Actualmente en Mérida se encuentra la sede principal de la radio extremeña pública "Canal Extremadura Radio" perteneciente a la "CEXMA". Además de esta sede tiene otras en Badajoz, Cáceres, Plasencia, Villanueva de la Serena y Madrid.
En la actualidad no existe ninguna radio autonómica extremeña que emita en la región.

Actualmente solo existe una radio pública en la región que emita a nivel comarcal/local. Se trata de "Radio Miajadas" que emite en dicha localidad y su área de influencia.
En Extremadura emiten pequeñas radios que informan de la actualidad comarcal y local como, por ejemplo:
"Radio Plasencia Centro", "Canal Norte", "Radio Forum Mérida", "Norte Radio Trujillo"...

En la capital, Mérida se encuentra la sede principal en la región de la "RTVE" desde la que emite "TVE". Además existen otras sedes de la corporación en Badajoz y Cáceres. Desde estas ciudades "TVE" emite a nivel regional el informativo territorial "Noticias Extremadura", de lunes a viernes.
En la región se pueden sintonizar los canales de televisión nacionales privados de España como, por ejemplo:
"Antena 3", "Telecinco", "La Sexta"...

Actualmente existe un canal público de televisión que emite a nivel autonómico, se trata de "Canal Extremadura TV" que pertenece a la "CEXMA". Tiene su sede principal en Mérida, y delegaciones en Badajoz, Cáceres, Plasencia,
Villanueva de la Serena y Madrid.
En la actualidad no emite ningún canal de televisión a nivel regional, pero está pendiente que empiece a emitir "Kiss TV".

En Extremadura solo existen tres canales de televisión públicos que emiten a nivel comarcal/local, se tratan de
Almendralejo TV, Villafranca TV Y TV Miajadas. Dichos canales emiten en sus localidades respectivamente y su área de influencia a través de la TDT.
En la región hay canales privados de televisión que emiten a nivel comarcal/local a través de la TDT como, por ejemplo:
K30 TV, Comarcalia TV, Vía Plata TV, TelePlasencia, TeleZafra...

Extremadura posee tres lugares que han sido declarados Patrimonio de la Humanidad cultural por la Unesco:


Del mismo modo preparan su candidatura:


El 13 de abril de 2007, el Monasterio de Yuste fue declarado Patrimonio Europeo.

Las vías pecuarias son rutas o itinerarios por los que hace siglo transitaba el ganado entre los pastos de verano en las montañas del norte y los pastos de invierno en las llanuras del sur. Estas vías se pueden clasificar por su anchura:

En Extremadura, las vías pecuarias alcanzan una longitud de 7.200 kilómetros y ocupan una superficie aproximada de 30.000 hectáreas. Además, seis de las grandes cañadas de la red nacional atraviesan la región.

El uso ganadero de estas vías ha decaído en la actualidad y hay factores como la circulación de vehículos o la urbanización, que pueden deteriorarlas e invadirlas. En este sentido, hay que trabajar para frenar este proceso, pero, sobre todo, porque estas vías tienen muchas posibilidades desde el punto de vista turístico y recreativo, esto es, son un recurso endógeno más de gran valor ambiental y cultural que es necesario rentabilizar para el Desarrollo Rural. El objetivo es reconvertir su uso específicamente ganadero en espacios de ocio en el medio rural recuperando con ello toda una cultura popular y profesional basada en la trashumancia.

Por todo ello, estas vías son un importante elemento para el Desarrollo Rural porque favorecen la fijación de la población en las zonas rurales, debido a su alto potencial en el desarrollo de actividades socioeconómicas como el turismo de naturaleza, la puesta en valor del patrimonio natural y cultural o la promoción de actividades artesanales.


Las siguientes películas y series están ambientadas en Extremadura o han sido rodadas en la región:


Extremadura cuenta con unas 40 fiestas de interés turístico durante todo el año. La tramitación y concesión del título de las fiestas se realizan a través de la Consejería de Medio Ambiente, Urbanismo y Turismo. Para la obtención del título de "Fiesta de Interés Turístico Regional", una fiesta debe cumplir los siguientes requisitos:


Estas fiestas de interés turístico suelen coincidir, aunque no siempre, con días de fiestas populares en varios lugares de Extremadura, como San Sebastián, San Blas, Carnavales, Semana Santa, agosto o el Día de Todos los Santos. Destacan, entre otras:






En poblaciones menores destacan las fiestas de Interés Turístico Nacional como son la Encamisá de Torrejoncillo o la fiesta del Peropalo en Villanueva de la Vera; también destacan la fiesta de la Chanfaina y la romería de San Isidro Labrador, en Fuente de Cantos, ambas de Interés Turístico Regional (siendo el único municipio con dos fiestas de esta declaración); y el Jarramplas, en Piornal, de Interés Turístico de Extremadura, o la Batalla de La Albuera, también de Interés Regional, entre otras muchas.

Extremadura ha sabido guardar entre sus esencias más queridas gran número de bailes y danzas tradicionales autóctonas del más puro sabor. El Cancionero constituye uno de sus grandes tesoros, donde se puede encontrar cantares para todas las ocasiones.
Extremadura ha contado con eminentes musicólogos como Bonifacio Gil, Manuel García Matos y Ángela Capdeville, entre otros, que han realizado estudios sobre el Cancionero popular de Extremadura, recorriendo los pueblos para recopilar cientos de canciones y sentar las bases del cancionero autóctono.

El baile tiene como principal característica la sencillez y la elegancia. La mujer, con sus pasos agitados hace mover sus vistosos refajos. Sus brazos, a pesar de encontrarse sujetos por los policromos pañuelos de "filoseda" que cruzan en sus cuerpos, toman movimiento de ir y venir de acuerdo con el ritmo. El hombre baila con los brazos en alto mirando a su pareja, mientras sus pies marcan fuertemente el ritmo. Las jotas toman en Extremadura gran variedad de formas y matices, también sobresale el fandango, la rondeña, la jota del triángulo, las paleos, el pindongo, el perantón, sones brincaos y sones llanos. También es importante el flamenco (jaleos extremeños, tangos extremeños)...

Los Instrumentos utilizados son la flauta de tres agujeros (gaita extremeña) y tamboril, guitarra, laúd, rabel, pandero y otros instrumentos de percusión como almireces, castañuelas, botella de anís...

La gastronomía de Extremadura es el conjunto de platos y tradiciones culinarias de la región. La apertura de la Vía de la Plata ha hecho que la cocina extremeña se haya divulgado por otras regiones influyendo también en la española, mientras que al mismo tiempo la cocina extremeña se ha visto influenciado por otras cocinas. La existencia de numerosos monasterios, como el de Yuste o el de Guadalupe, ha dado lugar a un esplendor culinario de recetas que han provenido de sus cocinas. Extremadura no da al mar, y los platos que ofrece son fundamentalmente cárnicos y compuestos de hortalizas diversas. En Extremadura, varias comidas, especias o frutas tienen Denominación de Origen protegida.

En el terreno de la carne cabe destacar la gran producción de subproductos del cerdo como pueden ser los embutidos y la chacinería en general. La producción porcina tiene en esta región unas altas cuotas de calidad, debido a que crían la razas ibéricas alimentadas de las abundantes bellotas. Una de las zonas de mayor producción porcina es las comarcas de Montánchez, se cuenta como leyenda que los buenos jamones (Jamón de Montánchez) de esta tierra se deben a la persecución que hacen los cerdos de las víboras. Los chorizos extremeños tan abundantes en ajo y en pimentón de la Vera. Uno de los platos representativos es la cachuela extremeña, la chanfaina, etc. Como Extremadura es tierra de pastoreo cabe destacar platos con cordero: caldereta de cordero, el frito extremeño. La caza es abundante y cabe destacar la caza menor una de los platos de caza más conocidos son las perdices al modo de Alcántara debido a una historia con las tropas francesas. Entre los pescados, cabe destacar las diversas recetas elaboradas con bacalao en salazón, sobre todo aquellas que contienen la denominación de vigilia: potaje de vigilia.


El pimentón de la Vera es un producto con Denominación de Origen, resultante de la molienda de pimientos rojos de las variedades Ocales, Jaranda, Jariza, Jeromín, y Bola. Se cultiva y elabora en la comarca de La Vera, provincia de Cáceres, España. El Pimentón de la Vera es un producto de sabor y aroma ahumados debido al proceso de secado al humo de los pimientos. Su coloración es roja con relativo brillo. Posee un gran poder colorante, mayor en la variedad Ocales que en la variedad Bola. El sabor, aroma y color son estables dado el lento proceso de deshidratación empleado en su elaboración.

La torta del Casar es un queso español con denominación de origen protegida de ámbito europeo por el Reglamento (CE) 1491/2003 de la Comisión Europea. Se trata de uno de los quesos más reconocidos de Extremadura.

En las etiquetas, contraetiquetas y otros sistemas destinados a identificar los productos amparados deberán destacar el nombre y logotipo de la Denominación de Origen Protegida «Torta del Casar», así como todas aquellas indicaciones que estipule la legislación vigente en la materia.


















</doc>
<doc id="1138" url="https://es.wikipedia.org/wiki?curid=1138" title="Eolo">
Eolo

En la mitología griega, Eolo o Éolo (en griego Αἴολος) es el nombre de tres personajes distintos. Los datos ofrecidos por los mitógrafos han llevado a confundirlos. 

Este Eolo fue hijo de Helén y de la náyade Orséis y hermano de Doro y Juto. Se le describe como rey de Eólida (posteriormente llamada Tesalia) y se le supone fundador de la rama eólica de la nación helénica. Eolo desposó a Enárete, hija de Dímaco, con la que tuvo muchos hijos, aunque su número e identidades varían de un autor a otro. Algunos incluyen a Creteo, Sísifo, Deyoneo, Salmoneo, Atamante, Perieres y quizás a Magnes y Etlio. Entre las hijas de Eolo y Enárete se cuentan Cálice, Cánace, Pisídice, Perimede y Alcíone. También se menciona como hijo suyo a Macareo que mantuvo relaciones amorosas con su hermana Cánace. Horrorizado, Eolo envió a Cánace una espada para que se suicidase (Macareo también se suicidó) y arrojó al hijo incestuoso a los perros.

Este Eolo también tuvo una hija ilegítima llamada Arne, también llamada Melanipa, que engendró con Hipe, hija del centauro Quirón. Esta Arne sería la madre del segundo Eolo, a través de Poseidón. Otro de los hijos mencionados es Mimante que es vinculado al tercer Eolo (véase abajo) a través de una genealogía muy acomodaticia.

Este Eolo fue hijo de Poseidón y Arne. Tuvo como gemelo a Beoto. Cuando Arne confesó a su padre que estaba embarazada de Poseidón, este no le creyó y ordenó a un extranjero de la ciudad de Metaponto que se la llevara a su ciudad. Como consecuencia de ello, Beoto y Eolo nacieron y fueron adoptados por otro hombre de Metaponto que no tenía hijos. Cuando los gemelos se hicieron mayores, se apoderaron del reino durante una revuelta. Después, hubo una disputa entre Arne y Autólite, la esposa del metapontio. Eolo y Beoto tomaron partido por su madre, mataron a Autólite, y como el metapontio se indignó por ello, tuvieron que equipar unas naves y huir de la ciudad, con Arne y otros amigos. Beoto se marchó al país de su abuelo Eolo, lo sucedió en el trono y llamó Arne al país y beocios a sus habitantes; Eolo, por su parte, llegó hasta un grupo de islas en el mar Tirreno, las cuales recibieron en su honor el nombre de Islas Eolias y se le atribuye también la fundación de la ciudad de Lípara.

En una versión alternativa, la madre de los gemelos es llamada Melanipe, hija de Desmontes o de Eolo, fue encadenada por su padre y había sido un rey de Icaria llamado Metaponto el que había adoptado a los gemelos, que habían sido abandonados. La esposa de Metaponto, llamada en esta versión Teano, había tenido otros hijos e incitó a que sus hijos matasen a Eolo y Beoto, pero estos últimos fueron los que salieron victoriosos y, tras ser avisados por Poseidón de que su verdadera madre estaba en prisión, la liberaron. Melanipe y Metaponto se casaron y Eolo y Beoto dieron nombre a Beocia y Eolia, respectivamente. 

Aunque tradicionalmente su hogar ha sido identificado como una de las Islas Eólias, cerca de Sicilia, se ha sugerido como localización alternativa a Gramvousa en la costa noroccidental de Creta.

La paternidad de este tercer Eolo es atribuida a Hípotes, que, según cuenta Diodoro Sículo en su "Biblioteca histórica", era hijo de Mimante, uno de los hijos del Eolo Helénida. 

En otra parte de la obra de Diodoro que parece mezclar datos del segundo y del tercer Eolo, se narra cómo, al llegar a la isla de Lípara, donde reinaba el rey Líparo, ayudó a este a apoderarse de la zona de Sirrento mientras él se casó con la hija del rey, Cíane, y se convirtió en rey de la isla. Era piadoso, justo y amable con los extranjeros, enseñó a los navegantes el manejo de las velas y se decía que era capaz de predecir los vientos. En este pasaje se mencionan seis hijos de Eolo.

Según la "Odisea", este Eolo, Señor de los Vientos, vivía en la isla flotante de Eolia, con sus seis hijos y sus seis hijas, que se habían casado entre sí. Zeus le había dado el poder de controlar los vientos; Eolo los tenía encerrados y los gobernaba con un dominio absoluto, apresándolos o liberándolos a su antojo. Trató de ayudar a Odiseo, que lo visitó al retornar a Ítaca. Eolo lo trató muy bien, y le dio un viento favorable, además de un odre que contenía todos los vientos y que debía ser utilizado con cuidado. Sin embargo, la tripulación de Odiseo creyó que la bolsa contenía oro y la abrió, provocando graves tempestades. La nave terminó regresando a las costas de Eolia, pero Eolo se negó a ayudarlos de nuevo. Eolo es representado empuñando un cetro como símbolo de su autoridad, y rodeado de turbulentos remolinos, los Vientos, cada uno de los cuales era un dios.

En la "Eneida", Juno le ofrece a la ninfa Deyopea (Δηιόπεια) como esposa a cambio de mandar sus vientos a la flota de Eneas para impedir que desembarcase en Italia.



</doc>
<doc id="1140" url="https://es.wikipedia.org/wiki?curid=1140" title="Edad Media">
Edad Media

La Edad Media, Medievo o Medioevo es el período histórico de la civilización occidental comprendido entre el siglo y el . Convencionalmente, su inicio es situado en el año 476 con la caída del Imperio romano de Occidente y su fin en 1492 con el descubrimiento de América, o en 1453 con la caída del Imperio bizantino, fecha que tiene la singularidad de coincidir con la invención de la imprenta —publicación de la Biblia de Gutenberg— y con el fin de la guerra de los Cien Años.

A día de hoy, los historiadores del período prefieren matizar esta ruptura entre Antigüedad y Edad Media de manera que entre los siglos y se suele hablar de Antigüedad Tardía, que habría sido una gran etapa de transición en todos los ámbitos: en lo económico, para la sustitución del modo de producción esclavista por el modo de producción feudal; en lo social, para la desaparición del concepto de ciudadanía romana y la definición de los estamentos medievales, en lo político para la descomposición de las estructuras centralizadas del Imperio romano que dio paso a una dispersión del poder; y en lo ideológico y cultural para la absorción y sustitución de la cultura clásica por las teocéntricas culturas cristiana o islámica (cada una en su espacio).

Suele dividirse en dos grandes períodos: Temprana o Alta Edad Media (ss. -, sin una clara diferenciación con la Antigüedad Tardía); y Baja Edad Media (ss. -), que a su vez puede dividirse en un periodo de plenitud, la Plena Edad Media (ss. -), y los dos últimos siglos que presenciaron la crisis del siglo.

Aunque hay algunos ejemplos de utilización previa, el concepto de "Edad Media" nació como la segunda edad de la división tradicional del tiempo histórico debida a Cristóbal Cellarius ("Historia Medii Aevi a temporibus Constantini Magni ad Constaninopolim a Turcis captam deducta", Jena, 1688), quien la consideraba un tiempo intermedio, sin apenas valor por sí mismo, entre la Edad Antigua identificada con el arte y la cultura de la civilización grecorromana de la Antigüedad clásica y la renovación cultural de la Edad Moderna —en la que él se sitúa— que comienza con el Renacimiento y el Humanismo. La popularización de este esquema ha perpetuado un preconcepto erróneo: el de considerar a la Edad Media como una época oscura, sumida en el retroceso intelectual y cultural, y un aletargamiento social y económico secular (que a su vez se asocia con el "feudalismo" en sus rasgos más oscurantistas, tal como se definió por los revolucionarios que combatieron el Antiguo Régimen). Sería un periodo dominado por el aislamiento, la ignorancia, la teocracia, la superstición y el miedo milenarista alimentado por la inseguridad endémica, la violencia y la brutalidad de guerras e invasiones constantes y epidemias apocalípticas.

Sin embargo, en este largo período de mil años hubo todo tipo de hechos y procesos muy diferentes entre sí, diferenciados temporal y geográficamente, respondiendo tanto a influencias mutuas con otras civilizaciones y espacios como a dinámicas internas. Muchos de ellos tuvieron una gran proyección hacia el futuro, entre otros los que sentaron las bases del desarrollo de la posterior expansión europea, y el desarrollo de los agentes sociales que desarrollaron una sociedad estamental de base predominantemente rural pero que presenció el nacimiento de una incipiente vida urbana y una burguesía que con el tiempo desarrollarán el capitalismo. Lejos de ser una época inmovilista, la Edad Media, que había comenzado con migraciones de pueblos enteros, y continuado con grandes procesos repobladores (Repoblación en la Península Ibérica, "Ostsiedlung" en Europa Oriental) vio cómo en sus últimos siglos los antiguos caminos (muchos de ellos vías romanas decaídas) se reparaban y modernizaban con airosos puentes, y se llenaban de toda clase de viajeros (guerreros, peregrinos, mercaderes, estudiantes, goliardos, etc.) encarnando la metáfora espiritual de la vida como un viaje ("homo viator").

También surgieron en la Edad Media formas políticas nuevas, que van desde el califato islámico a los poderes universales de la cristiandad latina (Pontificado e Imperio) o el Imperio bizantino y los reinos eslavos integrados en la cristiandad oriental (aculturación y evangelización de Cirilo y Metodio); y en menor escala, todo tipo de ciudades estado, desde las pequeñas ciudades episcopales alemanas hasta repúblicas que mantuvieron imperios marítimos como Venecia; dejando en la mitad de la escala a la que tuvo mayor proyección futura: las monarquías feudales, que transformadas en monarquías autoritarias prefiguran el estado moderno.

De hecho, todos los conceptos asociados a lo que se ha venido en llamar modernidad aparecen en la Edad Media, en sus aspectos intelectuales con la misma crisis de la escolástica. Ninguno de ellos sería entendible sin el propio feudalismo, se entienda este como modo de producción (basado en las relaciones sociales de producción en torno a la tierra del feudo) o como sistema político (basado en las relaciones personales de poder en torno a la institución del vasallaje), según las distintas interpretaciones historiográficas.

El choque de civilizaciones entre cristianismo e islamismo, manifestado en la ruptura de la unidad del Mediterráneo (hito fundamental de la época, según Henri Pirenne, en su clásico "Mahoma y Carlomagno"), la Reconquista española y las Cruzadas; tuvo también su parte de fértil intercambio cultural (escuela de Traductores de Toledo, Escuela Médica Salernitana) que amplió los horizontes intelectuales de Europa, hasta entonces limitada a los restos de la cultura clásica salvados por el monacato altomedieval y adaptados al cristianismo.

Esa misma Europa Occidental produjo una impresionante sucesión de estilos artísticos (prerrománico, románico y gótico), que en las zonas fronterizas se mestizaron también con el arte islámico (mudéjar, arte andalusí, arte árabe-normando) o con el arte bizantino.

La ciencia medieval no respondía a una metodología moderna, pero tampoco lo había hecho la de los autores clásicos, que se ocuparon de la naturaleza desde su propia perspectiva; y en ambas edades sin conexión con el mundo de las técnicas, que estaba relegado al trabajo manual de artesanos y campesinos, responsables de un lento pero constante progreso en las herramientas y procesos productivos. La diferenciación entre oficios viles y mecánicos y profesiones liberales vinculadas al estudio intelectual convivió con una teórica puesta en valor espiritual del trabajo en el entorno de los monasterios benedictinos, cuestión que no pasó de ser un ejercicio piadoso, sobrepasado por la mucho más trascendente valoración de la pobreza, determinada por la estructura económica y social y que se expresó en el pensamiento económico medieval.
Medievalismo es tanto la "cualidad o carácter de medieval", como el interés por la época y los temas medievales y su estudio; y medievalista el especialista en estas materias. El descrédito de la Edad Media fue una constante durante la Edad Moderna, en la que Humanismo, Renacimiento, Racionalismo, Clasicismo e Ilustración se afirman como reacciones contra ella, o más bien contra lo que entienden que significaba, o contra los rasgos de su propio presente que intentan descalificar como pervivencias medievales. No obstante desde fines del siglo XVI se producen interesantes recopilaciones de fuentes documentales medievales que buscan un método crítico para la ciencia histórica. El Romanticismo y el Nacionalismo del siglo XIX revalorizaron la Edad Media como parte de su programa estético y como reacción anti-académica (poesía y drama románticos, novela histórica, nacionalismo musical, ópera), además de como única posibilidad de encontrar base histórica a las emergentes naciones (pintura de historia, arquitectura historicista, sobre todo el neogótico —labor restauradora y recreadora de Eugène Viollet-le-Duc— y el neomudéjar). Los abusos románticos de la ambientación medieval (exotismo), produjeron ya a mediados del siglo XIX la reacción del realismo. Otro tipo de abusos son los que dan lugar a una abundante literatura pseudohistórica que llega hasta el presente, y que ha encontrado la fórmula del éxito mediático entremezclando temas esotéricos sacados de partes más o menos oscuras de la Edad Media (Archivo Secreto Vaticano, templarios, rosacruces, masones y el mismísimo Santo Grial). Algunos de ellos se vincularon al nazismo, como el alemán Otto Rahn. Por otro lado, hay abundancia de otros tipos de producciones artísticas de ficción de diversa calidad y orientación inspiradas en la Edad Media (literatura, cine, cómic). También se han desarrollado en el siglo XX otros movimientos medievalistas: un medievalismo historiográfico serio, centrado en la renovación metodológica (fundamentalmente por la incorporación de la perspectiva económica y social aportada por el materialismo histórico y la Escuela de los Annales) y un medievalismo popular (espectáculos medievales, más o menos genuinos, como actualización del pasado en el que la comunidad se identifica, lo que se ha venido en llamar "memoria histórica").

Las grandes migraciones de la época de las invasiones significaron paradójicamente un cierre al contacto de Occidente con el resto del mundo. Muy pocas noticias tenían los europeos del milenio medieval (tanto los de la cristiandad latina como los de la cristiandad oriental) de que, aparte de la civilización islámica, que ejerció de puente pero también de obstáculo entre Europa y el resto del Viejo Mundo, se desarrollaban otras civilizaciones. Incluso un vasto reino cristiano como el de Etiopía, al quedar aislado, se convirtió en el imaginario cultural en el mítico reino del Preste Juan, apenas distinguible de las islas atlánticas de San Brandán y del resto de las maravillas dibujadas en los bestiarios y los escasos, rudimentarios e imaginativos mapas. El desarrollo marcadamente autónomo de China, la más desarrollada civilización de la época (aunque volcada hacia su propio interior y ensimismada en sus ciclos dinásticos: Sui, Tang, Song, Yuan y Ming), y la escasez de contactos con ella (el viaje de Marco Polo, o la mucho más importante expedición de Zheng He), que destacan justamente por lo inusuales y por su ausencia de continuidad, no permiten denominar a los siglos V al XV de su historia como "historia medieval", aunque a veces se haga, incluso en publicaciones especializadas, más o menos impropiamente.

La historia de Japón (que durante este periodo estaba en formación como civilización, adaptando las influencias chinas a la cultura autóctona y expandiéndose desde las islas meridionales a las septentrionales), a pesar de su mayor lejanía y aislamiento, suele ser paradójicamente más asociada al término "medieval"; aunque tal denominación es acotada por la historiografía, significativamente, a un "periodo medieval" que se localiza entre los años 1000 y 1868, para adecuarse al denominado feudalismo japonés anterior a la era Meiji ("véase también shogunato, han y castillo japonés").

La historia de la India o la del África negra a partir del siglo VII contaron con una mayor o menor influencia musulmana, pero se atuvieron a dinámicas propias bien diferentes (Sultanato de Delhi, Sultanato de Bahmani, Imperio Vijayanagara —en la India—, Imperio de Malí, Imperio Songhay —en África negra—). Incluso llegó a producirse una destacada intervención sahariana en el mundo mediterráneo occidental: el Imperio almorávide.

De un modo todavía más claro, la historia de América (que atravesaba sus periodos clásico y postclásico) no tuvo ningún tipo de contacto con el Viejo Mundo, más allá de la llegada de la denominada "Colonización vikinga en América" que se limitó a una reducida y efímera presencia en Groenlandia y la enigmática "Vinland", o las posibles posteriores expediciones de balleneros vascos en parecidas zonas del Atlántico Norte, aunque este hecho ha de entenderse en el contexto del gran desarrollo de la navegación de los últimos siglos de la Baja Edad media, ya encaminada a la Era de los Descubrimientos.

Lo que sí ocurrió, y puede considerarse como una constante del periodo medieval, fue la periódica repetición de puntuales interferencias centroasiáticas en Europa y el Próximo Oriente en forma de invasiones de pueblos del Asia Central, destacadamente los turcos (köktürks, jázaros, otomanos) y los mongoles (unificados por Gengis Kan) y cuya Horda de Oro estuvo presente en Europa Oriental y conformó la personalidad de los Estados cristianos que se crearon, a veces vasallos y a veces resistentes, en las estepas rusas y ucranianas. Incluso en una rara ocasión, la primitiva diplomacia de los reinos europeos bajomedievales vio la posibilidad de utilizar a los segundos como contrapeso a los primeros: la frustrada embajada de Ruy González de Clavijo a la corte de Tamerlán en Samarcanda, en el contexto del asedio mongol de Damasco, un momento muy delicado (1401-1406) en el que también intervino como diplomático Ibn Jaldún. Los mongoles ya habían saqueado Bagdad en una incursión de 1258.

Aunque se han propuesto varias fechas para el inicio de la Edad Media, de las cuales la más extendida es la del año 476, lo cierto es que no podemos ubicar el inicio de una manera tan exacta ya que la Edad Media no nace, sino que "se hace" a consecuencia de todo un largo y lento proceso que se extiende por espacio de cinco siglos y que provoca cambios enormes a todos los niveles de una forma muy profunda que incluso repercutirán hasta nuestros días. Podemos considerar que ese proceso empieza con la crisis del siglo III, vinculada a los problemas de reproducción inherentes al modo de producción esclavista, que necesitaba una expansión imperial continua que ya no se producía tras la fijación del "limes" romano. Posiblemente también confluyeran factores climáticos para la sucesión de malas cosechas y epidemias; y de un modo mucho más evidente las primeras invasiones germánicas y sublevaciones campesinas ("bagaudas"), en un periodo en que se suceden muchos breves y trágicos mandatos imperiales. Desde Caracalla la ciudadanía romana estaba extendida a todos los hombres libres del Imperio, muestra de que tal condición, antes tan codiciada, había dejado de ser atractiva. El Bajo Imperio adquiere un aspecto cada vez más medieval desde principios del siglo IV con las reformas de Diocleciano: difuminación de las diferencias entre los esclavos, cada vez más escasos, y los colonos, campesinos libres, pero sujetos a condiciones cada vez mayores de servidumbre, que pierden la libertad de cambiar de domicilio, teniendo que trabajar siempre la misma tierra; herencia obligatoria de cargos públicos —antes disputados en reñidas elecciones— y oficios artesanales, sometidos a colegiación —precedente de los gremios—, todo para evitar la evasión fiscal y la despoblación de las ciudades, cuyo papel de centro de consumo y de comercio y de articulación de las zonas rurales cada vez es menos importante. Al menos, las reformas consiguen mantener el edificio institucional romano, aunque no sin intensificar la ruralización y aristocratización (pasos claros hacia el feudalismo), sobre todo en Occidente, que queda desvinculado de Oriente con la partición del Imperio. Otro cambio decisivo fue la implantación del cristianismo como nueva religión oficial por el Edicto de Tesalónica de Teodosio I el Grande (380) precedido por el Edicto de Milán (313) con el que Constantino I el Grande recompensó a los hasta entonces subversivos por su providencialista ayuda en la batalla del Puente Milvio (312), junto con otras presuntas cesiones más temporales cuya fraudulenta reclamación (Pseudo-donación de Constantino) fue una constante de los Estados Pontificios durante toda la Edad Media, incluso tras la evidencia de su refutación por el humanista Lorenzo Valla (1440).
Ningún evento concreto —a pesar de la abundancia y concatenación de hechos catastróficos— determinó por sí mismo el fin de la Edad Antigua y el inicio de la Edad Media: ni los sucesivos saqueos de Roma (por los godos de Alarico I en el 410, por los vándalos en el 455, por las propias tropas imperiales de Ricimero en 472, por los ostrogodos en 546), ni la pavorosa irrupción de los hunos de Atila (450-452, con la batalla de los Campos Cataláunicos y la extraña entrevista con el papa León I el Magno), ni el derrocamiento de Rómulo Augústulo (último emperador romano de Occidente, por Odoacro el jefe de los hérulos -476-); fueron sucesos que sus contemporáneos consideraran iniciadores de una nueva época. La culminación a finales del siglo V de una serie de procesos de larga duración, entre ellos la grave dislocación económica, las invasiones y el asentamiento de los pueblos germanos en el Imperio romano, hizo cambiar la faz de Europa. Durante los siguientes 300 años, la Europa Occidental mantuvo un período de unidad cultural, inusual para este continente, instalada sobre la compleja y elaborada cultura del Imperio romano, que nunca llegó a perderse por completo, y el asentamiento del cristianismo. Nunca llegó a olvidarse la herencia clásica grecorromana, y la lengua latina, sometida a transformación (latín medieval), continuó siendo la lengua de cultura en toda Europa occidental, incluso más allá de la Edad Media. El derecho romano y múltiples instituciones continuaron vivas, adaptándose de uno u otro modo. Lo que se operó durante ese amplio periodo de transición (que puede darse por culminado para el año 800, con la coronación de Carlomagno) fue una suerte de fusión con las aportaciones de otras civilizaciones y formaciones sociales, en especial la germánica y la religión cristiana. En los siglos siguientes, aún en la Alta Edad Media, serán otras aportaciones las que se añadan, destacadamente el islam.

El texto se refiere concretamente a Hispania y sus provincias, y los bárbaros citados son específicamente los suevos, vándalos y alanos, que en el 406 habían cruzado el "limes" del Rin (inhabitualmente helado) a la altura de Maguncia y en torno al 409 habían llegado a la península ibérica; pero la imagen es equivalente en otros momentos y lugares que el mismo autor narra, del periodo entre 379 y 468.

Los pueblos germánicos procedentes de la Europa del Norte y del Este, se encontraban en un estadio de desarrollo económico, social y cultural obviamente inferior al del Imperio romano, al que ellos mismos percibían admirativamente. A su vez eran percibidos con una mezcla de desprecio, temor y esperanza (retrospectivamente plasmados en el influyente poema "Esperando a los bárbaros" de Constantino Cavafis), e incluso se les atribuyó un papel justiciero (aunque involuntario) desde un punto de vista providencialista por parte de los autores cristianos romanos (Orosio, Salviano de Marsella y San Agustín de Hipona). La denominación de "bárbaros" (βάρβαρος) proviene de la onomatopeya "bar-bar" con la que los griegos se burlaban de los extranjeros no helénicos, y que los romanos -bárbaros ellos mismos, aunque helenizados- utilizaron desde su propia perspectiva. La denominación "invasiones bárbaras" fue rechazada por los historiadores alemanes del siglo XIX, momento en el que el término barbarie designaba para las nacientes ciencias sociales un estadio de desarrollo cultural inferior a la civilización y superior al salvajismo. Prefirieron acuñar un nuevo término: "Völkerwanderung" ("Migración de Pueblos"), menos violento que "invasiones", al sugerir el desplazamiento completo de un pueblo con sus instituciones y cultura, y más general incluso que "invasiones germánicas", al incluir a hunos, eslavos y otros.

Los germanos, que disponían de instituciones políticas peculiares, en concreto la asamblea de guerreros libres ("thing") y la figura del rey, recibieron la influencia de las tradiciones institucionales del Imperio y la civilización grecorromana, así como la del cristianismo (aunque no siempre del cristianismo católico o "atanasiano", sino del "arriano"); y se fueron adaptando a las circunstancias de su asentamiento en los nuevos territorios, sobre todo a la alternativa entre imponerse como minoría dirigente sobre una mayoría de población local o fusionarse con ella.

Los nuevos reinos germánicos conformaron la personalidad de Europa Occidental durante la Edad Media, evolucionaron en monarquías feudales y monarquías autoritarias, y con el tiempo, dieron origen a los estados-nación que se fueron construyendo en torno a ellas. Socialmente, en algunos de estos países (España o Francia), el origen germánico (godo o franco) pasó a ser un rasgo de honor u orgullo de casta ostentado por la nobleza como distinción sobre el conjunto de la población.

El Imperio romano había pasado por invasiones externas y guerras civiles terribles en el pasado, pero a finales del siglo IV, aparentemente, la situación estaba bajo control. Hacía escaso tiempo que Teodosio había logrado nuevamente unificar bajo un solo centro ambas mitades del Imperio (392) y establecido una nueva religión de Estado, el Cristianismo niceno (Edicto de Tesalónica -380), con la consiguiente persecución de los tradicionales cultos paganos y las heterodoxias cristianas. El clero cristiano, convertido en una jerarquía de poder, justificaba ideológicamente a un "Imperium Romanum Christianum" (Imperio Romano Cristiano) y a la dinastía Teodosiana como había comenzado a hacer ya con la Constantiniana desde el Edicto de Milán (313).

Se habían encauzado los afanes de protagonismo político de los más ricos e influyentes senadores romanos y de las provincias occidentales. Además, la dinastía había sabido encauzar acuerdos con la poderosa aristocracia militar, en la que se enrolaban nobles germanos que acudían al servicio del Imperio al frente de soldados unidos por lazos de fidelidad hacia ellos. Al morir en 395, Teodosio confió el gobierno de Occidente y la protección de su joven heredero Honorio al general Estilicón, primogénito de un noble oficial vándalo que había contraído matrimonio con Flavia Serena, sobrina del propio Teodosio. Pero cuando en el 455 murió asesinado Valentiniano III, nieto de Teodosio, una buena parte de los descendientes de aquellos nobles occidentales ("nobilissimus, clarissimus") que tanto habían confiado en los destinos del Imperio parecieron ya desconfiar del mismo, sobre todo cuando en el curso de dos decenios se habían podido dar cuenta de que el gobierno imperial recluido en Rávena era cada vez más presa de los exclusivos intereses e intrigas de un pequeño grupo de altos oficiales del ejército itálico. Muchos de estos eran de origen germánico y cada vez confiaban más en las fuerzas de sus séquitos armados de soldados convencionales y en los pactos y alianzas familiares que pudieran tener con otros jefes germánicos instalados en suelo imperial junto con sus propios pueblos, que desarrollaban cada vez más una política autónoma. La necesidad de acomodarse a la nueva situación quedó evidenciada con el destino de Gala Placidia, princesa imperial rehén de los propios saqueadores de Roma (el visigodo Alarico I y su primo Ataúlfo, con quien finalmente se casó); o con el de Honoria, hija de la anterior (en segundas nupcias con el emperador Constancio III) que optó por ofrecerse como esposa al propio Atila enfrentándose a su propio hermano Valentiniano.

Necesitados de mantener una posición de predominio social y económico en sus regiones de origen, reducidos sus patrimonios fundiarios a dimensiones provinciales, y ambicionando un protagonismo político propio de su linaje y de su cultura, los "honestiores" (los más honestos u honrados, los que tienen honor), representantes de las aristocracias tardorromanas occidentales habrían acabado por aceptar las ventajas de admitir la legitimidad del gobierno de dichos reyes germánicos, ya muy romanizados, asentados en sus provincias. Al fin y al cabo, éstos, al frente de sus soldados, podían ofrecerles bastante mayor seguridad que el ejército de los emperadores de Rávena. Además, el avituallamiento de dichas tropas resultaba bastante menos gravoso que el de las imperiales, por basarse en buena medida en séquitos armados dependientes de la nobleza germánica y alimentados con cargo al patrimonio fundiario provincial de la que esta ya hacía tiempo se había apropiado. Menos gravoso tanto para los aristócratas provinciales como también para los grupos de "humiliores" (los más humildes, los rebajados en tierra -"humus"-) que se agrupaban jerárquicamente en torno a dichos aristócratas, y que, en definitiva, eran los que habían venido soportando el máximo peso de la dura fiscalidad tardorromana. Las nuevas monarquías, más débiles y descentralizadas que el viejo poder imperial, estaban también más dispuestas a compartir el poder con las aristocracias provinciales, máxime cuando el poder de estos monarcas estaba muy limitado en el seno mismo de sus gentes por una nobleza basada en sus séquitos armados, desde su no muy lejano origen en las asambleas de guerreros libres, de los que no dejaban de ser "primun inter pares".

Pero esta metamorfosis del Occidente romano en romano-germano, no había sido consecuencia de una inevitabilidad claramente evidenciada desde un principio; por el contrario, el camino había sido duro, zigzagueante, con ensayos de otras soluciones, y con momentos en que parecía que todo podía volver a ser como antes. Así ocurrió durante todo el siglo V, y en algunas regiones también en el siglo VI como consecuencia, entre otras cosas, de la llamada "Recuperatio Imperii" o Reconquista de Justiniano.

Las invasiones bárbaras desde el siglo III habían demostrado la permeabilidad del "limes" romano en Europa, fijado en el Rin y el Danubio. La división del Imperio en Oriente y Occidente, y la mayor fortaleza del imperio oriental o bizantino, determinó que fuera únicamente en la mitad occidental donde se produjo el asentamiento de estos pueblos y su institucionalización política como reinos.

Fueron los visigodos, primero como Reino de Tolosa y luego como Reino de Toledo, los primeros en efectuar esa institucionalización, valiéndose de su condición de federados, con la obtención de un "foedus" con el Imperio, que les encargó la pacificación de las provincias de Galia e Hispania, cuyo control estaba perdido en la práctica tras las invasiones del 410 por suevos, vándalos y alanos. De los tres, solo los suevos lograron el asentamiento definitivo en una zona: el Reino de Braga, mientras que los vándalos se establecieron en el norte de África y las islas del Mediterráneo Occidental, pero fueron al siglo siguiente eliminados por los bizantinos durante la gran expansión territorial de Justiniano I (campañas de los generales Belisario, del 533 al 544, y Narsés, hasta el 554). Simultáneamente los ostrogodos consiguieron instalarse en Italia expulsando a los hérulos, que habían expulsado a su vez de Roma al último emperador de Occidente. El Reino Ostrogodo desapareció también frente a la presión bizantina de Justiniano I.

Un segundo grupo de pueblos germánicos se instala en Europa Occidental en el siglo VI, de entre los que destaca el Reino franco de Clodoveo I y sus sucesores merovingios, que desplaza a los visigodos de las Galias, forzándolos a trasladar su capital de Tolosa (Toulouse) a Toledo. También derrotaron a burgundios y alamanes, absorbiendo sus reinos. Algo más tarde los lombardos se establecen en Italia (568-9), pero serán derrotados a finales del siglo VIII por los mismos francos, que reinstaurarán el Imperio con Carlomagno (año 800).

En Gran Bretaña se instalarán los anglos, sajones y jutos, que crearán una serie de reinos rivales que serán unificados por los daneses (un pueblo nórdico) en lo que terminará por ser el reino de Inglaterra.

La monarquía germánica era en origen una institución estrictamente temporal, vinculada estrechamente al prestigio personal del rey, que no pasaba de ser un "primus inter pares" (primero entre iguales), que la asamblea de guerreros libres elegía (monarquía electiva), normalmente para una expedición militar concreta o para una misión específica. Las migraciones a que se vieron sometidos los pueblos germánicos desde el siglo III hasta el siglo V (encajonados entre la presión de los hunos al este y la resistencia del limes romano al sur y oeste) fue fortaleciendo la figura del rey, al tiempo que se entraba en contacto cada vez mayor con las instituciones políticas romanas, que acostumbraban a la idea de un poder político mucho más centralizado y concentrado en la persona del Emperador romano. La monarquía se vinculó a las personas de los reyes de forma vitalicia, y la tendencia era a hacerse monarquía hereditaria, dado que los reyes (al igual que habían hecho los emperadores romanos) procuraban asegurarse la elección de su sucesor, la mayor parte de las veces aún en vida y asociándolos al trono. El que el candidato fuera el primogénito varón no era una necesidad, pero se terminó imponiendo como una consecuencia obvia, lo que también era imitado por las demás familias de guerreros, enriquecidos por la posesión de tierras y convertidos en linajes nobiliarios que se emparentaban con la antigua nobleza romana, en un proceso que puede denominarse feudalización. Con el tiempo, la monarquía se patrimonializó, permitiendo incluso la división del reino entre los hijos del rey.

El respeto a la figura del rey se reforzó mediante la sacralización de su toma de posesión (unción con los sagrados óleos por parte de las autoridades religiosas y uso de elementos distintivos como orbe, cetro y corona, en el transcurso de una elaborada ceremonia: la coronación) y la adición de funciones religiosas (presidencia de concilios nacionales, como los Concilios de Toledo) y taumatúrgicas (toque real de los reyes de Francia para la cura de la escrófula). El problema se suscitaba cuando llegaba el momento de justificar la deposición de un rey y su sustitución por otro que no fuera su sucesor natural. Los últimos merovingios no gobernaban por sí mismos, sino mediante los cargos de su corte, entre los que destacaba el mayordomo de palacio. Únicamente tras la victoria contra los invasores musulmanes en la batalla de Poitiers el mayordomo Carlos Martel se vio justificado para argumentar que la legitimidad de ejercicio le daba méritos suficientes para fundar él mismo su propia dinastía: la carolingia. En otras ocasiones se recurría a soluciones más imaginativas (como forzar la tonsura -corte eclesiástico del pelo- del rey visigodo Wamba para incapacitarle).

Los problemas de convivencia entre las minorías germanas y las mayorías locales (hispano-romanas, galo-romanas, etc.) fueron solucionados con más eficacia por los reinos con más proyección en el tiempo (visigodos y francos) a través de la fusión, permitiendo los matrimonios mixtos, unificando la legislación y realizando la conversión al catolicismo frente a la religión originaria, que en muchos casos ya no era el paganismo tradicional germánico, sino el cristianismo arriano adquirido en su paso por el Imperio Oriental.

Algunas características propias de las instituciones germanas se conservaron: una de ellas el predominio del derecho consuetudinario sobre el derecho escrito propio del Derecho romano. No obstante los reinos germánicos realizaron algunas codificaciones legislativas, con mayor o menor influencia del derecho romano o de las tradiciones germánicas, redactadas en latín a partir del siglo V (leyes teodoricianas, edicto de Teodorico, Código de Eurico, Breviario de Alarico). El primer código escrito en lengua germánica fue el del rey Ethelberto de Kent, el primero de los anglosajones en convertirse al cristianismo (comienzos del siglo VI). El visigótico "Liber Iudicorum" (Recesvinto, 654) y la franca "Ley Sálica" (Clodoveo, 507-511) mantuvieron una vigencia muy prolongada por su consideración como fuentes del derecho en las monarquías medievales y del Antiguo Régimen.

La expansión del cristianismo entre los bárbaros, el asentamiento de la autoridad episcopal en las ciudades y del monacato en los ámbitos rurales (sobre todo desde la regla de San Benito de Nursia -monasterio de Montecassino, 529-), constituyeron una poderosa fuerza fusionadora de culturas y ayudó a asegurar que muchos rasgos de la civilización clásica, como el derecho romano y el latín, pervivieran en la mitad occidental del Imperio, e incluso se expandiera por Europa Central y septentrional. Los francos se convirtieron al catolicismo durante el reinado de Clodoveo I (496 ó 499) y, a partir de entonces, expandieron el cristianismo entre los germanos del otro lado del Rin. Los suevos, que se habían hecho cristianos arrianos con Remismundo (459-469), se convirtieron al catolicismo con Teodomiro (559-570) por las predicaciones de San Martín de Dumio. En ese proceso se habían adelantado a los propios visigodos, que habían sido cristianizados previamente en Oriente en la versión arriana (en el siglo IV), y mantuvieron durante siglo y medio la diferencia religiosa con los católicos hispano-romanos incluso con luchas internas dentro de la clase dominante goda, como demostró la rebelión y muerte de San Hermenegildo (581-585), hijo del rey Leovigildo). La conversión al catolicismo de Recaredo (589) marcó el comienzo de la fusión de ambas sociedades, y de la protección regia al clero católico, visualizada en los Concilios de Toledo (presididos por el propio rey). Los años siguientes vieron un verdadero "renacimiento visigodo" con figuras de la influencia de san Isidoro de Sevilla (y sus hermanos Leandro, Fulgencio y Florentina, los "cuatro santos de Cartagena"), Braulio de Zaragoza o Ildefonso de Toledo, de gran repercusión en el resto de Europa y en los futuros reinos cristianos de la Reconquista ("véase cristianismo en España, monasterio en España, monasterio hispano y liturgia hispánica"). Los ostrogodos, en cambio, no dispusieron de tiempo suficiente para realizar la misma evolución en Italia. No obstante, del grado de convivencia con el papado y los intelectuales católicos fue muestra que los reyes ostrogodos los elevaban a los cargos de mayor confianza (Boecio y Casiodoro, ambos "magister officiorum" con Teodorico el Grande), aunque también de lo vulnerable de su situación (ejecutado el primero -523- y apartado por los bizantinos el segundo -538-). Sus sucesores en el dominio de Italia, los también arrianos lombardos, tampoco llegaron a experimentar la integración con la población católica sometida, y su divisiones internas hicieron que la conversión al catolicismo del rey Agilulfo (603) no llegara a tener mayores consecuencias.

El cristianismo fue llevado a Irlanda por San Patricio a principios del siglo V, y desde allí se extendió a Escocia, desde donde un siglo más tarde regresó por la zona norte a una Inglaterra abandonada por los cristianos britones a los paganos pictos y escotos (procedentes del norte de Gran Bretaña) y a los también paganos germanos procedentes del continente (anglos, sajones y jutos). A finales del siglo VI, con el Papa Gregorio Magno, también Roma envió misioneros a Inglaterra desde el sur, con lo que se consiguió que en el transcurso de un siglo Inglaterra volviera a ser cristiana.

A su vez, los britones habían iniciado una emigración por vía marítima hacia la península de Bretaña, llegando incluso hasta lugares tan lejanos como la costa cantábrica entre Galicia y Asturias, donde fundaron la diócesis de Britonia. Esta tradición cristiana se distinguía por el uso de la tonsura céltica o escocesa, que rapaba la parte frontal del pelo en vez de la "coronilla".

La supervivencia en Irlanda de una comunidad cristiana aislada de Europa por la barrera pagana de los anglosajones, provocó una evolución diferente al cristianismo continental, lo que se ha denominado cristianismo celta. Conservaron mucho de la antigua tradición latina, que estuvieron en condiciones de compartir con Europa continental apenas la oleada invasora se hubo calmado temporalmente. Tras su extensión a Inglaterra en el siglo VI, los irlandeses fundaron en el siglo VII monasterios en Francia, en Suiza (Saint Gall), e incluso en Italia, destacándose particularmente los nombres de Columba y Columbano. Las Islas Británicas fueron durante unos tres siglos el vivero de importantes nombres para la cultura: el historiador Beda el Venerable, el misionero Bonifacio de Alemania, el educador Alcuino de York, o el teólogo Juan Escoto Erígena, entre otros. Tal influencia llega hasta la atribución de leyendas como la de Santa Úrsula y las Once Mil Vírgenes, bretona que habría efectuado un extraordinario viaje entre Britania y Roma para acabar martirizada en Colonia.

Por su parte, la extensión del cristianismo entre los búlgaros y la mayor parte de los pueblos eslavos (serbios, moravos y los pueblos de Crimea y estepas ucranianas y rusas -Vladimiro I de Kiev, año 988-) fue muy posterior, y a cargo del Imperio bizantino, con lo que se hizo con el credo ortodoxo (predicaciones de Cirilo y Metodio, siglo IX); mientras que la evangelización de otros pueblos de Europa Oriental (el resto de los eslavos -polacos, eslovenos y croatas-, bálticos y húngaros -San Esteban I de Hungría, hacia el año 1000-) y de los pueblos nórdicos (vikingos escandinavos) se hizo por el cristianismo latino partiendo de Europa Central, en un periodo todavía más tardío (hasta los siglos XI y XII); permitiendo (especialmente la conversión de Hungría) las primeras peregrinaciones por vía terrestre a Tierra Santa.

Los jázaros eran un pueblo turco procedente del Asia central (donde se había formado desde el siglo VI el imperio de los Köktürks) que en su parte occidental había dado origen a un importante estado que dominaba el Cáucaso y las estepas rusas y ucranianas hasta Crimea en el siglo VII. Su clase dirigente se convirtió mayoritariamente al judaísmo, peculiaridad religiosa que lo convertía en un vecino excepcional entre el califato islámico de Damasco y el imperio cristiano de Bizancio.

La división entre Oriente y Occidente fue, además de una estrategia política (inicialmente de Diocleciano -286- y hecha definitiva con Teodosio -395-), un reconocimiento de la diferencia esencial entre ambas mitades del Imperio. Oriente, en sí mismo muy diverso (Tracia -Península Balcánica-, Asia -Anatolia, Cáucaso, Siria, Palestina y la frontera mesopotámica con los persas- y Egipto), era la parte más urbanizada y con economía más dinámica y comercial, frente a un Occidente en vías de "feudalización", ruralizado, con una vida urbana en decadencia, mano de obra esclava cada vez más escasa y la aristocracia cada vez más ajena a las estructuras del poder imperial y recluida en sus lujosas "villae" autosuficientes, cultivadas por colonos en régimen similar a la servidumbre. La "lingua franca" en Oriente era el griego, frente al latín de Occidente. En la implantación de la jerarquía cristiana, Oriente disponía de todos los patriarcados de la "Pentarquía" menos el de Roma (Alejandría, Antioquía y Constantinopla, a los que se añadió Jerusalén tras el concilio de Calcedonia de 451); incluso la primacía romana (sede pontificia o cátedra de San Pedro) era un hecho discutido.
La supervivencia de Roma en Oriente no dependía de la suerte de Occidente, mientras que lo contrario sí: de hecho, los emperadores orientales optaron por sacrificar la ciudad de Rómulo y Remo -que ya ni siquiera era la capital occidental- cuando lo consideraron conveniente, abandonándola a su suerte o incluso desplazando hacia ella a los bárbaros más agresivos, lo que precipitó su caída.

Justiniano I consolidó la frontera del Danubio y, desde 532 logró un equilibrio en la frontera con la Persia sasánida, lo que le permitió desplazar los esfuerzos bizantinos hacia el Mediterráneo, reconstruyendo la unidad del "Mare Nostrum": En 533, una expedición del general Belisario aniquila a los vándalos (batalla de Ad Decimum y batalla de Tricamarum) incorporando la provincia de África y las islas del Mediterráneo Occidental (Cerdeña, Córcega y las Baleares). En 535 Mundus ocupó Dalmacia y Belisario Sicilia. Narsés elimina a los ostrogodos de Italia en 554-555. Rávena volvió a ser una ciudad imperial, donde se conservarán los fastuosos mosaicos de San Vital. Liberio solo consiguió desplazar a los visigodos de la costa sureste de la península ibérica y de la provincia Bética.

En Constantinopla se iniciaron dos programas ambiciosos y de prestigio con el fin de asentar la autoridad imperial: uno de recopilación legislativa: el "Digesto", dirigido por Triboniano (publicado en 533), y otro constructivo: la iglesia de Santa Sofía, de los arquitectos Antemio de Tralles e Isidoro de Mileto (levantada entre el 532 y el 537). Un símbolo de la civilización clásica fue clausurado: la Academia de Atenas (529). Otro, las carreras de cuadrigas siguieron siendo una diversión popular que levantaba pasiones. De hecho, eran utilizadas políticamente, expresando el color de cada equipo divergencias religiosas (un precoz ejemplo de movilizaciones populares utilizando colores políticos). La revuelta de Niká (534) estuvo a punto de provocar la huida del emperador, que evitó la emperatriz Teodora con su famosa frase "la púrpura es un glorioso sudario".

Los siglos VII y VIII representaron para Bizancio una "edad oscura" similar a la de occidente, que incluyó también una fuerte ruralización y feudalización en lo social y económico y una pérdida de prestigio y control efectivo del poder central. A las causas internas se sumó la renovación de la guerra con los persas, nada decisiva pero especialmente extenuante, a la que siguió la invasión musulmana, que privó al Imperio de las provincias más ricas: Egipto y Siria. No obstante, en el caso bizantino, la disminución de la producción intelectual y artística respondía además a los efectos particulares de la querella iconoclasta, que no fue un simple debate teológico entre iconoclastas e iconódulos, sino un enfrentamiento interno desatado por el patriarcado de Constantinopla, apoyado por el emperador León III, que pretendía acabar con la concentración de poder e influencia política y religiosa de los poderosos monasterios y sus apoyos territoriales (puede imaginarse su importancia viendo cómo ha sobrevivido hasta la actualidad el Monte Athos, fundado más de un siglo después, en 963).
La recuperación de la autoridad imperial y la mayor estabilidad de los siglos siguientes trajo consigo también un proceso de "helenización", es decir, de recuperación de la identidad griega frente a la oficial entidad romana de las instituciones, cosa más posible entonces, dada la limitación y homogeneización geográfica producida por la pérdida de las provincias, y que permitía una organización territorial militarizada y más fácilmente gestionable: los "temas" ("") con la adscripción a la tierra de los militares en ellos establecidos, lo que produjo formas similares al feudalismo occidental.

El periodo entre 867 y 1056, bajo la dinastía macedonia, se conoce con el nombre de "Renacimiento Macedónico", en que Bizancio vuelve a ser una potencia mediterránea y se proyecta hacia los pueblos eslavos de los Balcanes y hacia el norte del mar Negro. Basilio II "Bulgaróctono" que ocupó el trono en el período 976-1025 llevó al Imperio a su máxima extensión territorial desde la invasión musulmana, ocupando parte de Siria, Crimea y los Balcanes hasta el Danubio. La evangelización de Cirilo y Metodio obtendrá una esfera de influencia bizantina en Europa Oriental que cultural y religiosamente tendrá una gran proyección futura mediante la difusión del alfabeto cirílico (adaptación del alfabeto griego para la representación de los fonemas eslavos, que se sigue utilizando en la actualidad); así como la del cristianismo ortodoxo (predominante desde Serbia hasta Rusia).

Sin embargo, la segunda mitad del siglo XI presenciará un nuevo desafío islámico, esta vez protagonizado por los turcos selyúcidas y la intervención del Papado y de los europeos occidentales, mediante la intervención militar de las Cruzadas, la actividad comercial de los mercaderes italianos (genoveses, amalfitanos, pisanos y sobre todo venecianos) y las polémicas teológicas del denominado Cisma de Oriente o Gran Cisma de Oriente y Occidente, con lo que la teórica ayuda cristiana se demostró tan negativa o más para el Imperio Oriental que la amenaza musulmana. El proceso de feudalización se acentuó al verse forzados los emperadores Comneno a realizar cesiones territoriales (denominadas "pronoia") a la aristocracia y a miembros su propia familia.

En el siglo VII, tras las predicaciones de Mahoma y las conquistas de los primeros califas (a la vez líderes políticos y religiosos, en una religión -el islamismo- que no reconoce distinciones entre laicos y clérigos), se había producido la unificación de Arabia y la conquista del Imperio persa y de buena parte del Imperio bizantino. En el siglo VIII se llegó a la península ibérica, la India y el Asia Central (batalla del Talas -751- victoria islámica ante China tras la que no se profundizó en ese Imperio, pero que permitió un mayor contacto con su civilización, aprovechando los conocimientos de los prisioneros). En el occidente la expansión musulmana se frenó desde la batalla de Poitiers (732) ante los francos y la mitificada batalla de Covadonga ante los asturianos (722). La presencia de los musulmanes como una civilización rival alternativa asentada en la mitad sur de la cuenca del Mediterráneo, cuyo tráfico marítimo pasan a controlar, obligó al cierre en sí misma de Europa Occidental por varios siglos, y para algunos historiadores significó el verdadero comienzo de la Edad Media.
Desde el siglo VIII se produjo una difusión más lenta de la civilización islámica por sitios tan lejanos como Indonesia y el continente africano, y desde el siglo XIV por Anatolia y los Balcanes. Las relaciones con la India fueron también muy estrechas durante el resto de la Edad Media (aunque la imposición del imperio mogol no se produjo hasta el siglo XVI), mientras que el océano Índico se convirtió casi en un "Mare Nostrum" árabe, donde se ambientaron las aventuras de "Simbad el marino" (uno de los cuentos de "Las mil y una noches" de la época de Harún al-Rashid). El tráfico comercial de las rutas marítimas y caravaneras unían el Índico con el Mediterráneo a través del mar Rojo o el golfo Pérsico y las caravanas del desierto. Esa llamada ruta de las especias (prefigurada por la ruta del incienso en la Edad Antigua) fue esencial para que llegaran a occidente retazos de la ciencia y la cultura de Extremo Oriente. Por el norte, la ruta de la seda cumplió la misma función atravesando los desiertos y las cordilleras del Turquestán. El ajedrez, la numeración indo-arábiga y el concepto de cero, así como algunas obras literarias ("Calila e Dimna") estuvieron entre los aportes hindúes y persas. El papel, el grabado o la pólvora, entre las chinas. La función de los árabes, y de los persas, sirios, egipcios y españoles arabizados (no solo islámicos, pues hubo muchos que mantuvieron su religión cristiana o judía -no tanto la zoroastriana-) distó mucho de ser mera transmisión, como testimonia la influencia de la reinterpretación de la filosofía clásica que llegó a través de los textos árabes a Europa Occidental a partir de las traducciones latinas desde el siglo XII, y la difusión de cultivos y técnicas agrícolas por la región mediterránea. En un momento en que estaban prácticamente ausentes de la economía europea, destacaron las prácticas comerciales y la circulación monetaria en el mundo islámico, animadas por la explotación de minas de oro tan lejanas como las del África subsahariana, junto con otro tipo de actividades, como el tráfico de esclavos.
La unidad inicial del mundo islámico, que se había cuestionado ya en el aspecto religioso con la separación de suníes y chiíes, se rompió también en lo político con la sustitución de los Omeyas por los Abbasíes al frente del califato en el 749, que además sustituyeron Damasco por Bagdad como capital. Abderramán I, el último superviviente Omeya, consiguió fundar en Córdoba un emirato independiente para Al-Ándalus (nombre árabe de la península ibérica), que su descendiente Abderramán III convirtió en un califato alternativo en el 929. Poco antes, en el 909 los Fatimíes habían hecho lo propio en Egipto. A partir del siglo XI se producen cambios muy importantes: el desafío a la hegemonía árabe como etnia dominante dentro del islam a cargo de los islamizados turcos, que pasarán a controlar distintas zonas del Medio Oriente (mamelucos, otomanos), o de kurdos como Saladino; la irrupción de los cristianos latinos en tres puntos clave del Mediterráneo (reinos cristianos de la Reconquista en Al Ándalus, normandos en el sur de Italia y cruzados en Siria y Palestina); y la de los mongoles desde el centro de Asia.

Hacia el siglo VIII, la situación política europea se había estabilizado. En oriente, el Imperio bizantino era fuerte otra vez, gracias a una serie de emperadores competentes. En occidente, algunos reinos aseguraban relativa estabilidad a varias regiones: Northumbria a Inglaterra, Visigotia a España, Lombardía a Italia, y el Reino Franco a la Galia. En realidad, el "reino franco" era un compuesto de tres reinos: Austrasia, Neustria y Aquitania.

El Imperio carolingio surge de las bases creadas por los predecesores de Carlomagno desde principios del siglo VIII (Carlos Martel y Pipino el Breve). La proyección de sus fronteras a través de una gran parte de la Europa Occidental permitió a Carlos la aspiración de reconstruir la extensión del antiguo Imperio romano Occidental, siendo la primera entidad política de la Edad Media que estuvo en condiciones de convertirse en una potencia continental. Aquisgrán (Aachen en alemán, Aix-la Chapelle en francés) fue elegida como capital, en una situación central y suficientemente alejada de Italia, que a pesar de ser liberada del dominio de los longobardos y de las teóricas reivindicaciones bizantinas, conservó una gran autonomía que llegaba a la soberanía temporal con la cesión de unos incipientes estados papales (el "Patrimonium Petri" o Patrimonio de San Pedro, que incluía Roma y buena parte del centro de Italia). Como resultado de la estrecha vinculación entre el pontificado y la dinastía carolingia, que se legitimaban y defendían mutuamente ya por tres generaciones, el papa León III reconoció las pretensiones imperiales de Carlomagno con una coronación en extrañas circunstancias, el día de Navidad del año 800.
Se crearon las marcas para fijar las fronteras ante los enemigos exteriores (árabes en la Marca Hispánica, sajones en la Marca Sajona, bretones en la Marca Bretona, lombardos -hasta su derrota- en la Marca Lombarda y ávaros en la Marca Ávara; posteriormente también se creó una para los magiares: la Marca del Friuli). El territorio interior fue organizado en condados y ducados (unión de varios condados o marcas). Los funcionarios que los dirigían (condes, marqueses y duques) eran vigilados por inspectores temporales (los "missi dominici" -enviados del señor-), y se procuraba que no se heredaran para evitar que quedaran patrimonializados en una familia (cosa, que con el tiempo, no pudo evitarse). La consignación de tierras junto con los cargos, pretendía sobre todo el mantenimiento de la costosa caballería pesada y los nuevos caballos de batalla ("destreros", introducidos desde Asia en el siglo VII, que se empleaban de una manera completamente distinta a la caballería antigua, con estribos, aparatosas sillas y que podían sostener armaduras). Tal proceso estuvo en el origen del nacimiento de los feudos que había que ceder a cada militar de acuerdo con su rango, hasta la unidad básica: el caballero que ejercía de señor sobre un territorio, se quedaba para su mantenimiento con una reserva señorial y dejaba los mansos para sus siervos, que estaban obligados a cultivar la reserva con prestaciones gratuitas de trabajo a cambio de la protección militar y el mantenimiento del orden y la justicia, que eran las funciones del señor. Lógicamente, los feudos en sus distintos niveles sufrieron la misma transformación patrimonial que marcas y condados, estableciendo una red piramidal de fidelidades que es el origen del vasallaje feudal.

Carlomagno negoció de igual a igual con otras grandes potencias de la época, como el Imperio bizantino, el Emirato de Córdoba, y el Califato Abasida. Aunque él mismo, ya en edad adulta, no sabía escribir (cosa habitual en la época, en que únicamente algunos clérigos lo hacían), Carlomagno siguió una política de prestigio cultural y un notable programa artístico. Pretendió rodearse de una corte de sabios e iniciar un programa educativo basado en el "trivium" y el "quadrivium", para lo que mandó llamar a la intelectualidad de su tiempo a sus dominios impulsando, con la colaboración de Alcuino de York, el llamado "Renacimiento carolingio". Dentro de este empeño educativo ordenó a sus nobles aprender a escribir, cosa que él mismo intentó, aunque nunca consiguió hacerlo con soltura.

Muerto Carlomagno en 814, toma el poder su hijo Ludovico Pío. Los hijos de este: Carlos el Calvo ("Francia occidental"), Luis el Germánico ("Francia oriental") y Lotario I (primogénito y heredero del título imperial), se enfrentaron militarmente disputándose los diferentes territorios del imperio, que, más allá de las alianzas aristocráticas, manifestaban distintas personalidades, interpretables desde una perspectiva protonacional (idiomas diferentes: hacia el sur y oeste se imponían las lenguas romances que se comenzaban a diferenciar del latín vulgar, hacia el norte y este las lenguas germánicas, como testimoniaban los previos "Juramentos de Estrasburgo"; costumbres, tradiciones e instituciones propias —romanas hacia el sur, germanas hacia el norte—). Esta situación no concluyó ni siquiera en el 843 tras el Tratado de Verdún, puesto que la posterior división del reino de Lotario entre sus hijos (la Lotaringia, franja central desde los Países Bajos hasta Italia, pasando por la región del Rin, Borgoña y Provenza) llevó a los tíos de estos (Carlos y Luis), a otro reparto (el Tratado de Mersen del 870) que simplificaba las fronteras (dejando únicamente Italia y Provenza en manos de su sobrino el emperador Luis II el Joven —cuyo cargo no suponía más primacía que la honorífica—, pero no condujo a una mayor concentración de poder en manos de esos monarcas, débiles y en manos de la nobleza territorial. En algunas regiones, el pacto no era más que una entelequia, puesto que la costa del mar del Norte estaba ocupada por los vikingos. Incluso en las zonas teóricamente controladas, las posteriores herencias y luchas internas entre los sucesivos reyes y emperadores carolingios subdividieron y reunificaron los territorios de manera casi aleatoria.

La división, sumada al proceso institucional de descentralización inherente al sistema feudal, en ausencia de fuertes poderes centrales, y al debilitamiento preexistente de las estructuras sociales y económicas, hizo que la siguiente oleada de invasiones bárbaras, sobre todo las protagonizadas por magiares y vikingos, sumieran de nuevo a Europa Occidental en el caos de una nueva edad oscura.

El fracaso del proyecto político centralizador de Carlomagno llevó, en ausencia de ese contrapeso, a la formación de un sistema político, económico y social que los historiadores han convenido en llamar feudalismo, aunque en realidad el nombre nació como un peyorativo para designar del Antiguo Régimen por parte de sus críticos ilustrados. La Revolución francesa suprimió solemnemente "todos los derechos feudales" en la noche del 4 de agosto de 1789 y "definitivamente el régimen feudal", con el decreto del 11 de agosto.

La generalización del término permite a muchos historiadores aplicarlo a las formaciones sociales de todo el territorio europeo occidental, pertenecieran o no al Imperio carolingio. Los partidarios de un uso restringido, argumentando la necesidad de no confundir conceptos como feudo, "villae", "tenure", o señorío lo limitan tanto en espacio (Francia, Oeste de Alemania y Norte de Italia) como en el tiempo: un «primer feudalismo» o «feudalismo carolingio» desde el siglo hasta el año 1000 y un «feudalismo clásico» desde el año 1000 hasta el 1240, a su vez dividido en dos épocas, la primera, hasta el 1160 (la más descentralizada, en que cada señor de castillo podía considerarse independiente, y se produce el proceso denominado "incastellamento"); y la segunda, la propia de la "monarquía feudal"). Habría incluso "feudalismos de importación": la Inglaterra normanda desde 1066 y los estados latinos de oriente creados durante las Cruzadas (siglos y ).

Otros prefieren hablar de "régimen" o "sistema feudal", para diferenciarlo sutilmente del feudalismo estricto, o de "síntesis feudal", para marcar el hecho de que sobreviven en ella rasgos de la antigüedad clásica mezclados con contribuciones germánicas, implicando tanto a instituciones como a elementos productivos, y significó la especificidad del feudalismo europeo occidental como formación económico social frente a otras también feudales, con consecuencias trascendentales en el futuro devenir histórico. Más dificultades hay para el uso del término cuando nos alejamos más: Europa Oriental experimenta un proceso de "feudalización" desde finales de la Edad Media, justo cuando en muchas zonas de Europa Occidental los campesinos se liberan de las formas jurídicas de la servidumbre, de modo que suele hablarse del feudalismo polaco o ruso. El Antiguo Régimen en Europa, el islam medieval o el Imperio bizantino fueron sociedades urbanas y comerciales, y con un grado de centralización política variable, aunque la explotación del campo se realizaba con relaciones sociales de producción muy similares al feudalismo medieval. Los historiadores que aplican la metodología del materialismo histórico (Marx definió el modo de producción feudal como el estadio intermedio entre el esclavista y el capitalista) no dudan en hablar de «economía feudal» para referirse a ella, aunque también reconocen la necesidad de no aplicar el término a cualquier formación social preindustrial no esclavista, puesto que a lo largo de la historia y de la geografía han existido otros modos de producción también previstos en la modelización marxista, como el modo de producción primitivo de las sociedades poco evolucionadas, homogéneas y con escasa división social —como las de los mismos pueblos germánicos previamente a las invasiones— y el modo de producción asiático o "despotismo hidráulico" —Egipto faraónico, reinos de la India o Imperio chino— caracterizado por la tributación de las aldeas campesinas a un estado muy centralizado. En lugares aún más lejanos se ha llegado a utilizar el término feudalismo para describir una época. Es el caso de Japón y el denominado feudalismo japonés, dadas las innegables similitudes y paralelismos que la nobleza feudal europea y su mundo tiene con los samuráis y el suyo. También se ha llegado a aplicarlo a la situación histórica de los periodos intermedios de la historia de Egipto, en los que, siguiendo un ritmo cíclico milenario, decae el poder central y la vida en las ciudades, la anarquía militar rompe la unidad de las tierras del Nilo, y los templos y señores locales que alcanzan a controlar un espacio de poder gobiernan en él de manera independiente sobre los campesinos obligados al trabajo.

Dos instituciones eran claves para el feudalismo: por un lado el vasallaje como relación jurídico-política entre señor y vasallo, un contrato sinalagmático (es decir, entre iguales, con requisitos por ambas partes) entre señores y vasallos (ambos hombres libres, ambos guerreros, ambos nobles), consistente en el intercambio de apoyos y fidelidades mutuas (dotación de cargos, honores y tierras -el feudo- por el señor al vasallo y compromiso de "auxilium et consilium" -auxilio o apoyo militar y consejo o apoyo político-), que si no se cumplía o se rompía por cualquiera de las dos partes daba lugar a la felonía, y cuya jerarquía se complicaba de forma piramidal (el vasallo era a su vez señor de vasallos); y por otro lado el feudo como unidad económica y de relaciones sociales de producción, entre el señor del feudo y sus siervos, no un contrato igualitario, sino una imposición violenta justificada ideológicamente como un "do ut des" de protección a cambio de trabajo y sumisión.

Por tanto, la realidad que se enuncia como relaciones feudo-vasalláticas es realmente un término que incluye dos tipos de relación social de naturaleza completamente distinta, aunque los términos que las designan se empleaban en la época (y se siguen empleando) de manera equívoca y con gran confusión terminológica entre ellos:

El vasallaje era un pacto entre dos miembros de la nobleza de distinta categoría. El caballero de menor rango se convertía en vasallo ("vassus") del noble más poderoso, que se convertía en su señor ("dominus") por medio del Homenaje e Investidura, en una ceremonia ritualizada que tenía lugar en la torre del homenaje del castillo del señor. El homenaje ("homage") -del vasallo al señor- consistía en la postración o humillación -habitualmente de rodillas-, el "osculum" (beso), la "inmixtio manum" -las manos del vasallo, unidas en posición orante, eran acogidas entre las del señor-, y alguna frase que reconociera haberse convertido en "su hombre". Tras el homenaje se producía la investidura -del señor al vasallo-, que representaba la entrega de un feudo (dependiendo de la categoría de vasallo y señor, podía ser un condado, un ducado, una marca, un castillo, una población, o un simple sueldo; o incluso un monasterio si el vasallaje era eclesiástico) a través de un símbolo del territorio o de la alimentación que el señor debe al vasallo -un poco de tierra, de hierba o de grano- y del espaldarazo, en el que el vasallo recibe una espada (y unos golpes con ella en los hombros), o bien un báculo si era religioso.

La encomienda, encomendación o patrocinio ("patrocinium", "commendatio", aunque era habitual utilizar el término "commendatio" para el acto del homenaje o incluso para toda la institución del vasallaje) eran pactos teóricos entre los campesinos y el señor feudal, que podían también ritualizarse en una ceremonia o -más raramente- dar lugar a un documento. El señor acogía a los campesinos en su feudo, que se organizaba en una reserva señorial que los siervos debían trabajar obligatoriamente (sernas o corveas) y en el conjunto de las pequeñas explotaciones familiares (mansos) que se atribuían a los campesinos para que pudieran subsistir. Obligación del señor era protegerles si eran atacados, y mantener el orden y la justicia en el feudo. A cambio, el campesino se convertía en su siervo y pasaba a la doble jurisdicción del señor feudal: en los términos utilizados en la península ibérica en la Baja Edad Media, el señorío territorial, que obligaba al campesino a pagar rentas al noble por el uso de la tierra; y el señorío jurisdiccional, que convertía al señor feudal en gobernante y juez del territorio en el que vivía el campesino, por lo que obtenía rentas feudales de muy distinto origen (impuestos, multas, monopolios, etc.). La distinción entre propiedad y jurisdicción no era en el feudalismo algo claro, pues de hecho el mismo concepto de propiedad era confuso, y la jurisdicción, otorgada por el rey como merced, ponía al señor en disposición de obtener sus rentas. No existieron señoríos jurisdiccionales en los que la totalidad de las parcelas pertenecieran como propiedad al señor, siendo muy generalizadas distintas formas de alodio en los campesinos. En momentos posteriores de despoblamiento y "refeudalización", como la crisis del siglo XVII, algunos nobles intentaban que se considerase despoblado completamente de campesinos un señorío para liberarse de todo tipo de cortapisas y convertirlo en "coto redondo" reconvertible para otro uso, como el ganadero.

Junto con el feudo, el vasallo recibe los siervos que hay en él, no como propiedad esclavista, pero tampoco en régimen de libertad; puesto que su condición servil les impide abandonarlo y les obliga a trabajar. Las obligaciones del señor del feudo incluyen el mantenimiento del orden, o sea, la jurisdicción civil y criminal ("mero e mixto imperio" en la terminología jurídica reintroducida con el Derecho Romano en la Baja Edad Media), lo que daba aún mayores oportunidades para obtener el excedente productivo que los campesinos pudieran obtener después de las obligaciones de trabajo -corveas o sernas en la reserva señorial- o del pago de renta -en especie o en dinero, de circulación muy escasa en la Alta Edad Media, pero más generalizada en los últimos siglos medievales, según fue dinamizándose la economía-. Como monopolio señorial solían quedar la explotación de los bosques y la caza, los caminos y puentes, los molinos, las tabernas y tiendas. Todo ello eran más oportunidades de obtener más renta feudal, incluidos derechos tradicionales, como el "ius prime noctis" o derecho de pernada, que se convirtió en un impuesto por matrimonios, buena muestra de que es en el excedente de donde se extrae la renta feudal de manera extraeconómica (en este caso en la demostración de que una comunidad campesina crece y prospera).

Con el tiempo, siguiendo la tendencia marcada desde el Bajo Imperio romano, que se consolidó en la "época clásica" del feudalismo y que pervivió durante todo el Antiguo Régimen, se fue conformando una sociedad organizada de manera estamental, en los llamados estamentos u "ordines" (órdenes): nobleza, clero y pueblo llano (o tercer estado): "bellatores, oratores y laboratores" los hombres que guerrean, los que rezan y los que trabajan, según el vocabulario de la época. Los dos primeros son privilegiados, es decir, no se les aplica la ley común, sino un fuero propio (por ejemplo, tienen distintas penas para el mismo delito, y su forma de ejecución es diferente) y no pueden trabajar (les están prohibidos los "oficios viles y mecánicos"), puesto que esa es la condición de "no privilegiados". En época medieval, los órdenes feudales no eran estamentos cerrados y bloqueados, sino que mantenían una permeabilidad que permitía en casos extraordinarios el ascenso social debido al mérito (por ejemplo, a la demostración de un excepcional valor), que eran tan escasos que no se vivían como una amenaza, cosa que sí ocurrió a partir de las grandes convulsiones sociales de los siglos finales de la Baja Edad Media, en que los privilegiados se vieron obligados a institucionalizar su posición procurando cerrar el acceso a sus estamentos de los no privilegiados (en lo que tampoco tuvieron una eficacia total). Completamente impropia sería la comparación con la sociedad de castas de la India, en que guerreros, sacerdotes, comerciantes, campesinos y "parias" pertenecían a castas diferentes entendidas como linajes desconectados cuya mezcla se prohibía.

Las funciones de los órdenes feudales estaban fijadas ideológicamente por el agustinismo político ("Civitate Dei" -426-), en búsqueda de una sociedad que, aunque como "terrena" no podía dejar de ser corrupta e imperfecta, podía aspirar a ser al menos una sombra de la imagen de una "Ciudad de Dios" perfecta de raíces platónicas en que todos tuvieran un papel en su protección, su salvación y su mantenimiento. Esta idea fue reformulada y perfilada a lo largo de la Edad Media, sucesivamente por autores como Isidoro de Sevilla (630), la "escuela de Auxerre" (Haimón de Auxerre -865- en la abadía borgoñona en la que trabajaban Erico de Auxerre y su discípulo Remigio de Auxerre, que seguían la tradición de Escoto Eriúgena), Boecio (892), Wulfstan de York (1010), Gerardo de Cambrai (1024) o Adalberón de Laon; y utilizada en textos legislativos como la llamada "Compilación de Huesca" de los Fueros de Aragón (Jaime I), y el Código de las Siete Partidas (Alfonso X "el Sabio", 1265).

Los "bellatores" o guerreros eran la nobleza, cuya función era la protección física, la defensa de todos ante las agresiones e injusticias. Estaba organizada piramidalmente desde el emperador, pasando por los reyes y descendiendo sin solución de continuidad hasta el último escudero, aunque atendiendo a su rango, poder y riqueza puede clasificarse en dos partes diferenciadas: alta nobleza (marqueses, condes y duques) cuyos feudos tienen el tamaño de regiones y provincias (aunque la mayor parte de las veces no en continuidad territorial, sino repartido y difuso, lleno de enclaves y exclaves); y la baja nobleza o caballeros (barones, infanzones), cuyos feudos son del tamaño de pequeñas comarcas (a escala municipal o inferior a la municipal), o directamente no poseen feudos territoriales, viviendo en los castillos de señores más importantes, o en ciudades o poblaciones en las que no ejercen jurisdicción (aunque sí pueden ejercer su "regimiento", es decir, participar en su gobierno municipal en representación del "estado noble"). A finales de la Edad Media y en la Edad Moderna, cuando la nobleza ya no ejercía su función militar, como era el caso de los hidalgos españoles, que aducían sus privilegios estamentales para evitar el pago de impuestos y obtener alguna ventaja social, alardeando de ejecutoria o de blasón y casa solariega, pero que al no disponer de rentas feudales suficientes para mantener la manera de vida nobiliaria, corrían el peligro de perder su condición por contraer un matrimonio desigual o ganarse la vida trabajando:
Además de la legitimación religiosa, a través de la cultura y el arte laicos (la épica de los cantares de gesta y la lírica del amor cortés de los trovadores provenzales) se difundía socialmente la legitimación ideológica de la forma de vida, la función social y los valores de la nobleza.

Los "oratores" o clérigos eran el clero, cuya función era facilitar la salvación espiritual de las almas inmortales: algunos formaban una élite poderosa llamada alto clero (abades, obispos), y otros más humildes, el bajo clero (curas de pueblo o los hermanos legos de un monasterio). La extensión y organización del monacato benedictino a través de la Orden de Cluny, estrechamente vinculado a la organización de la red episcopal centralizada y jerarquizada, con cúspide en el Papa de Roma, estableció la doble pirámide feudal del clero secular, destinado a la administración los de sacramentos (que controlaban toda la trayectoria vital de la población, desde el nacimiento hasta muerte); y el clero regular, apartado del "mundo" y sometido a una regla monástica (habitualmente la regla benedictina). Los tres votos monásticos del clero regular: pobreza, obediencia y castidad; así como el celibato eclesiástico que se fue imponiendo al clero secular, funcionaron como un eficaz mecanismo de vinculación de los dos estamentos privilegiados: los hijos segundones de la nobleza ingresaban en el clero, donde eran mantenidos sin estrecheces gracias a las numerosas fundaciones, donaciones, dotes y mandas testamentarias; pero no disputaban las herencias a sus hermanos, que podían mantener concentrado el patrimonio familiar. Las tierras de la Iglesia quedaban como manos muertas, cuya función era la de garantizar las misas y oraciones previstas por los donadores, de modo que los hijos rezaban por las almas de los padres. Todo el sistema garantizaba el mantenimiento del prestigio social de los privilegiados, asistiendo a misa en lugares destacados mientras vivían y enterrados en lugares principales de iglesias y catedrales cuando morían. No faltaron los enfrentamientos: la evidencia de simonía y nicolaísmo (nombramientos de cargos eclesiásticos interferidos por las autoridades civiles o su pura compraventa) y la utilización de la principal amenaza religiosa al poder temporal, equivalente a una muerte civil: la excomunión. El Papa se atribuía incluso la autoridad de eximir al vasallo de la fidelidad debida a su señor y reivindicarla para sí mismo, lo que fue utilizado en varias ocasiones para la fundación de reinos que pasaban a ser vasallos del Papa (por ejemplo, la independencia que Afonso Henriques obtuvo para el condado convertido en reino de Portugal frente al reino de León).

Los "laboratores" o trabajadores, eran el pueblo llano, cuya función era el mantenimiento de los cuerpos, la función ideológicamente más baja y humilde -"humiliores" eran los cercanos al "humus", la tierra, mientras que sus superiores eran "honestiores", los que podían mantener la honra u honor-. Necesariamente los más numerosos, y la inmensa mayoría de ellos dedicados a tareas agrícolas, dado la bajísima productividad y rendimiento agrícola, propios de la época preindustrial y del muy escaso nivel técnico (de ahí la identificación en castellano de "laborator" con labrador). Por lo común estaban sometidos a los otros estamentos. El pueblo llano estaba compuesto en su gran mayoría por campesinos, siervos de los señores feudales o campesinos libres ("villanos"), y por artesanos, que eran escasos y vivían, bien en las aldeas (aquellos de menor especialización, que solían compartir las tareas agrícolas: herreros, talabarteros, alfareros, sastres) o en las pocas y pequeñas ciudades (los de mayor especialización y de productos de necesidad menos apremiante o de demandada de las clases altas: joyeros, orfebres, cereros, toneleros, tejedores, tintoreros). La autosuficiencia de los feudos y los monasterios limitaba su mercado y capacidad de crecer. Los oficios de la construcción (cantería, albañilería, carpintería) y la misma profesión de maestro de obras o arquitecto son una notable excepción: obligados por la naturaleza de su trabajo al desplazamiento al lugar donde se construye el edificio, se transformaron en un gremio nómada que se desplazaba por los caminos europeos comunicándose novedades técnicas u ornamentales transformadas en "secretos de oficio", lo que está en el origen de su lejana y mitificada vinculación con la sociedad secreta de la masonería, que desde su origen los consideró como los primitivos "masones".

Las zonas sin dependencia intermedia de señores nobles o eclesiásticos se denominaban realengo y solían prosperar más, o al menos solían considerar como una desgracia el pasar a depender de un señor, hasta el punto de que en algunas ocasiones conseguían evitarlo con pagos al rey, o se incentivaba la repoblación de zonas fronterizas o despobladas (como ocurrió en el reino astur-leonés con la despoblada Meseta del Duero) donde podían aparecer figuras mixtas, como el caballero villano (que podía mantener con su propia explotación al menos un caballo de guerra y armarse y defenderse a sí mismo) o las behetrías, que elegían a su propio señor y podían cambiar de uno u a otro si les convenía, o con la oferta de un fuero o carta puebla que otorgaba a un población su propio "señorío colectivo". Los privilegios iniciales no fueron suficientes para impedir que con el tiempo la mayor parte de ellos cayeran en la feudalización.

Los tres órdenes feudales no eran en la Edad Media aún unos estamentos cerrados: eran consecuencia básica de la estructura social que se había ido creando lenta pero inexorablemente con la transición del esclavismo al feudalismo desde la crisis del siglo III (ruralización y formación de latifundios y "villae", reformas de Diocleciano, descomposición del Imperio romano, las invasiones, el establecimiento de los reinos germánicos, instituciones del Imperio carolingio, descomposición de este y nueva oleada de invasiones). Los señores feudales eran continuación de las líneas clientelares de los condes carolingios, y algunos pueden remontarse a los latifundistas romanos o los séquitos germanos, mientras que el campesinado provenía de los antiguos esclavos o colonos, o de campesinos libres que se vieron forzados a encomendarse, recibiendo a veces una parte de sus antiguas tierras propias en forma de manso "concedido" por el señor. El campesino heredaba su condición servil y su sujeción a la tierra, y rara vez tenía oportunidad de ascender de nivel como no fuera por su fuga a una ciudad o por un hecho todavía más extraordinario: su ennoblecimiento por un destacado hecho de armas o servicio al rey, que en condiciones normales le estaban completamente vedados. Lo mismo puede decirse del artesano o el mercader (que en algunos casos podía acumular fortuna, pero no alterar su origen humilde). El noble lo era generalmente por herencia, aunque en ocasiones podía alguien ennoblecerse como soldado de fortuna, después de una victoriosa carrera de armas (como fue el caso, por ejemplo, de Roberto Guiscardo). El clero, por su parte, era reclutado por cooptación, con un acceso distinto según el origen social: asegurado para los segundones de las casas nobles y restringido a los niveles inferiores del bajo clero para los del pueblo llano; pero en casos particulares o destacados, el ascenso en la jerarquía eclesiástica estaba abierto al mérito intelectual. Todo esto le daba al sistema feudal una extraordinaria estabilidad, en donde había "un lugar para cada hombre, y cada hombre en su lugar", al tiempo que una extraordinaria flexibilidad, porque permitía al poder político y económico atomizarse a través de toda Europa, desde España hasta Polonia.

El legendario año mil, final del primer milenio, que se utiliza convencionalmente para el paso de la Alta a la Baja Edad Media, en realidad tan solo es una cifra redonda para el cómputo de la era cristiana, que no era de universal utilización: los musulmanes utilizaban su propio calendario islámico lunar que comienza en la Hégira (622); en algunas partes de la Cristiandad se utilizaban eras locales (como la era hispánica, que cuenta desde el 38 a. C.). Pero ciertamente, el milenarismo y los pronósticos del final de los tiempos estaban presentes; incluso el propio papa durante el cambio de milenio Silvestre II, el francés Gerberto de Aurillac, interesado en todo tipo de conocimientos, se ganó una reputación esotérica. La astrología siempre pudo encontrar fenómenos celestes extraordinarios en los que apoyar su prestigio (como los eclipses), pero ciertamente otros eventos de la época estuvieron entre los más espectaculares de la historia: el cometa Halley, que se acerca a la Tierra periódicamente cada ocho décadas, alcanzó su brillo máximo en la visita de 837, despidió el primer milenio en 989 y llegó a tiempo de la batalla de Hastings en 1066; mucho más visibles aún, las supernovas SN 1006 y SN 1054, que reciben el número del año en que se registraron, fueron más detalladamente reflejadas en fuentes chinas, árabes e incluso indoamericanas que en las escasas europeas (a pesar de que la de 1054 coincidió con la batalla de Atapuerca).

Todo el siglo X, más bien por las condiciones reales que por las imaginarias, puede considerarse parte de una época oscura, pesimista, insegura y presidida por el miedo a todo tipo de peligros, reales e imaginarios, naturales y sobrenaturales: miedo al mar, miedo al bosque, miedo a las brujas y los demonios y a todo lo que, sin entrar dentro de lo sobrenatural cristiano, quedaba relegado a lo inexplicable y al concepto de lo "maravilloso", atribuido a seres de dudosa o quizá posible existencia (dragones, duendes, hadas, unicornios). El hecho no tenía nada de único: mil años más tarde, el siglo XX hizo nacer miedos comparables: al holocausto nuclear, al cambio climático (versiones contemporáneas del "fin del mundo"); al comunismo (la "caza de brujas" con la que se identificó al macarthismo), a la libertad ("Miedo a la Libertad" es la base del fascismo en la interpretación de Erich Fromm), comparación que ha sido puesta de manifiesto por los historiadores e interpretada por los sociólogos ("Sociedad del riesgo" de Ulrich Beck).

En la coyuntura histórica del año mil, las estructuras políticas más fuertes del periodo anterior se estaban demostrando muy débiles: el Islam se descompuso en califatos (Bagdad, El Cairo y Córdoba), que para el año 1000 se estaban demostrando incapaces de contener a los reinos cristianos, especialmente al Reino de León, en la península ibérica (fracaso final de Almanzor) y al Imperio bizantino en el Mediterráneo Oriental. También sufre la expansión bizantina el Imperio búlgaro, que queda destruido. Los particularismos nacionales francés, polaco y húngaro dibujan fronteras protonacionales que, curiosamente, son muy similares a las del año 2000. En cambio, el Imperio carolingio se había disuelto en principados feudales ingobernables, que los Otónidas se proponían incluir en una segunda "Restauratio Imperii" (Otón I, en el 962), esta vez sobre bases germanas.

Los miedos y la inseguridad no acabaron con el año mil, ni tampoco hubo que esperar para volver a encontrarlos a la terrible Peste Negra y a los flagelantes del siglo XIV. Incluso en el "óptimo medieval" del expansivo siglo XIII lo más habitual era encontrar textos como el de Dante, o como los siguientes:

Este himno de autor desconocido, atribuido a muy diversos personajes (el papa Gregorio -que pudiera ser Gregorio Magno, a quien también se atribuye el canto gregoriano, u otro de los de ese nombre-, al fundador del Cister San Bernardo de Claraval, a los monjes dominicos Umbertus y Frangipani y al franciscano Tomás de Celano) e incorporado a la liturgia de la misa:

Pero también participa de la misma concepción pesimista del mundo este otro, proveniente de un ambiente totalmente opuesto, recogido en una colección de poemas goliardos (monjes y estudiantes de vida desordenada):
Lo sobrenatural estaba presente en la vida cotidiana de todos como un constante recordatorio de la brevedad de la vida y la inminencia de la muerte, cuyo radical igualitarismo se aplicaba, en contrapunto con la desigualdad de las condiciones, como un cohesionador social, al igual que la promesa de la vida eterna. La imaginación se excitaba con las imágenes más morbosas de lo que ocurriría en el juicio final, los tormentos del infierno y de los méritos que los santos habían obtenido con su vida ascética y sus martirios (que bien administrados por la Iglesia podían ahorrar las penas temporales del purgatorio). Esto no solo operaba en los amedrentados iletrados que únicamente disponían del "evangelio en piedra" de las iglesias; la mayor parte de los lectores cultos daban todo crédito a las escenas truculentas que llenaban los martirologios y a las inverosímiles historias de la "Leyenda Áurea" de Jacopo da Vorágine.

El miedo era inherente a la violencia estructural permanente del feudalismo, que aunque se encauzara por mecanismos aceptables socialmente y estableciera un orden estamental teóricamente perfecto, era un permanente recuerdo de la posibilidad de subversión del orden, periódicamente renovado con guerras, invasiones y sublevaciones internas. En particular, las "sátiras contra el rústico" eran manifestaciones de la mezcla de desprecio y desconfianza con que clérigos y nobles veían al siervo, reducido a un monstruo deforme, ignorante y violento, capaz de las mayores atrocidades, sobre todo cuando se agrupaba.

Pero al mismo tiempo, se sostenía, como parte esencial del edificio ideológico (era la justificación de la elección papal) que la voz del pueblo era la voz de Dios ("Vox populi, vox Dei"). El espíritu medieval debía asumir la contradicción de impulsar manifestaciones públicas de piedad y devoción y al tiempo permitir generosas concesiones al pecado. Los carnavales y otras parodias grotescas (la fiesta del asno o el "charivari") permitían todo tipo de licencias, incluso la blasfemia y la burla a lo sagrado, invirtiendo las jerarquías (se elegían "reyes de los tontos" "obispillos" u "obispos de la fiesta") haciendo triunfar todo lo que el resto del año estaba prohibido, era considerado feo, desagradable o daba miedo, como reacción saludable al terror cotidiano al más allá y garantía de que, pasados los excesos de la fiesta, se volvería dócilmente al trabajo y la obediencia. "Seriedad y tristeza eran prerrogativas de quien practicaba un sagrado optimismo (hay que sufrir pues luego nos aguarda la vida eterna), mientras que la risa era la medicina del que vivía con pesimismo una vida miserable y difícil". Frente al mayor rigorismo del cristianismo primitivo, los teólogos medievales especulaban sobre si Cristo rio o no (la "Epístola de Léntulo", uno de los evangelios apócrifos sostenía que no; mientras que algunos padres de la iglesia defendían el "derecho a una santa alegría"), lo que justificaba textos cómicos eclesiásticos, como la "Coena Cypriani" y la "Joca monachorum".

La "Baja Edad Media" es un término que a veces produce confusión, pues procede de un equívoco etimológico entre alemán y castellano: "baja" no significa "decadente", sino "reciente"; por oposición al "alta" de la "Alta Edad Media", que significa "antigua" (en alemán "alt": viejo, antiguo). No obstante, es cierto que desde alguna perspectiva historiográfica puede verse al conjunto del periodo medieval como el ciclo de nacimiento, desarrollo, auge e inevitable caída de una civilización, modelo interpretativo que inició Gibbon para el Imperio romano (donde es más obvia la oposición entre Alto Imperio y Bajo Imperio) y que se ha aplicado con mayor o menor fortuna a otros contextos históricos y artísticos. Así se entiende que se asigne el nombre de "Plenitud de la Edad Media" al periodo de la Historia de Europa que ocupa los siglos XI al XIII. Esa "Plena Edad Media" o "Plenitud del Medievo" terminaría en la crisis del siglo XIV o crisis de la Edad Media, en la que sí se pueden apreciar procesos decadentes, y es habitual calificarla de "ocaso" u "otoño". No obstante, los últimos siglos medievales están llenos de hechos y procesos dinámicos, con enormes repercusiones y proyecciones en el futuro, aunque lógicamente son los hechos y procesos que pueden entenderse como "nuevos", que prefiguran los nuevos tiempos de la modernidad. Al mismo tiempo, los hechos, procesos, agentes sociales, instituciones y valores caracterizados como medievales han entrado claramente en decadencia; sobreviven, y sobrevivirán por siglos, en buena medida gracias a su "institucionalización" (por ejemplo, el cierre de los estamentos privilegiados o la adopción del mayorazgo), lo que no deja de ser un síntoma de que es entonces, y no antes, que se consideró necesario defenderlos tanto.

La justificación de esa denominación es lo excepcional del desarrollo económico, demográfico, social y cultural de Europa que tiene lugar en ese período, coincidente con un clima muy favorable (se ha hablado del "óptimo medieval") que permitía cultivar vides en Inglaterra. También se ha hablado, en concreto para el siglo XII, de la revolución del siglo XII o renacimiento del siglo XII.

El simbólico año mil (cuyos terrores milenaristas son un mito historiográfico frecuentemente exagerado) no significa nada por sí mismo, pero a partir de entonces se da por terminada la Edad Oscura de las invasiones de la Alta Edad Media: húngaros y normandos están ya asentados e integrados en la cristiandad latina. La Europa de la Plena Edad Media es expansiva también en el terreno militar: las cruzadas en el Próximo Oriente, la dominación angevina de Sicilia y el avance de los reinos cristianos en la península ibérica (desaparecido el Califato de Córdoba) amenazan con reducir el espacio islámico a la ribera sur de la cuenca del Mediterráneo y el interior de Asia.

El modo de producción feudal se desarrolla sin encontrar de momento límites a su extensión (como ocurrirá con la crisis del siglo XIV). La renta feudal se distribuye por los señores fuera del campo, donde se origina: las ciudades y la burguesía crecen con el aumento de la demanda de productos artesanales y del comercio a larga distancia, nacen y se desarrollan las ferias, las rutas comerciales terrestres y marítimas e instituciones como la Hansa. Europa Central y Septentrional entran en el corazón de la civilización Occidental. El Imperio bizantino se mantiene entre el islam y los cruzados, extendida su influencia cultural por los Balcanes y las estepas rusas donde se resiste el empuje mongol.

El arte románico y el primer gótico son protegidos por las órdenes religiosas y el clero secular. Cluny y el Císter llenan Europa de monasterios. El camino de Santiago articula la península ibérica con Europa. Nacen las Universidades (Bolonia, Sorbona, Oxford, Cambridge, Salamanca, Coímbra). La escolástica llega a su cumbre con Tomás de Aquino, tras recibir la influencia de las traducciones del árabe (averroísmo). El redescubrimiento del derecho romano (Bártolo de Sassoferrato, Baldo degli Ubaldi) empieza a influir en los reyes que se ven a sí mismos como "emperadores en su reino".

Los conflictos crecen a la par que la sociedad: herejías, revueltas campesinas y urbanas, la salvaje represión de todas ellas y las no menos salvajes guerras feudales son constantes.

Lejos de ser un sistema social anquilosado (el cierre del acceso a los estamentos es un proceso que se produce como reacción conservadora de los privilegiados, tras la crisis final de la Edad Media, ya en el Antiguo Régimen), el feudalismo medieval demostró suficiente flexibilidad como para permitir el desarrollo de dos procesos, que se retroalimentaron mutuamente favoreciendo una rápida expansión. Por una parte, el asignar un lugar a cada persona dentro del sistema, permitió la expulsión de todos aquellos para quienes no había lugar, enviándolos como colonos y aventureros militares a tierras no ganadas para la Cristiandad Occidental, expandiendo así brutalmente sus límites. Por la otra, el asegurar un cierto orden y estabilidad social para el mundo agrario tras el fin del periodo de las invasiones; aunque ni mucho menos se acabaron las guerras —consustanciales al sistema feudal— el nivel habitual de violencia en periodos bélicos tendía a controlarse por las propias instituciones —código de honor, tregua de Dios, acogimiento a sagrado— y en periodos "normales" tendía a ritualizarse — desafíos, duelos, rieptos, justas, torneos, paso honroso—, aunque no desaparecía ni en las relaciones internacionales ni dentro de los reinos, con unas ciudades que basaban su seguridad y "pax urbana" en sus fuertes murallas, sus toques de queda y su expeditiva justicia, y unos inseguros campos en los que señores de horca y cuchillo imponían sus prerrogativas e incluso abusaban de ellas (malhechores feudales), no sin encontrar la resistencia antiseñorial de los siervos, a veces mitificada (Robin Hood). A diferencia del modo de producción esclavista, el modo de producción feudal ponía en el productor —campesino— la responsabilidad en el aumento de la producción: sea buena o mala la cosecha, debe pagar unas mismas rentas. Es por ello que el sistema por sí solo estimula el trabajo y la incorporación de lo que la experiencia demuestre como buenas prácticas agrícolas, incluso la incorporación de nuevas técnicas que mejoren el rendimiento de la tierra. Si el aumento de la producción es permanente y no coyuntural (una sola buena cosecha por causas climáticas), quien empezará a recibir estímulos será el señor feudal, que detectará ese aumento de los excedentes cuya extracción es la base de su renta feudal (mayor uso del molino, mayor circulación por los caminos y puentes, mayor consumo en tiendas y tabernas; de todos los cuales cobra impuestos o aspirará a hacerlo), incluso se verá impulsado a subir la renta. Cuando lo que ocurre es que los campesinos, empujados por el aumento de sus familias, presionan los límites de los mansos roturando tierras antes incultas (eriales, pastos, bosques, humedales desecables), el señor podrá imponer nuevas condiciones, e incluso impedirlo, porque forman parte de su reserva o de sus usos monopolísticos (caza, alimento de sus caballos).

Esa dinámica "lucha de clases" entre siervos y señores dinamizaba la economía y hacía posible el inicio de una concentración de riquezas acumuladas a partir de las rentas agrícolas; pero nunca de manera comparable a la acumulación de capital propia del capitalismo, pues no se hacía con ellas inversión productiva (como hubiera ocurrido de disponer los campesinos del uso del excedente), sino atesoramiento en manos de nobleza y clero. Tal cosa, en última instancia, a través de los programas de construcción (castillos, monasterios, iglesias, catedrales, palacios) y el gasto suntuario en productos de lujo —caballos, armas sofisticadas, joyas, obras de arte, telas de calidad, tintes, sedas, tapices, especias— no pudo dejar de estimular el rudimentario comercio a larga distancia, la circulación monetaria y la vida urbana; en definitiva, el resurgimiento económico de Europa Occidental. Irónicamente, ambos procesos terminarían por minar las bases del feudalismo, y llevarlo hacia su destrucción. No obstante, no hay que imaginar que se produjo nada parecido a la revolución agrícola previa a la revolución industrial: el hecho de que ni campesinos ni señores pudieran convertir en capital el excedente (unos porque se lo extraían y otros porque su posición social era incompatible con las actividades económicas) hacía lenta y costosa cualquier innovación, además del hecho de que cualquier innovación chocaba con prejuicios ideológicos y una mentalidad fuertemente tradicionalista, ambas cosas propias de la sociedad preindustrial. Solo en el transcurso de siglos, y debido al ensayo y error del buen hacer artesanal de anónimos herreros y talabarteros sin ningún tipo de conexión con la investigación científica, se produjo la incorporación de escasas pero decisivas mejoras técnicas como la collera (que posibilita el aprovechamiento eficaz de la fuerza de los caballos de tiro, que empiezan a sustituir a los bueyes) o el arado de vertedera (que sustituye al arado romano en las tierras húmedas y pesadas del norte de Europa, no así en las secas y ligeras del sur). El barbecho de "año y vez" siguió siendo el método de cultivo más utilizado; la rotación de cultivos era desconocida, el abonado era un recurso excepcional, dada la escasez de animales, cuyo estiércol era el único abono disponible; el regadío estaba limitado a algunas de las zonas mediterráneas de cultura islámica; se escatimaba la utilización de hierro en herramientas y aperos de labranza, dado su coste inasumible por los campesinos; el nivel técnico, en general, era precario. El molino de viento fue una transferencia tecnológica que, como tantas otras en otros campos (pólvora, papel, brújula, grabado), provenía de Asia. Aun con su alcance limitado, el conjunto de innovaciones y cambios se concentró especialmente en un periodo que algunos historiadores han venido en llamar el "Renacimiento" del siglo XII o la Revolución del siglo XII, momento en el que el dinamismo económico y social, a partir del motor principal, que es el campo, produce el despertar de un mundo urbano hasta entonces marginal en Europa Occidental, y el surgimiento de fenómenos intelectuales como la universidad medieval y la escolástica.

Siguiendo el precedente de la organización carolingia de las escuelas palatinas, catedralicias y monásticas (debida a Alcuino de York -787-), más que el de otras instituciones semejantes existentes en el mundo islámico, las primeras universidades de la Europa cristiana fueron fundadas para el estudio del derecho, la medicina y la teología. La parte central de la enseñanza envolvía el estudio de las artes preparatorias (denominadas artes liberales por cuanto eran mentales o espirituales y "liberaban" del trabajo manual propio de las artesanías, consideradas oficios viles y mecánicos); estas artes liberales eran el "trivium" (gramática, retórica y lógica) y el "quadrivium" (aritmética, geometría, música y astronomía). Después, el alumno entraba en contacto con estudios más específicos. Además de centros de enseñanza, eran también el lugar de investigación y producción del saber, y foco de vigorosos debates y polémicas, lo que a veces requirió incluso las intervenciones del poder civil y eclesiástico, a pesar de los fueros de los que estaban dotadas y que las convertían en instituciones independientes, bien dotadas económicamente con una base patrimonial de tierras y edificios. La transformación cultural generada por las universidades ha sido resumida de este modo: "En 1100, la escuela seguía al maestro; en 1200, el maestro seguía a la escuela." Las más prestigiosas recibían el nombre de "Studium Generale", y su fama se extendía por toda Europa, requiriendo la presencia de sus maestros, o al menos la comunicación epistolar, lo que inició un fecundo intercambio intelectual facilitado por el uso común de la lengua culta, el latín.

Entre 1200 y 1400 fueron fundadas en Europa 52 universidades; 29 de ellas de fundación papal, las demás de fundación imperial o real. La primera fue posiblemente Bolonia (especializada en Derecho, 1088), a la que siguió Oxford (antes de 1096), de la que se escindió su rival Cambridge (1209), París, de mediados del siglo XII (uno de cuyos colegios fue La Sorbona, 1275), Salamanca (1218, precedida por el "Estudio General de Palencia" de 1208), Padua (1222), Nápoles (1224), Coímbra (1308, trasladada desde el "Estudio General de Lisboa" de 1290), Alcalá de Henares (1293, refundada por el Cardenal Cisneros en 1499), "La Sapienza" (Roma, 1303), Valladolid (1346), la Universidad Carolina (Praga, 1348), la Universidad Jagellónica (Cracovia, 1363), Viena (1365), Heidelberg (1386), Colonia (1368) y, ya al final del periodo medieval, Lovaina (1425), Barcelona (1450), Basilea (1460) y Upsala (1477). En medicina gozaba de un gran prestigio la Escuela Médica Salernitana, con raíces árabes, que provenía del siglo IX; y en 1220 empezó a rivalizar con ella la Facultad de Medicina de Montpellier.

La escolástica fue la corriente teológico-filosófica dominante del pensamiento medieval, tras la patrística de la Antigüedad tardía, y se basó en la coordinación de fe y razón, que en cualquier caso siempre suponía la clara sumisión de la razón a la fe ("Philosophia ancilla theologiae" -la filosofía es esclava de la teología-). Pero también es un método de trabajo intelectual: todo pensamiento debía someterse al principio de autoridad ("Magister dixit" -lo dijo el Maestro-), y la enseñanza se podía limitar en principio a la repetición o glosa de los textos antiguos, y sobre todo de la Biblia, la principal fuente de conocimiento, pues representa la Revelación divina; a pesar de todo ello, la escolástica incentivó la especulación y el razonamiento, pues suponía someterse a un rígido armazón lógico y una estructura esquemática del discurso que debía exponerse a refutaciones y preparar defensas. Desde el comienzo del siglo IX al fin del XII los debates se centraron en la cuestión de los universales, que opone a los realistas encabezados por Guillermo de Champeaux, a los nominalistas representados por Roscelino y a los conceptualistas (Pedro Abelardo). En el siglo XII tiene lugar la recepción de textos de Aristóteles antes desconocidos en Occidente, primero indirectamente a través de los filósofos judíos y musulmanes, especialmente Avicena y Averroes, pero en seguida directamente traducido del griego al latín por san Alberto Magno y por Guillermo de Moerbeke, secretario de santo Tomás de Aquino, verdadera cumbre del pensamiento medieval y elevado al rango de "Doctor de la Iglesia". El apogeo de la escolástica coincide con el siglo XIII, en que se fundan las universidades y surgen las órdenes mendicantes: dominicos (que siguieron una tendencia aristotélica -los anteriormente citados-) y franciscanos (caracterizados por el platonismo y la tradición patrística -Alejandro de Hales o san Buenaventura-). Ambas órdenes coparán las cátedras y la vida de los colegios universitarios, y de ellas procederán la mayoría de los teólogos y filósofos de la época.

El siglo XIV representará la crisis de la escolástica a través de dos franciscanos británicos: el "doctor subtilis" Duns Scoto y Guillermo de Occam. Precedente de ambos sería la Escuela de Oxford (Robert Grosseteste y Roger Bacon) centrada en el estudio de la naturaleza, defendiendo la posibilidad de una ciencia experimental apoyada en la matemática, contra el tomismo dominante. La polémica de los universales se terminó decantando por los nominalistas, lo que dejaba un espacio a la filosofía más allá de la teología.

La burguesía es el nuevo agente social formado por los artesanos y mercaderes que surgen en el entorno de las ciudades, bien en las antiguas ciudades romanas que habían decaído, bien en nuevos núcleos creados en torno a castillos o cruces de caminos -los propiamente llamados burgos-. Muchas de estas ciudades incorporaron ese nombre - Hamburgo, Magdeburgo, Friburgo, Estrasburgo; en España Burgo de Osma o Burgos-.

La burguesía estaba interesada en presionar al poder político (imperio, papado, las diferentes monarquías, la nobleza feudal local o instituciones eclesiásticas -diócesis o monasterios- de las que dependieran sus ciudades) para que se facilitara la apertura económica de los espacios cerrados de las urbes, se redujeran los tributos de portazgo y se garantizaran formas de comercio seguro y una centralización de la administración de justicia e igualdad de las normas en amplios territorios que les permitieran desarrollar su trabajo, al tiempo que garantías de que los que vulnerasen dichas normas serían castigados con igual dureza en los distintos territorios.

Aquellas ciudades que abrían las puertas al comercio y a una mayor libertad de circulación, veían incrementar la riqueza y prosperidad de sus habitantes y las del señor, por lo que con reticencias pero de manera firme se fue difundiendo el modelo. Las alianzas entre señores eran más comunes, no ya tanto para la guerra, como para permitir el desarrollo económico de sus respectivos territorios, y el rey fue el elemento aglutinador de esas alianzas.

Los burgueses pueden considerarse como "hombres libres" en cuanto estaban parcialmente fuera del sistema feudal, que literalmente los asediaba -se ha comparado a las ciudades con "islas en un océano feudal"-, porque no participaban directamente de las relaciones feudo-vasalláticas: ni eran señores feudales, ni campesinos sometidos a servidumbre, ni hombres de iglesia. La sujeción como súbdito del poder político era semejante a un lazo de vasallaje, pero más bien como "señorío colectivo" que hacía que la ciudad respondiera como un todo a las demandas de apoyo militar y político del rey o del gobernante a la que estuviera vinculada, y que a su vez participara en la explotación feudal del campo circundante (alfoz en España).

La expresión alemana "Stadtluft macht frei" "Los aires de la ciudad dan libertad", o "te hacen libre" (paráfrasis de la frase evangélica "la verdad os hará libres"), indicaba que quienes podían radicarse en las ciudades, a veces huyendo literalmente de la sujeción de la servidumbre. El siervo huido se consideraba libre de retornar con su señor si conseguía domiciliarse en una corporación urbana por un año y un día. tenían todo un nuevo mundo de oportunidades que explotar, aunque no en régimen de libertad, entendida esta en su forma contemporánea. La sujeción a las normas gremiales y a las leyes urbanas podía ser más dura incluso que las del campo: la "pax urbana" significaba la rigidez en la aplicación de la justicia, que mantenía los caminos y las puertas de entrada flanqueados con cadáveres de ajusticiados y un severo toque de queda, con cierre de puertas al anochecer y rondas de vigilancia. Eso sí: concedía a los burgueses la oportunidad de ejercer parcela de poder, incluyendo el uso de las armas en la milicia urbana (como las hermandades castellanas que se unificaron en la Santa Hermandad ya en el siglo XV), que en no pocas ocasiones se utilizaron en contra de las huestes feudales, con el beneplácito de las emergentes monarquías autoritarias. En el caso más precoz y espectacular fueron las comunas italianas, que se independizaron de hecho del Sacro Imperio Romano Germánico a partir de la batalla de Legnano (1176).

En los burgos surgieron muchas instituciones sociales nuevas. El desarrollo del comercio llevó aparejado consigo el del sistema financiero y la contabilidad. Los artesanos se unieron en asociaciones llamadas gremios, ligas, corporaciones, cofradías, o artes, según el lugar geográfico. El funcionamiento interno de los talleres gremiales implicaba un aprendizaje de varios años del aprendiz a cargo de un maestro (el dueño del taller), que implicaba el paso de aquel a la condición de oficial cuando demostrara conocer el oficio, lo que implicaba su consideración como trabajador asalariado, una condición de por sí ajena al mundo feudal que incluso se trasladó al campo (en principio de manera marginal) con los jornaleros que no disponían de tierras propias ni concedidas por el señor. La asociación de los talleres en los gremios, funcionaba de manera completamente contraria al mercado libre capitalista: se procuraba evitar todo rasgo posible de competencia fijando los precios, las calidades, los horarios y condiciones de trabajo, e incluso las calles donde podían radicarse. La apertura de nuevos talleres y el paso del rango de oficial al de maestro estaban muy restringidos, de modo que en la práctica se incentivaban las herencias y los enlaces matrimoniales endogámicos dentro del gremio. El objetivo era conseguir la supervivencia de todos, no el éxito del mejor.

Más apertura demostró el comercio. Los buhoneros que iban de aldea en aldea, y los escasos aventureros que se atrevían a hacer viajes más largos eran los mercaderes más habituales de la Alta Edad Media, antes del año 1000. En tres siglos, para comienzos del siglo XIV, las ferias de Champaña y de Medina habían creado rutas terrestres estables y más o menos seguras que (a lomos de mulas o con carretas en el mejor de los casos) recorrían Europa de norte a sur (en el caso castellano siguiendo las cañadas trashumantes de la Mesta, en el caso francés enlazando los emporios flamenco y norte-italiano a través de las prósperas regiones borgoñonas y renanas, todas ellas salpicadas de ciudades). La "Hansa" o liga hanseática estableció a su vez rutas marítimas de una estabilidad y seguridad similar (con mayor capacidad de carga, en barcos de tecnología innovadora) que unían el Báltico y el mar del Norte a través de los estrechos escandinavos, conectando territorios tan lejanos como Rusia y Flandes y rutas fluviales que conectaban todo el norte de Europa (ríos como el Rin y el Vístula), permitiendo el desarrollo de ciudades como Hamburgo, Lübeck y Danzing, y estableciendo consulados comerciales denominados "kontor". En el Mediterráneo se llamaron Consulado del Mar: el primero en Trani en 1063 y luego Pisa, Mesina, Chipre, Constantinopla, Venecia, Montpellier, Valencia (1283), Mallorca (1343) y Barcelona (1347). Cuando el estrecho de Gibraltar fue seguro, se pudieron conectar marítimamente ambas Europas, con rutas entre las ciudades italianas (sobre todo Génova), Marsella, Barcelona, Valencia, Sevilla, Lisboa, los puertos del Cantábrico (Santander, Laredo, Bilbao), los del Atlántico francés y los del canal de la Mancha (ingleses y flamencos, sobre todo Brujas y Amberes). El contacto cada vez más fluido de gentes de distintas "naciones" (como comenzaron a llamarse a las agrupaciones de comerciantes de cercano origen geográfico que se entendían en la misma lengua vulgar, al igual que ocurría en las secciones de las órdenes militares) terminó produciendo que ambas instituciones funcionaran de hecho, como primitivas "organizaciones internacionales".

Todo ello desarrolló un incipiente capitalismo comercial ("véase también Historia del capitalismo") con el incremento o surgimiento "ex novo" de la economía monetaria, la banca (crédito, préstamos, seguros, letras de cambio), actividades que mantuvieron siempre recelos morales (pecado de usura para todas las que significara lucro indebido, y en que únicamente podían incurrir los judíos cuando prestaban a otros que no fueran de su religión, oficio prohibido tanto a los cristianos como a los musulmanes). La aparición de burgueses ricos y de una plebe urbana pobre originó un nuevo tipo de tensiones sociales, que produjeron revueltas urbanas. En cuanto a los aspectos ideológicos, la expresión del inconformismo burgués con su puesto marginal en la sociedad feudal está en el origen de las herejías a lo largo de toda la Baja Edad Media (cátaros, valdenses, albigenses, dulcinianos, hussitas, wycliffianos). Los intentos de responder a esas demandas del mundo urbano por parte de la Iglesia, así como de controlarlas y en su caso reprimirlas, produjeron la aparición de las órdenes mendicantes (franciscanos y dominicos) y de la Inquisición. A veces, la imposibilidad de conseguir el control hizo optar por el exterminio, como ocurrió en Beziers en 1209, siguiendo la respuesta del legado pontificio Arnaud Amaury:

En la Plena Edad Media se observó una gran disparidad en la escala a que se ejercía el poder político: los poderes universales (Pontificado e Imperio) seguían reivindicando su primacía frente a las Monarquías feudales, que en la práctica funcionaban como estados independientes. Al mismo tiempo, entidades mucho más pequeñas en extensión demostraban ser muy dinámicas en las relaciones internacionales (las ciudades-estado italianas y las ciudades libres del Imperio Germánico), y el municipalismo demostró ser una fuerza muy a tener en cuenta en todos los territorios de Europa.

El redescubrimiento del Digesto justinianeo ("Digestum Vetus") permitió el estudio autónomo del Derecho (Pepo e Irnerio) y el surgimiento de la Escuela de los Glosadores y de la Universidad de Bolonia (1088). Ese suceso, que permitirá el redescubrimiento paulatino del Derecho romano, llevará a la formación del llamado "Corpus Iuris Civilis" y a la posibilidad de plantear un "Ius commune" (Derecho común), y justificar la concentración de poder y capacidad reglamentaria en la institución imperial, o en los monarcas, cada uno de los cuales empezará a considerarse como "imperator in regno suo" ("emperador en su reino" -definiciones de Bártolo de Sassoferrato y Baldo degli Ubaldi-).
La difícil convivencia de Pontificado e Imperio ("regnum et sacerdocium") a lo largo de los siglos dio origen entre 1073 y 1122 a la querella de las investiduras. Distintas formulaciones ideológicas (teoría de las dos espadas, "Plenitudo potestatis", "Dictatus papae", condenas de la simonía y el nicolaísmo) constituían un edificio levantado durante siglos por el que el Papa pretendía marcar la supremacía de la autoridad religiosa sobre el poder civil (lo que se ha venido denominando agustinismo político), mientras que el Emperador pretendía hacer valer la legitimidad de su cargo, que pretendía derivar del antiguo Imperio romano ("Translatio imperii"), así como el hecho material de su capacidad militar para imponer su poder territorial e incluso tutelar la vida religiosa (tanto en los aspectos institucionales como los dogmáticos), a semejanza de su equivalente en Oriente. El acceso de distintas dinastías a la dignidad imperial debilitó el poder de los emperadores, sujetos a un sistema de elección que les hacía dependientes de un delicado juego de alianzas entre los dignatarios que alcanzaron el título de príncipe elector, unos laicos (príncipes territoriales, independientes en la práctica) y otros eclesiásticos (obispos de ciudades libres). No obstante, periódicamente se asistía a intentos de recuperar el poder imperial (Otón III y Enrique II entre los últimos otónidas), que en ocasiones llegaban a enfrentamientos espectaculares (Enrique IV, de la dinastía salia, o Federico I Barbarroja y Federico II de la dinastía Hohenstaufen). La oposición entre güelfos y gibelinos, cada uno asociado a uno de los poderes en liza (papa y emperador), presidió la vida política de Alemania e Italia desde el siglo XII hasta bien entrada la Baja Edad Media.

Ambas pretensiones distaron mucho de hacerse efectivas, agotadas en su propio debate y superadas por la mayor eficacia política de las entidades urbanas y los reinos del resto de Europa.

Apareció el parlamentarismo, una forma de representación política que con el tiempo se convirtió en el precedente de la división de poderes consustancial a la democracia de la Edad Contemporánea. La primacía en el tiempo la tiene el "Alþingi" islandés (930), que seguía el modelo de los thing o asambleas de guerreros germanos; pero desde finales del siglo XI se fue gestando un nuevo modelo institucional, derivado de la obligación feudal de "consilium", que implicaba a los tres órdenes feudales, y se generalizó por Europa occidental: las Cortes de León (1188), el Parlamento inglés (1258) -previamente las relaciones de poder entre rey y nobleza habían sido reguladas en la Carta EMagna, 1215, o las Provisiones de Oxford, 1258- y los Estados Generales franceses (1302).

Hildebrando de Toscana, ya desde su posición bajo los pontificados de León IX y Nicolás II, y más tarde como papa Gregorio VII (con lo que cubre toda la segunda mitad del siglo XI), emprendió un programa de centralización de la Iglesia, con la ayuda de los benedictinos de Cluny, que se extendieron por toda Europa Occidental implicando a las monarquías feudales (destacadamente en los reinos cristianos peninsulares, a través del Camino de Santiago).

Las siguientes reformas monásticas, como la cartuja (San Bruno) y sobre todo la cisterciense (San Bernardo de Claraval) significarán nuevos fortalecimientos de la jerarquía eclesiástica y su implantación dispersa en todo el territorio europeo como una impresionante fuerza social y económica ligada a las estructuras feudales, vinculada a las familias nobles y a las dinastías regias y con una base de riqueza territorial e inmobiliaria, a la que se añadía el cobro de los derechos propios de la Iglesia (diezmos, primicias, derechos de estola, y otras cargas locales, como el voto de Santiago en el noroeste de España).

El fortalecimiento del poder papal intensificó las tensiones políticas e ideológicas con el Imperio Germánico y con la Iglesia oriental, que en este caso terminarán llevando al Cisma de Oriente.

Las Cruzadas trajeron como consecuencia la creación de un tipo especial de órdenes religiosas, que, además de someterse a una regla monástica (habitualmente la cisterciense, incluyendo el cumplimiento teórico de los votos monásticos) exigían a sus componentes una vida castrense más que ascética: fueron las órdenes militares, fundadas tras la toma de Jerusalén en 1099 (caballeros del Santo Sepulcro, templarios -1104- y hospitalarios -1118-). También se constituyeron en otros contextos geográficos (órdenes militares españolas y caballeros teutónicos).

La adaptación a la pujante vida urbana de los siglos XII y XIII será misión de un nuevo ciclo de fundaciones en el clero regular: las órdenes mendicantes, cuyos miembros no eran monjes, sino frailes (franciscanos de San Francisco de Asís y dominicos de Santo Domingo de Guzmán, a las que siguieron otras, como los agustinos); y de nuevas instituciones: las Universidades y la Inquisición.

A partir del siglo XI y el siglo XII, se introdujeron en el cristianismo latino innovaciones dogmáticas y devocionales de gran trascendencia:

La imposición del rito romano frente a la anterior multiplicidad de liturgias (rito hispánico, rito bracarense, rito ambrosiano, etc.)

La imposición del celibato sacerdotal en el Concilio de Letrán (1123).

El hallazgo del papel del purgatorio como estadio intermedio de las almas entre cielo e infierno, que intensificará la función intermediadora de la Iglesia a través de las oraciones y misas y los méritos de la "Comunión de los Santos" por ella administrados.

La intensificación del papel de la Virgen María, que pasa a ser una corredentora con atributos investigados por la mariología y aún no dogmatizados (Inmaculada Concepción, Asunción de la Virgen), con nuevas devociones y oraciones (Avemaría -yuxtaposición de textos evangélicos que se introduce en occidente en el siglo XI-, Salve -adoptada por Cluny en 1135-, Rosario -introducido por Santo Domingo contra los albigenses-), una fiebre de fundaciones de iglesias en su nombre, y con un amplísimo tratamiento artístico. En la época del amor cortés "la devoción a la Virgen apenas podía distinguirse, al menos en las formas, de la que el caballero sentía por su dama".

La mariología había nacido en la Antigüedad tardía con la patrística, y el culto popular de la virgen fue uno de los factores clave de la suave transición del paganismo al cristianismo, que suele interpretarse como una adaptación del patriarcal monoteísmo del judaísmo al matriarcal panteón de las diosas-vírgenes-madre del Mediterráneo clásico: "la cananea Astarté, la babilonia Istar, las griegas Rea y Gaia, la frigia Cibeles, la Artemisa de Éfeso, la Deméter de Eleusis, la egipcia Isis, etc.", si bien "hay dos diferencias fundamentales entre el culto cristiano a María y los cultos paganos: la clara conciencia de la absoluta trascendencia de Dios, que opera como factor que elimina cualquier tendencia idolátrica y la oposición por parte del cristianismo a una divinización de la vida que ponga en peligro el carácter absolutamente libre de la decisión creadora de Dios". La controversia "Cristotokos-Theotokos" (María como "Madre de Cristo" o "Madre de Dios"), y el amplio tratamiento de esta en el arte bizantino habían caracterizado a la iglesia oriental. El protagonismo de la Virgen quedaba ampliamente compensado con la misoginia del tratamiento de otras figuras femeninas, destacadamente Eva, la Magdalena y Santa María Egipcíaca. La renuncia al cuerpo (la "carne" enemiga del alma) y a las riquezas, que da oportunidad al arrepentimiento y la redención (y confía su gestión a la "Madre" Iglesia) solía ser el aspecto más destacable también en las vidas de otras santas y mártires.

Por último, la institucionalización de los sacramentos, especialmente la penitencia y la comunión pascual que se plantean como trámites anuales que el fiel ha de cumplir ante su párroco y confesor. La vivencia comunitaria de los sacramentos, sobre todo los que significan cambios vitales (bautismo, matrimonio, extrema unción), y los rituales funerarios, cohesionaban fuertemente a las sociedades locales tanto aldeanas como urbanas, sobre todo cuando se enfrentaban a la convivencia con otras comunidades religiosas -judíos en toda Europa y musulmanes en España-.

La celebración de las festividades en días distintos (viernes los musulmanes, sábados los judíos, domingos los cristianos), los distintos tabúes alimentarios (cerdo, alcohol, rituales de matanza que obligan a separar las carnicerías) y la separación física de las comunidades -guetos, aljamas o juderías y morerías- planteaban una situación que, incluso con tolerancia religiosa, distaba mucho de ser un trato igualitario. Los judíos cumplieron una función social de chivo expiatorio que dio salida a las tensiones sociales en determinados momentos, con el estallido de pogromos (revueltas antijudías, que tras la conversiones masivas dieron paso a revueltas anticonversas) o con las políticas de expulsión (Inglaterra -1290-, Francia -1394- y España -1492- y Portugal en 1496). La existencia de minorías religiosas dentro del cristianismo, en cambio, no podía ser aceptada, puesto que la comunidad política se identificaba con la unidad en la fe. Los definidos como herejes, por tanto, eran perseguidos por todos los medios.

En cuanto a las desviaciones del comportamiento que no supusieran desafíos de opinión sino delitos o pecados (conceptos identificables y de imposible deslindamiento), su tratamiento era objeto de las jurisdicciones civil (que aplicaba el fuero correspondiente, la legislación del reino o el derecho común) y religiosa (que aplicaba el Derecho Canónico en cuestiones ordinarias, o el procedimiento inquisitorial en caso necesario), cuya coordinación era a veces compleja, como ocurría con las desviaciones de la conducta sexual considerada correcta (masturbación, homosexualidad, incesto, estupro, amancebamiento, adulterio y otros asuntos matrimoniales). En cualquier caso, la vivencia de la sexualidad y la desnudez del cuerpo tuvo tratamientos muy distintos en cada época y lugar; y diferentes expectativas para cada nivel social (se consideraba que era propio de los campesinos un comportamiento "animal", es decir, natural, y se pretendía que los nobles y clérigos tuvieran más voluntad para controlar sus instintos).

También costumbres como los baños (conocidos desde las termas romanas y reintroducidos por los árabes) y prácticas como la prostitución fueron objeto de críticas morales y reglamentaciones más o menos permisivas, llegando en el caso de los baños progresivamente hasta la prohibición (se les acusaba de inmorales y de producir el "afeminamiento" de los guerreros), y en el de la prostitución al confinamiento en determinados barrios, la obligación de llevar determinadas prendas y la detención de sus actividades en determinadas fechas (Semana Santa). La erradicación de la prostitución no se concebía posible, dado lo inevitable del pecado, y su papel de mal menor que evitaba que el deseo irrefrenable de los varones fuera en contra del honor de las doncellas y las mujeres "respetables". Por lo general, los historiadores suelen coincidir que el periodo de la Plena Edad Media fue una etapa de mayor libertad de costumbres que no tuvo que esperar a "El Decamerón" (1348), y que en algunas cuestiones, como la condición femenina, significó una verdadera promoción, tanto frente a la Alta Edad Media como frente a la Edad Moderna; aunque el extendido mito de que se llegara a dudar si la mujer tenía alma es un error filológico.

La expansión geográfica se llevó a cabo, o se intentó llevar a cabo, al menos, en varias direcciones, siguiendo no tanto un propósito determinado por concepciones nacionalistas inexistentes en la época, sino la dinámica propia de las casas feudales. Los normandos, vikingos asentados en Normandía, dieron origen a una de las casas feudales más expansivas de Europa, que se extendió por Francia, Inglaterra e Italia, enlazada con las de Anjou-Plantagenet y Aquitania. Las casas de Navarra y Castilla (dinastía Jimena), Francia, Borgoña y Flandes (Capetos, Casa de Borgoña -extendida por la península ibérica-, Valois) y Austria (casa de Habsburgo) son otros buenos ejemplos, y todas ellas se vieron vinculadas por alianzas, enlaces matrimoniales y enfrentamientos sucesorios o territoriales, consustanciales a las relaciones feudo-vasalláticas y expresión de la violencia inherente al feudalismo. En el contexto espacial de la Europa Nórdica y Centro-Oriental tuvieron un desarrollo similar la Casa de Sweyn Estridsson danesa, la Bjälbo noruega y los Sverker y Erik suecos; y más tarde la Dinastía Jogalia o Jagellón (Hungría, Bohemia, Polonia y Lituania).

En España, simultáneamente a la disolución del Califato de Córdoba (en guerra civil desde el 1010 y extinguido el 1031), se creó un vacío de poder que los reinos feudales cristianohispánicos de Castilla, León, Navarra, Portugal y Aragón (fusionado dinásticamente con el condado de Barcelona) intentaron aprovechar, expandiéndose frente a los reinos de taifas musulmanes en la llamada Reconquista. En las islas británicas, el reino de Inglaterra intentó repetidas veces invadir a Gales, Escocia e Irlanda, con mayor o menor éxito.
En Europa del Norte, acabadas las invasiones de los vikingos, las riquezas saqueadas por estos sirvieron para adquirir productos y servicios occidentales, creando en el mar Báltico una próspera red comercial que atrajo a los escandinavos a la civilización occidental, mientras su expansión hacia el oeste por el Atlántico (Islandia y Groenlandia) no pasó de la mítica Vinlandia (asentamiento fracasado en América del Norte, en torno al año 1000). Los vikingos orientales, (varegos), fundaron numerosos reinos en la Rusia europea y llegaron hasta Constantinopla. Los vikingos occidentales (normandos) se instalaron en Normandía, Inglaterra, Sicilia y el sur de la actual Italia, creando reinos centralizados y eficientes (Rolón, Guillermo el Conquistador y Roger I de Sicilia). En el este, en el año 955, Otón el Grande batió a los magiares en la batalla del Río Lech y reincorporó Hungría a Occidente, al tiempo que comenzaba la "germanización" de Polonia, hasta entonces pagana. Posteriormente, desde tiempos de Enrique el León (siglo XII), los alemanes se fueron abriendo paso a través de las tierras de los vendos, hasta el mar Báltico, en un proceso de colonización conocido como "Ostsiedlung" (que será mitificado posteriormente con el romántico nombre de "Drang nach Osten", o "Afán de ir hacia el Este", lo que sirvió para justificar la teoría nazi del espacio vital alemán "Lebensraum"). Pero sin lugar a dudas, el movimiento de expansión más espectacular, aunque finalmente fallido, fueron las Cruzadas, en donde selectos miembros de la nobleza guerrera occidental cruzaron el mar Mediterráneo e invadieron el Medio Oriente, creando reinos de efímera duración.

Las Cruzadas fueron expediciones emprendidas, en cumplimiento de un solemne voto, para liberar Tierra Santa de la dominación musulmana. El origen de la palabra remonta a la cruz hecha de tela y usada como insignia en la ropa exterior de los que tomaron parte en esas iniciativas, a partir de la petición del Papa Urbano II y las predicaciones de Pedro el Ermitaño. Las sucesivas cruzadas tuvieron lugar entre los siglos XI y XIII. Fueron motivadas por los intereses expansionistas de la nobleza feudal, el control del comercio con Asia y el afán hegemónico del papado sobre las iglesias de Oriente.

El balance de esta expansión fue espectacular, por comparación a la vulnerabilidad de la oscura época anterior: Tras medio siglo de instituciones carolingias, hacia 843 (Tratado de Verdún), los territorios que podían identificarse más o menos próximamente con ellas (lo que podría denominarse una formación social cristiano occidental) se extendían por Francia, el oeste y sur de Alemania, el sur de Gran Bretaña, las montañas septentrionales de España y el norte de Italia. Un siglo después, en la época de la batalla del Río Lech (955), no había región de Europa Occidental a salvo de las nuevas oleadas de invasores bárbaros, que parecían conducir a una nueva crisis de civilización.

Sin embargo, en los dos siglos siguientes al fatídico año mil el panorama había cambiado completamente: para la época de la batalla de Navas de Tolosa (1212), habían sido incorporadas a la civilización europea toda Italia hasta Sicilia, la Gran Bretaña no inglesa (Escocia y Gales), Escandinavia (que se expandía por el Atlántico Norte hasta Groenlandia), buena parte de Europa Oriental (Polonia, Bohemia, Moravia y Hungría, quedando los pueblos eslavos de los Balcanes y Rusia en la órbita del cristianismo oriental e institucionalizando sus propios reinos) y media península ibérica (en el transcurso del siglo XIII lo sería toda excepto el tributario reino nazarí de Granada, quedando marcado definitivamente el predominio cristiano sobre el estrecho de Gibraltar con la batalla del Salado -1340-). Otros territorios periféricos (como Lituania o Irlanda) estaban sometidos a una presión militar cada vez mayor por parte de los reinos centrales de la cristiandad latina. Más allá de los límites de Europa Occidental, las incursiones militares de huestes "latinas" de muy variada composición habían puesto en sus manos lugares tan lejanos como Constantinopla y los ducados Atenas y de Neopatria o Jerusalén y los Estados Cruzados.

El símil astronómico de "ocaso", que Johan Huizinga convierte en "otoño", es utilizado con mucha frecuencia en la historiografía, con un valor analógico que más que una decadencia en lo económico o lo intelectual refleja un claro agotamiento de los rasgos específicamente "medievales" frente a sus sustitutos "modernos".

El final de la Edad Media llega con el comienzo de la transición del feudalismo al capitalismo, otro periodo secular de transición entre modos de producción que no finalizará hasta el final del Antiguo Régimen y el comienzo de la Edad Contemporánea, con lo que tanto este último periodo medieval como la Edad Moderna entera cumplen un papel similar y cubren una similar extensión temporal (500 años) a lo que significó la Antigüedad Tardía para el comienzo de la Edad Media.

La ley de rendimientos decrecientes empezó a mostrar sus efectos a medida que el dinamismo de los campesinos forzó la roturación de tierras marginales y las lentas mejoras técnicas no podían sucederse a un ritmo semejante. La coyuntura climática cambió, acabando con el denominado óptimo medieval que permitió la colonización de Groenlandia y el cultivo de vides en Inglaterra. Las malas cosechas condujeron a hambrunas que debilitaron físicamente a las poblaciones, preparando el terreno para que la Peste negra de 1348 fuera una catástrofe demográfica en Europa. La repetición sucesiva de epidemias caracterizó un ciclo secular.

Las consecuencias no fueron negativas para todos. Los supervivientes acumularon inesperadamente capital en forma de herencias, que pudo en algunos casos invertirse en empresas comerciales, o acumularon inesperadamente patrimonios nobiliarios. Las alteraciones de los precios de mercado de los productos, sometidos a tensiones nunca vistas de oferta y demanda cambió la forma de percibir las relaciones económicas: los salarios (un concepto, como el de circulación monetaria ya de por sí disolvente de la economía tradicional) crecían al tiempo que las rentas feudales pasaron a ser inseguras, obligando a los señores a decisiones difíciles. Alternativamente primero tendieron a ser más comprensivos con sus siervos, que a veces estuvieron en situación de imponer una nueva relación, liberados de la servidumbre; mientras que en un segundo momento, sobre todo tras algunas rebeliones campesinas fracasadas y duramente reprimidas, impusieron en algunas zonas una nueva refeudalización, o cambios de estrategia productiva como el paso de la agricultura a la ganadería (expansión de la Mesta).

El negocio lanero produjo curiosas alianzas internacionales e interestamentales (señores ganaderos, mercaderes de la lana, artesanos de paños) que suscitaron verdaderas guerras comerciales (en ese sentido se ha podido interpretar las cambiantes alianzas y divisiones internas Inglaterra-Francia-Flandes durante la guerra de los Cien Años, en la que Castilla se implicó en su propia guerra civil). Únicamente los nobles con más capacidad (demostrada la mayor parte de las veces por el despojo de nobles con menos capacidad) pudieron convertirse en una gran nobleza o aristocracia de grandes casas nobiliarias, mientras que la pequeña nobleza se empobrecía, reducida a la mera supervivencia o a la búsqueda de nuevos tipos de ingresos en la creciente administración de las monarquías, o a los tradicionales de la Iglesia.

En las instituciones del clero también se va abriendo un abismo entre el alto clero de obispos, canónigos y abades y los curas de parroquias pobres; y el bajo clero de frailes o clérigos vagabundos, de opiniones teológicas difusas, o bien supervivientes materialistas en la práctica, goliardos o estudiantes sin oficio ni beneficio.

En las ciudades, la alta burguesía y la baja burguesía viven un similar proceso de separación de fortunas, que hace imposible mantener que un aprendiz o incluso un oficial o un maestro de taller pobre tenga algo que ver con un mercader enriquecido por el comercio a larga distancia de la Hansa o las ferias de Champaña y de Medina, o un médico o un letrado salidos de la universidad para entrar en la alta sociedad. Se va abriendo paso la posibilidad (antes inaudita) de que la condición social dependa más de la capacidad económica (no necesariamente ligada siempre a la tierra) que del origen familiar.

Frente al mundo medieval de los tres órdenes, basado en una economía agraria y firmemente ligada a la posesión de la tierra, emerge un mundo de ciudades basado en una economía comercial. Los centros de poder se desplazan hacia los nuevos burgos. Estos reequilibrios se vieron reflejados en los campos de batalla, ya que los caballeros feudales empezaron a ser superados por el desarrollo de técnicas militares como el arco de tiro largo, arma que los ingleses usaron para barrer a los franceses en la batalla de Agincourt, en 1415, o la pica, usada por la infantería de mercenarios suizos. Es en esta época cuando aparecen los primeros ejércitos profesionales, compuestos por soldados a los que no les une un pacto de vasallaje con su señor sino la paga. A partir del siglo XIII se registran en Occidente los primeros usos de la de pólvora, invención china extendida desde la India por los árabes, pero de forma muy discontinua. Roger Bacon la describe en 1216) y hay relatos del uso de armas de fuego en la defensa musulmana de Sevilla (1248) y Niebla (1262, "véase El cañón en la Edad Media"). Con el tiempo, el oficio militar se "envilece", devaluando las funciones de la nobleza con las de la caballería y los castillos, que quedan obsoletos. El aumento de los costes y las tácticas de batallas y asedios traerá como consecuencia el aumento del poder del rey frente a la aristocracia. La guerra pasa a depender no de las huestes feudales, sino de los crecientes impuestos, pagados por los no privilegiados.

Las nuevas ideas religiosas -que se adaptan mejor a la forma de vida de la burguesía que a la de los privilegiados- ya estuvieron en el fermento de las herejías que se habían producido previamente, a partir del siglo XII (cátaros, valdenses), y que habían encontrado eficaz respuesta en las nuevas órdenes religiosas mendicantes, insertas en el entorno urbano; pero en los últimos siglos medievales el husismo o el wycliffismo tienen una mayor proyección hacia lo que será la Reforma protestante del siglo XVI. El milenarismo de los flagelantes convivía con el misticismo de un Tomás de Kempis y con los desórdenes y corrupción de costumbres en la Iglesia que culminaron en el Cisma de Occidente. Fue devastador el impacto que tuvo en la cristiandad occidental el espectáculo de dos (y hasta tres) papas excomulgándose mutuamente (y a emperadores, reyes y obispos, y con ellos a todos sus sacerdotes y fieles), uno en la llamada "cautividad de Aviñón" a la que le sometía el rey de Francia ("fille ainée de l'Eglise" -hija mayor de la Iglesia-), otro en Roma y un tercero elegido por el Concilio de Pisa (1409). La situación no se recondujo totalmente ni siquiera con el Concilio de Constanza (1413), que si hubieran prosperado las tesis "conciliaristas" se habría convertido en una especie de parlamento europeo supranacional, cuasi-soberano y competente en toda clase de temas. Hasta la humilde Peñíscola se llegó a convertir por algún tiempo en el centro del mundo cristiano -para los escasos seguidores del Papa Luna-.

Los intentos de imprimir mayor racionalidad al catolicismo ya venían estando presentes desde la cumbre de la escolástica de los siglos XII y XIII con Pedro Abelardo, Tomás de Aquino o Roger Bacon; pero ahora esa escolástica se enfrenta a su propia crisis y cuestionamiento interno, con Guillermo de Ockham o Duns Scoto. La mentalidad teocéntrica iba lentamente dando paso a una nueva antropocéntrica, en un proceso que culminará con el humanismo del siglo XV, en lo que ya puede denominarse Edad Moderna. Ese cambio no se limitó únicamente a las élites intelectuales: personalidades extravagantes, como Juana de Arco, se convierten en héroes populares (con el contrapunto de otras terribles, como Gilles de Rais -Barba Azul-); la mentalidad social va alejándose del conformismo temeroso para acoger otras concepciones que implican una nueva forma de afrontar el futuro y las novedades:

El anonimato conscientemente buscado en el que vivieron silenciosamente generaciones durante siglos

y que seguirá siendo la situación de los humildes durante los siglos siguientes, da paso a la búsqueda de la fama y de la gloria personal, no solo entre los nobles, sino en todos los ámbitos sociales: los artesanos comienzan a firmar sus productos (desde las obras de arte a las marcas artesanas), y cada vez es menos excepcional que cualquier acto de la vida deje su huella documental (libros parroquiales, registros mercantiles, escribanos, protocolos notariales, actos jurídicos).

El desafío al monopolio económico, social, político e intelectual de los privilegiados, creaba lentamente nuevos espacios de poder en beneficio de los reyes, así como un lugar cada vez más amplio para la burguesía. Aunque la mayor parte de la población siguió siendo campesina, lo cierto es que el impulso y las novedades ya no provenían del castillo o el monasterio, sino de la Corte y la ciudad. Entre tanto, el amor cortés (procedente de la Provenza del siglo XI) y el ideal caballeresco se revitalizaron y pasaron a convertirse en una ideología justificativa del modo de vida nobiliario justo cuando este empezaba a estar en cuestión, viviendo una época dorada, obviamente decadente, localizada en el período de esplendor del ducado de Borgoña, que reflejó Johan Huizinga en su magistral "El otoño de la Edad Media".

Mientras que para el Mediterráneo Oriental el fin de la Edad Media supuso el avance imparable del islámico Imperio otomano, en el extremo occidental, los expansivos reinos cristianos de la península ibérica, tras un periodo de crisis y ralentización del avance secular hacia el sur, simplificaron el mapa político con la unión matrimonial de los Reyes Católicos (Fernando II de Aragón e Isabel I de Castilla), los acuerdos de estos con el de Portugal (Tratado de Alcáçovas, que suponían el reparto de influencias sobre el Atlántico) y la conquista de Granada. Navarra, dividida en una guerra civil entre bandos orientados e intervenidos por franceses y aragoneses, sería anexionada en su mayor parte a la creciente Monarquía Católica en 1512.









</doc>
<doc id="1142" url="https://es.wikipedia.org/wiki?curid=1142" title="Emulador">
Emulador

En informática, un emulador es un "software" que permite ejecutar programas o videojuegos en una plataforma (sea una arquitectura de "hardware" o un sistema operativo) diferente de aquella para la cual fueron escritos originalmente. A diferencia de un simulador, que solo trata de reproducir el comportamiento del programa, un emulador trata de modelar de forma precisa el dispositivo de manera que este funcione como si estuviese siendo usado en el aparato original.

Un uso popular de los emuladores es el de imitar la experiencia de los videojuegos de máquinas recreativas o videoconsolas en computadoras personales, o el poder ser jugados en otras videoconsolas. La emulación de videojuegos de sistemas antiguos ("abandonware") en las modernas computadoras personales y videoconsolas de hoy día resulta generalmente más cómoda y práctico que en los dispositivos originales. Sin embargo, puede ser requerido a los creadores de emuladores una licencia de "software" para escribir programas originales que dupliquen la funcionabilidad de la ROM y BIOS del hardware original, lo que comúnmente se conoce como "high-level emulation" o "emulación de alto nivel".

Otro uso común es el de emular sistemas operativos obsoletos, o vigentes para otra máquina o dispositivo, para utilizar programas compatibles con estos sistemas operativos.

En sentido teórico, la tesis de Church-Turing implica que cualquier ambiente funcional puede ser emulado dentro de cualquier otro. En la práctica, esto puede resultar realmente difícil, particularmente cuando el comportamiento exacto del sistema emulado no está documentado y debe ser deducido mediante ingeniería inversa. Tampoco se habla en la tesis sobre las diferencias en sincronización; si el emulador no actúa tan rápidamente como el hardware original, el software de emulación va a ir más lento que si fuese el hardware original.

La mayoría de los emuladores solo emulan una determinada configuración arquitectura de hardware - si el sistema de explotación ( o sistema operativo) también se requiere para emular cierto programa entonces ha de ser emulado también. Tanto el sistema de explotación como el programa deben ser interpretados por el emulador, como si estuviese ejecutándose en el equipo original. Aparte de la interpretación del lenguaje de la máquina emulada, es preciso emular el resto del equipo, como los dispositivos de entrada y salida, de forma virtual: si escribir en una región específica de la memoria debe influir en el contenido en pantalla, por ejemplo, esto también debe ser emulado.

En vez de una emulación completa del equipo, una compatibilidad superficial puede ser suficiente. Esto traduce las llamadas del sistema emulado a llamadas del sistema anfitrión.

Los desarrolladores de programas para máquinas con sistemas computarizados y consolas de videojuego comúnmente utilizan emuladores especialmente exactos llamados simuladores antes de ejecutarlos en el equipo real. Esto permite que el programa pueda ser producido y probado antes de que la versión final del equipo para el cual se está desarrollando sea producida en grandes cantidades, de esta forma puede ser probado sin tener que copiar el programa en el equipo, de modo que puedan ser eliminados errores en un nivel bajo sin tener los efectos colaterales de un depurador.

Típicamente, un emulador se divide en módulos que corresponden de forma precisa a los subsistemas del equipo emulado. Lo más común, es que un emulador este compuesto por los siguientes módulos:


Lo más común es que los buses no sean emulados, por razones de simplicidad y rendimiento, y para que los periféricos virtuales se comuniquen directamente con la UCP y los subsistemas de memoria.

El simulador de la unidad central de procesamiento (CPU) es a menudo la parte más compleja de un emulador. Muchos emuladores son escritos utilizando simuladores de CPU "preempaquetados", para así poder realizar una emulación fiel y eficiente de una máquina específica.

El simulador de CPU más simple sería un intérprete informático, que sigue el flujo de ejecución del código de programación emulado y, por cada instrucción de código de la máquina emulada, ejecuta en el procesador en que se carga, instrucciones semánticamente equivalentes a las originales.

Esto es posible asignando una variable a cada registro y "flag" de la CPU emulada. La lógica de la CPU simulada puede ser más o menos traducida directamente a algoritmos de software, creando una reimplementación del software que básicamente refleja la implementación original del hardware.

El ejemplo siguiente ilustra el modo en que la simulación de CPU por un intérprete. En este caso, las interrupciones se revisan después de la ejecución de cada instrucción, aunque este comportamiento no es usual en los emuladores en la realidad, por razones de rendimiento.

Los intérpretes son muy populares en el caso de los simuladores de CPU, ya que son más sencillos de implementar que otras soluciones alternativas de mejor rendimiento, y su velocidad es más que adecuada para emular computadoras de hace más de una década en máquinas modernas.

Aun así, la penalización de velocidad inherente en la interpretación puede ser un problema al emular computadores cuya velocidad de procesador está en el mismo orden de magnitud que la máquina huésped. Hasta no hace tantos años, la emulación en tales situaciones era considerada impracticable.

Lo que permite el rompimiento de esta restricción son las técnicas avanzadas de "recompilación dinámica". Una translación simple "a priori" del código del programa emulado al código que corre en la arquitectura original es usualmente imposible por varias razones:

Varias formas de recompilación dinámica, incluyendo la popular técnica de "compilación en tiempo de ejecución" (compilación JIT), trata de bordear estos temas esperando hasta que el proceso de control de flujo se mueva hasta donde esta la parte donde está localizado el código sin traducir, y es solo entonces {"en tiempo de ejecución") cuando los bloques traducidos del código al código anfitrión pueden ser ejecutados. 

El código traducido se mantiene en el "código caché", y el código original no se pierde ni es afectado; de esta forma, incluso los segmentos de data pueden ser trasladados por el recompilador, resultando solo en un gasto de tiempo de traslado.

La mayoría de los emuladores, como dicho anteriormente, no emulan el sistema principal bus; cada dispositivo de entrada y salida es tratado a menudo como un caso especial, y no existe una interfaz constante para los periféricos virtuales.

Esto puede resultar en una ventaja en el funcionamiento, proveyendo que cada módulo de entrada y salida pueda ser adaptado a las características del dispositivo emulado; diseños basados en un estándar, entradas y salidas unificadas por medio de API pueden sin embargo proveer modelos más simples, y además tienen la ventaja adicional de permitir de forma "automática" la utilización de servicios plugins para proveer dispositivos virtuales de terceros en el emulador.

Las entradas y salidas unificadas por medio de API no necesariamente reflejan la estructura del bus del hardware real: el diseño del bus está limitado por varios parámetros eléctricos y la necesidad del manejo de programación paralela que la mayoría de las veces puede ser ignorada en la implementación del software.

Aún los emuladores que tratan cada dispositivo como un caso especial poseen una infraestructura básica en común para ello:


Los emuladores arrancan imágenes ROM, o sea el contenido de los cartuchos, disquetes o cintas que se usaban con los sistemas antiguos. Físicamente en las PC las ROM son archivos binarios que se pueden cargar en la memoria. Es decir, el emulador es un programa que hace las funciones de una consola, por ejemplo la Game Boy Advance o una PDA, y la ROM es un archivo que hace de cartucho, CD-ROM, o cinta, por ejemplo "Mario Bros.".

También hay una vertiente en la emulación que puede ser realizada por virtualización, consistente en crear una capa de abstracción, pero ejecutando instrucciones en una máquina del mismo tipo, y da como resultados obtener una computadora dentro de otra. Ejemplos de esto son:


Los emuladores de videoconsolas son un tipo de emuladores diseñados para emular una o varias videoconsolas y así poder jugar un videojuego diseñado para ser jugado en ésta(s). Los emuladores múltiples suelen emular consolas con características similares (por ejemplo MEKA emula todas las consolas de Sega de 8 bits y la Colecovision)




</doc>
<doc id="1143" url="https://es.wikipedia.org/wiki?curid=1143" title="Espeleología">
Espeleología

La espeleología (del griego σπηλαιου "spelaiou" que significa cueva y -logía, tratado) es una ciencia cuyo objeto es la exploración y estudio de las cavidades subterráneas. Considerado el padre de la espeleología moderna, el francés Édouard Alfred Martel (1859-1938) inició las primeras exploraciones científicas y en 1895 fundó la "Sociedad Espeleológica de Francia".

Se ha propuesto sin éxito que aquellas ocasiones en que su práctica se asemeja más bien a un deporte, sería más apropiado denominarla "espeleísmo"; aunque, no deja de tener sus orígenes en una ciencia que estudia la morfología de las cavidades naturales del subsuelo. Se investiga, se topografía y se catalogan todo tipo de descubrimientos subterráneos. Es más, la espeleología es una ciencia en la que se hallan implicadas varias otras: la formación y las características de las cavidades interesan a los geógrafos y geólogos; los cursos subterráneos de agua a los hidrólogos; la fauna (más variada y numerosa de lo que se cree) a los zoólogos; los vestigios del hombre prehistórico a los antropólogos y arqueólogos y los fósiles de animales a los paleontólogos, etc.

La espeleología oferta multitud de atractivos, tanto lúdicos como científicos a diversos niveles, lo que hace de ella una actividad muy completa.

De modo global, podemos distinguir varios tipos de espeleología, según el tipo de cavidad en que se desarrollan.

En primer lugar decir que el término "Karst" proviene de la palabra eslovena Kras que significa "terreno pedregoso y estéril", nombre de una región eslovena, posteriormente los alemanes lo llamaron Karst.

Dado que se practica en las cuevas con mayores longitudes y desniveles del planeta, puede considerarse como la principal rama de la exploración espeleológica; las condiciones de exploración son, además, generalmente duras. Muchas de las cuevas kársticas conocidas actualmente se encuentran en macizos montañosos relativamente fríos, con corrientes de agua subterráneas permanentes. Estos ríos suelen tener temperaturas gélidas que hacen más difícil la progresión del espeleólogo, o pueden crecer súbitamente debido a tormentas en el exterior, lo que dejaría a los equipos de espeleólogos aislados en zonas secas de la cavidad. 

Se desarrolla en cavidades de origen kárstico, es decir, cavidades excavadas por corrientes de agua en macizos de rocas solubles como la caliza y la dolomía. Existen también cavidades horadadas en macizos yesíferos, salinos (halita) e incluso bajo glaciares (casos que se denominan pseudokarst), y que al fin y al cabo están originadas por un proceso de disolución de la roca encajante. Estos procesos se desarrollan de modo muy lento, pudiendo tardar millones de años para formar una cavidad y concrecionarla (las estalactitas, gours, excéntricas... son espeleotemas secundarios que forman la llamada "decoración de la cavidad").

El espeleobuceo es la variante más complicada y difícil de la espeleología, que centra su actividad en la exploración de cavidades subacuáticas. Muchas de las cuevas acaban en conductos cegados por el agua, denominados sifones. A partir de este punto, los espeleobuceadores toman el relevo a los espeleólogos para continuar la exploración de la cavidad. La práctica del buceo en cuevas debe ser realizada por personas que, además de ser buenos espeleólogos y buzos expertos, dominen las técnicas con equipos especializados. A veces se necesitan mezclas con helio, oxígeno y nitrógeno (Trimix y Nitrox) para bajar los largos tiempos de descompresión y combatir la narcosis de nitrógeno.

Las características tan hostiles que presentan los espacios inundados en las cavernas, hacen del espeleobuceo una de las actividades más peligrosas del mundo. Aunque se toman grandes precauciones y los sistemas de seguridad son redundantes, los errores muy frecuentemente se cobran vidas.

Vulcanoespeleología es la espeleología que se desarrolla en cuevas volcánicas, esto es, las que son creadas por la lava de un volcán durante una erupción, ya sea por desplazamientos de lava fluida (carácter reogenético) o por movimientos de retracción térmica (carácter tectónico). La mayor parte de cavidades volcánicas se forman en un periodo de tiempo corto: días, meses o a lo sumo años, según la técnica de progresión por cuerda fija.

Sin embargo, el tipo más común de cavidades volcánicas se origina al fluir una colada volcánica por un terreno de pendiente moderada (desplazamiento casi horizontal), dando lugar a lo que se conoce por "tubo volcánico" o tubo de lava. Estos tubos tienen poca inclinación (raras veces se supera el 60%), con lo cual pueden recorrerse, en general, sin necesidad de cuerdas. La ausencia generalizada de agua, dado que no interviene en la génesis de la cavidad, es un punto que hace más simple a la vulcanoespeleología, pues se eliminan riesgos derivados de su presencia, como las crecidas y la hipotermia. 

Pero la dificultad viene dada por otras características, como un sustrato generalmente áspero, la existencia de muchos pasos estrechos y temperaturas que suelen tender a calurosas (aunque esto depende de la región geográfica donde se ubique la cueva). En ocasiones, también es necesario el uso de cuerdas en las llamadas "simas volcánicas", que se forman por un desplazamiento vertical de la lava fluida, o en cascadas de lava en el interior de tubos volcánicos.

Estas características de exploración hacen que, por lo general, el equipo de progresión del vulcanoespeleólogo sea más ligero y menos sofisticado que el empleado por un espeleólogo kárstico.

En una cavidad las formaciones son muy numerosas, y se las conoce como "decoración" o más específicamente espeleotemas; en las cavernas kársticas se pueden encontrar desde "simples" estalactitas y estalagmitas hasta una inmensidad de variadas formaciones, banderolas, concreciones, gours, excéntricas, microgours, golpes de gubia, coladas, pisolitas, conulitos, columnas, muchos tipos de helictitas, antoditas y demás formaciones propias de cada tipo de cueva dependiendo del lugar donde se encuentren. Estas últimas, las excéntricas, se diferencian del resto por su curiosa forma. Suele parecerse a la forma creada de una pasta dentífica cuando se presiona con fuerza el tubo. Su rareza recae en que en vez de ser formaciones verticales son horizontales. Se les llama lámparas a la congregación numerosa de excéntricas pendidas del techo. En España encontramos en la Cueva de El Soplao (Cantabria) la mayor extensión de excéntricas y de lámparas de toda Europa conocida hasta hoy.

Los tubos volcánicos poseen a su vez su propia decoración, creada tanto por la lava al solidificarse en variadas formaciones (decoración primaria o reogenética) como por las filtraciones de agua posteriores, una vez consolidada la cavidad (concreciones secundarias o epigenéticas). Entre las formas primarias están estafilitos, cornisas, terrazas, churretes, castillos, jameos, lagos de lava, cascadas de lava y columnas. Entre las concreciones destacan las calcáreas (que en algunos tubos llegan a formar pequeñas estalactitas) y sobre todo las de yeso, ya que el basalto sometido a una humedad constante tiende a formar este mineral.


</doc>
<doc id="1144" url="https://es.wikipedia.org/wiki?curid=1144" title="Ernst Lubitsch">
Ernst Lubitsch

Ernst Lubitsch (Berlín, 28 de enero de 1892-Los Ángeles, California; 30 de noviembre de 1947) fue un director de cine judío-alemán, nacido en Alemania, naturalizado ya en 1933 estadounidense, a donde había emigrado. Su versatilidad como cineasta fue notable; dominando la comedia, el drama, la tragedia, la farsa o el espectáculo.

Lubitsch nació en 1892 en Berlín. Era hijo de Simón Lubitsch, dueño de una próspera sastrería, cuya familia tenía raíces judías askenazis, y que había nacido en Grodno; su madre nació en Wriezen (Oder), fuera de Berlín. Simón quiso orientar a Ernst hacia el negocio familiar. 

Estudió Lubitsch en el instituto Sophien de Berlín, pero desde adolescente hizo funciones teatrales. A los 16 años empezó a trabajar como actor (aunque ayudaba a su padre). Es más, sin alcanzar los veinte años, comenzó a actuar en el teatro de Max Reinhardt desde 1911 (el Deutsches Teather); y ya hizo con esa compañía el papel de Wagner del "Fausto", que circuló con la compañía por Londres, París y Viena. En 1912 entró en el cine como atrecista del Bioscope.

En 1913 creó un personaje cómico judío para diferentes cortometrajes que escribió y dirigió. Desde 1914 hasta 1922, rodó cerca de cincuenta filmes de distinto metraje. Hizo su primer viaje a Estados Unidos en 1921, y asistió al rodaje de "Las dos huérfanas" de Griffith. 

En Estados Unidos continuó luego una brillante carrera, tanto en cine mudo como en sonoro, desde 1922. Destacaría especialmente en el género musical, y lo mejor de su obra serán las películas de comedia.

Fue supervisor de la Paramount, lo que aprovechó para ofrecer su primera oportunidad a jóvenes promesas que huían de Europa ante el antisemitismo nazi, como Billy Wilder y Otto Preminger.

Ya había rodado con éxito, en 1918, "Los ojos de la momia", "Meyer de Berlín" y "Carmen" (según Merimée); en 1919, "La Princesa de las Ostras", "Madame Du Barry" (con gran aceptación) y "La muñeca"; en 1920, "Romeo y Julieta", "Las hijas del cervecero", "Sumurun" (donde actuaba) y "Ana Bolena". Al año siguiente rodó "El gato montés" y "La mujer del faraón", cuyo gran éxito le valió ir a California. Fue muy entrevistado y habló muy bien de Chaplin. Al regresar a Berlín, y hastiado del cine histórico, hizo un drama de cámara "Montmartre" ("Die Flamme", 1922).

Se trasladó a los Estados Unidos a la edad de 30 años, como un maestro consumado. Sus cuatro primeros largometrajes obtuvieron un notable éxito, por lo que la actriz Mary Pickford le propuso un contrato en Hollywood. Del primero destacan en 1923 "Rosita"; en 1924, "Los peligros del flirt" y "La frivolidad de una dama"; en 1925 "Divorciémonos" y especialmente una obra maestra por su sutileza, "El abanico de Lady Windemere". En 1928, rodó "El patriota" e hizo su último film silencioso en 1929: "Amor eterno", romántico y bello visualmente.

Luego, hasta su nacionalización en 1933, hizo "Montecarlo" (1930), "El teniente seductor" (1931); un drama antibelicista, "Remordimiento" (1932), que se considera obra maestra; y otras comedias, como "Una hora contigo", "Un ladrón en la alcoba", "Si yo tuviera un millón" (episodio), todo en 1932, y al año siguiente "Una mujer para dos".

Formó parte del modelo star-system de Hollywood. Una vez en Estados Unidos, se consagró con la llamada «comedia refinada» de la que se le considera fundador. En este mismo subgénero (dentro de la comedia americana clásica), dirigió la famosa sátira contra la absurda rigidez soviética "Ninotchka" (1940), y más tarde la mordaz sátira antinazi "Ser o no ser" (1943), pero trenzada con su esquema del engaño amoroso matrimonial, que fue su guía. Después rodó "El diablo dijo no" (1943), "El pecado de Cluny Brown" (1946) y "La dama del armiño" (1948), que ya no pudo concluir.

Su obra se ha caracterizado por un modo irónico especial, el llamado «toque Lubitsch», que usaba no solo para saltarse la censura, sino también para complicar la trama, para divertirse, para hacer ambiguas las situaciones. Nadie lo ha definido de un modo muy concreto, porque no existe, decía él. Un ejemplo de este método estaría en "Trouble in paradise" (1932) en el que se nos permite intuir una infidelidad con puertas que se abren y cierran. Se ha dicho que ese toque es un modo de narrar que posee "los sutiles ingredientes de la ironía, el pathos, la amargura y la risa, todos en uno; muy a menudo es el sarcasmo más anímico que visual que brota de una situación imposible que pueda degradar al héroe o descalificar al genio".

Se denomina "Toque Lubitsch" la «habilidad que tenia el cineasta alemán de sugerir más de lo que mostraba». Consiste en la inteligencia del espectador, ya que el director sugiere un concepto es el espectador quien llega a imaginarlo mediante esta sugerencia. 

El T"oque Lubitsch" era un concepto que muchas personas conocían, pero que nadie lograba explicar. Tan solo Ernst Lubitsch sabia en qué consistía exactamente. 

Este recurso denominado "Toque Lubitsch", consiste en una composición de argumento elegante y sofisticado que acababa dirigiéndose hacia la ironía. Se caracteriza por su capacidad de sugerir aquello que no podía mostrar de forma explícita, obligando así al espectador a imaginar lo que el propio Lubitsch está queriendo mostrar. El objetivo, era evitar que sus películas fueran censuradas, por lo que subyacía un erotismo muy sutil, que le proporcionaban a las películas una apariencia ligera, pero en el fondo tenían un gran compromiso tanto moral como social. 

Un claro ejemplo donde se aprecia el "Toque Lubitsch" es en "Ser o no ser" (1943), película en la que Lubitsch contó las peripecias de una compañía de teatro en la Varsovia ocupada por los nazis.


"A veces he hecho películas que no alcanzaban el nivel que me exijo, pero es que lo único que se puede decir de un mediocre es que toda su obra alcanza el nivel que se exige."




</doc>
<doc id="1149" url="https://es.wikipedia.org/wiki?curid=1149" title="El Salvador">
El Salvador

El Salvador, oficialmente República de El Salvador, es un país soberano de América Central ubicado en el litoral del océano Pacífico con una extensión territorial de 21 041 km². En el año 2015 contaba con una población estimada en 7 329 015habitantes,
siendo el país más densamente poblado del continente americano. Su clima es cálido tropical pero debido al contraste geográfico el clima puede variar. El Salvador limita con Guatemala al oeste y con Honduras al norte y al este, al sureste el golfo de Fonseca lo separa de Nicaragua, y flanqueado al sur por el océano Pacífico. Su territorio está organizado en 14 departamentos, 39 distritos y .
La ciudad de San Salvador es la capital del país; su área metropolitana incluye 14 municipalidades cercanas, y concentra la actividad política y económica de la república. Las ciudades de Santa Ana y San Miguel son otros centros importantes del país.

El actual territorio de El Salvador comprende lo que antes fuera la Alcaldía Mayor de Sonsonate y lo que fue la Intendencia de San Salvador que conformó la mayor parte del territorio. Ambas provincias adquirieron su independencia de España en 1821 junto a la Capitanía General de Guatemala y en 1824 se unieron para formar el «Estado del Salvador»,
como parte de la República Federal de Centro América. En la época precolombina, existía un importante núcleo indígena conocido como el Señorío de Cuzcatlán (que en lengua náhuat significa ‘lugar de joyas’ o ‘lugar de collares’).

Una guerra civil de 12 años, cuyo costo humano llegó aproximadamente a 75 000 vidas, finalizó el 16 de enero de 1992, cuando el gobierno y la guerrilla firmaron los acuerdos de paz que dieron lugar a reformas militares, sociales y políticas.

Es muy poco conocida la historia de por qué El Salvador lleva este nombre. Quizá una de las razones sea porque se trata de un proceso lento y paulatino de larga data.

Durante la Conquista de América, y más específicamente, durante la conquista de las ahora tierras salvadoreñas, se llevaron a cabo una serie de luchas contra los nativos del lugar, para luego fundar poblaciones españolas que se encargaran de mantener dominada una determinada región. Después de la conquista de Tenochtitlán, Hernán Cortés envió al clan Alvarado al mando del adelantado Pedro de Alvarado para que sometiera las regiones al Sur del Imperio azteca. La primera región en ser conquistada fueron los territorios que ahora componen Guatemala. Estando acá, Pedro de Alvarado decide incursionar en las tierras del Oriente, terruños que estaban sometidos a una especie de vasallaje del Señorío de Cuzcatlán. Acá, los iberos y sus aliados, los llamados "indios amigos", se encontraron con aguerridos pobladores que hicieron cruentos frentes en contra de los invasores, como ocurrió en la batalla de Acajutla, así como en la batalla de Tacuzcalco y la batalla de Cuzcatlán. Todo esto acaeció en 1524. Infructuoso el cometido de Pedro de Alvarado de someter a los naturales de estas tierras, regresa este a la recién fundada Ciudad de Guatemala.

Al año siguiente, en 1525, Pedro de Alvarado envía a un grupo de españoles al mando de Gonzalo de Alvarado con órdenes expresas de que fundase en estas tierras una villa con el nombre de San Salvador, para que controlara a los nativos del lugar. No obstante, al año venidero, debido a la resistencia de los lugareños, la efímera Villa de San Salvador es despoblada y sus vecinos regresan a Guatemala. Será hasta 1528 que se refundará la Villa de San Salvador en el Valle de la Bermuda, a 8 km al sur del poblado indígena de Suchitoto. Hacia 1540, se crea la Alcaldía Mayor de San Salvador. Para entonces ya existiría otra población de origen español en la región, San Miguel de la Frontera. La sede de las autoridades de la Alcaldía Mayor se establecerían en la Villa de San Salvador. La mencionada Alcaldía abarcaría gran parte de lo que hoy es la nación salvadoreña, con excepción de los ahora departamentos de Ahuachapán y Sonsonate. Con ello, al territorio se le comenzaría a identificar con el nombre de Provincia de San Salvador. He aquí los inicios primigenios del nombre de esta república.

Siglos después, con la implementación de las Reformas borbónicas en América se crearían intendencias. Estas eran entidades político-administrativas bien delimitadas con una autoridad muy fortalecida. La antigua Alcaldía Mayor de San Salvador se convertiría en la Intendencia de San Salvador en 1785 con capital en la ya ciudad de San Salvador. La creación de esta intendencia será muy importante para la consolidación futura de la idea de una nación salvadoreña, ya que le permitió a las élites sansalvadoreñas tener una conciencia o identidad particular, independiente de Guatemala, que era vista con recelo.

Hacia 1821, en el territorio de la Intendencia de San Salvador se crea la Provincia de San Salvador, oficialmente así llamada, ahora completamente independiente de Guatemala. Esto fue producto de la restauración del régimen constitucional en España, el cual decretó que todas las intendencias se convertirían en provincias completamente independientes de cualquier otra autoridad para tener sus propias autoridades. No obstante, esto sería bastante efímero, ya que el 15 de septiembre de 1821 la Capitanía General de Guatemala declararía su independencia de España, hecho que ratificaron el resto de provincias del Reino de Guatemala.

De tal suerte que durante toda la época de dominio español en América, a lo que hoy es El Salvador se le identificaría con el nombre de Provincia de San Salvador. Pero hacia finales de 1823 y comienzos de 1824, en dos partes, la Alcaldía Mayor de Sonsonate decide integrarse a la Provincia de San Salvador para fundar juntos el Estado salvadoreño como parte de las Provincias Unidas del Centro de América, proclamadas el 1 de julio de 1823, y que más tarde, el 22 de noviembre de 1824, se convertirían en la República Federal de Centro América. Debido a esta unión, para evitar que el nombre sonara a un Estado encabezado por la ciudad de San Salvador, la primera asamblea constituyente del naciente Estado decide cambiar su tradicional nombre.

Es así que, producto de la unión de las provincias de Sonsonate y San Salvador, el nombre oficial de «El Salvador» fue aceptado en la primera Constitución del Estado, promulgada el 12 de junio de 1824. Sin embargo, la usanza de hacer contracción de la primera palabra provocó que fuera escrito como «Estado del Salvador». Incluso, esa misma Carta Magna estipulaba que el Estado se denominaría «Estado del Salvador» (art. 7).
El Estado conservaría este nombre durante toda la existencia de la República Federal de Centro América e incluso después de la desintegración de esta. Sin embargo, el 2 de febrero de 1841El Salvador abandona oficialmente la unión, pero será hasta el 25 de enero de 1859 que oficialice su calidad de república libre, soberana e independiente.

Hacia comienzos del siglo XX, por medio del Decreto Legislativo del 7 de junio de 1915, publicado en el Diario Oficial No. 133, Tomo No. 78, del 9 de junio de 1915,
fue establecido definitivamente como nombre oficial «El Salvador».
A pesar del precepto, en documentos oficiales internacionales continuaba la práctica de omitir la primera parte del nombre oficial de la república. Por gestiones del Subsecretario de Cultura, Jorge Lardé y Larín,
se emitió el Decreto Legislativo No. 2737, del 23 de octubre de 1958, publicado en el Diario Oficial No. 210, Tomo No. 181, del 11 de noviembre de 1958,
en el que se añadió al texto del 7 de junio de 1915 la prohibición de suprimir la palabra «El» cuando fuera asociado a las palabras «República» o «Estado». Asimismo, se determinó la reserva del derecho a contestar cualquier documento o suscribir cualquier convenio donde apareciese escrito incorrectamente el nombre oficial de la república.
Es así como, finalmente, el nombre oficial de este país centroamericano se consolida como «República de El Salvador».

De acuerdo al historiador Pedro Escalante Arce, el cambio de «San Salvador» a «Estado del Salvador» se realizó para significar que, a partir de la formación como Estado, abarcaría tanto a la Provincia de San Salvador, como a la de Sonsonate, que desde 1823 era parte de ella.

El territorio salvadoreño forma parte del área de Mesoamérica, y se encuentra ubicado en una región que sirvió de paso de objetos e ideas a través del tiempo.
Las primeras evidencias culturales en El Salvador se remontan a ocho mil años, justamente en el período arcaico (8000 a 1500 a. C.), época de grandes migraciones a diversas zonas mesoamericanas, una de ellas la costa del Pacífico del país.
Entre el período preclásico temprano (1500—900 a. C.) y medio (900—500~400 a. C.), se asentaron grupos proto mayas en la región occidental.
Para el caso, en el área de Chalchuapa se han encontrado restos de antiguos asentamientos, probablemente emigrados de Chiapas y Guatemala.
Desde esta zona partieron grupos hacia lugares como Jayaque o Antiguo Cuscatlán en el período preclásico medio.

En el preclásico tardío (500~400 a. C.—200~250 d. C.), existió desarrollo cultural y relaciones de tipo lingüística, escultórica y comercial con las tierras altas de Guatemala, especialmente con la cerámica Usulután y la obsidiana.
Además, las tres zonas del país (occidental, central y oriental) se encontraban pobladas; y se incrementó la construcción de montículos como en Quelepa, Atiquizaya y El Trapiche.
Sin embargo, el florecimiento se vio interrumpido en varios sectores por la erupción del volcán de Ilopango en el 260 d. C.

En el período clásico temprano (200~250—400 d. C.), en Quelepa —poblado por lencas y que no fue afectado por la erupción de Ilopango— hubo progreso notable y se establecieron relaciones con poblaciones de tierras altas y del sur del istmo. Para el período clásico medio (400 a 650 d. C.) existió repoblación del occidente y centro del territorio por grupos mayas-chortí. Una de las localidades era Joya de Cerén, ocupada en el siglo VI y cuyos habitantes se vieron afectados por la erupción del volcán Caldera; también la zona del lago de Güija fue un lugar de intercambio importante con el occidente de Honduras, valle de Motagua y Petén.
Por otra parte, en esa época se establecieron los cacaoperas en la región oriental.
En el período clásico tardío (del 600 al 950 d. C.), se manifestó un desarrollo cultural evidenciado por la construcción de complejos arquitectónicos, siendo los más representativos: Tazumal, Cara Sucia, Cihuatán,
Quelepa y San Andrés, que también tuvo sus años de esplendor entre los años 600~650 y 900~1000.

El período postclásico (950-1524) es caracterizado por los Estados seculares. Sitios como Tazumal y Laguna Seca son abandonados después del año 1200; aunque posteriormente arribaron grupos multiétnicos de influencia nahua: los nonoalca-pipiles,
que ocuparon un estimado de tres cuartas partes del territorio salvadoreño.
En esta fase existió la construcción de obras de ingeniería y el comercio a larga distancia; por otra parte, la sociedad se vio marcada por la estratificación, el dominio de un gobernante supremo y la presencia de órdenes militares. Entre los núcleos indígenas más importantes se encontraban los izalcos y principalmente el Señorío de Cuscatlán, que se considera el modelo del desarrollo local en este período.

El año 1522, cinco navíos españoles partieron desde Panamá para explorar las costas del litoral pacífico. El piloto mayor era Andrés Niño quien bautizó al golfo de Fonseca y el 31 de mayo desembarcó en una isla a la que llamó «Petronila» (Meanguera).
Para junio de 1524 el conquistador Pedro de Alvarado atravesó el río Paz con tropas españolas acompañadas de indios auxiliares, e inició el sometimiento de los nativos en el actual territorio salvadoreño. Los colonizadores establecieron en los años posteriores diversas poblaciones: San Salvador, erigida en 1525 pero que tuvo su asiento definitivo en 1545; San Miguel, cuyo primer asentamiento surgió en 1530; y la villa de la Trinidad (Sonsonate), fundada en 1553. Todo el territorio comprendería las Alcaldías Mayores de Sonsonate y San Salvador, ambas parte del Reino de Guatemala. Junto a la conquista española también se desarrolló el mestizaje, el proceso de evangelización católica, la enseñanza del idioma castellano, y el arribo de esclavos africanos.

Por la escasez de oro y plata, el Reino no tenía la preponderancia de otras posesiones americanas, por lo que sustentó su economía en la agricultura. Para la creación de riqueza era aprovechado el trabajo de los indios, así como la apropiación de tierra.
Además, los nativos, reducidos a pueblos de indios,
eran sujetos a tributos, y no fueron raras las quejas por abusos de autoridad. De hecho se registró un motín en Izalco el año 1725.

La conquista centroamericana tuvo una etapa inicial de extracción de materias primas, a la que siguió la dependencia de un producto de exportación: primero fue el cacao cuyo cultivo de grandes plantaciones empezó desde 1540 en la provincia salvadoreña, principalmente en la región sonsonateca;
y después el tinte de añil que desde 1600 era de gran importancia para la economía del Reino y de San Salvador especialmente, ya que era su principal producto de exportación.
En contraste, su proceso de elaboración perjudicaba la salud de los obreros indígenas.
A estos artículos se añadían el hierro de Metapán y también el denominado bálsamo del Perú cuya exportación, como sucedió con el añil, perduró una vez terminado el dominio español.
Sin embargo, en este período existieron factores que menoscababan el dinamismo de la economía, tales como: la merma de la población indígena por enfermedades, recesiones provocadas por las guerras en las que se enfrascaba la corona española, pésimas vías de comunicación, plagas de chapulín, y el dominio del comercio en la región por los ricos comerciantes afincados en la ciudad de Guatemala, entre otros. Para 1785, en virtud de las reformas borbónicas, se instituyó la Intendencia de San Salvador.

Desde la primera década del siglo XIX, en las posesiones americanas de la corona española, comenzaban a surgir movimientos con inquietudes independentistas. San Salvador no era ajena a los sucesos, ya que la situación económica y política era desfavorable para los habitantes de la provincia. La élite local conformada por criollos y religiosos deseaban lograr la autonomía y sacudirse el dominio de la aristocracia guatemalteca, por lo que el 5 de noviembre de 1811 estalló una sublevación en contra de las autoridades europeas. La revuelta, que fue la primera en el Reino, no halló respaldo en las autoridades de las demás poblaciones, por lo que terminó en fracaso. Sin embargo, otro alzamiento tendría lugar en 1814. El gobierno de la Capitanía logró mantener el control sobre los amotinados hasta el año 1821, cuando en la región se conoció la firma del Plan de Iguala en el Virreinato de Nueva España, y la proclamación de independencia de Ciudad Real; que motivó a los independentistas a presionar al Jefe Político Gabino Gaínza para que convocase a la Diputación Provincial y firmar el Acta de Independencia que tuvo lugar el 15 de septiembre.

Sin embargo, y a pesar que en dicha acta se estipulaba la convocatoria a un congreso para decidir el gobierno de las provincias, las autoridades guatemaltecas y adeptos al Plan de Iguala dispusieron la anexión al Imperio Mexicano el 5 de enero de 1822. La facción salvadoreña se opuso a la decisión por sus ideas republicanas,
pero no pudo impedir que San Salvador acabara anexada al Imperio, aunque por breve tiempo, ya que Agustín de Iturbide abdicaría al trono. El 1 de julio de 1823 se proclamó la independencia absoluta de las antiguas provincias del Reino de Guatemala que pasaron a llamarse Provincias Unidas del Centro de América y cuya Asamblea Constituyente era presidida por José Matías Delgado. A finales de ese año y principios de 1824, la Alcaldía Mayor de Sonsonate y posteriormente la localidad de Ahuachapán, se anexaron a la provincia salvadoreña.

La República Federal de Centro América se constituyó el día 22 de noviembre de 1824, y El Salvador era uno de sus cinco Estados. No obstante, el 12 de junio de ese mismo año los salvadoreños se habían apresurado a emitir su propia constitución, para contrarrestar cualquier asechanza del centralismo guatemalteco.

A pesar del régimen federal, en el territorio aún prevalecía la vieja rivalidad entre los provincianos, que deseaban mantener la autonomía ante el mismo poder federal, y los conservadores guatemaltecos, que pretendían conservar su hegemonía en la región. Tal antagonismo, sumado a la economía precaria, deficientes sistemas de comunicación, y una fuerza armada frágil, dificultó la existencia de la República hasta provocar dos guerras civiles entre los años 1826-1829, y 1830-1842. También en El Salvador ocurrió un levantamiento indígena acaudillado por Anastasio Aquino.

Con el éxodo de Francisco Morazán en 1840 —presidente centroamericano que tenía simpatizantes en El Salvador y quien se esforzó en implantar medidas liberales extremas en la nación—, acabó la República Federal. El 2 de febrero de 1841, El Salvador se proclamó como Estado soberano e independiente.

Luego de la disolución de la unión se sucedió un período de pugnas entre liberales y conservadores que se prolongó hasta 1871. En este período, decayó el cultivo del añil y se introdujo el del café, el cual fue fomentado durante la administración del Dr. Eugenio Aguilar,
e intensificado en la del capitán general Gerardo Barrios.
Entre 1871 y 1931 se sucedieron los gobiernos liberales que favorecieron los intereses de la naciente élite ligada al cultivo del café. En 1881 y 1882, durante la presidencia de Rafael Zaldívar, la Asamblea Legislativa decretó sendas leyes de abolición de las tierras comunales y ejidales, que fueron vendidas a particulares, lo que provocó un cambio brusco en la tenencia de la tierra.

Con la "Ley de Extinción de Comunidades", aprobada mediante Decreto Legislativo del 15 de febrero de 1881, publicado en el Diario Oficial No. 49, Tomo No. 10, del 26 de febrero de 1881,
se argumentaba que «la división de los terrenos poseídos por comunidades, impide el desarrollo de la agricultura, entorpece la circulación de la riqueza y debilita los lazos de la familia y la independencia del individuo» y que «tal estado de cosas debe cesar cuanto antes como contrario á los principios económicos, políticos y sociales que la República ha aceptado».
Y por su parte, con la "Ley de Extinción de Ejidos", aprobada mediante Decreto Legislativo del 2 de marzo de 1882, publicado en el Diario Oficial No. 62, Tomo No. 12, del 14 de marzo de 1882,
se sostenía que uno de los mayores obstáculos para el desarrollo de la agricultura «es el sistema ejidal, por cuanto anula los beneficios de la propiedad en la mayor y más importante parte de los terrenos de la República, que se hayan destinados á cultivos de ínfimo valor ó abandonados del todo, por lo precario del derecho de sus poseedores, manteniendo á estos en el aislamiento y la apatía é insensibles á toda mejora» y que «aunque el dominio directo de dichos terrenos corresponde á la nación por las leyes preexistentes, no es justo privar de su uso y goce á las municipalidades, sin una previa indemnización».

En esta parte de la historia viene un gran progreso para consolidar un Estado-Nación cafetalero se invierte en infraestructura. En 1908 construyeron vías ferroviarias para articular las zonas cafetaleras con el puerto de Acajutla. Para tener una rápida comunicación entre la zona oeste con el este del país se construyó sobre el río Lempa el “Puente de oro”. Los financiamientos y las inversiones norteamericanas fueron desplazando a los ingleses. La alianza con la oligarquía y con la burguesía agrícola fue la política que los Estados Unidos siguieron para expandir su dominio político y económico en la región, método a la vez para desplazar al capital inglés.

Sin embargo, el descontento en la clase indígena trabajadora por las injusticias recibidas desembocarían en un conflicto de grandes proporciones y el cambio de la forma de gobernar.

En 1929, la economía del país entró en crisis, como consecuencia de la caída de los precios del café en el mercado internacional. En 1931, el General Maximiliano Hernández Martínez, llegó al poder tras un golpe de estado contra el presidente civil Arturo Araujo. Martínez, estableció un gobierno ultraconservador y autoritario. El dirigente indígena Feliciano Ama acaudilló el levantamiento campesino en Izalco de 1932. Tras la derrota de la rebelión fue capturado y ejecutado. El General Martínez reprimió con el ejército dicho levantamiento campesino en el occidente del país, lo que resultó en muerte de miles de personas. El número de víctimas mortales de estos hechos, aún se debate. Las cifras de muertos, difieren según los autores, y van desde 7000 hasta 30 000 personas.
Los historiadores todavía debaten la influencia de los miembros del Partido Comunista Salvadoreño en la insurrección y del dirigente comunista Agustín Farabundo Martí. El general Martínez fue depuesto por una huelga general en 1944, llamada «huelga de los Brazos Caídos». Pero su gobierno marcó el inicio de una serie de gobiernos militares autoritarios sucesivos, que finalizarían en 1979 con un golpe de Estado al General Carlos Humberto Romero, del PCN y la instauración de la Junta Revolucionaria de Gobierno. En 1982, se eligió una Asamblea Constituyente, a la que la Junta entregó el poder; posteriormente se celebraron en 1984 las primeras elecciones presidenciales de la era democrática.

En 1969 se produjo una breve guerra con Honduras, cuyo nombre formal, según el gobierno del presidente Fidel Sánchez Hernández, fue «la guerra de la legítima defensa»; pero llegó a ser conocida también como la «Guerra de las 100 horas», o equivocadamente como la «Guerra del Fútbol». La razón del conflicto armado radicó en una iniciativa de las autoridades de Honduras de llevar a cabo una reforma agraria dentro de sus fronteras; dicha distribución de tierras favorecía solamente a hondureños, lo cual obligó a miles de salvadoreños radicados en Honduras a volver a su país, luego de haber sido expropiados de sus tierras. En respuesta a esta situación, El Salvador declaró la guerra a Honduras.

El ambiente de violencia política que se había vivido la década anterior contribuyó enormemente a la guerra civil que duraría 12 años (1980-1992). Fue un conflicto que militarmente se definió como una guerra de baja intensidad, o guerra popular prolongada, como la denominaban las fuerzas guerrilleras del FMLN y que costó la vida a más de 75 000 personas entre muertos y desaparecidos.

Algunos factores que contribuyeron a la guerra fueron: la caída internacional del precio del café, los constantes fraudes electorales y el descontento de la población por la forma de gobernar de los militares. Entre algunos sucesos que encendieron los ánimos durante el conflicto armado destacan los asesinatos del arzobispo de San Salvador, Óscar Arnulfo Romero, y Fray Cosme Spessotto Zamuner, ambos en 1980.

El ambiente turbulento finalizó en 1992 cuando los combatientes del Frente Farabundo Martí para la Liberación Nacional (FMLN) formado por cinco agrupaciones de izquierda, y el gobierno de derecha del entonces presidente Alfredo Cristiani, de Alianza Republicana Nacionalista (ARENA), firmaron los acuerdos de paz el 16 de enero de 1992 en Chapultepec, México, que aseguraron reformas políticas y militares, pero no profundizaron en el aspecto social.

En 1992, la Corte Internacional de Justicia (CIJ) mandó la delimitación de «Los Bolsones» (un área fronteriza disputada entre El Salvador y Honduras), pero, gracias a la intervención de la Organización de los Estados Americanos (OEA) y la CIJ en 2003, la total demarcación de la frontera terrestre ha sido finalizada en el 2006. También en 1992, la CIJ aconsejó una resolución tripartita para la creación de las fronteras marítimas en el golfo de Fonseca. El Salvador continúa reclamando la Isla Conejo, la cual no se incluye en la decisión de la CIJ en este mismo caso.

San Salvador, la capital, es conocida por los muchos sismos que ocurren; por lo cual se le ha llamado popularmente «Valle de las Hamacas» desde tiempos de la colonia. El 10 de octubre de 1986, un terremoto de 5.7 grados de intensidad en la escala Richter, de 10 segundos de duración y muy superficial, destruyó gran parte de la ciudad de San Salvador con un total de 1500 fallecidos y 200 000 damnificados. El 13 de enero de 2001, otro terremoto, este de 7.7 grados en la escala Richter, causó gran destrucción a lo largo y ancho del país. Una de las tragedias humanas que sucedió como consecuencia del sismo fue un desprendimiento de tierra en la llamada cordillera del Bálsamo, en la ciudad de Santa Tecla (La Libertad), que provocó el fallecimiento de 800 personas y dejó a varios miles sin hogar. El 13 de febrero de 2001, exactamente un mes después, otro terremoto, de 6.6 grados en la escala Richter, mató a 255 personas, dejando sin sus casas a cientos de familias, especialmente en el interior de la república, donde viven los estratos más pobres de la sociedad. El 13 de octubre de 2014, un terremoto, de 7.3 grados en la escala Richter, ocurrió tres días después de la conmemoración del terremoto de 1986. A pesar de su magnitud, y que se prolongó por casi un minuto, los daños fueron leves y mató a una persona.

Las elecciones presidenciales, celebradas el 15 de marzo de 2009, dieron como ganador al periodista Mauricio Funes del partido de izquierda FMLN, siendo el primer gobierno de izquierda en la historia del país.

Posteriormente, en los comicios del 9 de marzo de 2014 el FMLN vence nuevamente a ARENA y es electo como Presidente de la República Salvador Sánchez Cerén, un excomandante de las Fuerzas Populares de Liberación Farabundo Martí (FPL), organización integrante de ahora partido político FMLN, junto con Óscar Ortiz como Vicepresidente de la República.

La Constitución Política del año 1983, dispone que El Salvador es un país con un sistema político pluralista que se expresa por medio de sus partidos políticos, los cuales son los únicos instrumentos para la representación del pueblo.
Para su administración política, el territorio se divide en departamentos, y en cada uno de ellos existe un gobernador elegido por el poder ejecutivo; dichos funcionarios ejercen labores administrativas cuya función principal es la de servir de enlace entre la Presidencia y los gobiernos locales de cada departamento, así como atender las necesidades de las comunidades en coordinación con la dirección de Protección Civil del Ministerio de Gobernación.
Los partidos políticos legalmente inscritos en el Tribunal Supremo Electoral son los siguientes (en orden alfabético):

En El Salvador, para el gobierno local los departamentos se dividen en municipios, que son autónomos en lo económico, técnico y administrativo, aunque están obligados a colaborar con otras instituciones públicas en los planes de desarrollo nacional y regional.

De acuerdo a la Constitución, en El Salvador existen tres órganos fundamentales, los cuales son el Legislativo, el Ejecutivo y el Judicial.

Es un cuerpo colegiado conformado por ochenta y cuatro diputados, al que le corresponde, fundamentalmente, la función de legislar. Sus miembros se renuevan cada tres años, y pueden ser reelegidos. Las resoluciones del Órgano Legislativo, o Asamblea Legislativa, requieren del voto favorable de la mitad más uno de los diputados, salvo los casos específicos dictados en la Constitución.
También puede formar comisiones especiales para investigar asuntos de interés nacional.

El Órgano Ejecutivo se encuentra conformado por el presidente y vicepresidente de la República, los ministros y viceministros junto a sus funcionarios dependientes. El período presidencial es de cinco años. El presidente es también el comandante general de la Fuerza Armada, institución encargada de la defensa nacional. La seguridad pública se encuentra a cargo de la Policía Nacional Civil. También existe un Consejo de Ministros.

La potestad de juzgar y hacer ejecutar lo juzgado corresponde al Órgano Judicial, el cual está compuesto por la Corte Suprema de Justicia, las Cámaras de Segunda Instancia, y los demás tribunales que disponen las leyes del país en las materias que les corresponden.
También existe un Consejo Nacional de la Judicatura, una entidad independiente en sus funciones que contribuye a la eficiencia de la carrera judicial.

El Ministerio Público de El Salvador lo conforman la Fiscalía General de la República, encargada de defender y representar los intereses del Estado, así como la competencia de investigar y promover la acciòn penal ante el cometimiento de un hecho delictivo; la Procuraduría para la Defensa de los Derechos Humanos, surgida en virtud de las reformas constitucionales como consecuencia de los acuerdos de paz de Chapultepec; y la Procuraduría General de la República, que vela por la defensa de la familia, de las personas e intereses de los menores de edad, entre otras facultades.

El Tribunal Supremo Electoral es la máxima autoridad en materia de elecciones. Está compuesto por cinco magistrados elegidos por la Asamblea Legislativa y duran cinco años en sus funciones. Al organismo le corresponde convocar, organizar, dirigir y vigilar los procesos electorales relacionados con la elección del presidente y vice presidente de la República, diputados al Parlamento Centroamericano, diputados a la Asamblea Legislativa, y miembros de los concejos municipales.

La Corte de Cuentas de El Salvador es el ente que le corresponde la fiscalización de la hacienda pública en general y de la ejecución del presupuesto en particular, por lo que se considera el organismo rector del sistema nacional de control y auditoría de la gestión pública. Las acciones de control consisten en auditorías financieras, auditorías operacionales y exámenes especiales.

El Salvador se divide en 14 departamentos. Geográficamente están agrupados en tres zonas, las cuales son: Occidental, Central y Oriental. Cada departamento está fraccionado en municipios, , los cuales tienen autonomía en lo económico, técnico y en lo administrativo.
Son regidos por un concejo municipal elegido cada tres años por votación pública. En el territorio de cada municipio existe una cabecera que es nominada como pueblo, villa o ciudad. Asimismo, dentro de la circunscripción hay cantones, los cuales están conformados por caseríos.

La extensión territorial de El Salvador es de 21 041 km², la menor de América Central.
Cabe agregar que el 11 de septiembre de 1992, la Corte Internacional de Justicia resolvió un diferendo limítrofe entre El Salvador y Honduras sobre un total de 440 km², de los que se adjudicaron 150 km² a El Salvador y 290 km² a Honduras.
Ambos países dieron por finalizada la demarcación de la frontera en el año 2006 en cumplimiento de la sentencia.
El Salvador ejerce también soberanía y jurisdicción sobre el mar, el subsuelo y el lecho marinos hasta una distancia de 200 millas marinas contadas desde la línea de más baja marea.

La demarcación de la CIJ tuvo como resultado una gran cantidad de habitantes con doble nacionalidad y muchos ciudadanos que siguen considerándose salvadoreños, siendo contados los hondureños, lo que genera problemas debido a la doble nacionalidad a la hora de votar
y complicaciones a la hora de buscar asistencia pública, dado que las instituciones hondureñas se encuentran alejadas de estas zonas y las personas siguen acercándose a las instituciones salvadoreñas.

El país se encuentra limitado en el Norte y Noreste por la República de Honduras; en el Este y Sureste por el golfo de Fonseca, que lo separa de la República de Nicaragua; en el Sur por el océano Pacífico; y en el Oeste y Noroeste por Guatemala.
La topografía de El Salvador es escabrosa debido a las actividades volcánicas y tectónicas. Desde el punto de vista morfológico, se divide en seis regiones fisiográficas: planicie costera, cadena costera, fosa central, fosa interior, cadena interior y cordillera fronteriza. También se distinguen una serie de valles.

Se ubica entre la costa bañada del océano Pacífico y las estribaciones merindionales de la cadena costera, y se encuentra comprendida en la denominada zona-costera que abarca 21.000 km², de los cuales 7.000 km² pertenecen a la franja costera y 14.000 km² a la franja marina. La línea de costa tiene 307 km de longitud abarcando desde el río Paz hasta el golfo de Fonseca. La cordillera del Bálsamo, la sierra de Jucuarán y el volcán de Conchagua, dividen el paisaje costero en seis secciones: planicie costera de Occidente, entre el estuario del río Paz y Punta Remedios; costa acantilada, asociada a la cordillera del Bálsamo; planicie costera central, entre La Libertad y playa El Espino; costa acantilada, asociada a la sierra de Jucuarán; planicie costera oriental, entre playa El Cuco y Punta Amapala; y la costa del golfo de Fonseca, entre Punta Amapala y el río Goascorán.

Ubicada entre la planicie costera y la fosa central, abarca desde el río Paz hasta el valle medio del río Grande de San Miguel, y se divide en las sierras Apaneca-Ilamatepec, que es la zona de la mayor producción de café en el país;
la sierra Libertad-San Vicente, en cuya parte Norte localizada en el departamento de La Libertad se ubican la cuenca del río Lempa y la sub cuenca del río Suquiapa;
y la sierra Tecapa-Chinameca, zona asociada con la bahía de Jiquilisco.
También sobresale la cordillera costera-meridional Jucuarán-Intipucá que se eleva entre la bahía de Jiquilisco y el golfo de Fonseca, y sus elevaciones más notables son los cerros El Mono, Baúl, Panela, Montoso, Buenavista y volcán Conchagua.

Se encuentra situada entre la cadena costera y las montañas fronterizas. Tiene una anchura que varía entre los 10 km y 30 km. Además se localizan lagos como el Coatepeque e Ilopango; así como lagunas, valles y numerosos ríos. En este lugar han ocurrido desplazamientos tectónicos a lo largo de la historia, y una intensa actividad eruptiva que ha provocado edificios volcánicos, entre los que cabe mencionar a los volcanes Chingo, Santa Ana, Izalco, San Salvador, San Vicente, Tecapa, Usulután y cerro Guazapa. Por otro lado, es la zona más densamente poblada del país, ya que allí se asientan importantes ciudades como lo son San Salvador, Santa Ana, y San Miguel.

Son cordilleras fronterizas las de Alotepeque-Metapán que penetra al Norte del departamento de Santa Ana, se ramifica en el municipio de Metapán y se extiende en el centro y Norte del departamento de Chalatenango; al Oeste de Honduras se une con la cordillera de Celaque. Abundan las coníferas.
Aquí se encuentran los puntos más elevados de El Salvador y las temperaturas más frías. Las cimas más elevadas son los cerros Miramundo, Montecristo, El Brujo, El Pital (la cima más elevada del país con 2.730 msnm) y el cerro Negro.
La otra cordillera fronteriza es la de Nahuaterique en el Norte del departamento de Morazán.


Los valles en El Salvador se clasifican en superiores y bajos. El más notable por su extensión es el valle superior del río Lempa. Otros valles de importancia son:

Es la unidad geomorfológica más pequeña del país, ya que abarca un 5% del territorio. Se encuentra situada al Noroeste del mismo, en las regiones de los departamentos de Santa Ana y Chalatenango. Tiene una longitud aproximada de 70 km y contiene mucho cascajo. El río Lempa y algunos de sus afluentes depositan en la fosa sedimentos fluviales.

En el Oeste del territorio, separa como una franja estrecha e irregular la fosa interior de la meseta central y se extiende desde las faldas del volcán Chingo hacia el centro y Norte del departamento de Santa Ana. Puede considerarse una estribación de la Sierra Madre de Chiapas.

En El Salvador existe una ley de áreas naturales protegidas, que le otorga al Ministerio de Medio Ambiente la potestad de declararlas por medio de un decreto ejecutivo.
De acuerdo a la legislación, dichas áreas pueden estar localizadas en territorio nacional de propiedad del Estado, de un municipio, de entes autónomos o privados y de personas naturales.
Hasta el mes de abril del año 2010 el número de áreas naturales protegidas era de setenta.
Entre ellas destacan el Parque Nacional de los Volcanes, que comprende a tres importantes volcanes de la cordillera Apaneca-Ilamatepec: el Izalco, Santa Ana y Cerro Verde; el Parque nacional Montecristo, parte de la reserva de la biosfera Trifinio; Parque nacional El Imposible; volcán Tecapa, en el que se ubica también la laguna de Alegría; Parque El Boquerón en el volcán de San Salvador; el arrecife Los Cóbanos; complejo Conchagua; el parque nacional San Diego, San Felipe Las Barras, el Parque del Bicentenario, etc.
También existen sitios RAMSAR como el complejo Jaltepeque, laguna El Jocotal, bahía de Jiquilisco, embalse del Cerrón Grande, laguna de Olomega y complejo Güija.

Sin embargo, El Salvador es considerado el país más deforestado de Centroamérica. Para el año 2006, la extensión de bosque, incluyendo manglares, era 2.665 km² que equivalía a 12.6% del territorio, el cual correspondía a 1.1% del bosque regional. Los factores de la reducción del área boscosa han sido ocasionadas por los ciclos históricos de producción agrícola que empezó con la explotación del añil, y continuó con el café y el algodón; además, la alta presión poblacional que sobrepasa los 300 habitantes por kilómetro cuadrado, ocasiona la demanda de leña para cocinar y tierra para fines agrícolas. Toda esta degradación magnífica la incidencia de los fenómenos naturales que provocan deslizamientos de tierras, inundaciones o pérdida de suelo fértil.

Para el año 2006, los recursos hídricos de El Salvador se estimaban en 17.8 km³, de los cuales 11.6 provienen de las aguas superficiales.
Asimismo es el único país de Centroamérica cuyo territorio drena totalmente a la vertiente del océano Pacífico.
Un total de 360 ríos se consideran de importancia, los cuales están agrupados en diez regiones hidrográficas. Las más importante es la cuenca del río Lempa (10 167 km²), de la que un 56 % pertenece a El Salvador, y el resto a Guatemala y Honduras.

Las otras cuencas son: Paz (919.9 km²), Cara Sucia-San Pedro (768.8 km²), Grande de Sonsonate-Banderas (778.4 km²), Mandinga-Comalapa (1294.5 km²), Jiboa-Estero Jaltepeque (1638.6 km²), bahía de Jiquilisco (779.01 km²), Grande de San Miguel (2389.2 km²), Sirama (1294.5 km²), y Goascorán (1044.4 km²).

Por otra parte, para el año 2005 fueron identificados un total de 59 cuerpos de agua como lagos (entre los que destacan Ilopango, Güija y Coatepeque), así como lagunas, embalses, manglares y esteros. Los embalses hidroeléctricos comprenden: Cerrón Grande, 5 de noviembre, 15 de septiembre y Guajoyo.

El Salvador también dispone de aguas subterráneas. Aunque su delimitación geográfica no ha sido detallada, existe un estimado de 2000 millones de m³ de recarga de precipitación al año. Los acuíferos de mayor rendimiento corresponden a Sonsonate-Acajutla, Jiboa-Lempa, Lempa-Jiquilisco, Usulután-Vado Marín, Valle de Zapotitán, Quezaltepeque-Opico, y San Salvador, entre otros. Todos ellos se encuentran ubicados en la Fosa Central y Planicie costera del territorio.

El país se encuentra en el cinturón de Fuego del Pacífico, y su territorio volcánico es muy activo.
De hecho, el 90 % de su suelo es conformado por materiales volcánicos. El número de volcanes individuales es de veintitrés, aunque solo cuatro de ellos (Santa Ana, San Salvador, San Miguel e Izalco) han tenido actividad continuada.
Por otra parte, la erupción del volcán de Ilopango en el año 260 d. C., ha sido una de las más grandes de la región centroamericana.

Por las características geotectónicas y morfológicas, los volcanes se dividen en dos grupos: los volcanes antiguos del Terciario (de más de dos millones de años), y los volcanes jóvenes del Cuaternario (menos de dos millones de años). Al primer grupo pertenecen volcanes como el de Siguatepeque y Cacahuatique, y se considera que tienen remotas posibilidades de entrar en erupción; por su parte, los volcanes del Cuaternario presentan los tipos de estrato volcanes altos, depresiones volcano-tectónicas, cráteres de explosión, cráteres por hundimiento o conos de escorias. Ejemplos de ellos son: Santa Ana, Izalco, San Salvador, San Vicente, San Miguel, Tecapa y Conchagua, entre otros.

El Salvador, por su cadena volcánica y su ubicación en un sistema de fallas geológicas y el proceso de subducción entre las placas tectónicas de Cocos y el Caribe, se encuentra en una región de alto índice de actividad sísmica.
Un total de 55 terremotos han ocurrido entre 1573 y 2001, y se estima que un 70 % del territorio puede verse afectado por la ocurrencia de un evento de esta naturaleza. El número de víctimas desde los años 1980 se ha incrementado, situación que se atribuye a la presión demográfica.

El Salvador se encuentra en la zona climática tropical y ofrece condiciones térmicas similares durante todo el año. Sin embargo, debido a su franja costera a lo largo del Océano Pacífico, ocurren oscilaciones anuales importantes relacionadas con la brisa marina que transporta humedad y calor.

La temperatura media anual (período considerado: 1950-1990) es de 24.8 °C, presentándose la temperatura media más baja en los meses de diciembre (23.8 °C) y enero (23.9 °C), mientras que el mes más cálido es abril (32.0 °C). La precipitación media anual es de 1823 mm.

Como los termómetros de las estaciones meteorológicas van siendo influenciados por la isla de calor de las urbes, en los últimos treinta años la temperatura ha aumentado 1.2 °C,
siendo los años ochenta una de las décadas más calientes (aunque la estadística ni siquiera cubre una centuria), con precipitaciones influenciadas por el evento ENOS.

El Salvador tiene dos estaciones: la seca (noviembre-abril) y la lluviosa (mayo-octubre). Además, el país se ve afectado por la estación de huracanes del Caribe (junio-noviembre). Las frecuentes tormentas tropicales y huracanes aumentan el caudal de los ríos locales, afectando algunas de las áreas con inundaciones. Los huracanes más destructivos que han afectado a El Salvador son:
Fifi (en 1974),
Gilbert (en 1988),
Andrew (en 1992),
Mitch (en 1998),
Stan (en 2005),
Félix (en 2007),
Ida (2009, que registró una lluvia de 522 mm en solo cuatro horas),
Agatha (en 2010, que acumuló 574 mm y
la Depresión tropical Doce-E (en 2011, que dejó acumulados de más de 1200 mm en 5 días.

La economía salvadoreña ha experimentado una mezcla de resultados durante los sucesivos gobiernos del partido ARENA en las iniciativas del mercado libre y el modelo de gerencia fiscal que incluyen la privatización del sistema de actividades bancarias, las telecomunicaciones, las pensiones públicas, la distribución eléctrica, y una parte de la generación eléctrica, reducción de los aranceles, eliminación de los controles de precios y una aplicación mejorada de los derechos de propiedad intelectual.
El PIB ha estado creciendo en un paso constante pero modesto después de la firma de los acuerdos de paz en 1992, en un ambiente de la estabilidad macroeconómica. Un problema que El Salvador enfrenta es la desigualdad económica de la distribución de ganancias personales. En 1999, la quinta parte más rica de la población recibió el 45 % de la ganancia del país, mientras que la quinta parte más pobre recibió solamente 5.6 %.

Desde el mes de diciembre de 1999, las reservas internacionales netas llegaron a US$1800 millones de dólares. Teniendo este almacenador intermediario de la moneda fuerte para trabajar, el Gobierno de El Salvador emprendió un plan monetario de la integración que comenzaba del 1 de enero de 2001, por el cual el dólar estadounidense se convirtió en moneda de curso legal junto al colón salvadoreño, lo cual facilita las operaciones económicas con el exterior, y toda la contabilidad formal fue emprendida en los dólares. De esta manera, el gobierno ha limitado formalmente su posibilidad de poner políticas monetarias sobre el mercado para influir variables a corto plazo en la economía.
Desde 2001, a pesar de que existen dos monedas legales en el país, el colón dejó de circular y ahora ya no se utiliza para hacer transacciones; sin embargo algunos almacenes todavía informan al público de precios en colones y a la vez en dólares. En general, debido al fuerte efecto de las remesas, la población apoyó con el cambio del colón al dólar. El cambio al dólar también precipitó una pauta de intereses más bajos en El Salvador, ayudando a muchos para asegurar crédito para comprar una casa o un automóvil. Algunos economistas estiman que esta subida de precios igualmente habría sucedido a causa de la inflación sin que el cambio monetario se hubiese producido. Los sectores políticos de izquierda, han sido muy críticos del proceso de dolarización que consideran favorece al interés de las empresas del sector financiero.
Debido a la guerra civil y al estancamiento nacional de los años 80, el PIB no ha superado aún los niveles de finales de los años 70 en términos de la paridad del poder adquisitivo. Actualmente, la economía está más orientada hacia la manufactura y los servicios, en lugar de la agricultura (cultivo del café). Sus principales industrias son la de alimentos y bebidas, productos del petróleo, tabaco, productos químicos, textiles y muebles.

Hay actualmente quince zonas de libre comercio en El Salvador. El beneficiario más grande ha sido la industria de la maquila textil, que proporciona 88 700 trabajos directos, y consiste sobre todo en el corte de las ropas que montan para la exportación a los Estados Unidos.

El Salvador fue el primer país en firmar e implementar el Tratado de Libre Comercio entre Estados Unidos, Centroamérica y República Dominicana (CAFTA), así como acuerdos de libre comercio con México, Chile, la República Dominicana, y Panamá, y ha aumentado sus exportaciones a dichos países. El Salvador, Guatemala, Honduras y Nicaragua también están negociando un acuerdo de libre comercio con Canadá. Así mismo, se ha terminado la negociación de un Tratado de Libre Comercio con Colombia y otro con Taiwán. En el 2007 se iniciara un proceso de negociación con la Unión Europea, que busca lograr un acuerdo de asociación.

La política fiscal ha sido el desafío más grande para el gobierno de El Salvador. Los acuerdos de paz del 1992 comprometieron al gobierno a los gastos para los programas de la transición y los servicios sociales. Aunque la ayuda internacional era abundante y caritativa, el gobierno se ha centrado en mejorar la colección de sus ingresos corrientes. Un impuesto de valor añadido del 10 % (IVA), implementado el septiembre de 1992, fue aumentado hasta el 13 % en julio de 1995. El IVA es la fuente más grande del rédito, contabilidad para cerca de 52.3 % de ingresos fiscales totales en 2004.

El modelo liberal implantado, de acuerdo a muchos académicos, ha generado resultados mixtos a nivel macroeconómico, existe una pequeña porción de población, principalmente los grupos con poder político, que se han visto beneficiados y que han tenido un fuerte crecimiento mientras que en muchos otros sectores no se reflejan una mejora del nivel de vida.
Desde el 2001 el país adoptó, por decreto legislativo, al dólar como moneda oficial y se sustituyó al antiguo colón. Desde que se realizó el cambio, las tasas de interés han caído y los salvadoreños con acceso a crédito lo han obtenido a las tasas más bajas en tres décadas. El progreso económico ha permitido que reconocidas instituciones financieras internacionales, como es el caso de Moody's, le haya otorgado a El Salvador una calificación de «grado de inversión», la cual solo la gozan además en Hispanoamérica, Chile, México, Perú, Panamá y Colombia. En la actualidad, la banca salvadoreña se ha expandido a toda Centroamérica, convirtiéndose en los bancos más grandes de la región. Así mismo, la línea aérea regional más grande, Avianca El Salvador, pertenece en un 70 % a empresarios salvadoreños. La inversión privada salvadoreña se encuentra en toda la región, especialmente en el área de servicios. Otros ejemplos son la presencia en toda la región de Agrisal y sus marcas: Holiday Inn, Crowne Plaza. Grupo Roble con Metrocentro, Multiplaza y otros proyectos que han llegado al Caribe y Sudamérica. Urbánica e Inversiones Bolívar.

Las remesas de salvadoreños que trabajan en los Estados Unidos y envían a los miembros de sus familias son una fuente importante de ingresos del extranjero y compensan el déficit comercial substancial de alrededor $4 000 millones. Las remesas han aumentado constantemente de la década pasada y han alcanzado un colmo absoluto de $3.78 mil millones en 2008 —aproximadamente el 17.1 % del producto interno bruto (PIB)—.

En abril de 2004, las reservas internacionales estaban calculadas en $1900 millones. En años recientes la inflación ha caído a niveles de un dígito y las exportaciones totales han crecido substancialmente.

Al ser un país rico en folclore y tradiciones, la producción artesanal se encuentra muy difundida en todo el estado y contribuye en gran medida al desarrollo de la economía nacional. Se trabajan materiales como: el mimbre, la jarcia, el barro, la palma, la madera, el tule, las jícaras, el cuero y los metales, entre ellos el oro y la plata. Está muy difundida la artesanía del tejido, la alfarería, la orfebrería ("filigranas") y la hojalatería (" aperos para la labranza, machetes") y resulta una forma de generar progreso económico para muchas personas, que se dedican a vender artesanías a turistas nacionales y extranjeros y a exportar, principalmente a Estados Unidos, Alemania y el resto de la Unión Europea.

En la actualidad, El Salvador, junto a México, todos los países centroamericanos y Colombia, llevan a cabo el Plan Puebla Panamá, que es un esfuerzo de integración regional, algunos piensan que traerá inmensos beneficios a cada uno de las naciones involucradas, debido a la magnitud de inversión en infraestructura y desarrollo social.

En El Salvador más de la mitad de la energía se produce a partir de recursos renovables como lo son la hidroeléctrica y la geotérmica, con altas expectativas de crecimiento por los proyectos de ampliación de las plantas geotérmicas y la construcción de nuevas presas hidroeléctricas, además se está dando paso a una planta de gas natural con inversión de 900 millones de dólares. El Salvador es el segundo país del mundo con mayor porcentaje de producción de energía geotérmica con respeto a su total con un 25 % al 2013.

El cuadro siguiente muestra la producción total de energía de El Salvador al 2013 y sus porcentajes.

Debido a la alta densidad de población y a la temprana explotación del café, los recursos forestales de El Salvador se han reducido a un pequeño porcentaje de la superficie del país (5.8 % el equivalente a unas 1210 km²) y la mayoría están protegidos. Como resultado, la mayor parte de la madera que necesita el país debe ser importada. No obstante se mantienen especies de árboles muy particulares del país junto con otras existentes en casi toda Iberoamérica. Los árboles de bálsamo son muy abundantes en sus bosques. De hecho, El Salvador es uno de los principales proveedores de goma de bálsamo.

El Salvador ha hecho grandes esfuerzos para promocionarse como destino turístico para 2014, aproximadamente 1.36 millones de personas visitaron El Salvador, dejando en el país unos 822 millones de dólares.
Para facilitar el turismo para extranjeros y nacionales el Ministerio de Turismo ha propuesto diferentes rutas, las cuales son las siguientes:
Joya de Cerén, San Andrés, Santa Ana, Chalchuapa, Tazumal, Casa Blanca.

Ilobasco, Suchitoto, San Sebastián, Cihuatán, Colima, La Palma, San Ignacio, El Pital, Las Pilas, Miramundo, Citalá, Iglesia del Pilar.

Perquín, Cacaopera, Arambala, Corinto, San Fernando.

Bosque de Chaguantique, Bahía de Jiquilisco, Volcán de Tecapa y Laguna de Alegría, Berlín, Alegría.

Concepción de Ataco, Nahuizalco, Ilobasco, La Palma San Sebastián, Cihuatán, Joya de Cerén, San Andrés, Santa Ana, Chalchuapa, Tazumal, Casa Blanca, Iglesia Santiago Apóstol, Suchitoto, Panchimalco.

Playas de El Salvador:




Salcoatitán, Nahuizalco, Juayúa, Apaneca y Concepción de Ataco.

Cerro Verde, Izalco y Santa Ana.

En la actualidad, las plantas de energía hidroeléctrica aportan el 36 % de la electricidad producida en El Salvador. La compañía pública estatal CEL (Comisión Ejecutiva Hidroeléctrica del Río Lempa) posee y opera el 97 % de esta capacidad.
Las cuatro plantas de energía hidroeléctrica en El Salvador son: 5 de noviembre (81.4 MW), Guajoyo (15 MW), Cerrón Grande (135 MW) y 15 de septiembre (156.3 MW), todas ellas sobre el río Lempa.

En este sector, los proyectos actualmente en marcha son los siguientes:


Esta expansión de la capacidad hidroeléctrica añadiría 351 MW al sistema en los próximos 5 años, lo que representa un aumento del 76 % en la capacidad actual. Además, si se ejecutaran los proyectos binacionales El Tigre (en el río Lempa) y El Jobo y Piedra de Toro (en el río Paz) con Honduras y Guatemala, se añadirían 488 MW de capacidad adicional al sistema de generación.

En la actualidad hay dos instalaciones geotérmicas en funcionamiento en El Salvador, la planta de Ahuachapán, de 95 MW, y la de Berlín, de 104 MW. La compañía eléctrica con mayoría de capital estatal LaGeo, antiguamente denominada Gesal, opera las dos plantas. LaGeo está ampliando actualmente las dos plantas geotérmicas existentes y llevando a cabo un estudio de factibilidad para una tercera planta, Cuyanausul. Se espera que los tres proyectos agreguen 64 MW de capacidad de generación eléctrica instalada para 2007.
En 2015 se inaugura AES Moncagua en San Miguel, la cual es una planta de generación fotovoltaica con capacidad para generar 2.5 MW, producidos por más de 8000 módulos fotovoltaicos de tipo policristalino. La planta cuenta con una estación de monitoreo climático que le permite analizar y confirmar su correcto funcionamiento. Se permitirá reducir 2700 toneladas de CO al año

El Salvador cuenta con los siguientes puertos marítimos:

Los siguientes aeropuertos de carácter internacional:

Localizado a 40 km de la capital. Fue construido en la segunda mitad de los años 1970 siendo finalizado en 1979 por la constructora japonesa Hazumi Gumi, para sustituir a su predecesor, el Aeropuerto de Ilopango,
El aeropuerto es el principal centro de conexiones, o hub, para la aerolínea Avianca El Salvador, y da servicio también a otras aerolíneas que vuelan a 31 destinos entre Centroamérica, Norteamérica, Sudamérica y Europa. Además, la nueva aerolínea salvadoreña VECA Airlines ofrece servicios a la región. Por el mismo tuvo un movimiento de pasajeros, siendo el tercer aeropuerto más transitado. Posee 17 posiciones de estacionamiento, una pista de 3200 metros y amplia gama de opciones para compras en la terminal.

El aeropuerto sirvió como el principal aeropuerto internacional. Actualmente es utilizado con fines de aviación militar, vuelos chártes y vuelos civiles regionales.

La infraestructura vial en El Salvador, según el último Informe Global de Competitividad del Foro Económico Mundial, El Salvador se ubica en tercer lugar en América Latina, destacando por la alta calidad de carreteras en la región. Solo por debajo de Chile y Panamá. Obteniendo una puntuación de 4.7 en escala de 7. Sobrepasando países como México, Brasil, Colombia y a sus similares en la región.

La población estimada de El Salvador para el año 2015 es de 6 377 195, dentro de su territorio. Para el año 2007, había un 86.3 % de población mestiza; 12.7 % blanca; 0.23 % de indígenas, entre ellos kakawiras (0.07 %), nahua-pipiles (0.06 %), y lencas (0.04 %); también un 0.13   de población negra y 0.64 % de otros grupos étnicos.
Es el país más densamente poblado de América. Cabe mencionar que El Salvador es actualmente el segundo país en Latinoamérica con el menor porcentaje de crecimiento demográfico de la región sólo por encima de Uruguay con 0.27% de cambio anual.

Con respecto a la población negra, su presencia en el territorio se remonta al inicio de la presencia española, pero se trató de ocultar su existencia en el proceso de configuración de la nación de los siglos XIX y XX, en los que se exaltaba el mestizaje y sus dos orígenes: la raza blanca e india.
Para el caso, el general Maximiliano Hernández Martínez llegó a instituir leyes de razas en la década de 1930 que prohibían la entrada de poblaciones negras al país. El capítulo III de la Ley de Migración de 1933, «Restricciones y limitaciones a la inmigración», decía en su capítulo 25: «Se prohíbe la entrada al país, a los extranjeros comprendidos en uno o más de los casos siguientes: a los de raza negra; a los malayos y a los gitanos, conocidos también en el país con el nombre de “húngaros”». Y el artículo 26 continuaba: «No se permitirá asimismo el ingreso al país de nuevos inmigrantes originarios de Arabia, Líbano, Siria, Palestina o Turquía, generalmente conocidos con el nombre de “turcos”».
También es destacable la discriminación ejercida en el campo económico por el general Maximiliano Hernández Martínez contra estos mismos grupos de extranjeros domiciliados en el país. Esta clase de discriminación quedó legalizada mediante Decreto Legislativo No. 49, del 15 de mayo de 1936, publicado en el Diario Oficial No. 111, Tomo No. 120, del 20 de mayo de 1936, en el que se prohibía el establecimiento de almacenes, tiendas, pulperías, talleres, fábricas industriales e industrias agrícolas que sean de propiedad o que sean regentados por personas que pertenecieran a las razas árabe, palestina, turca, china, libanesa, siria, egipcia, persa, hindú y armenia, aunque estuvieran nacionalizadas.

Al inicio de año 2004, vivían fuera de El Salvador un aproximado de 3.1 millones de salvadoreños, como inmigrantes en Estados Unidos - la mayoría de forma indocumentada/ilegal-, que es el destino a donde tradicionalmente se dirigen para dejar la precaria situación económica en la que viven o para mejorar sus condiciones de vida. La segunda comunidad más grande de salvadoreños residiendo en el exterior, es la comunidad de Guatemala que suman unos 111 000, también hay nutridas comunidades salvadoreñas en Canadá, México, Italia, Suecia, España, Australia y Costa Rica. Tal situación se agrava durante la guerra civil de la década del 80 y posteriormente por condiciones económicas y sociales adversas.

De acuerdo a la Encuesta de Hogares de Propósitos Múltiples (EHPM), los hombres tienen una tasa de alfabetización de un 89.8 % y las mujeres de 85.0 %, en promedio, un 11.7 % de la población de todo el país no sabe leer ni escribir.
De acuerdo a datos del Gobierno, existen 28 municipios en los que el analfabetismo ha sido erradicado.
Esto implica que al menos el 96 % de los habitantes sabe leer y escribir.

De acuerdo con la legislación salvadoreña, la educación formal corresponde a los niveles inicial, parvulario, básico, medio y superior.
Pero la ley establece también que la educación inicial, parvularia, básica, media y especial será gratuita y obligatoria.

La educación inicial comienza desde el alumbramiento del niño hasta antes de cumplir los cuatro años de edad.
La educación parvularia tiene una duración de tres años y atiende a niños de cuatro a seis años de edad.

La educación básica se ofrece normalmente a estudiantes de siete a quince años de edad y es obligatoria y también gratuita cuando la imparta el Estado. Se puede admitir alumnos de seis años, siempre que bajo criterio pedagógico demuestren madurez y aptitud apropiadas de acuerdo a los criterios y mecanismos de evaluación establecidos por el Ministerio de Educación. La educación básica comprende nueve grados de estudio divididos en tres ciclos de tres años cada uno.

La educación media ofrece la formación en dos modalidades, una general y otra vocacional. Los estudios de educación media culminan con el grado de bachiller. El bachillerato general tiene una duración de dos años, mientras que el bachillerato técnico-vocacional es de tres años. El tiempo de duración del bachillerato nocturno es de tres y cuatro años para las modalidades general y vocacional, respectivamente.
Para obtener el grado de Bachiller es indispensable haber cursado y aprobado el plan de estudios correspondiente, incluyendo el servicio social estudiantil;
además de someterse a una prueba obligatoria establecida por el Ministerio de Educación para medir el aprendizaje y las aptitudes de los estudiantes.
Dicho examen, aplicado desde 1997, es conocido con el nombre oficial de Prueba de Aprendizaje y Aptitudes para Egresados de Educación Media (PAES). Los centros educativos oficiales que imparten la educación media se definen como Institutos Nacionales, mientras que las instituciones privadas son llamadas colegios o liceos.

La Educación Superior se regirá por una Ley Especial y tiene los objetivos siguientes:formar profesionales competentes con fuerte vocación de servicio y sólidos principios morales; promoverla investigación en todas sus formas; prestar un servicio social a la comunidad; y cooperar en la conservación, difusión y enriquecimiento del legado cultural en su dimensión nacional y universal. Esta integra tres funciones: la docencia, la investigación científica y la proyección social. La educación superior se imparte en institutos tecnológicos, institutos especializados de nivel superior y universidades.

La educación especial es un proceso de enseñanza-aprendizaje que se ofrece, a través de metodologías dosificadas y específicas, a personas con necesidades educativas especiales.

La Universidad de El Salvador (UES) fue fundada el 16 de febrero de 1841, por , emitido durante el mandato del Presidente de la República, Juan Lindo, ante la decidida intervención del general Francisco Malespín. La UES fue erigida con el objetivo de proporcionar un centro de educación superior para la juventud nacional, y así evitar que los salvadoreños que tenían la posibilidad y el deseo de cursar estudios superiores, decidieran emigrar a Guatemala o a Nicaragua para completar su formación académica, respectivamente, en la Universidad de San Carlos o en la Universidad de León, tal como lo hacían desde la época colonial. En sus primeros años, la UES tuvo una existencia precaria por el exiguo apoyo económico que recibía por parte del Estado.

Durante el gobierno del presidente Santiago González fueron erigidas otras dos instituciones públicas de educación superior: las Universidades de Occidente y de Oriente, con sus respectivas sedes en las ciudades de Santa Ana y San Miguel. La Universidad de Occidente fue creada mediante Decreto Ejecutivo del 22 de septiembre de 1874, publicado en el Boletín Oficial No. 14, Tomo No. 3, del 26 de septiembre de 1874. Y por su parte, la Universidad de Oriente fue creada mediante Decreto Ejecutivo del 15 de octubre de 1874, publicado en el Boletín Oficial No. 18, Tomo No. 3, del 17 de octubre de 1874. No obstante, estas instituciones educativas fueron suprimidas por el gobierno del presidente Rafael Zaldívar a través de la Ley Orgánica y Reglamentaria de Instrucción Pública,aprobada mediante Decreto Ejecutivo publicado en el Diario Oficial No. 26, Tomo No. 18, del 30 de enero de 1885. Con la desaparición de estas dos universidades públicas, la UES volvió a tener el monopolio de la educación superior en el país hasta 1965, cuando nace la Universidad Centroamericana José Simeón Cañas (UCA) como la primera universidad privada salvadoreña.

Desde la década de 1950, la Universidad de El Salvador se convirtió en el principal referente de pensamiento de la izquierda salvadoreña y fue uno de los núcleos más importantes de oposición a los gobiernos autoritarios y militaristas del país, y fue por esta actitud que muchos de sus estudiantes y catedráticos fueron víctimas de la represión militar.

La primera universidad privada que surge es la Universidad Centroamericana José Simeón Cañas, cuyo antecedente más significativo se remonta a los inicios de la década de los sesenta, cuando monseñor Luis Chávez y González, Arzobispo de San Salvador, expresó la idea de fundar una universidad católica dirigida por jesuitas, como hay muchas en diferentes países.

La cultura popular de El Salvador comprende tradiciones y costumbres ancestrales, provenientes de las culturas prehispánicas, que se fusionaron con las costumbres españolas.
Los núcleos de población más representativos y tradicionales se localizan en las zonas de los izalcos, nonualcos, alrededores de San Salvador y Cacaopera.
Entre las expresiones materiales del folclore salvadoreño, se incluyen elementos como la artesanía, en la que existen importantes centros de producción en Nahuizalco, La Palma o Ilobasco; y los objetos incluyen diversos tipos de alfarería, cerámica, jarcia, cestería, barro cocido, juguetes, pirotecnia, etc.

En cuanto a la vivienda, según datos de 2003, en las comunidades indígenas la utilización del techo de paja se consideraba desaparecido, mientras que las paredes de adobe aún perduraban.
En lo que respecta a vestimenta, las prendas tradicionales son utilizadas en su mayor parte en eventos culturales,
aunque ocasionalmente puede observarse como parte de la vestimenta diaria en ciertas poblaciones como Izalco, Nahuizalco o Panchimalco.

En el campo de las expresiones sociales, resaltan las cofradías y hermandades, que en El Salvador alcanzan un número de cincuenta y tres.
Las localidades adonde se encuentran las de mayor tradición, incluyen a Izalco,
Panchimalco,Jayaque,San Pedro Nonualco,
o Santo Domingo de Guzmán;
por otra parte, en el comercio popular, existe el tiangue, y sobreviven juegos tradicionales para niños y adultos como el yo-yo, el trompo, el capirucho, las chibolas, el palo ensebado, la carrera de cintas a caballo, etc.

En la cultura popular concerniente al aspecto espiritual y mental, cabe destacar a las fiestas patronales que tienen lugar en todos los municipios, entre ellas resaltan las de San Miguel, en la que tiene lugar un reconocido carnaval, así como en San Salvador, con las fiestas agostinas, o Santa Ana con las fiestas julias. Otras expresiones son las danzas, y una breve lista comprende al torito pinto, los historiantes, los chapetones, el tigre y el venado, los emplumados, etc.
También existe un acervo de leyendas y cuentos, siendo representativas la siguanaba, el cipitío, y el cadejo, entre otras.
El maíz, que es igualmente utilizado por muchos pueblos de América, es el ingrediente principal de la cocina típica salvadoreña. El platillo por excelencia es la pupusa, que tiene un día nacional que se celebra cada segundo domingo de noviembre.
Otros alimentos populares elaborados de maíz son: las tortillas, muy importantes en la alimentación diaria de los salvadoreños;
así como los tamales; variedades de atoles como el de atol de elote, piñuela, shuco o chilate; y bocadillos como las riguas; tustacas y totopostes; y la chicha de maíz como bebida.
Además existen festivales del maíz, también conocidos como "atoladas", que son celebrados en el segundo semestre de cada año en diversas poblaciones del país, usualmente en agosto. Estos festines pueden tener un carácter familiar.
Aparte del maíz, el frijol es otro ingrediente muy utilizado en la cocina salvadoreña.

Otros platillos tradicionales son: gallo en chicha, sopa de gallina, sopa de patas, consomé de garrobo, sopa de frijoles con cerdo y masitas, nuegados de yuca, buñuelos de huevo, yuca con chicharrón, ayote en miel, torrejas en miel, y pan con pavo, entre otros.

También existe una variedad de dulces artesanales, y poblaciones como Santa Ana y San Vicente son importantes en su elaboración. Se comercializan principalmente en las fiestas patronales del país, y una breve lista comprende: conservas de coco, coco rallado, melcochas, chilacayote, dulce de leche, dulce de nance, dulce de tamarindo, dulce de panela, entre muchos otros.
Otra importante oferta gastronómica tradicional, dentro del "pan dulce", incluye la cemita, viejitas, salpores, pichardines, quesadillas de queso, torta de yema, marquesote, etc.
Bebidas tradicionales calientes son el chocolate, el café, leche poleada, y las ya mencionadas que son elaboradas a partir del maíz. Bebidas frías populares, llamados "frescos", son: horchata, tamarindo, cebada, ensalada, arrayán, chan, y el tiste, por mencionar algunos.

 Durante la época independentista en la provincia de San Salvador predominaba la oratoria, y en los primeros años de la república se desarrolló una etapa Neoclásica cuyos iniciadores fueron Miguel Álvarez Castro, Enrique Hoyos e Ignacio Gómez. Ya a mediados del siglo XIX existió una primera generación romántica con autores como Juan José Cañas, Francisco Esteban Galindo, y Antonia Galindo. La segunda corriente romántica tuvo entre sus exponentes a Francisco Gavidia, quien fue también uno de los iniciadores del Modernismo en Centroamérica;
así como Román Mayorga Rivas, y Vicente Acosta, entre otros.

El final del siglo vio nacer a Alberto Masferrer quien destacó con un pensamiento social,
el cual dejó plasmado en su obra periodística, oratoria, y ensayística. En esa época también figuraban Arturo Ambrogi, notable autor del impresionismo literario;
y José María Peralta Lagos, conocido costumbrista. Poetas de la época fueron: Ramón de Nunfio, Alfonso Espino, Alberto Rivas Bonilla, o Sarbelio Navarrete; y entre los prosistas: Francisco Herrera Velado, Carlos Serpas, Miguel Ángel Espino y Alberto Guerra Trigueros, entre otros. Literatos de la generación de los años 1910 y 1915 fueron: Alfredo Espino, Vicente Rosales y Rosales, Raúl Contreras, o Julio Enrique Ávila.

A partir de los años 1920 apareció otra generación de autores salvadoreños, entre los que destacan Salvador Salazar Arrué (Salarrué), que es considerado el mejor cuentista salvadoreño;Claudia Lars, una de las mejores voces femeninas de la lírica hispanoamericana del siglo XX;
así como Serafín Quiteño, o Lilian Serpas. Otros autores del siglo XX son: Quino Caso, Pedro Geoffroy Rivas, Hugo Lindo, Alice Lardé de Venturino, Ricardo Trigueros de León, Matilde Elena López, y el fabulista León Sigüenza.

Asimismo, existió el grupo denominado de la «Generación comprometida», que incorporaba a Ítalo López Vallecillos, Waldo Chávez Velasco, Irma Lanzas, Álvaro Menen Desleal, José Roberto Cea, Eugenio Martínez Orantes y Tirso Canales, entre otros; y el Círculo Literario Universitario Salvadoreño de Roque Dalton, Jorge Arias Gómez, Manlio Argueta y Roberto Armijo; tras estas generaciones surgieron poetas como David Escobar Galindo, y provenientes de grupos literarios como Luis Melgar Brizuela, Julio Iraheta Santos o Jaime Suárez Quemain. Otros literatos contemporáneos son: Horacio Castellanos Moya, Francisco Andrés Escobar, Miguel Huezo Mixco, Berne Ayalá, Jacinta Escudos, Carmen González Huguet, Ricardo Lindo, Rafael Menjívar Ochoa, Otoniel Guevara, Yanira Soundy, Rafael Mendoza y Silvia Elena Regalado, por mencionar algunos.

En la rama de la pintura, el primer artista conocido en El Salvador fue Wenceslao Cisneros. Posteriormente surgieron nombres como Marcelino Carballo, oriundo de Zacatecoluca; y Pascasio González, que también figuró en la arquitectura. Ya en el siglo XX, artistas con influencia europea fueron: Carlos Alberto Imery, formador de generaciones de pintores; Miguel Ortiz Villacorta, que también tuvo a su cargo una academia; así como Pedro Ángel Espinoza, de origen humilde.

De características costumbristas, surgidos del primer tercio del siglo XX, son el mismo Salarrué, Zélie Lardé y José Mejía Vides. Notable personaje que dejó escuela en el país fue el español Valero Lecha, formador de reconocidos pintores como: Julia Díaz, Raúl Elas Reyes y Noé Canjura. Opuestos a la corriente academicista, llamados "Los independientes", son: Camilo Minero, Luis Ángel Salinas y Carlos Cañas. Durante los años 1970, época de agitación social, surgieron varias figuras entre las que se puede mencionar a Roberto Huezo, Armando Solís, Antonio García Ponce, Fernando Llort y César Menéndez, entre otros. Parte de una fecunda lista de artistas contemporáneos son: Antonio Bonilla, Roberto Galicia, Giovanni Gil, Sonia Melara, Mayra Barraza, y Walterio Iraheta.
En la rama de la caricatura, resalta Toño Salazar, y otros artistas del género son Rigo, Bollani y Ruz.

En el campo de la escultura, resalta el nombre de Valentín Estrada, que es considerado el primer «escultor nacional». Para los años 1970 ejerció influencia en el país el español Benjamín Saúl; otros escultores son: Enrique Salaverría, Rubén Martínez, Leonidas Ostorga, Negra Álvarez, Tití Escalante, Mauricio Álvarez, Verónica Vides y Guillermo Perdomo.

La música tradicional salvadoreña —que para el caso es interpretada en sus danzas—
es producto del mestizaje precolombino, europeo y africano.
En los primeros años de la época republicana eran interpretados en el país coplas, valses, romances y canciones patrióticas, y también surgieron las primeras bandas militares.
En la primera mitad del siglo XX se popularizaron las marimbas, y algunos grupos lograron notoriedad internacional.
Asimismo, fue la época en la que destacaron notables compositores de temas que variaban de lo académico a lo costumbrista, tales como Felipe Soto, Ciriaco de Jesús Alas, David Granadino, Pancho Lara, Lito Barrientos, Luis Alonso Polío, Francisco Palaviccini, y Benjamín Solís; cabe también mencionar a la musicóloga María de Baratta.
Otros intérpretes de música académica son Germán Cáceres, Alejandro Muñoz Ciudad Real, Esteban Servellón, y el maestro de origen rumano Ion Cubicec.

También en El Salvador existen la Orquesta Sinfónica, así como la Orquesta Sinfónica Juvenil, además de un Coro Nacional.

Con el arribo de nuevos géneros musicales, aparecieron las orquestas de baile, y para los año 1960 y 1970 empezaron a proliferar los grupos juveniles, entre los que cabe destacar a los intérpretes del género rock
y otros estilos modernos como el heavy metal, existiendo en 2011 ochenta y seis bandas de este estilo con discos grabados.
Por otra parte, en el país se ha consolidado la cumbia salvadoreña.

En el año 1824 apareció en San Salvador el primer periódico escrito: "El Semanario Político Mercantil" del presbítero Miguel José Castro y Lara, el cual dejó de publicarse en 1826. En lo que restaría del siglo los temas políticos y comerciales dominarían las páginas de los periódicos. A finales de la centuria, y principios del siglo XX, surgieron diversos medios de prensa literaria como el "Repertorio Salvadoreño" (1891) de la Academia de Ciencias y Bellas Artes de San San Salvador; "El Fígaro" (1893), adonde colaboraba Arturo Ambrogi, y "La Quincena" (1903) de Vicente Acosta, entre otros. Pero es el nicaragüense Román Mayorga Rivas quien aportaría un periodismo ágil y novedoso en "Diario del Salvador" (1895), por lo que es considerado el fundador del periodismo moderno en el país.
Otro nicaragüense que dejaría huella en varios escritores salvadoreños fue Juan Felipe Toruño, promotor de talentos en páginas literarias.

En los años posteriores aparecieron importantes rotativos como Diario Latino, fundado en 1890 por Miguel Pinto padre. "La Prensa" de José Dutriz en 1915, y "El Diario de Hoy" de Napoleón Viera Altamirano en 1936. Merecen también nombrarse los periódicos "Patria" de Alberto Masferrer, así como "La Tribuna", en el que colaboraron varios intelectuales. El año 1966 comenzó a circular "El Mundo". En la época de la guerra y la posguerra, el semanario "Primera Plana" sentó las bases de un periodismo de investigación. "La Crónica" del Dr. José Napoleón González, y el más reciente "Co•Latino", propiedad de una cooperativa de trabajadores, que dirige Francisco Valencia.

En los momentos más actuales, del año 2000 en adelante, han aparecido con bastante dinamismo los medios en línea, es decir, en Internet, como El Faro, Diario1, La Página, El Blog, Solo Noticias y ContraPunto.

Además se ubica entre los primeros 10 países de América de gozar de una buena libertad de prensa según el último informe de Reporteros sin Fronteras de 2016.

A través de una ley general de los deportes,
que entró en vigencia en diciembre de 2007, se ha establecido la regulación de la política deportiva en el país y los organismos responsables para tal efecto. En tal legislación se «declara de interés social y de utilidad pública la organización, promoción y desarrollo del deporte en todo el territorio nacional» (Art. 3). El principal ente encargado de esta tarea es el Instituto Nacional de los Deportes (INDES), que ya había sido creado en 1980. Asimismo, esta ley regula las distintas federaciones que son la máxima autoridad para la disciplina pertinente. Todas deben ser reconocidas por el INDES. En la actualidad se enumeran 43 instituciones de este tipo.
La normativa reconoce también las funciones del Comité Olímpico de El Salvador.

El deporte más popular del país es el fútbol. La Selección Nacional local ha clasificado dos veces al campeonato mundial. A través de su historia, Jorge «Mágico» González ha sido considerado el mejor jugador de esta disciplina. Sin embargo, es la modalidad de fútbol playa la que ha logrado el mayor éxito en torneos internacionales, ya que ocupó el cuarto lugar en la Copa Mundial de Fútbol Playa FIFA 2011. Las playas de la línea costera también han favorecido la práctica del surf, siendo la playa El Tunco en el Departamento de La Libertad el centro de atracción más importante a nivel internacional.

Por otro lado, en Juegos Olímpicos el país ha estado presente desde 1968.
En Juegos Panamericanos el mejor desempeño ha sido en la justa de Río de Janeiro 2007,
destacando la medalla de oro de la marchista Cristina Esmeralda López. Entre otros logros relevantes, el arquero Jorge Jiménez alcanzó la cima del ranking mundial de la FITA en 2007.

En lo relativo a competencias internacionales organizadas por El Salvador, destacan los Juegos deportivos centroamericanos y Juegos Centroamericanos y del Caribe, ambos realizados en dos ocasiones. Asimismo, las respectivas federaciones han desarrollado eventos relativos a su competencia.

La Constitución de El Salvador garantiza el libre ejercicio de todas las religiones. La misma carta fundamental reconoce la personalidad jurídica de la Iglesia católica, mientras que las demás iglesias pueden obtener, conforme a las leyes, el reconocimiento de su personalidad (art. 26). Históricamente el país ha tenido una marcada mayoría católica, de acuerdo a diferentes encuestas, esta realidad ha ido cambiando, en 1995, un 16.8 % de la población se consideraba cristianos evangélicos, mientras que para el año 2008 el porcentaje había aumentado hasta 34.4 %, en contraste la población católica se encuentra en disminución, pasando de un 67.9 % en 1995, hasta un 50.4 % de acuerdo a un sondeo de la Universidad Centroamericana José Simeón Cañas del año 2009 (esta encuesta difiere en el número de cristianos evangélicos, estimándolos en un 38.2 % de la población del país; 2.5 % a pertenecía a otra religión; mientras que el 8.9 % aseveraba no tener religión).

Los grupos cristianos no protestantes en El Salvador son la Iglesia de Jesucristo de los Santos de los Últimos Días, los testigos de Jehová, y la Comunidad de Cristo; y doctrinas no cristianas, como el bahaísmo, islamismo, budismo, judaísmo,
grupos relacionados con el hinduismo, rosacrucismo, movimientos psíquico-espiritualistas de la "Nueva Era", y religión popular o sincrética de tradiciones nativas y catolicismo.




</doc>
<doc id="1151" url="https://es.wikipedia.org/wiki?curid=1151" title="Euclides">
Euclides

Euclides (en griego Ευκλείδης, "Eukleidēs", latín "Euclīdēs") fue un matemático y geómetra griego (ca. 325 a. C.-ca. 265 a. C.). Se le conoce como "el padre de la geometría".

Su vida es poco conocida, salvo que vivió en Alejandría (ciudad situada al norte de Egipto) durante el reinado de Ptolomeo I. Ciertos autores árabes afirman que Euclides nació en Tiro y vivió en Damasco. Era hijo de Naucrates y se barajan tres hipótesis:


Proclo, el último de los grandes filósofos griegos, que vivió alrededor del 450, escribió importantes comentarios sobre el libro I de los "Elementos." Dichos comentarios constituyen una valiosa fuente de información sobre la historia de la matemática griega. Así sabemos, por ejemplo, que Euclides reunió aportes de Eudoxo de Cnido en relación a la teoría de la proporción, y de Teeteto sobre los poliedros regulares.

Su obra "Elementos" es una de las producciones científicas más conocidas del mundo y era una recopilación del conocimiento impartido en el ámbito académico de entonces. En ella se presenta de manera formal, partiendo únicamente de cinco postulados, el estudio de las propiedades de líneas y planos, círculos y esferas, triángulos y conos, etc.; es decir, de las formas regulares. Probablemente ninguno de los resultados de "Los elementos" haya sido demostrado por primera vez por Euclides, pero la organización del material y su exposición, sin duda alguna se deben a él. De hecho, hay mucha evidencia de que Euclides usara libros de texto anteriores cuando escribía "Los elementos," ya que presenta un gran número de definiciones que no son usadas, tales como la de un oblongo, un rombo y un romboide. Los teoremas de Euclides son los que generalmente se aprenden en la escuela moderna. Por citar algunos de los más conocidos:


En los libros VII, VIII y IX de "Los Elementos" se estudia la teoría de la divisibilidad.

La geometría de Euclides, además de ser un poderoso instrumento de razonamiento deductivo, ha sido extremadamente útil en muchos campos del conocimiento; por ejemplo, en la física, la astronomía, la química y diversas ingenierías. Desde luego, es muy útil en las matemáticas. Inspirados por la armonía de la presentación de Euclides, en el siglo II se formuló la teoría ptolemaica del Universo, según la cual la Tierra es el centro del Universo, y los planetas, la Luna y el Sol dan vueltas a su alrededor en líneas perfectas, o sea circunferencias y combinaciones de circunferencias. Sin embargo, las ideas de Euclides constituyen una considerable abstracción de la realidad. Por ejemplo, supone que un punto no tiene tamaño; que una línea es un conjunto de puntos que no tiene ni ancho ni grueso, solamente longitud; que una superficie no tiene grosor, etcétera. En vista de que el punto, de acuerdo con Euclides, no tiene tamaño, se le asigna una dimensión nula o de cero. Una línea tiene solamente longitud, por lo que adquiere una dimensión igual a uno. Una superficie no tiene espesor, no tiene altura, por lo que tiene dimensión dos: ancho y largo. Finalmente, un cuerpo sólido, como un cubo, tiene dimensión tres: largo, ancho y alto. Euclides intentó resumir todo el saber matemático en su libro "Los elementos". La geometría de Euclides fue una obra que perduró sin variaciones hasta el siglo XIX.

De los axiomas de partida, solamente el de las paralelas parecía menos evidente. Diversos matemáticos intentaron sin éxito prescindir de dicho axioma intentándolo deducir del resto de axiomas. Pretendieron presentarlo como un teorema, sin lograrlo.

Finalmente, algunos autores crearon geometrías nuevas basándose en invalidar o sustituir el axioma de las paralelas, dando origen a las "geometrías no euclidianas". Dichas geometrías tienen como característica principal que al cambiar el axioma de las paralelas los ángulos de un triángulo ya no suman 180 grados.












</doc>
<doc id="1152" url="https://es.wikipedia.org/wiki?curid=1152" title="Escocia">
Escocia

Escocia (en inglés y escocés: "Scotland"; en gaélico escocés: "Alba") es la más septentrional de las cuatro naciones constituyentes del Reino Unido. Junto con Inglaterra y Gales, forma parte de la isla de Gran Bretaña, abarcando un tercio de su superficie total; además consta de más de 790 islas. Limita al norte y oeste con el océano Atlántico; al este con el mar del Norte, al sur con Inglaterra y al suroeste con el canal del Norte y el mar de Irlanda. El territorio escocés abarca 78 772 km², y su población se estima en 5 347 600 habitantes en 2014, lo que da una densidad de población de 67,9 habitantes por km². La capital es Edimburgo, mientras que Glasgow es la ciudad más grande, y su área metropolitana concentra un 40 % del total de la población escocesa.

Escocia toma su nombre de «Scotus», término latino que significa «irlandés» (la forma plural es «Scoti», «irlandeses»). Esto hace referencia a los colonizadores gaélicos de Irlanda, país que los romanos inicialmente llamaron «Scotia» (forma femenina de «Scotus»). Los irlandeses que colonizaron la actual Escocia eran conocidos como «Scoti». Los romanos de la Alta Edad Media utilizaban el nombre «Caledonia» para referirse a la actual Escocia.

El Reino de Escocia fue un estado independiente hasta 1707, fecha en la que se firmó el Acta de Unión con Inglaterra, para crear el Reino de Gran Bretaña. La unión no supuso alteración del sistema legal propio de Escocia, que desde entonces ha sido distinto del de Gales, Inglaterra e Irlanda del Norte, por lo que es considerada en el derecho internacional como una entidad jurídica distinta. La pervivencia de unas leyes propias, y de un sistema educativo y religioso diferenciado forman parte de la cultura escocesa y de su desarrollo a lo largo de los siglos.

Surgido en el siglo XIX, el independentismo escocés ha ganado influencia desde finales del siglo XX; representado por el Scottish National Party (SNP, Partido Nacional de Escocia), que aboga por la independencia de Escocia y obtuvo la mayoría absoluta en el Parlamento escocés en las elecciones de mayo de 2011. En 2014, el gobierno escocés y el gobierno conservador de David Cameron llegaron a un acuerdo para plantear un referéndum pactado sobre la independencia escocesa que se celebró el 18 de septiembre de ese mismo año ganando la continuidad en el Reino Unido por 10,6 puntos.

La "Crónica anglosajona" del siglo X es el documento más antiguo en el que aparece el término Scotland, formado a partir del término latino "Scoti", de origen dudoso, empleado como una referencia a los habitantes de Hibernia (la actual Irlanda). La palabra "Scotia", aparecida en el latín vulgar, se empleó solo para referirse a la zona de Escocia en la que se hablaba gaélico; además, este término alternaba con "Albania", procedente del término gaélico para Escocia, Alba. El empleo del término Scotland para referirse a todo el territorio escocés solo se generalizó en la baja Edad Media. En los tiempos modernos el término "Scot" se aplica a todos los habitantes de Escocia, independientemente de su origen étnico, ya que la identidad escocesa es primordialmente cívica y no étnica o lingüística. El término "scot" también se emplea para referirse al idioma escocés, hablado en algunas zonas de los "Lowlands" o Tierras Bajas Escocesas.

La bandera de Escocia o "The Saltire" consta de un aspa o Cruz de San Andrés blanca sobre fondo azul, emblema que también entró a formar parte de la bandera del Reino Unido o "Union Jack" en 1606. Hay muchos otros símbolos de Escocia, oficiales o no, tales como el cardo (la flor nacional), la Declaración de Arbroath, el dibujo del tartán, relacionado con los clanes escoceses, o la bandera del "León Rampante" que aparece en el Estandarte Real de Escocia. El es "Nemo me impune lacessit", que puede traducirse como "Nadie me ofende impunemente", y que a su vez se relaciona con el cardo.

La canción "Flower of Scotland" es popularmente considerada como himno nacional de Escocia, compitiendo con "Scotland the Brave". La primera es la que se emplea en la mayoría de acontecimientos políticos y deportivos, como, por ejemplo, en los encuentros de la selección de fútbol de Escocia, mientras que la segunda se usa para representar a Escocia en los Juegos de la Mancomunidad. Dado que no existe un himno oficial, la disputa continúa abierta, especialmente tras la Descentralización de poderes de 1998, y existen otras canciones candidatas, como "Scots Wha Hae", "A Man's A Man for a'That" o, más recientemente, "I'm Gonna Be (500 Miles)".

La fiesta nacional de Escocia es el "Día de San Andrés", el 30 de noviembre, aunque la "Burns Night" o Noche de Burns, celebrada el 25 de enero en honor al poeta nacional, Robert Burns, tiene un mayor seguimiento. El "Día del Tartán" es otra celebración de invención reciente, y originaria de Canadá. En 2007, el Parlamento de Escocia aprobó el decreto oficial por el que el Día de San Andrés pasaba a ser "bank holiday", día de fiesta oficial.

Se ignora si Escocia estuvo habitada durante el Paleolítico, ya que las sucesivas glaciaciones que cubrieron su actual territorio podrían haber destruido todas las evidencias de asentamientos humanos anteriores al periodo Mesolítico. Se cree que los primeros grupos de cazadores-recolectores llegaron hace unos 11 000 años, cuando los hielos de la primera glaciación comenzaron a retirarse hacia el norte. Los primeros asentamientos aparecieron en el territorio escocés hace aproximadamente 9500 años, y los primeros pueblos hace unos 6000. De este periodo data por ejemplo el asentamiento de Skara Brae, en la más grande de las islas Orcadas, que se encuentra en muy buen estado de conservación, así como otros restos de viviendas, enterramientos y centros rituales del Neolítico encontrados sobre todo en las . Esta abundancia de construcciones que han sobrevivido al paso del tiempo puede deberse a la ausencia de árboles en la zona, que permitió a los pobladores primitivos crear construcciones en la propia roca local.

La historia escrita de Escocia comienza con la romanización del centro-sur de Gran Bretaña (las actuales Gales e Inglaterra, que formaban la provincia de "Britannia"). Los romanos llamaron inicialmente Caledonia ("Tierra de Caledonios") a Escocia, por el inmenso bosque de pinos caledonios que se extendía de norte a sur y de este a oeste por todo el país. El principal pueblo asentado en aquella época en la región escocesa era el de los pictos, así llamados, aparentemente, por su costumbre de pintarse el cuerpo. Los escotos, por su parte, eran un pueblo de origen irlandés, también conocido como dalriadas, que se estableció en el oeste de Escocia. Durante este periodo existían por lo tanto dos reinos diferenciados: el del oeste de Escocia, Scotland, y el reino picto del este, Alba.

La romanización de Escocia fue un largo proceso con multitud de interrupciones: en el año 83 a. C., el general Cneo Julio Agrícola derrotó a los caledonios en la batalla del Monte Graupio, lo que permitió la construcción de una cadena de fortificaciones conocida como "Gask Ridge", cerca de la Falla de las Highlands (adentrándose más al norte, como lo testimonia el fuerte romano de Cawdor); poco después, sin embargo, los romanos se retiraron a los "Southern Uplands" ("Mesetas del Sur"), es decir, al tercio más meridional de Escocia, y comenzaron la construcción del Muro de Adriano para controlar a las tribus de la zona. Esta línea marcó durante casi todo el periodo de ocupación romana el límite septentrional del Imperio romano, pese a la construcción, más al norte aún, del Muro de Antonino. Esta frontera solo pudo ser defendida durante breves períodos, de los cuales el más tardío tuvo lugar entre los años 208 y 210, durante el mandato del emperador Septimio Severo. Con posterioridad se creó en el territorio la provincia romana de Valentia. En total, la ocupación de estas zonas de Escocia por parte de los romanos se extendió durante no más de 40 años, aunque la influencia latina en la parte más meridional, sobre todo entre las tribus de origen bretón, fue más duradera.

El reino de los pictos (con sede en Fortriu hacia el siglo VI) experimentó un importante desarrollo durante la Edad Media, quizás como respuesta al propio imperialismo romano. Un hito importante en esta lucha por la supervivencia y la ampliación fue la batalla de Dunnichen (685), en la que los pictos derrotaron a las tribus de Northumbria durante el reinado de Bridei III (671-693). El reinado de Oengus I (732-761) fue igualmente un periodo de consolidación para el reino picto. El reino de los pictos ocupaba en esta época, según la descripción de Beda el Venerable, una extensión similar a la que después ocuparía el reino de los escotos durante el reinado de Alejandro I (1107-1124). Sin embargo, ya en el siglo X, el reino picto fue dominado por una cultura de origen gaélico, estableciendo el mito de la ascendencia irlandesa de la dinastía real de Cináed mac Ailpín (Kenneth MacAlpin o Kenneth I). En los siglos siguientes, partiendo desde su territorio original en el este de Escocia, al norte del fiordo de Forth y al sur del río Oykel, el reino picto logró controlar las tierras del norte y del sur. Hacia finales del siglo XII, los reyes de Alba habían añadido a su territorio el área angloparlante del sureste de Escocia y dominaban también las zonas de Galloway y Caithness; al final del siglo XIII, este reino se había extendido hasta alcanzar la extensión aproximada de la Escocia actual.
Sin embargo, ciertos procesos culturales y económicos iniciados en el siglo XII iban a hacer que durante la Baja Edad Media Escocia adquiriera rasgos bien diferentes. El principal impulso a esta transformación se produjo durante el reinado de David I de Escocia, que inició lo que se conoce como la Revolución davidiana. Esta es la época en la que se introduce el feudalismo en Escocia, se reorganizan las formas de gobierno y se fundan las primeras ciudades y pueblos con fueros propios (los llamados burghs). Estas instituciones, así como la inmigración de caballeros y clérigos franceses y anglo-franceses, facilitaron un proceso de "ósmosis cultural", durante el cual los territorios meridionales y costeros del reino de Alba se convirtieron en angloparlantes, como ya lo eran muchas de las tierras recién conquistadas en el sur; el resto del reino, en cambio, siguió conservando la lengua gaélica.

La muerte de Alejandro III en 1286, seguida por la de su nieta Margarita I, rompió la línea sucesoria de la dinastía reinante. Esto llevó a la intervención de Eduardo I de Inglaterra, quien puso en el trono a su protegido Juan de Balliol. Cuando su relación se deterioró, se produjo un intento de conquista por parte de Inglaterra, que fue rechazado por William Wallace en la Guerras de independencia de Escocia. Por su parte, Robert the Bruce, conde de Carrick, se proclamó Rey de Escocia con el nombre de Roberto I de Escocia. La guerra con Inglaterra duró varias décadas, y la guerra civil entre los partidarios de la dinastía de "Robert the Bruce" (quien aseguraba ser descendiente de David I) y los partidarios de los Balliol, apoyados por Inglaterra, duró hasta mediados del siglo XIV. Pese a que la dinastía Bruce fue la vencedora, la ausencia de descendientes de su hijo David II permitió a su sobrino, Roberto II, ascender al trono y situar en él a la dinastía Estuardo. Los Estuardo gobernaron Escocia durante el resto de la Edad Media, un periodo de prosperidad que va desde el final del siglo XIV hasta la Reforma Protestante, pasando por el Renacimiento. Pese a ello, las luchas con Inglaterra continuaron, así como la división interna entre las Tierras Altas o "Highlands" y las Tierras Bajas o "Lowlands".

La Edad Moderna se abrió en la historia escocesa con el "Rough Wooing" o "cortejo violento" (1544-1551), una serie de ofensivas militares intermitentes mediante las cuales Inglaterra pretendía forzar un casamiento entre María I Estuardo y Eduardo VI de Inglaterra, objetivo que finalmente no logró. Además, el siglo XVI es el siglo de la Reforma Protestante, encabezada en Escocia por figuras como John Knox y apoyada desde Inglaterra.

En 1603, Jacobo VI de Escocia y I de Inglaterra heredó el trono de Inglaterra y se convirtió en Jaime I de Inglaterra. Sin embargo, con la excepción de un breve periodo conocido como "Protectorado", Escocia continuó siendo un estado independiente, aunque sacudido por constantes enfrentamientos entre la corona y los "Convenanters", sobre la forma de gobierno de la Iglesia. Tras la Revolución Gloriosa y el derrocamiento del católico Jaime VII de Escocia por Guillermo III de Inglaterra y su esposa María II (1688), Escocia amenazó con elegir a un rey protestante distinto al de Inglaterra. En 1707, sin embargo, tras las amenazas inglesas de cerrar el comercio con Escocia, se firmó el Acta de Unión, que certificaba la creación del Reino de Gran Bretaña.

Pese a esta unificación de los dos reinos, los defensores de la Casa de Estuardo, conocidos como jacobitas, seguían teniendo influencia en las Tierras Altas y en la zona noreste del país, especialmente entre los no presbiterianos. Sin embargo, los levantamientos jacobitas producidos en 1715 y 1745 no lograron apartar del trono británico a la Casa de Hannover. Dichos levantamientos sirvieron además como excusa para el desplazamiento masivo de los habitantes de las Tierras Altas o "Highlands", en lo que se conoce como "Highland Clearances".

La Ilustración o Escuela escocesa fue un movimiento cultural del siglo XVIII caracterizado por la destacada producción intelectual, científica, y cultural desarrollada en Escocia, sobre todo a partir de la segunda mitad de siglo. Usualmente vista como una Edad de Oro en la historia de Escocia, este movimiento significó la eclosión cultural de los escoceses, internacionalizándose y convirtiendo a Escocia en uno de los principales focos culturales de Europa.

Entre los productos más destacados de este movimiento se encuentran los logros en filosofía, economía, geología, ingeniería y sociología. Algunas de las principales figuras de la Ilustración escocesa fueron los filósofos David Hume, Francis Hutcheson y Thomas Reid, el economista Adam Smith, el antropólogo Lord Kames, Adam Ferguson, John Playfair, el químico Joseph Black, el geólogo James Hutton, el ingeniero James Watt y el lingüista Lord Monboddo.

Tras la Ilustración y la Revolución industrial, Escocia se transformó en uno de los centros comerciales, intelectuales y culturales de Europa. Glasgow y Edimburgo, sobre todo, se desarrollaron rápidamente a finales del siglo XVIII y durante el siglo XIX, con el paréntesis trágico de una gran hambruna (1846-1857) consecuencia de la misma plaga de tizón tardío (phytophthora infestans) que provocó la gran hambruna irlandesa (1845-1849). Este suceso, que afectó sobre todo a las tierras altas, provocó una gran emigración, pese a lo cual surgió una industria pesada en las riberas del río Clyde de construcción de navíos que transformó a Glasgow en la "Segunda ciudad del Imperio Británico" después de Londres. 

La situación empeoró tras la Primera Guerra Mundial, en la que murieron un gran número de escoceses, provenientes sobre todo de las "Highlands" o tierras altas, pero en especial después de la Segunda Guerra Mundial, tras la cual la situación económica de Escocia empeoró muy rápidamente con la desaparición de un gran número de industrias que ya no eran competitivas en el mercado internacional. Sólo en las últimas décadas del siglo XX logró el país apuntar una recuperación económica y cultural, gracias al surgimiento de nuevos servicios financieros y del sector electrónico (en lo que se conoce como Silicon Glen), así como a los beneficios del petróleo y gas del mar del Norte.

El 1 de marzo de 1979 se celebró el referéndum escocés de 1979, que fue la primera consulta popular para la reinstauración del Parlamento escocés (cámara legislativa propia), tras su integración en la británica en 1707. La respuesta afirmativa no obtuvo la mayoría cualificada necesitada para validar dicha propuesta de la Ley de Escocia de 1978.

El 11 de septiembre de 1997 se realizó el referéndum escocés de 1997 para consultar a la ciudadanía escocesa sobre lo que se conoció como la "devolución" del Parlamento. El resultado fue afirmativo y al año siguiente se promulgaría la Ley de Escocia de 1998, por la que el Gobierno del Reino Unido concedía mayores niveles de soberanía a Escocia, restablecía el Parlamento Escocés, les permitía tener gobierno propio y devolvía a Edimburgo, simbólicamente, la Piedra de Scone. No obstante, todavía se mantenía como nación constituyente y región administrativa del Reino Unido de Gran Bretaña e Irlanda del Norte.

El 18 de septiembre de 2014 se celebró otro referéndum, para decidir si Escocia debería ser un país independiente del Reino Unido. Tras un acuerdo entre el Parlamento Escocés y el Parlamento del Reino Unido, la pregunta formal de este referéndum fue: "¿Debe Escocia ser un país independiente? Sí o No". El resultado de la consulta obtuvo un 55,3 % de los votos para el "No". Pocos días antes de producirse el referéndum, algunas encuestas indicaban una pequeña ventaja para el "Sí".
Sin embargo, los resultados del referéndum celebrado el 23 de junio de 2016 sobre la permanencia o no del Reino Unido en la UE han vuelto a plantear la opción de un nuevo plebiscito sobre la independencia de Escocia debido a que, a diferencia de Inglaterra y Gales, el voto mayoritario en esta región fue favorable a la permanencia dentro de la Unión Europea.

Dado que Escocia es uno de los países constituyentes del Reino Unido, el jefe de estado escocés es el monarca británico, es decir, la reina Isabel II del Reino Unido desde su coronación en 1952. En Escocia, la reina utiliza el título de "Queen Elizabeth" («Reina Isabel») en vez del de «Isabel II», dado que nunca ha habido una reina «Isabel I de Escocia».

Constitucionalmente, el Reino Unido es un Estado unitario con un Parlamento y un Gobierno soberanos. Tras la descentralización de poderes aprobada en referéndum en 1997, Escocia goza de un autogobierno limitado: el Parlamento Británico sigue conservando la capacidad de reformar, cambiar, ampliar o abolir el sistema de gobierno escocés a voluntad, por lo que puede considerarse que el Parlamento escocés no es realmente soberano.

El poder ejecutivo del Reino Unido recae en lo que jurídicamente se denomina "Queen-in-Council" ("La reina y sus consejeros"), mientras que el poder legislativo lo ostenta el "Queen-in Parliament" ("La reina y el Parlamento"). En la práctica política, el poder ejecutivo lo ostenta el Gobierno del Reino Unido, con el primer ministro a la cabeza, y el legislativo, el Parlamento del Reino Unido. Bajo el régimen de la descentralización de poderes, ciertas áreas del legislativo y el ejecutivo han sido transferidas al Gobierno de Escocia y al Parlamento de Escocia, en Holyrood (Edimburgo). El Parlamento del Reino Unido, por su parte, mantiene su poder sobre los impuestos, seguridad social, ejército, relaciones internacionales, medios de comunicación y otras áreas explícitamente indicadas en la Scotland Act de 1998 como «materias reservadas».

El Parlamento escocés tiene autoridad legislativa para todas aquellas áreas relacionadas con Escocia, incluso para variar levemente los impuestos, aunque nunca ha ejercido dicho poder. También puede remitir asuntos relacionados con las competencias devueltas al Parlamento británico, para ser consideradas en el conjunto de la legislación del Reino Unido. En determinados asuntos, la legislación escocesa ha optado por soluciones distintas a las adoptadas en el conjunto del estado: por ejemplo, la educación universitaria y los cuidados para ancianos son gratuitos para los residentes de Escocia y comunitarios europeos, mientras que en el resto de Reino Unido se deben pagar unas tasas por los mismos servicios. Escocia fue también el primer país del Reino Unido en prohibir el tabaco en espacios públicos.

El Parlamento escocés es unicameral, y está compuesto por 129 miembros, 73 de los cuales representan a un distrito electoral o "constituency", y son elegidos por el sistema de escrutinio uninominal mayoritario, los restantes 56 miembros son elegidos en solo ocho distritos electorales, mediante el sistema de representación proporcional; los cargos electos tienen una duración de cuatro años. Tras la elección del Parlamento, este propone a uno de sus miembros para ser nombrado Ministro Principal de Escocia ("First Minister of Scotland" o "Prìomh Mhinistear na h-Alba") por la reina. El resto de los ministros también son propuestos por el Parlamento y aprobados por la Reina, y forman, junto con el Ministro Principal de Escocia, el Gobierno de Escocia, es decir, el poder ejecutivo escocés.

En las elecciones al Parlamento escocés de 2011, el Partido Nacional Escocés (Scottish National Party o SNP) obtuvo la mayoría absoluta, a diferencia de las elecciones de 2007 donde el SNP obtuvo la mayoría simple liderando en un Gobierno en minoría. El líder del Partido Nacional Escocés, Alex Salmond, fue elegido nuevamente como Ministro Principal de Escocia, conservando el cargo luego de obtenerlo en las elecciones de 2007. En 2014 Salmond fue sustituido por Nicola Sturgeon. En las elecciones al Parlamento escocés de 2016, el Partido Nacional Escocés (Scottish National Party o SNP) perdió la mayoría absoluta, aunque logró liderar un Gobierno en minoría. La líder del Partido Nacional Escocés, Nicola Sturgeon fue elegida de nuevo Ministra Principal de Escocia.

Otros partidos representados en el Parlamento escocés son los laboristas con 24 escaños, el Partido Conservador con 37 escaños, los conservadores 31, y el Partido Liberal Demócrata con 5 escaños. El Partido Verde Escocés, codirigido por Patrick Harvie, Maggie Chapman, Hap y Dona tienen a su haber 7 asientos.

Escocia tiene además representación en la Cámara de los Comunes del Reino Unido, con 59 representantes elegidos en función de los distritos electorales escoceses. La "Scotland Office" u "Oficina de Escocia", dirigida por el Secretario de Estado de Escocia, es el departamento del Gobierno Británico dedicado a tratar los asuntos relacionados con Escocia. Desde mayo de 2010, el cargo de Secretario de Estado para Escocia lo ocupa Michael Moore.

Las divisiones históricas de Escocia son muy variadas, e incluyen los condados, ducados, "burghs" (ciudades independientes con representación en el Parlamento de Escocia) y parroquias. En 1975 se puso en funcionamiento una división en regiones y distritos que sin embargo fue abolida en 1996. Desde entonces, a efectos administrativos Escocia está dividida en 32 "council áreas" o "concejos", administradas por una autoridad unitaria responsable de todos los servicios locales. Los "Community councils" ("concejos comunitarios"), por su parte, son organizaciones informales que representan a determinadas subdivisiones dentro del concejo.

Existen otras subdivisiones distintas de Escocia para distintos fines. Así, hasta el 1 de abril de 2013, los sistemas de bomberos y de policía todavía se basaban en la división en regiones introducida en 1975. Para el sistema sanitario, para los distritos postales así como para otras organizaciones gubernamentales y no gubernamentales, se mantienen subdivisiones geográficas diversas de larga tradición.

El estatus de ciudad en el Reino Unido viene determinado por una patente real. Hay siete ciudades en Escocia: Aberdeen, Dundee, Edimburgo, Glasgow, Inverness, Stirling y Perth.

Las leyes escocesas se basan en el Derecho romano, combinando elementos tanto del Derecho civil (que puede rastrearse hasta el "Corpus Iuris Civilis" latino), y del Derecho anglosajón, con origen en la Edad Media. El tratado de unión con Inglaterra de 1707 garantizaba la continuidad de dos sistemas legales distintos en Escocia, y en Inglaterra y Gales. Antes de 1611, existía una gran diversidad de leyes regionales en Escocia, entre las que destacaba la "Ley Udal", vigente en las Órcadas y en las islas Shetland, y que se derivaba del antiguo sistema legal noruego. Otros sistemas legales se derivaban, en cambio, de las leyes celtas o de las leyes de Brehon, y permanecieron vigentes hasta el siglo XIX. El Derecho escocés tiene, por otra parte, una peculiaridad que lo hace único, al incluir un tercer veredicto posible además de "inocente" o "culpable": el de "no probado".

La ley escocesa establece tres tipos de tribunales responsables de administrar justicia: tribunales civiles, criminales y heráldicos. El máximo ámbito de administración de justicia civil es el "Court of Session", aunque pueden realizarse apelaciones civiles a la Cámara de los Lores del Reino Unido. El "High Court of Justiciary", por su parte, es el máximo tribunal penal. Ambos se encuentran situados en la Parliament House, antigua ubicación del Parlamento de Escocia. La principal instancia civil y penal sin embargo son los "sheriff courts": hay 49 "sheriff courts" activos en Escocia. Los Tribunales de Distrito fueron creados en 1975 para ofensas menores. Por último, el "Court of the Lord Lyon" regula el derecho heráldico.

Escocia ocupa aproximadamente el tercio superior de la isla de Gran Bretaña, al noroeste del continente europeo. En total, su territorio abarca 78 772 km². La única frontera de Escocia en tierra firme es la que le une por el sur con Inglaterra, y que mide alrededor de 96 km, entre el río Tweed en la costa este y el fiordo de Solway en la oeste. El océano Atlántico rodea el norte y oeste de Escocia, mientras que al este se encuentra el mar del Norte. Irlanda se encuentra a solo 30 km desde la península de Kintyre, mientras que Noruega queda a 400 km al noreste, las islas Feroe a 310 km e Islandia a 798 km al noroeste. El centro geográfico de Escocia, tradicionalmente, se sitúa a pocos kilómetros de Newtonmore, en Badenoch, al norte de las zonas más pobladas, aunque existen diversas opiniones al respecto, dependiendo del modo empleado para las mediciones, o de si se toman en consideración o no las islas escocesas.

La extensión territorial actual de Escocia es muy similar a la establecida en el Tratado de York de 1237 entre Inglaterra y Escocia y en el Tratado de Perth de 1266 entre Escocia y Noruega. Existen algunas excepciones: la Isla de Man, que antes era territorio escocés, es ahora una Dependencia de la Corona británica; las islas Órcadas y Shetland fueron adquiridas a Noruega en el siglo XV; mientras que Rockall, un pequeño islote rocoso en el Atlántico, fue anexionado al Reino Unido primero y a Escocia después por el Acta de la Isla de Rockall de 1972. Sin embargo, la legalidad de esta anexión ha sido puesta en tela de juicio por Irlanda, Dinamarca e Islandia, y probablemente no tiene efectos en el derecho internacional.

Todo el territorio escocés estaba cubierto por el hielo durante las glaciaciones del Pleistoceno, lo que tiene importantes consecuencias en su paisaje. Desde el punto de vista geológico, Escocia está subdividida en tres zonas: las "Tierras Altas" y las islas se sitúan al noroeste de la falla de las Tierras Altas, que va desde la isla de Arran hasta Stonehaven. Esta parte de Escocia está compuesta fundamentalmente de rocas antiguas procedentes de los periodos Cámbrico y Precámbrico, que fueron elevadas durante la posterior Orogenia caledonia. Esta base rocosa está entrecruzada por múltiples intrusiones ígneas de épocas más recientes, cuyos vestigios han formado macizos montañosos como los Cairngorms o los Cuillins, en Skye. Una excepción significativa a lo anterior la constituyen los estratos de arenisca conocidos como "Old Red Sandstone", en los que se han encontrado fósiles, sobre todo alrededor del fiordo de Moray. Las "Highlands" o Tierras Altas son generalmente montañosas y están divididas por el Great Glen o "Gran Valle". Las mayores elevaciones de las islas británicas se encuentran aquí, incluido el Ben Nevis, el pico más alto, con una altitud de 1344 metros. Escocia consta de más de 790 islas, divididas en cuatro grupos principales: Shetland, Órcadas, y Hébridas, las cuales a su vez se dividen en Hébridas Interiores y Hébridas Exteriores. Además, en esta zona se encuentran numerosas fuentes de agua dulce, incluyendo el lago Ness o el lago Lomond. Algunas partes de la costa consisten en "machair", un tipo de terreno consistente en dunas cubiertas de pasto.

El terreno conocido como "Central Lowlands" o también "Central Belt" es una fosa tectónica compuesta fundamentalmente por formaciones del Paleozoico. Algunos de los estratos sedimentarios de esta zona han resultado de gran importancia económica, ya que en ellos se encuentran el carbón y el hierro en los que se basó la Revolución Industrial escocesa. Esta área ha experimentado una intensa actividad volcánica, como demuestra Arthur's Seat, una cima cercana a Edimburgo que es el resto de un cono volcánico más elevado que estuvo activo durante el periodo Carbonífero hace unos 300 millones de años. Conocida también como Midland Valley, esta área es relativamente llana, aunque existen abundantes colinas como Ochil Hills o Campsie Fells.

Las llanuras meridionales o "Tierras Bajas" están compuestas por una serie de colinas de unos 200 km de longitud, alternados con anchos valles. Se encuentran al sur de una segunda falla que va desde Stranraer hasta Dunbar. Esta zona está compuesta fundamentalmente por depósitos del silúrico, hace 400 o 500 millones de años.

Las fallas, valles o "glens" que cruzan Escocia de este a oeste albergan frecuentemente lagos o "lochs", tales como el "lago Ness", que se sitúa en el Gran Glen, o el lago Lomnd (el mayor lago de agua dulce del Reino Unido), en la falla de las Tierras Altas. Además, Escocia también está cruzada por ríos que fluyen hacia el océano Atlántico o hacia el mar del Norte, y que a menudo dan lugar a fiordos en su desembocadura, tales como el fiordo de Clyde, el fiordo de Forth o el fiordo de Tay. Los ríos más largos de Escocia son el río Tay (193 km), el Spey (172 km), el Clyde (171 km) y el Tweed (156 km).

El clima de Escocia es templado y oceánico, y tiende a ser muy variable. Está atemperado por la corriente del Golfo proveniente del océano Atlántico, y por ello tiene inviernos mucho más suaves (aunque también veranos más templados y húmedos) que otras áreas de latitud similar, como Oslo o Moscú. Sin embargo, las temperaturas son generalmente más bajas que en el resto del Reino Unido: la températura histórica más baja registrada en el país son los -27,2 °C (–16,96 °F) registrados en Braemar, en los Montes Grampianos, el 11 de febrero de 1895 y el 10 de enero de 1982, así como en Altnaharra, en las "Highlands", el 30 de diciembre de 1995. Las máximas en invierno rondan los 6 °C (42,8 °F) en las Tierras Bajas, y las máximas en verano promedian 18 °C (64,4 °F). La temperatura más alta registrada alcanzó los 32,9 °C (91,22 °F) en Greycrook, en los Scottish Borders, un 9 de agosto de 2003.

En general, el oeste de Escocia es más cálido que el este, debido a la influencia de las corrientes marinas, y a las temperaturas más bajas del mar del Norte. Tiree, en las Hébridas Interiores, es uno de los lugares más soleados del país: tuvo 329 horas de sol en mayo de 1975. Las precipitaciones varían enormemente a través de Escocia. El oeste de las "Highlands" es la zona más lluviosa, con más de 3000 milímetros anuales. En cambio, gran parte de Escocia recibe menos de 800 mm. Las nevadas no son habituales en las Tierras Bajas, pero sí en zonas de mayor altitud. Braemar experimenta una media de 59 días de nieve al año, mientras que las zonas de la costa tienen una media de menos de 10 días.

La fauna y flora de Escocia es la típica del noroeste de Europa, aunque varios grandes mamíferos, como el oso pardo, el lobo, el uro, el tarpán, el lince, el castor, el reno, el alce o la morsa fueron cazados hasta la extinción en la época histórica. Existen todavía importantes poblaciones de focas y zonas de anidación de aves marinas, como el alcatraz común. El águila real es casi un símbolo nacional, junto con el águila de cola blanca, el águila pescadora o el milano real, que han sido recientemente reintroducidos en Escocia después de haber sido perseguidos hasta la extinción.

Una población de Plectrophenax nivalis acude en verano a las cumbres montañosas de Escocia, en las que durante el invierno también pueden observarse perdices, liebres y armiños en su pelaje invernal. Todavía se conservan ciertos bosques de pinos en los que habita el "Loxia scotica", la única ave endémica de Gran Bretaña; el mismo hábitat es también propicio para el urogallo y el gallo lira, el gato montés, la ardilla roja y la marta.

Cabe mencionar, por su gran difusión mundial, la leyenda contemporánea del Monstruo del lago Ness, relacionada con la criptozoología y la pseudociencia (y alimentada como reclamo turístico por las autoridades locales).

La flora del país es muy variada, con abundancia de árboles caducifolios y coníferas y especies propias del páramo y la tundra. Sin embargo, la plantación comercial a gran escala de especies no nativas de coníferas, y la utilización de los páramos septentrionales para la cría de ganado y las actividades deportivas (principalmente la caza de ciervos y urogallos), han tenido un importante impacto en la distribución de las especies autóctonas de plantas y animales. Un árbol situado en Perthshire, el Tejo de Fortingall, un ejemplar de tejo europeo de entre 2000 y 5000 años de antigüedad, es probablemente el ser vivo más viejo de Europa y con seguridad el del Reino Unido. La flor nacional es el cardo, que aparece en el Escudo del Reino Unido y que también puede relacionarse simbólicamente con el lema de Escocia, "Nemo me impune lacessit".

A lo largo de los siglos, la cultura de Escocia se ha moldeado con la amalgama de distintos elementos. Existe una importante actividad artística, tanto musical como dramática y literaria, influida poderosamente por fuentes tradicionales escocesas, aunque también abierta a influencias externas, en especial europeas. La música ocupa un importante lugar en la cultura escocesa. El instrumento tradicional escocés más destacable es la gaita, en particular la gaita de las Highlands, un instrumento de viento consistente en uno o más tubos sonoros alimentados por una reserva de aire contenida en una bolsa. El "Clàrsach" o arpa celta, los violines y el acordeón también son instrumentos tradicionales escoceses, especialmente los dos últimos, que forman parte de una típica banda para danzas tradicionales escocesas. Los emigrantes escoceses llevaron consigo muchas de estas formas tradicionales de música, que influyeron en sus países de acogida, por ejemplo en la música country estadounidense. En el panorama musical moderno, existen muchas bandas y artistas originarios de Escocia, tales como Annie Lennox, Belle & Sebastian, Primal Scream, Travis, Biffy Clyro, Franz Ferdinand o Snow Patrol.

La televisión nacional es "BBC Scotland" ("BBC Alba" en gaélico), que forma parte de la British Broadcasting Corporation, el canal público del Reino Unido. Además de dos canales de televisión, la BBC también posee canales nacionales de radio: "BBC Radio Scotland" y "BBC Radio nan Gaidheal", entre otros. Las principales televisoras privadas en Escocia son la STV y Border Television. También existen periódicos específicos del ámbito escocés, como el "Daily Record", el "The Herald" (publicado en Glasgow) o el "The Scotsman". Entre los periódicos de difusión local o regional destacan el "The Courier", publicado para Dundee y el este de Escocia, y el "Press and Journal", para Aberdeen y el norte.

La prenda tradicional escocesa es el "kilt", la mal llamada "falda escocesa" —término que ofende a los escoceses—. El "kilt" suele estar hecho de lana, con un diseño de tartán que —según suele decirse— se asocia a un determinado clan escocés. Cada escocés recibe un "kilt" a muy temprana edad, y lo utilizará en ocasiones especiales, como bodas, bautizos, comuniones... El "kilt" se enrolla alrededor de la cintura, y cubre la parte inferior hasta la altura de las rodillas; además, dado que no tiene bolsillos, puede complementarse con un bolso especial denominado "sporran". En contra de la creencia popular de que bajo el "kilt" no debe vestirse ropa interior, lo cierto es que no hay ninguna norma establecida al respecto.

Las lenguas habladas en la actualidad o en el pasado en Escocia se dividen en dos familias: lenguas celtas y lenguas germánicas. La única lengua celta que todavía se conserva en Escocia es el gaélico escocés, hablado en algunas zonas de las "Highlands" y en las Islas Hébridas (zonas conocidas como "Gàidhealtachd"), pero que anteriormente se hablaba en zonas mucho más amplias, como atestigua la toponimia. Una variante del gaélico se hablaba también en la zona suroeste de Escocia, alrededor de Galloway, y también en Annandale y Strathnith, pero ha desaparecido. Ambas lenguas provienen del gaélico antiguo, descendiente a su vez del gaélico primitivo. Según el censo de Escocia de 2001, aproximadamente un 1% de la población total son hablantes de gaélico escocés.

Además, en la Escocia actual se hablan dos lenguas germánicas: el escocés y el inglés de Escocia. El escocés (en inglés, "Scots" o "Lowland Scots") se habla en el sur de Escocia, en la zona conocida como Tierras Bajas. Proviene de una variante septentrional del denominado inglés medio conocida como "escocés antiguo". Según el censo de 2001, aproximadamente un 30 % de la población se consideraba hablante fluido de "scots". El inglés de Escocia, por su parte, es el dialecto estándar del idioma inglés hablado en Escocia. En él pueden encontrarse influencias del escocés y del gaélico escocés. La variante más septentrional constituye un dialecto diferenciado, el inglés de las Highlands, más influido aún por el gaélico escocés.

La literatura escocesa incluye los textos escritos en Escocia, en inglés, gaélico escocés, escocés, francés o latín. El considerado "poeta nacional", Robert Burns, escribió tanto en escocés como en inglés, aunque gran parte de su obra está escrita en una versión simplificada del escocés accesible para un público más amplio. Otros escritores escoceses de renombre internacional son Sir Walter Scott y Arthur Conan Doyle, cuyas obras tuvieron una repercusión internacional a finales del siglo XIX. James Matthew Barrie, autor de "Peter Pan", fue el creador del movimiento conocido como "escuela de Kailyard", también a finales del siglo XIX, que volvió a poner de moda la fantasía y el folclore en la literatura. Esta tradición literaria ha sido considerada por algunos críticos como un freno a la evolución de la literatura escocesa, ya que se centraba en una imagen pastoril e idílica de Escocia. Algunos novelistas modernos, como Irvine Welsh (autor de "Trainspotting"), han optado por reflejar las realidades más crudas de la vida contemporánea en las ciudades escocesas, utilizando para ello el inglés de Escocia.

Desde la Reforma Protestante de Escocia en 1560, la Iglesia de Escocia, también conocida como "The Kirk", se convirtió en la iglesia nacional de Escocia. Es una Iglesia protestante y calvinista con un sistema de organización presbiteriano, y disfruta de independencia del Estado. Alrededor del 12 % de los habitantes de Escocia eran miembros de la Iglesia de Escocia en 2005, mientras que en 2001 un 40 % se declaraba afiliada a ella. La Iglesia opera con una estructura de parroquias locales, de forma que cada comunidad escocesa tiene su propia congregación. Escocia también tiene una importante población católica, en especial en el oeste. Tras la Reforma Protestante, el catolicismo sobrevivió en la zona de las "Highlands" y en algunas islas como Uist y Barra, y se fortaleció durante el siglo XIX gracias la inmigración de Irlanda. Otras denominaciones religiosas cristianas en Escocia incluyen la Iglesia Libre de Escocia y la Iglesia episcopaliana de Escocia.

El Islam es la religión no cristiana más importante de Escocia, con aproximadamente 50 000 fieles (menos de un 1 % del total). También hay congregaciones del judaísmo, hinduismo y sijismo, especialmente en Glasgow. El monasterio de Kagyu Samyé Ling, cerca de Eskdalemuir, inaugurado en 1967, contiene el mayor templo budista de Europa Occidental. En el censo de 2001, el 28% de la población decía no profesar ninguna religión.

El sistema educativo escocés siempre ha sido distinto al del resto del Reino Unido, con un énfasis característico en la educación general. Escocia fue, después de Esparta, el primer lugar en diseñar un sistema de educación pública general. La escolarización se volvió obligatoria por primera vez con el Acta de Educación de 1496, y en 1561, la Iglesia de Escocia diseñó un programa para la reforma espiritual, que incluía la creación de una escuela en cada parroquia. La educación siguió siendo un asunto más de la Iglesia que del Estado hasta el Acta de Educación de 1872.

Los niños de 3 y 4 años tienen derecho en Escocia a guardería gratuita, con un "marco curricular para niños de 3-5 años". La educación primaria formal comienza aproximadamente a los 5 años y dura siete (P1-P7); la "guía 5-14" establece el marco curricular correspondiente para esta etapa. Hoy en día, los niños escoceses deben realizar un examen a los 15 o 16 años, tras el cual pueden elegir seguir en la escuela y estudiar para los exámenes de Acceso, Intermedios, Superiores o Avanzados. Un pequeño número de estudiantes de escuelas privadas puede seguir el sistema educativo inglés en vez del escocés.

Hay 14 universidades en Escocia, algunas de las cuales se encuentran entre las más antiguas del mundo. El país produce el 1 % de las publicaciones científicas del mundo con tan solo el 0,1 % de la población, y las instituciones de educación superior son responsables del 9 % de las exportaciones del sector servicios de Escocia.

La gastronomía de Escocia comparte muchas de las características de la cocina inglesa, pero con algunos rasgos y alimentos propios, derivados a veces de su historia y de las influencias foráneas. En general, la cocina escocesa se caracteriza por su simplicidad, empleando los productos naturales autóctonos (lácteos, carne, pescado, frutas y verduras) y renunciando a las especias y hierbas.

Algunos de los platos tradicionales escoceses son el "Scotch broth" o "caldo escocés", hecho con cebada, carne y verduras; el "porridge" o papilla de avena, o los pasteles de carne, en especial el "Scotch pie", relleno de carne de cordero. Algunos de estos platos, como el "porridge" o los "oatcakes" (pasteles de avena) pueden tener su origen en el carácter nómada de los escoceses originarios, que llevaban consigo siempre una bolsa de avena para poder comer. También el "haggis", considerado el "plato nacional escocés", pudo surgir originalmente al transportar carne en una tripa de cerdo o cordero. El "haggis" es similar a una morcilla, aunque con carne de cordero o incluso de ciervo, y se come tradicionalmente durante la "Cena de Burns", el 25 de enero.

En los primeros años del siglo XXI, la cocina escocesa ha tenido un cierto "Renacimiento": en 2006, nueve de sus restaurantes tenían alguna estrella de la Guía Michelín, y abundan los restaurantes que combinan los elementos tradicionales con las innovaciones de la cocina contemporánea. Además, todas las principales ciudades escocesas albergan restaurantes de cocina internacional (china, italiana, mexicana, india...).

La bebida internacionalmente más reconocida de Escocia es el whisky, hasta el punto de que en Estados Unidos se lo denomina simplemente "Scotch", y en Inglaterra el término "whisky" implica su origen escocés, salvo que se indique lo contrario. El origen del whisky en Escocia parece remontarse al siglo IV o V, cuando los monjes del continente trajeron consigo la destilación. Durante siglos la producción de whisky escocés se mantuvo estable, pero su explosión definitiva se produjo en el siglo XIX, cuando se desarrollaron nuevos modos de producción, y aprovechando la plaga de filoxera que asoló los viñedos franceses y españoles en 1880.

También la cerveza es una bebida popular entre los escoceses: las "ales" de Escocia se caracterizan por su color oscuro y su sabor a malta. Algunas de las marcas de cerveza más conocidas de Escocia son Belhaven, Tennents o Caledonian, aunque existen muchas otras "ales" de distribución local o regional.

Entre las bebidas no alcohólicas, la más característica de Escocia es Irn-Bru, refresco que compite en popularidad con la Coca-Cola.

La población de Escocia según el censo de 2001 era de 5 062 011 habitantes, que se han elevado a unos 5 347 600 según la estimación del 30 de junio de 2014, convirtiendo a Escocia en el 117.º si fuera un Estado soberano. La capital, Edimburgo, tiene una población de alrededor de 600 000 habitantes, buena parte de ellos estudiantes. No obstante, la ciudad más poblada de Escocia es Glasgow, ubicada en la costa occidental, con casi 800 000 habitantes y un área metropolitana de alrededor de 2 000 000. Históricamente, Glasgow ha constituido el motor económico de la región, aparte de ser su principal centro académico: su Universidad, fundada a mediados del siglo XV, se encuentra entre las más antiguas del mundo de habla inglesa. El desarrollo social, cultural y económico de Glasgow durante el siglo XIX y principios del XX la llevó a ser considerada «la segunda ciudad del Imperio».

La zona central de Escocia, conocida como "Central Belt", alberga la gran mayoría de los pueblos y ciudades principales: Glasgow al oeste, y Edimburgo, Aberdeen y Dundee al este. En cambio, las "Highlands" están escasamente pobladas, aunque la ciudad de Inverness ha crecido rápidamente en los últimos años. De las muchas islas que conforman el territorio escocés, solo las más grandes y las más accesibles (unas 90) están habitadas. Por su parte, las mesetas meridionales o "Southern Uplands" son esencialmente rurales y en ellas predomina la agricultura. Debido a los problemas de Glasgow y Edimburgo para albergar a su población, entre 1947 y 1966 se crearon cinco ciudades planificadas: East Kilbride, Glenrothes, Livingston, Cumbernauld e Irvine.

Debido a la inmigración producida tras la Segunda Guerra Mundial, en Glasgow, Edimburgo y Dundee viven unas significativas comunidades asiáticas. Tras la ampliación de la Unión Europea, un creciente número de personas de Europa Oriental y Central se ha instalado en Escocia: entre 40 000 y 50 000 polacos vivían en 2005 en el país. En 2001, había unos 16 310 residentes chinos.

El deporte también juega un importante papel en la cultura escocesa, ya que el país alberga sus propios campeonatos nacionales de diversas variedades deportivas, además de tener representación independiente del resto del Reino Unido en eventos como el Mundial de Fútbol, el Mundial de Rugby o los Juegos de la Commonwealth (aunque no en los Juegos Olímpicos, en los que Reino Unido participa como un único equipo). Además, Escocia tiene sus propios organismos deportivos, tales como la Asociación Escocesa de Fútbol (la segunda asociación nacional de fútbol más antigua del mundo) o la Scottish Rugby Union.

El deporte más popular en Escocia es el fútbol. Algunas variedades del fútbol se han practicado en Escocia desde hace varios siglos: la referencia más antigua data de 1424. El fútbol asociación es el deporte nacional de Escocia, y de hecho la Copa de Escocia es el trofeo nacional de fútbol más antiguo del mundo. Los equipos de fútbol más importantes de Escocia son el Celtic Football Club y el Rangers Football Club, ambos de Glasgow: el Celtic, cuyo estadio es el Celtic Park, se proclamó campeón de la Copa de Europa en 1967, mientras que el Rangers, que juega en el Ibrox Stadium, lo fue de la Recopa de Europa en 1972. Su rivalidad va más allá de lo meramente deportivo, ya que el Celtic de Glasgow es el equipo de los católicos de Escocia, mientras que el Glasgow Rangers lo es de los protestantes. Dicha rivalidad es conocida en todo el mundo como Old Firm. Ambos equipos juegan en la Premier League de Escocia, fundada en 1891 y en la que compiten 12 equipos. Ibrox Stadium, el campo del Rangers, y Hampden Park, el estadio donde por lo general juega sus partidos de local la selección escocesa de fútbol, son según los criterios de la UEFA.
St. Andrews, en el condado de Fife, es internacionalmente conocido como la "cuna del golf" y para muchos golfistas el Old Course de St Andrews, considerado como el campo de golf más antiguo del mundo, es casi un lugar de peregrinación. Hay muchos otros campos de golf famosos en Escocia, incluyendo los de Carnoustie, Gleneagles, Muirfield o Royal Troon. 

El rugby es también muy popular en Escocia: la Selección de rugby de Escocia (que disputa sus partidos como local en el estadio de Murrayfield) participa en el Torneo de las Seis Naciones desde su fundación, y lo ha ganado en 14 ocasiones.

Otros elementos distintivos del deporte escocés son los "Highland Games" o "juegos de la montaña", así como algunos deportes celtas, como el "curling" o el "shinty".

A comienzos del siglo XXI Escocia tiene una economía mixta abierta similar a la del resto de Europa y del mundo occidental. Tradicionalmente, la industria escocesa estaba dominada por la industria pesada, apoyada por los astilleros, la minería (especialmente de carbón) y las industrias siderúrgicas. El petróleo extraído en el mar del Norte también ha sido una importante fuente de ingresos y de ocupación, especialmente desde los años 1970, en el noreste del país. La desindustrialización de los años 1970 y años 1980 provocó un giro hacia los sectores de servicios y hacia las industrias tecnológicas, especialmente en lo que se conoce como Silicon Glen.
Edimburgo es el centro de las finanzas en Escocia, y el sexto centro financiero más importante de Europa después de Londres, París, Fráncfort, Zúrich y Ámsterdam, por ser el centro de firmas como Royal Bank of Scotland, HBOS (dueños del Bank of Scotland) o Standard Life.

En 2005, las exportaciones totales de Escocia (incluyendo las exportaciones al resto del Reino Unido) alcanzaron aproximadamente los 17.500 millones de libras, un 70 % de los cuales proviene de productos manufacturados. Las principales exportaciones escocesas son el whisky, los productos electrónicos y los servicios financieros, siendo sus principales clientes internacionales los Estados Unidos, los Países Bajos, Alemania, Francia y España. En 2006, el producto interno bruto (PIB) de Escocia era algo superior a los 86 000 millones de libras, con lo cual la renta per cápita se situaba en 16 900 libras.

El turismo también es reconocido como un importante factor de la economía escocesa. Un estudio publicado en 2002 por el Centro de Información del Parlamento Escocés afirmaba que el turismo era responsable del 5 % del PIB y del 7,5 % del empleo en Escocia. En noviembre de 2007, la tasa de desempleo era del 4,9 %, inferior a la media del Reino Unido y a la de la mayoría de los países de la Unión Europea.

Aunque el Banco de Inglaterra es el banco central del Reino Unido, tres bancos escoceses todavía tienen la potestad de producir sus propios billetes: el Bank of Scotland, el Royal Bank of Scotland y el Clydesdale Bank. El valor de los billetes escoceses en circulación se estima en unos 1 500 millones de libras, y pese a que oficialmente no es una moneda de curso legal en ningún lugar del Reino Unido, en la práctica estos billetes son intercambiables con los producidos por el Banco de Inglaterra. Pese a esta equivalencia, los billetes emitidos en Escocia son en ocasiones rechazados en Inglaterra y Gales, y no siempre son aceptados por otros bancos y oficinas de cambio de divisas fuera del Reino Unido. Esto es especialmente cierto con el billete de 1 libra que todavía emite el Royal Bank of Scotland, y que es el único billete de 1 libra que permanece en circulación en todo el Reino Unido.

Escocia tiene cinco aeropuertos internacionales: Glasgow, Edimburgo, Aberdeen, Glasgow Prestwick e Inverness, los cuales conectan en total con 150 destinos internacionales en vuelos regulares y chárter. BAA opera tres de estos aeropuertos (Edimburgo, Glasgow y Aberdeen), mientras que Highland and Islands Airports controla 11 aeropuertos regionales más pequeños (incluido el de Inverness), que conectan con los puntos más remotos de Escocia. Por último, la compañía Infratil posee el aeropuerto de Glasgow Prestwick.

Las principales autopistas y las carreteras más importantes (conocidas como "trunk roads") están regentadas por Transport Scotland, mientras que el resto de la red de carreteras es responsabilidad de las autoridades locales de cada área.

Dado que Escocia contiene gran cantidad de islas, existen servicios regulares de ferries que las unen con el territorio principal. Estos servicios son principalmente desarrollados por Caledonian MacBrayne, pero existen otras compañías, y algunas líneas dependen directamente de los concejos correspondientes. También hay líneas de ferry internacionales, que conectan Escocia con Irlanda del Norte, Bélgica, Noruega, las Islas Feroe e Islandia.
La red de ferrocarriles de Escocia está dirigida por Transport Scotland. Las líneas conocidas como East Coast Main Line ("línea principal de la costa este"), West Coast Main Line ("línea principal de la costa oeste") y la Cross Country Line ("línea a través del país") conectan la mayoría de las principales ciudades de Escocia entre sí, y con la red de trenes de Inglaterra. Existen también servicios de tren domésticos, operados por Abellio Scotrail. En la línea principal de la costa este se incluye la sección que cruza el fiordo de Forth a través del Forth Bridge. Este puente en ménsula, completado en 1890, está considerado una obra pionera de la ingeniería civil, y es uno de los monumentos más reconocibles de Escocia.

Network Rail posee y controla todas las infraestructuras ferroviarias de Escocia, mientras que el gobierno de Escocia es responsable de la planificación y financiación.

Aunque Escocia tiene una larga tradición militar anterior al Acta de Unión con Inglaterra, sus fuerzas armadas forman ahora parte de las Fuerzas Armadas Británicas, con la notable excepción de los Atholl Highlanders, el único ejército privado legal de Europa. En 2006, los distintos regimientos de División Escocesa fueron fusionados para formar el Regimiento Real de Escocia.

Debido a su topografía y a su localización aparentemente remota, algunas partes de Escocia han sido elegidas para albergar importantes instalaciones de defensa, lo que ha provocado sentimientos encontrados en la población. Entre 1960 y 1991, el Holy Loch ("lago Sagrado") fue la base para la flota estadounidense de submarinos UGM-27 Polaris. Hoy en día la base naval HMNB Clyde se encuentra a 40 km al oeste de Glasgow, y alberga cuatro submarinos de la clase Vanguard armados con misiles Trident, que forman parte del arsenal nuclear del Reino Unido. HMS Caledonia, en Rosyth (Fife) es la base de apoyo para operaciones navales en Escocia y también sirve como Oficina Naval Regional para Escocia e Irlanda del Norte. Una base de desarrollo de reactores nucleares Rolls-Royce PWR de la Marina Real Británica se encuentra en Dounreay, donde también se desarrolló el programa de reactores nucleares reproductores rápidos. Por su parte, HMS Gannet es una base de búsqueda y rescate cerca del Aeropuerto de Glasgow-Prestwick en Ayrshire, en la que operan tres helicópteros Sea King Mk 5. Por último, la base RM Cóndor, en Arbroath (Angus), alberga al comando 45 de los Marines Reales.

En Escocia también hay tres bases de vanguardia de la Royal Air Force (RAF): Lossiemouth, la base principal de la RAF para los cazas Panavia Tornado; Kinloss, base de los aviones Hawker Siddeley Nimrod de patrulla marítima, y Leuchars, la base de cazas más septentrional del Reino Unido, en la que se asientan tres escuadrones de Panavia Tornados. Dos helicópteros Sea King HAR3A se encuentran estacionados en la base de Lossiemouth, para servir en misiones de búsqueda y rescate. El "Centro de Control del Tráfico Aéreo de Escocia" se encuentra en Prestwick, en Ayrshire, en la que también tiene su base la ""Distress and Diversion Cell"", especialmente diseñada para asistir a aviones civiles o militares en situaciones de emergencia.

El único centro al aire libre de pruebas de armas con uranio empobrecido en las islas británicas está localizado cerca de Dundrennan. Como consecuencia, más de 7000 proyectiles radiactivos descansan en el lecho del fiordo de Solway. El gran número de bases militares que existen en Escocia ha llevado a la creación del término "Fortaleza Escocia". En 2005, las posesiones del Ministerio de Defensa en territorio escocés (en propiedad o arrendadas) alcanzaban las 115 300 hectáreas, lo que representa el 31,5 % del total de las posesiones de este Ministerio.



</doc>
<doc id="1155" url="https://es.wikipedia.org/wiki?curid=1155" title="Física">
Física

La física es la ciencia natural que se encarga del estudio de la energía, la materia, el tiempo y el espacio, así como las interacciones de estos cuatro conceptos entre sí. El término proviene del lat. "physica", y este del gr. τὰ φυσικά, neutro plural de φυσικός, 'natural, relativo a la naturaleza'. 

La física es una de las más antiguas disciplinas académicas, tal vez la más antigua, ya que la astronomía es una de sus subdisciplinas. En los últimos dos milenios, la física fue considerada parte de lo que ahora llamamos filosofía, química, y ciertas ramas de la matemática y la biología, pero durante la Revolución Científica en el siglo XVII surgió para convertirse en una ciencia moderna, única por derecho propio. Sin embargo, en algunas esferas como la física matemática y la química cuántica, los límites de la física siguen siendo difíciles de distinguir.

Esta disciplina incentiva competencias, métodos y una cultura científica que permiten comprender nuestro mundo físico y viviente, para luego actuar sobre él. Sus procesos cognitivos se han convertido en protagonistas del saber y hacer científico y tecnológico general, ayudando a conocer, teorizar, experimentar y evaluar actos dentro de diversos sistemas, clarificando causa y efecto en numerosos fenómenos. De esta manera, la física contribuye a la conservación y preservación de recursos, facilitando la toma de conciencia y la participación efectiva y sostenida de la sociedad en la resolución de sus propios problemas.

La física es significativa e influyente, no solo debido a que los avances en la comprensión a menudo se han traducido en nuevas tecnologías, sino también a que las nuevas ideas en la física resuenan con las demás ciencias, las matemáticas y la filosofía.

La física no es solo una ciencia teórica; es también una ciencia experimental. Como toda ciencia, busca que sus conclusiones puedan ser verificables mediante experimentos y que la teoría pueda realizar predicciones de experimentos futuros basados en observaciones previas. Dada la amplitud del campo de estudio de la física, así como su desarrollo histórico con relación a otras ciencias, se la puede considerar la ciencia fundamental o central, ya que incluye dentro de su campo de estudio a la química, la biología y la electrónica, además de explicar sus fenómenos.

La física, en su intento de describir los fenómenos naturales con exactitud y veracidad, ha llegado a límites impensables: el conocimiento actual abarca la descripción de partículas fundamentales microscópicas, el nacimiento de las estrellas en el universo e incluso conocer con una gran probabilidad lo que aconteció en los primeros instantes del nacimiento de nuestro universo, por citar unos pocos campos.

Esta tarea comenzó hace más de dos mil años con los primeros trabajos de filósofos griegos como Demócrito, Eratóstenes, Aristarco, Epicuro o Aristóteles, y fue continuada después por científicos como Galileo Galilei, Isaac Newton, Leonhard Euler, Joseph-Louis de Lagrange, Michael Faraday, William Rowan Hamilton, Rudolf Clausius, James Clerk Maxwell, Hendrik Antoon Lorentz, Albert Einstein, Niels Bohr, Max Planck, Werner Heisenberg, Paul Dirac, Richard Feynman, Stephen Hawking, Edward Witten, entre muchos otros.

Es conocido que la mayoría de las civilizaciones de la antigüedad trataron desde un principio de explicar el funcionamiento de su entorno; miraban las estrellas y pensaban cómo ellas podían regir su mundo. Esto llevó a muchas interpretaciones de carácter más filosófico que físico; no en vano en esos momentos a la física se le llamaba filosofía natural. Muchos filósofos se encuentran en el desarrollo primigenio de la física, como Aristóteles, Tales de Mileto o Demócrito, por ser los primeros en tratar de buscar algún tipo de explicación a los fenómenos que les rodeaban. A pesar de que las teorías descriptivas del universo que dejaron estos pensadores eran erradas, estas tuvieron validez por mucho tiempo, casi dos mil años, en parte por la aceptación de la Iglesia católica de varios de sus preceptos, como la teoría geocéntrica o las tesis de Aristóteles.

Esta etapa, denominada oscurantismo en la ciencia de Europa, termina cuando el canónigo y científico Nicolás Copérnico, considerado padre de la astronomía moderna, en 1543 recibe la primera copia de su "De Revolutionibus Orbium Coelestium". A pesar de que Copérnico fue el primero en formular teorías plausibles, es otro personaje al cual se le considera el padre de la física como la conocemos ahora. Un catedrático de matemáticas de la Universidad de Pisa a finales del siglo XVI cambiaría la historia de la ciencia, empleando por primera vez experimentos para comprobar sus aseveraciones: Galileo Galilei. Mediante el uso del telescopio para observar el firmamento y sus trabajos en planos inclinados, Galileo empleó por primera vez el método científico y llegó a conclusiones capaces de ser verificadas. A sus trabajos se les unieron grandes contribuciones por parte de otros científicos como Johannes Kepler, Blaise Pascal y Christian Huygens.

Posteriormente, en el siglo XVII, un científico inglés reunió las ideas de Galileo y Kepler en un solo trabajo, unifica las ideas del movimiento celeste y las de los movimientos en la Tierra en lo que él llamó gravedad. En 1687, Isaac Newton, en su obra "Philosophiae Naturalis Principia Mathematica", formuló los tres principios del movimiento y una cuarta ley de la gravitación universal, que transformaron por completo el mundo físico; todos los fenómenos podían ser vistos de una manera mecánica.

El trabajo de Newton en este campo perdura hasta la actualidad; todos los fenómenos macroscópicos pueden ser descritos de acuerdo a sus tres leyes. Por eso durante el resto de ese siglo y el posterior siglo XVIII todas las investigaciones se basaron en sus ideas. De ahí que se desarrollaron otras disciplinas, como la termodinámica, la óptica, la mecánica de fluidos y la mecánica estadística. Los conocidos trabajos de Daniel Bernoulli, Robert Boyle y Robert Hooke, entre otros, pertenecen a esta época.

En el siglo XIX se produjeron avances fundamentales en la electricidad y el magnetismo, principalmente de la mano de Charles-Augustin de Coulomb, Luigi Galvani, Michael Faraday y Georg Simon Ohm, que culminaron en el trabajo de James Clerk Maxwell de 1855, que logró la unificación de ambas ramas en el llamado electromagnetismo. Además, se producen los primeros descubrimientos sobre radiactividad y el descubrimiento del electrón por parte de Joseph John Thomson en 1897.

Durante el siglo XX, la física se desarrolló plenamente. En 1904, Hantarō Nagaoka había propuesto el primer modelo del átomo, el cual fue confirmado en parte por Ernest Rutherford en 1911, aunque ambos planteamientos serían después sustituidos por el modelo atómico de Bohr, de 1913. En 1905, Einstein formuló la teoría de la relatividad especial, la cual coincide con las leyes de Newton cuando los fenómenos se desarrollan a velocidades pequeñas comparadas con la velocidad de la luz. En 1915 extendió la teoría de la relatividad especial, formulando la teoría de la relatividad general, la cual sustituye a la ley de gravitación de Newton y la comprende en los casos de masas pequeñas. Max Planck, Albert Einstein, Niels Bohr y otros, desarrollaron la teoría cuántica, a fin de explicar resultados experimentales anómalos sobre la radiación de los cuerpos. En 1911, Ernest Rutherford dedujo la existencia de un núcleo atómico cargado positivamente, a partir de experiencias de dispersión de partículas. En 1925 Werner Heisenberg, y en 1926 Erwin Schrödinger y Paul Adrien Maurice Dirac, formularon la mecánica cuántica, la cual comprende las teorías cuánticas precedentes y suministra las herramientas teóricas para la Física de la materia condensada.

Posteriormente se formuló la teoría cuántica de campos, para extender la mecánica cuántica de acuerdo con la Teoría de la Relatividad especial, alcanzando su forma moderna a finales de la década de 1940, gracias al trabajo de Richard Feynman, Julian Schwinger, Tomonaga y Freeman Dyson, que formularon la teoría de la electrodinámica cuántica. Esta teoría formó la base para el desarrollo de la física de partículas. En 1954, Chen Ning Yang y Robert Mills desarrollaron las bases del modelo estándar. Este modelo se completó en los años 1970, y con él fue posible predecir las propiedades de partículas no observadas previamente, pero que fueron descubiertas sucesivamente, siendo la última de ellas el quark top.

Los intentos de unificar las cuatro interacciones fundamentales han llevado a los físicos a nuevos campos impensables. Las dos teorías más aceptadas, la mecánica cuántica y la relatividad general, que son capaces de describir con gran exactitud el macro y el micromundo, parecen incompatibles cuando se las quiere ver desde un mismo punto de vista. Por eso se han formulado nuevas teorías, como la supergravedad o la teoría de cuerdas, donde se centran las investigaciones a inicios del siglo XXI.
Esta ciencia no desarrolla únicamente teorías: también es una disciplina de experimentación. Sus hallazgos, por lo tanto, pueden ser comprobados a través de experimentos. Además sus teorías permiten establecer previsiones sobre pruebas que se desarrollen en el futuro.

Gracias a su vasto alcance y a su extensa historia, la física es clasificada como una ciencia fundamental. Esta disciplina científica puede dedicarse a describir las partículas más pequeñas o a explicar cómo nace una estrella, por ejemplo. Galileo Galilei, Isaac Newton y Albert Einstein han sido algunos de los físicos más reconocidos de la historia. El desarrollo originario de la física, de todos modos, quedó en mano de los filósofos griegos.
En este sentido, habría que destacar, por ejemplo, la figura de Empédocles que fue un filósofo y físico griego que llevó a cabo la demostración de la existencia del aire. Y lo hizo mediante un artilugio que recibió el nombre de clepsidra, que era una esfera de cobre que se llenaba de agua cuando se sumergía en dicho líquido y que se caracterizaba porque tenía agujeros en el fondo y un cuello abierto.

La física, en su búsqueda de describir la verdad última de la naturaleza, tiene varias bifurcaciones, las cuales podrían agruparse en cinco teorías "principales": la mecánica clásica, que describe el movimiento macroscópico; el electromagnetismo, que describe los fenómenos electromagnéticos como la luz; la relatividad, formulada por Einstein, que describe el espacio-tiempo y la interacción gravitatoria; la termodinámica, que describe los fenómenos moleculares y de intercambio de calor; y, finalmente, la mecánica cuántica, que describe el comportamiento del mundo atómico.

Se conoce como mecánica clásica a la descripción del movimiento de cuerpos macroscópicos a velocidades muy pequeñas en comparación con la velocidad de la luz. Existen dos tipos de formulaciones de esta mecánica, conocidas como mecánica newtoniana y mecánica analítica.

La mecánica newtoniana, como su nombre indica, lleva intrínsecos los preceptos de Newton. A partir de las tres ecuaciones formuladas por Newton y mediante el cálculo diferencial e integral, se llega a una muy exacta aproximación de los fenómenos físicos. Esta formulación también es conocida como mecánica vectorial, y es debido a que a varias magnitudes se les debe definir su vector en un sistema de referencia inercial privilegiado.

La mecánica analítica es una formulación matemática abstracta sobre la mecánica; nos permite desligarnos de esos sistemas de referencia privilegiados y tener conceptos más generales al momento de describir un movimiento con el uso del cálculo de variaciones. Existen dos formulaciones equivalentes: la llamada mecánica lagrangiana es una reformulación de la mecánica realizada por Joseph Louis Lagrange que se basa en la ahora llamada ecuación de Euler-Lagrange (ecuaciones diferenciales de segundo orden) y el principio de mínima acción; la otra, llamada mecánica hamiltoniana, es una reformulación más teórica basada en una funcional llamada hamiltoniano realizada por William Hamilton. En última instancia las dos son equivalentes.

En la mecánica clásica en general se tienen tres aspectos invariantes: el tiempo es absoluto, la naturaleza realiza de forma espontánea la mínima acción y la concepción de un universo determinado.

El electromagnetismo describe la interacción de partículas cargadas con campos eléctricos y magnéticos. Se puede dividir en electrostática, el estudio de las interacciones entre cargas en reposo, y la electrodinámica, el estudio de las interacciones entre cargas en movimiento y la radiación. La teoría clásica del electromagnetismo se basa en la fuerza de Lorentz y en las ecuaciones de Maxwell.

La electrostática es el estudio de los fenómenos asociados a los cuerpos cargados en reposo. Como se describe por la ley de Coulomb, estos cuerpos ejercen fuerzas entre sí. Su comportamiento se puede analizar en términos de la idea de un campo eléctrico que rodea cualquier cuerpo cargado, de manera que otro cuerpo cargado colocado dentro del campo estará sujeto a una fuerza proporcional a la magnitud de su carga y de la magnitud del campo en su ubicación. El que la fuerza sea atractiva o repulsiva depende de la polaridad de la carga. La electrostática tiene muchas aplicaciones, que van desde el análisis de fenómenos como tormentas eléctricas hasta el estudio del comportamiento de los tubos electrónicos.

La electrodinámica es el estudio de los fenómenos asociados a los cuerpos cargados en movimiento y a los campos eléctricos y magnéticos variables. Dado que una carga en movimiento produce un campo magnético, la electrodinámica se refiere a efectos tales como el magnetismo, la radiación electromagnética, y la inducción electromagnética, incluyendo las aplicaciones prácticas, tales como el generador eléctrico y el motor eléctrico. Esta área de la electrodinámica, conocida como electrodinámica clásica, fue sistemáticamente explicada por James Clerk Maxwell, y las ecuaciones de Maxwell describen los fenómenos de esta área con gran generalidad. Una novedad desarrollada más reciente es la electrodinámica cuántica, que incorpora las leyes de la teoría cuántica a fin de explicar la interacción de la radiación electromagnética con la materia. Paul Dirac, Heisenberg y Wolfgang Pauli fueron pioneros en la formulación de la electrodinámica cuántica. La electrodinámica es inherentemente relativista y da unas correcciones que se introducen en la descripción de los movimientos de las partículas cargadas cuando sus velocidades se acercan a la velocidad de la luz. Se aplica a los fenómenos involucrados con aceleradores de partículas y con tubos electrónicos funcionando a altas tensiones y corrientes.

El electromagnetismo abarca diversos fenómenos del mundo real como por ejemplo, la luz. La luz es un campo electromagnético oscilante que se irradia desde partículas cargadas aceleradas. Aparte de la gravedad, la mayoría de las fuerzas en la experiencia cotidiana son consecuencia de electromagnetismo.

Los principios del electromagnetismo encuentran aplicaciones en diversas disciplinas afines, tales como las microondas, antenas, máquinas eléctricas, comunicaciones por satélite, bioelectromagnetismo, plasmas, investigación nuclear, la fibra óptica, la interferencia y la compatibilidad electromagnéticas, la conversión de energía electromecánica, la meteorología por radar, y la observación remota. Los dispositivos electromagnéticos incluyen transformadores, relés, radio/TV, teléfonos, motores eléctricos, líneas de transmisión, guías de onda, fibras ópticas y láseres.

La relatividad es la teoría formulada principalmente por Albert Einstein a principios del siglo XX, y se divide en dos cuerpos de investigación: la relatividad especial y la relatividad general.

En la teoría de la relatividad especial, Einstein, Lorentz y Minkowski, entre otros, unificaron los conceptos de espacio y tiempo, en un ramado tetradimensional al que se le denominó espacio-tiempo. La relatividad especial fue una teoría revolucionaria para su época, con la que el tiempo absoluto de Newton quedó relegado y conceptos como la invariabilidad en la velocidad de la luz, la dilatación del tiempo, la contracción de la longitud y la equivalencia entre masa y energía fueron introducidos. Además, con las formulaciones de la relatividad especial, las leyes de la Física son invariantes en todos los sistemas de referencia inerciales; como consecuencia matemática, se encuentra como límite superior de velocidad a la de la luz y se elimina la causalidad determinista que tenía la física hasta entonces. Hay que indicar que las leyes del movimiento de Newton son un caso particular de esta teoría donde la masa, al viajar a velocidades muy pequeñas, no experimenta variación alguna en longitud ni se transforma en energía, y al tiempo se le puede considerar absoluto.

Por otro lado, la relatividad general estudia la interacción gravitatoria como una deformación en la geometría del espacio-tiempo. En esta teoría se introducen los conceptos de la curvatura del espacio-tiempo como la causa de la interacción gravitatoria, el principio de equivalencia que dice que para todos los observadores locales inerciales las leyes de la relatividad especial son invariantes y la introducción del movimiento de una partícula por líneas geodésicas. La relatividad general no es la única teoría que describe la atracción gravitatoria, pero es la que más datos relevantes comprobables ha encontrado. Anteriormente, a la interacción gravitatoria se la describía matemáticamente por medio de una distribución de masas, pero en esta teoría no solo la masa percibe esta interacción, sino también la energía, mediante la curvatura del espacio-tiempo, y por eso se necesita otro lenguaje matemático para poder describirla, el cálculo tensorial. Muchos fenómenos, como la curvatura de la luz por acción de la gravedad y la desviación en la órbita de Mercurio, son perfectamente predichos por esta formulación. La relatividad general también abrió otro campo de investigación en la física, conocido como cosmología, y es ampliamente utilizado en la astrofísica.

La termodinámica trata los procesos de transferencia de calor, que es una de las formas de energía, y cómo se puede realizar un trabajo con ella. En esta área se describe cómo la materia en cualquiera de sus fases (sólido, líquido, gaseoso) va transformándose. Desde un punto de vista macroscópico de la materia, se estudia cómo esta reacciona a cambios en su volumen, presión y temperatura, entre otras magnitudes. La termodinámica se basa en cuatro leyes principales: el equilibrio termodinámico (o ley cero), el principio de conservación de la energía (primera ley), el aumento temporal de la entropía (segunda ley) y la imposibilidad del cero absoluto (tercera ley).

Una consecuencia de la termodinámica es lo que hoy se conoce como mecánica estadística. Esta rama estudia, al igual que la termodinámica, los procesos de transferencia de calor, pero, al contrario a la anterior, desde un punto de vista molecular. La materia, como se conoce, está compuesta por moléculas, y el conocer el comportamiento de una sola de sus moléculas nos lleva a medidas erróneas. Por eso se debe tratar como un conjunto de elementos "caóticos" o "aleatorios", y se utiliza el lenguaje estadístico y consideraciones mecánicas para describir comportamientos macroscópicos de este conjunto molecular microscópico.

La mecánica cuántica es la rama de la física que trata los sistemas atómicos y subatómicos, y sus interacciones con la radiación electromagnética, en términos de cantidades observables. Se basa en la observación de que todas las formas de energía se liberan en unidades discretas o paquetes llamados "cuantos". Sorprendentemente, la teoría cuántica solo permite normalmente cálculos probabilísticos o estadísticos de las características observadas de las partículas elementales, entendidos en términos de funciones de onda. La ecuación de Schrödinger desempeña el papel en la mecánica cuántica que las leyes de Newton y la conservación de la energía hacen en la mecánica clásica. Es decir, la predicción del comportamiento futuro de un sistema dinámico, y es una ecuación de onda en términos de una función de onda la que predice analíticamente la probabilidad precisa de los eventos o resultados.

En teorías anteriores de la física clásica, la energía era tratada únicamente como un fenómeno continuo, en tanto que la materia se supone que ocupa una región muy concreta del espacio y que se mueve de manera continua. Según la teoría cuántica, la energía se emite y se absorbe en cantidades discretas y minúsculas. Un paquete individual de energía, llamado cuanto, en algunas situaciones se comporta como una partícula de materia. Por otro lado, se encontró que las partículas exponen algunas propiedades ondulatorias cuando están en movimiento y ya no son vistas como localizadas en una región determinada, sino más bien extendidas en cierta medida. La luz u otra radiación emitida o absorbida por un átomo solo tiene ciertas frecuencias (o longitudes de onda), como puede verse en la línea del espectro asociado al elemento químico representado por tal átomo. La teoría cuántica demuestra que tales frecuencias corresponden a niveles definidos de los cuantos de luz, o fotones, y es el resultado del hecho de que los electrones del átomo solo pueden tener ciertos valores de energía permitidos. Cuando un electrón pasa de un nivel permitido a otro, una cantidad de energía es emitida o absorbida, cuya frecuencia es directamente proporcional a la diferencia de energía entre los dos niveles.
El formalismo de la mecánica cuántica se desarrolló durante la década de 1920. En 1924, Louis de Broglie propuso que, al igual que las ondas de luz presentan propiedades de partículas, como ocurre en el efecto fotoeléctrico, las partículas, a su vez, también presentan propiedades ondulatorias. Dos formulaciones diferentes de la mecánica cuántica se presentaron después de la sugerencia de Broglie. En 1926, la mecánica ondulatoria de Erwin Schrödinger implica la utilización de una entidad matemática, la función de onda, que está relacionada con la probabilidad de encontrar una partícula en un punto dado en el espacio. En 1925, la mecánica matricial de Werner Heisenberg no hace mención alguna de las funciones de onda o conceptos similares, pero ha demostrado ser matemáticamente equivalente a la teoría de Schrödinger. Un descubrimiento importante de la teoría cuántica es el principio de incertidumbre, enunciado por Heisenberg en 1927, que pone un límite teórico absoluto en la precisión de ciertas mediciones. Como resultado de ello, la asunción clásica de los científicos de que el estado físico de un sistema podría medirse exactamente y utilizarse para predecir los estados futuros tuvo que ser abandonada. Esto supuso una revolución filosófica y dio pie a numerosas discusiones entre los más grandes físicos de la época.

La mecánica cuántica se combinó con la teoría de la relatividad en la formulación de Paul Dirac de 1928, lo que, además, predijo la existencia de antipartículas. Otros desarrollos de la teoría incluyen la estadística cuántica, presentada en una forma por Einstein y Bose (la estadística de Bose-Einstein) y en otra forma por Dirac y Enrico Fermi (la estadística de Fermi-Dirac), la electrodinámica cuántica, interesada en la interacción entre partículas cargadas y los campos electromagnéticos, su generalización, la teoría cuántica de campos y la electrónica cuántica.

El descubrimiento de la mecánica cuántica a principios del siglo XX revolucionó la física, y la mecánica cuántica es fundamental para la mayoría de las áreas de la investigación actual.

En general un concepto físico es interpretable solo en virtud de la teoría física donde aparece. Así la descripción clásica de un gas o un fluido recurre al concepto de medio continuo aun cuando en realidad la materia está formada por átomos discretos, eso no impide que el concepto de medio continuo en el contexto de aplicación de la mecánica de fluidos o la mecánica de sólidos deformables no sea útil. Igualmente la mecánica newtoniana trata el campo gravitatorio como un campo de fuerzas, pero por otra parte la teoría de la relatividad general considera que no existen genuinamente fuerzas gravitatorias sino que los fenómenos gravitatorios son una manifestación de la curvatura del espacio-tiempo.

Si se examina una lista larga de conceptos físicos rápidamente se aprecia que muchos de ellos solo tienen sentido o son definibles con todo rigor en el contexto de una teoría concreta y por tanto no son conceptos fundamentales que deban aparecer en cualquier descripción física del universo. Sin embargo, un conjunto reducido de conceptos físicos aparecen tanto en la descripción de la física clásica, como en la descripción de la física relativista y la de la mecánica cuántica. Estos conceptos físicos que parecen necesarios en cualquier teoría física suficientemente amplia son los llamados conceptos físicos fundamentales, una lista no exhaustiva de los mismos podría ser:

La cultura de la investigación en física en los últimos tiempos se ha especializado tanto que ha dado lugar a una separación de los físicos que se dedican a la teoría y otros que se dedican a los experimentos. Los teóricos trabajan en la búsqueda de modelos matemáticos que expliquen los resultados experimentales y que ayuden a predecir resultados futuros. Así pues, teoría y experimentos están relacionados íntimamente. El progreso en física a menudo ocurre cuando un experimento encuentra un resultado que no se puede explicar con las teorías actuales, por lo que hay que buscar un nuevo enfoque conceptual para resolver el problema.

La física teórica está muy relacionada con las matemáticas, ya que esta suministra el lenguaje usado en el desarrollo de las teorías físicas. Los teóricos confían en el cálculo diferencial e integral, el análisis numérico y en simulaciones por ordenador para validar y probar sus modelos físicos. Los campos de física computacional y matemática son áreas de investigación activas.

Los teóricos pueden concebir conceptos tales como universos paralelos, espacios multidimensionales o minúsculas cuerdas que vibran o la teoría del todo, y a partir de ahí, realizar hipótesis físicas.

La física de la materia condensada se ocupa de las propiedades físicas macroscópicas de la materia, tales como la densidad, la temperatura, la dureza, o el color de un material. Los materiales consisten en un gran número de átomos o moléculas que interactúan entre ellos, por lo que están "condensados", a diferencia de estar libres sin interactuar. La física de la materia condensada busca hacer relaciones entre las propiedades macroscópicas, que se pueden medir, y el comportamiento de sus constituyentes a nivel microscópico o atómico y así comprender mejor las propiedades de los materiales.

Las fases "condensadas" más comunes son sólidos y líquidos, que surgen del enlace químico entre los átomos, debido a la interacción electromagnética. Fases más exóticas son los superfluidos, los condensados de Bose-Einstein encontrados en ciertos sistemas atómicos a muy bajas temperaturas, la fase superconductora de los electrones de conducción de ciertos materiales, y las fases ferromagnéticas y antiferromagnéticas de los espines en las redes atómicas.

La física de la materia condensada es el campo de la física contemporánea más extenso y que involucra a un mayor número de físicos. Históricamente, la física de la materia condensada surgió de la física de estado sólido, que se considera en la actualidad uno de sus principales subcampos. La expresión física de la materia condensada aparentemente fue acuñada por Philip Anderson cuando renombró en 1967 su grupo de investigación, anteriormente llamado de teoría del estado sólido. La física de la materia condensada tiene una gran superposición con la química, la ciencia de materiales, la nanotecnología y la ingeniería.

La física atómica y molecular se centran en el estudio de las interacciones materia-materia y luz-materia en la escala de átomos individuales o estructuras que contienen unos pocos átomos. Ambas áreas se agrupan debido a su interrelación, la similitud de los métodos utilizados, así como el carácter común de las escalas de energía relevantes a sus investigaciones. A su vez, ambas incluyen tratamientos tanto clásicos como cuánticos, ya que pueden tratar sus problemas desde puntos de vista microscópicos y macroscópicos.

La investigación actual en física atómica se centra en actividades tales como el enfriamiento y captura de átomos e iones, lo cual es interesante para eliminar "ruido" en las medidas y evitar imprecisiones a la hora de realizar otros experimentos o medidas (por ejemplo, en los relojes atómicos), aumentar la precisión de las mediciones de constantes físicas fundamentales, lo cual ayuda a validar otras teorías como la relatividad o el modelo estándar, medir los efectos de correlación electrónica en la estructura y dinámica atómica, y la medida y comprensión del comportamiento colectivo de los átomos de gases que interactúan débilmente (por ejemplo, en un condensado de Bose-Einstein de pocos átomos).

La física molecular se centra en estructuras moleculares y sus interacciones con la materia y con la luz.

La física de partículas es la rama de la física que estudia los componentes elementales de la materia y las interacciones entre ellos como si estas fueran partículas. Es llamada también "física de altas energías", pues muchas de las partículas elementales no se encuentran en la naturaleza y es necesario producirlas en colisiones de alta energía entre otras partículas, como se hace en los aceleradores de partículas. Los principales centros de estudio sobre partículas son el Laboratorio Nacional Fermi o Fermilab, en Estados Unidos, y el Centro Europeo para la Investigación Nuclear o CERN, en la frontera entre Suiza y Francia. En estos laboratorios lo que se logra es obtener energías similares a las que se cree existieron en el Big Bang, y así se intenta tener cada vez más pruebas del origen del universo.

En la actualidad, las partículas elementales se clasifican siguiendo el llamado Modelo Estándar en dos grandes grupos: bosones y fermiones. Los bosones son las partículas que interactúan con la materia y los fermiones son las partículas constituyentes de la materia. En el modelo estándar se explica cómo las interacciones fundamentales en forma de partículas (bosones) interactúan con las partículas de materia (fermiones). Así, el electromagnetismo tiene su partícula llamada fotón, la interacción nuclear fuerte tiene al gluón, la interacción nuclear débil a los bosones W y Z y la gravedad a una partícula hipotética llamada gravitón. Entre los fermiones hay más variedad; se encuentran dos tipos: los leptones y los quarks. En conjunto, el modelo estándar contiene 24 partículas fundamentales que constituyen la materia (12 pares de partículas/anti-partículas) junto con tres familias de bosones de gauge responsables de transportar las interacciones.

La Física Nuclear es el campo de la Física que estudia los constituyentes del núcleo atómico y sus interacciones. Las aplicaciones más conocidas de la física nuclear son la tecnología de generación de energía y armamento, pero el campo ha dado lugar a aplicaciones en diversos campos, incluyendo medicina nuclear e imágenes por resonancia magnética, ingeniería de implantación de iones en materiales y datación por radiocarbono en geología y arqueología.

La astrofísica y la astronomía son ciencias que aplican las teorías y métodos de otras ramas de la física al estudio de los objetos que componen nuestro variado universo, tales como estrellas, planetas, galaxias y agujeros negros. La astronomía se centra en la comprensión de los movimientos de los objetos, mientras que, "grosso modo", la astrofísica busca explicar su origen, su evolución y su comportamiento. Actualmente los términos astrofísica y astronomía se suelen usar indistintamente para referirse al estudio del universo.

Esta área, junto a la física de partículas, es una de las áreas más estudiadas y más apasionantes del mundo contemporáneo de la física. Desde que el telescopio espacial Hubble nos brindó detallada información de los más remotos confines del universo, los físicos pudieron tener una visión más objetiva de lo que hasta ese momento eran solo teorías.

Debido a que la astrofísica es un campo muy amplio, los astrofísicos aplican normalmente muchas disciplinas de la física, incluida la mecánica, el electromagnetismo, la mecánica estadística, la termodinámica, la mecánica cuántica, la relatividad, la física nuclear y de partículas, y la física atómica y molecular. Además, la astrofísica está íntimamente vinculada con la cosmología, que es el área que pretende describir el origen del universo.

La biofísica es un área interdisciplinaria que estudia la biología aplicando los principios generales de la física. Al aplicar el carácter probabilístico de la mecánica cuántica a sistemas biológicos, obtenemos métodos puramente físicos para la explicación de propiedades biológicas. Se puede decir que el intercambio de conocimientos es únicamente en dirección a la biología, ya que esta se ha ido enriqueciendo de los conceptos físicos y no viceversa. La biomecánica por otra parte consiste en la aplicación de conceptos de la dinámica clásica y la mecánica de sólidos deformables al comportamiento cinemático, dinámico y estructural de las diferentes partes del cuerpo.

Esta área está en constante crecimiento. Se estima que durante los inicios del siglo XXI cada vez la confluencia de físicos, biólogos y químicos a los mismos laboratorios se incrementará. Los estudios en neurociencia, por ejemplo, han aumentado y cada vez han tenido mayores frutos desde que se comenzó a implementar las leyes del electromagnetismo, la óptica y la física molecular al estudio de las neuronas.

Clasificación de la física con respecto a teorías: 




</doc>
<doc id="1158" url="https://es.wikipedia.org/wiki?curid=1158" title="Free Software Foundation">
Free Software Foundation

La Free Software Foundation o Fundación por el Software Libre es una organización creada en octubre de 1985 por Richard Stallman y otros entusiastas del "software" libre con el propósito de difundir este movimiento.

En sus inicios, la FSF destinaba sus fondos principalmente a contratar programadores para que escribiesen "software" libre. A partir de mediados de la década de 1990 existen ya muchas compañías y autores individuales que escriben "software" libre, por lo que los empleados y voluntarios de la FSF han centrado su trabajo fundamentalmente en asuntos legales, organizativos y promocionales en beneficio de la comunidad de usuarios de "software" libre.

La FSF se creó con la idea original de promover el "software" libre. La organización desarrolla el sistema operativo GNU como ejemplo de ello.
la licencia de "software" libre más utilizada, cuya última versión es la GPLv3 que fue publicada en forma definitiva en junio de 2007. Aparte la FSF también es responsable de la [GNU LGPL|Licencia Pública General Reducida GNU] (GNU LGPL) y la Licencia de documentación libre GNU (GNU iFDL). 







La Fundación se ha posicionado en incontables ocasiones contra las patentes de software.



La información financiera acerca de la Free Software Foundation es supervisada por la . En 2006 Charity Navigator valoró la Fundación como de 4 estrellas: «Excepcional. Supera las normas del sector y lo hace mejor que la mayoría de las organizaciones benéficas».

La FSF ha desempeñado y desempeña un papel muy importante en el desarrollo del "software" libre, por ello goza de muchas simpatías entre los usuarios de dicho "software" y tiene muchos enemigos en la industria del software privativo. 

Al margen de este hecho, dentro de la comunidad no todos comparten plenamente la filosofía o actuaciones de la FSF siendo la Open Source Initiative (OSI) la principal línea de pensamiento alternativa a la FSF.




</doc>
<doc id="1159" url="https://es.wikipedia.org/wiki?curid=1159" title="Filosofía continental">
Filosofía continental

La filosofía continental es un conjunto de movimientos filosóficos de los siglos XIX y XX en contraste con la filosofía analítica. La filosofía continental se desarrolló principalmente en la Europa Continental (de ahí su nombre), sobre todo en Francia y Alemania, mientras que la filosofía analítica que tiene su origen en los países anglosajones de Gran Bretaña y Estados Unidos.

La filosofía continental se caracterizó por ser más especulativa y por dar más importancia a la historia que la filosofía analítica. La fenomenología, el existencialismo, el estructuralismo, el postestructuralismo y la postmodernidad son algunas escuelas que caen dentro de esta tradición.

Tradicionalmente se ha incluido dentro de la filosofía continental el idealismo alemán, la fenomenología, el existencialismo, la hermenéutica, el estructuralismo, el postestructuralismo, el feminismo, la teoría crítica de la Escuela de Frankfurt, así como algunas corrientes del marxismo.

Algunos de los autores más influyentes de la tradición fueron Edmund Husserl, Martin Heidegger, Jean Paul Sartre, Maurice Merleau-Ponty y José Ortega y Gasset en la primera mitad del siglo, seguidos por Michel Foucault, Jacques Derrida, Noam Chomsky, Hannah Arendt y Gilles Deleuze en la segunda. La Escuela crítica tuvo como exponentes destacados a Theodor Adorno, Walter Benjamin, Max Horkheimer y Jürgen Habermas. Otros filósofos: Jacques Derrida, Gilles Deleuze y Michel Foucault.

Resulta difícil identificar rasgos comunes a todos los movimientos filosóficos agrupados bajo el término de filosofía continental. Este, al igual que el término filosofía analítica, carece de una definición formal y puede ser entendido como una agrupación de filosofías dispares dentro del contexto de la Europa continental de los siglos XIX y XX. 

Simon Glendinning sostiene que el término fue utilizado originalmente por los filósofos analíticos de forma peyorativa, agrupando las filosofías occidentales que eran rechazadas por ellos mismos. No obstante, Michael E. Rosen se ha aventurado a identificar los temas comunes en la filosofía continental:








</doc>
<doc id="1160" url="https://es.wikipedia.org/wiki?curid=1160" title="Fotón">
Fotón

En física moderna, el fotón (en griego φῶς "phōs" (gen. φωτός) 'luz', y -ón) es la partícula elemental responsable de las manifestaciones cuánticas del fenómeno electromagnético. Es la partícula portadora de todas las formas de radiación electromagnética, incluyendo los rayos gamma, los rayos X, la luz ultravioleta, la luz visible, la luz infrarroja, las microondas y las ondas de radio. El fotón tiene una masa invariante cero, y viaja en el vacío con una velocidad constante formula_1. Como todos los cuantos, el fotón presenta tanto propiedades corpusculares como ondulatorias ("dualidad onda-corpúsculo"). Se comporta como una onda en fenómenos como la refracción que tiene lugar en una lente, o en la cancelación por interferencia destructiva de ondas reflejadas; sin embargo, se comporta como una partícula cuando interactúa con la materia para transferir una cantidad fija de energía, que viene dada por la expresión:

donde "h" es la constante de Planck, "c" es la velocidad de la luz, formula_2 es la longitud de onda y formula_3 la frecuencia de la onda. Esto difiere de lo que ocurre con las ondas clásicas, que pueden ganar o perder cantidades arbitrarias de energía. Para la luz visible, la energía portada por un fotón es de alrededor de 4×10 julios; esta energía es suficiente para excitar las células oculares fotosensibles y dar lugar a la visión.

Además de energía, los fotones llevan también asociado un momento lineal y tienen una polarización. Siguen las leyes de la mecánica cuántica, lo que significa que a menudo estas propiedades no tienen un valor bien definido para un fotón dado. En su lugar se habla de las probabilidades de que tenga una cierta polarización, posición o momento lineal. Por ejemplo, aunque un fotón puede excitar una molécula, a menudo es imposible predecir cuál será la molécula excitada.

La descripción anterior de un fotón como un portador de radiación electromagnética es utilizada con frecuencia por los físicos. Sin embargo, en física teórica, un fotón puede considerarse como un mediador para cualquier tipo de interacción electromagnética. 

La discusión sobre la naturaleza de la luz se remonta hasta la antigüedad. En el siglo XVII, Newton se inclinó por una interpretación corpuscular de la luz, mientras que sus contemporáneos Huygens y Hooke apoyaron la hipótesis de la luz como onda. Experimentos de interferencia, como el realizado por Young en el siglo XIX, confirmaron el modelo ondulatorio de la luz. 

La idea de la luz como partícula retornó con el concepto moderno de fotón, que fue desarrollado gradualmente entre 1905 y 1917 por Albert Einstein apoyándose en trabajos anteriores de Planck, en los cuales se introdujo el concepto de cuanto. Con el modelo de fotón podían explicarse observaciones experimentales que no encajaban con el modelo ondulatorio clásico de la luz. En particular, explicaba cómo la energía de la luz dependía de la frecuencia (dependencia observada en el efecto fotoeléctrico) y la capacidad de la materia y la radiación electromagnética para permanecer en equilibrio térmico.

Otros físicos trataron de explicar las observaciones anómalas mediante modelos "semiclásicos", en los que la luz era descrita todavía mediante las ecuaciones de Maxwell, aunque los objetos materiales que emitían y absorbían luz estaban cuantizados. Aunque estos modelos semiclásicos contribuyeron al desarrollo de la mecánica cuántica, experimentos posteriores han probado las hipótesis de Einstein sobre la cuantización de la luz (los cuantos de luz son los fotones).

El concepto de fotón ha llevado a avances muy importantes en física teórica y experimental, tales como la teoría cuántica de campos, el condensado de Bose-Einstein y la interpretación probabilística de la mecánica cuántica, y a inventos como el láser.

De acuerdo con el modelo estándar de física de partículas los fotones son los responsables de producir todos los campos eléctricos y magnéticos, y a su vez son el resultado de que las leyes físicas tengan cierta simetría en todos los puntos del espacio-tiempo. Las propiedades intrínsecas de los fotones (masa invariante y espín) están determinadas por las propiedades de la simetría de Gauge. 

Los fotones se aplican a muchas áreas, como la fotoquímica, el microscopio fotónico y la medición de distancias moleculares. Incluso se los ha estudiado como componentes de computadoras cuánticas y en aplicaciones sofisticadas de comunicación óptica como por ejemplo en criptografía cuántica.

El fotón fue llamado originalmente por Albert Einstein "cuanto de luz” (en alemán: "das Lichtquant"). El nombre moderno “fotón” proviene de la palabra griega φῶς (que se transcribe como phôs), que significa luz, y fue acuñado en 1926 por el físico Gilbert N. Lewis, quien publicó una teoría especulativa en la que los fotones no se podían “crear ni destruir". Aunque la teoría de Lewis nunca fue aceptada —siendo contradicha en muchos experimentos— el nuevo nombre ""fotón"" fue adoptado enseguida por la mayoría de los científicos.

En física, el fotón se representa normalmente con el símbolo formula_4 (la letra griega gamma). Este símbolo proviene posiblemente de los rayos gamma, descubiertos y bautizados con ese nombre en 1900 por Villard y que resultaron ser una forma de radiación electromagnética según demostraron Rutherford y Andrade en 1914. En química e ingeniería óptica, los fotones se simbolizan habitualmente por formula_5, que representa también la energía asociada a un fotón, donde formula_6 es la constante de Planck y la letra griega formula_7 es la frecuencia de la partícula. Con mucha menor asiduidad, el fotón también se representa por formula_8, siendo formula_9, en este caso, la frecuencia.

El fotón no tiene masa, tampoco posee carga eléctrica y no se desintegra espontáneamente en el vacío. El fotón tiene dos estados posibles de polarización que pueden describirse mediante tres parámetros continuos: las componentes de su vector de onda, que determinan su longitud de onda formula_10 y su dirección de propagación. El fotón es el bosón de gauge de la interacción electromagnética, y por tanto todos los otros números cuánticos —como el número leptónico, el número bariónico, o la extrañeza— son exactamente cero.

Los fotones se emiten en muchos procesos naturales, por ejemplo, cuando se acelera una partícula con carga eléctrica, durante una transición molecular, atómica o nuclear a un nivel de energía más bajo, o cuando se aniquila una partícula con su antipartícula.

Los fotones se absorben en los procesos de reversión temporal que se corresponden con los ya mencionados: por ejemplo, en la producción de pares partícula-antipartícula o en las transiciones moleculares, atómicas o nucleares a un nivel de energía más alto.

En el espacio vacío, los fotones se mueven a la velocidad de la luz formula_1, y su energía formula_12 y momento lineal p están relacionados mediante la expresión formula_13, donde formula_14 es el módulo del momento lineal. En comparación, la ecuación correspondiente a partículas con una masa formula_15 es formula_16, como se demuestra en la relatividad especial.

La energía y el momento lineal de un fotón dependen únicamente de su frecuencia formula_7 o, lo que es equivalente, de su longitud de onda formula_10.

formula_19

formula_20

y en consecuencia el módulo del momento lineal es:

formula_21

donde formula_22 (conocida como constante de Dirac o constante reducida de Planck); k es el vector de onda (de módulo formula_23) y formula_24 es la frecuencia angular. Debe tenerse en cuenta que k apunta en la dirección de propagación del fotón. Este tiene además momento angular de espín que no depende de la frecuencia. El módulo de tal espín es formula_25, y la componente medida a lo largo de su dirección de movimiento, su helicidad, tiene que ser formula_26. Estos dos posibles valores corresponden a los dos posibles estados de polarización circular del fotón (en sentido horario o antihorario).

Para ilustrar la importancia de estas fórmulas, la aniquilación de una partícula con su antipartícula tiene que dar lugar a la creación de al menos dos fotones por la siguiente razón: en el sistema de referencia fijo en el centro de masas, las antipartículas que colisionan no tienen momento lineal neto, mientras que un fotón aislado siempre lo tiene. En consecuencia, la ley de conservación del momento lineal requiere que al menos se creen dos fotones, para que el momento lineal resultante pueda ser igual a cero. Las energías de los dos fotones —o lo que es equivalente, sus frecuencias— pueden determinarse por las leyes de conservación. El proceso inverso, la creación de pares, es el mecanismo principal por el que los fotones de alta energía (como los rayos gamma) pierden energía al pasar a través de la materia. 

Las fórmulas clásicas para la energía y el momento lineal de la radiación electromagnética pueden ser expresadas también en términos de eventos fotónicos. Por ejemplo, la presión de radiación electromagnética sobre un objeto es debida a la trasferencia de momento lineal de los fotones por unidad de tiempo y unidad de superficie del objeto, ya que la presión es fuerza por unidad de superficie y la fuerza, a su vez, es la variación del momento lineal por unidad de tiempo.

En la mayoría de las teorías hasta el siglo XVIII, la luz se consideraba formada por partículas. El hecho de que los modelos de partículas no pudieran explicar fenómenos como la difracción, la refracción o la birrefringencia de la luz, hizo que René Descartes en 1637, Robert Hooke en 1665, y Christian Huygens en 1678, propusieran teorías ondulatorias para la luz; sin embargo, los modelos de partículas permanecieron vigentes, principalmente debido a la influencia de Isaac Newton.

A principios del siglo XIX Thomas Young y August Fresnel demostraron con claridad que los fenómenos de interferencia y difracción se daban también para la luz, y para 1850 los modelos ondulatorios habían sido generalmente aceptados. En 1865, las predicciones de Maxwell sobre la naturaleza de la luz como onda electromagnética, que serían posteriormente confirmadas experimentalmente por Heinrich Hertz en 1888,parecieron significar el final del modelo de partículas.

Sin embargo, la teoría ondulatoria de Maxwell no explicaba todas las propiedades de la luz. Predecía que la energía de una onda luminosa dependía solamente de su intensidad, no de su frecuencia, pero diversos experimentos demostraron que la energía aportada por la luz a los átomos dependía sólo de su frecuencia, y no de su intensidad. Por ejemplo, algunas reacciones químicas eran provocadas únicamente por luz con una frecuencia mayor que un valor determinado; si la frecuencia no alcanzaba dicho valor, la reacción no se producía, independientemente de la intensidad que tuviera la luz. De forma similar, se podían extraer electrones de una placa metálica iluminándola con radiación de una frecuencia suficientemente alta (efecto fotoeléctrico), y la energía con la que los electrones abandonaban la placa era función únicamente de la frecuencia de la luz incidente, y no de su intensidad.

Al mismo tiempo, las investigaciones realizadas a lo largo de cuatro décadas (1860-1900) por varios investigadores sobre la radiación de un cuerpo negro, culminaron con la hipótesis de Max Planck,

Puesto que la teoría de Maxwell permitía todas las posibles energías de radiación electromagnética, la mayoría de los físicos asumieron inicialmente que la cuantización de la energía era el resultado de alguna restricción desconocida sobre la materia que absorbía o emitía la radiación. En 1905, Einstein fue el primero en proponer que la cuantización de la energía era una propiedad intrínseca de la radiación electromagnética. Aunque aceptaba la validez de la teoría de Maxwell, Einstein apuntó que las anomalías observadas en muchos experimentos podían explicarse si la energía de una onda de luz maxweliana estuviera localizada en unos puntos cuánticos que se movieran independientemente unos de otros, incluso aunque la onda se difundiera de forma continua por el espacio. En 1909 y 1916 Einstein demostró que si era aceptada la teoría de Planck sobre la radiación de los cuerpos negros, los cuantos de energía tenían también que poseer momento lineal formula_29, con lo que los convertía en partículas en todo el sentido de la palabra.

El momento lineal de los fotones fue observado experimentalmente por Arthur Compton, quien por este descubrimiento recibió el Premio Nobel en 1927. La pregunta fundamental entonces paso a ser: ¿cómo unificar la teoría ondulatoria de Maxwell con la naturaleza corpuscular observada experimentalmente? La respuesta a esta pregunta mantuvo ocupado a Einstein el resto de su vida, y fue resuelta dentro de la electrodinámica cuántica y de su sucesor, el modelo estándar de la física de partículas.

Las predicciones de Einstein de 1905 fueron verificadas experimentalmente de varias formas dentro de las dos primeras décadas del siglo XX, como reseñó Robert Millikan en su conferencia por la obtención del Premio Nobel. Sin embargo, antes de que los experimentos de Compton mostraran que los fotones poseían un momento lineal proporcional a su frecuencia (1922), la mayoría de los físicos eran reacios a creer que la radiación electromagnética pudiera estar formada por partículas. (véanse por ejemplo las conferencias por la obtención del Nobel de Wien,Planck y Millikan.). Estas reticencias eran comprensibles dado el éxito y verosimilitud del modelo ondulatorio de Maxwell. Por ello, la mayoría de los físicos sostenían, en su lugar, que la cuantización de la energía era consecuencia de alguna restricción desconocida sobre la materia que absorbía o emitía radiación. Niels Bohr, Arnold Sommerfeld y otros, desarrollaron modelos atómicos con niveles discretos de energía que pudieran explicar cualitativamente las finas líneas espectrales y la cuantización de la energía observada en la emisión y absorción de la luz por parte de los átomos. Estos modelos coincidían muy bien con el espectro del hidrógeno, pero no con el de otros elementos. Únicamente el experimento de Compton sobre la dispersión de fotones por un electrón "libre" (el cual no podía tener niveles de energía, al no tener una estructura interna) fue capaz de convencer a la mayoría de los investigadores sobre el hecho de que la propia luz estuviera cuantizada.

Incluso después del experimento de Compton, Bohr, Hendrik Kramers y John Slater hicieron un último intento por preservar el modelo de campo electromagnético continuo de Maxwell, que se conoció como el modelo "BKS" Para justificar los datos disponibles, había que efectuar dos hipótesis drásticas:


Sin embargo, experimentos de Compton refinados mostraron que el par "energía-momento lineal" se conservaba extraordinariamente bien en los procesos elementales, y también que la excitación del electrón y la generación de un nuevo fotón en la dispersión de Compton obedecían a una causalidad del orden de 10 ps. Como consecuencia, Bohr y sus colegas dieron a su modelo «un funeral tan honorable como fue posible». En cualquier caso, el modelo BKS inspiró a Werner Heisenberg en su desarrollo de la mecánica cuántica.

Unos cuantos físicos persistieron en el desarrollo de modelos semiclásicos, en los cuales la radiación electromagnética no estaba cuantizada, aunque la materia obedecía las leyes de la mecánica cuántica. Aunque la evidencia de los fotones, a partir de los experimentos físicos y químicos, era aplastante hacia 1970, esta evidencia no podía considerarse "absolutamente" definitiva; puesto que recaía en la interacción de la luz con la materia, una teoría de la materia suficientemente complicada podía explicar la evidencia. Sin embargo, "todas" las teorías semiclásicas fueron refutadas definitivamente en los años 70 y 80 del siglo XX por elegantes experimentos de correlación de fotones. Con ellos, se consideró probada la hipótesis de Einstein que indicaba que la cuantización era una propiedad intrínseca de la luz.

En la teoría especial de la relatividad ordinaria los fotones se mueven a lo largo de líneas rectas cuyo vector tangente es un . Dado un punto del espacio-tiempo el conjunto de direcciones en las que se puede emitir un fotón viene dado por el llamado cono de luz futuro.

En teoría de la relatividad general los fotones tienen trayectorias más complicadas y no viajan en línea recta, ya que el espacio-tiempo en presencia de materia tiene curvatura no nula. Los fotones en un espacio-tiempo general se mueven a lo largo de geodésicas lumínicas (curvas cuyo vector tangente es isótropo o de tipo luz). En algunos contextos, como sucede en el interior de los agujeros negros, todas la geodésicas dirigidas hacia el futuro apuntan hacia el interior de la región de agujero negro, por lo que los fotones y las otras partículas no pueden escapar de dicha región una vez penetraron en ella.

Los fotones, como todos los objetos cuánticos, presentan tanto propiedades ondulatorias como corpusculares. Su naturaleza dual onda-partícula puede ser difícil de visualizar. El fotón muestra sus propiedades ondulatorias en fenómenos como la difracción y las interferencias. Por ejemplo, en un experimento de la doble rejilla, un fotón individual pasando a través de éstas incidiría en la pantalla con una distribución de probabilidad dada por sus patrones de interferencia determinados por las ecuaciones de Maxwell. Sin embargo, los experimentos confirman que el fotón "no" es un corto pulso de radiación electromagnética; no se dispersa al propagarse, ni se divide al encontrarse con un divisor de haz. En vez de esto, el fotón se comporta como una partícula puntual, puesto que es absorbido o emitido en su conjunto por sistemas arbitrariamente pequeños, sistemas mucho más pequeños que sus longitudes de onda, tales como un núcleo atómico (≈10 m de diámetro) o incluso un electrón. Sin embargo, el fotón no es una partícula puntual cuya trayectoria sea determinada probabilísticamente por el campo electromagnético, según fue concebido por Einstein y otros; esa hipótesis fue también refutada por los experimentos de correlación de fotones ya mencionados anteriormente. De acuerdo con los conocimientos actuales, los propios campos electromagnéticos son producidos por fotones, los cuales a su vez resultan de una simetría de gauge local y las leyes de la teoría cuántica de campos.

Un elemento clave de la mecánica cuántica es el principio de incertidumbre de Heisenberg, que prohíbe el conocimiento simultáneo de la posición y el momento lineal de una partícula. Hay que destacar que el principio de incertidumbre para partículas materiales cargadas, "requiere" la cuantización de la luz en fotones, e incluso que la energía y el momento lineal de los fotones dependan de la frecuencia.

Una ilustración elegante es el experimento mental de Heisenberg para localizar un electrón con un microscopio ideal. La posición del electrón puede determinarse dentro de la resolución óptica del microscopio, que viene dada por la fórmula de óptica clásica

donde formula_31 es la apertura angular del microscopio. Por tanto, la incertidumbre en la posición formula_32 puede hacerse arbitrariamente pequeña reduciendo la longitud de onda. El momento lineal del electrón es incierto, formula_33, puesto que sufrió un “choque” con la luz que resultó desviada al interior del microscopio. Si la luz "no" estuviera cuantizada en fotones, la incertidumbre formula_33 podría hacerse arbitrariamente pequeña mediante la reducción de la intensidad de la luz. En ese caso, puesto que la longitud de onda y la intensidad de la luz pueden variarse de forma independiente, uno podría determinar de forma simultánea la posición y el momento lineal con una precisión arbitrariamente alta, violando el principio de incertidumbre. Como contraste, la fórmula de Einstein para el momento lineal del fotón preserva el principio de incertidumbre; puesto que el fotón es desviado a cualquier sitio dentro de la abertura, la incertidumbre del momento lineal transferido es

obteniéndose el producto formula_36, que es el principio de incertidumbre de Heisenberg. De esta forma, todo resulta cuantizado; tanto la materia como los campos tienen que obedecer un conjunto consistente de leyes cuánticas, si alguno de ellos va a ser cuantizado.

El principio de incertidumbre correspondiente para los fotones prohíbe la determinación simultánea del número formula_37 de fotones (véase estado de Fock y la sección Segunda cuantización más abajo) en una onda electromagnética y la fase formula_38 de esa onda

Tanto los fotones como las partículas materiales (p. ej.: los electrones) crean patrones de interferencia análogos cuando pasan por una doble rendija. Para los fotones, esto corresponde a la interferencia de una onda electromagnética de Maxwell mientras que, para partículas materiales, corresponde a la interferencia de la ecuación de ondas de Schrödinger. Aunque esta similitud podría sugerir que las ecuaciones de Maxwell son simplemente la ecuación de Schrödinger para los fotones, la mayoría de los físicos no están de acuerdo con esto. Por un lado, son matemáticamente diferentes; lo más obvio es que la ecuación de Schrödinger se resuelve para un campo complejo, mientras que las cuatro ecuaciones de Maxwell se resuelven para campos reales. Con mayor generalidad, el concepto habitual de una función de onda de probabilidad de Schrödinger no puede aplicarse a los fotones. Al no tener masa, no pueden localizarse sin ser destruidos; técnicamente, los fotones no pueden tener un eigenestado de posición formula_40, y, por tanto, el principio de incertidumbre habitual de Heisenberg formula_41 no es aplicable a los fotones. Se han sugerido algunas funciones de onda sustitutorias para el fotón, pero no han llegado a usarse de forma generalizada. En su lugar, los físicos aceptan generalmente la teoría de la segunda cuantización de los fotones que se describirá más abajo, en la cual los fotones son excitaciones cuantizadas de modos electromagnéticos.

En 1924, Satyendra Nath Bose derivó la ley de Planck de la radiación del cuerpo negro sin utilizar el electromagnetismo, mediante una especie de recuento en el espacio de fase. Einstein demostró que esta modificación era equivalente a asumir que los fotones son rigurosamente idénticos y que ello implicaba una "misteriosa interacción no local", ahora entendida como la exigencia de un estado simétrico mecánico cuántico. Este trabajo dio lugar al concepto de los estados coherentes y al desarrollo del láser. En los mismos artículos, Einstein amplió el formalismo de Bose a partículas no materiales (bosones), y predijo que a temperaturas lo suficientemente bajas se condensarían en su estado cuántico fundamental; este condensado de Bose-Einstein se observó experimentalmente en 1995.

Los fotones deben obedecer la estadística de Bose-Einstein si van a permitir el principio de superposición de los campos electromagnéticos, la condición es que las ecuaciones de Maxwell sean lineales. Todas las partículas se dividen en fermiones y bosones, en función de si su espín es semi-entero o entero respectivamente. El teorema de la estadística del espín pone de manifiesto que todos los bosones deben obedecer la estadística de Bose-Einstein, mientras que todos los fermiones obedecen la estadística de Fermi-Dirac o, de forma equivalente, el principio de exclusión de Pauli, que establece que, como máximo, una única partícula puede ocupar un estado cuántico. Así, si el fotón fuera un fermión, en un instante de tiempo sólo un fotón podría moverse en una dirección determinada. Esto es incompatible con la observación experimental de que los láseres pueden producir luz coherente de intensidad arbitraria, es decir, con muchos fotones desplazándose en la misma dirección. Por lo tanto, el fotón debe ser un bosón y obedecer la estadística de Bose-Einstein.

En 1916, Einstein demostró que la hipótesis cuántica de Planck formula_42 podría derivarse de un tipo de ecuación cinética. Considere una cavidad en equilibrio térmico y llena de radiación electromagnética y de sistemas que pueden emitir y absorber la radiación. El equilibrio térmico requiere que la densidad formula_43 de fotones con frecuencia formula_3 sea constante en el tiempo, por lo cual, la tasa de "emisión" de fotones a una determinada frecuencia debe ser igual a la tasa de "absorción" de ellos.

Einstein teorizó que el ritmo de absorción de un fotón de frecuencia formula_3
y transicionar de un estado de energía más bajo formula_46 a otro más alto 
formula_47 era proporcional al número formula_48 de moléculas con 
energía formula_46 y a la densidad formula_43 de fotones en el ambiente con tal frecuencia.

donde formula_52 es la constante para el ritmo de absorción formula_53 de los niveles energéticos formula_46 a formula_47.

De manera más atrevida, Einstein teorizó que el ritmo inverso formula_56 para que el sistema "emitiera" un fotón de frecuencia formula_3 y transicionara desde 
formula_47 a formula_46 se componía de dos términos:

donde formula_61 es el ritmo de emisión espontánea de un fotón y formula_62 es la constante para el ritmo de emisión en respuesta a
los fotones presentes en el ambiente (emisión inducida o estimulada).
Einstein demostró que la fórmula de Planck formula_42 es una consecuencia
necesaria de estas dos ecuaciones teóricas y de los requerimientos básicos de que la radiación ambiente esté en equilibrio térmico con los sistemas que absorben y emiten la radiación y que sea independiente de la composición del material del sistema.

Este sencillo modelo cinético fue un estímulo poderoso para la investigación. Einstein pudo mostrar que formula_64, esto es ambas constantes para los ritmos de absorción y emisión inducida eran iguales, y más sorprendente aún:

Einstein no trató de justificar sus dos ecuaciones pero hizo notar que formula_61 y formula_62 deberían poder derivarse de la mecánica y la electrodinámica modificadas para acomodadar la hipótesis cuántica. Esta predicción fue confirmada en la mecánica cuántica y en la electrodinámica cuántica, respectivamente, y ambas son necesarias para obtener las constantes de velocidad de Einstein a partir de primeros principios. Paul Dirac derivó las constantes de velocidad Bij en 1926 utilizando un enfoque semiclásico, y, en 1927, logró derivar todas las constantes de velocidad a partir de primeros principios.

El trabajo de Dirac representó el fundamento de la electrodinámica cuántica, es decir, la cuantización del mismo campo electromagnético. El enfoque de Dirac también se le llama segunda cuantización o teoría cuántica de campos, la anterior mecánica cuántica (la cuantificación de las partículas materiales moviéndose en un potencial) representa la "primera cuantización".

En 1910, Peter Debye dedujo la ley de Planck de radiación de un cuerpo negro a partir de una suposición relativamente simple. Descompuso correctamente el campo electromagnético en una cavidad, en sus modos de Fourier, y asumió que la energía en cualquier modo era un múltiplo entero de formula_68, donde formula_3 es la frecuencia del modo electromagnético. La ley de Planck de la radiación del cuerpo negro se obtiene inmediatamente como una suma geométrica. Sin embargo, la aproximación de Debye falló a la hora de dar la fórmula correcta para las fluctuaciones de energía de la radiación del cuerpo negro, que fue obtenida por Einstein en 1909.

En 1925, Born, Heisenberg y Jordan reinterpretaron el concepto de Debye en una forma clave. Como puede demostrarse clásicamente, los modos de Fourier del campo electromagnético —un conjunto completo de ondas electromagnéticas planas caracterizadas por sus vectores de onda k y sus estados de polarización— son equivalentes a un conjunto de osciladores armónicos simples desacoplados. Tratado de un modo mecano-cuántico, se demuestra que los niveles de energía de dichos osciladores son formula_70, donde formula_3 es la frecuencia del oscilador. El paso clave fue identificar un modo electromagnético con energía formula_70, como un estado con formula_73 fotones, cada uno de ellos con energía formula_68. Esta aproximación sí da la fórmula para la correcta fluctuación de energía.

Dirac dio un paso más. Él trató la interacción entre una carga y un campo electromagnético como una pequeña perturbación que induce transiciones en los estados de los fotones, cambiando el número de fotones de los modos, mientras se conservan la energía y el momento lineal total. Dirac pudo obtener los coeficientes formula_61 y formula_62 de Einstein a partir de los principios fundamentales, y demostró que la estadística de Bose-Einstein de los fotones es consecuencia natural de cuantizar correctamente los campos electromagnéticos (el razonamiento de Bose fue en el sentido opuesto; él dedujo la ley de Planck de la radiación del cuerpo negro a partir de la estadística de BE). En la época de Dirac, no era aún conocido que todos los bosones, incluidos los fotones, tienen que obedecer la estadística de BE.

La teoría de perturbaciones de segundo orden de Dirac puede involucrar a fotones virtuales, estados intermedios transitorios del campo electromagnético; dichos fotones virtuales actúan como mediadores en la electricidad estática y las interacciones magnéticas. En la teoría cuántica de campos, la amplitud de probabilidad de eventos observables se calcula mediante la suma de "todos" los posibles pasos intermedios, incluso aquellos que son no-físicos; por tanto, los fotones virtuales no se limitan a satisfacer formula_77, y pueden tener estados de polarización extra; dependiendo del gauge utilizado, los fotones virtuales pueden tener tres o cuatro estados de polarización, en lugar de los dos estados de los fotones reales. Aunque estos fotones virtuales transitorios nunca pueden ser observados, contribuyen de forma apreciable a las probabilidades de eventos observables. De hecho, dichos cálculos de perturbaciones de segundo orden y órdenes superiores pueden proporcionar aparentemente infinitas contribuciones a la suma. Los resultados no-físicos se corrigen mediante técnicas de renormalización. Otras partículas virtuales pueden contribuir también a la suma; por ejemplo, dos fotones pueden interactuar de forma indirecta por medio de pares electrón-positrón virtuales.

En notación de física moderna, el estado cuántico del campo electromagnético se escribe como un estado de Fock, un producto tensorial de los estados para cada modo electromagnético

donde formula_79 representa el estado en el cual formula_80 fotones están en el modo formula_81. En esta notación, la creación de un nuevo fotón en modo formula_81 (p. ej., el emitido desde una transición atómica) se escribe como formula_83. Esta notación simplemente expresa el concepto de Born, Heisenberg y Jordan descrito arriba, y no añade nada de física.

El campo electromagnético se puede entender por medio de una teoría gauge como un campo resultado de exigir que unas simetrías sean independientes para cada posición en el espacio-tiempo. Para el campo electromagnético, esta simetría es la simetría Abeliana U(1) de los números complejos, que refleja la capacidad de variar la fase de un número complejo sin afectar números reales construidos del mismo, tales como la energía o el lagrangiano.

El cuanto en el campo gauge abeliano debe ser tipo bosón sin carga ni masa, mientras no se rompa la simetría; por ello se predice que el fotón no tiene masa, y tener cero carga eléctrica y spin entero. La forma particular de la interacción electromagnética especifica que el fotón debe tener spin ± 1, por lo que su helicidad debe ser formula_26. Estos dos componentes del spin corresponden a los conceptos clásicos de luz polarizada circularmente a la derecha y a la izquierda. 

En el Modelo estándar de física de partículas, el fotón es una de los cuatro bosones gauge en la interacción electrodébil, siendo los otros tres los bosones W, W y Z que son responsables de la interacción débil. A diferencia de los fotones, estos bosones tienen una masa invariante debido a un mecanismo que rompe su simetría gauge SU(2) particular. La unificación de los fotones con los mencionados bosones en la interacción electrodébil fue realizada por Sheldon Glashow, Abdus Salam y Steven Weinberg, por el que fueron galardonados con el Premio Nobel de física 1979.

Los físicos continúan buscando hipótesis sobre grandes teorías de unificación que conecten estos cuatro bosones gauge con los ocho bosones gauge gluones de la cromodinámica cuántica. Sin embargo, varias predicciones importantes de estas teorías, tales como la desintegración de protones, no se han observado experimentalmente.

De acuerdo con la cromodinámica cuántica, un fotón real puede interactuar como una partícula puntual, o como una colección de quarks y gluones, esto es, como un hadrón. La estructura de los fotones no se determina por las tradicionales distribuciones de quarks de valencia como en un protón, sino por fluctuaciones del fotón puntual en una colección de partones.

En teoría de la relatividad, la energía de un sistema que emite un fotón se reduce en una cantidad igual a la energía formula_12 del fotón medida en el sistema de referencia en reposo del sistema emisor, lo cual resulta en una reducción de la masa por un valor formula_86. Del mismo modo, la masa de un sistema que absorbe un fotón se incrementa por la misma cantidad correspondiente.

Este concepto se aplica en un factor clave predicho por la QED, la teoría de la electrodinámica cuántica iniciada por Dirac (descrita anteriormente). QED es capaz de predecir el momento dipolar magnético de los leptones con una exactitud muy alta; las mediciones experimentales de los momentos de los dipolos magnéticos están perfectamente de acuerdo con estas predicciones. Las predicciones, sin embargo, requieren contar las contribuciones de fotones virtuales a la masa del leptón. Otro ejemplo de este tipo de contribuciones que están comprobadas experimentalmente es la predicción de la QED del efecto Lamb observado en la estructura hiperfina de pares de leptones ligados, tales como el muonio y el positronio.

Dado que los fotones contribuyen al tensor de energía-impulso, ejercen una atracción gravitatoria sobre otros objetos, de acuerdo con la teoría general de la relatividad. A su vez, la gravedad afecta los fotones; normalmente sus trayectorias rectas pueden ser dobladas por un espacio-tiempo deformado, como ocurre en las lentes gravitacionales, y sus frecuencias disminuyen al pasar a un potencial gravitatorio más alto, como en el experimento de Pound y Rebka. Sin embargo, estos efectos no son específicos de los fotones; los mismos efectos se predecirían para las ondas electromagnéticas clásicas.

La luz que viaja a través de materia transparente, lo hace a una velocidad menor que "c", la velocidad de la luz en el vacío. Por ejemplo, los fotones en su viaje desde el centro del Sol sufren tantas colisiones, que la energía radiante tarda aproximadamente un millón de años en llegar a la superficie; sin embargo, una vez en el espacio abierto, un fotón tarda únicamente 8,3 minutos en llegar a la Tierra. El factor por el cual disminuye la velocidad se conoce como índice de refracción del material. Desde la óptica clásica, la reducción de velocidad puede explicarse a partir de la polarización eléctrica que produce la luz en la materia: la materia polarizada radia nueva luz que interfiere con la luz original para formar una onda retardada. Viendo al fotón como una partícula, la disminución de la velocidad puede describirse en su lugar como una combinación del fotón con excitaciones cuánticas de la materia (cuasipartículas como fonones y excitones) para formar un polaritón; este polaritón tiene una masa efectiva distinta de cero, lo que significa que no puede viajar con velocidad "c". Las diferentes frecuencias de la luz pueden viajar a través de la materia con distintas velocidades; esto se conoce como dispersión. La velocidad de propagación del polaritón formula_87 es igual a su velocidad de grupo, que es la derivada de la energía con respecto al momento lineal.

donde, formula_12 y formula_14 son la energía y el módulo del momento lineal del polaritón, y formula_90 y formula_91 son su frecuencia angular y número de onda, respectivamente. En algunos casos, la dispersión puede dar lugar a velocidades de la luz extremadamente lentas. Los efectos de las interacciones de los fotones con otras cuasipartículas puede observarse directamente en la dispersión Raman y la dispersión Brillouin.

Los fotones pueden también ser absorbidos por núcleos, átomos o moléculas, provocando transiciones entre sus niveles de energía. Un ejemplo clásico es la transición molecular del retinal (CHO, figura de la derecha), que es responsable de la visión, como descubrieron el premio Nobel George Wald y su colaboradores en 1958. Como se muestra aquí, la absorción provoca una isomerización cis-trans que, en combinación con otras transiciones, dan lugar a impulsos nerviosos. La absorción de fotones puede incluso romper enlaces químicos, como en la fotólisis del cloro; éste es un tema de fotoquímica.

Los fotones tienen muchas aplicaciones en tecnología. Se han elegido ejemplos que ilustran las aplicaciones de los fotones "per se", y no otros dispositivos ópticos como lentes, etc. cuyo funcionamiento puede explicarse bajo una teoría clásica de la luz. El láser es una aplicación extremadamente importante.

Los fotones individuales pueden detectarse por varios métodos. El tubo fotomultiplicador clásico se basa en el efecto fotoeléctrico; un fotón que incide sobre una lámina de metal arranca un electrón, que inicia a su vez una avalancha de electrones. Los circuitos integrados CCD utilizan un efecto similar en semiconductores; un fotón incidente genera una carga detectable en un condensador microscópico. Otros detectores como los contadores Geiger utilizan la capacidad de los fotones para ionizar moléculas de gas, lo que da lugar a un cambio detectable en su conductividad.

La fórmula de la energía de Planck formula_92 es utilizada a menudo por ingenieros y químicos en diseño, tanto para calcular el cambio de energía resultante de la absorción de un fotón, como para predecir la frecuencia de la luz emitida en una transición de energía dada. Por ejemplo, el espectro de emisión de una lámpara fluorescente puede diseñarse utilizando moléculas de gas con diferentes niveles de energía electrónica y ajustando la energía típica con la cual un electrón choca con las moléculas de gas en el interior de la lámpara.

Bajo algunas condiciones, se puede excitar una transición de energía por medio de "dos" fotones, no ocurriendo dicha transición con los fotones por separado. Esto permite microscopios con mayores resoluciones, porque la muestra absorbe energía únicamente en la región en la que los dos rayos de colores diferentes se solapan de forma significativa, que puede ser mucho menor que el volumen de excitación de un rayo individual. Además, estos fotones causan un menor daño a la muestra, puesto que son de menor energía.

En algunos casos, pueden acoplarse dos transiciones de energía de modo que, cuando un sistema absorbe un fotón, otro sistema cercano "roba" su energía y re-emite un fotón con una frecuencia diferente. Esta es la base de la transferencia de energía por resonancia entre moléculas fluorescentes, que se utiliza para medir distancias moleculares.

Actualmente se cree comprender teóricamente la naturaleza fundamental del fotón. El modelo estándar predice que el fotón es un bosón de gauge de spin 1, sin masa ni carga, que media la interacción electromagnética y que resulta de la simetría gauge local U (1). Sin embargo, los físicos continúan buscando discrepancias entre los experimentos y las predicciones del modelo estándar, buscando nuevas posibilidades para la física más allá del modelo estándar. En particular, hay cotas de mayor precisión en los experimentos para los límites superiores para una hipotética carga y masa del fotón. 
Hasta ahora, todos los datos experimentales son consistentes con el fotón de carga y masa cero Los límites superiores aceptados universalmente en la carga y masa del fotón son 5×10 C (o 3×10 por la carga elemental) y 1.1×10 kg (6×10 eV/c), respectivamente. 

Se ha investigado mucho las posibles aplicaciones de los fotones en óptica cuántica. Los fotones parecen adecuados como elementos de un ordenador cuántico, y el entrelazamiento cuántico de los fotones es un campo de investigación. Otra área de investigación activa son los procesos ópticos no lineales, con tópicos tales como la absorción de dos fotones, auto modulación de fases y los osciladores ópticos parametrizados. Finalmente, los fotones son esenciales en algunos aspectos de la comunicación óptica, especialmente en criptografía cuántica.




</doc>
<doc id="1164" url="https://es.wikipedia.org/wiki?curid=1164" title="Física atómica">
Física atómica

La física atómica es un campo de la física que estudia las propiedades y el comportamiento de los átomos (electrones y núcleos atómicos). El estudio de la física atómica incluye a los iones así como a los átomos neutros y a cualquier otra partícula que sea considerada parte de los átomos.

La física atómica y la física nuclear tratan cuestiones distintas, la primera trata con todas las partes del átomo, mientras que la segunda lo hace solo con el núcleo del átomo, siendo este último especial por su complejidad. Se podría decir que la física atómica trata con las fuerzas electromagnéticas del átomo y convierte al núcleo en una partícula puntual, con determinadas propiedades intrínsecas de masa, carga y espín. 





</doc>
<doc id="1170" url="https://es.wikipedia.org/wiki?curid=1170" title="Federico García Lorca">
Federico García Lorca

Federico García Lorca (Fuente Vaqueros, Granada, 5 de junio de 1898-camino de Víznar a Alfacar, Granada, 18 de agosto de 1936) fue un poeta, dramaturgo y prosista español, también conocido por su destreza en muchas otras artes. Adscrito a la llamada Generación del 27, fue el poeta de mayor influencia y popularidad de la literatura española del siglo. Como dramaturgo se le considera una de las cimas del teatro español del siglo , junto con Valle-Inclán y Buero Vallejo. Murió fusilado tras el golpe de Estado que dio origen a la Guerra Civil Española un mes después de iniciada esta.

Nació en el municipio de Fuente Vaqueros, Granada (España), en el seno de una familia de posición económica desahogada, el 5 de junio de 1898, y fue bautizado con el nombre de Federico del Sagrado Corazón de Jesús García Lorca; su padre fue Federico García Rodríguez (1859-1945), un hacendado, y su madre, Vicenta Lorca Romero (1870-1959) fue la segunda esposa de su padre, maestra de escuela que fomentó el gusto literario de su hijo. Su primera casa, en Fuente Vaqueros, es hoy un museo.

En 1909, cuando tenía once años, la familia se mudó a la ciudad de Granada. En su adolescencia, se interesó más por la música que por la literatura, de hecho estudió piano con Antonio Segura Mesa y entre sus amigos de la universidad lo conocían más como músico que por escritor novel.

En 1914 se matriculó en la Universidad de Granada para estudiar las carreras de Filosofía y Letras y de Derecho. Durante esta época, el joven Lorca se reunía con otros jóvenes intelectuales en la tertulia «El Rinconcillo» del café Alameda.

En la Universidad recibió clases de Martín Domínguez Berrueta, profesor de Teoría de la Literatura y de las Artes, el cual llevó a Lorca y a sus compañeros de viaje por Baeza, Úbeda, Córdoba, Ronda, León, Burgos y Galicia. Estos viajes por distintas partes de España fueron los que despertaron su vocación como escritor. De hecho, fruto de esto surgió su primer libro en prosa "Impresiones y paisajes", publicado en 1918, una pequeña antología de sus mejores páginas en prosa sobre temas políticos y sobre sus intereses estéticos.

En la primavera de 1919, varios de sus amigos de "El Rinconcillo" se trasladaron a Madrid, y Lorca, gracias a la ayuda de Fernando de los Ríos, quien le ayudó a convencer a sus padres a seguir sus estudios en la Residencia de Estudiantes, no tardó en unirse a ellos. Así pasó el poeta a formar parte de esta institución.

La Residencia de Estudiantes era en aquella época un hervidero intelectual, que acogió a figuras de la talla de Albert Einstein, John Maynard Keynes o Madame Curie, lo que influiría enormemente en la formación intelectual de Lorca. De esta forma, entre los años 1919 y 1926, se relacionó con muchos de los escritores e intelectuales más importantes de España, como Luis Buñuel, Rafael Alberti o Salvador Dalí y consiguió huir del tedio cultural provinciano, que odiaba, como escribió a su amigo el compositor Adolfo Salazar:

Entre 1919 y 1921, Lorca publicó "Libro de poemas", compuso sus primeras "Suites", estrenó "El maleficio de la mariposa" y desarrolló otras piezas teatrales. También durante esta etapa, gracias otra vez a la ayuda de Fernando de los Ríos, tuvo ocasión de conocer a Juan Ramón Jiménez, que influiría en su visión de la poesía y con el que llegaría a tener mucha amistad.

En mayo de 1921, Lorca volvió a Granada, teniendo así la oportunidad de conocer al maestro Manuel de Falla, que se había instalado en la ciudad en septiembre del año anterior. Su amistad les llevó a emprender varios proyectos en torno a la música, el cante jondo, los títeres, y otras actividades artísticas paralelas. Ese mismo año, Lorca escribió el "Poema del cante jondo", obra que no se publicaría hasta diez años después. Esos años en Granada giraron alrededor de dos focos culturales: Falla y la tertulia de El Rinconcillo, reunida en el café Alameda.

El 6 de enero de 1923, festividad de los Reyes Magos, Falla participó en una fiesta privada montada por Federico, Adolfo Salazar y Hermenegildo Lanz, dedicada a dos niñas de la familia, su hermana Isabel y Laura, la hija de Fernando de los Ríos. Se representó una adaptación lorquiana para títeres de cachiporra del cuento andaluz "La niña que riega la albahaca y el príncipe preguntón", un entremés atribuido a Cervantes y el "Misterio de los Reyes Magos", un auto sacramental del siglo XIII, para el que Falla había colaborado en la composición de la música incidental. Aquel mismo año, Lorca y Falla trabajaron en una opereta lírica, "Lola, la comedianta", obra que nunca terminaron.

En 1925 viajó a Cadaqués para pasar la Semana Santa en casa de su amigo Salvador Dalí. Esta visita y otra más larga en 1927 marcaron profundamente la vida y obra de ambos. Fruto de esta intensa amistad fue la "Oda a Salvador Dalí", que se publicó en la "Revista de Occidente" en 1926. Además, fue el mismo Dalí el que animó al escritor a iniciarse en la pintura, consiguiendo que en 1927 presentase su primera exposición en las Galeries Dalmau de Barcelona. Por su parte, Lorca alentó a Dalí como escritor.

El término parte de la fecha de diciembre de 1927, cuando se reúnen varios poetas españoles en Sevilla, en un acto organizado por la Sociedad Económica de Amigos del País para conmemorar los trescientos años de la muerte de Luis de Góngora. Cabe destacar que esta reunión es el origen de lo que algunos llaman la Generación del 27 en la que se incluyen escritores como Jorge Guillén, Pedro Salinas, Rafael Alberti, Dámaso Alonso, Gerardo Diego, Luis Cernuda, Vicente Aleixandre, Manuel Altolaguirre y Emilio Prados.

No todos los estudiosos reconocen el concepto de generación a la Generación del 27 al no cumplir los criterios establecidos por el historiador Julius Petersen (fechas de nacimiento próximas; formación educativa semejante; buenas relaciones entre ellos; fecha próxima en la publicación de sus primeras obras; hecho histórico generacional; ideas comunes; lenguaje generacional; presencia de un guía ideológico; y anquilosamiento de la generación anterior). Algunos han propuesto un cambio de nombre como Generación de la Dictadura, Generación Guillén-Lorca, Generación de 1925, Generación de las Vanguardias, Generación de la amistad, etc. Sin embargo, es un término muy admitido por comodidad y costumbre.

Este grupo se caracteriza por fundir las formas de la poesía tradicional (neopopularismo) con los movimientos de vanguardia; por tratar los mismos temas de una manera similar (la muerte en sentido trágico; el amor como fuerza que da sentido a la vida; preocupaciones sociales como la injusticia, la miseria, etc.), por el uso de la metáfora y la imagen; etc.

Volviendo a la vida de Lorca, se puede decir que la etapa de 1924 a 1927 fue el momento en el que el escritor llegó a su madurez como poeta.

Sin embargo, también es en esta época cuando Federico García Lorca vive, según sus palabras, «una de las crisis más hondas de mi vida», a pesar de que sus obras "Canciones" y "Primer romancero gitano", publicados en 1927 y 1928 respectivamente, están gozando de gran éxito crítico y popular. Esta crisis fue provocada por varios acontecimientos en su vida. Por un lado, con el éxito del "Romancero gitano", comenzó a verse a Lorca como costumbrista, defensor de los gitanos, ligado al folclore andaluz. Este se quejaba en una carta a Jorge Guillén diciendo: «Me va molestando un poco mi mito de gitanería. Los gitanos son un tema. Y nada más. Yo podía ser lo mismo poeta de agujas de coser o de paisajes hidráulicos. Además, el gitanismo me da un tono de incultura, de falta de educación y de poeta salvaje que tú sabes bien no soy. No quiero que me encasillen. Siento que me va echando cadenas». Y, por otro lado, se separó de Emilio Aladrén, un escultor con el que había mantenido una intensa relación afectiva. Además, esta crisis debió agravarse cuando Lorca recibió las duras críticas de Dalí y Luis Buñuel sobre el "Romancero gitano". A pesar de esto, Lorca siguió trabajando y comenzando nuevos proyectos, como la revista "Gallo" de la que solo se publicaron dos números o la obra "Amor de don Perlimplín con Belisa en su jardín", la cual intentó estrenar en 1929 pero fue prohibida por la censura de la Dictadura de Primo de Rivera.

En la primavera de 1929, Fernando de los Ríos propuso a Lorca que le acompañase en su viaje a Nueva York. Este aceptó viendo la oportunidad de alejarse de Aladrén , aprender inglés, cambiar de vida y renovar su obra. Se embarcaron en el —buque hermano del malogrado — a principios de junio de 1929 y llegaron el 26 de junio a Nueva York; él mismo describió su estancia en Nueva York como "una de las experiencias más útiles de mi vida". Describió a la ciudad como un lugar de «de alambre y muerte» y se vio sorprendido por la economía capitalista y el trato a los negros. Según él, Estados Unidos era «una civilización sin raíces. [Los ingleses] han levantado casas y casas, pero no han ahondado en la tierra». Volcó sus impresiones en "Poeta en Nueva York", que no se publicó hasta cuatro años después de su muerte. En su trabajo Lorca buscó expresar «la esclavitud dolorosa del hombre y máquina juntos» en una ciudad a la que denominó como «geometría y angustia».

En marzo de 1930 dejó Nueva York para viajar a la ciudad de La Habana en Cuba, donde exploró la cultura y la música cubana y trabajó en nuevos proyectos como "El público" y "Así que pasen cinco años". En junio de 1930, Lorca ya estaba en Madrid.

Con la instauración de la Segunda República en abril de 1931, comenzó una nueva etapa para Lorca. Junto a Eduardo Ugarte, el escritor granadino codirigió La Barraca, un grupo de teatro universitario que representó obras teatrales del Siglo de Oro (Calderón de la Barca, Lope de Vega, Miguel de Cervantes) por ciudades y pueblos de España. Financiado por el Ministerio de Educación que dirigía el socialista Fernando de los Ríos, tuvo por primera vez en sus manos un proyecto propio. El estallido de la guerra civil española frustraría el empeño.

En 1933 la compañía de Lola Membrives estrenó en Buenos Aires "Bodas de sangre" con un gran éxito popular. Por ello, Lorca recibió la invitación de Lola Membrives y de su marido para viajar a esta ciudad. Allí, consiguió triunfar profesionalmente y, gracias a esto, consiguió su independencia económica. A lo largo de los seis meses que permaneció en Buenos Aires, tuvo la oportunidad de dirigir "Bodas de sangre", que fue representada más de ciento cincuenta veces; "Mariana Pineda", "La zapatera prodigiosa", "El retablillo de don Cristóbal" y una adaptación de "La dama boba" de Lope de Vega. También durante este tiempo tuvo la ocasión de dar varias conferencias y de hacer nuevas amistades, como Pablo Neruda, Juana de Ibarbourou, Ricardo Molinari, Salvador Novo y Pablo Suero.

Cuando García Lorca volvió a España en 1934, mantuvo un elevado ritmo creativo: terminó obras como "Yerma", "Doña Rosita la soltera", "La casa de Bernarda Alba" y "Llanto por Ignacio Sánchez Mejías"; revisó obras como "Poeta en Nueva York", "Diván del Tamarit y Suites"; hizo un viaje a Barcelona para dirigir algunas de sus obras, recitar sus poemas y dar conferencias, visitó Valencia y siguió representando obras con La Barraca; organizó clubes de teatro; etc. También tuvo una gran estadía en Montevideo (Uruguay), donde terminó de escribir un par de obras y tuvo contacto con los artistas locales, tales como Juana de Ibarbourou.

Sin embargo, es también en este momento cuando en España se empieza a vivir una época de violencia e intolerancia. La situación política era insostenible. Estaba a punto de estallar la Guerra Civil española.

Colombia y México, cuyos embajadores previeron que el poeta pudiera ser víctima de un atentado debido a su puesto de funcionario de la República, le ofrecieron el exilio, pero Lorca rechazó las ofertas y se dirigió a la Huerta de San Vicente para reunirse con su familia. Llegó allí el 14 de julio de 1936, tres días antes de que estallara en Melilla la sublevación militar contra la República que dio lugar a la Guerra civil. Inicialmente, la situación en la capital granadina fue tranquila y no hubo ningún incidente. Sin embargo, el día 20, la guarnición militar se sublevó y en poco tiempo el centro de Granada estaba en poder de las fuerzas sublevadas. El cuñado de Federico y alcalde de la ciudad, Manuel Fernández-Montesinos, fue arrestado en su despacho del ayuntamiento. Sería fusilado un mes más tarde.

En esos momentos políticos alguien le preguntó sobre su preferencia política y él manifestó que se sentía a su vez católico, comunista, anarquista, libertario, tradicionalista y monárquico. De hecho nunca se afilió a ninguna de las facciones políticas y jamás discriminó o se distanció de ninguno de sus amigos, por ninguna cuestión política. Conocía al líder y fundador de la Falange Española, José Antonio Primo de Rivera, muy aficionado a la poesía. El propio Lorca dijo de él al joven Gabriel Celaya, en marzo de 1936:

Esta declaración es entendida por los estudiosos como una exageración o una broma, como lo apuntó el propio Celaya al relatar esta anécdota. Al describir la escena, resume las consecuencias dramáticas de la actitud insensata de García Lorca:

Se sentía, como dijo al periodista y caricaturista Luis Bagaría en una entrevista para "El Sol" de Madrid poco antes de su muerte, íntegramente español, pero «antes que esto hombre del mundo y hermano de todos».

En Granada buscó refugio en casa de la familia de su amigo el poeta Luis Rosales, donde se sentía más seguro ya que dos de sus hermanos, en los que confiaba, eran destacados falangistas de Granada. A pesar de ello, el 16 de agosto de 1936, se presentó allí la Guardia Civil para detenerlo. Acompañaban a los guardias Juan Luis Trescastro Medina, Luis García-Alix Fernández y Ramón Ruiz Alonso, exdiputado de la CEDA, que había denunciado a Lorca ante el gobernador civil de Granada José Valdés Guzmán. Valdés consultó con Queipo de Llano lo que debía hacer, a lo que este le respondió: «Dale café, mucho café». Según el historiador Ian Gibson, se acusaba al poeta de «ser espía de los rusos, estar en contacto con éstos por radio, haber sido secretario de Fernando de los Ríos y ser homosexual». Fue trasladado al Gobierno Civil, y luego al pueblo de Víznar donde pasó su última noche en una cárcel improvisada, junto a otros detenidos.

Después de que la fecha exacta de su muerte haya sido objeto de una larga polémica, parece definitivamente establecido que Federico García Lorca fue fusilado a las 4:45 h de la madrugada del 18 de agosto, en el camino que va de Víznar a Alfacar. Su cuerpo permanece enterrado en una fosa común anónima en algún lugar de esos parajes, junto con el cadáver de un maestro nacional, Dióscoro Galindo, y los de los banderilleros anarquistas Francisco Galadí y Joaquín Arcollas, ejecutados con él. Juan Luis Trescastro presumiría después de haber participado personalmente en los asesinatos, recalcando la homosexualidad de Lorca.La fosa se encuentra en el paraje de Fuente Grande, en el municipio de Alfacar.

H. G. Wells envió el siguiente despacho a las autoridades militares de Granada:

cuya respuesta fue la siguiente:

El 23 de abril de 2015 se hizo público un informe policial de julio de 1965, basado en una investigación realizada en 1965, que corroboraba la ejecución de Lorca por las autoridades franquistas. En el informe se le acusaba de «socialista», amigo de Fernando de los Ríos, y «masón, perteneciente a la logia 'Alhambra', en la que adoptó el nombre simbólico de 'Homero'», y le atribuía «prácticas de homosexualismo y aberración». También afirma que fue condenado a muerte tras «haber confesado», aunque no especifica qué habría confesado. El informe está fechado el 9 de julio de 1965, y fue redactado por la 3.ª brigada regional de investigación social de la Jefatura Superior de la Policía de Granada a petición de la hispanista francesa Marcelle Auclair, aunque nunca obtuvo respuesta, ya que el informe fue ocultado por la dictadura franquista. La existencia del dicho informe fue mencionada por primera vez por el periodista falangista Eduardo Molina Fajardo en su libro póstumo, "Los últimos días de García Lorca" (1983). Según Gibson, es evidente que Molina Fajardo había tenido acceso al informe policial.

Después de su muerte se publicaron "Primeras canciones" y "Amor de Don Perlimplín con Belisa en su jardín".

Una de las obras más estremecedoras sobre el hecho de su muerte es el poema «El crimen fue en Granada», escrito por Antonio Machado en 1937. En el otro bando, el periódico falangista de San Sebastián, "Unidad", publicó el 11 de marzo de 1937, una sentida elegía firmada por Luis Hurtado Álvarez y titulada «A la España imperial le han asesinado su mejor poeta».

Una de las biografías sobre Federico García Lorca más documentadas, controvertidas y populares es el best-seller publicado en 1989 y titulado "Federico García Lorca: A life" ("Vida pasión y muerte de Federico García Lorca", edición en español en 1998), del hispanista de origen irlandés Ian Gibson.

En 2009, en aplicación de la ley para la recuperación de la memoria histórica aprobada por el gobierno de José Luis Rodríguez Zapatero, se abrió la fosa donde supuestamente descansaban los restos del poeta, sin encontrarse nada.

En mayo de 2012 salió a la luz su última carta, dirigida a su amigo íntimo, el escritor y crítico de arte Juan Ramírez de Lucas.

En 2014 se iniciaron trabajos de localización de la fosa donde fue enterrado y de identificación de cuerpos, aunque dada la negativa de la familia del poeta parece improbable la exhumación de su cuerpo.

En 2015 la escritora Marta Osorio publica un libro en el que analiza la información que Agustín Penón recopiló sobre el emplazamiento del cuerpo del poeta (principalmente de Emilia Llanos, amiga íntima del poeta), apuntando a un traslado del cuerpo a otro emplazamiento del mismo camino donde fue enterrado o incluso a Madrid.

El universo lorquiano se define por un palpable sistematismo: la poesía, el drama y la prosa se alimentan de obsesiones —amor, deseo, esterilidad— y de claves estilísticas constantes. La variedad de formas y tonalidades nunca atenta contra esa unidad cuya cuestión central es la frustración.

Los símbolos: de acuerdo con su gusto por los elementos tradicionales, Lorca utiliza frecuentemente símbolos en su poesía. Se refieren muy frecuentemente a la muerte aunque, dependiendo del contexto, los matices varían bastante. Son símbolos centrales en Lorca:


La metáfora: es el procedimiento retórico central de su estilo. Bajo la influencia de Góngora, Lorca maneja metáforas muy arriesgadas: la distancia entre el término real y el imaginario es considerable. En ocasiones, usa directamente la metáfora pura. Sin embargo, a diferencia de Góngora, Lorca es un poeta conceptista, en el sentido de que su poesía se caracteriza por una gran condensación expresiva y de contenidos, además de frecuentes elipsis. Las metáforas lorquianas relacionan elementos opuestos de la realidad, transmiten efectos sensoriales entremezclados, etc.

El neopopularismo: aunque Lorca asimila sin problemas las novedades literarias, su obra está plagada de elementos tradicionales que, por lo demás, demuestran su inmensa cultura literaria. La música y los cantos tradicionales son presencias constantes en su poesía. No obstante, desde un punto de vista formal no es un poeta que muestre una gran variedad de formas tradicionales; sin embargo, profundiza en las constantes del espíritu tradicional de su tierra y de la gente: el desgarro amoroso, la valentía, la melancolía y la pasión.

La obra poética de Lorca constituye una de las cimas de la poesía de la Generación del 27 y de toda la literatura española. La poesía lorquiana es el reflejo de un sentimiento trágico de la vida, y está vinculada a distintos autores, tradiciones y corrientes literarias. En esta poesía conviven la tradición popular y la culta. Aunque es difícil establecer épocas en la poética de Lorca, algunos críticos diferencian dos etapas: una de juventud y otra de plenitud.

Aquí se incluyen sus primeros escritos: "Impresiones y paisajes" (en prosa, aunque sin embargo muestra procedimientos característicos del lenguaje poético) y "Libro de poemas" (escrito bajo el influjo de Rubén Darío, Antonio Machado y Juan Ramón Jiménez); en este poema García Lorca proyecta un amor sin esperanza, abocado a la tristeza.

La Diputación de Granada editó en 1986 una antología poética, seleccionada, presentada y anotada por Andrew A. Anderson. Esta antología aporta "Suites" (1920-1923) y "Poemas en prosa" (1927-1928). En "Suites" se encuentra «» (pág. 71), y en "Poemas en prosa" «Degollación de los Inocentes» (pág. 150). En estos escritos el poeta hace referencia al drama del aborto.

"La viudita y el conde Cabra", basada en una historia real y que llegó a sus oídos a través de una canción infantil.

Comienza con el "Poema del cante jondo" (1921) que, mediante la unidad temática, formal, conceptual y la expresión de los sentimientos, debida en parte a su inspiración folclórica, describe la lírica neopopularista de la Generación del 27.

En "Primeras canciones" (1936) y "Canciones" (1927) emplea las mismas formas: la canción y el romance. Los temas del tiempo y la muerte se enmarcan en el alba, la noche, la ciudad andaluza y los paisajes lunares.

La muerte y la incompatibilidad moral del mundo gitano con la sociedad burguesa son los dos grandes temas del "Romancero gitano". Destacan los procedimientos habituales de poesía de origen popular, y la influencia del compositor Manuel de Falla. No se trata de una obra folclórica; está basada en los tópicos con que se asocia lo gitano y andaluz. Lorca eleva al personaje gitano al rango de mito literario, como después hará también con el negro y el judío en "Poeta en Nueva York". En el "Romancero gitano" emplea el romance, en sus variantes de novelesco, lírico y dramático; su lenguaje es una fusión de lo popular y lo culto.

Lorca escribió "Poeta en Nueva York" a partir de su experiencia en EE. UU., donde vivió entre 1929 y 1930. Para Lorca la civilización moderna y la naturaleza son incompatibles. Su visión de Nueva York es de pesadilla y desolación, propia de un mal sueño. Para expresar la angustia y el ansia de comunicación que lo embargan, emplea las imágenes visionarias del lenguaje surrealista. Su libertad expresiva es máxima, aunque junto al verso libre se advierte el uso del verso medido (octosílabo, endecasílabo y alejandrino).

El "Diván del Tamarit" (1940) es un libro de poemas de atmósfera o sabor oriental, inspirado en las colecciones de la antigua poesía arábigo-andalusí. El tema central es el del amor sujeto a experiencias frustrantes y amargas; su lenguaje está muy próximo al de "Poeta en Nueva York".

"Llanto por la muerte de Ignacio Sánchez Mejías" (1935) es una elegía de incontenible dolor y emoción que actúa de homenaje al torero sevillano que tanto apoyó a los poetas de la Generación del 27.

La obra poética de García Lorca se cierra con "Seis poemas gallegos" y la serie de once poemas amorosos titulada "Sonetos del amor oscuro". Lorca siempre ha contado con el respeto y admiración incondicional de los poetas de generaciones posteriores a la Guerra Civil. Considerado un poeta maldito, su influencia se ha dejado sentir entre los poetas españoles del malditismo.


El teatro de García Lorca es, con el de Valle-Inclán, el de mayor importancia escrito en castellano en el siglo XX. Es un teatro poético, en el sentido de que gira en torno a símbolos medulares —la sangre, el cuchillo o la rosa—, de que se desarrolla en espacios míticos o presenta un realismo trascendido, y de que, en fin, encara problemas sustanciales del existir. El lenguaje, aprendido en Valle-Inclán, es también poético. Sobre Lorca influyen también el drama modernista (de aquí deriva el uso del verso), el teatro lopesco (evidente, por ejemplo, en el empleo organizado de la canción popular), el calderoniano (desmesura trágica, sentido de la alegoría) y la tradición de los títeres. La producción dramática de Lorca puede ser agrupada en cuatro conjuntos: farsas, comedias «irrepresentables» (según el autor), tragedias y dramas.

Entre las farsas, escritas entre 1921 y 1928, destacan "La zapatera prodigiosa", en la que el ambiente andaluz sirve de soporte al conflicto, cervantino, entre imaginación y realidad, y "Amor de don Perlimplín con Belisa en su jardín", complejo ritual de iniciación al amor, que anuncia los «dramas irrepresentables» de 1930 y 1931: "El público" y "Así que pasen cinco años", sus dos obras más herméticas, son una indagación en el hecho del teatro, la revolución y la presunta homosexualidad —la primera— y una exploración —la segunda— en el ser humano y en el sentido del vivir.

Consciente del éxito de los dramas rurales poéticos, Lorca elabora las tragedias "Bodas de sangre" (1933) y "Yerma" (1934), conjugación de mito, poesía y sustancia real.

Los problemas humanos determinan los dramas. Así, el tema de la «solterona» española ("Doña Rosita la soltera", 1935), o el de la represión de la mujer y la intolerancia en "La casa de Bernarda Alba" (1936), para muchos la obra maestra del autor.










</doc>
<doc id="1171" url="https://es.wikipedia.org/wiki?curid=1171" title="Franz Kafka">
Franz Kafka

Franz Kafka (Praga, Imperio austrohúngaro, 3 de julio de 1883-Kierling, Austria, 3 de junio de 1924) fue un escritor de origen judío nacido en Bohemia que escribió en alemán. Su obra está considerada una de las más influyentes de la literatura universal y está llena de temas y arquetipos sobre la alienación, la brutalidad física y psicológica, los conflictos entre padres e hijos, personajes en aventuras terroríficas, laberintos de burocracia y transformaciones místicas.

Fue autor de las novelas "El proceso" "(Der Prozeß)", "El castillo" "(Das Schloß)" y "El desaparecido" "(Amerika" o "Der Verschollene)", la novela corta "La metamorfosis" "(Die Verwandlung)" y un gran número de relatos cortos. Además, dejó una abundante correspondencia y escritos autobiográficos. Su peculiar estilo literario ha sido comúnmente asociado con la filosofía artística del existencialismo —al que influyó— y el expresionismo. Estudiosos de Kafka discuten sobre cómo interpretar al autor, algunos hablan de la posible influencia de alguna ideología política antiburocrática, de una religiosidad mística o de una reivindicación de su minoría etnocultural, mientras otros se fijan en el contenido psicológico de sus obras. Sus relaciones personales también tuvieron gran impacto en su escritura, particularmente su padre ("Carta al padre"), su prometida Felice Bauer ("Cartas a Felice") y su hermana ("Cartas a Ottla").

Albert Camus, Jean-Paul Sartre, Jorge Luis Borges y Gabriel García Márquez se encuentran entre los escritores influidos por la obra de Kafka. El término "kafkiano" se usa en el idioma español para describir situaciones insólitas, por lo absurdas y angustiosas, como las que se encuentran en sus libros y tiene sus equivalentes en otros idiomas. Solo unas pocas de sus obras fueron publicadas durante su vida. La mayor parte, incluyendo trabajos incompletos, fueron publicados por su amigo Max Brod, quien ignoró los deseos del autor de que los manuscritos fueran destruidos.

Franz Kafka nació en Praga el 3 de julio de 1883 en el seno de una familia de judíos asquenazíes. Sus padres fueron Hermann Kafka (1852-1931) y Julie Löwy (1856-1934).
Su padre había nacido en Wossek, aldea de población mayoritariamente judía checo-hablante, cerca de Písek, en la región de Bohemia Meridional. Originario de una familia rural judía de carniceros, con frecuentes problemas económicos, tras trabajar como representante de comercio, en 1881 se estableció por su cuenta en Praga, donde regentó un negocio textil en la "Zeltnergasse" (Celetná ulice) 12, que contaba con 15 empleados cuando Franz nació. Utilizaba un grajo ("kavka", en checo) como emblema comercial.

Su madre, nacida en Poděbrady, era de familia germano hablante perteneciente a la burguesía judeoalemana. Era hija de Jakob Löwy, un próspero fabricante de cerveza. Provenía, por tanto, de una familia mucho más adinerada que la de su marido y tenía una educación más refinada. En su ámbito había profesores universitarios, bohemios y artistas.

El matrimonio se instaló en Praga y pasó a formar parte de la alta sociedad. Desde el comienzo, quien marcó la pauta de la educación de Franz fue el padre que, como resultado de su propia experiencia, insistió en la necesidad del esfuerzo continuado para superar todas las dificultades de la existencia, siempre desde una actitud permanente de autoritarismo y prepotencia hacia sus hijos. La madre quedó relegada a un papel secundario en el aspecto educativo.

El pequeño recibió su nombre de pila en honor al emperador Francisco José I. Era el mayor de seis hermanos. Dos de ellos, Georg y Heinrich, fallecieron a los quince y seis meses de edad, respectivamente, antes de que Franz cumpliera los siete años. Tuvo tres hermanas: Gabriele ("Elli") (1889-1941), Valerie ("Valli") (1890-1942), y Ottilie ("Ottla") (1892-1943). Tras la ocupación de Checoslovaquia, los nazis llevaron a las tres hermanas al gueto de Łódź. De allí llevaron a Ottilie al campo de concentración de Theresienstadt y el 7 de octubre de 1943 al campo de exterminio de Auschwitz, donde murió ese mismo día en las cámaras de gas, igual que otras 1318 personas que también acababan de llegar. Las otras dos hermanas también perecieron en el Holocausto.

Las relaciones con sus hermanos constituyeron una experiencia singular en la formación del carácter de Franz, especialmente en lo que respecta a Georg y Heinrich, por cuya muerte se sintió culpable, en cierto sentido, al vincularla con sus deseos de que desapareciesen, motivado por sus celos.

Como muchos praguenses en aquella época, Kafka hablaba checo y alemán, en su caso desde la primera infancia, por ser las lenguas maternas de su padre y madre, respectivamente. Posteriormente adquirió conocimientos de francés y cultura francesa. Entre sus autores favoritos estaban Flaubert, Dickens, Cervantes y Goethe.

Cursó sus estudios primarios entre 1889 y 1893, en la Deutsche Knabenschule, ubicada en Masný trh/Fleischmarkt, actualmente Masá única. Sus padres tenían poco apego a las tradiciones judías y, aparte de la celebración del Bar Mitzvah, al cumplir Franz los 13 años acudía a regañadientes apenas cuatro veces al año a la sinagoga, acompañado de su padre.

Cursó la educación secundaria, entre los diez y los dieciocho años, en el riguroso Altstädter Deutsches Gymnasium (Instituto de Enseñanza Media Imperial Real), situado en el interior del Palacio Kinsky, en la Staroměstské náměstí («Plaza de la Ciudad Vieja»).

Durante los últimos años de su adolescencia se hizo miembro de la Freie Schule («Escuela Libre»), una institución anticlerical. Leía ávidamente a Nietzsche, Darwin y Haeckel, sentía verdadero entusiasmo por el socialismo (especialmente en lo que se refiere al ideal de solidaridad) y el ateísmo. Por lo demás, sus notas sobresalían de la media de sus compañeros. Entabló una gran amistad con un compañero de clase, Oskar Pollak, con el que compartía el interés por las ciencias naturales y la historia del arte.

Hacia los 14 años, Kafka realizó sus primeros intentos como escritor. Aunque destruyó los textos, llegó a percibir la diferencia entre sus trabajos y los de sus compañeros de clase, sobre todo en el aspecto formal.

Tras aprobar el examen de bachillerato en 1901, comenzó a estudiar Química en la Universidad de Praga, pero solo duró dos semanas. A continuación, probó también Historia del Arte y Filología alemana, pero finalmente, obligado por su padre, estudió Derecho. Alfred Weber (hermano de Max Weber), profesor de sociología, ejerció una enorme influencia sobre él y dirigió su tesis doctoral. A Kafka le impresionó la forma en que analizaba la sociedad industrial y sus peligros. Obtuvo el doctorado en leyes el 18 de junio de 1906.

Mientras estudiaba, participó en la organización de actividades literarias y sociales como miembro del club Lese- und Redehalle der Deutschen Studenten. Promocionó representaciones para el teatro judeoalemán. En sus relaciones sociales, Kafka temía causar repulsión tanto por su físico como por su personalidad. Sin embargo, impresionaba a los demás con su aspecto infantil, pulcro y austero, su conducta tranquila y fría y su gran inteligencia, además de su particular sentido del humor. Desde 1905 se vio obligado a frecuentar los sanatorios por su debilidad física.

Al terminar la carrera de Derecho en 1906, hizo un año de servicio obligatorio (sin remuneración) en los tribunales civiles y penales, con funciones administrativas. Tras ello, entró como pasante, también sin retribución, en una casa italiana de seguros de accidentes laborales, Assicurazioni Generali. Entonces empezó a escribir. Tras abandonar la compañía de seguros en 1908, consiguió un trabajo en la compañía Arbeiter-Unfall-Versicherungs-Anstalt für Königsreich Böhmen, en la que estuvo hasta su jubilación anticipada en 1922 por causa de la tuberculosis, enfermedad que empezó a padecer en 1917 y que le causaría la muerte en 1924. Aunque el padre de Kafka se refería a este trabajo como "Brotberuf", un empleo solo para pagar las cuentas, el horario cómodo le permitió dedicarse a escribir. Con todo, este trabajo burocrático, que desempeñó con competencia y en el que fue ascendiendo de puesto, le dio muchas ideas para su obra literaria.

Entre 1909 y 1912 hizo varios viajes al extranjero: Riva (1909), París (1910), otra vez a Italia y París (1911) y Weimar (1912).

En 1912 Kafka tomó conciencia de ser escritor. Escribió en ocho horas "Das Urteil" ("El juicio") y, a finales de noviembre de 1912, terminó "Contemplación" ("Betrachtung"), una colección de dieciocho relatos que previamente habían aparecido dispersos en diversos medios. La aparición de este libro le dio a conocer como escritor.

En 1913 escribió "Consideración" y, en 1915, "La metamorfosis". En 1917 se le diagnosticó tuberculosis, lo que le obligó a mantener frecuentes períodos de convalecencia, durante los que recibió el apoyo de su familia, en especial de su hermana Ottilie, con quien tenía mucho en común. En 1919 terminó los catorce cuentos fantásticos (o catorce lacónicas pesadillas) que componen "Un médico rural".

Un tema de gran importancia en su obra es su relación con un padre autoritario. En la intimidad, este no dejó nunca de menospreciar a su hijo y hasta el año 1922 lo tiranizó. De ese conflicto y de sus tenaces meditaciones sobre las "misteriosas misericordias" y las ilimitadas exigencias de la patria potestad, declaró el propio Kafka que procedía toda su obra, en particular su célebre "Carta al padre", nunca publicada en vida.

Entre 1913 y 1917 mantuvo una relación difícil con Felice Bauer, que dio origen a una correspondencia de más de 500 cartas y tarjetas postales. Su falta de reacción ante el manuscrito de "La metamorfosis" llevó a Kafka a un profundo abatimiento. Aunque llegó a presentar una solicitud de matrimonio en junio de 1913, al final no lo hicieron. Ya en el otoño de ese mismo año se produjo una primera ruptura, ocasionada al conocer a G.W, la mujer identificada como «la suiza» en sus diarios, durante su estancia en el sanatorio de Riva.

Después de esto, Kafka intentó trasladarse a Berlín, pero el estallido de la Primera Guerra Mundial se lo impidió. No fue movilizado por sus problemas de salud. Durante la segunda mitad de 1914 escribió un antecedente de "El proceso" ("Fragmento de Josef K.") y la narración "En la colonia penitenciaria".

Debido a la guerra, el marido de su hermana Elli tuvo que incorporarse al ejército, por lo que Kafka tuvo que hacerse cargo de la dirección de la fábrica de la familia y su hermana debió trasladarse a vivir a la casa familiar. Esto obligó a Kafka a alquilar una habitación. Como consecuencia de todo ello no escribió nada durante casi año y medio, desde octubre de 1914.

Deprimido por estos acontecimientos, intentó reconciliarse con Felice, ayudado por Grete Bloch, con quien mantenía una relación que daría lugar a un hijo. En julio de 1917 se comprometieron en matrimonio, pero otra vez la boda no llegó a consumarse. En diciembre se separaron definitivamente.

La noche del 12 al 13 de agosto se le manifestó una hemoptisis que confirmó una tuberculosis pulmonar. Durante su estancia en Schlesen para asistir a un sanatorio conoció a Julie Wohryzek, con la que se prometió en matrimonio. La extracción social no burguesa de la joven puso en contra de la relación al padre de Kafka. La relación con Julie se rompió en noviembre de 1919.

En otoño de 1920 escribió varias piezas narrativas del género de las parábolas aforísticas. Como consecuencia del empeoramiento de su estado de salud, pasó gran parte de 1921 y 1922 en sanatorios. Durante los tres meses que pasó en Meran en la primavera de 1922 consolidó por vía epistolar su relación con la escritora, traductora y periodista checa Milena Jesenskà, casada, a quien había conocido a principios de 1920.

Entre diciembre de 1920 y septiembre de 1921 estuvo en el sanatorio de Matliary, etapa en la que conoció a Robert Klopstock, quien sería su amigo por el resto de su vida. Hasta 1923 escribió, entre Praga y Berlín, una docena de relatos.

En julio de 1923 estuvo en una colonia judía de vacaciones en Müritz, a orillas del Báltico, donde conoció a Dora Diamant, una joven periodista de 25 años descendiente de una familia judía ortodoxa que había huido de su pueblo natal. Ella le disuadió de un viaje programado a Palestina para octubre. Más tarde se trasladó a Berlín, con la esperanza de distanciarse de la influencia de su familia y concentrarse en su obra. Allí vivió con Dora, que se convirtió en su compañera y tuvo mucho que ver en el interés de Kafka por el judaísmo.
En la Navidad de 1923, Kafka contrajo una pulmonía que le obligó a regresar al hogar paterno en Praga en marzo de 1924. Al agravarse la enfermedad, ingresó en el sanatorio de Wiener Wald, cerca de Viena, donde sufrió un ataque de tuberculosis de laringe, lo que hacía que tragar los alimentos le resultara muy doloroso, de manera que en sus últimas semanas se alimentó principalmente de líquidos. Le trasladaron a la clínica universitaria de la capital y, a finales de abril, al sanatorio Dr. Hoffmann de Kierling, donde falleció el 3 de junio. Le enterraron el 11 de junio en la parte judía del Nuevo Cementerio de Praga-Žižkov.

En sus diarios y cartas se quejaba frecuentemente de insomnio y dolores de cabeza. Fue partidario de la dieta vegetariana y del naturismo. Se dice que bebía mucha leche sin pasteurizar, lo que pudo desencadenar su tuberculosis en 1917. No hay acuerdo sobre los problemas psicológicos de Kafka. En sus cuadernos íntimos él habla de "demonios", "derrumbamiento", "embates", "desamparo", "persecución", "soledad", "asalto a las últimas fronteras terrenales" y "agobiante observación de uno mismo". Kafka fue un ser atormentado y complicado, pero también a su manera gozó de la vida con una intensidad fuera de lo común. Pudo tener lo que ahora se denomina trastorno esquizoide de la personalidad.

Kafka solo publicó algunas historias cortas durante toda su vida, una pequeña parte de su trabajo, por lo que su obra pasó prácticamente inadvertida hasta después de su muerte. Poco antes de su muerte, le dijo a su amigo y albacea Max Brod que destruyera todos sus manuscritos. Brod no le hizo caso y supervisó la publicación de la mayor parte de los escritos que tenía. La compañera final de Kafka, Dora Diamant, cumplió sus deseos pero solo en parte: guardó en secreto la mayoría de sus últimos escritos, entre ellos 20 cuadernos y 35 cartas, hasta que la Gestapo los confiscó en 1933. La búsqueda de los papeles desaparecidos de Kafka aún continúa en varios países.

Los escritos de Kafka pronto despertaron el interés del público y recibieron elogios de la crítica, lo que posibilitó su rápida divulgación. Su obra marcó la literatura de la segunda mitad del siglo . Todas sus páginas publicadas, excepto varias cartas en checo dirigidas a Milena, están escritas en alemán.

Se hizo famoso en los años 1920 en Austria y Alemania y en los años 1930 en Francia, el Reino Unido y los Estados Unidos, aunque con interpretaciones muy dispares. G. Janouch publicó su biografía, "Conversaciones", en 2006.

Su obra se apreció aún más después de la Segunda guerra mundial. En Francia, Marthe Robert consiguió que se hiciesen ediciones más fiables, en un lento proceso que duró años.En Buenos Aires fue traducido y difundido en todos los países de lengua española. En España, "La metamorfosis" fue un relato de enorme éxito desde muy temprano. Galaxia Gutenberg publicó la obra completa de Kafka en castellano a finales del siglo .

En su obra a menudo el protagonista se enfrenta a un mundo difícil, basado en reglas desconocidas, paradójicas o inescrutables. La importancia de su mirada ha sido tal que en varias lenguas se ha acuñado el adjetivo «kafkiano» para describir situaciones que recuerdan a las reflejadas por él.

Harold Bloom escribió en 1995: «Desde una perspectiva puramente literaria, ésta es la época de Kafka, más incluso que la de Freud. Freud, siguiendo furtivamente a Shakespeare, nos ofreció el mapa de nuestra mente; Kafka nos insinuó que no esperáramos utilizarlo para salvarnos, ni siquiera de nosotros mismos».

La mayoría de los escritores y críticos del siglo ha hecho referencias a su figura. Ha habido multitud de estudiosos que han intentado (e intentan) encontrarle sentido a la obra de Kafka, interpretándola en función de distintas escuelas de crítica literaria, como por ejemplo la modernista o la realista mágica.

La desesperación y el absurdo reflejados en su obra se consideran (o se consideraron) emblemáticos del existencialismo, según la lectura de Albert Camus y en cierta medida de Jean-Paul Sartre, dominante tras la Segunda Guerra Mundial. En ese sentido, hablaban de Kierkegaard como su principal antecesor (dejando de lado los aspectos religiosos), si bien Kafka fue un lector devoto de Flaubert, un admirador de Dickens (presencia perceptible en su "América"). Georges Bataille introdujo la mirada de Kafka dentro de la tradición romántica del mal.

Algunos han visto una influencia marxista en la satirización de la burocracia en "En la colonia penitenciaria", "El proceso" y "El castillo". Otros ven una tendencia anarquista en el individualismo antiburocrático de Kafka, tomando en cuenta su breve militancia en una organización anarquista y su apoyo a algunas campañas de los anarquistas checos. Otros han interpretado su obra bajo el prisma del judaísmo y el misticismo. Existe también una lectura política, referida sobre todo a "El proceso," que tiene en cuenta el contexto antisemita y pre-nazi en el que vivió Kafka.

Walter Benjamin, que rechazaba la idea de Brod según la cual Kafka estaba en el camino a la santidad, interpretó una tensión entre la tradición mística y la experiencia del hombre en la gran ciudad.Según el ensayista alemán, Kafka «vive en un mundo complementario», como Klee, cuya pintura estaba esencialmente aislada en su esfera propia.

Muchos críticos consideran que bajo las líneas de Kafka no se encuentra ningún sentido recóndito, que sus textos solo son historias y cuentos. Autores como Vladimir Nabokov o Edmund Wilson, el segundo de un modo algo despectivo, han rechazado las lecturas esotéricas. El mundo de Kafka no es nada oculto, sino un mundo de los hombres, construido por ellos mismos, y como señala Arendt, que está expresado gracias a la «simplicidad y fácil naturalidad de su lenguaje». Cada frase vale literalmente lo que se dice en ella, según señalaba el pensador alemán Adorno.

La traductora kafkiana Marthe Robert, entre 1963 y 1979, renovó los estudios sobre el checo. Más aún, Barthes, de acuerdo con esta crítica francesa, defendió fijarse ante todo en su técnica «alusiva», técnica que apela a algo que es defectuoso por fuerza, puesto que el sentido del mundo no es enunciable en realidad.

Se subraya repetidamente el motivo de la alienación y de la manía persecutoria en Kafka. Este énfasis está inspirado en parte en la contra-crítica de Gilles Deleuze y Félix Guattari, que mantenían que Kafka representa mucho más que el estereotipo de figura solitaria que escribe movida por la angustia, y que su trabajo era mucho más deliberado, subversivo y, aun así, «alegre» de lo que parecía ser. Los biógrafos han comentado que Kafka, como otros grandes escritores, solía leer capítulos del libro en el que estaba trabajando a sus amigos más íntimos, y que la situación llegaba a ser cómica y concluía en risas de todos.

Su obra es expresiva como ninguna otra de las ansiedades y la alienación del hombre del siglo . También viene a expresar las relaciones entre literatura y amenaza, como señalaba Blanchot. Según Auden Kafka «es tal vez el más grande, el maestro de la parábola pura, un género literario sobre el cual el crítico puede decir muy poco que valga la pena», pues el "significado de una parábola, en realidad, es diferente para cada lector".

O bien, como señaló Coetzee, que siendo el menos psicológico de los escritores, Kafka tuvo un sentido penetrante de las obscenas interioridades del poder. Pero puede entenderse paralelamente por vías muy distintas. Por ejemplo el escritor y crítico Sebald describe la llegada de K. al Castillo como la elección del país de la muerte.

Ha sido constante también el análisis de su obra a la luz de la biografía de Kafka. En su caso,
La novela corta "Descripción de una lucha" ("Beschreibung eines Kampfes", 1904/1905) fue la primera obra que publicó Kafka. De acuerdo con su título, la narración describe una lucha personal, esto es, la reflexión sobre unos conflictos internos que el narrador en primera persona expone a lo largo de su conversación con otro personaje. El tema es la inseguridad vital permanente como fruto de la intromisión de lo improbable en lo probable, de lo fantástico o imaginado en lo real. Formalmente, la novela presenta una característica falta de lógica narrativa en medio de un mundo de irrealidad.

La indecisión entre la realidad y lo improbable, se decanta en favor de la primera en esta segunda novela corta. Con un cierto alejamiento de las abstracciones, el relato presenta a un individuo que, ante su inminente boda, que siente como una obligación, expresa sus malas sensaciones acerca de una vida social a la que no va a ser capaz de adaptarse y que terminará por ser una carga para él. La perspectiva narrativa es la de un narrador objetivo, cinematográfico.

Se trata de un libro compuesto por 18 relatos en los que se continúa con el tema de los conflictos del individuo en el interior de su medio social y se mantiene el interés por el difícil equilibrio entre lo seguro y lo inseguro que es inherente a la realidad; una realidad vista como circular e imprecisa, donde la verdad se sustenta en una lógica que solo es aparente. Técnicamente, es significativo el uso de la parábola, a la que Kafka despoja de su componente didáctico.

El motivo argumental de esta narración es una disputa familiar entre un hijo y un padre que al final se resuelve según la voluntad de este. La consecuencia psicológica es un rechazo del hijo hacia su padre que le lleva incluso a desear asesinarlo. La fluctuación que hay en el texto entre la psicología de los personajes y los hechos externos envuelven al relato en una atmósfera próxima a la de un sueño.

"La metamorfosis", también conocida como La transformación, relato que por su extensión entra en la categoría de novela corta, se gestó a finales de 1912. Muestra cómo cambia la vida del joven Gregor Samsa, un sencillo viajante de comercio, cuando al despertar una mañana tras un sueño intranquilo se encontró en su cama convertido en un monstruoso insecto. A partir de ahí, la novela cuenta el camino que sigue el protagonista que toma conciencia de su nueva situación, y cómo la asume también su propia familia, hasta su muerte y liberación que esta supone para los que le rodean.

A lo largo de esta obra, Kafka muestra no solo los pensamientos y el afán de supervivencia del hombre insecto una vez que asume su nueva realidad, sino principalmente las reacciones de los que tiene su alrededor: su jefe, la sirvienta, los huéspedes que irán a vivir a su casa y, sobre todo, su padre, su madre y su hermana Greta, de 17 años. Los sentimientos evolucionan desde la pena o el rechazo inicial, al odio y el alivio tras la muerte. Pese a las pocas alusiones temporales, el relato empieza, más o menos, en Navidad y termina a finales de marzo. Hay alguna que otra "analepsis" que muestra algunos hechos del pasado.

La novela presenta la historia a través de un narrador externo y objetivo. Esta novela reúne lo más significativo del estilo de Kafka, por cuanto reproduce sus principales características: un protagonista que se siente perdido ante circunstancias que no controla; el simbolismo y el valor metafórico que puede darse su contenido; la escasez de la acción, que gira casi exclusivamente en torno a un personaje indefenso ante una realidad hostil. Todo ello narrado de manera objetiva y ajena a todo artificio retórico.

















"Fuentes online"



</doc>
<doc id="1172" url="https://es.wikipedia.org/wiki?curid=1172" title="Función">
Función

El término función puede referirse a:





</doc>
<doc id="1173" url="https://es.wikipedia.org/wiki?curid=1173" title="Francia">
Francia

Francia (en francés, '), oficialmente República Francesa ('), es un país soberano, miembro de la Unión Europea, constituido en Estado social y democrático de derecho y cuya forma de gobierno es la república semipresidencialista. Su territorio, que incluye regiones de ultramar, se extiende sobre una superficie total de 643 801 km². En 2015 el país contaba con 66,3 millones de habitantes, 64,2 en la Francia metropolitana y 2,1 en los territorios de ultramar.

El territorio de Francia, y su parte metropolitana o continental, se ubica en Europa Occidental, donde limita, al sur, con el mar Mediterráneo, Mónaco (4,4 km) e Italia (488 km); al suroeste, con España (623 km), Andorra (56,6 km) y el mar Cantábrico; al oeste, con el océano Atlántico; al norte, con el canal de la Mancha, Reino Unido (22,6 m., en medio del túnel submarino que los une), el mar del Norte y Bélgica (620 km), y al este, con Luxemburgo (73 km), Alemania (451 km) y Suiza (573 km). Su territorio insular europeo comprende la isla de Córcega, en el Mediterráneo occidental, y diversos archipiélagos costeros en el océano Atlántico. En América, es territorio de Francia la Guayana Francesa, que limita con Brasil (673 km) y Surinam (510 km), y las islas y archipiélagos de Martinica, Guadalupe, San Bartolomé, San Martín y San Pedro y Miquelón. En el océano Índico posee las islas de Mayotte y de Reunión, así como los archipiélagos de la Polinesia Francesa, Wallis y Futuna y Nueva Caledonia en el océano Pacífico. Son territorios deshabitados de Francia el atolón de Isla Clipperton, en el Pacífico oriental, y las denominadas Tierras Australes y Antárticas Francesas.

Francia es la quinta economía mundial con una muy elevada difusión cultural en el contexto internacional. Es miembro del G8, de la zona euro y del espacio Schengen, y alberga a muchas de las más importantes empresas multinacionales, líderes en diversos segmentos de la industria y del sector primario, además de que es el primer destino turístico mundial, con 83 millones de visitantes extranjeros por año (7 % del PIB).
Francia, donde se redactó la Declaración de los Derechos del Hombre y del Ciudadano de 1789, es miembro fundador de la Organización de las Naciones Unidas y uno de los cinco miembros permanentes de su Consejo de Seguridad. Francia alberga las sedes del Consejo de Europa y del Parlamento Europeo, ambas en Estrasburgo, y las de la Organización para la Cooperación y el Desarrollo Económico y de la Unesco, en París. Es también una de las ocho potencias nucleares reconocidas y miembro de la OTAN.

Durante el siglo XIX, el país fue una potencia colonial, y durante mucho tiempo el idioma francés fue la principal lengua de la diplomacia. Aún hoy, es una de las lenguas con mayor proyección, y la cultura y la civilización francesas forman el nexo de unión de los países de la Francofonía. Además, el país era miembro de la disuelta Unión Latina.

Existen importantes restos del Paleolítico inferior en el río Somme y los Pirineos tradicionales (hombre de Neandertal), así como en La Chapelle-aux-Saints, Le Moustier y La Ferrassie. Del Paleolítico superior hay abundantes vestigios de los hombres de Cro-Magnon y Chancelade, datados en unos 25 000 años de antigüedad, los cuales están ubicados en el valle de Dordoña. Entre las más famosas pinturas rupestres del mundo están las de Lascaux y de Font de Gaume, en los Pirineos franceses.

En el Mesolítico algunas actividades agropecuarias fueron reemplazando en importancia a las cuevas, y en el Neolítico (desde el III milenio a. C.) surgió la cultura megalítica (que empleó menhires, dólmenes y enterramientos). Desde alrededor de 1500 a. C. se inicia la edad del bronce, desarrollándose rutas comerciales. Se ha encontrado utillaje de la industria achelense del homo erectus de hace 900 000 a 1 000 000 años en la gruta Le Vallonnet, en el sur de Francia. La Edad del Hierro y las culturas celtas se ubican dentro del I milenio a. C.
Las fronteras de la Francia moderna (1810) son aproximadamente iguales que las de la Antigua Galia, que fue habitada por los grupos celtas conocidos como galos, quienes fueron los habitantes de la región y casi toda Europa central desde la prehistoria. Galia fue conquistada por Roma y su líder Julio César (que venció al jefe galo Vercingétorix) en el siglo I a. C., y los galos adoptaron el idioma romano (el latín, del que evolucionó el francés junto a la presencia de dialectos celtas como el bretón). El cristianismo enraizó en los siglos II y III, y se estableció firmemente durante los siglos V y VI, en aquella época Jerónimo de Estridón (San Jerónimo) escribió que Galia era la única región «libre de herejía».

En el año 451, Atila, el líder de los hunos invadió la Galia con ayuda de los pueblos francos y visigodos, logrando establecerse en la parte principal de la Galia. En el siglo IV, la frontera del este de Galia a lo largo del Rin fue cruzada por pueblos germánicos, principalmente los francos, de la que deriva el antiguo nombre de «Francie». La «Francia moderna» debe su nombre al dominio feudal de los reyes capetos de Francia, alrededor de París. Los francos fueron la primera tribu entre los conquistadores germánicos de Europa, después de la caída del Imperio romano, en convertirse al cristianismo a raíz del bautismo del rey Clodoveo en 498; así, Francia obtuvo el título de «Hija mayor de la Iglesia», y el país adoptaría esto como justificación para llamarse «el reino más cristiano de Francia».

Francia durante la Edad Media fue gobernada por las siguientes dinastías:

La dinastía merovingia gobernó la actual Francia y parte de Alemania entre los siglos V y VIII. El primer rey fue Clodoveo I quien conquistó gran parte del territorio Galo entre 486 y 507; y se convirtió al cristianismo ortodoxo (por oposición a la herejía arriana), siendo bautizado en Reims hacia el 496. obteniendo el apoyo de las élites galo-romanas y estableciendo un importante lazo histórico entre la corona francesa y la Iglesia católica.

En 732, Carlos Martel derrotó a las fuerzas árabes del Califato Omeya en la batalla de Poitiers, también llamada batalla de Tours, deteniendo así el avance musulmán hacia Roma por el oeste de Europa.

La existencia como entidad separada comenzó con el Tratado de Verdún (843), con la división del Imperio carolingio de Carlomagno en Francia Oriental, Francia Central y Francia Occidental. Francia Occidental comprendía aproximadamente el área ocupada por la Francia moderna, de la que fue precursora.

Los carolingios gobernaron Francia hasta 987, cuando Hugo Capeto fue coronado rey de Francia. Sus descendientes, la dinastía de los Capetos, la Casa de Valois, y la Casa de Borbón, extendieron y unificaron progresivamente el país con una serie de guerras y herencias dinásticas.

Entre el 1 de enero de 1337 y el 17 de octubre de 1453 (116 años), el Reino de Francia fue escenario de la guerra de los Cien Años. Guerra que sostuvo contra el Reino de Inglaterra, y que se saldó con la retirada inglesa de suelo galo. 

La historia de Francia en el siglo XVII estuvo marcada por el apogeo del poder real, que se convirtió en absoluto. Después del Tratado de los Pirineos (1659), el reino de Francia se convirtió en una potencia cuyo resplandor se extendía a gran parte de Europa.

Es también un periodo de grandes cambios desde un punto de vista cultural. La cultura francesa irradia Europa, en todos los dominios, apoyada por la creación de Academias: la literatura, las artes, las ciencias. El francés se confirma como lengua de grandes escritores (Molière, Corneille). La pintura, la escultura, la arquitectura y la música también florecen. Los científicos franceses tienen un puesto muy importante en Europa (astronomía, matemáticas, física, óptica), con Fermat, Pascal, Descartes. Los artistas e intelectuales franceses están en ese momento en el corazón de las redes culturales europeas. Esta es la razón por la cual el siglo XVII es denominado en Francia como «el Gran Siglo».

La monarquía absoluta se fue imponiendo paulatinamente a partir de la llegada al trono de la casa de Borbón, un proceso iniciado por Enrique IV y que alcanzó su apogeo bajo el reinado de Luis XIV en el siglo XVII y principios del XVIII.

A pesar de la oposición periódica de la alta nobleza y de las tensiones con los parlamentos provinciales, este régimen se mantuvo hasta el reinado de Luis XVI. En este tiempo Francia poseía la población más grande de Europa y su política, su economía y su cultura influían en todo el continente. Francia también obtuvo muchas posesiones de ultramar en América, África y Asia y parte de Europa. El reinado de Luis XIV fue el más importante de la historia francesa mientras supo dirigir al reino. El final de su reinado estuvo marcado por los primeros síntomas de decadencia del régimen absolutista, el declive de la hegemonía francesa en Europa, el fracaso de su política colonial y el malestar social que padecían los pobres; tensas situaciones que tuvieron en vilo a sus herederos.

La secesión del Tercer Estado en los Estados Generales de 1789 y la creación de la Asamblea Constituyente marcaron el inicio de la Revolución francesa, cuyo hito simbólico fue la toma de la Bastilla. Este proceso social, económico y político se desarrolló entre 1789 y 1799 y sus principales consecuencias fueron la abolición de la monarquía y la proclamación de la Primera República Francesa, habiendo eliminado las bases económicas y sociales del Antiguo Régimen en Francia.
Después de una serie de esquemas gubernamentales de breve duración, Napoleón Bonaparte tomó el control de la república en 1799, haciéndose primer cónsul y emperador del que ahora se conoce como el Primer Imperio francés (1804-1814). Aparte de sus proezas militares, a Napoleón también se le conoce por el establecimiento del Código Napoleónico, un código civil que permanecería vigente hasta la segunda mitad del siglo XX y serviría de modelo a otros países, como España. Se le conoce también por su talento para hacerse rodear de brillantes expertos con un elevado sentido del Estado, que supieron crear el marco jurídico y administrativo de la Francia contemporánea. Otros, sin embargo, lo consideran un dictador tiránico cuyas guerras causaron la muerte de millones de personas, y uno de los personajes más megalómanos y nefastos de todos los tiempos.

Después de llevar a la victoria los ejércitos de la Revolución en una guerra de defensa del territorio nacional amenazado por los ejércitos de las monarquías europeas, su ejército, la "Grande Armée", conquistó la mayor parte de Europa continental. En los territorios invadidos, Napoleón nombró a los miembros de la familia Bonaparte y a algunos de sus generales más cercanos como monarcas de los territorios. Hoy en día, la familia real sueca desciende del general bonapartista Bernadotte.

Si bien la organización política de Francia osciló entre república, imperio y monarquía durante 75 años después de que la Primera República cayera tras el golpe de Estado de Napoleón Bonaparte, lo cierto es que la revolución marcó el final definitivo del absolutismo y dio a luz a un nuevo régimen donde la burguesía, y en algunas ocasiones las masas populares, se convirtieron en la fuerza política dominante en el país. Tras la derrota final de Napoleón en 1815 en la batalla de Waterloo, sus vencedores se reunieron en el Congreso de Viena, donde la monarquía francesa de los Borbones fue reinstaurada, pero con nuevas limitaciones definidas por una Carta Magna.
En la revolución de julio de 1830, una sublevación civil derrocó al rey Carlos X y estableció la monarquía constitucional llamada Monarquía de Julio, llevando al trono a Luis Felipe I, de la casa de Orleans.

La Revolución francesa de 1848 es una insurrección popular que tuvo lugar en París del 23 al 25 de febrero de 1848. Obligó al rey Luis Felipe I de Francia a abdicar y dio paso a la Segunda República Francesa.

Este régimen de breve duración terminó en diciembre de 1852, fecha en que el presidente francés Carlos Luis Napoleón Bonaparte, sobrino del extinto Napoleón Bonaparte, dio un golpe de Estado y se proclamó a sí mismo Napoleón III, emperador del Segundo Imperio francés.

Entonces, en el país se produce un considerable desarrollo en medios de transportes, crece la bonanza económica positiva, se incrementa la red bancaria y se firma un tratado librecambista con Inglaterra en 1860 que fomenta el comercio internacional. Sin embargo la política exterior tuvo una serie de fracasos importantes como la Segunda Intervención Francesa en México y sobre todo la estrepitosa derrota en la Guerra Franco-prusiana de 1870 en la cual Napoleón III fue vencido por completo.

La caída en la Guerra Franco-prusiana precipitó la proclamación de la tercera república francesa. Francia tuvo posesiones coloniales en varias partes del mundo, desde principios del siglo XVII hasta los años 1960. En los siglos XIX y XX, su imperio colonial era el segundo más grande del mundo después del Imperio británico. En su pico, entre 1919 y 1939, el segundo Imperio colonial francés se extendió sobre 12 347 000 kilómetros cuadrados (4 767 000 millas cuadradas) de tierra. Incluyendo Francia metropolitana, el área total de la tierra bajo la soberanía francesa alcanzó 12 898 000 kilómetros cuadrados (4 980 000 millas cuadradas) en los años veinte y los años treinta, que es 8,6 % del área terrestre del planeta.

En agosto de 1914, tras el asesinato del heredero de la corona austrohúngara, el Frente Occidental de la Primera Guerra Mundial se abrió luego de que el ejército alemán invada Bélgica y Luxemburgo, por lo que consiguió hacerse con el control militar de los más importantes lugares industriales de Francia.

Aunque en última instancia acabó como uno de los vencedores en la Primera Guerra Mundial, Francia sufrió unas pérdidas humanas y materiales enormes que la debilitaron en las décadas por venir. Los años 30 fueron marcados por una variedad de reformas sociales introducidas por el gobierno del Frente Popular.

Francia y Reino Unido declararon la guerra a la Alemania nazi el 3 de septiembre de 1939 en virtud de un tratado suscrito con Polonia, cuyo territorio había sido invadido por la Wehrmacht, ejército alemán. Al principio de la Segunda Guerra Mundial, Francia llevó a cabo una serie de campañas fracasadas de rescate en Noruega, Bélgica y los Países Bajos entre 1939 y 1940. Después del "ataque relámpago" de la Alemania Nazi entre mayo y junio de 1940 y su aliado, la Italia fascista, la dirección política de Francia firmó el Armisticio del 22 de junio de 1940. Los alemanes establecieron un régimen autoritario bajo la tutela del mariscal Philippe Pétain conocido como la Francia de Vichy, que adoptó una política de colaboración con la Alemania Nazi. Los opositores del régimen formaron el estado de Francia Libre fuera de Francia, sostuvieron a la resistencia francesa y fueron sumando cada vez más territorios coloniales a su causa. Francia continental fue liberada con el esfuerzo común de los aliados, Francia Libre, y de la resistencia francesa en 1945.

La Cuarta República Francesa, fundada después de la Segunda Guerra Mundial, luchó para mantener su estatus económico y político como potencia mundial. Intentó recuperar el control sobre su imperio colonial, afectado por la guerra. La tentativa poco entusiasta en 1946 de recuperar el control en Indochina Francesa dio lugar a la Primera Guerra de Indochina, que terminó en derrota francesa en la batalla de Dien Bien Phu en 1954. Solamente unos meses más adelante, Francia hizo frente a un nuevo conflicto, incluso más áspero que el anterior en su más vieja e importante colonia, Argelia.
El debate por mantener el control de Argelia, entonces tierra de un millón de colonos europeos, debilitó al país y condujo casi a la guerra civil. En 1958, la cuarta república débil e inestable llevó a la Quinta República Francesa, que se apoya en un fuerte poder ejecutivo. Charles de Gaulle tomó el camino extremo de la guerra. La Guerra de Argelia y la guerra civil que estalló en Argelia entre los partidarios de abandonar la colonia y los colonos que se aferraban a mantener la presencia francesa, se concluyó en 1962, con la declaración de Evian que incluían la celebración de un referéndum de autodeterminación. El general De Gaulle también tuvo que afrontar otra dura prueba en mayo de 1968, de la que salió triunfante en las elecciones anticipadas convocadas en junio del mismo año.

En 1981, el socialista François Mitterrand fue elegido presidente de Francia y gobernó desde 1981 hasta 1995. Luego, el conservador Jacques Chirac sería elegido presidente de Francia, gobernando entre 1995 y 2007, año en que su ministro de Interior, Nicolas Sarkozy, fue elegido presidente. Francia apoyó a Estados Unidos en la primera Guerra del Golfo (1990), así como en el derrocamiento del régimen talibán. La reconciliación y la cooperación de Francia con Alemania probaron la línea central a la integración política y económica de la Unión Europea de desarrollo, incluyendo la introducción del euro en enero de 1999. Francia estuvo en la vanguardia de los Estados miembros europeos de la unión que intentaban explotar el ímpetu de la unión monetaria para crear una unión europea política, con una defensa y un aparato unificados y más capaces en la seguridad.

Dominique de Villepin, a la cabeza de la diplomacia francesa, lideró el bloque de países que se opuso a la invasión de Irak de 2003, amenazando con utilizar su derecho al veto en el Consejo de Seguridad, llevando de paso a un enfriamiento de las relaciones con la administración de George W. Bush. El candidato de la derecha conservadora, Nicolas Sarkozy, derrotó a Segolene Royal en los comicios electorales del 6 de mayo de 2007 para ocupar la Presidencia de la República Francesa, sucediendo a Jacques Chirac. El 6 de mayo de 2012 Sarkozy fue derrotado en su aspiración a continuar al frente del gobierno en las elecciones presidenciales por el candidato socialista François Hollande.
El 7 de enero de 2015 en París, el atentado contra Charlie Hebdo (revista satírica francesa) por parte de la banda terrorista Estado Islámico se cobró la vida de 12 personas y hubo toma de rehenes y secuestros durante los dos días siguientes lo que produjo una conmoción enorme en el país y grandes movilizaciones. El 13 de noviembre del mismo año, el EI perpretró un atentado aún mayor en la ciudad con varios ataques simultáneos en cafés y la masacre del teatro Bataclan en pleno recital dejando 130 muertes y una conmoción y reacción aún más grandes en Europa, lo que hizo que Francia reforzase su seguridad interna y se implique definitivamente en la guerra contra Estado Islámico.

El 14 de julio de 2016, otro ataque en Niza. Un camión atropella a centenares de personas durante los festejos de la Revolución francesa en el paseo de los Ingleses, dejando un saldo de 85 muertos y más de 300 heridos.

La actual Constitución de Francia (Constitución de la quinta república) fue aprobada por referéndum el 28 de septiembre de 1958. Con su implantación, el cargo de presidente de la República fortaleció notablemente su autoridad sobre el poder ejecutivo, anteriormente encarnado en el primer ministro y el gobierno, constituyendose en verdadero representante del Ejecutivo en relación con el parlamento. Según la Constitución, el presidente es elegido por sufragio directo por un período de 5 años (originalmente eran 7 años). El arbitraje del presidente asegura el funcionamiento regular y el equilibrio de los poderes públicos. El presidente designa al primer ministro, quien preside el Gabinete, comanda a las fuerzas armadas y concluye tratados. El gabinete o consejo de ministros es nombrado por el presidente a propuesta del primer ministro. Esta organización del gobierno se conoce como república semipresidencialista.

La Asamblea Nacional es el principal cuerpo legislativo. Sus 577 diputados son electos directamente por un término de 5 años y todos los escaños son votados en cada elección. La otra cámara es el Senado, cuyos 321 senadores son elegidos por un colegio electoral (es un sufragio indirecto) y permanecen 9 años en sus cargos. Un tercio del senado es renovado cada 3 años. Los poderes legislativos del senado son limitados, y la asamblea nacional es quien posee la palabra final en caso de ocurrir una disputa entre ambas cámaras. El gobierno posee una fuerte influencia sobre la agenda parlamentaria. Además existe un Consejo Constitucional (9 miembros), que asegura el control de la constitucionalidad de las leyes y resuelve los contenciosos electorales. Son ciudadanos franceses todos los mayores de 18 años.

Desde la presidencia del General Charles de Gaulle (1958-1969), la política exterior de Francia se caracteriza por un deseo de independencia, sobre todo frente a los Estados Unidos, lo que ha dado lugar al desarrollo por Francia de las armas nucleares y la retirada de Francia del comando integrado de la OTAN en 1966 2009.

La red de embajadas de Francia es la tercera a nivel mundial, contando con 156 embajadas y 97 consulados a través de cinco continentes. Francia ayuda a los países en desarrollo, especialmente África. La asistencia oficial para el desarrollo representa un 0,36% del producto nacional bruto de Francia en 2014, siendo más bajo que el del Reino Unido o Alemania.

La "Declaración Schuman" es el título con el que informalmente se conoce al discurso pronunciado por el Ministro de Asuntos Exteriores francés Robert Schuman el 9 de mayo de 1950 en el que —tal como lo reconoce oficialmente la Unión Europea (UE)— se dio el primer paso para la formación de esta organización al proponer que el carbón y el acero de Alemania y Francia (y los demás países que se adhirieran) se sometieran a una administración conjunta.

El Tratado de París, firmado el 18 de abril de 1951 entre Bélgica, Francia, la República Federal Alemana, Italia, Luxemburgo y los Países Bajos, estableció la Comunidad Europea del Carbón y del Acero (CECA) que posteriormente formó parte, primero, de las Comunidades Europeas y, luego, de la Unión Europea. Los franceses cuentan con la segunda representación más numerosa en el Parlamento Europeo, en virtud de su número de habitantes; además, el francés Jean-Claude Trichet fue Presidente del Banco Central Europeo y Jacques Barrot fue uno de los vicepresidentes de la Comisión Europea para el período 2004-2009.

Estrasburgo es la sede del Parlamento Europeo; las sesiones plenarias se realizan allí una semana cada mes. Por ello la ciudad es considerada como la segunda capital de la UE después de Bruselas, donde están los diputados el resto del tiempo. La ciudad también es sede del Comando Central del Eurocuerpo y el Centro de información de Europol.

El 14 de julio de 2007 tropas de los 27 países de la Unión Europea desfilaron juntas por primera vez en los Campos Elíseos de París con motivo de la fiesta nacional francesa en una ceremonia encabezada por Sarkozy. La presidencia francesa del Consejo de la Unión Europea en el segundo semestre de 2008 estuvo enmarcada dentro del sistema de administración rotativa de dicha institución. Estaba previsto que al término de la administración entrase en vigor el Tratado europeo de Lisboa, permitiendo nombrar al Primer Presidente permanente de la Unión, pero ello no fue posible ya que el documento no fue ratificado por todos los estados.

En 2017 Emmanuel Macron es uno de los líderes principales del proyecto de refundación de la Unión Europea.

Las Fuerzas armadas francesas son miembros de la OTAN, la EUFOR y del Eurocuerpo. El ejército francés, con una fuerza de personal de 547 278 en 2014 (257 920 de fuerza regular, 204 000 reservistas y cerca de cien mil de gendarmería), constituye una de las fuerzas militares más grandes de Europa. En 2011 el país tuvo el quinto gasto militar mundial más alto, detrás de los Estados Unidos, China, Rusia y el Reino Unido.

La dinámica industria armamentística gala, especialmente la aeronáutica, produce aviones de caza como el "Rafale", con cargamento nuclear. El DGSE es el servicio de inteligencia del país. La Armada Francesa cuenta con un solo portaaviones, el de impulsión nuclear "Charles de Gaulle" pero esperan tener disponible en el 2012 uno con el nombre "PA2" (Portaaviones 2) que desplazará 75 000 toneladas. En el año 2011, Francia destinó el 2,3 % de su PIB anual a la defensa nacional, según los datos de la OTAN y junto con Alemania destinan en conjunto más del 40 % del gasto en defensa total de la Unión Europea. Alrededor del 10 % del presupuesto en defensa francés se destina a la "Force de frappe", encargada de las armas nucleares embarcadas en submarinos.

En marzo de 2008 el Gobierno francés anunció sus planes para lograr la reducción de su arsenal a menos de 300 cabezas nucleares, «"la mitad del máximo"» de las que mantuvo durante la Guerra Fría.

Francia se divide administrativamente en regiones, departamentos, distritos, cantones, y municipios (o comunas). Adicionalmente cuenta con colectividades, territorios y dependencias. El departamento más extenso es la Guayana Francesa con 91 000 km².

Las 27 regiones y sus correspondientes 101 departamentos son de la metrópoli o de ultramar.


Seis dependencias son islas francesas dispersas y actualmente deshabitadas: Clipperton, en el nororiente del océano Pacífico (administrada desde la Polinesia Francesa) y la Isla Europa, las Islas Gloriosas, Juan de Nova, Tromelin, y Bassas da India, en el suroccidente del océano Índico (administradas por Reunión).

El territorio francés tiene una extensión de 643 801 km², lo que representa el 0,50 % de las tierras emergidas del planeta (Puesto 40º en el mundo). La "Francia metropolitana", es decir, europea, cuenta con 551 500 km², en tanto que la Francia de ultramar tiene otros 123 722 km² (sin considerar la Tierra Adelia por el Tratado Antártico en 1959 que suspendió el reconocimiento de todas las soberanías en dicha región). Sus islas de mayor tamaño son Nueva Caledonia, Córcega, Guadalupe y Martinica.

La demarcación política de la Francia continental europea se apoya en sus «fronteras naturales» siendo estas (en sentido antihorario): el mar del Norte, el canal de la Mancha, el océano Atlántico (golfo de Vizcaya); los Pirineos (frontera con España y Andorra); el mar Mediterráneo (golfo de León, Costa Azul); los Alpes; los montes Jura; el río Rin. El Rin es frontera solo en una parte de su curso, punto desde el cual y hasta el mar del Norte, no existen accidentes geográficos que delimiten «naturalmente» la frontera con Bélgica, Luxemburgo y Alemania. La isla francesa más importante en Europa es Córcega, ubicada en el mar Mediterráneo. En la Francia metropolitana las fronteras se extienden a lo largo de 2889 km y la línea costera por otros 3427 km. En África, Asia, Oceanía, América del Norte y el Caribe, el territorio francés es insular. La Guayana Francesa es el único territorio continental fuera de Europa, limita al norte con el océano Atlántico (378 km); al oeste con Surinam (510 km), al este con Brasil (673 km). La Isla de San Martín tiene una frontera meridional con las Antillas Holandesas (10,2 km).

Francia posee parte de los Pirineos y los Alpes, ambos al sur. Otros macizos montañosos son el Jura (en la frontera con Suiza), las Ardenas, el Macizo Central y la cordillera de los Vosgos. El Mont Blanc en los Alpes con 4810,06 metros de altura es la cumbre más alta de Europa occidental. El punto más bajo del país está en el delta del río Ródano: –2 m. El territorio cuenta también con llanuras costeras hacia el norte y oeste del país.

La mayor parte del territorio metropolitano de Francia corresponde al bioma de bosque templado de frondosas, aunque también están presentes el bosque templado de coníferas en los Alpes y el bosque mediterráneo en el sureste. La cantidad de venados y ciervos en estado salvaje se está incrementando gracias a políticas orientadas con este objetivo, además se garantiza la protección de las especies autóctonas no domésticas, con la creación de parques y reservas naturales, así como por la reintroducción de especies que fueron exterminadas en el país (oso pardo, lince y bisonte europeo, entre otros).

En la Francia metropolitana hay 136 especies de árboles, algo excepcional tratándose de un país europeo. Las especies vegetales cultivadas para consumo humano directo y para la producción agro-industrial ocupan grandes espacios de la superficie francesa, destacándose la vid y el trigo entre muchas otras. Se practica una intensiva crianza y explotación de reses, cerdos, ovejas, cabras y caballos. También abundan especies menores como conejos y aves de corral.

La producción agropecuaria representa un 56 % (del cual las tierras de labrantío son un 33 %, las cosechas permanentes un 3 %, y los pastos permanentes un 20 %), la masa forestal el 28 %, y «otros» el 16 %. Los bosques se extienden sobre la superficie de la Francia metropolitana hasta cubrir más de 140 000 km. Las zonas especialmente protegidas conforman el 8 % del territorio nacional. El subsuelo proporciona materiales de construcción en abundancia (grava, arena, cal) y materias primas (caolín, talco, azufre, potasa), pero es pobre en productos energéticos y minerales. La Guayana Francesa, por su parte, forma parte del Macizo Guayano-venezolano, teniendo el 90 % de su territorio cubierto por la selva tropical.

Las aguas interiores cubren el 0,26 % de la superficie continental francesa. Los ríos más importantes de Francia son, en la vertiente atlántica: Loira, Garona, Dordoña (en el océano Atlántico), y Sena (en el canal de la Mancha). En la vertiente mediterránea el Ródano (en el golfo de León), con su afluente el Saona. También posee una buena parte de las cuencas de los ríos Rin, Mosa, Mosela y Escalda (que desembocan en el mar del Norte). El río interior más extenso es el Loira, con más de 1000 km. El lago más extenso es el Lemán (582 km²).

Francia tiene 5500 km de costas y ocupa el cuarto lugar en producción pesquera en la UE. En total las costas francesas son bañadas por los océanos Atlántico, Índico, y Pacífico. La Zona Marítima de Francia es de 12 millas contadas desde la costa, y la Zona Económica Exclusiva se extiende hasta las 200 millas desde la costa (11 millones de km²).

Francia es considerado un país de primer mundo por su nivel de vida (IDH). Es la quinta economía mundial en , y a nivel europeo se coloca por detrás de Alemania, con un PIB en dólares superior al del Reino Unido. En 2006 el crecimiento económico francés llegó al 2 % siendo el más bajo de la zona euro y sus índices de desempleo entre los más altos.

La economía francesa cuenta con una gran base de empresas privadas, pero la intervención estatal en las grandes compañías es superior a la de otras economías de su tamaño. Sectores clave con grandes inversiones en infraestructura como el eléctrico, las telecomunicaciones o el sector aeronáutico, históricamente han sido dirigidos directamente o indirectamente por el Estado, aunque desde principios de la década de 1990 la participación estatal ha ido decayendo.

Sus bazas son diversas: transporte, telecomunicaciones, industrias agro-alimentarias, productos farmacéuticos, aeronáutica, defensa, tecnología, así como el sector bancario, los seguros, el turismo, y los tradicionales productos de lujo (marroquinería, prêt-à-porter, perfumes, alcoholes, etc.). El PIB por sector: La agricultura (2,7 %), industria (24,4 %), servicios (72,9 %). Por otro lado, la energía solar está comenzando a tener cada vez mayor importancia en Francia. Tiene una industria aeroespacial importante conducida por el consorcio europeo Airbus además de tener una base espacial llamado puerto espacial de Kourou. En telecomunicaciones destaca France Télécom como el principal operador del país.
Sin la producción petrolífera, Francia ha confiado en el desarrollo de la energía nuclear, que ahora representa aproximadamente el 78 % de la producción de electricidad del país. Los residuos radiactivos son almacenados en instalaciones de retratamiento. En 2006 la producción neta de electricidad ascendió a 548,8 TWH, de los cuales:


EL PIB per cápita francés es ligeramente inferior al de otras grandes economías europeas comparables, como la alemana o la británica, aunque el PIB por hora trabajada es uno de los más altos de la OCDE. El PIB per cápita se determina por (I) la productividad por hora trabajada, que en Francia es la más alta de los países miembros del G8, (II) el número de horas trabajadas, que es uno de los más bajos de las economías desarrolladas; (III) la tasa de actividad. Francia tiene una de las tasas de actividad más bajas para el segmento de población entre 15 y 64 años de la OCDE: En 2004 solo el 68,8 % de esta franja de población estaba empleada, frente a tasas del 80 % en Japón, 78,9 % en Reino Unido o del 71,0 % en Alemania, los tramos de edad de 15-24 y de 55-64 son precisamente los que presentan tasas significantemente bajas en relación con la Unión Europea a 25.

El hecho de que la tasa de actividad sea baja se explica por la existencia de un salario mínimo alto (lo que mantiene fuera del mercado laboral a trabajadores poco productivos, como los jóvenes, aunque garantiza condiciones laborales dignas), una enseñanza universitaria en muchos casos poco acorde con el mundo laboral y en el caso de trabajadores más ancianos, incentivos para la prejubilación.

En cuanto al nivel de vida de los franceses, un dato significativo es que la brecha entre ricos y pobres se ha profundizado en Francia durante el periodo de 2004 a 2007. Según un estudio del INSEE ("Institut National de la Statistique et des Études Économiques"), «la población en general se ha vuelto más pobre en comparación con quienes perciben ingresos muy elevados, que han visto incrementos medios mucho más fuertes».

Los grandes conflictos bélicos europeos y mundiales entre 1870 y 1945 enfrentaron a Francia y Alemania, sin embargo, ambos países han construido desde los años 1950 un entramado de relaciones: institutos de investigación y universidades comunes, un intenso intercambio juvenil, más de 2000 ciudades hermanadas e innumerables contactos personales. Esta situación puso el fundamento de la integración política de Europa, son recíprocamente su principal socio comercial y juntos constituyen el motor económico de la Unión Europea (UE).

En 2005 con un 10,2 %, volvió a ser el principal destino de las exportaciones alemanas y el origen del 8,7 % de las importaciones. En 2006 más del 14 % de las exportaciones francesas tuvieron como destino a Alemania y cerca del 17 % del total de las importaciones francesas provino de Alemania. Otros socios importantes en 2006 fueron: Bélgica, Italia, Reino Unido y España.

Es el principal productor agrícola de la Unión europea, aproximadamente un tercio de toda la tierra agrícola. El norte de Francia está caracterizado por granjas de trigo grandes. Los productos lácteos, la carne de cerdo y la producción de manzana se encuentran sobre todo en la región occidental. La producción de ternera está localizada principalmente en la zona central, mientras la producción de frutas, verduras, y el vino se extiende del centro hacia el sur. Es un gran productor agrícola y actualmente amplía su silvicultura e industrias de piscifactoría. La puesta en práctica de la Política agrícola común de la Unión Europea y el Acuerdo General sobre tarifas y comercio, GATT han causado reformas del sector agrícola de la economía.

Es un líder de producción mundial agrícola y el sexto más grande. También es el segundo mayor exportador, después de los Estados Unidos. Sin embargo, el destino del 70 % de sus exportaciones son otros miembros de la Unión Europea y muchos países pobres africanos (incluyendo sus antiguas colonias) que afrontan una escasez seria de alimentos. Las exportaciones estadounidenses agrícolas a Francia, son aproximadamente de 600 millones de dólares cada año y consisten principalmente en soja, productos de alimentación y forrajes y mariscos. A los Estados Unidos exportan principalmente el queso, productos procesados y vino. Asciende a más de 950 millones de dólares al año.

El sector avícola francés se compone principalmente de dos sectores: pollos de engorde y huevos para consumo.

En energía eléctrica, la empresa Électricité de France se encarga del abastecimiento principal de electricidad en Francia. Por otro lado, la vecina España suele exportar electricidad a Francia a través de las interconexiones existentes entre los sistemas eléctricos de ambos países.
La industria nuclear francesa es ahora un sector líder en su economía y uno de los pilares de su política energética. Francia es el segundo mayor productor de energía nuclear en el mundo sólo por detrás de los Estados Unidos. Con más de 60 reactores nucleares en su territorio, Francia tiene el segundo complejo más grande en el mundo mientras que la proporción de la energía nuclear en la producción total de su electricidad corresponde cerca del 79%, con lo que Francia es líder en todo el mundo en cuanto a este desarrollo.

El turismo es una fuente primordial de la economía francesa, pues éste es el país con más visitantes en el mundo, con aproximadamente 80 millones al año; sus turistas provienen principalmente de América del Norte, Japón, China, y otros países de Europa. París es la principal atracción, pero también recibe muchos visitantes la Costa Azul. Francia es un país con múltiples puntos de interés turístico: aparte de poseer uno de los mayores patrimonios histórico y artístico del mundo, es de los pocos países que puede ofrecer actividades de playa, montaña y campo.
También posee Francia diversos parques temáticos. Los más famosos son:

Desde hace más de treinta años que la industria francesa se ha ido exteriorizando considerablemente. El desarrollo de las exportaciones francesas, sin embargo, varía mucho de un sector a otro.

Muy importante para el equilibrio del comercio exterior francés es el sector agroalimentario, pues en esta área incluyen producciones como las de las bebidas alcohólicas (champán, vino, coñac), seguidas de la producción de cereales (como el trigo) y el ganado y las carnes. En términos de equilibrio de exportación e importación, el sector agroalimentario es seguido por el sector automotriz.
Los principales socios comerciales de Francia en el exterior son los países de la Unión Europea con los que tuvo un superávit comercial del 62% de las exportaciones y del 60% de las importaciones en el año 2000. Luego de la Unión Europea los países del Asia y Estados Unidos son también sus principales socios en materia económica en el exterior.

Los principales proveedores de petróleo de Francia son Noruega, Arabia Saudita, Rusia y Reino Unido. Otros productos de importación son los electrodomésticos y productos de ropa de cuero franceses.

La trayectoria histórica de Francia, así como la construcción de su sólido modelo económico tras la Segunda Guerra Mundial, le han proporcionado un estatus político muy relevante en la mayor parte de las organizaciones internacionales. De hecho, al margen de indicadores macroeconómicos como el PIB o la renta per cápita, Francia destaca en indicadores sociales como el porcentaje de carreteras pavimentadas o el ratio de usuarios de Internet, cuyo incremento en los últimos años (372,8 % desde el año 2000) ha sido superior al de algunos países adyacentes. Según el Banco Mundial, Francia tiene un 53 % de terreno dedicado a la agricultura, y es uno de los países que más han reducido las emisiones de CO2 per cápita en las últimas décadas, para lo cual se ha apoyado en parte en la proliferación de centrales de energía nuclear. Según datos de CIA World Factbook, la esperanza de vida media de los franceses es de 80,98 años y de ellos 64 años son con buena salud (noveno país en el ranking europeo, según Eurostat). El número de camas en hospitales, un indicador importante para medir el ámbito global sanitario, es de 718,3 unidades por cada 100 000 habitantes (el único país europeo de gran tamaño que lo supera es Alemania). Además, según el Foro Económico Mundial, Francia es el decimoquinto país del mundo en el Índice de Competitividad Global. En la siguiente tabla se puede analizar el contexto socioeconómico de Francia a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

La red de ferrocarril es de 29 640 kilómetros (cifra de 2008), siendo la segunda más extensa de Europa Occidental tras Alemania. Es operada por la empresa estatal SNCF (Sociedad Nacional de los Ferrocarriles Franceses) que posee trenes de alta velocidad como el Thalys, el Eurostar y el TGV que alcanza los 320 kilómetros por hora. Los trenes Eurostar conectan Francia a través del Eurotúnel con el Reino Unido. También tiene conexiones ferroviarias con sus demás países vecinos de Europa, excepto con Andorra. Además hay metro en varias ciudades del país como París, Lille, Lyon, Marsella, Rennes y Toulouse.

Hay aproximadamente un millón de kilómetros de calzada útil en el país. La región de París posee la red más densa de carreteras, que la unen con prácticamente todas las partes del país y con Bélgica, España, Mónaco, Suiza, Alemania e Italia. No hay ningún precio por impuestos en las carreteras, sin embargo, el uso de la autopista tiene peaje excepto en los alrededores de las grandes aglomeraciones. Las marcas francesas dominan el mercado de los automóviles en el país, como Renault (el 27 % de coches vendidos en Francia en 2003), Peugeot (el 20,1 %) y Citroën (el 13,5 %). Más del 74 % de los coches nuevos vendidos en 2007 tenían motor diésel.

Hay aproximadamente 478 aeropuertos, incluyendo campos de aterrizaje. El Aeropuerto de París-Charles de Gaulle, localizado en los alrededores de París, es el aeropuerto más grande y con más actividad del país, manejando la mayoría del tráfico civil y comercial, y conectando París con prácticamente todas las grandes ciudades del mundo. Air France es la línea aérea nacional, aunque numerosas compañías aéreas privadas proporcionan viajes domésticos e internacionales.

Hay diez puertos principales, el más grande de los cuales es el de Marsella. 14 932 kilómetros de vías fluviales atraviesan Francia incluyendo el Canal del Mediodía que conecta el mar Mediterráneo con el océano Atlántico por el río Garona.

Posee 66 952 000 habitantes (octubre de 2015), de los cuales 62 793 432 habitan en la Francia metropolitana, con una densidad de 115 hab/km², y 2 653 942 habitan en la Francia ultramarina, incluyendo a la comunidad de unos 2000 científicos e investigadores destacados en la Antártida.

Alrededor del 75 % de franceses vive en núcleos urbanos. París y su área metropolitana correspondiente a la Región conocida como «Isla de Francia» concentra 11 769 433 de habitantes, lo que la convierte en una de las más grandes del mundo, y la más poblada de la Unión Europea. Otras áreas metropolitanas de más de un millón de habitantes son Lyon y Marsella que superan el millón y medio de habitantes cada una.

La esperanza de vida al nacer es de 84,5 años para las mujeres y de 77,8 años para los varones (2009). Generalmente los varones tienden a obtener empleos a tiempo completo y las mujeres a tiempo parcial. En Francia las vacaciones pagadas legales suman cinco semanas en cada año laboral. Es considerado como uno de los países con mayor calidad de vida ya que la población disfruta de un alto grado de servicios, aparte de la sanidad que es una de las mejores del mundo.

La población está compuesta por descendientes de varios grupos étnicos, principalmente de origen celta (pero también ligure e ibero), fundamentalmente galos fusionados con la población precedente, que dieron nombre a la región de la Galia, hoy Francia (que incluía también Bélgica, Luxemburgo y Suiza). Cronológicamente se fueron sumando otros grupos étnicos: en el proceso histórico formativo de la Francia actual son también significativas las poblaciones de origen griego, romano, vasco, germano (principalmente franco pero también burgundio), vikingo (en Normandía) y en menor medida sarraceno.
Desde el siglo XIX, Francia es un país de inmigración. Uno de cada cuatro habitantes es de origen extranjero (en 1999, 23 % de la población). Entre los extranjeros que se van integrando, predominan los belgas, suizos, alemanes, italianos, españoles (la inmigración española comenzó en el siglo XIX), portugueses, polacos, armenios, griegos, magrebíes, subsaharianos, chinos (1 000 000 en 2007), indochinos (vietnamitas, 250 000 en 2008), turcos (500 000 en 2010) y gitanos (500 000 en 2005). El mayor número de inmigrantes en los últimos años proviene del Magreb. En total existen unos cuatro millones y medio de inmigrantes, de los cuales aproximadamente un millón y medio nació en tierra extranjera pero se ha naturalizado adquiriendo la nacionalidad francesa, en tanto que otros tres millones son aún extranjeros. Según el Gobierno se calcula que en Francia hay entre 200 000 y 400 000 inmigrantes ilegales, aunque las ONG hablan de medio millón.

Los estudios de población francesa muestran su composición mayoritaria de ciudadanos de origen europeo, un 91,6 %, de los cuales son franceses 85,0 % y de otros países 6,6 %. El 5,7 % de la población proviene de países africanos, 3,0 % de asiáticos y 0,6 % de americanos. Según un estudio publicado en "La France africaine" (2000), el 13 % de la población francesa es de origen africano (Magreb y África negra). Esta composición es el resultado de la evolución migratoria y de la presencia significativa de población nacida en Francia pero de padres extranjeros, generalmente inmigrantes que a través de los años fueron obteniendo la ciudadanía francesa. La población de origen judío se estimaba en 550 000 personas a principios de los años 2000, aunque no existen datos estadísticos dado que la ley francesa prohíbe recoger datos censales sobre etnias o religiones.

La situación privilegiada en Europa Occidental, en el centro de una de las regiones históricamente más pobladas del mundo, ha favorecido unas tasas elevadas de poblamiento y de expansión demográficas, siendo el tercer país más poblado de la tierra hasta el siglo XVIII. Esta expansión experimentó una fuerte desaceleración en vísperas de la revolución industrial que se mantuvo hasta entrado el siglo XX, en paralelo con el incremento demográfico de las regiones limítrofes, especialmente hacia la centroeuropea, en el área de influencia de Alemania, y las Islas Británicas.

Por otra parte, y especialmente durante los siglos XVI a principios del XX, una parte de la población francesa se instaló en otras regiones del mundo, al abrigo de la expansión colonial, configurando la base de las características poblacionales y composición étnica de otros países, principalmente en el Quebec de Canadá, Haití y otras antiguas colonias africanas, asiáticas y de Oceanía. En América, en los territorios de soberanía francesa de San Pedro y Miquelón; la Guayana Francesa, Martinica y Guadalupe, a la base poblacional proveniente de la metrópoli, se añadió la de origen africano que junto con la mestiza, se ha convertido en el grupo étnico mayoritario. En Oceanía la emigración de franceses ha sido menor y centralizada en Nueva Caledonia y la Polinesia Francesa, mientras que en el norte de África, una parte de la instalada en el Magreb conformó tras su repatriación a mediados del siglo XX la comunidad conocida como de los «pieds-noirs».

También existe una presencia significativa de población de origen francés en otros países fuera del continente europeo no directamente relacionados con sus colonias, principalmente Estados Unidos y en menor medida países de Hispanoamérica, como Brasil, Argentina, México, Uruguay o Chile.
Tras la Segunda Guerra Mundial y el periodo demográfico conocido como "Baby boom", el lento estancamiento de las tasas de crecimiento ha sido menos marcado en Francia que en otros países de su entorno, manteniendo un nivel de natalidad destacado en Europa gracias a las políticas sociales aplicadas para su estímulo.

El idioma oficial es el francés, que según unos lingüistas del siglo XIX provendría del "franciano", variante lingüística hablada en la Isla de Francia que a principios de la Edad Media y a lo largo de los siglos se ha impuesto al resto de lenguas y variantes lingüísticas que se hablan en otras parte del territorio; la otra tesis es que es un estándar configurado a partir de las distintas lenguas de oïl.

A menudo, esta imposición del francés ha sido fruto de decisiones políticas tomadas a lo largo de la historia, con el objetivo de crear un Estado uniformizado lingüísticamente. De hecho, el artículo 2 de la Constitución francesa de 1958 dice textualmente que «"La langue de la République est le français"».

Este artículo ha servido para no permitir el uso oficial en los ámbitos de uso cultos de las lenguas que se hablan en Francia, hasta que en 1999 el informe Cerquiglini estableciera 75 lenguas regionales y minoritarias habladas en Francia metropolitana y de Ultramar. Desde 2006, 13 de ellas se enseñan como segunda lengua extranjera optativa en la escuela pública, como el bretón, el catalán, el corso, el occitano, el vasco, el alsaciano, el tahitiano y 4 lenguas melanesias. La inmigración proveniente de fuera del país, así como de regiones exclusivamente francófonas, hace que el porcentaje de hablantes de estas lenguas sea cada vez más bajo.

Es uno de los estados que no han firmado la Carta europea de las lenguas minoritarias. A pesar de todo, hoy en día, algunas instituciones privadas han procurado fomentar el uso de estas lenguas creando medios de comunicación, asociaciones culturales, escuelas primarias y secundarias para enseñar estas lenguas y emprender acciones reivindicativas a favor de una política lingüística alternativa.

La República Francesa oficialmente se declara como un estado laico, secular y que tiene la libertad religiosa como un derecho constitucional. Algunas organizaciones como la Cienciología, la Iglesia de la Unificación o la Familia o Familia Internacional (ex Niños de Dios) tienen el estatuto de asociaciones sin ánimo de lucro ya que no son reconocidas como religiones, y son consideradas «sectas» en numerosos estudios parlamentarios. La oficina central de culto, dependiente del Ministerio del Interior, asegura las relaciones entre el Estado y las asociaciones religiosas establecidas.

La religión mayoritaria es la católica. Hay más de 45.000 iglesias católicas en Francia. La Ley francesa de separación de la Iglesia y el Estado de 1905 se ve excepcionada en algunos puntos debido a la reanudación de la relación concordataria con la Iglesia católica en 2008 con la firma del Acuerdo sobre reconocimientos de grados y diplomas de enseñanza superior de 18 de diciembre de 2008, con entrada en vigor el 1 de enero de 2009, y que ha supuesto el reconocimiento oficial de la enseñanza religiosa. Hay que tener en cuenta que estos acuerdos, con valor de tratado internacional, desplazan en lo que sea incompatible la legislación interna, en virtud de la primacía del Derecho Internacional. No supone, por tanto, una derogación de la ley, pero sí que no será de aplicación a la Iglesia Católica en lo que respecta a los aspectos del acuerdo.

Según una encuesta de enero de 2007 hecha por las Noticias Católicas Mundiales, en su población están representadas las principales confesiones religiosas, pero el catolicismo está en receso: católicos 52 % (frente al 80 % de 15 años antes), ateos 30 % (frente al 23 % en la misma encuesta hecha 15 años antes), musulmana 6 %, protestante 6 %, judía 1,5 %, budista 1 %, ortodoxa 2 %, otras 1 %. En otra encuesta realizada por IFOP y publicada en la revista católica La Vie, los católicos representan el 64 %, la proporción de ateos es igual al 27 %, el 3 % se identifica como musulmán, el 2,1 % se identifica como protestante y el 0,6 % se identifica como judío.

Según el más reciente eurobarómetro del año 2005, el 43 % de los ciudadanos franceses respondió que «ellos creen que hay un dios», mientras que el 27 % contestó que «ellos creen que hay algún tipo de espíritu o de fuerza» y el 30 % que «ellos no creen que haya ningún tipo de espíritu, dios, o fuerza». Otro estudio da el 32 % de personas que se declara atea, y otro 32 % que se declara «escéptico sobre la existencia de Dios, pero no un ateo».

La comunidad de judíos en Francia se cuenta aproximadamente en 600 000 según el Congreso Mundial Judío y es el grupo más grande de esta religión en Europa. Las estimaciones del número de musulmanes varían mucho. Según el censo de 1999 había solo 3,7 millones de personas (el 6,3 % de la población total). En 2003, el Ministerio de los Asuntos Interiores estimó el número total entre 5 y 6 millones (8 millones según el Frente Nacional).

En Francia han nacido grandes inventores como los Hermanos Montgolfier (inventores del globo aerostático), Joseph-Nicéphore Niépce (químico, litógrafo y científico aficionado que inventó, junto a su hermano, un motor para barcos y, junto a Daguerre, la fotografía), Clément Ader (inventor del avión, un micrófono y los primeros perfeccionamientos del teléfono), los Hermanos Lumière (inventores del proyector cinematográfico), René Théophile Hyacinthe Laënnec (inventor del estetoscopio), Louis Pasteur (la técnica conocida como pasteurización) entre otros; cuyos aportes a la ciencia han sido decisivos en la historia de la humanidad.
En Francia la educación es gratuita en todos sus niveles, tanto para los estudiantes franceses como para los extranjeros. En 2007 los gastos en educación alcanzaron el 28 % del presupuesto del Estado.

Francia es el país con más (quince). Entre los grandes escritores franceses de todos los tiempos se pueden mencionar al dramaturgo Molière, los filósofos Descartes, Montesquieu, Rousseau y Voltaire, el fabulista La Fontaine, el cuentista Charles Perrault, el romántico Victor Hugo, los novelistas Gustave Flaubert, Alejandro Dumas y Guy de Maupassant, y los ganadores del Premio Nobel Sully Prudhomme, Jean-Paul Sartre, Patrick Modiano y Maurice Druon, autor de la serie Los reyes malditos, entre muchos otros. También se puede mencionar al gran escritor Antoine de Saint-Exupéry, autor del libro "El principito" y Julio Verne, uno de sus más celebres escritores. Tanto los ciudadanos franceses, como los francógrafos de otros países (como el belga Maurice Maeterlinck o el senegalés Léopold Sédar Senghor) componen lo que se denomina como literatura francófona, que ha influenciado la obra de importantes autores extranjeros, y la literatura de muchos países. Tal es el caso del cubano Alejo Carpentier o del denominado "boom latinoamericano".

Las primeras manifestaciones provienen del arte prehistórico, en estilo franco-cantábrico. La época carolingia marca el nacimiento de una escuela de iluminadores que se prolongará a lo largo de toda la Edad Media, culminando en las ilustraciones del libro de "Las muy ricas horas del duque de Berry". Los pintores clásicos del siglo XVII francés son Poussin y Lorrain. En el siglo XVIII predomina el rococó, con Watteau, Boucher y Fragonard. A finales de siglo comienza el clasicismo de un Jacques-Louis David. El romanticismo está dominado por las figuras de Géricault y Delacroix. El paisaje realista de la Escuela de Barbizon tiene su continuación en artistas de un realismo más testimonial sobre la realidad social de su tiempo, como Millet y Courbet. A finales del siglo XIX París, convertida en centro de la pintura, ve nacer el impresionismo, precedido por la obra de Édouard Manet. A estos siguen Toulouse-Lautrec, Gauguin y Cézanne. Ya en el siglo XX, surgen los fauvistas en torno a Matisse y el cubismo de la mano de Georges Braque y el español Picasso que trabaja en París. Otros movimientos artísticos se van sucediendo en el París de entreguerras, decayendo como centro pictórico mundial después de la Segunda Guerra Mundial.

En Francia la escultura ha evolucionado desde la antigüedad por diversos estilos, sobresaliendo en todos ellos: prehistórico, romano, cristiano, románico, gótico, renacentista, barroco y rococó, neoclásico (Frédéric Auguste Bartholdi: "Estatua de la Libertad"), romántico (Auguste Rodin: "El pensador"), y los contemporáneos.

En lo que se refiere a la arquitectura, los celtas dejaron su huella también en la erección de grandes monolitos o megalitos, y la presencia griega desde el siglo VI a. C. se recuerda hoy en la herencia clásica de Massalia (Marsella). El estilo romano tiene ejemplos en la "Maison Carrée", templo romano edificado entre 138-161 a. C., o en el Pont du Gard construido entre los años 40 y 60 d. C., en Nimes y declarado patrimonio universal en 1985. En Francia se inventó el estilo gótico, plasmado en catedrales como las de Reims, Chartres, Amiens, Notre Dame o Estrasburgo. El renacimiento surgido en Italia, tiene su estilo arquitectónico representado magistralmente en el Castillo de Chambord o en el Palacio de Fontainebleau entre otros.

El arte barroco (también de origen italiano), y el rococó (invención francesa) tienen obras extraordinarias en Francia. Tal es el caso del Palacio del Louvre y el Panteón de París entre tantos otros. El modernismo o arte moderno en arquitectura abarca todo el siglo XIX y la mitad del XX, y en él Alexandre Gustave Eiffel revolucionó la teoría y práctica arquitectónica de su tiempo en la construcción de gigantescos puentes y en el empleo de materiales como el acero. Su obra más famosa es la llamada Torre Eiffel. Otro grande de la arquitectura universal es Le Corbusier, un innovador y funcionalista celebrado especialmente por sus aportes urbanísticos en las edificaciones de viviendas y conjuntos habitacionales.

En la música francesa desde antes del año 1000 se destaca el canto gregoriano empleado en las liturgias. En Francia se creó la polifonía. En la denominada "Ars Antiqua", se le atribuye a Carlomagno el "Scholae Cantorum" (783). Los "Juramentos de Estrasburgo" es la obra lírica francesa más importante de la Edad Media, periodo en el que se desarrollan los Cantares de Gesta como el "Cantar de Roldán". Francia fue la cuna de los trovadores en el siglo XII, así como del "Ars Nova" dos siglos más tarde. Durante el Romanticismo París se convierte en el centro musical del mundo y en la actualidad Francia mantiene un lugar privilegiado en la creación musical gracias a nuevas generaciones de compositores. Dentro de los exponentes de la música popular francesa de la segunda mitad del siglo XX, se encuentran figuras como Edith Piaf, Dalida, Charles Aznavour, Charles Trenet, Gilbert Bécaud, Johnny Hallyday, Georges Brassens, Serge Gainsbourg, Jean-Michel Jarre, Michel Sardou o Barbara.

Caracterizada por su variedad, fruto de una diversidad regional, tanto cultural como de materias primas, así como también por su refinamiento, la cocina francesa está considerada como referente mundial. Su influencia se deja sentir principalmente en las cocinas del mundo occidental que han ido incorporando a sus bases conocimientos técnicos franceses. El renombre internacional de sus principales "chefs", como Taillevent, La Varenne, Carême, Escoffier, Ducasse o Bocuse contribuyó a la difusión de la alta cocina por los restauradores franceses desde finales del siglo XIII. El "art de la table" o arte de la mesa, desarrolla una serie de recomendaciones sobre cómo presentar la mesa, servir los platos y degustarlos. La célebre guía roja Michelin ("Guide rouge Michelin") establece una clasificación de los mejores restaurantes mundiales mediante una jerarquización por número de estrellas, el máximo de ellas reservado a unos pocos considerados de calidad suprema.
Con el apoyo de las autoridades y el beneplácito del presidente de la República Nicolas Sarkozy, un grupo de chefs y gastrónomos abogan por que la cocina francesa sea incluida por la Unesco en la lista del Patrimonio de la Humanidad.

Tradicionalmente, cada región posee su propia cocina, caracterizada por los productos

Si en algo destaca la gastronomía francesa, aparte de por sus panes, sus quesos y su bollería, es por sus vinos y licores de todo tipo, desde el burdeos hasta los espumosos de la región de Champaña-Ardenas. Son, además, típicos franceses y de producción nacional la absenta, el armañac, el calvados, el chartreuse, el Cointreau, el coñac y el pastis.

A lo largo de su historia, Francia ha tenido grandes deportistas que han puesto en alto la bandera tricolor francesa. Entre ellos cabe destacar al 4 veces campeón de Fórmula 1, Alain Prost, a Romain Grosjean, a la tenista Mary Pierce, a los tenistas Gael Monfils y Richard Gasquet, a los baloncestistas de la NBA, Tony Parker , Joakim Noah y Boris Diaw. La mejor participación de Francia en los Juegos Olímpicos fue en 1900, año en que la cita se realizó en París, ciudad que volvió a acoger el certamen en 1924. En este evento, la delegación gala nunca ha bajado de los 10 primeros lugares siendo una de las mayores potencias mundiales a nivel olímpico y por qué no, a nivel deportivo.

Francia es una de las potencias del Automovilismo a nivel mundial, ya que es sede de las 24 Horas de Le Mans, una de las carrera de automovilismo más importantes del mundo. El Gran Premio de Francia se disputó desde 1950 hasta 2008, además hubo numerosos equipos franceses en la categoría reina entre los que destacan Equipe Ligier y el equipo Renault F1 que fueron campeones en 2005 y 2006.

Los están bien implantados en Francia. Así por ejemplo el Tour de Francia, celebrado anualmente en el mes de julio desde 1903, es la competición ciclística más prestigiosa del calendario profesional. También destacan en el ciclismo en pista, modalidad en la que han conseguido varios campeonatos del mundo. El Torneo Roland Garros en París es uno de los torneos más cosmopolitas del Grand Slam. En lo referente a las artes marciales, Francia también destaca entre uno de los mejores de Europa. Pues la que más domina hasta el día de hoy es el karate, el judo y el savate (box francés), este último uno de los más difundidos en el mundo principalmente en los torneos del Knock Out. En Judo destaca como uno de los más importantes en la historia del mundo, el francés David Douillet con diversas participaciones y premiaciones a lo largo de su trayectoria en este deporte.
En cuanto a los , la selección de fútbol de Francia es uno de los combinados nacionales más importantes a nivel mundial. Obtuvo el campeonato mundial de 1998 y en el 2006 obtuvo el subcampeonato gracias a la "generación dorada" liderada por Thierry Henry y Zinedine Zidane. Este mismo conjunto obtuvo la Eurocopa 2000 y las Copas Confederaciones de 2001 y 2003.

La liga nacional, conocida como la Ligue 1 es una de las mejores a nivel europeo. Destacan clubes como el Olympique de Marsella, único club ganador de la prestigiosa Liga de Campeones, así como el Olympique de Lyon, club ganador de siete títulos de liga de forma ininterrumpida en los inicios del siglo XXI. Otros equipos importantes son el París Saint-Germain, el AS Monaco, el Girondins de Burdeos, entre otros.

Por su parte la Selección de rugby de Francia es una de las mejores del mundo. El Balonmano es uno de los deportes más seguidos, teniendo a la Selección de balonmano de Francia como un gran protagonista a nivel internacional. Dentro de su palmarés se cuenta el título en la Copa de Europa 2010, los campeonatos del Mundo de 2009 y 2011, y la medalla de oro de los Olímpicos de Beijing 2008, siendo la primera selección de balonmano en conseguir estos tres títulos, los más importantes del mundo en este deporte, de manera consecutiva. También la Selección de baloncesto de Francia es igualmente uno de los mejores combinados nacionales más importantes a nivel mundial. Obtuvo el quinto puesto en el Campeonato mundial de baloncesto de 2006.




</doc>
<doc id="1175" url="https://es.wikipedia.org/wiki?curid=1175" title="Fuerza">
Fuerza

En física, la fuerza es una magnitud vectorial que mide la razón de cambio de momento lineal entre dos partículas o sistemas de partículas. Según una definición clásica, fuerza es todo agente capaz de modificar la cantidad de movimiento o la forma de los materiales. No debe confundirse con los conceptos de esfuerzo o de energía. 

En el Sistema Internacional de Unidades, la unidad de medida de fuerza es el newton que se representa con el símbolo N, nombrada así en reconocimiento a Isaac Newton por su aportación a la física, especialmente a la mecánica clásica. El newton es una unidad derivada del Sistema Internacional de Unidades que se define como la fuerza necesaria para proporcionar una aceleración de 1 m/s² a un objeto de 1 kg de masa.

La fuerza es un modelo matemático de intensidad de las interacciones, junto con la energía. Así, por ejemplo, la fuerza gravitacional es la atracción entre los cuerpos que tienen masa, el peso es la atracción que la Tierra ejerce sobre los objetos en las cercanías de su superficie, la fuerza elástica es el empuje o tirantez que ejerce un resorte comprimido o estirado, respectivamente, etcétera. En Física, hay dos tipos de ecuaciones de fuerza: las "de causas", en las cuales se especifica el origen de la atracción o repulsión, como, por ejemplo, la ley de la gravitación universal de Newton o la ley de Coulomb; y las "de efectos", la cual es, fundamentalmente, la segunda ley de Newton. 

La fuerza es una magnitud física de carácter vectorial capaz de deformar los cuerpos (efecto estático), modificar su velocidad o vencer su inercia y ponerlos en movimiento si estaban inmóviles (efecto dinámico). En este sentido, la fuerza puede definirse como toda acción o influencia capaz de modificar el estado de movimiento o de reposo de un cuerpo (imprimiéndole una aceleración que modifica el módulo o la dirección de su velocidad).

Comúnmente nos referimos a la fuerza aplicada sobre un objeto sin tener en cuenta al otro objeto u objetos con los que está interactuando y que experimentarán, a su vez, otras fuerzas. Actualmente, cabe definir la fuerza como un ente físicomatemático, de carácter vectorial, asociado con la interacción del cuerpo con otros cuerpos que constituyen su entorno.

El concepto de fuerza fue descrito originalmente por Arquímedes, si bien únicamente en términos estáticos. Arquímedes y otros creyeron que el ""estado natural"" de los objetos materiales en la esfera terrestre era el reposo y que los cuerpos tendían, por sí mismos, hacia ese estado si no se actuaba sobre ellos en modo alguno. De acuerdo con Aristóteles la perseverancia del movimiento requería siempre una causa eficiente (algo que parece concordar con la experiencia cotidiana, donde las fuerzas de fricción pueden pasar desapercibidas). 

Galileo Galilei (1564-1642) sería el primero en dar una definición dinámica de fuerza, opuesta a la de Arquímedes, estableciendo claramente la ley de la inercia, afirmando que un cuerpo sobre el que no actúa ninguna fuerza permanece en movimiento inalterado. Esta ley, que refuta la tesis de Arquímedes, aún hoy día no resulta obvia para la mayoría de las personas sin formación científica.

Se considera que fue Isaac Newton el primero que formuló matemáticamente la moderna definición de fuerza, aunque también usó el término latino "vis impressa" ('fuerza impresa') y "vis motrix" para otros conceptos diferentes. Además, Isaac Newton postuló que las fuerzas gravitatorias variaban según la ley de la inversa del cuadrado de la distancia.

Charles Coulomb fue el primero que comprobó que la interacción entre cargas eléctricas o electrónicas puntuales también varía según la ley de la inversa del cuadrado de la distancia (1784).

En 1798, Henry Cavendish logró medir experimentalmente la fuerza de atracción gravitatoria entre dos masas pequeñas utilizando una balanza de torsión. Gracias a lo cual pudo determinar el valor de la constante de la gravitación universal y, por tanto, pudo calcular la masa de la Tierra.

Con el desarrollo de la electrodinámica cuántica, a mediados del siglo XX, se constató que la "fuerza" era una magnitud puramente macroscópica surgida de la conservación del momento lineal o cantidad de movimiento para partículas elementales. Por esa razón las llamadas fuerzas fundamentales suelen denominarse "interacciones fundamentales".

La fuerza se puede definir a partir de la derivada temporal del momento lineal:
Si la masa permanece constante, se puede escribir:
donde m es la masa y a la aceleración, que es la expresión tradicional de la segunda ley de Newton. En el caso de la estática, donde no existen aceleraciones, las fuerzas actuantes pueden deducirse de consideraciones de equilibrio.

La ecuación es útil sobre todo para describir el movimiento de partículas o cuerpos cuya forma no es relevante para el problema planteado. Pero incluso si se trata de estudiar la mecánica de sólidos rígidos se necesitan postulados adicionales para definir la velocidad angular del sólido, o su aceleración angular así como su relación con las fuerzas aplicadas. Para un sistema de referencia arbitrario la ecuación debe substituirse por:
2\mathbf{A}_t\frac{d\mathbf{r}}{dt} + 
\left( \frac{d\mathbf{A}_t}{dt} -\mathbf{A}^2_t \right)\mathbf{r}</math>
Donde:
En un sentido estricto, todas las fuerzas naturales son fuerzas producidas a distancia como producto de la interacción entre cuerpos; sin embargo desde el punto de vista macroscópico, se acostumbra a dividir a las fuerzas en dos tipos generales:

En los sólidos, el principio de exclusión de Pauli conduce junto con la conservación de la energía a que los átomos tengan sus electrones distribuidos en capas y tengan impenetrabilidad a pesar de estar vacíos en un 99 %. La impenetrabilidad se deriva de que los átomos sean "extensos" y que los electrones de las capas exteriores ejerzan fuerzas electrostáticas de repulsión que hacen que la materia sea macroscópicamente impenetrable.

Lo anterior se traduce en que dos cuerpos puestos en "contacto" experimentarán superficialmente fuerzas resultantes normales (o aproximadamente normales) a la superficie que impedirán el solapamiento de las nubes electrónicas de ambos cuerpos.

Las fuerzas internas son similares a las fuerzas de contacto entre ambos cuerpos y si bien tienen una forma más complicada, ya que no existe una superficie macroscópica a través de la cual se den la superficie. La complicación se traduce por ejemplo en que las fuerzas internas necesitan ser modelizadas mediante un tensor de tensiones en que la fuerza por unidad de superficie que experimenta un punto del interior depende de la dirección a lo largo de la cual se consideren las fuerzas.

Lo anterior se refiere a sólidos, en los fluidos en reposo las fuerzas internas dependen esencialmente de la presión, y en los fluidos en movimiento también la viscosidad puede desempeñar un papel importante.

La fricción en sólidos puede darse entre sus superficies libres en contacto. En el tratamiento de los problemas mediante mecánica newtoniana, la fricción entre sólidos frecuentemente se modeliza como una fuerza tangente sobre cualquiera de los planos del contacto entre sus superficies, de valor proporcional a la fuerza normal.

El rozamiento entre sólido-líquido y en el interior de un líquido o un gas depende esencialmente de si el flujo se considera laminar o turbulento y de su ecuación constitutiva.

En mecánica newtoniana la fuerza de atracción entre dos masas, cuyos centros de gravedad están lejos comparadas con las dimensiones del cuerpo, viene dada por la ley de la gravitación universal de Newton:

Donde:

Cuando la masa de uno de los cuerpos es muy grande en comparación con la del otro (por ejemplo, si tiene dimensiones planetarias), la expresión anterior se transforma en otra más simple:
_r =
-mg\hat{\mathbf{u}}_r = 
m\mathbf{g} </math>
Donde:

En mecánica newtoniana también es posible modelizar algunas fuerzas constantes en el tiempo como campos de fuerza. Por ejemplo la fuerza entre dos cargas eléctricas inmóviles, puede representarse adecuadamente mediante la ley de Coulomb:

Donde:
También los campos magnéticos estáticos y los debidos a cargas estáticas con distribuciones más complejas pueden resumirse en dos funciones vectoriales llamadas campo eléctrico y campo magnético tales que una partícula en movimiento respecto a las fuentes estáticas de dichos campos viene dada por la expresión de Lorentz:

Donde:
Los campos de fuerzas no constantes sin embargo presentan una dificultad especialmente cuando están creados por partículas en movimiento rápido, porque en esos casos los efectos relativistas de retardo pueden ser importantes, y la mecánica clásica, da lugar a un tratamiento de acción a distancia que puede resultar inadecuado si las fuerzas cambian rápidamente con el tiempo.

La fuerza eléctrica también son de acción a distancia, pero a veces la interacción entre los cuerpos actúa como una fuerza atractiva mientras que, otras veces, tiene el efecto inverso, es decir puede actuar como una fuerza repulsiva.

En el Sistema Internacional de Unidades (SI) y en el Cegesimal (cgs), el hecho de definir la fuerza a partir de la masa y la aceleración (magnitud en la que intervienen longitud y tiempo), conlleva a que la fuerza sea una magnitud derivada. Por el contrario, en el Sistema Técnico la fuerza es una Unidad Fundamental y a partir de ella se define la unidad de masa en este sistema, la unidad técnica de masa, abreviada u.t.m. (no tiene símbolo). Este hecho atiende a las evidencias que posee la física actual, expresado en el concepto de fuerzas fundamentales, y se ve reflejado en el Sistema Internacional de Unidades.

En relatividad especial la fuerza se debe definir solo como derivada del momento lineal, ya que en este caso la fuerza no resulta simplemente proporcional a la aceleración:
\frac{m\mathbf{v}}{\left[1-\frac{v^2}{c^2}\right]^{3/2}} \left( \frac{\mathbf{v}}{c^2}\cdot \mathbf{a} \right) + \frac{m\mathbf{a}}{\sqrt{1-\frac{v^2}{c^2}}} </math>
De hecho en general el vector de aceleración y el de fuerza ni siquiera serán paralelos, solo en el movimiento circular uniforme y en cualquier movimiento rectilíneo serán paralelos el vector de fuerza y aceleración pero en general se el módulo de la fuerza dependerá tanto de la velocidad como de la aceleración.

En la teoría de la relatividad general el campo gravitatorio no se trata como un campo de fuerzas real, sino como un efecto de la curvatura del espacio-tiempo. Una partícula másica que no sufre el efecto de ninguna otra interacción que la gravitatoria seguirá una trayectoria geodésica de mínima curvatura a través del espacio-tiempo, y por tanto su ecuación de movimiento será:

Donde:

La fuerza gravitatoria aparente procede del término asociado a los símbolos de Christoffel. Un observador en "caída libre" formará un sistema de referencia en movimiento en el que dichos símbolos de Christoffel son nulos, y por tanto no percibirá ninguna fuerza gravitatoria tal como sostiene el principio de equivalencia que ayudó a Einstein a formular sus ideas sobre el campo gravitatorio.

El efecto del campo electromagnético sobre una partícula relativista viene dado por la expresión covariante de la fuerza de Lorentz:

Donde:
La ecuación de movimiento de una partícula en un espacio-tiempo curvo y sometida a la acción de la fuerza anterior viene dada por:

Donde la expresión anterior se ha aplicado el convenio de sumación de Einstein para índices repetidos, el miembro de la derecha representa la cuadriaceleración y siendo las otras magnitudes:

En mecánica cuántica no resulta fácil definir para muchos sistemas un equivalente claro de la fuerza. Esto sucede porque en mecánica cuántica un sistema mecánico queda descrito por una función de onda o vector de estado formula_25 que en general representa a todo el sistema en conjunto y no puede separarse en partes. Solo para sistemas donde el estado del sistema pueda descomponerse de manera no ambigua en la forma formula_26 donde cada una de esas dos partes representa una parte del sistema es posible definir el concepto de fuerza. Sin embargo en la mayoría de sistemas interesantes no es posible esta descomposición. Por ejemplo si consideramos el conjunto de electrones de un átomo, que es un conjunto de partículas idénticas no es posible determinar una magnitud que represente la fuerza entre dos electrones concretos, porque no es posible escribir una función de onda que describa por separado los dos electrones.

Sin embargo, en el caso de una partícula aislada sometida a la acción de una fuerza conservativa es posible describir la fuerza mediante un potencial externo e introducir la noción de fuerza. Esta situación es la que se da por ejemplo en el modelo atómico de Schrödinger para un átomo hidrogenoide donde el electrón y el núcleo son discernibles uno de otro. En este y otros casos de una partícula aislada en un potencial el teorema de Ehrenfest lleva a una generalización de la segunda ley de Newton en la forma:

Donde:

En otros casos como los experimentos de colisión o dispersión de partículas elementales de energía positiva que son disparados contra otras partículas que hacen de blanco, como los experimentos típicos llevados a cabo en aceleradores de partículas a veces es posible definir un potencial que está relacionado con la fuerza típica que experimentará una partícula en colisión, pero aun así en muchos casos no puede hablarse de fuerza en el sentido clásico de la palabra.

En teoría cuántica de campos, el término "fuerza" tiene un sentido ligeramente diferente al que tiene en mecánica clásica debido a la dificultad específica señalada en la sección anterior de definir un equivalente cuántico de las fuerzas clásicas. Por esa razón el término "fuerza fundamental" en teoría cuántica de campos se refiere al modo de interacción entre partículas o campos cuánticos, más que a una medida concreta de la interacción de dos partículas o campos.

La teoría cuántica de campos trata de dar una descripción de las formas de interacción existentes entre las diferentes formas de materia o campos cuánticos existentes en el Universo. Así el término "fuerzas fundamentales" se refiere actualmente a los modos claramente diferenciados de interacción que conocemos. Cada fuerza fundamental quedará descrita por una teoría diferente y postulará diferentes lagrangianos de interacción que describan como es ese modo peculiar de interacción.

Cuando se formuló la idea de fuerza fundamental se consideró que existían cuatro "fuerzas fundamentales": la gravitatoria, la electromagnética, la nuclear fuerte y la nuclear débil. La descripción de las "fuerzas fundamentales" tradicionales es la siguiente:

Sin embargo, cabe señalar que el número de fuerzas fundamentales en el sentido anteriormente expuesto depende de nuestro estado de conocimiento, así hasta finales de los años 1960 la interacción débil y la interacción electromagnética se consideraban fuerzas fundamentales diferentes, pero los avances teóricos permitieron establecer que en realidad ambos tipos de interacción eran manifestaciones fenomenológicamente diferentes de la misma "fuerza fundamental", la interacción electrodébil. Se tiene la sospecha de que en última instancia todas las "fuerzas fundamentales" son manifestaciones fenomenológicas de una única "fuerza" que sería descrita por algún tipo de teoría unificada o teoría del todo.





</doc>
<doc id="1177" url="https://es.wikipedia.org/wiki?curid=1177" title="Fermión">
Fermión

Un fermión es uno de los dos tipos básicos de partículas elementales que existen en la naturaleza (el otro tipo es el bosón). Los fermiones se caracterizan por tener espín semi-entero (1/2, 3/2, ...).
En el modelo estándar de física existen dos tipos de fermiones fundamentales, los quarks y los leptones. Los fermiones se consideran los constituyentes básicos de la materia, que interactúan entre ellos vía bosones de gauge. El tipo de partícula se llama así en honor al científico italiano Enrico Fermi.

En la descripción de la mecánica cuántica no relativista las funciones de onda de los fermiones son antisimétricas, lo cual se corresponde con el hecho de que obedecen la estadística de Fermi-Dirac verificando, por tanto, el principio de exclusión de Pauli. Esta propiedad implica que dos fermiones no pueden ocupar el mismo estado cuántico al mismo tiempo.
Todas las partículas elementales "observadas" son fermiones o bosones. Una partícula compuesta, formada por varias elementales, puede ser también un fermión o un bosón dependiendo solo del número de fermiones que contenga:


Por el contrario el número de bosones que contenga la partícula es irrelevante de cara a determinar su posible naturaleza fermiónica o bosónica.

Por supuesto, el comportamiento fermiónico o bosónico de las partículas compuestas solo se aprecia si observamos el sistema a gran distancia en comparación con la escala de la partícula. Si observamos a escalas similares entonces la contribución de la estructura espacial empieza a ser importante. Por ejemplo, dos átomos de helio-4 a pesar de ser bosones no pueden ocupar el mismo espacio si este es comparable al tamaño de la estructura de la partícula en cuestión. Así, el helio líquido tiene una densidad finita comparable a la densidad de la materia líquida ordinaria.

Los fermiones elementales se dividen en dos grupos:


La materia ordinaria está básicamente formada por fermiones y a ellos debe prácticamente toda su masa. Los átomos están compuestos por quarks que a su vez forman los protones y los neutrones del núcleo atómico y también por leptones, los electrones. El principio de exclusión de Pauli obedecido por los fermiones es el responsable de la "impenetrabilidad" de la materia ordinaria, que hace que esta sea una substancia extensa. El principio de Pauli también es responsable de la estabilidad de los orbitales atómicos haciendo que la complejidad química sea posible. También es el responsable de la presión ejercida por la materia degenerada.

Los fermiones elementales también pueden ser clasificados en:



</doc>
<doc id="1180" url="https://es.wikipedia.org/wiki?curid=1180" title="Frankeniaceae">
Frankeniaceae

La familia Frankeniaceae consta de más de 100 especies de hierbas perennes o subarbustos, la mayoría halófilas y propias de regiones cálidas. Como familia ha sido ampliamente reconocida por muchos taxonomistas y estrechamente relacionada con "Tamaricaceae".

El Sistema APG II de 2003, también la reconoce como familia y la asigna al orden "Caryophyllales", en el clado de los eudicotiledóneos.

Sus miembros se caracterizan por hojas opuestas, pequeñas, ericoides, simples y enteras. Flores hermafroditas, actinomorfas; Cáliz con 4 - 7 dientes, parcialmente soldados; corola con 4 - 7 pétalos, provistos de un apéndice ligular en la uña; anteras con un número variable de estambres, a menudo 6 en 2 verticilos, 3 + 3 o 2 + 4; ovario súpero unilocular. Inflorescencias cimosas o flores aisladas. Fruto en caápsula loculicida.

La familia fue descrita por Nicaise Augustin Desvaux y publicado en "Dictionnaire raisonné de botanique" 188. 1817. El género tipo es: "Frankenia" 


</doc>
<doc id="1182" url="https://es.wikipedia.org/wiki?curid=1182" title="Fabales">
Fabales

Fabales es un orden de plantas de la clase "magnoliopsida", subclase "rosidae", de distribución mundial (más frecuente en las zonas tropicales) y con alta distribución altitudinal. Entre 16.000 y 18.000 especies (uno de los mayores órdenes), con gran importancia económica, como alimentación: frutos, semillas o la planta entera (forraje); medicinal; industrial: gomas, aceites y perfumes; ornamental; etc.

Grupo muy homogéneo. Flores actinomorfas o zigomorfas (existe tendencia a la zigomorfía), hermafroditas, pentámeras, con tendencia a la reducción del número de estambres, con un carpelo. Hojas en general compuestas y estipuladas. Fruto generalmente seco y dehiscente por dos suturas (nervio del carpelo y sutura): legumbre.
Es frecuente la formación de nódulos fijadores de nitrógeno.
Árboles, arbustos y hierbas (estos dos últimos más frecuentes en las zonas templadas. Relacionado con Rosaceae y con Saxifragaceae.

Tres grupos, que suelen distribuirse de dos formas diferentes: 


</doc>
<doc id="1186" url="https://es.wikipedia.org/wiki?curid=1186" title="Fagaceae">
Fagaceae

Fagaceae, las Fagáceas, son una familia del orden Fagales que reúne unas 670 especies aceptadas de árboles o arbustos propios del hemisferio norte.

Árboles o arbustos monoicos, anemófilos o más raramente entomófilos, de hojas persistentes, marcescentes o caducas, simples -a menudo lobadas-, alternas, con estípulas caducas, pecioladas y con nervadura pinnada. Flores masculinas reunidas en amentos erectos o péndulos, o en glomérulos, de perianto sepáloide dividido en 4-6(9) lóbulos o lacinias, con (4)6- 20(40) estambres, exertos y de filamentos libres. Flores femeninas solitarias o dispuestas en grupos de 2-3 en la base de las inflorescencias masculinas y rodeadas por un involucro basal cupuliforme de brácteas escamoides soldadas, el cual se transforma en una cúpula más o menos envolvente en el fruto o la infrutescencia; tienen el perianto con 4-8 lóbulos o lacinias, el ovario ínfero, generalmente trilocular -a veces con 6(9) lóculos-, con 2 rudimentos seminales por lóculo y 6-9 estilos. Frutos monospermas en nuez/aquenio de endocarpo generalmente con interior peludo, rodeados parcial (bellota) o totalmente (castaña, hayuco), individualmente o en grupos de 2-3, excepcionalmente hasta 15, en una cúpula -o calibio- multibracteada escuamiforme o espinosa, dehiscente por valvas en número igual al número de nueces/aquenios más uno. Las semillas carecen de endospermo y están rodeadas por un tegumento (episperma) membraneáceo.

Las fagáceas se dividen en 2 subfamilias (Fagoideae K. Koch y Quercoideae Õrsted) y se aceptan 7 géneros.

La Monofilia de las fagáceas tienen un fuerte apoyo tanto en datos morfológicos (especialmente la morfología del fruto) como moleculares.

El género del hemisferio sur Nothofagus, con sus casi 40 especies, usualmente las "hayas meridionales", fue históricamente ubicado dentro de las fagáceas, como género hermano de "Fagus", pero recientes evidencias moleculares sugieren que las cosas son de otra manera. Mientras que "Nothofagus" comparten un número de características comunes con las fagáceas, como una estructura de fruto en forma de cúpula, difiere significativamente en otras, incluyendo una distintiva morfología del polen y las estípulas así como por tener diferente número de cromosomas. El punto de vista aceptado actualmente por los botánicos sitemáticos es colocar "Nothofagus" dentro de su propia familia monogenérica, las notofagáceas.


Las fagáceas están ampliamente distribuidas por todo el hemisferio norte. La diversidad a nivel de género está concentrada en el sureste de Asia, donde se cree que evolucionaron la mayor parte de los géneros existentes antes de emigrar a Europa y Norteamérica (a través del Puente de Beringia). Algunos miembros de las fagáceas, como "Fagus grandifolia" o "Castanea dentata" y "Quercus alba" en el noreste de los Estados Unidos, o "Fagus sylvatica", "Quercus robur" y "Q. petraea" en Europa) a menudo son ecológicamente dominantes en los bosques templados septentrionales.

Varios miembros de las fagáceas tienen importantes usos económicos. Muchas especies de roble, castaño y haya (géneros "Quercus", "Castanea" y "Fagus" respectivamente) se usan comúnmente como madera para suelos, muebles, gabinetes y barricas de vino. El corcho para los tapones de botellas y una miríada de otros usos se hace a partir de la corteza del alcornoque, "Quercus suber." Las castañas, un alimento sabroso para el invierno, son los frutos de especies del género "Castanea." Numerosas especies de diversos géneros son prominentemente ornamentales, y astillas de madera del genus "Fagus" a menudo se usan para dar sabor a las bebidas.



</doc>
<doc id="1187" url="https://es.wikipedia.org/wiki?curid=1187" title="Frecuencia">
Frecuencia

La Frecuencia es una magnitud que mide el número de repeticiones por unidad de tiempo de cualquier fenómeno o suceso periódico.

Para calcular la frecuencia de un suceso, se contabilizan un número de ocurrencias de éste, teniendo en cuenta un intervalo temporal, y luego estas repeticiones se dividen por el tiempo transcurrido. Según el Sistema Internacional (SI), la frecuencia se mide en hercios (Hz), en honor a Heinrich Rudolf Hertz. Un hercio es la frecuencia de un suceso o fenómeno repetido por segundo. Así, un fenómeno con una frecuencia de dos hercios se repite dos veces por segundo. Esta unidad se llamó originalmente «ciclo por segundo» (cps).
Otras unidades para indicar frecuencias son revoluciones por minuto (rpm o r/min según la notación del SI); las pulsaciones del corazón se miden en latidos por minuto (lat/min) y el "tempo" musical se mide en «pulsos por minuto» (bpm, del inglés “beats per minute”).

Un método alternativo para calcular la frecuencia es medir el tiempo entre dos repeticiones (periodo) y luego calcular la frecuencia (f) recíproca de esta manera:

donde T es el periodo de la señal.

La frecuencia tiene una relación inversa con el concepto de longitud de onda (ver gráfico), a mayor frecuencia menor longitud de onda y viceversa. La frecuencia "f" es igual a la velocidad "v" de la onda, dividido por la longitud de onda λ (lambda):

Cuando las ondas viajan de un medio a otro, como por ejemplo de aire a agua, la frecuencia de la onda se mantiene constante, cambiando solo su longitud de onda y la velocidad.

En Europa, Asia, Oceanía, África y gran parte de América del Sur, la frecuencia de corriente alterna para uso doméstico (en electrodomésticos, etc.) es de 50 Hz. En cambio en América del Norte de 60 Hz.

Para determinar la frecuencia de la corriente alterna producida por un generador eléctrico se utiliza la siguiente ecuación:

formula_4

Donde:

otra manera de calcular la frecuencia de la corriente alterna producida por un generador eléctrico:

formula_5

Donde:

De acuerdo a lo indicado anteriormente, la longitud de onda tiene una relación inversa con la frecuencia, a mayor frecuencia, menor longitud de onda, y viceversa. La longitud de onda λ (lambda) es igual a la velocidad "v" de la onda, dividido por la frecuencia "f":

Una onda electromagnética de 2 milihercios tiene una longitud de onda aproximadamente igual a la distancia de la Tierra al Sol (150 millones de kilómetros).
Una onda electromagnética de 1 microhercio tiene una longitud de onda de 0,0317 años luz.
Una onda electromagnética de 1 nanohercio tiene una longitud de onda de 31,69 años luz.

La luz visible es una onda electromagnética, que consiste en oscilaciones eléctricas y campos magnéticos que viajan por el espacio. La frecuencia de la onda determina el color: 4×10 Hz es la luz roja, 8×10 Hz es la luz violeta, y entre estos (en el rango de 4-8×10 Hz) están todos los otros colores del arco iris. Una onda electromagnética puede tener una frecuencia de menos de 4×10 Hz, pero no será visible para el ojo humano, tales ondas se llaman infrarrojos (IR). Para frecuencias menores, la onda se llama microondas, y en las frecuencias aún más bajas tenemos las ondas de radio. Del mismo modo, una onda electromagnética puede tener una frecuencia mayor que 8×10 Hz, pero será invisible para el ojo humano, tales ondas se llaman ultravioleta (UV). Las ondas de frecuencia mayor que el ultravioleta se llaman rayos X, y con frecuencias más altas aún encontramos los rayos gamma.

Todas estas ondas, desde las de radio de baja frecuencia hasta los rayos gamma de alta frecuencia, son fundamentalmente las mismas, todas ellas son llamadas radiación electromagnética y viajan a través del vacío a la velocidad de la luz.

Otra característica de una onda electromagnética es la longitud de onda. La longitud de onda es inversamente proporcional a la frecuencia, por lo que una onda electromagnética con una frecuencia más alta tiene una longitud de onda más corta, y viceversa.

El sonido es un fenómeno físico que consiste en la vibración de una fuente que lo propaga a través del aire u otro medio elástico y es percibida por un receptor, el aparato auditivo humano.
Tal vibración puede ser más o menos frecuente, se repite más o menos veces en la unidad de tiempo, y a tal propiedad se la denomina precisamente FRECUENCIA. La cual por convención se mide en ciclos por segundo. Cuanto más frecuentes son las vibraciones (más ciclos por segundo) el oído percibe el sonido definiéndolo por tal sensación como más "agudo", y a la inversa, al ser menos frecuentes, como más "grave".
El oído humano tiene un rango de percepción limitado, que muy aproximadamente (ya que varía en cada individuo y con la edad para uno solo) va desde 20 Hz hasta 20 000 Hz.





</doc>
<doc id="1189" url="https://es.wikipedia.org/wiki?curid=1189" title="Filicopsida">
Filicopsida

Los helechos (taxón Filicopsida, Pterophyta, Filicinae o Polypodiophyta) son plantas vasculares sin semilla (pteridofitas), cuyas características morfológicas más sobresalientes son sus hojas grandes ("megafilos" o "frondes"), usualmente pinadas y con prefoliación circinada. Tradicionalmente ha agrupado a 3 gruposː los helechos leptosporangiados (Polypodiidae), maratiales y ofioglosales, sin embargo, los análisis genéticos modernos encontraron que los ofioglosales están relacionados con los psilotales, los cuales históricamente se clasificaron aparte al considerárseles primitivos, agrupándose ahora juntos en un solo taxón llamado Ophioglossidae o Psilotopsida.

La naturaleza monofilética de los helechos ha sido puesta en duda por varios autores debido a los resultados de los primeros análisis filogenéticos moleculares; sin embargo, se ha comprobado que forman un clado hermano de los equisetos con base en la genética plastidial, nuclear y mitocondrial. Tradicionalmente se han agrupado en dos grupos sobre la base de la estructura y desarrollo de los esporangios: maratiales y ofioglosales son llamados en conjunto "helechos eusporangiados" (pero también son eusporangiados los equisetos y los psilotos), y los polipódidos son llamados "helechos leptosporangiados"; aunque los análisis filogenéticos determinaron que los eusporangiados son en realidad un grupo parafilético en relación a los leptosporangiados. 

Filogenéticamente se puede dividir en dos gruposː Ophioglossidae (ofioglosales y psilotales) y el grupo conocido popularmente como de los "helechos verdaderos" (maratiales y polipódidos) que hoy en día luego de los análisis moleculares de ADN consensuados se determinó que forman un clado (grupo monofilético según la escuela cladista).

La palabra castellana helecho, al igual que términos como Filices o Filicopsida, provienen del latín "filix" o "filicis". Un lugar poblado de helechos se llamaba "filictum" o "filectum" en latín.

El análisis genético plastidial ha colocado a los helechos como un clado hermano de los equisetos, al igual que el análisis genético nuclear y el análisis genético mitocondrial. La filogenia más actualizada (2013-2014), indica que los helechos vivientes forman un grupo monofilético dentro de Monilophyta del siguiente modo:

Se estima que el clado de los helechos aquí mostrado tiene más de 350 millones de años, pudiéndose observar que presenta los dos subclados siguientesː

Ophioglossidae o Psilotopsida reúne a ofioglossales y psilotales. Anteriormente no fueron considerados un grupo debido a sus diferencias morfológicas, pues se creyó que "Psilotum" estaba relacionado con pteridofitas primitivas sin hojas como las riniofitas. Hoy se considera que "Psilotum" redujo evolutivamente sus frondas a escamas al haberse asociado con hongos.

Este clado se caracteriza por incluir plantas pequeñas, con reducción del sistema radicular, las raíces no presentan pelos radicales o están ausentes y el esporóforo se sitúa junto a la cara adaxial (haz) de la fronda. Embrión exoscópico y el gametofito subterráneo, axial, no fotosintético y en simbiosis micorriza (con hongos). El genoma es muy grande, inusual para las plantas terrestres. La antigüedad del grupo se calcula en casi 300 millones de años.

Usualmente, se denominan helechos verdaderos a las maratiáceas y a los helechos leptosporangiados (Polipodiidae). Son notables las características que los diferencian de los demás helechos, como la típica fronda compuesta usualmente bipinnada y la vernación circinada (primordio foliar enrollado). Presentan frondas fértiles (esporófilos) que contienen los soros (esporangios) situados debajo (al envés) y hay escamas. El tipo de haz vascular de las hojas es anficribal o perifloemático, es decir, el haz es concéntrico y el floema rodea al xilema. El gametofito o prótalo es verde (fotosintético) y está sobre el suelo. La antigüedad de este clado se calcula en más de 300 millones de años.

Las maratiáceas y a los helechos leptosporangiados, a pesar de sus evidentes similitudes, no han sido considerados un grupo formal y los helechos verdaderos así descritos no han poseído un nombre científico o taxón, salvo en ocasiones en que se han denominado Pteridophyta o Filicophyta (separado de Ophioglossophyta). Esto se debe a dos razonesː En primer lugar, las clasificaciones históricas le dieron valor taxonómico al desarrollo del esporangio (leptosporangio y eusporangio), por lo que se estableció así una relación entre maratiales y ofioglosales. En segundo lugar, los análisis filogenéticos moleculares han sido contradictorios, obteniéndose diversos resultados, en donde los equisetos aparecían a veces relacionados con Marattiales y/o Polypodiidae o con Ophioglossidae, lo que provocó que el taxón Filicopsida dejara de usarse en los últimos sistemas taxonómicos. Sin embargo, los análisis más completos y recientes que se basan en la genética plastidial, nuclear y mitocondrial han respaldado la unidad de los helechos, por lo que es probable que en el futuro se le asigne un taxón (probablemente clase o subclase) al clado de los helechos y al subclado de los helechos verdaderos.
Establecer la filogenia de grupos extintos es difícil y especulativa. Sin embargo, algunos autores han intentado establecer estas relaciones:

Estudios filogenéticos anteriores consideraron a los helechos como un grupo parafilético, tal como se presenta a Monilophyta en el cuadro a continuación:

Para una discusión acerca de la filogenia de estos grupos ver la parte de sistemática en Pteridophyta. Para una descripción básica de la morfología de los helechos ver Pteridophyta. La monofilia de este grupo es discutida: Ver también el sistema de clasificación de monilophytas de Smith 2006).

Las filicopsidas se pueden definir como pteridofitas con esporofito con: cilindro vascular derivado de la sifonostela, megafilos, esporofilia (esporangios siempre en las hojas), y esporangios ubicados en el margen o en la cara abaxial de los megafilos. Si estamos definiendo a las Filicopsida "sensu" Engler, o a las Pterophyta/Pteropsida "sensu" Bold & "al.", los esporangios pueden ser eusporangios o leptosporangios. Si estamos definiendo a las Filicopsida "sensu" Bold & "al.", a este taxón corresponden solo las pterophytas con leptosporangios.

La mayoría son terrestres, saxícolas (que viven en las piedras) o epífitas, pero también las hay palustres (continentales y litorales) y acuáticas.

Hay varios términos equivalentes que definen a los helechos, históricamente se clasificaron dentro de Pteridophyta. El término más usado es Filicopsida, que filogenéticamente son el grupo más moderno dentro de las pteridofitas. En el sistema de clasificación de Engler, tanto los helechos con megafilos eusporangiados como los leptosporangiados entran dentro de este taxón. En el sistema aceptado por Bold & "al." (1989), solo los helechos con megafilos leptosporangiados (Polypodiidae) pertenecen al taxón Filicopsida, y los helechos con megafilos eusporangiados junto con los leptosporangiados pertenecen a la división Pterophyta (que por lo tanto es sinónimo de Filicopsida "sensu" Engler). A veces a las pterophytas no se les da el rango de división sino el de clase, al referirse a las filicópsidas es imprescindible aclarar según qué sistema de clasificación se las está definiendo.

En el siglo 18 se consideraba a los helechos en la familia Filices (Linneo 1751, Adanson 1763) y se los colocó dentro de las plantas "acotiledóneas" (Jussieu 1774). En el siglo 19 se usó los términos Filicoideae (Lindley 1846), Filices (Haeckel 1866), clase Filicinae que junto a Equisetinae y
Lycopodinae formaban la división Pteridophyta (Eichler 1883, Engler 1886). En el siglo 20 hay varios nombres: Pteridophyta (Bessey 1907), clase Filicopsida (Engler 1924), Filicinae (Wettstein 1924), Pterophyta (Smith 1955, Bold 1957), Polypodiophyta (Cronquist et al 1966), Filicatae (Kubitzki et al. 1990-), Filicinophyta (Margulis et al 1998) y nombres menos usados como Filicophyta, Filicinlophyta, Filicophytina, y las clases Polypodiopsida y Pteropsida.

En este siglo, a la luz de los análisis filogenéticos moleculares contradictorios, se ha preferido no asignarles ningún taxón a los helechos, ni tampoco a los helechos verdaderos. Sin embargo, APWeb (2015) hace alusión al clado ((Psilotales + Ophioglossales) (Marattiopsida + Polypodiopsida)).

Históricamente se clasifican en diversos grupos:

Las clasificaciones tradicionales más antiguas como la de Engler habían agrupado a todos los "helechos" en el mismo clado, siendo Filicopsida la clase en que se agrupaban los "helechos con megafilos", hoy conocidos como los clados Polypodiopsida, Marattiopsida y Ophioglossaceae. Dentro de "Filicopsida" ("sensu" Engler), Engler se había dado cuenta de que los helechos eusporangiados eran más primitivos, y probablemente no estaban relacionados entre sí, por lo que las Ophioglossaceae y las Marattiaceae estaban ubicadas en su propia subclase. Con respecto a los leptosporangiados, no los concibió como un clado, dejando en su propia subclase a los leptosporangios más modificados: así las Osmundaceae (con su leptosporangio primitivo con anillo lateral), las Marsileaceae y las Salviniaceae tenían sus propias subclases. Tampoco relacionó a los helechos heterosporados Marsileaceae y Salviniaceae como hermanos, ya que sus esporocarpos parecían tener orígenes diferentes, y supuso que sus parecidos eran una convergencia debido a la transición al hábito acuático, más que el resultado de descender de un antecesor común (para una interesante discusión acerca de las homologías en el esporocarpo de marsileáceas y salviniáceas ver Salviniales, clado donde hoy en día se agrupa a las dos familias).

En resumen, la clasificación "sensu" Engler es la siguiente:

Clasificación Taxonómica

. TAXONOMÍA Y MORFOLOGÍA

Los helechos son plantas sin flores ni semillas, pertenecientes al grupo de las Pteridofitas. Se reproducen mediante esporas, las cuales necesitan la presencia de agua para completar su ciclo biológico.
Los helechos son notables por:

•Sus hojas (frondes).
•Su tallo subterráneo (rizomatoso).
•Su reproducción particular.
•Sus numerosos géneros y especies. 



Es un cormo sin crecimiento secundario, con raíces adventicias, sifonostela, megafilos, esporangios en margen o cara abaxial de megafilos. La prefoliación es circinada, característica de los helechos (si en el sistema de clasificación de Engler, con excepción de la subclase Ophioglossidae, donde la prefoliación es plegada con estípulas formando vaina).

Los leptosporangios pueden tener apertura por estomio apical (Osmundaceae), por anillo funcional (Filicidae), o pueden no tener partes de la pared especializadas en la apertura (Marsileaceae, Salviniales).

Normalmente los helechos tienen megafilos que pueden ser:

Las esporas pueden dar gametos masculinos y femeninos (esporofitos isosporados), o puede haber 2 morfos de esporas que darán diferentes sexos del gametofito (esporofitos heterosporados), en este caso se llaman megasporas (las que darán gametofito femenino con gametas femeninas) y micrósporas (las que darán gametofito masculino con gametas masculinas). Todos los subtaxones de Filicopsida son isosporados, salvo Marsileaceae y Salviniales, ambos taxones adaptados para la vida acuática o palustre, que son heterosporados.

Al microscopio se observan dos morfos de esporas, que pueden ser trilete o monolete, carácter utilizado en la determinación de las familias.

A diferencia del otro sistema de clasificación, Engler reúne en las Filicopsidas tanto a los helechos eusporangiados como a los leptosporangiados. De esta forma Marattiaceae y Ophioglossidae entran dentro de este taxón.

El sistema de clasificación de Engler divide a las Filicopsidas en 7 subclases, una de representantes extinguidos:

1 - Primofílices. Subclase de representantes extinguidos, con dos órdenes: Cladoxylales y Coenopteridales.

2 - Ophioglossidae. Esporofitos isospóreos, eusporangiados. Trofoesporofilos sectoriales (en esta subclase las pinas fértiles se llaman espigas). Eusporangios en sinangios o soros en las últimas pinas del trofoesporofilo. Esporas trilete. Prefoliación plegada con estípulas formando vaina. Necesitan mucha agua para vivir. Raíces micorrícicas (que se asocian con hongos). Gametofito también micorrícico y tuberoso. Un orden: Ophioglossales, única familia: Ophioglossaceae.

3 - Marattidae. Esporofitos isospóreos, eusporangiados. Trofoesporofilos temporales. Esporangios en sinangios o soros. Esporas trilete. Polistela. Prefoliación circinada. Estípulas aladas. Un orden: Marattiales, única familia: Marattiaceae.

4 - Osmundidae. Esporofitos isospóreos. Leptosporangios con estomio apical y escudo (según algunos autores, su morfología es intermedia entre eusporangiados y leptosporangiados). Esporofilos o trofoesporofilos sectoriales. Prefoliación circinada. Esporas trilete. Orden Osmundales, única familia: Osmundaceae.

5 - Filicidae. Esporofitos isospóreos. Leptosporangios con anillo funcional. Prefoliación circinada. Muchos órdenes y familias. Los comúnmente llamados "helechos".

6 - Marsileidae. Esporofitos heterospóreos. Leptosporangios sin anillo o con anillo no funcional débilmente marcado en la parte apical. Leptosporangios encerrados en esporocarpos. Prefoliación circinada. Solo viven en terrenos de agua permanente. Un orden: Marsileales, única familia: Marsileaceae.

7 - Salviniidae. Esporofitos heterospóreos. Leptosporangios sin anillo, en soros encerrados en esporocarpos. Prefoliación circinada. Plantas flotantes. Orden Salviniales, dos familias (a veces se ven como dos géneros de la misma familia): Salviniaceae, Azollaceae.






</doc>
<doc id="1191" url="https://es.wikipedia.org/wiki?curid=1191" title="Fungi">
Fungi

En biología, el término fungi (latín, literalmente ""hongos"") designa a un grupo de organismos eucariotas entre los que se encuentran los mohos, las levaduras y los organismos productores de setas. Se clasifican en un reino distinto al de las plantas, animales y protistas. Se distinguen de las plantas en que son heterótrofos; y de los animales que poseen paredes celulares, como las plantas, compuestas por quitina, en vez de celulosa, y que se alimentan por absorción, como las plantas. Se ha descubierto que organismos que parecían hongos en realidad no lo eran, y que organismos que no lo parecían en realidad sí lo eran, si llamamos "hongo" a todos los organismos derivados del que ancestralmente adquirió la capacidad de formar una pared celular de quitina. Debido a ello, si bien este taxón está bien delimitado desde el punto de vista evolutivo, aún se están estudiando las relaciones filogenéticas de los grupos menos conocidos, y su lista de subtaxones ha cambiado mucho con el tiempo en lo que respecta a grupos muy derivados o muy basales.

Los hongos se encuentran en hábitats muy diversos: pueden ser pirófilos ("Pholiota carbonaria") o coprófilos ("Psilocybe coprophila"). Según su ecología, se pueden clasificar en cuatro grupos: saprofitos, liquenizados, micorrizógenos y parásitos. Los hongos saprofitos pueden ser sustrato específicos: "Marasmius buxi" o no específicos: "Mycena pura". Los simbiontes pueden ser: hongos liquenizados basidiolichenes: "Omphalina ericetorum " y ascolichenes: "Cladonia coccifera" y hongos micorrízicos: específicos: "Lactarius torminosus" (solo micorriza con abedules) y no específicos: "Hebeloma mesophaeum".
En la mayoría de los casos, sus representantes son poco conspicuos debido a su diminuto tamaño; suelen vivir en suelos y juntos a materiales en descomposición y como simbiontes de plantas, animales u otros hongos. Cuando fructifican, no obstante, producen esporocarpos llamativos (las setas son un ejemplo de ello). Realizan una digestión externa de sus alimentos, secretando enzimas, y que absorben luego las moléculas disueltas resultantes de la digestión. A esta forma de alimentación se le llama osmotrofia, la cual es similar a la que se da en las plantas, pero, a diferencia de aquellas, los nutrientes que toman son orgánicos. Los hongos son los descomponedores primarios de la materia muerta de plantas y de animales en muchos ecosistemas, y como tales poseen un papel ecológico muy relevante en los ciclos biogeoquímicos.

Los hongos tienen una gran importancia económica: las levaduras son las responsables de la fermentación de la cerveza y el pan, y se da la recolección y el cultivo de setas como las trufas. Desde 1940 se han empleado para producir industrialmente antibióticos, así como enzimas (especialmente proteasas). Algunas especies son agentes de biocontrol de plagas. Otras producen micotoxinas, compuestos bioactivos (como los alcaloides) que son tóxicos para humanos y otros animales. Las enfermedades fúngicas afectan a humanos, otros animales y plantas; en estas últimas, afecta a la seguridad alimentaria y al rendimiento de los cultivos.

Los hongos se presentan bajo dos formas principales: hongos filamentosos (antiguamente llamados "mohos") y hongos levaduriformes. El cuerpo de un hongo filamentoso tiene dos porciones, una reproductiva y otra vegetativa. La parte vegetativa, que es haploide y generalmente no presenta coloración, está compuesta por filamentos llamados "hifas" (usualmente microscópicas); un conjunto de hifas conforma el micelio (usualmente visible). A menudo las hifas están divididas por tabiques llamados septos.

Los hongos levaduriformes —o simplemente levaduras— son siempre unicelulares, de forma casi esférica. No existe en ellos una distinción entre cuerpo vegetativo y reproductivo.

Dentro del esquema de los cinco reinos de Wittaker y Margulis, los hongos pertenecen en parte al reino protista (los hongos ameboides y los hongos con zoosporas) y al reino Fungi (el resto). En el esquema de ocho reinos de Cavalier-Smith pertenecen en parte al reino Protozoa (los hongos ameboides), al reino Chromista (los Pseudofungi) y al reino Fungi todos los demás.. La diversidad de taxones englobada en el grupo está poco estudiada; se estima que existen unas 1,5 millones de especies, de las cuales apenas el 5 % han sido clasificadas. Durante los siglos XVIII y XIX, Carlos Linneo, Christiaan Hendrik Persoon, y Elias Magnus Fries clasificaron a los hongos de acuerdo a su morfología o fisiología. Actualmente, las técnicas de biología molecular han permitido el establecimiento de una taxonomía molecular basada en secuencias de ácido desoxirribonucleico (ADN), que divide al grupo en siete filos.

La especialidad de la biología que se ocupa de los hongos se llama micología, donde se emplea el sufijo "-mycota" para las divisiones y "-mycetes" para las clases.

El término «Fungi» es el plural de la palabra latina "fungus", empleado ya por el poeta Horacio y el naturalista Plinio el Viejo para nombrar a sus cuerpos fructíferos, que en castellano dio origen a la palabra «hongo» así como a la palabra "fungus" en inglés. En cambio, en otros idiomas la raíz es el vocablo de griego antiguo σφογγος (esponja), que hace referencia a las estructuras macroscópicas de mohos y setas; de esta han derivado los términos alemanes "Schwamm" (esponja), "Schimmel" (moho), el francés "champignon" y a través de este último el español «champiñón». La disciplina que estudia los hongos, la micología, deriva del griego "mykes"/μύκης (hongo) y "logos"/λόγος (discurso); se cree que fue creada por el naturalista inglés Miles Joseph Berkeley en su publicación de 1836 "The English Flora of Sir James Edward Smith, Vol. 5".

Antes del desarrollo de los análisis moleculares de ARN y su aplicación en la dilucidación de la filogenia del grupo, los taxónomos clasificaban a los hongos en el grupo de las plantas debido a la semejanza entre sus formas de vida (fundamentalmente, la ausencia de locomoción y una morfología semejante). Como ellas, los hongos crecen en el suelo y, en el caso de las setas, forman cuerpos fructíferos que en algunos casos guardan parecido con ejemplares de plantas, como los musgos. No obstante, los estudios filogenéticos indicaron que forman parte de un reino separado del de los animales y plantas, de los cuales se separó hace aproximadamente mil millones de años.

Algunas de las características morfológicas, bioquímicas y genéticas de los hongos son comunes a otros organismos; no obstante, otras son exclusivas, lo que permite su separación de otros seres vivos.

Como otros eucariotas, los hongos poseen células delimitadas por una membrana plasmática rica en esteroles y que contienen un núcleo que alberga el material genético en forma de cromosomas. Este material genético contiene genes y otros elementos codificantes así como elementos no codificantes, como los intrones. Poseen orgánulos celulares, como las mitocondrias y los ribosomas de tipo 80S. Como compuestos de reserva y glúcidos solubles poseen polialcoholes (p.e. el manitol), disacáridos (como la trehalosa) y polisacáridos (como el glucógeno, que, además, se encuentra presente en animales). Al igual que los animales, los hongos carecen de cloroplastos. Esto se debe a su carácter heterotrófico, que exige que obtengan como fuente de carbono, energía y poder reductor compuestos orgánicos.

A semejanza de las plantas, los hongos poseen pared celular y vacuolas. Se reproducen de forma sexual y asexual, y, como los helechos y musgos, producen esporas. Debido a su ciclo vital, poseen núcleos haploides habitualmente, al igual que los musgos y las algas.

Los hongos guardan parecido con euglenoides y bacterias. Todos ellos producen el aminoácido L-lisina mediante la vía de biosíntesis del ácido alfa-aminoadípico.

Las células de los hongos suelen poseer un aspecto filamentoso, siendo tubulares y alargadas. En su interior, es común que se encuentren varios núcleos; en sus extremos, zonas de crecimiento, se da una agregación de vesículas que contienen proteínas, lípidos y moléculas orgánicas llamadas Spitzenkörper. Hongos y oomicetos poseen un tipo de crecimiento basado en hifas. Este hecho es distintivo porque otros organismos filamentosos, las algas verdes, forman cadenas de células uninucleadas mediante procesos de división celular continuados.

Al igual que otras especies de bacterias, animales y plantas, más de sesenta especies de hongos son bioluminiscentes (es decir, que producen luz).

Los hongos se reproducen sobre todo por medio de esporas, las cuales se dispersan en un estado latente, que se interrumpe solo cuando se hallan condiciones favorables para su germinación. Cuando estas condiciones se dan, la espora germina, surgiendo de ella una primera hifa, por cuya extensión y ramificación se va constituyendo un micelio. La velocidad de crecimiento de las hifas de un hongo es verdaderamente espectacular: en un hongo tropical llega hasta los 5 mm por minuto. Se puede decir, sin exagerar, que incluso es posible ver crecer a algunos hongos en tiempo real.

Las esporas de los hongos se producen en esporangios, ya sea asexualmente o como resultado de un proceso de reproducción sexual. En este último caso la producción de esporas es precedida por la meiosis de las células, de la cual se originan las esporas mismas. Las esporas producidas a continuación de la meiosis se denominan meiosporas. Como la misma especie del hongo es capaz de reproducirse tanto asexual como sexualmente, las meiosporas tienen una capacidad de resistencia que les permite sobrevivir en las condiciones más adversas, mientras que las esporas producidas asexualmente cumplen sobre todo con el objetivo de propagar el hongo con la máxima rapidez y extensión posible.

El micelio vegetativo de los hongos, o sea el que no cumple con las funciones reproductivas, tiene un aspecto muy simple, porque no es más que un conjunto de hifas dispuestas sin orden. La fantasía creativa de los hongos se manifiesta solo en la construcción de cuerpos fructíferos, los cuales, como indica el nombre, sirven para portar los esporangios que producen las esporas.

Los hongos poseen una distribución cosmopolita y poseen un amplio rango de hábitats, que incluyen ambientes extremos como los desiertos, áreas de extremada salinidad.

Se han descrito unas 100 000 especies de hongos, aunque la diversidad global no ha sido totalmente catalogada por los taxónomos. Empleando como herramienta de análisis el ratio entre el número de especies de hongos respecto al de plantas en hábitats seleccionados, se ha realizado una estima de una diversidad total de 1.5 millones de especies. La micología ha empleado diversas características para configurar el concepto de especie. La clasificación morfológica, basada en aspectos como el tamaño y forma de las estructuras de fructificación y las esporas, ha sido predominante en la taxonomía tradicional. También se han empleado caracteres bioquímicos y fisiológicos, como la reacción ante determinados metabolitos. Se ha empleado la compatibilidad para la reproducción sexual mediante isogamia. Los métodos de taxonomía molecular, como el uso de marcadores moleculares y los análisis filogenéticos han permitido aumentar la discriminación entre variantes genéticas; esto ha aumentado la resolución a la hora de separar especies.


A los hongos se les trata desde la antigüedad como vegetales, por la inmovilidad y la presencia de pared celular, a pesar de que son heterótrofos. Esto significa que son incapaces de fijar carbono a través de la fotosíntesis, pero usan el carbono fijado por otros organismos para su metabolismo. Actualmente se sabe que los hongos son más cercanos al reino animal (Animalia) que al reino vegetal (Plantae), y se sitúan junto con los primeros en un taxón monofilético, dentro del grupo de los opistocontos.

Durante la mayor parte de la era paleozoica, los hongos al parecer fueron acuáticos. El primer hongo terrestre apareció, probablemente, en el período silúrico, justo después de la aparición de las primeras plantas terrestres, aunque sus fósiles son fragmentarios. Los hongos de mayor altura que se conocen se desarrollaron hace 350 millones de años, es decir, en el período devónico y correspondían a los llamados protaxites, que alcanzaban los 6 m de altura. Quizás la aparición, poco tiempo después, de los primeros árboles provocó por competencia evolutiva la desaparición de los hongos altos.

A diferencia de los animales, que ingieren el alimento, los hongos lo absorben, y sus células tienen pared celular. Debido a estas razones, estos organismos están situados en su propio reino biológico, llamado Fungi.

Los hongos forman un grupo monofilético, lo que significa que todas las variedades de hongos provienen de un ancestro común. El origen monofilético de los hongos se ha confirmado mediante múltiples experimentos de filogenética molecular; los rasgos ancestrales que comparten incluyen la pared celular quitinosa y la heterotrofia por absorción, así como otras características compartidas.

La taxonomía de los hongos está en un estado de rápida modificación, especialmente debido a artículos recientes basados en comparaciones de ADN, que a menudo traslocan las asunciones de los antiguos sistemas de clasificación. No hay un sistema único plenamente aceptado en los niveles taxonómicos más elevados y hay cambios de nombres constantes en cada nivel, desde el nivel de especie hacia arriba y, según el grupo, también a nivel de especie y niveles inferiores. Hay sitios en Internet como Index Fungorum, ITIS y que registran los nombres preferidos actualizados (con referencias cruzadas a sinónimos antiguos), pero no siempre concuerdan entre sí o con los nombres en la Wikipedia o en cada variante idiomática.

Pese al carácter monofilético o de un ancestro común, los hongos presentan una sorprendente variabilidad morfológica, dada no solo por el aspecto sino por las dimensiones y características. Así, son hongos los "prototaxites" de 6 m de altura, también lo son los mohos y levaduras, las setas (nombre que se da con precisión a los hongos macroscópicos comestibles que crecen sobre el suelo), las subterráneas trufas o los casi microscópicos, como el oidio o los de la tiña u otras micosis (ptiriasis), la roya, etcétera. La asociación simbiótica de hongos con algas da lugar a los líquenes.

Anteriormente se clasificaban como hongos todos los seres de aspecto fungoide y hábitos saprofíticos. Pero los estudios filogenéticos modernos separan al reino Fungi de los protistas o cromistas como Oomycota que en realidad no son verdaderos hongos, sino que sus adaptaciones hicieron confundirlos con ellos.

Uno de los sistemas actualizados (2015), simplifica y le da a los hongos cinco divisiones:

Esta clasificación reconoce como válidos los grupos parafiléticos, que en este caso son Chytridiomycota y Zygomycota .

El NCBI en cambio, utiliza grupos monofiléticos en su clasificación, por lo que de Chytridiomycota se ha escindido Chytridiomycota "sensu stricto", Neocallimastigomycota, Blastocladiomycota y Olpidiaceae; mientras que Zygomycota se divide en Entomophthoromycota, Kickxellomycotina, Mortierellomycotina, Mucoromycotina, Zoopagomycotina y Nephridiophagidae, definiéndose los siguientes grupos dentro de Fungi:


Las relaciones filogenéticas no está del todo consensuadas. El análisis genético de unas 200 especies (2006) y otros estudios, pero usando la nomenclatura moderna (2015), dio el siguiente resultado:

Fungi: Reino definido por la capacidad de sintetizar quitina. Se puede establecer supergrupos de acuerdo con su filogenia y grado evolutivo:

Opisthosporidia, no se considera comúnmente como parte de los hongos verdaderos (Eumycota) y se han clasificado como protistas, pues además de ser unicelulares se consideraba que carecían de la típica pared de quitina de los hongos, sin embargo, Microsporidia y los grupos relacionados, sí presentan quitina a nivel de las zoosporas o la pared celular, agrupándose estos microorganismos parásitos en el clado Opisthosporidia.

Eumycota es el grupo de los hongos verdaderos y se caracteriza por formar hifas. El ciclo de vida típico de Eumycota implica tres etapas: 1) el esporóforo produce y dispersa las esporas; 2) la espora germina y crece hasta formar el talo; 3) el talo finalmente fructifica y forma nuevamente esporóforos. Sexualmente el ciclo se puede resumir en: esporóforo (meiosis) → espora → talo → gametangio → cigoto → esporóforo. Históricamente Whittaker (1969) dividió a Eumycota en Opisthomastigomycota y Amastigomycota:

Por la belleza que guardan los hongos, muchos se han usado con un fin estético y ornamental, incluyéndoselos en ofrendas que, acompañados con flores y ramas, son ofrecidas en diversas ceremonias. En la actualidad todavía es fácil encontrar esta costumbre en algunos grupos étnicos de México, como son la náhuatl en la sierra de Puebla-Tlaxcala; los zapotecas en Oaxaca y los tzotziles y tojalabale en Chiapas. Los hongos que destacan entre los más empleados con este fin son los hongos psilocibios y la "Amanita muscaria"; esta última se ha convertido en el estereotipo de seta por lo altamente llamativa que es, ya que está compuesta por un talo blanco y una sombrilla (basidiocarpo) roja, moteada de color blanco.

Quizás el primer empleo directo que se les dio a los hongos es el de alimento. Mucho se ha discutido sobre el valor nutritivo de ellos, si bien es cierto a la mayoría se les puede considerar con elevada calidad porque contienen una buena proporción de proteínas y vitaminas y escasa cantidad de carbohidratos y lípidos.

Dentro de los hongos más consumidos tenemos a: "Boletus edulis", "Lactarius deliciosus", "Russula brevipes" y "Amanita caesarea". Otros hongos que se consumen notablemente son: "Agaricus campestris" y "A. bisporus", comúnmente conocidos como "champiñones" u "hongos de París"; la importancia de estos se debe a que son de las pocas especies que pueden cultivarse artificialmente y de manera industrial.

Los hongos microscópicos también han invertido directa o indirectamente para la creación de fuentes alimenticias y representan una expectativa de apoyo para el futuro; en este campo cabe citar los trabajos de obtención de biomasa, a partir de levaduras como "Candida utilis", que se usa para mejorar el alimento forrajero.

El crecimiento de diversos hongos incluidos sobre algunos alimentos también pueden elevar el nivel nutricional de estos; por ejemplo, en los estados mexicanos de Chiapas y Tabasco, se consume una bebida fermentada a base de maíz molido, que se le conoce popularmente con el nombre de "pozol" o atole agrio, hay estudios realizados que indican que al aumentar los días de fermentación de este, se incrementa la forma microbiológica, proporcionando principalmente sobre todo aminoácidos y proteínas.

Igualmente destaca hongos parásitos de diversas especies vegetales los cuales también son comestibles. Entre ellos podemos mencionar al "Ustilago maydis", conocido en México como "huitlacoche" o "cuitlacoche", una especie de hongo comestible parásito del maíz; o la "Cyttaria espinosae", conocido en Chile como " digüeñe" o "dihueñe", un hongo comestible y parásito estricto y específico del árbol "Nothofagus".

También se encuentra el ejemplo del hongo parásito"Cyttaria darwinii", cuyo micelio se encuentra dentro de ramas o troncos de lengas, guindos y ñires. como respuesta a la presencia del hongo, el árbol produce una multiplicación celular anormal o tumoración llamada nudo de lenga. la estrategia del árbol para defenderse del hongo no llega a eliminarlo, ya que periódicamente fructifica en esferas cuyo color varia desde el blanco al anaranjado llamadas pan de indio. Es un parásito débil ya que las ramas mueren poco a poco, pero el árbol se mantiene vivo por mucho tiempo. las fructificaciones del hongo aparecen en primavera y permanecen hasta su maduración en la próxima primavera. otro parásito similar es el Llao - Llao ("Cyttaria harioti"). aparentemente ambos eran consumidos por los Yamanas en grandes cantidades.

Los hongos enteógenos (con propiedades psicotrópicas) cobran particular importancia en Mesoamérica, debido a que se encuentran ampliamente distribuidos. Al igual que con los individuos del género "Claviceps", los hongos alucinógenos, también llamados hongos psilocibios, han sido utilizados últimamente por la industria farmacéutica para la extracción de productos con fines psicoterapéuticos (psilocibinas y psilocinas) y también algunas especies del género "Monera". Algunos hongos reportados como tóxicos son en realidad enteógenos.

Desde el descubrimiento por Fleming de la penicilina como un metabolito del mecanismo antagónico que tienen los hongos contra otros microorganismos, se ha desarrollado una gran industria para el descubrimiento, separación y comercialización de nuevos antibióticos. Entre los hongos medicinales más importantes destacan varias especies del género "Penicillium", como el "Penicillium notatum" y "Penicillium chrysogenicum", de los que se extrae la penicilina, "Ganoderma lucidum", "Trametes versicolor" (o "Coriolus v".), "Agaricus blazei", "Cordyceps sinensis" y "Grifola frondosa", entre muchos otros.

Los hongos contaminantes resultan un grave problema para el ser humano; dentro de las setas cabe mencionar las que parasitan y pudren la madera, como "Coniophara" o las comúnmente denominadas "orejas". Sin embargo, el mayor perjuicio se obtiene de los hongos microscópicos, sobresaliendo los mohos que pueden atacar y degradar tanto materiales como alimentos. Los hongos y mohos que parasitan materiales de construcción y alimentos producen sustancias que, en ciertas concentraciones, pueden resultar tóxicas para animales y el hombre.

En la naturaleza, solo ciertas variedades de hongos son comestibles, el resto son tóxicos por ingestión pudiendo causar severos daños multisistémicos e incluso la muerte. La Micología tiene estudios detallados sobre estas variedades de hongos. Especies como la "Amanita phalloides", "Cortinarius orellanus", "Amanita muscaria", "Chlorophyllum molybdites", "Galerina marginata" o la "Lepiota helveola" debido a sus enzimas tóxicas para el ser humano causan síntomas como: taquicardias, vómitos y cólicos dolorosos, sudor frío, exceso de sed y caídas bruscas de la presión arterial, excreciones sanguinolentas. La víctima contrae graves lesiones necróticas en todos los órganos especialmente en el hígado y el riñón. Estos daños son muchas veces irreparables y se requiere trasplante de órganos por lo general.

La identificación de las diferentes especies de hongos venenosos requiere el conocimiento visual de su morfología específica. No existe ninguna regla general válida para su reconocimiento.

Si bien muchos hongos son útiles, otros pueden infectar a plantas o animales, perturbando su equilibrio interno y enfermándolos. Los hongos parásitos causan graves enfermedades en plantas y animales. Unos cuantos causan enfermedades al ser humano.

Las royas se deben a un tipo de basidiomiceto que necesita dos plantas distintas para completar su ciclo de vida. El viento lleva a los trigales las esporas que la roya produce en el agracejo. Las esporas germinan en los trigales, infectan las plantas de trigo y producen otro tipo de espora que infecta al trigo, con lo que la enfermedad se propaga rápidamente. Ya avanzada la temporada de cosecha, la roya produce un nuevo tipo de espora negra y resistente, la cual sobrevive fácilmente al invierno. En la primavera, esta espora pasa por una fase sexual y reproduce esporas que infectan al agracejo, recomenzando nuevamente el ciclo. Por fortuna, una vez que los agrónomos entendieron el ciclo de vida de la roya, pudieron frenarla destruyendo los agracejos.

El cultivo de los hongos se llama micocultura, y se practica por su interés económico o científico. En el primer caso se trata por ejemplo de especies comestibles de géneros como "Agaricus" o "Pleurotus", o de especies saprotróficas que producen sustancias alopáticas (antibióticos) como la penicilina, producida por hongos del género "penicilium". Las levaduras son importantes en la producción de alimentos o bebidas fermentadas, especialmente las del género "Saccharomyces", y también como organismos modelo en la investigación biológica.

Los hongos generalmente se desarrollan mejor en la semi oscuridad y en ambientes húmedos.

Entre los hongos que son cultivados, se encuentran los hongos culinarios como por ejemplo el champiñón o las trufas y otras variedades. Es posible igualmente cultivar o dejar que prosperen mohos para su estudio en casa o en la escuela. un ejemplo de ello es el observar sobre el pan humedecido como crece pronto un micelio de "Rhizopus", que forma esporangios globosos y oscuros; y en la cáscara de los cítricos se desarrolla enseguida "Penicillium", con sus características esporas verdeazuladas.

Sin embargo, es recomendable hacer estos estudios bajo la supervisión de un micólogo o especialista debido a que hay hongos que son altamente peligrosos. En general como precaución, se debe evitar el inhalar cantidades altas de esporas de hongos; ya que aunque muchas veces no son directamente infecciosos, si pueden causar alergias.





</doc>
<doc id="1194" url="https://es.wikipedia.org/wiki?curid=1194" title="Filogenia">
Filogenia

La filogenia es la relación de parentesco entre especies o taxones en general. Aunque el término también aparece en lingüística histórica para referirse a la clasificación de las lenguas humanas según su origen común, el término se utiliza principalmente en su sentido biológico.

La "filogenética" es la parte de la biología evolutiva que se ocupa de determinar la filogenia, y consiste en el estudio de las relaciones evolutivas entre diferentes grupos de organismos a partir de la distribución de los caracteres primitivos y derivados en cada taxón, utilizando matrices de información de moléculas de ADN y de morfología. Con esta información se establecen los árboles filogenéticos, base de la clasificación filogenética. Esta clasificación forma parte de la sistemática, que además también comprende los sistemas de clasificación fenética y clásica o Linneana.

La necesidad de descubrir la historia evolutiva de los organismos se inició con la publicación de "El origen de las especies" por Darwin en 1859. La incorporación de teorías evolutivas en los sistemas de clasificación de los organismos es un proceso que hoy en día aún no está terminado (de Queiroz y Gauthier 1992). Un paso crítico en este proceso fue la adquisición de métodos explícitos para hipotetizar relaciones filogenéticas, ponerlas a prueba y verlas reflejadas en las clasificaciones, métodos para los que biólogos como Willi Hennig (entomólogo alemán, 1913-1976), Walter Zimmermann (botánico alemán, 1892-1980), Warren H. Wagner, Jr. (botánico norteamericano, 1920-2000) y muchos otros han hecho valiosos aportes.

El primer paso para reconstruir la filogenia de los organismos es determinar cuán parecidos son entre sí en su morfología, anatomía, embriología, moléculas de ADN, etcétera, ya que en última instancia estos parecidos son un indicador de su parecido genético, y por lo tanto de sus relaciones evolutivas.

En el cladograma, la especie 1 comparte con su ancestro todos los estados de los caracteres salvo el tallo, que es leñoso. La especie 2 comparte a su vez con su ancestro todos los caracteres salvo el color de los pétalos, que es rojo. Las dos especies comparten entre sí todos los caracteres salvo la leñosidad del tallo y el color de los pétalos. En este ejemplo, se han establecido 2 linajes: secuencias de poblaciones desde el ancestro hasta los descendientes.

En los inicios de la sistemática, los caracteres utilizados para comparar a los grupos entre sí eran conspicuos, principalmente morfológicos. A medida que se acumuló más conocimiento se empezó a tomar cada vez más cantidad de caracteres crípticos, como los anatómicos, embriológicos, serológicos, químicos y finalmente caracteres del cariotipo y los derivados del análisis del ADN. 

Los caracteres correspondientes al ancestro de un grupo de organismos que son retenidos por el grupo se dice que son plesiomórficos (ancestrales), mientras que los que fueron adquiridos exclusivamente por ese grupo (en el ejemplo, el tallo leñoso para la especie 1 o los pétalos rojos para la especie 2) se dice que son sinapomórficos o derivados ("nuevos"). Nótese que solo la presencia de sinapomorfías nos indica que se ha formado un nuevo linaje, nótese también que en árboles filogenéticos más extensos, como el siguiente:

el mismo carácter puede ser una sinapomorfía o una plesiomorfía, según desde qué porción del árbol se la observe. Por ejemplo, el tallo leñoso es una sinapomorfía de C (y de C+A+B) pero una plesiomorfía para A, ya que comparte ese estado del carácter con B a través de su ancestro común. Otra forma de decirlo es que el tallo leñoso es un carácter derivado desde el punto de vista de la población original, pero es ancestral para A y para B.

El aspecto del árbol filogenético (su topología) solo está dado por las conexiones entre sus nodos, y no por el orden en que son diagramados. Así, A+B]+C] es el mismo árbol que [C+[A+B. La topología tampoco está dada por la posición en que el árbol es dibujado, a veces se los dibuja erectos (con el ancestro abajo y los grupos terminales arriba), a veces se los dibuja recostados (con el ancestro a la izquierda y los grupos terminales a la derecha). Las dos formas de dibujarlos son igualmente válidas. En los árboles filogenéticos como los aquí expuestos, el largo de las ramas tampoco da ninguna información acerca de cuánto diverge ese linaje en términos de sus caracteres ni acerca de en qué momento geológico ocurrió el aislamiento de ese linaje (pero hay árboles que sí dan esa información).

Un grupo formado por un ancestro y todos sus descendientes se denomina monofilético, también llamado clado. Al grupo al que se le ha excluido alguno de sus descendientes se lo llama parafilético. Los grupos formados por los descendientes de más de un ancestro se denominan polifiléticos. 
Por ejemplo, se cree que las aves y los reptiles descienden de un único ancestro común, luego este grupo taxonómico (amarillo en el diagrama) es considerado monofilético. Los reptiles actuales como grupo también tienen un ancestro común a todos ellos, pero ese grupo (reptiles modernos) no incluye a todos los descendientes de tal ancestro porque se está dejando a las aves fuera (solo incluye los de color cian en el diagrama), un grupo así decimos que es parafilético. Un grupo que incluyera a los vertebrados de sangre caliente contendría solo a los mamíferos y las aves (rojo/naranja en el diagrama) y sería polifilético, porque entre los miembros de este agrupamiento no está el más reciente ancestro común de ellos. Los animales de sangre caliente son todos descendientes de un ancestro de sangre fría. La condición endotérmica ("sangre caliente") ha aparecido dos veces, independientemente, en el ancestro de los mamíferos, por un lado, y en el de las aves (y quizá algunos o todos los dinosaurios), por otro.

Algunos autores sostienen que la diferencia entre grupos parafiléticos y polifiléticos es sutil, y prefieren llamar a estos dos tipos de asemblajes como "no monofiléticos". Muchos taxones largamente reconocidos de plantas y animales resultaron ser no monofiléticos según los análisis de filogenia hechos en las últimas décadas, por lo que muchos científicos recomendaron abandonar su uso, ejemplos de estos taxones son Prokaryota, Protista, Pisces, Reptilia, Bryophyta, Pteridophyta, Dicotyledoneae, y varios otros más. Como su uso está muy extendido por haber sido tradicionalmente reconocidos, y porque muchos científicos consideran a los taxones parafiléticos válidos (discusión que aún no está terminada en el ambiente científico, el ejemplo más claro de un taxón que muchos desean conservar quizás sean los reptiles), a veces se indica el nombre del taxón, con la salvedad de que su nombre se pone entre comillas, para indicar que el taxón no se corresponde con un clado.

Las sinapomorfías que caracterizan a cada grupo monofilético son estados de los caracteres que se originaron en el ancestro común a todos los miembros del grupo, pero que no estaban presentes en los ancestros anteriores a estos, ancestros comunes tanto a los miembros del grupo como a otros grupos más. Hay que tener en cuenta que si bien una sinapomorfía es un estado del carácter que se hipotetiza que está presente en el ancestro del grupo, no necesariamente será encontrada en todos sus descendientes, debido a que la evolución puede modificarla y hasta revertirla a su estado anterior por azar (proceso que se conoce como reversión). Por lo tanto, no está garantizado que una lista de sinapomorfías vaya a encontrarse en todos los miembros de un grupo, y solo mediante un síndrome de caracteres podemos asegurarnos de que cada miembro pertenece a ese clado. El concepto de sinapomorfía fue formalizado por primera vez por Hennig (1966) y Wagner (1980). Mucho del análisis filogenético actual se basa en la búsqueda de sinapomorfías que permitan establecer grupos monofiléticos. En ese sentido, son revolucionarios los análisis moleculares de ADN que se están realizando desde hace algunos años, que entre otras técnicas determinan la secuencia de bases del mismo trozo de ADN en diferentes taxones, y comparan directamente sus secuencias de bases. En estos análisis, que se realizan con secuencias conservadas de genes concretos (como el ARNr), cada base es un carácter, y los posibles estados del carácter son las 4 posibles bases: adenina, timina, guanina y citosina. Si bien las sinapomorfías encontradas a través de los análisis moleculares de ADN son oscuras y no son útiles para identificar organismos en el campo o para plantear hipótesis acerca de la adaptación de los organismos a su ambiente, poseen ventajas (como la cantidad de caracteres medidos con poca cantidad de recursos, el establecimiento de caracteres menos subjetivos que los basados en fenotipos), que le otorgan a los análisis filogenéticos una precisión sin precedentes, obligando en muchas ocasiones a abandonar hipótesis evolutivas largamente reconocidas. Además, según la hipótesis del reloj molecular, la comparación de secuencias de ADN permite no solo determinar la distancia genética entre dos especies, sino además estimar el tiempo transcurrido desde el último antecesor común.

La regla para construir los árboles filogenéticos es el reconocimiento de grupos monofiléticos (clados) a partir de sus sinapomorfías (estados de los caracteres comunes al grupo). Esto es cierto para todos los nodos del árbol salvo el terminal, a nivel de las especies. No se puede establecer monofilia a nivel de las especies debido a que la naturaleza de las relaciones entre los organismos cambia por encima y por debajo del nivel de especie: por encima del nivel de especie, organismos de dos clados diferentes no pueden cruzarse entre sí y dar descendencia fértil, por lo que sus bagajes genéticos se mantienen sin mezclarse. Por debajo del nivel de especie, existe interfertilidad entre los organismos, por lo que el genoma de cada organismo es el resultado del cruce de dos genomas diferentes. Esta diferencia se puede esquematizar como un árbol ramificado para representar a todas las agrupaciones de organismos por encima del nivel de especie, pero en los organismos que pertenecen a la misma especie, las ramas del árbol se entrecruzan entre sí creando una red interconectada de organismos. Como muchas poblaciones del planeta están en diferentes etapas del proceso de especiación, y a veces se reconocen dos poblaciones diferentes como especies diferentes a pesar de ser algo interfértiles, entonces no es fácil determinar si un estado de un carácter es exclusivo de una de las especies o pertenece también en una baja proporción no muestreada a la otra especie, o si pertenecerá en algún momento debido a una hibridación casual, a la otra especie.




</doc>
<doc id="1195" url="https://es.wikipedia.org/wiki?curid=1195" title="Festuca">
Festuca

Festuca es un género de gramíneas (o poáceas) distribuidas en las regiones templadas y en montañas de regiones tropicales. Comprende aproximadamente unas 450 a 600 especies, muchas de las cuales se consideran excelentes forrajeras y se las cultiva para tal fin.
El género "Festuca" incluye a hierbas perennes, con hojas planas, convolutas o conduplicadas y espiguillas dispuestas en panojas.

Las espiguillas son pauci- o plurifloras, comprimidas lateralmente, con raquilla articulada por encima de las glumas y entre los antecios. Las glumas son lineal-lanceoladas o lanceoladas, agudas, desiguales, siendo menor la gluma inferior.
Las lemmas son lanceoladas u oblongo-lanceoladas, membranosas o papiráceas, redondeadas en el dorso, 5-nervadas, agudas, generalmente aristadas en el ápice. La lemma es bicarenada. Las flores son hermafroditas o bien, las superiores masculinas. Los estambres son 1 a 3, los estilos son cortos con estigmas plumosos. El cariopse es oblongo o lineal.. Varios hibridos son fertiles.

Aunque en agricultura algunas especies son consideradas malezas, por su gran capacidad de regeneración y su resistencia a desaparecer, son un forraje muy nutritivo para los herbívoros y se utilizan a estas especies para alimento de la fauna salvaje y el ganado doméstico y en programas de control para evitar la erosión de los suelos. 

Son gramíneas próximas a "Lolium" muy difundidas y capaces de adaptarse a los más diversos tipos de suelos y climas, muy resistentes al pisoteo, agresivas, invasivas y persistentes. Son plantas pioneras que sobreviven donde muchas especies leñosas no son capaces de hacerlo y constituyen en algunas áreas el único alimento disponible. Algunas especies están adaptadas a suelos áridos, calizos, arenosos, yesosos, salobres o tóxicos, con exceso de aluminio, cobre, mercurio y otros metales. En zonas apropiadas forman praderas densas. 

Su distribución es mundial, excepto en la Antártida.

El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 73–76. 1753. La especie tipo es: "Festuca ovina" L.
El nombre del género deriva del latín y significa "tallo o brizna de paja", también el nombre de una mala hierba entre la cebada. 

El número cromosómico básico del género es x = 7, con números cromosómicos somáticos de 2n = 14, 28, 35, 42, 56 y 70, ya que hay especies diploides y una serie poliploide. Cromosomas relativamente "grandes".

Se han descrito híbridos intergenéricos (notogéneros) entre "Festuca" con "Vulpia" (× "Festulpia" Melderis ex Stace & R.Cotton), con "Lolium" (× "Festulolium" Ascher & Graebn.) y con "Bromus" (× "Bromofestuca" Prodan)

Algunas especies son parasitadas por hongos endófitos como "Neotyphodium", "Acremonium" o "Claviceps", que se distribuyen por toda la planta excepto las raíces y que produce sustancias tóxicas alcaloides venenosas para el ganado, que en cantidad elevada producen la muerte, siendo también la causa de abortos y anomalías físicas como peso bajo, malformaciones o enanismo.





</doc>
<doc id="1196" url="https://es.wikipedia.org/wiki?curid=1196" title="Festival de la Isla de Wight">
Festival de la Isla de Wight

El Festival de la Isla de Wight es un festival de música que se organiza anualmente en la Isla de Wight de Reino Unido y cuya primera edición tuvo lugar en 1968. Las tres primeras ediciones tuvieron lugar entre 1968 y 1970, año en el que obtuvo su máxima asistencia. El evento no volvió a organizarse hasta 2002, cuando se trasladó a Seaclose Park. Desde 2002, el festival se organiza anualmente. 

El primer Festival de la Isla de Wight se celebró el 31 de agosto y el 1 de septiembre de 1968, organizado por la compañía Fiery Creations Ltd. de los hermanos Ron, Ray y Bill Foulk. La actuación principal corrió a cargo del grupo Jefferson Airplane. También actuaron Arthur Brown, The Move, Smile, T. Rex, Plastic Penny, Fairport Convention y The Pretty Things.

Segundo festival de la Isla de Wight, (el primero se celebró un año antes). Entre otros, actúa Dylan en Europa por primera vez en varios años.

Además de Dylan, acudieron al festival The Band, The Nice, The Pretty Things, Marsha Hunt, The Who, Third Ear Band, Bonzo Dog Doo-Dah Band, Fat Mattress, Joe Cocker. Esta edición del festival contó con la asistencia de celebridades como John Lennon, Richard Burton y Jane Fonda.

Entre el 26 y el 30 de agosto, cientos de miles de personas se reunieron en Afton Down para ver las actuaciones de Joan Baez, Jimi Hendrix, The Doors, Donovan, Sly Stone, John Sebastian (estos tres últimos muy habituales de este tipo de festivales), Ten Years After, Taste, Joni Mitchell, Miles Davis, Leonard Cohen, Melanie, Richie Havens, Supertramp, The Who, Tony Joe White, Emerson, Lake & Palmer, The Moody Blues y Jethro Tull.

Se llegó a decir que el número de espectadores de esta edición había alcanzado los 600 000, superando a Woodstock, aunque los promotores afirmaron que la cifra real era de la mitad. No obstante, la inesperada afluencia provocó la aprobación, en 1971, de la «Ley de la Isla de Wight», que prohíbe reuniones en la isla de más de 5000 personas sin un permiso especial.

Las dificultades de trasladar y alojar en la isla a un público tan numeroso, la oposición de los vecinos, así como las pérdidas financieras de esta edición significaron la suspensión del festival durante los años siguientes.
La banda emergente más importante que se presentó en la versión de 1970 fue EL&P

En el año 2002 se celebró su cuarta edición, el 3 de junio en Seaclose Park, a las afueras de Newport.

El festival se ha mantenido en los años sucesivos, con actuaciones, entre otras, de The Rolling Stones, Paul McCartney, Muse, Stereophonics, Donovan, Ray Davies, Robert Plant, David Bowie, Manic Street Preachers, The Who, R.E.M., Coldplay, The Proclaimers, Bryan Adams, The Police, Foo Fighters y Feeder.



</doc>
<doc id="1197" url="https://es.wikipedia.org/wiki?curid=1197" title="Folclore">
Folclore

El folclore, folclor o folklore (del inglés "folk", «pueblo» y "lore", «acervo», «saber» o «conocimiento») es el conjunto de artesanías, bailes, chistes, costumbres, cuentos, historias orales, leyendas, música, proverbios y supersticiones, común a una población concreta, incluyendo las tradiciones de dicha cultura, subcultura o grupo social. Además se suele llamar de la misma manera al estudio de estas materias. Sin embargo, hubo muchos desacuerdos referentes a qué contenía exactamente el folclore: algunos hablaban solo de cuentos, creencias y otros incluían también festividades y vida común. Según el investigador argentino Augusto Raúl Cortazar, todo hecho para ser considerado folklórico, debe ser anónimo, tradicional, vigente, de transmisión oral, popular, colectivo, funcional, empírico y regional.

El término inglés "folklore" fue usado por primera vez el 22 de agosto de 1846 por su creador, el arqueólogo británico William Thoms, quien deseaba crear una palabra para denominar lo que entonces se llamaba «antigüedades populares». 

La definición más ampliamente aceptada por los investigadores actuales de la especialidad es «la comunicación artística en grupos pequeños», propuesta por el investigador de la Universidad de Pensilvania Dan Ben Amos.

En 1960, la UNESCO designó el 22 de agosto de cada año como "Día Mundial del Folclore" como reconocimiento a Thoms.

Johann Gottfried Herder se dedica por primera vez a registrar y preservar deliberadamente el folclore para documentar el auténtico espíritu, tradición e identidad del pueblo germano. La creencia de que tal autenticidad pueda existir es uno de los principios del nacionalismo romántico que Herder desarrolló. Para Herder, las clases campesinas son al mismo tiempo depositarias, vehículo y guardianes del «genio popular», que se modeló mediante el contacto de los hombres con la tierra y el clima y se transmitió de generación en generación, tanto oralmente como en las epopeyas, cuentos y leyendas. En una visión universalista, Herder mantuvo que cada pueblo posee su «genio» único y singular, que aparece como fundamento por excelencia del renacimiento cultural que debía permitir reunificar a los pueblos germánicos. Se practica en países como Panamá, Colombia, Bolivia, Perú, etcétera. El "hecho folclórico" representado en la proyección, sea "genuino auténtico", es decir, fiel espejo de la cultura en que se nutre y conserva y conforme lo ejecuta la comunidad imitada.

Sobre los incentivos de Herder, los hermanos Grimm se comprometieron como pioneros con la enorme empresa de recopilar cuentos orales alemanes, para recuperar el carácter auténtico de una cultura nacional perdida por las élites. Así, en 1812 publicaron la primera serie de cuentos tradicionales como "Kinder- und Hausmärchen" (‘Historias infantiles y familiares’).

Rápidamente, la iniciativa de los hermanos Grimm fue imitada en toda Europa (del Este y el Oeste) y en los países escandinavos. A partir del siglo XIX se emprende la labor de educar al pueblo en su propio folclore, que aparece amenazado de desaparición bajo los efectos de la modernidad y la urbanización. Las campañas de difusión del folclore toman la forma de verdadera propaganda nacionalista, procurando esencialmente hacer resaltar la originalidad y singularidad propia del folclore de cada pueblo, permitiendo distinguirlo de los vecinos y vincularlo a los que, en el contexto de instauración de las identidades nacionales, se designa como sus antepasados.

En primera instancia el folclore se limitó a la tradición oral. Hacia la mitad del siglo XIX se amplía el ámbito del folclore, comenzando los recopiladores a interesarse también por distintas producciones que emanan de las culturas populares (creencias, medicina tradicional, trajes, artes, técnicas, etcétera).

No fue hasta el siglo XX cuando los etnógrafos empezaron a intentar registrar el folclore sin manifestar metas políticas.

Aunque el folclore puede contener elementos religiosos y mitológicos, se preocupa también con tradiciones a veces mundanas de la vida cotidiana.Se relaciona con frecuencia lo práctico y lo esotérico en un mismo bloque narrativo. Ha sido a menudo confundido con la mitología, y viceversa, porque se ha asumido que cualquier historia figurativa que no pertenezca a las creencias dominantes de la época no tiene el mismo estatus que dichas creencias dominantes. Así, la religión romana es calificada de «mitología» por los cristianos. De esa forma, tanto la mitología como el folclore se han convertido en términos clasificatorios para todos los relatos figurativos que no se corresponden con la estructura de creencias dominante.

A veces el folclore es de naturaleza religiosa, como las historias del "Mabinogion" galés o las de la poesía escáldica islandesa. Muchos de los relatos de "La leyenda dorada" de Santiago de la Vorágine también plasman elementos folclóricos en un contexto cristiano: ejemplos de dicha mitología cristiana son los temas desarrollados en torno a San Jorge o San Cristóbal. En este caso, el término «folclore» se usa en un sentido peyorativo, es decir, mientras las historias del trotamundos Odín tienen un valor religioso para los nórdicos que compusieron las historias, debido a que no encajan en las creencias cristianas no son consideradas «religiosas» sino «folclóricas» por los cristianos.

Los cuentos populares son un término general para diversas variedades de la narrativa tradicional. La narración de historias parece ser un elemento universal cultural, común por igual a las sociedades básicas y las complejas. Incluso las formas que adoptan las historias populares son ciertamente parecidas de una cultura a otra, y los estudios comparativos de temas y formas narrativas han tenido éxito al demostrar estas relaciones.

Por otra parte, el folclore puede usarse para describir precisamente una narrativa figurada, que no tiene contenido sagrado o religioso alguno. Desde el punto de vista jungiano, que no es más que un método de análisis, puede en su lugar corresponder a patrones psicológicos inconscientes, instintos o arquetipos de la mente. Este saber puede o no tener componentes fantásticos (tales como magia, seres etéreos o personificaciones de objetos inanimados). Estas historias populares pueden surgir de una tradición religiosa, pero habla de asuntos psicológicos profundos. El folclore familiar, como "Hansel y Gretel", es un ejemplo de esta sutil línea.

El propósito manifiesto del cuento puede ser primordialmente una enseñanza mundana sobre la seguridad en el bosque o secundariamente un cuento cautelar sobre los peligros del hambre en las familias grandes, pero su significado latente puede evocar una fuerte respuesta emocional debido a los ampliamente comprendidos temas y motivos, tales como «la madre terrible», «la muerte» y «la expiación con el padre». Puede haber un alcance tanto moral como psicológico en la obra, así como un valor lúdico, dependiendo de la naturaleza del narrador, el estilo de la historia, la edad media de la audiencia y el contexto general de la actuación. Los folcloristas se suelen resistir a las interpretaciones universales de los relatos y, donde sea posible, analizan las versiones orales de historias en contextos específicos, más que en fuentes impresas, que a menudo muestran el efecto del sesgo del escritor o editor.

Los relatos contemporáneos comunes en Occidente incluyen la leyenda urbana. Hay muchas formas de folclore que son tan comunes pero que, sin embargo, la mayoría de la gente no advierte que son folclore, tales como acertijos, rimas infantiles y cuentos de fantasmas, rumores (incluyendo teorías conspirativas), chismes, estereotipos étnicos, costumbres festivas y ritos del ciclo vital (bautizos, funerales, etcétera). Los relatos de abducciones por ovnis pueden ser consideradas, en un cierto sentido, como actualizaciones de los cuentos de la Europa precristiana o incluso de historias de la Biblia tales como la ascensión al cielo de Elías. Adrienne Mayor, al presentar una bibliografía sobre este tema, señaló que la mayoría de los folcloristas modernos desconocen en gran medida los paralelos y precedentes clásicos, en materiales que están solo parcialmente representados por la familiar etiqueta de "esópicos": 

Todo hecho cultural es un hecho social, por tanto si estudiamos el grupo humano necesariamente debemos conocer el medio social que nos rodea y las características que posee cada sociedad en cada época por lo tanto la cultura en lo resultante del trabajo humano con el conocimiento de la actividad laboral y de la fabricación de los primeros instrumentos musicales, se inició la sociedad humana.



</doc>
<doc id="1198" url="https://es.wikipedia.org/wiki?curid=1198" title="Fortran">
Fortran

Fortran (previamente FORTRAN,
contracción del inglés "The IBM Mathematical Formula Translating System") es un lenguaje de programación de alto nivel de propósito general, procedimental e imperativo, que está especialmente adaptado al cálculo numérico y a la computación científica. Desarrollado originalmente por IBM en 1957 para el equipo IBM 704, y usado para aplicaciones científicas y de ingeniería, el FORTRAN vino a dominar esta área de la programación desde el principio y ha estado en uso continuo por más de medio siglo en áreas de cómputo intensivo tales como la predicción numérica del tiempo, análisis de elementos finitos, dinámica de fluidos computacional (CFD), física computacional y química computacional. Es uno de los lenguajes más populares en el área de la computación de alto rendimiento y es el lenguaje usado para programas que evalúan el desempeño (benchmark) y el ranking de los supercomputadores más rápidos del mundo.

El FORTRAN abarca un linaje de versiones, cada una de las cuales evolucionó para añadir extensiones al lenguaje mientras que usualmente retenía compatibilidad con las versiones previas. Versiones sucesivas han añadido soporte para procesamiento de datos basados en caracteres (FORTRAN 77), programación de arreglos, programación modular y programación orientada a objetos (Fortran 90/95), y programación genérica (Fortran 2003).

A finales de 1953, John W. Backus sometió una propuesta a sus superiores en IBM para desarrollar una alternativa más práctica al lenguaje ensamblador para programar el computador central IBM 704. El histórico equipo FORTRAN de Backus consistió en los programadores Richard Goldberg, Sheldon F. Best, Harlan Herrick, Peter Sheridan, Roy Nutt, Robert Nelson, Irving Ziller, Lois Haibt y David Sayre.

A mediados de 1954 fue terminada una especificación del borrador para el "IBM Mathematical Formula Translating System". El primer manual de FORTRAN apareció en octubre de 1956, porque los clientes eran reacios a usar un lenguaje de programación de alto nivel a menos que su compilador pudiera generar código cuyo desempeño fuera comparable al de un código hecho a mano en lenguaje ensamblador.

Mientras que la comunidad era escéptica en que este nuevo lenguaje, este redujo en 20 veces el número de sentencias de programación necesarias para operar una máquina, y rápidamente ganó aceptación. Durante una entrevista en 1979 con Think, la revista de los empleados de IBM, el creador John Backus, dijo: "Mucho de mi trabajo surgió por ser perezoso. No me gustaba escribir programas y por eso, cuando estaba trabajando en el IBM 701 escribiendo programas para computar trayectorias de misiles, comencé a trabajar en un sistema de programación para hacer más fácil escribir programas".

El lenguaje fue ampliamente adoptado por los científicos para escribir programas numéricamente intensivos, que incentivó a los escritores de compiladores a producir compiladores que pudieran generar un código más rápido y más eficiente. La inclusión en el lenguaje de un tipo de datos y de la aritmética de números complejos amplió la gama de aplicaciones para las cuales el lenguaje se adaptaba especialmente e hizo al FORTRAN especialmente adecuado para aplicaciones técnicas tales como la ingeniería eléctrica.

Hacia 1960, las versiones de FORTRAN estaban disponibles para los computadores IBM 709, 650, 1620, y 7090. La cada vez mayor popularidad del FORTRAN estimuló significativamente a fabricantes de computadores de la competencia a proporcionar compiladores FORTRAN para sus máquinas, así que allá por 1963 existían más de 40 compiladores FORTRAN. Por estas razones, el FORTRAN es considerado el primer lenguaje de programación ampliamente usado soportado a través de una variedad de arquitecturas de computador.

El desarrollo del FORTRAN fue paralelo a la temprana evolución de la tecnología del compilador. De hecho, muchos avances en la teoría y el diseño de compiladores fueron motivados específicamente por la necesidad de generar código eficiente para los programas en FORTRAN.

Algunas otras versiones subsiguientes fueron:

El lenguaje fue diseñado teniendo en cuenta que los programas serían escritos en tarjetas perforadas de 80 columnas. Así por ejemplo, las líneas debían ser numeradas y la única alteración posible en el orden de ejecución era producida con la instrucción "goto". Estas características han evolucionado de versión en versión. Las actuales contienen subprogramas, recursión y una variada gama de [[estructuras de control]

Como fue una primera tentativa de creación de un lenguaje de programación de alto nivel, tiene una sintaxis considerada arcaica por muchos programadores que aprenden lenguajes más modernos. Es difícil escribir un bucle "for", y errores en la escritura de un solo carácter pueden llevar a errores durante el tiempo de ejecución en vez de errores de compilación, en el caso de que no se usen las construcciones más frecuentes. Algunas de las primeras versiones no poseían facilidades que son consideradas muy útiles, tal como la asignación dinámica de memoria.

Se debe tener en cuenta que la sintaxis de Fortran fue orientada para el uso en trabajos numéricos y científicos. Muchas de sus deficiencias han sido abordadas en revisiones recientes del lenguaje. Por ejemplo, Fortran 95 posee comandos mucho más breves para efectuar operaciones matemáticas con matrices y dispone de tipos. Esto no solo mejora mucho la lectura del programa sino que además aporta información útil al compilador.

Por estas razones Fortran prácticamente no se usa fuera de los campos científicos y del análisis numérico, pero permanece como el lenguaje preferido para desarrollar aplicaciones de computación numérica de alto rendimiento.

Existen dos versiones normalizadas del lenguaje.

A continuación se muestra el código fuente en lenguaje Fortran de un programa que permite realizar un ajuste o regresión lineal de una serie de datos:

Básicamente, en el programa se lee desde un archivo [[ASCII]] cierta cantidad de pares ordenados, se convoca a una rutina que calcula la recta de ajuste correspondiente, usando el método de [[mínimos cuadrados]], para luego retornar aportando los coeficientes o parámetros de la recta en cuestión.



[[Categoría:Lenguajes de programación por procedimientos]]
[[Categoría:Lenguajes de programación de IBM]]
[[Categoría:Lenguajes compilados]]
[[Categoría:Acrónimos de informática]]
[[Categoría:Estándares informáticos]]
[[Categoría:Software de 1957]]

</doc>
<doc id="1200" url="https://es.wikipedia.org/wiki?curid=1200" title="Fuego">
Fuego

Se llama fuego al conjunto de partículas o moléculas incandescentes de materia combustible, capaces de emitir calor y luz visible, producto de una reacción química de oxidación violenta. Las llamas son las partes del fuego que emiten luz visible, mientras que el humo son físicamente las mismas pero que ya no la emiten. 

Coloquialmente se le conoce también como lumbre o candela en algunos países.

Esta fuerte reacción química de oxidación es un proceso exotérmico, lo que quiere decir que, al mismo tiempo, desprende energía en forma de calor al aire de su alrededor. El aire que se encuentra alrededor de las moléculas o partículas calientes disminuye la densidad y tiende a flotar sobre el aire más frío (convección). En el caso particular del fuego de estado sólido, el aire caliente viaja hacia arriba a tal velocidad que empuja aún partículas pesadas de combustible en la misma dirección (aún calientes y brillantes), las cuales van bajando de temperatura al igual que el aire circundante, dejando de brillar y tornándose generalmente de un color negro como el carbón; el aire, al enfriarse, empieza a bajar de velocidad, a tal punto que ya no puede empujar las partículas para arriba y estas empiezan (si pesan más que el aire) a levitar sin subir, para luego caer de nuevo a tierra.

En la antigüedad clásica el fuego fue uno de los cuatro elementos clásicos, junto con el agua, la tierra y el aire. Estos cuatro elementos representaban las cuatro formas conocidas de la materia y eran utilizados para explicar diferentes comportamientos de la naturaleza. En la cultura occidental el origen de la teoría de los cuatro elementos se encuentra en los filósofos presocráticos de la Grecia clásica, y desde entonces ha sido objeto de numerosas obras de expresión artística y filosófica, perdurando durante la Edad Media y el Renacimiento e influyendo profundamente en el pensamiento y la cultura europeos. Paralelamente, el hinduismo y el budismo habían desarrollado concepciones muy parecidas.

En la mayoría de estas escuelas de pensamiento se suele añadir un quinto elemento a los cuatro tradicionales, que se denomina, alternativamente, idea, vacío, éter o quintaesencia (literalmente "la quinta esencia").

El concepto de los elementos clásicos continuó vigente en Europa durante la Edad Media, debido a la preeminencia de la visión cosmológica aristotélica y a la aprobación de la Iglesia católica del concepto del éter que apoyaba la concepción de la vida terrenal como un estado imperfecto y el paraíso como algo eterno.

El uso de los cuatro elementos en la ciencia se abandonó en los siglos XVI y XVII, cuando los nuevos descubrimientos sobre los estados de la materia superaron, la concepción clásica.

En el siglo XVII, Johann Joachim Becher propuso una versión particular de la teoría de los cuatro elementos: el papel fundamental estaba reservado a la tierra y al agua, mientras que el fuego y el aire eran considerados como simples agentes de las transformaciones. Todos los cuerpos, tanto animales como vegetales y minerales, estaban formados según Becher por mezclas de agua y tierra. Defendió también que los verdaderos elementos de los cuerpos debían ser investigados mediante el análisis, y, en coherencia, propuso una clasificación basada en un orden creciente de composición.
Becher sostenía que los componentes inmediatos de los cuerpos minerales eran tres tipos diferentes de tierras, cada una de ellas portadora de una propiedad: el aspecto vítreo, el carácter combustible y la fluidez o volatilidad. La tierra, que denominó "terra pinguis", se consideraba portadora del principio de la inflamabilidad. Su nombre podría traducirse como "tierra grasa" o "tierra oleaginosa", que en la alquimia se conoce con el nombre de azufre, aunque Becher empleó también otras expresiones para designarla; entre ellas, "azufre flogisto" (este sustantivo derivado del griego "phlogistos", que significa "inflamable"). Finalmente fue la palabra flogisto la que acabó imponiéndose, gracias sobre todo a la labor del más efectivo defensor de sus ideas, Georg Ernst Stahl.

La teoría del flogisto se mantuvo hasta los años ochenta del siglo XVIII, cuando Antoine Laurent Lavoisier, considerado el padre de la química moderna, diseñó un experimento para contrastarla. Lavoisier colocó una pequeña cantidad de mercurio sobre un sólido flotando sobre agua, lo cerró bajo una campana de vidrio y provocó la combustión del mercurio. Según la teoría del flogisto, el cuerpo flotante debería estar menos sumergido tras la combustión, ya que la cantidad restante de sustancia junto a la ceniza debería pesar menos que la inicial y el volumen de aire dentro de la campana debería aumentar como efecto de la asimilación del flogisto, y con ello el nivel de líquido cerrado debería ser más bajo que al comienzo. El resultado del experimento contradijo los resultados esperados según esta teoría. Lavoisier interpretó correctamente la combustión, eliminado el flogisto en su explicación. Las sustancias que arden se combinan con el oxígeno del aire, por lo que ganan peso. El aire que está en contacto con la sustancia que se quema pierde oxígeno y, por tanto, también volumen.

Con Lavoisier los químicos abandonaron progresivamente la teoría del flogisto y se apuntaron a la teoría de la combustión basada en el oxígeno.

Desde que el humano comenzó a dominar el fuego, se presentó un problema importante: encenderlo. De ahí que las religiones se convirtieran en las guardianas del fuego: mantener un fuego permanente era importante por si los fuegos domésticos se apagaban, y de ahí que todas las religiones, todavía ahora, mantengan un fuego encendido en el santuario.

El culto del fuego siguió al que se tributaba al Sol y casi todos los pueblos lo adoraron como el más noble de los elementos y como una viva imagen del astro del día. Los caldeos lo tenían por una deidad suprema. Sin embargo, en Persia es donde se extendió su culto casi exclusivamente. Se encontraban por todas partes cercados cerrados con muros y sin techo, dentro los cuales, se encendía asiduamente el fuego en donde el pueblo devoto venía a ciertas horas para rogarle. Los grandes señores se arruinaban arrojando en él esencias preciosas y flores odoríferas, privilegio que miraban como uno de los mejores derechos de la nobleza. Estos templos descubiertos fueron conocidos de los griegos con el nombre de "Pyreia" (Πυραία) o "Pyrateia" (Πυραταία). Los viajeros modernos hablan también de ellos como de los más antiguos monumentos del culto del fuego. Cuando un rey de Persia estaba agonizando, se apagaba el fuego en las principales ciudades del reino y no se volvía a encender hasta después de la coronación de su sucesor. Estos pueblos se imaginaban que el fuego había sido traído del cielo y puesto sobre el altar del primer templo que Zoroastro había mandado edificar en la ciudad de Xis, en la Media. Estaba prohibido arrojar a él nada que no fuese puro, llegando a tal punto la superstición que nadie osaba mirarlo atentamente. En fin para más imponer, los sacerdotes lo conservaban secretamente y hacían creer al pueblo que era inalterable y se alimentaba de sí mismo. Hyde ha creído que este culto tenía por único objeto representar al Ser Supremo.

Sea lo que fuere, esta costumbre pasó a Grecia. Ardía aun el sagrado fuego en los templos de Apolo en Atenas y en Delfos, en el de Ceres en Mautíuaa, en el de Minerva en el de Júpiter Ammon y en las pritaneas de todas las ciudades griegas, donde ardían continuamente las lámparas cuidando muy particularmente que no se apagasen. Los romanos, imitadores de los griegos, adoptaron este culto y Numa fundó un colegio de vestales, cuyas funciones consistían en conservar el fuego sagrado. Esta religión subsistió entre los guebros o parsos, como también en muchos pueblos de América, entre otros, en Virginia. Cuando estos pueblos volvían de alguna expedición militar o habían salido felizmente de un peligro inminente, encendían un gran fuego y atestiguan su alegría danzando a su alrededor con una calabaza o campanilla en la mano, como dando gracias a este elemento por haberles salvado la vida.

Jamás empezaban sus comidas sin haber arrojado antes al fuego el primer bocado a modo de una ofrenda y todas las tardes los encendían cantando y danzando a su alrededor.

El fuego es igualmente una de las principales divinidades de los tártaros. No permiten acercar a su territorio a ningún extranjero sin que antes se haya purificado pasando por entre dos hogueras. Evitan con gran cuidado meter en el fuego un cuchillo o siquiera tocarlo con este instrumento. Sería un crimen mayor astillar la madera con hacha cerca las llamas. Antes de beber tienen la costumbre de volverse hacia al medio día, que es el lado que, según ellos, corresponda el fuego, en honor del cual edifican también sus cabañas con la puerta mirando hacia esa parte. Se construía expresamente una cabaña en el lugar en que estaba acampado el emperador de Monomotapa, en la cual se encendía un fuego que se conservaba con un cuidado religioso.

Los antiguos africanos tributaban los honores divinos o este elemento y mantenían en sus templos un fuego eterno.

Los yakouts, población de Siberia, creen que existe en el fuego un ser, a quien atribuyen el poder de dispensar los bienes y los males y le ofrecen sacrificios perpetuos. Los indios vecinos de las orillas de Columbia miraban el fuego como un ser poderoso y terrible. Le ofrecían constantemente sacrificios y le suponían igualmente árbitro del bien y del mal. Buscaban su apoyo porque solo él podía interceder con su protector alado y procurarles todo lo que deseaban como hijos varones, esto es, una pesca y una caza abundante, en una palabra todo lo que a su modo de ver constituía la riqueza y el bienestar.

Los chinos que habitan los confines de Siberia reconocen un dios del fuego. Durante la residencia de M. Pailas en Maiinatschiu, se pegó el en la población; las llamas devoraban muchas casas y sin embargo, ningún habitante procuraba atajarlo. Todos permanecían alrededor del incendio en una consternación inactiva; algunos arrojaban tan solo por intervalos gotas de agua en él para apaciguar al dios, que decían, había escogido sus habitaciones por un sacrificio. Si los rusos no hubiesen extinguido el incendio, toda la ciudad habría quedado reducida a cenizas.

Este elemento tuvo altares, sacerdotes y sacrificios en muchísimas comunidades del planeta. Los romanos lo representaban bajo la figura de Vulcano en medio de los cíclopes. Una vestal cerca de un altar sobre el cual arde el fuego sagrado o una mujer teniendo un vaso lleno de él con una salamandra a sus pies son también símbolos por medio de los cuales los antiguos representaban el fuego. Cesare Ripa y Gravelot han juntado a estos emblemas la presencia del Sol, principio del calor y de la luz, y el fénix, que muere y renace en este elemento, expresión simbólica que, en opinión de los filósofos, creían que el mundo sería consumido algún día por las llamas para renacer más brillante y perfecto.

La masonería también incluye el fuego entre sus símbolos: es uno de los cuatro elementos que, al igual que en las culturas de la Antigüedad, son presencia permanente en el lenguaje y en los trabajos de las logias. La masonería toma el significado simbólico antiguo del fuego y reconoce su doble naturaleza: creación e iluminación, por un lado, y destrucción y purificación, por el otro.

El fuego conlleva un conjunto de peligros, el primero y más evidente son las quemaduras. También otros como la intoxicación por inhalación de humo. 

En el apartado de psicología está la piromanía, que se define como una enfermedad en la que una persona siente la necesidad de quemar algo y cuanto más grande sea el fuego mejor (para él). Esto ha provocado incendios forestales intencionales.



</doc>
<doc id="1201" url="https://es.wikipedia.org/wiki?curid=1201" title="Frank Herbert">
Frank Herbert

Frank Patrick Herbert (Tacoma, Estados Unidos; 8 de octubre de 1920 - Madison, "ibídem"; 11 de febrero de 1986) fue un escritor estadounidense de ciencia ficción, conocido principalmente por la serie de libros de Las crónicas de Dune.

Nació en Tacoma, Washington. Trabajó en múltiples trabajos como fotógrafo, cámara de televisión, presentador de radio, incluso de pescador de ostras o analista. En 1965 presenta Dune con gran éxito de público y crítica, consigue el premio Hugo y el premio Nébula además del premio Internacional de Fantasía (junto con la novela: El señor de las moscas). Después ampliaría esta novela con otras cinco más hasta su muerte, continuando otros escritores con otros títulos pero con la misma referencia.

Gran parte de su obra refleja su interés por la ecología y la psicología. En sus últimos veinte años y junto con su familia residieron en una «granja biológica», primero cerca de Washington y más tarde en Hawái, viviendo de forma autosuficiente y en pleno contacto con la naturaleza.

Es una de las novelas más vendidas del mundo, popularizó en la ciencia ficción el tema de la ecología. En esta novela además se habla de la supervivencia de la especie humana, su evolución, las interacciones entre el poder, la religión y la política.

La novela se desarrolla en un futuro lejano sobre un planeta árido, Arrakis o Dune, muy importante por proporcionar la especia Melange, eje fundamental del Imperio Galáctico. En este escenario, un adolescente perteneciente a una de las castas de la nobleza, Paul Atreides, está destinado a convertirse en el mesías, dictador y mártir del pueblo del desierto, los Fremen.


En colaboración con Bill Ransom publicó:


En colaboración con Brian Herbert publicó "El hombre de dos mundos" (1986)

Además, Las crónicas de Dune se completaron con dos novelas escritas por Brian Herbert y Kevin J. Anderson elaboradas a partir de notas dejadas por Frank Herbert en una caja de depósito que tuvo que ser abierta con taladro, y que solo fueron encontradas hasta después de su muerte:



"Ediciones Debolsillo" ha editado la "Saga completa de Dune", de la que solo los seis primeros volúmenes corresponden a Frank Herbert:



</doc>
<doc id="1202" url="https://es.wikipedia.org/wiki?curid=1202" title="Febrero">
Febrero

Febrero es el segundo mes del año en el calendario gregoriano. Tiene 28 días y 29 en los años bisiestos. En muy raras ocasiones ha habido un 30 de febrero, producido bien en la conversión del calendario juliano al gregoriano, o bien en la adopción de un calendario revolucionario en el que todos los meses tenían 30 días.

Fue llamado así en honor a las februa en las Lupercales, el festival de la purificación en la Antigua Roma: los sabinos celebraban una fiesta anual de purificación que llamaban februa (de "februum", una especie de correa), en una fecha que hoy se identifica como el 15 de febrero. Tras la fundación de Roma y el posterior surgimiento del Imperio Romano, la urbe dominante tomó prestado el nombre de las fiestas 'februas' para designar el mes en que estas tenían lugar, que por entonces era el último del año.

Es el mes que menos días posee del año.

Entre los romanos este mes estaba bajo la protección de Neptuno. Lo representaban bajo la imagen de una mujer vestida de azul, con la túnica levantada y sujetada con un cinturón. Llevaba un ave acuática entre las manos y traía sobre su cabeza una urna de la cual salía agua en abundancia, para indicar que es el mes de las lluvias; lo que también significaba la garza real y el pescado que ponían a sus pies. 

Cl. Andran lo alegoriza del siguiente modo: el dios de las aguas con su tridente en la mano, está en pie sobre una gruta formada de cascadas, llena de redes y otros instrumentos de pescar y de peces, signo de este mes. Cerca de todo se ven los caballos de Neptuno y más lejos una nave con sus aparejos. Los adornos son una mezcla de aves marinas, peces, corales y toda especie de ricas conchas.




</doc>
<doc id="1205" url="https://es.wikipedia.org/wiki?curid=1205" title="Fermio">
Fermio

El fermio es un elemento químico radiactivo creado artificialmente cuyo número atómico es 100 y de peso atómico 254, de símbolo Fm. Existen 16 isótopos conocidos siendo el Fm el más estable con un periodo de semidesintegración de 100,5 días. El fermio es uno de los elementos transuránicos del grupo de los actínidos del sistema periódico. El elemento fue aislado en 1952, a partir de los restos de una explosión de bomba de hidrógeno, por el químico estadounidense Albert Ghiorso y sus colegas. Más tarde el fermio fue preparado sintéticamente en un reactor nuclear bombardeando plutonio con neutrones, y en un ciclotrón bombardeando uranio 238 con iones de nitrógeno. Se han obtenido isótopos con números másicos desde 242 a 259; el fermio 257, que es el que tiene una vida más larga, tiene una vida media de 80 días. Al elemento se le dio el nombre de fermio en 1955, en honor al físico nuclear estadounidense de origen italiano Enrico Fermi. El fermio no tiene aplicaciones industriales.

Fue descubierto en 1954, y era llamado Centurio y su símbolo era Ct. Actualmente su antiguo nombre y símbolo ya no se utilizan.

El fermio no se encuentra en la naturaleza; su descubrimiento y producción se alcanza por transmutación nuclear artificial de elementos más ligeros. Se han descubierto los isótopos radiactivos de número de masa 244-259. El peso total del fermio que ha sido sintetizado es mucho menor de una millonésima de gramo.

La fisión espontánea es el modo principal de decaimiento para Fm, Fm y Fm. El isótopo con vida más larga es Fm, el cual tiene una vida media de unos 100 días. El fermio -258 decae por fisión espontánea y tiene una vida media de 0.38 milisegundos. Esto sugiere la existencia de una anormalidad en este punto en la tabla periódica.


</doc>
<doc id="1206" url="https://es.wikipedia.org/wiki?curid=1206" title="Corrección de errores hacia adelante">
Corrección de errores hacia adelante

La corrección de errores hacia adelante (en inglés, Forward Error Correction o FEC) es un tipo de mecanismo de corrección de errores que permite su corrección en el receptor sin retransmisión de la información original. Se utiliza en sistemas sin retorno o sistemas en tiempo real donde no se puede esperar a la retransmisión para mostrar los datos. Este mecanismo de corrección de errores se utiliza por ejemplo, en las comunicaciones vía satélite, en las grabadoras de DVD y CD o en las emisiones de TDT para terminales móviles (estándar DVB-H).

La posibilidad de corregir errores se consigue añadiendo al mensaje original unos bits de redundancia. La fuente digital envía la secuencia de datos al codificador, encargado de añadir dichos bits de redundancia. A la salida del codificador obtenemos la denominada palabra código. Esta palabra código es enviada al receptor y éste, mediante el decodificador adecuado y aplicando los algoritmos de corrección de errores, obtendrá la secuencia de datos original. Los dos principales tipos de codificación usados son:


FEC reduce el número de transmisiones de errores, así como los requisitos de potencia de los sistemas de comunicación e incrementa la efectividad de los mismos evitando la necesidad del reenvío de los mensajes dañados durante la recepción.

En general incluir un número mayor de bits de redundancia supone una mayor capacidad para corregir errores. Sin embargo, este hecho reduce notablemente el régimen binario de transmisión, y aumenta el retardo en la recepción del mensaje


</doc>
<doc id="1207" url="https://es.wikipedia.org/wiki?curid=1207" title="Fisiología">
Fisiología

La fisiología (del griego "physis", naturaleza y "logos", conocimiento, estudio) es la ciencia que estudia las funciones de los seres vivos. La anatomía y fisiología son campos de estudio estrechamente relacionados en donde la primera hace hincapié en el conocimiento de la forma mientras que la segunda pone interés en el estudio de la función de cada parte del cuerpo, siendo ambas áreas de vital importancia en el conocimiento médico general.

La fisiología tiene varias ramas: Fisiología celular, de tejidos, de órganos, veterinaria o animal, humana, y comparada.

El estudio de la fisiología humana se remonta al menos a 420 a. C. en tiempos de Hipócrates, el padre de la medicina. El pensamiento crítico de Aristóteles y su énfasis en la relación entre estructura y función marcó el inicio de la fisiología en la antigua Grecia, mientras que Galeno de Pérgamo (c. 126-199 dC), conocido como únicamente Galeno, fue el primero en utilizar los experimentos para probar la función del cuerpo. Galeno fue el fundador de la fisiología experimental. Los antiguos libros indios de Ayurveda, el Sushruta Samhita y el Charaka Samhita, también son importantes en las descripciones de la anatomía y la fisiología humanas, vegetales y animales.

Durante la Edad Media, las antiguas tradiciones médicas griegas e indias fueron desarrolladas por los médicos musulmanes, sobre todo de Avicena (980-1037), quien introdujo la experimentación y la cuantificación en el estudio de la fisiología en el "Canon de la Medicina". Muchas de las antiguas doctrinas fisiológicas fueron finalmente desacreditadas por Ibn al-Nafis (1213-1288), quien fue el primer médico en describir correctamente la anatomía del corazón, la circulación coronaria, la estructura de los pulmones y la circulación pulmonar, y es considerado el padre de la fisiología circulatoria. También fue el primero en describir la relación entre los pulmones y la oxigenación de la sangre, la causa de la pulsación, y un concepto inicial de la circulación capilar.

A raíz de la Edad Media, el Renacimiento trajo consigo un aumento de la investigación fisiológica en el mundo occidental que ha activado el estudio moderno de la anatomía y la fisiología. Andreas Vesalius fue autor de uno de los libros más influyentes sobre anatomía humana: "De humani corporis fabrica". Vesalio es tenido a menudo como el fundador de la anatomía humana moderna. El anatomista William Harvey describió el sistema circulatorio en el siglo XVII, que fue fundamental para el desarrollo de la fisiología experimental. Herman Boerhaave es tenido a veces como el padre de la fisiología, debido a su enseñanza ejemplar en Leiden y a los libros de texto "Medicae Institutiones" (1708). 

Santorio Santorio en Padua realiza un experimento con él durante 30 años, pesándose y balanceando su comida y alimentos diariamente logrando descubrir el metabolismo.

En el siglo XVIII, obras importantes en este campo fueron las de Pierre-Jean-Georges Cabanis, médico y fisiólogo francés. 

En el siglo XIX, los conocimientos fisiológicos comenzaron a acumularse a un ritmo rápido, más notablemente en 1838 con la teoría de la célula de Matthias Schleiden y Theodor Schwann, que radicalmente declaró que los organismos están formados por unidades llamadas células. En (1813-1878), nuevos descubrimientos de Claude Bernard condujeron a su concepto de "medio interno", que más tarde sería retomado y defendido como "homeostasis" por el fisiólogo estadounidense Walter Cannon (1871-1945).

En el siglo XX, los biólogos también se interesaron en los organismos distintos de los seres humanos. Han sido importantes en estos campos Knut Schmidt-Nielsen y Jorge Bartolomé. Más recientemente, la fisiología evolutiva se ha convertido en una especialidad distinta.

Los sistemas endocrino y nervioso juega un papel importante en la recepción y transmisión de las señales que integran la función. La homeostasis es un aspecto importante en lo que respecta a las interacciones dentro de un organismo, incluyendo a los humanos.



</doc>
<doc id="1208" url="https://es.wikipedia.org/wiki?curid=1208" title="Filología">
Filología

La filología (del latín "philologĭa", y este del griego φιλολογία "philología", ‘amor o interés por las palabras’) es el estudio de los textos escritos, a través de los que se intenta reconstruir, lo más fielmente posible, el sentido original de estos con el respaldo de la cultura que en ellos subyace.

El trabajo filológico se aproxima al hermenéutico, al menos en la medida en que interpreta el sentido, y se sirve, por tanto, del estudio del lenguaje, la literatura y demás manifestaciones idiomáticas, en cuanto constituyen la expresión de una comunidad cultural determinada o de varias, o de meros individuos. Se entiende usualmente por filología, bien el estudio de las lenguas y las literaturas, así como la correspondiente cultura de sus hablantes, bien el estudio diacrónico o eidético de los textos literarios o incluso de todo vestigio de lengua escrita o de la lengua en general. 

En su más amplio y pleno sentido, especialmente en las tradiciones modernas románica y germánica, Filología es el término general que designa el estudio de las lenguas naturales y abarca, pues, tanto la serie disciplinaria de la Ciencia del Lenguaje o Lingüística (Lingüística histórica, Lingüística teórico-descriptiva y Lingüística aplicada), una de las dos grandes series filológicas, como aquella otra formada por la Ciencia de la literatura (esto es, Historia de la literatura, Teoría de la literatura y Crítica literaria), según ha venido a establecer simétricamente el desarrollo de los criterios de la "ciencia real". Ello representa en consecuencia, no solo la integración de la Retórica y la Poética clásicas (cosa evidente desde la Antigüedad), y también modernas, sino la completa integración de todas aquellas metodologías internas, ya fuertemente transversales y compartidas como sobre todo la Comparatística, la Gramática comparada o la Literatura comparada, ya técnicamente restrictivas y particularizadoras como la Ecdótica o Crítica textual. 

En este último aspecto, además, la Filología, técnicamente fundada para Occidente en el Museo de Alejandría, ha asumido paulatinamente durante la segunda mitad del siglo XX el instrumental proporcionado por los medios digitales, los cuales han transformado la aplicabilidad e incluso los resultados (en el caso del hipertexto) del trabajo crítico textual y en general la edición de textos.

La Filología, en cuyo seno se suele distinguir entre filología general y filologías particulares (aproximadamente correspondientes a lenguas o familias de lenguas o bien regiones culturales) constituye en conjunto el milenario, más extenso, fundamentador y multiplicadamente cultivado sector disciplinar de las Ciencias humanas.

Entre varias consideraciones, fue ganando terreno aquella que concebía la labor de alguien consagrado a la explicación de textos desde los diferentes puntos de vista posibles, actividad ésta que comenzó siendo una afición noble cultivada con mayor o menor acierto y, hasta cierto punto, de manera no profesional. Tanto Gramática ("grammatiké") como Filología son disciplinas entroncadas en no pequeña medida, si bien cada una adquirirá grados de especialización y esta última denominación acabará disfrutando de la capacidad definitoria más abarcadora e incluyente por tanto de la anterior. Aunque en diferente grado, otro tanto sucede respecto de la Retórica, en menor medida respecto de la Poética.

A veces se utiliza "filología helenística" queriendo designar la "filología griega" en su más amplio sentido, pero la calificación de "helenístico" es preferible sea restringida al determinado periodo y cultura tardíos de la lengua griega clásica, por lo demás dispersa y frecuentemente entremezclada con el cristianismo. A este periodo corresponden autores tan eminentes como Longino, Filón de Alejandría o Plotino. 

Los primeros filólogos en el sentido restrictivo fueron los alejandrinos (siglo III a. C.), discípulos de los sofistas, cuyo más sobresaliente representante es Aristófanes de Bizancio (siglo III a. C.), fundador de un método que su discípulo Aristarco de Samotracia, director de la Biblioteca de Alejandría, aplicó, más tarde, al estudio de los poemas de Homero. Estos primeros filólogos desarrollaron, en la Biblioteca de Alejandría, una importante actividad editorial, centrada en la copia de manuscritos de los más importantes y representativos autores del pasado, cuyos textos se limpiaban de errores y se interpretaban de acuerdo con unas normas determinadas. En manos de los alejandrinos, la filología se convirtió, así, en un conjunto de conocimientos sistemáticos y ordenados, aunque amplios y poco profundos, puesto que el filólogo debía poseer no solo conocimientos lingüísticos y literarios, sino también históricos, geográficos, artísticos, retóricos, etc. Por eso se le consideraba la persona ideal tanto para explicar los textos como para reconstruirlos, modernizarlos y restaurarlos. 

La primera Gramática ("Techne Grammatiké"), la de Dionisio de Tracia, es muestra excelente de la amplitud y diversidad de los quehaceres filológicos, ya gramaticales si tomamos esta palabra en nuestro limitado sentido contemporáneo, ya críticos y literarios. 
Aquello que acabaría genéricamente llamándose "filología" comenzó ocupándose, por una parte, de la lectura correcta de los textos y, por otra, de la fijación, depuración y exégesis de los mismos. Las experiencias adquiridas y los materiales empleados en esta actividad se irían recogiendo en léxicos, repertorios, inventarios, etc. La filología se convierte, así, en época alejandrina, en una disciplina de carácter enciclopédico que abarca enseñanzas de gramática, retórica, historia, epigrafía, numismática, bibliografía, métrica, etc. Los filólogos así formados son, por antonomasia, hombres cultos que reúnen, aun de manera esquemática, los saberes de su época.

Roma asimiló los métodos de los cesarianos y continuó la labor emprendida por estos; fue el caso de Varrón (siglo I a. C.), por ejemplo. En época imperial proliferan quienes estudian, critican y comentan las obras maestras de la cultura latina, llamándose a sí mismos filólogos o gramáticos, voz que irá suplantando a la primera hasta hacerla desaparecer. En efecto, el término filología se utilizará poco en el Bajo Imperio, coincidiendo con la decadencia de los estudios de este tipo, que llegan a desaparecer casi por completo a partir de este momento y durante toda la Edad Media. A pesar de ello, es importante recordar las figuras del latino Servio Macrobio (siglo IV) y, mucho más tarde, el bizantino Focio (siglo IX); también puede destacarse la edición de las Suidas (siglo X) bizantinas siguiendo métodos alejandrinos.

La época latina construyó la gran síntesis de las disciplinas de raigambre filológica mediante la Retórica, como no podía ser de otro modo, es decir gracias a las "Institutio Oratoria" de Quintiliano a finales del siglo I. Esta poderosa construcción, que fundía asimismo la cultura humanística y por tanto la educación, determinaría el curso medieval, gramaticalizado y de poética retorizada, proceso que solo alcanzará a desmembrarse tras el final de las corrientes tradicionalistas y dialécticas, por así decir enmarañadamente medievales, en virtud de la nueva visión de las Poetrias, ya emancipadas de la persistente pervivencia gramatical de Donato y Prisciano. El "De Vulgari Eloquentia" de Dante, no publicado en su tiempo, fue un atisbo que tardó en localizar su propio camino.
A la Patrística, especialmente a San Jerónimo y San Agustín, es preciso reconocer que se debe no ya la integración de la cultura y los saberes filológicos grecolatinos en el nuevo mundo cristianizado, sino la creación por este de una retórica, una filología y traductología que habrían de confluir en la obra de Erasmo de Rotterdam. Por otra parte, la reactualización de Cicerón representará la nueva Retórica o Eloquentia renacentista.

La cultura del Renacimiento y, sobre todo, del Humanismo, constituye, ya sea en su vertiente de interpretación más cívica (Eugenio Garin) o más filológica (Kristeller), el gran establecimiento de la filología moderna y el primer gran dominio y acopio de las fuentes clásicas. Se ha discutido mucho acerca de la importancia medieval del llamado Protorrenacimiento, o de la distinción de varios Prerrenacimientos, uno de los cuales podría entenderse como específicamente filológico. La importancia de la operación académica llevada a cabo por Carlomagno es de todo punto indudable y relativa a lo que llamamos historia y creación de las escuelas catedralicias y las universidades propiamente dichas.

Como es bien sabido, la creación de la imprenta y la edición de textos clásicos en este nuevo medio significó algo parecido a una revolución cultural extendida a todos los ámbitos del conocimiento y las posibilidades de su difusión. Si el Cuatrocientos fue la prodigiosa época del arte y su teoría, el Quinientos fue la de la Poética y la Crítica (Minturno, Escaligero, Castelvetro), pero todo ese tiempo fue en general el de los saberes filológicos, cuando menos desde los maestros de Petrarca. Puede decirse que se instauró la pasión bibliográfica en el destino buscado de restituir a los clásicos grecolatinos y los textos escriturísticos. Durante el siglo XV, personajes tan importantes y dispares como Aldo Manuzio o Angelo Poliziano habían señalado el camino de la dedicación al estudio de los clásicos, cuyo estilo imitan y cuyos textos editan. El siglo XVI es para los estudios filológicos en amplio sentido, la época quizás sobre todo de Julio César Escaligero, que continúa entre otras cosas el "parangón" (base originaria de la Comparatística o Literatura comparada) en la tradición virtuosista de Dionisio de Halicarnaso. Se trata de un ingente decurso filológico que cruza de Salutati a Pontano, de Bracciolini y Valla a Bocaccio, Pletón o Ficino. Y así lo demuestran también Henri Estienne, o Erasmo de Rotterdam, quien retoma y eleva la tradición jeronimiana, o Nebrija y la fundamentación de la nueva lengua de América.

En el siglo XVIII, la Ilustración y el renovado interés por la ciencia en general hacen renacer o establecen una nueva etapa para el interés filológico. Richard Bentley instaura en la Universidad de Cambridge los estudios clásicos dando un definitivo empuje a los estudios filológicos; por primera vez, puede decirse, es superada la filología alejandrina mediante la teorización de la existencia de la digamma en los textos homéricos. Es una etapa de corrección de los textos deteriorados o deformados, acomodándolos al estilo de sus autores ("usus scribendi") y a las circunstancias de su época de origen. 

En el último cuarto del siglo XVIII, el término "filología" es rescatado por Friedrich August Wolf, considerado en este sentido padre de la filología moderna. Wolf, en efecto, abre un nuevo periodo importante para la historia de las disciplinas lingüísticas en sentido amplio. Ferdinand de Saussure, consideraba la filología de Wolf como un «movimiento científico», que tiene por objeto de estudio no solo la lengua sino también la fijación, interpretación y comentario de textos, lo que le lleva a ocuparse de la historia literaria, las costumbres, las instituciones, etcétera, utilizando un método propio: la crítica. Estas investigaciones filológicas, según Saussure, tendrían el mérito de haber preparado el camino de la lingüística histórica.

Pero el último cuarto del Setecientos es señaladamente el momento de la creación, por parte de la "Escuela Universalista Española del siglo XVIII",
esto es Lorenzo Hervás ("Catálogo de las Lenguas") y Juan Andrés ("Origen, progresos y estado actual de toda la literatura"), de la Lingüística comparada y la Historia literaria universal y comparada o Literatura comparada, respectivamente. Es el moderno gran impulso de una tradición que de diferente modo procede directamente de Dionisio de Halicarnaso, Escalígero y Erasmo.

La filología alemana del siglo XIX, junto a la Estética y en general la Filosofía, representa uno de los mayores momentos de la cultura de la Humanidad. Tras Wilhelm von Humboldt, cenit de la Lingüística, el siglo XIX va a configurar el desarrollo de la filología comparada en el marco del nuevo humanismo alemán. La publicación, a mediados de siglo, de la primera "Gramática comparada" por parte de Franz Bopp, sirvió para demostrar que se podía llevar a cabo un proceso avanzado de comparación entre las lenguas. La filología comparada puede considerarse en gran medida una consecuencia directa del movimiento romántico. El afán por el conocimiento del pasado, tan propio del Romanticismo, contribuyó a crear la mentalidad historicista que le era necesaria, mientras que el deseo de conocer el alma de los pueblos, por otro lado, también típicamente romántico, condujo a la evolución historiográfica, filosófica y filológica aplicada a un nuevo estudio de sus lenguas y literaturas. Gracias a tales condicionamientos, los románticos miraron hacia las lenguas y literaturas clásicas. Y, en el estudio de las lenguas clásicas, el método histórico-comparatista dio excelentes resultados en la reconstrucción de una lengua de la cual no se conservaban textos escritos, pero que podía presuponerse por la comparación de diversas lenguas europeas y asiáticas, especialmente el sánscrito: el proto-indoeuropeo. También el exotismo romántico significó la primera gran apertura al oriente asiático, que habría de ser tan importante para la gran filología que encierra la "Mitología comparada" de Max Müller. Muy pronto, la evolución de la nueva filología romántica, amparada en una tradición ejemplarmente sólida en la propia Alemania desde tiempos de Lessing, se había incorporado a la naciente epistemología científica. La filología decimonónica determinó uno de sus centros de interés en las lenguas y literaturas de los pueblos románicos, a cuyo estudio aplicó los métodos de la filología clásica. Esto dio lugar al nacimiento propiamente dicho de la filología Románica. En ecdótica, el filólogo Karl Lachmann idea y aplica un procedimiento para reconstruir científicamente textos perdidos a través de la comparación o colación de errores comunes, que en su honor será denominado método lachmaniano.

El siglo XX asistió al nacimiento y fuerte desarrollo de la lingüística formal y estructural radicalmente neo-neopositivista, especialmente a partir del Curso transmitido de Ferdinand de Saussure. En este sentido, sería probablemente necesario distinguir entre filología y este tipo de lingüística de tendencia tecnológica y la extensa gama de sus escuelas y modelos. No cabe olvidar, con todo, la subsistencia de una dispersa lingüística idealista, así el caso eminente de Karl Vossler, discípulo de Benedetto Croce, al igual que es preciso recordar a propósito de los ámbitos de la Ciencia literaria. Pero el hecho, sin embargo, es que el último cuarto del siglo XX dio muestras de un claro desplazamiento de las escuelas formalistas hacia el dominio pragmático y, por otra parte, hizo patente el ya inocultable desvanecimiento de tales proyectos tecnológicos. En cualquier caso, la Filología había continuado su labor, quizás un tanto ensimismada o encerrada, con centro en los textos escritos, pero también definitivamente abierta a los aspectos más sincrónicos de la tradición oral así como a las nuevas circunstancias tanto teóricas y críticas como instrumentales propiciadas por los medios digitales.

La Filología, en su sentido más característico o restringido, pero dentro del ámbito de la filología general, ha tenido y tiene diversos cometidos:

Históricamente, la Filología, más que relacionarse o confundirse con otras disciplinas, ha sido subrayada en la preferencia de alguna de sus partes, las cuales al fin no son sino parte de su propia configuración y por ello de su identidad de más pleno horizonte y sentido. Es de señalar la difícil relación durante el siglo XX del ámbito más característicamente filológico con cierta Lingüística estructural y formalista. Pero también es de subrayar, y ahora de manera más estable, la relación filológica con la Hermenéutica y con la Historia y, evidentemente, la Historia de la literatura (y en general la Ciencia de la literatura: junto a la historiografía literaria, la Teoría literaria y la Crítica literaria, disciplinas mediante las cuales alcanza la Filología su estado de cuerpo entero, pero que, de manera semejante a la Lingüística, también padecieron durante el siglo XX, en grandes sectores, de una complicada coyuntura técnica formalista y en consecuencia también de difícil vecindad filológica).

La Filología se confunde con la Hermenéutica en la medida en que ambas buscan el significado de los textos o su interpretación. Pero en esto la Crítica literaria ha de ser entendida a su vez como una particularización hermenéutica. Tanto la filología como su especificación de tipo lingüístico se ocupan del mismo objeto de estudio: el lenguaje humano. Pero la diferencia básica consiste en la preferencia crítico textual con frecuencia asignada a lo filológico, su indagación más particular y reconstructiva, de fijación de textos, que deviene ecdótica, frente al interés lingüístico por el lenguaje en sí mismo y la utilización de textos únicamente como un medio más de conocimiento de este. 

Por su parte, Historia y Filología colaboran en la reconstrucción de los hechos históricos pero, mientras la primera se ocupa, efectivamente, de la reconstrucción de los hechos, auxiliándose, en este caso, del método filológico y de otros medios y disciplinas, la segunda trata de situar los textos concretos en una época determinada, sirviéndose, en este caso, de los conocimientos históricos.

En realidad, la Filología, tanto en su sentido general relativo a los textos de las lenguas naturales como en el particularizado diacrónico y ecdótico, comparte su objeto con la serie disciplinaria de la Ciencia literaria, el cual es primordialmente la Literatura en tanto que textos constituidos en unidades o grupos de unidades textuales "altamente elaboradas".

En el pleno ámbito de la disciplina, del conjunto de ámbitos disciplinarios y por encima de la metodología, es preciso distinguir entre Filología general y Filologías particulares. Pudiera decirse que existen tantas filologías como culturas, o como lenguas, pero estas no son magnitudes correspondientes ni a veces tienen independencia. Es preciso subrayar, al margen del mundo egipcio (Egiptología), sobre todo las dos grandes culturas filológicas asiáticas, hindú y china, y a partir de esta última toda la gama que de ella deriva (coreana, japonesa...). Tanto la Indología como la Sinología son concebidas en general como filología en amplio sentido. Otro tanto habría que decir de la Coreanología y la Niponología o Japonología. Por otra parte, al margen de la Filología Árabe y la Filología Semítica, que integraría a la anterior al tiempo que participa de una filología especial, la Bíblica, respecto del mundo africano subsahariano es preciso subrayar por su parte que el Africanismo se funda en lenguas y áreas culturales originalmente orales, sin escritura, es decir que solo cabe concebir su configuración filológica desde la aplicación moderna, ya se trate desde las lenguas autóctonas o desde las europeas importadas o coloniales. 

En la tradición europea se diferencian varios grandes campos filológicos fundamentales, algunos de los cuales, como después se indicará, han tenido importantísima proyección extraeuropea:






Dentro de la gran familia Románica, la Filología italiana y la Filología Francesa poseen una gran dimensión nacional. A diferencia de estas, y otras de ámbito más reducido como la Filología Rumana, la Filología Portuguesa, trocadamente indisociable de la Galaica como Filología Gallegoportuguesa, posee una gran proyección americana brasileña y en alguna medida africana mozambiqueña. Aún más que esta última, la Filología Española como Hispánica ha tenido y configura una extensísima proyección americana o Hispanoamericana. Por ello, a la Filología Española conviene más la denominación de Hispánica, pues atañe directamente al patrimonio y a la realidad viva de más de quinientos millones de hablantes de todo el mundo.





</doc>
<doc id="1211" url="https://es.wikipedia.org/wiki?curid=1211" title="Idioma francés">
Idioma francés

El idioma francés ( o ) es una lengua romance hablada en Francia, junto con otras lenguas como el idioma bretón en Bretaña, el occitano en Occitania, el vasco en el país vasco francés, el catalán en el Rosellón, y el corso en Córcega. En los territorios franceses de ultramar es hablado en muchos casos, junto con otras lenguas como el tahitiano en la Polinesia Francesa, el "créole" de la isla Reunión, así como los de Guadalupe y Martinica, o en Estados Unidos (francés cajun, créole y francés colonial).

Se calcula que hay 274 millones (212 millones uso diario) de francófonos en el mundo, de los cuales aproximadamente 72 millones son hablantes parciales. Es el noveno idioma más hablado por hablantes nativos y la segunda lengua en las relaciones internacionales por el número de países que la emplean como lengua oficial y, o, de comunicación y por el número de organizaciones internacionales que la emplean como lengua de trabajo, como pueden ser la Unión Europea, las Naciones Unidas, etc.

El francés es también uno de los idiomas oficiales de Bélgica (4,3 millones de belgas francófonos), dónde es el idioma oficial de Valonia, mientras que en la capital, Bruselas, es el idioma más hablado (90 % de los habitantes) y es cooficial con el neerlandés; está presente en otros países como Suiza, donde un 29 % de la población lo habla (1,75 millones de francófonos a finales de 2006), en Mónaco es el único idioma oficial desde la aprobación Constitución de 1962. Aunque el catalán es el idioma oficial en Andorra, el francés se habla habitualmente, más en unas ciudades que otras, además del español, gozando Andorra de tres sistema educativos: el andorrano, el francés y el español; en Luxemburgo, donde es cooficial con el alemán y el luxemburgués; en Italia (solo en el Valle de Aosta) y en las Islas del Canal de la Mancha. También se conoce en zonas fronterizas del norte de España, donde hay un porcentaje significativo de bilingües sobre todo en el enclave de Llívia. Forman parte de la francofonía por tener allá gran difusión como segunda lengua los estados del este europeo Bulgaria, Moldavia y Rumanía.

El francés es el segundo idioma más hablado en la Unión Europea como lengua materna, tras el alemán y por delante del inglés. Es nombrado con frecuencia "la lengua de Molière", del nombre de uno de los más famosos escritores franceses. Es una de las veinticuatro lenguas oficiales y de trabajo en la UE. 

 En el continente americano es cooficial con el inglés en Canadá, aunque la mayoría de los canadienses son anglófonos, salvo en las regiones de Quebec, donde la mayoría de la población es francófona, siendo el francés ("français québécois") la única lengua oficial en la provincia en la cual ya se han celebrado varios referendums secesionistas con resultado negativo, Nuevo Brunswick es bilingüe y Ontario tiene una comunidad francófona muy numerosa con autonomía cultural y lingüística; también en el estado de Luisiana (Estados Unidos), donde se habla el cajún, un idioma criollo basado en el francés, y en los estados del NE fronterizos con Canadá (Vermont y Maine), donde se habla un dialecto del francés, el acadiano; y en la República de Haití, aunque el idioma mayoritario en este país es el criollo haitiano. Es hablado también por algunas comunidades de las islas de Dominica, Santa Lucía, Trinidad y Tobago y en la zona fronteriza entre la República Dominicana y Haití (aunque en las islas francófonas del Caribe lo que habla la mayoría de la población son dialectos del francés: creoles y criollo francés). También lo hablan algunas pequeñas comunidades francesas o de origen francés en el resto del Caribe y en la América del Sur hispanohablante, y en la zona fronteriza con la Guayana francesa del estado de Amapá (Brasil).
El francés es también el idioma oficial en los territorios de ultramar de Francia de la Guayana Francesa, Guadalupe, Martinica, San Bartolomé, San Martín y San Pedro y Miguelón.

En el continente africano, se utiliza, en forma dialectal, en los países que formaban parte del Imperio francés o que fueron colonias belgas, como la República Democrática del Congo (ex Zaire), República del Congo, Burkina Faso, Senegal, Guinea, Malí, Chad, Níger, Burundi, Ruanda, Togo, Benín, República Centroafricana, Gabón, Costa de Marfil, Madagascar, Mauricio, Yibuti, islas Seychelles, Camerún (que fue partido en dos zonas: una zona francesa (la más importante) y una zona inglesa), islas Comoras, las islas de Reunión y Mayotte, que son territorio francés, y una parte de la población de la Guinea Ecuatorial, que lo emplea junto con el español como lengua oficial, Marruecos, Argelia, Mauritania y Túnez, donde se habla junto con el árabe y los dialectos bereberes, en Egipto, donde es muy minoritario, pero que se utiliza como lengua de cultura; así, la Universidad Senghor de Alejandría (Université Senghor d'Alexandrie) es francófona.

En Asia, se utiliza en forma minoritaria en Camboya, Laos, Vietnam e India (especialmente en Puducherry). En Oriente Próximo, es utilizado como lengua administrativa y por el 50 % de la población del Líbano, aunque también es hablado por una minoría en Siria, debido al protectorado francés.

En Oceanía, es hablado en los territorios franceses de las islas de Nueva Caledonia, la Polinesia francesa y en Wallis y Futuna, y también se habla en Vanuatu.

La principal variación dialectal del francés se encuentra dentro de Europa, donde numerosas variedades históricas han estado en uso desde el siglo IX. Fuera de Europa, existen también variedades regionales evolucionadas a partir del francés medio y por tanto presentan diferencias menos profundas. Las principales variedades dentro de Europa son:

Los principales variantes fuera de Europa son:
Las estimaciones sobre el número de francófonos varían dependiendo de los criterios considerados por las fuentes (lengua materna, lengua administrativa, lengua de trabajo, lengua de cultura…). Las fuentes principales y sus respectivas estimaciones son:


El francés es una de las seis lenguas de trabajo de la ONU (y uno de las dos lenguas del secretariado), una de las dos lenguas oficiales del Comité Olímpico Internacional, de la OTAN, de la OMC, y de los servicios postales, una de las dos lenguas principales de la Unión Africana y una de las tres lenguas de trabajo en la UE (junto al inglés y al alemán) y en la Organización de la Conferencia Islámica, una de las dos lenguas oficiales del Consejo de Europa (con el inglés), y una de las siete lenguas de la cadena europea de noticias Euronews.

El territorio de lo que hoy es Francia empezó a ser poblado por los galos alrededor del siglo VII a. C., los cuales hablaban idiomas celtas que no poseían escritura. Hacia el suroeste, los aquitanos hablaban probablemente una lengua precursora del vasco, pero desconocían la escritura. En la zona de Massilia (la actual Marsella) los habitantes de las colonias griegas hablaban y escribían en este idioma, pero no lo difundieron más allá de sus colonias.

Todos esos idiomas y otros hablados en la antigua Galia seguramente fueron desapareciendo con la colonización romana y la progresiva implantación del latín. Con el declive del Imperio romano, una serie de pueblos de origen germánico llegaron a la Galia romana. Entre ellos, dos se establecieron de modo más consolidado: los francos en el norte y los visigodos en el sur, con el río Loira como frontera. A pesar de que ambos pueblos hablaban sus propias lenguas, pronto adoptaron el latín hablado por la población local. No obstante, el idioma hablado por los francos está en el origen del neerlandés que es un idioma germánico hablado hoy en día en sus distintas variedades en los Países Bajos, donde se le denomina holandés, en parte de Bélgica y en el extremo norte de Francia.

Durante mucho tiempo, el idioma hablado en el norte de Galia (en realidad ya Francia) es un latín más o menos evolucionado, con grandes influencias, fundamentalmente fonéticas del idioma germánico hablado por los francos. Al sur, la evolución es diferente, por lo que poco a poco se van diferenciando dos lenguas con una frontera que en principio se marcará en el Loira, aunque a lo largo de la historia irá desplazándose cada vez más hacia el sur. Al sur de esa frontera se hablaba la lengua de oc. La línea de separación iba del Macizo Central a la desembocadura del Loira en Nantes.

De cualquier modo, no resulta sencillo establecer el momento en el que el latín vulgar se transforma en francés o provenzal, pero ese momento hay que situarlo entre los siglos VI y IX. A partir del siglo VII ya se cuenta con testimonios de que la lengua hablada en el territorio de la actual Francia es diferente del latín y del germánico. El documento fundamental es el de los Juramentos de Estrasburgo (842), que se considera el texto más antiguo escrito en protoromance, en los que las diferentes tropas de los nietos de Carlomagno, Lotario, Carlos el Calvo y Luis el Germánico juran respeto a la división que se produce tras la muerte de Luis el Piadoso y que está marcada por el Tratado de Verdún, y se ven obligados a hacerlo tanto en latín, como en germánico y en un idioma romance, a caballo entre el latín y el francés. En Francia, los dos grandes dialectos romances antes mencionados pasarán a ser conocidos con los nombres de "langue d'oc" y "langue d'oïl" (en función del modo en que se decía «sí»). El francés actual es heredero de este último.

Poco tiempo después empieza a aparecer una literatura escrita por clérigos en este nuevo idioma, que con la aparición de los primeros textos literarios (el primero es la Secuencia de Santa Eulalia), entre los que destaca el Cantar de Roldán, el idioma romance fue consolidándose y diferenciándose cada vez más del latín. Poco a poco se transformó de idioma declinado en idioma analítico, en el cual el uso de preposiciones y el orden de las palabras en la oración reemplazan al sistema de casos.

Lo que se conoce como "francés antiguo" se fue consolidando a partir del siglo XI, y aunque hoy se estudie todo lo que se hablaba al norte del Loira como si se tratara de una sola lengua, en realidad se trataba de dialectos con elementos comunes.

La influencia germánica en el idioma obligó a usar en el lenguaje escrito algunos dígrafos para reproducir algunos de los sonidos que se utilizaban pero que no habían existido en latín vulgar. Así, la nasalización, uno de los elementos fonéticos más característicos de la influencia germánica en el francés se va marcando en la escritura por el uso de la n en posición final de sílaba. La evolución fonética de la u latina hacia el sonido que actualmente tiene en francés obligó asimismo a utilizar el dígrafo ou para reproducir el sonido original de dicha letra en latín.

A continuación se presentan algunas evoluciones fonéticas por siglos que dan una idea del ritmo de los principales cambios fonéticos acaecidos:

El alfabeto francés ("alphabet français" en francés) son los símbolos alfabéticos utilizados en el idioma francés. Incluye las 26 letras del alfabeto latinomoderno, las 14 que se forman añadiéndoles signos diacríticos (13 vocales acentuadas y el grafema cedilla «ç») y 2 ligaduras («æ» y «œ»). Por lo tanto, componen el alfabeto francés 42 letras en total.

El inventario de fonemas consonánticos distintivos viene dado por:
¹ En la pronunciación actual, el fonema // se distingue cada vez menos de [nj]. 
² En algunos dialectos, la // puede ser reemplazada por // o /r/. Este fenómeno se denomina alofonía.
³ Estas dos aproximantes son labialiadas
El inventario de alófonos vocálicos viene dado por:
¹ En la pronunciación actual, [ə] tiende a acercarse a [ø], y tiende a aproximarse a .

VOCALES

CONSONANTES

El francés se escribe con el alfabeto latino. Utiliza cinco diacríticos: (acento agudo, acento circunflejo, acento grave, cedilla y diéresis), así como dos ligaduras ("æ" y "œ").

La escritura tiene poco que ver con la pronunciación real pero es fácil predecir la pronunciación a partir de la escritura lo cual no es cierto a la inversa pues esta no es predecible a partir de la audición. Una de sus características es el uso de dos o tres letras para indicar un fonema, si bien muchas veces estos fonemas franceses reúnen el carácter de dos fonemas predominando uno de ellos, por ejemplo el dígrafo "ou" en el francés parisino suena prácticamente como una [u] española aunque mantiene casi átono algo del fonema [o]. En general, la forma escrita es más conservadora que la forma hablada. La pronunciación francesa es monótona, en el sentido de que todas las sílabas se acentúan con la misma intensidad, salvo los términos extranjeros asimilados que mantienen su acento original ( \ˈkɛ.nɪ.di\, \ˈhɪt.lɐ\, \ˌwɚk ˈaʊt\...). La frecuente poca correspondencia entre el francés escrito y el hablado es un fenómeno que se debe a los fuertes cambios fonéticos que se han presentado desde el período del francés antiguo, y que no se correspondieron con cambios en la escritura. Sin embargo, han ocurrido algunos cambios conscientes en la escritura para restaurar la ortografía latina:

A veces los impresores impusieron su propia grafía para evitar ambigüedad:

Es casi imposible predecir la escritura basándose únicamente en la pronunciación. Las consonantes finales, en particular "s", "x", "z", "t" y "d", suelen ser mudas; y "n" y "m" son perceptibles incluso al final de palabra porque nasalizan a la vocal que acompañan. En cambio, "c", "r", "f", y "l" suelen pronunciarse incluso en posición final. Por ejemplo, las siguientes palabras terminan en consonante, pero en su pronunciación acaban en un sonido vocálico: "nez", "doigt", "pied", "aller", "les", "lit", "beaux". Con la pérdida de la vocal final en la pronunciación el género llega a quedar marcado, paradójicamente, con el fonema «s» propio del plural.

Los diacríticos tienen un significado fonético, semántico y etimológico.


La ligadura œ («cœur») es una contracción obligatoria de "oe", y cambia la pronunciación (como entre "coefficient" y "sœur").

La ligadura æ también es una contracción obligatoria, pero es más rara. Se utiliza solamente en palabras latinas (como «curriculum vitæ») o en nombres propios (como «Lætitia»).

Se ha proyectado reformar la ortografía .

El sustantivo (en francés: "nom substantif"), al igual que en español, se ve afectado por el género y el número. Se distinguen dos géneros en el francés: el masculino ("rat", 'rata'; "homme", 'hombre'; "ours", 'oso'), y el femenino ("voiture", 'automóvil'; "actrice", 'actriz'; "baleine", 'ballena').

El plural se forma, generalmente, añadiendo una "s" al final de la palabra ("crayon" → "crayons"; "fleur" → "fleurs"). Sin embargo, existen algunos casos especiales en los que el plural sigue otras pautas:

Varía en número (singular o plural) y en género (masculino o femenino). No tienen significado propio y dependen del contexto. Al igual que en otras lenguas, su función sintáctica es sustituir al sustantivo. Puede ser tónico, acompañando siempre al verbo; o átono, necesario cuando no se acompaña al verbo.

Ejemplo de pronombre tónico:

Ejemplo de pronombre átono:

Pronombres tónicos:

Pronombres átonos:

Estos últimos funcionan como objeto directo u objeto indirecto y los primeros (tónicos) siempre acompañan al verbo en francés, es obligatorio. Si no, se utiliza el átono.

Varía en número (singular o plural), tiempo (presente, futuro, pretérito imperfecto, pretérito perfecto compuesto, pretérito indefinido o pretérito perfecto simple, usado sobre todo en literatura; pretérito anterior, pretérito pluscuamperfecto y una fórmula francesa llamada "le surcomposé"), en modo (indicativo, subjuntivo, imperativo) y voz (activa y pasiva). Designan acciones o estados. Al igual que el español, el verbo francés tiene desinencias para cada tiempo, existiendo algunos verbos irregulares como son: aller (je vais), venir (il vient), être (nous sommes), avoir (vous avez).

Para la negación se utiliza la siguiente fórmula:



El sistema de contar francés es parcialmente vigesimal: el veinte (') se usa como un número base en los nombres de los números del 60 al 99. La palabra francesa para "ochenta", por ejemplo, es ', la cual literalmente significa «cuatro veintes», y "" (literalmente «sesenta-quince») significa 75. Esta reforma surgió después de la Revolución francesa para unificar los diferentes sistemas de contar (la mayoría vigesimal cerca de la costa, a causa de influencias vikinga y celta, esta última a través del bretón). Este sistema es comparable al uso de "score" en inglés arcaico, como en "fourscore and seven" (87), o "threescore and ten" (70).

El francés de Bélgica, el francés de Suiza y el francés de las antiguas colonias belgas, República Democrática del Congo, Ruanda y Burundi son diferentes en cuanto a esto. En estos países 70 y 90 son ' y '. En Suiza, dependiendo del dialecto local, 80 puede ser ' (Ginebra, Neuchâtel, Jura) o ' (Vaud, Valais, Friburgo). "Octante" ha sido usado en Suiza en el pasado, pero ahora está considerado arcaico. En Bélgica, sin embargo, "quatre-vingts" se usa universalmente.

También debe mencionarse que el francés usa un espacio, o un punto, para separar los millares, menos en Suiza donde se separan así: 20'000 (veinte mil). La coma se usa en los números franceses como un punto decimal: 2,5 = "deux virgule cinq". Los números cardinales en francés del 1 al 20 son como sigue:
Existen muchos préstamos lingüísticos del francés que han entrado a formar parte del español. Se trata de galicismos como amateur, argot, beige, bricolaje, bulevar, cabaret, capó, carnet, chalet, chaqueta, chef, chófer, chovinismo, cofre, collage, complot, debut, doblaje, dossier, élite, gourmet, homenaje, hotel, interesante, jamón, manjar, maquillaje, mensaje, menú, mesón, ordenador, pana, pantalón, peluche, popurrí, rol, sabotaje, tour, vedette, vinagre, etc.





</doc>
<doc id="1213" url="https://es.wikipedia.org/wiki?curid=1213" title="Protocolo de transferencia de archivos">
Protocolo de transferencia de archivos

El Protocolo de transferencia de archivos (en inglés File Transfer Protocol o FTP), es un protocolo de red para la transferencia de archivos entre sistemas conectados a una red TCP (Transmission Control Protocol), basado en la arquitectura cliente-servidor. Desde un equipo cliente se puede conectar a un servidor para descargar archivos desde él o para enviarle archivos, independientemente del sistema operativo utilizado en cada equipo.

El servicio FTP es ofrecido por la capa de aplicación del modelo de capas de red TCP/IP al usuario, utilizando normalmente el puerto de red 20 y el 21. Un problema básico de FTP es que está pensado para ofrecer la máxima velocidad en la conexión, pero no la máxima seguridad, ya que todo el intercambio de información, desde el login y password del usuario en el servidor hasta la transferencia de cualquier archivo, se realiza en texto plano sin ningún tipo de cifrado, con lo que un posible atacante puede capturar este tráfico, acceder al servidor y/o apropiarse de los archivos transferidos.

Para solucionar este problema son de gran utilidad aplicaciones como SCP y SFTP, incluidas en el paquete SSH, que permiten transferir archivos pero cifrando todo el tráfico.

El protocolo FTP se empezó a utilizar en abril de 1971, publicado como el RFC 114, antes de que existiera la pila TCP/IP. La estructura general fue establecida en 1973. Fue modificado varias veces, añadiendo nuevos comandos y funcionalidades. Al final se publicó el RFC 959 en octubre de 1985, que es la que se utiliza actualmente.

En el modelo, el intérprete de protocolo (PI) de usuario inicia la conexión de control en el puerto 21. Las órdenes FTP estándar las genera el PI de usuario y se transmiten al proceso servidor a través de la conexión de control. Las respuestas estándar se envían desde la PI del servidor hasta la PI de usuario por la conexión de control como respuesta a las órdenes.

Estas órdenes FTP especifican parámetros para la conexión de datos (puerto de datos, modo de transferencia, tipo de representación y estructura) y la naturaleza de la operación sobre el sistema de archivos (almacenar, recuperar, añadir, borrar, etc.). El proceso de transferencia de datos (DTP) de usuario u otro proceso en su lugar, debe esperar a que el servidor inicie la conexión al puerto de datos especificado (puerto 20 en modo activo o estándar) y transferir los datos en función de los parámetros que se hayan especificado.

Vemos también en el diagrama que la comunicación entre cliente y servidor es independiente del sistema de archivos utilizado en cada computadora, de manera que no importa que sus sistemas operativos sean distintos, porque las entidades que se comunican entre sí son los PI y los DTP, que usan el mismo protocolo estandarizado: el FTP.

También hay que destacar que la conexión de datos es bidireccional, es decir, se puede usar simultáneamente para enviar y para recibir, y no tiene por qué existir todo el tiempo que dura la conexión FTP. Pero tenía en sus comienzos un problema, y era la localización de los servidores en la red. Es decir, el usuario que quería descargar algún archivo mediante trump debía conocer en qué máquina estaba ubicado. La única herramienta de búsqueda de información que existía era Gopher, con todas sus limitaciones.

Gopher significa 'lanzarse sobre' la información. Es un servicio cuyo objetivo es la localización de archivos a partir de su título. Consiste en un conjunto de menús de recursos ubicados en diferentes máquinas que están intercomunicadas. Cada máquina sirve un área de información, pero su organización interna permite que todas ellas funcionen como si se tratase de una sola máquina. El usuario navega a través de estos menús hasta localizar la información buscada, y desconoce exactamente de qué máquina está descargando dicha información. Con la llegada de Internet, los potentes motores de búsqueda dejaron el servicio Gopher, y la localización de los servidores FTP dejó de ser un problema. En la actualidad, cuando el usuario se descarga un archivo a partir de un enlace de una página web no llega ni a saber que lo está haciendo desde un servidor FTP. El servicio FTP ha evolucionado a lo largo del tiempo y hoy día es muy utilizado en Internet, en redes corporativas, Intranets, etc. Soportado por cualquier sistema operativo, existe gran cantidad de software basado en el protocolo FTP.

Un servidor FTP es un programa especial que se ejecuta en un equipo servidor normalmente conectado a Internet (aunque puede estar conectado a otros tipos de redes, LAN, MAN, etc.). Su función es permitir el intercambio de datos entre diferentes servidores/ordenadores.

Por lo general, los programas servidores FTP no suelen encontrarse en los ordenadores personales, por lo que un usuario normalmente utilizará el FTP para conectarse remotamente a uno y así intercambiar información con él.

Las aplicaciones más comunes de los servidores FTP suelen ser el alojamiento web, en el que sus clientes utilizan el servicio para subir sus páginas web y sus archivos correspondientes; o como servidor de backup (copia de seguridad) de los archivos importantes que pueda tener una empresa. Para ello, existen protocolos de comunicación FTP para que los datos se transmitan cifrados, como el SFTP ("Secure File Transfer Protocol").

Cuando un navegador no está equipado con la función FTP, o si se quiere cargar archivos en un ordenador remoto, se necesitará utilizar un programa cliente FTP. Un cliente FTP es un programa que se instala en el ordenador del usuario, y que emplea el protocolo FTP para conectarse a un servidor FTP y transferir archivos, ya sea para descargarlos o para subirlos.

Para utilizar un cliente FTP, se necesita conocer el nombre del archivo, el ordenador en que reside (servidor, en el caso de descarga de archivos), el ordenador al que se quiere transferir el archivo (en caso de querer subirlo nosotros al servidor), y la carpeta en la que se encuentra.

Algunos clientes de FTP básicos en modo consola vienen integrados en los sistemas operativos, incluyendo Microsoft Windows, DOS, GNU/Linux y Unix. Sin embargo, hay disponibles clientes con opciones añadidas e interfaz gráfica. Aunque muchos navegadores tienen ya integrado FTP, es más confiable a la hora de conectarse con servidores FTP no anónimos utilizar un programa cliente.

Los servidores FTP anónimos ofrecen sus servicios libremente a todos los usuarios, permiten acceder a sus archivos sin necesidad de tener un 'USER ID' o una cuenta de usuario. Es la manera más cómoda fuera del servicio web de permitir que todo el mundo tenga acceso a cierta información sin que para ello el administrador de un sistema tenga que crear una cuenta para cada usuario.

Si un servidor posee servicio 'FTP anonymous' solamente con teclear la palabra «anonymous», cuando pregunte por tu usuario tendrás acceso a ese sistema. No se necesita ninguna contraseña preestablecida, aunque tendrás que introducir una sólo para ese momento, normalmente se suele utilizar la dirección de correo electrónico propia.

Solamente con eso se consigue acceso a los archivos del FTP, aunque con menos privilegios que un usuario normal. Normalmente solo podrás leer y copiar los archivos que sean públicos, así indicados por el administrador del servidor al que nos queramos conectar.

Normalmente, se utiliza un servidor FTP anónimo para depositar grandes archivos que no tienen utilidad si no son transferidos a la máquina del usuario, como por ejemplo programas, y se reservan los servidores de páginas web (HTTP) para almacenar información textual destinada a la lectura en línea.

Si se desea tener privilegios de acceso a cualquier parte del sistema de archivos del servidor FTP, de modificación de archivos existentes, y de posibilidad de subir nuestros propios archivos, generalmente se suele realizar mediante una cuenta de usuario. En el servidor se guarda la información de las distintas cuentas de usuario que pueden acceder a él, de manera que para iniciar una sesión FTP debemos introducir una autentificación (en inglés: "login") y una contraseña (en inglés: "password") que nos identifica unívocamente.

Un «cliente FTP basado en Web» no es más que un cliente FTP al cual podemos acceder a través de nuestro navegador web sin necesidad de tener otra aplicación para ello. El usuario se conecta mediante HTTP a un servidor web, y el servidor web se conecta mediante FTP al servidor de archivos. El servidor web actúa de intermediario haciendo pasar la información desde el servidor FTP en los puertos 20 y 21 hacia el puerto 80 HTTP que ve el usuario.

Siempre hay momentos en que nos encontramos fuera de casa, no llevamos el ordenador portátil encima y necesitamos realizar alguna tarea urgente desde un ordenador de acceso público, de un amigo, del trabajo, la universidad, etc. Lo más común es que no estén instaladas las aplicaciones que necesitamos y en muchos casos hasta carecemos de los permisos necesarios para realizar su instalación. Otras veces estamos detrás de un proxy o cortafuegos que no nos permite acceder a servidores FTP externos.

Al disponer de un cliente FTP basado en Web podemos acceder al servidor FTP remoto como si estuviéramos realizando cualquier otro tipo de navegación web. A través de un cliente FTP basado en Web podrás, crear, copiar, renombrar y eliminar archivos y directorios. Cambiar permisos, editar, ver, subir y descargar archivos, así como cualquier otra función del protocolo FTP que el servidor FTP remoto permita.

El acceso sin restricciones al servidor que proporcionan las cuentas de usuario implica problemas de seguridad, lo que ha dado lugar a un tercer tipo de acceso FTP denominado invitado (guest), que se puede contemplar como una mezcla de los dos anteriores.

La idea de este mecanismo es la siguiente: se trata de permitir que cada usuario conecte a la máquina mediante su login y su password, pero evitando que tenga acceso a partes del sistema de archivos que no necesita para realizar su trabajo, de esta forma accederá a un entorno restringido, algo muy similar a lo que sucede en los accesos anónimos, pero con más privilegios.

Entre los varios clientes FTP que existen, se pueden mencionar los siguientes:

FTP admite dos modos de conexión del cliente. Estos modos se denominan "activo" (o Estándar, o PORT, debido a que el cliente envía comandos tipo PORT al servidor por el canal de control al establecer la conexión) y "pasivo" (o PASV, porque en este caso envía comandos tipo PASV). Tanto en el modo Activo como en el modo Pasivo, el cliente establece una conexión con el servidor mediante el puerto 21, que establece el canal de control.

En modo Activo, el servidor siempre crea el canal de datos en su puerto 20, mientras que en el lado del cliente el canal de datos se asocia a un puerto aleatorio mayor que el 1024. Para ello, el cliente manda un comando PORT al servidor por el canal de control indicándole ese número de puerto, de manera que el servidor pueda abrirle una conexión de datos por donde se transferirán los archivos y los listados, en el puerto especificado.

Lo anterior tiene un grave problema de seguridad, y es que la máquina cliente debe estar dispuesta a aceptar cualquier conexión de entrada en un puerto superior al 1024, con los problemas que ello implica si tenemos el equipo conectado a una red insegura como Internet. De hecho, los cortafuegos que se instalen en el equipo para evitar ataques seguramente rechazarán esas conexiones aleatorias. Para solucionar esto se desarrolló el modo "pasivo".

Cuando el cliente envía un comando PASV sobre el canal de control, el servidor FTP le indica por el canal de control, el puerto (mayor a 1024 del servidor. Ejemplo:2040) al que debe conectarse el cliente. El cliente inicia una conexión desde el puerto siguiente al puerto de control (Ejemplo: 1036) hacia el puerto del servidor especificado anteriormente (Ejemplo: 2040).

Antes de cada nueva transferencia tanto en el modo Activo como en el Pasivo, el cliente debe enviar otra vez un comando de control (PORT o PASV, según el modo en el que haya conectado), y el servidor recibirá esa conexión de datos en un nuevo puerto (aleatorio si es en modo pasivo o por el puerto 20 si es en modo activo).

En el protocolo FTP existen 2 tipos de transferencia en ASCII y en binarios. Es importante conocer cómo debemos transportar un archivo a lo largo de la red, si no utilizamos las opciones adecuadas podemos destruir la información del archivo. Por eso, al ejecutar la aplicación FTP, debemos acordarnos de utilizar uno de estos comandos (o poner la correspondiente opción en un programa con interfaz gráfica):

Adecuado para transferir archivos que solo contengan caracteres imprimibles (archivos ASCII, no archivos resultantes de un procesador de texto), por ejemplo páginas HTML, pero no las imágenes que puedan contener. Se transforman algunos símbolos de control para mantenerlos compatibles entre diferentes sistemas, por ejemplo, si el archivo está alojado sobre un servidor linux, el salto de línea para los archivos de texto es "\n" (byte 10 en decimal). Si el cliente es un sistema Mac, el salto de línea es "\r" (byte 13 en decimal), este modo cambia estos símbolos de control para que el archivo sea legible en ambos lados, al igual que si se envía a un sistema windows, el salto de línea es "\r\n" (dos bytes, 13 y 10). Si se usa este modo en archivos que no son de texto plano, en el caso de intercambiarse entre diferentes sistemas, ese archivo quedará corrupto.

Este tipo es usado cuando se trata de archivos comprimidos, ejecutables para PC, imágenes, archivos de audio, entre otros.

Ejemplos de cómo transferir algunos tipos de archivo dependiendo de su extensión:

En la red existen diversas soluciones de software que desarrolla este tipo de tecnología, los más conocidos, son Filezilla (software libre) y CuteFTP (shareware).

A continuación se muestra un resumen de la respuesta de los códigos FTP que puede ser devuelto por un servidor FTP. Estos códigos se han estandarizado en RFC 959 por IETF. El código de respuesta es un valor de tres dígitos. El primer dígito se utiliza para indicar una de tres posibles resultados-el éxito, el fracaso o para indicar un error o una respuesta incompleta:

El segundo dígito define la clase de error:


El tercer dígito del código de respuesta se utiliza para proporcionar detalles adicionales para cada una de las categorías definidas por el segundo dígito.

Para iniciar sesión en un servidor FTP que requiere una contraseña teclee la URL de esta forma:

codice_1

Donde codice_2 es el nombre de usuario, codice_3 es el servidor FTP, codice_4 es la contraseña de acceso, y codice_5 es el directorio donde iniciamos sesión.

Ejemplo: codice_6






</doc>
