<doc id="11335" url="https://es.wikipedia.org/wiki?curid=11335" title="Cantabria">
Cantabria

Cantabria es una comunidad autónoma española uniprovincial definida como "comunidad histórica" en su Estatuto de Autonomía. Limita al este con el País Vasco (provincia de Vizcaya), al sur con Castilla y León (provincias de León, Palencia y Burgos), al oeste con el Principado de Asturias y al norte con el mar Cantábrico. La ciudad de Santander es su capital y localidad más poblada. Tiene una fuerte vinculación histórica con el Ducado de Cantabria, las Asturias de Santillana, la Hermandad de las Cuatro Villas, la provincia de los Nueve Valles y la provincia de Santander.

Cantabria está situada en la cornisa Cantábrica, nombre dado a la franja de tierra existente entre el mar Cantábrico y la cordillera Cantábrica, en el norte de la península ibérica. Posee un clima oceánico húmedo y de temperaturas moderadas, fuertemente influenciado por los vientos del océano Atlántico que chocan contra las montañas. La precipitación media es de 1200 mm, lo que permite el crecimiento de frondosa vegetación. Su mayor elevación se localiza en el pico de Torre Blanca (2619 metros)
La comunidad está compuesta por 102 municipios, siendo uno de ellos, Valle de Villaverde, un exclave en Vizcaya.

Cantabria es una comunidad rica en yacimientos arqueológicos del Paleolítico Superior, aunque los primeros signos de ocupación humana datan del Paleolítico Inferior. Destacan en este aspecto las pinturas de la cueva de Altamira, datadas en el 37 000 a. C. Junto a otras nueve cuevas cántabras, esta cavidad fue declarada Patrimonio de la Humanidad por la Unesco.

La provincia de Cantabria se constituyó el 28 de julio de 1778 en la casa de juntas de Puente San Miguel.

Diversos han sido los autores que han tratado el origen etimológico del nombre de Cantabria (San Isidoro de Sevilla, Julio Caro Baroja, Aureliano Fernández Guerra, Joaquín González Echegaray y Adolf Schulten, entre otros). Aunque no es segura su procedencia, la opinión más aceptada por los expertos es que deriva de la raíz "cant-", de origen celta o ligur y que significa 'roca' o 'piedra', y el sufijo "-abr", frecuente en las regiones celtas. De todo esto se deduce que "cántabro" vendría a significar 'pueblo que habita en las peñas' o 'montañés', en clara referencia al territorio abrupto y montañoso de Cantabria. Es una de las comunidades autónomas españolas con la toponimia más antigua, ya que el término «cántabros» aparece por primera vez reflejado en las fuentes romanas en el siglo II a. C., por el autor Catón el Viejo, aunque evidentemente Cantabria aún no existía en ese momento como entidad política unida, sino que en ella vivían diversos pueblos. En su obra "Orígenes" (c. 195 a. C.) habla del nacimiento del río Ebro en "tierra de cántabros":

Popularmente Cantabria recibe también otros nombres: "La Montaña" y "La Tierruca".

La comunidad posee una superficie de 5.326 km² y sus costas tienen una longitud total de 284 kilómetros. Su cabo más sobresaliente es el Cabo de Ajo (). En la comunidad existen tres ámbitos geográficos bien diferenciados: La Marina, La Montaña y Campo, pertenecientes a las cuencas del río Ebro y del Duero. La presencia predominante de la montaña y su difícil orografía del terreno explica que históricamente además se conozca a la comunidad entera como La Montaña.

Cantabria es una comunidad de carácter montañoso y costero y con un importante patrimonio natural. Su enérgico relieve hace que el 40 % de su superficie se sitúe por encima de los 700 metros de altitud y un tercio de la comunidad presenta pendientes de más del 30 % de inclinación. Es la cuarta provincia más montañosa de España atendiendo al desnivel del terreno. En ella se distinguen tres áreas morfológicamente bien diferenciadas:

Debido a la corriente del Golfo "Cantabria", al igual que el resto de la región Cantábrica, tiene unas temperaturas mucho más suaves que las que les correspondería por su latitud, similar a la de Nueva Escocia en Norteamérica. La comunidad está afectada por un clima templado oceánico húmedo, con veranos e inviernos suaves. Las precipitaciones se sitúan en torno a 1200 mm anuales en la costa, aumentando los valores en las zonas montañosas hasta los 2400 mm, lo que la sitúa en la denominada España húmeda (o España verde).

La temperatura media se sitúa alrededor de los 14 °C. La nieve es frecuente en las partes altas de Cantabria entre los meses de noviembre y marzo. Los meses más secos son: julio y agosto, aunque generalmente no existe sequía propiamente dicha, ya que por una parte siempre existe un mínimo de precipitación, y por otra las temperaturas no son muy elevadas (Exceptuando las zonas de clima mediterráneo o templado submediterráneo). En algunas zonas de los Picos de Europa con clima de alta montaña, por encima de los 2500 msnm se mantienen los bancos de nieve durante todo el año.

No obstante las diferencias entre comarcas pueden llegar a ser importantes. Así las más alejadas del litoral, como Liébana y Campoo, presentan un clima mediterráneo continentalizado, en el primer caso por el mesoclima especial de la zona y en el segundo por su proximidad a la meseta central.

La influencia del relieve montañoso de Cantabria es destacable sobre su clima, siendo la causa principal de fenómenos atmosféricos peculiares como son las llamadas "suradas", propiciadas por el efecto Foehn. El viento del sur sopla fuerte y seco, aumentando la temperatura a medida que nos acercamos a la costa. Esto provoca una llamativa disminución de la humedad relativa del aire y la ausencia de precipitaciones. Condiciones que contrastan con las de la vertiente sur de la cordillera donde el viento es más fresco y húmedo y puede estar lloviendo. Estas situaciones son más frecuentes en otoño e invierno, registrándose unas temperaturas anormalmente altas de más de 28 °C. No son inusuales los incendios avivados por este viento, como el que arrasó la ciudad de Santander en el invierno de 1941.

Por otro lado, las zonas costeras suelen estar sometidas a vientos constantes provenientes del océano Atlántico, que frecuentemente llegan a ser fuertes. En condiciones muy particulares, más propicias en los meses de abril-mayo y septiembre-octubre, los vientos del Oeste pueden alcanzar magnitudes de galerna.

Los ríos cántabros son cortos, rápidos y poco caudalosos; salvan unas considerables pendientes al estar el mar próximo a su nacimiento en la cordillera Cantábrica. Sus recorridos suelen ser perpendiculares a la costa, si exceptuamos el río Ebro, y poseen un caudal más o menos persistente a lo largo de todo el año motivado por unas precipitaciones por lo general constantes. Aun así, este es escaso (20 m³/s anualmente) en comparación con otros ríos de la península ibérica.
La rapidez de sus aguas, motivado por las considerables pendientes de los recorridos, hacen que tengan un gran poder erosivo, formando los encajados valles en forma de "V" característicos de la cornisa Cantábrica. La actividad humana, cada vez más abundante en ellos por el aumento y concentración constante de la población en los valles, está ejerciendo una fuerte presión sobre estos ríos.

Los principales ríos que dividen la región en otras tantas cuencas hidrográficas son:

El Pico Tres Mares (2175 msnm), en la comarca de Campoo-Los Valles, en el límite con Palencia, separa las tres cuencas hidrográficas; en sus faldas nacen los ríos Híjar, Pisuerga y Nansa que vierten respectivamente al Mediterráneo, Atlántico y Cantábrico. Cantabria es, junto con Castilla y León, la única comunidad autónoma cuyos ríos desembocan en cada uno de los tres mares que rodean la Península Ibérica.

Las diversas altitudes de Cantabria, que van en poca distancia del nivel del mar a los 2600 msnm de La Montaña, hacen que la diversidad vegetal sea grande y exista un amplio número de biotopos.
Cantabria posee una vegetación eurosiberiana, dentro de la provincia Atlántica. Se caracteriza por tener bosques de especies frondosas y caducifolias, como son el roble y el haya. No obstante la acción humana desde tiempos remotos ha favorecido la creación de pastos, propiciando grandes superficies de pastizales y praderías que alimentan al ganado vacuno.

Los prados de pastos se intercalan con plantaciones de eucaliptos ("Eucalyptus globulus") y pequeñas masas de bosques autóctonos de robles y fresnos.

La parte meridional de Cantabria, ya dentro de la comarca de Campoo y limitando con la meseta castellana, se caracteriza por tener un paisaje de transición hacia una vegetación seca, conviviendo variedades bioclimáticas atlánticas y mediterráneas. Su diversidad vegetal está propiciada por localizarse en el límite del dominio biogeográfico mediterráneo, lo que hace que existan especies propias de este bioclima, como son la encina o el madroño, localizados en suelos calizos poco desarrollados y de escasa humedad.

En Cantabria se pueden diferenciar varios niveles florísticos:

Junto a estas características habría también que citar las peculiaridades de la comarca de Liébana, que al poseer un mesoclima particular cercano al mediterráneo también crecen alcornocales, viñedos y olivos, y cuyo grado de degradación por la actividad humana es muy escaso.

En 2013 Cantabria contaba con una población de 591 888 habitantes según datos provisionales del Instituto Nacional de Estadística (representa el 1,24 % de la población de España).

Cantabria solo supera, demográficamente hablando, a una comunidad autónoma, La Rioja (316 474) y a las dos ciudades autonómicas Ceuta (84 672) y Melilla (83 251) (). En cuanto a provincias, ocupa el puesto 28.º de 50 provincias que hay en España ().

Tiene una densidad de población de 110,52 habitantes/km² y una esperanza de vida de 80 años para los varones y 87 años para las mujeres. Según la OMS (Organización Mundial de la Salud), en España (en el año 2005) la esperanza de vida es de 80,3 años de media: 76,9 para los hombres y 83,6 para las mujeres.

Comparada con otras regiones españolas, Cantabria no ha experimentado altas tasas de inmigración, puesto que en 2017 un 4,99 % de la población de Cantabria era inmigrante mientras que en el mismo año en el total de la población española el 9,79 % era inmigrante. Las nacionalidades predominantes son Rumania, Moldavia, Marruecos, Colombia, Perú, República Dominicana, Ecuador y Brasil por este orden.

Las principales poblaciones cántabras se encuentran en la zona litoral. Así, la zona costera ha sufrido una importante urbanización y poblamiento, mientras que las zonas interiores de la Comunidad sufren un elevado despoblamiento. Destacan tres ciudades, la capital cántabra, Santander, con 176.064 habitantes, Torrelavega, como segundo núcleo urbano e industrial de Cantabria, con una población de 54.827 habitantes y Castro Urdiales con 32.309 habitantes (INE 2013). Las dos primeras son los núcleos de una conurbación denominada área metropolitana de Santander-Torrelavega.

Los municipios más importantes desde el punto de vista demográfico (más de 10 000 habitantes; datos INE 2016) son los siguientes:


La provincia de Cantabria es la 23.ª de España en que existe un mayor porcentaje de habitantes concentrados en su capital (29,91 %, frente al 31,96 % del conjunto de España).

La delincuencia se situó en 2011 en niveles muy bajos con respecto a la media de España, con una tasa de delitos de 29,5 infracciones penales por cada mil habitantes (la media española se sitúa en 45,1 y en torno a 70 la de la UE).

El idioma oficial de Cantabria es el español, siendo hablado en todo el territorio de la Comunidad. En Cantabria también existe el cántabro o montañés, un habla de transición entre el asturleonés y el Idioma español que hoy en día está prácticamente desaparecido y está restringido a algunas zonas rurales del interior y a personas de avanzada edad; recientemente se han llevado a cabo algunas iniciativas para proteger el cántabro, pero a día de hoy no cuenta con ningún tipo de reconocimiento oficial ni protección institucional.

En los años 2010, 2011 y 2012 el Centro de Investigaciones Sociológicas (CIS) de España llevó a cabo un estudio en Cantabria entrevistando a 1398 personas. del cual se desprendieron los siguientes datos:

La primera presencia humana en la cornisa cantábrica data de hace 200.000 años (Paleolítico). Los Homo Erectus, asentados durante un período interglaciar, se organizaban en clanes seminómadas dedicados a la caza y la recolección, y fabricaban bifaces. Durante la glaciación de Würm el hombre de Neanderthal ocupó las cuevas y desarrolló una importante industria lítica (puntas, raederas, raspadores, denticulados) que será llevada a su cenit (azagayas, bastones perforados) por el "Homo sapiens" durante el Paleolítico Superior.

El arte que desarrolló aquel hombre de las cavernas, rupestre y mobiliar, se encuentra a lo largo de una extensa nómina de cuevas cántabras (Altamira, El Castillo, La Pasiega, Las Monedas, Covalanas, Hornos de la Peña, El Pendo). Practicaban grabado, pintura y ciertos atisbos de escultura, representando sus presas de caza (ciervo, caballo, bisonte, reno), motivos geométricos y simbólicos, pero rara vez la figura humana y nunca sus enemigos depredadores.

La revolución neolítica –aparición de sociedades productoras-, iniciada en el Mediterráneo, llega al Cantábrico con un importante desfase cronológico, convirtiéndolo en una región marginal en la que durante mucho tiempo coexistirán sociedades cazadoras-recolectoras y productoras (agrícolas-ganaderas). Culturalmente destaca el megalitismo, vinculado a la ganadería trashumante.

Los romanos se encontraron en Cantabria con una sociedad clánica sin unidad política que habitaba en castros (poblados fortificados) y practicaba el pillaje en la Meseta para equilibrar su frágil economía. Ello, los recursos mineros, la voluntad de cerrar las fronteras del Imperio y la búsqueda de laureles de victoria llevaron a Octavio Augusto a iniciar la invasión de la región en 29 a. C.. La romanización en Cantabria fue tardía, centrada en la explotación minera y ganadera, la cual marcó la disposición de las comunicaciones, dispuestas para el transporte de las mercaderías y mercancías. Como urbes solo destacan Julióbriga y Flavióbriga.

La sociedad visigoda sucedió a la romana, y en 574 Leovigildo estableció su dominio en la Cordillera, fundando el Ducado de Cantabria como marca defensiva con capital en Amaya. A comienzos del siglo VIII la invasión islámica alcanza Peña Amaya, empujando al norte una importante inmigración hispanogoda.

En 722 la victoria de Pelayo en Covadonga permitió la constitución del Reino de Asturias, núcleo político dentro del cual se configurará la sociedad cántabra medieval: asentamiento de aldeas en los valles, implantación de una economía agraria asentada en el cereal, la vid y las frutas y triunfo del cristianismo introducirán el feudalismo en la región, con el desarrollo de señoríos religiosos vinculados a los primeros monasterios (Arte de Repoblación): Santo Toribio, Santa María de Piasca, Santa Juliana, Emeterio y Celedonio, San Pedro de Cervatos, San Martín de Elines.

El avance de la Reconquista hacia el sur marginó de nuevo la región cantábrica, que solo alcanzará un nuevo y relevante papel a partir del siglo XII, con la concesión de fueros a las villas marineras (San Vicente de la Barquera, Santander, Laredo y Castro Urdiales) por parte de la corona castellana para impulsar el comercio de las lanas con el norte de Europa y asegurar las fronteras del reino. Las villas experimentan así un notable crecimiento demográfico y un desarrollo urbano alrededor de la pesca y el comercio, introduciendo el Gótico en la región (destacan las cuatro grandes catedrales). Su prosperidad les lleva a confederarse en la Hermandad de las Cuatro Villas primero y en la Hermandad de las Marismas (1296) con otros puertos del Cantábrico después, sirviendo militarmente al reino en la conquista de las ciudades andaluzas durante el siglo XIII.

La crisis del siglo XIV tiene su reflejo en las guerras de banderizas provocadas por los diferentes linajes que tejían la estructura señorial en Cantabria en pos de la extensión de sus patrimonios (La Vega, Manrique, Velasco). Esta ofensiva señorial desangrará el territorio cántabro (en villas y valles) hasta la imposición de la autoridad real durante el reinado de los Reyes Católicos.

Durante la Edad Media se articuló la estructura administrativa cántabra a través de concejos, juntas (o valles) y merindades ("Becerro de las Behetrías", 1352) , con la posterior implantación de los corregimientos como instituciones de control estatal: uno para Asturias de Santillana, Campoo y Liébana y otro para las Cuatro Villas y Trasmiera.

El fin de la Edad Media en el siglo XV no alterará la situación de desvertebración política y administrativa de Cantabria, compartimentada en villas y valles, realengo y señoríos, costa e interior. El siglo XVI marcará, además, la crisis de las villas marineras, afectadas por las distorsiones económicas provocadas por las guerras de hegemonía de los Austrias y por la sucesión de hambrunas y plagas entre finales de la centuria y la primera mitad del XVII. Por otro lado la introducción desde América de nuevos productos agrícolas, especialmente el maíz, mejorará la precaria dieta posibilitando una recuperación demográfica que se sostendrá a lo largo del siglo XVIII. A partir de la apertura del Camino de las Harinas en 1753 Santander, convertida en el puerto de Castilla hacia América (Reales Decretos de 1765 y 1778), experimentará un fuerte desarrollo alrededor de las actividades comerciales: creación del Obispado en 1754, concesión del título de ciudad en 1755, creación del Consulado del Mar en 1785.

Los proyectos de unidad de las comarcas cántabras toman fuerza según se aproxima el final de la Edad Moderna, partiendo de dos ámbitos. Uno, tradicional, desde el Partido de las Cuatro Villas (buscando la defensa de sus exenciones fiscales) o desde la Provincia de los Nueve Valles que daría lugar a la Provincia de Cantabria de 1778. Otro, vinculado a la burguesía santanderina, será el que triunfe con la creación de la Provincia de Santander en 1801 y su restauración definitiva en 1833 dentro del esquema territorial implantado por Javier de Burgos.

Durante el XIX se inician y desarrollan procesos que configurarán la Cantabria contemporánea.

Los cambios iniciados en la anterior centuria se aceleran y profundizan, evolucionando la Provincia hacia lo que será la Comunidad Autónoma creada en 1981.

Tras la aprobación de la Constitución española de 1978 se abre la puerta al camino de las autonomías para las regiones españolas. La incipiente comunidad de Castilla y León pretendió en un primer momento integrar a la antigua provincia de Santander dentro de su proyecto estatutario, pero las presiones de los municipios y las autoridades cántabras impulsaron un proyecto de Estatuto para la región que fue apoyado por la Asamblea regional, así como por 87 de los 102 municipios cántabros.

En 1979 se inicia la redacción del Estatuto, que sería aprobado por las Cortes Generales en 1981. Finalmente, el 1 de febrero de 1982 entra en vigor el Estatuto de Autonomía de Cantabria que convierte oficialmente a la antigua provincia de Santander en la comunidad autónoma de Cantabria.

El Estatuto de Autonomía de Cantabria del 30 de diciembre de 1981 establece que Cantabria encuentra en sus instituciones la voluntad de respetar los derechos fundamentales y libertades públicas, a la vez que se afianza e impulsa el desarrollo regional sobre la base de unas relaciones democráticas. En este documento se recogen las competencias de la Comunidad Autónoma que han sido transferidas desde el Gobierno de España, cabe destacar que aún quedan algunas no transferidas, al igual que en otras Comunidades.

El Parlamento de Cantabria es la principal institución de autogobierno de la Comunidad Autónoma, siendo el órgano representativo del pueblo cántabro. En la actualidad está constituido por treinta y nueve diputados elegidos por sufragio universal, igual, libre, directo y secreto.

Las funciones principales del Parlamento son: ejercer la potestad legislativa, aprobar los presupuestos de la Comunidad Autónoma, impulsar y controlar la acción del gobierno y desarrollar las demás competencias que le confiere la Constitución española, el Estatuto de Autonomía para Cantabria y las demás normas del ordenamiento jurídico.

El presidente de la comunidad autónoma ostenta la más alta representación de la misma y la ordinaria del Estado en Cantabria y preside, dirige y coordina su actuación. Será elegido por el Parlamento de entre sus miembros, previa consulta con las fuerzas políticas representadas en el mismo, y nombrado por el Rey. Presentará su programa al Pleno de la Cámara y, deberá contar con la mayoría absoluta o simple en segunda votación.

El Gobierno de Cantabria es el órgano encargado de dirigir la acción política y ejerce la función ejecutiva y la potestad reglamentaria de acuerdo con la Constitución, el Estatuto y las leyes. El Gobierno estará compuesto por el presidente, el vicepresidente, en quien podrá delegar temporalmente sus funciones ejecutivas y de representación el Presidente, y los consejeros, que serán nombrados y cesados por el presidente.

Las elecciones autonómicas son cada cuatro años coincidiendo con las elecciones municipales. De esta forma, en las elecciones autonómicas se eligen los diputados del Parlamento de Cantabria. Los 39 diputados que constituyen el Parlamento de Cantabria actualmente son elegidos por sufragio universal, igual, libre, directo y secreto. Las primeras elecciones al Parlamento de Cantabria se celebraron el 8 de mayo de 1983.

Tras varias legislaturas presididas por el Partido Popular de Cantabria o por la UPCA de Juan Hormaechea, el Gobierno de Cantabria estuvo entre las elecciones autonómicas del año 2003 y las de 2011 dirigido por una coalición entre el Partido Regionalista de Cantabria y el Partido Socialista de Cantabria-PSOE. En este periodo, el presidente de Cantabria fue Miguel Ángel Revilla (PRC) y su vicepresidenta, Dolores Gorostiaga (PSC-PSOE). Tras las elecciones autonómicas del año 2011, en las que por primera vez el PP consiguió una mayoría absoluta en la cámara, con 20 diputados, su candidato Ignacio Diego fue nombrado presidente de Cantabria. El pacto PRC-PSOE se reeditó en 2015, otorgando de nuevo la presidencia a Miguel Ángel Revilla.

Ideológicamente, Cantabria es en conjunto una comunidad conservadora si se compara con otras zonas de España. En el presente período democrático, los partidos conservadores (Coalición Popular / Partido Popular) han sido casi siempre la lista más votada, a pesar de que se han dado pactos entre otros partidos que han permitidos otros gobiernos. En esta tendencia resulta clave el peso de la capital, Santander, tradicionalmente muy conservadora. Las zonas industriales de la comunidad como Torrelavega o Reinosa, así como algunas localidades costeras con población más joven es en general donde los partidos progresistas logran más votos.

Las siguientes tablas muestran los resultados de las elecciones al Parlamento de Cantabria de 2003, 2007, 2011 y 2015.


La Ley 8/1999 de Comarcas de la Comunidad Autónoma de Cantabria del 28 de abril de 1999 establece que la comarca es una entidad necesaria integrante de la organización territorial de la comunidad. Con esta ley se abre el desarrollo a la comarcalización en Cantabria fomentándose la creación de entidades comarcales, proceso el cual apenas se ha desarrollado. Asimismo, señala que la creación de las comarcas no exigirá su generalización a todo el territorio de la comunidad autónoma mientras no se haya producido la comarcalización del 70 % del territorio de la comunidad. De igual forma dilucida que la ciudad de Santander no se regirá por dicha ley de comarcalización, teniendo en cambio que establecer su propia área metropolitana.

Actualmente las comarcas en Cantabria no tienen un carácter administrativo y apenas sí están definidas. Únicamente Liébana, por su condición geográfica en los Picos de Europa, Trasmiera y Campoo, en el valle del Ebro se establecen como comarcas claramente definidas en la comunidad. No obstante se pueden establecer diferencias funcionales en el territorio que dividen Cantabria a modo de comarcas:


En relación con los rasgos físicos del medio natural Cantabria se dividen en diez comarcas que atienden a las diferentes franjas bastante definitorias en que se fracciona el territorio de la comunidad.


A partir del siglo XIII la organización de Cantabria en valles, típica de todo el norte de España, fue sustituida por las ciudades, villas o comarcas históricas que agrupaban valles.

En la actualidad el número de municipios en Cantabria asciende a 102. Por lo general estos poseen varias localidades y estas varios barrios. Algunos municipios tienen el nombre de una de sus localidades (sea su capital o no) y otros no comparten nombre con ninguna de sus localidades. Cada municipio está regido por su propio ayuntamiento.

Uno de los municipios de Cantabria, llamado Valle de Villaverde, es un enclave cántabro rodeado completamente por la provincia de Vizcaya (País Vasco).

La Mancomunidad Campoo-Cabuérniga no constituye "per se" un municipio, aún a pesar de la extensión de su territorio. Se trata de una gran propiedad comunal singular por su tamaño y características, de gestión compartida entre los municipios de la Hermandad de Campoo de Suso, Cabuérniga, Los Tojos y Ruente. En esta finca de montaña, destinada al pasto en sus brañas de ganado vacuno de raza tudanca fundamentalmente y caballar en menor medida, perviven tradiciones ganaderas transterminantes.

De acuerdo con la Contabilidad Regional que realiza el Instituto Nacional de Estadística, en el año 2007 el PIB per capita de Cantabria era de 23 377 euros por habitante, similar a la media española que se sitúa en 23 396 euros y por debajo de los 29 455 € de la UE de los 25. El PIB en términos reales es de un 4,1 %, dos décimas por encima de la media nacional (3,9 %) en el mismo periodo. En el segundo trimestre de 2011 la tasa de paro en Cantabria se situaba en el 14,8 % de la población activa, frente al 20,89 % de la media de España.
Cantabria ha llevado a cabo desde 1994 una paulatina convergencia con las regiones europeas más desarrolladas, la cual fue posible gracias a su inclusión durante seis años en la lista de regiones Objetivo 1 y por la que percibió subvenciones a fondo perdido para su desarrollo. El éxito económico llevó parejo la pérdida progresiva de estos fondos de cohesión que venía percibiendo desde 1994-1999. En 1999 finaliza el programa marco financiero de la UE y al hacer los cálculos para el nuevo periodo 2006-2007 Cantabria es excluida del Objetivo 1. Dado que su salida fue muy cuestionada debido a que superaba mínimamente el límite establecido del 75 % de PIB per cápita, fue considerada región Objetivo 1 «en situación transitoria». En el año 2007 los Fondos Europeos de Desarrollo Regional (FEDER) disminuyeron un 46,2 % como consecuencia de la conclusión del periodo transitorio de salida del Objetivo 1 y la entrada en el Objetivo 2.

Cantabria cuenta con un sector primario en retroceso que ocupa al 5,8 % de la población activa con ganadería vacuna, lechera tradicionalmente y cárnica en los últimos tiempos; agricultura, destacando el maíz, patatas, hortalizas y plantas forrajeras; pesca marítima; y minería del zinc y canteras.

En el sector secundario asienta el 30,4 % de la población activa. En la industria destacan la siderúrgica, la alimentaria, la química, la papelera, la textil, la farmacéutica, equipos industriales y de transporte, etc. En la construcción se empiezan a notar síntomas de estancamiento, si bien sigue siendo el mayor activo de éste sector.

El sector terciario emplea al 63,8 % de la población activa y va en aumento, siendo este hecho sintomático de la concentración de la población en los centros urbanos y de la importancia que el turismo (especialmente el rural) ha adquirido en los últimos años. Como entidades bancarias principales de la comunidad autónoma, destaca la Caja Cantabria que en la actualidad gestiona un volumen de negocio cercano a los 10 800 millones de euros, y el Banco Santander que dio lugar al Grupo Santander, con 129 000 empleados, 66 millones de clientes, 10 200 sucursales y 2,4 millones de accionistas en todo el mundo. El grupo se encuentra entre las diez primeras entidades financieras del mundo y es el mayor banco de la Zona Euro. En lo relativo a la venta de vehículos, en 2013 bajó un 2,6 % con respecto al mismo mes del año anterior. En cambio en el resto de España la venta de coches ha crecido un 10 %. Al parecer, el objetivo del plan PIVE-2 de renovar el parque automovilístico no está causando el efecto esperado en Cantabria, a pesar de ser una de las comunidades autónomas con mayor número de concesionarios por habitante.

La consecuencia más significativa que se deriva de la fuerte energía del relieve del territorio cántabro es la existencia de barreras topográficas que condicionan decisivamente el trazado de las infraestructuras de conexión, tanto perpendicular, en sus accesos a la meseta castellana, como trasversal, en la comunicación entre valles, así como su elevado coste de construcción y mantenimiento.

Las insuficiencias en la dotación de infraestructuras de transporte de competencia estatal, fundamentalmente en lo que se refiere a comunicación con la meseta por carretera y por ferrocarril, y el importante coste por kilómetro lineal de construcción debido a su difícil orografía, ha supuesto un significativo déficit en las comunicaciones de Cantabria con el exterior.

Según el Ministerio de Fomento, Cantabria cuenta con 2393 km de carreteras convencionales y 206 km de autovías o autopistas.

El Aeropuerto de Santander, único aeródromo de Cantabria destinado al tráfico regular de viajeros, ha visto crecer mucho el tráfico de viajeros desde que en 2003 empezase a operar en él la aerolínea de bajo coste "Ryanair". En la actualidad desde el aeropuerto se puede volar a diferentes destinos nacionales e internacionales.

En conjunto las principales infraestructuras de comunicación de la comunidad son:

El número de lectores de prensa en Cantabria se sitúa por encima de la media española, con más de 100 ejemplares por cada 1000 habitantes. Los principales periódicos son "El Diario Montañés", fundado en 1902, y "Alerta", fundado en 1937, con una tirada en el primero de los casos de 45 000 ejemplares.

En la Comunidad Autónoma existe un predominio claramente superior de la prensa cántabra frente a la de cobertura estatal, siendo una de las regiones donde este dato es más abrumador. Así, existen casos como el del citado periódico decano de la prensa cántabra y uno de los más importantes a nivel regional en España, El Diario Montañés, que acapara más del 60 % del mercado cántabro.

La Guerra Civil Española dio al traste con un panorama de prensa diaria mucho más extenso que el actual y que había abarcado el último tercio del siglo XIX y los primeros treinta años del XX. Desaparecerían tres de las cabeceras históricas que habían marcado una época hasta entonces: "El Cantábrico", "La Región" y "La Voz de Cantabria".

En los últimos años, aprovechando las facilidades para la difusión que ofrecen las nuevas tecnologías, han surgido en la comunidad nuevas alternativas de periodismo digital mediante ediciones electrónicas de periódicos impresos o el nacimiento de otros nuevos que tienen en Internet su único canal de difusión. Junto a estos nuevos modelos aparecen iniciativas de prensa de distribución gratuita siguiendo el ejemplo de otros muchos proyectos semejantes en España y el resto de Europa.

En febrero de 2008 el diario "El Mundo" lanzó una separata con una edición para Cantabria, "El Mundo Hoy en Cantabria". En junio de ese mismo año, el Grupo Digital 2006 publicó en Cantabria el nuevo periódico "Aquí Diario", intentando cubrir la demanda de medios de izquierda en la región. Desde octubre del mismo año, "Aquí Diario" se vendió exclusivamente junto con el diario "Público" hasta que este dejó de editarse.

Actualmente hay diversos periódicos de difusión gratuita en la región, tales como "Pueblos" (semanal, distribuido en toda la región), "Qué!" (diario), "Gente en Santander" (distribuido semanalmente, solamente en Santander), "Rakeros" (distribuido semanalmente, solamente en Santander), "En Titulares" (distribuido semanalmente, solamente en Santander), "Diagonal Cantabria" (separata bimensual del periódico quincenal Diagonal). En el año 2008 se lanzó el periódico quincenal Ciudad del Besaya, que se reparte en la comarca del Besaya.

A diferencia de la prensa escrita, la radio en Cantabria ha experimentado en las últimas décadas un constante crecimiento. Radio Santander fue la pionera, casi simultáneamente con Radio Torrelavega (EFJ 44), que fue la primera en pasar de la OM a la FM y posteriormente también la que dotó a sus emisiones de la estereofonía. Años más tarde llegaron en los años sesenta y setenta, la COPE (la antigua Radio Popular) y más tarde Radio Nacional de España.

En los años noventa hicieron su aparición las emisoras de frecuencia modulada, destacando Onda Cero, viendo la luz una gran cantidad de radios de ámbito regional y local, algunas de legalidad incierta. Esto dio lugar incluso a denuncias por parte de la Dirección General de Aviación Civil por interferencias en el espectro de radiofrecuencias destinadas a la navegación aérea por la potencia con que emitían ciertas de ellas desde Peña Cabarga y, en algunos casos, desde emplazamientos no autorizados. Gran parte de estos problemas se fundamentaban en la permisividad de los estamentos públicos competentes ante la ocupación fraudulenta del espacio radioeléctrico. Se intentó resolver esta cuestión mediante concursos públicos para asignar nuevas frecuencias a emisoras que en aquel momento se encontraban en un limbo jurídico y que en muchos casos resultaron polémicos. Ante el anuncio del Gobierno regional de abrir expedientes sancionadores han surgido plataformas que agrupan a radios independientes que siguen careciendo de licencias.

Según diversos autores, es de esperar que estos problemas de gestión del espectro radioeléctrico se superen con la implantación de la radio digital terrestre y con ello la arbitraria política de atribución de frecuencias radiofónicas que ha sido una constante en España desde los años setenta. No obstante en Cantabria aún no se ha convocado concurso alguno para asignación de licencias para emisiones DAB.

Cantabria carece de canal de televisión autonómico público. En 1989 el gobierno de Cantabria, bajo la presidencia de Juan Hormaechea, adquirió equipamiento destinado a un centro emisor de producción de televisión pero el cambio de gobierno y el gran coste que suponía hizo que finalmente el proyecto se desechara y el material vendido. Actualmente no existen planes de retomarlo y la presidencia de gobierno ya ha señalado que la creación de una televisión autonómica no es una prioridad.

En 1984 se crea el Centro Regional de TVE en Cantabria y en 1996 inician sus emisiones las primeras televisiones locales.
Con el apagón analógico y el paso a la Televisión Digital Terrestre el Gobierno de Cantabria contempló inicialmente la difusión de la señal mediante transmisión vía satélite a los hogares, dado que se consideraba que esta era la única tecnológica que garantizaba una completo desplìegue de la señal en Cantabria debido al fuerte perfil montañoso de la región. Pero en noviembre de 2008 el gobierno regional decidió rescindir el contrato con la empresa ganadora del concurso público al considerar inviable la implantación del servicio concertado y dado que desde el Gobierno de España se concedió ayudas a las comunidades autónomas para la instalación de repetidores digitales terrestres que permitiese el despliegue de la TDT, a las que se acogió Cantabria. Este hecho provocó que la empresa adjudicataria SES Astra demandase al Gobierno de Cantabria ante los tribunales por incumplimiento de contrato, siendo condenado este último en 2013 al pago de 1,4 millones de euros.
El 30 de enero de 2009, el Gobierno de Cantabria convocó un nuevo concurso para el reparto de las licencias locales de radio y televisión digital terrestre a la que no se presentó buena parte de las emisoras candidatas debido a las fuertes garantías provisionales que se exigían y ante las incertidumbres sobre la rentabilidad.

"Artículos principales: , Playas de Cantabria, Flora de Cantabria y Fauna de Cantabria".

Desde el punto de vista de su flora, Cantabria se localiza entre dos regiones biogeográficas. La mayoría del territorio pertenece a la región Eurosiberiana, pero el extremo meridional forma parte de la región Mediterránea. Esta situación fronteriza tiene un efecto directo en las características del paisaje vegetal de la región, en el que se entremezclan especies mediterráneas y especies atlánticas, que enriquecen la composición botánica de los distintos ecosistemas existentes.


La fauna de Cantabria posee una riqueza que se puede considerar elevada, tanto en número de especies como en la importancia y singularidad de algunas de ellas, debido a su todavía elevado grado de naturalidad, variedad de medios y a su situación geográfica. La mayoría del territorio pertenece a la región Eurosiberiana, pero el extremo meridional forma parte de la región Mediterránea. Esta situación fronteriza tiene un efecto directo en las características de la fauna de la región y hace que coincidan especies mediterráneas y especies atlánticas.


A pesar de su escaso tamaño, Cantabria posee un buen número de espacios protegidos. Integran la Red de Espacios Protegidos de Cantabria:
El más importante de ellos es el Parque Nacional de los Picos de Europa, que afecta además de a Cantabria a Castilla y León y Asturias y cuya gestión comparten las tres comunidades autónomas.

Por otra parte Cantabria cuenta con 8 Zonas de Especial Protección para Aves (ZEPAS): Marismas de Santoña, Victoria y Joyel y Ría de Ajo, Liébana, Desfiladero de La Hermida, Sierra de Peña Sagra, Sierra de Híjar, Sierra del Cordel y cabeceras del Nansa y Saja, Embalse del Ebro y Hoces del Ebro.

Además existen 21 Lugares de Importancia Comunitaria (LIC): Liébana, Montaña Oriental, Rías occidentales y Duna de Oyambre, Dunas de Liencres y Estuario del Pas, Dunas del Puntal y Estuario del Miera, Costa Central y Ría de Ajo, Marismas de Santoña, Victoria y Joyel, Sierra del Escudo de Cabuérniga, Valles altos del Nansa y Saja y Alto Campoo, Sierra del Escudo, Río Deva, Río Nansa, Río Saja, Río Pas, Río Miera, Río Asón, Río Agüera, Río y Embalse del Ebro, Río Camesa y 2 cavidades con importantes colonias de quirópteros.

Cantabria pertenece a una unidad cultural común que comparte, pese a las diferencias regionales, con las comunidades del norte de España bañadas por las costa cantábrica. Esta unidad cultural, que hunde sus raíces en la época prerromana, ya fue reconocida en el siglo I por el geógrafo griego Estrabón:

No obstante esta unidad cultural de la fachada atlántica no significa una homogeneización cultural de las sociedades de este ámbito geográfico. Dentro de todo este conjunto, Cantabria posee una indudable personalidad etnográfica, que la distingue por el este y el oeste de vascos y asturianos, así como naturalmente de los habitantes de la Tierra de Campos por el sur. Para conocer a fondo la estructura cultural regional hay que entender la naturaleza de su territorio, dividido en valles, más o menos aislados entre sí. La fuerte compartimentación del territorio, como consecuencia de una robusta orografía, ha generado una marcada división interna de Cantabria, con unas difíciles comunicaciones trasversales entre valles, siendo ésta una cuestión imprescindible para poder entender el conjunto de las tradiciones y costumbres de la región.

Es este relieve abrupto, y el consecuente tipo de explotación que los cántabros ha venido ejerciendo desde tiempo inmemorial del territorio, otro de los factores distintivos a la hora de definir la realidad cultural de Cantabria: poblamientos tendentes a la concentración en las comarcas centrales y occidentales, y dispersos o ultradispersos en la zona oriental y de manera especial en la comarca pasiega, es decir, en las cabeceras del río Pas y del Miera.

Una de las peculiaridades más características de Cantabria es el modelo, muy definido, de vivienda tradicional montañesa, con tejado a dos aguas y fachada principal en una de las caídas. En ella es muy frecuente la solana o balcón corrido de madera, protegido bajo el alero. Este modelo, que tiene variantes según las comarcas, ha dado origen a la típica casona montañesa, uno de cuyos elementos es la portalada, por lo general timbrada con escudo de armas, la cual da acceso a la corralada. Pero existen también otros modelos de casas, siendo característica y singular la llamada cabaña pasiega, con la fachada principal en el hastial.

En cuanto al modelo productivo tradicional sus formas no difieren en exceso de lo que es común a las otras regiones del cuadrante noroccidental de la Península Ibérica. Fue a mediados del siglo XX cuando se inició un profundo cambio en la economía agraria de La Marina y los valles prelitorales de Cantabria, cuando las gentes del medio rural empezaron a abandonar la dedicación predominantemente agrícola hasta entonces para entregarse a una actividad ganadera extensiva de parcos rendimientos, sustentada en un territorio con un terrazgo extremadamente fragmentado, que no se ha ido corrigiendo hasta hace unos lustros.

Dentro de este complejo cabe señalar, como muy característico, el uso de un modelo peculiar de carro chillón, con su yugo cornal típico, así como el empleo de la basna. Del mismo modo, y relacionado con las labores del campo destaca la artesanía en aperos y herramientas de labranza realizado frecuentemente con un verdadero gusto artístico, como es el caso de las albarcas y de las colodras.

Es en la cultura inmaterial donde quizá destaca especialmente la particularidad de Cantabria. Además de creencias, mitos y supersticiones propias, hay que señalar la amplia diversidad de su rica literatura oral, compuesta de cuentos, leyendas, romances, trovas, refranes, adivinanzas y oraciones. Pero es aquí donde cabe señalar sobre todo la riqueza de su patrimonio y cultura musical en todas sus variadas formas: desde cantos de cuna, hasta cantares de ronda, pasando por canciones infantiles, tonadas, jotas, picayos, marzas, etc. Muchas de estas melodías van acompañadas de danzas, destacando las modalidades de baile «"a lu altu"» y «"a lu baju"», y entre éstas la famosa Baila de Ibio.

Entre los muchos escritores cántabros o de ascendencia cántabra de prestigio, hay que destacar a los que por su obra han alcanzado renombre nacional y aún universal en el transcurso de la historia:

El español o castellano es la lengua oficial de Cantabria. En la actualidad, el novelista Álvaro Pombo es uno de los escritores con más reconocimiento a escala nacional.

Destaca Marcelino Menéndez Pelayo, polígrafo, político y erudito español, consagrado fundamentalmente a la historia de las ideas, la crítica e historia de la literatura española e hispanoamericana y la filología hispánica en general, aunque también cultivó la poesía, la traducción y la filosofía, hermano del escritor Enrique Menéndez Pelayo.

Otro ilustre es Gerardo Diego, poeta y escritor de la Generación del 27.

El dialecto cántabro o montañés, considerada dentro del sistema lingüístico del asturleonés, no está regulado ni tiene reconocimiento oficial. Quedan restos del montañés con más fuerza en la mitad occidental y en los valles de Pas y de Soba, en la montaña oriental.



En Cantabria se celebran multitud de fiestas patronales, ferias de origen comercial y festividades de origen pagano con mayor o menor pervivencia del folclore tradicional. Las más frecuentes celebran festejos en torno a San Juan y San Miguel.

El segundo domingo de agosto se celebra en Cabezón de la Sal el Día de La Montaña, con motivo del cual se practican multitud de actividades tradicionales como el juego de los bolos, arrastre de bueyes, mercados de artesanía y representación de danzas y música cántabras. Está además considerado de Interés Turístico Nacional.

Además, el día 28 de julio se celebra el Día de las Instituciones de Cantabria en Puente San Miguel (Reocín).

En cuanto a ferias, entendidas como grandes mercados de productos celebrados periódicamente, destaca la Feria de Ganado de Torrelavega celebrada en el Mercado Nacional de Ganado “Jesús Collado Soto” el tercero más grande de España, que aglutina la compraventa de todo tipo de ganado de la región y parte de las regiones colindantes, siendo el principal producto el vacuno. Por toda la región se celebran ferias ganaderas y de productos típicos semanal, mensual o anualmente que congregan a los vecinos de la comarca.




El norte de España es una zona rica en mitología. En toda la Cornisa Cantábrica, desde Galicia hasta el País Vasco, pasando por Asturias y Cantabria, existen ritos, historias y seres imaginarios e imposibles (o no).

En el caso de la mitología de Cantabria ésta hace de los bosques y montañas cántabros lugares mágicos que propician la aparición de leyenda, bien mantenidas en el acervo popular mediante la tradición oral trasmitida de padre a hijos, bien porque recuperadas o ideadas por folcloristas (Manuel Llano Merino y otros).

En su mitología y supersticiones, como en las de toda Europa, podrían subsistir elementos de religiones y creencias precristianas (romanas o prerromanas) que habrían sido más o menos cristianizadas. Cabe destacar, al igual que en otros pueblos, la presencia de seres fabulosos de proporciones gigantes y facciones ciclópeas (los ojáncanus y las ojáncanas), animales fantásticos (el culebre, los Caballucos del Diablu, los ramidrejus, etc.), seres feéricos (las anjanas, las Ijanas del Valle de Aras), duendes (Nuberus, Trentis, Ventolines, Trasgus, Trastolillus), personajes antropomórficos (la Sirenuca, el Hombre pez, la Osa de Andara), etc.


 
El deporte tradicional por antonomasia en Cantabria es el juego de los bolos en sus cuatro modalidades: bolo palma, pasabolo tablón, pasabolo losa y bolo pasiego. El primero es el más extendido, rebasando el propio ámbito regional a la zona oriental de Asturias, y siendo el que mayor complejidad presenta a la hora de jugar. La existencia de boleras o "corros" destinados al juego de los bolos es importante en todos los núcleos de población de Cantabria, localizándose generalmente próximos a la iglesia o bar del pueblo.

Desde finales de los años ochenta, los bolos viven una época de consolidación con la potenciación de las escuelas de bolos, impulsadas por los diferentes ayuntamientos e instituciones cántabras; las competiciones de Liga, Copa y Circuitos Regionales o Nacionales o su expansión mediática motivado por el interés social.

Como en toda la costa norte de España, especialmente en Cantabria y el País Vasco, el remo es un deporte muy tradicional en las localidades costeras. Los orígenes del remo se remontan varios siglos atrás, cuando varias traineras de cada pueblo se disputaban la venta del pescado, que se reservaba a la embarcación que antes llegase a la lonja. Fue a finales del siglo XIX cuando el trabajo se convirtió en deporte y se comenzaron a organizar regatas entre localidades del Cantábrico. Los clubes de Cantabria, especialmente Castro Urdiales, Astillero, y Pedreña son tres de los más laureados en la historia de este deporte y actualmente atraviesan unos de sus mejores momentos deportivos tras décadas de sequía de trofeos.

El salto pasiego es otro de los deportes rurales destacados de la región y un claro ejemplo de como el uso de una habilidad o técnica de trabajo va desapareciendo con el paso del tiempo, dando lugar a la competición y al juego. Similar en concepción a otro tipo de modalidades como el salto del pastor canario, en un principio esta técnica se utilizaba en los valles pasiegos para salvar las paredes de piedra que limitaban los prados, los bardales, arroyos, barrancos, etc. que obstaculizaban el paso en la abrupta topografía de las zonas altas de Cantabria.

Dentro de los deportes de masas, Cantabria está presente en competiciones nacionales e internacionales a través de equipos como el Racing de Santander o la Gimnástica de Torrelavega, en fútbol; el Balonmano Cantabria que ha ganado varias ligas y copas del Rey así como títulos internacionales, en balonmano, el Cantabria Lobos, que ha militado en la ACB en baloncesto y el Estela Santander que milita en LEB, y también está representado en la máxima categoría del ciclismo mundial como es el equipo UCI Pro Tour, Footon-Servetto así como su filial el Trasmiera-Fuji, el Camargo FerroAtlantica o el Cuevas El Soplao en categoría amateur.

El Rally de Cantabria forma parte del Campeonato de España de Rallyes desde 1989.

Cabe mencionar en el aspecto individual a deportistas de la talla de José Manuel Abascal, Severiano Ballesteros, Óscar Freire, María Pardo, Francisco Gento y Carlos Alonso González (santillana).




</doc>
<doc id="11337" url="https://es.wikipedia.org/wiki?curid=11337" title="Estelas cántabras">
Estelas cántabras

Las estelas cántabras son discos de piedra monolíticos de diferentes dimensiones, cuyos primeros ejemplares fueron tallados en los siglos previos a la romanización de Cantabria. En su ornamentación habitual figuran esvásticas, trisqueles, cruces, hélices, aspas, guerreros o representaciones funerarias pre-romanas. La más famosa es la llamada "Estela de Barros" la cual puede verse en el "Parque de Las Estelas" de la localidad de Barros, en Los Corrales de Buelna (Cantabria). Esta estela forma parte del actual escudo de Cantabria y el significado del tetrasquel está relacionado con el culto lunar. En el "Parque de las Estelas" además de la famosa "Estela" o "Rueda de Barros" (cómo se la conoce en la zona), podemos apreciar otra estela de mayor tamaño. La "Estela de Barros" es una estela discoide gigante, tipo que llama mucho la atención y que supone, precisamente por su tamaño, una de las mayores diferenciaciones con las estelas encontradas en otros lugares del norte de España.

Otras estelas encontradas están expuestas en el "Museo Regional de Prehistoria y Arqueología de Cantabria" en Santander. Se trata de dos estelas halladas en Lombera conocidas como Primera y Segunda estela de Lombera, otra encontrada en Zurita que lleva decoración iconográfica (en una de sus caras observamos como un buitre se abalanza sobre un guerrero caído) y otra más proveniente de las cercanías del castro de la Espina del Gallego. A su vez, se han encontrado fragmentos de otras estelas cántabras, como la tercera de Lombera, y el de la Estela de San Vicente de Toranzo, donde en una de sus caras aparece representado un guerrero cántabro a caballo, además de otras menores.

Las estelas cántabras son el testimonio más importante de los pueblos cántabros prerromanos y uno de los signos más representativos de la Cantabria actual, y se siguieron utilizando en Cantabria durante la Edad Media e incluso durante el periodo Barroco, a semejanza de las antiguas, pero perdiendo en parte su forma discoide y sustituyéndose los motivos solares centrales por cruces. Las estelas discoideas medievales y modernas fueron también típicas de otras regiones del norte peninsular, encontrándose numerosos ejemplares, además de en Cantabria, en el País Vasco, y varios en Navarra.

Las estelas tienen un importante simbolismo en la actual Cantabria. El Escudo de la Comunidad representa una estela y también una interpretación contemporánea de estas estelas da origen al Lábaru, una bandera de uso muy extendido en Cantabria. De la misma manera, los canteros y artistas de muchos lugares de Cantabria reproducen antiguas estelas o crean otras nuevas semejantes a aquéllas, labradas en piedra o madera, que sirven como adornos a veces de nuevas construcciones. De la misma manera las reproducciones de estelas, en madera o metálicas, son habituales en colgantes y pequeñas figuras, todo lo cual da una idea de la importancia que tienen como símbolo regional.

Aunque los antiguos cántabros produjeron muchas estelas, las más conocidas son las estelas gigantes, de las cuales se conocen cinco, habiéndose descubierto cuatro de ellas en el valle de Buelna. Habitualmente están fechadas entre los siglos I a.C. y I d.C., si bien hay divergencias y algunas podrían ser incluso de los siglos V o VI a.C.



</doc>
<doc id="11338" url="https://es.wikipedia.org/wiki?curid=11338" title="Existencialismo">
Existencialismo

El existencialismo es una corriente filosófica que tuvo su origen en el siglo XIX y se prolongó aproximadamente hasta la segunda mitad del siglo XX. Los filósofos existencialistas se centraron en el análisis de la condición humana, la libertad y la responsabilidad individual, las emociones, así como el significado de la vida.

No se trata de una escuela filosófica homogénea ni sistematizada, y sus seguidores se caracterizan principalmente por sus reacciones contra la filosofía tradicional. Actualmente se consideran tres tipos de "escuelas" existencialistas: el existencialismo cristiano, el existencialismo agnóstico y el existencialismo ateo.

Nunca existió un acuerdo general sobre la definición de existencialismo. El término a menudo es visto como una conveniencia histórica que fue inventada para describir a muchos filósofos, en retrospectiva, mucho después de haber muerto. De hecho, aunque generalmente se considera que el existencialismo se originó con la obra de Kierkegaard, fue Jean-Paul Sartre el primer filósofo prominente en adoptar el término para describir su propia filosofía. Sartre propone la idea de que «"Todos los existencialistas tienen en común la doctrina fundamental de que la existencia precede a la esencia»" lo que significa que la consideración más importante para la persona es el hecho de ser un ser consciente que actúa de forma independiente y responsable: «la existencia», en lugar de ser etiquetado con roles, estereotipos, definiciones u otras categorías preconcebidas que se ajustan al individuo: «la esencia». La vida real de la persona es lo que constituye lo que podría llamarse su «verdadera esencia» en lugar de estar allí atribuido a una esencia arbitraria que otros utilicen para definirla.

Según el filósofo Steven Crowell, definir el existencialismo ha sido relativamente difícil, y argumenta que se comprende mejor como un enfoque general que se utiliza para rechazar ciertas filosofías sistemáticas, y no como una filosofía sistemática en sí.

Uno de sus postulados fundamentales es que en el ser humano "la existencia precede a la esencia" (Sartre), es decir, que no hay una naturaleza humana que determine a los individuos, sino que son sus actos los que determinan quiénes son, así como el significado de sus vidas. El existencialismo defiende que el individuo es libre y totalmente responsable de sus actos. Esto incita en el ser humano la creación de una ética de la responsabilidad individual, apartada de cualquier sistema de creencias externo a él.

En líneas generales el existencialismo busca una ética que supere a los moralismos y prejuicios; esto, al observador neófito puede resultarle contradictorio, ya que la ética buscada por el existencialismo es una ética universal y válida para todos los seres humanos, que muchas veces no coincide con los postulados de las diversas morales particulares de cada una de las culturas preexistentes.

Algunos consideran que el existencialismo en sí atraviesa a toda la historia de la humanidad (por ejemplo en la sumeria Epopeya de Gilgamesh se encuentran planteamientos llenos de angustia, esperanza, duelo, melancolía, anhelos de eternidad, que luego reiterará siempre el existencialismo) ya que sus temas son los capitales de cada ser humano y de todo el conjunto de la humanidad.

El existencialismo tiene sus antecedentes en el siglo XIX en el pensamiento de Søren Kierkegaard y Friedrich Nietzsche. También, aunque menos directamente, en el pesimismo de Arthur Schopenhauer, así como en las novelas de Fiódor Dostoyevski. En el siglo XX, entre los filósofos más representativos del existencialismo se encuentran Martin Heidegger, Karl Jaspers, Jean-Paul Sartre, Miguel de Unamuno, Simone de Beauvoir, Gabriel Marcel y Albert Camus.

Sin embargo, el existencialismo adquiere su nombre en el siglo XX y, particularmente, tras las terriblemente traumáticas experiencias que vivió la humanidad durante la Primera Guerra Mundial y la Segunda Guerra Mundial. Durante estos dos conflictos (que podrían ser calificados por una parte como casos extremos de la estupidez que puede tener la humanidad y por la otra -concordando con Hannah Arendt- como las formas en las que la violencia humana llega a su apogeo con la banalización del mal) surgieron los pensadores que luego se preguntaron ¿qué sentido tiene la vida?, ¿para o por qué existe el ser? y ¿existe la libertad total?

El existencialismo nace como una reacción frente a las tradiciones filosóficas imperantes, tales como el racionalismo o el empirismo, que buscan descubrir un orden legítimo dentro de la estructura del mundo observable, en donde se pueda obtener el significado universal de las cosas. Entre los años 1940 y 1950, existencialistas franceses como Jean-Paul Sartre, Albert Camus y Simone de Beauvoir dieron a conocer escritos académicos o de ficción que popularizaron temas existenciales del tipo de la libertad, la nada, el absurdo, entre otros. Walter Kaufmann describió el existencialismo como "el rechazo a pertenecer a cualquier escuela de pensamiento, el repudiar la adecuación a cualquier cuerpo de creencias, y especialmente las sistemáticas, y una marcada insatisfacción hacia la filosofía tradicional, la cual tacha de superficial, académica y alejada de la vida".

Al existencialismo se le ha atribuido un carácter vivencial, ligado a los dilemas, estragos, contradicciones y estupidez humana. Esta corriente filosófica discute y propone soluciones a los problemas más propiamente inherentes a la condición humana, como el absurdo de vivir, la significancia e insignificancia del ser, el dilema en las guerras, el eterno tema del tiempo, la libertad, ya sea física o metafísica, la relación dios-hombre, el ateísmo, la naturaleza del hombre, la vida y la muerte. El existencialismo busca revelar lo que rodea a la humanidad, haciendo una descripción minuciosa del medio material y abstracto en el que se desenvuelve el individuo (existente), para que éste obtenga una comprensión propia y pueda dar sentido o encontrar una justificación para su existencia. Esta filosofía, a pesar de los ataques provenientes con mayor intensidad de la religiosidad cristiana del siglo XX, busca una justificación para la existencia humana.

El existencialismo, de acuerdo a Jean-Paul Sartre, dice que en la naturaleza humana la existencia precede a la esencia (lo que para algunos es un ataque a dogmas religiosos), pensamiento iniciado por Aristóteles, concretado por Hegel ("Fenomenología del Espíritu": «Si es cierto que el embrión es "en sí" un ser humano, no lo es, sin embargo, "para sí"; para sí el ser humano sólo lo es en cuanto a razón cultivada que se ha "hecho" a sí misma lo que es "en sí"». En esto y solamente en esto reside su realidad'), y proseguido en Sartre, quien indica que los seres humanos primero existimos y luego adquirimos esencia; es decir, sólo existimos y, mientras vivimos, vamos aprendiendo de los demás humanos que han inventado cosas abstractas; desde Dios hasta la existencia de una esencia humana previa, el humano, entiende Sartre, se libera en cuanto se realiza libremente y esa es su esencia, su esencia parte desde sí "para-sí".

En términos de la existencia e importancia de Dios, hay tres escuelas de pensamiento existencialista: el existencialismo ateo (representado por Sartre), el existencialismo cristiano (Kierkegaard, Dostoievski, Unamuno o Gabriel Marcel) y el agnóstico (Camus, Heidegger). Esta última propone que la existencia o la inexistencia de Dios es una cuestión irrelevante para la existencia humana: Dios puede o no existir. El problema, tan sólo por tener una idea firme, no soluciona los problemas metafísicos del hombre.

Heidegger se distancia expresamente de Sartre en su Carta sobre el humanismo. Buytendijk, psicólogo cercano a Heidegger, admite ser existencialista. Merleau-Ponty es gran representante de la corriente, aunque manteniendo más nexos con la fenomenología de Husserl. Martin Buber, por su parte, representa a una corriente de existencialismo judío muy influida por el hasidismo. Mientras que Gabriel Marcel y Jacques Maritain son encuadrables en un "existencialismo cristiano" no tanto de línea kierkegaardiana sino más bien jasperiana/mounierista ("filosofía de la existencia" y personalismo).

Uno de los antecedentes importantes del existencialismo es el novelista ruso Fiódor Dostoyevski. En muchas de sus llamadas “novelas de ideas”, Dostoyevski nos presenta imágenes de gente en situaciones extremas, en un mundo carente de valores y en el que esta gente tiene que decidir cómo actuar sin más guía que su propia conciencia. Tal vez una de sus obras más emblemáticas en este sentido sean las "Memorias del subsuelo". Ahí, Dostoyevski es escéptico acerca del poder de la razón para guiarnos en la vida, su posición es de rebelión en contra del racionalismo.

En novelas como "Crimen y castigo", "Los endemoniados", "Los hermanos Karamázov" y "El idiota" confluyen algunos temas recurrentes en las obras de Dostoievski que incluyen el suicidio, la destrucción de los valores familiares, el renacimiento espiritual a través del sufrimiento (siendo uno de los puntos capitales), el rechazo a Occidente y la afirmación de la ortodoxia rusa y el zarismo.

El antecedente más importante del existencialismo fue el filósofo danés Søren Kierkegaard (1813-1855). Kierkegaard es considerado por muchos como el primer filósofo existencialista en la historia de la filosofía. De hecho, él inventó el término “existencialista” (aunque parece no haberlo usado para referirse a sí mismo). Hay tres rasgos que hacen que lo podamos considerar como un filósofo existencialista: 1) su individualismo moral; 2) su subjetivismo moral; 3) su idea de angustia.

En contra de la tradición filosófica, que sostiene que el bien ético más alto es el mismo para todos, Kierkegaard afirmaba que el bien más alto para el individuo es encontrar su propia vocación. Él decía: “Debo encontrar una verdad que sea verdadera para mí... la idea por la que pueda vivir o morir”. La idea que está detrás es que uno debe escoger su propio camino sin la ayuda de normas o criterios universales u objetivos. Se ha llamado a esta posición individualismo moral. En contra de la posición tradicional de que el juicio moral involucra (o debe involucrar) una norma objetiva de corrección o incorrección, Kierkegaard sostiene que no se puede encontrar una base objetiva o racional en las decisiones morales. La única base de una filosofía con significado es el “individuo existente” (“situado”, podríamos añadir); la filosofía no tiene que ver con una contemplación imparcial (objetiva) del mundo ni de descifrar la “verdad”. Para él, verdad y experiencia están ligadas y hay que abandonar la idea de que la filosofía es una especie de ciencia exacta y pura.

Posteriormente, los existencialistas seguirían a Kierkegaard al enfatizar la importancia de la acción individual al decidir sobre asuntos de moralidad y de verdad. La experiencia personal y actuar de acuerdo con convicciones propias es esencial para llegar a la verdad. El entendimiento que de una situación tiene el agente involucrado es superior al de un observador desinteresado. Los existencialistas pondrán énfasis en la perspectiva subjetiva (lo que permite que podamos llamarlos, en cierto sentido, subjetivistas). Esto hace que sean filósofos asistemáticos. Se oponen a la existencia de principios racionales, objetivos y universalmente válidos (como los que proponía Kant). En cierto sentido, los existencialistas, a partir de Kierkegaard, son “irracionalistas”: no porque nieguen el papel del pensamiento racional, sino porque creen que las cosas más importantes de la vida no son accesibles a la razón o a la ciencia.

El alemán Heidegger rechazó que su pensamiento fuera catalogado como existencialista. El equívoco provendría, según los estudiosos, de la lectura e interpretación del primer gran tratado del filósofo, ""Ser y tiempo"". En verdad, allí se plantea que el objetivo de la obra es la búsqueda del ""sentido del ser"" -olvidado por la filosofía desde sus inicios-, ya desde los primeros párrafos, lo cual con propiedad no permitiría entender el trabajo -como expresa el autor- como "existencialista"; pero Heidegger, tras esa especie de anuncio programático entiende que es previa a la buscada ontología o dilucidación del ser, una "ontología fundamental" y al consagrarse a ella con método fenomenológico, se dedica a un análisis descriptivo pormenorizado y excluyente de la ""existencia humana"" o ""Dasein"", con una hondura y una originalidad, inéditas en la historia del pensamiento occidental, siguiendo el método fenomenológico de quien fuera su maestro Edmund Husserl. Con posterioridad, el resto de su obra, que seguirá al primer tratado mencionado, publicado en 1927, se ocupará de otros asuntos en los que ya no se transparenta la temática ""existencial"". Esta aparente ruptura con el hilo conductor de su primer pensamiento será un hiato en su discurso que el filósofo no aceptará nunca como tal... Pero muchos críticos la denominarán: ""el segundo Heidegger"" y da como toda respuesta filosófica final (literalmente) "el silencio".

La característica principal del existencialismo es la atención que presta a la existencia concreta, individual y única del hombre, por lo tanto, en el rechazo de la mera especulación abstracta y universal. El tema central de su reflexión es precisamente la existencia del ser humano, en términos de "estar fuera" ( a saber, en el mundo), de vivencia, y en especial de pathos o en todo caso el temple de ánimo. En expresión de Heidegger: «el-ser-en-el-mundo».

Heidegger, en efecto, se caracteriza, según algunos, por su firme pesimismo: considera al ser humano como "yecto" (arrojado) en el mundo; el "Dasein" se encuentra arrojado a una existencia que le ha sido impuesta, abandonado a la angustia que le revela su mundanidad, el hecho de que puede ser en el mundo y que por consiguiente, ha de morir. Sartre, siguiendo a Heidegger, también dista de caracterizarse por un estilo y discurso optimistas; plantea, al igual que Heidegger, un ser humano no tan sólo como "yecto", sino como "pro-yecto": un "proyecto" en situación. No obstante, estas posturas no tienen que comprenderse necesariamente como pesimistas. Para Sartre la angustia de un alma consciente por encontrarse condenada a ser libre, significa tener en cada instante de la vida, la absoluta responsabilidad de renovarse, y de este punto parte Gabriel Marcel para sustentar una perspectiva optimista, que le lleva a superar cualquier oposición entre el hombre y Dios, en contradicción con la concepción atea de Sartre.

Gabriel Marcel en su primer libro, "Journal Metaphysique" (Diario metafísico), abogaba por una filosofía de lo concreto que reconociera que la encarnación del sujeto en un cuerpo y la situación histórica del individuo condicionan en esencia «lo que se es en realidad». Marcel es, como Maritain, uno de los "existencialistas cristianos franceses".

Gabriel Marcel distinguió la que llamó "reflexión primaria", que tiene que ver con los objetos y las abstracciones. Esta reflexión alcanza su forma más elevada en la ciencia y la tecnología. Para Marcel la "reflexión secundaria" -usada por él como método- se ocupa de aquellos aspectos de la existencia humana, como el cuerpo y la situación de cada persona, en los que se participa de forma tan completa que el individuo no puede abstraerse de los mismos. Asimismo, la reflexión secundaria contempla los misterios y proporciona una especie de verdad (filosófica, moral y religiosa) que no puede ser verificada mediante procedimientos científicos, pero que es confirmada mientras ilumina la vida de cada uno.
Marcel, a diferencia de otros existencialistas, hizo hincapié en la participación en una comunidad en vez de denunciar el ontológico aislamiento humano. No sólo expresó estas ideas en sus libros, sino también en sus obras de teatro, que presentaban situaciones complejas donde las personas se veían atrapadas y conducidas hacia la soledad y la desesperación, o bien establecían una relación satisfactoria con las demás personas y con Dios.

En cuanto a la familia, Marcel tras reflexionar en su experiencia de temprana muerte de su madre, afirmaba que la institución familiar era una especie de símbolo de una realidad personal "mucho más rica y profunda donde el amor recíproco y la mutua donación son la base o fundamento" (es evidente que la teoría del mutuo don en el pensamiento de Gabriel Marcel fue inspirada por la teoría antropológica del mismo nombre propuesta por Marcel Mauss). En ese mundo, el niño ve un refugio de recuerdos felices donde vuelve cada vez que hace falta. En el caso de los que morían, hacía notar al mismo tiempo su lejanía (ya no están) y su cercanía (la nostalgia).

Como se ha mencionado, los textos suyos reflejan tanto sus estudios de filósofos y corrientes de pensamiento, —escrito eso sí a modo de diario— como sus experiencias personales. Así la segunda parte del "Diario de metafísica" trata de su experiencia de la guerra y evoca su idea de la trascendencia de la existencia encarnada por medio de un análisis fenomenológico propio.

Esta metodología fue desarrollada ulteriormente cuando oponía la «fenomenología del tener» a la «fenomenología del ser» que lo pone en las puertas de la metafísica.

Siendo Marcel defensor de los golpistas sublevados (franquistas) contra la República durante la Guerra Civil Española, fue que el anarquista Albert Camus polemizó con él en varias cartas públicas donde denunció las contradicciones éticas de su reflexión filosófica humanista. Aunque adscrito al existencialismo, Gabriel Marcel es considerado uno de los pensadores menos existencialistas.

José Ortega y Gasset, influido, como su condiscípulo Heidegger, por el que fuera maestro de ambos: Husserl, resumió su filosofía en la tesis "Yo soy yo y mi circunstancia"; consideró que vida es la realidad radical, la relación entre el yo y las circunstancias, el ámbito en el que se hace presente todo, es el experimentar la realidad, un conjunto de vivencias (en alemán "Erlebnisse"), en las que cada uno se relaciona con el mundo; la intuición es la vivencia en la que está presente la evidencia y es sobre las evidencias que descansa nuestro conocimiento. "La vida es una actividad que se ejecuta hacia adelante, y el presente o el pasado se descubren después, en relación con ese futuro. La vida es futurización, es lo que aún no es”. Ortega y Gasset es junto a Miguel de Unamuno el máximo exponente del existencialismo en idioma español del siglo XX. Las teorías de Ortega y Gasset en cierto momento se hacen paralelas al existencialismo propiamente dicho, por ejemplo cuando considera una pantonomía del Universo.

Los detractores de Sartre le calificaron de «un filósofo decimonónico» a lo cual Sartre respondió (fines de los años 1970) «es cierto, porque lo de ahora no es verdadera filosofía», por otra parte Sartre definió concretamente a su existencialismo como un humanismo refutando a quienes le tacharon de nihilista.

Es prácticamente imposible resumir en pocas líneas al existencialismo sartreano porque está relacionado con otros "ismos" de su época y de todos los tiempos.

Durante la vida de Sartre, éste fue especialmente atacado por quienes lo denostaban de ateo y materialista queriendo presentar a Sartre como un "amoral", sin embargo de todos los pensadores existencialistas es quizás el más moralista o, mejor dicho, el más eticista.

En el primer Sartre, como en el primer Heidegger, el ser humano es un ser para la nada, y por esto con una existencia absurda que debe vivir el momento, pero muy pronto hace una inversión copernicana en relación a los criterios que hasta entonces utilizaba la filosofía: en las cosas la esencia ni siquiera precede a la existencia, la "esencia de un objeto es su misma existencia" en cambio en el ser humano la existencia precede a la esencia, será el yo de cada humano con sus transcendencias el que le dará sentido a la existencia humana, por otra parte rechaza en "El ser y la nada" el nihilismo de Heidegger: la nada es algo "irrealizante": es la destrucción de lo ya dado para crear nuevas realidades, ante esto cada ser humano tiene un compromiso existencial con el prójimo y, aunque parezca contradictorio e incluso aporético, el compromiso existencial debe lograr la libertad de todos y cada uno de los seres humanos, de otro modo la existencia humana carece de sentido; en uno de sus apotegmas dice con aparente paradoja que ""nunca se es más libre que cuando se está privado de la libertad"" porque -si se tiene consciencia (si no se está alienado), de la situación- es cuando se tiene consciencia de la -siempre con aparente paradoja- necesidad (o ἀνάγκη) de la libertad, los seres humanos entiende Sartre son un "ser en situación" todavía en una "Sociedad condicionada y arte" sin embargo su destino es "de dioses" (es decir de ser libres; la frase de Sartre no debe ser tomada literalmente como un postulado metafísico), otro de los célebres apotegmas de Sartre es: ""[los seres humanos] estamos condenados a la libertad""; los vaivenes del sartrismo resultan interesantes al encontrarse en ellos implícitas antinomias: la esencia del humano es la libertad pero (esto se observa en la Polémica Merleau-Ponty-Sartre) "el infierno es la mirada del otro" porque cuando el otro mira a cada otro que no es él (para decirlo más sencillamente: cuando una persona observa o considera a otra) lo objetiviza, lo objeta y lo tiende a hacer objeto.

En sus últimos años (y en esto puede hablarse de un segundo Sartre) tras que intentara un psicoanálisis existencial que negaba a lo inconsciente freudiano por ser de "cuño irracionalista alemán" y en lugar de lo inconsciente trataba de imponer la noción de mala fe ante la cual cada humano debía asumir su compromiso existencial, el mismo Sartre se dio cuenta, y lo reconoció en "Sartre por él mismo" y en el "El existencialismo es un humanismo" que se había equivocado al rechazar de plano a lo inconsciente (que Nietzsche llamaba "Das Es" [Lo ello] y Freud como Schopenhauer "Das Unbewußt"), esta recapacitación le hizo decir a Sartre: «Como diría Lacan el humano es có"$"mico» (notar que acá Sartre usa el símbolo lacaniano para el sujeto escindido o sujeto clivado no sólo con el uso lacaniano sino probablemente también con una ironía al sugerir que el ser humano está dominado por el dinero) de este modo sin negar el compromiso existencial en pos de la libertad humana es que Sartre admitía como epílogo de su obra que no todo depende de la voluntad consciente de cada sujeto, aunque mantuvo que el esfuerzo humano en pos de la libertad es de todos modos posible.

Durante décadas (desde fines de los 1940 hasta inicios de los 1980) para la opinión pública el existencialismo era presentado casi exclusivamente como sartrismo.

 (París, 9 de enero de 1908 - París, 14 de abril de 1986) fue una escritora, profesora y filósofa francesa defensora de los derechos humanos y feminista. Escribió novelas, ensayos, biografías y monográficos sobre temas políticos, sociales y filosóficos. Su pensamiento se enmarca en la corriente filosófica del existencialismo y su obra "El segundo sexo", se considera fundamental en la historia del feminismo. Fue pareja del también filósofo Jean Paul Sartre.

Otros destacados pensadores adscribibles al existencialismo, en mayor o menor grado, serían: Edith Stein, Lev Isaákovich Shestov (más conocido en español como León Chestov), Nicola Abbagnano, Nikolai Berdyaev, Albert Camus, Peter Wessel Zapffe, Karl Jaspers, Max Scheler, Simone de Beauvoir, Simone Weil, Abraham Alonzo, Paulo Freire y Emmanuel Mounier.

Hans Jonas afirma que la esencia del existencialismo es un dualismo encubierto; una separación profunda entre mundo y naturaleza, separación que genera en el hombre un desgarro cosmológico y existencial.

El barcelonés Alfredo Rubio de Castarlenas propuso en 1980 el realismo existencial (22 Historias clínicas de realismo existencial, Ed. Edimurtra 1980), que propone la sorpresa de verse existiendo, pudiendo no haber existido, si cualquier cosa anterior a nosotros de las que incidieron en nuestro origen, hubiera sido distinta. Su visión abreva del existencialismo pero no se ancla en la angustia, sino en la "alegre desangustia de haber podido no ser".

Algunos consideran que los conceptos desarrollados en la filosofía existencialista han sido fuertemente influidos por el arte. Novelas, obras de teatro, películas, cuentos y pinturas, sin que hayan sido catalogadas necesariamente como existencialistas, sugieren ser precursoras de sus postulados. He aquí algunos autores y obras representativas:

Las novelas, cuentos y relatos de Franz Kafka, como El Proceso, El Castillo, La metamorfosis; en las cuales los protagonistas se enfrentan a situaciones absurdas, extremas, carentes de explicación, aunque haya respuestas, a las que nunca tienen acceso, al modo de los encausados por la inquisición a las acusaciones que originaron el proceso.

Rainer Maria Rilke escribió poesía y novelas que influyeron directamente sobre los existencialistas. Su novela "Los cuadernos de Malte Laurids Brigge" influyó sobre "La náusea" de Sartre, y Heidegger escribió un largo ensayo sobre uno de sus poemas. Muchos de los motivos existencialistas se encuentran en "Los cuadernos de Malte Laurids Brigge": la búsqueda de una existencia auténtica y el enfrentamiento con la muerte, entre otros.

La obra del escritor portugués, Fernando Pessoa, en particular: "El marinero" y El libro del desasosiego.

Obras de autores franceses como La náusea, de Sartre; La peste, de Camus; Viaje al fin de la noche, de Cèline; "Para acabar con el juicio de Dios", de Antonin Artaud y la poesía y dramaturgia de Jean Genet.

Una de las novelas más conocidas de Hermann Hesse: El lobo estepario, plantea una situación en la que el protagonista, Harry Haller, se encuentra sumido en un profundo dilema sobre su identidad. Hay dos almas viviendo en su pecho: un lobo y un hombre, que representan la virtud y la humanidad, en contraste con la satisfacción salvaje de los instintos y una profunda misantropía.

Las películas del cineasta sueco Ingmar Bergman, como El séptimo sello, Gritos y susurros y Fanny y Alexander, o las del ruso Andrey Tarkovsky en casi toda su obra (por ejemplo Solaris basada en el libro de Stanisław Lem usa como pretexto a la ciencia ficción para dar lugar a reflexiones existencialistas) o en El espejo y especialmente en su última obra: El sacrificio (o Sacrificio).





</doc>
<doc id="11343" url="https://es.wikipedia.org/wiki?curid=11343" title="Unión Soviética">
Unión Soviética

La , oficialmente llamada Unión de Repúblicas Socialistas Soviéticas (URSS, tr.: "Soyuz Sovétskij Sotsialistícheskij Respúblik"; ; abreviado СССР, "SSSR") fue un Estado federal marxista-leninista que existió en Eurasia entre 1922 y 1991. El nombre utilizado informalmente entre sus residentes fue la Unión ("Soyuz").

La Unión Soviética tuvo un sistema político de partido único dominado por el Partido Comunista hasta 1990 y aunque era una unión federal de 15 repúblicas soviéticas subnacionales, el Estado soviético fue estructurado bajo un Gobierno nacional y una economía altamente centralizados.

La Revolución de Febrero de 1917, que provocó la caída del Imperio ruso, tuvo como sucesor al Gobierno provisional ruso, que fue derrocado por la Revolución de Octubre estableciéndose el Gobierno de los bolcheviques denominado Sovnarkom. A continuación, se desencadenó la Guerra Civil Rusa que fue ganada por el nuevo régimen soviético. En diciembre de 1922 fue creada la Unión Soviética con la fusión de la República Socialista Federativa Soviética de Rusia, la República Federal Socialista Soviética de Transcaucasia, la República Socialista Soviética de Ucrania y la República Socialista Soviética de Bielorrusia.

Tras el deceso del primer líder soviético, Vladímir Lenin, en 1924, Iósif Stalin acabó ganando la lucha por el poder y dirigió el país a través de una industrialización a gran escala, con una economía centralizada y una extrema represión política. En junio de 1941, durante la Segunda Guerra Mundial, Alemania junto a sus aliados invadió la Unión Soviética, un país con el que había firmado un pacto de no agresión. Al cabo de cuatro años de una guerra brutal, la Unión Soviética emergió victoriosa como una de las dos superpotencias del mundo, junto a los Estados Unidos.

La Unión Soviética y sus Estados aliados de Europa oriental, denominados Bloque del Este, estuvieron involucrados en la Guerra Fría, que fue una prolongada lucha ideológica y política mundial contra los Estados Unidos y sus aliados del Bloque occidental; finalmente la URSS cedió ante los problemas económicos y los disturbios políticos internos y externos. Durante este período, la Unión Soviética llegó a ser el modelo de referencia para futuros Estados socialistas. Desde 1945 hasta 1991, la Unión Soviética y los Estados Unidos dominaron la agenda global de la política económica, asuntos exteriores, operaciones militares, intercambio cultural, progresos científicos incluyendo la iniciación de la exploración espacial, y deportes (incluidos los Juegos Olímpicos). A finales de la década de 1980, el último líder soviético Mijaíl Gorbachov trató de reformar el Estado con sus políticas de la "perestroika" y "glásnost", pero la Unión Soviética se derrumbó y fue disuelta formalmente en diciembre de 1991 tras el fallido intento de golpe de Estado de agosto. Luego de esto, la Federación de Rusia asumió sus derechos y obligaciones.

Los límites geográficos de la Unión Soviética variaron con el tiempo, pero tras sus últimas anexiones territoriales principales y la ocupación de los países Bálticos (Lituania, Letonia, y Estonia), del este de Polonia, Besarabia, y algunos otros territorios durante la Segunda Guerra Mundial, desde 1945 hasta la disolución, los límites correspondieron aproximadamente a aquellos de la extinta Rusia Imperial, con las exclusiones notables de Polonia, la mayor parte de Finlandia, y Alaska.

Se piensa tradicionalmente que la Unión Soviética es la sucesora del Imperio ruso, no obstante pasaron cinco años entre el último Gobierno de los zares y la instauración de la Unión Soviética. El último zar, Nicolás II, gobernó el Imperio ruso hasta su abdicación en marzo de 1917 en la Revolución de febrero, en parte debido a la presión de los enfrentamientos en la Primera Guerra Mundial, luego un breve Gobierno Provisional Ruso tomó el poder, para ser derrocado en la Revolución de octubre de 1917 por revolucionarios encabezados por el líder bolchevique Vladímir Lenin.

La Unión Soviética fue establecida en diciembre de 1922 como la Unión de las Repúblicas Socialistas Soviéticas de Rusia (conocida como Rusia Bolchevique), Ucrania, Bielorrusia y Transcaucasia gobernadas, las tres primeras, por partidos bolcheviques y la última por el menchevique. A pesar de la fundación del Estado soviético como una entidad federativa de muchas repúblicas constituyentes, cada una con sus propias entidades políticas y administrativas, el término «Rusia Soviética» —estrictamente aplicable sólo a la República Socialista Federativa Soviética de Rusia (RSFSR)— fue a menudo incorrectamente aplicado a todo el país por políticos y escritores no soviéticos.

La actividad revolucionaria moderna en el Imperio ruso comenzó con la Revuelta Decembrista de 1825, y aunque la servidumbre fue abolida en 1861, lo fue en términos desfavorables para los campesinos y sirvió para animar a los revolucionarios. Un parlamento, la Duma Imperial de Rusia, fue establecido en 1906, después de la Revolución de 1905. A pesar de la resistencia del zar a los intentos de pasar de una monarquía absoluta a una constitucional, finalmente fue promulgada la Constitución rusa de 1906, la primera constitución del país. Sin embargo, la agitación social continuó y se agravó durante la Primera Guerra Mundial por el fracaso militar y la escasez de alimento en las ciudades principales.

Un levantamiento popular espontáneo en Petrogrado, en respuesta al decaimiento de la economía y la moral en tiempo de guerra, culminó con el derrocamiento del Gobierno imperial en marzo de 1917 ("véase Revolución de Febrero"). La autocracia zarista fue reemplazada por el Gobierno Provisional Ruso, cuyos líderes pensaron en establecer una democracia liberal en Rusia y continuar participando en el lado de la Triple Entente en la Primera Guerra Mundial. Al mismo tiempo, para asegurar los derechos de la clase obrera, las asambleas de trabajadores, conocidas como sóviets, nacen a lo largo de todo el país. Los bolcheviques, dirigidos por Vladímir Ilich Lenin, presionaron a favor de una revolución socialista tanto en dichas asambleas como en las calles, derrocándose al Gobierno Provisional el 7 de noviembre, 25 de octubre según el calendario juliano, de 1917 ("véase Revolución de Octubre"), y entregándose el poder a los sóviets de obreros, soldados y campesinos. En diciembre, los bolcheviques firmaron un armisticio con las Potencias Centrales, aunque en febrero de 1918, los combates se habían reanudado. En marzo, los soviéticos abandonaron la guerra definitivamente y firmaron el Tratado de Brest-Litovsk.

A partir de 1917 se produjo una larga y sangrienta Guerra Civil Rusa entre los Rojos y los Blancos, terminando en 1923 con la victoria de los Rojos e incluyó la intervención extranjera, la ejecución del zar Nicolás II y su familia y la hambruna de 1921, que mató a cerca de cinco millones de personas. Tras la Guerra Polaco-Soviética de 1919-1921, se firmó la «Paz de Riga» que a principios del año 1921 dividió los territorios disputados de Bielorrusia y Ucrania entre Polonia y la RSFS de Rusia. La Unión Soviética tuvo que resolver conflictos similares con la recién creada República de Finlandia, la República de Estonia, la República de Letonia y la República de Lituania.

El 28 de diciembre de 1922 en una conferencia de delegaciones plenipotenciarias de la RSFS de Rusia, RFSS de Transcaucasia, la RSS de Ucrania y la RSS de Bielorrusia se aprobó el Tratado de Creación de la URSS y la Declaración de la Creación de la URSS, formándose la Unión de las Repúblicas Socialistas Soviéticas.Estos dos documentos fueron confirmados por el primer Congreso de los Sóviets de la Unión Soviética y firmados por los cabezas de las delegaciones Mijaíl Kalinin, , Mijaíl Frunze, Grigori Petrovski y Aleksandr Chervyakov respectivamente el 30 de diciembre de 1922.

El 1 de febrero de 1924 la Unión Soviética fue reconocida por el Imperio británico y en ese mismo año se aprobó una Constitución soviética, legitimando la unión de diciembre de 1922.

La reestructuración intensiva de la economía, la industria y la política del país empezaron desde los primeros días del poder soviético en 1917. Una gran parte se realizó según los Decretos Iniciales Bolcheviques, documentos del Gobierno soviético, firmados por Vladímir Lenin. Uno de los adelantos más prominentes era el plan GOELRO, que propugnaba una reestructuración profunda de la economía soviética basada en la electrificación total del país. El plan se inició en 1920, desarrollándose durante un período de 10 a 15 años. Incluyó la construcción de una red de 30 centrales eléctricas regionales, incluyendo diez grandes centrales hidroeléctricas, y la electrificación de numerosas empresas industriales. El Plan llegó a ser el prototipo para el subsiguiente Plan Quinquenal finalizándose prácticamente en 1931.

Desde el comienzo de la Unión Soviética su Gobierno estuvo basado en un unipartidismo administrado por el partido bolchevique. Después de la política económica del comunismo de guerra llevada a cabo durante la Guerra Civil, el Gobierno soviético permitió que algunas empresas privadas coexistieran con la industria nacionalizada durante los años 1920. Del mismo modo, la requisa total de los excedentes alimentarios en el campo fue reemplazado por impuestos sobre los alimentos ("véase Nueva Política Económica").

Los líderes soviéticos sostuvieron que un Gobierno de un único partido era necesario para asegurar que la «explotación capitalista» no regresara a la Unión Soviética y que los principios del centralismo democrático representaran la voluntad del pueblo. El debate sobre el futuro de la economía constituyó el telón de fondo en la lucha por el poder que se desencadenó entre los líderes soviéticos tras la muerte de Lenin en 1924. En un principio, Lenin iba a ser reemplazado por un liderazgo colectivo compuesto por Grigori Zinóviev de Ucrania, Lev Kámenev de Rusia, y Stalin de Georgia.

El 3 de abril de 1922 Stalin fue nombrado Secretario General del Partido Comunista de la Unión Soviética y Lenin lo había nombrado como Jefe de Inspección de los Trabajadores y Campesinos. Al consolidar gradualmente su influencia y aislar o limitar a sus rivales dentro del partido, Stalin se convirtió en el principal dirigente soviético. En octubre de 1927, Grigori Zinóviev y León Trotsky fueron expulsados del Comité Central y obligados a exiliarse.

En 1928, Stalin introdujo el Primer Plan Quinquenal destinado a construir una economía socialista. Esto, a diferencia del internacionalismo proletario expresado por Lenin y Trotsky a través del curso de la Revolución, apuntó al socialismo en un solo país. En la industria, el Estado asumió el control de todas las empresas existentes y emprendió un programa intensivo de industrialización y en la agricultura fueron establecidas las granjas colectivas (koljós) por todas partes en el país.
Los kuláks supervivientes fueron perseguidos y muchos enviados a los Gulags a realizar trabajos forzados. Los trastornos sociales continuaron a mediados de la década de 1930. La Gran Purga de Stalin resultó en la ejecución de muchos «viejos bolcheviques», que habían participado en la Revolución de Octubre. La cifra de muertos es incierta, con una amplia gama de estimaciones. Según los archivos soviéticos desclasificados, entre 1937 y 1938 la NKVD arrestó a 1.500.000 personas, de las cuales fueron fusiladas 681.692. El exceso de muertes durante la década de 1930 en su conjunto estaban en el rango de 10 a 11 millones de personas. A pesar de la confusión de mediados a finales de la década de 1930, la URSS desarrolló una poderosa economía industrial en los años precedentes a la Segunda Guerra Mundial, convirtiéndole en una potencia industrial a nivel internacional.
La década de 1930 vio la cooperación más cercana entre los países occidentales y la URSS. En 1933 se establecieron relaciones diplomáticas entre los Estados Unidos y la URSS. Cuatro años más tarde, la URSS apoyó a la República Española en la Guerra Civil Española contra el golpe de Estado de los sublevados, apoyados por la Italia fascista y la Alemania nazi. No obstante, después de que el Reino Unido y Francia concluyesen los Acuerdos de Múnich con la Alemania nazi, la URSS realizó tratos con este último país concluyendo el Pacto Ribbentrop-Mólotov (pacto de no agresión nazi-soviético) y el Tratado Alemán-Soviético de Amistad, Cooperación y Demarcación. Esto favoreció la invasión soviética de Polonia de 1939 y la ocupación de Lituania, Letonia y Estonia en 1940. A finales de noviembre de 1939, al verse incapaz de forzar a la Finlandia a mover su frontera 25 kilómetros de Leningrado por medios diplomáticos, Stalin ordenó la intervención del Ejército Rojo en dicho país, provocando la llamada Guerra de Invierno.

En el este, el Ejército Rojo ganó varias batallas decisivas durante los enfrentamientos fronterizos con el Imperio del Japón en 1938 y 1939. Sin embargo, en abril de 1941, la URSS firmó el Pacto de Neutralidad con los japoneses, reconociendo la integridad territorial de Manchukuo, un Estado títere japonés.

Aunque se ha discutido si la Unión Soviética tenía intención alguna de invadir Alemania, la propia Alemania una vez que fue lo suficientemente fuerte, rompió el pacto de no agresión e invadió la Unión Soviética el 22 de junio de 1941, iniciando lo que se conocía en la URSS (y aún en la Rusia actual) como la «Gran Guerra Patriótica». El Ejército Rojo detuvo al aparentemente invencible ejército alemán en la Batalla de Moscú, con la ayuda de un invierno inusualmente severo. La Batalla de Stalingrado, que duró desde finales de 1942 hasta principios de 1943, asestó un duro golpe a los alemanes del cual nunca se recuperaron completamente y los convirtió en un punto de inflexión de la guerra. Después de Stalingrado, las fuerzas soviéticas avanzaron a través de Europa del Este hasta Berlín forzando la rendición de Alemania en mayo de 1945. El ejército alemán sufrió el 80 % de sus bajas militares en el Frente Oriental.

Ese mismo año, la URSS, en el cumplimiento de su acuerdo con los aliados en la Conferencia de Yalta, denunció el Pacto de Neutralidad soviético-japonés en abril de 1945 e invadió Manchukuo y otros territorios controlados por Japón el 9 de agosto de 1945. Este conflicto terminó con una decisiva victoria soviética, que contribuyó a la rendición incondicional de Japón y al fin de la Segunda Guerra Mundial.

La Unión Soviética sufrió enormemente durante la guerra, perdiendo aproximadamente 27 millones de personas. A pesar de ello, surgió del conflicto como una superpotencia militar. Una vez que negó el reconocimiento diplomático del mundo occidental, la Unión Soviética tuvo relaciones oficiales con prácticamente todas las naciones en la década de 1940. Como miembro de las Naciones Unidas durante su fundación en 1945, se convirtió en uno de los cinco miembros permanentes del Consejo de seguridad de la ONU, que le dio el derecho de veto a cualquiera de sus resoluciones ("véase Unión Soviética y las Naciones Unidas").

La Unión Soviética mantuvo su estatus como una de las dos superpotencias del mundo durante cuatro décadas a través de su hegemonía en Europa oriental derivada de su fuerza militar, su fuerza económica, su ayuda a países en vías de desarrollo y de sus investigaciones científicas, especialmente en tecnología espacial y armamento.

Durante la posguerra inmediata, la Unión Soviética reedificó y expandió su economía, al mantener su control estrictamente centralizado. La Unión Soviética ayudó la reedificación de los países de Bloque del Este en la posguerra, mientras los convertía en Estados satélite y los unía en una alianza militar, al fundar el Pacto de Varsovia en 1955 y el Consejo de Ayuda Mutua Económica o COMECON de 1949 a 1991, este último fue un equivalente a la Comunidad Económica Europea. Más tarde, el COMECON suministró ayuda a la eventual victoria del Partido Comunista de China y vio crecer su influencia en otras partes del mundo. Ante el temor de sus ambiciones, los aliados durante la Segunda Guerra de la Unión Soviética, el Reino Unido y los Estados Unidos, se convirtieron en sus enemigos y en la subsiguiente Guerra Fría, los dos bloques se enfrentaron indirectamente utilizando la mayor parte de sus fuerzas.

Iósif Stalin murió el 5 de marzo de 1953. En ausencia de un sucesor mutuamente aceptable, los funcionarios más altos de Partido Comunista optaron por gobernar la Unión Soviética en comité. Nikita Jrushchov, que se había impuesto en esa lucha por el poder a principios de la década de los años 1950, denunció en su "discurso secreto" al XX Congreso del PCUS de 1956 la represión política en la Unión Soviética y ordenó la liberación de los presos políticos del Gulag. Además de esa denuncia, procedió a relajar los controles de tipo represivo que hasta entonces ejercía el Partido sobre la sociedad. Todo esto se conoce como el proceso de desestalinización.

Moscú consideró a Europa oriental como una zona tapón para la defensa preventiva de sus fronteras occidentales y aseguró su control de la región transformando los países de Europa del Este en Estados satélites. Al mismo tiempo, la fuerza militar soviética fue utilizada para reprimir sublevaciones anticomunistas en Hungría y Polonia en 1956 (véanse Protestas de Poznań de 1956, Octubre polaco y Revolución húngara de 1956).

A finales de 1950, una confrontación con China relacionada al acercamiento de la URSS con Occidente y por lo que Mao Zedong percibió como revisionismo de Jrushchov condujo a la ruptura Chino-Soviética. Esto dio lugar a una ruptura en todo el movimiento comunista mundial, haciendo que los Gobiernos comunistas en Albania, Camboya y Somalia prefirieran aliarse con China en lugar de la URSS.

Durante este período, la Unión Soviética continuó avanzando científica y tecnológicamente, lo que le permitió lanzar el primer satélite artificial Sputnik 1 y conseguir la hazaña de llevar por primera vez un ser vivo al espacio exterior: la perra Laika. El 12 de abril de 1961 Yuri Gagarin se convirtió en el primer ser humano en viajar al espacio exterior a bordo de la nave Vostok 1. Valentina Tereshkova fue la primera mujer en ir al espacio a bordo del Vostok 6 el 16 de junio de 1963, Alekséi Leónov se convirtió en la primera persona en caminar en el espacio el 18 de marzo de 1965, y los primeros vehículos exploradores lunares, Lunokhod 1 y Lunokhod 2.

Jrushchov inició «el deshielo» mejor conocido como el "Deshielo de Jrushchov", un complejo cambio en la vida política, cultural y económica de la Unión Soviética. Que incluía la apertura y el contacto con otras naciones y nuevas políticas sociales y económicas con mayor énfasis en los productos básicos y en la consrucción de la vivienda, permitiendo que los niveles de vida aumentaran de una manera espectacular y manteniendo altos niveles de crecimiento económico. La censura también fue suavizada, aunque seguía la prohibición de publicación de novelas que no se ajustaban a los preceptos del realismo socialista como, por ejemplo, la novela "Doctor Zhivago" cuyo autor, Borís Pasternak, se vio forzado a rechazar el Premio Nobel de Literatura en 1958. Sin embargo, ese mismo año los físicos soviéticos Pável Cherenkov, Iliá Frank e Ígor Tamm fueron galardonados con el Premio Nobel de Física.

Las reformas de Jrushchov en la agricultura y la administración, sin embargo, fueron generalmente improductivas. En 1962, desencadenó una crisis con los Estados Unidos durante el despliegue soviético de misiles nucleares en Cuba. La Unión Soviética retrocedió después que los Estados Unidos inició un bloqueo naval, que le provocó mucha vergüenza y pérdida de prestigio a Jrushchov y como consecuencia fue forzado a dimitir en 1964.

Tras la salida de Jrushchov, se produjo otro período de liderazgo colectivo, conformado por Leonid Brézhnev como Secretario General, Alekséi Kosygin como Presidente del Consejo de Ministros y Nikolái Podgorni como Presidente del Presidium, que duró hasta la década de 1970 donde Brézhnev se estableció como el más importante líder soviético. En 1968 la Unión Soviética y sus aliados del Pacto de Varsovia invadieron Checoslovaquia para detener las reformas de la Primavera de Praga.

Brézhnev presidió durante un período de "Détente" o distensión con Occidente ("véase SALT I, SALT II y Tratado sobre Misiles Antibalísticos") sin dejar al mismo tiempo de incrementar la fuerza militar soviética; la concentración armamentística contribuyó a la desaparición de la "Détente" a finales de los años 1970. Otro factor que contribuyó al fin de la distensión fue la Guerra de Afganistán en diciembre de 1979, con el objeto de apoyar a un Gobierno comunista local que se hallaba en graves dificultades.

En octubre de 1977, fue aprobada por unanimidad la tercera Constitución soviética, pero el estado de ánimo predominante en el liderazgo soviético durante el momento de la muerte de Brézhnev en 1982, era la aversión al cambio. El largo período de Gobierno a cargo de Brézhnev había comenzado a ser denominado como uno de inmovilismo (застой), con un envejecido y estancado liderazgo político.

En el ámbito deportivo, la Unión Soviética organizó los Juegos Olímpicos de Moscú 1980, con sede en Moscú. Hubo un intento de boicot del evento por parte de Estados Unidos: en el marco de la Guerra Fría y en protesta por la presencia soviética en Afganistán, los estadounidenses decidieron no asistir a los Juegos Olímpicos, tratando al mismo tiempo de persuadir a sus aliados para que tampoco asistieran. En total, 65 países se abstuvieron de participar, principalmente debido a la iniciativa estadounidense.

Dos fenómenos caracterizaron la siguiente década: el desmoronamiento cada vez más evidente de las estructuras económicas y políticas de la Unión Soviética, y un conjunto poco coherente de reformas enfocadas a revertir ese proceso. Kenneth S. Deffeyes argumentó en "Beyond Oil" que la administración Reagan había alentado a Arabia Saudita a bajar el precio del petróleo hasta el punto en que los soviéticos no lograran obtener beneficios vendiendo su petróleo, por lo que se agotaron las reservas de divisas de la URSS.

Los próximos dos sucesores de Brézhnev, serían figuras de transición con profundas raíces en la tradición brezhnevita, que no duraron mucho. Cuando asumieron el poder, Yuri Andrópov tenía 68 años y Konstantín Chernenko 72; ambos murieron en menos de dos años. En un intento de evitar un tercer líder efímero, en 1985 los soviéticos se volcaron a la próxima generación y seleccionan a Mijaíl Gorbachov.

Gorbachov comenzó a aplicar cambios significativos en la economía y en el liderazgo del partido con la "perestroika". Su política "glásnost" permitió el acceso público a la información después de décadas de fuerte censura por parte del Gobierno.

Gorbachov también se movió para ponerle fin a la Guerra Fría. En 1988, la Unión Soviética abandonó sus nueve años de guerra en Afganistán y comenzó a retirar sus tropas. En la década de 1980, retiró el apoyo militar a los antiguos Estados satélites de la Unión Soviética, lo que resultó en la caída de varios Gobiernos comunistas. Con el derribo del Muro de Berlín y con Alemania Oriental y Occidental persiguiendo la unificación, el telón de hierro se vino abajo.

A finales de los años 1980, las repúblicas que componían la Unión Soviética incorporaron legalmente movimientos hacia la declaración de soberanía sobre sus territorios, citando el Artículo 72 de la Constitución de la URSS, que indicaba que cualquier república integrante de la Unión Soviética era libre de separarse. El 7 de abril de 1990 fue aprobada una ley en virtud de la cual una república podía salirse de la unión si más de dos terceras partes de los residentes de la misma votaban a favor de ello en un referéndum. Muchas repúblicas celebraron sus primeras elecciones libres en la era soviética a fin de crear sus propias legislaturas nacionales hacia 1990. Muchas de estas legislaturas procedieron a elaborar una legislación que contradecía las leyes de la Unión en lo que se conoció como la «La Guerra de Leyes».

En 1989, la RSFS de Rusia, que era entonces la república más grande (con cerca de la mitad de la población) convocó unas nuevas elecciones para elegir un Congreso de Diputados del Pueblo. Borís Yeltsin fue elegido presidente del Congreso. El 11 de marzo de 1990 Lituania proclama la restitución de la independencia y el fin de ocupación por parte de la URSS. El 12 de junio de 1990, el Congreso de Diputados del Pueblo declaró la soberanía de Rusia sobre su territorio y tomó la delantera en la elaboración de leyes que trataban de reemplazar algunas de las leyes de la URSS. El período de incertidumbre legal continuó a lo largo de 1991 así como las repúblicas constituyentes fueron lentamente independizándose de facto.

El 17 de marzo de 1991 se celebró un referéndum que buscaba preservar la Unión Soviética, en el que la mayoría de la población votó por su conservación en nueve de las quince repúblicas soviéticas. Este referéndum dio a Gorbachov un respiro y en el verano de 1991 se diseñó un Nuevo Tratado de la Unión, en un intento de llegar a acuerdos que convirtieran a la Unión Soviética en una federación mucho más laxa y de disminuir el centralismo político.

En el Nuevo Tratado de la Unión ya no se hacía mención de la URSS y no se utilizaba más la palabra socialista. Este Nuevo Tratado fue realizado en secreto y cuando el Primer Ministro Pávlov encontró un borrador de este, los líderes conservadores del partido lo interpretaron como la base de la disolución de la Unión Soviética y por esa razón optaron por filtrarlo a la prensa. Según el contenido de dicho tratado, la URSS estaba a punto de dividirse en varios Estados soberanos. Por ello decidieron enfrentarse a Gorbachov y reafirmar el control central del Gobierno sobre las repúblicas de la URSS.

El tratado se firmaría el 20 de agosto, pero la firma fue interrumpida por el intento de golpe de Estado de agosto de 1991 contra Gorbachov, por parte de los conservadores en un intento de preservar el sistema soviético. Los conservadores habían creado un Comité de Estado de Emergencia, movilizando tropas soviéticas para proteger las instituciones del Estado, pero desistieron cuando se produjo la muerte accidental de tres jóvenes que cayeron bajo los tanques.

Tras el fracaso del intento de golpe de Estado, Yeltsin, luego de permanecer oculto en su residencia, apareció en el público y desacreditó al Comité de Estado de Emergencia presidido por Yanáyev declarándolo inconstitucional, mientras tanto el poder de Gorbachov disminuyó vertiginosamente, hecho que Yeltsin aprovechó para consolidar su poder y deslegitimar de una vez por todas el control del Partido Comunista sobre el Gobierno. El equilibrio político se inclinó apreciablemente hacia las repúblicas secesionistas. De hecho, inmediatamente y todavía en agosto de 1991, Letonia y Estonia declararon la restauración de la independencia plena (siguiendo el ejemplo que había dado Lituania en 1990), mientras que las otras 12 repúblicas soviéticas continuaban discutiendo posibles modelos para una Unión cada vez más débil.

El 8 de diciembre de 1991, los presidentes de RSFS de Rusia, RSS de Ucrania y RSS de Bielorrusia firmaron el Tratado de Belavezha que declaró oficialmente la disolución de la Unión Soviética y el establecimiento de la Comunidad de Estados Independientes (CEI), en su lugar. Como quedaban dudas sobre la autoridad del Tratado de Belavezha para disolver la Unión, el 21 de diciembre de 1991, los representantes de todas las repúblicas soviéticas excepto Georgia, inclusive las 3 repúblicas que habían firmado el Tratado de Belavezha, firmaron el Protocolo de Alma-Ata, que confirmó el desmantelamiento consecuente de la URSS y volvió a plantear el establecimiento de la CEI. La cumbre de Alma-Ata convino también en varias otras medidas prácticas como consecuencia de la extinción de la Unión Soviética. El 25 de diciembre de 1991, Gorbachov presentó su dimisión como Presidente de la URSS declarando el cargo como extinto y transfirió los poderes que habían sido creados en la presidencia a Borís Yeltsin, el Presidente de Rusia.

Al día siguiente, el Sóviet Supremo de la Unión Soviética, el cuerpo gubernamental más alto de la Unión Soviética, se disolvió a sí mismo. Este hecho es reconocido generalmente como la disolución final de la Unión Soviética como Estado. Muchas organizaciones como el Ejército Rojo y las fuerzas policiales continuaron ocupando sus respectivos puestos hasta principios del año 1992, pero fueron retirados progresivamente y absorbidos por los nuevos Estados constituidos.

Tras la disolución de la Unión Soviética el 26 de diciembre de 1991, Rusia fue reconocida internacionalmente como su sucesor legal en la escena internacional. Para ello, Rusia aceptó voluntariamente todas las deudas externas soviéticas y reclamó las propiedades soviéticas en ultramar como propias. Desde entonces, la Federación de Rusia ha asumido los derechos y obligaciones de la Unión Soviética.


















La Unión Soviética se creó en 1922. Al principio se crearon algunos organismos; sin embargo, el nuevo Estado no se institucionalizó hasta la aprobación en 1924 de una nueva constitución. La Constitución de 1924 establecía unas bases fundamentales del Estado. El órgano legislativo superior era el Sóviet Supremo, elegido mediante sufragio universal y formado por dos cámaras: el Sóviet de la Unión y el Sóviet de las Nacionalidades. La primera de las cámaras ejercía las tareas propias de un parlamento. El Sóviet de las Nacionalidades estaba formado por representantes de las diversas repúblicas federadas y autónomas, en un número determinado por la ley. Otra fuente de poder parlamentario era el Congreso de los Sóviets, que se reunía anualmente y estaba formado por representantes de diversos soviets de la Unión Soviética. La Jefatura de Estado estaba encarnada en un órgano colectivo: el Comité Ejecutivo Central de toda la Unión. El Gobierno lo ejercía un Consejo de Comisarios del Pueblo. Ambos órganos eran elegidos por el Sóviet Supremo. Hasta su muerte en 1924, el Presidente del Consejo de Comisarios del Pueblo fue Lenin. En la Constitución de la Unión Soviética de 1924 se incluyó por primera vez la estructura federal de la Unión Soviética y el derecho de las repúblicas federadas a separarse de la URSS y establecerse como Estados independientes. No se daba al partido una función relevante en el Estado, como sí se haría más tarde en las demás constituciones.

La Unión Soviética fue una república federal basada en quince repúblicas unidas. A su vez, una serie de unidades territoriales formaban las repúblicas. Las repúblicas tuvieron también jurisdicción pensada para proteger los intereses de minorías nacionales. Las repúblicas tenían sus propias constituciones, que, junto con la Constitución de la Unión, proporcionaban la división teórica del poder en la Unión Soviética. Todas las repúblicas menos la RSFS de Rusia tuvieron sus propios partidos comunistas. En 1989, sin embargo, el PCUS y el Gobierno central se apropiaron toda autoridad significativa, estableciendo las políticas que debían ejecutar los Gobiernos de las repúblicas, óblasts, y distritos.

En lo alto del Partido Comunista estaba el Comité Central, elegido en los congresos y conferencias del Partido. El Comité Central, por su lado, escogía al Politburó (llamado Presidium entre 1952 y 1966), al Secretariado y al Secretario General (denominado Primer Secretario entre 1953 y 1966), que era literalmente el cargo máximo de la Unión Soviética. Según el grado de consolidación del poder, podían ser tanto el Politburó como cuerpo colectivo o el Secretario General, que siempre estaba ocupado por uno de los miembros del Politburó, quienes dirigían al país y al partido (excepto por el período de Stalin, marcado por un autoritarismo altamente personalizado, ejercido directamente a través de su posición en el Consejo de Ministros, en lugar del Politburó a partir de 1941). No estaban sometidos al control de todos los miembros del Partido, ya que el principio fundamental del la organización del Partido era el centralismo democrático, exigiendo una estricta subordinación a los órganos superiores, además las elecciones eran sin oposición, puesto que los candidatos eran propuestos por los niveles superiores.

El Partido Comunista mantuvo su dominio sobre el Estado principalmente por su control en el sistema de nombramientos. Todos los altos funcionarios del Gobierno y la mayoría de los diputados del Sóviet Supremo eran miembros del PCUS. De los jefes del Partido, Stalin entre 1941 y 1953 y Jrushchov entre 1958 y 1964, fueron presidentes del Consejo de Ministros. Tras el retiro forzoso de Jrushchov el líder del partido prohibió este tipo de doble pertenencia, pero los últimos Secretarios Generales, al menos durante una parte de su mandato, también ocuparon la posición de Presidente del Presidium del Sóviet Supremo, nominalmente el jefe del Estado. Las instituciones en los niveles inferiores fueron supervisadas y en ocasiones sustituidas por las organizaciones primarias del Partido.

En la práctica, el grado de control del Partido podía extenderse por toda la burocracia estatal, particularmente después de la muerte de Stalin, estaba lejos de ser total, con la burocracia persiguiendo intereses distintos que en ocasiones provocaban conflictos con el Partido. Sin embargo, el Partido, tampoco era monolítico de arriba abajo, aunque las facciones fueron ocasionalmente prohibidas.

El Sóviet Supremo (sucesor del Congreso de los Sóviets y del Comité Ejecutivo Central), fue nominalmente el máximo órgano de Estado durante la mayor parte de la historia soviética, mientras que en un inicio simplemente actuaba como una institución para sellar, aprobar e implementar todas las decisiones tomadas por el Partido, sin embargo, las facultades y funciones del Sóviet Supremo se ampliaron en la década de 1950, 1960 y 1970, incluyendo la creación de comisiones y comités estatales nuevos. También adquirió poderes adicionales tras la aprobación de los Planes Quinquenales y por el presupuesto estatal soviético. El Sóviet Supremo elegía un Presidium para ejercer su poder entre las sesiones plenarias, celebradas ordinariamente en dos ocasiones al año, y nombraba al Tribunal Supremo, al Procurador General y al Consejo de Ministros (conocido antes de 1946 como Consejo de Comisarios del Pueblo), presidido por el Presidente (Primer Ministro) y dirigía a la enorme burocracia responsable por la administración de la economía y la sociedad. Las estructuras del Estado y del Partido de las repúblicas constituyentes emulaban enormemente la estructura de las instituciones centrales, si bien la RSFS de Rusia, a diferencia del resto de repúblicas, no tuvo una rama republicana del PCUS durante la mayor parte de su historia, siendo gobernada directamente por el Partido de toda la unión hasta 1990. Las autoridades locales se organizaban mediante los comités del partido locales, los sóviets locales y los comités ejecutivos. Mientras que el sistema estatal era nominalmente federal, el PCUS era unitario.

La policía de seguridad del Estado, (la KGB y las agencias predecesoras) jugaron un papel muy importante en la política soviética. Fueron instrumentales en el terror estalinista, pero después de la muerte de Stalin, la policía de seguridad del Estado quedó sometida a un estricto control por parte del Partido. Bajo Yuri Andrópov, presidente de la KGB entre 1967 y 1982 y Secretario General del Partido entre 1982 y 1983, la KGB, además de dedicarse a la supresión de la disidencia política y al mantenimiento de una extensa red de informantes, se reafirmó a sí misma como un actor político, siendo hasta cierto punto independiente dentro de la estructura del partido, que culminó en la campaña de anticorrupción enfocada a oficiales de alto rango del Partido que se llevó a cabo a finales de la década de 1970 e inicios de los 80.

La Unión de Repúblicas Socialistas Soviéticas fue un Estado socialista federal compuesto por quince repúblicas, creado el 30 de diciembre de 1922 y disuelto el 25 de diciembre de 1991. Si bien la jefatura de Estado y de Gobierno eran cargos diferenciados, buena parte del poder político recaía en el Secretario General del Partido Comunista de la Unión Soviética y otros miembros de su Comité Central.

De hecho, era común que el Secretario General del Partido fuera Presidente del Presidium, Jefe de Estado o Presidente del Consejo de Ministros (Jefe de Gobierno). Hasta Nikita Jrushchov fue costumbre que el líder del partido estuviera directamente a cargo del poder ejecutivo, pero a partir su sucesor Leonid Brézhnev ocuparon la jefatura de Estado. La prensa occidental por lo general hacía caso omiso de estas distinciones y llamaba al líder político Presidente de la Unión Soviética o Primer Ministro de la Unión Soviética, aunque estos cargos no existieron oficialmente hasta los últimos meses del Gobierno de Mijaíl Gorbachov.

El cargo de Secretario General del Partido no fue creado hasta el mes de abril de 1922 y se convirtió en el máximo puesto tras la muerte de Lenin, ideólogo de la Revolución de Octubre y principal dirigente bolchevique. Entre marzo de 1953 y el 8 de abril de 1966 el cargo se llamó Primer Secretario. A partir de esa fecha y hasta el 14 de marzo de 1990 el cargo volvió a denominarse Secretario General del PCUS.

Las Constituciones soviéticas, que se promulgaron en 1918, 1924, 1936 y 1977, no limitaron el poder del Estado. No existía una separación formal de los poderes entre el partido, el Soviet Supremo y el Consejo de Ministros que representaran a los poderes ejecutivo y legislativo del Gobierno. El sistema fue gobernado más por convenios informales que por el estatuto, y no existió ningún mecanismo asentado para la sucesión del liderazgo. Hubo amargas y a veces mortales luchas de poder en el Politburó después de la muerte de Lenin y Iósif Stalin, así como después de la destitución de Jrushchov, debido a un golpe de Estado en el Politburó y en el Comité Central. Todos los líderes soviéticos del partido antes de Gorbachov murieron en ejercicio, excepto Georgi Malenkov y Jrushchov, ambos despedidos de la dirección del partido en medio de una lucha interna dentro del mismo.

En el período de 1988 a 1990, frente a una considerable oposición, Mijaíl Gorbachov promulgó las reformas que cambiaron el poder de los órganos superiores del partido y que hicieron al Soviet Supremo menos dependiente en ellos. Se estableció el Congreso de los Diputados del Pueblo, del cual la mayoría de los miembros fueron elegidos en elecciones competitivas celebradas en marzo de 1989. El Congreso ahora elegía al Soviet Supremo, que se había convertido en un Parlamento a tiempo completo, mucho más fuerte que antes. Por primera vez desde la década de 1920, se negó a autorizar las propuestas del partido y del Consejo de Ministros. En 1990, Gorbachov introdujo y asumió el cargo de Presidente de la Unión Soviética, concentró el poder en su oficina ejecutiva, independiente del partido y subordinado al Gobierno, ahora renombrado a sí mismo como el Gabinete de Ministros de la URSS.

Las tensiones crecieron entre las autoridades de toda la unión en virtud de Gorbachov, los reformistas en Rusia dirigidos por Borís Yeltsin, controlaban al recién elegido Sóviet Supremo de la RSFS de Rusia y a los de línea dura del Partido Comunista. Del 19 al 21 de agosto de 1991, un grupo de línea dura efectuó un golpe de Estado fallido. Tras el fallido golpe, el Consejo de Estado de la Unión Soviética se convirtió en el máximo órgano de poder del Estado «en el período de transición». Gorbachov renunció como Secretario General, permaneciendo sólo como Presidente durante los últimos meses de existencia de la URSS.

El poder judicial soviético no era independiente de las otras ramas del Gobierno. La Corte Suprema supervisaba a los tribunales inferiores (Tribunales del Pueblo) y aplicaba la ley según lo establecido por la Constitución o según lo que interpretase el Sóviet Supremo. El Comité de Supervisión Constitucional revisaba la constitucionalidad de las leyes y decretos. La Unión Soviética utilizó el principio inquisitivo del Derecho romano, donde el juez, el procurador y el abogado defensor colaboraban para establecer la verdad.

Tras la negación inicial del reconocimiento diplomático por parte del mundo capitalista, la Unión Soviética llegó a tener relaciones oficiales con la mayoría de las naciones del mundo a finales de los años 1980, aumentando su importancia en la esfera internacional y pasando de estar fuera de las organizaciones y negociaciones internacionales, a ser uno de los árbitros del destino de Europa después de la Segunda Guerra Mundial. Como miembro de las Naciones Unidas desde su fundación en 1945, el país se convirtió en uno de los cinco miembros permanentes del Consejo de Seguridad de Naciones Unidas que le dio el derecho de veto de sus resoluciones (" ver " Unión Soviética y las Naciones Unidas).
Enero de 1949:

Febrero de 1949:
1950:
1962:
1972:
1978:

La Unión Soviética emergió de la Segunda Guerra Mundial como una de las dos potencias principales del mundo, una posición mantenida durante cuatro décadas a través de su hegemonía en Europa Oriental ("véase bloque del este"), fuerza militar, ayuda a los países en vías de desarrollo, e investigación científica, especialmente en tecnología espacial y armamentística. Su influencia cada vez mayor en el exterior en los años de la posguerra ayudó a conducir a un sistema comunista a los Estados de Europa Oriental, unidos por acuerdos militares y económicos. Alcanzó al Imperio Británico como superpotencia global, tanto en su sentido militar como en su capacidad de expandir su influencia más allá de sus fronteras. En 1949 nueve países de Europa Oriental fundaron el Consejo de Ayuda Mutua Económica (COMECON), como réplica al Plan Marshall y a la OECE. El objetivo del órgano era integrar la economía de estos países en la de la URSS, por medio de una rigurosa planificación, que los países miembros debían seguir obligatoriamente, y una estrecha coordinación. La contraparte militar al COMECON era el Pacto de Varsovia. La economía soviética era también de gran importancia para la Europa Oriental debido a las importaciones de recursos naturales vitales de la URSS, como el gas natural.

Moscú consideraba a Europa Oriental una zona excelente para defender sus fronteras occidentales y aseguró su control en la región transformando los países de Europa del Este en Estados satélites, algo así como los EE UU con la Europa occidental. Las tropas soviéticas intervinieron en la Revolución Húngara de 1956 y junto con el Pacto de Varsovia expulsaron a los dirigentes checoslovacos en 1968, ya que el Gobierno de ese país había dictado medidas económicas que se hallaban fuera del marco de planificación, así como otras medidas políticas. Este suceso se conoce como la «Primavera de Praga».

A finales de los años 1950, una confrontación con China derivada del acercamiento de la Unión Soviética con Occidente que Mao rechazó, sumada a una serie de reformas implementadas por Jrushchov, condujo a la ruptura sino-soviética. Esto dio lugar a una rotura a través del movimiento comunista global y de Gobiernos comunistas en Albania y Camboya que eligieron aliarse con China en lugar de la Unión Soviética. Por una época, la guerra entre los aliados anteriores parecía ser una posibilidad; mientras que las relaciones se refrescarían durante los años 1970, no volverían a la normalidad hasta la era de Mijaíl Gorbachov.

Durante el mismo período, hubo una confrontación tensa entre la Unión Soviética y los Estados Unidos sobre el despliegue soviético de misiles nucleares en Cuba durante la Crisis de los misiles de Cuba.

El KGB (Comité para la Seguridad del Estado) sirvió en cierto modo como la contraparte soviética a la Oficina Federal de Investigación (FBI) y a la Agencia Central de Inteligencia (CIA) de los Estados Unidos, funcionando con una red masiva de informantes a través de la Unión Soviética y siendo utilizada para supervisar las violaciones de la ley. La rama exterior del KGB fue utilizada para recoger información en países alrededor del globo. Después de la disolución de la Unión Soviética fue sustituido en Rusia por el SVR (Servicio de Inteligencia Extranjera) y el FSB (Servicio Federal de Seguridad).

El KGB no estaba sin control. El GRU (Directorio Principal de Inteligencia), que no fue hecho público por la Unión Soviética hasta el final de la era soviética durante la perestroika, fue creado por Lenin en 1918 y sirvió como órgano centralizado de la inteligencia militar y como controlador institucional para la energía con relativamente menos restricción que el KGB. Con eficacia, sirvió para espiar a los espías, y, curiosamente, el KGB sirvió una función similar con el GRU. Como el KGB, el GRU funcionó en otras naciones alrededor del mundo, particularmente en los Estados del bloque soviético y países satélites. El GRU continúa funcionando aún en Rusia, con unos recursos que exceden los del SVR según algunas estimaciones.

En los años 1970, la Unión Soviética alcanzó una paridad nuclear aproximada con los Estados Unidos. Percibió su propia implicación como esencial para la solución de cualquier problema internacional importante. Mientras tanto, la Guerra Fría dejó paso a la distensión y a un patrón más complicado de las relaciones internacionales en las cuales el mundo no estuvo claramente dividido en dos bloques opuestos. Los países menores tenían más capacidad de afirmar su independencia, y las dos superpotencias reconocieron su interés común en intentar controlar la extensión y la proliferación de armas nucleares ("véase SALT I, SALT II, y el Tratado sobre Misiles Anti-Balísticos").

En el año 1972 los Estados Unidos y la Unión Soviética sorprendieron al mundo, cuando anunciaron que estaban trabajando en la creación de una estación espacial única. Las delegaciones de ambas superpotencias firmaron ese mismo año un tratado en Moscú, sobre este innovador proyecto. El Proyecto de pruebas Apolo-Soyuz que entonces parecía anunciar el fin de la Guerra Fría, se convirtió en un símbolo de paz y buena voluntad que acabaría con las tensiones causadas por la carrera espacial y permitiría que cada parte conociera mejor el programa espacial del otro. El día 17 de julio de 1975, los objetivos del convenio se hicieron realidad cuando el astronauta estadounidense Thomas Stafford, comandante de la tripulación de la nave Apolo y el cosmonauta soviético Alexei Leonov, comandante de la tripulación de nave Soyuz, estrecharon sus manos en el primer saludo espacial internacional de la historia. El extraordinario trabajo conjunto y la convivencia de esta primera tripulación espacial internacional conmovió al mundo; al demostrar que ambas superpotencias podían hacer a un lado sus diferencias y unir sus esfuerzos y recursos para lograr algo semejante. El resultado de la misión conjunta fue un éxito rotundo y un logro inimaginable tanto desde el punto de vista tecnológico; cómo desde el punto de vista de las relaciones internacionales entre ambos. En 1977, poco antes de las conversaciones en Ginnebra sobre los acuerdos SALT II, las delegaciones estadounidense y soviética, firmaron un nuevo convenio espacial que prorrogaba el trabajo conjunto que hizo posible la misión Apolo-Soyuz en 1975.

Durante este tiempo, la Unión Soviética firmó tratados de amistad y de cooperación con un buen número de países no socialistas, especialmente del tercer mundo o pertenecientes al movimiento de los no aliados como la India y Egipto. A pesar de algunas diferencias ideológicas, Moscú se interesó en ganar posiciones estratégicas importantes mediante la ayuda económica y militar a los movimientos revolucionarios en el tercer mundo. Por todas estas razones, la política exterior soviética era de gran importancia para el resto de países del mundo que no integraban el campo socialista y ayudaba a determinar la dirección de la política exterior a nivel internacional.

Aunque innumerables burocracias estuvieron implicadas en la formación y la ejecución de la política exterior soviética; las pautas principales de la política fueron determinadas por el Politburó del partido comunista. Los primeros objetivos de la política exterior soviética habían sido el mantenimiento y el realce de la seguridad nacional y el mantenimiento de la hegemonía en Europa Oriental. Las relaciones con los Estados Unidos y la Europa occidental eran también una preocupación importante para los gobernantes soviéticos, y las relaciones con los Estados del tercer mundo fueron por lo menos parcialmente determinadas por la proximidad de cada Estado a la frontera soviética y a las estimaciones soviéticas de su significación estratégica.

Después de que Mijaíl Gorbachov sucediera a Konstantín Chernenko como Secretario General del PCUS en 1985 introdujo muchos cambios en la política exterior soviética y en la economía de la Unión Soviética. Gorbachov persiguió políticas conciliatorias hacia el oeste en vez de mantener el "statu quo" de la Guerra Fría. La Unión Soviética terminó su intervención en Afganistán, firmó tratados estratégicos de reducción de armas con los Estados Unidos, y permitió que sus aliados en Europa Oriental determinaran sus propios asuntos. La caída del muro de Berlín, que comenzó en noviembre de 1989, señaló dramáticamente el fin de la influencia externa de la Unión Soviética en la Europa central y oriental, culminando dos años más tarde con el desmantelamiento del sistema sovético.

Constitucionalmente, la Unión Soviética fue una unión de Repúblicas Socialistas Soviéticas (RSS) junto a la República Socialista Federativa Soviética de Rusia (RSFSR), aunque el Gobierno altamente centralizado del Partido Comunista hizo que la unión fuera meramente nominal. El Tratado de Creación de la URSS fue firmado en diciembre de 1922 por cuatro repúblicas fundadoras, la RSFSR, RFSS de Transcaucasia, RSS de Ucrania y la RSS de Bielorrusia. En 1924, durante la delimitación nacional en Asia Central, las RSS de Uzbekistán y de Turkmenistán fueron constituidas de partes de la RSFSR, que eran la RSSA de Turkestán y dos dependencias soviéticas, la RSS de Corasmia y la RPS de Bujará. En 1929, la RSS de Tayikistán se separó de la RSS de Uzbekistán. Con la Constitución de 1936, los constituyentes de la RFSS de Transcaucasia, concretamente las RSS de Georgia, Armenia y Azerbaiyán, fueron elevados a repúblicas de la unión, mientras que las RSS de Kazajistán y Kirguistán fueron separadas de la RSFSR. En agosto de 1940, la Unión Soviética formó la RSS de Moldavia de partes de la RSS de Ucrania y de la Besarabia anexionada desde Rumania. También anexó los Estados bálticos como las RSS de Estonia, Letonia y Lituania. La RSS Carelo-Finesa se separó de la RSFSR en marzo de 1940 y se fusionó en 1956. En octubre de 1944 la Unión Soviética se anexionó la República de Tannu Tuvá, Estado independiente de Asia central, que pasó a constituirse como Oblast autónomo dentro de la RSFSR. Entre julio de 1956 y en septiembre de 1991, hubo 15 repúblicas de la unión (véase el mapa abajo).

El 16 de noviembre de 1988, el Soviet Supremo de la RSS de Estonia aprobó la declaración de soberanía Estonia que reafirmó la soberanía de Estonia y declaró la supremacía de las leyes de Estonia sobre las de la Unión Soviética. En marzo de 1990, el recién elegido Soviet Supremo de la RSS de Lituania declaró su independencia, que fue seguida por el Soviet Supremo de Georgia en abril de 1991. Aunque el derecho simbólico de las repúblicas de separarse fue nominalmente garantizado por la Constitución y el Tratado de la Unión, las autoridades soviéticas se negaron a reconocerlo en un principio. Después del intento de golpe de Estado de agosto, la mayoría de las otras repúblicas siguieron el ejemplo. Finalmente, la Unión Soviética reconoció la secesión de Estonia, Letonia y Lituania el 6 de septiembre de 1991. Las repúblicas restantes fueron reconocidas como independientes con la disolución final de la Unión Soviética en diciembre de 1991.

La bandera de la Unión Soviética corresponde al emblema utilizado por dicho Estado desde su establecimiento en 1922 hasta su disolución durante 1991.

A lo largo de su historia, el emblema tuvo diversas modificaciones, pero en general mantuvo la misma estructura desde su adopción, el 12 de noviembre de 1923. La bandera, en proporción 1:2, era completamente roja (color tradicional del comunismo) y en su cantón tenía en dorado el símbolo de la hoz y el martillo y sobre este una estrella roja con borde dorado.

La bandera tuvo gran importancia para los diversos movimientos políticos de carácter marxista y sirvió de inspiración para diversos emblemas, especialmente de países socialistas durante la época de la Guerra Fría. A su vez, las diversas banderas de las repúblicas que conformaban la U.R.S.S. eran modificaciones de la bandera nacional.

El escudo de la Unión Soviética muestra los tradicionales símbolos soviéticos de la hoz y el martillo sobre un globo terráqueo, que es abrazado por dos haces de trigo rodeados por una cinta roja con el lema de la URSS escrito en los distintos idiomas de las Repúblicas Socialistas Soviéticas, en orden inverso al que son citadas en la Constitución de la URSS. Dentro de los haces y bajo el globo aparece un sol radiante, representante del porvenir, y encima del conjunto una estrella roja de cinco puntas.

El escudo fue adoptado en 1924 y se utilizó hasta la desintegración de la Unión Soviética en 1991. Se trata de un emblema y no de un escudo de armas, ya que no respeta las normas heráldicas. Sin embargo, en ruso siempre ha sido llamado "герб", la palabra usada para los escudos de armas tradicionales.

La versión usada en 1991 tenía el lema de la URSS en 15 idiomas, después de que en 1956, la República Socialista Soviética Karelo-Finesa fuera integrada en la RSFS de Rusia como "República Socialista Soviética Autónoma".

Cada "República Socialista Soviética" y cada "República Socialista Soviética Autónoma" tenían sus propios escudos de armas, claramente inspirados en el de la Unión Soviética. El escudo de la URSS también sirvió de base para muchos otros escudos de Estados socialistas, como la República Federal Socialista de Yugoslavia y la República Democrática Alemana.

La Unión Soviética se convirtió en el primer país en adoptar una economía planificada, mediante la cual la producción y distribución de bienes fueron centralizados y dirigidos por el Gobierno. La primera experiencia bolchevique con una economía de comando fue con la política del comunismo de guerra, que implicó la nacionalización de la industria, la distribución centralizada de la producción, la requisición coercitiva de la producción agrícola e intentos de eliminar la circulación de dinero, así como las empresas privadas y el libre comercio. Como en 1921, esto había agravado un severo colapso económico causado por la guerra, Lenin reemplazó al comunismo de guerra por la Nueva Política Económica (NEP), legalizando el libre comercio y la propiedad privada de las empresas más pequeñas. Con esto la economía se recuperó rápidamente.

Tras un largo debate entre los miembros del Politburó en el transcurso del desarrollo económico, ya por 1928 y 1929, al ganar el control del país, Iósif Stalin abandonó la NEP e impulsó una planificación central completa, comenzando la colectivización forzada de la agricultura. Los recursos fueron movilizados para la industrialización rápida, que amplió enormemente la capacidad soviética en la industria pesada y en bienes de capital durante la década de 1930. La preparación para la guerra fue una de las principales fuerzas impulsoras detrás de la industrialización, principalmente debido a la desconfianza en el mundo capitalista exterior. Como resultado, la URSS pasó de una economía mayoritariamente agraria a una gran potencia industrial, abriendo el camino para su surgimiento como una superpotencia después de la Segunda Guerra Mundial. Durante la guerra, la infraestructura y la economía soviética sufrieron una devastación masiva y requirieron una extensa reconstrucción.

A principios de los años 1940, la economía soviética había llegado a ser relativamente autosuficiente; la mayor parte del período hasta la creación del Comecon, solo una proporción muy pequeña de productos nacionales fueron comercializados internacionalmente. Después de la creación del Bloque del Este, el comercio exterior aumentó rápidamente. La influencia de la economía mundial en la URSS seguía siendo limitada por los precios internos fijos y un monopolio estatal sobre el comercio exterior. El consumo de granos y manufacturas sofisticadas se convirtieron en los principales artículos de importación alrededor de la década de 1960. Durante la carrera armamentística de la Guerra Fría, la economía soviética fue agobiada por los gastos militares y presionada fuertemente por una poderosa burocracia dependiente de la industria de armamentos. Al mismo tiempo, la Unión Soviética se convirtió en el mayor exportador de armas al tercer mundo. Importantes cantidades de recursos soviéticos durante la Guerra Fría fueron asignados para la ayuda de los demás Estados socialistas.

Desde la década de 1930 hasta su colpaso a finales de la década de 1980, la forma de funcionamiento de la economía soviética se mantuvo esencialmente sin cambios. La economía formalmente fue dirigida por la planificación central, llevada a cabo por el Gosplán y organizada en planes quinquenales. Sin embargo, en la práctica, los planes fueron altamente globales y provisionales, sujetos a intervenciones especiales por superiores. Todas las decisiones económicas claves fueron tomadas por los dirigentes políticos. La asignación de recursos y las metas de los planes fueron denominadas normalmente en rublos, en lugar de hacerlo en bienes físicos. El crédito estaba desalentado, pero de forma generalizada. La asignación final de la producción se logró mediante la contratación relativamente descentralizada, no planificada. Aunque en teoría los precios se establecieron legalmente desde arriba, en la práctica los precios reales a menudo se negociaron y los vínculos horizontales informales eran generalizados.

Una serie de servicios básicos fueron financiados por el Estado, tales como la educación y la salud. En el sector manufacturero, se le asignó una mayor prioridad a industria pesada y de defensa que a la producción de bienes de consumo. Los bienes de consumo, especialmente fuera de las grandes ciudades, a menudo eran escasos, de mala calidad y de elección limitada. Bajo la economía planificada, los consumidores no tenían casi ninguna influencia sobre la producción, por lo que las cambiantes demandas de una población con mayores ingresos no podían ser satisfechas con los suministros a precios rígidamente fijos. Una segunda gran economía no planificada creció junto a la planificada vigente a niveles bajos, proporcionando algunos de los bienes y servicios que los planificadores no podían ofrecer. Con la reforma de 1965, se intentó la legalización de algunos elementos de la economía descentralizada.
Aunque las estadísticas de la economía soviética son notoriamente poco confiables y su crecimiento económico difícil estimar precisamente, según la mayoría de las fuentes, la economía siguió creciendo hasta mediados de los 80. Hasta la década de 1950, la economía soviética experimentó un crecimiento relativamente alto y estaba alcanzando a Occidente. Sin embargo, desde finales de los años 50, el crecimiento, aunque aún suigió siendo positivo, declinó constantemente, mucho más rápido y consistentemente que en otros países, a pesar de un rápido aumento en el capital social (la tasa de aumento de capital sólo fue superada por Japón).

En general, entre 1960 y 1989, la tasa de crecimiento del ingreso per cápita en la Unión Soviética fue un poco superior al promedio mundial (basado en 102 países). Sin embargo, dado al muy alto nivel de inversión en capital físico, al alto porcentaje de personas con educación secundaria y al bajo crecimiento de la población, la economía debería haber crecido mucho más rápido. Según Stanley Fischer y William Easterly, el registro de crecimiento soviético estaba entre «los peores en el mundo». Según sus cálculos, el ingreso per cápita de la Unión Soviética en 1989 debería haber sido dos veces mayor de lo que lo era, si la inversión, la educación y la población hubieran tenido su típico efecto sobre el crecimiento. Los autores atribuyen este pobre desempeño a la baja productividad del capital en la Unión Soviética.

En 1987, Mijaíl Gorbachov trató de reformar y revitalizar la economía con su programa de la "perestroika". Sus políticas relajaron el control del Estado sobre las empresas, pero aun no permitía su reemplazamiento por incentivos de mercado, resultando finalmente en una fuerte disminución de la producción. La economía, que ya sufría con los bajos ingresos por la exportación de petróleo, comenzó a derrumbarse. Los precios aún eran fijados, y gran parte de las propiedades todavía eran estatales hasta después de la disolución de la Unión Soviética. Durante la mayor parte del período después de la Segunda Guerra Mundial hasta su colapso, la economía soviética fue la segunda más grande del mundo por PIB (PPA), aunque en términos per cápita el PIB soviético estaba por detrás de los países del primer mundo.

La necesidad de combustible en la URSS disminuyó desde la década de 1970 hasta la de 1980, tanto en rublos por tonelada de productos sociales brutos como en rublos por productos industriales. Al principio, esta disminución aumentó muy rápidamente, pero fue desacelerándose gradualmente entre 1970 y 1975.

Desde 1975 y 1980, la URSS tuvo un crecimiento lento, solo del 2,6 por ciento. El historiador David Wilson, creyó que la industria del gas representaba el 40 por ciento de la producción de combustible soviético a finales de siglo, pero su teoría no se concretó debido al colapso de la URSS. Teóricamente, la Unión Soviética, habría continuado teniendo una tasa de crecimiento económico del 2 al 2.5 por ciento durante la década de 1990 debido a los campos energéticos soviéticos. Sin embargo, el sector energético enfrentó muchas dificultades, entre ellas los altos gastos militares del país y las relaciones hostiles con Occidente (era pre Gorbachov).

En 1991, la Unión Soviética tenía una red de ductos de 82.000 kilómetros para petróleo crudo y otra de 206.500 kilómetros para gas natural. El petróleo, los productos a derivados del mismo, el gas natural, los metales, la madera, los productos agrícolas y una gran variedad de productos manufacturados, principalmente maquinaria, armas y equipos militares, fueron exportados. Durante la década de 1970 y 1980, la Unión Soviética dependía fuertemente de las exportaciones de combustibles fósiles para obtener divisas. En su apogeo en 1988, fue el mayor productor y el segundo mayor exportador de crudo, superada solo por Arabia Saudita.

La Unión Soviética puso mucho énfasis en la ciencia y tecnología dentro de su economía, sin embargo, los éxitos soviéticos más notables en la tecnología, como producir el primer satélite espacial, por lo general estuvieron a cargo de los militares. Lenin creía que la URSS nunca superaría al mundo desarrollado si permanecía atrasada tecnológicamente como estaba. Las autoridades soviéticas demostraron su compromiso con la creencia de Lenin, mediante el desarrollo de masivas redes de organizaciones de investigación y desarrollo. En 1989, los científicos soviéticos estaban entre los mejores especialistas capacitados del mundo en diversas áreas, tales como la energía física, determinadas áreas de la medicina, las matemáticas, la soldadura y en las tecnologías militares. Debido a la rígida planificación estatal y a la burocracia, los soviéticos permanecieron muy por detrás tecnológicamente en la química, la biología y en las computadoras, en comparación con el resto de Occidente.

El Proyecto Sócrates, bajo la administración Reagan, determinó que la Unión Soviética había abordado la adquisición de la ciencia y tecnología de una manera radicalmente diferente a la que los Estados Unidos estaba utilizando en ese momento. En el caso de los Estados Unidos, la priorización económica estaba siendo utilizada para el legado de investigación y desarrollo autóctono; y lo veía como el medio para adquirir la ciencia y tecnología tanto en el sector privado como en el público. Por el contrario, la Unión Soviética fue la ofensiva y defensiva en maniobrar la adquisición y utilización de la tecnología en todo el mundo, para así aumentar la ventaja competitiva que había adquirido a partir de la tecnología, mientras prevenía que los Estados Unidos adquieran una ventaja competitiva. Además, la planificación basada en tecnología de la Unión Soviética era ejecutada de manera centralizada, centrada en el Gobierno que obstaculizaba enormemente su flexibilidad. Esta significativa falta de flexibilidad fue aprovechada por los Estados Unidos para socavar la fuerza de la Unión Soviética y así promover su reforma.

El transporte fue un componente clave de la economía del país. La centralización económica durante las décadas de 1920 y 1930 condujo al desarrollo de la infraestructura a gran escala, particularmente el establecimiento de Aeroflot, la mayor empresa de aviación soviética. El país tenía una gran variedad de medios de transporte por tierra, agua y aire. Sin embargo, debido al mal mantenimiento, la mayor parte del transporte civil por carretera, agua y aire eran anticuados y tecnológicamente atrasados en comparación con el resto de Occidente.

El transporte ferroviario soviético fue el más grande y el más intensamente utilizado en el mundo, también fue más desarrollado que en la mayoría de sus homólogos occidentales. A finales de 1970 y comienzos de 1980, los economistas soviéticos pedían la construcción de más carreteras para aliviar parte de la carga de los ferrocarriles y mejorar el presupuesto público soviético. La red de carreteras y la industria del automóvil permanecieron subdesarrolladas, y las rutas de tierra eran comunes en las afueras de las ciudades más importantes. Los proyectos soviéticos de mantenimiento mostraron ser incapaces de hacerse cargo incluso de las pocas rutas que había en el país. Durante la primera mitad década de 1980, las autoridades soviéticas trataron de resolver el problema de las carreteras ordenando la construcción de otras nuevas. Mientras tanto, la industria automotriz estaba creciendo a un ritmo más rápido que la construcción de carreteras. La red de carreteras subdesarrollados llevó a una creciente demanda de transporte público.

La flota marina mercante soviética fue una de las más grandes del mundo.

En la Unión Soviética hubo dos formas básicas de propiedad, la "propiedad individual" y la "propiedad colectiva" (de propiedad conjunta, que en la práctica era cooperativa o estatal). Esta era muy diferente tanto en su contenido como en su condición jurídica. Según las teorías comunistas, el capital (los medios de producción) no podría ser de propiedad privada, aparte de algunas pequeñas excepciones. Tras el fin de la flexibilización a corto plazo de la Nueva Política Económica de Lenin, cualquier propiedad industrial y de terrenos pasó a ser propiedad común de los habitantes, o sea de la propiedad estatal, respectivamente. La propiedad individual podía ser compuesta únicamente por bienes personales, es decir, los de capital (los medios de producción) eran automáticamente de propiedad estatal o cooperativa.

La Unión Soviética ocupó la porción oriental del continente europeo y la porción septentrional del continente asiático. La mayor parte del país quedaba al norte de 50° de latitud norte y cubría un área total de aproximadamente 22 402 200 km². Debido al gran tamaño del Estado, el clima variaba mucho, desde subtropical y continental a subártico y polar, El 11 % de la tierra era cultivable, 16 % eran praderas y pasto, el 41 % bosque, y 32 % fue declarado como «otros» (incluyendo la tundra).

La Unión Soviética medía unos 10 000 kilómetros desde Kaliningrado, en el oeste, a la Isla de Ratmánova (Islas Diómedes), en el Estrecho de Bering, aproximadamente el equivalente a la distancia de Edimburgo, Escocia, al este de Nome, Alaska. Desde la punta de la Península de Taimir, en el Océano Ártico, al pueblo de Asia Central de Kushka, cerca de la frontera afgana, hay casi 5000 kilómetros de terreno, en su mayor parte escabroso e inhóspito. La anchura total de los Estados Unidos continentales quedaría comprendida entre las extremas fronteras septentrional y meridional de la Unión Soviética.

Los primeros cincuenta años del siglo XX en la Rusia zarista y la Unión Soviética estuvieron marcados por una sucesión de desastres, cada uno acompañado por pérdidas de grandes cantidades de población. El exceso de muertes en el transcurso de la Primera Guerra Mundial y la Guerra Civil Rusa (incluyendo la hambruna de la posguerra) ascendieron a un total de 18 millones, unos 10 millones en la década de 1930, y más de 26 millones entre 1941 y 1945. La población soviética en la posguerra fue de 45 a 50 millones menor de lo que hubiera sido si el crecimiento demográfico de la preguerra hubiese continuado.

La tasa bruta de natalidad de la URSS se redujo de 44,0 por mil en 1926 a 18,0 en 1974, en gran parte debido a la creciente urbanización y al aumento promedio de la edad de los matrimonios. La tasa bruta de mortalidad demostró así una disminución gradual – de 23,7 por mil en 1926 a 8,7 en 1974. En general, las tasas de nacimiento de las repúblicas del sur en Transcaucasia y Asia Central fueron considerablemente superiores a las de la parte septentrional de la Unión Soviética, y en algunos casos incluso aumentó en el período posterior a la Segunda Guerra Mundial, un fenómeno atribuido en parte a las menores tasas de urbanización y a los matrimonios tradicionalmente más tempranos en las repúblicas del sur. La Europa soviética se desplazó hacia la fertilidad de sub-reemplazo, mientras que la Asia Central soviética continuó mostrando un crecimiento de la población muy por encima del nivel de la fertilidad de reemplazo.

La década de 1960 y 1970 fue testigo de una reversión en la trayectoria decreciente de la tasa de mortalidad en la URSS y esto se notó sobre todo entre los hombres en edad de trabajar, pero también era algo común en Rusia y en otras áreas predominantemente eslavas del país. Un análisis de los datos oficiales de la década de 1980 demostró que después de empeorarse a finales de la década de 1970 y principios de los 80, la mortalidad adulta comenzó a mejorar nuevamente. La tasa de mortalidad infantil aumentó de 24,7 en 1970 a 27,9 en 1974. Algunos investigadores consideran que el ascenso fue real en su mayoría, a consecuencia del empeoramiento de las condiciones de salud y los servicios. El aumento en la mortalidad adulta e infantil no fue explicado o defendido por los funcionarios soviéticos, y el Gobierno soviético simplemente dejó de publicar todas las estadísticas de mortalidad durante diez años. Los demógrafos y especialistas en salud soviéticos permanecieron en silencio con respecto al aumento de la mortalidad hasta finales de los años 1980, cuando se reanudó la publicación de los datos de mortalidad y los investigadores pudieron indagar en las verdaderas causas.

La Unión Soviética fue un país muy diverso étnicamente, con más de 100 grupos étnicos distintos. La población total fue estimada en 293 millones en 1991 y según una estimación de 1990, la mayoría eran rusos (50,78 %), seguidos por los ucranianos (15.45 %) y uzbekos (5,84 %).

Todos los ciudadanos de la Unión Soviética tenían su propia filiación étnica que figuraba en el documento de identidad. El origen étnico de una persona era elegido a la edad de 16 años por los padres del niño; si estos no estaban de acuerdo, al niño se le asignaba automáticamente el origen étnico de la madre. Debido en parte a las políticas soviéticas, algunos de los grupos étnicos pequeños eran considerados como parte de los más grandes, como los mingrelios de la RSS de Georgia, que fueron clasificados con los lingüísticamente relacionados georgianos.

El extenso Estado multinacional que los bolcheviques heredaron después de su revolución fue creado por la expansión zarista durante casi cuatro siglos. Algunos grupos de naciones se unieron voluntariamente al Estado, pero la mayoría fue unida a la fuerza. Generalmente, los rusos y la mayoría de la población no rusa del imperio compartieron poco en cuanto a cultura, religión e idioma. Muy a menudo, dos o más nacionalidades diversas fueron colocadas en el mismo territorio. Por lo tanto, los antagonismos nacionales se desarrollaron con los años no sólo contra los rusos, sino a menudo entre algunas de las naciones sujetas también.

Durante cerca de setenta años, los líderes soviéticos habían mantenido que las fricciones entre las muchas nacionalidades de la Unión Soviética habían sido erradicadas y que la Unión Soviética consistía en una familia de naciones que vivían armoniosamente juntas. No obstante, el fermento nacional que sacudió a la Unión Soviética en los años ochenta probó que dicha afirmación no tenía mayor asidero con la realidad, pues las religiones y culturas tradicionales reemergerían a la más pequeña oportunidad. Esta realidad que enfrentaban Gorbachov y sus colegas significó que, ante la poca confianza en el tradicional uso de fuerza, tuvieran que encontrar soluciones alternativas a fin de evitar la disolución de la Unión Soviética.

Las concesiones otorgadas a las culturas nacionales y la autonomía limitada tolerada en las repúblicas de la Unión durante los años 1920 llevaron al desarrollo de élites nacionales y a un elevado sentido de identidad nacional. La represión subsecuente y la rusificación provocaron el resentimiento contra la dominación por parte de Moscú y promovieron el posterior crecimiento de la conciencia nacional. Los sentimientos nacionales fueron exacerbados en el Estado multinacional soviético por la competencia incrementada por los recursos, servicios y trabajos.

Antes de 1917, en el Imperio ruso, la educación era inaccesible o de difícil acceso para la mayor parte de la población, en especial para el ciudadano urbano y las familias campesinas. No existía educación pública gratuita. Las estimaciones de 1917 registraron que desde un 56 por ciento de la población rusa era analfabeta.
Luego de la revolución Anatoli Lunacharski se convirtió en el Comisariado Popular de Educación de la Rusia Soviética. Desde un comienzo, las autoridades soviéticas hicieron un gran hincapié en la alfabetización de la población. Las personas que eran alfabetizadas eran contratadas automáticamente como profesores. Durante un breve período, la calidad fue sacrificada por la cantidad. Hacia 1940, Iósif Stalin pudo anunciar que el analfabetismo había sido eliminado del país. Después de la Gran Guerra Patriótica, el sistema educativo del país se amplió considerablemente. En la década de 1960, casi todos los niños soviéticos tenían acceso a la educación primaria y secundaria, excepto aquellos que vivían en zonas remotas. Nikita Jrushchov trató de hacer la educación aún más accesible, dejándole claro a los niños que la educación estaba estrechamente vinculada a las necesidades de la sociedad. Ideológicamente, la educación era considerada fundamental para la creación del Nuevo hombre soviético.

El acceso a la educación superior era limitado: sólo el 20 por ciento de todos los aspirantes eran aceptados. El resto ingresaba al mercado de trabajo o aprendía un oficio en una Escuela Técnica Vocacional o en un Technicum, otra escuela técnica superior. Además, los estudiantes de familias de dudosa confiabilidad política solían ser excluidos de la educación superior. En este sentido, la administración de Brézhnev introdujo una norma que exigía a todos los aspirantes universitarios presentar una referencia del secretario local del partido Komsomol. Según las estadísticas de 1986, el número de estudiantes por cada 10.000 habitantes fue de 181 para la Unión Soviética, en comparación con los 517 para los Estados Unidos.

En 1917, antes de la revolución bolchevique, las condiciones de salud estaban muy por detrás de los países desarrollados. Como Lenin señaló más tarde, "«O el piojo derrota al socialismo o el socialismo derrota a los piojos»". El principio soviético de la asistencia médica fue concebido por el Comisariado del Pueblo para la Salud Pública en 1918. La asistencia médica iba a ser controlada por el Estado y se prestaría a sus ciudadanos de forma gratuita. El artículo 42 de la Constitución soviética de 1977 le dio a todos los ciudadanos el derecho a la protección de la salud y el acceso libre a cualquier institución de salud en la Unión Soviética. Sin embargo, el sistema de salud de la Unión Soviética no pudo satisfacer todas las necesidades de su pueblo. Antes de que Leonid Brézhnev llegara al poder, la medicina socializada soviética fue vista con un alto estima por muchos especialistas extranjeros. Sin embargo esto cambió; a partir de la ascensión de Brézhnev y la tenencia de Mijaíl Gorbachov como líder, el sistema de salud soviético fue criticado fuertemente por muchos errores básicos, tales como la calidad del servicio y la irregularidad en su disposición. Durante el XIX Congreso del Partido Comunista de la Unión Soviética, el Ministro de la Salud Yevgueni Cházov, además de destacar el éxito soviético por tener la mayoría de los médicos y hospitales en el mundo, reconoció las deficiencias del sistema y consideró que se habían desperdiciado miles de millones de rublos soviéticos.

Después de la toma de poder comunista, subió la expectativa de vida para todas las edades. Esta estadística fue utilizada por las autoridades para «demostrar» que el sistema socialista era superior al sistema capitalista. Se mantuvo bastante estable durante varios años, aunque en la década de 1970, bajó ligeramente, probablemente debido al abuso del alcohol. La mayoría de las fuentes occidentales culparon al creciente abuso del alcohol y a la mala asistencia médica; esta teoría también fue aceptada implícitamente por las autoridades soviéticas. Al mismo tiempo, la mortalidad infantil comenzó a aumentar y por esto, después de 1974, el Gobierno dejó de publicar estadísticas sobre este tema. Finalmente, en los años 80 la Unión Soviética poseía una esperanza de vida muy inferior a los países occidentales y comparable a países asiáticos.
Esta tendencia en parte puede explicarse por el drástico aumento en el número de embarazos en la parte asiática del país donde la mortalidad infantil era más alta, mientras disminuía notablemente en la parte europea más desarrollada de la Unión Soviética.

A. L. Eliseev escribió que en una reunión de la comisión antioreligiosa del Comité Central del Partido Comunista de toda la Unión (bolchevique) presidida por E. Laroslavskii y que tuvo lugar el 23 de mayo de 1929, los creyentes en el país fueron estimados en el 80 %. No puede descartarse que este porcentaje fue algo subestimado, para demostrar el éxito de la lucha contra la religión.

El cristianismo y el Islam tuvieron el mayor número de adeptos entre los ciudadanos religiosos del Estado soviético. El cristianismo oriental predominaba entre los cristianos, con tradicional Iglesia ortodoxa rusa siendo la denominación cristiana más grande de la Unión Soviética. Aproximadamente el 90 por ciento de los musulmanes de la Unión Soviética eran suníes, con los chiitas concentrados en la República Socialista Soviética de Azerbaiyán. Los grupos pequeños incluían, católicos, judíos, budistas y una variedad de denominaciones protestantes.

La influencia religiosa había sido fuerte en el Imperio ruso y la Iglesia ortodoxa rusa gozaba de un estatus privilegiado como la Iglesia de la monarquía participando en la realización de funciones oficiales del Estado. El período inmediato después del establecimiento del Estado soviético incluyó una lucha contra la Iglesia ortodoxa, a la que los revolucionarios consideraban una aliada de la ex clase dominante.

En el Derecho soviético, la "«libertad para celebrar servicios religiosos»" estaba garantizada constitucionalmente, aunque el Partido Comunista consideraba a la religión como incompatible con el espíritu marxista del materialismo científico. En la práctica, el sistema soviético se suscribió a una interpretación restrictiva de este derecho y de hecho utilizó una variedad de medidas oficiales para desalentar la religión y frenar las actividades de los grupos religiosos.
El decreto de 1918 del Consejo de Comisarios del Pueblo que establecía a la República Socialista Federativa Soviética de Rusia como un Estado secular también decretó que "«la enseñanza de la religión en todos [los lugares] donde se enseñen materias de aprendizaje general, está prohibida. Los ciudadanos pueden enseñar y pueden aprender religión en privado.»" Entre otras restricciones, las aprobadas en 1929, con media década de Gobierno de Stalin, incluían prohibiciones expresas de una variedad de actividades de la iglesia, incluyendo reuniones organizadas para el estudio de Biblia. Miles de establecimientos tanto cristianos como no cristianos fueron cerrados en las décadas de 1920 y 1930 y, en 1940, fueron cerradas no menos del 90 por ciento de las iglesias, sinagogas y mezquitas que habían estado operando en 1917.

Convencido de que el antisovietismo religioso se había convertido en una cosa del pasado, el Gobierno de Stalin comenzó a trasladarse hacia una política más moderada con respecto a la religión en la década de 1930. Los establecimientos religiosos soviéticos se congregaron abrumadoramente para apoyar el esfuerzo bélico durante la guerra con la Alemania nazi. En medio de otras adaptaciones a la fe religiosa, las iglesias fueron reabiertas, la Radio Moscú comenzó a transmitir un horario religioso y en 1943 fue celebrado un encuentro histórico entre Stalin y el Patriarca Sergio I de Moscú, el líder de la Iglesia Ortodoxa en ese entonces. La tendencia general de este período fue un incremento de la actividad religiosa entre los creyentes de todas las religiones.

El sistema soviético se enfrentó nuevamente con las iglesias bajo el liderazgo del Secretario General Nikita Jrushchov, que tuvo la característica de ser un período donde el ateísmo fue enfatizado en el currículum educativo y donde numerosas publicaciones estatales promovieron opiniones ateas. Entre 1959 y 1965, el número de iglesias cayó de 20.000 a 10.000, y el número de sinagogas descendió de 500 a 97. El número de mezquitas activas también disminuyó, cayendo de 1.500 a 500 en una década.

Las instituciones religiosas siguieron siendo supervisadas por el Gobierno soviético, pero todas las iglesias, sinagogas, templos y mezquitas recibieron más libertad de acción durante la época de Brézhnev. Las relaciones oficiales entre la Iglesia ortodoxa y el Gobierno soviético se calentaron nuevamente hasta el punto en que el mandato de Brézhnev honró dos veces al Patriarca ortodoxo Alejo I con la Orden de la Bandera Roja del Trabajo. Una encuesta hecha por las autoridades soviéticas en 1982 registró a un 20 por ciento de la población soviética como «"creyentes religiosos activos"».

Las estadísticas sobre delincuencia en la Unión Soviética a menudo fueron publicados de forma parcial por el Gobierno, porque esta era considerada como una vergüenza ideológica para la Unión Soviética. Según los expertos occidentales, los robos, homicidios y otros delitos violentos fueron menos frecuentes en la Unión Soviética, que en los Estados Unidos porque la Unión Soviética tenía una mayor fuerza policial, estrictos controles sobre las armas y una baja incidencia en el abuso de drogas. La corrupción en la forma de soborno era frecuente, debido principalmente a la escasez de bienes y servicios en el mercado abierto.

Aunque la prensa y radio soviéticas dieron amplia cobertura a la delincuencia en Occidente, la persistencia de la delincuencia en la Unión Soviética era una vergüenza ideológica a la que se le daba relativamente poca atención. Nunca se publicaron estadísticas detalladas acerca de la delincuencia de la URSS, y un periodista soviético, L. Vladímirov, que desertó a Gran Bretaña en 1966, confirmó que estaba prohibido mencionar el número de delitos en el país en su conjunto o por distritos, provincias, regiones o ciudades.

Una premisa básica del marxismo es que la delincuencia es un fenómeno socio-económico:

Los teóricos marxistas sostuvieron que las razones más inmediatas de delincuencia en la Unión Soviética fueron la influencia capitalista, el retraso mental y la mala educación.

En 1989 la Unión Soviética tenía pocas prisiones. Alrededor del 99 % de los criminales convictos sirvieron sus condenas en los campos de trabajo Gulag, supervisados por la Dirección General de Campos de Trabajo Correctivo que estaba bajo el MVD. Los campamentos tenían cuatro regímenes de severidad ascendente. En los campamentos de régimen estricto, los reclusos trabajaban en las tareas más difíciles, por lo general al aire libre y recibiendo raciones escasas. Los trabajos eran menos exigentes y con mejores raciones en los campamentos de los regímenes más leves. El sistema de trabajo correctivo fue considerado por las autoridades soviéticas exitoso debido a que la tasa de reincidencia era muy baja. Sin embargo, las prisiones y campos de trabajo, desde la óptica de los antiguos presos y observadores occidentales, eran conocidos por sus duras condiciones, el tratamiento arbitrario y sádico de los prisioneros y por las violaciones flagrantes de los derechos humanos. En 1989 se estuvo elaborando una nueva legislación, que hacía hincapié en la rehabilitación en lugar del castigo, para humanizar el sistema especial. Sin embargo, en 1989 las condiciones para muchos presos tuvieron pocos cambios.

La pena de muerte, llevada a cabo por fusilamiento, se aplicó en la Unión Soviética sólo en los casos de traición, espionaje, terrorismo, sabotaje, ciertos tipos de asesinato y robo a gran escala de bienes del Estado por los funcionarios. De lo contrario, la pena máxima para un delincuente que delinquía por primera vez era de quince años. La libertad condicional era permitida en algunos casos después de la finalización de la mitad de la pena y las amnistías periódicas a veces también dieron lugar a la liberación anticipada.

Cerca y tras el colapso de la Unión Soviética, las estadísticas sobre la delincuencia se movieron brusca y uniformemente hacia arriba. Entre 1991 y 1992, el número de delitos notificados oficialmente y la tasa de delincuencia general mostró un aumento del 27 por ciento; la tasa de criminalidad casi se duplicó entre 1985 y 1992. En los comienzos de la década de 1990, el hurto, robo y otros actos contra la propiedad representaron aproximadamente dos tercios de todos los delitos en Rusia. Sin embargo, el rápido crecimiento de los delitos violentos fueron los de particular interés para los ciudadanos, incluyendo los homicidios violentos.

La cultura soviética pasó por varias etapas durante los 70 años de su existencia. Durante los primeros once años de Revolución (1918–1929), hubo una relativa libertad y los artistas experimentaron con varios estilos diferentes en un esfuerzo de encontrar un estilo artístico soviético distintivo. Lenin quiso que el arte fuera accesible al pueblo ruso. Por otro lado, cientos de intelectuales, escritores y artistas fueron exiliados o ejecutados, y sus trabajos prohibidos, por ejemplo Nikolái Gumiliov (ejecutado por conspirar contra el Gobierno bolchevique) y Yevgueni Zamiatin (prohibido).

El Gobierno alentó una variedad de tendencias. En el arte y la literatura, numerosas escuelas, algunas tradicionales y otras radicalmente experimentales, proliferaron. Los escritores comunistas Máximo Gorki y Vladímir Mayakovski estuvieron activos durante este período. El cine recibió el apoyo del Estado; muchos de los mejores trabajos del cinematógrafo Serguéi Eisenstein datan de este período.

Más tarde, durante el Gobierno de Stalin, la cultura soviética se caracterizó por el auge y el dominio del estilo impuesto por el Gobierno del realismo socialista, con todas las otras tendencias siendo severamente reprimidas, con raras excepciones, por ejemplo las obras de Mijaíl Bulgákov. Muchos escritores fueron encarcelados y asesinados.

Tras el deshielo de Jrushchov de la década de 1950 y 1960, la censura disminuyó. Una mayor experimentación en formas de arte fueron nuevamente permitidas, por lo que trabajos más sofisticados y sutilmente críticos comenzaron a ser producidos. El Gobierno aflojó su énfasis en el realismo socialista; así, por ejemplo, muchos protagonistas de las novelas del autor Yuri Trífonov se preocupaban por ellos mismos y los problemas de la vida cotidiana, en lugar de hacerlo con la construcción de socialismo. Una literatura disidente clandestina, conocida como "samizdat", se desarrolló durante este último período. En la era de Jrushchov la arquitectura se centró principalmente en el diseño funcional en contraposición al estilo adornado de la época de Stalin.

En la segunda mitad de la década de 1980, las políticas de Gorbachov de la "perestroika" y "glásnost" ampliaron considerablemente la libertad de expresión en los medios de comunicación y prensa.

La nostalgia por la Unión Soviética es un fenómeno común en Rusia y la CEI del período postsoviético, así como entre los ciudadanos rusos en el extranjero nacidos en la URSS. Esta nostalgia se expresa en el sistema político, la sociedad, la seguridad social, la cultura, o la estética, además de en los recuerdos de la infancia y la juventud. Este es un fenómeno controvertido, que abarca una amplia gama de opiniones.

Según unas encuestas realizadas en 2011, a uno de cada cinco rusos le gustaría vivir nuevamente en la Unión Soviética. El número de rusos que desean vivir nuevamente en la Unión Soviética aumentó de un 16 % en 2010 al 20 %. El total del número de rusos que desean una unión con Ucrania, Bielorrusia y Kazajistán es del 37 %.

Existe un arraigado sentimiento de nostalgia por la Unión Soviética, probablemente debido al hecho de que la URSS está ligada a los recuerdos de la juventud de muchos habitantes, entre ellos todas las manifestaciones de la era soviética. También se puede deber a las actitudes y la ética de la sociedad soviética: la Unión Soviética promovía los ideales de la bondad, justicia y humanismo, y en una parte importante de la sociedad ha prevalecido el espíritu del colectivismo y rechaza muchos de los valores de la Rusia moderna. Consideran que se está produciendo una devaluación de los valores morales, y a menudo sienten frustración y resentimientos por los intentos, en su opinión, de distorsionar al pasado, menospreciando los ideales y valores sobre los cuales crecieron. En algunos casos, es una consecuencia del desorden social o la insatisfacción con la vida en la Rusia moderna, en la que una parte considerable de la población está acostumbrada al modo de vida soviético.

También desempeñan un papel importante los aspectos sociales. El nivel de vida de la mayor parte de la población cayó de manera drástica en los primeros años posteriores al colapso de la Unión Soviética y las reformas económicas que le siguieron. Además, el Estado soviético era el propietario de la superficie habitable y concedía a los ciudadanos una vivienda, además de encargarse de proporcionar la asistencia sanitaria, la educación y otros servicios sociales, por lo que los ciudadanos pueden ver el cambio como una pérdida de condiciones de vida. Los anticapitalistas también sienten nostalgia de la URSS.

Según los críticos, la nostalgia por la URSS y el sistema soviético se expresa en la negación o subestimación de las deficiencias reales que existían en la URSS (el déficit, el igualitarismo, la coerción de masas, las colas, el robo, la supresión del libre pensamiento y la disidencia, las limitaciones en las actividades creativas, los cierres fronterizos, etc.) y la exageración de las virtudes del sistema soviético (la justicia social, la estabilidad, la seguridad, los precios bajos, la accesibilidad de la vivienda, la educación, la medicina pública, etc.).





</doc>
<doc id="11345" url="https://es.wikipedia.org/wiki?curid=11345" title="Augustus De Morgan">
Augustus De Morgan

Augustus De Morgan (Madurai, India; 27 de junio de 1806 - Londres, 18 de marzo de 1871) fue un matemático y lógico británico nacido en la India. Profesor de matemáticas en el University College de Londres entre 1828 y 1866; y primer presidente de la Sociedad Matemática de Londres. Conocido por formular las llamadas leyes de De Morgan, en su memoria, y establecer un concepto riguroso del procedimiento, inducción matemática.

Augustus De Morgan nació en Madurai (Madrás, India), en 1806. Su padre era el teniente coronel John De Morgan (1772-1816), quien ocupó varios cargos al servicio de la Compañía de las Indias Orientales. Su madre, Elizabeth Dodson (1776-1856) era descendiente de James Dodson (conocido por ser el autor de tablas de anti-logaritmos). De Morgan se quedó ciego de un ojo a los dos meses de su nacimiento. La familia se trasladó a Inglaterra cuando Augustus tenía siete meses de edad. Como su padre y su abuelo habían sido ambos nacidos en la India, De Morgan solía decir que él "≪no era ni inglés, ni escocés, ni irlandés, pero sí un británico "sin ataduras"≫".

Su padre murió cuando De Morgan tenía diez años. La señora De Morgan residió en diversos lugares en el suroeste de Inglaterra, y su hijo recibió su educación primaria en varias modestas escuelas locales. Sus talentos matemáticos pasaron desapercibidos hasta que cumplió los catorce años, cuando un amigo de la familia lo descubrió haciendo un dibujo detallado de una figura de Euclides con regla y compás, le explicó a Augustus las ideas del geómetra griego, y le inició en las técnicas de demostración.

Recibió su educación secundaria del señor Parsons, miembro del Oriel College de Oxford, que apreciaba más los autores clásicos que las matemáticas. Su madre era un miembro activo y ardiente de la Iglesia de Inglaterra, y deseaba que su hijo se convirtiera en clérigo; pero ya por entonces De Morgan había empezado a mostrar su firme disconformidad con los planes de su madre.

En 1823, a la edad de dieciséis años, ingresó en el Trinity College de Cambridge, donde estudió bajo la influencia de George Peacock y William Whewell, que se convirtieron en sus amigos para toda la vida; del primero se deriva su interés por la renovación del álgebra, y del segundo su dedicación a la formalización de la lógica, los dos temas principales de su futura vida laboral. Su tutor en la universidad era John Philips Higman (1793-1855).

En la universidad aprendió a tocar la flauta, y era un personaje destacado en los clubes musicales. Su amor por el conocimiento en sí mismo interfirió con la formación necesaria para comenzar una gran carrera académica en matemáticas; como consecuencia de ello, obtuvo el grado de "cuarto wrangler". Esto le daba derecho al título de "Bachelor of Arts"; pero para obtener el grado superior de "Master of Arts" y de ese modo ser elegible para una beca, en aquella época era necesario pasar una prueba teológica. Sus convicciones le llevaron a rechazar estas pruebas, a pesar de que había sido criado en la Iglesia de Inglaterra. Alrededor de 1875 las pruebas teológicas para la obtención de grados académicos fueron abolidas en las Universidades de Oxford y de Cambridge.

Como no podía cursar ninguna carrera en su propia universidad, decidió seguir el ""Bar"" (procedimiento establecido para cualificarse en el ejercicio legal), y se instaló en Londres; aunque prefería dedicarse a enseñar matemáticas que aplicarse en la lectura de la ley. Por entonces, se estaba fundando la Universidad de Londres (actualmente University College de Londres). Las dos antiguas universidades de Oxford y Cambridge estaban tan condicionadas por las pruebas teológicas, que ningún judío o disidente fuera de la Iglesia de Inglaterra podía entrar como estudiante, y mucho menos ser nombrados para cualquier cargo académico. Un grupo de hombres de mentalidad liberal resolvió salvar este obstáculo, estableciendo en Londres una Universidad con el principio de neutralidad religiosa. De Morgan, con 22 años de edad, fue nombrado profesor de matemáticas. Su conferencia introductoria "En el estudio de las matemáticas" es un discurso sobre la educación de las mentes de valor permanente, y se ha reimpreso recientemente en los Estados Unidos.

La Universidad de Londres era una nueva institución, y las relaciones del Consejo de administración, el Senado de los profesores y el cuerpo de los estudiantes no estaban bien definidas. Surgió una controversia entre el profesor de anatomía y sus estudiantes, y como consecuencia de las medidas adoptadas por el Consejo, varios profesores renunciaron, encabezados por De Morgan. Fue nombrado un profesor de matemáticas sustituto, que falleció ahogado un par de años más tarde. De Morgan, que se había mostrado como un líder de los maestros, fue invitado a regresar a su cargo, que se convirtió a partir de entonces en el centro permanente de sus trabajos durante treinta años.

El mismo grupo de personalidades reformistas encabezadas por Lord Brougham, un eminente escocés tanto en la ciencia como en la política que había instituido la Universidad de Londres, fundan casi al mismo tiempo la Sociedad para la Difusión del Conocimiento Útil. Su objetivo era difundir todo tipo de conocimientos (especialmente el conocimiento científico) por medio de tratados económicos y claramente escritos por los mejores autores de la época. Uno de sus escritores más prolíficos y eficaces era De Morgan. Escribió una gran obra sobre el "Cálculo diferencial e integral" que fue publicada por la Sociedad; y escribió una sexta parte de los artículos en la Penny Cyclopedia, también publicada por la Sociedad, así como las emitidas en otras publicaciones. Cuando De Morgan se trasladó a residir en Londres, encontró un amigo afín en William Frend, a pesar de su "herejía matemática" sobre cantidades negativas. Ambos tenían amplios conocimientos aritméticos, y sus puntos de vista religiosos eran bastante similares. Frend vivía en lo que entonces era un suburbio de Londres, en una casa de campo antes ocupado por Daniel Defoe e Isaac Watts. De Morgan, acompañado de su flauta, era un visitante bienvenido.

"The London University", de la que De Morgan era profesor, es una institución distinta de la "University of London" (Universidad de Londres). La Universidad de Londres fue fundada cerca de diez años más tarde por el Gobierno del Reino Unido, con el fin de otorgar grados después del examen, sin ningún tipo de calificación previa como el período de residencia. "The London University" estaba afiliada como un colegio de enseñanza a la Universidad de Londres, y su nombre fue cambiado a "University College". La Universidad de Londres fracasó como organismo meramente examinador; y se convirtió en una institución de enseñanza al uso. De Morgan era un maestro de gran éxito en la docencia de las matemáticas. Daba clases de una hora de duración, y al final de cada clase planteaba una serie de problemas y ejemplos ilustrativos del tema sobre el que había disertado. Invitaba a sus estudiantes a sentarse con él y a mostrarle sus resultados, que traía revisados antes de la siguiente clase. En opinión de De Morgan, la comprensión profunda y la asimilación de grandes principios era mucho más importante que la destreza meramente analítica en la aplicación de principios y medios para manejar casos particulares.
Durante este período, también promovió la obra del matemático indio autodidacta Ramchundra, al que se llamaba el "Ramanujan de De Morgan". Supervisó la publicación en Londres del libro de Ramchundra "Máximos y mínimos" en 1859. En la introducción a este libro, reconoció ser consciente de la tradición india de la lógica, aunque no se sabe si esto tuvo alguna influencia sobre su propio trabajo.

Así mismo, fue tutor de Ada Lovelace, con la que mantuvo posteriormente correspondencia escrita.

En 1866 la cátedra de filosofía mental del "University College" quedó vacante. James Martineau, un clérigo unitarista y profesor de filosofía mental, fue recomendado formalmente por el Senado al Consejo; pero en el Consejo había algunos que se opusieron a un clérigo unitarista, y otros que se opusieron a la filosofía teísta. Un laico de la escuela de Alexander Bain y Herbert Spencer fue nombrado. De Morgan consideró que la antigua norma de la neutralidad religiosa había sido incumplida, y renunció de inmediato. Tenía entonces 60 años de edad. Sus alumnos le aseguraron una pensión de 500 libras anuales, pero sus desgracias continuaron. Dos años más tarde, su hijo George ("el "Bernoulli más joven"", como a Augustus le encantaba oír que le llamaban, en alusión a los eminentes matemáticos padre e hijo de este nombre) murió. Este golpe fue seguido por la muerte de una hija. Cinco años después de su dimisión del "University College", De Morgan moría por una afección nerviosa el 18 de marzo de 1871.

Augustus fue uno de los siete hermanos De Morgan, cuatro de los cuales sobrevivieron hasta la edad adulta.

En otoño de 1837, se casó con Sofía Elizabeth (1809-1892), la hija mayor de William Frend (1757-1841) y de Sarah Blackburne (1779-?), nieta de Francis Blackburne (1705-1787), arcediano de Cleveland.

De Morgan tenía tres hijos y cuatro hijas, incluyendo a la autora de cuentos de hadas Mary De Morgan. Su hijo mayor era el ceramista William De Morgan. Su segundo hijo, George De Morgan adquirió gran prestigio matemático en el "University College" y en la "Universidad de Londres". Con otro ex alumno de ideas afines concibió la idea de fundar la Sociedad Matemática de Londres, donde los artículos matemáticos no solo serían archivados (como en la Royal Society), si no que serían realmente leídos y debatidos. La primera reunión se celebró en el "University College"; De Morgan fue el primer presidente y su hijo el primer secretario. Era el comienzo de la Sociedad Matemática de Londres.

De Morgan era un escritor brillante e ingenioso, ya sea como polemista o como corresponsal. En su época coincidió con dos "Sir William Hamilton", que a menudo se confunden. Uno de ellos fue Sir William Hamilton, 9º Baronet (es decir, su título fue heredado), un escocés, profesor de lógica y metafísica en la Universidad de Edimburgo; el otro era un caballero (es decir, ganó el título), un irlandés, profesor de astronomía en la Universidad de Dublín. El barón contribuyó a la lógica, sobre todo a la doctrina de la cuantificación del predicado; el caballero, cuyo nombre completo era William Rowan Hamilton, contribuyó a las matemáticas, especialmente al álgebra geométrica, siendo el primero en describir los cuaterniones. De Morgan se interesó por el trabajo de ambos, y mantuvo correspondencia con los dos; pero la correspondencia con el escocés terminó en una controversia pública, mientras que con el irlandés mantuvo una amistad que terminó solamente a su muerte. En una de sus cartas a Rowan, De Morgan dice:

La correspondencia de De Morgan con Hamilton el matemático se prolongó durante más de veinticuatro años; contiene discusiones no solo de asuntos matemáticos, sino también de temas de interés general. Se caracterizaba por la genialidad de Hamilton y por el ingenio por parte de De Morgan. La siguiente es una muestra: Hamilton escribió,

De Morgan respondió:

De Morgan estaba lleno de peculiaridades personales. Con motivo de la toma de posesión de su amigo, Lord Brougham, como Rector de la Universidad de Edimburgo, el Senado se ofreció a conferirle el grado honorífico de "LL. D."; Morgan declinó el honor por haberse denominado con un nombre inapropiado. Una vez mandó imprimir su nombre de esta manera:

No le gustaba desplazarse fuera de Londres, y mientras su familia disfrutaba a la orilla del mar, y los hombres de ciencia pasaban buenos ratos en las reuniones de la Asociación Británica en cualquier rincón de Inglaterra, él permanecía en las bibliotecas sofocantes y polvorientas de la metrópoli. Dijo que se sentía como Sócrates, quien declaró que "cuanto más lejos estaba de Atenas, más lejos estaba de la felicidad". Nunca trató de convertirse en miembro de la Royal Society ni asistió a una de sus reuniones; dijo que no tenía ideas o simpatías en común con el estudio de la física. Su actitud era posiblemente debida a sus limitaciones físicas, ya que le impedían ser un buen observador o experimentador. Nunca votó en una elección, y nunca visitó la Cámara de los Comunes, la Torre de Londres, o la Abadía de Westminster.
El título original de esta obra en inglés es ""A Budget of Paradoxes"". Fue publicada póstumamente en 1872 por su esposa, un año después de la muerte del matemático. El libro refleja muy bien el carácter irónico de De Morgan, que no deja de asombrarse ante la abundancia de descubridores revolucionarios (falsos "paradoxers" los denomina), que pretenden haber resuelto problemas irresolubles, como la cuadratura del círculo o la trisección del ángulo.
En la introducción al libro, De Morgan explica lo que quiere decir con la palabra "paradoja":

¿Cómo puede distinguirse el falso paradoxer del verdadero? De Morgan suministra la siguiente prueba:

Su ""Colección"" consiste en la revisión de una gran recopilación de libros "paradójicos", que De Morgan había acumulado en su propia biblioteca, en parte formada por sus compras en librerías, por los libros que le enviaban para su revisión, y por los libros enviados por sus propios autores. Incluye la siguiente clasificación: Cuadradores de círculos; Trisectores de ángulos; Duplicadores de cubos; Constructores de movimientos perpetuos; Anuladores de la gravitación; Inmovilizadores de la Tierra; y Constructores del Universo. Opina que aún pueden encontrarse "especímenes" de todas estas clases en el Nuevo Mundo y en el nuevo siglo. De Morgan da su conocimiento personal de los "paradoxers":

Un paradoxer al que De Morgan hizo el mismo "regalo" que Aquiles hizo a Héctor -arrastrarlo alrededor de las murallas una y otra vez- fue James Smith, un exitoso comerciante de Liverpool, quien aseguraba haber encontrado que formula_1. Su modo de razonamiento era una curiosa caricatura de la ""reductio ad absurdum"" de Euclides. Decía que formula_1, y entonces exponía que en tal caso cualquier otro valor de formula_3 debía ser absurdo. En consecuencia, formula_4 es el valor verdadero. Lo que sigue es una muestra del ""arrastre efectuado por De Morgan en torno a las murallas de Troya"":

En la región de la matemática pura, De Morgan podía distinguir fácilmente la falsa de la verdadera paradoja; pero no era tan experto en el campo de la física. Su suegro y su esposa podrían considerarse de alguna manera "paradoxers"; y en opinión de los físicos de su tiempo, el propio De Morgan a duras penas escapaba de esta denominación. Su esposa escribió un libro que describe los fenómenos del espiritismo, mesa-rap, mesas giratorias, etc.; y De Morgan redactó un prefacio en el que aseguraba que conocía algunos de los hechos afirmados, y que creía en otros mediante testimonios, pero que no pretendía saber si fueron causados por espíritus, o tenían algún origen desconocido e inimaginable. De esta alternativa dejaba fuera las causas materiales ordinarias. Faraday pronunció una conferencia sobre espiritismo, en la que dejó sentado que la investigación debe establecer la idea de lo que es físicamente posible o imposible; De Morgan no creía en esto.

Siendo ya un hombre maduro, De Morgan se interesó en los fenómenos del espiritismo. En 1849 había investigado la clarividencia y quedó impresionado por la experiencia. Más tarde se llevaron a cabo investigaciones paranormales en su propia casa con la médium María Hayden. El resultado de estas investigaciones fue publicado posteriormente por su esposa Sophia. De Morgan pensaba que su carrera como científico podría haber sido afectada si se hubiera revelado su interés en el estudio del espiritismo, por lo que contribuyó a editar el libro de forma anónima. Fue publicado en 1863, con el título:""From Matter to Spirit: The Result of Ten Years Experience in Spirit Manifestations."" (""De la materia al espíritu: El Resultado de diez años de experiencias en manifestaciones de espíritus."")

De acuerdo con Oppenheim (1988), la esposa de De Morgan, Sophia, era una espiritista convencida, pero De Morgan mantenía una posición distinta ante los fenómenos espiritistas que Oppenheim define como una "posición de esperar y ver"; no era ni un creyente ni un escéptico. Su punto de vista era que la metodología de las ciencias físicas no excluye automáticamente los fenómenos psíquicos y que esos fenómenos pueden ser explicables posteriormente por la posible existencia de fuerzas naturales que los físicos aún no habían identificado.

En el prefacio de ""De la materia al espíritu"" (1863) De Morgan decía:

En ""Parapsicología: Una Historia Concisa"" (1997), John Beloff escribió que "De Morgan fue el primer científico notable en Gran Bretaña interesado en el estudio del espiritismo, y sus actividades habrían influido en la decisión de William Crookes de estudiar también el espiritismo". También afirma que De Morgan era un ateo y que esto le privó de alcanzar una posición en Oxford o Cambridge.

Cuando el estudio de las matemáticas revivió en la Universidad de Cambridge, también lo hizo el estudio de la lógica. El espíritu de este movimiento era Whewell, el Maestro del Trinity College, cuyos escritos principales eran una ""Historia de las ciencias inductivas"" y una ""Filosofía de las ciencias inductivas"". Sin duda, De Morgan fue influenciado en sus investigaciones lógicas por Whewell; pero otros contemporáneos influyentes fueron Sir William Rowan Hamilton de Dublín, y el profesor Boole de Cork. El trabajo de De Morgan en lógica formal, publicado en 1847, es principalmente notable por su desarrollo del silogismo numéricamente definido:

Este único principio es suficiente para demostrar la validez de todos los modos de razonamiento aristotélicos. Por lo tanto, es un principio fundamental en el razonamiento deductivo.

He aquí que De Morgan había hecho un gran avance con la introducción de la cuantificación de los términos. En esa época, el filósofo Sir William Hamilton estaba enseñando en Edimburgo una "doctrina de la cuantificación del predicado", y surgió la correspondencia entre ambos. Sin embargo, De Morgan percibe pronto que la cuantificación de Hamilton era de un carácter diferente; que significaba, por ejemplo, que las expresiones "La totalidad de A es la totalidad de B", y "La totalidad de A es parte de B", podían sustituir a la forma Aristotélica "Todo A es B". Hamilton pensaba que "había colocado la piedra angular del arco aristotélico", como así lo expresó. Curioso arco éste, que se había sostenido durante 2.000 años sin una piedra angular. Como consecuencia de ello, no prestaba atención a las innovaciones de De Morgan, le acusó de plagio, y la controversia se extendió durante años en las columnas de la revista del Athenæum, y en las publicaciones de los dos escritores.

El trabajo de De Morgan titulado "Trigonometry and Double Algebra" contiene dos partes; la primera es un tratado de trigonometría, y la segunda es un tratado de álgebra generalizada, a la que llamó "Álgebra doble".

La teoría del álgebra de George Peacock fue mejorada por D.F. Gregory, un miembro más joven de la Escuela de Cambridge, quien hizo hincapié no en la permanencia de formas equivalentes, sino en la permanencia de ciertas leyes formales. Esta nueva teoría del álgebra como la ciencia de los símbolos y de sus leyes de combinación, llevó a la edición por De Morgan basada en la lógica; y su doctrina, sobre el tema, todavía es seguida por un gran número de algebristas británicos. Así, George Chrystal basó su libro de texto de álgebra en la teoría morganiana; aunque un lector atento puede observar que prácticamente la abandona cuando se enfrenta al tema de las series infinitas. La teoría morganiana se reafirma en su volumen sobre "Trigonometría y Álgebra doble", donde en el Libro II, Capítulo II, dedicado al "Álgebra simbólica", escribe:
La primera etapa en el desarrollo del álgebra es "aritmética", donde solo aparecen números y operadores tales como formula_5, formula_6, etc.

La segunda etapa es la "aritmética universal", donde las letras sustituyen a los números para denotarlos universalmente, y los procesos se llevan a cabo sin conocer los valores de estos símbolos. Se tiene que formula_7 y formula_8 reperesentan cualquier cantidad; entonces una expresión como formula_9 no se puede calcular; si bien en la aritmética universal se habla de "previsión", es decir, "que la operación prevista es posible".

La tercera etapa es el "álgebra sencilla", donde un símbolo puede afectar a una cantidad por delante o por detrás, pudiendo representarse adecuadamente como segmentos en una línea recta pasando por su origen. Las cantidades negativas son entonces posibles; se representan con segmentos en sentido contrario. Pero una imposibilidad todavía permanece en la parte final de una expresión como formula_10 que surge en la resolución de una ecuación cuadrática.

La cuarta etapa es el "álgebra doble". La simbología algebraica denota en general un segmento de una línea en un plano dado. En una simbología doble se involucran dos especificaciones, nominalmente, longitud, y dirección; formula_11 es interpretado como una dimensión en otro cuadrante. La expresión formula_10 entonces representa una línea en el plano con una abscisa formula_7 y una ordenada formula_8. Argand y Warren habían llevado el álgebra doble mucho más allá; pero no fueron capaces de interpretar en sus teorías expresiones como formula_15. De Morgan lo intentó "reduciéndola" como una expresión de la forma formula_16, y demostró que había hallado un procedimiento para lograr esta reducción en cualquier caso. El hecho destacable es que esta álgebra doble satisface todas las leyes fundamentales enumeradas, y cualquier combinación de símbolos aparentemente imposible podía ser interpretada como si tuviese la forma completa del álgebra. En el capítulo 6 introduce las funciones hiperbólicas y analiza la conexión entre la trigonometría común y la hiperbólica.

Si la teoría anterior es cierta, la siguiente etapa de desarrollo debería ser el ""Álgebra triple"" y si formula_10 realmente representa una línea en un plano dado, debería ser posible encontrar un tercer elemento que añadido a los anteriores fuese asimilable a una recta en el espacio. Argand y muchos otros supusieron que era formula_18 aunque esto contradecía los postulados de Euler, en los que formula_19. De Morgan y otros muchos trabajaron duramente en este problema sin éxito hasta que intervino Hamilton. Ahora puede verse claramente el porqué: la simbología del álgebra doble denota no una longitud y una dirección; si no "un módulo" y "un ángulo". Los ángulos están confinados en un plano. Entonces la siguiente etapa será un ""Álgebra cuádruple"", en la que el eje del plano se hace variable. Esto brinda la respuesta a la primera cuestión; el Álgebra doble analíticamente representa la trigonometría del plano, y por esto se convirtió en la herramienta natural del análisis de la corriente eléctrica alterna. Pero De Morgan nunca fue tan lejos. Murió con el convencimiento de que "el álgebra doble permitirá completar el desarrollo de las concepciones de la aritmética pendientes, tan lejos como estos símbolos están involucrados, como la propia aritmética sugiere inmediatamente".

En el capítulo 2 del segundo libro, continuando sus planteamientos teóricos acerca del álgebra simbólica, De Morgan procede a inventariar tanto los símbolos fundamentales del álgebra como sus leyes. Los símbolos son formula_20, formula_21, formula_5, formula_23, formula_6, formula_25, formula_26, y letras; solo estos, todos los demás se derivan de los anteriores. Como De Morgan explica, el último de estos símbolos permite escribir un exponencial, situándolo por encima y a continuación de una expresión dada. Su inventario de leyes fundamentales se reduce a catorce puntos, aunque algunos son meras definiciones. La lista precedente de símbolos figura bajo el primero de estos catorce puntos. Las leyes propiamente dichas pueden reducirse a las siguientes, que como él mismo admite, no son totalmente independientes entre sí, "pero el carácter asimétrico de la operación exponencial, y el deseo de conectar los procesos de formula_5 y formula_6... se prestan necesariamente a mantenerlas por separado":

De Morgan procede a dar un inventario completo de las leyes a las que obedecen los símbolos del álgebra, afirmando que "Cualquier sistema de símbolos que obedezca estas reglas y no otras; excepto que estén formadas por combinaciones de estas mismas reglas; es entonces un "álgebra simbólica"." Desde este punto de vista, ninguno de los principios anteriores son reglas; formalmente son leyes, esto es, arbitrariamente eligen relaciones a las que los símbolos algebraicos están sujetos. De Morgan no menciona la ley, que anteriormente había sido apuntada por Gregory, nominalmente: formula_29, posteriormente llamada "Ley Asociativa". Si la Ley Conmutativa falla, la Ley Asociativa debe establecerse mejor; pero no al revés. Es una desafortunada circunstancia para simbolistas y formalistas que en aritmética universal formula_30 no es igual que formula_31; entonces la Ley Conmutativa tendría alcance pleno.¿Por qué no se le dio alcance pleno? Porque los cimientos del álgebra son, después de todo, reales y no formales, materiales y no simbólicos. Para los formalistas, las operaciones exponenciales son demasiado inmanejables, en consecuencia no las consideran, relegándolas a la matemática aplicada.

De Morgan descubrió el álgebra de relaciones en su obra "Syllabus of a Proposed System of Logic" ("Programa de una Propuesta de Sistema Lógico"), publicada en 1860. Esta álgebra fue extendida por Charles Sanders Peirce (quien admiraba a De Morgan y llegó a reunirse con él), y nuevamente expuesta y extendida en el vol. 3 del "Vorlesungen über die Algebra der Logik" de Ernst Schröder. El álgebra de relaciones fue una prueba crítica del "Principia Mathematica" de Bertrand Russell y Alfred North Whitehead. A su vez, esta álgebra llegó a ser el objeto de mucho más trabajo, iniciado en 1940 por Alfred Tarski y sus colegas y estudiantes de la Universidad de California.

Principalmente a través de los esfuerzos de Peacock y Whewell, se había creado en Cambridge una Sociedad Filosófica; y para sus Anales (("Mathematical Proceedings of the Cambridge Philosophical Society")) De Morgan contribuyó con cuatro memorias sobre los fundamentos del álgebra, e igual número de escritos para la lógica formal.

Estas memorias sobre lógica con las que De Morgan contribuyó a las Transacciones de la Sociedad Filosófica de Cambridge posteriores a la publicación de su libro sobre ""Lógica Formal"" son, con mucho, las más importantes contribuciones que hizo a la ciencia, en especial su cuarta memoria, en la que comienza el trabajo en el amplio campo de la ""Lógica de Relativos"". Este campo ha adquirido gran relevancia posterior, orientado al mejor conocimiento de la lengua y de los procesos de pensamiento. Identidad y diferencia son las dos principales relaciones consideradas por los lógicos; pero hay otras muchas igualmente merecedores de estudio, como la igualdad, la equivalencia, la consanguinidad, la afinidad, etc.

En la moderna lógica matemática, se conocen con la denominación de Leyes propuestas por De Morgan los siguientes principios fundamentales del álgebra de la lógica:
En escritura formal simbólica:

Los escritos de De Morgan publicados en forma de obras completas, formarían una pequeña biblioteca, como es el caso por ejemplo de sus escritos para la Sociedad del Conocimiento Útil. La mejor presentación de su visión del álgebra se encuentra en el volumen titulado "Trigonometría y Álgebra Doble", publicado en 1849. Su obra "más peculiar" fue su estudio de los que él denominaba "paradoxers" ("A Budget of Paradoxes"); que originalmente apareció publicado en forma de cartas en las columnas de la revista del Athenæum; fue revisada y ampliada por De Morgan en los últimos años de su vida, y publicada póstumamente por su viuda. Desde el punto de vista estrictamente académico, su obra más reconocida es "La lógica formal o el cálculo de inferencias necesarias y probables" (1847).

Cronológicamente, sus principales obras se ordenan de la siguiente manera (relación de títulos originales en inglés):





</doc>
<doc id="11346" url="https://es.wikipedia.org/wiki?curid=11346" title="Rabia">
Rabia

La rabia es una enfermedad zoonótica viral, de tipo aguda e infecciosa. Es causada por un "Rhabdoviridae" que ataca el sistema nervioso central, cursando una encefalitis con una letalidad cercana al 100%. 

El virus de la rabia pertenece a la familia Rhabdoviridae, género Lyssavirus tipo 1, tiene forma de bala o bastoncillo y mide entre 130 y 240 por entre 65 y 80nm. Este virus consta de una sola cadena de ARN. Su envoltura está constituida por una capa de lípidos cuya superficie contiene cinco proteínas estructurales: la G (glico proteína) que alterna con proteínas M1 y M2 (proteínas matriz); en la nucleocápside se encuentran las proteínas N (nucleoproteína), NS (nucleocápside) y L (transcriptasa). La glicoproteína es el mayor componente antigénico, responsable de la formación de anticuerpos neutralizantes que son los que confieren inmunidad. No obstante, es posible que participen otros mecanismos en la protección contra la enfermedad.

El virus de la rabia se encuentra difundido en todo el planeta y ataca a mamíferos, tanto domésticos como salvajes, incluyendo también al ser humano. Se encuentra en la saliva y en las secreciones de los animales infectados y se inocula al humano cuando animales infectados lo atacan y provocan en el humano alguna lesión por mordedura. Además el virus puede ser transfundido también cuando un individuo que tiene algún corte en la piel (vía de entrada del virus) tiene contacto con las secreciones salivales de un animal infectado.

La rabia es una zoonosis causada por un virus de la familia Rhabdoviridae. Esta enfermedad afecta a todos los mamíferos ubicados en dos grandes nichos ecológicos: aéreo (murciélagos) y terrestre (perros, gatos, mangostas, zorros, hurones, mapaches y lobos).

Los indicios para saber si un murciélago presenta rabia son:

En general los demás animales presentan una secreción salival abundante, que actúa como cultivo del virus, y, en etapas avanzadas, sangrado de orificios.

La rabia se transmite a través de mordedura o contacto directo de mucosas o heridas con saliva del animal infectado. También se ha documentado su adquisición a través de trasplante corneal de donante muerto infectado por rabia y no diagnosticado, por aerosol en cuevas contaminadas con guano de murciélagos o en personal de laboratorio. Aunque no se ha documentado su transmisión por mordedura de humano a humano, el virus se ha aislado de la saliva de pacientes con rabia. Este virus también se ha identificado en sangre, leche y orina. No se ha documentado transmisión transplacentaria. 
El virus se excreta en el animal infectado desde cinco días de las manifestaciones clínicas, aunque en el modelo experimental este período puede extenderse hasta 14 días antes de la aparición de la enfermedad.

El período de incubación varía desde cinco días a un año, con un promedio de 20 días. Existe alguna evidencia de replicación local del virus en las células musculares en el sitio de la herida. Sin embargo, es posible que el virus se disemine al sistema nervioso central sin previa replicación viral, a través de los axones, hasta el encéfalo, a una velocidad de 3 mm/h (en modelos animales), con replicación exclusivamente en el tejido neuronal.

La rabia se manifiesta por un periodo prodrómico que dura de dos a diez días con signos y síntomas inespecíficos como cansancio, cefalea, fiebre, anorexia, náusea, vómito y parestesias en el sitio de la herida, seguidas de dificultad para la deglución, hidrofobia entre el 17% y 50% de los casos, desorientación, alucinaciones visuales u olfatorias, crisis convulsivas focales o generalizadas, periodos de excitabilidad y aerofobia. En el 20% de los casos aproximadamente la rabia puede manifestarse como una parálisis fláccida. Estas manifestaciones clínicas son seguidas por un período de coma y que tiene como desenlace el fallecimiento en la gran mayoría de los casos.

Esta enfermedad, si no se trata con la máxima urgencia, acaba provocando la muerte del enfermo. No existe en la actualidad tratamiento específico para los pacientes con rabia. Esta enfermedad se considera generalmente fatal. Solo existen informes aislados de supervivencia con medidas de cuidados intensivos. Cuando una persona se contagia, los síntomas de la enfermedad pueden tardar entre 60 y 300 días en manifestarse.

La transmisión solo es posible mediante el contacto directo con un vector portador o con material biológico procedente del mismo, ya que al tratarse de un virus con una envoltura lipídica es muy sensible a los factores ambientales (lábil).

La rabia es un padecimiento de distribución prácticamente universal, a excepción de Australia, que afecta tanto a animales domésticos como salvajes. En países menos industrializados, la exposición a animales domésticos (perro y gato) constituyen la mayor fuente de la rabia humana, a diferencia de países como Estados Unidos en donde los animales salvajes (incluyendo murciélagos) constituyen el reservorio de rabia más importante. El virus comienza a excretarse en el animal infectado a partir de cinco días antes de las manifestaciones clínicas.

En México, la rabia humana y canina representan un problema de salud pública. El Compendio Estadístico de Morbilidad de la SSA reporta una tasa de 0.03/100000 habitantes, para 1994.

La Organización Mundial de la Salud (OMS) maneja datos que corroboran que en algunas regiones aún es un gran problema de salud pública como en algunos países de Asia y África, en los que causa más de 55000 muertes al año, de las cuales la mayoría de las víctimas son personas menores de 15 años de edad. Se estima que la rabia causa 31000 muertes al año en Asia, lo que representa el 60% de los fallecimientos por esta causa en el mundo.

En los últimos años, el número de casos ha aumentado en China y en Vietnam debido al consumo habitual humano, sin las debidas condiciones higienicosanitarias, de perros y gatos. Según las últimas estadísticas del año 2007, en China, donde menos del 10% de los perros están vacunados, 3380 personas murieron por rabia.

La rabia es un virus que puede ser trasmitido a cualquier mamífero. Los vectores de transmisión más comunes son perros y gatos en zonas urbanas o rurales y murciélagos en zonas silvestres. 

El virus se presenta comúnmente en el sistema nervioso o en la saliva del animal afectado. Generalmente, aunque no siempre, el virus es transmitido debido a una mordedura. Recientemente, se han presentado datos de contagio por exposiciones atípicas consistentes básicamente en contagios por manejo de carne y vísceras de animales infectados en cocinas.

En muchos casos los animales infectados tienen un comportamiento variable, son extremadamente violentos y atacan sin provocación aparente.

La patología en la especie humana es la siguiente:


Sintomáticamente, el enfermo pasa por cuatro fases:


A partir de la segunda fase, es mortal en el 99,9% de los casos. La única opción de tratamiento es suministrar inmunoglobulinas e inyectar una vacuna contra el virus, lo que solo es eficaz durante la fase de incubación.

Un diagnóstico seguro es post-mortem. No obstante, se puede diagnosticar por microscopía gracias a la aparición de los llamados “cuerpos de Negri” en las células.


En el tratamiento contra pacientes infectados por el virus Rhabdoviridae consiste primero en un lavado exhaustivo con abundante agua y jabón y la atención hospitalaria oportuna. Debe suministrarse una dosis de inmunoglobulina antirrábica humana (HRIG) además de cuatro dosis de vacuna antirrábica administradas dos semanas después. Si se presenta una herida, la dosis completa de inmunoglobulina antirrábica humana debe aplicarse, si es posible, en la herida. La primera dosis de la vacuna se administra al mismo tiempo, y el resto de las inyecciones se administran en los días 3, 7 y 14 después de la inyección inicial. Las personas que tienen sistemas inmunológicos debilitados pueden requerir una quinta dosis de la vacuna.

Una persona que ha sido vacunada contra la rabia y ha sido expuesta al virus de la rabia debe recibir dos dosis de vacuna de refuerzo tres días después de haber estado expuesta. Estas personas no necesitan una inyección de inmunoglobulina antirrábica humana.

Debe evitarse la sutura de la herida porque el virus Rhabdoviridae es anaeróbico y el cierre de la misma favorecería su multiplicación. La herida se cierra si afecta el funcionamiento del órgano comprometido, si es demasiado extensa (se sutura con catgut 2-0 haciendo puntos simples separados entre 1 y 2 cm) o si afecta zonas como cara, genitales o pliegues.

En lo que tiene que ver son la aplicación del toxoide antitetánico, no está demostrada su eficacia.

Si el paciente presenta algún tipo de síntoma neurológico debe inducirse un coma, a la espera de la respuesta del sistema inmune innato y la activación de la inmunidad adaptativa mediada por los linfocitos T1. Ha de precisarse que en cualquiera de los casos se puede presentar muerte por paro cardiorrespiratorio de origen central.

La vacuna antirrábica para humanos es elaborada sobre la base de cerebro de ratón lactante, la cual se aplica en dosis de 2 ml. por vía subcutánea y periumbilical. En pacientes gestantes se aplica en región interescapular o deltoidea. El tratamiento es de diez dosis, en un esquema de 7 dosis en serie, seguido de 3 refuerzos: al décimo, vigésimo y sexagésimo día contados a partir de la última vacuna de la serie. 


El tratamiento post exposición contempla la aplicación de la vacuna antirrábica solamente (esquema reducido 10 dosis) o aplicación de vacuna antirrábica + suero antirrábico (esquema clásico 14 dosis más suero) y dicho esquema depende del tipo de exposición y de la condición del animal agresor.

Actualmente se ha aprobado el esquema de 5 dosis los días 0,3,7,14 y 28 post exposición.

Si tiene niños en casa hay que cuidarlos de animales que tengan esta enfermedad.


Tanto el suero como la gammaglobulina proporcionan una protección inmediata, con duración de aproximadamente 21 días.


Se calcula que 1 por cada 8000 receptores de vacuna, pueden presentar alguna complicación neurológica como encefalitis, mielitis transversa, neuropatía periférica y neuritis. Las complicaciones están en relación directa con el número de dosis de vacuna y la edad del paciente. En caso de presentarse cualquiera de estas reacciones adversas debe suspenderse este tipo de vacuna y continuar con la de células diploides con el esquema señalado en el cuadro 13.

Se pueden utilizar esteroides en el manejo de las reacciones severas, que pongan en peligro la vida del paciente.


Las complicaciones neurológicas asociadas a la vacuna se han correlacionado a la inadecuada inactivación del virus y en las vacunas iniciales a la presencia de tejido neuronal.


Se ha reportado en el mundo siete casos de supervivencia a la rabia. El primero, el de la paciente Jeanna Giese) ocurrió después de que se indujera al paciente a un estado de coma. Mediante este proceso, los médicos fueron capaces de curar la enfermedad en ese caso particular.

El 10 de abril de 2008 en Cali, Colombia, un diario local reportó que un niño de 11 años podría haberse recuperado después de un tratamiento de inducción al coma.<ref name="El Tiempo_10/04/08">El Tiempo Nación Cali, "Nuevos síntomas dan aliento sobre recuperación de niño caucano contagiado por rabia", April 10th 2008()</ref> Este niño se habría infectado el 15 de febrero de 2008 cuando varios niños fueron mordidos por un gato al maltratarlo e intentarlo matar, en Santander de Quilichao, un poblado cercano a Cali. Sin embargo no fue posible aislar el virus de la rabia de muestras de saliva, cabello y líquido cefaloraquídeo pertenecientes al niño superviviente que fueron enviadas al Instituto Pasteur en Brasil y al Instituto Nacional de Salud en Bogotá, por lo que algunos creen que nunca padeció la enfermedad. Aun así se ha comprobado la supervivencia de 6 personas infectadas a partir de fase 2 de la enfermedad, por lo que el tratamiento de dicho protocolo podría estar bien encaminado.

En el mes de junio de 2013, el chileno Cesar Barriga sufrió la mordedura de un perro contagiado con rabia. Luego de desarrollar los síntomas de la enfermedad, se le indujo un coma por un periodo de un mes, al cabo del cual pudo recuperarse, transformándose en el séptimo sobreviviente mundial de la enfermedad, desde que se tiene registro.


Los perros son una de las especies que transmiten el virus a los humanos.

La rabia urbana se presenta mayoritariamente en zonas cuya densidad poblacional canina es alta; por ello, la forma de prevención más eficaz para detener el ciclo de transmisión vírica son las campañas masivas de vacunación, de este modo se consigue la disminución de perros susceptibles a la enfermedad.
Otra medida que se debería tomar en cuenta es la esterilización de las mascotas para disminuir la población canina callejera.
Los murciélagos son los principales transmisores de la rabia silvestre, siendo más difícil su control.




</doc>
<doc id="11363" url="https://es.wikipedia.org/wiki?curid=11363" title="Georg Cantor">
Georg Cantor

Georg Ferdinand Ludwig Philipp Cantor (San Petersburgo, 3 de marzo de 1845-Halle, 6 de enero de 1918) fue un matemático nacido en Rusia, aunque de ascendencia alemana y judía. Fue inventor con Dedekind y Frege de la teoría de conjuntos, que es la base de las matemáticas modernas. Gracias a sus atrevidas investigaciones sobre los conjuntos infinitos fue el primero capaz de "formalizar" la noción de infinito bajo la forma de los números transfinitos (cardinales y ordinales).

Vivió aquejado por episodios de depresión, atribuidos originalmente a las críticas recibidas y sus fallidos intentos de demostración de la hipótesis del continuo, aunque actualmente se cree que poseía algún tipo de "depresión ciclo-maníaca". Murió de un ataque cardíaco en la clínica psiquiátrica de Halle.

Era hijo del comerciante Georg Waldemar Cantor y de Marie Böhm. Su padre había nacido en Copenhague, Dinamarca, pero emigró en 1845 a San Petersburgo. Allí nació su hijo y vivieron hasta que en 1856 una enfermedad pulmonar impulsó al padre a trasladar a su familia a Fráncfort del Meno, Alemania. Todos estos eventos provocaron que distintas naciones reclamaran como propio a Georg Cantor.

La educación primaria de Georg Cantor fue inicialmente confiada a un profesor particular, pasando luego a la escuela elemental de San Petersburgo. Cuando la familia se mudó a Alemania, Cantor asistió a escuelas privadas de Fráncfort y Darmstadt hasta que a los 15 años de edad ingresó al Instituto de Wiesbaden.

Los estudios universitarios de Georg Cantor se iniciaron en 1862 en Zúrich, pero al siguiente año, después de la muerte de su padre, pasó a la Universidad de Berlín donde se especializó en matemáticas, filosofía y física, aunque el interés del joven se centró en las dos primeras. Tuvo como profesores en el campo de las matemáticas a Ernst Kummer, Karl Weierstrass y Leopold Kronecker.

En 1872, cuando contaba con 27 años de edad, se convirtió en catedrático en la Universidad de Halle, dando inicio entonces a sus principales investigaciones.

Sus primeros trabajos con las series de Joseph Fourier le llevaron al desarrollo de una teoría de los números irracionales y en 1874 apareció su primer trabajo sobre la Teoría de conjuntos.

En cuanto al estudio de los conjuntos infinitos, que fue considerado por su maestro Kronecker como una locura matemática, Cantor descubrió que aquellos no tienen siempre el mismo tamaño, o sea el mismo cardinal: por ejemplo, el conjunto de los racionales es "enumerable", es decir, del mismo tamaño que el conjunto de los naturales, mientras que el de los reales no lo es: existen, por lo tanto, varios infinitos, más grandes los unos que los otros.

Este hecho supuso un desafío para un espíritu tan religioso como el de Georg Cantor. Y las acusaciones de blasfemia por parte de ciertos colegas envidiosos o que no entendían sus descubrimientos no le ayudaron. Sufrió de depresión, y fue internado repetidas veces en hospitales psiquiátricos. Su mente luchaba contra varias paradojas de la teoría de los conjuntos, que parecían invalidar toda su teoría (tornarla "inconsistente" o "contradictoria" en el sentido de que una cierta propiedad podría ser "a la vez cierta y falsa").

Además, trató durante muchos años de probar la hipótesis del continuo, lo que se sabe hoy que es imposible, y que tiene que ser aceptada (o rehusada) como axioma adicional de la teoría. El constructivismo negará este axioma, entre otras cosas, desarrollando toda una teoría matemática alternativa a la matemática moderna.

Empezó a equiparar el concepto de infinito absoluto (que no es concebible por la mente humana) con Dios, y escribió artículos religiosos sobre el tema.

Sistematizó el conjunto ℝ de los números reales y usó el concepto de conjunto abierto. Impulsor de la investigación en Rusia, en la línea de Euler, es el autor del "Principio de los intervalos encajados", creador de ciertos conjuntos en topología y en teoría de la medida.

Georg Cantor falleció en Halle, Alemania, el 6 de enero de 1918 a los 72 años de edad. Actualmente, su obra es ampliamente reconocida y ha sido acreedora de varios honores.




</doc>
<doc id="11365" url="https://es.wikipedia.org/wiki?curid=11365" title="Asphodelus albus">
Asphodelus albus

El asfódelo, varilla de San José, gamoncillo o gamón blanco (Asphodelus albus) es una planta herbácea perenne nativa de la región mediterránea.

"A. albus" puede alcanzar hasta 200 cm de altura, aunque esto puede variar muchísimo según la disponibilidad de agua. Tiene un único tallo recto, apoyado en raíces tuberosas. Las hojas nacen a partir de la base del tallo; son largas y acanaladas, de superficie cerúlea. Las flores aparecen entre mayo y agosto en su región nativa; son hermafroditas, actinomorfas, hexapétalas, y se van juntando a medida que se asciende por el tallo, que raramente se encuentra ramificado, hasta llegar al ápice que están en racimos o más agrupadas. Los frutos son cápsulas ovoides, ubicadas al cabo de cortos pedúnculos, de color amarillo-verdoso que se abren en tres partes al madurar.

"A. albus" crece de forma silvestre en praderas y llanuras soleadas de España, el sur de Francia y la costa mediterránea hasta los Balcanes, entre el nivel del mar y los 2.000 metros sobre el nivel del mar. Prefiere suelos alcalinos, y es marcadamente termófila.

En la antigua Grecia, el asfódelo blanco se asociaba a la muerte y el tránsito a los Campos Elíseos; era frecuente su presencia en las ceremonias fúnebres. En la mitología, los Prados asfódelos eran una sección del inframundo equivalente al limbo cristiano.

El rizoma y los tubérculos son tóxicos en crudo, no recomendables por su contenido de asfodelina. La fermentación de los mismos produce alcohol. 

Dentro de la Comarca de Omaña (provincia de León) se utilizaban las hojas de los gamones para dar de comer a los gochos (cerdos).

En Campo de Gibraltar, hasta los años sesenta la raíz se usaba para tratar los hongos o empeines de la cara y extremidades.

En Ubrique, un pueblo de la provincia de Cádiz, hay una fiesta tradicional, celebrada el tres de mayo, en la que el tallo de los gamones se calienta en algunas candelas y se hace explotar chocándolo contra las piedras.

En Cabeza del Caballo y en la comarca de la Ramajería, en Salamanca, se usaban los tallos secos para encender candiles y faroles tomando la llama desde la lumbre.

"Asphodelus albus" fue descrita por Philip Miller y publicado en "Gard. Dict." ed. 8 3 1768.
Asphodelus: nombre genérico que deriva del griego antiguo ἀσφόδελος, de etimología desconocida

En la Grecia Antigua el asfódelo se relaciona con los muertos. Homero afirma que en el Hades o mundo subterráneo estaban los Prados Asfódelos (ἀσφόδελος λειμών), adonde iban los muertos que no merecían premio ni castigo. Con frecuencia se relaciona el asfódelo con Perséfone, que aparece coronada con una guirnalda de esta planta. 

albus: epíteto latíno que significa "blanco".





</doc>
<doc id="11368" url="https://es.wikipedia.org/wiki?curid=11368" title="Pantera (banda)">
Pantera (banda)

Pantera (estilizado PanterA) fue una banda estadounidense de "groove metal" fundada en 1981 por los hermanos Abbott, Darrell y Vinnie Paul, en Arlington, Texas. El bajista Rex Brown se uniría a finales de 1981 con el vocalista, guitarrista y tecladista Terry Glaze. En 1985 Phil Anselmo se convertiría en el vocalista principal del grupo. La banda permaneció activa entre 1981 hasta su disolución en 2003.

El género del grupo fue variando con los años. Durante la década de los 80, junto al cantante Terry Glaze, el "glam metal" predominaba en la apariencia y estilo de la banda. Tras el despido de Glaze y la llegada de Phil Anselmo, la banda abandona sus raíces, muy influenciadas por Kiss, y se vuelca en un estilo más pesado, periodo marcado por la publicación del álbum de estudio "Cowboys from Hell" en 1990, que los catapultó a la fama. En 1992 lanzan su álbum "Vulgar Display of Power", considerado uno de los álbumes pioneros del "groove metal". En 1994, su disco "Far Beyond Driven" debuta en el nº 1 del Billboard 200, y de esta forma Pantera es considerada la responsable de "mantener con vida" al "heavy metal" en una década en la cual el "grunge" y el "rock" alternativo alcanzaban el "mainstream".

A mediados de la década de los 90, Pantera comenzó a sufrir numerosas discusiones y tensiones entre sus integrantes, debido principalmente al abuso de drogas de Anselmo, lo cual provocó un comportamiento errático y volátil por su parte, que lo hizo distanciarse de sus compañeros. El cantante atribuye la razón de su drogadicción a un problema crónico en su columna vertebral, causado por años de violentas actuaciones sobre los escenarios, lo que le provocaba un gran dolor. En el 2001 deciden tomarse un receso, y sus integrantes toman caminos distintos. Anselmo siguió con sus proyectos que ya había fundado anteriormente, Superjoint Ritual y Down, este último al lado de su compañero Rex Brown, bajista de Pantera, y los hermanos Abbott formaron la banda Damageplan, tras esperar e intentar reiterada y fallidamente contactar con Anselmo, quien se había sumergido en sus otros proyectos. Pantera se disolvió oficialmente en el 2003.

Cualquier esperanza de una reunificación se vendría abajo con la trágica muerte de su legendario guitarrista Dimebag Darrell, que fue asesinado a tiros en el escenario "Alrosa Villa" en Columbus, Ohio, el 8 de diciembre de 2004 por un infante de marina llamado Nathan Gale, tras sólo unos segundos de haber comenzado el concierto de Damageplan.

Sólo unos pocos días antes de la tragedia, Anselmo había dicho a la revista Metal Hammer que los demás miembros de Pantera no tenían por qué opinar sobre su adicción, y que Dimebag merecía recibir una buena paliza. Estos comentarios terminaron de romper la amistad entre los miembros de la ya desaparecida banda. El cantante diría después que fue un comentario irónico, quejándose del sensacionalismo de la prensa del "heavy metal" en general, y aseguró que jamás habría sido capaz de lastimar a su difunto amigo. No obstante, Vinnie Paul no creyó esto, y acusó a Anselmo de ser el responsable indirecto de la muerte de su hermano, ya que su comportamiento y sus palabras podrían haber desencadenado las acciones del asesino de Darrell, de quien se comprobó que era esquizofrénico y estaba molesto por la separación de Pantera. La familia del guitarrista no le permitió a Anselmo asistir al funeral de su excompañero.

A pesar de todo lo sucedido, hoy en día muchos fans de la banda reclaman una reunión de sus miembros; pidiendo que Anselmo, ya recuperado de su adicción y de su problema en la espalda, y Vinnie Paul, quien hoy es parte del supergrupo Hellyeah, hagan las paces en honor a la memoria de Dimebag Darrell. También se ha hablado la posibilidad de una reagrupación de la banda junto al guitarrista de Ozzy Osbourne y Black Label Society, Zakk Wylde, quien fue un gran amigo del difunto guitarrista de Pantera, y que posee un estilo de tocar bastante similar a él. Tanto Anselmo como Wylde han manifestado que están dispuestos a reunirse, pero Vinnie Paul afirma que esa reunión no pasará, ya que, en sus palabras, "nunca habrá Pantera sin Dimebag Darrell".

Vinnie Paul y su hermano Dimebag Darrell nacieron en Dallas, Texas, en 1964 y 1966 respectivamente, hijos de Jerry Abbott, un músico de country que poseía un estudio de grabación en Pantego, Texas, por lo que ambos hermanos se acostumbraron rápidamente al mundo musical. En un principio, Vincent, apodado Vinnie Paul se interesó por la batería, por lo que sus padres le compraron una. Su hermano Darrell se sintió atraído a su vez por la batería de su hermano, pero luego, al ver a numerosos guitarristas de country y blues desfilando por los estudios de su padre, prefirió la guitarra eléctrica. Ambos hermanos, amantes de la música de rock de los '70 y del naciente "heavy metal", con grupos como Black Sabbath y Kiss, decidieron formar un grupo musical que recogiese estas influencias, unidas al dominio que los hermanos Abbott iban tomando en sus respectivos instrumentos; este sueño se haría realidad en 1981.

Pantera fue formada en Arlington, Texas, en 1981, por el cantante Donnie Hart, los guitarristas Darrell Abbott (apodado "Diamond Darrell" o "Dimebag Darrell") y Terry "Terrence Lee" Glaze, el bajista Tommy Bradford y el baterista Vinnie Paul, hermano de Darrell. Empezaron tocando covers de Quiet Riot y Van Halen, así como material propio encuadrado dentro del "glam metal" y el "hair metal", en clubes nocturnos de Texas.

En 1982, Hart abandonó la banda, y el guitarrista Glaze tomó la parte vocal. Poco tiempo después, Tommy Bradford fue reemplazado por Rex Brown, por ese entonces conocido como "Rex Rocker". Pantera se convirtió en una de las bandas favoritas del underground, aunque sus tours regionales nunca los llevaron más allá de Texas, Oklahoma y Luisiana. La banda empezó a telonear otros actos de "glam metal", como los de bandas como Stryper, Dokken, y Quiet Riot, quienes a cambio promovieron el debut de Pantera, "Metal Magic". Este álbum fue lanzado por el sello propio de la banda, con el mismo nombre, en 1983, y fue producido por el padre de los hermanos Abbott, Jerry Abbott, en los estudios "Pantego".

Luego, Pantera lanzó otros dos también desapercibidos álbumes: "Projects In The Jungle" y "I Am The Night", en los que seguía dominando el "glam metal" en sus composiciones, aunque se fueron separando progresivamente de las de su disco antecesor. Este último disco, "I Am the Night", vendió únicamente 25.000 copias, por lo que es en la actualidad una pieza de coleccionista.

La influencia de dos discos capitales dentro del desarrollo del "thrash metal" ("Reign in Blood" de Slayer y "Master of Puppets" de Metallica) habían marcado la carrera de la banda hacia dicho estilo, en el que no cuadraba Glaze, por lo que fue despedido. Phil Anselmo, proveniente de Nueva Orleans, fue su reemplazo como vocalista después de meditar la entrada de cantantes como David Peacock o Matt L'Amour. Con él lanzaron el álbum "Power Metal" (1988), en el cual se encuentra la canción "Proud To Be Loud", escrita por el guitarrista de Keel, Marc Ferrari. El estilo de dicho trabajo se orientó más hacia una mezcla del "hard rock" de los años '80 y el naciente "thrash metal", añadiendo además el estilo vocal de Anselmo, más áspero y rudo que el de Terry Glaze.

El posterior cambio estilístico de la banda hizo de estos discos casi piezas de coleccionista, llegando a ser relegados al ostracismo por la propia banda, ya que no aparecen en la discografía presente en su página oficial.

Poco después de la edición de "Power Metal", Dimebag Darrell se presentó a las audiciones de Megadeth, para formar parte del grupo liderado por Dave Mustaine. Darrell había puesto como condición que se uniese también su hermano Vinnie Paul, pero como Megadeth ya tenía un baterista estable, Nick Menza, Darrell no fue contratado, siendo elegido en su lugar por Marty Friedman.

Después de buscar durante un largo período un sello que acompañase a Pantera en la grabación del siguiente disco de la banda, Mark Ross, que trabajaba para Atco Records, vio un concierto de la banda en un local de Texas y convenció a su empresa para que fichase al grupo. Atco aceptó, y la banda remató el año 1989 grabando su siguiente material en los estudios Pantego.

"Cowboys From Hell" (1990) marcó un cambio drástico en la música de Pantera, que se decantó por un sonido más aguerrido y poderoso dejando atrás el glam, condicionado por la voz aguardentosa de Anselmo y los gruesos "riffs" de guitarra de Dimebag Darrell. Editado el 24 de junio de 1990, sus canciones más destacadas son "Domination", "Cowboys From Hell", "Cemetery Gates", "Psycho Holiday" y "Primal Concrete Sledge". Muchos fans, e incluso los miembros mismos de la banda, consideraron este trabajo como su debut oficial. Dimebag Darrell hizo sus "riffs" y solos más complejos, y Anselmo adoptó un estilo vocal aún más abrasivo que en "Power Metal". Para presentar adecuadamente el trabajo, Pantera giró durante un tiempo con Exodus y Suicidal Tendencies, antes de abrir para artistas de la talla de Metallica, AC/DC o Judas Priest, tocando ante una multitud de más de 500.000 personas en Moscú para celebrar uno de los primeros conciertos de música occidental desde la caída de la Unión Soviética.

Posteriormente llegó "Vulgar Display Of Power" (25 de febrero de 1992), que presentó aún mayor madurez, más personalidad y estilo propio, acercándose ligeramente hacia el "hardcore". En el disco destaca la ralentización de los tempos y el estilo aún más abrasivo y violento si cabe de Anselmo en la parte vocal. De este disco cabría destacar los temas "Walk", "A New Level", "This Love", "Fucking Hostile", "Rise", "Mouth For War" y "Hollow". Los fans y críticos consideraron este trabajo como el mayor esfuerzo de la banda. Además, el público acompañó al álbum, llegando al 44º puesto en las listas del Billboard gracias, entre otros motivos, a la repercusión que tuvieron algunos de los vídeos del disco en la influyente MTV.

Al poco de editar el disco, Pantera colaboró con el vocalista de Judas Priest, Rob Halford, para grabar el tema "Light Comes Out of Black", que conformó la banda sonora de la serie "Buffy the Vampire Slayer". Para ello, Halford tomó la voz principal y Anselmo los coros. Después de esta pequeña incursión en el estudio de grabación, la banda se sumerge en una gira por Japón primero e Italia después, en la que compartieron escenario con gigantes del metal como Black Sabbath y Iron Maiden.

Tras "Vulgar Display Of Power", en 1994 se publicó el disco "Far Beyond Driven", ligeramente más directo y brutal que su antecesor, que debutó en el primer puesto del Billboard estadounidense y en las listas de Australia. De este disco se podrían destacar los temas "5 Minutes Alone", "Becoming" y "I'm Broken" (nominada al Grammy en la categoría de en 1995). Con este disco ganaron un gran respeto entre los fans más acérrimos de la música más "brutal". La portada del disco, con un cráneo siendo atravesada por un taladro, causó gran impacto en su época.

En la gira de promoción del álbum, Pantera comenzó un tour por Sudamérica y en otro de los festivales "Monsters of Rock". Por esta época, Anselmo y los hermanos Abbott comenzaron a distanciarse, debido, según Anselmo, a unos dolores crónicos en la espalda que le impedían comportarse con normalidad. Para intentar solucionar estos problemas de espalda, Anselmo se volvió adicto al alcohol, algo que acabó distanciándolo más de los miembros de la banda según sus propias declaraciones. Esto provocó unas declaraciones suyas en un concierto en Montreal, Canadá, en las que dijo que "la música rap induce a matar blancos" (""rap music advocates the killing of white people""). A raíz de estas desafortunadas declaraciones, Anselmo negó las acusaciones de racismo, pidiendo disculpas poco tiempo después, arguyendo que estaba borracho y que fue un error. Los médicos le recomendaron pasar por el quirófano para solucionar dichos problemas, pero Anselmo se negó ya que debería pasar un año en total reposo, por lo que comenzó a usar la heroína como un reductor del dolor, volviéndose adicto a dicha droga.

En 1995, Anselmo creó un proyecto llamado Down, paralelo a Pantera, junto con el bajista Todd Strange, los guitarristas Pepper Keenan y Kirk Windstein y el batería Jimmy Bower. Down editó su primer disco en septiembre del mismo año bajo el nombre de "NOLA". Para el segundo disco del supergrupo, Strange sería reemplazado por el bajista de Pantera, Rex Brown, quien grabaría "", el título es uno de los versos de la conocida canción de Led Zeppelin "Stairway to Heaven".

El siguiente álbum de Pantera, "The Great Southern Trendkill", fue publicado en 1996 durante el final del auge del "grunge" y el surgimiento del rapcore y el nu metal. Cabe destacar los temas "Floods", "The Great Southern Trendkill", "War Nerve", "Drag The Waters" y los complementarios "Suicide Note Pt. I" y "Suicide Note Pt. II", dos canciones dedicadas por el cantante Phil Anselmo a su adicción a la heroína. Anselmo grabó sus partes vocales en un estudio de Nueva York junto con Trent Reznor de Nine Inch Nails, mientras el resto del grupo grabó lo que restaba en Texas, una prueba más del progresivo distanciamiento que sufría Anselmo con respecto al resto de integrantes de Pantera.

El 13 de julio de 1996, Anselmo sufrió una sobredosis de heroína una hora después de un concierto perteneciente a la gira que la banda estaba realizando a lo largo del estado de Texas. Su corazón se paró durante cinco minutos, por lo que los médicos que lo atendieron le administraron una fuerte dosis de adrenalina y fue enviado al hospital. Después de despertarse, Anselmo agradeció a sus compañeros de banda el apoyo recibido durante su sobredosis, aunque esto no hizo gran cosa en lo que respecta al distanciamiento de Anselmo con el resto de miembros, ya que los Abbott estaban avergonzados por el comportamiento del vocalista.

En 1997 publican el disco en directo "", recopilando las mejores canciones de sus cuatro discos anteriores tocadas en la gira "Tourkill" entre 1996 y 1997, demostrando su brutal puesta en escena y su sonido en directo, uno de los puntos fuertes del grupo. También añadieron dos temas inéditos grabados en estudio, "Where You Come From" y "I Can't Hide", ambas grabadas en 1997. Dos semanas antes de la publicación de dicho álbum, la banda consiguió su primer disco de platino de su carrera por "Cowboys from Hell". Apenas cuatro meses después, "Vulgar Display of Power" y "Far Beyond Driven" consiguieron este premio también.

Durante 1997, Pantera también tocó en el festival Ozzfest, siendo cabezas de cartel junto con Ozzy Osbourne, Black Sabbath, Marilyn Manson o Machine Head. Un año después repetirían la experiencia, tocando en el Ozzfest de 1998 junto con Slayer, Foo Fighters y Soulfly.

A lo largo de estos dos años, Anselmo se embarcó en más proyectos paralelos, entre los que hay que destacar su colaboración como guitarrista en el álbum de Necrophagia "Holocausto de la Morte", y ayudó a los grupos de "black metal" Viking Crown y Eibon. Por su parte, los hermanos Abbot y Rex Brown formaron Rebel Meets Rebel junto con el vocalista David Allan Coe, en el que añadieron sonidos "country" al sonido de Pantera.

Tras los rumores de ruptura del grupo debido a la gran cantidad de proyectos de sus componentes, el grupo contraataca con el que sería su último disco, "Reinventing the Steel" (2000), recuperando un sonido más pesado donde las raíces de Black Sabbath se sienten más que en sus últimos trabajos. Las canciones destacadas de este álbum son "Goddamn Electric", "Yesterday Don't Mean Shit", "You've Gotta Belong To It" y "Revolution Is My Name" (primer "single" y vídeo en el que se puede ver a los componentes en su preadolescencia pintados como los componentes de Kiss).

Este mismo año, Pantera se volvió a embarcar en otro Ozzfest junto con Ozzy Osbourne, Incubus, Queens of the Stone Age o Black Label Society. Una vez finalizado el Ozzfest, la banda hizo gira por Australia, Estados Unidos, Corea del Sur y Europa. Sin embargo, los atentados del 11 de septiembre de 2001 hicieron que la gira por Europa se cancelase, regresando los miembros de Pantera a sus hogares en Estados Unidos. Una vez en casa, los hermanos Abbott habían planeado componer y grabar otro disco con Pantera, algo que nunca pudo llevarse a cabo. Durante esta época, Anselmo fundó nuevos proyectos, como Superjoint Ritual, y editó el segundo álbum de Down. El baterista Vinnie Paul expresó que Anselmo le había dicho que no giraría durante el tiempo que Pantera estuviese parada, algo que supuestamente rompió el cantante al organizar la gira de presentación del segundo trabajo de Down y el disco de Superjoint Ritual. Sin embargo, y según declaraciones de Anselmo, el descanso de Pantera y la realización de sus giras con Down y Superjoint Ritual se llevaron a cabo "de mutuo acuerdo".

La banda se disolvió oficialmente en 2003, cuando los Abbott (Dimebag Darrell y Vinnie Paul) se dieron cuenta de que Anselmo les había abandonado y que no retornaría. La ruptura de la banda no fue en absoluto amistosa y trascendió del mundo musical para llegar a informativos y periódicos de tirada general. Mientras Darrell y Vinnie Paul, junto con los técnicos de Pantera y demás ayudantes, juraron y perjuraron que habían intentado contactar por teléfono con Anselmo, éste adujo que nadie se había interesado por él. Tal fue el enfrentamiento entre Anselmo y los hermanos Abbott, que el vocalista, en una entrevista a la revista "Metal Hammer", dijo: ""Dimebag merece que le peguen una buena paliza"". Anselmo diría después que fue un comentario irónico, algo que Vinnie Paul no creyó, empeorando más si cabe las relaciones entre los miembros de la ya desaparecida banda.

En julio de 2004, "Vulgar Display of Power" alcanzó de nuevo el disco de platino, y "The Great Southern Trendkill" consiguió también dicha certificación.

Un año después de la ruptura de Pantera, los hermanos Abbott fundaron Damageplan junto con Bob Zilla al bajo y Patrick Lachman como vocalista para editar un único disco, "New Found Power", en 2004.

Durante la gira de presentación de "New Found Power" ocurrió la catástrofe. El 8 de diciembre de 2004, exactamente veinticuatro años después del asesinato de John Lennon, durante el concierto en el local Alrosa Villa, en Columbus, Ohio, Dimebag Darrell fue asesinado a quemarropa por Nathan Gale, un supuesto fan alienado de la banda que fue después abatido por un policía mientras portaba un rehén. Aparte del malogrado Darrell, tres personas más sufrieron heridas mortales, entre las que se encontraban Nathan Bray, un fan de la banda de veintitrés años; Erin Halk, empleado del local de veintinueve años de edad; Jeffrey Thompson, jefe de seguridad de Damageplan, con cuarenta años. Chris Paluska, mánager de la gira, y John Brooks, técnico de sonido de la batería, fueron también heridos por Gale. Esto provocó un "shock" entre los fans metaleros, convirtiendo a Dimebag Darrell en una leyenda. Aunque Anselmo declaró poco después del asesinato de Darrell que estaba meditando reunir a Pantera, Vinnie Paul dijo un año después que esa reunión "nunca pasará". Paul declaró también que era imposible una reconciliación con Anselmo.

Dimebag Darrell y su hermano Vinnie Paul estaban de gira con Damageplan, a pocos días de finalizar e irse a casa por Navidad. Según afirma Rita Haney, la novia de Dimebag Darrell, los últimos días antes de su muerte, Dimebag Darrell la llamaba mucho por teléfono, contándole que estaba harto de Pat Lachman (vocalista de Damageplan) con el que tenía discusiones ya que este no quería cantar canciones de Pantera, cansado de la gira y con ganas de volver a casa por Navidad. Descorazonadoramente, el 8 de diciembre de 2004, cuando Damageplan salió al escenario en el "Alrosa Villa" en Columbus, Ohio, en no más de 10 segundos tras empezar a tocar la primera canción, Dimebag Darrell fue disparado 5 veces en la cabeza por un exmarine esquizofrénico llamado Nathan Gale, que también disparó a varias personas del público y del equipo de Damageplan. Afortunadamente no tuvo tiempo de llegar a localizar a Vinnie Paul, al que buscaba desesperadamente tras disparar a su hermano, para también acabar con su vida. Dimebag Darrell falleció en el momento, junto con varias personas más asesinadas por el exmarine esa noche. La policía llegó al lugar tras dos minutos después de haber recibido la primera llamada de emergencia, y Nathan Gale fue abatido por el agente de policía James Niggemeyer, que le disparó en la cara cuando este se disponía a matar a un rehén, John "Kat" Brooks, miembro del equipo de Damageplan y antiguo amigo y miembro del equipo de Pantera, que se enfrentó al asesino intentando quitarle la pistola, salvando así la vida del rehén y la de muchas más personas.

Según las investigaciones policiales, Nathan Gale sufría de esquizofrenia y había sido expulsado del cuerpo de los marines. Estaba determinado a cometer un asesinato contra Dimebag Darrell y Vinnie Paul, ya que decía que Pantera le robaba sus letras. Además, fan de Pantera, se cree que la ruptura de la banda le llevó a querer cometer los asesinatos contra sus miembros como venganza. Al parecer, Nathan Gale había provocado un altercado en el anterior concierto que Damageplan había dado en Columbus, Ohio, queriendo colarse en el escenario afirmando que Pantera le robaba sus letras, pero fue expulsado del concierto por los miembros de seguridad.

Pantera ha aparecido en multitud de actos y programas de entretenimiento. La serie animada "Beavis and Butt-Head" incluyó los vídeos de las canciones "Mouth for War", "Psycho Holiday", "I'm Broken" y "This Love". En dicha serie, sus protagonistas comentaban los vídeos mientras las interpretaban. Aunque dichos personajes suelen comentar de forma negativa la mayoría de los vídeos que incluyen en su serie, con los de Pantera realizan una excepción al comentarlos relativa y favorablemente. "Walk" fue usada durante la retransmisión del programa de lucha libre Extreme Championship Wrestling por el luchador Rob Van Dam. La música de Pantera ha aparecido también en multitud de videojuegos, entre los que destacan "Doom" (en el que aparecen los temas "Rise", "Mouth for War", "Regular People (Conceit)" y "This Love", aunque todas ellas sin parte vocal), y "Guitar Hero", en el que la canción "Cowboys from Hell" es una de las más difíciles de tocar con la canción "I'm Broken", en 2008 la cantante estadounidense Madonna hizo un cover de la canción A New Level mezclándola con el éxito Hung Up durante el Sticky and Sweet Tour.

Por otro lado, muchas canciones de Pantera que no aparecen en ningún álbum oficial de la banda, sí lo hacen en las bandas sonoras de, por orden cronológico, "Buffy the Vampire Slayer, El cuervo, Cuentos de la cripta, Strangeland, Detroit Rock City, Heavy Metal 2000, Dracula 2000 y La matanza de Texas". También una canción parecida a "Death rattle" apareció en el capítulo "Semana de prehibernación" de la serie Bob Esponja apareciendo en los créditos "Invitado Especial Grupo Pantera".

El estilo de Pantera ha sido numerosas veces sometido a crítica debido al parecido de éste con el de la banda Exhorder. Muchos fans de dicha banda acusaron a Pantera de haber robado su estilo, el groove metal que luego popularizarían. La biografía presente en Allmusic dice que, si Exhorder hubiera tenido un presupuesto mayor de grabación y una gran compañía detrás, quizá se habría hablado de unos "nuevos Pantera". Otro músico que cree en un posible plagio de Pantera a Exhorder es Dave Mustaine, líder de Megadeth, quien lo dijo en una entrevista al canal MTV en 1994.

En el polo opuesto se encuentra el crítico musical Brian Davis, quien trabaja para la emisora de radio de habla inglesa por internet, KNAC, al decir que existen algunas similitudes entre el sonido de Exhorder y el de Pantera, pero que decir que Pantera robó el sonido de Exhorder es excesivo. A pesar de la controversia que hubo en su día acerca de un posible plagio entre las dos formaciones, el vocalista de Exhorder, Kyle Thomas, declaró que no le importa la polémica que hay alrededor de su estilo, argumentando que los miembros de Pantera y los de Exhorder son grandes amigos y que lamentaba la muerte de Darrell.

La banda está considerada como una de las fundamentales para asentar las bases del "groove metal" y una de las más influyentes formaciones de metal de la década de los 90.

Pantera ha sido incluida en numerosas listas de importancia dentro de la historia del "heavy metal" y del "hard rock", llegando al quinto puesto de la lista de la MTV de las 10 mejores bandas de "heavy metal" de la historia, así como aparecer en el puesto número 45 de la lista de VH1 de las 100 mejores bandas de "hard rock".

La discografía de Pantera está compuesta por nueve álbumes de estudio, un álbum en directo, un álbum recopilatorio, más tarde éste sería publicado en dos versiones. También lanzaron dos EP, seis sencillos, cinco video álbumes, once videos musicales y dos cajas recopiladoras.





</doc>
<doc id="11371" url="https://es.wikipedia.org/wiki?curid=11371" title="Entero (tipo de dato)">
Entero (tipo de dato)

Un tipo de dato entero en computación es un tipo de dato que puede representar un subconjunto finito de los números enteros.
El número mayor que puede representar depende del tamaño del espacio usado por el dato y la posibilidad (o no) de representar números negativos. Los tipos de dato entero disponibles y su tamaño dependen del lenguaje de programación usado así como la arquitectura en cuestión. Por ejemplo, si para almacenar un número entero disponemos de 4 bytes de memoria tememos que:

Las típicas operaciones aritméticas: suma, resta, multiplicación y división se pueden realizar con datos de tipo entero. En el caso de la división, el resultado podría ser un valor real, en ese caso, si el resultado se ha de almacenar como entero la parte decimal del resultado deberá ser eliminada, en principio hay dos métodos para hacerlo:


Otra operación importante que se puede realizar con número enteros es la operación de módulo o resto de la división entera, es decir:

En general la operación "módulo" cumple que:

Si en un programa de ordenador se intenta asignar a un entero un valor que está fuera del rango de los valores que se pueden representar (Ej: a=2) se produce un fallo que se conoce con el nombre de desbordamiento ("overflow" en inglés). Cuando esto ocurre, lo habitual es que el programa siga funcionando como si nada hubiera pasado, pero el nuevo valor quedaría establecido en 0, si el desbordamiento se produce en un entero sin signo; y en -2 si se produce en un entero con signo.


</doc>
<doc id="11373" url="https://es.wikipedia.org/wiki?curid=11373" title="Bellis perennis">
Bellis perennis

Chrysanthemun Leaucanthemum, comúnmente llamada chiribita, margarita común, pascueta o vellorita es una planta herbácea muy utilizada a efectos decorativos mezclada con el césped, por su resistencia a la siega.

Planta herbácea perenne, ocasionalmente con pequeños rizomas, glabrescentes o laxamente pubescentes y hojas obovado-espatuladas, crenadas o dentada-redondeadas de 10-60 por 4-20 mm. Escapos sin hojas de hasta 20 cm de altura. Las brácteas involucrales tienen pelos pluricelulares más o menos abundantes en el dorso. Las flores hemiliguladas de 5,5-8,5 mm, sobrepasan el involucro en 2-5 mm, y tienen un tubo de 0,3-0,8 mm; son blancas, a veces teñidas de púrpura; los flósculos, amarillos, tienen 1,5-2 mm. El fruto es un aquenio de 1-1,5 por 0,5-1 mm, obovoideo, comprimido, algo peludo, con borde periférico engrosado; vilano ausente.<br>
Florece y fructifica de octubre a junio.

Nativa de Europa y Norte de África hasta Asia Central. Introducida en el resto del mundo.
Los capítulos florales contienen taninos (que son derivados poliacetilénicos), saponócitos, aceites esenciales, ácidos orgánicos y saponinas. Además, contiene antoxantina, responsable de la coloración amarilla.

Las partes utilizadas son las hojas, raíces y flores, aunque las raíces son las que se usan con menos frecuencia.

Es un popular remedio contra muchas enfermedades y tiene una gran variedad de formas de aplicación. Es la hierba tradicionalmente utilizada contra las heridas, ampollas, quemaduras y para disminuir inflamaciones.

Las raíces se utilizan en el tratamiento del escorbuto y eccemas dérmicos.
No se ha descrito ningún tipo de toxicidad para esta especie.

Es comestible; Se ha consumido las hojas en ensaladas, habitualmente mezclada con diente de león ("Taraxacum officinale") e hinojo ("Foeniculum vulgare").

"Bellis perennis" fue descrita por Carlos Linneo y publicado en "Species Plantarum", vol. 2, p. 886 en 1753.


Todos los descritos, una veintena, son meros sinónimos de la especie o de otras especies de "Bellis".
Castellano: María, agamarza, amagarza, bella margarita, bellis menor, bellorita (13), chibirita, chiribita (3), chiriva, chirivas, chirivita (9), chirivitas (2), consolida menor, consuelda menor, flor de Alejandría, galana, gamarza (2), gamazón, gramaza, gramazón, hierba del buenaliento, magarza, margarida, margarita (24), margarita común, margarita de prados, margarita menor (5), margarita silvestre, margaritas, margaritas de prado, margaritina, marzas, maya (18), maya maya, maya borracha, maya colorada, mayas, mogigato, pascueta (6), primavera de prados, rosa, rosa blanca, vellorita (9), vellorito, velorita, vichaya, viroleta, yerba de las perlas, yerba-margarita. Entre paréntesis, la frecuencia del vocablo en España.



</doc>
<doc id="11374" url="https://es.wikipedia.org/wiki?curid=11374" title="Brassica nigra">
Brassica nigra

La mostaza negra o ajenabe ("Brassica nigra") es una planta herbácea anual, cultivada por sus semillas, que se emplean como especia. Hoy es menos frecuente que la mostaza parda ("Brassica juncea") y que la blanca ("Sinapis spp."), pero se cultiva aún, en especial en la India, como fuente de aceite e ingrediente en aderezos. Se consume también como verdura de hoja.

"B. nigra" es una hierba anual, erecta, de tallo ligeramente pubescente y poco ramificado, que puede alcanzar casi 250 cm de altura. Presenta hojas alternas; las inferiores son pinatífidas, con un lóbulo terminal bien pronunciado además de algunos laterales, y de entre 10 y 20 cm de largo, mientras que las superiores son sésiles y reducidas.

Las flores son terminales, de pequeño tamaño, vistosas. Muestran cuatro sépalos y cuatro pétalos bífidos de color amarillo pálido; tienen seis estambres, dos de los cuales son marcadamente más cortos, y anteras rizadas. El fruto es una silicua de hasta 2 cm de largo, con picos de forma cónica; contiene semillas numerosas, de alrededor de 1 mm de diámetro, color pardorrojizo y superficie reticulada.

Se estima que la mostaza negra es originaria de la región mediterránea, pero se ha naturalizado en buena parte del mundo. Crece de forma silvestre en prados, terrenos baldíos, a la vera de los caminos o en cualquier terreno soleado y ligeramente seco.

Todos los órganos aéreos de "Brassica nigra" contienen sustancias cuyo consumo puede provocar problemas en la salud humana según el compendio publicado por la Autoridad Europea de Seguridad Alimentaria en 2012. En concreto se ha detectado la presencia, especialmente en las semillas, de glucosinolatos tales como sinigrósido, de derivados del alil isotiocianato como la gluconapina, la gluconasturtiina y la glucoisoberberina.

El ingrediente que da su sabor a la semilla de mostaza es el alilglucosinolato, que conforma un 1% del peso de la misma. Reacciona con la enzima mirosinasa liberando alil-isotiocianato, un compuesto similar a los hallados en la mostaza blanca, el rábano picante y el wasabi. La planta los produce como defensa frente a los herbívoros; por su carácter agresivo, están presentes sólo en forma de glicosinolatos inertes, que se liberan al contacto con el sistema digestivo.

Las semillas, una vez desprovistas de su cubierta, se emplean secas y molidas como especia. Tostadas pierden parte de su intensidad, pero ganan un aroma intenso y nogado. Sólo una pequeña parte de la producción se emplea para elaborar mostaza en pasta, en parte por el hecho de que el grano de mostaza negra rinde un producto de sabor demasiado intenso para los hábitos occidentales, y en parte porque el alil-isotiocianato, que es su principio activo, se degrada por hidrólisis más rápidamente que el de la mostaza blanca. Cuando se la utiliza para ese propósito, la solución empleada es más ácida de lo habitual.

En la cocina india, las semillas se utilizan directamente para aderezar algunos platos; la cocción destruye el principio picante, pero enriquece su aroma. Normalmente se tuestan o fríen en un poco de manteca para aromatizarla. Molidas en crudo forman parte de diversos currys, como el "panch phoron" producido en Bengala y el "sambaar podi" de Maharashtra y el sur. 

El aceite de mostaza negra se emplea también en la cocina de la India; al igual que el aceite de sésamo, resiste mal las altas temperaturas, pero se emplea como aderezo y para marinadas. Es un de los ingredientes principales del "vindaloo" preparado en Goa, uno de los platos más característicos de la cocina de la zona. En Bangladesh y Bengala se emplea para frituras, y se produce de las semillas tratadas de tal modo que los isotiocianatos se conservan, dándole un sabor particular. Por contener ácido erúcico, su uso como ingrediente alimentario no está permitido en algunos países, por lo que no es fácil obtenerlo fuera de la India. 

En Europa la mostaza negra es conocida desde antiguo, y fue introducida en Europa por los romanos. Su nombre en castellano refleja ese uso latino; proviene del latín "mustum ardens", "mosto ardiente", llamada así porque se mezclaba con mosto.

"Brassica nigra" fue descrita por originalmente por Linneo como "Sinapis nigra", transferida a su actual género por W.D.J.Koch y publicado en "Röhlings Deutschlands Flora" 4: 713–714. 1833.



</doc>
<doc id="11375" url="https://es.wikipedia.org/wiki?curid=11375" title="Calendula officinalis">
Calendula officinalis

Calendula officinalis, de nombre común (entre otros) botón de oro, caléndula, mercadela o maravilla, es una hierba de la familia de las asteráceas.

Planta herbácea, aromática, glandular, de anual a perenne, leñosa únicamente en la base. El tallo de 20 a 55 cm de altura, es erguido o procumbente, ramificada y generalmente con hojas casi hasta el extremo superior. Las hojas de 7-14 x 1-4 cm, son alternas, simples, oblongas-lanceoladas, estrechamente obovadas, oblongas o espatuladas. Las flores son liguladas y amarillas, con una floración que dura prácticamente todo el año, cerrándose de noche y abriéndose a al amanecer. Las inflorescencias en capítulos de 3-5cm de ancha, de un color amarillo anaranjado. Los frutos son aquenios encorvados, provistos casi todos en el dorso de unas alas membranosas o púas dorsales que alternan con otros cimbiformes más cortos, de forma navicular. El olor que desprenden las flores es desagradable y su sabor es amargo.

A pesar del gran número de nombres con el que se conoce a esta especie, nadie sabe a ciencia cierta de dónde procede en realidad. Se supone que del área mediterránea y que con toda probabilidad no es más que el resultado del cruce de otras especies del género "Caléndula", quizá de "C. arvensis", la maravilla silvestre, y alguna otra.

Se trata de una planta que se viene utilizando en la región mediterránea desde la época de los antiguos griegos, y con anterioridad ya era conocida por los hindúes y los árabes por sus cualidades terapéuticas como una hierba medicinal así como un tinte para telas, productos de alimentación y cosméticos, aunque muchos de los usos populares que se le han atribuido no se han podido demostrar científicamente. 

El uso medicinal de botón de oro es viejo, como lo demuestra su presencia en la "Capitulare de villis vel curtis imperii", una orden emitida por Carlomagno que reclama a sus campos para que cultiven una serie de hierbas y condimentos incluyendo "solsequiam" identificada actualmente como "Calendula officinalis".

Hemicriptófito poco exigente respecto al tipo de suelo, aunque prefiere los arcillosos. Es una planta de clima templado, pero resiste heladas y sequías. Cultivada en Europa desde el siglo XII, existe localmente naturalizada en el sur y oeste de Europa, y casual para todos los lugares. 

Las caléndulas sirven de alimento a diversas especies de larvas de lepidópteros. Entre ellos "Mamestra brassicae", "Naenia typica", "Noctua pronuba" y "Xestia c-nigrum".

Es muy atacada por los pulgones, lo que ha de tenerse en cuenta para las agrupaciones florales en jardinería.

Es sobradamente conocida en jardinería. Se cultiva muy a menudo en los jardines de los que escapa con facilidad. Se usa como planta ornamental y desde hace siglos se utiliza como planta medicinal debido a sus cualidades terapéuticas.

En gastronomía se pueden utilizar sus pétalos como colorante sustituto del azafrán.

La Comisión E considera que la flor de caléndula tiene una acción antinflamatoria y fuertemente cicatrizante cuando se aplica de forma tópica. Con extractos de la flor de caléndula, muestra una acción estimulante de la epitelización de las heridas y una actividad antiinflamatoria en edemas donde interviene la prostaglandina (los triterpenos, sobre todo el faradiol, han demostrado ser los principios antiinflamatorios más importantes).

En medicina popular se utiliza por su acción antibacteriana, fungicida y antiespasmódica. Se considera también emenagoga, como regulador y calmante de los dolores menstruales. Es un buen emoliente ya que suaviza, tonifica e hidrata la piel. De hecho cada vez son más los productos cosméticos que la incluyen entre sus componentes. También se ha considerado callicida ayudando a la desaparición de verrugas víricas de la piel, debido a su contenido en ácido acetilsalicílico. Es colerético estimulando la actividad hepática, especialmente la secreción biliar. También resulta eficaz en gastritis, gastroenteritis y vómitos por su acción antiulcerosa dado que ayudar a la cicatrización de úlceras gástricas.

Únicamente su uso tópico está contraindicado en pacientes sensibles a las asteráceas, ya que experimentalmente se ha visto una débil sensibilización de la piel, pero no se han registrado casos claros de dermatitis de contacto. 

Se seleccionan numerosos cultivares por las diversas variaciones de la flor, desde el amarillo pálido al naranja rojizo. Con multicorolas de flósculos radiales que reemplazan parte o todos los discos florales. Algunas de estas variedades son: 'Alfa' (naranja oscuro), 'Jane Harmony', 'Sun Glow' (amarilla brillante), 'Lemon' (amarillo pálido), 'Orange Prince' (naranja), 'Indian Prince' (naranja rojizo oscuro), 'Pink surprise' (multicorola con el anillo interior más oscuro que el exterior), y 'Chrisantha' (multicorola amarilla). La variedad 'Variegata' es un cultivar con hojas variegadas de color amarillo.

"Calendula officinalis" fue descrita por Carlos Linneo y publicado en "Species Plantarum", vol. 2: 921, 1753.
El nombre genérico, "caléndula", deriva del latín "calendulae" que significa "a lo largo de los meses", con lo que se quiso subrayar el largo período de floración que tiene esta planta, el nombre específico, "officinalis", expresa su carácter medicinal.







</doc>
<doc id="11376" url="https://es.wikipedia.org/wiki?curid=11376" title="Cymbalaria muralis">
Cymbalaria muralis

Cymbalaria muralis, comúnmente llamada picardia o hierba de campanario, es una especie de la familia Plantaginaceae, aunque en el pasado el género "Cymbalaria" se encontraba clasificado en la familia Scrophulariaceae. Es nativa de la Europa mediterránea y se encuentra ampliamente naturalizada en muchos otros lugares. 

Es una hierba perenne, rastrera (llega a tener unos 5 cm de altura) de rápido crecimiento que habita en muros (preferentemente húmedos), rocas, paredes e incluso aceras, raramente en suelos. Presenta hojas redondas o en forma de corazón, con tres a siete lóbulos de 2,5 a 5 cm de largo y ancho, situados de forma alterna sobre el tallo. Los delgados tallos pueden alcanzar hasta 70 cm de largo; sin pubescencia. Las flores solitarias, de no más de 1 cm, con corola lila o violeta, surgen de forma axilar (el pedúnculo sale entre la hoja y el tallo).

Esta especie posee un método de propagación poco habitual. El tallo floral tiene inicialmente un fototropismo positivo, moviéndose hacia la luz; tras la fecundación, este fototropismo se vuelve negativo (se aleja de la luz), lo que facilita que las semillas caigan en el interior de las grietas de la pared o la roca donde vegeta para poder germinar.

Se ha llegado a utilizar las flores en infusión como antiescorbútico y diurético, pero se entiende que casos meramente esporádicos, a mediados de siglo ya se desaconseja su uso. Es considerada como mala hierba por los jardineros, a pesar de que algunas variedades sean utilizadas en jardinería.
"Cymbalaria muralis" fue descrito por Gärtner, C.A.Mey & Scherb y publicado en "Systema Naturae, Editio Decima" 2: 975. 1759. 
Existen en jardinería cultivares de "C. muralis", aunque al ser una planta invasora, y dado su tamaño, es mayoritariamente empleado en composiciones de rocalla y jardineras.






</doc>
<doc id="11377" url="https://es.wikipedia.org/wiki?curid=11377" title="Euphorbia helioscopia">
Euphorbia helioscopia

La lecherula, lechetrezna girasol, pichoga o tornagallos ("Euphorbia helioscopia") es una planta herbácea anual nativa de Europa, donde crece de manera silvestre en las praderas y a la vera de los caminos. Su savia contiene un látex rico en ésteres sumamente tóxicos, y es venenosa tanto fresca como seca, en especial en contacto con el torrente sanguíneo. Su extracto se emplea en la industria farmacéutica.

"E. helioscopica" es principalmente europea y asiática, pero se ha naturalizado raramente en algunos lugares de América y el norte de África. Requiere suelos ligeros o medios, mucha luz y poca humedad para germinar; aparece con frecuencia espontáneamente en eriales, llanuras, al borde de caminos y en el exterior de la orla boscosa en las regiones templadas de Europa.

La savia de "E. helioscopia" es intensamente tóxica, como protección contra los predadores naturales; contiene varios ésteres del 12-deoxiforbol, de los cuales el más concentrado y tóxico es 12-deoxiforbol-13-fenilacetato-20-acetato. Provoca una aguda inflamación de las mucosas con las que entra en contacto, y de la membrana gástrica en caso de ingestión o absorción sanguínea. Experimentalmente se ha utilizado en la industria farmacéutica, y como potencial alternativa natural para la producción de goma en regiones templadas donde las fuentes tradicionales no pueden cultivarse.

En la medicina india, su misma toxicidad hace que se utilice como antihelmíntico tópica y sistémicamente, empleando para ello el aceite de las semillas y la decocción de hojas y tallos.

"Euphorbia helioscopia" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 1: 459. 1753.
Euphorbia: nombre genérico que deriva del médico griego del rey Juba II de Mauritania (52 a 50 a. C. - 23), Euphorbus, en su honor – o en alusión a su gran vientre – ya que usaba médicamente "Euphorbia resinifera". En 1753 Carlos Linneo asignó el nombre a todo el género.

helioscopia: epíteto


</doc>
<doc id="11378" url="https://es.wikipedia.org/wiki?curid=11378" title="Euphorbia serrata">
Euphorbia serrata

La lechetrezna serrada, tártago de hoja serrada o higuera del infierno (Euphorbia serrata ) es una planta herbácea anual nativa de Europa, donde crece de manera silvestre en las praderas y a la vera de los caminos. Su savia contiene un látex rico en ésteres, que se ha utilizado tradicionalmente en España como catalizador del cuajado de la leche.

"Euphorbia serrata" es una hierba monoica, anual, de unos 40 cm de altura, erecta y sin ramificaciones. En su único tallo se distribuyen hojas alternas, aserradas y ovales; el característico borde serrado de hojas y brácteas permite distinguirla fácilmente de otros euforbios. Las flores, de color verde muy brillante, aparecen a mediados de la primavera; son hermafroditas. La polinización está normalmente a cargo de dípteros. El fruto es una pequeña cápsula dehiscente. Todas las partes de la planta contienen un látex blanco y muy viscoso, de donde toma su nombre común.

"Euphorbia serrata" es europea. Requiere suelos ligeros o medios, mucha luz y poca humedad para germinar; aparece con frecuencia espontáneamente en eriales, llanuras, al borde de caminos y en el exterior de la orla boscosa en las regiones templadas de Europa. También es conocida en cultivos, en especial de vid ("Vitis vinifera"), donde es considerada mala hierba.

Se dice que en algunos pueblos de la zona de Andalucía, las niñas extraían su leche para poder "pintarse" lunares en sus rostros a modo de juego infantil. Aplicaban una pequeña cantidad de esa sustancia en sus caras, y la misma les producía una quemadura que simulaba ser un pequeño lunar que las embellecía.

La mariposa "Oxicesta serratae" pone sus huevos en esta euforbiácea para más tarde servir de alimento a sus larvas.

Actualmente la lechetrezna está de moda. Se usa como especie de interés medio ambiental y de enriquecimiento del paisaje en jardines de urbanizaciones costeras. Es una planta agradecida y muy resistente. Las matas de la planta quedan muy bien en las rocallas y al pie de muros. Su necesidad de agua es mínima.

Como otras de su género. es una planta bastante tóxica. Su resina blanca o 'látex', conocido popularmente como 'leche', puede irritar la piel y los ojos severamente. También se usó para eliminar verrugas y durezas de la piel.

"Euphorbia serrata" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 1: 459. 1753.
Euphorbia: nombre genérico que deriva del médico griego del rey Juba II de Mauritania (52 a 50 a. C. - 23), Euphorbus, en su honor – o en alusión a su gran vientre – ya que usaba médicamente "Euphorbia resinifera". En 1753 Carlos Linneo asignó el nombre a todo el género.

serrata: epíteto latino que significa aserrado, aludiendo a esta característica de las hojas y brácteas de la inflorescencia en esta planta.




</doc>
<doc id="11379" url="https://es.wikipedia.org/wiki?curid=11379" title="Fritillaria lusitanica">
Fritillaria lusitanica

Fritillaria lusitanica es una planta herbácea perenne y bulbosa de la familia de las liliáceas. Es nativa de la Península Ibérica, donde crece de forma silvestre en zonas altas, mostrando una gran variedad de fenotipos. Produce una atractiva flor de color intenso.

"F. lusitanica" es una hierba vivaz de hasta 50 cm de altura. Presenta hojas alternas, graminoides, lineares a lanceoladas. El tallo floral, delgado y glabro, brota a comienzos de primavera de un bulbo globoso, y hacia finales de abril presenta flores solitarias, terminales, acampanadas, normalmente colgantes, con tépalos muy vistosos de colores que van del caoba y el violeta oscuro al verde claro y el amarillo, muchas veces con franjas alternas de color, que permanecen hasta alrededor de julio.

Crece en sitios rocosos y secos, aliada con el boj o en claros de pinares o carrascales, a pleno sol, entre los 500 y los 2000 msnm.

"Fritillaria lusitanica" fue descrita por Johan Emanuel Wikström y publicado en "Kongliga. Vetenskaps Academiens Handlingar" 352. 1821.
Fritillaria: nombre genérico que deriva del término latino para un cubilete ("fritillus"), y, probablemente, se refiere al patrón a cuadros de las flores de muchas especies.

lusitanica: epíteto geográfico que alude a su localización en Lusitania.


</doc>
<doc id="11380" url="https://es.wikipedia.org/wiki?curid=11380" title="Fumaria officinalis">
Fumaria officinalis

Fumaria officinalis, comúnmente llamada palomilla o sangre de Cristo —entre otros muchos nombres—, es una especie de planta herbácea anual del género "Fumaria" en la familia Papaveraceae, nativa de Europa.

El término "Fumaria" deriva del latín "fumus" (humo) posiblemente y según dijo Plinio el Viejo, debido a que su zumo provoca un intenso lagrimeo, como si se tratara de humo, así como por su olor, que también se le parece. Los antiguos exorcistas, creían que si se quemaba esta planta, su humo ahuyentaban los malos espíritus; existe, además, la leyenda de que la planta no se originaba de sus semillas, sino del humo que emanaba del interior de la tierra.

Es una hierba glabra, de tallo erecto y bien ramificado, bastante difusa que alcanza los 50 cm de altura. Presenta hojas pinnaticompuestas, alternas, con los últimos folíolos casi lineares. A comienzos de primavera forma inflorescencias en racimos terminales de entre 10 a 25 flores zigomorfas, de hasta 9 mm de longitud cada uno. Las flores tienen el cáliz formado por dos sépalos pequeños, de color blanquecino, ovados, con el borde dentado, más angostos que la corola, de color rosado, la cual está compuesta por cuatro pétalos unidos en el ápice pero libres, de los cuales el superior se prolonga en un espolón. El androceo es diadelfo, es decir, con 6 estambres fusionados por sus filamentos en dos grupos, que parecen cada uno de ellos dividido en 3 anteras. El gineceo muestra dos carpelos, con el ovario súpero. El fruto es un pequeño aquenio globoso estriado/rugoso, más o menos truncado.

Originaria de Europa; Linneo, en su diagnosis original, indica: «"Habitat in Europae agris, cultis"». Cosmopolita; introducida en Norteamérica. 
Crece en terrenos cultivados o llanuras de suelo seco.

La infusión ligera se utiliza como hepatorregulador, diurético y laxante, y tópicamente, para las afecciones del cuero cabelludo. Debe evitarse la sobredosificación, pues los alcaloides que contiene resultan cardiotóxicos en dosis elevadas.

En su composición química se encuentran, entre otros:

"Fumaria officinalis" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 700. 1753.


En "cursiva", los más extendidos o corrientes.




</doc>
<doc id="11381" url="https://es.wikipedia.org/wiki?curid=11381" title="Fumaria capreolata">
Fumaria capreolata

Fumaria capreolata, comúnmente llamada fumaria blanca o palomilla, es una planta herbácea anual de la subfamilia Fumarioideae antigua familia Fumariaceae, nativa de Europa meridional.

Es una hierba glabra, de tallo trepador o rastrero, que alcanza los 100 cm de altura. Presenta hojas plurilobuladas, de segmentos lanceolados, alternas. En invierno o a comienzos de primavera aparecen en los tallos floríferos que brotan de las axilas foliares racimos de flores de 10 a 15 mm, blancas, con dos sépalos petaloides semitransparentes y el ápice de intenso color púrpura. La corola tiene forma tubular, compuesta por cuatro pétalos unidos en el ápice pero libres, de los cuales el superior se prolonga en un espolón. Presenta dos estambres trífidos. El fruto que en un pequeño aquenio liso o apenas rugoso, de forma oblonga u obtusa, que aparece al cabo de un pedicelo retroflexo protegido por brácteas.

Crece en terrenos cultivados o ruderales de toda el área mediterránea y las zonas templadas de Asia. Prefiere suelos ricos en nitrógeno.

En hibridación con "Fumaria densiflora" produce la "Fumaria × gagrica", que se difunde más al norte y este.

"Fumaria capreolata" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 701. 1753.
Número de cromosomas de "Fumaria capreolata" (Fam. Papaveraceae) y táxones infraespecíficos: 2n=c.70. 2n=c.64. 2n=56
Fumaria: nombre genérico del Latín "fumus" = "humo", posiblemente por el color o el olor de las raíces frescas.
El "humo" o el origen "fumy" de su nombre proviene del color translúcido de sus flores, dándoles la apariencia de humo o de colgar en el humo, y al color bruma ligeramente gris-azulado de su follaje, también se asemeja al humo proveniente del suelo, sobre todo después de rocío de la mañana.

La planta ya fue llamado "fumus terrae" (humo de la tierra) a principios del siglo XIII, y hace dos mil años, Dioscórides escribió en "De Materia Medica" (Περὶ ὕλης ἰατρικῆς) y Plinio el Viejo en "Naturalis Historia" que frotarse los ojos con la savia o látex de la planta provoca lágrimas, como el humo acre ("fumus") hace a los ojos. Su nombre en griego es "kapnos" (καπνός, por el humo)

capreolata: epíteto latino que significa "que tiene zarcillos".


</doc>
<doc id="11382" url="https://es.wikipedia.org/wiki?curid=11382" title="Galium aparine">
Galium aparine

El amor de hortelano, azotalenguas o lapa ("Galium aparine") es una hierba anual de la familia de las rubiáceas, nativa de Europa y Norteamérica. Todas las partes de la planta están cubiertas de pequeños espolones, que hacen que se adhiera como el velcro a la ropa o el vello corporal. La infusión de sus semillas molidas se toma como sucedáneo del café, con el que está remotamente emparentado.

"G. aparine" es una hierba anual, de hasta 2 m de longitud de tallo. Éste es trepador, de sección cuadrangular, ramificado desde la base, con los nudos setosos, anguloso, cubierto de espolones. Las hojas forman verticilos de 6 a 8 unidades; son mononervadas, lineares a lanceoladas o espatuladas, de hasta 1 cm de largo, con el ápice hialino, mucronadas. Presentan acúleos retrorsos en los márgenes. Las flores son hermafroditas, blancas o verde claro, carentes de cáliz, tetrámeras, con los pétalos soldados en la base, de cuatro estambres; forman cimas axilares de pocos flores. El fruto es un esquizocarpo globoso, cubiertos de pelos uncinados de base tuberculada. Florece a comienzos de primavera.

"G. aparine" es nativo de Europa y América del Norte. Crece de forma silvestre en pastizales, terrenos arados y jardines; es una de las malezas más frecuentes que afectan al cereal, por la similitud de sus semillas con las de estos.

Es un terófito, es decir, completan todo su desarrollo durante la estación favorable; muere al aproximarse el frío. Los espolones de los frutos favorecen la dispersión por zoocoria.

Planta conocida desde la Antigüedad, de la que Dioscórides dice: "Su flor aplicada en forma de emplasto, sana las quemaduras del fuego y restaña las efusiones de sangre". Su rayz atiza la virtud genital". Andrés Laguna añade: "restiñe todo fluxo de sangre". Se cuenta además que sus bellas flores amarilla sirvieron en la antigüedad para enrubiar los cabellos, así como para cuajar la leche para hacer quesos que adoptan un bello color amarillo. De esto último parece derivar el nombre del género (de "gala" = leche).

"Galium aparine" fue descrita por Carlos Linneo y publicado en "Species Plantarum 1: 108", en el año 1753. 
Número de cromosomas de "Galium aparine" (Fam. Rubiaceae) y táxones infraespecíficos: 2n=66. 2n=64. 2n=64, 66. 
Galium: nombre genérico que deriva de la palabra griega "gala" que significa "leche", en alusión al hecho de que algunas especies fueron utilizadas para cuajar la leche. 

aparine: epíteto que significa "como el género "Aparine" (ahora un sinónimo de "Galium").




</doc>
<doc id="11383" url="https://es.wikipedia.org/wiki?curid=11383" title="Glaucium corniculatum">
Glaucium corniculatum

La lagartera, amapola loca o amapola cornuda ("Glaucium corniculatum") es una planta herbácea, de vistosa flor roja, que recuerda a la amapola ("Papaver" spp.), con la cual está emparentada.

"G. corniculatum"es un tallo velloso recubierto de una fina capa cerúlea glauca, del que mana un látex amarillento al quebrarse. Alcanza los 10-40 cm de altura. Las hojas son pinnatífidas o pinnatipartidas, de margen irregularmente dentado, las basales pecioladas mientras que las superiores son sésiles y amplexicaules, de consistencia carnosa.

En primavera presenta flores grandes para el porte de la planta (hasta 5 cm de diámetro), axilares, solitarias, tetrámeras, de corola naranja o roja, mostrando a veces manchas negras en la base. Los sépalos son dos, libres y caedizos. La flor es hermafrodita, con numerosos estambres y anteras amarillas bien visibles. El fruto es una cápsula alargada, superando los 10 cm, silicuiforme, con dehiscencia del ápice, que es cornudo, a la base, cubierto por pilosidades rígidas.

Es nativa del sudoeste europeo, y se distribuye desde la península ibérica hasta el sudeste asiático y el norte de África. Se ha introducido en América del Norte.

Crece de forma silvestre en terrenos en barbecho, pasturas o cultivos, o a la vera del camino.

"Glaucium corniculatum " fue descrita por (L.) Curtis y publicado en "Flora Londinensis" 6: t. 32. 1789.
Número de cromosomas de "Glaucium corniculatum" (Fam. Papaveraceae) y táxones infraespecíficos: 2n=12
Glaucium: nombre genérico que deriva del griego "glaucous" que significa "glauco, grisáceo".

corniculatum: epíteto latino que significa "con cuernos".



</doc>
<doc id="11384" url="https://es.wikipedia.org/wiki?curid=11384" title="Lamium amplexicaule">
Lamium amplexicaule

Lamium amplexicaule (conocida según las regiones como zapatitos, conejitos u ortiga mansa, términos genéricos que designan a todas las especies de "Lamium") es una especie de fanerógama herbácea, anual nativa de las regiones cálidas y templadas de Eurasia; naturalizada con facilidad en América, se la considera una mala hierba por su agresivo crecimiento.

"L. amplexicaule" es una planta rastrera, anual, de hasta 25 cm de altura, con el tallo y hojas cubiertos de fina pubescencia. Las hojas son opuestas, redondeadas, con el margen lobulado, sésiles, con las inferiores tendiendo a la forma oval. Florece entre mediados de invierno y principios del verano, produciendo inflorescencias en verticiliastros con brácteas abrazadoras (de allí su nombre "amplexicaule"), formadas por flores hermafroditas, zigomorfas, de color morado, con el tubo de la corola largo de uno a dos centímetros como máximo, con labio superior galeado e inferior blanco moteado de púrpura. El cáliz lo forman cinco sépalos soldados.

Se propaga de forma silvestre en pastizales, campos y terrenos arados en toda Europa; tolera bien la sombra. Es una fuente importante de polen para las abejas melíferas, siendo una de las primeras flores que se abren en invierno.

La raíz y las hojas son comestibles y se han llegado a utilizar en ensaladas y ciertos dulces.

Lamium amplexicaule




</doc>
<doc id="11385" url="https://es.wikipedia.org/wiki?curid=11385" title="Linum narbonense">
Linum narbonense

El lino azul o de Narbona (Linum narbonense) es una planta herbácea de la familia de las lináceas, estrechamente emparentada con el lino común ("Linum usitatissimum"). Es característica por su bella flor azul.
"L. narbonense" es una hierba perenne, erecta, vivaz, lampiña, que alcanza los 50 cm de altura. Sus hojas son alternas, lanceoladas, marcadas por una única nervadura, sésiles o apenas pecioladas. Las flores son solitarias, terminales, pentámeras, de color azul pálido o vivo, a veces con franjas longitudinales de color más claro, alcanzando los 2,5 cm de diámetro; aparecen poco antes de comienzos del verano.

Crece de forma silvestre en la península Ibérica y las Islas Baleares, en matorrales y tomillares bien soleados, o como sotobosque en zona de pinares; prefiere suelos calizos, ligeramente ácidos, poco húmedos, sobre todo con buen drenaje. Se utiliza como ornamental gracias a su belleza y fácil germinación.
Es el único hospedero de las larvas de "Coleophora benedictella".

"Linum narbonense" fue descrita por Carlos Linneo y publicado en "Sp. Pl." 278 1753. 
Linum: nombre genérico que deriva de la palabra griega: "linum" = "lino" utilizado por Teofrasto.

narbonense: epíteto geográfico que alude a su localización en Narbona.


</doc>
<doc id="11386" url="https://es.wikipedia.org/wiki?curid=11386" title="Lupinus angustifolius">
Lupinus angustifolius

El altramuz azul (Lupinus angustifolius) es una planta herbácea anual, una de las pocas especies cultivadas del género "Lupinus", cuyo fruto se aprovecha en alimentación, siendo un aperitivo típico de la región mediterránea.

Se trata de una planta herbácea de hasta 100 cm de altura, anual y pubescente. Presenta hojas palmaticompuestas, alternas, con pecíolos de 2 a 7 cm de largo. Sus láminas, digitadas, se encuentran divididas en 5 a 9 foliolos más o menos carnosos y de forma linear- oblonga o linear-espatulada, muy estrechos y con el ápice redondeado, con el haz glabro y el envés pubescente. Los bordes son enteros. Los tallos muy ramificados desde la base o desde cierta altura. Son erectos, pelosos, con pelos patentes de 0'5 - 0'8 mm. Florece entre la primavera y principios del verano (marzo – agosto ) formando inflorescencias muy vistosas de tipo racimo, terminal, laxo, de entre 10 y 20 cm. que puede tener hasta 30 flores alternas; tienen pedicelos de hasta 4 mm., con brácteas lineares, caducas, con bractéolas de 1 mm., oblongas. Cada una de estas flores son hermafroditas y presentan una simetría de tipo zigomorfa.

El cáliz, de 7 a 9 mm, es seríceo, bilabiado, con el labio superior de longitud hasta casi la mitad que el inferior, hendido en dos lacinias separadas; el inferior es bi o tridentado.

La corola es glabra, papilionácea y de color azulado; el estandarte, de hasta 16 mm x 15 mm, es erecto, de carácter orbicular, con la base atenuada y formando una uña ancha y poco definida; las alas son obtusas y obovadas de hasta 15 mm., soldadas en el ápice con una aurícula bien diferenciada en la base del limbo; la quilla de hasta 15 mm., es semicurvada y está encerrada por las alas, presentando una aurícula en la base del limbo. El androceo es monadelfo, ya que todos los filamentos están soldados en un tubo por el que pasa el estilo. El ovario es sentado, con un estilo curvo, glabro y el estigma húmedo, terminal con un anillo de pelos en la base. El fruto es una legumbre de 40 – 70 x 10 – 12 mm, conteniendo de 3 a 5 semillas medianas, redondeadas, con el tegumento blanco o moteado de gris; la vaina se vuelve amarilla, parda o negra al madurar. Lo encontraremos cubierto de una serie de pelos rígidos, los cuáles miden entre tres y seis cm. de largo.

Presentan procesos de nodulación (donde se fijará nitrógeno) provocados por bacterias del género "Bradyrhizobium sp."

En su región de origen crece de forma silvestre en campos de suelo arenoso. Prefiere suelos ligeramente ácidos o neutros, con buen drenaje, ricos en nutrientes, en especial cobalto, fósforo y potasio. No se desarrolla bien sin temperaturas moderadas durante la fase vegetativa, y tolera bien las heladas. Exige una pluviosidad de entre 250 y 1500 mm al año.
Se caracteriza por un fuerte carácter ruderal y arvense, pudiéndose desarrollar en cultivos abandonados, eriales o bordes de carreteras.

Se cultiva en la región septentrional de Europa, así como en Australia, Tasmania, Nueva Zelandia, Sudáfrica y Estados Unidos por su fruto, rindiendo entre 500 y 2500 kg/ha según la riqueza del suelo. En España aparece prácticamente en todas las provincias.



Contiene lupaina, lupinina, lupinidina, proteínas, aceite, lecitina, sales, ácido inositinexafosfórico. Se usan las semillas como antihelmíntico, diurético, depurativo, emenagogo, pectoral, nutritivo, hipoglucemiante y vermífugo. Las raíces son digestivas.


En valores porcentuales (referidos a cantidad presente por cada 100g.):

Destaca sobre todo en el altramuz su altísimo aporte proteico que lo convierte en una buena proteína vegetal alternativa a la carne y a la soja o soya.
Es muy remineralizante destacando su aporte en hierro (7,6 mg) y en calcio (180 mg)
También aporta Zinc, el potasio, fósforo, magnesio, vitaminas del grupo B y vitamina E. Aunque vemos que el aporte del altramuz en grasas es alto hay que tener en cuenta que estamos hablando de ácidos grasos, cuyo aporte es beneficioso.

Una dieta con altramuz nos aporta los siguientes beneficios:

Es cierto que el sabor ligeramente amargo del altramuz se debe a que este contiene alcaloides (esparteína, lupinina, ácido lupínico y lupanina) que podrían producir una intoxicación del sistema nervioso denominada latirismo. Este riesgo desaparece totalmente hirviendo la legumbre (como de hecho se hace con todas las legumbres) o también desaparece dejándola en remojo con agua salada. Es algo muy similar como lo que ocurre con la yuca (nunca se come cruda)
Los hipertensos deben de cuidar su consumo ya que, al comprarlo ya hecho, puede venir demasiado salados.
"Lupinus angustifolius" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 721. 1753.
Números cromosomáticos de "Lupinus angustifolius" (Fam. Leguminosae) y táxones infraespecificos: 2n=40



</doc>
<doc id="11387" url="https://es.wikipedia.org/wiki?curid=11387" title="Matthiola fruticulosa">
Matthiola fruticulosa

El alhelí del campo (Matthiola fruticulosa) es una hierba perenne que crece en sitios secos y rocallosos de la cuenca mediterránea, salvo en Córcega y Cerdeña.

Es una planta perenne, herbácea, subleñosa en la base, con tallos de entre 10 y 60 cm de altura cubiertos de densa pilosidad blanca. Las hojas son alternas, oblongas a lineares, de color verde grisáceo. Florece entre principios de primavera y mediados del verano, formando inflorescencias de flores amarillas a púrpura, pediceladas, con cuatro pétalos dispuestos en cruz de hasta 3 cm y sépalos de hasta 15 mm. El fruto es una silicua cilíndrica.
España, Portugal y Francia. En España se distribuye por zonas áridas, en zonas más lluviosas ocupa los suelos arenosos que se secan rápidamente y no permiten el crecimiento de otras plantas que requieren más humedad. Necesita suelos calcáreos o yesosos, no se encuentra sobre pizarras o granitos. Es común en las sierras interiores calcáreas, como el Sistema Ibérico y las serranías béticas. Más escasa a medida que disminuye la aridez, alcanza el Prepirineo, parte de la Sierra de Ávila, la Cordillera Cantábrica, la Costa del Sol occidental y Baleares. Crece en tomillares, pastizales soleados, pradillos terofíticos, escombreras y márgenes de caminos, sobre calizas, arenas, margas yesíferas, en suelos pedregosos, pobres o inexistentes.

"Matthiola fruticulosa" fue descrita por (Loefl. ex L.) Maire y publicado en "Catalogue des Plantes du Maroc" 2: 311. 1932.
Matthiola: nombre genérico que está dedicado al médico y botánico italiano Pietro Andrea Gregorio Mattioli.

fruticulosa: epíteto latino que significa "algo arbustiva".




</doc>
<doc id="11388" url="https://es.wikipedia.org/wiki?curid=11388" title="Mimosa">
Mimosa

Mimosa puede referirse a:


</doc>
<doc id="11389" url="https://es.wikipedia.org/wiki?curid=11389" title="Muscari botryoides">
Muscari botryoides

El jacinto de la uva o jacinto ramoso ("Muscari bothyroides") es una hierba perenne de vistosas flores de color púrpura o azul, nativa de Europa Central y Asia.

Es una hierba que apenas llega a los 30 cm de altura en condiciones óptimas, con la raíz formando bulbos. Las hojas son acanaladas o en forma de U, de unos 2 cm de largo por 5 milímetros de ancho. Desde finales de invierno hasta principio del verano presenta flores colgantes de color púrpura o azul marino, de hasta 1 cm de tamaño, formando racimos compactos de ellas. La corola, minúscula, presenta 6 piezas con puntas blancas y cortas. El fruto es una cápsula alada.

Prefiere suelos húmedos, prados y pastizales. Tolera suelos calizos y temperaturas bajas.

Está muy extendido en jardinería dada su facilidad a la naturalización. Las composiciones de rocalla, agrupaciones; alrededor de arbustos, formando grupos más o menos compactos, etc.

En los jardines de p lo Keukenhof (Holanda), se plantan millares de muscaris, formando un pasillo largo y estrecho que simula las aguas de un río.

"Muscari botryoides" fue descrito por Carlos Linneo y publicado en "The Gardeners Dictionary":... eighth edition no. 1. 1768.
Muscari: nombre genérico que deriva del latín medieval "muscarium", un derivado del almizcle, que evoca el olor almizclado de ciertas especies.

botryoides: epíteto latíno compuesto que significa "parecido a una uva".




</doc>
<doc id="11390" url="https://es.wikipedia.org/wiki?curid=11390" title="Leopoldia comosa">
Leopoldia comosa

El jacinto comoso o hierba del querer o nazareno ("Leopoldia comosa") es una hierba vivaz de vistosas flores de color púrpura o azul, nativa de Europa Central y Asia.

Es una hierba que alcanza los 60 cm de altura, con la raíz formando bulbos de color rojizo. Las hojas son basales, de forma lineal, de unos 15 mm de largo por 12 de ancho. Florece en primavera presenta flores ovoides o tubulares, con tres dientes, de color púrpura o azul marino, de hasta 1 cm de tamaño, formando racimos compactos de ellas. El ovario es trilobulado, dando como fruto es una cápsula alada trivalva.

Prefiere suelos húmedos, prados y pastizales. Tolera suelos calizos y temperaturas bajas. Está muy extendido en jardinería dada su facilidad a la naturalización; por su rusticidad se la considera a veces invasiva. Las composiciones de rocalla, agrupaciones; alrededor de arbustos, formando grupos más o menos compactos, etc. Se la encuentra en Europa meridional, el Medio Oriente y el norte de África.

Existe una variedad ornamental, llamada "plumosum" o "monstruosum" que forma una vistosa inflorescencia.

Los bulbos, parecidos a los de la cebolla pero más pequeños y de sabor más amargo, se comen en algunos países de la cuenca Mediterránea.

Dioscórides (s. I) dice de estos bulbos:
"Leopoldia comosa" fue descrita por (L.) Parl. y publicado en "Flora Palermitana" 435. 1845 

Agüelicos, ajete, ajete de cigüeña, ajipuerco, ajo, ajo de cigüeña, ajo de culebra, ajo de perro, ajo perro, ajopuerro, ajos de cigüeña, cebolla de lagarto, cebollita de milano, cebollón, guitarrillo, guitarrillos, hiacinto, hierba del querer, hierbas de los amores, implo, jacinto, jacinto comoso, jacinto de penacho, jacinto mayor comoso, jacinto penachudo, jacintos silvestres, lilas, matacandil, mayos, nazareno, nazarenos, ojo de ajo, penitentes.


</doc>
<doc id="11391" url="https://es.wikipedia.org/wiki?curid=11391" title="Myosotis ramosissima">
Myosotis ramosissima

El nomeolvides temprano, de las colinas o azul ("Myosotis ramosissima") es una planta herbácea anual o bienal nativa de Europa, donde crece de manera silvestre en terrenos arenosos, en especial cerca de la costa.
Es una hierba erecta, de hasta 30 cm de altura, con el tallo de sección circular y pubescente. Las hojas basales forman una roseta; las distales son alternas, ovadas a espatuladas, pubescentes, 
En primavera florece produciendo inflorescencias cimosas y elongadas de florecillas azules, raramente blancas con el margen azul, con la corola pentámera, de no más de 2 mm de longitud. El fruto es un aquenio de paredes muy duras, monoseminado; la semilla es parda y ovoide, con el ápice agudo.

Crece de manera silvestre en Europa en terrenos arenosos y secos o en praderas, muchas veces cerca de la costa marítima. Es rara salvo en Italia y en las Islas Británicas se encuentra protegida.

Esta especie en concreto no es utilizada para jardinería. Sin embargo sí el género, con especies sobresalientes, relleno de rocallas, composición de colores con el agravante de colores en distintas tonalidades. Forman conjuntos llamativos y decorativos. No se encuentran utilidades farmacológicas.

"Myosotis ramosissima" fue descrito por Rochel ex Schult. y publicado en "Oesterreichs Flora. Ein Taschenbuch auf botanischen Excursionen", ed. 2 1: 366. 1814. 
Número de cromosomas de "Myosotis ramosissima" (Fam. Boraginaceae) y táxones infraespecíficos: n=24
Myosotis: nombre genérico que deriva del griego: "mys, myos", que significa "ratoncillo" y "otos", que significa "oreja", aludiendo a la forma de la hoja en algunas de las especies del género.

ramosissima: epíteto latíno que significa "con muchas ramas"


 


</doc>
<doc id="11392" url="https://es.wikipedia.org/wiki?curid=11392" title="Matemático">
Matemático

Un matemático (del latín: "mathēmāticus" y este a su vez del griego μαθηματικός "mathēmatikós") es una persona cuya área primaria de estudio e investigación son las matemáticas, es decir, es una persona que contribuye con nuevo conocimiento en este campo de estudio. En sentido estricto, un matemático es un investigador en el área de las matemáticas. El término recubre una gran gama de competencias y de prácticas muy diferentes, que comparten un vocabulario común y un formalismo específico, así como una exigencia de rigor propia de esta disciplina.

Es capaz de convertir en hechos verificables las leyes formuladas en forma general (resolución de ecuaciones) y analiza la validez de dichas leyes mediante el uso de estadísticas. Usa, inventa, reflexiona y experimenta con la matemática con el fin de encontrar nuevas aplicaciones de los métodos matemáticos con vistas a su utilización en la investigación científica o en la aplicación técnica.

El término genérico "matemático" puede decantarse en dominios más restringidos, como por ejemplo: geómetra, algebrista, analista, etc.

Existen principalmente dos interpretaciones, por un lado, se le llama matemático a aquella persona que "trabaja activamente en la investigación matemática", lo cual, en la actualidad, la mayoría de las veces se acompaña con publicaciones en especializadas en el tema; a esta clasificación pertenecen Henri Poincaré o Andrew Wiles, por ejemplo. Por otro lado, matemático puede designar a una persona con "conocimiento especiales" en matemática, o que trabajó en un campo conexo como la enseñanza o la vulgarización; como por ejemplo Aurelio Baldor o Martin Gardner.

La Unión Matemática Internacional publica un anuario mundial de matemáticos, la definición retenida es:
Suele hacerse a veces la distinción entre matemáticas puras y matemáticas aplicadas para diferenciar la investigación "en" matemática, de la investigación en áreas relacionadas (industria, ingeniería, tecnología) o interdisciplinas (ciencias cognitivas), en ciencias afines (estadística, informática) o incluso en ciencias sociales (filosofía, historia). Esta distinción, sin embargo, no es aceptada unánimemente, como tampoco la clasificación de un matemático como "científico".



Como consecuencia de las enormes dificultades e impedimentos con los que las mujeres han tenido que enfrentarse, a lo largo de la historia y en todos los lugares del mundo, para poder llevar a cabo una labor de estudio o investigación en matemáticas (y en la ciencia, en general), la mayoría de las personas que han sobresalido en el área de las matemáticas y han alcanzado renombre universal han sido hombres. A pesar de estos inconvenientes, ha habido mujeres que, gracias a una indomable voluntad, una posición social alta y, generalmente, a la ayuda de algún mecenas masculino, han dejado una huella imborrable en las matemáticas. Y no solo porque sus historias de superación sean un ejemplo, sino porque sus contribuciones científicas han tenido una notable repercusión y relevancia. Entre las mujeres matemáticas más prominentes nacidas antes del siglo XX podemos citar a: Téano de Crotona (siglo VI  a. C.), Hipatia de Alejandría (alrededor del 400), Ada Lovelace (1815-1852), Maria Gaetana Agnesi (1718-1799), Sophie Germain (1776-1831), Sofia Kovalévskaya (1850-1891), Alicia Boole Stott (1860-1940), Émilie du Châtelet (1706-1749), Carolina Herschel (1750-1848), Mary Somerville (1780-1872) y Florence Nightingale (1820-1910).

Los profundos cambios demográficos y sociales acontecidos principalmente desde el final de la Segunda Guerra Mundial han favorecido la integración de las mujeres en el ámbito laboral y la paulatina reducción de las diferencias de oportunidades con los hombres. Por tanto, la lista de grandes mujeres matemáticas del siglo XX es extensa y entre sus figuras más destacadas cabe mencionar a Mileva Marić (1875-1948), Emmy Noether (1882-1935), Mary Lucy Cartwright (1900-1998), Rózsa Péter (1905-1977), Grace Murray Hopper (1906-1992), Olga Taussky-Todd (1906-1995), Julia Robinson (1919-1985), Emma Castelnuovo, (1913-2014), María Wonenburger (1927-), Ingrid Daubechies (1954-)..

No obstante, la presencia de las mujeres en los puestos académicos y científicos de responsabilidad es escasa. Por ello, y como ocurre en los demás ámbitos del conocimiento, en diversos países existen asociaciones de mujeres matemáticas con una fuerte implicación social en la búsqueda de la igualdad de oportunidades en el marco de la investigación y la docencia en matemáticas. Este es el caso de la Asociación Mujeres y Matemáticas, la European Women in Mathematics (EWM) o la Comisión Mujeres y Matemáticas de la Real Sociedad Matemática Española, así como algunas asociaciones latinoamericanas de mujeres matemáticas.
Cabe citar a Roswitha, monja de un convento sajón del siglo X, de mejor y mayor trabajo en literatura y filosofía que en la ciencia de los números. No obstante lució buen conocimiento de la Aritmética de Boecio y menciona cuestiones ligadas a números defectivos y perfectos, señalando entre ellos a 6, 28, 496, y 8128.

En una publicación sobre matemática recreativa de Rodríguez Vidal y Rodríguez Rigual, también figuran los nombres que siguen, como cultoras de matemática.


Nota: No existe premio Nobel de matemáticas; el Premio Abel o la Medalla Fields se consideran por lo general su equivalente.

-- Estructura del informe --

"Puede elegir el orden de la lista, pulsando en el Premio, Sede, etc."



</doc>
<doc id="11393" url="https://es.wikipedia.org/wiki?curid=11393" title="Ophrys lutea">
Ophrys lutea

Ophrys lutea (Gouan) Cav. 1793 es una orquídea monopodial y terrestre de la subtribu Orchidinae de la familia Orchidaceae del género "Ophrys". Es de las llamadas orquídeas abeja. Son orquídeas muy variables que pueden presentar variaciones o subespecies.

Esta especie de hábitos terrestres monopodial se distribuye por el Mediterráneo (España, sur de Francia, y Córcega) en general en toda Europa. En prados, garrigas, arbustos y bosques. Alcanzan una altura de 25 a 30 cm.

Durante el verano esta orquídea está durmiente como un bulbo subterráneo o tubérculo, que sirve como una reserva de alimento. Al final del verano-otoño desarrolla una roseta de hojas. También un nuevo tubérculo empieza a desarrollarse y madura hasta la siguiente primavera, el viejo tubérculo muere lentamente. En la primavera siguiente el tallo floral empieza a desarrollarse, y durante la floración las hojas comienzan a marchitarse.

La mayoría de las orquídeas "Ophrys" dependen de un hongo simbionte, debido a esto desarrollan sólo un par de pequeñas hojas alternas. No pueden ser trasplantadas debido a esta simbiosis. Las pequeñas hojas basales forman una roseta pegadas a ras de suelo. Son oblongas, lanceoladas, redondeadas, sin identaciones; tienen un color verde azulado. Se desarrollan en otoño y pueden sobrevivir las heladas del invierno.

La "Ophrys lutea" es una orquídea terrestre que tiene un tubérculo subterráneo, globular, y pequeño del cual sale el tallo floral erecto, sencillo y sin ramificaciones de unos 30 cm. Las flores poseen un labelo de gran tamaño. El labelo de color amarillo canario intenso de unos 13 a 18 mm de longitud tiene tres lóbulos con los dos lóbulos laterales triangulares algo más pequeños y glabros. El lóbulo intermedio es glabro y más grande que los laterales en el que el espéculo es menor que en otras especies, de color acero azulado, con forma de H, enmarcado dentro de una mancha marrón oscuro imitando el abdomen de ciertos insectos.

Esta variedad tiene dos sépalos laterales iguales en tamaño redondeados en el ápice, el tercero se vuelve un poco hacia adelante. Los tres sépalos de unos 7 mm de longitud y un color uniforme amarillo verdoso o verde claro. De dos a diez flores se desarrollan en el tallo floral con hojas basales. Las flores son únicas, no sólo por su inusual belleza, color y formas excepcionales, sino también por la ingenuidad con la que atraen a los insectos. Su labelo imita en este caso al abdomen de una abeja. Florecen de mediados de marzo a abril. 

Esta sugestión visual sirve como reclamo intimo. Esta polinización mímica está acrecentada al producir además la fragancia de la hembra del insecto en celo. Estas feromonas hacen que el insecto se acerque a investigar. Esto ocurre solamente en el periodo determinado en el que los machos están en celo y las hembras no han emergido aún. El insecto está tan excitado que empieza a copular con la flor. Esto se denomina "pseudocopulación", la firmeza, la suavidad, y los pelos aterciopelados del labelo, son los mayores incentivos, para que el insecto se introduzca en la flor. Las polinia se adhieren a la cabeza ó al abdomen del insecto. Cuando vuelve a visitar otra flor las polinias golpean el estigma. Los filamentos de las polinias durante el transporte cambian de posición de tal manera que los cereos granos de polen puedan golpear al estigma, tal es el grado de refinamiento del proceso que si los filamentos no toman la nueva posición las polinias no podrían fecundar la nueva orquídea.

Cada orquídea tiene su propio insecto polinizador y depende completamente de esta especie polinizadora para su supervivencia. Lo que es más los machos embaucados es probable que no vuelvan ó incluso que ignoren plantas de la misma especie. Por todo esto solamente cerca del 10 % de la población de "Ophrys" llega a ser polinizada. Esto es suficiente para preservar la población de "Ophrys", si se tiene en cuenta que cada flor fertilizada produce 12.000 diminutas semillas.

"Ophrys lutea" fue descrito por Antonio José de Cavanilles y publicado en "Icones et Descriptiones Plantarum" 2: 46, t. 160. 1793.
Ophrys. nombre genérico que deriva de la palabra griega: "ophrys" = "ceja" refiriéndose a la alta consideración que se tiene hacia este género. "Ophrys" se menciona por vez primera en el libro "Historia Natural" de Plinio el Viejo (23-79 AD).

lutea: epíteto latino que significa "amarilla". 
Estas Orquídeas se denominan las "Orquídeas Abejas" .




</doc>
<doc id="11394" url="https://es.wikipedia.org/wiki?curid=11394" title="Ophrys speculum">
Ophrys speculum

Ophrys speculum es una orquídea, monopodial y terrestre, perteneciente a la subtribu Orchidinae. Es una de las denominadas popularmente «orquídea abeja». 
Su nombre ""Ophrys"" deriva de la palabra griega: "ophrys" = "ceja" refiriéndose a la alta consideración que se tiene hacia este género.
Del griego ""speculum"' '= ""Similar a un espejo"" refiriéndose a su labelo que puede pasar como el vientre de una abeja visto en un espejo. 
Ophrys se menciona por vez primera en el libro "Historia Natural" de Plinio el Viejo (23-79 AD).
Estas Orquídeas se denominan las "Orquídeas Abejas" .

Esta especie de hábitos terrestres monopodial se distribuye por el Mediterráneo (España, sur de Francia, y Córcega) en general en toda Europa. En prados, garrigas, arbustos y bosques. Alcanzan una altura de 25 a 30 cm.

Durante el verano estas orquídeas están durmientes como un bulbo subterráneo tubérculo, que sirve como una reserva de comida. Al final del verano-otoño desarrolla una roseta de hojas. También un nuevo tubérculo empieza a desarrollarse y madura hasta la siguiente primavera, el viejo tubérculo muere lentamente. En la próxima primavera el tallo floral empieza a desarrollarse, y durante la floración las hojas ya comienzan a marchitarse.

La mayoría de las orquídeas Ophrys dependen de un hongo simbionte, debido a esto desarrollan solo un par de pequeñas hojas alternas. No pueden ser trasplantadas debido a esta simbiosis. Las pequeñas hojas basales forman una roseta pegadas a ras de suelo. Son oblongo lanceoladas redondeadas sin identaciones tienen un color verde azulado. Se desarrollan en otoño y pueden sobrevivir las heladas del invierno.

La "Ophrys speculum" es Orquídea terrestre que tiene tubérculo subterráneo, globular, y pequeño del cual sale el tallo floral erecto sencillo y sin ramificaciones de unos 30 cm. Las flores poseen un labelo de gran tamaño. El labelo es trilobulado marrón oscuro, con lóbulo central aterciopelado, triangular, alargado y abombado. El labelo de color pardo rojizo de unos 13 a 18 mm de longitud tiene tres lóbulos con los dos laterales triangulares que están vueltos ligeramente hacia adelante con pelos abundantes finos y sedosos imitando élitros de insecto. El lóbulo intermedio es glabro y más grande que los laterales en el que el espéculo es de color acero azulado, con forma de I, con ribete amarillo delimitando el espejo central de la zona pilosa .

Esta variedad tiene dos sépalos laterales iguales en tamaño el tercero se vuelve un poco hacia adelante. Los tres sépalos de unos 7 mm de longitud y un color uniforme verde claro con dos rayas marrones los laterales y varias rayas el central. Los pétalos más internos son bastante más pequeños que los sépalos, estrechos y afilados ( imitan las antenas de un insecto), pero del mismo color verde claro que los sépalos, y hacen un gran contraste con los tonos oscuros del labelo. De dos a diez flores se desarrollan en el tallo floral con hojas basales. Las flores son únicas, no solo por su inusual belleza, gradación de color y formas excepcionales, sino también por la ingenuidad con la que atraen a los insectos. Su labelo imita en este caso al abdomen de una "Dasyscolia ciliata", una avispa de la familla Scoliidae. Esta especie es muy variable en sus dibujos y gradación de color. Florecen de mediados de marzo a abril. 
Esta sugestión visual sirve como reclamo intimo. Esta polinización mímica está acrecentada al producir además la fragancia de la hembra del insecto en celo. Estas feromonas hacen que el insecto se acerque a investigar. Esto ocurre solamente en el periodo determinado en el que los machos están en celo y las hembras no han copulado aún. El insecto está tan excitado que empieza a copular con la flor. Esto se denomina "pseudocopulación", la firmeza, la suavidad, y los pelos aterciopelados del labelo, son los mayores incentivos, para que el insecto se introduzca en la flor. Las polinia se adhieren a la cabeza ó al abdomen del insecto. Cuando vuelve a visitar otra flor los polinia golpean el estigma. Los filamentos de los polinia durante el transporte cambian de posición de tal manera que los cereos granos de polen puedan golpear al estigma, tal es el grado de refinamiento de la reproducción. Si los filamentos no toman la nueva posición los polinia podrían no haber fecundado la nueva orquídea.

Cada orquídea tiene su propio insecto polinizador y depende completamente de esta especie polinizadora para su supervivencia. Lo que es más los machos embaucados es probable que no vuelvan ó incluso que ignoren plantas de la misma especie. Por todo esto solamente cerca del 10 % de la población de "Ophrys" llega a ser polinizada. Esto es suficiente para preservar la población de "Ophrys", si se tienen en cuenta que cada flor fertilizada produce 12,000 diminutas semillas.

La fecundación de esta orquídea en particular la realizan los machos de una especie de avispa "Campsoscolia ciliata". al confundir el labelo de la flor con una hembra e intentar copular con ella.

El parecido del labelo con la hembra es tan grande, a los ojos del insecto, que la mayoría de los machos prefieren la flor a la verdadera hembra.




</doc>
<doc id="11396" url="https://es.wikipedia.org/wiki?curid=11396" title="Orobanche rapum-genistae">
Orobanche rapum-genistae

El espárrago de lobo (Orobanche rapum-genistae ) es una hierba vivaz de la familia de las orobancáceas; es un holoparásito carente de clorofila, que se fija a plantas de la familia de las fabáceas para extraer de ellas sus nutrientes.

El espárrago de lobo es una hierba vivaz, de tallos erectos de hasta 90 cm de altura y color amarillento o purpúreo. Las hojas son vestigiales, alternas, carnosas, sésiles, oblongas a ovadas. 

Florece entre junio y agosto, formando inflorescencias terminales en forma de espiga, de color amarillento y olor desagradable; los 10 a 20 floros son pentámeros, hermafroditas, con cuatro estambres y un pistilo, y el ovario súpero. La polinización la llevan a cabo insectos, normalmente dípteros. El fruto es una cápsula unilocular con numerosas semillas que se dispersan por anemocoria. Las espigas muertas del año anterior normalmente se conservan adheridas al tallo.
Como parásito de piornos y escobas.

El espárrago de lobo parasita las raíces de arbustos leguminosos, disminuyendo su vigor. Habita los terrenos en los que aparecen éstos, normalmente colinas, pastizales y bancales arenosos.
Es oriunda de las regiones templadas de Europa occidental, donde se extiende desde Italia hasta las Islas Británicas, donde hoy se encuentra amenazada por la destrucción de su hábitat.



</doc>
<doc id="11397" url="https://es.wikipedia.org/wiki?curid=11397" title="Paronychia argentea">
Paronychia argentea

Paronychia argentea, comúnmente llamada sanguinaria, o nevadilla es una planta herbácea de la familia de las cariofiláceas; creciendo en arenales, caminos, campos abandonados y terrenos secos. Es la planta hospedadora del insecto "Phyllomorpha laciniata".
Especie anual de hábito procumbente, alcanza los 30 cm de altura. Similar a "Paronychia capitata" pero con las hojas casi glabras y con una cerda rígida y prominente y lóbulos del cáliz con márgenes transparentes.
El tallo es glabro o pubescente con hojas opuestas, elípticas, estipladas y mucronadas. <br>Las flores se presentan en glomérulos laterales y terminales. Son hermafroditas, pentámeras y actinomorfas, acompañadas de brácteas escarioso-plateadas mayores que ellas mismas. El fruto es un aquenio.

En todo el Mediterráneo. Vive en terrenos baldíos o secos, dunas y cunetas. Florece de invierno a verano.
Se utilizó, cocida, como diurético y purificadora de la sangre ("sanguinaria") y en emplasto para curar heridas.
"Paronychia argentea" fue descrito por Jean-Baptiste Lamarck y publicado en "Flore Françoise" 3: 230. 1778[1779].
Número de cromosomas de "Paronychia argentea" (Fam. Caryophyllaceae) y táxones infraespecíficos: 2n=28


</doc>
<doc id="11398" url="https://es.wikipedia.org/wiki?curid=11398" title="Plantago lanceolata">
Plantago lanceolata

Llantén menor o siete venas (Plantago lanceolata) L. es una especie de planta herbácea perenne natural de toda Europa, América del Norte, América Latina y Asia occidental donde crece en terrenos secos, taludes, bordes de caminos y lugares incultos.

Es una planta herbácea vivaz sin tallos ramificados y con tallos florales que alcanzan 30-50 cm de altura, tiene un rizoma corto central del que brotan muchas raicillas de color amarillo. Las hojas lanceoladas u ovadas, largas, algo dentadas y radicales están dispuestas en una roseta basal en la base del tallo, tienen de 3-7 nervaciones longitudinales que se estrechan y continúan en el peciolo. La inflorescencia terminal es una espiga densa con flores muy pequeñas de color blanca o purpurea. La espiga es corta durante la floración y luego se va alargando. El fruto es un pixidio con 4-16 semillas.

"P. lanceolata" contiene feniletanoides como acteosida (verbascósido), cistanoside F, lavandulifolioside, plantamajoside y isoacteoside. También contienen los glucósidos iridoides aucubin y catalpol.

"Plantago media" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 1: 113-114. 1753. 
Plantago: nombre genérico que deriva de "plantago" = muy principalmente, nombre de varias especies del género "Plantago" L. (Plantaginaceae) –relacionado con la palabra latina "planta, -ae f." = "planta del pie"; por la forma de las hojas, según dicen–. Así, Ambrosini (1666) nos cuenta: “Es llamada Plantago por los autores latinos, vocablo que toman de la planta del pie (a causa de la anchura de sus hojas, las que recuerdan la planta del pie; y asimismo porque las hojas tienen líneas como hechas con arado, semejantes a las que vemos en la planta del pie)”

lanceolata: epíteto latíno que significa "lanceolada", en referencias a sus hojas.
Números cromosomáticos de "Plantago lanceolata" (Fam. "Plantaginaceae") y táxones infraespecíficos: 2n=12
Llanten kocue.
yantén, yentén, yerba de las cinco venas, yerba de los pájaros, zaragatona.


</doc>
<doc id="11400" url="https://es.wikipedia.org/wiki?curid=11400" title="Raphanus raphanistrum">
Raphanus raphanistrum

La rabaniza, rabizón o rábano silvestre ("Raphanus raphanistrum") es una planta herbácea anual de la familia de las brasicáceas. Se lo señala como uno los posibles antepasados del rábano doméstico ("R. sativus").

Sus primeras hojas crecen en forma de roseta en la base de un tallo erecto pubescente, mientras que las demás crecen a lo largo de él. Tiene flores tetrámeras de color rosado y su fruto es una silicua. Al igual que el rábano doméstico, su raíz está engrosada porque allí almacena almidón de reserva.

Son hierbas anuales o bianuales gruesas, con raíces axonomorfas, erectas y ramificadas, de 3–8 dm de alto, en general escasamente híspidas. Hojas inferiores obovado-oblongas, pinnatífidas con 5–15 segmentos oblongos, progresivamente más grandes hacia el segmento terminal, hojas superiores reducidas y frecuentemente enteras o casi así. Pétalos 1–1.5 cm de largo, amarillentos tornándose blancos; estambres tetradínamos. Silicuas indehiscentes, cilíndricas o casi así cuando frescas, tornándose acostilladas al secarse, estrechadas entre las semillas en la porción fértil, la cual es 2–4 cm de largo y 4–8 mm de ancho, un rostro estéril de 1–3 cm de largo se encuentra sobre la parte fértil; semillas esféricas, cotiledones conduplicados.

Es una especie originaria de Asia o del Mediterráneo que está presente en todos los continentes y, por su facilidad de dispersarse y no tener usos relevantes, se considera una maleza. Tiene buena capacidad de adaptación, por lo que crece tanto a orillas de los caminos y en terrenos abandonados de escasa fertilidad, como dentro de cultivos de todo tipo.

"Raphanus raphanistrum" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 669. 1753.
Raphanus: nombre genérico que deriva del Griego "ράφανος" y luego el Latín "rǎphǎnus, -i" que designaba el "Raphanus sativus" y sus variedades, en particular la variedad "niger", en la antigüedad, y viene descrito en la "Historia naturalis" ("19, XXVI, 80") de Plinio el viejo.

raphanistrum: epíteto






</doc>
<doc id="11401" url="https://es.wikipedia.org/wiki?curid=11401" title="Senecio squalidus">
Senecio squalidus

Senecio squalidus es una especie perteneciente a la familia de las asteráceas. Es nativa de las regiones montañosas de Europa central y del sudeste y ampliamente distribuida por el hemisferio norte. Su hábitat natural son caminos, vertederos, parques públicos. No tiene excesivos requerimientos de sustrato.

Es una planta herbácea perenne o bienal. Alcanza de 50 cm a 1 m de altura, dependiendo de las condiciones. Tallo erecto de "color vino tinto aguado" como describe el botánico Pío Quer en el Dioscórides. Hojas axiales en forma de cuerno de arce, que se van desplegando a medida que crecen. Los capítulos amarillos están formadas por 10 a 14 florecillas. Los pétalos de la corola, también amarillos, miden entre 8 a 15 mm de largo por 2 a 4 mm de ancho.

Esta planta está escasamente documentada, pero para el género "Senecio" se ha comprobado la existencia de pirrolicidina, un alcaloide tóxico para el ganado y los seres humanos.

"Senecio squalidus" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 869. 1753. 
Senecio: nombre genérico que deriva del Latín "sĕnĕcĭo, ōnis" = "anciano", por los capítulos maduros que recuerdan a sus cabezas de pelo y barba blancas.

squalidus: epíteto latíno que significa "escuálido".




</doc>
<doc id="11402" url="https://es.wikipedia.org/wiki?curid=11402" title="Sesamum indicum">
Sesamum indicum

El sésamo o ajonjolí (Sesamum indicum ), cuya semilla es el ajonjolí, es una planta cultivada por sus semillas ricas en aceite, que se emplean en gastronomía, como en el pan para hamburguesas. También es usado para hacer dulces como la halva.
Son hierbas que alcanzan un tamaño de hasta 1,50 m de alto, ramificadas o no. Hojas basalmente alternadas y disminuyendo de tamaño hacia el ápice, ovadas a linear-lanceoladas, ápice agudo, base redondeada angostamente cuneada, dentadas o enteras; pecíolos acanalados, los inferiores hasta 1 cm de largo, los superiores hasta 8 cm de largo. Flores solitarias en las axilas; sépalos connados solamente en la base, lineares, 5–8 mm de largo, algo carnosos, ebracteolados; corola oblicuamente campanulada, blanca,negro, zambo rosada o rosa viejo, nectarostigmas amarillo pálidos o ausentes, lobos no manchados; estambres 4, estaminodios ausentes. Fruto una cápsula oblongo-cuadrangular, café-amarillenta, no pectinada, dehiscente, con 2 rostros terminales de 3–5 mm de largo; semillas numerosas, obovadas, negras, cafés o blancas, testa brillante.

El sésamo es originario de la India y de África, desde donde llegó a América transportada por los esclavos, quienes utilizaban sus semillas para espesar y dar sabor a gran variedad de platos. En los estados sureños de EE.UU. y en el Caribe, donde el sésamo fue introducido por esclavos africanos, se lo conoce mayormente por su nombre en lengua Mandé: "benne".

Las semillas de sésamo poseen una elevada cantidad de proteínas, además de ser ricas en metionina, un aminoácido esencial. Las grasas que contiene son insaturadas, es decir 'buenas', lo que junto a su contenido de lecitina y fitoesteroles las convierte en un alimento que contribuye a reducir el nivel de colesterol sanguíneo. Igualmente son destacables sus muy altos niveles de calcio (que interviene en la formación de huesos y dientes), de hierro (que desempeña numerosas e importantes funciones en el organismo), así como de zinc (mineral que participa en el metabolismo de los hidratos de carbono, las grasas y las proteínas, e incluso previene la impotencia masculina). Aproximadamente, 100 gramos de semillas de sésamo crudo, contienen y aportan:

Además de vitaminas de los grupos B y E.

También contienen lignano, incluyendo la sesamina, un fitoestrógeno con propiedades antioxidantes. Entre los aceites comestibles de seis especies, el de sésamo tiene el mayor contenido antioxidante.

Para absorber los nutrientes de las semillas de sésamo es imprescindible tostarlas y triturarlas (con un suribachi o molinillo de café), pero sin llegar a molerlo por completo (el puré de sésamo no tiene tantas propiedades y es indigesto). De lo contrario, se expulsan del organismo sin digerir.

Las semillas de sésamo poseen también buenas cantidades de fibra, por lo que su consumo resulta beneficioso para la regulación de la función intestinal.

Las mujeres de la antigua Babilonia comían halva, una mezcla de miel y semillas de sésamo, para prolongar su juventud y belleza; y los soldados de Roma hacían lo mismo para aumentar su fortaleza y energía.

Éstas pueden estar ya incluidas en productos como el pan tostado o las galletas de sésamo, o bien pueden añadirse a gran variedad de platos. Resultan exquisitas en ensalada y en platos de pasta o arroz, gracias al peculiar sabor y textura que presentan. En España, Italia, Francia, Grecia y en el Cercano Oriente es común el consumo del sésamo espolvoreado sobre tortas de aceite o rosquillas como las llamadas taralli o koulourakia, pasteli o simit , así como en la baklava; por otra parte, es con sésamo que se confecciona uno de los aliños principales de la comida del Mediterráneo Oriental, la tahina. En el Medio Oriente el sésamo es componente principal del plato conocido como Halva, en Japón del goma-dofu, en China de los bollos llamados din deui o matuan y en Vietnam del báh hrán.

Cerca de un tercio del sésamo importado por EE.UU. de México es adquirido por McDonald's para usar en comidas (The Nut Factory 1999).

Otro de los modos más frecuentes de encontrarlo es en aceite. Éste se obtiene a partir del prensado en frío de las semillas. Conviene tener en cuenta que para poder aprovechar todas las propiedades que posee el aceite de sésamo es importante comprarlo sin refinar.

Existen muy diversas formas de incluir el sésamo en la dieta, como por ejemplo en forma de tahini, una pasta de sésamo de consistencia cremosa muy sencilla de preparar, en forma de gomasio, nombre que recibe la sal de sésamo, o como salsa de sésamo, apta para acompañar casi cualquier tipo de alimento gracias a su suave y agradable sabor.

Actualmente, las semillas de ajonjoli son una de las semillas oleaginosas más utilizadas en la cocina y repostería internacional, sobre todo en la oriental. Se emplea frecuentemente en la cocina como una especie de acompañamiento de platos y como producto elaborado hay aceite de sésamo muy frecuente en la cocina asiática. El sésamo se emplea como alimento de las larvas de algunas especies de Lepidopteras como "Agrotis segetum". Este alimento es una buena fuente de magnesio y no contiene gluten. Se usa para sushi, ensaladas y algunas variedades de pan.

Pedaliáceae es una familia de plantas de fanerógamas clasificada en el orden Lamiales. Se caracterizan por tener pelos mucilaginosos en tallos y hojas que le dan una sensación fangosa o húmeda, tienen a menudo, frutos con ganchos y se parecen a las semillas de los ajíes y pimentones

Esta planta es muy cultivada en los países de Oriente Medio y en la India, de donde es originario. Planta herbácea que alcanza hasta 1,50 m de altura. Cultivado en campos cerca de los ríos. Los niveles de producción son altos en la India Y en el Oriente Medio. Una planta de sésamo de 60 cm puede llegar a tener entre 8 y 16 semillas (aproximadamente), pero Una planta de sésamo de 1,5 metros puede llegar a tener entre 10 y 35 semillas (aproximadamente).

"Sesamum indicum" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 634. 1753.
Los dos nombres que tiene en español proceden: el primero del latín "sesámum" y "ajonjolí" del árabe: de "al-ŷulŷulān", pronunciado "al-ŷulŷulīn" en árabe andalusí debido al fenómeno fonético llamado "imala". La palabra "ŷulŷulān" alude al repiqueteo (جلجلة "ŷalŷala") de las semillas maduras dentro de la cápsula.

indicum: epíteto geográfico que alude a su localización en el Océano Índico.

Sésamo, ajonjolí, ajonjolín, ajonjulí, aljonjolé, aljonjolí, jonjolé, Jjonjolí, haholí, jijirí, ejonjilí.

La palabra sésamo se menciona en el cuento Alí Babá y forma parte del nombre de un programa de televisión para niños, Plaza Sésamo -> Barrio Sésamo.




</doc>
<doc id="11403" url="https://es.wikipedia.org/wiki?curid=11403" title="Taraxacum officinale">
Taraxacum officinale

El diente de león (Taraxacum officinale), también conocido como achicoria amarga y meacamas, es una especie de la familia de las asteráceas.

Considerada generalmente como una "mala hierba", sus hojas se consumen en ensalada y se le han atribuido numerosas propiedades medicinales.

Esta planta perenne con raíz primaria larga y roseta basal, suele alcanzar 40 cm de altura.
Tiene hojas alternas lanceoladas con una nervadura central, sin peciolo diferenciado, pinnatipartidas con lóbulos en forma triangular de márgenes dentados y agudos, a veces presenta microvellosidades. El tallo permanece siempre en un estado extremadamente acortado, es por esto que se denominan plantas acaules. Además son capaces de producir un entrenudo alargado con una inflorescencia, denominado escapo. Pedúnculos de la inflorescencia huecos, que al romperse emanan un jugo lechoso amargo. Flores hermafroditas de un color amarillo dorado que la hacen fácilmente identificable. Corola en lígulas terminada en cinco pequeños dientes, florece en primavera a hasta fines de verano. El fruto es un "aquenio" (cipsela) con largo pico y vilano.

Hay indicios serios sobre una procedencia europea. En la actualidad se ha extendido prácticamente por todos los continentes.

Se encuentra fácilmente en los caminos, pastizales, prados, siembra directa, y sobre todo en jardines, tanto que es considerada "mala hierba" o "maleza", por los jardineros.

Es una planta depurativa, indicada para purificar el organismo de elementos tóxicos. Puede actuar en el hígado, riñón y la vesícula biliar, y con su efecto diurético evita la aparición de piedras en el riñón. También es un tónico digestivo contra el estreñimiento y la resaca de alcohol.

Para uso tópico es eficaz para limpiar la impurezas de la piel, acné, urticaria. Estas propiedades son por su contenido de inulina, ácidos fenólicos, sales minerales, entre otras sustancias que aportan beneficios en la piel.

En algunos periodos de escasez, la raíz seca se ha utilizado como sustituto de la achicoria, que a su vez era sustituto del café. Sus hojas silvestres o cultivadas son comestibles, se prefieren las que son jóvenes y tiernas para ensaladas mientras que las maduras al ser más amargas se consumen cocidas aunque está sin confirmarse la existencia de cultivos para este fin.

Sin embargo, Font Quer en su "Dioscórides renovado" comenta de la existencia de cultivos en León por el látex de la raíz, rico en caucho (sin especificar la especie de "Taraxacum" de que se tratara).

Es una de las principales especies de flora de interés apícola en las praderas, las abejas visitan sus flores indefectiblemente, entregando muy buena cantidad de néctar y polen. Por su distribución prácticamente cosmopolita es conocido en todo el mundo por los apicultores.

Se llega a hablar de una "taraxoterapia" en cuanto al uso medicinal de esta planta; en medicina popular es usado para diversas recetas y composiciones con otros fitoremedios, principalmente como:

Entre los compuestos más importantes de "Taraxacum" se encuentran las sesquiterpenlactonas (a las cuales se les atribuyen las propiedades antiinflammatorias y anticancerígenas), fenilpropanoides (se les atribuyen propiedades antiinflamatorias), saponinas triterpenoides y polisacáridos. Las sesquiterpenlactonas normalmente se encuentran como glucósidos, por ejemplo los taraxacósidos, taraxacólidos, dihidrolactucina, ixerina, ácidos taraxínicos, y ainsliósido. Entre los fenilpropanoides se destacan el ácido cicórico, el ácido monocafeoiltartárico, el ácido 4-cafeoilquínico, ácido clorogénico, ácido cafeico y compuestos relacionados. La inulina se encuentra en cantidades considerables en la raíz.

En fitoterapia (herbolaria) se usa también los principios activos puros mediante infusiones o decoctos, principalmente para inapetencia, indigestión y disturbios hepáticos.

Sus hojas contienen gran cantidad de vitamina A, C, hierro, llevando más hierro y calcio que las espinacas u otras hortalizas.

En las artes culinarias de países del Mediterráneo es apreciada la ensalada primaveral depurativa hecha ya sea sólo con la hojas de taraxacum o mezclada con otras verduras.

También los pétalos de las flores pueden contribuir a dar sabor y color a ensaladas mixtas. Los botones de las flores son apreciados si se preparan con aceite de oliva. Las flores también se pueden preparar en pastel e incluso fritas (rehogadas). Los tiernos brotes basales se pueden consumir al natural o con aceite de oliva extravirgen o salteados en una sartén con ajo (o aún mejor con ajo ursino).

En muchas regiones de Europa se preparaba una mermelada de estas flores. También se prepara un vino de diente de león.

Las hojas de esta planta son uno de los ingredientes del preboggion, mezcla de hierbas típica de la cocina de Liguria.

En Primavera a la Carta, un cuento de O. Henry incluido en "Los cuatro millones", tal vez su obra narrativa más importante, se incluye al taraxacum officinale (Dandelion en inglés y diente de león en español) como uno de los platos primaverales (Dandelions with hard-boiled egg) en un restaurante de Nueva York y viene a ser el protagonista involuntario de una breve y simpática historia de amor, que puede leerse, en inglés, en Wikisource ().

"Taraxacum officinale" fue descrita por L.) Weber ex F.H.Wigg. y publicado en "Primitiae Florae Holsaticae" 56. 1780. 
Número de cromosomas de "Taraxacum officinale" (Fam. Compositae) y taxones infraespecíficos: 2n=24, 26.
Todos los demás serían meros sinónimos de la especie o de otras especies del género.

También pelosilla, corona de fraile, achicoria amarilla, achicoria silvestre, bufas de lobo, chinita de campo, flor de macho, frango, lechiriega, taraxaco y tatusia.





</doc>
<doc id="11404" url="https://es.wikipedia.org/wiki?curid=11404" title="Tragopogon porrifolius">
Tragopogon porrifolius

Tragopogon porrifolius, conocido comúnmente como salsifí o barba cabruna, entre otros, es una especie de planta herbácea del género "Tragopogon" de la familia de las asteráceas.

Se trata de una planta herbácea anual, bienal o perenne con el tallo erecto, glabro o algo tomentoso, simple o parcialmente ramificado y que puede medir desde 30-40 cm hasta 1,5 m de altura. Tiene una raíz robusta y largamente cónica comestible. Las hojas basales —no organizadas en roseta— y caulinares, semi-amplexicaules y de forma linear a lanceolada, miden 15-40 cm de largo por medio centímetro de ancho y tienen los márgenes a menudo ondulados y el ápice acuminado; pueden ser glabras o tomentosa-lanudas. Los capítulos, soportados por un pedúnculo apicalmente hinchado, son usualmente solitarios y su involucro, de 4-5 cm en la antesis hasta 8 cm en la fructificación, está constituido por 7-8 brácteas lineares glabras de 3-4 cm de largo. Rodean un receptáculo desnudo que soporta una 85-110 lígulas de color violeta-purpúreo, a veces amarillas en su base, y con el tubo apicalmente peludo. Dichas lígulas engendran cipselas fusiformes, algo curvadas, con el cuerpo ornamentado por 10 costillas más o menos tuberculadas acabadas en un largo y fino pico acostillado, liso y apicalmente inflado en un disco tomentoso que soporta un vilano persistente de pelos fina y densamente plumosos.

Es una especie nativa de Europa mediterránea occidental y meridional —incluidas sus islas (Baleares, Córcega y Cerdeña)— así como de África del Norte extendiéndose hasta más allá de Pakistan. Ha sido introducid a y se ha naturalizada, e incluso cultivada, en Europa central y septentrional; en África del sur, Norteamérica, el Cono sur (Argentina, Chile, donde se cultiva localmente)9, Australia y Nueva Zelanda.
Como todas las especies del género, crece en prados y praderas algo soleados nitrificados, pero en sitios más secos que los donde crece "Tragopogon pratensis" y menos soleados que los donde vive "Tragopogon dubius".
Florece y fructifica de mayo hasta agosto. 

En la península ibérica se encuentra dispersa en todo el territorio, excepto en Portugal, donde escasea. Está también presente en las Islas Baleares y las Islas Canarias; en estas últimas, es dudoso que sea nativa.

La especie ha sido descrita originalmente como "Tragopogon Porri folio" por Joseph Pitton de Tournefort en "Institutiones Rei Herbariae", vol. 1, p. 477 en el año 1700 y ha sido ulteriormente validada por Carlos Linneo y publicado en "Species Plantarum", vol. 2, p. 789 en 1753 como "Tragopogon porrifolium", sin indicación de "locus typicus". 
Es la especie tipo del género "Tragopogon"; su lectotipo fue designado en 1992 por Consuelo Díaz de Guardia y Gabriel Blanca a partir de un ejemplar del Herbario de Joachim Burser (1583-1639) conservado en la Universidad de Uppsala (Suecia), debido a que el espécimen del herbario del propio Linneo no es válido para conservarlo como tipo.


Todos los otros taxones infraespecíficos descritos son meras sinonimías.


Linneo había ya obtenido artificialmente en 1759 híbridos entre "Tragopogon pratensis" y "Tragopogon porrifolius" con lígulas de color purpuráceo y de bases amarillas. Este híbrido fue encontrado ulteriormente en estado natural, primero en Suecia ("Tragopogon porrifolio-pratensis" Gosselm), luego en el oeste y centro de Francia y descrito entonces por Georges Rouy como "Tragopogon × mirabilis", a veces citado como "T. × mirabile".

La especie, introducida en Estados Unidos donde se volvió maleza invasora, ha dado lugar a un híbrido alopoliploide (2n=24) fértil endémico de zonas limitadas de Estados Unidos (Estados de Washington y de Idaho): "Tragopogon mirus" ("Tragopogon dubius" × "Tragopogon porrifolius").

También en Estados Unidos (Estado de Maryland) se ha descrito otro híbrido fértil de parientes europeos introducidos/naturalizados: "Tragopogon × neohybridus" Farw., nacido del cruce de "Tragopogon porrifolius" y "Tragopogon pratensis" var. "tortilis", y que presenta lígulas de un color "Rojo Neutro" correspondiente exactamente a la mezcla, artificial, de los colores básicos de las especies progenitoras ("Amarillo Limón" y "Purpureo Lavanda Claro"), determinados los 3 colores según la escala cromática en vigor en Estados Unidos en la época de la descripción ("Color standards and color nomenclature" de Robert Ridgway, 1912).


</doc>
<doc id="11405" url="https://es.wikipedia.org/wiki?curid=11405" title="Trifolium arvense">
Trifolium arvense

Trifolium arvense, llamado comúnmente pie de liebre, es una hierba anual o bienal, que alcanza los 40 cm de alto, nativa de las zonas frías y templadas de Europa y el oeste asiático. Prefiere los suelos arenosos, ácidos o alcalinos; se encuentra habitualmente en descampados, en zonas no irrigadas o de escasa humedad.

Son plantas anuales, tomentosas. Tallos de 5-35 cm de altura, ascendentes o erectos, ramificados. Hojas superiores subsentadas; las inferiores con pecíolos de hasta 25 mm; folíolos de 7-18 x 2-4 (-5) mm, linear-oblongos o estrechamente elípticos, ligeramente denticulados, mucronados; estípulas ovado-lanceoladas, acuminadas. Inflorescencias de 9-25 x 7-18 mm, ovoideas o cilíndricas, axilares y terminales, multifloras, sobre pedúnculos de hasta 35 mm. Flores sentadas. Cáliz con 1O nervios, tomentoso, con tubo ovoideo en la fructificación; dientes subiguales, 2-3 veces más largos que el tubo, setáceos. Corola de (2,5) 3-4 (-4,5) mm, mucho más corta que el cáliz, blanca o rosada. Florece de marzo a julio.

"Trifolium arvense" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 769. 1753.


Número de cromosomas de "Trifolium arvense" (Fam. Leguminosae) y táxones infraespecíficos: 2n=14


Trifolium: nombre genérico derivado del latín que significa "con tres hojas".

arvense: epíteto latino que significa "de campos cultivados".








</doc>
<doc id="11406" url="https://es.wikipedia.org/wiki?curid=11406" title="Vinca major">
Vinca major

Vinca major, llamada popularmente hierba doncella, es una planta originaria de la región mediterránea de Europa y del Asia Menor, desde España hasta Turquía y naturalizada y cultivada en el mundo entero.

Arbusto con una altura no muy superior a 1 metro, perenne con tallos erectos y cortos. Hojas 3-8 × 2-5 cm, aovadas a lanceoladas, la mayoría glabras, en ocasiones ciliadas a lo largo de los márgenes, las nervaduras secundarias, 4-7 pares, la base redondeada a cordata, el ápice obtuso a agudo, pecíolos 1-2 cm. Tiene inflorescencias axilares, pero consiste en una sola flor usualmente azul-púrpura o azul localizada en las axilas foliares alternas a lo largo del tallo; pedúnculo/pedicelo floral usualmente de 2-4 cm, curvado. Flores con los sépalos 10-18 mm, linear-triangulares, persistentes, ciliados; corola con el tubo (12-)15-20(-25) mm, expandiéndose en diámetro hacia el ápice, los lobos usualmente 15-20 × 5-12 mm, lanceolados a oblanceolados; estambres insertados cerca de la abertura del tubo de la corola; ovario con 2 nectarios, el estilo terete, delgado, la cabezuela estigmática con un borde basal y pelos apicales agrupados. Frutos 2.5-3.5(-5) cm, alargados, ligeramente curvados, glabros; semillas pocas por fruto, desnudas, ligeramente comprimidas, oblongas, ligeramente foveoladas.

En jardinería, setos no muy altos, rincones húmedos, claros y relleno de las bases de árboles.

Otro uso interesante de especies del género "Vinca" es la extracción de una serie de medicamentos conocidos en conjunto como alcaloides de la "Vinca". Estos se utilizan para el tratamiento de diferentes formas de cáncer.

Contiene los siguientes principios activos: Vinblastina, Vincristina, Vindesina y Vinorelbina son los cuatro compuestos hasta ahora aislados de este grupo de plantas.

"Vinca major" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 1: 209. 1753.

Tiene un número de cromosomas de: 2n=92

Brusela, brusela mayor, de viña en viña, enredadera, fincavervinca, hiedra, hierba doncella, laurel de Dafne, ojos azules, ojos llorosos, pervinca, pervíncola, pusela, siempreverde, vincapervinca, vincapervinca mayor, violeta, violeta de las brujas, violeta de los hechiceros, violeta de burro, violeta de El Paular, yerba doncella, yerba doncella de hoja ancha.




</doc>
<doc id="11407" url="https://es.wikipedia.org/wiki?curid=11407" title="Vicia cracca">
Vicia cracca

Vicia cracca, la arveja silvestre (que no debe confundirse con la arveja o guisante común) es una planta trepadora silvestre de la familia de las fabáceas. 
Sus tallos pubescentes alcanzan los 2 m de altura. Tiene hojas pinnadas con hasta doce foliolos, acabados en zarcillos, de contorno lanceolado. Las inflorescencias están formadas por hasta 40 flores azuladas, con el cáliz marcadamente más largo que el tubo, que salen de un largo pedúnculo. Los frutos, como en todas las especies del género, se presentan en vainas delgadas que miden hasta 3 cm de longitud. 

Es muy similar a otras especies del género, diferenciándose sobre todo por la forma de sus hojas y frutos.

Se encuentra generalmente en sitios húmedos, orillas de ríos, laderas de caminos, setos o campos de cultivo.
Se encuentra en sotos, prados, herbazales húmedos en la orla del quejigal, pinar, hayedo y bosques de ribera; a una altitud de 0-1950 metros en casi toda Europa, N, NE y W de Asia y Norte de África; introducida en Norteamérica. N de España y Sistema Ibérico.

"Vicia cracca" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 735. 1753.
Número de cromosomas de "Vicia cracca" (Fam. Leguminosae) y táxones infraespecíficos: 2n=12
Vicia: nombre genérico que deriva del griego "bíkion, bíkos", latinizado "vicia", vicium = la veza o arveja ("Vicia sativa" L., principalmente).

cracca: epíteto


</doc>
<doc id="11412" url="https://es.wikipedia.org/wiki?curid=11412" title="Uzbekistán">
Uzbekistán

La República de Uzbekistán (en uzbeko: Ўзбекистон Республикаси ["O‘zbekiston Respublikasi"]), anteriormente llamada Gran Bukaria, es un país situado en Asia Central. Limita al noroeste y al norte con Kazajistán, al sur con Afganistán, al noreste con Kirguistán, al sureste con Tayikistán y al suroeste con Turkmenistán. Junto con Liechtenstein, es uno de los dos únicos países doblemente aislados del mar, es decir, que uno desde Uzbekistán tiene que atravesar dos fronteras mínimamente para llegar al mar (salvo que se consideren como mares —y no como lagos— el Caspio y el casi desaparecido mar de Aral).

Fue parte integrante del Imperio samánida hasta que pasó a la dinastía Timúrida. La región fue conquistada en el siglo XVI por los nómadas uzbekos, que hablaban un dialecto del turco oriental. La mayor parte de la población uzbeka sigue hablando el uzbeco, idioma de la familia de las lenguas túrquicas.

Uzbekistán fue incorporada al Imperio ruso en el siglo XIX y en 1924 se constituyó en República Soviética, en el seno de la Unión de Repúblicas Socialistas Soviéticas conocida como la República Socialista Soviética Uzbeka. Accedió finalmente a su independencia en diciembre de 1991 después de la desmembración de la URSS.

La economía de Uzbekistán reside en la producción de diversas materias primas, como algodón, oro, uranio, potasio y gas natural. A pesar de declarar su intención de convertirse en una economía de libre mercado, hoy por hoy, sigue manteniendo rígidos controles, que a veces ahuyentan a los inversores extranjeros. La política de transición gradual, estrictamente controlada ha producido sin embargo resultados en la forma de progreso económico después de 1995. La política interna de Uzbekistán sobre derechos humanos y libertades individuales es a menudo criticada por organizaciones internacionales.

Antes de la llegada gradual de invasores turcos el área estuvo poblada por elementos escitas y gentes de habla persa y de estirpe iraní, que aún comprenden una minoría grande en Uzbekistán y son llamados hoy en día tayikos. Durante la Edad Media la actual Uzbekistán formó parte del poderoso Imperio corasmio. Desde la Edad Moderna, los emiratos en que se dividía el país (Bujará, Samarcanda y otros) fueron estados tapón entre las aspiraciones persas y chinas, y posteriormente rusas.

En el siglo XIX, el Imperio ruso comenzó a expandirse y a repartirse el Asia Central. El periodo del “Gran Juego” es generalmente considerado como continuo aproximadamente desde 1813 hasta la convención Anglo-Rusa de 1907. Seguida de la revolución bolchevique de 1917, siguió una segunda fase menos intensiva. A comienzos del siglo XIX, había unas 2000 millas que separaban a la India británica y las regiones remotas de la Rusia zarista. Gran parte de la tierra no aparecía en los mapas.

A principios del siglo XX, Asia Central estaba firmemente en las manos de Rusia y a pesar de alguna resistencia a los bolcheviques, Uzbekistán y el resto de Asia Central se hicieron parte de la Unión Soviética.

El 1 de septiembre de 1991, Uzbekistán declaró la independencia sin mayor convencimiento. Mientras las repúblicas bálticas llevaban la lucha por la independencia, los estados del Asia Central tenían miedo de ella. «Las fuerzas centrífugas que rompieron la Unión fueron las más débiles en Asia Central. Después del intento de golpe de estado de agosto de 1991, todos los líderes de Asia Central creyeron que la Unión podría ser preservada de alguna manera», escribió Michael McFaul en "Russia's Unfinished Revolution".

Constitucionalmente, el gobierno de Uzbekistán establece la separación de poderes, la libertad de expresión y la democracia representativa. En realidad, el ejecutivo ejerce casi todo el poder . El poder judicial no destaca por su independencia y el parlamento (Oliy Majlis), que se reúne solamente unos cuantos días al año, tiene poco poder para dar forma a las leyes .

El presidente escoge y reemplaza a los gobernadores provinciales. Islom Karimov, el ex primer secretario del Comité Central del Partido Comunista de la República Socialista Soviética de Uzbekistán, fue elegido para un mandato presidencial de 5 años en diciembre de 1991 con 88 % de los votos. En un referéndum de diciembre de 1995, su mandato se extendió hasta 2000. El presidente Karimov fue reelegido en enero de 2000 con 91,9 % de los votos. En un referéndum de enero de 2002, el término de la presidencia se amplió de cinco años a siete. El presidente Karimov fue reelegido en diciembre de 2007 con el 88,1 % de los votos.

La Organización para la Seguridad y la Cooperación en Europa (OSCE) no desplegó una misión de observación electoral en las elecciones parlamentarias de diciembre de 2009 debido a la preocupación de que las elecciones no ofrecían una posibilidad real de elección entre alternativas políticas. Se envió una misión de evaluación electoral más pequeña, que tomó nota de algunas mejoras en la forma en que las elecciones se llevaron a cabo.

Uzbekistán ha luchado contra una insurgencia de baja intensidad desde finales de 1990. A principios de esta década, el Movimiento Islámico de Uzbekistán (IMU) puso en marcha una serie de pequeñas incursiones, transfronteriza. El IMU se alió en el verano de 2001 con el gobierno talibán en Afganistán, donde estaba la base de la mayoría de sus tropas y, posteriormente, participaron de las fuerzas de EE. UU. en Afganistán. Desde la caída del gobierno talibán en 2001, la IMU parece haberse vuelto menos activa en Uzbekistán.

Atentados terroristas, atribuidos a los grupos de IMU y astilla, se han producido esporádicamente, incluyendo ataques múltiples y simultáneos en Taskent en 1999 que destruyó una parte de la sede del Ministerio del Interior y estuvo a punto de matar al presidente Karimov. Las estimaciones de muertos en los ataques y tiroteos posteriores en Taskent con presuntos terroristas llegó a 200. La cifra oficial de muertos del gobierno fue de 16. En marzo y abril de 2004, bombarderos suicidas atacaron EE. UU. y las embajadas de Israel en Taskent y también detonaron artefactos en la ciudad de Bujará. En mayo de 2005, pistoleros armados en la ciudad de Andiján atacaron una comisaría, se apoderaron de armas y luego irrumpieron en una cárcel, liberando a los miembros de una organización local islámico acusado por el gobierno del extremismo. En los eventos posteriores, cuyos detalles no fueron aclarados, los atacantes se reunieron en la plaza principal de Andijan. Miles de residentes locales se congregaron en la plaza. Hubo disparos entre las fuerzas gubernamentales y los insurgentes, y murió un número grande pero indeterminado de personas. El Gobierno de Uzbekistán, que puso la cifra de muertos en 187, se negó escuchar los pedidos de Europa y EE. UU. de una investigación internacional independiente. Las estimaciones no oficiales de muertos fue de entre 700 y 800. Si bien la investigación internacional no tuvo lugar, el gobierno afirmó haber llevado a cabo investigaciones internas sobre los acontecimientos de mayo de 2005. Se discutieron las técnicas de investigación y los resultados con los diplomáticos y otros representantes internacionales en 2006, 2007 y 2008. En mayo de 2009, un atacante suicida en la ciudad de Andiján y un asalto a un puesto fronterizo cerca de la ciudad de Khanabad en la frontera entre Uzbekistán y Kirguistán llevó al Gobierno uzbeko a cerrar temporalmente su frontera con Kirguistán y a bloquear algunas zonas del Valle de Ferghana.
A mediados de junio de 2010, hasta 100.000 refugiados de la etnia uzbeka huyeron de Kirguistán a Uzbekistán tras los enfrentamientos étnicos en el sur de Kirguistán. El Gobierno de Uzbekistán trabajó en colaboración con organizaciones internacionales para proporcionar alimentos y albergue a los refugiados hasta que regresaron a finales de junio.

En el marco del referéndum de diciembre de 1995, el primer mandato de Karimov fue prorrogado. Otro referéndum nacional tuvo lugar el 27 de enero de 2002 para, de nuevo, prorrogar su mandato. El referéndum se aprobó y el mandato de Karimov fue extendido por una ley del Parlamento hasta diciembre de 2007.

La mayoría de observadores internacionales declinaron participar en el proceso y no reconocieron los resultados rechazándolos por no reunir los estándares básicos.

El referéndum de 2002 también incluía un plan para crear un Parlamento bicameral. La misión de observación limitada de la OSCE concluyó que las elecciones apenas alcanzaron los estándares internacionales para unas elecciones democráticas.

Varios partidos políticos han sido formados con la aprobación del Gobierno pero no han mostrado todavía interés por defender alternativas a la política del gobierno. Similarmente, aunque se han establecido múltiples medios de comunicación (radio, TV, prensa), éstos también se encuentran bajo el control del gobierno y raramente tratan temas políticos.

Se permitió a los partidos políticos independientes su creación, el reclutamiento, y la posibilidad de celebrar convenciones y conferencias de prensa, pero se les ha negado la posibilidad de registro bajo unos procedimientos de registro restrictivos.

El 28 de marzo y el 1 de abril de 2004 se perpetraron sendos atentados terroristas en Taskent y Bujará, sin esclarecerse quién cometió los ataques. Sin embargo, Uzbekistán es formalmente un aliado de Estados Unidos, teniendo bases militares de este país desde que EE. UU. invadió Afganistán, siendo la estabilidad de este país una de las preocupaciones principales en la región.

Uzbekistán fue miembro de la Organización del Tratado de Seguridad Colectiva (OTSC), y es miembro actualmente de la Organización de Cooperación de Shanghái (OCS), la Comunidad de Estados Independientes (CEI), las Naciones Unidas, el Consejo de Asociación Euro-Atlántica, la Asociación para la Paz de la OTAN, la Organización para la Seguridad y la Cooperación en Europa (OSCE), la Organización de la Conferencia Islámica (OCI) y la Organización de Cooperación Económica, compuesta por los cinco países de Asia Central: Azerbaiyán, Turquía, Irán, Afganistán y Pakistán. En 1999, Uzbekistán se sumó a la alianza GUAM (Georgia, Ucrania, Azerbaiyán y Moldavia), que se formó en 1997 (lo que lo convierte GUUAM), pero luego se retiró oficialmente en el 2005. Uzbekistán ha servido como anfitriona de las reuniones para la sede regional del mando Antiterrorista (RATS) de la Organización de Cooperación de Shanghái (OSC), cuyas reuniones fueron celebradas en la ciudad de Taskent. En 2006, Uzbekistán se anexiona a la Comunidad Económica Euroasiática (CEEA), integrada por Bielorrusia, Kazajistán, Kirguistán, Rusia y Tayikistán, pero posteriormente se retiró en el año 2008.

Uzbekistán participó en la fuerza de mantenimiento de la paz de la CEI en Tayikistán y en grupos organizados por Naciones Unidas para ayudar a resolver los conflictos entre Tayikistán y Afganistán, dos de los cuales lo vieron como una amenaza a su propia estabilidad. Uzbekistán es un partidario de los esfuerzos de los Estados Unidos en su lucha contra el terrorismo en todo el mundo y se unió a la coalición de lucha contra el terrorismo en Afganistán. En su territorio se sigue prestando apoyo a operaciones de la coalición antiterrorista que opera en Afganistán, al permitir el envío de mercancías no letales por ferrocarril a través de Afganistán y por la concesión de acceso a Alemania a una base aérea en el sur de Uzbekistán. Uzbekistán ha participado activamente en los esfuerzos regionales para combatir el terrorismo y el narcotráfico.

Los Estados Unidos reconocieron la independencia de Uzbekistán el 25 de diciembre de 1991, y abrió su embajada en Taskent en marzo de 1992. Desde entonces la política de Estados Unidos ha sido enfocada para apoyar el desarrollo de Uzbekistán como un país independiente, soberano, con instituciones democráticas arraigadas en el marco de un Estado de Derecho. Los Estados Unidos y Uzbekistán colaboraron estrechamente en los hechos siguientes a los ataques terroristas del 11 de septiembre de 2001, así como en el inicio de la guerra contra el movimiento Talibán en Afganistán.

Sin embargo, las relaciones se enfriaron después de que las demandas europeas y de Estados Unidos por una investigación internacional independiente sobre los actos de violencia por parte de tropas estatales en las protestas de Andijon de mayo de 2005 y sobre cómo el Gobierno de Uzbekistán las trató, al negar cualquier hecho de parte de sus estamentos del orden, y a pesar de lo observado por medios de prensa externos. Desde mediados de 2007, los Estados Unidos y Uzbekistán han comenzado a reconstruir la cooperación en cuestiones de interés mutuo, incluida la seguridad y las relaciones económicas, así como cuestiones de la sociedad política y civil. Uzbekistán cuenta con la mayor población de Asia Central y es importante para los intereses de EE. UU. para garantizar la estabilidad y la seguridad en la región.

A partir de dichos actos se han dejado las antes cordiales relaciones, limitando el acceso al paso fronterizo con Afganistán, y han hecho de esto un lazo para el actual serio distanciamiento entre ambas naciones, por lo que se ha tratado de limitar la influencia de Estados Unidos y otras organizaciones no gubernamentales extranjeras que trabajan en la sociedad civil haciendo exigencias sobre una serie de reformas políticas al gobierno, que según medios internacionales es autoritario, así como demanda mostrar los hecho reales del tratamiento a los derechos humanos en el interior del país, que según el reporte de periodistas extranjeros, hacen dudar de la legitimidad del gobierno en cumbre.

Uzbekistán cuenta con la mayor fuerza militar en la región de Asia Central, que tiene alrededor de 65 000 personas en servicio. Su estructura es heredada de las fuerzas armadas soviéticas. El gobierno ha aceptado las obligaciones de control de armas de la antigua Unión Soviética, se adhirieron al Tratado de No Proliferación (como un estado no nuclear), y ha apoyado un programa activo de los EE. UU. Agencia de Defensa de Reducción de Amenazas (DTRA) de desmilitarizar y limpieza de armamentos de la masa de instalaciones relacionadas con la destrucción-en el oeste de Uzbekistán (Nukus y Vozrozhdeniye Isla), así como para proteger contra la proliferación de materiales radiológicos través de sus fronteras. El Gobierno de Uzbekistán gasta alrededor de 2 % del PIB en el ejército (2005 est).

A partir de la década de 1990 hasta el año 2004, el gobierno de Uzbekistán recibió Financiamiento Militar Extranjero (FMF), Internacional de Educación y Entrenamiento Militar (IMET) y otros fondos de asistencia de seguridad. A partir de 2004, los nuevos FMF y la ayuda a Uzbekistán IMET se detuvo, y es que el gobierno estadounidense no pudo certificar que el Gobierno de Uzbekistán estaba haciendo progresos en el cumplimiento de sus compromisos, incluido el respeto de los derechos humanos y la reforma económica en el marco del Acuerdo Marco Estratégico US-Uzbekistán. Uzbekistán aprobó la petición de Comando Central de EE. UU. para el acceso a una base aérea militar de vital importancia en el sur de Uzbekistán tras el 11 de septiembre de 2001, pero pidió a los EE. UU. abandonarla en julio de 2005 por haber cesado las ayudas de Washington. Todas las fuerzas de EE. UU. habían salido de esa instalación en noviembre de 2005.

En Uzbekistán no existe una oposición política significativa. Cinco partidos políticos progubernamentales tienen todos los asientos en el parlamento y los partidos políticos independientes han sido efectivamente suprimidos desde principios de 1990. Existen múltiples medios de comunicación independientes y gubernamentales (radio, televisión, prensa) pero la autocensura es la norma. Los editores y periodistas que han abordado temas políticamente sensibles han experimentado habitualmente repercusiones, incluyendo la pérdida de empleo.

Desde 1991, muchos destacados opositores al gobierno han huido y otros han sido detenidos. El gobierno reprime severamente a los sospechosos de extremismo islámico, incluyendo a los sospechosos de afiliación a organizaciones tales como el proscrito Partido de los extremistas de Liberación Islámica (Hizb ut-Tahrir) o la más moderada Nurchilar (seguidores de Said Nursi de Turquía). Miles de extremistas sospechosos han sido encarcelados desde 1992. El número exacto que queda en custodia es desconocido, pero pueden ser varios miles. Un gran número de prisioneros ha muerto bajo custodia por enfermedades, condiciones de pobreza, malos tratos y abuso. Los presos políticos y extremistas sospechosos, al parecer, son tratados peor que los presos comunes.

La policía y los servicios de inteligencia han utilizado la tortura como técnica de investigación rutinaria. En mayo de 2003, tras la visita del Relator Especial de la ONU sobre la Tortura, el Gobierno de Uzbekistán elaboró un plan de acción para aplicar las recomendaciones del Relator. El gobierno comenzó a adoptar una serie de disposiciones del plan y desde entonces ha reiniciado la cooperación con las organizaciones internacionales que participan en la vigilancia de la cárcel. No obstante, y al tanto de las denuncias que se siguen dando, las condiciones de reclusión y la prevalencia de la tortura hoy en día son muy amplias. A pesar de ello, Uzbekistán abolió la pena de muerte en enero de 2008 y se convirtió en signatario de la Convención de la ONU sobre los Derechos de las Personas con Discapacidad en febrero de 2009.

Uzbekistán está dividido en 12 provincias ("vilotayi"), una ciudad ("shahri") y una república autónoma ("respublikasi"):

Uzbekistán cubre 447 400 km², una superficie similar a la que ocupan Marruecos o Suecia. Se extiende 1425 kilómetros de este a oeste y 930 de norte a sur. Limita con Kazajistán al norte, con Kirguistán al este, con Tayikistán al sureste, con Turkmenistán al suroeste y con Afganistán al sur.

El desierto de Kyzyl Kum, que también comprende a Kazajistán, ocupa gran parte de las planicies en el norte y centro de Uzbekistán. Al este de Kyzyl Kum, se encuentra el Valle de Ferganá, un área fértil donde se concentra la producción agrícola. Al este, sur y norte del valle de Fergana comienzan las cordilleras que separan a Asia Central de China. Al oeste del país se extiende la planicie Ustyurt, una región desértica habitada por grupos nómadas dedicados a la actividad pastoril. Los dos principales ríos del país son el Syr Darya y el Amu Daria, cuyo uso intensivo para irrigar los cultivos ha contribuido al encogimiento del mar de Aral.

Uzbekistán no posee costas oceánicas ni al mar de forma directa, pero tiene acceso a mares de interior (mar Aral).

Desde la independencia, el gobierno ha seguido una política de transición gradual hacia una economía de libre mercado, pero la mayoría de las grandes empresas siguen siendo de propiedad estatal o controladas. La economía se basa principalmente en la producción agrícola y la extracción de recursos naturales del subsuelo. Uzbekistán es un importante productor y exportador de algodón, pero el gas natural le ha reemplazado como la principal fuente de divisas. También es un importante exportador de oro, uranio y minerales estratégicos. El uranio es el más grande producto de exportación de Uzbekistán, su venta se hace principalmente a los Estados Unidos, y actualmente cursan procesos de reinstalación de la industria pesada y ligera, con la apretura de fábricas de alimentos procesados, productos de índole electrónica, y sobre todo en el sector de la industria del automóvil, que está dirigida principalmente a la exportación hacia el mercado ruso.

Es difícil estimar con precisión el crecimiento económico en Uzbekistán debido a las estadísticas oficiales, que son poco fiables. El crecimiento económico ha sido fuerte en los últimos años; según el gobierno central, pero la riqueza está estrictamente en manos de la élite gubernamental. Según el Banco Mundial, aproximadamente el 25 % de los uzbekos viven en o por debajo del umbral de pobreza.

El gobierno aplica una fuerte política de sustitución de importaciones para controlar el comercio exterior y evitar la salida de capitales. Varias reformas estructurales importantes que se necesitan, sobre todo en el ámbito de la mejora de las facilidades para la inversión, han hecho que para los inversores extranjeros el país sea poco atractivo, y la liberalización del sector agrícola se ha hecho de forma muy lenta.

Aunque el gobierno se ha comprometido en teoría a acatar las disposiciones del Fondo Monetario Internacional (según el VIII estudio emanado del FMI, en el artículo sobre la convertibilidad de la moneda para las operaciones de cuenta corriente), en la práctica las empresas pueden esperar meses o incluso hasta años para obtener divisas para su funcionamiento o compra de insumos extranjeros, afectando notablemente su desarrollo real.

Las duras condiciones sobre la existencia en restricciones legales de convertibilidad, la dificultad para convertir la moneda local de las cuentas bancarias a dólares o rublos, así como otras medidas del gobierno para controlar la actividad económica (por ejemplo: restricciones a la importación y exportación de bienes, cierres intermitentes de las fronteras) han limitado el crecimiento económico y llevado a las organizaciones internacionales de crédito a suspender o retirar sus créditos anteriormente aprobados.


El Fondo Monetario Internacional estima que la cifra de crecimiento del PIB en 2010 al 8 %. El FMI proyecta 2011 el crecimiento del PIB del 7 %. El desempleo y el subempleo son muy altos, pero es muy difícil obtener cifras fiables, ya que no creíbles encuestas recientes se ha hecho. Extraoficialmente, el desempleo se estima en torno a un 8 % y el subempleo de alrededor del 25 %. El subempleo en el sector agrícola es particularmente alto, lo cual es importante dado el hecho de que el 62 % de la población se dedica al sector agrícola. Muchos observadores creen que el crecimiento del empleo y el crecimiento de los salarios reales se ha estancado, debido, al prácticamente, nulo crecimiento de la producción.

La alfabetización en Uzbekistán es casi universal, y los trabajadores están en general bien educados y entrenados. El aumento de la corrupción del sistema educativo del país en los últimos años ha comenzado a erosionar la ventaja de Uzbekistán en términos de capital humano, los grados y títulos suelen ser comprados. Además, los estudiantes de primaria y secundaria en las provincias remotas tienen poco acceso a la educación básica. La mayoría de locales de capacitación técnica y de gestión no cumple con las normas internacionales de negocios, pero las empresas extranjeras que participan en el informe de producción contratan a los trabajadores localmente ya que aprenden rápidamente y trabajan con eficacia. Uzbekistán subvenciona los estudios para los estudiantes de la Universidad de Westminster – una de las pocas instituciones de educación de estilo occidental en Uzbekistán. Para el año escolar 2009-2010, Westminster admitió unos 685 estudiantes (incluyendo estudiantes graduados). El gobierno financió a 53 estudiantes, y la universidad un adicional de 20 becas. Los costes académicos por año académico en Westminster son de 4900 USD.

Con el cierre o la reducción de muchas empresas extranjeras, es relativamente fácil encontrar empleados calificados y bien entrenados, pero los salarios son muy bajos para los estándares occidentales. El gobierno ha implementado límites salariales en un intento de evitar que las empresas eludan las restricciones a la retirada de dinero en efectivo de los bancos. Algunas empresas han intentado en el pasado evadir estos límites a las retiradas inflando los salarios de los empleados, lo que permite a las empresas a retirar más dinero. Estos topes salariales previenen que muchas empresas extranjeras paguen a sus trabajadores tanto como les gustaría. Las regulaciones del mercado laboral en Uzbekistán son similares a los que se usaron en la Unión Soviética, con todos los derechos garantizados, pero obviando algunos derechos. El desempleo es un problema persistente, y un número significativo de personas siguen en busca de puestos de trabajo en Rusia, Kazajistán, Oriente Medio y el Sudeste Asiático. Los analistas de negocio estiman que un alto número de ciudadanos uzbekos trabajan en el extranjero. Las estimaciones van desde un mínimo de 3 millones a máximos de 5 millones de ciudadanos de Uzbekistán en edad de trabajar que lo hacen fuera de Uzbekistán, la mayoría en los países vecinos o Rusia. Uzbekistán firmó un acuerdo laboral con Rusia en 2007 para facilitar la migración temporal de trabajadores de Uzbekistán y la imposición de sus ingresos.


El desempeño macroeconómico ha sido fuerte en los últimos tres años y dio lugar a una balanza comercial positiva. El crecimiento real del PIB fue alto, y las reservas oficiales siguieron aumentando. La inflación se espera sea entre 9% -11% en 2010. Con el fin de combatir la inflación, el gobierno ha ejercido un estricto control de divisas, causando escasez periódica de dinero en efectivo. Como reacción al debilitamiento del dólar al euro, el gobierno se ha pasado recientemente al euro para su contabilidad y gestión financiera. En el sector de la hostelería ocurre lo mismo.

Las reservas oficiales brutas en el año 2009 se estiman en 12,2 mil millones dólares. En 2007, el Banco Mundial y las Naciones Unidas para el Desarrollo (PNUD) prestaron asistencia técnica para la reforma del Banco Central y Ministerio de Hacienda en las instituciones que la conducta de la política fiscal y monetaria orientada al mercado. Sin embargo, los datos económicos oficiales sobre Uzbekistán siguen siendo a menudo poco fiables y no siempre están disponible. La reforma del Banco es muy lenta e inhibe la capacidad de los ciudadanos o las empresas privadas para obtener crédito y otros servicios bancarios.

La agricultura y el sector agroindustrial contribuyen con alrededor del 18% al PIB de Uzbekistán. El algodón es el cultivo dominante de Uzbekistán, que representa aproximadamente el 11 % del PIB del país en 2009. Uzbekistán también produce importantes cantidades de seda, trigo, frutas y verduras. Casi toda la agricultura de riego implica pesados. En 2008, el presidente firmó un decreto sobre la ampliación de las explotaciones privadas, lo que ha llevado a la redistribución de la tierra de los pequeños agricultores en favor de las grandes explotaciones. Los agricultores y trabajadores agrícolas ganan salarios bajos, que el Estado rara vez paga sobre una base regular. En general, el gobierno controla el sector de la agricultura, dicta lo que crece en las granjas, y fija los precios de los productos básicos como el algodón y el trigo. La mayoría de las explotaciones que cultivan trigo y algodón es para satisfacer la orden estatal, y los agricultores se enfrentan a la pérdida de sus tierras arrendadas, si no cumplen con las cuotas estatales.

Los recursos naturales, los minerales y la minería son parte integral de la economía de Uzbekistán. El gas natural es la fuente de divisas más importante de Uzbekistán, estimada en alrededor del 50 % (2009). El oro es otra fuente importante de ingresos de divisas (alrededor de 7-10 % de las exportaciones totales). Uzbekistán es el séptimo productor más grande del mundo de oro, alrededor de 80 toneladas por año, y mantiene la cuarta reserva mayor del mundo. Produce aceite para el consumo interno y tiene importantes reservas de cobre, plomo, zinc, tungsteno y uranio.

Las exportaciones de Uzbekistán / política de importación se basa en la sustitución de importaciones. El régimen de comercio altamente regulado ha conducido a la disminución de importación y exportación desde 1996, aunque las importaciones se han reducido más que las exportaciones, ya que el gobierno apretó las importaciones para mantener las reservas de divisas. tarifas draconianas y cierres esporádicos frontera y cruzar "honorarios" disminuir las importaciones legales de productos de consumo y bienes de capital. socios tradicionales de Uzbekistán comerciales de la Comunidad de Estados Independientes (CEI), en particular Rusia, Ucrania y Kazajstán. socios fuera de la CEI han aumentado en importancia en los últimos años, con la Unión Europea, China, Corea del Sur, Alemania, Japón y Turquía es el más activo.

Uzbekistán es miembro del FMI, el Banco Mundial, el Banco Asiático de Desarrollo, el Banco Islámico de Desarrollo y el Banco Europeo de Reconstrucción y Desarrollo. Tiene la condición de observador en la Organización Mundial del Comercio (OMC) y ha declarado públicamente su intención de adherirse a la OMC. Es miembro de la Organización Mundial de la Propiedad Intelectual y es signatario de la Convención sobre Arreglo de Diferencias Relativas a Inversiones entre Estados y Nacionales de Otros Estados, la Convención de París sobre la Propiedad Industrial, el Arreglo de Madrid sobre Protección de Marcas y el Tratado de Cooperación de Patentes. En 2008, Uzbekistán se colocó de nuevo en el especial "301" Lista de Vigilancia de la falta de protección de derechos de propiedad intelectual.

Desde la independencia de Uzbekistán, las empresas de EE. UU. han invertido alrededor de EE. UU. $ 500 millones en Uzbekistán. En 2006 y 2007, algunos inversores extranjeros abandonaron Uzbekistán debido a la disminución de la confianza de los inversores, el acoso, y los problemas de convertibilidad de moneda. Sin embargo, en 2007, GM-DAT, una subsidiaria coreana de GM, entró en Uzbekistán, al firmar un acuerdo de joint venture con UzDaewoo para ensamblar los coches coreanos fabricados para la exportación y venta nacional, incluyendo Chevrolet. Esta planta en Asaka ahora produce muchas líneas de automóviles bajo la placa de identificación de Chevrolet para la exportación a Rusia, así como el mercado interno. General Motors también firmó un acuerdo para comenzar a producir motores de propulsión en Uzbekistán en una nueva planta en las afueras de Taskent. La planta se encuentra en la fase de construcción y se prevé que comenzará a operar a finales de 2010. Boeing también tiene una larga relación con la compañía aérea nacional de Uzbekistán Airways, Uzbekistán. Coca Cola, Baker Hughes, Nukem, Hewlett Packard, y otras empresas de EE. UU. a cabo operaciones a pequeña escala en Uzbekistán, así.

El comercio y la inversión. Las relaciones comerciales se rigen por un acuerdo comercial bilateral, que entró en vigor el 14 de enero 1994. Se prevé la ampliación de la nación más favorecida al comercio de estado-la mayoría entre los dos países. Los EE. UU., además, beneficiarse de la exención Uzbekistán desde muchos aranceles de importación de EE. UU. en el marco del Sistema Generalizado de Preferencias (SGP estado) el 17 de agosto de 1994. Un Tratado Bilateral de Inversiones fue firmado 16 de diciembre 1994, ha sido ratificado por Uzbekistán y recibió consejo y consentimiento del Senado de los EE. UU. en octubre de 2000. Sin embargo, el Tratado Bilateral de Inversión es improbable que entrará en vigor hasta que se embarca Uzbekistán sobre la reforma económica. El gobierno está tomando algunas medidas modestas para reducir las restricciones burocráticas en el incipiente sector privado.

Es el único país limítrofe con todos los otros estados de Asia Central. El crecimiento y el desarrollo de Uzbekistán siempre se ve afectado por cuestiones como la energía, el agua, el comercio y, en última instancia, la estabilidad política y social en la región.

EE. UU. ayuda al gobierno de Uzbekistán con aproximadamente 12 millones de dólares en 2010, tratando de mitigar la inestabilidad potencial, al tiempo de reforzar los mecanismos de protección social y sentar las bases para el crecimiento económico, mejorando las condiciones de vida de las personas dedicadas a la agricultura, la reducción de muertes por enfermedades infecciosas, mejorar la capacidad de respuesta de Uzbekistán frente a las amenazas de la delincuencia transnacional y a la seguridad, y ampliar las oportunidades para la cooperación al desarrollo entre los dos países. Además, la ayuda de EE. UU. se centra en estrategias para mitigar los posibles conflictos en torno a temas como el agua y la energía. Desde 1993, la Agencia de EE. UU. para el Desarrollo Internacional (USAID) ha proporcionado más de 330 000 000 USD en ayuda a Uzbekistán.

Uzbekistán es el país más poblado de Asia Central. Sus 29 millones de habitantes, concentradas en el sur y este del país, son casi la mitad de la población total de la región. Uzbekistán había sido una de las repúblicas más pobres de la Unión Soviética; gran parte de su población estuvo dedicada al cultivo del algodón en comunidades rurales pequeñas. La población continúa siendo fuertemente rural y dependiente del cultivo para su sustento. Los uzbecos son el grupo étnico dominante. Otros grupos étnicos incluyen a los rusos (5,5 %), tayikos (5 %), coreanos (4,7 %), kazajos (3 %), karakalpakos (2,5 %) y tártaros (1,5 %). El uzbeco es el idioma estatal oficial; no obstante, el ruso es la lengua oficial de facto para la comunicación interétnica, incluido gran parte de uso cotidiano en el comercio y gobierno.

Los uzbecos son el grupo étnico dominante. Otros grupos étnicos incluyen a los rusos (5,5 %), tayikos (5 %), coreanos (4,7 %), kazajos (3 %), karakalpacos (2,5 %) y tártaros (1,5 %).

La nación es 88 % musulmana sunita, 9 % cristiana ortodoxa oriental y el 3 % sigue otra religión según el censo del Departamento de Estado de los Estados Unidos de 2009.

El uzbeko es el idioma estatal oficial; no obstante, el ruso es la lengua oficial "de facto" para la comunicación interétnica, incluido gran parte de uso cotidiano en el comercio y gobierno. La constitución del país reconoce a su vez la oficialidad del karakalpako en la república de Karakalpakia

El sistema educacional ha alcanzado un 99,3 % de alfabetización, y la edad media de escolarización para hombres y mujeres es de 11 años. Sin embargo, debido a restricciones presupuestarias y a otros problemas de transición seguidos del colapso de la Unión Soviética, textos y otros materiales escolares, métodos de enseñanza, curricula, e instituciones educacionales están desfasadas, son inadecuadas y están escasamente cuidadas. Además, la proporción de personas en edad escolar ha ido cayendo. Aunque el gobierno está preocupado por estas cuestiones, el presupuesto sigue siendo ajustado. De igual modo en el ámbito de la salud, la esperanza de vida es larga, pero tras la desmembración de la Unión Soviética, los recursos de la salud han declinado, reduciendo la calidad, accesibilidad y eficiencia.

La música tradicional de Uzbekistán, constituida básicamente por el "maqam" y el "shash-maqam", tiene muchos rasgos similares con la música tradicional de su vecina Tayikistan, mezclándose así elementos de la música persa. Sherali J'oraev es uno de los maqamistas más conocidos y tradicionales del país.

En cuanto a la música "pop", el "rock and roll" y particularmente el "rap", Uzbekistán es el país que se lleva la mayor parte de la vida artística y musical del Asia Central.

Musicalmente, la presencia rusa en esta antigua república soviética ha sido bastante fuerte. La mayoría de los cantantes y grupos de este país hacen música con un sonido bastante occidentalizado y moderno musicalmente, cosa que solo ocurre en uno de sus países vecinos como es el caso de Kazajistán.

En el mes de octubre de los años impares se celebra el festival de música "Sharq Taronalari" (‘ritmos del este’ en uzbeko) en la ciudad de Samarcanda. Este reúne a los músicos más representativos del Asia Central, así como de países extrarregionales. El festival de 2005 contó con la presencia de Charles Aznavour (de origen armenio), entre otros.

Aún cuando la presencia de las multinacionales es escasa, dominan con diferencia las empresas discográficas nacionales y centroasiáticas, por ejemplo uno de los más poderosos y populares sellos discogradicos es Best uzbek music, que es el que más presencia tiene en el mundo musical uzbeko, siendo la más exitosa de este país. A esta discográfica están ligados grandes voces de la música uzbeka.


El autor nacido en Uzbekistán más conocido sea probablemente Avicena (980-1037). Nació en un pueblo cerca de Bujará. Fue autor de numerosas obras de diferentes temas, sobre todo de filosofía y medicina. Su contemporáneo, también nacido en tierras del actual Uzbekistán, Al-Biruni (973-1048), escribió obras sobre historia, astronomía, astrología, matemáticas y farmacología.

En 2001, el gobierno de Uzbekistán decretó la celebración del 2.700 aniversario del Avesta, el libro sagrado del Zoroastrismo. Aunque en la obra no se muestra el lugar concreto donde vivió el autor, numerosos investigadores lo sitúan en Corasmia, el actual Uzbekistán.

El poeta Pahlavan Mahmud (1247-1326) fue famoso por su fuerza hercúlea, además de por sus poemas. Tiene un mausoleo en Samarcanda.

Aunque nacido en Gerat, Afganistán, el poeta Ali-Shir Nava'i (1441-1501), eligió el idioma uzbeko antiguo para la mayor parte de sus obras, que firmaba únicamente como Navoi.

El poeta Zahiriddin Muhammad Babur (1483-1530) nació en Andiján. Fue el fundador del Imperio mogol. Escribió "Baburnama", que ya en el siglo XIX fue traducido al inglés y al francés.

El primer escritor en prosa uzbeka fue Abulghazi Bahadur (1603-1664), gobernante del kanato de Jiva, quien escribió dos obras históricas importantes, "Genealogía de los turcomanos" y "Genealogía de los turcos."

En el siglo XIX encontramos a Furqat (1859-1909), escritor, poeta y activista político, y Agakhi Mukhammad Riza (1809-1874), historiador y traductor.

En el siglo XX, destacan: Hamza Hakimzade Niyazi (1889 - 1929), poeta y dramaturgo, el poeta de la Unión Soviética en Uzbekistán y uno de los padres de la poesía uzbeka moderna; Agakhi Mukhammad Riza (1809-1874), historiador y traductor; Abdulla Kadiri (1894-1938), poeta, escritor y traductor, autor de novelas históricas; Hamid Alimjan (1909-1944), poeta y dramaturgo en la época soviética; Zulfia Isroilova (1915-1996), poetisa que firmaba sus obras como Zulfiya, y que con 17 años publicó "Las hojas de la vida", y Said Ahmad (1920-2007), entre otros.

Ya en el periodo de independencia de Uzbekistán, son autores destacables, entre otros: Shukur Holmirzaev (1940-2005), Utkir Hoshimov (1941-2013), Erkin Vohidov (1936), Abdulla Oripov (1941), Oydin Hojieva (1942), Muhammad Ali (1942), Tohir Malik (1946), Azim Suyun (1948), Erkin Azam (1950), Sharof Boshbekov (1951), Alishir Ibadinov (1953) y Muhammad Yusuf (1954-2001).

Un famoso deportista uzbeco fue Djamolidine Abdoujaparov (Taskent, 28 de febrero de 1964), apodado "El Califa", ciclista profesional entre los años 1990 y 1997, durante los cuales logró 54 victorias.
Antes de pasar al ciclismo profesional, "Abdou" obtuvo buenos resultados en las categorías inferiores, llegando a proclamarse campeón en ruta de la Unión Soviética. Fue 5º en la prueba de ruta de los Juegos Olímpicos de 1988.
Excelente esprínter, logró victorias de etapa en las tres Grandes Vueltas al obtener 7 victorias en la Vuelta a España, 1 en el Giro de Italia y 9 en el Tour de Francia. También consiguió la clasificación por puntos de la Vuelta (1992), del Giro (1994) y del Tour (1991, 1993 y 1994).
Era famoso por su agresivo estilo de esprintar, y por mover excesivamente su bicicleta, con lo que consiguió unos cuantos enemigos en el pelotón y más de una caída.
Otro uzbeco famoso es el dos veces Mejor Jugador de la AFC y capitán de su selección Server Djeparov. Djeparov es un mediapunta de gran habilidad

La Selección de fútbol de Uzbekistán es el equipo formado por jugadores de nacionalidad uzbeka que representa desde 1992 (anteriormente siendo parte de la Unión Soviética) a la Federación de Fútbol de Uzbekistán en las competiciones oficiales organizadas por la Confederación Asiática de Fútbol y la Federación Internacional de Asociaciones de Fútbol.

La selección de Uzbekistán es conocida como «Oq boʻrilar» (Lobos blancos). Ha logrado clasificarse a la Copa Asiática desde que forma parte de la Confederación Asiática de Fútbol






</doc>
<doc id="11418" url="https://es.wikipedia.org/wiki?curid=11418" title="LyX">
LyX

formula_1 (escrito LyX en texto plano) es un programa gráfico multiplataforma creado por Matthias Ettrich que permite la edición de texto usando LaTeX, por lo que «hereda» todas sus capacidades (notación científica, edición de ecuaciones, creación de índices, etcétera).

Se trata de un procesador de textos en el que el usuario no necesita pensar en el formato final de su trabajo, sino sólo en el contenido y su estructura (WYSIWYM) (Lo Que Ves Es Lo Que Quieres Decir, por sus siglas en Inglés), por lo que puede ser utilizado para editar documentos grandes (libros) o con formato riguroso (tesis, artículos para revistas científicas), con facilidad.

Matthias Ettrich empezó a desarrollar un programa shareware llamado Lyrix en 1995. Poco después, éste fue anunciado en USENET donde recibió un enorme grado de atención durante los siguientes años. Después del lanzamiento inicial, Lyrix fue renombrado a Lyx debido a un conflicto con el nombre de un software (un procesador de texto de Santa Cruz Operation). Fue liberado bajo la Licencia Pública General de GNU, lo cual abrió el proyecto a la comunidad de código abierto. El nombre LyX fue escogido a causa del sufijo '.lyx' que tenían los ficheros de Lyrix.

El historial de lanzamientos de las versiones principales de LyX es el siguiente:




</doc>
<doc id="11420" url="https://es.wikipedia.org/wiki?curid=11420" title="Área biogeográfica">
Área biogeográfica

El área de distribución de una especie, subespecie u otro taxón, es el espacio geográfico sobre el que se distribuye un ecosistema y todo su entorno. La especialidad que dentro de la biogeografía, se ocupa de las áreas concretas de los taxones se denomina corología.

En ecología y biogeografía el estudio de las características de las áreas es un capítulo importante. El área se liga, por ejemplo, con la demografía y con las posibilidades de supervivencia de los taxones. La fragmentación del área por la alteración debida al desarrollo económico, es uno de los temas mayores de la biología de la conservación.

La extensión es uno de los parámetros fundamentales, pero no el único. Una especie es cosmopolita o ubicuista cuando encuentra y ocupa hábitats apropiados en todos los continentes o en todos los océanos. En este sentido la especie humana es un ejemplo perfecto, como lo son sus acompañantes, la cucaracha, la mosca doméstica o el gorrión común.

En el extremo opuesto, una especie es endémica cuando se presenta en un área muy restringida. Un endemismo puede encontrase en el área donde se originó, como ocurre con muchas especies de islas y otros hábitats dispersos (por ejemplo montañas aisladas), en cuyo caso se puede decir que son neoendemismos. Un paleoendemismo es una especie cuya distribución restringida representa solo una pequeña parte de otra anterior más amplia, generalmente lejos del área en el que surgió evolutivamente. Se pueden decir en este caso que la especie ocupa un área relicta o relictual.

Un parámetro importante del área de una especie es su carácter continuo o discontinuo (en corología se utiliza el término «área disyunta»). La distribución de una especie evolutivamente nueva es naturalmente continua, pero los azares del cambio climático, las epidemias o la competencia ecológica pueden conducir a su fragmentación. Una vez escindida el área en varias separadas, la evolución puede conducir a destinos distintos a las poblaciones de cada zona, interpretándose que este es uno de los mecanismos más importantes implicados en la diferenciación de especies nuevas (especiación alopátrica).

Un tema biogeográfico relacionado, pero distinto, es el de la distribución de los biomas, conjuntos de especies y de comunidades que se extienden sobre un área que es homogénea climática e históricamente (en el sentido de la historia biológica, de la comunidad de origen). 
Una provincia, región o reino biogeográfico es una zona terrestre o marítima ocupada por un bioma característico (definido por los taxones y comunidades que lo forman).

Se utilizan los términos provincia faunística o región zoogeográfica cuando solo se refiere a la parte animal de la biota, es decir la fauna; de forma similar se dice reino floral o fitogeográfico cuando se refiere a la flora, la parte de la biota formada por las plantas.



</doc>
<doc id="11423" url="https://es.wikipedia.org/wiki?curid=11423" title="Nivel trófico">
Nivel trófico

Se denomina nivel trófico a cada uno de los conjuntos de especies, o de organismos, de un ecosistema que coinciden por la posición o turno que ocupan en el flujo de energía y nutrientes, es decir, a los que ocupan un lugar equivalente en la cadena alimenticia.

Los niveles tróficos se pueden caracterizar de esta manera:

En la utilización del concepto de nivel trófico aparecen algunas dificultades que obligan a precisar ciertos aspectos del concepto:



</doc>
<doc id="11424" url="https://es.wikipedia.org/wiki?curid=11424" title="Humanidad (desambiguación)">
Humanidad (desambiguación)

Humanidad, en antropología, puede referirse a:
Asimismo, en otros ámbitos, puede hacer referencia a:
Además, en música y cine, puede referirse a:


</doc>
<doc id="11427" url="https://es.wikipedia.org/wiki?curid=11427" title="Bucle local">
Bucle local

En telecomunicaciones; el bucle local, bucle de abonado o lazo local es el cableado que se extiende entre la central telefónica (o conmutador) y las dependencias del usuario.

La conexión del bucle local telefónico es típicamente un par trenzado de cobre que va desde la central telefónica al local o vivienda del usuario.
Las líneas telefónicas de bucle local individual están conectadas a la central local o a un concentrador remoto.

Las conexiones al bucle local pueden ser utilizadas para transportar información utilizando varias tecnologías, incluyendo:

El término "bucle local" se utiliza también como sinónimo de una conexión del "último kilómetro" al local del usuario, independientemente de la tecnología. De ahí la frase "bucle local inalámbrico", donde este último tramo no es un par físico sino un enlace vía radio.



</doc>
<doc id="11428" url="https://es.wikipedia.org/wiki?curid=11428" title="Demografía de Colombia">
Demografía de Colombia

La población de Colombia se concentra en las áreas andinas y en la costa del Atlántico, donde se aprecian los núcleos demográficos de la sabana de Bogotá, conformado por Bogotá y Soacha, del valle de Aburrá, que comprende a Medellín, Bello e Itagüí, del Valle del Cauca, compuesto por Cali y Palmira. Lo mismo que las ciudades de la Costa Atlántica, Cartagena, Barranquilla y Santa Marta. Al igual que los centros demográficos de Bucaramanga y Cúcuta en la zona de los Santanderes, el Eje cafetero, Huila y Tolima.

En cuanto a su demografía, Colombia se caracteriza por ser el tercer país más poblado en Latinoamérica después de Brasil y México. Ha experimentado un rápido crecimiento poblacional como muchos países de la región, con un leve descenso en las últimas décadas. Alrededor de 3 millones de colombianos viven fuera del país a causa del conflicto armado. Sin embargo, gracias a mejoras económicas desde la década de los 2000, en los centros urbanos han mejorado los estándares de vida.

Los primeros asentamientos en el actual territorio de Colombia corresponden a diferentes grupos indígenas americanos y datan de por lo menos a 12 mil años antes del presente. Desde los primeros asentamientos españoles en 1509 un importante grupo de europeos, principalmente españoles y franceses, llegó a colonizar y establecerse en el territorio de la actual Colombia. Las primeras exploraciones y asentamientos europeos estaban constituidos principalmente por hombres, lo cual favoreció el mestizaje. Más adelante y a partir del establecimiento de instituciones coloniales, se facilitaría y promovería la migración de familias enteras.

Con los Borbones en el poder en España se liberó en parte la migración hacia la América española, lo que permitió un mayor ingreso de vascos, catalanes, franceses, Alemanes y otros europeos no castellanos. Adicionalmente, los europeos introdujeron (mediante la migración forzosa) diferentes grupos étnicos del África los cuales constituyeron la mano de obra esclava para diversas actividades económicas (generalmente la explotación con fines comerciales, de la tierra y de las minas). Las islas de San Andrés y Providencia fueron controladas durante gran parte de la colonia por británicos y Holandeses y fueron pobladas por grupos étnicos africanos, hoy conocidos como afro-antillanos, que provenían de Jamaica y otras dependencias británicas, a estos se sumaron otros inmigrantes europeos y árabes.

Durante la época republicana, Colombia no tuvo los grandes índices de inmigración de otros países sudamericanos como Brasil, Argentina, Chile o Uruguay. Aun así, en Colombia migraron diferentes grupos provenientes de Alemania, Italia, Francia, Inglaterra, Rusia, Polonia y otros países europeos o de las Antillas. El grupo más numeroso fue, sin embargo, el de árabes (2.5 millones de descendientes aprox)(principalmente católicos) provenientes de Palestina y de los actuales Siria y Líbano, en ese entonces bajo el poder del Imperio otomano.

La mayor parte de estas migraciones se concentraron en la Región del Caribe colombiana, principalmente en Barranquilla como el principal puerto de entrada, aunque se estima que una cuarta parte de estas migraciones también se estableció en los departamentos de Antioquia y Santander.

El Censo general de población de 2005 se identificó como afrocolombiano el 10,6% de la población, como indígena el 3,4%, como mestizo 49% y como blanco 37%. 

El Censo nacional de 2005 registró 1,378,884 indígenas, el 3.4% de la población censada en el país, distribuidos entre más de 80 etnias, de las cuales las más numerosas son los Wayúu, Nasa, Zenú y Emberá quienes habitan en todos los departamentos, pero los de mayor población nativa son, en su orden, La Guajira, Cauca, Nariño, Córdoba, Sucre, Tolima. Y los de mayor porcentaje de población indígena son Vaupés (66%), Guainía (65%), Guajira (45%), Vichada (44%), Amazonas (43%), Cauca (22%) y Putumayo (18%).

El mismo Censo de 2005 registró 4,261,996 afrocolombianos que representan el 10,6% de la población total censada, siendo los departamentos con mayor porcentaje de población afrocolombiana, Chocó (83%), San Andrés y Providencia (57%), Bolívar (28%), Valle del Cauca y Cauca (22%). 

También fueron censados 4,832 Rom (gitanos), principalmente en Atlántico, Bolívar, Valle, Bogotá y los Santanderes.

La inmigración en Colombia en el transcurso del siglo XIX y XX no fue tan fuerte como en otros países del continente. Esta situación se debió a dos factores principales: primero a las políticas heredadas desde el tiempo de la Colonia Española con leyes que siempre desestimulaban el ingreso de extranjeros al territorio, primero del Virreinato de la Nueva Granada. El segundo factor es la inestabilidad social, política y económica del país luego de su independencia del Imperio español debido a constantes conflictos internos, guerras civiles, dictaduras y golpes de estado. Estos hechos hicieron que el atractivo del país no fuese de gran atención para grupos inmigrantes. Aun así entraron en el país grupos y comunidades provenientes de Europa y Oriente Medio que tuvieron un profundo impacto en el desarrollo económico, social y cultural en determinadas áreas del territorio nacional colombiano. Los inmigrantes entraron a través del puerto de Barranquilla, aumentando considerablemente la población de la ciudad y convirtiéndola en una de las ciudades más cosmopolitas, desarrolladas y urbanizadas de Colombia.

Entre los flujos migratorios más numerosos e importantes destaca la inmigración árabe, proveniente de países como Líbano y Siria, de diferentes religiones (principalmente cristianos), que se instalaron en las zonas del norte, como Maicao, donde se encuentra la comunidad musulmana más numerosa del país y la segunda mézquita más grande de América Latina. También llegaron a Colombia inmigrantes judíos, procedentes principalmente de Polonia, Lituania, Ucrania. Debe mencionarse también la inmigración europea, principalmente de españoles, seguidos de grupos alemanes, británicos, franceses, italianos y de otros países europeos; y finalmente, la poca inmigración de asiáticos. También se presentó (aunque cuantitativamente reducida) la llegada de inmigrantes políticos de otros países latinoamericanos en tiempos en que había dictaduras o represiones políticas en sus países, como Argentina, Uruguay, Brasil, Chile y países del Caribe.

La emigración de colombianos se ha derivado de la difícil situación económica, el deterioro de la calidad de vida y la intensificación del conflicto interno hacia finales del siglo XX, llevándolos a buscar una mejor calidad de vida o seguridad ante la persecución o el desempleo. Las autoridades colombianas afirman que este movimiento alcanzó su nivel más alto en el año 2000.

Los principales destinos de emigración en América son: Estados Unidos, que ha sido el principal receptor desde los años 1960, el país con mayor número de colombianos como residentes y donde los colombianos constituyen uno de los grupos de inmigrantes mayoritarios; Venezuela, que tuvo una recepción importante durante los años 1970 hasta que empezaron los problemas internos venezolanos , convirtiéndose Colombia en un receptor importante de personas procedentes de Venezuela. Además de Costa Rica, que gracias a la cercanía geográfica y la afinidad cultural los colombianos son rápidamente asimilados, representando en este momento la segunda comunidad inmigrante más grande en el país Centroamericano (donde casi el 10% del total de la población es inmigrante). En menor medida, los colombianos emigran a Ecuador, Panamá, Canadá, México, Brasil y Argentina.

En Europa, España tiene la comunidad colombiana más grande del continente y le siguen en importancia Alemania, Italia, Holanda y el Reino Unido. Los destinos preferidos de los emigrantes colombianos hoy día se concentran entre Norteamérica y Europa, siendo Australia una nuevo destino que cada vez despierta mayor interés en este grupo.

Población estimada en 1535 del actual territorio colombiano:


Crecimiento de la población colombiana en el siglo XIX:
Censos colombianos durante los siglos XX y XXI:

En mayo de 2011 Colombia cumplió con los 46.000.000 de habitantes según el reloj poblacional del DANE. Se cree que a mediados de siglo el país sufra un proceso de envejecimiento producto de la baja en la tasa de natalidad y el aumento en la esperanza de vida. En el siguiente cuadro se muestra el futuro aumento de la población en tercera edad.
El idioma oficial es el español o castellano. Dentro del español empleado en Colombia encontramos los diferentes acentos como el santandereano, antioqueño, el valluno, el rolo, el costeño, el pastuso, el opita, entre otras. 

También son oficiales en sus territorios las lenguas indígenas de Colombia, el Criollo Palenquero y el Sanandresano de los raizales de San Andrés y Providencia. Se hablan más de sesenta lenguas aborígenes, como Wayuunaiki, Nasa Yuwe, Emberá, Guambiano y Ticuna.

Aunque cerca del 74% de la población es católica (situación favorecida por el Concordato de 1973), la Constitución Política de 1991 establece la libertad e igualdad de cultos. Minorías son protestante (20%), agrupados en una multitud de congregaciones independientes.

Religiones:

Población: 43.593.035 (Julio de 2006 est.)
64,5% (hombres 13.689.384/mujeres 14.416.439)

Edad mediana:

Con la realización del Censo de población de 2005 se calculó una tasa de natalidad de 21,66% y una tasa de mortalidad de 5,95% dejando una tasa de crecimiento natural de 15,71% (1,1571). Sin embargo el país solo crecía 12,53% anualmente puesto que la tasa de migración era -3,18%. Para 2005 la tasa de fecundidad fue de 2,22 hijos por mujer y la esperanza de vida de 72,56 años.

El DANE proyectó que para 2010 la tasa de natalidad sería de 19,86% y la tasa de mortalidad sería de 5,82% dejando una tasa de crecimiento natural de 14,04% (1,1404), aunque el país crecería 1,178% anualmente porque la tasa de migración seria de -2,26%. Para el 2010 se calcula una tasa de fecundidad de 2,10 hijos por mujer y una esperanza de vida 74 años.




</doc>
<doc id="11429" url="https://es.wikipedia.org/wiki?curid=11429" title="Zambo">
Zambo

Zambo puede referirse a:



</doc>
<doc id="11430" url="https://es.wikipedia.org/wiki?curid=11430" title="Negro (desambiguación)">
Negro (desambiguación)

Negro/a hace referencia a varios artículos:














</doc>
<doc id="11431" url="https://es.wikipedia.org/wiki?curid=11431" title="Árabe">
Árabe

El término árabe puede designar:





</doc>
<doc id="11432" url="https://es.wikipedia.org/wiki?curid=11432" title="Idioma árabe">
Idioma árabe

El árabe, también llamado arábigo, arabía, o algarabía, ( "al-ʻarabīyah" o "ʻarabī", pronunciación: [alʕaraˈbijja] o [ˈʕarabiː]) es una macrolengua de la familia semítica, como el arameo, el hebreo, el acadio, el maltés y otras lenguas similares. Es el cuarto idioma más hablado en el mundo (número de hablantes nativos) y es oficial en veinte países y cooficial en al menos otros seis, y una de las seis lenguas oficiales de la Organización de Naciones Unidas. El árabe clásico es también la lengua litúrgica del islam.

La lengua árabe comprende tanto una variedad estándar que se observa en lectoescritura, en ocasiones formales y en medios masivos de comunicación ("fuṣḥà" o estándar moderno - اللغة العربية الفصحى , ampliamente basado en el árabe clásico pero no idéntico a él), como numerosos dialectos coloquiales, que a veces pueden ser incomprensibles entre sí debido a diferencias lexicales y fonológicas, mientras que mantienen mayor continuidad en el plano sintáctico. En general, las decenas de dialectos árabes se dividen en dos principales, mashrequíes (orientales) y magrebíes (occidentales). El más comprendido entre los árabes es el dialecto egipcio المصرية العامية, por ser el país árabe más poblado y también por su producción cinematográfica y su presencia mediática y artística en general. 

La denominación de esta lengua en el propio idioma árabe es "[al-luga] al-‘arabiyya" ("la [lengua] árabe"), aunque en algunos dialectos como el egipcio se denomina "‘arabī" (en género masculino).

La lengua árabe pertenece a la rama semítica meridional de la familia afroasiática. La literatura árabe comienza en el siglo VI d. C. y se puede dividir a grandes rasgos en los siguientes períodos:
Durante el período postclásico surgieron variedades de árabe coloquiales, algunas notoriamente diferentes del árabe clásico y del árabe estándar moderno, que son usadas como lenguas habladas, en programas de televisión regionales y otros contextos informales.

Siglos antes del surgimiento del Islam las tribus árabes ya habían emigrado hacia las regiones de Palestina, Siria y Mesopotamia; los árabes eran el grupo dominante entre los habitantes de Palmira, gobernada por largo tiempo por una dinastía de origen árabe, hasta que los romanos destruyeron ese reino en el 273 d. C. Entre el siglo I a.C. y el siglo III d. C., los nabateos establecieron un Estado que alcanzaba el Sinaí en el occidente, el Hiyaz en el oriente y desde Mada'in Salih en el sur, a Damasco en el norte, teniendo a Petra como su capital. Las tribus arabófonas de Palmira y los nabateos usaron el alfabeto arameo como sistema de escritura, pero la influencia del árabe está claramente atestiguada en inscripciones en las que se usan nombres propios y vocablos árabes.

El corpus de textos preislámicos, que cubre los siglos VI y VII d. C., fue recogido por los filólogos árabes de los siglos VIII y IX. pero el árabe clásico no era una lengua uniforme, pues los filólogos árabes hablan de un dialecto dividido entre la zona occidental del Hiyaz y la oriental de Tamim y otras tribus beduinas. Los fonemas glotales oclusivos preservados en los dialectos orientales habían sido reemplazados en los dialectos de Hiyaz por vocales o semivocales.

El Corán, el primer texto literario escrito en árabe clásico, está compuesto en un lenguaje muy idéntico al de la antigua poesía. Tras la difusión del Islam se convirtió en la lengua ritual de los musulmanes y también en la lengua de la enseñanza y la administración. El incremento de pueblos no árabes que participaban de las nuevas creencias por un lado y la voluntad de los musulmanes de proteger la pureza de la revelación por otro, condujo al establecimiento de normas gramaticales y a la institucionalización de la enseñanza de la lengua.

El desarrollo de normas gramaticales tuvo lugar en el siglo VIII, junto con un proceso de unificación y normalización de la lengua culta. Expresiones y formas propias de la poesía en los períodos pre-islámico e islámico temprano, así como del Corán, desaparecieron de la prosa durante la segunda mitad del siglo VIII. Tras la creación de un árabe clásico normativo por los gramáticos árabes, la lengua permaneció básicamente invariable en su morfología y estructura sintáctica, convirtiéndose en la lengua culta del mundo islámico.

En su forma normativa, el árabe clásico fue adoptado también, además de por las élites educadas musulmanas, por otras minorías religiosas, como judíos y cristianos. Sin embargo, la lengua vernácula desde el principio era muy diferente al árabe clásico, que se convirtió en una lengua de erudición y literaria incluso en las regiones arabófonas. Esta situación lingüística, en la que dos variantes diferentes de la misma lengua, una baja y otra alta, conviven es lo que se ha denominado diglosia. La cuestión de cuándo se produce esta diglosia en la comunidad arabófona es muy controvertida. El concepto tradicional árabe es que se desarrolló en el primer siglo de la era islámica, como resultado de las conquistas árabes, cuando los no árabes comenzaban a hablar árabe; otros en cambio llegan a la conclusión de que la diglosia es un fenómeno preislámico.

Durante muchos siglos la enseñanza del árabe estuvo bajo el dominio de los eruditos musulmanes, no teniendo mucho lugar los judíos y cristianos, que no compartían plenamente la educación filológica.

Como lengua literaria y erudita, el árabe clásico continúa hasta el día actual, pero en los siglos XIX y XX surgieron nuevas élites que influidas por el poder y la civilización occidental revitalizaron el árabe clásico y formaron una medio lingüístico denominado árabe moderno normativo, adaptado a las cuestiones de la vida moderna. A través de los medios de comunicación, el árabe moderno ha tenido amplia influencia sobre el público y es la lengua oficial en todos los países árabes, incluyendo Somalia e Israel. También es la segunda lengua por todo el mundo islámico, particularmente entre los representantes religiosos del Islam.

El árabe moderno difiere del árabe clásico sólo en vocabulario y características de estilo; su morfología y estructura sintáctica no han cambiado, pero hay innovaciones periféricas y en secciones que no están estrictamente reguladas por las autoridades clásicas. Añadido a esto hay diferencias regionales en el vocabulario, dependiendo de la influencia de los dialectos locales y de lenguas extranjeras, tales como el francés en el norte de África o el inglés en Egipto, Jordania y otros países.

El árabe coloquial es hablado como lengua materna por unos 150 millones de personas, siendo entendida también por varios millones que la usan como lengua coránica. 

En las regiones donde se habla la lengua árabe se da la peculiaridad de la diglosia. El término diglosia se refiere al hecho de que una misma lengua tiene dos variedades básicas que conviven una al lado de la otra, realizando cada una funciones diferentes. Probablemente este es un fenómeno lingüístico universal, aunque en árabe es un hecho que une a todo el mundo árabe. Salvo los hablantes de árabe chipriota, maltés y la mayor parte de las variedades de juba y chádico, esta característica es común a los demás hablantes de árabe y probablemente ya proviene del período pre-islámico.

La diglosia se aprecia en el hecho de usar árabe coloquial para la vida cotidiana y árabe moderno normativo en la escuela; generalmente el árabe moderno normativo se usa en textos escritos, sermones, tesis universitarias, discursos políticos, programas de noticias, mientras que el coloquial se usa con la familia y amigos, aunque también en algunos programas de radio y TV. El árabe moderno normativo es la marca de panarabismo, pues entre algunos dialectos del árabe hay un alto grado de ininteligibilidad, como entre el marroquí y el iraquí. En 2016 Gambia declaró al árabe como el nuevo idioma oficial reemplazando así al inglés.

El árabe es una de las lenguas del mundo con mayor número de hablantes, alrededor de 280 millones como primera lengua y 250 millones como segunda lengua. Representa el primer idioma oficial en Arabia Saudí, Argelia, Baréin, Egipto, Emiratos Árabes Unidos, Irak, Jordania, Kuwait, Líbano, Libia, Marruecos, Mauritania, Omán, Autoridad Palestina, Catar, Sáhara Occidental, Siria, Sudán, Túnez y Yemen. Se habla también en zonas de Chad, Comores, Eritrea, Irán, Malí, Níger, Senegal, Somalia, Turquía, Yibuti y otros países. Además, varios millones de musulmanes residentes en otros países poseen conocimientos de árabe, por razones básicamente religiosas (ya que el Corán está escrito en árabe). Desde 1974 es una de las lenguas oficiales de las Naciones Unidas.

 Lingüísticamente la principal diferencia entre las variantes de árabe es la que se da entre las variedades orientales y occidentales, cada uno con un cierto número de subdivisiones:


Se llama en general árabe dialectal a la multitud de variedades coloquiales locales del árabe. La lengua oficial y literaria es sólo una, pero las variedades habladas son muy distintas entre sí, de modo que la intercomprensión resulta difícil en muchos casos. Suele decirse que la diferencia entre dialectos árabes es la misma que hay entre lenguas romances, pero esto es una exageración.

La formación de los dialectos se debe a varios factores combinados tales como la exportación de las variedades dialectales existentes en Arabia antes de la expansión islámica, la influencia de los substratos, el aislamiento geográfico y cultural de algunas zonas y la influencia de las lenguas de la colonización. Las mayores diferencias se dan entre los dialectos orientales o mashrequíes y occidentales o magrebíes. 

En la actualidad el árabe estándar es comprendido generalmente y la mayoría de los árabes es capaz de hablarlo con mayor o menor corrección: es la lengua de la escritura, del Corán, de la enseñanza, de las instituciones y de los medios de comunicación. También es comprendido en general el árabe egipcio, dialecto oriental con algunos rasgos magrebíes, exportado a todo el mundo árabe a través de gran cantidad de películas, series de televisión y canciones. 

Ejemplo de frase en varios dialectos:

Las diferencias dialectales tienden a reducirse debido al impacto de los medios masivos de comunicación.

El maltés, hablado en Malta, es un dialecto árabe que se escribe con caracteres latinos y está ampliamente influido por el siciliano y el inglés.


El árabe ha dejado gran cantidad de préstamos en lenguas con las que ha estado en contacto, como el persa, el turco, el swahili o el español. En esta última lengua los arabismos proceden sobre todo del árabe andalusí, variedad hablada en la Península Ibérica desde el siglo VIII hasta el siglo XVI. Eran más abundantes en el léxico cotidiano en tiempos medievales.
Muchos han pasado al español con adición del artículo árabe ("al-" y sus variaciones "as-", "ar-", etc.):
Otros sin artículo:

Hay también numerosos topónimos. Algunos de ellos son adaptaciones árabes de topónimos preexistentes:

Es un idioma que pertenece a la sub-rama semítica occidental (formada en total por tres lenguas: hebreo, arameo y árabe) de la rama semítica del tronco camito-semítico. Es la lengua semítica más arcaica, esto es, más cercana al semítico primitivo de cuantas siguen vivas hoy en día. Es lengua literaria desde el siglo VI y lengua litúrgica de los musulmanes desde el siglo VII. 

La forma literaria se llama en árabe "al-luga al-fuṣḥà" ("la lengua más elocuente") e incluye el árabe antiguo de la poesía preislámica, el del Corán y la literatura clásica y el árabe estándar moderno, utilizado en la literatura contemporánea y los medios de comunicación. Las formas dialectales reciben el nombre genérico de "al-luga al-‘ammiyya" ("la lengua general"). Existen formas intermedias entre una y otra.

La lengua árabe se encuentra muy emparentada con otras lenguas semíticas, especialmente con el hebreo. Este parentesco se percibe tanto en lo morfosintáctico, como en lo semántico. Incluso, algunas teorías afirman que un estadio primitivo de esta lengua fue la base para la formación del hebreo antiguo:

El árabe utiliza un sistema de escritura propio que se escribe de derecha a izquierda, uniendo las letras entre sí, de modo que cada letra puede tener hasta cuatro formas, según se escriba aislada, al principio, en medio o al final de la palabra.

Salvo contadísimas excepciones, a cada grafema corresponde un fonema, esto es, apenas existen letras mudas, letras omitidas, ni letras que en determinadas posiciones, o unidas a otras, tengan un valor distinto al que les corresponde en principio. Las excepciones se suelen deber a la tradición religiosa.

En los árabes hablados algunas letras tienen valores diferentes, según la región, al que tienen en árabe clásico. Por lo general, estas particularidades locales de pronunciación se mantienen cuando el hablante utiliza el árabe estándar.

En árabe no existen las letras mayúsculas. Hubo un intento de introducirlas en los años 20, pero no fue aceptado. Dado que los nombres propios árabes suelen tener significado, a veces, para evitar confusiones, se los encierra entre paréntesis o comillas.

El árabe ha incorporado (y adaptado en algunos casos) los signos de puntuación de las lenguas europeas: el punto, la coma (،), el punto y coma (؛), la interrogación (؟), etc. Los puntos suspensivos suelen ser dos y no tres.

El Árabe estándar moderno tiene tres vocales, con formas cortas y largas: /a/, /i/, /u/. Hay también dos diptongos: /aj/ y /aw/.

El inventario consonántico del árabe está formado por los siguientes fonemas:

Como en el resto de las lenguas semíticas, la morfología del árabe se basa en el principio de las raíces (جذر) y las formas o pesos (وزن). La raíz es la mayoría de las veces trilítera, esto es, formada por tres consonantes, y tiene un significado general. La forma es un paradigma de flexión de la raíz que frecuentemente contiene también en sí misma un significado. Por ejemplo, la unión de la forma verbal istaf‘ala (mandar hacer) con la raíz KTB (escribir) da el verbo "istaKTaBa" (dictar, o sea mandar que se escriba o hacer escribir); con JDM (servir) da "istaJDaMa" (utilizar, o sea hacer servir); con NZL (descender) da "istaNZaLa" (inspirarse, o sea "hacer descender" la inspiración). Otros ejemplos de paradigmas con la raíz كتب KTB:


Muchas veces es posible conjeturar el significado de una palabra desconocida uniendo los significados de su raíz y de su paradigma. Por ejemplo, la palabra 
"zāhir" combina una raíz de significado 'ver' con un paradigma de significado 'lo que', y esto nos permite conjeturar la palabra tiene el significado 'lo que se ve' o 'visible'. Esta palabra efectivamente tiene este significado. Pero además tiene otro, 'arrabales', que no podríamos haber deducido de esta manera.

La existencia de paradigmas fijos facilita la deducción de las vocales, es decir, inferir la vocalización de palabras leídas, pero todavía nunca oídas.

Por ejemplo, casi todas las palabras que tienen una forma escrita del tipo 12ā3 (los números corresponden a las consonantes radicales) se vocalizan 1i2ā3: kitāb, kifāh, himār, kibār, etc. Sin embargo, también hay excepciones: la palabra escrita "dhāb" ('ir') se lee "dahāb". Como resultado, quien haya aprendido esta palabra leyéndola en vez de, por ejemplo, oyéndola en una recitación coránica, la pronunciará, por analogía, "dihāb". Según los expertos nativos, que tienden a considerar el árabe como una lengua hablada, "dihāb" es mal árabe, y "dahāb" es la única forma correcta. Según los expertos occidentales, para quienes el árabe es una lengua escrita y los detalles de pronunciación son secundarios, el supuesto error está tan extendido que debe considerarse correcto, árabe estándar. 

El árabe clásico tiene más formas léxicas que los coloquiales. Con frecuencia muchos de los significados originales de las formas se han perdido, no así los de las raíces. Los diccionarios árabes organizan las palabras por raíces, y dentro de cada raíz las palabras derivadas por grado de complejidad. Ello supone la necesidad de conocer la raíz para buscar la palabra, lo que no siempre es fácil porque hay raíces irregulares.

El árabe tiene dos géneros: masculino y femenino. Generalmente son femeninas las palabras que "tienen forma de femenino", es decir, los singulares que acaban en ة, اء o ى (-ā<nowiki>'</nowiki>h, -a, -à, todas estas terminaciones suenan aproximadamente como la a española), y son masculinas las que no tienen esas terminaciones.

La mayoría de las excepciones a esta regla son femeninos sin terminación de femenino. Entre ellas:

Es muy infrecuente que una palabra con terminación de femenino sea masculina. Es el caso de los numerales tres a diez en masculino, y de la palabra خليفة "jalīfa" (califa o jalifa). 

El femenino singular de los seres animados casi siempre se forma añadiendo la terminación ة (-at) al masculino: كاتب "kātib" (escritor) > كاتبة "kātiba" (escritora); مستخدم "mustajdim" (usuario) > مستخدمة "mustajdima" (usuaria); صحراوي "ṣaḥarāwī" (saharaui) > صحراوية "ṣaḥarāwiyya", etc. 

Algunas palabras tienen ambos géneros, como قتيل "qatīl" (muerto /a)

En árabe hay tres números: singular, dual y plural.


En otros casos, a determinada forma de singular corresponde determinada forma de plural indefectiblemente. Por ejemplo:

A veces una palabra tiene varios plurales posibles. El árabe estándar tiende a simplificar y fijar en este caso una sola forma de plural para palabras que en clásico podemos encontrar con varios plurales, según épocas y lugares. Pero a pesar de tal tendencia, es difícil saber cuál de las varias formas que listan los diccionarios es la estándar, pues es normalísimo que siga usándose más de una.

Las diferencias persisten también en los dialectos coloquiales:
Según los gramáticos, en palabras de varios plurales posibles, los plurales de formas a12u3, a12ā3, a12i3a, o 1i23a (los números son las letras radicales), o el plural regular masculino, deben usarse para conjuntos de tres a diez. Estas formas se llaman paucales, o plurales de pequeño número. En ninguna época se ha seguido esta regla a rajatabla, pero muchos siguen diciendo que "ṯalāṯatu ašhur" ("tres meses") es más correcto que "ṯalāṯatu šuhūr".

El árabe clásico tiene una declinación con tres casos (nominativo, acusativo y genitivo) y dos formas (determinado e indeterminado) para cada caso.

La declinación aparece generalmente como signo diacrítico colocado sobre la letra final. Como las vocales breves, no se escribe salvo en textos didácticos o cuando hay riesgo de confusión:
Como se puede ver, las letras que se escriben son siempre las mismas excepto en el caso del acusativo indeterminado, en el que el diacrítico va colocado sobre un "alif" (ا). Las terminaciones de plural y dual tienen, como hemos visto, su propia declinación que sí implica variación en las letras, y lo mismo ocurre con algunas formas verbales.

Al ser diacríticos, quien lea en voz alta un texto no vocalizado debe comprender el texto para saber qué caso pronunciar al final de cada palabra. Esto implica que la declinación realmente no aporta nada a la comprensión del texto; de hecho es redundante porque su función ya la realizan las preposiciones y la posición de las palabras dentro de la frase. Se trata de un arcaísmo utilizado en árabe ante todo por su valor estético, ya que a los oídos árabes suena más armónica una frase en la que se pronuncian todas las declinaciones porque éstas ligan unas palabras con otras. El árabe estándar suele omitir aquellas flexiones que no tienen reflejo en la escritura, entre ellas las vocales breves de final de palabra. La pronunciación de la declinación es habitual si se lee un texto, si se pronuncia un discurso o si se recita poesía, pero resulta inadecuada y pomposa en la conversación a menos que se le quiera dar cierta solemnidad o se produzca, por ejemplo, entre filólogos. 

El árabe dialectal omite todas las declinaciones: para las terminaciones de dual y plural usa únicamente la forma acusativo/genitivo.

Ejemplo: "los usuarios escriben largas páginas sentados frente al ordenador"

Pronunciación clásica: 
Pronunciación sin flexiones:
Ambas se escriben igual:

Pronunciación dialectalizante:
Escritura:

En su forma más clásica, el orden habitual de la frase es verbo + sujeto + complementos. Sin embargo, en las formas dialectales es más frecuente el orden sujeto + verbo, que también se utiliza con frecuencia en el árabe estándar moderno.
Cuando el verbo antecede a un sujeto plural, el verbo se mantiene en singular. No ocurre así si el verbo se sitúa tras el sujeto.

El adjetivo va siempre después del nombre. Si éste se refiere a personas, o si se refiere a cosas y es singular, el adjetivo concuerda con él en género y número (y caso, si se usa la declinación). Sin embargo, si el nombre es un plural de cosa o de seres vivos (excepto los humanos), el adjetivo concuerda con él en femenino singular. Es decir, diremos por ejemplo:
pero en plural diremos

Si el sustantivo está determinado por el artículo "al-", los adjetivos deben estarlo también. Así, "el mundo árabe" se dirá "al-‘āliam al-‘arabī", esto es, "el mundo el árabe".

Existe un tipo de adjetivo muy productivo llamado نسبي "nisbī" o de relación, que se forma añadiendo el sufijo ي "-ī" (masc.) o ية "-iyya" (fem.). Es uno de los pocos casos en árabe de formación de palabras mediante adición de sufijos y no por flexión interna. Ha dado en castellano el sufijo "-í" (masc. y fem.) en palabras como "ceutí", "alfonsí", "saudí", etc. El adjetivo de relación sirve para formar los gentilicios y es frecuente en apellidos y palabras que indican relación o pertenencia:
La terminación femenina en plural (يات "-iyyāt") sirve también para formar sustantivos:

En árabe existe un único artículo determinado, sin variación de género y número aunque sí de pronunciación. Se trata del artículo ال "al-", que se escribe unido a la palabra a la que determina, razón por la cual frecuentemente se transcribe en caracteres latinos separado de ésta con un guion y no con un espacio.

La "l" del artículo cambia su pronunciación por la de la primera letra de la palabra determinada cuando dicha letra es una de las llamadas "solares". Son solares la mitad de las letras del alfabeto: tāʾ, ṯāʾ, dāl, ḏāl, rāʾ, zāy, sīn, šīn, ṣād, ḍād, ṭāʾ, ẓāʾ, lām y nūn. El resto se llaman "lunares". De este modo, التون "al-tūn" (el atún) se pronuncia "at-tūn"; الزيت "al-zayt" (el aceite) se pronuncia "az-zayt", etc. En la transcripción latina se puede mantener la "l" del artículo o sustituirla por la letra "solarizada". 
El árabe dialectal a veces "solariza" otras letras.

Por otro lado, la "a" del artículo desaparece cuando la palabra anterior acaba en vocal (lo que ocurre con mucha frecuencia si se emplea la declinación):

En árabe no existe en principio en artículo indeterminado, ya que dicho valor lo da la declinación. El árabe dialectal con frecuencia usa el numeral واحد "wāḥid" (uno) seguido del artículo determinado:

Existen dos tipos de pronombres: los aislados y los sufijos. Estos últimos, sufijados a un sustantivo, indican posesión: بيتي "bayt-ī": "mi casa"; بيتها "baytu-hā": "su casa de ella", etc. Cuando se sufijan a un verbo, indican el complemento directo o indirecto: كتبتها "katabat-hā": "[ella] la escribió" (p. ej, una carta) o "[ella] le escribió" (a una mujer).

El orden en la frase verbal suele ser sujeto, verbo, complementos. Un orden más clásico pone el verbo antes del sujeto, y en ese caso va siempre en singular aunque el sujeto sea plural. 

Al igual que en español hablado, la voz pasiva no tiene sujeto agente: una frase como "El Quijote fue escrito por Cervantes" sería imposible en árabe clásico, que sólo podría expresar "El Quijote lo escribió Cervantes" (que es construcción perfectamente correcta en árabe clásico aunque su traducción española es considerada vulgar), o bien 'se escribió el "Quijote" (no se sabe por quién), o bien "Cervantes escribió el Quijote". Sin embargo, el árabe estándar, sobre todo el usado en la prensa, va incorporando, por imitación de las lenguas europeas, construcciones gramaticales ajenas a la lengua árabe, entre ellas la de la oración pasiva: "se escribió el Quijote por parte de Cervantes", y la perífrasis del tipo "tuvo lugar el escribimiento del Quijote por parte de Cervantes".

Como en otras lenguas, el verbo "ser" en presente no se utiliza. Para decir "soy árabe" diremos: أنا عربي "anā ‘arabī", esto es, "yo árabe". 

Pero eso normalmente no funciona cuando el predicado es determinado. Las palabras العالم العربي "al-‘ālam al-‘arabī" (literalmente: el mundo el árabe) sólo pueden significar "el mundo árabe". Si le quitamos el artículo al adjetivo, calcando la estructura del español, se obtiene العالم عربي "al-‘ālam ‘arabī" que significa necesariamente "el mundo es árabe", y jamás "el mundo árabe".

En ocasiones se usan los pronombres de tercera persona para marcar el lugar donde debería estar el verbo "ser", para dar un matiz de intensidad o evitar confusiones: العالم هو عربي "al-‘ālam huwa ‘arabī" ("el mundo él árabe"): "el mundo es efectivamente árabe" (lo mismo que "inna al-‘ālam ‘arabī"). Es mejor usar así los pronombres sólo cuando el predicado es determinado: "ana huwa l-mudarris" ("yo soy el profesor").

El verbo árabe posee dos aspectos, "pasado" y "presente", que, más que indicar "tiempo", corresponden a la acción acabada y a la acción en curso. El imperativo y el futuro son modificaciones del presente. No existe el infinitivo. En los diccionarios, los verbos se enuncian en la tercera persona del singular masculino del pasado. Así, el verbo "escribir" es en árabe el verbo "escribió" ("kataba"). El presente, a su vez, tiene tres modos: indicativo, subjuntivo y yusivo, que difieren mayormente en las vocales breves finales. En árabe dialectal los tres se funden en uno solo.

Existen diez paradigmas verbales diferentes: cada raíz puede formar hasta diez verbos distintos (ver el apartado "Raíces y formas"). Por ejemplo los verbos "naẓara" (miró) e "intaẓara" (esperó) derivan los dos de la misma raíz verbal nẓr, en los paradigmas "1a2a3a" e "i1ta2a3a".

Del verbo derivan el "maṣdar", nombre que designa la acción del verbo y se traduce frecuentemente como un infinitivo o un "nomen actionis", y los participios activo y pasivo. Ambos se utilizan con frecuencia en lugar del verbo. Por ejemplo, "estoy esperando el metro" puede decirse:

Hay diferencia de significado entre el primero ("me pongo a esperar", "voy a esperar")
y los dos últimos ("estoy esperando").

Con frecuencia el adverbio se forma añadiendo al sustantivo la terminación de acusativo indeterminado "-an" (que, recordemos, se refleja en la escritura a través de un "alif" final):

La lengua árabe ha incorporado numerosos préstamos a lo largo del tiempo, tanto el árabe clásico como el estándar o el dialectal. Los préstamos más antiguos, ya irreconocibles, proceden de otras lenguas semíticas como el arameo. En época medieval entraron en la lengua árabe numerosas palabras persas, griegas y más adelante turcas. Y en época moderna ha incorporado muchos vocablos de origen francés, inglés o italiano. Los préstamos son mucho más habituales en los dialectos que en el árabe literario y afectan también a la sintaxis. Son frecuentes las palabras de origen tamazight o bereber en el Magreb, turco otomano en Egipto, persa y kurdo en Irak. 

Ejemplos:

A veces los préstamos se integran dentro del sistema de raíces y formas, tomando de la palabra incorporada tres o cuatro radicales que servirán para crear nuevas palabras de acuerdo con las reglas habituales de la derivación árabe. Por ejemplo, de "faylasūf" (filósofo, de origen griego) se extrae la raíz cuadrilítera FLSF con la que se forman palabras como "falsafa" (filosofía), "mutafalsif" (el que se las da de filósofo). "Warša" y "kūbrī", de origen inglés y turco, respectivamente, tienen plurales derivados de las raíces WRŠ en el primer caso y KBRY en el segundo: "awrāš", "kabārī".

La lengua árabe tiene una amplísima producción literaria que abarca desde el siglo V hasta la actualidad. 

Las muestras importantes de literatura árabe más antiguas son unas composiciones de la Arabia preislámica llamadas "mu‘allaqat", «colgadas». Este nombre se atribuye tradicionalmente al hecho de que podrían haber sido escritas y colgadas de los muros de la Kaaba, entonces panteón de La Meca, por haber resultado vencedoras en alguna justa poética. Esto habría permitido su supervivencia, dado que en la época la literatura era de transmisión oral y por tanto cabe suponer que la mayor parte de su producción se perdiese. Las "mu‘allaqat" son largos poemas que responden a un esquema fijo que luego heredará, con variaciones, la poesía clásica de época islámica. La poesía preislámica ha quedado en la cultura árabe como modelo lingüístico y literario y como ejemplo de valores primigenios ligados a la vida en el desierto, como la caballerosidad.

El Corán y la extensión del islam marcan un hito en la historia de la literatura árabe. En primer lugar, supone el desarrollo definitivo de la escritura y la fijación de la lengua literaria, el árabe clásico. En segundo lugar, la literatura en lengua árabe deja de estar circunscrita a la península arábiga y pasa a desarrollarse por todas las tierras por las que se extiende el islam, en las que el árabe es lengua oficial y de prestigio (más tarde sustituida por el persa en algunas regiones de Asia). Se abre así el amplio campo de la literatura árabe clásica, con gran profusión de géneros y autores. 

Con la caída de Al-Ándalus y de las potencias árabes de Oriente (Bagdad, El Cairo), que serán sustituidas por el Imperio otomano, la literatura árabe entra en una etapa de decadencia, con una producción mucho menor y de escasa originalidad comparada con el esplendor de los siglos anteriores.

Entre mediados del siglo XIX y principios del XX, según las zonas, el mundo árabe, y con él su literatura, entran en el proceso de revivificación llamado Nahda (Renacimiento). La literatura árabe contemporánea se despega de los modelos clásicos e incorpora con profusión géneros como la novela o el relato breve y, en menor medida, el teatro. La poesía sigue siendo, como en época clásica, el género más cultivado. 

La eclosión del nacionalismo árabe a mediados del siglo XX y hasta los años 1970 sirvió de acicate al desarrollo literario. Por zonas, es Egipto el país que más escritores ha dado a la literatura árabe contemporánea (de allí era el premio Nobel Naguib Mahfuz), seguido de Líbano, Siria, los Territorios Palestinos o Irak.

Un aforismo célebre declaraba que «Egipto escribe, Líbano publica e Iraq lee». 



</doc>
<doc id="11433" url="https://es.wikipedia.org/wiki?curid=11433" title="Alfabeto árabe">
Alfabeto árabe

El alfabeto árabe, también conocido como «alifato» en español (de "alif", su primera letra), es la escritura usada en muchas lenguas de Asia y África, tales como el árabe, el persa y el urdu. Es el segundo alfabeto más extendido a nivel mundial, sólo detrás del alfabeto latino.

El alifato tiene características similares al alfabeto hebreo, en este sentido es un "abyad". Esto se refiere al hecho de que las vocales cortas no se transcriben en la mayoría de libros y publicaciones, sino que han de deducirse del contexto. Esta situación se ve aliviada con el hecho de que las lenguas semíticas ponen la mayor parte de su significado en consonantes y vocales largas, que sí son transcritas. Tiene 28 letras básicas, con algunas variantes y diversos signos auxiliares.

La escritura árabe actual data del siglo IV y recibe el nombre de nasji para diferenciarla de la primitiva escritura más redondeada llamada cúfica, de Kufa.

La escritura árabe es una escritura ligada y cursiva, más que una sucesión de caracteres individuales. Además de otras consecuencias, esto implica que la forma de la letra está influida por la posición que ocupa en la palabra. Se escribe de derecha a izquierda; no tiene mayúsculas y no se permite la división de la palabra a final de renglón; en cambio, es posible alargar los trazos de unión entre letras tanto como se quiera, a fin de que el texto quede alineado. Las consonantes dobles se indican con un tashdid, (un símbolo parecido a la 'w') sobre la letra en cuestión.

El Corán está escrito usando el alfabeto árabe. Además del árabe, hay varias lenguas que usan este mismo alfabeto, entre las cuales se incluyen el urdu y el persa; el turco se escribía con alifato hasta las reformas de Kemal Atatürk en la década de 1920. Éste fue reincorporado oficialmente por el gobierno turco en el año 2014, aunque solo para el ámbito religioso. Algunos musulmanes españoles de los siglos XIV a XVI escribieron obras, principalmente religiosas, en lengua romance con caracteres arábigos (lo que se conoce como literatura aljamiada).

La caligrafía árabe se considera un arte por derecho propio. Dado que el islam sunní prohíbe la representación de seres animados, la arquitectura islámica (mezquitas y palacios) suele usar versículos del Corán delicadamente escritos. Un ejemplo es el palacio de la Alhambra de Granada.

El SATTS ("Standard Arabic Technical Transliteration System" - Sistema de transliteración técnica del árabe estándar) es un estándar que usa el Ejército de los Estados Unidos para transcribir el alfabeto árabe con letras del alfabeto latino.

El alfabeto árabe puede remontarse al alfabeto nabateo usado para escribir el dialecto de los nabateos de las lenguas arameas.

Los fenicios crearon hace más de 3.000 años en la región de Canaán el alfabeto fenicio, que rápidamente se extendió y dio lugar a la mayoría de los sistemas de escritura que se usan hoy en el mundo.

Una rama de ese alfabeto evolucionó en el alfabeto griego, que a su vez evolucionó en el alfabeto latino, usado por la mayoría de los idiomas europeos. Otra rama dio lugar al alfabeto arameo, que a su vez evolucionó al alfabeto árabe.



El alfabeto de uso más común actualmente, llamado hijā'ī (هِجَائِي) o alifbā'ī (أَلِفْبَائِي), agrupa las letras por similitud gráfica. Muchos grafemas tienen un mismo trazo básico y se distinguen entre sí gracias a unos puntos situados encima o debajo del trazo. Estos puntos se incorporaron en la época de la expansión islámica: hasta entonces, la escritura se utilizaba poco y frecuentemente como una especie de taquigrafía de uso personal para elaborar registros, contratos, albaranes, etc. Las necesidades ligadas a la administración del nuevo Estado islámico, así como a la correcta transmisión del Corán hicieron necesario el perfeccionamiento del sistema de escritura. Las letras representan consonantes o vocales largas. En caso de necesidad pueden utilizarse unos signos diacríticos adicionales para representar las vocales breves. Dichos signos se usan sobre todo en textos didácticos y en escritos cuya correcta vocalización se considera especialmente importante, como el Corán. De hecho, se inventaron precisamente para asegurar la correcta transmisión del libro sagrado, sobre todo entre musulmanes no árabes.

En caso de que no se utilicen los diacríticos vocálicos, que es el caso en la mayoría de los textos, para una correcta lectura el lector debe conocer la palabra o bien deducir su vocalización por su morfología y por el contexto. Esta es una característica común a todas las escrituras alfabéticas semíticas. Ejemplos:



Las vocales largas pueden deducirse de la presencia de las semiconsonantes ي (Y) y و (W), que por lo general aparecen unidas a las vocales breves "i" y "u" para dar las correspondientes largas, y por el signo "álif" ( ا ), que generalmente representa la vocal "a" larga, aunque en inicio de palabra puede representar cualquier vocal.

Salvo contadísimas excepciones, a cada grafema corresponde un fonema, esto es, no existen letras mudas ni letras que en determinadas posiciones, o unidas a otras, tengan un valor distinto al que les corresponde en principio. 

En los dialectos árabes hablados, algunas letras tienen varios valores diferentes al que tienen en árabe clásico. Muchas veces, estas particularidades locales de pronunciación se mantienen cuando el hablante intenta utilizar el árabe estándar, por lo que se indican en el apartado de descripción de las letras. Pero conviene aclarar que el árabe estándar tiene una pronunciación estándar, que es la que se enseña en las escuelas y que se considera universalmente como "la mejor". Así pues, a pesar de que muchos egipcios pronunciarán [ʔalbek] en lugar de [qalbuk] cuando hablan en su casa, cualquier locutor árabe de televisión, ya sea egipcio o de otro país, pronunciará siempre la letra qaf como una oclusiva uvular.

En la escritura árabe las letras de la misma palabra se escriben siempre ligadas entre sí, salvo 6 letras que no pueden conectarse con la letra siguiente (aunque sí con la anterior), lo que obliga a dejar un pequeño espacio de separación; estas 6 letras que no conectan son: alif (ا), dal (د), dhal (ذ), ra' (ر), zay (ز) y wau (و).




En cualquier caso, la lectura exige cierto grado de comprensión del texto y de conocimiento de la gramática. Por esta razón, un reducido grupo de académicos propuso en los años 1920 adoptar el alfabeto latino, tal y como había hecho Turquía, argumentando que "otros pueblos leen para comprender; nosotros debemos comprender para poder leer". Este fue reincorporado oficialmente por el gobierno turco en el año 2014, pero solo para el ámbito confesional. La propuesta se desestimó, pero permaneció abierto el debate de hasta qué punto este sistema de escritura dificultaba la alfabetización. Hoy en día se tiende más a pensar que los problemas de alfabetización son ante todo económicos y políticos, ya que no parece presentar ninguna dificultad en Israel, que tiene un sistema de escritura similar, ni en países como China o Japón, siempre que se cuente con los medios y la voluntad política necesarios de cada individuo.

Hay tres tipos de numerales en la escritura árabe; por un lado están los numerales orientales, divididos en: árabes, que se usan en todo el "Máshrek", y persas, usados en la escritura árabe de Irán, Pakistán e India. Por otro lado están los llamados números arábigos, de uso común en la mayor parte del mundo, que se usan en los países del Magreb. Todos proceden de la India, en diferentes épocas.





</doc>
<doc id="11435" url="https://es.wikipedia.org/wiki?curid=11435" title="Afroamericano">
Afroamericano

Afroamericano es un término que comenzó a utilizarse en los Estados Unidos de América en la década de 1960, por la misma población con ascendencia africana derivada de la esclavitud con o sin mestizaje, para revindicar el orgullo de sus raíces africanas.

El término fue ampliado y comenzó a ser utilizado con igual propósito, para hacer referencia a las personas nacidas en el continente americano, que tienen antepasados africanos subsaharianos derivado de la esclavitud con o sin mestizaje; los afroamericanos son por tanto un grupo de afrodescendientes. La mayoría son descendientes de personas capturadas, esclavizadas y trasladadas desde el África subsahariana (la inmensa mayoría del golfo de Guinea) hasta América por los europeos para trabajar en sus colonias, fundamentalmente en las minas y plantaciones como esclavos, entre los siglos XVI y XIX (véase Comercio atlántico de esclavos). 

No debe confundirse con afroestadounidense que es la traducción literal del término inglés "African American" (‘estadounidense africano’). En inglés posee el sinónimo: "Black American" (‘estadounidense negro/a’).

En la actualidad, constituyen alrededor del 30% de la población del continente, con los porcentajes de mayor a menor en Haití (95%), Barbados (92,4%), Jamaica (92,1%), Bahamas (90,6%), Granada (89,4%) Islas Turcas y Caicos, (87,6%), Antigua y Barbuda (87,3%)), Dominica (86,6%), Santa Lucía (85,3%), República Dominicana (84% incluyendo mulatos), San Vicente y las Granadinas (66%), Trinidad y Tobago (57,2% incluyendo mezclas), Bermuda (53,8%), Panamá (50% incluyendo mulatos y zambos), Guyana (46,9%), Brasil (45,3% incluyendo mulatos), Cuba (35 % incluyendo mulatos), Colombia (24% incluyendo mulatos), Uruguay (15% incluyendo mulatos), Estados Unidos (13,6%), Perú (9,7% incluyendo mulatos y zambos), Nicaragua (9%), Costa Rica (7,8% incluyendo mulatos), Ecuador (7,2%), Honduras (5%), Venezuela (3.5%, 55.2% incluyendo morenos), Canadá (3,2%), México (1,2% incluyendo zambos), Bolivia (1%) y Guatemala (0,5% incluyendo garífunas).
Por su parte en los países de Chile, Paraguay, Argentina y El Salvador las poblaciones afrodescendientes o afromestizas son sumamente escasas y se calcula que no representan ni el 0,2% del total de sus respectivas poblaciones.

El término afroamericano se emplea fundamentalmente para referirse a las personas de piel negra con raíces africanas, nacidas en el continente americano. El término se originó por los propios afrodescendientes en los Estados Unidos y poco a poco se fue extendiendo por otros territorios de todo el continente americano.
Los hispanohablantes en Estados Unidos y otros países de habla inglesa aplican el término afroamericano exclusivamente a ciudadanos estadounidenses con ancestros africanos.

Después de Estados Unidos, fue Haití, país de población casi por completo afrodescendiente, la segunda colonia americana en lograr su independencia. Tras los procesos de independencia, muchos países americanos han estimulado la inmigración de europeos, reduciendo así la proporción de población negra y mulata en el conjunto del país: Brasil, Estados Unidos, República Dominicana, Colombia, Venezuela,etc.

En el sistema de castas impuesto por España en sus colonias de América, se denominó mulato al hijo de negro y blanco y zambo al de negro y amerindio, entre muchas otras denominaciones para otras mezclas étnicas.

En las colonias anglosajonas, estos términos no existen dando por definición al término exclusivo de negro o afroamericano, a todas aquellas personas con raíces africanas sin importar su mestizaje ni el color de su piel.

Del 21 al 25 de noviembre de 1995 se celebró el Congreso Continental de los Pueblos Negros de las Américas.

Los afroamericanos aún son objeto de discriminación en la mayor parte del continente. Según David de Ferranti, vicepresidente del Banco Mundial para la región de América Latina y el Caribe, los afroamericanos tienen una menor expectativa de vida, mayor mortalidad infantil, mayor frecuencia de enfermedades y más generalizadas, mayores tasas de analfabetismo y menores ingresos que sus conciudadanos. Así, en Estados Unidos, constituyen más del 40 % de los prisioneros en el corredor de la muerte. Las mujeres, que también son objeto de discriminación de género, sufren peores condiciones de vida.

Con respecto a las enfermedades, los afroamericanos sufren con más incidencia patologías propias del mundo occidental como son la cardiopatía isquémica o el cáncer, sobre todo el cáncer de próstata, que la población residente en África y que incluso los blancos americanos de todos los países.

Incluso en países como Brasil, con el 6,9 % de la población fenotípicamente "negro" y el 23,8 % de los fenotípicamente "mulato", tienden a la pobreza. Sin embargo, es importante señalar que en Brasil la categoría "pardo" se emplea para una persona "multirracial" o "mestiza", e incluye todos los mulatos, zambos y el resultado de su mestizaje con otros grupos (que no parezcan lo suficientemente subsaharianos o negros y no tengan suficiente apariencia de blanco), pero es independiente de la ascendencia africana, ya que parte de los brasileños blancos tienen al menos un antepasado africano reciente y/o un ancestro nativo americano, y entre los "pardos" también se incluye a los caboclos (descendientes de blancos y amerindios o mestizos. 

Según diversos estudios, la principal contribución genética de los brasileños es europea (siempre por encima del 65 %, y para otros americanos llega a ser del 77 %) y los "pardos" poseen un grado intermedio de ascendencia africana en comparación con la media de los brasileños blancos y los afrobrasileños (los primeros en su mayoría con algún rasgo detectable de color debido a sus antepasados y los segundos co rasgos muy mezclados) y presentan una mayor contribución amerindia en zonas como la cuenca del Amazonas y una mayor contribución africana en las zonas de esclavitud histórica, como el sudeste de Brasil y las ciudades costeras del noreste, aunque ambas están presentes en todas las regiones, y que los rasgos físicos en muchos casos no se correlacionan con la ascendencia detectable.

El 4 de noviembre de 2008 el primer presidente estadounidense afrodescendiente, Barack Obama, ganó las elecciones presidenciales con el 52 % de los votos, tras los resultados positivos en los estados que tradicionalmente habían votado por presidentes republicanos como Indiana y Virginia.




</doc>
<doc id="11436" url="https://es.wikipedia.org/wiki?curid=11436" title="Blanco">
Blanco

Blanco es un color acromático, de claridad máxima y oscuridad nula. Perceptualmente es la consecuencia de la fotorrecepción de una luz intensa constituida por todas las longitudes de onda del espectro visible, por tres longitudes de onda (larga, media y corta) o por dos longitudes de onda complementarias. Se asemeja al color de la nieve, aunque otras sustancias de máxima reflectancia, como la magnesia, el color yeso y la baritina (sulfato de bario), resultan ejemplos más específicos del blanco. La denominación de «blanco» incluye a las coloraciones similares al blanco estándar, denominadas blanquecinas o blancuzcas, que poseen una ligera sugerencia de saturación y matiz.

La palabra «blanco» proviene del latín vulgar "blancus", ‘blanco’; el cual se deriva del germánico "*blank", ‘brillante’; y este del protogermánico "*blangkaz", ‘brillar, deslumbrar’. La forma extendida de la raíz protoindoeuropea "*bhel–", ‘brillar, destellar, quemar’.

En idioma castellano, el término «blanco» comienza a usarse hacia el año 1140.

El lexema "leuco", del griego λευκός ("leucos" ), ‘blanco’ (y este de la raíz indoeuropea "*lewk–", ‘luz, brillo’), asocia a los términos que lo incluyen con el color blanco. Un ejemplo de esto es la palabra leucocito.

Un sinónimo de uso poético para "blanco" es albo, del latín "albus", ‘blanco’. El mismo origen tienen los lexemas "alba" y "albo", que se encuentran, por ejemplo, en las palabras albino y alborada. Otro sinónimo es cándido, del latín "candĭdus", ‘blanco, puro’, ‘sincero, honesto’.

En el sistema de síntesis sustractiva de color, donde los colores se crean mezclando pigmentos o tintes (pinturas, colorantes, tintas), la tríada de colores primarios más usual es cian, magenta y amarillo. En este sistema, el blanco no puede obtenerse por mezcla; para representarlo se utiliza pigmento blanco o se recurre a dejar sin colorear el soporte sobre el que se trabaja (papel, tela, etc.), si es que este es blanco.

En el sistema aditivo de síntesis de color, en el cual los colores se obtienen mezclando luz de color en lugar de pigmentos, los colores primarios son el rojo, el amarillo y el azul. Esto significa que cuando se trabaja con luz de color, basta con mezclar esos tres colores en diferentes proporciones para obtener todos los demás. Para crear el blanco, se mezclan los tres colores primarios en su máxima intensidad.

Este sistema aditivo de colores luz es el que utilizan los monitores y televisores para producir colores. En este sistema, un color se describe con valores numéricos para cada uno de sus componentes (rojo, verde y azul), indicando al rojo con «R», al verde con «G» y al azul con «B». En una escala de valores de 0 a 255, el blanco aditivo puro se expresa como R=255 (rojo al valor máximo), G=255 (verde al valor máximo) y B=255 (azul al valor máximo). "Véase RGB."

Desde la más remota antigüedad se ha buscado producir sustancias coloreadas para pintar o teñir que tuviesen buen color, poder de tinción y permanencia; que fuesen estables ante la luz, que secasen razonablemente rápido, que tuviesen la densidad necesaria y que pudiesen mezclarse sin problemas con otros colores. Debajo se describen algunos pigmentos blancos que se han destacado en la historia de la pintura.

Albayalde o blanco de plomo

Blanco anularia

Blanco de cinc

Blanco de titanio

Otros


El blanco no es un color heráldico. Cuando aparece en un blasón, generalmente representa al metal plata. Sin embargo, puede aparecer específicamente como blanco si la descripción de las armas requiere la representación de alguna figura blanca «al natural» (por ejemplo, una paloma blanca).

En vexilología, el color blanco deriva de la plata heráldica. En las banderas su uso es frecuente; la superficie blanca en algunas de ellas es considerable, y otras incluso emplean al blanco como color de fondo.

En los ejemplos bajo estas líneas: «Águila Blanca» ("Orzeł Biały" ) es el escudo nacional de Polonia; el fondo blanco de las banderas de Chipre y de Corea del Sur significa la paz; el amarillo y el blanco de la bandera de la Ciudad del Vaticano provienen de los metales heráldicos oro y plata.

"Véase colores políticos: blanco político".

"Véase colores litúrgicos".

La luz puede tomar también diferentes tonos de blanco dependiendo del momento del día. Por ejemplo, la luz de la puesta de sol es más bien rojiza. A esto se le denomina temperatura de color. En iluminación artificial se busca crear diferentes tipos de blancos para poder asemejarse a esa luz natural cambiante. Las temperaturas de color más generalizadas son:



</doc>
<doc id="11438" url="https://es.wikipedia.org/wiki?curid=11438" title="Chibcha">
Chibcha

El término chibcha (idioma muisca: "chib-cha[cum]" (‘báculo-varón’: ‘hombre del báculo’) y más exactamente "Chib" (Nuestra), "Cha" (Gente - Hombre). hace referencia a varios artículos:



</doc>
<doc id="11439" url="https://es.wikipedia.org/wiki?curid=11439" title="Río Magdalena">
Río Magdalena

El río Magdalena es una corriente de agua continua de Colombia que desemboca en el mar Caribe. Con una longitud de más de 1500 km, es navegable desde Honda hasta su desembocadura, y su principal afluente es el río Cauca. Su cuenca ocupa el 24 % del territorio continental del país. En ella están 11 departamentos de Colombia, los cuales son Magdalena, Atlántico, Bolívar, Cesar, Antioquia, Santander, Boyacá, Cundinamarca, Caldas, Tolima, y Huila; vive aquí el 80 % de la población colombiana y se produce el 85 % del PIB nacional. Es considerada la principal arteria fluvial del país pese a no ser el río más largo ni el más caudaloso, en lo que es superado por el Putumayo, el Caquetá, el Meta, el Guanía sin contar el Orinoco y el Amazonas, ríos con los que el país hace frontera. La primera ciudad capital que atraviesa es Neiva.

El río Magdalena, gracias a su posición geográfica que corta las poderosas ramas andinas del norte de Sudamérica, fue desde tiempos precolombinos ruta de incursión hacia el interior de lo que hoy es Colombia y seguramente hacia el sur de la misma como Ecuador. Las culturas caribes, por ejemplo, penetraron muy probablemente por el río, así como otras culturas influyentes venidas del norte y Mesoamérica.

De la misma manera, los conquistadores españoles que llegaron a lo que hoy es Colombia a principios del siglo XVI usaron el río para adentrarse al interior de un país agreste y de un relieve difícil. El descubrimiento por parte de los colonizadores se le atribuye a Rodrigo de Bastidas en el año 1501. En 1519, Jerónimo de Melo realizó la primera entrada por el río.

En tiempo de la Colonia española, el río no fue menos importante. Este fue la única vía por la que la capital colonial, Santa Fe de Bogotá, se comunicaba con el importante puerto de Cartagena de Indias y por ende con Europa.

Las luchas de independencia no descuidaron el río. Los ejércitos patriotas y reales navegaron por el río en la búsqueda del dominio absoluto y político de la Colonia que rompía sus yugos. En la obra "El general en su laberinto" del escritor colombiano Gabriel García Márquez se puede ver una excelente descripción de lo que significaba el río para el tiempo y sus gentes.

El advenimiento de los ferrocarriles, la construcción de carreteras que dominaron el difícil relieve andino y la aviación, hicieron que el río perdiera su dominio absoluto sobre el discurrir nacional en cuestiones de transporte e intercambio. Pero la época moderna no pudo hacer perder la importancia que tiene el río más grande de la geografía nacional.

El río Magdalena nace al Suroeste de Colombia, en la cordillera de los Andes, específicamente en el Eje Central del macizo colombiano, atraviesa el país por el occidente de Sur a Norte, en un recorrido de unos 1.540 km entre las cordilleras Oriental y Central de los Andes colombianos, conformando un valle que a su vez es un corredor vial y que llega al litoral del mar Caribe.

El Magdalena nace en la laguna de la Magdalena en el Páramo de las Papas, al sur del Parque Nacional Natural Puracé en el límite entre los departamentos del Cauca y el Huila.

Navegable unos 990 km, entre Honda (Tolima), pasando por Puerto Salgar, Barrancabermeja, Mompós y Magangué y culminando en Barranquilla, el río es la principal ruta fluvial de Colombia. Río arriba, luego de los rápidos de Honda, es navegable otros 240 km, aproximadamente hasta el municipio de Girardot lo que se conoce como el valle del Magdalena Medio.

En su desembocadura en el mar Caribe, conocida como Bocas de Ceniza a 7,5 km de Barranquilla se construyó una de las más grandes obras de ingeniería del país. La desembocadura fue modificada y extendida hacia el mar por medio de tajamares que permiten mantener un calado necesario para el ingreso de buques de gran tamaño. Esto debido a que el río deposita 500.000 m³ de sedimento por trimestre.

El río posee una cuenca de unos 250.000 km², la cual en su parte media (Magdalena Medio), es la gran reserva de hidrocarburos del país.

El afluente principal del Río Magdalena es el río Cauca, pero tiene innumerables afluentes a lo largo y ancho de su recorrido que aportan un buen caudal de aguas.

A la altura del El Banco, al sur del Magdalena, se desvía por lo que anteriormente era conocido como el Brazo de Loba, el cual es notorio en el aumento de su envergadura brindando así mayor longitud total, pasando por la ciudad de Magangué, aislando así a Santa Cruz de Mompox, cuya cauce original a la altura del último mencionado se ve notoriamente reducido.

Los comienzos del desarrollo industrial en Colombia a principios del siglo XX afectaron lógicamente el ambiente con problemas como la contaminación y la deforestación. De ello el río Magdalena es un termómetro preciso y sensible, ya que la temperatura y otros factores influyen en este tipo de estereotipos.

Las épocas de intensa lluvia en Colombia han traído como consecuencias el desbordamiento del río que reclama el espacio perdido y hace pagar los precios de deforestaciones sin medida. Aún no existen en Colombia proyectos de magnitud que velen radicalmente por la protección del medio ambiente y la preservación de los recursos naturales. La riqueza en fauna y flora, a lo largo de un río que recorre regiones tan diversas y distantes, es amplia e interesante, pero la contaminación y la deforestación han hecho perder muchas especies asociadas al río.

El río Magdalena fue la ruta para acceder a las zonas andinas del norte de Sudamérica: primero, en tiempos precolombinos para la incursión en la expansión de la nación Caribe, que penetró su hoya hidrográfica hacia el interior de Colombia; segundo, desde la conquista en 1501 cuando Rodrigo de Bastidas lo explora. Y tercero durante la Colonia, por ser la vía que conducía a Santa Fe y al Virreinato del Perú por Honda, Popayán y Quito. La navegación concesionada en 1823 durante el gobierno de Francisco de Paula Santander apenas se regularizó hacia la década de 1880 y se desarrolló en la década de 1920, con el advenimiento de los Cables y Ferrocarriles Cafeteros.

Pero en tiempos de la República, este camino además de sufrir los efectos de la competencia del FFCC del Istmo (1855) y del Canal de Panamá (1914), desde 1930 empezó a palidecer por el advenimiento del transporte carretero que, a pesar de dinamizar el mercado interno, facilitó los procesos de sedimentación con la expansión de la frontera agrícola unida a la cultura de la tala, la quema y el azadón. Y finalmente, desde 1970, el río se postra a los efectos sobre el suelo y el agua de la Revolución Verde en la agricultura, que exacerban los factores de erosión, declinando la navegación por los del monopolio del transporte carretero.

La más grande hidroeléctrica en el río Magdalena es Betania ubicada en el departamento de Huila, pero su primer puesto le es arrebatado por la nueva hidroeléctrica en construcción, El Quimbo, también en Huila.

El río, a lo largo de la historia, ha sido preponderante en el comercio y el intercambio de bienes: transporte, trueque, importaciones, exportaciones, pesca, aprovechamiento de las tierras aledañas al río y su natural fertilidad, hacen del río un patrón primordial en la economía nacional.

En la actualidad existen muchos embalses y represas sustentados por este río, los cuales sirven para producir y suministrar energía eléctrica, para el consumo doméstico e industrial y excedentes que se exportan, de donde se obtienen importantes ingresos para la Nación. Lastimosamente, estas hidroeléctricas no hacen parte del Estado en su totalidad ya que algunas fueron vendidas a empresarios y consorcios extranjeros o simplemente dieron permiso para la construcción, por lo tanto algunas son privadas y otras de economía mixta (Sector Privado y Entidades Estatales).

En este gran río colombiano, existen 290 especies de peces dulceacuícolas, de los cuales los más conocidos y comercializados son:



</doc>
<doc id="11442" url="https://es.wikipedia.org/wiki?curid=11442" title="Mar Caribe">
Mar Caribe

El Mar Caribe es un mar abierto en el océano Atlántico tropical, situado al este de América Central y al norte de América del Sur, cubriendo la superficie de la placa del Caribe. También es llamado mar de las Antillas por estar ubicado al sur y al oeste del arco antillano.

Limita al norte con las llamadas Antillas Mayores —Cuba, La Española (Haití y República Dominicana) y Puerto Rico (Estados Unidos)—, ubicadas al sur del Trópico de Cáncer, al este con las Antillas Menores (meridiano 60° O), al sur con Venezuela, Colombia y Panamá (paralelo 9° N), y al oeste con México, Belice y Guatemala (meridiano 88° O), y Honduras, Nicaragua y Costa Rica (meridiano 84° O).

El mar Caribe es uno de los mares salados más grandes del mundo y tiene un área de unos 2.763.800 km².El punto más profundo del mar es la fosa de las islas Caimán, ubicado entre Cuba y Jamaica a 7.686 m bajo el nivel del mar. El país con mayor extensión tanto costera como de aguas territoriales en el Caribe es Venezuela, con 4.208 km de costas que abarcan de este a oeste, pasando por islas y archipiélagos. La línea costera del Caribe tiene muchos golfos y bahías: la bahía de Samaná, la de las Águilas, el golfo de Venezuela, el de Morrosquillo, el de Darién, el de los Mosquitos y el de Honduras.

“El Caribe” es una región conformada por el mar Caribe, sus islas y las costas que rodean a este mar.

El mar Caribe se comunica con el océano Pacífico a través del canal de Panamá.

Se le denomina caribeño a los habitantes que nacieron o viven en zonas cercanas a este mar (algo diferente al gentilicio ).

Los primeros habitantes de las islas Antillas fueron los taínos, una tribu sedentaria con creencias religiosas de carácter politeísta y que destacaban por ser buenos agricultores, pescadores y alfareros; su lengua deriva de la de los arawak, familia de la que procedieron, migrando desde Sudamérica hace aproximadamente unos 3.000 años. En el momento del descubrimiento, los caribes, que se destacaban por sus habilidades como navegantes y guerreros, ocupaban predominantemente la región, provenientes de las márgenes del río Orinoco, y estaban en plena conquista de los territorios taínos. En sus primeras crónicas, los europeos también afirmaban que los caribes comían carne humana, idea que ha quedado registrada en la palabra "caníbal".
El mar Caribe era un cuerpo de agua desconocido para Europa y Asia hasta 1492, cuando Cristóbal Colón lo navegó por primera vez tratando de encontrar una ruta a la India. Después del descubrimiento de sus islas, el área fue rápidamente colonizada por la civilización occidental, convirtiéndose en lugar común para las rutas comerciales europeas y eventualmente atractivo para la piratería. Los Reyes Católicos permitieron en 1495 a todos sus súbditos tripular naves a las recién descubiertas Indias, lo que hizo que muchas embarcaciones se lanzaran al Atlántico sin la debida preparación, siendo presa fácil para los "lobos del mar". En las costas del Caribe, durante aquella época se desarrollaban algunas de las ferias comerciales más famosas, como la de Portobelo, que duraba 40 días, población en donde se producirían constantes ataques de piratas, por lo cual los españoles construyeron muy cerca de ella el Fuerte de San Lorenzo a finales del siglo XVI. Este mismo problema se dio en otros puertos del Caribe como Cartagena de Indias y La Habana, en donde se construyeron sendas defensas militares, trabajo para el cual fueron transportados numerosos grupos de esclavos africanos a la región.

Poco después de su descubrimiento y ocupación por parte de España, el mar llamó la atención de las coronas inglesa y francesa, que enviaron marinos experimentados a la conquista de territorios y tomaron exitosamente las islas de Martinica y Guadalupe, para Francia, y Antigua y Barbuda, Montserrat, Barbados y Jamaica, para Inglaterra, siendo estas las posesiones más importantes que perdió el Imperio español en el Caribe.
En 1625 se conformó en la isla de la Tortuga una base en donde corsarios y bucaneros de ambas nacionalidades se asociaron para atacar embarcaciones procedentes de las colonias españolas y desde allí partían expediciones para asediar a las ciudades costeras hasta finales del siglo XVII. Otra famosa base de piratas se estableció en el puerto jamaiquino de Port Royal en 1656, hasta su destrucción parcial por un terremoto ocurrido el 7 de junio de 1692. En la región fueron muy reconocidos y temidos algunos nombres de piratas como Morgan, El Olonés y Barbanegra, entre otros.
A partir del siglo XIX comienzan a independizarse los países colonizados, aunque actualmente algunas posesiones francesas, británicas, neerlandesas, y estadounidenses continúan bajo la administración europea. En sus aguas se encuentran 22 territorios insulares y 12 países, siendo Cuba el último país en independizarse de España en el año 1898. En ese mismo año, Puerto Rico fue tomado por los Estados Unidos como premio de guerra y sigue bajo dominio norteamericano hasta el presente.

En 1903, con la intervención de Estados Unidos, se separó Panamá de Colombia y se construyó el canal, que comunica el mar Caribe con el océano Pacífico. Fue inaugurado el 15 de agosto de 1914, pero fue administrado por Estados Unidos hasta el 31 de diciembre de 1999.

El 12 de diciembre de 2001, los jefes de Estado y de gobierno de los países miembros de la Asociación de Estados del Caribe, reunidos en la Isla de Margarita (Venezuela), adoptaron la Declaración de Margarita, «reconociendo el mar Caribe como patrimonio común de la región, y un activo invaluable al cual damos prioridad para su conservación», con el objetivo de la «consolidación de una identidad caribeña propia». Se han comprometido «a establecer la región del Gran Caribe como una Zona de Cooperación», que «consistirá inicialmente de acciones conjuntas en las áreas de prioridad de la AEC, es decir, Comercio, Turismo Sustentable, Transporte y Desastres Naturales».

El nombre "Caribe" se deriva de los "caribes", nombre utilizado para describir la etnia amerindia predominante en la región en la época del primer contacto con los europeos a finales del siglo XV. El navegante italiano Américo Vespucio afirmaba que el término "Charaibi" entre los indígenas significaba 'hombres sabios' y es posible que este fuese utilizado para describir a los europeos a su llegada a América. Después del descubrimiento de las Indias Occidentales por Cristóbal Colón, el término español de "Antillas" fue común para este lugar; derivado de él, el "mar de las Antillas" ha sido un nombre común para el mar Caribe en varios idiomas europeos. Durante las décadas siguientes al descubrimiento, el dominio español en este mar fue indiscutible y, por ende, la denominación de Antillas se mantuvo durante muchos años.

El mar Caribe es un mar situado a lo largo de la placa del Caribe. Se estima que tiene una edad entre 160 a 180 millones de años y se formó por una fractura horizontal que dividió al supercontinente llamado Pangea en la Era Mesozoica. La superficie del mar Caribe se divide en 5 cuencas oceánicas separadas por algunas cadenas montañosas submarinas. La presión que ejerce la placa Sudamericana al oriente del Caribe, hace que la región de las Antillas menores tenga una alta actividad volcánica, destacándose eventos como la erupción volcánica del monte Pelée en 1902, que fue la causante de .

El océano Atlántico entra en el Caribe a través del "paso de Anegada" entre las Antillas Menores y las islas Vírgenes, y el "paso de los Vientos" localizado entre Cuba y Haití, la cual es una importante ruta entre los Estados Unidos y el canal de Panamá. El canal de Yucatán comunica el mar Caribe con el golfo de México entre la península de Yucatán, en México y la isla de Cuba.

Los puntos más profundos se encuentran en la depresión de las Islas Caimán alcanzando 7.686 m. A pesar de esto, el mar Caribe es considerado un mar relativamente poco profundo en comparación con otros grandes cuerpos de agua.

El suelo submarino del mar Caribe tiene una sola fosa oceánica: la fosa de las Caimán, ya que la fosa de Puerto Rico, aunque se encuentra próxima, se halla en el costado opuesto de la isla homónima, en el océano Atlántico abierto; aun así, ambas ponen el área en un alto riesgo de terremotos. Los terremotos submarinos plantean la amenaza de generar tsunamis que podrían tener efectos devastadores en las islas. Los datos históricos científicos revelan que durante los últimos 500 años han ocurrido en el área doce terremotos con una magnitud superior a 7,5 en la escala de Richter.

La máxima autoridad internacional en materia de delimitación de mares, la Organización Hidrográfica Internacional («International Hydrographic Organization, IHO), considera el mar Caribe como un mar independiente. En su publicación de referencia mundial, «Limits of oceans and seas» ("Límites de océanos y mares", 3ª edición de 1953), le asigna el número de identificación 27 y lo define de la forma siguiente:

En promedio, la salinidad del mar Caribe es de 35 a 36 partes por mil y la temperatura superficial es de 28 °C, mientras que en el fondo del mar el agua alcanza una temperatura de 4 °C.

Las corrientes del Caribe transportan cantidades considerables de agua desde el océano Atlántico a través de los pasos orientales en las Antillas Menores hacia el noroeste para salir al golfo de México a través del canal de Yucatán. En promedio, entre un 15 y 20% del agua de la superficie que entra hacia el Caribe es proveniente de las aguas dulces de los estuarios de los ríos Orinoco y Amazonas, conducidas hacia el noroeste por la corriente Caribeña. Por otra parte, el agua descargada por el Orinoco durante los meses de lluvia genera grandes concentraciones de clorofila en la zona oriental del mar.

En el área comprendida entre el norte de Venezuela, Colombia y Nicaragua se presenta durante casi todo el año una corriente circular que gira en el sentido contrario a las manecillas del reloj. Esta corriente se genera por las fuertes precipitaciones en la región, las cuales también pueden reducir la temperatura y aumentar la salinidad y la densidad del agua, aportando algunos nutrientes al agua como nitrógeno, fósforo y otros utilizados por las plantas.

La vertiente hidrográfica del mar Caribe es una de las más extensas del mundo. El río más largo que desemboca en él es el Magdalena, que cruza a Colombia desde el Macizo Colombiano a lo largo de unos 1.540 km. El Magdalena a su vez recibe el caudal de otros ríos como el Cauca y Cesar.

Otros ríos que desembocan en el Caribe son: Unare, Tuy, Tocuyo, Catatumbo y Chama, en Venezuela; Ranchería, Sinú y Atrato, en Colombia; San San, Chagres (Canal de Panamá) y Changuinola, en Panamá; Grande, Prinzapolca y Huahua, en Nicaragua; San Juan, en la zona sureste de Nicaragua, que conecta el lago Cocibolca o lago de Nicaragua con el Caribe; Coco, en la frontera de Honduras y Nicaragua; Patuca, Sico, Aguán y Ulúa, en Honduras; Motagua y Dulce, en Guatemala; Belice, en Belice; Hondo, en México; Cauto, en Cuba; Yaque del Sur, Ozama, Nizao, Haina, Chavón y Macorís, en República Dominicana; Negro, en Jamaica; y Grande de Patillas, en Puerto Rico.

Los estuarios que se forman en la desembocadura de los ríos al mar crean ecosistemas y condiciones de vida especiales. Las condiciones ecológicas básicas en este medio son: una salinidad que fluctúa a lo largo del año, aporte de aguas dulces, cargadas con materia orgánica y nutrientes, los cuales contribuyen a la productividad biológica y también cargadas con sedimentos que enturbian el medio, e influencia permanente de aguas marinas costeras que en el Caribe son más claras y menos fértiles que las de cualquier estuario.

También se destaca el lago de Maracaibo, que se conecta al Caribe a través del golfo de Venezuela, es el lago más grande de Sudamérica con una superficie de 13.820 km² y uno de los más antiguos sobre la tierra.

El clima del Caribe está influido por las corrientes oceánicas del Golfo y de Humboldt. La ubicación tropical del mar ayuda a que el agua se mantenga a una temperatura alta moderada, en un rango entre 21 y 32,2 °C durante el año (70 y 90 °F).

El Caribe es el lugar de origen de algunos huracanes del hemisferio occidental. La temporada de huracanes del Caribe se presenta entre los meses de junio a diciembre, y con mayor fuerza entre agosto y septiembre. En promedio anualmente se producen cerca de 9 tormentas tropicales y 5 alcanzan la intensidad de huracán. De acuerdo con el Centro Nacional de Huracanes en el Caribe ocurrieron 385 huracanes entre 1494 y 1900. Las corrientes de aire que se desarrollan en la costa oeste de África hacen su recorrido a través del océano Atlántico, algunas de estas se convierten en tormentas tropicales e incluso pueden convertirse en huracanes del Atlántico, especialmente en áreas de baja presión del Caribe oriental.

Dentro de los récords históricos de los huracanes más devastadores se registran: el huracán San Calixto II entre el 10 y 16 de octubre de 1780 el cual pasó por las Antillas Menores, Puerto Rico, República Dominicana y posiblemente La Florida, dejando un saldo de entre 22.000 y 24.000 muertos, y el huracán Mitch que se originó en el Caribe colombiano y 
recorrió Centroamérica hasta la península de Yucatán y La Florida entre el 22 de octubre y el 5 de noviembre de 1998, dejando entre 11.000 y 18.000 muertos.

Los huracanes son un problema anual para las islas del Caribe debido a su naturaleza destructiva. Los arrecifes de coral también se encuentran en peligro de destrucción por los huracanes, ya que depositan en ellos gran cantidad de arena, barro, sedimentos y rocas.

La flora del mar Caribe presenta una gran biodiversidad. Se estima que el Caribe tiene 13.000 especies de plantas y que más de 6.500 de éstas son endémicas. Algunas de las plantas que se pueden encontrar son el aceituno que se ubica principalmente en República Dominicana, el caimito que se extiende por toda la región Caribe, el guayacán (flor nacional de Jamaica), la ceiba (árbol nacional de Puerto Rico y Guatemala) y la caoba (árbol nacional de República Dominicana).

Hacia el Sur, entre Panamá y Colombia, las costas del mar Caribe forman parte de uno de los ecosistemas más biodiversos del planeta, el Chocó biogeográfico.

La fauna del Caribe es característica de clima subtropical, principalmente influida por las corrientes marinas calientes, es endémica en un 42% de sus especies. Existen cerca de 450 especies de peces entre las que se pueden mencionar la barracuda, el mero, la morena y diversas familias de caracinos. También se contabilizan 600 especies de aves, 155 de ellas endémicas como las cortacubas (especie endémica y una de las más antiguas del Caribe); la mayoría de las especies de aves son migratorias como el canario del manglar y la garcita verde. De acuerdo con Bidlife International en el 2006 habían 29 especies de aves en peligro de extinción en Cuba y dos oficialmente extintas. Especies de aves como la amazona puertorriqueña, la yacutinga y la paloma sabanera se encuentran en peligro de extinción.

Existen 500 especies de reptiles en el Caribe, de las cuales el 94% son endémicas como la iguana verde y la iguana azul, endémica de la isla Gran Caimán (ambas en peligro de extinción), la iguana de Mona, endémica de la isla de Mona (Puerto Rico), la iguana rinoceronte propia de República Dominicana, y el cocodrilo americano extendido por las islas del Caribe, Centroamérica y el norte de Sudamérica (en peligro de extinción), así como diversas especies de tortugas marinas como la carey.

Existen 170 especies de anfibios endémicos en el Caribe y de acuerdo con el informe de la evaluación anfibia global, en el 2004 más del 80 % de los anfibios estaban amenazados en República Dominicana, Cuba y Jamaica, y el 92 % en Haití. Especies como el coquí dorado se encuentran en grave amenaza de extinción.

Se contabilizan 90 especies de mamíferos en el Caribe, dentro de los mamíferos nativos se pueden mencionar el delfín, el manatí, el almiquí (endémico de las Antillas) y diversas especies de murciélagos, y la ballena jorobada como especie migratoria. Otras especies como la foca monje del Caribe
se han extinguido durante los últimos siglos por la acción directa del hombre. En los últimos 1.500 años se extinguieron el 90% de los mamíferos de las Antillas.

En el Caribe se encuentra un 9% de los arrecifes de coral del planeta cubriendo cerca de 20.000 millas cuadras, muchas de ellas localizadas fuera de las islas del Caribe y la costa de Centroamérica. Entre ellos se destaca la Barrera del Arrecife de Belice, con una superficie de 96.300 ha, la cual fue declarada patrimonio de la humanidad en 1996, hace parte del Gran Arrecife Maya (también conocido como Sistema Arrecifal Mesoamericano), que con más de mil kilómetros de extensión es el segundo más grande del mundo, cubriendo las costas en el Caribe de México, Belice, Guatemala y Honduras. Actualmente las corrientes de agua caliente están poniendo en peligro los arrecifes de coral del Caribe. Los arrecifes de coral mantienen algunos de los más diversos hábitats en el mundo, pero son ecosistemas muy frágiles. Cuando las aguas tropicales superan los 30 °C en un largo período de tiempo, las zooxantelas mueren. Estas plantas proveen de alimento a los corales y le dan su color. El blanqueamiento resultante en los arrecifes de coral los mata y daña el ecosistema. Más de un 42% de las colonias de corales se han blanqueado completamente, mientras que un 95% están experimentando algún tipo de blanqueamiento.

El hábitat mantenido por los arrecifes es crítico para algunas actividades turísticas como la pesca y el buceo y provee unos ingresos económicos para las naciones del Caribe de $3.1-4.6 billones de dólares. La continua destrucción de los arrecifes puede deteriorar la economía de la región. En 1986 entró en vigencia el protocolo de la convención para la protección y el desarrollo del ambiente marino en la región Caribe, cuyo propósito es proteger la vida marina que está en peligro a través de la prohibición de actividades humanas que pueden incrementar su destrucción en diversas áreas. Actualmente este protocolo ha sido ratificado por 15 naciones. También se han formado algunas organizaciones para preservar la vida marina del Caribe, como la "Corporación para la conservación del Caribe" que busca estudiar y proteger a las tortugas marinas, y enseñarle a las personas acerca su cuidado.

En relación con lo anterior, cabe mencionar que el Instituto de Ciencias del Mar y Limnología de la Universidad Nacional Autónoma de México, llevó a cabo un estudio regional, financiado por el Departamento de Cooperación Técnica del Organismo Internacional de Energía Atómica, en el que participaron especialistas de 12 países latinoamericanos (de Colombia, Costa Rica, Cuba, Guatemala, Haití, Honduras, Jamaica, México, Nicaragua, Panamá, República Dominicana y Venezuela), cuyas conclusiones indican que metales pesados como el mercurio, arsénico y plomo, han sido identificados en la zona costera del mar Caribe. El análisis de metales e hidrocarburos tóxicos se basa en la indagación de sedimentos costeros que se han acumulado a menos de 50 metros de profundidad durante los últimos ciento cincuenta años. Los resultados del proyecto fueron presentados en Viena, dentro del foro "El agua importa", y la Conferencia General de 2011 de la citada organización multilateral.

Costas continentales:


















Las principales islas dependientes de otros países en el Caribe son:






La región Caribe ha experimentado un incremento significativo en la actividad humana desde su período de colonización. El mar es una de las áreas de producción de aceite más grandes del mundo, con aproximadamente 170 millones de toneladas anuales. En el Caribe venezolano se encuentran importantes yacimientos de petróleo y gas natural, los cuales reportan una producción de 3.081 millones de barriles diarios de petróleo (2005) y de 29,7 miles de millones de metros cúbicos de gas (2003). El área también genera una extensa industria pesquera en los países que la rodean, contabilizando medio millón de toneladas de pescados anuales. Asimismo, es gran productora de caña de azúcar con una producción anual cercana a las 30 millones de toneladas en 2005, lo cual representa aproximadamente un 2% de la producción mundial.

La actividad humana en el área también contabiliza un significativo incremento de la polución, las estimaciones de la Organización Panamericana de la Salud de 1993 informan que tan solo un 10% de los residuos de Centroamérica y las islas del Caribe son tratados adecuadamente.

El mar Caribe es una de las mecas del turismo internacional. La Organización del Turismo del Caribe estima que cerca de 12 millones de turistas visitan la región durante todo el año. El Caribe es uno de los principales destinos de los cruceros en el mundo. La Organización del Turismo del Caribe también estimó que entre 1991 y 1992 se recibieron 8 millones de turistas que viajaron en cruceros. Entre los sitios preferidos por los visitantes y turistas, se encuentran desde la isla de Puerto Rico, la República Dominicana, Cuba, Jamaica, Aruba, Barbados, las Islas Vírgenes, San Martín, Costa Rica, Trinidad o Margarita en Venezuela; hasta las ciudades de Cancún, Puerto Aventuras, Playa del Carmen y Cozumel, así como el parque eco-arqueológico Xcaret, en la Riviera Maya; Majahual, Xcalak y Río Huach en la ruta Costa Maya de México; o Cartagena de Indias, San Andrés y Providencia y Santa Marta en Colombia; Puerto La Cruz, Barcelona, Isla de Aves, Los Roques, Punto Fijo, Choroní, Tucacas y Barlovento en Venezuela; Bocas del Toro, Colón, Guna Yala y el Canal de Panamá en Panamá, por solo nombrar algunos de sus innumerables destinos.

El Caribe es el escenario de inspiración de diversas obras literarias y películas relacionadas con piratería y fantasía, género en donde se destacan autores como Daniel Defoe y Robert Louis Stevenson, entre otros. Entre las películas de ficción caracterizadas geográficamente en el Caribe se pueden mencionar la serie de películas Piratas del Caribe y algunas de James Bond. Una adaptación de la primera serie de películas se encuentra representada en un parque de Disneylandia. La vida y costumbres de los habitantes del Caribe también ha sido representada en obras literarias con autores como el novelista cubano Alejo Carpentier, el dominicano Juan Bosch, el santaluciano Derek Walcott y el colombiano Gabriel García Márquez, entre otros.

La región del Caribe es cuna de diversos ritmos musicales, como el reggae y el ska, procedentes de Jamaica, el merengue y la bachata de República Dominicana; el calipso de Trinidad y Tobago; el reggaeton comparte sus orígenes entre Panamá y Puerto Rico, el bolero, el son cubano y el son montuno originarios de Cuba; la cumbia, el porro y el vallenato de la costa del Caribe colombiana, entre otros.

Uno de los deportes más populares en el Caribe es el béisbol, del cual se realiza una competencia regional anual denominada la Serie del Caribe. También se destacan el críquet en las Antillas de habla inglesa y, más recientemente, el fútbol con todas sus asociaciones afiliadas a la Concacaf, a excepción de Colombia y Venezuela que se encuentran en la Conmebol. Por otra parte, el evento multideportivo regional que reúne a los representantes del Caribe son los Juegos Centroamericanos y del Caribe, que se celebran cada cuatro años desde 1926, siendo la competencia multideportiva regional más antigua vigente en la actualidad.

En el área del mar Caribe se hablan una gran variedad de idiomas debido a la diversidad de orígenes de su cultura, entre los más destacados se puede mencionar español (México, Cuba, República Dominicana, Puerto Rico y costas de Centro y Sudamérica — incluyendo archipiélagos de dichos países), inglés (Jamaica — patois), Islas Vírgenes, Bahamas, Antigua y Barbuda, Dominica, Granada, San Cristóbal y Nieves, San Vicente y las Granadinas, Santa Lucía, Trinidad y Tobago, Barbados, Islas Caimán, Anguila, Islas Turcas y Caicos, Montserrat), el criollo sanandresano en las islas de San Andrés y Providencia en Colombia, francés (Haití ("créole"), Guadalupe, Martinica, San Martín, San Bartolomé), neerlandés (Bonaire (papiamento), Curazao (papiamento), Saba, San Eustaquio, San Martín y Aruba).

La religión predominante es la cristiana católica (República Dominicana, Puerto Rico, Jamaica, Antigua y Barbuda, Santa Lucía, Islas Caimán, Dominica, Antillas holandesas, costas de Centro y Sudamérica), aunque en algunas islas se practica el protestantismo (Barbados), el hinduismo (una de las más representativas en Trinidad y Tobago), el anglicanismo (Montserrat, San Vicente y las Granadinas), y en otras se practica la santería (Cuba), el vudú (Haití) y el rastafarismo (una de las más representativas en Jamaica).





</doc>
<doc id="11444" url="https://es.wikipedia.org/wiki?curid=11444" title="Papiamento">
Papiamento

El papiamento es una lengua hablada en las islas de Curazao ("papiamentu"), ("papiamento") Bonaire ("papiamen") y en Aruba ("papiamento"), todas éstas cercanas a las costas de Venezuela, y actualmente parte del Reino de los Países Bajos.

Posee dos formas de escritura: la fonética, aplicada en Curazao y Bonaire, y la etimológica, basada en el idioma español, aplicada en Aruba. Papiamento (parlamento) proviene de "papia", evolución del español y portugués coloquial "papear", voz onomatopéyica que, según el diccionario de la RAE significa: "Balbucir, tartamudear, hablar sin sentido", que a su vez deriva de "papa", que dicho diccionario define como expresión coloquial de "tontería, vaciedad, paparrucha".

El papiamento es oficial en Aruba desde 2003 y en Bonaire y Curazao desde 2007. Tiene ortografía propia desde 1976. El texto más antiguo en papiamento es una carta del año 1775 de un judío de Curazao, indicando que el papiamento existía hace más de 200 o 500 años. Hay autores que piensan que, al menos la base lingüística, es más antigua. 
Hay diversas teorías sobre su origen. Lo que se puede definir es que el papiamento es un idioma que se desarrolló por sí mismo por el contacto entre los hablantes de diversos idiomas. Para comunicarse con otro se usaba este idioma como lengua general.
Se trata de una lengua criolla cuyo léxico probablemente procede del español principalmente, mezclada con palabras de origen portugués, la lengua indígena arahuaca y diversas lenguas africanas. El idioma estaría basado en un criollo africano-portugués que los esclavos llevaron de África, reforzado posteriormente con judíos sefardíes llegados de los enclaves holandeses del Brasil, y ha ido evolucionando con el tiempo debido a las colonizaciones y la posición geográfica de las islas, recibiendo una mayor influencia del idioma español en especial, por su proximidad con territorios de habla española como Venezuela y Colombia.

El papiamento no es una variedad de español ya que difiere significativamente en su gramática del español moderno, además incorpora una gran cantidad de léxico procedente del portugués y el inglés para los cuales el español moderno sigue conservando una forma patrimonial. Si bien su origen histórico se debe a hablantes en contactos con el español, parece haberse originado como un pidgin que se criollizó, de ahí que su gramática difiera de manera tan notable del español. Si su origen hubiera sido la evolución natural del español en las islas, sería una variedad equiparable a las demás del español de América (cuyas divergencias son debidas sólo al proceso de cambio lingüístico natural sin pasar por una fase de criollización).

Sin embargo el papiamento al menos en su forma escrita tiene cierto grado de inteligibilidad con el español. Esto es debido a que el papiamento tiene su propia estructura gramatical y difieren en sus construcciones, por lo que tiene una independencia lingüística respecto al español como la que tiene cualquier otro idioma. El papiamento tiene léxico de procedencia portuguesa y española, sin embargo no por eso es directamente inteligible para los hablantes de estas lenguas, si no se habituan a él. Su gramática es más similar a la de otros criollos afroportugueses, no existe en general la conjugación, solamente en participio pasado y suele recurrir es más analítico que las lenguas románicas (es decir, las ideas complejas se presentan mediante construcciones sintácticas más que por derivación o flexión morfológicas).

El Papiamento/u hablado en Aruba, Bonaire y Curazao presenta diferencias menores por lo que comúnmente se consideran dialectos o variedades de la misma lengua:

En 1634 ocuparon las islas los holandeses. La población era de 1415 indígenas y 32 españoles. En 1648 comenzó el flujo de esclavos negros que los portugueses llevaban de África y colonos holandeses del Brasil.

En 1795 la isla pasó a poder de los franceses, en 1800 fue protectorado inglés y en 1802 volvió de nuevo a Holanda. La lengua oficial impuesta fue el neerlandés, pero el papiamento es la lengua que usa la mayor parte de la población, configurada por esa oleada sucesiva de esclavos y colonos, limitando el neerlandés al lenguaje escrito y la comunicación con los colonos holandeses. Debido a los movimientos nacionalistas, poco a poco, el papiamento fue extendiéndose a la literatura así como periódicos, radio, revistas, y sitios web.

Como en la mayoría de las lenguas criollas, los verbos en papiamento carecen de flexión por lo que no se conjugan morfológicamente. Por consiguiente, tiempos, tonos, y relaciones de aspecto se expresan por el uso de partículas preverbales y otras construcciones analíticas. El orden de las palabras en la frase sigue el esquema Sujeto-Verbo-Objeto. Y contrariamente a sus principales lenguas dadoras –el español y el portugués– el papiamento hace uso común de los pronombres, y no realiza acuerdos de género.

El vocabulario del papiamento se deriva principalmente (por orden de importancia): del español, del portugués, del neerlandés, del inglés, del francés, y de las lenguas africanas. Un claro ejemplo es el de la tercera persona del pronombre plural, nan (probablemente de origen africano), igualmente utilizado como marcador del plural post nominal, ej. kas “casa” > kasnan “casas”. El papiamento se caracteriza también, tanto escrito como oral, por el uso de un discurso pasivo basado en el auxiliar (como es el caso en muchas lenguas habladas en Europa), lo que resulta de un fenómeno de descriollización a beneficio del neerlandés y del español.
Algunos ejemplos: yo viviré - "mi lo biba", 'lo' indica tiempo futuro, y se llama 'la partícula de tiempo'. Partícula de tiempo es parte de la oración y que expresa la acción del verbo, ejemplo para expresar 'tiempo presente' utilizas "ta" ("ta biba" - yo vivo), para expresar 'tiempo pasado' utilizas "a" (Pretérito Definido) y "tawata" (Préterito Imperfecto) ("a biba", "tawata biba" - yo viví, había vivido/vivía, etc). En participio pasado: la casa pintada - "e cas geverf".



Más palabras y frases simples:

Palabras para usar en las compras:

Más palabras y frases:

Nótese la dificultad de saber si una palabra o frase es de origen español, neerlandés o portugués.



</doc>
<doc id="11447" url="https://es.wikipedia.org/wiki?curid=11447" title="Antillas Menores">
Antillas Menores

Las Antillas Menores o Pequeñas Antillas es el grupo de islas en el mar Caribe formado por las Antillas de menor tamaño, que forman un arco insular al sudeste de las Antillas Mayores o Grandes Antillas, que va desde el este de Puerto Rico hasta la costa occidental de Venezuela.

Las islas son parte de un largo arco de islas volcánicas, la mayoría de los cuales se encuentra alrededor de la parte oriental del mar Caribe en el límite oeste con el océano Atlántico, y algunas de las cuales se encuentran en una franja sureste de ese mismo mar, justo al norte de América del Sur. Las Antillas Menores más o menos coinciden con el borde exterior de la Placa del Caribe, y muchas de las islas se formaron como resultado de la subducción, cuando una o más placas del Atlántico se deslizaron por debajo de la placa del Caribe.

Políticamente las Pequeñas Antillas se dividen en 8 países insulares independientes, 3 Territorios Británicos de Ultramar, 2 departamentos de ultramar de Francia, 2 colectividades de ultramar de Francia, 3 países autonómos del Reino de los Países Bajos, 3 Municipios especiales del Reino de los Países Bajos, 1 Área insular de Estados Unidos, y 2 entidades federales de Venezuela.

Las lenguas principales por orden de importancia en las Antillas Menores son el inglés, el francés, el español, el papiamento y el neerlandés.


El clima tropical cálido es agradablemente templado por los vientos alisios más o menos constantes durante todo el año. Estos vientos son solo interrumpidos por algunas tormentas sobre el océano Atlántico. En el interior, el clima es ligeramente más caliente, y se enfría, con la altitud, y a medida que aumenta la humedad también.

Sin embargo se distinguen dos tipos de estaciones:


</doc>
<doc id="11448" url="https://es.wikipedia.org/wiki?curid=11448" title="Isla">
Isla

Una isla es una zona de masa terrestre estable, más o menos extensa, rodeada completamente por una masa de agua. Toda su superficie, tomada a la misma altura sobre el nivel del mar, está sometida a un clima similar. Existen islas en los ríos, lagos, mares y océanos. El tamaño de las islas es variable, pudiendo tener de superficie hasta más de tres millones de kilómetros cuadrados, como es el caso de Groenlandia.

Estas islas son partes de tierra conectadas por la plataforma continental a un continente. Esto significa que son parte del continente adyacente, y que están localizadas en su plataforma continental.

Ejemplos de islas continentales de diverso tamaño y forma:


La actividad volcánica que se produce en los fondos oceánicos trae como consecuencia la formación de islas. Esto suele estar relacionado con el movimiento de placas de la corteza terrestre.

Ejemplos de este tipo de islas islóticas son: 

Las islas y arrecifes coralinos se encuentran en mares tropicales y subtropicales. Están formadas por los esqueletos de un grupo de organismos marinos primitivos, denominados corales. Se forman cuando el coral crece hasta la superficie del océano, desde plataformas submarinas no muy profundas, siendo muchas veces conos volcánicos. Cuando el cono está completamente sumergido se forma un atolón coralino. El coral dejará de crecer hacia arriba cuando llega a la superficie. Por este motivo estas islas son planas y bajas. Ejemplos de este tipo de islas son: 


Estas islas se forman en la desembocadura de ríos grandes por la acumulación de arena, grava y lodo, que son arrastrados por la corriente del río. Estos sedimentos se van depositando formando montículos en lagos, lagunas, u otros ríos donde la corriente pierde velocidad. Estas islas forman un delta, como por ejemplo los deltas de los ríos Ebro, Ganges, Misisipi, Orinoco, Nilo y Paraná. La isla de Marajó, en la desembocadura del Amazonas, es la mayor isla sedimentaria del mundo, con una extensión igual a la de Dinamarca.

Las islas fluviales se forman a partir de barras presentes en el canal central del río, cuyas partículas se componen de materiales de diverso tamaño. La migración de los ríos de curso meándrico y anastomosado dejan una serie de crestas o restingas y depresiones pantanosas o bajiales, que se denominan complejo de orillares, lo que va determinando la conformación de diferentes tipos de vegetación, como por ejemplo ambientes de tierra firme, ambientes inundables o ambientes transicionales entre estos dos. Cada cresta representa el resultado de la migración del curso durante la formación de una nueva playa.

Las islas fluviales, al encontrarse delimitadas por un río y sujetas a su dinámica de inundación, presentan una serie de condiciones ambientales específicas en áreas muy pequeñas, producto de las diferencias topográficas, lo que obliga a ciertas especies animales y vegetales a adaptarse a las condiciones que este dinamismo conlleva. Por ejemplo, los bosques inundados temporalmente tienen características muy heterogéneas en áreas pequeñas; estos bosques no son estables, pues están sujetos a cambios causados por el crecimiento y avance del cauce el río. Se considera que la Isla del Bananal en el centro de Brasil es la mayor isla fluvial de la Tierra.

La isla tiene una presencia importante en el arte y las creencias religiosas. Su simbolismo es ambiguo: por una parte se asocia a las ideas negativas de aislamiento, confinamiento y muerte (de hecho, algunas islas han sido usadas como prisiones, como la Isla del Diablo y El frontón); por otra, es el lugar propicio para situar un tesoro (así, en "La isla del tesoro" de Robert Louis Stevenson), una sociedad perfecta (Atlántida, Utopía) o el paraíso (morada del buen salvaje o de las almas de los bienaventurados: Islas de los Bienaventurados, Tír na nÓg, Ávalon). A menudo se asocian a la figura femenina, como sucede en la "Odisea", donde Circe y Calipso, acogedoras y peligrosas al mismo tiempo, son señoras de sendas islas, Eea y Ogigia.

La complejidad de este simbolismo se presta a situar en las islas historias con valor iniciático, en las que el héroe debe afrontar un gran riesgo, enfrentándose a dificultades de todo tipo (monstruos, trampas, tentaciones, enemigos) para alcanzar el conocimiento de sí mismo, la madurez o un tesoro material. La serie de televisión "Lost" ("Perdidos") es un ejemplo reciente de este tipo de narraciones, que tiene su precedente en novelas como "Robinson Crusoe" de Daniel Defoe, "La isla misteriosa" de Jules Verne, "La montaña análoga" de René Daumal o "El señor de las moscas" de William Golding.




</doc>
<doc id="11449" url="https://es.wikipedia.org/wiki?curid=11449" title="Antillas">
Antillas

Las Antillas, también conocidas como islas del Caribe o América Central insular, constituyen un numeroso grupo de archipiélagos conformado por las islas de Bahamas o Lucayas, las Antillas Mayores y las Antillas Menores, ubicado entre el mar Caribe y el océano Atlántico. Estas islas dibujan un arco que se extiende en forma de medialuna desde el sureste de la península de la Florida (Estados Unidos) y el este de la península de Yucatán (México), en Norteamérica, hasta la costa oriental de Venezuela, en Sudamérica. Todas las islas de las Antillas juntas tienen una superficie total de unos 299 000 km².

Las Antillas, que fueron las primeras tierras en las que Cristóbal Colón desembarcó, recibieron este nombre porque los cartógrafos de la época citaban una isla llamada Antilia situada en la región occidental del Atlántico.

Los primeros nombres que recibió la región, sin embargo, provenían de la denominación de sus pobladores indígenas. Así se las conoció como islas Caribes, Islas Caribeñas, islas Lucayas o islas Camercanes. Antes de la llegada de Colón, el pueblo de los Caribes habitaba la costa norte de Sudamérica, específicamente en las costas de Venezuela y muchas de sus islas; a ellos se debe el nombre "Caribe". El mismo etnónimo al parecer motivó la formación de otro término —el de caníbales— que aún hoy se emplea para describir a las personas que se alimentan de carne humana. No obstante, se han propuesto otras interpretaciones.

En inglés se les denomina aún "West Indies" (Indias Occidentales), denominación que evoca la creencia de los primeros navegantes europeos, convencidos de haber arribado a las primeras islas de las Indias Orientales. Al descubrirse el error, predominó el término con el epíteto de occidentales para diferenciarlas.

La denominación actual, Antillas, no se impuso hasta el siglo XVII.

Los idiomas predominantes en la región son el español (hablado por casi 25 millones de personas y predominante en las Grandes Antillas, se habla en Cuba, República Dominicana y Puerto Rico), el francés y el criollo haitiano (en total, 9 millones de hablantes en Haití y otras islas), el inglés (hablado en Jamaica, en las Bahamas y en la mayor parte de las Pequeñas Antillas, en total más de 5 millones) y, en menor medida, el neerlandés y el papiamento (unas 300 000 personas en conjunto).

Estas islas pertenecieron inicialmente en su totalidad a España, quien fue la potencia dominante en las Antillas Mayores, sin embargo, su escaso interés en conservarlas, especialmente las Antillas Menores, motivó que estas últimas pudieran ser conquistadas sin mayores problemas por ingleses, franceses y holandeses. Fueron plazas que, posteriormente, éstos utilizaran como punto de partida para otras conquistas, lo que ha dado lugar al rico mosaico actual de nacionalidades, lenguas y culturas.

Varias de las islas son independientes pero muchas siguen siendo posesiones o dependencias de otros países. Algunas, como Guadalupe y Martinica, ambas regiones de Francia, forman parte del territorio nacional de países en otros continentes.

El turismo domina la economía de Antigua y Barbuda, produciendo casi 60 % del PIB y 40 % de las inversiones. La disminución de turistas desde el año 2000 obligó al gobierno a transformar el país en un paraíso fiscal. La producción agrícola está centrada en el ámbito doméstico y limitada por el reducido suministro de agua y una disminución de la mano de obra debido a los mejores salarios en los sectores de turismo y construcción.

Es importante también la producción agrícola de caña de azúcar, algodón y frutas; así como el refino de petróleo y las manufacturas téxtiles, de carpintería y de producción de ron. Produce algo de cerveza, ropas, cemento, artesanías locales y muebles.

La moneda oficial es el Dólar del Caribe Oriental (East Caribean Dollar), con una paridad fija de 2,7:1 con el dólar americano desde el año 1976. El producto bruto interno fue de 180 100 dólares "per capita" en 2009, año de una retracción de 6,5 % del PIB. La tasa de inflación anual es muy baja (1,5 % en 2007).

Las Bahamas es un país en desarrollo estable, dependiente de la economía basada en el turismo y actividades bancarias. El turismo solamente, supone más del 60 % del PIB y emplea directamente o indirectamente la mitad de la mano de obra del archipiélago. El crecimiento constante del turismo y el auge en la construcción de hoteles, de recursos, y de nuevas residencias habían conducido al crecimiento sólido del PIB durante algunos años hasta el 2006, pero desde aquel año hubo una caída en el número de turistas.

Los servicios financieros constituyen el segundo sector en importancia de la economía de Bahamas, cerca del 15 % del PIB. Sin embargo, desde diciembre de 2000, cuando el gobierno decretó nuevas regulaciones sobre el sector financiero, muchos negocios internacionales han salido de las Bahamas. La industria y la agricultura, contribuyen aproximadamente una décima parte del PIB y muestran poco crecimiento, a pesar de los incentivos que el gobierno destino a estos sectores. En suma, el crecimiento depende del funcionamiento del sector del turismo, que depende del crecimiento en los EE. UU., la fuente de más del 80 % de los visitantes. Además del turismo y de las actividades bancarias, el gobierno apoya el desarrollo de un "tercer pilar", el comercio.

Barbados es el país más rico y más desarrollado del Caribe Oriental y tiene una de las rentas per cápita más altas de América. Su economía tradicional se basaba en la producción de azúcar, principal materia de exportación. Con la explosión del turismo, se produjo una reorientación de la actividad. Ahora mantiene un sistema muy dependiente de Estados Unidos y Europa que son los lugares de procedencia de la mayoría de los turistas, lo que debilita su economía en los periodos de contención en los países de origen. En la actualidad ha diversificado parcialmente su economía con algo de industria ligera. Es así mismo sede de importantes empresas, sobre todo financieras, dado el alto nivel de protección del secreto bancario que ofrece y los bajos impuestos que soportan. Por la comunidad internacional es considerado un paraíso fiscal.

La economía cubana está sustentada en los recursos naturales del país, que son muy variados y van desde minerales como el níquel y el cobalto a los paisajes tropicales que atraen a millones de turistas todos los años. El capital humano es el otro pilar fundamental de la economía del país, que cuenta con las tasas más elevadas de alfabetización, esperanza de vida y cobertura sanitaria de toda la América Latina y el Caribe.

El gobierno cubano mantiene su adhesión a los principios socialistas a la hora de organizar su economía, lo que ha llevado a que su política económica se base en la planificación, con opciones diferentes y cerradas a las que serían dictadas por el mercado; aunque después del derrumbe de la URSS y de los países socialistas del este de Europa, la iniciativa privada y el papel del mercado hayan aumentado, aunque no al nivel de lo sucedido en la Europa del Este.

Por otro lado, y según datos de la ONU, Cuba sería el único país del mundo que cumple los dos criterios que, para la organización WWF, significan la existencia del desarrollo sostenible: desarrollo humano alto (IDH > 0,8) y huella ecológica sostenible (huella < 1'8 ha/p). Según el informe EPI de 2010, realizado por las universidades de Yale y Columbia en Estados Unidos el país está en la posición 9.ª en el mundo con mejor desempeño ambiental.

La economía de Dominica depende principalmente de los servicios financieros offshore. El crecimiento de su industria de servicios financieros offshore deriva de un proceso gubernamental en donde se han realizado cambios estructurales con la finalidad de diversificar sus fuentes de ingreso, el gobierno busca promover activamente la isla como centro bancario internacional, y recientemente firmó un acuerdo con la Unión Europea con la finalidad de explorar sus potenciales de energía geotérmica.

Aunque anteriormente dependía en gran medida de la agricultura - especialmente banana - sus medios de ingreso se han diversificado, Su segunda fuente de ingreso es el turismo, en especial el ecoturismo.

El 2003 el gobierno comenzó una extensa reestructuración de la economía, con la eliminación del control de precios, privatización del sector bananero, y aumento de impuestos, con miras a enfrentar una crisis económica y atender las recomendaciones del Fondo Monetario Internacional. Esta reestructuración permitió la recuperación económica - en 2006 el crecimiento ultrapasó los dos dígitos - y ayudó a reducir la deuda pública.

El progreso económico de Granada, debido a las reformas fiscales y una macroeconomía prudente ha disparado el crecimiento anual del país al 5-6 % en 1998-1999. El incremento de la actividad económica ha estado liderado por la construcción y el comercio. Actualmente el país depende del turismo como su principal fuente de ingresos de capital extranjero, especialmente después de la inauguración de su aeropuerto internacional el 1985. Las instalaciones turísticas se han aumentado desde entonces.

Los huracanes Iván (2004) y Emily (2005) han severamente damnificado su sector agrícola - especialmente el cultivo de cacao. Después de la devastación, el país confronta un enorme déficit presupuestario, ampliado durante el proceso de reconstrucción, y que llega actualmente a 110 % del PIB.

La economía de Haití es la más pobre de América y del Hemisferio Occidental, es decir, Haití es el país con menor PIB per cápita y uno de los más desiguales del mundo. Su renta per cápita es alrededor de una décima parte de la de sus vecinos de la región del Caribe. Tiene una tasa de desempleo superior al 50% de su población, sus ingresos anuales per cápita son menores al salario mínimo de otros países latinoamericanos y la pobreza extrema alcanza casi el 70 % de la población.

La economía de Kingston es principalmente agrícola y minera, aunque desde la década de los 90 del siglo XX tomo impulso especial el turismo. El crecimiento sostenido desde las reformas de 1982 ha permitido alcanzar un PIB de 7400 millones de dólares. La agricultura emplea a más de un 20 % de la población, siendo el cannabis el principal producto. Esto supone una dependencia excesiva del precio del azúcar en los mercados internacionales. Además, se cultivan plátanos, café y tabaco que en buena medida se dirigen a la exportación, además de los productos para consumo interno como la patata y el maíz. La cabaña ganadera asciende a más de 800 000 cabezas entre ganado vacuno y caprino, siendo el cerdo residual con apenas 150 000 cabezas.

La alúmina y la bauxita constituyen la espina dorsal de la minería desde su descubrimiento en 1940, cuya producción íntegra se destina a la exportación. La industria ha alcanzado cierto nivel de importancia, sobre toda la manufacturera (textil y calzado) y las de refino petrolífero.

A partir del 2000 Jamaica empezó a experimentar crecimientos positivos de su economía tras un periodo de cuatro años de crisis. La inflación terminó por controlarse a niveles aceptables en 2001, si bien en 2003 y 2004 ha vuelto a repuntar hasta niveles preocupantes.

La economía de la República Dominicana es la primera economía del Caribe y la octava economía más grande de América Latina después de Brasil, México, Argentina, Colombia, Chile, Perú y Ecuador. Es un país en desarrollo de ingresos altos según el Banco Mundial, dependiendo, principalmente, de la agricultura, el comercio exterior, los servicios, la minería, la industria y el turismo. Aunque el sector servicios ha sobrepasado a la agricultura como el principal proveedor de empleos debido, sobre todo, al auge y crecimiento del turismo y la industria, la agricultura todavía se mantiene como el sector más importante en términos de consumo doméstico y está en segundo lugar (detrás de la minería) en términos de exportación. El turismo aporta más de US$ 7000 millones al año. La industria y turismo son los sectores de mayor crecimiento. Las remesas de los ciudadanos dominicanos viviendo en el exterior se estiman en unos US$ 5500 millones por año.

San Cristóbal y Nieves fue el último lugar en practicar el monocultivo de azúcar en las Antillas Menores. Pero debido a que la industria azucarera encontraba cada vez mayores dificultades para conseguir beneficios, el gobierno decidió realizar un programa de diversificación para el sector agricultor y estimulación del desarrollo en otros sectores de la economía, particularmente el turismo.

El gobierno instituyó un programa de incentivos a la inversión, alentando tanto la inversión privada doméstica como extranjera. Las políticas gubernamentales incluían exenciones fiscales, importación de equipamiento y materiales libres de impuestos y subsidios para la capacitación a personal local. El turismo ha mostrado un gran incremento. Hacia 1987, había sobrepasado al azúcar como fuente de ingreso de divisas.

La economía de San Vicente depende en una gran medida de la agricultura. El cultivo de la banana representa un 60% del empleo y un 50 % de las exportaciones. Está muy fuerte dependencia de un solo cultivo hace que la economía sea vulnerable a múltiples factores externos. Los agricultores de banana de San Vicente poseen acceso preferencial al mercado europeo. Dado que la Unión Europea ha anunciado que dicho acceso preferencial será discontinuado, es que la diversificación de la actividad económica se torna una prioridad para San Vicente.

El turismo ha crecido, convirtiéndose en un elemento importante de la actividad económica. En 1993, el turismo desplazó a las exportaciones de banana como el principal elemento generador de ingreso de divisas. Las Granadinas se han convertido en un mercado favorito de los fanáticos con altos niveles de ingreso que practican el yachting. La tendencia de crecimiento del turismo es muy probable continúe. En 1996, se inauguraron nuevos atracaderos y amarraderos para cruceros y buques, con el consecuente aumento de la cantidad de pasajeros arribados. En 1998, arribaron un total de 202,109 visitantes, la mayoría de los turistas provinieron de otros países del Caribe y el Reino Unido.

La economía del país depende en gran parte del cultivo de plátanos. Sin embargo, los cambios en el régimen de importaciones de la Unión Europea y la creciente competencia de los productores América Latina han forzado la diversificación. En años recientes la industria del turismo y las finanzas internacionales han adquirido un papel preponderante en la composición de su Producto Interno Bruto y ahora casi el 73 % del mismo es generado por la industria de servicios (2002). Su sector de manufactura, aunque menos importante, es uno de los más diversificados del Caribe Oriental.

Los principales productos de exportación de la isla son el plátano y algunos productos textiles que vende al Reino Unido y a los Estados Unidos por un monto cercano a los USD $30 millones, casi la mitad de sus exportaciones totales. Debido a las condiciones geográficas y demográficas de la isla, gran parte de sus insumos son importados, siendo sus principales proveedores Brasil (41,7 %), Estados Unidos (21,4 %) y Trinidad y Tobago (11,9 %).

La isla fue uno de los países fundadores de la Organización Mundial del Comercio y se integró al Fondo Monetario Internacional el 15 de noviembre de 1979. Su moneda, el dólar del Caribe Oriental, es la moneda de curso legal en otros seis países. Santa Lucía ha firmado algunos convenios de libre comercio y cooperación económica con la Organización de Estados del Caribe Oriental y con la Comunidad del Caribe. En materia técnica recibe asesoría por parte de la Mancomunidad Británica de Naciones y de la CEPAL y también recibe apoyos económicos del Banco de Desarrollo del Caribe.

El año fiscal en la isla comienza el 1 de abril y finaliza el 31 de marzo del año siguiente.

La economía de Trinidad y Tobago experimentó, durante el año 2002, un índice de crecimiento del 3,2 %. Esto se debe a 9 años consecutivos de verdadero crecimiento después de 8 años de recesión. El gobierno del primer ministro Patrick Manning ha seguido la política macroeconómica del gobierno anterior, tratando de atraer las inversiones en el país. A largo plazo, parece que va a producirse un gran crecimiento, un crecimiento que irá estrechamente ligado al desarrollo de los hidrocarburos, lapetroquímica, y el sector siderúrgico, que supondrá aumentos significativos en las exportaciones de Trinidad y Tobago. Además, el país sigue sus esfuerzos en la diversificación de servicios, el turismo, la industria y la agricultura.

Así pues, el gran índice de crecimiento de Trinidad y Tobago ha producido excedentes que son exportados, aún sin dejar de importar, ya que la extensión industrial y el aumento de consumo así lo requieren. Por consiguiente, el ratio de deudas ha pasado de un 15,4 % en 1997 a un 4,4 % en 2002. El paro disminuye lentamente: ha pasado de un 12,1 % en 2001 a un 10,4 % en 2002.

La actividad agrícola más importante es el cultivo de la caña de azúcar, al que se asocia la producción de azúcar en los seis ingenios del oeste de la isla, así como de mieles y de ron. Le siguen en importancia el cacao, el grano y su beneficio, las frutas cítricas y el café. La ganadería es poco importante: 65 000 cabezas de ganado bovino, 6000 de ovino, etc.




</doc>
<doc id="11450" url="https://es.wikipedia.org/wiki?curid=11450" title="Archipiélago">
Archipiélago

Un archipiélago es aquel conjunto, generalmente numeroso, de islas agrupadas en una superficie más o menos extensa del mar. Estas islas se encuentran cercanas entre sí y pueden tener su origen de diferentes maneras, y por eso hay varios tipos.

Estas islas son segmentos de territorios fértiles rodeados totalmente por mar, y juntos forman un archipiélago. Además de islas, los archipiélagos pueden contener otras masas de tierra menores como islotes, arrecifes y cayos.

La palabra viene del griego άρχι (quiere decir, "superior") y πέλαγος ("mar").Antiguamente la palabra "archipielgus significaba "Mar principal" y hacía referencia al Mar Egeo porque estaba lleno de islas." En italiano, comenzó siendo el nombre propio para el mar Egeo desde 1268 y más adelante, el uso pasó a referirse a las islas del mar Egeo. Desde se utiliza para referirse a cualquier grupo de islas o, a veces, a un mar que contiene un pequeño número de islas dispersas.

Los archipiélagos más frecuentes son aquellos de naturaleza volcánica asociados a grandes erupciones de magma pero también pueden ser resultado de erosión o deposición de tierra.

Dependiendo del origen geológico, las islas que forman los archipiélagos se pueden considerar como islas oceánicas o islas continentales, y por consiguiente, los archipiélagos pueden ser oceánicos o continentales.
Los archipiélagos oceánicos están formados por islas que no pertenecen a una placa tectónica continental y son principalmente de origen volcánico. La formación de esto archipiélagos es mucho más rápida que la formación de archipiélagos continentales.

El archipiélago de Hawái es el claro ejemplo de este tipo de archipiélago.
La masa de tierra que forman las islas continentales pertenecen a fragmentos continentales que se han separado de la masa principal del continente mediante el movimiento de las placas téctonicas y otros fenómenos geológicos. A diferencia de los archipiélagos oceánicos, su formación es muy lenta.

Islas Baleares, Groenlandia o las Islas Británicas son ejemplos de archipiélagos continentales.

La gran mayoría de los archipiélagos más conocidos se sitúan en el sudeste asiático, a este grupo podríamos añadir Las Islas Hawái ( pertenece a Estados Unidos) y Las Islas Canarias ( pertenecen España).El archipiélago Malay es considerado uno de los más grandes del mundo, siendo este compuesto por más de 25.000 islas. A continuación, una lista de los archipiélagos más conocidos. No todos están incluidos en esta lista, debido a dificultad de calcular todos los existentes en el mundo.





</doc>
<doc id="11451" url="https://es.wikipedia.org/wiki?curid=11451" title="Mar">
Mar

La definición comparativa de mar como extensión de agua salada menor que el océano establece una clasificación de las extensiones de agua salada en que los océanos serían las mayores extensiones y vendrían luego, de diferentes tamaños, los mares. Los mares se diferencian principalmente por el contacto con el océano, pudiendo ser abiertos o cerrados: si está rodeado casi totalmente por tierra, como el mar Negro, se habla de mar continental, mientras que si está muy abierto, como el mar de la China, se habla de mar litoral.

La distinción entre mar y océano obedece a diversas causas, sobre todo cuando se habla de mares abiertos en que suele distinguirse atendiendo a la situación geográfica, generalmente enclavada entre dos masas terrestres o, a veces, las menos, a la posición de la plataforma continental. Algunos ejemplos de esto son los siguientes: el mar del canal de la Mancha comunica con el océano Atlántico por el mar Céltico, pero se distingue por su posición entre la costa sur de Inglaterra y la costa norte de Francia. Otro caso muy claro es el mar Mediterráneo, que comunica con el océano Atlántico por el estrecho de Gibraltar y se distingue claramente por estar enclavado entre Europa, Asia y África, al punto de que tiene unas condiciones marítimas muy diferentes (diferentes temperaturas, diferente fauna y flora, y mareas de diferente amplitud). Otro mar abierto, en este caso el de los Sargazos, con su acumulación de algas a lo largo de la Florida, se distingue del océano Atlántico de forma totalmente arbitraria.

La máxima autoridad internacional en materia de delimitación de mares es la Organización Hidrográfica Internacional (IHO-OHI), siendo la referencia mundial su publicación Limits of oceans and seas ("Límites de océanos y mares") (3.ª edición de 1953).

Dicha publicación no establece diferencias entre océanos y mares, sino que se limita a enumerar todos los océanos y mares del mundo, asignándoles un número, llegando hasta el 66, aunque como utiliza a veces números con letra, en realidad son 73. Son un total de 5 océanos (el Atlántico y el Pacífico están divididos cada uno en dos, Norte y Sur) y 67 mares, de ellos dos divididos en dos cuencas, el mar Mediterráneo y el mar de China.

Algunos mares tienen mares interiores (que se numeran con una letra minúscula) como el Báltico (3), el Mediterráneo (8) y el Archipiélago de la India Oriental (13). La publicación considera además de océanos y mares, golfos, bahías, canales y estrechos, y muchas veces, no resulta muy claro cual es el criterio utilizado, ya que a veces es el simple uso desde tiempos pasados.

Existen tres categorías de mares: mares litorales (o costeros), mares continentales y los mares cerrados.

Los mares litorales o costeros pueden ser considerados como golfos, muy grandes y ampliamente abiertos, de los océanos. No están separados de éstos por ningún umbral submarino; no obstante se distinguen de ellos por ser, en promedio, menos profundos, por la mayor amplitud de las mareas y la temperatura más elevada de sus aguas. Son mares litorales el mar de Beaufort en el océano Ártico, el mar de Noruega en el Atlántico o el mar de Omán en el Índico, entre otros.

Se llama mar epicontinental al que se asienta sobre una plataforma continental con su lecho submarino a una profundidad media de 200 m o menos; ejemplos de este tipo son el mar del Norte, o el mar Argentino. Durante el punto máximo de las glaciaciones, los mares epicontinentales desaparecen, pasando a ser solo llanuras de los continentes aledaños.

Los mares continentales, entre los cuales destaca el mar Mediterráneo, deben su nombre al hecho de hallarse enteramente situados dentro de los continentes, aunque comunicados con los océanos por un estrecho cuya escasa profundidad crea un umbral que dificulta los intercambios; éstos se producen, no obstante, en forma de corrientes de compensación y de descarga. Entre los mares continentales y el océano existen diferencias de temperaturas y de salinidad que llegan a ser considerables. Sus mareas son de tan escasa amplitud que pasan desapercibidas. Además del Mediterráneo, son mares continentales el mar Báltico, el mar Negro y el mar del Japón.

Los mares cerrados o interiores suelen ocupar extensas depresiones endorreicas. Corresponden a lagos muy grandes, de agua más o menos salada, entre los cuales destacan el mar Muerto, el mar Caspio y el mar de Aral.

Aunque la mencionada publicación del IHO no considera los mares incluidos en los océanos —sino como algo aparte de modo que entre todos cubren toda la superficie marina— habitualmente siempre se han considerado así, obedeciendo a una consideración de ámbito más geográfico. A veces en algunos mares situados en los bordes entre dos océanos, hay discrepancia entre asignarlos a uno u otro, y depende de la publicación consultada. Por eso parece más oportuno clasificarlos de acuerdo al continente al que bañan, con las mismas salvedades en cuanto a situación de borde.

Los "mares lunares" son vastas planicies basálticas en la Luna que fueron llamadas "mares" porque los primeros astrónomos pensaban que eran grandes masas de agua, por lo que se refirieron a ellas como mares.

Se estima que hay agua líquida sobre la superficie de muchos satélites naturales, como en Europa, una luna de Júpiter. También se piensa que hay hidrocarburos en estado líquido en la superficie de Titán, aunque han de ser considerados más bien «lagos» que «mares». La distribución de esas regiones líquidas será mejor comprendida después de la llegada de la sonda espacial Cassini-Huygens.

El mar aparece como objeto en algunos de los ensayos de la historiografía, por ejemplo: "El mar" de Jules Michelet o en Memorias del Mediterráneo de Fernand Braudel. Dice Michelet: 

«Mucho antes de vislumbrarse el mar, se oye y se adivina el temible elemento. Primero un rumor lejano, sordo y uniforme. Poco a poco cesan todos los ruidos dominados por aquél. No tarda en notarse la solemne alternativa, la vuelta invariable de la misma nota, fuerte y profunda, que corre más y más, y brama».

En 1905 el compositor francés Claude Debussy finaliza la composición de una obra sinfónica con el título "La mer, trois esquisses symphoniques pour orchestre".

En 1946 el compositor francés Charles Trenet graba el tema titulado "La mer", que supuso su mayor éxito, y que tuvo numerosas versiones posteriores (más de cuatrocientas).

El mar como tema ha sido abundantemente abordado en la pintura, habiéndose creado un género notablemente vasto y de origen muy antiguo, el de la marina, que comprende toda obra pictórica cuyo tema principal es el mar.



</doc>
<doc id="11452" url="https://es.wikipedia.org/wiki?curid=11452" title="Mar Cantábrico">
Mar Cantábrico

El mar Cantábrico es el mar litoral del océano Atlántico que baña la costa norte de España y el extremo suroeste de la costa atlántica de Francia; supone la zona sur del golfo de Vizcaya. Se extiende desde la punta de Estaca de Bares, en la provincia de La Coruña, hasta la desembocadura del río Adur, cerca de la ciudad de Bayona, en la costa del departamento de Pirineos Atlánticos, en el País Vasco Francés. Baña 800 kilómetros de costa compartida por las provincias de La Coruña y Lugo (Galicia), Asturias, Cantabria, Vizcaya y Guipúzcoa (País Vasco), y el departamento francés de Pirineos Atlánticos.

Constituye un mar de transición entre los mares fríos del norte y los templados del trópico, lo que hace que sea ecotono de especies vegetales y animales de aguas frías. El afloramiento de aguas profundas y frías existente frente a las costas gallegas hace que la temperatura del agua aumente conforme nos desplazamos hacia el Este. Esa temperatura del agua superficial presenta una acusada estacionalidad, así durante el invierno la temperatura del agua puede bajar hasta los 11 °C, mientras que en verano alcanza los 22 °C aproximadamente. A partir de 35 o 40 m de profundidad la temperatura del agua se mantiene prácticamente estable durante todo el año. Estas temperaturas son inusualmente altas dada la región geográfica que ocupa el mar Cantábrico, y se deben a los efectos cálidos de la corriente del Golfo.

Los fuertes vientos, del Noroeste preferentemente, que soplan sobre el mar Cantábrico tienen su origen en las bajas presiones centradas sobre las islas británicas y el mar del Norte en combinación con el anticiclón de las Azores. La distancia recorrida por el viento y el mantenimiento de su dirección y velocidad constantes hacen que se generen olas de 2 a 3 m de altura, lo que origina un mar bastante agitado. En condiciones muy particulares, más propicias en los meses de abril-mayo y septiembre-octubre, los vientos del Oeste pueden alcanzar magnitudes de galerna con olas que llegan a superar los 7 m de altura.

La salinidad media del Cantábrico es de 35 g/L, aunque varía ligeramente en función del régimen de lluvias y la mayor o menor cercanía a la costa y/o desembocadoras de ríos caudalosos.
Tiene una significativa amplitud de marea, pudiendo ser de 4,5 m como máximo, especialmente en las mareas vivas de marzo.

El mar Cantábrico fue bautizado por los romanos en el siglo I a. C. como "Cantabricus Oceanus" en referencia a uno de los pueblos que poblaban sus costas, los cántabros. En otras citas clásicas más antiguas aparece con el nombre de "Britannicus Oceanus" y "Gallicus Oceanus". En sus costas se crearon asentamientos humanos de tribus de astures, cántabros, autrigones, caristios y várdulos que hicieron de la pesca su principal actividad económica, aunque esta en esos tiempos primitivos no fue muy importante.

Con la decadencia romana se inicia un periodo convulso y con escasas fuentes historiográfica. Hidacio señala que hacia el año 456 d. C. la costa es devastada por expediciones de hérulos. Durante este periodo el litoral cantábrico eran costas indefensas frente a las "razzias" de los pueblos del norte de Europa. Aunque el mar probablemente sí estaría abierto a la navegación, no se tiene constancia de la existencia de comercio o intercambios marítimos. Se desconoce si los puertos romanos seguían aun activos, estaban abandonados o únicamente daban servicio a intercambios locales.
Posteriormente se registra la primera llegada de los vikingos a la península ibérica a través del mar Cantábrico en el siglo IX, quienes intentaron asaltar y saquear numerosos pueblos costeros aunque fueron derrotados en numerosas ocasiones e inicialmente por Ramiro I de Asturias.
La pesca se convirtió en una importante actividad económica en el mar Cantábrico, especialmente las capturas de ballenas, hoy extintas en la región.

El mar Cantábrico ha sido considerado tradicionalmente un "mare tenebrosum", cerrado, peligroso y de difícil tránsito. No obstante, las investigaciones arqueológicas actualmente están cuestionando esta visión. Desde finales del siglo I d. C., de sus resguardadas bahías y ensenadas surgieron asentamientos que con el tiempo llegaron a tener gran importancia, como demuestra el surgimiento de la Hermandad de las Cuatro Villas o de la de las Marismas, federaciones de puertos que conformaron un poder naval y económico de primer orden en el Arco Atlántico.

Principales municipios a la orilla del mar Cantábrico:


</doc>
<doc id="11453" url="https://es.wikipedia.org/wiki?curid=11453" title="Corriente del Golfo">
Corriente del Golfo

La corriente del Golfo es una corriente oceánica que desplaza una gran masa de agua cálida procedente del golfo de México y que se dirige al Atlántico Norte. Es una corriente superficial (por la temperatura cálida de sus aguas) y disminuye gradualmente en profundidad y velocidad hasta prácticamente anularse a unos 100 m, cota donde la influencia del calentamiento por los rayos solares desaparece en la práctica. Tiene una anchura de más de 1000 km en gran parte de su larga trayectoria, lo que da una idea aproximada de la enorme cantidad de energía que transporta y de las consecuencias tan beneficiosas de la misma. Se desplaza a 1,8 m/s aproximadamente y su caudal es enorme: unos 80 millones de m³/s.

La circulación de esta corriente asegura a Europa un clima cálido para la latitud en que se encuentra. También determina en buena parte la flora y la fauna marina de los lugares por los que pasa (por ejemplo, los artrópodos y cefalópodos abundan más en las costas de Galicia que en las del País Vasco, donde su influencia es menor).

Es provocada por la acción combinada del movimiento de rotación terrestre (y en menor grado el de traslación) y de la configuración de las costas tanto americanas como europeas.

La corriente del Golfo se forma en el Golfo de México (de ahí su nombre) desde donde sale al Atlántico por el estrecho de Florida. Es la corriente de borde oeste de la circulación anticiclónica del Atlántico norte. El punto donde termina ha sido motivo de controversia, pero se considera que la corriente del Golfo propiamente dicha finaliza a aproximadamente 40°N y 50°O donde el flujo no cesa sino que sus aguas cálidas y saladas siguen fluyendo por un lado hacia el norte, en la corriente del Atlántico Norte (también llamada deriva del Atlántico Norte) y la corriente de Noruega que la prolongan, y por otro lado hacia el sur vía la corriente de las Islas Canarias.
Ya desde el primer viaje de Colón, los españoles comprobaron la dificultad de navegar hacia el oeste a una latitud superior al trópico de Cáncer, rumbo que los hizo retrasar considerablemente en su recorrido. De hecho, en los cuatro viajes que Colón realizó, el primero fue el único que siguió este rumbo. Esta ruta atravesaba el cinturón de altas presiones de lo que ahora se conoce como el anticiclón de las Azores, donde los vientos son relativamente débiles y abundan los días de calma. Y cuando ya estaban relativamente cerca de las tierras americanas (que en un primer momento se llamaron las Indias Occidentales), se encontraron con el mar de los Sargazos (nombre de origen griego, empleado por Aristóteles para denominar una parte del mar en la que abundan las algas y utilizado posteriormente para indicar un área extensa ubicada al este-noreste de las Grandes Antillas), donde abundan las algas de este nombre, lo cual fue interpretado, erróneamente, como un obstáculo que frenaba el viaje de las embarcaciones. Como después se pudo comprobar, las algas, que son más ligeras que el agua para flotar, no ofrecen ninguna clase de resistencia a la navegación.

En la misma obra de Anglería se intuye la existencia de una fuerza superior a la de los vientos que hacía desviar las embarcaciones, indicando las experiencias de Bartolomé Colón (hermano de Cristóbal) en las costas de La Española (ahora Santo Domingo), tan temprano como en 1497. 

El descubrimiento por parte de los europeos de la corriente del Golfo data de 1513, año de la expedición de Juan Ponce de León, fundador de la provincia de la Florida y explorador de las costas de esta península. Navegando hacia el sur a lo largo de las costas orientales de la Florida, con viento en popa (aunque débil) se dieron cuenta de que su embarcación retrocedía en lugar de avanzar. El descubrimiento se atribuye a su piloto, Antón de Alaminos. A partir de dicha fecha fue ampliamente utilizada por los barcos españoles en su viaje de vuelta del Caribe a España.

Otro autor que identifica con precisión la naturaleza de la corriente del Golfo es Jerry Wilkinson, en un artículo reciente sobre este tema:

El primero que publicó descripciones detalladas y mapas precisos de la corriente del Golfo fue Benjamin Franklin en su obra de 1786 "Sundry Maritime Observations".

Los pescadores norteamericanos, en particular los balleneros cuya área de pesca se extendía de Terranova a las Bahamas y las Azores, se habían dado cuenta de que las ballenas evitaban las aguas cálidas de la Corriente y se mantenían en sus bordes. Transmitieron sus conocimientos a los capitanes norteamericanos de navíos que modificaron su ruta ganando así dos semanas en el trayecto de América a Gran Bretaña. En 1769, la Oficina de Aduanas de Boston se quejó a las autoridades británicas de que los navíos británicos tardaban más que los americanos en realizar el trayecto. Franklin, por entonces Responsable General de Correos de Nueva Inglaterra, consultó a su primo, Thomas Folger, capitán de navío y antiguo ballenero basado en Londres. Siguiendo sus indicaciones, mandó a cartografiar la corriente del Golfo en 1669-1770 pero el mapa fue rechazado por el Almirantazgo y los capitanes ingleses que mantenían que el camino más corto tenía que ser el más rápido y se negaban a aceptar los consejos de simples pescadores americanos.

Franklin decidió estudiar el fenómeno y en sus numerosos viajes entre América y Europa tomó medidas sistemáticas de la temperatura de las aguas. Constató que las corrientes norte-sur eran más frías que las que fluían en sentido contrario, y concluyó que el termómetro podía ser también una útil herramienta de navegación.
Con Franklin la corriente del Golfo adquirió nombre propio ("Gulf Stream" en inglés) y abrió el camino al estudio de la oceanografía física. Las autoridades británicas empezaron a dar instrucciones a sus navíos para que tomaran mediciones de la Corriente, y los cuadernos de bitácora de los buques se convirtieron en la principal fuente de información sobre las corrientes marinas. Entre 1810 y 1830 el geógrafo británico James Rennell compiló estos datos para cartografiar las corrientes del océano Atlántico con un interés particular en la del Golfo. Su obra "Currents of the Atlantic Ocean", publicada en 1832, es la primera síntesis científica exhaustiva sobre el tema. 

El geógrafo Matthew Fontaine Maury, del Observatorio Naval de los Estados Unidos, retomó los trabajos de Rennell y realizó mapas de vientos y de corrientes para la navegación, promediando datos recogidos en cuadernos de bitácora entre 1840 y 1850. Impulsó en ese aspecto la cooperación internacional, en la primera conferencia internacional de meteorología de Bruselas en 1853, del que fue el iniciador, y dio los primeros pasos hacia la «oceanografía sinóptica». A partir de 1844 se realizaron estudios sistemáticos de la corriente del Golfo sobre la base de mediciones de la temperatura en superficie y en profundidad, desde la costa hacia el mar abierto. Pero los medios disponibles, ligados a barcos oceanográficos lentos y de autonomía limitada, no permitían apreciar la variabilidad de la dinámica oceánica ni medir la velocidad de las corrientes a gran profundidad. Hubo que esperar hasta los años 1960-1970, cuando se desarrollaron sistemas espaciales que permitieron cubrir en tiempo real todos los océanos y desplegar instrumentos de medida localizados y comunicados por satélite.



</doc>
<doc id="11454" url="https://es.wikipedia.org/wiki?curid=11454" title="Golfo de Vizcaya">
Golfo de Vizcaya

El golfo de Vizcaya (; ) es un amplio golfo del océano Atlántico Norte localizado en la parte occidental de Europa. Se extiende desde el cabo Ortegal en Galicia (España) hasta la punta de Pern en la isla de Ouessant, en Bretaña (Francia). Baña las costas de las comunidades autónomas españolas de Galicia, Asturias, Cantabria y el País Vasco, así como las regiones francesas de Nueva Aquitania, Países del Loira y Bretaña.

En España se considera el golfo de Vizcaya como la parte más oriental del mar Cantábrico, con la que se designa el mar litoral que baña la costa norte de España y la costa suroeste de Francia y que correspondería con lo que los romanos en el siglo I a. C. nombraron como "Sinus Cantabrorum" («bahía de los cántabros»). La parte más septentrional era denominada "Sinus Aquitanus" o "Mare Aquitanicum" (mar de los aquitanos).

Su costa en el sur es escarpada, con multitud de acantilados entre los que se abren playas y pequeñas bahías, generalmente en las desembocaduras de los ríos (que suelen ser en forma de rías). Destacan la rasa mareal de la costa guipuzcoana, entre Deba y Zumaya (que se extiende en menor medida hasta Ondárroa), y las playas de Gijón, Llanes, Laredo, Comillas, Laga, Deba, Zarauz o San Sebastián, mientras que la costa francesa es recta, baja y arenosa, con dunas y numerosos pantanos, del sur hasta la desembocadura del Loira; en el tercio norte, en la costa de Bretaña, alternan tramos rocosos y elevados, con numerosas ensenadas, bahías y amplias playas de arena.

Los ríos que desembocan en la costa sur de este golfo son de corto recorrido, como todos los de la vertiente cantábrica. En cambio los de la costa este (Garona que desemboca en la ciudad de Burdeos o Loira) tienen un gran recorrido, volviendo a ser de curso corto al norte (en Bretaña). Entre los españoles destacan el Nalón, siendo el río más largo y caudaloso del área española, el Nervión, que forma la ría de Bilbao, y el Bidasoa, que marca en parte la frontera entre Francia y España.

La corriente de Navidad son las aguas cálidas superficiales que fluyen por la costa atlántica de la Península Ibérica de sur a norte y la costa cantábrica de oeste a este, hasta chocar con la costa continental francesa para desplazarse al norte. Los meses de noviembre a marzo. en una franja de aproximadamente 50 km de ancho.

Los vientos fuertes del suroeste que la generan se originan con las bajas presiones centradas sobre las Islas Británicas y el mar del Norte, combinadas con el anticiclón de las Azores.

Esta corriente es la culpable de que parte del vertido de chapapote o galipot del naufragio del Prestige llegara hasta las costas francesas desde más allá de la ciudad de La Coruña en Galicia.

Respecto a la batimetría, el golfo de Vizcaya presenta dos plataformas continentales separadas por una amplia llanura abisal con una profundidad máxima de 2789 m. Esta llanura fue creada por la separación y rotación de la placa ibérica con respecto a la eurasiática. El límite entre ambas plataformas está definido por la fosa de Capbreton, un estrecho fiordo submarino de 2100 m de profundidad y 150 km de largo que se acerca frente al puerto de Capbreton, en el departamento francés de las Landas.

Esta disposición batimétrica y la orientación noroeste del Golfo de Vizcaya hacen que esté especialmente expuesto a los temporales provenientes del Atlántico Norte. La estrechez de la plataforma continental de la parte sur hace que las olas pueden alcanzar una altura considerable en esta costa, especialmente frente a la fosa de Capbreton.

La pesquería del golfo de Vizcaya es similar a la del mar Cantábrico. Está muy explotada y hay muchas especies que están en peligro serio de extinción, como el besugo, la merluza e incluso la anchoa. Otras, como el verdel y el bonito, gozan de buena salud y se explotan regularmente. Algunas especies ya han desaparecido del golfo de Vizcaya, como la ballena franca glacial, cuyo último ejemplar se cazó en Orio a principios del siglo XX. No obstante, es una buena región para la observación de mamíferos marinos.

Desde la antigüedad el golfo de Vizcaya ha sido una zona de tránsito naval importante. La característica de su ubicación y forma ha potenciado que se usara para la navegación entre la costa occidental continental y el norte peninsular, y entre estos puntos y las Islas Británicas (a diferencia de la región occidental del mar Cantábrico, las costas gallega y asturiana, donde se propiciaron las rutas hacia y desde Irlanda). Hay servicios regulares de ferry entre Gijón y Nantes, entre Santander y Plymouth.

Comprende importantes puertos comerciales, como los de Avilés, Gijón, Santander, Bilbao, Pasajes, Bayona (Francia), Burdeos, La Rochelle, Nantes o Lorient, y pesqueros como los de Vivero, Burela, Luarca, Cudillero, Candás, Llanes, Santoña, Laredo, Castro Urdiales, Bermeo, Ondárroa, Guetaria, San Juan de Luz, Les Sables-d'Olonne o Concarneau.

La máxima autoridad internacional en materia de delimitación de mares, la Organización Hidrográfica Internacional («International Hydrographic Organization, IHO), considera el golfo de Vizcaya («Bay of Biscay») como un mar. En su publicación de referencia mundial, «Limits of oceans and seas» (Límites de océanos y mares, 3ª edición de 1953), le asigna el número de identificación 22 y lo define de la forma siguiente:



</doc>
<doc id="11455" url="https://es.wikipedia.org/wiki?curid=11455" title="Vizcaya">
Vizcaya

Vizcaya (en euskera, y oficialmente Bizkaia) es una provincia de España y un territorio histórico de la comunidad autónoma del País Vasco, heredero del antiguo señorío de Vizcaya. Su capital es Bilbao. En ella se produjo una masiva industrialización a finales del siglo XIX y la primera mitad del siglo XX. En la actualidad, la actividad industrial ha dado paso a una actividad en el sector servicios, sobre todo tras la profunda desindustrialización sufrida durante la década de 1970 y posteriores.

El término "Vizcaya" o "Bizkaia" tiene una etimología discutida. Para algunos significa "cima", y sería un sinónimo de la actual palabra vasca "bizkar" (‘loma’). En el año 1141 en referencia a la cima del monte Igueldo de San Sebastián, aparece inscrito el siguiente topónimo: "Iheldo Bizchaya" (‘cima de Igeldo’). También en Navarra hay una comarca denominada «La Vizcaya», que puede significar ‘La cima’. Se han propuesto también otras etimologías, como "bits-kaia" (‘puerto de espuma’) o "bizi-kaia" ("puerto vivo"), menos probables, pues hay topónimos similares en lugares alejados del mar, como el citado de Navarra o el de Labets-Biscay.

"Bizkaia" es la denominación en euskera recomendada por la Real Academia de la Lengua Vasca, usada habitualmente en documentos oficiales en este idioma. Es usada en documentos oficiales de la Administración española (es desde 2011 la única denominación oficial), también en documentos en castellano, y es la más empleada por los medios de comunicación en castellano del País Vasco. Es también la denominación utilizada en la versión en euskera de la Constitución española y en la versión en euskera del Estatuto de Autonomía para el País Vasco.

A pesar de que es la única denominación oficial aprobada para el territorio histórico por sus Juntas Generales mediante Norma Foral 12/1986, de 15 de diciembre, de las Juntas Generales de Vizcaya, sobre "Signos de Identidad del Territorio Histórico de Bizkaia", como dicha Norma Foral no afectaba a la denominación de la provincia, ya que el Real Decreto legislativo 781/1986, de 18 de abril, por el que se aprobaba el texto refundido de las disposiciones legales vigentes en materia de régimen local, disponía en su artículo 25.2 que «sólo mediante ley aprobada por las Cortes Generales puede modificarse la denominación y capitalidad de las provincias», Vizcaya continuó siendo la única denominación oficial de la provincia según el Real Decreto de 30 de noviembre de 1833 , hasta el año 2011.

El día 29 de junio de 2004, el Grupo Parlamentario Partido Nacionalista Vasco en el Congreso de los Diputados presentó la proposición de ley núm. 122/000084 en la que proponía establecer como denominación oficial única la de "Bizkaia". Esta propuesta fue eliminada por ese mismo Grupo Parlamentario el día 9 de mayo de 2006 por falta de apoyos.

En 2011, el acuerdo presupuestario alcanzado por el PSOE y el PNV en el Congreso de los Diputados, incluyó el cambio de denominación actual, mediante el cual, la única denominación oficial del territorio vizcaíno sería la de "Bizkaia".

Vizcaya es la denominación en castellano, recomendada por la Real Academia de la Lengua Española. Puede ser usada en documentos no oficiales y, en general, en el ámbito escrito hispanohablante. Es también la denominación que fue utilizada en la versión en castellano de la Constitución española de 1978 y en la versión en castellano del Estatuto de Autonomía del País Vasco de 1979.

Hay constancia de poblamiento en el Paleolítico en varios lugares de Vizcaya, como en las cuevas de Bolinkoba (Abadiano), Arenaza (Galdames), Atxeta (Forua), Santimamiñe (Cortézubi) y Lumentxa (Lequeitio).

La presencia de varios castros de la Edad de los Metales,como los de Arrola, Malmasín o Bolumburu, hacen pensar en una ocupación del territorio por indoeuropeos. La arqueología actual opina: 

En la distribución de tribus prerromanas de Ptolomeo, engloba parte norte de las antiguas Caristia y Autrigonia prerromanas. En las de Estrabón, Pomponio Mela y Plinio el Viejo, corresponde a la parte occidental del territorio de los várdulos. La filiación de estas tres tribus es desconocida. Los historiadores discuten sobre su origen cántabro, vascón, indoeuropeo, celta o celtibérico sin que haya pruebas concluyentes en favor de ninguna de estas hipótesis.

Los autrigones, que en Vizcaya ocuparían las Encartaciones, no fueron mencionados por Estrabón. Otros historiadores romanos como Pomponio Mela y Plinio el Viejo los sitúan en el interior, en la zona norte de la actual provincia de Burgos (Briviesca). Plinio el Viejo alrededor del año 77 citaba «entre las diez ciudades de los autrigones "Tricio" (Tritium Autrigonum) y "Virovesca" (Briviesca) como capital del los autrigones».

Ptolomeo los sitúa lindando con cántabros al oeste y turmogos al sur, y con caristios y berones al este, y, según esta distribución, se extenderían entre el río Asón y el río Nervión. Su ciudad principal era Virovesca (Briviesca), una de las cecas de las monedas del jinete ibérico. Otras ciudades importantes fueron Tricio, en la Rioja; Deóbriga (Miranda de Ebro) y en la costa Flaviobriga (Castro Urdiales) (aunque Plinio asigna esta ciudad a los várdulos) la última colonia fundada por los romanos en Hispania. Otros asentamientos fueron Osma de Valdegovia, Poza de la Sal y es posible que en la desembocadura del río Nerua (Nervión) tuvieron un puerto ya que se encontraron monedas romanas en la barra de Portugalete y en Bilbao. Floro y Orosio cuentan que eran frecuentemente atacados por los cántabros, por lo que posiblemente colaborasen con Augusto en las guerras cántabras y como premio obtuviesen el dominio de nuevos territorios en la cornisa cantábrica llegando casi hasta el río Deva.

Se discute si estaban emparentados a cántabros, celtíberos o vascones. Lo primero es dudoso ya que fue el ataque de cántabros contra autrigones y turmódigos lo que inició la guerra romano-cántabra. El hecho de que algunas de sus ciudades tengan la terminación "briga" parece indicar un origen céltico.

Los caristios ocupaban el resto de Vizcaya, según Ptolomeo. No son mencionados por Estrabón, ni por Pomponio Mela, pero sí por Plinio el Viejo, que les llama "Carietes" y les sitúa en el interior, en la zona sur del actual País Vasco.

Ptolomeo los sitúa entre el río Deva, en la provincia de Guipúzcoa y lo que actualmente es Bilbao, llegando por el sur hasta el Ebro. Su territorio limitaba con los de los várdulos y el de los autrigones. Sus ciudades eran "Tullica" (quizás Tuyo a la orilla del Zadorra), "Suessatio" (que podría ser la actual Zuazo) y "Veleia" (que podría ser la actual Iruña-Veleia), las dos últimas se encontraban en la calzada romana de Burdeos a Astorga.

También en este caso se discute si estaban emparentados a cántabros, celtíberos o vascones.

Se han encontrado numerosos restos de la romanización de Vizcaya, como los restos de los asentamientos costeros de Lequeitio, Portuondo o Bermeo, siendo quizás el más importante el puerto fluvial de Forua y los restos de su poblado romano.

Desde la caída del Imperio romano hasta las proximidades del año 1000, hay muy pocas noticias históricas de Vizcaya. Probablemente sufrió las devastaciones de los hérulos, ya que el cronista Hidacio, relata que 400 hérulos en siete naves atacaron la costa cántabra y de Vardulia en el año 456.

Las últimas investigaciones arqueológicas parecen indicar una expansión francoaquitana en Vizcaya a partir del siglo VI, lo que se contradice con las propuestas historiográficas que se basan en una continuidad de la cultura desde la protohistoria hasta los inicios de la Edad Media:

La relación con los francos merovingios se explicaría a través del Ducado de Vasconia.

Ni las invasiones de los visigodos ni las de los musulmanes parecen haber llegado a Vizcaya, aunque probablemente sus costas fueron desoladas por los vikingos, especulándose con la posibilidad de un asentamiento vikingo en las cercanías de Mundaca, que podría ser el origen de la leyenda de Jaun Zuria.

Tras la invasión musulmana, se cree que Vizcaya quedó bajo la órbita del reino de Asturias, con algunos enfrentamientos cuyo reflejo sería la también mítica batalla de Padura. En la crónica de Alfonso III de Asturias, escrita en el siglo IX, y refiriéndose al reinado de Alfonso I, es donde se hace por primera vez referencia a Vizcaya: «"Alava, Vizcaya, Alaon y Orduña siempre habían sido poseídas por sus habitantes"», por lo que no hubo necesidad de repoblarla; en cambio sí «pobló» Sopuerta y Carranza (es decir colocó bajo su control el oeste, las Encartaciones).

Tras la anexión del condado de Castilla por Sancho III de Navarra (1029), Vizcaya queda bajo la influencia del Reino de Pamplona; hasta el año 1040, cuando Íñigo López Ezquerra, conde de Vizcaya que gobernaba la Vizcaya nuclear (sin las Encartaciones ni el Duranguesado), en los enfrentamientos entre Castilla y Navarra, se alía al rey de Castilla, aprovechando para hacerse señor hereditario de Vizcaya.

En 1135 la Vizcaya nuclear vuelve a estar bajo órbita navarra, pasando definitivamente a la de Castilla el año 1180. Las Encartaciones siguen en el Reino de Castilla y el Duranguesado sigue en el de Navarra, hasta el año 1200, en que pasa a depender de Castilla.

A fines del siglo XIII y en el siglo XIV la sucesión en el señorío se altera por diferencias dinásticas y por la intervención en los asuntos del reino de Castilla, donde los señores de la casa de Haro tenían feudos y emparentaban con casas nobiliarias como los Lara o la casa real.

El Señorío de Vizcaya, por herencia materna, en 1370 recae en el Infante don Juan de Castilla, que hereda de su padre el reino de Castilla, como Juan I, permaneciendo desde entonces ligado a la corona, primero a la de Castilla y luego, desde Carlos I, a la de España, siempre con la condición de que el Señor de turno jurase defender y mantener los fueros del señorío (leyes propias vizcaínas) que en su texto afirmaban que los vizcaínos, al menos en teoría, podían desobedecer al Señor que así no lo hiciera.

La crisis bajomedieval afectó a Vizcaya produciéndose una disminución de la producción agrícola, hambrunas, etc. A esta crisis se sumó la epidemia de la peste negra de 1348. Muchos campesinos murieron, y otros se refugiaron en las villas, lo cual afectó a las rentas de las casas principales.

Los intentos de mantener su prestigio y la búsqueda de ingresos llevó a los jefes de linaje a luchas de poder que dieron lugar a dos bandos: oñacinos y gamboínos, liderados los oñacinos por el Señor de la Casa de Mújica, y los gamboínos por la Casa de Urquizu de Abendaño. Así comenzaron las guerras de banderizos que asolaron Vizcaya desde la Baja Edad Media hasta principios de la Edad Moderna. Los demás linajes de Vizcaya se adscribían a uno u otro bando en función de sus intereses, siendo normal el cambio de bando. Los señores no dudaban en robar en la villas consideradas enemigas, en saquear y extorsionar a sus campesinos, ni en asaltar los convoyes de los mercaderes de Burgos que se dirigían a los puertos para exportar sus géneros.

Las Encartaciones, en 1394, adoptan el Fuero de Avellaneda, para luchar contra la conflictividad social generada por la violencia de los banderizos. Los labradores de la Tierra Llana y las Villas acudieron al rey Enrique III de Castilla, Señor de Vizcaya, para pedirle autorización para formar una Hermandad para protegerse de las tropelías de los "jaunchos". El rey, en 1393, comisiona al corregidor Gonzalo Moro, para redactar unas nuevas Ordenanzas de Hermandad, lo que se hace en Junta General, pero estas ordenanzas no llegan a aplicarse por la oposición de algunos señores del bando oñacino.

A mediados del siglo XV, las peleas entre señores banderizos se transforman en una lucha de poder entre éstos, que dominan la Tierra Llana, por una parte, y las Villas y la Ciudad por otra. En 1479, en la Junta de Villas reunida en Durango, acuerda formar una nueva hermandad para las Villas. Y en 1480 se acuerda que, para pacificar Vizcaya, se formará una comisión con apoderados de las villas de Bilbao, Bermeo, Lequeitio y Durango y miembros de los linajes de Butrón, Múgica, Abendaño y Arteaga para dirimir las querellas y dar fin a las peleas.

Las guerras de banderizos acaban a finales del siglo XV. La puesta de las Villas bajo control administrativo de la Corona, la pujanza de las Hermandades de las villas y el reconocimiento de la hidalguía universal a todos los vizcaínos fueron elementos importantes en la pérdida de poder de los señores.

Por otro lado, los valores de los señores banderizos (nobleza, honor, honra) pasaron a ser considerados propios de la sociedad vizcaína, y, añadidos a otras costumbres importadas, como el mayorazgo castellano, reforzaron la idea de una identidad propia vizcaína.

La Vizcaya medieval estaba dividida en tres partes con gobierno y jurisdicción propios:

Al ir siendo dotadas las Villas y la Ciudad de cartas pueblas y fueros particulares durante los siglos XII y XIII, éstas dejaban de depender de los fueros de Vizcaya, Encartaciones o Durango, y pasaban a celebrar sus Juntas separadamente. Las villas y el año de concesión de fueros eran: Valmaseda (1199), Bermeo (1236), Lanestosa (1287), Plencia (1299), Bilbao (1301), Ochandiano (1304), Portugalete (1322), Lequeitio (1325), Ondárroa (1327), Areatza (1338), Marquina (1355), Elorrio (1356), Guernica (1366), Durango (1372), Ermua (1372), Miravalles (1375), Munguia (1376), Larrabezua (1376) y Rigoitia (1376); la ciudad es Orduña (1228).

Las Villas y la Ciudad, las Encartaciones y la merindad de Durango sólo acudían a las Juntas Generales de Guernica enviando representantes cuando se iban a tratar temas comunes que les afectasen.

El año 1068 Sancho II de Castilla concedió a la sede episcopal de Oca permiso para pescar en varios puertos cántabros. Se cree que, entre finales del siglo IX y principios del X la población, que había abandonado la franja costera vizcaína por temor a los ataques vikingos, vuelve a ocuparla y van apareciendo las localidades y asentamientos que conocemos en la actualidad. Pero no hay referencias escritas hasta el año 1082, en la donación de la ermita de San Miguel en Bermeo: «"et illa ecclesia S. Micaelis arcangeli in portu de Vermelio, in ora maris, cum suos morturos ad illa pertinente"». Esta repoblación es lenta. Los puertos pesqueros y comerciales se irán desarrollando a partir de los siglos XII y XIII.

Bermeo recibe su fuero en 1236, convirtiéndose en Cabeza de Vizcaya, y en 1296 pasa a formar parte de la Hermandad de las Villas de la Marina de Castilla con Vitoria.

Refiriéndose a Bermeo, un documento de 1269 menciona «cinco cabañas» a orillas del mar, lo que parece indicar que la actividad pesquera todavía era estacional. Pero también describe instalaciones más importantes, y dice que hay dos puertos, mayor y menor, y que el menor se puede cerrar con una cadena. También menciona otros dos fondeaderos llamados Arcaeta y Portuondo, que probablemente estarían en la ría de Mundaca. Bermeo y otras villas costeras irán convirtiéndose en importantes centros pesqueros y comerciales hasta el desastre de la peste negra del verano y otoño de 1348.

En esos puertos, la actividad pesquera fue adquiriendo cada vez más importancia, especialmente la caza de la ballena. Y el hecho de ser los puertos naturales para la exportación de hierro vizcaíno y lana castellana hacia Inglaterra, Francia, Flandes y los Países Bálticos los convirtió también en puertos comerciales.

En el siglo XIII hay constancia de fábricas en la ría del Nervión y en los puertos mayores. Ya en el siglo XIV se plantean pleitos entre Ondárroa y Lequeitio y entre Lequeitio y Marquina por el aprovechamiento de los bosques, cuyos árboles son necesarios para la construcción naval. Aunque no se puedan considerar astilleros, se construyen barcos en Ondárroa en "Icaran", en Lequeitio junto a la orilla del río Lea. En Bermeo en 1357 el Convento de San Francisco se encuentra cerca «del arrabal donde se labran las nabes», o sea en la zona que se denomina Ribera y en Bilbao se construyen barcos en las orillas de la ría. En el siglo XV se van consolidando los astilleros, y su funcionamiento pasa a ser regulado al tiempo que aparecen las industrias auxiliares como ferrerías o cordelerías que se instalan en sus proximidades. En Lequeitio el astillero está en la parte sur de la Plaza del Astillero, en Bermeo en la Ribera, en Plencia en el camposanto, Ondárroa y Berriatua comparten astillero y se carenaban barcos en Amallo, Rentería y Asánsolo. Pero el mayor auge de los astilleros es en Bilbao, donde desde el actual Puente de San Antón hasta Portugalete hay multitud de gradas, fábricas y playas, pasando a ser a partir del siglo XV el centro de la construcción naval de Vizcaya. Al ser punto de paso obligado entre Orduña y Bermeo, Bilbao le va quitando protagonismo a Bermeo para convertirse en el puerto y la villa más importante de Vizcaya. En el siglo XV, los astilleros de Bilbao y el comercio lanero con Francia y Flandes eran muy importantes. Y en el siglo XVI, Portugalete rivalizaba con el puerto de Bilbao.

Durante la guerra de las Comunidades de Castilla Vizcaya se mantuvo en completa calma. El 30 de julio de 1520 una de sus ciudades, Bilbao, le envió una carta a Carlos I asegurandole la fidelidad de toda la provincia. 

Siglos después, sí hubieron algunas revueltas en Vizcaya, por ejemplo: Rebelión de la sal (siglo XVII), Matxinada (siglo XVIII).

La Guerra de la Convención con la monarquía española supuso la invasión francesa de Vizcaya en 1794 y su retirada con la Paz de Basilea en 1795. Poco más tarde (1808) la Guerra de Independencia española llevó a nuevos enfrentamientos. La población se decantó en su abrumadora mayoría por Fernando VII y durante toda la guerra, la provincia fue escenario de violentos combates. En 1808 en el lapso de tres meses (6 de agosto-2 de noviembre) Bilbao cambió de manos seis veces y sufrió una revolución, una gran batalla y dos saqueos a fondo. En 1812 se repitió la situación, por la ofensiva del Séptimo Ejército español, que ocupó y perdió Bilbao varias veces. Al mismo tiempo, las guerrillas de la provincia llegaron a sumar varios miles de combatientes que hostigaban sin cesar a los invasores. 

La sucesión del rey Fernando VII inició las guerras carlistas; en Vizcaya hubo dos, entre 1833–1840 y entre 1872–1876. La mayor parte de Vizcaya apoyó al carlismo pero Bilbao apoyó al gobierno liberal y fue asediada por los carlistas que no consiguieron tomarla (véase: Sitio de Bilbao de 1835, 1836 y 1874).

El final de la última guerra supuso para Vizcaya la pérdida de la mayor parte de la autonomía (la «abolición foral» de 1876), aunque la provincia fue compensada con el «Concierto económico», un régimen fiscal y administrativo propio similar al que Navarra gozaba desde 1841. Fue también el inicio de la explotación ilimitada de las minas de hierro (que el régimen foral limitaba como un tesoro); así Vizcaya se transformó en un país industrial con consecuencias importantes: Agotamiento de las minas al cabo de un siglo (una gran parte del mineral va a Inglaterra, de donde viene carbón); Inmigración masiva de obreros venidos de otras regiones de España que viven en condiciones miserables sobre todo en la margen izquierda de la ría (conflictos entre obreros y patrones y formación de dos comunidades: nativa = vasca, e inmigrada = «maketos»); Formación de grandes fortunas (Ybarra, Chávarri, Lezama-Leguizamón..)(además de los capitales ingleses, franceses o belgas) que inviertan una gran parte fuera de Vizcaya (que se transforma en un centro capitalista de España: Banco Bilbao y Banco Vizcaya hoy unidos en el BBVA).

Tras la derrota carlista, Sabino Arana, un vizcaíno de famillia carlista acomodada, creó el Partido Nacionalista Vasco a fines del XIX (de derecha, católico) que llega a ser uno de los grandes partidos de Vizcaya (junto con la derecha y la izquierda «españolistas») cuando cae la monarquía española con la proclamaciónn de la Segunda República (1931). En 1936 se llega a la aprobación del estatuto de autonomía.

La guerra civil española, entre 1936 y 1939, dejó casi aislada a Vizcaya del gobierno de Madrid, lo que permitió al Gobierno de Euzkadi, con sede en Bilbao, una amplia autonomía. Pero la derrota de las fuerzas leales a la república (bombardeo de Guernica), trajo el régimen de Franco: represión de todo lo que era de izquierda, «rojo», o «separatista» (es decir, nacionalista vasco); declarada «provincia traidora» por el franquismo, Vizcaya perdió el resto de autonomía que le quedaba. 

Durante los años 50 y, sobre todo, 60, coincidiendo con la etapa del Desarrollismo, se produjo la segunda gran oleada de inmigrantes provenientes del resto de España que se trasladaron al País Vasco en busca de trabajo. Su elevado número y su mezcla con los autóctonos (parte de los cuales provenían de la primera oleada de inmigración de finales del siglo XIX) produjo la actual sociedad vasca.

Muerto el franquismo, como Franco, de vejez en 1975, con una sociedad que quería ser «europea», y no «diferente» como el franquismo, llega la democracia actual: Constitución Española de 1978 y autonomía con el Estatuto de Autonomía del País Vasco de 1979, que establece a Vizcaya como «territorio histórico» con una cierta autonomía.

El escudo tradicional del Señorío de Vizcaya muestra los lobos de la familia Haro, que recuerdan la batalla de Padura, y un roble, que se identifica como el Árbol de Guernica sede de las Juntas, al que se añadió una cruz.

El escudo oficial, definido por una Norma Foral prescinde de los lobos, pero dice «"No obstante lo dispuesto en la presente Norma Foral, se mantendrán los escudos existentes en aquellos edificios caracterizados por su valor histórico-artístico, así como las enseñas actualmente existentes como integrantes de la Historia del Pueblo de Vizcaya"», lo que permite la coexistencia de los dos escudos, el tradicional y el oficial.

La heráldica municipal de Vizcaya incorpora en numerosas armerías el motivo del árbol y los lobos, asociadas con elementos originales así como también, alusiones religiosas, especialmente cruces de San Andrés y figuras de San Miguel Arcángel; motivos vegetales como 
las típicas panelas, las ramas de roble, encinas o acebos; animales heráldicos, en particular el león, usado en ocasiones como soporte exterior, pero también marinos como la ballena; construcciones como torres, castillos y puentes, o las armas de familias nobiliarias asociadas a la historia de cada municipio. En algunos casos también se combinan las tradicionales armas vizcaínas con las de la corona de Castilla. Las actividades económicas de la agricultura y la pesca también son evocadas, junto con la industria pesada y naval.

Ubicación: situada al norte de la península ibérica, limita al oeste con la Comunidad Autónoma de Cantabria, al sur con la provincia de Burgos y el territorio histórico de Álava, al este con Guipúzcoa y al norte con el mar Cantábrico (golfo de Vizcaya). Su orografía es muy accidentada al encontrarse en la zona de unión de la Cordillera Cantábrica con los Pirineos. Es la quinta provincia más montañosa de España si se tiene en cuenta la pendiente media del terreno.

Extensión: 2217 km². Perímetro terrestre: 167 km, marítimo: 80 km.

Vías de acceso:

Clima: clima templado, oceánico, con mucha nubosidad a lo largo de todo el año. Precipitaciones abundantes y frecuentes, especialmente en otoño e invierno, con una media anual de 1200 mm. Las temperaturas son suaves tanto en verano como en invierno (14-15 °C de media anual).

Según el censo INE 2014, Vizcaya cuenta con 1 151 905 habitantes (denominados «vizcaínos») y su densidad de población es de 519,58 hab/km²; solo superada por la Comunidad de Madrid y Barcelona. Quinta provincia española por población en 1981, a pesar de la crisis demográfica que viene sufriendo desde la Transición, es aún la novena provincia española en número de habitantes. Debido a que desde principios de los 80 ha presentado un fuerte saldo migratorio negativo hacia otras regiones de España, contaba en el 2009 tan solo con un 5,7 % de extranjeros, al menos seis puntos menos que la media nacional.

Vizcaya ocupa la situación 32.ª del conjunto estatal en que existe un mayor porcentaje de habitantes concentrados en su capital (30,92 %, frente a 31,96 % del total).

Las instituciones y órganos forales de Vizcaya, como territorio histórico del País Vasco, son las Juntas Generales de Vizcaya y la Diputación Foral de Vizcaya.

Las Juntas Generales de Vizcaya son la asamblea unicameral que ejerce la potestad normativa del territorio histórico de Vizcaya. Sus miembros, denominados "apoderados", son elegidos mediante sufragio popular directo. Las elecciones tiene lugar cada cuatro años, coincidiendo con las elecciones municipales, en cuatro circunscripciones. 

Las Juntas Generales de Vizcaya tienen su salón de plenos en la Casa de Juntas de Guernica, y oficinas en Bilbao.

La composición de las Juntas tras las elecciones de 2015 es la siguiente:

La Diputación Foral ejerce la función ejecutiva y la potestad reglamentaria dentro del ámbito de competencias de Vizcaya.

La Diputación Foral de Vizcaya está formada por un Diputado General, actualmente Unai Rementería (PNV), elegido por las Juntas Generales, y por los demás diputados (no necesariamente miembros de las Juntas Generales) que designe el Diputado General hasta un máximo de diez.

Las normas emanadas de las Juntas Generales se denominan "Normas Forales" y son producto del poder legislativo con el que las Juntas Generales están investidas. Por su parte, la Diputación Foral puede emitir "Decretos Forales", de similar categoría a los Reales Decretos del Gobierno Central. Tanto las normas forales como los decretos forales tienen rango reglamentario y están sometidas, por tanto, a control de legalidad por parte de los Tribunales ordinarios, a excepción de las normas forales fiscales, que, por decisión del Tribunal Constitucional, tienen rango de Ley y sólo pueden ser controladas en consecuencia por este mismo Tribunal.

La gastronomía vasca goza de merecida reputación, no solo por el prestigio que en tiempos recientes han alcanzado cocineros como Juan Mari Arzak sino sobre todo por la variedad y arraigo de un extensísimo recetario popular. Por lo que respecta a la cocina vizcaína, íntimamente emparentada con su vecina guipuzcoana, destacan platos tan conocidos como el bacalao al pil-pil o a la vizcaína, el marmitako, el pisto a la bilbaina, los chipirones en su tinta o la merluza a la ondarresa. Buena muestra de la importancia de la gastronomía en la sociedad vizcaína y vasca es la abundancia de sociedades gastronómicas (conocidas como txokos en Vizcaya).

Su capital, Bilbao, es famosa por el Museo Guggenheim Bilbao y su ría.

Monumentos y lugares de interés:






</doc>
<doc id="11458" url="https://es.wikipedia.org/wiki?curid=11458" title="Provincia de Nueva Vizcaya">
Provincia de Nueva Vizcaya

Nueva Vizcaya (tagalo: "Bagong Biskaya"; inglés: "New Viscaya") es una provincia de Filipinas, perteneciente a la región de Valle del Cagayán.

La provincia de Nueva Vizcaya, tiene como cabecera a Bayombong, situada a 268 kilómetros al norte de Manila. 

Tiene una superficie de 437,880 hectáreas distribuida entre quince municipios con 275 barangays. Debido a sus características topográficas, menos de 20 por ciento de la tierra se usa para la agricultura.

La provincia tiene un clima relativamente fresco. La temperatura mínima registrada en Bayombong es de 12 grados Celsius y la máxima de 25 grados Celsius. Los meses más fríos son diciembre y enero y los más templados abril y mayo. 

Suele llover entre mayo y octubre. La estación seca abarca los meses de noviembre a febrero. 

La provincia de Nueva Vizcaya está compuesta de quince municipios con Bayombong como capital. Solano y Bambang son los centros comerciales mientras que Kayapa, debido a su clima muy fresco, es considerado su capital de verano. 

La provincia consiste en un distrito del congreso con dos sectores, el Norte y el Sur. El Sector Norte comprende siete municipios a saber Ambaguio, Bagabag, Bayombong (capital), Diadi, Quezón, Solano y Villaverde. El Sector Sur tiene por otro lado ocho municipios: Alfonso Castañeda, Aritao, Bambang, Dupax del Norte, Dupax del Sur, Kasibu, Kayapa y Santa Fe. 

La población de la provincia es de 334,965 personas según censo de 1995. El 56% de la población se dedica a la agricultura. Hay un 20 por ciento de desempleados.

Políticamente se divide en 15 municipios y ninguna ciudad. Cuenta con 275 barangays. 
Consta de un único distrito para las elecciones al Congreso.
La provincia se creó como una provincia político-militar separada en tiempos del Gobernador español, Luis Lardizabal a través de un Decreto Real por el Rey de España el 10 de abril de 1841.
Se trataba entonces de uno de los Gobiernos político militares de la isla de Luzón. "Confinaba al norte con La Isabela, al este y al sur con el Distrito de El Príncipe, al sur con Nueva Ecija y al oeste con Benguet y Pangasinán. Era su capital Bayombong". 

Habitada por los Igorotes, Ifugaos, Ilongotes, y Alaguetes (Aetas o Negritos). Las tribus salvajes llevaron una vida nómada y sobrevivían recorriendo la zona desértica de la Cordillera, las regiones de Ilongote y la Sierra Madre.

Estas tribus fueron objeto de expediciones religiosas dirigidas por los dominicos y los misioneros agustinos. España administró la provincia a través de las misiones de Ituy y Paniqui. La misión de Ituy que cubría la parte sur estaba principalmente habitada por el Isinays mientras la misión de Paniqui que cubría la parte norte por el Gaddangs. 

El año 1877 tenía una extensión de 40.650 hectáreas y estaba habitada por 32,209 humanos distribuidos en 8 pueblos: Bayombong (capital con 2,897 almas), Bambang, Dupax, Aritao, Solano, Bagabag, Diadi e Ibung y 3 rancherías: Silipan, Ibuag y Lagavia, sin contar las tribus alzadas que pueden clasificarse como sigue:

A finales del siglo XIX la provincia de Nueva Vizcaya comprendía la Comandancia de Cayapa.

Debido a los recursos naturales ricos, Nueva Vizcaya atrajo a corrientes migratorias de otras partes del país. Ilocanos, Tagalos, Pangasinenses, Pampangos, Ibanas, Ibontocs y Batangueños. Otros incluso vinieron de lugares tan lejanos como las islas Bisayas y de Mindanao.


</doc>
<doc id="11459" url="https://es.wikipedia.org/wiki?curid=11459" title="Valle del Cagayán">
Valle del Cagayán

El Valle del Cagayán (ilocano: "Tanap ti Cagayán") es una región de Filipinas, también denominada Región II. Está compuesta por las provincias de Batanes, Cagayán, Isabela, Nueva Vizcaya y de Quirino. La capital regional es Tuguegarao.

La mayoría de la región se encuentra en un gran valle en el noreste de Luzón, entre la Cordillera Central y la Sierra Madre. El río Cagayán, el más largo del país, fluye por su centro y desemboca en el estrecho de Luzón en el norte, en el pueblo de Aparri. Los grupos de islas de Babuyan y Batanes pertenecen también a la región.

Las cinco provincias cuentan con 3 ciudades, 90 municipios y 2.311 Barangays.
A finales del siglo XIX la provincia de Cagayán comprendía las comandancias de Apayaos, Cabugaoan e Itaves.


</doc>
<doc id="11462" url="https://es.wikipedia.org/wiki?curid=11462" title="Trópico de Cáncer">
Trópico de Cáncer

El trópico de Cáncer es uno de los paralelos del planeta que están ubicados en el hemisferio norte. Es el paralelo situado a una latitud de 23º 26′ 14″ al norte del ecuador. 

Se está desplazando hacia el sur a un ritmo de casi medio segundo (0,46 s) por año (en el año 1917 estuvo en 23° 27').

Esta línea imaginaria delimita los puntos más septentrionales en los que el Sol alcanza el cénit (la vertical del lugar), lo que ocurre entre el 20 y el 21 de junio de cada año, a lo que se le denomina como solsticio de junio. En tablas astronómicas, la fecha y la hora de este evento se señalan en tiempo universal coordinado (UTC).

En el instante en que ocurre el solsticio de junio, los rayos solares caen verticalmente sobre el suelo en la línea imaginaria del trópico del hemisferio norte. En el solsticio de diciembre, lo hacen sobre el trópico del hemisferio sur

El trópico de Cáncer señala el límite septentrional de la llamada Zona Intertropical, comprendida entre los trópicos de Cáncer y Capricornio.

Se le denomina «de Cáncer» porque en la Antigüedad, cuando se producía el solsticio de verano en el hemisferio norte, el Sol estaba en la constelación de Cáncer. En la actualidad está en la constelación de Tauro, muy cerca del borde de la constelación de Géminis. La palabra "tropos" proviene del griego y significa "devolver", señalando así que en los solsticios, el Sol aparenta devolverse.

Según la dinámica de la precesión de los solsticios (y de los equinoccios) hace un poco más de 20 siglos el punto solsticial estaba al final de la constelación de Cáncer. La siguiente constelación a la de Cáncer en sentido precesional es la de Géminis que abarca 28º de la Eclíptica, y el punto solsticial avanza 1º cada 71,6 años. Así, durante los últimos 20 siglos el punto solsticial ha atravesado Géminis y actualmente ha ingresado ya en Tauro, situándose en su primer grado.

Por esto en el trópico a mediodía se reciben los rayos procedentes del Sol situado hacia Tauro y por ello éste sería el nombre astronómico del trópico, un nombre que nos aporta información astronómica y de la dinámica de la precesión del punto solsticial estival de la Tierra. Así mismo podemos llamar al solsticio como «Solsticio de Tauro». Igualmente ocurriría con el otro solsticio y el trópico de Capricornio.

El trópico de Cáncer pasa a través de los siguientes países, partiendo del océano Atlántico hacia el este:


De acuerdo a las reglas establecidas por la Fédération Aéronautique Internationale, para que un vuelo se califique para competir por el récord de velocidad alrededor del mundo:

Para calcular la longitud del trópico:




</doc>
<doc id="11463" url="https://es.wikipedia.org/wiki?curid=11463" title="Trópico">
Trópico

Trópico proviene del latín "tropĭcus", y éste del griego "τροπικός" ["tropikós"], que significa ‘tropico’. El plano horizontal en el cual se produce el movimiento de traslación de la Tierra alrededor del Sol se conoce como plano de la eclíptica. Ya que el eje de rotación de la Tierra no es perpendicular al plano de la eclíptica, la intersección de este plano con la esfera no coincide con el plano ecuatorial terrestre. La latitud máxima a la que la eclíptica corta a la esfera terrestre es de 23º 26′ 14″ N y 23º 26′ 14″ S (en 2015 y 2016); por lo que los paralelos que pasan por estas latitudes tienen una relevancia especial y se les conoce como trópico de Cáncer (en el hemisferio norte) y trópico de Capricornio (en el hemisferio sur).

La región comprendida entre los dos trópicos se conoce como zona intertropical, tórrida o tropical aunque la primera denominación tiende a reemplazar a las dos últimas en aras de la exactitud; desde el punto de vista biogeográfico, los trópicos pueden extenderse más allá de los paralelos de Cáncer y Capricornio, v. gr., la península de la Florida en los Estados Unidos yace en los subtrópicos (latitud mayor a 23º26'N) pero aloja muchas especies características de los trópicos del nuevo mundo, en parte debido al efecto atemperante del clima que brinda la corriente del Golfo. Igualmente, los valles medio y bajo del río Paraná son subtropicales pero hacen parte de la región biogeográfica neotropical que incluye la Patagonia y demás regiones australes del continente. De la misma forma, y en sentido inverso, también los climas secos de las zonas subtropicales (inmediatamente al norte del trópico de Cáncer o al sur del trópico de Capricornio) pueden extenderse dentro de la zona intertropical en las costas occidentales de los continentes. Estas observaciones se justifican por el hecho de que las líneas de los trópicos constituyen un concepto matemático (geométrico, más propiamente), mientras que los conceptos de clima o de la biogeografía, son netamente geográficos y la latitud apenas es uno de los cinco factores que modifican estos conceptos.

La zona intertropical húmeda es un mundo con mucha lluvia que es bueno para la agricultura. Toda esta zona tropical ocupa el 20 % de la tierra emergida, representando el 40 % de la tierra útil para el ser humano, y acoge a algo más del 40 % de la población mundial, aunque con una desigual distribución en el territorio.



</doc>
<doc id="11465" url="https://es.wikipedia.org/wiki?curid=11465" title="Islas de Barlovento">
Islas de Barlovento

Las islas de Barlovento son un grupo de islas de América que acotan al este la cuenca del mar Caribe, integrado por las islas septentrionales de las Pequeñas Antillas. Algunas de las islas principales son Granada, Martinica, Santa Lucía, Barbados, Guadalupe, Dominica, Trinidad y Tobago.

Las islas de Barlovento fueron llamadas así porque estaban más a barlovento (en la dirección de origen del viento) de las naves que venían al Nuevo Mundo que las islas de Sotavento, dado que los vientos que prevalecen en esa zona soplaban en el sentido de este a oeste. Las corrientes transatlánticas y los vientos que producían la ruta más rápida a través del océano llevaban a las naves primero a estas islas ubicadas en el sureste de las Antillas para luego continuar a su destino final en el Caribe o Norteamérica.

Las islas de Barlovento son, de norte a sur, las siguientes:



</doc>
<doc id="11466" url="https://es.wikipedia.org/wiki?curid=11466" title="Islas de Sotavento">
Islas de Sotavento

Las islas de Sotavento son un grupo de islas de las Antillas Menores, integrado por diversas islas repartidas entre los Países Bajos y Venezuela, y situadas frente a las costas de este último país y sobre la plataforma continental sudamericana. 

Es importante resaltar que la clasificación anglosajona de estas islas varía con respecto a la del resto del mundo, por lo que algunas islas clasificadas como de Sotavento o Barlovento pueden variar según la fuente que se consulte.

Existe una importante diferencia en la consideración de que islas pertenecen al grupo de Barlovento o Sotavento, según sea el ámbito lingüístico, de un lado el inglés y de otro el español, francés y neerlandés.

Las islas de Sotavento son, de occidente a oriente, las siguientes:



</doc>
<doc id="11467" url="https://es.wikipedia.org/wiki?curid=11467" title="Antillas Mayores">
Antillas Mayores

Las Antillas Mayores o Grandes Antillas son un grupo de islas en el norte del mar Caribe, localizadas al este de Yucatán (México) y sureste de la Florida (Estados Unidos) y al oeste de las Antillas Menores. El grupo está compuesto por Cuba, Jamaica, La Española (que incluye a República Dominicana y Haití), y Puerto Rico. Las Bahamas, si bien vecinas, no integran esta unidad geográfica junto con las Islas Turcas y Caicos, Islas Caimán y las Bermudas.

Las Antillas Mayores constituyen casi el 90% de la masa de tierra de todas las Indias Occidentales, así como más del 90% de su población. El resto de la tierra pertenece a las Bahamas y al archipiélago de las Antillas Menores, que es una cadena de islas al este (que se extiende de norte a sur y abarca el borde oriental del Mar Caribe, donde se encuentra con el Océano Atlántico) y al sur (que se extiende de este a oeste desde la costa norte de América del Sur).

La palabra "Antillas" se originó en el período anterior a la conquista europea del Nuevo Mundo. Los europeos usaron el término "Antilia" como una de las tierras misteriosas que aparecen en las cartas medievales, a veces como archipiélago, a veces como tierra continua de mayor o menor extensión, fluctuando su ubicación en medio del océano entre las Islas Canarias y Eurasia.

Las Grandes Antillas descansan sobre un macizo submarino común y están atravesadas por una cadena abrupta y elevada de montañas, cuyos picos más altos oscilan entre 2.000 y 3.000msnm (metros sobre el nivel del mar) que culminan en la República Dominicana (en el Pico Duarte con 3.087msnm) y declina, a ambos lados, en Cuba, Jamaica y Puerto Rico. Esas montañas están compuestas de piedra caliza, con afloramiento de otras rocas, todas ellas mucho más antiguas que las de origen eruptivo de las Pequeñas Antillas y sin huellas de actividad volcánica reciente. Las Bahamas, por el contrario, son islas de origen coralino. Antiguamente a las Bahamas ni siquiera se las consideraba como parte de las Antillas, aunque en la actualidad está difundido su englobamiento como un tercer grupo dentro de las mismas (Grandes Antillas, Pequeñas Antillas y las Bahamas).
La República Dominicana es la que más se destaca entre las Antillas Mayores y una de las más importante, ya que se encuentran, los ríos más largos (Río Artibonito), el punto más bajo y el lago más grande de las Antillas (Lago Enriquillo).

Las Grandes Antillas están en una parte de América Central llamada Archipiélago Antillano y están bañadas por el mar Caribe y el océano Atlántico.

Algunos de los recursos minerales que podemos encontrar en las Antillas Mayores son: bauxita,
oro, cobre, hierro, plata, mármol, entre otros.

Las grandes Antillas están divididas desde el punto de vista administrativo en 4 países independientes y 2 dependencias.


</doc>
<doc id="11470" url="https://es.wikipedia.org/wiki?curid=11470" title="Artesano">
Artesano

Un artesano es la persona que realiza objetos artesanales o artesanías. Los artesanos realizan su trabajo a mano o con herramientas manuales, por lo que hay que tener cierta destreza y habilidad para realizar su trabajo. Pueden trabajar solos o junto a otras personas que les pueden servir de ayudantes o aprendices.

Los objetos producidos suelen tener un valor estético y/o utilitario. El artesano puede vender, a título personal o a terceros sus creaciones, las cuales produce en su "taller", a pie de calle, en un puesto de artesanía o en el taller de un maestro artesano, cuando trabaja como empleado. 

Los artesanos y su trabajo suelen forman parte del folclore de su lugar de origen, utilizan materiales típicos de su zona para fabricar sus productos o se inspiraran en motivos tradicionalmente lugareños. Cada cual suele tener sus materiales preferentes, que en muchos casos imprimen un estilo especial a sus creaciones; entre los materiales que utilizan se incluyen: conchas marinas spondylus, algas, granos de arroz, cuarzo, maderas específicas, piedras, huesos, incluso fósiles u otros elementos que el propio artesano recoge y elige en playas o campos, etc.

La palabra "artesano" viene del italiano "artigiano" (significando 'que ejerce un arte mecánico'), y este término viene del latín "ars", "artis". El latín nos dio arte en castellano, el que viene de la raíz indoeuropea "ar" (significando 'mover, ajustar, hacer actuar'). Es solo a partir de finales del siglo XV, durante el renacimiento Italiano, cuando por primera vez se hace la distinción entre el artesano y el artista, esta diferencia da lugar a la figura del artista.




</doc>
<doc id="11472" url="https://es.wikipedia.org/wiki?curid=11472" title="Cerámica">
Cerámica

Cerámica (procedente del griego antiguo "κεραμική" (keramiké), femenino de "κεραμικός" ("keramikós", ‘hecho de arcilla’), "cerámico", que designaba al barrio de los alfareros de la antigua Atenas, al noroeste de la Acrópolis), es el arte de fabricar vasijas y otros objetos de arcilla u otro material cerámico por acción del calor, es decir cocida a una temperatura superior a los 400 o 500 grados. El resultado es una diversa variedad de piezas u objetos de terracota —o alfarería «de basto»—, de loza y del conjunto de porcelanas. Además de denominar la técnica y su actividad, también da nombre al conjunto de objetos y producción.

Su uso inicial fue la fabricación de recipientes empleados para contener alimentos o bebidas. Más adelante se utilizó para modelar figurillas de posible carácter simbólico, mágico, religioso o funerario. También se empleó como material de construcción en forma de ladrillo, teja, baldosa o azulejo, conformando muros o revistiendo paramentos. La técnica del vidriado aumentó su atractivo suntuario y su uso arquitectónico. A partir del siglo XIX se aplicó a la industria como aislante eléctrico y térmico en hornos, en motores y en blindajes. La moderna cerámica se aplica a las industrias de silicatos (grupo de minerales de mayor abundancia, pues constituyen más del 95 % de la corteza terrestre) y como complemento en tecnologías de construcción asociada al cemento. También es la base de las técnicas de esmaltes sobre metal.

Existe cierta confusión, provocada desde el propio contexto de la investigación a partir del siglo XVIII, entre los conceptos alfarería y cerámica, llegando a generar un incómodo conflicto semántico (semántica lógica). Las dos palabras se usan indistintamente para nombrar las actividades artesanales, artísticas e industriales a partir del barro cocido, así como el producto o los productos de las mismas y su cultura.

La propuesta de los diccionarios (ideológicos y de sinónimos) y los manuales léxicos no ayuda a resolver la disyuntiva cuando «alfarería» aparece redirigida o referida a «cerámica», dándosele así a esta última mayor valor troncal. En el capítulo de las etimologías se indica que "Alfarería", como alfar, provienen del árabe hispánico "alfah hár", y este del árabe clásico "fah har" ‘alfarería’, y a su vez del hebreo "hhafar" ‘tierra, barro’. Por su parte, "Cerámica" procede del griego antiguo "κεραμική" (keramiké), femenino de "κεραμικός", "keramikós" ‘hecho de arcilla’; “cerámico”, que designaba originalmente al barrio de los alfareros de la antigua Atenas, al noroeste de la Acrópolis.
A comienzos del siglo XVI, el humanista Antonio de Nebrija ya mencionaba el término griego "ceramion" en un contexto amplio. Pero se ha atribuido al arqueólogo Giovanni Battista Passeri la responsabilidad de incluir la voz "cerámica" en el contexto lingüístico moderno, al usarlo en una obra impresa en Venecia en 1768. Joan Corominas completa el seguimiento del término y su uso explicando que dicho vocablo llegó a España en 1869, justo un siglo después de la propuesta de Passeri.

Las definiciones con más peso oficial, tras admitir que ambos términos designan el arte de elaborar objetos de barro, relacionan la alfarería con los espacios de fabricación y venta, y a la cerámica con el conjunto de objetos y sus vertientes científicas asociadas a la arqueología.

En un manual clásico de términos de arte, ambos términos se relacionan con el «arte y técnicas del barro y la arcilla»; dándole preferencia a la alfarería en esta acepción y reservando a cerámica la definición de los objetos fabricados con dichas características y haciéndolo extensivo a otros términos más concretos como: loza, porcelana, mayólica y terracota.


Además de las diferenciaciones según aspectos geográficos, lingüísticos, sociológicos, económicos, se ha clasificado:

La base y los materiales arqueológicos para dichas clasificaciones y su investigación, por convención, son los diferentes productos del trabajo alfarero. Estructuralmente se han propuesto tres fases de investigación: la "histórico-artística" (del siglo XV a 1880) cuando se trata de vasos completos, la "tipológica" (de 1880 a 1956) en el caso de que sean fragmentos, y la fase "contextual" (de 1956-60 en adelante) cuando se parte de muestras microscópicas o se trabaja con conjuntos de muestras.

Existen varias razones por las que se considera muy importante el estudio de las cerámicas en comparación con el resto del registro arqueológico:


Cuando nos enfrentamos al análisis de un objeto cerámico debemos tener en cuenta que éste va a ser una aproximación a la historia total del artefacto, desde su producción a su deposición y alteraciones posteriores, y que esta historia contiene información desde un nivel puramente estético a un nivel relacionado con el grado de tecnología de estas comunidades, las posibles funciones de las cerámicas (uso doméstico, ritual, simbólico...), la procedencia de las mismas (intercambio, producción autónoma, etc.).

Este argumento ha traído como consecuencia la superación de la fase llamada crono-tipológica en los estudios cerámicos, que había llegado a un punto de estancamiento por no ser capaz de dar más información que la puramente descriptiva.

De este modo, se recurrió a otras disciplinas para poder llegar a incrementar los niveles de información recuperable que no podían extraerse con ningún otro medio arqueológico.

Por otro lado es muy importante tener en cuenta que el estudio de las cerámicas ha de realizarse siempre teniendo en cuenta el contexto en el que han sido halladas (con qué otros elementos arqueológicos estaban, que disposición en el espacio tenían respecto a los demás elementos y su posición estratigráfica, en qué tipo de estructuras estaban, si están en un asentamiento, en una necrópolis, en un área de producción, etc.). Aisladas del mismo, la información es mucho más reducida y prácticamente se limita a su datación relativa y posible función.

La importancia de los datos proporcionados por las distintas técnicas de análisis no tienen relevancia arqueológica directa si no es por que se estudian como fruto de un sistema humano de conducta, como un producto humano (se han llegado a hacer análisis del tipo de medidas de diámetro, estadísticas, reagrupamientos con análisis Cluster, etc, para al final decir que tal conjunto cerámico es de tal período o tal cultura), una conducta que puede inferirse de ellos, y que en última instancia son los que interesan en la investigación arqueológica.

Por ello, en la investigación hay que partir en primer lugar de un marco teórico que sea el que dote de significado los estudios analíticos que se emprendan, en un intento de integrar la información de la composición de las cerámicas y la información cultural, buscando así la interrelación entre las aproximaciones experimentales y las arqueológicas.

La caracterización de una cerámica, al igual que la tipología, no tiene un valor más que puramente descriptivo si no tiene un marco teórico que dote de significado a estos estudios analíticos.

Los estudios tecnológicos de las cerámicas fueron aplicados en un primer momento fuera de España. Estos no sólo se pueden quedar en darle un carácter científico a una publicación, sino que hay que interpretar los datos para poder responder a hipótesis previas.

Con la caracterización de un objeto cerámico se intenta determinar los constituyentes de su materia prima con el fin de poder llegar a realizar inferencias sobre aspectos tecnológicos que nos informan sobre su proceso de manufactura, y también son susceptibles de informarnos sobre la posible procedencia de los mismos.

Esta información puede ser muy valiosa para detectar patrones de producción o de intercambio y comercio, así como para documentar datos sobre factores socio-económicos y culturales. Los resultados serán más valiosos si trabajamos con cerámicas bien contextualizadas.

Al estudiar la naturaleza de la materia prima, el fin principal por lo tanto es la tecnología y su procedencia.

Aunque ambas cuestiones debieran jugar un papel semejante, se ha puesto mayor énfasis en los aspectos relacionados con la procedencia de las cerámicas, (más de un tercio de los trabajos en todo el mundo). Para ello se lleva a cabo un estudio del entorno geológico en donde se ha hallado la cerámica y se recogen sedimentos arcillosos potencialmente utilizables dentro del área geográfica del estudio, como apoyo y contrastación de los resultados analíticos obtenidos con la caracterización de las cerámicas.

Las materias primas de la cerámica son la arcilla, el desgrasante o clastos y el agua.

La arcilla es llamada fracción fina de un suelo o sedimento, siendo el conjunto de partículas minerales que tienen un diámetro de dos micras o menos. Algunos autores prefieren denominar la materia prima de la cerámica como tierras, porque las arcillas seleccionadas nunca son puras, están mezcladas con elementos minerales de mayor tamaño o fracciones gruesas, no plásticos o desgrasante. Es decir, aunque el mayor porcentaje de material sea arcilla, no lo es todo. También contienen limos y arenas en cantidades variables que serán factores determinantes respecto al tipo de textura.

La razón de que se use la arcilla es por su propiedad plástica, sus facultades de moldeo en el estado pastoso pero dureza en el estado cocido.

El desgrasante se añade o ya va incluido en las arcillas para que sirva de armazón y de solidez a la parte plástica de la cerámica (arcilla y agua). Las arcillas tienen una gran capacidad de absorción de agua, no sólo la intrínseca sino también la añadida por el alfarero para darle plasticidad y poder moldearla (supone el 18-25 % del total). Si se le echa poca agua se fragmenta y si se le echa mucha ya no es plástica.

El desgrasante suele ser más visible en la pared interior, ya que en la exterior normalmente se procede a un acabado final de alisamiento por motivos estéticos y prácticos (por ejemplo para evitar en lo posible la porosidad).

Los desgrasantes pueden ser minerales (cuarzo, calcita, feldespato, esquisto, mica, etc), orgánicos (carbón, vegetales, cereales, hojas), animales (conchas, fragmentos de hueso), y trozos de cerámica, fragmentos de sílex, etc.

Su tamaño puede ser de fracción gruesa, 2mm, media, de 2 a 1mm, o fina, 1mm.

El tipo de desgrasante en ocasiones era seleccionado según la función que fuese a cumplir la vasija. Para las que tenían que soportar altas temperaturas, como los crisoles por ejemplo, añadían gran cantidad de cuarzo; para las de actividad de cocina le añadían mayor cantidad de minerales desgrasantes que a las rituales o de enterramientos (estas últimas suelen tener unas pastas con el desgrasante más fino). Si requerían alta porosidad para transpirar (para contener agua, aceite, leche) se utilizaban desgrasantes orgánicos, ya que éstos al cocerse la cerámica desaparecen y dejan los huecos.

Se pueden hacer estudios, incluso dentro de un mismo yacimiento, sobre cómo va variando la cerámica a lo largo del tiempo en relación a su mayor o menor calidad, su forma, su función, etc., y deducir, por ejemplo, que el cambio está motivado por un cambio en la dieta o por otros aspectos y el por qué (por contacto con otros grupos, por evolución interna en el tipo de producción inducido por un cambio en el medio, por nuevas técnicas de producción, por un nuevo modo de vida nómada o sedentaria, etc.).

Asimismo se pueden hacer estudios de la procedencia de los minerales: si se trata de esquinas redondeadas o cantos desbastados procede normalmente de las márgenes de un río o de depósitos fluviales. En el estudio concreto de la cerámica neolítica granadina, la presencia de mica dorada era un detector clave del lugar de procedencia del sedimento (Sierra Nevada).

El tipo de resistencia mecánica de la cerámica puede ser también un indicador importante: si se trata de una cerámica con arcilla muy fina y cocida a altas temperaturas, su resistencia es alta en tanto que si la densidad es baja y tiene alta porosidad, puede indicar cierto grado de arcaísmo.

Existen distintas técnicas de modelado:


La historia de la cerámica va unida a la historia de casi todos los pueblos del mundo. Abarca sus mismas evoluciones y fechas y su estudio está unido a las relaciones de los seres humanos que han permitido el progreso de este arte.

La invención de la cerámica se produjo durante el neolítico, cuando se hicieron necesarios recipientes para almacenar el excedente de las cosechas producido por la práctica de la agricultura. En un principio esta cerámica se modelaba a mano, con técnicas como el "pellizco", el "colombín" o la placa (de ahí las irregularidades de su superficie), y tan solo se dejaba secar al sol en los países cálidos y cerca de los fuegos tribales en los de zonas frías. Más adelante comenzó a decorarse con motivos geométricos mediante incisiones en la pasta seca, cada vez más compleja, perfecta y bella elaboración determinó, junto con la aplicación de cocción, la aparición de un nuevo oficio: el del alfarero.

Según las teorías difusionistas, los primeros pueblos que iniciaron la elaboración de utensilios de cerámica con técnicas más sofisticadas y cociendo las piezas en hornos fueron los chinos. Desde China pasó el conocimiento hacia Corea y Japón por el Oriente, y hacia el Occidente, a Persia y el norte de África hasta llegar a la Península Ibérica. En todo este recorrido, las técnicas fueron modificándose. Esto fue debido a ciertas variantes; una de ellas fue porque las arcillas eran diferentes. En China se utilizaba una arcilla blanca muy pura, el caolín, para elaborar porcelana, mientras que en Occidente estas arcillas eran difíciles de encontrar. Otras variantes fueron los motivos decorativos y los diferentes métodos utilizados para la cocción.

El invento del torno de alfarero, ya en la Edad de los Metales, vino a mejorar su elaboración y acabado, como también su cocción al horno que la hizo más resistente y amplió la gama de colores y texturas. En principio, el torno era solamente una rueda colocada en un eje vertical de madera introducido en el terreno, y se la hacía girar hasta alcanzar la velocidad necesaria para elaborar la pieza. Poco a poco fue evolucionando, se introdujo una segunda rueda superior y se hacía girar el torno mediante un movimiento del pie; posteriormente se añadió un motor, que daba a la rueda diferente velocidad según las necesidades.

A menudo la cerámica ha servido a los arqueólogos para datar los yacimientos e, incluso, algunos tipos de cerámica han dado nombre a culturas prehistóricas. Uno de los primeros ejemplos de cerámica prehistórica es la llamada cerámica cardial. Surgió en el Neolítico, debiendo su denominación a que estaba decorada con incisiones hechas con la concha del "cardium edule", una especie de berberecho. La cerámica campaniforme, o de vaso campaniforme, es característica de la edad de los metales y, más concretamente, del calcolítico, al igual que la cerámica de El Argar (argárica) lo es de la Edad del Bronce.

Los ceramistas griegos trabajaron la cerámica influenciados por las civilizaciones del Antiguo Egipto, Canaán y Mesopotamia. Crearon recipientes con bellas formas que cubrieron de dibujos que narraban la vida y costumbres de su época. La estética griega fue heredada por la Antigua Roma y Bizancio, que la propagaron hasta el Extremo Oriente. Se unió después a las artes del mundo islámico, de las que aprendieron los ceramistas chinos el empleo del bello azul de cobalto.

Desde el norte de África penetró el arte de la cerámica en la Península Ibérica, dando pie a la creación de la loza hispano-morisca, precedente de la cerámica mayólica con esmaltes metálicos, de influencia persa, y elaborada por primera vez en Europa en Mallorca (España), introducida después con gran éxito en Sicilia y en toda Italia, donde perdió la influencia islámica y se europeizó.

El torno y el horno son los elementos fundamentales e importantes para la fabricación de la cerámica. Se necesita además pinceles y varillas para la decoración. Las principales herramientas o utensilios son:

Las distintas técnicas que se han ido utilizando han dado como resultado una gran variedad de acabados:

La materia prima es la arcilla. Se emplea agua, sílice, plomo, estaño y óxidos metálicos. Para la cerámica llamada gres se utiliza una arcilla no calcárea y sal. Otro material importante para otro tipo de cerámica es el caolín mezclado con cuarzo y feldespato. También se emplea el polvo de alabastro y mármol. Para las porcelanas se utilizan los óxidos de potasio, magnesio y aluminio.

Tanto antes como después de ser cocida, la pieza de alfarería puede ser adornada sometiéndola a diferentes técnicas de decoración:

La fabricación de componentes cerámicos tiene lugar de la siguiente manera:

Los materiales son buenos aislantes térmicos y que además tienen la propiedad de tener una temperatura de fusión y resistencia en compresión elevadas. Asimismo, su módulo de Young (pendiente hasta el límite elástico que se forma en un ensayo de tracción) también es muy elevado (lo que llamamos fragilidad).

Todas estas propiedades hacen que los materiales sean imposibles de fundir y de mecanizar por medios tradicionales (fresado, torneado, brochado, etc). Por esta razón, en las cerámicas realizamos un tratamiento de sinterización. Este proceso, por la naturaleza en la cual se crea, produce poros que pueden ser visibles a simple vista. Un ensayo a tracción, por los poros y un elevado módulo de Young (fragilidad elevada) y al tener un enlace iónico covalente, es imposible de realizar.

Existen materiales cuya tensión mecánica en un ensayo de compresión puede llegar a ser superior a la tensión soportada por el acero. La razón, viene dada por la compresión de los poros/agujeros que se han creado en el material. Al comprimir estos poros la fuerza por unidad de sección es mayor que antes del colapso de los poros.

Las propiedades de un material cerámico dependen de la naturaleza de la arcilla empleada, de la temperatura y de las técnicas de cocción a las que ha sido sometido. Así tenemos:




</doc>
<doc id="11473" url="https://es.wikipedia.org/wiki?curid=11473" title="Botijo">
Botijo

Un botijo (también boteja en Hispanoamérica y "búcaro" en gran parte de la España meridional) es un recipiente de barro cocido poroso, diseñado para beber y conservar fresca el agua. En alfarería se define como vasija de cuerpo esferoide, un asa en su parte superior, y con dos o más orificios. Por lo general se llama "boca" al más ancho -por el que se llena-, y "pitón o pitorro" al otro, que produce un fino chorrillo ideal para beber sin demasiado desperdicio.

El botijo es un objeto típico de la cultura española, habitual en Castilla, Aragón y el tercio sur de la península (Extremadura, La Mancha, Levante y Andalucía), como en las zonas más húmedas del norte o el territorio insular.

El ejemplar más antiguo aparecido en la península ibérica pertenece a la cultura argárica y fue hallado en la necrópolis de Puntarrón Chico (Beniaján), cercana a la capital de la región murciana, en cuyo museo arqueológico se conserva; pieza importante en la historiografía de la cerámica por tratarse de una 'obra cerrada', con un solo orificio de 2 cm y el asa colocada en la parte superior; la medida del botijo es de 11 x 9,5 cm.

El principio de funcionamiento del botijo es el siguiente: el agua almacenada se filtra por los poros de la arcilla y en contacto con el ambiente seco exterior (característica del clima mediterráneo) se evapora, produciendo un enfriamiento (2,219 kilojulios por gramo de agua evaporada). La clave del enfriamiento está, por lo tanto, en la evaporación del agua exudada, ya que ésta, para evaporarse, extrae parte de la energía térmica del agua almacenada dentro del botijo.

En algunas regiones, antes de usarlo por primera vez, se "cura" dejándolo durante un par de días lleno de agua y con un poco de anís. En zonas de litoral, para curar el barro se introducen algunos cantos marinos por la boca de carga, se dejan en agua unos días y se enjuaga bien para que no quede regusto a sal. 

Al margen de la RAE, se sabe que existió el término latino "buttis", botella, tonel, y luego el latín medieval "butticula". Probablemente la mezcla de voces romances de origen latino con otras de la cultura mozárabe formaron su tronco etimológico.

Sebastián de Covarrubias en el año 1611, describe "botija", como "vaso de tierra ventrudo con la boca y cuello angosto. Los niños cuando están para llorar hinchan los carrillos y a esto le llaman embotijarse".

En la geografía española, el botijo recibe distintos nombres: en el sur y suroeste de España se alterna con términos como boteja o botejo, "búcaro", "cachucho", "pimporro" o piporro, "pipo" o pipote, "pirulo" en las vegas de Granada y el Guadalquivir, "ñañe" y "pichilín" en Huelva, "piche" en Extremadura. En Aragón "rallo". En valenciano "botija" (se pronuncia ‘boticha’, plural) y diminutivo "boticheta", documentada en obras de teatro desde 1850.
En Vascongadas, "txongila" en Cegama (Guipúzcoa) y "càntir", Cataluña que aglutina una variada familia de modelos y tipos.
La alfarería catalana celebra una feria anual en la localidad barcelonesa de Argentona que cuenta con uno de los mejores museos monográficos dedicados a botijos cerámicos.
Otras piezas de alfarería de agua de la familia del botijo son, por ejemplo, el barril y la botija de carro, con su forma panzuda y el pitorro como si fuera el ombligo, con la espalda plana, para poder colgarla del carro. Existe, asimismo, una gran variedad de cantarillas y botijas.

En 1995, Gabriel Pinto y José Ignacio Zubizarreta de la Universidad Politécnica de Madrid desarrollaron un modelo matemático para un botijo esférico. Dos ecuaciones diferenciales describen el proceso:

donde:

Joaquín Sorolla, pintor luminista valenciano, pintó al menos en dos ocasiones un botijo blanco, similar a los de Agost. Hacia 1905, en un óleo titulado precisamente "El botijo", en el que una muchacha ayuda a un niño a beber de él. El cuadro, vendido originalmente a un particular y a pesar de no ser especialmente representativo de su obra, fue una de las pinturas seleccionadas en 1964 para la serie filatélica dedicada a Sorolla, llevando la imagen del botijo español hasta los más recónditos confines postales del planeta. Años después, un botijo similar aparece en el lado izquierdo de una de las muchas escenas íntimas captadas por Sorolla en las playas valencias: "Madre e hija. Playa de Valencia", de 1916. 




</doc>
<doc id="11474" url="https://es.wikipedia.org/wiki?curid=11474" title="Real Fábrica de Sargadelos">
Real Fábrica de Sargadelos

La cerámica de Sargadelos es una famosa cerámica elaborada en Sargadelos (en el municipio lucense de Cervo, Galicia, España). La primera fábrica fue creada a principios del siglo XIX por Antonio Raimundo Ibáñez y que tras varias generaciones acabó cerrando en 1875. A partir de mediados del siglo XX Sargadelos forma parte de un grupo de empresas del sector, el "grupo Sargadelos" —al que pertenece igualmente la cerámica de Castro-Sada— gracias al impulso del ceramista Isaac Díaz Pardo, basada en coloraciones en tonos azulados.

Antonio Raimundo Ibáñez, notable enciclopedista de familia hidalga de escasos recursos, dedicado desde muy joven a negocios de importación y exportación, introdujo innovaciones tecnológicas para sus fábricas. Asentado en Ribadeo, inició una industria siderúrgica, y en el año 1806 creó conjuntamente una manufactura de cerámica que estuvo en sus primeros tiempos dedicada a la fabricación de loza fina para vajillas con estampación e influida de la loza inglesa, en aquel tiempo muy valorada. En 1808, tras el éxito de la inauguración de la fábrica de cerámica, Carlos IV le condecoró con la cruz de la Orden de Carlos III, otorgándole los títulos de marqués de Sargadelos y conde de Orbaiceta.

Como consecuencia de la guerra de la Independencia y sus sucesos revolucionarios, Antonio Raimundo Ibáñez fue asesinado el año 1808, sucediéndole en el cargo de la fábrica su cuñado Francisco Acevedo, quien contrató para la dirección de la misma al portugués Antonio Correa de Saa. 

A partir de esta nueva dirección la fábrica produjo un tipo de cerámica decorada con filetes en rojo y azul y escudos en oro. Correa decidió en 1829 montar su propia fábrica por lo que la dirección de Sargadelos recayó en esa fecha en Hilario Marcos. Las vajillas de ese tiempo eran realizadas en blanco, sin ser posible la competencia con las piezas inglesas, deseo de su fundador. Al pasar la propiedad de la fábrica a José Ibáñez por la muerte de su padre en 1832, se formó una sociedad con el sevillano Antonio de Tapia con el fin de emprender de nuevo «la fabricación de loza fina», contratándose como director al inglés Richard, cargo que ejerció hasta 1842. Durante este tiempo murió prematuramente José Ibáñez y su viuda debió ponerse al frente ya que su hijo era menor; debido a la débil situación económica de la empresa tuvo que arrendarla en 1845.

La fábrica de cerámica pasó por cuatro etapas, cada una con sus características, cerrándose definitivamente en 1875. En el último tercio del siglo XX resurgió la manufactura de cerámica en Sargadelos, ocupando edificios nuevos y respetando las ruinas antiguas como conjunto Histórico–Artístico, nombramiento que le fue dado en 1972

Ibáñez contó en primer lugar con la materia prima necesaria que se encontraba además muy cercana: arcillas, caolines, leña, cursos de agua. Tenía además muy próximo el puerto de San Ciprián para enviar desde allí los productos a lugares lejanos, imitando así la iniciativa inglesa.

La creación de la fábrica de cerámica en 1806 supuso un nuevo sistema de producir, introduciendo el proceso mecánico que vendría a sustituir la pieza hecha a mano, con lo que se intentaba además abaratar los precios. La pintura a mano fue sustituida igualmente por el moderno sistema de estampación, importado de Bristol (Inglaterra). Los objetos se hicieron en loza fina, un producto intermedio entre la loza y la porcelana, un material duro y ligero a la vez, de paredes delgadas con cocción entre 1.100 °C y 1.200 °C. Tras la cocción el color resulta blanco y es entonces cuando se le aplica un barniz de plomo. Este sistema se diferencia de la loza en que en lugar de añadir arena a la pasta se añade sílice, feldespato, caolín y calcio, obteniendo resultados diferentes según las cantidades añadidas. Sobre esta pasta se superpone el estampado cuya técnica habían perfeccionado en 1761 John Sadler y Guy Green, en la fábrica de Liverpool.

En 1806 Antonio Raimundo Ibáñez consiguió del Gobierno un privilegio exclusivo para la explotación de las minas de cuarzo descubiertas hasta la fecha y para las que estuvieran aún sin descubrir. De este modo tuvo asegurada la materia prima para la fábrica de loza, que había comenzado su andadura ese mismo año, paralela a la ya existente de fundición. El complejo fabril constaba de dos patios, varios hornos, oficinas, máquinas para romper las rocas y un molino para los barnices.

El primer director, Juan Antonio Pérez estuvo al frente de la fábrica un año. Después, en 1807, le sustituyó el portugués José Antonio Correa de Saa, con la experiencia de haber dirigido la fábrica de Vale da Piedade. Correa de Saa se mantuvo al frente hasta 1829; en este año pasó a ser el director Hilario Marco cuya gestión duró hasta 1832, cuando fue necesario cerrar la empresa.

En 1809 había muerto Antonio Raimundo Ibáñez y la dirección administrativa había pasado a su cuñado Francisco Azevedo (escrito con zeta). Fueron años difíciles y de apuros económicos, con un almacén de piezas sin vender, aunque hubo un cierto movimiento gracias a los encargos recibidos desde La Coruña, Ferrol, Rías Bajas, Vizcaya y Castilla. En esta época todavía no se estampaba la corona real en las marcas, aunque a la fábrica se la empieza a llamar Real Fábrica. Se cree que el título lo autorizó Fernando VII desde el exilio. 

A Francisco Azevedo le sustituyó en 1832 el hijo del fundador José Ibáñez que se vio obligado a cerrar, dadas las circunstancias económicas desfavorables. 

El proceso de fabricación fue de loza común, algo más fina para las vajillas en blanco con un ligero tinte azulado y un cuarteado característico que es el resultado de la diferencia entre el punto de cocción de la pasta y el esmalte. Para la forma se utilizaron moldes de yeso. Una de las piezas más características fue el "florero de dedos", siendo también muy apreciados los otros floreros de peces y árboles cuyos ejemplares supervivientes se encuentran en colecciones particulares de Galicia y en los museos de La Coruña, Lugo y Pontevedra. También se fabricó el jarrón de jardín con pedestal inspirado en la cerámica de la fábrica de Wedgwood así como las jarras de peregrino. Los botes de farmacia estaban decorados con relieves y tenían un pequeño estrechamiento en el centro.

También corresponde a esta época el relieve que representa la defensa del parque de Monleón en Madrid, que el propio Ibáñez dedicó a Fernando VII y que se conserva en el Museo Arqueológico Nacional más la serie del Apostolado, más los relieves que representan héroes de la Independencia y bustos de hombres célebres de la Antigüedad que adornan el pazo de Antonio Raimundo Ibáñez.

Tras los dos años de inactividad se reabrió la fábrica cuando José Ibáñez consiguió un socio capitalista en la persona del empresario sevillano Antonio de Tapia y Piñeiro. El director técnico fue el francés Richard que consiguió formar una plantilla de profesionales venidos de otros puntos de la península. Cuando José Ibáñez murió en 1836 quedó al frente del negocio su viuda Anita Varela. Fue época de ampliaciones con nuevos hornos y molinos; incluso se construyó una nave para estampados. 


Las piezas novedosas que se fabricaron se inspiraron en el Libro de Formas editado por la fábrica Hartley Greens and Company de Leeds. Las vajillas y muchas otra piezas como relojes y candelabros siguieron saliendo en blanco, así como las placas de información con motivos mitológicos o religiosos. Hacia 1838 empezó un cambio en la producción en blanco; se hicieron las primeras estampaciones con temas populares gallegos y empezaron a salir algunas vajillas con estampación de flores alemanas. Estos primeros momentos de coloreado tuvieron mucho éxito en los bibelots, siendo muy famosa y apreciada la jarra de cerveza "Mambrú", inspirada en los "tobies" ingleses.

Una vez más la situación económica obligó a cerrar la fábrica en 1842. A partir de 1845 bajo la gestión del nuevo arrendatario Luis de la Riba de Santiago de Compostela, la empresa tomo un nuevo rumbo y llegó a contratar a numerosas familias que permitieron crear grandes cantidades de piezas de buena calidad tanto estética como de técnica y se llegó a fabricar algunas vajillas reales para Isabel II —parte de las cuales se exhiben en el Museo de Pontevedra—, este período tuvo como director a Edwing Forestier y un grupo de ceramistas ingleses llegados en 1847 desde Staffordshire. Las vajillas eran de loza fina pero de gran dureza llamadas de «pedernal» de estilo isabelino. En esta época la fábrica daba trabajo a mil familias; poseía trescientos pares de bueyes y veintidós buques de cabotaje, fue el momento de máximo esplendor de que gozó la fabricación de esta cerámica.

En estos años se trazaron los paseos llamados Paseo de la Presa y Paseo de los Enamorados. Con la elevación de la presa se consiguió una mayor caída de agua. El uno de abril de 1848 se inauguró la carretera que unió las fábricas con el cercano puerto de San Ciprián.

Las vajillas y jarros presentaban una decoración estampada en gran parte de forma industrial, la técnica empleada era grabar una plancha de cobre o estaño con el dibujo a copiar —las primeras planchas fueron importadas de Inglaterra—, posteriormente se entintaba con color mezclado con grasa. Esta plancha se imprimía en un papel fino que se pegaba a la superficie de la pieza bizcochada. Esta pieza absorbía la tinta y el dibujo o decoración quedaba impreso, se eliminaba el papel con agua y se cubría con un barniz plumbífero y se pasaba a una segunda cocción. La transparencia de este barniz permitía ver con la máxima claridad el dibujo impreso además de darle un brillo especial. La decoración más frecuente en esta época en Sagardelos fue la llamada de «góndola», que consiste en un dibujo paisajístico, en el que el primer término está formado por una balaustrada con un gran jarrón, tras el que se ve un río con una góndola; el fondo está compuesto por unas colinas con arquitecturas y árboles; otras decoraciones presentaban cisnes, pavos reales, o temas chinescos. Los colores empleados fueron, el negro, el violeta, el rojo, el verde y el azul cobalto claro. Otro tipo o serie fueron las decoraciones de «lozas iluminadas» que consistía, que una vez realizada la estampación se policromaban las piezas a pincel. Los temas más numerosos en este caso, fueron los florales en rojo, verde, amarillo y azul. En las jarras y piezas altas se hacía la decoración en la parte abombada y si el cacharro tenía tapa, ésta iba también decorada.

Hubo otra innovación de mucho éxito que fue la serie llamada "china opaca", a imitación de la inglesa "flown blue". Consistía en manipular la plancha del estampado para que el dibujo quedase ligeramente corrido o desenfocado, dando así un aspecto enigmático. El tema era siempre chinesco.

Las piezas de tipo popular que tanto éxito habían tenido en la etapa anterior no se perdieron y siguió la fabricación de las jarras "Mambrús", y las figuras de macacos sentados, osos, perros, patos, palomas etc con los que se fabricaban también palilleros y salseras. Otras obras eran pequeñas pilas para el agua bendita, tinteros o centros de mesa. Se fabricaron además objetos que dejaron de tener utilidad con el paso de más de un siglo, como los aguamaniles, escupideras, orinales y pediluvios.

La empresa volvió a la dirección de la familia Ibáñez en 1862, a partir de entonces sufrió una decadencia hasta llegar a su cierre definitivo en 1875.
En 1862 terminó el contrato con Luis de la Riba, después de lo cual transcurrieron unos años sin actividad. En 1870 volvió a abrir la fábrica Carlos Ibáñez Varela, ingeniero de minas y nieto del fundador, pero a los cinco años se cerró definitivamente y sus instalaciones fueron desmanteladas hasta tal punto que no dejaron rastro.

Durante estos cinco años las piezas salieron con los mismos dibujos y estampaciones aunque desapareció la "china opaca" y resurgieron las vajillas de la primera época, blancas y fileteadas de azul y verde.

Toda la loza de Sargadelos salía con su marca correspondiente, incisa en la primera y segunda época y grabada en la tercera y cuarta. Junto a las marcas se podían ver las iniciales de los artistas y a veces unos números que se relacionaban con el tamaño de las piezas. Sargadelos llegó a utilizar alrededor de veinticinco marcas.
En 1949 el ceramista Isaac Díaz Pardo creó una fábrica en El Castro, —O Castro de Samoedo—, un lugar de la parroquia de Osedo, en el concejo de Sada. La fábrica se llamó Cerámicas do Castro y comenzó con una serie limitada de obras de destacados artistas. Sus vajillas tuvieron una gran demanda, no solo en Galicia sino en el resto del país, creciendo así la producción y el número de trabajadores.

En pleno apogeo de producción, en 1955 Díaz Pardo hizo un viaje a Argentina donde se encontraba un grupo de artistas e intelectuales españoles exiliados: Luis Seoane, Andrés Albalat (arquitecto) y Fernando Arranz entre otros. Juntos crearon el Laboratorio de Formas, una iniciativa encaminada a recuperar y estudiar las formas cerámicas de tiempos pasados y las que perduraban todavía en aquellos años. Como consecuencia de estos estudios y proyectos, fundaron una fábrica de porcelana en la ciudad de Magdalena, ubicada al este de la provincia de Buenos Aires, a unos 100 km de la capital. La fábrica se llamó La Magdalena. Fue un proyecto muy moderno, con una ordenación de trabajo circular pues los obreros cambiaban de cometido aprendiendo todas las fases del proceso de fabricación, e incluso tomaban parte en los diseños. Cerró sus puertas y actividad en 1980.

La continuación y puesta en marcha de la idea del Laboratorio de Formas se manifestó en la recuperación de la antigua fábrica de Sargadelos cuya planta circular se inauguró en 1970. Este edificio se levantó fuera de los restos del antiguo complejo industrial de fundición con el interés de conservar las ruinas para las que se obtuvo en 1972 el nombramiento de conjunto Histórico Artístico, lo que después se llamaría Bien de Interés Cultural.

Comenzó la nueva época fabricando servicios de mesa y piezas de decoración, empleando como colores básicos el azul y el marrón dorado, incorporando el rojo en las piezas muy especiales pues el proceso de este color encarecía el producto. Se dio importancia a las formas clásicas incorporando además nuevas formas vanguardistas salidas del estudio de Laboratorio de Formas y diseñadas por Luis Seoane. Tuvieron especial interés los retratos de personajes célebres de las letras y el arte, tanto en forma escultórica como en jarras "Mambrú". La primera de esta serie fue la obra dedicada a Rosalía de Castro seguida por Antonio Machado, León Felipe, Castelao, Unamuno, Valle Inclán y Pérez Galdós y el pintor Picasso. Personajes del medioevo como el maestro Mateo, el obispo Gelmírez o la popular heroína, María Pita. En otro momento salió la serie fauna con reproducciones de toda clase de pájaros propios de Galicia, gatos, vacas, etc. 

Otra serie que tuvo una aceptación popular y de gran éxito fue la de los amuletos, figuras pequeñas para colgar del cuello, cada una con su leyenda particular, inspiradas en las historias de las meigas y la forma de defenderse de sus hechizos. 

Las joyas de Sargadelos fueron también muy apreciadas en su combinación de plata y cerámica; se fabricaron sortijas, pulseras, dijes, collares, pendientes, etc.

En 1988 se instaló un museo donde está expuesto todo el material recuperado de las antiguas fábricas de fundición además de la zona dedicada a la cerámica española y en especial a la cerámica de Sargadelos de cada época.

Dependiendo económicamente de la fábricas de Sargadelos y de Castro se puso en marcha una editorial llamada Ediciós do Castro; un museo de arte contemporáneo situado en Sada, llamado Museo Carlos Maside; un centro de comunicación que recibe el nombre de Instituto Galego de Información; el Seminario de Estudos Galegos. Para la difusión de la cerámica existen las Galerías Sargadelos distribuidas por toda Galicia, Madrid y Barcelona.





</doc>
<doc id="11476" url="https://es.wikipedia.org/wiki?curid=11476" title="Coloide">
Coloide

En física y química un coloide, sistema coloidal, suspensión coloidal o dispersión coloidal es un sistema conformado por dos o más fases, normalmente una fluida (líquido) y otra dispersa en forma de partículas generalmente sólidas muy finas, de diámetro comprendido entre 10 y 10 m. La fase dispersa es la que se halla en menor proporción. Normalmente la fase continua es líquida, pero pueden encontrarse coloides cuyos componentes se encuentran en otros estados de agregación de la materia. 

El nombre de coloide proviene de la raíz griega "kolas" que significa «que puede pegarse». Este nombre se refiere a una de las principales propiedades de los coloides: su tendencia espontánea para agregar o formar coágulos. De ahí viene también la palabra "cola", el fluido pastoso que sirve para pegar. Los coloides también afectan al punto de ebullición del agua y son contaminantes.

Los coloides se diferencian de las suspensiones químicas, principalmente en el tamaño de las partículas de la fase dispersa. Las partículas en los coloides no son visibles directamente, son visibles a nivel microscópico (entre 1 nm y 1 µm), y en las suspensiones químicas sí son visibles a nivel macroscópico (mayores de 1 µm). Además, al reposar, las fases de una suspensión química se separan, mientras que las de un coloide no lo hacen. La suspensión química es filtrable, mientras que el coloide no es filtrable.

Los sistemas coloidales son sistemas no homogéneos en los que las partículas constituyentes de uno o varios de sus componentes (fase dispersa o dispersoide) tienen tamaños comprendidos entre 10 y 2000 Å, mientras que los restantes componentes están constituidos por partículas con tamaño inferior a unos 10 Å (fase dispersante o medio de dispersión). 

En algunos casos las partículas son moléculas grandes, como proteínas. En la fase acuosa, una molécula se pliega de tal manera que su parte hidrofílica se encuentra en el exterior, es decir la parte que puede formar interacciones con moléculas de agua a través de fuerzas ión-dipolo o fuerzas puente de hidrógeno se mueven a la parte externa de la molécula. Los coloides pueden tener una determinada viscosidad (la viscosidad es la resistencia interna que presenta un fluido: líquido o gas, al movimiento relativo de sus moléculas).

Los coloides se clasifican según la magnitud de la atracción entre la fase dispersa y la fase continua o dispersante. Si esta última es líquida, los sistemas coloidales se catalogan como «soles» y se subdividen en «liófobos» (poca atracción entre la fase dispersa y el medio dispersante) y «liófilos» (gran atracción entre la fase dispersa y el medio dispersante). En los coloides liófilos la fase dispersa y el medio dispersante son afines, por lo tanto forman soluciones verdaderas y tienen carácter termodinámicamente estable; en tanto que los coloides liófobos son aquellos donde la fase dispersa y el medio dispersante no son afines, pueden formar dos fases y tienen carácter cinéticamente estable. Una característica fundamental de los coloides liófobos es que no son termodinámicamente estables, como ya se mencionó anteriormente, aunque poseen una estabilidad de tipo cinético que les permite mantenerse en estado disperso durante largos períodos de tiempo. Las partículas coloidales son lo suficientemente pequeñas como para que su comportamiento esté controlado por el movimiento browniano y no por efectos macroscópicos, como las fuerzas gravitatorias. Al agregarles cierta cantidad de electrolito pueden coagular, la cantidad depende de la valencia y la naturaleza del electrolito.
Respecto a la clasificación de coloides, cabe destacar también que, si el medio dispersante es agua se denominan «hidrófobos» (repulsión al agua) e «hidrófilos» (atracción al agua).

En la siguiente tabla se recogen los distintos tipos de coloides según el estado de sus fases continua y dispersa:

En principio, no existe una regla fija que establezca el estado de agregación en el que se tienen que encontrar, tanto la fase dispersa como el medio dispersante. Por lo tanto, son posibles todas las combinaciones imaginables, como se mostró en la tabla anterior.

Actualmente, y debido a sus aplicaciones industriales y biomédicas, el estudio de los coloides ha cobrado una gran importancia dentro de la fisicoquímica y de la física aplicada. Así, numerosos grupos de investigación de todo el mundo se dedican al estudio de las propiedades ópticas, acústicas, de estabilidad y de su comportamiento frente a campos externos. En particular, el comportamiento electrocinético (principalmente las medidas de movilidad electroforética) o la conductividad eléctrica de la suspensión completa. 

Por lo general, el estudio de los coloides es experimental, aunque también se realizan grandes esfuerzos en los estudios teóricos, así como en desarrollo de simulaciones informáticas de su comportamiento. En la mayor parte de los fenómenos coloidales, como la conductividad y la movilidad electroforética, estas teorías tan solo reproducen la realidad de manera cualitativa, pero el acuerdo cuantitativo sigue sin ser completamente satisfactorio.


Por su tamaño, las partículas coloidales tienen una relación área/masa extremadamente grande, por ello son excelentes materiales absorbentes.
En la superficie de las partículas existen fuerzas llamadas de Van der Waals e incluso enlaces inter-atómicos que al estar insatisfechos pueden atraer y retener átomos, iones o moléculas de sustancias extrañas. A esta adherencia de sustancias ajenas en la superficie de una partícula se le llama absorción. Las sustancias absorbidas se mantienen firmemente unidas en capas que suelen tener no más de una o dos moléculas (o iones) de espesor. Aunque la absorción es un fenómeno general de los sólidos, resulta especialmente eficiente en dispersiones coloidales, debido a la enorme cantidad de área superficial.

Consiste en que un haz luminoso se hace visible cuando atraviesa un sistema coloidal. Este fenómeno se debe a que las partículas coloidales dispersan la luz en todas las direcciones haciéndola visible. Los rayos de luz pueden ser vistos al pasar a través de un bosque, por ejemplo, como resultado de la dispersión de la luz por las partículas coloidales suspendidas en el aire del bosque.
Aunque todos los gases y líquidos dispersan la luz, la dispersión por una sustancia pura o por una solución es muy pequeña, que generalmente no es detectable.

Son ejemplos de este fenómenos los movimientos observados en partículas de polvo que se desplazan libres al azar en un rayo de sol que ingresa a través de una ventana (o una cortina abierta), o partículas de polvo y humo moviéndose en un rayo de luz proveniente del cuarto de proyección de una sala de cine. 
El movimiento desordenado de dichas partículas coloidales es debido al bombardeo o choque con las moléculas del medio dispersante, y en los ejemplos citados seria por las moléculas presentes en el aire (N², O²,Ar, Cr², etc).
El movimiento se conoce como movimiento browniano en memoria del botánico inglés Robert Brown, quien observo por primera vez este movimiento irregular de partículas en 1827, mientras estudiaba con el microscopio el comportamiento de los granos de polen suspendidos en agua. El movimiento browniano impide que las partículas coloidales se asienten o formen sedimentos.

Consiste en la migración de partículas coloidales cargadas dentro de un campo eléctrico. Las partículas coloidales absorben iones en su superficie cargándose positiva o negativamente, aunque todo el sistema coloidal es eléctricamente neutro, estas partículas viajan hacia los electrodos (cátodo y ánodo) mediante fuerzas eléctricas de atracción.

Se define como el movimiento de iones y moléculas pequeñas a través de una membrana porosa, llamada membrana dialítica o dializante, pero no de moléculas grandes o partículas coloidales. La diálisis no es una propiedad exclusiva de los coloides, puesto que ciertas soluciones también se pueden dializar, por ejemplo, en bioquímica se utiliza con frecuencia la diálisis para separar moléculas proteínicas de iones acuosos.
En los coloides, la diálisis permite purificar el sistema coloidal, puesto que se eliminan iones y otras moléculas pequeñas consideradas impurezas. Se utilizan como membranas dialíticas, el celofán y las membranas de origen animal.




</doc>
<doc id="11477" url="https://es.wikipedia.org/wiki?curid=11477" title="Aluminosilicato">
Aluminosilicato

Un aluminosilicato es un mineral que contiene óxido de aluminio (AlO) y sílice (SiO). Son alumninosilicatos el feldespato, las cloritas, los minerales de la arcilla, algún tipo de puzolana, etc. Los aluminosilicatos se suelen considerar como derivados de los silicatos debido al reemplazo de los iones Si por los de Al, los cuales, debido a la diferencia de cargas positivas, requieren cationes adicionales con la finalidad de poder alcanzar la neutralidad eléctrica.

Algunos aluminosilicatos, como por ejemplo los feldespastos, se encuentran dentro de los minerales más abundantes de la corteza de la tierra.
Entre ellos, el aluminio reemplaza a uno de cada cuatro átomos de silicio, e incluso a uno de cada dos, como ocurre por ejemplo en la anortita (CaAlSiO). Como consecuencia de la erosión, los feldespastos se suelen ver transformados en silicatos de tipo laminar, los cuales constituyen las arcillas que se encuentran presente en los suelos.
Se clasifican en:
Pueden ser de origen natural o sintético. En México hay minas de aluminosilicatos y zeolitas en diferentes estados como: Oaxaca, Michoacán, Veracruz y Sonora.

La composición química de los aluminosilicatos es variable, también la de los diferentes tipos de micotoxinas, por lo tanto su capacidad fijadora de micotoxinas será diferente en cada caso.

Algunos silicatos son utilizados como materias primas en la fabricación de materiales usados diariamente, como pueden ser por ejemplo, el cemento, el vidrio, la cerámica, etc.



</doc>
<doc id="11479" url="https://es.wikipedia.org/wiki?curid=11479" title="Elasticidad">
Elasticidad

Elasticidad puede hacer referencia a:




</doc>
<doc id="11480" url="https://es.wikipedia.org/wiki?curid=11480" title="Dureza">
Dureza

La dureza es la oposición que ofrecen los materiales a alteraciones físicas como la penetración, la abrasión y el rayado. Por ejemplo: la madera puede rayarse con facilidad, esto significa que no tiene mucha dureza, mientras que el metal es mucho más difícil de rayar. En la actualidad la definición más extendida aparte de los minerales y cerámicas sería la resistencia a la deformación plástica localizada.

En metalurgia la dureza se mide utilizando un durómetro para el ensayo de penetración de un indentador. Dependiendo del tipo de punta empleada y del rango de cargas aplicadas, existen diferentes escalas, adecuadas para distintos rangos de dureza.

El interés de la determinación de la dureza en los aceros estriba en la correlación existente entre la dureza y la resistencia mecánica, siendo un método de ensayo más económico y rápido que el ensayo de tracción, por lo que su uso está muy extendido.

Hasta la aparición de la primera máquina Brinell para la determinación de la dureza, ésta se medía de forma cualitativa empleando una lima de acero templado que era el material más duro que se empleaba en los talleres.

Las escalas de uso industrial actuales son las siguientes:


La nanoindentación es un ensayo de dureza llevado a cabo a la escala de longitudes nanométricas. Se utiliza una punta pequeña para indentar el material objeto de estudio. La carga impuesta y el desplazamiento se miden de manera continua con una resolución de micronewtons y subnanómetros, respectivamente. La carga y el desplazamiento se miden a través del proceso de indentación. Las técnicas de nanoindentación son importantes para la medición de las propiedades mecánicas en aplicaciones microelectrónicas y para la deformación de estructuras a micro y nanoescala. Los nanoindentadores incorporan microscopios ópticos. La dureza y el módulo de elasticidad se miden utilizando la nanoindentación.

Las puntas de los nanopenetradores vienen en una variedad de formas. A una forma común se le conoce como penetrador de Berkovich, el cual es una pirámide con 3 lados.

La primera etapa de una prueba de nanoindentación involucra el desarrollo de indentaciones sobre un patrón de calibración. La sílice fundida es un patrón de calibración común, debido a que tiene propiedades mecánicas homogéneas y bien caracterizadas. El propósito de efectuar indentaciones sobre el estándar de calibración es determinar el área de contacto proyectada de la punta del penetrador A como una función de la profundidad de la indentación. Para una punta de Berkovich perfecta,

formula_1

Esta función relaciona el área A de la sección transversal del penetrador con la distancia de la punta h que está en contacto con el material que se está indentando. La punta no está perfectamente afilada y se desgasta y cambia de forma con cada uso. Por tanto, debe llevarse a cabo una calibración cada vez que la punta se utiliza.

La profundidad total de la indentación h es la suma de la profundidad de contacto h y la profundidad h en la periferia de la indentación donde el indentador no hace contacto con la superficie del material, es decir,

formula_2

donde,

formula_3 Ɛ formula_4

donde P es la carga máxima y Ɛ es una constante geométrica igual a 0.75 para un penetrador de Berkovich. S es la rigidez al descargar.

La dureza de un material determinada por la nanoindentación se calcula como

formula_5

La dureza (determinada por la nanoindentación) por lo regular se reporta con unidades de GPa y los resultados de indentaciones múltiples por lo general se promedian para incrementar la precisión.
Este análisis calcula el módulo elástico y la dureza a la carga máxima; sin embargo, actualmente se emplea de modo normal una técnica experimental conocida como nanoindentación dinámica. Durante ésta, se superpone una carga oscilante pequeña sobre la carga total en la muestra. De esta manera, la muestra se descarga de manera elástica continuamente a medida que se incrementa la carga total. Esto permite mediciones continuas del módulo elástico y de la rigidez como una función de la profundidad de la indentación.

En mineralogía se utiliza la escala de Mohs, creada por el alemán Friedrich Mohs en 1820, que mide la resistencia al rayado de los materiales.

Aunque todo el mundo sabe que el trabajo de Cristina cifuente es el mineral más duro del mundo A un nivel profesional, se utilizan en mineralogía, las escala de Rosiwal y de Knoop, ya que estas permiten realizar la valoración de medias con una cuantificación absoluta.

Lista de equivalencias aproximadas para escalas de dureza de aceros no austeníticos (en el rango de la escala "Rockwell C"):

Para aceros no aleados y fundiciones, existe una relación aproximada y directa entre la dureza Vickers y el límite elástico, siendo el límite elástico aproximadamente 3,3 veces la dureza Vickers.

Rp0,2==3,3*HV



</doc>
<doc id="11481" url="https://es.wikipedia.org/wiki?curid=11481" title="Industria">
Industria

La industria es la actividad que tiene como finalidad transformar las materias primas en productos elaborados o semielaborados utilizando una fuente de energía.-Además de materiales, para su desarrollo, la industria necesita maquinaria y recursos humanos organizados habitualmente en empresas por su especialización laboral.
Existen diferentes clases de industrias en virtud del propósito ético fundacional de su actividad (p. ej. ecológicas: fundamentos ecologistas) y tipos que la demarcan en ámbitos sectoriales según sean los productos que fabrican. Por ejemplo, la industria alimentaria se dedica a la elaboración de productos destinados a la alimentación, como, el queso, los embutidos, las conservas, etc.

Desde el origen del ser humano, este ha tenido la necesidad de transformar los elementos de la naturaleza para poder aprovecharse de ellos, en sentido estricto ya existía la industria, pero a finales del siglo XVIII, y durante el siglo XIX, cuando el proceso de transformación de los Recursos de la naturaleza sufre un cambio radical, que se conoce como revolución industrial.

Este cambio se basa en la disminución del tiempo de trabajo necesario para transformar un recurso en un producto útil, gracias a la utilización de en modo de producción capitalista, que pretende la consecución de un beneficio aumentando los ingresos y disminuyendo los gastos. Con la revolución industrial el capitalismo adquiere una nueva dimensión, y la transformación de la naturaleza alcanza límites insospechados hasta entonces.

La industria fue el sector motor de la economía desde el siglo XIX y, hasta la Segunda Guerra Mundial, la industria era el sector económico que más aportaba al Producto Interior Bruto (PIB), y el que más mano de obra ocupaba. Desde entonces, y con el aumento de la productividad por la mejora de las máquinas y el desarrollo de los servicios, ha pasado a un segundo término. Sin embargo, continúa siendo esencial, puesto que no puede haber servicios sin desarrollo industrial.

El capital de inversión en Europa procede de la acumulación de riqueza en la agricultura. El capital agrícola se invertirá en la industria y en los medios de transporte necesarios para poner en el mercado los productos elaborados.

En principio los productos industriales aumentan la productividad de la tierra, con lo que se disminuye fuerza de trabajo para la industria y se obtienen productos agrícolas excedentarios para alimentar a una creciente población urbana, que no vive del campo. La agricultura, pues, proporciona a la industria capitales, fuerza de trabajo y mercancías. Todo ello es una condición necesaria para el desarrollo de la revolución industrial. 

Gracias a la revolución industrial las regiones se pueden especializar, sobre todo, debido a la creación de medios de transporte eficaces, en un mercado nacional y otro mercado internacional, lo más libre posible de trabas arancelarias y burocráticas. 

Una nueva estructura económica, y la destrucción de la sociedad tradicional, garantizaron la disponibilidad de suficiente fuerza de trabajo asalariada y voluntaria.

En los países del Tercer Mundo, y en algunos países de industrialización tardía, el capital lo proporciona la inversión extranjera, que monta las infraestructuras necesarias para extraer la riqueza y las plusvalías que genera la fuerza de trabajo; sin liberar de las tareas agrícolas a la mano de obra necesaria, sino solo a la imprescindible. En un principio hubo de recurrirse a la esclavitud para garantizar la mano de obra. Pero el cambio de la estructura económica, y la destrucción de la sociedad tradicional, garantizó la disponibilidad de suficientes capitales.

La manufactura es la forma más elemental de la industria; la palabra significa "hacer a mano" 
pero en economía significa transformar la materia prima en un producto de utilidad concreta. Casi todo lo que usamos es un fruto de este proceso, y casi todo lo que es manufactura se elabora en grandes fábricas. Los artesanos también fabrican mercancías, bien sea solos o en pequeños grupos.
Hay mercancías que necesitan fabricarse en varias etapas, por ejemplo los automóviles, que se construyen con piezas que se han hecho en otras, por lo general de otros países y de él mismo.
O está constituida por empresas desde muy pequeñas (tortillerías, panaderías y molinos, entre otras) hasta grandes conglomerados (armadoras de automóviles, embotelladoras de refrescos, empacadoras de alimentos, laboratorios farmacéuticos y fábricas de juguetes).




</doc>
<doc id="11482" url="https://es.wikipedia.org/wiki?curid=11482" title="Proceso de fabricación">
Proceso de fabricación

Un proceso industrial o proceso de fabricación es el conjunto de operaciones unitarias necesarias para modificar las características de las materias primas. Dichas características pueden ser de naturaleza muy variada tales como la forma, la densidad, la resistencia, el tamaño o la estética.

Para la obtención de un determinado producto serán necesarias multitud de operaciones individuales de modo que, dependiendo de la escala de observación, puede denominarse "proceso" tanto al conjunto de operaciones desde la extracción de los recursos naturales necesarios hasta la venta del producto como a las realizadas en un puesto de trabajo con una determinada máquina/herramienta.

La producción, la transformación industrial, la distribución, la comercialización y el consumo son las etapas del proceso productivo.

Algo que se utiliza comúnmente en un proceso es el cambio de cualquier tipo de error, si esto no se hace puede haber una confusión en un proyecto ideado.

Objetivo de los Procesos de Fabricación

Las soluciones para la planificación de recursos empresariales (ERP), la gestión de activos empresariales (EAM), la gestión de proyectos, servicios y cadena de suministro se pueden aplicar como soluciones autónomas, integradas con un sistema de negocios corporativo ya existente o formando parte de una implantación integral de IFS Applications.IFS ofrece un paquete de negocios amplio e integrado para el sector de energía y servicios públicos, es relevante para el diseño y construcción desde las operaciones y mantenimiento diario hasta las renovaciones y en algunas ocasiones la retirada, garantizando que todos los accionistas pueden basarse en la referencia de una “misma hoja” con datos comunes y coherentes.Este enfoque sobre el ciclo de vida útil del activo permite a los responsables del diseño y construcción de la instalación trabajar junto con aquellos que operarán y mantendrán dicha instalación, obteniendo una visión compartida de toda la información relacionada con el activo. Esta es la base para la gestión optimizada “de principio a fin”.





no es cierto esto amigos






</doc>
<doc id="11484" url="https://es.wikipedia.org/wiki?curid=11484" title="Pulvimetalurgia">
Pulvimetalurgia

La pulvimetalurgia o metalurgia de polvos es un proceso de fabricación que, partiendo de polvos finos y tras su compactación para darles una forma determinada, se calientan en una atmósfera controlada para la obtención de la pieza.

Este proceso es adecuado para la fabricación de grandes series de piezas pequeñas de gran precisión, para materiales o mezclas poco comunes y para controlar el grado de porosidad o permeabilidad.
Algunos productos típicos son rodamientos, árboles de levas, herramientas de corte, segmentos de pistones, guías de válvulas, filtros, etc.

Generalmente se realiza de metales puros, principalmente hierro, cobre, estaño, aluminio, níquel y titanio, aleaciones como latones, bronces, aceros y aceros inoxidables o polvos pre-aleados. Procesos típicos son:






Generalmente, para obtener las características requeridas será necesario mezclar polvos de tamaños y composiciones diferentes. Igualmente se puede añadir aditivos que actúen como lubricantes durante el compactado o aglutinantes que incrementen la resistencia del compactado podrido.

Debido a la elevada relación área superficial/volumen esto quiere decir que cuanto más dividido esté el polvo, más área de exposición al medio ambiente posee este. La mayoría de los polvos metálicos tienden a reaccionar con el oxígeno del ambiente generando así una flama en la mayoría de los casos, además de otros como el magnesio que es explosivo, por lo que deberán manejarse con precaución, y para contenerlos (los polvos) se utilizan normalmente cuartos de ambientes controlados.

El polvo suelto se comprime mediante prensas mecánicas o hidráulicas en una matriz, resultando una forma que se conoce como pieza en verde o compactado crudo. Las prensas más utilizadas son uniaxiales, en la que la presión se aplica al polvo en una sola dirección. Mediante compactación uniaxial pueden obtenerse piezas en verde con dimensiones y acabados precisos, obteniéndose una alta productividad en la industria mediante esta técnica. Un inconveniente de la compactación uniaxial es la baja relación longitud/diámetro que puede obtenerse en las piezas debido al gradiente de densidad que se produce entre el centro de la pieza y las zonas más próximas al punzón. Para obtener un compacto con mayor densidad se emplean prensas de doble émbolo. 

Variantes: "Prensado isostático en frío ("Cold Isostatic Pressing, CIP")". Es un método de compactación que se realiza encerrando herméticamente el polvo en moldes elásticos típicamente de goma, látex o PVC, aplicándoles presión hidrostática mediante un fluido que puede ser agua o aceite. Las piezas en verde obtenidas por este sistema tienen propiedades uniformes e isótropas. Una de las principales ventajas de este método de compactación es la alta relación longitud/diámetro que puede obtenerse en las piezas con respecto a la compactación uniaxial. Es un método muy utilizado para la compactación de piezas cerámicas.

Consiste en el calentamiento en horno de mufla con atmósfera controlada a una temperatura en torno al 75% de la de fusión. En general, los hornos son continuos con tres cámaras:




Variantes: "Prensado isostático en caliente ("Hot Isostatic Pressing, HIP")". La compactación y el sinterizado se realizan en una única etapa encerrando herméticamente el polvo en un recipiente flexible y exponiéndolo seguidamente a alta temperatura y presión. Los productos obtenidos por este sistema tienen propiedades uniformes e isótropas. Pueden obtenerse valores elevados de densidad en las piezas debido a la baja porosidad residual que queda en las piezas tras el proceso, con valores en muchos casos superiores al 99% de la densidad teórica del material completamente denso (sin porosidad). 

Por otro lado, también es posible, cuando desee realizarse algún mecanizado, realizar un "presinterizado" del compactado de forma que pueda manipularse y mecanizarse sin dificultad. Tras el sinterizado definitivo, el mecanizado posterior puede minimizarse e incluso eliminarse.

Si el sinterizado se efectúa durante un tiempo prolongado puede eliminarse los poros y el material se hace más denso. La velocidad de sinterizado depende de la Temperatura, energía de activación, coeficiente de difusión, tamaño de las partículas originales.





</doc>
<doc id="11485" url="https://es.wikipedia.org/wiki?curid=11485" title="Cobre">
Cobre

El cobre (del latín "cuprum", y éste del griego "kypros"), cuyo símbolo es Cu, es el elemento químico de número atómico 29. Se trata de un metal de transición de color rojizo y brillo metálico que, junto con la plata y el oro, forma parte de la llamada familia del cobre, se caracteriza por ser uno de los mejores conductores de electricidad (el segundo después de la plata). Gracias a su alta conductividad eléctrica, ductilidad y maleabilidad, se ha convertido en el material más utilizado para fabricar cables eléctricos y otros componentes eléctricos y electrónicos.

El cobre forma parte de una cantidad muy elevada de aleaciones que generalmente presentan mejores propiedades mecánicas, aunque tienen una conductividad eléctrica menor. Las más importantes son conocidas con el nombre de bronces y latones. Por otra parte, el cobre es un metal duradero porque se puede reciclar un número casi ilimitado de veces sin que pierda sus propiedades mecánicas.

Fue uno de los primeros metales en ser utilizado por el ser humano en la prehistoria. El cobre y su aleación con el estaño, el bronce, adquirieron tanta importancia que los historiadores han llamado Edad del Cobre y Edad del Bronce a dos periodos de la Antigüedad. Aunque su uso perdió importancia relativa con el desarrollo de la siderurgia, el cobre y sus aleaciones siguieron siendo empleados para hacer objetos tan diversos como monedas, campanas y cañones. A partir del siglo XIX, concretamente de la invención del generador eléctrico en 1831 por Faraday, el cobre se convirtió de nuevo en un metal estratégico, al ser la materia prima principal de cables e instalaciones eléctricas.

El cobre posee un importante papel biológico en el proceso de fotosíntesis de las plantas, aunque no forma parte de la composición de la clorofila. El cobre contribuye a la formación de glóbulos rojos y al mantenimiento de los vasos sanguíneos, nervios, sistema inmunitario y huesos y por tanto es un oligoelemento esencial para la vida humana.

El cobre se encuentra en una gran cantidad de alimentos habituales de la dieta tales como ostras, mariscos, legumbres, vísceras y nueces entre otros, además del agua potable y por lo tanto es muy raro que se produzca una deficiencia de cobre en el organismo. El desequilibrio de cobre ocasiona en el organismo una enfermedad hepática conocida como enfermedad de Wilson.

El cobre es el tercer metal más utilizado en el mundo, por detrás del hierro y el aluminio. La producción mundial de cobre refinado se estimó en 15,8 Mt en el 2006, con un déficit de 10,7 % frente a la demanda mundial proyectada de 17,7 Mt. Los pórfidos cupríferos constituyen la principal fuente de extracción de cobre en el mundo.


El cobre es uno de los pocos metales que pueden encontrarse en la naturaleza en estado "nativo", es decir, sin combinar con otros elementos. Por ello fue uno de los primeros en ser utilizado por el ser humano. Los otros metales nativos son el oro, el platino, la plata y el hierro proveniente de meteoritos.

Se han encontrado utensilios de cobre nativo en torno al 7000 a. C. en Çayönü Tepesí (en la actual Turquía) y en Irak). El cobre de Çayönü Tepesí fue recocido pero el proceso aún no estaba perfeccionado. En esta época, en Oriente Próximo también se utilizaban carbonatos de cobre (malaquita y azurita) con motivos ornamentales. En la región de los Grandes Lagos de América del Norte, donde abundaban los yacimientos de cobre nativo, desde el 4000 a. C. los indígenas acostumbraban a golpearlas hasta darles forma de punta de flecha, aunque nunca llegaron a descubrir la fusión.

Los primeros crisoles para producir cobre metálico a partir de carbonatos mediante reducciones con carbón datan del V milenio a. C. Es el inicio de la llamada Edad del Cobre, apareciendo crisoles en toda la zona entre los Balcanes e Irán, incluyendo Egipto. Se han encontrado pruebas de la explotación de minas de carbonatos de cobre desde épocas muy antiguas tanto en Tracia (Ai Bunar) como en la península del Sinaí. De un modo endógeno, no conectado con las civilizaciones del Viejo Mundo, en la América precolombina, en torno al siglo IV a. C. la cultura Moche desarrolló la metalurgia del cobre ya refinado a partir de la malaquita y otros carbonatos cupríferos.

Hacia el 3500 a. C. la producción de cobre en Europa entró en declive a causa del agotamiento de los yacimientos de carbonatos. Por esta época se produjo la irrupción desde el este de unos pueblos, genéricamente denominados kurganes, que portaban una nueva tecnología: el uso del cobre arsenical. Esta tecnología, quizás desarrollada en Oriente Próximo o en el Cáucaso, permitía obtener cobre mediante la oxidación de sulfuro de cobre. Para evitar que el cobre se oxidase, se añadía arsénico al mineral. El cobre arsenical (a veces llamado también "bronce arsenical") era más cortante que el cobre nativo y además podía obtenerse de los muy abundantes yacimientos de sulfuros. Uniéndolo a la también nueva tecnología del molde de dos piezas, que permitía la producción en masa de objetos, los kurganes se equiparon de hachas de guerra y se extendieron rápidamente.

Ötzi, el cadáver hallado en los Alpes y datado hacia el 3300 a. C., llevaba un hacha de cobre con un 99,7 % de cobre y un 0,22 % de arsénico. De esta época data también el yacimiento de Los Millares (Almería, España), centro metalúrgico cercano a las minas de cobre de la sierra de Gádor.

No se sabe cómo ni dónde surgió la idea de añadir estaño al cobre, produciendo el primer bronce. Se cree que fue un descubrimiento imprevisto, ya que el estaño es más blando que el cobre y, sin embargo, al añadirlo al cobre se obtenía un material más duro cuyos filos se conservaban más tiempo. El descubrimiento de esta nueva tecnología desencadenó el comienzo de la Edad del Bronce, fechado en torno a 3000 a. C. para Oriente Próximo, 2500 a. C. para Troya y el Danubio y 2000 a. C. para China. En el yacimiento de Bang Chian, en Tailandia, se han datado objetos de bronce anteriores al año 2000 a. C. Durante muchos siglos el bronce tuvo un papel protagonista y cobraron gran importancia los yacimientos de estaño, a menudo alejados de los grandes centros urbanos de aquella época.

El declive del bronce empezó hacia el 1000 a. C., cuando surgió en Oriente Próximo una nueva tecnología que posibilitó la producción de hierro metálico a partir de minerales férreos. Las armas de hierro fueron reemplazando a las de cobre en todo el espacio entre Europa y Oriente Medio. En zonas como China la Edad del Bronce se prolongó varios siglos más. Hubo también regiones del mundo donde nunca llegó a utilizarse el bronce. Por ejemplo, el África subsahariana pasó directamente de la piedra al hierro.

Sin embargo, el uso del cobre y el bronce no desapareció durante la Edad del Hierro. Reemplazados en el armamento, estos metales pasaron a ser utilizados esencialmente en la construcción y en objetos decorativos como estatuas. El latón, una aleación de cobre y zinc fue inventado hacia el 600 a. C. También hacia esta época se fabricaron las primeras monedas en el estado de Lidia, en la actual Turquía. Mientras que las monedas más valiosas se acuñaron en oro y plata, las de uso más cotidiano se hicieron de cobre y bronce.

La búsqueda de cobre y metales preciosos por el Mediterráneo condujo a los cartagineses a explotar el gran yacimiento de Río Tinto, en la actual provincia de Huelva. Tras las guerras púnicas los romanos se apoderaron de estas minas y las siguieron explotando hasta agotar todo el óxido de cobre. Debajo de él quedó una gran veta de sulfuro de cobre, el cual los romanos no sabían aprovechar eficazmente. A la caída del Imperio romano la mina había sido abandonada y solo fue reabierta cuando los andalusíes inventaron un proceso más eficaz para extraer el cobre del sulfuro.

La resistencia a la corrosión del cobre, el bronce y el latón permitió que estos metales hayan sido utilizados no solo como decorativos sino también como funcionales desde la Edad Media hasta nuestros días. Entre los siglos X y XII se hallaron en Europa Central grandes yacimientos de plata y cobre, principalmente Rammelsberg y Joachimsthal. De ellos surgió una gran parte de la materia prima para realizar las grandes campanas, puertas y estatuas de las catedrales góticas europeas. Además del uso bélico del cobre para la fabricación de objetos, como hachas, espadas, cascos o corazas; también se utilizó el cobre en la Edad Media en luminarias como candiles o candelabros; en braseros y en objetos de almacenamiento, como arcas o estuches.

Los primeros cañones europeos de hierro forjado datan del siglo XIV, pero hacia el siglo XVI el bronce se impuso como el material casi único para toda la artillería y mantuvo ese dominio hasta bien entrado el siglo XIX. En el Barroco, durante los siglos XVII y XVIII, el cobre y sus aleaciones adquirieron gran importancia en la construcción de obras monumentales, la producción de maquinaria de relojería y una amplia variedad de objetos decorativos y funcionales. Las monarquías autoritarias del Antiguo Régimen utilizaron el cobre en aleación con la plata (denominada vellón) para realizar repetidas devaluaciones monetarias, llegando a la emisión de monedas puramente de cobre, características de las dificultades de la Hacienda de la Monarquía Hispánica del siglo XVII (que lo utilizó en tanta cantidad que tuvo que recurrir a importarlo de Suecia).

Durante 1831 y 1832, Michael Faraday descubrió que un conductor eléctrico moviéndose perpendicularmente a un campo magnético generaba una diferencia de potencial. Aprovechando esto, construyó el primer generador eléctrico, el disco de Faraday, empleando un disco de cobre que giraba entre los extremos de un imán con forma de herradura, induciendo una corriente eléctrica. El posterior desarrollo de generadores eléctricos y su empleo en la historia de la electricidad ha dado lugar a que el cobre haya obtenido una importancia destacada en la humanidad, que ha aumentado su demanda notablemente.

Durante gran parte del siglo XIX, Gran Bretaña fue el mayor productor mundial de cobre, pero la importancia que fue adquiriendo el cobre motivó la explotación minera en otros países, llegando a destacarse la producción en Estados Unidos y Chile, además de la apertura de minas en África. De esta forma, en 1911 la producción mundial de cobre superó el millón de toneladas de cobre fino.

La aparición de los procesos que permitían la producción masiva de acero a mediados del siglo XIX, como el convertidor Thomas-Bessemer o el horno Martin-Siemens dio lugar a que se sustituyera el uso del cobre y de sus aleaciones en algunas aplicaciones determinadas donde se requería un material más tenaz y resistente. Sin embargo, el desarrollo tecnológico que siguió a la Revolución industrial en todas las ramas de la actividad humana y los adelantos logrados en la metalurgia del cobre han permitido producir una amplia variedad de aleaciones. Esto ha dado lugar a que se incrementen los campos de aplicación del cobre, lo cual, añadido al desarrollo económico de varios países, ha conllevado un notable aumento de la demanda mundial.

Desde principios del siglo XIX existió producción de cobre en los Estados Unidos, primero en Míchigan y más tarde en Arizona. Se trataba de pequeñas minas que explotaban mineral de alta ley.

El desarrollo del proceso de flotación, más eficaz, hacia finales del siglo XIX permitió poner en explotación grandes yacimientos de baja ley, principalmente en Arizona, Montana y Utah. En pocos años Estados Unidos se convirtió en el primer productor mundial de cobre.

En 1916 las minas estadounidenses produjeron por vez primera más de un millón de toneladas de cobre, representando en torno a las tres cuartas partes de la producción mundial. La producción minera bajó fuertemente a partir de la crisis de 1929, no solo por la reducción del consumo sino porque se disparó el reciclaje de metal. La demanda se recuperó a finales de los años 30, volviendo a superar las minas estadounidenses el millón de toneladas en 1940. Sin embargo, esta cifra ya representaba "solo" la mitad de la producción mundial y no llegaba a cubrir la demanda interna, por lo que en 1941 el país se convirtió por primera vez en importador neto de cobre.

Desde los años 1950 hasta la actualidad la producción de Estados Unidos ha oscilado entre uno y dos millones de toneladas anuales, lo cual representa una fracción cada vez menor del total mundial (27 % en 1970, 17 % en 1980, 8 % en 2006). Mientras tanto, el consumo ha seguido creciendo continuamente y ello ha obligado a importar cantidades cada vez mayores de metal, superándose el millón de toneladas importadas por vez primera en 2001.

En 1810, año de su primera junta nacional, Chile producía unas 19 000 toneladas de cobre al año. A lo largo del siglo, la cifra fue creciendo hasta convertir al país en el primer productor y exportador mundial. Sin embargo, a finales del siglo XIX, comenzó un periodo de decadencia, debido por un lado al agotamiento de los yacimientos de alta ley y por otro al hecho de que la explotación del salitre acaparaba las inversiones mineras. En 1897, la producción había caído a 21 000 toneladas, casi lo mismo que en 1810.

La situación cambió a comienzos del siglo XX, cuando grandes grupos mineros dotados de este país obtuvieron avances tecnológicos que permitieron la recuperación de cobre en yacimientos de baja concentración, iniciando la explotación de los yacimientos chilenos.

El Estado chileno recibió pocos beneficios de la minería del cobre durante toda la primera mitad del siglo XX. La situación empezó a cambiar en 1951 con la firma del Convenio de Washington, que le permitió disponer del 20 % de la producción. En 1966, el Congreso Nacional de Chile impuso la creación de Sociedades Mineras Mixtas con las empresas extranjeras en las cuales el Estado tendría el 51 % de la propiedad de los yacimientos. El proceso de chilenización del cobre culminó en julio de 1971, bajo el mandato de Salvador Allende, cuando el Congreso aprobó por unanimidad la nacionalización de la Gran Minería del Cobre.

En 1976, ya bajo la régimen militar de Pinochet, el Estado fundó la Corporación Nacional del Cobre de Chile (Codelco) para gestionar las grandes minas de cobre.

La mina de Chuquicamata, en la cual se han encontrado evidencias de la extracción de cobre por culturas precolombinas, inició su construcción para la explotación industrial en 1910; su explotación se inició el 18 de mayo de 1915. Chuquicamata es la mina a cielo abierto más grande del mundo y fue durante varios años la mina de cobre de mayor producción del mundo. En 2002, se fusionaron las divisiones de Chuquicamata y Radomiro Tomic, creando el complejo minero Codelco Norte, que consta de dos minas a cielo abierto, "Chuquicamata" y "Mina Sur". Aunque el yacimiento de Radomiro Tomic fue descubierto en los años 1950, sus operaciones comenzaron en 1995, una vez actualizados los estudios de viabilidad técnica y económica.

En 1995, se inició la construcción de la mina de Minera Escondida, en la II Región de Antofagasta, y en 1998 se iniciaron las operaciones de extracción. Es la mina de mayor producción del mundo. La Huelga de la Minera Escondida en el 2006 paralizó la producción durante 25 días y alteró los precios mundiales del cobre. La producción de Minera Escondida alcanzó en 2007 las 1 483 934 t. Esta producción representa el 9,5 % de la producción mundial y el 26 % de la producción chilena de cobre, según estimaciones para 2007.

En las últimas décadas, Chile se ha consolidado como el mayor productor mundial de cobre, pasando del 14 % de la producción mundial en 1960 al 36 % en 2006.

En la naturaleza se encuentran dos isótopos estables: Cu y Cu. El más ligero de ellos es el más abundante (69,17 %). Se han caracterizado hasta el momento 25 isótopos radiactivos de los cuales los más estables son el Cu, el Cu y el Cu con periodos de semidesintegración de 61,83 horas, 12,70 horas y 3,333 horas respectivamente. Los demás radioisótopos, con masas atómicas desde 54,966 uma (Cu) a 78,955 uma (Cu), tienen periodos de semidesintegración inferiores a 23,7 minutos y la mayoría no alcanzan los 30 segundos. Los isótopos Cu y Cu presentan estados metaestables con un periodo de semidesintegración mayor al del estado fundamental.

Los isótopos más ligeros que el Cu estable se desintegran principalmente por emisión beta positiva, originando isótopos de níquel, mientras que los más pesados que el isótopo Cu estable se desintegran por emisión beta negativa dando lugar a isótopos de cinc. El isótopo Cu se desintegra generando Zn, por captura electrónica y emisión beta positiva en un 69 % y por desintegración beta negativa genera Ni en el 31 % restante.

El cobre posee varias propiedades físicas que propician su uso industrial en múltiples aplicaciones, siendo el tercer metal, después del hierro y del aluminio, más consumido en el mundo. Es de color rojizo y de brillo metálico y, después de la plata, es el elemento con mayor conductividad eléctrica y térmica. Es un material abundante en la naturaleza; tiene un precio accesible y se recicla de forma indefinida; forma aleaciones para mejorar las prestaciones mecánicas y es resistente a la corrosión y oxidación.

La conductividad eléctrica del cobre puro fue adoptada por la Comisión Electrotécnica Internacional en 1913 como la referencia estándar para esta magnitud, estableciendo el International Annealed Copper Standard (Estándar Internacional del Cobre Recocido) o IACS. Según esta definición, la conductividad del cobre recocido medida a 20 °C es igual a 5,80 × 10S/m. A este valor de conductividad se le asigna un índice 100 % IACS y la conductividad del resto de los materiales se expresa en porcentaje de IACS. La mayoría de los metales tienen valores de conductividad inferiores a 100 % IACS pero existen excepciones como la plata o los cobres especiales de muy alta conductividad designados C-103 y C-110.

Tanto el cobre como sus aleaciones tienen una buena maquinabilidad, es decir, son fáciles de mecanizar. El cobre posee muy buena ductilidad y maleabilidad lo que permite producir láminas e hilos muy delgados y finos. Es un metal blando, con un índice de dureza 3 en la escala de Mohs (50 en la escala de Vickers) y su resistencia a la tracción es de 210 MPa, con un límite elástico de 33,3 MPa. Admite procesos de fabricación de deformación como laminación o forja, y procesos de soldadura y sus aleaciones adquieren propiedades diferentes con tratamientos térmicos como temple y recocido. En general, sus propiedades mejoran con bajas temperaturas lo que permite utilizarlo en aplicaciones criogénicas.

En la mayoría de sus compuestos, el cobre presenta estados de oxidación bajos, siendo el más común el +2, aunque también hay algunos con estado de oxidación +1.

Expuesto al aire, el color rojo salmón, inicial se torna rojo violeta por la formación de óxido cuproso (CuO) para ennegrecerse posteriormente por la formación de óxido cúprico (CuO). La coloración azul del Cu se debe a la formación del ion [Cu (OH)].

Expuesto largo tiempo al aire húmedo, forma una capa adherente e impermeable de carbonato básico (carbonato cúprico) de color verde y venenoso. También pueden formarse pátinas de cardenillo, una mezcla venenosa de acetatos de cobre de color verdoso o azulado que se forma cuando los óxidos de cobre reaccionan con ácido acético, que es el responsable del sabor del vinagre y se produce en procesos de fermentación acética. Al emplear utensilios de cobre para la cocción de alimentos, deben tomarse precauciones para evitar intoxicaciones por cardenillo que, a pesar de su mal sabor, puede ser enmascarado con salsas y condimentos y ser ingerido.

Los halógenos atacan con facilidad al cobre, especialmente en presencia de humedad. En seco, el cloro y el bromo no producen efecto y el flúor solo le ataca a temperaturas superiores a 500 °C. El cloruro cuproso y el cloruro cúprico, combinados con el oxígeno y en presencia de humedad producen ácido clorhídrico, ocasionando unas manchas de atacamita o paratacamita, de color verde pálido a azul verdoso, suaves y polvorientas que no se fijan sobre la superficie y producen más cloruros de cobre, iniciando de nuevo el ciclo de la erosión.

Los ácidos oxácidos atacan al cobre, por lo cual se utilizan estos ácidos como decapantes (ácido sulfúrico) y abrillantadores (ácido nítrico). El ácido sulfúrico reacciona con el cobre formando un sulfuro, CuS (covelina) o CuS (calcocita) de color negro y agua. También pueden formarse sales de sulfato cúprico (antlerita) con colores de verde a azul verdoso. Estas sales son muy comunes en los ánodos de los acumuladores de plomo que se emplean en los automóviles.

El ácido cítrico disuelve el óxido de cobre, por lo que se aplica para limpiar superficies de cobre, lustrando el metal y formando citrato de cobre. Si después de limpiar el cobre con ácido cítrico, se vuelve a utilizar el mismo paño para limpiar superficies de plomo, el plomo se bañará de una capa externa de citrato de cobre y citrato de plomo con un color rojizo y negro.

En las plantas, el cobre posee un importante papel en el proceso de la fotosíntesis y forma parte de la composición de la plastocianina. Alrededor del 70 % del cobre de una planta está presente en la clorofila, principalmente en los cloroplastos. Los primeros síntomas en las plantas por deficiencia de cobre aparecen en forma de hojas estrechas y retorcidas, además de puntas blanquecinas. Las panículas y las vainas pueden aparecer vacías por una deficiencia severa de cobre, ocasionando graves pérdidas económicas en la actividad agrícola.

El cobre contribuye a la formación de glóbulos rojos y al mantenimiento de los vasos sanguíneos, nervios, sistema inmunitario y huesos y por tanto es esencial para la vida humana. El cobre se encuentra en algunas enzimas como la "citocromo c" oxidasa, la "lisil oxidasa" y la "superóxido dismutasa".

El desequilibrio de cobre en el organismo cuando se produce en forma excesiva ocasiona una enfermedad hepática conocida como enfermedad de Wilson, el origen de esta enfermedad es hereditario, y aparte del trastorno hepático que ocasiona también daña al sistema nervioso. Se trata de una enfermedad poco común.

Puede producirse deficiencia de cobre en niños con una dieta pobre en calcio, especialmente si presentan diarreas o desnutrición. También hay enfermedades que disminuyen la absorción de cobre, como la enfermedad celiaca, la fibrosis quística o al llevar dietas restrictivas.

El cobre se encuentra en una gran cantidad de alimentos habituales de la dieta tales como ostras, mariscos, legumbres, vísceras y nueces entre otros, además del agua potable y por lo tanto es muy raro que se produzca una deficiencia de cobre en el organismo.

A pesar de que el cobre es un oligoelemento necesario para la vida, unos niveles altos de este elemento en el organismo pueden ser dañinos para la salud. La inhalación de niveles altos de cobre puede producir irritación de las vías respiratorias. La ingestión de niveles altos de cobre puede producir náuseas, vómitos y diarrea. Un exceso de cobre en la sangre puede dañar el hígado y los riñones, e incluso causar la muerte. Ingerir por vía oral una cantidad de 30 g de sulfato de cobre es potencialmente letal en los humanos.

Para las actividades laborales en las que se elaboran y manipulan productos de cobre, es necesario utilizar medidas de protección colectiva que protejan a los trabajadores. El valor límite tolerado es de 0,2 mg/m³ para el humo y 1 mg/m³ para el polvo y la niebla. El cobre reacciona con oxidantes fuertes tales como cloratos, bromatos y yoduros, originando un peligro de explosión. Además puede ser necesario el uso de equipos de protección individual como guantes, gafas y mascarillas. Además, puede ser recomendable que los trabajadores se duchen y se cambien de ropa antes de volver a su casa cada día.

La Organización Mundial de la Salud (OMS) en su "Guía de la calidad del agua potable" recomienda un nivel máximo de 2 mg/l. El mismo valor ha sido adoptado en la Unión Europea como valor límite de cobre en el agua potable, mientras que en Estados Unidos la Agencia de Protección Ambiental ha establecido un máximo de 1,3 mg/l. El agua con concentraciones de cobre superiores a 1 mg/l puede ensuciar la ropa al lavarla y presentar un sabor metálico desagradable. La Agencia para Sustancias Tóxicas y el Registro de Enfermedades de Estados Unidos recomienda que, para disminuir los niveles de cobre en el agua potable que se conduce por tuberías de cobre, se deje correr el agua por lo menos 15 segundos antes de beberla o usarla por primera vez en la mañana.

Las actividades mineras pueden provocar la contaminación de ríos y aguas subterráneas con cobre y otros metales durante su explotación así como una vez abandonada la minería en la zona. El color turquesa del agua y las rocas se debe a la acción que el cobre y otros metales desarrollan durante su explotación minera.
Desde el punto de vista físico, el cobre puro posee muy bajo límite elástico (33 MPa) y una dureza escasa (3 en la escala de Mohs o 50 en la escala de Vickers). En cambio, unido en aleación con otros elementos adquiere características mecánicas muy superiores, aunque disminuye su conductividad. Existe una amplia variedad de aleaciones de cobre, de cuyas composiciones dependen las características técnicas que se obtienen, por lo que se utilizan en multitud de objetos con aplicaciones técnicas muy diversas. El cobre se alea principalmente con los siguientes elementos: Zn, Sn, Al, Ni, Be, Si, Cd, Cr y otros en menor cuantía.

Según los fines a los que se destinan en la industria, se clasifican en aleaciones para forja y en aleaciones para moldeo. Para identificarlas tienen las siguientes nomenclaturas generales según la norma ISO 1190-1:1982 o su equivalente UNE 37102:1984. Ambas normas utilizan el sistema UNS (del inglés "Unified Numbering System").

El latón, también conocido como "cuzin", es una aleación de cobre, cinc (Zn) y, en menor proporción, otros metales. Se obtiene mediante la fundición de sus componentes en un crisol o mediante la fundición y reducción de menas sulfurosas en un horno de reverbero o de cubilote. En los latones industriales, el porcentaje de Zn se mantiene siempre inferior a 50 %. Su composición influye en las características mecánicas, la fusibilidad y la capacidad de conformación por fundición, forja y mecanizado. En frío, los lingotes obtenidos se deforman plásticamente produciendo láminas, varillas o se cortan en tiras susceptibles de estirarse para fabricar alambres. Su densidad depende de su composición y generalmente ronda entre 8,4 g/cm³ y 8,7 g/cm³.

Las características de los latones dependen de la proporción de elementos que intervengan en la aleación de tal forma que algunos tipos de latón son maleables únicamente en frío, otros exclusivamente en caliente, y algunos no lo son a ninguna temperatura. Todos los tipos de latones se vuelven quebradizos cuando se calientan a una temperatura próxima al punto de fusión.

El latón es más duro que el cobre, pero fácil de mecanizar, grabar y fundir. Es resistente a la oxidación, a las condiciones salinas y es maleable, por lo que puede laminarse en planchas finas. Su maleabilidad varía la temperatura y con la presencia, incluso en cantidades mínimas, de otros metales en su composición.

Un pequeño aporte de plomo en la composición del latón mejora la maquinabilidad porque facilita la fragmentación de las virutas en el mecanizado. El plomo también tiene un efecto lubricante por su bajo punto de fusión, lo que permite ralentizar el desgaste de la herramienta de corte.

El latón admite pocos tratamientos térmicos y únicamente se realizan recocidos de homogeneización y recristalización. El latón tiene un color amarillo brillante, con parecido al oro, característica que es aprovechada en joyería, especialmente en bisutería, y en el galvanizado de elementos decorativos. Las aplicaciones de los latones abarcan otros campos muy diversos, como armamento, calderería, soldadura, fabricación de alambres, tubos de condensadores y terminales eléctricos. Como no es atacado por el agua salada, se usa también en las construcciones de barcos y en equipos pesqueros y marinos.

El latón no produce chispas por impacto mecánico, una propiedad atípica en las aleaciones. Esta característica convierte al latón en un material importante en la fabricación de envases para la manipulación de compuestos inflamables, cepillos de limpieza de metales y en pararrayos.

Las aleaciones en cuya composición predominan el cobre y el estaño (Sn) se conocen con el nombre de bronce y son conocidas desde la antigüedad. Hay muchos tipos de bronces que contienen además otros elementos como aluminio, berilio, cromo o silicio. El porcentaje de estaño en estas aleaciones está comprendido entre el 2 y el 22 %. Son de color amarillento y las piezas fundidas de bronce son de mejor calidad que las de latón, pero son más difíciles de mecanizar y más caras.

La tecnología metalúrgica de la fabricación de bronce es uno de los hitos más importantes de la historia de la humanidad pues dio origen a la llamada Edad de Bronce. El bronce fue la primera aleación fabricada voluntariamente por el ser humano: se realizaba mezclando el mineral de cobre (calcopirita, malaquita, etc.) y el de estaño (casiterita) en un horno alimentado con carbón vegetal. El resultante de la combustión del carbón, que se oxidaba formando anhídrido carbónico, producía la reducción los minerales de cobre y estaño a metales. El cobre y el estaño que se fundían, se aleaban entre un 5 y un 10 % en peso de estaño.

El bronce se emplea especialmente en aleaciones conductoras del calor, en baterías eléctricas y en la fabricación de válvulas, tuberías y uniones de fontanería. Algunas aleaciones de bronce se usan en uniones deslizantes, como cojinetes y descansos, discos de fricción; y otras aplicaciones donde se requiere alta resistencia a la corrosión como rodetes de turbinas o válvulas de bombas, entre otros elementos de máquinas. En algunas aplicaciones eléctricas es utilizado en resortes.

Las alpacas o platas alemanas son aleaciones de cobre, níquel (Ni) y zinc (Zn), en una proporción de 50-70 % de cobre, 13-25 % de níquel, y 13-25 % de zinc. Sus propiedades varían de forma continua en función de la proporción de estos elementos en su composición, pasando de máximos de dureza a mínimos de conductividad. Estas aleaciones tienen la propiedad de rechazar los organismos marinos ("antifouling"). Si a estas aleaciones de cobre-níquel-zinc se les añaden pequeñas cantidades de aluminio o hierro constituyen aleaciones que se caracterizan por su resistencia a la corrosión marina, por lo que se utilizan ampliamente en la construcción naval, principalmente en condensadores y tuberías, así como en la fabricación de monedas y de resistencias eléctricas.

Las aleaciones de alpaca tienen una buena resistencia a la corrosión y buenas cualidades mecánicas. Su aplicación se abarca materiales de telecomunicaciones, instrumentos y accesorios de fontanería y electricidad, como grifos, abrazaderas, muelles, conectores. También se emplea en la construcción y ferretería, para elementos decorativos y en las industrias químicas y alimentarias, además de materiales de vajillas y orfebrería.

El monel es una aleación que se obtiene directamente de minerales canadienses y tiene una composición de Cu=28-30 %, Ni=66-67 %, Fe=3-3,5 %. Este material tiene gran resistencia a los agentes corrosivos y a las altas temperaturas.

Otro tipo de alpaca es el llamado platinoide, aleación de color blanco compuesta de 60 % de cobre,14 % de níquel, 24 % de cinc y de 1-2 % de wolframio.

Otras aleaciones de cobre con aplicaciones técnicas son las siguientes:

Algunas aleaciones de cobre tienen pequeños porcentajes de azufre y de plomo que mejoran la maquinabilidad de la aleación. Tanto el plomo como el azufre tienen muy baja solubilidad en el cobre, separándose respectivamente como plomo (Pb) y como sulfuro cuproso (CuS) en los bordes de grano y facilitando la rotura de las virutas en los procesos de mecanizado, mejorando la maquinabilidad de la aleación.

El cobre nativo suele acompañar a sus minerales en bolsas que afloran a la superficie explotándose en minas a cielo abierto. El cobre se obtiene a partir de minerales sulfurados (80 %) y de minerales oxidados (20 %), los primeros se tratan por un proceso denominado pirometalurgia y los segundos por otro proceso denominado hidrometalurgia. Generalmente en la capa superior se encuentran los minerales oxidados (cuprita, melaconita), junto a cobre nativo en pequeñas cantidades, lo que explica su elaboración milenaria ya que el metal podía extraerse fácilmente en hornos de fosa. A continuación, por debajo del nivel freático, se encuentran las piritas (sulfuros) primarias calcosina (CuS) y covellina (CuS) y finalmente las secundarias calcopirita (FeCuS) cuya explotación es más rentable que la de las anteriores. Acompañando a estos minerales se encuentran otros como la bornita (CuFeS), los cobres grises y los carbonatos azurita y malaquita que suelen formar masas importantes en las minas de cobre por ser la forma en la que usualmente se alteran los sulfuros.

La tecnología de obtención del cobre está muy bien desarrollada aunque es laboriosa debido a la pobreza de la ley de los minerales. Los yacimientos de cobre contienen generalmente concentraciones muy bajas del metal. Ésta es la causa de que muchas de las distintas fases de producción tengan por objeto la eliminación de impurezas.

La metalurgia del cobre depende de que el mineral se presente en forma de sulfuros o de óxidos (cuproso u cúprico).

Para los sulfuros se utiliza para producir cátodos la vía llamada pirometalurgia, que consiste en el siguiente proceso: Conminución del mineral -> Concentración (flotación) -> fundición en horno -> paso a convertidores -> afino -> moldeo de ánodos -> electrorefinación -> cátodo. El proceso de refinado produce unos cátodos con un contenido del 99,9 % de cobre. Los cátodos son unas planchas de un metro cuadrado y un peso de 55 kg.

Otros componentes que se obtienen de este proceso son hierro (Fe) y azufre (S), además de muy pequeñas cantidades de plata (Ag) y oro (Au). Como impurezas del proceso se extraen también plomo (Pb), arsénico (As) y mercurio (Hg).

Como regla general una instalación metalúrgica de cobre que produzca 300.000 t/año de ánodos, consume 1.000.000 t/año de concentrado de cobre y como subproductos produce 900.000 t/año de ácido sulfúrico y 300.000 t/año de escorias.

Cuando se trata de aprovechar los residuos minerales, la pequeña concentración de cobre que hay en ellos se encuentra en forma de óxidos y sulfuros, y para recuperar ese cobre se emplea la tecnología llamada hidrometalurgia, más conocida por su nomenclatura anglosajona Sx-Ew.

El proceso que sigue esta técnica es el siguiente: Mineral de cobre-> lixiviación-> extracción-> electrólisis-> cátodo

Esta tecnología se utiliza muy poco porque la casi totalidad de concentrados de cobre se encuentra formando sulfuros, siendo la producción mundial estimada de recuperación de residuos en torno al 15 % de la totalidad de cobre producido.

El cobre y sus aleaciones permiten determinados tratamientos térmicos para fines muy determinados siendo los más usuales los de recocido, refinado y temple.

El cobre duro recocido se presenta muy bien para operaciones en frío como son: doblado, estampado y embutido. El recocido se produce calentando el cobre o el latón a una temperatura adecuada en un horno eléctrico de atmósfera controlada, y luego se deja enfriar al aire. Hay que procurar no superar la temperatura de recocido porque entonces se quema el cobre y se torna quebradizo y queda inutilizable.

El refinado es un proceso controlado de oxidación seguida de una reducción. El objetivo de la oxidación es eliminar las impurezas contenidas en el cobre, volatilizándolas o reduciéndolas a escorias. A continuación la reducción es mejorar la ductilidad y la maleabilidad del material.

Los tratamientos térmicos que se realizan a los latones son principalmente recocidos de homogeneización, recristalización y estabilización. Los latones con más del 35 % de Zn pueden templarse para hacerlos más blandos.

Los bronces habitualmente se someten a tratamientos de recocidos de homogeneización para las aleaciones de moldeo; y recocidos contra dureza y de recristalización para las aleaciones de forja. El temple de los bronces de dos elementos constituyentes es análogo al templado del acero: se calienta a unos 600 °C y se enfría rápidamente. Con esto se consigue disminuir la dureza del material, al contrario de lo que sucede al templar acero y algunos bronces con más de dos componentes.

Ya sea considerando la cantidad o el valor del metal empleado, el uso industrial del cobre es muy elevado. Es un material importante en multitud de actividades económicas y ha sido considerado un recurso estratégico en situaciones de conflicto.

El cobre se utiliza tanto con un gran nivel de pureza, cercano al 100 %, como aleado con otros elementos. El cobre puro se emplea principalmente en la fabricación de cables eléctricos.

El cobre es el metal no precioso con mejor conductividad eléctrica. Esto, unido a su ductilidad y resistencia mecánica, lo han convertido en el material más empleado para fabricar cables eléctricos, tanto de uso industrial como residencial. Asimismo se emplean conductores de cobre en numerosos equipos eléctricos como generadores, motores y transformadores. La principal alternativa al cobre en estas aplicaciones es el aluminio.

También son de cobre la mayoría de los cables telefónicos, los cuales además posibilitan el acceso a Internet. Las principales alternativas al cobre para telecomunicaciones son la fibra óptica y los sistemas inalámbricos. Por otro lado, todos los equipos informáticos y de telecomunicaciones contienen cobre en mayor o menor medida, por ejemplo en sus circuitos integrados, transformadores y cableado interno.

El cobre se emplea en varios componentes de coches y camiones, principalmente los radiadores (gracias a su alta conductividad térmica y resistencia a la corrosión), frenos y cojinetes, además naturalmente de los cables y motores eléctricos. Un coche pequeño contiene en total en torno a 20 kg de cobre, subiendo esta cifra a 45 kg para los de mayor tamaño.

También los trenes requieren grandes cantidades de cobre en su construcción: 1 - 2 toneladas en los trenes tradicionales y hasta 4 toneladas en los de alta velocidad. Además las catenarias contienen unas 10 toneladas de cobre por kilómetro en las líneas de alta velocidad.

Por último, los cascos de los barcos incluyen a menudo aleaciones de cobre y níquel para reducir el ensuciamiento producido por los seres marinos.

Una gran parte de las redes de transporte de agua están hechas de cobre o latón, debido a su resistencia a la corrosión y sus propiedades anti-bacterianas, habiendo quedado las tuberías de plomo en desuso por sus efectos nocivos para la salud humana. Frente a las tuberías de plástico, las de cobre tienen la ventaja de que no arden en caso de incendio y por tanto no liberan humos y gases potencialmente tóxicos.

El cobre y, sobre todo, el bronce se utilizan también como elementos arquitectónicos y revestimientos en tejados, fachadas, puertas y ventanas. El cobre se emplea también a menudo para los pomos de las puertas de locales públicos, ya que sus propiedades anti-bacterianas evitan la propagación de epidemias.

Dos aplicaciones clásicas del bronce en la construcción y ornamentación son la realización de estatuas y de campanas.

El sector de la construcción consume actualmente (2008) el 26 % de la producción mundial de cobre.

Desde el inicio de la acuñación de monedas en la Edad Antigua el cobre se emplea como materia prima de las mismas, a veces puro y, más a menudo, en aleaciones como el bronce y el cuproníquel.

Ejemplos de monedas que incluyen cobre puro:

Ejemplos de monedas de cuproníquel:

Ejemplos de monedas de otras aleaciones de cobre:

El cobre participa en la materia prima de una gran cantidad de diferentes y variados componentes de todo tipo de maquinaria, tales como casquillos, cojinetes, embellecedores, etc. Forma parte de los elementos de bisutería, bombillas y tubos fluorescentes, calderería, electroimanes, monedas, instrumentos musicales de viento, microondas, sistemas de calefacción y aire acondicionado. El cobre, el bronce y el latón son aptos para tratamientos de galvanizado para cubrir otros metales.

El sulfato de cobre (II) también conocido como sulfato cúprico es el compuesto de cobre de mayor importancia industrial y se emplea como abono y pesticida en agricultura, alguicida en la depuración del agua y como conservante de la madera.

El sulfato de cobre está especialmente indicado para suplir funciones principales del cobre en la planta, en el campo de las enzimas: oxidasas del ácido ascórbico, polifenol, citocromo, etc. También forma parte de la plastocianina contenida en los cloroplastos y que participa en la cadena de transferencia de electrones de la fotosíntesis. Su absorción se realiza mediante un proceso activo metabólicamente. Prácticamente no es afectado por la competencia de otros cationes pero, por el contrario, afecta a los demás cationes. Este producto puede ser aplicado a todo tipo de cultivo y en cualquier zona climática en invernaderos.

Para la decoración de azulejos y cerámica, se realizan vidriados que proporcionan un brillo metálico de diferentes colores. Para decorar la pieza una vez cocida y vidriada, se aplican mezclas de óxidos de cobre y otros materiales y después se vuelve a cocer la pieza a menor temperatura. Al mezclar otros materiales con los óxidos de cobre pueden obtenerse diferentes tonalidades. Para las decoraciones de cerámica, también se emplean películas metálicas de plata y cobre en mezclas coloidales de barnices cerámicos que proporcionan tonos parecidos a las irisaciones metálicas del oro o del cobre.

Un pigmento muy utilizado en pintura para los tonos verdes es el cardenillo, también conocido en este ámbito como "verdigris", que consiste en una mezcla formada principalmente por acetatos de cobre, que proporciona tonos verdosos o azulados.

El cobre blíster, también llamado ampollado o anódico, tiene una pureza de entre 98 y 99,5 %, y su principal aplicación es la fabricación por vía electrolítica de cátodos de cobre, cuya pureza alcanza el 99,99 %. También se puede emplear para sintetizar sulfato de cobre y otros productos químicos. Su principal aplicación es su transformación en ánodos de cobre.

El paso intermedio en la transformación de cobre blíster en cátodos de cobre es la producción de ánodos de cobre, con cerca de 99,6 % de pureza. Un ánodo de cobre tiene unas dimensiones aproximadas de 100x125 cm, un grosor de 5 cm y un peso aproximado de 350 kg.

El cátodo de cobre constituye la materia prima idónea para la producción de alambrón de cobre de altas especificaciones. Es un producto, con un contenido superior al 99,99 % de cobre, es resultante del refino electrolítico de los ánodos de cobre. Su calidad está dentro de la denominación Cu-CATH-01 bajo la norma EN 1978:1998. Se presenta en paquetes corrugados y flejes, cuya plancha tiene unas dimensiones de 980x930 mm y un grosor de 7 mm con un peso aproximado de 47 kg. Su uso fundamental es la producción de alambrón de cobre de alta calidad, aunque también se utiliza para la elaboración de otros semitransformados de alta exigencia.

Después del proceso de elaborar ánodo de cobre y cátodo de cobre se obtienen los siguientes subproductos: Ácido sulfúrico. Escoria granulada. Lodos electrolíticos. Sulfato de níquel. Yeso

El alambrón de cobre es un producto resultante de la transformación de cátodo en la colada continua. Su proceso de producción se realiza según las normas ASTM B49-92 y EN 1977.

Las características esenciales del alambrón producido por la empresa Atlantic-copper son:

El alambrón se comercializa en bobinas flejadas sobre palet de madera y protegidas con funda de plástico. Cuyas dimensiones son: Peso bobina 5000 kg, diámetro exterior 1785 mm, diámetro interior 1150 mm y altura 900 mm. Las aplicaciones del alambrón son para la fabricación de cables eléctricos que requieran una alta calidad, ya sean esmaltados o multifilares de diámetros de 0,15/0,20 mm.

El alambre de cobre desnudo se produce a partir del alambrón y mediante un proceso de desbaste y con un horno de recocido. Se obtiene alambre desnudo formado por un hilo de cobre electrolítico en tres temples, duro, semiduro y suave y se utiliza para usos eléctricos se produce en una gama de diámetros de 1 mm a 8 mm y en bobinas que pueden pesar del orden de 2250 kg. Este alambre se utiliza en líneas aéreas de distribución eléctrica, en neutros de subestaciones, conexiones a tierra de equipos y sistemas y para fabricar hilos planos, esmaltados y multifilares que pueden tener un diámetros de 0,25/0,22 mm. Está fabricado a base de cobre de alta pureza con un contenido mínimo de 99,9 % de Cu. Este tipo de alambre tiene una alta conductividad, ductilidad y resistencia mecánica así como gran resistencia a la corrosión en ambientes salobres.

Se denomina trefilado al proceso de adelgazamiento del cobre a través del estiramiento mecánico que se ejerce al mismo al partir de alambrón de 6 u 8 mm de diámetro con el objetivo de producir cables eléctricos flexibles con la sección requerida. Un cable eléctrico se compone de varios hilos que mediante un proceso de extrusión se le aplica el aislamiento exterior con un compuesto plástico de PVC o polietileno. Generalmente el calibre de entrada es de 6 a 8 mm, para luego adelgazarlo al diámetro requerido. Como el trefilado es un proceso continuo se van formando diferentes bobinas o rollos que van siendo cortados a las longitudes requeridas o establecidos por las normas y son debidamente etiquetados con los correspondientes datos técnicos del cable.

Se llama apantallado al cubrimiento de un conductor central debidamente aislado por varios hilos conductores de cobre, que entrelazados alrededor forman una pantalla. Cuando es necesario aislar un hilo conductor mediante esmaltado se le aplica una capa de barniz (poliesterimida). Estas mezclas de resinas son usadas para recubrir el conductor metálico quedando aislados del medio ambiente que lo rodea y logrando de esta forma conducir el flujo eléctrico sin problemas.

Un tubo es un producto hueco, de sección normalmente redonda, que tiene una periferia continua y que es utilizado en gasfitería, fontanería y sistemas mecánicos para el transporte de líquidos o gases. Los tubos de cobre se utilizan masivamente en edificios residenciales, comerciales e industriales.

Para la fabricación de tubo se parte, por lo general, de una mezcla de cobre refinado y de chatarra de calidad controlada, que se funde en un horno. De la colada de cobre se obtienen lingotes conocidos como «billets», que tienen forma cilíndrica, unos 300 mm de diámetro y 8 m de largo y un peso de unas 5 toneladas. Los tubos sin costura se fabrican a partir de estos lingotes mediante las operaciones siguientes:


Una de las propiedades fundamentales del cobre es su maleabilidad que permite producir todo tipo de láminas desde grosores muy pequeños, tanto en forma de rollo continuo como en planchas de diversas dimensiones, mediante las instalaciones de laminación adecuadas.

El cobre puro no es muy adecuado para fundición por moldeo porque produce "galleo". Este fenómeno consiste en que el oxígeno del aire se absorbe sobre el cobre a altas temperaturas y forma burbujas; cuando después se enfría el metal, se libera el oxígeno de las burbujas y quedan huecos microscópicos sobre la superficie de las piezas fundidas.

Sus aleaciones sí permiten fabricar piezas por cualquiera de los procesos de fundición de piezas que existen dependiendo del tipo de pieza y de la cantidad que se tenga que producir. Los métodos más usuales de fundición son por moldeo y por centrifugado.

Se denomina fundición por moldeo al proceso de fabricación de piezas, comúnmente metálicas pero también de plástico, consistente en fundir un material e introducirlo en una cavidad, llamada molde, donde se solidifica. El proceso tradicional es la fundición en arena, por ser ésta un material refractario muy abundante en la naturaleza y que, mezclada con arcilla, adquiere cohesión y moldeabilidad sin perder la permeabilidad que posibilita evacuar los gases del molde al tiempo que se vierte el metal fundido

El proceso de fundición centrifugada consiste en depositar una capa de fundición líquida en un molde de revolución girando a gran velocidad y solidificar rápidamente el metal mediante un enfriamiento continuo del molde o coquilla. Las aplicaciones de este tipo de fundición son muy variadas.

El forjado en caliente de una pieza consiste en insertar en un molde una barra de metal, calentarla a la temperatura adecuada y obligarla a deformarse plásticamente hasta adoptar la forma del molde. La ventaja de forjar en caliente es que se reduce la potencia mecánica que debe suministrar la prensa para la deformación plástica.

Los productos del cobre y sus aleaciones reúnen muy buenas condiciones para producir piezas por procesos de estampación en caliente, permitiendo el diseño de piezas sumamente complejas gracias a la gran ductilidad del material y la escasa resistencia a la deformación que opone, proporcionando así una vida larga a las matrices. Una aleación de cobre es “forjable” en caliente si existe un rango de temperaturas suficientemente amplio en el que la ductilidad y la resistencia a la deformación sean aceptables. Este rango de temperaturas depende de composición química que tenga, en la que influyen los elementos añadidos y de las impurezas.

Las piezas de cobre o de sus aleaciones que van a someterse a trabajos de mecanizado por arranque de viruta tienen en su composición química una pequeña aportación de plomo y azufre que provoca una fractura mejor de la viruta cortada.

Actualmente (2008) el mecanizado de componentes de cobre, se realiza bajo el concepto de mecanizado rápido en seco con la herramienta refrigerada por aire si es necesario. Este tipo de mecanizado rápido se caracteriza por que los cabezales de las máquinas giran a velocidades muy altas consiguiendo grandes velocidades de corte en herramientas de poco diámetro.

Asimismo, las herramientas que se utilizan suelen ser integrales de metal duro, con recubrimientos especiales que posibilitan trabajar con avances de corte muy elevados. Los recubrimientos y materiales de estas herramientas son muy resistentes al desgaste, pueden trabajar a temperaturas elevadas, de ahí que no sea necesario muchas veces su refrigeración, tienen un coeficiente de fricción muy bajo y consiguen acabados superficiales muy finos y precisos.

Para soldar uniones de cobre o de sus aleaciones se utilizan dos tipos de soldadura diferentes: soldadura blanda y soldadura fuerte.

La soldadura blanda es aquella que se realiza a una temperatura de unos 200 °C y se utiliza para la unión de los componentes de circuitos impresos y electrónicos. Se utilizan soldadores de estaño y el material de aporte es una aleación de estaño y plomo en forma de alambre en rollo y que tiene resina desoxidante en su alma. Es una soldadura poco resistente y sirve para asegurar la continuidad de la corriente eléctrica a través del circuito.

Las soldaduras de tuberías de agua y gas realizadas por los fontaneros son de diversos tipos en función de los materiales que se quieran unir y de la estanqueidad que se quiera conseguir de la soldadura. Actualmente, la mayoría de los tubos de instalaciones de fontanería son de cobre, aunque en ocasiones se usan también otros materiales.

La soldadura de tuberías de cobre se realiza con sopletes de gas que proporcionan la llama para fundir el material soldante. El combustible del soplete puede ser butano o propano.

El cobre se utiliza también como aglutinante en la soldadura fuerte de fontanería, utilizada para conducciones de gas y canalizaciones complejas de agua caliente. Un metal alternativo para esta aplicación es la plata.

Se llama calderería a una especialidad profesional de la rama de fabricación metálica que tiene como función principal la construcción de depósitos aptos para el almacenaje y transporte de sólidos en forma de granos o áridos, líquidos y gas así como todo tipo de construcción naval y estructuras metálicas. Gracias a la excelente conductividad térmica que tiene la chapa de cobre se utiliza para fabricar alambiques, calderas, serpentines, cubiertas, etc.

Se denomina embutición al proceso de conformado en frío por el que se transforma un disco o piezas recortada, según el material, en piezas huecas, e incluso partiendo de piezas previamente embutidas, estirarlas a una sección menor con mayor altura.

El objetivo es conseguir una pieza hueca de acuerdo con la forma definida por la matriz de embutición que se utilice, mediante la presión ejercida por la prensa. La matriz de embutición también es conocida como molde.

Se trata de un proceso de conformado de chapa por deformación plástica en el curso del cual la chapa sufre simultáneamente transformaciones por estirado y por recalcado produciéndose variaciones en su espesor. Para la embutición se emplean, casi exclusivamente, prensas hidráulicas.

La chapa de cobre y sus aleaciones tienen unas propiedades muy buenas para ser conformados en frío. La embutición es un buen proceso para la fabricación en chapa fina de piezas con superficies complejas y altas exigencias dimensionales, sustituyendo con éxito a piezas tradicionalmente fabricadas por fundición y mecanizado.

Se conoce con el nombre de estampación a la operación mecánica que se realiza para grabar un dibujo o una leyenda en la superficie plana de una pieza que generalmente es de chapa metálica. Las chapas de cobre y sus aleaciones reúnen condiciones muy buenas para realizar en ellas todo tipo de grabados.

Los elementos claves de la estampación lo constituyen una prensa que puede ser mecánica, neumática o hidráulica; de tamaño, forma y potencia muy variada, y una matriz llamada estampa o troquel, donde está grabado el dibujo que se desea acuñar en la chapa, y que al dar un golpe seco sobre la misma queda grabado.

El estampado de los metales se realiza por presión o impacto, donde la chapa se adapta a la forma del molde. La estampación es una de las tareas de mecanizado más fáciles que existen, y permite un gran nivel de automatismo del proceso cuando se trata de realizar grandes cantidades de piezas.

La estampación se puede realizar en frío o en caliente, la estampación de piezas en caliente se llama forja, y tiene un funcionamiento diferente a la estampación en frío que se realiza en chapas generalmente. Las chapas de acero, aluminio, plata, latón y oro son las más adecuadas para la estampación. Una de las tareas de estampación más conocidas es la que realiza el estampado de las caras de las monedas en el proceso de acuñación de las mismas.

Se denomina troquelado a la operación mecánica que se realiza para producir piezas de chapa metálica o donde sea necesario realizar diversos agujeros en las mismas. Para realizar esta tarea, se utilizan desde simples mecanismos de accionamiento manual hasta sofisticadas prensas mecánicas de gran potencia.

Los elementos básicos de una prensa troqueladora lo constituyen el troquel que tiene la forma y dimensiones exteriores de la pieza o de los agujeros que se quieran realizar, y la matriz de corte por donde se inserta el troquel cuando es impulsado de forma enérgica por la potencia que le proporciona la prensa mediante un accionamiento de excéntrica que tiene y que proporciona un golpe seco y contundente sobre la chapa, produciendo un corte limpio de la misma.

Según el trabajo que se tenga que realizar, así son diseñadas y construidas las prensas. Hay matrices simples y progresivas donde la chapa, que está en forma de grandes rollos, avanza automáticamente provocando el trabajo de forma continuado, y no requiriendo otros cuidados que cambiar de rollo de chapa cuando se termina e ir retirando las piezas troqueladas así como vigilar la calidad del corte que realizan.

Cuando el corte se deteriora por desgaste del troquel y de la matriz, se desmontan de la máquina y se les rectifica en una rectificadora plana, estableciendo un nuevo corte. Una matriz y un troquel permiten muchos reafilados hasta que se desgastan totalmente.

Hay troqueladoras que funcionan con un cabezal donde puede llevar insertado varios troqueles de diferentes medidas y una mesa amplia donde se coloca la chapa que se quiere mecanizar. Esta mesa es activada mediante CNC y se desplaza a lo largo y ancho de la misma a gran velocidad, produciendo las piezas con rapidez y exactitud.

Los mecanismos subyacentes a los efectos de intoxicación por Cu en humanos no son muy comprendidos. El Cu es un metal de transición que, al igual que el resto de este tipo de metales (excepto el Zn), tiene electrones desapareados en sus orbitales externos. Por este motivo es que estos metales pueden ser considerados radicales libres.

El Cobre puede ser encontrado en muchas clases de comidas, en el agua potable y en el aire. Debido a que absorbemos una cantidad eminente de cobre cada día por la comida, bebiendo y respirando. La absorción del Cobre es necesaria, porque el Cobre es un elemento traza que es esencial para la salud de los humanos. Aunque los humanos pueden manejar concentraciones de Cobre proporcionalmente altas, mucho cobre puede también causar problemas de salud.

Las concentraciones del Cobre en el aire son usualmente bastante bajas, así que la exposición al Cobre por respiración es insignificante. Pero gente que vive cerca de fundiciones que procesan el mineral cobre en metal pueden experimentar esta clase de exposición.

La gente que vive en casas que todavía tiene tuberías de cobre están expuestas a más altos niveles de Cobre que la mayoría de la gente, porque el Cobre es liberado en sus aguas a través de la corrosión de las tuberías.

La producción mundial de Cobre está todavía creciendo. Esto básicamente significa que más y más Cobre termina en el medio ambiente. Los ríos están depositando barro en sus orillas que están contaminados con Cobre, debido al vertido de aguas residuales contaminadas con Cobre. El Cobre entra en el aire, mayoritariamente a través de la liberación durante la combustión de fuel. El Cobre en el aire permanecerá por un periodo de tiempo eminente, antes de depositarse cuando empieza a llover. Este terminará mayormente en los suelos, como resultado los suelos pueden también contener grandes cantidades de Cobre después de que esté sea depositado desde el aire.

El Cobre puede ser liberado en el medio ambiente tanto por actividades humanas como por procesos naturales. Ejemplo de fuentes naturales son las tormentas de polvo, descomposición de la vegetación, incendios forestales y aerosoles marinos. El Cobre es a menudo encontrado cerca de minas, asentamientos industriales, vertederos y lugares de residuos.

Cuando el Cobre termina en el suelo este es fuertemente atado a la materia orgánica y minerales.

El Cobre no se rompe en el ambiente y por eso se puede acumular en plantas y animales cuando este es encontrado en suelos. En suelos ricos en Cobre sólo un número pequeño de plantas pueden vivir. El Cobre puede seriamente influir en el proceso de ciertas tierras agrícolas, dependiendo de la acidez del suelo y la presencia de materia orgánica. A pesar de esto el estiércol que contiene Cobre es todavía usado.

El Cobre puede interrumpir la actividad en el suelo, su influencia negativa en la actividad de microorganismos y lombrices de tierra. La descomposición de la materia orgánica puede disminuir debido a esto.

Cuando los suelos de las granjas están contaminados con Cobre, los animales pueden absorber concentraciones de Cobre que dañan su salud. Principalmente las ovejas sufren un gran efecto por envenenamiento con Cobre, debido a que los efectos del Cobre se manifiestan a bajas concentraciones.

A pesar de que en los trabajos químicos de referencia se indica que las sales de cobre son tóxicas, en la práctica esto sólo es cierto cuando las disoluciones se utilizan de forma incontrolada, con fines suicidas o como tratamiento tópico de áreas con quemaduras graves. Cuando se ingiere sulfato de cobre, también conocido como piedra azul o azul vitriolo, en cantidades del orden de gramos, se producen náuseas, vómitos, diarrea, sudoración, hemólisis intravascular y posible fallo renal; en raras ocasiones, se observan también convulsiones, coma y la muerte. Cuando se beben aguas carbonatadas o zumos de cítricos que han estado en contacto con recipientes, cañerías, grifos o válvulas de cobre se puede producir irritación del tracto gastrointestinal, que pocas veces llega a ser grave. Este tipo de bebidas son suficientemente ácidas para disolver niveles de cobre irritantes. Existe un informe de úlceras corneales e irritación cutánea, con baja toxicidad de otro tipo, en un minero de cobre que cayó en un baño electrolítico, aunque la causa pudo haber sido la acidez más que el cobre. En algunos casos en que se utilizaron sales de cobre para el tratamiento de quemaduras, se observaron concentraciones elevadas de cobre sérico y manifestaciones tóxicas. La inhalación de polvos, humos o nieblas de sales de cobre puede causar congestión nasal y de las mucosas, y ulceración con perforación del tabique nasal. Los humos desprendidos durante el calentamiento del cobre metálico pueden producir fiebre, náuseas, gastralgias y diarrea.

Efectos tóxicos crónicos atribuibles al cobre sólo parecen existir en personas que han heredado una pareja específica de genes recesivos autosómicos y que, como consecuencia, desarrollan una degeneración hepatolenticular (enfermedad de Wilson). Es una enfermedad rara. La mayor parte de la alimentación diaria que consume el hombre contiene de 2 a 5 mg de cobre, que prácticamente no se retiene en el organismo. El contenido corporal de cobre en una persona adulta es de 100 a 150 mg y es casi constante. En individuos normales (sin enfermedad de Wilson), casi todo el cobre está presente como parte integrante y funcional de una docena de proteínas y sistemas enzimáticos, como la citocromo oxidasa, la dopa-oxidasa y la ceruloplasmina sérica. En personas que ingieren grandes cantidades de ostras o mariscos de concha, hígado, setas, nueces y chocolate, alimentos todos ellos ricos en cobre, o en mineros que trabajan y comen durante 20 años o más en un ambiente cargado con un 1 o 2 % de polvo de minerales de cobre, pueden llegar a observarse concentraciones hasta 10 veces superiores a lo normal. Sin embargo, aún no se ha descrito ningún caso de toxicidad crónica primaria por cobre (perfectamente definida a partir de las observaciones de pacientes con toxicosis por cobre crónica heredada "la enfermedad de Wilson" como disfunción y lesiones estructurales hepáticas, del sistema nervioso central, de los riñones, los huesos y los ojos) excepto en personas que padecen la enfermedad de Wilson. Sin embargo, los depósitos excesivos de cobre hallados en el hígado de pacientes con cirrosis biliar primaria, colestasis y cirrosis infantil de la India pueden contribuir a la gravedad de la enfermedad hepática característica de estos procesos.

Los mecanismos subyacentes a los efectos de intoxicación por Cu en humanos no son muy comprendidos. El Cu es un metal de transición que, al igual que el resto de este tipo de metales (excepto el Zn), tiene electrones desapareados en sus orbitales externos. Por este motivo es que estos metales pueden ser considerados radicales libres. El Cu, al igual que el hierro puede participar en las reacciones tipo Fenton (1) y Häber-Weiss (2) produciendo ROS:
Las sales de Cu+ reaccionan con el HO con mayor eficiencia que el Fe. De modo que el principal mecanismo de toxicosis mediada por cobre puede descansar en su habilidad para provocar sobreproducción de ROS y subsecuente daño pro-oxidativo a lípidos, ácidos nucleicos y proteínas

El cobre tiene importantes efectos como agente citotóxico y genotóxico desarrollando un papel importante en la etiopatogénesis de las neoplasias . Este último mecanismo consiste en dañar la estructura molecular del ADN por vía indirecta (ROS) o directamente por formación de complejos con grupos funcionales de las bases nitrogenadas que las modifican introduciendo mutaciones, o dificultando el proceso de reparación.

Se cree que una de las vías por las que los iones Cu ejercen su efecto tóxico es produciendo un aumento del estrés oxidativo en múltiples tejidos del organismo.

El cobre es uno de los pocos materiales que no se degradan ni pierden sus propiedades químicas o físicas en el proceso de reciclaje. Puede ser reciclado un número ilimitado de veces sin perder sus propiedades, siendo imposible distinguir si un objeto de cobre está hecho de fuentes primarias o recicladas. Esto hace que el cobre haya sido, desde la Antigüedad, uno de los materiales más reciclados.

El reciclado proporciona una parte fundamental de las necesidades totales de cobre metálico. Se estima que en 2004 el 9 % de la demanda mundial se satisfizo mediante el reciclado de objetos viejos de cobre. Si también se considera "reciclaje" el refundido de los desechos del proceso de refinado del mineral, el porcentaje de cobre reciclado asciende al 34 % en el mundo y hasta un 41 % en la Unión Europea.

El reciclado del cobre no requiere tanta energía como su extracción minera. A pesar de que el reciclado requiere recoger, clasificar y fundir los objetos de metal, la cantidad de energía necesaria para reciclar el cobre es solo alrededor de un 25 % de la requerida para convertir el mineral de cobre en metal.

La eficacia del sistema de reciclado depende de factores tecnológicos como el diseño de los productos, económicos como el precio del cobre y sociales como el concienciamiento de la población acerca del desarrollo sostenible. Otro factor clave es la legislación. Actualmente existen más de 140 leyes, regulaciones, directivas y guías nacionales e internacionales que tratan de favorecer la gestión responsable del final del ciclo de vida de los productos que contienen cobre como por ejemplo electrodomésticos, teléfonos y vehículos.

En la Unión Europea, la directiva 2002/96/CE sobre residuos de aparatos eléctricos y electrónicos (RAEE, o "WEEE" del inglés "Waste Electrical and Electronic Equipment") propicia una política de minimización de desperdicios, que incluye una obligatoria y drástica reducción de los desechos industriales y domiciliarios, e incentivos para los productores que producen menos residuos. El objetivo de esta iniciativa era reciclar 4 kilos por habitante al año a fines de 2006.

Un ejemplo de reciclaje masivo de cobre lo constituyó la sustitución de las monedas nacionales de doce países europeos por el euro en 2002, el cambio monetario más grande de la historia. Se eliminaron de la circulación unas 260.000 toneladas de monedas, conteniendo aproximadamente 147.496 toneladas de cobre, que fueron fundidas y recicladas para su uso en una amplia gama de productos, desde nuevas monedas hasta diferentes productos industriales.

La producción mundial de cobre durante el 2014 alcanzó un total de 18.7 millones de toneladas métricas de cobre fino. El principal país productor es Chile, con casi un tercio del total, seguido por China y Perú:
De entre las diez mayores minas de cobre del mundo, cinco se encuentran en Chile (Escondida, Codelco Norte, Collahuasi, El Teniente y Los Pelambres), dos en Indonesia, una en Estados Unidos, una en Rusia y otra en Perú (Antamina).

De acuerdo a información entregada en el informe anual del United States Geological Survey (USGS), las estimaciones señalan que las reservas conocidas de cobre en el 2011 a nivel mundial alcanzarían 690 millones de toneladas métricas de cobre fino. Y según las estimaciones de USGS, en Chile existirían del orden de 190 millones de toneladas económicamente explotables, equivalentes al 28 % del total de reservas mundiales del mineral; seguido de Perú con 90 millones de toneladas económicamente explotables, equivalentes al 13 % del total de reservas mundiales del mineral:

El cobre es el tercer metal más utilizado en el mundo, por detrás del hierro y el aluminio.
Existe un importante comercio mundial de cobre que mueve unos 30.000 millones de dólares anuales.

Los tres principales mercados de cobre son el LME de Londres, el COMEX de Nueva York y la Bolsa de Metales de Shanghái. Estos mercados fijan diariamente el precio del cobre y de los contratos de futuros sobre el metal. El precio de suele expresar en dólares / libra y en la última década ha oscilado entre los 0,65 $/lb de finales de 2001 y los más de 4,00 $/lb alcanzados en 2006 y en 2008. El fuerte encarecimiento del cobre desde 2004, debido principalmente al aumento de la demanda de China y otras economías emergentes, ha provocado una oleada de robos de objetos de cobre (sobre todo cables) en todo el mundo, con los consiguientes riesgos para la infraestructura eléctrica.

Los principales productores de mineral de cobre son también los principales exportadores, tanto de mineral como de cobre refinado y derivados. Los principales importadores son los países industrializados: Japón, China, India, Corea del Sur y Alemania para el mineral y Estados Unidos, Alemania, China, Italia y Taiwán para el refinado.





</doc>
<doc id="11487" url="https://es.wikipedia.org/wiki?curid=11487" title="Ductilidad">
Ductilidad

La ductilidad es una propiedad que presentan algunos materiales, como las aleaciones metálicas o materiales asfálticos, los cuales bajo la acción de una fuerza, pueden deformarse plásticamente de manera sostenible sin romperse, permitiendo obtener alambres o hilos de dicho material. A los materiales que presentan esta propiedad se les denomina "dúctiles". Los materiales no dúctiles se califican como frágiles. Aunque los materiales dúctiles también pueden llegar a romperse bajo el esfuerzo adecuado, esta rotura sólo sucede tras producirse grandes deformaciones.

En otros términos, un material es dúctil cuando la relación entre el alargamiento longitudinal producido por una tracción y la disminución de la sección transversal es muy elevada.

En el ámbito de la metalurgia se entiende por metal dúctil aquel que sufre grandes deformaciones antes de romperse, siendo el opuesto al metal frágil, que se rompe sin apenas deformación. Nótese que la ductilidad es un fenómeno observable sólo en régimen plástico.

No debe confundirse dúctil con blando, ya que la ductilidad es una propiedad que como tal se manifiesta una vez que el material está soportando una fuerza considerable, suficiente para producir plastificación. Esto es, mientras la carga sea pequeña, la deformación también lo será y en general la deformación será elástica y reversible, sin embargo, alcanzado cierto punto el material cede fluye por plastificación, deformándose en mucha mayor medida de lo que lo había hecho hasta entonces pero sin llegar a romperse.

En un ensayo de tracción, los materiales dúctiles presentan una fase de fluencia caracterizada por una gran deformación sin apenas incremento de la carga. Desde un punto de vista tecnológico, al margen de consideraciones económicas, el empleo de materiales dúctiles presenta ventajas:

La ductilidad de un metal se valora de forma indirecta a través de la resiliencia. La ductilidad es la propiedad de los metales para formar alambres o hilos de diferentes grosores. Los metales se caracterizan por su elevada ductilidad, la que se explica porque los átomos de los metales se disponen de manera tal que es posible que se deslicen unos sobre otros y por eso se pueden estirar sin romperse.

Tras una prueba de tensión, o prueba de tracción, son dos las "medidas" que nos proporcionan información acerca de la "ductilidad" de un material: el porcentaje de elongación y la reducción porcentual en el área.

Donde "L" es la distancia entre las marcas calibradas tras la falla de la muestra.

donde Af es el área de la sección transversal final en la superficie de la fractura.




</doc>
<doc id="11494" url="https://es.wikipedia.org/wiki?curid=11494" title="Cayo">
Cayo

Un cayo, término de origen antillano, es una pequeña isla con una playa de baja profundidad, formada en la superficie de un arrecife de coral.

Los cayos por lo general se encuentran en ambientes tropicales de los océanos Pacífico, Atlántico e Índico (incluidos el mar Caribe, la Gran barrera de coral y el arrecife de barrera de Belice), donde pueden proporcionar tierra habitable y agrícola para cientos de miles de personas. Sus ecosistemas de arrecifes que lo rodean también proporcionan alimentos y materiales de construcción para los habitantes de la isla. Un inconveniente habitual en estas superficies terrestres es la falta de agua potable.

Al conjunto de cayos se le llama cayería. Algunos de ellos pueden ser de considerable extensión territorial, como es el caso del cayo Coco (aproximadamente 370 kilómetros cuadrados), al norte de la isla de Cuba, que constituye así la cuarta mayor isla del archipiélago cubano, después de la isla de Cuba y de la isla de Pinos o isla de la Juventud y del cayo Romano (vecino a cayo Coco).

Un cayo se forma cuando las corrientes oceánicas transportan sedimento suelto a través de la superficie de un arrecife hacia un nodo de depósitos, lugar donde la corriente disminuye o converge con otra corriente, liberando su carga de sedimentos. Poco a poco, las capas de la acumulación de sedimentos son depositadas en la superficie del arrecife.

Estos nodos se producen en áreas de superficies de arrecifes en barlovento o sotavento, aunque a veces surgen alrededor de un afloramiento de un antiguo arrecife emergente o en una playa rocosa.

La isla que resulta de la acumulación de sedimentos se compone casi enteramente de sedimento biogénico –restos de esqueletos de plantas y animales– de los ecosistemas de arrecifes circundantes. Si los sedimentos acumulados son predominantemente arena, la isla se llama "cayo", y si son predominantemente de grava, la isla se llama "islote".

Los sedimentos de un cayo están compuestos principalmente de carbonato de calcio (CaCO), aragonito, calcita y calcita magnésica. Estos son producidos por diversas plantas (por ejemplo, algas coralinas y especies del alga verde Halimeda) y animales (por ejemplo, el coral, moluscos o foraminíferos). Suelen encontrarse pequeñas cantidades de silicato de sedimento también aportado por esponjas de mar y otros animales similares. Con el tiempo, el suelo y la vegetación se pueden desarrollar en la superficie de un cayo, asistidos por el depósito del guano de las aves marinas.

Una gama de influencias físicas, biológicas y químicas determinan el desarrollo en curso o la erosión del entorno de los cayos. Estas influencias son: la extensión de acumulaciones de arrecifes de arena superficiales, los cambios en las olas del mar, las corrientes, las mareas, los niveles del mar y las condiciones meteorológicas, la forma del arrecife subyacente, los tipos y abundancia de la biota carbonato de producción y otros organismos, tales como aglutinantes, bioerosionadores y bioturbadores (criaturas que se unen, erosionan y mezclan sedimentos) que viven en los alrededores de los ecosistemas de arrecifes.

Los cambios significativos en los cayos y sus ecosistemas circundantes pueden ser resultado de fenómenos naturales como el Fenómeno del Niño o los severos ciclos del Fenómeno del Enos. Además, los ciclones tropicales pueden ayudar a construir o destruir estas islas.

Hay un gran debate y preocupación por la estabilidad futura de los cayos frente a las crecientes poblaciones humanas y las presiones sobre los ecosistemas de los arrecifes que las componen, así como las predicciones de cambios climáticos y el aumento del nivel del mar. A esto se suma que se desconoce con certeza cuántos años poseen los cayos en cuanto a su formación actual para tomar decisiones conservacionistas al respecto.

Para ello, es necesario entender el potencial de cambio en las fuentes de sedimentos para la creación de playas en los cayos, con vistas a determinar si el cambio del medio ambiente es un factor importante para predecir su estabilidad presente y futura. A pesar de ello, hay consenso en que estos ambientes insulares son muy complejos y algo frágiles a los elementos externos.

Los cayos suelen tener mayor variedad de insectos y reptiles que las islas normales.

La preservación del ambiente de los cayos se ve comprometida por el avance de los proyectos turísticos, que aprovechan la belleza de las playas, la riqueza de la vegetación y los excelentes sitios de buceo. Los cayos son reductos frágiles de flora y fauna, que deben ser respetados y cuidados. Así, en muchos proyectos se incentiva una interacción respetuosa con el ambiente, como son el buceo contemplativo y las excursiones ecológicas.








</doc>
<doc id="11496" url="https://es.wikipedia.org/wiki?curid=11496" title="Mesosfera">
Mesosfera

En meteorología se denomina mesosfera o mesósfera a la parte de la atmósfera terrestre situada por encima de la estratosfera y por debajo de la termosfera. Es la capa de la atmósfera en la que la temperatura va disminuyendo a medida que se aumenta la altura, hasta llegar a unos −80 °C a los 80 kilómetros aproximadamente. Se extiende desde la estratopausa (zona de contacto entre la estratosfera y la mesosfera). La mesosfera es la tercera capa de la atmósfera de la Tierra. Es la zona más fría de la atmósfera.

Contiene sólo cerca del 0,1 % de la masa total del aire. Es importante por la ionización y las reacciones químicas que ocurren en ella. La baja densidad del aire en la mesosfera determinan la formación de turbulencias y ondas atmosféricas que actúan a escalas espaciales y temporales muy grandes. La mesosfera es la región donde las naves espaciales que vuelven a la Tierra empiezan a notar la estructura de los vientos de fondo, y no sólo el freno aerodinámico. También en esta capa se observan las estrellas fugaces que son meteoroides que se han desintegrado en la termosfera.

En ella se desintegran los meteoritos que se dirigen a la Tierra provocando destellos de luz llamados Estrellas Fugaces.

Debido a que la mesosfera se encuentra por encima de la altitud máxima de globos y aviones, pero demasiado baja para los satélites artificiales, sólo puede estudiarse con cohetes sonda durante tiempo limitado. Por esta razón, es la zona peor entendida de la atmósfera y entre los científicos ha dado lugar al apodo humorístico "ignorosfera".


</doc>
<doc id="11497" url="https://es.wikipedia.org/wiki?curid=11497" title="Efecto Coriolis">
Efecto Coriolis

El efecto Coriolis, descrito en 1836 por el científico francés Gaspard-Gustave Coriolis, es el efecto que se observa en un sistema de referencia en rotación cuando un cuerpo se encuentra en movimiento respecto de dicho sistema de referencia. Este efecto consiste en la existencia de una aceleración "relativa" del cuerpo en dicho sistema en rotación. Esta aceleración es siempre perpendicular al eje de rotación del sistema y a la velocidad del cuerpo.

El efecto Coriolis hace que un objeto que se mueve sobre el radio de un disco en rotación tienda a acelerarse con respecto a ese disco según si el movimiento es hacia el eje de giro o alejándose de éste. Por el mismo principio, en el caso de una esfera en rotación, el movimiento de un objeto sobre los meridianos también presenta este efecto, ya que dicho movimiento reduce o incrementa la distancia respecto al eje de giro de la esfera.

Debido a que el objeto sufre una aceleración desde el punto de vista del observador en rotación, es como si para éste existiera una fuerza sobre el objeto que lo acelera. A esta fuerza se le llama "fuerza de Coriolis", y no es una fuerza real en el sentido de que no hay nada que la produzca. Se trata pues de una fuerza inercial o ficticia, que se introduce para explicar, desde el punto de vista del sistema en rotación, la aceleración del cuerpo, cuyo origen está en realidad, en el hecho de que el sistema de observación está rotando.

Un ejemplo canónico de efecto Coriolis es el experimento imaginario en el que disparamos un proyectil desde el Ecuador en dirección norte. El cañón está girando con la tierra hacia el este y, por tanto, imprime al proyectil esa velocidad (además de la velocidad hacia adelante al momento de la impulsión). Al viajar el proyectil hacia el norte, sobrevuela puntos de la tierra cuya velocidad lineal hacia el este va disminuyendo con la latitud creciente. La inercia del proyectil hacia el este hace que su velocidad angular aumente y que, por tanto, adelante a los puntos que sobrevuela. Si el vuelo es suficientemente largo (ver cálculos al final del artículo), el proyectil caerá en un meridiano situado al este de aquél desde el cual se disparó, a pesar de que la dirección del disparo fue exactamente hacia el norte. Finalmente, el efecto Coriolis, al actuar sobre masas de aire (o agua) en latitudes intermedias, induce un giro al desviar hacia el este o hacia el oeste las partes de esa masa que ganen o pierdan latitud o altitud en su movimiento.

La fuerza de Coriolis es una fuerza ficticia que aparece cuando un cuerpo está en movimiento con respecto a un sistema en rotación y se describe su movimiento en ese referencial. La fuerza de Coriolis es diferente de la fuerza centrífuga. La fuerza de Coriolis siempre es perpendicular a la dirección del eje de rotación del sistema y a la dirección del movimiento del cuerpo vista desde el sistema en rotación. La fuerza de Coriolis tiene dos componentes:
La componente del movimiento del cuerpo paralela al eje de rotación no engendra fuerza de Coriolis. El valor de la fuerza de Coriolis formula_1 es:

donde:

En 1835, GIL BEBE Gaspard-Gustave de Coriolis, en su artículo "Sur les équations du mouvement relatif des systèmes de corps", describió matemáticamente la fuerza que terminó llevando su nombre. En ese artículo, la fuerza de Coriolis aparece como una componente suplementaria a la fuerza centrífuga experimentada por un cuerpo en movimiento relativo a un referencial en rotación, como puede producirse, por ejemplo, en los engranajes de una máquina.
El razonamiento de Coriolis se basaba sobre un análisis del trabajo y de la energía potencial y cinética en los sistemas en rotación. Ahora, la demostración más utilizada para enseñar la fuerza de Coriolis utiliza las herramientas de la cinemática.

Esta fuerza no comenzó a aparecer en la literatura meteorológica y oceanográfica hasta finales del siglo XIX. El término "fuerza de Coriolis" apareció a principios del siglo XX.

Para demostrar la expresión analítica expresada en la introducción, pueden usarse dos aproximaciones diferentes: por conservación del momento angular o por derivación en base móvil. A continuación se explican ambas.

Es preciso recordar que cuando un observador en un sistema no inercial (como lo es un sistema en rotación) trata de comprender el comportamiento de su sistema como si fuese un sistema inercial ve aparecer fuerzas ficticias. En el caso de un sistema en rotación, el observador ve que todos los objetos que no están sujetos se alejan de manera radial como si actuase sobre ellos una fuerza proporcional a sus masas y a la distancia a una cierta recta (el eje de rotación). Esa es la fuerza centrífuga que hay que compensar con la fuerza centrípeta para sujetar los objetos. Por supuesto, para un observador externo, situado en un sistema inercial (sistema fijo), la única fuerza que existe es la fuerza centrípeta, cuando los objetos están sujetos. Si no lo están, los objetos tomarán la tangente y se alejarán del eje de rotación.

Si los objetos no están inmóviles con respecto al observador del sistema en rotación, otra fuerza ficticia aparece: la fuerza de Coriolis. Visto desde el sistema en rotación, el movimiento de un objeto se puede descomponer en una componente paralela al eje de rotación, otra componente radial (situada sobre una línea que pasa por el eje de rotación y perpendicular a éste), y una tercera componente tangencial (tangente a un círculo centrado en el eje y perpendicular a éste) (ver gráfica).

Un objeto que se desplaza paralelamente al eje de rotación, visto de un sistema fijo, gira con el sistema en rotación a la misma velocidad angular y con radio constante. La única fuerza que actúa sobre el objeto es la fuerza centrípeta. El observador del sistema en rotación sólo nota la fuerza centrífuga contra la cual hay que oponerse para que se quede a la misma distancia del eje.

Supóngase que un observador en el sistema en rotación mantiene una masa formula_6 a una distancia formula_7 del eje de rotación mediante un hilo de masa despreciable. El observador tira del hilo y modifica ligeramente el radio de rotación de la masa de formula_8. Eso le ha tomado un tiempo formula_9. Como el momento dinámico es nulo, el momento angular de la masa se conserva. Si formula_10 es la velocidad de la masa, la conservación del momento angular expresa:

El signo menos indica que cuando el radio aumenta la velocidad tangencial disminuye.

Si la masa se moviese siguiendo una trayectoria radial, fija con respecto al sistema en rotación, conservando en consecuencia la misma velocidad angular formula_13 del sistema en rotación, su velocidad lineal habría aumentado de formula_14 (o disminuido, si formula_8 es negativo). Para un observador fijo, entre la velocidad de la masa que se ve obligada a seguir una trayectoria radial y la velocidad de la masa que conserva su momento angular hay una diferencia de:

Como el objeto no está sujeto al sistema en rotación, el observador en ese sistema ve la masa tomar una velocidad lateral formula_17. Eso se interpreta como la aplicación de una fuerza lateral (de Coriolis). Si el cambio de velocidad tomó formula_9 segundos, la aceleración de Coriolis será (en valor absoluto):

donde formula_20 es la velocidad radial. Esa aceleración corresponde a una fuerza (de Coriolis) de:

Considerando un objeto con velocidad tangencial formula_22 vista por el observador en el sistema en rotación. Esta vez, la misma masa tenida por un hilo tiene una velocidad angular diferente del sistema en rotación. Para el observador en el sistema en rotación, las fuerzas que nota aplicadas a la masa para que siga una trayectoria circular son: la fuerza centrífuga formula_23 que ve aplicada en todos los objetos, más la fuerza centrípeta debido a la rotación aparente de la masa formula_24. Pero eso no basta. Hay aún otra fuerza aparente, y es precisamente la fuerza de Coriolis. Se calcula ahora la fuerza centrípeta que ve un observador fijo: la velocidad tangencial es formula_25. Para este observador, la fuerza centrípeta que mantiene la masa a distancia constante será:

El primer término es la fuerza centrífuga común a todos los objetos que giran con el sistema en rotación. El tercero es la fuerza centrípeta debida a la rotación de la masa con respecto al sistema en rotación. Y el segundo término es la fuerza de Coriolis. Es un término suplementario debido al hecho de que la fuerza centrípeta depende del cuadrado de la velocidad tangencial y no puede obtenerse sumando las fuerzas centrífuga y centrípeta debido a velocidades parciales. La fuerza de Coriolis es:

Como se ha dicho , esa fuerza es radial.

Para esta demostración se utilizará el subíndice abs para indicar magnitudes vistas desde el sistema de referencia inercial, es decir, uno donde el espacio sea homogéneo e isótropo y donde el tiempo sea constante. El subíndice rel (relativa) se refiere a magnitudes vistas desde una referencia no galileana o no inercial. El subíndice ar (arrastre) hace referencia al movimiento de la base móvil respecto a la base fija. También es necesario conocer cómo se deriva en una base móvil:

Una aceleración es un cambio en la magnitud o en la orientación de la velocidad respecto del tiempo. Para esa demostración se considera un movimiento que no varía la magnitud de su velocidad, es decir, que no está sometido a fuerzas que tengan alguna componente en la dirección del movimiento. Entonces:

Por una parte:

Por otra:
donde:
Como no se considera el movimiento alrededor del Sol, sino sólo el giro de la tierra en torno a sí misma:

Además, como se está imaginando un movimiento sin aceleración relativa (como el de un proyectil):

quedando así:
Pero:
Entonces:
Volviendo al principio:
La aceleración de Coriolis es el primer sumando:
La aceleración centrípeta es el segundo:

El ejemplo más notorio de manifestación del efecto Coriolis se da cuando masas de aire o de agua se desplazan siguiendo meridianos terrestres, y su trayectoria y velocidad se ven modificadas por él. En efecto, los vientos o corrientes oceánicas que se desplazan siguiendo un meridiano se desvían acelerando en la dirección de giro (este) si van hacia los polos o al contrario (oeste) si van hacia el ecuador. Se puede añadir, que por consecuencia, en el Ecuador, no hay efecto de Coriolis. La manifestación de estas desviaciones produce, de manera análoga al giro de la bolita mostrado al principio, que las borrascas tiendan a girar en el hemisferio sur en el sentido de las agujas del reloj y, en el hemisferio norte, en sentido contrario.

El efecto de la fuerza de Coriolis deberá considerarse siempre que se estudie el movimiento de fluidos y también el de cualquier objeto móvil sobre esferas o superficies planas en rotación. Esto incluye a los planetas gaseosos del sistema solar, el Sol y todas las estrellas y, en el planeta Tierra, el movimiento de las aguas de los ríos, los lagos, los océanos y, por supuesto, de la atmósfera. El efecto de Coriolis predice que siempre que se observen los movimientos giratorios de esos cuerpos, los vórtices seguirán la norma descrita para las borrascas y anticiclones terrestres.

Además de su influencia sobre la atmósfera, es muy notoria la que tiene también sobre la circulación oceánica. En las cuencas que tienen la forma apropiada (como, por ejemplo, la cuenca del Atlántico norte y la del Atlántico sur), el efecto Coriolis desvía a las corrientes marinas hacia la derecha en el hemisferio norte y hacia la izquierda en el hemisferio sur, de la misma manera que sucede con la circulación general de los vientos.

Las excepciones o modificaciones de este patrón general de la circulación general de los océanos tienen que ver con la disposición de las costas y la compensación introducida por las corrientes cálidas que van, en los océanos, de las costas orientales de la zona intertropical hacia las occidentales de las zonas templadas de los continentes (corriente del Golfo y de Kuro Shivo, especialmente). Además, en los océanos, lo mismo que sucede en la atmósfera, se produce una especie de convergencia en las latitudes ecuatoriales por la fuerza centrífuga del movimiento de rotación: tanto el océano como la atmósfera tienen un abombamiento ecuatorial por la rotación terrestre, de varios kilómetros de altura en el caso de los océanos y aún mayor en el caso de la atmósfera debido a su menor densidad. A su vez, este "abombamiento" ocasiona una especie de obstáculo a la libre circulación y al libre intercambio de energía (oceánica y atmosférica) entre los dos hemisferios. La circulación en la zona ecuatorial es, por lo tanto, de este a oeste, tanto en lo que respecta a las corrientes ecuatoriales del norte y del sur como con respecto a los alisios del noreste en el hemisferio norte y del sureste en el hemisferio sur. Por último, lo que se ha denominado abombamiento ecuatorial de los océanos tiene varias consecuencias: entre ellas, la formación de lo que se ha denominado contracorrientes ecuatoriales también del norte y del sur, definidas e identificadas en muchos atlas y libros de geografía y de ciencias de la Tierra, y la desviación hacia las zonas subtropicales y templadas: de nuevo, hacia la derecha en el hemisferio norte y hacia la izquierda en el hemisferio sur.

Una de las raras ocasiones en la cual una persona puede sentir la fuerza de Coriolis es cuando trata de caminar siguiendo una trayectoria radial en un tiovivo (o carrusel). Cuando la persona se aleja del eje de rotación, sentirá una fuerza que la empuja en el sentido contrario a la rotación: es la fuerza de Coriolis. Cuando una persona se aleja o se acerca del eje de rotación a una velocidad de 1 m/s en un tiovivo que gira a 10 vueltas por minuto, la aceleración de Coriolis es:

Se trata, por consiguiente, de una aceleración lateral 4,6 veces más pequeña que la gravedad, pero que para una persona de 70 kg, eso corresponde a una fuerza lateral igual al peso de 15 kg. que es perfectamente percibida.

La Tierra gira mucho más lentamente que un carrusel. Su velocidad angular es de formula_36 radianes por día sideral (23 h, 56 m, 4,1 s) es decir formula_37. La aceleración de Coriolis debido a la rotación de la Tierra es mucho menor.

Cuando un cuerpo sigue una trayectoria norte-sur sobre la Tierra (siguiendo un meridiano), la componente radial de su velocidad (la velocidad a la cual el cuerpo se acerca o se aleja del eje de rotación terrestre) depende de la latitud del cuerpo. Es fácil ver que la componente radial es formula_38. Cuando el cuerpo está cerca del ecuador, su distancia respecto al eje de la Tierra no cambia. Si la trayectoria del cuerpo es este-oeste y sigue un paralelo, su distancia respecto al eje terrestre no varía, pero ya hemos visto que sentirá una aceleración de Coriolis dirigida hacia el eje de la Tierra que vale formula_39. La componente paralela a la superficie de la Tierra depende de la latitud y es: formula_40.

Vemos que en los dos casos, visto desde la Tierra, un cuerpo que se desplaza sobre la superficie de la Tierra siente una aceleración lateral de valor formula_41 dirigida hacia la derecha de la velocidad.

Un cuerpo que se desplaza con una velocidad de 1 m/s, sin interacción con el suelo, a una latitud de 45° encuentra una aceleración lateral de Coriolis igual a:

lo cual corresponde a una fuerza lateral aproximadamente 100 000 veces menor que su propio peso. Dicho de otra manera, la trayectoria se desvía hacia la derecha como si el terreno estuviese inclinado hacia la derecha 1 milímetro cada 100 metros.

Si se trata de un avión cuya velocidad es 900 km/h (250 m/s), la aceleración será 250 veces mayor. El efecto será darle al avión una trayectoria circular de 4850 km de diámetro (a una latitud de 45°):
Por supuesto, el piloto corregirá esta desviación, pero no parece posible que pueda distinguirla de los efectos del viento o de los errores de reglaje de la posición neutra de los alerones de dirección y de profundidad.

Tomemos el caso de un obús, situado a una latitud de 45° y que tira un proyectil a 110 km de distancia. El ángulo de tiro para esa distancia es de 45°. Si se desprecia el efecto de los rozamientos con el aire, la velocidad horizontal del proyectil es de 734 m/s, y el tiempo de vuelo es de 150 segundos. La aceleración de Coriolis será:

La distancia lateral de desvío provocada por la aceleración de Coriolis es:

Esa distancia corresponde a un error en el ángulo de tiro de 0,44°. Las opiniones divergen sobre la importancia de este error, comparado con la influencia de otras fuerzas y, sobre todo, con la fuerza provocada por el efecto Magnus sobre proyectiles que giran axialmente.

Para cañones de menor alcance, el error en el ángulo de tiro es aún menor. Por ejemplo, para un proyectil cuyo alcance es de 20 km y cuya velocidad media es la misma, el error del ángulo es 25 veces menor.

La versión simplificada del efecto Coriolis esta ligada a su componente horizontal causada por movimientos horizontales con respecto a la superficie terrestre.

Pero también hay componentes verticales del efecto Coriolis que son significativos. Los objetos que viajen hacia el este a gran velocidad se desviarán hacia arriba (parecerán más ligeros), mientras que los que lo hagan hacia el oeste se desviarán hacia abajo (parecerán más pesados). Esto se conoce como el efecto Eötvös. Este componente vertical del efecto Coriolis es mayor en el ecuador, y se reduce a cero en los polos.

Otro caso a tener en cuenta es el de objetos que viajan en dirección perpendicular al plano terrestre. Aquellos que se desplacen arriba a gran velocidad se desviarán hacia el oeste y los que lo hagan hacia abajo se desviarán hacia el este. El efecto de nuevo alcanza su máximo en el ecuador y es 0 en los polos (en el ecuador un movimiento vertical es perpendicular al eje de rotación y en los polos sin embargo es paralelo y por lo tanto el efecto causado por Coriolis en ese caso es 0). 

Imaginemos un tren que viaja por una vía sin rozamiento alrededor del ecuador de la Tierra a la velocidad necesaria para completar una vuelta al mundo en un día (465 m/s). Analizamos el efecto Coriolis en tres casos:
Para cada uno de estos casos calculamos el efecto Coriolis, primero desde el punto de vista de nuestro sistema de referencia en rotación en la Tierra para a continuación comprobar que el resultado es el mismo observando el tren en un sistema de referencia inercial. En la siguiente imagen podemos observar los tres casos en el sistema de referencia inercial vistos desde un punto fijo sobre la tierra en su eje de rotación: 

Esto explica por que los proyectiles a alta velocidad que se disparan hacia el este se desvían hacia arriba mientras que si son disparados hacia el oeste la desviación es hacia abajo. Esta componente vertical del efecto de Coriolis se denomina el Efecto Eötvös.

Podemos usar el ejemplo para explicar por que el efecto Eötvös comienza a reducirse en objetos que viajan hacia el oeste una vez que su velocidad tangencial supera la velocidad de rotación de la tierra (465 m/s en el ecuador). Si el tren que viaja hacia el oeste en el ejemplo incrementa su velocidad en esa dirección y lo observamos desde el sistema de referencia inercial en el espacio veremos que empieza a rotar alrededor de la tierra que gira debajo en dirección contraria. Para mantener esa trayectoria circular, parte de la fuerza de la gravedad que empuja al tren contra las vías actuaría como fuerza centrípeta. Una vez que el tren doblara su velocidad a 930 m/s la fuerza centrípeta sería igual a la experimentada cuando el tren se encuentra parado. Desde el punto de vista del sistema de referencia inercial en ambos casos el tren está rotando a la misma velocidad (465 m/s) solo que en direcciones opuestas. Por lo tanto la fuerza es la misma y por tanto el efecto Eötvös se cancelaría completamente a esa velocidad. Cualquier objeto que se mueva hacia el oeste a una velocidad superior a 930 m/s no experimentara una desviación hacia abajo, si no hacia arriba. El gráfico de la derecha ilustra la fuerza causada por el efecto Eötvös que experimentaría un objeto de 10 gramos en el tren del ejemplo en función de su velocidad. La forma parabólica del gráfico se explica porque la fórmula de la fuerza centrípeta es proporcional al cuadrado de la velocidad tangencial. En el sistema de referencia inercial la parte de abajo de la parábola estaría centrada en el origen. El desplazamiento del origen se explica porque estamos usando el sistema de referencia en rotación de la tierra. Observando el gráfico podemos comprobar que el efecto Eötvös no es simétrico, y que la fuerza hacia abajo experimentada por un objeto viajando hacia el oeste a gran velocidad es menor que la fuerza hacia arriba experimentada por el mismo objeto viajando en dirección al este a la misma velocidad.

Una aplicación práctica de la fuerza de Coriolis es el caudalímetro másico, un instrumento que mide el caudal másico de un fluido que circula a través de una tubería. Este instrumento fue comercializado en 1977 por Micro Motion Inc.

Los caudalímetros normales miden el caudal volumétrico, el cual es proporcional al caudal másico sólo cuando la densidad del fluido es constante. Si el fluido tiene una variación de densidad o contiene burbujas, entonces el caudal volumétrico, multiplicado por la densidad, no será exactamente igual al caudal másico. El caudalímetro másico de Coriolis funciona aplicando una fuerza de vibración a un tubo curvado a través del cual pasa el fluido. El efecto Coriolis crea una fuerza en el tubo perpendicular a ambas direcciones: la de vibración y la dirección de la corriente. Esta fuerza se mide para obtener el caudal másico. Los caudalímetros de Coriolis pueden usarse además con fluidos no newtonianos, en los cuales los caudalímetros normales tienden a dar resultados erróneos. El mismo instrumento puede usarse para medir la densidad del fluido. Este instrumento tiene una novedad adicional, que consiste en que el fluido está en un tubo liso, sin partes móviles, que no necesita limpieza ni mantenimiento y presenta una caída de presión muy baja.





</doc>
<doc id="11499" url="https://es.wikipedia.org/wiki?curid=11499" title="Bioma">
Bioma

Un bioma (del griego «bios», vida), también llamado paisaje bioclimático o áreas bióticas (y que no debe confundirse con una ecozona o una ecorregión), es una determinada parte del planeta que comparte el clima, flora y fauna. Un bioma es el conjunto de ecosistemas característicos de una zona biogeográfica que está definido a partir de su vegetación y de las especies animales que predominan. Es la expresión de las condiciones ecológicas del lugar en el plano regional o continental: el clima y el suelo determinarán las condiciones ecológicas a las que responderán las comunidades de plantas y animales del bioma en cuestión.

En función de la latitud, la temperatura, las precipitaciones y la altitud, en definitiva, y de las características básicas del clima, se puede dividir la tierra en zonas de características semejantes; en cada una de esas zonas se desarrolla una vegetación (fitocenosis) y una fauna (zoocenosis) que cuando están relacionadas, definen un bioma, que comprende las nociones de comunidad y la interacción entre suelo, plantas y animales. 

Hay diferentes sistemas para la clasificación de biomas, que en general suelen dividir la tierra en dos grandes grupos —biomas terrestres y biomas acuáticos-, con un número no demasiado grande de biomas. A escala planetaria, la selva tropical densa, la sabana, la estepa, los bosques templados y la tundra, son los grandes biomas que caracterizan la biósfera y que tienen un reparto zonal, es decir, que no superan ciertos valores latitudinales. A escala regional o continental, los biomas son difíciles de definir, en parte porque existen diferentes patrones y también porque sus fronteras suelen ser difusas (véase el concepto de ecotono).

Los biomas a menudo son conocidos por sus nombres locales. Por ejemplo, un bioma de herbazales se conoce como pradera en Norteamérica, sabana en África, estepa en Asia, pampa en Sudamérica y veld en Sudáfrica.

Los biomas terrestres son descritos por la ciencia de la biogeografía. Por extensión, se habla de microbioma para designar la esfera de la vida microbiota.

El concepto de bioma no debe confundirse con otros conceptos similares como el de ecozona —grandes extensiones de la superficie de la tierra donde las plantas y los animales se desarrollan en relativo aislamiento durante largos períodos de tiempo, separados unos de otros por las características geológicas, tales como océanos, grandes desiertos, altas montañas o cordilleras, que forman barreras a la migración de plantas y animales—, hábitat —área que es habitada por una especie particular de animales o plantas— o ecosistema —complejo dinámico compuesto por plantas, animales y microorganismos, y la naturaleza muerta que los rodea actuando en interacción en tanto que unidad funcional—. Las distintas ecorregiones del mundo se agrupan tanto en biomas como en ecozonas.

Los biomas son áreas definidas climática y geográficamente, con similares condiciones ecológicas, tales como las comunidades de plantas y animales, (que a menudo se nombran como ecosistemas). Los biomas están definidos por factores tales como la estructura de las plantas (árboles, arbustos y hierbas), los tipos de hojas (hoja ancha y hoja acicular o agujas), el espaciado de las plantas (cerrado, abierto) y el clima. A diferencia de las ecozonas, los biomas no están definidos por semejanzas genéticas, taxonómicas o históricas. Los biomas con frecuencia se identifican con patrones particulares de sucesión ecológica y vegetación clímax (casi-estado de equilibrio del ecosistema local). Un ecosistema tiene muchos biotopos y un bioma es un tipo mayor de hábitat. Un tipo principal de hábitats, sin embargo, es un compromiso ya que posee una falta de homogeneidad intrínseca. 

La biodiversidad característica de cada bioma, especialmente la diversidad de la flora y fauna, está en función de factores abióticos que determinan la productividad de la biomasa de la vegetación dominante. En los biomas terrestres, la diversidad de especies tiende a correlacionarse positivamente con la producción primaria neta, con la disponibilidad de humedad y con la temperatura. 

El bioma está caracterizado fundamentalmente por el clima, en particular, por la temperatura y las precipitaciones. Fue de hecho la distribución zonal de los climas lo que llevó a poner de relieve la zonificación de las tierras a finales del siglo XIX, y después, los biomas. Hay algunos otros parámetros físicos que pueden estar involucrados, como una altitud particular o la existencia de un suelo periódicamente sumergido, por ejemplo. El clima es el factor más importante que determina la distribución de los biomas terrestres y depende de: 


Los sistemas de clasificación de los biomas más utilizados corresponden a la latitud (o la zonificación de temperaturas) y la humedad. De hecho, el agua y la temperatura —cuya distribución a escala global está en gran medida condicionada por la rotación de la Tierra sobre su eje— son los dos factores clave para el establecimiento de un clima que presentan, a escala global y continental, variaciones según la latitud. Esta distribución está, por tanto, en correlación con bandas de vegetación homogéneas. Estas bandas latitudinales fueron observadas por primera vez por Vasili Dokucháyev, padre de la edafología rusa, y se llamaron zonas (del griego «zonê» que significa cintura), lo que dio a luz al concepto de zonificación, fundamental en la geografía del medio natural. Así por ejemplo, la biodiversidad es creciente, en general, desde los polos al ecuador, ya sea desde un punto de vista animal o vegetal, como en el caso de la selva ecuatorial densa que es el bioma más rico y diverso.

El término bioma a menudo suele confundirse con otros semejantes, como:

Un bioma, en general, agrupa más de un ecosistema y se puede clasificar dentro de niveles de organización biológica: 

El WWF organiza los grupos biológicos del siguiente modo:

Las características primarias de esta región son temperaturas bajas (entre –15 °C y 5 °C) y gran brevedad de la estación favorable. La precipitación pluvial es más bien escasa (unos 300 mm al año), pero el agua no suele ser factor limitante, ya que el ritmo de evaporación es también muy bajo. 

El terreno está casi siempre congelado, excepto en los 10 o 20 cm superiores que experimentan deshielo durante la brevísima temporada calurosa. El clima tan frío de este bioma da lugar al permafrost, que es una capa de hielo congelada que permite únicamente el crecimiento de plantas en los días de verano ya que se descongela su superficie.

Existe una tundra ártica, también llamada "desierto polar", que se extiende por encima de los 60º de latitud N y una "tundra antártica", por encima de los 50ºS, que comprende la Antártida, las islas subantárticas y parte de la Patagonia.

Se da en pocas regiones del mundo: El Sur de Europa, el Norte de África, el Sur de Estados Unidos y parte de Sudamérica (Centro de Chile y Argentina). Cuando las temperaturas son más templadas y la humedad más abundante y repartida a lo largo del año, el bosque de coníferas es sustituido por el bosque caducifolio. En el Hemisferio Norte este bioma está dominado por hayas (americana y mexicana), robles, avellanos, olmos, castaños y numerosos arbustos que generan un suelo profundo y fértil. En las zonas templadas, si la pluviosidad es baja y la estación seca muy marcada, se instala otro tipo de bosque, de hoja perenne y resistente a la sequía estival. Es el bosque mediterráneo, con vegetación xerófila, dominado en Europa por la encina, el alcornoque o el roble quejigo.

Clima de bosque caducifolio: Encontramos el bosque caducifolio en torno a los 40º 55º de latitud . El clima típico tiene un régimen térmico moderado, precipitaciones abundantes, y bien distribuidas a lo largo del año y 4 estaciones bien definidas. En el predominan los suelos pardos poco o nada lixiviados y con humus mull o moder (degradación del bosque a la pradera alpina). En las pendientes aparecen suelos ranker o rendzina, más o menos ácidos, causados por la erosión sobre roca madre carbonatada.

El bioma de la pradera se encuentra en parajes con lluvia de 300 a 1500 mm por año, cifra insuficiente para el sustento de un bosque, y superior a la normal en un desierto verdadero. Algunas praderas se han desertificado por la acción del hombre. Se encuentra terreno de prado en el interior de los continentes y son bien conocidas las praderas del occidente de Estados Unidos y las de Argentina, Uruguay y parte de la región sur del Brasil, Australia, Rusia meridional y Siberia. El suelo de las praderas es muy rico en capas por virtud del rápido crecimiento y descomposición de los vegetales, y muy apropiado para el crecimiento de plantas alimenticias como trigo y maíz. Otras de sus características pueden ser:




El chaparral es también conocido como bosque mediterráneo. En las regiones del mundo de clima dócil, con lluvias relativamente abundantes en invierno pero con veranos muy secos, la comunidad culminante incluye árboles y arbustos de hojas gruesas y duras. Este tipo de vegetación se llama ""xerófila"". Durante los veranos secos y calurosos es constante el peligro de fuego que puede invadir rápidamente los lomeríos del chaparral.

Las comunidades de chaparral son muy extensas en California y costa noroccidental de México, a lo largo del Mediterráneo, en Chile y a lo largo de la costa sur de Australia.La diversidad del chaparral, un medio ambiente bastante uniforme, soporta relativamente pocas especies, pero muchas de sus plantas producen bayas comestibles y dan vida a vasta poblaciones de insectos y lo que el chaparral pierde en diversidad lo gana en número de individuos. Algunos vertebrados residentes característicos son los pequeños, ratas del bosque, ardillas listadas, lagartos y otros. Un ave característica del chaparral es el chochín herrerillo (Chamaea fasciata), una especie callada cuya área coincide casi exactamente con los límites del chaparral.

En el Mediterráneo, aunque la diversidad animal residente no es grande, la de aves migratorias es muy grande ya que esta región queda a mitad del camino entre los trópicos y las zonas más templadas. Durante el verano, la población de aves es menor, encontrándose solamente algunas aves tropicales, adaptadas al hábitat arbustivo y a condiciones de aridez. Llegan al Mediterráneo en primavera para nidificar, abandonándolo antes del comienzo del invierno. Entre los visitantes invernales, predominan las paseriformes (tales como las currucas y zorzales) y los patos.

El desierto se desarrolla en regiones con menos de 225 mm de lluvia anual. Lo característico de estas zonas es: 

Son poco productivos (menos de 500 g de carbono por año) y su productividad depende proporcionalmente de la lluvia que cae.
Algunos desiertos son cálidos, como el del Sahara, mientras que otros son fríos como el de Gobi. En algunos la lluvia es prácticamente inexistente, como en el de Atacama, en la cordillera de los Andes. Atacama está rodeado de altas montañas que bloquean la entrada de humedad desde el mar y favorecen la aparición de vientos catabáticos, secos y descendentes; este fenómeno se conoce como efecto Foehn. Otro mecanismo climático que forma desiertos en zonas cercanas a las costas es el ascenso de corrientes marinas frías cerca de los bordes continentales occidentales de África y América del Sur. El agua fría baja la temperatura del aire y son lugares en donde el aire desciende y no sopla hacia tierra. En el mar serán frecuentes las nieblas, pero en la tierra cercana no lloverá.

La vegetación se encuentra muy espaciada y las plantas suelen tener mecanismos repelentes para asegurar que en su cercanía no se sitúan otros ejemplares.

Hay cuatro formas principales de vida vegetal adaptadas al desierto: 

1. Plantas que sincronizan sus ciclos de vida, con los periodos de lluvia y crecen solo cuando hay humedad. Cuando llueve con intensidad suficiente, sus semillas germinan y con gran rapidez crecen las plantas y forman vistosas flores. Los insectos son atraídos por las flores y las polinizan al viajar de unas a otras. Muchos de estos insectos poseen también unos ciclos vitales muy cortos, adaptados a los de las plantas de las que se alimentan.

2. Matorrales de largas raíces que penetran en el suelo hasta llegar a la humedad. Se desarrollan especialmente en desiertos fríos. Sus hojas se suelen caer antes que la planta se marchite totalmente y de esta forma pasa a un estado de vida latente, hasta que vuelva a haber humedad en el subsuelo.

3. Plantas que acumulan agua en sus tejidos. Son de formas suculentas, como los cactus o las euforbias y tienen paredes gruesas, púas y espinas para protegerse de los fitófagos. Su rigidez es otra forma de protegerse contra la desecación producida por el viento.

4. Microflora, que permanece latente hasta que se producen buenas condiciones para su desarrollo.

La vida animal también ha desarrollado adaptaciones muy específicas para sobrevivir en un medio tan seco. Las excreciones de los animales que viven en el desierto contienen muy poca agua y muchos son capaces de obtener agua de los alimentos. Son de hábitos de vida nocturnos y durante el día permanecen en cuevas y madrigueras bajo tierra. 
El hombre ha desarrollado culturas que, con mucho ingenio, le han permitido vivir en los límites de los desiertos o en las mismas zonas desérticas.

Cuando el terreno desértico se riega, en los lugares en los que los suelos son adecuados, puede convertirse en uno de los sistemas agrícolas más productivos. Pero la puesta en cultivo de los terrenos áridos suele traer problemas de agotamiento de las fuentes de agua y salinización, como sucedió en las antiguas culturas mesopotámicas, si no se aplican sistemas para evitar esta dificultad. Para su explotación es necesario tener conocimientos del ecosistema y actuar en consecuencia.

Ocupa una franja de más de 1500 km de anchura en el hemisferio norte (América del norte, Europa y Asia) y también se encuentra en zonas montañosas.

Temperaturas invernales muy bajas (menos de -40 °C) y un verano relativamente corto. Escasez de agua (250 mm-500 mm anuales) y además permanece helada muchos meses.


La estepa es un bioma que comprende un territorio llano y extenso, de vegetación herbácea, propio de climas extremos y escasas precipitaciones. También se lo asocia a un desierto frío para establecer una diferencia con los desiertos tórridos. Estas regiones se encuentran lejos del mar, con clima árido continental, una gran amplitud térmica entre verano e invierno y precipitaciones que no llegan a los 500 mm anuales. Predominan las hierbas bajas y matorrales. El suelo contiene muchos minerales y poca materia orgánica; también hay zonas de la estepa con un alto contenido en óxido de hierro lo que le otorga una tonalidad rojiza a la tierra.

Las selvas tropicales ocupan extensas superficies cercanas al centro del Ecuador, Sudamérica, África, Asia y Oceanía, y prosperan en climas muy húmedos y calurosos, estando provistas no solo de lluvias abundantes, sino también de ríos caudalosos que experimentan crecidas violentas en otoño. Una selva de lluvia no es una "jungla". La jungla es una vegetación arbustiva muy densa que crece a lo largo de las riberas de los ríos. Puede aparecer en tierra cuando la selva lluviosa ha sido talada por los humanos o por un evento natural como una inundación o un incendio. La mayor parte de las junglas se transforman en selvas lluviosas. Por lo tanto, la jungla es una selva húmeda.

Las sabanas son praderas tropicales con una pequeña cantidad de árboles o arbustos dispersos. Se desenvuelven en regiones de alta temperatura, que tienen marcada diferencia entre las estaciones seca y húmeda. En la estación húmeda el crecimiento de las plantas es rápido, pero éstas se secan y bajan en calidad durante la estación seca. Las sabanas tropicales cubren áreas extensas en América del Sur, África, India, Sudeste Asiático y Australia Septentrional. 
El crecimiento animal y vegetal en la sabana tropical, depende de las distintas alteraciones periódicas. Los grandes animales emigran en busca de agua, y sus ciclos reproductivos corresponden a la disponibilidad de crecimiento de nuevas plantas. Muchos animales se reúnen en grandes manadas. Es necesario una gran área de producción fotosintética para alimentar a estos grandes animales. El fuego regular es importante para este ecosistema, de él depende el mantenimiento de las praderas en lugares donde las manadas no son tan numerosas.

Los biomas acuáticos pueden ser marinos (agua salada) o dulceacuícolas. Los biomas marinos son básicamente el oceánico o pelágico y el litoral o nerítico, caracterizados por la diferente profundidad que alcanza el agua y por la distancia a la costa. La zona litoral se caracteriza por la luminosidad de sus aguas, escasa profundidad y abundancia de nutrientes. En ella se concentran algas, moluscos, equinodermos y arrecifes de coral. Las tortugas, focas y peces óseos son muy comunes en esta zona. La zona pelágica se caracteriza por tener una banda iluminada pero también grandes profundidades sin luz. En estas regiones los seres acuáticos se han adaptado a vivir sin ella y a estar sometidos a grandes presiones.

Los biomas dulceacuícolas son básicamente las aguas quietas (lénticas) de lagos y lagunas y las aguas corrientes (lóticas) de ríos y arroyos. De la superficie del planeta, el 70% de su superficie está ocupado por los océanos. Del restante 30%, que corresponde a tierras emergidas, un 11% de esa superficie se halla cubierto por hielo, lo que se puede clasificar como desierto helado, y el 10% lo ocupa la tundra.

Los manglares son biomas de árboles que toleran la sal y crecen en las costas, donde baja y sube el nivel del mar. Estos árboles generan tierras firmes de forma natural al acumular partículas de arena y hojas de mangle en el suelo y cuando baja la marea formando tierras pantanosas.

La necesidad de disponer de un sistema de clasificación de los biomas surgió después de la creación de los sistemas de clasificación de climas, que se basaban solamente en criterios meteorológicos como la pluviometría y la insolación. Las primeras clasificaciones bioclimáticas nacieron en la década de 1950 con la clasificación de Holdridge. Los sistemas de clasificación pioneros trataban de definir los biomas utilizando las mediciones climáticas. Después, en los años 1970 y 1980 se produjo un importante impulso para entender las relaciones entre estas parámetros y las propiedades energéticas de los ecosistemas, porque tales descubrimientos permitirían la predicción de las tasas de captura de energía y la transferencia entre los distintos componentes de los ecosistemas. 

Un estudio de ese tipo fue realizado por Sims et al. (1978) sobre las praderas de América del Norte. El estudio encontró una correlación positiva entre la evapotranspiración, en mm/año y la producción primaria neta por encima del suelo en g/m²/año. Otros resultados generales del estudio fueron que la precipitación y el uso del agua llevan a la producción primaria sobre el terreno; que la radiación solar y la temperatura llevan a una producción primaria subterránea (raíces); y que la temperatura y el agua llevan a hábitats de crecimiento estacional de temporada fría y caliente. Estos resultados ayudan a explicar las categorías utilizadas en el sistema de bioclasificación de Holdridge, que luego fueron simplificados en la de Whittaker.

Las clasificaciones ecológicas se fueron haciendo cada vez más precisas y detalladas y varios países quisieron tener su propio sistema de clasificación. El número de sistemas de clasificación y la amplia variedad de los factores determinantes utilizados debe tomarse como un indicador de que no todos los biomas encajan perfectamente en los sistemas de clasificación creados y que las clasificaciones realizadas no son equivalentes, ya que los criterios elegidos para la definición de las zonas cumplen diferentes objetivos según sean los Estados o las organizaciones que los eligen. 
Así los Estados Unidos han establecido clasificaciones como la Clasificación Estándar de la vegetación nacional de los Estados Unidos («United States National Vegetation Classification Standard») en el marco de la Comisión para la Cooperación Ambiental («Commission de coopération environnementale») que ayudará a definir los biomas. 

Los biomas definidos son enumerados de manera precisa, lo que permite definir una política de protección precisa. Los lugares importantes para cada bioma fueron listados en bases de datos del tipo de la base europea Corine Biotopo («Corine Biotope»), hoy reemplazada por la del European Union Nature Information System (EUNIS). Los biomas utilizados por la Unión Europea figuran en el Mapa Digital de la Región Ecológica Europea («Digital Map European Ecological Region», DMEER) o por la Clasificación medioambiental de Europa (Environmental classification of Europe, CNE). A veces, todo un bioma puede ser objeto de protección, especialmente por la acción individual de una nación, mediante la elaboración de un Plan de Acción sobre la Biodiversidad («Biodiversity Action Plan», BAP).

El Sistema de clasificación de Holdridge es un proyecto para la clasificación de las diferentes áreas terrestres según su comportamiento global bioclimático. Fue desarrollado por el botánico y climatólogo estadounidense Leslie Holdridge (1907-99) y fue publicado por vez primera en 1947 (con el título de Determination of World Plant Formations from Simple Climatic Data) y posteriormente actualizado en 1967 (Life Zone Ecology).
Utiliza el concepto de zona de vida y se basa en los siguientes factores: 

En este sistema las zonas biogeográficas se clasifican según los efectos biológicos de la temperatura y las precipitaciones en la vegetación, en el supuesto de que estos dos factores abióticos son los principales determinantes del tipo de vegetación que se encuentra en una zona. Holdridge utiliza 4 ejes (biotemperatura, precipitación, piso altitudinal y región latitudinal) para definir las llamadas 30 «provincias de humedad», que son claramente visibles en el diagrama de Holdridge. Ya que su clasificación ignora en gran medida el suelo y la exposición al sol, Holdridge reconoció que estos elementos, eran factores importantes, demasiado, en la determinación de los biomas.

Robert Harding Whittaker (1920-80), ecólogo y botánico estadounidense, apreció la existencia de los tipos de bioma como una representación de la gran diversidad del mundo viviente, y vio la necesidad de establecer una manera sencilla de clasificar esos tipos de biomas. Whittaker basó su sistema de clasificación en dos factores abióticos: la temperatura y la precipitación. Su esquema puede considerarse como una simplificación del de Holdridge, más fácilmente accesible, pero quizás echando en falta la mayor especificidad que proporciona el de Holdrige. 

Whittaker basa su representación de los biomas mundiales en las dos anteriores afirmaciones teóricas, así como en una toma de muestras empíricas cada vez mayor de los ecosistemas mundiales. Whittaker se encontraba en una posición única para hacer tal afirmación holística ya que previamente había compilado una revisión de la clasificación de biomas.

Los conceptos clave para la comprensión del esquema de Whittaker son los siguientes:


La distinción de Whittaker entre bioma y formación se puede simplificar: la formación se utiliza cuando se aplica sólo a las comunidades vegetales, mientras que el bioma se utiliza cuando se trata de plantas y animales. La convención de Whittaker de tipo de bioma o tipo de formación es simplemente un método más amplio para clasificar comunidades similares. Los tipos de bioma del mundo, mostrados en un mapa del mundo, se puede ver en el siguiente enlace: here

Whittaker, viendo la necesidad de disponer de una manera más sencilla de expresar la relación de la estructura de la comunidad con el medio ambiente, utiliza lo que él llamó «análisis de gradiente» («gradient analysis») de patrones de ecoclinas para relacionar las comunidades con el clima a una escala mundial. Whittaker considera cuatro grandes ecoclinas en el reino terrestre:


A lo largo de estos gradientes, Whittaker encontró varias tendencias que le permitieron establecer cualitativamente los tipos de bioma. 


Whittaker resume los efectos de los gradientes (3) y (4) disponiendo un gradiente de temperatura conjunto y combina éste con el gradiente de humedad (2), para expresar las conclusiones anteriores en lo que se conoce como el Esquema de Clasificación de Whittaker («Whittaker Classification Scheme»). El esquema representa gráficamente la precipitación media anual (eje x) versus la temperatura media anual (eje Y) para clasificar los tipos de biomas.

El sistema de clasificación de Heinrich Walter fue desarrollada por Heinrich Walter, un ecologista alemán. Se diferencia tanto de los regímenes de Holdridge y Whittaker porque tiene en cuenta la estacionalidad de la temperatura y las precipitaciones. El sistema, también basado en la precipitación y temperatura, encuentra 9 grandes biomas, cuyos rasgos más importantes de clima y tipos de vegetación se resume en el cuadro adjunto. Los límites de cada bioma se correlacionan con las condiciones de humedad y frío que son determinantes importantes de la forma de las plantas y, por tanto, de la vegetación que define la región. 

Robert G. Bailey casi desarrolló un sistema de clasificación biogeográfica para los Estados Unidos en un mapa publicado en 1976. Bailey posteriormente amplió el sistema para incluir el resto de América del Sur en 1981 y en el mundo en 1989. El sistema de Bailey se basa en el clima y está dividido en siete dominios (polar, templado húmedo, seco, húmedo y húmedo tropical), con otras divisiones basadas en otras características climáticas (subártica, cálido templado, caliente templado y subtropical; marinos y continental; tierras bajas y montaña).

Un equipo de biólogos convocado por el Fondo Mundial para la Naturaleza (WWF) ha desarrollado un sistema de clasificación ecológico en el que se identificaron los llamados «tipos principales de hábitat» («Major Habitat Types», semejantes a los biomas) después de analizar las 867 ecorregiones terrestres en que se dividió la Tierra. Cada una de esas ecorregiones terrestres tiene un número de identificación o EcoID, con un formato del tipo XXnnNN (en el que XX es la Ecozona, nn es el número del bioma y NN es el número individual de la ecorregión). Esta clasificación se utiliza para definir la lista Global 200 de las ecorregiones identificadas por el WWF como prioridades para la conservación. 

El WWF organiza los biomas en dos grandes grupos, los biomas terrestres y los marinos, y los terrestres, a su vez, en dos subgrupos, los biomas terrestres propiamente y los biomas de agua dulce. Aunque existen biomas marinos, responden mucho menos a los criterios de zonificación —debido a las grandes corrientes que atraviesan los océanos a todos los niveles de profundidad— y son más difíciles de definir en el espacio. En el sentido de bioma según ha sido definido, el estudio de los ambientes acuáticos recaería preferentemente en la oceanografía —estudio de los mares— o de la limnología —estudio de las aguas dulces—. 

El WWF ha identificado 14 tipos de hábitat principales terrestres, 12 de aguas dulces y 7 marinos. Todos ellos se recogen en la siguiente Tabla (el código de colores responde al utilizado en la Wikipedia en inglés, ya que no existe una norma que lo unifique y depende de las distintas publicaciones).

La forma de clasificar las ecorregiones del WWF responde al siguiente esquema:



</doc>
<doc id="11500" url="https://es.wikipedia.org/wiki?curid=11500" title="François Truffaut">
François Truffaut

François Truffaut (París, 6 de febrero de 1932 - 21 de octubre de 1984) fue un director, crítico y actor francés. Fue uno de los iniciadores del movimiento llamado "la Nouvelle vague", si bien luego evolucionó de un modo muy personal.

Reconocido en el registro civil como hijo por Roland Truffaut, un delineante (o arquitecto y decorador), François Truffaut nunca llegó a conocer a su verdadero padre. Su madre Jeanine de Montferrand, que era secretaria en el periódico "L'Illustration", será recordada en su cine conflictivamente. 

Sus padres se despreocuparon de él, y fue atendido por sus abuelos maternos hasta los diez años. La orfandad forma parte de sus personajes esenciales y también originó esa "novela familiar" que rodea varias de sus historias. De todos modos, una agencia privada de detectives, encargada por Truffaut, señaló en 1968, que las indagaciones sobre su origen conducían a Roland Levy, un dentista de origen judío, de Bayona (al que vio de lejos); ese hallazgo lo rechazó la familia materna, pero a Truffaut le pareció posible, y hoy viene recogida en las monografías más autorizadas, así en la muy extensa que fue escrita por dos autores clave de "Cahiers du Cinéma".

François Truffaut, cuya infancia fue más bien desgarrada y fantasiosa, estudió en la escuela de la rue Clauzel y en el liceo Rollin, aunque nunca fue un alumno ejemplar. A partir de 1939, el joven Truffaut, que era un lector apasionado de literatura, también se pasaba la vida en el cine, a veces durante las horas en las que debería estar en clase (destacó pronto a Renoir, Rossellini, Hitchcock, Vigo, Buñuel, Bresson, Welles, N. Ray, K. Vidor, Ophuls, Sternberg, Stroheim).

Desde 1946, una vez que dejó sus estudios, sobrevivió con pequeños trabajos, como mozo de almacén, y fundó un cine-club en 1947, pero algunos problemas económicos (el alquiler de películas le condujo al impago por fracaso) hacen que sea enviado por su padre adoptivo a un correccional en Villejuif, del que fue sacado por André Bazin, que conoció en ese trabajo de divulgación cinematográfica.

Gracias de nuevo al crítico de cine André Bazin, su referencia vital, François Truffaut empieza a trabajar en "Travail et Culture". Escribe sus primeros artículos desde 1950. Tras alistarse en el ejército, se le envía a Alemania, pero deserta y pasa por la prisión militar; es liberado por Bazin, alegando inestabilidad de carácter. 

A continuación publica críticas en los "Cahiers du cinéma" en 1953, con sus colegas innovadores, pero también ese trabajo, que llega hasta 1959, lo hace en "Le Parisienne", en "Arts, Radio, Cinéma" y "Le Bulletin de Paris".La persona de cine de su momento más influyente en él fue Jacques Rivette.

Dirige ya al año siguiente, 1954, su primer cortometraje: "Une visite".

En 1956, Truffaut fue ayudante de dirección de Roberto Rossellini. Se casó en 1957 con Madeleine Morgenstern, hija de un distribuidor de cine, siendo testigos André Bazin y Roberto Rossellini; tuvo dos hijas, Laura y Eva. Se separaron en 1965, aunque mantuvieron relación y hasta convivencia toda la vida, por amistad y por las hijas (ella se casó pero se separó enseguida). Madeleine le cuidó al final de sus días, y ha sido su albacea (aunque Truffaut tuvo otra hija, Josephine, con Fanny Ardant, en 1983, que fue la mujer del final). Ese mismo año dirigió otro cortometraje, "Les Mistons" ("Los golfillos").

En 1958, rueda "Los cuatrocientos golpes", que servirá de carta de presentación al mundo del movimiento de la Nouvelle vague, que encabeza junto a Claude Chabrol, Éric Rohmer, Jean-Luc Godard, Alain Resnais o Jacques Rivette. Tendrá un éxito espectacular (Cannes, Acapulco, Fémina de Bélgica, Crítica de Nueva York, el Meliès, el Laurel de David Selznick, Valladolid).

Colaboró con Godard (guion de "Al final de la escapada"), y en los inicios de Rivette. Aparece ya una característica de Truffaut, su preocupación por la infancia, tan conflictiva en su caso, y por los más desamparados; e irá desde su primer largo "Los cuatrocientos golpes" (documento que radiografía autobiográficamente la realidad francesa tras la 2.ª Guerra Mundial), pasando por la revisión de las teorías de Jean-Jacques Rousseau en "El pequeño salvaje", hasta la sensibilidad que demuestra en la visión que un adulto puede llegar a tener de los niños y su mundo acometida en "La piel dura".

En 1968, cuando el gobierno destituyó a Henry Langlois de la Cinemateca francesa, se creó un comité de defensa, presidido por Jean Renoir, del que él fue tesorero, con Doniol-Valcroce, y organizó protestas. Fue el momento de mayor intervención social de Truffaut, en general replegado, pero firme defensor de libertades, como hizo con su admirado Jean-Paul Sartre.

Dirigirá Truffaut películas hasta su muerte a los 52 años, el 21 de octubre de 1984 en Neuilly-sur-Seine debido a un tumor cerebral. Está enterrado en el cementerio de Montmartre en París.

Hay que destacar que François Truffaut aparece como actor en varias de sus películas: "La habitación verde", "La noche americana", "El pequeño salvaje" y también en "Close Encounters of the Third Kind" de Steven Spielberg en 1977, en la que interpretaba al sabio francés "Claude Lacombe".

Es autor de un extenso libro de entrevistas a Alfred Hitchcock, "El cine según Hitchcock", que se ha convertido en una referencia en los estudios de cine, y que decidió su éxito global en lengua inglesa. 

Pues destaca el Truffaut escritor. Además de ser un cuidadoso guionista (sus guiones se han editado), escribió muchas y buenas críticas así como el prólogo a la obra de André Bazin, muerto prematuramente como él mismo, o el prefacio al libro de su gran director de fotografía, Néstor Almendros, con el que hizo nueve películas.

Truffaut es el director de su generación que fue más aceptado en Estados Unidos. Woody Allen siempre se declaró admirador suyo. Estuvo varias temporadas en California, para aprender inglés o para descansar y ver a amigos; periódicamente viajó allí como su otro lugar, como un territorio para replegarse.

Entre las muchas películas de Truffaut, cabe destacar la serie en la que aparece el personaje de Antoine Doinel, interpretado por el actor Jean-Pierre Léaud, quien inicia con 14 años su carrera de actor en "Los cuatrocientos golpes": será el actor-fetiche y "alter ego" del propio Truffaut, con el que le confundieron alguna vez, según aparece en "Les aventures de Antoine Doinel", libro prologado por Truffaut que recoge sus guiones de toda esa secuencia de filmes. Esta serie seguirá hasta "El amor en fuga", y pasando por un episodio de "El amor a los 20 años", "Besos robados" y "Domicilio conyugal" junto a Claude Jade en el papel de Christine, amiga y mujer de Doinel. Una hija de Truffaut, Eva Truffaut, seguía en 2004 buscando las últimas escenas de su padre y ha producido un serial radiofónico "El diario de Alphonse", en donde aparecen Christine Doinel (Claude Jade) y su hijo Alphonse (Stanislas Merhar). 

Lector apasionado, Truffaut llevará al cine muchas novelas: a) policiales estadounidenses ("La novia vestida de negro" y "La sirena del Mississippi" de William Irish, "Vivamente el domingo" (o bien, más cercano al francés, "Ojalá el domingo llegue pronto", de Charles Williams, "Disparen al pianista" de David Goodis y "Una chica tan decente como yo" de Henry Farrell); b) satírico-costumbristas, destacadamente de Henri-Pierre Roché "Jules y Jim" y "Las dos inglesas y el continente"; c) de ciencia-ficción "Fahrenheit 451" de Ray Bradbury; d) un relato de fantasmas de Henry James, en "La habitación verde", que es un film que revela lo más profundo de sus inquietudes: la amistad, la pasión, la muerte.

El resto de las películas de Truffaut surgen de guiones originales, a menudo en colaboración con su gran colaboradora, Suzanne Schiffman, o Jean Gruault. Son películas de temas muy diversos, que van desde "Diario íntimo de Adèle H.", basada en la vida de la hija de Víctor Hugo, con Isabelle Adjani, o "La noche americana", un auténtico homenaje al cine, que fue premiado en la ceremonia de los Óscar de Hollywood con el Óscar a la mejor película de habla no inglesa en 1973), y también "El último metro", película que se desarrolla durante la ocupación alemana de Francia y con la que ganó diez Premios César concedidos por la Academia del Cine Francés. 

Pero no hay que olvidar que el propio director decía que "no hay buenas historias, sólo hay buenas películas".

Los inicios del movimiento cinematográfico y del propio realizador son una crítica al academicismo y a los convencionalismos del cine francés hasta mediados de los años 50, a los que acusaban de ser caducos reflejos del arte de narrar visualmente una historia, un sentimiento, etc. Ellos creían que el cine tenía que renovarse enfocando cada historia, personaje o situación desde una perspectiva más cercana, humana y, dentro de lo posible, real. Concretamente, Truffaut señaló que sólo unos pocos directores franceses trabajaban de un modo más personal, como Jacques Tati, Robert Bresson, Max Ophuls, Jacques Becker y Jean Renoir.

Por ello, muchos de estos jóvenes teóricos cinematográficos, reconvertidos en directores, se adhieren al género documental en sus primeras realizaciones, tomando incluso elementos del entonces en declive "neorrealismo italiano", del realismo francés de los años 30 de Jean Vigo, Renoir o Carné, además del cine experimental y de vanguardia de los años 20.

Tras debutar en el largometraje, estos directores rápidamente entendieron que el nuevo movimiento (al igual que ocurrirá con el "free cinema" británico o el "nuevo cine" alemán), tenía unas claras limitaciones en cuanto a estructuras narrativo-visuales, y que al intentar salir de la independencia artística e integrar sus motivos conceptuales en un cine más comercial —y con mejores medios a raíz del éxito comercial de sus primeras cintas—, el estilo se diluía en parte desde su propia base y era percibido por crítica y público como un cine igual de clásico que el de la etapa anterior, si bien suponía un clasicismo renovado y una reflexión sobre un presente muy distinto ya de los años de posguerra. 

El propio Truffaut comienza siendo renovador y rupturista, pero con su estilo más moderado (desde "Jules y Jim" hasta "Domicilio conyugal") que otros, para ser además un autor lúcido y brillante y con un clasicismo formal tan descollante como insospechado, desde "Las dos inglesas y el amor" hasta su último film. 

De ahí las muy polémicas páginas sobre él escritas por Godard, su amigo-enemigo, que le alabó cariñosamente en su estreno y que decía en 1965 que era el "cineasta cada vez más y más serio". En 1973, Godard atacó absurda y violentamente a Truffaut (éste sólo escribiría "historias"), y la respuesta implacable de Truffaut, que denunciaba a Godard por su frialdad y cobardía, su ideologismo coyuntural y elitista, su impostura vanidosa, les llevó a la ruptura.Truffaut le había ayudado en el primer guion y también como productor. Hicieron una carrera en paralelo en vida de Truffaut, con dos ángulos de visión casi opuestos; incluso su roce indica admiración, pese a tantas diferencias radicales.












</doc>
<doc id="11501" url="https://es.wikipedia.org/wiki?curid=11501" title="Bioestadística">
Bioestadística

La bioestadística es la rama de la estadística aplicada a las ciencias de la vida, como la biología o la medicina, entre otras.

El primer médico que utilizó métodos matemáticos para cuantificar variables de pacientes y sus enfermedades fue el francés Pierre Charles-Alexandre Louis (1787-1872). La primera aplicación del Método numérico (que es como tituló a su obra y llamó a su método) en su clásico estudio de la tuberculosis, que influyó en toda una generación de estudiantes. Sus discípulos, a su vez, reforzaron la nueva ciencia de la epidemiología con en el método estadístico. En las recomendaciones de Louis para evaluar diferentes métodos de tratamiento están las bases de los ensayos clínicos que se hicieron un siglo después. En Francia Louis René Villermé (1782-1863) y en Inglaterra William Farr (1807-1883) —que había estudiado estadística médica con Louis— hicieron los primeros mapas epidemiológicos usando métodos cuantitativos y análisis epidemiológicos. Francis Galton (1822-1911), basado en el darwinismo social, fundó la biometría estadística.

Pierre Simon Laplace (1749-1827), astrónomo y matemático francés, publicó en 1812 un tratado sobre la teoría analítica de las probabilidades, Théorie analytique des probabilités, sugiriendo que tal análisis podría ser una herramienta valiosa para resolver problemas médicos.

Los primeros intentos de hacer coincidir las matemáticas de la teoría estadística con los conceptos emergentes de la infección
bacteriana tuvieron lugar a comienzos del siglo XX. Tres diferentes problemas cuantitativos fueron estudiados por otros tantos autores. William Heaton Hamer (1862-1936) propuso un modelo temporal discreto en un intento de explicar la ocurrencia regular
de las epidemias de sarampión; John Brownlee (1868-1927), primer director del British Research Council, luchó durante veinte
años con problemas de cuantificación de la infectividad epidemiológica, y Ronald Ross (1857-1932) exploró la aplicación matemática
de la teoría de las probabilidades con la finalidad de determinar la relación entre el número de mosquitos y la incidencia de malaria en situaciones endémicas y epidémicas. Pero el cambio más radical en la dirección de la epidemiología se debe a Austin
Bradford Hill (1897-1991) con el ensayo clínico aleatorizado y, en colaboración con Richard Doll (n. 1912), el épico trabajo que correlacionó el tabaco y el cáncer de pulmón.

Los primeros trabajos bioestadísticos en enfermería los realizó, a mediados del siglo XIX la enfermera inglesa Florence Nightingale. Durante la guerra de Crimea, Florence Nightingale observó que eran mucho más numerosas las bajas producidas en el hospital que en el frente. Por lo tanto, recopiló información y dedujo que la causa de la elevada tasa de mortalidad se debía a la precariedad higiénica existente. Así, gracias a sus análisis estadísticos, se comenzó a tomar conciencia de la importancia y la necesidad de unas buenas condiciones higiénicas en los hospitales.

El razonamiento y la modelización bioestadísticas fueron fundamentales en la fundación de la Síntesis Moderna de la evolución. A principios de los años noventa, después del redescubrimiento de la obra de Mendel, los problemas conceptuales ligados a la comprensión de la relación entre la genética y el darwinismo condujeron a un acalorado debate entre "biométricos" (Weldon, Pearson) y "mendelianos" (Davenport, Bateson). En los años 30, tres grandes estadísticos, Ronald Fisher, quién desarrolló varios métodos básicos de la estadística en su libro "The Genetical Theory of Natural Selection, " Sewall G. Wright y J. B. S. Haldane lograron resolver el conflicto e introdujeron la bioestadística y, en particular, la genética de poblaciones, como una de las ramas esenciales de la Síntesis evolutiva moderna.

La aplicación resulta hoy en día necesaria, en los campos:

La colaboración de la bioestadística ha sido clave en el desarrollo de nuevos fármacos, en el entendimiento de enfermedades crónicas como el cáncer y el sida, y estos son solo algunos de los miles de ejemplos posibles.

La estrecha relación de la Estadística con el método científico hace de la Bioestadística una disciplina imprescindible en la mayoría de los proyectos en el área tecnológica.

El pensamiento estadístico no sólo resuelve y entiende la compleja metodología para dar respuesta a hipótesis, sino que es capaz de organizar el “sistema” que involucra la investigación desde el diseño general, diseño de muestreo, control de calidad de la información, análisis y presentación de resultados.

Siendo como es, parte fundamental del desarrollo del conocimiento en todas las áreas de la salud, la estadística no está exenta de dificultades. Lo cierto es que, como han puesto de manifiesto numerosos autores, la mayor parte de los trabajos científicos que se publican en la actualidad están aquejados de defectos en su metodología, graves en numerosas ocasiones, a veces debidos a la falta de formación de los autores y los revisores, pero también, en otras ocasiones, debidos a la intencionalidad de transmitir algún mensaje concreto a través de los resultados del trabajo.




</doc>
<doc id="11503" url="https://es.wikipedia.org/wiki?curid=11503" title="Atmósfera terrestre">
Atmósfera terrestre

La atmósfera terrestre es la parte gaseosa de la Tierra, siendo por esto la capa más externa y menos densa del planeta. Está constituida por varios gases que varían en cantidad según la presión a diversas alturas. Esta mezcla de gases que forma la atmósfera recibe genéricamente el nombre de aire. El 75 % de masa atmosférica se encuentra en los primeros 11 km de altura, desde la superficie del mar. Los principales gases que la componen son: el oxígeno (21 %) y el nitrógeno (78 %), seguidos del argón, el dióxido de carbono y el vapor de agua.

La atmósfera y la hidrosfera constituyen el sistema de capas fluidas superficiales del planeta, cuyos movimientos dinámicos están estrechamente relacionados. Las corrientes de aire reducen drásticamente las diferencias de temperatura entre el día y la noche, distribuyendo el calor por toda la superficie del planeta. Este sistema cerrado evita que las noches sean gélidas o que los días sean extremadamente calientes.

La atmósfera protege la vida sobre la Tierra, absorbiendo gran parte de la radiación solar ultravioleta en la capa de ozono. Además, actúa como escudo protector contra los meteoritos, los cuales se desintegran en polvo a causa de la fricción que sufren al hacer contacto con el aire.

Durante millones de años, la vida ha transformado, una y otra vez, la composición de la atmósfera. Por ejemplo; su considerable cantidad de oxígeno libre es posible gracias a las formas de vida —como son las plantas— que convierten el dióxido de carbono en oxígeno, el cual es respirable —"a su vez"— por las demás formas de vida, tales como los seres humanos y los animales en general.

En la atmósfera terrestre se pueden distinguir dos regiones con distinta composición, la homosfera y la heterosfera.

La homosfera ocupa los 100 km inferiores y tiene una composición constante y uniforme.

La heterosfera se extiende desde los 80 km hasta el límite superior de la atmósfera (unos 10 000 km); está estratificada, es decir, formada por diversas capas con composición diferente.

La variación con la altura de la presión atmosférica con el conocimiento que se tiene del magnetismo o de la densidad atmosférica es lo que se conoce como "Ley barométrica".La diferencia de presión entre dos capas separadas por un formula_1 es:

pues se supone la densidad constante. La "ley de la densidad" suponiendo el aire como un gas ideal

aplicada a la superficie de la Tierra resulta una densidad del aire formula_2.

En una atmósfera isoterma la presión varía con la altura siguiendo la ley:
donde M es la masa molecular, g la aceleración de la gravedad, h-h es la diferencia de alturas entre los niveles con presiones P y P y T es la temperatura absoluta media entre los dos niveles, y R la constante de los gases perfectos. El hecho de que la temperatura varíe sí limita la validez de la fórmula. Por el contrario, la variación de la aceleración de la gravedad es tan suave que no afecta.

La escala de altura es la altura a la que hay que elevarse en una atmósfera para que la presión atmosférica disminuya en un factor "e" = 2,718182. Es decir la disminución de presión es 1-1/"e" = 0,632 (= 63,2 %). Para calcularla basta con poner en la Ley barométrica formula_4 resulta:

Para la atmósfera de la Tierra la escala de alturas H es de 8,42 km. En función de la escala de alturas H la presión puede expresarse:
y análogamente para la densidad:

La temperatura de la atmósfera terrestre varía con la altitud. La relación entre la altitud y la temperatura es distinta dependiendo de la capa atmosférica considerada: troposfera, estratosfera, mesosfera y termosfera. A esto se le llama el gradiente térmico atmosférico.

Las divisiones entre una capa y otra se denominan respectivamente tropopausa, estratopausa, mesopausa y termopausa.

Sus principales características son:

Su nombre obedece a que está dispuesta en capas más o menos horizontales (o estratos).
Se extiende entre los 9 o 18 km hasta los 50 km de altitud. La estratosfera es la segunda capa de la atmósfera de la Tierra. A medida que se sube, la temperatura en la estratosfera aumenta. Este aumento de la temperatura se debe a que los rayos ultravioleta transforman al oxígeno en ozono, proceso que involucra calor: al ionizarse el aire, se convierte en un buen conductor de la electricidad y, por ende, del calor. Es por ello que a cierta altura existe una relativa abundancia de ozono (ozonosfera) lo que implica también que la temperatura se eleve a unos –3 °C o más. Sin embargo, se trata de una capa muy enrarecida, muy tenue.

Se denomina capa de ozono, u ozonosfera, a la zona de la estratosfera terrestre que contiene una concentración relativamente alta de ozono. Esta capa, que se extiende aproximadamente de los 15 km a los 40 km de altitud, reúne el 90 % del ozono presente en la atmósfera y absorbe del 97 % al 99 % de la radiación ultravioleta de alta frecuencia.

Es la tercera capa de la atmósfera de la Tierra. Se extiende entre los 50 y 80 km de altura, contiene solo el 0.1 % de la masa total del aire. Es la zona más fría de la atmósfera, pudiendo alcanzar los −80 °C. Es importante por la ionización y las reacciones químicas que ocurren en ella. La baja densidad del aire en la mesosfera determina la formación de turbulencias y ondas atmosféricas que actúan a escalas espaciales y temporales muy grandes.

En la termosfera o ionosfera (de 69/90 a los 600/800 km), la temperatura aumenta con la altitud, de ahí su nombre. La ionosfera es la cuarta capa de la atmósfera de la Tierra. Se encuentra encima de la mesosfera. A esta altura, el aire es muy tenue y la temperatura cambia con la mayor o menor radiación solar tanto durante el día como a lo largo del año. Si el sol está activo, las temperaturas en la termosfera pueden llegar a 1500 °C e incluso más altas.
La termosfera de la Tierra también incluye la región llamada ionosfera. En ella se encuentra el 0.1 % de los gases.

La última capa de la atmósfera de la Tierra es la exosfera (600/800 - 2000/). Esta es el área donde los átomos se escapan hacia el espacio.
Como su nombre indica, es la región atmosférica más distante de la superficie terrestre. Su límite superior se localiza a altitudes que alcanzan los 960 e incluso 1000 km., y está relativamente indefinida. Es la zona de tránsito entre la atmósfera terrestre y el espacio interplanetario.


Se llama dinámica de la atmósfera o dinámica atmosférica a una parte de la Termodinámica que estudia las leyes físicas y los flujos de energía involucrados en los procesos atmosféricos. Estos procesos presentan una gran complejidad por la enorme gama de interacciones posible tanto en el mismo seno de la atmósfera como con las otras partes (sólida y líquida) de nuestro planeta.

La termodinámica establece tres leyes, además de lo que se conoce como principio cero de la termodinámica. Estas tres leyes rigen en todo el mundo físico-natural y constituyen la base científica de los procesos que constituyen el campo de la dinámica de la atmósfera. Así pues, la dinámica atmosférica involucra a todos los movimientos que se presentan en el seno de la atmósfera terrestre y estudia también las causas de dichos movimientos, los efectos de los mismos y, en general todos los flujos de energía térmica, eléctrica, físico-química, y de otros tipos que ocurren en la capa de aire que rodea a la Tierra.

La atmósfera funciona como un escudo protector contra los impactos de enorme energía que pueden provocar los pequeños objetos espaciales al colisionar a altísima velocidad contra la superficie del planeta.

Sin atmósfera, la velocidad de colisión de estos objetos sería la suma de su propia velocidad inercial espacial (medida desde nuestro planeta) más la aceleración provocada por la gravitación terrestre.

La energía cinética de los meteoritos se transforma en calor por la fricción de los mismos en el aire y desde la superficie vemos un meteoro, meteorito o también estrella fugaz.

La fricción es la manifestación macroscópica de una transferencia de energía cinética, o su transformación en otro tipo de energía, por la que un cuerpo "pierde" movimiento cediéndoselo a otro ya sea transfiriéndole parte de su propio movimiento o transformándose en movimientos moleculares (calor, vibración sonora, etc.)

Un cuerpo en caída libre dentro de la atmósfera puede tener velocidad decreciente, dado que la atracción gravitacional produce un movimiento uniformemente acelerado solamente en el vacío.

Si un cuerpo comienza a caer atravesando la atmósfera, se va acelerando hasta que su peso es igual a la fuerza de fricción que se produce por el desplazamiento dentro del aire. En ese momento deja de acelerar, y su velocidad comienza a decrecer a medida que la atmósfera aumenta su densidad, provocando una fuerza de fricción mayor.

Puede desacelerar la velocidad de caída no solo por la densidad de la atmósfera sino también por la variación del área de sección atravesada, lo que aumenta la fricción. Los acróbatas aéreos de caída libre pueden variar su velocidad de caída acelerando o desacelerando: si se desplazan de cabeza aceleran hasta equilibrar su peso, y si abren los brazos y piernas desaceleran.

La atmósfera tiene una gran importancia en los ciclos biogeoquímicos. La composición actual de la atmósfera es debida a la actividad de la biosfera (fotosíntesis), controla el clima y el ambiente en el que vivimos y engloba dos de los tres elementos esenciales (nitrógeno y carbono); aparte del oxígeno.

La actividad del hombre está modificando su composición, como el aumento del dióxido de carbono o el metano, causando el efecto invernadero o el óxido de nitrógeno, causando la lluvia ácida.

Las radiaciones solares nocivas, como la ultravioleta, son absorbidas casi en un 90 % por la capa de ozono de la estratosfera. La actividad mutágena de dicha radiación es muy elevada, originado dímeros de timina que inducen la aparición de melanoma en la piel. Sin ese filtro, la vida fuera de la protección del agua no sería posible.

Gracias a la atmósfera, la Tierra no tiene grandes contrastes térmicos; debido al efecto invernadero natural, que está producido por todos los componentes gaseosos del aire, que absorben gran parte de la radiación infrarroja re-emitida por la superficie terrestre; este calor queda retenido en la atmósfera en vez de perderse en el espacio gracias a dos características físicas del aire: su compresibilidad, que comprime el aire en contacto con la superficie terrestre por el propio peso de la atmósfera lo que, a su vez, determina la mayor absorción de calor del aire sometido a mayor presión y la diatermancia, que significa que la atmósfera deja pasar a la radiación solar casi sin calentarse (la absorción directa de calor procedente de los rayos solares es muy escasa), mientras que absorbe gran cantidad del calor oscuro () reenviado por la superficie terrestre y, sobre todo, acuática de nuestro planeta. Este efecto invernadero tiene un papel clave en las suaves temperaturas medias del planeta. Así, teniendo en cuenta la constante solar (calorías que llegan a la superficie de la Tierra por centímetro cuadrado y por minuto), la temperatura media del planeta sería de -27 °C, incompatible con la vida tal y como la conocemos; en cambio, su valor real es de unos 15 °C debido precisamente al efecto invernadero.

La composición de la atmósfera terrestre no ha sido siempre la misma, sino que ha variado con a lo largo de la vida del planeta por diversas causas. Además, los elementos ligeros escapan continuamente de la gravedad terrestre; de hecho, en la actualidad se fugan unos tres kilogramos de hidrógeno y 50 gramos de helio cada segundo, cifras que en tiempos geológicos (millones de años) resultan decisivas, aunque compensan, al menos en gran parte, la materia recibida del sol en forma de energía. Esta compensación también tiende a equilibrarse en el tiempo, de acuerdo a la mayor o menor energía solar recibida, generando un ciclo complejo, diario, estacional y de ciclos más largos (de acuerdo con la mayor o menor actividad solar) y una respuesta equivalente de la atmósfera en el almacenamiento de dicha energía y su posterior liberación en el espacio. Por ejemplo, la formación del ozono (O) en la capa denominada precisamente, ozonosfera, absorbe la mayor parte de la radiación ultravioleta recibida del sol pero cede esa energía al volverse a transformar durante la noche en oxígeno (O).

Se pueden establecer diferentes etapas evolutivas de la atmósfera según su composición:

La atmósfera se deriva de diversas fuentes, estaba y está condicionada por factores como:

Antes de la vida, la atmósfera sufrió algunos cambios importantes:

Etapa con la aparición de las primeras bacterias anaeróbicas (que usaban H y HS) y fotosintéticas (Bacterias del azufre y cianobacterias):

Etapa con la aparición de organismos eucariotas con fotosíntesis más eficiente:




</doc>
<doc id="11504" url="https://es.wikipedia.org/wiki?curid=11504" title="Inglés">
Inglés

Inglés puede referirse a:



</doc>
<doc id="11505" url="https://es.wikipedia.org/wiki?curid=11505" title="Baisers volés">
Baisers volés

Baisers volés, ("Besos robados" (España), "La hora del amor" (Argentina)), es una película francesa de 1968, dirigida por François Truffaut. Protagonizada por Jean-Pierre Léaud y Claude Jade en los papeles principales. 

Es la continuación de la historia del personaje Antoine Doinel, que inició con la película "Los 400 golpes" y el cortometraje "Antoine y Colette" y que sería seguida por "Domicilio conyugal" y "El amor en fuga". En esta película "Antoine" inicia su relación amorosa con "Christine". El personaje "de Antoine siempre" fue interpretado por Jean-Pierre Léaud.

La historia comienza cuando Antoine Doinel, quien de pequeño había huido de su hogar como es descrito en "Los 400 golpes", es licenciado del servicio militar y se reencuentra con su amiga Christine ("Claude Jade"). Ahora en la vida civil, Antoine busca un trabajo para sobrevivir, empezando por el de vigilante nocturno, pero por infortunadas situaciones y por su ineptitud y mala suerte termina siendo despedido. Consigue entonces un trabajo como detective privado y de este modo termina infiltrado en una tienda de zapatos como vendedor, a pedido del dueño de la tienda, quien busca averiguar porqué las personas que lo rodean ( sus empleados y demás) lo detestan. Antoine termina seducido por la esposa del dueño de la tienda, con quien tiene una aventura. La relación de Antoine y Christine se deteriora y terminan separándose, él pierde además su trabajo como detective privado. Antoine ahora trabajando como reparador de electrodomésticos, es enviado a la casa de Christine quien intencionalmente ha descompuesto su televisor para poder ver a Antoine mientras sus padres están fuera de casa.

Finalmente Antoine y Christine terminan reconciliándose y comprometidos. Su relación como pareja se describe en los filmes posteriores.



</doc>
<doc id="11514" url="https://es.wikipedia.org/wiki?curid=11514" title="Claude Jade">
Claude Jade

Claude Marcelle Jorré (Dijon, 8 de octubre de 1948 - Boulogne-Billancourt, 1 de diciembre de 2006), conocida como Claude Jade, fue una actriz francesa.

Hija de profesores de inglés, pasó tres años en la Escuela de Arte Dramático. Se trasladó a París y comenzó a actuar en producciones de televisión y en teatro. Fue descubierta por François Truffaut, quien le dio el papel de Christine Darbon, novia de su álter ego Antoine Doinel en "Besos robados". Su debut en la pantalla causó gran sensación y dio a Claude Jade una proyección internacional. Repitió su papel como Christine en "Domicilio conyugal" y " El amor en fuga", también de Truffaut. La crítica estadounidense Pauline Kael considera, no sin razón, que Claude Jade «parece una Catherine Deneuve menos etérea, más práctica». Detectado el éxito de Besos robados, François Truffaut decidió seguir la saga de Antoine e Christine comprometiendo a los dos principales actores, Jean-Pierre Léaud y Claude Jade; además. La escena en "Domicilio conyugal" en que Claude Jade se viste a la japonesa es de una inteligencia que roza la perfección. Su irrupción en la gran pantalla de la mano de Truffaut le abrió la puerta de otros grandes directores, como el británico Alfred Hitchcock, con quien en 1969 trabajó en "Topaz", donde interpretó el personaje de Michèle Picard, hija de un agente secreto y esposa de un periodista.

Más tarde, Edouardo Molinaro le ofreció interpretar en "Mon oncle Benjamin" el papel de la esposa de Jacques Brel, que permitió a la actriz trabajar junto al popular cantante e incrementar así su popularidad.

"Le bateau sur l'herbe", de Gérard Brach, "Home sweet Home", de Benoît Lamy, son otras de su treintena de filmes, una serie que concluyó en 1998 con "Le Radeau de la méduse", de Iradj Azimi.

La televisión le permitió mantener contacto con la interpretación, con trabajos en series policiacas, y donde interpretó su papel más popular como Véronique d'Hergemont, heroína de "L'île aux trente cercueils" ("La isla de los treinta ataúdes") (1979), Suzan Frend en "El gran secreto" (1989) y desde 1998 hasta 2000 como Anna en la serie de la televisión "Cap des pins".
La última actuación de Jade fue en la obra de Rampal "Celimene et le Cardinal", que se exhibió en París y en algunos festivales en los últimos meses.

La actriz Claude Jade, que ya padecía cáncer, tenía un ojo plástico para sus actuaciones, dijo Rampal. Antes de morir, estuvo leyendo un guion para una película de televisión que esperaba filmar en los próximos meses, indicó. Falleció el 1 de diciembre de 2006 a los 58 años de edad por un cáncer en el ojo.





</doc>
<doc id="11515" url="https://es.wikipedia.org/wiki?curid=11515" title="Amor en rebeldía (película)">
Amor en rebeldía (película)

Amor en rebeldía (en francés "Les feux de la chandeleur") es una película francesa de Serge Korber estrenada en 1972.
Con su mujer Marie-Louise (Annie Girardot) y sus dos niños Juan-Paul y Laura, Alexandre Boursault (Jean Rochefort), notario de provincia, habría sido el más feliz de los hombres si su mujer no indicara abiertamente sus opiniones gauchistes y no participara en toda clase de manifestaciones. La vida común que no es ya posible, el 2 de febrero de 1962, día del Chandeleur, Alexandre se separa de su mujer... Pero se encuentra pronto reducida a la inacción, sin marido, sin oficio, sin niños. En diez años afecta varias veces el fondo del abismo. El 2 de febrero de 1972, publica que es la primavera y sale con un sombrero de paja rojo mientras que nieva a grandes copos. Alexandre Boursault le envía la palabra - la primera desde años - para aconsejarle otro peinado. Este encuentro actúa como un golpe de rayo. En este remolino Laura (Claude Jade) cae enamorado de Marc Champenois (Bernard Fresson), un amigo de su madre. Marie-Louise encuentra - inspirada por la felicidad de Laura - su oportunidad: convencida de que Alexandre está siempre enamorado ella, ya no vive más que en la esperanza de una reconciliación...

</doc>
<doc id="11517" url="https://es.wikipedia.org/wiki?curid=11517" title="Jean Rochefort">
Jean Rochefort

Jean Rochefort (París, 29 de abril de 1930-Ibídem, 9 de octubre de 2017) fue un actor francés.

Nacido en París de padres bretones, asistió al Instituto Pierre Corneille de Ruan. Con 19 años entró en el Centro de Arte Dramático de la calle Blanche y posteriormente se incorporó al Conservatorio Nacional. Trabajó con la Compañía Grenier Hussenot como actor de teatro desde 1953 y durante siete años.

Tras algunos papeles secundarios interpretó su primer papel importante en el drama "Amor en rebeldía" (1972) con Annie Girardot y Claude Jade. En esta película interpretó a un padre de 41 años de edad con una familia de niños adultos (la joven Claude Jade tenía ya 23). Tenía un bigote, su marca registrada "Moustache", que solo se quitó una vez desde entonces (1992 en "Ridicule"). Ese mismo año también apareció en "El gran rubio con un zapato negro" y en su continuación "La vuelta del gran rubio (con un zapato rojo)" (1974). Aumentó notablemente su popularidad al protagonizar la comedia "Un elefante se equivoca enormemente" (1976).

Falleció el 9 de octubre de 2017 a los 87 años de edad.




</doc>
<doc id="11518" url="https://es.wikipedia.org/wiki?curid=11518" title="Número transfinito">
Número transfinito

En teoría de conjuntos, número transfinito es el término original que el matemático alemán Georg Cantor introdujo para referirse a los ordinales infinitos, que son mayores que cualquier número natural.

En la terminología moderna, al referirse a ordinales o cardinales, «transfinito» e «infinito» son sinónimos.

Al igual que con los números naturales, puede pensarse en los números transfinitos como cardinales u ordinales:

Asumiendo el axioma de elección, todo lo que puede demostrarse con los axiomas de Zermelo-Fraenkel es:

La hipótesis del continuo afirma que de hecho "c" = . Sin embargo, el trabajo de Gödel y Paul Cohen demuestra que la hipótesis es independiente de dichos axiomas: no puede ser refutada o demostrada a partir de ellos. Es decir, usando los axiomas de Zermelo-Fraenkel (ZF) puede comprobarse que los tres cardinales anteriores cumplen formula_1. La hipótesis del continuo afirma que de hecho formula_3. Gödel probó en 1938 que esta hipótesis es consistente con los axiomas ZF, y por tanto puede ser tomado como un axioma nuevo para la teoría de conjuntos. Sin embargo, en 1963 Paul Cohen probó que la negación de la hipótesis del continuo también es consistente con los axiomas ZF, lo cual prueba que dicha hipótesis es totalmente independiente de los axiomas ZF. Es decir, pueden construirse tanto "teorías de conjuntos cantorianas" (en las que la hipótesis del continuo es una afirmación cierta), como "teorías de conjuntos no cantorianas" (en las que la hipótesis del continuo sea falsa). Esta situación es similar a la de las geometrías no euclidianas.

Para los números transfinitos se pueden extender sin ambigüedad la suma, la multiplicación y la potenciación. Sean por ejemplo dos conjuntos disjuntos formula_4 y formula_5, la suma y la multiplicación puede construirse a partir del cardinal de la unión y del producto cartesiano de estos dos conjuntos:

Es sencillo comprobar que estas operaciones están bien definidas ya que:

Aunque la suma y la multiplicación no presentan problemas, la resta y la división no están definidas. A diferencia de lo que sucede con los cardinales finitos no pueden definirse sin ambigüedad operaciones equivalentes a la resta o la división. La resta y la división pueden introducirse entre los cardinales finitos gracias a que a partir del conjunto de los cardinales finitos, que coinciden con los números naturales formula_6, pueden construirse el conjunto de los enteros y de los racionales. La construcción de los enteros y los racionales es posible debido a que todo cardinal finito es regular respecto a la suma, es decir, para cualesquiera cardinales "a, b" y "c" > 0, finitos se cumple:

Esas dos últimas propiedades de hecho no se cumplen nunca cuando uno de los cardinales es transfinito, si formula_7 tenemos las siguientes igualdades:

Los cardinales transfinitos dotados de la suma o la multiplicación constityen un monoide conmutativo. Debido a la falta de regularidad de los cardinales transfinitos no es aplicable el teorema de simetrización de un monoide que permitiría definir la resta y la división.
La potenciación requiere construir un conjunto más complicado, pero resulta igualmente bien definida. Si "A" y "B" son dos conjuntos cualesquiera y formula_4 y formula_5 se puede definir la exponenciación formula_10 como el cardinal del conjunto de funciones de "B" en "A":

Un caso particular interesante se da cuando "a" = 2, en este caso podemos por ejemplo "A" = {0,1}, y el conjunto A se puede identificar naturalmente con el conjunto de partes de B o conjunto potencia.

La potenciación también tiene propiedades de saturación curiosas, así para cardinales de tipo alef se tiene:
Cantor se percató de que era posible hablar de la cantidad de elementos de un conjunto infinito tal y como se habla de la cantidad de elementos de un conjunto finito. Es decir, encontró que era posible “medir” el tamaño de un conjunto infinito y, de hecho, comparar el tamaño de dos conjuntos infinitos para encontrar que el de uno era “mayor” que el del otro, y elaboró una teoría hasta cierto punto rigurosa respecto de estas ideas: la teoría de números transfinitos.

Cantor argumentaba que el desprecio de los matemáticos por el infinito y su naturaleza se debía a un abuso de este concepto. Lo que Cantor quería decir era que el término infinito se aplicaba sin distinción a cualesquiera conjuntos no finitos, siendo que, de entre ellos, era posible tomar algunos que son, de alguna manera, medibles y de tamaños comparables. Las reflexiones y posterior estudio de Cantor acerca de todo esto comenzaron cuando, intuyendo éste algún resultado no trivial, se preguntó si era posible poner en correspondencia uno a uno el conjunto de los números naturales con el conjunto de los números reales. Pronto pudo Cantor demostrar que no existía tal correspondencia, revelando así una diferencia entre la infinitud de dos conjuntos infinitos, lo que constituyó, en definitiva, un resultado de mucho interés. Cantor probó también que, contrario a lo que pudiera pensarse, el conjunto de los números racionales, que tiene propiedad de densidad, se corresponde uno a uno con el conjunto de los números naturales.

Es fácil dar un ejemplo de dos conjuntos que, uno teniendo todos los elementos del otro y más, se corresponden uno a uno. Tomemos, por ejemplo, a los números naturales:

y tomemos ahora solo aquellos números que son el cuadrado de algún número natural (claramente no todos los números naturales cumplen con esta característica, por lo que se descartan muchos de ellos):

Apenas es necesario explicar más para percatarse de que existe una correspondencia uno a uno entre formula_6 y su subconjunto

Además, Cantor encontró que la medición de un conjunto (ya sea finito o infinito), puede realizarse de dos maneras: una de ellas no considera nada más que la cantidad de elementos de un conjunto, mientras que la otra toma en cuenta el orden de los elementos de un conjunto. De esta distinción surgen los números cardinales y los números ordinales, los cuales pueden ser también transfinitos. Para conjuntos finitos, estos dos conceptos son equivalentes. Sin embargo, los dos conceptos difieren en el momento de aplicarse a conjuntos infinitos.




</doc>
<doc id="11520" url="https://es.wikipedia.org/wiki?curid=11520" title="Topaz (película)">
Topaz (película)

Topaz es una película estadounidense de 1969 del llamado género del suspense, dirigida por Alfred Hitchcock y con Frederick Stafford, Dany Robin, Claude Jade, Michel Subor, Karin Dor, John Vernon, Michel Piccoli, Philippe Noiret y John Forsythe en los papeles principales. 

La película "Topaz" está basada en la novela del mismo nombre escrita por Leon Uris y publicada en 1967 por McGraw-Hill.

La trama de la película comienza en 1962, en el ámbito de la Guerra Fría, con un imponente desfile militar del Ejército Rojo en la Plaza Roja. Mientras, en Copenhague, un oficial de los servicios de espionaje soviéticos, Boris Kusenov (Per-Axel Arosenius), con la ayuda de los agentes de la CIA, deserta a Estados Unidos junto con su esposa e hija.

El desertor soviético revela a los agentes de la CIA dos datos fundamentales: Cuba va a recibir misiles de la Unión Soviética y existe dentro de los servicios de inteligencia franceses una organización llamada Topaz, que traspasa información de la OTAN a la Unión Soviética mediante un «"topo"».

El agente estadounidense Nordstrom (John Forsythe), que había sido el interrogador de Kusenov, informa a su colega y amigo 
André Devereaux (Frederick Stafford), del Servicio de Documentación Exterior y Contraespionaje francés, de la existencia de un documento firmado por los gobiernos de Cuba y la Unión Soviética en el que se establecían las bases de las relaciones militares y todo lo concerniente a los misiles soviéticos en Cuba. Dicho documento estaba en poder de Enrique Parra (John Vernon), delegado de Cuba ante la Organización de las Naciones Unidas que estaba en Nueva York para asistir a una asamblea, por lo que le pide a Devereaux que intente hacerse con una copia de dicho documento.

Andre acompañó a su hija Michèle (Claude Jade) y su hijo Francois (Michel Subor) en su viaje de luna de miel a Nueva York. En Nueva York, André contacta a uno de sus agentes, Philippe Dubois ("Roscoe Lee Browne"), que consigue una entrevista con Parra bajo el pretexto de escribir un reportaje para la revista "Ebony". Aprovechando el barullo en la embajada de Cuba (ubicada en Harlem), la venalidad de un secretario y la soberbia de Parra que acepta saludar desde el balcón a las masas, Dubois consigue sacar unas fotos del texto del acuerdo. Pero al ser descubierto, debe darse a la fuga perseguido por los guardias de la embajada. Ya en la calle, finge atropellar a André para pasarle la cámara y desaparece entre la muchedumbre. Un guardaespaldas de Parra llega, pone a André de pie, lo observa de arriba a abajo y finalmente le suelta.

Ahora a los agentes de la CIA solo les faltan fotos de los misiles en Cuba y Nordstrom propone a André ir a Cuba para conseguirlas

André vuela a Cuba como agregado comercial de la embajada francesa, a pesar de la ira y el ansia de su esposa Nicole (Dany Robin) quien sospecha que él tiene una amante en Cuba. En efecto, André tiene una amante, la hermosa morena Juanita de Córdoba (Karin Dor), joven viuda de un héroe de la revolución. Juanita es ahora una espía contrarrevolucionaria, comanda una red anti-castrista e incluso aprovecha sus estrechas relaciones con Parra para conseguir información de primera mano.

Al llegar a casa de Juanita, André encuentra a Parra que se despide y los dos rivales se desafían mutuamente. Luego, en la alcoba y antes de acostarse, el agente francés pide a su amante si es posible conseguir fotos de los misiles.

Juanita envía a una pareja de sus sirvientesal puerto bajo el pretexto de una comida campestre. Allí sacan fotos de los buques rusos descargando los misiles, pero son descubiertos, detenidos y llevados a la sede de la Dirección General de Inteligencia (DGI). Donde serán torturados, pero no sin antes esconder su camara en la viga hueca de un puente, donde un peón de Juanita la recoge. La película es rápidamente revelada y las imágenes transferidas en un microfilm que es escondido en la máquina de escribir de André.

Entretanto, André presencia, como empleado de la embajada, una gran arenga de Fidel Castro al pueblo, donde el guardaespaldas de Parra lo reconoce. A su vez, en el sótano de la DGI la criada de Juanita balbucea en la oreja de Parra el nombre de su jefe: Juanita de Córdoba. Inmediatamente se organiza una redada en la casa de de Córdoba. En la cual se hacen pesquisas y se confirma la traición. Parra toma en sus brazos a Juanita, la estrecha y susurrando le dice que no quiere que los verdugos descuarticen a tan hermoso cuerpo. Tras lo cual le dispara una bala en el corazón. Seguidamente llama al aeropuerto para que detengan a André, pero el francés acaba de despegar. Los aduaneros no hallaron nada extraño en su equipaje.

Para su sorpresa, en Washington D. C. no halla a su esposa, Nicole ha vuelto sola a París. Además sus jefes están furiosos, ¿qué hizo en Cuba que La Habana se quejó de la «actitud inamistosa» del agregado francés? André decide inmediatamente ir tras los pasos de su esposa.

En París halla a su esposa y su hija Michèle, en un intento por reconciliarse. También organiza una reunión para sus amigos y colegas en el restaurante de lujo Chez Pierre, buscando revelar la identidad del topo. El servicio empieza y André declara que hay un espía sentado a la mesa. En el silencio repentino solo Jarré (Philippe Noiret) empieza a comer vorazmente el paté de hígado y a beber grandes tragos de vino. En su estado de nerviosismo, dice que a él le parece que esto es solo un intento de desinformación por parte de los rusos, pues que sabe de fuente fidedigna que Kusenov ha muerto hace dos años. Y se va.

Pero en la tarde, Jarré, muy inquieto, va a ver su jefe en la red Topaz, Granville (Michel Piccoli). Un alto funcionario francés, viejo amigo de André. Granville en vez de calmar a Jarré, le reta. Ha atraído la atención y además le molesta porque está esperando a una visita galante. Al desperdirse se encuentra a Nicole, era ella a quien Granville esperaba. Y mientras se abrazan en el vestíbulo se puede ver colgada al muro una vieja foto en un cuadro, Nicole entre Granville y André, con cazadoras, boinas y fusiles, juveniles y amistosos, tomados durante sus años en la Resistencia francesa, unas dos décadas atrás. 

André, que ahora sospecha de Jarré, le envía a su yerno François (un periodista y caricaturista) para que le hostigue con el pretexto de hacerle una entrevista para un periódico; pero Jarré, acorralado, llama a sus guardaespaldas. André y Michèle, alarmados, llegan poco después al piso y lo hallan muerto, caído de su balcón sin una huella de François. Después, el padre y su hija regresan a su piso, donde Nicole les espera. De repente llega François vacilante, los guardaespaldas le golpearon, pero pudo recobrar el sentido. Les oyó llamar a un número de teléfono y se dio a la fuga. Pero el joven recuerda el número y André averigua que éste es el de su viejo amigo Granville. Nicole ve al retrato de Jarré y entiende que su amante es el jefe de la red Topaz. Sin poder soportarlo, con sus ojos llenos de lágrimas le confiesa todo a su familia.



Hitchcock aparece en el aeropuerto con una mujer que le lleva en silla de ruedas. Hitchcock ve a un conocido, se levanta a saludarle y ambos se retiran caminando.



</doc>
<doc id="11525" url="https://es.wikipedia.org/wiki?curid=11525" title="Ceferino">
Ceferino

Ceferino (Roma, Imperio Romano; ¿?-Ib.; 20 de diciembre de 217) fue el papa n.º 15 de la Iglesia católica de 199 a 217.

Hijo de Abundio, al iniciar su pontificado nombró a Calixto, que sería su sucesor, archidiácono de Roma, cargo equivalente al actual de secretario de estado, y que supuso convertirlo en su principal consejero, lo que dada la escasa formación teológica de Ceferino lo hizo depender totalmente de aquel.

Conocemos mucho más de Ceferino que de cualquier otro pontífice de los primeros años de la Iglesia, aunque esta información está posiblemente sesgada al proceder del teólogo romano Hipólito, quien, en su obra "Philosopheumena", acusaba al papa de adepto al monarquianismo modalístico o modalismo, doctrina que negaba la Trinidad y que posiblemente aceptó Ceferino, influenciado por su consejero Calixto, como respuesta al montanismo. En dicha obra, Hipólito describe a Ceferino como torpe e ignorante, lo cual puede ser cierto, ya que no gozaba de los conocimientos teológicos de su archidiácono y consejero. 

Ceferino estableció que los jóvenes, cumplidos los 14 años, hiciesen la comunión por Pascua y que los cálices no fueran de madera, sino de vidrio. Introdujo, además, el uso de la patena. También excomulgó a Tertuliano.

Ordenó que los sacerdotes y diáconos se ordenasen públicamente en presencia de muchos clérigos y legos para que fuera manifiesta la inocencia y que fueran dotados para estos oficios personas de vida irreprensible.

Durante su pontificado, iniciado bajo el gobierno del emperador Septimio Severo, se reanudaron las persecuciones contra los cristianos, persecuciones que se suavizaron a su muerte y durante el mandato de su sucesor, Caracalla, pero que se reactivaron al ascender, en 217, al trono del imperio Macrino, lo que hace afirmar a ciertas fuentes que Ceferino murió en ese mismo año tras sufrir martirio, aunque, al no existir pruebas documentales de tal afirmación, lo más probable es que falleciera de muerte natural.

Ceferino fue enterrado en una cámara sepulcral suya propia cerca del cementerio de Calixto en la Vía Apia.

La oración propia de las misas que se celebran por San Ceferino es el "Praesta quaesumus", propia de los pontífices mártires.



</doc>
<doc id="11526" url="https://es.wikipedia.org/wiki?curid=11526" title="Espora">
Espora

En biología, el término espora designa un cuerpo microscópico unicelular o pluricelular que se forma con fines de dispersión y supervivencia por largo tiempo (dormancia) en condiciones adversas, y que generalmente es una célula haploide. En muchos seres eucariotas, es parte fundamental de su reproducción, originándose un nuevo organismo al dividirse por mitosis (especialmente en hongos) o meiosis (plantas), sin tener que fusionarse con otra célula, mientras que en algunas bacterias se trata en cambio de una etapa inactiva, resistente a la desecación y con fines de supervivencia no reproductivos. El término deriva del griego σπορά ("sporá"), "semilla".

La espora es un elemento importante en los ciclos vitales biológicos de plantas, hongos, algas y algunos protozoos, los cuales suelen producir las esporas en estructuras denominadas esporangios. En las plantas, las esporas son los gametofitos dentro de su ciclo de vida y permiten al mismo tiempo la dispersión de los propágulos. La mayoría de los hongos producen esporas; aquellos que no lo hacen se denominan hongos asporógenos.

Las esporas se pueden clasificar según su función, estructura, origen del ciclo vital o por su movilidad:

Las diásporas son unidades de dispersión de los hongos, musgos y algunas otras plantas. En hongos, las clamidosporas son esporas multicelulares de pared gruesa resultado de reproducción asexual y las zygosporas son la parte sexual pues se dividen por meiosis cuando logra condiciones para germinar. Los hipnozigotos de los hongos zigomicetos son producidos por vía sexual y pueden dar lugar a una conidiospora (“zygosporangium”) asexual.

Una meiospora es el producto de la meiosis (la etapa citogenética crítica de la reproducción sexual), lo que significa que es haploide y que dará lugar a una célula o individuo haploide. Esto es característico en los ciclos vitales de plantas y algas.

Una mitospora se produce por un mecanismo de esporulación y se propaga por un medio asexual como resultado de la mitosis. La mayoría de los hongos producen mitoesporas.

La motilidad es la capacidad de moverse autónoma y espontáneamente. Las esporas se dividen según puedan moverse o no. La zoospora puede moverse por medio de uno o más flagelos y se pueden encontrar en algunas algas y hongos. En tanto la autoespora no puede moverse y no tiene el potencial de desarrollar ningún flagelo. Las balistosporas se descargan activamente del cuerpo fructífero (tal como la seta). La estatismospora no se descarga activamente del cuerpo fructífero, como en el pedo de lobo.

Las plantas se caracterizan por tener un ciclo vital con alternancia de generaciones, una generación esporofítica y una gametofítica. Ciertas células de los esporofitos producen esporas haploides por meiosis. Estas esporas se desarrollarán hasta convertirse en gametofitos. Un ejemplo es el gametofito de las plantas vasculares más altas (angiospermas y gimnospermas), que son meiosporas de dos tipos:

En el caso de las plantas vasculares como los helechos, la dispersión anemócora proporciona una gran capacidad de distribución de las esporas. También, las esporas son menos propicias para la depredación animal que las semillas porque no contienen casi ninguna reserva de alimento, pero son más propicias para la depredación por hongos y bacterias. Su principal ventaja es que, de todas las formas de reproducción, las esporas requieren menos energía y materiales para producirse. Las esporas de las plantas vasculares son siempre haploides, pudiendo ser isosporas (homosporas) o heterosporas. Las heterosporas, presentes por ejemplo en las selaginellas, isoetes y algunos helechos acuáticos, producen esporas de dos tamaños: las esporas más grandes (megasporas) producen gametófitos femeninos y las más pequeñas (microsporas) producen gametófitos masculinos. Las esporas pueden ser de dos tipos atendiendo a las marcas de desarrollo: monoletas o triletas. En las monoletas, hay una sola línea elevada en la espora que indica el eje a lo largo del cual la célula madre de las esporas se dividió. En las esporas triletas, las cuatro esporas comparten un origen común, se disponen según un tetraedro y entran en contacto en tres caras separadas por tres carenas que irradian de un punto central (en Y).

Esporas de gran diversidad y otros propágulos juegan un rol central en la mayoría de algas multicelulares, afectando su ecología. Los fósiles más antiguos son esporangios de algas rojas de hace 1.200 millones de años. Se presentan esporas en algas verdes, rodofitas, heterocontofitas y cloraracniofitas.

En los hongos y pseudohongos, son a menudo clasificados por las estructuras productoras de esporas. Estas esporas suelen tener características propias de un taxón en particular. Principales tipos de esporas:

Las oosporas forman parte del ciclo sexual de los oomicetes.

Las esporas bacterianas son características de ciertas bacterias, que por lo general desarrollan una sola espora por cada célula. En este caso la formación de esporas no es un tipo de reproducción definitiva; estas células pueden resistir la destrucción en un medio hostil o desfavorable. Son diversas bacterias terrestres, especialmente Gram positivas, las que pueden inducirse al estado de espora mediante un mecanismo llamado esporulación, logrando así resistencia contra la desecación, trituración, escasez de nutrientes, frío, calor, radiación (UV, X, γ), sal, oxidantes, desinfectantes, pH extremo, etc. debido a su cubierta dura e impermeable. Es un estado inactivo o latente en el que no crece y no hay reproducción, pues de una bacteria se produce una sola espora. Su activación en condiciones favorables se denomina germinación. Hay 3 tipos de esporas bacterianas:


</doc>
<doc id="11528" url="https://es.wikipedia.org/wiki?curid=11528" title="Errores de tipo I y de tipo II">
Errores de tipo I y de tipo II

En un estudio de investigación, el error de tipo I también denominado error de tipo alfa (α) o falso positivo, es el error que se comete cuando el investigador rechaza la hipótesis nula (formula_1) siendo esta verdadera en la población. Es equivalente a encontrar un resultado falso positivo, porque el investigador llega a la conclusión de que existe una diferencia entre las hipótesis cuando en realidad no existe. Se relaciona con el nivel de significancia estadística.

La hipótesis de la que se parte formula_1 aquí es el supuesto de que la situación experimental presentaría un «estado normal». Si no se advierte este «estado normal», aunque en realidad existe, se trata de un error estadístico tipo I. Algunos ejemplos para el error tipo I serían:

En un estudio de investigación, el error de tipo II, también llamado error de tipo beta (β) (β es la probabilidad de que exista este error) o falso negativo, se comete cuando el investigador no rechaza la hipótesis nula siendo esta falsa en la población. Es equivalente a la probabilidad de un resultado falso negativo, ya que el investigador llega a la conclusión de que ha sido incapaz de encontrar una diferencia que existe en la realidad.

Se acepta en un estudio que el valor del error beta esté entre el 5 y el 20%.

Contrariamente al error tipo I, en la mayoría de los casos no es posible calcular la probabilidad del error tipo II. La razón de esto se encuentra en la manera en que se formulan las hipótesis en una prueba estadística. Mientras que la hipótesis nula representa siempre una afirmación enérgica (como por ejemplo formula_3 «"Promedio μ = 0"») la hipótesis alternativa, debido a que engloba todas las otras posibilidades, es generalmente de naturaleza global (por ejemplo formula_4 «"Promedio μ ≠ 0"» ). El gráfico de la derecha ilustra la probabilidad del error tipo II (rojo) en dependencia del promedio μ desconocido.

El poder o potencia del estudio representa la probabilidad de observar en la muestra una determinada diferencia o efecto, si existe en la población. Es el complementario del error de tipo II (1-β).

Una vez realizado el contraste de hipótesis, se habrá optado por una de las dos hipótesis, la hipótesis nula o base formula_5 o la hipótesis alternativa formula_6, y la decisión escogida coincidirá o no con la que en realidad es cierta. Se pueden dar los cuatro casos que se exponen en el siguiente cuadro:

Si la probabilidad de cometer un error de tipo I está unívocamente determinada, su valor se suele denotar por la letra griega α, y en las mismas condiciones, se denota por β la probabilidad de cometer el error de tipo II, esto es:

En este caso, se denomina Potencia del contraste al valor 1-β, esto es, a la probabilidad de escoger formula_6 cuando esta es cierta

Cuando es necesario diseñar un contraste de hipótesis, sería deseable hacerlo de tal manera que las probabilidades de ambos tipos de error fueran tan pequeñas como fuera posible. Sin embargo, con una muestra de tamaño prefijado, disminuir la probabilidad del error de tipo I, α, conduce a incrementar la probabilidad del error de tipo II, β.

Usualmente, se diseñan los contrastes de tal manera que la probabilidad α sea el 5% (0,05), aunque a veces se usan el 10% (0,1) o 1% (0,01) para adoptar condiciones más relajadas o más estrictas. El recurso para aumentar la potencia del contraste, esto es, disminuir β, probabilidad de error de tipo II, es aumentar el tamaño muestral, lo que en la práctica conlleva un incremento de los costes del estudio que se quiere realizar.




</doc>
<doc id="11533" url="https://es.wikipedia.org/wiki?curid=11533" title="Folíolo">
Folíolo

En botánica, se llama pinna o folíolo a cada una de las piezas separadas en que a veces se encuentra dividido el limbo de una hoja.
Cuando el limbo foliar está formado por un solo folíolo, es decir no está dividido, se dice que la hoja es una hoja simple.
Cuando el limbo foliar está dividido en folíolos se dice que la hoja es hoja compuesta.

Según el número de folíolos o pinnas de una hoja compuesta podemos diferenciar:

Una hoja pinnada puede tener a su vez las pinnas divididas en pínnulas, estas hojas frecuentes por ejemplo en muchos helechos, se denominan bipinnadas.



</doc>
<doc id="11534" url="https://es.wikipedia.org/wiki?curid=11534" title="Epicureísmo">
Epicureísmo

El epicureísmo es un movimiento filosófico que abarca la búsqueda de una vida feliz mediante la búsqueda inteligente de placeres, la ataraxia (ausencia de turbación) y las amistades entre sus correligionarios. Fue enseñada por Epicuro de Samos, filósofo ateniense del siglo IV a. C. (341 a. C.) que fundó una escuela llamada Jardín y cuyas ideas fueron seguidas por otros filósofos, llamados "epicúreos".

El gusto, para el epicureísmo, no debía conformarse al cuerpo, como preconizaba el hedonismo cirenaico, sino que debía ser también intelectual. Además, para Epicuro la presencia de placer o felicidad era un sinónimo de la ausencia de dolor o de cualquier tipo de aflicción: el hambre, la tensión sexual, el aburrimiento, etc. Era un equilibrio perfecto entre la mente y el cuerpo que proporcionaba la serenidad o ataraxia. 

Según Adolfo Sánchez Vázquez, «el epicúreo alcanza el bien, retirado de la vida social, sin caer en el temor a lo sobrenatural, encontrando en sí mismo, o rodeado de un pequeño círculo de amigos, la tranquilidad de ánimo y la autosuficiencia». 

Para Epicuro, los placeres y sufrimientos son consecuencia de la realización o impedimento de los "apetitos". Epicuro distingue entre tres clases de apetitos, por tanto placeres:

Es importante aclarar que Epicuro no era dualista, es decir, no postulaba la oposición cuerpo-alma; el alma, igual que el cuerpo, es material y está compuesta de átomos.
También distinguía entre dos tipos de placeres, basados en la división del hombre entre dos diferentes pero unidos, el cuerpo y el alma:

Pese a que el placer es un bien y el dolor un mal, hay que administrar inteligentemente el placer y el dolor: en ocasiones debemos rechazar placeres a los que les siguen sufrimientos mayores y aceptar dolores cuando se siguen de placeres mayores. La razón representa un papel decisivo en lo que respecta a nuestra felicidad, nos permite alcanzar la total imperturbabilidad (ataraxia), la cual compara Epicuro «con un mar en calma», cuando ningún viento lo azota y nos da libertad ante las pasiones.

La finalidad de la filosofía de Epicuro no era teórica, sino más bien práctica, que buscaba sobre todo procurar el sosiego necesario para una vida feliz y placentera en la que los temores al destino, los dioses o la muerte quedaran definitivamente eliminados.

Para ello se fundamentaba en una teoría empirista del conocimiento, en una física atomista inspirada en las doctrinas de Leucipo y Demócrito y en una ética hedonista.

Entre los seguidores de las enseñanzas de Epicuro en la Antigua Roma figuran los poetas Horacio, cuya famosa declaración " Carpe Diem" ("aprovecha el día") ilustra su filosofía, Virgilio y Lucrecio. El epicureísmo es una doctrina de un paganismo típicamente laico y mediterráneo, y en este ámbito ganó gran número de seguidores que la consideraron una doctrina verdadera que solucionaba todos los problemas. 

Su escuela de pensamiento perduró largamente durante siete siglos tras la muerte de Epicuro; pero después fue casi relegada al olvido al advenir la Edad Media, periodo en el que se perdió o fue destruida la mayoría de los escritos de este filósofo griego a causa del rechazo que por sus ideas experimentó el Cristianismo, que no pudo adaptarlas a su sistema de creencias por la visión cristiana del dolor. Por otra parte, el platonismo y el aristotelismo lo intentaron integrar con poco éxito. 

Lo que queda de la filosofía epicúrea está disponible a través de diversas fuentes:





</doc>
<doc id="11537" url="https://es.wikipedia.org/wiki?curid=11537" title="Función continua">
Función continua

En matemáticas, una función continua es aquella para la cual, intuitivamente, para puntos cercanos del dominio se producen pequeñas variaciones en los valores de la función; aunque en rigor, en un espacio métrico como en variable real, significa lo contrario, que pequeñas variaciones de la función implican que deben estar cercanos los puntos. Si la función no es continua, se dice que es discontinua. Una función continua de formula_1 en formula_1 es aquella cuya gráfica puede dibujarse sin levantar el lápiz del papel (más formalmente su grafo es un conjunto conexo).

La continuidad de funciones es uno de los conceptos básicos del análisis matemático y de la topología general. El artículo describe principalmente la continuidad de funciones reales de una variable real.

Informalmente hablando, una función f definida sobre un intervalo I es continua si la curva que la representa, es decir el conjunto de los puntos (x, f(x)), con x en I, está constituida por un trazo continuo, es decir un trazo que no está roto, ni tiene "hoyos" ni "saltos", como en la figura de la derecha.

El intervalo I de x es el dominio de definición de f, definido como el conjunto de los valores de x para los cuales f(x) existe.

El intervalo J de y es el rango (también conocido como imagen) de f, el conjunto de los valores de y, tomados como y = f(x). Se escribe J = f(I). Notar que en general, no es igual que el codominio (sólo es igual si la función en cuestión es suprayectiva.)

El mayor elemento de J se llama el máximo absoluto de f en I, y el menor valor de J es su mínimo absoluto en el dominio I.

Definición de continuidad en un punto
si: 

tal que para toda x en el dominio de la función:

Esto se puede escribir en términos de límites de la siguiente manera:
Si "x" es punto del dominio de la función que es punto de acumulación del mismo, entonces "f" es continua en "x" si y sólo si formula_5. Cuando "x" es un punto del dominio que no es de acumulación del mismo, es decir, es punto aislado del dominio, se cumple trivialmente la definición, luego toda función es continua en los puntos aislados de su dominio. Por ejemplo, las sucesiones de números reales son un caso de función real de variable real cuyo dominio es el conjunto de los números naturales. Como todos los puntos del dominio de una sucesión son puntos aislados del mismo, se concluye que toda sucesión es una función continua. Por otro lado, no tiene sentido hablar de si una función es o no continua en un punto que no pertenezca al dominio de la misma. Por ejemplo, a función f(x)=1/x es continua en todos los puntos de su dominio. En cero, como no está en el dominio, no podemos hablar ni de continuidad ni de discontinuidad.

OBSERVACIÓN IMPORTANTE:<br>
En el caso de aplicaciones de formula_6 en formula_6, es corriente ver que se dice que una función formula_8 es continua en un punto x si existe f (x), si existe el límite de f (x) cuando x tiende hacia x por la derecha, si existe el límite de f (x) cuando x tiende hacia x por la izquierda, y además ambos coinciden con f (x). Esto implicaría que, dada una función, si no está definida en un punto, ésta no es continua en él, llegando a una situación como la siguiente: La función formula_9 definida como formula_10 no es continua en 0 por que no está definida en dicho punto, pero tampoco es continua en 3, en 5, en 1000000 ni en -e, pero por el mismo motivo no sería continua en 1+2i o en (1,2,5). Esta definición, no satisfactoria, de continuidad está muy extendida, pero hay que recordar el requisito indispensable para poder hablar de continuidad de que el punto en el que se estudia la continuidad pertenezca al dominio. Si no está en el dominio, pero es punto de acumulación del mismo, podemos hablar de si puede o no extenderse con continuidad a dicho punto, pero no podemos decir que la función es discontinua en dicho punto (la función extendida sí podría ser discontinua, puesto que al incorporar dicho punto al dominio, tiene sentido plantearse el estudio de la continuidad en él).
Así pues, una función f continua en un punto de su dominio x que, además, es punto de acumulación del mismo, implica lo siguiente:

1. existe el límite por la derecha:

2. existe el límite por la izquierda:

3. La función tiene límite por la derecha y por la izquierda del punto x

4. El límite por la derecha, el límite por la izquierda coinciden:

5. Si existen el límite por la derecha y por la izquierda y sus valores coinciden, la función tiene límite en este punto:

6. Existe f(x):

7. El límite y el valor de la función coinciden:

La función es continua en ese punto. Una función es continua en un intervalo si es continua en todos sus puntos.

Si f(x)= y, la continuidad en x se expresa así:

parafraseando, cuando x se aproxima a x, f(x) se aproxima a y'. Por definición de los límites, esto significa que para todo intervalo abierto J, centrado en y, existe un intervalo abierto I, centrado en x, tal que formula_20.

Si f ejecuta un salto en el punto, el teorema cae en falta. En efecto no todo intervalo I alrededor de x tiene su imagen en un intervalo J centrado en y, con un radio inferior al salto de f, no importa lo pequeño que este intervalo sea, hay valores de x del intervalo I alrededor de x que tiene su imagen en un intervalo K centrado en y, siendo y y y valores distintos, esto es: x tiene imágenes que se salen de J.

La ventaja de esta definición es que se generaliza a cualquier espacio topológico. 

Una función formula_21 es continua por la izquierda en el punto formula_22 si el límite lateral por la izquierda y el valor de la función en el punto son iguales. Es decir: 

como en la figura.

Una función formula_21 es continua por la derecha en el punto formula_25 si su límite lateral por la derecha y el valor de la función en el punto son iguales. Es decir: 

Una función formula_21 es continua en un punto si es continua por la izquierda y es continua por la derecha. Esto es:
Un valor c, pertenece a un intervalo abierto I, de extremo izquierdo a y extremo derecho b, representado I= (a,b) si:

Una función, f es continua en un intervalo abierto I= (a,b), si y solo si la función es continua en todos los puntos del intervalo, es decir:

Un valor c, pertenece a un intervalo cerrado I, de extremo izquierdo a y extremo derecho b, representado I= [a,b] si:

Una función f es continua en un intervalo cerrado [a, b] si la función es continua en el intervalo abierto (a,b) y es continua por la derecha de a y continua por la izquierda de b:

Las funciones polinomiales, trigonométricas: seno y coseno, las exponenciales y los logaritmos son continuas en sus respectivos dominios de definición.

La parábola, como función polinómica, es un ejemplo de función continua a lo largo de todo el dominio real.

En la gráfica se ve la función seno que es periódica, acotada y continua en todo el domino real, dado su carácter periódico, con ver uno solo de los ciclos es suficiente para comprobar la continuidad, porque el resto de los ciclos son exactamente iguales.
Las funciones definidas para distintos intervalos de x, puede ser discontinua en los puntos de cambio de intervalo, como por ejemplo:


Su curva es una sucesión de segmentos horizontales a distintas alturas. Esta función no es continua en los enteros, pues los límites a la izquierda y a la derecha difieren de uno, pero es continua en los segmentos abiertos (n, n+1) donde es constante.

Las funciones racionales son continuas en un intervalo adecuado. Un ejemplo de esto es la función inverso de x:

Esta función es una hipérbola compuesta por dos tramos. x < 0 y x > 0. Como vemos, efectivamente es continua en todo el dominio formula_34 porque no está definida en x= 0. Si se extiende el dominio de la función a R (dándole un valor arbitrario a f(0)) la función será discontinua.

Estos son algunos de los teoremas más importantes sobre funciones continuas.


Las funciones derivables son continuas. Si una función es derivable en x= a entonces es continua en x= a. De modo que la continuidad es una condición necesaria para la derivabilidad. O el conjunto de las funciones derivables es parte de las funciones continuas.

Es importante notar que lo recíproco no es válido; es decir que nada se puede afirmar sobre la derivabilidad de una función continua. Un ejemplo claro de esta situación es la función valor absoluto f(x)= |x| que si bien es continua en todo su dominio no es derivable en x= 0. Incluso hay funciones continuas en todo formula_46 pero no derivables en ningún punto (las funciones del movimiento browniano verifican esto con probabilidad 1). Sobre esto consultar "Calculus" de Spivak.

Una función formula_47, se dice que: 
Cualquier función polinómica de una variable es una función de clase formula_58. La función generalizada denomiada delta de Dirac es una función de clase formula_59 ya que es la derivada segunda de la función rampa que es continua, y la derivada primera de la función escalón de Heaviside que es de clase formula_60

Se puede dar ejemplos que muestran que hay funciones de clase formula_50
pero no lo son de clase formula_62. Los ejemplos clásicos son formula_63.

Sean formula_64 e formula_65 dos espacios topológicos. Una aplicación formula_66 se dice que es continua si:

Esta definición se reduce a la definición ordinaria de continuidad de una función formula_71 si sobre formula_72 y formula_73 se considera la topología inducida por la distancia euclídea.

Con la misma notación anterior, si formula_74, diremos que formula_8 es continua en formula_76 cuando se obtiene que formula_77 es un entorno de formula_76, cualquiera que sea el entorno formula_79 de formula_80.

Es "inmediato" entonces comprobar que formula_8 es continua si y solo si es continua en formula_82, cualquiera que sea éste, es decir, cuando sea continua en cada uno de los puntos de su dominio.

El término función continua en la parte de la teoría de conjuntos que se refiere a los números ordinales tiene un sentido diferente al referido a las funciones sobre espacios topológicos. Concretamente una función "F" definida sobre la clase de los números ordinales formula_83 es continua si para cada ordinal límite γ se cumple la siguiente propiedad:



</doc>
<doc id="11538" url="https://es.wikipedia.org/wiki?curid=11538" title="Rioja (vino)">
Rioja (vino)

Rioja es una Denominación de origen calificada (DOCa) de España con la que se distinguen a ciertos vinos elaborados en áreas de las comunidades autónomas de La Rioja y el País Vasco mayoritariamente, y en menor medida en Navarra o Castilla y León, (menos de 2,5 km²). Por la diversidad orográfica y climática se distinguen tres subzonas de producción —Rioja Alta, Rioja Baja y Rioja Alavesa— donde se originan vinos de distintas características. La producción media anual de vino de Rioja es de 250 millones de litros (85% vino tinto y 15% vino blanco y rosado). Los vinos de Rioja son frescos, aromáticos, de composición equilibrada y excelente buqué.

El vino de la DO Rioja se identifica por sus contraetiquetas y precintos numerados. Es la denominación de origen más elegida por los consumidores tanto dentro como fuera de casa, con un 36% y un 27%, respectivamente, de las consumiciones.


Las variedades tradicionales autorizadas por el Consejo Regulador de la D.O.Ca. Rioja desde su creación en 1925 han sido siete, cuatro tintas y tres blancas:

Las variedades preferentes son la Tempranillo en tinto y la Viura en blanco.

En el año 2007, el Consejo Regulador de la D.O.Ca. Rioja autorizó, por primera vez desde 1925, la incorporación de nueve variedades nuevas dentro de los límites de la denominación.
, cambios que se reflejaron en dos modificaciones del Reglamento existente aprobado en 2004: "BOE-A-2008-4991" y "BOE-A-2009-8950". Son las siguientes:


Estas nuevas variedades autorizadas solo se pueden plantar en sustitución de arranques, para no incrementar la masa vegetal de la Denominación.

En el caso de las nuevas variedades autóctonas, tanto tintas como blancas, no se establece un límite en el porcentaje que deben llevar los vinos, por lo que se permite la elaboración de vinos monovarietales de estas uvas. Por el contrario, en las variedades blancas foráneas (Chardonnay, Sauvignon blanc y Verdejo) se establece que no podrán ser las predominantes en la composición final del vino. Por tanto, si se indican las variedades en la etiqueta, deberá figurar siempre en primer lugar la variedad blanca autóctona (Viura, Garnacha blanca, Malvasía de Rioja, Maturana blanca, Tempranillo blanco o Turruntés).

La incorporación de estas nuevas variedades se hizo con la finalidad de recuperar el patrimonio vitícola riojano -en el caso de las uvas autóctonas- y para incrementar la competitividad de los blancos de Rioja en el mercado internacional -en el caso de las variedades blancas foráneas.

Además de estas uvas, el Consejo Regulador autoriza en ocasiones la incorporación de otras variedades bajo la denominación de ""experimentales"" siempre y cuando no sea la variedad predominante y no se especifique su nombre en la etiqueta o simplemente se nombren como ""otras variedades"". El caso más conocido es el de la Bodega Herederos del Marqués de Riscal a la que se le permite incluir la uva Cabernet sauvignon en algunos de su "coupages" (""Gran Reserva"" y ""Barón de Chirel"") ya que la utiliza desde su fundación en 1858, muchos años antes de la formación del propio Consejo Regulador. No obstante, a pesar de los más de 150 años transcurridos, legalmente se sigue considerando una variedad "experimental". Otras muchas bodegas utilizan esta casta de uva como variedad "experimental" como: Bodegas Marqués de Murrieta (""Dalmau""), Bodegas Alicia Rojas (""Colección Privada""), Bodegas y Viñedos Marqués de Vargas, Martínez Bujanda (""Finca Valpiedra ""), Bodegas Paternina, Solarce, Barón de Ley(""Finca Monasterio""), Izadi o la La Rioja Alta (""Barón de Oña""). Otras variedades tintas cultivadas como "experimentales" son Merlot y Sirah (Bodegas Enartis, Bodegas Bagordi, Bodegas Campo Viejo, Hacienda de Susar, etc.). En cuanto a las variedades blancas, algunas han dejado de ser "experimentales" como la Chardonnay y la Sauvignon blanc y otras lo siguen siendo. Por ejemplo, el vino ""Remelluri Blanco"" de Granja Ntra. Sra. de Remelluri contiene además de Chardonnay y Sauvignon blanc, Viognier, Roussane, Marsanne y Moscatel.

La superficie cultivada en 2009, en hectáreas, según las variedades de uva y por Comunidades Autónomas es la siguiente:

Como puede verse las uvas tintas representan el 93,68% y las blancas el 6,32%.

En cuanto a variedades, las uvas tintas se distribuyen de las siguiente manera: Tempranillo: 85,33%, Garnacha: 9,91%, Mazuelo: 2,65%, Graciano: 0,17% y otras: 0,37%. El porcentaje entre las blancas queda determinado así: Viura: 94,91%, Malvasía: 1,91%, Garnacha blanca: 0,36% y otras: 2,81%.

La poda consiste en formar la cepa con tres brazos y dos pulgares en cada brazo. Cada pulgar tendrá dos yemas de las que brotarán los sarmientos. La vendimia se hace manualmente en el mes de octubre. Para garantizar la calidad se restringe la cantidad a 6500 kg/ha para variedades tintas y 9000 kg/ha para blancas.

Tradicionalmente el vino de Rioja se ha elaborado ensamblando diferentes tipos de variedades de uva, aunque hoy en día también es muy común encontrar vinos monovarietales.

De acuerdo con el Reglamento de la D.O.Ca. Rioja (BOE-A-2004-18384) y su última modificación (BOE-A-2009-8950), los diferentes tipos de vino deben emplear las variedades autorizadas en las siguientes proporciones:







La elaboración se realiza en barricas de roble de 225 litros durante un tiempo que oscila entre 1 y 3 años, y posteriormente en la propia botella durante un período de 6 meses a 6 años.

Dependiendo del tiempo que el vino permanece en barrica se clasifica como:


Las calificaciones de las cosechas de la D.O.Ca. Rioja otorgadas por su Consejo Regulador desde su fundación en 1926 son las siguientes:



Los términos municipales englobados en la D.O.Ca. Rioja, desglosados por subzonas y provincias son los siguientes:


El Reglamento actual de la D.O.Ca. Rioja viene recogida en la Orden Ministerial:

Este Reglamento ha sido modificado posteriormente por las siguientes Órdenes Ministeriales:

Otro documento importante es


Dentro del territorio de La Rioja se encuentra reconocida la indicación geográfica Valles de Sadacia, con derecho a la mención tradicional de ""Vino de la Tierra"", utilizada para designar los vinos de mesa originarios de la zona vitícola de cuatro de los siete valles de la comunidad autónoma, pertenecientes a los ríos Iregua, Leza, Cidacos y Alhama.

La Universidad de La Rioja (UR) imparte el Grado y la Licenciatura en Enología en la Facultad de Ciencias, Estudios Agroalimentarios e Informática desde 1996 y es el segundo campus español que creó esta titulación oficial de segundo ciclo.

Los alumnos de la UR completan su formación teórica con un "practicum" de tres meses en alguna de las bodegas de la DOCa Rioja y, gracias a las instalaciones del Complejo Científico Tecnológico -dotadas con Bodega Experimental y Sala de Análisis Sensorial-, completan el ciclo de la vid, desde la vendimia hasta el embotellado de sus propios vinos.

Además, la Universidad de La Rioja imparte el programa de Doctorado en Enología, el Máster en Turismo Enológico, el Máster en Viticultura, Enología y Dirección de Empresas y varios cursos de Especialista Universitario.

El vino impregna múltiples facetas de la vida en La Rioja y dispone de variadas manifestaciones culturales, como el ciclo de conciertos en bodega "Catarsis", el programa "El Rioja y los 5 Sentidos", el Museo de la Cultura del Vino Dinastía Vivanco en Briones, la popular "Batalla del Vino de Haro" o la "Batalla del clarete" de San Asensio, las Fiestas de la Vendimia en Logroño y, organizado de forma independiente, el Festival Mariquitina's Day.




</doc>
<doc id="11545" url="https://es.wikipedia.org/wiki?curid=11545" title="Resta">
Resta

La "resta" o la sustracción es una [[operación de aritmética ] que se representa con el [[signo menos|signo (–)]], representa la operación de eliminación de objetos de una colección. Por ejemplo, en la imagen de la derecha, hay 5-2 manzanas—significando 5 manzanas con 2 quitadas, con lo cual hay un total de 3 manzanas. Por lo tanto, 5 – 2 = 3. Además de contar frutas, la sustracción también puede representar combinación otras magnitudes físicas y abstractas usando diferentes tipos de objetos: [[números negativos]], [[fracción|fracciones]], números irracionales, [[vector]]es, decimales, funciones, matrices y más.

La sustracción sigue varios patrones importantes. Es [[conmutatividad|anticonmutativa]], lo que significa que el cambio de la orden cambia el signo de la respuesta. No es [[Asociatividad (álgebra)|asociativa]], lo que significa que cuando se restan más de dos números, importa del orden en el que se realiza la resta. Restar a [[0 (número)|0]] no cambia un número. La sustracción también obedece a reglas predecibles relativas a las operaciones relacionadas, tales como la [[Suma|adición]] y la [[multiplicación]]. Todas estas reglas pueden probarse, a partir de la sustracción de números enteros y generalizarlas mediante los [[números reales]] y más allá. Las [[Operación binaria|operaciones binarias]] generales que siguen estos patrones se estudian en el [[álgebra abstracta]].

Realizar sustracciones es una de las tareas numéricas más simples. La sustracción de números muy pequeños es accesible para los niños pequeños. En la [[educación primaria]], los estudiantes se les enseña a restar números en el sistema decimal, comenzando con un solo dígito y progresivamente abordando problemas más difíciles. Las ayudas mecánicas van desde el antiguo [[ábaco]] a la [[computadora]] moderna.

[[Archivo:Line Segment jaredwf.svg|left|]]
Imagine un [[segmento|segmento de recta]] de [[longitud]] "b" con el extremo izquierdo etiquetado a y el extremo derecho etiquetado "c". Partiendo de a, se toma b posiciones a la derecha para llegar a c. Este movimiento hacia la derecha se modela matemáticamente mediante la [[suma|adición]]:

De "c", se toman "b" posiciones a la izquierda para volver a "a". Este movimiento a la izquierda se modela por sustracción:

[[Archivo:Subtraction line segment.svg|left]]

Ahora, un segmento de la línea marcada con los números [[Uno|1]], [[Dos|2]] y [[Tres|3]].
Desde la posición 3, no se toma ningún paso hacia la izquierda para permanecer en el 3, por lo que 3 − 0 = 3. Se necesitan 2 pasos a la izquierda para llegar a la posición 1, por lo que 3 − 2 = 1. Esta imagen es inadecuada para describir lo que sucedería después de pasar 3 pasos a la izquierda de la posición 3. Para representar dicha operación, la línea debe extenderse.

Para restar [[números naturales]] arbitrarios, uno comienza con una línea que contiene cada número natural (0, 1, 2, 3, 4, 5, 6, ...).
Del 3, se toma 3 pasos a la izquierda para llegar a 0, por lo que 3 - 3 = 0.
Pero 3 − 4 todavía es inválido, puesto que una vez más sale de la línea.
Los números naturales no son un contexto útil para la resta.

La solución es considerar la [[línea numérica]] [[número entero|entera]] (..., −3, −2, −1, 0, 1, 2, 3, ...). Del 3, se toma 4 pasos a la izquierda para llegar a −1:

Hay algunos casos donde resta como una [[Operación (matemáticas)|operación]] separada se vuelve problemática. Por ejemplo, 3 - (-2) (es decir, restar -2 de 3) no es inmediatamente obvia desde un punto de vista del [[número natural]] o una vista de línea de números, porque no está claro de inmediato lo que significa mover -2 pasos a la izquierda o para quitar -2 manzanas. Una solución es ver a la resta como la suma de números con signo. Un signo menos extra simplemente denota [[Opuesto|inversión aditiva]]. Entonces tenemos 3 - (-2) = 3 + 2 = 5. Esto también ayuda a mantener el [[Anillo (matemática)|anillo]] de los enteros "simple" al evitar la introducción de "nuevos" operadores como la resta. Por lo general un anillo solo tiene dos operaciones definidas en el mismo; en el caso de los números enteros, éstos son la suma y la multiplicación. Un anillo ya tiene el concepto de inversiones aditivas, pero no tiene ninguna noción de una operación de sustracción separada, así que el uso de la suma como la resta firmada nos permite aplicar los axiomas de anillo para la resta sin necesidad de demostrar nada.

Hay varios algoritmos para la resta, y difieren en su idoneidad para diversas aplicaciones. Para el cálculo a mano, se adaptan un número de métodos; por ejemplo, al hacer el cambio, no se realiza la resta real, sino más bien sigue subiendo el cambio de cuentas.

Para cálculo en máquina, se prefiere el [[método de complementos]], por lo que la resta se sustituye por una adición en una aritmética modular.

Los métodos utilizados para enseñar la resta para la [[escuela primaria]] varían de país en país, y dentro de un país, están de moda diferentes métodos en diferentes momentos.
Algunas escuelas europeas emplean un método de sustracción llamado método austriaco, también conocido como el método de adiciones. En este método, no hay préstamo. En cambio, existen muletas (marcas para ayudar a la memoria), que varían de acuerdo al país.

Este método separa la sustracción como un proceso de sustracciones de un dígito por valor de posición. A partir de un dígito menos significativo, una sustracción de sustraendo:
desde el minuendo
donde cada "s" y "m" es un dígito, procediendo a escribir
abajo "m" − "s", "m" − "s", y así sucesivamente, siempre y cuando "s" no exceda "m". En caso contrario, "m" se incrementa en 10 y algunos otros dígitos se modifica para corregir de este aumento. El método americano lo corrige intentando disminuir el dígito minuendo "m" por uno (o continuar el préstamo hacia la izquierda hasta que no sea un dígito distinto de cero desde el que presta). El método europeo corrige incrementado el dígito sustraendo "s" por uno.

Ejemplo: 704 − 512. 

El minuendo es 704, el sustraendo es 512. Los dígitos del minuendo son "m" = 7, "m" = 0
y "m" = 4. Los dígitos sustraendo son "s" = 5, "s" = 1 y "s" = 2. Comenzando en el lugar de las unidades, 4 es no menos de 2 por lo que se escribe 2 la diferencia en el lugar del resultado. En el lugar de las decenas, 0 es menor que 1, por lo que el 0 se incrementa en 10, y la diferencia con 1, que es 9, se escribe en lugar de las decenas. El método americano corrige el aumento de diez reduciendo el dígito en el lugar de la centena del minuendo en uno. Es decir, el 7 está tachado y se sustituye por un 6. Entonces, la resta procede en el lugar de las centenas, donde 6 no es inferior a 5, lo que la diferencia se reduce en el lugar del resultado de cien. Ahora hemos terminado, el resultado es 192.

El método austriaco no reduce la 7 a 6. Más bien aumenta el dígito de las centenas del sustraendo en uno. Se hace una pequeña marca cerca o por debajo de esta cifra (dependiendo de la escuela). A continuación, la restas procede por preguntar qué número cuando aumenta en 1, y 5, se añade a la misma, hace 7. La respuesta es 1, y se anota el resultado en el lugar de las centenas.

Hay una sutileza adicional en que el estudiante siempre emplea una tabla de sustracción mental en el método americano. Muchas veces, el método austriaco alienta al estudiante a usar mentalmente la tabla de sumar a la inversa. En el ejemplo anterior, en lugar de la adición de 1 a 5, consiguiendo 6, y resta este desde el 7, el estudiante se le pide que considere qué número, cuando aumenta en 1, y 5, se añade al mismo, haciendo 7.

Ejemplo:

Ejemplo:

En este método, cada dígito del sustraendo se sustrae del dígito por encima de él comenzando de derecha a izquierda. Si el número superior es demasiado pequeño para restar el número inferior del mismo, se le suma 10 al mismo; este 10 es 'prestado' desde el dígito superior hacia la izquierda, lo que se resta 1 de. Luego se pasa a restar el siguiente dígito y el préstamo como sea necesario, hasta que se haya restado cada dígito.
Ejemplo:
Una variante del método americano, donde todos los préstamos se realizan antes de que toda resta.

Ejemplo:

El método de las diferencias parciales se diferencia de otros métodos de sustracción verticales porque ningún préstamo o o acarreo se realiza. En su lugar, se usan unos lugares más o signos de menos en función de si el minuendo es mayor o menor que el sustraendo. La suma de las diferencias parciales es la diferencia total.

Ejemplo:

En lugar de encontrar diferencia dígito por dígito, puede contar los números entre el sustraendo y el minuendo.

Ejemplo:

1234 − 567 = puede ser encontrada en los siguientes pasos:
Se suma el valor de cada paso para obtener la diferencia total: 3 + 30 + 400 + 234 = 667.

Otro método que es útil para el cálculo mental es dividir la resta en pequeños pasos.

Ejemplo:

1234 − 567 = puede ser resuelta de la siguiente manera:

El mismo método de cambio se basa en el hecho de que sumar o restar el mismo número del minuendo y sustraendo no cambia la respuesta. Se añade la cantidad necesaria para obtener ceros en el sustraendo.

Ejemplo:

«1234 − 567 =» puede ser resuelta de la siguiente manera:

Al restar dos números con unidades de medida, tales como kilogramos o libras, deben tener la misma unidad. En la mayoría de casos, la diferencia tendrá la misma unidad que los números originales.

Una excepción es cuando se restan dos números con [[porcentaje]] como unidad. En este caso, la diferencia tendrá [[punto porcentual|puntos porcentuales]] como unidad; la diferencia es que los porcentajes deben ser positivos, mientras que los puntos porcentuales pueden ser negativos.


[[Categoría:Álgebra]]
[[Categoría:Operaciones básicas de la aritmética]]

</doc>
<doc id="11548" url="https://es.wikipedia.org/wiki?curid=11548" title="Tegucigalpa">
Tegucigalpa

Tegucigalpa, oficialmente Tegucigalpa, Municipio del Distrito Central y abreviado como , es la capital y sede de gobierno de la República de Honduras, junto a su ciudad gemela Comayagüela, según los Artículos 8 y 295 de la actual Constitución de Honduras.

Aunque ya desde 1536 se le conocía al pequeño poblado a las orillas de la cuenca del río Choluteca (hoy en día el Centro Histórico) por el peculiar nombre de "", es con la llegada de los españoles a la región en busca de minerales que se reconoce el 29 de septiembre de 1578 como el día que marca su fundación bajo el nombre de "Real de Minas de San Miguel de Tegucigalpa". Tres siglos después, el 30 de octubre de 1880 se convierte en la capital del país, durante la presidencia de Marco Aurelio Soto.

Durante la corta existencia de la Constitución Política de la República Federal de Centro América, entre 1824 y 1839, Tegucigalpa fue declarada un distrito federal y capital de los entonces unidos en una sola nación: los estados de El Salvador, Guatemala y Honduras. Después de este fallido intento de preservar una república centroamericana, Honduras regresa a ser un país individual e independiente y el 30 de enero de 1937, se reforma el Artículo 179 de la Constitución de Honduras de 1936 bajo el Decreto No. 53 y se establece a Tegucigalpa y Comayagüela como el Distrito Central. El 09 de diciembre del mismo año se ratifica bajo el Decreto No. 2.

El Distrito Central se encuentra en la región montañosa sur central de Honduras en el departamento de Francisco Morazán, del cual es también la cabecera departamental. El área metropolitana de Tegucigalpa y Comayagüela se encuentra en un valle, rodeado por montañas y ambas, siendo ciudades gemelas, están geológicamente separadas por la cuenca del río Choluteca que les atraviesa. El Distrito Central es el municipio más grande y más poblado de Francisco Morazán y el decimocuarto más grande de Honduras. Tegucigalpa y Comayagüela, juntas, es la ciudad más grande y más poblada de Honduras.

La capital es el centro político y administrativo del país donde se ubican 23 embajadas y 16 consulados representando diplomática y consularmente a 39 países de alrededor del mundo. Es la sede de la mayoría de las agencias públicas y empresas estatales, entre ellas, la ENEE y Hondutel, las compañías nacionales de energía y telecomunicaciones, respectivamente. Es también el hogar de la selección nacional de fútbol y del plantel principal y rectoría de la Universidad Nacional Autónoma de Honduras (UNAH), la máxima casa de estudios del país. El aeropuerto internacional, Toncontín, ha adquirido fama e infamia mundial por su pista de aterrizaje extremadamente corta para un aeropuerto de categoría internacional lo cual obliga a los aviadores a emprender maniobras algo irregulares durante el despegue y aterrizaje para evadir las montañas aledañas.

La Alcaldía Municipal del Distrito Central (AMDC) es la autoridad gubernamental de la ciudad y municipio, encabezada por un alcalde y 10 regidores quienes forman la Corporación Municipal, él órgano ejecutivo-legislativo del municipio. Siendo cabecera departamental, es sede del gobernador político departamental de Francisco Morazán. Para 2013, la Alcaldía aprobó un presupuesto de más de tres mil millones de lempiras (US$153.5 millones), y acumuló una deuda arriba de los mil millones de lempiras (US$50 millones), en parte para financiar los proyectos de infraestructura que está emprendiendo la presente administración municipal.

La infraestructura capitalina no se ha mantenido al ritmo de su explosión demográfica. La falta de planificación adecuada, la urbanización densa y desordenada sumados con fenómenos socioeconómicos como la pobreza y la delincuencia, son azotes de la vida cotidiana. Las principales vías de circulación son el escenario de embotellamientos ya que la presente red vial no se da abasto con los más de 400 mil vehículos que circulan por ellas diariamente. Tanto el gobierno nacional como el municipal han desarrollado proyectos para incrementar la infraestructura y aliviar la pobreza en la ciudad.

La mayoría de las fuentes sugieren que el origen y significado del vocablo "Tegucigalpa" deriva de la lengua náhuatl. Su significado exacto está abierto a diferentes interpretaciones, pero la versión más difundida entre la creencia popular es que deriva del vocablo nahua "Taguz-galpa" en el cual significa "cerros de plata". Aun así, entre historiadores como el hondureño Jesús Aguilar Paz, dicha interpretación es incierta ya que los pobladores aborígenas ignoraban la presencia de yacimientos minerales en la región. Se ha perdido en la historia quién o cuándo se determinó lo de "cerros de plata", una teoría es que fueron los españoles, y no los nativos, quienes le llamaron así a la región tras el descubrimiento de sus riquezas minerales.

El polígrafo mexicano Antonio Peñafiel, en su libro "Nomenclatura geográfica de México" (1897), define el vocablo "Tegucigalpa" como una corrupción de "Tecutli-cal-pa" que significa "[señor] en los palacios reales". Otra creencia entre historiadores mexicanos como José Ignacio Dávila Garibi y Alfredo Barrera Vásquez, contempla que "Tegucigalpa" es del vocablo nahua "Tecuztlicallipan" que se traduce como "lugar de residencia de los nobles", o posiblemente del vocablo "Tecuhtzincalpan" que significa "lugar sobre la casa del amado señor" o "cerro de los sabios".

El filólogo hondureño Alberto de Jesús Membreño, en su libro "Nombres Geográficos Indígenas de la República de Honduras" (1901) (republicado en 1994 como “Toponimias indígenas de Centroamérica”), descarta por completo el tradicional "cerros de plata" y argumenta que "Tegucigalpa" deriva del vocablo nahua "Teguycegalpa" que significa "en las casas de las piedras puntiagudas". Membreño defiende su interpretacíón haciendo apunte de que "Taguzgalpa" era el nombre antiguo de la zona oriental de Honduras y cuyo vocablo significa "en las casas de la tierra amarilla".

El lingüista americanista austríaco, Rodolfo R. Schuller, propone que el vocablo "Tegucigalpa" significa "lugar donde está la casa de la aurora", mientras que el investigador guatemalteco Flavio Rodas Noriega, promovió una discusión sobre el origen etimológico de "Tegucigalpa" y propuso que el término deriva de "Totogalpa", lo que es una referencia a "Tototi", vocablo nahua que significa "pájaro" y/o a "toncontín" que es otro término nahua cuyo significado es "baile de los indios mexicanos". Por otra parte, el escritor hondureño Rafael Heliodoro Valle, escribió que el nombre es "Teguiazkalpa", cuya etimología significa "la región de los cerros de los venerables ancianos".

La autora e historiadora hondureña Leticia de Oyuela, en su libro “Historia Mínima de Tegucigalpa” (1989), contempla la idea de que la palabra "Tegucigalpa" deriva de otra lengua en el cual significa "piedras pintadas". La antropóloga hondureña Gloria Lara Pinto, en su colaboración titulada "Dicotomía de una ciudad: Las raíces indígenas de Tegucigalpa y Comayagüela" (2011) para la Revista Paradigma de la Universidad Pedagógica Nacional Francisco Morazán, propone que es una derivación de "Teguzigalpa" o "Tecuzincalpan" y significa "en la tierra del pequeño señor". El historiador hondureño Mario Felipe Martínez Castillo, en su libro de bolsillo "Lecturas de la capital de Honduras" (2012), hace hincapié de que "Tegucigalpa" no puede significar "cerros de plata" por las razones ya indagadas por previos investigadores y por lo cual sugiere que viene de la lengua lenca y significa "lugar donde se reúnen los señores".

En sus inicios fue poblada por un grupo de españoles que buscaban vetas de plata en el lugar cerca de 1560, posteriormente con el crecimiento del poblado minero se le conoció con el nombre de "Real Villa de San Miguel de Tegucigalpa de Heredia" el 29 de septiembre de 1578 sobre un antiguo poblado indígena existente. En esa época el área de Tegucigalpa era un centro de actividad minera donde se extraía especialmente plata y oro.

El primer alcalde de Tegucigalpa, Juan de la Cueva, nunca se imaginó que aquella encantadora y pintoresca ciudad, se convertiría años más tarde en la zona más importante de Honduras, funcionando las principales oficinas del Estado y sector privado.

Fue fundada en 1578, como centro minero, y de la Cueva fue nombrado alcalde en 1579. La población fue denominada "Real Minas de Tegucigalpa", obteniendo el título de Villa de San Miguel de Heredia.

Durante todo el período colonial la villa tuvo un carácter minero, extrayéndose minerales desde el cerro El Picacho y en la zona montañosa de San Juancito. Al devenir la independencia del país la capitalidad de la República de Honduras pasó de Tegucigalpa a Comayagua y viceversa en varias ocasiones, hasta que en 1880 quedó definitivamente establecida en Tegucigalpa.

En 1817 se inicia, por iniciativa del alcalde Narciso Mallol, la construcción de un puente sobre el río Choluteca, de mampostería en siete arcos. La obra, terminada cuatro años más tarde, unió a Tegucigalpa con la vecina ciudad de Comayagüela, sobre la margen opuesta del río. Hoy se la conoce, popularmente, como el "Puente Mallol".

En 1821 fue elevada al rango de ciudad. En 1824, el primer congreso de la República de Honduras decretó que Tegucigalpa y Comayagua, las dos ciudades principales del país, se alternaran como capital del Estado, hasta que el 30 de octubre de 1880 se trasladó la sede del Gobierno definitivamente a la ciudad de Tegucigalpa como capital del Estado, se decretó que residirán en ella autoridades civiles, excepto la Corte Suprema de Justicia que residirá en Comayagua, trasladando de inmediato las oficinas dependientes del Gobierno Supremo.

En el año 1847 se funda la primera universidad en el país, con el nombre de "La Sociedad del Genio Emprendedor y del Buen Gusto", siendo su primer rector el sacerdote José Trinidad Reyes.

En 1875 durante la presidencia del Capitán general José María Medina se ordenó la construcción de un nuevo Cementerio General de Tegucigalpa ubicándolo en Comayagüela y terminado en 1877, inaugurado durante la presidencia de Marco Aurelio Soto, en marzo de 1995 el Congreso Nacional decretó al Cementerio General como "Patrimonio Cultural Nacional" dejándose de vender nuevos lotes y ordenándose su protección y cuidado. 

Desde 1898 se dispuso que Tegucigalpa y Comayagüela, las dos ciudades vecinas, a ambas orillas del Choluteca, formasen la capital, pero manteniendo nombres separados, con dos gobiernos municipales. Contaban, en aquel entonces, con unos 40.000 habitantes y el Distrito Central, incluyendo poblaciones circunvecinas, reunía más de 50.000 almas.

Tegucigalpa ha sido la cuna de ilustres patriotas y estadistas hondureños, como Dionisio de Herrera, Francisco Morazán, José Trinidad Cabañas, José Trinidad Reyes, General José Santos Guardiola, Doctor Marco Aurelio Soto, entre otros.

Tegucigalpa ha crecido en los últimos 50 años, pero se ha convertido en una ciudad desorganizada debido a la falta de planificación de la misma. La migración del campo hacia la ciudad ha venido a incrementar la población capitalina, especialmente en los terrenos aledaños ubicados en las laderas de los numerosos cerros, muchos de ellos, carentes de urbanización.

La ciudad de Tegucigalpa, se encuentra en constante crecimiento. En estos momentos los polos de desarrollo residencial apuntan hacia el sur de la ciudad, desde el aeropuerto Toncontín hasta la zona de la represa Los Laureles y como ciudades dormitorios, tenemos en la zona noreste, a los municipios de Santa Lucía y Valle de Ángeles.

El 30 de octubre de 1998 la ciudad sufrió daños importantes tras el paso del huracán Mitch, que destruyó una parte de Comayagüela y los lugares bordeados por el río Grande o Choluteca. El huracán se mantuvo sobre el territorio hondureño por cinco días lo que ocasionó que la tierra no pudiera absorber tanta lluvia y aunado a la deforestación, provocara graves inundaciones en todo el país, principalmente en Tegucigalpa.

La crecida de los afluentes del río Grande o Choluteca hicieron que este rebasará la altura del puente Juan Ramón Molina, el cual fue arrastrado por la corriente y sustituido rápidamente por un puente Bailey.

Las lluvias también provocaron deslizamientos de tierra en el sector del cerro El Berrinche. Estos deslizamientos arrastraron la mayor parte de la colonia Soto, cuyos escombros cayeron sobre la cuenca del río haciendo que se formara un dique a la altura de dicha colonia, este dique estancó las aguas del río Grande o Choluteca y ocasionó la inundación en las partes bajas de Comayagüela destruyendo los viejos establecimientos ubicados a inmediaciones de la Calle Real. En otros sectores la corriente derrumbó colinas, cerros y laderas de montañas, llevándose consigo barrios enteros, edificios, parques, automóviles, etc. Las áreas mayormente afectadas fueron las situadas cerca de ríos.

Actualmente Tegucigalpa ha estado pasando por un notable crecimiento en varios y muy importantes aspectos.

El centro histórico de Tegucigalpa conserva algunos interesantes exponentes de la arquitectura colonial de los siglos XVIII, XIX, los edificios religiosos más importantes son:



Entre algunas edificaciones de principios del XX, tenemos:


Según los resultados del Censo de Población y de Vivienda del 2001 del Instituto Nacional de Estadísticas (INE), la población del Distrito Central, que comprende las ciudades de Tegucigalpa y Comayagüela, era de 906.129 habitantes. En 2010 la población del Distrito Central contaba 1.126.534 habitantes de acuerdo con las proyecciones del INE.

Tegucigalpa se encuentra en una cadena de montañas a alturas de 935 metros (3.068 pies) en sus puntos más bajos y 1.463 metros (4.800 pies) en su nivel más alto en áreas suburbanas. Al igual que la mayoría de las tierras altas del interior de Honduras, la mayoría de la superficie actual de Tegucigalpa fue ocupada por bosques abiertos. El área que rodea la ciudad sigue siendo el apoyo a los bosques abiertos bosque de pinos mezclados con algunos de roble, matorral y claros de hierba, así como la aguja de hoja perenne de hojas y bosques caducifolios de hoja ancha.

Tegucigalpa limita al norte con los municipios de Cedros y Talanga, al sur con los municipios de Maraita, San Buenaventura, Santa Ana y Lepaterique, al este con los municipios de Santa Lucía, San Antonio de Oriente, Valle de Ángeles y San Juan de Flores y al oeste con los municipios de Ojojona, Lepaterique, Lamaní y San Antonio de Flores.

Tegucigalpa, junto con Comayagüela, constituyen la capital de Honduras. El río Choluteca, que cruza la ciudad de norte a sur, separa físicamente de Tegucigalpa y Comayagüela, mientras Tegucigalpa se encuentra a la margen derecha del río Grande o Choluteca, Comayagüela está en el sector occidental de la ciudad y próxima al aeropuerto. Ambas ciudades se localizan en el municipio del Distrito Central, sede constitucional del Gobierno de la República de Honduras y de la Arquidiócesis de Tegucigalpa.
La ciudad se compone de suaves colinas, y el anillo de montañas que rodean la ciudad tiende a atrapar la contaminación.
Hay una reserva conocida como "Embalse Los Laureles", al oeste de la ciudad ofreciendo un 30 por ciento del suministro de agua de la ciudad, así como una planta de tratamiento de aguas al sur de la ciudad alrededor de 7,3 kilómetros (4,5 millas) del aeropuerto, parte del embalse de la Concepción a solo 6 km (3,7 millas) al suroeste de la planta de agua.

Tegucigalpa es la ciudad que cuenta el mayor Índice de desarrollo humano de Honduras, el cual es de 0.859, muy superior al de San Pedro Sula (0.720), aunque se mantiene menor que el resto de capitales centroamericanas superando únicamente a Managua, Nicaragua.

Al igual que gran parte del centro de Honduras, la ciudad tiene un clima tropical, aunque templado por la altitud, lo que significa menos húmedo que los valles más bajos y las regiones costeras. Cuenta con dos temporadas, la temporada seca y fría que comienza en noviembre y finaliza en marzo y la temporada lluviosa y cálida que inicia en abril y finaliza en octubre.

El promedio de horas de sol por mes durante el año es 211,2 y el promedio de días lluviosos por mes es de 8,9. El promedio de horas de sol durante la estación seca es de 228 por mes, mientras que 182,5 milímetros (7,19 pulgadas) es el promedio de precipitación mensual durante la estación húmeda. Los meses más lluviosos de la temporada de lluvias es de mayo-junio y septiembre-octubre, con un promedio 16.2 días de lluvia durante esos períodos.

La contaminación es uno de los principales problemas que afectan a la ciudad, desde ya algunas décadas. Durante algunos meses del año la ciudad se ve cubierta por una extensa capa de smog, el cual puede ser producido debido a la quema de desechos tóxicos o bosques cercanos a la ciudad, así como el humo expulsado por la gran cantidad de vehículos que circulan por la metrópoli. Aunque también puede ser causada por la combustión de carbón, madera o biomasa.

En mayo de 2014, un estudio reveló que Tegucigalpa es la ciudad con el aire más contaminado en Centroamérica, y una de las capitales más contaminadas de Latinoamérica (junto a Ciudad de México, Lima, Buenos Aires, Bogotá, Santiago de Chile y Ciudad de Guatemala entre otras). La contaminación urbana en Tegucigalpa provoca también un declive económico, ya que anualmente el país sufre pérdidas de 913 millones de lempiras.

Como capital de Honduras, como cabecera departamental y como municipio, el Distrito Central es la sede de tres gobiernos: el gobierno nacional, el gobierno departamental y el gobierno municipal. Antes de 1991, el gobierno central ejercía mayor jurisdicción sobre la ejecución del manejo municipal en todo el país, lo cual causaba una representación admistrativa dispareja y una distribución inadecuada de recursos y de gobernabilidad. Como resultado, a finales de 1990, bajo el Decreto No. 134-90, el Congreso Nacional de Honduras aprobó la Ley de Municipalidades, dándole una definición más clara a las instituciones municipales y departamentales, sus representantes y sus funciones para así darle autonomía a los gobiernos locales y descentralizarlos del gobierno nacional.

Aunque autónomo, el Distrito Central es influenciado por el gobierno nacional siendo que el territorio es la sede del gobierno de la república. Cambios importantes en la estructura política del municipio y el financiamiento de grandes proyectos deben ser presentados ante el Despacho Presidencial y aprobados por el Congreso Nacional antes de ser ejecutados por el gobierno local.

El Municipio del Distrito Central es constitucionalmente la capital de Honduras mientras que Tegucigalpa y Comayagüela son dos entidades dentro del municipio, que en su tiempo fueron ciudades y municipios propios hasta ser incorporados en un solo municipio y una sola ciudad, por la necesidad de poder asentar oficinas gubernamentales de ambos lados de la cuenca del río Choluteca.

La actual Constitución de Honduras, en su Título I, Capítulo I, Artículo 8 declara:
Además, en su Título V, Capítulo XI, Artículo 295 declara:

Aun así, popularmente se indentifica a Tegucigalpa como la capital, siendo que fue Tegucigalpa quien ocupara dicho título antes de compartirlo con Comayagüela. Aunque legal y políticamente hablando son una sola ciudad, tradicionalmente, se les sigue identificando como dos ciudades hermanas o gemelas, dado a la historia detrás de sus inicios.

Hoy en día, es correcto decir que "Tegucigalpa" es la capital de Honduras, también es correcto decir que "Tegucigalpa y Comayagüela", juntas, son la capital de Honduras; y por último, a partir de su formación el 30 de enero de 1937 bajo el Decreto No. 53 del reformado Artículo 179 de la Constitución de Honduras de 1936 es correcto decir que el "Distrito Central" es la capital.

Cabe resaltar que en Honduras los municipios se definen como divisiones administrativas de los departamentos y no necesáriamente como una sola ciudad, por lo cual un municipio puede contener más de una ciudad o poblado, incluyendo su cabecera municipal que en el caso de Honduras tiende a ser la ciudad homónima y más poblada del municipio; aunque para propósitos administrativos y legales, la alcaldía municipal es la autoridad dentro de la ciudad cabecera y el resto del municipio.

Un ejemplo, el Municipio del Distrito Central es el municipio más poblado de Honduras y el área metropolitana de Tegucigalpa y Comayagüela forman la ciudad más grande y más poblada del país, aun así, el Distrito Central no es el municipio más grande de Honduras cuando en términos de superficie administrativa se habla (territorio). Aunque es el municipio más grande de Francisco Morazán, es únicamente el decimocuarto más grande de Honduras, habiendo 13 municipios más grandes en términos de área administrativa pero no en población. Los dos municipios más grandes de Honduras son Puerto Lempira y Catacamas en los departamentos de Gracias a Dios y Olancho, respectivamente.

Otro ejemplo se observa en la ciudad de La Ceiba, cabecera municipal del municipio homónimo, uno de los ocho municipios del Departamento de Atlántida. La Ceiba es la ciudad más grande de Atlántida y la tercera ciudad más grande de Honduras, en términos de población y área urbana, pero el Municipio de La Ceiba es solo el segundo municipio más grande de Atlántida, siendo el Municipio de Tela el más grande de dicho departamento, aunque menos poblado, por lo cual la ciudad de Tela no se considera la ciudad más grande de Atlántida.

Además del urbe de Tegucigalpa y Comayagüela, el Distrito Central también cuenta con 41 aldeas y 293 caseríos, éstos son pequeños poblados en las zonas rurales del municipio cuyas poblaciones varían entre unas cuantas docenas en los caseríos más pequeños hasta unos cuantos miles, en las aldeas más pobladas. Para propósitos administrativos, la ley municipal permite asignarles alcaldes auxiliares y/o patronatos para actuar como representantes locales.

El Distrito Central es el centro político y administrativo de Honduras. Es la sede de los tres poderes del gobierno nacional y sus dependencias, incluyendo de la mayoría de las agencias públicas y empresas estatales. La capital es sede de todas las misiones diplomáticas que mantienen presencia en Honduras, con la excepción de Filipinas, cuyo consulado en el país se encuentra en San Pedro Sula. Actualmente se ubican 23 embajadas y 16 consulados en Tegucigalpa, representando a todos los países centroamericanos, la mayoría de los sudamericanos, 14 países europeos incluyendo Rusia, tres países caribeños, dos países asiáticos, Canadá, Estados Unidos, México y Sudáfrica.

La residencia oficial y despacho del Ejecutivo, la Casa Presidencial, se encuentra sobre el Bulevar Juan Pablo II en la Colonia Los Profesionales, el Congreso Nacional se encuentra en el Centro Histórico de Tegucigalpa sobre la Calle Bolívar del Barrio La Merced y la Corte Suprema de Justicia se encuentra en el Centro Cívico Gubernamental localizado a un costado del distribuidor vial del Bulevar Fuerzas Armadas y el Bulevar Kuwait, al sur del Centro Comercial Mall las Cascadas. La capital es también la sede de la Policía Nacional, de las Fuerzas Armadas y de la mayoría de las instituciones financieras del país, tanto públicas como privadas.

El Distrito Central es también la sede del gobierno del departamento de Francisco Morazán encabezado por el gobernador político departamental. El gobernador es nombrado por el presidente de la república y a su vez éste primero es el representante del ejecutivo nacional a nivel departamental. Históricamente, el gobernador político departamental ha tenido un papel menos visible en el marco político y administrativo del país a nivel departamental y municipal al grado que sus incumbentes han declarado que el gobernador necesita una autonomía y autoridad más evidente así como sucede en otros países como México y Estados Unidos. El gobernador político actual es Rigoberto Herrera del Partido Nacional durante el periodo de 2010-2014 y devenga un sueldo base mensual de 35,000 lempiras (US$1,725).

A nivel nacional, el departamento de Francisco Morazán está representado por 23 de los 128 diputados que constituyen el Congreso Nacional. Así mismo, el Distrito Central como el resto de los municipios, es miembro de la Asociación de Municipios de Honduras (AMHON), quien observa los intereses municipales dentro del marco civil y político del país y actúa como enlace a nivel nacional.

El gobierno local toma forma dentro de un sistema donde los poderes del ejecutivo y el legislativo son representativo (electos por voto popular) y compartido (alcalde y regidores), regidos por la Ley de Municipalidades que entró en vigor el 1.º de enero de 1991. La Alcaldía Municipal del Distrito Central (AMDC) es la autoridad gubernamental de la ciudad y municipio cuya sede de gobierno se encuentra en el Centro Histórico de Tegucigalpa frente al Parque Central. Como lo establece la Ley de Municipalidades, la AMDC está estructurada en una Corporación Municipal, cual es el órgano deliberativo de la municipalidad, electa por el pueblo y máxima autoridad dentro del término municipal.

La Corporación Municipal está formada por un alcalde quien actúa como jefe ejecutivo, administrador general y representante legal del municipio y un vice alcalde quien asume el puesto del alcande al ser requerido y supervisa las funciones dentro de la AMDC según le indique el alcalde. El alcalde y vice alcalde devengan un sueldo base mensual de L.61,000 (US$3.000) y L. 55,000 (US$2.700), respectivamente.

La Corporación Municipal también la integran diez regidores quienes constituyen el poder legislativo y deliberativo dentro del municipio y juntos con el alcalde ejecutan sus obligaciones delegadas por la Ley de Municipalidades, incluyendo la administración del municipio, sus normas presupuestarias y la legislación de leyes y ordenanzas a nivel municipal. Los regidores devengan un sueldo base mensual de L.55,000 (US$2,700).

Un gerente general, nombrado por el alcalde, actúa como jefe de auditoría encargado del manejo, recaudación y repartición de fondos de la comuna municipal. Una secretaria municipal, también nombrada por el alcalde, actúa como oficiadora legal encargada del registro oficial de todos los procedimientos legales. La Corporación Municipal también cuenta con un Consejo de Desarrollo Municipal el cual actúa como gabinete de asesoría en todas las áreas de enfoque de la ciudad, como el desarrollo social, la seguridad, servicios públicos, etc.

El actual alcalde del Distrito Central es Nasry Juan Asfura Zablahz quien pertenece al Partido Nacional (PNH), después de ganar la elección en noviembre de 2013. Asfura es la octava persona electa en ocupar el puesto de Alcalde del Distrito Central desde que las elecciones locales fueron restablecidas en 1986. Antes de 1986, el gobierno local del Distrito Central, conocido como Consejo Metropolitano, era designado por el Presidente de la República. Ésta es la novena elección desde entonces.

De los diez regidores actuales, siete son hombres y tres son mujeres. Cinco pertenecen al Partido Nacional mientras que otros dos pertenecen al Partido Libertad y Refundación (Libre), dos pertenecen al Partido Liberal (PLH) y uno pertenece al Partido Anti Corrupción (PAC).

Tanto el alcalde y como los regidores son electos a un término de cuatro años por los votantes del Distrito Central. La destitución del alcalde o cualquier regidor por cualquier causa queda reservada a la Secretaría del Interior y Población (antes Secretaría de Gobernación y Justicia).

El Alcalde de Tegucigalpa es el Ingeniero Nasry Asfura, fue electo para administrar el gobierno de la capital en el periodo 2014-2018 (actual).

La presente administración cuenta con la siguiente organización:

El presupuesto de la alcaldía para el año 2016 es de 4,200 millones de lempiras. El PIB per cápita es de ciento cincuenta mil Lempiras.

La Policía Nacional de Honduras a través de la Policía Nacional Preventiva es la autoridad uniformada encargada de preservar el orden público y el cumplimiento de la ley. La Policía Nacional mantiene su sede en el Distrito Central en la Colonia Casamata. La Jefatura Metropolitana No. 1 es la designación al departamento de policía del municipio. Éste cuenta con siete distritos policiales dentro de la zona metropolitana.

Para 2011, la Secretaría de Seguridad designó dos mil 162 millones de Lempiras (US$ 114 millones de dólares) a seguridad pública e investigación criminal en el Distrito Central.

Según lo establecido por la Ley de Policía y Convivencia Social, los municipios pueden financiar sus propias policías municipales y el Distrito Central opera en la actualidad una Policía Municipal compuesta por aproximadamente 160 oficiales, algunos de ellos asignados a las zonas turísticas de la ciudad. Existe también la Policía de Tránsito, dependencia de la Policía Nacional, encargada de observar el cumplimiento de las leyes de la vía pública. El Departamento Municipal de Justicia a través del Juzgado de Policía Municipal procesa las infracciones locales.

El Ministerio Público de Honduras, con sede en el Distrito Central y jurisdicción a nivel nacional a través de sus fiscalías regionales, está a cargo de la investigación de los delitos y el ejercicio de la acción penal pública representando a la sociedad hondureña. La Procuraduría General de la República, también con la misma sede domiciliar, ejerce la representación legal del Estado en defensa de sus intereses.

Tegucigalpa se caracteriza por su variado e interesante carácter cultural. La ciudad posee un gran valor cultural que ha estado atrayendo a muchas personas en las últimas décadas, se caracteriza por su bello estilo colonial y moderno a la vez lo que la hace un sitio muy especial.

La ciudad celebra varias ferias como la Feria del Aniversario de Tegucigalpa el 29 de septiembre esta festividad pretende obtener lo mejor de los capitalinos y es una época del año que siempre llena de mucha satisfacción para reunirse.

También se celebran otras ferias como AGAFAM (Feria de Asociación de Ganaderos y Agricultores de Francisco Morazán), la Feria del Caballo y la Feria del Emprendedor.

En Tegucigalpa encontramos muchos centros culturales, entre ellos destacan:


Tegucigalpa cuenta con algunas bibliotecas, presentes en solo algunas zonas de la capital, quedando la mayor parte de la capital y áreas escolares sin acceso a bibliotecas públicas. En Tegucigalpa se han realizado también varias "ferias del libro".

Además Honduras cuenta con varios museos con diferentes temáticas, entre ellos:


La capital cuenta con un limitado número de bibliotecas, entre ellas se encuentran:

La Biblioteca Nacional de Honduras (1880): La Biblioteca Nacional de Honduras es una biblioteca que contiene más de cuarenta mil volúmenes, concita el sueño de su fundador el doctor Antonio Ramón Vallejo y los sueños de su propiciador, secretario de gobierno de Marco Aurelio Soto, doctor Ramón Rosa. Es una institución de utilidad pública, dependiente de la Secretaría de Cultura, Artes y Deportes, cuya misión es recopilar, catalogar, clasificar, conservar y difundir toda la producción documental publicada en el país y en el extranjero. Se encuentra en la antigua casa donde nació el General Francisco Morazán, esta antigua casa, fue también: "Casa de la Moneda" (1780) y en 1830 sirvió para las reuniones del Congreso Nacional. Entre los años: 1859-1876 sirvió como cuartel y más tarde en 1898 se instaló la Tipografía Nacional; y como información hasta 1926 se dejó de acuñar monedas.

La ciudad de Tegucigalpa cuenta también con la Biblioteca de la Universidad Nacional Autónoma de Honduras para apoyar el desarrollo de la investigación, la docencia y el estudio, proporcionando el acceso a los recursos de información necesarios, propios de la Universidad o ajenos a ella. Los diferentes puntos de servicio atienden a toda la comunidad universitaria y se ofrecen en 10 centros universitarios, cada uno con varias bibliotecas de facultad, Centro de Recursos de Aprendizaje y museos especializados.

Cuenta la capital de Honduras con interesantes museos, entre encontramos los siguientes:

Museo Nacional Villaroy: considerado por su valor arquitectónico como un monumento característico dentro del contexto urbano Tegucigalpa. Su construcción fue realizada entre 1936-1940 por Samuel Salgado de marcada influencia Italiana, dentro de un esquema paladian.

Museo del Hombre Hondureño: ofrece al público visitante tres salas de exhibiciones pictóricas de artistas del pincel hondureño y la Biblioteca especializada en arte Reina Sofía, entre otros. Además funciona el Taller de Restauración Miguel Ángel Gómez, donde se han recuperado más de 400 obras, patrimonio religioso. De carácter privado y a cargo de la Fundación Museo del Hombre Hondureño (FMHH). Uno de los logros más grandes de la fundación es la obtención de la Casa Ramón Rosa, actual sede del centro cultural, donde antes funcionaba la Corte Suprema de Justicia.

Museo Histórico Militar, se encuentra en el edificio del Cuartel San Francisco este museo tiene una selección de artículos personales y fotografías de los ilustres héroes militares y hombres fuertes de Honduras. Así mismo, tiene una sala con armas de fuego antiguas y modernas.
Museo de las Telecomunicaciones que tiene por objetivo resguardar el patrimonio histórico que constituyen los equipos y documentación así como el edificio mismo del Palacio de Telecomunicaciones. 

Museo para la Identidad Nacional (MIN): Es una institución permanente abierta al público, sin fines de lucro al servicio de la sociedad y su desarrollo, que adquiere, conserva, investiga, comunica y exhibe con propósito de estudio, de educación y disfrute, la evidencia material e inmaterial de los pobladores que habitaron y habitan el territorio hondureño a fin de fortalecer la memoria histórica y el sentido de identidad nacional.

Quien no haya tenido oportunidad de visitar el sitio arqueológico de ruinas de Copán, en el Museo de Identidad Nacional encontrará un auditorio que muestra, en una versión tecnológica de avanzada, la principal ciudad de los mayas en Honduras: Copán. El Auditorio del sitio arqueológico de Copán en el MIN permite al visitante tener una experiencia imaginaria y transportarse en espacio y tiempo a la época en que Copán se encontraba en su mayor esplendor.

El Museo del Aíre de Honduras situado en las cercanías del Aeropuerto Internacional Toncontín cuenta con algunos de los aparatos voladores con los que se dio inicio a la Historia de la Aviación en Honduras que es una visión más allá de lo que fueron aquellos tiempos de bonanza. Esta fundación museo cuenta con piezas únicas en el mundo como el avión de caza pilotado por Fernando Soto Henríquez en la Guerra del Fútbol de 1969, que es el último en su tipo de haber salido victorioso en un combate aéreo, además de otros modelos que fueron parte de la historia de la Fuerza Aérea Hondureña, el museo además cuenta con videos, fotografías, maquetas, planos, etc.

Tegucigalpa se caracteriza por sus parques como:





La manera más rápida de trasladarse de un punto a otro en la ciudad, es a través del anillo periférico "Quinto Centenario". Este anillo, cubre el lado este de la ciudad de Tegucigalpa y también está conectada a la carretera nacional, donde están los ramales nacionales hacia el norte del país, (hacia San Pedro Sula), al sur (hacia Nicaragua) y otras salidas hacia pueblos cercanos.

Tegucigalpa está comunicada con el resto del país y el exterior por diversas carreteras pavimentadas. La principal de ellas se dirige hacia el norte del país, otra hacia el sur -conectando con la Carretera Interamericana- y una tercera hacia el este.

La ciudad tiene en construcción el proyecto de transporte público Metrobús Tegucigalpa, iniciado en el año 2010 e inaugurado una etapa en fecha 24 de enero de 2014.

El aeropuerto principal de Tegucigalpa es el Aeropuerto Internacional Toncontín, ubicado en el sur de la ciudad. Este aeropuerto es considerado uno de los más peligrosos del mundo por la cercanía de una sierra y una pista de aterrizaje relativamente corta; durante varios años se ha tratado de sustituirlo por el aeropuerto de Palmerola, en Comayagua, donde actualmente opera una base aérea de los Estados Unidos.

Toncontín ha sido mejorado significativamente por medio de las obras realizadas por la Corporación Aeroportuaria de Tegucigalpa y Interairports, empresa privada contratada por el gobierno para administrar los cuatro aeropuertos internacionales del país. Anteriormente, Toncontín solo contaba con una pista de aterrizaje de 1863 metros de longitud. En 2009 fue ampliada con 300 metros, de las cuales 150 metros de pista útil, 60 metros de franja de seguridad de pista, y 90 metros de área de seguridad nivelado al extremo de la pista. La altitud de la pista es de 1033 msnm.

Toncontín cuenta, además, con servicios de migración, aduana, meteorología y control del tráfico aéreo. 
Es atendido por compañías aéreas internacionales como American Airlines, Avianca, Continental Airlines, Copa Airlines, DELTA y varias líneas aéreas locales, que la conectan con el resto del país, El Salvador y Estados Unidos.

De categoría privada:
De categoría pública:


El centro recreativo y deportivo más amplio en Tegucigalpa es la Villa Olímpica. Es de acceso gratuito, cuenta con un estadio olímpico, parque de béisbol, piscinas, varios gimnasios, canchas de baloncesto, de tenis, amplios aparcamientos para automóviles y áreas verdes para descanso. Se puede acceder fácilmente por el anillo periférico de la ciudad.

Es un estadio destinado para partidos de béisbol, ubicado frente al estadio metropolitano Tiburcio Carias Andino, es el segundo estadio en importancia para este deporte después del ubicado en las instalaciones de la Villa Olímpica de Tegucigalpa. creado en 1951

Tegucigalpa cuenta con muchos centros deportivos en cada colonia, barrio o centro, además con muchos estadios, y complejos deportivos.

Tegucigalpa es sede de los dos clubes más grandes de la Liga Nacional de Fútbol de Honduras: El Club Deportivo Olimpia, y el Club Deportivo Motagua. Entre ambos suman más de 30 títulos de liga. El deportivo Olimpia, es el más popular y el que posee más campeonatos de liga, seguido de cerca de su archirrival Motagua. Ambos equipos han sido campeones de Centroamérica. Además la ciudad cuenta con una complejo de entrenamiento para selecciones juveniles denominado proyecto GOAL que fue financiado por la FIFA y construido en los terrenos de la Universidad Nacional Autónoma de Honduras (UNAH).

1. Sistema Agropecuario 
2. Bosque tropical siempre verde estacional aciculifoliado montano inferior 
3. Bosque tropical siempre verde estacional mixto montano inferior y 
4. Bosque tropical siempre verde estacional latifoliado montano superior. 
Este último está en la parte más elevada que posee el parque.

El bosque seco subtropical está ubicado en la zona norte del parque y es el que tiene menor cantidad de área. La Tigra tiene una gran variedad de flora y fauna, entre la vegetación podemos mencionar especies de árboles como ser: Pino de Ocote, Robles, Encinos, Liquidámbar, Aguacatillos entre otros, también hay diversidad de helechos seis de ellos en peligro de extinción los cuales son protegidos por AMITIGRA.

Entre la fauna hay especies de mamíferos, anfibios, reptiles y aves que son los grupos más comunes y que podemos observar dentro del parque, se sabe que viven animales como: Tigrillos, Guatusas, Venados Cola Blanca, Micos de Noche, Pumas y Yaguaroundis. Aves como Jilgueros, Pavas de Montaña, Quetzales, Gavilanes, Tucanes entre otras más.


Destaca un jaguar, felino más grande de América y que es nativo de Honduras, así como una colección muy completa de venados cola blanca y monos araña.
Con un total de 310 animales, entre los que podemos contar 20 especies diferentes de mamíferos, 23 de aves y 7 de reptiles.

El área total del zoológico es de unas 22 manzanas.

En las cercanías de Tegucigalpa hay muchos pueblos coloniales, entre ellos encontramos:

Tegucigalpa es una ciudad de hotelería y negocios. Hay un amplio abanico de hoteles, entre los más grandes se encuentran los siguientes:



</doc>
<doc id="11549" url="https://es.wikipedia.org/wiki?curid=11549" title="Proyección de Mollweide">
Proyección de Mollweide

La proyección de Mollweide, también conocida como Babinet, es una proyección cartográfica equitativa y pseudocilíndrica, usada generalmente para mapas de la Tierra o del cielo nocturno.

La proyección fue publicada por primera vez por el matemático y astrónomo Karl (o Carl) Brandan Mollweide (1774–1825) de Leipzig en 1805. Fue reinventada y popularizada en 1857 por Jacques Babinet, quien le dio el nombre de proyección homalográfica.

Su propósito es representar la proporción de las áreas con la máxima exactitud posible.

El ecuador tiene el doble de longitud que el eje corto, el meridiano central o tipo, es recto. Los meridianos a 90° son arcos circulares. Los paralelos son rectos pero desigualmente espaciados. La escala es casi verdadera sólo a lo largo de los paralelos estándar de 40:44N y 40:44S, por lo que tiene una mayor representación por la zona ecuatorial.
La proyección de Mollweide es usada para mapas del mundo, especialmente para representar zonas de latitudes bajas.

La proyección transforma latitudes y longitudes en coordenadas "x" e "y" por medio de las siguientes ecuaciones:

donde "θ" es un ángulo auxiliar definido por

y "λ" es la longitud, "λ" es el meridiano central, "φ" es la latitud, y "R" es el radio del globo a ser proyectado. El mapa tiene como área 4π"R", conforme a la superficie de globo generador. La coordenada "x" tiene un rango de [−2"R", 2"R"], y la coordenada "y" tiene un rango de [−"R", "R"].

La ecuación (1) puede ser resuelta con una convergencia rápida (pero lenta cerca de los polos) usando la iteración del Método de Newton–Raphson:

Si "φ" = ±, entonces también "θ" = ±. En ese caso la iteración debe evitarse; de otro modo, podría resultar en división por cero.

Existe una forma cerrada de transformación inversa:

donde "θ" se puede encontrar por la relación

Las transformaciones inversas permiten encontrar la latitud y longitud correspondientes a las coordenadas "x" e "y".




</doc>
<doc id="11551" url="https://es.wikipedia.org/wiki?curid=11551" title="Media geométrica">
Media geométrica

En matemáticas y estadística, la media geométrica de una cantidad arbitraria de números (por decir "n" números) es la raíz n-ésima del producto de todos los números, es recomendada para datos de progresión geométrica, para promediar razones, interés compuesto y números índices.
\sqrt[n]{x_1 \cdot x_2 \cdots x_n} 

Por ejemplo, la media geométrica de 2 y 18 es 
Otro ejemplo, la media de 1, 3 y 9 sería

 \le \frac{x_1+ x_2 +\dots + x_n}{n}</math>
La igualdad sólo se alcanza si formula_3.


Solo es relevante la media geométrica si todos los números son positivos. Como hemos visto, si uno de ellos es 0, entonces el resultado es 0. Si hubiera un número negativo (o una cantidad impar de ellos) entonces la media geométrica sería o bien negativa, o bien inexistente en los números reales.

En muchas ocasiones se utiliza su trasformación en el manejo estadístico de variables con distribución no normal.

La media geométrica es relevante cuando varias cantidades son multiplicadas para producir un total.

Al igual que en una media aritmética pueden introducirse pesos como valores multiplicativos para cada uno de los valores con el fin de ponderar o hacer pesar más en el resultado final ciertos valores, en la media geométrica pueden introducirse pesos como exponentes:
\right)^{\frac{1}{\sum_i{\alpha_i}}}=
Donde las formula_5 son los «pesos».

Una cadena de expendedores de gasolina el año pasado aumentó sus ingresos respecto al año anterior en 21%; y han proyectado que este año van a llegar a un aumento de 28% con respecto al año pasado. ¿Cuánto es el promedio anual del aumento porcentual?

Definitivamente no es (21% + 28%):2 = 24,5%.

El monto de la producción, al final de dos años, es 100(1,21)(1,28)= 154,88. Si en cada año se tuviera una tasa anual de aumento de i% resulta

Entonces


El peso w de una sustancia que tiene pesos hallados por dos balanzas u y v , resulta formula_12





</doc>
<doc id="11556" url="https://es.wikipedia.org/wiki?curid=11556" title="Gerardus Mercator">
Gerardus Mercator

Gerard Kremer, conocido por su nombre latinizado Gerardus Mercator (Rupelmundo, Flandes; 5 de marzo de 1512-Duisburgo, Sacro Imperio Romano Germánico; 2 de diciembre de 1594), también llamado "Mercator" o "Gerardo Mercator", fue un geógrafo, matemático y cartógrafo flamenco, famoso por idear la llamada proyección de Mercator, un sistema de proyección cartográfica conforme, en el que se respetan las formas de los continentes pero no los tamaños. Fue uno de los primeros en utilizar el término «atlas» para designar una colección de mapas.

Nació en Rupelmundo, Flandes. Su nombre era Gerard de Cremere (o Kremer). "Mercator" es la latinización de su nombre, que significa 'mercader'. Recibió educación del humanista Macropedius en Bolduque y en la Universidad Católica de Lovaina. 

En 1534, Mercator se dedicó al estudio de las matemáticas, la astronomía y la geografía bajo la tutela del matemático Gemma Frisius. También aprendió a hacer grabados gracias a la ayuda de Gaspard van der Heyden, grabador y constructor de globos terráqueos (mapas esféricos). A principios del siglo XVI, los cartógrafos, o dibujantes de mapas, empleaban gruesos caracteres góticos que limitaban el espacio disponible para añadir información en los mapas. No obstante, Mercator adoptó un nuevo estilo italiano de escritura cursiva —o letra itálica— que resultó muy útil en la fabricación de globos terráqueos y un tipo de letra más adecuado para los grabados en cobre de los mapas.. Escribió al respecto un libro que fue el primero que trataba sobre este tema (Europa del Norte). Trabajó como grabador con Frisius y van der Heyden en la elaboración de un mapa esférico en 1536.

Su primer trabajo en solitario fue la elaboración de un mapa de Palestina en 1537, después de lo que dedicó tres años a su "Exactissima Flandriae Descriptio" ("La descripción más exacta de Flandes"), el mejor mapa de Flandes confeccionado hasta el momento. 

En 1544 por mostrarse tolerante al protestantismo es acusado de herejía y pasó en prisión siete meses. En 1552, se trasladó a Duisburgo donde abre un taller de cartografía. Trabajó en la elaboración de un mapa de Europa, compuesto por seis paneles, que completó en 1554; también se dedicó a enseñar matemática. Asimismo realizó otros mapas. Fue nombrado cosmógrafo de la corte por el duque Guillermo de Cléveris en 1564. Durante estos años, concibió la idea de una nueva proyección aplicable en los mapas, que utilizó por primera vez en 1569, la cual sería conocida posteriormente como proyección de Mercator; lo novedoso en su propuesta del nuevo sistema de proyección era que las líneas de longitud eran paralelas, lo cual facilitaba la navegación por mar al poderse marcar las direcciones de las brújulas con líneas rectas.

Estimuló a Abraham Ortelius a hacer el primer atlas moderno, "Theatrum Orbis Terrarum" en 1570. Posteriormente Mercator comenzó a elaborar su propio atlas, organizado en varios tomos, el primero de los cuales fue publicado en 1578 y consistía en una versión corregida de los mapas de Ptolomeo, aunque esta edición también incluía algunos errores propios de Mercator. En 1585, se publicaron mapas de Francia, Alemania y Holanda, y en 1588 se agregaron mapas de los Balcanes y Grecia.

En el título de su obra "Atlas sive Cosmographicae meditationes de fabrica mvndi et fabricati figura" ("Atlas, o meditaciones cosmográficas sobre la creación del universo y el universo en tanto creación") es donde aparece por primera vez el término "Atlas" para describir una publicación de ese tipo. Los dos primeros tomos aparecieron en 1594 y el tercero al año siguiente completado por su hijo Rumold.







Mercator falleció sin haber terminado su atlas. Fue su hijo Rumold Mercator, quien concluiría la obra publicando más mapas en 1595.

El Museo Mercator, en Sint-Niklaas, Bélgica, tiene una exposición permanente con trabajos sobre la vida y el legado de Mercator.





</doc>
<doc id="11558" url="https://es.wikipedia.org/wiki?curid=11558" title="Campeonato Mundial de Atletismo">
Campeonato Mundial de Atletismo

El Campeonato Mundial de Atletismo es la máxima competición de atletismo a nivel internacional. Es organizado por la Asociación Internacional de Federaciones de Atletismo (IAAF) desde 1983; las tres primeras ediciones (de 1983 a 1991) se disputaron de forma cuatrienal, pero a partir de entonces, se convirtió en bienal.

Con doce medallas (tres de oro, cuatro de plata y siete de bronce), la jamaicana Merlene Ottey es la atleta con más medallas en los campeonatos del mundo. 

Con once medallas de oro, el jamaicano Usain Bolt es el atleta con mayor número de condecoraciones áureas en la historia de los campeonatos mundiales de atletismo. 

Asimismo, con catorce medallas totales (once de oro, dos de plata y una de bronce), Usain Bolt es el atleta masculino más condecorado en la historia de la competición; superando a Carl Lewis, que consiguió ocho medallas de oro, una de plata y una de bronce.

Con siete medallas de oro individuales: 200 m (cuatro) y 100 m (tres), Usain Bolt es el atleta que ha obtenido más victorias individuales. Con sus dos medallas de oro individuales obtenidas en el Mundial de Pekín 2015, Usain Bolt supera a quienes con seis medallas de oro, Serguei Bubka en salto con pértiga y Michael Johnson en 400 m (cuatro) y 200 m (dos), eran los atletas que habían obtenido más victorias individuales hasta antes de la edición de 2015. 

Las listas de los atletas con más medallas en el Mundial, actualizadas hasta la edición de Pekín 2015, se muestran a continuación:





</doc>
<doc id="11563" url="https://es.wikipedia.org/wiki?curid=11563" title="Aleación">
Aleación

Una aleación es una combinación de propiedades metálicas, que está compuesta de dos o más elementos metálicos sólidos.

Las aleaciones están constituidas por elementos metálicos como Fe (hierro), Al (aluminio), Cu (cobre), Pb (plomo), ejemplos concretos de una amplia gama de metales que se pueden alear. El elemento aleante puede ser no metálico, como: P (fósforo), C (carbono), Si (silicio), S (azufre), As (arsénico). 

Mayormente las aleaciones son consideradas mezclas, al no producirse enlaces estables entre los átomos de los elementos involucrados. Excepcionalmente, algunas aleaciones generan compuestos químicos.

Se clasifican teniendo en cuenta el elemento que se halla en mayor proporción (aleaciones férricas, aleaciones base cobre, etc.). Cuando los aleantes no tienen carácter metálico suelen hallarse en muy pequeña proporción, mientras que si únicamente se mezclan metales, los aleantes pueden aparecer en proporciones similares

Las aleaciones presentan brillo metálico y alta conductividad eléctrica y térmica, aunque usualmente menor que los metales puros. Las propiedades físicas y químicas son, en general, similares a la de los metales, sin embargo las propiedades mecánicas tales como dureza, ductilidad, tenacidad y otras pueden ser muy diferentes, de ahí el interés que despiertan estos materiales.

Las aleaciones no tienen una temperatura de fusión única, dependiendo de la concentración, cada metal puro funde a una temperatura, coexistiendo simultáneamente la fase líquida y fase sólida como se puede apreciar en los diagramas de fase. Hay ciertas concentraciones específicas de cada aleación para las cuales la temperatura de fusión se unifica. Esa concentración y la aleación obtenida reciben el nombre de eutéctica, y presenta un punto de fusión más bajo que los puntos de fusión de los componentes.
Históricamente, la mayoría de las aleaciones se preparaban mezclando los materiales fundidos. Más recientemente, la pulvimetalurgia ha alcanzado gran importancia en la preparación de aleaciones con características especiales. En este proceso, se preparan las aleaciones mezclando los materiales secos en polvo, prensándolos a alta presión y calentándolos después a temperaturas justo por debajo de sus puntos de fusión. El resultado es una aleación sólida y homogénea. Los productos hechos en serie pueden prepararse por esta técnica abaratando mucho su costo. Entre las aleaciones que pueden obtenerse por pulvimetalurgia están los cermets. Estas aleaciones de metal y carbono (carburos), boro (boruros), oxígeno (óxidos), silicio (siliciuros) y nitrógeno (nitruros) combinan las ventajas del compuesto cerámico, estabilidad y resistencia a las temperaturas elevadas y a la oxidación, con las ventajas del metal, ductilidad y resistencia a los golpes. Otra técnica de aleación es la implantación de ion, que ha sido adaptada de los procesos utilizados para fabricar chips de ordenadores o computadoras. Sobre los metales colocados en una cámara de vacío, se disparan haces de iones de carbono, nitrógeno y otros elementos para producir una capa de aleación fina y resistente sobre la superficie del metal. Bombardeando titanio con nitrógeno, por ejemplo, se puede producir una aleación idónea para los implantes de prótesis.

La plata, el oro de 18 quilates y el oro blanco son aleaciones de metales preciosos. La aleación antifricción, el latón, el bronce, el metal Dow, la plata alemana, el bronce de torpedo, el monel, el peltre y la soldadura son aleaciones de metales menos preciosos. Debido a sus impurezas, el aluminio comercial es en realidad una aleación. Las aleaciones de mercurio con otros metales se llaman amalgamas.

Las aleaciones más comunes utilizadas en la industria son:



</doc>
<doc id="11564" url="https://es.wikipedia.org/wiki?curid=11564" title="Acero">
Acero

El término acero sirve comúnmente para denominar, en ingeniería metalúrgica, a una mezcla de hierro con una cantidad de carbono variable entre el 0,03 % y el 2,14 % en masa de su composición, dependiendo del grado. Si la aleación posee una concentración de carbono mayor del 2,14 %, se producen fundiciones que, en oposición al acero, son mucho más frágiles y no es posible forjarlas, sino que tienen que ser moldeadas.

No se debe confundir el acero con el hierro, que es un metal duro y relativamente dúctil, con diámetro atómico (dA) de 2,48 Å, con temperatura de fusión de 1535 °C y punto de ebullición 2740 °C. Por su parte, el carbono es un no metal de diámetro menor (dA = 1,54 Å), blando y frágil en la mayoría de sus formas alotrópicas (excepto en la forma de diamante). La difusión de este elemento en la estructura cristalina del anterior se logra gracias a la diferencia en diámetros atómicos, formándose un compuesto intersticial.

La diferencia principal entre el hierro y el acero se halla en el porcentaje del carbono: el acero es hierro con un porcentaje de carbono de entre el 0,03 % y el 1,075 %; a partir de este porcentaje se consideran otras aleaciones con hierro.

Cabe destacar que el acero posee diferentes constituyentes según su temperatura, concretamente, de mayor a menor dureza, perlita, cementita y ferrita; además de la austenita (para mayor información consultar el artículo Diagrama hierro-carbono).

El acero conserva las características metálicas del hierro en estado puro, pero la adición de carbono y de otros elementos tanto metálicos como no metálicos mejora sus propiedades físico-químicas.

Existen muchos tipos de acero en función del elemento o los elementos aleantes que estén presentes. La definición en porcentaje de carbono corresponde a los aceros al carbono, en los cuales este no metal es el único aleante, o hay otros pero en menores concentraciones. Otras composiciones específicas reciben denominaciones particulares en función de múltiples variables como por ejemplo los elementos que predominan en su composición (aceros al silicio), de su susceptibilidad a ciertos tratamientos (aceros de cementación), de alguna característica potenciada (aceros inoxidables) e incluso en función de su uso (aceros estructurales). Usualmente estas aleaciones de hierro se engloban bajo la denominación genérica de aceros especiales, razón por la que aquí se ha adoptado la definición de los comunes o "al carbono" que además de ser los primeros fabricados y los más empleados, sirvieron de base para los demás. Esta gran variedad de aceros llevó a Siemens a definir el acero como «un compuesto de hierro y otra sustancia que incrementa su resistencia».

El término acero procede del latín "aciarius", y éste de la palabra "acies", que es como se denomina en esta lengua el filo de un arma blanca. "Aciarius" sería, por tanto, el metal adecuado, por su dureza y resistencia, para ponerlo en la parte cortante de las armas y las herramientas.
Se desconoce la fecha exacta en que se descubrió la técnica para obtener hierro a partir de la fusión de minerales. Sin embargo, los primeros restos arqueológicos de utensilios de hierro datan del 3000 a. C. y fueron descubiertos en Egipto, aunque hay vestigios de adornos anteriores. Algunos de los primeros aceros provienen del este de África, cerca de 1400 a. C.
Durante la dinastía Han de China se produjo acero al derretir hierro forjado con hierro fundido, en torno al siglo I a. C. También adoptaron los métodos de producción para la creación de acero wootz, un proceso surgido en India y en Sri Lanka desde aproximadamente el año 300 a. C. y exportado a China hacia el siglo V. Este temprano método utilizaba un horno de viento, soplado por los monzones. También conocido como acero Damasco, era una aleación de hierro con gran número de diferentes materiales, incluyendo trazas de otros elementos en concentraciones menores a 1000 partes por millón o 0,1 % de la composición de la roca. Estudios realizados por Peter Paufler sugirieron que en su estructura se incluían nanotubos de carbono, lo que podría explicar algunas de las cualidades de este acero -como su durabilidad y capacidad de mantener un filo-, aunque debido a la tecnología de la época es posible que las mismas se hayan obtenido por azar y no por un diseño premeditado.

Entre los siglos IX y X se produjo en Merv el acero de crisol, en el cual el acero se obtenía calentando y enfriando el hierro y el carbón por distintas técnicas. Durante la dinastía Song del siglo XI en China, la producción de acero se realizaba empleando dos técnicas: la primera producía acero de baja calidad por no ser homogéneo —método "berganesco"— y la segunda, precursora del método Bessemer, quita el carbón con forjas repetidas y somete la pieza a enfriamientos abruptos.

El hierro para uso industrial fue descubierto hacia el año 1500 a. C., en Medzamor y el monte Ararat, en Armenia. La tecnología del hierro se mantuvo mucho tiempo en secreto, difundiéndose extensamente hacia el año 1200 a. C.

No hay registros de que la templabilidad fuera conocida hasta la Edad Media. Los métodos antiguos para la fabricación del acero consistían en obtener hierro dulce en el horno, con carbón vegetal y tiro de aire, con una posterior expulsión de las escorias por martilleo y carburación del hierro dulce para cementarlo. Luego se perfeccionó la cementación fundiendo el acero cementado en crisoles de arcilla y en Sheffield (Inglaterra) se obtuvieron, a partir de 1740, aceros de crisol. La técnica fue desarrollada por Benjamin Huntsman.

En 1856, Henry Bessemer, desarrolló un método para producir acero en grandes cantidades, pero dado que solo podía emplearse hierro que contuviese fósforo y azufre en pequeñas proporciones, fue dejado de lado. Al año siguiente, Carl Wilhelm Siemens creó otro, el procedimiento Martin-Siemens, en el que se producía acero a partir de la descarburación de la fundición de hierro dulce y óxido de hierro como producto del calentamiento con aceite, gas de coque, o una mezcla este último con gas de alto horno. Este método también quedó en desuso.

Aunque en 1878 Siemens también fue el primero en emplear electricidad para calentar los hornos de acero, el uso de hornos de arco eléctricos para la producción comercial comenzó en 1902 por Paul Héroult, quien fue uno de los inventores del método moderno para fundir aluminio. En este método se hace pasar dentro del horno un arco eléctrico entre chatarra de acero cuya composición se conoce y unos grandes electrodos de carbono situados en el techo del horno.

En 1948 se inventa el proceso del oxígeno básico L-D. Tras la segunda guerra mundial se iniciaron experimentos en varios países con oxígeno puro en lugar de aire para los procesos de refinado del acero. El éxito se logró en Austria en 1948, cuando una fábrica de acero situada cerca de la ciudad de Linz, Donawitz desarrolló el proceso del oxígeno básico o L-D.

En 1950 se inventa el proceso de colada continua que se usa cuando se requiere producir perfiles laminados de acero de sección constante y en grandes cantidades. El proceso consiste en colocar un molde con la forma que se requiere debajo de un crisol, el cual con una válvula puede ir dosificando material fundido al molde. Por gravedad el material fundido pasa por el molde, que está enfriado por un sistema de agua; al pasar el material fundido por el molde frío se convierte en pastoso y adquiere la forma del molde. Posteriormente el material es conformado con una serie de rodillos que al mismo tiempo lo arrastran hacia la parte exterior del sistema. Una vez conformado el material con la forma necesaria y con la longitud adecuada el material se corta y almacena.

En la actualidad se utilizan algunos metales y metaloides en forma de ferroaleaciones, que, unidos al acero, le proporcionan excelentes cualidades de dureza y resistencia.

Actualmente, el proceso de fabricación del acero se completa mediante la llamada metalurgia secundaria. En esta etapa se otorgan al acero líquido las propiedades químicas, temperatura, contenido de gases, nivel de inclusiones e impurezas deseados. La unidad más común de metalurgia secundaria es el horno cuchara. El acero aquí producido está listo para ser posteriormente colado, en forma convencional o en colada continua.

El uso intensivo que tiene y ha tenido el acero para la construcción de estructuras metálicas ha conocido grandes éxitos y rotundos fracasos que al menos han permitido el avance de la ciencia de materiales. Así, el 7 de noviembre de 1940 el mundo asistió al colapso del puente Tacoma Narrows al entrar en resonancia con el viento. Ya durante los primeros años de la Revolución industrial se produjeron roturas prematuras de ejes de ferrocarril que llevaron a William Rankine a postular la fatiga de materiales y durante la Segunda Guerra Mundial se produjeron algunos hundimientos imprevistos de los cargueros estadounidenses Liberty al fragilizarse el acero por el mero descenso de la temperatura, problema inicialmente achacado a las soldaduras.

Los dos componentes principales del acero se encuentran en abundancia en la naturaleza, lo que favorece su producción a gran escala. Esta variedad y disponibilidad lo hace apto para numerosos usos como la construcción de maquinaria, herramientas, edificios y obras públicas, contribuyendo al desarrollo tecnológico de las sociedades industrializadas. A pesar de su densidad (7850 kg/m³ de densidad en comparación a los 2700 kg/m³ del aluminio, por ejemplo) el acero es utilizado en todos los sectores de la industria, incluso en el aeronáutico, ya que las piezas con mayores solicitaciones (ya sea al impacto o a la fatiga) solo pueden aguantar con un material dúctil y tenaz como es el acero, además de la ventaja de su relativo bajo costo.

Las clasificaciones normalizadas de aceros como la AISI, ASTM y UNS, establecen valores mínimos o máximos para cada tipo de elemento. Estos elementos se agregan para obtener unas características determinadas como templabilidad, resistencia mecánica, dureza, tenacidad, resistencia al desgaste, soldabilidad o maquinabilidad. A continuación se listan algunos de los efectos de los elementos aleantes en el acero:



Se denomina impurezas a todos los elementos indeseables en la composición de los aceros. Se encuentran en los aceros y también en las fundiciones como consecuencia de que están presentes en los minerales o los combustibles. Se procura eliminarlas o reducir su contenido debido a que son perjudiciales para las propiedades de la aleación. En los casos en los que eliminarlas resulte imposible o sea demasiado costoso, se admite su presencia en cantidades mínimas.



Los aceros aleados o especiales contienen otros elementos, además de carbono, que modifican sus propiedades. Estos se clasifican según su influencia:


Aunque es difícil establecer las propiedades físicas y mecánicas del acero debido a que estas varían con los ajustes en su composición y los diversos tratamientos térmicos, químicos o mecánicos, con los que pueden conseguirse aceros con combinaciones de características adecuadas para infinidad de aplicaciones, se pueden citar algunas propiedades genéricas:

Es la degradación física (pérdida o ganancia de material, aparición de grietas, deformación plástica, cambios estructurales como transformación de fase o recristalización, fenómenos de corrosión, etc.) debido al movimiento entre la superficie de un material sólido y uno o varios elementos de contacto.

Para homogeneizar las distintas variedades de acero que se pueden producir, existen sistemas de normas que regulan la composición de los aceros y las prestaciones de los mismos en cada país, en cada fabricante de acero, y en muchos casos en los mayores consumidores de aceros.

Por ejemplo, en España están regulados por la norma UNE-EN 10020:2001 y antiguamente estaban reguladas por la norma UNE-36010, ambas editadas por AENOR.

Existen otras normas reguladoras del acero, como la clasificación de AISI (de uso mucho más extendido internacionalmente), ASTM, DIN, o la ISO 3506.

Debido a la facilidad que tiene el acero para oxidarse cuando entra en contacto con la atmósfera o con el agua, es necesario y conveniente proteger la superficie de los componentes de acero para protegerles de la oxidación y corrosión. Muchos tratamientos superficiales están muy relacionados con aspectos embellecedores y decorativos de los metales.

Los tratamientos superficiales más usados son los siguientes:

Un proceso de tratamiento térmico adecuado permite aumentar significativamente las propiedades mecánicas de dureza, tenacidad y resistencia mecánica del acero. Los tratamientos térmicos cambian la microestructura del material, con lo que las propiedades macroscópicas del acero también son alteradas.

Los tratamientos térmicos que pueden aplicarse al acero sin cambiar en su composición química son:

Son tratamientos térmicos en los que, además de los cambios en la estructura del acero, también se producen cambios en la composición química de la capa superficial, añadiendo diferentes productos químicos hasta una profundidad determinada. Estos tratamientos requieren el uso de calentamiento y enfriamiento controlados en atmósferas especiales. Entre los objetivos más comunes de estos tratamientos están aumentar la dureza superficial de las piezas dejando el núcleo más blando y tenaz, disminuir el rozamiento aumentando el poder lubrificante, aumentar la resistencia al desgaste, aumentar la resistencia a fatiga o aumentar la resistencia a la corrosión.

Entre los factores que afectan a los procesos de tratamiento térmico del acero se encuentran la temperatura y el tiempo durante el que se expone a dichas condiciones al material. Otro factor determinante es la forma en la que el acero vuelve a la temperatura ambiente. El enfriamiento del proceso puede incluir su inmersión en aceite o el uso del aire como refrigerante.

El método del tratamiento térmico, incluyendo su enfriamiento, influye en que el acero tome sus propiedades comerciales.

Según ese método, en algunos sistemas de clasificación, se le asigna un prefijo indicativo del tipo. Por ejemplo, el acero O-1, o A2, A6 (o S7) donde la letra "O" es indicativo del uso de aceite (del inglés: "oil quenched"), y "A" es la inicial de aire; el prefijo "S" es indicativo que el acero ha sido tratado y considerado resistente al golpeo ("shock resistant").

El acero que se utiliza para la construcción de estructuras metálicas y obras públicas, se obtiene a través de la laminación de acero en una serie de perfiles normalizados.

El proceso de laminado consiste en calentar previamente los lingotes de acero fundido a una temperatura que permita la deformación del lingote por un proceso de estiramiento y desbaste que se produce en una cadena de cilindros a presión llamado tren de laminación. Estos cilindros van formando el perfil deseado hasta conseguir las medidas que se requieran. Las dimensiones de las secciones conseguidas de esta forma no se ajustan a las tolerancias requeridas y por eso muchas veces los productos laminados hay que someterlos a fases de mecanizado para ajustar sus dimensiones a la tolerancia requerida.

La forja es el proceso que modifica la forma de los metales por deformación plástica cuando se somete al acero a una presión o a una serie continuada de impactos. La forja generalmente se realiza a altas temperaturas porque así se mejora la calidad metalúrgica y las propiedades mecánicas del acero.

El sentido de la forja de piezas de acero es reducir al máximo posible la cantidad de material que debe eliminarse de las piezas en sus procesos de mecanizado. En la forja por estampación la fluencia del material queda limitada a la cavidad de la estampa, compuesta por dos matrices que tienen grabada la forma de la pieza que se desea conseguir.

El acero corrugado es una clase de acero laminado usado especialmente en construcción, para emplearlo en hormigón armado. Se trata de barras de acero que presentan resaltos o «corrugas» que mejoran la adherencia con el hormigón. Está dotado de una gran ductilidad, la cual permite que a la hora de cortar y doblar no sufra daños, y tiene una gran soldabilidad, todo ello para que estas operaciones resulten más seguras y con un menor gasto energético.

Las barras de acero corrugado están normalizadas. Por ejemplo, en España están cubiertas por las Normas UNE 36068:2011, UNE 36065:2011 y UNE 36811:1998 IN.

Las barras de acero corrugados se producen en una gama de diámetros que van de 6 a 40 mm, en la que se cita la sección en cm² que cada barra tiene así como su peso en kg.

Las barras inferiores o iguales a 16 mm de diámetro se pueden suministrar en barras o rollos, para diámetros superiores a 16 siempre se suministran en forma de barras.

Las barras de producto corrugado tienen unas características técnicas que deben cumplir, para asegurar el cálculo correspondiente de las estructuras de hormigón armado. Entre las características técnicas destacan las siguientes, todas ellas se determinan mediante el ensayo de tracción:

La estampación del acero consiste en un proceso de mecanizado sin arranque de viruta donde a la plancha de acero se la somete por medio de prensas adecuadas a procesos de embutición y estampación para la consecución de determinadas piezas metálicas. Para ello en las prensas se colocan los moldes adecuados.

La troquelación del acero consiste en un proceso de mecanizado sin arranque de viruta donde se perforan todo tipo de agujeros en la plancha de acero por medio de prensas de impactos donde tienen colocados sus respectivos troqueles y matrices.

Las piezas de acero permiten mecanizarse en procesos de arranque de virutas en máquinas-herramientas (taladro, torno, fresadora, centros de mecanizado CNC, etc.) luego endurecerlas por tratamiento térmico y terminar los mecanizados por procedimientos abrasivos en los diferentes tipos de rectificadoras que existen.

El proceso de rectificado permite obtener muy buenas calidades de acabado superficial y medidas con tolerancias muy estrechas, que son muy beneficiosas para la construcción de maquinaria y equipos de calidad. Pero el tamaño de la pieza y la capacidad de desplazamiento de la rectificadora pueden presentar un obstáculo.

En ocasiones especiales, el tratamiento térmico del acero puede llevarse a cabo antes del mecanizado en procesos de arranque de virutas, dependiendo del tipo de acero y los requerimientos que deben ser observados para determinada pieza. Con esto, se debe tomar en cuenta que las herramientas necesarias para dichos trabajos deben ser muy fuertes por llegar a sufrir desgaste apresurado en su vida útil. Estas ocasiones peculiares, se pueden presentar cuando las tolerancias de fabricación son tan estrechas que no se permita la inducción de calor en tratamiento por llegar a alterar la geometría del trabajo, o también por causa de la misma composición del lote del material (por ejemplo, las piezas se están encogiendo mucho por ser tratadas). En ocasiones es preferible el mecanizado después del tratamiento térmico, ya que la estabilidad óptima del material ha sido alcanzada y, dependiendo de la composición y el tratamiento, el mismo proceso de mecanizado no es mucho más difícil.

En algunos procesos de fabricación que se basan en la descarga eléctrica con el uso de electrodos, la dureza del acero no hace una diferencia notable.

En muchas situaciones, la dureza del acero es determinante para un resultado exitoso, como por ejemplo en el taladrado profundo al procurar que un agujero mantenga su posición referente al eje de rotación de la broca de carburo. O por ejemplo, si el acero ha sido endurecido por ser tratado térmicamente y por otro siguiente tratamiento térmico se ha suavizado, la consistencia puede ser demasiado suave para beneficiar el proceso, puesto que la trayectoria de la broca tenderá a desviarse.

El doblado del acero que ha sido tratado térmicamente no es muy recomendable pues el proceso de doblado en frío del material endurecido es más difícil y el material muy probablemente se haya tornado demasiado quebradizo para ser doblado; el proceso de doblado empleando antorchas u otros métodos para aplicar calor tampoco es recomendable puesto que al volver a aplicar calor al metal duro, la integridad de este cambia y puede ser comprometida.

Para su uso en construcción, el acero se distribuye en perfiles metálicos, siendo éstos de diferentes características según su forma y dimensiones y debiéndose usar específicamente para una función concreta, ya sean vigas o pilares.

El acero en sus distintas clases está presente de forma abrumadora en nuestra vida cotidiana en forma de herramientas, utensilios, equipos mecánicos y formando parte de electrodomésticos y maquinaria en general así como en las estructuras de las viviendas que habitamos y en la gran mayoría de los edificios modernos. En este contexto existe la versión moderna de perfiles de acero denominada Metalcón.
Los fabricantes de medios de transporte de mercancías (camiones) y los de maquinaria agrícola son grandes consumidores de acero.

También son grandes consumidores de acero las actividades constructoras de índole ferroviario desde la construcción de infraestructuras viarias así como la fabricación de todo tipo de material rodante.

Otro tanto cabe decir de la industria fabricante de armamento, especialmente la dedicada a construir armamento pesado, vehículos blindados y acorazados.

También consumen mucho acero los grandes astilleros constructores de barcos especialmente petroleros, y gasistas u otros buques cisternas.

Como consumidores destacados de acero cabe citar a los fabricantes de automóviles porque muchos de sus componentes significativos son de acero.

A modo de ejemplo cabe citar los siguientes componentes del automóvil que son de acero:

Cabe destacar que cuando el automóvil pasa a desguace por su antigüedad y deterioro se separan todas las piezas de acero, son convertidas en chatarra y son reciclados de nuevo en acero mediante hornos eléctricos y trenes de laminación o piezas de fundición de hierro.

Cuando un técnico proyecta una estructura metálica, diseña una herramienta o una máquina, define las calidades y prestaciones que tienen que tener los materiales constituyentes. Como hay muchos tipos de aceros diferentes y, además, se pueden variar sus prestaciones con tratamientos térmicos, se establecen una serie de ensayos mecánicos para verificar principalmente la dureza superficial, la resistencia a los diferentes esfuerzos que pueda estar sometido, el grado de acabado del mecanizado o la presencia de grietas internas en el material, lo cual afecta directamente al material pues se pueden producir fracturas o roturas.

Hay dos tipos de ensayos, unos que pueden ser destructivos y otros no destructivos.

Todos los aceros tienen estandarizados los valores de referencia de cada tipo de ensayo al que se le somete.

Los ensayos no destructivos son los siguientes:


Los ensayos destructivos son los siguientes:


El consumo mundial de productos acabados de acero acabados en 2005 superó los mil millones de toneladas. La evolución del consumo resulta sumamente dispar entre las principales regiones geográficas. China registró un incremento del consumo aparente del 23 % y representa en la actualidad prácticamente un 32 % de la demanda mundial de acero. En el resto, tras un año 2004 marcado por un significativo aumento de los stocks motivado por las previsiones de incremento de precios, el ejercicio 2005 se caracterizó por un fenómeno de reducción de stocks, registrándose la siguiente evolución: −6 % en Europa (UE25), −7 % en Norteamérica, 0 % en Sudamérica, +5 % en CEI, +5 % en Asia (excluida China), +3 % en Oriente Medio.

La producción mundial de acero bruto en 2005 ascendió a 1129,4 millones de toneladas, lo que supone un incremento del 5,9 % con respecto a 2004. Esa evolución resultó dispar en las diferentes regiones geográficas. El aumento registrado se debe fundamentalmente a las empresas siderúrgicas chinas, cuya producción se incrementó en un 24,6 %, situándose en 349,4 millones de toneladas, lo que representa el 31 % de la producción mundial, frente al 26,3 % en 2004. Se observó asimismo un incremento en India (+16,7 %). La contribución japonesa se ha mantenido estable. Asia en conjunto produce actualmente la mitad del acero mundial. Mientras que el volumen de producción de las empresas siderúrgicas europeas y norteamericanas se redujo en un 3,6 % y un 5,3 % respectivamente.

La distribución de la producción de acero en 2005 fue la siguiente según cifras estimadas por el International Iron and Steel Institute (IISI) en enero de 2006:

El acero, al igual que otros metales, puede ser reciclado. Al final de su vida útil, todos los elementos construidos en acero como máquinas, estructuras, barcos, automóviles, trenes, etc., se pueden desguazar, separando los diferentes materiales componentes y originando unos desechos seleccionados llamados comúnmente chatarra. La misma es prensada en bloques que se vuelven a enviar a la acería para ser reutilizados. De esta forma se reduce el gasto en materias primas y en energía que deben desembolsarse en la fabricación del acero. Se estima que la chatarra reciclada cubre el 40 % de las necesidades mundiales de acero (cifra de 2006).

El proceso de reciclado se realiza bajo las normas de prevención de riesgos laborales y las medioambientales. El horno en que se funde la chatarra tiene un alto consumo de electricidad, por lo que se enciende generalmente cuando la demanda de electricidad es menor. Además, en distintas etapas del reciclaje se colocan detectores de radiactividad, como por ejemplo en la entrada de los camiones que transportan la chatarra a las industrias de reciclaje.

El personal que manipula chatarra debe estar siempre vacunado contra la infección del tétanos, pues puede infectarse al sufrir alguna herida con la chatarra. Cualquier persona que sufra un corte con un elemento de acero, debe acudir a un centro médico y recibir dicha vacuna, o un refuerzo de la misma si la recibió con anterioridad.





</doc>
<doc id="11565" url="https://es.wikipedia.org/wiki?curid=11565" title="Mineral">
Mineral

Un mineral es una sustancia natural, de composición química definida, normalmente sólido e inorgánico, y que tiene una cierta estructura cristalina. Es diferente de una roca, que puede ser un agregado de minerales o no minerales y que no tiene una composición química específica. La definición exacta de un mineral es objeto de debate, especialmente con respecto a la exigencia de ser abiogénico, y en menor medida, a que deba tener una estructura atómica ordenada. El estudio de los minerales se llama mineralogía.

Hay más de minerales conocidas, de ellas más de 5070 aprobadas por la Asociación Internacional de Mineralogía ("International Mineralogical Association", o IMA). Continuamente se descubren y describen nuevos minerales, entre 50 y 80 al año. La diversidad y abundancia de especies minerales es controlada por la química de la Tierra. El silicio y el oxígeno constituyen aproximadamente el 75% de la corteza terrestre, lo que se traduce directamente en el predominio de los minerales de silicato, que componen más del 90% de la corteza terrestre. Los minerales se distinguen por diversas propiedades químicas y físicas. Diferencias en la composición química y en la estructura cristalina distinguen varias especies, y estas propiedades, a su vez, están influidas por el entorno geológico de la formación del mineral. Cambios en la temperatura, la presión, o en la composición del núcleo de una masa de roca causan cambios en sus minerales.
Los minerales pueden ser descritos por varias propiedades físicas que se relacionan con su estructura química y composición. Las características más comunes que los identifican son la estructura cristalina y el hábito, la dureza, el lustre, la diafanidad, el color, el rayado, la tenacidad, la exfoliación, la fractura, la partición y la densidad relativa. Otras pruebas más específicas para la caracterización de ciertos minerales son el magnetismo, el sabor o el olor, la radioactividad y la reacción a los ácidos fuertes.

Los minerales se clasifican por sus componentes químicos clave siendo los dos sistemas dominantes la clasificación de Dana y la clasificación de Strunz. La clase de silicatos se subdivide en seis subclases según el grado de polimerización en su estructura química. Todos los silicatos tienen una unidad básica en forma de tetraedro de sílice , es decir, un catión de silicio unido a cuatro aniones de oxígeno. Estos tetraedros pueden ser polimerizados para dar las subclases: neosilicatos (no polimerizados, y por lo tanto, solo tetraedros), sorosilicatos (dos tetraedros enlazadados entre sí), ciclosilicatos (anillos de tetraedros), inosilicatos (cadenas de tetraedros), filosilicatos (láminas de tetraedros), y tectosilicatos (redes en tres dimensiones de tetraedros). Otros grupos minerales importantes son los elementos nativos, sulfuros, óxidos, haluros, carbonatos, sulfatos y fosfatos.

La definición general de un mineral comprende los siguientes criterios:


Las tres primeras características generales son menos debatidas que las dos últimas. El primer criterio significa que un mineral se tiene que formar por un proceso natural, lo que excluye compuestos antropogénicos. La estabilidad a temperatura ambiente, en el sentido más simple, es sinónimo de que el mineral sea sólido. Más específicamente, un compuesto tiene que ser estable o metaestable a 25°C. Son ejemplos clásicos de excepciones a esta regla el mercurio nativo, que cristaliza a -39°C, y el hielo de agua, que es sólido sólo por debajo de 0°C; puesto que estos dos minerales se habían descrito con anterioridad a 1959, fueron adoptados por la Asociación Internacional de Mineralogía (IMA). Los avances modernos suponen un amplio estudio de los cristales líquidos, que también concierne ampliamente a la mineralogía. Los minerales son compuestos químicos, y, como tales, pueden ser descritos por una fórmula fija o una variable. Muchos grupos de minerales y especies están compuestos por una solución sólida; las sustancias puras generalmente no se encuentran debido a la contaminación o sustitución química. Por ejemplo, el grupo del olivino se describe por la fórmula variable , que es una solución sólida de dos especies de miembro extremo, la forsterita rica en magnesio y la fayalita rica en hierro, que se describen mediante una fórmula química fija. Otras especies minerales podrían tener composiciones variables, tales como el sulfuro de mackinawita, , que es principalmente un sulfuro ferroso, pero que tiene una impureza de níquel muy significativa que se refleja en su fórmula.

El requisito de que una especie mineral para ser válida ha de ser abiogénica también se ha descrito como similar a que sea inorgánica; sin embargo, este criterio es impreciso y a los compuestos orgánicos se les ha asignado una rama de clasificación separada. Por último, la exigencia de tener una disposición atómica ordenada es generalmente sinónimo de cristalinidad; sin embargo, los cristales también son periódicos, por lo que se utiliza en su lugar el criterio más amplio. Una disposición atómica ordenada da lugar a una variedad de propiedades físicas macroscópicas, como la forma cristalina, la dureza y la exfoliación. Ha habido varias propuestas recientes para modificar la definición para considerar las sustancias biogénicas o amorfas como minerales. La definición formal de un mineral aprobada por la IMA en 1995:

Además, las sustancias biogénicas fueron excluidas explícitamente: 

Los sistemas de clasificación de minerales y sus definiciones están evolucionando para recoger los últimos avances de la ciencia mineral. Los cambios más recientes han sido la adición de una clase orgánica, tanto en el nuevo Dana y en los esquemas de la clasificación de Strunz. La clase orgánica incluye un grupo muy raro de minerales con hidrocarburos. La «Comisión sobre nuevos minerales y nombres de minerales» de la IMA aprobó en 2009 un esquema jerárquico para la denominación y clasificación de los grupos minerales y de los nombres de los grupos y estableció siete comisiones y cuatro grupos de trabajo para revisar y clasificar los minerales en una lista oficial de sus nombres publicados. De acuerdo con estas nuevas reglas,

La exclusión de Nickel (1995) de las sustancias biogénicas no fue universalmente respetada. Por ejemplo, Lowenstam (1981) declaró que «los organismos son capaces de formar una gran variedad de minerales, algunos de los cuales no se pueden formar inorgánicamente en la biosfera.»La distinción es una cuestión de clasificación y tiene menos que ver con los constituyentes de los minerales mismos. Skinner (2005) considera todos los sólidos como minerales potenciales e incluye los biominerales en el reino mineral, que son aquellos creados por las actividades metabólicas de los organismos. Skinner amplió la definición previa de un mineral para clasificar como mineral cualquier «elemento o compuesto, amorfo o cristalino, formado a través de los procesos biogeoquímicos».

Los recientes avances en la genéticas de alta resolución y espectroscopía de absorción de rayos X están proporcionando revelaciones sobre las relaciones biogeoquímicas entre microorganismos y minerales que pueden hacer obsoleta la exclusión biogénica de Nickel (1995) y una necesidad la inclusión biogénica de Skinner (2005). Por ejemplo, el IMA encargó al «Grupo de trabajo de Mineralogía ambiental y Geoquímica» tratar de los minerales en la hidrosfera, atmósfera y biosfera. El alcance del grupo incluye microorganismos formadores de minerales, que existen en casi todas las rocas, en el suelo y en la superficie de las partículas que atraviesan el globo hasta una profundidad de al menos 1600 metros por debajo del fondo del mar y 70 kilómetros en la estratosfera (posiblemente se introduzcan en la mesosfera). Los ciclos biogeoquímicos han contribuido a la formación de minerales durante miles de millones de años. Los microorganismos pueden precipitar los metales de la disolución, contribuyendo a la formación de yacimientos de mineral. También pueden catalizar la disolución de los minerales.

Antes de la lista de la Asociación Internacional de Mineralogía, más de 60 biominerales ya habían sido descubiertos, nombrados y publicados. Estos minerales (un subconjunto tabulado en Lowenstam (1981)) se consideran propiamente minerales de acuerdo con la definición de Skinner (2005). Estos biominerales no figuran en la lista oficial de nombres de minerales de la IMA, aunque muchos de estos biominerales representativos se distribuyen entre las 78 clases minerales que figuran en la clasificación de Dana. Otra clase rara de minerales (principalmente de origen biológico) incluye los cristales líquidos minerales que tienen propiedades tanto de líquidos y cristales. Hasta la fecha se han identificado más de 80.000 compuestos cristalinos líquidos.

La definición de mineral de Skinner (2005) toma en cuenta esta cuestión afirmando que un mineral puede ser cristalino o amorfo, incluyendo en este último grupo los cristales líquidos. Aunque los biominerales y los cristales líquidos no son la forma más común de minerales, ayudan a definir los límites de lo que constituye propiamente un mineral. La definición formal de Nickel (1995) menciona explícitamente la cristalinidad como una clave para la definición de una sustancia como un mineral. Un artículo de 2011 define la icosahedrita, una aleación de hierro-cobre-aluminio, como mineral; llamada así por su singular simetría icosaédrica natural, es un cuasi cristal. A diferencia de un verdadero cristal, los cuasicristales están ordenados pero no de forma periódica.

Los minerales no son equivalentes a las rocas. Una roca puede ser un agregado de uno o más minerales, o no tener ningún mineral. Rocas como la caliza o la cuarcita se componen principalmente de un mineral —calcita o aragonito en el caso de la caliza, y cuarzo, en la última. Otras rocas pueden ser definidas por la abundancia relativa de los minerales clave (esenciales); un granito está definido por las proporciones de cuarzo, feldespato alcalino y plagioclasa. Los otros minerales de la roca se denominan accesorios, y no afectan en gran medida la composición global de la roca. Las rocas también pueden estar compuestas enteramente de material no mineral; el carbón es una roca sedimentaria compuesta principalmente de carbono derivado de manera orgánica.

En las rocas, algunas especies y grupos minerales son mucho más abundantes que otros; éstos se denominan minerales formativos. Los principales ejemplos son el cuarzo, feldespatos, las micas, los anfíboles, los piroxenos, los olivinos, y la calcita; excepto la última, todos son minerales silicatos. En general, alrededor de unos 150 minerales se consideran particularmente importantes, ya sea en términos de su abundancia o valor estético en términos de coleccionismo.

Los minerales y rocas comercialmente valiosos se conocen como minerales industriales y rocas industriales. Por ejemplo, la moscovita, una mica blanca, puede ser utilizada para ventanas (a veces conocida como isinglass), como material de relleno o como un aislante. Las menas son minerales que tienen una alta concentración de un determinado elemento, normalmente de un metal. Ejemplos de ello son el cinabrio (), un mineral de mercurio, esfalerita (), un mineral de zinc, o la casiterita (), un mineral de estaño. Las gemas son minerales con un alto valor ornamental, y se distinguen de las no gemas por su belleza, durabilidad, y por lo general, rareza. Hay alrededor de 20 especies minerales que se califican como minerales gema, que constituyen alrededor de las 35 piedras preciosas más comunes. Los minerales gema están a menudo presentes en diversas variedades, y así un mineral pueden dar cuenta de varias piedras preciosas diferentes; por ejemplo, rubí y el zafiro son ambas corindón, .

Los minerales se solían clasificar en la antigüedad con criterios de su aspecto físico; Teofrasto, en el siglo III a. C., creó la primera lista sistemática cualitativa conocida; Plinio el Viejo (siglo I), en su “Historia Natural”, realizó una sistemática mineral, trabajo que, en la Edad Media, sirvió de base a Avicena; Linneo (1707-1778) intentó idear una nomenclatura fundándose en los conceptos de género y especie, pero no tuvo éxito y dejó de usarse en el siglo XIX; con el posterior desarrollo de la química, el químico sueco Axel Fredrik Cronstedt (1722-1765) elaboró la primera clasificación de minerales en función de su composición; el geólogo estadounidense James Dwight Dana, en 1837, propuso una clasificación considerando la estructura y composición química. La clasificación más actual se funda en la composición química y la estructura cristalina de los minerales. Las clasificaciones más empleadas son las de Strunz y Kostov.

Los minerales se clasifican según la variedad, especie, serie y grupo, en orden creciente de generalidad. El nivel básico de definición es el de las especies minerales, que se distinguen de otras especies por sus propiedades químicas y físicas específicas y únicas. Por ejemplo, el cuarzo se define por su fórmula química, , y por una estructura cristalina específica que lo distingue de otros minerales con la misma fórmula química (denominados polimorfos). Cuando existe un rango de composición entre dos especies minerales, se define una serie mineral. Por ejemplo, la serie de la biotita está representada por cantidades variables de la endmembers flogopita, siderofilita, annita, y eastonita. Por contraste, un grupo mineral es una agrupación de especies minerales con algunas propiedades químicas comunes que comparten una estructura cristalina. El grupo piroxeno tiene una fórmula común de , en donde X e Y son ambos cationes, siendo X generalmente mayor que Y (radio iónico); los piroxenos son silicatos de cadena sencilla que cristalizan en cualquiera de los sistemas cristalinos monoclínico o ortorrómbico. Finalmente, una variedad mineral es un tipo específico de especies minerales que difieren por alguna característica física, como el color o el hábito del cristal. Un ejemplo es la amatista, que es una variedad púrpura del cuarzo.

Para ordenar minerales dos son las clasificaciones más comunes, la de Dana y la de Strunz, ambas basadas en la composición, en especial respecto a los grupos químicos importantes, y en la estructura. James Dwight Dana, un geólogo principal de su tiempo, publicó por primera vez su "System of Mineralogy" [Sistema de Mineralogía] en 1837; en 1997 se editó su octava edición. La clasificación de Dana asigna un número de cuatro partes a una especie mineral. Su número de clase se basa en los grupos de composición importantes; el número de tipo da la relación de cationes/aniones en el mineral; y los dos últimos números corresponden al grupo de minerales por similaridad estructural dentro de un tipo o clase determinada. La clasificación de Strunz —utilizada con menor frecuencia y llamada así por el mineralogista alemán Karl Hugo Strunz— se basa en el sistema de Dana, pero combina tanto criterios químicos como estructurales, estos últimos con respecto a la distribución de los enlaces químicos.

En enero de 2016, la IMA había aprobado 5.090 especies minerales. Se han nombrado en general en honor de una persona (45%) — ver: —, seguidos por la ubicación del lugar, mina o yacimiento del descubrimiento (23%); otras etimologías comunes son los nombres basados en la composición química (14%) y en las propiedades físicas (8%). El sufijo común "-ita" usado en los nombres de las especies minerales desciende del antiguo sufijo griego - ί τ η ς (-ites), que significa 'relacionado con' o 'que pertenece a'.

La abundancia y diversidad de minerales es controlada directamente por su composición química, que a su vez, depende de la abundancia de los elementos en la Tierra. La mayoría de los minerales observados derivan de la corteza terrestre. Ocho elementos representan la mayor parte de los componentes clave de los minerales, debido a su abundancia en la corteza terrestre. Estos ocho elementos suponen más del 98% de la corteza en peso, y son, en orden decreciente: oxígeno, silicio, aluminio, hierro, magnesio, calcio, sodio y potasio. El oxígeno y el silicio son, con mucho, los dos más importantes —el oxígeno compone, en peso, el 46,6% de la corteza terrestre, y el silicio un 27,7%.

Los minerales que se forman son controlados directamente por la química mayor del cuerpo matriz. Por ejemplo, un magma rico en hierro y magnesio formará minerales máficos, como el olivino y los piroxenos; por el contrario, un magma más rico en sílice cristalizará para formar minerales que incorporen más , como los feldespatos y cuarzos. La caliza, la calcita o la aragonita (todas ) se forman porque la roca es rica en calcio y carbonato. Un corolario es que no se encontrará un mineral en una roca cuya química mayor no se parezca a la química mayor del mineral dado, con la excepción de algunas trazas de minerales. Por ejemplo, la cianita, , se forma a partir del metamorfismo de lutitas ricas en aluminio; no sería probable que ocurriera en rocas pobres en aluminio, como la cuarcita.

La composición química puede variar entre las especies terminales de una serie de solución sólida. Por ejemplo, los feldespatos plagioclasa comprenden una serie continua que va desde el miembro extremo de la albita, rica en sodio (), hasta la anortita, rica en calcio (), con cuatro variedades intermedias reconocidas entre ellas (recogidas en orden de riqueza del sodio al calcio): oligoclasa, andesina, labradorita y bytownita. Otros ejemplos de serie son la serie del olivino, desde la forsterita, rica en magnesio, a la fayalita, rica en hierro, y la serie del wolframita, desde la hübnerita, rica en manganeso, hasta la ferberita, rica en hierro.

La sustitución química y la coordinación de poliedros explican esta característica común de los minerales. En la naturaleza, los minerales no son sustancias puras, y se contaminan por otros elementos que están presentes en el sistema químico dado. Como resultado, es posible que un elemento sea sustituido por otro. La sustitución química se producirá entre iones de un tamaño y carga similares; por ejemplo, no sustituirá a debido a las incompatibilidades químicas y estructurales causadas por la gran diferencia en tamaño y carga. Un ejemplo común de sustitución química es el del > por , que están próximos en carga, tamaño y abundancia en la corteza terrestre. En el ejemplo de la plagioclasa, hay tres casos de sustitución. Los feldespatos son todos armazones de sílice, que tienen una relación de silicio-oxígeno de 2:1, y el espacio para otros elementos se da por la sustitución del ion por el ion para dar una unidad de base de ; sin la sustitución, la fórmula pude ser cargada-equilibrada como , dando cuarzo. La importancia de esta propiedad estructural se explica además por los poliedros de coordinación. La segunda sustitución se produce entre el ion y el ion ; sin embargo, la diferencia en la carga tiene que contabilizarse haciendo una segunda sustitución del ion por el ion .

La coordinación de poliedros es una representación geométrica de cómo un catión está rodeado por un anión. En mineralogía, debido a su abundancia en la corteza terrestre, los poliedros de coordinación se consideran generalmente en términos del oxígeno. La unidad base de los minerales de silicato es el tetraedro de sílice —un ion rodeado de cuatro —. Una forma alternativa de describir la coordinación del silicato es mediante un número: en el caso del tetraedro de sílice, se dice que tiene un número de coordinación de 4. Diversos cationes tienen un rango específico de posibles números de coordinación; para el silicio, es casi siempre 4, excepto para minerales de muy altas presiones en los que los compuestos se comprimen de tal manera que el silicio está seis veces (octaédrico) coordinado con el oxígeno. Los cationes mayores tienen un número de coordinación más grande debido al aumento en el tamaño relativo en comparación con el oxígeno (la última subcapa orbital de los átomos más pesados es diferente también). Los cambios en los números de coordinación conduce a diferencias físicas y mineralógicas; por ejemplo, a alta presión, tal como en el manto, muchos minerales, especialmente algunos silicatos como el olivino y los granates cambiarán a una estructura de perovskita, en el que el silicio está en coordinación octaédrica. Otro ejemplo son los aluminosilicatos cianita, andalucita y silimanita (polimorfos, ya que comparten la fórmula ), que se diferencian por el número de coordinación del ; estos minerales transitan de uno al otro como una respuesta a los cambios en la presión y en la temperatura. En el caso de materiales de silicato, la sustitución del ion por permite una variedad de minerales, debido a la necesidad de equilibrar las cargas.

Los cambios de temperatura, de presión y de composición alteran la mineralogía de una roca simple: los cambios en la composición pueden ser causados por procesos como la erosión o metasomatismo (alteración hidrotérmica); los cambios en la temperatura y en la presión se producen cuando la roca madre se somete a movimientos tectónicos o magmáticos en diferentes regímenes físicos; y los cambios en las condiciones termodinámicas favorecen que algunas asociaciones de minerales reaccionen entre sí para producir nuevos minerales. Como tal, es posible que dos rocas tengan una química de roca base idéntica, o muy similar, sin tener una mineralogía similar. Este proceso de alteración mineralógica está relacionado con el ciclo de las rocas. Un ejemplo de una serie de reacciones minerales se ilustra como sigue.

El feldespato ortoclasa () es un mineral que se encuentra comúnmente en el granito, una roca ígnea plutónica. Cuando se expone a la intemperie, reacciona para formar caolinita (, un mineral sedimentario, y ácido silícico):

Bajo condiciones metamórficas de bajo grado, la caolinita reacciona con el cuarzo para formar pirofilita ():

A medida que aumenta el grado metamórfico, la pirofilita reacciona para formar cianita y cuarzo:

Alternativamente, un mineral puede cambiar su estructura cristalina como consecuencia de cambios de temperatura y de presión sin reaccionar. Por ejemplo, el cuarzo se convertirá en una variedad de sus polimorfos de , como la tridimita y la cristobalita a altas temperaturas, y en coesita a altas presiones.

La caracterización de los minerales puede variar de ser muy simple a muy difícil. Un mineral puede ser identificado por varias propiedades físicas, siendo algunos de ellas suficientes para una plena identificación sin ambigüedades. En otros casos, los minerales sólo se pueden clasificar mediante análisis más complejos, ópticos, químicos o de difracción de rayos X; estos métodos, sin embargo, pueden ser costosos y consumen mucho tiempo. Las propiedades físicas que se estudian para la clasificación son la estructura cristalina y el hábito, la dureza y el lustre, la diafanidad, el color, el rayado, la exfoliación y la fractura, y la densidad relativa. Otras pruebas menos generales son la fluorescencia y fosforescencia, el magnetismo, la radioactividad, la tenacidad (respuesta a los cambios mecánicos inducidos de forma), la piezoelectricidad y la reactividad para diluir ácidos.

La estructura cristalina resulta de la disposición espacial geométrica ordenada de los átomos en la estructura interna de un mineral. Esta estructura cristalina se basa en una disposición atómica o iónica interna regular, que se expresa a menudo en la forma geométrica que el cristal toma. Incluso cuando los granos minerales son demasiado pequeños para ser vistos o son de forma irregular, la estructura cristalina subyacente siempre es periódica y se puede determinar por difracción de rayos X. Los minerales por lo general son descritos por su contenido de simetría. Los cristales están cristalográficamente restringidos a 32 grupos de puntos, que se diferencian por su simetría. Estos grupos se clasifican a su vez en categorías más amplias, siendo las de mayor alcance seis familias de cristales. (a veces una de las familias, la hexagonal, también se divide en dos "sistemas" cristalinos: el trigonal, que tiene un eje tres veces simétrico, y el hexagonal, que tiene un eje seis veces simétrico.)

Estas familias pueden ser descritas por las longitudes relativas de los tres ejes cristalográficos, y los ángulos que forman entre ellos; estas relaciones corresponden a las operaciones de simetría que definen los grupos de puntos más estrechos. Se resumen a continuación; a, b, y c representan los ejes, y α, β, y γ representan el ángulo opuesto al eje cristalográfico respectivo (por ejemplo, α es el ángulo opuesto al eje a, es decir el ángulo entre los ejes b y c.):
La química y la estructura cristalina, en conjunto, definen un mineral. Con una restricción a grupos de 32 puntos, los minerales de diferente química pueden tener una estructura cristalina idéntica. Por ejemplo, la halita (), la galena () y la periclasa () pertenecen todas al grupo de puntos hexaoctahedral (familia isométrica), ya que tienen una estequiometría similar entre sus diferentes elementos constitutivos. En contraste, los polimorfos son agrupaciones de minerales que comparten una fórmula química, pero que tienen una estructura diferente. Por ejemplo, la pirita y la marcasita, ambos sulfuros de hierro, tienen la fórmula ; sin embargo, el primero es isométrico mientras que el último es ortorrómbico. Este polimorfismo se extiende a otros sulfuros de fórmula genérica ; estos dos grupos son conocidos colectivamente como los grupos de la pirita y marcasita.

El polimorfismo se puede extender más allá del contenido de la pura simetría. Los aluminosilicatos son un grupo de tres minerales —cianita, andalucita y silimanita— que comparten la fórmula química . La cianita es triclınica, mientras que la andalucita y la silimanita son ambas ortorrómbicas y pertenecen al grupo de puntos bipiramidal. Estas diferencias surgen correspondiendo a como el aluminio se coordina dentro de la estructura cristalina. En todos los minerales, un ion de aluminio está siempre seis veces coordinado con el oxígeno; el silicio, por regla general está en coordinación de cuatro veces en todos los minerales; una excepción es un caso como la stishovita (, un polimorfo de cuarzo de ultra-alta presión con estructura de rutilo). En la cianita, el segundo aluminio está en coordinación seis veces; su fórmula química se puede expresar como , para reflejar su estructura cristalina. La andalucita tiene el segundo aluminio en coordinación cinco veces () y la silimanita lo tiene en coordinación de cuatro veces (().

Las diferencias en la estructura cristalina y la química influyen mucho en otras propiedades físicas del mineral. Los alótropos del carbono, el diamante y el grafito, tienen propiedades muy distintas; el diamante es la sustancia natural más dura, tiene un lustre adamantino, y pertenece a la familia isométrica, mientras que el grafito es muy blando, tiene un lustre grasiento, y cristaliza en la familia hexagonal. Esta diferencia se explica por diferencias en el enlace. En el diamante, los átomos de carbono están en orbitales híbridos sp, lo que significa que forman un marco o armazón en el que cada carbono está unido covalentemente a cuatro vecinos de una manera tetraédrica. Por otro lado, el grafito forma láminas de átomos de carbono en orbitales híbridos sp, en los que cada átomo de carbono está unido covalentemente a sólo otros tres. Estas hojas se mantienen unidas por fuerzas mucho más débiles que las fuerzas de van der Waals, y esta discrepancia se traduce en grandes diferencias macroscópicas.

La macla es la interpenetración de dos o más de cristal de una única especie mineral. La geometría de la macla es controlada por la simetría del mineral y, como resultado, hay varios tipos: de contacto, reticuladas, geniculadas, de penetración, cíclicas y polisintéticas. Las maclas de contacto, o maclas simples, constan de dos cristales unidos en un plano; este tipo de maclas es común en la espinela; las maclas reticuladas, comunes en forma de rutilo, son cristales entrelazados que se asemejan a un reticulado. Las maclas geniculadas tienen una mezcla en el medio que es causada por el comienzo del maclado. Las maclas de penetración constan de dos cristales individuales que han crecido uno dentro de otro; ejemplos de este hermanamiento son las maclas en forma de cruz de la estaurolita y las maclas de Carlsbad en la ortoclasa. Las maclas cíclicas son causados por el maclado repetido en torno a un eje de rotación. Se produce alrededor de tres, cuatro, cinco, seis, o ocho ejes de plegado. Las maclas polisintéticas son similares a las maclas cíclicas por la presencia de maclados repetitivos aunqueo, en lugar de producirse alrededor de un eje de rotación, lo hacen siguiendo planos paralelos, por lo general en una escala microscópica.

El hábito cristalino se refiere a la forma general de cristal. Se utilizan varios términos para describir esta propiedad: acicular, que describe cristales en forma de aguja como en la natrolita; acuchillado; arborescente o dendrítica (patrón de árbol, común en el cobre nativo); equante, que es típico del granate; prismático (alargado en una dirección); y tabular, que se diferencia de acuchillado en que el primero es plano mientras que este último tiene un alargamiento definido. En relación con la forma cristalina, la calidad de las caras del cristal es diagnóstico de algunos minerales, especialmente con un microscopio petrográfico. Los cristales euhedrales tienen una forma externa definida, mientras que los cristales anhedrales no lo hacen; las formas intermedias se denominan subhedrales.

La dureza de un mineral define cuánto puede resistir el rayado. Esta propiedad física depende de la composición química y de la estructura cristalina, y por ello no es necesariamente constante en todas las cara; la debilidad cristalográfica hace que algunas direcciones sean más blandas que otras. Un ejemplo de esta propiedad se muestra en la cianita, que tiene una dureza de Mohs de 5½ en la dirección paralela a [001], pero de 7 paralela a [100].

La escala más común de medición es la escala de dureza de Mohs ordinaria. Definida por diez indicadores, un mineral con un índice más alto rasca los minerales que están por debajo de él en la escala. La escala va desde el talco, un silicato estratificado, hasta el diamante, un polimorfo de carbono que es el material natural más duro.

El lustre o brillo indica cómo se refleja la luz que incide sobre la superficie del mineral, una propiedad que no depende del color y sí de su naturaleza química: es más intenso en sustancias que tienen enlaces metálicos y menor en las de enlaces iónicos o covalentes. El tipo y la intensidad del brillo dependen del índice de refracción y de la relación entre la luz absorbida y la reflejada. Hay numerosos términos cualitativos para su descripción, agrupándose en tres:


La diafanidad de un mineral describe la capacidad de la luz de pasar a través de él. Los minerales transparentes no disminuyen la intensidad de la luz que pasa a través de ellos. Un ejemplo de estos minerales es la moscovita (mica de potasio); algunas variedades son lo suficientemente claras como para haber sido utilizadas como vidrios en las ventanas. Los minerales translúcidos permiten pasar algo de luz, pero menos que los que son transparentes. La jadeíta y nefrita (formas minerales del jade) son ejemplos de minerales con esta propiedad. Los minerales que no dejan pasar la luz se denominan opacos.

La diafanidad de un mineral depende del espesor de la muestra. Cuando un mineral es suficientemente delgado (por ejemplo, en una lámina delgada para petrografía) puede llegar a ser transparente, incluso si esa propiedad no se ve en la muestra de mano. Por el contrario, algunos minerales, como la hematita o la pirita son opacos incluso en láminas delgadas.

El color es la propiedad más obvia de un mineral, pero a menudo no sirve para caracterizarlo. Es causada por la radiación electromagnética que interactúa con los electrones (excepto en el caso de incandescencia, que no se aplica a los minerales). Por su contribución en el color, se definen tres grandes clases de minerales:




Algunos metales, como el hierro, pueden ser tanto alocromático como idiocromático: en el primer caso es considerado como una impureza, mientras que en el segundo forma parte intrínseca del mineral coloreado.

El color de algunos minerales puede cambiar, ya sea de manera natural o con un poco de ayuda. Los bajos niveles de radiación, que se dan a menudo en la naturaleza, pueden contribuir a oscurecer algunos minerales incoloros. Los mismos berilos de color amarillo verdoso se tratan artificilamente ahora con calor para darles una coloración más azulada.

Además del simple color del cuerpo, los minerales pueden tener otras propiedades ópticas distintivas que pueden implican variabilidad del color:
 
La raya de un mineral se refiere al color de un mineral en forma de polvo, que puede o no ser idéntico al color de su cuerpo. La forma más común de evaluar esta propiedad se hace con una placa de raya, que está hecha de porcelana y es de color blanco o negro. La raya de un mineral es independiente de los elementos traza o de cualquier alteración de la superficie a causa de la intemperie. Un ejemplo común de esta propiedad se ilustra con la hematita, que es de color negro, plata o rojo en la muestra, pero que tiene una raya de color rojo cereza. a marrón rojizo. La raya es más a menudo distintiva de los minerales metálicos, en contraste con los minerales no metálicos, cuyo color de cuerpo está creada por elementos alocromáticos. La prueba de la raya se ve limitada por la dureza del mineral, ya que los minerales de dureza superior a siete rayan ellos la placa.

Por definición, los minerales tienen una disposición atómica característica y cualquier debilidad de esa estructura cristalina es la causa de la existencia de los planos de debilidad. La rotura del mineral a lo largo de esos planos se denomina exfoliación. La calidad de la exfoliación puede ser descrita en función de cómo de limpia y fácilmente se rompa el mineral; los términos con los que se describen comúnmente esa calidad, en orden decreciente , son «perfecto», «bueno», «distinto» y «pobre». En particular en los minerales transparentes, o en una sección delgada, la exfoliación se puede ver como una serie de líneas paralelas que señalan las superficies planas cuando se ven de lado. La exfoliación no es una propiedad universal de los minerales; por ejemplo, el cuarzo, compuesto por tetraedros de sílice muy interconectados, no tiene ninguna debilidad cristalográfica que le permitiría exfoliarse. Por el contrario, las micas, que tienen una exfoliación basal perfecta, consisten en láminas de tetraedros de sílice que se mantienen juntas muy débilmente .
Como la exfoliación es función de la cristalografía, hay gran variedad de tipos de exfoliación produciéndose en uno, dos, tres, cuatro o seis direcciones. La exfoliación basal en una única dirección es una característica distintiva de las micas. La exfoliación en dos direcciones, denominada prismática, se produce en anfíboles y piroxenos. Los minerales como la galena o la halita tienen exfoliación cúbica (o isométrica) en tres direcciones, a 90°; cuando hay tres direcciones de exfoliación, pero no a 90°, como en la calcita o en la rodocrosita, se denomina exfoliación romboédrica. La exfoliación octaédrica (cuatro direcciones) está presente en la fluorita y en el diamante, y la esfalerita tiene seis direcciones de exfoliación del dodecaedro.

Los minerales con muchas exfoliaciones pueden no romper igual de bien en todas las direcciones; por ejemplo, la calcita tiene buena exfoliación en tres direcciones, pero el yeso solo tiene una exfoliación perfecta en una dirección, y pobre en las otras dos. Los ángulos entre los planos de exfoliación varían entre los minerales. Por ejemplo, dado que los anfíboles son silicatos de cadena doble y los piroxenos son silicatos de cadena única, el ángulo entre sus planos de exfoliación es diferente: los piroxenos exfolian en dos direcciones a aproximadamente 90°, mientras que los anfíboles lo hacen claramente en dos direcciones separadas aproximadamente a 120° y 60°. Los ángulos de exfoliación se pueden medir con un goniómetro de contacto, que es similar a un transportador.

La partición, a veces llamada "falsa exfoliación", es similar en apariencia a la exfoliación pero se produce por defectos estructurales en el mineral en lugar de por una debilidad sistemática. La partición varía de cristal a cristal de un mismo mineral, mientras que todos los cristales de un mineral determinado exfoliaran si la estructura atómica permite tal propiedad. En general, la partición es causada por una cierta tensión aplicada a un cristal. Las fuentes de las tensiones incluyen la deformación (por ejemplo, un aumento de la presión), exsolution o maclado. Los minerales que a menudo muestran partición son los piroxenos, la hematita, la magnetita y el corindón.

Cuando un mineral se rompe en una dirección que no corresponde a un plano de exfoliación, se habla de fractura. Hay varios tipos:


La tenacidad está relacionada tanto con la exfoliación y la fractura. Mientras que la fractura y la exfoliación describen las superficies que se crean cuando el mineral se rompe, la tenacidad describe la resistencia que ofrece el mineral a tal ruptura. Los minerales pueden ser:


La densidad relativa (a veces llamada gravedad específica) describe numéricamente la densidad de un mineral. Las dimensiones de la densidad son unidades de masa divididas por unidades de volumen: kg/m³ o en g/cm³. La densidad relativa mide la cantidad de agua desplazada por una muestra mineral. Se define como el cociente de la masa de la muestra y la diferencia entre el peso de la muestra en el aire y su correspondiente peso en agua; la densidad relativa es una relación adimensional, sin unidades. Para la mayoría de los minerales, esta propiedad no sirve para caracterizarlos. Los minerales que forman las rocas —normalmente silicatos y occasionalmente carbonatos— tienen una densidad relativa de 2.5–3.5.<

Una alta densidad relativa si permite diagnosticar algunos minerales. La variación química (y por consiguiente, en la clase mineral) se correlaciona con un cambio en la densidad relativa. Entre los minerales más comunes, los óxidos y sulfuros tienden a tener una alta densidad relativa, ya que incluyen elementos con mayor masa atómica. Una generalización es que los minerales metálicos o con brillo diamantino tienden a tener densidades relativas más altas que las que tienen los minerales no-metálicos o de brillo mate. Por ejemplo, la hematita, , tiene una densidad relativa de 5.26 mientras que la galena, , tiene una gravedad específica de 7.2–7.6, que es el resultado de su alto contenido en hierro y en plomo, respectivamente. La densidad relativa es muy alta en los metales nativos; la kamacita, una aleación de hierro-níquel común en los meteoritos de hierro, tiene una densidad relativa de 7.9, y el oro tiene una densidad relativa observada entre 15 y 19.3.

Se pueden utilizar otras propiedades para identificar minerales, aunque son menos generales y solo aplicables a ciertos minerales.

La inmersión en ácido diluido (a menudo en HCl al 10%) ayuda a distinguir los carbonatos de otras clases de minerales. El ácido reacciona con el grupo del carbonato ([CO3] 2-), lo que causa que el área afectada sufra efervescencia, con desprendimiento de gas dióxido de carbono. Esta prueba se puede ampliar para poner a prueba el mineral en su forma original de cristal o en polvo. Un ejemplo de esta prueba se realiza para distinguir la calcita de la dolomita, especialmente dentro de las rocas (caliza y dolomía, respectivamente). La efervescencia de la calcita es inmediata en ácido, mientras que para que lo haga la dolomita el ácido debe aplicarse a muestras en polvo o sobre una superficie rayada en una roca. Los minerales de zeolita no sufren efervescencia en ácido; en vez de eso, se vuelven esmerilados después de 5-10 minutos, y si se dejan en ácido durante un día, se disuelven o se convierten en un gel de sílice.

El magnetismo es una propiedad muy notable de ciertos minerales. Entre los minerales comunes, la magnetita muestra esta propiedad con fuerza, y también está presente, aunque no con tanta intensidad, en la pirrotita y la ilmenita.

Algunos minerales también pueden identificarse mediante la prueba del sabor u olor. La halita, NaCl, es la sal de mesa; su homólogo de potasio, la silvita, tiene un sabor amargo pronunciado. Los sulfuros tienen un olor característico, sobre todo cuando las muestras están fracturadas, reaccionando o en polvo.

La radiactividad es una propiedad poco frecuente, aunque algunos minerales pueden integrar elementos radiactivos. Pueden ser constituyentes que los definen, como el uranio en la uraninita, la autunita y la carnotita, o como impurezas traza. En este último caso, la desintegración de los elementos radiactivos daña el cristal mineral; el resultado, denominado "halo radiactivo" o "halo pleocroico", es observable mediante diversas técnicas, en especial en las láminas finas de petrografía.

Dado que la composición de la corteza terrestre está dominada por el silicio y el oxígeno, los elementos con silicatos son, con mucho, la clase de minerales más importante en términos de formación de rocas y diversidad: la mayoría de las rocas se componen en más de un 95% de minerales de silicato, y más del 90% de la corteza terrestre está compuesta por estos minerales. Además de los componentes principales, silicio y oxígeno, son comunes en los minerales de silicato otros elementos comunes en la corteza terrestre, como el aluminio, el magnesio, el hierro, el calcio, el sodio y el potasio. Los silicatos más importantes que forman rocas son los feldespatos, los cuarzos, los olivinos, los piroxenos, los anfíboles, los granitos y las micas.

A su vez, los minerales no-silicatos se subdividen en varias clases por su química dominante: elementos nativos, sulfuros, haluros, óxidos e hidróxidos, carbonatos y nitratos, boratos, sulfatos, fosfatos y compuestos orgánicos. La mayoría de las especies minerales no silicatos son extremadamente raras (constituyen en total un 8% de la corteza terrestre), aunque algunas son relativamente comunes, como la calcita, pirita, magnetita y hematita. Hay dos estilos estructurales principales observados en los no-silicatos: el empaquetamiento compacto y los tetraedros enlazados como aparecen en los silicatos. Las estructuras compactas son una manera de empaquetar densamente átomos y reducir al mínimo el espacio intersticial. El empaquetado compacto hexagonal consiste en apilar capas en las que cada capa es la misma ("ababab"), mientras que el empaquetado cúbico consiste en grupos de apilamiento de tres capas ("abcabcabc"). Análogos a los tetraedros de sílice enlazados son los tetraesdros que forman los iones (sulfato), (fosfato), (arseniato), y (vanadato).

Los minerales no-silicatos tienen una gran importancia económica, ya que concentran más elementos más que lo hacen los minerales de silicato y se explotan especialmente como menas. 

Los silicatos son sales que combinan la sílice con otros óxidos metálicos. La base de la unidad de un mineral de silicato es el tetraedro : en la mayoría de casos, el silicio se encuentra coordinado cuatro veces, o en coordinación tetraédrica, con el oxígeno; en situaciones de muy altas presiones, el silicio estará coordinado seis veces, o en coordinación octaédrica, como en la estructura de perovskita o en el cuarzo polimorfo stishovita (). (En el último caso, el mineral ya no tiene una estructura de silicato, si no de rutilo () y su grupo asociado, que son óxidos simples.) Estos tetraedros de sílice son luego polimerizados en algún grado para crear otras estructuras, como cadenas unidimensionales, láminas bidimensionales o armazones tridimensionales. El mineral de un silicato básico sin polimerización de tetraedros requiere de otros elementos que equilibren la base cargada 4-. En las otras estructuras de silicato son varias las combinaciones de elementos que equilibran esa carga negativa. Es común que el sea sustituido por debido a la similitud en radio iónico y en carga; en otros casos, los tetraedros de forman las mismas estructuras que lo hacían los tetraedros no sustituidos, pero los requisitos del equilibrio de cargas son diferentes.

El grado de polimerización puede ser descrito tanto por la estructura formada como por el número de vértices tetraédricos (u oxígenos de coordinación) compartidos (por el aluminio y el silicio en sitios tetraédricos): los ortosilicatos (o nesosilicatos) no tienen ninguna vinculación de poliedros, así que los tetraedros no comparten vértices; los disilicatos (o sorosilicatos) tienen dos tetraedros que comparten un átomo de oxígeno; los inosilicatos son silicatos en cadena: los de cadena simple tienen dos vértices compartidos y los de cadena doble dos o tres; los filosilicatos forman una estructura de lámina que requiere tres oxígenos compartidos (en el caso de silicatos de cadena doble, algunos tetraedros deben compartir dos vértices en lugar de tres como harían si resultase una estructura de lámina); los silicatos "en armazón" o tectosilicatos, tienen tetraedros que comparten los cuatro vértices; los silicatos de anillo, o ciclosilicatos, solo necesitan tetraedros que compartan dos vértices para formar la estructura cíclica.

Se describen a continuación en orden decreciente de polimerización, las subclases de silicato.

Los tectosilicatos son muy abundantes, constituyendo aproximadamente el 64% de los minerales de la corteza terrestre.
También conocidos como silicatos de "estructura en armazón", tienen el grado de polimerización más alto y tienden a ser químicamente estables como resultado de la fuerza de los enlaces covalentes. Son ejemplos el cuarzo, los feldespatos, los feldespatoides, y las zeolitas. 

Tienen una estructura basada en un entramado tridimensional de tetraedros () con los cuatro vértices ocupados por el ion O compartidos, lo que implica relaciones Z:O=1:2. La Z es silicio (Si) (la fórmula resultante es , sílice), pero parte del puede ser reemplazado por (en raras ocasiones por , y ). Al suceder esto, las cargas negativas resultantes se compensan con la entrada de cationes grandes, como el , el o el (y con menos frecuencia , y ).También pueden tener aniones complementarios F, Cl, S, CO, SO.

El cuarzo () es la especie mineral más abundante, formando el 12% de la corteza terrestre. Se caracteriza por su alta resistividad química y física. Tiene varios polimorfos, incluyendo la tridimita y la cristobalita a altas temperaturas, la coesita a alta presión y la stishovita a ultra-alta presión. Este último mineral solo puede formarse en la Tierra por impacto de meteoritos, y su estructura está tan compuesta que había cambiado de una estructura de silicato a la de rutilo (). El polimorfo de sílice que es más estable en la superficie de la Tierra es el α-cuarzo. Su homólogo, el cuarzo-β, está presente solo a altas temperaturas y presiones (a 1 bar, cambia a cuarzo-α por debajo de 573°C). Estos dos polimorfos difieren en un "retorcimiento" de los enlaces; este cambio en la estructura da al cuarzo-β mayor simetría que al cuarzo-α, y por lo tanto también se les llama cuarzo alto (β) y cuarzo bajo (α).

Los feldespatos son el grupo más abundante en la corteza terrestre, en torno al 50%. En los feldespatos, los sustitutos de los crean un desequilibrio de carga que debe ser explicado por la adición de cationes. La estructura de base se convierte ya en , ya en . Hay 22 especies minerales de feldespatos, subdivididas en dos grandes subgrupos —alcalino y plagioclasa— y dos grupos menos comunes —celsiana y banalsita. Los feldespatos alcalinos son los más comunes en una serie que va desde la entre ortoclasa, rica en potasio, a la albita, rica en sodio; en el caso de las plagioclasas, la serie más común varía desde la albita a la anortita, rica en calcio. El maclado de cristales es común en los feldespatos, especialmente con maclas polisintéticas en las plagioclasas y maclas de Carlsbad en los feldespatos alcalinos. Si el último subgrupo se enfría lentamente a partir de una masa fundida, se forma laminillas de exsolution porque los dos componentes —ortoclasa y albita— son inestables en solución sólida. La exsolution puede darse desde una escala microscópica hasta ser fácilmente observable en la muestra de mano; se forma una textura pertitica cuando un feldespato rico en Na exsolve en un huésped rico en K. La textura opuesta (antipertitica), cuando un feldespato rico en K exsolve en un huésped rico en Na, es muy rara.
Los feldespatoides son estructuralmente similares a los feldespatos, pero se diferencian en que se forman en condiciones de carencia de silicio lo que permite una mayor sustitución por . Como resultado, los feldespatoides no se pueden asociar con cuarzo. Un ejemplo común de un feldespatoide es la nefelina (); comparada con los feldespatos alcalinos, la nefelina tiene una relación : de 1: 2, en lugar de 1:6 en el feldespato.

Las zeolitas a menudo tienen hábitos de cristal distintivos, produciendo agujas, placas o bloques masivos. Se forman en presencia de agua a bajas temperaturas y presiones, y tienen canales y huecos en su estructura. Las zeolitas tienen varias aplicaciones industriales, especialmente en el tratamiento de aguas residuales.

Los filosilicatos son un grupo de minerales muy extendidos en la corteza terrestre, integrantes de muchos tipos de rocas, ígneas, metamórficas y sedimentarias. Las arcillas están formadas fundamentalmente por filosilicatos.

La característica principal de los filosilicatos es su disposición en capas, que ocasiona hábitos típicos fácilmente reconocibles (minerales hojosos o escamosos). Además suelen ser minerales blandos y poco densos.

Los filosilicatos consisten en apilamientos de láminas de tetraedros polimerizados. Las láminas, desde el punto de vista estructural, son de dos tipos: tetraédricas y octaédricas. Los tetraédricas están enlazados a tres sitios de oxígeno, lo que da una relación característica de silicio:oxígeno de 2:5. Ejemplos importantes son la mica, el grupo de las cloritas y los grupos de caolinita-serpentina. Las láminas están débilmente enlazadas por fuerzas de van der Waals o enlaces de hidrógeno, lo que provoca una debilidad cristalográfica, que a su vez conduce a una prominente exfoliación basal entre los filosilicatos. Además de los tetraedros, los filosilicatos tienen una hoja de octaedros (elementos de coordinación seis con oxígeno) que equilibran los tetraedros de base, que tienen una carga negativa (por ejemplo, ) Estas hojas de tetraedros (T) y octaedros (O) se apilan en una gran variedad de combinaciones para crear los distintos grupos de los filosilicatos. En una capa octaédrica, hay tres sitios octaédricos en una estructura única; sin embargo, no todos los sitios pueden estar ocupados. En ese caso, el mineral se denomina dioctahédrico, mientras que en otro caso se denomina trioctaédrico.

El grupo de la caolinita-serpentina consiste en pilas de T-O (minerales de arcilla 1:1); su dureza varía de 2 a 4, cuando las láminas están retenidas por enlaces de hidrógeno. Los minerales de arcilla 2:1 (pirofilita-talco) consisten en pilas T-O-T, pero son más blandos (dureza 1-2), ya que están se mantienen unidos por fuerzas de van der Waals. Estos dos grupos de minerales están divididos en subgrupos según la ocupación octaédrica; específicamente, la caolinita y la pirofilita son dioctaédricos mientras que la serpentina y el talco son trioctaédricos.

Las micas son también filosilicatos T-O-T apilados, pero difieren de los otro miembros de las subclases apiladas T-O-T y T-O en que incorporan aluminio en las láminas tetraédricas (los minerales de arcilla tienen en los sitios octaédricos). Ejemplos comunes de micas son la moscovita y las series de la biotita. El grupo de la clorita se relaciona con el grupo de la mica, pero con una capa similar a la brucita () entre la de las pilas T-O-T.<

A causa de su estructura química, los filosilicatos típicamente tienen capas flexibles, elásticas, transparentes que son aislantes eléctricos y se pueden dividir en escamas muy finas. Las micas se puede utilizar en la electrónica como aislantes, en la construcción, como relleno óptico, o incluso en cosméticos. Crisotila, una especie de serpentina, es la especie mineral más común en el amianto industrial, ya que es menos peligrosa en términos de la salud que los asbestos anfíboles.

Los inosilicatos son metasilicatos que consisten en tetraedros unidos repetidamente en cadenas. Estas cadenas pueden ser simples —cuando un tetraedro está unido a otros dos para formar una cadena continua —o dobles, cuando dos cadenas sencillas se combinan entre ellas. Los silicatos de cadena individuales tienen una relación de silicio:oxígeno de 1:3 (por ejemplo, ), mientras que las variedades de doble cadena tiene una proporción de 4:11, por ejemplo . Los inosilicatos tienen dos importantes grupos de minerales que forman rocas; los piroxenos, generalmente silicatos de cadena simple, y los anfiboles, de cadena doble. Hay cadenas de orden superior (por ejemplo, cadenas de tres, cuatro o cinco miembros) pero son raras.

El grupo de los piroxenos consta de 21 especies minerales. Los piroxenos tienen una fórmula de estructura general (), siendo X un sitio octaédrico e Y otro que puede variar en número de coordinación de seis a ocho. La mayoría de las variedades de los piroxenos consisten en permutaciones de , y que equilibran la carga negativa de la cadena principal. Los piroxenos son comunes en la corteza terrestre (aproximadamente el 10%) y son un componente clave de las rocas ígneas máficas.

Los anfiboles tienen una gran variabilidad química, por ello descritos a veces como un «cesto mineralógico» o un «tiburón mineralógico nadando en un mar de elementos». La columna vertebral de los anfíboles es la ; está equilibradoa por cationes en tres posiciones posibles, aunque la tercera posición no siempre se utiliza y un elemento puede ocupar las restantes. Los anfíboles están generalmente hidratados, es decir, que tienen un grupo hidroxilo (), aunque puede ser reemplazado por un fluoruro, un cloruro, o un ion de óxido. Debido a su química variable, hay más de 80 especies de anfíboles, aunque las variaciones más comunes, como en los piroxenos, implican mezclas de , y . Varias especies minerales de los anfíboles pueden tener un hábito cristalino asbestiforme. Estos minerales de asbesto forman fibras largas, delgadas, flexibles y fuertes, que son aislantes eléctricos, químicamente inertes y resistentes al calor; como tal, tienen varias aplicaciones, especialmente en materiales de construcción. Sin embargo, los asbestos son conocidos carcinógenos, y causan varias enfermedades más, como la asbestosis; los asbestos anfíboles (antofilita, tremolita, actinolita, grunerita y riebeckita) se consideran más peligrosos que el asbesto serpentina crisotilo.

La clase de los ciclosilicatos corresponde a la clase 9.C de la clasificación de Strunz y tiene 16 familias. Está integrada por tres o más tetraedros de [SiO] unidos por sus vértices, formando un anillo cerrado, simple o doble, el cual puede tener enlaces iónicos con un metales como por ejemplo sodio, calcio, hierro, aluminio, potasio, magnesio, etc. Algunos ejemplos de ciclosilicatos son la turmalina, cordierita, rubelita, benitoita, dioptasa, etc.

Los ciclosilicatos, o silicatos de anillo, tienen una relación de silicio a oxígeno de 1:3. Los anillos de seis miembros son los más comunes, con una estructura de base de ; ejemplos del grupo son la turmalina y el berilo. Hay otras estructuras de anillo, habiendo sido descritas las de 3, 4, 8, 9 y 12 . Los ciclosilicatos tienden a ser fuertes, con cristales alargados y estriados. Los anillos pueden ser simples o ramificados, aislados unos de otros o agrupados en dos. Estos anillos están generalmente apilados en la estructura y determinar canales que puede estar vacíos u ocupados por iones o moléculas. Los ciclosilicates se clasifican según el tipo de anillos, y en particular por el número de tetraedros en el anillo. 

Las turmalinas tienen una química muy compleja que puede ser descrita por una fórmula general . El es la estructura básica del anillo, donde T es generalmente , pero pueden ser sustituidos por o . Las turmalinas pueden dividirse en subgrupos por el sitio que ocupe el X, y de ahí se subdividen por la química del sitio W. Los sitios Y y Z pueden acomodar una variedad de cationes, especialmente diversos metales de transición; esta variabilidad en el contenido del metal de transición estructural da al grupo de la turmalina mayor variabilidad en color. Otro ciclosilicato es el berilo, , cuyas variedades incluyen piedras preciosas como la esmeralda (verde) y la aguamarina (azulado). La cordierita es estructuralmente similar al berilo, y es un mineral metamórfico común.

La clase de los sorosilicatos corresponde a la clase 9.B de la clasificación de Strunz y tiene 10 familias, de dos tipos, el de las de las epidotas y el de las idocrasas.

Los sorosilicatos, también denominados disilicatos, tienen un enlace tetraedro-tetraedro en un oxígeno, lo que resulta en una relación de 2:7 de silicio al oxígeno. El elemento estructural común resultante es el grupo . Los disilicatos más comunes son, con mucho, los miembros del grupo de la epidota. Las epidotas se encuentran en diversos entornos geológicos, que van desde las cordilleras oceánicas a los granitos y hasta las metapelitas. Las epidotas se construyen alrededor de la estructura ; por ejemplo, las especies minerales de epidota tiene calcio, aluminio y hierro férrico para equilibrar las cargas: . La presencia de hierro como y ayuda a entender la fugacidad de oxígeno, que a su vez es un factor significativo en petrogénesis.

Otros ejemplos de sorosilicatos son la lawsonita, un mineral metamórfico que forma las facies blueschist (ajuste de zona de subducción con baja temperatura y alta presión), la vesuvianita, que ocupa una cantidad significativa de calcio en su estructura química.

La clase de los ortosilicatos corresponde a la clase 9.A de la clasificación de Strunz y tiene 10 familias con cerca de 120 especies.

Los ortosilicatos consisten en tetraedros aislados que tienen las cargas equilibrada por otros cationes. También denominados nesosilicatos, este tipo de silicatos tiene una relación silicio:oxígeno de 1:4 (por ejemplo, ). Los ortosilicatos típicos tienden a formar bloques de cristales equantes, y son bastante pesados. Varios minerales que forman rocas son parte de esta subclase, como los aluminosilicatos, el grupo del olivino o el grupo del granate.

Los aluminosilicatos —cianita, andalucita, y silimanita, todos — están estructuralmente compuestos por un tetraedro y un en coordinación octaédrica. El restante puede estar en coordinación de seis (cianita), cinco (andalucita) o cuatro (silimanita); qué mineral se forma en un entorno dado depende de las condiciones de presión y temperatura. En la estructura del olivino, la serie principal de olivino consisten en forsterita, rica en magnesio, y fayalita, rica en hierro. Tanto el hierro como el magnesio están en coordinación octaédrica con el oxígeno. Existen otras especies minerales que tienen esta estructura, como la tefroita, . El grupo del granate tiene una fórmula general de , donde X es un gran catión ocho veces coordinado, e Y es un catión menor seis veces coordinado. Hay seis miembros terminales ideales de granate, divididos en dos grupos. Los granates piralspita tienen en la posición Y: piropo (), almandino (), y espesartina (). Los granates ugrandita tienen en la posición X: uvarovita (), grossular () y andradita (). Si bien hay dos subgrupos de granate, existen soluciones sólidas entre los seis miembros finales.

Otros ortosilicatos son el circón, la estaurolita y el topacio. El zirconio () es útil en geocronología ya que el puede ser sustituido por ; además, debido a su estructura muy resistente, es difícil resetearlo como un cronómetro. La estaurolita es un común mineral índice de grado intermedio metamórfico. Tiene una estructura cristalina particularmente complicada que solo fue descrita plenamente en 1986. El topacio (, que se encuentra a menudo en pegmatitas graníticas asociadas con turmalina, piedra preciosa es un mineral común.

Los elementos nativos son aquellos minerales integrados por elementos que no están unidos químicamente a otros elementos. Este grupo incluye minerales metales nativos, semi-metales y no metales, y varias aleaciones sólidas y soluciones. Los metales se mantienen unidos por enlaces metálicos, lo que les confiere propiedades físicas distintivas, como su lustre metálico brillante, ductilidad y maleabilidad, y conductividad eléctrica. Los elementos nativos se subdividen en grupos por su estructura o atributos químicos.

El grupo del oro, con una estructura cercana al empaquetamiento cúbico, incluye metales como el oro, la plata y el cobre. El grupo del platino es similar en estructura al grupo de oro. El grupo del hierro-níquel se caracteriza por tener varias especies de aleaciones de hierro-níquel. Dos ejemplos son la kamacita y la taenita, que se encuentran en meteoritos de hierro; estas especies difieren en la cantidad de Ni en la aleación; la kamacita tiene menos de 5–7% de níquel y es una variedad de hierro nativo, mientras que el contenido de níquel de la taenita es del 7–37%. Los minerales del grupo del arsénico se componen de semi-metales, que tienen solamente algunos metálicos; por ejemplo, carecen de la maleabilidad de los metales. El carbono nativo aparece en dos alótropos, el grafito y el diamante; el último se forma a muy alta presiones en el manto, lo que le confiere una estructura mucho más fuerte que el grafito.

La clase de los minerales sulfuros y sulfosales —denominación engañosa pues los sulfuros solo son una parte del grupo— corresponde a la clase 2 de la clasificación de Strunz y en ella se incluyen: minerales sulfuros —con el ion —-, los seleniuros, teluriuros, arseniuros, antimoniuros, bismutiuros, sulfoarseniuros y sulfosales. Los sulfuros se clasifican por la relación del metal o del semimetal con el azufre, M:S igual a 2:1, o 1:1. A pesar de que los sulfuros son mucho menos abundantes que los silicatos, su química y sus estructuras son muy variadas, lo que explica porque el número de minerales de sulfuro es muy alto en relación a su abundancia.

Se agrupan entre los sulfuros los minerales compuestos de uno o más metales o semimetales con un azufre, que tienen una fórmula de tipo general de , donde M es un metal (Ag, Cu, Pb, Zn, Fe, Ni, Hg, As, Sb, Mo, Hg, Tl, V). Los arseniuros, los antimoniuros, los telurios... se clasifican entre los «sulfuros» "sensu lato" debido a su similitud estructural con los sulfuros.

Los sulfuros minerales se caracterizan por la unión covalente, la opacidad y el brillo metálico; se estudian con el microscopio de reflexión. Los sulfuros tienden a ser blandos y frágiles, con un alto peso específico y la mayoría son semiconductores. Muchos sulfuros en polvo, como la pirita, tienen un olor sulfuroso cuando son pulverizados. Los sulfuros son susceptibles a la intemperie, y muchos se disuelven fácilmente en agua; estos minerales disueltos se pueden después volver a redepositar, lo que crea yacimientos de menas secundarias.
Muchos minerales de sulfuro son importantes económicamente como minerales metálicos; son ejemplos la esfalerita (), una mena de zinc; la galena (), una mena de plomo; el cinabrio (), una mena de mercurio; y la molibdenita (, una mena de molibdeno. La pirita () es el sulfuro que aparece más y se puede encontrar en la mayoría de entornos geológicos. No es, sin embargo, una mena de hierro, pero puede ser oxidada para producir ácido sulfúrico. Relacionados con los sulfuros están las raras sulfosales, en las que un elemento metálico está unido al azufre y a un semimetal, como antimonio, arsénico o bismuto. Al igual que los sulfuros, las sulfosales son típicamente minerales blandos, pesados y frágiles.

La clase de los minerales óxidos e hidróxidos corresponde a la clase 4 de la clasificación de Strunz y en ella se incluyen: óxidos, hidróxidos, vanadatos, arsenitos, antimonitos, bismutitos, sulfitos, selenitos, teluritos y yodatos.

Los minerales óxidos se dividen en tres categorías: óxidos simples, hidróxidos y óxidos múltiples. Los óxidos simples se caracterizan por como anión principal y enlace principalmente iónico. Se pueden subdividir además por la relación del oxígeno a los cationes. El grupo de la periclasa consta de minerales con una relación 1:1. Óxidos con una relación 2:1 incluyen la cuprita () y el hielo de agua. minerales del grupo del corindón tienen una proporción de 2:3, e incluye minerales como el corindón () y la hematita (). Los minerales del grupo del rutilo tienen una proporción de 1:2; la especie del mismo nombre, rutilo () es el principal mena del titanio; Otros ejemplos incluyen la casiterita (, mena de estaño), y pirolusita (, mena de manganeso).

En hidróxidos, el anión dominante es el ion hidroxilo, . Las bauxitas son la mena principal del aluminio, y son una mezcla heterogénea de minerales de hidróxido de diáspora, gibbsita, y bohmita; se forman en áreas con una alta tasa de meteorización química (principalmente condiciones tropicales). Por último, varios óxidos son compuestos de dos metales con oxígeno. Un grupo importante dentro de esta clase son las espinelas, con una fórmula general de . Ejemplos de especies incluyen la propia espinela (), la cromita () y la magnetita (). Esta última es fácilmente distinguible por su fuerte magnetismo, que se produce ya que tiene hierro en dos estados de oxidación (), lo que hace que sea un óxido múltiple en lugar de un óxido simple.

La clase de los minerales haluros corresponde a la clase 3 de la clasificación de Strunz y en ella se incluyen: haluros o halogenuros simples o complejos, con HO o sin ella, así como derivados oxihaluros, hidroxihaluros y haluros con doble enlace.

Los minerales haluros son compuestos en los que un halógeno (flúor, cloro, yodo y bromo) es el anión principal. Estos minerales tienden a ser blandos, débiles, quebradizos y solubles en agua. Los ejemplos más comunes de haluros son la halita (, sal de mesa), la silvita () y la fluorita (). La halita y la silvita se forman comúnmente como evaporitas, y pueden ser minerales dominantes en las rocas sedimentarias químicas. La criolita, , es un mineral clave en la extracción de aluminio a partir de la bauxita; Sin embargo, dado que la única ocurrencia significativa está en Ivittuut, Groenlandia, en una pegmatita granítica, ya agotada, la criolita sintética se puede hacer a partir de la fluorita.

La clase de los minerales carbonatos y nitratos corresponde a la clase 5 de la clasificación de Strunz y en ella se incluyen carbonatos, uranilo-carbonatos y nitratos.

Los minerales carbonatos son aquellos en los que el grupo aniónico principal es un carbonato, . Los carbonatos tienden a ser frágiles, muchos tienen exfoliación romboédrica, y todos reaccionan con ácido. Debido a la última característica, los geólogos de campo a menudo llevan ácido clorhídrico diluido para distinguir los carbonatos de los no-carbonatos. La reacción del ácido con los carbonatos, que se encuentra más comúnmente como los polimorfos calcita y aragonita (), se refiere a la disolución y precipitación del mineral, que es un elemento clave en la formación de las cuevas de caliza —con elementos como estalactitas y estalagmitas— y los accidentes geográficos kársticos. Los carbonatos se forman con mayor frecuencia en forma de sedimentos biogénicos o químicos en ambientes marinos. El grupo carbonato es estructuralmente un triángulo, donde un catión central de está rodeado por tres aniones ; diferentes grupos de minerales se forman a partir de diferentes disposiciones de estos triángulos.

El mineral de carbonato más común es la calcita, que es el componente principal de la sedimentaria caliza y del mármol metamórfico. La calcita, , puede tener una impureza de alto contenido en magnesio; en condiciones de alto magnesio, se formará en su lugar su polimorfo, la aragonita; la geoquímica marina se puede describir, en este sentido, como un mar de aragonito o mar de calcita, dependiendo de qué mineral se forme preferentemente. La dolomita es un carbonato doble, de fórmula . La dolomitization secundaria de la caliza es común, en la que la calcita o la aragonita se convierten en dolomita; esta reacción aumenta el espacio de los poros (el volumen de la celda unidad de la dolomita es el 88% del de la calcita), lo que puede crear un yacimiento de petróleo y gas. Estas dos especies minerales son miembros de los grupos de minerales del mismo nombre: el grupo de la calcita incluye carbonatos con fórmula general y el de la dolomita la de .

La clase de los minerales sulfatos corresponde a la clase 7 de la clasificación de Strunz y en ella se incluyen: sulfatos, selenatos, teluratos, cromatos, molibdatos y wolframatos.
Los minerales sulfatos tienen todos el anión sulfato, . Tienden a ser de transparentes a translúcidos, blandos, y muchos son frágiles. Los minerales de sulfato se forman comúnmente como evaporitas, donde se precipitan de la evaporación de las aguas salinas; alternativamente, los sulfatos también se pueden encontrar en los sistemas de vetas hidrotermales asociados con sulfuros, o como productos de oxidación de sulfuros. Los sulfatos se pueden subdividir en minerales anhidros e hidratados. El sulfato hidratado más común, con mucho, es el yeso, ⋅. Se forma como un evaporita, y se asocia con otros evaporitas como la calcita y la halita; si incorpora granos de arena cuando cristaliza, el yeso puede formar rosas del desierto. El yeso tiene muy baja conductividad térmica y mantiene una temperatura baja cuando se calienta a medida que pierde el calor por deshidratación; como tal, el yeso se utiliza como aislante en materiales de construcción. El equivalente anhidro del yeso es la anhidrita; se puede formar directamente de agua de mar en condiciones muy áridas. El grupo de la barita tiene la fórmula general , donde X es un catión grande 12-enlazado. Son ejemplos la barita (), la celestina (), y la anglesita (); la anhidrita no es parte del grupo de la barita, ya que el más pequeño sólo tiene enlace ocho veces.

La clase de los minerales fosfatos corresponde a la clase 8 de la clasificación de Strunz y en ella se incluyen fosfatos, arseniatos y vanadatos. Son 51 familias agrupadas en 7 divisiones, un grupo grande y diverso, que sin embargo, tiene solo unas pocas especies relativamente comunes. 

Los minerales fosfatos se caracterizan por el anión fosfato coordinado tetraédricamente , aunque la estructura se puede generalizar siendo el fósforo sustituido por antimonio (), arsénico (), o vanadio (). Los aniones de cloro (), flúor () e hidróxido () también encajan en la estructura cristalina. 

El fosfato más común es el grupo de la apatita, un nombre genérico que designa fosfatos hexagonales de composición bastante variable, . Las especies más comunes del grupo son la fluorapatita (), la clorapatita () y la hidroxiapatita (). Los minerales de este grupo son los principales constituyentes cristalinos de los dientes y de los huesos de los vertebrados.

Otro grupo relativamente abundante es el grupo de la monacita, que tiene una estructura general de , donde T es el fósforo o arsénico, y A es, a menudo, un elemento de las tierras raras. La monacita es importante en dos sentidos: en primer lugar, como "sumidero" de tierras raras, puede concentrar la cantidad suficiente de estos elementos para convertirse en una mena; en segundo lugar, los elementos del grupo de la monacita pueden incorporar cantidades relativamente grandes de uranio y torio, que pueden ser utilizadas para datar una roca basándose en la desintegración del U y Th en plomo.

La clase de los minerales compuestos orgánicos corresponde a la clase 10 de la clasificación de Strunz y en ella se incluyen sales y ácidos orgánicos que aparezcan en minas y los hidrocarburos. Son 7 familias agrupadas en 3 divisiones, un grupo escaso.

Estos raros compuestos contienen carbono orgánico, pero se pueden formar también medianteun proceso geológico. Por ejemplo, la whewellita, ⋅ es un oxalato que se puede depositar en las venas de menas hidrotermales. Mientras el oxalato de calcio hidratado se puede encontrar en las vetas de carbón y en otros depósitos sedimentarios que comprenden materia orgánica, la ocurrencia hidrotérmica no se considera que está relacionada con la actividad biológica.

Los minerales tienen gran importancia por sus múltiples aplicaciones en los diversos campos de la actividad humana. 
La industria moderna depende directa o indirectamente de los minerales.

Algunos minerales se utilizan prácticamente tal como se extraen; por ejemplo el azufre, el talco, la sal de mesa, etc. Otros, en cambio, deben ser sometidos a diversos procesos para obtener el producto deseado, como el hierro, cobre, aluminio, estaño, etc. Los minerales constituyen la fuente de obtención de los diferentes metales, base tecnológica de la sociedad actual. Así, de distintos tipos de cuarzo y silicatos, se produce el vidrio. Los nitratos y fosfatos son utilizados como abono para la agricultura. Ciertos materiales, como el yeso, son utilizados profusamente en la construcción. Los minerales que entran en la categoría de piedras preciosas o semipreciosas, como los diamantes, topacios, rubíes, se destinan a la confección de joyas.

Se ha sugerido que los biominerales podrían ser indicadores importantes de vida extraterrestre y que por lo tanto podrían jugar un papel importante en la búsqueda de vida pasada o presente en el planeta Marte. Por otra parte, se cree que los componentes orgánicos (biofirmas), que a menudo se asocian con los biominerales, juegan un papel crucial tanto en reacciones pre-bióticas como bióticas.

El 24 de enero de 2014, la NASA informó que los estudios actuales de los rovers "Curiosity" y "Opportunity" en Marte estarán ahora destinados a la búsqueda de evidencia de vida antigua, incluyendo una biosfera basada en microorganismos autótrofos, quimiótrofos y/o quimiolitoautotróficos, así como en agua antigua, incluyendo ambientes fluvo-lacustres (llanuras relacionadas con antiguaos rios o lagos) que pueden haber sido habitables. La búsqueda de evidencia de habitabilidad, tafonomía (relacionada con los fósiles), y el carbono orgánico en el planeta Marte son ahora un objetivo primordial de la NASA.





</doc>
