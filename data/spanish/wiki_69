<doc id="15381" url="https://es.wikipedia.org/wiki?curid=15381" title="Persecución a los cristianos">
Persecución a los cristianos

Numerosos cristianos han sufrido persecuciones por parte de no cristianos e incluso de otros cristianos de creencias diversas o más o menos estrictas durante la historia del cristianismo. 

Tales persecuciones tienen o tuvieron varios grados de intensidad, desde el arresto sin garantías, la mengua de derechos públicos, el encarcelamiento, el azotamiento y la tortura, hasta la ejecución, llamada martirio, pasando por el pago de un impuesto suplementario —como el caso de los mozárabes—, la confiscación de sus bienes o incluso la destrucción de sus propiedades, su arte, sus libros y sus símbolos o la incitación a abjurar de sus principios y delatar a otros cristianos.

El "Nuevo Testamento" dice que los primeros cristianos, comenzando por el propio Jesús, sufrieron persecución a manos de los jefes judíos de esa época. También relata el principio de persecuciones por los romanos. El término «los cristianos» es usado con frecuencia en una forma indiscriminada que ha sido causa de controversia.

Según el "Nuevo Testamento", la persecución de los primeros cristianos continuó después de la muerte de Jesús. Pedro y Juan fueron encarcelados por los jefes judíos, incluido el sumo sacerdote Ananías, quien no obstante los liberó más tarde (Hechos 4:1-21). En otro momento, todos los apóstoles fueron encarcelados por el sumo sacerdote y otros saduceos, pero fueron liberados por un ángel (Hechos 5:17-18). Los apóstoles, tras haber escapado, fueron llevados nuevamente ante el Sanedrín, pero esta vez Gamaliel, un rabino fariseo bien conocido de la literatura rabínica, convenció al Sanedrín de liberarlos (Hechos 5:27-40).

La razón más probable de la persecución fue, por parte de los judíos, la evidente herejía que representaba la doctrina cristiana desde un punto de vista de la doctrina tradicional judía, ya que entre otras cosas, la idea de un Dios-Hombre chocaba de frente con su arraigado monoteísmo (esto se percibe claramente en la narración bíblica de los hechos de los primeros cristianos). Es deducible además que a oídos romanos, la predicación de los cristianos sobre el inminente regreso del rey de los judíos y el establecimiento de su reino, era sediciosa. Los romanos dieron a los judíos en ese tiempo un autogobierno limitado; las principales obligaciones de los líderes judíos eran recolectar impuestos para Roma y mantener el orden civil. Así, los líderes judíos tendrían que suprimir cualquier tesis sediciosa, como las que defendían los cristianos. Esta oposición judía fue un potente motor para plantar en Roma la semilla del odio al incipiente cristianismo.

El "Nuevo Testamento" relata la lapidación de Esteban (Hechos 6:8-7:60) por miembros del Sanedrín. Esteban es recordado en el cristianismo como el primer mártir (del griego: "mártÿros", ‘testigo’).

La ejecución de Esteban fue seguida de una gran persecución de cristianos (Hechos 8:1-3), dirigida por un fariseo llamado Saulo Pablo de Tarso, enviando a muchos cristianos a prisión. Según el "Nuevo Testamento", esta persecución continuó hasta que Saulo se convirtió al cristianismo (y cambió su nombre a Pablo), tras decir que había visto una luz brillante y oído la voz de Jesús en el camino hacia Damasco, donde estaba viajando para encarcelar a más cristianos (Hechos 9:1-22).

Hechos 9:23-25 dice que «los judíos» en Damasco trataron entonces de matar a Pablo. Estaban esperándole en las puertas del pueblo, pero los evadió al ser bajado sobre el muro de la ciudad en una canasta por otros cristianos y luego escapó hacia Jerusalén. Comprensiblemente, tuvo dificultad al principio para convencer a los cristianos de Jerusalén que él, su antiguo perseguidor, se había convertido y de que ahora estaba siendo perseguido a su vez (Hechos 9:26-27). Otro atentado se hizo contra su vida, esta vez por «los grecianos» (KJV), refiriéndose a un grupo de judíos helenistas (Hechos 9:29), a quienes él debatió mientras estaban dentro y alrededor de Jerusalén.

Al principio, los romanos consideraron el cristianismo como una nueva secta judía. Aparte de las esporádicas persecuciones de Nerón y Domiciano, durante el siglo I los cristianos tuvieron que enfrentarse con mayor frecuencia con la animadversión de los escribas y fariseos, rectores del judaísmo, que con las autoridades romanas. 

Sobre la base de diversos testimonios se afirma que durante la segunda mitad del siglo I, todo el siglo II y hasta el siglo IV, los cristianos fueron también perseguidos por autoridades del Imperio romano, que consideraba a los cristianos, ya sea como judíos sediciosos (recordando que en el año 70 los judíos armaron una revuelta en Judea que originó la destrucción de Jerusalén y la deportación de los judíos de su territorio a manos romanas), o como rebeldes políticos. El historiador Suetonio menciona las revueltas causadas en Roma en tiempo del emperador Claudio «por un tal Cresto», a quien cabe identificar con Cristo, cuyas doctrinas debían haber sido divulgadas por emigrantes o esclavos judíos en Roma. Asimismo, Tácito en sus "Anales" habla de la persecución a los cristianos («nombre que toman de un tal Cristo»), por parte de Nerón.

Tertuliano, en su "Apología contra los gentiles", escrita en el año 200, explica cuáles eran los delitos que la fama imputaba a los cristianos: 
Los gentiles asimilaban las reuniones nocturnas de los cristianos a ritos orientales de los «misterios», como los de Eleusis y Samos, enraizados en las prácticas mágicas, los misterios de Cibeles, los de Isis, originarios de Egipto, o los de Mitra, procedentes de Persia, que alcanzaron notable difusión incluso en España y en especial en la costa catalana.

En este contexto, hay que recordar que se hizo costumbre entre varios emperadores romanos el erigir estatuas propias en las diversas ciudades del imperio, y en autoproclamarse dioses o hijos de dioses (bajo el título de señor de señores) a los que sus súbditos debían de respetar. Un signo ejemplar de esto era la obligación de adorar o cuando menos arrodillarse ante las estatuas de los emperadores en las ciudades donde se encontraran. 

Los cristianos, tomando como principio el que Jesús es el único Señor de señores, y el único hijo del Dios verdadero, se negaban a tomar tales actitudes. Los romanos, antes que juzgar sus creencias, verían en estos gestos las actitudes de una rebelión política contra el imperio, lo cual originó varias persecuciones contra los cristianos en esa época. Los componentes ideológicos potencialmente subversivos de las doctrinas y costumbres cristianas debieron ser tomadas como una amenaza para el estatus quo del orden social romano y una amenaza, sobre todo para las clases privilegiadas de ese orden. 

Tal es el caso de la creencia en la filiación divina de toda la humanidad («Todos somos hijos de Dios») que implicaba la hermandad universal («todos somos hermanos») y la dignidad humana («cualquier cosa que le hicierais al más pequeño de ellos es como si me lo hicierais a mí»), un alegato a favor de la igualdad que chocaba frontalmente con una sociedad esclavista. También el alegato contra la riqueza y las prácticas comunistas de los primeros cristianos (que ponían a disposición de la «comunidad» todos sus bienes cuando entraban a formar parte de ella) debieron resultar amenazadores para los poderosos y privilegiados del imperio. El cristianismo fue inicialmente una religión dirigida a los humildes, a los que sufren injusticia, los pobres y a los esclavos, los grupos sociales más numerosos en un imperio en crisis, y entre los que se extendió rapidísimamente a pesar de los esfuerzos de las autoridades por evitarlo.

Hubo diez grandes persecuciones romanas contra el Cristianismo, denominadas generalmente con el nombre de los emperadores que las decretaron: las de Nerón, Domiciano, Trajano, Marco Aurelio, Septimio Severo, Maximiano, Decio, Valeriano, Aureliano y Diocleciano. 

Puesto que el cristianismo era considerado ilegal en el imperio, los cristianos debían ocultarse. Sus reuniones serían entonces secretas y son famosas las catacumbas de la ciudad de Roma, donde se dice que los cristianos se reunían, aunque según los testimonios cristianos conservados, las catacumbas no eran el medio más utilizado para esconderse, ya que la mayor parte de las reuniones de culto, se haría secretamente en las mismas casas de los fieles. Para identificarse habrían utilizado símbolos que a ojos romanos no fueran evidentes, como el símbolo del Pez (Ichthys, o IXΘΥΣ en griego), acrónimo que significaba para ellos "Iēsoûs CHristós THeoû hYiós Sōtér", 'Jesucristo, Hijo de Dios, Salvador'.

Una de las más conocidas e implacables y quizá la más temprana es la originada por el emperador Nerón, en torno al cual se originó la leyenda de su autoría del incendio que acabó con varios barrios de la ciudad de Roma. El historiador Cornelio Tácito escribió a principios del siglo II que ante el rumor popular de que el incendio se había originado por orden superior, halló en los cristianos los chivos expiatorios que en principio satisficieron la ira del pueblo. Fueron cruelmente reprimidos, según los "Anales" de Tácito. Suetonio, otro escritor prominente de principios del siglo II corrobora la versión, señalando que entre las obras públicas de Nerón se contaba «persiguió a los cristianos». Esta sería una de las razones que habrán llevado a cristianos como Pedro o Pablo a la muerte en Roma, de lo que hablan escritores cristianos de los primeros siglos como Clemente I.

Otro emperador que se recuerda por su crueldad con los cristianos fue Domiciano, entre los años 81 y 96. Entre los numerosos cristianos martirizados durante esta persecución estaban Simeón, obispo de Jerusalén, que fue crucificado. Flavia, hija de un senador romano, fue asimismo desterrada al Ponto; y se dictó una ley diciendo: «Que ningún cristiano, una vez traído ante un tribunal, quede exento de castigo sin que renuncie a su religión».

Entre 109 y 111 dC, Plinio el Joven fue enviado por el emperador Trajano (98-117) a la provincia de Bitinia como gobernador. Durante su mandato, Plinio encuentra a los cristianos, y escribe al emperador sobre ellos. El gobernador indicó que había ordenado la ejecución de varios cristianos. Sin embargo, no estaba seguro de qué hacer con aquellos que dijeron que ya no eran cristianos, y pidió consejo a Trajano. El emperador respondió que los cristianos no deben ser buscados y que las acusaciones anónimas deben ser rechazadas como una muestra «indigna de nuestra época», y si se retractan y «adoran a nuestros dioses», deben ser liberados. Los que persistan, sin embargo, deben ser castigados.

Parte del problema que los cristianos tuvieron durante esta época, fue mayormente provocada por el populacho, que saqueó a las comunidades cristianas de Asia Menor fundadas por el Apóstol Pablo. Sin embargo, la condena de Marco Aurelio al cristianismo, tuvo repercusiones tan conocidas como la condena a muerte de Justino, que ocurrió durante esta época. La Persecución de Lyon, que fue precedida por la violencia colectiva incluyendo asaltos, robos y lapidaciones (Eusebio, Historia eclesiástica 5.1.7), provocó la aniquilación de la floreciente cristiandad de esta ciudad (según se dijo, por ateísmo e inmoralidad). Otros cristianos conocidos fueron torturados y martirizados en este momento, como Potino o Blandina

Otro emperador bajo quien los cristianos sufrieron fue Septimio Severo, que gobernó desde el 193-211. Durante su reinado, Clemente de Alejandría dejó escrito: «Muchos mártires son quemados a diario, confinados o decapitados, ante nuestros ojos».

Septimio Severo usó la persecución como pretexto para atribuir a los cristianos la peste y el hambre que asolaban el imperio; en esta persecución, especialmente violenta, sufrieron martirio Santa Cecilia y su esposo Valeriano y tuvo lugar el famoso episodio de la Legión fulminante. 

El emperador Severo quizás no estaba personalmente en contra de los cristianos, pero la iglesia estaba ganando poder y la adhesión masiva de fieles condujo al sentimiento popular anti-cristiano y su persecución en Cartago, Alejandría, Roma y Corinto aproximadamente entre 202 y 210.

En el año 202 Septimio promulgó una ley que prohibió la difusión del cristianismo y el judaísmo. Este fue el primer decreto universal prohibiendo la conversión al cristianismo. Estallaron violentas persecuciones en Egipto y África del Norte. Leonidas, defensor del cristianismo, fue decapitado; su hijo Orígenes fue perdonado porque su madre escondió su ropa. Una joven fue cruelmente torturada y luego quemada en una caldera de brea ardiente con su madre. Perpetua y Felicidad fueron martirizadas durante este tiempo, al igual que muchos estudiantes de Orígenes de Alejandría.

Maximino el Tracio inició una persecución dirigida principalmente contra los jefes de la Iglesia en el año 235. Una de sus primeras víctimas fue Ponciano, que con Hipólito fue desterrado a la isla de la Cerdeña.

La persecución de Decio arrojó numerosos eremitas a los bosques; entre sus mártires se cuentan el papa San Fabián y Santa Águeda; el célebre Orígenes sufrió tales tormentos que murió después a consecuencia de ellos. La persecución de los cristianos se extendió a todo el Imperio durante el reinado de Decio y marcó de forma duradera a la iglesia cristiana.

En enero de 250, Decio publicó un edicto por el que se requería que todos los ciudadanos hicieran un sacrificio para mayor gloria del emperador en la presencia de un oficial romano y así obtener un certificado (Libellus) que demostrara que lo habían hecho. En general, la opinión pública condenaba la violencia del gobierno y se admiraba de la resistencia pasiva de los mártires con lo que el movimiento cristiano se fortaleció. La persecución de Decio cesó en 251, pocos meses antes de su muerte.

La persecución de Decio tuvo repercusiones duraderas para la iglesia: ¿Cómo deben ser tratados los que habían comprado un certificado o había hecho realmente el sacrificio? Parece que en la mayoría de las iglesias, los apóstatas fueron aceptados de nuevo al seno de la iglesia, pero algunos grupos se les negó la entrada a la iglesia. Esto plantea importantes cuestiones acerca de la naturaleza de la Iglesia, el perdón, y el alto valor del martirio. Un siglo y medio más tarde, san Agustín discutió con un influyente grupo llamados Donatistas, que se separó de la Iglesia Católica porque ésta abrazó a los que se habían acobardado.

Gregorio de Tours glosa las persecuciones en su "Historia de los francos":

Los escritos de Cipriano, obispo de Cartago, arrojan luz sobre las consecuencias de la persecución de Decio en la comunidad cristiana cartaginesa.

Bajo el reinado de Valeriano, que subió al trono en 253, todos los clérigos cristianos fueron obligados a sacrificar a los dioses romanos. En un edicto de 257, el castigo fue el exilio, en 258, el castigo era la muerte. Senadores cristianos, caballeros y damas fueron también obligados a sacrificar, bajo pena de fuertes multas, reducción de rango y, más tarde, la muerte. Por último, se prohibió a todos los cristianos visitar sus cementerios. Entre los ejecutados por Valeriano se encuentran: San Cipriano, obispo de Cartago, y Sixto II, obispo de Roma. Según una carta escrita por Dionisio durante este tiempo, «hombres y mujeres, jóvenes y ancianos, doncellas y matronas, soldados y civiles, de toda edad y raza, algunos por la flagelación y el fuego, otros por la espada, han conquistado en la lucha y ganado sus coronas». La persecución terminó con la captura de Valeriano por Persia. Su hijo y sucesor Galieno, revocó los edictos de su padre.

Una orden de arrestar a un cristiano, de fecha 28 de febrero 256, se encontró entre los Papiros de Oxirrinco (P. Oxy 3035). En el documento no se detallan los motivos de la detención.

La persecución de Diocleciano fue la más grave, pues este quiso reformar el imperio en todos los aspectos y una parte muy esencial de su política era reforzar el culto imperial. Fue instigado a ella por los césares Maximiano y Galerio; hasta ciudades enteras cristianas fueron arrasadas. Fue tan larga esta persecución que fue llamada la Era de los mártires, y entre los más célebres se cuentan varios papas, San Sebastián, San Pancracio y Santa Inés.

Juliano el Apóstata fue el último emperador pagano del Imperio romano. Se crio en un momento en que el paganismo estaba en declive, en Roma. Al ser proclamado augusto en el año 361, Juliano de inmediato declaró su fe a los antiguos dioses romanos y buscó provocar un renacimiento pagano. Sin embargo, fue asesinado en Persia en el año 363 y su intento de restaurar el paganismo finalmente fracasó.

Juliano utilizó muchos métodos para romper sutilmente la Iglesia. Recordó a los obispos que habían sido desterrados por las enseñanzas heréticas, el clero fue despojado de su derecho a viajar por cuenta del Estado (como lo habían hecho anteriormente) y prohibió a los cristianos enseñar obras clásicas tales como la "Ilíada" o la "Odisea". Juliano fue sustituido por el emperador cristiano Joviano.

En el transcurso de la descristianización de Francia durante la Revolución de ese país, se dieron las primeras persecuciones a los cristianos en la época moderna, considerándose mártires a cientos de sacerdotes y religiosos que fueron asesinados en ese periodo de la historia, como en las llamadas Masacres de septiembre y los 191 Mártires de París en la Revolución Francesa (1792).
Se considera que el primer genocidio moderno se produjo en La Vendée, al oeste de Francia, cuando en 1793 los jacobinos anticlericales de la Revolución mataron a miles de campesinos católicos considerados como contrarrevolucionarios. En 1794, durante el período conocido como «El Terror», se guillotinaron 16 monjas en Compiègne por negarse a renunciar a sus votos monásticos (años después este hecho inspiró la obra "Diálogos de Carmelitas"). Un mes antes corrieron la misma suerte cuatro monjas de Arras Hijas de la Caridad de San Vicente de Paúl, mientras ejercían su misión caritativa, son conocidas como las Martíres de Cambrai. 

Una de las mayores persecuciones contra los cristianos de la historia moderna tuvo lugar en Vietnam a lo largo del periodo que va desde 1625 hasta 1886. Se calcula que en esos años fueron asesinados unos 130 000 cristianos.

Según diversos estudios, en el siglo XX habrían sido asesinados unos 45 millones de cristianos.

En España, desde 1934 a 1939 —periodo que va desde la revolución de octubre hasta la Guerra Civil Española—, se contabilizan alrededor de 10 mil católicos (sacerdotes, religiosos y laicos) asesinados por motivos religiosos. Esta persecución, por su intensidad, ha podido ser calificada la mayor de toda la historia del cristianismo:

En 2001 el número de cristianos asesinados por motivos de su fe sería superior a 160 mil.

Entre los años 2003 y 2009, según informó Asianews en diciembre de 2009, habrían sido asesinados alrededor de 2000 cristianos en Irak. A causa de la inestabilidad y de los ataques dirigidos contra cristianos, muchos de ellos han huido a otros territorios: de los cerca de 800 mil cristianos que había en 2003, se calcula que quedan 450 mil en 2010.

Por lo que se refiere a la India, entre 2008 y 2010 se registraron más de 1000 episodios anticristianos en el estado de Karnataka, según se informó en marzo de 2010. En el estado de Orissa, entre los años 2008 y 2010, más de 4000 cristianos sufrieron persecución y presiones para convertirse a la religión hindú. 

Según unas declaraciones de Mario Mauro en agosto de 2010, que fungía entonces como representante de la OSCE contra la discriminación de los cristianos, de 100 personas que mueren al año por persecución religiosa, 75 serían cristianos. Ese mismo mes de agosto de 2010, monseñor Mario Toso, Secretario del Consejo Pontificio para la Justicia y la Paz, declaró que los cristianos eran el grupo religioso más perseguido en el mundo. Habría, según los datos de ese año, unos 200 millones de cristianos en situaciones de persecución. En cambio, según un informe publicado también en 2010 por la Comisión de las Conferencias Episcopales Europeas, el número de cristianos perseguidos estaría en torno a la cifra de 100 millones.

En cuanto al número de cristianos muertos anualmente por su fe, según una declaración hecha pública en junio de 2011 por Massimo Introvigne, representante de la Organización para la Seguridad y la Cooperación en Europa (OSCE) para la lucha contra la intolerancia y la discriminación contra los cristianos, se trataría de 105 000 muertos al año. La cifra fue puesta en discusión en 2013, sea por la modalidad en la que se obtuvo, sea por lo elevado de la misma. Según otro estudio, el número de cristianos asesinados anualmente durante la primera década del siglo XXI sería de 10 000.

En el presente, se registran ejemplos de intolerancia o persecución hacia cristianos particularmente en países de África, entre ellos, Egipto, Marruecos, Nigeria, Kenia, República Centroafricana, y en Asia, en países como Pakistán, Indonesia, regiones de la India, Laos, y hasta en Arabia Saudita, donde la apertura de templos cristianos está prohibida.





</doc>
<doc id="15382" url="https://es.wikipedia.org/wiki?curid=15382" title="Patrística">
Patrística

La patrística es el estudio del cristianismo de los primeros siglos y de sus primeros autores conocidos como padres de la Iglesia. La palabra deriva de la forma combinada del latín "pater" y del griego "patḗr" (padre). Se considera que el periodo corre desde la parte final del Nuevo Testamento, específicamente desde los Hechos de los Apóstoles (año 100 DC) y hasta 451 (la fecha del Concilio de Calcedonia), o hasta el Segundo Concilio de Nicea, del siglo VIII. En su contenido ideológico, la patrística se caracterizó por ser el periodo en que se gestó el contenido doctrinal de las creencias religiosas cristianas, así como su defensa apologética contra los ataques de las religiones paganas primero, y sucesivamente de las interpretaciones que dieron lugar a las herejías, después. Para ser reconocido un padre de la Iglesia, era necesario reunir las siguientes condiciones: 

La religión cristiana encontró en la filosofía griega los argumentos para justificar su doctrina, pues la religión cristiana era para los padres de la Iglesia la expresión cumplida y definitiva de las verdades que la filosofía griega había logrado encontrar de manera imperfecta y parcial."En efecto, el "logos" que se hizo carne en Cristo y que se tiene en la palabra por Él revelada plenamente a los hombres, es la misma en la cual se inspiraron los filósofos paganos e intentaron traducir en sus especulaciones".

Durante este tiempo surgieron figuras destacadas en defensa de la nueva fe cristiana. En torno de la comunidad de Alejandría, en Egipto, gran centro cultural del mundo romano, se formó una escuela en la que brillaron Clemente de Alejandría (150-215) y su discípulo Orígenes (185-254): cabe mencionar que la comunidad de Alejandría estaba en contra de las herejías gnósticas; Filón y Clemente de Alejandría fueron pieza clave para esta aportación. Basados en las filosofías griegas, se introdujeron en el modo de pensar de bastantes personas. Clemente de Alejandría era escuchado por ricos y pobres, personas de clase alta, políticos, etc. y por gente humilde; se dice que se sabía de memoria los diálogos de Platón y hacía continuo uso de ellos.

Orígenes escribió numerosas obras (unas 800) y aunque incurrió en algunos errores graves, debido a su intento de "explicar" orgánicamente todas las dificultades que pudieran presentarse ante la reflexión de las creencias cristianas, en unos momentos en que el dogma no estaba todavía fijado por completo, no cabe atribuir su actitud a afán polémico o sensacionalista, sino a un íntimo deseo de aprehender toda la verdad. Este afán común a muchos espíritus cultos de la época llevó a polémicas apasionadas. De la pasión que se vertía en los escritos polémicos de los primeros siglos de la Iglesia, podrán dar idea las siguientes palabras de Zonaro referentes a la persecución de Decio: 

Dos grandes personalidades del África noroccidental fueron el presbítero Tertuliano (160-245), originario de Cartago, y su discípulo el obispo San Cipriano (160-258), de Cartago también, decapitado en la persecución de Valeriano. 

Tertuliano, iniciado en el culto de Mitra cuando joven, debió convertirse después al cristianismo y luego pasó (213) al montanismo, creencia considerada entonces herejía, predicada por el frigio Montano, enemigo de la Iglesia jerarquizada. Tertuliano fue un rigorista extremado.

San Cipriano, retórico convertido al cristianismo en edad madura, es un asceta y un moralista, pero es sobre todo un espíritu práctico. Dos problemas le preocupan en especial: el de los lapsi cristianos asustadizos que ante la persecución negaban su condición de tales y prestaban adoración al emperador (a quienes considera readmisibles en el seno de la Iglesia mediante ciertas condiciones), y el de los bautizados por los considerados herejes (que no cree lo estén en realidad). 

Una de las obras de San Cipriano, escrita en 251 con ocasión del cisma provocado en Roma por Novaciano al negar a la Iglesia el derecho a readmitir a los lapsi en la comunión de los fieles, se titula "La Unidad de la Iglesia católica", y en ella advierte que no todos los peligros derivan de la persecución: "no hay que temer únicamente la persecución o todo aquello que con descubierta acometida se dirige a derribar y derrotar a los siervos de Dios; cuando el peligro está a la vista, es más fácil la cautela, y cuando el adversario se declara, el ánimo se apresta de antemano al combate. Hay que temer sí y guardarse más del enemigo cuando se presenta a escondidas, cuando engañando con cara de paz, se arrastra con paso oculto" (cap. I). "¿Y qué cosa más astuta y sutil, que el enemigo encubierto y apostado junto a la senda de Cristo (...) tramara un nuevo engaño, como el de engañar a los incautos con el mismo título de nombre cristiano? Inventó, pues, herejías y cismas, con los cuales destruye la fe, corrompe la verdad, rompe la unidad". "Todo esto sucede", sigue diciendo Cipriano, "por no volver al origen de la verdad, por no buscar la cabeza" (cap. III). Y recuerda entonces las palabras de Jesucristo a San Pedro cuando cimentó en él su iglesia. "Sobre uno únicamente, insiste, edifica su iglesia". "Quien no se cuenta en esta unidad de la Iglesia ¿cree que tiene la fe?". 






</doc>
<doc id="15383" url="https://es.wikipedia.org/wiki?curid=15383" title="Simbolismo cristiano">
Simbolismo cristiano

La definición y preservación de los dogmas de la fe exigía mucha cautela en un ambiente tan diverso y tan presto al sincretismo como el del Imperio romano en aquellos siglos. Los catecúmenos se habían dividido en dos grupos: oyentes (audientes), que deseaban iniciarse en la fe, entre los cuales no faltaban a veces espías a sueldo, pero que demoraban el bautismo, y elegidos ("electi"), que se preparaban ya para su ingreso en la comunidad cristiana. Unos y otros, aunque más formados estos últimos, debían mantenerse al margen de los ritos reservados para los iniciados y en especial del "misterio" de la carne y la sangre del Verbo de Dios. De aquí que, para reconocerse, los fieles "iniciados" utilizaran símbolos.

Algunos autores consideran que algunos símbolos pudieran ser derivados de la mitología antigua. El pavo y el ave Fénix simbolizan la resurrección. La palma la victoria. La paloma la sencillez cristiana, el pudor y la paz concedida al alma fiel. El ciervo, el servidor diligente de Cristo. El áncora, la esperanza en la salvación. La nave, la Iglesia. Orfeo, simbolizaba a Jesucristo. 

Se cree que en la simbología cristiana primitiva (s. II y III d. C.) el signo del ancla o "áncora" sería una forma velada de hacer referencia a la cruz de Cristo, esto, con la intención de ocultar su fe en tiempos de persecución, como la desatada en los días del emperador Diocleciano.

Símbolos cristianos eran: El pez. Objetos que se han datado como del siglo II d. C. que llevan figuras de pescados junto con la palabra griega para pescado, "“ΙΧΘΥΣ (IKHTHUS o IKHTHYS)”", que se cree es un críptico para la expresión griega "“Iesoús Christós Theoú Yiós Sotḗr”", que quiere decir “Jesucristo, Hijo de Dios, Salvador.” 

Según "The Interpreter’s Dictionary of the Bible", los pescados aparecían frecuentemente en el antiguo simbolismo pagano, a menudo aparte de escenas acuáticas. “En tales casos,” dice, “parecería tener significado simbólico, posiblemente para representar una deidad, poder, fecundidad, etc.” Esta misma obra de consulta dice, además, que ciertos judíos adoptaron el símbolo del pescado de algunas costumbres religiosas gentiles, y agrega: “Es probable que las consideraciones mencionadas expliquen hasta cierto grado la aparición del pescado en el arte de las más antiguas catacumbas cristianas. No sabemos cuándo llegó a ser interpretada la palabra griega para ‘pescado’ (ikhthys) como una cifra para ‘Jesucristo, Hijo de Dios, Salvador’;[…] pero una vez que se hizo esta identificación, el pescado llegó a ser un símbolo cristiano normal”. 

Luego desde el siglo III empiezan a haber representaciones más explícitas, como una joya en cornalina que muestra la crucifixión de Cristo junto a los doce apóstoles, del siglo III o IV d. C., procedente de la colección fotográfica y anotaciones del arqueólogo clásico sir John Beazley.

En la actualidad el cristianismo está lleno de símbolos; la cruz recuerda a la crucifixión, la virgen María personifica la forma de maternidad más pura reforzada por la asociación al color azul y al blanco, como en Isis. La figura con cuernos y cola es la representación simbólica más común del diablo, intensificada por el color rojo (como Set rojo). La creación de iconos era considerada una parte muy importante del culto. El cordero, símbolo del sacrificio de Cristo y su victoria, y el Buen Pastor, símbolo de Jesucristo y de Orfeo. Algunos símbolos eran de tema histórico - bíblico, como el sacrificio de Isaac, que se utilizaba para representar el sacrificio de la cruz; Adán y Eva, imagen de Jesucristo, nuevo Adán que reparó el pecado; el Arca de Noé, imagen de la Iglesia, etc. A veces se utilizaban también escenas alegóricas, como las de la viña, el convivió o cena, las vírgenes prudentes y las imprudentes de la parábola, etc. 

La creencia popular de que las catacumbas, cementerios subterráneos comunes a varias ciudades del imperio, fueran usadas a veces como refugio para los cristianos en tiempos de persecución ha sido descartada por la historiografía moderna.

"Hoy día es difícil sostener el carácter de refugio que se le ha venido dando a las catacumbas, ya que, exceptuando las tres grandes persecuciones de Decio en 250, de Valeriano en 257-258 y de Diocleciano entre fines del siglo III y comienzos del IV, los cristianos gozaron de periodos de relativa tranquilidad. Las catacumbas deben ser vistas como cementerios subterráneos dedicados a los difuntos y a los mártires, en cuyo honor se celebraba la eucaristía, como lugares de reposo a la espera de la resurrección, y, por ello, las pinturas que las decoran están llenas de sugerencias a la otra vida y a la celebración eucarística".

Al igual que otras comunidades, los cristianos también enterraban a sus difuntos allí, y en ellas hallaban sepultura también los cuerpos de los mártires, muertos en las persecuciones. La veneración que empezó a tributárseles originó la construcción de capillas más amplias entre los estrechos pasillos subterráneos, a menudo superpuestos en varios pisos, e hizo que los cristianos se reunieran en ellas para celebrar los misterios de la fe. El arte cristiano primitivo halló ocasión de plasmar en las paredes de estos recintos y capillas sus admirables realizaciones. 

Junto a la "Via Appia" antigua se hallan las catacumbas de San Calixto, las de San Sebastián y las de Pretextato; en la "Via Ardeatina", las de Domitila, las de Priscila en la "Via Salaria" y las de Sta Inés en la Nomentana. Todas ellas, muy visitadas por los peregrinos y turistas que acuden a Roma, no representan más que una mínima parte de las sesenta de que hoy se tiene noticia, con más de seiscientos kilómetros de galerías subterráneas de planta laberíntica, con cuatro o cinco sepulturas por piso, una encima de la otra, como los nichos de un cementerio moderno. 

Sus asambleas, que generalmente se celebraban en los tituli o casas de nobles, quienes las prestaban gustosos para ello, también se celebraban en las tumbas de los mártires. Se iniciaba con el saludo tradicional: "Que la paz sea con vosotros" para continuar con el rezo de las letanías, que el pueblo contestaba a coro; seguían dos oraciones breves, diversas lecturas, canto de un salmo, y rezo y comentario del Evangelio. Confesión publica de pecados y el canto del Marhanatha. Cuando concluía esta primera parte, se despedía a los catecúmenos y paganos. Luego continuaba la ceremonia con el ofertorio (en que los asistentes ofrecían sus presentes o limosnas) y seguían los preparativos para el sacrificio, rezo de varias oraciones, entre ellas la eucarística y la comunión bajo las dos especies (fragmento de pan asimo consagrado depositado en la mano derecha de cada comulgante por los obispos, y un sorbo de vino del cáliz que era pasado, de uno en uno, por los diáconos) Oración en acción de gracias, bendición episcopal a los fieles, y la fórmula de despedida que aún subsiste: "Id, la misa ha terminado".

La Cruz cristiana es un símbolo religioso muy familiar en la cristiandad. Este método de ejecución fue común para los esclavos romanos y para los criminales que no eran romanos. El evangelio usa la palabra stauros (estaca) y xylon (madero).

Las palabras «cruz» y «crucifijo» provienen de las derivaciones del verbo latino "cruciare", que significa "torturar".
En el s II se desarrolla el concepto teológico neoplatónico de la Cruz como límite del Pleroma.




</doc>
<doc id="15385" url="https://es.wikipedia.org/wiki?curid=15385" title="Historia del cristianismo durante la Edad Media">
Historia del cristianismo durante la Edad Media

La historia del cristianismo durante la Edad Media abarca los hechos relacionados con el cristianismo desde la caída del Imperio romano de Occidente (c. 476) hasta la reforma protestante (), que es cuando se considera que comienza el cristianismo moderno. Este período de la historia coincide con lo que se conoce como Edad Media.

La Alta Edad Media comienza con el derrocamiento del último emperador romano de occidente (Rómulo Augusto) por Odoacro, líder de los hérulos, en el año 476 y finaliza con la coronación de Carlomagno en el año 800. Aunque esta división es arbitraria, ya que el inicio de la Alta Edad Media fue un proceso gradual en el cual la fuente de riqueza y poder se fue transfiriendo desde las ciudades al campo, mientras decaía la autoridad del poder central del emperador de Roma.

En los comienzos del cristianismo no había diferencia entre los diferentes obispos, aunque tras el cese de las persecuciones romanas (c. 360) surgió la necesidad de unificar las creencias y centralizar el poder. Los inicios del primado papal pueden rastrearse hasta Dámaso I (366-384), quien se presentó como un nexo espiritual entre los cristianos del Imperio Romano de Occidente y de Oriente, mientras se mostraba intrasigente con las doctrinas contrarias a las establecidas en los concilios. Al mismo tiempo, la figura del emperador se consolida en el "dominado", por la que adopta una forma mística, legitimada y enviada por Dios, que busca el centralismo del poder mediante el apoyo de la Iglesia. El papa León I el Magno (440-461) asumió el título de "pontifex maximus", que habían abandonado los emperadores romanos desde el 382. La supremacía papal se consolida con Gelasio I (492-496), quien dirigió una carta al emperador Anastasio I (491-518) en donde formula la "doctrina de las dos espadas", entendida como la justificación de la superioridad de la potestad espiritual del Papa sobre la temporal del emperador.

Al mismo tiempo que el poder de la Iglesia cristiana iba creciendo en Europa, el de los emperadores disminuía. En medio de la crisis por las guerras constantes, el emperador Justiniano I (527-565) trató de reafirmar el dominio imperial en Italia desde el este, en lo que se conoce como guerra gótica (535-554). A pesar de que la campaña fue exitosa, se estableció para Italia un exarcado, la influencia imperial era limitada. En 568 los lombardos invadieron la península estableciendo el Reino lombardo. Cuando entraron en Italia, algunos lombardos conservaron su forma nativa de paganismo, mientras que otros eran cristianos arrianos, de ahí que no tuvieran buenas relaciones con la Iglesia católica, a la que persiguieron con celo. El fracaso de los emperadores para enviar ayuda dio lugar a que los papas se encargaran de la alimentación de la ciudad con el grano de la hacienda papal. Así como de la negociación de acuerdos con los lombardos, mediante el pago a sus líderes a cambio de protección o, en su defecto, la contratación de soldados para defender la ciudad. Esto marcó el final de la influencia en Roma del Imperio bizantino.

Tras la caída del Imperio Romano de Occidente, los misioneros cristianos comenzaron a predicar entre pueblos de origen celta y germánico.

En el existía un contacto fluido entre lo que hoy es Irlanda, Escocia y Gales. En este contexto, el cristianismo comenzó a expandirse en estas regiones desde la Britania posromana; comenzando por Gales, región en la cual convivían celtas paganos con bretones cristianos ya desde la época romana.

A comienzos , Irlanda se encontraba dominada por los druidas. Se desconoce como se introdujo por primera vez el cristianismo en la isla, pero se estima que comenzó con los prisioneros que eran capturados en las costas de Gran Bretaña durante las incursiones que se llevaban a cabo en busca de botín y esclavos. La crónica de Próspero de Aquitania (390-455) menciona que en el 431 Paladio de Escocia fue enviado por el papa Celestino I (422-432) a Irlanda para ser su primer obispo, aunque abandonaría la isla poco después debido a la fuerte oposición a su presencia del jefe de Wicklow. Esto evidencia que para aquella fecha ya había una pequeña comunidad cristiana.

La tradición da preeminencia a Patricio de Irlanda, quien teniendo 16 años fue secuestrado por un grupo de escotos, llevado a Irlanda y vendido como esclavo. La fecha de su cautiverio no está clara, aunque se sabe que duró seis años. Según distintos autores, debió ser entre los años 410 y 430, siendo lo más probable en torno al 420; pero en ningún caso anterior al 405. Después de su fuga estudió teología y fue enviado de regreso a Irlanda en 433 como líder de un grupo de misioneros por Germán de Auxerre (378-448), obispo de Britania, como segundo intento de evangelización luego de la expedición fallida de Paladio dos años antes. Patricio logró la conversión de los líderes de algunos clanes, lo que propició la conversión del resto de la población.

Según la tradición, la introducción del cristianismo en Escocia se atribuye a Columba de Iona (521-597). Aunque se desconoce a ciencia cierta cuánto contribuyó a esto efectivamente, no hay dudas de que fue muy influyente en las primeras comunidades cristianas de Escocia. Columba llegó a la isla de Iona en el 563 proveniente de Irlanda, junto a otros doce hombres, y allí fundó una abadía. Tras su llegada estableció contacto y fue protegido por Conall mac Comgall, rey de Dalriada, un importante estado escoto, lo que favoreció la expansión de la nueva religión.

 Pueblos germánicos que invadieron el sur y el este de la Gran Bretaña, desde principios del siglo V hasta la conquista normanda en el año 1066.

En los siglos IV y V, el imperio romano perdió buena parte de su extensión en Occidente y se transformó en oriental bizantino. Se suele señalar como sintomática la fecha del año 476, pero de hecho la invasión y cuarteamiento del imperio había empezado mucho antes (406). Un grupo de pueblos, originarios de Escandinavia, los germanos, desde Europa central se había lanzado a la conquista de los despojos de Roma. De estos pueblos, los visigodos fueron cristianizados por el obispo Ulfilas, pero el arrianismo arraigó en ellos hasta que pasaron a la ortodoxia en el 589. Burgundios y vándalos eran también arrianos. Los suevos, el 408, eran en parte todavía paganos y estuvieron vacilando entre el arrianismo y la ortodoxia hasta que hacia el 560, optaron por la última. Los ostrogodos, cuando en 489 se apoderaron de Italia, practicaban ya el arrianismo, pero su rey Teodorico se esforzó para evitar roces con los católicos. Los francos, en cambio, paganos, pasaron directamente a la ortodoxia, el 496, con el bautismo de su rey Clodoveo. "Adore tout ce que tu as brûlé, et brûle tout ce que tu as adoré", que traducido significa "Adora todo aquello que has quemado y quema todo aquello que has adorado..." 

Los germanos, no obstante, constituían la minoría dirigente. La mayor parte del campo contaba aún con poblaciones indígenas paganas. En las ciudades, la mayoría era cristiana. Cuando los vándalos pasaron al África, en el 429, hicieron que a la jerarquía episcopal ortodoxa se sumara una jerarquía arriana. Muchas ciudades del África vándala tuvieron simultáneamente obispo ortodoxo y obispo arriano. Cerca de cinco mil católicos fueron exilados por el monarca vándalo Hunirico y uno de sus sucesores, Trasamundo (496- 523), exilió a la isla de Cerdeña 120 obispos. Cuando el 534 los bizantinos recuperaron la provincia de África, el catolicismo se hallaba diezmado. La invasión musulmana, a mediados del siglo VII, lo hizo prácticamente desaparecer. 

En los siglos IV y V, Germania se va cristianizando; las regiones del Rin y del Danubio medio (Nórico y Recia) son las primeras en recibir el Evangelio, por obra de san Severino (482). Pablo Orosio y Salviano, autores religiosos de la época, aprecian los valores del mundo germánico y desean su plena conversión. 

En Oriente, san Simeón y los monjes del Sinaí convertían del arrianismo a la ortodoxia a los sabeos del sur de Arabia, Abisinia, Persia y Armenia abrazaban también la ortodoxia y el ámbito del cristianismo se extendía por el mundo.



</doc>
<doc id="15386" url="https://es.wikipedia.org/wiki?curid=15386" title="Little Richard">
Little Richard

Little Richard, nombre artístico de Richard Wayne Penniman, (Macon, Georgia, 5 de diciembre de 1932) es un cantante, compositor y pianista afroamericano de "rock and roll" estadounidense.

Sus primeras grabaciones en los años 50 eran una mezcla de "blues" y "rhythm and blues", con una fuerte influencia del "gospel", pero con una habilidad tal que marcaron decididamente una nueva clase de música. De sí mismo ha dicho que se consideraba como el "arquitecto" del "rock and roll", pero que el color de su piel le apartó de la gloria acaparada, entre otros, por Elvis. Además, se autodenomina "El Predicante Rey del Rock & Roll, Rhythm & Blues y Soul".

Algunos de sus trabajos más conocidos son Tutti Frutti y Long Tall Sally.

Proveniente de una familia humilde, hijo de un destilador ilegal de whisky, fue el tercero de doce hijos, pasando su infancia más próximo a su madre que a su severo padre. Gracias a ella, recibió clases de piano. Él mismo dijo "vine a una familia a la que no le gustaba el "rhythm and blues". "Pennies From Heaven" de Bing Crosby y a Ella Fitzgerald era todo lo que podía escuchar". Perteneciente a la Iglesia Adventista del Séptimo Día, aprendió música "gospel" en las iglesias pentecostales del sur de Estados Unidos.

A los 13 años, su padre lo echa de casa escandalizado por sus escarceos homosexuales. Libre de la opresión familiar, libera sus pasiones reprimidas y se dedica a cantar en bares, tugurios o simples esquinas de la calle, para ganarse la vida. Por suerte, un matrimonio blanco, Ann y Johnny Johnson, lo sacan de ese mundo y le permiten seguir desarrollando sus aptitudes musicales en el escenario del Tick Tock, el club que regentan.

En 1951 gana un concurso local y es invitado por la compañía discográfica RCA Records con la que grabaría ocho discos sencillos que no terminarían de cuajar. 

El año de 1952 estuvo lleno de acontecimientos para Little Richard. Conoce a Sugarfoot Sam, actuando en sus números de vodevil. Pronto pasó a actuar con los Tidy Jolly Steppers en el estado de Alabama, pero poco después los abandonaría para ser solista de la banda de J. L. Heath, con los que actúa por Georgia. Conoce a Billy Wright, que le propone grabar un disco, ya bajo el nombre de Little Richard. Unos meses después, moría asesinado su padre.

En 1953 decide formar su propio grupo, con el nombre de The Upsetters y en 1954 graba diversos temas en una nueva discográfica, la Peacock, pero sin lograr resultados destacables. Trabajando como lavaplatos en la estación de autobuses de Macon y viendo que su carrera está estancada, decide en 1955 enviar una maqueta a Specialty Records. Seis meses más tarde llega la respuesta de Specialty para una sesión de grabación en Nueva Orleans, con la condición de que acepte dejar a su grupo para ser acompañado por músicos de prestigio. Las primeras sesiones no terminan de convencer, pero durante una pausa en una de dichas sesiones, Richard comenzó a cantar de manera improvisada "Tutti Frutti", una canción obscena y llena de lascivia que había estado cantando en sus actuaciones. Se cambió la letra ""Tutti Frutti, good, booty / If it don't fit, don't force it / You can grease it, make it easy"" (""Tutti Frutti, buen culito / Si no entra, no lo fuerces / puedes engrasarlo, para facilitarlo"") a ""Tutti frutti, all rooty, a-wop-bop-a-loon-bop-a-boom-bam-boom"" porque el productor de grabación, Roberte Bumps Blackwell, lo consideraba un exceso (además, "Tutti-frutti" en argot significaba "gay"). Además, Dorothy La Bostrie (su compositora) consideró que esos versos eran inaceptables.

La canción, con su onomatopéyico ""Womp-bomp-a-loom-op-a-womp-bam-boom!"", se convirtió en modelo para muchas otras pequeñas canciones futuras de Richard, tocando su piano, con Lee Allen al saxofón y su ritmo implacable. En los siguientes años, Richard tendría varios éxitos más: "Long Tall Sally", "Slippin' and Slidin'", "Jenny, Jenny" y "Good Golly, Miss Molly". Su estilo frenético se puede ver en películas como "Don't Knock the Rock" (1956) y "The Girl Can't Help It" (1956), para las cuales cantó las canciones que daban el título, escritas por Bobby Troup.

A pesar del sonido primario de su música, sus sencillos fueron cuidadosamente seleccionados, según se puede apreciar en el triple álbum "The Specialty Sessions", en el que se incluyen muchas versiones. Como ejemplo de su artesanía, él y Blackwell ensayaron la estrofa de "Long Tall Sally", ""He saw Aunt Mary coming and he ducked back in the alley"" (Vio a tía Mary venir y se agachó detrás del callejón) durante todo un día hasta que consideró que había alcanzado la precisión deseada. Fue plagiado, inicialmente con éxito por cadenas de radio "para blancos", especialmente a través de Pat Boone. Este hecho, posiblemente favoreció que la fama de Little Richard se extendiera. 

En 1956 compra una mansión en Los Ángeles, California, y vuelve a tocar con su antiguo grupo (The Upsetters).

Little Richard detuvo su carrera musical de forma repentina en 1957, durante una gira por el centro de Australia; renunció a su forma de vida en el "rock and roll". Parece ser que su decisión tuvo que ver con el accidental incendio de uno de los motores del avión en el que viajaba junto con su grupo. Después de aterrizar, se quitó de los dedos cuatro anillos de diamantes valorados en unos 8.000 dólares y los lanzó al río Hunter. Ingresó en una universidad cristiana en Alabama para estudiar teología y se hizo ministro pentecostal. Mientras su casa discográfica, la Specialty Records, lanzaba algunas nuevas canciones basadas en antiguas sesiones de grabación, Richard hizo muy poco musicalmente hablando, apenas algunas canciones de gospel a comienzo de los años 60.

En 1962 regresó con un entusiástico recibimiento en su gira por el Reino Unido. Los Rolling Stones, quienes admiraban a Richard incluso antes de que tuvieran un contrato de grabación, y los Beatles, también admiradores suyos, le apoyaron. Llegó a acompañar a los Beatles en su gira por Hamburgo. En 1982, Paul McCartney decía: "La primera canción que canté en público fue "Long tall Sally", de Little Richard. Cuando los Beatles comenzaban, actuamos con él en Liverpool y Hamburgo. Para mí, es uno de los reyes del "rock and roll". Además es un gran tipo, al que ahora considero mi amigo". También inspiró al legendario cantante de Deep Purple, quien le dedicó la canción "Speed King" del álbum "In Rock".

Desde entonces, Little Richard ha trabajado periódicamente en películas, ha lanzado ocasionalmente algún sencillo que otro y ha aguantado como uno de los grandes y legendarios pioneros del "rock and roll". Su vida parece como si hubiera ido siempre de un extremo a otro. En 1964 vuelve a los escenarios grabando nuevas versiones de sus éxitos; en los años 70 sus excesos sexuales y con las drogas hicieron que su iglesia lo rechazara. Finalmente, tras la muerte de uno de sus hermanos, Little Richard reorganizaría su vida: limpiaba su organismo de drogas, se hacía vendedor de biblias a domicilio y volvía a su iglesia. 

Regresó con dedicación plena al final de los años 80, diciendo que venía para realizar lo que Dios le tenía destinado ser: Little Richard. Todavía tiene la licencia de su ministro, sin embargo, y ocasionalmente celebra bodas (entre las que caben destacar las de Cyndi Lauper y Bruce Willis y Demi Moore).

En 1986 apareció en la película "Down and Out in Beverly Hills", anotándose su primer gran éxito con el tema "Great Gosh-a-Mighty!", lo que condujo a un resurgimiento de su popularidad. También en este año, cuando se abrió el Rock and Roll Hall of Fame, Richard figuraba entre los primeros artistas. Su contribución pionera al género también ha sido reconocida por el Rockabilly H 

En 2005 Little Richard estuvo trabajando en otros éxitos de R&B y "soul". Junto con el cantante y compositor Michael Jackson lanzó el sencillo titulado "I Have A Dream" (Tengo un sueño), los ingresos se destinaron a las víctimas del huracán Katrina.

También en 2005 apareció, junto a estrellas como Madonna, Iggy Pop, Bootsy Collins, y The Roots, en un anuncio comercial para la televisión americana, promocionando el teléfono Motorola ROKR.

Además salió en un capítulo de Los Simpson (temporada 14 capítulo 7) interpretándose a sí mismo.







</doc>
<doc id="15387" url="https://es.wikipedia.org/wiki?curid=15387" title="Rock (desambiguación)">
Rock (desambiguación)

Rock puede referirse a:


Asimismo, puede hacer referencia a las siguientes localidades o divisiones administrativas de Estados Unidos:


También, puede referirse a los siguientes autores de nombres científicos:


Además, puede hacer referencia a:


</doc>
<doc id="15388" url="https://es.wikipedia.org/wiki?curid=15388" title="Placebo">
Placebo

«Placebo» puede referirse a:


</doc>
<doc id="15389" url="https://es.wikipedia.org/wiki?curid=15389" title="Nymphaea alba">
Nymphaea alba

El nenúfar blanco europeo (Nymphaea alba, también llamado aguapé blanco, azucena de agua, escudete de Europa, golfán blanco o rosa de Venus) es una planta acuática de la familia de las ninfáceas, que habita los cursos de agua tranquilos y los estanques en las regiones templadas de Europa, tolerando incluso aguas contaminadas. Florece entre junio y septiembre y se recolecta en verano y otoño.

Tiene un rizoma carnoso y horizontal, que se arraiga al fondo del espejo de agua en el que habita. Las hojas flotan, al cabo de largos peciolos; son grandes, cordiformes y bien lobuladas, de textura coriácea y color verde claro. Las flores son solitarias, hermafroditas, con un largo pedúnculo y de coloración blanca a rosada; el cáliz se compone de cuatro sépalos, y la corola de hasta una cincuentena de pétalos gruesos. Los estambres son numerosos, provistos de anteras amarillas. La polinización puede ser autógama o entomógama. El fruto, un aqueno, disemina las semillas por hidrocoria. "2n" = 56, 84.

Se distingue del estrechamente emparentado nenúfar blanco boreal, "Nymphaea candida" , por el número de cromosomas en las células somáticas (2n = 84). Se conocen dos subespecies, "Nymphaea alba" subsp. "alba", ya descrita por Linneo, y "Nymphaea alba" subsp. "occidentalis"

China, India, Rusia, Cadeaso, Marruecos, Argelia, Túnez, suroeste de Asia, Europa.

Irritado de los desprecios de la diosa Diana, Cupido tomó un día sus flechas, montó su arco, cogió una de ellas y la apuntó al corazón de Diana. La flecha voló a su blanco, pero no hirió a Diana, quien en un rápido movimiento logró esquivarla. Sin embargo, la flecha atravesó el seno de Ninfea, una de las ninfas de Diana.

Ninfea quedó así enamorada, y su corazón experimentó lo que nunca antes había sentido; un ardor desconocido la consumía. Se debatió entonces entre un deseo ciego y el pudor. Maldijo las leyes austeras, y amargamente se quejó del yugo que le imponía la necesidad. Trató dentro de sí de arrancar la flecha, pero no pudo. Lanzando gemidos y quejas se lanzó a los bosques. «¡Oh, pudor! -exclamó-; tú, el más precioso y más bello adorno de una ninfa sagrada; si mi espíritu es culpable para contigo de un sentimiento vivo que te ofende, mi cuerpo todavía está inocente; que sea suficiente esta víctima para tu cólera excelsa; que esta pura onda me lave de un crimen que concebí para mi pena, y que mi voluntad con horror detesta.» Así dijo, y levantando al cielo sus ojos, anegados de lágrimas, se precipitó a las aguas. Sus compañeras mientras tanto la buscaban. Las dríades finalmente la encontraron. Diana deploró el horrible destino de Ninfea, pero no permitió que su cuerpo se sumergiera. Sobre las ondas del agua, lo hizo flotar, y lo convirtió en la flor que lleva por nombre nenúfar, de una blancura brillante, con un tallo majestuoso de anchas hojas verdes. Desde entonces, las aguas que rodean al nenúfar son tranquilas y calmas. 

Quiso Diana que, puesto que Ninfea había calmado los fuegos de la pasión del hijo de Venus en el frío elemento del agua, así mismo el nenúfar tuviera la propiedad de calmar, y de embotar los sentidos para no entregarse a los ardores de la voluptuosidad.

Desde ese tiempo, las ninfas no temen ya a las flechas de Cupido, pues el humilde nenúfar las protege y les sirve como antídoto a los ataques del Amor.

Se le ha atribuido propiedades medicinales como antiafrodisíaco, calmante y Anticolinérgico. Antiguamente se usaba en conventos y seminarios en forma de infusión. Supuestamente puede usarse en ninfomanías y erectismo genital.

Las semillas pueden usarse como sucedáneo del coffea y las flores pueden conservarse en salmuera.

Sin embargo, el cultivo de "N. alba" es principalmente ornamental; una variedad de color rojo, procedente del lago Fagertärn en Tividen, Suecia, es particularmente popular, aunque su recogida del ámbito silvestre está severamente restringida hoy en día.

Adarga, adarga de río, cobertera, coberteras, cuencos, escudete blanco, escudete de río, escudetes de río, escudillos, flores de escudete, flores nenúfares, flores ninfeos, golfan blanco, golfán, golfán blanco, hierba de escudete, higos de agua, higos del río, higos de río, lirio de agua, nenúfar, nenúfar blanco, nenunfar, nimfea blanca, ninfa, ninfa blanca, ninfa de la flor blanca, ninfea, ninfea blanca, ninfea de flor blanca, nínfea, platos, rosa de amor, rosa de Venus, yerba de adarga, yerba de escudete.

es un buen detalle para una mujer por ejemplo para la novia,la madre, abuela

</doc>
<doc id="15390" url="https://es.wikipedia.org/wiki?curid=15390" title="Siemens (unidad)">
Siemens (unidad)

Se denomina siemens (símbolo S) a la unidad derivada del SI para la medida de la conductancia eléctrica, que se representa con la letra G. Se nombró así por el ingeniero alemán Werner von Siemens. Su inversa es la resistencia eléctrica, que se representa por la letra R y cuya unidad es el ohmio.

formula_1

En donde I es la intensidad eléctrica o corriente eléctrica, y V es el voltaje (tensión o diferencia de potencial eléctrico).

Esta unidad también se denominaba mho (por ser la unidad inversa al ohmio), porque la conductancia es la inversa de la resistencia, pero este nombre no está en las actuales normas. Se representaba con una mayúscula (Ʊ) —una letra omega mayúscula invertida (℧)—.

En el dibujo anterior está representando que la conductancia eléctrica es inversamente proporcional a la resistencia eléctrica, pero con la notación antigua.

A continuación una tabla de los múltiplos y submúltiplos del Sistema Internacional de Unidades.



</doc>
<doc id="15392" url="https://es.wikipedia.org/wiki?curid=15392" title="Arte contemporáneo africano">
Arte contemporáneo africano

Muchas de las denominadas artes tradicionales de África están todavía en pleno uso y vigencia.

Como en todos los periodos artísticos, coexisten actualmente en África importantes innovaciones junto con significativos conservadurismos estilísticos. En años recientes, los avances en los medios de comunicación experimentados en el continente africano han facilitado la dispersión y difusión a gran escala de las diversas formas artísticas entre sus distintas culturas. Hoy, por ejemplo, algunas máscaras de estilo nigeriano se están usando con asiduidad entre las poblaciones de Ghana y otras tribus de la costa de Guinea.

El arte africano ha estado también sujeto a influencias exteriores. Por ejemplo, la arquitectura y los motivos decorativos islámicos pueden verse en muchas de las manifestaciones artísticas de la zona norte, especialmente en Nigeria, Malí, Burkina Faso y Níger. Motivos estampados similares a los utilizados en la India, se han encontrado en las esculturas y máscaras de los ibibio y efik, a lo largo de la costa sur de Nigeria.

Algunos artistas contemporáneos han adoptado temas cristianos para los diseños de puertas, artesonados y pilas bautismales de las iglesias y catedrales del África cristiana.

En fechas recientes, los artistas han encontrado sus principales fuentes de mecenazgo en los bancos, establecimientos comerciales, oficinas gubernamentales y cortes de los nuevos países. El turismo también ha contribuido a favorecer la demanda de arte africano, especialmente máscaras decorativas y esculturas ornamentales de ébano o marfil, dentro de los límites oficialmente permitidos.

El desarrollo de las escuelas de arte y arquitectura en las ciudades del África subsahariana ha alentado a los artistas a trabajar en nuevos materiales, como el cemento, el óleo y otras pinturas, tinta, piedra, aluminio y una gran variedad de medios gráficos. Las imágenes y diseños así creados reflejan una vibrante fusión entre la tradición africana y el Occidente contemporáneo.

Artistas como Twins Seven Seven y Ashira Olatunde, ambos de Nigeria, o Nicholas Mukomberanwa, de Zimbabue, o Eric Adjetey Anang, de Ghana se cuentan entre los más brillantes seguidores de estas nuevas formas de creación artística.



</doc>
<doc id="15393" url="https://es.wikipedia.org/wiki?curid=15393" title="Conductancia eléctrica">
Conductancia eléctrica

Se denomina conductancia eléctrica (G) a la facilidad que ofrece un material al paso de la corriente eléctrica; es decir, que la conductancia es la propiedad inversa de la resistencia eléctrica.

Al encontrar el recíproco de la resistencia eléctrica de un material se tendrá una medida de que tan bien conducirá este la electricidad. La cantidad se llama conductancia, tiene el símbolo G y se mide en siemens (S). 

No debe confundirse con conducción, que es el mecanismo mediante el cual la carga fluye, o con la conductividad, que es la conductancia específica de un material.

La unidad de medida de la conductancia en el Sistema Internacional de Unidades es el siemens.

Este parámetro es especialmente útil a la hora de tener que manejar valores de resistencia muy pequeños, como es el caso de los conductores eléctricos.

Como ya se mencionó, la relación entre la conductancia y la resistencia está dada por:

donde:

Para el caso reactivo, la conductancia se puede relacionar con la susceptancia y la admitancia mediante la siguiente ecuación:

o por:

donde



</doc>
<doc id="15396" url="https://es.wikipedia.org/wiki?curid=15396" title="Teogonía">
Teogonía

La Teogonía (del griego Θεογονία, "Theogonía", literalmente “Origen de los dioses”) es una obra poética escrita por Hesíodo. Contiene una de las más antiguas versiones del origen del cosmos y el linaje de los de la mitología griega. Es una de las obras claves de la épica grecolatina. Se discute si debe fecharse en el siglo VIII o en el VII a. C.

La obra está construida a partir de géneros poéticos preexistentes que hasta el momento habían pertenecido a la tradición oral en Grecia: cosmogonías, teogonías, genealogías, catálogos y mitos de sucesión. Los tres primeros géneros pueden aparecer fundidos, vertebran la obra y están ordenados con un criterio aproximadamente cronológico. Los mitos de sucesión, a pesar de que pueden ser considerados como digresiones dentro de los bloques genealógicos, le dan sentido a toda la obra.

El proemio tiene dos bloques: 
finaliza con una invocación (v. 105 - 115) que marca la transición a la parte principal del poema.

Compositivamente el proemio no se distingue esencialmente de la estructura de otros proemios conservados, como los Himnos homéricos: su estructura ternaria (anuncio del tema del himno, relato de algún episodio de la vida del dios celebrado, invocación de cierre pidiendo su favor) lo vincula a formas de la lírica.
Aquí son mencionados un conjunto de deidades que representan elementos cósmicos, en forma genealógica.


Sigue una genealogía de carácter más marcadamente teogónica:

puesto que aunque allí se mencionan deidades que representan elementos (como Océano, Hiperión, Rea), colectivamente aparecen dioses más antropomórficos que los anteriores: los Titanes, Cíclopes y Hecatonquiros.

Como cierre de este bloque aparece, como primera parte del mito de sucesión, el

Sigue un conjunto de genealogías en mera yuxtaposición, con importantes digresiones épicas que contienen el resto del mito de sucesión.


Hijos de Zeus (v. 886 - 929)


Hacia el final el poema pierde su hilo:






</doc>
<doc id="15397" url="https://es.wikipedia.org/wiki?curid=15397" title="Wilfredo Gómez">
Wilfredo Gómez

Wilfredo Gómez (San Juan, 29 de octubre de 1956) es un exboxeador puertorriqueño tres veces campeón mundial. Es considerado por muchos, junto a Carlos Ortiz, Wilfred Benítez y Félix Trinidad, los mejores boxeadores de Puerto Rico. Sus apodos sobre el ring fueron "Bazooka" y "El niño de Las Monjas".

Campeón mundial aficionado en Cuba en 1974, Gómez se vio forzado a vivir en Panamá por varios años, debido a que no podía encontrar oponentes en Puerto Rico. Debuta como profesional en Panamá, siendo relegado a un empate a seis asaltos por Jacinto Fuentes. Después de esa pelea, encadenó un total de 32 victorias corridas por la vía del nocaut, entrando así en el grupo exclusivo de boxeadores con 20 o más victorias por nocaut seguidas. Su cadena de nocauts consecutivos lo sitúa en tercer lugar entre todos los boxeadores en cuanto a victorias conseguidas por nocaut, solo superado por Lamar Park, con 44, y Billy Fox con 43. Sin embargo, entre los campeones mundiales el y Deontay Wilder son los que más larga cadena de nocauts lograron a través de la historia, pues Park y Fox no fueron campeones mundiales. Cuando Wilder ganó su título mundial peso completo (o pesado) del Consejo Mundial de Boxeo al derrotar por puntos a Bermane Stiverne, el empató con Gómez en cuanto a campeones mundiales con la racha las larga de victorias por nocaut en la historia, pero al mismo tiempo aseguró no poder quebrar el récord ahora perteneciente a él y a Gómez. 

En 1977, y aún en medio de esa cadena de victorias por nocaut, el campeón mundial super-gallo del Consejo Mundial de Boxeo (CMB), Dong Kiung Yum de Corea del Sur, viaja a Puerto Rico a defender la corona mundial ante Gómez. Gómez visitó la lona en el primer asalto de este combate, pero se recuperó y noqueó a Yem en doce asaltos, coronándose campeón mundial por primera vez. 

Gómez defendió el título con éxito 17 veces, todas por nocaut, estableciendo un récord mundial de defensas consecutivas por nocaut en cualquier división,y también el récord de defensas en el peso Super-gallo. Entre otros, derrotó a los campeones mundiales Leo Cruz, Juan Meza, Lupe Pintor y Carlos Zárate. A Zarate lo derrotó en cinco asaltos, y su pelea contra Pintor, la cual duró catorce asaltos, se considera por críticos y expertos como una de las mejores peleas en la historia.

El 21 de agosto de 1981, Gómez sube de peso para retar al campeón mundial categoría pluma del CMB, Salvador Sánchez. En lo que muchos consideran la victoria más grande de un mexicano sobre un puertorriqueño en la historia del boxeo, Sánchez derrota a Gómez por nocaut en el octavo asalto, sorprendiendo inclusive a los apostadores de Las Vegas, ciudad sede del combate, que daba a Gómez favorito para ganar. 

Gómez bajó de peso inmediatamente, para defender la corona super-gallo cuatro veces más, con la esperanza de que Sánchez le diera una revancha. Dicha revancha nunca llegó, sin embargo, pues Sánchez falleció, el 12 de agosto de 1982, en un accidente de auto en la carretera San Luis Potosí - Querétaro.Entre sus 4 defensas en 1982, destacan los combates ante Juan Meza, futuro campeón mundial peso Super Gallo, noqueado en seis asaltos en Atlantic City, Nueva Jersey, y Lupe Pintor, en una pelea que es considerada generalmente entre los combates mas emotivos y violentos en la historia del deporte, cuando Gómez, con lesiones en los ojos y los cachetes, logró derrotar al futuro miembro del salon de la fama internacional del boxeo por nocaut en el asalto numero catorce. Mientras esto sucedía, Juan Laporte, otro puertorriqueño, se coronaría campeón mundial pluma del CMB al conquistar la corona dejada vacante por la muerte de Sánchez.

En 1984, Gómez sube de peso nuevamente y reta a Laporte, resultando triunfador esta vez, por decisión unánime en doce asaltos. Habiendo conquistado su segundo título mundial, Gómez esperó nueve meses para defender su corona, pero perdió el título en su primera defensa, cayendo noqueado en once asaltos ante Azumah Nelson, de Ghana.

Gómez comenzó 1985 esperando una revancha con Nelson o una oportunidad ante el campeón mundial ligero júnior de la Asociación Mundial de Boxeo (AMB), Rocky Lockridge. Lockridge aceptó pelear con Gómez, de manera que Gómez subió de peso nuevamente, y el 19 de mayo de ese año, se convierte en el octavo boxeador en conquistar tres coronas mundiales, además de ser el cuarto latinoamericano y el segundo puertorriqueño en lograr tal hazaña, al derrotar a Lockridge por una cerrada decisión dividida en quince asaltos.

Al igual que cuando reinó en el peso pluma, Gómez perdió la corona ligero júnior en su primera defensa, noqueado en nueve asaltos por el panameño Alfredo Layne, quien fue ejecutado por sicarios colombianos en 1999 al estar involucrado en una transacción de cocaína en la que se robó el cargamento pactado, por lo cual fue torturado y asesinado en la Ciudad de Panamá. 

Tras dos victorias adicionales en 1988 y 1989, Gómez anunció su retiro. Luego vivió en Venezuela y Colombia antes de regresar a su patria. En 1995 Gómez fue elegido miembro del Salón de la Fama Internacional del Boxeo. Durante su período de campeón mundial super-gallo, de 1977 a 1983, Gómez logró ser considerado un héroe nacional en Puerto Rico, título que la mayoría de puertorriqueños aún le concede.

Gómez tuvo un récord de 44 victorias, 3 derrotas y un empate, con 42 victorias por nocaut.



</doc>
<doc id="15398" url="https://es.wikipedia.org/wiki?curid=15398" title="Hominidae">
Hominidae

Los homínidos (Hominidae) son una familia de primates hominoideos, que incluyen 4 géneros y 7 especies vivientes, entre las cuales se halla el ser humano y sus parientes cercanos, orangutanes, gorilas, chimpancés y bonobos.

En la clasificación tradicional, la familia Hominidae estaba compuesta exclusivamente por primates bípedos (géneros "Homo", "Australopithecus", "Paranthropus", etc.). Actualmente, según la taxonomía cladística cuyo uso se está imponiendo en primatología, los Hominidae incluyen además a los grandes simios (géneros "Gorilla", "Pan", y "Pongo") anteriormente clasificados en la familia de los póngidos. En la mayor parte de los trabajos científicos actuales, los homínidos bípedos son ahora clasificados en la subtribu Hominina.

Por tanto, existe una cierta confusión de términos:


Estudios realizados con técnicas moleculares del ADN indican que los chimpancés, gorilas y humanos forman un clado, con los orangutanes un poco más separados filogenéticamente. Salvo por el orangután (nativo de Asia, específicamente Borneo y Sumatra), los actuales simios homínidos; humanos, chimpancés y gorilas son originarios de África (si bien en el caso del humano se extendió por todo el mundo). Sin embargo se han encontrado fósiles de homínidos en Europa y diversos lugares de Asia y África, procedentes del Mioceno (cerca de 20 millones de años antes del presente). No existen evidencias físicas de que haya ningún tipo de homínido nativo de América, y el único simio homínido que cruzó de Eurasia a América de forma natural fue "Homo sapiens".

Los homínidos son ágiles para trepar a los árboles y son omnívoros. Además conforman las más complejas redes sociales y tienen un comportamiento sexual elaborado que no necesariamente está sujeto a fines reproductivos, sino en muchos casos, por placer, algo que los diferencia de otras especies animales.

Los homínidos son los primates más grandes, con un peso que oscila de 48 kg a 270 kg. En general, los machos son mayores que las hembras (dimorfismo sexual), con cuerpos robustos y brazos bien desarrollados. Tienen numerosas diferencias con respecto al esqueleto de los otros primates, especialmente relacionadas con su porte vertical.

Se caracterizan por su adaptación a la postura y marcha erectas, acortamiento de las extremidades superiores y evolución de la mano hacia una mayor funcionalidad; la regular proporción en las dimensiones de sus dientes, yuxtapuestos sin diastemas, describiendo un arco parabólico corto, con premolares inferiores homomorfos, bicuspidado el primero; y, en fin, el incremento progresivo de la capacidad craneana y la complejidad del cerebro, alojado bajo una bóveda cada vez más elevada.

Todos los miembros de esta familia tienen cerebros relativamente grandes y complejos. Tienen las narinas próximas una de otra y orientadas hacia el frente y hacia abajo. La fórmula dental es la misma en todos los miembros de este grupo: 2/2, 1/1, 2/2, 3/3 = 32.

Los homínidos son omnívoros, aunque la base de su alimentación suelen ser las frutas y vegetales: en el caso del chimpancé, pueden incluir pequeños invertebrados o incluso mamíferos, lo que constituye menos del 2% de su dieta. Otra característica es la complejidad de su comportamiento social, expresión facial y vocalización compleja. Todos construyen nidos o refugios y cuidan mucho a sus crías durante un largo período; las hembras tienen generalmente una cría en cada gestación.

Las siete especies vivientes de homínidos se clasifican en cuatro géneros. La siguiente clasificación es la más aceptada:
Adicionalmente a las especies y subespecies anteriores, los paleoantropólogos han descrito numerosas especies extintas:

Algunos autores consideran también a los driopitécidos como otra subfamilia (driopitecinos, "Dryopithecinae") de Hominidae.

La siguiente tabla enlista el número estimado de grandes simios que viven fuera de zoológicos.



</doc>
<doc id="15399" url="https://es.wikipedia.org/wiki?curid=15399" title="Humor gráfico">
Humor gráfico

Humor gráfico es un neologismo con el que se designa a una gama diversa de obras gráficas realizadas para la prensa, desde chistes de una sola viñeta y caricaturas hasta verdaderas historietas, tiras cómicas e incluso planchas enteras. Muchas abundan en la sátira de la actualidad política y social.

Hasta mediados del siglo XX, la viñeta de prensa se llamó caricatura, y el humorista gráfico, caricaturista. En las páginas de "The New Yorker", que influyen en la mayoría de publicaciones en todo el mundo, nace el "nuevo estilo de hacer humor". 

Los renovadores del género son los americanos Chas Addams, Peter Arno, George Price, Virgil Partch (VIP) y sobre todo Saul Steinberg. También los franceses Chaval, Bosc, André François y Siné. 

En España confluyen varias tradiciones satíricas distintas. En el norte sobresalen los autores gallegos, con Castelao a la cabeza. En el centro hay una escuela de sátira costumbrista, con Tovar, Sileno, Fresno y K-Hito, a los que se añade el catalán Bagaria. En Valencia hay una tradición satírica propia, con nombres como Bluff, Tramús o Juan Pérez del Muro, además de Ernesto Guasp que desarrollará su carrera en la prensa catalana y mexicana. Finalmente en Cataluña hay una importante escuela satírica, con características propias, que se remonta a Pellicer y Apel.les Mestres, e incluye a Cornet, Junceda, Opisso, Nogués, Passarell o Bon.

En México, nombres como Salvador Pruneda, Audiffred o García Cabral, son los precursores de la generación de Freyre, Arias Bernal, Vadillo o Carreño, que anteceden a Rius, Quezada, Helioflores o Naranjo.

En Argentina podemos considerar precursores a Cao, Mayol, Sirio, o Zavattaro. Y en Cuba a Blanco, Valls, Massaguer, Maribona y Avela, que anteceden a Sergio Ruiz, Fresquito Fresquet, Chago, Fornés, Niko, Jesús de Armas, René de la Nuez, David, entre otros. En el año 2009, en la muestra "Bicentenario: 200 años de Humor Gráfico" que el Museo del Dibujo y la Ilustración realizó en el Museo Eduardo Sívori de Buenos Aires, se homenajeó a los más importantes creadores del Humor Gráfico en Argentina a través de su historia.

La Guerra Civil en España acaba con la tradición humorística anterior. En la revista "La Codorniz", de Tono, Mihura y Herreros, se darán a conocer humoristas como Mingote, Chumy Chúmez, Miguel Gila, Summers o Pablo. También destacan Carlos Conti, Joaquim Muntañola, Peñarroya y Castanys, y a partir de la transición, nombres nuevos como El Perich, Cesc y Ops.

Desde poco antes de la muerte de Franco se produce el "boom del humor gráfico". Hay un gran número de revistas y libros de humor. En 1977, más de cien profesionales de la historieta y el humor gráfico se integraron en la Asociación de Artistas Plásticos, buscando un mayor reconocimiento de sus derechos. Carecen entonces de ""las mínimas condiciones de contratos, seguridad social, seguro de desempleo"" y ""la propiedad intelectual de sus obras no es reconocida con la eficacia que lo son otras obras de otros sectores"". 

En la actualidad los principales humoristas están en la revista "El Jueves": Óscar, J.L. Martín, Kim, Fer, Vizcarra, Monteys, Manel Fontdevila, Malagón, etc.

Y en la prensa diaria: Gallego & Rey, Idígoras & Pachi, Guillermo, Ricardo (El Mundo); Mingote, Martinmorales, Puebla (ABC); El Roto, Peridis, Forges, Ramón, Máximo, Carlos Romeu Müller (El País); Juan Kalvellido (La República, Diagonal, Rebelión, etc), Caín, Turcios (La Razón); Manel Fontdevila, Santi Orúe, Vergara, Mauro Entrialgo (Público); Ferreres, Tàssies, Juanjo Sáez (El Periódico); Ventura & Coromina, Toni, Krahn, Kap, Labanda(La Vanguardia); Zulet (El Correo); Soria, Mesamadero (Ideal), Eneko, Calpurnio (20 minutos); Rodera (Adn), Xaquín Marín(La voz de Galicia), Sabela Arias Castro (Tierras de Santiago); Tris (La Rioja)…

En la prensa deportiva encontramos a Guillermo ("Marca"), Caye ("Sport"), Kap ("El Mundo Deportivo") y Bernal ("Equipo").

El Internet son destacables Juan Ramón Mora, Runtime-Error, Mel y las plataformas digitales que le brindan los medios a sus respectivos dibujantes, por ejemplo a Mauro Entrialgo, Ferran Martín, Manel Fontdevila o Daniele.

En dos libros colectivos editados en 2007 se puede encontrar lo más representativo del humor español contemporáneo: Humor a Toda Vela, y Comunica con Humor.

En 2016 abre oficialmente sus puertas Humoristán , el primer museo digital dedicado integramente al humor gráfico. En marzo de 2017 publica un pdf gratuito de 46 páginas " Un año de humor gráfico, informe Humoristan 2016 ". 

En "Picardía mexicana", libro del escritor mexicano Armando Jiménez, aparece un capítulo con algunos ejemplos de humor gráfico mexicano, sobre todo el de doble sentido.





</doc>
<doc id="15405" url="https://es.wikipedia.org/wiki?curid=15405" title="Gobierno de Colombia">
Gobierno de Colombia

Colombia es una república presidencialista, y un Estado unitario con separación de poderes ejecutivo, legislativo y judicial.
La Constitución política vigente fue proclamada, el 4 de julio de 1991. El 59° Presidente de la República, los gobernadores departamentales son los que se encargan de hacer cumplir los reglamentos de la nación.

La constitución política define en el capítulo 1 del título 5 la estructura del estado colombiano mediante la división del poder público en tres ramas: la ejecutiva, la legislativa y la judicial. Sin embargo, dado que existen funciones del estado que estas entidades no cumplen, se nombran los órganos para la realización de estas como son: el Ministerio público, la Contraloría General, el Consejo Nacional Electoral, la Registraduría Nacional, el Banco de la República, la Autoridad Nacional de Televisión y la Comisión Nacional del Servicio Civil, entr></ref>

Es la que se encarga de hacer cumplir las leyes, mantener el orden público, organizar los servicios para la población y recaudar impuestos para hacer uso de ellos. 

El Presidente de la nación y Jefe de Gobierno es la cabeza del poder ejecutivo, el cual comparte con un Gabinete ministerial .

Además es el comandante en jefe de las Fuerzas Militares

El gabinete se compone, además del presidente y el vicepresidente, de los ministros de despacho y los directores de departamentos administrativos.

El presidente es elegido por voto popular directo para un período de cuatro años o menos, en caso de sustitución. La Constitución de 1991 prohibía la reelección presidencial de por vida y con anterioridad era posible la reelección mediata (un expresidente podía ser reelegido pero el presidente en ejercicio no podía ser reelegido para el período siguiente). Con referendo constitucional en 2005 esta prohibición fue abolida y se legalizo la reelección inmediata por una sola vez. Dos presidentes hicieron uso de ella pudiendo participar en las elecciones desde el cargo.

Se encarga de elaborar las leyes y normas. 
Un Congreso bicameral formado por el Senado (100 miembros elegidos por circunscripción nacional por un periodo de cuatro años y un número adicional de 2 senadores elegidos en circunscripción especial por comunidades indígenas) y la Cámara de Representantes, conformada por ciento sesenta y seis miembros elegidos por 4 años, de los cuales ciento sesenta y uno representan a las circunscripciones territoriales (departamentos y el Distrito Capital).

Se encarga de aplicar la ley de manera justa y resuelve conflictos entre las personas de acuerdo a la ley. 

El poder judicial de Colombia empieza a partir de la Constitución Política de 1991. Es conformado por la Corte Suprema de Justicia, la Corte Constitucional, el Consejo de Estado, el Consejo Superior de la Judicatura, así como los tribunales y juzgados. La Fiscalía General de la Nación que es un organismo independiente adscrito a la rama judicial del Poder Público en Colombia.

Son entidades del Estado, ajenas a las tres ramas del poder colombiano:



Los departamentos tienen gobernadores y corporaciones públicas (asambleas departamentales) propias elegidos por sufragio cada cuatro años. Se subdividen en municipios con un alcalde y un concejo municipal, electos también cada cuatro años por votación directa.

En 2015 según el Consejo Nacional Electoral (CNE) de Colombia, y las elecciones legislativas de 2014, los Partidos y Movimientos Políticos reconocidos como tal en la actualidad en Colombia son trece, a saber:





</doc>
<doc id="15409" url="https://es.wikipedia.org/wiki?curid=15409" title="Noam Chomsky">
Noam Chomsky

Avram Noam Chomsky (Filadelfia, 7 de diciembre de 1928) es un lingüista, filósofo, politólogo y activista estadounidense. Es profesor emérito de lingüística en el Instituto Tecnológico de Massachusetts (MIT) y una de las figuras más destacadas de la lingüística del siglo XX, gracias a sus trabajos en teoría lingüística y ciencia cognitiva. También es reconocido por su activismo político, caracterizado por una fuerte crítica del capitalismo contemporáneo y de la política exterior de los Estados Unidos. Se le considera de pensamiento socialista libertario.
El "New York Times" lo ha señalado como «el más importante de los pensadores contemporáneos».

Propuso la gramática generativa, disciplina que situó la sintaxis en el centro de la investigación lingüística. Con ésta cambió la perspectiva, los programas y métodos de investigación en el estudio del lenguaje. Su lingüística es una teoría de la adquisición individual del lenguaje e intenta explicar las estructuras y principios más profundos del lenguaje. Postuló un aspecto bien definido de innatismo en la adquisición del lenguaje y la autonomía de la gramática (sobre los otros sistemas cognitivos), así como la existencia de un «órgano del lenguaje» y de una gramática universal. Se opuso con dureza al empirismo filosófico y científico y al funcionalismo, en favor del racionalismo cartesiano. Todas estas ideas chocaban frontalmente con las tradicionales de las ciencias humanas, lo que concitó múltiples adhesiones, críticas y polémicas que le han acabado convirtiendo en uno de los autores más citados.

Destaca su contribución al establecimiento de las ciencias cognitivas a partir de su crítica del conductismo de Skinner y de las gramáticas de estados finitos, que puso en tela de juicio el método basado en el comportamiento del estudio de la mente y el lenguaje que dominaba en los años cincuenta. Su enfoque naturalista en el estudio del lenguaje ha influido en la filosofía del lenguaje y de la mente (ver a Harman y a Fodor). Es el descubridor de la jerarquía de Chomsky, una clasificación de lenguajes formales de gran importancia en teoría de la computación.

También es conocido por su activismo político y por sus críticas a la política exterior de Estados Unidos y de otros países, como Israel. Chomsky, que desvincula completamente su actividad científica de su activismo político, se describe a sí mismo como simpatizante del anarcosindicalismo (es miembro del sindicato IWW). Chomsky es considerado una figura influyente en su país de origen y en el mundo.

Noam Chomsky nació el 7 de diciembre de 1928 en Filadelfia (Pensilvania), hijo del doctor William (Zev) Chomsky (estudioso de la lengua hebrea y uno de sus más distinguidos gramáticos) y de Elsie Simonofsky, maestra de hebreo. Ambos eran inmigrantes judeo-ucranianos. Desde 1945, estudió filosofía, lingüística y matemática en la Universidad de Pensilvania. Allí estuvo bajo la tutela del profesor Zellig Harris (también inmigrante judeo-ucraniano, fundador del primer departamento especializado en lingüística en Norteamérica). Harris y Elsie influyeron más que Zev en la formación de su ideología política. También por influencia de Zellig Harris, Chomsky comenzó a tomar clases de matemáticas y filosofía. Uno de sus maestros fue el filósofo Nelson Goodman, quien más tarde los presentaría en la Society of Fellows de Harvard. Recibió su doctorado en 1955, después de llevar a cabo la mayor parte de sus investigaciones en la Universidad de Harvard durante los cuatro años anteriores. En 1998 recibió el Doctorado honoris causa (lingüística) de la Universidad Rovira i Virgili. Recibió esta misma distinción por parte de la Universidad Nacional de Colombia en 2002, de la Universidad de Chile y de la Universidad de la Frontera en 2006 y de la Universidad Nacional Autónoma de México en 2010.

En su tesis doctoral comenzó a desarrollar algunas de sus ideas en lingüística, elaborándolas luego en su libro "Estructuras sintácticas", posiblemente su trabajo más conocido en este campo. Sus planteamientos lingüísticos han revolucionado muchos puntos clave del estudio del lenguaje humano, que se han plasmado en la teoría de la Gramática generativa transformacional.

Es profesor del Massachusetts Institute of Technology (MIT) desde 1961, donde ocupó la cátedra Ferrari P. Ward de Lenguaje Moderno y Lingüística de 1966 a 1976.

Su cónyuge fue Carol Schatz, quien murió el 20 de diciembre de 2008.
Tiene dos hijas y un hijo.

En 1957, con solo 29 años, Chomsky revolucionó el campo de la lingüística teórica con la publicación de la obra "Estructuras sintácticas", basada en su tesis doctoral ―"Estructura lógica de la teoría lingüística"―, que no se publicaría hasta 1975. Su efecto sobre las teorías lingüísticas y psicológicas entonces en boga fue demoledor, ya que atacaba los presupuestos centrales tanto del estructuralismo como de la psicología conductista. Hasta entonces, se creía que la adquisición del lenguaje, como cualquier otra destreza humana, se producía por medio del aprendizaje y de la asociación. Sin embargo, Chomsky postulaba la existencia de un dispositivo cerebral innato (el «órgano del lenguaje»), que permite aprender y utilizar el lenguaje de forma casi instintiva. Comprobó además que los principios generales abstractos de la gramática son universales en la especie humana y postuló la existencia de una Gramática Universal.

La Gramática Universal de Chomsky asegura que el fundamento común de la lenguas humanas es su recursividad, un proceso, habitualmente asociado a la subordinación, que posibilita a un hablante a introducir oraciones en otras oraciones sin límite. Este principio sería el que permitiría a los seres humanos establecer una comunicación rica y compleja para distanciarse, por ejemplo, de los animales. Sin embargo, la teoría de la recursividad de Chomsky se puso en entredicho en el momento en el que el profesor Daniel Everett, después de convivir con la tribu indígena de los pirahã, descubrió un idioma nuevo que contradice dicha teoría: el idioma pirahã. Este nuevo idioma, que carece de numeración; tiempos verbales y colores, se caracteriza por su simplicidad aunque, a pesar de tener una percepción simple y reducida del mundo, cumple con las necesidades comunicativas de la tribu. Debido a la falta de subordinación de la lengua pirahã, se demostró que la recursividad no es una propiedad universal. 

Chomsky denominó gramática generativa al conjunto de reglas innatas que permite traducir combinaciones de ideas a combinaciones de un código. Fundamentó la hipótesis, ya existente, de que la gramática es un sistema combinatorio discreto que permite construir infinitas frases a partir de un número finito de elementos mediante reglas diversas que pueden formalizarse. La nueva teoría consideraba que las expresiones (secuencias de palabras) tienen una sintaxis que puede caracterizarse (globalmente) por una gramática formal; en particular, una gramática extendida por normas de transformación. A los niños se les supone un conocimiento innato de la gramática elemental común a todas las lenguas humanas (lo que supone que toda lengua existente es una clase de restricción). Se sostiene que la modelización del conocimiento de la lengua a través de una gramática formal explica la «productividad» de la lengua: con un juego reducido de reglas gramaticales y un conjunto finito de términos, los humanos pueden producir un número infinito de frases, incluidas frases que nadie haya dicho anteriormente.

"The Principles and Parameters approach" (P&P) ("Aproximación por principios y parámetros"), desarrollada en las "Conferencias" de Pisa (1979) y publicada más tarde bajo el título "Lectures on Government and Binding" (LGB), retoma mucho de la gramática universal: los principios gramaticales en los que se basan las lenguas son innatos y fijos; las diferencias entre las distintas lenguas en el mundo se pueden caracterizar en términos de parámetros programados en el cerebro (como el parámetro de elisión, "pro drop param", que indica cuándo un tema explícito es siempre requerido, como en inglés, o si este puede elidirse, como en español) a menudo comparados a interruptores (de ahí el término de principios y parámetros utilizado para calificar este enfoque). Según esta teoría, un niño que aprende una lengua solo necesita adquirir los elementos léxicos básicos (palabras, morfemas gramaticales y refranes) y fijar los valores convenientes en los parámetros, lo que puede efectuarse sobre algunos ejemplos clave.

Los partidarios de esta concepción ponen como ejemplo que la velocidad con la cual los niños aprenden lenguas es inexplicablemente rápida, algo no posible a menos que tengan una capacidad innata para aprenderlas. La similaridad de las etapas que siguen todos los niños a través del mundo cuando aprenden una lengua, y el hecho de que cometan errores característicos cuando adquieren su primera lengua, mientras que otros tipos de error al parecer lógicos no se producen nunca (y, según Chomsky, estos deberían darse si el mecanismo de aprendizaje utilizado fuese general más que específico de una lengua), se postulan también como un argumento a favor de dicho innatismo.

Más recientemente, en su "Programa minimalista" (1995), conservando al mismo tiempo el concepto central de «principios y parámetros», Chomsky intenta una revisión importante de las máquinas lingüísticas implicadas en el modelo de LGB, despojándolos de todo excepto de los elementos estrictamente necesarios. Al mismo tiempo, preconiza un enfoque general de la arquitectura de la facultad de la lengua humana, destaca los principios de la economía y la concepción óptima y retorna al enfoque "derivacional" de la generación, en oposición con la mayor parte del enfoque "representativo" clásico del P&P.

Chomsky caracterizó la tarea del lingüista mucho mejor que ninguno de sus predecesores y fijó con todo rigor el campo para el estudio científico del lenguaje. Su objetivo nunca fue establecer una teoría especulativa más sobre el lenguaje, sino una explicación rigurosa de su complejidad. La intención era por tanto pasar de una pre-ciencia meramente descriptiva a una ciencia con poder explicativo y predictivo falsable y con construcciones abstractas que permitiesen un riguroso sistema axiomático. Nada ha sido igual desde entonces en el campo del estudio del lenguaje y, por extensión, de la mente humana. La gramática generativa de Chomsky fue la primera evidencia sólida de que la inteligencia humana está basada en dispositivos cerebrales especializados e innatos y eso ha permitido agrupar las ciencias cognitivas. También provocó una enorme escisión epistemológica, que todavía se mantiene, frente a quienes rechazan la concepción modular e innata de la mente y siguen siendo partidarios de un modelo de cerebro como "tabla rasa", como por ejemplo los psicólogos que trabajan con procesos de emergencia o las teorías conexionistas, que consideran la lengua como un caso particular de los procesos generales del cerebro.

Chomsky se ocupa de las lenguas naturales partiendo de una gramática universal propia de todos los seres humanos, de raíz biológica, de la cual derivan las distintas lenguas de las diversas culturas que han existido en la historia del hombre y que existen aún.

La diferencia entre la gramática universal (GU) y las distintas gramáticas particulares (GGPP) radica en que la primera se relaciona con la disposición de un conjunto de principios ―como el «principio de proyección», el «principio de dependencia de la estructura», el «principio de ligamiento», la «teoría del caso», el «criterio temático» y algunos otros―, mientras que las GGPP se vinculan a las múltiples variaciones que pueden hacer las lenguas de los parámetros de esos principios. Un ejemplo de esta variación se da en el «parámetro de los sujetos nulos», que en español se puede presentar mientras que en inglés no, como muestra el siguiente ejemplo:
Así, las GGPP no son más que combinaciones de elementos finitos que pueden dar lugar a múltiples lenguas e idiomas que en esta teoría son llamadas lengua-I.

El sistema encargado de articular estos principios y variar los parámetros es el cerebro humano con su capacidad de sintaxis, que en su sentido amplio adquiere la forma de un sistema computacional que opera en módulos. Los módulos responden a una estructura matriz compuesta por tres componentes, dentro de los cuales actúan los principios y parámetros definidos como una serie de teorías de lenguaje, conectadas con cuatro módulos centrales: la estructura-P, la estructura-S, la forma fonológica (FF) y la forma lógica (FL). La estructura-P conecta las oraciones con principios, mientras que la estructura-S apela a la transformación o variabilidad que pueden presentar dichas conexiones; además, la FF se vincula con la entonación y sonido de las expresiones lingüísticas o fonología y la FL se encarga de la semántica de estas expresiones en relación a su interpretación de sentido y significado.

En la estructura-P se encuentran las primeras relaciones entre léxico y sintaxis, como las relaciones sintagmáticas que establecen qué es sintagma verbal, sintagma nominal, sintagma adjetival o sintagma preposicional, entre otras relaciones categoriales.

La estructura-S señala acciones transformacionales o de parámetro, no solamente de principio como en la estructura-P. Un ejemplo es la operación "muévase α", en la que un elemento se mueve en la oración a otra posición. La estructura-S también sirve como conector entre dos módulos que no se relacionan directamente. El primero es la forma fonológica (FF), que se encarga de articular sonidos con formas léxicas a partir de fonemas definidos, como también de establecer las entonaciones de una pregunta o una afirmación, una suposición entre otras acciones ligadas a lo mismo.

Por último, la forma lógica, quizás la más compleja de todas, conecta con el ejercicio semántico de interpretación y significado en el sentido de un oración en la cual se encuentran a nivel léxico las redes temáticas y las selecciones S, como modos de organizar la oración según papeles temáticos (tales como "agente", "tema", "experimentante" o "benefactivo") y categorías gramaticales (tales como "animado" o "humano") respectivamente, para luego dibujar la estructura morfológica de la oración a nivel sintáctico.

Estos cuatro módulos entregan una salida ("output") que sirve como entrada ("input") del siguiente módulo hasta entregar una realización lingüística u oración en un acto comunicativo.

Noam Chomsky se interesó por la política a muy temprana edad, estimulado por las lecturas en las librerías de los anarquistas españoles exiliados en Nueva York. A los once años publicó su primer artículo sobre la caída de Barcelona y la expansión del fascismo en Europa.

Su activismo político arranca de la movilización popular contra la Guerra del Vietnam. La participación de Chomsky en esta movilización fue particularmente sorprendente considerando que su propia universidad, MIT, estaba investigando helicópteros, bombas inteligentes y técnicas de contrainsurgencia para la guerra en Vietnam. Y, como dice Chomsky, "se desarrolló una buena cantidad de tecnología de orientación de misiles [nucleares] en el campus del MIT". Como Chomsky también dice, "aproximadamente el 90% [del MIT] estaba financiado por el Pentágono en ese momento. Y yo personalmente estaba justo en el medio de eso. Estaba en un laboratorio militar.” La oposición de Chomsky a la guerra de Vietnam lo llevó a analizar el papel del mundo académico en la implicación de Estados Unidos en esta guerra. Fruto de este esfuerzo fueron varios artículos compilados en el libro "American Power and the New Mandarins" (El poder estadounidense y los nuevos mandarines) 1969, de entre los cuales destaca "La responsabilidad de los intelectuales" (publicado inicialmente en febrero de 1967 en "The New York Review of Books"). Desde entonces, ha sido muy conocido por sus ideas políticas de izquierda, que se centran en la lucha por superar el déficit democrático existente de Estados Unidos —es decir, la gran distancia entre las decisiones políticas y la opinión pública—, y en denunciar las "ambiciones imperiales" del gobierno de este país en el mundo. En general, se le considera un crítico del capitalismo y también ha hablado en contra del darwinismo social de Herbert Spencer.

Se define a sí mismo como partidario de la tradición anarquista, especialmente de la corriente de orientación laboral del anarquismo, el anarcosindicalismo, y es miembro del célebre sindicato revolucionario estadounidense IWW, al que también perteneció su padre. Pese a ello, no se opone totalmente a la política electoral, al menos en el ámbito de la estrategia: su postura en las elecciones de Estados Unidos es que los ciudadanos deberían votar por los demócratas locales si con ello se consigue sacar del poder a los republicanos, mientras que en las situaciones donde las victorias republicana o demócrata están claras ha pedido el voto para candidaturas más a la izquierda, como las del Partido Verde. Es uno de los más importantes colaboradores del grupo mediático independiente Z Communications. Esta actuación se inscribe claramente dentro de la tradicional táctica anarcosindicalista de impulsar movilizaciones populares que coaccionen la acción de los poderes públicos y fácticos hasta conseguir cambios concretos y reales (véase el prefacio de Chomsky al libro de Rudolf Rocker, "Anarcho-Syndicalism: Theory and Practice", 1989).

Desde un punto de vista más personal y filosófico, también se considera un conservador de la variante liberal clásica ("Chomsky's Politics", pp. 188) y se ha definido como un sionista; aunque observa que la mayoría considera como antisionista su definición de sionismo. Percibe un cambio en el significado del sionismo ("Chomsky Reader") desde la década de 1940. En la misma línea y rescatando su contenido libertario, Chomsky ha declarado su admiración y adhesión al kibutz como forma social alternativa.

Con el tiempo, se ha convertido en una de las principales figuras de la política radical estadounidense. Junto a José Saramago o Leonardo Boff, entre otros, es uno de los principales intelectuales de la izquierda en el mundo, pese a lo cual, a diferencia de su actividad científica, su aportación teórica en el ámbito político no es demasiado relevante. Nunca se ha considerado un teórico en política, sino simplemente un ciudadano informado que mantiene una actitud muy crítica hacia la ideología dominante. Chomsky cree que, mientras la actividad científica no está al alcance de cualquiera (ya que exige una formación y una abstracción conceptual muy elevada), para la actividad de crítica política basta una cierta apertura de espíritu. Ha reiterado a menudo que la política debería ser cosa de todos y no dejarse en manos de la "intelligentsia", ni mucho menos aceptar que solo los profesionales de la política (sean periodistas, intelectuales o políticos) sean los únicos capacitados para opinar sobre política.

Uno de sus principales aportes intelectuales ha sido el análisis de los medios de comunicación. En sus estudios sobre el tema se ha ocupado de los enfoques sesgados, o incluso engañosos, que hay detrás de la supuesta neutralidad de los medios más prestigiosos. Se trata de un trabajo de «contrainformación» que ha obtenido gran difusión y que muchos otros han continuado. Fruto de este esfuerzo es el libro "Los guardianes de la libertad," escrito junto con Edward S. Herman, profesor de la Universidad de Pensilvania.

Su denuncia de la política exterior de Estados Unidos, de las deficiencias democráticas de su maquinaria política, y de los engaños de los grandes medios de comunicación en este país, supone poner en duda tres de los pilares del nacionalismo estadounidense. Por otro lado, su visión sobre la política del estado israelí en Oriente Medio es parte de su crítica a la política exterior de Estados Unidos. Chomsky señala que desde hace años la maquinaria militar israelí depende enormemente del apoyo material y diplomático de Estados Unidos, y que ambos estados realizan sistemáticamente acciones violentas al margen de las leyes internacionales. Esta última circunstancia ha motivado que Chomsky declare que según los criterios internacionales actuales, ambos estados ejercen el terrorismo. En concreto en su libro "11/09/2001", afirma que los Estados Unidos es «uno de los principales estados terroristas» («"a leading terrorist state"»). Noam Chomsky lo publicó en diciembre del 2001, tres meses después de lo sucedido en Nueva York. Es un ensayo sobre los hechos y las consecuencias de los atentados del 11 de septiembre. Se basa en una estructura de siete largas entrevistas de periodistas extranjeros durante el primer mes y medio posterior a los ataques al World Trade Center y al Pentágono. No analiza únicamente las causas, las consecuencias de los atentados y la reacción del pueblo norteamericano, sino que cuestiona las razones de la guerra y los bombardeos. En este libro Chomsky refleja de nuevo su visión crítica con el poder y la industria militar.

A raíz de estas denuncias, varios detractores de Chomsky lo han tildado de antiestadounidense. Algunos incluso han comprendido sus críticas como una supuesta obsesión antiestadounidense y antisionista. Para algunos nacionalistas, es especialmente controvertida su crítica a la política del gobierno de Israel, por su origen judío. También ha sido polémico su apoyo a la libertad de expresión en los que se conoce como el escándalo Faurisson. En la década de 1970, Robert Faurisson realizaría un estudio y escribiría un libro en el cual concluye que muchos de los acontecimientos del holocausto ( como las cámaras de gas) no existieron realmente. Chomsky firmaría una petición para garantizar a las autoridades la libertad de expresión, aclarando que él mismo no compartía el punto de vista negacionista, pero que no reconocía expresiones antisemitas en el trabajo de Faurisson. Chomsky califica al holocausto como "la peor muestra de locura colectiva en la historia de la humanidad", pero considera fundamental garantizar la defensa de la libertad de expresión, incluso para aquellas ideas popularmente mal vistas. Por último, destaca la crítica que hace de la izquierda posmoderna y de su entusiasmo por el relativismo cultural que, al "deconstruir" la noción de verdad, ha invalidado también la posibilidad de la crítica.

Chomsky ha pedido a EE. UU. y a Canadá levantar sanciones económicas impuestas a Venezuela .

Chomsky es uno de los detractores de la globalización, y esto se debe a su forma de entender la hegemonía del capitalismo moderno. Para Chomsky, Estados Unidos no cree en el libre comercio sino que lo utiliza como un método mediante el cual los países más fuertes imponen a los países pobres la obligación de cumplir unas normas coercitivas y rígidas (la ley del embudo).

El objetivo básico de la globalización económica es globalizar toda la economía mundial, y Estados Unidos controlaría la economía mundial con el apoyo de los organismos satélites (Fondo Monetario, Banco Mundial, Organización Mundial del Comercio).
El argumento habitual a favor del libre comercio liberalizado es que conducirá a un aumento generalizado de los niveles de vida. La experiencia ha demostrado que con la apertura de los mercados comerciales y financieros los inversores y empresarios han ganado mucho más dinero, pero gran parte de los países más pobres han sido las víctimas de un descenso pronunciado de sus niveles de vida.

Según precisa Noam Chomsky:
Sus afirmaciones políticas le han concitado un gran número de simpatizantes, en amplios sectores de la izquierda, especialmente europea y latinoamericana, y también algunos detractores. Su libro "11 de septiembre" ("9/11") tuvo una gran difusión, pese a haber sido publicado por una pequeña editorial. Solo la edición de este libro en inglés vendió centenares de miles ejemplares, y ha sido traducido a varias lenguas. Posteriormente, su libro "Hegemonía o supervivencia: la búsqueda estadounidense del dominio global" fue recomendado por el presidente de Venezuela Hugo Chávez en su discurso frente a la asamblea general de la ONU el día 20 de septiembre de 2006, lo que ocasionó que dicho libro, en aproximadamente dos días, pasase del puesto 160.772, al número 2 de los libros más vendidos en Amazon.

En cuanto a España, en 2009, firmó un manifiesto de apoyo a la candidatura a las elecciones europeas de la formación política Izquierda Anticapitalista, y en 2014 en apoyo de la formación política Podemos.

Desde 2009 es miembro honorario de AIPTI.

En diversas ocasiones se le ha preguntado a Chomsky si tiene una postura religiosa o es ateo, a lo cual él respondió en una ocasión:

En una discusión con Lawrence Krauss y Sean M. Carroll en el 2006, Chomsky dio una respuesta similar:
Adicionalmente, Chomsky ha reconocido los límites de la razón humana, y claramente ha rechazado el cientificismo (la idea de que la ciencia lo puede explicar todo):

Por otra parte, Chomsky ha dejado claro que su postura no es antirreligiosa, pues como analista social, al igual que muchos otros autores, ha reconocido que hay una diferenciación radical entre el cristianismo de los evangelios en contraste con el de la mayor parte de los gobiernos y organizaciones religiosas:

Además, ha hablado favorablemente de la teología de la liberación y ha reconocido la labor de movimientos que han tratado de restaurar y rescatar los principios del cristianismo primitivo:









</doc>
<doc id="15410" url="https://es.wikipedia.org/wiki?curid=15410" title="Economía de Francia">
Economía de Francia

La economía de Francia es la quinta economía más grande del mundo, con un Producto Interno Bruto (nominal) de 2 billones, 574.807 millones de dólares) en 2017 en términos absolutos. A nivel regional, la francesa es la segunda mayor economía de Europa, detrás de Alemania.

El sector de los servicios ocupa al 75% de la población, mientras que el primario a menos del 2% y el secundario al 24%. La economía francesa es una economía cada vez más abierta, representando un lugar importante en el comercio internacional. Francia es el quinto país por sus exportaciones y el sexto por sus importaciones. En 2016, las exportaciones francesas representaron al 20% del su PIB y las importaciones un 23%. La tasa de desempleo sigue siendo más alta que la de otros países desarrollados. 

La industria química es un sector clave para Francia, ya que esto ayuda a desarrollar otras actividades de fabricación y contribuye al crecimiento económico. La industria turística de Francia es un componente importante de su economía, ya que Francia es el destino más visitado del mundo. Sophia Antipolis es el principal centro tecnológico de la economía de Francia. Según el Fondo Monetario Internacional, en 2013, Francia fue el vigésimo país del mundo por PIB per cápita con USD 44,099 dolares por habitante. En 2013, Francia se incluyó en el Índice de Desarrollo Humano de las Naciones Unidas con 0,884 (muy alto desarrollo humano) y en el puesto 25 en el Índice de Percepción de la Corrupción. La OCDE tiene su sede en París, la capital financiera de la nación.

La economía de Francia entró en la recesión de finales de la década de 2000 más tarde y pareció salir antes que la mayoría de las economías afectadas, solo soportando cuatro cuartas partes de la contracción. Sin embargo, Francia experimentó un crecimiento estancado entre 2012 y 2014, con una expansión de la economía de 0% en 2012, 0,8% en 2013 y 0,2% en 2014, aunque el crecimiento repuntó en 2015 con un crecimiento del 0,8% y un crecimiento de 1.1% para 2016, y un crecimiento pronosticado de 1.6% para 2017 y 1.8% para el año 2018, ambos pronostican un crecimiento para cada uno de los niveles más altos desde 2011 (2.1%).

En 2017, el 10 % más rico de los franceses poseen más de la mitad de la riqueza del pais mientras que el 50 % de los más pobres tienen el 5 %.

Desde sus inicios, el poder económico de Francia ha sido a menudo vinculado a la demografía. En virtud de Luis XIV, fue el país más poblado de Europa y, por tanto, el económicamente dominante. Estaba, sin embargo, obstaculizada por la debilidad estructural de sus flota mercante y militar.

Mientras que la primera Revolución Industrial comenzó en Inglaterra en el siglo XVIII (que le permite superar Francia), y luego se extiende al Benelux, Francia solo la conoció durante la segunda mitad del siglo XIX, gracias a la liberalización económica bajo el Segundo Imperio y el comienzo de la Tercera República. A fin del siglo, Francia era un país próspero y poderoso, que había superado la potencia económica de Inglaterra y que seguía extendiendo y ampliando sus asentamientos.

En 1880, producía el 10% de la producción mundial. Luego, su poder económico se debilitó gradualmente por de las malas políticas económicas y un bajo crecimiento de su población agrícola. En el siglo XX, las guerras mundiales y la descolonización redujeron su peso.

Entre 1946 y 1973, vivió un período de fuerte crecimiento (un promedio de 5% por año) que el economista Jean Fourastié clasificado como los Treinta Gloriosos. Este fuerte crecimiento se debía principalmente a unas periodos muy importantes de trabajo y a un fuerte aumento de la productividad, gracias a la actualización tecnológica respecto a la potencia dominante, los Estados Unidos, pues la economía francesa tenía mucho retraso económico. Así, en 1950, el ingreso promedio de un francés representaba poco más de la mitad de la de un americano (55%), mientras que llegó a las cuatro quintas partes en 1973.que dio forma al Estado de Bienestar. El Estado, en los países occidentales, asumió tareas activas en relación con las posibilidades de incidir directamente sobre la actividad económica, en cuestiones como el nivel de empleo, de demanda y de inversión.

El final de la recuperación coincidía con el final del período de fuerte crecimiento. La fuerza de trabajo hace poco crecimiento durante este período, a pesar del "baby boom", porque la fuerza de trabajo hacía estudios más largos que antes. La economía francesa se ha beneficiado de Mercado Común Europeo, desde 1957. Francia fue uno de los países fundadores de la Unión Europea en los años cincuenta.

Los franceses disfrutan de un alto nivel de vida, pero su sentido es vivir un período de crisis desde el final de los Treinta Gloriosos. Durante mucho tiempo, esta "crisis" no impidió un crecimiento significativo, y mantener la economía a nivel mundial envidiable, pero desde el decenio de 1980, los temas de "declive" y el temor de la competencia extranjera (la globalización, incluso la integración europea) han sido mucho más importante, mientras que los indicadores económicos son cada vez más alarmantes. En particular, el desempleo ha aumentado y, a pesar de un descenso a partir de 1997, la tasa media de desempleo sigue siendo más de 3 puntos de la de los países del G7.

En Francia en 1990, el PIB per cápita en PPP representaba el 75% del de los Estados Unidos, frente al 70% en 2006. Durante años, Francia ha seguido siendo la cuarta economía más grande, y la diferencia con Gran Bretaña (2.346 millones en 2006) ha sido baja. En cambio, el exceso en este ranking por China, y después por la India, es inevitable.

Algunas estadísticas macroeconómicas muestran una disminución significativa en una parte de las clasificaciones económicas internacionales sobre los veinticinco últimos años. En 1980, Francia fue uno de los países más ricos del mundo: el PIB per cápita fue el sexto más grande del mundo, detrás de los Estados Unidos, Suiza, Luxemburgo, Islandia o Canadá. Se superaba algunos rivales económicos como Alemania, Japón o el Reino Unido. El nivel de vida en los países escandinavos también estaba por debajo del francés. El decenio de 1980 fue de relativo declive económico.

En 1994, el PIB per cápita de los franceses era el décimo tercero a escala global. Algunas economías, como las de Alemania o Japón, han visto un aumento importante. Otros han sufrido una caída aún más fuerte que la francesa, como la de Canadá.

En 1999, la introducción de la moneda única marco el deseo de estrechar la cooperación económica de la mayoría de los países de la Unión Económica y Monetaria. En 2004, el PIB per cápita en Francia es el 16 o 17 más grande del mundo.

En 2005, la deuda pública francesa superó el 60% del PIB. La tasa de actividad de los franceses es inferior a la de los otros países desarrollados, por la entrada tardía de los jóvenes en la vida laboral (22 años en promedio), la reducción de la edad efectiva de jubilación (57 años) y la baja tasa de empleo de la población en edad de trabajar. El tiempo legal de trabajo se redujo a 35 horas semanales en 2002

La tasa de empleo (63,8% en 2006), cerca de la media europea (64,8%) es inferior a la UE-15 (66,2%), y el promedio de los países desarrollados, especialmente para personas de la tercera edad, los jóvenes menores de 30 años y poco calificados.

El crecimiento del PIB per cápita francés es menor que la de otros países durante los dos últimos decenios. Durante los últimos años una fuerte oposición social en contra de las reformas del mercado laboral ha impedido que el gobierno intente reactivar la economía a costa de la seguridad de los trabajadores. En 2007, el gobierno ha lanzado importantes esfuerzos para reformar la economía. En 2007, el déficit del presupuesto público ha vuelto a estar dentro de la limitante del 3% del PIB impuesta por la Unión Europea, y el paro ha bajado de 9%.

Francia atraviesa por una transición, desde una economía moderna y desarrollada con una importante presencia del gobierno, hacia una donde el mercado carece de regulaciones. El gobierno ha privatizado varias grandes empresas, bancos y aseguradores. Aún tiene una fuerte presencia en algunos sectores, particularmente la energía, el transporte público, la defensa y la industria. Las telecomunicaciones se abren cada vez más a la competencia. La presión fiscal es una de las más altas en Europa (casi el 45% del PIB).

En 2017, el endeudamiento del sector público alcanza el 98 % del PIB, y el endeudamiento del sector privado el 130 % del PIB. En diez años, la deuda de las empresas francesas aumentó de 750 mil millones de euros.

Francia, con 834.000 nacimientos en 2008 (contra 543.000 decesos) es el país europeo donde nacen más personas y uno de los pocos países donde el crecimiento de la población no está asegurada por la sola inmigración. Mientras que la población francesa estaba tan grande en 1945 que en 1900 (alrededor de 41 millones de habitantes), en 2008 incluye más de 64 millones de franceses.

Pero la importancia de esos nacimientos se debe principalmente al hecho de que las madres pertenecen a las generaciones del baby-boom. Pero en las treintas próximas décadas las mujeres serán menos que sus madres. Así, alrededor de 2050, los nacimientos y las muertes deberían ser equilibradas.

En 2006, Francia se convirtió en el primer país de Europa en materia de fecundidad, superando Irlanda por primera vez. Con una tasa de fertilidad de 2 hijos por mujer, El país está en una situación cercana a la de la década de 1960, después de un largo paréntesis durante el cual la simple sustitución de generaciones no estaba garantizada.

El punto más bajo se había alcanzado a mediados de 1990 con una tasa de 1,65. En toda Europa, hay una reanudación de la fertilidad, pero sigue en niveles muy bajos en países como Polonia (1,23 hijos por mujer), Italia (1,33) o la Alemania (1,37), donde a menudo las mujeres deben elegir entre el trabajo y la maternidad.

Francia se caracteriza por altas tasas de fecundidad y una fuerte participación de las mujeres en la fuerza de trabajo con una tasa de participación del 80% para las mujeres de 25 a 49 años. Además, este equilibrio entre la maternidad y el trabajo se realiza sin un gran trabajo a tiempo parcial como en el Reino Unido o los Países Bajos (donde el 75% de las mujeres son a tiempo parcial).

El trabajo no impide tener hijos, incluso eso crea condiciones favorables para mejorar la fertilidad. Desde hace mucho hay una política familiar para desarrollar viveros (320 000 niños en 2005 es decir un niño de cada diez) y acoger a todos los niños en la escuela a 3 años. Otras medidas incluyen las prestaciones familiares pagadas a los padres, los beneficios fiscales relacionados con la presencia de niños, la mejora de las competencias relacionadas con los niños (cuidadores), el desarrollo de la licencia parental.

Más de 13 000 franceses en 2009 superaron 100 años, y podrían ser 60 000 en 2050, entre los cuales una gran mayoría de las mujeres. Hoy en día, la esperanza de vida al nacer (o vida media) es de 77 años para los hombres y 84 años para las mujeres y aumenta en dos o tres meses al año. En 1950, la esperanza media de vida en los países desarrollados era de alrededor de 66 años.

La población se alimenta mejor que antaño, la higiene es mejor y las enfermedades infecciosas han disminuido significativamente, afectando hoy más los niños que las personas mayores, mucho mejor curadas que en el pasado. Por lo tanto, el porcentaje de personas de la tercera edad (60 años y más) en la población en 2009 es alrededor del 22%.

En 2050, Francia puede contar (según los demógrafos) alrededor de 20 millones de personas de más de 60 años, y entre ellos la mitad de 75 años y más, casi un tercio de la población de entonces. La mediana de edad (la edad por debajo de la cual es la mitad de la población) aumentaría de 37 a 45 años, un fenómeno común a todos los países desarrollados.

Por lo tanto, el futuro de las pensiones es en cuestión. En el sistema francés de los regímenes de pensiones, deben ser, en principio, un equilibrio entre los ingresos, alimentado por las contribuciones de personas que trabajan y los gastos de las pensiones de jubilación consistirá. Este equilibrio se ve seriamente amenazado.

En 2005, había en Francia más de 195 contribuyentes por 100 jubilados, debido a una combinación de factores, entre ellos el desempleo, la baja participación de la mujer antes de la década de 1970, la edad de jubilación a los 60 años y la entrada tardía de los jóvenes en el trabajo. Dentro de 25 años, la situación podría empeorar si estos factores se combinan, y Francia podría haber dos jubilados por tres activos.

El envejecimiento de la población causa inevitablemente un aumento en el consumo de medicamentos, y, por tanto, en los costes sanitarios. Según las análisis más pesimistas, podría haber entre 2000 y 2050 un crecimiento del 40% en el gasto en salud debido únicamente al envejecimiento, y el presupuesto de la salud podría representar un tercio del PIB. Desde un punto de vista médico, parece urgente desarrollar la investigación que podría evitar, o prevenir ese tipo de aumento de los costos asociados con una vida útil más larga.

La migración neta en Francia se estima en 75 000 personas en 2008. Francia mantiene su especificidad en comparación con sus vecinos europeos en los cuales la migración contribuye a una cuarta parte del crecimiento de la población, mientras que representa el 80% del crecimiento de los veinticinco países de la Unión Europea.

Desde 1975, la proporción de inmigrantes en la población se ha mantenido estable, pero la inmigración ha cambiado: las migraciones por motivos familiares han aumentado, hay más mujeres y vienen de países cada vez más lejanos. Los inmigrantes son más frecuentemente casados que el resto de la población y con más niños. Tienen bajos ingresos y se concentran en las grandes ciudades.

Los inmigrantes son más afectadas por el desempleo, ocupan puestos de obreros o empleados en los servicios con poca cualificación. Sin embargo, su representación excesiva en la industria y la construcción está bajando. Además, los descendientes de los migrantes tienen el mismo estatuto social y nivel de vida que los nativos de misma origen social.

El desempleo de los inmigrantes es uno de los mayor problemas. Los inmigrantes tienen más probabilidades que los nativos de estar desempleados o haciendo un trabajo para los que son sobrecalificados. Para los hijos, aún cuando nacieron en Francia y con calificaciones, también resulta difícil encontrar trabajo. Los inmigrantes, especialmente los recién llegados, se encuentran entre los más afectados en crisis económicas, ya que muchos tienen puestos de trabajo poco cualificados o trabajan en sectores cíclicos, como la construcción. Las capacidades de los inmigrantes altamente cualificados no son altamente utilizadas y reconocidas.

La población activa en Francia, según la definición del OIT (personas entre 15 y 64 años que tienen un puesto de trabajo o están desempleados) estaba acerca de 28 millones de personas en 2007. Entre ellas, unas 25,5 millones de personas estaban empleadas, o sea unas 2,5 millones se encontraban en el desempleo según la OIT. Eso corresponde a una tasa de participación de una tasa de empleo de 64,5%.

La tasa de participación de las mujeres es del 65% (y el tasa de empleo del 60%) contra el 75% (tasa de empleo 69%) para los hombres, y las mujeres representan un 47% de la población activa total. Si se toma como referencia la población de más de 15 años (49,5 millones de personas), la tasa de participación es del 56%. La de los hombres es del 62% y de las mujeres del 51%.

En cuanto al paro, la situación del mercado del trabajo ha mejorado en los últimos años, pero la diferencia con respecto a países con mejores resultados siguen siendo significativa. Mientras que había alcanzado un 12% en 1996, la tasa de desempleo francés se redujo al 7,5% a mediados del 2007. Esta sigue siendo, sin embargo, un punto porcentual por encima de la media de EU-15 y casi tres puntos por encima de la media de la OCDE. Otro problema es que el desempleo en Francia puede durar más tiempo que en otros países: 40% de los desempleados quedan en el paro más de un año, y 20% más de dos años.

Mientras que la población había aumentado durante el siglo XIX, el número de activos evolucionó poco en cincuenta años. En 1962 como en 1911, el censo de población contaba 20 millones de activos, contra 13 millones en 1806. La población en edad de trabajar (15-64 años según la definición de la OIT) aumentó en 3,3 millones entre 1911 y 1962, pero la tasa de actividad bajó. Según los censos, la fuerza de trabajo representaba el 69% de los 15-64 años en 1962 contra el 78% en 1911.

El trabajo hembro está en declive a cualquier edad, porque el peso relativo de la agricultura está disminuyendo. Desde 1921, las tasas de actividad para los hombres jóvenes (15 a 24 años) y más antiguos (más de 60) también están a la baja. Sin embargo, aproximadamente siete de cada diez hombres de 15 a 24 años, como de 60 a 64 años, aún estaban activos en 1962. A principios de los años sesenta, hubo tres movimientos: la avanzada de la generación baby boom, la migración y el flujo de las mujeres en el mercado laboral. A partir de 1975 y hasta 1995, los ancianos y los jóvenes son "excluidos" del mercado laboral.

Desde los principios de los años sesenta, el número de empleos creció rápidamente con un ritmo cercano a lo de la población activa. La desaceleración de la actividad económica puso fin a esta situación. El número de puestos de trabajo se redujo en cerca de 400 000 durante la primera mitad de la década de los ochenta y, a continuación, 500 000 de 1991 a 1993, mientras que en las etapas de la recuperación (76-79, 86-91) el empleo creció a un ritmo cercano a lo de los años sesenta. De eso resultó el aumento del desempleo masivo y persistente.

La población en edad de trabajar disminuirá después de 2010, pero la población seguirá aumentando durante varios años. Más allá de 2020-2030, es difícil anticipar los cambios en la fuerza de trabajo. La disminución de la fuerza de trabajo podría detenerse, al menos parcialmente. La edad de cese de actividad podría aumentar aún más debido al aumento de la duración de contribución. La tasa neta de migración de los trabajadores puede aumentar. También podría haber un aumento de la fecundidad más allá de 2030.

A pesar de una creciente diversidad en el mercado laboral y de la mejor cualificación de las mujeres, las principales diferencias entre hombres y mujeres en cuanto a los puestos de trabajo se mantienen. Hay ocupaciones que quedan principalmente el monopolio de un sexo. Las mujeres ocupan puestos en los servicios personales, la educación, la salud y la acción social. En constrate, la construcción son sectores masculinos. También, mucho más mujeres ocupan puestos a tiempo parcial y tienen puestos menos estables. Casi una de cada tres mujeres trabajan a tiempo parcial, contra un hombre de veinte.

Una persona de cada dos de más de 15 años y casi dos tercios de personas en edad de trabajar (15-64 años) trabajan. Pero a todos los periodos de la vida, la tasa de empleo de los hombres es mayor de la de las mujeres. Entre 25 y 49 años, la diferencia es más pronunciada: 89% de los hombres de esa edad están en el empleo, frente al 76% de mujeres.

En estas edades, las madres suelen ser menos activos en el mercado de trabajo que otras mujeres (80% contra 89%) en contraste con los hombres que suelen ser más activos cuando tienen hijos. Entre 15 y 25 años, esta diferencia es menor (68% de los hombres y 71%). Al final de la vida, entre 55 y 64 años, el 44% de los hombres y el 39% de mujeres son empleados. En total, más del 51% de las mujeres de 15 años o más son activas, 10 puntos menos que los hombres. Sin embargo, en comparación con Europa, las mujeres francesas son los más activos detrás de países nórdicos (Dinamarca, Finlandia, Noruega y Suecia).

Los inmigrantes se encuentran entre los trabajadores poco cualificados y trabajan en sectores como los servicios a los particulares, las ventas, la construcción y obras públicas. En un contexto general de envejecimiento de la población en Europa, con perspectivas disminución de la población en edad de trabajar, la inmigración va a desempeñar un papel de apoyo para satisfacer las necesidades del mercado laboral. A pesar de la liberalización del mercado laboral en Europa, la inmigración europea es minoritaria.

Las minorías raciales son más frecuentemente en desempleo que el resto de la población, en parte por culpa a la discriminación. La discriminación por motivos de origen étnico para la contratación de nuevos empleados es ilegal, y hay leyes que sancionan tal práctica, pero sólo el 29% de los ciudadanos franceses conocen esta ley: esta falta de sensibilización de la opinión pública constituye un fuerte obstáculo para la aplicación efectiva de las normas jurídicas. De hecho, para que las leyes se cumplan, las personas tienen que tomar acciones legales, así los trabajadores deben saber que tienen el derecho legal a la igualdad de trato. Por eso, la HALDE (Alta Autoridad de Lucha contra la Discriminación y Promoción de la Igualdad) fue creada en 2005 para llevar campañas de información y educación.

Aunque es demasiado pronto para evaluar su impacto, la HALDE tiene una fuerte influencia, y puede desempeñar un papel importante en la lucha contra la discriminación. Tiene facultades de investigación a fin de que puedan ayudar a un individuo para reunir evidencia de discriminación, puede investigar a las empresas, incluso en ausencia de una reclamación individual, y puede aplicar sanciones cuando hay pruebas de discriminación, y por fin puede ayudar para resolver un conflicto de discriminación a través de la mediación en lugar de acciones judiciales.

La situación del mercado laboral de los jóvenes y los trabajadores de más edad sigue siendo un problema. Los trabajadores de edad media trabajan mucho en Francia, con el 82% de las personas entre 25 a 54 años que tienen un empleo, contra el 77% en la zona de la OCDE. Por el contrario, la tasa de desempleo entre los jóvenes de entre 15 a 24 años es del 20%, 4 puntos porcentuales más que en la zona de la OCDE. En Francia, los jóvenes se enfrentan a fuertes obstáculos para obtener empleo en todos los niveles de escolaridad.

Asimismo, sólo el 38% de las personas entre 55 y 64 años están trabajando, 15 puntos porcentuales inferior a la media de la OCDE. Esta situación de bajas tasas de empleo de los trabajadores de más edad se debe a impuestos significativos, a un edad oficial de jubilación muy bajo (60 años), y a programas de jubilación con antelación financiados por el Estado.

Sin embargo, los gobiernos han adoptado medidas en los últimos años para mejorar la situación. Es posible jubilarse más tarde que antes, y medidas han sido adoptadas para aumentar los ingresos de los que trabajan más allá de la edad oficial de jubilación. Los programas de jubilación con antelación fueron reducidos. Usando la interfaz de usuario del sistema como una forma de jubilación anticipada se ha hecho más difícil. Pero la facilidad del acceso ampliado a las prestaciones por desempleo y períodos de contribución a niveles demasiados bajos siguen siendo problemas.

Casi el 90% de los trabajadores están contratados por un empleador: son 23 millones contra 2 millones de independientes. El empleo por cuenta propia (independientes) sigue siendo una minoría. La proporción de empleados independientes es dos veces más alta entre hombres que entre las mujeres. Los jóvenes están menos interesados en el empleo por cuenta propia: entre los menores de 25 años, menos del 2% tienen un empleo por cuenta propia; entre más de 50 años, la proporción es de casi el 16%. 

El sector terciario emplea a ocho de cada diez empleados, y en este sector, el sector público incluye a dos empleados de cada diez.

20 millones de empleados tienen un contrato permanente y 3,1 millones tienen otros tipos de contratos (temporales, contratos a plazo fijo, pasantes, aprendices y contratos "ayudados"). Estas formas de empleo representan el 12% del empleo. Sin embargo, la mayor parte de los nuevos empleos son a duradera limitada.

La legislación de protección del empleo es bastante estricta. Las normas para los despidos en gran escala son significativas, las indemnizaciones legales son altas, hay restricciones sobre el uso de contratos de duración determinada y limitaciones sobre el tiempo de trabajo. Eso acarrea un aumento en los costes ambos de los despidos y de la mano de obra, reduciendo así la contratación. Sin embargo, los gobiernos de los últimos años han tomado medidas, tales como la suspensión de las leyes más estrictas de protección del empleo.

La rigidez del mercado laboral puede ser medida por el nombre de puestos de trabajo ocupados por personas desde hace menos de un año. Solo un 12% de los puestos de trabajo están ocupados por personas que trabajan en su empresa por menos de un año. La tasa de renovación de la mano de obra es el más alto en la construcción (alrededor del 17%). En casi todos los sectores del sector terciario, es más bajo, excepto en los servicios domésticos y personales (casi el 20%). En la administración, es del 6%, y en la industria menos del 9%.

El sueldo mínimo es muy alto en comparación con otros países de la OCDE y reduce la contratación, especialmente para ciertos grupos como los jóvenes y los trabajadores poco cualificados. Desde hace dos décadas, los gobiernos han adoptado medidas de grandes reducciones de las cotizaciones sociales para los trabajadores con bajos salarios. Eso permito reducir los costes laborales, pero esta tendencia se ha ralentizado recientemente con la legislación sobre las 35 horas semanales.

Francia es ahora uno de los países de la OCDE donde la gente trabaja menos. El gobierno llevó a cabo al principio de los años 2000 una política de reducción del tiempo de trabajo, lo que empeoró la situación. No hay ningún país de la zona de la OCDE que haya aplicado esas políticas. Fue impuesta de manera autoritaria, por dos leyes de 1998 y 2001, y requiere el mantenimiento del poder adquisitivo de los empleados, mientras que otorgaba un apoyo financiero para las empresas. Por último, fue una política para crear nuevos empleos (así se llevó a cabo en una situación económica favorable). Los efectos a corto plazo de esta medida han sido probablemente positivos.

En una perspectiva a largo plazo, hay preocupaciones de que esta política de reducción colectiva del tiempo de trabajo pesa fuertemente sobre las finanzas públicas y penalice el potencial de crecimiento económico. Otros consideran que la disminución del tiempo de trabajo facilita su reparto y la creación de nuevos empleos, además de incrementar la retribución del trabajador por hora trabajada.

Además, sólo el 64,5% de las personas en edad de trabajar (15-64 años) tienen un empleo en Francia, en comparación con más del 70% en países de la OCDE como Canadá, Dinamarca, los Países Bajos, Suecia, Estados Unidos y el Reino Unido. Según el OCDE, eso puede explicar la situación difícil del mercado labora en Francia.

La salud mental de los trabajadores ha empeorado ligeramente en Francia en la última década. Al mismo tiempo, la proporción de los trabajadores sufriendo de problemas de salud mental está cerca de la media de la UE. Trabajos relacionados con los problemas de salud mental son más a menudo asociadas con las condiciones de trabajo más difíciles, tales como largas jornadas de trabajo y discriminación laboral.

Las condiciones de trabajo que tienen un impacto sobre la salud mental se han empeorado en Francia (la intensidad del trabajo y el cambio frecuente de trabajo), pero ciertos aspectos han mejorado (la discriminación en el lugar de trabajo). Sin embargo, la enfermedad mental sigue siendo más frecuente entre los desempleados o las otras personas inactivas, que entre aquellos que tienen un puesto de trabajo.

Francia es la primera potencia agrícola de la Unión Europea. Es el segundo mayor exportador mundial de productos alimentarios, detrás de los Estados Unidos, y el excedente del comercio exterior de este sector ascendió a 9 mil millones de euros en 2007. En 2005, la agricultura empleaba a cerca de un millón de personas (6% de los activos). En 2008, los ingresos agrícolas netos eran de 23 millones de euros (2% del PIB), incluyendo 7 millones de subvenciones.

La parte de los agricultores en la población laboral francesa de la fuerza laboral está disminuyendo, pero la agricultura sigue siendo uno de los sectores más dinámicos. Se ha modernizado mucho desde hace tres decenios, cuando han sucedido espectaculares aumentos en la productividad gracias a rendimientos muy fuertes.

Los principales cultivos son cereales (trigo, maíz) y el azúcar (gracias a los territorios de ultramar), vino, productos lácteos, frutas y hortalizas, animales y productos cárnicos, que son exportados y que generan excedentes. Por el contrario, la pesca conoce dificultades y es deficitaria. Francia tiene una de las mayores ganaderías de la Unión Europea: incluye más de 20 millones de cabezas de ganados, 16 millones de cerdos y 9 millones de ovejas.

Produce casi una cuarta parte de la carne consumida en Europa, es el mayor productor europeo de carne de aves y el tercer productor de ovinos y porcinos. En 2007, Francia producía 60 millones de toneladas de cereales, de los cuales alrededor de la mitad está representada por el trigo para el consumo de alimentos del ganado. La cebada y el maíz son también utilizados para el ganado. Produce alrededor de 6 millones de toneladas de carne y 20 millones de toneladas de frutas y hortalizas.

La agricultura constituye el apoyo de una fuerte sector industrial de los alimentos (sector secundario). Sector importante de la economía francesa, representa un volumen de negocios de 140 mil millones de euros, incluyendo 25 mil millones para las exportaciones. Con casi 400 000 empleados, la agroindustria es el tercer mayor empleador de la industria francesa. La industria alimentaria también es un mercado muy abierto para la exportación, que genera un superávit comercial importante. Las ventas de vinos llegan por delante de los productos más exportados, seguido de productos lácteos y del sector de los cereales.

La Política Agrícola Común (PAC), que fue creada a iniciativa de Francia para fortalecer la agricultura nacional, ha sido una fuente permanente de problemas, por no mencionar los conflictos políticos en Europa.

La industria francesa es la secunda en Europa y la novena más grande del mundo. El sector secundario representa el 20% de los puestos de trabajo, el 40% de las inversiones y casi el 80% de las exportaciones francesas. Sin embargo, aunque la industria ha visto su producción aumentar, perdió cerca de 1,5 millones de puestos de trabajo durante los últimos veinticinco años. La industria francesa ha experimentado una rápida fusión de sus negocios y una rápida expansión de sus inversiones directas en el extranjero. En el año 2008, las empresas francesas y sus 20 000 filiales fuera del hexágono empleaban 3,7 millones de personas. Las empresas controladas por grupos extranjeros emplean el 30% de los empleados.
La industria francesa posee una fama y prestigio muy importantes, reflejando el "savoir-faire" francés en los diferentes sectores de las industrias tradicionales como la automoción, el material ferroviario, el lujo, la moda y las industrias de la alimentación, sino también el éxito de tecnologías como el sector de la energía o aeronaves y naves espaciales.

Francia tiene otros sectores fuertes como las telecomunicaciones, las producción de tarjetas de chips (más del 80% de la producción mundial). La industria aeronáutica y espacial está dominada por grandes empresas, entre ellas Dassault, Airbus, Aérospatiale o Matra. La densidad del red industrial y su calidad aseguran una presencia permanente de empresas que sub-contratan muchos servicios para las empresas.

Durante toda la década 1990 (excepto en 1993) y hasta el comienzo de los años 2000, la industria francesa estaba un sector lidero en la economía nacional, creando muchos empleos y mejorando cada año su productividad. Estaba una industria competitiva y diversificada que generaba superávites comerciales récords, estabilizando sus cuotas de mercado delante Reino Unido y Italia. Pero a comienzos de los años 2000, el sector sufrió mucho la crisis mundial y está acumulando deficites exteriores y perdiendo cuotas de mercado desde 2001, con un alza de los costes y una baja significativa de la competitividad.

"Para la industria energética y la industria de transportes, ver arriba Infraestructuras""Para la industria agroalimentaria, ver abajo Agricultura"

La industria del automóvil desempeñaba un papel de liderazgo en el crecimiento de la producción industrial. Los fabricantes se concentran cada vez más en su diseño y montaje, y subcontratan una gran parte de otras funciones, pero hay un efecto multiplicador en las industrias productoras de bienes (acero, plástico, vidrio...), que representan el 30% de sus consumos intermedios, así como la producción de equipos mecánicos (máquina-herramienta), pero también las industrias de servicios (vehículos de transporte y sus partes). Así, 2 465 000 empleos dependen indirectamente de la industria automóvil, y en los 90 mil millones de euros de volumen de negocios, el 65% se realiza con otros sectores.

El sector se ha concentrado mucho en los últimos décadas, y dos constructores están ahora presentes en el mercado, el grupo PSA, que tiene las marcas Peugeot y Citroën, y Renault. En 2008, estos dos grupos produjeron 5 800 millones de vehículos, incluyendo 5 mil millones de automóviles, con cerca de 40% de la producción hecha en Francia.

Exportan más de 4 mil millones de vehículos en 2007, lo que genera excedentes comerciales significativos. Sin embargo, después de una década de crecimiento sostenible, la industria automóvil se ha recientemente enfrentado a una concurrencia mundial aguda, con perdidas de cuotas de mercado, a pesar de establecerse cada vez más en el extranjero para bajar los costes.

A partir de 1945, estaba una necesidad urgente modernizar el sistema de producción para enfrentar el crecimiento demográfico. Pero después de tres décadas de excepcional expansión, en 1975 las dificultades económicas llevaron a las empresas a reducir sus inversiones en el edificio, con una baja de la compra de viviendas por los hogares. Desde 1975, la actividad de la construcción se ha ralentizado y ha experimentado muchas pérdidas de puestos de trabajo, Sin embargo, ha conocido una ligera recuperación desde 1997. Ahora, representa un volumen de negocios de más de 270 millones de euros. La industria de la construcción emplea directamente a 1,7 millones de personas y representa casi el mismo número de puestos de trabajo indirectos.

Las obras públicas son el dominio privilegiado de las grandes empresas que han atravesado un gran movimiento de concentración a partir de 1975. Los más importantes son Bouygues, Vinci y Eiffage. Estas empresas se basan en técnicas cada vez más sofisticadas. Ellos operan dentro del marcado nacional para la construcción de carreteras y de grandes edificios tales como el viaducto de Millau que fue el puente más alto del mundo. También son muy activas fuera de Francia, donde se enfrentan, sin embargo, la competencia de grupos extranjeros, incluidos los de los países recientemente industrializados.

La construcción de viviendas, por el contrario, presenta una estructura muy fragmentada, con 30 000 pequeñas y medianas empresas (PYME). La actividad de este sector está estrechamente vinculada a las medidas adoptadas para la construcción de vivienda, por diversas formas de ayuda y préstamos, que representan un total de unos 18 millones de euros al año. Desde 2000, el número de viviendas construidas cada año supera las 300 000 unidades, y supero las 400 000 unidades entre 2005 y 2007. La casa representa a la mayor parte del sector, con casi el 60% de los nuevas construcciones en 2008.

El sector terciario emplea al 76% de la población activa, más de 16 millones de franceses. Este es el sector que más contribuye al crecimiento de la francesa y que más procura empleos. Representa ahora el 75% del PIB y se desarrolla cada vez más. Así, mientras que en 1998 solo el 19% de los hogares tenían un ordenador y el 4% una conexión internet, en 2008, estaban el 62% y el 56%.

El sector del comercio emplea a más de 3 millones de personas en Francia, casi un empleado de cada cinco. El comercio es la actividad principal de 660 000 empresas: 61% en el comercio minorista (1,6 millones de empleados), el 26% en el comercio mayorista (995 000) y el 13% del comercio en las reparaciones de automóviles (420 000). En cuanto al volumen de negocios, el del comercio mayorista es de 620 mil millones, en el comercio minorista 440 mil millones, y en el comercio de automóviles 140 mil millones. La mayor parte de las empresas son pequeños comercios y tiendas del artesanado comercial, del comercio al por mayor y del comercio automóvil. Pero el sector del comercio minorista es dominado por las empresas de la gran distribución.

La gran distribución francesa emplea a más de 2,5 millones de personas. Con 1 600 hipermercados y 10 000 supermercados, Francia es uno de los países que disponen de los redes más grandes del mundo. Los distribuidores venden más del 60% de la distribución de alimentos y del 30% de los productos no alimentarios. Grupos especializados tales como Carrefour, Auchan, Intermarché, Champion, E.Leclerc y Casino dominan el sector, y se han instalado en el extranjero.

Algunos se han especializado, tales como FNAC, Decathlon, Darty, Conforama o Leroy Merlin. Los hipermercados están ubicados en las afueras de las grandes ciudades, donde hay grandes espacioso, en centros comerciales donde están concentradas muchas grandes surperficias. Las pequeñas empresas conocen una rápida disminución de su actividad empresarial, aún si el gobierno les protege. Sin embargo, Francia sigue siendo uno de los países europeos donde hay más pequeñas empresas en el sector minorista, con cuatro personas en promedio por empresa. La venta por correspondencia se ha también desarrollado, dominada por La Redoute, Trois Suisses y CAMIF.

El sistema bancario es un pilar de la economía francesa. Las actividades bancarias emplean a más de 400 000 personas y contribuyen en casi el 3% del PIB. Los principales grupos bancarios están entre las mayores empleadores del país y entre las mayores capitalizaciones bursátiles. Hay ahora más de 40 000 oficinas bancarios, 430 para un millón de personas. Algunos bancos ocupan un importante peso en el sector bancario francés: BNP Paribas, Société Générale, Crédit Agricole, Crédit Mutuel, Caisse d'épargne, Banque Populaire, Dexia, Natixis, CIC, Crédit Lyonnais. Estas se encuentran entre las empresas que emplean el mayor número de personas. La empresa pública La Poste, que asegura la distribución del correo, ha diversificado mucho sus actividades hacia el sector bancario y las actividades financieras, con su filial La Banque Postale, y tienen 17 000 oficinas bancarias en Francia y 10 millones de clientes.

Los bancos se han adaptado rápidamente a las privatizaciones de los años 1980 y han resistido a las crisis bancarias desde 1990. El sector bancario ha experimentado grandes cambios desde principios de los años sesenta: la oposición tradicional entre los bancos convencionales y los bancos de inversión se desvaneció. El sistema bancario se ha desarrollado mucho. Los bancos han internacionalizado sus actividades a raíz de la mundialización del comercio y de la libre circulación de los capitales dentro de la Comunidad Europea. El reciente período se ha caracterizado por una aceleración de las fusiones entre bancos franceses pero también con grupos extranjeros. Los bancos franceses son muy presentes en el extranjero, y en particular en Europa. El número de empresas de créditos está reduciendo rápidamente desde hace dos decenios, y apenas supera 700 ahora.

El sector de los aseguradores franceses ocupa la cuarta posición en todo el mundo con un volumen de negocios superior a 195 mil millones de euros en 2007, de los cuales 93 mil millones fueron realizados en el extranjero. El sector tiene un peso significativo, emplea a 145 000 personas.Tiene cerca de 480 empresas, pero el sector está dominado por algunas grandes aseguradores.

Los mayores aseguradores franceses son grupos internacionales que han diversificado sus actividades en los últimos años para mejorar su rentabilidad, y muchas empresas fusionaron a nivel nacional tan como europeo. AXA, el mayor asegurador francés, (volumen de negocios de 91 mil millones de euros en 2008) es presente en más de 30 países, tiene 80 millones de clientes y 214 000 empleados. CNP Assurances (29 mil millones de euros), la primera aseguradora de personas en Francia, es presente en Europa y en Sudamérica. El Crédit Agricole, que es un banco, tiene una filial para los seguros, segundo asegurador en el territorio nacional.

AGF (11 mil millones de euros), que estaba en el origen una empresa francesa, fue comprada por el alemán Allianz, el líder europea para los seguros, en 2007. Otros mayor aseguradores incluyen Groupama, BNP Paribas Assurances y Sogecap (filial de la Société Générale). Los mayores mutuos son MMA, MACIF, GMF y MAIF, pero son sobre todo presentes en Francia.

Francia es el primer destino del mundo para los turistas. Ha acogido a 81 millones de turistas en 2007, o aproximadamente el 10% del total mundial. El turismo representa el 6% del PBI y emplea directamente a 800 000 activos. Contribuye positivamente a la balanza por cuenta corriente. En 2007 el turismo internacional generó 33 millones de euros de ingresos en Francia, así Francia es el tercer país para los ingresos turísticos detrás de Estados Unidos y España. Pero es el país que acoge al más turistas del mundo, delante de España y de los Estados Unidos.

Hay alrededor de 180 000 empresas, incluidos los 89 000 restaurantes, cafés 51 000, 37 000 hoteles y otros alojamientos colectivos y 3 600 agencias de viajes. Con 8,5 millones de euros en 2000, el sector del turismo se caracteriza por una importante inversión. Estos están relacionados principalmente con el alojamiento y la restauración y las instalaciones turísticas.

Entre los sitios culturales más frecuentados es la Catedral de Notre-Dame de París (14 millones de visitantes en 2007), la Torre Eiffel (7 millones), el Centro Georges Pompidou (5 millones), el Musée du Louvre (8 millones), la Basílica del Sacré Cœur, Nuestra Señora de Lourdes, y el Palacio de Versalles (5 millones). En el sector de parques de ocio, Disneyland París, con 14 millones de entradas en 2007, es líder delante del Parc Astérix. Algunas empresas se han implementado en el extranjero, como las agencias de viajes Club Méditerranée y Pierre et Vacances, y los gigantes Sodexo para la alimentación y Accor para la hostelería.

Francia es el segundo exportador de Europa, por detrás de Alemania, y el quinto del mundo. Sus cuotas de mercado se sitúan en 4% del total mundial, pero está reduciéndose desde el comienzo de los años 2000, a causa de una falta de competitividad de las empresas francesas. Después de haber conseguido excedentes récord en los años 1990, la situación de la balanza de los pagos no dejó de deteriorarse. A partir de los años 1960 y 1970, el francés comercio se ha concentrado hacia los países europeos, pero ahora está diversificando sus socios hacia los países emergentes y países de Europa del este. Sin embargo, su especialización sectorial se ha enfocado en productos manufacturados desde hace un medio siglo, sin gran modificación. La degradación rápida del comercio exterior desde los años 2000, mientras que Alemania registra un superávit récord en las mismas condiciones económicas, plantea la cuestión de la especialización de la industria francesa y de su competitividad.

Se presentan a continuación las mercancías de mayor peso en las importaciones de Francia para el período 2010-hasta abril de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Francia para el periodo 2010-hasta abril de 2015.La mayoría de sus importadores están en Europa salvo Rusia, Estados Unidos y China. Las cifras expresadas son en dólares estadounidenses valor FOB.

Los intercambios se centran principalmente en países geográficamente próximos, en particular el Euromed que representa casi el 10% de las exportaciones francesas, y países de Europa Central y Oriental. Fuera de Europa, Francia es particularmente activa en África y en menor medida en el Oriente Medio.

El mercado europeo representa dos tercios del comercio exterior francés. Las exportaciones franceses a la UE-27 representan el 63% del total y las importaciones francesas provenientes de UE-27 el 59%. Esta alta concentración del comercio en el mercado europeo es más importante en Francia que para Alemania, Reino Unido y Italia y eso es una tendencia estructural.

El déficit comercial francés con respecto a la UE está creciendo de manera constante en los últimos diez años. Esta degradación se debe principalmente al comercio con Alemania y los países del Benelux y es el signo de una pérdida la competitividad de las empresas nacionales.

También el comercio francés es orientado al Sur y al Este. El Magreb y otras regiones vecinas son clientes importantes para Francia: Francia está el segundo mayor exportador de productos manufacturados a todos los países mediterráneos (detrás de Alemania) y el mayor exportador a los países del Magreb, en particular Argelia y Túnez.

Sin embargo, el peso total de esos países es menor, y después de la Unión Europea, los Estados Unidos son el mayor socio comercial de Francia con el 6% del comercio nacional. Sin embargo, en los próximos años la cuota de esos países en las exportaciones francesas cayera, al exportar cada vez más hacia mercados de alto crecimiento, como China y Brasil. También, Francia se ha orientado mucho hacia los países de Europa del este y de la Asia del Sureste, y la parte de sus intercambios con esos países ha aumentado mucho desde los años 1990.

Francia ya está bien posicionada en el mercado de los "BRIC". China es uno de los motores de la comercio desde finales de los años 1990, y ahora es el segundo proveedor de Francia. India, Rusia y Brasil han acelerado sus importaciones en los últimos años. Francia exporta más que el Reino Unido y Italia a China y Brasil, pero sigue siendo mucho detrás de Alemania. En China, su cuota de mercado es muy debajo en comparación con la de Alemania. En Rusia, el retraso es mucho más fuerte que en los otros tres mercados, pero es el cuarto proveedor para Francia, a causa de las exportaciones de gas. Francia saca provecho del comercio con esos países, aún hay un déficit comercial significativo.

La especialización sectorial Francia es inadecuada. Sus exportaciones son productos manufacturados afectados por la competencia de los países desarrollados. En un entorno competitivo caracterizado por la creciente gama de las exportaciones de los BRIC y la liberalización multilateral de los servicios, las cuotas de mercado de Francia están disminuyendo rápidamente. Las exportaciones franceses están posicionadas en los productos de alta tecnología, pero de media gama. Por fin Francia no es suficientemente implicada en las inversiones materiales.

La mala situación del comercio se debe en gran parte a su especialización industrial inadecuada en comparación con los otros países de la OCDE. La industria francesa es orientada a la media y alta tecnología, en lugar de la alta tecnología. Francia tiene una especialización en alta tecnología, con exportaciones de la industria aeroespacial y productos farmacéuticos, pero Alemania tiene una posición más elevada que Francia en materia de gama.

La gama media representa una mayor proporción de las exportaciones francesas: Francia exporta en la gama alta para el sector baja tecnología, pero más bien en la media gama para la alta tecnología. Al contrario, Alemania refuerza su posición en la alta calidad, en todos los niveles de tecnología.

Además, los productos franceses no tienen una competitividad suficiente, incluyendo para la alta tecnología y la alta gama. Francia ha perdido cuotas de mercado para las exportaciones de productos con alto valor añadido. Primero hay una especialización sectorial inadecuada, ya que Francia produce bienes de capital que son sensibles a los precios y los tipos de cambio (competitividad-precio o coste), cuando Alemania produce bienes industriales cuyas ventas no pueden ser afectadas por las variaciones del precio (competitividad estructural). También la especialización geográfica es inadecuada, ya que Francia es insuficientemente orientada a los países con un alto crecimiento, como India, China y los países emergentes.

La industria francesa sufre tres grandes problemas: la desindustrialización, la debilidad de la innovación y la debilidad del apoyo público a la innovación industrial. La competencia creciente a nivel mundial y la aparición de nuevos mercados en los que las empresas francesas no son suficientemente presentes son las principales razones de las perdidas de cuotas de mercado. También la política industrial del gobierno parece inadecuada, al contrario de países como Japón y EE. UU.
Todos los trabajos recientes son pesimistas en cuanto la situación de la industria francesa. La investigación es insuficiente. Entre 1980 y 2004, la industria ha perdido 1,5 millones de empleos, un tercio de su fuerza de trabajo, y la parte de la producción industrial en el PIB bajo de 30 a 20%. Estos cifras se deben a la desindustrialización de la economía francesa: la industria alcanzó un máximo del 40% de los activos en 1975 y bajo hasta 20% en la actualidad.

La industria no se adaptó a la globalización. Además, Francia acumulo un retraso frente a los otros países desarrollados a partir de los principios de los años 90 en términos de I&D privada. Francia dedica el 2% de su PIB a la investigación y la innovación frente al 2,7% en los EE. UU. y el 3% en Japón. El número de patentes no aumenta en los sectores de alta tecnología (productos farmacéuticos, biotecnología, micro-electrónica).

La acción de los gobiernos en el apoyo a la innovación industrial es insufficiente. La asistencia del gobierno para defender los sectores tradicionales (aeronáutica, espacio, energía nuclear) representa casi el 80% del total de la ayuda pública, lo que explica la debilidad de la ayuda en la tecnología más moderna. El resto de la ayuda está muy fragmentado, no se centra sectores específicos, en particular en las nuevas tecnologías con alto potencial industrial. Las ayudas públicas no ayudan suficientemente las compañías, en particular las mayores pymes, y la mayoría de las pymes son de tamaño demasiado pequeño y no crecen, así tienen dificultad exportar.

Así pues, dada la dispersión de los recursos y la baje de la competitividad, el gobierno francés ha creado en 2004 los polos de competitividad. Esos polos deben permitir una reorientación de los recursos públicos para poner en marcha programas de innovación industrial (la nanotecnología y la biotecnología). Estos programas permiten la coordinación de los actores públicos y privados en torno a un proyectos comunes. El objetivo es fortalecer las especialidades de la industria francesa, crear condiciones favorables para la aparición de nuevas actividades con una fuerte visibilidad internacional, y por tanto, mejorar la atractividad de los territorios y la lucha contra la deslocalización.

A pesar de que sólo tiene recursos limitados, Francia es parcialmente independiente gracias a la industria nuclear. Produce la mitad de sus necesidades enérgicas. La producción de electricidad nuclear de Francia esta hoy la segunda más grande del mundo para este tipo de energía, detrás de los Estados Unidos. Sin embargo, las importaciones de Francia representan la gran mayoría de sus hidrocarburos: Francia sigue siendo muy dependiente, aún si esta dependencia ha sido reducida.

La producción de petróleo alcanza 2 millones de toneladas, cuando las importaciones superan 70 millones de toneladas de petróleo crudo (25 millones de toneladas de productos refinados). Francia dispone de una red de refinado muy operativa (13 refinerías). Su dependencia es casi total en cuanto al gas natural, distribuido por el grupo público Gaz de France, un grupo. El carbón representa sólo el 5% de la energía primaria nacional, contra 15% en 1973.
La producción de electricidad se ha multiplicada casi por 10 en 50 años. Cubre más del 40% del total de las necesidades energéticas del país. Électricité de France (EDF) se ha convertido en una de las primeras empresas de electricidad en todo el mundo, y exporta su producción en toda la Europa. La energía nuclear representa el 78% del total de la producción nacional de electricidad, las centrales térmicas convencionales más del 10% y la energía hidroeléctrica el 12% (en contra de 55% en 1960).

Francia tiene varias ventajas en cuanto a la energía renovable: grandes recursos hidroeléctricos, uno de los más grandes bosques en Europa, unos fuertes vientos, grandes superficies. También algunas empresas como EDF y Suez han invertido mucho en la energía fotovoltaica, la energía solar y la energía térmica. De hecho, Francia es el primer productor europeo de la energía renovable con más del 20% del total de la producción de la UE. Las energías renovables proporcionan el 12% del consumo de energía, y hay una política energética importante de parte del gobierno, que ha lanzado una serie de reformas y de objetivos para desarrollar este tipo de energía.

Algunos de los principales principios que guiaron la política energética de Francia durante más de treinta años fueron la lucha contra la dependencia energética y el desarrollo de la energía nuclear por culpa a la falta de recursos fósiles en el territorio. Dos acontecimientos más recientes han cambiado las directrices básicas: el deseo de preservar el medio ambiente y un mayor papel dejado por el estado al mercado. Los consumidores franceses benefician de los precios de la energía entre los más bajos en los países de la OCDE.
Un primer principio de la política energética ha sido diversificar las fuentes. Debido a la falta de recursos fósiles en Francia, el gas y el petróleo, que representan actualmente el 49% del consumo de energía, son casi totalmente importados. La dependencia del petróleo en el Oriente Medio es hoy más bajo (27% del petróleo importado) que ayer, porque la mayor cantidad de petróleo proviene de África (19%) del mar del Norte (30%) o Rusia (23%).

Sin embargo, esta diversificación tiene sus límites, ya que hay que recordar que dos tercios de las reservas de petróleo están en el Oriente Medio. En términos de gas natural, el deseo de diversificación ha llevado a Francia a buscar otros socios que Rusia (22% del gas importado): Egipto, Argelia, Países Bajos, países acerca del mar Caspio.

La energía nuclear está en el corazón de la política energética de Francia. El país es el segundo productor de energía nuclear en el mundo y el 78% del consumo francés de electricidad está generada por la energía nuclear. Históricamente, la energía nuclear era una respuesta a la crisis del petróleo de 1973 y al declive de la producción de carbón.

La búsqueda de la independencia energética estaba en el origen de esta política: en aquella época, Francia importaba 76% de sus necesidades de energía, principalmente en forma de hidrocarburos. Hoy en día, gracias a la energía nuclear, esta cifra se redujo por debajo del 50%. El ganó de las importaciones de combustibles fósiles se estima ahora en más de 20 millones de euros al año.

La industria nuclear emplea directamente a 100 000 personas en Francia, un peso económico muy importante. En la lucha contra el efecto invernadero, la ventaja de esta tecnología es innegable: Francia es la más baja emisión de CO2 per cápita de toda la Unión Europea.

El desarrollo de las energías renovables es otro punto más reciente de la política energética. La posición exacta de la energía nuclear en el futuro dependerá en gran medida de los resultados de la investigación en energías renovables. La eólica, la solar y la energía hidroeléctrica tienen esta ventaja en la generación de electricidad que no descarguen sus desechos como la energía nuclear, pero su uso en Francia sigue siendo marginal, ya que actualmente representan sólo el 5,6% del consumo total de energía en el país. Sin embargo, los requisitos medioambientales relacionados, en particular, al calentamiento global debería forzar su desarrollo en los próximos decenios.

Desde la década de 1990, la tendencia es la retirada del estado del sector de la energía. Con la privatización de grandes empresas petroleras, la apertura a la competencia (bajo la presión de Bruselas), los productores y los distribuidores de gas y electricidad, nuevos grupos franceses se han convertido en jugadores competitivos en la economía europea y mundial. Sin embargo, el estado aún tiene un papel importante en el sector de la energía debido a su carácter estratégico: ha decidido invertir con otros países en el desarrollo del reactor experimental ITER, basada en la fusión nuclear y puso en marcha la construcción de un reactor nuclear de tercera generación, EPR.

Francia tiene uno de los sistemas de transporte más densos y más eficientes en el mundo, con 146 km de carreteras y 6,2 km de líneas ferroviarias por cada 100 kilómetros cuadrados. Los redes nacionales e internacionales se centran en París, lo que provoca un aumento de la influencia de la capital en la organización del territorio, y por lo tanto un desbalance. En los últimos años las redes de transportes han sidos adaptadas a Europa, con muchos conexiones con los países vecinos.

En el ferrocarril, que ha disfrutado de dos décadas de espectacular desarrollo de las líneas de alta velocidad (TGV). En primer lugar con líneas internas que no dejan de modernizarse, en particular con la LGV Atlantique y la LGV Méditerranée, y, cada vez más, las conexiones con las redes en los países vecinos (Barcelona, Bruselas, Turín, Londres). Hay también una fuerte determinación del gobierno de practicar una política de transportes para mantener una red local en regiones abandonadas.
En cuanto al transporte aéreo, la fuerte competencia entre las compañas en Europa dio lugar al fortalecimiento de la posición dominante de Air France. Mientras que había algunos competidores, todos han desaparecido. A principios de los años 2000, Air France estaba la primera empresa europea y la tercera compañía aérea mundial para el transporte internacional de pasajeros y el cuarto para el transporte internacional de mercancías. Se fusionó en 2003 con KLM.

Air France-KLM se convirtió en el primer grupo europeo y el tercer grupo en todo el mundo en términos de tráfico, y el primer grupo en todo el mundo en términos de negocios. El tráfico de pasajeros es dominada por los aeropuertos de Orly y Roissy-Charles de Gaulle (el 38% de tráfico local y el 76% del tráfico internacional).

Francia tiene ventajas en ámbitos como la energía nuclear, la tecnología aeroespacial y el transporte. No obstante, los resultados de la innovación, medidos por distintos indicadores, ha disminuido en los últimos años. La reducción de los gastos en I+D, que se redujeron de 2,3% del PIB en 1995 a 2,1% en 2006, ha llevado a Francia detrás de Alemania (2,5%), pero sigue por delante el Reino Unido (1,8%). Hasta mediados de los años 2000, Francia ha sido distanciada por sus principales competidores en las tecnologías de desarrollo rápido, incluidas la biotecnología y la nanotecnología.

Al igual que en muchos estados miembros de la UE, el sector público representa una parte significativa del gasto en I+D, cuando la de las empresas privadas aumenta lentamente. Francia lleva un número de publicaciones científicas per cápita ligeramente por debajo de la media de la OCDE, y es superada por el Reino Unido y Austria, que, sin embargo, invierten menos en I+D. Francia fue responsable del 4,5% de patentes presentadas en todo el mundo en 2005, y el número de patentes per cápita es de alrededor de la media de la OCDE. Si el número de patentes presentadas por las universidades se ha incrementado, la comercialización de los resultados de la investigación sigue siendo insatisfactoria.

La tasa de creación de empresas ha mejorado a través de iniciativas públicas pero son pocos las nuevas empresas que están creciendo. Las empresas francesas se están quedando atrás en cuanto al número de innovaciones de productos, incluyendo en la industria manufacturera, donde la innovación es crucial para la competitividad de las exportaciones. De hecho, entre 1996 y 2005, la proporción de las exportaciones de Francia de media y alta tecnología cayó al 6,8% del total mundial. Las empresas francesas tienen resultados algo mejor en las innovaciones de procesos, sin embargo se sitúan acerca de la media.

En Francia, como en la mayoría de los países industrializados, se ha desarrollado en el último cuarto de siglo una verdadera política medioambiental. Francia fue uno de los primeros países en crear, el 27 de enero de 1971, un Ministerio de Protección de la Naturaleza y el Medio Ambiente, encargado por aquel entonces simplemente de coordinar los esfuerzos del resto de los ministerios. Antes de eso, algunas medidas habían reflejado ya el interésque despertaban tales cuestiones, como demuestra la ley de 1960 por la que se creaban los parques nacionales, y la ley de 1964, muy avanzada para su época, que planteaba mecanismos de intervención económica, basados en el principio de «quien contamina paga».
De 1970 a 1998 la política francesa en materia de medio ambiente se centró en la puesta en marcha de una reglamentación y unas instituciones especializadas dedicadas a la recuperación y la eliminación de residuos (1976), al control de la calidad de aire (1981), y al control energético (1982), institituciones que en 1990 quedaron subsumidas en la Agencia del Medio Ambiente y del Control Energético (ADEME). Todo ello desembocó en la adopción de un Plan Nacional para el Medio Ambiente (1990) que condujo a la primera reforma de peso de la administración encargada del medio ambiente que supuso sobre todo la creación en 1991 de 26 direcciones regionales del medio ambiente (DIREN).

El periodo 1989-2001 ha sido una etapa clave en la que la importancia del medio ambiente dentro de las políticas públicas se ha visto considerablemente reforzada por una renovación de la actuación pública (desarrollo de procedimientos de concertación y de contractualización), por la modernización y el impulso dado a la administración medioambiental y por la consolidación del dispositivo legislativo, sobre todo mediante la ley de orientación sobre ordenamiento y desarrollo sostenible del territorio (1999) y la adopción del código del medio ambiente (2000).
A partir de 2002 se ha intensificado la atención al desarrollo sostenible por medio de la elaboración de una estrategia nacional, especialmente visible en el proyecto de la carta constitucional sobre medio ambiente; por medio de las políticas emprendidas sobre el agua, la naturaleza, los paisajes, la contaminación, la prevención o los riesgos; por medio de la ampliación de las capacidades en materia de evaluación medioambiental o de análisis socioeconómico; y también por medio de la acción internacional. La política nacional de desarrollo sostenible está supervisada por un Comité Interministerial de Desarrollo Sostenible (CIDD), creado en 2003 y presidido por el primer ministro, que reemplaza a tres instancias anteriores: el Comité Interministerial del Medio Ambiente (CIEN), la Comisión Interministerial de Lucha contra el Efecto Invernadero (CIES) y el Comité Interministerial de Prevención de Grandes Riesgos Naturales (CIPRNM).


Panorama general


Asuntos particulares

Sitios de estadísticas

Sitios gubernamentales

Sitios de análisis
Son sitios públicos, gobernales o independientes que analizan la situación de la economía francesa para consejar al gobierno:


Otras fuentes
Son sitios del ministerio francés de la economía y del ministerio del presupuesto, que se enfocan en puntos particulares de la economía nacional:


Hay muchos sitios públicos en relación con le economía francesa, incluyendo fuentes gobernales.

Sitios gobernales

Organismos públicos


</doc>
<doc id="15412" url="https://es.wikipedia.org/wiki?curid=15412" title="Bituminaria bituminosa">
Bituminaria bituminosa

Bituminaria bituminosa, llamado popularmente trébol hediondo, es una especie de la familia de las fabáceas. 

Planta vivaz con tallo de 20-100 cm, más o menos pubescente. Sus Hojas, que exhalan un característico olor a betún, son imparipinnadas con 3 folíolos peciolados; folíolos de formas muy variables y provistos de pelos y glándulas. Inflorescencia largamente pedunculada, con cabeza densa. Corola azul-violeta, raramente púrpura rodeada por un Cáliz quinquefido hirsuto. El fruto es una legumbre monosperma ovoide de alrededor de 1/2cm, muy espinosa y velluda, provista de un pico arqueado, ancho y aplanado, unas dos veces más largo que el cuerpo del fruto.

Este representante del género "Bituminaria" es nativo en toda la Cuenca Mediterránea y Canarias. También lo es en África del Norte no desértica y, hacia el Este, hasta el Caúcaso. Presente en la India e islas del Océano Índico ("ex.gr."Mauricio).

En el archipiélago canario, se reconocen dos taxones infraespecificos:


Estas poblaciones quedan bien separadas morfológicamente de las restantes canarias y peninsulares, que corresponden con la variedad típica, "B. bituminosa" var. "bituminosa".

Habita en matorrales y formaciones preforestales, preestépicas y estépicas, desde el nivel del mar hasta 2.000 msnm. Muy corriente en bordes de caminos y carreteras.

Presenta varios usos actuales y potenciales: 

"Bituminaria bituminosa" fue descrita primero por Carlos Linneo como "Psoralea bituminosa" y publicada en "Species Plantarum", vol. 2, p. 763, 1753 y ulteriormente transferido al género "Bituminaria" por Charles Howard Stirton y publicado en "Bothalia", vol. 13(3–4), p. 318, 1981.





</doc>
<doc id="15413" url="https://es.wikipedia.org/wiki?curid=15413" title="Presión de vapor">
Presión de vapor

La presión de vapor es la presión de la fase gaseosa o vapor de un sólido o un líquido sobre la fase líquida, para una temperatura determinada, en la que la fase líquida y el vapor se encuentran en equilibrio dinámico; su valor es independiente de las cantidades de líquido y vapor presentes mientras existan ambas. Este fenómeno también lo presentan los sólidos; cuando un sólido pasa al estado gaseoso sin pasar por el estado líquido (proceso denominado "sublimación" o el proceso opuesto, llamado "sublimación inversa") también hablamos de presión de vapor. En la situación de equilibrio, las fases reciben la denominación de líquido saturado y vapor saturado. Esta propiedad posee una relación inversamente proporcional con las fuerzas moleculares, debido a que cuanto mayor sea el módulo de las mismas, mayor deberá ser la cantidad de energía entregada (ya sea en forma de calor u otra manifestación) para vencerlas y producir el cambio de estado.

Inicialmente sólo se produce la evaporación, ya que no hay vapor; sin embargo, a medida que la cantidad de vapor aumenta ,y por tanto la presión en el interior de la ampolla, se va incrementando también la velocidad de condensación, hasta que transcurrido un cierto tiempo ambas velocidades se igualan. Llegado este punto se habrá alcanzado la presión máxima posible en la ampolla (presión de vapor o de saturación), que no podrá superarse salvo que se incremente la temperatura.

El equilibrio dinámico se alcanzará más rápidamente cuanto mayor sea la superficie de contacto entre el líquido y el vapor, pues así se favorece la evaporación del líquido; del mismo modo que un charco de agua extenso pero de poca profundidad se seca más rápido que uno más pequeño pero de mayor profundidad que contenga igual cantidad de agua. Sin embargo, el equilibrio se alcanza en ambos casos para igual presión.

El factor más importante que determina el valor de la presión de saturación es la propia naturaleza del líquido, encontrándose que en general entre líquidos de naturaleza similar, la presión de vapor a una temperatura dada es tanto menor cuanto mayor es el peso molecular del líquido.

Por ejemplo, el aire al nivel del mar saturado con vapor de agua a 20º C, tiene una presión parcial de 23 mbar de agua y alrededor de 780 mbar de nitrógeno, 210 mbar de oxígeno y 9 mbar de argón.

La presión de vapor es medida en unidades estándar de presión. El Sistema Internacional de Unidades (SI) reconoce la presión como una unidad derivada de la fuerza ejercida a través de un área determinada; a esta unidad se le conoce por el nombre de pascal (Pa). Un pascal es equivalente a un newton por metro cuadrado (N·m ó kg·m·s).

La medición experimental de la presión de vapor es un procedimiento simple para presiones similares que estén entre 1 y 200 kPa. Resultados más exactos son obtenidos cerca del punto de ebullición de cada sustancia en particular y con índice de error más significativo en mediciones menores a 1 kPa. Con frecuencia, algunos procedimientos consisten en purificar las sustancias que son analizadas, aislando la sustancia deseada en un contenedor, evitando cualquier gas indeseado y midiendo la presión de equilibrio de la fase gaseosa de la sustancia en el sistema cerrado a distintas temperaturas. El uso de herramientas, como un isoteniscopio, genera una mayor exactitud en el proceso.

Un líquido está, a cualquier temperatura, en equilibrio con su propio vapor cuando las moléculas de éste están presentes en una cierta concentración. La presión que corresponde a esta concentración de moléculas gaseosas se llama "presión de vapor del líquido" a la temperatura dada. La presión de vapor de cada líquido aumenta con la temperatura. La temperatura para la cual la presión de vapor de un líquido iguala a la presión externa se denomina "punto de ebullición" del líquido. A esta temperatura aparecen en el líquido burbujas de vapor que escapan de la superficie.

Como una tendencia general, la presión de vapor de los líquidos a presión atmosférica se incrementa con el aumento en la temperatura de ebullición. Este fenómeno es ilustrado en el diagrama adjunto, que muestra, para varios líquidos, el comportamiento de su presión de vapor versus la temperatura. Por ejemplo, a cualquier temperatura, el cloruro de metileno tiene la más alta presión de vapor de todos los líquidos expuestos en el gráfico. También se observa la baja temperatura de ebullición del propano, cuya curva de presión de vapor (línea cian) se interseca con la línea horizontal correspondiente a 1 atmósfera en -41º C.

Aunque la relación entre la presión de vapor y la temperatura no es lineal, el gráfico usa un eje logarítmico vertical para obtener una línea poco curva y así poder representar en un solo gráfico el comportamiento de varios líquidos.

El índice de peligrosidad (Ip) de una sustancia está determinado por el cociente entre la presión de vapor de la sustancia y su CMP (concentración máxima permitida) en condiciones estándar (25º C y 1 atm), por lo que esta propiedad nos permite analizar la viabilidad del uso de una sustancia para actividades determinadas, debido a que indica la probabilidad de que la misma se volatilice.



</doc>
<doc id="15414" url="https://es.wikipedia.org/wiki?curid=15414" title="Allah-Taala">
Allah-Taala

Allah-Taala, dios, supremo, creador y glorificador, adorado principalmente en el país de Hiyaz, "Arabia Pétrea", antes del advenimiento de Muhammad.

Varias de las antiguas tribus árabes reconocían, antes que viniera
Muhammad, un creador del Cielo y de la tierra y le llamaban "Allah-Taalai", el muy alto, en sentido opuesto a la denominación de los otros dioses a los cuales llamaban "Al-ilahat", divinidades inferiores; que según ellos eran la verdadera compañía de Dios, pero sometidas en un todo a su poder.

La fórmula usada para acercarse al "Allah-Taalai", estaba concebida en estos términos. "Yo me consagro a tu servicio, oh Dios, tú no tienes compañero, excepto las divinidades que forman tu cohorte: pero de las cuales eres tú el dueño y soberano como de todo lo que depende de ellas". Cuando plantaban árboles frutales, o sembraban algún campo, tiraban una línea que dividía el suelo en dos panes, una para el Dios soberano y la otra para las divinidades inferiores. Si caían frutos de ésta parte a la consagrada al gran Dios, tenían la costumbre de indemnizarlas, lo que no hacían en caso contrario, porque decían que las divinidades inferiores tienen necesidad de lo que pertenece al Dios soberano: pero que este no tiene necesidad de nada.

Los griegos que no entendieron las palabras "Allah-Taalai" y "Al-ilahat", formaron del primero el nombre "Orotal" y del segundo el de "Alilat":, indicando con ellos dos divinidades adoradas por los árabes.


</doc>
<doc id="15415" url="https://es.wikipedia.org/wiki?curid=15415" title="Pancratium maritimum">
Pancratium maritimum

Pancratium maritimum, la azucena de mar -entre otros numerosos nombres vernaculares-, es una planta bulbosa de la familia de las Amarilidáceas. Se encuentra en los arenales y en las dunas fijas de las costas del Atlántico y en las costas del Mediterráneo, a pleno sol y tolera bien periodos prolongados de sequía.

El nardo marítimo es una planta herbácea; las hojas erguidas sobresalen del suelo, formando un denso ramillete; tienen entre 5 y 20 mm de ancho y son de color verde azulado. Tienen un bulbo alargado, blanquecino, con múltiples capas membranosas. Ingerido, resulta de gran toxicidad, debido a que contiene heterósidos cardiotónicos. Las raíces están situadas a una profundidad de hasta 80 cm bajo la superficie. 
Las flores son pediceladas, grandes y llamativas, de color blanco, con gran parecido a los narcisos y muy aromáticas, con un tamaño de hasta 15 cm de longitud. La flor presenta seis tépalos lanceolados abiertos en la periferia y con una nervio dorsal verdoso que nace en la base de la umbela. La corola con forma de trompeta, también blanca, tiene doce dientes de forma triangular. Los seis estambres son de color blanquecino, con unas anteras de color amarillo con forma arriñonada.
El ovario es trilocular y sobresale sobre el cáliz espatoide de dos brácteas caedizas. Su fruto es una cápsula grande y ovoidea, en cuyo interior se encuentran las semillas, negras, angulosas, brillantes, con forma subtriangular, de placentación axial y apiladas en cada uno de los tres lóculos. 

Florece desde finales de junio, en julio y agosto, hasta septiembre, cuando la mayoría de las plantas ya han pasado su floración. 

Vive en las dunas costeras. Requiere suelo bien drenado aunque sea pobre, seco, árido, y exposición a pleno sol. La planta tiene la particularidad de poderse enterrar más profundamente para evitar la desecación, o bien de alargar sus tallos en caso de haber quedado muy cubierta de arena. 
La planta es polinizada por una polilla halcón llamada "Agrius convolvuli". Estos insectos visitan la flor cuando la velocidad del viento es de dos metros por segundo. Cuando es mayor, las polillas no visitan la planta. Aunque la especie es polinizada de manera artificial durante el tiempo ventoso la polinización no es eficaz. Otro dato específico del lirio arena es que no es receptivo a su propio polen y la planta puede reconocerlo. Esta flor solo puede ser fértil con polinización cruzada.

Las hojas son devoradas por la oruga del Lepidóptero "Brithys crini", asociado exclusivamente a esta planta. 

Crece bien en terrenos arenosos, perfectamente drenados y en lugares cálidos y soleados. Para que los bulbos maduren totalmente es imprescindible, luego de la floración, un período cálido y seco. Los bulbos se plantan en otoño a una profundidad de 15 cm. Se multiplica mediante bulbillos, los cuales deben separarse del bulbo original en otoño.
Los bulbos de "Pancratium maritimum" contienen un inhibidor de la acetilcolinesterasa, llamado ungeremina que puede ser adecuado como tratamiento para la enfermedad de Alzheimer. Ungeremina también se ha aislado de "Nerine bowdenii", "Ungernia spiralis", "Zephyranthes flava", "Ungernia minor", "Crinum augustum", "Crinum asiaticum" y "Hippeastrum solandriflorum".

4'-Hydroxy-5,7-dimethoxy-8-methylflavan es un flavano que también se encuentra en la planta "P. maritimum".

"Pancratium maritimum" fue descrita por Carlos Linneo y publicado en "Species Plantarum", 1: 290, 1753.

Pancratium: nombre genérico que proviene del griego παν ("pan", "todo") y κρατυς ("cratys", "potente") en alusión a supuestas virtudes medicinales. 

maritimum: epíteto latino proviene del latín "mar", por su hábitat costero.

Castellano: amor mío (6), amores míos (3), amormio, azucena, azucena de la Virgen (3), azucena de la mar, azucena de mar (17), azucena marina (4), azucenas de la Virgen, corona de rey, corona de rey marítima, lirio de la Virgen (2), lliri de mar, lirio de mar, narciso coronado, narciso de mar (7), narciso marino (2), nardo (2), nardo coronado (6), nardo marino (6), pancracio. Entre paréntesis, la frecuencia del vocablo en España.




</doc>
<doc id="15416" url="https://es.wikipedia.org/wiki?curid=15416" title="Cuscuta campestris">
Cuscuta campestris

Cuscuta campestris es una especie de planta parásita de la familia de las cuscutáceas. Son naturales de la región del Caribe.

Esta planta parásita a otras herbáceas, generalmente sobre especies como "Amaranthus, Daucus, Foeniculum, Medicago, Salsola, Trifolium, Xanthium" y otras especies cultivadas. Todas las especies del género son muy parecidas.

Se ha confundido en algunas publicaciones recientes con "Cuscuta pentagona" , pero las diferencias entre las dos especies son claras. 
En español se la conoce por los siguientes nombres comunes: barba de chivo, cáncer, pelillo, tiña. coscuta


</doc>
<doc id="15417" url="https://es.wikipedia.org/wiki?curid=15417" title="Antoni Gaudí">
Antoni Gaudí

Antoni Gaudí y Cornet, también conocido en español como Antonio Gaudí (Reus o Riudoms, 25 de junio de 1852-Barcelona, 10 de junio de 1926), fue un arquitecto español, máximo representante del modernismo catalán.

Gaudí fue un arquitecto con un sentido innato de la geometría y el volumen, así como una gran capacidad imaginativa que le permitía proyectar mentalmente la mayoría de sus obras antes de pasarlas a planos. De hecho, pocas veces realizaba planos detallados de sus obras; prefería recrearlos sobre maquetas tridimensionales, moldeando todos los detalles según los iba ideando mentalmente. En otras ocasiones, iba improvisando sobre la marcha, dando instrucciones a sus colaboradores sobre lo que debían hacer.

Dotado de una fuerte intuición y capacidad creativa, Gaudí concebía sus edificios de una forma global, atendiendo tanto a las soluciones estructurales como a las funcionales y decorativas. Estudiaba hasta el más mínimo detalle de sus creaciones, integrando en la arquitectura toda una serie de trabajos artesanales que dominaba él mismo a la perfección: cerámica, vidriería, forja de hierro, carpintería, etc. Asimismo, introdujo nuevas técnicas en el tratamiento de los materiales, como su famoso "trencadís" hecho con piezas de cerámica de desecho.

Después de unos inicios influido por el arte neogótico, así como ciertas tendencias orientalizantes, Gaudí desembocó en el modernismo en su época de mayor efervescencia, entre finales del y principios del . Sin embargo, el arquitecto reusense fue más allá del modernismo ortodoxo, creando un estilo personal basado en la observación de la naturaleza, fruto del cual fue su utilización de formas geométricas regladas, como el paraboloide hiperbólico, el hiperboloide, el helicoide y el conoide.

La arquitectura de Gaudí está marcada por un fuerte sello personal, caracterizado por la búsqueda de nuevas soluciones estructurales, que logró después de toda una vida dedicada al análisis de la estructura óptima del edificio, integrado en su entorno y siendo una síntesis de todas las artes y oficios. Mediante el estudio y la práctica de nuevas y originales soluciones, la obra de Gaudí culminará en un estilo orgánico, inspirado en la naturaleza, pero sin perder la experiencia aportada por estilos anteriores, generando una obra arquitectónica que es una simbiosis perfecta de la tradición y la innovación. Asimismo, toda su obra está marcada por las que fueron sus cuatro grandes pasiones en la vida: la arquitectura, la naturaleza, la religión y el amor a Cataluña.

La obra de Gaudí ha alcanzado con el transcurso del tiempo una amplia difusión internacional, siendo innumerables los estudios dedicados a su forma de entender la arquitectura. Hoy día es admirado tanto por profesionales como por el público en general: la Sagrada Familia es actualmente uno de los monumentos más visitados de España. Entre 1984 y 2005 siete de sus obras han sido consideradas Patrimonio de la Humanidad por la Unesco.

Antoni Gaudí nació el 25 de junio de 1852, hijo del industrial calderero Francesc Gaudí i Serra (1813-1906) y Antònia Cornet i Bertran (1819-1876). Era el menor de cinco hermanos, de los que solo llegaron a edad adulta tres: Rosa (1844-1879), Francesc (1851-1876) y Antoni. Los orígenes familiares de Gaudí se remontan al sur de Francia, en Auvernia, desde donde uno de sus antepasados, Joan Gaudí, vendedor ambulante, pasó a Cataluña en el ; el apellido en su origen podría ser Gaudy o Gaudin.

Se desconoce el lugar exacto del nacimiento de Gaudí, ya que no se conserva ningún documento que lo especifique, existiendo una controversia entre Reus y Riudoms (dos municipios vecinos y colindantes de la comarca del Bajo Campo) sobre la localidad natalicia del arquitecto. Aun así, en la mayoría de documentos de Gaudí, tanto de su época de estudiante como en los de su época profesional, figura como nacido en Reus. Sin embargo, el propio Gaudí manifestó en diversas ocasiones que era de Riudoms, lugar de origen de su familia paterna. Lo que sí es seguro es que fue bautizado en la iglesia prioral de Sant Pere Apòstol de Reus el día después de su nacimiento. El nombre que consta en su partida de bautismo es Anton Placid Guillem.

Fuese como fuese, Gaudí sintió un gran aprecio por su tierra natal, lo que evidenciaba en su gran mediterraneísmo, hecho que influyó notablemente en su arquitectura: Gaudí decía que los pueblos mediterráneos tienen un sentido innato del arte y el diseño, que son creativos y originales, mientras que los pueblos nórdicos son más técnicos y repetitivos. En palabras del propio Gaudí:

La estancia en su tierra natal le sirvió asimismo para conocer y estudiar profundamente la naturaleza, sobre todo durante sus estancias veraniegas en el Mas de la Calderera, la casa de los Gaudí en Riudoms. Le gustaba el contacto con la naturaleza, por lo que posteriormente se hizo miembro del Centro Excursionista de Cataluña (1879), entidad con la que realizó numerosos viajes por toda Cataluña y el sur de Francia. También practicó durante un tiempo la equitación, y hasta su vejez caminaba unos diez kilómetros diarios.

El ambiente familiar quizás fue uno de los catalizadores de la creatividad de Gaudí. Más de cinco generaciones en su familia trabajaron en la manufactura de productos de cobre, incluyendo a su padre y a sus dos abuelos. Fabricaban principalmente toneles gigantes para la destilación del alcohol de la uva, en Tarragona. El mismo Gaudí admite que los aspectos espaciales de estas grandes figuras de láminas de cobre forjado tuvieron una influencia en él, haciendo que desde pequeño tuviera una noción de los objetos como tridimensionales y no representados sobre un plano geométricamente. Esta percepción de las figuras como objetos maleables y casi esculturales, lo llevaron a desarrollar su estilo tan característico en el futuro.

El pequeño Gaudí era de naturaleza enfermiza, y padeció reumatismo desde niño, lo que le transmitió un carácter un tanto retraído y reservado. Quizá por eso, de mayor se convirtió en vegetariano y en partidario de las teorías higienistas del doctor Kneipp. Debido a estas creencias –y por motivos religiosos–, en ocasiones se entregaba a severos ayunos, tanto que en ocasiones ponía en peligro su propia vida, como en 1894, año en que cayó gravemente enfermo a causa de un prolongado ayuno.
Realizó sus primeros estudios en el parvulario del maestro Francesc Berenguer, padre del que sería uno de sus principales colaboradores, y luego pasó a los escolapios de Reus; destacó en dibujo, colaborando con el semanario "El Arlequín". También trabajó durante un tiempo como aprendiz en la fábrica textil Vapor Nou de Reus. En 1868 se trasladó a Barcelona para cursar enseñanza media en el Convento del Carmen de la ciudad condal. En su adolescencia estuvo cercano al socialismo utópico, realizando junto con dos compañeros de estudios, Eduard Toda i Güell y Josep Ribera i Sans, un proyecto de restauración para el Monasterio de Poblet que lo convertiría en un falansterio utópico-social.

Entre 1875 y 1878 realizó el servicio militar en el Arma de Infantería en Barcelona, siendo destinado a Administración Militar. Pasó la mayor parte del tiempo rebajado de servicio a causa de su salud, por lo que pudo continuar con los estudios. Gracias a ello no tuvo que entrar en combate, pues coincidió en esas fechas con la Tercera Guerra Carlista. En 1876 tuvo lugar el triste suceso de la muerte de su madre, a los 57 años, así como la de su hermano Francesc a los 25, médico recién titulado que no llegó a ejercer.

Cursó arquitectura en la Escuela de la Llotja y en la Escuela Técnica Superior de Arquitectura de Barcelona, donde se graduó en 1878.
Junto a las asignaturas de arquitectura asistió a clases de francés y cursó algunas asignaturas de Historia, Economía, Filosofía y Estética. Su expediente académico fue regular, con algún que otro suspenso; Gaudí se preocupaba más de sus propios intereses que de las asignaturas oficiales. Elies Rogent, director de la Escuela de Arquitectura de Barcelona, dijo en el momento de otorgarle el título:

Para pagarse la carrera, Gaudí trabajó como delineante para diversos arquitectos y constructores, como Leandre Serrallach, Joan Martorell, Emilio Sala Cortés, Francisco de Paula del Villar y Lozano y Josep Fontserè. Quizá por eso, al recibir el título, Gaudí, con su irónico sentido del humor, comentó a su amigo el escultor Llorenç Matamala:

Sus primeros proyectos fueron los de las farolas para la Plaza Real, el proyecto irrealizado de Kioscos Girossi y la Cooperativa Obrera Mataronense. Con su primer encargo importante, la Casa Vicens, Gaudí empieza a adquirir renombre, y recibe encargos cada vez de mayor envergadura. En la Exposición Universal de París de 1878 Gaudí expuso una vitrina realizada para la Guantería Comella. El diseño modernista, a la vez funcional y estético de dicha obra, impresionó al industrial catalán Eusebi Güell que, a su regreso, contactó con el arquitecto para encomendarle varios proyectos que tenía en mente. Comenzó así una larga amistad y un fructífero mecenazgo que dio origen a algunas de las más destacadas obras de Gaudí: las Bodegas Güell, los Pabellones Güell, el Palacio Güell, el Parque Güell y la Capilla de la Colonia Güell. Asimismo, se relacionó con el marqués de Comillas, suegro del conde Güell, para el que realizó El Capricho de Comillas.

En 1883 aceptó hacerse cargo de continuar las recién iniciadas obras del Templo Expiatorio de la Sagrada Familia. Gaudí modificó totalmente el proyecto inicial, convirtiéndola en su obra cumbre, conocida y admirada en todo el mundo. A partir de 1915 se dedicó casi por completo a este proyecto, hasta que murió. Gaudí comenzaba a recibir cada vez más encargos, por lo que, al trabajar en varias obras a la vez, tuvo que rodearse de un amplio equipo de profesionales de todos los campos relacionados con la construcción; en su estudio se formarían numerosos arquitectos que con el tiempo alcanzarían un puesto de renombre en el sector, como Josep Maria Jujol, Joan Rubió, Cèsar Martinell, Francesc Folguera y Josep Francesc Ràfols. En 1885, para escapar de la epidemia de cólera que asolaba Barcelona ("véase": Pandemias de cólera en España), Gaudí pasó una estancia en Sant Feliu de Codines, residiendo en la casa de Francesc Ullar, al que en agradecimiento diseñó una mesa de comedor.
Uno de los acontecimientos de la época para la capital catalana, y que sirvió de punto de partida para el modernismo, fue la Exposición Universal de 1888, donde los principales arquitectos del momento expondrían sus mejores obras. Gaudí participó con el edificio de la Compañía Trasatlántica, y recibió un encargo para reestructurar el Salón de Ciento del Ayuntamiento de Barcelona, que finalmente no se llevó a cabo. En los primeros años 1890 recibió dos encargos fuera de Cataluña: el del Palacio Episcopal de Astorga y el de la Casa Botines en León. Así, la fama y el prestigio del arquitecto reusense se iba extendiendo por toda España. En 1891 viajó a Málaga y Tánger para examinar el terreno de un proyecto para unas Misiones Católicas Franciscanas, que le había encargado el 2º marqués de Comillas; el proyecto no se efectuó, pero las torres proyectadas para las Misiones le sirvieron a Gaudí como modelo para las torres de la Sagrada Familia.
En 1899 se hizo socio del Círculo Artístico de San Lucas, sociedad artística de corte católico fundada en 1893 por el obispo José Torras y Bages y los hermanos Josep y Joan Llimona. También se afilió a la Lliga Espiritual de la Mare de Déu de Montserrat, entidad catalanista igualmente de signo católico. Se evidencia así el carácter conservador y religioso de su pensamiento político, vinculado a la defensa de la identidad cultural del pueblo catalán. Pese a la aparente contradicción entre los ideales utópicos de su juventud y su posterior adscripción a posiciones más conservadoras, la evolución puede resultar natural si tenemos en cuenta la profunda espiritualidad del arquitecto; en palabras de Cèsar Martinell, “sustituyó la filantropía laicista por la caridad cristiana”.

El principio de siglo encontró a Gaudí embarcado en numerosos proyectos, en los que se evidenciaba el cambio de su estilo, cada vez más personal e inspirado en la naturaleza. En 1900 recibió el premio al mejor edificio del año por la Casa Calvet, otorgado por el Ayuntamiento de Barcelona. Durante la primera década del siglo se ocupa de proyectos como la Casa Figueras, más conocida como Bellesguard, el Parque Güell, proyecto de urbanización que no tuvo éxito, y la restauración de la Catedral de Santa María de Palma de Mallorca, para la que realizó varios viajes a la isla. Entre 1904 y 1910 construye la Casa Batlló y la Casa Milà, dos de sus obras más emblemáticas.
La fama de Gaudí iba en aumento, provocando por ejemplo que en 1902 el pintor Joan Llimona escogiese la fisonomía de Gaudí para representar a san Felipe Neri en las pinturas del crucero de la iglesia de San Felipe Neri de Barcelona. Ese año funda con Joan Santaló, hijo de su amigo el doctor Pere Santaló, una sociedad dedicada al forjado de hierro, que fracasó.

Desde su traslado a Barcelona, Gaudí había cambiado a menudo de domicilio: en su época de estudiante vivió de pensión, generalmente en la zona del Barrio Gótico; al iniciar su carrera, pasó a diversos pisos de alquiler en la zona del Ensanche. Por fin, en 1906 se instaló en una casa de propiedad, en el Parque Güell, construida por su ayudante Francesc Berenguer como casa de muestra de la urbanización; actualmente es la Casa-Museo Gaudí. Aquí vivió con su padre (fallecido en 1906 a los 93 años) y su sobrina, Rosa Egea Gaudí (fallecida en 1912 a los 36 años). Vivió en esta casa hasta 1925, pocos meses antes de su muerte, residiendo este último tiempo en el taller de la Sagrada Familia.
Uno de los sucesos que marcaron profundamente a Gaudí fueron los acontecimientos de la Semana Trágica de 1909; Gaudí permaneció ese tiempo recluido en su casa del Parque Güell, pero debido al ambiente anticlerical y a los atentados contra iglesias y conventos temió por la integridad de la Sagrada Familia —que afortunadamente no sufrió daños—.

En 1910 se celebró en el Grand Palais de París una exposición dedicada a Gaudí, dentro del salón anual de la Société des Beaux-Arts de Francia. Gaudí participó a instancias del conde Güell, concurriendo con una serie de fotos, planos y maquetas en yeso de varias de sus obras. Aunque participó fuera de concurso, recibió muy buenas críticas por parte de la prensa francesa. Buena parte de esta exposición se pudo ver al año siguiente en el I Salón Nacional de Arquitectura celebrado en el Pabellón Municipal de Exposiciones del Buen Retiro de Madrid.

Mientras se celebraba la exposición de París, en mayo de 1910, Gaudí pasó una estancia de reposo en Vich, donde diseñó dos farolas de basalto y hierro forjado para la Plaza Mayor de Vich, con ocasión del centenario de Jaime Balmes. Al año siguiente también se vio obligado a pasar una temporada en Puigcerdà, a causa de unas fiebres de Malta; en ese periodo de descanso concibió la fachada de la Pasión de la Sagrada Familia. Debido a su gravedad, el 9 de junio redactó un testamento ante el notario Ramon Cantó i Figueres; por fortuna, pudo reponerse por completo.

Los años 1910 fueron duros para Gaudí, que sufrió varias desgracias: en 1912 murió su sobrina Rosa; en 1914 falleció su principal colaborador, Francesc Berenguer; en 1915 una grave crisis económica casi paraliza las obras de la Sagrada Familia; en 1916 murió su amigo José Torras y Bages, obispo de Vich; en 1917 se interrumpen las obras de la Colonia Güell; en 1918 falleció su amigo y mecenas, Eusebi Güell. Quizá por todo ello desde 1915 se dedica por entero a la Sagrada Familia, refugiándose en su trabajo. Gaudí confiesa a sus colaboradores:

Efectivamente, los últimos años de su vida los dedica por completo a la «Catedral de los pobres» —como es popularmente conocida—, para la que incluso llegará a pedir limosna a fin de poder continuar con las obras. Aparte de esa dedicación, realiza pocas más actividades, casi siempre relacionadas con la religión: en 1916 participó en un cursillo de canto gregoriano impartido en el Palacio de la Música Catalana por el monje benedictino Gregori M. Sunyol.

Gaudí vivió dedicado por completo a su profesión, permaneciendo soltero toda su vida. Al parecer, tan solo en una ocasión se sintió atraído por una mujer, Josefa Moreu, maestra de la Cooperativa Mataronense, hacia 1884, pero no fue correspondido. Desde entonces Gaudí se refugió en su profunda religiosidad, en la que encontraba gran sosiego espiritual. A menudo se ha pintado la imagen de un Gaudí huraño y antipático, de bruscas contestaciones y gestos altaneros; pero la gente que lo trató más de cerca lo describió como persona afable y cortés, buen conversador y fiel con sus amigos, entre los que destacaron especialmente su mecenas, Eusebi Güell, y el obispo de Vic, José Torras y Bages, así como los escritores Joan Maragall y Jacinto Verdaguer, el doctor Pere Santaló y algunos de sus más fieles colaboradores, como Francesc Berenguer y Llorenç Matamala.
La apariencia personal de Gaudí —de rasgos nórdicos, pelo rubio y ojos azules— sufrió una radical transformación con el paso del tiempo: de ser un joven con aspecto de dandi (trajes caros, pelo y barba bien arreglados, gustos de "gourmet", frecuente asistencia al teatro y a la ópera, incluso visitaba las obras montado en su carruaje), pasó en su vejez a la más estricta sencillez, comiendo con frugalidad, vistiendo trajes viejos y gastados, con un aspecto descuidado, tanto que a veces lo tomaban por mendigo, como por desgracia pasó en el momento del accidente que le provocó la muerte.

Gaudí no dejó prácticamente escritos, aparte de informes técnicos de sus obras requeridos por instancias oficiales, algunas cartas a amigos (principalmente a Joan Maragall) y algún artículo periodístico. Se conservan algunas frases suyas recogidas por algunos de sus ayudantes y discípulos, principalmente Josep Francesc Ràfols, Joan Bergós, Cèsar Martinell e Isidre Puig i Boada. El único escrito dejado por Gaudí es el conocido como "Manuscrito de Reus" (1873-1878), una especie de diario de estudiante donde recogía diversas impresiones sobre arquitectura y decoración, exponiendo sus ideas al respecto; destacan los análisis que hizo sobre el templo cristiano y la casa solariega, así como un texto sobre ornamentación y una memoria para una mesa-escritorio.
Gaudí se reconoció siempre partidario del catalanismo, aunque nunca quiso vincularse con la política –algunos políticos como Francesc Cambó o Enric Prat de la Riba le propusieron presentarse a diputado, pero él declinó el ofrecimiento–. Aun así, tuvo diversos altercados con la policía: en 1920 fue golpeado por la misma en un tumulto formado en la celebración de los Juegos Florales; el 11 de septiembre de 1924, Día Nacional de Cataluña, durante una manifestación en contra de la prohibición del uso del catalán por parte de la dictadura de Primo de Rivera, fue arrestado por la Guardia Civil, pasando una breve estancia en el calabozo, del que salió con una fianza de 50 pesetas.

El 7 de junio de 1926 Gaudí se dirigía a la iglesia de San Felipe Neri, que visitaba a diario para rezar y entrevistarse con su confesor, mosén Agustí Mas i Folch; pero al pasar por la Gran Vía de las Cortes Catalanas, entre las calles Gerona y Bailén, fue atropellado por un tranvía, que lo dejó sin sentido. Siendo tomado por un mendigo, al ir indocumentado y a causa de su aspecto descuidado, con ropas gastadas y viejas, no fue socorrido de inmediato, hasta que un guardia civil paró un taxi que lo condujo al Hospital de la Santa Cruz. Al día siguiente lo reconoció el capellán de la Sagrada Familia, mosén Gil Parés, pero ya era tarde para hacer nada por él. Murió el día 10 de junio de 1926, a los 73 años de edad, en la plenitud de su carrera. Fue enterrado el 12 de junio, con presencia de grandes multitudes que quisieron darle el último adiós, en la capilla de Nuestra Señora del Carmen de la cripta de la Sagrada Familia. En su lápida figura la siguiente inscripción:

Tras su muerte Gaudí cayó en un relativo olvido, y su obra fue denostada por la crítica internacional por barroca y excesivamente fantasiosa. En su tierra natal fue igualmente menospreciado por la nueva corriente que sustituyó al modernismo, el novecentismo, estilo que retornaba a los cánones clásicos. En 1936, durante el transcurso de la Guerra Civil Española, fue asaltado el taller de Gaudí en la Sagrada Familia, destruyéndose gran cantidad de documentos, planos y maquetas del arquitecto modernista.
Su figura comenzó a ser reivindicada en los años 1950, por Salvador Dalí en primer lugar, seguido del arquitecto Josep Lluís Sert. En 1956 se organizó una retrospectiva sobre Gaudí en el Salón del Tinell de Barcelona, y en 1957 su primera gran exposición internacional, en el MoMA de Nueva York. Asimismo, entre los años 1950 y 1960, los estudios de críticos internacionales como Bruno Zevi, George Collins, Nikolaus Pevsner y Roberto Pane dieron gran difusión a la obra de Gaudí, mientras que en su tierra natal era reivindicado por Alexandre Cirici, Juan Eduardo Cirlot y Oriol Bohigas. También es de remarcar el gran éxito obtenido por Gaudí en Japón, donde su obra es muy admirada, destacando los estudios realizados por Kenji Imai y Tokutoshi Torii. Desde entonces la valoración de Gaudí ha ido en aumento, proceso que se reflejó en la catalogación en 1969 de 17 obras de Gaudí como Monumentos Histórico-Artísticos de Interés Cultural por parte del Ministerio de Cultura español (RD 1794/1969), siendo el primer artista «contemporáneo» en alcanzar esta distinción, pues hasta entonces las normas dictaban que solo podían tener esta catalogación las obras con un siglo o más de antigüedad. Igualmente, en 1984 varias obras del arquitecto fueron declaradas como Patrimonio de la Humanidad de la Unesco.

En 1952, centenario del nacimiento del arquitecto, se fundó la Asociación de Amigos de Gaudí, para divulgar y conservar el legado dejado por el artífice catalán. En 1956 se creó la Cátedra Gaudí, perteneciente a la Universidad Politécnica de Cataluña, con el objeto igualmente de profundizar en el estudio de la obra gaudiniana y participar en su conservación; en 1987 el rey Juan Carlos I le concedió el título de Real Cátedra Gaudí. En 1976, con motivo del 50 aniversario de su muerte, el Ministerio de Asuntos Exteriores organizó una exposición sobre Gaudí que recorrió todo el mundo.

Con motivo del 150 aniversario del nacimiento de Gaudí se celebró el año 2002 el Año Internacional Gaudí, con multitud de actos oficiales, conciertos, espectáculos, conferencias, publicaciones, etc. Entre otros eventos, el 24 de septiembre de ese año se estrenó en el Palacio de los Deportes de Barcelona el musical "Gaudí", sobre la vida y obra del arquitecto reusense, obra de Jordi Galceran, Esteve Miralles y Albert Guinovart. El año 2008 se instituyeron en su honor los Premios Gaudí, otorgados por la Academia del Cine Catalán, que reconocen las mejores producciones cinematográficas catalanas del año.

Hombre de profunda religiosidad y de vida ascética, se ha propuesto la beatificación de Antoni Gaudí, proceso iniciado en 1998 por el arzobispo de Barcelona, Ricard Maria Carles. El año 2000 fue autorizado el inicio del proceso por parte de la Santa Sede con el decreto nihil obstat, por el cual Gaudí pasa a ser considerado siervo de Dios, el primer peldaño para la beatificación.

En 2013, con motivo del 130º aniversario de la primera obra de Gaudí, la Cooperativa Obrera Mataronense, se creó con el apoyo de la Generalidad de Cataluña el Consejo para el Fomento y la Difusión de la obra de Gaudí, un órgano presidido por el consejero de Cultura de la Generalidad encargado de preservar el legado arquitectónico del genio modernista, así como difundir y dar a conocer su obra entre la población. Entre otras iniciativas, para 2017 está previsto el lanzamiento de un «pasaporte Gaudí», similar al existente para el camino de Santiago, que sería sellado al visitar cada uno de los edificios construidos por el arquitecto, fomentando así el conocimiento de sus obras.

La trayectoria profesional del arquitecto tuvo una evolución "sui generis", debido a su constante investigación en el campo de la estructura mecánica de las obras. En sus inicios, Gaudí recibió cierta influencia del arte oriental (India, Persia, Japón), a través del estudio de los teóricos de la arquitectura historicista, Walter Pater, John Ruskin y William Morris. Vemos esta corriente orientalizante en obras como el Capricho de Comillas, el Palacio Güell, los Pabellones Güell o la Casa Vicens. Más tarde, sigue la corriente neogótica de moda en el momento, siguiendo los dictámenes del arquitecto francés Viollet-le-Duc. Se puede percibir en el Colegio de las Teresianas, el Palacio Episcopal de Astorga, la Casa Botines y la Casa Bellesguard, así como en la cripta y el ábside de la Sagrada Familia. Finalmente, desemboca en su etapa más personal, con un estilo naturalista, individual, orgánico, inspirado en la naturaleza, en el que realizará sus obras maestras.

Durante su época de estudiante Gaudí pudo contemplar una colección de fotografías que la Escuela de Arquitectura poseía sobre Egipto, la India, el arte persa, maya, chino y japonés, así como los monumentos islámicos españoles, los cuales le dejaron una profunda huella, sirviéndole de inspiración para muchas de sus obras. También estudió con detenimiento el libro "Plans, elevations, sections and details of the Alhambra", de Owen Jones, perteneciente a la biblioteca de la Escuela. De los artes nazarí y mudéjar tomó múltiples soluciones estructurales y ornamentales que aplicó con ciertas variantes y libertad estilística a sus obras. Un aspecto a destacar que Gaudí toma del arte islámico es la indefinición espacial, la concepción del espacio sin límites estructurados; espacio que adquiere un sentido secuencial, fragmentado, a través de pequeños tabiques o huecos diáfanos, que crean separación sin suponer barreras compactas que delimiten un espacio uniformemente cerrado.

Pero sin duda el estilo que más le influyó fue el arte gótico, que a finales del vivía un gran renacimiento debido sobre todo a la obra teórica y restauradora de Viollet-le-Duc. El arquitecto francés propugnaba estudiar los estilos del pasado y adaptarlos al presente de una forma racional, atendiendo tanto a la razón estructural como a la ornamental. Sin embargo, para Gaudí el gótico era «imperfecto», porque pese a la eficacia de algunas de sus soluciones estructurales era un arte que había que «perfeccionar». En sus propias palabras:

Después de estas influencias iniciales, Gaudí desemboca en el modernismo en su época de mayor esplendor, en los años situados entre los siglos y . En sus inicios, el modernismo encuentra la inspiración en la arquitectura historicista, ya que para los artistas modernistas la vuelta al pasado supone una reacción contra las formas industriales impuestas por los nuevos adelantos tecnológicos producidos con la Revolución industrial. La utilización de los estilos del pasado supone una regeneración moral que permite a la nueva clase dirigente, la burguesía, identificarse con unos valores que reconocen como sus raíces culturales. Asimismo, el resurgir de la cultura catalana desde mediados del (la Renaixença), lleva a adoptar las formas góticas como estilo «nacional» de Cataluña, con la pretensión de conjugar nacionalismo y cosmopolitismo, de integrarse en la corriente modernizadora europea.

Algunos rasgos esenciales del modernismo serán: un lenguaje anticlásico heredero del romanticismo, con tendencia a un cierto lirismo y subjetivismo; vinculación decidida de la arquitectura con las artes aplicadas y los oficios artísticos, creando un estilo remarcadamente ornamental; utilización de nuevos materiales, creando un lenguaje constructivo mixto y rico en contrastes, buscando el efecto plástico del conjunto; fuerte sentimiento de optimismo y fe en el progreso, que produce un arte exaltado y enfático, reflejo del clima de prosperidad del momento, sobre todo en la clase burguesa.

Gaudí suele ser considerado el gran maestro del modernismo catalán, pero su obra va más allá de cualquier estilo o intento de clasificación. Es una obra personal e imaginativa que encuentra su principal inspiración en la naturaleza. Gaudí estudió con profundidad las formas orgánicas y anárquicamente geométricas de la naturaleza, buscando un lenguaje para poder plasmar esas formas en la arquitectura. Algunas de sus mayores inspiraciones vendrán de la montaña de Montserrat, las cuevas de Mallorca, la Cueva del Salnitre (Collbató), los riscos de Fra Guerau en la sierra de Prades cerca de Reus, la montaña de Pareis al norte de Mallorca, el Coll de la Desenrocada (entre Argentera y Vilanova d'Escornalbou) o Sant Miquel del Fai en Bigas, todos ellos lugares visitados por Gaudí.

Este estudio de la naturaleza se traduce en el empleo de formas geométricas regladas como son el paraboloide hiperbólico, el hiperboloide, el helicoide y el conoide, que reflejan exactamente las formas que Gaudí encuentra en la naturaleza. Las superficies regladas son formas generadas por una recta, denominada generatriz, al desplazarse sobre una línea o varias, denominadas directrices. Gaudí las halló en abundancia en la naturaleza, como por ejemplo en juncos, cañas o huesos; decía que no existe mejor estructura que un tronco de árbol o un esqueleto humano. Estas formas son a la vez funcionales y estéticas, y Gaudí las emplea con gran sabiduría, sabiendo adaptar el lenguaje de la naturaleza a las formas estructurales de la arquitectura. Gaudí asimilaba la forma helicoidal al movimiento, y la hiperboloidal a la luz. Decía lo siguiente sobre las superficies regladas:

Otro de los elementos empleados profusamente por Gaudí es la curva catenaria. Gaudí había estudiado en profundidad la geometría cuando era joven, leyendo numerosos tratados sobre ingeniería que alababan las virtudes de la utilización de la curva catenaria como elemento mecánico, que sin embargo entonces solo se usaba en la construcción de puentes suspendidos; Gaudí fue el primero en utilizar este elemento en la arquitectura común. La utilización de arcos catenarios en obras como la Casa Milà, el Colegio de las Teresianas, la capilla de la Colonia Güell o la Sagrada Familia permite a Gaudí dotar a sus estructuras de un elemento de gran resistencia, ya que la catenaria distribuye regularmente el peso que soporta, sufriendo únicamente fuerzas tangenciales que se anulan entre ellas.

Con todos estos elementos, Gaudí pasó de la geometría plana a la espacial, la geometría reglada. Además, estas formas constructivas se avenían muy bien a un tipo de construcción sencilla y de materiales baratos, como el ladrillo: Gaudí utilizó con asiduidad el ladrillo unido con argamasa, en capas superpuestas, como en la tradicional bóveda catalana tabicada. Esta búsqueda de nuevas soluciones estructurales tuvo su culminación entre los años 1910 y 1920, cuando experimentó de forma práctica todas sus investigaciones en su obra cumbre: la Sagrada Familia. Gaudí concibió dicho templo como si fuese la estructura de un bosque, con un conjunto de columnas arborescentes divididas en diversas ramas para sustentar una estructura de bóvedas de hiperboloides entrelazados. Las columnas las inclinó para recibir mejor las presiones perpendiculares a su sección; además, les dio forma helicoidal de doble giro (dextrógiro y levógiro), como en las ramas y troncos de los árboles. Esta ramificación crea una estructura hoy denominada fractal que, junto con la modulación del espacio, que lo subdivide en pequeños módulos independientes y autosustentantes, crea una estructura que soporta perfectamente los esfuerzos mecánicos de tracción sin la necesidad de utilizar contrafuertes, como requería el estilo gótico. Gaudí logró así una solución racional y estructurada, perfectamente lógica y adaptada a la naturaleza, creando al mismo tiempo un nuevo estilo arquitectónico, original y sencillo, práctico y estético.
Esta nueva técnica constructiva permite a Gaudí realizar su mayor afán arquitectónico, perfeccionar y superar el estilo gótico: las bóvedas de hiperboloides tienen su centro donde las góticas tenían la clave, con la salvedad de que el hiperboloide permite crear un hueco en ese espacio, un vacío que deja el paso de la luz natural. Asimismo, en la intersección entre las bóvedas, donde las góticas tenían los nervios, el hiperboloide permite nuevamente la apertura de pequeños vanos, que Gaudí aprovecha para dar la sensación de un cielo estrellado.

Esta visión orgánica de la arquitectura se complementa en Gaudí con una singular visión espacial que le permitía concebir sus diseños arquitectónicos de forma tridimensional, contrariamente a la bidimensionalidad del diseño en plano de la arquitectura tradicional. Gaudí decía que había adquirido este sentido espacial de niño, viendo los diseños que hacía su padre para las calderas y alambiques que fabricaba. Debido a esta concepción espacial Gaudí siempre prefirió trabajar sobre moldes y maquetas, o incluso ir improvisando sobre el terreno a medida que la obra avanzaba; reacio a dibujar planos, en raras ocasiones elaboró croquis de sus obras, tan solo cuando se lo requerían instancias oficiales.
Una de sus muchas innovaciones en el terreno técnico fue la utilización de una maqueta para el cálculo de estructuras: para la iglesia de la Colonia Güell construyó en un cobertizo junto a las obras una maqueta a gran escala (1:10), de cuatro metros de altura, donde instaló un tablero de madera —fijado en el techo— donde había dibujado la planta de la iglesia; de los puntos que en este dibujo representaban los elementos sustentantes del edificio —columnas e intersección de paredes— colgó unos cordeles de los que pendían saquitos de tela rellenos de perdigones de plomo —cuyo peso era proporcional a las cargas—, que así suspendidos, y por efecto de la gravedad, daban la curva catenaria resultante, tanto en arcos como en bóvedas. De aquí sacaba una fotografía, que una vez invertida daba la estructura de columnas y arcos que Gaudí estaba buscando. Sobre estas fotografías Gaudí pintaba, con gouache o pastel, el contorno ya definido de la iglesia, remarcando hasta el último detalle del edificio, tanto arquitectónico como estilístico y decorativo.

La posición de Gaudí dentro de la Historia de la Arquitectura supone la de un gran genio creador que, inspirándose en la naturaleza, creó un estilo propio, de gran perfección técnica a la vez que un cuidado valor estético, marcado por el sello de su fuerte personalidad. Sus innovaciones estructurales, que suponen en cierta medida la superación de los estilos anteriores, desde el dórico hasta el barroco, pasando por el gótico, principal fuente de inspiración del arquitecto, podría considerarse que representan la culminación de los estilos clásicos, que Gaudí reinterpreta y perfecciona. Así Gaudí supera el historicismo y eclecticismo de su generación, pero sin llegar a conectar con otras corrientes de la arquitectura del , que con sus postulados racionalistas derivados de la Escuela de la Bauhaus supondrá una evolución antitética a la iniciada por Gaudí, hecho que marcará el menosprecio y la incomprensión inicial hacia la obra del arquitecto modernista.

Otro de los factores de la inicial caída en el olvido del artífice catalán es que, pese a contar en la ejecución de sus obras con numerosos ayudantes y discípulos, Gaudí no creó una escuela propia, ya que nunca se dedicó a la docencia ni dejó prácticamente escritos. Alguno de sus colaboradores siguieron sus huellas de cerca, sobre todo Francesc Berenguer y Josep Maria Jujol; otros, como Cèsar Martinell, Francesc Folguera y Josep Francesc Ràfols evolucionaron hacia el novecentismo, apartándose de la estela del maestro. Pese a ello, cierta influencia del creador de la Sagrada Familia la podemos percibir en algunos arquitectos modernistas –o que partieron del modernismo– que no tuvieron un contacto directo con Gaudí, como Josep Maria Pericas (Casa Alòs, Ripoll), Bernardí Martorell (Cementerio de Olius ) o Lluís Muncunill (Masía Freixa, Tarrasa).

Aun así, Gaudí ha dejado una profunda huella en la arquitectura del : arquitectos como Le Corbusier se declararon admiradores de la obra del arquitecto catalán, y otros como Pier Luigi Nervi, Friedensreich Hundertwasser, Oscar Niemeyer, Félix Candela, Eduardo Torroja o Santiago Calatrava son hasta hoy día deudores del estilo iniciado por Gaudí. Frei Otto empleó formas gaudinianas en el Estadio Olímpico de Múnich. En Japón, la obra de Kenji Imai es de una evidente influencia gaudiniana, como se puede apreciar en el Memorial a los 26 mártires de Japón en Nagasaki (Premio Nacional de Arquitectura de Japón en 1962), donde destaca el uso del famoso "trencadís" del arquitecto reusense. Por otro lado, la labor docente e investigadora llevada a cabo por los críticos de arte desde el año 1950 ha situado al artista en un merecido lugar de relevancia dentro de la arquitectura del .

En su etapa de estudiante, Gaudí frecuentó diversos talleres artesanales, como los de Eudald Puntí, Llorenç Matamala y Joan Oñós, donde aprendió los aspectos básicos de todos los oficios relacionados con la arquitectura, como la escultura, la carpintería, la forja, la vidriería, la cerámica, el moldeado en yeso, etc. Asimismo, supo asimilar los nuevos avances tecnológicos, incorporando a su técnica la construcción en hierro o en hormigón armado. Todo ello se debió a la visión global que Gaudí tenía de la arquitectura como obra de diseño multifuncional, en la que debía elaborarse hasta el más mínimo detalle en un conjunto compenetrado, proporcionado. Estos conocimientos le permitieron no solo dedicarse a sus proyectos arquitectónicos, sino diseñar igualmente todos los elementos de las obras que creaba, desde el mobiliario hasta la iluminación o los acabados en forja de hierro.

Gaudí también fue un innovador en el terreno de los oficios artesanales, ideando nuevas soluciones técnicas o decorativas con los materiales que utilizaba, como por ejemplo su forma de diseñar aplacados en cerámica hecha con piezas de desecho ("trencadís"), en combinaciones originales y fantasiosas. Para la restauración de la Catedral de Mallorca creó una nueva técnica de hacer vidrieras, consistente en yuxtaponer tres vidrios de los colores primarios —y a veces uno neutro—, variando el grueso del cristal para poder graduar la intensidad de la luz.
Asimismo, diseñó personalmente muchas de las esculturas de la Sagrada Familia, aplicando un curioso método de trabajo ideado por él: en primer lugar hacía un profundo estudio anatómico de la figura, centrándose en las articulaciones —para lo que estudió detenidamente la estructura del esqueleto humano—; a veces se servía de muñecos confeccionados con alambre para probar la postura adecuada de la figura a esculpir. En segundo lugar, realizaba fotografías de los modelos, utilizando un sistema de espejos que proporcionaban múltiples perspectivas. A continuación, hacía moldes en yeso de las figuras, tanto de personas como de animales (en una ocasión tuvo que izar un burro para que no se moviese). Sobre estos moldes modificaba las proporciones para conseguir una perfecta visión de la figura dependiendo de su ubicación en el templo (más grandes cuanto más elevadas). Por último, se esculpía en piedra.

Además de arquitecto, Gaudí fue urbanista y paisajista, procurando siempre ubicar sus obras en el entorno más adecuado, tanto natural como arquitectónico. Realizaba un profundo estudio del emplazamiento de sus construcciones, las cuales procuraba que se integrasen de una manera natural en el paisaje circundante, llegando a utilizar en numerosas ocasiones el material más común en su entorno, como la piedra pizarrosa en Bellesguard o el granito gris del Bierzo en el Palacio Episcopal de Astorga. Muchos de sus proyectos incluían jardines, como la Casa Vicens o los Pabellones Güell, o incluso eran totalmente ajardinados, como el parque Güell o los Jardines de Can Artigas. Un ejemplo perfecto de integración en la naturaleza fue el Primer Misterio de Gloria del Rosario Monumental de Montserrat, donde el marco arquitectónico es la propia naturaleza —en este caso la roca de Montserrat—, que da cabida al grupo escultórico que decora el camino a la Santa Cueva.
Igualmente, Gaudí destacó como interiorista, encargándose personalmente de la decoración de la mayoría de sus edificios, desde el diseño del mobiliario hasta los detalles más nimios. En cada caso supo aplicar particularidades estilísticas, personalizando la decoración según el gusto del dueño, el estilo predominante del conjunto o su ubicación en el entorno, ya fuese urbano o natural, o dependiendo de su tipología, laica o religiosa —buena parte de su producción estuvo ligada al mobiliario litúrgico—. Así, desde el diseño de un pupitre para su propio despacho al comienzo de su carrera, pasando por el mobiliario diseñado para el Palacio de Sobrellano de Comillas, realizó todo el mobiliario de las casas Vicens, Calvet, Batlló y Milà, del Palacio Güell y de la Torre Bellesguard, para desembocar en el mobiliario litúrgico de la Sagrada Familia. Es de remarcar que Gaudí efectuó estudios de ergonomía para adaptar su mobiliario a la anatomía humana de la forma más óptima posible. Buena parte del mobiliario que diseñó se expone actualmente en la Casa-Museo Gaudí del Parque Güell.

Otro aspecto a destacar es la inteligente distribución del espacio, pensado para crear un ambiente de confort e intimidad en el interior de todos sus edificios. Para ello organiza el espacio en diferentes secciones o ambientes adaptados a su uso específico, mediante el empleo de tabiques, falsos techos, puertas corredizas, vidrieras o armarios de pared. Además de cuidar hasta el último detalle todos los elementos estructurales y ornamentales, se cuidaba de que sus construcciones tuviesen una perfecta iluminación y ventilación, para lo que estudiaba con detalle la orientación del edificio respecto a los puntos cardinales, así como la climatología de la zona y su encaje en el entorno natural circundante. En aquella época comenzaba la demanda de un mayor confort doméstico, con la canalización de agua, gas y luz eléctrica, elementos que Gaudí supo incorporar de forma magistral en sus construcciones. Para la Sagrada Familia, por ejemplo, llevó a cabo profundos estudios de acústica e iluminación, para optimizarlas. Gaudí decía lo siguiente respecto a la luz:

La iluminación le sirve igualmente a Gaudí para organizar el espacio, atendiendo de forma cuidadosamente estudiada a la gradación de la intensidad lumínica para adaptarse adecuadamente a cada ambiente específico. Esto lo consigue con distintos elementos como tragaluces, vidrieras, persianas o celosías; cabe destacar en este sentido la gradación cromática utilizada en el patio de luces de la Casa Batlló para conseguir una distribución uniforme de la luz en todo el interior. Asimismo, suele orientar las casas al sur para aprovechar al máximo la luz solar.

La obra de Gaudí es de difícil clasificación. Inscrito en el modernismo, pertenece sin duda a esta corriente por su afán de renovación —sin romper por ello con la tradición—, la búsqueda de la modernidad, el sentido ornamental aplicado a su obra y el carácter multidisciplinar otorgado a sus realizaciones, donde tienen un papel fundamental los trabajos artesanales. A estas premisas Gaudí añade ciertas dosis de barroquismo, la inclusión de los adelantos tecnológicos y el mantenimiento de lenguajes arquitectónicos tradicionales, que junto a la inspiración en la naturaleza y el toque de originalidad que otorga a sus realizaciones constituyen la amalgama que proporciona al conjunto de su obra un sello personal y único en la historia de la arquitectura.

Cronológicamente, es difícil establecer unas pautas que determinen de forma veraz la evolución de su estilo. Si bien parte de unos postulados claramente historicistas para enmarcarse de lleno en el modernismo que surgía con fuerza en el último tercio del siglo XIX en Cataluña y llegar por fin a la resolución final de su estilo personal y orgánico, esta evolución no presenta unas etapas precisas con rupturas entre unas y otras, sino que en todas hay reflejos de las primeras, a medida que las va asimilando y superando. Una de las mejores periodificaciones realizadas de la obra de Gaudí es la de su discípulo y biógrafo Joan Bergós, efectuada según criterios plásticos y estructurales; Bergós establece cinco periodos en la producción gaudiniana: periodo preliminar, mudéjar-morisco, gótico evolucionado, naturalismo expresionista y síntesis orgánica.

Sus primeras realizaciones, tanto durante su etapa de estudiante como las primeras ejecutadas al obtener el título, destacan por la gran precisión de los detalles, la utilización de la geometría superior y la preponderancia de las consideraciones mecánicas en el cálculo de estructuras.

Durante sus estudios Gaudí realizó diversos proyectos de carrera, entre los que destacan: una puerta de cementerio (1875), un pabellón español para la Exposición Universal de Filadelfia de 1876, un embarcadero (1876), un patio para la Diputación de Barcelona (1876), una fuente monumental para la Plaza Cataluña de Barcelona (1877) y un paraninfo universitario (1877).

Antoni Gaudí comenzó su carrera profesional durante sus estudios universitarios, ya que para pagarse los estudios trabajó como delineante para varios de los mejores arquitectos que destacaban en la Barcelona del momento, como Joan Martorell, Josep Fontserè, Francisco de Paula del Villar y Lozano, Leandre Serrallach y Emilio Sala Cortés. Con Josep Fontserè tenía Gaudí una antigua relación, pues su familia era también originaria de Riudoms y se conocían de hacía tiempo. Pese a no tener título de arquitecto, Fontserè recibió el encargo del Ayuntamiento de Barcelona de la urbanización del Parque de la Ciudadela, realizado entre 1873 y 1882. En dicho proyecto Gaudí se encargó del diseño de la reja de entrada al parque, de la balaustrada de la placeta de la banda municipal y del proyecto hidráulico de la Cascada Monumental, donde proyectó una gruta artificial que ya demuestra su gusto por la naturaleza y el sentido orgánico que aplica a su arquitectura. También se apunta la autoría de Gaudí como delineante de Fontserè en una fuente-farola-reloj instalada en el mercado del Borne en 1875. Realizada en hierro fundido, tenía una base con una fuente con caños que salían de unas figuras de cisnes, sobre los que se encontraban cuatro esculturas de nereidas que sostenían sendas farolas de gas, con un reloj en la parte superior. Este diseño era muy parecido al coronamiento de la fuente monumental diseñada por Gaudí para la plaza de Cataluña, por lo que hace pensar que la autoría sería del arquitecto reusense.

Para Francisco del Villar Gaudí trabajó en el ábside del monasterio de Montserrat, dibujando en 1876 el Camarín de la Virgen para la iglesia benedictina; más tarde, sucedería a Villar en las obras de la Sagrada Familia. Con Leandre Serrallach trabajó en un proyecto de tranvía a la Villa Arcadia de Montjuïc. Por último, con Joan Martorell colaboró en la iglesia de los Jesuitas de la calle Caspe y el convento de las Salesas del Paseo de San Juan, así como en la iglesia de Villaricos (Almería). Igualmente, realizó para Martorell el proyecto para el concurso de la nueva fachada de la catedral de Barcelona, que finalmente no fue aprobado. Su relación con Martorell, al que consideró siempre como uno de sus principales y más influyentes maestros, le reportó un inesperado y venturoso fruto, ya que fue Martorell quien recomendó a Gaudí para hacerse cargo del proyecto de la Sagrada Familia.
Una vez obtenido el título de arquitecto en 1878 sus primeros trabajos fueron unas farolas para la plaza Real, el proyecto de Kioscos Girossi y el de la Cooperativa “La Obrera Mataronense”, que fue su primera obra importante. Gaudí recibió el encargo para unas farolas del Ayuntamiento de Barcelona en febrero de 1878, cuando había aprobado la carrera pero aún no se había expedido el título, que se despachó en Madrid el 15 de marzo de ese año. Para este encargo proyectó dos distintos tipos de farolas: una de seis brazos, de la que se instalaron dos en la plaza Real, y otra de tres, de la que también se instalaron dos en la plaza de Palacio, frente al Gobierno Civil. Las farolas fueron inauguradas en las fiestas de la Mercè de 1879. Hechas de hierro colado, con base de mármol, tienen una decoración donde destaca el caduceo de Mercurio, símbolo del comercio, así como el escudo de Barcelona.
El proyecto irrealizado de Kioscos Girossi fue un encargo del comerciante Enrique Girossi de Sanctis; habría consistido en 20 kioscos repartidos por toda Barcelona, cada uno de los cuales habría incluido unos retretes públicos, un puesto de flores y unos paneles de cristal para publicidad, además de reloj, calendario, barómetro y termómetro. Gaudí concibió una estructura de pilares de hierro y placas de mármol y cristal, coronado por una gran marquesina de hierro y cristal, con un sistema de iluminación de gas.

La Cooperativa Obrera Mataronense fue el primer proyecto de envergadura de Gaudí, en el que trabajó de 1878 a 1882, por encargo de Salvador Pagès i Anglada. El proyecto, para la sede social de la empresa en Mataró, constaba de una fábrica, un barrio de casas para los obreros, un casino y un edificio de servicios, de los que finalmente solo se llevaron a cabo la fábrica y el edificio de servicios. En la nave de la fábrica Gaudí utilizó por primera vez el arco catenario, con un sistema de ensamblaje con pernos ideado por Philibert de l'Orme. También aplicó por primera vez, en el edificio de servicios, la decoración en azulejo cerámico. Gaudí realizó el diseño urbanístico basándose en la orientación solar, otra de las constantes en sus obras, e incluyó zonas ajardinadas en el proyecto. Diseñó incluso el emblema de la Cooperativa, con la figura de una abeja, símbolo de la laboriosidad.
En mayo de 1878 diseñó Gaudí una vitrina para la Guantería Esteban Comella, que fue expuesta en el pabellón español de la Exposición Universal de París de ese año. Fue esta obra la que atrajo la atención del empresario Eusebi Güell, de visita en la capital francesa; quedó tan impresionado que a su retorno quiso conocer a Gaudí, empezando entonces una larga amistad y colaboración profesional, siendo Güell el principal mecenas de Gaudí y patrocinador de muchos de sus grandes proyectos.

El primer encargo que Güell realizó a Gaudí, ese mismo año, fue el diseño del mobiliario para la capilla-panteón del Palacio de Sobrellano en Comillas, que estaba entonces construyendo Joan Martorell, el maestro de Gaudí, por encargo del marqués de Comillas, suegro de Güell. Gaudí diseñó un sillón, un banco y un reclinatorio: el sillón estaba forrado de terciopelo, rematado por dos águilas con el escudo del marqués; el banco destaca por el relieve de un dragón, proyectado por Llorenç Matamala; el reclinatorio tiene decoración en bajorrelieve de formas vegetales.
También en 1878 realizó unos planos para un teatro en la antigua localidad de San Gervasio de Cassolas (hoy día un barrio de la Ciudad Condal); Gaudí no intervino en la posterior construcción del teatro, actualmente desaparecido. Al año siguiente diseñó los muebles y mostrador de la Farmacia Gibert, con marquetería de influencia árabe. Ese mismo año efectuó cinco dibujos para una cabalgata en homenaje al poeta Francesch Vicens García en Vallfogona de Riucorb, localidad en la que fue párroco este célebre escritor del siglo XVII, amigo de Lope de Vega. El proyecto de Gaudí giraba en torno al poeta glorificado y a distintos aspectos del trabajo en el campo, como la siega o la recogida de la uva y la aceituna; sin embargo, a causa de problemas organizativos del certamen, la idea de Gaudí no se llevó a cabo.

Entre 1879 y 1881 realizó el proyecto de decoración de la iglesia de Sant Pacià, perteneciente al Colegio de Jesús-María de San Andrés de Palomar: realizó el altar de estilo gótico, la custodia de influencia bizantina, el mosaico y la iluminación, así como el mobiliario del colegio. Incendiada la iglesia en la Semana Trágica de 1909, en la actualidad solo persiste el mosaico, de «opus tesselatum», probable obra del mosaiquista italiano Luigi Pellerin. Para estas mismas religiosas se encargó de la decoración de la iglesia del Colegio de Jesús-María de Tarragona (1880-1882): realizó el altar en mármol blanco italiano, y su parte frontal, o antipendio, lo dispuso con cuatro columnas que exhibían medallones de alabastro polícromo, con figuras de ángeles; el ostensorio, de madera dorada, obra de Eudald Puntí, decorado con rosarios, ángeles, los símbolos del Tetramorfos y la paloma del Espíritu Santo; y la sillería del coro, destruida en 1936.
En 1880 hizo un proyecto de iluminación eléctrica para la Muralla de Mar de Barcelona, que finalmente no fue llevado a cabo. Habría consistido en ocho grandes farolas de hierro, profusamente decoradas con motivos vegetales, frisos, escudos y nombres de batallas y de almirantes catalanes. Ese mismo año participó en el concurso para la construcción del Casino de San Sebastián (actual Ayuntamiento), que finalmente ganaron Luis Aladrén Mendivi y Adolfo Morales de los Ríos; Gaudí presentó un proyecto que era síntesis de varios estudios suyos anteriores, como el proyecto de fuente para la plaza Cataluña o el de patio para la Diputación Provincial.
Un nuevo encargo de los Güell-López para Comillas fue el de un quiosco para la visita del rey Alfonso XII a la localidad cántabra en 1881. Gaudí diseñó un pequeño templete con forma de turbante de influencia hindú, recubierto de mosaico y decorado con una gran profusión de pequeñas campanillas que producían un constante repique musical. Posteriormente fue instalado en los Pabellones Güell.

En 1882 realizó para su antiguo maestro, Joan Martorell, el proyecto para un monasterio benedictino y una iglesia dedicada al Espíritu Santo en Villaricos (Cuevas del Almanzora, Almería). Era de planta neogótica, parecida al convento de las Salesas que Gaudí proyectó igualmente con Martorell. Finalmente no se llevó a cabo, y los planos del proyecto fueron destruidos en el saqueo de la Sagrada Familia en 1936. Ese mismo año recibió el encargo para construir un pabellón de caza y unas bodegas en una finca llamada La Cuadra, en Garraf (Sitges), propiedad del magnate Eusebi Güell. Finalmente el pabellón no se llevó a cabo, construyéndose tan solo las bodegas unos años más tarde.

La colaboración de Gaudí con Martorell fue determinante para que éste recomendase a Gaudí para la Sagrada Familia. El famoso templo gaudiniano fue idea de Josep Maria Bocabella, fundador de la Asociación de Devotos de San José, para lo que adquirió una manzana completa del Ensanche barcelonés. En principio se encargó del proyecto el arquitecto Francisco de Paula del Villar y Lozano, que planeó la construcción de una iglesia de estilo neogótico, iniciándose las obras en 1882. Sin embargo, al año siguiente Villar renunció por desavenencias con la junta constructora, y el encargo pasó a manos de Gaudí, que reformó por completo el proyecto —salvo la parte ya construida de la cripta—. Gaudí emplearía el resto de su vida en la construcción del templo, que será la síntesis de todos sus hallazgos arquitectónicos, culminando en su .

En estos años Gaudí realiza una serie de obras de marcado gusto oriental, inspiradas en el arte del Próximo y Lejano Oriente (India, Persia, Japón), así como en el arte islámico hispánico, principalmente el mudéjar y nazarí. Gaudí emplea con gran profusión la decoración en azulejo cerámico, así como los arcos mitrales, cartelas de ladrillo visto y remates en forma de templete o cúpula.

Entre 1883 y 1888 construyó la Casa Vicens, encargo del corredor de bolsa Manuel Vicens i Montaner. Está estructurada en cuatro niveles o plantas, con tres fachadas y un amplio jardín, con una fuente monumental de ladrillo formada por un arco parabólico encima del cual había un paso entre columnas. La casa se cerraba con un muro de cerca con una reja de hierro colado, decorada con hojas de palmito, obra de Llorenç Matamala. Los muros de la casa son de mampostería alternada con filas de azulejo, que reproduce unas flores amarillas propias de la zona; la casa se remata con chimeneas y unas torres en forma de templetes. En el interior destacan los techos de vigas de madera policromada, adornados con temas florales de papel maché; los muros tienen esgrafiados de motivos vegetales, así como pinturas obra de Josep Torrescasana; por último, el suelo es de mosaico romano de "opus tesselatum". Una de las estancias más originales es el fumadero, donde destaca el techo en forma de cielo raso decorado con mucarnas árabes, que recuerdan el Generalife de la Alhambra de Granada.
El mismo año de 1883 Gaudí hizo un proyecto de retablo para la capilla del Santísimo Sacramento de la iglesia parroquial de San Félix de Alella, así como unos planos topográficos de la finca Can Rosell de la Llena en Gelida, y recibió el encargo de un hotelito anexo al Palacio de Sobrellano, del marqués de Comillas, en la homónima localidad cántabra. Conocido como El Capricho, fue encargado por Máximo Díaz de Quijano y construido entre 1883 y 1885. La dirección de las obras corrió a cargo de Cristóbal Cascante, compañero de estudios de Gaudí. De estilo oriental, tiene planta alargada, con tres niveles y una torre cilíndrica en forma de alminar persa, revestida completamente de cerámica. El acceso presenta cuatro columnas y arcos adintelados, con capiteles decorados con pájaros y hojas de palmito, como en la Casa Vicens. El salón principal destaca por un amplio ventanal con ventanas de guillotina, y dispone de un fumadero cubierto por falsas bóvedas de estuco de estilo árabe.
Gaudí realizó un segundo encargo para Eusebi Güell entre 1884 y 1887, los Pabellones Güell de Pedralbes. Güell tenía una finca en Les Corts de Sarrià, unión de dos terrenos conocidos como Can Feliu y Can Cuyàs de la Riera. El arquitecto Joan Martorell había construido un palacete de aire caribeño, derribado en 1919, en cuyo lugar se construyó el Palacio Real de Pedralbes. Gaudí recibió el encargo de reformar la casa y construir un muro de cerca y los pabellones de portería, además del diseño de los jardines, en los que situó la Fuente de Hércules. Realizó el muro de mampostería con varias puertas de entrada, la principal con una reja de hierro en forma de dragón, con una simbología alusiva al mito de Hércules y el Jardín de las Hespérides. Los pabellones constan de caballeriza, picadero y portería: la caballeriza es de base rectangular, cubierta con bóveda tabicada con forma de catenaria; el picadero es de base cuadrada, con una cúpula de perfil hiperboloidal, rematada por un templete; la portería consta de tres pequeñas edificaciones, la central de planta poligonal y cúpula hiperbólica, y otras dos más pequeñas de planta cúbica. Las tres están rematadas por unos ventiladores en forma de chimeneas recubiertas de cerámica. La obra está realizada con ladrillo visto de diversas tonalidades entre el rojo y el amarillo, y recubierta de cristal de colores; en ciertas secciones utilizó también bloques prefabricados de cemento. Actualmente los pabellones pertenecen a la Universidad Politécnica de Cataluña.

En 1885 Gaudí recibió de parte de Josep Maria Bocabella, el promotor de la Sagrada Familia, el encargo para un altar situado en el oratorio de la familia Bocabella, al haber obtenido licencia del Papa de poder tener un altar en su domicilio privado. El altar es de caoba, con barnizado de laca, con una losa de mármol blanco en el centro para las reliquias. Tiene decoración vegetal y varios motivos religiosos, como las letras griegas alfa y omega, símbolo del principio y el fin, frases del Evangelio e imágenes de San Francisco de Paula, Santa Teresa de Jesús y la Sagrada Familia; se cierra con una cortina con un crismón bordado. Su confección corrió a cargo del ebanista Frederic Labòria, que también colaboró con Gaudí en la Sagrada Familia.
Poco tiempo después Gaudí recibió un nuevo encargo del conde Güell, la construcción de su casa familiar, en la calle Nou de la Rambla de Barcelona. El Palacio Güell (1886-1888) sigue la tradición de las grandes casas señoriales catalanas como las de la calle Montcada. Gaudí diseñó una entrada monumental con unas magníficas puertas de arcos parabólicos y rejas caladas de hierro forjado, ornamentadas con el escudo de Cataluña y un yelmo con un dragón alado, obra de Joan Oñós. Destaca el recibidor interior, que tiene una altura de tres plantas; es el núcleo central del edificio, ya que está rodeado por las principales estancias del palacio, y destaca por su cubierta con doble cúpula de perfil paraboloide en el interior y cónico en el exterior, solución típica del arte bizantino. En la tribuna de la fachada Gaudí empleó un original sistema de arcos catenarios y columnas con capiteles hiperboloidales, estilo no empleado ni anterior ni posteriormente a Gaudí. Diseñó con esmero el interior del palacio, con una suntuosa decoración de estilo mudéjar, donde destacan los techos con artesonados de madera y hierro. En el tejado destacan las chimeneas, de formas geométricas, recubiertas de cerámica de vivos colores, así como la alta aguja en forma de linterna que supone el remate exterior de la cúpula del salón central, hecha igualmente de cerámica y rematada con una veleta de hierro.
Entre 1886 y 1902 el artífice reusense diseñó dos vitrales para la Capilla de Can Pujades en Vallgorguina: el primero, fechable entre 1886 y 1902, es un rosetón de unos 90 cm de diámetro, que representa la mano de Dios con el ojo bíblico que todo lo ve, rodeada de tres anagramas de Jesús, María y José; el segundo, datado en 1894, es una representación del Arcángel Miguel, de 75 x 24,5 cm. Estas obras provocaron una cierta polémica en 2014, cuando la Consejería de Cultura de la Generalidad de Cataluña y el Instituto de Estudios Catalanes anunciaron que se habían descubierto dos obras nuevas de Gaudí desconocidas hasta entonces, dentro de un inventario que se estaba confeccionando de vitrales de toda Cataluña. Sin embargo, luego se comprobó que estas obras eran ya conocidas anteriormente, y habían aparecido citadas en revistas y libros especializados en el corpus gaudiniano.

Con motivo de la Exposición Universal celebrada en el Parque de la Ciudadela de Barcelona en 1888, Gaudí construyó el pabellón de la Compañía Trasatlántica, propiedad del marqués de Comillas, en la Sección Marítima del certamen. Lo realizó en estilo nazarí granadino, con arcos de herradura y decoración de estuco; subsistió hasta la apertura del Paseo Marítimo de Barcelona en 1960. Con motivo de tal evento recibió de parte del Ayuntamiento de Barcelona el encargo de la restauración del Salón de Ciento y de la Escalera de Honor de la Casa de la Ciudad, junto con la realización de un sillón para la Reina Regente; del proyecto solo se llevó a cabo el sillón que el alcalde Francisco de Paula Rius y Taulet regaló a la reina.

En esta etapa Gaudí se inspiró sobre todo en el arte gótico medieval, el cual asume de forma libre, personal, intentando mejorar sus soluciones estructurales. El neogótico fue en aquella época uno de los estilos historicistas de mayor éxito, sobre todo a raíz de los estudios teóricos de Viollet-le-Duc. Gaudí estudió con profundidad el gótico catalán, balear y rosellonés, así como el leonés y el castellano en sus estancias en León y Burgos, llegando al convencimiento de que era un estilo imperfecto, a medio resolver. En sus obras elimina la necesidad de contrafuertes mediante el empleo de superficies regladas, y suprime cresterías y calados excesivos.
Un primer exponente será el Colegio de las Teresianas (1888-1889), en la calle Ganduxer de Barcelona, encargo de San Enrique de Ossó. Gaudí cumplió la voluntad de la orden de reflejar austeridad en el edificio, en cumplimiento del voto de pobreza; siguiendo las indicaciones de las religiosas proyectó un edificio sobrio, realizado en ladrillo por fuera, y con algunos elementos de ladrillo por dentro. También incorporó a la fachada rejas de hierro forjado, uno de sus materiales preferidos, y la coronó con un conjunto de almenas que sugieren un castillo, posible alusión a la obra de santa Teresa "El castillo interior". En los ángulos de la fachada figuran unos pináculos de ladrillo con una columna helicoidal culminada con la cruz de cuatro brazos, típica de las obras de Gaudí, y con unos escudos de cerámica con diversos símbolos definitorios de la orden teresiana. En el interior existe un pasillo que es famoso por la sucesión de arcos catenarios que contiene. Estos arcos de líneas elegantes no son meramente decorativos, sino que tienen la función de sostener el techo y la planta superior. Gaudí utilizó el arco en parábola como elemento constructivo idóneo, capaz de aguantar pesos elevados mediante perfiles poco gruesos.
El siguiente encargo lo recibió Gaudí de parte de un clérigo amigo de su Reus natal, Joan Baptista Grau i Vallespinós, que al ser nombrado obispo de Astorga encargó a Gaudí la construcción de un Palacio Episcopal para aquella ciudad, ya que recientemente se había incendiado el edificio anterior. Construido entre 1889 y 1915, es de aire neogótico, con una planta articulada con cuatro torres cilíndricas, rodeada por un foso. La piedra en la que está construido (granito gris de la comarca de El Bierzo) es respetuosa con el entorno, en especial con la catedral que se encuentra en la inmediata vecindad, así como también con la naturaleza, que en la Astorga de finales del siglo XIX estaba más presente que en la actualidad. El pórtico de entrada tiene tres grandes arcos abocinados, hechos con sillares separados entre sí por contrafuertes inclinados. La estructura del edificio se sustenta en pilares con capiteles decorados y en bóvedas de crucería sobre arcos ojivales de cerámica vidriada. Se remata con un almenado de estilo mudéjar. Gaudí abandonó el proyecto en 1893, a la muerte del obispo Grau, por desavenencias con el Cabildo, siendo terminado en 1915 por Ricardo García Guereta. Actualmente es Museo de los Caminos.

Otro proyecto de Gaudí fuera de Cataluña fue la Casa Botines, en León (1891-1894), encargo de Simón Fernández Fernández y Mariano Andrés Luna, comerciantes de tejidos leoneses, que recibieron la recomendación de Gaudí de parte de Eusebi Güell, con el que trataban en sus negocios. El proyecto de Gaudí fue un impresionante edificio de estilo neogótico, resuelto con su inconfundible estilo modernista. El edificio sirvió para albergar en sus plantas bajas los despachos y almacenes del negocio de tejidos, y disponía al mismo tiempo de viviendas en las plantas superiores. La construcción se realizó con muros de sólida cantería caliza, dispuesta en forma de almohadillado. El edificio está flanqueado por cuatro torres cilíndricas rematadas con elevadas agujas de forma cónica, hechas de pizarra, y rodeado de un foso con reja de forja. Las ventanas son de guillotina, con voladizos inclinados para retener la nieve, muy frecuente en el invierno leonés. La fachada es de estilo gótico, con arcos lobulados, y tiene un reloj y una escultura de "San Jorge y el dragón", obra de Llorenç Matamala. En la actualidad acoge el Museo Gaudí Casa Botines gestionado por la Fundación España-Duero.
En 1892 recibió Gaudí de parte de Claudio López Bru, segundo marqués de Comillas, el encargo para unas Misiones Católicas Franciscanas para la ciudad de Tánger, en Marruecos (por aquel entonces una colonia española). El proyecto consistía en un conjunto compuesto por iglesia, hospital y escuela, y Gaudí concibió una estructura de planta cuadrilobulada, en forma de cinco cruces potenzadas (seña de los misioneros franciscanos de Marruecos), con arcos catenarios y torres de perfil parabólico, con ventanas hiperboloidales. Finalmente el proyecto no se llevó a cabo, cosa que Gaudí lamentó profundamente, guardando siempre consigo el boceto que realizó del conjunto. Pese a todo, este proyecto le influyó para las obras de la Sagrada Familia, especialmente en el diseño de las torres, de perfil parabólico como en las Misiones.

Para la familia Güell proyectó en 1895 una capilla funeraria para el monasterio de Montserrat, obra irrealizada de la que se conocen pocos datos. Ese año por fin se iniciaron las obras de las Bodegas Güell, del antiguo proyecto de 1882 para un pabellón de caza y unas bodegas en la finca La Cuadra de Garraf (Sitges), propiedad de Eusebi Güell. Construidas entre 1895 y 1897 bajo la dirección de Francesc Berenguer, ayudante de Gaudí, las bodegas tienen un perfil frontal triangular, con cubiertas de gran verticalidad con pronunciadas pendientes de losas de piedra, rematadas por un juego de chimeneas y dos puentes que la unen al antiguo edificio. Tiene tres plantas: la baja para cochera, la vivienda y una capilla cubierta con bóveda catenaria, con el altar en el centro. El conjunto se completa con un pabellón portería, donde destaca la puerta de forja, con forma de red de pesca.

En el término municipal de Sant Gervasi de Cassoles (hoy día un barrio de Barcelona), Gaudí recibió el encargo, de parte de la viuda de Jaume Figueras, de reformar la Torre Bellesguard (1900-1909), antiguo palacio de veraneo del rey Martín I el Humano. Gaudí hizo un proyecto neogótico, respetando al máximo el edificio anterior; como siempre, procuró integrar la arquitectura en el marco natural circundante, por lo que efectuó la construcción con la piedra pizarrosa del lugar. El edificio es de planta cuadrada de 15 x 15 metros, con los vértices orientados a los cuatro puntos cardinales. Construido con piedra y ladrillo, tiene mucha más proyección vertical, ayudado por una torre troncocónica coronada con la cruz de cuatro brazos, junto a la bandera catalana y una corona real. La casa dispone de sótano, planta baja, planta noble y desván, con techo de cuatro aguas.

En este periodo Gaudí perfecciona su estilo personal, inspirándose en las formas orgánicas de la naturaleza, poniendo en práctica toda una serie de nuevas soluciones estructurales originadas en los profundos análisis efectuados por Gaudí de la geometría reglada. A ello añade el arquitecto una gran libertad creativa y una imaginativa creación ornamental. Partiendo de cierto barroquismo sus obras adquieren gran riqueza estructural, de formas y volúmenes desprovistos de rigidez racionalista o de cualquier premisa clásica.

Por encargo de la razón social Hijos de Pedro Mártir Calvet, Gaudí construyó la Casa Calvet (1898-1899), en la calle Caspe de Barcelona. La fachada es de piedra de sillería de Montjuïc, adornada con balcones de hierro forjado y rematada por dos frontones, coronados con cruces de hierro de forja. Destaca asimismo en la fachada la tribuna del piso principal, decorada con motivos vegetales y mitológicos. En este proyecto Gaudí utilizó un cierto estilo barroco, visible en el uso de columnas salomónicas, la decoración con temas florales y el proyecto de azotea con cascada y maceteros de aire rococó. Por esta obra ganó en 1900 el premio al mejor edificio del año otorgado por el Ayuntamiento de Barcelona.

Una obra casi desconocida de Gaudí es la Casa Clapés (1899-1900), en la calle Escorial 125, encargo del pintor Aleix Clapés, que colaboró en alguna ocasión con Gaudí, como en la decoración del Palacio Güell y de la Casa Milà. Tiene planta y tres pisos, de muros revocados y balcones de hierro colado. Por su falta de decoración o de soluciones estructurales originales se ignoró la autoría de Gaudí hasta 1976, fecha en que se hallaron los planos firmados por el arquitecto. En 1900 reformó la casa del doctor Pere Santaló, en la calle Nou de la Rambla 32, obra igualmente de escasa importancia. Santaló era amigo de Gaudí, al que acompañó en su estancia en Puigcerdà en 1911, y fue el que le recomendó hacer trabajos manuales para su reumatismo.
También en 1900 diseñó dos estandartes: el del Orfeó Feliuà (de Sant Feliu de Codines), confeccionado en latón, cuero, corcho y seda, con motivos ornamentales basados en el martirio de san Félix (una rueda de molino), en la música (un pentagrama y una clave de sol) y la inscripción “Orfeó Feliuà”; y el de la Virgen de la Misericordia de Reus, para la peregrinación de los reusenses residentes en Barcelona, que presenta una imagen de Isabel Besora, la pastora a la que se le apareció la Virgen en 1592, obra de Aleix Clapés y, en el reverso, una rosa y la bandera de Cataluña. Precisamente, del Santuario de la Virgen de la Misericordia de Reus hizo Gaudí ese mismo año un anteproyecto para la reforma de la fachada principal de la iglesia, que finalmente no se llevó a término, ya que la junta del Santuario lo consideró oneroso. Este rechazo sentó muy mal a Gaudí, dejándole cierto resquemor hacia Reus, pudiendo ser el origen de su afirmación posterior de ser Riudoms su lugar de nacimiento. Entre 1900 y 1902 Gaudí trabajó en la Casa Miralles, encargo del industrial Hermenegild Miralles i Anglès; Gaudí solo diseñó el muro de cerca y la puerta de acceso, hechos de mampostería de formas onduladas, con puerta de hierro rematada con la cruz de cuatro brazos. Posteriormente, la casa de Miralles fue obra de Domènec Sugrañes, arquitecto colaborador de Gaudí.
El principal proyecto de Gaudí a principios del siglo XX fue el Parque Güell (1900-1914), nuevo encargo de Eusebi Güell para construir una urbanización residencial al estilo de las ciudades-jardín inglesas. El proyecto no tuvo éxito, ya que de 60 parcelas en que se dividió el terreno solo se vendió una. Pese a ello, se construyeron los accesos al parque y las áreas de servicios, desplegando Gaudí todo su genio arquitectónico y poniendo en práctica muchas de sus innovadoras soluciones estructurales que serán emblemáticas de su estilo organicista y que culminarán en la Sagrada Familia. El parque Güell se sitúa en la llamada Montaña Pelada, en el barrio del Carmelo de Barcelona. Era un paraje abrupto, con fuertes desniveles que Gaudí sorteó con un sistema de viaductos integrados en el terreno. El acceso al parque tiene dos edificios, destinados a portería y administración, rodeados de un muro de mampostería y cerámica vidriada policromada. Estos pabellones de entrada son muestra de la plenitud gaudiniana, con cubiertas de bóvedas catalanas en forma de paraboloide hiperbólico. Pasados los pabellones se encuentra un escalinata que conduce a los niveles superiores, decorada con unas fuentes esculpidas donde destaca el dragón, que se ha convertido en símbolo del parque y uno de los más reconocidos emblemas de Gaudí. Esta escalinata conduce a la Sala Hipóstila, que habría servido de mercado de la urbanización, hecha con grandes columnas de orden dórico. Encima de esta sala se encuentra una gran plaza en forma de teatro griego, con el famoso banco corredizo revestido de cerámica troceada (“trencadís”), obra de Josep Maria Jujol. La casa de muestra del parque, obra de Francesc Berenguer, fue residencia de Gaudí de 1906 a 1926, y actualmente acoge la Casa-Museo Gaudí.
En esta época Gaudí colaboró en un interesante proyecto colectivo, el Rosario Monumental de Montserrat (1900-1916). Ubicado en el camino a la Santa Cueva de Montserrat, se trataba de una serie de grupos escultóricos que evocaban los misterios de la Virgen que se rezan en el Rosario. En este proyecto intervinieron los mejores arquitectos y escultores de la época, y es una singular muestra del modernismo catalán. Gaudí proyectó el "Primer Misterio de Gloria", que aludía al Santo Sepulcro, con una estatua de "Cristo resucitado", obra de Josep Llimona, y el grupo de las "Tres Marías" esculpido por Dionisio Renart. Otro proyecto monumental ideado por Gaudí para Montserrat no se llegó a realizar: habría consistido en coronar el Cavall Bernat (uno de los picos de la montaña) con un mirador en forma de corona real, incorporando a la pared un escudo de Cataluña de veinte metros de altura.

En 1901 realizó Gaudí la decoración de la casa de Isabel Güell López, marquesa de Castelldosrius, hija de Eusebi Güell. Sita en la calle Junta de Comerç 19, la casa había sido construida en 1885 y reformada entre 1901 y 1904; la casa fue destruida por una bomba durante la Guerra Civil. Al año siguiente intervino Gaudí en la decoración del Bar Torino, propiedad de Flaminio Mezzalama, sito en Paseo de Gracia 18; Gaudí diseñó la ornamentación del Salón Árabe de dicho establecimiento, confeccionada con losetas de cartón prensado y barnizado, de estilo árabe (hoy desaparecido).

Un proyecto de gran interés para Gaudí fue la restauración de la catedral de Santa María de Palma de Mallorca (1903-1914), por encargo del obispo de esa ciudad, Pere Campins i Barceló. Gaudí proyectó una serie de actuaciones como desmontar el retablo barroco del altar mayor, dejando a la vista la cátedra episcopal, desplazar el coro del centro de la nave y situarlo en el presbiterio, dejar expedita la capilla de la Trinidad, colocar nuevas cantorías y púlpitos, decorar la catedral con iluminación eléctrica, descegar los ventanales góticos de la Capilla Real y dotarlos de vidrieras, situar un gran baldaquino sobre el altar mayor y completar la decoración con pinturas. Las obras las dirigió Joan Rubió i Bellver, ayudante de Gaudí, interviniendo también Josep Maria Jujol y los pintores Joaquín Torres García, Iu Pascual y Jaume Llongueras. Gaudí abandonó el proyecto en 1914 por divergencias con el cabildo catedralicio.
Uno de los mayores encargos y de las obras más emblemáticas de Gaudí fue la Casa Batlló (1904-1906). Encargo de Josep Batlló i Casanovas para reformar un edificio anterior de Emilio Sala Cortés de 1875, Gaudí se centró en la fachada, el piso principal, el patio de luces y la azotea, y levantó un quinto piso para el personal de servicio. Para esta obra contó con la colaboración de sus ayudantes Domènec Sugrañes, Joan Rubió y Josep Canaleta. La fachada se hizo con piedra arenisca de Montjuïc, tallada según superficies regladas en forma alabeada; las columnas tienen forma ósea, con representaciones vegetales. Gaudí conservó la forma rectangular de los balcones del edificio anterior —con barandillas de hierro con forma de antifaz—, dando al resto de la fachada una forma ondulada en sentido ascendente. Asimismo revistió la fachada con cerámica de pedazos de cristal de varios colores ("trencadís"), que Gaudí obtenía en los desechos de la vidriería Pelegrí. El patio interno se cubrió con una claraboya de cristal sostenida por una estructura de hierro con forma de doble T, que apoya en una serie de arcos catenarios. En la azotea destacan las chimeneas de formas helicoidales y rematadas por sombreretes cónicos, revestidas de vidrio transparente en su parte central y de cerámica en la superior, y rematadas por unas bolas de cristal transparente rellenas de arena de distintos colores. Culmina la fachada una bóveda formada por arcos catenarios cubiertos con dos capas de ladrillo, recubierta con cerámica vidriada en forma de escamas (en tonos amarillo, verde y azul), que recuerda el lomo de un dragón; en la parte izquierda hay una torre cilíndrica con los anagramas de Jesús, María y José, y con la cruz gaudiniana de cuatro brazos.

En 1904, por encargo del pintor Lluís Graner, realizó el proyecto de decoración de la Sala Mercè, en la Rambla de los Estudios, uno de los primeros cines de Barcelona; la sala imitaba una gruta, inspirándose en las Cuevas del Drach de Mallorca. También para Graner diseñó un chalet en la Bonanova, del que solo se construyó los cimientos y la puerta principal, con tres aperturas: para personas, carruajes y pájaros; el edificio habría tenido una estructura semejante a la Casa Batlló o a la portería del parque Güell. Unos años después el albañil Julián Bardier —que trabajó en el chalet Graner— construyó una réplica de la puerta de los Pájaros en Comillas (Cantabria).
El mismo año construyó el Taller Badia, para Josep y Lluís Badia Miarnau, herreros y forjadores colaboradores de Gaudí en varias de sus obras, como las casas Batlló y Milà, el parque Güell y la Sagrada Familia; sito en la calle Nàpols 278, era un edificio de líneas sencillas, hecho de mampostería (hoy desaparecido). En esas fechas diseñó también un pavimento hidráulico de baldosas de forma hexagonal para la Casa Batlló, aunque finalmente no se colocaron en esa ubicación y se reaprovecharon para la Casa Milà; eran de color verde y estaban decoradas con un alga, un caracol y una estrella de mar. Esta baldosa fue elegida posteriormente para pavimentar el paseo de Gracia barcelonés.

Al año siguiente construyó el chalet-refugio de Catllaràs, en La Pobla de Lillet, para la fábrica de cemento Asland, propiedad de Eusebi Güell. Tiene una estructura simple pero muy original, con forma de arco apuntado, con dos tramos de escaleras semicirculares para conducir a los dos pisos superiores. En esta misma localidad realizó entre 1905 y 1907 los Jardines de Can Artigas, en la zona llamada Fuente de la Magnesia, por encargo del industrial textil Joan Artigas i Alart; intervinieron en esta obra operarios que habían trabajado en el Parque Güell, realizando un proyecto parecido al del famoso parque barcelonés.
En 1906 hizo el proyecto del puente sobre el Torrente de Pomeret, entre Sarrià y Sant Gervasi. Este torrente se encontraba precisamente entre dos obras de Gaudí, la Torre Bellesguard y el Chalet Graner, por lo que pidieron al arquitecto un estudio para salvar el desnivel: Gaudí proyectó una interesante estructura compuesta de triángulos yuxtapuestos que sostendrían el entramado del puente, siguiendo el estilo de los viaductos que había realizado en el parque Güell. Se habría construido de cemento, y habría tenido una longitud de 154 metros y una altura de 15 metros; la barandilla estaría recubierta de azulejo, con una inscripción dedicada a Santa Eulalia. El proyecto no fue aprobado por el Ayuntamiento de Sarrià.
El mismo año intervino al parecer en la torre Damià Mateu, en Llinars del Vallés, en colaboración con su ayudante Francesc Berenguer, si bien no está clara la autoría del proyecto o en qué grado intervino cada uno. El estilo del edificio evoca las primeras obras de Gaudí, como la Casa Vicens o los Pabellones Güell; tenía una reja de entrada en forma de red de pescar, actualmente instalada en el Parque Güell. La casa fue demolida en 1939. También en 1906 diseñó un nuevo estandarte, esta vez para el Gremio de Cerrajeros y Herreros, para la procesión de Corpus Christi de 1910 en la catedral de Barcelona. Era de color verde oscuro, con el escudo de Barcelona en el borde superior izquierdo, y una imagen de san Eloy, patrón del gremio, con instrumentos típicos del oficio. La bandera fue quemada en julio de 1936.
Otro de los mayores encargos y una de las obras más elogiadas de Gaudí será la Casa Milà, más conocida como "La Pedrera" (1906-1910), encargo de Pere Milà i Camps. Gaudí concibió la casa alrededor de dos grandes patios de forma curvilínea, con una estructura de pilares de piedra, ladrillo y hierro colado, y entramados de jácenas de hierro. Toda su fachada está realizada en piedra calcárea de Villafranca del Panadés, salvo la parte superior que está cubierta de azulejos blancos, evocando una montaña nevada. Posee un total de cinco plantas, más un desván —realizado en su totalidad con arcos catenarios— y la azotea, así como los dos grandes patios interiores, uno de planta circular y otro de planta oval. En la azotea destacan las salidas de escalera, rematadas con la cruz de cuatro brazos, así como las chimeneas, recubiertas de cerámica con unas formas que sugieren yelmos de soldados. La decoración interior corrió a cargo de Josep Maria Jujol y los pintores Iu Pascual, Xavier Nogués y Aleix Clapés. La fachada habría estado rematada por un grupo escultórico de piedra, metal y cristal con la Virgen del Rosario rodeada de los arcángeles Miguel y Gabriel, de cuatro metros de altura. Se hizo un boceto a cargo del escultor Carles Mani, pero debido a los sucesos de la Semana Trágica de 1909 se abandonó el proyecto.
Con motivo del séptimo centenario del nacimiento del rey Jaime I Gaudí proyectó en 1907 un monumento en su memoria. Se habría situado en la plaza del Rey, y habría supuesto también la reforma de los edificios adyacentes: nuevo techo para la catedral, así como la culminación de sus torres y cimborio; colocación de tres jarrones sobre los contrafuertes de la Capilla de Santa Ágata, dedicados a las advocaciones de las letanías lauretanas ("Vas Spirituale", "Vas Honorabile" y "Vas Insigne Devotiones"), así como la figura de un ángel sobre el campanario de la capilla; por último, abrir una gran plaza junto a la muralla (actual Plaza de Ramón Berenguer el Grande). El proyecto no se realizó porque no gustó al consistorio barcelonense.

En 1908 Gaudí concibió un proyecto no realizado para un gran hotel-rascacielos en Nueva York, el Hotel Atracción, encargo de dos empresarios estadounidenses de los que se desconoce el nombre. Habría tenido 360 metros de altura (más que el Empire State), con un cuerpo central más alto de forma paraboloide, rematado con una estrella, y flanqueado por cuatro cuerpos de edificio dedicados a museos, galerías de arte y auditorios, con formas parecidas a la Casa Milà. En el interior, habría tenido cinco grandes salones superpuestos, uno dedicado a cada continente.

El último proyecto para su gran mecenas, Eusebi Güell, fue el de una iglesia para la Colonia Güell, en Santa Coloma de Cervelló, de la que solo se construyó la nave inferior (conocida hoy día como Cripta de la Colonia Güell) (1908-1918). Proyecto de colonia obrera iniciado en 1890, se había construido la fábrica, edificios de servicios y viviendas para los obreros. La que habría sido iglesia de la Colonia fue proyectada por Gaudí en 1898, aunque no se colocó la primera piedra hasta el 4 de octubre de 1908. Lamentablemente, solo se construyó la nave inferior de la iglesia, ya que a la muerte del conde Güell en 1918 sus hijos abandonaron el proyecto. Gaudí proyectó una iglesia de planta oval con cinco naves, una central y dos más a cada lado. Ideó un conjunto plenamente integrado en la naturaleza, reflejo del concepto que Gaudí tenía de la arquitectura como estructura orgánica. Un pórtico de bóvedas de paraboloide hiperbólico antecede a la cripta, primera vez que Gaudí empleó esta estructura y primer ejemplo de bóvedas paraboloidales en la historia de la arquitectura. En la cripta destacan los grandes ventanales, de forma hiperboloidal, cubiertos con vidrios de colores en forma de pétalos de flor o alas de mariposa. En el interior se alternan pilares circulares de ladrillo con columnas inclinadas de basalto de Castellfollit de la Roca.

En los últimos años de su carrera, dedicados casi en exclusiva a la Sagrada Familia, Gaudí llega a la culminación de su estilo naturalista, haciendo una síntesis de todas las soluciones y estilos probados hasta aquel entonces. Gaudí logra una perfecta armonía en la interrelación entre los elementos estructurales y los ornamentales, entre plástica y estética, entre función y forma, entre contenido y continente, logrando la integración de todas las artes en un todo estructurado y lógico.

El primer ejemplo de su etapa final lo tenemos en un edificio sencillo pero muy ingenioso, las Escuelas de la Sagrada Familia, pequeño edificio destinado a escuela para los hijos de los obreros que trabajaban en el templo. Construido en 1909, tiene planta rectangular de 10x20 metros, y constaba de tres aulas, vestíbulo y capilla. La construcción se realizó con ladrillo visto, en tres capas superpuestas, siguiendo la técnica tradicional catalana. Tanto las paredes como el tejado tienen forma ondulada, que confiere a la estructura una sensación de ligereza pero a la vez una gran resistencia. Las Escuelas de la Sagrada Familia han sido un ejemplo en genialidad constructiva y han servido de fuente de inspiración para muchos arquitectos, por su simplicidad, resistencia, originalidad del volumen, funcionalidad y pureza geométrica.

En el mismo año podría haber colaborado con su ayudante, Francesc Berenguer, en la parroquia de San Juan Bautista de Gracia (Barcelona), donde podría haber sido el responsable de la capilla del Santísimo Sacramento y del jubé. Esta posible autoría, no acreditada documentalmente, fue dada a conocer por el escritor y biógrafo gaudiniano Josep Maria Tarragona en el Segundo Congreso Mundial Gaudí celebrado en 2016. Según este experto, cabría adjudicar esta obra al arquitecto en función de su análisis estilístico, y habida cuenta de que Berenguer no poseía el título de arquitecto, por lo que necesitaba acreditación para sus trabajos. La capilla es subterránea, con un ábside y cuatro cúpulas recubiertas de "trencadís", decoradas con una cruz de Malta con doce espigas, una parra con doce racimos de uvas —en alusión a los doce apóstoles— y varias inscripciones en latín. Por su parte, el jubé se encuentra en una fachada lateral del edificio, y está formado por un balcón rodeado de coros, con una crucifixión encima. 
En mayo de 1910 Gaudí pasó una breve estancia de reposo en Vich, donde recibió el encargo de diseñar unas farolas para la Plaza Mayor de la ciudad, en conmemoración del primer centenario del nacimiento de Jaume Balmes. Eran unas farolas en forma de obelisco, con base y fuste de piedra basáltica de Castellfollit de la Roca y brazos de hierro forjado, rematadas por la cruz de cuatro brazos; la decoración era de motivos vegetales e incluía las fechas de nacimiento y defunción de Balmes. Las farolas fueron derribadas en 1924, pues presentaban mal estado de conservación.

Ese mismo año, con motivo de la obtención del título de conde por parte de Eusebi Güell, Gaudí diseñó un escudo de armas para su gran mecenas: hizo un escudo con la parte inferior de forma catenaria, tan típica en Gaudí; lo dividió en dos con la figura del templete del Palacio Güell, poniendo a la derecha una paloma con una rueda dentada —en alusión a la Colonia Güell de Santa Coloma de Cervelló ("coloma" es paloma en catalán)—, con la leyenda «ahir pastor» (ayer pastor) y a la izquierda un búho posado sobre media luna —símbolo de prudencia y sabiduría— con la leyenda «avuy senyor» (hoy señor). Remata el escudo un yelmo con la corona condal y la paloma símbolo del Espíritu Santo.

En 1912 construyó dos púlpitos para la iglesia de Santa María de Blanes: el del lado del Evangelio tenía planta hexagonal, decorado con la paloma del Espíritu Santo y los nombres en latín de los cuatro evangelistas y los siete Dones del Espíritu Santo; el de la Epístola tenía los nombres de los apóstoles que escribieron epístolas (san Pedro, san Pablo, san Juan Evangelista, san Judas Tadeo y Santiago el Menor), con las tres virtudes teologales y las llamas del fuego de Pentecostés. Estos púlpitos fueron quemados en julio de 1936. Para la restauración de la catedral de Manresa se pidió a Gaudí en 1915 que realizase una valoración del anteproyecto realizado por el arquitecto Alexandre Soler i March, encargado de las obras. Gaudí sugirió algunas correcciones, como colocar un pórtico junto al baptisterio, una cubierta a dos aguas sobre la nave principal y una sala sobre el pórtico para museo y archivo.
Desde 1915 Gaudí se dedicó prácticamente en exclusiva a su obra cumbre, la Sagrada Familia, que supone la síntesis de toda la evolución arquitectónica del genial arquitecto. Después de la realización de la cripta y el ábside, todavía en estilo neogótico, el resto del templo lo concibió en un estilo orgánico, imitando las formas de la naturaleza, donde abundan las formas geométricas regladas. El interior debía semejar un bosque, con un conjunto de columnas arborescentes inclinadas, de forma helicoidal, creando una estructura a la vez simple y resistente. Gaudí aplicó en la Sagrada Familia todos sus hallazgos experimentados anteriormente en obras como el parque Güell o la cripta de la Colonia Güell, consiguiendo elaborar un templo estructuralmente perfecto a la vez que armónico y estético.

La Sagrada Familia tiene planta de cruz latina, de cinco naves centrales y transepto de tres naves, y ábside con siete capillas. Ostenta tres fachadas dedicadas al Nacimiento, Pasión y Gloria de Jesús, y cuando esté concluido tendrá 18 torres: cuatro en cada portal haciendo un total de doce por los apóstoles, cuatro sobre el crucero invocando a los evangelistas, una sobre el ábside dedicada a la Virgen y la torre-cimborio central en honor a Jesús, que alcanzará los 170 metros de altura. El templo dispondrá de dos sacristías junto al ábside, y de tres grandes capillas: la de la Asunción en el ábside y las del Bautismo y la Penitencia junto a la fachada principal; asimismo, estará rodeado de un claustro pensado para las procesiones y para aislar el templo del exterior. Gaudí aplicó a la Sagrada Familia un alto contenido simbólico, tanto en arquitectura como en escultura, dedicando a cada parte del templo un significado religioso.
Durante la vida de Gaudí solo se completaron la cripta, el ábside y, parcialmente, la fachada del Nacimiento —de la que Gaudí solo vio coronada la torre de San Bernabé—. A su muerte se hizo cargo de la construcción su ayudante, Domènec Sugrañes; posteriormente, ha estado bajo la dirección de diversos arquitectos, siendo Jordi Faulí i Oller director de las obras desde 2016. En la decoración escultórica han trabajado artistas como Llorenç y Joan Matamala, Carles Mani, Jaume Busquets, Joaquim Ros i Bofarull, Etsuro Sotoo y Josep Maria Subirachs, autor de la decoración de la fachada de la Pasión.

Durante los últimos años de su vida, aparte de su dedicación a la Sagrada Familia, solo intervino en pequeños proyectos que no fueron llevados a término: en 1916, al morir el obispo de Vic Josep Torras i Bages, amigo de Gaudí, proyectó un monumento en homenaje al clérigo, que pensó instalar frente a la fachada de la Pasión de la Sagrada Familia. Realizó un boceto del proyecto, que finalmente no se llevó a cabo, y se realizó un busto de yeso del obispo Torras, obra de Joan Matamala bajo las órdenes de Gaudí; instalado en la Sagrada Familia —habría formado parte del monumento—, fue destruido en 1936. Actualmente está prevista la realización de este monumento, en el conjunto de las obras de la Fachada de la Pasión de la Sagrada Familia. Otro proyecto de monumento conmemorativo, igualmente irrealizado, fue el dedicado a Enric Prat de la Riba, que se habría situado en Castelltersol, lugar de nacimiento del político catalán. El proyecto data de 1918, y habría consistido en una alta torre con dos pórticos y una aguja rematada en una estructura de hierro de la que pendería la bandera catalana. El dibujo del proyecto fue de Lluís Bonet i Garí, ayudante de Gaudí.

En 1922 recibió Gaudí un encargo de parte del padre franciscano Angélico Aranda de una iglesia dedicada a Nuestra Señora de los Ángeles en Rancagua (Chile). Gaudí se excusó diciendo que ocupaba su tiempo en exclusiva a la Sagrada Familia, pero envió a Chile unos bocetos de la capilla de la Asunción que había proyectado para el ábside de la Sagrada Familia, que más o menos coincidían un poco con los solicitado por el padre Aranda. Este proyecto no se llevó a cabo, aunque en la actualidad existe la intención de retomarlo —por parte del arquitecto chileno Christian Matzner—, y construir por fin una obra diseñada por Gaudí en el Nuevo Continente. Por el momento hay destinados unos terrenos —llamados parque Cataluña— para la construcción de la iglesia, y se baraja la fecha de 2017 para su construcción.

Ese mismo año Gaudí recibió una consulta para la construcción de una estación monumental de trenes para Barcelona (la futura Estación de Francia). Gaudí sugirió una estructura de hierro en forma de gran toldo suspendido, solución original bastante adelantada a su época; quizá por ello, el proyecto arredró a los ingenieros encargados, que declinaron el ofrecimiento de Gaudí. Los últimos proyectos conocidos del arquitecto son el de una capilla para la Colonia Calvet en Torelló, de 1923, y el de un púlpito para Valencia (se desconoce el lugar exacto), de 1924. Desde entonces Gaudí trabajó ya exclusivamente para la Sagrada Familia, hasta el fatídico día del accidente que le causó la muerte.

La ingente tarea a la que hizo frente Gaudí —no en cantidad de obras, pero sí en la complejidad de las mismas, cuidadas hasta el último detalle— hizo que necesitase la colaboración de un gran número de ayudantes, tanto arquitectos como artesanos y profesionales de todos los sectores. Gaudí siempre marcaba las pautas de trabajo, pero dejaba margen de maniobra a las capacidades individuales de todos sus colaboradores. Prueba de su maestría tanto en el oficio como en las relaciones humanas es que supo aglutinar un gran número de profesionales, todos con distintas idiosincrasias y maneras de trabajar, y crear un equipo integrado y perfectamente estructurado.

Entre sus colaboradores destacan:


Siete de las han sido declaradas por la Unesco como Patrimonio de la Humanidad: en 1984 el Parque Güell, el Palacio Güell y la Casa Milà; y en 2005 la fachada del Nacimiento, la cripta y el ábside de la Sagrada Familia, la Casa Vicens y la Casa Batlló en Barcelona, junto con la cripta de la Colonia Güell en Santa Coloma de Cervelló.

La declaración de Patrimonio Mundial de estas obras de Gaudí supone reconocer su valor universal excepcional. De acuerdo con sus Criterios de evaluación del Valor Universal Excepcional, las obras cumplen tres de estos criterios, siendo razonados por la UNESCO de la siguiente forma:




La figura de Gaudí ha sido recreada en obras literarias y cinematográficas.





</doc>
<doc id="15418" url="https://es.wikipedia.org/wiki?curid=15418" title="Alfabeto gótico">
Alfabeto gótico

El alfabeto gótico es fundamentalmente una adaptación del alfabeto griego en su grafía uncial. 

Proviene del alfabeto ulfilano creado por el obispo Ulfilas. Además contiene tres caracteres de uncial latino y cinco runas germánicas. Cada letra posee un valor numérico y dos de ellas no poseen ninguna otra función. La transliteración en las obras científicas y didácticas se realiza aumentando en dos símbolos el alfabeto latino por medio de la ligadura, "ƕ" "(h+v") y la letra "thorn", "þ", tomada del inglés antiguo. La notación de Wulfila era ambigua: Un mismo diagrama "ai" podía anotarse, por ejemplo, como [ai], [ɛ] o [ɛ̄]. La transcripción recurre a diacríticos para aligerar las dificultades de lectura.

"Nota: Para poder visualizar estos caracteres es posible que el ordenador necesite una ."

Las respectivas grafías en código unicode ordenadas alfabéticamente corresponden a: 𐌰 𐌱 𐌲 𐌳 𐌴 𐌵 𐌶 𐌷 𐌸 𐌹 𐌺 𐌻 𐌼 𐌽 𐌾 𐌿 𐍀 𐍁 𐍂 𐍃 𐍄 𐍅 𐍆 𐍇 𐍈 𐍉 𐍊.



</doc>
<doc id="15419" url="https://es.wikipedia.org/wiki?curid=15419" title="Economía de Alemania">
Economía de Alemania

La economía de Alemania es la cuarta economía más poderosa del mundo después de la de Estados Unidos, China y Japón y la quinta por PIB (PPA). El país es considerado el motor económico de la Unión Europea (UE). En 2014, Alemania registró el mayor superávit comercial en el mundo con 285 mil millones de dólares, por lo que es el mayor exportador de capital a nivel mundial. Alemania es el tercer mayor exportador del mundo con 1.511.000 millones de dólares exportados en 2014. Las exportaciones representan el 41% de la producción nacional. El sector servicios contribuye alrededor del 70% del total del PIB, la industria 29,1%, y la agricultura 0,9%. Los principales bienes exportados de Alemania son vehículos, maquinarias, productos químicos, productos electrónicos, productos farmacéuticos, equipos de transporte, metales básicos, productos alimenticios, caucho y plásticos. 

La política socio-económica de Alemania se basa en el concepto de economía social de mercado.

Alemania es el primer país industrializado importante del mundo que se compromete a la transición energética renovable llamada Energiewende. Alemania es el principal productor de turbinas eólicas y tecnología de energía solar en el mundo. Más de 1,5 millones de plantas de generación de energía renovable se han instalado en Alemania durante los últimos 25 años. Las energías renovables producen en la actualidad más del 27% de la electricidad total que se consume en Alemania.

El 99% de todas las empresas alemanas pertenecen a las denominadas Mittelstand, pequeñas y medianas empresas de propiedad familiar. De las 500 empresas que cotizan en bolsa más grandes del mundo, 50 tienen su sede en Alemania. Por capitalización de mercado, 20 empresas con sede en Alemania están en el Fortune Global 500 como Volkswagen, Allianz, Daimler, BMW, Siemens, BASF, Munich Re, E.ON, Bayer, y RWE.

Alemania es el mayor productor de lignito en el mundo. Alemania también es rica en madera, hierro, potasa, sal, uranio, níquel, cobre y gas natural. La energía en Alemania se obtienen principalmente por los combustibles fósiles, seguida de la energía nuclear, y por las energías renovables como la biomasa (madera y biocombustibles), eólica, hidráulica y solar.

Alemania es la ubicación más importante para las ferias comerciales del mundo. Alrededor de dos tercios de las ferias más importantes del mundo se llevan a cabo en Alemania. Las mayores ferias anuales y congresos internacionales se llevan a cabo en varias ciudades alemanas, como Hannover, Munich, Frankfurt y Berlín.

Alemania es el único país entre los cinco principales exportadores de armas que no es miembro permanente del Consejo de Seguridad de las Naciones Unidas.

La Revolución Industrial en Alemania llegó casi un siglo después más tarde de lo que lo hizo en Gran Bretaña, Francia y Bélgica, ya que Alemania se convirtió en un país unificado en el siglo XIX.

El establecimiento del Zollverein (unión aduanera alemana) y la creación de sistemas ferroviarios fueron los principales impulsores de la revolución industrial y de la unión política. En 1834, se eliminaron las barreras arancelarias entre los estados alemanes. En 1835, el primer ferrocarril alemán fue construido uniendo Dresde y Leipzig, y tuvo tanto éxito que la década de 1840 se vivió una "fiebre por los trenes" en todos los estados alemanes. Con el tiempo, otros estados alemanes se unieron a la unión aduanera y comenzaron a vincular sus sistemas de ferrocarriles, que comenzaron a conectar todos los rincones de Alemania. Con la creación de un sistema ferroviario en toda Alemania en la década de 1840 se intensificó el desarrollo económico que abrió nuevos mercados para los productos locales, se incrementó la demanda de ingenieros, arquitectos y operarios calificados y estimuló las inversiones en el carbón y el hierro..
Con la derrota de la Francia napoleónica en 1870 y la creación del Imperio Alemán en 1871 la industrialización se estimuló aún más. La reacción a las conquistas de Napoleón de los estados alemanes durante la época de la Revolución Francesa produjo importantes reformas institucionales, incluyendo la supresión de las restricciones feudales sobre la venta de grandes latifundios, la reducción del poder de los gremios en las ciudades, y la introducción de una nueva ley comercial más eficiente. No obstante, las decisiones políticas sobre la economía del Imperio Alemán seguían en gran parte controlados por una coalición de "centeno y hierro", es decir los terratenientes Junker del este y la industria pesada del oeste.

En el año 1900, Alemania era líder mundial en la industrialización. Entre 1895 y 1907, el número de trabajadores empleados en la construcción de maquinaria se duplicó de medio millón a más de un millón. Alemania también fue testigo de un crecimiento demográfico sin precedentes pasando de 35 millones de habitantes en 1850 a 67.000.000 en 1913. El rápido avance hacia la madurez industrial condujo a un cambio drástico en la situación económica de Alemania, de ser un importador de tecnología para ser un gran exportador de productos terminados. En 1913, Alemania llegó a dominar todos los mercados europeos y en 1914, se convirtió en uno de los tres mayores exportadores del mundo.

Los nazis llegaron al poder, mientras que el desempleo era muy alto, pero se logró el pleno empleo más tarde gracias a los programas públicos masivos como el Reichsbahn, Reichspost o Reichsautobahn.

Las políticas económicas y fiscales expansivas tras la crisis financiera de 1931 (como Alemania estaba fuera del patrón oro) fueron aconsejadas por el Ministro de Economía no-nazi, Hjalmar Schacht, que en 1933 se convirtió en el presidente del banco central. Hjalmar Schacht abandonó el puesto en 1938 y fue reemplazado por Hermann Göring.

Las políticas comerciales del Tercer Reich estaban encaminadas a la autosuficiencia, pero con la falta de materias primas, Alemania tendrían que mantener los vínculos comerciales, pero en las preferencias bilaterales, los controles de divisas, cuotas de importación y subvenciones a la exportación en virtud de lo que se llamó el "Nuevo Plan" (Plan de Neuer) de 19 de septiembre 1934. El "Plan Nuevo" se basaba en el comercio con los países menos desarrollados que cambiarían las materias primas para los productos industriales alemanes. Esta política se conoce como la política Grosswirtschaftsraum ("mayor área económica").

Finalmente, el partido nazi desarrolló fuertes relaciones con las grandes empresas y los sindicatos, abolidos en 1933 con el fin de formar el Servicio Nacional del Trabajo (RAD) y el Frente Alemán del Trabajo (DAF) para ajustar las horas de trabajo.

Con la sustitución del Reichsmark por el Marco alemán como moneda de curso legal, se vivió un período duradero de baja inflación y rápido crecimiento industrial supervisado por el gobierno encabezado por el canciller Konrad Adenauer y su ministro de Economía, Ludwig Erhard, levantando la Alemania Occidental de la total devastación de la guerra para convertirse en una de las naciones más desarrolladas en la Europa moderna.

Contrariamente a la creencia popular, el Plan Marshall se amplió para incluir también a la Alemania Occidental después de darse cuenta de que la supresión de la economía alemana occidental estaba frenando la recuperación del resto de Europa. La cuantía de la ayuda monetaria (que era en forma de préstamos) recibidas por Alemania a través del Plan Marshall (alrededor de 1.65 mil millones de dólares en total) fue en la medida eclipsado por el importe que los alemanes tuvieron que pagar por las reparaciones de guerra y por que los altos cargos de los Aliados hicieron a los alemanes pagar alrededor de 2400 millones de dólares al año. 

En 1953 se decidió que Alemania debía pagar 1.1 mil millones de dólares de la ayuda que había recibido. El último reembolso se hizo en junio de 1971. Es discutible, sin embargo, que la recuperación habría sido posible sin el impulso económico inicial, así como la modernización de la infraestructura proporcionada por el plan de recuperación económica.

Además de estos factores, el trabajo duro, largas horas de trabajo a pleno rendimientonen los años 1950, 1960 y principios de 1970 y mano de obra extra suministrados por miles de Gastarbeiter ("trabajadores invitados") ofrecieron una base vital para la recuperación económica.
Los esfuerzos de reconstrucción siguieron al final de la guerra, la industria y con ello la economía del país se desarrollaron rápidamente, dando lugar al fenómeno histórico conocido como el milagro económico alemán. La calidad de los productos alemanes nunca perdió su renombre a nivel mundial, y la nación se impuso en menos de una década como primera potencia económica de Europa, posición que conserva hoy en día.

A principios de la década de 1950 la Unión Soviética se había apoderado de las reparaciones de guerra en forma de productos agrícolas e industriales y exigió pagos de reparaciones más pesados. La Baja Silesia, que contenía las minas de carbón, y Stettin, un puerto natural prominente, se perdieron a favor de Polonia.

Las exportaciones de la Alemania Occidental superó 323 mil millones dólares en 1988. En el mismo año, Alemania Oriental exportó 30.7 mil millones de dólares en bienes, el 65% a otros estados comunistas. La Alemania Oriental tuvo desempleo cero.

En 1976, el crecimiento medio anual del PIB fue de aproximadamente 5,9%

La economía alemana prácticamente se estancó en el comienzo de la década de 2000. Las peores cifras de crecimiento se lograron en 2002 (+ 1,4%), en 2003 (+ 1,0%) y en 2005 (+ 1,4%). El desempleo también era alto. Debido a estos problemas, junto con envejecimiento de la población alemana, el sistema de bienestar estuvo bajo una presión considerable. Esto llevó al gobierno a llevar a cabo un amplio programa de reformas de austeridad, la Agenda 2010 , incluidas las reformas del mercado de trabajo conocidas como Hartz I - IV.

En la última parte de la primera década de 2000 la economía mundial experimentó un alto crecimiento, de la que Alemania como principal exportador también se benefició. Los efectos de las reformas Hartz lograron un alto crecimiento y disminución del desempleo, pero otros sostienen que provocaron una disminución masiva del nivel de vida, y que sus efectos son limitados y temporales. 

El PIB de Alemania se contrajo en el segundo y tercer trimestres de 2008, poniendo al país en una recesión técnica junto con la recesión europea y mundial. La producción industrial alemana cayó a 3,6% en septiembre. En enero de 2009, el gobierno alemán bajo Angela Merkel aprobó un plan de estímulo económico de 50 mil millones € para proteger a varios sectores de una recesión y un posterior aumento de la tasas de desempleo. Alemania salió de la recesión en el segundo y tercer trimestre de 2009, debido a las exportaciones (principalmente de fuera de la Zona Euro ) y a una demanda de consumo relativamente estable.

Alemania es un miembro fundador de la UE, el G-8 y el G-20, y fue el mayor exportador del mundo de 2003 a 2008. En 2011 se mantuvo como el tercer exportador y el tercer mayor importador. La mayor parte de las exportaciones del país son en ingeniería, especialmente maquinaria, automóviles, bienes químicos y metales. Alemania es un importante productor de turbinas eólicas y tecnología de energía solar. Numerosas ferias anuales y congresos se celebran en ciudades en toda Alemania. El 2011 fue un año récord para la economía alemana. Las empresas alemanas exportaron bienes por valor de más de 1 billón de €, la cifra más alta en la historia y el número de ocupados ha aumentado a 41,6 millones, la cifra más alta jamás registrada. 

Durante los años posteriores, la economía de Alemania siguió siendo más fuerte en relación con los países vecinos de la zona.

A partir de enero de 2015, la tasa de desempleo fue de 4,8 por ciento. 
A partir de diciembre de 2014, la tasa interanual del IPC fue del 0,6 por ciento.

La siguiente tabla muestra el crecimiento sin desestacionalizar del PIB durante el periodo 1992-2014

De las 500 mayores empresas cotizadas del mercado de valores del mundo medida por los ingresos en 2010, la lista Fortune Global 500, 37 tienen su sede en Alemania. 30 empresas con sede en Alemania están incluidas en el DAX, el índice bursátil alemán. Algunas de las marcas alemanas más conocidas son Mercedes-Benz, BMW, SAP, Siemens, Volkswagen, Adidas, Audi, Allianz, Porsche, Bayer, BASF, Bosch, y Nivea. 

Alemania es reconocida por sus especializadas pequeñas y medianas empresas. Alrededor de 1.000 de estas empresas son líderes del mercado mundial en su segmento y se etiquetan como campeones ocultos . 

De 1991 a 2010 se han producido 40 301 fusiones y adquisiciones, con una participación de empresas alemanas con un valor total de 2422 billones de Euros. Las mayores transacciones desde 1991 son: la adquisición de Mannesmann por parte de Vodafone con 204,8 billones de euros en 1999 y la fusión de Daimler-Benz con Chrysler para formar DaimlerChrysler en 1998 por valor de 36,3 billones de euros.
La lista incluye a las mayores empresas alemanas por ingresos en 2011:

Alemania, como federación, es un país policéntrico y no tiene un solo centro económico. La bolsa de valores se encuentra en Frankfurt am Main, la mayor compañía de medios de comunicación (Bertelsmann SE & Co. KGaA) tiene su sede en Gütersloh y los mayores fabricantes de automóviles están en Wolfsburg, Stuttgart y Múnich.

Alemania es un defensor de la integración económica y política europea más estrecha. Sus políticas comerciales son cada vez más determinadas por acuerdos entre los miembros de la Unión Europea (UE). Alemania introdujo la moneda común europea, el euro, el 1 de enero de 1999. Su política monetaria es fijada por el Banco Central Europeo en Frankfurt.

Los estados del sur ("Bundesländer"), especialmente Baviera, Baden-Württemberg y Hesse, son económicamente más fuerte que los estados del norte. Una de las regiones económicas tradicionalmente más fuertes (y al mismo tiempo más antiguas) es la región del Ruhr, en el oeste, entre Bonn y Dortmund. 27 de las 100 empresas más grandes del país se encuentran allí. En los últimos años, sin embargo, la zona, cuya economía se basa en los recursos naturales y la industria pesada, ha visto un aumento sustancial del desempleo (2010: 8,7%).

La economía de Baviera y Baden-Württemberg, los estados con el menor número de personas desempleadas (2010: 4,5%, 4,9%), por el contrario, se basa en productos de alto valor. Los sectores más importantes son los automóviles, electrónica, aeroespacial y la biomedicina, entre otros. Baden-Württemberg es un centro industrial, especialmente para el automóvil y la construcción de maquinaria de la industria y el hogar de marcas como Mercedes-Benz (Daimler), Porsche y Bosch.

Con la reunificación el 3 de octubre de 1990, Alemania comenzó la importante tarea de reconciliar los sistemas económicos de las dos ex-repúblicas. La Planificación económica intervencionista aseguró el desarrollo gradual en el este de Alemania hasta el nivel de la antigua Alemania Occidental, pero el nivel de vida y los ingresos anuales sigue siendo significativamente mayor en los estados alemanes occidentales. La modernización y la integración de la economía alemana del este sigue siendo un proceso a largo plazo programado hasta el año 2019, con transferencias anuales de oeste a este por valor de aproximadamente 80 mil millones de dólares. La tasa general de desempleo ha caído constantemente desde 2005 y alcanzó un mínimo de 20 años en 2012. En julio del 2014 comenzó legislar para introducir un salario mínimo por mandato federal que entraría en vigor el 1 de enero de 2015. 

Alemania es el país más rico de Europa, y el segundo más rico del mundo, después de Estados Unidos, en términos de la cantidad de hogares altos de riqueza por valor de más de 100 millones de dólares. La siguiente lista de los 10 de los alemanes multimillonarios se basa en una evaluación anual de la riqueza y los activos compilado y publicado por Forbes el 4 de marzo de 2014.


Wolfsburg es la ciudad en Alemania con el ingreso per cápita más alto del país con 128,000 $. La siguiente lista de las 10 de las ciudades alemanas con el más alto ingreso per cápita se basa en un estudio realizado por el Instituto de Investigación Económica de Colonia el 31 de julio de 2013


El suelo alemán es relativamente pobre en materias primas. Sólo lignito (carbón marrón) y potasa (Kalisalz) están disponibles en cantidades significativas. Sin embargo, la antigua empresa minera Wismut produjo un total de 230.400 toneladas de uranio entre 1947 y 1990 e hizo la Alemania Oriental el cuarto mayor productor de mineral de uranio en todo el mundo (el más grande en la esfera de control de la URSS) en el momento. Petróleo, gas natural y otros recursos están, en su mayor parte, importados de otros países.

La sal potasa se extrae en el centro del país (Baja Sajonia, Sajonia-Anhalt y Turingia). El productor más importante es K + S AG (anteriormente Kali und Salz AG).

Los depósitos de carbón bituminoso de Alemania fueron creados hace más de 300 millones de años a partir de los pantanos que se extendía desde el actual sur de Inglaterra, sobre la cuenca del Ruhr a Polonia. Los depósitos de lignito se desarrollan de manera similar, pero en un período posterior, hace unos 66 millones de años. Debido a que la madera no está todavía completamente transformada en carbón, el lignito contiene menos energía que el carbón bituminoso.

El lignito se extrae en las partes occidentales y orientales extremas del país, principalmente en Renania del Norte-Westfalia, Sajonia y Brandenburgo. Cantidades considerables se queman en las plantas de carbón cerca de las zonas mineras, para producir electricidad. El transporte de lignito en distancias lejanas no es económicamente viable, por lo tanto, las plantas se encuentran prácticamente al lado de los sitios de extracción. El carbón bituminoso se extrae en Renania del Norte-Westfalia y el Sarre. La mayoría de las centrales eléctricas que queman carbón bituminoso operan en material importado, por lo tanto, las plantas se encuentran no sólo cerca de los yacimientos mineros, sino en todo el país.

Alemania tiene una economía social de mercado que se caracteriza por un personal altamente calificado , una infraestructura desarrollada, un gran capital social, un bajo nivel de corrupción, y un alto nivel de innovación. Tiene la economía nacional más grande de Europa , la cuarta más grande por el PIB nominal en el mundo, y está clasificado quinto por PIB (PPA) en 2009.
El sector servicios aporta alrededor del 70% del total del PIB, la industria el 29,1%, y la agricultura 0,9%.

En 2010 la agricultura, la silvicultura y la minería representaron sólo el 0,9% del producto interno bruto de Alemania (PIB) y empleaba sólo el 2,4% de la población, por debajo de 4% de 1991. La agricultura es muy productiva, y Alemania es capaz de cubrir el 90% de sus necesidades nutricionales con la producción nacional. Alemania es el tercer mayor productor agrícola en la Unión Europea después de Francia e Italia. Los principales productos agrícolas de Alemania son patatas, trigo, cebada, remolacha de azúcar, frutas y coles.

A pesar del alto nivel de industrialización del país, casi un tercio de su territorio está cubierto por bosques. La industria forestal proporciona alrededor de dos tercios del consumo interno de la madera y sus productos, por lo que Alemania es un importador neto de estos artículos.

La industria y construcción representaron el 29% del producto interno bruto en 2008, y emplean el 29,7% de la fuerza laboral. Alemania destaca en la producción de automóviles, maquinaria, equipos eléctricos y productos químicos. Con la fabricación de 5,2 millones de vehículos en 2009, Alemania fue el cuarto mayor productor del mundo y el mayor exportador de automóviles. Las empresas automotrices alemanes gozan de una posición muy fuerte en el llamado segmento premium, con una cuota de mercado mundial combinado de aproximadamente 90%.

Las pequeñas empresas manufactureras medianas Mittelstand que se especializan en productos tecnológicamente avanzados y con frecuencia son de propiedad familiar y forman parte importante de la economía alemana. Se estima que alrededor de 1.500 empresas alemanas ocupan una posición alta en su respectivo segmento de mercado en todo el mundo.

En 2008 los servicios constituyeron el 69% del producto interno bruto (PIB), y el sector emplea al 67,5% de la fuerza laboral. Los subcomponentes son servicios financieros, el alquiler y actividades empresariales (30,5%); comercio, hoteles y restaurantes, y el transporte (18%); y otras actividades de servicios (21,7%).

Los mayores ferias anuales y congresos internacionales se llevan a cabo en varias ciudades alemanas, como Hannover, Frankfurt y Berlín.

Alemania es el tercer país más visitado de Europa, con un total de 369,6 millones de pernoctaciones durante el año 2010.

Alemania es el quinto mayor consumidor mundial de energía, y dos tercios de su energía primaria se importó en el año 2002. En el mismo año, Alemania fue el mayor consumidor de electricidad de Europa, por un total de 512,9 teravatios-hora. La política del Gobierno promueve la conservación de la energía y el desarrollo de energías renovables, como la solar, eólica, biomasa, hidroeléctrica y geotérmica. Como resultado de las medidas de ahorro energético, la eficiencia energética ha mejorado desde principios de la década de 1970. El Gobierno se ha fijado el objetivo de satisfacer las demandas de energía media del país a partir de fuentes renovables para el año 2050.

En 2000, el canciller Schröder y la industria de la energía nuclear acordaron eliminar gradualmente todas las centrales nucleares para el año 2021. La coalición conservadora bajo la canciller Merkel revirtieron esta decisión en enero de 2010 para mantener las plantas abiertas. El desastre nuclear de la planta nuclear japonesa de Fukushima en marzo de 2011 sin embargo, cambió el clima político fundamental: las centrales nucleares más antiguas han sido cerradas. Y una fase general a cabo hasta el año 2020 o 2022 es ahora probable. La energía renovable todavía sigue jugando un papel más modesto en el consumo de energía, aunque las industrias solares y eólicas alemanas desempeñan un papel de liderazgo en todo el mundo.

En 2009, el consumo total de energía de Alemania (no sólo la electricidad) provino de las siguientes fuentes: Petróleo 34,6%, el gas natural 21,7%, lignito 11,4%, el carbón bituminoso 11,1%, la energía nuclear 11,0%, y eólica 1,5% , Otros 9,0%.

Hay 3 principales puntos de entrada de los oleoductos: en el noreste (el oleoducto Druzhba, procedentes de Gdańsk ), oeste (procedente de Rotterdam ) y sureste (procedentes de Nelahozeves). Los oleoductos de Alemania no constituyen una red adecuada, ya veces sólo se conectan dos lugares diferentes.

La red de gas natural, por otro lado, es densa y bien comunicada. Los Gasoductos proviene principalmente de Rusia, los Países Bajos y el Reino Unido. Aunque las importaciones de gas de Rusia han sido históricamente confiable, incluso durante la guerra fría, los conflictos recientes de los precios entre Gazprom y las antiguas repúblicas soviéticas, como Ucrania, han afectado también a Alemania. Como resultado, la gran importancia política se coloca en la construcción del gasoducto Nord Stream, que va desde Vyborg en Rusia a lo largo del mar Báltico a Greifswald en Alemania.

Con su posición central en Europa, Alemania es un importante centro de transporte. Esto se refleja en sus densas y modernas redes de transporte. La extensa autopista (Autobahn) que ocupa la tercera más grande a nivel mundial por su longitud total y cuenta con una falta de límites de velocidad manta en la mayoría de las rutas.

Alemania ha establecido una red policéntrica de trenes de alta velocidad . El InterCityExpress o ICE es la categoría de servicio más avanzado de la Deutsche Bahn y sirve las principales ciudades alemanas, así como destinos en países vecinos. La velocidad máxima del tren varía entre 200 KM/h 320 kmh. Las conexiones se ofrecen en cada 30 minutos, cada hora, o dos-hora.

Los mayores aeropuertos alemanes son el aeropuerto internacional de Frankfurt y el aeropuerto internacional de Múnich, ambos son centros mundiales de Lufthansa. Otros aeropuertos importantes son Berlín Tegel, Berlín-Schönefeld, Düsseldorf, Hamburgo, Hannover, Colonia-Bonn, Leipzig/Halle y en el futuro Aeropuerto Internacional de Berlín Brandeburgo.

Los logros de Alemania en ciencias han sido importantes, y la investigación y desarrollo forman parte integrante de la economía. 

Alemania es también uno de los países líderes en el desarrollo y uso de tecnologías verdes. Las empresas especializadas en tecnología verde tienen una facturación estimada de 200 millones €. El socio alemán para la ingeniería, la ciencia y la investigación es eminentemente respetable.

Los mercados líderes de la industria de la tecnología verde de Alemania son la generación de energía, la movilidad sostenible, la eficiencia de los materiales, eficiencia energética, gestión de residuos y el reciclaje , sostenible la gestión del agua .

Con respecto a las patentes triádicas Alemania ocupa el tercer lugar después de los EE.UU. y Japón. Con más de 26.500 registros de patentes presentadas a la Oficina Europea de Patentes, Alemania es la nación líder en Europa. Siemens, Bosch y BASF, con casi 5.000 registros de patentes entre ellos en 2008, se encuentran entre los Top 5 de los más de 35.000 empresas que registren patentes . Junto con los EE.UU. y Japón, con respecto a las patentes de nano, bio y las nuevas tecnologías Alemania es uno de los países más activos del mundo. Con alrededor de un tercio de las patentes triádicas Alemania está a la cabeza mundial en el campo de la reducción de emisiones de vehículos

Como motor de la Unión Europea, Alemania dispone de la economía más potente de la Eurozona, y sus indicadores macroeconómicos son una referencia indiscutible a nivel internacional, mostrando desde hace décadas unos claros índices de modernidad y fortaleza. Alemania es el cuarto país del mundo por PIB (recientemente superado por China) y el quinto país según el Índice de Competitividad Global calculado por el Foro Económico Mundial. Además, Alemania ocupa el puesto nº 12 a nivel mundial en el ranking de los países con mayor renta per cápita. No obstante, de Alemania cabe destacar otros parámetros como la gran cantidad de superficie forestal conservada (a pesar de su elevada densidad de población) y que, según datos de Eurostat, es el país con más camas en hospitales. En la siguiente tabla se puede comprobar el contexto socio-económico de Alemania a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Se presentan a continuación las mercancías de mayor peso en las importaciones de Alemania para el período 2010-hasta abril de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Alemania para el periodo 2010-hasta abril de 2015.La mayoría de sus importadores están en Europa salvo Estados Unidos y China. Las cifras expresadas son en dólares estadounidenses valor FOB.




</doc>
<doc id="15420" url="https://es.wikipedia.org/wiki?curid=15420" title="Economía de Italia">
Economía de Italia



</doc>
<doc id="15421" url="https://es.wikipedia.org/wiki?curid=15421" title="Ciberpunk">
Ciberpunk

El ciberpunk (del original en inglés cyberpunk y cuya pronunciación es /'saɪbəʳpʌŋk/) es un subgénero de la ciencia ficción, conocido por reflejar visiones distópicas del futuro en las cuales se combinan la tecnología avanzada con un bajo nivel de vida. El ciberpunk recibe su nombre de la adjunción del prefijo "ciber-" (relacionado con redes informáticas) al vocablo punk (en referencia a su carácter rebelde). En él, la ciencia (y sobre todo la informática y la cibernética) suele generar o interaccionar con algún tipo de cambio de paradigma social o cultural.

En las tramas del género ciberpunk, el argumento suele estar centrado en los hipotéticos conflictos entre "hackers", inteligencias artificiales y megacorporaciones, todo ello situado en un futuro cercano del planeta tierra. Este contexto se opone al de muchas historias clásicas de la ciencia fición, como "Fundación" de Isaac Asimov o "Dune" de Frank Herbert, que generalmente se sitúan en un futuro distante y en planetas y estrellas extrasolares. Las distopías posindustriales del ciberpunk, sin embargo, acostumbran a estar marcadas por un desarrollo cultural extraordinario, y por la subversión en el uso de las tecnologías, que son explotadas en ámbitos nunca anticipados por sus creadores. Según las palabras de William Gibson en la novela "Quemando cromo", "la calle encuentra sus propios usos para las cosas". La atmósfera del género también se inspira en el cine negro, y reutiliza técnicas comunes en las novelas policíacas. Entre sus primeros escritores notables se pueden contar William Gibson, Bruce Sterling, Pat Cadigan, Rudy Rucker y John Shirley. El término ciberpunk fue acuñado en los años 1980, y aún es utilizado hoy en día.

A diferencia de la ciencia ficción de la Nueva ola, que importó en su seno las técnicas y las preocupaciones estilísticas preexistentes en la literatura y la cultura, el origen primigenio del ciberpunk se sitúa en la ciencia ficción, antes de que aumentara su popularidad. A comienzos y a mediados de los años ochenta, el ciberpunk se convirtió en uno de los temas de modas de los círculos académicos, donde comenzó a ser objeto de investigación por parte del postmodernismo. Durante ese mismo período, el cine de Hollywood tomó interés por el género, incorporándolo a sus producciones de ciencia ficción. En las películas más influyentes del ciberpunk, como "Blade Runner", "Terminator", "Desafío Total" y "Akira", se puede apreciar la continuación de los temas y estilos más importantes del género. Los videojuegos, los juegos de mesa y los juegos de rol ciberpunk, tales como "Shadowrun" o el apropiadamente nombrado "Cyberpunk 2020", ofrecen a menudo guiones fuertemente influenciados por las películas y la literatura ciberpunk. A partir de los años 1990, ciertas tendencias en los campos de la moda y de la música fueron calificadas como ciberpunk.

En el mismo periodo en el que escritores muy diversos comenzaron a trabajar con conceptos del ciberpunk, nuevos sub-géneros emergieron, centrándose en la tecnología y en sus efectos sociales de una manera diferente. Entre sus ejemplos están el steampunk, iniciado por Tim Powers, Kevin Wayne Jeter y James Blaylock, y el biopunk (o alternativamente ribofunk), en el que destaca Paul Di Filippo. Asimismo, algunas personas consideran novelas como "La era del diamante" de Neal Stephenson como el inicio de la categoría postciberpunk.

Los escritores ciberpunk tienden a emplear elementos de la novela policíaca dura, del cine negro y de la prosa postmoderna para describir las características del lado clandestino de sus sociedades dominadas por la tecnología. Su visión de un futuro imperfecto puede ser vista como la antítesis del porvenir utópico que se anunciaba en las historias de la "Edad de Oro de la ciencia ficción", populares en los años 1940 y 1950.)

En la escritura ciberpunk la mayor parte de la acción ocurre en línea, en el ciberespacio; atenuando cualquier frontera entre la realidad y la realidad virtual. Un tropo típico en estas obras es la conexión directa entre el cerebro humano y un sistema de cómputo. El mundo dominado por los sistemas informáticos es representado como un lugar oscuro, siniestro, donde las redes de comunicación controlan todos los aspectos de la vida. Las corporaciones multinacionales gigantes han tomado el papel de los gobiernos como centros del poder político, económico y militar. La lucha entre un personaje marginalizado y un sistema totalitario es un tema común en la ciencia ficción (por ejemplo, la novela "1984" de George Orwell) y particularmente en el ciberpunk, aunque en la ciencia ficción convencional los sistemas totalitarios tienden a ser estériles, ordenados y controlados por el Estado.

Los protagonistas de la escritura ciberpunk generalmente son hackers, quienes son moldeados frecuentemente en la idea de héroe solitario que combate la injusticia: vaqueros, rōnin, etc. A menudo son individuos marginalizados que se encuentran envueltos en situaciones extraordinarias, más que científicos brillantes o capitanes estrella buscando intencionalmente avances o aventura, y no siempre son verdaderos “héroes”.

Uno de los personajes prototípicos del género ciberpunk es Case, de la novela "Neuromante" de William Gibson. Case es un "vaquero de la consola", un hacker brillante, que traiciona a sus socios del crimen organizado. Robado su talento con una lesión que lo deja lisiado; infligida en venganza por sus socios criminales, Case recibe una inesperada única oportunidad en la vida de ser curado con asistencia médica experta; pero a cambio de su participación en otra empresa criminal con un nuevo equipo. Como Case muchos protagonistas ciberpunk son manipulados, puestos en situaciones donde tienen poca o ninguna opción, y aunque ellos pueden verse en esto, no necesariamente llegan a estar más lejos de lo que previamente estaban. Estos anti-héroes –“criminales, parias, visionarios, desertores e inadaptados”– no experimentan el “camino de héroe” de Campbell como un protagonista de la epopeya homérica o una novela de Alexandre Dumas.
Ellos en cambio, traen a la memoria el investigador privado de la novela policíaca, que podría solucionar los casos más complejos, pero nunca recibir una recompensa justa. Este énfasis sobre los inadaptados y descontentos -que Thomas Pynchon llama el ""pretérito"" y Frank Zappa el ""olvido de la Gran Sociedad""- es el componente "punk" del ciberpunk.

El ciberpunk se sitúa como un defensor de la libre circulación de la información. Decididamente opuesto a los derechos de propiedad intelectual. Se trata de un acérrimo defensor de las tecnologías de cifrado para garantizar la privacidad así como del dinero electrónico y de todas las modernas tecnologías digitales, en general.

La literatura ciberpunk suele servir frecuentemente como una metáfora de las preocupaciones actuales sobre los efectos y el control de las corporaciones sobre las personas, la corrupción de los gobiernos, la enajenación y la vigilancia tecnológica. El ciberpunk puede ser entendido como una inquietud a los lectores y un llamado a la acción. Esto a menudo expresa el sentido de rebelión, sugiriendo que uno podría describirlo como un tipo de ciencia ficción contracultural. En las palabras del autor y crítico David Brin,

Las historias ciberpunk se han considerado a veces como pronósticos ficticios de la evolución del Internet. El mundo virtual conocido actualmente como Internet, aparece a menudo bajo varios nombres, incluyendo "ciberespacio", "la Red", "el Metaverso" o "la Matriz". En este contexto es importante observar que las descripciones más tempranas de una red global de comunicaciones aparecieron mucho antes de que la World Wide Web se incorporara al conocimiento popular, aunque no antes de que los escritores tradicionales de la ciencia ficción tales como Arthur Charles Clarke y en algunos comentaristas sociales como James Burke comenzaran a predecir que tales redes eventualmente se formarían.

El ciberpunk es también un movimiento contracultural. Como tal, tiene su origen en una tradición libertaria y una profunda desconfianza en el uso de las nuevas tecnologías que, si bien pueden proporcionar mayores niveles de comodidad y progreso, también pueden alienar al individuo y ayudar a controlarlo.

Del mismo modo que la fuerza estética del ciberpunk ha influido en otros géneros más allá de la ciencia ficción, la fuerza de sus futuros, claramente distópicos, ha influido en la sociedad modificando nuestro punto de vista acerca de las nuevas tecnologías. Así, siendo una de las funciones de la ciencia ficción alertar a la sociedad de los peligros de sus actitudes y de sus creaciones, el ciberpunk ha sido uno de los movimientos más exitosos dentro del género.

Sin embargo, el ciberpunk no es un movimiento reaccionario. No se posiciona contra la tecnología, sino contra determinados usos de la misma. Así, del mismo modo que los poderosos se valen de la tecnología para mantener su control sobre las masas, cualquier acción en contra de ellos deberá también contar con el uso de tecnologías sofisticadas.

Además de posicionarse contra las implicaciones negativas de la ciencia y la tecnología, el ciberpunk muestra situaciones que se producen en un escenario económico controlado por organizaciones cada vez más poderosas e influyentes, a la vez que alejadas de la ciudadanía. Se denuncia así una fractura social en la que los ricos y poderosos se valen de su dinero y poder para manipular a la sociedad mediante el control de la información.

Algo a tener en cuenta al analizar el ciberpunk como corriente social es que sus autores no se posicionan contra algo que será, sino contra algo que está siendo. Es esta cercanía de los contenidos lo que ha hecho este movimiento tan inquietante.

El editor de ciencia ficción Gartner Dozois es generalmente conocido como la persona que popularizó el uso del término "ciberpunk" como un tipo de literatura. El escritor Bruce Bethke acuñó el término en 1980 para su historia corta "Cyberpunk", aunque la historia no se publicó hasta noviembre de 1983, en "Amazing Stories", Volumen 57, Número 4.

El término fue rápidamente acogido como una etiqueta aplicada a los trabajos de William Gibson, Bruce Sterling, John Shirley, Rudy Rucker, Michael Swanwick, Pat Cadigan, Lewis Shiner, Richard Kadrey y otros. De éstos, Sterling inició el movimiento, liderando la ideología, gracias a su fanzine "Cheap Truth" ("Verdad barata"). (Véase también los artículos de John Shirley sobre Sterling y Rucker).

Los elementos del ciberpunk están presentes en "Los Cantos de Hyperion" de Dan Simmons; el planeta Lusus posee muchas características del mundo distópico de Neuromante ("Neuromancer") y los niveles cibernéticos de la vida y la existencia de inteligencia artificial tienen obvias influencias de los trabajos de Gibson.

William Gibson con su novela "Neuromancer", es probablemente el más famoso escritor conectado con el término. El estilo enfático, la fascinación con la superficie, la «apariencia y sensación» de futuro y la atmósfera ya tradicional en la ciencia ficción son vistos como la ruptura y a veces como «el trabajo arquetípico del ciberpunk». Neuromancer fue galardonada con los premios Hugo, Nébula y Philip K. Dick. De acuerdo con el archivo de la jerga "La total ignorancia de Gibson acerca de computadoras y la cultura hacker actual le permitieron especular sobre el rol de las computadoras y hackers en el futuro de modo que ambas son desde entonces irritantemente ingenuas y tremendamente estimulantes".

Tempranamente, el ciberpunk fue aclamado como una ruptura radical de los estándares de la ciencia ficción y una nueva manifestación de vitalidad, sin embargo poco tiempo después surgieron muchos críticos para cambiar su estatus a «movimiento revolucionario». Estos críticos dicen que la ciencia ficción de la "Nueva ola" de los años 60 era mucho más innovadora en cuanto a estilo y técnicas narrativas. Además mientras el narrador de "Neuromancer" pudo haber tenido una “voz” inusual para la ciencia ficción, se pueden encontrar muchos otros ejemplos anteriores a este: la voz narrativa de Gibson, por ejemplo se asemeja a la del actualísimo Raymond Chandler en su novela El Gran Sueño (1939). Otros consideran que los rasgos considerados únicos del ciberpunk, de hecho se pueden encontrar en trabajos más antiguos de otros escritores, de los que podemos citar James Graham Ballard, Philip K. Dick, Harlan Ellison, Stanisław Lem, Samuel R. Delany e incluso William Burroughs. Por ejemplo los trabajos de Philip K. Dick contienen temas recurrentes de decaimiento social, inteligencia artificial, paranoia y líneas ocultas entre la realidad y una especie de realidad virtual; la película ciberpunk "Blade Runner" está basada en uno de estos libros. Humanos vinculados con máquinas son el cimiento de la novela "Wolfbane" de Frederik Pohl y Cyril M. Kornbluth (1959) y "Criaturas de luz y oscuridad" de Roger Zelazny (1986).

En 1994 el académico Brian Stonehill insinuó que la novela "El arco iris de gravedad" de Thomas Pynchon «no solo insulta, sino plagia a los precursores del ciberespacio».
Otros importantes predecesores incluyen a dos novelas muy celebradas de Alfred Bester, "El hombre demolido" y "Las estrellas mi destino", así como la novela de Vernor Vinge "Nombres verdaderos". En esta década el escritor brasileño Fausto Fawcett publica sus primeras novelas.

El escritor de ciencia ficción David Brin describe el ciberpunk como «(...) la campaña de promoción gratuita más fina emprendida a nombre de la ciencia ficción». Esto pudo no haber atraído a los «verdaderos "punks"», pero atrajo a muchos nuevos lectores y dispuso la clase de movimiento que la literatura postmodernista buscaba comentar (una ilustración de esto es el "Manifiesto Cyborg" de Donna Haraway, un intento de construir un «mito político» usando cyborgs como metáforas de la «realidad social» contemporánea). El ciberpunk hizo más atractiva la ciencia ficción para los académicos, argumenta Brin. Además hizo a la ciencia ficción más lucrativa para Hollywood y las artes visuales en general. Aún cuando su «importancia retórica y quejas de persecución» por parte de los aficionados al ciberpunk era irritante en el peor y chistoso en el mejor de los casos, Brin declara que «Los rebeldes pusieron las cosas patas arriba; estamos en deuda con ellos [...]». Pero, el pregunta "¿Fueron ellos originales?".

El futuro ciberpunk inspiró a muchos escritores profesionales que no se encontraban entre los ciberpunk "originales" al incorporar ideas ciberpunk en sus propios trabajos, tales como Walter Jon Williams con "Hardwired" y "Voz del torbellino", y George Alec Effinger con su obra "Cuando la gravedad falla". Mientras nuevos escritores y artistas empezaron a experimentar con ideas ciberpunk, nuevas variedades de ficción emergieron, a veces manejando el mismo nivel de crítica que las historias del ciberpunk original.Lawrence Person escribió en un ensayo publicado en el foro de Internet Slashdot:
El ensayo de Person aboga usando el término "postciberpunk" para etiquetar los nuevos trabajos que estos escritores producen. En esta visión, las historias típicas del postciberpunk continúan enfocándose en una atmósfera de datos ubicua de información computarizada y el aumento cibernético en el cuerpo humano, pero sin asumir la distopía. Buenos ejemplos pueden ser "La era del diamante" de Neal Stephenson o "Transmetropolitan" de Warren Ellis y Darick Robertson. Como todas las categorías incluidas en la ciencia ficción, los límites del postciberpunk son susceptibles de cambiar o ser mal definidos. Para complicar el asunto, hay un mercado continuo de novelas ciberpunk "puras" fuertemente influenciadas por el trabajo temprano de Gibson, como "Carbono alterado" de Richard Morgan.

En 1965, Jean-Luc Godard estrena Alphaville, un film de ciencia-ficción con elementos de novelas de ese mismo género, en la cual aparece un futuro distópico propio del ciberpunk, basado, probablemente en el que aparece en "Un mundo feliz" de Aldous Huxley.

La película "Blade Runner" (1982), adaptada del libro" ¿Sueñan los androides con ovejas eléctricas?" de Philip Kindred Dick, se ubica en una distopía futura en la cual seres manufacturados llamados "replicantes" (en la novela, "andrillos") son usados como esclavos en colonias del espacio, y en la Tierra presa de varios cazadores de recompensas, quienes se encargan de "retirarlos" (matarlos). Aunque "Blade Runner" no fue un éxito en su lanzamiento, encontró un gran nicho en el mercado de alquiler de películas. Puesto que la película omite los elementos religiosos y míticos de la novela de Dick (por ejemplo, cajas de empatía y Wilbur Mercer), cae más estrictamente dentro del género ciberpunk que la novela. William Gibson revelaría después que la primera vez que vio la película, se había sorprendido mucho de cómo la apariencia de esta película era similar a su visión cuando estaba trabajando en "Neuromancer". Aunque no fue hasta principios de los noventa cuando se consagró como un género de denominación popular, gracias a numerosas películas, entre las que destacan "Hardware" o "Death Machine".

Según lo mencionado anteriormente, la serie de televisión "Max Headroom" también expandió el ciberpunk, quizá con un éxito más popular que los primeros trabajos escritos del género.

El número de películas de este género, o por lo menos de uno de sus elementos ha crecido constantemente desde "Blade Runner". Varios de los trabajos de Philip Kindred Dick se han adaptado a la pantalla gigante, con elementos ciberpunk llegando a ser típicamente dominantes, los ejemplos incluyen "Screamers" (1996), "Minority Report" (2002), "Paycheck" (2003) y "Una mirada a la oscuridad" (2006).

Pero desafortunadamente para el argumento original, la película "Johnny Mnemonic" (1995) fue un fracaso, comercialmente y para la crítica. Los fans de Gibson reclaman que el argumento se desvió sustancialmente del trabajo original, aún cuando Gibson mismo escribió el guion final.

El director Darren Aronofsky ubica su opera prima "π" (1998) en una Nueva York actual, pero construyó el libreto con influencias de la estética ciberpunk. De acuerdo con comentarios del DVD, él hizo esta producción usando deliberadamente máquinas antiguas (como el diskette de 5-¼ de pulgada), imitando el estilo tecnológico de "Brazil" (1985), para crear una "sensación" ciberpunk. Aronofsky describe el Chinatown, donde se ubica la película, como "el vecindario ciberpunk después de Nueva York".

Se encuentran otras películas prácticamente coetáneas a "Blade Runner", que también reflejan este mundo cyberpunk, como por ejemplo, "Cielo líquido" (1982), pues tiene un argumento de ciencia-ficción urbanita con protagonistas bastante marginales, también merece mención la película "Max Headroom" (1985), ya que en una época como los años 80, un argumento como el de esta película era muy llamativo, en ella, una inteligencia artificial tenía el papel protagonista, se convertiría, además, en una serie televisiva. Por otro lado, también encontramos la película "Días extraños (1995)" tratando un apocalipsis de realidad virtual en 1999, aunque fue un filme con muy poca acogida, lo mismo que ocurrió con la ya comentada película "Johnny Mnemonic." 

La serie "Robocop" se ajusta más al futuro cercano donde hay por lo menos una corporación, "Omni Productos de Consumo", que es una empresa todopoderosa en la ciudad de Detroit. "Hasta el fin del mundo" (1991) muestra otro ejemplo donde el ciberpunk es el tema de fondo, y una estrategia de argumento, para verla de otro modo y dirigir el personaje de la historia. "Gattaca" (1997) dirigida por Andrew Niccol es un filme negro futurista cuyo empapado modo distópico provee un buen ejemplo del biopunk.

La serie "The Matrix", que inicio en 1999 con "The Matrix" (conformada también por "The Matrix Reloaded", "The Matrix Revolutions" y "The Animatrix") usan una amplia variedad de elementos ciberpunk.

El estilo ciberpunk y el diseño futurista han encontrado una gran acogida (y vasta exposición) en el anime, incluyendo "Akira" (primer referente anime del género) es un manga en el que también se basa la película homónima de animación japonesa. Ambas obras tuvieron un reconocimiento instantáneo como clásicos dentro de sus respectivos géneros. El manga, de más de dos mil páginas, fue escrito y dibujado por Katsuhiro Otomo entre los años 1982 y 1993 obteniendo un éxito significativo en Japón y en el resto del mundo. Premiada con el Premio Kōdansha al mejor manga en 1984 en la categoría general (一般部門). El largometraje homónimo se separa de la línea argumental del manga por causas claras: la película fue estrenada cinco años antes de la conclusión del manga. Akira se ambienta en la ciudad futurista de Neo-Tokio, representada con profundo detalle en la película de animación (se invirtieron cerca de siete millones de dólares sólo en los decorados). Otros animes en abordar esta temática son: Ghost in the Shell, este anime es uno de los que más importancia presenta dentro de este subgénero, presentando conexiones con el cine negro y reflexiones bastante pesimistas sobre un mundo donde distinguir máquina de humano es cada vez más difícil, al lado de este potencial encontramos otras obras como Cyber City Oedo 808, Battle Angel Alita, Bubblegum Crisis, Armitage III, Armitage Dual Matrix, Silent Möbius, Serial Experiments Lain, Texhnolyze, Appleseed, Ergo Proxy, Psycho-Pass, siendo esta última la que más ha influenciado la juventud contemporánea japonesa que vive con una relativa cercanía a la ambientación de la serie, que muestra un Japón con tecnologías de punta y que advierte sobre los riesgos que puede causar esto ante una posible perdida de identidad humana.

El anime también ha proporcionado ejemplos de los subgéneros steampunk, como es el caso del manga de CLAMP Clover, también en muchos de los trabajos de Hayao Miyazaki, pero también notablemente en "Last Exile" (2003), creados por el estudio Gonzo y dirigido por Koichi Chigira, que ofrece una curiosa mezcla de sociedad victoriana y batallas futuristas entre naves aéreas.

Este subgénero también sigue plasmándose en las películas y series de la actualidad, un ejemplo de ello es la película "Origen" del año 2010 dirigida por Christopher Nolan e interpretada por Leonardo Di Caprio, se puede relacionar con este subgénero ya que este versátil director sin tener que tratar la socorrida realidad virtual, hace entrar al espectador en una realidad lejana a la nuestra haciendo que el protagonista junto con sus secuaces se introduzcan en sueños ajenos, algo que encaja con los patrones de este subgénero a tratar.

También puede destacarse la película "Dredd" del año 2012, dirigida por Pete Travis, ya que a pesar del poco éxito comercial, es un buen ejemplo de estas claves del ciberpunk establecidas, pues se representa un futuro violento y distópico.

El término "música ciberpunk" puede referirse a dos categorías algo superpuestas. Primero puede denotar la amplia gama de los trabajos musicales que las películas ciberpunk utilizan como banda sonora. Estos trabajos varían en género desde la música clásica y el jazz –usada en "Blade Runner", y que por otra parte evoca el ambiente del cine negro- hasta el noise y la música electrónica. Típicamente las películas hacen uso de la electrónica, electronic body music, música industrial, noise, futurepop, rock alternativo, rock gótico, Synthpop, retrowave, vaporwave e intelligent dance music, derivados y fusiones para crear la sensación "apropiada". El mismo principio aplica a los videojuegos. Por supuesto, mientras los trabajos escritos no están asociados a bandas sonoras con tanta frecuencia como las películas, la alusión a trabajos musicales es usada para el mismo efecto. Por ejemplo la novela gráfica "Kling Klang Klatch" (1992), una fantasía oscura sobre un mundo de juguetes vivos, donde un oso de peluche amargado tiene una adicción hacia el azúcar y una predilección por el jazz.

La "música ciberpunk" también describe los trabajos asociados con la tendencia de la moda que emergió del desarrollo de la ciencia ficción. El libro "Future Shock" de Alvin Toffler influyó tanto en los creadores del techno en Detroit a principios de los 80, como Juan Atkins y su grupo Cybotron, como a los pioneros europeos del sintetizador Kraftwerk, produciendo canciones de clara inspiración distópica. La banda candiense de thrash/punk/progressive metal Voivod fue una de las primeras en autodenominarse ciberpunk. En los 1990, la cultura popular comenzó a incluir un movimiento en la música y en la moda que llamaron también "ciberpunk" y que llegó a ser particularmente asociada con las subculturas rave y techno. Con el nuevo milenio llegó un nuevo movimiento de bandas industriales que hacían música de "portátil". Punks y okupas se armaron con equipo digital y fusionaron la tecnología con sonidos callejeros. La subcultura hacker documentada en lugares como el archivo de la jerga contempla este movimiento con sentimientos encontrados, desde los autoproclamados ciberpunks que están frecuentemente "inclinados" hacia el cuero negro y el cromo quienes hablan entusiasmados de tecnología en lugar de aprender o verse involucrados en esto. ("La actitud no sustituye a la capacidad", entrada del Archivo). Sin embargo estos autoproclamados ciberpunks al menos están "emocionados con las cosas correctas" y típicamente respetan a las personas que actualmente trabajan con esto de "la naturaleza hacker".

El español José María Ávalos Oliveros, en su tesis de master para la carrera de postproducción digital de la Universidad Politécnica de Valencia, llamada "Distopía musical: La música en el Cyberpunk" se sostiene que ningún compositor se amolda a unas reglas concretas para escribir o componer música ciberpunk. No hay un estilo preestablecido ni pautas a seguir. Cada músico aporta una novedad distinta, por lo general, en cada producción en la que hayan participado. También hay que tener en cuenta factores como la época en la que se compone la música, las canciones, en caso de haber, que se utilizan en la banda sonora junto al carácter comercial y la influencia que puede tener sobre otras producciones del género. 

Ciertos géneros musicales como el drum and bass fueron directamente influenciados por el ciberpunk, incluso generando un subgénero completo llamado neurofunk. Un claro ejemplo de la influencia ciberpunk en la música son la banda Sigue Sigue Sputnik y el video del tema de Duran Duran "Union of the Snake". El álbum de 1982 del grupo electrónico The Cassandra Complex, se llama "Cyber Punk". En la actualidad podemos decir que el género que representa a plenitud el espíritu ciberpunk es el Futurepop, de la mano de bandas como Mind.In.A.Box, VNV Nation, Rotersand, Covenant, Colony 5 y bandas de Synthpop como Neuroactive, Neuroticfish y Seabound. Estos grupos destacan por el intenso uso del Vocoder (sintetizador de voz) en sus canciones, ritmos bailables entre 120-140 bpm, letras futuristas, y melodías pegadizas que provoca un efecto adecuado a la atmosfera Cyberpunk

En Brasil destaca Fausto Fawcett, también escritor. Comenzó su carrera musical en 1986, por sugestión de uno de sus amigos de la facultad, el cineasta Cacá Diegues, y firmó con la Warner Music Group para lanzar su álbum debut, "Fausto Fawcett e os Robôs Efêmeros" (Fausto fawcett y los Robots Efímeros) al año siguiente. Descrito como una "obra conceptual sobre una Copacabana "Blade Runner"".

Los videojuegos usan frecuentemente el Ciberpunk como fuente de inspiración, algunos de estos como "Blade Runner" o "Enter the Matrix", están basados en películas del género, mientras que otros como "Deus Ex" y "System Shock", "Final Fantasy VII" , "Mega Man” o Snatcher son trabajos originales.Algunas franquicias multimedia entran al terreno de los videojuegos como el caso de Shadowrun o Ghost in the Shell, mientras que otras tienden a incluir ambiente y temas del género ciberpunk como un elemento más en torno a la construcción de su mundo y narrativa, como es el caso de la saga .Hack//, la trilogía de Xenosaga, algunos títulos de las franquicias Metal Gear y Megami Tensei, a la vez que novelas visuales como VA-11 Hall-A recurren al género como un medio tanto de homenaje como sátira a sus tropos narrativos. CD Projekt Red actualmente está desarrollando un título dedicado al género llamado "Cyberpunk 2077".

Existen varios juegos de rol titulados "Ciberpunk": por ejemplo "Ciberpunk 2013", "Cyberpunk 2020" y "Ciberpunk V.3" son las tres ediciones de un mismo juego, publicado por Talsorian Games, y existe también un suplemento para el sistema genérico "GURPS" ("GURPS Ciberpunk"), publicado por Steve Jackson Games.
"Ciberpunk 2020" fue diseñado con el argumento de los escritos de William Gibson en mente, y hasta cierto punto con su aprobación, diferente de la aproximación (quizá más creativa) hecha por la "FASA" en la producción del juego "Shadowrun". Ambos juegos se ambientan en un futuro cercano, en un mundo donde la cibernética es prominente.
"Netrunner" es un juego de cartas coleccionables introducido en 1996, basado en el juego de rol "Ciberpunk 2020"; fue lanzado junto a un popular juego de realidad alternativa en línea llamado "Webrunner", que permite a los jugadores ingresar al mainframe de una perversa organización futurista. También Iron Crown Enterprises lanzó un juego de rol, titulado "Cyberspace", ahora ya descatalogado.

En 1990, en una inusual unión entre la realidad y la ficción del ciberpunk, el Servicio Secreto de los Estados Unidos llegó a las instalaciones de Steve Jackson Games y confiscaron todas sus computadoras bajo la "Operación Sundevil", que fue un masivo golpe a los hackers y crackers de computadoras. Esto se debió a que – supuestamente – el libro de "GURPS Ciberpunk" podría ser usado para preparar crímenes por ordenador. Esta, en efecto, no fue la principal razón para la redada, pero tras el evento ya fue muy tarde para corregir la impresión del público.
Más tarde "Steve Jackson Games" ganó el juicio contra el Servicio Secreto, ayudados por la Electronic Frontier Foundation, de mente más amplia. Este evento alcanzó algo de notoriedad, lo que se extendió también al libro. Todas las ediciones publicada de "GURPS Ciberpunk" contienen una cita en la cubierta que dice ""¡El libro que fue decomisado por el Servicio Secreto de los Estados Unidos!"". En su interior el libro provee un resumen de la redada y sus consecuencias.

El 2004 trajo numerosas publicaciones nuevas de juegos de rol Ciberpunk, destacó entre ellas "Ex Machina", un juego más cinematográfico con cuatro escenarios completos y enfocado en actualizar el lado lúdico del género a temas corrientes dentro de la ficción Ciberpunk. Estos cambios incluyen un mayor ángulo político, transfiriendo la alineación del género e incluso incorporando temas transhumanos. El 2006 vio la largamente esperada publicación de "Ciberpunk V.3" de Talsorian Games', la secuela de "Ciberpunk 2020", sin embargo muchos la vieron más como una edición transhumanista o Postciberpunk que realmente Ciberpunk.

Los juegos de rol también han producido una de las más originales tomas del género en la forma de la serie de juegos "Shadowrun" de 1989. Aquí, el escenario es un distópico futuro cercano; sin embargo, también incorpora elementos de la fantasía y la literatura, como magia, espíritus, duendes y dragones. Las facetas ciberpunk de "Shadowrun" fueron modeladas en gran parte basadas en los escritos de William Gibson, y la FASA, quienes lo publicaron originalmente, han sido acusados por algunos de copiar el trabajo de Gibson sin siquiera mencionar su influencia. Gibson, mientras tanto, ha mostrado su desagrado por la inclusión de elementos de fantasía dentro de los escenarios que él ayudó a desarrollar. Sin embargo, "Shadowrun" ha introducido a muchos al género, y sigue siendo popular entre los jugadores.

El juego de rol "Torg", publicado por West End Games también incluyó una variante del escenario (o cosmos) ciberpunk llamado "Cyberpapado". Este escenario fue inicialmente una distopía religiosa medieval que repentinamente sufrió un surgimiento tecnológico. En vez de corporaciones y gobiernos corruptos, el Cyberpapado fue dominado por el “Falso Papado de Avignon”. En lugar de la Internet, los hackers navegan por la "GodNet", una red común de computadoras con directo simbolismo religioso, hogar de ángeles, demonios, y otras figuras bíblicas. Otro “cosmos” aparte del juego Torg fue "Nippon Tech", el cual incorporaba otros aspectos del ciberpunk como corporaciones dominantes con asesinos profesionales, sin embargo no incluye redes de computadores como parte fundamental del escenario.

El ciberpunk también ha sido usado en videojuegos de aventura para computadoras, destacan el ahora freeware "Beneath a Steel Sky", publicado por Revolution Software, "Neuromancer", publicado por Interplay en 1988, "Bloodnet", publicado por Microprose en 1993 y "", por Gametek en 1994. También el ahora abandonware, "Flashback". El videojuego de acción y aventura "Neuromancer" está basado directamente en la novela, incluyendo Chiba City, algunos de los personajes, hacking de bases de datos y plataformas ciberespaciales.

Este estilo llegó a verse plasmado en videojuegos de disparos en primera persona. Algo que se puede apreciar, por ejemplo, en Neotokyoº , un mod del videojuego Half-Life 2, situado en un Japón futurista.

El primer libro cubano ciberpunk fue "Nova de Cuarzo" (1999), de Vladimir Hernández Pacín. Otra novela "cyber" publicada fue "Dioses de neón" (2002), de Michel Encinosa Fú. Uno de los exponentes más claros del Ciberpunk en Chile es Jorge Baradit, quien ha escrito las novelas Ygdrasil, Kalfukura y Synco, además de participar o promover proyectos artísticos como , Ucronía Chile y Lluscuma. Uno de los grupos españoles que se autodenomina ciberpunk aparece en Berlín en 1989 con autores de diversos fanzines underground que, en 1996, pasarían a publicar en la Web uno de los primeros ezines españoles. Tras constituirse como asociación en 2002 sus publicaciones evolucionarán hacia el ciberactivismo abandonando prácticamente la publicación de relatos. Literariamente la única aportación reconocida de este grupo han sido las primeras novelas escritas en español para teléfonos móviles: "Lía, MAD phreaker", de David de Ugarte y "BCN No Future" de Javier Lorente. En un contexto más futurista está "2123 El año de Moebius", con booktráiler de Ángel De Aluart. "El sueño del Rey Rojo", del autor asturiano Rodolfo Martínez, suele considerarse también dentro del género. El filósofo y escritor Jonás Barnaby, bajo el seudónimo Albert Mut, puede contarse entre las emergentes personalidades del género en los últimos años, con relatos claramente distópicos y tecnológicos como "La gallina temporal" o "Phobos B-101".
En el cine, pocas son las películas españolas que hacen uso de este estilo. Un ejemplo lo encontramos en "Natalie_Net", dirigida por Chico Morera que cuenta la historia de una videoblogger de fama que empieza a desarrollar características de computadora. La película muestra un ambiente insano, en un entorno distópico y atemporal en el que la tecnología, los virus informáticos y las relaciones humanas toman el protagonismo y muestran su lado más oscuro. 

En cuanto al desarrollo del movimiento en México, se considera que éste se introdujo por medio de la literatura y de allí partió para encontrar otros medios de expresión más populares, como la música. La primera obra literaria escrita en México y que puede enmarcarse dentro del ciberpunk es el cuento "La red" de Isidro Ávila. Sin embargo, la obra que se considera que originó el movimiento en México, fue una novela publicada un par de años después que el cuento de Ávila. "La primera calle de la soledad" (1994), del entonces joven Gerardo Horacio Porcayo, sirvió de ancla para que muchos escritores de ciencia ficción tomaran al género como algo suyo, y aunque el ciberpunk mexicano nunca terminó por germinar completamente, ha perdurado más de una década después de su nacimiento.

La primera novela de ciencia ficción que podría considerarse ciberpunk en Paraguay es "La Sociedad de las Mentes" (2001), de Juan de Urraza, que si bien contiene elementos utópicos que resultan disonantes con el género, en realidad los une al mundo virtual, sobre todo si se tiene en cuenta como un todo y se mira como unidad con su segunda novela "Yronia" (2005), que es la continuación de la misma.

Entre los subgéneros del Ciberpunk está el Steampunk que se ubica en una era victoriana ucrónica pero con una visión negra del mundo. El término fue acuñado originalmente en 1987 como broma para describir algunas de las novelas de Tim Powers, James Blaylock y Kevin Wayne Jeter, pero con el tiempo William Gibson y Bruce Sterling ingresaron al subgénero con su novela en colaboración "La Máquina Diferencial" y el término fue empezado a tomarse en serio. El Silkpunk sería un derivado de este último con la diferencia de que se enfoca en un contexto ambientado en la China de la Dinastía Han. Siendo Ken Liu y su libro La Gracia de los Reyes un referente a esta tendencia.

Otro subgénero similar de aún muy reciente clasificación es el que se ha venido a llamar Wirepunk, heredero del Steampunk, que en lugar de tomar como partida el siglo XIX, se centra en la tecnología del siglo XX, ahora que ya supone un tiempo pasado. Un ejemplo claro es la saga literaria de Jeanne DuPrau iniciada con "City of Ember".

Los inicios de 1990 vieron el nacimiento del biopunk, un estilo derivado construido no sobre la base de la tecnología sino sobre la biología. En estas historias la gente es cambiada de varias formas, pero no por medios mecánicos, sino por manipulación genética de varios de sus cromosomas. Paul di Filipo es visto como el más prominente escritor biopunk, aunque "Shaper/Mechanist" de Bruce Sterling es su mayor influencia.

El género emergente llamado postciberpunk continúa preocupándose por los efectos de los ordenadores, pero sin dar por supuesta la distopía ni dar tanta importancia a los implantes cibernéticos. También heredero del ciberpunk podemos considerar el concepto de singularidad tecnológica utilizado en la ciencia ficción más reciente, que recoge su preocupación por el desarrollo de la inteligencia artificial hasta el extremo, y el rol que los humanos podríamos adoptar en tales circunstancias.



</doc>
<doc id="15422" url="https://es.wikipedia.org/wiki?curid=15422" title="Economía de Bélgica">
Economía de Bélgica

La moderna economía de mercado de Bélgica se beneficia de la privilegiada localización geográfica del país en Europa, por una red de transportes bastante desarrollada y por una base industrial y comercial diversificada. La industria está concentrada principalmente en la región de Flandes, al norte.

Con pocos recursos naturales, el país importa grandes cantidades de materias primas (MP) y exporta principalmente manufacturados. El resultado es una economía muy dependiente de los mercados mundiales.

Cerca de 3/4 del comercio del país es hecho con otros países de la Unión Europea. En 2009 la economía del país sufrió una retracción de 2,7%, el desempleo creció ligeramente y el déficit presupuestario empeoró debido a la ayuda en gran escala al sector financiero. El déficit presupuestario creció para 4,8% del PIB en 2010, mientras la deuda pública superaba los 100% del PIB el mismo año.

El país es lo 18º en el ranking de competitividad del Foro Económico Mundial.

Su moneda anterior era el franco belga; desde el 1 de enero de 2002 es el euro, moneda de la Unión Europea.


Población ocupada

Población ocupada por sectores

(Estimaciones 199

Población bajo el umbral de la pobreza

Se presentan a continuación las mercancías de mayor peso en las importaciones de Bélgica para el período 2010-hasta abril 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Bélgica para el periodo 2010-hasta abril 2015.La mayoría de sus importadores están en Europa salvo Estados Unidos, India y China. Las cifras expresadas son en dólares estadounidenses valor FOB.



</doc>
<doc id="15423" url="https://es.wikipedia.org/wiki?curid=15423" title="Relación de indeterminación de Heisenberg">
Relación de indeterminación de Heisenberg

En mecánica cuántica, la relación de indeterminación de Heisenberg o principio de incertidumbre establece la imposibilidad de que determinados pares de magnitudes físicas observables y complementarias sean conocidas con precisión arbitraria. Sucintamente, afirma que no se puede determinar, en términos de la física cuántica, simultáneamente y con precisión arbitraria, ciertos pares de variables físicas, como son, la posición y el momento lineal (cantidad de movimiento) de un objeto dado. En otras palabras, cuanta mayor certeza se busca en determinar la posición de una partícula, menos se conoce su momento lineal y, por tanto, su masa y velocidad. Este principio fue enunciado por Werner Heisenberg en 1925. 

El principio de indeterminación no tiene un análogo clásico y define una de las diferencias fundamentales entre física clásica y física cuántica. Desde un punto de vista lógico es una consecuencia de axiomas corrientes de la mecánica cuántica y por tanto estrictamente se deduce de los mismos.

La explicación «divulgativa» del principio de incertidumbre afirma que las variables dinámicas como posición, momento angular, momento lineal, etc. se definen de manera "operacional", esto es, en términos relativos al procedimiento experimental por medio del cual son medidas: la posición se definirá con respecto a un sistema de referencia determinado, definiendo el instrumento de medida empleado y el modo en que tal instrumento se usa (por ejemplo, midiendo con una regla la distancia que hay de tal punto a las referencias).

Sin embargo, cuando se examinan los procedimientos experimentales por medio de los cuales podrían medirse tales variables resulta que la medida siempre acabará perturbada. En efecto, si por ejemplo pensamos en lo que sería la medida de la posición y velocidad de un electrón, para realizar la medida (para poder «ver» de algún modo el electrón) es necesario que un fotón de luz choque con el electrón, con lo cual está modificando su posición y velocidad; es decir, por el mismo hecho de realizar la medida, el experimentador modifica los datos de algún modo, introduciendo un error que es imposible de reducir a cero, por muy perfectos que sean nuestros instrumentos.

Esta descripción cualitativa del principio, sin ser totalmente incorrecta, es engañosa en tanto que omite el principal aspecto del principio de incertidumbre: el principio de incertidumbre establece el límite de aplicabilidad de la física clásica. La física clásica concibe sistemas físicos descritos por medio de variables perfectamente definidas en el tiempo (velocidad, posición...) y que en principio pueden conocerse con la precisión que se desee. Aunque en la práctica resultara imposible determinar la posición de una partícula con una precisión infinitesimal, la física clásica concibe tal precisión como alcanzable: es posible y perfectamente concebible afirmar que tal o cual partícula, en el instante de tiempo exacto 2 s, estaba en la posición exacta 1,57 m. En cambio, el principio de incertidumbre, al afirmar que existe un límite fundamental a la precisión de la medida, en realidad está indicando que si un sistema físico real se describe en términos de la física clásica, entonces se está haciendo una aproximación, y la relación de incertidumbre nos indica la calidad de esa aproximación.

Por motivos culturales y educativos, las personas se suelen enfrentar al principio de incertidumbre por primera vez estando condicionadas por el determinismo de la física clásica. En ella, la posición formula_1 de una partícula puede ser definida como una función continua en el tiempo, formula_2". Si la masa de esa partícula es formula_3 y se mueve a velocidades suficientemente inferiores a la de la luz, entonces el momento lineal de la partícula se define como masa por velocidad, siendo la velocidad la primera derivada en el tiempo de la posición: formula_4. 

Dicho esto, atendiendo a la explicación habitual del principio de incertidumbre, podría resultar tentador creer que la relación de incertidumbre simplemente establece una limitación sobre nuestra capacidad de medida que nos impide conocer con precisión arbitraria la posición inicial formula_5 y el momento lineal inicial formula_6 . Ocurre que si pudiéramos conocer formula_5 y formula_6 , entonces la física clásica nos ofrecería la posición y la velocidad de la partícula en cualquier otro instante; la solución general de las ecuaciones de movimiento dependerá invariablemente de formula_5 y formula_6 . Esto es, resolver las ecuaciones del movimiento lleva a una familia o conjunto de trayectorias dependientes de formula_5 y formula_6 ; según qué valor tomen formula_5 y formula_6 , se tendrá una trayectoria dentro de esa familia u otra, pero la propia resolución de las ecuaciones limita el número de trayectorias a un conjunto determinado de ellas. Según se ha razonado, de acuerdo con el principio de incertidumbre formula_5 y formula_6 no se pueden conocer exactamente, así que tampoco podrán conocerse formula_17 y formula_18 en cualquier otro instante con una precisión arbitraria, y la trayectoria que seguirá la partícula no podrá conocerse de manera absolutamente exacta. Este razonamiento es, sin embargo, incorrecto, pues en él subyace la idea de que, pese a que formula_5 y formula_6 no se pueden conocer exactamente, es posible continuar usando la descripción clásica en virtud de la cual una partícula seguirá una trayectoria definida por la solución general de las ecuaciones de movimiento, introduciendo la noción añadida de que las condiciones iniciales formula_5 y formula_6 no pueden conocerse al detalle: esto es, no podemos conocer exactamente qué trayectoria va a seguir la partícula, pero estaremos aceptando que, de facto, va a seguir una. 

Esta forma de proceder es, sin embargo, totalmente incorrecta: el principio de incertidumbre conlleva un desvío completo de las concepciones clásicas, haciendo que la noción clásica de trayectoria debe ser desechada: preguntar cuáles son simultáneamente los valores de formula_17 y formula_18 es un absurdo. Así dicho, podría resultar paradójico que primero se establezca una relación de incertidumbre en términos de posición formula_25 y momento lineal formula_26 , para luego afirmar que formula_25 y formula_26 , que aparecen en dicha relación, no tienen sentido: si no tienen sentido, ¿qué sentido puede tener una relación que las emplee? Ocurre que, en física cuántica, es posible introducir una serie de entidades matemáticas formula_25 y formula_26 que se correspondan en muchos aspectos con la posición y el momento clásicos. Dichas entidades no son, no obstante, exactamente iguales a la posición y el momento clásicos: el principio de incertidumbre sencillamente indica que si interpretamos esas entidades como posición y momento lineal -y por tanto interpretamos el movimiento de una forma clásica-, entonces existe un límite fundamental en la precisión con que dichas variables pueden ser conocidas; esto es, si intentamos introducir variables clásicas e intentamos interpretar el movimiento de forma clásica, la precisión con que estas variables pueden ser especificadas está limitada.

Este principio supone un cambio básico en la naturaleza de la física, ya que se pasa de un conocimiento absolutamente preciso en teoría (aunque no en el conocimiento basado sólo en probabilidades). Aunque debido a la pequeñez de la constante de Planck, en el mundo macroscópico la indeterminación cuántica es casi siempre completamente despreciable, y los resultados de las teorías físicas deterministas, como la teoría de la relatividad, siguen teniendo validez en todos casos prácticos de interés.

Las partículas, en mecánica cuántica, no siguen trayectorias definidas. No es posible conocer exactamente el valor de todas las magnitudes físicas que describen el estado de movimiento de la partícula en ningún momento, sino sólo una distribución estadística. Por lo tanto no es posible asignar una trayectoria a una partícula. Sí se puede decir que hay una determinada probabilidad de que la partícula se encuentre en una determinada región del espacio en un momento determinado.

Comúnmente se considera que el carácter probabilístico de la mecánica cuántica invalida el determinismo científico. Sin embargo, existen varias interpretaciones de la mecánica cuántica y no todas llegan a esta conclusión. Según puntualiza Stephen Hawking, la mecánica cuántica es determinista en sí misma, y es posible que la aparente indeterminación se deba a que realmente no existen posiciones y velocidades de partículas, sino sólo ondas. Los físicos cuánticos intentarían entonces ajustar las ondas a nuestras ideas preconcebidas de posiciones y velocidades. La inadecuación de estos conceptos sería la causa de la aparente impredecibilidad. Otros fenómenos deducibles o conectados con el principio de indeterminación de Heisenberg son:

Si se preparan varias copias idénticas de un sistema en un estado determinado, como puede ser un átomo, las medidas de la posición y de la cantidad de movimiento variarán de acuerdo con una cierta distribución de probabilidad característica del estado cuántico del sistema. Las medidas del objeto observable sufrirán desviación estándar Δ"x" de la posición y el momento Δ"p". Verifican entonces el principio 
de indeterminación que se expresa matemáticamente como:

donde la "h" es la constante de Planck (para simplificar, formula_31 suele escribirse como formula_32 )

El valor conocido de la constante de Planck es:

En la física de sistemas clásicos esta indeterminación de la posición-momento no se manifiesta puesto que se aplica a estados cuánticos del átomo y "h" es extremadamente pequeño. Una de las formas alternativas del principio de indeterminación más conocida es la indeterminación tiempo-energía que puede escribirse como:

Esta forma es la que se utiliza en mecánica cuántica para explorar las consecuencias de la formación de partículas virtuales, utilizadas para estudiar los estados intermedios de una interacción. Esta forma del principio de indeterminación es también la utilizada para estudiar el concepto de energía del vacío.

Además de las dos formas anteriores existen otras desigualdades como la que afecta a las componentes "J" del momento angular total de un sistema:

Donde "i", "j", "k" son distintos y "J" denota la componente del momento angular a lo largo del eje "x".

Más generalmente si en un sistema cuántico existen dos magnitudes físicas "a" y "b" representadas por los operadores u observables denotados como formula_34, en general no será posible preparar una colección de sistemas todos ellos en el estado formula_35, donde las desviaciones estándar de las medidas de "a" y "b" no satisfagan la condición:
La expresión general de la relación de indeterminación se deduce de los postulados I y III de la mecánica cuántica. La demostración más particular de que existen magnitudes que no pueden conocerse con precisión arbitraria usa también y de manera crítica el postulado VI.

Para probar el principio de indeterminación de Heisenberg supongamos dos observables formula_36 y formula_37 cualesquiera y supongamos un estado formula_38 tal que formula_39. En esa situación puede demostrarse que:

Donde:
Definiendo a partir de formula_36 y formula_37, los operadores autoadjuntos:

Se puede construir la función real:

Y desarrollando el producto escalar anterior:

Teniendo en cuenta que:
La ecuación puede ser reescrita como:

Como formula_48 es un operador hermítico los coeficientes de la función polinómica anterior son reales, y como la expresión anterior es real para todo valor de formula_49 necesariamente el discriminante del polinomio asociado debe ser negativo:

Reordenando y obteniendo raíces cuadradas en la ecuación anterior se obtiene precisamente la ecuación . Si se particulariza la ecuación tomando formula_50:
Mediante el principio de incertidumbre es posible estimar la energía del punto cero de algunos sistemas. Para ello supondremos que en tales sistemas el punto cero cumple que la partícula estaría clásicamente en reposo (a nivel cuántico significa que el valor esperado del momento es nulo). Este método del cálculo de energías tan solo da una idea del orden de magnitud del estado fundamental, nunca siendo un método de cálculo del valor exacto (en algún sistema puede resultar que el valor obtenido sea el exacto pero ello no deja de ser más que una simple casualidad).
La interpretación física del método es que debido al principio de incertidumbre, la localización de la partícula tiene un coste energético (el término de la energía cinética), de modo que cuanto más cerca del centro de fuerzas esté la partícula más energía tendrá el sistema debido a las fluctuaciones cuánticas, de modo que en el nivel fundamental el sistema minimizará su energía total.

A continuación se estimará la energía fundamental de un átomo monoelectrónico.
Por el principio de indeterminación se tiene que:
Empleando como estimación que para el nivel fundamental se cumple:
La energía total es la suma de cinética más potencial. Dado que el valor medio del momento radial es nulo, su valor cuadrático esperado será igual a su desviación y se aproximará el valor esperado del inverso del radio al inverso de su desviación.
En el nivel fundamental la energía ha de ser mínima de modo que:
El valor obtenido es casualmente idéntico al radio de Bohr y sustituyendo en la estimación obtenida para la energía se obtiene:
Casualmente este es exactamente la energía del estado fundamental de un átomo hidrogenoide. El objetivo del método es la estimación del valor, si bien en este ejemplo particular obtenido es idéntico al calculado formalmente.

Empleando como estimación:
Tomando que el valor medio de la posición y momento son nulos debido a la simetría del problema se tiene que la energía total es:
Minimizando la energía:
Sustituyendo el valor en la energía se obtiene:
Como se puede observar el valor obtenido es el doble del punto cero del oscilador armónico, de modo que aunque el valor obtenido no sea exacto el orden de magnitud sí es el correcto.

Sea una partícula que se encuentra confinada en un pozo infinito de anchura 2a. Dado que las únicas posiciones posibles de la partícula se encuentran dentro del pozo se puede estimar que:
La energía cinética será por tanto:
Como se observa el resultado obtenido difiere en un factor algo superior a 2 del valor real, pero de nuevo el orden de magnitud es el correcto. Este cálculo da una idea de las energías que hay que aportar para confinar una cierta párticula en una región, tal como puede ser un nucleón en el núcleo.





</doc>
<doc id="15427" url="https://es.wikipedia.org/wiki?curid=15427" title="Anillo (desambiguación)">
Anillo (desambiguación)

El término anillo puede referirse a:



</doc>
<doc id="15429" url="https://es.wikipedia.org/wiki?curid=15429" title="TeX">
TeX

TeX, estilizado como formula_1, es un sistema de tipografía escrito por Donald E. Knuth, muy popular en el entorno académico, especialmente entre las comunidades de matemáticos, físicos e informáticos. Ha conseguido sustituir con creces a troff, otro programa de tipografía habitual en Unix.

TeX se considera generalmente la mejor forma de componer fórmulas matemáticas complejas pero, especialmente en la forma de LaTeX y otros paquetes de macros, se puede usar para otras tareas de composición.

Knuth empezó a escribir TeX porque se sentía molesto con la calidad cada vez menor de la tipografía en los volúmenes I a III de su obra "El arte de programar ordenadores". Empezó por ello a diseñar su propio lenguaje de tipografía. Pensó que podría acabarlo en su año sabático, 1978; se equivocó por tan solo ocho años. El lenguaje se finalizó y congeló (no se hicieron más modificaciones) alrededor de 1985.

Guy Steele coincidió en Stanford en el verano de 1978, cuando Knuth estaba desarrollando su primera versión de TeX. Cuando volvió al MIT a finales de año, reescribió la entrada/salida de TeX para que se ejecutase en el ITS.

La primera versión de TeX se escribió usando el lenguaje de programación SAIL que se ejecutaba en una PDP-10 en el sistema operativo WAITS de la Universidad de Stanford. Para las versiones posteriores de TeX, Knuth inventó el concepto de programación literaria, una forma de producir código fuente compilable y documentación con referencias de alta calidad (por supuesto, escrito en TeX) partiendo del mismo archivo original. El lenguaje usado se llama WEB y produce programas en Pascal.

TeX tiene un sistema de numeración de versiones peculiar. Desde la versión 3, las actualizaciones se indican añadiendo una cifra decimal extra al final, de modo que el número de versión se aproxime asintóticamente a π. La versión más reciente es la 3,14159265 y por ser muy estable sólo se prevén pequeñas actualizaciones.

Knuth ha indicado que el "último cambio final (hecho después de mi muerte)" será cambiar el número de versión a π, y que en ese momento todos los errores que queden serán considerados características.

Las órdenes de TeX empiezan con una barra invertida ("\") y sus argumentos se indican mediante
llaves ("{}"). Sin embargo, casi todas las propiedades sintácticas
de TeX pueden cambiarse sobre la marcha, con lo que la entrada de TeX es
algo difícil de analizar salvo por el propio TeX. TeX es un lenguaje
basado en órdenes básicas y macros: muchas órdenes, incluidas la
mayoría de las que definen los usuarios, se sustituyen sobre la marcha hasta
que solo quedan órdenes básicas, que entonces se ejecutan. La sustitución en sí
misma está libre de efectos secundarios. La recursión de macros no consume
memoria y asimismo se dispone de construcciones if-then-else. Todo ello hace
de TeX un lenguaje Turing completo incluso al nivel de sustitución.

El sistema TeX tiene un conocimiento preciso de los tamaños de los caracteres
y símbolos, y usando esta información calcula el alineamiento óptimo de letras
por línea y de líneas en cada página. Posteriormente produce un archivo DVI (de las siglas en inglés "device independent", independiente del dispositivo) que contiene la posición final de todos los caracteres. El archivo dvi se puede imprimir directamente usando un controlador
de impresora adecuado, o puede convertirse a otros formatos. Actualmente,
pdfTeX se usa para generar archivos PDF saltándose la generación del DVI.

La mayor parte de la funcionalidad viene dada por diversas macros: las
originales de Knuth englobadas en lo que se llama plainTeX, LaTeX (mayoritario
en las ciencias técnicas) y ConTeXt (usado principalmente para
publicaciones).

La referencia principal de TeX son los dos primeros volúmenes de la obra "Computers and Typesetting" de Knuth: `"The TeXbook"'´ y `"TeX: The Program"´ (éste incluye el código fuente de TeX completo y documentado).

La organización de los directorios en una instalación de TeX está normalizada en un árbol llamado texmf.

La licencia de TeX permite la distribución y modificación libres, pero exige que cualquier versión modificada no se llame TX, TeX o algo similar, que pueda ser confundido con la versión original. La licencia da derechos similares a aquellos de una marca registrada.

Aunque está bien escrito, TeX es tan grande (y tan lleno de técnica avanzada) que se dice haber descubierto al menos un error en cada sistema Pascal en el que se ha compilado, ya que TeX se ejecuta en la mayoría de los sistemas operativos.

Knuth ofrece recompensas monetarias para la gente que encuentre e informe de un error en el programa. El premio por error empezó con un centavo y se doblaba cada año hasta que quedó congelado en su valor actual de 327,68 dólares. Esto, sin embargo, no ha arruinado a Knuth, porque se han encontrado muy pocos errores y
en cualquier caso el cheque que prueba que el propietario encontró un error en TeX se suele enmarcar en vez de cobrarlo.

Donald Knuth explica en su obra "The TeXbook" que la palabra "technology" ("tecnología") tiene raíz griega y esta comienza por las letras τεχ. Por tanto, el nombre TeX en español se tiene que pronunciar [tej], y no [teks]. Ello se debe a que TeX no quiere decir TEX sino τεχ, acabado en la letra griega χ <nowiki>[</nowiki>ji<nowiki>]</nowiki>. La misma palabra griega τέχνη (ΤΕΧΝΗ – technē) significa "arte", una referencia a que la técnica no está reñida con el arte ni con la presentación elegante.

Cuando se está escribiendo un archivo en TeX y se quiere hacer referencia al
nombre se dispone de la orden \TeX, definida así:

O así en formula_2:

y que fue creada por Knuth para demostrar lo que es posible hacer con TeX. La letra "E" queda por
debajo de la línea base y más unida a la T; en los otros sistemas se escribe
usando la aproximación "<nowiki>TeX</nowiki>".

Varios sistemas de procesamiento de documentos están basados en TeX; destacan entre ellos:


Todos estos sistemas están escritos en el lenguaje de programación TeX (algunos con complementos en otros lenguajes de programación). Además, hay programas que extienden el lenguaje de programación con nuevas órdenes y capacidades:

Además, hay programas asociados como BibTeX para el manejo de
bibliografías, MakeIndex y xindy para los índices alfabéticos
y Metafont para gráficos.

Todas las extensiones están disponibles en el
CTAN, ("Comprehensive TeX Archive Network").

En sistemas compatibles Unix, TeX se distribuye bajo la forma teTeX. En sistemas Windows existen MiKTeX y fpTeX. En sistemas Mac OS X existe MacTeX con utilidades como TeXShop.

El editor de texto TeXmacs es un editor de textos científicos WYSIWYG que pretende ser compatible con TeX. Usa las tipografías de Knuth y puede generar un archivo TeX. Otra herramienta similar es LyX.

Un ejemplo simple en TeX: 
crea un archivo llamado miprimer.tex que contenga lo siguiente:

Abre un intérprete de órdenes y escribe

TeX creará un archivo llamado "miprimer.dvi". Usa un programa adecuado para visualizarlo. Por ejemplo, MiKTeX incluye el visor yap

El visor muestra "hola" en una página. "\bye" es la orden Tex que marca el final de un archivo y no se muestra en la salida final.

El archivo dvi puede ser impreso directamente desde el visor o convertido a un formato más común tal como PostScript usando el programa dvips.

Es posible crear directamente archivos PDF usando pdfTeX:

pdfTeX se creó originalmente porque al convertir los PostScript generados en PDF se obtenía una visualización de las tipografías de baja calidad, aunque la impresión era buena. La causa es que TeX usa de forma nativa tipografías Tipo 3 de mapas de bits, que no se visualizan tan bien como las tipografías Tipo 1 escalables.

Es posible actualmente hacer que dvips use las tipografías escalables con un poco de configuración (versiones recientes de Ghostscript lo permiten), pero una conversión directa a PDF tiene otros beneficios: es un proceso en un solo paso, en lugar de dos, y pdfTeX incluye cosas tales como marcadores e hipervínculos, ausentes en PostScript.

Para ver a TeX en acción, prueba a escribir la conocida fórmula de la ecuación cuadrática:

Con el texto de arriba deberías obtener algo que se viese como esto

En un documento, para entrar en el "modo matemático" se escribe un signo $, a continuación la fórmula de manera que la entienda TeX y se cierra con otro signo $. Otro modo de presentación, que deja la fórmula centrada en una nueva línea, se consigue usando $$. Por ejemplo, la fórmula anterior se escribiría

y se vería como
formula_4

Aplicación de Fórmula del cociente






</doc>
<doc id="15430" url="https://es.wikipedia.org/wiki?curid=15430" title="Ingeniería civil">
Ingeniería civil

La ingeniería civil es la disciplina de la ingeniería profesional que emplea conocimientos de cálculo, mecánica hidráulica y física para encargarse del diseño, construcción y mantenimiento de las infraestructuras emplazadas en el entorno, incluyendo carreteras, ferrocarriles, puentes, canales, presas, puertos, aeropuertos, diques y otras construcciones relacionadas. La ingeniería civil es la más antigua después de la ingeniería militar, de ahí su nombre para distinguir las actividades no militares con las militares. Tradicionalmente ha sido dividida en varias subdisciplinas incluyendo ingeniería ambiental, Ingeniería Agroindustrial, ingeniería sanitaria, ingeniería geotécnica, geofísica, geodesia, ingeniería de control, ingeniería estructural, mecánica, ingeniería del transporte, ciencias de la Tierra, ingeniería del urbanismo, ingeniería del territorio, ingeniería hidráulica, ingeniería de los materiales, ingeniería de costas, agrimensura, e ingeniería de la construcción. Los ingenieros civiles ocupan puestos en prácticamente todos los niveles: en el sector público desde el ámbito municipal al gubernamental y en el ámbito privado desde los pequeños consultores autónomos que trabajan en casa hasta los contratados en grandes compañías internacionales.

La ingeniería ha sido un aspecto de la vida desde el inicio de la existencia humana. Las prácticas más tempranas de la ingeniería civil podrían haber comenzado entre el 4000 y el en el Antiguo Egipto y Mesopotamia cuando los humanos comenzaron a abandonar la existencia nómada, creando la necesidad de un cobijo. Durante este tiempo el transporte empezó a incrementar su importancia, lo que llevó al desarrollo de la rueda y de la navegación.

Hasta la Edad Contemporánea no hay una distinción clara entre ingeniería civil y arquitectura, y el término ingeniero y arquitecto sufrió variaciones refiriéndose a la misma persona, incluso intercambiándose. La construcción de las Pirámides de Egipto entre el 2700 y el 2500 a. C. podría considerarse las primeras muestras de construcciones de gran tamaño. Otras construcciones históricas incluyen el sistema de gestión de aguas de Qanat, el Partenón por Ictino en la Grecia Antigua (), la vía Apia por los ingenieros Romanos o la Gran Muralla China en el 220 a. C, o los trabajos de irrigación en Anuradhapura. De todas las civilizaciones antiguas quizás la más desarrollada en ingeniería civil fueron los romanos que fueron pioneros en la construcción de una red de calzadas, acueductos, puertos, puentes, presas y alcantarillados.

En el siglo XVIII el término ingeniería civil fue acuñado para incorporar toda la ingeniería para usos civiles en oposición de la ingeniería militar (artillería, balística, construcción de defensas...). En 1747 se crea la escuela de ingeniería civil más antigua del mundo, la École nationale des ponts et chaussées en París, que aún hoy perdura. El primer ingeniero civil autoproclamado fue John Smeaton que construyó el faro de Eddystone. En 1771 Smeaton y algunos colegas formaron la "Smeatonian Society of Civil Engineers", un grupo de profesionales que se reunían diariamente para debatir sobre su profesión. A través de estos encuentros se formaron las sociedades profesionales que conocemos hoy en día.

En España se consideró la necesidad de crear un cuerpo de ingenieros específico que se encargara de las obras públicas, por eso se funda la Escuela Oficial del Cuerpo de Ingenieros de Caminos dirigida por Agustín de Betancourt en 1802. Por aquel entonces México ya había establecido el primer instituto de investigación especializado en la ingeniería civil y en 1857 se instituyen las enseñanzas de ingeniero civil en la Academia de San Carlos basándose en los planes de estudios europeos.

Los ingenieros civiles cuentan con un título académico en ingeniería civil. El tiempo de estudio es de entre 4 y 5 años para el "título de grado en ingeniería" ("bachelor de ingeniería" en los países anglosajones), que es necesario para poder cursar posteriormente los estudios de posgrado (títulos de "máster en ingeniería" y "doctor en ingeniería").

En la mayoría de los países, el título universitario representa el primer paso a la certificación profesional y el programa de la titulación en sí mismo está certificado por un colegio profesional. Después de completar un programa de titulación certificada el ingeniero debe satisfacer una serie de requerimientos (incluyendo experiencia laboral y un examen) antes de ser certificado. Una vez certificado, el ingeniero es designado con el título de ingeniero profesional (en Estados Unidos, Canadá y Sudáfrica), o ingeniero colegiado (en la mayoría de los países de la Commonwealth), ingeniero profesional colegiado (en Australia y Nueva Zelanda) o ingeniero europeo (para algunos países de la Unión Europea). Existen acuerdos internacionales entre colegios de ingenieros que permiten a ingenieros de otros países ejercer fuera de sus fronteras. En España cualquier persona que completa la carrera puede ejercer y colegiarse, sin ningún otro requisito adicional como experiencia o examen.

Las ventajas de la certificación varían dependiendo del sitio. Por ejemplo, en Estados Unidos y Canadá “sólo un ingeniero profesional licenciado puede preparar, firmar y sellar, y entregar un proyecto de ingeniería a una autoridad pública para su aprobación, o sello para clientes públicos o privados”. En el estado de Quebec, en Canadá, esto es así. En Reino Unido no existe una legislación tan restrictiva ni en España si bien existen colegios que pueden expulsar a sus miembros por mala praxis y así no poder ejercer. Se supone que todos los ingenieros deben respetar un código ético y que si no lo cumplen se les puede culpar por negligencia.

En España existe actualmente el grado en "Ingeniería Civil", "Obras Públicas" o "Civil y Territorial" (entre otros nombres dependiendo de la universidad que lo otorga) de 4 años y 240 ECTS), así como el máster en "Ingeniería de Caminos, Canales y Puertos" de entre 1 y 2 años más y 66 a 120 ECTS). Anteriormente existían las titulaciones oficiales de "Ingeniero Técnico de Obras Públicas" e "Ingeniero de Caminos, Canales y Puertos". Dichas titulaciones generalmente incluyen unidades que cubren física, matemáticas, gestión de proyectos, diseño y temas específicos de la ingeniería civil. Normalmente en el inicio de la titulación las asignaturas cubren la mayoría, si no todas, las subdisciplinas de la ingeniería civil. Los estudiantes entonces eligen especializarse en la parte final de la titulación en una o más subdisciplinas en vistas a terminar sus titulaciones. Además del "Máster Universitario en Ingeniería de Caminos, Canales y Puertos", que atribuye las competencias específicas de dicha profesión regulada, las universidades generalmente ofrecen además másteres de especialización para mejorar los conocimientos del ingeniero civil en un área de particular interés dentro de la ingeniería civil.

Actualmente se estudia 5 o 6 años para el “grado en ingeniería civil”, el cual es necesario para cursar estudios de postgrado, como “máster en ingeniería de las estructuras, hidráulica, métodos numéricos”, después el “doctorado”. Las materias necesarias para la obtención del grado de ingeniero civil se clasifican entre matemáticas y ciencias básicas, y materias dirigidas ya a la ingeniería civil como Ciencia.

Su campo de aplicación es muy amplio. Estarían, por ejemplo, las infraestructuras del transporte:

Las obras hidráulicas:

La intervención sobre problemas de estabilidad del terreno.

Las estructuras que componen las obras anteriores:

En general, las obras de ingeniería civil implican el trabajo una gran cantidad de personas (en ocasiones cientos y hasta miles) a lo largo de lapsos que abarcan desde unas pocas semanas o meses hasta varios años.

Debido al elevado costo de los trabajos que se acometen (piénsese en el coste de una autovía o de una línea de ferrocarril) buena parte de los trabajos que se realizan son para el Estado, o bien para grandes compañías que pretenden la explotación de una infraestructura a largo plazo (autopistas y túneles de peaje, compañías de ferrocarril, etcétera). Sin embargo, sus técnicas son también aplicadas para obras semejantes a las anteriores pero de más pequeña escala, como podrían ser:

Además, son también competencia de un ingeniero civil:

De esta forma, un ingeniero civil no se limita a las grandes obras de infraestructura, muy raras debido a su elevado coste.

El trabajo de un ingeniero civil comienza al presentarse una determinada necesidad (un nuevo dique en un puerto, la ampliación o construcción de una carretera, una presa que dé continuidad y estabilidad al caudal de un río…). En esta etapa de planificación, los ingenieros civiles trabajan en forma integrada con otros profesionales y autoridades nacionales o locales con poder de decisión.

Entra entonces el trabajo de recopilación de los datos necesarios para el diseño de una solución a dicha necesidad, datos que pueden ser topográficos (medición de la superficie real del terreno), hidrológicos (pluviometría de una cuenca, caudal de un río, etc.), estadísticos (aforos de las carreteras o calles existentes, densidades de población), etcétera.

Para esta finalidad los diseños de las obras y sistemas más complejos se hacen en varias etapas. La primera etapa denominada de pre-factibilidad, se encarga de analizar el mayor número de soluciones posibles. Es en esta etapa en la cual los organismos competentes decidirán por ejemplo: el emplazamiento de un puerto, el trazado general de una carretera o tomarán la decisión respecto a si construir una vía férrea para transporte de minerales o un mineroducto. Para la toma de decisiones se consideran, entre otros, los siguientes puntos de vista: dificultad de la obra; costo de la obra; impacto ambiental producido por la obra. El estudio de pre-factibilidad involucra un equipo multidisciplinario de técnicos, donde además de ingenieros civiles participan ingenieros eléctricos, mecánicos, geólogos, economistas, sociólogos, ecologistas. Como resultado de esta fase se escogen 2 o 3 soluciones para detallarlas en la etapa siguiente.

En la siguiente etapa, llamada factibilidad técnico-económica, ya se avanza mucho en los detalles constructivos, en la determinación de los costos, en el cronograma de construcción y en el flujo de caja necesario para la ejecución de la obra. En esta etapa tienen mucho peso las investigaciones de campo para detectar dificultades específicas relacionadas con la geología de las áreas en las que se intervendrá, y se detallarán los impactos ambientales, incluyendo tanto la parte física como la abiótica y la social. En general es en esta fase que se escoge la solución definitiva, que será detallada en la etapa de diseño definitivo o proyecto ejecutivo.

Viene entonces el trabajo real sobre el terreno: acondicionar éste para que sea capaz de soportar las estructuras que se van a construir sobre él (llegándose en ocasiones a sustituir el terreno por otro de mayor capacidad portante si el existente no cumple las condiciones necesarias), movimientos de tierras (desmontes y terraplenes), construcción de las estructuras (pilotes, zapatas, pilares, estribos, vigas, muros de contención).

Sin embargo, todos estos pasos rara vez se dan de forma fluida ni, mucho menos, competen a un mismo equipo de ingeniería. Así, a menudo son los ingenieros de la Administración correspondiente los que detectan la necesidad que se tratará de solventar, mientras que en otras ocasiones la obra viene incluida dentro de un plan de actuación político (no siempre con una clara justificación técnica).

Si la obra a acometer es de gran envergadura la Administración no la ejecuta, sino que sus ingenieros elaboran un anteproyecto que es sacado a subasta pública. Entonces son los ingenieros de las diferentes empresas constructoras los que, a partir de las prescripciones técnicas del anteproyecto, elaboran diferentes alternativas. Las alternativas ofrecidas por las constructoras pueden ser muy distintas al anteproyecto y entre sí, pues cada empresa hace uso de la maquinaria y procedimientos que le son más conocidos, y la Administración elegirá la más barata de las opciones que cumplan las exigencias.

Los ingenieros que lleven a cabo la obra no tienen por qué ser (ni, generalmente, son) los que la hayan diseñado. La empresa constructora puede decidir también sub-contratar diferentes trabajos a otras empresas, con lo que puede llegar a haber a diferentes empresas para una misma obra (una ejecuta los movimientos de tierras, otra las estructuras de hormigón…) cada una con su correspondiente departamento de ingeniería y su correspondiente equipo de ingenieros en obra.

Muy a menudo, debido a lo imprevisible del terreno se producen problemas a pie de obra que obligan a realizar modificaciones en el proyecto; en otras ocasiones la Administración puede decidir variar algunas condiciones o exigencias a medida que la obra se desarrolla y se observan problemas o posibilidades que no se habían estudiado o que en el momento en que se elaboró el anteproyecto no se consideraron importantes. Puede ocurrir que una nueva infraestructura obligue a hacer modificaciones o surja la posibilidad de que dos obras diferentes, construidas por empresas diferentes (por supuesto con diferentes equipos de ingenieros) sean ejecutadas en conjunto.

Todo esto puede dar idea de la gran cantidad de variables que afectan al trabajo de ingeniería civil . Por suerte, las obras de gran envergadura son raras, y más frecuentemente el ingeniero civil se limita a la supervisión de la obra y a la toma de decisiones concretas en problemas concretos que no afectan al desarrollo o presupuesto general de la obra. Así, trabajos como la contención de un terreno de características habituales, la colocación de una viga pretensada o la ejecución de un firme, son trabajos rutinarios que no implican cambios significativos en el proyecto.



</doc>
<doc id="15431" url="https://es.wikipedia.org/wiki?curid=15431" title="Linfedema después de una mastectomía">
Linfedema después de una mastectomía

Durante una tumorectomía o una mastectomía suele ser necesario extirpar algunos de los ganglios linfáticos de la axila que recogen la linfa de la región de los antebrazos, de la mayor parte de la mama, de la nuca y de la propia axila. Los ganglios linfáticos procesan los fluidos, los posibles microbios y los residuos de las infecciones. 

El brazo puede sufrir un edema linfático o linfedema cuando se alteran los ganglios o vasos linfáticos. Este daño linfático puede deberse a cirugía, a radioterapia o, más frecuentemente, a una combinación de ambas. La quimioterapia puede también contribuir al edema del brazo. 

La mujer a la que han extirpado los ganglios de la axila tiene un mayor riesgo para desarrollar linfedema, lo que puede ocurrir inmediatamente después de la cirugía, o meses o años después. No todas las mujeres que tienen una mastectomía experimentarán linfedema. 

Hay varios tipos de linfedema. El tipo agudo, temporal y suave de linfedema aparece unos pocos días después de la cirugía y usualmente dura un período corto de tiempo. Otro tipo de linfedema agudo, más doloroso, puede aparecer de 4 a 6 semanas después de la cirugía. Pero el tipo más común de linfedema tiene lugar lentamente y sin dolor, y puede tener lugar de 18 a 24 meses después de la cirugía. 

El síntoma principal del linfedema es el edema del brazo afectado. El grado de edema puede variar. Algunas personas pueden experimentar un edema grave - cuando el brazo afectado está varias pulgadas más grande que el otro brazo. Mientras que otras experimentarán una forma más suave del edema - cuando el brazo afectado está solo un poco más grande que el otro brazo.

Además del edema del brazo afectado, los siguientes son síntomas comunes en el linfedema. 

Sin embargo, cada individuo puede experimentar los síntomas de una forma diferente. Puesto que los síntomas del linfedema pueden parecerse a otras enfermedades el diagnóstico y el tratamiento deberán llevarse a cabo bajo supervisión médica. Un tratamiento conservador de elección de probada eficacia es el drenaje linfático manual.



</doc>
<doc id="15432" url="https://es.wikipedia.org/wiki?curid=15432" title="Benceno">
Benceno

El benceno es un hidrocarburo aromático de fórmula molecular CH, (originariamente a él y sus derivados se le denominaban compuestos aromáticos debido a la forma característica que poseen) también es conocido como benzol. En el benceno cada átomo de carbono ocupa el vértice de un hexágono regular, aparentemente tres de las cuatro valencias de los átomos de carbono se utilizan para unir átomos de carbono contiguos entre sí, y la cuarta valencia con un átomo de hidrógeno. Según las teorías modernas sobre los enlaces químicos, tres de los cuatro electrones de la capa de valencia del átomo de carbono se utilizan directamente para formar los enlaces covalentes típicos (2C-C y C-H) y el cuarto se comparte con los de los otros cinco átomos de carbono, obteniéndose lo que se denomina "la nube π (pi)" que contiene en diversos orbitales los seis electrones. El benceno es un líquido incoloro y muy inflamable de aroma dulce (que debe manejarse con sumo cuidado debido a su carácter cancerígeno), con un punto de ebullición relativamente alto.

El benceno se usa en grandes cantidades en los Estados Unidos. Se encuentra en la lista de los 20 productos químicos de mayor volumen de producción. Algunas industrias usan el benceno como punto de partida para manufacturar otros productos químicos usados en la fabricación de plásticos, resinas, nilón y fibras sintéticas como lo es el kevlar y en ciertos polímeros. También se usa benceno para hacer ciertos tipos de gomas, lubricantes, tinturas, detergentes, medicamentos y pesticidas. Los volcanes e incendios forestales constituyen fuentes naturales de benceno. El benceno es también un componente natural del petróleo crudo y la gasolina. Se encuentra también en el humo de cigarrillo y otros materiales orgánicos que se han quemado. Puede obtenerse mediante la destilación fraccionada del alquitrán de hulla.

Se suele mostrar, en términos de estructura de Lewis, como un hexágono, plano e indeformable, carente de tensiones de anillo (transanulares), en cuyos vértices se encuentran los átomos de carbono, con tres dobles enlaces y tres enlaces simples en posiciones alternas (1=2, 3=4, 5=6; 6-1, 2-3, 4-5; o bien 1=2-3=4-5=6-1). Esta estructura difería de la de Brønsted y Lowry.
Hay que resaltar que, acorde a los resultados de la espectrofotometría infrarroja, el benceno no posee ni simples ni dobles enlaces, sino un híbrido de resonancia entre ambos, de distancia de enlace promedio entre simple y doble (aproximadamente 1,4 Å). Estos resultados coinciden con la previsión de la TOM (teoría de orbitales moleculares), que calcula una distribución de tres orbitales enlazantes totalmente ocupados. A esta especial estabilidad se le llama aromaticidad y a las moléculas (iones o no, estables o intermedios de reacción) se les llama aromáticas.

La molécula de Benceno fue descubierta por Faraday en 1825, quien aisló por primera vez a partir del gas de alumbrado el compuesto, de fórmula empírica CH. Fue Eilhard Mitscherlich quien logró medir su masa molecular a partir de su presión de vapor, estableciéndola en 78 u, lo que correspondía a una fórmula molecular C6H6. El compuesto se había obtenido de la goma benjuí, lo que llevó a que se denominase bencina, y posteriormente benceno.

Inicialmente se propusieron formas abiertas (alifáticas) para la cadena de benceno, con dos triples enlaces, sin embargo los datos experimentales que se obtenían a partir de sus reacciones eran contradictorios con estos modelos abiertos, dado que presentaba un número inusualmente bajo de isómeros. Así, por ejemplo, la monobromación del compuesto presentaba un único isómero, al igual que ocurría con la nitración. Por otro lado no respondía a las adiciones habituales de nucleófilos a enlaces múltiples.

Esto llevó a que se propusieran diversas estructuras para comprender estos hechos, como la de Dewar, la de Klaus o la de Kekulé.
Sin embargo, la estructura de Kekulé seguía presentando una incompatibilidad con la malformación 1,2 de la molécula dado que deberían formarse dos isómeros (isómeros ortobencénicos), uno de ellos con el bromo sobre un doble enlace y el otro con ambos bencenos sobre un enlace simple. Esto llevó a Kekulé a proponer que el benceno alternaba entre dos formas, en las que los enlaces cambiaban continuamente de posición, por lo que únicamente se detectaría un isómero.

La representación de los tres dobles enlaces se debe a Friedrich Kekulé, quien además fue el descubridor de la estructura anular de dicho compuesto y el primero que lo representó de esa manera.

De todas formas, fue el , Linus Pauling quien consiguió encontrar el verdadero origen de este comportamiento, la resonancia o mesomería, en la cual ambas estructuras de Kekulé se superponen.

Normalmente se representa como un hexágono regular con un círculo inscrito para hacer notar que los tres dobles enlaces del benceno están deslocalizados, disociados y estabilizados por resonancia. Es decir, no "funcionan" como un doble enlace normal sino que al estar alternados, esto es, uno sí y uno no, proporcionan a la molécula sus características tan especiales. Cada carbono presenta en el benceno hibridación sp. Estos híbridos se usarán tanto para formar los enlaces entre carbonos como los enlaces entre los carbonos y los hidrógenos. Cada carbono presenta además un orbital P adicional perpendicular al plano molecular y con un electrón alojado en su interior, que se usará para formar enlaces π.

La reacción típica del benceno es la de sustitución aromática que sigue dos caminos alternativos:

Las reacciones de sustitución aromática más corrientes son las originadas por reactivos electrofílicos. La capacidad del benceno para actuar como un donador de electrones se debe a la polarización del núcleo bencénico. Las reacciones típicas del benceno son las de sustitución. Los agentes de sustitución utilizados con más frecuencia son:

El cloro y el bromo dan derivados por sustitución de uno o más hidrógenos del benceno, que reciben el nombre de haluros de arilo.

formula_1

formula_2

La halogenación está favorecida por las bajas temperaturas y algún catalizador, como el hierro, el tricloruro de aluminio u otro ácido de Lewis, que polariza al halógeno para que se produzca la reacción. En el caso del bromobenceno se utiliza FeBr como catalizador.

Cuando los hidrocarburos bencénicos se tratan con ácido sulfúrico concentrado, que es una mezcla de (HSO) y (SO), se forman compuestos característicos que reciben el nombre ácidos sulfónicos. El electrófilo que reacciona puede ser HSO o SO. Es la única reacción reversible de las que estamos considerando.

El ácido nítrico fumante o una mezcla de ácidos nítrico y sulfúrico, denominada mezcla sulfonítrica, (una parte de ácido nítrico y tres de sulfúrico), produce derivados nitrados, por sustitución. El ácido sulfúrico protona al ácido nítrico que se transforma en el ion nitronio positivo (NO) que es el agente nitrante efectivo:

Este proceso se efectúa haciendo reaccionar el benceno con ácido nítrico y usando como catalizador ácido sulfúrico, mezcla que se conoce como sulfonítrica, generándose el ión nitronio NO, que actúa como agente electrofílico a una temperatura entre 50 a 60 °C, produciéndose en este proceso el nitro benceno y agua

El benceno es inflamable y arde con llama fuliginosa, propiedad característica de la mayoría de los compuestos aromáticos y que se debe a su alto contenido en carbono.

formula_5

El anillo de benceno puede ser reducido a ciclohexano, con hidrogenación catalítica (por ejemplo, usando níquel Raney) a alta presión, manteniendo así la estructura de la cadena cerrada. La reducción parcial se puede llevar a cabo por medio del método de Birch para formar ciclohexadienos. 

El benceno reacciona con los haluros de alquilo, en presencia de cloruro de aluminio anhidro (AlCl) como catalizador, formando homólogos.

formula_6

El ataque sobre el anillo bencénico por el ion CH es semejante al realizado por el ion Cl en la cloración.

Es una modificación de la de Wortz de la serie grasa. Los homólogos del benceno pueden prepararse calentando una solución etérea de un halogenuro de alquilo y otro de arilo con sodio.
Este método tiene la ventaja sobre el de Friedel–Crafts, de que se conoce la estructura del producto y puede introducirse fácilmente cadenas largas normales.

Cuando se introduce un segundo sustituyente y en un derivado del benceno del tipo CHX, la posición que ocupa Y depende del carácter electrónico del grupo X, que ya está presente en el núcleo. Los productos de la reacción pueden ser orto y para o meta disustituidos y eso depende de la velocidad de la reacción de sustitución en cada una de las tres posiciones.

Hay unas reglas de orientación:

Hay un método sencillo de orientación para los derivados disustituidos que fue establecido por Körner. Frecuentemente es llamado método 2,3,1 de Körner. Se basa en el principio de que la introducción de un tercer sustituyente en un compuesto "para" proporciona un producto trisustituido, en el isómero "orto" dos y en el "meta" tres. Körner aplicó este principio para establecer la orientación de los dibromobencenos isómeros. Nitró cada uno de ellos y examinó el número de productos nitrados. El isómero que dio un solo dibromo-nitrobenceno es el "para"; el que dio dos derivados nitrados, el "orto", y el tercero que dio tres, es el compuesto "meta".

Los hidrocarburos como el tolueno, etilbenceno, etc., tienen carácter alifático y aromático. El benceno es no polar, lo mismo que el metano, siendo cero el momento dipolar de cada uno de estos compuestos. Sin embargo, el tolueno tiene un pequeño momento dipolar (aproximadamente 0,4 D) con la carga negativa sobre el núcleo y la positiva sobre el grupo metilo. Los alquilbencenos experimentan la cloración y bromación, ya sea en el núcleo o en la cadena lateral, según sean las condiciones de la reacción. Para denominar las posiciones relativas del benceno, véase Patrones de sustitución en hidrocarburos aromáticos.

Respirar niveles de benceno muy altos puede causar la muerte, mientras que niveles bajos pueden causar somnolencia, mareo y aceleración del latido del corazón o taquicardia. Comer o tomar altos niveles de benceno puede causar vómitos, irritación del estómago, mareo, somnolencia o convulsiones y, en último extremo, la muerte.

La exposición de larga duración al benceno se manifiesta en la sangre. El benceno produce efectos nocivos en la médula ósea y puede causar una disminución en el número de hematíes, lo que conduce a padecer anemia. El benceno también puede producir hemorragias y daños en el sistema inmunitario, aumentando así las posibilidades de contraer infecciones por inmunodepresión.

Los efectos nocivos del benceno aumentan con el consumo de bebidas alcohólicas.

Algunos estudios sobre una muestra de mujeres que respiraron altos niveles de benceno durante varios meses han revelado que presentaron menstruaciones irregulares, así como disminución en el tamaño de sus ovarios. No se sabe si la exposición al benceno afecta al feto durante el embarazo. Varios estudios en animales han descrito bajo peso de nacimiento y problemas en la formación de huesos.

El Departamento de Salud y Servicios Sociales de los Estados Unidos (DHHS) ha determinado que el benceno es un reconocido carcinógeno en seres humanos y otros mamíferos lactantes. La exposición de larga duración a altos niveles de benceno en el aire puede producir leucemia así como cáncer de colon.

En el organismo, el benceno es transformado en productos llamados metabolitos. Ciertos metabolitos pueden medirse en la orina o en las heces. Sin embargo, este examen debe hacerse con celeridad después de la exposición y el resultado del análisis no indica a que concentración de benceno se estuvo expuesto, ya que los metabolitos en la orina pueden originarse a partir de otras fuentes.

El benceno se utiliza como constituyente de combustibles para motores, disolventes de grasas, aceites, pinturas y nueces en el grabado fotográfico de impresiones; como intermediario químico, y en la manufactura de detergentes, explosivos y productos farmacéuticos.




</doc>
<doc id="15435" url="https://es.wikipedia.org/wiki?curid=15435" title="Tipos anatomopatológicos de cáncer de mama">
Tipos anatomopatológicos de cáncer de mama

Los carcinomas de mama pueden encontrarse en dos formas principales según su origen. Un noventa por ciento, aproximadamente, tienen su origen en el epitelio ductal. El restante diez por ciento, en las células de los acinos glandulares. El primer tipo, además, puede presentarse en formas variadas que suelen clasificarse como subtipos, existiendo distintos tipos de rasgos anatomopatológicos, macroscópicos y microscópicos, que los distinguen. La clasificación puede presentarse como sigue:

Distribución:



</doc>
<doc id="15436" url="https://es.wikipedia.org/wiki?curid=15436" title="Zarzuela">
Zarzuela

La zarzuela es una forma de música teatral o género musical escénico surgido en España que se distingue principalmente por contener partes instrumentales, partes vocales (solos, dúos, coros...) y partes habladas, aunque existen excepciones en las que estas últimas, las partes habladas, están completamente ausentes. El término «zarzuela», aplicado al género musical y teatral, procede del Palacio de la Zarzuela, palacio real español situado en las proximidades de Madrid y en el que se hallaba el teatro que albergó las primeras representaciones del género.

De una manera reductora y errónea se ha asimilado la zarzuela a la opereta, género de origen francés, principalmente por contener partes habladas o declamadas, pretendiendo así que «la zarzuela es la opereta española». Pero la zarzuela es históricamente muy anterior y esa característica ya se encontraba en otros géneros europeos, también muy anteriores a la opereta y no necesariamente anteriores a la zarzuela. En realidad en ese sentido la zarzuela sería más bien el equivalente español del "opéra-comique" francés o del "singspiel" alemán. Dichos géneros de Francia y del mundo germánico se caracterizan por producir representaciones teatrales y musicales en las que, a diferencia de la ópera propiamente dicha, se alterna música con partes habladas o declamadas. "La flauta mágica" de Mozart, por ejemplo, no es una ópera sino un "singspiel" y, por consiguiente, tanto sentido tiene decir que «la zarzuela es la opereta española» como decir que «el "singspiel" es la zarzuela vienesa». A pesar de todo, ha habido zarzuelas del género grande que por no tener partes habladas son parecidas al "grand opéra" francés o a la ópera seria italiana. Por lo tanto la zarzuela se definiría de una manera más adecuada, y más simple, como el arte lírico y escénico propiamente hispánico, pues aunque naciera en España, al poco tiempo de su aparición se extendió a la casi totalidad del mundo hispánico.

Parece ser que los primeros autores que aportaron a este nuevo estilo de teatro musical fueron Lope de Vega y Calderón de la Barca. Según las investigaciones, Calderón de la Barca es el primer dramaturgo que adopta el término de zarzuela para una obra suya titulada "El golfo de las sirenas" que se estrenó en 1657 y que interpretaba la vida de un joven aventurero que emprendía un largo viaje lleno de misterios y peligros.

Lope de Vega escribió una obra que tituló "La selva sin amor", comedia con orquesta. Según el autor era «cosa nueva en España». En el prólogo de 1629 de esta obra se dice: «Los instrumentos ocupaban la primera parte del teatro, sin ser vistos, a cuya armonía cantaban las figuras los versos en aquella frondosa selva artificial, haciendo de la misma composición de la música las admiraciones, quejas, iras y demás afectos…». Sin embargo, sólo se conserva la música suficiente en la obra "Los celos hacen estrellas" de Juan Hidalgo de Polanco y Juan Vélez de Guevara, que se estrenó en 1672. Con esta obra se puede tener una idea de cómo era este género en el siglo XVII y como marcó la diferencia para las siguientes doctrinas del género. 

El siglo XVIII da entrada a la dinastía de los Borbones; con ellos se pusieron de moda los estilos italianos en diversas manifestaciones artísticas, incluida la música y la danza en los centros de convivencia de la plebe. Las zarzuelas del siglo XVIII se convirtieron en obras estilísticamente parecidas a las óperas italianas: por ejemplo, las obras de Antonio de Literes. Pero al llegar el reinado de Carlos III, amante de las buenas representaciones teatrales, los problemas políticos provocaron una serie de revueltas contra los ministros italianos llevando el conflicto a la toma de ayuntamientos y disturbios frecuentes (como, por ejemplo, el motín de Esquilache) (i.e. Squillace), hecho que repercutió en las representaciones teatrales y de nuevo imperó la tradición popular española representada, en esta ocasión, por los sainetes de don Ramón de la Cruz. La primera obra de este autor representada en este género fue "Las segadoras de Vallecas" (1768), con música de Rodríguez de Hita.

El auge de la zarzuela y su fama le llegó en el siglo XIX, a partir de 1839, con varios músicos entre ellos destacan Francisco Barbieri y Emilio Arrieta. Muchas veces el éxito de la obra se debía a una o más canciones que el público aprende y da a conocer oralmente a los demás por medio de representaciones acústicas, como ocurría con los cuplés. El engranaje de la obra siguió siendo el mismo: números hablados, cantados, coros, que se aderezan con escenas cómicas o de contenido amoroso que, generalmente, son interpretadas por un dúo. Abundaba el género costumbrista y regionalista y en los libretos se recogía toda clase de modismos, regionalismos y jerga popular para asegurar que la interpretación fuera un éxito.

Contrario a las escenas españolas de cortes o aldeas, la zarzuela cubana describía imágenes y costumbres de la época colonial, utilizando las suaves cadencias musicales que dan a Cuba tanto reconocimiento mundial. Tema popular era el señorito rico, hijo del dueño del ingenio, que aunque comprometido con una joven de su clase, cortejaba a la joven mulata, zalamera y atrevida, con quien tenía amores prometiéndole matrimonio. El final era por lo general truculento, con desengaños, pasión, celos y lágrimas. Estos impresionantes finales no restaban un ápice a la belleza de la música, antes bien ponían énfasis en las habilidades y talentos histriónicos y musicales de los artistas de la interpretación teatral y musical del Divino Maestro.

En ésta época de mediados del siglo se divide en género chico, (zarzuelas de un solo acto) y género grande (zarzuelas de dos, tres o más actos). Se adoptan temas costumbristas, populares, cómicos y bailes españoles. Algunos músicos respetados de esta época son Emilio Arrieta, Federico Chueca, Fernández Caballero, Tomás Bretón y Ruperto Chapí. 

Después de la Revolución de 1868, el país entró en una profunda crisis (sobre todo económica) que se reflejó también en el teatro. El espectáculo teatral era caro y ya no se podían pagar aquellos precios. Fue entonces cuando el Teatro Variedades de Madrid tuvo la idea de reducir el precio del espectáculo y, al mismo tiempo, la duración de la representación. Una función teatral duraba, por aquel entonces, cuatro horas y se redujo a una hora. Fue lo que se llamó teatro por horas. La innovación tuvo un gran éxito y los compositores de zarzuelas se acomodaron al nuevo formato creando obras mucho más cortas pero el verdadero triunfo tardó diez años hasta 1879. A las zarzuelas de un solo acto se las clasificó como Género chico y Género grande a las zarzuelas de dos, tres actos o más. La zarzuela grande fue batallando en el Teatro de la Zarzuela de Madrid, pero con poco éxito y poco público. A pesar de esto, en 1873 se abrió un nuevo teatro Apolo de Madrid, que compartió los fracasos con el anterior, por querer hacerle un lugar para el drama y la comedia, hasta que no tuvo más remedio que cambiar el espectáculo al género chico en el que triunfó durante décadas.

 En los primeros años del siglo XX, se componen obras de mayor calidad musical como "El puñao de rosas", "La alegría del batallón", "El trust de los tenorios" en el género chico y "Doña Francisquita" de Amadeo Vives, "La calesera" o, un poco antes (en 1898), "Gigantes y Cabezudos" del maestro Manuel Fernández Caballero, que supo ganarse muy bien a la crítica componiendo una obra muy del "gusto popular".

La zarzuela se va manteniendo con estas producciones que, a veces, se ajustan a la estructura musical de una ópera italiana, gracias a autores de la talla de Francisco Alonso, José Padilla, Pablo Sorozábal, Federico Moreno Torroba, Tomas Barrera Saavedra, Rafael Calleja, Pablo Luna, José Serrano Simeón y Jacinto Guerrero. La guerra española abre un paréntesis nefasto que acaba por agravar el mismo problema que había los años anteriores y en la posguerra, la decadencia es casi total. No existen apenas nuevos autores para este género y no se renuevan las obras por no cuajar los estrenos como lo hicieron en otras épocas. Por otro lado, la zarzuela existente es difícil y costosa de representar y sólo aparece de forma esporádica, por temporadas, durante unos pocos días o semanas.

En estos primeros años del siglo se empieza a dar el apelativo de "género ínfimo" a las representaciones conocidas como revistas. Son obras musicales con conexión a algunas ideas de la zarzuela pero más ligeras y atrevidas, con números escénicos que, en la época, se calificaron de «verdes», es decir, pícaros para los tiempos de hoy, que hablaban o ponían sobre la mesa la evolución de la sociedad sobre temas sexuales y con letras de doble intención, en casi todas hay "cuplés". Una de estas obras fue "La corte de Faraón", basada en la opereta francesa "Madame Putiphar". La música se hizo tan popular que algunos de sus números acabaron siendo verdaderos cuplés difundidos por el público.

La zarzuela se cultivó con muchos aciertos al trasladarse a Cuba, donde destacaron los compositores Gonzalo Roig y Ernesto Lecuona, y Rodrigo Prats, Eliseo Grenet, Argentina, en cuya capital hasta en 3 teatros se representaba "La verbena de la Paloma" el año de su estreno y a Venezuela, con José Ángel Montero y Pedro Elías Gutiérrez.

En Argentina, la zarzuela, el sainete y el tango conformaron un nuevo género peculiar de gran éxito popular conocido como sainete criollo.

En Filipinas, la popularidad de las zarzuelas cedió a la indigenización de este género. Durante la colonización norteamericana, las "sarswelas" (la forma indígena) fueron una forma mayor de mostrar resistencia a fuerzas extranjeras. Honorata 'Atang' de la Rama fue conocida como la Reina de la Sarswela Filipina. Esta forma de la Arte se llama también "zarzuelta" en varios lugares del país.

Los siglos XIX y XX fueron épocas de gran producción de zarzuelas en la Hispanoamérica, en especial en Venezuela, Cuba, México y Argentina, de donde salieron grandes obras que todavía son presentadas internacionalmente como "El cumpleaños de Leonor", de Montero que era la historia de una mujer mayor que al descubrir la traición de su marido buscaba una vida mejor en la gran ciudad; "María la O" de Ernesto Lecuona y "La media naranja" del íberoargentino Antonio Reynoso.

En Argentina la zarzuela comenzó a difundirse en la segunda mitad del siglo XIX en el mismo momento en que se generaba el tango, a partir de la fusión de diversos estilos locales, de origen africano, gaucho e indígena, y otros aportados por contingentes inmigratorios de diferentes partes del mundo que estaban llegando en gran cantidad al país.

La zarzuela, como género específico, tuvo mucho éxito popular hasta la segunda mitad del siglo XX. Varios músicos argentinos compusieron zarzuelas, como Carlos López Buchardo con "Amalia", "La Pericona" y "Madame Lynch". Antonio Videgain García que vivió allí compuso alguna obra de este corte y Francisco Alonso, por su parte, compuso "Manuelita Rosas" (1941), una zarzuela ambientada en Argentina.

Pero la zarzuela además fue una importante influencia en la gestación del tango. De hecho, la primera vez que se usó la palabra "tango" para nombrar al género musical, fue en una zarzuela, "Justicia Criolla" de Ezequiel Soria.

Pero además la zarzuela fue una de las fuentes del tango, dando lugar al tango "azarzuelado", a la vez que influyó en la creación de un género dramático-musical de Argentina, que adoptó el nombre de "sainete criollo", designado a excepcionalmente también como "zarzuela criolla", que tuvo enorme éxito popular, con obras destacadas como "El conventillo de la Paloma" de Alberto Vacarezza.

La zarzuela llegó a las Filipinas en 1879 o 1880, cuando el grupo de Dario de Céspedes presentó el Juego de fuego en Manila. Desde entonces, varios grupos filipinos comenzaron a hacer su propias zarzuelas en varios idiomas indígenas. Las más populares fueron escritas en tagalo, pampangueño, ilocano, cebuano, panayano y samareño.

La primera sarswela conocida en samareño es "An Pagtabang ni San Miguel" (El Ayuda de San Miguel) de Norberto Romualdez, mientras "Ing Managpe" de Mariano Proceso Pabalan Byron es la primera en pampangueño. El héroe nacional José Rizal, músico además de literato, es autor de la zarzuela llamada "Junto al Pásig".

A la llegada del vodevil, las sarswelas perdieron su popularidad, pero renovaron su éxito con la llegada del cine. Muchas sarswelas, principalmente las tagalas, se filmaron para el cine.

A partir de 1950 la zarzuela pudo sobrevivir en el gusto popular gracias a la discografía, un campo que se mantuvo en auge desde entonces. Se produjeron una serie de grabaciones de gran éxito, la mayoría de ellas dirigidas por el músico español Ataúlfo Argenta colaborando músicos tan respetados como Mary Carmen Alvira o Julián Parera. Las mejores voces del momento aparecieron en estos discos, cantantes mundialmente famosos que profesionalmente se dedicaban a la ópera y a los recitales. Voces como las de Teresa Berganza, Ana María Iriarte, Carlos Munguía, etc., participaron en las grabaciones. Se añadieron los coros del Orfeón Donostiarra y Coro de Cantores de Madrid contribuyendo a darles una gran calidad. Pero por otro lado enturbió el recuerdo de los cantantes del estreno que empezaron a no ser recordados como los participes del éxito de esas obras.

Tras la muerte de Ataúlfo Argenta se incorporaron los directores Indalecio Cisneros, García Asensio, y otros. Incluso hubo grabaciones raras porque fueron dirigidas por el propio autor de la obra por el motivo que argumente anteriormente, como fue el caso de Pablo Sorozábal y Federico Moreno Torroba. En esta etapa participaron en las grabaciones nuevas y grandes voces consagradas: Monserrat Caballé, Alfredo Kraus, Plácido Domingo, Juan Pons, etc.

Durante los años 60, Radio Televisión Española inició la producción de una serie de zarzuelas interpretadas por conocidos actores del momento, tales como José Moreno, Antonio Casal, Juan Luis Galiardo, María Cuadra y María José Alfonso), con buenas direcciones musicales, normalmente a cargo de Federico Moreno Torroba, y utilizando voces o cubriendo sus deficiencias con el doblaje por artistas líricos de reconocido prestigio como Alfredo Kraus o Luis Sagi Vela para los números vocales, grabados con la técnica del "playback". Muchas de ellas fueron dirigidas por Juan de Orduña y se emplearon, en lo posible, escenarios naturales para la grabación de las mismas, lográndose obras de notable calidad, especialmente en el apartado musical. Con este sistema se grabaron, por ejemplo:

En los últimos años de 1970 se reaviva el interés por la zarzuela, en especial por su música. En toda Europa se desencadena un renacer de la afición por los espectáculos líricos, sobre todo entre la juventud. Este renacimiento repercute en España que muestra un gran interés por la zarzuela. El empresario José Tamayo pone en escena un espectáculo teatral de gran producción hacia tiempo olvidado, "Antología de la zarzuela", representando los fragmentos más populares del repertorio de zarzuela moderna con cantantes de primera línea, montaje que se mantiene durante décadas renovando los números incluidos. Las casas discográficas ofrecen colecciones cuyos discos van acompañados de un fascículo que contiene la sinopsis de la obra y algunos datos del autor. La radio y la televisión dedican varios espacios a su programación. Los programas que TVE ofreció con el título de "Antología de la Zarzuela", basados en playbacks de las grabaciones de mediados de siglo representados en estudio de TV con vestuarios y baile, gozaron de una gran audiencia. En cuanto a los años más recientes, según datos de la SGAE en 2006 la zarzuela experimentó un aumento de más de un 4%.
Además, la Fundación Autor se ha unido con la Fundación de la Zarzuela para la promoción de la zarzuela entre nuevos públicos con los proyectos "Zarzuela en femenino", con las sopranos Isabel Segarra y Sonia Martínez, presentado en Málaga en 2014 y "Zarzuela en masculino", en producción.






</doc>
<doc id="15437" url="https://es.wikipedia.org/wiki?curid=15437" title="Diagnóstico del cáncer de mama">
Diagnóstico del cáncer de mama

El diagnóstico de certeza del cáncer de mama requiere el examen microscópico de una muestra del tejido mamario sospechoso (biopsia). La biopsia, sin embargo, es tan solo el último escalón en una cadena de procedimientos cuyo objetivo en separar los estudios mamarios en dos grupos principales: los que presentan algún grado de sospecha de cáncer y los que no. 

La anamnesis (interrogatorio) seguida del examen físico o exploración física de la mama es el primer paso que se da para identificar si hay indicios de enfermedad. 

Dentro del interrogatorio es de suma importancia investigar si la paciente tiene familiares directos que han tenido cáncer de mama (madre, hermana), si ha tenido tumores benignos en mama, si su menstruación fue de inicio temprano (12 años o menos) y su menopausia tardía (mayor de 50 años), si ha tomado anticonceptivos, si fuma; ya que todos estos se han identificado de cierta forma como factor de riesgo del cáncer de mama. Después de eso, se debe averiguar si la paciente ha tenido dolor mamario (mastalgia) o ha presentado alguna tumoración.

Posteriormente sigue la exploración física que la paciente la debe autorealizar cada mes. Un médico con experiencia también deberá explorarla al menos cada 6 meses. Se deben buscar tumoraciones, deformidades en piel, en pezones o bien tumoraciones por arriba o abajo de la clavícula o en axila.

A continuación, si ha sido posible obtener algún dato que lo justifique, debe recurrirse a algunas de las siguientes técnicas de diagnóstico por imagen:


La mamografía por rayos X, es un estudio que proporciona imágenes radiológicas en varias proyecciones, obtenidas en un aparato de rayos X que ha sido diseñado especialmente para estudiar las mamas. Otras técnicas, como la galactografía, la neumoquistografía y la neumooncografía, representan variantes de la mamografía en las que se asocian técnicas invasivas para precisar el estudio de determinadas alteraciones.

La ecografía mamaria es una técnica de diagnóstico por imagen que complementa a otras, su principal utilidad consiste en la distinción de la naturaleza sólida o quística de lesiones nodulares identificadas en la mamografía. También es de utilidad en el estudio de mama con un componente glandular importante que condiciona una elevada densidad de la imagen mamogràfica, dificultando la discriminación de posibles lesiones. Permite una medición muy precisa del tamaño de los nódulos mamarios y es de gran utilidad para guiar punciones para obtener material celular o tisular para examen citológico o biópsico que permitan el estudio y diagnóstico histo-patológico. 

El Mamógrafo de impedancia eléctrica a través del cálculo de la conductividad eléctrica de los tejidos, proporciona información importante sobre procesos fisiológicos y patológicos en la glándula mamaria, que permite diagnosticar el riesgo de cáncer, FCD [Fibro Cystic Disease, según sus siglas en inglés] (enfermedad fibroquística), mastitis, involución fisiológica, evaluación de la lactancia, etc.

La mamografía de impedancia eléctrica permite ver la distribución de la conductividad del tejido biológico en varias secciones trasversales de la glándula y detectar tumores visualizándolos como área con valores anormales de conductividad eléctrica. El principio es sustentado por una suposición de que los tumores malignos de la glándula mamaria muestran una conductividad eléctrica mucho mayor (habilidad del paso de la corriente eléctrica) que aquella de los tejidos sanos circulantes.
Este tipo de tecnología es sin dolor, sin radiación y se puede utilizar en pacientes de cualquier edad entre otros beneficios, su diagnóstico es de alta eficacia ya que da un resultado tanto cualitativo como cuantitativo.

Es ideal para la detección oportuna del cáncer de mama, ya que aparte de ser rápido en su aplicación es la mejor herramienta en su tipo, para realizar Cribado o Tamizaje de una marea rápida y segura.

La resonancia magnética y la T.E.P. (o P.E.T.) tienen importancia en casos concretos y su empleo, en la actualidad, no es rutinario. Sin embargo, las indicaciones de su empleo van ampliándose cada vez más. Las principales indicaciones de la resonancia son el seguimiento de cambios cicatrizales mamarios intensos post quirúrgicos, el estudio de multicecentricidad del cáncer mamario, la valoración de la extensión local para apoyar o contraindicar el tratamiento conservador y el estudio de complicaciones de prótesis mamarias. 

Cuando se obtiene una mamografía, el radiólogo examina cuidadosamente las imágenes obtenidas buscando ciertos signos radiológicos que son conocidos como indicadores probables de patología. Las imágenes pueden visualizarse de manera analógica, utilizando como soporte una película radiográfica especial para mamografía; o bien de manera digital, utilizando sistemas informáticos.


</doc>
<doc id="15440" url="https://es.wikipedia.org/wiki?curid=15440" title="Ilusionismo">
Ilusionismo

El ilusionismo, vulgarmente denominado magia, es un arte escénico, subjetivo, narrativo y espectáculo de habilidad e ingenio, que consiste en producir artificialmente efectos en apariencia maravillosos e inexplicables mientras se desconoce la causa que los produce. Estos efectos (desapariciones, transformaciones, uniones, lecturas de la mente, etc), que fingidamente hacen parecer realidad lo imposible, se conocen como efectos, juegos de magia, ilusiones y vulgarmente como trucos de magia.

Dentro de la magia caben diversas especialidades: fantasistas, prestidigitadores, prestímanos, cartománticos, escamoteadores y reyes de la evasión con o sin ataduras, que protegen sus trucos con el compromiso del secreto profesional.

Conocido bajo los diversos nombres de "magia simulada", "magia blanca" o "escamoteo", el ilusionismo se remonta a la más lejana antigüedad.

Los primeros datos escritos y documentados de magia vienen de Egipto, hace más de 4000 Años.Un dibujo en la pared de una cámara mortuoria de la ciudad de Beni Hassan —trazado probablemente 2200 años antes de Cristo— representa a dos hombres dedicados a realizar con unos cuencos en forma de copa lo que parece un truco de ilusionismo. Los jeroglíficos que indican salida de debajo dan la impresión de confirmar que debajo de una de las vasijas se encuentra una bola o algún pequeño objeto redondo, a punto de aparecer en forma mágica.

Henry Westcar, un aventurero británico, descubrió en 1825 el papiro Westcar, primer documento que describe una función mágica realizada por el mago Dyedi en la corte real de Khufu (Keops). El papiro ilustra la categoría única y especial de la que gozaba el arte del ilusionismo. Según aquel texto, Dyedi era toda una leyenda entre los hombres. Se le atribuían ciento diez años de edad y unos apetitos que rivalizaban con los dioses. Su mera presencia inspiraba temor a los hombres normales. Hasta el faraón omnipotente solicitó que compareciese ante él.

De su actividad nómada y feriante constan testimonios en manuscritos del siglo X y entre sus primeros grandes especialistas figuran el maestro Gonin (finales del s. XVI), fundador de una dinastía de magos.

Asimilados a los "hombres de ciencia", utilizaron autómatas y otros artefactos antes de que en el s. XVIII incorporasen la electricidad y otros adelantos científicos para ampliar su repertorio de trucos, que presentaban bajo el nombre de "física" y de donde nació la física recreativa. La consolidación de esta profesión se produjo en el s. XVIII, dando lugar a la aparición de los "teatros de magia" (Robertson, Robert-Houdin). En un principio, el repertorio se reducía sobre todo al "escamoteo" (hacer desaparecer un objeto para encontrarlo en otro lugar distinto de aquel en que debiera estar o hacer aparecer otro en su lugar), pero se amplió luego con trucos complejos de "gran magia".

El más célebre mago y escapista del siglo XIX (y posiblemente de todos los tiempos) fue Harry Houdini (1874-1926), tomó su nombre profesional de Harry Keller y del mencionado Robert-Houdin, y desarrolló una serie de ilusiones de magia escénicas, basadas muchas de ellas en el arte del escape.

A finales del siglo XX, el ilusionismo volvió a tener auge de la mano de Doug Henning primero, y David Copperfield después, a través de sus especiales televisivos, espectáculos en Broadway y giras internacionales.



San Juan Bosco (1815-1888) es el patrón de los ilusionistas. Fueron los mismos magos quienes en un congreso internacional celebrado en Segovia (España), lo escogieron como modelo y protector, a mediados del siglo XX.

Don Bosco, como tradicionalmente se le conoce, fue un sacerdote moderno, cercano a los jóvenes más pobres, que supo ganarse la amistad de éstos con técnicas inspiradas en el ilusionismo, así logró evitar que muchos fueran a la cárcel y que tomaran en su vida el buen camino.

Se suele clasificar el ilusionismo según diferentes conceptos en función de la distancia a los espectadores, número de ellos y localización de la presentación:

En función de los objetos utilizados:

En función de los tipos de efectos:

Los objetos más comunes a la hora de robar en un espectáculo de pickpocketing son: relojes, carteras, corbatas, cinturones, gafas, pañuelos, teléfonos móviles... es decir, cualquier objeto que pueda llevarse en los bolsillos tanto de la chaqueta o camisa, como de los pantalones.

Por lo general, este tipo de demostraciones suelen ser cómicas y hechas en escenario, por lo que el objeto es devuelto a la supuesta víctima al terminar el número.

Como en toda profesión existe un día en el año para celebrar el ejercicio de la misma, para la magia es el 31 de enero el día internacional del mago. Otros magos lo celebran el 31 de octubre, fecha en que conmemoran el fallecimiento de Harry Houdini.

El ilusionista realiza un efecto que el espectador percibe como maravilloso, contrario a las leyes naturales o al sentido común, y cuya causa le parece desconocida e inexplicable. Entre los posibles efectos mágicos que se pueden realizar están:






</doc>
<doc id="15442" url="https://es.wikipedia.org/wiki?curid=15442" title="Johann Strauss (hijo)">
Johann Strauss (hijo)

Johann Strauss II (St. Ulrich, Viena, Austria, 25 de octubre de 1825 - Viena, 3 de junio de 1899) fue un compositor austriaco conocido especialmente por sus valses, como "El Danubio azul". Hijo del compositor Johann Strauss I y hermano de los compositores Josef Strauss y Eduard Strauss, Johann II es el más famoso de la familia Strauss. Fue conocido en su vida como «el rey del vals» y a él se debe en gran medida la popularidad del vals en la Viena del siglo XIX. Revolucionó el vals, elevándolo de una danza campesina a una de entretenimiento apta para la Corte Imperial de los Habsburgo. Sus obras gozan de mayor popularidad que las de sus predecesores, como su padre y Josef Lanner. Algunas de sus polcas y marchas son también muy conocidas, así como su opereta "Die Fledermaus" ("El Murciélago").

El único familiar que le prestó su apoyo fue su madre. Por el contrario, al ser descubierto por su padre, Johann recordaría «una desagradable y violenta escena» y que su padre «no quería saber nada de sus planes musicales»". Al parecer, en lugar de evitar que Strauss se convirtiera en su rival, el padre quería apartar a su hijo de los rigores de la vida de músico. Fue entonces cuando Strauss padre abandonó a la familia y encontró una amante, Emilie Trampusch, cuando Johann tenía 17 años y había decidido concentrarse plenamente en la carrera de compositor con la ayuda de su madre.

Entonces Strauss comenzó a estudiar contrapunto y armonía con el profesor Joachim Hoffmann, quien poseía una escuela privada de música. Su talento fue reconocido asimismo por el compositor Josef Drechsler (también escrito Drexler), quien le enseñó ejercicios de armonía. Su otro maestro de violín fue Anton Kollmann, rèpètiteur del ballet de la Ópera de la Corte de Viena. Armado con esto, el mismo día que su madre había solicitado el divorcio de su marido, se presentó ante las autoridades vienesas para actuar en público. Inicialmente formó una pequeña orquesta, contratando a algunos músicos de la taberna «Zur Stadt Belgrad».

La influencia de Johann Strauss I en varios establecimientos de entretenimiento significó que muchos de ellos fueron cautelosos en ofrecer un contrato al joven Strauss, temiendo el enojo del padre. Strauss hijo fue capaz de persuadir al Casino Dommayer en Hietzing, Viena, para que hiciera su debut. La prensa local se apresuró a divulgar la noticia de Strauss contra Strauss, rivalidad entre padre e hijo. Strauss padre, encolerizado con su hijo y ante la desobediencia del propietario, se negó a tocar nunca más en el Casino Dommayer, que había sido el escenario de sus anteriores triunfos.

Strauss encontró muchas dificultades en sus primeros años como músico, pero pronto ganó audiencia amante de la música, tras haber aceptado comisiones para actuar fuera de Viena. El primer gran reconocimiento para el joven compositor fue la posición de Maestro de Capilla del Segundo Regimiento de Ciudadanos de Viena, que había quedado vacante tras la muerte de Josef Lanner dos años antes. Viena fue asolada por una revolución burguesa el 24 de febrero de 1848, y la rivalidad entre padre e hijo se hizo mucho más evidente.

Johann II decidió apoyar a los revolucionarios, como lo ponen de manifiesto los títulos de dos obras que datan de este período, los valses "Freiheitslieder" ("Canciones de Libertad") op. 52 y "Burschenlieder" ("Canciones de los Jóvenes") op. 55, así como las marchas "Revoluciones de Marzo" op. 54 y la agitada "Marcha de los Estudiantes" op. 56. Esta decisión demostró serle desfavorable profesionalmente, ya que la realeza austriaca le negó dos veces la tan codiciada posición de "KK Hofballmusikdirecktor" (Director Musical del Baile de la Corte), posición que fue dada a Johann I en reconocimiento a sus contribuciones musicales. Por otra parte, el joven Strauss también fue apresado por las autoridades vienesas por tocar en público «La Marsellesa», atizando los sentimientos revolucionarios, pero más tarde fue absuelto. Poco después de su absolución, compuso la polca "Geißelhiebe" ("Latigazos") op. 60, que contiene elementos de «La Marsellesa» en su «Trío», como una sección musical en respuesta a su detención. Strauss padre se mantuvo leal a la monarquía del Danubio y compuso su "Marcha Radetzky" op. 228 dedicada al mariscal de campo Joseph Radetzky von Radetz que pasaría a ser su composición más conocida.

Cuando el anciano Strauss murió de escarlatina en Viena en 1849, el joven Strauss fusionó ambas orquestas y participó en numerosas giras. Posteriormente, también compondría una serie de marchas patrióticas dedicadas al monarca Francisco José I, como la "Kaiser Franz-Josef Marsch" ("Marcha del Emperador Francisco José") op. 67 y la "Kaiser Franz Josef Rettungs Jubel-Marsch" ("Marcha de Júbilo por la salvación del Emperador Francisco José") op. 126, probablemente para congraciarse con el nuevo monarca que subió al trono de Austria tras la Revolución de 1848.

Finalmente superó la fama de su padre, y se convirtió en uno de los más populares compositores de valses de su época, viajando por Austria, Polonia y Alemania con su orquesta. Sería habitual que el público viera una sola representación antes de que se trasladara rápidamente a otro lugar. Sería la primera y última representación en cada uno de esos lugares, y en cuyas placas proclamarían con orgullo «"Heut Spielt der Strauss!"» o «¡Hoy toca Strauss!».

También hizo visitas a Rusia, donde actúo en Pávlovsk y escribió varias composiciones, que más tarde retituló para que se ajustara al público vienés; a Gran Bretaña donde actuó con su primera esposa Hetty Treffz, en el Covent Garden, a Francia, Italia y más tarde a los Estados Unidos en la década de 1870, donde tomó parte en el Festival de Boston por invitación del maestro de banda Patrick Gilmore y fue el principal director en el "Monster Concert" de más de 1000 músicos, en el que interpretó su vals "El Danubio Azul" op. 314, entre otras piezas de gran éxito.

Entre las más populares piezas de baile que Strauss escribió en este período destacan los valses "Sängerfahrten" op. 41, "Liebeslieder" (Canciones de amor) op. 114, "Nachtfalter" (Mariposa nocturna) op. 157, "Accelerationen" (Aceleraciones) op. 234 y las polcas "Annen" (de Ana) op. 117 y "Tritsch-Tratsch" op. 214.

Se casó con la cantante Hetty Treffz en 1862 y postuló al título de Director Musical del Baile de la Corte, puesto que alcanzó en 1863, después de haberle sido negado en varias ocasiones por sus frecuentes fricciones con las autoridades locales. Su participación en el Baile de la Corte significaba que sus trabajos serían ahora escuchados por la realeza. Su segunda esposa, Angelika Dittrich (actriz), con quien se casó en 1878, no era una ferviente partidaria de su música y la diferencia de edad y opiniones, y sobre todo su indiscreción, llevó a que Johann le pidiera el divorcio.

A Strauss no le concedió la nulidad la Iglesia católica y, por lo tanto, cambió de religión y nacionalidad y se convirtió en ciudadano de Sajonia-Coburgo-Gotha el 28 de enero de 1887. Strauss buscó consuelo en su tercera esposa, Adele (con quien se casó el 15 de agosto de 1882) y en sus últimos años fluyeron sus talentos creativos, lo que resultó en gran parte buena música, como las que se encuentran en las operetas "Der Zigeunerbaron" y "Waldmeister" y los valses "Kaiser-Walzer" op. 437, "Kaiser Jubiläum" op. 434, "Märchen aus dem Orient" op. 444 y "Klug Gretelein" op. 462.

Adele, al igual que el abuelo de Strauss, era de origen judío, hecho que los nazis ocultaron.

Después de crear su primera orquesta antes de la muerte de su padre, fundó muchas otras que tocarían en diversos establecimientos de entretenimiento y de baile, como el «Sperl» y el «Apollo», a quienes les dedicó varias piezas con sus nombres para conmemorar sus primeras actuaciones. Más tarde, aceptó comisiones para tocar en Rusia para el archiduque Michael y el Zar Alejandro II, especialmente en Pavlovsk, donde había sido construida una nueva línea de ferrocarril. Cuando las comisiones se hicieron demasiadas para atenderlas él solo, trató de convencer a sus hermanos Josef y Eduard para que lo sustituyeran en su ausencia, ya fuese por su mala salud o por su apretada agenda. En 1853, incluso tuvo que internarse en un sanatorio, ya que sufría de escalofríos y padecía de neuralgia. Deseosa de que la empresa familiar no se viniera abajo, la madre Anna Strauss ayudó a convencer al reacio Josef para que asumiera el mando de la orquesta Strauss. Los vieneses acogieron con satisfacción a ambos hermanos y eventualmente hubo de admitir que «Josef era el más talentoso de ambos, yo simplemente soy el más popular». Josef dejó su propia marca con sus propios valses y esta nueva rivalidad fue muy propicia para el desarrollo del vals. Johann Strauss II procedió a consolidar su posición como «rey del vals» con su exquisito vals "El Danubio Azul" op. 314, que nació como un vals coral con texto escrito por un poeta local.

Lo más destacado del triunvirato de los Strauss queda de manifiesto en el "Concierto de Música Perpetua" en 1860, donde su acertada broma musical "Perpetuum Mobile" op. 257 se interpretó por los tres hermanos encabezando tres orquestas diferentes. En la misma época, los tres hermanos Strauss también organizaron numerosas actividades durante sus conciertos en el "Volksgarten" en Viena, donde el público podía participar. Por ejemplo, se interpretaba una nueva pieza y el público era invitado a adivinar cuál de los tres la había compuesto.

Aunque el más solicitado compositor de música de baile fue Johann Strauss entre 1860 y 1890, tuvo una dura competencia con Karl Michael Ziehrer y Émile Waldteufel; con el segundo competía desde París. Phillip Fahrbach también le negó al joven Strauss el cargo de Director Musical del Baile de la Corte cuando postuló por primera vez al cargo. El compositor alemán Jacques Offenbach, que se hizo famoso en París, le planteó asimismo un desafío a Strauss en el campo de la opereta. Más tarde, la aparición del maestro de la opereta Franz Lehár marcó el inicio de la Edad de Plata en Viena de este género y desplazó la posición de Strauss en el mundo de la opereta.

Johann fue admirado por otros prominentes compositores. Richard Wagner admitió una vez que amaba el vals "Vino, mujeres y canto", Op. 333. Richard Strauss (sin estar emparentado con la familia) al componer sus valses del El caballero de la rosa dijo en referencia a Johann Strauss hijo: «¿Cómo podría olvidar al sonriente genio de Viena?»

Johannes Brahms fue un amigo personal, a quien Strauss dedicó su vals "Seid umschlungen, Millionen!" ("¡Abrazaos, millones!"), Op. 443, inspirado en la Oda a la alegría de Friedrich Schiller. Una historia se cuenta en las biografías de ambos hombres: la hija de Strauss se acercó a Brahms con la intención de pedirle un autógrafo. Era usual que los compositores escribieran algunos compases de su música más conocida y firmaran con su nombre. Brahms, sin embargo, escribió unos cuantos compases de los valses más conocidos de Strauss y a continuación escribió: «Desafortunadamente, NO por Johannes Brahms».

La mayoría de las operetas de Strauss, sin embargo, no han tenido un éxito perdurable al compararlas con sus piezas de baile, y gran parte del éxito se lo adjudican "Die Fledermaus" ("El Murciélago"), "Una Noche en Venecia" y "El Barón Gitano". A pesar de la falta de popularidad de sus operetas, hay muchas piezas extraídas de ellas que fueron recibidas calurosamente, como el "Vals Cagliostro" op. 370 de la opereta "Cagliostro en Viena", el vals "Oh, hermoso mayo" op. 375 (Príncipe Matusalén), el vals Rosas del Sur op. 388 (El Pañuelo de Encaje de la Reina) y el Vals del Beso op. 400 (La Guerra Divertida). También escribió una ópera, "Ritter Pásmán", que tiene numerosas fallas en el libreto, pero muchos atribuyen su fracaso al uso de valses y polcas, lo que indicaría que era incapaz de escribir música seria. De hecho, para su tercera y más exitosa opereta de todos los tiempos, Die Fledermaus (El Murciélago) de 1874, los críticos de música de Viena profetizaron «que el motivo de las melodías serían valses y polcas». Sin embargo, su mayor crítico e irónicamente firme defensor Eduard Hanslick escribió en el momento de la muerte de Strauss en 1899 que su desaparición supondría el final de los tiempos felices en Viena.

Johann Strauss murió de neumonía en Viena el 3 de junio de 1899 a la edad de 73 años y fue sepultado en el Zentralfriedhof de Viena (Cementerio Central de Viena). Al momento de su muerte, se encontraba trabajando en su ballet "Aschenbrödel" ("Cenicienta").

La música de Strauss es interpretada regularmente en el Concierto de Año Nuevo de la Orquesta Filarmónica de Viena, como resultado de los esfuerzos de Clemens Krauss quien realizó un programa especial dedicado a Strauss en 1929 con la orquesta vienesa. Varios intérpretes de Strauss, como Willi Boskovsky, continuaron la tradición de dirigir violín en mano como era costumbre en la familia Strauss, así como Herbert von Karajan y Riccardo Muti. Además, la Orquesta de Viena Johann Strauss que se formó en 1966 le rinde homenaje durante las giras de esta conocida orquesta.


También se han hecho obras con música de Strauss posteriormente:

Ritter Pásmán, Caballero Pásmán (1892)

Aschenbrödel, Cenicienta (1899)






</doc>
<doc id="15443" url="https://es.wikipedia.org/wiki?curid=15443" title="Ecografía">
Ecografía

La ecografía (del griego «ἠχώ» ēkhō="eco", y «γραφία» grafía= "escribir"), también llamada ultrasonografía o ecosonografía, es un procedimiento de diagnóstico usado en los hospitales que emplea el ultrasonido para crear imágenes bidimensionales o tridimensionales. Un pequeño instrumento muy similar a un "micrófono" llamado transductor emite ondas de ultrasonidos. Estas ondas sonoras de alta frecuencia se transmiten hacia el área del cuerpo bajo estudio, y se recibe su eco. El transductor recoge el eco de las ondas sonoras y una computadora convierte este eco en una imagen que aparece en la pantalla.

La ecografía es un procedimiento sencillo, a pesar de que se suele realizar en el servicio de radiodiagnóstico; y por dicha sencillez, se usa con frecuencia para visualizar fetos que se están formando. La ecografía es relativamente una prueba no invasiva en el que se usan vibraciones mecánicas con frecuencia de oscilación en el rango del ultrasonido, a diferencia de los procedimientos de radiografía, en los que se emplea radiación nuclear . Al someterse a un examen de ecografía, el paciente sencillamente se acuesta sobre una mesa y el médico mueve el transductor sobre la piel que se encuentra sobre la parte del cuerpo a examinar. Antes es preciso colocar un gel sobre la piel para la correcta transmisión de los ultrasonidos.

Actualmente se pueden utilizar contrastes en ecografía. Consisten en microburbujas de gas estabilizadas que presentan un fenómeno de resonancia al ser insonadas e incrementan la señal que recibe el transductor. Así, por ejemplo, es posible ver cuál es el patrón de vascularización de un tumor, el cual da pistas sobre su naturaleza. En el futuro quizá sea posible administrar fármacos como los quimioterápicos, ligados a burbujas semejantes, para que éstas liberen el fármaco únicamente en el órgano que se está insonando, para así conseguir una dosis máxima en el lugar que interesa, disminuyendo la toxicidad general.

En 1942, en Austria, el psiquiatra Karl Dussik intentó detectar tumores cerebrales registrando el paso del haz sónico a través del cráneo. Trató de identificar los ventrículos midiendo la atenuación del ultrasonido a través del cráneo, lo que denominó hiperfonografía del cerebro.

En 1947, el doctor Douglas Howry detectó estructuras de tejidos suaves al examinar los reflejos producidos por los ultrasonidos en diferentes interfases.

En 1949 se publicó una técnica de eco pulsado para detectar cálculos y cuerpo extraños intracorpóreos.

En 1951 hizo su aparición el ultrasonido compuesto, en el cual un transductor móvil producía varios disparos de haces ultrasónicos desde diferentes posiciones y hacia un área fija. Los ecos emitidos se registraban e integraban en una sola imagen. Se usaron técnicas de inmersión en agua con toda clase de recipientes: una tina de lavandería, un abrevadero para ganado y una torreta de ametralladora de un avión B-29.

En 1952, Douglas Howry, Dorothy Howry, Roderick Bliss y Gerald Posakony publicaron imágenes bidimensionales del antebrazo, en vivo.

En 1952, John J. Wild y John Reid publicaron imágenes bidimensionales de carcinoma de seno, de un tumor muscular y del riñón normal. Posteriormente estudiaron las paredes del sigmoide mediante un transductor colocado a través de un rectosigmoideoscopio y también sugirieron la evaluación del carcinoma gástrico por medio de un transductor colocado en la cavidad gástrica.

En 1953, Lars Leksell, usando un reflectoscopio Siemens, detectó el desplazamiento del eco de la línea media del cráneo en un niño de 16 meses. La cirugía confirmó que este desplazamiento era causado por un tumor. El trabajo fue publicado sólo hasta 1956. Desde entonces se inició el uso de ecoencefalografía con M-MODE.

En 1954, Ian Donald hizo investigaciones con un detector de grietas, en aplicaciones ginecológicas.

En 1956, Wild y Reid publicaron 77 casos de anormalidades de seno palpables y estudiadas además por ultrasonido, y obtuvieron un 90 por ciento de certeza en la diferenciación entre lesiones quísticas y sólidas.

En 1957, el ingeniero Tom Brown y el Dr. Donald, construyeron un escáner de contacto bidimensional, evitando así la técnica de inmersión. Tomaron fotos con película Polaroid y publicaron el estudio en 1958.

EN 1957, el Dr Donald inició los estudios obstétricos a partir de los ecos provenientes del cráneo fetal. En ese entonces se desarrollaron los cálipers (cursores electrónicos).

En 1959, Satomura reportó el uso, por primera vez, del Doppler ultrasónico en la evaluación del flujo de las arterias periféricas.

En 1960, Donald desarrolló el primer escáner automático, que resultó no ser práctico por lo costoso.

En 1960, Howry introdujo el uso del Transductor Sectorial Mecánico ("hand held scanner").

En 1962, Homes produjo un escáner que oscilaba 5 veces por segundo sobre la piel del paciente, permitiendo una imagen rudimentaria en tiempo real.

En 1963, un grupo de urólogos japoneses reportó exámenes ultrasónicos de la próstata, en el A-MODE.

En 1964 apareció la técnica Doppler para estudiar las carótidas, con gran aplicación en Neurología.

En 1965 La firma austriaca Kretztechnik asociada con el oftalmólogo Dr Werner Buschmann, fabricó un transductor de 10 elementos dispuestos en fase, para examinar el ojo, sus arterias, etc.

En 1966, Kichuchi introdujo la "Ultrasonocardiotomografía sincronizada", usada para obtener estudios en 9 diferentes fases del ciclo cardiaco, usando un transductor rotatorio y una almohada de agua.

En 1967, se inicia el desarrollo de transductores de A-MODE para detectar el corazón embrionario, factible en ese entonces a los 32 días de la fertilización.

En 1968, Sommer reportó el desarrollo de un escáner electrónico con 21 cristales de 1,2 MHz, que producía 30 imágenes por segundo y que fue realmente el primer aparato en reproducir imágenes de tiempo real, con resolución aceptable.

En 1969 se desarrollaron los primeros transductores transvaginales bidimensionales, que rotaban 360 grados y fueron usados por Kratochwil para evaluar la desproporción cefalopélvica. También se inició el uso de las sondas transrectales.

En 1970 Kratochwill comenzó la utilización del ultrasonido transrectal para valorar la próstata.

En 1971 la introducción de la escala de grises marcó el comienzo de la creciente aceptación mundial del ultrasonido en diagnóstico clínico.

1977 Kratochwil combino el ultrasonido y laparoscopia, introduciendo un transductor de 4.0 MHz a través del laparoscopio, con el objeto de medir los folículos mediante el A-MODE. La técnica se extendió hasta examinar vesícula, hígado y páncreas.

En 1982 Aloka anunció el desarrollo del Doppler en color en imagen bidimensional.

En 1983, Lutz usó la combinación de gastroscopio y ecografía, para detectar CA gástrico y para el examen de hígado y páncreas.

En 1983, Aloka introdujo al mercado el primer Equipo de Doppler en Color que permitió visualizar en tiempo real y en color el flujo sanguíneo.

Aunque ya se obtienen imágenes tridimensionales, el empleo de tal tecnología ha sido desaprovechado pues se ha limitado a usos puramente "estéticos" para estimular a las madres a ver sus hijos en tercera dimensión, pero no para mejorar el diagnóstico.

En 2017, Jan Tesarik introdujo la “Histeroscopia ultrasonográfica virtual” para detectar, en 3 dimensiones, anomalías de la cavidad uterina sin entrar en la matriz, igual de precisa y menos invasiva que la histeroscopia convencional. y posteriormente aplicó la misma técnica al estudio de las trompas falopianas (histerosalpingoscopia virtual), la cavidad de folículos ováricos (foliculoscopia virtual) y sacos gestacionales (embrioscopia virtual).

La ecografía abdominal puede detectar tumores en el hígado, vesícula biliar, páncreas y hasta en el interior del abdomen.

La ecografía vaginal sirve para estudiar el útero, detectando la posición, el tamaño o la presencia de miomas o pólipos; el endometrio, conociendo la fase del ciclo menstrual; y los ovarios, para detectar posibles quistes, embarazos ectópicos o para realizar un recuento folicular.

La ecografía de mama se utiliza para diferenciar nódulos o tumores que pueden ser palpables o aparecer en la mamografía. Su principal objetivo es detectar si el tumor es de tipo sólido o líquido para determinar su benignidad. Las ecografías mamarias son recomendables cuando las mamas son densas o se necesita diferenciar la benignidad del tumor. El sistema BI-RADS establece tres tipos de densidad mamaria 1.- Mama grasa 2 .-Densidad media 3.- Densidad heterogénea 4.- Mama muy densa.

En las mamas grasas son fáciles de detectar tumores en las mamografía s, pero en las mamas densas (3-4) (Fibrosas) se necesitan análisis complementarios. La densidad de la mama varía con la edad por lo general, a mayor edad la mama es más grasa.

La ecografía médica para el diagnóstico del cáncer de próstata consiste en la introducción de una sonda por el recto que emite ondas de ultrasonido que producen ecos al chocar con la próstata. Estos ecos son captados de nuevo por la sonda y procesados por una computadora para reproducir la imagen de la próstata en una pantalla de vídeo. El paciente puede notar algo de presión con esta prueba cuando la sonda se introduce en el recto. Este procedimiento dura sólo algunos minutos y se realiza ambulatoriamente. La ecografía transrectal es el método más usado para practicar una biopsia. Los tumores de próstata y el tejido prostático normal a menudo reflejan ondas de sonido diferentes, por eso se utiliza la ecografía transrectal para guiar la aguja de biopsia hacia el área exacta de la próstata dónde se localiza el tumor. La ecografía transrectal no se recomienda de rutina como prueba de detección precoz del cáncer de próstata. La ecografía transrectal es también imprescindible en el estadiaje del cáncer colorrectal.

La ecografía doppler o simplemente eco-Doppler, es una variedad de la ecografía tradicional, basada por tanto en el empleo de ultrasonidos, en la que aprovechando el efecto Doppler, es posible visualizar las ondas de velocidad del flujo que atraviesa ciertas estructuras del cuerpo, por lo general vasos sanguíneos, y que son inaccesibles a la visión directa. La técnica permite determinar si el flujo se dirige hacia la sonda o si se aleja de ella, así como la velocidad de dicho flujo. Mediante el cálculo de la variación en la frecuencia del volumen de una muestra en particular, por ejemplo, el de un flujo de sangre en una válvula del corazón, se puede determinar y visualizar su velocidad y dirección. La impresión de una ecografía tradicional combinada con una ecografía Doppler se conoce como ecografía dúplex.

La información Doppler se representa gráficamente con un Doppler espectral, o bien como una imagen usando Doppler direccional o un power Doppler (Doppler no-direccional). La frecuencia Doppler cae en el rango audible y puede escucharse utilizando altavoces estéreo, produciendo un sonido pulsátil distintivo.

En los últimos tiempos se ha podido ver una revolución en el campo de la medicina materno-fetal. Esa revolución, además, no sólo ha afectado a la medicina en sí misma, sino que ha aportado a la sociedad la posibilidad de establecer una unión emocional con los neonatos mucho más profunda de lo que hasta ahora se creía posible, gracias a una calidad de imagen que permite ver el aspecto del futuro bebé en fotografía (3D) o en imagen en movimiento (4D).

Para lograrlo, mediante el ecógrafo, se emiten los ultrasonidos en cuatro ángulos y direcciones, pasando el emisor suavemente por la barriga del paciente, a la cual se le ha aplicado previamente un gel para mejorar la eficiencia del proceso. Los ultrasonidos rebotan y son captados por el ordenador, que procesa automáticamente la información para reproducir en la pantalla la imagen a tiempo real del bebé.

Esta técnica diagnóstica permite detectar tumores cutáneos, procesos inflamatorios, alteraciones ungueales, enfermedades del pelo y también es aplicable a la dermoestética. Utilizada por primera vez en Chile por la Dra. Wartsman, en España la técnica ha sido introducida por el Dr. Fernando Alfageme Roldán.

Inicialmente la ecografía ha sido una técnica diagnóstica desarrollada y utilizada por radiólogos, sin embargo, hoy día es utilizada cada vez más en otras especialidades médicas como herramienta diagnóstica: cardiología, ginecología, obstetricia, medicina de urgencias, cuidados intensivos, medicina general, familia, urología o pediatría.



</doc>
<doc id="15444" url="https://es.wikipedia.org/wiki?curid=15444" title="Tomografía axial computarizada">
Tomografía axial computarizada

Tomografía viene del griego "τομή" que significa corte o sección y de "γραφή" que significa imagen o gráfico. Por tanto la tomografía es la obtención de imágenes de cortes o secciones de algún objeto.
La posibilidad de obtener imágenes de cortes tomográficos reconstruidas en planos no transversales ha hecho que en la actualidad se prefiera denominar a esta técnica tomografía computarizada o TC en lugar de TAC. 

En lugar de obtener una imagen de proyección, como la radiografía convencional, la TC obtiene múltiples imágenes al efectuar la fuente de rayos X y los detectores de radiación movimientos de rotación alrededor del cuerpo. La representación final de la imagen tomográfica se obtiene mediante la captura de las señales por los detectores y su posterior proceso mediante algoritmos de reconstrucción.

En los fundamentos de esta técnica trabajaron de forma independiente el ingeniero electrónico y físico sudafricano nacionalizado norteamericano Allan McLeod Cormack y el ingeniero electrónico inglés Sir Godfrey Newbold Hounsfield, que dirigía la sección médica del Laboratorio Central de Investigación de la compañía EMI. Ambos obtuvieron de forma compartida el en 1979.

En 1967 Cormack publica sus trabajos sobre la TC siendo el punto de partida de los trabajos de Hounsfield, que diseña su primera unidad. En 1972 comenzaron los ensayos clínicos cuyos resultados soprendieron a la comunidad médica, si bien la primera imagen craneal se obtuvo un año antes.

Los primeros cinco aparatos se instalaron en Reino Unido y Estados Unidos; la primera TC de un cuerpo entero se consiguió en 1974.

En el discurso de presentación del comité del Premio Nobel se destacó que previo al escáner, “las radiografías de la cabeza mostraban solo los huesos del cráneo, pero el cerebro permanecía como un área gris, cubierto por la neblina. Súbitamente la neblina se ha disipado”.

En recuerdo y como homenaje a Hounsfield, las unidades que definen las distintas atenuaciones de los tejidos estudiadas en TC se denominan "unidades Hounsfield" o "número TC" ("CT number)," donde el agua corresponde a 0HU, tejidos blandos +30 a+60HU, grasa -40 a -120HU, entre otros que permiten hacer caracterización de tejidos.

El aparato de TC emite un haz colimado de rayos X que incide sobre el objeto que se estudia. La radiación que no ha sido absorbida por el objeto es recogida por los detectores. Luego el emisor del haz, que tenía una orientación determinada (por ejemplo, estrictamente vertical a 90º) cambia su orientación (por ejemplo, haz oblicuo a 95º). Este espectro también es recogido por los detectores. El ordenador 'suma' las imágenes, promediándolas. Nuevamente, el emisor cambia su orientación (según el ejemplo, unos 100º de inclinación). Los detectores recogen este nuevo espectro, lo 'suman' a los anteriores y 'promedian' los datos. Esto se repite hasta que el tubo de rayos y los detectores han dado una vuelta completa, momento en el que se dispone de una imagen tomográfica definitiva y fiable.

Para comprender qué hace el ordenador con los datos que recibe lo mejor es examinar el diagrama que se aprecia líneas abajo.

Una vez que ha sido reconstruido el primer corte, la mesa donde el objeto reposa avanza (o retrocede) una unidad de medida (hasta menos de un milímetro) y el ciclo vuelve a empezar. Así se obtiene un segundo corte (es decir, una segunda imagen tomográfica) que corresponde a un plano situado a una unidad de medida del corte anterior.

A partir de todas esas imágenes transversales (axiales) un computador reconstruye una imagen bidimensional que permite ver secciones de la pierna (o el objeto de estudio) desde cualquier ángulo. Los equipos modernos permiten incluso hacer reconstrucciones tridimensionales. Estas reconstrucciones son muy útiles en determinadas circunstancias, pero no se emplean en todos los estudios, como podría parecer. Esto es así debido a que el manejo de imágenes tridimensionales no deja de tener sus inconvenientes.

Un ejemplo de imagen tridimensional es la imagen 'real'. Como casi todos los cuerpos son opacos, la interposición de casi cualquier cuerpo entre el observador y el objeto que se desea examinar hace que la visión de éste se vea obstaculizada. La representación de las imágenes tridimensionales sería inútil si no fuera posible lograr que cualquier tipo de densidad que se elija no se vea representada, con lo que determinados tejidos se comportan como transparentes. Aun así, para ver completamente un órgano determinado es necesario mirarlo desde diversos ángulos o hacer girar la imagen. Pero incluso entonces veríamos su superficie, no su interior. Para ver su interior debemos hacerlo a través de una imagen de corte asociada al volumen y aun así parte del interior no siempre sería visible. Por esa razón, en general, es más útil estudiar una a una todas las imágenes consecutivas de una secuencia de cortes que recurrir a reconstrucciones en bloque de volúmenes, aunque a primera vista sean más espectaculares.

La TC se basa en el trabajo desarrollado por Johann Radon en 1917 quien demostró que era posible reconstruir una imagen a partir de múltiples proyecciones de estas a diferentes ángulos, esta operación matemática usada en la TC es conocida como Transformada de Radon.

El tubo de rayos X que gira alrededor del objeto a escanear captura diferentes tomas en su rotación, y del número de estas depende en gran parte la calidad la resolución del escaneo (plano XY), el otro factor de hardware que afecta este item es el número de detectores (pixeles) . Al tiempo que el tubo y el detector giran respecto al paciente, se mueven longitudinalmente para cubrir la superficie a estudiar y las imágenes pueden ser más "gruesas" (>5mm) o "delgadas"(<5mm) (más resolución) según el número de líneas de detectores, que en los equipos más modernos pueden ser superiores a 128.

Las múltiples proyecciones obtenidas son almacenadas en una única matriz llamada sinograma, a la cuál se le aplica un algoritmo de reconstrucción llamado retroproyección filtrada que igualmente está basado en la transformada de Radón.

Para aplicarlo a la medicina hubo que esperar al desarrollo de la computación y del equipo adecuado que mezclase la capacidad de obtener múltiples imágenes axiales separadas por pequeñas distancias, almacenar electrónicamente los resultados y tratarlos. Todo esto lo hizo posible el británico G. H. Hounsfield en los años 70.

La TC, es una exploración o prueba radiológica muy útil para el estadiaje o estudio de extensión de los cánceres en especial en la zona craneana, como el cáncer de mama, cáncer de pulmón y cáncer de próstata o la detección de cualquier cáncer en la zona nasal los cuales en su etapa inicial pueden estar ocasionando alergia o rinitis crónica. Otro uso es la simulación virtual y planificación de un tratamiento del cáncer con radioterapia es imprescindible el uso de imágenes en tres dimensiones que se obtienen de la TC.

Las primeras TC fueron instaladas en España a finales de los años 70 del siglo XX. Los primeros TC servían solamente para estudiar el cráneo, fue con posteriores generaciones de equipos cuando pudo estudiarse el cuerpo completo. Al principio era una exploración cara y con pocas indicaciones de uso. Actualmente es una exploración de rutina de cualquier hospital, habiéndose abaratado mucho los costos. Ahora con la TC helicoidal, los cortes presentan mayor precisión distinguiéndose mejor las estructuras anatómicas. Las nuevas TC multicoronal o multicorte incorporan varios anillos de detectores (entre 2 y 320), lo que aumenta aún más la rapidez, obteniéndose imágenes volumétricas en tiempo real.

Esquema de una TC de cuarta generación. El tubo gira dentro del "gantry" que contiene múltiples detectores en toda su circunferencia. La mesa con el paciente avanza progresivamente mientras se realiza el disparo.

Entre las ventajas de la TC se encuentra que es una prueba rápida de realizar, que ofrece nitidez de imágenes que todavía no se han superado con la resonancia magnética nuclear como es la visualización de ganglios, hueso, etc. y entre sus inconvenientes se cita que la mayoría de veces es necesario el uso de contraste intravenoso y que al utilizar rayos X, se reciben dosis de radiación ionizante, que a veces no son despreciables. Por ejemplo en una TC abdominal, se puede recibir la radiación de más de 500 radiografías de tórax, el equivalente de radiación natural de más de cinco años.

Por medio de la visualización a través de la exploración por TC un radiólogo experto puede diagnosticar numerosas causas de dolor abdominal con una alta precisión, lo cual permite aplicar un tratamiento rápido y con frecuencia elimina la necesidad de procedimientos de diagnóstico adicionales y más invasivos.
Cuando el dolor se produce a causa de una infección e inflamación, la velocidad, facilidad y precisión de un examen por TC puede reducir el riesgo de complicaciones graves causadas por la perforación del apéndice o la rotura del divertículo y la consecuente propagación de la infección.
Las imágenes por TC son exactas, no son invasivas y no provocan dolor. También se utiliza en el diagnostico de la Hernia Paraestomal

Una ventaja importante de la TC es su capacidad de obtener imágenes de huesos, tejidos blandos y vasos sanguíneos al mismo tiempo.
A diferencia de los rayos X convencionales, la exploración por TC brinda imágenes detalladas de numerosos tipos de tejido así como también de los pulmones, huesos y vasos sanguíneos.
Los exámenes por TC son rápidos y sencillos; en casos de emergencia, pueden revelar lesiones y hemorragias internas lo suficientemente rápido como para ayudar a salvar vidas.

La TC es menos sensible al movimiento de pacientes que la RMN, por lo que en los equipos más modernos es posible hacer tomografía cardíaca de alta calidad aún con el movimiento del corazón.

La TC se puede realizar si usted tiene implante de dispositivo médico de cualquier tipo, a diferencia de la RMN.
El diagnóstico por imágenes por TC proporciona imágenes en tiempo real, haciendo de éste una buena herramienta para guiar procedimientos mínimamente invasivos, tales como biopsias por aspiración y aspiraciones por aguja de numerosas áreas del cuerpo, particularmente los pulmones, el abdomen, la pelvis y los huesos.
Un diagnóstico determinado por medio de una exploración por TC puede eliminar la necesidad de una cirugía exploratoria y una biopsia quirúrgica.
Luego del examen por TC no quedan restos de radiación en su cuerpo.
En general, los rayos X utilizados en las exploraciones por TC no tienen efectos secundarios.

La dosis efectiva de radiación y la dosis de radiación absorbida a partir de este procedimiento es diferente según la máquina, y la parte del cuerpo escaneada, y varía en algunas máquinas probadas de aproximadamente 1 a 10 mSv, y desde aproximadamente 10 a 140 mGy para un solo análisis. A veces, más de una exploración se realiza a la vez, una con y otra sin agente de contraste, que el doble de la dosis. La dosis efectiva es de aproximadamente la misma proporción que una persona promedio recibe de radiación de fondo en tres años, pero la dosis absorbida puede ser aproximadamente la misma proporción que la parte del cuerpo que recibe de radiación de fondo en 60 años.
Las mujeres siempre deben informar a su médico y al tecnólogo de rayos X o TC si existe la posibilidad de que estén embarazadas.
En general, el diagnóstico por imágenes por TC no se recomienda para las mujeres embarazadas, salvo que sea médicamente necesario, debido al riesgo potencial para el bebé.
Las madres en período de lactancia deben esperar 24 horas después de que hayan recibido la inyección intravenosa del material de contraste antes de poder volver a amamantar.
Antes de realizar un estudio con contraste el paciente debe de llenar un cuestionario en donde se le realizan preguntas acerca de su historial de salud como: alergias, síntomas y razón por la que se le realiza el estudio. El riesgo de una reacción alérgica grave al material de contraste, que contiene yodo, muy rara vez ocurre, y los departamentos de radiología deben de poseer las herramientas necesarias en caso de que ocurra un evento como este . Por eso siempre se debe de llevar a cabo un proceso de documentación en unos libros de procedimientos en donde se identifica al paciente , estudio que se le realizó y el contraste que se le administró. De esta forma se logra llevar un control en cuanto a las reacciones alérgicas que han ocurrido y se mantiene un historial en el expediente.
Debido a que los niños son más sensibles a la radiación, se les debe someter a un estudio por TC únicamente si es fundamental para realizar un diagnóstico, y no se les debe realizar estudios por TC en forma repetida a menos que sea absolutamente necesario.

El estudio "BMJ: Cancer risk in 680.000 people exposed to computed tomography scans in childhood or adolescence: data linkage study of 11 million Australians" publicado en el BMJ el 22 de mayo de 2013, realizado a 700.000 niños de 0 a 19 años -sometidos anteriormente exploraciones de Tomografía Computarizada (TC) confirmarían un incremento de un 24% en la incidencia de cáncer (cáncer encefálico y leucemias), en relación con población de similar edad no sometida a TAC. El riesgo aumentaría cuanto mayor es el número de exploraciones realizadas y cuanto menor es la edad del niño.



</doc>
<doc id="15449" url="https://es.wikipedia.org/wiki?curid=15449" title="Campylobacter fetus">
Campylobacter fetus

Campylobacter fetus es una especie de "Campylobacter", gram negativa, móviles, bacilos oxidasa positiva, con una característica forma de "S", similar a los miembros del género "Vibrio". "C. fetus" está recubierta de una proteína de superficie que funciona similar a una cápsula e interrumpe la adherencia de la molécula del complemento C3b. 

Por lo general es un patógeno oportunista que, diferencia de otras bacterias del mismo género, rara vez causa diarrea, sino que provoca infecciones extraintestinales en pacientes inmunodeprimidos o con enfermedades de base acompañantes como la cirrosis hepática, la diabetes mellitus, cáncer, leucemia, cardiopatía, etc. El cuadro infeccioso se manifiesta por una poco frecuente bacteriemia o septicemia en la que aparece casi siempre la fiebre. Como resultado de la bacteriemia puede haber afectación en distintos órganos, destacando las localizaciones cardiovaculares con endocarditis y pericarditis, tromboflebitis, meningitis y meningoencefalitis, artritis y abortos.

Pueden surgir otros procesos supurados como peritonitis, absceso de pulmón, empiema, celulitis, infecciones del tracto urinario y colecistitis. También el "Campylobacter fetus", puede ocasionar gastroenteritis con sintomatología semejante a la producida por "Campylobacter jejuni". El reservorio natural del "C. fetus" son el ganado y las ovejas.




</doc>
<doc id="15450" url="https://es.wikipedia.org/wiki?curid=15450" title="Phlomis herba-venti">
Phlomis herba-venti

Phlomis herba-venti, popularmente aguavientos o hierba de las moscas, es una especie perteneciente a la familia Lamiaceae. Nativa de la región Mediterránea y el Asia central. 

Es una planta herbácea perenne de hasta 70 cm de altura, con hojas lanceoladas u ovadas, coriáceas, cordadas con pecíolo de 4-8 cm y limbo de 7-20 x 5-10 cm, verdes. Las flores son de color púrpura.

subsp. herba-venti. Del sur de Europa y norte de Marruecos.
subsp. kopetdaghensis (Knorr.) Rech.f., in Fl. Iran. 150: 309 (1982). de Turkmenistán a Irán.
subsp. lenkoranica (Knorring) Rech.f., in Fl. Iran. 150: 309 (1982). De Transcaucasia al sur de Turkmenistán.
subsp. pungens (Willd.) Maire ex DeFilipps, Bot. J. Linn. Soc. 64: 233 (1971). Sudeste de Europa a Irán y noroeste de África.



</doc>
<doc id="15451" url="https://es.wikipedia.org/wiki?curid=15451" title="Mitrídates, rey de Ponto">
Mitrídates, rey de Ponto

Mitrídates, rey de Ponto (título original en italiano, "Mitridate, Rè di Ponto") es una ópera seria en tres actos con música de Wolfgang Amadeus Mozart y libreto en italiano de Vittorio Amedeo Cigna-Santi. Lleva por número KV 87. En el último catálogo Köchel: K 74a. Se compuso por encargo del conde Firmian, gobernador de Milán y mecenas. Se estrenó en el Teatro Regio Ducal de Milán el 26 de diciembre de 1770. 

La ópera ocurre en Ninfea, puerto de Crimea, reino del Ponto en el año 63 a. C. El protagonista es el rey Mitrídates VI Eupator (132-63 a. C.). Enzarzado en sus luchas contra los romanos, deja a su prometida Aspasia, al cuidado de sus hijos, Farnaces y Sifares. Después de sufrir una severa derrota, Mitrídates es dado por muerto. 

Acto I

"Escena 1"

Arbate, el gobernador de Ninfea, da la bienvenida a Sifares que está enojado con su hermano, Farnaces, debido a los fuertes lazos que lo unen a los romanos, sus enemigos. Arbate jura lealtad a Sifares. Aspasia ruega a Sifares, para que la ayude a resistir los avances de Farnaces. Sifares acepta sus súplicas, y al tiempo revela su amor por ella. Aspasia ama secretamente a Sifares.

"Escena 2"

Farnaces, el primogénito, ofrece su amor a Aspasia, quien lo rechaza con el apoyo de Sifares, que la protege frente a su poderoso hermano. Llegan noticias de que Mitrídates está vivo y se acerca a la ciudad. Arbate insta a los hermanos a sobreponerse a sus diferencias y saludar a su padre. Farnaces conspira con Marzio, tribuno romano, contra Mitrídates.

"Escena 3"

Mitrídates llega a Ninfea con la princesa Ismene, hija del rey de los partos, para ofrecerla como esposa a su hijo Farnaces. Mitrídates quiere que Farnaces se case con Ismene, su prometida. Ismene está enamorada de Farnaces. Arbate le dice a Mitrídates que Farnaces persigue a Aspasia, pero no menciona a Sifares. Celoso, Mitrídates jura vengarse de Farnaces. 

Acto II

"Escena 1"

Farnaces desprecia y amenaza a Ismene, y ésta se lo dice a Mitrídates, quien sugiere que se case con Sifares. Mitrídates pide a Aspasia que se casen inmediatamente, pero ella vacila, lo que demuestra su infidelidad. Aspasia le confiesa su amor a Sifares, pero acuerdan separarse para salvaguardar el honor. Sifares planea marcharse y Aspasia queda preocupada, inmersa en su conflicto entre el amor y el deber. 

"Escena 2"

Mitrídates es consciente del complot de Farnaces y los romanos contra él, y planea vengarse, a pesar de la oferta de paz que Marzio le hace llegar. Detiene a Farnaces, acusado de traición. Ismene salva al príncipe Farnaces lo confiesa todo a su padre y es ingresado en prisión. Aspasia y Sifares declaran su amor y están dispuestos a morir, por temor a Mitrídates. 

Acto III

"Escena 1"

Ismene, todavía enamorada de Farnaces, trata de convencer a Mitrídates para que perdone a Aspasia y Sifares. Los romanos, guiados por Marzio, atacan y Mitrídates se prepara para la batalla. Aspasia piensa en suicidarse ingiriendo veneno, y sólo la intervención de Sifares consigue salvarla. Sifares también quiere morir y une a su padre en la batalla.

"Escena 2"

Marzio libera a Farnaces y le promete el trono de su padre si le ayuda. Pero el príncipe cambia de idea, se arrepiente de su traición y se une al ejército de su padre.

"Escena 3"

Mitrídates es herido en combate y él mismo se arroja sobre su espada para suicidarse, ante la derrota. Antes de morir, perdona a sus hijos y da su bendición a Sifares y Aspasia, mientras Farnaces se declara dispuesto a desposar a Ismene. En el quinteto final Sifares, Aspasia, Farnaces, Ismene y Arbate declaran su intención de vengarse de los romanos y combatir a aquellos que pretenden acabar con la libertad del mundo entero.

Originalmente interpretada con 2 flautas, 2 oboes, 4 cornos, 2 fagotes, 2 trompetas, timbales, cuerdas y bajo continuo.

El texto originario era el "Mithridate" de Racine (1673); fue traducido por el abate Giuseppe Parini. Vittorio Amadeo Cigna-Santi versificó esta traducción para la ópera de Mozart. Este poeta residía en Turín y envió a Milán el libreto por partes. La historia de Mitrídates ya había sido puesta en música con anterioridad, por Quirino Gasparini.


Consta de una obertura, veintiún arias, una cavata, una cavatina, un dúo y un coro final. Mozart intercaló siete recitativos acompañados. De las piezas vocales de esta ópera, destacan: 

Se compuso para inaugurar la temporada musical, por parte del conde Firmian, gobernador y mecenas milanés. Las circunstancias de su composición y estreno pueden seguirse a través de las cartas de Leopold Mozart. Se estrenó con gran éxito en el Teatro Regio Ducal de Milán el 26 de diciembre de 1770.

Esta primera representación suscitó el entusiasmo del público, en Parini y en todos los cantantes. El castrado Pietro Benedetti afirmó que, si el público no quedaba encantado con el dueto final del segundo acto, “se haría castrar por segunda vez". Después de esa primera representación, hubo otras veinte en el mismo escenario, dirigiendo Mozart las cuatro primeras. No se volvió a representar hasta el siglo XX. Se interpretó en Salzburgo en versión de concierto en 1977.

Esta ópera se representa poco; en las estadísticas de Operabase aparece la n.º 163 de las óperas representadas en 2005-2010, siendo la 24.ª en Austria y la decimocuarta de Mozart, con 19 representaciones en el período.

Mozart escribió "Mitridate" mientras se encontraba de viaje por Italia en 1770. Tenía catorce años. Fue su primera experiencia con la ópera seria. Recibió cien florines y la manutención durante los cinco meses que tardó en componerla. Como el resto de sus primeras óperas, sigue muy de cerca el modelo italiano.


Igualmente, está disponible una grabación en DVD por Charles T. Downey (2006, Ionarts).








</doc>
<doc id="15453" url="https://es.wikipedia.org/wiki?curid=15453" title="Caja negra (transporte)">
Caja negra (transporte)

Se denomina caja negra o registrador de vuelo al dispositivo que, principalmente en aeronaves, trenes, barcos y naves espaciales, registra la actividad de los instrumentos y las conversaciones de los tripulantes. Su función es almacenar datos que, en caso de un accidente, permitan analizar lo ocurrido en los momentos previos y establecer sus causas. Los aviones comerciales de gran tamaño llevan dos cajas negras, técnicamente conocidas por sus siglas en inglés como CVR (grabadora de voces de cabina) y FDR (grabadora de datos de vuelo).

Los primeros registradores de vuelo se empezaron a usar a finales de los años 1950 y se les llamó "cajas negras", denominación que perduró incluso después de que se pintasen de color naranja para facilitar su localización tras un accidente. El origen de la denominación de "caja negra" no está claro: algunos de los prototipos de la RAF estaban pintados de negro, otros prototipos eran cámaras oscuras con placas fotográficas, y desde un punto de vista de sistemas, se comportan como cajas negras (se pone foco en sus entradas y salidas).

Se denomina caja negra o registrador de vuelo al dispositivo que, principalmente en las aeronaves y coches motores o locomotoras de trenes, registra la actividad de los instrumentos y las conversaciones en la cabina. Su función es almacenar datos que, en caso de un accidente, permitan analizar lo ocurrido en los momentos previos. Según las normas de aviación internacionales, estos aparatos hoy son obligatorios en todos los vuelos comerciales ya que graban los datos del viaje y son clave en las investigaciones sobre accidentes de avión. Gracias a ellos, nueve de cada diez accidentes, se pueden explicar. Por eso se ha puesto tanto empeño a la caja de vuelo MH370 de Malaysia Airlines perdido en marzo del 2014 en vuelo de Kuala Lampur, capital de Malasia, a Pekín, capital de China.

Como ocurre con tantos otros inventos sofisticados, no tiene un único inventor, pero el primer prototipo de caja negra, data del año de 1939 y fue diseñado por el ingeniero francés Francois Hussenot. Se trataba de una rudimentaria caja hecha con film fotográfico calibrada con espejos. Los sensores a bordo lanzaban flashes en el film fotográfico y así se registraba el historial del vuelo. Consciente de lo importante de su invento, se dice que Hussenot escondió la caja del ejército nazi invasor de su patria, enterrándola cerca de una playa del Océano Atlántico en junio de 1940. Y como también ocurre con tantos avances tecnológicos, la guerra perfeccionó la tecnología, que se extendió a los vuelos comerciales en todo el mundo. Después de la Segunda Guerra Mundial, algunos dispositivos usaban fotografía y otros imprimían los datos en bobinas de aluminio.

Los primeros registradores de vuelo se empezaron a usar a finales de los años 1950 y se les llamó "cajas negras", denominación que perduró incluso después de que se pintasen de color naranja, esto para facilitar su localización tras un accidente. La denominación de "cajas negras" proviene, al igual que en otras situaciones (como día negro) de que en el momento que las cajas negras se hacen necesarias, es porque ha sucedido un accidente aéreo.

La caja negra propiamente dicha es obra del australiano David Warren. En 1953 le pidieron a este químico e ingeniero de aviación que ayudara a descubrir la causa de una serie de accidentes aéreos. Los expertos intentaban entender por qué varios aviones Comet, se habían estrellado sin ninguna explicación, lo que ponía en duda el futuro de los vuelos comerciales. "Me quedé pensando para mis adentros ... Si pudiéramos recuperar esos últimos segundos" dijo en una entrevista en 1985 citada por The New York Times, "se ahorrarían muchas discusiones e incertidumbre". Un año más tarde, Warren propuso instalar un dispositivo de grabación en la cabina del piloto y para 1958 había producido el prototipo de la Unidad de Memoría del Vuelo. Esa primera versión era ligeramente más grande que la mano de un adulto, pero capaz de grabar unas cuatro horas de conversación de cabina y de lecturas de mandos. La versión de Warren grababa el sonido en una bobina de acero magnetizado. Para sorpresa de Warren, el dispositivo fue rechazado por las autoridades de aviación, que le encontraron "poca utilidad directa e inmediata para las aeronaves civiles", mientras que los pilotos dijeron que era como un "Big Brother" (Gran Hermano) que espiaría su trabajo.

Cuando Warren llevó el invento al Reino Unido, fue recibido con entusiasmo y luego de un reportaje de la BBC sobre el aparato, los fabricantes comenzaron a interesarse con el proyecto. Mientras tanto en Estados Unidos, ya había investigaciones sobre el aparato y en 1960, ya se daban los primeros pasos para hacer que los dispositivos fueran obligatorios. A mediados de la década de 1960, los registradores de vuelo -de datos y de voz- eran obligatorios para los aviones comerciales. Actualmente, las computadoras de vuelo, han reemplazado a la cinta magnética, los dispositivos pueden grabar más datos y son mucho más propensos a sobrevivir a un impacto. Debe tener una etiqueta con las letras de al menos 2.5 cm de alto que digan: "REGISTRADOR DE VUELO: NO ABRIR"

Los registradores actuales emplean microcircuitos de memoria flash, capaces de almacenar datos durante varios años sin alimentación de energía. En la actualidad graban digitalmente las dos últimas horas o los últimos treinta minutos (según el modelo) de todas las conversaciones realizadas en la cabina, tanto las realizadas por los pilotos como las de ambiente, que se captan por medio de un micrófono normalmente instalado en el panel superior (overhead) y que registra todos los sonidos que se producen en cabina (conversaciones, avisos sonoros del avión, etc). Esos registradores contienen también tarjetas de circuito que procesan y comprimen los datos, aunque sólo los microcircuitos de memoria están encerrados en el bloque antichoque de la caja. Ese bloque se cubre con un blindaje grueso de acero para que resista los aplastamientos por impacto. Bajo el acero hay una capa de aislante térmico diseñado para proteger los microcircuitos de memoria de los incendios que suelen ocurrir tras un accidente del reactor.

Todas las aeronaves comerciales de gran tamaño llevan dos cajas: la grabadora de voces de cabina o CVR ("Cabin Voice Recorder - CDR") que recoge las conversaciones de la tripulación de vuelo y los sonidos procedentes de la cabina, y el registrador de datos de vuelo ("Flight Data Recorder - FDR"), que anota la altitud del aparato, su velocidad con respecto al aire, su rumbo y otras lecturas instrumentales. Dada la importancia de esa información, los registradores se diseñan para resistir aceleraciones considerables, además de ubicarse en sitios que suelen ser menos castigados por un impacto como la cola del avión. 

Recientemente se amplió la lista de lecturas instrumentales a almacenar y también se ha propuesto que cada grabadora de voces de cabina esté equipada con una fuente de alimentación de reserva para que pueda seguir funcionando aunque se averíen los circuitos eléctricos de la aeronave.

Las cajas negras más modernas disponen de entradas para almacenar vídeo, dando la posibilidad de grabar las acciones sucedidas en la cabina de vuelo en los momentos previos al accidente.

Las pruebas de certificación que se realizan para comprobar que estén preparadas, son las siguientes:





Una de las mayores deficiencias de las cajas negras es la posibilidad de pérdida -especialmente en accidentes sucedidos en el mar- o destrucción total. Para subsanar esas deficiencias se han propuesto innovaciones como la elaboración de cajas negras flotantes, auto-expulsables en caso de accidente, dotarlas de un localizador GPS, o con capacidad para transmitir los datos vía satélite a medida que se registran. La tecnología de cajas negras auto-expulsables fue utilizada inicialmente en la aviación militar y desde 2015 en algunos aviones comerciales.

La posibilidad de utilizar sistemas de transmisión de datos vía satélite en tiempo real ha sido observada debido al peligro de que personas o empresas ajenas a las autoridades a cargo de la investigación de los accidentes, pudieran acceder a la información para manipularla o utilizarla abusivamente.

Actualmente es obligatoria la instalación de un Registrador de Datos de la Travesía (RDT o VDR por sus siglas en inglés) en todos los buques de nueva construcción, con la excepción de buques que no sean de pasaje cuyo arqueo bruto sea inferior a 3.000 toneladas. Existen versiones simplificadas (S-VDR) para buques más pequeños. La filosofía es similar al caso de las aeronaves: se graban los sonidos captados en el puente de mando y los "alerones" (especie de "balcón" que posee el puente, a babor y estribor), audio del sistema VHF y por otro lado se graban datos de los mandos tales como ángulo de timón, velocidad de máquinas, estado de puertas estancas, junto a datos del GPS, de la ecosonda, del radar, u otros. Todo queda registrado en una cápsula hermética que sobreescribe los datos periódicamente dejando siempre legibles las últimos 12 horas (48 hs según MSC.333(90)) anteriores al corte de energía, los que deben conservarse por un mínimo de 30 días posteriores. Las cápsulas pueden quedar fijas al casco o liberarse mediante zafas hidrostáticas como las radiobalizas de emergencia y las balsas salvavidas. 




</doc>
<doc id="15454" url="https://es.wikipedia.org/wiki?curid=15454" title="Criptoanálisis">
Criptoanálisis

El criptoanálisis (del griego "kryptós", "escondido" y "analýein", "desatar") es la parte de la criptología que se dedica al estudio de sistemas criptográficos con el fin de encontrar debilidades en los sistemas y romper su seguridad sin el conocimiento de información secreta. En el lenguaje no técnico, se conoce esta práctica como romper o forzar el código, aunque esta expresión tiene un significado específico dentro del argot técnico. A las personas que se dedican al criptoanálisis se llaman criptoanalistas.

Los métodos y técnicas del criptoanálisis han cambiado drásticamente a través de la historia de la criptografía, adaptándose a una creciente complejidad criptográfica. Los sistemas criptográficos han evolucionado desde los métodos de lápiz y papel del pasado, pasando por máquinas como Enigma -utilizada por los nazis durante la Segunda Guerra Mundial-, hasta llegar a los sistemas basados en computadoras del presente. Al aumentar la potencia de cálculo de los sistemas criptográficos, también los esquemas criptográficos han ido haciéndose más complejos. A mediados de los años 1970 se inventó una nueva clase de criptografía: la criptografía asimétrica. Los métodos utilizados para romper estos sistemas son por lo general radicalmente diferentes de los anteriores, y usualmente implican resolver un problema cuidadosamente construido en el dominio de la matemática pura. El ejemplo más conocido es la factorización de enteros.

Los resultados del criptoanálisis han cambiado también: ya no es posible tener un éxito ilimitado al romper un código, y existe una clasificación jerárquica de lo que constituye un ataque en la práctica.

La técnica del criptoanálisis se basa en buscar errores o algún error en el sistema para penetrarlo y hacer daños.

El objetivo del criptoanálisis es encontrar debilidades en los sistemas criptográficos que permitan elaborar ataques (ataques criptoanalíticos) que rompan su seguridad sin el conocimiento de información secreta. Para ello estudia en profundidad el diseño y propiedades de los sistemas criptográficos.

Por ejemplo para un sistema criptográfico de cifrado un estudio criptoanalítico puede consistir por ejemplo en conseguir la clave secreta o simplemente en acceder al texto en claro sin ni siquiera tener dicha clave. Sin embargo el criptoanálisis no sólo se ocupa de los cifrados sino que su ámbito es más general estudiando los sistemas criptográficos con el objetivo de sortear la seguridad de otros tipos de algoritmos y protocolos criptográficos.

Sin embargo, el criptoanálisis suele excluir ataques que no tengan como objetivo primario los puntos débiles de la criptografía utilizada; por ejemplo, ataques a la seguridad que se basen en el soborno, la coerción física, el robo, el keylogging y demás, aunque estos tipos de ataques son un riesgo creciente para la seguridad informática, y se están haciendo gradualmente más efectivos que el criptoanálisis tradicional.

Para la consecución de su objetivo, de elaboración de ataques criptoanalíticos que 'rompan' la seguridad de los sistemas criptográficos, los criptoanalistas estudian los sistemas criptográficos con el objetivo de descubrir debilidades que se puedan aprovechar. Para ello estudian los sistemas desde distintos enfoques.

La teoría de la información proporciona herramientas para evaluar la seguridad de los sistemas criptográficos. Por ejemplo, en los sistemas de cifrado se estudia la entropía de la clave, de los criptogramas y de los mensajes en claro. Como el mensaje en claro suele estar expresado en idiomas humanos, también es interesante el estudio de su entropía y en especial su ratio de entropía.

Los criptoanalistas también estudian el secreto de los sistemas criptográficos. Por ejemplo, en los sistemas de cifrado estudian el grado de secreto caracterizando aquellos sistemas que tienen secreto perfecto a nivel teórico. De su estudio se concluye que el secreto perfecto requiere que el número de claves sea al menos tan grande como el número de mensajes. Esto es impracticable excepto para los llamados cifradores de libreta de un solo uso. En la práctica la mayor parte de los sistemas tienen claves finitas. Para caracterizar la seguridad de estos sistemas los criptoanalistas han desarrollado el concepto de distancia de unicidad que es el valor mínimo de caracteres cifrados que hacen que sólo haya una clave posible que haya sido utilizada para obtener este criptograma. Para ello se aprovecha el concepto de la entropía condicional del conocimiento de la clave una vez conocido el texto cifrado.

Para un sistema de cifrado hay dos entropías condicionales interesantes desde el punto de vista del criptoanalista:

Para un sistema de cifrado hay una serie de entropías condicionales interesantes:

Supongamos
Entonces:


(K)</math>


Se ha demostrado que se cumple la siguiente relación entre las distintas entropías:

De esta relación podemos sacar una conclusión:

Por ejemplo, la criptografía asimétrica emplea en problemas matemáticos "duros" como base para su seguridad, así que un punto obvio de ataque es desarrollar métodos para resolver el problema. Los algoritmos asimétricos se diseñan en torno a la conjeturada dificultad de resolver ciertos problemas matemáticos. Si se encuentra un algoritmo mejorado que puede resolver el problema, el criptosistema se ve debilitado. Ejemplos:

Otra caraterística distintiva de los algoritmos asimétricos es que, a diferencia de los ataques sobre criptosistemas simétricos, cualquier criptoanálisis tiene la oportunidad de usar el conocimiento obtenido de la clave pública.

Los ataques criptoanalíticos consisten en la aplicación de estudios criptoanalíticos para explotar las debilidades de sistemas criptográficos y así 'romper' su seguridad.

Los ataques criptoanalíticos varían en potencia y en su capacidad de amenaza para los sistemas criptográficos. Se dice que un ataque explota una "debilidad certificacional" si es un ataque teórico que resulta improbable de aplicar en ninguna situación realista; Muchos de los resultados demostrados en la investigación criptoanalítica moderna son de este tipo.

Cada ataque tiene sus propiedades, las cuales lo caracterizan, y que hacen que ese ataque sea más o menos realizable.

No todos los ataques criptoanalíticos tienen como objetivo la ruptura total del sistema. El objetivo de un ataque criptoanalítico es obtener información desconocida sobre el sistema criptográfico de forma que se vaya debilitando su seguridad

Los ataques criptoanalíticos se puede clasificar en función de sus características.

Los ataques se pueden clasificar según la forma de actuar del atacante

En los ataques pasivos el atacante no altera la comunicación, sólo la escucha o monitoriza, para obtener información.
Por tanto este tipo de ataques suelen usar técnicas de escucha de paquetes(sniffing) y de análisis de tráfico.
Son difíciles de detectar ya que no implican alteración de los datos.
En algunos casos este tipo de ataques se pueden dificultar cifrando la información posible objetivo de escuchas.

Suponen alguna modificación del flujo de datos o la creación de flujos falsos. Hay muchas técnicas que se usan en este tipo de ataques. Ejemplos:

El criptoanálisis puede realizarse bajo una serie de supuestos sobre cuánto puede observarse o descubrirse sobre el sistema en cuestión antes de realizar el ataque. Como un punto de comienzo básico se supone que, para los propósitos del análisis, el algoritmo general es conocido; ésta es la Máxima de Shannon, ""el enemigo conoce el sistema"". Éste es un supuesto razonable en la práctica - a lo largo de la Historia, hay incontables ejemplos de algoritmos secretos que fueron conocidos mediante el espionaje, la traición y la ingeniería inversa. (En algunas ocasiones, algunos códigos han sido reconstruidos mediante la pura deducción, por ejemplo, el código Lorenz y el código PURPLE, así como una cierta cantidad de códigos clásicos.)

Otros supuestos se pueden categorizar como sigue:

Estos tipos de ataque difieren evidentemente en la plausibilidad de que ocurran en la práctica. Aunque algunos son más probables que otros, los criptógrafos suelen adoptar un enfoque conservador y asumir el peor caso imaginable cuando diseñan algoritmos, razonando que si un sistema es seguro incluso contra amenazas tan poco realistas, entonces debería resistir también al criptoanálisis en el mundo real.

Los supuestos en los que se basan estos ataques son a menudo más realistas de lo que podría parecer a primera vista. Para obtener un ataque con texto claro conocido, el criptoanalista podría muy bien conocer o ser capaz de inferir una parte que probablemente forma parte del texto claro, como por ejemplo el encabezamiento de una carta cifrada ("Estimado Sr."), o que el inicio de una sesión de ordenador contenga las letras "LOGIN". Un ataque de texto claro escogido es menos probable, pero en algunos casos puede ser plausible: por ejemplo, si convences a alguien para reenviar un mensaje que tú mismo le has mandado antes, pero en forma cifrada. Los ataques de clave relacionada son básicamente teóricos, aunque pueden ser realistas en ciertas situaciones, como por ejemplo al construir funciones hash criptográficas utilizando un cifrado por bloques.

Los resultados de un criptoanálisis también pueden variar en utilidad. Por ejemplo, el criptógrafo Lars Knudsen (Knudsen, 1998) clasificó varios tipos de ataque sobre cifrados por bloques de acuerdo con la cantidad y la calidad de la información secreta que pudiera ser descubierta:


Se pueden aplicar estas categorías a los ataques sobre otros tipos de algoritmos.

Los ataques se pueden categorizar por la cantidad de recursos que requieren. Estos pueden tomar la forma de:


En la criptografía académica, una "debilidad" o una "ruptura" en un algoritmo se definen de una manera bastante conservadora. Bruce Schneier resume esta posición de la siguiente manera: ""Romper un cifrado simplemente significa encontrar una debilidad en el cifrado que puede ser explotada con una complejidad inferior a la de la fuerza bruta. No importa que la fuerza bruta pudiera requerir 2 cifrados; un ataque que requiera 2 cifrados se consideraría una ruptura... puesto de una manera simple, una ruptura puede ser tan sólo una debilidad certificacional: una evidencia de que el código no es tan bueno como se publicita"" (Schneier, 2000).

Hay multitud de métodos de ataque criptoanalíticos. Estos se pueden clasificar en a si están especializado en algún tipo de criptografía o si son más generales. Los principales son los siguientes:


Los ordenadores cuánticos son potencialmente útiles para el criptoanálisis. Debido a que los estados cuánticos pueden existir en una superposición (es decir, estar entrelazados), es posible un nuevo paradigma computacional, en el que un bit no representa tan sólo los estados 0 y 1, sino cualquier combinación lineal de estos. Peter Shor de los Laboratorios Bell probó la posibilidad, y varios equipos han demostrado uno u otro aspecto de la computación cuántica en los años transcurridos desde entonces. Por el momento, sólo se ha demostrado una muy limitada prueba de posibles diseños. No hay, a fecha de 2006, una perspectiva creíble de un ordenador cuántico real y utilizable.

Sin embargo, de construirse un ordenador cuántico, muchas cosas cambiarían. La computación en paralelo sería probablemente la norma, y varios aspectos de la criptografía cambiarían.

En particular, dado que un ordenador cuántico sería capaz de realizar búsquedas de claves mediante fuerza bruta extremadamente rápidas, tamaños de clave considerados hoy en día más allá de los recursos de cualquier atacante por fuerza bruta quedarían al alcance de este ataque. Los tamaños de clave necesarios para quedar más allá de la capacidad de un ordenador cuántico serían considerablemente más grandes que los actuales. Algunos escritores de divulgación han declarado que ningún cifrado permanecería seguro de estar disponibles los ordenadores cuánticos. Otros aseguran que simplemente añadiendo bits a las longitudes de las claves se evitarán los ataques de fuerza bruta, incluso con ordenadores cuánticos.

Una segunda posibilidad es que el aumento en capacidad computacional pueda hacer posibles otros ataques de búsqueda de claves, más allá de la simple fuerza bruta, contra uno o varios de los algoritmos actualmente inexpugnables. Por ejemplo, no todo el progreso en la factorización mediante números primos se ha debido a una mejora de los algoritmos. Una parte se debe al incremento del poder computacional de los ordenadores, y la existencia de un ordenador cuántico en funcionamiento podría acelerar considerablemente las tareas de factorización. Este aspecto es bastante predecible, aunque no claramente. Lo que no puede ser anticipado es un avance en el campo teórico que requiera la computación cuántica, que pudiera hacer realizables ataques actualmente impracticables o incluso desconocidos. En ausencia de un método para predecir estos avances, sólo nos queda esperar.

Se desconoce si existe un método de cifrado en tiempo polinómico que requiera un tiempo exponencial para su descifrado, incluso para un ordenador cuántico.

El criptoanálisis ha evolucionado conjuntamente con la criptografía, y la competición entre ambos puede ser rastreada a lo largo de toda la historia de la criptografía. Las claves nuevas se diseñaban para reemplazar los esquemas ya rotos, y nuevas técnicas de criptoanálisis se desarrollaban para abrir las claves mejoradas. En la práctica, se considera a ambas como las dos caras de la misma moneda: para crear un sistema criptográfico seguro, es necesario tener en cuenta los descubrimientos del criptoanálisis. De hecho, hoy en día se suele invitar a la comunidad científica a que trate de romper las nuevas claves criptográficas, antes de considerar que un sistema es lo suficientemente seguro para su uso.

Aunque la expresión criptoanálisis es relativamente reciente (fue acuñada por William F. Friedman en 1920), los métodos para romper códigos y cifrados son mucho más antiguos. La primera explicación conocida del criptoanálisis se debe al sabio árabe del siglo IX, Yusuf Yaqub ibn Ishaq al-Sabbah Al-Kindi, en su "Manuscrito para Descifrar Mensajes Criptográficos". Este tratado incluye una descripción del método de análisis de frecuencias (Ibraham, 1992).

El análisis de frecuencias es la herramienta básica para romper los cifrados clásicos. En todas las lenguas conocidas, ciertas letras del alfabeto aparecen más frecuentemente que otras; por ejemplo, en español, las vocales son muy frecuentes, ocupando alrededor del 45% del texto, siendo la E y la A las que aparecen en más ocasiones, mientras que la frecuencia sumada de F, Z, J, X, W y K no alcanza el 2%. Igualmente, se pueden reunir estadísticas de aparición de pares o tríos de letras. El análisis de frecuencias revelará el contenido original si el cifrado utilizado no es capaz de ocultar estas estadísticas. Por ejemplo, en un cifrado de substitución simple (en el que cada letra es simplemente substituida por otra), la letra más frecuente en el texto cifrado sería un candidato probable para representar la letra "E".

El análisis de frecuencias se basa tanto en el conocimiento lingüístico como en las estadísticas, pero al volverse cada vez más complicados los cifrados, las matemáticas se convirtieron gradualmente en el enfoque predominante en el criptoanálisis. Este cambio fue particularmente evidente durante la Segunda Guerra Mundial, cuando los esfuerzos para romper los códigos del Eje requirieron nuevos niveles de sofisticación matemática. Más aún, la automatización fue aplicada por primera vez en la Historia al criptoanálisis, bajo la forma de los dispositivos Bomba y Colossus, una de las primeras computadoras.

Aunque la computación fue utilizada con gran éxito durante la Segunda Guerra Mundial, también hizo posible nuevos métodos criptográficos que eran órdenes de magnitud más complejos que los empleados hasta la fecha. Tomada como un todo, la criptografía moderna se ha vuelto mucho más impenetrable al criptoanalista que los métodos de pluma y papel del pasado, y parece que en la actualidad llevan ventaja sobre los métodos del puro criptoanálisis. El historiador David Kahn escribió: ""Son muchos los criptosistemas en venta hoy por parte de cientos de compañías comerciales que no pueden ser rotos por ningún método conocido de criptoanálisis. De hecho, en ciertos sistemas incluso un ataque de texto claro escogido, en el que un fragmento de texto claro seleccionado es comparado con su versión cifrada, no permite conocer el código para romper otros mensajes. En cierto sentido, entonces, el criptoanálisis está muerto. Pero éste no es el final de la historia. El criptoanálisis puede estar muerto, pero, mezclando mis metáforas, hay más de un modo de desollar un gato."" (Observaciones sobre el 50 Aniversario de la National Security Agency, 1 de noviembre de 2002). Kahn menciona a continuación las mayores posibilidades para la intercepción, la colocación de dispositivos grabadores ("bugging"), los ataques de canal lateral y la criptogtafía cuántica como sustitutos de los métodos tradicionales del criptoanálisis.

Kahn podría haberse apresurado demasiado al declarar al criptoanálisis muerto; aún no se han extinguido los cifrados débiles. En medios académicos, se presentan regularmente nuevos diseños, y también son rotos frecuentemente: el cifrado por bloques Madryga, de 1984, demostró ser vulnerable a un ataque con sólo texto cifrado disponible en 1998; FEAL-4, propuesto como sustituto para el algoritmo estándar de cifrado de datos DES fue demolido por una avalancha de ataques de la comunidad académica, muchos de los cuales no eran enteramente realizables en condiciones prácticas. En la industria, igualmente, los cifrados no están exentos de fallos: por ejemplo, los algoritmos AS/1, AS/2 y CMEA, usados en la industria de teléfonos móviles, pueden ser rotos en horas, minutos o incluso en tiempo real por equipo informático ampliamente disponible. En 2001, se demostró que el algoritmo WEP, utilizado para proteger redes Wi-Fi, es susceptible de ser atacado mediante un ataque de clave relacionada.

Los criptoanálisis exitosos han influido sin lugar a dudas en la Historia. La capacidad de leer los pensamientos, supuestamente secretos, o los planes de otros puede ser una ventaja decisiva, y nunca con mayor razón que en tiempos de guerra. Por ejemplo, durante la Primera Guerra Mundial, el descifrado del Telegrama Zimmermann fue capital para la entrada de los Estados Unidos en la guerra. En la Segunda Guerra Mundial, el criptoanálisis de los códigos alemanes, incluyendo la máquina Enigma y el código Lorenz, ha sido considerado desde un factor que apenas acortó la guerra en algunos meses en Europa, hasta un elemento crucial que determinó el resultado final (véase ULTRA). Los Estados Unidos también se beneficiaron del criptoanálisis del código japonés PURPLE durante la contienda (véase MAGIC).

Todos los gobiernos han sido conscientes desde antiguo de los potenciales beneficios del criptoanálisis para la inteligencia militar, tanto en lo puramente bélico como en lo diplomático, y han establecido con frecuencia organizaciones dedicadas en exclusiva al descifrado de códigos de otras naciones, por ejemplo GCHQ y NSA, organizaciones americanas todavía muy activas hoy en día. En 2004, surgió la noticia de que los Estados Unidos habían roto los códigos utilizados por Irán: ).

En inglés:



</doc>
<doc id="15455" url="https://es.wikipedia.org/wiki?curid=15455" title="Protestantismo">
Protestantismo

El término protestante es utilizado para referirse tanto a los grupos cristianos que se separaron de la Iglesia católica con la Reforma Protestante del sigloXVI como a los desarrollos teológicos particulares de los reformadores y las iglesias resultantes de dicha Reforma (dentro de la cristiandad).

El nombre "protestantes" se comenzó a utilizar respecto de los partidarios de las ideas luteranas de la Reforma en Alemania a raíz de su protesta y resistencia a los edictos imperiales que intentaban buscar la uniformidad religiosa de Alemania. Para otros, el apelativo se les atribuyó con ocasión de que los príncipes que seguían a Martín Lutero protestaron por no poder asistir a la Dieta de Espira en 1529, apelando al concilio.

La doctrina luterana (algunos elementos centrales de las propuestas de Martín Lutero, además de en las 95 tesis del manifiesto colocado en la puerta de la iglesia de Wittenberg, se presentan en sus obras 'Catecismo Mayor' y 'Los artículos de Esmalkalda') giraría en torno a la idea de que la Biblia es la única autoridad en materia de fe para la Iglesia y en la necesidad absoluta de la gracia de Dios para que el hombre, mediante la sola fe en Cristo y el Evangelio, pueda ser salvado por Dios en un acto de conversión interior.

El protestantismo también defiende las doctrinas de la absoluta depravación del hombre y su necesidad total de Dios, la sola mediación de Cristo, la sacramentalidad única del bautismo y la cena del Señor (cuando no son percibidos como símbolos) y las obras buenas como fruto de la fe. Además, rechaza la autoridad del papa, las indulgencias, el purgatorio, el sacrificio incruento de la misa, la devoción a los santos, la intercesión de los santos difuntos, etc.

Debido a la diversidad de grupos que se sumaron al protestantismo y sus diferencias doctrinales, el mismo no se corresponde con el modelo de una sola iglesia ni una doctrina homogénea. A pesar de las coincidencias originales expresadas principalmente en las Cinco Solas, aun en sus orígenes, no se podría hablar de un movimiento sólidamente uniforme en este aspecto. El protestantismo habitualmente se expresa en tres tipos de movimientos o congregaciones:


Existen en el mundo alrededor de 800 millones de protestantes, distribuidos en diferentes denominaciones que siguen diferentes líneas interpretativas de la Biblia.

El término "protestante" deriva del latín "protestari", que significa ‘declaración pública o protesta’, en la protesta de los cinco príncipes electores y 14 ciudades imperiales alemanas contra la decisión de la Dieta de Espira en 1529, que reafirmaba el edicto de la Dieta de Worms de 1521, en el que se proscribía creer y enseñar las doctrinas luteranas. El término "protestante" no se utilizó en su origen para describir a los reformadores, sino posteriormente para describir a los diferentes grupos disidentes de la ortodoxia católica. Desde entonces se ha empleado en diferentes sentidos, siendo común para referirse a aquellos devotos no pertenecientes a la Iglesia católica ni a la ortodoxa.

Se trata de una de las principales divisiones de la cristiandad, junto con las Iglesias ortodoxas orientales, las Iglesias ortodoxas occidentales y el catolicismo. Las doctrinas de las diversas ramas protestantes varían, pero son prácticamente unánimes en lo que implica una relación personal directa del individuo con Dios sin ninguna institución de por medio y la Biblia como autoridad última en asuntos de fe, conocido como "sola scriptura".

El 31 de octubre de 1517, Martín Lutero, un fraile agustino alemán, publicó las 95 tesis, las cuales, de acuerdo con la tradición, clavó en la puerta de la Iglesia del palacio de Wittenberg, práctica común entonces. Las tesis condenaban la avaricia y el paganismo en la Iglesia católica como un abuso, y pedían una disputa teológica en lo que las indulgencias podían dar. Sin embargo, en sus tesis no cuestionaba directamente la autoridad del papa para conceder indulgencias. Lutero criticaba en particular la práctica común por aquel entonces de la venta de indulgencias, de las que la Iglesia católica de LeónX hizo un uso extensivo para recaudar fondos dedicados a la construcción de la Basílica de San Pedro, algo que consideraba contra las enseñanzas bíblicas, poniendo en duda la autoridad del papa y la doctrina del purgatorio. Lutero mantuvo que la salvación se garantizaba por la fe sola, expresando que las buenas obras y los sacramentos administrados por la Iglesia católica no eran necesarios para ser salvado. Lutero envió una copia de las tesis a su obispo, el cual las reenvió a Roma.
Tras ignorar inicialmente a Lutero, el papa LeónX escribió una refutación académica de sus tesis. En ella mantuvo la autoridad papal sobre la Iglesia y condenó cada “desviación” como una apostasía. Lutero replicó, iniciándose una controversia que culminó con la excomunión de Lutero por el papa LeónX el 3 de enero de 1521 mediante la bula "Decet Romanum Pontificem".

Debido a los errores de la Iglesia católica, que durante mucho tiempo había estado atesorando bienes materiales y se había empeñado en una lucha por el poder terrenal, las capas sociales más bajas, campesinos, artesanos y comerciantes estaban descontentos con las jerarquías eclesiásticas, que se llevaban el diezmo de sus bienes y de los que prácticamente no recibían nada a cambio. La vida de lujo y pecado de los cardenales y obispos en Roma era bien conocida por toda la población de Europa e incluso reyes y emperadores sentían rencor hacia el Papado que interfería frecuentemente en el gobierno. Sin embargo, ya desde el sigloXIII, con Francisco de Asís, se planteaba la cuestión de si la Iglesia debería acumular riquezas o debería repartirlas entre los pobres.

Se denomina “Período de la Prerreforma” al movimiento iniciado por John Wyclif, un peregrino inglés de origen judío que quería que la gente interpretara la Biblia por sí misma en vez de que la Iglesia tomara decisiones en el estilo de vida de esas personas. En el sigloXIV, Wyclif defendió, en su natal Inglaterra, varias opiniones que atentaban contra la autoridad de la Iglesia, criticando las riquezas del papado y las indulgencias mediante las que los ricos podían comprar el perdón para determinados pecados, incluso por anticipado. Asimismo, hizo que la Biblia se tradujera al inglés y encomendó a discípulos suyos, conocidos como «Los Predicadores de los Pobres», que predicaran en inglés, cuando la Santa Sede imponía el latín en todas las predicaciones. Wyclif y William Tyndale pudieron traducir la Biblia al inglés en contra de la Iglesia católica, para que las personas pudieran leerla en su lengua vernácula. De estos libros traducidos se imprimieron muy pocos, alrededor de 6000 ejemplares.

Después de muerto, la Iglesia le consideró hereje e hizo que, 44 años después de su muerte, su cuerpo fuera desenterrado y quemado en la hoguera, pero sus ideas calaron hondo en el ánimo de Jan Hus, un reformista bohemio que inició una campaña contra la Iglesia. Su ejecución por hereje en 1415 provocó una guerra civil en Bohemia que fue sofocada por el emperador y el Papa. A lo largo de todo este tiempo, tanto el Movimiento Lolardo o Wycliffita, como el Movimiento Husita y la protesta místico-evangélica de Girolamo Savonarola, señalaron de manera objetiva y frontal las diferentes opiniones sobre el cristianismo en la Edad Media, dentro de una perspectiva bíblica y evangélica.

El desarrollo de la imprenta a mediados del sigloXV hizo que las ideas anticlericales tuvieran una mayor difusión, y cuando Martín Lutero publicó, en 1517, sus 95 tesis contra las indulgencias papales, pudo difundir sus ideas mucho más que sus predecesores. Excomulgado por el Papa, condenado por el emperador, perseguido por ejércitos y sacerdotes, Lutero se mantuvo oculto durante más de un año en el castillo de Wartburg traduciendo la Biblia al alemán y escribiendo artículos que eran publicados y distribuidos masivamente. El resultado fue una revuelta de los campesinos que pensaron encontrar una liberación de la tiranía eclesiástica. Lutero, sin embargo, no pretendía desatar una guerra, por lo que publicó un panfleto en el que exhortaba a los campesinos a abandonar las armas. Ante esta actitud conciliadora de Lutero a dicha rebelión, muchos nobles se volvieron partidarios suyos.

Tras el fin de la revuelta, CarlosV concedió que cada Estado pudiera decidir, dentro de su propio territorio, sobre cuestiones religiosas, pero en 1529 la mayoría católica hizo que se derogase esta norma. Los luteranos elevaron su más enérgica protesta, lo que les hizo ganar el antes mencionado apodo de “protestantes”. CarlosV estaba empeñado en acabar con los luteranos, pero distraída su atención por varias guerras contra Francia y el Imperio turco, no pudo enviar tropas hasta quince años más tarde. Para entonces ya era tarde. El luteranismo se había convertido en la fe de más de la mitad de la población de Alemania y, aunque se perdieron batallas al principio, los luteranos consiguieron ganar la libertad religiosa.

En el plazo de dos décadas más, la Reforma se había expandido por la mayor parte del noroeste de Europa. En Inglaterra el rey EnriqueVIII rechazó la autoridad papal sobre la Iglesia, y la Iglesia de Inglaterra entró en una reforma que la volvió una entidad esencialmente protestante (aunque a menudo los anglicanos, también llamados episcopalianos, se clasifican aparte). En Suiza, Francia, partes de Alemania, de Escocia y de los Países Bajos comenzó una segunda corriente de reforma no luterana, influida principalmente por Juan Calvino, el francés convertido en ginebrino, y el líder suizo Ulrico Zuinglio.

Al mismo tiempo apareció un estilo más radical de Protestantismo en el ala izquierda del movimiento. Anabaptistas, menonitas y otros rebautizaron cristianos y los iniciaron en un movimiento que rechazó drásticamente las prácticas católicas, incluso las que el luteranismo, calvinismo y anglicanismo no habían rechazado.

Como se ha mencionado, la Reforma se extendió desde sus bases originales a Escandinavia y la Europa Central, pero apenas penetró en Rusia y en el sudeste de Europa, donde prevalecía la Iglesia ortodoxa, o en la Europa meridional, que seguía firmemente católica. Después de una serie de guerras religiosas desde mediados del sigloXVI hasta mediados del XVII, la mayoría de los protestantes (excepto los radicales) y los católicos adoptaron el principio de que los gobernantes de una región determinarían la religión de esa provincia o Estado. La separación de la Iglesia y el Estado, un principio que otros protestantes vinieron a sostener a fines del sigloXVIII, comenzó a romper la primacía protestante en el noroeste de Europa.

En la última parte del sigloXVIII y a través del sigloXIX y hasta el presente, los misioneros protestantes extendieron el movimiento por casi todo el mundo. Los puntos de penetración protestantes fueron muchas costas asiáticas y africanas, pero hasta hace relativamente poco que el protestantismo no llegó hasta la católica América hispana. A partir de 1607, cuando los anglicanos llegaron a Virginia, y hasta finales del sigloXIX, después de la inmigración en gran escala desde Europa del sur y de Irlanda, se creía que Norteamérica, menos Quebec, era territorio en gran parte protestante.

De una forma algo más pacífica, las ideas protestantes se infiltraron en muchos países europeos, unas veces apoyadas por la burguesía, otras por la nobleza, en ocasiones directamente por la monarquía. Apenas cincuenta años después de morir Lutero, el protestantismo había cambiado por completo el mapa de la sociedad.

La idea fundamental del protestantismo es que la Biblia es la Palabra de Dios pero, al contrario de lo que siempre afirmaron los católicos, cualquiera puede interpretarla y comprenderla. Así, libres de la autoridad eclesiástica, los protestantes pueden leer la Biblia y tras meditar en lo que han leído, pueden sacar sus propias conclusiones, conclusiones que posteriormente podrán ser discutidas con otras personas.

Esta libertad en la interpretación bíblica ha provocado que a lo largo de los años hayan surgido numerosas denominaciones, cada una con una interpretación distinta de diversos pasajes de la Biblia, pero también ha contribuido a darle un valor al pueblo, libre por fin de la autoridad religiosa, que fue el primer paso para las sociedades más democráticas.

La traducción de la Biblia a los diversos idiomas europeos, favorecida también por el auge de la imprenta, ha contribuido a la difusión de la cultura, haciendo que en los países protestantes el analfabetismo descendiera sensiblemente.

Entre los principales y más destacados personajes prerreformadores se señalan los siguientes: John Wyclif (1324-1384), William Tyndale, Jan Hus (1369-1415) y Girolamo Savonarola (1452-1498).

El Renacimiento, con su mentalidad crítica, trajo consigo el cuestionamiento de las enseñanzas y prácticas de la Iglesia, confrontándose principios humanistas con la teología escolástica medieval.

Con la invención de la imprenta como nuevo elemento divulgador, las ideas de los reformadores se expandieron con rapidez. El crecimiento de la ciudad y de su elemento intelectual, la Universidad, fue un catalizador de la Reforma.

El fortalecimiento de las monarquías nacionales europeas creó una palpable fricción entre poderes. La decadencia de los postulados dogmáticos de la reforma eclesiástico-cluniacense, y más concretamente de los papas Gregorio VII, Inocencio III y Bonifacio VIII sobre el poder supremo del papado, así como la corrupción de la máxima cúpula del sistema jerárquico eclesiástico medieval desde principios del sigloXIV con los cismas de Aviñón y de Occidente dieron lugar al surgimiento de exposiciones teológicas como las de Juan Taulero, de Guillermo de Occam y de Marsilio de Padua de un trasfondo antipapal. Surge la tesis conciliarista. El creciente fervor nacionalista europeo llevó a mirar con desconfianza y repudio el dominio papal sobre las diferentes naciones del viejo continente. Muchos monarcas vieron en la Reforma Protestante un modo de afianzar el Estado nacional y su poder monárquico o imperial. En el centro y norte de Europa hubo países, como Suiza o Suecia, donde la Reforma fue uno de los instrumentos más eficaces de la lucha contra los países católicos que los dominaban.

Influyen también la rápida decadencia del escolasticismo y el resurgimiento de la teología agustiniana con unos caracteres renovadores, volviendo con mayor vigor la lectura y el estudio de la teología de san Agustín en detrimento de la teología tomista.

Los principales reformadores, de vasta cultura teológica y humanista, se consideraban a sí mismos fieles cristianos que aspiraban a regresar a las doctrinas apostólicas y a renovar la Iglesia cristiana en la práctica y doctrina.

Juan Calvino estudió en la Sorbona y su padre trabajaba con un obispo; Lutero era monje y profesor universitario de Biblia; Zuinglio era sacerdote y humanista. De acuerdo con el programa de los humanistas, buscaron en las fuentes de la antigüedad cristiana las bases para una renovación. Releyeron las Sagradas Escrituras y a los Padres de la Iglesia, (especialmente a San Agustín), interpretando una visión de la fe y una doctrina más bíblica y cristocéntrica, despreciando, por otro lado, toda la tradición cultural y religiosa acumulada por la Iglesia desde los primeros siglos.

La diseminación de las ideas protestantes fue facilitada por la invención de la imprenta, que hizo posible difundir una amplia literatura apologética, bíblica y devocional y fomentó la edición de nuevas traducciones de la Biblia en lenguas vernáculas. Estas revisiones del texto hicieron patente la débil base de algunas doctrinas medievales. La nueva forma de fundamentar la autoridad, junto con el rechazo de la formulación escolástica ahora sustituida por lenguaje bíblico, hacía difícil a los teólogos católicos rebatirla. En el Concilio de Trento, los obispos católicos partidarios de Roma optarían por limitar el acceso laico a las escrituras, estableciendo que la Vulgata Latina era la única Biblia autorizada y redactando un índice de libros prohibidos.

Como resultado del apoyo de los gobiernos nacionales y locales, la Reforma Protestante logró éxito en amplias áreas de Europa. Se hizo predominante en el norte de Alemania y en Escandinavia, en su forma luterana. En Escocia prosperó la Iglesia presbiteriana de inspiración calvinista. También las Iglesias reformadas fructificaron en los Países Bajos, en las ciudades suizas y en el oriente de Hungría. Con posterioridad retornaron a la influencia del catolicismo Francia, Polonia, Bohemia, Bélgica, Hungría y amplias regiones de Alemania (sobre todo en el sur y el oeste). No obstante, con el desarrollo de los imperios europeos, particularmente el británico, el protestantismo continuó su expansión. Los siglosXIX y XX presenciaron una fuerte labor misionera que lo expandió por Asia, Oceanía, África y América. Hoy en día, cálculos estimativos señalan que más de 500 millones de personas profesarían alguna de las diversas formas del protestantismo moderno.

Los fundadores y colaboradores de la Reforma utilizaron todos los medios a su alcance para la extensión de la misma, valiéndose de cualquier factor que pudiese contribuir favorablemente con su movimiento. En relación a este punto podemos señalar algunos medios analizados y criticados por sus detractores (Iglesia católica):

En Alemania surgió la Iglesia luterana. En la Suiza de habla alemana, Ulrico Zuinglio y otros comenzaron también un intento de reforma de la Iglesia católica. Pero Juan Calvino fue el dirigente más destacado de la Reforma Protestante en Suiza. La Reforma que se había iniciado casi simultáneamente en Zúrich (cantón de habla alemana) y Ginebra (francófona) fue extendiéndose por los países vecinos, llegando a Escocia de la mano de John Knox, que se había formado en Ginebra, dando origen a la Iglesia Presbiteriana.

Mientras tanto, la Iglesia de Inglaterra (anglicana) no se dejó influir en un primer momento por el protestantismo, pero tras su ruptura con la Iglesia de Roma, comenzó un paulatino y vacilante acercamiento hacia los ideales reformados. Actualmente las Iglesias de la Comunión anglicana se declaran abiertamente reformadas. De ellas surgió la Iglesia Metodista, que, junto a los presbiterianos, y a las iglesias bautistas, entre otros, se conocen históricamente como disidentes.

Fuera de ese protestantismo, que muchos estudiosos denominan “magisterial”, se dio otra vertiente, que se distinguió tanto del catolicismo como de las Iglesias protestantes de carácter nacional. Esta corriente recibe el nombre de "Reforma Radical", cuyos integrantes pasaron a conocerse como anabaptistas, que rechazó la unión de la Iglesia cristiana con el Estado y repudiaron el bautismo infantil, constituyéndose en iglesias independientes o segregadas que dieron lugar a corrientes como los menonitas, e influyeron a los fundadores de otras, como las iglesias bautistas.

Desde finales del sigloXIX empezaron a surgir otras diferentes ramas influenciadas por los movimientos de reavivamiento. La principal corriente protestante surgida en ese periodo es el pentecostalismo, que empezó en Estados Unidos y se ha extendido principalmente a Latinoamérica y África. Las iglesias pentecostales dan un énfasis mayor en los dones espirituales descritos en el Nuevo Testamento, principalmente el “hablar en lenguas”.

Cada rama o denominación del protestantismo suele estar subdividida en diversos grupos independientes a los que también se les suele llamar “denominaciones” o “familias denominacionales”. Estos grupos se suelen distinguir entre los de su propia rama por diferencias cuanto al énfasis en determinados puntos doctrinales y aplicación de los textos bíblicos, pero también por estar en diferentes países o incluso regiones de una misma nación. También se suele dar el caso de divisiones provocadas por divergencias administrativas, aunque esto afecta mucho más a iglesias locales que a grupos enteros.

Asimismo existe una infinidad de congregaciones locales o grupos de congregaciones que no poseen vínculo formal con denominaciones instituidas, a las cuales se suele llamar “iglesias independientes”. Este tipo de iglesias ha experimentado una gran proliferación en las últimas décadas del sigloXX especialmente dentro del pentecostalismo, donde el énfasis en revelaciones divinas hace que muchas personas decidan tener su propio ministerio, empezando sus propias congregaciones de forma independiente, es decir, sin vínculo institucional.

Las iglesias independientes suelen mantenerse a nivel local como un solo grupo, aunque experimenten un gran crecimiento numérico, lo cual ha dado lugar a diversas “megaiglesias”, que son iglesias locales con miles de miembros. Aun así, existen iglesias independientes que se subdividen hasta el punto de convertirse ellas mismas en denominaciones, además de otras que se unen en fraternidades de iglesias que acaban transformándose también en denominaciones.








Del mismo modo que no se puede hablar de una sola iglesia protestante, tampoco se puede hablar de una sola doctrina protestante coherente y cohesionada. De hecho, la variedad doctrinal que el protestantismo ha ido adoptando a lo largo de su evolución ha sido una de las causas de su fragmentación. Aun con todo, se puede hablar de una doctrina de mínimos que con distinta intensidad sí comparten todas las iglesias herederas de la Reforma. Tradicionalmente se suele resumir esta doctrina común en las “cinco solas”, que desarrolladas comprenden el núcleo de la fe protestante:

Además de las “cinco solas”, el protestantismo, como la mayoría de las corrientes del cristianismo, comparte igualmente las creencias en la Trinidad, la cristología clásica o de los primeros concilios ecuménicos, la celebración de los sacramentos del bautismo y la cena del Señor (eucaristía), aunque con diferencias importantes, la creencia en el Juicio Final y la resurrección de la carne, etc. Algunas de sus iglesias se adhieren a los credos niceno-constantinopolitano y de Atanasio (Iglesia Anglicana, Iglesia Luterana, Iglesia Metodista, Iglesia Presbiteriana y calvinistas en general, etc.).

En cuanto a la eclesiología el protestantismo concibe a la Iglesia como una, santa, universal y apostólica igual que las demás iglesias cristianas. Lo peculiar de su eclesiología es que defiende la idea de una doble dimensión de la iglesia, una invisible y otra visible. Es invisible por cuanto es la reunión de todos los santos en el cuerpo místico de Cristo en todos los tiempos y lugares, la unicidad y santidad de la Iglesia está garantizada, pues, en Cristo. Es visible en la denominación o iglesia local en la que se congrega el creyente. Se acepta la existencia de distintas jurisdicciones en la iglesia y se rechaza la idea de que ésta deba estar gobernada por una sola persona o por una sola institución. El ecumenismo es percibido como la necesidad de buscar la unidad doctrinal en lo esencial y la intercomunión de todos los cristianos, pero no se acepta un ecumenismo que conduzca a la construcción de una sola iglesia gobernada por una sola institución.

Para entender la doctrina protestante hay que tener en cuenta que en su génesis fue un movimiento de reforma de la Iglesia católica. Por este motivo, muchas de las doctrinas protestantes sólo tienen sentido y deben su existencia al catolicismo y a la necesidad o intención de corregirlo de lo que fueron percibidos como errores por los reformadores protestantes. Un ejemplo que deja clara esta génesis dialéctica de ciertas doctrinas protestantes es, por ejemplo, la negación del purgatorio. El purgatorio en el protestantismo sencillamente no tiene cabida en su teología ni en sentido alguno en sus desarrollos positivos, pero aun así es doctrina usual en confesiones y catecismos protestantes el decir: “el purgatorio no existe”. Algunas doctrinas protestantes con este origen son:

En un principio, los protestantes expresaron sus posiciones doctrinales por medio de Confesiones de Fe, breves documentos apologéticos. En el luteranismo destaca la Confesión de Augsburgo. En el ámbito de la reforma calvinista, la Confesión Escocesa (1560), La Segunda Confesión Helvética (1531) y la Confesión de Fe de Westminster (1647). En el anglicanismo destacan Los Treinta y Nueve Artículos de Religión de la Iglesia de Inglaterra que concilian posiciones anglicanas y reformadas. Las iglesias bautistas y evangélicas también tienen sus propias declaraciones y confesiones de fe. La declaración teológica de Barmen, contra el régimen nazi, y la breve declaración de fe de la Iglesia presbiteriana en los Estados Unidos son ejemplos de declaraciones recientes.

La enseñanza doctrinal en el protestantismo suele realizarse en la iglesia mediante la predicación y la escuela dominical, predominando el aspecto ético y religioso.

La educación que la Reforma implantó desde sus inicios con Lutero, suponía la lectura de la Biblia, surgiendo la necesidad de enseñar a leer a todos, lo que llevó a que los reformadores se interesaran por la enseñanza popular. Cabe destacar que cada rama del protestantismo tiene características propias en cada país, además de que las doctrinas se comenzaron a impartir en lenguas vernáculas, o sea, en el idioma de cada país.

Diversos autores han destacado el importante papel que tuvo la Reforma protestante en el impulso de la educación y alfabetización pública, si éste se compara con la situación en los países católicos, surgiendo como una reacción eclesiástica, pero con un carácter religioso, alentándose con insistencia el estudio bíblico personal y colectivo, así como la participación activa de todos los miembros (laicos y ministros) en la formación para la evangelización. Generalmente es la predicación el medio más usado, aunque existen catecismos como el de Heidelberg y el Mayor en el luteranismo o el de Westminster en el presbiterianismo. Los seminarios y escuelas bíblicas son los centros de estudio teológico superior.

El país con mayor número de protestantes es Estados Unidos, donde pese a la pérdida de peso de los “WASP”, tradicionalmente a favor de otros grupos (especialmente los hispanos, de mayoría católica), la mayor parte de los estadounidenses pertenece a alguna confesión protestante. Entre los de mayor población, el que tiene el mayor porcentaje es el Reino Unido, cuyas confesiones mayoritarias son la Iglesia de Inglaterra (anglicana) y la Iglesia de Escocia (presbiteriana).

Los principales grupos protestantes comenzaron a establecerse en América Latina en el sigloXX. Los presbiterianos se instalaron en Argentina en 1836, en Brasil en 1859, en México en 1872 y en Guatemala en 1882. Los metodistas siguen un itinerario parecido: México en 1871, Brasil en 1886, Antillas en 1890, Costa Rica, Panamá y Bolivia en los últimos años del siglo; mientras que en Ecuador, Colombia y Perú se establecieron primeramente los bautistas y los pentecostales, así como una parte de los metodistas.

Actualmente las comunidades protestantes han ido ganando terreno frente al catolicismo en América Latina en general, ampliando su penetración en diversos países, en especial en Colombia y Centroamérica.



</doc>
<doc id="15456" url="https://es.wikipedia.org/wiki?curid=15456" title="Henri Léon Lebesgue">
Henri Léon Lebesgue

Henri Léon Lebesgue (; Beauvais, 28 de junio de 1875 - París, 26 de julio de 1941) fue un matemático francés.

Nació en Beauvais, Oise, Picardie, Francia. Estudió en la Escuela Normal Superior y en el período 1899 - 1902 impartió clases en el Liceo de Nancy. En 1910 recibió una cátedra en la Universidad de la Sorbona.

Lebesgue es fundamentalmente conocido por sus aportes a la teoría de la medida y de la integral. A partir de trabajos de otros matemáticos como Émile Borel y Camille Jordan, Lebesgue realizó importantes contribuciones a la teoría de la medida en 1901. Al año siguiente, en su disertación "Intégrale, longueur, aire" ("Integral, longitud, área") presentada en la Universidad de Nancy, definió la integral de Lebesgue, que generaliza la noción de la integral de Riemann extendiendo el concepto de área bajo una curva para incluir funciones discontinuas. Este es uno de los logros del análisis moderno que expande el alcance del análisis de Fourier.

También aportó en ramas como la topología, la teoría del potencial y el análisis de Fourier. En 1905 presentó una discusión sobre las condiciones que Lipschitz que Jordan habían utilizado para asegurar que "f(x)" es la suma de su serie de Fourier.

A partir de 1910 no se concentró más en el área de estudio que él había iniciado, debido a que su trabajo era una generalización, y él era temeroso de las mismas. En sus palabras: "Reducida a teorías generales, las matemáticas serían una forma hermosa sin contenido. Morirían rápidamente." A pesar de que desarrollos posteriores demostraron que su temor no tenía fundamentos, éste nos permite entender el curso que siguió su trabajo.

Además de aproximadamente 50 artículos, escribió dos libros: "Leçons sur l'intégration et la recherché des fonctions primitives" (1904) y "Leçons sur les séries trigonométriques" (1906).

Además de los distintos conceptos matemáticos que llevan su nombre, se tiene que:


Biografía


</doc>
<doc id="15458" url="https://es.wikipedia.org/wiki?curid=15458" title="Organización territorial de Cuba">
Organización territorial de Cuba

El territorio de la República de Cuba se divide en 15 provincias y el Municipio Especial Isla de la Juventud. Las provincias, a su vez, se dividen en municipios, 168 en total (incluyendo el Municipio Especial).

La creación de nuevas unidades territoriales y sus límites es materia de ley. Los cambios más recientes fueron aprobados por la Asamblea Nacional en agosto en 2010 (puestos en vigor a partir del 1 de enero de 2011), los cuales consistieron en la creación de dos nuevas provincias: Artemisa y Mayabeque a partir de la segmentación de la Provincia de La Habana, junto con el traspaso de los tres municipios más orientales de la provincia de Pinar del Río. También se extinguió el municipio de Varadero en la Provincia de Matanzas, integrando su territorio al municipio de Cárdenas. La anterior organización en 14 provincias y 169 municipios databa de 1976.

La capital del país es la ciudad de La Habana, que constituye una provincia, cuyo nombre oficial de 1976 a 2010 fue Ciudad de La Habana.

Las provincias y municipios cuentan con personalidad jurídica para todos los efectos de la ley. Tienen sus propias asambleas representativas y estructuras de gobierno, aunque con una estrecha dependencia de las autoridades centrales.

En cada provincia y municipio del país existe un Comité del Partido Comunista de Cuba, el que como fuerza dirigente de la sociedad y el Estado cubano, ejerce la misma función a nivel local. Los primeros secretarios provinciales y municipales son la principal autoridad política local.

La Asamblea Municipal del Poder Popular es el máximo órgano representativo municipal. Está integrada por delegados elegidos en cada circunscripción electoral a partir de candidatos propuestos en asambleas populares. La duración del mandato de sus delegados es de dos años y medio. La Asamblea elige a su presidente, a su vicepresidente, a su secretario y a las comisiones de trabajo.

La Asamblea elige al Consejo de la Administración Municipal que es el órgano de gobierno local. El presidente de la Asamblea es el presidente del Consejo, asistido por un vicepresidente encargado de la actividad diaria de gobierno y por otros vicepresidentes ramales. En las provincias de Artemisa y Mayabeque el cargo de Jefe de la Administración Municipal recae en un funcionario diferente al Presidente de la Asamblea Municipal, por Acuerdo de la Asamblea Nacional que autorizó de forma experimental la división de funciones en los municipios de estas dos provincias.

Los municipios se dividen, para facilitar las relaciones con los electores, en consejos populares integrados por los propios delegados y presididos por uno de ellos.

Los municipios de Santa Clara, Camagüey, Holguín y Santiago de Cuba (municipios de gran población), se dividen además en distritos, donde se agrupan varios consejos populares, con el fin de descentralizar y acercar a la población las diferentes oficinas administrativas.

La Asamblea Provincial del Poder Popular es el máximo órgano representativo provincial. Está integrada por delegados elegidos por voto directo de los electores a partir de los propuestos por las Comisiones de Candidatura y que integran una única lista cerrada. Los candidatos propuestos son aproximadamente un 50% delegados municipales y el resto personalidades de diferentes áreas de la vida social de la provincia. La duración del mandato de los delegados provinciales es de cinco años. La Asamblea elige a su presidente, a su vicepresidente, a su secretario y a las comisiones de trabajo.

La Asamblea elige al Consejo de la Administración Provincial que es el órgano de gobierno provincial. El presidente de la Asamblea es el presidente del Consejo, asistido por un vicepresidente encargado de la actividad diaria de gobierno y por otros vicepresidentes ramales. En las provincias de Artemisa y Mayabeque el cargo de Jefe de la Administración Provincial recae en un funcionario diferente al Presidente de la Asamblea Provincial, por Acuerdo de la Asamblea Nacional que autorizó de forma experimental la división de funciones en estas dos provincias.

Los órganos (Asamblea y Administración) del Municipio Especial Isla de la Juventud son los mismos de cualquier municipio pero en estos coinciden competencias municipales y provinciales.



</doc>
<doc id="15460" url="https://es.wikipedia.org/wiki?curid=15460" title="Célula endotelial">
Célula endotelial

Una célula endotelial es un tipo de célula aplanada que recubre el interior de los vasos sanguíneos y sobre todo de los capilares, formando parte de su pared.

El núcleo de las células endoteliales está muy aplanado y por eso aparece elíptico en los cortes visualizados al microscopio. La región nuclear y más gruesa de la célula hace prominencia en la luz. La porción periférica y más delgada de la célula es tremendamente fina, y las membranas que miran a la luz o al tejido están separadas por una capa de citoplasma de un grosor de 0,2 a 0,4 micras. 

Hay en la región cercana al núcleo un complejo de Golgi y unas pocas mitocondrias, mientras que en la región delgada periférica del citoplasma hay elementos tubulares tortuosos del retículo endoplásmico. Son raros los lisosomas, pero no son infrecuentes los cuerpos multivesiculares. 

Un rasgo llamativo de las células endoteliales es la presencia de una numerosa población de vesículas del plasmalema de unos 70 nanómetros de diámetro, de cuello delgado, que están presentes en ambas superficies celulares y que se abren a la luz y al espacio extravascular. 

La superficie luminal de las células es normalmente de perfil liso, pero a menudo los bordes de las células vecinas pueden superponerse y entonces, puede proyectarse hacia la luz por corta distancia una cresta o lengüeta. Faltan de ordinario los desmosomas y la "zonula adherens", pero hay una unión ocluyente de pequeño tamaño que en las preparaciones de criofractura muestra de uno a tres cordones intramembranosos paralelos en la cara E.

En la superficie extraluminal o externa, las células endoteliales están en contancto con la membrana basal y sustancias como colágeno, proteglicanos, heparánsulfato, integrinas; en la parte luminal las células endoteliales en contacto con la sangre poseen mucopolisacáridos, glucoproteínas, fibrinógeno y algo de fibrina.

En el cuerpo humano, el conjunto del endotelio vascular puede pesar unos 1,5 kilogramos y comprende un área de unos 600 metros cuadrados.

Las células endoteliales forman el endotelio vascular que es un epitelio plano simple (de una sola capa de células) que recubre la cara interna de los vasos sanguíneos y el corazón. Las células endoteliales tienen varias funciones en la homeostasis, entre las que figuran las siguientes: 


</doc>
<doc id="15461" url="https://es.wikipedia.org/wiki?curid=15461" title="Sistema educativo de Chile">
Sistema educativo de Chile

La educación en Chile se divide en cuatro fases —parvularia, básica, media y superior—, de los cuales los dos segundos son obligatorios. La educación chilena está regida por la Ley General de Educación (LGE) de 2009, sucesora de la Ley Orgánica Constitucional de Enseñanza (LOCE).

Los niveles parvulario, básico y medio del sistema de gobierno —así como los centros de formación técnica de gobierno superior— están regulados y vigilados por el Ministerio de Educación. El Consejo Superior de Educación (CSE) tiene como principales funciones pronunciarse sobre la solicitud de reconocimiento oficial de las universidades e institutos profesionales, verificar su desarrollo, establecer sistemas de examen selectiva y acreditación, recomendar sanciones y realizar estudios sobre la educación superior.

El derecho a la educación y a la libertad de enseñanza están resguardados en la Constitución Política de la República; sin embargo, para tener reconocimiento legal, los establecimientos particulares deben cumplir con los objetivos fundamentales y contenidos mínimos obligatorios (OF-CMO), prescritos por los artículos 15 a 20 de la LOCE. Dichos requisitos y normas son establecidas por el Ministerio de Educación previo informe del CSE.

Pese a que el derecho a la educación está constitucionalmente resguardado, en Chile existe una serie de problemas relacionados con la calidad y el acceso, sobre todo a nivel superior. En la última década, ha habido dos grandes olas de manifestaciones en relación a la situación de la educación en el país: en 2006 y 2011 —esta última se vio inmersa en un año de profunda y activa protesta social en el país en distintos ámbitos—.

En los últimos años, más de 800 escuelas municipales cerraron y apenas el 36 % de los alumnos está inscrito en colegios públicos.

En la Colonia, la educación estuvo a cargo principalmente de la Iglesia, especialmente las congregaciones religiosas establecidas en el país, destacando los jesuitas y dominicos. En el nivel primario el enfoque estaba en la enseñanza de la escritura y lectura, más algunas lecciones de catecismo y aritmética. También en este periodo las órdenes de los mercedarios y franciscanos formaron escuelas en Concepción, Osorno, La Imperial y Valdivia. Asimismo, debido a la necesidad de convertir a los indígenas a la fe católica, se abrió en Penco un curso de lengua araucana, pero no duró por la escasez de alumnos. También se mandó a hacer una escuela donde los Mapuches aprendiesen castellano, el Colegio de Naturales de Chillán (1697).

En cuanto a la educación superior, en el siglo XVII funcionaron en Chile tres centros de enseñanza superior con categoría de universidades pontificias, que tenían un carácter eminentemente eclesiástico: el Colegio Máximo San Miguel de los jesuitas y la Universidad de Santo Tomás de Aquino de los dominicos, ambas en Santiago; mientras que en Concepción funcionó durante 43 años la Universidad Pencopolitana dirigida por los jesuitas. En 1758, por autorización de Felipe V, se erige la Universidad de San Felipe, antecesora de la actual Universidad de Chile.

Con el advenimiento de la Independencia, la educación se transforma en un tema de interés para los dirigentes patriotas. En 1812 se establece la Biblioteca Nacional y en 1813 se crea el Instituto Nacional. Se establece la obligatoriedad de mantener escuelas de primeras letras por el Estado en los diversos textos constitucionales.

Una vez afianzada la organización del estado, se suceden diversos hitos en materia educacional. Así, en 1842 la U. de San Felipe es convertida en la Universidad de Chile, y se crea la Escuela Normal de Preceptores, la primera en su tipo en Sudamérica. Asimismo, para el desarrollo de la educación técnica, en 1848 se establece la Escuela de Artes y Oficios. En 1860 se establece la Ley Orgánica de Instrucción Primaria, y en 1877 el decreto Amunátegui permite la incorporación de la mujer a la educación superior.

Durante el siglo XIX convivieron los sistemas público y privado de educación, este último dominado por la Iglesia Católica. Con el advenimiento de la República Liberal, surgen en el marco de las "Cuestiones Teológicas" debates sobre la vigilancia estatal en la educación versus la libertad de enseñanza defendida por los colegios confesionales. Uno de los hitos más importantes de este enfrentamiento fue la creación, en 1888, de la Universidad Católica de Chile, primer centro privado de estudios superiores del país. Por otro lado, para la formación de profesores de enseñanza secundaria, se crea el Instituto Pedagógico en 1889.

El siglo XX fue generoso tanto en la creación de establecimientos como en las reformas impulsadas. En cuanto a lo primero, en 1921 se establece la primera universidad fuera de Santiago, la Universidad de Concepción (aunque existieron cursos universitarios sueltos previamente en Valparaíso). Asimismo, se crean otras cuatro universidades privadas en regiones: Católica de Valparaíso (1928), Federico Santa María (1931), Austral de Valdivia (1954) y Católica del Norte (1956). Mientras, en 1947 la Escuela de Artes y Oficios, junto a otros institutos técnicos públicos, se refunden y crean la Universidad Técnica del Estado. Todas las mencionadas anteriormente, además de las universidades de Chile y Católica de Santiago conforman el Consejo de Rectores de las Universidades Chilenas en 1954. Por otro lado, la Universidad de Chile se expandiría por el país creando varias sedes regionales, lo que sería imitado por la UTE y la Católica.

En cuanto a las reformas educacionales, en 1920 la Ley de Instrucción Primaria Obligatoria estableció como nivel mínimo de educación el 3.° año de preparatoria. En 1945 se hicieron planes de reforma parcial de la educación escolar, y en 1953 se crea la Superintendencia de Educación y la JUNAEB. Con todo, en 1965 se inicia bajo el gobierno de Eduardo Frei Montalva una profunda reforma educacional en la que se redujo de 6 a 4 años la enseñanza secundaria, que pasaría a llamarse "educación media", mientras que la educación preparatoria, que se renombró "educación básica", pasó de 6 a 8 años, que serían obligatorios, y se dividen las jornadas en dos. Por otro lado, las universidades pasarían por el período de la "reforma universitaria", en que se pretendió otorgar un cariz más democrático al gobierno de estas instituciones.

Tras el golpe de estado de 1973, se vivió un proceso de retroceso en materia de democracia educacional, a la vez que se descentralizó o liberalizó algunos aspectos de la educación. En 1974 empieza un proceso que elimina las escuelas normales y traspasa la formación de profesores de enseñanza básica a las universidades. En 1981 las sedes de las universidades de Chile y Técnica del Estado fueron convertidas en universidades regionales, o en otras universidades metropolitanas, y se autorizó la creación de universidades privadas al margen del Consejo de Rectores. Asimismo, los establecimientos escolares son trasferidos desde el Estado a las Municipalidades ("municipalización"). En las postrimerìas del régimen, se dicta la Ley Orgánica Constitucional de Enseñanza, que señala las pautas para la educación chilena desde los niveles pre-escolares, hasta la educación superior. Reconoce el derecho a la Educación y la libertad de enseñanza, además fija los requisitos mínimos y objetivos básicos que se deben cumplir.

Tras el retorno a la democracia, la educación vive una serie de cambios curriculares, amén del aumento de las demandas por acceso y calidad de la educación. En 1992 se establece el Estatuto Docente y en 1996 se inicia el programa de Jornada Educacional Completa, con importantes cambios en los contenidos curriculares.

La Revolución Pingüina, producida entre mayo y junio de 2006, coloca a la educación como un tema central de la política y la sociedad chilena. Eso lleva, entre otros, al reemplazo de la LOC de Enseñanza por la Ley General de Educación, que contempla modificaciones importantes en los procesos de admisión, currículum, y reconocimiento oficial de los establecimientos educacionales. Asimismo, se han producido eventos que generan gran impacto en la opinión pública, como el cierre forzoso de la Universidad del Mar y los casos de corrupción en la Comisión Nacional de Acreditación.

Básica: 6-13 años
Media: 14-18 años

La educación parvularia atiende a la población de niños y niñas entre los 6 meses y los 6 años. Pasó a ser obligatoria el 21 de mayo de 2013, cuando el presidente Sebastián Piñera anunció la aprobación del proyecto de ley que estipulaba la obligatoriedad del kínder, dejando así el prekínder no obligatorio.

La atención parvularia se realiza a través de las sala cunas y jardines infantiles de administración municipal, particular subvencionada, particular, de JUNJI o de la Fundación Nacional de Atención al Menor (Fundación INTEGRA). La educación parvularia está dividida en los siguientes niveles:

El 21 de mayo de 2013, se anunció una reforma constitucional para establecer el segundo nivel de transición (kínder) como obligatorio a partir de 2015, convirtiéndose en requisito para cursar el nivel básico, llegando así a 13 años de educación garantizada.

En 2015 se promulgó una ley que crea un nuevo esquema rector del nivel preescolar, el cual a agosto de 2016 está en fase de implementación.

La Enseñanza Básica desde la reforma de 1965, corresponde al ciclo inicial de estudios escolares. En 1920 la legislación chilena había establecido la obligatoriedad de cursar 4 años de escolaridad mínima. En 1929 este mínimo es aumentado a 6 años. Finalmente, en 1965 se establece la obligatoriedad del nivel básico, cuya duración actual es de 8 años divididos en 2 ciclos y 8 grados (de 6 a 13 años de edad ideal).


La Ley General de Educación de 2009 contempla el cambio a una educación básica de 6 años y la educación media también de seis años, con una renovada estructura curricular. El cambio se efectuará a contar de 2023.

La Enseñanza Media está dividida en Enseñanza Media Científico-Humanista (EMCH), Técnico-Profesional (EMTP), y Artística (desde 2006), con una duración de 4 años.

En el año 2003 el expresidente Ricardo Lagos junto a la ministra de educación otorgaron de carácter obligatoria esta etapa a través de la ley N°19.876.

La Enseñanza Media se organiza como sigue:

Los liceos o colegios que imparten especialidades técnico-profesionales otorgan Títulos de Técnico de Nivel Medio y se les denomina:

En la educación superior de Chile se distinguen cuatro tipos de establecimientos, creados por la reforma de la educación superior 1981. A ellos pueden optar todos los egresados de la educación media:

Quienes ingresan a la educación superior universitaria pueden optar entre universidades tradicionales, que fueron creadas antes de 1981 y que están agrupadas en el Consejo de Rectores de las Universidades Chilenas (CRUCH) o en las universidades "privadas". Las primeras reciben varios tipos de fondos del Estado, como el aporte fiscal directo (AFD) y el aporte fiscal indirecto (AFI). Según la legislación vigente, a todas las universidades chilenas se les considera como organizaciones sin fines de lucro, aunque solo desde el año 2011 se discute un mecanismo de fiscalización de dicha situación.

Las instituciones del CRUCH son 25 y la selección para el ingreso a estas universidades se efectúa a través de la Prueba de Selección Universitaria (PSU), la cual mide los conocimientos de los estudiantes en materias que son parte de los contenidos esperados para el nivel de educación secundaria. Esta prueba permite un sistema integrado, simultáneo y coordinado entre las diversas instituciones. Es controlado actualmente por la Universidad de Chile.

Durante 2011, el CRUCH invitó a universidades privadas a sumarse al sistema de ingreso, de las cuales se sumaron 8.

La Educación es gratuita en su duración formal para el 50% de la población más vulnerable y que haya elegido una universidad o instituto público y que no tenga ánimo de lucro. En cuanto a las universidades privadas o con ánimo de lucro, el estudiante puede optar a diferentes becas o créditos con condiciones muy diferentes entre sí para el financiamiento de sus estudios. Esto ha provocado críticas al sistema por parte de estudiantes y egresados. Los estudiantes de universidades del CRUCH pueden postular al Fondo Solidario de Crédito Universitario y los demás estudiantes de educación superior solo al Crédito Con Garantía Del Estado (o Crédito con Aval del Estado, CAE). En 2011 se creó una comisión que estudiaría mecanismos para mejorar el financiamiento de la educación superior, la que fue compuesta por 12 académicos.
El arancel promedio de una universidad chilena es de $3 565 645 pesos chilenos. Esto corresponde al 132% del sueldo mínimo anual, y a 93% en el caso del "arancel de referencia", que es el utilizado para calcular el monto de crédito otorgado para el CAE.

Desde 2004 se inició un proceso de acreditación de la calidad de la educación superior mediante la Comisión Nacional de Acreditación de Pregrado (CNAP).
Por la Ley N° 20.129 de 2006 se establece un sistema nacional de aseguramiento de la calidad de la educación superior (CFT, IP y universidades) a cargo de la Comisión Nacional de Acreditación (CNA-Chile). Sus principales objetivos son la acreditación institucional y acreditación de carreras y programas de la educación superior. El sistema es voluntario para las instituciones por lo que su impacto es acotado.

La cobertura del sistema educacional chileno es prácticamente universal, como ocurre en países desarrollados, teniendo índices de matrícula que representan esa realidad. La matrícula en Educación Básica (EGB) alcanza al 99,7 % de los niños entre 6 y 14 años. En el caso de la Educación Media la cobertura de la matrícula es de 87,7 %, de los adolescentes entre 15 y 18 años.

Antiguamente, la obligatoriedad escolar abarcaba solo el Ciclo Básico (EGB) de 8 años. Pero, a partir del 7 de mayo del 2003, una reforma constitucional, bajo el gobierno del presidente Ricardo Lagos, estableció la Educación Media gratuita y obligatoria para todos los chilenos hasta los 18 años de edad, entregando al Estado la responsabilidad de garantizar el acceso a ella.
También se distinguen modalidades especiales de la educación básica y media como la educación de adultos y la especial (educación diferencial).

Con la entrada en vigencia de la Ley General de Educación de 2009, se reemplazó el Consejo Superior de Educación por el Consejo Nacional de Educación. Adicionalmente, la Ley de Aseguramiento de la Calidad de la Educación de 2011 separa funciones del ministerio en tres organismos, para lo cual crea dos nuevas instituciones reguladoras del sistema escolar, la Superintendencia de Educación y la Agencia de Calidad de la educación, las que entraron en operación en el segundo semestre de 2012.

Se ha mencionado la creación de equivalentes para el nivel superior, pero a agosto de 2016 estos proyectos no se han concretado.

En el índice de Desarrollo Humano de las Naciones Unidas (Educación), Chile (0.847) está en el puesto número 1en Latinoamérica. Los países con mejores índices compuestos de Educación (alfabetización, gasto en educación, tasa bruta de matriculación, usuarios de internet por cada 100 personas, años de educación promedio, años esperados de instrucción) en América Latina son Argentina (0.764), y Uruguay (0.731).

En el Informe PISA del año 2013, los estudiantes chilenos lograron el puntaje promedio más alto de los países latinoamericanos, posicionándose en el puesto 52 de 66 países que participaron de la medición. aunque ha descendido desde el puesto 44.Chile se coloca en el puesto número 51 con 423 puntos en matemáticas, por debajo de la media fijada por PISA (de 494), mientras que en lectura obtiene 441 y en ciencia 445. En Lenguaje se obtuvo 441 puntos contra 449 del año 2009 y 494 del promedio OCDE; mientras que en Ciencias se obtuvo 445 bajando dos puntos de la medición anterior.
La Prueba Pisa mide a 66 países, a todos los pertenecientes a la organización OCDE más diferentes países de América Latina, Asia y Europa.

En el ámbito universitario y basándose en la clasificación internacional elaborada por la Universidad Jiao Tong de Shanghái en China, la Universidad de Chile y la Pontificia Universidad Católica de Chile están entre las mejores 500 del mundo. Por otro lado, en el año 2013 el ranking QS World University incluyó a nueve universidades chilenas dentro de las 800 mejores del mundo, entre las que se encontraban, además de las anteriores, la Universidad de Santiago de Chile, Universidad de Concepción, Pontificia Universidad Católica de Valparaíso, Universidad Adolfo Ibañez, Universidad Austral de Chile, Universidad de Talca y la Universidad Técnica Federico Santa María. A nivel investigativo, y de acuerdo al ranking SIR Global 2013, aparecen 17 universidades chilenas lideradas por la Universidad de Chile, seguida de la Pontificia Universidad Católica de Chile, Universidad de Concepción, Pontificia Universidad Católica de Valparaíso y Universidad Austral de Chile, entre otras.

El actual sistema educativo tiene su origen en las reformas de 1980 que significó el traspaso de la educación pública a la administración municipal, permitiendo la competencia de las escuelas municipales y particulares que recibían subvención escolar del estado, además se permitió que privados crearan universidades, institutos profesionales y centros de formación técnica. Esta institucionalidad profundizó la segmentación social, característica histórica de la educación chilena. 

Antes del gobierno militar había tres instancias escolares; los estudiantes de clase alta asistían a colegios privados pagados, los de clase media estudiaban preferentemente en liceos públicos y los de extracción popular cursaban solo algunos años de enseñanza básica en las escuelas primarias públicas o privadas subvencionadas. Las universidades, eran gratuitas, estaban reservadas para una pequeña parte de la población que lograba aprobar los exigentes requisitos de acceso y cuyas familias podían seguir manteniéndola, en promedio, solo el 7 % de los jóvenes en edad universitaria estudiaban en la educación superior, es decir 55 000 estudiantes.

La reforma de los años ochenta reforzó la estratificación social, por la diferenciación que se indujo entre escuelas privadas subvencionadas y municipales. A las primeras se les permitió operar como entidades que podían obtener utilidades, a lo que sumó la oferta tradicional de escuelas religiosas con nuevos establecimientos privados. Muchos de ellos buscaron atraer a las familias de clase media ofreciéndoles un ambiente social más homogéneo y símbolos de distinción, infraestructuras deportivas y similares. Los más exitosos pusieron en marcha exámenes de admisión para seleccionar a los estudiantes con mayor capacidad de aprendizaje. De este modo, el sector privado subvencionado empezó a congregar a alumnos de clase media y las escuelas municipales se fueron quedando a cargo de aquellos estudiantes de menor condición socioeconómica y con mayores dificultades para sus aprendizajes.

Llegada la democracia se desarrollaron una serie de iniciativas destinadas a implementar la equidad, igualdad y calidad educativa; ello con alta inversión en infraestructura, proyectos de mejoramiento educativo, jornada escolar completa, etcétera; ha pasado el tiempo y en estos últimos años se ha optado por una reforma educacional de envergadura, destinada a modificar la estructura del sistema vigente. Por eso, a fines del 2016 se inició el proceso legislativo del término de la municipalización y su reemplazo por servicios locales financiados centralmente. También, la ley de inclusión, promulgada en 2015, prohibió la selección en los establecimientos con financiamiento público, poniendo fin al copago en la educación particular subvencionada y prohibió el lucro de estos establecimientos, ello a través de una implementación gradual y que comienza plenamente este año.

A lo largo del período hubo también cambios fundamentales en la institucionalidad de la educación con la creación de organismos para la calidad y la regulación del sector, poniéndose en marcha un sistema de carrera docente, se reformó el currículo, se creó la Subsecretaría de Educación Parvularia y se multiplicó la dotación de establecimientos de ese nivel de enseñanza. La generalidad de estas iniciativas se relacionan con la enseñanza básica y media, claro es, que aún se cuestiona la calidad. Mientras tanto, la educación superior estuvo prácticamente desprovista de atención por parte de la política pública, salvo lo referido al sistema de crédito estudiantil. 

En estos últimos años, se ha verificado como nunca antes en la historia de Chile, una expansión de la matrícula en la enseñanza superior, pero bajo un marco desregulado, sin instancias de coordinación ni resguardos de la calidad de los estudios. La situación empezó a cambiar después de las masivas movilizaciones de protesta del 2011. En el segundo gobierno de Michelle Bachelet se ha impulsado una reforma del sector que incluye la instalación gradual de la gratuidad de la enseñanza, una Subsecretaría de Educación Superior y la creación de más universidades estatales, entre otras iniciativas que deberá afinar, modificar e impulsar el gobierno de Sebastián Piñera. 

Cabe preguntarse, si todas las iniciativas en educación logran o no el objetivo central, que es aportar al crecimiento económico con recursos humanos más calificados y productivos, para igualar oportunidades y reducir las brechas de aprendizaje entre los jóvenes, sirviendo además las demandas sociales. 

El aporte de la educación superior a la movilidad social es un tema relevante si se considera que la cobertura de la educación superior ha aumentado en los últimos años y que entre el 40% y el 50% de los jóvenes de los estratos medios bajos y bajos está ingresando a alguna institución de educación superior. Muchos de estos jóvenes son la primera generación de sus familias que se incorporan a la educación superior. 

Pero hay desafíos, un estudio del PNUD en Chile señala que los jóvenes de los estratos medios bajos y bajos, no consiguen los mismos resultados que los jóvenes de origen familiar más acomodado. La mayoría cursa estudios superiores técnico-profesionales o bien va a universidades de menor calidad académica, presentan mayores tasas de deserción y sus ingresos laborales cuando egresan son más bajos, pero más elevados que en el caso de no haber llegado a este nivel de enseñanza. Esto último contribuye a acortar brechas; sin embargo, el número de estos estudiantes ha crecido a tasas mucho mayores que la economía en los últimos diez o quince años, por tanto, un factor crítico es la capacidad actual y futura que tiene nuestra economía de proveer los empleos esperados por los más de un millón de estudiantes que hoy está en la educación superior. Sumamos a ello el efecto que tendrá la creciente automatización de los procesos productivos en empleos. 

En relación a lo anterior, es probable que la cobertura de la educación superior en Chile esté próxima a tocar techo en términos de los empleos que puede proveer la economía para sus egresados. La evidencia internacional señala que no hay país en el mundo que aspire a que toda la población tenga estudios superiores. Es un desafío pendiente para la enseñanza media dotar de competencias a los jóvenes que no ingresarán a la educación superior, así como la instalación de una oferta de educación continua que permita la renovación de conocimientos y competencias a lo largo de la vida.

Los jóvenes de estrato bajo y medio bajo que cursan estudios superiores en centros de formación técnica e institutos profesionales obtienen ingresos que son más bajos que los obtenidos por los jóvenes de hogares acomodados quienes tienden menos a estudiar en esos centros. Ahora bien, la brecha de ingresos entre los profesionales universitarios, según su origen socioeconómico es significativa. Esta diferencia de salario entre profesionales del estrato alto y del estrato bajo se explica por la acumulación de factores a lo largo de la niñez y la juventud, que determina un acceso muy diferenciado a la educación superior en términos de la calidad de la institución y del tipo de carrera. Además, se explica por la valoración diferenciada que hacen los empleadores, especialmente cuando se trata de puestos altos. Para el caso de altos ejecutivos se prefiere a egresados de colegios privados de élite por un tema supuestamente cultural y porque tienen más redes de contacto.

Quizás, un tema no estudiado en términos académicos sea el futuro impacto que tendrán en este cuadro los “nuevos chilenos”, vale decir, los hijos de inmigrantes y los jóvenes extranjeros que se radicarán definitivamente en el país, ellos vendrán a sumarse a la demanda por educación superior y empleo, para lo cual, habrá que adecuar las políticas públicas, tanto para el acceso y financiamiento para la educación como también para la incorporación laboral de todos los jóvenes, será el desafío para el siglo XXI. El mayor acceso a la educación superior ha generado expectativas de movilidad social en los hogares chilenos, y es parte de discurso político situar la educación como centro del desarrollo del país; por eso los resultados del proceso serán muy importantes, no solo para el desarrollo económico y social de Chile sino para la inclusión que tengan las personas respecto del modelo de desarrollo vigente.




</doc>
<doc id="15462" url="https://es.wikipedia.org/wiki?curid=15462" title="Lábaro cántabro">
Lábaro cántabro

Lábaro cántabro, también conocido como lábaru cántabru o simplemente lábaro o lábaru, es el nombre que recibe la interpretación moderna y contemporánea de un antiguo estandarte militar conocido por los romanos como cantabrum. En la actualidad, es representado habitualmente como un pendón de tela de color magenta sobre el cual está bordado un círculo rodeado de una decoración geométrica con cuatro medias lunas enfrentadas dos a dos que combina el estandarte militar con la simbología de las estelas cántabras.

En las últimas décadas su uso se ha popularizado dentro de la Comunidad Autónoma de Cantabria siendo en la actualidad muy visible especialmente en eventos deportivos y fiestas regionales. En el año 2016 el Parlamento de Cantabria lo reconoció como "símbolo identitario del pueblo cántabro", aunque sin sustituir a la bandera oficial de Cantabria.

El origen del nombre y del diseño se encuentra en la teoría defendida por diversos autores de una posible relación entre la génesis del labarum y el estandarte militar denominado "cantabrum", con la consiguiente identificación de ambos como una misma cosa; y a la supuesta relación que el Codex Theodosianus establece entre el "labarum" y los cantabrarii, colegio de soldados romanos encargados de portar el "cantabrum".

Su significado etimológico, "el que habla", hace referencia a su uso como estandarte utilizado para enviar órdenes o señales a la tropa durante la batalla.

Los relatos de Tertuliano y Minucio Félix no establecen relación alguna entre el "cantabrum" y el "labarum", dejando únicamente clara la veneración que las tropas romanas hacían de sus cruces, cubiertas por las telas de los "cantabra" y "vexilia":

Según estas teorías, el "cantabrum" es el estandarte que Constantino I el Grande tras su conversión al cristianismo transforma en el "labarum" al incluir el crismón, anagrama que representa a Cristo, consistente en las grafías mayúsculas en griego de las dos primeras letras de su nombre, una "X" sobre la que se superpone una "P".

Se justifica también la relación en la etimología celta del término lábaro procedente de "(p) lab-" hablar, de donde se ha derivado el adjetivo "labaros", orador, ampliamente representado en las lenguas celtas. Galés: "llafar", habla, idioma, voz, orador; antiguo córnico y bretón: "lavar" palabra; antiguo irlandés: "labar" charlatán, "labrad" habla, lenguaje; irlandés: "labhar" locuaz, en voz alta y "labhairt" palabra, habla < célt. "(p) labro-". En latín "Labarum".

Asimismo, el antropónimo "Labaro" ya existía entre los antiguos cántabros, habiendo sido recogido en lápidas funerarias.

El diseño actual, siguiendo igualmente la teoría de ser el "labarum" lo mismo que el "cantabrum", establece para el lábaro cántabro el color rojo púrpura del labarum.

El tetrasquel dorado representa las cuatro crecientes lunares que aparecen representadas en varias estelas cántabras discoideas gigantes. Siendo un símbolo que se ha constatado que usaban los cántabros frecuentemente, como se observa en caetras representadas en monedas acuñadas tras las guerras cántabras.

Además este tipo de estandartes y sus variantes estaban bastante extendidos entre los pueblos célticos, como lo demuestran los relieves del arco de triunfo de Orange. Su diseño entronca con antiguos símbolos celtas como el trisquel y su simbolismo, de tipo religioso, se relaciona con el culto al Sol y a la Luna.

El Pleno del Parlamento de Cantabria, en su sesión del 14 de marzo de 2016, aprobó una resolución como consecuencia de la tramitación de la proposición no de ley, N.º 9L/4300-0056, relativa a reconocimiento del lábaro como símbolo representativo e identitario del pueblo cántabro y los valores que representa.

"El Parlamento de Cantabria:

1. Reconoce el lábaro como símbolo representativo e identitario del pueblo cántabro y los valores que representa.

2. Insta a las instituciones y a la sociedad civil de Cantabria a que promuevan y participen de forma activa en su conocimiento y difusión como expresión iconográfica de la identidad del pueblo cántabro. Manteniéndose el carácter oficial de la bandera de la Comunidad de Cantabria y el resto de los símbolos institucionales de Cantabria."

La interpretación moderna del lábaro cántabro y su posible uso como símbolo oficial o cooficial de la Cantabria actual ha surgido como debate en el seno de esta Comunidad Autónoma, desatando un conjunto de enraizadas disputas dialécticas difundidas en muchos casos a través de los medios de comunicación.

En este diálogo mediático las posturas que más voz ostentan provienen de la Asociación para la Defensa de los Intereses de Cantabria (ADIC), por un lado, y de investigadores que intervinieron en la creación de los símbolos de la actual Comunidad Autónoma enmarcados dentro del Centro de Estudios Montañeses, por el otro.

Actualmente, y desde ciertos colectivos cántabros tanto sociales como políticos, se reivindica el uso oficial del estandarte aureomagenta como bandera de Cantabria, como representación del legítimo cantabrum, en sustitución de la actual, o al menos otorgándole la misma oficialidad. Algunos ayuntamientos, caso del de Comillas, aprobaron la utilización de dicha bandera y su colocación en el balcón de la Casa Consistorial durante la celebración de fiestas locales y regionales. Igualmente, municipios como Torrelavega, Camargo, El Astillero, Comillas, Ampuero o Arredondo lo exhiben en sus ayuntamientos para conmemorar el 28 de julio, Día de las Instituciones de Cantabria. Asimismo, el lábaro ondea en el Ayuntamiento de Colindres durante la semana en la que se celebra el festival de música cántabra Sauga Folk y se procede anualmente a su izado solemne en acontecimientos de la talla del Día'l Pueblu Cántabru de Novales o el Día Infantil de Cantabria, cuya celebración tiene lugar en la península de la Magdalena de Santander.

Existe una serie de expertos como Joaquín González Echegaray, José Luis Casado Soto o Ramón Teja que defienden la legitimidad histórica de la actual bandera de Cantabria frente al lábaro, al argumentar que el pendón blanquirrojo es el que llevaban los barcos cántabros desde, al menos, el siglo XVIII. Según estos académicos, aunque en los textos antiguos hay alguna referencia a un estandarte denominado "cantabrum", en ningún caso las fuentes clásicas dan una descripción exacta de la forma, colores o símbolos del mismo, siendo aventurado reconstruirlo sin más elementos de juicio.

Frente a tergiversaciones publicadas en determinados medios críticos con el lábaro, González Echegaray en su estudio "Acerca del llamado "Lábaro Cántabro"" se limita a afirmar sobre el lábaro moderno: «Se trata de una creación nueva, que solo puede decirse que se halla vagamente sugerida por algunos de los elementos históricos que de aquí hemos hablado», si bien su opinión respecto a adoptar el lábaro como bandera es negativa.

Para Casado Soto, más crítico, el lábaro no sería sino un invento del regionalismo cántabro, cuya antigüedad no va más allá del periodo preautonómico, y el actual debate en torno a los símbolos regionales sería un intento de destruir el consenso que se alcanzó en el Estatuto de Autonomía.




</doc>
<doc id="15465" url="https://es.wikipedia.org/wiki?curid=15465" title="Narciso López">
Narciso López

Narciso López de Urriola (Caracas, 2 de noviembre de 1797 – La Habana, 1 de septiembre de 1851) fue un militar español nacido en Venezuela creador de la Bandera de Cuba y del Escudo de Cuba. A partir de una idea de Narciso López, junto a otros exiliados cubanos en Nueva York como el poeta Miguel Teurbe Tolón, José Aniceto Iznaga Borrell, su sobrino José María Sánchez Iznaga, Cirilo Villaverde y Juan Manuel Macías, confeccionaron en 1849 la bandera de Cuba, que es hoy la bandera y pabellón oficial: 2 franjas blancas, tres azules, un triángulo rojo y una estrella solitaria. Sobre ella juraron luchar y ofrendar la vida por hacer de Cuba una república independiente del imperio español. López fue líder de hasta cinco intentos para liberar a Cuba hasta que fuera ejecutado por las autoridades coloniales en La Habana por alta traición mediante garrote vil el 1 de septiembre de 1851.

Algunos historiadores, como Hugh Thomas, argumentan que Narciso López se convirtió en un promotor de la anexión de Cuba a los Estados del sur esclavista de los Estados Unidos. Como corriente política, ese anexionismo de Narciso López fue animado por los intereses expansionistas de los EE.UU. Al fracasar en el intento los estados del sur optaron por el secesionismo del norte industrializado lo cual desembocó en la guerra civil americana.

Narciso López nació en Caracas, Venezuela, en 1797. Sus padres fueron Pedro Manuel López y Ana Paula de Oriola, ambos de origen vasco.

Durante el proceso de emancipación de la América Hispana sirvió en el ejército español, luchando entre otras batallas en las de Las Queseras del Medio en 1819 y Carabobo en 1821 donde dirigió el "Regimiento Guías del General" de la "Quinta División" del ejército del Mariscal Miguel de la Torre. Su última actuación en Venezuela, fue en la Batalla naval del Lago de Maracaibo en 1823. Al ser destrozada la flota española, el coronel Narciso López huyó a Cuba con los restos del ejército realista, incluyendo a Calixto García de Luna e Izquierdo (abuelo de Calixto García) y Marcos Maceo (padre de Antonio Maceo y José Maceo) que lucharon por la independencia de la isla caribeña.

Cuatro años más tarde marchó a España, y allí frecuentó los círculos criollos. Luchó en la guerra civil que se desata en España (primera Guerra Carlista), donde sus méritos militares le elevaron al grado de brigadier en 1836. En 1839 recibió el cargo de gobernador de Valencia y un año más tarde fue ascendido a general. También ocupó el cargo de Gobernador Militar de Madrid y representante en las Cortes por Sevilla. Tomó parte en la revolución española de 1840.

Regresó a Cuba en 1840 con Jerónimo Valdés, que había sido nombrado Capitán General. Este le confió la Gobernación de las Cuatro Villas (Trinidad, Sancti Spíritus, Remedios y Santa Clara), y la Presidencia de la Comisión Militar Ejecutiva y Permanente contrayendo asimismo matrimonio con María de los Dolores de Frías y Jacob, hermana del gran terrateniente e intelectual cubano, Francisco de Frías y Jacott, IV conde de Pozos Dulces.

A la caída de Valdés, el sucesor de este, el Capitán General de Cuba Leopoldo O'Donnell, le destituyó en 1843 de sus cargos, y desde entonces se alineó y comprometió con las causas de los terratenientes cubanos, en línea con el mantenimiento de la esclavitud del Sur de los Estados Unidos.

En contacto con los grupos autonomistas locales dueños de grandes fortunas en Cuba, se embarcó en acciones contra la metrópoli en las serranías de Manicaragua, como la llamada conspiración de la Mina de la Rosa Cubana de 1848, que tenía ramificaciones en toda la isla y tras cuyo fracaso se vio obligado a huir a Estados Unidos, donde recibió la protección del gobernador del estado de Missisipi.

En aquel mismo año, el contacto entre grupos independentistas cubanos (el de Trinidad, dirigido por el propio López, y el aristocrático de La Habana y Camagüey, liderado por el marqués de Santa Lucía), fructificó en la organización de un Consejo Cubano en Nueva York. José Aniceto Iznaga Borrell, Gaspar Betancourt y Alonso Betancourt pasaron a Washington con el propósito de entrevistarse con el presidente de los EE.UU. James Knox Polk partidario decidido de la doctrina expansionista del Destino Manifiesto. Para llegar a esto, solicitaron la intervención de Jefferson Davis, senador por el Estado de Missisipi, y William J. Brown, subsecretario de Comunicaciones. Se presentaron todos en la Casa Blanca el 23 de junio de 1848. Desde aquella plataforma trataron de sensibilizar a los medios políticos estadounidenses, proponiendo al presidente Polk la compra de Cuba a la Corona de España, negociaciones que, al efectuarse directamente con el gobierno federal, podían significar el fin de la esclavitud lo que no convenía a los intereses que López representaba.

Narciso López, por su lado, se dedicó en Nueva York a preparar una expedición para la liberación de Cuba, a la apertura de suscripciones y financiación a través de la familia Iznaga, a actividades de propaganda e incluso, junto a Teurbe Tolón en Nueva York, al diseño de una bandera, a imagen y semejanza de la de Texas para su incorporación a la Unión como nueva estrella, y que luego se convertiría en la actual bandera cubana.

En julio de 1849 López decidió que la expedición partiría desde , Missisipi. En ella participaban exilados cubanos y algunos veteranos norteamericanos de la guerra contra México. Otros iban por la oferta de 1000 dólares y 64 hectáreas de tierras cultivables en Cuba que se les habría hecho efectivas en caso de tener éxito. López ofreció el mando al político sudista Jefferson Davis, quien recomendó al coronel Robert E. Lee por 200.000 dólares. Lee rehusó ante la oposición del gobierno de Washington de romper el "Tratado de Neutralidad con España" de 1818 y consecuentemente, López decidió asumir personalmente la jefatura de la expedición, de varios cientos de hombres. Sin embargo, la expedición fue frustrada en septiembre de 1849 al enviar el presidente de los Estados Unidos Zachary Taylor una fuerza naval para capturar los barcos de López, como consecuencia de un cambio de política con respecto a la anexión de Cuba.

En un segundo intento, López organizó otra expedición, en esta ocasión desde Nueva Orleans. Contó con la ayuda del gobernador de Mississippi , veterano de la guerra de México al que ofreció el mando de la aventura, que declinó. El 19 de mayo de 1850, con 600 voluntarios de Mississippi y Luisiana, desembarcó en Cárdenas, enarbolando por primera vez la que sería tomada en la Asamblea de Guáimaro como la enseña nacional de Cuba, por lo que a Cárdenas se le conoce también con el nombre de Ciudad Bandera. Tras quemar la casa del gobernador López controló la localidad durante varias horas pero la población de la misma no apoyó la revuelta, tras comprobar que el objetivo era mantener la esclavitud. La inferioridad de sus fuerzas y la aproximación de tropas españolas le obligaron a reembarcarse, siendo su barco perseguido por un navío de guerra español hasta Cayo Hueso; a pesar del fracaso, fue recibido como héroe en el Sur de Estados Unidos.

El 4 de julio de 1851 un grupo liderado por Joaquín de Agüero se levantó contra los españoles en Las Tunas y declaró la independencia de Cuba. La revuelta sería aniquilada rápidamente y Agüero fue capturado en Camagüey terminando sus días frente a un pelotón de fusilamiento, pero la noticia no hizo sino abrir las apetencias de los inversionistas especuladores en el futuro cubano, lo cual motivó a López a organizarse una vez más para intentar una nueva y última invasión a la isla.

El 3 de agosto de 1851 salió otra vez desde Nueva Orleans una expedición de 420 hombres, entre los que figuraba un "regimiento" de voluntarios sudistas al mando de William J. Crittenden sobrino del presidente en ejercicio Millard Fillmore. El 12 de agosto de 1851 los mercenarios a bordo de "El Pampero", desacatando las órdenes del gobierno federal, desembarcaron en la isla con la pretensión de establecer una república independiente y su posterior anexión a los Estados Unidos.

El desembarco se produjo en la playita del "Morrillo" de Pinar del Río, actual municipio de Bahía Honda, Provincia de Artemisa. El destacamento invasor fue objeto de persecución por el ejército español enviado desde La Habana. Sostuvo un primer encuentro armado victorioso en el poblado de Las Pozas. No obstante, ante la superioridad numérica de los españoles se vio obligado a replegarse hacia la Sierra del Rosario, en el curso alto del río Bayate. Una parte del destacamento (cincuenta hombres), que había permanecido en el lugar del desembarco bajo el mando del coronel Crittenden, segundo comandante de la expedición, se reembarcó en "El Pampero" y fue apresado por los vapores españoles "Cárdenas" y "El Habanero". Los expedicionarios fueron conducidos a La Habana y fusilados el 13 de agosto. Como respuesta a estas muertes el consulado español en Nueva Orleans fue destruido, mientras que los comercios de varios españoles en la ciudad fueron saqueados por las turbas. Posteriormente el gobierno del presidente Millard Fillmore negoció la liberación del resto de prisioneros estadounidenses en manos españolas.

Días después, los mercenarios de López sostuvieron un combate desastroso contra el general español Manuel de Enna y el brigadier Rosales, aunque el propio general Enna fue herido y falleció posteriormente. Con las fuerzas diezmadas, sin apoyo interno, acusado de piratería y bregando por la Sierra, López sostuvo dos batallas más, la última en la Puerta de La Muralla, cerca de San Cristóbal y fue finalmente capturado en Pinos de Rangel; en total, murieron unos 200 expedicionarios en los combates y el resto fue apresado: 160 de ellos fueron enviados a España.Lopéz fue conducido a La Habana el 31 de agosto y ejecutado por alta traición, mediante garrote vil, en la mañana del 1 de septiembre de ese año en la explanada del castillo de la Punta: se convirtió posiblemente en la figura más controvertida de la historia de Cuba.

La orden de su ejecución fue emitida por el entonces Capitán General de Cuba, José Gutiérrez de la Concha, quien había combatido bajo el mando de López durante el estallido de las guerras carlistas. Las últimas palabras de López fueron ""Mi muerte no cambiará los destinos de Cuba"."

La derrota y muerte de muchos expedicionarios, procedentes de Nueva Orleans, provocó la destrucción del consulado español en aquella ciudad y el cambio de nombre de numerosos habitantes para ocultar su procedencia española. Varios miembros de la familia Iznaga, ante la posibilidad de ser acusados, se trasladaron al estado de Mississippi, donde adquirieron extensiones de tierra para el cultivo de algodón mediante esclavos. Inspirado por las hazañas de López, el filibustero estadounidense William Walker organizó nuevas expediciones para apoderarse de Nicaragua, pero acabó fusilado en 1860 en Trujillo (Honduras). Los estados del Sur cambiaron su política anexionista por la secesionista que condujo a la Guerra civil estadounidense entre 1861 y 1865. Las invasiones de este aventurero venezolano colaboraron a la formación del concepto de América Latina y al antiimperialismo estadounidense.




</doc>
<doc id="15466" url="https://es.wikipedia.org/wiki?curid=15466" title="Escudo de Cuba">
Escudo de Cuba

El escudo de Cuba, conocido como el de "La Palma Real", fue creado en 1849 por Miguel Teurbe Tolón —quien también creó la bandera cubana— a petición del general venezolano Narciso López, para sellar los despachos y bonos que como jefe del gobierno provisional de Cuba emitió entre 1850 y 1851.

La versión actual no es exactamente igual a la original, ya que se suprimieron algunos elementos que contenía aquél y que podían haberse asociado con ideas anexionistas. Las especificaciones de diseño del escudo fueron establecidas mediante decreto por el primer presidente de Cuba, Tomás Estrada Palma, el 21 de abril de 1906 y han permanecido sin modificaciones desde entonces.

Según la ley 42 de la Asamblea Nacional, es el "Símbolo de la Nación" y está formado por dos arcos de círculos iguales, que se cortan volviendo la concavidad el uno al otro, como una adarga ojival. Se compone de tres espacios o cuarteles.

En el superior representa un mar con dos cabos o puntas terrestres a sus lados (Florida y Yucatán), entre los cuales cierra el estrecho una llave de vástago macizo (Cuba), con la palance hacia abajo y a cuyo fondo un sol naciente esparce sus rayos por todo el cielo del paisaje. El espacio inferior izquierdo tiene cinco bandas de igual ancho alternadas de color azul turquí y blanco e inclinadas todas de izquierda a derecha. El cuartel inferior derecho figura un paisaje representando un valle en el centro del cual se alza una palma real, con el botón de su hoja central en lo más alto.

El escudo está sostenido por un haz de varas, unido por una banda estrecha de color rojo cruzada en equis. La corona que sobresale por la parte superior del escudo está cubierta por un gorro frigio de color rojo, vuelto hacia la derecha. El gorro tiene en su parte central una estrella blanca de cinco puntas, una de ellas orientada hacia arriba. Sin exceder la altura del escudo, una rama de laurel y otra de encina los orlan a su izquierda y derecha respectivamente.



</doc>
<doc id="15468" url="https://es.wikipedia.org/wiki?curid=15468" title="Símbolos nacionales no oficiales de Cuba">
Símbolos nacionales no oficiales de Cuba

Junto a los símbolos de la Nación, Cuba posee otros atributos que la distinguen y diferencian del resto de las naciones del mundo y aunque no con el carácter oficial que les concede la ley a los primeros (como lo son la bandera, el himno nacional y el escudo), son también considerados genuinos representantes de la cubanía por la tradición, origen o su uso o presencia particular en Cuba.

La mariposa, cuyo nombre científico es "Hedychium coronarium" , de la familia de las zingiberáceas (alpináceas). No es originaria de Cuba sino de Asia, pero se ha adaptado maravillosamente al suelo cubano. Fue en 2001 que los botánicos del Jardín de la Paz en Argentina, pidieron a sus homólogos cubanos que determinaran cuál podría ser la flor nacional. El 13 de octubre de ese mismo año, fue elegida la mariposa, debido a que su blancura representa la pureza de los ideales independentistas, es símbolo de la paz, es un elemento presente en las franjas de la enseña nacional, así como la forma de su flores unidas al tallo central también son simbólicas de la unión de los cubanos. Es también paradigma de la gracia y la esbeltez de la mujer cubana y según la tradición oral, se cuenta que durante las guerras de independencia, en estas flores prendidas en velos y mantones, se escondían mensajes para el ejército libertador.

Cuando hablamos de el Árbol nacional, nos referimos al gran árbol que apareció en un 6 de octubre del 1953, la palma real, cuyo nombre científico es "Roystonea regia" . Es reconocida por los cubanos como la reina de los campos, por la majestuosidad de su estructura, por su peculiar talla, la utilidad que reporta y por ser, además, el más numeroso de los árboles de la Isla. Pertenece a la familia de las "palmáceas", es un árbol elevado, erecto que alcanza generalmente entre cuarenta y cincuenta pies de altura, coronado por un bellísimo penacho de hojas "pinnatisectas", capaz de suscitar tal admiración que muchos poetas y músicos han cantado a su elegancia. Florecen y crecen sus frutos durante casi todo el año y desde tiempos inmemoriales fue utilizada, primero por los aborígenes y más tarde por los campesinos cubanos, para satisfacer algunas de sus necesidades más vitales, desde la comida para los animales de crianza hasta la madera para la construcción de las casas y las hojas para cubrir sus techos. Su gallarda presencia en el Escudo Nacional, representa la libertad e independencia de la joven república cubana, símbolo de la lozanía y feracidad de su privilegiado suelo, al mismo tiempo que el más útil de sus árboles. No es exclusiva de Cuba.

El tocororo, cuyo nombre científico es "Priotelus temnurus", del orden "Trogoniformes" y perteneciente a la familia "Trogodinae". No es exclusivo de Cuba como se creía, sino que también vive en Venezuela. Llamado por los originarios cubanos "guatini" -nombre que continúa dándosele en algunas de las provincias orientales- habita en todo el país en lugares boscosos, preferentemente de montaña. Es el ave nacional por dos motivos: su espléndido plumaje de vivos colores y por su resistencia al cautiverio, ya que muere cuando se le mantiene cautivo. Considerado como el ave más bella de Cuba, parte de su plumaje en verde recuerda los campos, su pecho de plumas blancas, su vientre de plumaje rojo y las plumas azules de su cabeza completan el claro simbolismo de la enseña nacional.

También conocida como «bandera de Yara» o «La bandera del 10 de octubre», fue creada por Carlos Manuel de Céspedes, el Padre de la Patria, y confeccionada por Candelaria Acosta "Cambula". Según el hijo de Céspedes, su padre se habría inspirado en la bandera de Chile para su creación: «"imaginó una bandera nueva, que luciendo los mismos colores y forma de la de Carreras [sic] y O'Higgins se diferenciase de ésta en la disposición de aquellos"».

Esta bandera ha presidido desde 1868, y continua presidiendo, junto a la enseña nacional, todas las sesiones del parlamento cubano.

Han sido varios los poetas que han recibido, en distintas épocas, el título de Poeta Nacional de Cuba, entre los que se incluyen José María Heredia (1803-1839), de quien el propio José Martí hiciera grandes elogios por su poesía, de profundo contenido patriótico, entre la que destaca especialmente su "Oda al Niágara" con la descripción de las "palmas que en mi patria se mecen del viento a la sonrisa", Julián del Casal, el poeta cubano que murió riéndose (1863-1893), Agustín Acosta (1886-1979) y por último Nicolás Guillén (1902-1989), conocido especialmente por sus "Motivos del Son" y su poesía negra como contribución al espectro de los componentes de la nación y la nacionalidad cubana, especialmente por la musicalidad de sus versos.

El deporte nacional de Cuba es sin dudas la "pelota" o béisbol. Surgió en los Estados Unidos y se comenzó a practicar en Cuba a finales del siglo XIX.

El danzón fue creado en Matanzas en 1878.


</doc>
<doc id="15471" url="https://es.wikipedia.org/wiki?curid=15471" title="Electromiografía">
Electromiografía

Electromiografía del gr. γραφή graphḗ 'escritura' y de γράμμα grámma 'escrito', es la técnica de registro gráfico de la actividad eléctrica producida por los músculos esqueléticos. 
Esta actividad eléctrica es conocida como el electromiograma o “EMG”.
El EMG puede ser monitoreado a través de electrodos insertados dentro de los músculos (electrodos intramusculares) o a través de electrodos en la superficie de la piel sobre el músculo (electrodos superficiales). 
El EMG es usado por científicos para estudiar el sistema neuromuscular, por médicos para el diagnóstico de enfermedades neuromusculares, y por fisioterapeutas para monitorear la activación de músculos de un paciente.

La fuente eléctrica es el potencial de la membrana muscular de alrededor de -70 mV, midiendo los rangos potenciales de EMG de menores a mayores rangos entre 50 μV hasta 20 o 30 mV, dependiendo del músculo en observación.

El rango típico de repetición de una unidad motora muscular es de alrededor 7–20 Hz dependiendo del tamaño del músculo. El daño a las unidades esperadas puede ser entre rangos de 450 y 780 mV.

El primer material en el que aparece el EMG fue en el de trabajo de Francesco Redi en 1666. Redi descubrió un músculo altamente especializado en la anguila eléctrica Electrophorus electricus que generaba electricidad. En 1773, Walsh pudo demostrar que el tejido muscular de la Raya Eléctrica tenía la capacidad de generar una chispa de electricidad. En 1792, en una publicación titulada "De Viribus Electricitatis in Motu Musculari Commentarius" escrita por Luigi Galvani, aparecía que el autor demostraba que la electricidad podía iniciar contracciones musculares. Seis décadas después, en 1849, Dubois-Raymond descubrió que era también posible llevar un registro de la actividad eléctrica durante la actividad de la contracción muscular. El primer registro real fue hecho por Marey en 1890, quien además introdujo el término de electromiografía. En 1922, Gasser y Erlanger usaron un osciloscopio para mostrar las señales eléctricas de los músculos. Entre 1930 y 1950 los científicos comenzaron a utilizar electrodos mejorados y más sofisticados para los estudios musculares. El uso clínico del EMG de superficie (sEMG) para el tratamiento de desórdenes más específicos comenzó en la década de los 60’. Hardyck y sus colaboradores fueron los primeros (1966) en usar el sEMG. En los comienzos de los 80’s, Cram y Steger introdujeron un método clínico para escanear una variedad de músculos utilizando un dispositivo para el sensado del EMG.

No fue hasta mediados de los 80’s, cuando las técnicas de integración en electrodos fueron lo suficientemente avanzadas para permitir la producción por lotes de la instrumentación y los amplificadores pequeños y livianos requeridos. En el presente, hay un gran número de amplificadores disponibles comercialmente. Investigaciones recientes han resultado en una mejor comprensión de las propiedades del sEMG. La electromiografía de superficie es crecientemente usada para el registro de músculos superficiales en protocoles clínicos o kinesiológicos, mientras que los electrodos intramusculares son utilizados para investigar músculos profundos o actividad muscular localizada.

Hay muchas aplicaciones para el uso de la EMG. El EMG es utilizado clínicamente para el diagnóstico de problemas neurológicos y neuromusculares. Es utilizado diagnósticamente por los laboratorios de marcha y por clínicos entrenados en el uso del biofeedback o el aseguramiento ergonómico. El EMG es también utilizado en muchos tipos de laboratorios de investigación, incluyendo a los que están involucrados en el campo de la biomecánica, el control motor, la fisiología neuromuscular, los desórdenes de movimiento, el control postural y la terapia física.

Hay dos métodos para utilizar el EMG, uno es la superficial, y el otro método es el intramuscular. Para llevar a cabo un EMG intramuscular, se usa una aguja electrodo, se inserta a través de la Piel hasta que entre al tejido muscular. Un profesional entrenado (como un neurofisiólogo, un neurólogo, o un fisiatra), va observando la actividad eléctrica mientras inserta el electrodo. Mientras se va insertando el electrodo provee una información valiosa en cuanto a la actividad muscular como al nervio que inerva ese músculo. Los músculos cuando están en reposo muestran señales normales eléctricas, cuando el electrodo es insertado, por ende la actividad eléctrica se estudia cuando el músculo está en reposo. La actividad anormal espontánea indica un daño en el nervio o en el músculo. Después se le pide al paciente que contraiga el músculo suavemente para poder realizar un análisis con más profundidad. El tamaño, la frecuencia y la forma resultante de la unidad potencial motora son analizados. Posteriormente el electrodo es retirado unos pocos milímetros e insertado nuevamente para analizar la actividad, la cual debe tener unidades por lo menos entre 10–20. Cada trazo del electrodo da una imagen muy local de la actividad del músculo completo. Debido a que el músculo esquelético difiere en su estructura interna, el electrodo debe ser puesto en varias localizaciones para obtener resultados confiables de estudio.

El método Intramuscular EMG puede ser considerado demasiado invasivo o innecesario en algunos casos. En su lugar, el método superficial emplea una superficie en la cual el electrodo se puede utilizar para controlar la imagen general de la activación muscular, a diferencia de la actividad de sólo unas pocas fibras como se observa utilizando un EMG intramuscular. Esta técnica se utiliza en una serie de ajustes, por ejemplo, en la fisioterapia, la activación muscular se controlará mediante EMG superficial y los pacientes tienen un estímulo auditivo o visual para ayudarles a saber cuándo se está activando el músculo (retroalimentación).

Una unidad motora se define como un motor neurona y todas las fibras musculares que inerva. Cuando una unidad motora se activa, el impulso llamado potencial de acción se desplaza de la neurona motora hacia el músculo. El área donde el nervio hace contacto con el músculo se llama unión neuromuscular. Después de que el potencial de acción se transmite a través de la unión neuromuscular, se obtiene un potencial en todas las fibras musculares inervadas por la unidad motora particular. La suma de toda esta actividad eléctrica se conoce como un potencial motor de la acción de la unidad (MUAP). La actividad electrofisiológica de las múltiples unidades motoras es la señal que normalmente se evalúa durante un EMG. La composición de la unidad motora, el número de fibras musculares por unidad motora, el tipo metabólico de las fibras musculares y muchos otros factores afectan la forma de los potenciales de unidad motora en el miograma.

Algunos pacientes pueden encontrar el procedimiento doloroso, otros experimentan un pequeño nivel de disconfort cuando la aguja es insertada. Los músculos a los cuales se les realiza el procedimiento pueden quedar adoloridos por uno o dos días después del procedimiento.

Un equipo básico de electromiografía consta de los siguientes elementos:

El tejido muscular en reposo es eléctricamente inactivo. Después de la actividad eléctrica causada por la inserción de las agujas, el electromiógrafo no debe detectar ninguna actividad anormal espontánea (es decir, un músculo en reposo debe estar eléctricamente silencioso, con la excepción del área de la unión neuromuscular, que en circunstancias normales, se activa muy espontáneamente). Cuando el músculo se contrae voluntariamente, los potenciales de acción comienzan a aparecer. Como la fuerza de la contracción muscular aumenta, más y más fibras musculares producen potenciales de acción. Cuando el músculo se contrae completamente, deben aparecer un grupo desordenado de potenciales de acción de tasas y amplitudes variables.

El EMG es utilizado para diagnosticar enfermedades que generalmente están clasificadas en una de las siguientes categorías: neuropatías, enfermedades del empalme neuromuscular y miopatías.

Las Neuropatías se definen desde las siguientes del EMG:

Miopatías definiendo características del EMG:

Los resultados anormales son causados por las siguientes condiciones médicas:

Las señales del EMG se componen principalmente de los potenciales de acción de las unidades motoras superpuestas. La medición de la señales del EMG pueden ser descompuestas en los potenciales de acción de las unidades motoras (PAUMs) constituyentes. Los PAUMs de diferentes unidades motoras pueden tener distintas formas, mientras que los PAUMs registrados por el mismo electrodo de la unidad motora, son típicamente similares. La forma y el tamaño del PAUM dependen notablemente del lugar donde se localice el electrodo con respecto o a las fibras.

Las señales del EMG son usadas en muchas aplicaciones clínicas y biomédica. El EMG es usado como una herramienta para diagnosticar enfermedades neuromusculares, y desórdenes del control motor. Las señales del EMG también son utilizadas para el desarrollo de prótesis de manos, brazos y extremidad inferior.

El EMG también es usado para detectar la actividad muscular en los lugares donde no se produce movimiento. Se puede reconocer el habla de una persona con incapacidad para producir voz mediante la observación de la actividad del EMG, en los músculos asociados con el habla.




</doc>
<doc id="15473" url="https://es.wikipedia.org/wiki?curid=15473" title="Mostaza">
Mostaza

La mostaza hace referencia generalmente al condimento envasado con apariencia externa pastosa y de sabor picante que se elabora de las semillas de varias plantas del género "Sinapis", familia de las crucíferas, que también incluye las coles y los nabos. Asimismo, hace referencia también a la pequeña semilla de mostaza, usada como especia y que se emplea frecuentemente en algunas gastronomías, como por ejemplo: la alemana, la india o la francesa, entre otras.

La mostaza se denominaba en el castellano clásico como jenabe, que a su vez proviene del latín "sinapi", y éste del griego con el mismo nombre, de aquí proviene la palabra sinapismos que son las cataplasmas de mostaza aplicadas al pecho como remedio natural de catarros y otras afecciones pulmonares. La denominación, tal y como se conoce hoy en día, aparece por primera vez en Francia posiblemente hacia el año 1220 de una derivación de la palabra latina ""mustum"" y la primera constancia registrada del nombre asociado al condimento es: ‘moutarde’ y se sospecha que provenga del latín vulgar ‘"mustum ardens"’ ("mosto ardiente") por tener los romanos la costumbre de añadir, o diluir, granos de mostaza en el zumo de la uva (mosto). Casi en la misma época aparece registrado en castellano con el nombre de mostaza y en Italia con el de "mostarda".
Las semillas de mostaza están relacionadas desde varios enfoques religiosos como las semillas de fe y de abundancia. Esta semilla se nombra como algo muy pequeño que se multiplica y simboliza la abundancia y el fenómeno de la multiplicidad.

Se cree que fueron los romanos quienes desarrollaron el preparado de mostaza que conocemos hoy. Mezclaban zumo de uva sin fermentar, conocido como "mosto" con semillas de mostaza, llamadas "sinapis" para formar el "mustum ardens" o "mosto ardiente". La empleaban como condimento gastronómico, Plinio la menciona como un aditamento en los vinos especiados y como también confitaban en vinagre sus hojas, era empleado en la elaboración del moretum (queso especiado). También se empleaba como planta medicinal aplicada como remedio contra los dolores de cabeza o simplemente como digestivo.
Los griegos la empleaban como condimento y Pitágoras recomendaba su consumo ya que tenía la convicción que aumentaba la memoria y le daba alegría al ánimo, se sabe también que el botánico Teofrasto la cultivaba en los jardines.

Se puede considerar este periodo como el primer auge de esta especia. De hecho, se empieza a emplear como condimento de carnes (sobre todo vacunas) y tal vez para ocultar el sabor de la carne en mal estado. Es en el siglo XIII cuando aparece en casi todos los platos de la gastronomía europea, y su cultivo se intensificó, así se puede comprobar en las ciudades de Cremona en Italia y Dijon en Francia; en esta última la producción continúa hoy en día, y se considera una de las primeras del mundo (una gran parte de la producción mundial proviene de esta región de la Borgoña y, la otra, de Canadá).

Ya en la época moderna nos encontramos numerosas recetas de elaboración diversas por país, en España en el siglo XVII, por ejemplo, el cocinero de los reyes de la Casa de Austria, Francisco Martínez Motiño, menciona una "receta española" de elaboración de la mostaza. Posteriormente en el siglo XX se hace famosa por una simple semejanza de olor con la iperita que tiene el gas mostaza (no tiene ninguna otra cosa en común). 

Hoy en día se emplea como salsa acompañante de salchichas (especialmente los perros calientes) y es un integrante importante de las hamburguesas. También se emplea en algunos sándwiches (principalmente la del tipo americano que viene coloreada con cúrcuma, llamada mostaza preparada).

La variedad francesa o tipo Dijon suele emplearse en platos más de estilo "gourmet."

La mostaza es una salsa baja en calorías y es 0% colesterol al no tener como ingrediente ningún tipo de grasa animal. Su semilla tiene un alto contenido proteico y de minerales. Además posee propiedades antisépticas y digestivas.

La mostaza blanca dulce ("Brassica alba") crece de forma silvestre en el norte de África, el Oriente Medio y la Europa mediterránea, extendiéndose ampliamente por su prolongado cultivo. La mostaza morena ("Brassica juncea"), originaria de las laderas del Himalaya, se cultiva comercialmente en el Reino Unido, Canadá y Estados Unidos. La mostaza negra ("Brassica nigra"), se cultiva en Argentina, Chile, Estados Unidos y algunos países europeos. Canadá cultiva el 90 % de toda la semilla de mostaza para el comercio internacional.

Se sabe que existen unas cuarenta especies distintas de mostaza, de las cuales sólo tienen interés culinario y médico la denominada mostaza blanca ("Sinapis alba"), la mostaza negra ("Sinapis nigra") y la mostaza salvaje ("Sinapis arvensis"). Se emplea fundamentalmente en gastronomía como condimento de algunos platos y en la elaboración de algunas salsas, como la Cumberland (elaborada con oporto) en la cocina portuguesa y la salsa Robert, inventada por Robert Vinot, en la gastronomía francesa. En algunos países de Europa Oriental se utiliza una mostaza agridulce, hecha a base de dos partes de mostaza por una de mayonesa, sazonada con especias y endulzada con azúcar.

La mostaza es un ingrediente que está presente en numerosos alimentos. Debido a su capacidad de inducir procesos de alergia, de acuerdo con las directivas de la Comunidad Económica Europea, es obligatoria su identificación en los alimentos que la contengan.


</doc>
<doc id="15476" url="https://es.wikipedia.org/wiki?curid=15476" title="LEP/DELPHI">
LEP/DELPHI

DELPHI ("DEtector with Lepton, Photon and Hadron Identification") es el nombre de uno de los cuatro detectores que operaron en el acelerador de partículas LEP.

Fue diseñado como un detector de propósito general con un especial énfasis en la identificación de partículas, incluso en el caso de sucesos complejos. Entre sus características más relevantes se encuentra el uso de detectores de efecto Cherenkov ("Ring Imaging CHerenkov counters", RICH) para la identificación de trazas dentro de jets, la información tridimensional que proporciona tanto para partículas cargadas como neutras, la elevada granularidad de la mayoría de sus componentes y su precisión en la reconstrucción de vértices.

DELPHI se encontraba instalado en una caverna subterránea a 100 m por debajo del nivel del suelo. En la figura inferior puede observarse la estructura general del detector. Constaba de una sección cilíndrica, el "barril", y dos tapas que pueden abrirse axialmente, más un detector de luminosidad situado en el túnel de LEP. DELPHI tenía en conjunto un diámetro de más de 10 m y
un peso total cercano a las 3500 Tm.

Un solenoide superconductor de 7.4 m de longitud y 5.2 m de diámetro interior proporcionaba un campo magnético altamente uniforme de 1.2 T en la dirección del haz, el cual permitía distinguir la carga de las partículas por el sentido de la curvatura de su trayectoria en el seno del detector.

El sistema de detección de trazas se estructuraba alrededor del tubo del haz. En la zona del barril estaba formado por distintos subdetectores optimizados para definir la posición de la partícula a su paso por ellos. Consistía en el detector de microvértices, el detector interno, la cámara de proyección temporal y el detector externo. Las cámaras "forward" A y B contribuyen en la zona de las tapas. Los detectores RICH se hallaban intercalados entre estos detectores y proporcionan una ayuda en la identificación de los tipos de partículas que los atraviesaban.

Los calorímetros electromagnéticos se situaban alrededor de los detectores anteriores tanto en la zona del barril como en la zona "forward". Rodeaban a éste, el retorno del imán y el calorímetro hadrónico en la zona del barril. Finalmente, en las zonas más externas de DELPHI se encontraban las cámaras de muones la cual contribuía de forma decisiva a la identificación de estos leptones.


</doc>
<doc id="15479" url="https://es.wikipedia.org/wiki?curid=15479" title="Lotería">
Lotería

La lotería o loto es un juego que puede ser público mediante billetes y sorteos o un juego de mesa que consiste en cartones y barajas. El coleccionismo de billetes de lotería se denomina loterofilia.

Se supone que el nombre de "lotería" procede del italiano "lotta", "lucha", porque al parecer se establece una lucha entre el jugador, la suerte y los concurrentes: otros suponen que se deriva del alemán "lot", que significa "suerte", por que es lo que uno desea en la lotería y demás juegos de azar. Otra definición proviene del latín "loterus" que se usaba en referencia a la suerte de los individuos.

La evidencia más antigua registrada de loterías son billetes keno de la dinastía china Han de entre 205 y 187 a. C. Keno es un tipo de lotería que aún se juega en los casinos de hoy en día. Hay evidencia que esas loterías chinas iniciales ayudaron a financiar la construcción de la Gran Muralla de China.

Es tan antiguo este juego de azar que en la descripción de las saturnales lo vemos ya usado por los romanos y se sospecha que fueron sus inventores para hacer más agradables dichas fiestas. Empezaban éstas por una distribución gratuita de billetes a los convidados, que ganaban algo de importancia o mérito en el caso de ser favorecidos por la suerte: lo que había escrito en los billetes se llamaba "apophaneta". De orden de Augusto se hicieron extracciones de poco valor, mientras Nerón, para halagar al pueblo mandó distribuir hasta mil billetes diarios alguna vez con los cuales se podía hacer la fortuna de algunas familias. Heliogábalo inventó una lotería muy original y consistía en lotes de mucho valor y lotes de muy poco: por ejemplo, doce esclavos y doce garbanzos, seis vasos de plata y seis de barro, una libra de fruta y una de oro. Parece que se debe la reaparición de este juego en la Europa moderna al monje Celestino Galiano, que floreció en el siglo XVIII y se dice que inventó otro juego llamado el "loto", semejante al de la lotería.

En la República de Génova existía la costumbre de echar a la suerte el nombre de los cinco senadores que debían ocupar ciertas plazas. El senado estaba compuesto de noventa miembros y para el sorteo se metían en una caja cincuenta bolas, cinco de ellas marcadas, que eran las de los cargos vacantes. El público, que desconocía el nombre de los noventa senadores, hacía apuestas sobre los que pudieran ser los agraciados, las cuales eran objeto de verdadera especulación. Se autorizó a varios banqueros para verificar operaciones regulares, fundándose con tal motivo una lotería por vez primera en 1629 que en pocos años pasó a las naciones vecinas.

En Francia, la lotería no nació hasta el año 1776, época en que se constituyó la lotería real, que fue abolida en 1836.

La lotería es un juego de azar que consiste en acertar los números de un billete previamente comprado con los números extraídos de una tómbola o un recipiente que garantice que sean extraídos al azar. Los números de dicho billete pueden ya estar preimpresos o bien ser elegidos por las propias personas. El número de aciertos pueden ser todos o parte de los número del billete. Al ganador o ganadores se les entrega un premio en dinero o especies. Por lo general si no hay ganadores para un sorteo el premio se acumula para el siguiente.

La lotería es un monopolio estatal o una concesión regulada por la leyes. En todos los países existen prohibiciones para que los particulares organicen juegos de lotería que no estén regulados de alguna forma. Una parte de lo recaudado por la venta de los billetes de lotería en general es entregada a obras de beneficencia social o queda en manos del Estado y es destinado a los gastos corrientes del mismo; de ahí que se diga que se trata de: "un impuesto voluntario". En este mismo orden fiscal, se ha detectado el frecuente uso de las loterías como instrumento de fraude fiscal.

Consiste en un grupo de barajas con figuras determinadas y con varios cartones que contienen un número determinado de éstas figuras ordenado al azar (ej. 9, 12, 16). Los jugadores toman cartones y uno de ellos además, previo a haber revuelto perfectamente el mazo, va sacando una a una las barajas y dándo su nombre, a esto se le llama en México, "cantar las barajas" o "echar la baraja" o simplemente "cantarlas" o "echarlas". A medida que se van "cantando" las barajas los jugadores apuntan en sus cartones las que van teniendo. Gana el primero que llene un cartón, es decir que todas las figuras de éste hayan salido y obviamente el jugador se haya dado cuenta, pues si no se dice que "se le pasaron" y el juego continua hasta que se dé cuenta o alguien más llene su cartón. Es común que existan metas intermedias como el primero que logra una figura al centro del cartón (en caso de que éste tenga una figura central ej. cartones de 3x3 o 5x5 figuras), a esto se le llama "Bolazo" y otras metas intermedias pueden ser para el primero en lograr "cuatro esquinas" o "raya" en un cartón particular.

Es común que este juego se juega con dinero, para lo cual se fija una cooperación por cartón y el monto de los premios del bolazo, la raya y las cuatro esquinas, en caso de que se decida que existan además de que el resto del dinero recolectado por los cartones utilizados luego de pagar los premios anteriores es para el ganador.

El año 1763, reinando Carlos III y siendo su ministro el Marqués de Esquilache, se estableció en Madrid la Real lotería "primitiva" o "antigua" en beneficio de varios establecimientos piadosos, habiéndose celebrado su primer sorteo el día 10 de diciembre de aquel año. 

Por un real decreto de 30 de septiembre del año 1763, se estableció en la villa de Madrid, a imitación de la corte de Roma y otras, la primera lotería, o sea la extracción de unos números a favor de los hospitales, hospicios y otras obras pías, bajo las seguridades, método y reglas que se creyeron conducentes e imprimieron para gobierno de los empleados.

En 20 de julio por resolución de Carlos III y circular del Consejo de 23 de agosto del siguiente año, se prohibió el establecimiento de ofertas extranjeras en España en atención a haberse introducido abusivamente en varias ciudades y pueblos billetes de varias de ellas que se beneficiaban y despachaban en el reino, para evitar la exportación del numerario bajo la pena de 500 ducados (5,500 rs.) por la primera vez a cada infractor, dividida entre el denunciador, juez y fisco por iguales partes; por la segunda la pena doblada y por la tercera, cuatro años de presidio además de los 1.000 ducados de multa.




</doc>
<doc id="15481" url="https://es.wikipedia.org/wiki?curid=15481" title="Contraste radiológico">
Contraste radiológico

Un contraste radiológico es cualquier sustancia radiopaca susceptible de ser empleada durante un examen de rayos X o radiografías, que realza imágenes de estructuras normalmente no visibles debido a que tienen la misma densidad que las estructuras vecinas. También se emplean contrastes para las técnicas de resonancia magnética. 

Existen diversos tipos de contrastes. Los contrastes densos se basan en la elevada masa atómica de ciertos átomos cuya presencia dentro del organismo es bien tolerada por éste. Los átomos involucrados son el yodo y el bario.


Los contrastes hipodensos son el aire, empleado en las técnicas de "doble contraste" para tubo digestivo y en la neumooncografía mamaria. A veces se emplea gas carbónico.


</doc>
<doc id="15486" url="https://es.wikipedia.org/wiki?curid=15486" title="Treponema">
Treponema

Treponema es un género de espiroquetas gram negativas, finas y pequeñas (de 0,1 a 0,4 µm de diámetro y 6 a 10 µm de largo), con espiras regulares y apretadas y extremos afilados. En fresco solo pueden observarse con un microscopio de campo oscuro o por contraste de fase.

Los "Treponema" son bacterias helicoidales que se tiñen difícilmente con colorantes de anilina y fácilmente con Giemsa o por impregnación argéntica. Son móviles en medios líquidos por medios de rotación o translación. Tienen de 1 a 5 flagelos, generalmente 3. Son organismos quimioheterótrofos, utilizando una gran variedad de carbohidratos o aminoácidos como fuente de energía y carbono. Realizan una respiración anaerobia estricta o microaerófila.

Las especies patógenas son difíciles de cultivar en laboratorio, siendo más factible visualizar el organismo directamente de la muestra con inmunofluorescencia directa y ciertas tiniciones especializadas. Normalmente son parásitos y patógenos del hombre y animales. Viven en la cavidad oral, el aparato digestivo y órganos genitales.



</doc>
<doc id="15487" url="https://es.wikipedia.org/wiki?curid=15487" title="Spirochaetaceae">
Spirochaetaceae

Familia de microorganismos del orden de los Spirochaetales de la Phylum Spirochaetes, clase Spirochaetes.

Bacterias anaerobias, anaerobias facultativas o microaerofilas, helicoidales con un diámetro comprendido entre 0.1 y 3.0 micrómetros, los extremos no están curvados. En el peptidoglucano poseen L-ornitina. Utilizan carbohidratos o aminoácidos como fuente energética y carbonada.


</doc>
<doc id="15488" url="https://es.wikipedia.org/wiki?curid=15488" title="Daniel Barenboim">
Daniel Barenboim

Daniel Barenboim (; Buenos Aires, 15 de noviembre de 1942) es un pianista y director de orquesta argentino nacionalizado español, israelí y palestino.

Hijo de músicos (tanto Enrique Barenboim como Aída Schuster, sus padres, fueron destacados pianistas), debutó en Buenos Aires a los siete años con un éxito tal que fue invitado por el Mozarteum de Salzburgo a continuar sus estudios en esta ciudad, en cuyo festival triunfó tres años después. Posteriormente estudió con Nadia Boulanger, Igor Markevitch y en la Academia de Santa Cecilia de Roma.

Barenboim empezó sus estudios de piano a la edad de cinco años con su madre y continuó con su padre, quien quedó como su único profesor. En agosto de 1950 interpretó su primer concierto en Buenos Aires. Realizó sus estudios primarios en el Instituto Pestalozzi de Belgrano R.

En 1952 la familia Barenboim se trasladó a Israel. Dos años más tarde, sus padres lo enviaron a Salzburgo para que tomara clases de dirección con Igor Markevitch. Allí conoció a Wilhelm Furtwängler, para quien tocó el piano. 

En 1955 estudió armonía y composición con Nadia Boulanger en París.

Barenboim debutó como pianista en el Mozarteum de Salzburgo en 1952, en París ese mismo año, en Londres en 1956 y en Nueva York en 1957, bajo la dirección de Leopold Stokowski. En los años siguientes realizó regularmente conciertos en Europa, Estados Unidos, Sudamérica y el Lejano Oriente.

Realizó su primera grabación en 1954. Más tarde grabó sonatas para piano de Mozart y Beethoven y conciertos de Mozart (interpretando al piano y dirigiendo), Beethoven (con Otto Klemperer), Brahms (con John Barbirolli) y Béla Bartók (con Pierre Boulez).

Tras su debut como director con la Orquesta Filarmónica de Londres en 1967, recibió invitaciones de diversas orquestas sinfónicas europeas y estadounidenses. El 15 de junio de ese mismo año, Barenboim contrajo matrimonio con la cellista británica Jacqueline du Pré. En el transcurso de los últimos años de la vida de du Pré, Barenboim se instaló en París con la pianista Elena Bashkirova. Un año después de la muerte de du Pré por esclerosis múltiple en 1987, se casó con Bashkirova, con la que tuvo dos hijos, David y Michael.

Su debut como director de ópera tuvo lugar en 1973 con la representación del "Don Giovanni", de Mozart en el Festival de Edimburgo. Entre 1975 y 1989 fue director musical de la Orquesta de París, donde dirigió numerosas piezas de música contemporánea.

En 1981 debutó en el festival de Bayreuth, realizado anualmente en homenaje a Wagner. Barenboim dirigió regularmente en esa ciudad hasta 1999, donde hizo una lectura completa de "El anillo del nibelungo" y de "Tristán e Isolda", con la mezzosoprano Waltraud Meier y el tenor Siegfried Jerusalem.

Desde 1991 hasta el 17 de junio de 2006, Barenboim fue director musical de la Orquesta Sinfónica de Chicago, cargo al que accedió en sustitución de George Solti.

El 2 de septiembre de 2001 solicitó la nacionalidad española, que le fue concedida el 25 de octubre de 2002. Desde 1980 se presentó con frecuencia en el Palacio de Carlos V con motivo de la celebración del Festival Internacional de Música y Danza de Granada. Por su vinculación con el anterior, le fue entregada la Medalla de Honor del Festival en un acto celebrado el 9 de julio de 2011.

Es además el director musical general de la Deutsche Staatsoper o Staatsoper Unter den Linden, la Ópera Estatal de Berlín conocida como "Unter den Linden" (Bajo los tilos) desde 1992.
Además de sus actividades como pianista y director de orquesta, Barenboim ha compuesto varios tangos. En diciembre de 2006 dirigió el Concierto de Año Nuevo en Buenos Aires, cuyo repertorio fue "Tango Sinfónico".

En 2008 se presentó por primera vez en el Metropolitan Opera de Nueva York, dirigiendo Tristán e Isolda de Wagner tocando en la misma semana un recital de piano en el escenario del Met, el primero en 22 años, el último había sido dado por Vladímir Hórowitz.

En 2009, dirigió el Concierto de Año Nuevo, frente a la Orquesta Filarmónica de Viena. En 2014 también lo ha dirigido, y saludó a todos los miembros de la orquesta mientras sonaba la Marcha Radetzky.

Fue condecorado con la Legión de honor del gobierno francés.

A partir del 10 de agosto de 2011 es candidato al Premio Nobel de la Paz por sus diversas actividades a favor de la paz y la convivencia en Oriente Próximo.

Desde la década de 1960 ha realizado presentaciones en Buenos Aires en varias ocasiones. Se presentó en el teatro Colón en 1980 con la Orquesta de París, en 1989 interpretó las variaciones Goldberg de Bach, en 1995 con la Staatskapelle Berlín, en 2000 con la Sinfónica de Chicago y en un recital de piano conmemorando 50 años de su debut en Buenos Aires, en 2002 para la integral de sonatas de Beethoven, en 2004 para los dos tomos del Clave bien temperado de Bach, en 2005 con la West-Eastern Divan Orchestra, en 2006 con un concierto multitudinario de fin de año ante 50.000 personas junto a la Filarmónica de Buenos Aires, en 2008 con la Staatskapelle Berlin y en 2010 nuevamente con la West-Eastern Divan interpretando las nueve sinfonías de Beethoven y en un concierto al aire libre para 60.000 personas y con el coro y orquesta del Teatro Alla Scala de Milán en el Teatro Colón con motivo del bicentenario argentino.

El 7 de julio de 2001, Barenboim dirigió la Staatskapelle de Berlín en la representación de la ópera de Wagner "Tristán e Isolda" en el festival de Israel celebrado en Jerusalén. Fue llamado pronazi y fascista por algunos de los presentes.

Barenboim iba a interpretar el primer acto de "La Walkiria" con tres cantantes, entre los que se encontraba el tenor español Plácido Domingo. Sin embargo, las protestas de los supervivientes del holocausto y del gobierno israelí forzaron a la organización del festival a buscar un programa alternativo. Pese a estar en desacuerdo con la decisión, Barenboim accedió a sustituir estas piezas por composiciones de Schumann y Stravinski. Finalizado el concierto, declaró que en el bis iba a interpretar una pieza de Wagner, e invitó a aquellos de los presentes que tuvieran alguna objeción a que abandonaran la sala.

En 1999 junto al escritor estadounidense de origen palestino Edward Said, al que lo unió una gran amistad, fundó la West-Eastern Divan Orchestra, una iniciativa para reunir cada verano un grupo de jóvenes músicos talentosos tanto de origen israelí como de origen árabe o español. Ambos recibieron el premio Príncipe de Asturias de la Concordia por la iniciativa.

En 2004 Barenboim recibió el Premio de la Fundación Wolf de las Artes de Jerusalén.

El 12 de enero de 2008, después de un concierto en Ramala, Barenboim aceptó también la ciudadanía palestina honoraria. Se convirtió así en el primer ciudadano del mundo con ciudadanía israelí y palestina, y dijo que la había aceptado con la esperanza de que sirviera como señal de paz entre ambos pueblos.


Doctorados "honoris causa"

Premios Grammy

Barenboim ha recibido, como director y como pianista, seis premios Grammy: 



</doc>
<doc id="15489" url="https://es.wikipedia.org/wiki?curid=15489" title="Oncología radioterápica">
Oncología radioterápica

La oncología radioterápica es una especialidad médica con un ámbito específico de actividad quirúrgica, dedicada a los aspectos diagnósticos, cuidados clínicos y terapéuticos del enfermo oncológico, primordialmente orientada al empleo de los tratamientos con radiaciones, así como al uso y valoración relativa de los tratamientos alternativos o asociados e investicación y docencia. Emplea rayos X y rayos gamma de alta energía (fotones de alta energía), haces de electrones y otras radiaciones ionizantes para el tratamiento de ciertas clases de cáncer.

Tradicionalmente se ha llamado a esta especialidad y forma de tratamiento, radioterapia.

El enfermo oncológico es considerado en el contexto general de la enfermedad neoplásica; valorando especialmente la integración del tratamiento con radiación y tratamientos alternativos, en la secuencia diagnóstica y terapéutica del abordaje de su enfermedad. El especialista oncólogo radioterapeuta debe poseer una profunda formación clínica y conocimiento de la oncología médica, siendo su competencia la indicación, planificación, control, ejecución y seguimiento del tratamiento con radiaciones y terapias asociadas. Debe ser asimismo competente en el apoyo clínica paliativo del enfermo terminal, y para valoración y seguimiento de los pacientes oncológicos. El campo de acción se enmarca en la asistencia médica especializada, e impone que el especialista tenga acceso directo a la evaluación de pacientes, participe en la asistencia clínica multidisciplinar como son los comités de tumores, y promueva proyectos de investigación y educación postgraduada en aquellas instituciones con especial proyección académica.

La actividad y ámbito de trabajo del especialista abarca los distintos aspectos clínicos y de investigación relacionados con el cáncer y con el efecto biológico de las radiaciones y tratamientos asociados. Su actividad clínica incluye la epidemiología, prevención, patogenia, clínica, diagnóstico, tratamiento y valoración pronóstica de las neoplasias. El campo de acción clínico puede sintetizarse en tres grupos de situaciones que definen la asistencia médica propia de la especialidad:

Tiene su origen en los primeros años del siglo XX. El primer médico en emplear la radioterapia oncológica en España fue el Dr Celedonio Calatayud en 1906. 

El campo de acción instrumental incluye el profundo conocimiento y experta manipulación de todos los elementos tecnológicos que permitan desarrollar una labor asistencial adecuada a la evolución del equipamiento médico:


</doc>
<doc id="15490" url="https://es.wikipedia.org/wiki?curid=15490" title="Mole de caderas">
Mole de caderas

El Mole de Caderas o huaxmole es un platillo tradicional de carne de chivo de la región de Tehuacán, Puebla.

El "mole de caderas" es considerado como uno de los platillos más importantes en los estados de Puebla y Oaxaca, debido a la prolongada crianza y cuidados en la preparación del animal -del cual se aprovecha la totalidad de la carne- y de la celebración del Festival de la Matanza que acompaña y da inicio al sacrificio de animales de crianza para la preparación de los alimentos y para la posterior conservación y curado de la carne.

En la preparación del mole de caderas se emplea la carne y hueso de la cadera, condimentos a base de sal, chile y se da un baño en limon para darle un toque especial, con un caldo de color rojo hervido con la carne de las caderas y ejotes silvestres. El sabor del platillo es característico de la carne de los chivos que son llevados durante un trayecto de un año pastando a través de las regiones del sur del estado de Puebla y del norte de Oaxaca, alimentando al ganado solo con abundantes cantidades de sal, se mantienen hidratados solo por agua. De la práctica de este tipo de crianza se obtiene carne de un sabor fuerte y característico con el cual se preparan los platillos tradicionales.

Guiso tradicional mexicano que lleva como ingredientes distintivos la cadera y el espinazo del chivo. La salsa se elabora con chiles guajillo, costeño y serrano, tomate, jitomate, hoja de aguacate, cilantro y un ejote típico de la región.

Las caderas de se cuecen en agua con cebolla, ajo, y sal; los chiles se tuestan y se preparan en salsa, y ésta se incorpora al caldo junto con hojas tostadas de aguacate; los ejotes se añaden cuando la carne está cocida.

Es típico del estado de Puebla, sobre todo en la capital, Cholula y Tehuacán. Algunos añaden guajes crudos molidos y cilantro, y lo convierten en huaxmole de caderas, aunque no se use este nombre para designarlo. Esta forma de huaxmole también se come en Oaxaca.

En los restaurantes tradicionales de Puebla se anuncia con especial insistencia cuando se prepara este mole, ya que para muchos es muy especial, al grado que un plato de mole de caderas es más caro que el mole poblano. Se elabora donde se celebra una fiesta anual, durante la época de la matanza de chivos, esto es, de octubre a diciembre.

El 20 de octubre de cada año se lleva a cabo en Tehuacán el festival de la matanza, en la que hay bailes y danzas como la denominada "danza de la matanza", donde literalmente se baila a un cabro macho para sacrificarlo al final con un tiro en la frente.

Con esta celebración da inicio la matanza, no sin antes ofrecer una ceremonia por parte de los matanceros en un altar donde se pide para que la matanza sea buena, igual o mejor que la del año pasado. Los matanceros dan paso a los chiteros y éstos, a su vez, a los fritangueros de víceras.

Todo el animal es aprovechado: el espinazo y caderas son lo más cotizado por la cocina tradicional de la zona; los huesos se venden para acompañar platillos también asociados con la temporada, como el guasmole o el tesmole; las vísceras se consumen en asadura y con la piel se prepara chicharrón de chivo.

El mole por lo general es un platillo único y se acompaña con tortillas de maíz Se conoce también como mole de chivo, aunque éste refiere a un guiso tradicional, pero más usual.

Las referencias históricas señalan como fecha probable del inicio de la elaboración de este mole el año 1800, época en la que hubo un aumento sin precedentes en las cabezas de ganado caprino.

Esta receta mexicana de mole de caderas de Puebla, México, lleva los siguientes ingredientes:

Para preparar mole de caderas hay que cocer las carnes con ajo y cebolla. Poner a hervir los chiles, el tomate y el jitomate. Molerlos con ajo y cebolla; freír en manteca, dejar sazonar. Incorporar la salsa a las carnes, previamente cocidas, con su caldo. Moler el huaje crudo y agregar; cuando el guiso esté hirviendo, añadir hojas de aguacate y cilantro en ramas. Hervir un momento y servir luego. Rinde 10 raciones.


</doc>
<doc id="15491" url="https://es.wikipedia.org/wiki?curid=15491" title="Excitabilidad neuronal">
Excitabilidad neuronal

La excitabilidad neuronal o impulso nervioso es la capacidad de las neuronas de cambiar su potencial eléctrico y transmitir este cambio a través de su axón. La excitación neuronal se produce mediante un flujo de partículas cargadas a través de la membrana, lo cual genera una corriente eléctrica de modo que depende de la existencia de distintas concentraciones de iones a ambos lados de la membrana celular y de la capacidad de transporte activo a través de estas membranas para generar una diferencia de potencial electroquímico dentro y fuera de la célula.

La membrana de las células está polarizada, debido a que hay un reparto desigual de cargas eléctricas entre el interior y el exterior de la célula. Esto crea una diferencia de potencial, siendo el exterior positivo respecto al interior. En el exterior, en el líquido intersticial, el anión más abundante es el cloro. En el citoplasma, los aniones más abundantes son las proteínas, que en el pH celular se ionizan negativamente. 

El catión más abundante en el líquido intersticial es el sodio, y en el citoplasma el potasio y la mayor parte de los cambios en el potencial son debidos al intercambio de estos iones.

La representación gráfica de la variación de potencial respecto al tiempo es el potencial de acción. La cantidad de estímulo necesario para provocar la actividad de una neurona, se denomina umbral de excitabilidad. Alcanzado este umbral, la respuesta es un potencial de acción independiente del estímulo. Es decir, sigue la ley del "todo o nada". Esto es debido a los canales activados por voltaje de sodio.

Durante la despolarización, la neurona no es excitable y se dice que está en periodo refractario absoluto. Durante la hiperpolarización subsiguiente, la neurona es parcialmente excitable, parcialmente refractaria, es decir, que se precisa un estímulo más intenso para provocar un nuevo potencial de acción, ya que ha aumentado el umbral de excitabilidad.




</doc>
<doc id="15494" url="https://es.wikipedia.org/wiki?curid=15494" title="Narrativa española anterior a 1936">
Narrativa española anterior a 1936

El siglo XX se inicia en España con un amplio movimiento de renovación cultural y artística que tiene dos momentos significativos: la Generación de 1898 (Miguel de Unamuno, Azorín, Ramón María del Valle-Inclán, Pío Baroja) y la llamada Generación de 1914. 

Esta renovación, no alcanza muy particularmente al relato novelístico, al que impulsa a ensayar nuevas fórmulas. Así, propicia no sólo el desarrollo de una novela de corte psicológico, sino de una novela lírica en la que predomina la expresión de la subjetividad. Relacionada con esta actitud hay que considerar el escaso interés que los escritores de este periodo muestran hacia el relato tradicional de acontecimientos según un orden cronológico; y ello a pesar del enorme éxito de otro conjunto de narradores que se ciñen a los modos clásicos del relato para ponerlos ya al servicio del entretenimiento o la mera diversión, ya al del impulso reformista y social (Blasco Ibáñez, Felipe Trigo, v.gr.).
La ruptura del relato tradicional se logra mediante una gran variedad de procedimientos estructurales y estilísticos más o menos innovadores: 

Esta línea renovadora la prolongarán los escritores del 14, muy especialmente Ramón Pérez de Ayala, Gabriel Miró y Ramón Gómez de la Serna- sin desistir aún en su afán de encontrar un punto de equilibrio entre el realismo y el experimentalismo aislador. El resultado es la creación de un corpus novelístico que conjuga el acceso a un público potencialmente amplio con una exigencia de valoración estética. Y eso sin que se diluya en su totalidad la marcada preocupación reformista y social que tiñe la actividad de gran parte de los autores e intelectuales del momento.

El clima cultural en el que surge la joven novelística del 27 se caracteriza, pues, por una actitud antirrealista y por un decidido afán experimental. 
Esta nueva narrativa se congregó en la serie Nova Novorum de la Revista de Occidente. Allí se fragua un tipo de relato que ensaya la incorporación a la narración 

Se trata, por tanto, de una novela en la que la narración se libera de la dependencia de la historia, que rompe con la disposición lineal del tiempo, y 
que abre un amplio espacio para el distanciamiento irónico o humorístico. 

Toda la narrativa del 27 se puede ordenar en dos grandes vertientes: la novela lírico-intelectual (Benjamín Jarnés, Antonio Espina, Mauricio Bacarisse, Francisco Ayala, Pedro Salinas) y la humorística (Jardiel Poncela, Edgar Neville).

Sin embargo, la crítica ha ignorado, cuando no despreciado, la importancia de este relevante grupo de escritores que sintoniza perfectamente con las modernas tendencias europeas de la época.

Pese a la repercusión de las Vanguardias, entre finales de la década de los 20 y 1935 surge una generación de narradores que, opuesta al arte deshumanizado, cultiva una novela realista y de finalidad social. Esta nueva generación se propone una manifiesta rehabilitación de lo humano, del valor testimonial y de la trascendencia moral y política de la literatura. Figura clave en esta evolución de la novela es José Díaz Fernández. Junto a él, son considerados precursores de la narrativa comprometida Joaquín Arderíus, Ramón J. Sender y César Arconada, entre otros.

Véase también:
Literatura española contemporánea


</doc>
<doc id="15496" url="https://es.wikipedia.org/wiki?curid=15496" title="Violín">
Violín

El violín (del italiano "violino", diminutivo de "viola" o "viella") es un instrumento de origen italiano de cuerda frotada o percusion frotada según Javier Amor del instituto IES Valle de Camargo que tiene cuatro cuerdas. Es el más pequeño y agudo de la familia de los instrumentos de cuerda clásicos, que incluye la viola, el violonchelo y el contrabajo, los cuales, salvo el contrabajo, son derivados todos de las violas medievales, en especial de la fídula.

En los violines antiguos, las cuerdas eran de tripa. Hoy pueden ser también de metal o de tripa entorchada con aluminio, plata o acero; la cuerda en mi, la más aguda ―llamada "cantino"― es directamente un hilo de acero, y, ocasionalmente, de oro. En la actualidad se están fabricando cuerdas de materiales sintéticos que tienden a reunir la sonoridad lograda por la flexibilidad de la tripa y la resistencia de los metales.

Además del efecto logrado por el arco, se pueden conseguir otros efectos: "pizzicato" (pellizcando las cuerdas como si se tratase de una guitarra, pero no con la misma posición), "trémolo" (moviendo el arco arriba y abajo muy rápido), "vibrato" (haciendo vibrar los dedos sobre las cuerdas), "glissando" (moviendo la mano izquierda arriba y abajo sobre las cuerdas), "col legno" (tocando con la parte de madera del arco), "sul ponticello" (tocando prácticamente sobre el puente), "sul tasto" (tocando sobre el diapasón).

Las partituras de música para violín usan siempre la clave de "sol", llamada antiguamente «clave de violín».

Las cuerdas se afinan por intervalos de quintas:

(El número está indicado de acuerdo con el índice acústico internacional, según el cual el "do" central del piano es un "do". Este índice se utiliza en todo el mundo excepto Francia y Bélgica.) 

La cuerda de sonoridad más grave es la de "sol", y luego le siguen, en orden creciente, el "re", "la" y "mi".
En el violín la primera cuerda en ser afinada es la del "la"; esta se afina comúnmente a una frecuencia de 440 Hz, utilizando como referencia un diapasón clásico de metal ahorquillado o, desde finales del siglo XX, un diapasón electrónico. El diapasón ha tendido a subir en los últimos años y se sitúa más comúnmente en los 442 Hz en la actualidad, e incluso más arriba en las orquestas norteamericanas.

El cuerpo del violín posee una forma abombada, con silueta estilizada determinada por una curvatura superior e inferior con un estrechamiento a la cintura en forma de C. Las tapas del violín se modelan con suaves curvas que proporcionan la característica de abovedado. Los aros, que van alrededor del violín dando la silueta, son de poca altura, el mástil posee cierto ángulo de inclinación hacia atrás respecto al eje vertical, longitudinal y se remata por un caracol llamado colocho o voluta. La estructura interna del violín la constituyen dos elementos fundamentales en la producción sonora del instrumento dados por la barra armónica y el alma. La barra armónica corre a lo largo de la tapa justo debajo de las cuerdas graves y el alma está ubicada justo debajo del pie derecho del puente donde se ubican las cuerdas agudas.

El arco es una vara estrecha, de curva suave y construida idóneamente en la dura madera del palo brasil o «de Pernambuco» ("Caesalpinia echinata"), de unos 77 cm de largo, con una cinta de 70 cm constituida por entre 100 y 120 (con un peso de unos 60 gramos según longitud y calibre) crines de cola de caballo, siendo las de mejor calidad las llamadas "Mongolia", que provienen de climas fríos donde el pelo es más fino y resistente. Tal cinta va desde una punta a la otra del arco. Para que las cuerdas vibren y suenen de un modo eficiente, la cinta de cola de caballo del arco debe ser frotada adecuada y regularmente con una resina llamada colofonia (en España se llama ""perrubia"", de "pez-rubia"). También, actualmente ―muchas veces para abaratar costos―, la crin blanqueda de caballo es sustituida por fibras vinílicas. El arco del violín tiene en la parte por la que es tomado un sistema de tornillo que al hacer desplazar la pieza por la cual se aferra un extremo de la cinta de crin hace que esta se tense o se distienda.

Los violines se clasifican de acuerdo con su tamaño: el 4/4 ―cuya longitud suele ser de 14 pulgadas o 35,5 cm y su ancho máximo de 20 cm, y un alto de 4,5 cm― es el más grande y es el utilizado por los adultos; le siguen violines de tamaño menor, destinados a jóvenes y niños, denominados 3/4, 2/4 y 1/4. Existe también un violín de tamaño 7/8, llamado también "Lady", que es utilizado por algunas mujeres o por varones adultos de manos pequeñas. El tamaño del violín va de acuerdo al tamaño (longitud) de la mano.

La genealogía que lleva al violín actual es más compleja. Se encuentra en el frotamiento de las cuerdas del laúd y el "rebab" ―y su versión europea, el rabel―, instrumentos difundidos en la Europa mediterránea durante la expansión medieval de la cultura árabe. En Italia, a partir de la lira bizantina o el "rebab", surgen los antecedentes más evidentes, tanto del violín como de la llamada viola da gamba; son tales precedentes la viola de arco (nombre que se utilizaba para todo instrumento de cuerda frotada con arco, como el "rebec" o rabel, y que también recibe las denominaciones de viela, vihuela, vihuela de arco, fídula y giga) y la lira o "viola da braccio", esta ya muy semejante a un violín o viola primitivos, aunque con el diapasón separando los bordones. Es en el siglo XVI que aparece el violín propiamente dicho, aunque con algunas diferencias respecto a la mayoría de los violines que se vienen fabricando desde el siglo XIX. La tapa superior y las tablas laterales se hacen de madera blanda, mientras que la tapa inferior se hace de madera dura. En el norte de Italia la ciudad de Cremona se hallaba entre un bosque de abetos (madera blanda) y uno de arces (madera dura), por lo que estas maderas eran las usadas por los grandes maestros violeros. El arco ha sufrido muchas modificaciones. El modelo actual data del siglo XIX, cuando François Tourte le dio una curvatura cóncava, que en los modelos más primitivos era convexa, como la del arco de cacería.

Aunque en el siglo XVII el violín ("violino") se encontraba bastante difundido en Italia, carecía de todo prestigio (el laúd, la vihuela, la viela, la viola da gamba, la guitarra, la mandolina eran mucho más considerados). Sin embargo, Claudio Monteverdi es uno de los que descubren la posibilidad de las calidades sonoras del violín, y es por ello que lo usa para complementar las voces corales en su ópera "Orfeo" (1607). Desde entonces el prestigio del violín comienza a crecer. Hacia esa época comienzan a hacerse conocidos ciertos fabricantes de violines (llamados aún luteros o lauderos, o "luthiers" — más frecuentemente que "violeros"— ya que inicialmente se dedicaron a la fabricación de laúdes). Así se hacen conocidos Gasparo Bertolotti de Saló, o Giovanni Maggini de Brescia, o Jakob Steiner de Viena; sin embargo, una ciudad se hará celebérrima por sus lauderos especializados en la confección de violines: Cremona. En efecto, de Cremona son los justamente afamados Andrea Amati, Giuseppe Guarneri, Antonio Stradivari (sus apellidos suelen ser más conocidos en su forma latinizada: "Amatius", "Guarnerius", "Stradivarius") y el mismísimo Claudio Monteverdi. Durante el siglo XIX se destacaron François Lupot y Nicolas Lupot. Es a partir de entonces, y sobre todo con el barroco, que se inicia la Edad de Oro (al parecer de allí en más perpetua) del violín.

Desde entonces el violín se ha difundido por todo el mundo, encontrándose incluso como «instrumento tradicional» en muchos países no europeos, desde América hasta Asia. El violín es un instrumento protagonista en las orquestas, grupos de cámara etc. Especial atención ha recibido en la música árabe, en la que el ejecutante lo toca apoyado en la rodilla cual si fuera un chelo, y en la música celta irlandesa, donde el instrumento recibe el nombre de "fiddle" (derivado del italiano "fidula"), y sus músicas derivadas como, en cierto grado, el "country". 

En cuanto al secreto de la sonoridad típica de los violines realizados por las familias Stradivarius y Guarneri, existen hoy diversas hipótesis que, más bien que excluirse, parecen sumarse; en primer lugar se considera que la época fue particularmente fría, motivo por el cual los árboles desarrollaron una madera más dura y homogénea. A esto se suma el uso de barnices especiales que reforzaban la estructura de los violines. También se supone que los troncos de los árboles eran trasladados por ríos cuyas aguas tenían un pH que reforzaba la dureza de las maderas; también influye un comprobado tratamiento químico (acaso más que con el objetivo de la sonoridad, el de la conservación) de los instrumentos, que reforzó la dureza de las tablas. Por último, ciertos violines Stradivarius tienen en sus partes internas un acabado biselado de los contornos en donde contactan las maderas, el cual parece beneficiar la acústica de estos violines.

El violín consta principalmente de una caja de resonancia que posee elegantes y hermosas formas ergonómicas (de sección oval con dos estrechamientos cerca del centro). Tal caja de resonancia está constituida por dos tablas: la tabla armónica y la tabla del fondo (tradicionalmente hecha con madera de arce), las cubiertas laterales o "aros" y la tabla superior o "tapa armónica" (tradicionalmente de madera de abeto blanco o rojo); la tapa se encuentra horadada simétricamente y casi en el centro por dos aberturas de resonancia llamadas "oídos" o "eses", ya que en el tiempo de su diseño se usaba aún en la escritura o imprenta la S larga, semejante a una "efe" cursiva pero sin el travesaño horizontal, y en desuso a partir del siglo XVIII. Por la misma razón, actualmente se tienden a llamar "efes".

En el interior de la caja se encuentra el poste sonoro o "alma" del violín, que es una pequeña barra cilíndrica de madera dispuesta perpendicularmente entre la "tapa" y la "tabla armónica" del lado derecho del eje de simetría de la caja (esto es: prácticamente abajo, hacia la derecha, de la zona en donde se apoya el "puente"), del lado contrario al "alma", a lo largo de la cara interna de la "tapa", se encuentra adherido con cola un listón llamado "barra armónica". Tanto el "alma" como la "barra armónica" cumplen dos funciones: ser soportes estructurales (el violín sufre mucha tensión estructural) y transmitir mejor los sonidos dentro de la caja de resonancia.

La caja de resonancia tiene, en el violín de orquesta, 35,7 cm de longitud, y se encuentra orlada por rebordes en ambas tablas; tales rebordes cumplen, además de una función decorativa, la función de reforzar el instrumento.

Por fuera, la caja de resonancia se continúa por el "mango" o "astil"; el mástil o "mango" concluye en un "clavijero", oquedad rectangular en la que se insertan las cuerdas anudadas y tensionadas allí mediante sendas "clavijas" para cada cuerda, las clavijas son como llaves simples de sección ligeramente conoidal; luego del clavijero, un remate llamado ―por su forma― "voluta" (aunque en ciertos casos la voluta se encuentra sustituida por otras formas, por ejemplo una cara humana o la figuración de una cabeza de león).

En cierto ángulo, las líneas de la voluta, en perspectiva, hacen una línea recta y continua con las cuerdas, especialmente mi y sol, y se juntan en el horizonte. Esto permite saber, cuando el violín está puesto en el hombro, cuándo se encuentra correctamente recto.

Sobre el mango se ubica el diapasón del violín o "tastiera", este suele ser de ébano ya que esta madera produce ese sonido "maderil" que los instrumentos de cuerda frotada requieren además el ébano es sumamente duro y denso por lo que la fricción de las cuerdas no daña el diapasón. En violines antiguos pueden encontrarse tastieras de marfil.

Sobre la tapa de la caja se encuentra el "ponticello" o "puente" el cual mantiene elevadas las cuatro cuerdas, en la parte posterior de la caja de resonancia, unida a ella por un nervio flexible que se engancha a un botón, se encuentra otra pieza (tradicionalmente de madera de ébano) de forma triangular llamada el "cordal", como su nombre lo indica, el "cordal" sirve para retener las cuatro cuerdas, estas se apoyan en los siguientes puntos: los orificios del cordal, el ponticello, la cejilla ubicada sobre el astil y las clavijas.

Cuando se quiere atenuar el sonido, se aplica sobre el "puente" una especie de tabique llamado "sordina".

Desde fines de siglo XIX es común añadir a la parte trasera de la caja de los violines una "mentonera" o "berbiquí" desmontable, aunque tal aditamento "no" es indispensable (la invención de este añadido se atribuye a Louis Spohr); en cambio sí es de bastante importancia el barniz (Tradicionalmente "gomalaca" diluida en alcohol) con el cual se recubre, en su parte externa, a la mayor parte del violín.

La singular acústica del violín ha sido muy estudiada durante todo el siglo XX, destacándose las investigaciones del alemán Ernst Chladni, del cual deriva toda una formulación llamada "esquema de Chladni".

La manera de sostener el violín y de igual forma el arco es una parte importante en la enseñanza del instrumento ya que crea un rango de posibilidades para tener una buena o mala técnica, por lo tanto debe de tener una primordial consideración al empezar el estudio del instrumento.
Lo primero que se debe de tomar en cuenta en la posición del violín, es que este debe de sostenerse de tal manera de que los ojos de puedan fijar en la cabeza del violín; y a su vez el brazo izquierdo debe de acomodarse ligeramente hacia adelante para que los dedos se pongan de manera natural y perpendicular en el diapasón. De mismo modo, es importante que el violín de manera certeza en el cuello, y sea sostenido con el hombro, ya que de lo contrario puede crear desastrosos efectos en su sonido.
Debe de ser colocado lo más alto posible, para que el brazo tenga toda la libertad de movimiento y por consiguiente la mano pueda tener libre movimiento en los dedos para poder cambiar de posición con facilidad. 

Instrumento de singular resistencia, el violín suele requerir de pocos cuidados especiales. Cuando no se usa debe estar guardado en un estuche lo más hermético y acolchado posible, con la caja, la vara del arco y las cuerdas limpias, y las crines del arco levemente distendidas. El violín ha de estar al resguardo en todo lo posible para que no le afecte la humedad ni cambios bruscos de temperatura; por lo demás, solo requiere una habitual limpieza con un paño seco, o bien con productos especialmente diseñados para ello. Las cuerdas suelen romperse por la tensión y la fricción, y por este motivo es conveniente que el violinista tenga un juego de cuerdas de repuesto. También suelen romperse los pelos de cola de caballo (crines) que constituyen la cinta del arco; por este motivo los que ejecutan con bastante frecuencia música con el violín se ven obligados a un recambio anual de las crines. Si se ejecuta el violín sin la barbada o mentonera, conviene usar un pañuelo en la parte del cuello y mentón en la cual se apoya el violín para evitar que el instrumento se vea afectado por la transpiración. En general ocurre que un violín "viejo" que haya sido bien ejecutado, suena mejor que un violín nuevo o con poco uso.

Una característica importante en el cuidado es que al guardar el violín durante un período largo de tiempo, este no debe quedar afinado, es decir, las cuerdas no deben quedar tensas. Con esto, la estructura del violín no quedará sometida a una tensión innecesaria.

Desde la segunda mitad del siglo XX las cuerdas y la cinta del arco, en muchos casos, están siendo fabricadas con materiales sintéticos; empero, el uso de materiales sintéticos se ha extendido a otras partes en el caso de los violines fabricados en serie, por ejemplo cordales, mentoneras, tastieras, están siendo fabricados en plástico. Esto amerita la detracción de parte de los violinistas profesionales de escuela tradicional. Sin embargo, se construyen violines eléctricos, con casi todos sus componentes sintéticos, tales violines suelen usarse en conjuntos de pop, "rock", "jazz" y afines.

La introducción hacia fines del siglo XVI e inicios del XVII del violín en el ámbito del Cono Sur se debe principalmente a los frailes jesuitas y franciscanos, muchos de ellos nacidos italianos como Domenico Zipoli, cuyo nombre lleva una famosa escuela de música cordobesa.

Los jesuitas introdujeron la enseñanza musical en las reducciones creadas en territorios que hoy pertenecen a la Argentina, Paraguay, Bolivia y el sur de Brasil, en una región poblada en los citados siglos por indígenas entre los cuales preponderaba la cultura guaraní. La mayor parte de esas pequeñas ciudades fue destruida con la expulsión de los jesuitas, en 1767 en la colonia española, precedida por una decisión del reino de Portugal. Las misiones jesuíticas de Bolivia son las únicas que se salvaron de la destrucción que sobrevino a la expulsión de los religiosos. Se trata de siete ciudades en la región conocida como Chiquitania donde anualmente se realiza un festival de música barroca.

En Brasil, el violín artesanal conocido por el nombre de "rabeca" fue introducido también por los religiosos, especialmente en la zona de las misiones jesuíticas, pero su utilización en la música se desarrolló más intensamente durante la breve presencia colonizadora del holandés Mauricio de Nassau, en Recife, entre 1637 y 1643. Otro importante estímulo representó la instalación de la Corte portuguesa en Río de Janeiro en 1807.

Actualmente, la utilización de la rabeca como instrumento melódico es común en la música de la región nordeste y también en el norte amazónico. En la ciudad amazónica de Bragança, en el estado de Pará, la tradición de la rabeca recibió un notable impulso por parte del poder público que ayudó a instalar una escuela para la enseñanza del instrumento, basada en el conocimiento y la técnica de los maestros locales.

Dentro de los folclores sudamericanos el violín es particularmente relevante en el folclore de Argentina y en zonas aledañas, donde fue utilizado en la música religiosa, aunque rápidamente las poblaciones criollas y autóctonas supieron utilizarlo para músicas profanas. Así es que en gran parte del norte argentino y el sur de Bolivia, el violín (e incluso una variante más rústica que ha mantenido el arcaico nombre de "rebab") es uno de los instrumentos musicales principales, tras la guitarra y el bombo. Con el violín se suelen acompañar los gatos, chacareras, las cuecas bolivianas y en menor medida chamamés, zambas y polcas criollas.Música de origen folclórico, el tango cuenta con el violín como uno de sus principales instrumentos. El violín de tango suele ser el mismo que el violín de concierto para la llamada música clásica, en cambio los violines de las otras músicas mencionadas anteriormente suelen ser violines "criollos", de formas muy semejantes al violín clásico, aunque la gran diferencia se encuentra en las maderas con que están confeccionados (algarrobo criollo y mistol o chañar por ejemplo); en gran parte de Argentina (especialmente en el NOA) a los músicos especializados en tocar el violín "no" se les dice violinistas sino "violinistos" o "violistos", en el noreste es frecuente el término "violinero" (que sin embargo suele aplicarse más al "luthier"). Las etnias de ascendencia directamente aborigen también suelen confeccionar interesantes tipos de "violines", por ejemplo entre los qom'lek (o tobas) son característicos los "violines" fabricados a partir de una lata cuadrangular de aceite comestible a la cual se le aplica un mango de leño, las cuerdas suelen ser realizadas con tripa aunque más modernamente se realizan con los cables de metal que se obtienen de los sistemas de frenos de bicicletas; teniendo tales violines una entonación llamada "m'biké", tal entonación, se considera, es similar a la que poseían los violines europeos en el siglo XVI.

En Venezuela se utiliza principalmente en la región de Los Andes para ejecutar bambucos y valses de la región. 

En México, su uso se extiende al son huasteco, huapango, música calentana, música planeca y mariachi. En España, se utiliza en los verdiales. En los países anglosajones, al violín folclórico se le denomina "fiddle".

En Chile, la única región en la que el violín fue introducido de manera tradicional en la música folckórica es Chiloé, llegando a generarse una variante de este instrumento conocido como "violín chilote", el cual, aparte de incorporar el uso de maderas nativas de la Patagonia chilena en la lutheria de violines, como alerce, coigüe y ciruelillo, presenta una caja acústica más plana y de mayor tamaño que el violín docto, dándole un sonido característico. Una variante del violín chilote que ocupaba tripas de carnero como cuerdas es conocida como "Barraquito", siendo común escuchar ambos instrumentos en danzas como la "Pericona" y en pasacalles en honor a santos y vírgenes. En Chiloé es común encontrar también al rabel como parte de los instrumentos musicales tradicionales.

Nicoló Paganini creó una mixtura muy interesante entre la relación del humano con el violín, cuenta la historia que a su madre Teresa Bocciardo para decirle, que su hijo estaba destinado a ser el más importante violinista del mundo,en los pasillos musicales de Italia se hablaba del "diabólico talento" de Paganini, quien culminó esta etapa de la percepción de su pacto componiendo una de las obras más bellas según muchos críticos,"la Sonata del Diablo".

"Violin Playing As I Teach It" Auer Leopold



</doc>
<doc id="15497" url="https://es.wikipedia.org/wiki?curid=15497" title="Geografía de Indonesia">
Geografía de Indonesia

Una extensión de agua relativamente abierta (formada por los mares de Java, Flores y Banda) divide la mayor parte de las islas de Indonesia en dos hileras desiguales de islas: al sur, las islas (comparativamente largas y estrechas) de Sumatra, Java y Timor entre otras, y al norte, Borneo, islas Célebes, el archipiélago de las Molucas y Nueva Guinea.

Una cadena de montañas volcánicas, que alcanza altitudes superiores a los 3.700 m, se extiende de oeste a este, a través de las islas meridionales desde Sumatra hasta Timor. Los puntos más elevados de esta cadena son el Kerinci (3.800 m) en Sumatra, y el Semeru (3.676 m), en Java. Cada una de las islas septentrionales principales tiene una masa montañosa central y llanuras en torno a la costa. Puncak Jaya (5.030 m), en la cadena montañosa Surdiman de Irian Jaya, es la cima más elevada del país. Las zonas con mayor extensión de tierras bajas son Sumatra, Java, Borneo e Irian Jaya. Durante siglos las periódicas erupciones volcánicas de los numerosos volcanes activos han depositado ricos suelos en las tierras bajas, sobre todo en Java. Muchos continúan activos y también se producen . Uno de los más destructivos fue el terremoto del océano Índico de 2004, con epicentro cerca de Sumatra, que afectó a toda la cuenca del océano Índico y provocó la muerte de más de 200.000 personas.

El rico suelo volcánico de Indonesia es ideal para el desarrollo de los cultivos; los bosques se extienden por su superficie y cubren aproximadamente dos tercios del territorio. 

Los principales recursos del país son el estaño, la bauxita, el petróleo, el gas natural, el cobre, el níquel y el carbón; también cuenta con pequeñas cantidades de plata, diamantes y rubíes. La pesca es abundante y del mar se obtienen también perlas, conchas (carey) y agar, una sustancia que se extrae de las algas.

Las cálidas aguas alrededor de Indonesia proporcionan un clima suave y tropical durante todo el año. Las temperaturas promedio son de 28 ° C a lo largo de las planicies costeras y de 23 a 26 °C en las montañas del centro de las islas. La humedad relativa oscila entre el 70 y el 90%. Los vientos son moderados, el monzón, en general, sopla del sureste entre junio y septiembre, y del noroeste entre diciembre y marzo. Los tifones y las tormentas rara vez son un peligro, las corrientes entre las islas son el mayor riesgo para la navegación, especialmente en el estrecho de Lombok.

Las principales islas se recogen en la Tabla que sigue:

Hay además, muchas otras islas de menor importancia, que por área geográfica son: 






</doc>
<doc id="15498" url="https://es.wikipedia.org/wiki?curid=15498" title="Política de Indonesia">
Política de Indonesia

Indonesia es una república presidencialista. Al año siguiente el sistema federal de Indonesia fue abolido y el país se convirtió en una república unitaria.

Tres constituciones provisionales definieron la forma del gobierno de Indonesia. La primera fue proclamada en 1945; la segunda fue promulgada en febrero de 1950 y la tercera fue aprobada, en agosto de 1950, por la Cámara de Representantes. En 1959 se restableció la Constitución de 1945 mediante un decreto presidencial.

Según la Constitución de 1945, el principal poder ejecutivo de Indonesia es el presidente, elegido por un plazo de cinco años por el voto popular. Anteriormente era designado por un cuerpo nacional denominado la Asamblea Consultiva del Pueblo, que realiza parte de las funciones parlamentarias del país. 

El presidente, que puede ser elegido durante varios periodos, tiene un amplio poder y puede gobernar por decreto; también nombra y preside el gabinete de ministros.

El poder legislativo en Indonesia reside en el Consejo de Representantes, que debe aprobar todas las leyes y tiene derecho a presentar proyectos de ley para que sean ratificados por el presidente. El Consejo está formado por 400 miembros directamente elegidos y 100 nombrados. La Asamblea Consultiva del Pueblo está compuesta por los miembros del Consejo y 500 miembros más que son delegados regionales y representantes de grupos profesionales (como campesinos, hombres de negocios, intelectuales y mujeres). Las principales funciones de la Asamblea son determinar las líneas generales de la política del gobierno y del Estado. La Constitución requiere que la Asamblea se reúna al menos cada cinco años y que el Consejo se convoque una vez al año.

Los casos criminales y civiles se juzgan en tribunales de distrito distribuidos por toda Indonesia. Las apelaciones se realizan ante los tribunales supremos ubicados en las 14 ciudades más importantes; el tribunal de apelación final es el Tribunal Supremo, que tiene su sede en Yakarta. Las leyes del Código Penal se aplican en toda Indonesia. En los casos de jurisdicción civil, sin embargo, los indonesios son juzgados según una ley consuetudinaria no codificada (Ley de Adat), mientras que los occidentales y asiáticos de origen o antepasados extranjeros están sujetos a un sistema basado en los códigos civiles continentales europeos.

Cada una de las 33 provincias y distritos está administrada por un gobernador y por cuerpos administrativos y legislativos locales.

Indonesia tiene tres partidos políticos importantes. El de mayor entidad es Golongan Karja (GORKA, Grupos Funcionales, fundado en 1964), una alianza de organismos que representan a los trabajadores, campesinos, la juventud y otros grupos económicos. Otras agrupaciones son el Partido de la Unidad para el Desarrollo (1973), que tiene una fuerte orientación musulmana, y el pequeño Partido Democrático de Indonesia (1973), una coalición de grupos cristianos y nacionalistas.

La escasa alimentación, las viviendas hacinadas, la ausencia de higiene y las aguas no potables confieren aún mayor gravedad a los serios problemas de salud con los que se enfrenta la población de Indonesia. El gobierno ha iniciado programas que tienen como finalidad incrementar las normativas sobre salud y que intentan aportar soluciones a los problemas de adicción a los narcóticos y a la prostitución y tratan de conseguir la readaptación de los soldados desmovilizados. La esperanza de vida era, a finales de la década de 1980, de 55 años para los hombres y 58 años para las mujeres; el índice de mortalidad infantil era de 83‰. A finales de esa misma década Indonesia contaba con unos 21.500 médicos y más de 112.000 camas de hospital.

Las Fuerzas Armadas de Indonesia se unificaron en 1967 y se sometieron al control del ministro de Seguridad y Defensa. Desde entonces la institución militar ha ejercido una autoridad decisiva. El Ejército del país, la Armada y las Fuerzas Aéreas cuentan con un total de 274.500 personas.


</doc>
<doc id="15499" url="https://es.wikipedia.org/wiki?curid=15499" title="Cultura de Indonesia">
Cultura de Indonesia

La cultura de indonesia es el resultado de la mezcla de diferentes civilizaciones. Siendo hoy en día un país islámico, las creencias autóctonas, el hinduismo y el budismo de la India ejercieron una profunda influencia y han dejado una importante huella en la arquitectura y escultura del país. Las islas también han sentido la influencia de las culturas polinesia y de Asia suroriental, así como la de chinos y holandeses. La influencia árabe empezó a cobrar más importancia a partir del siglo XIII, sobre todo a través de las enseñanzas del islam. 

En Indonesia hay aproximadamente 20 bibliotecas de gran importancia que se hallan sobre todo en las ciudades de Bandung, Bogor, Yakarta y Yogyakarta. En Yakarta se encuentran los archivos nacionales y la Biblioteca del Museo Nacional (360.000 volúmenes), así como la Biblioteca Nacional (750.000 volúmenes), que alberga varias colecciones especiales. El Museo de Bali está situado en Denpasar.

La Constitución de Indonesia garantiza la religión, siempre que sea una de las cinco religiones oficiales (Islam, Catolicismo, Protestantismo, Budismo, Hinduismo) y bajo el credo de "Pancasila" entre otras cosas, defiende por igual y da el mismo trato a todas las creencias.

El Islam en sus diferentes manifestaciones es la fe de aproximadamente el 88% de la población. Entre los demás grupos religiosos se pueden señalar la presencia de más de 17 millones de cristianos, sobre todo protestantes, y más de 1,5 millones de budistas, la mayoría de origen chino. El hinduismo, que en el pasado tuvo una gran importancia, está confinado a la isla de Bali y algún punto remoto del este de Java.

El Islam en Indonesia es similar al Islam en los países árabes. Los indonesios son un pueblo extremadamente abierto y pacífico, con una base hindú y budista muy sólida por la cual se acogió el Islam hace cinco siglos. 

En general, existe respeto y tolerancia entre aquellos que profesan religiones distintas, aunque en momentos puntuales, siempre motivados políticamente, ha habido enfrentamientos entre musulmanes y cristianos (Célebes central, Molucas). 

En las islas de Java y Sumatra predomina el Islam, donde viven casi 200 millones de personas. Bali, por su parte, es el último lugar donde se practica el hinduismo, y en el Este de Indonesia (Flores, Timor, Molucas, Célebes Septentrional) encontramos cristianismo (católicos y protestantes); en estas provincias viven entre 15 y 20 millones de personas.
En Indonesia se hablan más de 100 idiomas, pero la lengua oficial y más hablada es el Bahasa Indonesia. De origen malayo, fue durante mucho tiempo la lengua de los comerciantes de las ciudades costeras, y posee elementos del chino, del indio, del holandés y del inglés.

Según la legislación indonesia, la enseñanza es obligatoria desde los seis años. El sistema de enseñanza del país sigue el sistema holandés con un programa de enseñanza secundaria dividido en matemáticas, lenguaje y ciencias económicas. Aproximadamente el 74% de los indonesios de 15 años o más saben leer y escribir.


A finales de la década de 1980, 26,7 millones de niños indonesios asistieron a escuelas primarias públicas y más de 8,9 millones de estudiantes se inscribieron en institutos de enseñanza secundaria. Además, más de 1,4 millones de estudiantes indonesios acudieron a escuelas de formación del profesorado.


A finales de la década de 1980, acudieron a las instituciones de educación superior casi 1,2 millones de estudiantes por año. Las instituciones con mayor número de alumnos son la Universidad de Indonesia (1950) en Yakarta, la Universidad Estatal de Pajajaran (1957) en Bandung y la Universidad Gajah Mada (1949) en Yogyakarta. Para el año académico de 2008/2009, el Ministerio de Educación Nacional otorgará a 1000 personas a participar en Beca Regular, y Short Course (curso corto). Los programas serán otorgados por el Gobierno de la República de Indonesia para estudiantes extranjeros que tengan interés en estudiar arte, danza típica, música tradicional, idioma Indonesio (bahasa Indonesia) y dialectos Indonesios en 54 universidades y colegios en Indonesia.

A finales de los años ochenta, funcionaban en Indonesia más de 890.000 teléfonos. La emisora estatal, Radio Republic Indonesia, opera en 49 estaciones que llegan a unos 32,8 millones de oyentes.

Un sistema de transmisión de televisión, controlado por el Estado, que comenzó a funcionar en 1962, se estima que llega a unos 7,1 millones de televidentes; la difusión de la televisión comercial privada se inició en 1989. 

Los principales periódicos de gran difusión de Indonesia son The Jakarta Post, Kompas, Pos Kota y Berita Buana, y la revista crítica Tempo, todos publicados en Yakarta.

El archipiélago cultural de Indonesia abarca 18.000 islas, con su propia historia única y distintos temperamentos culturales y artísticos. Esta diversidad en la fibra moral de las numerosas islas ha dado a luz a los centenares de diversas formas de música, que se acompañan a menudo de danza y teatro. Para saber más sobre la música y para bailar en Indonesia, es importante entender las varias influencias culturales que han formado eventualmente el país.
Si bien en sus orígenes fue influida por los sistemas musicales de China, India e Indochina, su evolución es independiente y totalmente diferenciada. La música de Indonesia no tiene sentido separada de la poesía o la danza y es, en general, de carácter mágico y religioso, tomando formas de representación teatral. La unidad de ejecución es el gamelan, orquesta formada por instrumentos diversos según las distintas variedades. La música de Indonesia comprende tres sectores: Java, Bali e islas periféricas.

La música de Java, Sumatra, Bali, Flores y otras islas ha fascinado a muchos. El "estallido" de la música tradicional en el curso de la música popular indonesia y de la música Se basaron en la forma de música de danza que ha sido popular desde mediados de los años setenta. El Qasidah moderno, es una forma de poesía religiosa acompañada por cantos y la percusión y es muy popular entre las audiencias del "estallido".El baile en Indonesia se realiza como en la mayor parte de los artes de ejecución del Oriente. La danza en Indonesia se cree que pudo haber comenzado como una forma de adoración religiosa. Hoy, aunque las influencias modernas continúan entrando calladamente, las viejas tradiciones de la danza y el drama todavía están bien resguardadas. Se están preservando por muchas organizaciones gubernamentaleso o academias de arte y escuelas de danza supervisadas, aparte de las que prosperan en las cortes. En tiempos pretéritos estas manifestaciones musicales fueron realizadas en las cortes reales para entretener, sin embargo, ahora estas danzas han alcanzado a amplios estratos populares de las cortes incluidas, y han incorporado una forma más espontánea de expresión.

Java: La música javanesa conoce dos sistemas de afinación principales, el slendro (pentatónico) y el pelog (heptatónico); de ellos derivan todos los actuales. A cada sistema de afinación corresponde un sistema de representación teatral basado en representaciones con actores o con marionetas y, según cuál sea el estilo, sobre ciclos del Ramayana y Mahabaratha o sobre ciclos autóctonos javaneses. Entre los instrumentos javaneses se pueden mencionar el gambang kayu, especie de xilofón, el bonag panerus, formado por una doble fila de tubos, el ageng, un tipo de gong, etc. Cada uno de ellos tiene una función definida dentro del gamelan y en relación al estilo y escala escogidos. El canto tiene gran importancia, ya que la poesía se canta siempre y no se recita. Existen gran variedad de formas vocales y de metros. El número de versos, su metro y la vocal final de verso están prescritos rigurosamente. Una variedad del gamelan es el kowangan de los pastores de las montañas, que utiliza instrumentos de cuerda, tamboriles e instrumentos de bambú.
Bali: El sistema musical de Bali es, en cuanto a lo que a instrumental y sistemas de afinación se refiere, similar al javanés, pero desde el punto de vista del carácter es fundamentalmente distinto. La base de la música balinesa la dan fuertes contrastes dinámicos y de tempos, una gran espectacularidad y una riqueza ornamental que contrasta con la severidad normativa de la música javanesa. La diferencia originaria estriba en que mientras la música de Java fue una música de corte, o al menos favorecida por las bussy. Modernamente, otros músicos occidentales se han acercado a la música de Bali.
Islas periféricas. Están influidas por la música de Java y Bali así como por la de culturas no indonésicas. La influencia balinesa es más importante en las islas de la Sonda, especialmente en Lombok. Las islas Célebes cuentan con cantos heroicos autóctonos acompañados por el keso-keso, especie de laúd. Borneo pertenece al área de influencia javanesa, salvo en el interior, donde existen cantos autóctonos y un interesante órgano de boca, llamado kledi, originario de Indochina. Por el contrario, la isla de Sumatra mezcla la influencia puramente indonésica con la del mundo islámico. La música de Sumatra muestra influencias arábigas y aun persas, existiendo en ella algunas especialidades instrumentales como el bangsi, especie de flauta, el serunai, especie de oboe, y el gambus, laúd de siete cuerdas.


</doc>
<doc id="15500" url="https://es.wikipedia.org/wiki?curid=15500" title="Arte en Italia">
Arte en Italia

En Italia el enfrentamiento y convivencia con la antigüedad clásica, considerada como un legado nacional, proporcionó una amplia base para una evolución estilística homogénea y de validez general. Por ello, allí, es posible el surgimiento del arte renacentista y precede a todas las demás naciones. En Florencia el desarrollo de una rica burguesía ayudará al despliegue de las fuerzas del Renacimiento, la ciudad se convierte en punto de partida del nuevo estilo, y surgen, bajo la protección de los Médicis, las primeras obras que desde aquí se van a extender al resto de Italia.

Fuera de Italia la Antigüedad Clásica supondrá un caudal académico asimilable, y el desarrollo del Renacimiento dependerá constantemente de los impulsos marcados por Italia. Artistas importados desde Italia o formados allí, hacen el papel de verdaderos transmisores.


</doc>
<doc id="15501" url="https://es.wikipedia.org/wiki?curid=15501" title="Austrodanthonia">
Austrodanthonia

Austrodanthonia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Australia, Nueva Zelanda y Nueva Guinea.

El número cromosómico básico del género es x = 12, con números cromosómicos somáticos de 2n = 24 diploide. 



</doc>
<doc id="15502" url="https://es.wikipedia.org/wiki?curid=15502" title="Historia de los Estados Unidos de América">
Historia de los Estados Unidos de América

La fecha del inicio de la historia de los Estados Unidos de América es un tema de debate entre los historiadores. Los libros de texto más antiguos comienzan con la llegada de Cristóbal Colón el 12 de octubre de 1492 y hacen hincapié en los antecedentes europeos de la colonización de las Américas, o comienzan alrededor de 1600 y hacen hincapié en la frontera estadounidense. En las últimas décadas, las escuelas y universidades estadounidenses han retrocedido en el tiempo para incluir más información del período colonial y mucho más de la prehistoria de los nativos americanos.

Los pueblos indígenas vivieron en lo que hoy es Estados Unidos durante miles de años antes de que los colonizadores europeos comenzaran a llegar, sobre todo de Inglaterra, después de 1600. Los españoles construyeron pequeños asentamientos en Florida y el suroeste, y los franceses a lo largo del río Mississippi y la costa del Golfo . En la década de 1770, trece colonias británicas contenían dos millones y medio de personas a lo largo de la costa atlántica al este de los Apalaches. Después del fin de las guerras francesas e indias en la década de 1760, el gobierno británico impuso una serie de nuevos impuestos, rechazando el argumento de los colonos de que cualquier nuevo impuesto debía ser aprobado por ellos (véase Stamp Act 1765). La resistencia fiscal, especialmente la Boston Tea Party (1773), llevó a leyes punitivas (las Actas Intolerables) por el Parlamento, diseñadas para poner fin al autogobierno en Massachusetts. Los patriotas americanos (como se llamaban a sí mismos) se adherían a una ideología política llamada republicanismo que enfatizaba el deber cívico, la virtud y la oposición a la corrupción, los lujos de fantasía y la aristocracia.

El conflicto armado comenzó en 1775 cuando los patriotas expulsaron a los oficiales reales de cada colonia y se reunieron en reuniones y convenciones de masas. En 1776, el Segundo Congreso Continental declaró que había una nueva nación independiente, los Estados Unidos de América, no sólo una colección de colonias dispares. Con el apoyo militar y financiero a gran escala de Francia y España y la dirección militar del general George Washington, los patriotas americanos ganaron la guerra revolucionaria. El tratado de paz de 1783 dio a la nueva nación la tierra al este del río Mississippi (excepto Florida y Canadá). El gobierno central establecido por los artículos de la Confederación demostró ser ineficaz para proporcionar estabilidad, ya que no tenía autoridad para recaudar impuestos y no tenía un oficial ejecutivo. El Congreso convocó una convención para reunirse secretamente en Filadelfia en 1787. Escribió una nueva Constitución, que fue adoptada en 1789. En 1791, se agregó una Carta de Derechos para garantizar derechos inalienables. Con Washington como el primer presidente y Alexander Hamilton su consejero político y financiero principal, se creó un gobierno central fuerte. Cuando Thomas Jefferson se convirtió en presidente compró el territorio de Luisiana de Francia, duplicando el tamaño de los Estados Unidos. Una segunda y última guerra con Gran Bretaña se libró en 1812.

Después de un inicio pacífico de los colonos, las guerras contra los franceses al norte obligaron a la creación de cuerpos de ejércitos coloniales, una de las primeras expresiones de identidad nacional. Más tarde, y fomentados por las ideas de los enciclopedistas franceses, vinieron las sublevaciones como el Motín del Té en el puerto de Boston (1773). Las medidas represivas del gobierno inglés provocaron el inicio de la Guerra de Independencia. Los colonos formaron un ejército de milicianos que se pusieron bajo el mando de George Washington, quien tuvo problemas para equipar a sus hombres con armas y municiones, además de que no disponía de una flota para combatir a la del imperio británico, por lo que pidió ayuda a Francia, país que recién salía de la Guerra de los Siete Años y que accedió a ayudar a las colonias británicas en su emancipación.

Animado por la noción de Destino Manifiesto, el territorio federal se expandió hasta el Pacífico. El crecimiento de la población fue rápido, llegando a 7,2 millones en 1810, 32 millones en 1860, 76 millones en 1900, 132 millones en 1940 y 321Millones en 2015. El crecimiento económico en términos de PIB global fue aún más rápido. Sin embargo, en comparación con las potencias europeas, la fuerza militar de la nación era relativamente limitada en tiempos de paz antes de 1940. La expansión fue impulsada por una búsqueda de tierras de bajo costo para los campesinos y propietarios de esclavos. La expansión de la esclavitud fue cada vez más polémica y alimentó las batallas políticas y constitucionales, que se resolvieron mediante compromisos. La esclavitud fue abolida en todos los estados al norte de la línea Mason-Dixon en 1804, pero el Sur continuó beneficiándose de la institución, produciendo exportaciones de algodón de alto valor para alimentar la creciente demanda en Europa. La elección presidencial de 1860 del republicano Abraham Lincoln se apoyó en el programa de terminar la extensión de la esclavitud y de ponerla en una trayectoria a la extinción.

Siete estados del sur profundo que utilizaban esclavos en el cultivo de algodón se separaron y más tarde fundaron la Confederación cuatro meses antes de la toma de posesión de Lincoln. Ninguna nación reconoció a la Confederación, pero ésta inició la guerra atacando Fort Sumter en 1861. Una oleada de ultraje nacionalista en el Norte alimentó una larga e intensa Guerra Civil Americana (1861-1865). Se luchó en gran parte en el sur pues las ventajas abrumadoras del material y de la mano de obra del norte resultaron decisivas en una guerra larga. El resultado de la guerra fue la restauración de la Unión, el empobrecimiento del Sur y la abolición de la esclavitud. En la era de la Reconstrucción (1863-1877), los derechos legales y de voto se extendieron al esclavo liberado. El gobierno nacional emergió mucho más fuerte, y debido a la Decimocuarta Enmienda en 1868, ganó el deber explícito de proteger los derechos individuales. Sin embargo, cuando los demócratas blancos recuperaron su poder en el sur durante la década de 1870, a menudo por la supresión paramilitar de la votación, pasaron las leyes de Jim Crow para mantener la supremacía blanca y las nuevas constituciones marginales que impedían la mayoría de los afroamericanos y muchos blancos pobres votar. Que continuó durante décadas hasta los avances del movimiento de los derechos civiles en los años 60 y la aprobación de la legislación federal para hacer cumplir los derechos constitucionales.

Los Estados Unidos se convirtieron en la principal potencia industrial del mundo a principios del siglo XX debido a una explosión de espíritu emprendedor en el Nordeste y Medio Oeste y la llegada de millones de trabajadores inmigrantes y agricultores de Europa. La red ferroviaria nacional se completó con el trabajo de los inmigrantes chinos y la minería a gran escala y fábricas industrializadas del noreste y medio oeste. El descontento masivo con la corrupción, la ineficiencia y la política tradicional estimuló el movimiento progresista, de los años 1890 a los años 20, que condujo a muchas reformas sociales y políticas. En 1920, la 19ª enmienda a la Constitución garantizaba el sufragio femenino (derecho de voto). Esto siguió a las enmiendas 16 y 17 en 1913, que estableció el primer impuesto sobre la renta nacional y la elección directa de senadores estadounidenses al Congreso. Inicialmente neutral durante la Primera Guerra Mundial, Estados Unidos declaró la guerra a Alemania en 1917 y más tarde financió la victoria aliada el año siguiente.

Después de una próspera década en la década de 1920, el Wall Street Crash de 1929 marcó el inicio de la década de la Gran Depresión mundial. El presidente demócrata, Franklin D. Roosevelt, puso fin al dominio republicano de la Casa Blanca e implementó sus programas de New Deal para alivio, recuperación y reforma. El New Deal, que definía el liberalismo americano moderno, incluía el alivio para los desempleados, el apoyo a los agricultores, la Seguridad Social y un salario mínimo. Después del ataque japonés a Pearl Harbor el 7 de diciembre de 1941, Estados Unidos entró en la Segunda Guerra Mundial junto con Gran Bretaña, la Unión Soviética, China y el menor número de naciones aliadas. Los Estados Unidos financiaron el esfuerzo de guerra aliado y ayudaron a derrotar a la Alemania nazi en el teatro europeo. Su participación culminó en el uso de las armas nucleares recién inventadas en las ciudades japonesas que ayudaron a derrotar al Japón Imperial en el teatro del Pacífico.

Los Estados Unidos y la Unión Soviética emergieron como superpotencias rivales después de la Segunda Guerra Mundial. Durante la Guerra Fría, Estados Unidos y la URSS se enfrentaron indirectamente en la carrera armamentista, la Carrera Espacial, las guerras por poderes y las campañas de propaganda. La política exterior estadounidense durante la Guerra Fría se construyó en torno al apoyo de Europa Occidental y Japón junto con la política de contención, deteniendo la propagación del comunismo. Estados Unidos se unió a las guerras en Corea y Vietnam para tratar de detener su propagación. En la década de 1960, en gran parte debido a la fuerza del movimiento de los derechos civiles, otra ola de reformas sociales fue decretada aplicando los derechos constitucionales del voto y la libertad de movimiento a los afroamericanos ya otras minorías raciales. El activismo de los nativos americanos también aumentó. La Guerra Fría terminó cuando la Unión Soviética se disolvió oficialmente en 1991, dejando a Estados Unidos como la única superpotencia del mundo.

Después de la Guerra Fría, Estados Unidos se centró en los conflictos internacionales alrededor de Oriente Medio en respuesta a la Guerra del Golfo a principios de los años noventa. El comienzo del siglo XXI fue testigo de los atentados del 11 de septiembre por Al-Qaeda en 2001, que luego fueron seguidos por las guerras en Irak y Afganistán. En 2008, los Estados Unidos tuvieron su peor crisis económica desde la Gran Depresión, que ha sido seguida por tasas de crecimiento económico más lentas de lo normal durante los años de 2010.

Los Anasazi eran un conjunto de tribus amerindias de la superárea cultural de Oasisamérica. Ocupaban, en varios grupos, la superficie de los estados actuales de Colorado, Utah, Arizona y Nuevo México. Su civilización ha dejado vestigios monumentales y litúrgicos en distintos lugares, de los cuales dos han sido clasificados como Patrimonio de la humanidad por la Unesco. Los restos arqueológicos demuestran conocimiento de la cerámica, el tejido y la irrigación. Además, dibujaban símbolos que no han sido descifrados y observaban los desplazamientos solares. A partir del año 1400, los anasazi se refugian en el Valle del Río Grande y en el centro de Arizona. Se pierden sus huellas poco antes de la llegada de los españoles. Las razones de este éxodo no son conocidas, sin embargo existen varias hipótesis: un cambio climático que amenazó las cosechas, un medio deteriorado que redujo las tierras cultivables disponibles, sobrepoblación, problemas políticos, guerras. No obstante, dada la ausencia de documentos escritos y la limitación de los conocimientos actuales no es posible probar ninguna de dichas hipótesis.

Los indios de las llanuras incluyen a todas las tribus que habitaban las Grandes Llanuras (la tierra ubicada entre las Montañas Rocosas y el río Misisipi). Fueron cazadores-recolectores la mayor parte de su existencia, pero cuando los exploradores españoles introducen en la región los caballos en el siglo XVII, los indios los consiguen y cambian su modo de vida a una civilización nómada, siguiendo las rutas migratorias de los bisontes americanos. Cuando los blancos invadieron y ocuparon las Grandes Llanuras en el siglo XIX, los indígenas participan en una amarga guerra de resistencia que duró desde 1836 hasta 1918. La combinación de las Guerras Indias y la política del gobierno de Estados Unidos de aniquilar a los bisontes americanos dio lugar a un colapso demográfico dramático en la población de los indios de las llanuras. Al cabo de su derrota, los blancos confinaron al resto de los indios en reservas, donde permanecen hoy en día.

Los inuit son un pueblo indígena que tradicionalmente han habitado la región circumpolar del este de Siberia (Rusia), a través de Alaska (Estados Unidos), Canadá y Groenlandia. La cultura más antigua fue la pre-Dorset, plenamente desarrollada, que data de hace 5000 años. Parece que han evolucionado en Alaska de personas que utilizan el arcaico herramientas de tecnología de la pequeña, que probablemente habían emigrado a Alaska de Siberia, al menos, de 2000 a 3000 años atrás, aunque podrían haber sido en Alaska ya en 10 000 a 12 000 años o más. Hay artefactos similares que se encuentran en Siberia, que se remonta quizás a hace 18 000 años.

Los Indios de los Bosques superpoblados habitaron en los bosques entre el océano Atlántico y el río Misisipi. Estas tribus eran generalmente comunales y vivían en aldeas con chozas de madera y carriles. La recepción de los invasores ingleses se mezcló con hechos resultantes en la guerra y el exterminio, mientras que otros fueron pacíficos. Finalmente, la relación entre los ingleses y los Indios de los Bosques fue de hostilidad permanente, tanto que los franceses, que controlaban el valle del río Misisipi, lo utilizaron para su beneficio. Los franceses mantuvieron una política de comercio y de paz con los Indios de los Bosques y eventualmente formaron una alianza militar con ellos.

La más avanzada de las civilizaciones precolombinas en el territorio que ahora es Estados Unidos fue la Confederación Iroquesa. La Confederación Iroquesa, o las Cinco Naciones, fue una liga o confederación de carácter democrático, con características tanto participativas como representativas (combinadas con algunas hereditarias). Se hallaba constituida por tribus amerindias de lengua iroquesa, que habitaban al noreste de Estados Unidos y al sureste de Canadá en la zona de los Grandes Lagos. La Confederación estaba formada originalmente por cinco tribus (seneca, cayuga, oneida, onondaga y mohawk) que se confederaron a mediados del siglo XII, y a las que se sumó tuscarora en 1720. 

El régimen democrático de la Confederación estaba regulado por una constitución de 117 artículos conocida como la Gran Ley de la Paz y gobernada por un Parlamento o Consejo de representantes de la población, considerado como el tercero más antiguo del mundo luego del Althing de Islandia y las Cortes de León (1188). La Gran Ley de la Paz establecía una especie de Estado de Derecho con estrictos límites y restricciones al poder de los gobernantes. Establecía también una división del poder entre hombres y mujeres, estableciendo que ningún hombre podía presidir un clan y ninguna mujer ser jefe militar o sachem. A las jefas de los clanes correspondía elegir a los jefes militares.
Así la Confederación tuvo una influencia directa tanto en la democracia y el constitucionalismo, como en la idea de la igualdad de mujeres y hombres en la sociedad moderna. En especial Benjamín Franklin, quien tuvo trato directo con Haudenosaunee en 1753, destacó en sus obras que el grado de autonomía individual que gozaban los habitantes de la liga era desconocido en Europa y publicó los tratados indios, considerada como una de sus obras más importantes. Para pensadores o historiadores de los movimientos radicales como Howard Zinn, la Confederación de las Seis naciones consituye una muestra de la aplicación de la democracia radical a través de las decisiones asamblearias.

Se cree que alrededor del año 1000, un grupo de vikingos establecidos en Groenlandia navegaron hacia la costa oriental de América del Norte bajo el mando de Leif Eriksson, arribando a un lugar que llamaron Vinland. En la provincia canadiense de Terranova se han encontrado irrefutables vestigios de una colonia vikinga, en L'Anse aux Meadows. Es probable que los vikingos también visitaran Nueva Escocia y Nueva Inglaterra; sin embargo, no lograron fundar colonias permanentes y pronto perdieron contacto con el nuevo continente.

Cinco siglos más tarde, la necesidad de incrementar el comercio y un error de navegación propiciaron un nuevo encuentro con el continente americano. A finales del siglo XV había en Europa una gran demanda de especias, sedas y tinturas de Asia. Cristóbal Colón creyó erróneamente que podría llegar al Extremo Oriente navegando 6.400 kilómetros hacia el oeste partiendo desde Europa. En 1492 persuadió a los reyes de España para que le financiaran el viaje. Colón navegó hacia occidente pero no llegó a Asia, sino a la isla de Guanahani en el Caribe, el 12 de octubre de 1492. Colón llegó a explorar la mayor parte del área caribeña; jamás alcanzó el Extremo Oriente, pero en cambio regresó a Europa con oro, y en el lapso de 60 años los aventureros españoles habían conquistado un enorme imperio en Centro y Sudamérica. Los españoles también fundaron algunas de las primeras colonias norteamericanas: San Agustín en Florida (1565), Santa Fe en Nuevo México-(1609), y San Diego en California-(1769).

Estados Unidos surgió a partir de la colonización británica de América, protagonizada por oleadas de inmigrantes británicos que fundaron entre los siglos XVII y XVIII Trece Colonias en la costa atlántica del subcontinente norteamericano, al Este de los Apalaches. Estas colonias daban la espalda a las posesiones francesas del Québec y la Luisiana.

Luego de un desarrollo más bien pacífico de los colonos, las guerras contra los franceses al norte obligaron la creación de cuerpos de ejército coloniales, una de las primeras expresiones de identidad nacional. Más tarde, y fomentados por las ideas de los enciclopedistas franceses, vinieron las sublevaciones como el Motín del Té en el puerto de Boston (1773). Las medidas represivas del gobierno inglés provocaron el inicio de la Guerra de Independencia. Los colonos formaron un ejército de milicianos que se pusieron bajo el mando de George Washington, quien tuvo problemas para equipar a sus hombres con armas y municiones, además de no disponer de una flota para combatir a la del imperio británico, así que pidió ayuda a Francia, la cual para desquitarse de la Guerra de los Siete Años accedió a ayudar a las colonias, misma razón que llevó a involucrar a España, que si bien era reticente a firmar un tratado pues en América del Sur tenía sus propias colonias, aportó entre otros un ejército de 7000 hombres.

La revolución estadounidense se inició con las tensiones de menor importancia entre la falta de representación política de los colonos norteaméricos en el parlamento británico y progresivamente se intensificó cuando Gran Bretaña aplicó impuestos a los colonos para saldar la deuda acumulada de la Guerra de los Siete Años. La revolución culminó con la Guerra de la Independencia que dio lugar a la proclamación de los Estados Unidos de América.

La principal causa de este conflicto fue el sentimiento de marginación por parte de los colonos, que aportaban riquezas e impuestos a la metrópoli, impuestos que se incrementaron a partir de 1765, año de imposición de la Ley del Timbre ("Stamp Act"), para sufragar los elevados gastos que a Inglaterra le había supuesto la Guerra de los Siete Años. Las colonias creían injusta su obligación de pagar impuestos a la metrópoli sin tener representación política en el parlamento de Londres. Esta situación hizo que desde mediados del siglo XVIII aumentara la creencia de que no hacía falta la fuerte dependencia de Inglaterra. Los colonos hicieron un llamado al gobierno británico para que permitiese que las colonias tuviesen una representación política en el parlamento, pero estas peticiones les fueron negadas en repetidas ocasiones. "Ningún impuesto sin representación" ("No taxation without representation") se convirtió en el lema de los colonos insatisfechos.

En 1773 se produjo en Boston, el denominado «Motín del Té», que provocó una escalada de las hostilidades entre los ingleses, que cerraron el puerto de la ciudad, y las colonias americanas cuyos representantes reunidos en Filadelfia en 1774 respaldaron a Boston frente a las exigencias de reparación inglesas.

En 1775 comienza oficialmente la guerra de la Independencia. Los colonos organizaron a toda prisa las milicias civiles y se acordó nombrar a George Washington, rico aristócrata, ex teniente y coronel del ejército británico, como su líder. Washington controlaba una enorme cantidad de capital financiero y creía que había sido injustamente acusado por los británicos de fiascos en la guerra franco-india, que a su juicio no fueron culpa suya.

El desarrollo inicial fue claramente de dominio inglés, pero su curso cambiaría cuando tras la Batalla de Saratoga, primera gran victoria estadounidense, Francia y posteriormente España entrasen en guerra apoyando a los independentistas norteamericanos.

En 1783 por la Paz de Versalles, Inglaterra se ve obligada a reconocer la independencia de las 13 colonias británicas, tal y como éstas habían redactado en la famosa Declaración de Independencia de los Estados Unidos de 1776.

Una vez lograda la independencia, resultó muy complicado poner de acuerdo a todas las antiguas colonias sobre si seguían como estados independientes, o se reunían en una sola nación. Tras varios años de negociaciones, en 1787, 55 representantes de las antiguas colonias se reunieron en el Congreso de Filadelfia con el fin de redactar una constitución. Se creaba así un gobierno federal único, con un Presidente de la República y dos Cámaras Legislativas (Congreso y Senado) como solución intermedia. Se redactó también la Constitución de 1787, y se convocó las elecciones de las que George Washington fue elegido primer Presidente de los Estados Unidos bajo la nueva constitución.

Esta constitución estaba inspirada en los principios de igualdad y libertad que defendían los ilustrados y se configuró como la primera carta magna que recogía los principios del liberalismo político, estableciendo un régimen republicano y democrático. La independencia y democracia estadounidense causó un notable impacto en la opinión y la política de Europa.

George Washington gobernó con un estilo federalista. Cuando los agricultores de Pensilvania se negaron a pagar un impuesto federal sobre el licor, Washington movilizó a un ejército de 15.000 hombres para sofocar la "Rebelión del Whisky". Con Alexander Hamilton al frente de la Secretaría de Hacienda, el gobierno federal se hizo cargo de las deudas de cada estado y creó una banca nacional. Estas medidas fiscales fueron concebidas para alentar la inversión y persuadir a la iniciativa privada a que apoyara al nuevo gobierno.

En 1797, a George Washington le sucedió otro federalista, John Adams, quien se vio envuelto en una guerra naval no declarada contra Francia. En una atmósfera de histeria bélica, el Congreso, controlado por los federalistas, aprobó en 1798 las Leyes sobre Extranjeros y Sedición. Estas medidas permitieron la deportación o arresto de extranjeros «peligrosos» y prescribieron multas o prisión por publicar ataques «falsos, escandalosos y maliciosos» contra el gobierno. Diez editores republicanos fueron condenados conforme a la Ley de Sedición, la cual fue duramente denunciada por el abogado virginiano y principal autor de la Declaración de Independencia Thomas Jefferson.

En 1803 la joven nación realiza la compra de Luisiana a Francia y poco tiempo después compra también Florida a España.

En 1807, Gran Bretaña introdujo una serie de restricciones comerciales para impedir el comercio estadounidense con Francia, en respuesta al apoyo estadounidense a Napoleón Bonaparte, con quien Gran Bretaña estaba en guerra. Los Estados Unidos impugnaron estas restricciones como un bloqueo ilegal. El reclutamiento forzoso de ciudadanos estadounidenses en la Marina Real y el apoyo militar de Gran Bretaña a los indios americanos, quienes se oponían a la expansión de la frontera estadounidense en el noroeste, agravó aún más la tensión entre los dos países. Además, Estados Unidos trató de defender el honor nacional de cara a lo que consideró insultos británicos, particularmente el asunto de Chesapeake. Estados Unidos declaró la guerra a Gran Bretaña el 18 de junio de 1812.

Estados Unidos comenzó una invasión total de la colonia británica de Canadá, pero para sorpresa de ellos, el ejército estadounidense fue prácticamente aniquilado en el campo de batalla por las guarniciones locales británicas, siendo repelido de Canadá. Los Estados Unidos respondieron con una segunda ofensiva en el este de Canadá, pero esta invasión también fue derrotada. El gobernador británico de Canadá, George Provost, ordenó una contra-invasión de los Estados Unidos, y los británicos saquearon la ciudad de Detroit y todo el estado de Maine.

Gran Bretaña decidió responder con una estrategia de cinco puntas: Bloqueo de la costa atlántica de los Estados Unidos, invasión de la región de la bahía de Chesapeake, saqueo a Washington, saqueo al principal puerto caribeño de Nueva Orleans, y finalmente invasión del valle del río Misisipi; dicha estrategia se basaba en la enorme superioridad de la Armada británica. Los británicos bloquearon con éxito la costa atlántica e invadieron la región de la bahía de Chesapeake. El ejército estadounidense atacó a los británicos en la batalla de Bladensburg pero fueron derrotados, dejando así un camino de menor resistencia entre la bahía de Chesapeake y Washington. El 24 de agosto de 1814, el ejército británico entró en Washington. El presidente estadounidense, James Madison había ordenado que la ciudad fuese evacuada, por lo que una vez más, los británicos no encontraron resistencia armada. El general británico, George Cockburn, ordenó arrasar la ciudad. La Casa Blanca, el Capitolio de los Estados Unidos, la sede de la Armada, la Biblioteca del Congreso, y el Tesoro de los Estados Unidos fueron quemados.

La derrota y el retorno al colonialismo parecía inevitable para los estadounidenses, pero, de repente, la marea de la guerra comenzó a girar. Dos semanas después del saqueo de Washington, el ejército estadounidense rechazó al ejército británico en la batalla de North Point, obligándolo a retirarse hacia el océano atlántico. Los británicos lanzaron una segunda ofensiva en contra de la ciudad portuaria de Baltimore, pero los estadounidenses rechazaron la invasión con éxito.

El presidente estadounidense, James Madison hizo un llamamiento para la paz y el primer ministro británico, Robert Jenkinson estuvo de acuerdo. En diciembre de 1814, los funcionarios de los dos países se reunieron en Gante, Bélgica y acordaron firmar un tratado de paz que resultó en el reconocimiento del "status quo ante bellum". Sin embargo la noticia del tratado de Gante no llegó a los Estados Unidos en varios meses y, mientras tanto, los británicos lanzaron su asalto final sobre las ciudades portuarias de Nueva Orleans y Mobile. El general estadounidense y futuro presidente, Andrew Jackson, llevó a los estadounidenses a la victoria en la batalla de Nueva Orleans, pero los británicos capturaron con éxito Mobile. Noticias del tratado de paz por fin llegaron a Estados Unidos el 23 de marzo de 1815 y los británicos retiraron todas las tropas de los Estados Unidos y terminaron el bloqueo naval.

Hoy en día, la guerra sigue siendo objeto de acalorado debate entre los estadounidenses, británicos y canadienses, con cada uno de los tres pueblos proclamando la victoria.

Después de esta segunda guerra, Estados Unidos gozó de un período de rápida expansión económica, sobre todo a partir de la colonización y expansión hacia el Oeste. Ya a fines del siglo XVIII se había iniciado el avance imparable de los colonos, bien desde los trece estados originales (las antiguas trece colonias que están representadas en las trece barras de la bandera estadounidense) o directamente desde el continente europeo. Por lo general, se trataba de emigrantes anglosajones (irlandeses, escoceses, ingleses y galeses) y de otros países de la Europa Central y Occidental (principalmente alemanes). Muchos de estos inmigrantes viajaban desde Nueva York y Filadelfia hacia la parte oriental del estado de Pensilvania, donde se construían en el hoy conocido como "Dutch Country" las carretas de gran tamaño tiradas por mulas que se conocían como «Conestoga Wagons» ('carretas Conestoga').

Las inacabables caravanas de estas carretas fueron los verdaderos motores de la ocupación progresiva del continente hacia el oeste. Sin embargo, no se trató de la ocupación de áreas «pioneras» (es decir, áreas deshabitadas que podían destinarse a la ocupación sistemática con fines agropecuarios), ya que gran parte del territorio estaba previamente ocupado por pueblos originarios, colonos franceses procedentes del Canadá francés, así como todas las ciudades fundadas por los españoles antes en los territorios de Arizona, Texas, Colorado, Nuevo México, Utah, Nevada y California, ciudades que ya habían crecido, incluso, antes de la expedición de los peregrinos en 1620 que dio origen a la formación de las colonias inglesas en el siglo XVII. Así pues, ciudades como Detroit, Dubuque, Saint Louis, Nueva Orleans, Baton Rouge, Des Moines, Louisville y muchas otras, ya habían sido fundadas por los franceses bastantes años antes de esa especie de estampida hacia el oeste, y lo mismo podía decirse de las ciudades fundadas por los españoles que procedían de México, como Socorro, San Antonio, Albuquerque, Santa Fe, El Paso, San Diego, San Bernardino, Los Ángeles, San Francisco, etc. que se habían fundado durante los siglos XVI y XVII.

Toda esta expansión hacia el Lejano Oeste ("Far West") se vio dinamizada por dos hechos muy importantes: el descubrimiento de oro en California (1848) y la culminación de la red ferroviaria con la primera línea transcontinental en 1869 (el primer ferrocarril de vapor se había inaugurado en Baltimore (Maryland), en 1830). Una red nacional de carreteras y canales recorría el país, buques de vapor surcaban los ríos, y la Revolución industrial había llegado a Estados Unidos: la región de Nueva Inglaterra contaba con fábricas de textiles y Pensilvania con fundiciones de hierro. Para la década de 1850 había fábricas que producían artículos de hule, máquinas de coser, zapatos, ropa, equipos agrícolas, pistolas, relojes, etc.

Entre las décadas de 1820 y 1830, después de la proclamación de la Doctrina Monroe de expansión territorial hacia el Pacífico, miles de colonos estadounidenses se establecieron en las comunidades anglosajonas de Texas (entonces territorio mexicano). En aquel momento el gobierno mexicano se encontraba en una mala situación económica al término de una guerra de independencia con España que duró más de una década, y dio la bienvenida a los colonos. El gobierno mexicano obtuvo fondos vendiendo tierras a estos colonos que prefirieron mudarse a territorio mexicano en vez de pagar altos precios en Luisiana y otros estados del sur. Estos colonos esperaban, además, que Estados Unidos comprara Texas para proveer de más tierra a sus nuevos ciudadanos.

En 1820 un empresario de Misuri, Moses Austin, había negociado con España para que se le permitiera llevar 300 colonos a Texas. Stephen Austin, el hijo (conocido como el padre de la República de Texas), siguió estos planes con el nuevo gobierno mexicano, escogiendo colonos que fueran buenos trabajadores y que pudieran ser leales al gobierno mexicano. El gobierno mexicano, que había abolido la esclavitud, toleró que los colonos trajeran sus esclavos para trabajar las tierras y venderlos a otros colonos pero se listaban como «sirvientes contratados» ("indentured servants" en inglés). Problemas con el nuevo gobierno del presidente Antonio López de Santa Anna causaron que los colonos se levantaran en armas y lucharan, con el franco apoyo del «Norte», para obtener la independencia, ya que para entonces los colonos anglosajones eran más numerosos que los colonos mexicanos. Después de la guerra (1836), Texas se estableció como una república independiente, pero casi inmediatamente buscó su anexión a los Estados Unidos, que obtuvo algunos años después.

La Guerra Mexicano-Americana (1846-48) estalló con los Whigs opuestos a la guerra, y los Demócratas apoyando la guerra. El ejército de los Estados Unidos, utilizando regulares y un gran número de voluntarios, derrotó a los ejércitos mexicanos, invadió en varios puntos, capturó Ciudad de México y ganó decisivamente. El tratado de Guadalupe Hidalgo puso fin a la guerra en 1848. Muchos demócratas quisieron anexionar a todo México, pero esa idea fue rechazada por los sureños que argumentaron que al incorporar a millones de mexicanos, principalmente de raza mixta, socavaría a los Estados Unidos como un país exclusivamente República blanca. [96] En cambio, los Estados Unidos tomaron Texas y las partes norteñas ligeramente asentadas (California y Nuevo México). Los residentes hispanos recibieron plena ciudadanía y los indios mexicanos se convirtieron en indios americanos. Simultáneamente, el oro fue descubierto en California en 1849, atrayendo a más de 100,000 hombres al norte de California en cuestión de meses en la fiebre del oro de California. Un compromiso pacífico con Gran Bretaña dio a los Estados Unidos la propiedad del País de Oregon, que fue renombrado el Territorio de Oregon. [95]

En 1846 Estados Unidos incursiona en el norte de México en una zona texana en disputa, donde las tropas son atacadas y como consecuencia en 1847 Estados Unidos le declara la guerra a México, venciéndole. Por el Tratado de Guadalupe-Hidalgo (1848) adquiere además de la zona en disputa, los territorios mexicanos de Alta California y Nuevo México que hoy actualmente conforman los estados de Arizona, California, Nevada, Nuevo México, Utah, y partes de Oregón, Colorado y Wyoming.

Desde su nacimiento, Estados Unidos se convirtió en el más importante comprador de esclavos para satisfacer la demanda de mano de obra en las pesadas labores agrícolas. La esclavitud se extendió entre los estados sureños que practicaban principalmente la agricultura y a la postre se convirtieron en los estados secesionistas.

La Isla de Gorea, ubicada a unos cuantos kilómetros frente a la costa de Senegal, en el océano Atlántico, fue el lugar desde donde se organizó el tráfico de esclavos hacia Estados Unidos de América, que durante los siglos XVII, XVIII y hasta la abolición de la esclavitud, en el siglo XIX, desplazó a más de 20 millones de personas de África.

En 1858, cuando el senador Douglas buscó la reelección, fue desafiado por Abraham Lincoln y el Partido Republicano (un nuevo partido en contra de la esclavitud, y que nada tenía que ver con el Partido Republicano de Jefferson). En una serie de debates históricos con Douglas, Lincoln exigió un alto a la expansión de la esclavitud. Estaba dispuesto a tolerarla en los estados del sur, pero al mismo tiempo afirmó que «"este gobierno no puede subsistir permanentemente siendo mitad esclavo y mitad libre"».

La mayoría en los estados sureños y fronterizos votaron contra Lincoln, pero el norte lo apoyó y ganó las elecciones. Unas semanas después, Carolina del Sur decidió mediante votación abandonar la Unión. Pronto se le unieron Misisipi, Florida, Alabama, Georgia, Luisiana, Texas, Virginia, Arkansas, Tennessee y Carolina del Norte. Estos estados proclamaron su independencia de la Unión con el nombre de Estados Confederados de América y así empezó la Guerra civil.. La Guerra civil fue el episodio más traumático de la historia de los Estados Unidos. Las cicatrices no se han cerrado por completo hasta el día de hoy.

Con excepción de la compra de Alaska a Rusia en 1867, la expansión territorial de Estados Unidos se había detenido en 1848. No obstante, alrededor de 1890, al tiempo que muchas naciones europeas expandían sus imperios coloniales, un nuevo espíritu animó la política exterior estadounidense, la cual en gran medida seguía las pautas de la Europa septentrional. Los políticos, los directores de periódicos y los misioneros protestantes declararon que la «raza anglosajona» tenía el deber de llevar los beneficios de la civilización occidental a los pueblos de Asia, África y América Latina. En el punto culminante de este período (1895), Cuba se sublevó contra el colonialismo de España, dando lugar en 1898 la Guerra Hispano-Estadounidense; la lucha fue desigual ya que España no contaba con todo el potencial de armamento que si tenía Estados Unidos

Después de la Guerra Hispano-Estadounidense de 1898, Estados Unidos de América se apoderó también de Cuba, Puerto Rico, Filipinas y Guam. En el archipiélago asiático, sostuvo una terrible guerra, conocida como Guerra Filipino-Estadounidense, que asoló el archipiélago asiático. Ese mismo año los Estados Unidos de América, tras promulgar una constitución al estilo estadounidense y abolir la monarquía hawaiana, decidió la anexión de Hawái en 1898. El territorio no obtendría la categoría de estado hasta 1959.

En abril de 1917 el presidente Woodrow Wilson pidió al Congreso una declaración de guerra; de esta manera los Estados Unidos tomaron parte de la Primera Guerra Mundial. Para Wilson la guerra constituiría una gran cruzada en pro de la paz mundial y la autodeterminación nacional. «"El mundo debe convertirse en un lugar seguro para la democracia"», declaró Wilson cuando Estados Unidos entró en «"la guerra que pondrá fin a todas las guerras"».

Cuando se declaró la guerra, el ejército de los Estados Unidos era una pequeña fuerza de 200.000 soldados. Millones de hombres tuvieron que ser reclutados, adiestrados, equipados y enviados a Europa a través de un océano infestado de submarinos. Transcurrió un año hasta que el ejército de Estados Unidos estuvo listo para contribuir de manera significativa al esfuerzo bélico de los aliados.

En 1919, Wilson viajó a Europa para redactar eI tratado de paz. Fue acogido por muchedumbres jubilosas en las capitales de los países aliados, pero la bienvenida se agrió cuando las negociaciones comenzaron en Versalles. Pese a las protestas de Wilson, los aliados impusieron sanciones aplastantes a Alemania y se repartieron sus colonias. Wilson logró establecer la Sociedad de Naciones, pero muchos estadounidenses temían que dicha organización mundial arrastrara a Estados Unidos a otra guerra extranjera. Un grupo de senadores republicanos impuso restricciones al Tratado de Versalles: aceptarían la Liga de Naciones sólo con el entendimiento de que el Congreso, no la Liga, retendría el control de las fuerzas armadas estadounidenses. Inglaterra y Francia no objetaron esa restricción, pero Wilson porfiadamente se negó a modificar el tratado. El Presidente y el Congreso no lograron superar su desacuerdo respecto a esta cuestión. Estados Unidos nunca ratificó el Tratado de Versalles ni pasó a formar parte de la Liga de Naciones.

La mayoría de los estadounidenses no lamentaron el fracaso del tratado, ya que se habían desilusionado con los resultados de la guerra. Después de 1920, Estados Unidos volvió la mirada hacia adentro y se retiró de los asuntos europeos.

El 24 de octubre de 1929, el denominado «Jueves Negro», una oleada de ventas de acciones provocada por el pánico originó un crack en la Bolsa de Valores de Nueva York. Una vez iniciado, el derrumbe en los precios de las acciones y de otros valores no pudo detenerse. Hacia 1932, miles de bancos y más de 100.000 sociedades mercantiles habían quebrado. La producción industrial se redujo a la mitad, el ingreso agrícola decayó en más del 50%, los salarios bajaron un 60%, la inversión nueva se redujo un 90%, y uno de cada cuatro trabajadores estaba desempleado.

En 1933 asume la presidencia el demócrata Franklin D. Roosevelt, quien salvaría al país de la quiebra económica.

En el Extremo Oriente las fuerzas japonesas habían invadido Manchuria (1931), China (1937) e Indochina francesa (julio de 1941). Roosevelt respondió a esta agresión prohibiendo las exportaciones de chatarra, acero y petróleo a Japón y congelando los créditos japoneses en Estados Unidos.

Para noviembre de 1941 los planificadores militares de Estados Unidos se preparaban para un asalto japonés, pero esperaban un ataque al sur, hacia las Indias Orientales Holandesas (actual Indonesia) ricas en petróleo. En vez de ello, bombarderos japoneses estacionados en seis portaaviones de una flota atacaron la base naval de Pearl Harbor en Hawái. El sorpresivo ataque hundió o averió ocho barcos de guerra y destruyó casi 200 aviones. Estados Unidos inmediatamente declaró la guerra a Japón. Cuatro días después Alemania e Italia, aliadas de Japón, declararon la guerra a Estados Unidos.

El 8 de mayo de 1942 la amenaza japonesa contra Australia fue detenida en la batalla del Mar del Coral. En junio la principal flota japonesa, que navegaba rumbo a Hawái, fue rechazada en la batalla de Midway, con una pérdida de cuatro portaaviones. Los criptógrafos estadounidenses eran expertos en descifrar las claves japonesas, así que los aliados generalmente conocían la disposición de la marina de guerra japonesa.

A lo largo de los tres años siguientes las fuerzas de Estados Unidos avanzaron hacia Japón «saltando entre islas», es decir, tomando algunas islas estratégicas en el Pacífico y pasando por alto otras. Una fuerza aliada bajo el mando del general Joseph W. Stillwell ayudó a los chinos, y las tropas comandadas por el general Douglas MacArthur regresaron a las Filipinas en octubre de 1944. La isla de Iwo Jima, en el Pacífico central, cayó en manos de Estados Unidos en marzo, y Okinawa en junio de 1945. Desde estas dos islas los bombarderos B-29 lanzaron ataques devastadores contra las ciudades japonesas.

Las fuerzas estadounidenses se prepararon en seguida para invadir las islas japonesas. Con la esperanza de llevar la guerra a un rápido fin, el presidente Harry Truman ordenó usar la bomba atómica contra Hiroshima (6 de agosto) y Nagasaki (9 de agosto). Japón se rindió el 14 de agosto. Casi 200.000 civiles murieron en los ataques nucleares.

Después de la guerra se crearon rápidamente tensiones entre los Estados Unidos y la Unión Soviética, lo que más tarde se conocería como la Guerra Fría.

Tras la Segunda Guerra Mundial, Corea fue dividida en dos estados, Corea del Norte y Corea del Sur, controlados por gobiernos comunistas y pro-occidentales respectivamente a lo largo del paralelo 38. Estos dos estados no tardaron en entrar en guerra, siendo apoyados por las grandes potencias sin reservas.

En este momento, se decide no usar armas atómicas en conflictos localizados, para evitar las repercusiones que tendría esta acción en la política global. Durante la guerra de Corea, las tropas estadounidenses entraron en combate directo con las chinas, que habían acudido a socorrer a la República Democrática Popular de Corea.

Tras tres años de lucha, la guerra quedó en tablas, con las fronteras prácticamente en los mismos lugares de antes de la guerra.

En 1953 Dwight D. Eisenhower, un ex militar, es elegido como presidente de los Estados Unidos. Este presidente se destacaría por fomentar e impulsar el uso de la inteligencia y las acciones encubiertas, así como por el desarrollo del avión espía U-2 que tanto aportaría al fin de la Guerra Fría.

La injerencia estadounidense en Vietnam se remonta al presidente Truman, quien ya durante la Segunda Guerra Mundial envió ayuda militar a Francia en apoyo al colonialismo francés en Indochina.

Después de retirarse los franceses del sureste de Asia en 1954, el presidente Eisenhower envió asesores y ayuda estadounidenses para contribuir al establecimiento de un gobierno democrático y pro-occidental en Vietnam del Sur, cosa que se conseguiría en 1956 instalando al general Ngo Dinh Diem en el poder.

En 1957 la URSS lanza el primer satélite artificial, llamado Sputnik, causando un gran revuelo en las opiniones públicas mundiales. Estados Unidos tratará de arrebatar a la Unión Soviética el liderazgo obtenido con este éxito formando en 1958 la NASA.

En 1959, Fidel Castro se alza como líder de una Revolución que llevará en poco tiempo a Cuba a convertirse en el primer gobierno comunista del hemisferio occidental. El presidente Eisenhower no iba a permitir la creación de un estado comunista a 150 km de las costas estadounidenses, de modo que la CIA comenzó a planear una operación para derrotar a Castro.

En 1960, las relaciones entre los Estados Unidos y la URSS empeoran aún más si cabe al ser derribado un avión espía U-2 estadounidense que sobrevolaba el espacio aéreo soviético. Este incidente terminó con la conferencia de París, acabando de momento con las iniciativas encaminadas a lo que años más tarde se conocería como distensión.

En el año siguiente, 1961, John F. Kennedy es elegido presidente. Su elección despierta aún hoy grandes pasiones, al ser el presidente más joven de la historia de los Estados Unidos, y el único católico. El mismo año de su elección, Kennedy se enfrentará a las crisis de Bahía de Cochinos y de Berlín.

Kennedy había heredado del anterior presidente un plan de la CIA para derrocar al gobierno de Fidel Castro, que consistía en organizar y dar apoyo a grupos de exiliados cubanos, esperando que si se producía una invasión, el pueblo de las ciudades cubanas se alzaría contra Castro.

Los miedos de Kennedy a la respuesta soviética hicieron que la operación fuese de bastante menor envergadura que lo previsto inicialmente, por lo que el 15 de abril de 1961, el grupo de exiliados cubanos fracasó en su intento de tomar Bahía de Cochinos, saliendo Fidel Castro muy reforzado tanto en su propio país como ante la opinión pública mundial.

La gran corriente migratoria que se había establecido huyendo de Alemania Oriental hacia la República Federal de Alemania decidió a las autoridades orientales a construir un muro de separación entre ambos sectores de la ciudad de Berlín en agosto de 1961. El incidente del Checkpoint Charlie en que tanques estadounidenses y soviéticos se encontraron frente a frente, hizo saltar las alarmas cuando los soviéticos amenazaron con defenderse con armas atómicas.

También en 1961 los primeros asesores e instructores militares estadounidenses (un total de 900) aterrizan en Saigón, capital de Vietnam del Sur.

Tras la fracasada operación de Bahía de Cochinos, el régimen cubano se sentía muy vulnerable frente al gigante estadounidense, de modo que buscó ayuda militar en la URSS. Ésta respondió instalando en octubre de 1962 baterías de misiles balísticos en Cuba, capaces de alcanzar en pocos minutos las principales ciudades estadounidenses. Así comenzaría la Crisis de los Misiles Cubanos, el episodio de la Guerra Fría en que ésta estuvo más cerca que nunca en convertirse en «caliente».

Tras la crisis de los misiles cubanos, se instaura el Teléfono Rojo por el cual se establecía un enlace de comunicación directo entre Washington y Moscú para evitar situaciones similares en un futuro.

El 22 de noviembre de 1963, durante un desfile en Dallas John Fitzgerald Kennedy es asesinado, supuestamente por Lee Harvey Oswald, aunque la duda sobre la autoría ha seguido en ciertos círculos hasta el día de hoy.

Después del asesinato del Presidente Kennedy, el Presidente Johnson se enfrentó a fuertes desafíos por parte de dos demócratas opuestos a la Guerra de Vietnam: los senadores Eugene McCarthy y Robert F. Kennedy, este último hermano del Presidente John F. Kennedy. El 31 de mayo de 1968, en vista de una humillante derrota en las encuestas de opinión pública y de la incesante prolongación del conflicto en Vietnam, Johnson se retiró de la contienda presidencial y ofreció negociar el fin de la guerra. En 1968, tras la renuncia de Johnson a las aspiraciones de su reelección, el partido Demócrata depositó todas sus esperanzas en el carismático senador Robert F. Kennedy, que se presentó como candidato y tenía inmejorables posibilidades de llegar a la Casa Blanca por encima de los demás precandidatos de su propio partido político e incluso su presunto rival republicano Richard Nixon.

Poco después de celebrar el triunfo de las elecciones primarias de California que lo aseguraba su nominación por los demócratas, Robert F. Kennedy sufrió un atentado perpetrado por un inmigrante palestino, Shiran Shiran, que lo hizo caer mortalmente herido en un hotel de Los Ángeles y muere al día siguiente, el 6 de junio de 1968. Al menos por ahora no se sabe quien estuvo detrás del asesino y se supone que hubo un complot organizado por la mafia que utilizó a ese hombre árabe para cumplir esa oscura misión.

El 20 de julio de 1969, el programa espacial de los Estados Unidos logra un gran éxito técnico y propagandístico al conseguir mandar un astronauta estadounidense a la luna y traerlo de vuelta sano y salvo a la Tierra.

Después de la Guerra de Vietnam y del escándalo Watergate, muchos estadounidenses se habían desilusionado de los hombres que los gobernaban y les habían perdido la confianza. Gerald Ford, el presidente republicano que ascendió al poder tras la renuncia de Richard Nixon, hizo mucho para restaurar la confianza de los ciudadanos, aunque algunos votantes nunca le perdonaron que hubiera indultado a su ex jefe, Richard Nixon.

En 2 de agosto de 1990, Irak invadió a Kuwait. Apenas se tuvo noticia de la invasión de Kuwait, el Consejo de Seguridad de las Naciones Unidas condenó este acto a través de una serie de resoluciones, de la misma forma que lo hizo la Liga Árabe. Los dictámenes fueron: Resolución Nº 660, que condenó el ataque e invasión iraquí; luego siguieron varias más entre las que se contaban las resoluciones Nº 661 del 6 de agosto de 1990, que imponía sanciones económicas; la Nº 665 del 25 de agosto, acerca del embargo marítimo; la Nº 670 del 25 de septiembre acerca del bloqueo aéreo, y finalmente, la que autorizaba el empleo de la fuerza o resolución Nº 678 del 29 de noviembre. Esta última exigió a Irak que saliera de Kuwait antes del 15 de enero de 1991. Si se cumplía el plazo y no había respuesta favorable, todos los países participantes podrían poner en práctica la resolución Nº 660 y atacar a Irak. Finalmente, EEUU organizó y lideró una coalición militar con fuerzas militares de Asia, Europa, África, y Medio Oriente.

En la mañana del 11 de septiembre de 2001, dos de los cuatro aviones secuestrados por Al-Qaeda impactaron en las dos torres del World Trade Center en Nueva York, el tercero en el Pentágono, causando la muerte a más de 3.000 personas, convirtiéndose en el peor atentado terrorista en la historia estadounidense (actualmente se discute sobre los hechos del atentado). Tras esto, Estados Unidos declaró su lucha contra el terrorismo, iniciando una invasión a Afganistán con el propósito de derrocar el régimen talibán y sus conexiones terroristas, lográndolo en menos de un mes iniciado el conflicto. Más tarde, argumentando la existencia de armas de destrucción masiva —las cuales hasta la fecha no han sido encontradas o no existieron— comenzó una invasión a Iraq. También se recortaron la libertades publica en EE UU. y se aprobaron la USA Patriot Act. El presidente de la Comisión de Derechos Humanos del Colegio de Abogados, Irma Lozada, sostuvo que la secuela del Patriot Act atenta contra la democracia. "Se trata del fin de la democracia tal y como la conocemos", sentenció. "11s ha dado un cheque en blanco al gobierno federal, para dar al traste con todo lo que los padres fundadores intentaron a fines del siglo 18 con las enmiendas a las constituciones, en cuanto a los derechos humanos y constitucionales de libertad de expresión, reunión, asamblea, organización, y de requerir del gobierno información sobre sus actos y pedir desagravios"", según él. Lozada sostuvo que la propuesta fortalece los poderes de las agencias de seguridad de detener sin garantías constitucionales a sospechosos, como en el caso del puertorriqueño José Padilla y los presuntos miembros de la red Al-Qaeda detenidos en Guantánamo.

El licenciado opinó que se establecería en Estados Unidos, y por ende en Puerto Rico, una nueva versión del macartismo, término que nació en los años 50 con la campaña de persecución contra el comunismo. "Van a perseguir a los patriotas e izquierda puertorriqueña, a toda persona que proponga por ejemplo la paz. Se justifica toda persecución contra el disidente. Es una redefinición del macartismo para el siglo 21, una revisita al mundo tenebroso de persecución contra todo lo que sea ideas nuevas o promueva posiciones contrarias al militarismo y al imperialismo estadounidense". El abogado constitucionalista, Alejandro Torres, añadió que la medida otorga una base legal a las autoridades federales para perseguir y reprimir sectores políticos disidentes. Lo mismo que antes se catalogaba como subversivo o acciones armadas de grupos independentistas, ahora le van a poner el mote de terrorismo doméstico. Con la histeria que hay uno debería esperar mayores mecanismos de control, persecución y representación contra el independentismo.

A pocas semanas de comenzar la acción militar en Irak, Saddam Hussein que en ese momento ejercía como jefe de estado, escapó y se escondió en la zona montañosa del sur iraquí. Posteriormente fue encontrado en una pequeña cueva excavada en el suelo de donde fue rescatado enfermo y hecho prisionero, siendo juzgado por su actuación represiva (y hasta ejecuciones masivas) ante la propia población de Iraq, especialmente, por motivos religiosos y políticos. Saddam Hussein fue ejecutado la madrugada del 30 de diciembre de 2006. Las victorias en Afganistán e Irak fueron logradas gracias a la superioridad tecnológica y militar estadounidense. Actualmente, la ocupación en esos países se encuentra jaqueada por la insurgencia y un profundo rechazo de la población hacia el ejército estadounidense, objeto de denuncias, probadas a través de vídeos que muestran torturas a ciudadanos iraquíes, por violación de los derechos humanos. Debido, parcialmente, a ello, en las elecciones legislativas de 2006 el presidente Republicano Bush perdió el control de la cámara de Representantes frente al partido Demócrata.

Desde 2004 la carrera del senador Barack Obama fue meteórica. Sus promesas de cambio y su famoso lema "Yes, we can " le dieron fama mundial y le llevarían a la Casa Blanca, tras ganar con una ventaja considerable las elecciones de 2008, convirtiéndose en uno de los presidentes de Estados Unidos que más fuerza consiguió en las urnas. El candidato demócrata Obama tuvo que afrontar la crisis financiera de 2008, la tensión con Irán, la resolución de las guerras de Irak y Afganistán y los problemas del medio ambiente. También, Barack Obama tuvo entre los objetivos que alcanzó relativamente la mejora de la política exterior con Europa y el diálogo con todos los gobiernos del mundo.




</doc>
<doc id="15504" url="https://es.wikipedia.org/wiki?curid=15504" title="Escultura de Italia">
Escultura de Italia

Las esculturas etruscas son principalmente en terracota o bronce.
Modelaron las figuras de los muertos, que aparecían recostados sobre los sarcófagos.
Con la escultura etrusca apareció el retrato realista, saliendo del idealismo del arte griego.

Tiene cierta semejanza con la primitiva escultura griega y cierta influencia mesopotámica.

Las principales obras de este período son:
La Quimera de Arezzo, la Loba capitolina, el Apolo de Veyes entre otras.

La escultura romana no tuvo un estilo propio hasta pasado cierto tiempo.

Sus primeras influencias fueron los etruscos. Más adelante, según aumentaba el territorio romano y avanzaban las conquistas, grandes cantidades de esculturas griegas llegaron a Roma como botín de guerra y también llegaron los escultores griegos. Realizaron de estas esculturas miles de copias que adornarían los jardines y los edificios públicos romanos.
De los etruscos heredaron el realismo de las imágenes de cera que realizaban a sus difuntos, de los griegos el idealismo. De época republicana destacan los retratos de Julio César, Cicerón y Pompeyo.
El idealismo griego se puede apreciar en las obras del principio del imperio (s.I a.c) como el Augusto de Prima Porta, o los retratos de Calígula y Tiberio.

Posterormente la época de los flavios y durante la anarquía militar del s. III d.c predominó la corriente más propia del realismo. Durante el reinado de los Antoninos el retrato tiende al barroquismo. Muestra de ello son los retratos de Cómodo, Antonio Pío y la Estatua ecuestre de Marco Aurelio.

En Roma también se esculpieron relieves, las influencias fueron las mismas, siendo el realismo una tendencia más popular y el idealismo más aristocrático. En los relieves, los artistas romanos hicieron uso de recursos pictóricos como las perspectivas. Y detalles anecdóticos.
La influencia más clara de Grecia se aprecia en los relieves del Ara Pacis de Augusto, esta tendencia idealista se fue perdiendo con el tiempo, aunque se mantiene en la Columna de Trajano o el Arco de Tito, pero es más débil en la Columna de Marco Aurelio en que sus relieves representan el horror de la guerra.

Las obras más destacadas de la escultura bizantina son las labores ornamentales de los capiteles con motivos vegetales y animales afrontados, como son los de San Vital de Rávena o los sarcófagos de la misma ciudad, en los que se representan los temas del Buen Pastor.

Pero las obras capitales de la escultura bizantina son las pequeñas obras, dípticos y cajas talladas en marfil, destacando el díptico Barberini, Museo del Louvre, del siglo V, o la célebre Cátedra del Obispo Maximiano, en Rávena, tallada hacia el año 533 sobre placas de marfil con minucioso trabajo.

Durante el románico, en el resto de Europa la escultura estuvo subordinada a la arquitectura, siendo una simple ornamentación, principalmente en las puertas de las iglesias y catedrales.
Pero en la mayor parte del territorio italiano, la decoración escultórica no existía, en el arte románico particular italiano se le dio más importancia al color, por lo que la decoración de las fachads no era esculpida si no que era pintada o utilizaba mármoles de diferentes colores.
Pero en general el románico italiano, al igual que el gótico fue más clasicista que en el resto de Europa.

La escultura gótica italiana se desarrolla principalmente en la Toscana y el norte de la península.
Son los lugares donde Nicola Pisano esculpió los relieves del púlpito del baptisterio de la Catedral de Pisa y de la Catedral de Siena.
Nicola Pisano tuvo una tendencia marcadamente clasicista que prácticamente se anticipa al renacimiento.
Por otro lado, su hijo Giovanni está más influido por la corriente internacional, tomando características propias del gótico francés como del alemán.

Finalmente con Lorenzo Ghiberti termina el gótico, conserva ciertos rasgos de la escultura gótica aunque volviendo en cierto modo al clasicismo lo que conducirá al renacimiento.




</doc>
<doc id="15505" url="https://es.wikipedia.org/wiki?curid=15505" title="Beckmannia">
Beckmannia

Beckmannia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del Norte de Eurasia y América del Norte. 
El género fue descrito por Nicolaus Thomas Host y publicado en "Icones et Descriptiones Graminum Austriacorum" 3: 5. 1805. La especie tipo es: "Beckmannia eruciformis" (L.) Host 
Beckmannia: nombre genérico que fue nombrado en honor de Johann Beckmann.

El número cromosómico básico del género es x = 7, con números cromosómicos somáticos de 2n = 14 (generalmente), o 16. 2 ploide. Cromosomas relativamente «grandes». 



</doc>
<doc id="15507" url="https://es.wikipedia.org/wiki?curid=15507" title="Sputnik 1">
Sputnik 1

El lanzado el 4 de octubre de 1957 por la Unión Soviética fue el primer satélite artificial de la historia.

El Sputnik 1 fue el primero de varios satélites lanzados por la Unión Soviética en su programa Sputnik, la mayoría de ellos con éxito. Le siguió el Sputnik 2, como el segundo satélite en órbita y también el primero en llevar a un animal a bordo, una perra llamada Laika. El primer fracaso lo sufrió el Sputnik 3.

La nave Sputnik 1 fue el primer intento no fallido de poner en órbita un satélite artificial alrededor de la Tierra. Se lanzó desde el Cosmódromo de Baikonur en Tyuratam, 370 km al suroeste de la pequeña ciudad de Baikonur, en Kazajistán (antes parte de la Unión Soviética). La palabra "sputnik" en ruso significa "compañero de viaje" ("satélite" en astronáutica). El nombre oficial completo, se traduce sin embargo como "Satélite Artificial Terrestre" (ISZ por sus siglas en ruso).

El Sputnik 1 fue el primero de una serie de cuatro satélites que formaron parte del programa Sputnik de la antigua Unión Soviética y se planeó como una contribución al Año Geofísico Internacional (1957-1958), establecido por Organización de las Naciones Unidas. Tres de estos satélites (Sputnik 1, Sputnik 2 y Sputnik 3) alcanzaron la órbita terrestre. El Sputnik 1 se lanzó con el vehículo de lanzamiento R-7 y se incineró durante su reentrada el 4 de enero de 1958.

La secuencia real de toma de decisiones en lo que respecta a la forma del Sputnik 1 fue enrevesada. Inicialmente el Académico Mstislav Kéldysh ideó un satélite de 1,5 t en forma de cono, con la capacidad de hacer muchas mediciones físicas en el espacio, pero cuando los soviéticos leyeron que el proyecto estadounidense Vanguard tenía diseñados, y planeados dos satélites, uno pequeño tan sólo para ver si podían poner algo en órbita, los rusos decidieron hacer lo mismo, realizando lo que se traduce como "el satélite más simple", que tenía un centímetro más de diámetro y era bastante más pesado que el Vanguard. Ellos tuvieron que ver si las condiciones en órbita terrestre baja podían permitir a un satélite mayor permanecer allí durante el tiempo necesario. Cuatro meses después del lanzamiento del Sputnik 1, fue puesto en órbita el satélite de prueba Vanguard, Jruschev lo ridiculizó comparándolo con un "pomelo". Una vez que los soviéticos descubrieron que también podían poner en órbita satélites de prueba, pensaron en poner en órbita el satélite y laboratorio espacial Keldysh como Sputnik 3, haciéndolo tras un primer lanzamiento fallido.

El Sputnik 1 tenía una masa aproximada de 83 kg, contaba con dos transmisores de radio (20,007 y 40,002 MHz) y orbitó la Tierra a una distancia de entre 938 km en su apogeo y 214 km, en su perigeo. El análisis de las señales de radio se usó para obtener información sobre la concentración de los electrones en la ionosfera. La temperatura y la presión se codificaron en la duración de los pitidos de radio que emitía, indicando que el satélite no había sido perforado por un meteorito.

El satélite artificial Sputnik 1 era una esfera de aluminio de 58 cm de diámetro que llevaba cuatro largas y finas antenas de 2,4 a 2,9 m de longitud. Las antenas parecían largos bigotes señalando hacia un lado. La nave obtuvo información perteneciente a la densidad de las capas altas de la atmósfera y la propagación de ondas de radio en la ionosfera. Los instrumentos y fuentes de energía eléctrica estaban alojadas en una cápsula que también incluía transmisores de radio operando a 20,007 y 40,002 MHz. (alrededor de 15 y 7,5 m en longitud de onda), las emisiones se realizaron en grupos alternativos de 0,3 s de duración. El envío a tierra de la telemetría incluía datos de temperatura dentro y sobre la superficie de la esfera.

Debido a que la esfera estaba llena de nitrógeno a presión, el Sputnik 1 dispuso de la primera oportunidad de detectar meteoritos, aunque no detectó ninguno. Una pérdida de presión en su interior, debido a la penetración de la superficie exterior, se habría reflejado en los datos de temperatura.

El Sputnik 1 fue el primero de una serie de cuatro satélites que formaron parte del programa Sputnik de la antigua Unión Soviética y se planeó como una contribución al Año Geofísico Internacional, establecido por Organización de las Naciones Unidas. Lanzado desde el Cosmódromo de Baikonur en Kazajistán, antes parte de la Unión Soviética. El Sputnik 1 se lanzó en un cohete R-7 y se incineró durante su reentrada el 4 de enero de 1958. Tres de estos satélites (Sputnik 1, Sputnik 2 y Sputnik 3) alcanzaron la órbita terrestre.

Los transmisores funcionaron durante tres semanas, hasta que fallaron las baterías químicas a bordo, y fue monitorizado con gran interés a lo largo de todo el mundo. La órbita del entonces satélite inactivo fue observada más tarde ópticamente, hasta caer 92 días después de su lanzamiento (4 de enero de 1958), después de haber completado alrededor de 1440 órbitas a la Tierra, acumulando una distancia de viaje, de aproximadamente unos 70 millones de km. El apogeo de la órbita decayó de 947 km tras el lanzamiento hasta 600 km el 9 de diciembre.

El cohete auxiliar de lanzamiento del Sputnik 1 también alcanzó la órbita terrestre y fue visible de noche, desde la Tierra, como un objeto de primera magnitud, mientras que la pequeña pero pulida esfera, apenas era visible en sexta magnitud, por lo que era más difícil seguirla desde Tierra. Varias réplicas del satélite Sputnik 1 pueden verse en museos de Rusia; hay otra junto a la embajada de Rusia en Madrid en España y una más está expuesta en el Smithsonian "National Air and Space Museum" (Museo Nacional Smithsonian del Aire y del Espacio) en Washington D. C.

En el 2003 una unidad de reserva del Sputnik 1, llamada "modelo PS-1" se vendió en eBay (sin la radio, que fue extraída durante los años 60 al ser clasificada como material militar). Había estado en exposición en un instituto de ciencias cerca de Kiev. Se estima que se construyeron de cuatro a veinte modelos con propósitos de prueba. Un modelo del Sputnik 1 se entregó como regalo a las Naciones Unidas y ahora decora el vestíbulo de entrada de sus oficinas centrales en Nueva York.




</doc>
<doc id="15509" url="https://es.wikipedia.org/wiki?curid=15509" title="Programa espacial de la Unión Soviética">
Programa espacial de la Unión Soviética

Se engloban bajo la etiqueta de Programa espacial soviético las iniciativas astronáuticas desarrolladas por la URSS desde 1957 hasta el momento de su disolución en 1991.
Las ambiciones espaciales rusas empezaron en el siglo XIX, tuvieron sus primeros estudios teóricos en el inicio del siglo XX y se desarrollaron principalmente durante la Guerra Fría en la Unión Soviética. Los soviéticos fueron pioneros de la carrera espacial al ser los primeros en: enviar un satélite (Sputnik 1), una criatura viva (Laika), un varón al espacio (Yuri Gagarin), una mujer (Valentina Tereshkova), enviar al primer varón que realizó una caminata espacial (Aleksei Leonov), enviar una estación espacial (Saliut), enviar la primera mujer que realizó una caminata espacial (Svetlana Savitskaya) y lanzar las primeras sondas interplanetarias a Marte (Marsnik 1) y Venus (Venera 1).

El 4 de octubre de 1957, el satélite Sputnik 1 fue lanzado con éxito por un cohete R-7. El primer satélite artificial puesto en órbita sorprendió a los estadounidenses, que rápidamente crearon la NASA para desarrollar su programa espacial e intentar alcanzar a los soviéticos. 

El principal ingeniero a cargo fue Serguéi Koroliov. Tuvo un gran equipo, otro miembro destacado fue Borís Yevséyevich Chertok, que estuvo a cargo del desarrollo de sistemas de guía y control. 

Un mes después, el 3 de noviembre de 1957, la perra Laika fue enviada al espacio a bordo del Sputnik 2. El objetivo de la misión fue monitorizar los efectos de un viaje al espacio en un ser vivo. Laika fue la primera criatura viva en orbitar la Tierra.

El 12 de julio de 2007, Rusia celebró el 100 aniversario del nacimiento de Serguéi Koroliov, el presidente Putin entregó reconocimientos y flores a la hija del padre del programa espacial. 

Las ideas de la exploración espacial ya existían en el Imperio ruso aún antes de la Primera Guerra Mundial. En sus trabajos pioneros, Konstantín Tsiolkovski había escrito y hablado sobre esto explicando el concepto de cohetes con múltiples etapas.

El primer cohete Soviético, llamado GIRD, fue lanzado el 18 de agosto de 1933. Luego, el 25 de noviembre de 1933, se lanzó un cohete híbrido de combustible especial llamado GIRD-X. Ya para la época de 1940-41 se llegó a otro avance en la propulsión de cohetes para producir en serie los cohetes para el sistema múltiple Katyusha.

Otra contribución para el avance del programa Soviético lo constituyó el trofeo de Guerra los V-2, el encargado del proyecto fue Dmitri Ustínov, y el diseñador e Ingeniero en jefe Serguéi Koroliov también contaron la ayuda de planos capturados y del científico alemán Helmut Gröttrup lograron construir una replica del V-2 y lo llamaron Cohete R-1

Pero el peso de las primeras cabezas nucleares soviéticas requería un propulsor más poderoso, después de varias pruebas con otros modelos Koroliov construyó el R-7 que logró llevar una carga a una distancia de 7000 km., convirtiéndose en ese momento como el cohete más avanzado de la época.

Años más tarde el Programa Espacial Soviético entró en un plan Quinquenal de 5 años y obtuvo también apoyos del Ejército Soviético, en enero de 1956 se aprobó el plan para desarrollar Satélites que orbitaran el planeta y obtener más conocimientos del ambiente espacial (Sputnik) y también para ganar experiencia militar espacial (Zenit).

Después del éxito mundial con el Spútnik, a Koroliov se le pidió marchas forzadas para el desarrollo de un programa tripulado y así producir la nave espacial Vostok.

Después de la muerte de Koroliov en 1966, Kerim Kerímov quedó a cargo de la construcción del Vostok 1. Kerímov fue nombrado como Jefe la comisión de Vuelos tripulados y estuvo en ese cargo por más de 25 años (1966-1991). Él supervisó cada una de las etapas de desarrollo y operación de vuelos tripulados y misiones de sonda espaciales de la Unión Soviética. Uno de sus más grandes logros fue la puesta en órbita de la estación espacial Mir en 1986.

El programa espacial soviético llevó a cabo un gran número de proyectos, incluyendo:




</doc>
<doc id="15513" url="https://es.wikipedia.org/wiki?curid=15513" title="Agoyo">
Agoyo

En ciertas regiones de Guinea, se rendía la máxima veneración al fetiche "Agoyo", especie de ídolo de buen agüero que se conservaba en la cabaña del brujo principal. Su forma era rarísima, casi inconcebible: una talla de unos cuarenta centímetros de altura, medio hombre y medio sapo, adornada con cintas rojas lo mismo que la vasija invertida que le servía de pedestal. En la cabeza llevaba un extraño tocado terminado en un dardo, constituido por un lagarto bajo una media luna, otro más pequeño y horizontal, un trozo de lanza, plumas, serpientes y más lagartos, todo esto se colocaba en una mesa con tres cuencos y dieciocho bolitas de barro.

Para consultar a este ídolo era preciso hacerle un sacrificio acompañado de un espléndido regalo al brujo mayor, que tenía la exclusiva de ese oráculo; si, al verter las bolitas varias veces en los cuencos, salía un número impar, la respuesta era afirmativa y, en caso contrario, negativa.



</doc>
<doc id="15515" url="https://es.wikipedia.org/wiki?curid=15515" title="Rock en español">
Rock en español

Rock en español es la música rock compuesta e interpretada en castellano. A diferencia del rock en inglés, el rock en español ha logrado tener éxito mundial en pocas ocasiones, y muchas veces ni siquiera entre países de habla hispana. Por eso el rock en castellano se ha desarrollado de manera heterogénea en las distintas naciones hispanohablantes; quedando así la música de muchas bandas para uso casi exclusivamente nacional hasta la llegada de la globalización de contenidos multimedia acentuada por la generalización de internet y desarrollada especialmente en el siglo XXI.

A pesar de esto, todas las escenas hispanohablantes siempre tuvieron al rock anglosajón como marco de referencias común, haciendo que el desarrollo de los diversos estilos de rock en cada país fueran contemporáneos. Aunque cabe añadir, que hubo épocas de represión del género en algunos países que atrasaron el desarrollo del rock en sus escenas locales.

El rock and roll, conocido inicialmente como rhythm and blues, es un estilo musical creado por la comunidad afroamericana de Estados Unidos a partir del final de la Segunda Guerra Mundial en 1945. En la década de 1950, músicos caucásicos (de raza blanca), como Elvis Presley y Bill Haley, impulsaron la masificación del género que se transformó en una cultura global.

La producción de rock en español se inició a finales de la década de 1950, con bandas musicales que en su gran mayoría, interpretaban en castellano los éxitos del rock and roll estadounidense. El inicio del rock en español se remonta a la segunda mitad de los años 1950. Aunque es objeto de controversia afirmar cuándo comienza exactamente a desarrollarse, es cierto que en ocasiones se suele señalar «El relojito» de Gloria Ríos en 1956 como punto de partida para el rock interpretado en castellano.

Sin embargo, el primer gran éxito internacional de rock en español fue «La bamba», una canción regional mexicana interpretada con ritmo de rock y cantada en español por el estadounidense Ritchie Valens (de origen mexicano) en 1958.

Poco después, el saxofonista Danny Flores, también alcanzó gran popularidad en Estados Unidos (y buena parte del mundo) ese mismo año, al llegar al primer lugar de las listas del Billboard con su éxito «Tequila».

Ya a finales de la década, Los Llopis -que eran en realidad una banda centrada en la canción melódica y en géneros más estandarizados- vertieron al español algunos temas del primer rock and roll estadounidense.

Con la llegada de 1960 y la nueva década, el rock empezó a generalizarse y los medios de comunicación comenzaron a darle cada vez mayor cobertura. Vista su enorme capacidad de convocatoria entre el público juvenil, los locales de ocio y los promotores musicales comenzaron a programar sistemáticamente conciertos de grupos de rock; de forma que en poco tiempo el género se convirtió en un verdadero fenómeno de masas.

La década comenzó con la misma tendencia con la que había finalizado la anterior, basándose sobre todo en la aparición de agrupaciones que aún versionaban éxitos de rock anglosajón traduciéndolos al castellano, como Los Teen Tops -que obtuvieron éxito en Hispanoamérica y España-. Sin embargo, el rock cada vez obtenía más atención y poco a poco fueron apareciendo diversos grupos y solistas que interpretarían sus temas originales en castellano, dejando de versionar éxitos estadounidenses. También es destacable la influencia de otros países europeos no angloparlantes, con la llegada del fenómeno Yeyé de la que salieron artistas como Raphael.

Por otra parte, en varios países sudamericanos se acuñó el término nueva ola para englobar a aquellos artistas que adoptaron la influencia musical del rock de Estados Unidos y de los patrones de la cultura pop de Europa. Este estilo de pop mezclado con twist, beat y rock llegó a cosechar gran popularidad en Latinoamérica. Sin embargo el estallido que vendría con la llegada de la ola inglesa que se dio a mediados de la década sería determinante para el desarrollo del rock en español.

Es justo entonces cuando los británicos The Beatles se convirtieron en un éxito mundial; a ellos les siguieron un gran número de grupos de su misma nacionalidad. Este fenómeno, la denominada invasión británica, afectó al mundo hispanohablante y a todo el planeta. Los nuevos sonidos venidos del Reino Unido (y también de los EE.UU.) como la música beat, el rythm and blues, la psicodelia, el soul, el folk-rock o el pop se impusieron por todo el mundo, ejerciendo una notable influencia en los países de habla hispana e impulsando el desarrollo del rock en sus respectivas escenas.
La influencia de la música beat, el pop o la psicodelia se hizo presente enseguida con Los Brincos, El Kinto, Los Gatos, The Speakers, y algunos artistas de éxito que se expresaban principalmente en inglés también interpretaron en castellano ocasionalmente como Los Bravos o Los Shakers. Aunque en los pocos casos que las bandas tuvieron éxito mundial fueron mayoritariamente con temas interpretados en inglés (como sucedió con Los Bravos o Miguel Ríos). También notable fue el caso de Los Saicos, una de las bandas pioneras del proto-punk en el mundo, siendo reivindicada posteriormente como ejemplo de garage rock primigenio en español. Y es que no todo se basó en adaptar los sonidos anglosajones al entorno hispano, sino que el rock fue más allá dejándose influenciar por la música autóctona de cada país. Así es como la banda Santana obtuvo un gran éxito mundial con su mezcla de rock y sonidos latinoamericanos, un estilo que dio en llamarse rock latino. Aunque es digno de mencionar que su repertorio se expresaba mayoritariamente en inglés, quedó algún éxito en castellano como «Oye cómo va». Esta tendencia del rock latino seguiría desarrollándose durante el final de la década y la siguiente con bandas como Malo así como la de mezclar sonidos folclóricos de otras regiones con el rock. Pero este hecho no quiere decir que dejara de ser influido el rock en castellano por el anglosajón pues durante el cambio de década seguirían siendo determinantes los estilos dominantes en inglés como el rock ácido, el blues rock o el hard rock; así como el rock progresivo donde ya se dejaba entrever en bandas como Almendra cuyo cantante Luis Alberto Spinetta sería una pieza clave en el rock interpretado en castellano durante la siguiente década.

Bajo la amalgama de influencias que se había producido durante la década anterior, el rock en castellano queda marcado por la psicodelia quedando presente con Los Dug Dug's, Pescado Rabioso —propuesta de Spinetta por el rock psicodélico pesado— o La Revolución de Emiliano Zapata —aunque rara vez interpretaban en castellano durante esta etapa—, el blues con Manal, y el rock progresivo con Invisible—último gran proyecto de Spinetta—, Sui Generis —con una línea más marcada hacia el folk—, Témpano, Los Jaivas —con su mezcla de rock y música de raíz folclórica andina—, Vox Dei —que se tornaría hacia sonidos más duros— o Triana —con una alta influencia del flamenco—.

Y es que Triana fue una banda pionera en lo que dio en llamarse rock andaluz, una derivación del rock progresivo y del rock sinfónico con una fuerte presencia del flamenco, estilo que quedaba fusionado a la música rock de manera totalmente homogénea. Aunque ese tipo de fusiones, en ocasiones, fueron todavía más allá, dejando de lado el sinfonismo y mezclando el flamenco a otros tipos de rock que anclaban sus raíces en el rock and roll tradicional, el blues o el folk, como hizo la banda Veneno.

Y tal como había ocurrido al final de la anterior década en el Reino Unido, el hard rock se abrió pasó a inicios de los setenta con bandas como Pappo's Blues —una de las grandes pioneras del género en lengua española—. Pronto, otras bandas seguirían ese camino, creando una escena musical de sonidos más pesados y, sobre todo, alumbrando nuevas corrientes musicales que marcarían la pauta a toda una generación. Entre ellas destacó un movimiento que se conoció como rock urbano (de España), claramente adscribible al hard rock, pero también influido por estilos como el rock progresivo y el blues rock; y cuyo máximo estandarte fue el grupo Leño.
Pero no todo fueron buenas noticias para el rock en español. De hecho, en dos de las escenas nacionales más potentes y representativas del género, una serie de acontecimientos extramusicales (de carácter socio-político) tuvieron consecuencias terriblemente negativas en México y Argentina.

En México, a principios de los setenta, el rock sufrió algo parecido a un persecución cuando el gobierno federal (en teoría, como consecuencia de los sucesos originados en un festival celebrado en la localidad de Avándaro), prohibió la celebración de conciertos, restringió su difusión mediática (radio y televisión) y presionó a las compañías discográficas para reducir la publicación de discos del género. 
En cuanto a Argentina, el golpe de estado de marzo de 1976 abrió también un período de represión y censura en el que, sin llegar ni mucho menos a la prohibición, el rock fue visto como algo sospechoso y subversivo, capaz de agitar y movilizar a la juventud contra el sistema establecido. Como consecuencia, varios músicos y bandas argentinas dejarían el país e irían a Europa —especialmente España, país que acababa de salir de la dictadura franquista— o a Estados Unidos, 

Esta migración de músicos argentinos hacia España dio lugar a una fugaz conexión entre dos de las escenas más potentes del género hasta el momento en el mundo de habla hispana. De hecho, los artistas argentinos exiliados se unieron a la escena española con rapidez y se adaptaron —en unos casos con mayor y en otros con menor éxito— a su país de acogida. Hubo casos en los que se formaron grupos con componentes de ambas nacionalidades (como en el de Tequila, banda que obtuvo un enorme éxito comercial), mientras otros desarrollaban su carrera como solistas (Moris).
Sea como sea, esa conexión de alguna manera pudo ayudar a consolidar una nueva escena musical alejada del rock progresivo y de los sonidos duros y sinfónicos que entonces eran predominantes a ambos lados del Atlántico. Una nueva escena heredera del rock and roll clásico, del glam rock, del rythm and blues y del pop y el rock de los años sesenta en la que ya destacaban bandas como Burning (con un estilo que se podría definir como "stoniano") y grupos difícilmente encasillables como La Orquesta Mondragón (que combinaba el rock con cierta teatralidad paródica): que, de alguna forma, era equivalente al pub rock británico que, por aquellas fechas, surgía en el Reino Unido; y que, en pocos años, terminaría dando lugar al surgimiento de nuevas corrientes como el punk y la new wave).

En cualquier caso, estas represiones de carácter político no impidieron que todavía sonara el rock en la escena "underground", y buena prueba de ello es que todavía surgirían bandas reconocidas durante este período como Serú Girán, proyecto de Charly García quien ya estuvo en la banda Sui Generis.

Cuando ya el rock progresivo estaba en declive en el resto del mundo, en la escena hispana aún daba sus últimos aciertos con Chac Mool o Frágil, con sus últimas grandes aportaciones a la escena progresiva.

Precisamente a finales de la década anterior el mundo se vio influenciado por el advenimiento de la escena punk que si bien ya tuvo pioneros durante el mismo período en la escena hispanohablante, sería a lo largo de ésta cuando resultaría ser más prolífica; justo cuando en el mundo angloparlante estaba en declive. Precisamente el movimiento estaba en pleno auge en el mundo hispanoparlante con bandas como La Polla Records —grupo que se englobó dentro del rock radical vasco—, Siniestro Total —con cierto tono humorístico— o Los Violadores.

Sin embargo en el punk anglosajón había derivado en nuevas tendencias como la new wave y el post-punk, algo que tampoco pasó desapercibido para la escena en español. De la movida madrileña, un movimiento contracultural que captó la atención internacional, surgieron numerosas bandas en esa línea como Alaska y Dinarama, Radio Futura, La Unión o Gabinete Caligari; aunque lejos de limitarse a ella, englobaba a otras de diferentes propuestas estilísticas como el rock and roll tradicionalista de Loquillo y los Trogloditas, el pop rock de Nacha Pop o el synth pop de Aviador Dro y Mecano.

El alcance de la new wave y el post-punk llegaría a influenciar también a bandas fuera de este movimiento (aunque muchas de ellas acabarían por cambiar su registro o estaban sometidas también a otras influencias) como Sumo, Sentimiento Muerto, Los Prisioneros, Los Abuelos de la Nada, Virus, Caifanes, Patricio Rey y sus Redonditos de Ricota —comúnmente abreviado a "Los Redondos"— o Soda Stereo. 

Y sería precisamente Soda Stereo el pistoletazo de salida para la internacionalización del rock en español. Y es que pese a que la escena había tenido ciertos contactos, nunca había tenido una difusión masiva. Aunque no fue ni mucho menos un equivalente a la invasión británica, pues no todos los estilos de rock recibieron la misma difusión aunque sí que sirvió para que se iniciara un ciclo de internacionalización del rock en castellano.

Bajo este escenario, durante la segunda mitad de la década, el español Miguel Ríos organizó los "encuentros de rock latinoamericano" y enseguida comenzó una campaña de difusión denominada «Rock en tu idioma» donde se promocionaron varios de los grupos mencionados junto a otros de diversa índole como Duncan Dhu, Maldita Vecindad y los Hijos del Quinto Patio, Los Toreros Muertos, Hombres G, Enanitos Verdes, Miguel Mateos, entre otros. Desde artistas de pop rock como El Último de la Fila o el «guacarrock» de Botellita de Jerez hasta cantautores como Fito Páez, Joaquin Sabina, Juan Carlos Baglietto y Rodrigo González mostraban que el rock estaba viviendo una época de bonanza. Rodrigo González sería una de las semillas de la corriente que se denominó rock urbano mexicano, que tenía algunas características afines al rock urbano de España, aunque anclaba sus raíces en un estilo más influenciado por el rock and roll, el blues, y el rhythm and blues dejando a un lado las del punk y el rock progresivo. Sin duda El Tri fue uno de los máximos exponentes de la corriente; valga decir que el movimiento se revitalizaría de nuevo en la década siguiente.

Por otro lado, la escena de heavy metal —totalmente ajena a la escena del «Rock en tu idioma»— estando influida por el hard rock de la década anterior y del movimiento que se conoció como la nueva ola del heavy metal británico (abreviado en inglés "NWOBHM"), iba tomando forma rápidamente con bandas como Riff —formada por el líder de Pappo's Blues—, Kraken o Barón Rojo —que además obtuvo cierto éxito en Europa al versionar algunos de sus temas al inglés—. Sin embargo, el mayor impacto de popularidad del metal en español lo darían bandas radicadas en esta década que se popularizarían a principios de la siguiente.

Precisamente Ángeles del Infierno que había desarrollado su carrera en la década anterior encontraría su popularidad en Hispanoamérica a partir de este momento. Y es que por aquel entonces en la escena anglosajona, el heavy metal estaba sufriendo una recesión en favor de nuevos estilos como el grunge. Sin embargo, tardarían algo más los estilos de rock alternativos en ser dominantes en la escena hispanohablante, pues justo cuando transcurría la eclosión del grunge en EE.UU, el heavy metal en castellano alcanzó nuevas cotas de popularidad con el éxito de Rata Blanca. Por supuesto otros estilos menos clásicos surgieron como el death metal de Brujería, el thrash metal de Ekhymosis o Transmetal —que su estilo se ubicaba entre ambos géneros—.

También fue notorio el resurgimiento del punk en el mundo anglosajón, al que se unieron rápidamente bandas (aunque la productiva era del punk en castellano quedaba muy cerca) como Attaque 77, Todos tus muertos —apostando más por el hardcore punk— o Ska-P —centrada en el ska punk—. Es notable decir que el ska fue un estilo que tuvo bastante presencia también con otras bandas como Desorden Público, King Changó —que catalogaría su estilo de "latin ska"—, Tijuana No! o Los Rabanes.

Por otro lado, muchas de las bandas del «Rock en tu idioma» estaban en su etapa de esplendor; y a ellas no tardaron en unirse otras de una onda similar, generalmente de base pop rock (muchas nacidas a finales de la década anterior) como Jarabedepalo, Los Rodríguez (y, tras su disolución, Andrés Calamaro como solista), Celtas Cortos —con su rock de raíces celtas—, Julieta Venegas, Juanes —que cambió su registro radicalmente desde su salida de Ekhymosis—, Ely Guerra, Los Pericos —entonando su estilo hacia el reggae—, Shakira, Maná o Héroes del Silencio—aunque estos últimos en una línea más dura y "rockera" que los otros—.

A pesar de las incursiones de Héroes del Silencio en el hard rock, no es habitual catalogar a la banda como fiel representante de dicho género. No obstante, éste seguía teniendo presencia con otros grupos que pueden reconocerse más claramente en la etiqueta; hablamos de La Renga —como parte del rock barrial—, Cuca —con una propuesta humorística— o el máximo artífice del renacimiento del viejo rock urbano español Extremoduro.

Aun así, sería demasiado aventurado afirmar que el rock en castellano gozara de fama internacional o mundial. Y es que el territorio hispanohablante era visto principalmente como fuente de éxitos de verano y canciones de baile. Resulta irónico que precisamente el productor de Ricky Martin, Draco Rosa, iniciara su carrera dejándose influenciar del rock alternativo. Y es que el rock alternativo se hizo patente en la escena hispanohablante y surgieron diversas bandas que se dejaron influenciar por su sonido como Caramelos de Cianuro, Libido, La Gusana Ciega, Santa Sabina, La Barranca, Los Tres, Lucybell, Divididos —con gran afinidad al hard rock e incluso el funk—, Zurdok, El Otro Yo o Babasónicos. Cabe señalar que la escena indie rock, de la cual podemos destacar a Los Planetas, no ha de ser confundida con la del rock alternativo aunque a veces pueda llegar a existir cierto solapamiento entre ambas.

Sin embargo, tal como lo hizo el clásico rock latino, la nueva tendencia del rock alternativo se dejó influenciar por la música autóctona latinoamericana y otros ritmos como el reggae o el ska, formando así el alterlatino. Lejos de ser algo anecdótico, la escena fue muy prolífica con numerosas bandas de éxito como el artista Manu Chao y su banda Mano Negra —que intercalaba diversos idiomas a sus lanzamientos—, Los Fabulosos Cadillacs, Fobia, Café Tacuba, Aterciopelados, Jaguares como también lo fue la banda Caifanes de la cual se radicó, Bersuit Vergarabat, Amparanoia, Los Piojos, Los Auténticos Decadentes, La Ley o Molotov —con una propuesta estilística basada en el rap rock— son algunos de los más representativos en dicha vertiente musical.
Tal y como había ocurrido en el mundo anglosajón, la escena quedó plagada de propuestas de carácter alternativo en comparación a lo que se había venido componiendo antiguamente como también lo hizo la escena "metálica". El metal alternativo se hizo patente con el nu metal (entre otros estilos) de Resorte, Puya —mezclando su sonido con la salsa— o A.N.I.M.A.L. —también de apuesta groove metal—.

A pesar de la internacionalización, muchas bandas de gran popularidad nacional aún continuaban sin expandir sus fronteras debido a la falta de promoción en otros países. La globalización de contenidos acentuada por la generalización de internet empezó a ayudar a unificar más aún las escenas regionales. Esto era, en general, un agravante para escenas concretas como el hard rock, metal o el punk. Sin duda, de toda la escena del heavy metal de habla hispana de los primeros años del siglo XXI, la que más trascendencia llegó a lograr fue la formación de folk metal Mägo de Oz.

Estilísticamente, el siglo comenzó como una extensión más de lo que había ocurrido durante la década de los noventa. Los sonidos del rock alternativo o del alterlatino seguían dejándose ver con Ozomatli, No Te Va Gustar, Panteón Rococó —inclinándose hacia el ska—, Kevin Johansen —en una línea más de cantautor—, Catupecu Machu, Los Bunkers, La Vida Bohème -más inclinado hacia el indie rock-, El Guincho —con su tropicalismo neopsicodélico—, La Vela Puerca, Macaco, Zoé, Jumbo o Kinky —incorporando a su estilo elementos de la música electrónica—.

Precisamente la música electrónica sería la base de otras que anclarían sus raíces en el rock alternativo como el trip hop de Plastilina Mosh, el electrofolk de Juana Molina, el electropop de Belanova y Miranda! o el synthpop oscuro de los primeros álbumes de Saiko.

Y es que si tuviéramos que destacar alguna tendencia nueva, sin duda, sería la de incorporar la electrónica; incluso el antiguo cantante de Soda Stereo, Gustavo Cerati, se dejó influenciar por el sonido.

Sin embargo, los estilos más «clásicos» no cayeron en el olvido, y es que si Enrique Bunbury en un principio inició su carrera en solitario dejándose influenciar por las nuevas tendencias alternativas e incluso electrónicas, pronto se desmarcaría de ellas experimentando con diversos estilos en una línea de cantautor y de pop rock.
Alejados de esas vertientes, en la escena pop rock podemos nombrar a Estopa —también vinculables a la rumba flamenca—, Bacilos —una apuesta de pop latino—, Natalia Lafourcade —con estilo más propio del folk y el pop barroco—, Fito & Fitipaldis —con sonido más declinado hacia el rock and roll—, El Cuarteto de Nos —con ciertos dotes humorísticos—, Mon Laferte —con un estilo melodramático de gran carga melancólica— u otros más cercanos a la canción de autor como Nacho Vegas, Jorge Drexler o Fiel a la Vega. También notable es el funk latino de Los Amigos Invisibles, estilo que se desmarca de todos los mencionados.




</doc>
<doc id="15516" url="https://es.wikipedia.org/wiki?curid=15516" title="Supertramp">
Supertramp

Supertramp es un grupo británico de "rock" fundado en 1969 por el músico Rick Davies. Con el apoyo financiero de Stanley August Miesegaes, la primera formación de Supertramp, integrada por Roger Hodgson, Richard Palmer y Robert Millar, publicó un álbum homónimo dominado por el "rock" progresivo de escaso éxito comercial, seguido de un segundo trabajo, "Indelibly Stamped", en el que Palmer y Millar fueron sustituidos por Frank Farrell, Kevin Currie y Dave Winthrop.

A pesar del escaso éxito inicial y de que Miesegaes cortó la financiación del grupo, Davies y Hodgson crearon una nueva formación, integrada por Dougie Thomson, John Helliwell y Bob Siebenberg, cuyos trabajos incluyeron un sonido más orientado al pop y elementos del "art rock" con un uso predominante del piano Wurlitzer y del saxofón.</ref> El primer álbum de esta formación, "Crime of the Century", favoreció el auge comercial de Supertramp, consolidado con sencillos como «Dreamer» y «Bloody Well Right». "Crime of the Century" fue seguido de trabajos como "Crisis? What Crisis?" y "Even in the Quietest Moments", que labraron la reputación de Supertramp como una banda de directo.

El álbum "Breakfast in America" consolidó a Supertramp como una banda de éxito al alcanzar el primer puesto en la lista de los discos más vendidos de países como Alemania, Australia, Canadá, Estados Unidos, España y Francia, entre otros. Tres de sus sencillos —«Goodbye Stranger», «Take the Long Way Home» y «The Logical Song»— fueron "top 20" en los Estados Unidos, donde el álbum vendió más de cuatro millones de copias. El éxito de "Breakfast in America" continuó con "Famous Last Words", tras el cual Hodgson anunció su abandono para emprender una carrera en solitario.

Con Davies como líder "de facto" de Supertramp, el grupo publicó "Brother Where You Bound" (1985), con una mayor influencia del "rock" progresivo, y "Free as a Bird" (1987), que incorporó elementos del "dance" y contó con la incorporación de Mark Hart. Tras una gira posterior, Supertramp estuvo inactivo durante casi una década.

En 1996, Davies volvió a reunir al grupo, ampliado con la presencia de Carl Verheyen, Cliff Hugo, Lee Thornburg y Jesse Siebenberg, para publicar "Some Things Never Change", seguido de una gira documentada en el álbum "It Was the Best of Times" (1999) y de "Slow Motion" (2002), su último álbum hasta la fecha. Tras ocho años de inactividad, Davies reformó nuevamente el grupo para realizar la gira 70-10 Tour, con motivo del 40º aniversario de la formación de Supertramp, seguida en 2015 de la gira Supertramp Forever Tour.

En 1969, Stanley 'Sam' August Miesegaes, un millonario holandés, dejó de apoyar económicamente a una banda llamada The Joint debido a su decepción con ellos. Sin embargo, ofreció a Rick Davies, miembro del grupo y de quien sentía que su talento se había visto «empantanado» en The Joint, una oportunidad para formar su propia banda, de nuevo con su respaldo financiero. Después de colocar un anuncio en el semanario musical "Melody Maker", Davies formó una banda con Roger Hodgson (bajo y voz), Richard Palmer-James (guitarras) y Keith Baker (percusión).

Davies y Hodgson tenían orígenes e inspiraciones musicales radicalmente diferentes: Davies tenía un origen humilde y sus principales influencias musicales eran el "blues" y el "jazz", mientras que Hodgson había comenzado a trabajar en la industria musical y era aficionado al pop y a la música psicodélica. A pesar de ello, comenzaron a escribir canciones juntos, con Palmer como tercer miembro del equipo compositivo. Dado que ningún otro miembro de la banda se mostró dispuesto, Palmer escribió todas las letras.
El grupo se denominó inicialmente como Daddy. Baker fue al poco tiempo reemplazado por Robert Millar, y después de varios meses ensayando en una casa de campo de West Hythe, la banda viajó a Munich para ofrecer una serie de conciertos en el P.N. Club. Una actuación de diez minutos de la canción "All Along The Watchtower" fue filmada por Haro Senft durante un concierto. Los ensayos fueron poco productivos, y su repertorio inicial consistía en solo cuatro canciones, dos de ellas versiones de otros artistas. Para evitar confusiones con la banda Daddy Longlegs, el grupo cambió su nombre por el de Supertramp, un apodo inspirado en el libro de W. H. Davies "Autobiografía de un súper vagabundo" ("The Autobiography of a Super-Tramp").

Supertramp fue uno de los primeros grupos en firmar con la rama británica de A&M Records, y su primer álbum, "Supertramp", fue publicado en julio de 1970 en el Reino Unido y Canadá (en los Estados Unidos no fue publicado hasta 1977). Estilísticamente, el álbum incluyó "rock" progresivo característico de la época y un sonido similar al del grupo Cressida. A pesar de obtener buenas reseñas, el álbum no atrajo a una gran audiencia.

Dave Winthrop (flauta y saxofón) se unió al grupo tras el lanzamiento del primer disco, y poco después, Supertramp tocó en el Festival de la Isla de Wight. La formación continuó cambiando en los seis meses siguientes a la publicación del álbum: Palmer abandonó el grupo debido a conflictos personales con Davies y Hodgson, seguido de Millar, quien sufrió una crisis nerviosa después de una gira por Noruega.

En su siguiente álbum, "Indelibly Stamped", publicado en junio de 1971, Frank Farrell (bajo) y Kevin Currie (percusión) reemplazaron a Palmer y Millar, mientras que Hodgson pasó a tocar la guitarra y Davies comenzó a ser el segundo vocalista. Con la salida de Palmer, Hodgson y Davies comenzaron a escribir las canciones del resto de trabajos del grupo. "Indelibly Stamped" obtuvo ventas inferiores a su predecesor, lo cual provocó que todos los miembros, a excepción de Davies y Hodgson, abandonaran el grupo, y que Miesegaes les retirase su apoyo financiero en octubre de 1972.

Una búsqueda de nuevos miembros llevó a bordo a Dougie Thomson, que había realizado conciertos con el grupo casi un año antes de reanudar las audiciones. En 1973, el grupo se amplió con Bob Siebenberg (batería) y John Helliwell (saxofón e instrumentos de viento), que completaron la nueva formación, vigente durante los siguientes diez años. Además de actuar como guitarrista, Hodgson también comenzó a tocar los teclados, especialmente el Wurlitzer.

Mientras tanto, el vínculo entre Davies y Hodgson comenzó a debilitarse paulatinamente. En julio de 1972, Hodgson consumió LSD por primera vez y le ofreció a Davies, quien se negó a consumirlo. En una carta a Miesegaes, Hodgson describió la experiencia como «el día más feliz de mi vida» y expresó su ansiedad por el hecho de que Davies no la tomara. Años después, Hodgson describió esta divergencia en sus experiencias como la raíz de la ruptura entre ellos. Durante la historia de Supertramp, la relación entre Davies y Hodgson fue amistosa pero con estilos de vida e inclinaciones musicales cada vez más distantes y menos solapadas. En este sentido, su asociación compositiva fue diluyéndose poco a poco y, aunque todas las canciones fueron acreditadas oficialmente a ambos, la mayoría fueron composiciones escritas individualmente por Davies o por Hodgson.

"Crime of the Century", publicado en septiembre de 1974, fue el primer gran éxito comercial y de crítica del grupo tras llegar al puesto cuatro en la lista "UK Albums Chart" y a la primera posición en la lista de discos más vendidos de Canadá. "Crime of the Century" subrayó la ambición del grupo, con muchas canciones fuertemente orquestadas y temas donde Davies y Hodgson compartieron la voz principal, como «School» y «Dreamer». La segunda, publicada como sencillo, llegó al "top 20" en el Reino Unido, mientras que su cara B, «Bloody Well Right», alcanzó el "top 40" en los Estados Unidos.

Con un álbum exitoso en su haber, las presiones sobre Supertramp aumentaron, y su sucesor, "Crisis? What Crisis?", fue grabado en los pocos meses de descanso entre dos giras. Como consecuencia, la mayoría del material consistió en descartes de "Crime of the Century", y décadas más tarde fue considerado por el propio grupo como uno de sus peores momentos. A pesar de las dudas del grupo, "Crisis? What Crisis?" fue bien recibido por la crítica y llegó al puesto veinte en la lista británica "UK Albums Chart" y al 44 en la estadounidense "Billboard 200".

El siguiente álbum, "Even in the Quietest Moments", fue publicado en abril de 1977 junto al sencillo «Give a Little Bit», número quince en los Estados Unidos y veintinueve en el Reino Unido. Al igual que con anterioridad, el álbum obtuvo un mayor éxito que los sencillos, y "Even in the Quietest Moments" llegó al puesto dieciséis en la lista "Billboard 200" y al doce en la lista de discos más vendidos del Reino Unido. Durante este periodo, el grupo trasladó su residencia a Los Ángeles, California.

El enfoque de un sonido más orientado al pop permitió que Supertramp alcanzara su mayor éxito con "Breakfast in America", publicado en marzo de 1979, que alcanzó el puesto tres en el Reino Unido y llegó a lo más alto de las listas de países como Canadá y los Estados Unidos. "Breakfast in America" produjo también cuatro sencillos: «The Logical Song», «Goodbye Stranger», «Take the Long Way Home» y «Breakfast in America», todos ellos "top 20" en los Estados Unidos. En marzo, el grupo se embarcó en una gira de 120 conciertos que rompió todos los récords de asistencia con respecto a conciertos anteriores tanto en Norteamérica como en Europa. Al finalizar la gira, los miembros del grupo decidieron tomar un descanso por un tiempo.
Para evitar un largo espacio entre álbumes durante su descanso, el grupo publicó "Paris", un doble disco en directo grabado en su mayoría en el Pavillon de París, Francia que alcanzó el puesto ocho en la lista estadounidense "Billboard 200". La versión en directo del sencillo «Dreamer» reportó al grupo su segundo número uno en Canadá después de «The Logical Song» y entró en el "top 20" en la lista estadounidense "Billboard Hot 100".

Durante este periodo, Hodgson trasladó a su familia a la zona montañosa del norte de California, donde construyó una casa y un estudio de grabación. Además, comenzó a pasar más tiempo con su familia y a mostrar interés por la espiritualidad, grabando de forma paralela "Sleeping with the Enemy", un primer álbum en solitario nunca publicado. El distanciamiento geográfico amplió la separación con respecto al resto del grupo, y durante la grabación de su siguiente trabajo, "...Famous Last Words...", Davies y Hodgson encontraron dificultades para conciliar sus respectivas ideas musicales. "...Famous Last Words..." fue publicado en octubre de 1982 y llegó a los puestos cinco y seis en las listas de discos más vendidos de los Estados Unidos y el Reino Unido respectivamente. Tras una gira mundial en 1983, Hodgson anunció públicamente que no iba a continuar con el grupo. Según el propio músico, su salida de Supertramp estuvo motivada por el deseo de pasar más tiempo con su familia y emprender una carrera en solitario, y que nunca tuvo problemas personales o profesionales reales entre Davies y él.

Tras la marcha de Hodgson, Davies pasó a liderar "de facto" Supertramp como único compositor y publicó "Brother Where You Bound" en 1985. El álbum fue un distanciamiento deliberado con respecto al pop de sus dos últimos trabajos y llegó al puesto veintiuno en la lista estadounidense "Billboard 200" y al veinte en el Reino Unido. "Brother Where You Bound" incluyó el sencillo «Cannonball», "top 30" en los Estados Unidos, junto con la canción principal, una larga exposición con temática de la Guerra Fría con un solo de guitarra del guitarrista de Pink Floyd David Gilmour.

Dos años después, el grupo publicó "Free as a Bird", un álbum marcado por la experimentación con sintetizadores y por incorporar elementos del pop y del "dance". Davies definió el álbum como «un experimento para tratar de ser moderno y construirlo con ordenadores y máquinas de ritmo, y que la gente viniese de uno en uno, lo cual te hacía perder el espíritu de grupo un poco». Aunque el sencillo «I'm Beggin' You» llegó al primer puesto en la lista "Hot Dance Music/Club Play" de "Billboard", "Free as a Bird" obtuvo un escaso éxito comercial. 

Tras la marcha de Hodgson, y con motivo de la gira de "Brother Where You Bound", el grupo decidió no interpretar canciones del músico, siguiendo un supuesto acuerdo verbal entre Davies y él. Sin embargo, el público se mostró poco entusiasmado por la omisión de estas canciones, por lo que la gira de "Free as a Bird" volvió a incluir composiciones de Hodgson interpretadas por Mark Hart que provocaron la marcha de Dougie Thomson. Tras la gira de 1988, el grupo se separó temporalmente. Al respecto, Davies comentó: «Hemos estado ahí cerca de veinte años entre grabaciones y giras y parecía el momento de tomar un descanso sin idea de cómo o cuándo volveremos. En realidad decidimos no decir nada, como si fuéramos viejos soldados desvaneciéndonos».

En 1993, Davies y Hodgson volvieron a tocar juntos por primera vez en diez años en un homenaje a Jerry Moss, cofundador de A&M Records, en el Beverly Hills Hilton, donde tocaron «The Logical Song» y «Goodbye Stranger». Tras el evento, ambos colaboraron durante seis meses ensayando canciones como «You Win I Lose» y «And the Light», antiguas composiciones de Davies. Sin embargo, el encuentro no fructificó y ambos siguieron caminos por separado.

Poco después, Davies retomó el proyecto de grabar un nuevo álbum y reformó Supertramp con John Helliwell, Bob Siebenberg y Mark Hart, presente desde la grabación de "Free as a Bird". Ampliando el grupo con otros cuatro músicos de sesión, Davies publicó "Some Things Never Change", un álbum con un retorno al sonido habitual de Supertramp, en marzo de 1997. "Some Things Never Change" llegó al "top" 10 en países europeos como Suiza, Francia y Alemania pero no entró en la lista estadounidense "Billboard 200".

"Some Things Never Change" fue seguido de la gira It's About Time Tour documentada en el álbum en directo "It Was the Best of Times", grabado en el Royal Albert Hall de Londres y publicado en abril de 1999. Tres años después, el grupo publicó "Slow Motion", su último álbum de estudio hasta la fecha. "Slow Motion" fue grabado en el nuevo hogar de Davies en Hampton Bays, después de residir durante más de dos décadas en Los Ángeles, usando por primera vez Pro Tools, y fue seguido de una nueva gira mundial, tras la cual el grupo volvió a permanecer inactivo.

Tras el lanzamiento de "Slow Motion", todos los miembros de Supertramp a excepción de Rick Davies realizaron proyectos paralelos al grupo. John Helliwell formó el grupo Créme Anglaise junto a Mark Hart y publicó un álbum homónimo en 2005, mientras que Bob Siebenberg formó parte del grupo Todd Hannigan And The Heavy 29’s junto a su hijo Jesse y trabajó en "The Glendale River", un álbum de estudio.
En 2005, con motivo de la publicación de "Retrospectacle - The Supertramp Anthology", Davies y Hodgson mantuvieron varias reuniones para intentar reformar Supertramp que no llegaron a fructificar. Tres años después, ambos músicos volvieron a encontrarse con vistas a una posible reunión del grupo que tampoco llegó a concretarse. 

A pesar de la negativa de Hodgson, Davies reformó Supertramp para la gira 70-10 Tour con motivo del cuadragésimo aniversario del grupo. La inclusión de canciones de Hodgson en la gira, de forma similar a las dos anteriores, provocó el enfado de Roger, quien dijo que rompía un acuerdo verbal entre él y Rick de no interpretarlas a cambio de mantener Davies el nombre de Supertramp. En respuesta, Davies explicó: «La única realidad es que existen 600 páginas de documentos contractuales que determinan lo que podemos hacer y lo que no. Por lo que a mí respecta, yo cumplo con mi parte de ese acuerdo e interpreto canciones de Supertramp. Eso tiene que ver con todo lo que publicamos juntos e interpretamos juntos sobre un escenario. Para mí, eso también es música de Supertramp».

La gira 70-10 Tour, que contó con la ausencia de Mark Hart y su sustitución por Gabe Dixon, comenzó en septiembre en Alemania y se extendió con una treinta de conciertos por Europa. Un año después, el grupo ofreció una etapa por Canadá antes de regresar a Francia, donde ofreció su concierto número 1 000.

En agosto de 2012, a pesar de la reprobación de Hodgson y de Davies, el grupo publicó el DVD "Live in Paris '79", con material audiovisual inédito filmado durante los conciertos de París en la gira de "Breakfast in America". El lanzamiento, promovido por el resto de miembros de Supertramp, obtuvo un notable éxito comercial al alcanzar el primer puesto en las listas de DVD más vendidos de países como Alemania, Bélgica, Noruega, Austria, Países Bajos y Suiza. 

En 2015, el grupo volvió a reformarse con motivo de la gira Supertramp Forever Tour, que finalmente fue suspendida por problemas de salud de Rick Davies.




</doc>
<doc id="15517" url="https://es.wikipedia.org/wiki?curid=15517" title="Roger Hodgson">
Roger Hodgson

Charles Roger Pomfret Hodgson (Portsmouth, Hampshire, England, 21 de marzo de 1950), más conocido como Roger Hodgson, es un músico y compositor británico, fundador junto a Rick Davies de la banda de rock progresivo Supertramp y compositor de gran parte del catálogo musical del grupo hasta su marcha en 1983. Es también reconocido por su voz aguda, marca distintiva de la música de Supertramp, así como por la temática de sus canciones, que habitualmente relatan temas espirituales y filosóficos. 

Tras abandonar Supertramp en 1983, Hodgson inició una carrera en solitario con la publicación del álbum "In the Eye of the Storm", grabando hasta la fecha tres álbumes de estudio. A pesar de varios intentos por retomar la colaboración con Rick Davies, su antiguo compañero en Supertramp, Hodgson centró desde 1997 su carrera artística en ofrecer conciertos periódicos durante extensas giras anuales, en las que combina actuaciones en solitario con conciertos respaldados por una banda de apoyo.

Hijo de Charles Hodgson y Jill Hodgson, Roger Hodgson nació el 21 de marzo de 1950 en Portsmouth, Inglaterra y se crio en Oxford, en una familia de clase media. Fue a la escuela Woodcote House, cerca de Wallingford, donde aprendió a tocar la guitarra eléctrica, y posteriormente acudió a la escuela Stowe School, cerca de Buckingham. A los 12 años su padre le regaló su primera guitarra y aprendió tres acordes básicos de su profesor en la escuela. Poco tiempo después comenzó a componer su propia música, y con 13 años ofreció su primer concierto en el colegio interpretando nueve canciones propias.

Hodgson formó su primera banda en el colegio, llamada H-Bombs y formada por él a la guitarra y Roy Hoby tocando una caja. Con 19 años, entró por primera vez en un estudio de grabación como guitarrista para el grupo People Like Us, que formó poco después de graduarse del internado. El grupo grabó dos canciones, «Duck Bound» y «Send Me No Flowers», que nunca fueron publicadas.

Tras la separación de People Like Us, Hodgson participó en una audición para el sello discográfico Island Records, gracias a la ayuda del representante del grupo Traffic. Island le usó como vocalista del grupo Argosy, formado por Reginald Dwight (más tarde conocido como Elton John), Caleb Quaye y Nigel Olsson. La única grabación del grupo fueron dos canciones, «Mr. Boyd» y «Imagine», compuestas por Hodgson y publicadas como sencillo en 1969 por dos sellos independientes, DJM en el Reino Unido y Congress en Estados Unidos. «Mr. Boyd» fue versionada en 1997 por Jake Shillingford y su grupo My Life Story en su álbum "The Golden Mile".

Tras la ruptura de Argosy, Hodgson respondió a un anuncio puesto en "Melody Maker" por Rick Davies, que buscaba un guitarrista para un nuevo grupo de rock progresivo bajo el nombre de Supertramp. Hodgson obtuvo en un primer momento el puesto, pero la llegada al día siguiente de Richard Palmer y su contratación como guitarrista obligó a Hodgson a aprender a tocar el bajo.

A pesar de que las canciones del primer álbum del grupo, "Supertramp", publicado en 1970, fueron acreditadas a Hodgson, Palmer y Davies, las letras fueron compuestas por Palmer. Sin embargo, la temprana marcha de Palmer del grupo permitió a Hodgson volver a la guitarra y centrarse, junto a su compañero Davies, en la composición de los temas de Supertramp a partir de su segundo álbum, "Indelibly Stamped". 

Con una formación fija y compuesta por John Helliwell al saxofón, Bob Siebenberg a la batería y Dougie Thomson al bajo, Supertramp obtuvo su primer éxito comercial con el álbum "Crime of the Century", que alcanzó el primer puesto en las listas de éxitos canadienses y el puesto 38 en la lista "Billboard 200". El éxito del grupo continuó con sus posteriores trabajos, "Crisis? What Crisis?" y "Even in the Quietest Moments", y alcanzó su apogeo con la publicación en 1979 de "Breakfast in America", que alcanzó el primer puesto en la lista "Billboard 200" y ha vendido hasta la fecha más de 20 millones de copias a nivel mundial. 
Entre 1974 y 1983, todas las canciones de Supertramp fueron legalmente fijadas con créditos compartidos entre Davies y Hodgson. Sin embargo, ambos compositores nunca escribieron como tándem, y en términos generales cada uno escribió la mitad del catálogo musical del grupo, perteneciendo a Hodgson canciones como «Give a Little Bit», «Breakfast in America», «The Logical Song», «Take the Long Way Home» e «It's Raining Again», entre otras.

El uso por parte de Davies de las canciones compuestas por Hodgson, generalmente más comerciales y reconocidas como marca de Supertramp, se convirtió desde la marcha de Hodgson en una de las principales disputas con su antiguo compañero de grupo. No obstante, a lo largo de la historia de Supertramp, la relación de amistad entre Davies y Hodgson se fue distanciando prematuramente a medida que las inclinaciones musicales y sus respectivos estilos de vida coincidían cada vez menos.

Tras la gira de promoción de "Breakfast in America" y la publicación en 1980 del álbum "Paris", Hodgson cambió su residencia y se trasladó desde Los Ángeles hasta las montañas del norte de California, donde construyó una casa y un estudio de grabación y comenzó a centrar su actividad en su familia y en la vida espiritual. La distancia geográfica separó aún más a Hodgson del grupo, y durante la grabación de "...Famous Last Words...", Davies y Hodgson encontraron dificultades en conciliar sus respectivas ideas musicales. Según declaró Bob Siebenberg en relación a los planteamientos musicales de Davies y Hodgson: «Al final, ambos cambiaron sus formatos y la imagen de cómo tendría que ser el álbum. Se convirtió en una versión diluida de lo que habían pensado».

Publicado en 1982, "...Famous Last Words..." se convirtió en el último trabajo de Supertramp con Hodgson, y fue seguido de una gira de promoción en 1983 donde Hodgson anunció que no iba a continuar con Supertramp. Según declaró Hodgson, su marcha estuvo motivada por el deseo de estar más tiempo con su familia y publicar trabajos en solitario, y que no hubo nunca problemas personales o profesionales entre Davies y él.

Desde su salida de Supertramp en 1983, Hodgson grabó tres álbumes en su estudio de grabación privado, el primero de ellos al poco tiempo de abandonar el grupo. Titulado "Sleeping With The Enemy", el álbum fue grabado en los meses entre la publicación de "...Famous Last Words..." y su posterior gira de promoción, y fue mezclado durante los ensayos con Supertramp con la esperanza de poder promocionar alguna canción durante los conciertos con el grupo. Sin embargo, en el último minuto Hodgson tuvo dudas sobre la calidad del álbum y decidió frenar su publicación, dedicando más tiempo a las nuevas canciones tras finalizar su última gira con Supertramp.

El resultado final fue "In the Eye of the Storm", publicado en 1984 y autoproducido en su mayoría por el propio Hodgson, tanto a nivel instrumental como compositivo. A pesar de la promoción como el primer trabajo de un antiguo miembro de Supertramp, "In the Eye of the Storm" no obtuvo un éxito comercial destacado ni en Reino Unido ni en Estados Unidos. Con un sonido más orientado hacia la música pop a diferencia de sus anteriores trabajos con Supertramp, el primer sencillo, «Had a Dream (Sleeping With the Enemy)», alcanzó el puesto 48 en Estados Unidos, mientras que otros sencillos como «In Jeopardy» y «Hooked On A Problem» no entraron en las listas de éxitos.

Aún no logrando el éxito comercial de sus anteriores trabajos bajo el nombre de Supertramp, "In the Eye of the Storm" se convirtió en el mayor éxito de crítica de su carrera en solitario. Bret Adams escribió para "Allmusic" una reseña positiva en la que afirmó que la calidad del álbum se debía al uso de la mayoría de los instrumentos por parte de Hodgson, y que aunque la música carecía de elementos de rock progresivo, «el espíritu de la experimentación del género musical está vivo en el álbum, con cinco de siete canciones que exceden los seis minutos».

Su segundo trabajo, "Hai Hai", fue publicado en 1987 y marcó un cambio de sonido hacia tendencias musicales orientadas hacia el synthpop, aún manteniendo la habitual línea compositiva de Hodgson. Sin embargo, previo a la publicación del álbum, Hodgson sufrió un accidente doméstico padeciendo la fractura de sus dos muñecas, lo que le impidió promocionar su trabajo. Como resultado, "Hai Hai" alcanzó solo el puesto 163 en la lista "Billboard 200", y Hodgson decidió tomar un descanso de giras y grabaciones y pasar más tiempo con sus hijos mientras se recuperaba de las lesiones.

En 1990, el grupo Yes ofreció a Hodgson entrar como vocalista, pero rechazó la oferta. Sin embargo, colaboró con Trevor Rabin componiendo la canción «Walls», publicada en el álbum de Yes "Talk". Una versión de la canción, con Hodgson y Rabin en la voz, fue publicada en el álbum "90125", con demos y trabajos de estudio de Rabin.

El primer intento por rehacer la formación clásica de Supertramp tuvo lugar en 1993, tras coincidir con Davies en un concierto homenaje a Jerry Moss, fundador de A&M Records, en el que interpretaron «The Logical Song» y «Goodbye Stranger». Tras el concierto, Hodgson y Davies colaboraron en el estudio desarrollando canciones como «In The Light» y «You Win I Lose», posteriormente publicadas en el álbum "Some Things Never Change". Sin embargo, la colaboración no dio el resultado esperado y Hodgson prefirió continuar en solitario.

Tras un largo descanso, Hodgson emprendió en 1994 su primera gira en diez años y publicó en 1997 "Rites of Passage", un álbum en directo con canciones interpretadas durante la gira. "Rites of Passage" fue grabado en Nevada City (California) e incluyó una banda de respaldo con su hijo Andrew y su compañero en Supertramp John Helliwell. A pesar de no obtener un éxito comercial destacado en Reino Unido y Estados Unidos, el álbum alcanzó el puesto 34 en Alemania. 

Dos años después, Hodgson interpretó el papel de Rey Arturo en la ópera rock "Excalibur: La Legende Des Celtes", un proyecto liderado por Alan Simon y publicado en 1999, y apareció en dos canciones del álbum, «The Elements» y «The Will of God». Además, contribuyó en los coros de la canción «The Moon Says Hello» en el álbum "Mayo Longo" del músico español Carlos Núñez.

Su tercer álbum en solitario, "Open the Door", fue publicado en el año 2000, siguiendo la estela de sus anteriores trabajos, y cuenta con la colaboración de Alan Simon y Trevor Rabin. En agosto del mismo año, Hodgson participó en la Fairport Convention interpretando los temas «Breakfast In America», «The Logical Song», «Open The Door» y «Give A Little Bit».
Durante 2001, Hodgson salió de gira como miembro del grupo All-Starr Band de Ringo Starr. Desde 2004 y hasta la actualidad, Hodgson ha emprendido giras anuales en las que combina actuaciones en solitario, interpretando canciones con la guitarra o con el piano, y conciertos con una banda de apoyo e incluso, en ocasiones, con orquesta, y dejando de lado cualquier trabajo en el estudio de grabación. Su gira de 2004 le llevó a escenarios de Centroeuropa y Canadá, mientras que en 2005 amplió sus conciertos a Estados Unidos y ofreció su primer concierto en veinte años en Londres, grabado para un futuro lanzamiento en DVD que se desechó. En su lugar, el concierto ofrecido en el Place Des Arts de Montreal el 6 de junio de 2006 fue publicado en el DVD "Take The Long Way Home - Live in Montreal", certificado como disco de platino por la Canadian Recording Industry Association. El DVD fue publicado a nivel global por Eagle Vision en 2007 y fue certificado como disco de oro en Alemania y Francia.

En mayo de 2006, Hodgson fue honrado por la ASCAP en reconocimiento de su canción «Give A Little Bit», por ser una de las más interpretadas del catálogo de ASCAP en 2005. Dos años después fue premiado nuevamente por la ASCAP por la canción de Gym Class Heroes «Cupid’s Chokehold», un "remake" de la canción «Breakfast in America» con amplia difusión comercial en 2007.

Durante su gira de 2007, Hodgson participó en el "Concert for Diana" organizado el 1 de julio en el Estadio de Wembley, interpretando un popurrí de sus canciones más conocidas: «The Logical Song», «Dreamer», «Breakfast in America» y «Give A Little Bit».
En 2009 ofreció conciertos en Europa y Norteamérica, visitó por primera vez países como Ecuador, Venezuela y participó en el Festival Internacional de la Canción de Viña del Mar en Chile y en el Festival Cultural Zacatecas de México. En 2010 organizó una nueva gira mundial con nuevos conciertos en Norteamérica, Sudamérica y Europa, visitando por primera vez países como Panamá.

En 2010, su compañero Rick Davies volvió a reformar Supertramp para emprender una gira con motivo del 40º aniversario del grupo. La promoción de la gira con canciones de Hodgson provocó el enfado de Roger, según el cual el uso de sus canciones rompe un acuerdo verbal entre él y Rick de no interpretarlas a cambio de mantener Davies el nombre de Supertramp. Ante esta situación, Hodgson mantuvo la línea de años anteriores y ofreció conciertos en solitario a nivel mundial, y publicó en octubre "Classics Live", un álbum en formato digital con canciones interpretadas durante la gira de 2010.

El 10 de abril de 2012, Hodgson comenzó la gira "Breakfast In America Tour" en Sudamérica, pasando por países como Ecuador, Perú, Chile, Argentina, Brasil y México. El 4 de mayo de 2012 fue nombrado Caballero de la Orden de las Artes y las Letras por el Ministerio de Cultura de Francia en reonocimiento a su contribución al mundo del arte.


https://www.facebook.com/rogerhodgsonspain/

Roger Hodgson Spain


</doc>
<doc id="15518" url="https://es.wikipedia.org/wiki?curid=15518" title="Hortaliza">
Hortaliza

Las hortalizas son un conjunto de plantas cultivadas generalmente en huertas o regadíos, que se consumen como alimento, ya sea de forma cruda o preparadas culinariamente, y que incluye las verduras y las legumbresverdes (las habas y los guisantes). Las hortalizas no incluyen las frutas ni los cereales.

Sin embargo, esta distinción es arbitraria y no se basa en ningún fundamento botánico. La Real Academia Española no reconoce esta taxonomía, y circunscribe esta acepción a los cultivos realizados en un huerto


Valor calórico. La mayor parte de las hortalizas son hipocalóricas. Por ejemplo, 100g de acelgas sólo contienen 15 calorías. La mayoría no superan las 50 calorías por 100g, excepto las alcachofas y las papas. Debido a este bajo valor calórico, las hortalizas deberían estar presentes en un gran porcentaje en una dieta contra la obesidad.

Todas estas propiedades hacen que sea recomendable consumirlas con bastante frecuencia y diariamente: se recomienda una ración en cada comida y de la forma más variada posible. Por eso las hortalizas ocupan el segundo piso, junto con las frutas, en la pirámide de los alimentos. Vale aclarar que esta pirámide es sólo una de las teorías existentes en la alimentación humana: existen otras pirámides nutricionales, como las que plantean el vegetarianismo, el veganismo o el crudiveganismo.

Las hortalizas frescas deben conservarse adecuadamente hasta el momento del consumo. Las condiciones y duración del almacenamiento influyen mucho en el aspecto y valor nutritivo. La mayoría de las hortalizas deben conservarse a temperaturas bajas con una alta humedad ambiental, por lo que el verdulero del refrigerador es el lugar más recomendable. Se aconseja ponerlas en bolsas agujereadas o con láminas de aluminio, y evitar que el envase sea hermético. En el frigorífico se pueden conservar algunos días, según la clase de hortaliza. Por ejemplo, las espinacas, la lechuga, etc, no conviene tenerlas más de 3 días; sin embargo, las zanahorias, los nabos y la remolacha son menos sensibles, y se conservan durante más tiempo. Algunas hortalizas, como las cebollas y los ajos secos, no precisan ser conservadas en el refrigerador, sino que es más adecuado un lugar seco y aireado.

Las verduras son partes de las plantas herbáceas que son idóneas para el consumo humano. Estos componentes comestibles de la planta pueden ser tallos, hojas, raíces, flores y frutos. El valor nutritivo de las verduras define la presencia de esas sustancias esenciales que son importantes para mantener la vida. Los científicos categorizan las verduras como nutracéuticos, porque son una mezcla de nutrición y farmacéutica: ciertas sustancias químicas presentes en los vegetales tienen un gran valor medicinal.

Las hortalizas se han de lavar o cepillar cuidadosamente antes de ser consumidas, según se trate de hojas, raíces o tubérculos. Cuando no se puedan pelar, hay que limpiarlas mucho, sobre todo si tienen la piel rugosa o peluda. Las hortalizas que se coman crudas deberían sumergirse en agua con unas gotas de lejía diluida durante unos cinco minutos, y después limpiarlas con agua corriente. Se debe hacer esto porque las hortalizas se riegan a veces con aguas no potables que pueden contener numerosas bacterias, y el agua de riego entra en contacto con la hortaliza, que suele estar a ras de suelo.

Las vitaminas de las hortalizas se destruyen con la exposición a la luz, el aire y el calor. Las sales minerales se disuelven en el agua al cocer las hortalizas. Para poder beneficiarse de las vitaminas, de los minerales y del sabor, es preciso cocinar las hortalizas con poca agua (o, mejor, con vapor) y de una forma muy rápida, sumergiéndolas directamente en agua hirviendo. El recipiente de cocción debe mantenerse tapado y evitar moverlo (o moverlo lo menos posible). El agua de cocción debería aprovecharse para hacer sopas, consomés y otro tipo de caldos, porque en el agua de cocción es donde se concentran los minerales. Las hortalizas cocidas que no se vayan a consumir en el momento deben enfriarse y guardarse en el refrigerador. Después se pueden volver a calentar, pero durante poco tiempo.


</doc>
<doc id="15519" url="https://es.wikipedia.org/wiki?curid=15519" title="Etnografía de Venezuela">
Etnografía de Venezuela

La etnografía de Venezuela se caracteriza por ser el resultado de la mezcla de tres grupos étnicos principales: amerindios, europeos y africanos subsaharianos. Los mestizos representan la mitad de la población, seguido por los blancos, negros e indígenas americanos. Otros grupos, como los asiáticos, se han incorporado recientemente a la etnografía venezolana.

Se han realizado algunos estudios genéticos para determinar la composición étnica del individuo venezolano, los cuales han entregado las siguientes contribuciones:

De acuerdo con el censo de 2011, cuando se les preguntó a las personas acerca de su origen étnico-racial, con las opciones: "Negro", "Moreno", "Blanco", "Afrodescendiente" u "Otro" un 51,6 % de la población dijo ser morena, 43,6 % se identificó como blanca, un 2,9 % dijo ser negra, 0,7 % dijo ser afrodescendiente y el resto (1,2 %) mencionó que es de otra raza.

En el censo realizado en 2011 se define a "Morena/Moreno: como "Es toda persona cuyas características fenotípicas son menos marcadas o pronunciadas que de la persona definida como negra o negro. Es un término que en algunos contextos puede ser utilizado para suavizar las implicaciones discriminatorias que conlleva ser una persona negra." 

Se aplica el término "moreno" a personas con una apariencia intermedia entre los estereotipos indígenas, europeos y africanos. Los morenos están distribuidos en toda Venezuela. El mestizaje en Venezuela comenzó en el siglo XVI cuando los conquistadores y colonos españoles se unían con mujeres indígenas o africanas, debido a la escasez de mujeres españolas en el país. También había enlaces entre esclavos africanos y mujeres indígenas, dando origen a los zambos. 

Los inmigrantes europeos eran al principio colonos españoles. En el siglo XX llegaron millones de personas provenientes de España, Portugal, Italia, Alemania y Europa oriental, etc, debido a la Segunda Guerra Mundial, la Guerra Civil Española y el crecimiento económico del país, aportando a la sociedad venezolana nuevas formas culturales como gastronómica, infraestructura, etc. En el área metropolitana de Caracas se concentra la mayoría de los europeos inmigrados después de la segunda guerra mundial

La población negra africana fue traída como esclava, sobre todo en las tierras bajas costeras, comenzando a principios del siglo XVI, y continuando hasta el siglo XIX. Actualmente, representa el 2.8% de la población venezolana.

Muchos de los pueblos indígenas fueron absorbidos por el mestizaje, pero aún existen grupos indígenas que mantienen su cultura e idiomas propios. De acuerdo al censo de 2011, la población indígena del país ascendía a 725.128 personas, lo que representa el 2,7% del total nacional. El 36,74% de los indígenas todavía vivía en comunidades indígenas de carácter rural, especialmente en los de Zulia, Bolivar, Amazonas y Delta Amacuro. Dentro de la población que se autorreconoció como originaria, un 57,3% dijo ser de la etnia wayúu; 6,7% warao, 4,7% kariña, 4,2% pemón; el 3% cada uno, jivi, cumanagoto, añu y piaroa; 2% chaima, pume y yukpa y 1,3% yanomami.

La comunidad colombiana en Venezuela es relativamente grande, sobre todo por los descendientes, debido al conflicto armado interno en Colombia, aunque se ha visto una disminución de su población residente, aun así representan más del 20% de la población venezolana junto con sus descendientes. Hay también inmigrantes provenientes de países andinos y antillanos. Como consecuencia de las dictaduras militares en el Cono Sur, llegaron exiliados argentinos, uruguayos y chilenos en el siglo pasado. Un grupo creciente es el de los asiáticos y árabes, especialmente libaneses, sirios y chinos.



</doc>
<doc id="15521" url="https://es.wikipedia.org/wiki?curid=15521" title="Laika">
Laika

Laika (en ruso "Лайка", ‘ladradora’; Moscú, 1954 - Sputnik 2, Órbita baja terrestre, 3 de noviembre de 1957) fue una perra espacial soviética que se convirtió en el primer ser vivo terrestre en orbitar la Tierra. Lo hizo a bordo de la nave soviética Sputnik 2, el 3 de noviembre de 1957, un mes después que el satélite Sputnik 1. También fue el primer animal que murió en órbita.

Como se sabía poco sobre los efectos que los vuelos espaciales podían producir sobre los seres vivos en el momento de la misión de Laika y, la tecnología suborbital no se había desarrollado todavía, no se tenía ninguna expectativa de que Laika sobreviviera. Algunos científicos creían que los humanos no podrían sobrevivir al lanzamiento o a las condiciones del espacio exterior, por eso los ingenieros de vuelo vieron a los vuelos de animales como los precursores necesarios para las misiones humanas. Laika, una perra callejera, originalmente llamada Kudryavka (Кудрявка, ‘pequeña de pelo rizado’), fue sometida a entrenamiento con otros dos perros, y finalmente fue elegida como la tripulante de la nave espacial soviética Sputnik 2, lanzada al espacio exterior el 3 de noviembre de 1957.

Laika murió horas después del lanzamiento por sobrecalentamiento que probablemente fue ocasionado por un fallo del sustentador de la central R-7, que forma parte del sistema térmico de la nave, al separarse de la carga útil. La verdadera causa y tiempo de su muerte no fue revelada sino hasta 2002; en cambio, fue ampliamente informado que había muerto cuando al sexto día, se quedó sin oxígeno, o como el gobierno soviético alegó inicialmente, fue sometida a eutanasia antes del agotamiento del oxígeno. El experimento demostró que es posible que un pasajero vivo sobreviva al ser puesto en órbita y soportar la microgravedad, allanando el camino para los vuelos espaciales humanos y proporcionando a los científicos algunos de los primeros datos sobre cómo los organismos vivos reaccionan a los entornos de los vuelos espaciales. Tras Laika, la URSS envió doce perros más al espacio, de los cuales cinco regresaron con vida a la Tierra.

El 11 de abril de 2008, las autoridades rusas desvelaron un monumento a Laika. Este pequeño monumento en su honor fue construido cerca del centro de investigación militar en Moscú que preparó el vuelo de Laika al espacio. Cuenta con la figura de un perro que se coloca en la parte superior de un cohete.

Tras el éxito del Sputnik 1, el líder soviético Nikita Jrushchov solicitó que se lanzara un segundo satélite artificial al espacio para el día del cuadragésimo aniversario de la revolución bolchevique, el 7 de noviembre de 1957. Cuando se recibió esta solicitud, ya se estaba construyendo un satélite más sofisticado, pero que no estaría listo sino hasta un mes después de la fecha requerida, por lo que fue descartado. El satélite descartado, sería el Sputnik 3.

Para cumplir con la fecha límite de noviembre, tendría que construirse una nueva nave. Específicamente, Kruschev quería ofrecerle a sus ingenieros un "espacio espectacular", una misión que repetiría el triunfo del Sputnik I, aturdiendo al mundo con proezas soviéticas. Los planes se asentaron en un vuelo orbital con un perro. Los ingenieros soviéticos de cohetes habían previsto con antelación una órbita "canina" antes de intentar vuelos espaciales humanos; desde 1951, habían lanzado 12 perros al espacio suborbital en vuelos balísticos, trabajando gradualmente hacia una misión orbital posiblemente en algún momento de 1958. Para satisfacer las demandas de Jruschov, el vuelo orbital canino fue acelerado para su lanzamiento en noviembre.

Según fuentes rusas, la decisión oficial de lanzar el Sputnik 2 se realizó el 10 o 12 de octubre, dejando al equipo solo cuatro semanas para diseñar y construir la nave espacial. El Sputnik 2, por lo tanto, tenía algo de un trabajo urgente, con la mayoría de los elementos de la nave espacial siendo construidos basándose en bocetos. Además de la misión principal de envío de un pasajero para vivir en el espacio, el Sputnik 2 también contenía instrumentación para la medición de la radiación solar y rayos cósmicos.

La nave estaba equipada con un sistema de soporte vital que consistía en un generador de oxígeno y aparatos para evitar envenenamiento por oxígeno, también conocido como "efecto de Paul Bert", y para absorber dióxido de carbono. Se añadió un ventilador, diseñado para activarse cuando la temperatura de la cabina superaba los 15 °C, con el propósito de mantener la temperatura del animal. Se proporcionó suficiente comida (en forma gelatinosa) para un vuelo de siete días, y la perra fue equipada con una bolsa para recoger los residuos. Adicionalmente, se diseñó un arnés para ser colocado al animal, por lo que no había cadenas para restringir sus movimientos al sentarse, ponerse de pie o acostarse; ya que en la cabina no había espacio para dar vueltas. Un electrocardiograma monitorizaba la frecuencia cardíaca y la instrumentación adicional medía la frecuencia respiratoria, la presión arterial máxima y los movimientos de la perra.

Laika fue encontrada como una perra callejera vagando por las calles de Moscú. Los científicos soviéticos optaron por utilizar perros callejeros de Moscú ya que se asumía que estos animales ya habían aprendido a soportar las condiciones extremas de frío y de hambre. Este espécimen era una hembra mestiza de 5 kg (11 libras) de aproximadamente tres años de edad. Otro relato informó que pesaba alrededor de 6 kg (13 lb). El personal soviético le dio varios nombres y apodos, entre ellos Kudryavka ("rizadita"), después Zhuchka ("bichito"), y luego Limonchik ("limoncito"). Laika, el nombre ruso de semejantes al husky, sería el nombre popularizado en todo el mundo. La prensa norteamericana la apodó Muttnik ("mutt" + el sufijo -nik) como un juego de palabras sobre el Sputnik, o también se refería a ella como "Curly". Su verdadero pedigrí es desconocido, aunque en general se acepta que fue parte husky u otra raza nórdica, y posiblemente parte terrier. Una revista rusa describió su temperamento como "flemático", argumentando que no se peleaba con otros perros. Vladimir Yazdovsky, quien dirigió el programa de perros de prueba utilizados en cohetes, en una publicación tardía escribió que «"Laika era tranquila y encantadora"».

Antes del lanzamiento del Sputnik 2, tanto la Unión Soviética como Estados Unidos, ya habían lanzado animales vivos en vuelos suborbitales. Para el vuelo del Sputnik 2, fueron entrenados tres perros: Albina, Mushka, y Laika. Los científicos soviéticos de vida espacial Vladimir Yazdovsky y Oleg Gazenko fueron los encargados de entrenar a los perros.

Adaptar los perros al confinado espacio de la pequeña cabina del Sputnik 2 requirió que permanecieran en compartimientos cada vez menores, por espacios de hasta 20 días. El extenso confinamiento causó que dejasen de orinar o defecar, haciéndolos inquietos, y causando que se deteriorase su estado general. Los laxantes que les suministraron no mejoraron su condición, por lo que los investigadores encontraron que lo único que resultaba eficaz eran los largos periodos de entrenamiento. Los perros fueron luego colocados en centrifugadoras que simulaban la aceleración del lanzamiento de un cohete y se colocaron en máquinas que simulaban los ruidos de la nave espacial. Esto hizo que sus impulsos cardíacos se duplicasen y su presión arterial aumentase un 30-65 torr. Los perros fueron también entrenados para comer un gel especial de alta nutrición que sería su comida en el espacio.

Antes de la puesta en marcha, uno de los científicos llevó a Laika a su casa para que jugase con sus hijos. En un libro que relata la historia de la medicina espacial soviética, el Dr. Vladimir Yazdovsky escribió: "Quería hacer algo bueno por ella: Le quedaba tan poco tiempo de vida."

Vladimir Yazdovsky hizo la selección final de perros y designó sus roles. Laika iba a ser la "perra voladora" —un sacrificio a la ciencia en una misión de ida al espacio. Albina, que ya había volado dos veces en un cohete de prueba a gran altura, se designó como reserva de Laika. El tercer perro, Mushka, era un "perro de control" -se quedaría en tierra y era usada para probar la instrumentación y el soporte vital.

Antes de partir hacia el cosmódromo de Baikonur, Yazdovsky y Gazenko realizaron una cirugía en los perros para conectar los cables de los transmisores a los sensores que medían la respiración, el pulso y la presión arterial.

Debido a que la pista de aterrizaje existente en Turatam, cerca del cosmódromo resultaba pequeña, los perros y la tripulación tuvieron que volar primero a bordo de un avión Tu-104 a Tashkent. Desde allí, un Il-14 más pequeño y ligero los llevó a Turatam. El entrenamiento de perros continuó a su llegada, y uno tras otro fueron colocados en las cápsulas para familiarizarse con el sistema de alimentación.

Según los documentos de la NASA, Laika fue colocada en la cápsula del satélite el 31 de octubre de 1957 —tres días antes del inicio de la misión. En esa época del año, las temperaturas en el sitio de lanzamiento eran extremadamente bajas, por lo que se usó una manguera conectada a un calentador para mantener caliente el contenedor. Dos asistentes estaban encargados de vigilar constantemente a Laika antes del comienzo de la misión. Justo antes del despegue, el 3 de noviembre de 1957, se limpió el pelaje de Laika con una solución de etanol, y le pintaron con yodo aquellas áreas donde la perra llevaría sensores para vigilar sus funciones corporales.

Uno de los técnicos que preparó la cápsula antes del despegue final declaró que "después de la colocación de Laika en el contenedor y antes de cerrar la escotilla, le besamos la nariz y le deseamos buen viaje, sabiendo que no iba a sobrevivir al vuelo."

La hora exacta del despegue varía de una fuente a otra, pero se menciona que fue a las 05:30:42 o a las 7:22 hora de Moscú. Al alcanzar la máxima aceleración después del despegue, el ritmo respiratorio de Laika aumentó de tres a cuatro veces lo normal, y su frecuencia cardiaca pasó de 103 a 240 latidos por minuto. Al alcanzar la órbita, se desprendió exitosamente la punta cónica del Sputnik 2. La otra sección de la nave que debía desprenderse (el "Blok A") no lo hizo, impidiendo que el sistema de control térmico funcionara correctamente. Se desprendió parte del aislamiento térmico, permitiendo que la cápsula alcanzara una temperatura interior de 40 °C. Tras tres horas de microgravedad, el pulso de Laika había descendido a 102 latidos por minuto; este descenso en la frecuencia cardíaca había tomado tres veces más tiempo que lo experimentado durante el entrenamiento, lo cual indicaba el estrés bajo el que estaba la perra. Los datos telemétricos iniciales mostraban que, aunque Laika estaba agitada, estaba comiendo. La recepción de datos vitales se detuvo entre cinco y siete horas después del despegue.

Los científicos soviéticos planearon sacrificarla con comida envenenada, que Laika consumiría después de diez días. Durante muchos años, la Unión Soviética dio explicaciones contradictorias sobre la muerte de Laika, diciendo a veces que la perra había muerto por falta de oxígeno cuando fallaron las baterías, o que había recibido eutanasia. En 1999, fuentes rusas aseguraron que Laika sobrevivió por lo menos cuatro días, y después pereció por el sobrecalentamiento de la nave. En octubre de 2002, el científico Dimitri Malashenkov, quien participó en el lanzamiento del Sputnik 2, reveló que Laika había muerto entre cinco y siete horas después del despegue, debido al estrés y sobrecalentamiento. De acuerdo a un artículo que presentó en el Congreso Mundial del Espacio en Houston:
El Sputnik 2 orbitó la Tierra 2.570 veces, durante 163 días. La nave se desintegró al entrar en contacto con la atmósfera el 14 de abril de 1958.

Debido al problema de la opacidad por la carrera espacial entre los Estados Unidos y la Unión Soviética, las cuestiones éticas planteadas por este experimento pasaron, en gran medida, sin abordarse durante algún tiempo. La prensa de 1957 estaba más preocupada en informar del impacto desde el punto de vista político, mientras que la salud y la recuperación —o la ausencia— de Laika se convirtió solo en un problema menor.

El Sputnik 2 no fue diseñado para ser recuperable, y siempre se tuvo la intención de que Laika muriera. La misión desencadenó un debate mundial sobre el maltrato y experimentos con animales en general, para avanzar en la ciencia. En el Reino Unido, la Liga Nacional de Defensa Canina ("NCDL", actualmente "Fundación para los Perros") pidió que los dueños de perros guardaran un minuto de silencio en honor a Laika, mientras que la Real Sociedad para la Prevención de la Crueldad contra los Animales (RSPCA) recibiera protestas, incluso antes de que Radio Moscú haya terminado de anunciar el lanzamiento. Varios grupos protectores de los derechos animales protestaron frente a embajadas soviéticas. Otros se manifestaron frente a las Naciones Unidas en Nueva York; sin embargo, algunos científicos estadounidenses ofrecieron apoyo a sus colegas soviéticos, por lo menos antes de que se anunciara la muerte de Laika.

Dentro de la Unión Soviética hubo menos controversia. Ni los medios de comunicación, ni los libros de los años siguientes, ni el público cuestionaron abiertamente la decisión de enviar un perro al espacio. No fue sino hasta 1998, después del colapso del régimen soviético, que Oleg Gazenko, uno de los científicos responsables del envío de Laika al espacio, expresó su pesar por permitir que muriese:

En otros países del Pacto de Varsovia era difícil realizar protestas abiertas del programa espacial soviético debido a la censura política. Sin embargo, hubo casos notables de críticas en los círculos científicos polacos. Una revista científica polaca, "Kto, Kiedy, Dlaczego", publicada en 1958, se refirió a la misión del Sputnik 2. En la sección de la revista dedicada a la astronáutica Krzysztof Boruń la describió no trayendo a Laika a la Tierra con vida como "lamentable" y "sin duda, una gran pérdida para la ciencia".

Laika es conmemorada en la forma de una estatua y placa en la Ciudad de las Estrellas, el centro ruso de Entrenamiento de Cosmonautas.

Las futuras misiones espaciales que llevasen perros serían diseñadas para ser recuperadas. Los únicos otros perros que murieron en una misión espacial soviética fueron Pchyolka y Mushka, que murieron cuando el Sputnik 6 fue destruido intencionalmente con una carga explosiva, a su reingreso, con el fin de evitar que las potencias extranjeras inspeccionaran la cápsula, debido a una trayectoria de reentrada atmosférica descontrolada, el 1 de diciembre de 1960.

El viaje de Laika la convirtió en uno de los perros más famosos del mundo.
En 1997, en la Ciudad de las Estrellas, fue desvelada una placa en homenaje a los cosmonautas caídos. Laika está representada en una esquina de la placa, espiando por entre las piernas de uno de los cosmonautas.
En el "Monumento a los Conquistadores del Espacio" (1964), en Moscú, Laika y Lenin son los únicos personajes que se pueden reconocer por su nombre, de entre todos los personajes que aparecen esculpidos en el monumento.
En distintos países se crearon sellos de correo con la imagen de la perra Laika, conmemorando su vuelo. Marcas de chocolates y cigarros fueron nombradas en su memoria, y una gran colección de souvenirs de Laika todavía aparece en subastas actualmente. 
El 9 de marzo de 2005, un área de terreno en el planeta Marte fue llamada "Laika", aunque no oficialmente, por los controladores de la misión del Mars Exploration Rover. El lugar se localiza cerca del cráter "Vostok" en Meridiani Planum.

Laika ha aparecido en numerosas obras literarias, mayormente de ciencia ficción o también de fantasía, que frecuentemente narran historias sobre su rescate o supervivencia. La novela "Intervention" (Intervención) de Julian May, relata que Laika fue rescatada por extraterrestres. En la novela "Weight" (Peso) de Jeanette Winterson, el titán griego Atlas encuentra la cápsula en órbita, y adopta al animal. En la serie Doctor Who se narró una historia sobre su funeral. En un capítulo de la historieta "Flash Gordon" aparece Laika rescatada por una raza de extraterrestres lunares con aspecto perruno.

Los nombres de varios grupos musicales están inspirados en Laika, entre ellos "Laika", "Laika Dog" y "Laika and the Cosmonauts". La perra apareció en la cubierta de los primeros tres álbumes del grupo "Laika". Laika es también el nombre de varias canciones, producidas por las bandas Arcade Fire, Moxy Früvous, The Cardigans. Massacre compuso un tema llamado "Laika se Va" donde relata el viaje desde la perspectiva de la perra. En 1988, el grupo español Mecano, en su álbum Descanso Dominical, incluyó una canción llamada ""Laika"" que relata el lanzamiento del Sputnik 2. La banda alemana "C.C.C.P." lanzó un álbum llamado "Cosmos" en 1996, cuya temática giraba alrededor del programa espacial soviético. En dicho álbum, la canción "Laika, Laika", tiene un coro militar ruso. El álbum "Laika Come Home" (2002) es un remix que el grupo Spacemonkeyz hizo del primer álbum de la banda Gorillaz. El título es una mezcla del nombre de la perra rusa, con el título de la primera película de la perra Lassie ("Lassie come home"). Antonio Arias en su disco "Multiverso" (2010) le dedica una canción, "Laika". Además, la perra ha sido tema de otros artistas como Akino Arai, György Kurtág y Åge Aleksandersen entre muchos otros.

El 11 de abril de 2008 fue inaugurado un monumento en honor a la perra Laika en el centro de Moscú.
Dicho monumento fue colocado en un centro comercial cerca del Instituto de Medicina Militar, donde medio siglo atrás ocurrieron los experimentos científicos con la participación de la célebre perra. La figura de bronce, de dos metros de altura, representa uno de los segmentos de un cohete espacial, que se transforma en una mano humana, sobre la cual está el cuerpo de Laika.





</doc>
<doc id="15523" url="https://es.wikipedia.org/wiki?curid=15523" title="Gases nobles">
Gases nobles

Los gases nobles son un grupo de elementos químicos con propiedades muy similares: por ejemplo, bajo condiciones normales, son gases monoatómicos inodoros, incoloros y presentan una reactividad química muy baja. Se sitúan en el grupo 18 (VIIIA) de la tabla periódica (anteriormente llamado grupo 0). Los siete gases son helio (He), neón (Ne), argón (Ar), kriptón (Kr), xenón (Xe), el radiactivo radón (Rn) y el sintético oganesón (Og).

Las propiedades de los gases nobles pueden ser explicadas por las teorías modernas de la estructura atómica: a su capa electrónica de electrones valentes se la considera "completa", dándoles poca tendencia a participar en reacciones químicas, por lo que solo unos pocos compuestos de gases nobles han sido preparados hasta 2008. El xenón reacciona de manera espontánea con el flúor (debido a la alta electronegatividad de este), y a partir de los compuestos resultantes se han alcanzado otros. También se han aislado algunos compuestos con kriptón. Los puntos de fusión y de ebullición de cada gas noble están muy próximos, difiriendo en menos de 10°C; consecuentemente, solo son líquidos en un rango muy pequeño de temperaturas.

El neón, argón, kriptón y xenón se obtienen del aire usando los métodos de licuefacción y destilación fraccionada. El helio es típicamente separado del gas natural y el radón se aísla normalmente a partir del decaimiento radioactivo de compuestos disueltos del radio. Los gases nobles tienen muchas aplicaciones importantes en industrias como iluminación, soldadura y exploración espacial. La combinación helio-oxígeno-nitrógeno (trimix) se emplea para respirar en inmersiones de profundidad para evitar que los buzos sufran el efecto narcótico del nitrógeno. Después de verse los riesgos causados por la inflamabilidad del hidrógeno, este fue reemplazado por helio en los dirigibles y globos aerostáticos.

"Gas noble" es una traducción del nombre alemán , usado por primera vez en 1898 por Hugo Erdmann, para indicar su extremadamente bajo nivel de reactividad. El nombre hace una analogía con el término «metales nobles», como el oro, asociado con riqueza y nobleza, y que tiene también una baja reactividad. También se ha dado a los gases nobles el nombre "gases inertes", pero esta etiqueta ha sido desaprobada a medida que los gases nobles se han ido conociendo más. "Gases raros" es otro término que se ha utilizado, pero también es incorrecto porque el argón conforma una parte bastante considerable (0,94 % por volumen, 1,3 % por masa) de la atmósfera terrestre.

Pierre Janssen y Joseph Norman Lockyer fueron los primeros en descubrir un gas noble el 18 de agosto de 1868 cuando examinaban la cromosfera del Sol, y lo llamaron helio a partir de la palabra griega para el Sol, (""). Anteriormente, en 1784, el químico y físico inglés Henry Cavendish había descubierto que el aire contenía una pequeña proporción de una sustancia menos reactiva que el nitrógeno. Un siglo más tarde, en 1895, lord Rayleigh descubrió que las muestras de nitrógeno del aire son de diferente densidad que las del nitrógeno como consecuencia de reacciones químicas. En colaboración con William Ramsay, científico del University College de Londres, Lord Rayleigh postuló que el nitrógeno extraído del aire se encontraba mezclado con otro gas y ejecutó un experimento que consiguió aislar exitosamente un nuevo elemento: el argón, palabra derivada del griego ("argós"), "inactivo". A partir de este descubrimiento, notaron que faltaba una clase completa de gases en la tabla periódica. Durante su búsqueda del argón, Ramsay también consiguió aislar el helio por primera vez, al calentar cleveíta, un mineral. En 1902, después de aceptar la evidencia de la existencia de los elementos helio y argón, Dmitri Mendeléyev incluyó estos gases nobles como Grupo 0 en su clasificación de elementos, que posteriormente se convertiría en la tabla periódica.

Ramsay continuó con la búsqueda de estos gases usando el método de la destilación fraccionada para separar aire líquido en varios componentes. En 1898, descubrió el kriptón, el neón y el xenón, llamados así a partir del griego (', "oculto"), (', "nuevo"), y ("", "extraño"), respectivamente. Por su parte, el radón fue identificado por primera vez en 1898 por Friedrich Ernst Dorn, y se le llamó "emanación de radio", pero no fue considerado como un gas noble hasta 1904, cuando se determinó que sus características eran similares a las de los otros gases nobles. Ese mismo año, Rayleigh y Ramsay recibieron el Premio Nobel de Física y Química, respectivamente, por el descubrimiento de los gases nobles.

El descubrimiento de los gases nobles ayudó a la compresión de la estructura atómica. En 1895, el químico francés Heri Moissan intentó infructuosamente producir una reacción entre el flúor, el elemento más electronegativo, y el argón, uno de los gases nobles, con el fin de aislar de la atmósfera aquellos gases caracterizados por su extraordinaria inercia química, comenzando por el que está en mayor abundancia relativa, y de crear nuevos elementos o compuestos. Los científicos fueron incapaces de producir compuestos de argón hasta fines del siglo XX, pero sus intentos ayudaron a desarrollar nuevas teorías de la estructura atómica. Basándose en estos experimentos, el físico danés Niels Bohr propuso en 1913 que los electrones en los átomos se encontraban ordenados en capas electrónicas en torno al núcleo y que en el caso de los gases nobles, exceptuando al helio, la capa exterior siempre contenía ocho electrones. En 1916, Gilbert N. Lewis formuló la regla del octeto, la cual concluye que la configuración más estable para cualquier átomo es contar con ocho electrones en la capa exterior; esta configuración produce elementos que no reaccionan con otros, ya que no necesitan más electrones para completar su capa exterior.

En 1962 Neil Bartlett descubrió el primer compuesto químico de un gas noble, el hexafluoroplatinato de xenón. Compuestos de otros gases nobles fueron descubiertos poco después: en 1962, el fluoruro de radón, y en 1963, el difluoruro de kriptón (KrF). El primer compuesto estable de argón se reportó en 2000 cuando se formó el fluorohidruro de argón a una temperatura de 40 K (−233,2 °C; −387,7 °F).

En diciembre de 1998, científicos del Joint Institute for Nuclear Research trabajando en Dubna, Rusia, bombardearon plutonio (Pu) con calcio (Ca) para producir un único átomo del elemento 114, bajo el nombre Flerovio (Fl). Experimentos químicos preliminares indican que este elemento puede ser el primer elemento transuránico en mostrar propiedades anormales y parecidas a las de los gases nobles, aún cuando es miembro del grupo 14 en la tabla periódica. En octubre de 2006, científicos del Joint Institute for Nuclear Research y del Lawrence Livermore National Laboratory sintetizaron exitosamente el oganesson (Og), el séptimo elemento en el Grupo 18, al bombardear californio (Cf) con calcio (Ca). Como curiosidad cabe indicar que la discusión científica sobre la posibilidad de licuar estos gases dio lugar al descubrimiento de la superconductividad por el físico holandés Heike Kamerlingh Onnes.

Los gases nobles cuentan con fuerzas intermoleculares muy débiles y, por lo tanto, tienen puntos de fusión y de ebullición muy bajos. Todos ellos son gases monoatómicos bajo condiciones estándar, incluyendo aquellos que tienen masas atómicas mayores que algunos elementos que se encuentran normalmente en estado sólido. El helio tiene varias propiedades únicas con respecto a otros elementos: tanto su punto de ebullición como el de fusión son menores que los de cualquier otra sustancia conocida; es el único elemento conocido que presenta superfluidez; de la misma manera no puede ser solidificado por enfriamiento bajo condiciones estándar, sino que se convierte en sólido bajo una presión de 25 atm (2500 kPa; 370 psi) y 0,95 K (−272,20 °C; −457.960 °F). Los gases nobles hasta el xenón tienen múltiples isótopos estables. El radón no tiene isótopos estables; su isótopo de mayor duración tiene un periodo de semidesintegración de 3,8 días que puede formar helio y polonio.

El radio atómico de los gases nobles aumenta de un periodo a otro debido al incremento en el número de electrones. El tamaño del átomo se relaciona con varias propiedades. Por ejemplo, el potencial de ionización disminuye a medida que aumenta el radio ya que los electrones de valencia en los átomos más grandes se encuentran más alejados del núcleo y, por lo tanto, no se encuentran ligados tan fuertemente por el átomo. Los gases nobles tienen los mayores potenciales de ionización de cada periodo, lo cual refleja lo estable que es su configuración electrónica y genera su falta de reactividad química. Sin embargo, algunos de los gases nobles más pesados tienen potenciales de ionización lo suficientemente bajos para ser comparables a los de otros elementos y moléculas. El químico Neil Bartlett, intentando crear el compuesto de un gas noble, notó que el potencial de ionización del xenón era similar al de la molécula de oxígeno, por lo que intentó oxidar xenón usando hexafluoruro de platino, un agente oxidante tan fuerte que es capaz de reaccionar con oxígeno. Los gases nobles no pueden aceptar un electrón para formar aniones estables. Esto quiere decir que poseen una afinidad electrónica negativa.

Las propiedades físicas macroscópicas de los gases nobles están determinadas por las débiles fuerzas de Van der Waals que se dan entre átomos. Las fuerzas de atracción aumentan con el tamaño del átomo como un resultado del incremento en la polarizabilidad y el descenso del potencial de ionización. Esto lleva a tendencias grupales sistemáticas. Por ejemplo, a medida que se baja en los grupos de la tabla periódica, el radio atómico y las fuerzas interatómicas aumentan. De igual forma, se adquieren mayores puntos de fusión y de ebullición, entalpía de vaporización y solubilidad. El aumento de densidad se debe al incremento en masa atómica.

Los gases nobles se comportan como gases ideales bajo condiciones normales de presión y temperatura, pero sus tendencias anormales a la ley de los gases ideales proporcionan claves importantes para el estudio de las fuerzas e interacciones moleculares. El potencial de Lennard-Jones, usado frecuentemente para modelar fuerzas intermoleculares, fue deducido en 1924 por John Lennard-Jones a partir de datos experimentales del argón antes de que el desarrollo de la mecánica cuántica proporcionara las herramientas necesarias para entender las fuerzas intermoleculares a partir de primeros principios. El análisis teórico de estas fuerzas se volvió viable debido a que los gases nobles son monoatómicos, y por tanto isótropos (independientes de la dirección).

En los seis primeros periodos de la tabla periódica, los gases nobles son exactamente los miembros del grupo 18 (8A) de la tabla (anteriormente conocido como grupo 0). Sin embargo, esto ya no es cierto en el séptimo periodo (debido a efectos relativistas): el siguiente miembro del grupo 18, el oganesson, probablemente no es tan gas noble. En cambio, el miembro del grupo 14 Flerovio presenta propiedades similares a las de los gases nobles.

Los gases nobles son incoloros, inodoros, insípidos y no inflamables en condiciones normales. Antiguamente se les asignaba el grupo 0 de la tabla periódica porque se creía que tenían una valencia cero, es decir, que sus átomos no se pueden combinar con otros elementos para formar compuestos. Sin embargo, más tarde se descubrió que algunos sí forman compuestos, haciendo que se abandonara esta denominación. Se conoce muy poco sobre las propiedades del miembro más reciente del grupo 18, el oganesson (oganesson). Los gases nobles tienen capas llenas de electrones de valencia. Los electrones de valencia son los electrones que se encuentran más al exterior de los átomos y normalmente son los únicos que participan en los enlaces químicos. Los átomos con capas de valencia llenas de electrones son extremadamente estables y por tanto no tienden a formar enlaces químicos y tienen poca tendencia a ganar o perder electrones. Sin embargo, los gases nobles más pesados, como el radón, están unidos menos firmemente por la fuerza electromagnética que los más ligeros, como el helio, haciendo que sea más fácil retirar electrones exteriores de los gases nobles pesados. Debido a que dicha capa está completa, los gases nobles se pueden utilizar de acuerdo con la notación de configuración electrónica para dar lugar a una "notación de gases nobles". Para ello, primero se escribe el gas noble más cercano que precede al elemento en cuestión, y se continúa la configuración electrónica a partir de ese punto. Por ejemplo, la notación electrónica del carbono es 1s² 2s² 2p², y su notación de gas noble es [He] 2s² 2p². Esta notación hace que resulte más fácil identificar elementos, y es más corta que escribir toda la notación de orbitales atómicos.

Los gases nobles tienen una reactividad extremadamente baja; a pesar de ello, se han formado una gran cantidad de compuestos de gases nobles. No se han formado compuestos neutros en los que el helio y el neón estén presentes en los enlaces químicos (aunque hay pruebas teóricas de algunos compuestos de helio), mientras que el xenón, el kriptón y el argón solo presentan una reactividad baja. La reactividad sigue el orden Ne < He < Ar < Kr < Xe < Rn.

En 1933, Linus Pauling argumentó que los gases nobles más pesados podían formar compuestos con el flúor y el oxígeno. De igual forma, arguyó la existencia del hexafluoruro de kriptón (KrF) y el hexafluoruro de xenón (XeF), y especuló que el XeF podría existir como compuesto inestable, sugiriendo también que el ácido xénico (HXeO) podía formar sales de perxenato. Se ha demostrado que estas predicciones eran generalmente precisas, salvo que actualmente se cree que el XeF es termodinámica y cinéticamente inestable. Los compuestos de xenón son los más numerosos de los compuestos de gas noble que se han formado. La mayoría de ellos tienen el átomo de xenón en el estado de oxidación +2, +4, +6 o +8 unido a átomos muy electronegativos como el flúor o el oxígeno, como en el fluoruro de xenón (XeF), el tetrafluoruro de xenón (XeF), el hexafluoruro de xenó] (XeF), el tetraóxido de xenón (XeO) y el perxenato de sodio (NaXeO). Algunos de estos compuestos han sido utilizados en la síntesis química como agentes oxidantes; el XeF, en particular, está disponible comercialmente y se puede utilizar como agente fluorador. En 2007, se habían identificado unos quinientos compuestos de xenón unidos a otros elementos, incluyendo compuestos organoxenones (unidos con carbono), así como xenón unido a nitrógeno, cloro, oro, mercurio y al propio xenón. También se han observado compuestos de xenón unido a boro, hidrógeno, bromo, yodo, berilio, azufre, titanio, cobre y plata, pero solo a temperaturas bajas en matrices de gases nobles, o en "jet streams" de gases nobles.

En teoría, el radón es más reactivo que el xenón, y por tanto debería formar enlaces químicos más fácilmente que el xenón. Sin embargo, debido a la gran radiactividad y la corta semivida de los isótopos del radón, en la práctica solo se han formado unos pocos fluoruros y óxidos de radón. El kriptón es menos reactivo que el xenón, pero se han observado diversos compuestos con el kriptón en el estado de oxidación +2. El difluoruro de kriptón es el más notable y fácil de caracterizar. También se han caracterizado compuestos en que el kriptón forma un enlace único con nitrógeno y oxígeno, pero solo son estables por debajo de −60 °C y −90 °C, respectivamente. Se han observado átomos de kriptón unidos químicamente a otros no metales (hidrógeno, cloro, carbono), así como algunos metales de transición tardíos (cobre, plata, oro), pero solo o bien a temperaturas bajas. Se utilizaron condiciones similares para obtener los primeros pocos compuestos de argón en el 2000, como el fluorohidruro de argón (HArF), y algunos unidos a los metales de transición tardíos. En 2007 no se conocían moléculas neutras estables con átomos de helio o neón con enlaces covalentes.

Los gases nobles, incluyendo el helio, pueden formar iones moleculares estables en fase gaseosa. El más simple es el hidrohelio, HeH, descubierto en 1925. Al estar compuesto por los dos elementos más abundantes del universo, el hidrógeno y el helio, se cree que se da naturalmente en el medio interestelar, aunque aún no ha sido detectado. Además de estos iones, hay muchos excímeros neutros conocidos de estos gases. Hay compuestos como ArF y KrF que solo son estables cuando se encuentran en un estado electrónico excitado, y algunos de ellos se emplean en los láseres de excímeros.

Además de los compuestos en que un átomo de gas noble está implicado en un enlace covalente, los gases nobles también forman compuestos no covalentes. Los clatratos, descritos por primera vez en 1949, consisten en un átomo de gas noble atrapado dentro de cavidades de la estructura cristalina de determinadas sustancias orgánicas e inorgánicas. La condición esencial para que se formen es que los átomos invitados (los del gas noble) deben tener el tamaño adecuado para encajar en las cavidades de la estructura cristalina del huésped. Por ejemplo, el argón, el kriptón y el xenón forman clatratos con la hidroquinona, pero el helio y el neón no, pues son demasiado pequeños o tienen una polarizabilidad insuficiente para ser retenidos. El neón, el argón, el kriptón y el xenón también forman hidratos de clatratos; esto quiere decir que los gases nobles quedan atrapados dentro de la capa de helio de dichos compuestos.

Los gases nobles pueden formar compuestos fulerenos endoédricos, en los que el átomo de gas noble está atrapado dentro de una molécula de fullereno. En 1993, se descubrió que cuando se expone C, una molécula esférica compuesta de 60 átomos de carbono, gases nobles a una presión elevada, se pueden formar complejos como He@C (@ indica que He se encuentra contenido dentro de C, pero que no está unido covalentemente). En 2008 se obtuvieron complejos endohédricos con helio, neón, argón, kriptón y xenón. Estos compuestos se utilizan en el estudio de la estructura y la reactividad de los fulerenos mediante la resonancia magnética nuclear del átomo de gas noble.

Se considera que los compuestos de gases nobles, como el difluoruro de xenón (XeF), son hipervalentes, pues violan la regla del octeto. Se puede explicar los enlaces en estos compuestos con un modelo de tres centros y cuatro electrones. Este modelo, propuesto por primera vez en 1951, considera la unión de tres átomos colineales. Por ejemplo, los enlaces de XeF se describen por un conjunto de tres orbitales moleculares derivadas de los orbitales p de cada átomo. Los enlaces resultan de la combinación de un orbital p de Xe con un orbital p medio lleno de cada átomo de F, resultando en un orbital de enlace lleno, un orbital de enlace no lleno, y un orbital de antienlace. El orbital molecular ocupado más alto se encuentra en los dos átomos terminales. Esto representa una localización de la carga facilitada por la alta electronegatividad del flúor. La química de los gases nobles más pesados, el kriptón y el xenón, está bien determinada. La de los más ligeros, el helio y el argón, aún se encuentra en un estado temprano, mientras que aún no se ha identificado algún compuesto de neón.

La abundancia de los gases nobles en el universo disminuye a medida que aumenta su número atómico. El helio es el elemento más común en el universo después del hidrógeno, con una proporción de masa de aproximadamente el 24 %. La mayoría del helio del universo se formó durante la nucleosíntesis primordial, pero la cantidad de helio aumenta constantemente debido a la fusión de hidrógeno en la nucleosíntesis estelar (proceso realizado mediante reacciones nucleares que tiene su origen en las estrellas durante su proceso evolutivo, y que antecede a una supernova por colapso gravitatorio). La abundancia en la Tierra muestra tendencias diferentes; por ejemplo, el helio es solo el tercer gas noble más abundante de la atmósfera. El motivo es que no hay helio primordial en la atmósfera, ya que debido a la pequeña masa de este átomo, el helio no puede ser retenido por el campo gravitatorio terrestre. El helio de la Tierra deriva de la desintegración alfa de elementos pesados como el uranio o el torio de la corteza terrestre, y tiende a acumularse en yacimientos de gas natural. Por otro lado, la abundancia del argón crece como resultado de la desintegración alfa del potasio-40, que también se encuentra en la corteza terrestre, para formar argón-40, que es el isótopo del argón más abundante de la Tierra a pesar de ser relativamente raro en el sistema solar. Este proceso es la base del método de datación por potasio-argón. El xenón tiene una abundancia relativamente baja en la atmósfera, lo que se ha dado a conocer como el «problema del xenón desaparecido»; una teoría es que el xenón que falta podría estar atrapado en minerales dentro de la corteza terrestre. El radón se forma en la litosfera por la desintegración alfa del radio. Se puede filtrar en edificios a través de los cimientos y acumularse en áreas mal ventiladas. Debido a su gran radiactividad, el radón supone un riesgo significativo para la salud; solo en Estados Unidos, está asociado con unas 21.000 muertes por cáncer de pulmón cada año.

El neón, el argón, el kriptón y el xenón se obtienen a partir del aire utilizando los métodos de licuefacción de gases, para convertir los elementos a un estado líquido, y de destilación fraccionada, para separar las mezclas en sus componentes. El helio se produce generalmente separándolo del gas natural, y el radón se aísla de la desintegración radioactiva de los compuestos de radio. El precio de los gases nobles está influido por su abundancia natural, siendo el argón el más barato y el xenón el más caro. Lo ilustra la tabla de la derecha, con los precios en USD de 2004 por cantidades de laboratorio de cada gas.

Los gases nobles tienen un punto de ebullición y de fusión muy bajos, lo que los hace útiles como refrigerantes criogénicos. En particular, el helio líquido, que hierve a 4,2K, se utiliza para imanes superconductores, como los que se emplean para la imagen por resonancia magnética y la resonancia magnética nuclear. El neón líquido, aunque no llega a temperaturas tan bajas como el helio líquido, también tiene aplicaciones en la criogenia, pues tiene una capacidad de refrigeración más de 40 veces superior a la del helio líquido y más de tres veces superior a la del hidrógeno líquido.

El helio se utiliza como componente de los gases respirables para sustituir al nitrógeno, gracias a su baja solubilidad en fluidos, especialmente en lípidos. Los gases son absorbidos por la sangre y los tejidos corporales cuando hay presión, como en el submarinismo, lo que provoca un efecto anestésico conocido como "mal de profundidad". Debido a su baja solubilidad, entra poco helio en las membranas celulares, y cuando se utiliza helio para sustituir parte de los gases respirables, como en el trimix o el heliox, se consigue una reducción del efecto narcótico del gas en profundidad. La baja solubilidad del helio ofrece más ventajas para el trastorno conocido como enfermedad por descompresión. A menor cantidad de gas disuelto en el cuerpo significa que se forman menos burbujas de gas durante la reducción de la presión durante el ascenso. Otro gas noble, el argón, es considerado la mejor opción como gas de inflación del traje seco en el submarinismo.

Desde el desastre del Hindenburg de 1937, el helio ha sustituido al hidrógeno como gas de sustentación en los dirigibles y globos, gracias a su ligereza e incombustibilidad, pese a una reducción en la flotabilidad de un 8,6 %. En muchas aplicaciones, los gases nobles se utilizan para formar una atmósfera inerte. El argón se utiliza en la síntesis de compuestos sensibles al aire que al mismo tiempo, son sensibles al nitrógeno. El argón sólido también se utiliza para estudiar compuestos muy estables, como intermedios reactivos, atrapándolos en una matriz inerte a temperaturas muy bajas. El helio es utilizado como medio portador en la cromatografía de gases, como gas de relleno en los termómetros, y en aparatos para medir la radiación, como el contador Geiger y la cámara de burbujas. Tanto el helio como el argón se utilizan habitualmente para proteger arcos de soldadura y metal base que les rodea de la atmósfera durante la soldadura y la ablación, así como en otros procesos metalúrgicos y la producción de silicio para la industria de los semiconductores.

Los gases nobles se usan habitualmente para la iluminación debido a su falta de reactividad química. El argón, mezclado con nitrógeno, se utiliza como gas de relleno de las bombillas incandescentes. El kriptón se usa en bombillas de alto rendimiento, que tienen una temperatura de color más elevada y una mayor eficacia, pues reduce la velocidad de evaporación del filamento más que el argón, las lámparas de halógeno, en particular, utilizan kriptón mezclado con pequeñas cantidades de compuestos de yodo o bromo. Los gases nobles lucen con colores característicos cuando se les utiliza en lámparas de descarga, como los faros de neón, que producen un color naranja-rojo. El xenón es utilizado habitualmente en faros de xenón que, debido a su espectro casi continuo que se asemeja a la luz del día, se usan en proyectores de películas y como faros de automóvil.

Los gases nobles se usan en láseres de excímeros, que se basan en moléculas excitadas electrónicamente de vida corta conocidas como excímeros. Los excímeros utilizados en los láseres pueden ser dímeros de gases nobles como Ar , Kr o Xe , o más habitualmente, el gas noble es combinado con un halógeno en excímeros como ArF, KrF, XeF o XeCl. Estos láseres producen una luz ultravioleta que, debido a su longitud de onda corta (193 nm por ArF y 248 nm para KrF), permite una imagen de alta precisión. Los láseres de excímeros tienen muchos usos industriales, médicos y científicos. Se utilizan en la microlitografía y la microfabricación, esenciales para la manufactura de circuitos integrados y por cirugía láser, incluyendo la angioplastia láser y la cirugía ocular. Algunos gases nobles tienen un uso directo en la medicina. A veces se usa el helio para mejorar la facilidad de respiración de los pacientes con asma. El xenón se utiliza como anestésico debido a su alta solubilidad en lípidos, que lo hace más potente que el habitual óxido nitroso, y como es eliminado fácilmente por el cuerpo, permite un restablecimiento más rápido. La captación de imágenes hechas a través de la resonancia magnética nuclear utiliza el xenón en combinación con otros gases. El radón, que es muy radiactivo y solo está disponible en cantidad mínimas, sirve en el tratamiento por radioterapia.





</doc>
<doc id="15525" url="https://es.wikipedia.org/wiki?curid=15525" title="Yang Liwei">
Yang Liwei

Yang Liwei (杨利伟) (nacido el 21 de junio de 1963) es un piloto de combate chino, y también el primer astronauta (en el país llamado taikonauta) que China logró enviar al espacio exterior. China es pues el tercer país que concreta esta hazaña, después de la URSS y de los Estados Unidos.

El cohete, un lanzador Larga Marcha 2F, despegó el día 15 de octubre de 2003 de la base de Jiuquan (Mongolia Interior), en el desierto de Gobi. El aterrizaje tuvo lugar 21 horas después del despegue, en un punto cercano a la base.

Durante ese tiempo, el astronauta a bordo de la cápsula Shenzhou 5 ("nave divina"), dio 14 vueltas a la Tierra a 340 kilómetros de altura.


</doc>
<doc id="15528" url="https://es.wikipedia.org/wiki?curid=15528" title="Nobel">
Nobel

El término Nobel puede referirse a:






</doc>
<doc id="15533" url="https://es.wikipedia.org/wiki?curid=15533" title="Ácido ascórbico">
Ácido ascórbico

El ácido ascórbico es un cristal incoloro, inodoro, sólido, soluble en agua, con un sabor ácido. Es un ácido orgánico, con propiedades antioxidantes, proveniente del azúcar.

En humanos, primates y cobayas, entre otros, la vitamina C (enantiómero L del ácido ascórbico) no se sintetiza, por lo que debe ingerirse a través de los alimentos. Esto se debe a la ausencia de la enzima L-gluconolactona oxidasa, que participa en la ruta del ácido úrico.

El enantiómero L (levógiro) de este ácido comúnmente se conoce como vitamina C. El nombre "ascórbico" proviene del prefijo "a-" ("sin") y del latín "scorbuticus" ("escorbuto"), procede de su propiedad de prevenir y curar el escorbuto.


El ácido ascórbico y sus sales de sodio, potasio y calcio se utilizan de forma general como antioxidantes. Estos compuestos son solubles en agua, por lo que no protegen las grasas de la oxidación. Para este propósito, pueden utilizarse los ésteres del ácido ascórbico solubles en grasas con ácidos grasos de cadena larga (palmitato y estearato de ascorbilo).

Desde mediados del siglo XVIII, ya se había observado que el jugo de limón podía prevenirles a los marineros padecer escorbuto. Al principio, se suponía que las propiedades ácidas eran responsables de este beneficio; sin embargo, pronto se hizo evidente que otros ácidos en la dieta, como el vinagre, no tenían tales beneficios. En 1907, dos médicos noruegos informaron de un compuesto esencial en los alimentos para prevenir la enfermedad, distinto del que impedía el beriberi. Estos médicos estaban investigando enfermedades por deficiencias dietéticas mediante el nuevo modelo animal de cobayas, susceptibles al escorbuto. Al recién descubierto factor alimentario se le llamó finalmente vitamina C.

Entre 1928 y 1932, el equipo de investigación húngaro dirigido por Albert Szent-Györgyi, y el del investigador norteamericano Charles Glen King, identificaron el factor antiescorbútico como una particular y sencilla sustancia química. En la Clínica Mayo, Szent-Györgyi había aislado químicamente el ácido hexurónico a partir de las glándulas suprarrenales de animales; sospechaba que era el factor antiescorbútico pero no podía demostrarlo sin un ensayo biológico. Tal ensayo se llevó a cabo por fin en la Universidad de Pittsburgh, usando conejillos de indias en el laboratorio de King, quien había trabajado en el problema durante años. A finales de 1931, el laboratorio de King obtuvo indirectamente de Szent-Györgyi ácido hexurónico renal y, utilizando su modelo animal, demostró a principios de 1932 que era la vitamina C.

Este fue el último de los compuestos de origen animal; pero luego, en ese mismo año, el grupo de Szent-Györgyi descubrió que la pimienta paprika, una especia común en la dieta de Hungría, era una rica fuente de ácido hexurónico. Envió algunos de los productos químicos, ahora más disponibles, a Walter Norman Haworth, un químico británico experto en el azúcar. En 1933, en colaboración con el entonces director adjunto de Investigación (y posteriormente sir) Edmund Hirst y sus equipos de investigación, Haworth dedujo la estructura correcta y la naturaleza isómerica-óptica de la vitamina C, y en 1934 informó de la primera síntesis de la vitamina. En honor de las propiedades antiescorbúticas del compuesto, Haworth y Szent-Györgyi propusieron entonces para el compuesto el nuevo nombre de «ácido a-escórbico» ("a-scorbic acid"). Finalmente ellos mismos lo nombraron ácido L-ascórbico cuando su estructura fue probada por síntesis.

En 1937, el Premio Nobel de Química le fue otorgado a Haworth por su trabajo en la determinación de la estructura del ácido ascórbico (compartido con Paul Karrer, quien recibió su premio por el trabajo sobre las vitaminas), y el premio de Fisiología o Medicina de ese mismo año fue para Szent-Györgyi por sus estudios sobre las funciones biológicas del ácido L-ascórbico. El médico estadounidense Fred R. Klenner promovió la vitamina C como una cura para muchas enfermedades en la década de 1950 elevando las dosis en gran medida hasta decenas de gramos de vitamina C al día mediante inyección. Desde 1967, otro ganador del premio Nobel Linus Pauling recomienda elevadas dosis de ácido ascórbico (él mismo tomaba 18 gramos al día) como prevención contra el resfriado y el cáncer. Los resultados de Klenner han sido controvertidos por el momento, ya que sus investigaciones no cumplen con los estándares metodológicos modernos.




</doc>
<doc id="15535" url="https://es.wikipedia.org/wiki?curid=15535" title="Nanómetro">
Nanómetro

El nanómetro es la unidad de longitud del Sistema Internacional de Unidades (SI) que equivale a una mil millonésima parte de un metro (1 nm = 10 m) o a la millonésima parte de un milímetro.

El símbolo del nanómetro es nm.

El nombre combina el prefijo "nano" (del griego , ', «enano») con la unidad "metro" (del griego , ', «unidad de medida»).

Puede escribirse en notación científica como 1 nm = 10 m y es simplemente formula_1 metros.

Un nanómetro equivale a 10 ångströms.

Recientemente la unidad ha cobrado notoriedad en el estudio de la nanotecnología, área que estudia materiales que poseen dimensiones de unos pocos nanómetros.

Se usa para describir los tamaños en las sucesivas generaciones de la industria de los semiconductores y microprocesadores.

El nanómetro se usa para expresar dimensiones en la escala atómica:

También se utiliza para medir la longitud de onda de la radiación ultravioleta, radiación infrarroja y la luz.
La luz visible va desde 400 a 700 nm.

Los pulmones humanos sólo pueden retirar partículas superiores a 200 nanómetros. Las partículas de tamaño inferior pueden llegar a cualquier parte del cuerpo y producir daños y tumores.

El diámetro del cabello humano va de 70 µm (70000 nm) a 80 µm (80000 nm).




</doc>
<doc id="15536" url="https://es.wikipedia.org/wiki?curid=15536" title="TAC">
TAC

TAC puede referirse a:









</doc>
<doc id="15550" url="https://es.wikipedia.org/wiki?curid=15550" title="Richard Nixon">
Richard Nixon

Richard Milhous Nixon (Yorba Linda, California, 9 de enero de 1913-Nueva York, 22 de abril de 1994) fue el presidente de los Estados Unidos entre 1969 y 1974, año en que se convirtió en el único presidente en dimitir del cargo. Anteriormente, Nixon había sido miembro de la Cámara de Representantes de Estados Unidos (por el 12.º distrito de California) y del Senado de Estados Unidos (por California).

Nixon nació en Yorba Linda (California). Tras completar sus estudios de pregrado en Whittier College, se graduó en la Escuela de Derecho de la Universidad de Duke en Carolina del Norte y regresó a California para ejercer la abogacía. Se mudó a Washington D. C. para trabajar para el gobierno federal en 1942 junto a su mujer, Pat Nixon. En esta época, sirvió activamente en la Reserva Marina de Estados Unidos durante la Segunda Guerra Mundial. Nixon fue elegido a la Cámara de Representantes en 1946 y al Senado en 1950, donde se consolidó como líder anticomunista tras el papel clave que desempeñó en el caso de Alger Hiss. Fue el candidato a la Vicepresidencia de Estados Unidos en las elecciones de 1952 por el Partido Republicano. Ejerció como vicepresidente durante ocho años. Posteriormente, libró una campaña presidencial sin éxito en 1960, perdiendo contra John F. Kennedy, y más tarde perdió las elecciones para gobernador de California de 1962. Nixon fue elegido Presidente en las elecciones presidenciales de Estados Unidos de 1968, derrotando a Hubert Humphrey.

Nixon terminó con la intervención estadounidense en la guerra de Vietnam en 1973 y trajo a los prisioneros de guerra a suelo estadounidense, además de acabar con el servicio militar obligatorio. La visita de Nixon a China en 1972 estableció relaciones diplomáticas entre las dos naciones. Nixon inició el "détente" entre Estados Unidos y la Unión Soviética, impulsando el Tratado sobre Misiles Antibalísticos. En política socioeconómica, Nixon impuso controles sobre los sueldos y los precios durante un período de noventa días, impuso la desegregación de las escuelas sureñas, y creó la Agencia de Protección Ambiental. Nixon presidió el alunizaje del Apolo 11, que marcó el final de la carrera espacial. El triunfo electoral de Nixon en 1972 ha sido uno de los más aplastantes en la historia de Estados Unidos, derrotando a George McGovern.

Sin embargo, el año 1973 trajo la crisis del petróleo, el racionamiento de la gasolina, y continuas revelaciones públicas sobre el escándalo Watergate. Este último suceso en particular hizo que Nixon perdiese gran parte de su apoyo político. Nixon dimitió como Presidente el 9 de agosto de 1974 ante un proceso de destitución ("impeachment") inevitable. Tras su renuncia, su sucesor, Gerald Ford lo indultó y fue rehabilitando su imagen tras publicar varios libros y haber viajado múltiples veces al extranjero. El 18 de abril de 1994, sufrió un derrame cerebral y murió cuatro días más tarde a los 81 años. Nixon sigue siendo un personaje de gran interés para los historiadores.

Nació en el seno de una familia de agricultores, metodista el padre, y cuáquera la madre, ambos de origen humilde. El padre se convirtió al cuaquerismo tras la boda, después de haber servido en la Armada de los Estados Unidos durante la Primera Guerra Mundial. Pronto se trasladaron a la localidad californiana de Whittier cuando el joven Richard tenía nueve años. Allí alternó sus estudios de primaria con su trabajo en la tienda de comestibles y en la gasolinera que regentaban sus padres. Se graduó en 1934 por el Whittier College de California, a 19 km de Los Ángeles, y en 1937 por la Duke University Law School.

Alistado en la Marina en 1942, sirvió en el Pacífico sur durante la Segunda Guerra Mundial.
Nixon estaba exento de realizar el servicio militar por dos motivos, ser cuáquero y por su trabajo en la Oficina de Administración de Precios, pero decidió no acogerse a ninguno de ellos y entró al servicio de la Armada de Estados Unidos en agosto de 1942. Fue entrenado en la Estación Naval Aérea de Quonset Point (Rhode Island), asignado a la Estación Naval Aérea de Ottumwa, Iowa, durante siete meses y reasignado como controlador de pasajeros aéreos navales del Comando de Transporte Aéreo de combate del Pacífico Sur, apoyando la logística de las operaciones del Teatro del Pacífico suroriental. Tras solicitar tareas que presentaran mayores desafíos, se le fueron asignando unidades en comando. Nixon regresó a Estados Unidos con dos medallas (aunque jamás estuvo en combate) y una recomendación, por lo que pasó a ser el Oficial administrativo de la Estación Naval Aérea Alameda. En enero de 1945, fue transferido al Bureau of Aeronautics en Filadelfia para ayudar a negociar la conclusión de los contratos de guerra. Además, ayudó a revisar los documentos capturados a nazis y japoneses. Recibió por ello otra carta de recomendación, esta vez del Secretario de la Marina James Forrestal. En octubre de 1945, fue promovido a teniente comandante y renunció a su comisión de servicios el día de año nuevo de 1946.

Allen Dulles llegó a un acuerdo con el joven oficial de la marina reclutado por Prescott Bush, por un anuncio de periódico en 1941, que estaba revisando los archivos de la Konti. Nixon le ayudaría a enterrar los archivos de la Konti. Como retribución, Allen Dulles «ayudó a financiar la primera campaña parlamentaria de Nixon contra Jerry Voorhis».

En las elecciones de noviembre de 1946, Nixon fue elegido Representante (diputado) republicano a la Cámara de Representantes del Congreso de los Estados Unidos por el 12.º distrito congresional de California (un distrito que para esa época ocupaba territorio del Condado de Los Ángeles) para el período 1947-1949; fue reelegido para un segundo período (1949-1951), pero faltando menos de dos meses para concluir ese segundo mandato renunciaría para ser senador. En 1948 y 1949 se hace famoso como miembro del Comité de Actividades Antiamericanas durante la investigación del caso Alger Hiss. Su forma de actuar en el caso le permitió a Richard Nixon ser elegido para elaborar, conjuntamente con otros representantes, el Plan Marshall de ayuda económica a la Europa de posguerra. En las elecciones de noviembre de 1950 fue elegido senador por California al Senado de los Estados Unidos para el período 1951-1957.

En 1952 fue nominado por el Partido Republicano a la vicepresidencia en la candidatura presidencial de Dwight D. Eisenhower, ganando las elecciones de noviembre, y nombrado , en enero de 1953. Permaneció como vicepresidente con Eisenhower durante todo el tiempo que éste fue , ocho años en total, pues fueron reelegidos en 1956, hasta enero de 1961.

[[[[Archivo:Dwight D Eisenhower2.jpg|thumb|Eisenohwer, presidente de Estados Unidos (1953-1961), de quien fue vicepresidente.]]

[[Archivo:Nixon and khrushchev.jpg|thumb|right|alt=A middle-aged man and an older one confer with each other.|[[Nikita Jrushchov]] (derecha) con el vicepresidente estadounidense Richard Nixon en 1959.]]

Richard Nixon gozó de un papel y unas prerrogativas políticas inusuales para su cargo, dadas las responsabilidades políticas que Eisenhower delegó en su persona. Presidió la mayor parte de las reuniones del Gobierno y de los líderes del Congreso, a la par que asumió tres veces (1955, 1956 y 1957) las funciones presidenciales debido a la crónica dolencia cardíaca que padecía el presidente. Destacó como embajador extraordinario de su país por todo el mundo, en calidad de lo cual visitó un total de 55 estados, incluida la [[Unión Soviética]].

En mayo de 1958 durante una visita a [[Caracas]], [[Venezuela]], su vehículo fue atacado a pedradas por una multitud. Relatando el episodio en su obra "Seis Crisis", Nixon afirmó que se salvó milagrosamente.

Finalizado el segundo mandato presidencial de Eisenhower, Nixon consiguió que el partido republicano le eligiera candidato a presidente en 1960. Sin embargo [[John Fitzgerald Kennedy]], candidato del [[Partido Demócrata de los Estados Unidos|partido demócrata]], con el que mantuvo cuatro debates televisados, lo venció en las elecciones presidenciales de noviembre de 1960 por un estrecho margen de votos. En 1962 intentó ser elegido gobernador de California, sin éxito.

[[Archivo:NIXONcampaigns.jpg|derecha|miniaturadeimagen|275px|Nixon haciendo campaña en [[Pensilvania]], 1968]]
A principios del año 1968 Nixon presentó su precandidatura presidencial para competir por la nominación oficial del [[Partido Republicano de los Estados Unidos|Partido Republicano]]. Los principales rivales internos de Nixon en la carrera por la candidatura presidencial eran [[Nelson Rockefeller]] (en ese momento [[gobernador]] de [[Nueva York (estado)|Nueva York]]) y [[Ronald Reagan]] (entonces gobernador de [[California]]). Rockefeller representaba al [[Republicano liberal#Estados Unidos|ala liberal republicana]] (centroizquierdista), Reagan al [[Partido Republicano de los Estados Unidos#Ideología y Tendencias Internas del Partido Republicano|ala conservadora republicana]] (derechista) y Nixon al sector o [[Partido Republicano de los Estados Unidos#Ideología y Tendencias Internas del Partido Republicano|ala moderada republicana]] (centrista). Nixon tenía una maquinaria electoral más poderosa y derrotó con relativa facilidad a Reagan y a Rockefeller en las elecciones primarias internas de la mayoría de los Estados; y por eso, cuando se reunió la Convención Nacional Republicana en [[Miami Beach]] el 5 de agosto de 1968, Nixon obtuvo en la primera votación el voto de 692 delegados contra 277 de Rockefeller y 182 de Reagan, quedando elegido como candidato presidencial del Partido Republicano.

[[Archivo:Supporters of Richard Nixon at the 1968 Republican National Convention Miami Beach, Florida.jpg|derecha|miniaturadeimagen|275px|Partidarios de Nixon en la Convención Nacional Republicana de agosto de 1968]]
Por su parte, el [[Partido Demócrata de los Estados Unidos|Partido Demócrata]] elige en la [[Convención Nacional Demócrata de 1968]] al entonces [[vicepresidente de los Estados Unidos]] [[Hubert Humphrey]] como su candidato presidencial. Pero un sector del partido, el de los demócratas [[Racismo|racistas]] de los Estados del sur, se separó del partido molesto por las políticas a favor de la igualdad entre blancos y negros que impulsaban Humphrey y el presidente [[Lyndon B. Johnson]]. Este grupo de demócratas disidentes fundaron un nuevo partido llamado el [[American Independent Party]]; y lanzaron la candidatura presidencial de [[George Wallace]], para ese entonces ex gobernador de [[Alabama]].
Nixon inicia su campaña para la presidencia con una nueva imagen que le presentaba como un elemento más moderado; pero al mismo tiempo prometía ""Ley y Orden"" (el lema principal de su campaña) para restablecer el orden en una sociedad sacudida por violentos disturbios contra la guerra y contra la segregación racial. Esta promesa era hecha en términos ambiguos en un esfuerzo para atraer el voto de los blancos del sur. Por eso la campaña de Nixon reclutó a antiguos demócratas sureños que se habían pasado al Partido Republicano, descontentos con las medidas a favor de los derechos civiles promovidas por Johnson. Pero el esfuerzo de conquistar el sur se estrellaba con el mensaje mucho más radical de Wallace, que resultaba más atractivo para los racistas.

Pero a la larga la estrategia moderada en el norte y el oeste, y más derechista en el sur le dio resultado a Nixon; y la [[Guerra de Vietnam]] fue un grave obstáculo para Humphrey. El 5 de noviembre de 1968 se celebraron las [[Elecciones presidenciales de Estados Unidos de 1968|elecciones presidenciales]]; Nixon obtuvo 31 783 783 votos populares, equivalentes al 43,42 % de los sufragios emitidos; Humphrey obtuvo 31 271 839 votos populares, que equivalían al 42,72 % de los votos; y Wallace obtuvo 9 901 118 votos populares, equivalentes al 13,53 % de los sufragios. Otros candidatos minoritarios obtuvieron en total 243 258 votos populares, un 0,33 % de los votos, por lo que Nixon derrotó a Humphrey en el sufragio popular por una diferencia de un poco más de 500 000 votos; pero como Nixon ganó en 32 [[Estado de los Estados Unidos de América|estados]], Humphrey en 13 estados (y el [[Distrito de Columbia]]) y Wallace en 5 estados, al final Nixon tuvo 301 electores en el [[Colegio electoral de Estados Unidos|Colegio Electoral]], contra 191 de Humphrey y 46 de Wallace.Nixon fue el presidente electo y tomó posesión el 20 de enero de 1969.

[[Archivo:Gustavo Diaz Ordaz Richard Nixon San Diego.jpg|miniaturadeimagen|El presidente mexicano [[Gustavo Díaz Ordaz]] (izquierda) con el presidente estadounidense Richard Nixon durante un recorrido en automóvil en [[San Diego (California)|San Diego]], California.]]
[[Archivo:Joint statement to the press with Chancellor Willy Brandt of West Germany - NARA - 194398.tif|miniaturadeimagen|izquierda|Richard Nixon con el Canciller de [[Alemania Occidental]] Willy Brandt en 1972.]]
Casi un año después de ser elegido, el 3 de noviembre de 1969, se dirige a la nación estadounidense en uno de los mensajes presidenciales más famosos de la historia, el denominado discurso de la "Mayoría Silenciosa", en el que intenta unir a los estadounidenses para resolver juntos la crisis ocasionada por la impopular [[Guerra de Vietnam]]. Junto con el [[Secretario de Estado de los Estados Unidos|secretario de estado]] [[Kissinger]], redefinió el papel de Estados Unidos en el escenario mundial. Se realizó una retirada gradual de los 500 000 soldados estadounidenses que combatían en [[Vietnam del Sur]], aunque la retirada se prolongó durante cuatro años. Su mayor logro fue su aproximación y apertura de relaciones con la [[República Popular de China]]. Nixon también viajó a [[Moscú]] para negociar el primer paso para un acuerdo sobre limitación de armas estratégicas. En [[Oriente Próximo]], estableció relaciones con [[Egipto]] manteniendo los compromisos con [[Israel]]. Políticas de Nixon se centraron en combatir la inflación- En el momento Nixon asumió el cargo en 1969, la inflación fue del 4,7 por ciento, la tasa más alta desde la Guerra de Corea. Con la inflación sin resolver en agosto de 1971, y un año electoral que se avecina, Nixon convocó una cumbre de sus asesores económicos en Camp David. Luego anunció controles temporales de precios y salarios, permitió que el dólar para flotar frente a otras monedas, y puso fin a la convertibilidad del dólar en oro. 

[[Archivo:Nixon-Hirohito.jpg|thumb|200px|[[Hirohito]] durante una conferencia del presidente estadounidense Richard Nixon, [[1971]].]]

[[Archivo:Richard Nixon Luis Echeverria 1972-06-15.jpg|derecha|thumb|250 px|El presidente estadounidense Richard Nixon (izquierda) y [[Luis Echeverría]] haciendo una inspección de tropas en 1972.]]

[[Archivo:Nixon and de Gaulle 30-0166a.gif|thumb|left|300px|[[Charles de Gaulle]] junto a Richard Nixon.]]

Después de ganar la reelección, Nixon la inflación volvió a acelerarse, Nixon volvió a imponer controles de precios en junio de 1973. Los controles de precios se hizo impopular con el público y los empresarios, que vio a los poderosos sindicatos como preferibles a la burocracia tabla de precios Los controles produjeron la escasez de alimentos, la carne desapareció de las tiendas de comestibles y los agricultores ahogaron pollos en lugar de venderlos a pérdida a pesar de la falta de control de la inflación, los controles fueron poco a poco habrá terminado, y el 30 de abril de 1974, su autorización legal caducado.El apoyo prestado a Israel en la Guerra de Yom Kipur llevó a un boicot árabe al petroleo, lo que resultó en la crisis del petróleo de 1973. El embargo causó escasez de gasolina y el racionamiento en los Estados Unidos a finales de 1973 y disparó aún más la inflación. La crisis provocó que las condiciones de vida se volvieran muy adversas para los desempleados, los grupos sociales marginados, algunos trabajadores de mayor edad, y cada vez más, para los trabajadores más jóvenes. Las escuelas y oficinas tuvieron que cerrar a menudo para ahorrar el combustible de la calefacción, las fábricas tuvieron que reducir la producción y despedir trabajadores. Esta escasez llevó al racionamiento de gasolina por lo que los automovilistas se enfrentaron a largas colas en las gasolineras.

El Nixon Shock fue una serie de medidas económicas llevadas a cabo por Estados Unidos el presidente Richard Nixon en 1971, el más importante de los cuales fue la cancelación unilateral de la directa convertibilidad del dólar de los Estados Unidos para el oro. En ese momento, los EE. UU. también tenía una tasa de desempleo del 6,1 % (agosto de 1971) y una inflación del 5,84 % (1971), las cifras más altas desde la Segunda Guerra.la principal influencia de la experiencia de la recesión 1973 llegó en la forma del concepto de [[estanflación]], es decir, la inflación durante un período de recesión
[[Archivo:Richard Nixon waves in presidential limousine.jpg|izquierda|miniaturadeimagen|251x251px|El presidente Nixon en la limusina presidencial.]]

[[Archivo:Richard_M._Nixon,_ca._1935_-_1982_-_NARA_-_530679.jpg|thumb|left|Richard Nixon fue el único presidente estadounidense que dimitió del cargo.]]
En [[1972]] Nixon era un presidente muy popular, por lo que su reelección parecía fácil; aun así dos [[Cámara de Representantes de los Estados Unidos|Representantes]] republicanos, uno liberal (izquierdista) y otro conservador (derechista) compitieron contra él por la candidatura oficial del partido republicano. Pero Nixon ganó las elecciones primarias con facilidad y por ello, cuando la Convención Nacional Republicana se reunió nuevamente en [[Miami Beach]] del 21 de agosto hasta el 23 de agosto de 1972, Nixon fue elegido candidato del partido con los votos de 1347 delegados contra un solo voto para su rival izquierdista y ninguno para el conservador.

[[Archivo:Kissinger Mao.jpg|thumb|330px|[[Henry Kissinger]], [[Zhou Enlai]] y [[Mao Zedong]] en [[Pekín]], durante la visita de Nixon a [[China]] en febrero de [[1972]].]] 

[[Archivo:ZhouNixonBanquet.gif|thumb|left|Richard Nixon y [[Zhou Enlai]] hablando en un banquete.]]

[[Archivo:Leonid Brezhnev and Richard Nixon talks in 1973.png|right|thumb|El presidente estadounidense Richard Nixon entablando una conversación con [[Leonid Brézhnev]] durante su visita a los Estados Unidos en junio de 1973.]]

El Partido Demócrata por su parte tuvo que elegir entre 10 precandidatos en una dura elección interna; finalmente el elegido fue [[George McGovern]], para ese entonces [[Senado de los Estados Unidos|senador]] por el estado de [[Dakota del Sur]].

McGovern fue sin duda el candidato presidencial demócrata de ideas más cercanas al socialismo en toda la historia de los Estados Unidos hasta ese momento. Su plataforma electoral estaba muy orientada al gasto social, con propuestas para aumentar los [[impuestos]], el gasto público y la burocracia. Igualmente su programa pretendía aumentar el tamaño del Estado y su intervención en la economía; e iniciar un desarme unilateral en plena [[Guerra Fría]]. Por eso los republicanos lo atacaron presentándolo como un radical peligroso y "medio loco"; mientras la popularidad de Nixon iba en aumento gracias a la buena situación económica.
[[Archivo:Richard Nixon with the Marcos family.png|miniaturadeimagen|259x259px|Richard Nixon con la familia del dictador filipino [[Ferdinand Marcos]]]]
El 7 de noviembre de 1972 se celebraron las [[Elecciones presidenciales de Estados Unidos de 1972|elecciones presidenciales]]; Nixon obtuvo 47 168 710 votos populares, que equivalían al 60,67 % de los sufragios populares emitidos; McGovern obtuvo 29 173 222 votos populares, equivalentes al 37,52 % de los sufragios; [[John Schmitz]], del [[American Independent Party]], obtuvo 1 100 868 votos populares que equivalían a un 1,42 %; y otros candidatos minoritarios sumaron 301 227 votos populares, un 0,39 %. Nixon ganó en 49 [[Estado de los Estados Unidos de América|estados]] y McGovern en apenas un estado ([[Massachusetts]]) y el [[Distrito de Columbia]]; en el [[Colegio electoral de Estados Unidos|Colegio Electoral]], Nixon obtuvo 520 Electores contra 17 para McGovern y uno para un candidato minoritario. Fue una de las victorias electorales más aplastantes de la historia estadounidense.El 6 de octubre de 1973, Israel entra en guerra contra una coalición árabe dirigido por Egipto y Siria. Israel en lo que se conoce como la Guerra de Yom Kippur. Israel sufrió grandes pérdidas y Nixon ordenó un puente aéreo para reabastecer las pérdidas israelíes. Debido a la victoria de Israel fue en gran parte debido al apoyo de Estados Unidos, los países de la OPEP árabe respondieron al negarse a vender petróleo crudo a los EE. UU., lo que resultó en la crisis del petróleo de 1973. El embargo causó escasez de gasolina y el racionamiento en los Estados Unidos a finales de 1973 y disparó aún más la inflación. Especialmente en Estados Unidos, la crisis provocó que las condiciones de vida se volvieran muy adversas para los desempleados, los grupos sociales marginados, algunos trabajadores de mayor edad, y cada vez más, para los trabajadores más jóvenes. Las escuelas y oficinas en EE. UU. tuvieron que cerrar a menudo para ahorrar el combustible de la calefacción, y las fábricas tuvieron que reducir la producción y despedir trabajadores. La crisis se agravó aún más a causa del control de los precios en Estados Unidos, que limitó el precio del "petróleo antiguo" (ya descubierto), mientras permitía que el petróleo recién descubierto pudiera ser vendido a un precio más elevado, lo que supuso una retirada del petróleo antiguo del mercado y una escasez artificial. El objetivo era promover las prospecciones petrolíferas. Esta escasez llevó al racionamiento de gasolina (que también se produjo en muchos otros países). Los automovilistas se enfrentaron a largas colas en las gasolineras.

En Estados Unidos, los conductores de vehículos cuyas matrículas acabaran en número impar (o matrículas personalizadas) fueron autorizados a adquirir carburante sólo en los días impares del mes, y la misma norma se aplicó a los propietarios de vehículos con matrículas pares.

[[Archivo:Nixon-depart.png|thumb|derecha|Nixon abordando el helicóptero con el que se retira de la Casa Blanca, 9 de agosto de 1974]]
No obstante, meses antes se había producido un extraño caso de allanamiento de la sede central del [[Partido Demócrata de los Estados Unidos|Partido Demócrata]] (en el edificio de oficinas [[Escándalo Watergate|Watergate]]), que el 17 de junio de 1972 destapó un método de realizar escuchas ilegales por hombres contratados por algunos colaboradores del presidente. Su situación comenzó a complicarse durante el juicio contra los acusados, cuando confesaron ante el juez Sirica, encargado de la investigación, que habían sido enviados por altos responsables del Partido Republicano. Para agravar los problemas de Nixon, su vicepresidente, Spiro T. Agnew, fue acusado de soborno y tuvo que dimitir de su cargo (Richard Nixon lo sustituyó por otro destacado congresista republicano, Gerald R. Ford, que se convertiría en Presidente tras la renuncia de su mentor). Paulatinamente se fue desvelando un plan preconcebido desde el entorno presidencial, en el cual se vieron implicados varios altos cargos, como John Mitchell, ministro de Justicia; John Dean, consejero presidencial; H. R. Haldeman, jefe de Personal de la Casa Blanca, o John Ehrlichman, asesor especial de la Casa Blanca para Asuntos Nacionales. 

En marzo de 1974 el Gran Jurado federal consideró al presidente copartícipe, sin cargos formales, en una conspiración para obstruir la acción de la justicia en la investigación del [[escándalo Watergate]]. En la tarde del 8 de agosto, Nixon anunció su dimisión. El 9 de agosto, [[Gerald Ford]] prestaba juramento del cargo.

[[File:Nixon grave 2011.jpg|thumb|left|Tumbas de Richard y [[Pat Nixon]] en [[Yorba Linda]], [[California]] ]]
Retirado en su rancho californiano de San Clemente, Nixon intentó volver a la práctica de la abogacía sin poder conseguirlo, ya que fue expulsado del Colegio de Abogados además de que fue incapacitado para el desempeño de su profesión en todo el territorio estadounidense. En [[1978]] plasmó sus experiencias como presidente en la obra "Mis memorias", libro por el que obtuvo importantes ganancias económicas. En el año [[1986]] volvió a publicar otra exitosa obra, "No más Vietnam".[[Archivo:FordNixonBushReaganCarter.jpg|thumb|Los presidentes [[Gerald Ford]], Richard Nixon, [[George H. W. Bush]], [[Ronald Reagan]] y [[Jimmy Carter]] (de izquierda a derecha) en una reproducción del [[Despacho Oval]] durante la inauguración de la [[Biblioteca y Museo Presidencial de Ronald Reagan]] en 1991.]]Nixon sufrió un [[derrame cerebral]] el [[18 de abril]] de [[1994]] y murió cuatro días más tarde a la edad de 81 años el [[22 de abril]]. A su funeral asistió el presidente [[Bill Clinton]].




[[Categoría:Richard Nixon| ]]

</doc>
<doc id="15554" url="https://es.wikipedia.org/wiki?curid=15554" title="Julio I">
Julio I

Julio I fue el papa nº 35 de la Iglesia católica entre el 6 de febrero de 337 y el 12 de abril de 352, fecha de su muerte.

Confirmó en su puesto a dos obispos cristianos a quienes los arrianos habían hecho abdicar. En el otoño de 341, Julio I convocó un concilio al que asistieron 50 obispos con el propósito de pronunciarse de nuevo en contra del arrianismo y condenar a quienes deponían obispos a su antojo.

A la muerte de Constantino I el Grande, el imperio se dividió entre sus tres hijos, uno de ellos, Constantino II, pronto desapareció de la historia y quedaron como emperadores sus otros dos hijos, Constancio II, en Oriente y Constante en Occidente. Mientras que Constante era católico, Constancio era arriano. En 350, Constante fue asesinado y el Imperio se reunificó bajo el mando de Constancio. El emperador desató entonces una terrible persecución contra la Iglesia.

Julio I fijó para la Iglesia de Occidente la solemnidad de Navidad el 25 de diciembre, en vez del 6 de enero, junto con la Epifanía. Tomó esta fecha porque, en el calendario juliano, el solsticio de invierno ocurría en ese día, siendo este acontecimiento festejado por muchos pueblos del Hemisferio Norte como un nuevo renacer del ciclo de la vida.

Los inicios del cristianismo en la era romana fueron difíciles, se producían constantes revueltas entre la población y enfrentamientos entre paganos y romanos recién convertidos al cristianismo. La celebración de ciertas fiestas paganas era también motivo de disputas sociales y políticas. Con el propósito de pacificar dichos enfrentamientos, el emperador Constantino el Grande con el apoyo del Papa Julio I decidieron hacer coincidir las fiestas paganas de las Saturnales con la celebración del nacimiento del Mesias. De este modo se celebraría el mismo día el nacimiento del Dios Sol con el nacimiento del Hijo de Dios el Cristo. 

Sin embargo sabemos que Jesús no nació en invierno sino en primavera. 

Se le considera el fundador del Archivo de la Santa Sede, porque ordenó la conservación de los documentos.


</doc>
<doc id="15556" url="https://es.wikipedia.org/wiki?curid=15556" title="Etnografía de Colombia">
Etnografía de Colombia

La etnografía de Colombia se caracteriza por ser el resultado de la mezcla de tres grupos principales: indígenas, españoles y africanos. La población colombiana está formada por el mestizaje directo de estos tres grupos, a los que se sumaron un importante número de inmigrantes provenientes de otros países de Europa y Oriente Medio. En el censo general de población de 2005, el 85,94% fue clasificado sin pertenencia étnica esto incluye a judíos y árabes. Entre las opciones para autoidentificarse el grupo afrocolombiano llegó a 10,62% de la población, el de indígena al 3,43%, y como gitano el 0,01%.

De acuerdo al censo llevado a cabo por el Departamento Administrativo Nacional de Estadística (DANE), en 2005 la población se auto identificó de la siguiente manera.

Un estudio llevado a cabo por la Federal Research Division estima que entre la población sin pertenencia étnica el 49% son mestizos y el 37% blancos.

Por su parte, otro estudio dirigido por el etnólogo mexicano Francisco Lizcano Fernández, señala que Colombia es un país mayoritariamente mestizo (53,2%), con importantes minorías de mulatos (21,0%) y criollos (20,0%), y pequeñas minorías de negros (3,9%), indígenas (1,8%) y creoles (0,1%).

A pesar de varios trabajos en etnohistoria, se desconoce exactamente cuántos indígenas habitaban el actual territorio de Colombia a la llegada de los españoles, debido a que la información prehispánica era de tradición oral, y por tanto se carece de documentos escritos que sirvan para calcular la población de la época. No obstante, si se sabe que tras la llegada de los españoles hubo una gran mortandad de la población indígena (el 90 %) propiciada por las enfermedades traídas por los europeos, las guerras y combates esporádicos que mantuvieron con éstos últimos y los trabajos forzados y semiesclavitud a que fueron sometidos los pueblos indígenas por los colonizadores españoles. No obstante, la población indígena del territorio colombiano era ya de por sí escasa, lo que explica en parte la necesidad de los españoles de importar de esclavos africanos para utilizarlos como mano de obra, aunque la razón principal fue el exterminio de la mayor parte de los indígenas.

Los primeros esclavos africanos llegaron en el año 1504, pero la necesidad era tal que a partir de 1520 entraban en el país aproximadamente 4000 esclavos africanos al año. Desde finales del s.XVI, muchos esclavos negros lograban huir (cimarrones) y fundaban y establecían pueblos libres negros (Palenques), como el famoso Palenque de San Basilio. El punto de entrada de los esclavos era Cartagena, que junto con Mompox era el principal punto de compra-venta de estos. Desde allí eran desplazados por los ríos Cauca y Magdalena hasta otros centros secundarios de comercio esclavista, como Popayán, Honda (Tolima), Anserma (Caldas) y Cali.Durante las primeras décadas se importaban principalmente esclavos varones jóvenes, pero luego se comenzó a introducir mujeres jóvenes para autoabastecer de nuevos esclavos al territorio. Los esclavos realizaban todo tipo de labores, principalmente en minería, agricultura, ganadería y servicio doméstico. Los principales grupos lingüísticos de los esclavos eran el bantú y el sudanés.Además los esclavos debían ser instruidos en la fe católica para ser reconocidos en la nueva sociedad. Recibir el sacramento del bautismo era una condición indispensable para entrar a la América hispánica, según las normas de la corona española, que prohibía la entrada a judíos, herejes y paganos.

Las primeras exploraciones europeas fueron realizadas por Alonso de Ojeda, Juan de la Cosa y Américo Vespucio, llegando hasta la Península de la Guajira. En 1501 Rodrigo de Bastidas descubrió las bocas del río Magdalena y la bahía de Cartagena, acompañado del propio Juan de la Cosa. La primera carta del litoral fue levantada por Juan de la Cosa entre 1492 y 1510. En 1511 Vasco Núñez de Balboa descubrió el río Atrato y contempló las aguas del Pacífico desde la sierra panameña de Darién. En 1522 Pascual de Andagoya, descubridor del Perú, llegó por el Pacífico hasta las bocas del río San Juan. Los españoles invirtieron unos veinte años en explorar las costas colombianas, fundaron varias ciudades y factorías y después avanzaron hacia el interior del país. Los primeros colonos españoles comenzaron a establecerse en el territorio inmediatamente después de su conquista por parte de Gonzalo Jiménez de Quesada, alrededor del año 1540.

En 1528, la familia de banqueros Welser consiguió de Carlos V la exclusividad para la conquista y colonización del territorio comprendido entre el Cabo de la Vela (actual Colombia) y Maracapana (actual Venezuela), siendo los primeros europeos no latinos que iniciaron el proceso colonizador en América latina. Algunos de los exploradores más importantes fueron Ambrosius Ehinger, Nikolaus Federmann, Georg Hohermut von Speyer o Philipp von Hutten, pero su presencia finalizó en 1546, tras ser retirada la concesión por el Consejo de Indias luego de los reiterados intentos poco exitosos de los gobernadores enviados por los Welser para establecer un gobierno estable en sus territorios, el descontento de los castellanos que habitaban Coro y acusaciones de diversa índole. Las razones para la retirada del contrato fue el incumplimiento del contrato de arrendamiento, donde se incluía la fundación de varias ciudades y varios fuertes, y también falló en la parte del contrato donde se estipulaba la obligatoriedad de extender el cristianismo entre los indígenas. Durante este corto período, pequeños grupos de colonos alemanes se establecieron en el territorio, pero el clima, el calor y las enfermedades acabaron con la vida de muchos de ellos y otros regresaron a Alemania, quedándose muy pocos.

Durante el siglo XVI y principios del XVII, los colonos españoles no eran más que soldados varones al servicio de los conquistadores que después se asentaban en el territorio. Las mujeres españolas tardarían en llegar y cuando lo hicieron sus números siempre fueron relativamente escasos. Esto unido a que los españoles varones eran jóvenes y generalmente habían llegado a América en busca de aventuras, riquezas y por los relatos acerca de que las mujeres indígenas iban desnudas, tenían grandes cantidades de hijos con las mujeres nativas y las esclavas africanas, a las cuales con frecuencia abandonaban. De este modo comenzó el mestizaje racial y en parte de los casos cultural, y en pocos años la población mestiza se alzó como la mayoría de la población, y conforme siguieron mezclándose europeos (sobre todo españoles), americanos y africanos, surgieron diversas variedades de razas, siendo denominadas las más importantes, como: mestizo (blanco-cobrizo), castizo (blanco-mestizo), moreno (blanco-negro), zambo (negro-cobrizo).

La sociedad colonial se caracterizó por dividirse en clases sociales étnicas. Así pues, la clase gobernante eran los criollos (denominación a los españoles y descendientes sin mezcla de éstos establecidos en América) y algunas variedades (castizos y mestizos de aspecto blanco), la clase media la formaban los mestizos y algunas variedades (algunos castizos y mestizos de pocos o medios rasgos indígenas), la clase baja la formaban los indígenas y algunas variedades (mestizos de aspecto predominante indígena) y en lo más bajo se hallaban los esclavos negros y algunas variedades (mulatos de aspecto predominante negro).

Desde tiempos de la colonia hasta tiempos incluso actuales, la población blanca generalmente ha alcanzado los principales y más importantes puestos, cargos y trabajos de la sociedad, teniendo un estatus económico y un nivel de bienestar social medio-alto, en contraste con las personas de otras etnias. Por ejemplo, la gran mayoría de presidentes del país han sido de raza blanca, las ciudades más grandes y desarrolladas del país actualmente Bogotá y Medellín tienen una mayor porcentaje de habitantes blancos, mientras que las zonas más atrasadas son aquellas donde la presencia cobriza o negra es mayor; como la costa pacífica o la región amazónica. Esto ha generado controversias internas sobre el papel de la raza blanca y su responsabilidad en ese atraso; desembocando en la "ley antidiscriminación" del 2011, en donde se establece: "El que arbitrariamente impida, obstruya o restrinja el pleno ejercicio de los derechos de las personas por razones de su raza, etnia, religión, nacionalidad, ideología política o filosófica, sexo u orientación sexual, incurrirá en prisión de 12 a 36 meses" 

A partir de la independencia del país, se sumaron a la mezcla pequeños grupos de inmigrantes árabes, judíos, europeos no españoles (italianos, alemanes...), chinos y otros asiáticos, aunque no tuvieron un impacto significativo en la composición étnica y la cultura del país.

En 1580 la población del Nuevo Reino de Granada estaba compuesta por 800,000 indígenas tributarios, 15,000 esclavos negros y 10,000 peninsulares.

En 1650 los indígenas eran 600,000, frente a 60,000 esclavos negros, 50,000 españoles, 20,000 mulatos y 20,000 mestizos.

En 1772 el territorio del Virreinato de la Nueva Granada estaba habitado por 353,435 mestizos, 143,800 indios, 129,279 blancos y 51,999 negros.

De acuerdo al Censo de 1851, la distribución racial en la Nueva Granada era la siguiente:

Según Tomas Cipriano de Mosquera, en 1852 la población colombiana estaba compuesta por 2.363.054 personas, clasificados de la siguiente manera:


En el censo de 1912, la población se auto identificó de la forma que sigue:

Según el Atlas de Colombia publicado por el Instituto Geográfico Agustín Codazzi en 1965, el 58% de la población colombiana era mestiza, el 20% blanca, el 14% mulata, el 4% negra, el 3% zamba y el 1% indígena.

En el censo de 1993 se pidió a los participantes que se auto identificaran como indígenas o afrocolombianos, arrojando unos resultados 1.61% y 1.52%, respectivamente.

En el siglo XX no fue tan numerosa con respecto a Brasil, Argentina, Venezuela, Cuba o Uruguay, situación que se debió a las políticas heredadas desde el tiempo de la Colonia española, con leyes que siempre desestimulaban el ingreso de extranjeros al territorio, primero del Virreinato de la Nueva Granada y después de lo que sería Colombia; y a la inestabilidad social, política y económica del país luego de su independencia del Imperio español debido a constantes conflictos internos, guerras civiles, dictaduras y golpes de estado. Esto desmotivó el atractivo del país a grupos inmigrantes, pero, aun así entraron en el país numerosos grupos y comunidades provenientes de Europa y Oriente Medio que tuvieron un profundo impacto en el desarrollo económico, social y cultural en determinadas áreas del territorio nacional colombiano. Los inmigrantes entraron a través del puerto de Barranquilla, aumentando considerablemente la población de la ciudad y convirtiéndola en una de las ciudades más cosmopolitas, desarrolladas y urbanizadas de Colombia.

Entre los flujos migratorios más numerosos e importantes después del español, se destaca la inmigración árabe, proveniente de países como Líbano, Siria, Jordania y Palestina, de diferentes religiones (principalmente cristianos), que se instalaron en las zonas del norte, como la ciudad de Maicao, donde se encuentra la comunidad musulmana más numerosa del país y la segunda mezquita más grande de América Latina. Se estima que en Colombia hay una población de 2 500 000 ciudadanos de origen árabe. También llegaron a Colombia inmigrantes judíos, procedentes principalmente de Polonia, Lituania, Ucrania y Alemania. Debe mencionarse también la inmigración europea, principalmente de españoles, seguidos de grupos italianos y algunos de alemanes y de otros países europeos; y finalmente, la relativamente reducida inmigración de chinos y otros asiáticos. También fue importante, aunque cuantitativamente reducida, la llegada de inmigrantes políticos de otros países latinoamericanos en tiempos en que había dictaduras o represiones políticas en sus países, como Argentina, Uruguay, Brasil , Chile y países del Caribe.

La presencia de extranjeros europeos en el país tiene una relación directa con los procesos de modernización en los aspectos económico y social. Los inmigrantes aportaron una serie de innovaciones en tecnología, ideas, usos y costumbres que propiciaron el desarrollo del país, por lo que representaron una ruptura con el pasado colonial. Por tal razón, el momento de su llegada empieza con la independencia del país, en la cual también participaron, respondiendo a los intereses comerciales de sus países de origen. Antes de ese momento, la inmensa mayoría de los inmigrantes que llegaban a estas tierras eran españoles. Esto implicó que las nuevas ideas llegaran a nuestro territorio teniendo por censores e intermediarios a los españoles, o que ingresaran por vías ilegales. Existe en la actualidad una tendencia migratoria importante de venezolanos "con dinero y bien preparados" en el país, principalmente por los drásticos cambios económicos y políticos en su país.

Constituyen el principal grupo étnico del país con un porcentaje del 49% al 58% del total del país. El mestizaje en Colombia comenzó poco después de que se establecieran los primeros colonizadores en el territorio. Es resultado directo de la escasez de mujeres europeas en algunos sectores del reino durante la conquista, debido a que durante todo el período colonial la mayoría de los inmigrantes europeos eran varones. Los españoles entonces se unían principalmente con mujeres nativas de los distintos grupos étnicos, indígenas o africanos. Los mestizos se hallan prácticamente en todo el territorio del país y su población es la más grande en Colombia, siendo el aporte europeo casi exclusivo por parte paterna, pues más del 80% de los colombianos descienden de un europeo por vía paterna, mientras que el 85 % de los colombianos provienen de una indígena por vía materna.

La ascendencia de los blancos colombianos es principalmente española y árabe, con algunos aportes italianos, franceses, alemanes y eslavos. Según fuentes externas, la cantidad de blancos en Colombia está entre el 20% y el 37% de la población.

En lo que era la Nueva Granada se presentó una gran cantidad de españoles que comenzaron a llegar al territorio como colonos poco después de la conquista en grandes números (en comparación con la población nativa del territorio por aquellos tiempos), pero eran principalmente varones solteros. El mayor ejemplo lo proporciona la región Andina, por ejemplo, en Antioquia las investigaciones genéticas encontraron que los haplogrupos del cromosoma Y muestran una ascendencia vía masculina 97% europea, 2% africana y 1% indígena y por el contrario, los haplogrupos del ADN mitocondrial revelan una ascendencia por vía materna 50% indígena, dependiendo del departamento 2% africana y 48% europea.

Tras la independencia del país se abrieron las puertas a inmigrantes europeos, a pesar de que el gobierno no la motivó ni la incentivó. Para entonces el país era política, social y económicamente muy inestable, produciéndose poco después de la independencia una serie de conflictos internos, guerras civiles y golpes de estado que lo desestabilizaron casi por completo; suponiendo una desmotivación para los inmigrantes europeos. A pesar de todo, pequeños grupos de españoles, italianos, alemanes, franceses, británicos, rusos, polacos (entre otros), llegaron al país principalmente a través del puerto de Barranquilla, estableciéndose mayormente en las principales ciudades. Una excepción importante a esta tendencia es el departamento de San Andrés y Providencia, el cuál fue colonia inglesa y la población blanca desciende de colonos escoceses e ingleses principalmente.

Históricamente, la población blanca ha desempeñado un papel influyente en la historia de Colombia, como lo es en la creación de las instituciones gubernamentales, la constitución, el ejército, el himno nacional, la construcción de infraestructura, creaciones en el arte, la arquitectura y las ciencias. 

Según datos del Departamento Administrativo Nacional de Estadística de Colombia (DANE) los datos arrojados en el último censo general de la nación correspondientes a la distribución de la población censada sin pertenencia étnica (blancos y mestizos), presentados en los informes finales de consolidación de resultados, según departamento, son:

Según el último censo del país, corresponden al 10,6% de la población, incluyendo a Mulatos, Raizales y Palenqueros. No obstante, algunas estimaciones del gobierno señalan que los afrocolombianos son el 26% de la población nacional, siendo la tercera población negra más grande del continente americano, tras las de Brasil y Estados Unidos. Dentro de los afrocolombianos se pueden diferenciar cuatro grupos importantes: Los que se ubican en el corredor del Pacífico colombiano, los raizales del Archipiélago de San Andrés Providencia y Santa Catalina, la comunidad de San Basilio de Palenque y otros palenques y la población que reside en las cabeceras municipales o en las ciudades capitales como Cali. Así pues, desde la llegada de los primeros esclavos en 1504, los negros constituyen una parte importante de la población colombiana. Este grupo étnico ha realizado grandes aportes a la música y los deportes del país. Los departamentos con mayor porcentaje de afrocolombianos son Chocó (82%), San Andrés y Providencia (57%), Bolívar (28%), Valle del Cauca (27%), y Cauca (22%). El 29,2% del total del país se concentra en las ciudades de Cartagena de Indias, Barranquilla, Cali, Medellín y Bogotá, dada la migración interna hacia las grandes ciudades por parte de algunas comunidades negras. En Bogotá, la ciudad del país con más personas que no declaran pertenencia étnica, residen 100 mil afrocolombianos, que representan el 1,5% de la población del Distrito. El 29% de esta población nació en la ciudad, mientras que el 17% llegó desde el Chocó.

La constitución colombiana reconoce los derechos, cultura, costumbres, tradiciones y territorios de la población afrocolombiana que constituyen 15 717 269 hectáreas que corresponde al 16,13% de las tierras del país, titulado en Colectivos de Comunidades Negras. La población afrocolombiana es mayoritariamente joven, pero está experimentando un progresivo envejecimiento, traduciéndose en un mayor aumento de adultos, aunque relativamente "jóvenes". Además, presenta en su estructura y distribución de género un comportamiento más similar al del total de la población del país. El 86% de la población afrocolombiana está alfabetizada, siendo ligeramente mayor el porcentaje en mujeres (88%) que en hombres (86%). En cuánto a educación, el 41% posee estudios básicos primarios, un 21% no posee estudios en ningún grado y un 16% posee estudios básicos secundarios. El 47% de la población es soltera. La población afrocolombiana posee la tasa de natalidad más alta del país, siendo la media de hijos por mujer de 2.7, estando por encima de la media nacional (2,1), siendo 2.4 en entornos urbanos y 3.5 en entornos rurales, en ambos casos por encima de la media nacional (1,9 y 3,1 respectivamente).

Según datos del Departamento Administrativo Nacional de Estadística de Colombia (DANE) los datos arrojados del último censo general de la nación correspondientes a la distribución de la Población censada afrocolombiana por Departamento es la siguiente:

A pesar de haber constituido un segmento importantísimo en el pasado (en 1852 los indígenas eran el 17,8% de la población total), la población indígena de Colombia actual constituye apenas el 3,43% del total. Tras haber sido víctimas de abusos, semiesclavitud, duras condiciones de vida y trabajos forzados durante siglos, la Constitución de 1991 reconoció los derechos fundamentales de los pueblos indígenas de Colombia, que además ratificó el Convenio 169 de la OIT que regula internacionalmente los derechos indígenas. El gobierno colombiano reconoce la existencia de 87 pueblos indígenas: Achagua, Amorúa, Andoke, Arhuaco, Arzario, Awá, Bara, Barasana, Barí, Betoye, Bora, Cañamomo, Carapana, Chimila, Chiricoa, Cocama, Coreguaje, Coconuco, Coyaima, Desano, Dujo, Emberá, Emberá Chamí, Emberá Katío, Eperara Siadipara, Guambiano, Guanaca, Guane, Guayabero, Hitnü, Inga, Kawiyarí, Kamëntsa, Kankuamo, Karijona, Kichwa, Kofán, Kogui, Kubeo, Kuiba, Kurripako, Letuama, Makaguaje, Makuna, Masiguare, Matapí, Miraña, Mokaná, Muisca, Nasa, Nonuya, Nunak, Ocaina, Pasto, Piaroa, Piratapuyo, Pisamira, Puinave, Sáliba, Senú, Sikuani, Siona, Siriano, Taiwano, Tanimuka, Tariano, Tatuyo, Tikuna, Totoró, Tsiripu, Tucano, Tule, Tuyuka, Tzase, Uitoto, U'wa, Wanano, Waunan, Wayuu, Yagua, Yanacona, Yaruro, Yauna, Yuko, Yukuna, Yuri y Yurutí. Los departamentos con mayor proporción de indígenas son Vaupés, Guainía, La Guajira, Vichada, Amazonas, Cauca y Putumayo. Los departamentos de La Guajira, Cauca y Nariño concentran aproximadamente la mitad de los indígenas del país. De acuerdo con la Constitución Nacional, las lenguas indígenas son también oficiales en sus territorios, aparte del castellano. En el país, se hablan 64 lenguas amerindias y una diversidad de dialectos que se agrupan en 13 familias lingüísticas.

Según datos del Departamento Administrativo Nacional de Estadística de Colombia (DANE) los datos arrojados del último censo general de la nación correspondientes a la distribución de la población indígena censada por departamento es la siguiente:




Estudios genéticos hechos por el Proyecto Candela del genetista colombiano Andrés Ruiz Linares, docente del University College de Londres sobre la población colombiana mostró un 60% de componente europeo en el ADN nuclear, 29% indígena y 11% africano. También desde Europa la investigación de la Universidad de Cornell, señala que los colombianos tienen en promedio 57,6% de ascendencia europea, 31,8% de ascendencia amerindia y 10,6% de ascendencia africana.

Un estudio realizado por el genetista Emilio Yunis, concluyó que el colombiano promedio tiene 65% de genes europeos, 22% indígenas y 13% africanos, mestizaje que resultó tras el predominio del aporte europeo por vía paterna y el amerindio por vía materna.
Esto último se puede constatar en otro estudio realizado por el mismo profesor Yunis, según el cual la ascendencia amerindia por el lado materno (mt DNA) en Colombia fluctúa entre el 74% y el 97%. 

Otro estudio realizado por la empresa norteamericana DNA Tribes con un total de 2397 muestras sanguíneas de población colombiana, identificó la composición genética sobre la base de 8 sub-poblaciones del mundo. Mientras en los indígenas colombianos la ascendencia nativa alcanzó el 98.7%, los mestizos colombiana presentaron 56.7% de ascendencia europea, 26.2% nativa americana, 8.5% del Medio Oriente, 6.0% subsahariana y 2.6% de otros lugares del mundo.

Según una investigación llevada a cabo en las cinco regiones naturales de Colombia, la composición genética es la siguiente:

En el mismo estudio, la Región Andina fue dividida en seis subregiones, cuya composición genética fue la siguiente:

Un estudio realizado por investigadores de la Universidad Nacional de Colombia analizando 8 sistemas genéticos en 30.259 individuos de una muestra, determinó que la ascendencia regional se distribuía de la siguiente forma:

El mismo estudio encontró que a nivel subregional la ascendencia genética era la siguiente:

Según la Universidad de Brasilia, la composición genética se distribuía de la siguiente forma:

Una investigación del Ulster Institute for Social Research reveló que la composición genética por departamento en Colombia era la siguiente:

Una investigación de 2014 señala la siguiente mezcla genética para algunos departamentos colombianos:

Un estudio realizado en trece poblaciones mestizas de Latinoamérica, cuatro de ellas colombianas, arroja los siguientes resultados:

Un estudio de 2017 sobre las mismas poblaciones encontró la siguiente mezcla genética:

Según un estudio de 2010, la composición genética en algunas ciudades y regiones colombianas es la siguiente:

Según el censo de 2005, la población se auto identificó como 11,62% afrodescendiente, 3,43% amerindia, 0,01% gitana, y 85,94% sin pertenencia étnica (blancos y mestizos). De este último grupo, se estima que el 49% son mestizos y el 37% blancos.

Según Latinobarómetro, en 2016 el 47% de los colombianos encuestados se auto identificaron como mestizos, el 26% como blancos, el 6% como negros, el 5% como amerindios, el 5% como mulatos, y el 2% como pertenecientes a otro grupo. El 9% no respondió o no supo responder la encuesta.

En la Encuesta Latinoamericana de Cohesión Social, llevada a cabo en 2007, el 37% de la población se identificó como blanca, el 23% se identificó como triracial (mezcla de todo), el 17% se identificó como mezcla de blanco y negro, el 15% como mezcla de blanco e indígena, el 4% como negra, el 2% como indígena, el 1% como mezcla de indígena y negro, y el 1% no contestó o no supo contestar la pregunta.



</doc>
<doc id="15559" url="https://es.wikipedia.org/wiki?curid=15559" title="Budismo en Japón">
Budismo en Japón

La influencia del budismo en Japón se ve reflejada en muchos aspectos de su sociedad a lo largo de la historia; desde su cultura, arte y arquitectura, pasando por su sistema de valores, su filosofía y su espiritualidad llegando a forjar su carácter.

La gran mayoría de los japoneses practica de manera simultánea el budismo y el Shinto, la religión autóctona del país. Según datos de 2010 unos 45.820.000 de habitantes se declaran budistas, el equivalente al 36.2% de la población.

Tras las enseñanzas de Siddhartha Gautama, el budismo se extiende en la India y otros países asiáticos dando lugar a distintas interpretaciones sobre los textos que promulgan su mensaje. Nacen dos corrientes principales que tratan el budismo de forma diferente: la Theravada, que se establece en Sri Lanka, Birmania, Laos, Camboya y Tailandia y se basa en el seguimiento de la doctrina de Buda poniendo especial atención en el estudio de los preceptos y la vida monástica; y la Mahayana, que nace como movimiento laico que interpreta los textos más como un método que como una filosofía sin dar a Buda un trato de deidad y que se expandiría a partir del siglo I d.E.C. en Asia Central, China, Corea y Japón.

Los primeros misioneros Mahayana penetran en China durante la Dinastía Han por vía marítima, llegando a las regiones sureñas del río Yangtzé y Huai, y a través de la Ruta de la Seda, alcanzando las regiones del este hasta llegar a la capital Han de Luoyang, donde en el año 68 d.E.C. se establecería el Templo del Caballo Blanco. Habiendo sido casi coetáneo de Confucio, el budismo no sería ampliamente aceptado en el país hasta la caída de los Han, que propiciaría la necesidad de la población china de acoger la nueva fe extranjera.

La llegada desde la India en el siglo V de Bodhidharma, supondría un cambio en la percepción de los preceptos budistas y el nacimiento del budismo Chan. Al contrario que otros misioneros anteriores, Bodhidharma no pretende ser recibido con honores de iluminado sino que cuestiona las escrituras y doctrinas establecidas.

Tras su llegada al sur de China, Bodhidharma es invitado por el emperador Wu, que busca su bendición después de haber realizado grandes inversiones en la difusión del budismo. Bodhidharma le daría a conocer el error que supone buscar la salvación por medio de la adoración de lo sagrado y viendo que su empresa no podría llevarse a cabo en el estado de los Liang, continuaría su marcha hasta llegar al estado de los Wei para finalmente establecerse en Shaolin. La forma de enseñar de Bodhidharma, basándose en formular preguntas que ayudaban a encontrar la iluminación en lugar de explicar problemas, supondría una de las bases del budismo zen. Posteriormente, las enseñanzas de Bodhidharma fueron difundidas por los diferentes patriarcas que le sucedieron que, fusionando a lo largo del tiempo los principios del budismo Mahayana primitivo con las ideas taoístas, dieron lugar al budismo Chan.

En el Libro de Liang de Las Veinticuatro Historias, texto chino que supone la única referencia de la época ya que los japoneses aún no dominaban la escritura, se tiene constancia de asentamiento de budistas en Japón.

En el año 552, Syong-Myong, rey de Paekche (uno de los tres reinos que formaban Corea), hace llegar una serie de regalos a Kinmei como muestra de agradecimiento por su colaboración en la guerra contra Silla. Estos se basaban en una imagen de Buda fundida en oro y cobre y textos con sutras escritos en sanscrito, y adjuntaban una carta donde el rey Syong-Myong mostraba su admiración por el budismo y la conveniencia política de adoptar la nueva religión.

El emperador Kinmei se mantuvo al margen respecto al budismo y cedió la imagen a Soga no Iname, encargado de gestionar las inversiones de inmigrantes acaudalados y miembro de la familia Soga que mantenía grandes relaciones con las cortes coreanas. Estos abrazaron el budismo y reunieron a tres monjas que tras recibir enseñanza en Corea, se encargarían de gestionar el templo budista que Soga no Umako hizo construir.

Hasta entonces, la religión practicada en Japón era el Shinto y algunas familias de la élite japonesa como la de los Mononobe y Nakatomi, que basaban su linaje en una supuesta descendencia de los "kami" sintoístas, se vieron amenazados por el budismo. Las tensiones entre la familia Soga y las de Mononobe y Nakatomi darían como resultado un conflicto armado en el que los Soga saldrían victoriosos y conseguirían el control de la familia imperial con la se emparentaría. 

Con la toma del poder por parte de la Emperatriz Suiko, sobrina de Soga no Umako, y gracias a la dedicación del Príncipe Regente Shōtoku, el budismo se establecería definitivamente en Japón. La consideración al emperador de descendiente directo de Amterasu, hace que las dos religiones, budismo y sintoísmo, se integren sin detrimento de ninguna. Shōtoku sería considerado una divinidad tras su muerte, y su vida sería contada con muchos paralelismos con la de Siddharta Gautama.

En este Periodo el número de templos experimentó un gran crecimiento y los emperadores Tenmu y Monmu, tras abrazar el budismo, sentaron las bases del patrocinio estatal. Este patrocinio dio lugar a seis escuelas: Ritsu, Jōjitsu y Kusha pertenecientes al budismo Theravada y Sanron, Hossō y Kegon que seguían directrices del budismo Mahayana. 

Los gobernantes encontraron especialmente atractivo el ideal budista de que el mandato benevolente de un monarca traía el paraíso en la tierra, concepto que añadía legitimidad a su gobierno.

Ya en el año 627, en el Japón había 46 templos budistas, 816 monjes budistas y 569 monjas budistas.

Durante el Periodo Heian se crean las escuelas Tendai y Shingon.

En el año 794 Saicho funda en Hiei la escuela Tendai, que basa su filosofía en el "Sutra del Loto" y los tratados Tiantai chinos sobre técnicas de meditación. Se cree que la idea de que Kyoto fuese el asentamiento como nueva capital se debe él tras aplicar técnicas de "feng shui."

Kūkai funda en el año 816, con la ayuda del Emperador Saga, un monasterio en el monte Koya y establece la secta Shingón. Fue uno de los emisarios enviados a China junto a Saicho y sigue las doctrinas del budismo esotérico Vajrayana. En 921 se le concede el título póstumo de Kōbō-Daishi “"Gran maestro que expande el budismo por doquier"”.

En esta época aparecen nuevas sectas muy diferentes a las aparecidas en Nara, con doctrinas más sencillas que facilitarían su llegada a las clases más populares. Estas nuevas formas de budismo resultan mucho más personal e íntimo, y reivindica el valor de las mujeres garantizándoles la igualdad de posibilidades de salvación religiosa, hasta entonces negada. Surgen dos grandes corrientes: el budismo de la Tierra Pura y el budismo Zen.

El budismo de la Tierra Pura se fundamenta en el "nenbutsu" o culto al Buda Amida (bodhisttva Dharmakara), héroe del Sutra de La Tierra Pura ("Daimuryoju-kyo" en japonés). fue el principal artífice de la expansión del culto de Amida llegado desde China en el año 847.

Honen (1133-1212) fue el fundador de la secta de la Tierra Pura. Tras el estudio del "Sutra de la visualización de la Tierra Pura," escrito por Shandao, Honen llega a la convicción de que la recitación constante del "nenbutsu" es la clave para la salvación como promete el Buda Amida. Actualmente, esta secta cuenta con 6.500.000 seguidores en Japón y es, junto a la secta de la Verdadera Tierra Pura, la que poseen mayor número de fieles.

Shinran (1173-1262), discípulo de Honen y formado también en la disciplina Tendai impartida en el monte Hiei, fue el fundador de la secta de la Verdadera Tierra Pura. Basaba su diferencia en que no creía en la conveniencia de la repetición del "nenbutsu", sino que consideraba que una sola muestra de devoción sincera hacia el buda Amida era suficiente. Determinó que los sacerdotes podían contraer matrimonio y el liderazgo asumió carácter hereditario. A día de hoy, esta secta cuenta con 13.000.000 de seguidores.

 (1234–1289) fundó la tercera de las escuelas del budismo de la Tierra pura. De familia acomodada, renunció a su fortuna para convertirse en predicador itinerante después de recibir en sueños un oráculo de Gongen, divinidad "kami" y manifestación de la esencia de Buda. Basó su existencia en emular a Buddha Shakyamuni, renunciando a todos los bienes materiales, desapegándose de la existencia egoísta. Atrajo a gran número de adeptos en poco tiempo y estos formaron la secta “Tempestiva” o Ji-shu. Actualmente cuenta con entre 300 y 400.000 adeptos.

El budismo Zen fue la otra gran corriente religiosa que gozó de una gran difusión en este periodo y actuó como un puente entre las sectas tradicionales y las nuevas. Contó con algunas sectas muy importantes como fueron la Rinzai y la Sōtō, que ejercieron una gran influencia sobre la filosofía samurái. 

Mientras en la secta de la Tierra Pura se pone énfasis en el culto a Amida y la recitación del "nenbutsu", las escuelas Zen se centran en el esfuerzo personal individual para alcanzar la iluminación ("satori") por medio de la meditación ("zazen"). Según la secta Sōtō, es la práctica de la meditación la que proporciona la iluminación. La secta Rinzai mira de acelerar este proceso añadiendo un "koan" (problema destinado a ser resuelto con el uso de la meditación). Se calcula que los seguidores de las diferentes sectas Zen suponen el diez por ciento de los budistas registrados en Japón.

Durante la regencia Hojo de Kamakura se patrocina el Zen, ya que se consideraba que transmitía la revitalizante cultura china y éste elevaba el nivel cultural del shogunato sobre la corte imperial de Kyoto.

El linaje Rinzai del Zen llegó a Japón procedente de China de mano de Eisai (1141-1215). Formado en el monte Hiei, tras peregrinar a China se propuso construir el primer templo Zen en Kyoto, encontrándose con la negativa de la secta Tendai. Escribió la "Propagación del Zen para la seguridad del país (Kozen gokokuron)," donde se afirmaba que el Zen era el camino para conocer la verdadera naturaleza de la conciencia y contenía la enseñanza de como eliminar el ego; promocionar el Zen era fomentar la falta de egoísmo, lo que según Eisai facilitaría la creación de una sociedad pacífica. Finalmente, en 1202 el shogunato le concedió permiso para construir el templo Zen de Ken’ninji en Kyoto, donde acudiría a practicar zazen un joven Dogen.

Dogen (1200-1253)fue ordenado en el monte Hiei de la secta Tendai con trece años y un año después se convirtió en discípulo de Eisai en Ken’ninji. En 1225, después de viajar a China, Dogen toma como maestro a Rujing ("Nyojyo") con el que establece una estrecha relación y bajo su guía alcanza la iluminación. En 1228 regresa a Japón y en 1233 funda el templo de Koshoji en Uji introduciendo la tradición del linaje Caodong (Sōtō en japonés) de su maestro Rujing. La redacción de sermones y directrices dirigidas a sus discípulos acabaría convirtiéndose en el "Tesoro de la visión del verdadero Dharma (Shōbōgenzō)."

Dogen era de la creencia que la meditación no se realizaba con el fin de alcanzar la iluminación, sino que la práctica del zazen constituía el fin en sí mismo, por lo que no veía necesario el uso de los "koan". Practicar la meditación de forma adecuada ayudaba a estar en consonancia con la naturaleza del buda original.

Al igual que otros líderes religiosos coetáneos, Nichiren (1222-1282) se formó en el monte Hiei, donde forjó su convicción de que el "Sutra del Loto" contenía las verdaderas enseñanzas de Buda. Predicador carismático, atrajo a un gran número de seguidores, especialmente acaudalados terratenientes. En 1257, tras una serie de calamidades naturales y la crisis social y política que vivía el país, Nichiren concluye que se deben a la desaparición de la práctica de la perseverancia y el sacrificio tal y como muestra el "Sutra del Loto", atribuyendo esas desgracias a la práctica del "nenbutsu" de la Tierra Pura. Tras los intentos de invasión mongoles de 1268 y 1281, sus acusaciones contra las sectas de la Tierra Pura van en aumento y es desterrado en varias ocasiones.

El Periodo Muromachi vio como el sintoísmo y el budismo se fusionaban. Las sectas Tendai y Shingon, cuyos fundadores Saicho y Kukai profesaban un profundo respeto por los "kami" autóctonos de Japón, propiciaron la incorporación de las divinidades sintoístas en su marco institucional. Las victorias obtenidas contra las invasiones mongolas de 1274 y 1281 por sendos tifones, hizo creer que Japón vivía bajo la protección de las divinidades "kami" que enviaban el viento divino (kamikaze).

Algunas sectas del Periodo Kamakura crearon sus propias milicias religiosas cuando el país quedó en manos de los señores de la guerra. Las sectas Nichiren y de la Tierra Pura entran en conflicto entre sí y con las sectas de Nara; es normal que los templos posean unidades militares propias formadas por monjes-soldado. 

En 1549 hace su introducción en la religión japonesa el cristianismo de la mano de Francisco Javier, misionero jesuita que llegaba a la isla con el objetivo de evangelizarla. En la campaña de unificación de Japón, Oda Nobunaga encuentra la férrea oposición de la comunidad de la Tierra Pura y decide arrasar el monte Hiei matando a quien se encuentra en su camino. Su repulsa a las sectas budistas provocó que patrocinara al cristianismo.

Toyotomi Hideyoshi, sucesor de Nobunaga, adopta el cristianismo en primera instancia pero algunas costumbres y prácticas llevadas a cabo por algunos conversos y la acumulación de poder de la que hacían gala, hacen que publique un edicto en el que se ordena abandonar Japón a los misioneros. Tras ser apaciguado por Valigniano, la prohibición no es llevada a cabo, pero el conocimiento de las intenciones de conquistar Japón por parte de los monarcas españoles y portugueses, y la entrada clandestina de franciscanos en el país, hacen desatar la ira de Hideyoshi y castiga a los cristianos residentes empleando técnicas de la Inquisición.

El sistema "danka", que obliga a las familias a convertirse en protectoras de su templo local como prueba del rechazo al cristianismo, convirtió a los templos budistas en instituciones. Unos 1600 templos recibieron el apoyo incondicional de la población. Además, existía la obligación de colaborar en los gastos del templo y en asistir a sus actos.

Ingen Ryuki (1592-1673), maestro Chan erudito e iluminado, llega a Japón tras ser invitado y después de una audiencia ante el shogun, éste queda tan impresionado que decide cederle terrenos para que pueda construir un monasterio. Su doctrina combinaba el nenbutsu con el zazen. Sus seguidores actualmente ascienden a 350.000 y forman el 8,5 por ciento de los budistas japoneses.

Con el traspaso de poderes del shogunato al emperador, algunos políticos influyentes promueven la separación del sintoísmo y el budismo, desatando una ola de violencia antibudista en varias zonas de Japón. Ante los actos vandálicos de los sintoístas, el gobierno determinó que “separación” no equivalía a “destrucción”.

Mientras se instauraba el Shinto Estatal, las sectas budistas se vieron obligadas a adaptarse. El Rinzai Zen y el Soto Zen se modernizaron adoptando ideas occidentales pero manteniendo su identidad japonesa. Se aprobaron edictos que permitían a los monjes comer carne y casarse. Estas medidas, junto a la difusión del Shinto Estatal, fueron definitivas para desacralizar al budismo y marginarlo. 

Después de la Restauración Meiji se registraron 13 escuelas budistas que se dividían en 56 ramas, durante la II Guerra Mundial se redujeron a 28. La ley que reguladora fue revocada y actualmente se permite su regreso.

Fundador: Xuanzang (玄奘 "Genjo" en japonés), China, c. 630 dC
Nombre en chino: Faxiang (法相), "El carácter del dharma"
Llega al Japón: con Dosho, 654 dC
Influencias principales: Sanron, Zen
Doctrina: "Yuishiki" ("sólo la conciencia")
Texto fundamental: "Jo yuishikiron" (成唯識論) 

Fundador: Dushun (杜順, "Dojun" en japonés), China, c. 600 dC
Nombre en chino: Huayan (華厳)
Llega al Japón: con Bodhisena, 736 dC
Influencias principales: Hosso
Doctrina: "Shihōkai" (四法界)
Texto fundamental: Avatamsaka Sutra ("Kegonkyo" 華厳経)
Fundador: Daoxuan (道宣, "Dosen" en japonés), China, c. 650 dC
Nombre en chino: Lü (律), "Vinaya"
Llega al Japón: con Ganjin (鑑真), 753 dC
Doctrina: Vinaya (las reglas monásticas en el Tripitaka)
Texto fundamental: Dharmaguptavinaya ("Shibunritsu" 四分律)

Las escuelas monásticas (密教, "mikkyo" en japonés) pertenecen a la escuela Vajrayāna (Vehículo de Diamante) del budismo, también conocido como budismo tántrico.

Fundador: Zhiyi (智顗, "Chigi" en japonés), China, c. 550 dC
Nombre en chino: Tiantai (天台), nombrado en honor al templo fundacional
Llega al Japón: con Saichō (最澄), 807 dC
Doctrina: "Sandai" (三諦, "Triple Verdad")
Texto fundamental: Sutra del Loto ("Hokkekyo" 法華経)

Fundador: Kukai (空海), Japón, 816 dC
Nombre en japonés: 真言, "Palabra Verdadera"
Influencias principales: Tantra
Doctrina: Vajrayāna/Tantra (diestro, en el sentido de "usar la mano derecha")
Textos fundamentales: Mahavairochana Sutra ("Dainichikyo" 大日経), Sutra del Diamante ("Kongokyo" 金剛経) 

Fundador: Nichiren Daishonin, 1253 dC
Nombre en japonés: 日蓮, "Sol Loto"
Influencias principales: Tendai
Doctrina: "Nam Myoho Renge Kyo" (南無妙法蓮華経)
Texto fundamental: Sutra del Loto ("Hokkekyo" 法華経)

El período Kamakura fue testigo de la llegada de las dos escuelas que, probablemente, han tenido el mayor impacto en el país: la escuela amidista Tierra Pura, que daba énfasis a la salvación a través de la creencia en Amitābha y es hasta nuestros días la escuela budista más grande del Japón (y por toda Asia); y la escuela Zen, de corte más filosófico, que fue rápidamente adoptada por las clases altas y tuvo un profundo impacto en la cultura japonesa.

Fundador: Huiyuan ("Eon" en japonés), China, c. 400 dC
Nombre en chino: "Jingtu" Tierra Pura
Llega al Japón: con Honen, 1175 dC
Doctrina: "Nembutsu" ("oración a Buda")
Texto fundamental: Sutra de la vida infinita ("Muryojukyo")

Fundador: Shinran, 1224 dC
Nombre en japonés: "La verdadera Tierra Pura"
Influencia principal: Jōdō
Doctrina: "shintai zokutai" ("Verdad cierta, verdad común")
Texto fundamental: Sutra de la vida infinita ("Muryojukyo")

Es una escuela de budismo Zen que se centra en la práctica de zazen Shikantaza (tan solo sentarse) para conseguir el satori (iluminación)

Escuela de budismo Zen que propone para conseguir el satori (iluminación) los ejercicios Kōan (enseñanzas en forma de acertijos)


El budismo llegó al Japón el año 572, cuando los coreanos llegan a Nara para presentar las ocho escuelas doctrinarias. Las escuelas de Nara finalmente menguaron en su influencia y las escuelas que aún se mantienen son:




</doc>
<doc id="15562" url="https://es.wikipedia.org/wiki?curid=15562" title="Geografía de Ecuador">
Geografía de Ecuador

Ecuador (nombre oficial: República del Ecuador) es un país situado en la parte noroeste de América del Sur. Ecuador limita al norte con Colombia, al sur y al este con Perú y al oeste con el océano Pacífico. El país tiene una extensión de 283.561 km². Además del territorio continental, Ecuador está formada por el archipiélago de Colón, aparte de otras cercanas al continente, como Puná, Santay, y la Isla de la Plata.

Ecuador se encuentra sobre la línea ecuatorial terrestre por lo cual su territorio se encuentra en ambos hemisferios. Comprende dos espacios distantes entre sí: el territorio continental al noroeste de América del Sur con algunas islas adyacentes a la costa y, el archipiélago o provincia insular de Galápagos, que se encuentra a 1000 kilómetros de distancia del litoral ecuatoriano en el Océano Pacífico.


Las principales unidades del relieve ecuatoriano son la llanura costera al norte del Golfo de Guayaquil, la sección de la Cordillera de los Andes en el centro del país y un extenso sector de la llanura amazónica ubicado al oriente del país.

Hacia el suroeste se ubica el Golfo de Guayaquil, donde desemboca el río Guayas en el Océano Pacífico. Muy cerca de Quito, la capital, sobre la Cordillera de los Andes, se alza el Cotopaxi, el volcán activo más alto del mundo.

El punto más alto del Ecuador es el volcán Chimborazo, con 6310 nbsp;msnm y cuya cima es el lugar más lejano al núcleo de la tierra debido a la silueta elíptica del planeta.

Es parte del Chocó biogeográfico. Se ubica al oeste del país; el territorio de la Costa está formado por llanuras fértiles, colinas, cuencas sedimentarias y elevaciones de poca altitud. Por su territorio corren ríos que parten desde los Andes hasta llegar al Océano Pacífico. Cinco provincias cuentan con playas y balnearios muy atractivos para el turista. En esta zona se encuentra la mayor ciudad de Ecuador: Guayaquil y otras importantes ciudades ecuatorianas: Machala, Manta, Portoviejo, Santo Domingo y Quevedo (Ecuador). La Costa está dividida en siete provincias: Esmeraldas, Santo Domingo de los Tsáchilas, Manabí, Guayas, Santa Elena, Los Ríos y El Oro.

Se encuentra ubicada entre el Nudo de los Pastos al norte hasta el de Loja al sur, ocupando una franja de 600 km de largo por 100 km a 120 km de ancho, la altura media es de 4 000 metros.
La estación lluviosa o invierno dura de octubre a mayo, con una temperatura anual promedio que varía de 12 °C a 18 °C. Esta región se caracteriza por sus impresionantes elevaciones montañosas, volcanes y nevados. Entre los más importantes están el Chimborazo y el Cotopaxi. Sus diez provincias cuentan con ciudades de gran importancia histórica como Quito y Cuenca, y centros artesanales como Otavalo. Igualmente, existen varios parques nacionales con flora y fauna muy ricas y variadas. Está conformada por 10 provincias: Carchi, Imbabura, Pichincha, Cotopaxi, Tungurahua, Bolívar, Chimborazo, Cañar, Azuay y Loja.

Comprende las provincias de Orellana, Pastaza, Napo, Sucumbíos, Morona Santiago, Zamora Chinchipe. Se extiende sobre un área de 120.000 km² de exuberante vegetación, propia de los bosques húmedo-tropicales. Sus límites están marcados por la Cordillera de los Andes en la parte occidental de esta región, mientras que Perú y Colombia el límite meridional y oriental, respectivamente. El relieve de la Amazonía está conformado por una serie de colinas que se originan en los Andes orientales y descienden hasta la llanura del Amazonas. Existen dos regiones geográficas: la Alta Amazonía y la Llanura Amazónica. En la primera región se pueden encontrar las cordilleras de Napo Galeras, Cutucú y Cóndor. Los relieves más importantes de la Amazonía se encuentran en la parte norte de la región, cerca al volcán Sumaco, y los más bajos hacia el este de la región.

Las islas Galápagos (también islas de los Galápagos y oficialmente archipiélago de Colón) constituyen un archipiélago del océano Pacífico ubicado a 1.000 km de la costa de Ecuador. Está conformado por 13 grandes islas volcánicas, 6 islas más pequeñas y 107 rocas e islotes, distribuidas alrededor de la línea del ecuador terrestre. Administrativamente, las islas constituyen una provincia de Ecuador, cuya capital es Puerto Baquerizo Moreno (oficialmente, también se le denomina "Región Insular del Ecuador"). El 12 de febrero de 1832, bajo la presidencia de Juan José Flores, las islas Galápagos fueron anexadas a Ecuador. Desde el 18 de febrero de 1973 constituyen una provincia de este país. Se estima que la formación de la primera isla tuvo lugar hace más de 5 millones de años, como resultado de la actividad tectónica. Las islas más recientes, llamadas Isabela y Fernandina, están todavía en proceso de formación, habiéndose registrado la erupción volcánica más reciente en 2009. Todo el archipiélago tiene una extensión total de 8 010 km².

Las principales islas son:

Casi todos los ríos en el del Ecuador nacen en la región de la Sierra y descienden al este hacia el río Amazonas o el oeste hacia el Océano Pacífico. El aumento de los ríos por el deshielo en los bordes de los picos nevados o de las abundantes precipitaciones que caen en las elevaciones más altas. En la región Sierra, los arroyos y ríos son estrechos y el flujo rápidamente en laderas escarpadas. Los ríos pueden lenta y ampliar a medida que cruzan el hoyas llegado a ser rápido una vez más a medida que fluyen desde las alturas de los Andes hasta las elevaciones más bajas de las otras regiones.

En la región de la Costa, la Costa Externa tiene en su mayoría ríos intermitentes que son alimentados por las constantes lluvias de diciembre a mayo y se convierten en cauces vacíos durante la estación seca. Las pocas excepciones son los más largos, ríos perennes que fluyen a lo largo de la Costa del Externa Interna Costa y la Sierra en su camino hacia el Océano Pacífico. La Costa Interna, por el contrario, es atravesado por los ríos perennes que pueden inundarse durante la temporada de lluvias, a veces formando pantanos.

El sistema del río Guayas, que fluye hacia el sur hasta el Golfo de Guayaquil, constituye el más importante de los sistemas de drenaje en el interior de Costa. La Cuenca del Río Guayas, incluida la tierra drenada por sus afluentes, es de 40.000 kilómetros cuadrados de superficie. El río Guayas, de sesenta kilómetros de largo nace, al norte de Guayaquil en la confluencia de los ríos Babahoyo y Daule. En pocas palabras constreñido a Guayaquil por las colinas, el Guayas se amplía al sur de la ciudad y fluye a través de una red de pequeñas islas del delta y los canales. En su desembocadura, el río forma un amplio estuario con dos canales en torno a Isla Puná, la más profunda de lo que se utiliza para la navegación.

El segundo gran sistema fluvial Costa del Esmeraldas, se levanta en la Hoya de Guayllabamba en la Sierra como el río Guayllabamba y fluye hacia el oeste para desembocar en el Océano Pacífico al este de la ciudad de Esmeraldas. El río Esmeraldas es de 320 kilómetros de largo y tiene una cuenca de drenaje de 20.000 kilómetros cuadrados.

Los principales ríos en el Oriente incluyen el Pastaza, Napo y Putumayo. El Pastaza está formado por la confluencia de los ríos Chambo y Patate el, ambos nacen en la Sierra. El Pastaza incluye la cascada de Agoyán, que a los sesenta y un metros es la cascada más alta de Ecuador. El Napo se levanta cerca del monte Cotopaxi y es el río principal utilizado para el transporte en las tierras bajas orientales. El Napo rangos de ancho de 500 a 1.800 metros. En su curso superior, el Napo fluye rápidamente hasta la confluencia con uno de sus principales afluentes, el río Coca, donde se hace más lento y se nivela. El Putumayo forma parte de la frontera con Colombia. Todos estos ríos desembocan en el río Amazonas.

Las Islas Galápagos no tienen ríos importantes. Varias de las islas más grandes tienen, sin embargo, fuentes de agua dulce.



Debido a la presencia de la cordillera de los Andes y según la influencia del mar, el Ecuador continental se halla climatológicamente fragmentado en diversos sectores. Además, a causa de su ubicación ecuatorial, cada zona climática presenta sólo dos estaciones definidas: la húmeda y la seca, llamadas erróneamente «invierno» y «verano» respectivamente, al igual que ocurre en otras regiones del globo donde por sus emplazamientos próximos a la línea ecuatorial, no ocurren verdaderos inviernos y veranos.

Tanto en la Costa como en el Oriente, la temperatura oscila entre los 20 °C y 33 °C, mientras que en la sierra, esta suele estar entre los 3 °C y 26 °C. La estación húmeda se extiende entre diciembre y mayo en la costa, entre noviembre a abril en la sierra y de enero a septiembre en la Amazonía.
Galápagos tiene un clima más bien templado y su temperatura oscila entre 22 y 32 °C, aproximadamente.

Estas estaciones húmedas y secas causan en cada región del país diferentes estaciones climáticas. Son muy variables las temperaturas.

Así, de enero a marzo es principalmente estación seca en la sierra, mientras que en la costa y amazonía es temporada húmeda, con la mayoría de días nublados.

Del modo contrario, de julio a septiembre en la sierra es temporada húmeda, mientras que en la costa, seca.











</doc>
<doc id="15564" url="https://es.wikipedia.org/wiki?curid=15564" title="Arte de la Antigua Grecia">
Arte de la Antigua Grecia

La historiografía del arte ha identificado varios estilos que periodizan el arte de la Antigua Grecia:

El periodo arcaico se inicia a finales del siglo VIII a. C. y abarca hasta comienzos del siglo V a. C. En este periodo se produce una expansión de la polis griega, instaurándose un nuevo orden ciudadano, con la tiranía como marco político principal, sistema que pronto desaparecerá frente al ideal igualitario de ciudadanía del siglo V a. C. La legitimación de este tipo de mandato ciudadano supone la promoción de grandes obras públicas, representativas del prestigio del tirano, quien apoya la creación de edificios civiles y religiosos en las ciudades donde gobierna, para lo cual manda remodelar su entramado urbano. Esta actuación tuvo como objeto otorgar a cada urbe una identidad propia, al tiempo que mostrar su preponderancia sobre el resto de ellas. Consecuentemente, el arte desempeña en esta etapa un nuevo papel propagandístico de la tiranía, cuyos gobernantes lo utilizan para justificar su poder escasamente legitimado. A partir del siglo VI a. C. el centro político de la polis se convierte en un lugar de gran relevancia artística, convirtiéndose la plaza pública o ágora en el corazón de las actividades cívicas de la sociedad. Entre todas ellas sobresale la de la ciudad de Atenas, impulsada por el legislador Solón y monumentalizada en la época de los Pisistrátidas.

El culto religioso desempeñó también un papel fundamental en la sociedad griega de este periodo, de manera que todas aquellas ciudades que dispusieron de medios económicos suficientes promovieron la construcción de edificios religiosos en piedra, los cuales cumplieron un importante papel a la hora de cohesionar las diferentes clases de la nueva sociedad, menos igualitaria que la de siglos anteriores. Se crean ahora santuarios panhelénicos, como Delfos y Olimpia, donde los distintos tiranos realizan grandes ofrendas votivas para exhibir su poder, y se fomentan nuevos cultos populares, al tiempo que surgen mitos relacionados con dioses y héroes locales, lo que incrementa las identidades políticas de las distintas polis que necesitan sentirse independientes y destacar sobre el resto.

La arquitectura griega fijó las formas del templo, que se fue desarrollando en las acrópolis (ακρόπολις) o ciudadelas elevadas de cada ciudad; así como en los santuarios panhelénicos. Los propiamente "panhellénikós" (πανελληνικός -"de todos los griegos"-), celebraban juegos ("agónes" αγώνες -"contienda", "desafío", "disputa"-), donde competían atletas y aurigas en representación de sus polis, en una sublimación de la violencia en lo sagrado que convertía a los vencedores en héroes o semidioses, por lo que adquirían el derecho a ser representados en estatuas; y acumulaban riquísimas ofrendas, guardadas en lujosos edificios, levantados a costa de cada "polis" (los "thesaurós" θησαυρός). Aunque había muchos otros juegos en honor de otras divinidades o en otras polis (como los Panatenaicos de Atenas), se destacaban cuatro, no por el premio ofrecido (unas olivas, o una corona de hojas de laurel), sino por el prestigio que daba la concurrencia periódica (cada dos o cuatro años) de gentes de toda la Hélade: el de Apolo en Delfos (donde se celebraban los oráculo de Dodona), el de santuario de Olimpia Zeus en Olimpia (del que sólo quedan ruinas, donde se celebraban los Juegos Olímpicos), el de Poseidón en Istmia (del que sólo quedan los cimientos, donde se celebraban los Juegos Ístmicos) y el de Zeus en Nemea (del que quedan unos restos de época helenística, donde se celebraban los Juegos Nemeos). Sin ser estrictamente "panhelénicos", también alcanzaron un enorme prestigio en toda la Hélade otros santuarios: el de Hera en Samos (Ἥραιον, "Heraion", el primer gran ejemplo de orden jónico -Reco y Teodoro de Samos-, donde se celebraba la enigmática "hierogamia" ἱερός γάμος) o el de Artemisa en Éfeso (Ἀρτεμίσιον, "Artemision", el segundo gran ejemplo del orden jónico, que entró en el catálogo de las siete maravillas del mundo).

La lista de los templos importantes sería inacabable (templo de las Musas en Helicón -de hecho, todo el monte Helicón estaba dedicado a ellas, al igual que el monte Parnaso, pero de un modo más tangible a la forma en que el monte Olimpo lo estaba a los principales dioses-, templo de Démeter en Eleusis, templo de Apolo en Dídima, templos de Poseidón -en Halicarnaso, en Ege, en Calauria, en Atenas-, templo de Artemisa -en Carje, en Esparta-, templos de Afrodita -en Cnido, en Lindos, en Citerea-, templos de Hermes -en Imbros, en Samotracia, en Lemnos-, templos de Hera -en Micenas, en Argos, en Figalia, en Esparta-, templo de Ares en Esparta, templos de Dionisos -en Naxos, en Chios, en Atenas-, templos de Asclepio -en Cos, en Epidauro, que alcanzarían mucho mayor prestigio en épocas posteriores-), algunos de ellos formando una relación espacial definida, como el "Triángulo Sagrado" entre el "Parthenón" (Παρθενών -templo "de la virgen", es decir, de Atenea-, en la Acrópolis de Atenas), el "Soúnion" (Σούνιονy, en el promontorio desde el que Egeo se arrojó al mar) y el templo de Afaia en Egina.

La forma del templo griego derivaba del "megaron" (μέγαρον) micénico: esencialmente una planta rectangular cubierta con tejado a dos aguas, con los elementos estructurales de madera. Con la misma estructura se han encontrado restos de un templo de la Época Oscura en Lefkandi (Eubea), y los primeros restos encontrados del "Heraion" de Samos (mediados del siglo VIII a. C.) son similares. La "petrificación" de los elementos del templo se fue produciendo paulatinamente (columnas -cuyo fuste mantiene el recuerdo vegetal con las estrías o el acanalamiento-, vigas -que producen los remates exteriores de triglifos y metopas-, arquitrabes, cornisas, etc.), siendo el ejemplo más evidente el "Heraion" de Olimpia (hacia el 600 a. C.). Una de las razones que impulsaron el cambio fue la generalización de las tejas de cerámica en sustitución de la cubierta de paja y ramas, y que se produjo en Corinto en el siglo VII a. C. Uno de los primeros fue el "Thermón" (Θερμον, templo de Apolo en Thermos, Etolia, hacia el 630 a. C.). El peso, muy superior, obligaba a disminuir la pendiente del tejado, y terminó por definir las proporciones definitivas del frontón que resultan tan armónicas. En las distintas zonas de la Hélade se definieron los estilos dórico (más sobrio y macizo) y jónico (más esbelto y decorativo).

La escultura griega de época arcaica, influenciada notablemente por la egipcia, se caracterizó por rasgos originales, como la sonrisa eginética o arcaica (llamada así por exhibirse en la figura de un famoso guerrero moribundo del Templo de Afaia en Egina); que se fueron transformando, al final del periodo (últimas décadas del siglo VI y primeras del V a. C.), en un estilo de transición al clasicismo denominado estilo severo, estimulado finalmente por la necesidad de renovar la decoración escultórica de los templos destruida durante la invasión persa.

Las figuras masculinas ("kuroi", en singular "kuros" κοῦρος) y femeninas ("korai", en singular "kore" κόρη) podían representar tanto a seres humanos como a dioses, muestra de la antropomorfización de estos y de la elevación al rango semidivino o heroico de aquellos (particularmente, del prestigio que alcanzaban los vencedores en los juegos panhelénicos).

Las primeras esculturas eran las "xoana" (ξόανα, en singular "xoanon" ξόανον), de madera, representaciones muy simplificadas del cuerpo humano adaptadas a la forma cilíndrica del tronco de un árbol. Fueron sustituyéndose por figuras talladas en mármol (especialmente prestigiosa fue la cantera del Pentélico) y las fundiciones de bronce. Dada la posibilidad de reutilizar este material tan caro, han sido muy pocas las que se han conservado. De mucho menor coste eran las figurillas de terracota, que se producían a escala industrial, mediante moldes.

Además de las posibilidades texturales que ofrecen los distintos materiales y técnicas de acabado, aprovechadas de forma limitada en la época arcaica, fue la policromía aplicada sobre las esculturas la que las dotó de luminosidad y sensación de vida. Los antiguos griegos no hubieran concebido que una escultura se dejase sin pintar, la considerarían imperfecta o inconclusa. Incluso la inevitable pérdida de los colores por el paso del tiempo, que el gusto romántico considera un incremento del interés estético, era considerada como un deterioro esencial.

Tras un inicial periodo geométrico (siglos IX y VIII a. C.), al que siguió un período orientalizante (siglos VII y primera mitad del VI a. C.) en el que se detecta la influencia asiria y de otras civilizaciones del Antiguo Oriente (por la importancia y difusión que alcanzaron en esta época los talleres de Corinto se habla de estilo protocorintio); la cerámica griega fue evolucionando sus formas, que hacia el final del siglo VI a. C. alcanzaron un alto grado de refinamiento expresivo, respondiendo a un amplio conjunto de necesidades refinadas de la vida cotidiana de las clases altas, y a la demanda de productos de lujo fácilmente exportables a todo el espacio mediterráneo, e incluso a lejanos lugares en el centro de Europa.

La producción en muchas de las colonias fundadas en esos siglos fue tan importante como la de las metrópolis. Además, la influencia de la cerámica griega se dejó notar en la producción local de los pueblos indígenas, especialmente en la cerámica etrusca (que tiene tipologías verdaderamente sincréticas, como es el caso de la hidria caeretana o hidria de Caere) o en la cerámica ibérica.

Se aprovecharon extensamente las posibilidades que las distintas tipologías de vasos daban en ciertas partes de su superficie (fondos de las copas, vientres y cuellos de las ánforas, etc.) para ejercer como soporte para la pintura griega, que se expresó sucesivamente en dos estilos principales, denominados "cerámica de figuras negras" y "cerámica de figuras rojas".

Cada escuela local de ceramistas se distinguió por un estilo local característico, aunque se influyeron mutuamente.

Comenzó a ser común que los ceramistas y, menos frecuentemente, los pintores firmaran sus obras (Clitias, Exequias, Psiax, Eufronio), lo que se interpreta como una valoración social de su trabajo, implicando un concepto muy moderno de la función del arte y del artista, en un momento en que el trabajo manual estaba degradándose en su consideración, vinculada a la de los esclavos. Es habitual que sólo se conozca el nombre del ceramista, con lo que el pintor se denomina por este (Pintor de Andócides, Pintor de Amasis, Pintor de Antimenes, Pintor de Taleides). En otras ocasiones sólo se ha podido establecer la identidad común de un maestro por sus obras (Pintor de Príamo, Pintor de Neso, Pintor de las cabezas de caballo, Pintor de Aqueloo) o por los lugares donde se han encontrado (Maestro del Dípilon) o los museos y colecciones particulares donde se conservan (Maestro o Pintor de Madrid, Maestro o Pintor de Princeton, Maestro o Pintor de Edimburgo, Maestro o Pintor de Rycroft, Maestro o Pintor de Castellani). A algunos se les agrupa por sus características comunes (Pequeños maestros, Grupo Leagros, Grupo Perizoma, Grupo de las tres líneas, Grupo pionero -este último ya a comienzos del siglo V a. C.-).

También hubo pintura sobre paneles y muros, que no se ha conservado a excepción de muy pocos restos, como los "Paneles de Pitsa" (descubiertos en una cueva de Sición, la localidad al norte del Peloponeso, cerca del Golfo de Corinto, donde la tradición consideraba que se había inventado la pintura sobre paneles -"pinax" πίναξ, plural "pinakes" πίνακες; de donde viene la palabra "pinacoteca"-). o los frescos de la Tumba del nadador, en Posidonia (Magna Grecia). La influencia etrusca de esta tumba es evidente; aunque a su vez la pintura etrusca había recibido una notable influencia griega durante los siglos VII y VI a. C..

El arte antiguo griego ha perdurado en la forma de esculturas y arquitectura; también en artes menores como el diseño de monedas, el grabado de alfarería y gemas.

Los griegos, como la mayoría de las culturas europeas, consideraban la pintura como una de las formas más altas de arte. Las obras de Polignoto de Tasos, que trabajó en el siglo V a. C., seguían siendo admiradas incluso 600 años después de su muerte, como después ocurrió con las de Leonardo da Vinci o Miguel Ángel, sin embargo en este caso no solo no se han conservado ninguna de sus obras sino tampoco ninguna reproducción.

Los pintores griegos trabajaron generalmente sobre paneles de madera, que se estropeaban rápidamente (a partir del siglo IV a. C.), cuando no eran bien protegidas. Hoy en día no queda casi ninguna pieza de pintura griega, excepto algunos restos de pinturas en terracota y de algunas pinturas en las paredes de tumbas, sobre todo en Macedonia e Italia. De las obras maestras de la pintura griega tenemos solamente algunas copias realizadas en las épocas romanas, la mayoría de ellas son de una calidad inferior.

Con anterioridad a la formación del arte griego en sí hubo en territorios de la antigua Grecia un arte que se ha llamado "prehelénico", conservadas tan sólo en ruinas de edificios de la época y sobre estuco, representando paisajes, acciones guerreras y ceremonias cortesanas o religiosas cuyas figuras aunque imperfectas revelan notable expresión y vida. En las decoraciones de vasijas se presenta raras veces la figura humana y siempre estilizada y de escasos detalles.
En cuanto a la pintura griega, el conocimiento de sus artistas se debe casi por entero a los antiguos historiadores, pues no se conserva de ella ni un solo cuadro ni se conoce obra alguna de los famosos Zeuxis, Parrasio y Apeles, considerados desde la antigüedad los pintores por antonomasia. Las obras pictóricas griegas que al presente se conocen y conservan consisten únicamente en decoraciones de ánforas y de otras elegantes vasijas salvo algunos mosaicos de pavimento y placas de arcilla pintadas y sin contar las obras de pintura romana en que intervino mano griega. Consta, no obstante, que los griegos pintaron cuadros excelentes, por lo menos murales (cuyas copias pueden ser algunas decoraciones de las grandes ánforas de lujo) y que emplearon los procedimientos al fresco, al encausto, al temple y quizás al óleo. Los asuntos representados en tales pinturas, a juzgar por lo que se observa en las mencionadas vasijas, fueron escenas de la vida humana y tradiciones o leyendas mitológicas y heroicas.

La gran mayoría de edificios griegos no han perdurado, debido a varias razones: fueron destruidos en guerras, saqueados para obtener materiales de construcción o abatidos por terremotos. Solamente un puñado de templos, tales como el Partenón y el templo de Hefesto en Atenas. De las cuatro maravillas del mundo creadas por los griegos las cuales ninguna de ellas han perdurado:

La Antigua Grecia destacaba en la arquitectura. Son los templos la construcción más representativa de la arquitectura griega, ya que su principal era brindarle protección o albergue a una deidad o dios. En la parte de adentro se encontraba el efigie de la deidad mientras tanto en la parte exterior se le rendía culto. Los griegos utilizaban el pretexto religioso para justificar con esto sus grandes creaciones de esta forma podían desatar su imaginación y crear maravillosas estructuras. Considerado como una arquitectura sublime esto sirvió de ejemplo para la construcción de otras estructuras griegas; por esto los edificios griegos comparten similares características. 

La diferencia principal del templo arcaico al templo pre-helénico es que se hace el alma de la ciudad, es decir, antes los palacios eran, a su vez, refugios para los ciudadanos en caso de guerra, en la época arcaica son los conjuntos de templos, es decir la acrópolis, es la casa del dios y el refugio de los ciudadanos, ya que estaban situados en una colina y además estaban fortificados, probablemente para las utilidades de antes.

Las ceremonias, cualquiera pese a su importancia, se realizan fuera del templo para que el olor de los sacrificios llegase a la estatua divina para que esta se lo agradeciese y les diese buenas cosechas, etc.

Al principio los templos son muy pequeños y apenas se diferencian de una casa, pero con el tiempo, además de la sustitución de elementos blandos por rocas o sillares, se establecen los órdenes: el dórico, el jónico y el corintio son los tres órdenes, los dos primeros surgen al principio de la época mientras que el corintio se origina después derivando del jónico.
Además la arquitectura griega es adintelada o arquitrabada por la viga que se pone en el pórtico llamada dintel. Ignora los arcos y otros tipos de arquitectura.

Si el templo está rodeado de columnas, se le llama períptero y si las columnas se limitan al pórtico, se llama próstilo, según las columnas que tenga el pórtico, será dístilo (dos columnas), tetrástilo (cuatro), y así sucesivamente siempre siendo pares.


El arquitrabe pasa a tener tres bandas horizontales que se llaman "fasciae" y que rebasan cada una a su inmediata inferior.
El friso es un espacio liso dedicado a realizar esculturas en él. Los demás elementos son iguales que el dórico.

Todas las esculturas y obras de arquitectura que han perdurado, sólo son una pequeña muestra de la inmensa colección de obras griegas. Muchas esculturas de dioses paganos fueron destruidas durante la era cristiana. Desgraciadamente, cuando se calcina el mármol se produce la cal, y ése era el destino de muchas obras de mármol griegas durante la Edad Media. Durante ese mismo período, debido a la escasez de metales, la mayoría de las estatuas de bronce eran fundidas.Actualmente muchas de las obras que hoy tenemos son copias romanas.

La escultura de la Antigua Grecia alcanzó el ideal de la belleza artística hasta donde pudo llegar por sí solo el ingenio humano. Aunque Grecia floreció en todas las Bellas Artes, ninguna le distingue tanto como la escultura. 

Cultivó el arte de la Antigua Grecia todos los géneros de escultura, adoptando con predilección el mármol y el bronce como material escultórico y tomando como asuntos principales los mitológicos y los guerreros a los cuales añadió en su última época el retrato de personajes históricos. 

Forman su característica en los mejores tiempos del Arte (los de Fidias) la expresión de la realidad idealizada, la regular proporción orgánica, el alejamiento de lo vago y monstruoso, la precisión en los contornos y detalles, la armonía y belleza en las formas y la finura en la ejecución.

Suele dividirse la escultura griega en cuatro periodos históricos bien delimitados a los cuales precede el protohistórico o minoico y micénico. En este, se desarrolló por espacio de unos veinte siglos (desde el año 3000 al 1100 a. C. aproximadamente) un arte rudimentario pero lleno de vida y movimiento que modeló el barro y trabajó la piedra, el marfil, el hueso e incluso el oro, el plomo y el bronce, produciendo relieve, grabados, entalles mitológicos en piedras finas y pequeñas estatuas e idolillos. Aunque labrados con cierta tosquedad, se presentan a veces con admirable corrección en el dibujo que parece recordar el arte de los cazadores del reno los cuales pudieron tener con la civilización egea algún lazo histórico.

Los cuatro períodos arqueológicos que tras un prolongado silencio artístico siguieron al micénico se distinguen del siguiente modo:


A partir del período arcaico del arte griego, las cerámicas pintadas y las esculturas son casi las únicas formas de arte que han perdurado. La pintura estaba en sus inicios durante aquel período, y ningún ejemplo ha perdurado. Aunque las monedas fueron inventadas en el siglo VII a. C., no eran comunes en la mayor parte de Grecia hasta el siglo V a. C.

De este período destaca la elaboración de cerámicas para uso cotidiano, o de carácter fúnebre, donde se emplearon grandes jarrones. Estos jarrones estaban ornamentados con representaciones lineales, y motivos relacionados con la muerte, como batallas marítimas o terrestres. La mayor parte de la alfarería está compuesta por piezas domésticas, de las que perduraron recipientes tales como las ánforas, pequeñas cráteras e hidrias. Por otra parte, de la cerámica funeraria se han encontrado varias urnas. También se fabricaron figurillas en barro cocido, principalmente para ser depositadas como ofrenda en los templos. Durante el período helenístico, fue elaborada una gran variedad de objetos de alfarería, aunque sólo algunas poseen valor artístico.

Durante los períodos más antiguos, hasta las pequeñas ciudades griegas producían objetos de alfarería para el mercado local, siendo sus estilos y modelos muy variados. Entre los años 550 y 480 a. C. el arte en cerámica sufrió una gran transformación; además, los autores incluyeron sus nombres, el nombre del alfarero o del pintor que decoraba aquellas piezas (también existían algunos artistas que practicaban ambos labores). La cerámica ática y cerámica corintia destacaron por sobre las demás. Atenas creó las primeras representaciones del estilo bello: recipientes con figuras rojas sobre fondo negro.

La historia de la cerámica griega antigua está subdividida en los siguientes períodos:

La gama de colores que podía ser utilizada sobre la alfarería fue restringida por las técnicas de cocción: negro, blanco, rojo y color amarillo eran los colores más comunes. Durante los tres primeros períodos, las cerámicas guardaban su color natural claro con algunos motivos negros.

Uno de los signos más fácilmente reconocibles de los logros artísticos griegos es su agraciada arquitectura, caracterizada por las elegantes columnas de piedra y los frontones triangulares esculpidos de los tres estilos arquitectónicos que se desarrollaron entre el 600 y el 300 a. C.

Estos estilos fueron creados para construir más templos a los dioses que eran muy importantes para ellos. Esculpidos en mármol, ellos imitaron las técnicas de corte de la madera de los edificios hechos originalmente en este material.

El estilo dórico es el más antiguo y el más simple, con columnas firmes y frentes cubiertos con esculturas que, al mismo tiempo, podían pintarse de rojo o azul para generar impacto; cabe destacar que no tiene base comparado con otros estilos. El mejor ejemplo superviviente de un templo dórico es el Partenón (438 a. C.) en la Acrópolis de Atenas.

El estilo jónico apareció alrededor del mismo tiempo en las ciudades más ricas de Asia Menor. Produce la sensación de más ligereza y es más decorativo, con columnas esbeltas destacando volutas ensortijadas en cada esquina del capitel. El estilo alcanzó su apogeo en el desaparecido Templo de Artemisa en Éfeso, una de las Siete Maravillas del Mundo. Se puede admirar la arquitectura jónica en el Templo de Atenea Niké en la Acrópolis.

Hacia el año 400 a. C. surgió una nueva versión, más elaborada, de la arquitectura jónica: la corintia. Se caracterizaba por intrincadas hojas espinosas de acanto esculpidas en los capiteles de las columnas, que puede reflejar la influencia del Oriente Medio. La prestancia del estilo corintio lo convirtió en el estilo arquitectónico favorito de la arquitectura del Imperio romano.
Los templos se pueden clasificar por el número de columnas que tienen:

-"In antis", si sólo tienen dos en su fachada y muros de la cella.

-Tetrástilo: cuatro.

-Hexástilo: seis.

-Octástilo: ocho.

-Decástilo: diez.

-Próstilo: si sólo tiene un pórtico en la parte delantera.

-Anfipróstilo: si lo tiene también en la parte posterior

-Períptero: cuando las columnas exentas rodean la cella.

-Díptero: cuando son dos las filas de columnas.

-Pseudoperíptero: cuando está dispuesto con columnas adosadas a los lados.

-Áptero: si no tiene columnas.

-Hípetro: si no tiene techo.

s

</doc>
<doc id="15565" url="https://es.wikipedia.org/wiki?curid=15565" title="Arte de la Antigua Roma">
Arte de la Antigua Roma

Arte romano son todas aquellas manifestaciones de las artes visuales desarrolladas en la ciudad de Roma que fueron exportadas a todos los territorios del Imperio romano. Las primeras manifestaciones del arte romano surgieron bajo el influjo del arte etrusco y fueron contagiadas por el arte griego, que los romanos conocieron en las colonias de la Magna Grecia, ubicadas en el sur de Italia y que conquistaron en el proceso de unificación territorial de la península durante los siglos IV y III a. C. La influencia griega se acrecienta cuando, en el , Roma ocupa Macedonia y Grecia.

Hasta cierto punto puede pensarse que el arte de Roma es una imitación y ampliación del arte griego, y por supuesto del arte etrusco, pero el espíritu que animó a los artistas romanos es totalmente diferente de aquellos. La Roma conquistadora y urbanista trató de unir al sentido estético griego, el carácter utilitario y funcional que sus obras requerían.

Desde el punto de vista cronológico, el arte romano se desarrolló con bastante homogeneidad y autonomía desde el hasta el siglo V. Siguiendo las etapas que su devenir histórico marca, destacan al menos la República, hasta el año 27 a. C., y el Imperio, que se extendió desde los tiempos de Augusto hasta la caída de Roma en manos de los bárbaros en el año 476.

A causa del profundo centralismo ejercido por Roma sobre sus provincias en todos los aspectos de la vida, se originó un arte muy uniforme sin que pueda hablarse de escuelas provinciales, al menos durante la época imperial. No obstante, dada la amplitud del Imperio y su constitución en diferentes momentos, no existe una contemporaneidad cronológica, pues en zonas donde el arte helenístico está más consolidado sus formas artísticas están mucho más evolucionadas que en las provincias más tardíamente incorporadas a la cultura romana. Arte romano (del al siglo V):

La Monarquía romana, República romana e Imperio romano, cubren el periodo desde el siglo VIII a. C. al . Se localiza primero en el Latium (Italia Central), y se extiende por toda la Cuenca del Mediterráneo ("Mare Nostrum"). 

El periodo anterior a la recepción de la cultura helenística (siglo III a. C.) desarrolla un arte latino emparentado con otros pueblos itálicos (sabinos y sobre todo etruscos) Loba capitolina . 

El periodo clásico del arte romano dura hasta el triunfo del cristianismo (siglo IV). Asimila y desarrolla la cultura griega (órdenes arquitectónicos, diseño de los templos, concepción escultórica), incorporándole características propias, tanto en materiales de construcción (mortero y cemento y hormigón romanos) como en elementos arquitectónicos (el arco -Arco de triunfo- y la bóveda, orden toscano y orden compuesto, principio de superposición de órdenes) y formas escultóricas (el retrato romano -exigido por el culto a los antepasados y la propaganda política, y que permite datar la evolución estilística y de la moda, sobre todo en la expresión y el peinado- ya el relieve romano, caracterizado por la búsqueda de la profundidad y la perspectiva) y pictóricas (los estilos pompeyanos, decorativos, narrativos o procurando el trampantojo).
Desarrollo arquitectónico con gusto por lo colosal y magnificente, al tiempo que con un acusado sentido práctico y utilitario. (puentes y acueductos -puente de Alcántara, Pont du Gard, Acueducto de Segovia-, calzadas). 

Edificios públicos (termas -termas de Caracalla-, teatro romano -Teatro Marcelo-, circo romano -Circo Máximo-, anfiteatros -Anfiteatro de Capua, Coliseo, Anfiteatro de El Djem-, etc.), religiosos (templo romano -Templo de Vesta, Maison Carrée, Panteón de Agripa-) y civiles (foro romano, basílicas, palacio romano -Domus Aurea de Nerón, construcción original del Palacio de Letrán, luego convertido en residencia papal-, villa romana -Villa romana del Casale- con su versión de villa imperial -Villa Jovis o de Tiberio en Capri, Villa Adriana-, casa romana -domus, vivienda (Roma Antigua)-). 

Escultura histórica narrativa (frisos corridos en relieve: Ara Pacis, Columna trajana), bustos, estatuas de cuerpo entero (Augusto de Prima Porta) y excepcionalmente ecuestres (estatua ecuestre de Marco Aurelio).



</doc>
<doc id="15568" url="https://es.wikipedia.org/wiki?curid=15568" title="Pintura de Francia">
Pintura de Francia

Con el nombre de pintura francesa puede designarse a toda la pintura realizada en lo que actualmente es Francia. 

Sus primeras manifestaciones se dieron en el arte prehistórico, dentro del arte rupestre francocantábrico. No se presenta en todo el territorio francés, sino que se concentra en determinadas zonas, sino allí donde las piedras calizas y areniscas ofrecen paredes adecuadas. La zona más rica se localiza en el Périgord, alrededor de Eyzies-de-Tayac, en los valles del Vézère y del Dordoña, donde pueden encontrarse las cuevas más célebres: Lascaux, Combarelles, Font-de-Gaume, Gabillou o Rouffignac. Las grutas decoradas del valle de Vezère están declaradas Patrimonio de la Humanidad por la Unesco.

Hay otra zona en los Pirineos franceses, como las de Massar (Ariège), Gourdan (Alto Garona), Bruniquel (Tarn y Garona), y otras en los departamentos de Bajos Pirineos y Altos Pirineos.

Son pinturas realizadas en las cuevas, representando animales (el caballo y el bisonte, principalmente), así como figuras humanas y signos. Su finalidad aún no se ha determinado plenamente, habiéndose interpretado como un arte religioso.

A comienzos del siglo XVII persisten las tendencias de la segunda escuela de Fontainebleau. El retorno de Simon Vouet, príncipe de la Academia de San Lucas de 1624 a 1627, en 1627 marca el comienzo de la recuperación de la pintura francesa. Este pintor es considerado el más propiamente barroco.

El naturalismo de origen caravaggesco queda representado en la obra de Valentin de Boulogne († 1634), el famoso tenebrista Georges de La Tour († 1652) que desarrolla su labor en la corte de Lorena y en las escenas campesinas pintadas a la manera de una escena de género por los hermanos Le Nain: Antoine, Louis y Matheo.

Los grandes maestros del clasicismo son Nicolas Poussin (1594-1665), pintor de temas mitológicos e históricos, y Claude Lorrain (1600-1682), destacado paisajista que influyó en el romanticismo e incluso en los orígenes del impresionismo. Ambos residen en Roma, pero reciben continuos encargos para su país. Trabajan en el problema dominante de la expresión de la perspectiva atmosférica. Poussin desempeña un papel decisivo en la rápida perfección de la escuela francesa en su breve vuelta a París (1640-1642).

En la corte francesa de Luis XIII y Luis XIV se cultivó con profusión el retrato. Inició el género el flamenco Philippe de Champaigne (1602-74), con representaciones de los personajes cortesanos en todo su esplendor y que en sus retratos laicos alcanza una expresión más mundana; fue continuado por retratistas que alcanzan ya el siglo XVIII: Hyacinthe Rigaud (1659-1747) y Nicolas de Largillière (1656-1746), quienes restituyen al retrato su calidad plástica, pero con una búsqueda de suntuosidad y elocuencia que excluye la profundidad de análisis.

En la vida pictórica de este siglo destaca la creación de la Academia Real de Bellas Artes (1648), para superar la vieja corporación de pintores, como un gremio u oficio, propugnando en cambio que se contemple como un "arte liberal". Charles Le Brun fue el pintor académico por excelencia, pintor del rey desde 1664, que ejerce una auténtica tiranía artística. Le Brun alcanza el ideal del pintor gran señor y amigo del soberano. Junto a él cabe mencionar al retratista cortesano Pierre Mignard, que hace tender el retrato hacia una fórmula graciosa y vacía.

Antoine Coypel y Charles de la Fosse († 1716) son los últimos representantes de las tendencias barrocas de inspiración italiana.

En este siglo predomina el rococó, unas pinturas llenas de viveza y encanto típicamente francés, con nombres como los de Watteau, Boucher o Fragonard.

A comienzos de siglo, continúa trabajando Hyacinthe Rigaud, cuyo Retrato de Luis XIV, conservado en el Museo del Louvre suele considerarse la imagen más representativa del Gran Siglo. Le Brun sigue marcando las tendencias desde la Academia, institución que goza de gran estabilidad. Aunque los jóvenes artistas siguen yendo a formarse a Roma, se produce un cierto desplazamiento, fijándose más en las obras que se realizan en Venecia.

Las formas del estilo clásico dan paso, en el reinado de Luis XV, al estilo rococó. Su representante más antiguo es Antoine Watteau (1684-1721), creador del género de las "fêtes galantes" («fiestas galantes»). François Boucher (1703-70) es el pintor de la sensualidad, de los desnudos femeninos. Finalmente, Jean-Honoré Fragonard (1732-1806) compagina la realización de escenas galantes y otras más sentimentales que preludian el romanticismo.

Este tono sentimental y algo lacrimoso se evidencia en la obra de Jean-Baptiste Greuze (1725-1815).

Continúa cultivándose el retrato palaciego, poniéndose de moda la técnica del pastel. Nattier († 1766) es el pintor de las damas de la nobleza, con colores claros y representaciones alegóricas. Maurice Quentin de La Tour († 1788), es el más grande pastelista del siglo, con gran penetración psicológica. Finalmente, Jean Siméon Chardin (1699-1779) cultiva el bodegón, y escenas de inspiración holandesa.

Es el siglo de la gran pintura francesa. París se convierte en un referente artístico de primer orden. Es la ciudad a la que los pintores de toda Europa viajan a formarse, sucediendo de este modo a Roma. Los grandes movimientos artísticos surgieron en la capital gala: romanticismo, realismo, impresionismo, postimpresionismo.
Entre los siglos XVIII y XIX se desarrolla el neoclasicismo, como reacción a los excesos rococós. Encarna los ideales de la Ilustración y se convierte en el arte de la Revolución francesa primero y del Imperio Napoleónico después. 

El artista más destacado es Jacques-Louis David (1748-1825), que en 1784 había presentado "Juramento de los Horacios." Como pintor napoleónico destaca en "La coronación de Napoleón I en Notre Dame" (1805-7).

Antoine-Jean Gros (1771-1835) sigue a Napoleón en sus campañas, siendo su obra más conocida "Napoleón visitando a los apestados de Jaffa" (1804).
Jean Auguste Dominique Ingres (1780-1867) es neoclásico, aunque se nota la influencia del romanticismo en cierta tendencia orientalizante ("La Odalisca"). 

El romanticismo se nota ya en un discípulo de David, François Gérard (1770-1837), que pinta retratos al estilo sentimental de la nueva época. 

Los pintores románticos franceses más destacados fueron Pierre Proudhon (1758-1823); Théodore Géricault (1791-1824), cuya obra más conocida es "La balsa de la Medusa"; y Eugène Delacroix (1798-1863), con obras como "Las matanzas de Quíos" y "La muerte de Sardanápalo". 

Ya desde 1831 se aprecia una evolución hacia el realismo, con obras que reflejan un paisaje realista: Camille Corot (1796-1875), pintor de transición entre el paisaje clásico y el realista. Realistas son también los paisajistas de la Escuela de Barbizon. 

El realismo testimonial, que refleja la vida cotidiana del pueblo, viene representada por autores como:

En 1874 se celebra en Francia la primera exposición colectiva de los impresionistas. Es considerado el movimiento más importante en la pintura de las últimas décadas del siglo XIX. 

Édouard Manet (1822-83) es considerado un precursor del movimiento; su obra más conocida es "Le Dejeuner sur l’herbe (Almuerzo sobre la hierba)". 

El cuadro que dio nombre a este movimiento fue "Impresión: sol naciente", de Claude Monet (1840-1936), presentado en la primera exposición colectiva (1874). Dentro del movimiento impresionista pintaron, además, Renoir (1841-1919), Camille Pissarro; Alfred Sisley (1839-99), más bien paisajista; Edgar Degas, que pinta escenas urbanas con luz artificial; Berthe Morisot y Paul Cézanne (1839-1906).

Con este nombre se conoce a un grupo heterogéneo de artistas que pintan entre 1886 y 1907, entre la última exposición impresionista y el surgimiento del cubismo. 

Los principales artistas postimpresionistas fueron: 

Una corriente particular dentro del postimpresionismo es el puntillismo o “divisionismo”, que aparece por primera vez en el Salón de los Independientes de 1884, encabezado por los pintores neoimpresionistas Georges Seurat (1859-1891) y Paul Signac (1863-1935).

Por su parte, el simbolismo se inició en las últimas dos décadas del siglo, con pintores como Gustave Moreau (1826-1898) y Pierre Puvis de Chavannes (1824-1898).

En esta misma época se agrupan una serie de pintores bajo la denominación "Escuela de Pont-Aven", que toma su nombre de la villa frecuentada por los alumnos de la Escuela de Bellas Artes de París. Vienen a ser una síntesis del impresionismo y el simbolismo. Entre otros pintores de esta escuela cabe mencionar a Emile Bernard y Charles Laval.

A la segunda generación simbolista se les conoce como los nabi, con una concepción estética fundamentalmente decorativa. Dentro de esta corriente puede citarse a Pierre Bonnard y Edouard Vuillard.

En la primera década del siglo, nacen en París el fovismo y el cubismo.

Aunque había ejemplos ya desde 1903, el fovismo es un movimiento que se desarrolló en torno al año 1905, cuando una serie de artistas, agrupados en torno a Matisse, se presentan en el "Salón de otoño de 1905". A pesar del escándalo, volvieron a reunirse en el "Salón de los independientes" en 1906. Hacia 1908 el grupo está disuelto, siguiendo cada artista su propia trayectoria.

Su figura más importante es Matisse (1869-1954), del que puede citarse su obra "Interior en rojo". Otros autores destacados son Albert Marquet (1875-1947), Manguin y Comoin. A este grupo se añaden con posterioridad Derain (1880-1954, "Puerto en Collioure", Maurice Vlaminck (1876-1958) y una serie de pintores provenientes de Le Havre: Othon Friesz, Raoul Dufy y Georges Braque.

Entre 1907 y 1914 se desarrolla el Cubismo, movimiento artístico que tuvo como principales fundadores al español Pablo Picasso y al francés Georges Braque. El cubismo trata las formas de la naturaleza por medio de figuras geométricas, representando todas las partes de un objeto en un mismo plano. Es considerada la primera vanguardia ya que rompe con el último estatuto renacentista vigente a principios del siglo XX, la perspectiva. Hace su primera aparición colectiva en el Salón de Independientes de 1911. 

Braque se aparta de su inicial afección al fovismo para lanzarse, tras conocer la obra de Picasso, al cubismo. Otros pintores que difundieron el cubismo fueron: Albert Gleizes (1891-1953), Jean Metzinger (1883-1956), Roger de la Fresnaye (1885-1925) y Fernand Léger (1881-1955). 

Derivados del cubismo son otros movimientos artísticos menores, como el "purismo" de Charles Edouard Jeanneret (1887-1966) y Amédée Ozenfant (1886-1966) y el "orfismo" lanzado desde 1912 por obra de Robert Delaunay y František Kupka, ya prenamente abstractos.

Dentro del arte abstracto Robert Delaunay elaboró, desde 1912, a partir de las teorías de Chevreul sobre el contraste simultáneo de los colores, sus ventanas y sus primeras formas circulares cósmicas abstractas, mientras que František Kupka exponía en el Salón de Otoño de 1912 "Amorfa, fuga de dos colores" y en 1913 "Planos verticales azules y rojos".

La abstracción de Fernand Léger ("Contrastes de forme", 1913-1914) y la de Picabia ("Udnie", 1913) utilizaron formas cubistas sin renunciar a la intensidad cromática.

En paralelo a la abstracción constructivista se desarrolló una abstracción llamada biomórfica, que nació de las formas creadas por Jean Arp a finales de la década de 1910.

En el período de entreguerras París sigue siendo centro de atracción de artistas venidos de otros lugares. Pero pierde protagonismo como centro creador de nuevas tendencias. Así, van surgiendo en otros lugares tendencias como el futurismo (Italia), el expresionismo (Alemania), el constructivismo (la URSS) o el neoplasticismo (Países Bajos).

El movimiento Dada se inicia por Tristan Tzara en 1916, y relacionado con él surge el surrealismo, movimiento creado en Francia. Sin embargo, muchos de sus principales representantes son extranjeros, como los españoles Joan Miró y Salvador Dalí. El propio Max Ernst es un pintor alemán nacionalizado francés. Aunque francés de nacimiento, Marcel Duchamp (1887-1968), quien encarna lo más valioso del dadaísmo neoyorquino de origen europeo. 

La pintura surrealista aparece en escena desde la exposición de 1925 en la Galería Pierre. Dentro de los surrealistas abstractos puede citarse a Andrés Masson e Yves Tanguy. 

Como una tendencia artística "menor" del primer tercio de siglo puede citarse el auge del cartel. Siguiendo la línea de Henri de Toulouse-Lautrec, Jules Chéret (1836-1933) es el primero en producir sistemáticamente, desde 1866, grandes carteles litográficos en color. Más adelante, Cassandre (1901-1968) asume el lenguaje formal del constructivismo para crear unos carteles poéticos ("Etoile du Nord", 1927; "Dubo-Dubon-Dubonnet", 1934).

Dentro del expresionismo pueden encontrarse dos pintores franceses: Georges Rouault (1871-1958) y Jules Pascin (1885-1930).

Tras la Segunda Guerra Mundial, París pierde definitivamente su carácter de centro de creación artística. Hay pintores en los distintos movimientos artísticos originados y difundidos en otros lugares del mundo.

El manifiesto del arte concreto, que publicó Theo van Doesburg en París en 1930, dio lugar a la tendencia del mismo nombre que tuvo un gran desarrollo en Suiza con Max Bill y de Richard Paul Lose, en Francia con François Morellet, y en todas las formas de arte sistemático nacidas después de la guerra. Estas tendencias entraron entonces en competencia con las diversas corrientes tachistas y gestuales (Jean Bazaine, Alfred Manessier, Pierre Soulages y Georges Mathieu, entre otros) que el crítico Michel Tapié reagrupó bajo la denominación de arte informal.

Mathieu, que presenta cierta afinidad con Pollock, puede citarse dentro de las tendencias informalistas y matéricas. Henri Michaux, con telas de manchas vibrantes y dibujos con "graffiti"; y Jean Fautrier usa de procedimientos mixtos que lo acercan a la pintura matérica.

El final de la década de 1960 vivió el desarrollo de una abstracción centrada en el análisis de sus propios componentes, con los grupos BMPT y Support(s)-Surface(s).

Hacia 1960, como una reacción contra el informalismo predominante durante los años 1950, surge una neofiguración en todo el mundo. Junto a Francis Bacon, el gran representante de esta tendencia es Jean Dubuffet, creador del "art brut".

Entre los artistas que, sin ser específicamente fotorrealistas, han utilizado la fotografía como medio de expresar la realidad está el francés Christian Boltanski, quien utiliza fotos de álbumes familiares de otras personas que según sus propias palabras, serían, tras haber fallecido, la prueba de su existencia.



</doc>
<doc id="15569" url="https://es.wikipedia.org/wiki?curid=15569" title="Camellia">
Camellia

El género Camellia agrupa entre 100 y 250 especies (hay cierta controversia sobre el número exacto) originarias de las regiones tropicales y subtropicales de Asia sudoriental, China y Japón. Se las encuentra en los bosques situados a media altura sobre el nivel del mar. Un botánico y misionero jesuita del siglo XVII, Georg Josephus Kamel (también conocido como Camellus), las describió y dibujo después de un viaje a Filipinas a bordo de un galeón español, Carlos Linneo nombró a este género en su honor.

Todas las especies son arbustos y árboles que pueden llegar a medir 10 m de altura. De follaje perennifolio, sus hojas son coriáceas, de un verde oscuro lustroso, enteras, puntiaguadas y de bordes enteros o ligeramente aserrados.

Las flores son generalmente grandes, con cinco sépalos y cinco pétalos (se han conseguido híbridos con doble o múltiple corola y gran cantidad de pétalos), sus colores varían del blanco al rojo pasando por el rosa y, ocasionalmente, pueden aparecer combinadas en el mismo pie e incluso jaspeadas en esas tonalidades. Hay varias especies, menos populares, de flor amarilla.

Quizás la especie más extendida en jardinería sea "C. japónica" por ser la más frecuentemente utilizada. Es nativa de Japón zona suroriental de China y Corea y de ella se deriva la variedad "Adolphe Audusson", indicada para cultivo en interiores. De las hojas de "C. sinensis" se obtiene el té.



</doc>
<doc id="15570" url="https://es.wikipedia.org/wiki?curid=15570" title="Arquitectura del Barroco">
Arquitectura del Barroco

La arquitectura barroca es un período de la historia de la arquitectura que vino precedida del Renacimiento y del Manierismo; se generó en Roma durante el siglo XVII y se extendió hasta mediados del siglo XVIII por los Estados absolutistas europeos.

El término Barroco, derivado del portugués ""barru"", "perla de forma diferente o irregular", se utilizó en un primer momento de forma despectiva para indicar la falta de regularidad y orden del nuevo estilo. La característica principal de la arquitectura barroca fue la utilización de composiciones basadas en puntos, curvas, elipses y espirales, así como figuras policéntricas complejas compuestas de motivos que se intersectaban unos con otros. La arquitectura se valió de la pintura, la escultura y los estucados para crear conjuntos artísticos teatrales y exuberantes que sirviesen para ensalzar a los monarcas que los habían encargado.

En algunos países europeos como Francia e Inglaterra y en otras regiones de la Europa septentrional se produjo un movimiento más racionalista derivado directamente del Renacimiento que se denominó Clasicismo barroco. A lo largo del siglo XVIII se fue desarrollando en Francia un movimiento derivado del Barroco que multiplicaba su exuberancia y se basaba fundamentalmente en las artes decorativas que se denominó Rococó y se acabó exportando a buena parte de Europa en el siglo xvx.
Contrariamente a las teorías según las cuales el movimiento barroco surgió a partir del Manierismo, fue el el movimiento que acabó desencadenando en último término el Barroco. De hecho, la arquitectura manierista no fue suficientemente revolucionaria para evolucionar radicalmente, en un sentido espacial y no sólo superficial, a partir de los estilos de la antigüedad a los nuevos fines populares y retóricos de la época del contrarreformismo.

Ya en el siglo XVI, Miguel Ángel Buonarroti había anunciado el Barroco de una forma colosal y masiva en la cúpula de la Basílica de San Pedro de Roma, así como las alteraciones en las proporciones y las tensiones de los órdenes clásicos expresados en la escalera de acceso a la Biblioteca Laurenciana de Florencia, del mismo autor, y la enorme cornisa añadida al Palacio Farnese. Estas intervenciones habían suscitado diversos comentarios en su época por su brusca alteración de las proporciones clásicas canónicas. No obstante, en otras obras Miguel Ángel había cedido a la influencia manierista, por lo que fue sólo tras el fin del Manierismo cuando se redescubrió a Miguel Ángel como el padre del Barroco.

El nuevo estilo se desarrolló en Roma, y alcanzó su momento álgido entre 1630 y 1670; a partir de entonces el Barroco se extendió por el resto de Italia y de Europa.

La influencia del Barroco no se limitó al siglo XVII; a principios del siglo XVIII se desarrolló el estilo denominado Rococó, que no siendo una pura continuación del primero podría ser considerado como la última fase del Barroco.

En 1585 el Papa Sixto V inició las obras para la transformación urbana de Roma, encargando a Domenico Fontana la conexión entre los principales edificios religiosos de la ciudad por medio de grandes ejes viarios rectilíneos. El proyecto, que se basaba en la ratificación de Roma como "ciudad santa", estableció el precedente para las intervenciones que se habrían de llevar a cabo en diversas ciudades europeas.

A la planificación centralizada de la ciudad ideal renacentista se contrapone la visión de la "ciudad capital" barroca, más dinámica y abierta a sus propios límites, y al mismo tiempo punto de referencia para todo el territorio. En Roma, los centros focales del panorama urbano se subrayaron mediante la colocación de antiguos obeliscos egipcios y altas cúpulas, mientras que en París los nodos del sistema viario se definieron por medio de plazas simétricas, en cuyo centro se colocaba la estatua del soberano.

En líneas generales, la plaza barroca cedió su función tradicional cívica y pública para convertirse en un medio de exaltación de la ideología religiosa o política, como en el caso de las "plazas reales" francesas (la Plaza de los Vosgos o la Plaza Vendôme, por ejemplo) o de la Plaza de San Pedro de Roma.

Durante el Renacimiento, la ciudad se encontraba encerrada en sí misma, de manera física y sensible, ya que el habitar se limitaba casi exclusivamente a lo que sucedía dentro de las murallas. En una escala menor, los espacios públicos eran poco comunes y los espacios privados muy frecuentes. El proceso de urbanización del Barroco fue el motor del de la configuración de la ciudad como un todo.

Así, la ciudad comienza a formar parte del paisaje y se adueña del mismo. El exterior se integra al interior como un integrante más del espacio. Lo que antes era una planta cerrada ahora se “abre” para producir una vinculación entre lo artificial y lo natural, provocando puntos de encuentro entre el mundo de la ciudad y el mundo natural del jardín y del paisaje.

Entre las iglesias, el punto de partida de la arquitectura barroco puede considerarse la Iglesia del Gesù de Roma, construida a partir de 1568 según el proyecto de Jacopo Vignola. El edificio, que representa una síntesis entre la arquitectura renacentista, manierista y barroca, satisfacía plenamente las nuevas exigencias surgidas tras la Contrarreforma: la disposición longitudinal de la planta permitía acoger al mayor número de fieles, mientras que la planta de cruz latina con numerosas capillas laterales suponía un retorno a la tradición del Concilio de Trento. Así de hecho lo hará constar una figura tan importante como el cardenal Borromeo:
Por otro lado, la presencia de una cúpula subrayaba la centralidad del espacio hacia el fondo de la nave, y presagiaba la búsqueda de una integración entre el esquema longitudinal y el centralizado. También la fachada, construida según el proyecto de Giacomo della Porta, anticipaba los elementos más marcadamente barrocos, comparables a los de los alzados de Santa Susana y San Andrés del Valle.

De este modelo derivaron una serie de iglesias de planta longitudinal centralizada o planta central alargada, caracterizadas por el eje longitudinal y por la presencia de un elemento catalizador de la composición, generalmente una cúpula.se construyó en los años 1985
Si los arquitectos manieristas alteraban la composición rigurosa de las fachadas renacentistas añadiéndoles temas y decoraciones caracterizadas por un intelectualismo refinado, pero sin modificar la lógica planimétrica y estructural de la fachada de los edificios, los arquitectos barrocos modificaron tanto la composición en planta como en fachada, generando una concepción nueva del espacio. Las fachadas de las iglesias dejaron de ser la continuación lógica de la sección interna, para convertirse en organismos plásticos que marcaban la transición entre el espacio exterior y el interior. El espacio interior, por tanto, estaba compuesto a partir de figuras complejas basadas en elipses y líneas curvas, y se definía a través del movimiento de los elementos espaciales, diferenciándose radicalmente de la concepción renacentista que generaba una sucesión uniforme de elementos dispuestos de forma simétrica entre ellos.

En la arquitectura civil del momento se puede distinguir entre dos tipos de construcciones nobles: el palacio, situado generalmente en el interior de la ciudad, y la villa del campo.

El palacio italiano y sus derivados europeos permanecieron fieles a la tipología residencial desarrollada durante el Renacimiento, con un cuerpo edificado cerrado en torno a un patio interno. Se dotó a las fachadas principales de cuerpos centrales resaltados y decorados mediante el uso de órdenes gigantes, que ya habían sido anticipados por Palladio. Se extendieron los ejes de simetría al interior del edificio, donde se abrían el vestíbulo y el patio interno; por ejemplo, el eje longitudinal introducido en el Palacio Barberini de Roma contribuía a la definición de la planta y subrayaba la conexión con el exterior del edificio. Por otro lado, este palacio constituyó un punto importante del desarrollo de la tipología residencial palaciega italiana: la planta se constituía en forma de H, y la entrada se producía mediante un profundo atrio que iba haciéndose más estrecho sucesivamente, hasta llegar a una sala elíptica que servía de centro nodal al palacio entero

En Francia, no obstante, el palacio urbano de la nobleza, denominado "hôtel", recuperó para sí el esquema de los castillos medievales. El clima más duro reclamaba una optimización del soleamiento en las principales estancias, lo que generó fachadas escalonadas y grandes alas laterales. El cuerpo principal se encontraba retrasado respecto a la calle y precedido de la "cour d'honneur", un espacio de transición abierto al exterior que al mismo tiempo separaba el palacio de la ciudad. Un ejemplo de este esquema es el parisino Palacio del Luxemburgo, construido a partir de 1615 por Salomon de Brosse. Aquí, a diferencia de otros edificios del mismo estilo y época, los pabellones angulares no fueron destinados a locales de servicio, sino que contenían estancias principales en cada planta.

Fue notable el desarrollo francés de residencias en el campo, los denominados "châteaux", que llevaron a la realización de extensos complejos de los que partían los ejes viarios principales que ordenaban el entorno. Entre ellos cabe destacar el Palacio de Vaux-le-Vicomte (1656-1659), proyectado por Louis Le Vau, y el Palacio de Versalles, máximo símbolo del absolutismo francés y cuyas labores de reconstrucción fueron iniciadas por el mismo Le Vau por encargo de Luis XIV.

El paisaje ideal de la época barroca halló su expresión más característica en el jardín francés especialmente en las creaciones de André Le Notre. El jardín francés se concebía como un paisaje infinito ordenado geométricamente y centrado en el palacio el cual representa el foco del sistema. Pero la verdadera finalidad es la sensación de espacio infinito que se materializa en un eje longitudinal dominante. Todos los demás elementos están relacionados con ese eje, el cual divide dos mundos: el mundo urbano del hombre y el mundo ampliamente abierto de la naturaleza.

Versalles representa la verdadera esencia del medio ambiente del siglo XVII: dominio, dinamismo y apertura. Hacia fines del siglo, todo el paisaje en torno a París se transformó en una red de sistemas centralizados e infinitamente extendidos. La resolución simbólica que parecían tener las plazas para representar el poder del monarca terminó siendo una resolución paisajística para el usuario.

Así, la ciudad comienza a formar parte del paisaje y se adueña del mismo. El exterior se integra al interior como un integrante más del espacio. Lo que antes era una planta cerrada ahora se “abre” para producir una vinculación entre lo artificial y lo natural, provocando puntos de encuentro entre el mundo de la ciudad y el mundo natural del jardín y del paisaje.

En la España, la afirmación del Barroco se encontró con las dificultades debidas a la decadencia económica del reinado de Felipe III. En la segunda mitad del siglo XVI, Felipe II había mandado construir el importante complejo del Monasterio de El Escorial, construido en su mayor parte según el proyecto de Juan de Herrera (1530-1597). A Herrera se debe también el proyecto de la Catedral de Valladolid, en el que se refuerza el concepto del eje central y que sirvió de modelo para la Catedral de México.

Progresivamente, la arquitectura española del siglo XVII fue evolucionando hacia el estilo barroco, aunque no dejó grandes ejemplos significativos. La mayor parte de las influencias barrocas fueron recogidas de forma exclusivamente decorativa, especialmente en las iglesias. Este lenguaje, que resultaba rápidamente comprensible incluso para el segmento de la población menos instruido, fue exportado con éxito a las colonias americanas.

Entre los edificios religiosos más importantes del siglo XVII en España puede destacarse la Colegiata de San Isidro en Madrid, iniciada en 1629, la iglesia de Santa María Magdalena de Granada (iniciada en 1677 con planta longitudinal derivada de los edificios con esta disposición de la Antigua Roma) y la Capilla de Nuestra Señora de los Desamparados en Valencia, de planta elíptica.

I.- Periodo purista o postherreriano (abarca los dos primeros tercios del siglo XVII). La penetración del barroco -en sus formas arquitectónicas italianas (plantas complicadas, movimiento de fachadas, decoración abundante y creadora de contrastes de luz)- va a ser lenta. La presencia de la ideología religiosa de la Contrarreforma y el prestigio de la monarquía de Felipe II pesan sobre el arte de la época: se prefiere la sobriedad, la sencillez y la uniformidad. Hay una evidente pobreza de materiales –ladrillo, tapial y yeso- junto a una depuración de líneas -al estilo del Escorial-. Así como un escaso desarrollo del movimiento en plantas y alzados; se prefiere la línea recta a la curva; hay un predominio de la Iglesia de nave única con capillas entre contrafuertes -tipo de la iglesia del Gesù de los Jesuitas. Las fachadas expresan la misma sencillez de planos:
"De un espíritu abstracto, los palacios, las Iglesias y conventos son con fachadas de paramentos lisos a base de grandes rectángulos ligeramente resaltados e interiores de diáfana blancura en la que solamente se recortan de manera neta las decoraciones de cuadrados y triángulos geométricos de las bóvedas, resultando conjuntos graves y apaciguados para aquellos que los contemplan al exterior o penetran al interior".

Ejemplos de este tipo de arquitectura lo tenemos en la Colegiata de San Isidro de Madrid (construida por un jesuita: es de planta de cruz latina similar a la del Gesù, o a San Andrés de Mantua de Alberti); la iglesia de la Encarnación (Madrid); la Cárcel de Madrid (hoy ministerio de Asuntos Exteriores), la Casa de la Villa de Madrid, la Plaza Mayor de Madrid, la ciudad de Lerma (Burgos); el palacio del Buen Retiro. Estos cinco últimos edificios siguen la línea llamada "estilo escurialense, caracterizado por la sobriedad de líneas, los volúmenes compactos y torres cuadrangulares en las esquinas, techumbres apiramidadas, agujas en los vértices torres, tejas de pizarra negra. En esta época destacan unas especiales concepciones urbanísticas españolas: las plazas mayores, organizaciones casi cerradas, centro de los espectáculos religioso-políticos (procesiones, autos de fe de la Inquisición, predicaciones, recepciones de reyes), formados por distintos bloques de edificios que se unen dejando, bajo ciertas arcadas, paso a las calles periféricas. La más famosa es la Plaza Mayor de Madrid.
II.- Finales del siglo XVII. Se comienza a complicar la arquitectura; primero penetran las formas decorativas del barroco italiano (columnas de orden gigante y salomónicas, movilidad de planos en las fachadas, etc.), y luego las formas espaciales (plantas ovaladas, o cóncavo-convexas, llenas de movimiento).Destacan: fachada de la Catedral de Granada -de Alonso Cano-, dispuesta a manera de arco de triunfo de tres calles, cubiertas de arcos de medio punto; el Pilar de Zaragoza; la torre de las campanas y la del Reloj (Domingo de Andrade) de Santiago de Compostela. Durante el siglo XVII son escasas las construcciones; ya a finales de siglo se construyen: el presbiterio de la Catedral de Valencia. Las obras más barrocas son la fachada de la Catedral- claro ejemplo de los movimientos de fachadas al estilo de Borromini- : entre el escaso espacio que quedaba entre capilla del santo cáliz y Miguelete, se despliega una fachada a modo de biombo con tres calles plegadas en movimientos sinuosos cóncavo convexo, recargada de decoración en relieve y esculturas. La capilla de la Virgen de los desamparados: de planta ovalada, con espacios de entrada o capillas; destacando el camarín de la Virgen. Otros ejemplos son el museo de Bellas Artes, San Pío V y la torre de Santa Catalina, Palacio del Marques de Dos Aguas.

III.- Corriente nacional: Churrigueresco. Durante el siglo XVIII se acelera la construcción de edificios; resalta la plena asimilación de las formas espaciales de Italia (De Borromini y Bernini) en edificios como: San Marcos de Madrid, las Salesas Reales de Madrid, San Francisco El Grande -Madrid-, Palacio Real de Aranjuez -capilla. Son todos ellos edificios en los que destaca su compleja planta con juegos de curvas y contracurvas, cambitación de formas ovaladas, tangentes y secantes; con alzados en los que las cúpulas, bóvedas, etc. son de gran complejidad (destacan las cúpulas encamonada creadas por Francisco Bautista en e1 siglo XVIII: son un sistema de doble cúpula en el que el intradós es de madera y yeso, mientras que el exterior se despega y separa quedando un espacio hueco para lograr mayor efecto de altura y monumentalidad. Al ser de menor peso permite la constitución de espacios más desahogados).
Por otro lado, la arquitectura del siglo XVIII aumenta la tendencia ornamental hasta límites nunca conseguidos; a este estilo se le llama Churrigueresco: por el nombre de la familia con este apellido que produjo mayores obras. Es una decoración de amontonamiento de formas en ciertos lugares del edificio –puertas, fachada, etc; sobresalen por su monumentalidad y aparatosidad. frente al resto del edificio de líneas más sóbrias-. Destacan: colegios de Anava y Calatrava en Valladolid, plaza Mayor de la ciudad de Salamanca. De Pedro Ribera son el puente de Toledo en Madrid, y el Hospicio de Madrid. Otros edificios de este estilo son: San Telmo en Sevilla. La fachada del Obradoiro en Santiago, etc. Esta fachada de Casas y Novoa sustituye a la románica construida delante del Pórtico de la Gloria; es una monumental fachada estructurada como un grandioso arco de triunfo en diversos planos de profundidad (hasta tres) y de una gran verticalidad.

Otra complicación del barroco español se encuentra en los espacios creados para dar cabida a las imágenes religiosas como: reliquias, sagrario , sacristías e imágenes de gran devoción : vienen a combinarse teatrales efectos en la utilización del espacio, la luz indirecta y de procedencia extraña, la pintura, escultura, etc. Son pequeños lugares en los que el barroquismo estalla en su mayor grado de complicación y teatralidad. Destacan el Transparente de la catedral de Toledo (de Narciso Tomé), el camarín y tabernáculo de la Cartuja del Paular, o el Sagrario de la Cartuja de Granada (Francisco Hurtado Izquierdo). Otra de las grandes escuelas del barroco español, es la fundada a inicios del siglo XVIII por Francisco Hurtado Izquierdo, en Priego de Córdoba. En la que intervinieron, sucesivamente, los hermanos Sánchez de Rueda, Juan de Dios Santaella, Francisco Javier Pedraxas, Remigio del Mármol y José Álvarez Cubero.

La arquitectura barroca francesa es sobre todo palaciega, y en cuanto a su exterior, de composición en general muy clásica. Asimismo, las tres claves de la arquitectura barroca francesa serán la sobriedad, la armonía y la claridad.
Es una arquitectura principalmente al servicio de la monarquía absoluta, especialmente a la persona de Luis XIV, el “Rey Sol”, quien tomó el palacio de Versalles como expresión de su poder y de su propia persona, convirtiéndose así en el prototipo de residencia áulica del príncipe absoluto. El monarca es el astro rey, de quien emana toda la sabiduría, toda la luz, y con su gloria ilumina a toda Francia. Este mensaje está claramente presente en la disposición de salones (el dormitorio de Luis XIV ocupa el centro del palacio y está dispuesto exactamente sobre el eje este-oeste, los salones de estado están dedicados cada uno a una divinidad romana, o lo que es lo mismo a un planeta, etc), así como en la fuente de Apolo; cuyo carro tira del sol, el cual, al estar la fuente mirando hacia el este, parece que va a emerger del agua. Muy pronto, el palacio y la ciudad que surgirán en Versalles se convertirán en un suntuoso signo de propaganda política y escenario de un sinfín de extravagancias y derroches.

Inicialmente, Versalles había sido un pequeño pabellón de caza construido por Philibert Le Roy por mandato de Luis XIII, quien quedó prendado de la belleza de aquel paisaje. Su transformación barroca va a seguir un proceso escalonado que coincide con el año 1661 en que empezaron los nuevos trabajos de ampliación acometidos por el arquitecto Louis le Vau, quien había maravillado al monarca demostrando su maestría en la construcción del Chateau de Vaux Le Vicomte. Hasta el momento Luis XIV convirtió Versalles en escenario de sus fastuosas fiestas, las cuales conllevaban también grandes inconvenientes, dado que se habían de desplazar miles de personas y además no había espacio suficiente para alojar a toda la corte. Sin embargo 1668 versalles es aún una mansión en el campo a la que Luis XIV se retira frecuentemente en compañías femeninas y con sus más allegados. Este año Le Vau inicia una segunda ampliación en la que el palacio es literalmente envuelto por un edificio de influencia barroca italiana, orientado hacia los jardines. Inicialmente este "envoltorio" que rodea el palacio primitivo se encuentra en su punto central unido por una gran terraza. Sin embargo, el incierto clima del Île-de-France hace ver lo poco práctico que resulta este gran espacio abierto, por lo que en su lugar se construye la suntuosa Galería de los Espejos. En 1682 Luis XIV expresa su deseo a su superintendente de finanzas Jean Baptiste Colbert, de trasladar la corte a Versalles, es decir, unas 4000 personas entre príncipes, sirvientes, ministros y demás cortesanos. Ello requerirá una obra colosal.

La tercera y última gran ampliación se alarga hasta el año 1692 y es llevada a cabo por el nuevo arquitecto real Jules Hardouin Mansart, quien quintuplicará la superficie de la residencia, añadiendo dos gigantescas alas laterales al núcleo central que se desarrolla alrededor del patio de mármol. Versalles se transforma así en capital de una gran nación; una ciudad con mansiones para los cortesanos, imponentes jardines llenos de esculturas y fuentes, ministerios para la administración, cuarteles para la guardia y las viviendas de los criados. Todo ello simétricamente articulado en torno al palacio que a su vez tiene como eje central la cámara del rey. Después, Mansart añadió dos alas en escuadra y nuevas dependencias: L’Orangerie, un invernadero de plantas exóticas, le Grand Trianon, un pequeño palacete emboscado en los jardines destinado a la intimidad del rey; y las Grandes y Petites Écuries, las caballerizas.

Por su parte, André Le Nôtre diseñó las 3 avenidas de jardines que confluyen en el palacio y los espacios alrededor del gran canal, disponiendo glorietas, fuentes, etc. Estas tres avenidas constituyen todavía hoy las tres principales vías de la ciudad de Versalles.
En la decoración interior del palacio intervino Charles Le Brun, quien se encargó también de la del Chateau de Vaux le Vicomte. De hecho, se dice que este último es el precursor del futuro palacio de Versalles, dado que tomaron parte en su construcción los mismos artistas (Le nôtre, Le Vau, Le brun...). Es por ello por lo que Vaux le Vicomte posee un valor artístico-arquitectónico incalculable.

A partir de Versalles, tanto el palacio como el modelo de jardín francés se extendieron por las cortes europeas. Entre otras obras a destacar de la arquitectura francesa de esta época encontramos el palacio del Louvre, el ahora inexistente Chateau de Marly, ciertas alas del inmenso chateau de Fontainebleau e innumerables creaciones más. Sin embargo, no se puede atribuir el desarrollo de la arquitectura barroca únicamente a las propiedades de la corona, ya que fue en esta época cuando proliferaron también muchas obras de dominio noble y burgués como los chateaux en las zonas rurales y los "hoteles" en las zonas urbanas; por ejemplo el Hotel de Toulouse, actual sede del Banque de France, o el Hotel de Soubise, el cual fue posteriormente remodelado para convertirse en claro ejemplo del estilo rococó. 

Entre los chateaux más destacables, además de los ya mencionados, se encuentran otras obras de François Mansart y su ya mencionado hijo Jules Hardouin, varios de los arquitectos barrocos más prolíficos de la época. Entre sus creaciones destacan el chateau de Dampier construido para el duque de Chevreuse, el ala barroca del Castillo de Blois, el Chateau de Maisons Laffitte (cuya realización marcará un antes y un después en la arquitectura de Francia) y la Iglesia parisina de Los Inválidos (que alberga actualmente los restos de Napoleón Bonaparte) junto con el conjunto adyacente del Hotel des Invalides. Por lo general, Francia fue uno de los países con mayor número de arquitectos de esta época, no sólo por coincidir con un periodo de bonanza económica, sino por contar con una amplia nobleza y burguesía pudiente, capaz de permitirse los excesos y las costosas representaciones arquitectónicas barrocas de estilo teatral.

Los estudios de arquitectura realizados en Italia por el escenógrafo Inigo Jones y el joven Earl of Arundel constituyeron un impulso inicial que abrió paso a una reorientación fundamental de la arquitectura inglesa, que seguía atrapada en las formas tardomedievales y manieristas. The Queen's House, en Greenwich, pone de manifiesto el brusco cambio de tendencias. El palacio de la reina consta de dos bloques rectangulares unidos entre sí por un puente, conectándolo con el que fue el Greenwich Hospital, hoy conocido como la Old Royal Naval College, declarada Patrimonio de la Humanidad por la UNESCO. Sobre la planta baja almohadillada se levanta el "piano nobile," la planta noble, que se abre al jardín mediante una amplia galería con columnas dóricas. Aparte de Jones hubo muy pocos arquitectos de renombre en este periodo, pero entre ellos cabe citar a Isaac de Caus, que erigió Wilton House, con sus elegantes y fastuosas estancias en forma de caja denominadas "The cube" y "The Double Cube". 
Sin duda si hay un arquitecto inglés que destaque por la maestría de sus obras ese es Sir Christopher Wren, quien consiguió imponer en Inglaterra el clasicismo de cuño romano. En 1666, tras el gran incendio de Londres, se le convocó junto con sus colegas para presentar propuestas destinadas a la reconstrucción y urbanización de la que era una de las ciudades más pobladas de la tierra. La impresionante catedral de Saint Paul, cuya silueta es inconfundible en el horizonte de la ciudad, y 51 iglesias más son obra del maestro Wren. También la ampliación del palacio de Hampton Court por orden de Guillermo III de Inglaterra fue llevada a cabo por el mismo entre los años 1689 y 1692. 

John Vanbrugh y Nicholas Hawksmoor otorgaron al estilo de Wren unas dimensiones aún más monumentales y sobre todo más pintorescas y teatrales. A partir de 1699 tuvieron a su cargo la construcción del imponente Castle Howard al norte de Yorkshire. El recinto entre "cour et jardin" (entre patio y jardín) consta de un ala de aposentos similar a un corredor en cuyo centro destacan el salón abierto al jardín y la gran sala cuadrada abierta al patio. En 1715 y 1717 respectivamente publicaron los dos volúmenes del Vitruvius Britannicus, con grabados de edificios británicos clásicos y la traducción de los "Quatro libri dell'architettura" de Andrea Palladio, lo que provocó un nuevo cambio revolucionario: El neopaladianismo. Esta tendencia tenía como objetivo un retorno a las "reglas nobles y verdaderas" de la Antigüedad tal y como las habían interpretado Palladio e Inigo Jones. El principal protagonista de este movimiento fue Lord Burlington, experto en arte que con su Chiswick House creó un edificio de asombrosa semejanza con las obras de Palladio. Por último cabe destacar otras hermosas obras del barroco británico que se materializan en la residencia de los Duques de Devonshire, conocida como Chattsworth en Derbyshire, Inglaterra, de la mano del arquitecto William Talman en 1694; sin olvidar claro está el monumental Blenheim Palace construido en 1710 por el antes mencionado John Vanbrugh, para el duque de Marlborough de parte de la Reina Ana.


La génesis de la arquitectura barroca se inicia en Italia, con figuras tan determinantes como Gian Lorenzo Bernini y Francesco Borromini. 

En España, la arquitectura barroca va a estar presidida por el gusto por la desornamentación y la sobriedad que había introducido el estilo herreriano, con importantes edificios en los que impera un estilo mesurado y casi clásico.

En América, tras la conquista española, el lenguaje del barroco se desarrolló en forma importante enriqueciéndose con la mano de obra y los conceptos propios de la arquitectura y arte precolombinos, como el uso extensivo de colores brillantes, destacándose en forma especial el barroco mexicano, peruano y el cubano.

En Alemania y en Austria la inspiración italiana combinada con la francesa creará edificios de gran exuberancia decorativa, sobre todo en los interiores, de luminosidad brusca, que darán paso al estilo Rococó (El Rococó se define por el gusto por los colores luminosos, suaves y claros).

En Inglaterra predomina el equilibrio y la austeridad.

La ciudad del barroco se ve como la imagen de su gobernante, cuya importancia se mide por su tamaño y por el número de sus habitantes.

En las cortes más poderosas de Europa, la estructura urbana intentará ostentosamente asentar los valores y la estructura política creada por los dirigentes.

La ciudad se va a estructurar en torno a un centro, como el poder absoluto tiene como centro el Rey, al que confluyen grandes vías, rectas de amplias perspectivas. Las plazas serán uno de los grandes elementos, reflejo y símbolo del poder civil o religioso, entendidas como escenarios de fiestas y representación.

Los cambios se van a reflejar mejor en las pequeñas cortes europeas, donde las realizaciones pueden cambiar y determinar la imagen de toda la ciudad, como es el caso de Würzburg, mientras que en los grandes organismos urbanos como París o Roma, la complejidad y la aparatosidad de los proyectos se va a enfrentar con la ciudad preexistente, que dificulta en gran medida la transformación pretendida, consiguiéndose mejores resultados en las nuevas residencias de los soberanos, fuera de la ciudad, como es el caso de Versalles.

América recibió los conceptos urbanísticos renacentistas primero y barrocos posteriormente, a lo largo de la extensiva urbanización que los colonizadores europeos llevaron a cabo durante los siglos XVI a XIX.




</doc>
